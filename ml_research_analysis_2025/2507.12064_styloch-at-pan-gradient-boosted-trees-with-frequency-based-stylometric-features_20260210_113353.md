---
ver: rpa2
title: 'StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features'
arxiv_id: '2507.12064'
source_url: https://arxiv.org/abs/2507.12064
tags:
- text
- detection
- features
- training
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a non-neural stylometric pipeline for generative
  AI detection. It preprocesses texts with spaCy for linguistic annotation and extracts
  n-gram frequency features, then classifies them using LightGBM gradient-boosted
  trees.
---

# StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features

## Quick Facts
- arXiv ID: 2507.12064
- Source URL: https://arxiv.org/abs/2507.12064
- Reference count: 40
- One-line primary result: Improved AI detection performance with gradient-boosted trees and stylometric features, though obfuscation reduces effectiveness.

## Executive Summary
This work proposes a non-neural stylometric pipeline for generative AI detection using spaCy for linguistic annotation and LightGBM gradient-boosted trees. The method extracts n-gram frequency features from token, POS, dependency, and morphological annotations, then classifies texts as human or machine-generated. Results show improved performance with increased model capacity and cross-validation, though the approach is sensitive to obfuscation and has limited cross-domain generalization.

## Method Summary
The pipeline preprocesses texts using spaCy en_core_web_lg to extract linguistic annotations, then computes normalized frequencies of n-grams from four feature classes: lemma n-grams (1-3), POS n-grams (1-4), dependency bigrams, and morphological unigrams. These features are fed into LightGBM gradient-boosted trees with DART boosting, trained on over 563,000 machine-generated texts from multiple datasets. The approach uses stratified 10-fold cross-validation for more reliable error estimation and prediction averaging.

## Key Results
- Increased model capacity (from small to big configurations) improved test performance across validation and test sets
- Stratified 10-fold cross-validation provided more reliable error estimation and improved prediction stability
- Performance degraded on obfuscated test sets, dropping from ~0.92 to ~0.88 on ELOQUENT adversarial data
- False negative rate (0.150) exceeded false positive rate (0.124), indicating higher recall for machine-generated texts but more missed human samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-layer linguistic annotation n-grams capture stylistic signatures that distinguish human from machine text
- Mechanism: spaCy produces token, named entity, dependency, POS, and morphology annotations. Normalized frequencies of n-grams from these layers form a stylometric fingerprint that LightGBM can learn to separate
- Core assumption: Machine-generated and human-authored texts exhibit distinguishable distributions in linguistic annotation n-grams
- Evidence anchors: [abstract] Feature extraction details; [PAGE 3] Specific n-gram computation; [corpus] Limited direct evidence
- Break condition: If annotation distributions significantly overlap or unseen LLM families produce divergent patterns

### Mechanism 2
- Claim: Increased model capacity enables better exploitation of large-scale training data for improved detection
- Mechanism: LightGBM's sequential boosting corrects residuals. Increasing num_leaves, num_iterations, and max_depth raises capacity, allowing more nuanced boundaries on ~563k samples
- Core assumption: Training corpus is representative of test distributions, and capacity gains generalize
- Evidence anchors: [PAGE 5] Capacity scaling improves scores; [PAGE 4, Table 2] Explicit parameter scaling with corresponding improvements
- Break condition: If training data lacks diversity or contains biases, increased capacity causes overfitting

### Mechanism 3
- Claim: Stratified 10-fold cross-validation provides more reliable error estimation and more stable predictions
- Mechanism: Stratified CV trains 10 models on different splits while preserving class balance. Averaging probability scores across folds acts as an ensemble, reducing variance
- Core assumption: Data splits are approximately i.i.d., and ensemble members are sufficiently diverse
- Evidence anchors: [PAGE 5] CV used for reliable estimation; [PAGE 5, Table 3] big-cv outperforms big-single across metrics
- Break condition: If data has temporal or domain structure violated by random splits, CV overestimates performance

## Foundational Learning

- Concept: Gradient Boosted Trees (LightGBM)
  - Why needed here: Core classifier. Understanding sequential residual correction and parameter control is essential for interpreting results and tuning
  - Quick check question: How does increasing num_leaves in a GBT typically affect overfitting risk on a small dataset versus a large one?

- Concept: Stylometry & N-gram Frequency Features
  - Why needed here: The paper's primary signal source. Understanding how n-grams capture local syntactic and lexical patterns is critical
  - Quick check question: Why might POS quadrigrams (4-tag sequences) be informative for authorship detection even when vocabulary differs?

- Concept: Stratified K-Fold Cross-Validation
  - Why needed here: Used for model selection and final prediction. Understanding stratification and ensemble averaging is key to interpreting reported metrics
  - Quick check question: What is the main advantage of stratified k-fold over random splits for imbalanced binary classification?

## Architecture Onboarding

- Component map: Raw Text -> spaCy Annotation -> Feature Extraction (n-gram frequencies) -> LightGBM Classification -> Probability Score (averaged if CV)
- Critical path: spaCy preprocessing produces linguistic annotations, which are converted to normalized n-gram frequencies, then classified by LightGBM
- Design tradeoffs:
  - Explainability vs. Generalization: Frequency-based features over neural embeddings; gains interpretability, risks lower cross-domain generalization
  - Capacity vs. Overfitting: Scaled parameters to exploit large data; improves in-distribution performance but increases overfitting risk on biased data
  - Compute Distribution: Feature extraction is main overhead (one-time); training/inference fast; favors low deployment cost over peak accuracy
- Failure signatures:
  - Obfuscation sensitivity: Performance drops from ~0.92 to ~0.88 on ELOQUENT obfuscated set
  - Out-of-distribution: Prior cross-domain work achieved F1=0.54; performance depends on training coverage
  - FNR exceeds FPR (0.150 > 0.124), indicating higher recall for MGTs but more missed human samples
- First 3 experiments:
  1. Reproduce capacity scaling: Train "small" vs "big" configurations on a data subset; verify validation score increases with capacity
  2. Feature ablation: Retrain "medium" model excluding one feature class; quantify performance delta on held-out set
  3. Obfuscation stress test: Evaluate "big-cv" on manually paraphrased samples; confirm degradation pattern

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does training the classifier on a dataset augmented with obfuscated samples significantly improve robustness against adversarial attacks and paraphrasing?
- Basis in paper: [explicit] The authors note in the conclusion that while "obfuscation considerably reduced" effectiveness, "The straightforward augmentation of the training set with obfuscated samples can further improve the results."
- Why unresolved: The current submission did not include obfuscated or adversarial examples in the training data
- What evidence would resolve it: A comparative evaluation of the model's performance on the ELOQUENT obfuscated test sets before and after fine-tuning on an augmented dataset

### Open Question 2
- Question: Can incorporating TF-IDF features or standardizing feature frequencies enable the LightGBM model to outperform the TF-IDF baseline?
- Basis in paper: [explicit] The conclusion states that "incorporating TF-IDF features... or standardising feature frequencies... could be beneficial," acknowledging that the current model "have not reached the baseline TF-IDF scores."
- Why unresolved: The authors limited the current feature set to frequencies of linguistic annotations and did not merge them with TF-IDF or standardization techniques
- What evidence would resolve it: Ablation studies showing performance metrics on the test set when these specific features are added to the pipeline

### Open Question 3
- Question: To what degree does systematic hyperparameter optimization improve detection accuracy over the fixed parameters derived from smaller datasets?
- Basis in paper: [explicit] The authors identify "hyperparameter optimisation (both in terms of feature set and LGBM parameters)" as an "unexplored avenue."
- Why unresolved: The team used fixed parameters based on prior experiments with smaller datasets and did not perform optimization for the 500k-sample training corpus
- What evidence would resolve it: A comparison of the current "big-cv" model performance against a model tuned via grid search or Bayesian optimization on the full dataset

## Limitations

- Performance relies heavily on in-distribution training data covering 348 LLM labels, with uncertain out-of-distribution generalization
- Feature selection mechanism for the 1500-item cap per class is unspecified, potentially affecting reproducibility
- Model shows vulnerability to obfuscation, with performance dropping significantly on adversarial test sets
- No explicit adversarial training or robustness mechanisms are described

## Confidence

- High: Multi-layer linguistic annotation n-grams capture distinctive stylistic signatures
- High: Increased model capacity improves in-distribution performance
- Medium: Stratified CV provides more reliable error estimation
- Medium: Explainability gains justify potential generalization trade-offs

## Next Checks

1. Out-of-distribution test: Evaluate the "big-cv" model on a held-out subset of LLM families not present in training to quantify domain generalization limits
2. Adversarial robustness test: Apply systematic text perturbations to validation samples and measure performance degradation
3. Feature importance analysis: Perform ablation studies removing individual feature classes to quantify their relative contribution to detection accuracy