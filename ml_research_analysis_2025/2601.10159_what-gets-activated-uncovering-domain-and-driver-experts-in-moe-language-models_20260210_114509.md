---
ver: rpa2
title: 'What Gets Activated: Uncovering Domain and Driver Experts in MoE Language
  Models'
arxiv_id: '2601.10159'
source_url: https://arxiv.org/abs/2601.10159
tags:
- experts
- expert
- domain
- driver
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates expert-level behavior in MoE language models
  by distinguishing domain experts (specialized for specific domains) and driver experts
  (exerting strong causal influence on model outputs). The authors propose entropy-based
  metrics to identify domain experts and causal-effect metrics to identify driver
  experts.
---

# What Gets Activated: Uncovering Domain and Driver Experts in MoE Language Models

## Quick Facts
- arXiv ID: 2601.10159
- Source URL: https://arxiv.org/abs/2601.10159
- Reference count: 19
- Primary result: Entropy-based and causal-effect metrics identify domain and driver experts in MoE models, with weight adjustments yielding 2.08% and 3.00% accuracy improvements respectively.

## Executive Summary
This paper investigates expert-level behavior in Mixture-of-Experts (MoE) language models by distinguishing domain experts (specialized for specific domains) and driver experts (exerting strong causal influence on model outputs). The authors propose entropy-based metrics to identify domain experts and causal-effect metrics to identify driver experts. Analysis across three MoE models (Mixtral, DeepSeek-MoE, Qwen-MoE) and three domains (Sentiment Analysis, MMLU, Math Reasoning) reveals that while general experts dominate, domain experts show clear specialization patterns and driver experts have concentrated causal influence, particularly in middle layers. The study finds that tokens occurring earlier in sentences are more likely to trigger driver experts. Adjusting weights of domain and driver experts leads to significant performance gains - 2.08% and 3.00% accuracy improvements respectively across all models and domains - demonstrating the practical value of task-aware expert activation in MoE models.

## Method Summary
The paper employs an inference-only analysis of three MoE models using entropy-based and causal-effect metrics. For domain experts, it computes per-expert entropy and activation rate, combining them into a Certainty-Weighted Activation Score (CWAS). For driver experts, it applies unit-norm perturbations to routing logits and measures KL divergence between clean and perturbed output distributions. The method involves extracting router logits via hooks during forward passes, computing entropy and CWAS scores to rank experts, implementing perturbation logic for causal effect measurement, and validating findings through weight scaling experiments where expert logits are multiplied by factors like 1.2 (up-weight) or 0.8 (down). Performance is evaluated using accuracy and weighted F1 metrics across three domains.

## Key Results
- Domain experts show clear specialization patterns with distinct CWAS peaks across models and domains
- Driver experts exert concentrated causal influence, clustering in middle layers of MoE models
- Tokens at sentence beginnings disproportionately trigger driver experts
- Weight adjustments of domain and driver experts yield 2.08% and 3.00% accuracy improvements respectively
- General experts dominate activations, but domain experts provide task-specific performance gains

## Why This Works (Mechanism)

### Mechanism 1: Entropy-Based Domain Specialization
The paper proposes a Certainty-Weighted Activation Score (CWAS) that combines low routing entropy with high activation frequency to identify domain experts. Low entropy indicates high certainty of selection for a specific domain, while high activation frequency ensures the expert is both confident and frequently used. This mechanism assumes that low routing entropy correlates with semantic domain specialization rather than token-level syntax or noise patterns.

### Mechanism 2: Causal-Effect Identification of Driver Experts
The paper performs causal intervention by applying unit-norm perturbation to routing logits and measuring KL divergence between clean and perturbed output distributions. High divergence identifies driver experts who exert disproportionate influence on model outputs. This assumes that sensitivity to logit perturbation serves as a reliable proxy for an expert's causal contribution to final decisions.

### Mechanism 3: Positional Token Triggering
The analysis shows tokens appearing at sentence starts are statistically more likely to trigger driver experts. This behavior is attributed to autoregressive bias or structural importance of introductory context in transformer attention mechanisms. The assumption is that this positional bias reflects the prominence of early sentence context in autoregressive models.

## Foundational Learning

- **Sparse MoE Routing (Top-K Gating)**: Understanding which experts are "activated" vs. "masked" is fundamental, as only a subset K of the total expert pool processes each token. Quick check: If K=2 and there are 8 experts, the router decides via softmax over logits plus top-K selection.

- **Entropy (H) and Certainty**: The paper uses low entropy to define high certainty of domain specialization. You need to grasp that H → 0 means the router is confident (selecting one expert almost exclusively), while high H means uncertainty. Quick check: If a router assigns probabilities [0.5, 0.5] to two experts, is the entropy high or low relative to [0.9, 0.1]?

- **Causal Mediation/Perturbation Analysis**: "Driver experts" are defined by how much they change the output when broken. Understanding intervention (changing z to ẑ) is key to separating "correlation" from "causation." Quick check: Why measure D_KL(P || Q) instead of just comparing accuracy? (Answer: It captures shifts in the probability distribution even if the final argmax class doesn't change).

## Architecture Onboarding

- **Component map**: Input Token x -> Router Logit z -> [Intervention Point] Modify z (perturb or scale) -> Softmax & Top-K -> Routing Weights G(x) -> Weighted Sum of Expert Outputs -> Layer Output

- **Critical path**: 1) Input Token x -> Router Logit z 2) [Intervention Point] Modify z (perturb or scale) 3) Softmax & Top-K -> Routing Weights G(x) 4) Weighted Sum of Expert Outputs -> Layer Output

- **Design tradeoffs**: Identification vs. Optimization - calculating causal effects requires expensive inference passes with perturbations compared to simple weight inspection. Specificity vs. Generality - up-weighting domain experts helps specific tasks but may degrade general capabilities.

- **Failure signatures**: Router Saturation - if the router always selects the same experts regardless of input, CWAS and causal metrics become uninformative. Metric Instability - if an expert has very low activation frequency, entropy calculation can be noisy or misleading.

- **First 3 experiments**:
  1. Verify Domain Experts: Take the "Math" dataset, run inference, and calculate CWAS for all experts. Check if the top-ranked experts differ from those in the "Sentiment" dataset.
  2. Verify Driver Experts: Implement the perturbation logic (add random noise vector to logits of expert ei). Run inference on 100 samples and verify that D_KL is significantly higher for the identified "driver" experts compared to random inactive experts.
  3. Validate Weight Scaling: Identify the top Driver Expert for a specific task. Modify the forward pass to multiply that expert's logits by 1.2 (up-weight) and measure the accuracy change on a held-out test set.

## Open Questions the Paper Calls Out

### Open Question 1
Why do tokens occurring earlier in sentences disproportionately trigger driver experts, and is this pattern universal across languages with non-left-to-right reading orders? The authors observe this pattern but do not conduct controlled experiments to disentangle positional encoding effects, autoregressive causality, or semantic salience of sentence-initial tokens.

### Open Question 2
How robust are domain and driver expert identifications to the choice of entropy and causal-effect thresholds, and what are principled methods for setting these thresholds? The paper does not provide sensitivity analysis or theoretical justification for threshold selection.

### Open Question 3
Why does fine-tuning the router yield inconsistent benefits across models (improving DeepSeek and Qwen but degrading Mixtral), and what architectural factors determine router-tuning effectiveness? The paper observes the discrepancy but does not analyze router architecture differences that might explain why direct weight manipulation outperforms learned router adaptation in some cases.

### Open Question 4
Do domain and driver experts emerge consistently in MoE models trained with different objectives (e.g., instruction-tuning, RLHF) or at different scales beyond the three models studied? Only base models are studied, and it's unknown whether instruction-tuned or RLHF-aligned variants preserve or alter expert specialization patterns.

## Limitations
- Identification relies on thresholds and routing logs, making results sensitive to design choices and hyperparameters
- Only three MoE LLMs are evaluated, and architectural and scale differences may affect the prevalence and behavior of domain/driver experts
- The causal-effect identification assumes KL divergence serves as a perfect proxy for causal influence, which may not capture indirect effects through gating mechanisms

## Confidence

**High Confidence**: Domain expert identification through CWAS metrics and performance improvements from up-weighting these experts (2.08% accuracy gain). The entropy calculation methodology and CWAS formulation are well-defined and reproducible.

**Medium Confidence**: Causal-effect identification of driver experts and their clustering in middle layers. While the perturbation methodology is sound, the assumption that KL divergence serves as a perfect proxy for causal influence needs further validation.

**Low Confidence**: Positional token triggering claims and their interpretation as reflecting autoregressive bias. This finding is based on statistical correlation without mechanistic explanation, and the paper itself notes potential task-dependent variations.

## Next Checks

1. **Ablation Test for Domain Expert Generalization**: Evaluate the performance of top-CWAS domain experts when tested on out-of-domain data to verify that low entropy truly reflects semantic domain specialization rather than token-level memorization or noise patterns.

2. **Causal Effect Validation with Multiple Perturbation Methods**: Compare the KL divergence-based causal effect identification with alternative perturbation approaches (e.g., gradient-based attribution, intervention at expert outputs rather than logits) to validate that the identified driver experts represent true causal influence rather than measurement artifacts.

3. **Positional Bias Task Dependency Analysis**: Test the positional token triggering hypothesis across diverse task types, including tasks requiring end-of-prompt reasoning and long-document processing, to determine whether the observed early-token bias is a general property or task-specific artifact.