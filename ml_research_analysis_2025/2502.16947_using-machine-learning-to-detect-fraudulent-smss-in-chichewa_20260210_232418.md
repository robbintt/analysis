---
ver: rpa2
title: Using Machine Learning to Detect Fraudulent SMSs in Chichewa
arxiv_id: '2502.16947'
source_url: https://arxiv.org/abs/2502.16947
tags:
- smss
- dataset
- learning
- datasets
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces the first Chichewa SMS dataset for fraud
  detection, addressing the gap in machine learning research for low-resource African
  languages. SMS fraud is a growing global issue, with significant financial losses
  reported annually, particularly in regions where internet access is limited and
  mobile communication dominates.
---

# Using Machine Learning to Detect Fraudulent SMSs in Chichewa

## Quick Facts
- **arXiv ID**: 2502.16947
- **Source URL**: https://arxiv.org/abs/2502.16947
- **Reference count**: 0
- **Primary result**: First Chichewa SMS dataset for fraud detection, with ML models achieving >96% accuracy on original language data

## Executive Summary
This study introduces the first Chichewa SMS dataset for fraud detection, addressing the gap in machine learning research for low-resource African languages. SMS fraud is a growing global issue, with significant financial losses reported annually, particularly in regions where internet access is limited and mobile communication dominates. Chichewa, a major language in Southern Africa, lacks dedicated NLP tools and datasets for fraud detection, making it difficult to develop targeted machine learning models. To address this, the researchers created a balanced dataset of 676 SMS messages in Chichewa, manually labeled as fraudulent or normal, and expanded it using label-preserving text augmentation techniques.

The dataset was also translated into English using both human and machine translation methods, creating three datasets for analysis: the original Chichewa (D-CHI), human-translated (D-HT), and machine-translated (D-MT) versions. Machine learning models—Random Forest (RF), Support Vector Machine (SVM), Logistic Regression (LR), and Naïve Bayes (NB)—were trained and tested on these datasets. The models achieved high accuracy on the original Chichewa dataset, with RF and SVM performing best, both exceeding 96% accuracy. However, performance dropped when models were applied to the translated datasets, particularly the machine-translated one, highlighting the challenges of relying on translation for training and the importance of language-specific models. Additionally, the study found that adding more normal messages to the dataset improved overall performance but worsened the detection of fraudulent SMS, emphasizing the need for balanced datasets and specialized classification approaches. This research underscores the necessity of developing language-specific tools and models for effective SMS fraud detection in underrepresented languages.

## Method Summary
The researchers created a balanced dataset of 676 Chichewa SMS messages, manually labeled as fraudulent or normal. They employed label-preserving text augmentation techniques to expand the dataset. The messages were then translated into English using both human and machine translation methods, resulting in three datasets: original Chichewa (D-CHI), human-translated (D-HT), and machine-translated (D-MT). Four machine learning models—Random Forest, Support Vector Machine, Logistic Regression, and Naïve Bayes—were trained and evaluated on these datasets using appropriate train-test splits and performance metrics.

## Key Results
- Random Forest and SVM models achieved over 96% accuracy on the original Chichewa dataset
- Model performance significantly decreased on translated datasets, especially the machine-translated version
- Adding more normal messages improved overall accuracy but reduced fraudulent SMS detection capability

## Why This Works (Mechanism)
The high performance on original Chichewa data demonstrates that language-specific models outperform translated versions, validating the need for native language NLP tools in fraud detection. The accuracy drop in translated datasets reveals translation quality issues and confirms that direct translation is insufficient for maintaining model performance in fraud detection tasks.

## Foundational Learning
- **Text augmentation techniques**: Why needed - to expand limited datasets; Quick check - verify augmented samples maintain label integrity
- **Cross-lingual model performance**: Why needed - to understand translation impact; Quick check - compare model metrics across original and translated datasets
- **Class imbalance effects**: Why needed - to optimize fraud detection; Quick check - analyze precision/recall trade-offs with dataset rebalancing

## Architecture Onboarding
**Component map**: SMS data -> Text augmentation -> Translation -> Feature extraction -> ML classification -> Performance evaluation
**Critical path**: Data collection → Labeling → Augmentation → Model training → Evaluation
**Design tradeoffs**: Original language models offer higher accuracy but limited scalability, while translation enables broader applicability at the cost of performance
**Failure signatures**: Performance degradation on translated datasets, false negatives increasing with dataset imbalance
**First experiments**: 1) Train RF/SVM on D-CHI and evaluate; 2) Test same models on D-HT and D-MT; 3) Analyze class-wise performance with dataset rebalancing

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size (676 messages) may not capture full SMS diversity
- Manual creation and labeling introduces potential human bias
- Limited generalizability to other low-resource African languages
- No analysis of adversarial techniques or temporal model stability

## Confidence
- **High confidence**: Dataset creation methodology and ML model comparison are well-documented and rigorously executed
- **Medium confidence**: Claim of being first Chichewa SMS dataset appears credible based on literature review
- **Low confidence**: Generalizability to other languages and real-world deployment effectiveness remains uncertain

## Next Checks
1. External validation on larger, independently collected Chichewa SMS dataset
2. Comprehensive translation quality evaluation using BLEU and human assessment
3. Real-world deployment trial for 3-6 months to test temporal stability and demographic performance