---
ver: rpa2
title: 'RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals'
arxiv_id: '2505.15110'
source_url: https://arxiv.org/abs/2505.15110
tags:
- table
- reasoning
- long
- traversal
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Row-of-Thought (RoT), a training-free method
  for table reasoning that improves reliability and reduces cost compared to Long
  Chain-of-Thought (Long CoT). RoT iteratively traverses tables row-by-row, leveraging
  LLMs' reflection capabilities to update intermediate results and refine reasoning
  at each step.
---

# RoT: Enhancing Table Reasoning with Iterative Row-Wise Traversals

## Quick Facts
- arXiv ID: 2505.15110
- Source URL: https://arxiv.org/abs/2505.15110
- Reference count: 40
- This paper proposes Row-of-Thought (RoT), a training-free method for table reasoning that improves reliability and reduces cost compared to Long Chain-of-Thought (Long CoT).

## Executive Summary
RoT enhances table reasoning by iteratively traversing tables row-by-row, leveraging LLMs' reflection capabilities to update intermediate results and refine reasoning at each step. This approach mitigates hallucination and focuses attention on tabular content. Experiments show RoT with non-reasoning LLMs outperforms Long CoT with reasoning LLMs by an average of 4.3% and achieves state-of-the-art results on WikiTableQuestions (78.7%) and TableBench (44.8%) with comparable models. RoT also demonstrates higher efficiency by using fewer reasoning tokens than Long CoT.

## Method Summary
RoT is a training-free prompting method that improves table reasoning by enforcing row-wise traversal. The model processes tables iteratively, row by row, updating intermediate results at each step. This iterative approach allows the model to reflect on its reasoning and potentially traverse multiple times for complex questions. The method works with both reasoning and non-reasoning LLMs, using zero-shot prompting for the former and one-shot for the latter.

## Key Results
- RoT with non-reasoning LLMs outperforms Long CoT with reasoning LLMs by an average of 4.3%
- Achieves state-of-the-art results on WikiTableQuestions (78.7%) and TableBench (44.8%) with comparable models
- Uses fewer reasoning tokens than Long CoT while maintaining higher accuracy

## Why This Works (Mechanism)

### Mechanism 1: Attention Grounding via Structural Constraints
Constraining reasoning to sequential row-wise steps reduces hallucination by forcing the model to attend to tabular content that might otherwise be lost in long contexts. By decomposing the task into row-level operations, the model retrieves and processes information in smaller, grounded chunks rather than maintaining a representation of the entire table simultaneously.

### Mechanism 2: Implicit Reasoning Scaling via Traversal
Iterative traversal allows non-reasoning models (non-RLLMs) to achieve performance comparable to or better than reasoning models (RLLMs) by scaling inference compute without training. The number of rows dictates the minimum number of reasoning steps, enforcing a "slow-thinking" pattern where the model accumulates intermediate results sequentially.

### Mechanism 3: Dynamic Reflection and Correction Loops
Allowing the model to autonomously iterate over the table enables self-correction and handling of multi-hop questions that single-pass methods miss. After one pass, the model can reflect on the intermediate result. If insufficient or doubtful, it initiates a new traversal, emulating reflection capability but triggering it based on the structured state of the table traversal.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) Scaling**
  - Why needed: RoT is fundamentally a method to scale CoT. Understanding that "reasoning length" correlates with accuracy is crucial.
  - Quick check: How does the token count of RoT's output compare to Short CoT, and why does this matter for accuracy? (See Section 3.4.3)

- **Concept: Hallucination in Structured Data**
  - Why needed: The primary motivation is that LLMs hallucinate when processing tables. Understanding why (attention drift) is essential to see how row-wise traversal fixes it.
  - Quick check: In the error analysis (Section 3.4.1), what percentage of Long CoT errors were attributed to hallucination compared to locating errors?

- **Concept: In-Context Learning (ICL) & Demonstrations**
  - Why needed: RoT is training-free and relies entirely on the prompt to teach the algorithm of row-wise traversal.
  - Quick check: Why does the paper suggest using "one-shot" for non-RLLMs but "zero-shot" for RLLMs (Section 3.4.6/B.1)?

## Architecture Onboarding

- **Component map:** Input Processor -> Prompt Constructor -> Inference Loop -> Output Parser
- **Critical path:**
  1. **Prompt Engineering:** The instruction must explicitly enforce the row-by-row constraint. Without this, the model reverts to standard CoT.
  2. **Iteration Logic:** The system must allow the LLM to generate multiple traversals. It cannot force a stop after the first pass if the model generates a "Let me re-examine" statement.

- **Design tradeoffs:**
  - **Row vs. Column Traversal:** Row-wise is generally superior because LLM attention mechanisms handle sequential rows better than fragmented columns. Exception: HiTab dataset (hierarchical headers) performed better with column-wise traversal.
  - **Token Consumption vs. Reliability:** RoT uses more tokens than Short CoT but fewer than Long CoT. It trades latency for higher reliability (reduced hallucination).

- **Failure signatures:**
  - **Early Termination:** The model concludes the answer before traversing all relevant rows (Locating Error).
  - **Context Overflow:** On tables with >50 rows, the accumulated reasoning history exceeds the context window.
  - **Format Drift:** The model stops outputting the specific row-by-row format and begins summarizing.

- **First 3 experiments:**
  1. **Sanity Check (WikiTQ):** Run the provided RoT prompt (one-shot) on Llama3-8B vs. a standard CoT prompt. Verify the row-wise structure appears in the output tokens.
  2. **Ablation (Unit of Traversal):** Implement a switch to traverse by *Column* instead of *Row* on the WikiTQ dataset to reproduce the performance drop shown in Figure 8.
  3. **Stress Test (Table Size):** Generate synthetic tables of increasing row counts (10, 20, 50, 100) to identify the "Break condition" where performance degrades due to context length limits (Figure 7).

## Open Questions the Paper Calls Out
None

## Limitations
- Performance heavily depends on specific prompt templates, particularly demonstration selection for non-RLLMs and zero-shot prompt for RLLMs
- The scalability claims regarding table size limits are based on a small sample of 6 tables per size bin
- For hierarchical tables in HiTab, the selection logic for choosing between row-wise and column-wise traversal is not defined

## Confidence

- **High Confidence:** The core claim that row-wise traversal reduces hallucination and improves reliability is well-supported by error analysis and ablation studies.
- **Medium Confidence:** The claim that RoT enables non-RLLMs to outperform RLLMs (4.3% average gain) is supported by experimental data but may be sensitive to specific model versions and prompt engineering.
- **Low Confidence:** The scalability claims regarding table size limits are based on limited testing with small sample sizes.

## Next Checks

1. **Prompt Template Isolation:** Implement the RoT prompt with and without the demonstration (one-shot vs. zero-shot) for a single non-RLLM model on WikiTQ. Measure the performance drop to quantify the dependency on demonstration quality.

2. **Hallucination Quantification:** Run the same WikiTQ questions through Long CoT and RoT for a non-RLLM. Use a script to compare the model's stated table values against the actual Markdown table to measure the absolute reduction in hallucination rate.

3. **Context Window Stress Test:** Generate synthetic tables of 10, 25, 50, 75, and 100 rows. Run RoT and measure: (a) the model's accuracy, (b) the total token count of the reasoning, and (c) whether the model completes the traversal or truncates. Identify the precise point where context length becomes a bottleneck.