---
ver: rpa2
title: 'Generative AI in Live Operations: Evidence of Productivity Gains in Cybersecurity
  and Endpoint Management'
arxiv_id: '2504.08805'
source_url: https://arxiv.org/abs/2504.08805
tags:
- incident
- copilot
- security
- alerts
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper measures the association between generative AI (GAI)
  tool adoption and productivity across four security and endpoint management metrics:
  number of security alerts per incident, probability of security incident reopenings,
  time to classify data loss prevention alerts, and time to resolve device policy
  conflicts. Using observational data from live operations and causal inference methods
  (difference-in-differences, propensity score matching, and two-way fixed effects
  regressions), the authors find that GAI adoption is associated with robust and statistically
  significant productivity improvements: 22.88% decrease in alerts per incident, 68.44%
  decrease in incident reopening probability, 18.38% reduction in DLP alert classification
  time, and 54.34% reduction in device policy conflict resolution time.'
---

# Generative AI in Live Operations: Evidence of Productivity Gains in Cybersecurity and Endpoint Management

## Quick Facts
- arXiv ID: 2504.08805
- Source URL: https://arxiv.org/abs/2504.08805
- Authors: James Bono; Justin Grana; Kleanthis Karakolios; Pruthvi Hanumanthapura Ramakrishna; Ankit Srivastava
- Reference count: 19
- Primary result: GAI adoption associated with 22.88-68.44% productivity gains across four security metrics

## Executive Summary
This study investigates the association between generative AI tool adoption and productivity in cybersecurity and endpoint management using observational data from Microsoft Defender XDR, DLP alerts, and Intune policy conflicts. The authors employ difference-in-differences analysis with propensity score matching across 378 organizations to measure four key productivity metrics. Results show robust, statistically significant associations between GAI adoption and productivity improvements: 22.88% decrease in alerts per incident, 68.44% decrease in incident reopening probability, 18.38% reduction in DLP alert classification time, and 54.34% reduction in device policy conflict resolution time.

While the authors acknowledge that unobserved confounders prevent definitive causal identification, these findings provide compelling evidence that generative AI tools can substantially enhance security operations productivity. The study also reveals that productivity gains are primarily driven by human-in-the-loop interfaces rather than automated API flows, suggesting that the cognitive augmentation provided by AI summarization is the key mechanism rather than pure automation.

## Method Summary
The study uses difference-in-differences with two-way fixed effects and propensity score matching to analyze productivity metrics before and after GAI adoption. Data sources include Microsoft Defender XDR telemetry (378 treated organizations), DLP alerts (71 organizations, 262,718 alerts), and Intune policy conflicts (494 organizations, 207,804 incidents). Treatment and control groups were constructed by matching on segment, industry, country, strategic category, and security product seats. The analysis employs log-linear models for time outcomes and logistic regression for reopening probability, with cluster-robust standard errors at the organization level. Data filtering removed incidents with >1000 alerts, excluded organizations with reopening rates >0.8, and limited DLP alerts to those classified within 60 minutes.

## Key Results
- 22.88% decrease in number of security alerts per incident
- 68.44% decrease in probability of security incident reopenings
- 18.38% reduction in time to classify data loss prevention alerts
- 54.34% reduction in time to resolve device policy conflicts

## Why This Works (Mechanism)

### Mechanism 1: Accelerated Information Synthesis (Summarization)
GAI tools reduce mean time to resolution and classification by summarizing complex telemetry and policy conflicts into analyst-ready formats, compressing the "reading and understanding" phase of incident response. The system aggregates data from SIEM/XDR solutions and policy management tools, generating natural language summaries that highlight salient features instead of requiring manual correlation of alerts or parsing of policy discrepancies.

### Mechanism 2: Early Incident Termination (Kill-Chain Shortening)
GAI adoption correlates with a 23% reduction in alerts per incident, suggesting analysts resolve threats earlier in the attack lifecycle before additional malicious actions generate more telemetry. By providing guided response actions and immediate interpretation of malicious scripts, the GAI enables faster core threat remediation, preventing attacks from progressing to subsequent stages that would trigger additional alerts.

### Mechanism 3: Decision Quality Enhancement (Accuracy & Consistency)
GAI tools improve initial triage decisions, evidenced by a 68% drop in incident reopenings. The GAI acts as a "second pair of eyes" or knowledge base, retrieving relevant threat intelligence and guiding analysts to appropriate responses, reducing the likelihood of incorrectly marking active threats as resolved or false positive.

## Foundational Learning

- **Security Operations Center (SOC) Metrics & Lifecycle**: Understanding the difference between "raw alerts" and "incidents" (aggregations of alerts) is required to interpret the "alerts per incident" metric. *Quick check*: If an analyst resolves an incident with 5 alerts instead of 20, does that necessarily mean they were faster, or did they catch it earlier?

- **Difference-in-Differences (DiD) with Observational Data**: The authors use DiD to compare adopters vs. non-adopters, requiring the "parallel trends" assumption. *Quick check*: Why does the paper state that "unobserved confounders inhibit causal identification" even after finding statistical significance?

- **Selection Bias in Tech Adoption**: The treatment group self-selected into adoption, introducing selection bias. *Quick check*: Would you expect a lazy, under-funded security team to adopt expensive GAI tools, or a high-performing, well-funded team? How does this affect the results?

## Architecture Onboarding

- **Component map**: Microsoft Defender XDR (telemetry/alerts) -> Microsoft Security Copilot (LLM + Security-specific plugins) -> Web Portal (Human-in-the-loop) vs. API (Automation pipelines) -> Outcome Measurement (telemetry logs with timestamps and metadata)

- **Critical path**: 1) Ingest raw telemetry (e.g., DLP alert triggered) 2) Copilot generates summary/context 3) Analyst (or API) makes classification/resolution decision 4) System logs time delta and accuracy (reopening status)

- **Design tradeoffs**: Observational vs. Experimental (high ecological validity vs. potential selection bias); Web Portal vs. API (human speed boost vs. negligible effect on automated flows)

- **Failure signatures**: Automation bias leading to missed nuances; selection effect limiting generalizability; metric gaming through premature incident closure

- **First 3 experiments**:
  1. Isolate the Interface Effect: A/B test "true positive" DLP alerts, comparing Web Portal (with Copilot) vs. standard tools
  2. Verification Overhead Test: Measure "Time to Verify Summary" vs. "Time to Read Raw Logs" for novel policy conflicts
  3. Reopening Root Cause Analysis: Qualitative review of remaining ~32% of reopened incidents to identify specific threat classes where GAI fails

## Open Questions the Paper Calls Out

1. **Why does GAI adoption correlate with reduced classification time for true positive DLP alerts but not for false positives?**
   - The authors note this is "an unproven conjecture" suggesting learning effects but lacking direct evidence
   - Resolution requires experimental studies isolating the classification task or qualitative analysis of analyst workflows

2. **Does self-selection of high-benefit organizations into early adoption overstate average productivity impact for non-adopters?**
   - The authors argue early adopters likely represent organizations that would benefit most, potentially overstating generalizability
   - Resolution requires randomized controlled trials or natural experiments with varying adoption propensities

3. **To what extent are observed productivity gains driven by unobserved co-occurring factors like budget expansion or additional training?**
   - The authors acknowledge that organizational changes like staffing or training cannot be isolated from telemetry alone
   - Resolution requires survey data combined with telemetry or field experiments controlling rollout

## Limitations
- Observational data prevents definitive causal identification due to unobserved confounders
- Results may not generalize to organizations with lower security maturity or different GAI implementations
- Selection bias from self-selection into adoption may overstate typical productivity gains

## Confidence
- **High confidence**: Statistical associations within the studied population are robust and substantial
- **Medium confidence**: Practical significance and generalizability to broader populations is uncertain due to selection effects
- **Low confidence**: Causal interpretation that GAI directly caused improvements cannot be definitively established

## Next Checks
1. Conduct controlled A/B testing on "true positive" DLP alerts to validate the 18% time saving claim with higher causal certainty
2. Measure verification overhead for novel policy conflicts to determine if the 54% reduction holds when accuracy verification is required
3. Perform qualitative analysis of reopened incidents to identify specific threat classes where GAI mechanisms fail