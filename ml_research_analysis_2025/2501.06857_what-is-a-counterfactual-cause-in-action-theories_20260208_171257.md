---
ver: rpa2
title: What Is a Counterfactual Cause in Action Theories?
arxiv_id: '2501.06857'
source_url: https://arxiv.org/abs/2501.06857
tags:
- cause
- action
- pickup
- actual
- achievement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a counterfactual account of actual causality
  in action theories. The key idea is to define a minimal cause as the shortest action
  sequence that achieves a goal, where counterfactual analysis requires that removing
  this sequence prevents the goal from being achieved by any shorter sequence.
---

# What Is a Counterfactual Cause in Action Theories?

## Quick Facts
- **arXiv ID:** 2501.06857
- **Source URL:** https://arxiv.org/abs/2501.06857
- **Reference count:** 40
- **Primary result:** Proposes a counterfactual account of actual causality in action theories using minimal action sequences and filters inexecutable actions post-counterfactual

## Executive Summary
This paper introduces a counterfactual account of actual causality within action theories, defining minimal causes as the shortest action sequences that achieve a goal while ensuring counterfactual analysis requires that removing this sequence prevents the goal from being achieved by any shorter sequence. The authors formalize this through Basic Action Theories (BATs) and show how their approach generalizes to achievement causes in action histories. They demonstrate that their framework provides a natural way to think about actions, effects, and preconditions in actual causation, with potential applications in robot programming and agent-oriented programming. The work also compares their approach to Halpern and Pearl's structural equation model account, noting that while their uniform standard modeling is simpler, it has limitations in handling non-atomic competing events where actions interleave.

## Method Summary
The method centers on identifying minimal counterfactual achievement causes within Basic Action Theories (BATs) using logical entailment checking. Given a BAT Σ, an action history z, and a goal φ, the approach first verifies that the goal is achieved after executing z. It then systematically checks prefixes of z to find the shortest one whose removal (with filtering of now-inexecutable actions) would prevent the goal from being achieved. The regression procedure converts future-state queries into present-state formulas by recursively applying successor state axioms, enabling efficient projection without simulation. The Filter function recursively removes actions that become inexecutable after prefix removal. Minimality can be measured by sequence length or by the set of fluents affected, with the latter capturing causal relevance more precisely but risking inclusion of irrelevant actions.

## Key Results
- Defines minimal causes as shortest action sequences achieving goals, with counterfactual analysis requiring that removing them prevents achievement by shorter sequences
- Introduces achievement cause for action histories using prefix-based counterfactual removal with inexecutable action filtering
- Shows the proposed framework generalizes Batusov and Soutchanski's causal chain and compares favorably to Halpern and Pearl's structural equation models in terms of uniform modeling
- Identifies limitations with non-atomic competing events where actions interleave across events

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A minimal cause can be defined as the shortest action sequence achieving a goal, such that removing it prevents the goal from being achieved by any shorter sequence.
- **Mechanism:** Given a Basic Action Theory (BAT) Σ and goal φ, sequence z is a minimal cause if: (1) Σ |= ¬φ initially, (2) Σ |= [z]φ after executing z, and (3) no shorter sequence satisfies (1)-(2). Minimality can be measured by length (Definition 3) or fluent-affected set size (Definition 4).
- **Core assumption:** The domain is faithfully modeled as a BAT with complete successor state axioms; all relevant effects are captured by the theory.
- **Evidence anchors:** [abstract] "define a minimal cause as the shortest action sequence that achieves a goal, where counterfactual analysis requires that removing this sequence prevents the goal from being achieved by any shorter sequence"; [section 3, Definition 2] Formal definition requiring Σ |= ¬φ, Σ |= [z]φ, and minimality; [corpus] Weak direct support; neighbor papers focus on HP-style structural models rather than action-theoretic minimal cause.
- **Break condition:** If the BAT is incomplete or the goal involves disjunctive competing events with interleaving actions, minimality may identify counterintuitive causes (see Example 9).

### Mechanism 2
- **Claim:** In action narratives (known histories), achievement cause generalizes via counterfactual removal of prefix subsequences, filtering inexecutable actions.
- **Mechanism:** For causal setting C = ⟨Σ, z, φ⟩, achievement cause is the minimal prefix z' ⊆ z such that: (1) φ holds for all z'' where z' ⊆ z'' ⊆ z, and (2) after filtering inexecutable actions from z\z', the goal does NOT hold. The Filter(·) function recursively removes actions whose preconditions fail.
- **Core assumption:** Action preconditions are explicitly axiomatized in Σap; the Filter function correctly identifies executable subsequences.
- **Evidence anchors:** [abstract] "counterfactual analysis requires that removing this sequence prevents the goal from being achieved by any shorter sequence"; [section 3, Definition 6] Formal achievement cause definition with Filter function; [corpus] No direct corpus support for this specific action-narrative filtering mechanism.
- **Break condition:** Fails for non-atomic competing events where actions interleave across events (Section 5 limitation discussion).

### Mechanism 3
- **Claim:** Regression converts future-state queries into present-state formulas, enabling efficient projection without simulation.
- **Mechanism:** R[Σ, z, φ] recursively replaces fluents in [z]φ with right-hand sides of successor state axioms, instantiated by ground actions in z. The result is a static formula about initial conditions that is logically equivalent to the original query.
- **Core assumption:** Successor state axioms completely specify fluent dynamics; the domain has a finite initial KB.
- **Evidence anchors:** [section 2, "Projection by Regression"] Explicit description of regression mechanism; [section 2, Example 1] Shows regression of [drop(C)]Broken(C) → Fragile(C) ∨ Broken(C); [corpus] Regression is standard in situation calculus literature; not discussed in neighbor papers.
- **Break condition:** Regression complexity grows with action sequence length and fluent nesting depth; may be intractable for very long narratives.

## Foundational Learning

- **Concept: Basic Action Theory (BAT)**
  - **Why needed here:** BATs (Σ = Σ0 ∪ Σap ∪ Σpost) provide the uniform standard modeling framework that replaces ad hoc causal modeling.
  - **Quick check question:** Can you write a successor state axiom for a fluent that becomes true after action A and remains true unless action B occurs?

- **Concept: Situation Calculus / Modal Logic ES**
  - **Why needed here:** The paper uses logic ES, a modal variant avoiding explicit situation terms; understanding [a]φ ("φ holds after a") and □φ ("φ holds after any sequence") is essential.
  - **Quick check question:** What is the difference between [pickup(C)]Holding(C) and □Holding(C)?

- **Concept: Counterfactual Analysis ("But-For" Causality)**
  - **Why needed here:** The core definition hinges on "had the cause not occurred, the effect would not hold"—a Humean counterfactual test.
  - **Quick check question:** In "Forest Fire" with match and lightning both true, why does the HP account identify the conjunction as cause rather than either alone?

## Architecture Onboarding

- **Component map:**
  BAT Σ ─┬─ Σ0 (initial KB)
          ├─ Σap (precondition axioms)
          └─ Σpost (successor state axioms)
                │
                ▼
          Regression Engine ──► Weakest Precondition R[z, φ]
                │
                ▼
          Minimality Checker ──► Length/Fluent-based comparison
                │
                ▼
          Filter Function ──► Remove inexecutable actions post-counterfactual
                │
                ▼
          Achievement Cause Identifier

- **Critical path:**
  1. Define BAT (fluents, actions, preconditions, effects)
  2. Specify goal φ and narrative z
  3. Verify Σ |= exec(z) ∧ [z]φ
  4. For each prefix z' ⊆ z (shortest first):
     - Compute Filter(z \ z')
     - Check if Σ |= [Filter(z \ z')]¬φ
     - If true, z' is achievement cause

- **Design tradeoffs:**
  - **Uniform modeling vs. flexibility:** BAT enforces standard structure (simpler) but cannot capture non-atomic interleaved competing events (less flexible than HP structural models).
  - **Length vs. fluent minimality:** Length is simpler but may miss causal relevance; fluent-based captures effect scope but risks including irrelevant actions.
  - **Prefix-only subsequences:** Restricts to temporally ordered causes; cannot identify non-consecutive action causes.

- **Failure signatures:**
  - **Disjunctive goals with competing events:** Cause may include "redundant" actions (Example 9: pickup(D) included even though pickup(C)·drop(C) suffices for Broken(C) ∨ Broken(D))
  - **Preemption scenarios:** All competing events identified as joint cause, losing temporal ordering (Example 6 discussion)
  - **Unexecutable subsequences:** Filter function returns empty sequence, trivially satisfying counterfactual condition

- **First 3 experiments:**
  1. Implement BAT for blocks world (Example 1); verify regression produces correct weakest preconditions for [pickup(C)][drop(C)]Broken(C)
  2. Test achievement cause on narrative z = pickup(C)·drop(C)·pickup(D) with goal Broken(C); confirm cause is pickup(C)·drop(C) (Example 5)
  3. Stress-test with disjunctive goal Holding(C) ∨ Holding(D) and narrative pickup(C)·pickup(D); observe that both actions are identified as joint cause (Example 6), then compare to HP-style structural model encoding

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the proposed counterfactual achievement cause definition be extended to an epistemic setting where agents reason about knowledge of causes and causes of knowledge?
- **Basis in paper:** [explicit] The authors state: "In terms of future work, it is interesting to see how our result can be extended to an epistemic setting, just like [24]."
- **Why unresolved:** The current framework operates in a purely objective action theory setting without modal epistemic operators; extending it requires integrating knowledge modalities while preserving counterfactual analysis.
- **What evidence would resolve it:** A formal definition of epistemic achievement cause that handles nested knowledge-about-cause and cause-of-knowledge scenarios, with proofs of desirable properties.

### Open Question 2
- **Question:** How can the counterfactual achievement cause be adapted for practical robot programming in GOLOG to enable causal reasoning during plan execution?
- **Basis in paper:** [explicit] The conclusion states: "it is promising to investigate how our method can be adapted for robot programming in GOLOG and other applications that are being built on action languages and require actual causation."
- **Why unresolved:** The framework is currently theoretical; adapting it for GOLOG requires addressing computational tractability, incremental causality checking, and integration with existing planning primitives.
- **What evidence would resolve it:** A working GOLOG implementation demonstrating causal attribution during execution, with performance benchmarks on standard planning domains.

### Open Question 3
- **Question:** Can the framework be enhanced to correctly identify causes in disjunctive goals where competing non-atomic events have interleaving, non-consecutive actions?
- **Basis in paper:** [explicit] The authors explicitly note: "the proposed definition of minimal counterfactual achievement causes suffers in handling competing events that are non-atomic where actions of different events might be non-consecutive and interleave."
- **Why unresolved:** The current minimal prefix definition fails when competing multi-action sequences interleave; determining which subsequence constitutes the "true" cause requires more sophisticated temporal analysis.
- **What evidence would resolve it:** An extended definition that handles interleaved competing events correctly, validated on counterexamples like the one in Example 9 where the current approach produces counterintuitive results.

### Open Question 4
- **Question:** What are the precise criteria for modeling a causal setting such that the identified cause is robust to modeling choices?
- **Basis in paper:** [explicit] Section 5 states: "It is open what are the criteria in modeling a causal setting."
- **Why unresolved:** Both the HP approach and the proposed framework exhibit sensitivity to modeling decisions; without principled criteria, different modelers may identify different causes for identical scenarios.
- **What evidence would resolve it:** Formal criteria that guarantee causal identification is invariant under "equivalent" model reformulations, with proofs of invariance properties.

## Limitations
- **Disjunctive goals with competing events:** The framework may identify joint causes including all competing events rather than the first sufficient one, leading to over-inclusive causal attribution
- **Non-atomic competing events:** The approach fails when actions from different competing events interleave non-consecutively, as the Filter function may yield empty sequences
- **Modeling sensitivity:** Both this approach and Halpern and Pearl's structural models exhibit sensitivity to modeling choices, with no established criteria for robust causal modeling

## Confidence
- **High confidence:** The core mechanism of identifying minimal action sequences via counterfactual analysis
- **Medium confidence:** The achievement cause definition for action narratives with the Filter function
- **Low confidence:** The comparison to Halpern and Pearl's structural equation model approach and handling of non-atomic competing events

## Next Checks
1. Implement a comprehensive test suite with BATs covering various scenarios: simple linear sequences, disjunctive goals with competing events, and non-atomic interleaved actions. Verify that the minimal cause identification matches expectations.
2. Develop a benchmark comparison between the proposed framework and Halpern and Pearl's structural equation model approach on the same set of causal scenarios, particularly those involving non-atomic competing events.
3. Investigate and implement extensions to handle non-atomic competing events, such as temporal ordering constraints or modified Filter function logic to better capture causal precedence in interleaved action scenarios.