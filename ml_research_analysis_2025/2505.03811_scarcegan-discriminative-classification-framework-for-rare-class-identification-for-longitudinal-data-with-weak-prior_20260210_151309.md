---
ver: rpa2
title: 'ScarceGAN: Discriminative Classification Framework for Rare Class Identification
  for Longitudinal Data with Weak Prior'
arxiv_id: '2505.03811'
source_url: https://arxiv.org/abs/2505.03811
tags:
- class
- samples
- data
- scarcegan
- positive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ScarceGAN, a semi-supervised GAN framework
  designed to identify extremely rare positive samples from multi-dimensional longitudinal
  telemetry data with weak label priors. The method addresses challenges including
  severe class imbalance, multi-class negative samples with overlapping distributions,
  and noisy/insufficient labels.
---

# ScarceGAN: Discriminative Classification Framework for Rare Class Identification for Longitudinal Data with Weak Prior

## Quick Facts
- **arXiv ID:** 2505.03811
- **Source URL:** https://arxiv.org/abs/2505.03811
- **Reference count:** 40
- **Primary result:** Achieves >85% recall on scarce positive class with ~60% improvement over vanilla semi-supervised GAN

## Executive Summary
ScarceGAN addresses the challenge of identifying extremely rare positive samples (0.05-0.1% prevalence) from multi-dimensional longitudinal telemetry data with weak and noisy label priors. The framework introduces a novel semi-supervised GAN architecture that combines complementary learning with a specially designed "bad" generator and a "leeway" class to handle label uncertainty. Evaluated on skill gaming data and KDDCUP99 intrusion dataset, ScarceGAN significantly outperforms state-of-the-art models by achieving high recall on the rare positive class while maintaining low false positive rates.

## Method Summary
ScarceGAN is a semi-supervised GAN framework that reformulates the discriminator's cost functions for both supervised and unsupervised paths. It introduces a "leeway" class to handle noisy labels, uses complementary learning with a generator designed to produce samples in low-density regions, and incorporates longitudinal feature synthesis through time series modeling (Prophet). The method decomposes the negative class into multiple sub-classes to improve visibility of the rare positive class and employs a dual-path discriminator with supervised classification and unsupervised real/fake discrimination.

## Key Results
- Achieves over 85% recall on the scarce positive class with minimal false positives
- Demonstrates ~60% improvement over vanilla semi-supervised GAN
- Outperforms state-of-the-art models on KDDCUP99 intrusion dataset
- Successfully handles severe class imbalance (0.05-0.1% positive class prevalence)

## Why This Works (Mechanism)

### Mechanism 1: Label-Noise Accommodation via "Leeway" Class
Introducing a "leeway" or "Unknown" class allows the discriminator to handle weak and noisy negative labels without misclassifying them as positive, thereby improving precision. The discriminator is trained with 5 output classes (3 known negatives, 1 positive, 1 unknown). If the model cannot confidently assign a negative sample to one of the known negative sub-classes, it assigns it to class U rather than forcing an incorrect classification or flipping to positive.

### Mechanism 2: Complementary Learning via "Bad" Generator
A generator designed to produce samples in low-density regions (a "bad" generator) improves the discriminator's decision boundaries for the scarce positive class better than a generator that mimics the real data distribution. Unlike a standard GAN generator that minimizes the difference between generated and real data distributions, this generator maximizes the entropy of generated features and minimizes the discriminator's confidence in high-density areas.

### Mechanism 3: Negative Class Decomposition (Divided Focus)
Breaking the monolithic "Negative" class into multiple sub-classes (Dormant, Normal, Heavy) reduces the effective class imbalance and improves the visibility of the positive class. By converting a binary problem into a multi-class problem, the relative probability of the positive class appearing in a batch increases, forcing the discriminator to learn distinct decision boundaries between negative sub-types.

## Foundational Learning

### Concept: Semi-Supervised GANs (SSGAN)
- **Why needed here:** ScarceGAN is a modification of the SSGAN architecture. You must understand how the discriminator shares weights between the "Real/Fake" unsupervised path and the "Classify" supervised path to grasp the loss function modifications.
- **Quick check question:** Can you explain why the unsupervised path in a standard SSGAN uses a sigmoid activation while the supervised path uses a softmax?

### Concept: Positive-Unlabeled (PU) Learning
- **Why needed here:** The paper frames the problem as a variant of PU learning. Understanding the bias in "Reliable Negatives" selection helps explain why the authors chose a generative-discriminative approach over standard two-step PU heuristics.
- **Quick check question:** Why does treating all unlabeled data as negative samples create a systematic estimation bias in standard PU learning?

### Concept: Time Series Feature Extraction (Prophet)
- **Why needed here:** The paper relies on "Third Order Statistics" (hyper-parameters from a forecasting model) rather than raw data. Understanding how time series trends are converted into static features is critical for the data pipeline.
- **Quick check question:** What is the difference between a "longitudinal aggregate" (e.g., mean) and a "third order statistic" (e.g., seasonality harmonics)?

## Architecture Onboarding

### Component map:
Inputs: Longitudinal telemetry (Time, Money, Desperation metrics) + Weak Labels (D, N, H, R)
Feature Engine: Prophet time-series model → extracts 10 hyper-parameters (trend, seasonality, etc.)
Discriminator: Shared base network (Fully Connected + Leaky ReLU). Splits into:
- Supervised Head: Softmax (5 classes: D, N, H, R, U)
- Unsupervised Head: Softmax (3 classes: Known, Unknown, Fake)
Generator: Fully Connected + Batch Norm. Objective: Maximize entropy (pull-away term) + Feature matching

### Critical path:
1. Data Prep: Convert raw logs to Prophet features (requires fitting time series per user)
2. Batching: Sample equal numbers from the 4 known classes (D, N, H, R) for the supervised path to manage imbalance
3. Training Loop:
   - Update Discriminator (Supervised Loss with Leeway α)
   - Update Discriminator (Unsupervised Loss with Leeway α)
   - Update Generator (Complementary objectives)

### Design tradeoffs:
- Recall vs. Verbosity: The architecture is tuned for high recall (>85%) on the positive class, accepting higher "verbosity" (false positives) in the unknown space compared to precision-focused models
- Complexity vs. Interpretability: Using "Leeway" class U handles noise but creates an "explainability" gap—you cannot easily explain why a user is in U vs N other than "ambiguity"

### Failure signatures:
- Leeway Collapse: If the "Unknown" class attracts >50% of the data, the α parameter is likely too low or the negative sub-classes are too overlapping
- Generator Collapse: If the generator loss drops to zero too fast, it may have stopped producing complementary samples, causing discriminator accuracy to plateau
- Prophet Errors: If input features have high variance, check the time-series fitting step; poor forecasting features will result in the discriminator seeing noise

### First 3 experiments:
1. Baseline Feature Check: Train the model using only simple aggregates (mean/max) vs. Prophet features to verify the value add of the complex feature engineering
2. Alpha Sweep: Run a grid search on α (e.g., 0.5 to 0.9) specifically measuring the trade-off between "Positive Recall" and "Unknown Class Volume"
3. Negative Ablation: Train a binary classifier (Positive vs. Negative only) using the same architecture to quantify the gain from the "Divided Focus" (multi-class negative) mechanism

## Open Questions the Paper Calls Out

### Open Question 1
How does the efficacy of the "Leeway" class (class U) vary with the specific ratio of noisy labels to unlabelled data? The paper notes in Section 5.4.1 that on the KDDCUP99 dataset, the leeway class "did not accumulate any samples" because the prior was strong, suggesting the mechanism is sensitive to label density.

### Open Question 2
Is there an optimal number of negative subclasses to maximize the "visibility" of the rare positive class? While the paper validates that 3 classes work better than binary classification, it does not investigate if further granularity improves the gradient flow or if a heuristic exists for determining the optimal number of negative clusters.

### Open Question 3
Does the reliance on "Third Order Statistics" (Prophet hyper-parameters) for feature synthesis fail on non-seasonal or chaotic longitudinal data? The paper relies on Prophet for feature synthesis which assumes underlying trends and seasonality, but rejects LSTM/shapelet approaches without deep discussion on data lacking these specific temporal properties.

## Limitations
- The "leeway" class mechanism may have limited generalizability to datasets where negative samples are not naturally decomposable into distinct sub-classes
- Reliance on Prophet for feature extraction introduces an additional modeling assumption that could fail if the time series do not exhibit clear trend/seasonality patterns
- Performance metrics are primarily reported on two datasets (skill gaming data and KDDCUP99), which may not represent all rare-class identification scenarios

## Confidence

### Confidence Labels for Major Claim Clusters
- **Mechanism 1 (Leeway Class):** Medium - The theoretical justification is clear, but the specific hyperparameter tuning (α) is not fully validated across different noise levels
- **Mechanism 2 (Complementary Generator):** Medium - Ablation study shows 10% performance drop, but the mechanism's effectiveness depends heavily on the specific negative class decomposition
- **Mechanism 3 (Negative Decomposition):** Medium - The multi-class approach is validated, but the assumption that negatives naturally form distinct clusters is not universally applicable

## Next Checks

1. **Alpha Parameter Sensitivity:** Systematically vary α from 0.3 to 0.9 and measure the trade-off between positive recall and unknown class volume to identify optimal settings for different noise levels
2. **Negative Class Robustness:** Test the model on datasets where negative samples are randomly assigned to sub-classes rather than naturally clustered to assess the importance of meaningful decomposition
3. **Feature Engineering Comparison:** Compare Prophet-derived features against simpler statistical aggregates (mean, variance, max) on multiple datasets to quantify the value added by complex time series modeling