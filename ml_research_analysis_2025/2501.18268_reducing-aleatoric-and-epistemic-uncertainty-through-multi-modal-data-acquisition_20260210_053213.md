---
ver: rpa2
title: Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition
arxiv_id: '2501.18268'
source_url: https://arxiv.org/abs/2501.18268
tags:
- training
- uncertainty
- size
- learning
- predictions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ALMA (Active Learning with Multi-modal data
  Acquisition), a framework for improving prediction reliability by disentangling
  epistemic and aleatoric uncertainty in multi-modal settings. The key idea is that
  epistemic uncertainty decreases with more training data, while aleatoric uncertainty
  decreases as more modalities are added.
---

# Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition

## Quick Facts
- arXiv ID: 2501.18268
- Source URL: https://arxiv.org/abs/2501.18268
- Reference count: 40
- Primary result: ALMA framework achieves higher accuracy on reliable prediction subsets (e.g., 97.8% vs 84.5% on BIOSCAN-5M) by actively acquiring data or modalities based on uncertainty type

## Executive Summary
This paper introduces ALMA (Active Learning with Multi-modal data Acquisition), a framework that improves prediction reliability by disentangling epistemic and aleatoric uncertainty in multi-modal settings. The key insight is that epistemic uncertainty decreases with more training data while aleatoric uncertainty decreases as more modalities are added. ALMA uses conformal prediction to assess reliability and actively acquires either more labeled data or additional modalities depending on which uncertainty dominates. Experiments across three datasets show that ALMA produces reliable predictions with higher accuracy on these subsets compared to overall performance.

## Method Summary
ALMA is a multi-modal active learning framework that routes uncertainty reduction efforts based on whether epistemic or aleatoric uncertainty dominates. The method uses conformal prediction (specifically Adaptive Prediction Sets) to determine prediction reliability, then compares disentangled uncertainty metrics to decide between acquiring more labeled training data (if epistemic uncertainty dominates) or additional data modalities (if aleatoric uncertainty dominates). The framework works with multiple uncertainty quantification methods including Deep Ensembles, Bayesian neural networks, and Random Forests, and was tested on three datasets: Wine (fictitious modalities), BIOSCAN-5M (DNA, images, geography), and MIMIC-IV (medical records).

## Key Results
- On BIOSCAN-5M, reliable predictions achieved 97.8% accuracy versus 84.5% overall accuracy
- Deep Ensemble uncertainty quantification performed best among tested methods
- Reliable subset accuracy consistently exceeded overall accuracy across all three datasets
- Framework successfully navigated between data acquisition and modality acquisition based on uncertainty type

## Why This Works (Mechanism)

### Mechanism 1: Uncertainty-Type Specific Remediation
The framework disentangles uncertainty into Epistemic (model ignorance) and Aleatoric (inherent noise). If Epistemic uncertainty dominates, the system queries more labeled training data (Active Learning). If Aleatoric uncertainty dominates, the system queries a new data modality for the test instance (Active Feature Acquisition). This is grounded in the property that adding modalities can only shrink uncertainty by the conditional mutual information.

### Mechanism 2: Conformal Reliability Gating
Conformal Prediction acts as a statistically grounded gatekeeper to determine when a prediction is sufficiently reliable to stop acquisition. The algorithm uses prediction set size: if $|\Upsilon(x)| = 1$, the decision is deemed reliable with marginal coverage guarantees. If $> 1$, the acquisition loop is triggered. This requires the calibration dataset to remain exchangeable with test points.

### Mechanism 3: Comparative Acquisition Heuristic
The algorithm compares $EU_j(x)$ and $AU_j(x)$ values directly. If $EU \ge AU$, the system prioritizes reducing model variance (data acquisition). If $AU > EU$, it prioritizes reducing entropy (modality acquisition). This simple comparison effectively routes the acquisition strategy, though it assumes these different uncertainty metrics are commensurate.

## Foundational Learning

- **Concept: Uncertainty Decomposition (Entropy-based)**
  - **Why needed here:** You cannot route the acquisition logic without calculating EU and AU separately. You must understand that $EU = Total\ Entropy - Expected\ Data\ Entropy$.
  - **Quick check question:** If I have a Deep Ensemble, how do I derive Epistemic Uncertainty from the variance of predictions across members?

- **Concept: Conformal Prediction (APS Score)**
  - **Why needed here:** The paper uses Adaptive Prediction Sets (APS) to decide when to stop. You need to understand how nonconformity scores translate into prediction sets with coverage guarantees ($1-\alpha$).
  - **Quick check question:** Does a prediction set size of 1 imply high confidence or just that the calibrated threshold was exceeded by only one class?

- **Concept: Active Learning Cycles**
  - **Why needed here:** The framework modifies the training set $D_L$ at inference time. You need to grasp the cycle of: Query $\rightarrow$ Label $\rightarrow$ Retrain $\rightarrow$ Re-evaluate.
  - **Quick check question:** Why does the paper require "new relevant instances similar to x" to be available at inference time to reduce Epistemic Uncertainty?

## Architecture Onboarding

- **Component map:** Test instance $x$ (initially modality 1) -> UQ Engine (Deep Ensemble or Bayesian NN) -> Conformal Prediction module (APS score) -> Acquisition Policy (EU vs AU comparison) -> Oracles (label or modality acquisition)
- **Critical path:** The accuracy of the UQ Engine. If EU/AU values are miscalibrated (e.g., Centroid method), the Router makes incorrect decisions.
- **Design tradeoffs:**
  - Deep Ensemble vs. Bayesian NN: Ensembles performed best but are computationally expensive (training $M$ models)
  - Entropy vs. Variance Decomposition: The paper notes little difference, but Variance-based may be more intuitive for regression-like tasks
  - Fixed Calibration Set: Ensures exchangeability (CP validity) but might lower sensitivity to distribution shifts
- **Failure signatures:**
  - Stuck in AU Loop: System keeps requesting modalities but AU does not decrease (modalities are uninformative)
  - Stuck in EU Loop: System keeps requesting labels but accuracy stalls (base learner lacks capacity)
- **First 3 experiments:**
  1. Baseline UQ Check: Train Deep Ensemble on Wine dataset, calculate AU and EU for test points, verify EU decreases with larger training sets
  2. Gate Calibration: Implement APS Conformal Prediction on Wine, confirm $\alpha=0.1$ gives roughly 90% coverage before active loop
  3. Full Loop Simulation: Run Algorithm 1 on BIOSCAN-5M subset, log "cost" (labels + modalities) for first 100 instances, compare against baseline querying all modalities

## Open Questions the Paper Calls Out

- **Question:** How can aleatoric and epistemic uncertainty be explicitly disentangled within conformal prediction nonconformity scores?
  - **Basis in paper:** Page 3 states analyzing the influence of aleatoric and epistemic uncertainty in conformal prediction is an important open research question
  - **Why unresolved:** Current methods like APS adapt set sizes based on total uncertainty but don't distinguish between the two types
  - **What evidence would resolve it:** Novel nonconformity scores utilizing disentangled uncertainty metrics for instance-specific coverage guarantees

- **Question:** Can the ALMA framework be extended to support dynamic modality ordering where the acquisition sequence varies per test instance?
  - **Basis in paper:** Page 4 notes the setup assumes a "fixed order" of modalities, distinguishing it from works where "the order in which features are queried varies over test instances"
  - **Why unresolved:** The current algorithm processes modalities sequentially ($1$ to $\mu$), restricting flexibility
  - **What evidence would resolve it:** An extension selecting the optimal next modality dynamically based on expected uncertainty reduction

- **Question:** How should Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU) be compared or weighted when their scales or costs are not commensurate?
  - **Basis in paper:** Page 5 mentions the algorithm assumes EU and AU are "commensurate and of equal importance," acknowledging this is a "reasonable default assumption"
  - **Why unresolved:** Direct comparison may not reflect real-world trade-offs when acquiring modalities is more expensive than labeling data
  - **What evidence would resolve it:** A theoretical framework or empirical study validating cost-sensitive thresholds or utility functions

## Limitations
- The framework assumes EU and AU values are directly comparable despite representing different uncertainty types, with no explicit normalization mechanism
- The paper doesn't specify how to select which instance to query from the unlabeled pool (Algorithm 1, Line 6)
- The conformal prediction reliability depends on calibration and test sets remaining exchangeable, which may break down as training data evolves

## Confidence
- **High Confidence:** The core mechanism of uncertainty-type specific remediation (Mechanism 1) is well-supported by theoretical proof and experimental validation
- **Medium Confidence:** The comparative acquisition heuristic (Mechanism 3) works in practice but relies on an implicit commensurability assumption
- **Low Confidence:** The conformal reliability gating (Mechanism 2) depends on exchangeability assumptions that may fail in dynamic active learning scenarios

## Next Checks
1. Systematically compare EU/AU values across different UQ methods (Deep Ensemble vs. Bayesian NN) on the same dataset to verify whether direct comparison is valid
2. Define and test multiple query strategies (e.g., uncertainty sampling, diversity-based) to determine their impact on ALMA's performance and convergence
3. Monitor calibration set coverage guarantees over multiple active learning iterations to quantify exchangeability breakdown and its effect on prediction reliability