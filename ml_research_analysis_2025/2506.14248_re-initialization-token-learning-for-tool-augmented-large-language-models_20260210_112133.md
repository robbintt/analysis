---
ver: rpa2
title: Re-Initialization Token Learning for Tool-Augmented Large Language Models
arxiv_id: '2506.14248'
source_url: https://arxiv.org/abs/2506.14248
tags:
- tool
- token
- language
- tools
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of integrating external tools
  into large language models (LLMs) by proposing a novel token learning approach called
  TokenLearning. The method constructs prior token embeddings from tool names or descriptions,
  which are used to initialize and regularize learnable tool token embeddings, ensuring
  better alignment with the word embedding space.
---

# Re-Initialization Token Learning for Tool-Augmented Large Language Models

## Quick Facts
- **arXiv ID:** 2506.14248
- **Source URL:** https://arxiv.org/abs/2506.14248
- **Reference count:** 40
- **Primary result:** Proposes TokenLearning, which initializes tool embeddings from tool name/description tokens and regularizes them with L2 loss, improving tool selection accuracy by ~3% on GSM8K-XL and consistently across KAMEL, FuncQA, and VirtualHome tasks.

## Executive Summary
This paper addresses the challenge of integrating external tools into large language models (LLMs) by proposing a novel token learning approach called TokenLearning. The method constructs prior token embeddings from tool names or descriptions, which are used to initialize and regularize learnable tool token embeddings, ensuring better alignment with the word embedding space. Experimental results on GSM8K-XL, FuncQA, KAMEL, and VirtualHome datasets show that TokenLearning significantly improves tool selection accuracy compared to recent baselines like CoT, REACT, ICL, and ToolkenGPT, with improvements of approximately 3% on GSM8K-XL and consistent gains across tasks involving numerical reasoning, knowledge-based question answering, and embodied plan generation.

## Method Summary
TokenLearning constructs prior token embeddings for each tool based on the tool's name or description tokens, which are used to initialize and regularize the learnable tool token embeddings. The method extracts word tokens from tool names/descriptions, applies pooling (average or max) to construct a single prior vector per tool, then uses this as initialization for the learnable tool token matrix Wτ. During training, L2 regularization constrains the learned embeddings to remain near their semantic priors while allowing task-specific adaptation. The tool tokens are represented in an extended vocabulary alongside word tokens, enabling unified next-token prediction for both text and tool calls. This approach ensures the learned tool embeddings are well-aligned with the pre-trained word embedding space while maintaining flexibility for task-specific optimization.

## Key Results
- TokenLearning achieves ~3% improvement in tool selection accuracy on GSM8K-XL compared to ToolkenGPT baseline
- Consistent performance gains across all evaluated datasets: KAMEL (234 relations), FuncQA (multi-hop arithmetic), and VirtualHome (embodied planning)
- Average pooling outperforms max pooling for prior embedding construction, especially with larger tool sets
- Optimal regularization strength (λ) is task-dependent, ranging from 1e-3 to 1e-2 across different datasets

## Why This Works (Mechanism)

### Mechanism 1: Prior Embedding Construction from Tool Semantics
Tool token embeddings initialized from semantically related word tokens improve alignment with the pre-trained embedding space. The method extracts word tokens comprising each tool's name or description from the LLM vocabulary, applies pooling (average or max) across their embeddings to construct a single prior vector per tool, then uses this as initialization for the learnable tool token matrix Wτ. This works because tool names (e.g., "add", "multiply") share semantic structure with their functional behavior, and the pre-trained embedding space encodes this relationship. The break condition occurs with tools having arbitrary or non-semantic names (e.g., "API_2847") where name tokens provide no functional signal.

### Mechanism 2: L2 Regularization Anchoring Learned Embeddings to Priors
Regularization constrains tool tokens to remain near their semantic priors during training, improving generalization and reducing overfitting. The method adds λ||Wτ − W0τ||²₂ to the next-token prediction loss, penalizing divergence from prior embeddings while allowing task-specific adaptation. This works because the prior embedding encodes useful structural knowledge that should not be entirely overwritten by limited training data. The break condition occurs when λ is too large (λ → 1.0), causing underfitting that prevents adaptation, or too small (λ → 0), causing overfitting to training data.

### Mechanism 3: Dual-Mode Token Prediction via Vocabulary Extension
Representing tools as discrete tokens in an extended vocabulary enables unified next-token prediction for both text and tool calls. The method concatenates tool token matrix Wτ to word embedding matrix Wv, forming [Wv; Wτ], and during inference, if predicted token ∈ T (tool set), switches to tool mode, generates arguments, executes tool, and re-injects output. This works because tool invocation decisions can be made via the same softmax distribution used for word generation. The break condition occurs when contextual signals are insufficient for disambiguating among many tools (e.g., 234 relations in KAMEL), causing accuracy to drop as tool count increases.

## Foundational Learning

- **Concept: Word Embedding Space**
  - **Why needed here:** TokenLearning's core thesis is that tool tokens must occupy geometrically coherent positions within the pre-trained embedding manifold.
  - **Quick check question:** Can you explain why adding random vectors to an embedding matrix would disrupt nearest-neighbor relationships in the embedding space?

- **Concept: Regularization (L2/Weight Decay)**
  - **Why needed here:** The λ term controls the bias-variance tradeoff; without this, tool tokens could drift into unpopulated regions of the space.
  - **Quick check question:** What happens to model capacity if you increase λ from 1e-4 to 1.0?

- **Concept: Next-Token Prediction Loss (Cross-Entropy)**
  - **Why needed here:** The base training objective; tool tokens are optimized via the same cross-entropy loss as word tokens, with [N/A] masking for non-predicted positions.
  - **Quick check question:** Why must [N/A] tokens be excluded from loss calculation (Eq. 3.1.3)?

## Architecture Onboarding

- **Component map:** Tool name → tokenizer → embedding lookup → pooling → W0τ → initialize Wτ → train with regularized loss → inference with mode switching
- **Critical path:** Tool name → tokenizer → embedding lookup → pooling → W0τ → initialize Wτ → train with regularized loss → inference with mode switching
- **Design tradeoffs:** Average pooling more stable across tool counts; max pooling can amplify noise for semantically sparse tool names. λ selection is task-dependent; start with 1e-3 for reasoning tasks, 1e-2 for planning tasks, tune on validation set. Works with ~5K examples; performance degrades with fewer samples or more tools.
- **Failure signatures:** Tool accuracy plateaus despite training → λ may be too restrictive; reduce by 10×. Random tool selection → check initialization; verify prior embeddings are computed from correct tokens. Performance drops as tool count increases → inherent limitation of token-based selection; consider retrieval-augmented approaches.
- **First 3 experiments:**
  1. Reproduce GSM8K-XL baseline: Train ToolkenGPT from scratch (random init) vs. TokenLearning (prior init); expect ~3% gap per Table 1.
  2. Ablate pooling method: Compare average vs. max pooling on KAMEL with 100+ tools; expect average pooling to maintain accuracy better.
  3. Sweep λ: Train with λ ∈ {1e-6, 1e-4, 1e-3, 1e-2} on VirtualHome; plot accuracy vs. λ to identify task-specific optimum (Table 6 suggests λ=1e-2 for LLaMA2-13B).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can prompt-based reasoning frameworks (like ReAct) be effectively hybridized with embedding-based tool learning to improve performance on complex multi-hop reasoning tasks?
- **Basis in paper:** The authors observe in Section 4.3.1 that ReAct outperforms their method on FuncQA multi-hop questions, noting "the complementary advantages of prompt-based versus learned tool invocation mechanisms" but do not attempt to combine them.
- **Why unresolved:** The paper evaluates the methods as distinct baselines and does not investigate whether the robust multi-hop reasoning of ReAct can mitigate the limitations of TokenLearning in complex scenarios.
- **What evidence would resolve it:** An experimental setup where ReAct-style reasoning traces trigger TokenLearning tool tokens, evaluated on multi-hop datasets like FuncQA.

### Open Question 2
- **Question:** How can the regularization strength (λ) be dynamically optimized or automatically determined to prevent the dataset-specific performance degradation observed in the ablation studies?
- **Basis in paper:** Section 4.4.3 and Table 6 show that the optimal λ varies significantly across datasets (e.g., 1e-3 for GSM8K-XL vs. 0.8 for VirtualHome), and the authors state that suboptimal selection "adversely impacts accuracy."
- **Why unresolved:** The paper treats λ as a static hyperparameter determined by empirical search, identifying the sensitivity as a constraint but offering no mechanism to adapt it automatically.
- **What evidence would resolve it:** A proposed adaptive regularization technique or a heuristic for setting λ that maintains consistent performance across the evaluated tasks without manual tuning.

### Open Question 3
- **Question:** Can the initialization strategy be modified to maintain high performance when tool names are semantically obfuscated or non-descriptive?
- **Basis in paper:** The method relies on constructing prior embeddings from tool names (Section 3.2). The ablation study (Table 4) shows a performance drop when using "Irrelevant vocabulary" for initialization compared to "Tools' name," implying a reliance on semantic alignment.
- **Why unresolved:** While the method improves upon baselines even when tool tokens are semantically weak (e.g., in KAMEL), the initialization disadvantage for non-semantic names remains a weakness relative to descriptive names.
- **What evidence would resolve it:** A variant of the initialization method that utilizes tool descriptions or usage examples to generate prior embeddings for tools with arbitrary, non-semantic identifiers.

## Limitations
- Performance degrades with increasing tool counts, showing inherent limitations of token-based selection mechanisms for large tool sets
- Core assumption that tool names semantically encode functional behavior may not hold for arbitrary tool identifiers or specialized domains
- Experimental validation focuses on specific tool-augmented LLMs without exploring transfer to other model architectures or training paradigms

## Confidence

- **High confidence:** The mechanism of prior embedding construction through pooling of tool-name tokens and L2 regularization for maintaining semantic alignment is clearly specified and theoretically sound.
- **Medium confidence:** Empirical improvements (3% on GSM8K-XL, consistent gains across tasks) are reported but lack statistical significance testing and ablation studies for all hyperparameters.
- **Low confidence:** The scalability claim for handling 234 relations in KAMEL is questionable given the performance drop with increasing tool counts and the absence of comparative analysis against alternative selection mechanisms.

## Next Checks

1. **Reproduce GSM8K-XL baseline with statistical validation:** Train both ToolkenGPT (random initialization) and TokenLearning (prior initialization) across 5 independent runs, report mean accuracy with 95% confidence intervals, and perform paired t-tests to establish statistical significance of the ~3% improvement claim.

2. **Test semantic assumption failure modes:** Construct synthetic tools with non-descriptive names (e.g., "tool_1", "func_42") and measure whether TokenLearning still provides benefits compared to random initialization. Compare against a retrieval-augmented baseline that matches tools based on context similarity rather than name semantics.

3. **Sweep regularization hyperparameter across all tasks:** Systematically vary λ ∈ {1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1} on each dataset, plot accuracy vs. λ curves, and verify whether the reported task-specific optimal values (Table 6) are reproducible and consistent across multiple random seeds.