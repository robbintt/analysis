---
ver: rpa2
title: Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF
  and BERT Embeddings for Low-Resource Language Processing
arxiv_id: '2501.05260'
source_url: https://arxiv.org/abs/2501.05260
tags:
- bert
- detection
- plagiarism
- marathi
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a weighted ensemble system that combines TF-IDF
  and BERT embeddings to improve plagiarism detection in Marathi, a low-resource language.
  The system uses both statistical and semantic features by training individual classifiers
  on TF-IDF vectors and BERT sentence embeddings, then combining their outputs via
  weighted voting.
---

# Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing

## Quick Facts
- arXiv ID: 2501.05260
- Source URL: https://arxiv.org/abs/2501.05260
- Reference count: 16
- Accuracy achieved: 82.04% on Marathi plagiarism detection task

## Executive Summary
This paper addresses the challenge of plagiarism detection in Marathi, a low-resource language, by proposing a weighted ensemble system that combines TF-IDF and BERT embeddings. The system leverages both statistical and semantic features to improve detection accuracy. By training individual classifiers on TF-IDF vectors and BERT sentence embeddings, then combining their outputs via weighted voting, the approach achieves 82.04% accuracy, outperforming individual models. This method is particularly promising for low-resource languages where fine-tuned language models alone may be insufficient.

## Method Summary
The proposed system translates the MIT Plagiarism Detection Dataset from English to Marathi using the `aryaumesh/english-to-marathi` mBART model. It preprocesses text by removing punctuation and stop words, then extracts MahaSBERT-STS embeddings (768-dim) and TF-IDF vectors (400-dim). Element-wise subtraction creates relationship vectors between text pairs. Separate classifiers (Logistic Regression, LightGBM, XGBoost, SVC) are trained on each representation type. The ensemble combines predictions using weights WBERT=0.6 and WTF-IDF=0.4, with probability outputs averaged to produce final predictions.

## Key Results
- Weighted ensemble achieved 82.04% accuracy, outperforming TF-IDF-only (~58%) and BERT-only (~80%) models
- Optimal configuration used WBERT=0.6 and WTF-IDF=0.4 for ensemble voting
- System trained on 366,915 text pairs from MIT dataset translated to Marathi

## Why This Works (Mechanism)

### Mechanism 1: Complementary Feature Integration
Combining TF-IDF with BERT embeddings improves plagiarism detection accuracy by capturing both statistical patterns (word frequency, term importance) and semantic relationships. TF-IDF excels at surface-level matching while BERT captures meaning-preserving paraphrases. When BERT alone is insufficient due to limited pretraining corpora, TF-IDF provides compensating signal.

### Mechanism 2: Ensemble Weighted Voting
Individual classifiers trained on different feature representations are combined via weighted averaging. This leverages classifier-specific strengths - TF-IDF models showed high recall for true positive identification while BERT models demonstrated higher precision. The weighted approach reduces error by aggregating partially uncorrelated predictions.

### Mechanism 3: Element-wise Subtraction for Relationship Encoding
For each text pair, embeddings are subtracted element-wise to create difference vectors representing the "semantic gap" or "statistical gap" between texts. This direct pairwise representation enables classifiers to learn from similarity patterns rather than precomputed metrics.

## Foundational Learning

- **TF-IDF Vectorization**
  - Why needed: Provides statistical backbone for detecting verbatim or near-verbatim copying; computationally efficient
  - Quick check: Can you compute cosine similarity from TF-IDF vectors? What does a high TF-IDF score indicate?

- **BERT Sentence Embeddings**
  - Why needed: Captures context-sensitive meaning for detecting paraphrases where words differ but semantics are preserved
  - Quick check: How does BERT differ from Word2Vec in representing word meaning? Why might fine-tuning on STS data improve plagiarism detection?

- **Ensemble Weighted Voting**
  - Why needed: Combines predictions from multiple classifiers with different inductive biases to reduce error
  - Quick check: If BERT classifiers have higher precision but lower recall than TF-IDF classifiers, how might you adjust WBERT to optimize F1?

## Architecture Onboarding

- **Component map**: Translation -> Preprocessing -> Feature Extraction -> Element-wise Subtraction -> Classification -> Ensemble Fusion
- **Critical path**: Translation quality → Embedding quality → Subtraction vector quality → Classifier training → Weight tuning
- **Design tradeoffs**: Full 768-dim BERT vs. PCA-reduced (256, 512): Full dimensions performed best; TF-IDF dimension (256 vs. 400): 400 captured more term information; Ensemble weights: WBERT = 0.6 optimal
- **Failure signatures**: High recall, low precision on TF-IDF-only suggests catching too many false positives; Accuracy drops when WBERT > 0.6 indicates over-weighting semantic similarity
- **First 3 experiments**: 1) Baseline replication: Train individual classifiers separately to confirm accuracy gap; 2) Weight sweep: Vary WBERT from 0.0 to 1.0 to identify optimal weight; 3) Ablation on subtraction vs. concatenation: Compare element-wise subtraction with concatenation

## Open Questions the Paper Calls Out
1. How does the system perform on longer academic texts or creative works compared to short-text pairs?
2. Does integration of stylometric features significantly improve detection accuracy for creative writing or obfuscated plagiarism?
3. Can the optimal weight configuration (WBERT=0.6, WTF-IDF=0.4) be generalized to other low-resource languages?
4. How does reliance on machine-translated dataset affect model's ability to detect plagiarism in naturally occurring native Marathi text?

## Limitations
- Dataset primarily consists of short-text pairs; applicability to longer academic texts or creative works remains untested
- Current feature extraction limited to TF-IDF and BERT representations; stylometric analysis not explored
- Optimal weights were empirically tuned specifically for Marathi; generalization to other languages is assumed but untested
- Reliance on machine-translated dataset raises questions about performance on naturally occurring native Marathi text

## Confidence
- **High confidence**: Complementary nature of TF-IDF and BERT features well-supported by accuracy gains; weighted voting framework is standard and reproducible
- **Medium confidence**: Element-wise subtraction method plausible but lacks comparative evidence; translation pipeline is potential weak link; stemming rules unspecified
- **Low confidence**: Generalization to other low-resource languages is assumed but untested; no ablation on individual classifier contributions or weight stability across folds

## Next Checks
1. Translation quality audit: Run BERTScore between English source and Marathi translation for random sample to verify translation quality
2. Subtraction vs. concatenation ablation: Replace element-wise subtraction with concatenation for both BERT and TF-IDF vectors and compare classifier performance
3. Weight stability across folds: Perform 5-fold cross-validation, tuning WBERT and WTF-IDF separately on each fold to assess robustness and overfitting risk