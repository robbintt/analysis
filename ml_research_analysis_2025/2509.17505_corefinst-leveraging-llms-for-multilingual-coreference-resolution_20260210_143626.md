---
ver: rpa2
title: 'CorefInst: Leveraging LLMs for Multilingual Coreference Resolution'
arxiv_id: '2509.17505'
source_url: https://arxiv.org/abs/2509.17505
tags:
- mentions
- coreference
- llms
- mention
- zero
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CorefInst, the first instruction-tuned LLM
  approach for multilingual coreference resolution that handles both overt and zero
  mentions. The method leverages five instruction sets to fine-tune decoder-only LLMs
  (Llama 3.1, Gemma 2, Mistral 0.3) using a controlled inference strategy that sequentially
  resolves coreferential relations.
---

# CorefInst: Leveraging LLMs for Multilingual Coreference Resolution

## Quick Facts
- **arXiv ID**: 2509.17505
- **Source URL**: https://arxiv.org/abs/2509.17505
- **Reference count**: 17
- **Primary result**: CorefInst outperforms state-of-the-art CorPipe24 by 2 pp average across 15 languages, achieving 72.3% CoNLL score on predicted mentions.

## Executive Summary
This paper presents CorefInst, the first instruction-tuned LLM approach for multilingual coreference resolution that handles both overt and zero mentions. The method leverages five instruction sets to fine-tune decoder-only LLMs (Llama 3.1, Gemma 2, Mistral 0.3) using a controlled inference strategy that sequentially resolves coreferential relations. When fully trained on CorefUD v1.2, CorefInst outperforms the state-of-the-art CorPipe24 by 2 pp on average across 15 languages, with statistically significant improvements on Turkish, Ancient Greek, and Old Church Slavonic. The model also shows 8.4 pp improvement on zero mentions in pro-drop languages, demonstrating LLMs' effectiveness in resolving hidden semantic relations.

## Method Summary
CorefInst fine-tunes decoder-only LLMs (Llama 3.1 8B, Gemma 2, Mistral 0.3) using LoRA (rank 16) and 4-bit quantization on masked input tuples from CorefUD v1.2. The system converts CoNLL-U documents into overlapping frames with `<m>...</m>` and `</z>` tags marking mentions and zero mentions, respectively. A controlled inference loop sequentially predicts cluster numbers at `MASK` tokens, feeding predictions back into context before resolving the next mask. A post-processing algorithm merges local frame predictions into global document clusters using overlapping regions. The method uses Instruction #5, which includes semantic consistency keywords and negative constraints to prevent over-merging distinct entities.

## Key Results
- CorefInst achieves 72.3% CoNLL score on predicted mentions versus CorPipe24's 70.5%, outperforming by 2 pp average across 15 languages
- Statistically significant improvements on Turkish (+11.5 pp), Ancient Greek (+7.9 pp), and Old Church Slavonic (+6.7 pp)
- 8.4 pp improvement on zero mentions in pro-drop languages, demonstrating effectiveness with dropped pronouns
- Outperforms all three baseline models (CorPipe24, CorPipe25, UniCoref) across most languages when using the same mention detection

## Why This Works (Mechanism)

### Mechanism 1: Controlled Autoregressive Inference
Sequentially resolving coreference relations via constrained decoding stabilizes reasoning compared to unconstrained generation. The controlled inference loop invokes the model only at specific `MASK` tokens to predict cluster numbers, maintaining a causal chain of entity assignments through autoregressive feedback.

### Mechanism 2: Instruction-Driven Boundary Enforcement
Including negative constraints and semantic consistency keywords in instructions reduces over-merging. The "coherent" keyword alongside "coreferential" and explicit non-coreferent examples steers the decoder to distinguish semantic relatedness from identity.

### Mechanism 3: Frame-Based Global Clustering
Global document-level coherence is approximated by stitching together predictions from overlapping local frames. A post-processing algorithm merges clusters by mapping local cluster IDs to global IDs whenever mentions appear in overlapping regions between consecutive frames.

## Foundational Learning

- **Coreference Types (Overt vs. Zero)**: Standard CR handles explicit text; this paper targets zero mentions (dropped pronouns in pro-drop languages), requiring inference of hidden semantic agents.
  - *Quick check*: In "Went to the store," who is the agent? If predicting "I" or "He" based on context, it's resolving a zero mention.

- **Causal Masking in Decoder-Only LLMs**: The controlled inference method relies on the model only seeing tokens to the left. This explains why the method must predict IDs sequentially rather than in parallel.
  - *Quick check*: When predicting cluster ID for Mention B, can the model attend to text after Mention B? (No)

- **Fine-Tuning with LoRA**: The paper uses LoRA (rank 16) and 4-bit quantization. Understanding this is critical for reproducing results on consumer hardware.
  - *Quick check*: Does LoRA update full weights of the Llama 3.1 model? (No, it updates small adapter matrices)

## Architecture Onboarding

- **Component map**: CorefUD v1.2 (CoNLL-U format) -> Pre-processor (CoNLL-U -> Masked Frames) -> Core Model (Llama 3.1 8B fine-tuned with Instruction #5) -> Inference Engine (Controlled loop) -> Post-processor (Cluster Merger algorithm)

- **Critical path**: The Post-processing/Merging Logic. While the LLM generates local predictions, the system's success relies on the deterministic algorithm that stitches these local predictions into valid document-level clusters.

- **Design tradeoffs**: Modularity vs. End-to-End (relies on CorPipe24 for mention detection); Context vs. Fragmentation (fixed-length frames allow processing long documents but risk splitting entity clusters).

- **Failure signatures**: Singleton Clusters (high count with size=1 implies failed linking); Giant Clusters (one cluster with most entities implies over-merging); Broken Chains (entity has different IDs in consecutive frames implies missing bridge mentions).

- **First 3 experiments**: 
  1. Load CorefUD v1.2, select Hungarian document, run pre-processor to visualize `<m>` and `</z>` tags and verify `MASK` placement
  2. Run CorefInst on single short sentence (1 frame), manually verify output replaces `MASK` with digit without extra generation
  3. Compare Inst#5 vs. Inst#1 on English en_gum subset to quantify impact of "coherent" keyword and negative examples on over-merging

## Open Questions the Paper Calls Out

1. **End-to-End Extension**: Developing an effective, accurate, and efficient controlled inference mechanism for the mention detection stage.
2. **Fragmentation Prevention**: How to prevent entity cluster fragmentation when overlapping frames lack explicit coreferential mentions.
3. **Context Window Impact**: Performance gains from utilizing larger context windows or natively multilingual LLMs compared to English-centric models.

## Limitations

- **Mention Detection Bottleneck**: Performance is fundamentally constrained by CorPipe24's ability to identify both overt and zero mentions, as CorefInst explicitly uses it for mention detection.
- **Context Fragmentation Risk**: Frame-based approach with overlapping regions can incorrectly split entities mentioned only in non-overlapping segments between frames.
- **Instruction Set Sensitivity**: The selection of Inst#5 may represent a local optimum that doesn't generalize to all language families or discourse types.

## Confidence

- **High Confidence**: The 2 pp average improvement over CorPipe24 (72.3% vs 70.5% CoNLL score) is well-supported by experimental methodology; controlled inference strategy and LoRA fine-tuning are clearly described and reproducible.
- **Medium Confidence**: The claim of being the "first instruction-tuned LLM approach" is reasonable but difficult to verify definitively; performance differences on specific languages are well-documented but may be influenced by dataset characteristics.
- **Low Confidence**: Long-term stability and robustness of frame-based global clustering across diverse document types and genres remains uncertain; performance on very long documents with sparse entity mentions is untested.

## Next Checks

1. **Frame Overlap Sensitivity Analysis**: Systematically vary overlap region size (currently 1000 tokens) and measure impact on cluster fragmentation rates using synthetic test cases where entities are mentioned in non-overlapping regions.

2. **End-to-End Performance Evaluation**: Replace CorPipe24's mention detection with a simpler heuristic-based approach and measure how much of CorefInst's 2 pp improvement comes from better linking versus better mention detection.

3. **Zero Mention Coverage Validation**: For pro-drop languages, manually annotate a small subset of documents to verify that the 8.4 pp improvement on zero mentions reflects actual semantic understanding rather than pattern matching, focusing on cases requiring deep contextual reasoning.