---
ver: rpa2
title: 'Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved
  Text-Based Learning for LGE Detection'
arxiv_id: '2502.12948'
source_url: https://arxiv.org/abs/2502.12948
tags:
- image
- text
- images
- data
- scar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates a text-based deep learning approach for
  detecting myocardial hyperenhancement from cardiac LGE MRI images using clinical
  reports, without requiring pixel-level annotations. The method incorporates domain
  knowledge through synthetic data augmentation, anatomically-informed image orientation
  normalization, and a captioning loss for fine-grained supervision, while leveraging
  pretraining of the vision encoder on a related segmentation task.
---

# Fake It Till You Make It: Using Synthetic Data and Domain Knowledge for Improved Text-Based Learning for LGE Detection

## Quick Facts
- **arXiv ID**: 2502.12948
- **Source URL**: https://arxiv.org/abs/2502.12948
- **Reference count**: 8
- **Primary result**: Achieves balanced accuracy of 0.83 for LGE detection using text-based deep learning with synthetic data augmentation

## Executive Summary
This study presents a novel text-based deep learning approach for detecting myocardial hyperenhancement from cardiac LGE MRI images using only clinical reports, eliminating the need for pixel-level annotations. The method leverages domain knowledge through synthetic data augmentation, anatomically-informed image orientation normalization, and a captioning loss for fine-grained supervision. The approach demonstrates strong performance on a clinical cohort of 965 patients, achieving balanced accuracy of 0.83 and outperforming several baseline methods including BiomedCLIP and MedFlamingo.

The key innovation lies in combining text-based training with synthetic scar augmentation and anatomical normalization to overcome the challenge of limited annotated medical imaging data. By pretraining the vision encoder on a related segmentation task and incorporating detailed text descriptions of cardiac findings, the model can identify LGE patterns without requiring manual segmentation of scar tissue. The approach enables zero-shot inference, making it particularly valuable for clinical applications where annotated data is scarce.

## Method Summary
The study introduces a text-based deep learning framework for LGE detection that eliminates the need for pixel-level annotations by leveraging clinical reports. The approach uses a pretrained vision encoder fine-tuned on a segmentation task, combined with a language model trained on medical reports describing cardiac findings. Key components include synthetic data augmentation to generate realistic scar patterns, anatomically-informed orientation normalization using cardiac landmarks, and a captioning loss for fine-grained supervision. The model is trained on 965 patients and evaluated using balanced accuracy, demonstrating superior performance compared to both text-only and image-only baseline methods.

## Key Results
- Achieves balanced accuracy of 0.83 on clinical cohort of 965 patients
- Outperforms BiomedCLIP (0.58), MedFlamingo (0.50), and image-only classifier (0.77)
- Synthetic scar augmentation contributes 10 percentage points to performance improvement
- LV orientation normalization adds 6 percentage points, captioning loss adds 3 percentage points
- Enables zero-shot inference without additional fine-tuning

## Why This Works (Mechanism)
The approach works by integrating domain knowledge into the learning process through multiple mechanisms. First, synthetic scar augmentation addresses the data scarcity problem by generating realistic pathological patterns that expose the model to diverse LGE appearances during training. Second, anatomically-informed orientation normalization ensures consistent spatial relationships across images, allowing the model to learn scar patterns relative to standardized cardiac anatomy rather than image-specific orientations. Third, the captioning loss provides detailed supervision by training the model to generate descriptive text about cardiac findings, which reinforces understanding of subtle LGE patterns. Finally, pretraining on a related segmentation task provides a strong visual feature representation that captures relevant anatomical structures before fine-tuning on the text-based LGE detection task.

## Foundational Learning
- **Text-based medical image analysis**: Learning from clinical reports instead of pixel-level annotations is needed because manual segmentation is time-consuming and requires expert knowledge. Quick check: Verify that report text contains sufficient detail about LGE patterns.
- **Synthetic data augmentation**: Generating artificial scar patterns addresses the limited availability of real LGE cases. Quick check: Ensure synthetic scars follow realistic anatomical distributions and intensity profiles.
- **Anatomical normalization**: Standardizing cardiac orientation removes variability in image acquisition. Quick check: Confirm landmark detection accuracy across diverse patient anatomies.
- **Zero-shot learning**: Enabling inference without additional fine-tuning is crucial for clinical deployment. Quick check: Validate performance on held-out test set without any model updates.
- **Multi-task pretraining**: Using segmentation task as pretraining provides relevant visual features. Quick check: Compare performance with and without pretraining on segmentation task.

## Architecture Onboarding

**Component Map**: Clinical Reports -> Text Encoder -> Vision Encoder (pretrained on segmentation) -> LGE Detector -> Classification Output

**Critical Path**: The most critical path is: Vision Encoder (with anatomical normalization) -> LGE Detector, as accurate visual feature extraction of cardiac structures directly impacts detection performance. The synthetic data generation pipeline is also critical for training data diversity.

**Design Tradeoffs**: The approach trades increased model complexity (synthetic data generation, anatomical normalization) for eliminating the need for manual pixel annotations. This adds computational overhead during training but provides long-term benefits through reduced annotation burden. The zero-shot capability requires careful pretraining but eliminates fine-tuning requirements at deployment.

**Failure Signatures**: Performance degradation may occur when clinical reports lack sufficient detail about LGE patterns, when synthetic scar generation fails to capture rare pathological variants, or when anatomical normalization fails due to severe cardiac pathology or poor image quality. The model may also struggle with LGE patterns not well-represented in the training data.

**First Experiments**: 1) Evaluate model performance on images with varying LGE severity to assess detection threshold sensitivity. 2) Test synthetic data ablation to quantify contribution of augmentation to overall performance. 3) Validate anatomical normalization by comparing performance with and without orientation standardization.

## Open Questions