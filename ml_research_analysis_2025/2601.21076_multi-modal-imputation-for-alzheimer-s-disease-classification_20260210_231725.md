---
ver: rpa2
title: Multi-modal Imputation for Alzheimer's Disease Classification
arxiv_id: '2601.21076'
source_url: https://arxiv.org/abs/2601.21076
tags:
- diffusion
- ddpm
- imputation
- alzheimer
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether conditional denoising diffusion
  models (DDPMs) can improve 3-way Alzheimer's disease classification (cognitively
  normal, mild cognitive impairment, Alzheimer's disease) by imputing missing diffusion-weighted
  imaging (DWI) scans from T1-weighted MRIs. The approach uses a 3D U-Net DDPM architecture
  to translate T1 scans into synthetic DWI fractional anisotropy volumes, addressing
  the challenge of incomplete multimodal datasets in neuroimaging.
---

# Multi-modal Imputation for Alzheimer's Disease Classification

## Quick Facts
- arXiv ID: 2601.21076
- Source URL: https://arxiv.org/abs/2601.21076
- Reference count: 30
- Primary result: DDPM-based imputation of DWI scans from T1 MRIs improves 3-way AD classification accuracy from 68.03% to 70.36% in bi-modal models

## Executive Summary
This study addresses the challenge of missing multimodal neuroimaging data in Alzheimer's disease classification by proposing a conditional denoising diffusion probabilistic model (DDPM) approach. The method generates synthetic diffusion-weighted imaging (DWI) scans from T1-weighted MRIs to augment training data for a 3-way classification task (cognitively normal, mild cognitive impairment, Alzheimer's disease). Extensive experiments demonstrate that synthetic DWI data improves classification performance across multiple metrics, particularly when the synthetic data is balanced across diagnostic categories. The results suggest DDPM-based imputation offers a promising solution for multimodal neuroimaging tasks where complete data collection is challenging.

## Method Summary
The approach uses a 3D U-Net DDPM architecture to translate T1-weighted MRI scans into synthetic DWI fractional anisotropy volumes. The conditional diffusion model is trained to denoise noisy versions of DWI scans conditioned on corresponding T1 scans. For classification, three experimental setups were compared: T1-only uni-modal models, DWI-only uni-modal models, and T1+DWI bi-modal models. Various imputation strategies were tested including baseline methods (blank scans, average diagnosis-based imputation) and the proposed DDPM-based approach. Classification performance was evaluated using accuracy, macro F1-score, and balanced accuracy metrics across all three diagnostic categories.

## Key Results
- DWI-only models: accuracy improved from 62.19% to 65.40%, macro F1-score from 41.00% to 50.79%
- Bi-modal models: accuracy improved from 68.03% to 70.36% when trained with synthetic MCI/AD scans
- Strongest performance gains occurred when synthetic data was balanced across diagnostic categories
- Baseline imputation methods (blank or average diagnosis-based) failed to improve classification results

## Why This Works (Mechanism)
The DDPM architecture leverages the strong correlation between T1 and DWI imaging modalities to generate realistic synthetic DWI volumes. By conditioning the diffusion process on T1 features, the model learns to reconstruct the complementary structural information captured in DWI scans. This synthetic data augmentation helps address class imbalance issues and provides additional training examples for minority classes (MCI and AD), leading to improved classification performance. The denoising process effectively learns the joint distribution of multimodal neuroimaging data, enabling generation of physiologically plausible DWI volumes that capture disease-specific patterns.

## Foundational Learning
- Diffusion probabilistic models: Why needed - generate high-quality synthetic data by reversing a gradual noising process; Quick check - understand the forward and reverse diffusion processes
- 3D U-Net architecture: Why needed - process volumetric medical imaging data while preserving spatial relationships; Quick check - verify receptive field size and skip connections
- Conditional generation: Why needed - ensure synthetic DWI volumes are consistent with corresponding T1 inputs; Quick check - validate conditioning mechanism effectiveness
- Multimodal neuroimaging: Why needed - different MRI modalities capture complementary brain structural information; Quick check - understand specific information captured by T1 vs DWI
- Fractional anisotropy: Why needed - DWI-derived metric quantifying water diffusion directionality in brain tissue; Quick check - verify FA volume preprocessing and normalization

## Architecture Onboarding

**Component Map:**
T1 MRI scans -> DDPM (3D U-Net) -> Synthetic DWI FA volumes -> Classification model (concatenated T1+DWI) -> AD classification

**Critical Path:**
T1 input -> DDPM denoising steps -> Synthetic DWI output -> Feature extraction -> Classification decision

**Design Tradeoffs:**
- 3D vs 2D U-Net: 3D preserves volumetric spatial relationships but requires more computational resources
- Conditional vs unconditional generation: Conditional ensures consistency but requires paired data
- FA volume vs raw DWI: FA is more interpretable but may lose some diffusion information

**Failure Signatures:**
- Mode collapse in synthetic DWI generation (all synthetic scans look similar)
- Inconsistent synthetic data across diagnostic categories
- Degradation in classification performance when adding synthetic data

**First 3 Experiments to Run:**
1. Visualize synthetic vs real DWI FA volumes for quality assessment
2. Ablation study: test DDPM performance with different noise schedule parameters
3. Cross-validation: assess classification performance across different train/test splits

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to single dataset without external validation for generalizability assessment
- No computational cost analysis for DDPM training and inference
- Does not compare against other generative models or state-of-the-art multimodal fusion techniques

## Confidence
- **High Confidence**: DDPM architecture and training methodology is clearly described and technically sound
- **Medium Confidence**: Classification performance improvements with synthetic data augmentation are demonstrated
- **Low Confidence**: Generalization of results to different populations and clinical settings remains uncertain

## Next Checks
1. External validation on independent multi-center datasets to assess model robustness and generalization
2. Ablation studies comparing DDPM-based imputation against other generative models (GANs, VAEs) and multimodal fusion approaches
3. Computational efficiency analysis including training time, inference latency, and hardware requirements for clinical deployment