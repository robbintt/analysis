---
ver: rpa2
title: Robust GNN Watermarking via Implicit Perception of Topological Invariants
arxiv_id: '2510.25934'
source_url: https://arxiv.org/abs/2510.25934
tags:
- wm-acc
- task
- graph
- watermark
- carrier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InvGNN-WM introduces a watermarking framework that ties ownership
  to a GNN's implicit perception of a graph invariant, rather than to synthetic triggers.
  By training the model to predict normalized algebraic connectivity on private carrier
  graphs, the watermark becomes an intrinsic part of the model's reasoning process.
---

# Robust GNN Watermarking via Implicit Perception of Topological Invariants

## Quick Facts
- arXiv ID: 2510.25934
- Source URL: https://arxiv.org/abs/2510.25934
- Reference count: 40
- Primary result: Achieves >98% watermark accuracy while matching clean task performance on GNN models

## Executive Summary
InvGNN-WM introduces a novel watermarking framework that embeds ownership in GNNs by training them to predict normalized algebraic connectivity (normalized Fiedler value) on private carrier graphs. Unlike traditional methods that use synthetic triggers, this approach ties ownership to the model's implicit perception of a graph invariant, making the watermark an intrinsic part of the model's reasoning process. The method demonstrates state-of-the-art watermark accuracy (>98% in most settings) while maintaining clean task performance and robustness against pruning, fine-tuning, and quantization attacks.

## Method Summary
The framework works by attaching a perception head (1-layer MLP with spectral normalization) to a GNN backbone and training it to predict the normalized algebraic connectivity of private carrier graphs. The carrier graphs are generated via degree-preserving edge swaps from task data and normalized using 5th/95th percentiles from the training distribution. During training, the model optimizes a dual loss combining the task objective with a watermark prediction loss. Ownership verification is performed through black-box queries on the carrier graphs, with a threshold of 94/128 matches required for confirmation. The approach theoretically proves that exact watermark removal is NP-complete and establishes a formal trade-off between watermark removal and task degradation.

## Key Results
- Achieves watermark accuracy exceeding 98% across multiple datasets and attack scenarios
- Maintains clean task performance with differences within ±0.5% compared to unwatermarked models
- Demonstrates robustness to pruning (0.3% drop), fine-tuning (2.1% drop), and quantization (0.8% drop)
- Theoretical proof establishes NP-completeness of exact watermark removal

## Why This Works (Mechanism)
The watermark becomes intrinsically tied to the model's learned representation through the perception head trained on private carrier graphs. By predicting a topological invariant (normalized algebraic connectivity), the model develops specialized reasoning about graph structure that cannot be easily removed without degrading task performance. The use of private carriers and the spectral normalization constraint make the watermark difficult to spoof or remove through common post-processing attacks.

## Foundational Learning
- **Normalized algebraic connectivity**: The second smallest eigenvalue of the graph Laplacian, normalized to be scale-invariant. Why needed: Serves as the topological invariant that the model learns to predict. Quick check: Verify λ̃₂ is invariant under node/edge permutations and scaling.
- **Degree-preserving edge swaps**: A method to generate graph variants while maintaining degree sequences. Why needed: Creates carrier graphs that are structurally similar but distinct from training data. Quick check: Confirm degree distribution matches exactly after swaps.
- **Spectral normalization**: Constrains the Lipschitz constant of the perception head. Why needed: Provides theoretical guarantees for watermark robustness. Quick check: Verify spectral norm of perception head weights ≤ 1.0.
- **Kolmogorov-Smirnov test for graph similarity**: Statistical test comparing degree and clustering distributions. Why needed: Ensures carriers are sufficiently distinct from training graphs. Quick check: p-values > 0.1 for carrier vs. training graph distributions.
- **Per-batch carrier ratio**: Proportion of carriers used per training batch. Why needed: Balances watermark learning with task performance. Quick check: Ratio ≤ 0.16 as reported.
- **Black-box verification threshold**: Statistical criterion for ownership confirmation. Why needed: Provides provable guarantees against false positives. Quick check: T ≥ 94 matches for m=128 carriers achieves 10⁻⁶ significance level.

## Architecture Onboarding

**Component Map**
GNN Backbone (GCN/GraphSAGE/GIN) -> Global Pooling -> Perception Head (1-layer MLP) -> Watermark Prediction -> Dual Loss (Task + Watermark)

**Critical Path**
1. Generate carrier graphs via degree-preserving edge swaps
2. Attach perception head to backbone with spectral normalization
3. Train with dual objective (task + watermark prediction)
4. Verify ownership via black-box queries on carriers

**Design Tradeoffs**
- Perception head complexity vs. watermark capacity: 1-layer MLP chosen for simplicity and theoretical guarantees
- β_wm value vs. task performance: Requires careful calibration to balance watermark strength and task accuracy
- Carrier generation method vs. watermark robustness: Degree-preserving swaps provide good balance between similarity and distinctiveness

**Failure Signatures**
- WM-ACC ~50%: β_wm too small or κ_marg near 0
- Task ACC drops >1%: β_wm exceeds theoretical bound
- Carriers rejected by KS-test: Over-aggressive swaps or inappropriate thresholds

**Three First Experiments**
1. Generate carriers from Cora dataset with varying swap counts (5-50) and verify KS-test acceptance rates
2. Train GCN on Cora with different β_wm values (1e-5 to 1e-4) and measure WM-ACC vs. Task ACC trade-off
3. Verify ownership on watermarked models using different threshold values (τ=90, 94, 98) and measure false positive/negative rates

## Open Questions the Paper Calls Out

**Open Question 1**
Can InvGNN-WM remain robust against fully adaptive adversaries that co-train with explicit anti-watermark objectives or search for alternative invariants to spoof the perception head?
The authors explicitly limit their threat model to common post-training edits, noting that extending benchmarks to "fully adaptive adversaries" is a "promising next step" (Appendix I). The current defense relies on the attacker lacking specific knowledge of the owner's private carriers and invariant choice during training; an adversary who actively optimizes to break the topological coupling during training is untested.

**Open Question 2**
Does the framework transfer effectively to highly expressive architectures like graph transformers with global attention or higher-order message passing networks?
The paper states that "more expressive operators (e.g., transformers with global attention...)" were not exhaustively studied and that systematic validation is "future work" (Appendix I). The theoretical guarantees rely on specific Lipschitz and margin conditions that might behave differently in attention-based mechanisms compared to the tested GCN/GraphSAGE backbones.

**Open Question 3**
Do invariant ensembles (mixtures of spectral, motif-, or diffusion-based properties) provide superior robustness for heterophilous or dynamic graphs compared to the single normalized algebraic connectivity invariant?
The authors note their choice of $\tilde{\lambda}_2$ "may not be uniformly optimal across all graph regimes (e.g., highly heterophilous graphs)" and suggest exploring "mixtures" as future work (Appendix I). A single spectral invariant may capture insufficient structural information for specific graph types, potentially reducing the robustness margin or watermark accuracy in those domains.

## Limitations
- Underspecified backbone architectures (hidden dimensions, layer counts) limit exact reproduction
- Normalization scheme requires precise percentile estimation from training graphs not fully detailed
- Theoretical bounds depend on task-specific loss landscapes that cannot be verified without exact conditions
- NP-completeness claim doesn't account for practical approximation algorithms

## Confidence
- **Watermark robustness to adversarial attacks**: High confidence - consistent >98% accuracy across multiple attack types with sound theoretical justification
- **Zero degradation in clean task performance**: Medium confidence - reported differences within ±0.5%, but sensitive to architectural choices and β_wm calibration
- **Theoretical NP-completeness of exact watermark removal**: High confidence - formal reduction from 3-SAT is logically sound

## Next Checks
1. **Architecture sensitivity analysis**: Systematically vary hidden dimensions (32, 64, 128) and layer counts (1, 2, 3) for each backbone to quantify impact on task-accuracy/watermark-accuracy trade-off curve.

2. **β_wm calibration validation**: Implement theoretical bound verification by estimating L_s and μ_PL from actual training runs, then test whether empirically optimal β_wm values fall within derived safety interval.

3. **Verification threshold calibration study**: Generate carriers with varying similarity to training graphs (KS-test thresholds δ=0.1, 0.2, 0.3) and measure how false positive rates change with τ(α) threshold to validate 94/128 provides claimed significance level.