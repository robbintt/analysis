---
ver: rpa2
title: 'ARETE: an R package for Automated REtrieval from TExt with large language
  models'
arxiv_id: '2511.04573'
source_url: https://arxiv.org/abs/2511.04573
tags:
- data
- species
- arete
- performance
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ARETE is an R package for automated species occurrence data extraction
  from unstructured text using large language models (LLMs). It integrates OCR, LLM
  processing via ChatGPT API, and outlier detection with geo-environmental validation.
---

# ARETE: an R package for Automated REtrieval from TExt with large language models

## Quick Facts
- arXiv ID: 2511.04573
- Source URL: https://arxiv.org/abs/2511.04573
- Reference count: 18
- Key outcome: ARETE is an R package for automated species occurrence data extraction from unstructured text using large language models (LLMs).

## Executive Summary
ARETE is an R package that automates extraction of species occurrence data from scientific literature using large language models. The system integrates OCR, LLM processing via OpenAI API, and outlier detection with geo-environmental validation. Fine-tuning on domain-specific corpora significantly improved extraction accuracy from 0.833 to 0.958 F1 score. When tested on 100 spider species, ARETE expanded known geographic ranges by approximately 2000× and identified species eligible for IUCN status downgrading. The package offers faster, lower-cost extraction compared to manual annotation while providing built-in performance validation capabilities.

## Method Summary
The ARETE pipeline processes scientific papers through OCR (if needed), text chunking based on model token limits, prompt-guided LLM extraction, and outlier detection using geographic and environmental validation. The system accepts PDF or text documents and extracts structured occurrence data including species names, locations, and coordinates. Fine-tuning on annotated ecological papers improves performance, with the best model achieving 0.958 F1 score compared to 0.833 for base models. Validation uses the gecko package to flag suspicious extractions based on spatial clustering and environmental envelopes. The package outputs tabular data with species, location, and coordinate fields, along with optional outlier detection results.

## Key Results
- Fine-tuning improved F1 scores from 0.833 to 0.958 on 50 annotated papers
- ARETE expanded known Extent of Occurrence by ~2000× for 100 spider species
- Identified 9 species eligible for IUCN status downgrading
- Processing speed of 3.7 pages/minute at ~315× lower cost than manual annotation
- 50% of false positives traced to OCR errors rather than model hallucinations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt-guided LLM extraction transforms unstructured taxonomic text into structured occurrence tables with measurable precision.
- Mechanism: Document text is chunked to fit model token limits, each chunk is appended to a structured prompt specifying output columns (Species, Location, Coordinates), and the LLM generates tabular output parsed by the package.
- Core assumption: LLMs pretrained on scientific literature retain sufficient latent understanding of taxonomic conventions and geographic coordinate formats.
- Evidence anchors:
  - [abstract]: "integrates all steps of the data extraction and validation process, from Optical Character Recognition to detection of outliers and output in tabular format"
  - [section 2.3]: "Each part of the original text is then appended to a prompt that is best suited for that service"
  - [corpus]: "Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology" demonstrates comparable LLM entity extraction from ecological literature (FMR 0.544)
- Break condition: OCR errors propagate upstream—50% of false positives were OCR-derived, not model hallucinations (Section 4.1).

### Mechanism 2
- Claim: Fine-tuning on a domain-specific annotated corpus improves extraction F1 from 0.833 to 0.958.
- Mechanism: K-fold training on RECODE (annotated ecological/taxonomic papers) teaches the model to recognize paper structures, attribute localities to correct species, and ignore reference-section false positives.
- Core assumption: The training corpus structure is representative of target documents.
- Evidence anchors:
  - [abstract]: "Fine-tuning improved F1 scores from 0.833 to 0.958 on 50 annotated papers"
  - [section 4.2]: Best fine-tuned model achieved F1=0.958 with manual weighted evaluation across folds
  - [corpus]: No directly comparable fine-tuning studies for species extraction found; corpus evidence is weak for this specific mechanism
- Break condition: Performance drops sharply on papers structurally different from training data—51.5% of false negatives came from 3 problematic papers representing <5% of sample (Section 5).

### Mechanism 3
- Claim: Multi-modal outlier detection using geographic, environmental, and SVM methods flags suspicious extractions before downstream use.
- Mechanism: Extracted coordinates are validated against WorldClim environmental envelopes and spatial proximity to other records; points exceeding 95th percentile distance thresholds or falling outside SVM-derived envelopes are flagged.
- Core assumption: Valid occurrence records cluster in both geographic and environmental space.
- Evidence anchors:
  - [abstract]: "outlier detection with geo-environmental validation"
  - [section 2.4]: "flags possible outliers using geographical distances (geo), environmental distances (env), and support vector machines (svm)"
  - [corpus]: Weak corpus evidence—no directly comparable geo-environmental validation pipelines for LLM extraction found
- Break condition: Species with genuinely disjunct or poorly sampled distributions may be incorrectly flagged; user must calibrate conservatism level.

## Foundational Learning

- Concept: Token limits and context window management
  - Why needed here: ARETE chunks documents based on model-specific limits (e.g., gpt-3.5-turbo-1106); exceeding limits truncates content and loses data.
  - Quick check question: Processing a 40-page PDF—how would you verify no text was dropped during chunking?

- Concept: Precision-recall tradeoff in conservation contexts
  - Why needed here: False positives (hallucinated occurrences) risk underestimating extinction threat; the paper prioritizes high precision (0.917) over recall (0.764) for this reason.
  - Quick check question: Why is a false positive more damaging than a false negative for IUCN status assessment?

- Concept: OCR error propagation
  - Why needed here: Half of false positives originated from OCR misreads in species names or coordinates, not LLM failures; diagnosis requires tracing upstream.
  - Quick check question: If extraction consistently misses a species present in the PDF, which layer should you inspect first?

## Architecture Onboarding

- Component map:
  Input: PDF/text → OCR (nougat/Tesseract fallback) → Text cleaning → Chunking → Prompt assembly → OpenAI API → Response parsing → Validation (detect_outlier) → Output table

- Critical path:
  1. get_geodata() receives path, taxon, API key
  2. Extract/embedded text or trigger OCR
  3. Chunk text per token limits
  4. Sequential API calls with rate-limit handling
  5. Parse and assemble output; optionally run outlier detection

- Design tradeoffs:
  - Proprietary vs. open models: Currently OpenAI-only for performance; open-source support planned
  - Fine-tuning investment: Higher accuracy requires annotated training data and tuning cost
  - Automation level: Designed for human-in-the-loop verification; outlier flags are advisory, not automatic rejections

- Failure signatures:
  - High false negatives with low F1: Check OCR quality and paper formatting first
  - Coordinates extracted but locations missing: Prompt may need adjustment for verbatim locality extraction
  - High Levenshtein distance in validation: Model is paraphrasing rather than preserving original text

- First 3 experiments:
  1. Run get_geodata() on one well-formatted paper with known occurrences; manually verify output completeness.
  2. Inject one incorrect coordinate into results; confirm detect_outlier() flags it appropriately.
  3. Run performance_report() against human-annotated ground truth for 5 papers; characterize error distribution (FP vs. FN, OCR vs. model).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can open-source Large Language Models (LLMs) achieve performance levels comparable to the fine-tuned proprietary GPT models currently used in ARETE?
- Basis in paper: [explicit] The authors state in Section 6 that "adding support for additional LLMs, in particular open-source alternatives (Llama, Bard, Palm, Gemini, DeepSeek, etc.)" is a planned future update.
- Why unresolved: The current study exclusively validates and relies on OpenAI's proprietary API, leaving the efficacy of open-source alternatives untested.
- What evidence would resolve it: Benchmarking the F1 scores and hallucination rates of fine-tuned open-source models against the reported 0.958 F1 score of the fine-tuned GPT model.

### Open Question 2
- Question: Can the ARETE pipeline be effectively generalized to extract morphological trait data with the same reliability as geospatial occurrence data?
- Basis in paper: [explicit] Section 6 explicitly lists "expanding the package's scope to also encompass the extraction of trait data" as a planned feature.
- Why unresolved: The current validation, prompts, and outlier detection mechanisms (geo-environmental distance) are specifically optimized for species, locations, and coordinates.
- What evidence would resolve it: A validation report using the performance_report() function on a corpus annotated for traits (e.g., body size, color) rather than occurrences.

### Open Question 3
- Question: To what extent does the English-centric bias of current LLMs degrade extraction performance when processing non-English scientific literature?
- Basis in paper: [explicit] In Supporting Information S.5.2.3, the authors note that "ARETE so far only makes use and tests the usage of LLM in English written text" and warns that lack of experience with non-English nouns may lead to misattribution.
- Why unresolved: The study filtered out non-English papers (155 removed) and did not test the pipeline on multilingual or non-English corpora.
- What evidence would resolve it: A comparative study of extraction accuracy (Levenshtein distance and F1 score) between English and non-English documents containing the same ground-truth data.

## Limitations
- Fine-tuned model weights are proprietary and inaccessible to the public
- RECODE validation corpus is listed as "in prep" and unavailable
- Performance drops significantly on non-English text (155 papers excluded)
- 50% of false positives traced to OCR errors rather than model hallucinations

## Confidence
**High Confidence**: The ARETE pipeline architecture (OCR → chunking → LLM → parsing) is technically sound and reproducible with base models. The conservation impact claim (expanding EOO by ~2000× and identifying 9 species for IUCN downgrading) is methodologically valid if the underlying extraction is accurate.

**Medium Confidence**: The 0.958 F1 score for fine-tuned models and the specific error analysis (OCR vs. model hallucinations) are verifiable in principle but cannot be independently reproduced without access to RECODE corpus and fine-tuned weights.

**Low Confidence**: Claims about scalability to large-scale biodiversity monitoring are speculative given the resource constraints (OpenAI API costs, manual validation requirements) and the documented sensitivity to document structure and language.

## Next Checks
1. Run get_geodata() on 10 PDFs with known OCR quality (searchable vs. scanned); compare extracted text against ground truth to quantify OCR-induced error rates.
2. Execute the pipeline on 5 non-English papers from the excluded 155; document failure modes and error rates to validate the claimed language limitation.
3. Test fine-tuned model performance (if weights become available) or base model performance on 10 papers from different journals/laboratories than RECODE to assess structural generalization limits identified in the error analysis.