---
ver: rpa2
title: Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks
arxiv_id: '2507.16761'
source_url: https://arxiv.org/abs/2507.16761
tags:
- b-cos
- explanations
- networks
- which
- chest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the need for faithful, interpretable deep learning
  models in safety-critical domains like medical imaging, focusing on chest X-ray
  diagnosis. Standard B-cos networks, while inherently interpretable, suffer from
  aliasing artifacts in their explanation maps, limiting clinical utility.
---

# Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks

## Quick Facts
- arXiv ID: 2507.16761
- Source URL: https://arxiv.org/abs/2507.16761
- Authors: Marcel Kleinmann; Shashank Agnihotri; Margret Keuper
- Reference count: 40
- This work addresses the need for faithful, interpretable deep learning models in safety-critical domains like medical imaging, focusing on chest X-ray diagnosis.

## Executive Summary
This paper addresses the need for faithful, interpretable deep learning models in safety-critical domains like medical imaging, focusing on chest X-ray diagnosis. Standard B-cos networks, while inherently interpretable, suffer from aliasing artifacts in their explanation maps, limiting clinical utility. To overcome this, the authors integrate anti-aliasing techniques—specifically FLCPooling and BlurPool—into B-cos models, eliminating artifacts and improving explanation quality. They also extend B-cos to handle multi-label classification, essential for realistic medical scenarios. Experiments on the RSNA Pneumonia Detection Challenge and VinBigData datasets demonstrate that B-cos FLC and B-cos BP preserve strong predictive performance while producing clear, artifact-free, and clinically meaningful explanations. B-cos FLC achieves up to a 5-point improvement in energy-based pointing game scores over baseline models, indicating superior localization and interpretability. The approach outperforms established methods like LayerCAM and CheXNet in both classification and interpretability, making B-cos networks a compelling choice for transparent, trustworthy AI-assisted diagnosis.

## Method Summary
The authors integrate anti-aliasing techniques (FLCPooling and BlurPool) into B-cos networks to eliminate grid artifacts in explanation maps. They replace all strided convolutions with stride=1 convolutions followed by anti-aliased pooling. The approach is extended to multi-label classification for chest X-ray diagnosis. Models are trained on RSNA Pneumonia Detection Challenge and VinBigData datasets with standard classification metrics and Energy-based Pointing Game (EPG) for interpretability evaluation.

## Key Results
- B-cos FLC achieves 28.25% EPG vs. 11.16% for standard B-cos—a >17-point improvement attributable to anti-aliasing
- B-cos FLC/BP maintains competitive F1 scores (61.88-63.23%) and AUC (86.50-87.27%) while eliminating artifacts
- Multi-label extension achieves F1 of 43.66% on VinBigData with interpretable per-class explanations
- B-cos FLC/BP outperforms LayerCAM and CheXNet in both classification and interpretability metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** B-cos networks produce inherently interpretable, class-specific contribution maps by replacing standard linear layers with a weight-input alignment mechanism.
- **Mechanism:** The B-cos transformation computes dynamic weights based on alignment between input features and learned weight vectors, such that the contribution map directly reflects which input regions positively or negatively influenced each class prediction. This eliminates the need for post-hoc gradient-based attribution methods.
- **Core assumption:** The weight-input alignment faithfully represents the model's decision process, and visualizing it provides a truthful account of model reasoning.
- **Evidence anchors:**
  - [abstract] "B-cos networks offer a promising solution by replacing standard linear layers with a weight-input alignment mechanism, producing inherently interpretable, class-specific explanations without post-hoc methods."
  - [page 2] "These models can directly show which part of the image caused network activations, enabling an understanding of why a classification was made [8]."
  - [corpus] Neighbor paper "B-cos LM" confirms extension of B-cos principles to language models for improved explainability, suggesting cross-domain validity of the alignment mechanism.
- **Break condition:** If the alignment weights are dominated by high-frequency spectral artifacts (from strided convolutions), the contribution maps become visually unreliable even if mechanistically faithful.

### Mechanism 2
- **Claim:** Anti-aliasing techniques (FLCPooling and BlurPool) eliminate grid artifacts in B-cos explanation maps by separating convolution from downsampling and applying proper low-pass filtering.
- **Mechanism:** Strided convolutions violate the Nyquist sampling criterion, causing high-frequency components to fold back as aliasing artifacts. FLCPooling applies frequency-domain low-pass filtering; BlurPool applies spatial-domain blurring before downsampling. Both methods decompose stride>1 convolutions into stride=1 convolution followed by anti-aliased pooling, preserving signal integrity in feature representations.
- **Core assumption:** The observed grid artifacts stem from aliasing during downsampling (not from other architectural components), and removing them improves clinical interpretability without degrading classification.
- **Evidence anchors:**
  - [page 4] "These arise due to distortions in the intermediate feature representations caused by strided convolutions, which downsample the feature maps using inefficient sampling strategies that violate the Nyquist theorem."
  - [page 6, Table 3] B-cos FLC achieves 28.25% EPG vs. 11.16% for standard B-cos—a >17-point improvement attributable to anti-aliasing.
  - [corpus] Limited direct corpus evidence on anti-aliasing in medical imaging; most related work focuses on detection accuracy rather than explanation quality.
- **Break condition:** If the target pathology requires precise high-frequency spatial details (e.g., fine reticular patterns), aggressive low-pass filtering may inadvertently smooth diagnostically relevant features.

### Mechanism 3
- **Claim:** Extending B-cos to multi-label classification enables contribution maps for all output neurons simultaneously, which is essential for chest X-rays where multiple pathologies co-occur.
- **Mechanism:** Standard B-cos generates explanations only for the predicted class. The multi-label extension (adopted from prior work [46]) computes contribution maps for every output neuron, allowing inspection of evidence for and against each possible condition independently.
- **Core assumption:** Co-occurring pathologies have spatially distinct or overlapping but independently interpretable features, and per-class contribution maps correctly attribute evidence to each condition.
- **Evidence anchors:**
  - [page 2] "Additionally, while the original B-cos models support multi-label classification, they were proposed for multi-class classification. Thus, we use the framework from [46], to obtain multi-label classification."
  - [page 7, Table 6] Multi-label results on VinBigData show competitive F1 (43.66% B-cos vs. 43.87% baseline) with the added benefit of interpretable per-class explanations.
  - [corpus] Neighbor work on chest X-ray abnormality localization emphasizes multi-class co-occurrence as a practical challenge, indirectly supporting this design choice.
- **Break condition:** If multiple conditions share nearly identical visual features (e.g., consolidation vs. mass), contribution maps may conflate evidence, reducing per-class interpretability.

## Foundational Learning

- **Concept: Aliasing and the Nyquist Theorem**
  - **Why needed here:** Understanding why strided convolutions produce grid artifacts requires grasping that undersampling high-frequency signal components causes spectral folding. The anti-aliasing solution only makes sense with this foundation.
  - **Quick check question:** If you downsample a feature map with stride 2 without pre-filtering, what happens to frequency components above 0.25 cycles/pixel?

- **Concept: Inherent vs. Post-hoc Interpretability**
  - **Why needed here:** The paper's core argument is that B-cos provides faithful explanations *by design*, unlike GradCAM/LayerCAM which approximate model reasoning after training. This distinction determines whether explanations can be trusted for clinical decisions.
  - **Quick check question:** What is the fundamental difference between an explanation computed from the model's internal weights versus one computed from gradients at inference time?

- **Concept: Energy-Based Pointing Game (EPG)**
  - **Why needed here:** The paper modifies standard EPG to handle negative contributions in B-cos maps. Understanding this metric is essential for interpreting the reported ~5-point improvements and their clinical significance.
  - **Quick check question:** How does the modified precision-EPG formula differ from the standard pointing game, and why must negative contributions be handled explicitly for B-cos?

## Architecture Onboarding

- **Component map:** Input Image → [Conv stem] → [B-cos blocks with stride=1 convs] → [MaxOut activation] → [BlurPool or FLCPooling] → [Repeat for each stage] → [Classification head] → [Per-class contribution map extraction]

- **Critical path:**
  1. Load pretrained B-cos ResNet50 from `B-cos-v2` repository
  2. Replace all strided convolutions with the anti-aliasing decomposition (see Fig. 2)
  3. Adapt output head for multi-label (binary cross-entropy per class) vs. multi-class (softmax)
  4. Fine-tune with chest X-ray specific augmentations (translation, gamma correction, conservative rotation)

- **Design tradeoffs:**
  - **FLCPooling vs. BlurPool:** FLC applies frequency-domain filtering (more principled, slightly higher EPG gains: 28.25% vs. 21.47% without augmentation). BlurPool is spatial-domain (simpler implementation, competitive results with augmentation: 25.75%).
  - **Augmentation vs. no augmentation:** Light augmentation improves F1 (63.23% vs. 61.88% for B-cos) but slightly reduces accuracy—tradeoff favors augmentation for clinical use where recall matters.
  - **ResNet50 vs. ViT-B:** ViT-B achieves marginally higher AUC (87.27% vs. 86.50%) but with 3× parameters; ResNet50 recommended for training efficiency.

- **Failure signatures:**
  - Grid artifacts in explanation maps → anti-aliasing not applied correctly; verify stride decomposition
  - Low recall with high precision → insufficient oversampling or augmentation; add minority class weighting
  - High EPG but poor classification → model overfitting to easy examples; check cross-validation fold balance
  - Contribution maps highlight wrong regions → potential label noise or dataset shift; inspect per-fold variance

- **First 3 experiments:**
  1. **Baseline replication:** Train standard ResNet50 on RSNA Pneumonia with reported hyperparameters (lr=1e-4, 30 epochs, batch=16). Verify classification metrics within ±2% of Table 1.
  2. **Anti-aliasing ablation:** Compare B-cos (no anti-aliasing), B-cos FLC, and B-cos BP on held-out set. Quantify artifact reduction via visual inspection and EPG delta.
  3. **Multi-label sanity check:** On VinBigData subset, verify that per-class contribution maps for a known multi-condition image (e.g., aortic enlargement + pleural thickening) highlight distinct regions for each label.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do anti-aliasing techniques impact the performance and interpretability of B-cos networks when applied to architectures like ConvNeXt or Vision Transformers?
- Basis in paper: [explicit] The Discussion notes that ConvNeXt was not extensively tested and ViT-B interpretability was not analyzed in depth, leaving the impact of anti-aliasing on these models an "open question."
- Why unresolved: The authors focused primarily on ResNet-50 due to training costs and its strong baseline performance.
- What evidence would resolve it: Comparative results of anti-aliased B-cos ConvNeXt and ViT models on chest X-ray benchmarks.

### Open Question 2
- Question: Can integrating spatial priors or bounding box information directly into the training process enhance the localization accuracy of B-cos contribution maps?
- Basis in paper: [explicit] The authors state in the Discussion that "integrating spatial priors or bounding box information into B-cos networks could enhance localization further."
- Why unresolved: The current implementation uses standard classification training without explicit spatial supervision.
- What evidence would resolve it: Improved Energy-based Pointing Game (EPG) scores in models trained with spatial priors versus the current classification-only baseline.

### Open Question 3
- Question: What is the trade-off between scalability and interpretability when applying B-cos models to large-scale datasets lacking explicit annotations?
- Basis in paper: [explicit] The Discussion suggests applying B-cos to "larger datasets lacking explicit annotations to explore the trade-off between scalability and interpretability."
- Why unresolved: Current evaluation relied on datasets with bounding boxes, limiting the assessment of fidelity on massive, weakly-labeled data.
- What evidence would resolve it: Analysis of explanation quality and model performance on large, annotation-scarce datasets like CheXpert.

## Limitations

- The core interpretability claims depend critically on the assumption that B-cos contribution maps faithfully reflect model reasoning, yet the paper provides limited ablation evidence directly linking anti-aliasing to explanation quality
- The EPG metric, while quantitative, is binary (in/out of bounding box) and may not capture nuanced localization quality needed for clinical diagnosis
- The multi-label extension builds on prior work [46] without validation of whether per-class contributions remain faithful when pathologies co-occur

## Confidence

- **High Confidence**: Anti-aliasing techniques effectively eliminate grid artifacts from B-cos explanations (direct visual evidence in figures, significant EPG improvements of 17-22 points)
- **Medium Confidence**: B-cos FLC/BP maintains or improves classification performance while improving interpretability (supported by competitive F1/AUC scores, but no direct comparison of clinical decision-making quality)
- **Low Confidence**: Per-class contribution maps for multi-label scenarios accurately attribute evidence to individual pathologies (theoretical extension without empirical validation of faithfulness in co-occurrence cases)

## Next Checks

1. **Ablation on anti-aliasing vs. explanation quality**: Train B-cos with and without anti-aliasing, compare EPG scores and conduct expert radiologist review of explanation map quality for clinically relevant cases
2. **Multi-label faithfulness validation**: Create synthetic chest X-rays with known pathology combinations, verify that contribution maps correctly isolate evidence for each condition without interference
3. **Cross-dataset generalization**: Test B-cos FLC/BP on a third external chest X-ray dataset (e.g., CheXpert) to validate that anti-aliasing improvements transfer beyond the two studied datasets