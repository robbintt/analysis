---
ver: rpa2
title: Unifying Streaming and Non-streaming Zipformer-based ASR
arxiv_id: '2506.14434'
source_url: https://arxiv.org/abs/2506.14434
tags:
- right-context
- streaming
- frames
- non-streaming
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a unified framework for training zipformer-based
  ASR models that work for both streaming and non-streaming applications. The core
  method introduces dynamic right-context during training through chunked attention
  masking, allowing flexible control of latency-accuracy tradeoffs during inference.
---

# Unifying Streaming and Non-streaming Zipformer-based ASR

## Quick Facts
- arXiv ID: 2506.14434
- Source URL: https://arxiv.org/abs/2506.14434
- Reference count: 17
- This paper presents a unified framework for training zipformer-based ASR models that work for both streaming and non-streaming applications.

## Executive Summary
This paper introduces a unified framework for training zipformer-based ASR models that can operate in both streaming and non-streaming modes through dynamic right-context training. The core innovation is using chunked attention masking with randomly sampled right-context frames during training, enabling flexible latency-accuracy tradeoffs during inference without retraining. The approach is evaluated on Librispeech and large in-house conversational datasets, demonstrating that streaming models with right-context can achieve performance close to non-streaming models. Results show WER improvements of up to 7.9% relative with minimal latency degradation, and the streaming model achieves inference speed advantages over non-streaming counterparts while maintaining competitive accuracy.

## Method Summary
The method trains zipformer-based ASR models using chunked attention masking with dynamic right-context sampling. During training, right-context frames are randomly selected from {0, 64, 128, 256} per mini-batch and applied through attention masking that exposes future frames beyond chunk boundaries. This creates a model that gracefully handles variable lookahead at inference. The zipformer architecture uses multi-scale frame rates (50Hz → 25Hz → 12.5Hz → 6.25Hz → 12.5Hz → 25Hz) which amplifies the effectiveness of right-context compared to standard conformers. The training employs the transducer loss and evaluates both simulated streaming and real server-client scenarios with varying right-context frames to demonstrate the latency-accuracy tradeoff capability.

## Key Results
- Dynamic right-context training enables flexible inference-time latency-accuracy tradeoffs without retraining
- Streaming models with right-context achieve WER improvements up to 7.9% relative compared to causal streaming
- Minimal latency degradation (~3ms per 64 frames) while maintaining competitive accuracy with non-streaming models
- Inference speed advantages: streaming model achieves 0.32x RTFX vs 0.36x for non-streaming at high concurrency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic right-context training enables inference-time latency-accuracy tradeoff without retraining
- Mechanism: During training, randomly sample right-context frames from {0, 64, 128, 256} per mini-batch, applied via chunked attention masking that exposes future frames beyond chunk boundaries. This creates a model that gracefully handles variable lookahead at inference.
- Core assumption: The model learns to extract useful information from arbitrary amounts of right-context rather than overfitting to a fixed context window.
- Evidence anchors: [abstract] "We propose to use dynamic right-context through the chunked attention masking in the training of zipformer-based ASR models." [section 3.2.3] "we use varying numbers of right-context frames by randomly choosing from the set {0, 64, 128, 256} for each batch during training"

### Mechanism 2
- Claim: Zipformer's multi-scale architecture amplifies right-context effectiveness versus standard conformers
- Mechanism: Zipformer encoder blocks operate at multiple frame rates (50Hz → 25Hz → 12.5Hz → 6.25Hz → 12.5Hz → 25Hz) with different embedding dimensions. Fewer frames at lower rates mean right-context propagates more efficiently through the network.
- Core assumption: Multi-scale temporal representations allow right-context to provide meaningful acoustic-linguistic cues across granularities.
- Evidence anchors: [abstract] "using right-context is more effective in zipformer models compared to other conformer models due to its multi-scale nature" [section 4.1, Figure 3] Zipformer shows more pronounced WER improvement than conformer baseline as right-context frames increase from 0 to ~240.

### Mechanism 3
- Claim: Baseline models not trained with right-context still improve when given right-context at inference
- Mechanism: Even without explicit right-context training, chunked attention masking inherently exposes early chunk frames to future intra-chunk context. Adding extra-context frames at inference extends this implicit exposure.
- Core assumption: The model generalizes from intra-chunk future context to extra-chunk context.
- Evidence anchors: [section 4.1] "the WER of the Libri Baseline model, which decreases from 3.33% to 2.83% as the number of decoding right-context frames increases from 0 to 256, despite this model not being trained with right-context" [section 4.2] Similar pattern observed in Large Baseline model across diverse testsets.

## Foundational Learning

- Concept: **Chunked attention masking in streaming ASR**
  - Why needed here: The entire method builds on constraining self-attention receptive fields per frame within chunks. Without this, you cannot control what context the model sees.
  - Quick check question: Can you explain how a frame at position t within a chunk sees different amounts of left/right context depending on its position?

- Concept: **Streaming vs. non-streaming ASR latency semantics**
  - Why needed here: The paper optimizes "final-chunk latency" (time from last audio chunk to transcript), not per-token latency. Understanding this metric is essential for interpreting Table 5.
  - Quick check question: If you add 64 right-context frames at 10ms/frame, what is the theoretical minimum additional latency in seconds?

- Concept: **Transducer (RNN-T/Conformer-T) loss basics**
  - Why needed here: The paper uses zipformer-medium/large with transducer training. The right-context mechanism operates in the encoder; the decoder (prediction network) remains unchanged.
  - Quick check question: In a transducer, which component consumes the encoder output and why does streaming require chunked encoding?

## Architecture Onboarding

- Component map:
  - Frontend: 100Hz acoustic features → Conv downsample to 50Hz
  - Zipformer encoder: 6 stacks at rates [50, 25, 12.5, 6.25, 12.5, 25] Hz with varying dimensions; each stack contains multi-head attention, non-linear attention, feed-forward modules
  - Attention masking layer: Applies M ∈ {0,1}^(Ly×Lk) to softmax(QK^T/√d) before V^T multiplication
  - Transducer decoder: Prediction network + joiner (unchanged from baseline)
  - Inference server: Sherpa websocket server with cpp backend for real-time streaming

- Critical path:
  1. Audio chunk (e.g., 32 frames = 320ms) arrives with 128 left-context frames and N right-context frames
  2. Attention mask constructed: left-context + chunk + right-context visible per-frame
  3. Encoder processes through 6 stacks at varying frame rates
  4. Transducer decoder produces partial/final transcripts
  5. Latency measured from last chunk sent to transcript received

- Design tradeoffs:
  - **Right-context frames (0-256)**: More frames → lower WER, higher latency (Table 5 shows ~3ms additional latency per 64 frames at high concurrency)
  - **Chunk size [16, 32, 64]** during training: Larger chunks provide more natural right-context but reduce streaming granularity
  - **Training right-context set {0, 64, 128, 256}**: Broader range increases flexibility but requires careful LR tuning; paper uses 0.045–0.05 base LR

- Failure signatures:
  - **WER plateaus despite increasing right-context**: Check if training used fixed (non-dynamic) right-context; Figure 4 shows RC-0-64-128-256 outperforms RC-128
  - **Latency spikes at high concurrency (>200 calls)**: Table 5 shows latency jumps from 2.17s to 3.24s when moving from 0 to 64 right-context at concurrency 300; consider reducing right-context or adding server capacity
  - **Streaming WER much worse than simulated**: Real streaming involves padding artifacts; Table 4 shows ~0.8% WER gap between simulated and server-client

- First 3 experiments:
  1. **Baseline comparison**: Train zipformer streaming model with NO right-context; evaluate with 0, 32, 64, 128, 256 right-context frames at inference. Expect WER improvement per Figure 3 trend.
  2. **Dynamic vs. fixed right-context training**: Compare RC-128 (fixed 128 frames) vs. RC-0-64-128-256 (dynamic) using 100h Librispeech subset. Measure WER on test-clean/test-other. Replicate Figure 4 to validate dynamic training advantage.
  3. **Latency-concurrency stress test**: Deploy RC-0-64-128-256 model on g5.2xlarge (or equivalent); measure latency and RTFX at concurrency levels 100, 200, 300 with 64 right-context frames. Compare against non-streaming baseline RTFX to quantify inference speed advantage claimed in abstract.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the training strategy be modified to prevent performance degradation when a model trained with right-context is decoded in a strictly causal (zero right-context) mode?
- Basis in paper: Explicit (Appendix A notes that models trained with right-context "experience degraded performance when decoded without right-context frames" compared to the baseline).
- Why unresolved: The current dynamic masking approach optimizes the model to utilize future context, creating a dependency that causes accuracy to drop below baseline levels if that context is unavailable during inference.
- What evidence would resolve it: A modified training objective or regularization technique that yields robust WER performance at zero right-context while retaining the accuracy gains achieved with higher context values.

### Open Question 2
- Question: Does utilizing a continuous distribution or curriculum for right-context frame selection yield a smoother latency-accuracy trade-off compared to the discrete set {0, 64, 128, 256}?
- Basis in paper: Inferred (Section 3.2.3 states the values were "randomly choosing from the set" based on small-data experiments, leaving the optimality of the sampling strategy unexplored).
- Why unresolved: The discrete sampling strategy may result in "step-function" improvements; it is unknown if continuous training allows the model to better interpolate accuracy for intermediate latency requirements.
- What evidence would resolve it: Comparative analysis of models trained with continuous or scheduled context ranges, showing improved WER at intermediate right-context frame counts not seen during training.

### Open Question 3
- Question: Is the effectiveness of right-context in Zipformer strictly dependent on the multi-scale encoder structure, or does it generalize to other sub-sampling architectures?
- Basis in paper: Inferred (Section 1 attributes the effectiveness to the "multi-scale nature" of Zipformer, but this architectural hypothesis is not isolated from other factors like attention reuse).
- Why unresolved: The paper compares Zipformer to standard Conformers but does not ablate whether the multi-scale frame rates specifically cause the improved right-context utilization.
- What evidence would resolve it: Ablation studies on single-scale Zipformer variants or multi-scale Conformer variants to isolate the contribution of frame rate variation to right-context efficacy.

## Limitations
- Training right-context coverage is limited to 256 frames, with untested behavior for larger context windows
- The specific advantage of zipformer's multi-scale architecture for right-context utilization lacks comprehensive comparative corpus analysis
- The 0.8% WER gap between simulated and real streaming is attributed to "padding artifacts" but not precisely quantified

## Confidence
- **High confidence**: The core mechanism of dynamic right-context training enabling inference-time latency-accuracy tradeoffs is well-supported by experimental results
- **Medium confidence**: The claim that zipformer's multi-scale architecture provides particular advantages for right-context utilization is supported but lacks comprehensive validation
- **Medium confidence**: The observation that baseline models improve with right-context at inference despite not being trained with it is demonstrated but needs further validation

## Next Checks
1. **Right-context scalability test**: Evaluate the RC-0-64-128-256 model with 384 and 512 right-context frames at inference to determine if performance plateaus or degrades beyond the training maximum.

2. **Multi-scale architecture ablation**: Train a single-frame-rate conformer model with the same dynamic right-context training strategy and compare its WER-latency tradeoff curve against zipformer on test-clean/test-other.

3. **Server-client artifact isolation**: Conduct controlled experiments varying chunk sizes, padding strategies, and streaming configurations on the in-house testset to quantify the specific contribution of padding artifacts to the simulated vs. real streaming WER gap.