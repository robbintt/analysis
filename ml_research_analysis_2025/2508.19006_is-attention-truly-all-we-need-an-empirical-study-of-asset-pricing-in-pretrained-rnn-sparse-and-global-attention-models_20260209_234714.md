---
ver: rpa2
title: Is attention truly all we need? An empirical study of asset pricing in pretrained
  RNN sparse and global attention models
arxiv_id: '2508.19006'
source_url: https://arxiv.org/abs/2508.19006
tags:
- attention
- which
- pricing
- layer
- asset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores pretrained RNN attention models for empirical
  asset pricing using 420 large-cap US stocks. It addresses limitations of traditional
  ML models by incorporating mainstream attention mechanisms (additive, Luong's three,
  global self-attention, sliding window sparse attention) and enforcing causal masks
  to prevent future data leakage.
---

# Is attention truly all we need? An empirical study of asset pricing in pretrained RNN sparse and global attention models

## Quick Facts
- arXiv ID: 2508.19006
- Source URL: https://arxiv.org/abs/2508.19006
- Authors: Shanyan Lai
- Reference count: 40
- Primary result: RNN global self-attention and sliding window sparse attention models achieve annualized Sortino ratios of 2.0 and 1.80 respectively during COVID-19 period

## Executive Summary
This study addresses limitations in traditional machine learning asset pricing models by incorporating mainstream attention mechanisms (additive, Luong's three, global self-attention, sliding window sparse attention) into pretrained RNN frameworks. The proposed models enforce causal masks to prevent future data leakage and use MLP autoencoder pre-training for dimensionality reduction. Tested across three market periods including COVID-19, the RNN global self-attention and RNN sliding window sparse attention models demonstrate superior performance in deriving absolute returns and hedging downside risks.

## Method Summary
The approach combines MLP autoencoder pre-training for dimensionality reduction (70% compression) and missing value imputation with two-hidden-layer RNN (64→32 neurons, tanh activation) enhanced by attention mechanisms. The model processes 182 firm characteristic-sorted portfolio factors for 420 large-cap US stocks using monthly data from 1/1957-12/2022. Attention variants include additive, Luong's three types, global self-attention, and sliding window sparse attention, all with enforced causal masks. Training uses MSE+L1 loss with Adam optimizer and early stopping, evaluated via out-of-sample R², pricing error alpha, and portfolio backtesting metrics.

## Key Results
- RNN global self-attention and RNN sliding window sparse attention models achieve annualized Sortino ratios of 2.0 and 1.80 respectively during COVID-19
- RNN sliding window sparse attention model performs more stably across market capitalizations than global self-attention model
- Models demonstrate strong performance in deriving absolute returns and hedging downside risks during extreme market conditions

## Why This Works (Mechanism)

### Mechanism 1: Causal Masking for Temporal Integrity
Enforced causal masks prevent future information leakage by setting attention scores between current time step t and future time steps j>t to -∞ before softmax normalization. This ensures attention weights are zero for any future information, maintaining temporal integrity in time-series asset pricing where current returns can only depend on historical information.

### Mechanism 2: Sparse Attention Window for Stability-Efficiency Trade-off
Sliding window sparse attention restricts attention computation to window S_t = {s | max(0, t-w) ≤ s ≤ t}, reducing complexity from O(T²) to O(T×w). This limits overfitting to idiosyncratic long-range patterns and achieves better generalization across market capitalization regimes than global self-attention while reducing computational cost.

### Mechanism 3: MLP Autoencoder Pre-training for Factor Compression
Autoencoder compresses n original factors to m latent factors (m = 70% of n) via encoder-decoder architecture with MSE reconstruction loss. This reduces dimensionality, imputes missing values, and mitigates overfitting from the "factor zoo" problem by extracting lower-dimensional signal while discarding redundant information.

## Foundational Learning

- **Concept: Recurrent Neural Networks for Sequential Data**
  - Why needed here: RNNs maintain hidden states updated at each time step, enabling temporal dependency capture that feedforward networks cannot naturally model
  - Quick check question: Why would an MLP with a rolling window of 36 months fail to capture dependencies within each window?

- **Concept: Query-Key-Value Attention Abstraction**
  - Why needed here: All attention variants share the Q/K/V framework for computing relevance scores between time steps
  - Quick check question: Given query q_t and key k_j, compute attention weights using scaled dot-product attention with d=32

- **Concept: Asset Pricing Metrics (Alpha, Sortino Ratio, OOS R²)**
  - Why needed here: Paper evaluates models using residual α (unexplained returns), Sortino ratio (downside risk-adjusted returns), and out-of-sample R² (predictive fitness)
  - Quick check question: In this paper, what does a statistically significant positive α indicate, and why might this differ from traditional factor model interpretations?

## Architecture Onboarding

- **Component map:** Input Layer (182 factors) → MLP Autoencoder (70% compression) → Two-layer RNN (64→32 neurons) → Attention Layer (Self or Sparse) → Linear Output Layer

- **Critical path:** 1) Train MLP autoencoder to convergence using early stopping on reconstruction loss 2) Extract latent factors from encoder bottleneck for all time steps 3) Train RNN+attention end-to-end with L1 regularization 4) Validate causal mask implementation before any backtesting

- **Design tradeoffs:** Self-attention vs. sparse attention: Self-attention achieves higher peak performance on volatile (small-cap) stocks; sparse attention generalizes better across market caps. RNN vs. LSTM/GRU: Vanilla RNN achieves highest OOS R² but lower trading returns; LSTM shows inconsistent performance with negative R² in some periods.

- **Failure signatures:** Negative OOS R² indicates overfitting (observed in additive attention, Luong concatenate, LSTM models in period 1911). Self-attention degradation in value-weighted portfolios suggests over-sensitivity to low-volatility regimes. Consistently positive α across all models may indicate systematic underprediction during trending markets or omitted factors.

- **First 3 experiments:** 1) Causal mask validation: Compare attention model performance with and without causal masking on identical data 2) Sparse window sweep: Test w ∈ {12, 24, 36, 48} months to identify optimal historical dependency window 3) Compression ratio analysis: Evaluate 50%, 70%, 90% latent dimensions against both reconstruction error and downstream OOS R²

## Open Questions the Paper Calls Out

- How can machine learning methods be systematically deployed to determine the optimal number of abstracted or transformed factors in asset pricing models?
- What is the economic structure and interpretability of the pricing error α (alpha) generated by ML-based asset pricing models?
- Can machine learning-based asset allocation strategies improve portfolio strategic returns compared to simple equal-weighted or value-weighted approaches?
- How can the issue of omitted factors be mitigated when using pre-selected input factors, and can alternative data sources substitute the current "factor zoo"?

## Limitations

- Model architecture details remain underspecified including L1 regularization coefficient, learning rate schedule, batch size, and sliding window size for sparse attention
- Data preprocessing gaps exist regarding exact imputation methods beyond autoencoder, outlier handling, and factor normalization procedures
- Evaluation methodology concerns include unspecified rolling window size, train/validation split ratio, and assumption of frictionless trading with only 50bp transaction costs

## Confidence

- **High confidence**: Causal masking mechanism - mathematical formulation is explicit and well-established in time series literature
- **Medium confidence**: Sparse attention stability claims - empirical evidence is strong but theoretical justification remains underdeveloped
- **Low confidence**: MLP autoencoder's contribution - no ablation studies provided and 70% compression ratio appears heuristic

## Next Checks

1. **Causal mask validation test** - Train identical attention models with and without causal masking on the same dataset to verify no look-ahead bias exists

2. **Sparse window sensitivity analysis** - Systematically test sliding window sizes w ∈ {12, 24, 36, 48} months across different market capitalization deciles to identify optimal window length

3. **Compression ratio ablation study** - Evaluate model performance at 50%, 70%, and 90% latent dimensions against both reconstruction error and downstream OOS R² to quantify autoencoder's actual contribution