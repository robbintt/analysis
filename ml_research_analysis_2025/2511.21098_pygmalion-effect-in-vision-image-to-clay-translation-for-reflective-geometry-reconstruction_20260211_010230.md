---
ver: rpa2
title: 'Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry
  Reconstruction'
arxiv_id: '2511.21098'
source_url: https://arxiv.org/abs/2511.21098
tags:
- clay
- images
- reflective
- gaussian
- geometry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of reconstructing geometry from
  multi-view images of reflective objects, where view-dependent reflections make it
  difficult to disentangle appearance from shape. The authors propose a novel framework
  inspired by the Pygmalion effect, using image-to-clay translation to suppress specular
  cues while preserving geometric consistency.
---

# Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction

## Quick Facts
- **arXiv ID**: 2511.21098
- **Source URL**: https://arxiv.org/abs/2511.21098
- **Reference count**: 40
- **Primary result**: Introduces image-to-clay translation to suppress specular cues and stabilize geometry reconstruction from multi-view reflective objects

## Executive Summary
This paper addresses the challenge of reconstructing geometry from multi-view images of reflective objects, where view-dependent reflections make it difficult to disentangle appearance from shape. The authors propose a novel framework inspired by the Pygmalion effect, using image-to-clay translation to suppress specular cues while preserving geometric consistency. Specifically, they introduce a dual-branch network: a BRDF-based reflective branch and a clay-guided branch that stabilizes geometry and refines surface normals. The clay branch is supervised by clay-like images generated from the reflective training images, providing reflection-free guidance during early training. Experiments on both synthetic and real datasets show substantial improvements in normal accuracy and mesh completeness compared to existing reflection-handling methods.

## Method Summary
The method uses a dual-branch 2D Gaussian splatting framework where a reflective branch handles BRDF parameters and a clay branch provides geometry-stabilizing supervision. The key innovation is generating pseudo-ground-truth clay images using a fine-tuned image-to-image translation model (OminiControl), which are then used to guide the clay branch during training. The two branches share the same underlying Gaussian geometry (position, scale, opacity, normal) but have separate appearance parameters. During early training, gradients from the reflective branch are detached to allow the geometry to converge primarily under clay supervision, creating a "geometry-first" curriculum.

## Key Results
- Achieves significantly lower Chamfer distance and higher normal accuracy compared to existing reflection-handling methods
- Demonstrates competitive novel-view synthesis performance while substantially improving mesh quality
- Shows that translating radiance into neutrality can serve as a powerful inductive bias for reflective object geometry learning
- Ablation studies confirm the importance of gradient detachment and clay supervision scheduling

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Removing view-dependent specular highlights via image-to-clay translation may reduce the optimization ambiguity between surface reflectance and surface geometry.
- **Mechanism:** The "clay" translation converts complex radiance into a Lambertian-like signal. This suppresses high-frequency specular noise that typically violates multi-view consistency, allowing the geometry optimizer to converge on shape without fitting to transient reflections.
- **Core assumption:** The image-to-image translation model preserves the underlying geometric structure and does not hallucinate new shapes during the conversion.
- **Evidence anchors:** Abstract mentions suppressing specular cues while preserving intrinsic geometric consistency; section 3.4 discusses clay renders containing almost no material texture and assigning higher SSIM weight.
- **Break condition:** The mechanism fails if the translated clay images alter object boundaries or fill in concavities.

### Mechanism 2
- **Claim:** Joint training with a dual-branch system likely stabilizes surface normal estimation by anchoring geometry to a static material representation.
- **Mechanism:** The network optimizes a shared set of Gaussians using two losses: a BRDF loss for reflective appearance and an L1/SSIM loss for the clay render. By anchoring the Gaussians to the "clay" target, the normals are refined against a diffuse signal that is mathematically easier to disentangle from lighting than specular highlights.
- **Core assumption:** A single set of Gaussian parameters can simultaneously satisfy the rendering requirements of both a high-gloss BRDF and a flat clay material.
- **Evidence anchors:** Abstract mentions dual-branch network with BRDF-based reflective branch complemented by clay-guided branch; section 3.4 states both branches operate on the same underlying Gaussian geometry.
- **Break condition:** If the reflective branch requires drastically different opacity distributions than the clay branch, the shared geometry may oscillate or blur.

### Mechanism 3
- **Claim:** Gradient detachment and scheduled training curricula appear necessary to prevent the reflective loss from corrupting the early geometric convergence.
- **Mechanism:** During early iterations, gradients from the RGB/BRDF branch are detached or suppressed, forcing the optimizer to rely primarily on the clay branch. This creates a "geometry-first" curriculum where structure is learned via clay, and texture/reflection is added later.
- **Core assumption:** The initial geometry provided by the clay branch is sufficiently accurate to serve as a warm-start for the complex BRDF optimization.
- **Evidence anchors:** Section 3.4 mentions detaching gradients from the BRDF branch; section 4.5 ablation study shows detaching RGB for geometry parameters yields lower Chamfer distance.
- **Break condition:** If the clay translation is noisy, relying on it exclusively during the early phase could lock in geometric errors that the RGB branch cannot correct later.

## Foundational Learning

- **Concept: 2D Gaussian Splatting (2DGS)**
  - **Why needed here:** The method builds directly on 2DGS (flat disks) rather than 3D volumes. You must understand how 2D surfels represent geometry via normals and opacity to grasp how the "clay" branch attaches to them.
  - **Quick check question:** How does a 2D Gaussian differ from a 3D Gaussian in terms of surface representation and normal derivation?

- **Concept: Physically Based Rendering (PBR/BRDF)**
  - **Why needed here:** The "reflective branch" relies on splitting light into diffuse and specular components (GGX microfacet). Understanding this disentanglement is key to seeing why removing specular (via clay) helps geometry.
  - **Quick check question:** In the rendering equation, which component causes view-dependent "shininess" that the clay branch aims to remove?

- **Concept: Image-to-Image Translation (I2I)**
  - **Why needed here:** The method uses an external generative model (FLUX/OminiControl) as a pre-processor. You need to know that these models can perform style transfer (reflective → clay) without changing the structure (content preservation).
  - **Quick check question:** What is the risk of using a generative model for supervision in a reconstruction pipeline?

## Architecture Onboarding

- **Component map:** Input: Multi-view Reflective Images → Pre-processor: OminiControl (fine-tuned with LoRA) → Pseudo-Ground-Truth Clay Images → Core: Dual-Branch 2D Gaussian Splatting → Output: Reflective Render + Clay Render

- **Critical path:** The accuracy of the Image-to-Clay translation is the primary bottleneck. If the generated clay images distort the object's silhouette, the Chamfer distance will likely increase regardless of the Gaussian optimization.

- **Design tradeoffs:**
  - **Robustness vs. Fidelity:** The method trades pure photometric fidelity (standard NeRF) for geometric stability by introducing an auxiliary clay loss.
  - **Speed vs. Quality:** Requires running a heavy diffusion/editing model on the entire training set before 3D optimization begins.

- **Failure signatures:**
  - **Texture-Geometry Confusion:** If the I2I model fails to remove strong reflections, the "clay" geometry will still contain bumps from the lights.
  - **Content Hallucination:** As noted in the paper's limitations, the I2I model might "invent" geometry (e.g., filling a coffee cup) where none exists.

- **First 3 experiments:**
  1. **Translation Fidelity Test:** Run the Image-to-Clay model on a held-out validation set of reflective objects. Check if the clay output preserves the mask/silhouette of the original.
  2. **Ablation on Detachment:** Train with and without detaching the RGB loss for geometry parameters (Table 6) to verify the "geometry-first" hypothesis.
  3. **Schedule Sensitivity:** Vary the iteration count $T_{clay}$ (currently 10k) to see if terminating clay supervision too early degrades the surface smoothness.

## Open Questions the Paper Calls Out
None

## Limitations
- The primary bottleneck is the reliability of the image-to-clay translation model, which could introduce shape distortions or fill concavities
- The method assumes a single set of Gaussian parameters can satisfy both BRDF and clay rendering constraints, which may not hold for extreme reflective-to-diffuse transitions
- Heavy reliance on a pre-trained diffusion model makes the pipeline computationally expensive and less reproducible

## Confidence

- **High confidence**: The dual-branch architecture and gradient detachment strategy are well-supported by ablation results showing improved Chamfer distance and normal accuracy
- **Medium confidence**: The mechanism by which clay translation stabilizes geometry is theoretically sound but relies heavily on the quality of the external I2I model
- **Low confidence**: The claim that this approach generalizes to real-world scenes is weakly supported, as most experiments are on synthetic data with limited real-world validation

## Next Checks
1. **Translation Fidelity Test**: Validate that the image-to-clay model preserves object silhouettes and does not hallucinate geometry by comparing clay outputs to ground-truth masks on a held-out validation set.
2. **Ablation on Detachment**: Re-run experiments with and without detaching the RGB loss for geometry parameters to confirm the "geometry-first" curriculum improves convergence.
3. **Schedule Sensitivity**: Test varying the clay supervision iteration count ($T_{clay}$) to determine the optimal balance between early geometry stabilization and later BRDF refinement.