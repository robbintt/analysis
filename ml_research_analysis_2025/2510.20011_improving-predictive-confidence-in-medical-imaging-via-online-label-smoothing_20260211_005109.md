---
ver: rpa2
title: Improving Predictive Confidence in Medical Imaging via Online Label Smoothing
arxiv_id: '2510.20011'
source_url: https://arxiv.org/abs/2510.20011
tags:
- label
- smoothing
- training
- medical
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces Online Label Smoothing (OLS), a dynamic training
  method that updates class-wise soft labels based on the model's own prediction patterns
  during training, addressing the overconfidence and miscalibration issues common
  in deep learning models for medical imaging. OLS improves classification accuracy
  on the large-scale RadImageNet dataset by reducing both Top-1 and Top-5 errors across
  multiple architectures (ResNet-50, MobileNetV2, VGG-19) compared to standard training,
  label smoothing, and knowledge distillation methods.
---

# Improving Predictive Confidence in Medical Imaging via Online Label Smoothing

## Quick Facts
- arXiv ID: 2510.20011
- Source URL: https://arxiv.org/abs/2510.20011
- Reference count: 3
- Primary result: OLS reduces Top-1/Top-5 errors and ECE on RadImageNet across multiple architectures

## Executive Summary
This paper introduces Online Label Smoothing (OLS), a dynamic training method that updates class-wise soft labels based on the model's own prediction patterns during training. The approach addresses overconfidence and miscalibration issues common in deep learning models for medical imaging. By encoding empirical class relationships into soft labels rather than using uniform distributions, OLS improves classification accuracy and calibration on the large-scale RadImageNet dataset. The method demonstrates consistent performance improvements across multiple architectures including ResNet-50, MobileNetV2, and VGG-19.

## Method Summary
OLS maintains a soft label matrix S that evolves throughout training. For each epoch, the model accumulates predicted probability vectors from correctly classified samples per class, then normalizes these accumulations column-wise to produce updated soft label distributions. Training uses a hybrid loss combining hard cross-entropy (L_hard) and soft cross-entropy (L_soft) weighted by hyperparameter α. The method initializes with uniform soft labels in epoch 1, then iteratively updates S based on learned confusion patterns. This dynamic approach provides more informative supervision than static label smoothing by concentrating probability mass on empirically confusable classes rather than distributing uniformly.

## Key Results
- Reduces Top-1 and Top-5 classification errors across ResNet-50, MobileNetV2, and VGG-19 architectures on RadImageNet
- Achieves lower Expected Calibration Error (ECE) compared to standard training, label smoothing, and knowledge distillation methods
- Produces more compact and well-separated feature embeddings as shown through t-SNE visualization
- Improves calibration by matching confidence estimates to actual correctness more closely than uniform label smoothing

## Why This Works (Mechanism)

### Mechanism 1
OLS generates more informative supervision signals by encoding empirical class relationships into soft labels. During training, predicted probability vectors from correctly classified samples are accumulated per class, then normalized to produce class-wise soft label distributions. Classes the model frequently confuses with the true class receive higher soft-label weight. This creates supervision that reflects actual semantic or visual relationships between classes.

### Mechanism 2
OLS improves calibration by matching confidence estimates to actual correctness more closely than uniform label smoothing. While uniform label smoothing spreads probability mass equally across non-target classes, OLS concentrates soft-label mass on empirically confusable classes. This teaches the model to express calibrated uncertainty where ambiguity actually exists, reducing the gap between predicted confidence and empirical accuracy.

### Mechanism 3
OLS acts as a representation learning regularizer, producing more compact and better-separated feature embeddings. By providing class-aware soft targets that reflect confusable neighbors, OLS encourages the model to form tighter intra-class clusters while maintaining inter-class margins. The penultimate-layer representations become more discriminative, leading to better-structured latent spaces.

## Foundational Learning

- **Label Smoothing (Static)**: Why needed: OLS builds on standard label smoothing by replacing uniform non-target distributions with learned ones. Quick check: Can you explain why static label smoothing uses a uniform distribution over non-target classes and what limitation this creates?

- **Expected Calibration Error (ECE)**: Why needed: The paper's key calibration claim rests on ECE reductions. Quick check: What does an ECE of 0.0151 vs. 0.1537 mean in terms of confidence-accuracy alignment?

- **Hybrid Loss Formulation**: Why needed: OLS uses α·L_hard + (1−α)·L_soft. Understanding why hard labels remain necessary prevents implementation mistakes. Quick check: Why does training with only soft labels from random initialization cause convergence issues?

## Architecture Onboarding

- **Component map**: Soft Label Matrix S -> Accumulator -> Normalizer -> Hybrid Loss -> Backbone CNN
- **Critical path**: Initialize S^0 as uniform → train with hybrid loss using S^(t-1) → accumulate predictions from correct classifications → normalize accumulators → produce S^t → use S^t for next epoch → repeat
- **Design tradeoffs**: α (hard/soft balance): Higher α = more hard-label signal (stable but less adaptive); lower α = more soft-label signal (riskier early, potentially better calibrated later). Accumulation only on correct predictions: Filters noisy signals but may slow soft-label maturation for hard classes.
- **Failure signatures**: Soft labels remain near-uniform after several epochs → model may not be learning discriminative features; check learning rate and data quality. ECE does not improve or worsens → α may be too high (soft labels have insufficient influence) or too low (noisy supervision).
- **First 3 experiments**: 1) Baseline replication: Train ResNet-50 with hard labels only; 2) OLS vs. LS ablation: Compare static label smoothing vs. OLS with α=0.5; 3) α sensitivity sweep: Run OLS with α ∈ {0.3, 0.5, 0.7, 0.9} and plot ECE vs. α.

## Open Questions the Paper Calls Out
- Does integrating OLS with other calibration techniques into a hybrid strategy yield significantly better alignment with clinical requirements than OLS alone?
- Does OLS maintain its calibration and accuracy benefits when applied to multi-center datasets that introduce greater domain shift and data heterogeneity?
- Is OLS effective for 3D volumetric medical imaging tasks, or is its utility limited to the 2D slices used in the RadImageNet evaluation?
- How sensitive is the OLS method to the choice of the balancing hyperparameter α during the training process?

## Limitations
- Critical implementation details missing: exact α value, learning rate schedule, weight decay, and total training epochs
- Dataset split strategy not described, creating ambiguity about train/validation/test consistency
- Embedding quality claims supported only by qualitative t-SNE visualization without quantitative metrics
- Mechanism assumes model confusion patterns are stable and meaningful without validation across training stages

## Confidence
- **High confidence**: OLS reduces Top-1 and Top-5 errors compared to baseline and standard label smoothing
- **Medium confidence**: OLS achieves lower Expected Calibration Error through better-calibrated confidence estimates
- **Low confidence**: OLS produces "more compact and well-separated feature embeddings"

## Next Checks
1. **α sensitivity analysis**: Systematically vary α ∈ {0.3, 0.5, 0.7, 0.9} on a smaller RadImageNet subset and plot ECE vs. α to identify the stable operating range
2. **Cold-start validation**: Compare training curves when starting OLS from random initialization vs. pre-trained weights to confirm uniform initialization S₀ prevents convergence issues
3. **Soft label stability analysis**: Monitor the entropy of the soft label matrix S across training epochs to verify that class-wise distributions stabilize after initial warm-up