---
ver: rpa2
title: 'Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech
  Translation'
arxiv_id: '2511.21517'
source_url: https://arxiv.org/abs/2511.21517
tags:
- gender
- speech
- language
- bias
- pages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how speech translation (ST) models assign
  gender to speaker-referring terms when translating from English to Spanish, French,
  and Italian. Through training data analysis, internal language model (ILM) examination,
  and contrastive feature attribution on spectrograms, we reveal that models do not
  simply replicate term-specific gender patterns from training data, but learn broader
  masculine prevalence patterns.
---

# Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation

## Quick Facts
- arXiv ID: 2511.21517
- Source URL: https://arxiv.org/abs/2511.21517
- Reference count: 0
- This study reveals that speech translation models use first-person pronouns to access speaker gender information distributed across formant frequencies, rather than relying on pitch manipulation.

## Executive Summary
This study investigates how speech translation (ST) models assign gender to speaker-referring terms when translating from English to Spanish, French, and Italian. Through training data analysis, internal language model (ILM) examination, and contrastive feature attribution on spectrograms, we reveal that models do not simply replicate term-specific gender patterns from training data, but learn broader masculine prevalence patterns. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Our key finding is that models use first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch. This mechanism, analogous to coreference resolution in text-based machine translation, transforms semantically neutral "I" into a functionally gendered marker through acoustic gender cues encoded primarily in formant frequencies. These findings demonstrate that ST models leverage complex mechanisms distinct from prior assumptions, suggesting that mitigation strategies focused solely on pitch manipulation or training data rebalancing may prove insufficient.

## Method Summary
The study analyzes Transformer and Conformer encoder-decoder models trained on MuST-C for speech translation from English to Spanish, French, and Italian. Gender assignment for speaker-referring terms is examined using ILM analysis (zeroing encoder output), contrastive feature attribution on spectrograms, and word-level alignment via Gentle forced aligner. The analysis focuses on MuST-SHE benchmark data filtered for speaker-referential terms, measuring masculine preference ratios, flip rates through feature occlusion, and saliency distributions across frequency bands.

## Key Results
- ST models exhibit strong ILM masculine bias (0.74-0.81 preference) that can be overridden using acoustic input
- First-person pronouns serve as coreference anchors, with 16.9-35.1% of flipped examples showing highest saliency in these regions
- Gender information is distributed across formant frequencies (350-2,500 Hz) rather than concentrated in pitch (80-350 Hz)
- Models use complex mechanisms beyond simple training data replication for gender assignment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ST models can override internal language model (ILM) masculine bias using acoustic input.
- **Mechanism:** The decoder develops entrenched masculine-default preferences during training (ILM masculine preference: 0.74–0.81), but encoder-derived acoustic representations can shift predictions toward the correct gender when salient features are present.
- **Core assumption:** The encoder successfully extracts gender-relevant acoustic features and the cross-attention mechanism allows these to influence decoder token predictions.
- **Evidence anchors:**
  - [abstract] "While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input."
  - [Section 7] Table 2 shows the Transformer frequently predicts genders to which the ILM assigns lower probability, particularly for feminine predictions (145/197 feminine examples in Spanish where ILM preferred masculine).
  - [corpus] Weak direct corpus support; related work (Fucci et al. 2025) confirms different ST models encode gender differently but doesn't replicate the ILM override finding.
- **Break condition:** If encoder representations fail to capture gender-distinguishing features (e.g., low-quality audio, atypical vocal characteristics), the model defaults to ILM bias.

### Mechanism 2
- **Claim:** Models use first-person pronouns as a coreference mechanism to access speaker gender information.
- **Mechanism:** Self-referential words ("I", "I'm", "my") serve as temporal anchors in the spectrogram. The model attends to these time regions to extract acoustic gender cues, analogous to how text-based MT uses gendered pronouns ("she"/"he") for disambiguation—but here, the gender signal is acoustic rather than lexical.
- **Core assumption:** The semantically neutral "I" carries functionally gendered information through co-occurring acoustic properties (formants) that the model has learned to associate with speaker gender.
- **Evidence anchors:**
  - [abstract] "Models use first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum."
  - [Section 8.2] "I" is the top-scoring word in 16.9–25.8% of flipped examples; including self-referential expressions raises this to 23.7–35.1% for the Transformer.
  - [corpus] No direct corpus replication; coreference in MT is well-established (Wisniewski et al. 2022, Manna et al. 2025) but acoustic coreference is novel.
- **Break condition:** If first-person pronouns are absent or acoustically degraded, models may fail to link gendered target terms to speaker gender cues.

### Mechanism 3
- **Claim:** Gender information is encoded primarily in formant frequencies (F1, F2), not pitch (F0).
- **Mechanism:** Saliency analysis reveals the formant range (350–2,500 Hz) receives higher attribution scores than the pitch range (80–350 Hz). Formants vary by speaker anatomy and correlate with perceived gender, providing distributed gender cues across frequency bands.
- **Core assumption:** The model learns to extract speaker gender from formant patterns rather than relying on the perceptually salient pitch cue.
- **Evidence anchors:**
  - [Section 8.1] Figure 2 shows peaks in saliency at F1 and F2 frequencies, with feminine terms showing higher-frequency peaks than masculine terms.
  - [Section 8.1] 99.9% of flipped examples include pitch region features among occluded features, but formant regions show highest average scores—suggesting distributed rather than pitch-concentrated information.
  - [corpus] No corpus papers directly address formant vs. pitch; Fucci et al. (2023a) assumed pitch manipulation would help, which this paper challenges.
- **Break condition:** If mitigation strategies target only pitch manipulation, they will fail to remove gender information encoded in formants.

## Foundational Learning

- **Concept: Internal Language Model (ILM)**
  - Why needed here: The decoder develops language-model-like preferences independent of encoder input; understanding ILM bias is essential for diagnosing why models default to masculine forms.
  - Quick check question: If you zero out the encoder output, what gender preference does the decoder exhibit for the term "diventata" vs. "diventato"?

- **Concept: Contrastive Feature Attribution**
  - Why needed here: Standard attribution explains overall prediction; contrastive attribution identifies features that causally drive choosing one gendered form over its alternative.
  - Quick check question: When you mask the top 2% of salient features, does the gender prediction flip? If not, the attribution is not causally validated.

- **Concept: Coreference Resolution (MT context)**
  - Why needed here: The paper draws an analogy between text-based coreference (pronouns) and speech-based coreference (first-person words + acoustic cues); understanding the former illuminates the latter.
  - Quick check question: In "She is a doctor," which source word provides gender information for translating "doctor" to Spanish?

## Architecture Onboarding

- **Component map:** Encoder -> Cross-attention -> Decoder (with ILM)
- **Critical path:**
  1. Input audio → spectrogram → encoder
  2. Encoder output + previous tokens → cross-attention → decoder
  3. Decoder ILM bias vs. acoustic evidence → gender assignment decision
  4. First-person pronoun regions → formant feature extraction → gender signal

- **Design tradeoffs:**
  - Transformer encoder: Higher gender accuracy (77–80% feminine, 91–94% masculine) but stronger ILM bias
  - Conformer encoder: Weaker ILM bias but poorer acoustic cue utilization (39–50% feminine accuracy)
  - Multilingual vs. monolingual training: Affects generalization of gender assignment strategies

- **Failure signatures:**
  - Masculine default when speaker is feminine: ILM override failure; check encoder representation quality
  - No response to pitch manipulation: Expected—formants carry primary signal
  - High correlation between ILM and full model predictions: Model not leveraging acoustic input effectively

- **First 3 experiments:**
  1. **ILM bias quantification:** Zero out encoder output, compute masculine preference across all gender-ambiguous terms; compare to training data prevalence.
  2. **Temporal attribution analysis:** Apply contrastive feature attribution; identify whether first-person pronouns receive highest saliency scores for gender assignment.
  3. **Frequency band ablation:** Mask pitch range (80–350 Hz) vs. formant range (350–2,500 Hz) separately; measure impact on gender prediction flip rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do speech-enhanced Large Language Models (SpeechLLMs) rely on the same mechanism of using first-person pronouns to access gender information distributed across formant frequencies as the Transformer models analyzed?
- Basis in paper: [explicit] The authors state in the Limitations that their analysis does not extend to SpeechLLMs (e.g., AudioPaLM, SALMONN) and that future work should investigate whether the identified patterns generalize to this emerging paradigm.
- Why unresolved: SpeechLLMs utilize different architectures and massive, opaque training datasets, which may alter the internal representations and attention mechanisms used for acoustic gender disambiguation compared to supervised Transformer models.
- What evidence would resolve it: Applying the same contrastive feature attribution methods to SpeechLLMs to determine if saliency maps highlight the first formant (F1) and second formant (F2) frequencies during self-referential pronouns.

### Open Question 2
- Question: Does the reliance on formant frequencies and self-referential pronouns persist when translating from source languages with different gender marking strategies or non-gendered source languages?
- Basis in paper: [explicit] The authors acknowledge their analysis is restricted to English→Romance language pairs and suggest that future work should extend to typologically diverse language pairs to determine if the mechanism is general or language-specific.
- Why unresolved: The identified mechanism may be contingent on the specific interaction between English (notional gender) and Romance languages (grammatical gender); different source languages might force models to rely on different acoustic or syntactic features.
- What evidence would resolve it: Conducting the same interpretability analysis on diverse language pairs (e.g., Japanese→Spanish) and comparing the frequency distribution of saliency heatmaps and ILM overrides.

### Open Question 3
- Question: How can bias mitigation strategies be redesigned to effectively address gender assignment given that models utilize distributed frequency information rather than just pitch?
- Basis in paper: [inferred] The conclusion states that mitigation strategies focused solely on pitch manipulation (a common assumption) may prove insufficient because models access gender information primarily through formants distributed across the spectrum.
- Why unresolved: Current debiasing techniques often target pitch shifting or data rebalancing, but the paper reveals a more complex interaction between coreference resolution and formant frequencies that simple pitch manipulation ignores.
- What evidence would resolve it: Developing and testing new interventions that perturb or normalize formant frequencies (F1/F2) or specifically regularize the attention mechanism on first-person pronouns, then measuring the reduction in misgendering rates.

## Limitations

- The core mechanism of acoustic coreference via first-person pronouns lacks direct causal validation
- ILM bias quantification relies on approximation of zeroing encoder output
- Exact frequency bands driving individual predictions remain underspecified
- Study restricted to English→Romance language pairs

## Confidence

- **High Confidence**: Training data masculine prevalence, ILM masculine bias (0.74-0.81 preference), formant frequency range (350-2,500 Hz) showing higher saliency than pitch (80-350 Hz)
- **Medium Confidence**: Models can override ILM bias using acoustic input, first-person pronouns as coreference anchors, gender information distributed across frequency spectrum
- **Low Confidence**: Exact mechanism of how semantically neutral "I" becomes functionally gendered marker, specific formant frequencies driving individual predictions, robustness across diverse speaker populations

## Next Checks

1. **Causal Validation of Acoustic Coreference**: Mask first-person pronoun regions in the spectrogram and measure if gender predictions fail at higher rates than random masking.

2. **Individual Feature Attribution Analysis**: For 50 randomly selected flipped examples, identify the specific formant frequencies (F1, F2 bands) with highest attribution scores and compare to speaker ground truth gender.

3. **Cross-Speaker Generalization Test**: Evaluate model gender accuracy on held-out speakers not present in training data to determine if ILM bias and acoustic override mechanisms behave similarly.