---
ver: rpa2
title: '"Wait, did you mean the doctor?": Collecting a Dialogue Corpus for Topical
  Analysis'
arxiv_id: '2501.07947'
source_url: https://arxiv.org/abs/2501.07947
tags:
- topic
- dialogue
- topics
- participants
- conversation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study aimed to create a dialogue corpus for analyzing topical
  organization in conversation by developing a messaging tool that could manipulate
  message content during exchanges. The tool, built on Element/Matrix, allowed for
  controlled modifications of participants' messages while maintaining natural conversation
  flow.
---

# "Wait, did you mean the doctor?": Collecting a Dialogue Corpus for Topical Analysis

## Quick Facts
- arXiv ID: 2501.07947
- Source URL: https://arxiv.org/abs/2501.07947
- Reference count: 5
- The study developed a messaging tool for controlled message manipulation during conversations to study topical organization

## Executive Summary
This paper presents a methodology for creating a dialogue corpus to analyze topical organization in conversation through controlled message manipulation. The researchers developed a messaging tool using Element/Matrix that can modify message content during exchanges while maintaining natural conversation flow. A pilot study tested various manipulation techniques, finding that switching task-relevant words (e.g., "doctor" to "pilot") successfully forced participants to negotiate meaning and reach common understanding. The tool enables flexible message manipulation through bot-mediated chat rooms, with plans to collect approximately 60 conversations in multiple languages.

## Method Summary
The method involves building a messaging tool on Element/Matrix that manipulates message content during conversations. Each participant has a real account and an associated bot account, with messages routed through separate bot-mediated rooms for modification before relay. The tool was tested in a pilot study with 12 participants in 18 dyads using a balloon task moral dilemma. The most effective manipulation technique involved switching task-relevant terms to create divergent topic interpretations that required explicit negotiation. All conversation data is stored in SQLite databases for analysis.

## Key Results
- Semantic word substitution (e.g., "doctor" â†’ "pilot") successfully created divergent topic interpretations requiring negotiation
- Participants developed repair strategies when task-relevant words were switched
- Degrading utterances prompted circumvention strategies rather than negotiation
- 5 of 18 pilot pairs did not complete the task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bot-mediated room separation enables undetected message manipulation
- Mechanism: Each participant has a real account and associated bot account. Messages route through separate rooms where bots modify content before relay
- Core assumption: Participants won't suspect manipulation and will attribute discrepancies to partner error
- Evidence anchors: Bot receives messages in separate rooms for processing; sender believes messages were sent normally
- Break condition: Participants communicate outside the tool to verify messages

### Mechanism 2
- Claim: Task-relevant word substitution forces explicit topic negotiation
- Mechanism: Switching domain-specific terms creates divergent topic interpretations between speakers
- Core assumption: Participants are motivated to complete the task and will engage in repair behavior
- Evidence anchors: Word switching often required discussion about partner's meaning; confusion prompts observable negotiation
- Break condition: Participants develop circumvention strategies if substitutions are too frequent or obvious

### Mechanism 3
- Claim: Constrained tasks with moral stakes produce identifiable sub-topics
- Mechanism: Balloon task with moral dilemma generates sub-topics while remaining conversationally open
- Core assumption: Participants engage authentically rather than treating it as artificial
- Evidence anchors: Task enables easier identification of sub-topics than casual dialogue
- Break condition: Immediate agreement without discussion reduces topic diversity

## Foundational Learning

- Concept: Matrix protocol and Element client architecture
  - Why needed here: Entire tool depends on Matrix's federated, open protocol for self-hosted server control and bot integration
  - Quick check question: Can you explain how a Matrix homeserver routes messages to specific rooms?

- Concept: Topic vs. topic shift in conversation analysis
  - Why needed here: Research goal is to study topical organization; distinguishing current topic from topic transition is essential
  - Quick check question: What distinguishes gradual topic drift from abrupt topic shift with explicit markers?

- Concept: Repair mechanisms in dialogue
  - Why needed here: Word-substitution manipulation is designed to trigger repair sequences; understanding these patterns is necessary for data interpretation
  - Quick check question: When a speaker says "Wait, did you mean X?", what conversational function does this serve?

## Architecture Onboarding

- Component map:
  - Matrix homeserver (self-hosted) -> Element clients -> Python orchestration scripts -> Bot accounts -> SQLite database
  - Each participant has real account + bot account with separate chat rooms

- Critical path:
  1. Deploy Matrix homeserver
  2. Create participant accounts + bot accounts
  3. Generate rooms (real+bot pairs)
  4. Start Python monitoring scripts
  5. Participants join via Element
  6. Scripts intercept, modify, relay messages
  7. Store to SQLite

- Design tradeoffs:
  - Separate bot rooms vs. in-line modification: Chosen approach hides manipulation from sender but doubles room count
  - Real-time vs. post-hoc editing: Real-time enables natural response but requires low-latency execution
  - Degrading vs. semantic substitution: Pilot showed degradation prompts circumvention; semantic substitution prompts negotiation

- Failure signatures:
  - Message not relayed: Bot account offline or script crashed
  - Modification detected: Participants mention "wrong words" or start spelling words unusually
  - Task abandonment: 5 of 18 pilot pairs did not complete

- First 3 experiments:
  1. Replicate pilot with naive participants to validate negotiation behavior persists without experimenter bias
  2. Vary substitution frequency to identify threshold where participants switch from negotiation to circumvention
  3. Compare monolingual vs. multilingual conditions to test whether negotiation strategies generalize across languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What strategies do participants develop to reach common understanding when message modifications create divergent topic interpretations between speakers?
- Basis in paper: Authors want to "see what strategies the participants develop to reach a common understanding" when task-related words are switched
- Why unresolved: Pilot focused on feasibility testing, not systematic strategy analysis
- What evidence would resolve it: Analysis of conversation transcripts from planned 60-participant corpus, coding for repair mechanisms and negotiation strategies

### Open Question 2
- Question: How do participants reraise past topics and manage multiple topics within short conversation spans?
- Basis in paper: Authors intend to "collect dialogues where participants are encouraged to reraise past topics or must cover several topics in a short time"
- Why unresolved: Balloon task focuses on single-topic deliberation; no data exists on multi-topic scenarios
- What evidence would resolve it: Corpus collection using new task designs requiring topic switching, followed by annotation of topic return markers

### Open Question 3
- Question: How does written messaging-mediated dialogue compare to face-to-face conversation in terms of topical organization and topic shift mechanisms?
- Basis in paper: Acknowledges oral face-to-face exchange is most complete form but chose written messaging for practical reasons
- Why unresolved: No comparative data collected; corpus is entirely text-based messaging
- What evidence would resolve it: Parallel data collection using identical tasks in both modalities with comparative topical annotation

### Open Question 4
- Question: How do multi-party conversations differ from dyadic ones in topic negotiation and agreement processes?
- Basis in paper: Authors plan to "extend this experiment to include Swedish data and multi-party conversations"
- Why unresolved: Current pilot and planned initial corpus are limited to dyadic exchanges
- What evidence would resolve it: Collection and analysis of three-plus participant conversations using same modification paradigm

## Limitations

- The manipulation mechanism relies entirely on participants not discovering the modification, with no validation data on detection rates
- The pilot only tested one specific task and four manipulation types, leaving unknown whether results generalize to other domains
- The assumption that semantic word substitution creates genuine divergent topic interpretations versus surface-level confusion remains untested
- Cross-linguistic extension introduces unknown variables in how word substitution effects might vary across languages

## Confidence

- High confidence: Matrix-based architecture is technically sound and separate-room manipulation mechanism is well-specified and reproducible
- Medium confidence: Assumption that task-relevant word substitution creates genuine divergent topic interpretations is plausible but not directly validated
- Low confidence: Claims about behavior in longer conversations or across multiple languages cannot be validated from current pilot data

## Next Checks

1. Conduct detection-rate validation with 20-30 participants across varying manipulation frequencies (0%, 25%, 50%, 75%) to empirically measure when participants begin suspecting manipulation versus engaging in repair behavior

2. Perform linguistic analysis on pilot data comparing semantic substitution conditions to control conditions, coding whether "topic negotiation" sequences actually reflect different topic interpretations or merely lexical confusion

3. Run parallel pilot tests of the balloon task in all three target languages with native speakers to identify whether word substitution effects and negotiation patterns transfer across languages or require language-specific adaptation