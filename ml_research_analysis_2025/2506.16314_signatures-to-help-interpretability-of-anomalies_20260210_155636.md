---
ver: rpa2
title: Signatures to help interpretability of anomalies
arxiv_id: '2506.16314'
source_url: https://arxiv.org/abs/2506.16314
tags:
- anomaly
- signatures
- data
- anomalies
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces "anomaly signatures" to improve interpretability
  of isolation forest anomaly detection results. The authors propose a feature importance
  metric that links the isolation forest score to specific features contributing to
  the anomaly decision.
---

# Signatures to help interpretability of anomalies

## Quick Facts
- arXiv ID: 2506.16314
- Source URL: https://arxiv.org/abs/2506.16314
- Reference count: 8
- The paper introduces "anomaly signatures" to improve interpretability of isolation forest anomaly detection results.

## Executive Summary
This paper addresses the interpretability challenge in isolation forest anomaly detection by proposing a feature importance metric called "signatures." The method attributes the isolation forest's anomaly score to specific features contributing to the decision, enabling visualization of which features drive anomaly detection. Applied to SNfactory supernova spectra data, signatures enable clustering of anomalies to distinguish noise-driven from scientifically interesting anomalies, achieving a 6x speedup in expert review by reducing the number of spectra requiring manual inspection from 232 to 39.

## Method Summary
The method extends isolation forest by computing per-sample feature signatures that capture how individual features contribute to anomaly scores. During tree traversal, the method tracks depth changes at each split and attributes these to the feature used, producing a signature vector for each sample. The signatures are averaged across all trees and samples to quantify feature importance for anomaly detection. For triage, the method clusters signatures of top anomalies using K-means to separate noise-dominated anomalies from novel ones, enabling experts to focus review on the most promising candidates.

## Key Results
- Signatures enable visualization of which spectral features drive anomaly scores in supernova spectra
- Clustering signatures separates noise-driven anomalies from scientifically interesting ones, enabling targeted expert review
- The approach achieved a 6x speedup in finding new anomalies by reducing expert review from 232 to 39 spectra
- Code is available in the Coniferest package for reproducibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Signatures decompose the isolation forest anomaly score into per-feature contributions by attributing depth changes to the features used at each split.
- Mechanism: At each tree traversal, when a sample reaches a node split on feature f, the signature element δS captures how that split changes the expected depth. Features that rapidly isolate a sample (creating large child-parent population ratios) yield negative signatures, indicating strong contribution to anomaly status. The final signature S_f* averages these δS values across all trees where feature f* was selected.
- Core assumption: The relationship between split depth and anomaly detection can be meaningfully attributed to individual features via their selection frequency and resulting cell populations.
- Evidence anchors:
  - [abstract] "The authors propose a feature importance metric that links the isolation forest score to specific features contributing to the anomaly decision."
  - [section 3] "Features responsible for separating outliers will have n_dk_t << n_(d-1)k_t, which will result in a negative signature S_f, while positive signatures will pinpoint features that are ineffective in detecting i as an outlier."
  - [corpus] Weak direct corpus support; related papers address explainability in other domains but not this specific depth-attribution mechanism.
- Break condition: If features interact non-linearly such that no single feature consistently isolates anomalies across trees, signatures may show weak or contradictory signals.

### Mechanism 2
- Claim: Clustering anomaly signatures separates noise-driven anomalies from scientifically interesting ones, enabling targeted expert review.
- Mechanism: Anomalies caused by different underlying mechanisms (e.g., instrumental noise vs. astrophysical phenomena) produce distinct signature patterns across features. K-means clustering on signature vectors groups anomalies by their characteristic feature contributions, allowing experts to focus on clusters with signatures indicating non-noise origins.
- Core assumption: Anomaly types are distinguishable by their signature patterns; noise artifacts produce signatures that cluster separately from meaningful anomalies.
- Evidence anchors:
  - [section 4.2] "Figure 3 shows that the average signature is significantly different from the noise signature for only 1 out of 5 clusters. The expert then only has to scan 39 spectra out of 232 to find new anomalies, speeding-up anomaly discovery rate by a factor 6."
  - [section 4.1] "While human may spot immediately that the outlier has a high noise level, the signature shows that the decision to label it as an outlier is made on the variance spectrum, rather than on the noisy data themselves."
  - [corpus] The financial anomaly detection neighbor paper mentions heterogeneous anomaly mechanisms requiring different explanations, aligning conceptually but without direct evidence for this method.
- Break condition: If signature distributions for different anomaly types overlap substantially, clustering will not cleanly separate them.

### Mechanism 3
- Claim: Signature visualization reveals which spectral regions or uncertainty channels drive anomaly scores, enabling domain interpretation without manual spectral analysis.
- Mechanism: By plotting signatures alongside original data (flux and error spectra), practitioners can immediately identify which wavelength bins or uncertainty features contributed to the anomaly designation, focusing attention on physically relevant regions.
- Core assumption: Feature-level attribution maps meaningfully to domain-relevant interpretation; the 578 spectral bins preserve interpretable physical structure.
- Evidence anchors:
  - [section 4.1] "Figures 1 and 2 present the data and the signatures for the most outlier and the most nominal event in the sample."
  - [section 4.1] "For the nominal spectrum, one may see that the signatures are positive, indicating that no feature is isolating this event as anomalous."
  - [corpus] The energy consumption anomaly explanation paper similarly emphasizes focusing on contextually relevant data for interpretability, supporting the general approach.
- Break condition: If important anomalies arise from distributed patterns across many features with small individual contributions, visualization may not highlight the relevant structure.

## Foundational Learning

- Concept: Isolation Forest fundamentals (random feature splits, path length as anomaly score, ensemble averaging)
  - Why needed here: Signatures directly extend the depth-based scoring mechanism; understanding how IF isolates anomalies via random splits is prerequisite to attributing those splits to features.
  - Quick check question: Can you explain why shorter average path lengths indicate higher anomaly scores in isolation forests?

- Concept: Feature importance vs. feature attribution (global vs. local explanations)
  - Why needed here: Signatures provide per-sample feature attribution, distinct from global importance; understanding this distinction prevents misinterpreting signatures as dataset-wide rankings.
  - Quick check question: What is the difference between SHAP values and permutation feature importance, and which category do signatures fall into?

- Concept: Clustering high-dimensional vectors (K-means on signature space)
  - Why needed here: The 6x speedup relies on clustering signatures to triage anomalies; understanding clustering assumptions (e.g., Euclidean distance appropriateness, cluster count selection) is necessary for applying this to new datasets.
  - Quick check question: What could go wrong if you apply K-means clustering to signatures without first normalizing or checking for dimensionality issues?

## Architecture Onboarding

- Component map:
  - Input layer: Tabular data (n_samples × n_features); SNfactory uses 2485 × 578 (flux + uncertainty per spectral bin)
  - Isolation Forest: Trained with n=1024 samples per tree, T=3000 trees, max_depth satisfying n=2^max_depth
  - Signature computation: Per-sample traversal of all trees, accumulating δS per feature via Eq. 3-5
  - Output layer: Per-sample anomaly score + per-sample signature vector (same dimensionality as input features)
  - Downstream: Visualization (signature plots), clustering (K-means on top-k% anomalies), triage

- Critical path:
  1. Data preprocessing: Normalize spectra (integral = 1 in this case)
  2. Train isolation forest: Set n and max_depth such that n = 2^max_depth (critical constraint per paper)
  3. Compute signatures for all samples during or after scoring
  4. For triage: Extract top-k% anomalies, cluster their signatures, identify clusters with non-noise signatures
  5. Expert reviews prioritized cluster only

- Design tradeoffs:
  - Tree count (T=3000): Higher T improves signature stability via more averaging but increases computation; paper does not provide sensitivity analysis
  - Sample size per tree (n=1024): Controls max_depth; larger n captures more complex structure but requires deeper trees
  - K for clustering: Paper uses K=5 empirically; no guidance on optimal selection
  - Threshold for "top anomalies": Paper uses 10%; domain-dependent

- Failure signatures:
  - All signatures near zero: Model not isolating samples effectively (check if data is normalized, if n is appropriate for dataset size)
  - Signatures identical across all features: Possible bug in feature indexing during tree traversal
  - Clustering produces one dominant cluster: May indicate most anomalies share same cause (often noise); consider pre-filtering or adjusting k
  - Positive signatures for known anomalies: Inversion somewhere in scoring or signature computation

- First 3 experiments:
  1. Reproduce on SNfactory data using Coniferest package to validate signature computation matches paper figures (especially Fig. 1-3 patterns).
  2. Ablation on tree count: Train forests with T∈{100, 500, 1000, 3000} and measure signature stability (variance across runs) to determine minimum viable T for your data scale.
  3. Apply to a different tabular dataset with known anomaly labels to validate whether signature clustering correlates with ground-truth anomaly types (not just noise vs. signal).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the "Signature" metric compare in performance and accuracy to existing depth-based feature importance methods, such as DIFFI, on benchmark datasets?
- Basis in paper: [inferred] The paper references the DIFFI method [3] as a related approach using depth for feature importance but proposes a "simpler quantity" without providing a direct experimental comparison of the two metrics.
- Why unresolved: The authors differentiate their method by claiming simplicity and a direct link to the score, but they do not quantify if this simplification results in loss of feature ranking accuracy compared to DIFFI.
- What evidence would resolve it: A benchmark study comparing feature ranking fidelity and computational cost of Signatures versus DIFFI on the same labeled anomaly datasets.

### Open Question 2
- Question: Can signature-based similarity search effectively identify cohorts of novel anomalies without relying on prior clustering?
- Basis in paper: [explicit] The authors state in the conclusion that "Finding similar outliers once one is selected is another possible use of signatures," listing it as a distinct application from the clustering approach demonstrated in the text.
- Why unresolved: While the paper demonstrates clustering the signatures to find anomaly types, it does not explicitly test or validate the proposed use case of querying for similar outliers directly based on signature distance.
- What evidence would resolve it: An experiment where a known anomaly is selected as a query, and the top-K nearest signatures are retrieved to verify if they belong to the same physical or anomaly class.

### Open Question 3
- Question: To what extent does the effectiveness of anomaly signatures generalize to non-astronomical, high-dimensional tabular datasets?
- Basis in paper: [explicit] The conclusion claims, "The use of Signatures is not restricted to astronomical use cases, and can be employed for all tabular data," despite the method being benchmarked exclusively on the SNfactory supernova dataset.
- Why unresolved: The empirical validation is confined to a specific astrophysical domain (spectrophotometric data with 578 dimensions), leaving the generalizability to other domains (e.g., finance, cybersecurity) unproven.
- What evidence would resolve it: Application of the Signature metric to standard open-source anomaly detection benchmarks (e.g., KDD Cup, Cardiotocography) to verify interpretability gains.

### Open Question 4
- Question: How robust are the computed signatures to variations in Isolation Forest hyperparameters, specifically the number of trees and subsampling size?
- Basis in paper: [inferred] The experiment utilizes a fixed configuration ($n=1024$ samples, $T=3000$ trees), but the sensitivity of the feature importance "signature" to these specific hyperparameters is not analyzed.
- Why unresolved: Feature importance metrics in tree ensembles can vary significantly with ensemble size and depth; without sensitivity analysis, it is unclear if the signature is stable across different model configurations.
- What evidence would resolve it: A sensitivity analysis showing the variation in signature values (e.g., standard deviation) as $T$ and $n$ are perturbed around the baseline values.

## Limitations
- The approach is validated only on astronomical data and its generalizability to other domains remains unproven
- The paper does not characterize the stability of signatures across different isolation forest hyperparameters
- The clustering-based triage assumes anomaly types are separable by their signature patterns, which may not hold for complex distributed anomalies

## Confidence
- Confidence: Medium for the core signature attribution mechanism, as the theoretical derivation is sound but empirical validation is limited to a single domain-specific dataset
- Confidence: Low for the clustering-based triage approach, as the paper does not validate whether signature clusters correspond to scientifically meaningful anomaly types beyond noise vs. non-noise separation

## Next Checks
1. Reproduce signature computation on a controlled synthetic dataset with known anomaly mechanisms to verify attribution accuracy
2. Perform ablation studies on forest parameters (tree count, sample size) to identify stability thresholds
3. Apply the method to a different domain (e.g., tabular business data) with ground-truth anomaly labels to validate generalizability of the clustering-triage workflow