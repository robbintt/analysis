---
ver: rpa2
title: Discrete Contrastive Learning for Diffusion Policies in Autonomous Driving
arxiv_id: '2503.05229'
source_url: https://arxiv.org/abs/2503.05229
tags:
- driving
- learning
- diffusion
- human
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DSDP (Discrete Style Diffusion Policy), a novel
  approach to modeling human driving behavior in autonomous vehicle testing. The method
  uses contrastive learning with InfoNCE loss and Lookup-Free Quantization (LFQ) to
  extract discrete driving styles from unlabeled human driving data, then trains a
  conditional diffusion policy to generate actions conditioned on both observations
  and driving styles.
---

# Discrete Contrastive Learning for Diffusion Policies in Autonomous Driving

## Quick Facts
- arXiv ID: 2503.05229
- Source URL: https://arxiv.org/abs/2503.05229
- Reference count: 40
- Primary result: DSDP achieves 4.0% crash rate and 0.404 F1 score on NGSIM, outperforming diffusion policy baselines

## Executive Summary
This paper introduces DSDP (Discrete Style Diffusion Policy), a method for modeling human driving behavior in autonomous vehicles using contrastive learning to extract discrete driving styles from unlabeled trajectory data. The approach combines InfoNCE loss with Lookup-Free Quantization (LFQ) to learn a dictionary of driving styles, then trains a conditional diffusion policy to generate actions conditioned on both observations and extracted styles. The method is evaluated on the NGSIM dataset, demonstrating significantly lower crash rates and higher F1 scores compared to baseline approaches including standard diffusion policies and K-Means clustering.

## Method Summary
DSDP operates in three stages: first, a contrastive pre-training phase extracts discrete driving styles from trajectory data using InfoNCE loss and LFQ, producing a codebook of 256 style vectors; second, a prior network predicts style indices from trajectory history; third, a conditional DDPM diffusion policy generates vehicle actions conditioned on both observations and predicted styles. The approach is evaluated on car-following scenarios from the NGSIM dataset, with preprocessing including normalization, feature augmentation, outlier removal, and Savitzky-Golay smoothing. The method achieves lower crash percentages and higher trajectory similarity scores compared to baselines by explicitly modeling driving style heterogeneity.

## Key Results
- Achieves 4.0% crash rate on NGSIM test set, significantly lower than diffusion policy baselines
- Attains 0.404 F1 score (density × coverage harmonic mean) versus ground truth trajectories
- Demonstrates particular robustness in US 101 and I-80 environments where it outperforms other learning-based methods

## Why This Works (Mechanism)
The method succeeds by explicitly modeling the heterogeneity in human driving behavior through discrete style extraction. By using contrastive learning with InfoNCE loss, the model learns to distinguish between trajectories from the same driving scenario (positive pairs) versus different scenarios (negative pairs), effectively clustering similar behaviors. The LFQ quantization ensures the learned styles form a discrete codebook that can be efficiently used for conditioning the diffusion policy. This explicit style conditioning allows the diffusion model to generate more diverse and human-like behaviors compared to directly learning from raw trajectories, addressing the limitations of standard diffusion policies that struggle with multi-modal behavior distributions.

## Foundational Learning
- **InfoNCE loss**: Contrastive objective that maximizes similarity between positive pairs while minimizing similarity between negative pairs; needed to learn discriminative style representations without labels; quick check: monitor InfoNCE loss convergence during pre-training
- **Lookup-Free Quantization (LFQ)**: Vector quantization method that updates codebook entries during training without requiring a separate lookup step; needed to maintain differentiable quantization for end-to-end learning; quick check: verify codebook utilization entropy is high (styles are used)
- **Diffusion probabilistic models (DDPM)**: Generative models that denoise random noise into samples through a Markov chain; needed to model complex action distributions conditioned on observations and styles; quick check: verify training loss decreases monotonically over epochs
- **Contrastive representation learning**: Learning embeddings where similar samples are close and dissimilar samples are far; needed to extract meaningful driving style features from unlabeled trajectories; quick check: visualize style embeddings using t-SNE to confirm clustering
- **Behavior cloning**: Learning to imitate expert demonstrations by supervised learning; needed as the fundamental framework for autonomous driving policy learning; quick check: monitor training loss and validation performance on held-out expert data
- **Trajectory forecasting metrics**: F1 score combining density and coverage measures; needed to evaluate how well generated trajectories match ground truth distributions; quick check: calculate F1 score on validation set during development

## Architecture Onboarding
- **Component map**: NGSIM trajectories → Preprocessing → Contrastive Encoder → Style Codebook (256 styles) → Prior Network → Style Index → DDPM Policy → Actions → Highway-Env Simulator → Crash Rate/F1
- **Critical path**: Contrastive pre-training → Prior training → Conditional DDPM training → Evaluation in simulation
- **Design tradeoffs**: Discrete styles vs continuous style embeddings (discrete enables efficient conditioning but may lose nuance); DDPM vs faster generative models (DDPM quality vs inference speed); full trajectory vs sub-trajectory contrastive pairs (computational efficiency vs context)
- **Failure signatures**: Style collapse (few codebook entries used) → remedy: increase entropy penalty or adjust InfoNCE temperature; High crash rates despite low training loss → remedy: verify prior accuracy and style-action alignment; Unstable contrastive training → remedy: reduce learning rate or increase target network momentum
- **First experiments**: 1) Train contrastive model and visualize style codebook utilization to check for collapse; 2) Train prior network alone and measure style prediction accuracy on validation set; 3) Train DDPM without style conditioning as ablation baseline to measure impact of style modeling

## Open Questions the Paper Calls Out
- **Visual data scaling**: Can DSDP be effectively scaled to learn driving styles directly from high-dimensional visual data rather than low-dimensional state vectors? The authors identify this as a way to better mimic human perception, but visual data introduces complexity regarding invariance and feature extraction that may disrupt the current contrastive learning mechanism.
- **Mixed-traffic generalization**: Can the method generalize to complex, mixed-traffic interactions involving pedestrians and cyclists without manual feature engineering? The current evaluation is restricted to car-following, and pedestrians/cyclists exhibit distinct behaviors that may not be captured by the current style dictionary.
- **Alternative generative backbones**: Can Consistency Models be integrated into DSDP to achieve real-time inference speeds without sacrificing behavior quality? The current DDPM requires many denoising steps, and it's unclear if discrete style conditioning is compatible with single-step generation processes.

## Limitations
- The MLP sieve architecture for the diffusion policy has underspecified details including skip connection placement and embedding dimensions
- The LFQ entropy penalty coefficient is unspecified, which could significantly affect codebook utilization
- The Savitzky-Golay smoothing parameters (window length and polynomial order) are not provided, potentially affecting trajectory quality

## Confidence
- **High confidence**: Overall methodology and evaluation results showing DSDP's superiority over baselines (lower crash rates, higher F1 scores)
- **Medium confidence**: Contrastive learning pre-training procedure with InfoNCE loss and LFQ is clearly specified
- **Low confidence**: Exact MLP sieve architecture and diffusion denoising parameters are underspecified

## Next Checks
1. Implement a grid search over MLP sieve architectures (varying layer counts, skip connection patterns, and embedding dimensions) to identify configurations achieving similar performance, monitoring training stability and downstream evaluation metrics
2. Systematically test different Savitzky-Golay smoothing parameters (window lengths 5-25, polynomial orders 2-4) to assess impact on trajectory smoothness and downstream style extraction quality, measuring changes in codebook utilization entropy
3. Conduct ablation studies removing the style conditioning from the diffusion policy while keeping all other components identical, to verify that the 4.0% crash rate improvement specifically stems from explicit style modeling rather than other implementation differences