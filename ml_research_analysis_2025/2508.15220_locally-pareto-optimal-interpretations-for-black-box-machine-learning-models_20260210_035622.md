---
ver: rpa2
title: Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models
arxiv_id: '2508.15220'
source_url: https://arxiv.org/abs/2508.15220
tags:
- decision
- interpretations
- names
- trees
- tree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a scalable method for synthesizing locally
  Pareto-optimal interpretations of black-box machine learning models, balancing accuracy
  and explainability. The approach uses Multi-Objective Monte Carlo Tree Search (MO-MCTS)
  to generate candidate interpretations, followed by SAT-based verification to ensure
  local Pareto-optimality within user-defined slack parameters.
---

# Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models

## Quick Facts
- arXiv ID: 2508.15220
- Source URL: https://arxiv.org/abs/2508.15220
- Authors: Aniruddha Joshi; Supratik Chakraborty; S Akshay; Shetal Shah; Hazem Torfah; Sanjit Seshia
- Reference count: 40
- One-line primary result: Scalable synthesis of locally Pareto-optimal decision tree interpretations for black-box models using MO-MCTS + SAT verification

## Executive Summary
This paper introduces a method for synthesizing locally Pareto-optimal interpretations of black-box machine learning models by balancing accuracy and explainability. The approach uses Multi-Objective Monte Carlo Tree Search (MO-MCTS) to generate candidate interpretations, followed by SAT-based verification to ensure local Pareto-optimality within user-defined slack parameters. Experiments on 20 benchmarks show that this method produces interpretations close to globally Pareto-optimal solutions and outperforms previous methods in scalability, successfully generating interpretations where earlier approaches fail. The method offers anytime guarantees, allowing useful solutions at any execution point.

## Method Summary
The method employs a two-phase hybrid approach: (1) MO-MCTS search for candidate decision trees using hypervolume-based UCB selection, and (2) SAT verification with Kissat solver checking local Pareto-optimality within slacks δc and δe. The system converts black-box models (4-layer MLPs with 7 neurons each) and datasets into decision trees with bounded node budgets, optimizing for both correctness (classification accuracy) and explainability (tree size and feature weights). SAT encodings incorporate tree syntax constraints, correctness bounds, explainability bounds, and Pareto-dominance conditions.

## Key Results
- Successfully generated interpretations on 20 benchmarks where previous methods failed to scale
- Produced solutions close to globally Pareto-optimal frontiers
- Demonstrated anytime guarantees with valid solutions at any execution point
- Showed improved scalability through the hybrid search-and-verify architecture

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Search-and-Verify Loop
- If a candidate solution is near-optimal but not locally perfect, a formal verifier can refine it or confirm its local optimality, provided the search phase provides adequate coverage
- The system decouples the "search" for candidates from the "proof" of optimality, using MO-MCTS to sample the interpretation space and SAT to verify or refine candidates
- Core assumption: MO-MCTS can find candidates "close enough" to the true optimal frontier for the SAT solver to efficiently patch or verify them
- Break condition: If MO-MCTS search space is too sparse or slack parameters are too small, SAT solver may struggle to find improvements

### Mechanism 2: Local Optimality Relaxation
- If global Pareto-optimality is computationally intractable, enforcing local optimality within a neighborhood provides a scalable approximation while retaining formal guarantees
- Instead of requiring no other interpretation in the entire universe dominates the candidate, the system requires no interpretation exists within a specific window of accuracy and explainability that dominates the candidate
- Core assumption: Users find value in solutions that cannot be easily improved upon locally, even if theoretically better solutions exist far away
- Break condition: If slack values are larger than the actual variation in the local neighborhood, the guarantee becomes trivial

### Mechanism 3: Anytime Monotonic Convergence
- If the algorithm is interrupted at any point, the current set of verified solutions remains valid because the process refines candidates monotonically
- The algorithm maintains a set of candidates, and verification only ever replaces a candidate with a strictly better one or moves it to the confirmed set
- Core assumption: A partial set of high-quality interpretations is useful to the user
- Break condition: Stopping extremely early might result in an empty or trivial set if the search hasn't had time to explore complex structures

## Foundational Learning

- **Concept**: Pareto Optimality
  - Why needed: Core objective requires understanding that we optimize two conflicting goals (Accuracy vs. Explainability) where a solution is optimal if you cannot improve one metric without hurting the other
  - Quick check: If Interpretation A has 90% accuracy and Interpretation B has 80% accuracy, is A guaranteed to be Pareto-optimal?

- **Concept**: Monte Carlo Tree Search (MCTS)
  - Why needed: Drives exploration of possible decision tree space, balancing exploring new tree structures vs. exploiting known high-reward branches
  - Quick check: How does the "Upper Confidence Bound" heuristic in MCTS prevent the search from getting stuck in a local optimum of tree structures?

- **Concept**: Boolean Satisfiability (SAT) Encodings
  - Why needed: Verification phase translates "Is there a better tree nearby?" into a Boolean logic formula
  - Quick check: In a SAT encoding for a decision tree, what might a boolean variable X_{i,j} represent regarding the structure of the tree?

## Architecture Onboarding

- **Component map**: Input -> MO-MCTS Engine -> SAT Encoder -> SAT Solver -> Output Manager
- **Critical path**: The verification loop is the bottleneck, depending on how quickly the SAT Solver can check the neighborhood of candidates produced by MO-MCTS
- **Design tradeoffs**:
  - Slack Tuning: Tighter slacks yield solutions closer to global optimal but make SAT verification harder; looser slacks make verification easier but solutions further from true frontier
  - Node Budget: Larger budgets allow more accurate trees but exponentially increase search space for both MCTS and SAT
  - Timeout Allocation: Increasing search time improves candidate quality; increasing total time allows more verification refinement
- **Failure signatures**:
  - Trivial Solutions: Output consists only of single-node trees (diagnosis: slacks too loose or MCTS failed to explore complex trees)
  - Timeout with No Output: (diagnosis: slacks too tight for solver or budget too large)
  - Inconsistent Pareto Front: Large gaps in accuracy-explainability curve (diagnosis: MCTS sampling is sparse)
- **First 3 experiments**:
  1. Baseline Validation: Run ALPO on small benchmark with large timeout, compare against global Pareto front from Synplicate
  2. Slack Sensitivity Analysis: Run ALPO on mid-sized benchmark while varying δc, plot relationship between slack size and SAT verification time
  3. Scalability Test: Run ALPO on Yeast benchmark where Synplicate fails, measure LPO interpretations found within fixed time budget

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the solutions generated by the SAT solver in the verification phase be integrated back into the MCTS search to improve heuristic guidance?
  - Basis: Conclusion states it would be interesting to use SAT solutions to improve search
  - Why unresolved: Current framework operates in two distinct sequential phases without feedback
  - What evidence would resolve it: Modified algorithm where SAT outputs update MO-MCTS heuristic, demonstrating improved convergence speed

- **Open Question 2**: Does the method scale effectively to more expressive interpretation classes, such as decision diagrams, rather than just decision trees?
  - Basis: Section 3.1 restricts to decision trees, noting they are essentially decision diagrams with additional restrictions
  - Why unresolved: SAT encoding explicitly constrains nodes to have at most one incoming edge; unclear if performance degrades significantly if this restriction is lifted
  - What evidence would resolve it: Implementation of SAT encoding for decision diagrams and comparison of synthesis time against decision tree benchmarks

- **Open Question 3**: Is the 50/50 static split of the time budget between search and verification phases optimal for maximizing interpretation quality?
  - Basis: Section 5 sets timeout ratio but doesn't justify this specific value
  - Why unresolved: Algorithm relies on user-defined timeout; poor balance could result in excellent search set with insufficient verification time or vice versa
  - What evidence would resolve it: Ablation study varying search-to-verification time ratio on benchmarks to identify optimal dynamic allocation strategy

## Limitations
- Scalability claims rely heavily on MO-MCTS and SAT solver interaction efficiency, not fully characterized for large problem sizes
- Slack parameters (δc, δe) are user-defined without clear optimal tuning guidance
- Experimental results based on relatively small neural networks and limited node budgets (≤6), leaving questions about performance on larger, more complex models

## Confidence

- **High**: Core hybrid architecture (MO-MCTS + SAT verification) is well-defined and mechanistically sound; anytime guarantee property is formally proven
- **Medium**: Scalability improvements over previous methods are demonstrated but limited to specific experimental setup; relationship between slack parameters and solution quality is theoretically justified but not empirically mapped out
- **Low**: Practical utility of "locally Pareto-optimal" solutions compared to globally optimal ones in real-world applications is not addressed

## Next Checks

1. **Scalability Boundary Test**: Systematically evaluate ALPO on progressively larger node budgets (B=5,10,15,20) on mid-sized benchmarks to identify where SAT verification becomes prohibitive

2. **Slack Sensitivity Analysis**: Conduct controlled experiment varying δc and δe independently on a fixed benchmark to quantify tradeoff between solution quality and computational cost

3. **Real-World Model Test**: Apply ALPO to interpret a deeper, more complex black-box model (e.g., 8+ layers, 20+ neurons) on a standard dataset to assess performance beyond paper's experimental constraints