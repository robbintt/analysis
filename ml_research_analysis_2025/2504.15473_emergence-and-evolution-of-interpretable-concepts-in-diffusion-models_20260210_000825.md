---
ver: rpa2
title: Emergence and Evolution of Interpretable Concepts in Diffusion Models
arxiv_id: '2504.15473'
source_url: https://arxiv.org/abs/2504.15473
tags:
- image
- diffusion
- concept
- concepts
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the internal representations of diffusion models
  to understand how they generate images. The authors train Sparse Autoencoders (SAEs)
  on Stable Diffusion v1.4 activations to extract interpretable concepts and study
  their evolution during the generation process.
---

# Emergence and Evolution of Interpretable Concepts in Diffusion Models

## Quick Facts
- arXiv ID: 2504.15473
- Source URL: https://arxiv.org/abs/2504.15473
- Reference count: 40
- This paper analyzes how diffusion models generate images by extracting interpretable concepts from early diffusion steps.

## Executive Summary
This paper investigates how diffusion models generate images by training Sparse Autoencoders (SAEs) on Stable Diffusion v1.4 activations to extract interpretable concepts. The authors discover that coarse image composition emerges as early as the first reverse diffusion step, with objects' locations being predictable from SAE features even before any visual content appears. Through intervention experiments, they demonstrate that spatially targeted interventions can control image layout in early stages, while global interventions can manipulate style in middle stages. The effectiveness of these interventions varies across the diffusion timeline, with image composition being finalized by the middle stages and only minor textural changes possible in final stages.

## Method Summary
The authors train k-sparse autoencoders (k=10 or 20, latent dim n_f=5120) on residual updates from cross-attention blocks at three timesteps (t=0.0, 0.5, 1.0) across Stable Diffusion v1.4. They collect 200k prompts from LAION-COCO, cache activations during denoising, and build a concept dictionary by matching SAE activations to object masks via a RAM→Grounding DINO→SAM pipeline. Validation uses segmentation prediction (IoU) and intervention success rates (CLIP similarity/LPIPS). The framework identifies when compositional vs. stylistic features solidify during generation.

## Key Results
- Coarse image composition is predictable from SAE features at t=1.0 with IoU≈0.26 before any visual content emerges
- Spatial interventions succeed at ~80% for layout edits at t=1.0 but drop to ~25% at later stages
- Global style interventions achieve 93% success at t=0.5 but only 69% at t=1.0
- Concept interpretability improves as generation progresses, with cohesion scores increasing over time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coarse image composition is determined during the very first reverse diffusion step, before any visual content appears in the model output.
- Mechanism: The text conditioning in cross-attention layers influences spatial activation patterns in early diffusion steps, embedding compositional layout information into residual stream updates that propagate through the denoising process.
- Core assumption: SAE-extracted features from cross-attention residual updates capture semantically meaningful spatial information rather than noise artifacts.
- Evidence anchors:
  - [abstract] "coarse image composition emerges as early as the first reverse diffusion step, with objects' locations being predictable from SAE features even before any visual content appears in the output"
  - [Section 4.2] "we are able to predict the rough layout of the final scene with IoU≈0.26 from mid_block SAE activations" at t=1.0
  - [corpus] Weak direct corpus support; neighboring papers focus on editing/control rather than early-stage composition emergence.
- Break condition: If SAE reconstruction error is too high (>50% unexplained variance) at early timesteps, extracted concepts may not reliably reflect model internals.

### Mechanism 2
- Claim: Intervention effectiveness is temporally partitioned—spatial composition edits succeed only in early diffusion stages, while style edits succeed only in middle stages.
- Mechanism: The denoising objective creates a temporal hierarchy where coarse structure is committed early (to reduce high-frequency noise), mid-level semantics solidify in middle stages, and only local refinements remain plastic in final stages. Interventions must align with the information that is still being actively modified at each stage.
- Core assumption: Skip connections in U-Net and null-text conditioning in CFG do not completely override local interventions.
- Evidence anchors:
  - [abstract] "spatially targeted interventions can control image layout in early stages, while global interventions can manipulate style in middle stages"
  - [Section 4.3.1-4.3.3] Quantitative intervention success: spatial edits achieve 80% success at t=1.0, ~25% (random baseline) at t=0.5 and t=0.0; global style edits achieve 93% success at t=0.5 vs. 78% at t=0.0 and 69% at t=1.0
  - [corpus] Consistent with neighboring work on localized concept erasure and training-free editing methods that target specific diffusion stages.
- Break condition: If interventions require strengths (β) so large they corrupt reconstructions, the causal claim weakens.

### Mechanism 3
- Claim: SAEs trained on diffusion cross-attention residual updates produce spatially localized, semantically interpretable concept features that can be mapped to object categories via overlap with vision-model annotations.
- Mechanism: The superposition hypothesis suggests diffusion models encode many concepts in fewer dimensions via sparse combinations; SAEs with TopK activation unpack these into an overcomplete basis where each latent dimension corresponds to a coherent concept.
- Core assumption: Top-k sparsity constraint produces monosemantic features rather than polysemantic mixtures.
- Evidence anchors:
  - [Section 3.1] "We opt for k-sparse autoencoders (with TopK activation) given their success with GPT-4 and SDXL Turbo"
  - [Section 3.3] Concept dictionary construction via IoU>0.5 overlap between SAE activations and Grounding DINO + SAM annotations
  - [corpus] Strong support from concurrent work applying SAEs to concept erasure in diffusion models (Sparse Autoencoder as Zero-Shot Classifier, 2503.09446).
- Break condition: If concept cohesion scores decline rather than improve as generation progresses, the interpretability claim fails.

## Foundational Learning

- Concept: **Diffusion denoising timeline (t ∈ [0,1])**
  - Why needed here: Intervention effectiveness and concept interpretability vary dramatically across t; you cannot apply edits uniformly.
  - Quick check question: At t=0.9, is composition more or less mutable than at t=0.3?

- Concept: **Sparse Autoencoder with TopK activation**
  - Why needed here: Standard autoencoders produce distributed/polysemantic representations; TopK enforces sparsity for interpretability.
  - Quick check question: Why use an overcomplete latent space (n_f ≫ d) rather than a bottleneck?

- Concept: **Cross-attention residual updates (Δℓ,t)**
  - Why needed here: The paper targets residual stream updates rather than raw activations; these encode the contribution of text conditioning to visual features.
  - Quick check question: What is the difference between cond and uncond features, and which does the paper find more interpretable?

## Architecture Onboarding

- Component map:
  Input: LAION-COCO prompts → SD v1.4 denoiser (U-Net with cross-attention blocks) → Activation extraction: Residual updates from down_block, mid_block, up_block at t ∈ {0.0, 0.5, 1.0} → SAE encoder: TopK(ReLU(W_enc(x - b))) with k ∈ {10, 20}, latent dim n_f = 4d = 5120 → SAE decoder: W_dec z + b; concept vectors are decoder columns → Concept dictionary: RAM (tagging) → Grounding DINO (detection) → SAM (segmentation) → IoU matching → Intervention: Modify activations via concept vectors with adaptive strength β_ij

- Critical path:
  1. Collect 200k prompts → run SD v1.4 with CFG (ω=7.5) → cache Δℓ,t per block/timestep
  2. Train separate SAEs per (block, timestep, conditioning) combination
  3. Build concept dictionary on 40k held-out prompts
  4. Validate via segmentation prediction (IoU) and intervention success rates

- Design tradeoffs:
  - **k=10 vs k=20 sparsity**: k=10 yields lower MSE but may miss nuanced concepts; k=20 improves explained variance (~65% vs ~58% at t=1.0 for up_block) but risks polysemanticity
  - **Block selection**: up_block provides highest spatial resolution (16×16) for segmentation; mid_block is bottleneck (8×8) but most amenable to interventions
  - **Intervention strength normalization**: Required for cross-object/cross-style consistency; unnormalized β produces erratic results

- Failure signatures:
  - **Dead features**: SAE latent dimensions that never activate; mitigated by auxiliary loss (AuxK) in training
  - **Context-free activations**: Concepts firing at fixed spatial positions (corners, edges) regardless of image semantics; likely optimization artifacts
  - **Leakage effects**: Skip connections and CFG uncond path bypass interventions, requiring higher β in early stages

- First 3 experiments:
  1. Replicate segmentation prediction at t=1.0: Train SAE on mid_block activations, predict object masks from concept activations, verify IoU>0.2 before first denoising update completes.
  2. Spatial intervention sweep: For objects "dog", "book", "car", apply quadrant constraints at t∈{0.8, 0.5, 0.2}; confirm success drops from ~80% (early) to ~25% (middle/final).
  3. Global style intervention at t=0.5: Select concept #1722 (cartoon) or equivalent, apply β=10, verify CLIP similarity increases while LPIPS stays moderate (~0.38).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can applying Sparse Autoencoders (SAEs) to Diffusion Transformers (DiTs) mitigate the "leakage effect" observed in U-Net architectures?
- Basis in paper: [explicit] The authors identify skip connections in U-Nets as a limitation causing information to bypass interventions, suggesting DiTs as a solution.
- Why unresolved: This study is restricted to Stable Diffusion v1.4 (U-Net), and the efficacy of SAE interventions on DiT architectures remains untested.
- What evidence would resolve it: Successful causal interventions on DiT models (e.g., FLUX) requiring lower intervention strengths or showing reduced reconstruction error leakage compared to U-Nets.

### Open Question 2
- Question: How can editing techniques be unified to adapt dynamically across the diffusion timeline?
- Basis in paper: [explicit] The authors state that developing editing techniques that adapt to the evolving nature of representations is a "promising direction for future work."
- Why unresolved: Current findings show distinct intervention windows (early for composition, middle for style), but a single, time-adaptive framework is missing.
- What evidence would resolve it: A unified algorithm that automatically selects the optimal intervention type (spatial vs. global) and strength based on the specific diffusion timestep.

### Open Question 3
- Question: Are the "context-free" activations found in structured image regions (e.g., corners) functional knobs or optimization artifacts?
- Basis in paper: [inferred] Appendix G discusses concepts firing in borders/corners irrespective of semantics, hypothesizing they might be optimization artifacts.
- Why unresolved: The paper demonstrates their existence but does not determine if they serve a functional role in reconstruction or are merely noise.
- What evidence would resolve it: Ablation studies removing these specific feature directions to observe if reconstruction error increases or generation quality degrades.

## Limitations
- Generalization to other architectures (SDXL, SD3) remains untested, particularly regarding skip connection leakage effects
- Concept dictionary construction relies on a three-stage pipeline that may introduce cascading errors
- Potential distribution shift between LAION-COCO training prompts and real-world usage scenarios

## Confidence
- **High Confidence**: Early-stage composition emergence (t=1.0), temporal partitioning of intervention effectiveness, concept interpretability through segmentation prediction (IoU>0.2)
- **Medium Confidence**: Cross-model generalizability of SAE concepts, effectiveness of global style interventions, concept dictionary construction pipeline
- **Low Confidence**: Long-term stability of interventions across extended generation chains, robustness to prompt distribution shift, impact of different CFG scales

## Next Checks
1. **Cross-architecture validation**: Train SAEs on SDXL activations and verify whether early composition emergence (IoU>0.2 at t=1.0) and temporal intervention partitioning hold. Test with 5k prompts spanning diverse object categories.

2. **Intervention robustness sweep**: Systematically vary CFG scale (ω∈{5, 7.5, 10}) and DDIM step count (25, 50, 100) while measuring intervention success rates. Confirm whether temporal partitioning remains stable across these hyperparameters.

3. **Concept polysemanticity audit**: For k=20 SAEs, compute pairwise cosine similarity between top-5 activation vectors across the concept dictionary. Flag any concept pairs with similarity >0.7 as potential polysemantic merges and retrain with k=10 to compare explained variance retention.