---
ver: rpa2
title: Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable
  SHAP-Guided Feature Selection and Classification
arxiv_id: '2510.19896'
source_url: https://arxiv.org/abs/2510.19896
tags:
- cancer
- bladder
- shap
- variables
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes an explainable AI approach to support urinary\
  \ tract disease diagnosis, with a focus on bladder cancer, by using SHAP (SHapley\
  \ Additive exPlanations) for feature selection and interpretability. The method\
  \ employs three gradient boosting algorithms\u2014XGBoost, LightGBM, and CatBoost\u2014\
  combined with Optuna for hyperparameter optimization and SMOTE for class balancing."
---

# Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification

## Quick Facts
- arXiv ID: 2510.19896
- Source URL: https://arxiv.org/abs/2510.19896
- Authors: Filipe Ferreira de Oliveira; Matheus Becali Rocha; Renato A. Krohling
- Reference count: 31
- Primary result: SHAP-guided feature selection achieved balanced accuracy up to 97.03% in BC vs. Cystitis classification

## Executive Summary
This paper proposes an explainable AI approach to support urinary tract disease diagnosis, with a focus on bladder cancer, by using SHAP (SHapley Additive exPlanations) for feature selection and interpretability. The method employs three gradient boosting algorithms—XGBoost, LightGBM, and CatBoost—combined with Optuna for hyperparameter optimization and SMOTE for class balancing. Six binary classification scenarios were evaluated to differentiate bladder cancer from other urological conditions using clinical and laboratory data. SHAP-guided feature selection reduced dimensionality while maintaining or improving performance, achieving balanced accuracy up to 97.03% in BC vs. Cystitis and 95.81% in BC vs. Prostate Cancer. The approach demonstrated superior performance compared to prior work, with precision and specificity reaching 100% in several cases.

## Method Summary
The methodology combines SHAP-based feature selection with gradient boosting classifiers optimized via Optuna. The approach uses a dataset from Mackay Memorial Hospital containing 1,336 samples across 5 disease classes with 39 raw variables (56 after preprocessing). For each binary classification scenario, the method applies KNN imputation for missing values, standard scaling for numerical features, and one-hot encoding for categorical features. SMOTE is applied during cross-validation folds for class balancing. Optuna performs 100 trials to optimize hyperparameters (learning rate, tree depth, regularization) for XGBoost, LightGBM, and CatBoost models. SHAP values are extracted from the best model to identify top predictive features, and a sensitivity analysis determines the optimal number of features to retain while maintaining or improving performance metrics.

## Key Results
- Achieved balanced accuracy up to 97.03% in BC vs. Cystitis classification using 18 selected features
- Precision and specificity reached 100% in several binary scenarios (BC vs. Cystitis, BC vs. KC)
- SHAP-guided feature selection improved performance metrics compared to using all features in most scenarios
- LightGBM and CatBoost consistently outperformed XGBoost across different binary classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SHAP-based feature selection reduces dimensionality while maintaining or improving classification performance.
- Mechanism: SHAP decomposes each prediction into the sum of individual feature contributions (marginal contributions across all possible feature coalitions), enabling ranking by predictive importance. Features with consistently low SHAP values are removed, reducing noise and mitigating overfitting in limited-sample datasets.
- Core assumption: Features with low average marginal contribution to predictions are redundant or irrelevant for the classification task.
- Evidence anchors:
  - [abstract]: "SHAP-based feature selection efficiently reduced data dimensionality while maintaining or even improving performance metrics such as balanced accuracy, precision, and specificity."
  - [section 4]: "In the BC vs. Cystitis experiment, the use of only 18 features increased BACC from 93.59% to 97.03%, while in the BC vs. KC experiment the best performance was achieved with only 5 variables."
  - [corpus]: Limited direct corroboration; neighbor papers discuss feature selection but don't specifically validate SHAP-guided reduction with these performance gains.
- Break condition: Would fail if low-SHAP-value features contain critical non-linear interactions, threshold effects, or conditional dependencies not captured by marginal contributions alone.

### Mechanism 2
- Claim: Synthetic minority oversampling enables better generalization on imbalanced medical datasets when combined with gradient boosting.
- Mechanism: SMOTE generates synthetic samples at random points along line segments connecting minority class instances to their k-nearest neighbors, expanding decision boundary coverage for underrepresented classes without simple duplication.
- Core assumption: Linear interpolation between minority samples produces valid synthetic instances that preserve underlying class distribution characteristics.
- Evidence anchors:
  - [abstract]: "class balancing with the SMOTE technique" applied across all six binary classification scenarios.
  - [section 2.2.2]: "generates new synthetic samples instead of simply replicating minority instances... repeated until the desired class proportion is achieved."
  - [corpus]: No direct corpus validation for this specific SMOTE implementation; corpus papers focus on explainability rather than class balancing.
- Break condition: Would fail if minority class has non-convex distribution, contains subclusters, or if synthetic samples create clinically unrealistic feature combinations.

### Mechanism 3
- Claim: Combining gradient boosting algorithms with Optuna hyperparameter optimization produces robust binary classifiers for differential diagnosis.
- Mechanism: Boosting iteratively combines weak learners (shallow decision trees), each trained to correct residual errors of previous iterations. Optuna performs 100 trials per scenario maximizing mean balanced accuracy across 5-fold stratified cross-validation, searching over learning rate, tree depth, regularization, and sampling parameters.
- Core assumption: Hyperparameter configurations that maximize validation BACC will generalize to unseen test data.
- Evidence anchors:
  - [abstract]: "balanced accuracy up to 97.03% in BC vs. Cystitis and 95.81% in BC vs. Prostate Cancer."
  - [section 2.4.2]: "A total of 100 optimization trials per scenario and per model were performed to identify the parameter combination that maximized BACC."
  - [corpus]: Neighbor papers (Liu et al. on Parkinson's, cardiovascular disease papers) confirm gradient boosting effectiveness for medical diagnosis with accuracy above 91%.
- Break condition: Would fail if hyperparameter search overfits to validation folds, if test distribution differs significantly from training, or if regularization is insufficient for small datasets.

## Foundational Learning

- Concept: **SHAP (SHapley Additive exPlanations) values**
  - Why needed here: Core technique for both feature selection and interpretability; determines which features drive predictions and enables dimensionality reduction.
  - Quick check question: Why does SHAP compute marginal contributions across "all possible coalitions" rather than using a single baseline comparison?

- Concept: **Gradient Boosting error-correction**
  - Why needed here: All three algorithms (XGBoost, LightGBM, CatBoost) use iterative residual fitting; understanding this mechanism is essential for interpreting results and debugging.
  - Quick check question: What is the difference between LightGBM's leaf-wise growth strategy and level-wise growth, and which requires more regularization?

- Concept: **Balanced metrics for imbalanced data**
  - Why needed here: Medical datasets often have severe class imbalance (e.g., 591 vs. 144 samples); raw accuracy can be misleading.
  - Quick check question: Why is balanced accuracy (average of sensitivity and specificity) preferred over accuracy when one class dominates?

## Architecture Onboarding

- Component map:
  Raw Data (1,336 samples, 39 variables) -> Missing Data Filter: >45% threshold -> [KNN Imputer (numerical) + Mode Imputer (categorical)] -> StandardScaler (numerical) + One-Hot Encoding (categorical) -> Stratified 80/20 Train-Test Split -> [SMOTE applied to TRAINING data only during CV folds] -> Optuna: 100 trials, 5-fold CV, maximize BACC -> Best hyperparameters -> [Train XGBoost / LightGBM / CatBoost] -> Best model per scenario -> SHAP value extraction on best model -> Sensitivity analysis: test N = 2 to total features -> Select optimal N, retrain, evaluate on held-out test set

- Critical path:
  1. **Stratified split BEFORE preprocessing** — prevents data leakage from test to train.
  2. **SMOTE only on training folds during CV** — never apply to validation or test data.
  3. **Two-pass training** — first train full model to extract SHAP values, then retrain with reduced features.
  4. **Sensitivity sweep** — test N from 2 to full feature count; select N with best BACC.

- Design tradeoffs:
  - KNN imputation preserves local structure but is O(n²) in sample size.
  - SHAP-guided selection improves interpretability but requires full model training first (computational overhead).
  - 100 Optuna trials × 5 folds = 500 model fits per algorithm per scenario.
  - LightGBM's leaf-wise growth is faster but more prone to overfitting on small data than level-wise.

- Failure signatures:
  - **Precision or specificity = 0%**: Model predicting single class; verify SMOTE applied correctly.
  - **BACC << Accuracy**: Class imbalance not addressed; check SMOTE configuration.
  - **Performance degrades after feature reduction**: Low-SHAP features may contain critical interactions; try higher N or interaction-aware methods.
  - **Large train-test BACC gap**: Overfitting; increase regularization (gamma, lambda) or reduce max depth.

- First 3 experiments:
  1. Replicate **BC vs. Cystitis** with all 57 features using LightGBM; confirm baseline BACC ~93.59% on test set.
  2. Extract SHAP values from best model, select top 18 features, retrain; verify BACC improvement to ~97% with precision reaching 100%.
  3. Run ablation across N = [5, 10, 15, 18, 25] to plot BACC vs. feature count and identify optimal point for each binary scenario.

## Open Questions the Paper Calls Out

- Question: How can SHAP-based feature selection be enhanced to explicitly capture dependency relationships between clinical variables?
  - Basis in paper: [explicit] "although SHAP is effective in assigning importance, it does not explicitly capture dependency relationships, making it necessary to combine it with specific methods"
  - Why unresolved: SHAP computes marginal contributions independently, potentially missing clinically meaningful feature interactions.
  - What evidence would resolve it: Integration of SHAP with dependency-aware methods (e.g., SHAP interaction values, causal inference techniques) demonstrating improved feature selection stability and interpretability.

- Question: To what extent does SMOTE-generated synthetic data affect the reliability of SHAP importance values and model generalizability?
  - Basis in paper: [explicit] "the dataset used presents class imbalance, which, despite the application of SMOTE, may introduce biases"
  - Why unresolved: Synthetic samples may create artificial patterns that inflate SHAP importance for certain features, potentially misleading clinical interpretation.
  - What evidence would resolve it: Comparative analysis using alternative balancing techniques with consistent SHAP rankings and validated performance on external datasets.

- Question: How do the SHAP-guided feature selection models perform when validated on independent datasets from different healthcare institutions?
  - Basis in paper: [inferred] Single-institution data (Mackay Memorial Hospital) without external validation; models may capture institution-specific patterns.
  - Why unresolved: Geographic, demographic, and clinical practice variations across institutions may affect model transferability.
  - What evidence would resolve it: Validation on geographically diverse cohorts demonstrating similar balanced accuracy and consistent SHAP feature importance rankings.

## Limitations

- The methodology relies on clinical data from a single medical center, limiting generalizability across different healthcare systems and populations.
- SHAP-based explainability provides feature importance but may not capture complex non-linear interactions between clinical variables in rare urological conditions.
- The performance claims are based on internal validation without external validation on independent datasets from different institutions.

## Confidence

- **High**: Overall performance improvements with balanced accuracy up to 97.03% achieved through SHAP-guided feature selection
- **Medium**: Superiority claims compared to prior work (limited direct comparisons available in the literature)
- **Medium**: Clinical interpretability benefits (SHAP values provide feature importance but not full causal understanding)

## Next Checks

1. External validation on independent urological datasets from different medical centers to assess generalizability of the 97.03% balanced accuracy claim
2. A/B testing comparing SHAP-guided feature selection against alternative methods (L1 regularization, mutual information) on the same dataset to quantify the specific contribution of SHAP
3. Clinical expert review of top SHAP features to verify their medical relevance and interpretability for bladder cancer diagnosis compared to other urological conditions