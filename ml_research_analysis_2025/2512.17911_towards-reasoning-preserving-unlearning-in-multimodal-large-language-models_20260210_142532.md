---
ver: rpa2
title: Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models
arxiv_id: '2512.17911'
source_url: https://arxiv.org/abs/2512.17911
tags:
- reasoning
- unlearning
- arxiv
- steering
- forget
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models

## Quick Facts
- **arXiv ID:** 2512.17911
- **Source URL:** https://arxiv.org/abs/2512.17911
- **Reference count:** 35
- **Primary result:** Introduces R-MUSE, a training-free inference-time method for unlearning sensitive reasoning traces from multimodal LLMs while preserving general reasoning.

## Executive Summary
This paper addresses a critical gap in machine unlearning for multimodal large language models (MLLMs): the need to erase not just final answers but also the intermediate reasoning traces that lead to those answers. R-MUSE is a training-free, inference-time framework that constructs span-hybrid unlearning subspaces targeting both answer and chain-of-thought token spans, uses a reasoning retain subspace (RRS) to orthogonally protect general reasoning capabilities, and employs adaptive calibration steering (ACS) via optimal transport to dynamically set steering strength. Evaluated on the RMLLMU-Bench benchmark, R-MUSE achieves state-of-the-art trade-offs between forgetting sensitive information and retaining general reasoning, outperforming traditional unlearning methods like gradient ascent and preference optimization.

## Method Summary
R-MUSE operates entirely at inference time, constructing two key subspaces offline: a span-hybrid unlearning subspace from forget-set data that captures both answer and reasoning traces, and a reasoning retain subspace (RRS) from retain-set data that protects general reasoning. During inference, for each query, the method computes an RRS alignment gate score; if below a threshold, it applies adaptive calibration steering that projects the unlearning direction onto the orthogonal complement of RRS and scales it using an optimal transport-based distance metric. The approach uses spherical interpolation (slerp) to modify hidden states in designated layers, aiming to erase sensitive information while preserving the model's ability to perform general reasoning tasks.

## Key Results
- R-MUSE achieves superior RIL/RCR trade-offs compared to vanilla models and traditional unlearning methods (GA, NPO) on RMLLMU-Bench.
- The span-hybrid unlearning subspace (targeting both answers and CoT) outperforms answer-only methods in reducing reasoning information leakage.
- The RRS protection mechanism significantly improves reasoning capability retention, with a gating threshold of τ=0.85 providing optimal balance.
- Adaptive Calibration Steering (ACS) provides better-calibrated steering strength compared to fixed hyperparameters.

## Why This Works (Mechanism)

### Mechanism 1: Span-Hybrid Unlearning Subspace
R-MUSE constructs a differential subspace by contrasting hidden states from forget-set items' original outputs (negative) with refusal-guided outputs (positive), targeting both answer and chain-of-thought spans. This span-hybrid approach captures sensitive information more comprehensively than answer-only methods, under the assumption that reasoning traces are linearly representable in activation space.

### Mechanism 2: Reasoning Retain Subspace (RRS) for Orthogonal Protection
RRS is built from retain-set data by contrasting detailed reasoning solutions with direct answers, creating a subspace that represents general reasoning ability. During steering, the unlearning update is projected onto the orthogonal complement of RRS, explicitly protecting reasoning capabilities. A gate mechanism based on RRS alignment determines when to apply steering.

### Mechanism 3: Adaptive Calibration Steering (ACS) via Optimal Transport
ACS dynamically sets steering strength by treating the process as optimal transport on the unit hypersphere. It computes the geodesic distance to the nearest refusal prototype as the target, then scales the steering angle proportionally. This removes the need for manual hyperparameter tuning while ensuring appropriate unlearning intensity.

## Foundational Learning

- **Machine Unlearning:** Understanding why we need to remove specific data influence from trained models and the trade-offs between forgetting and utility. *Quick check:* What are the two primary risks R-MUSE tries to balance?

- **Activation Steering in LLMs:** Grasping how contrastive activations can define directions in latent space that modulate model behavior. *Quick check:* How does R-MUSE compute its "unlearning direction" and what two sources does it contrast?

- **Representation Engineering / Subspace Methods:** Understanding that semantic properties can be localized to linear subspaces via SVD. *Quick check:* What is the purpose of the RRS and how is it used during steering?

## Architecture Onboarding

- **Component map:** Subspace Constructors (Unlearning Subspace Builder, RRS Builder) -> Inference-Time Analyzer (s_gate, gate check) -> Adaptive Steerer (θ_tar, θ_dir, λ calculation, slerp application)

- **Critical path:** Offline: Build U_un and U_rrs using forget/retain sets (contrastive outputs, span pooling, SVD). Online: For each token in designated layer, compute s_gate; if below threshold, calculate θ_tar and θ_dir, determine λ, apply slerp with RRS-orthogonal projection.

- **Design tradeoffs:** Training-free vs. effective (avoids retraining but needs access to forget/retain data); Orthogonal protection vs. interference (RRS assumes orthogonality, non-orthogonal subspaces cause trade-offs); Adaptive strength vs. simplicity (ACS removes λ hyperparameter but adds computational overhead).

- **Failure signatures:** Reasoning Leakage (high RIL, low RCR, check span-hybrid construction); Reasoning Collapse (low RCR, repetitive outputs, verify orthogonality); Utility Drop on Retain Set (over-aggressive steering, check τ and λ).

- **First 3 experiments:** 1) Baseline reproduction on RMLLMU-Bench (LLaVA-1.5-7B, 5% Forget) comparing R-MUSE against vanilla, GA, and NPO on RIL/RCR metrics; 2) Ablation study (w/o RRS, w/o Reasoning Span, w/o ACS) to validate component contributions; 3) Gate threshold sensitivity sweep (τ from 0.6 to 1.0) to identify optimal trade-off region.

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions in the main text. The open questions section is derived from analysis of the paper's limitations and potential future work areas based on the methodology and experimental scope.

## Limitations

- The method's efficacy depends on the assumption that sensitive reasoning information and general reasoning ability occupy sufficiently orthogonal linear subspaces, which is not directly validated.
- The optimal transport-based adaptive calibration adds computational overhead and relies on the quality of refusal prototypes, which are not fully specified in the main text.
- The evaluation uses LLM judges (Gemini-2.5-Flash) for RIL/RCR metrics, introducing potential bias and sensitivity to prompt engineering.
- The method requires access to forget and retain data for subspace construction, which may not always be available in practice.

## Confidence

- **High confidence:** The core algorithmic structure (span-hybrid subspace, RRS projection, adaptive steering) is clearly specified and internally consistent.
- **Medium confidence:** The theoretical motivation for each component is plausible but lacks direct validation through ablations for all design choices.
- **Low confidence:** Critical implementation details (refusal template pool, target distribution construction, precise intervention layers) are not fully specified in the main text.

## Next Checks

1. **Direct RRS-Orthogonality Test:** Measure dot products between unlearning direction and RRS basis vectors on held-out reasoning queries to test orthogonality assumption.

2. **Adaptive vs. Static λ Sweep:** Compare R-MUSE with fixed λ=0.5 against adaptive version across 5%, 10%, 15% forget rates to isolate ACS benefits.

3. **Span-Ablation Diagnostic:** Run R-MUSE full, w/o CoT span, and w/o answer span variants on same model/forget set to quantify span-hybrid contribution to RIL/RCR trade-off.