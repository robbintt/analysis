---
ver: rpa2
title: Probability Density from Latent Diffusion Models for Out-of-Distribution Detection
arxiv_id: '2508.15737'
source_url: https://arxiv.org/abs/2508.15737
tags:
- detection
- density
- diffusion
- methods
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the effectiveness of likelihood-based out-of-distribution
  (OOD) detection in representation space. Under a uniform OOD distribution assumption,
  it theoretically proves that density-based OOD detection is optimal.
---

# Probability Density from Latent Diffusion Models for Out-of-Distribution Detection

## Quick Facts
- arXiv ID: 2508.15737
- Source URL: https://arxiv.org/abs/2508.15737
- Authors: Joonas JÃ¤rve; Karl Kaspar Haavel; Meelis Kull
- Reference count: 40
- This work investigates likelihood-based OOD detection in representation space, proving density-based OOD detection is optimal under uniform OOD distribution assumptions, and achieves competitive results on CIFAR-10 but underperforms on ImageNet-200.

## Executive Summary
This paper proposes a novel approach to out-of-distribution (OOD) detection using latent diffusion models. The authors theoretically prove that density-based OOD detection is optimal under uniform OOD distribution assumptions, and implement this by training a Variational Diffusion Model on latent representations of pre-trained ResNet-18. They propose three OOD detection methods: exact likelihood, prior likelihood, and top-K diffusion loss, evaluating them on the OpenOOD benchmark.

## Method Summary
The approach leverages the latent representations of pre-trained ResNet-18 models as the space for density estimation. A Variational Diffusion Model (VDM) is trained on these latent representations to estimate probability densities, enabling exact log-likelihood computation through probability-flow ODEs. The framework transforms the standard image classification pipeline by adding a density estimation layer that operates on the feature space rather than the raw image space. Three distinct methods for OOD detection are implemented: exact likelihood (computing log-likelihood of the input's latent representation), prior likelihood (computing log-likelihood under the prior distribution), and top-K diffusion loss (using the negative log-likelihood of the top-K closest latent representations).

## Key Results
- Exact likelihood and prior likelihood methods achieve competitive performance with state-of-the-art methods on CIFAR-10
- All proposed methods underperform on ImageNet-200 compared to CIFAR-10, suggesting scalability limitations
- Top-K diffusion loss method proves more robust and stable across different benchmarks
- The approach validates that density-based OOD detection in representation space is viable for further research

## Why This Works (Mechanism)
The method works by exploiting the fact that OOD samples will have lower probability density in the latent representation space learned from in-distribution data. By training a diffusion model to estimate densities in this compressed representation space rather than raw image space, the approach can efficiently compute likelihoods for OOD detection. The use of probability-flow ODEs enables exact log-likelihood computation, which is crucial for the theoretical optimality of the approach under uniform OOD assumptions.

## Foundational Learning
- Variational Diffusion Models (VDMs): Why needed - To learn probability densities in latent space for OOD detection. Quick check - Can the VDM accurately reconstruct training samples?
- Probability-flow ODEs: Why needed - To enable exact log-likelihood computation from diffusion models. Quick check - Does the ODE solver converge and provide stable likelihood estimates?
- Latent representations: Why needed - To work in a compressed feature space rather than high-dimensional image space. Quick check - Do the latent representations preserve meaningful semantic information?
- Log-likelihood computation: Why needed - To quantify how likely an input is under the learned distribution. Quick check - Are the computed likelihoods well-calibrated and discriminative between in-distribution and OOD samples?
- Top-K diffusion loss: Why needed - To improve robustness by considering multiple closest representations. Quick check - Does top-K selection improve stability across different OOD datasets?

## Architecture Onboarding
Component map: Input Image -> ResNet-18 Encoder -> Latent Representation -> Variational Diffusion Model -> Log-Likelihood Score -> OOD Decision
Critical path: The most critical path is from the latent representation through the VDM to the log-likelihood score, as this determines the OOD detection quality.
Design tradeoffs: The approach trades computational efficiency (training a VDM) for theoretically optimal OOD detection under uniform assumptions. It also assumes the pre-trained ResNet-18 provides meaningful representations for OOD detection.
Failure signatures: Poor OOD detection performance may indicate insufficient model capacity, inadequate latent representation quality, or violation of the uniform OOD distribution assumption.
First experiments: 1) Train VDM on CIFAR-10 latent representations and evaluate reconstruction quality, 2) Compute log-likelihoods for in-distribution vs simple OOD datasets (like random noise), 3) Test top-K diffusion loss with different K values to find optimal stability.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes uniform OOD distribution, which is unrealistic in practical scenarios
- Performance degradation on ImageNet-200 compared to CIFAR-10 suggests scalability limitations and dependence on model capacity
- High computational cost of training diffusion models for OOD detection is not addressed
- Inconsistent performance across benchmarks indicates potential instability in certain scenarios

## Confidence
High confidence: The theoretical proof establishing density-based OOD detection as optimal under uniform OOD distribution assumptions is mathematically sound and well-supported.

Medium confidence: The experimental results demonstrating competitive performance on CIFAR-10 are reliable, but the underperformance on ImageNet-200 introduces uncertainty about the method's generalizability to larger, more complex datasets.

Low confidence: The claim that the proposed method "warrants further study" is somewhat vague and lacks specific directions or quantified gaps that need addressing.

## Next Checks
1. Evaluate the method on a wider range of datasets with varying complexity and domain shifts, including real-world OOD scenarios where the uniform distribution assumption clearly does not hold.

2. Conduct ablation studies to quantify the impact of model capacity, latent space dimensionality, and diffusion model architecture choices on OOD detection performance.

3. Compare computational efficiency (training time, inference latency, memory usage) against other state-of-the-art OOD detection methods to assess practical deployment viability.