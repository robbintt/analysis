---
ver: rpa2
title: Personalized Image Generation via Human-in-the-loop Bayesian Optimization
arxiv_id: '2602.02388'
source_url: https://arxiv.org/abs/2602.02388
tags:
- image
- optimization
- user
- multibo
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'MultiBO achieves target-aligned image generation through multi-choice
  human-in-the-loop Bayesian optimization in diffusion attention space. Using multi-choice
  preference feedback and constrained warping transformations, MultiBO outperforms
  five baselines in target alignment metrics (CLIP-I2I: 0.9364, LPIPS: 0.5497) while
  maintaining competitive performance on reward metrics.'
---

# Personalized Image Generation via Human-in-the-loop Bayesian Optimization

## Quick Facts
- **arXiv ID**: 2602.02388
- **Source URL**: https://arxiv.org/abs/2602.02388
- **Reference count**: 40
- **Primary result**: MultiBO achieves target-aligned image generation through multi-choice human-in-the-loop Bayesian optimization in diffusion attention space

## Executive Summary
MultiBO introduces a novel approach to personalized image generation that addresses the challenge of aligning generated images with user preferences while avoiding reward hacking. The method combines multi-choice human-in-the-loop feedback with constrained warping transformations in diffusion attention space, achieving strong target alignment metrics while maintaining competitive reward performance. The approach demonstrates effectiveness across various personalization tasks while requiring minimal user interaction.

## Method Summary
The paper presents a multi-choice human-in-the-loop Bayesian optimization framework for personalized image generation. The method operates in diffusion attention space, using multi-choice preference feedback and constrained warping transformations to optimize image generation. Users provide feedback through multiple choice selections rather than absolute ratings, enabling more nuanced preference capture. The Bayesian optimization framework iteratively refines the generation process based on this feedback, while constrained warping ensures that modifications remain within acceptable bounds to maintain image quality and avoid pathological outputs.

## Key Results
- Achieves strong target alignment metrics (CLIP-I2I: 0.9364, LPIPS: 0.5497)
- Requires only 50 user queries for effective personalization
- Demonstrates 70.82% win rate in human evaluation
- Avoids reward hacking issues seen in metric-optimized approaches

## Why This Works (Mechanism)
MultiBO works by operating in diffusion attention space where human preferences can be effectively captured through multi-choice feedback mechanisms. The Bayesian optimization framework uses this feedback to iteratively refine image generation parameters while constrained warping transformations prevent the optimization from producing unrealistic or undesirable outputs. This combination allows the system to find solutions that satisfy user preferences while maintaining image quality and avoiding the common pitfall of optimizing for metrics at the expense of actual user satisfaction.

## Foundational Learning
- **Bayesian Optimization**: Iterative optimization method that uses probabilistic models to guide the search for optimal parameters; needed for efficient exploration of the high-dimensional image generation space; quick check: verify acquisition function properly balances exploration/exploitation
- **Diffusion Attention Space**: Intermediate representation space in diffusion models where semantic modifications can be made; needed as the domain for applying human feedback; quick check: confirm modifications in attention space properly translate to image space
- **Multi-choice Preference Feedback**: Preference elicitation method where users select between multiple options rather than providing absolute ratings; needed to capture nuanced preferences; quick check: validate that multi-choice format captures more information than binary feedback
- **Constrained Warping Transformations**: Transformation techniques that maintain image quality while allowing controlled modifications; needed to prevent pathological outputs; quick check: verify constraint satisfaction across all generated images
- **CLIP-based Alignment Metrics**: Evaluation metrics using Contrastive Language-Image Pre-training models; needed for objective assessment of target alignment; quick check: confirm CLIP model captures relevant aspects of image quality
- **LPIPS Distance Metric**: Perceptual similarity metric for evaluating image similarity; needed for quantitative comparison of generated images; quick check: validate LPIPS scores correlate with human judgment

## Architecture Onboarding

**Component Map:**
Diffusion Model -> Attention Space -> Bayesian Optimizer -> Constrained Warper -> Image Generator -> User Feedback Loop

**Critical Path:**
1. User provides multi-choice feedback on generated images
2. Bayesian optimizer updates posterior distribution based on feedback
3. Constrained warper generates new candidate images within valid bounds
4. Images are rendered and presented to user for next feedback round

**Design Tradeoffs:**
- Multi-choice feedback vs. absolute ratings: Multi-choice captures more nuanced preferences but requires more user effort per iteration
- Bayesian optimization vs. direct gradient methods: Bayesian optimization handles non-differentiable preferences but converges slower
- Constrained warping vs. unconstrained optimization: Constraints maintain quality but may limit achievable personalization

**Failure Signatures:**
- Reward hacking: High reward metrics but poor alignment with user preferences
- Mode collapse: Repeated generation of similar images despite diverse feedback
- Constraint violations: Generated images falling outside acceptable quality bounds
- Slow convergence: Excessive iterations required to reach satisfactory personalization

**First Experiments:**
1. Synthetic preference feedback ablation to isolate contribution of feedback mechanism
2. Constraint strength sensitivity analysis to determine optimal constraint parameters
3. User study comparing multi-choice vs. binary feedback formats

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided material. However, based on the methodology and results presented, potential open questions could include: (1) How does the approach scale to more complex personalization tasks beyond avatars and facial modifications? (2) What is the long-term reliability of synthetic user feedback compared to real human preferences? (3) How can the constrained warping mechanism be generalized to other domains beyond image generation?

## Limitations
- Relies on synthetic user feedback rather than real human preferences in main experiments
- May not generalize well to subjective aesthetic preferences beyond CLIP-based alignment
- Effectiveness on personalization tasks beyond avatar and facial modifications remains untested

## Confidence
- **High confidence**: Technical implementation of multi-choice Bayesian optimization in diffusion attention space
- **Medium confidence**: Effectiveness of constrained warping transformations for maintaining image quality
- **Medium confidence**: Claim of avoiding reward hacking, pending real human preference validation
- **Low confidence**: Generalizability across different personalization domains

## Next Checks
1. Conduct user studies with real human preferences across diverse demographic groups to validate synthetic feedback results
2. Test the method on additional personalization tasks beyond avatar and facial modifications, including object-level and scene-level personalization
3. Implement an ablation study isolating the contributions of multi-choice feedback versus constrained warping to quantify their individual impacts on performance