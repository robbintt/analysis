---
ver: rpa2
title: '3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models'
arxiv_id: '2510.20967'
source_url: https://arxiv.org/abs/2510.20967
tags:
- reasoning
- medical
- diagnostic
- anatomical
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces 3DReasonKnee, the first 3D grounded reasoning
  dataset for medical images, to address the challenge of localizing and reasoning
  about anatomical structures in 3D medical images. The dataset comprises 494k high-quality
  quintuples derived from 7,970 3D knee MRI volumes, each containing a diagnostic
  question, 3D bounding box, clinician-generated reasoning steps, and structured severity
  assessments.
---

# 3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models

## Quick Facts
- **arXiv ID:** 2510.20967
- **Source URL:** https://arxiv.org/abs/2510.20967
- **Reference count:** 38
- **Primary result:** 3D grounded reasoning dataset for knee MRIs with 494k quintuples; best VLM accuracy 0.568 (zero-shot), 0.613 (supervised)

## Executive Summary
3DReasonKnee introduces the first 3D grounded reasoning dataset for medical images, addressing the critical gap in localizing and reasoning about anatomical structures in 3D medical volumes. The dataset comprises 494,000 high-quality quintuples derived from 7,970 3D knee MRI volumes, each containing a diagnostic question, 3D bounding box, clinician-generated reasoning steps, and structured severity assessments. The creation involved over 450 hours of expert clinician time for manual segmentation and reasoning chain generation. Benchmarking five state-of-the-art VLMs shows that even the best models achieve only 0.568 overall accuracy in zero-shot settings, with substantial improvements observed when ground truth regions are provided or through supervised fine-tuning (0.613 accuracy). This dataset serves as a valuable resource for advancing multimodal medical AI systems toward 3D, clinically aligned, localized decision-making capabilities.

## Method Summary
The 3DReasonKnee dataset is constructed from 7,970 3D knee MRI volumes (OAI DESS sequences) processed into 494,000 quintuples containing {Volume, Question, 3D Bounding Box, Chain-of-Thought Reasoning, Severity Grades}. The dataset creation involved over 450 hours of expert clinician time for manual segmentation and reasoning chain generation. The authors establish ReasonKnee-Bench to evaluate both localization (using 3D Intersection over Union) and diagnostic accuracy across anatomical regions. Five state-of-the-art VLMs (Qwen2.5-VL, Med3DVLM, o1) are evaluated under three settings: Zero-shot, Zero-shot with Instruction Schema, and Supervised Fine-tuning. The evaluation framework parses model outputs for structured grades and bounding boxes, calculating mean accuracy per lesion category and 3D IoU against ground truth annotations.

## Key Results
- VLMs achieve only 0.568 overall accuracy in zero-shot settings across 7 diagnostic categories
- Supervised fine-tuning improves accuracy to 0.613, demonstrating the value of task-specific training
- Zero-shot with ground truth region cropping significantly outperforms full-volume inference, indicating localization is a primary bottleneck
- Chain-of-Thought reasoning, while valuable for explainability, does not improve diagnostic accuracy in supervised settings

## Why This Works (Mechanism)
The dataset's effectiveness stems from its comprehensive grounding approach, requiring models to simultaneously localize anatomical regions, generate reasoning chains, and produce structured severity assessments. This multi-modal task design forces models to develop true understanding rather than pattern matching, as evidenced by the substantial performance gap between zero-shot and supervised settings.

## Foundational Learning
- **3D Medical Image Processing**: Understanding how 3D volumes differ from 2D images in terms of spatial relationships and feature extraction
  - *Why needed*: The dataset specifically targets 3D reasoning, requiring models to understand volumetric data
  - *Quick check*: Can the model correctly identify and localize anatomical structures in 3D space?
- **Medical Domain Knowledge**: Familiarity with knee anatomy, MOAKS grading system, and common pathologies
  - *Why needed*: Accurate diagnosis requires understanding medical terminology and grading criteria
  - *Quick check*: Does the model output clinically valid severity grades according to MOAKS standards?
- **Grounded Reasoning**: The ability to generate step-by-step explanations while maintaining spatial awareness
  - *Why needed*: The dataset requires both localization and reasoning, not just classification
  - *Quick check*: Does the model's reasoning chain correctly reference the localized anatomical region?

## Architecture Onboarding

**Component Map**: MRI Volumes -> 3D Tokenization -> VLM Encoder -> Reasoning Module -> Structured Output

**Critical Path**: Input preprocessing (160-slice standardization) → 3D volume encoding → anatomical region localization → diagnostic reasoning → severity grade classification

**Design Tradeoffs**: Full 3D volume processing vs. computational efficiency, structured output generation vs. model flexibility, localization accuracy vs. reasoning depth

**Failure Signatures**: Low IoU scores indicate localization failure; inconsistent grade formats indicate instruction-following issues; missing CoT indicates reasoning module failure

**First Experiments**:
1. Zero-shot inference with instruction schema prompt to establish baseline performance
2. Zero-shot with ground truth region cropping to isolate localization vs. reasoning challenges
3. Supervised fine-tuning with structured output loss to evaluate training effectiveness

## Open Questions the Paper Calls Out
- **RL for Grounded Reasoning**: Can reinforcement learning paradigms better leverage structured CoT rationales compared to supervised fine-tuning?
- **CoT Effectiveness**: Why does Chain-of-Thought reasoning fail to improve diagnostic accuracy during supervised fine-tuning?
- **3D Processing Efficiency**: How can models effectively process both full 3D volumes and localized subregions within computational limits?
- **Longitudinal Analysis**: Can the grounded reasoning framework be adapted to analyze disease progression across time points?

## Limitations
- Computational constraints limit full 3D volume processing, requiring region cropping or downsampling
- Supervised fine-tuning with CoT reasoning paradoxically reduces accuracy compared to standard training
- Current benchmark focuses on single-instance diagnosis rather than temporal disease progression

## Confidence
- **Dataset Construction Quality**: High - extensive clinician involvement and manual verification
- **Benchmark Design**: High - comprehensive evaluation of both localization and diagnostic accuracy
- **Model Performance Claims**: Medium - based on limited VLM evaluations, may not generalize to all architectures
- **Clinical Relevance**: High - uses established MOAKS grading system and real clinical questions

## Next Checks
1. Verify the SFT hyperparameters (learning rate, batch size, epochs) used in the reported 0.613 accuracy improvement
2. Implement the 3D tokenization strategy to understand how 160-slice volumes are processed
3. Test the "Zero-shot with GT region" setting to confirm localization is the primary bottleneck