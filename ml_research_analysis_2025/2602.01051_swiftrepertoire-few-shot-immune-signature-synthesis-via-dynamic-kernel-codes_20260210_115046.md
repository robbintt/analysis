---
ver: rpa2
title: 'SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes'
arxiv_id: '2602.01051'
source_url: https://arxiv.org/abs/2602.01051
tags:
- swiftrepertoire
- where
- bootstrap
- denotes
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces SwiftRepertoire, a prototype-conditioned fast-weight
  framework for few-shot adaptation of T-cell receptor repertoire models. The method
  synthesizes sparse, rank-aware adapter parameters via retrieval-driven parameter
  synthesis conditioned on compact task descriptors, enabling immediate adaptation
  to new tasks using only a handful of support examples.
---

# SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes

## Quick Facts
- arXiv ID: 2602.01051
- Source URL: https://arxiv.org/abs/2602.01051
- Reference count: 26
- Primary result: Achieves AUCs of 0.995 (lung) and 0.997 (thyroid) for cancer detection using only handful of support examples

## Executive Summary
SwiftRepertoire introduces a prototype-conditioned fast-weight framework for few-shot adaptation of T-cell receptor repertoire models. The method synthesizes sparse, rank-aware adapter parameters via retrieval-driven parameter synthesis conditioned on compact task descriptors, enabling immediate adaptation to new tasks without full model fine-tuning. This significantly reduces computational overhead while maintaining strong performance. The framework integrates a nested motif calibration workflow for interpretability, linking predictive adaptation to statistically controlled sequence discovery.

## Method Summary
SwiftRepertoire operates through a two-phase pipeline: (1) memory construction where per-task adapters are estimated via ridge regression, projected to PCA, and clustered into K geometry-aware prototypes; (2) retrieval training where lightweight task descriptors derived from pooled embedding statistics and probe gradients condition a retrieval network that outputs prototype activation weights. These weights are optimized via constrained proximal solver with ℓ1 regularization and hard top-r thresholding to synthesize adapter parameters applied to a frozen backbone. The method validates low-dimensional adapter structure via Fisher eigenvalue analysis and provides interpretable motif-level biological insights through a two-stage testing pipeline.

## Key Results
- Achieves AUCs of 0.995 (lung) and 0.997 (thyroid) for cancer detection, surpassing prior baselines by at least 2 percentage points
- Demonstrates strong performance in universal cancer screening with AUCs of 0.990 (GBM), 0.991 (PACA), and 0.986 (ESCA)
- Maintains robust few-shot scaling across support sizes {5, 10, 20, 50} with latency of approximately 8ms regardless of support size
- Provides interpretable, motif-level biological insights through nested motif calibration workflow

## Why This Works (Mechanism)

### Mechanism 1
Adapter parameters for new tasks can be synthesized from sparse combinations of learned prototypes, avoiding full fine-tuning. A learned dictionary of K geometry-aware prototypes spans a low-dimensional subspace. For a new task, ridge-estimated adapters are projected onto this basis via constrained proximal optimization with ℓ1 regularization, yielding sparse activation weights w with ∥w∥₀ ≤ r. The synthesized adapter θ_mem = M^T w is applied via small modules to a frozen backbone. Core assumption: Task-specific adapter vectors lie near a low-dimensional subspace with intrinsic dimension r ≪ d_θ. Break condition: If adapter intrinsic dimension grows linearly with pretraining tasks, prototype coverage error becomes unacceptably large.

### Mechanism 2
Lightweight task descriptors derived from pooled embedding statistics and probe gradients suffice for task conditioning. For each support set, compute pooled moments, explicit percentiles, and the PCA projection of averaged probe gradients from a fixed probe head. The concatenated descriptor z_t conditions a retrieval network that outputs prototype logits v_t, initializing the sparse retrieval process. Core assumption: Probe gradient statistics capture sufficient task geometry to discriminate among prototype configurations. Break condition: If descriptor-to-adapter mapping exhibits high variance across semantically similar tasks, retrieval initialization provides no meaningful prior.

### Mechanism 3
Enforced sparsity with hard top-r thresholding preserves performance while enabling interpretability. After proximal solver convergence, apply explicit hard thresholding to retain only r largest activations, coupling with a two-stage motif testing pipeline that screens channels by maximal activation, then tests motifs using adaptive permutations with Storey's π̂₀ estimation and bootstrap confidence intervals. Core assumption: r active prototypes suffice to approximate the task adapter within coverage tolerance. Break condition: If mutual coherence approaches 1 or condition number becomes large, sparse combinations become unstable.

## Foundational Learning

- **Fisher Information Matrix and Eigenvalue Analysis**: The method validates low-dimensional adapter structure via Fisher eigenvalue concentration; the bootstrap hypothesis test determines if leading r eigenvectors capture ≥95% of Fisher energy. Quick check: Given empirical Fisher eigenvalues λ₁ ≥ λ₂ ≥ ... ≥ λ_d, can you compute the energy ratio ζ_r = Σᵢ₌₁ʳ λᵢ / Σⱼ₌₁ᵈ λⱼ and interpret a bootstrap percentile p-value?

- **Proximal Gradient Methods with ℓ₁ Regularization**: Retrieval activations are computed via accelerated proximal-gradient solving Eq. (11); understanding soft-thresholding operators is essential for debugging convergence. Quick check: How does the soft-thresholding operator S_λ(x) = sign(x)·max(|x| - λ, 0) differ from hard thresholding, and what happens when λ → 0?

- **Multiple Testing Correction (Bonferroni, Storey's q-value)**: Motif calibration uses Bonferroni correction for the five candidate dimensions and Storey's π̂₀ for null proportion estimation in motif discovery. Quick check: If testing 5 candidate dimensions at familywise α = 0.01, what is the per-comparison threshold after Bonferroni correction? How does Storey's method improve on naive Benjamini-Hochberg when many hypotheses are non-null?

## Architecture Onboarding

- **Component map**: Frozen pretrained backbone -> TCR sequence encoder (protein LM/transformer) producing residue-level embeddings h_i -> Prototype memory M (K × d_θ matrix from geometry-aware clustering) -> Task descriptor encoder (computes z_t from pooled statistics and probe gradients) -> Retrieval network G_ϕ (maps z_t → logits v_t) -> Proximal solver (iteratively solves Eq. 11 with accelerated proximal gradient) -> Adapter modules (small rank-r modules applied to frozen backbone via θ_mem = M^T ẽw_t) -> Motif calibration pipeline (two-stage testing with bootstrap CIs and Storey estimation)

- **Critical path**: 1) Collect pretraining adapters → PCA → select r via Fisher bootstrap test (Table 4 shows r=20 selected) 2) Cluster canonicalized adapters → form prototypes M → compute coverage error ϵ_M with bootstrap 90% CI 3) For each new task: compute descriptor z_t → retrieve logits v_t → proximal solve → hard threshold → synthesize adapter 4) Apply adapter to frozen backbone → evaluate on query set → backprop through implicit differentiation

- **Design tradeoffs**: K (prototype count): Higher K improves coverage but increases retrieval complexity O(Kd_θ). r (sparsity level): Higher r improves approximation but reduces interpretability. λ (ℓ₁ coefficient): Controls soft sparsity before hard thresholding. Neural-ODE blocks: Continuous-time modeling for retrieval/descriptor pipelines.

- **Failure signatures**: High coverage error (bootstrap 90% upper bound ϵ^upper_M exceeds ~5%) → check prototype clustering stability; Unstable retrieval (condition number κ(M^T) > 100 or mutual coherence μ(M) > 0.8) → trigger prototype merging; Calibration drift (calibration-to-test AUC gap > 1%) → recalibrate channel threshold τ_c with nested CV; Sparsity collapse (post-threshold activation concentrates on single prototype) → check λ/γ balance and descriptor quality.

- **First 3 experiments**: 1) Prototype coverage validation: On T_pre split, compute adapters via ridge regression, project to PCA-r, measure reconstruction error with r-sparse prototype combinations. Verify bootstrap 90% CI for ϵ_M is < 3%. 2) Fisher dimension test reproduction: Replicate Table 4 bootstrap percentile test for candidate r ∈ {18, 19, 20, 21, 22}. Confirm r=20 is smallest dimension rejecting H₀ at Bonferroni-corrected α = 0.01. 3) Few-shot scaling sweep: Following Table 7, evaluate AUC, F1, and ECE across support sizes {5, 10, 20, 50}. Expect monotonic improvement with latency ~8ms regardless of support size.

## Open Questions the Paper Calls Out
- Does SwiftRepertoire maintain predictive performance and calibration when deployed prospectively in clinical cohorts undergoing routine cancer screening?
- Can the framework be extended to jointly model paired αβ TCR sequences and transcriptomic profiles without sacrificing interpretability?
- Does SwiftRepertoire generalize to non-neoplastic immune conditions such as autoimmune diseases, chronic infections, or vaccine responses?

## Limitations
- All experiments use retrospective public datasets; no prospective validation has been conducted to assess real-world clinical utility
- Current implementation handles single-chain TCR sequences only; joint modeling of paired chains and transcriptomics requires architectural modifications
- No experiments address whether the low-dimensional adapter hypothesis and prototype retrieval mechanism hold for immune signatures in non-cancer contexts

## Confidence

**High Confidence:** The reported AUC scores (0.995 lung, 0.997 thyroid) and their superiority over baselines by at least 2 percentage points are well-supported by ablation studies and few-shot scaling experiments. The mechanism of sparse prototype-based adapter synthesis via constrained proximal optimization is mathematically rigorous and demonstrably effective.

**Medium Confidence:** The Fisher information-based dimension selection and bootstrap hypothesis testing for r=20 are methodologically sound, but the exact behavior of r(N) across diverse pretraining task sets is not fully characterized. The effectiveness of gradient-based task descriptors for immune repertoire tasks lacks direct corpus validation.

**Low Confidence:** The biological interpretability claims (motif-level insights) are promising but are downstream of the adapter synthesis and depend on the quality of the two-stage motif testing pipeline. The generalizability to other immune repertoire tasks beyond cancer detection is not explicitly tested.

## Next Checks

1. **Prototype Coverage Stability**: Replicate the coverage error ϵ_M calculation (Eq. 6) with bootstrap 90% CI on a held-out set of pretraining adapters. Verify that the upper bound remains below 3% and that the 90% CI is tight, confirming that the chosen K prototypes provide adequate coverage for the adapter subspace.

2. **Intrinsic Dimension Saturation**: Conduct a synthetic experiment by progressively adding pretraining tasks and monitoring the Fisher energy explained ratio ζ_r and the bootstrap p-value for r. Confirm that r saturates (e.g., r(N) ≤ 25 for N > 50 tasks), validating the core assumption of a bounded low-dimensional structure.

3. **Descriptor Generalization**: Evaluate the task descriptor (Eq. 10) on a diverse set of unseen immune repertoire tasks (e.g., autoimmune diseases, infectious diseases) not used in retrieval training. Measure the retrieval accuracy (e.g., top-1 prototype retrieval) to assess whether gradient-based descriptors capture sufficient task geometry for robust generalization.