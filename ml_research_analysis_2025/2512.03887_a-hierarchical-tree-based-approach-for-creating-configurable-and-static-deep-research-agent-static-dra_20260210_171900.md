---
ver: rpa2
title: A Hierarchical Tree-based approach for creating Configurable and Static Deep
  Research Agent (Static-DRA)
arxiv_id: '2512.03887'
source_url: https://arxiv.org/abs/2512.03887
tags:
- research
- agent
- deep
- topic
- depth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of building configurable deep
  research agents capable of handling complex, multi-turn research tasks while balancing
  research quality against computational cost. The core method introduces Static-DRA,
  a hierarchical tree-based static workflow governed by two user-tunable parameters,
  Depth and Breadth, which control the intensity of research.
---

# A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)

## Quick Facts
- arXiv ID: 2512.03887
- Source URL: https://arxiv.org/abs/2512.03887
- Authors: Saurav Prateek
- Reference count: 29
- Primary result: Hierarchical tree-based deep research agent with tunable depth and breadth parameters; evaluated at depth=2, breadth=5 achieving 34.72 RACE score.

## Executive Summary
This paper introduces Static-DRA, a hierarchical tree-based static workflow for deep research agents that enables configurable multi-turn research tasks. The system uses Depth and Breadth parameters to balance research quality against computational cost through explicit user control. Evaluated on the DeepResearch Bench using gemini-2.5-pro, the agent achieved an overall score of 34.72 with depth=2 and breadth=5, demonstrating that parameter tuning allows users to trade comprehensiveness for efficiency.

## Method Summary
Static-DRA implements a hierarchical tree-based architecture with three specialized agent types: Supervisor, Independent, and Worker. The Supervisor agent determines whether topics can be decomposed further based on depth and splittability. Independent agents generate sub-queries and spawn child Supervisors with decremented depth and reduced breadth. Worker agents perform web search via Tavily, filter results at 30% relevance threshold, and synthesize research using LLM. The breadth parameter reduces by 2 at each depth level to focus resources on higher-level sub-topics while preventing exponential query growth.

## Key Results
- Static-DRA achieves overall score of 34.72 on DeepResearch Bench with depth=2 and breadth=5
- Higher Depth and Breadth values produce more in-depth research and higher evaluation scores
- The agent offers explicit user control over research intensity through tunable parameters
- System demonstrates resource-aware research capability with transparent computational cost management

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tunable depth and breadth parameters enable explicit user control over the research quality-computational cost tradeoff.
- Mechanism: The system recursively decomposes research topics into a tree of sub-queries. Depth (d) controls maximum recursion levels. Breadth (b) limits sub-topics per level. The number of leaf-node worker executions scales predictably with these parameters, following approximately ∏(max(b−2i,1)) for i=0 to d−1.
- Core assumption: Complex research topics can be meaningfully decomposed into independent, atomic sub-topics that retain coherence when researched separately.
- Evidence anchors:
  - [abstract] "two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity"
  - [section] Section 2.2 defines depth and breadth; Section 5 provides the mathematical formula for computing worker invocations
  - [corpus] Limited direct corpus validation; related work FlashResearch notes similar tradeoffs between orchestration and latency but does not test depth/breadth explicitly
- Break condition: If a topic cannot be decomposed further (STmax reached) or depth=0, the decomposition halts and workers execute research directly.

### Mechanism 2
- Claim: Role-specialized agents with explicit state passing enable multi-hop retrieval and parallel sub-topic investigation.
- Mechanism: Supervisor checks depth and splittability. If splittable, Independent agent generates sub-queries and spawns child Supervisors with depth−1, breadth−2. Workers perform web search + LLM synthesis when depth is exhausted or topics are atomic. Shared state accumulates up the tree for final report consolidation.
- Core assumption: The LLM can reliably judge splittability and generate coherent, non-redundant sub-queries; web search results contain sufficient signal for synthesis.
- Evidence anchors:
  - [abstract] "agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation"
  - [section] Algorithms 1–3 define the control flow; Section 2.5 describes Worker web search with Tavily and relevance filtering at 30% threshold
  - [corpus] Weak direct corpus evidence; FlowSearch and FlashResearch discuss multi-agent orchestration but without this specific hierarchy
- Break condition: If isDifferentResearchTopic fails (duplicate sub-topic), worker execution is skipped to prevent redundant LLM calls.

### Mechanism 3
- Claim: Reducing breadth by 2 at each depth level focuses computational resources on higher-level, more relevant sub-topics while limiting explosion at deeper levels.
- Mechanism: When Independent agents spawn child Supervisors, they pass currentBreadth−2. This decay ensures the tree expands more at the root (broader coverage) and narrows at deeper levels (focused depth), preventing exponential query growth.
- Core assumption: Higher-level sub-topics benefit from broader exploration; deeper sub-topics are inherently more specific and require less parallel coverage.
- Evidence anchors:
  - [abstract] Not explicitly mentioned; implied by "resource-aware solution"
  - [section] Section 2.2 and Algorithm 2 specify breadth−2 reduction; Section 5 formula reflects this in the worker count calculation
  - [corpus] No direct corpus validation; WideSeek discusses breadth scaling but in a different parallel retrieval context
- Break condition: If breadth decays below 1, it is clamped to 1 (via max(b−2i,1)), ensuring at least one sub-topic is explored.

## Foundational Learning

- Concept: **Recursive Tree Traversal with Parameterized Depth/Breadth**
  - Why needed here: The entire Static-DRA workflow is a depth-bounded tree expansion; understanding how parameters control traversal is essential for configuring and debugging the agent.
  - Quick check question: Given depth=3 and breadth=6, what is the approximate maximum number of leaf workers? (Answer: 6×4×2×1 = 48, accounting for breadth decay)

- Concept: **Tool-Augmented LLM Agents**
  - Why needed here: Workers rely on external web search (Tavily) to retrieve context before LLM synthesis; understanding tool-calling patterns is critical for extending or replacing the search backend.
  - Quick check question: What role does the relevance score threshold (30%) play in the Worker's research output?

- Concept: **Shared State Accumulation in Hierarchical Agents**
  - Why needed here: Citations, reports, and research topics are aggregated bottom-up; incorrect state handling causes missing citations or duplicate content in the final report.
  - Quick check question: In Algorithm 3, what happens if a child Supervisor's citations are not extended into the parent's state?

## Architecture Onboarding

- Component map:
  - Supervisor Agent -> Independent Agent -> Worker Agent (leaf nodes)
  - Shared State: depth, breadth, past reports, citations, research topics
  - Report Generator: Consolidates state into markdown

- Critical path: User query → Supervisor (depth check, splittability) → Independent (sub-query generation, spawn Supervisors with depth−1, breadth−2) → Workers (web search + synthesis at leaf nodes) → State aggregation → Final markdown report

- Design tradeoffs:
  - Static vs. Dynamic Workflows: Static-DRA uses predefined decomposition logic; cannot adapt mid-execution based on intermediate findings (unlike dynamic agents referenced in Section 1)
  - Breadth Decay: Reduces query explosion but may miss relevant adjacent topics at deeper levels
  - Relevance Threshold (30%): Filters noise but risks excluding niche but valuable sources; threshold is not dynamically adjusted

- Failure signatures:
  - Empty or sparse reports: Likely caused by Tavily search returning low-relevance results (below 30%) or depth/breadth set too low
  - Duplicate sub-topics: occurs if isDifferentResearchTopic check fails or LLM generates overlapping sub-queries
  - Missing citations: State not properly extended in Algorithm 3 or citation URLs not extracted from search responses
  - Excessive LLM costs: Depth/breadth over-configured for simple queries; breadth decay not applied correctly

- First 3 experiments:
  1. **Baseline calibration**: Run Static-DRA with depth=1, breadth=2 on a simple factual query (e.g., "What is the capital of France?"); verify single Worker execution and correct report structure. Expected: 1 worker, minimal cost, correct output.
  2. **Parameter sweep**: For a multi-faceted query (e.g., investment philosophies of three figures), run configurations (d=1,b=2), (d=2,b=3), (d=2,b=5); compare report length, citation count, and RACE-style manual quality ratings. Correlate with cost (token usage).
  3. **Failure injection**: Set relevance threshold to 90% to intentionally filter most search results; verify Worker produces sparse or empty research output. Then lower to 30% and confirm recovery. This validates the filtering mechanism and helps calibrate threshold sensitivity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the heuristic of reducing the breadth parameter by a factor of 2 at each recursive depth optimal, or does a dynamic decay strategy yield better resource efficiency?
- Basis in paper: [Inferred] from Section 2.2, which states the decision to reduce breadth by 2 per level was a "design decision" to focus on relevant topics, but provides no empirical justification for this specific constant.
- Why unresolved: The paper validates that increasing parameters improves scores, but does not ablate the specific decay function to see if it optimally balances cost and coverage.
- What evidence would resolve it: A comparative analysis of research quality versus cost using constant breadth versus the current reduction strategy.

### Open Question 2
- Question: Does the static workflow architecture inherently limit the upper bound of research quality compared to dynamic, feedback-driven agents?
- Basis in paper: [Inferred] from Table 2, where the Static-DRA (using `gemini-2.5-pro`) scores 34.72, significantly lower than the dynamic `gemini-2.5-pro-deepresearch` benchmark (49.71).
- Why unresolved: While the paper proves configurability, it does not isolate whether the lack of adaptive replanning (dynamic workflow) caps the agent's ability to synthesize complex insights.
- What evidence would resolve it: Error analysis of Static-DRA's "Insight" scores compared to dynamic baselines to determine if the static tree structure prevents necessary pivots during research.

### Open Question 3
- Question: At what specific combinations of Depth and Breadth does the marginal gain in RACE score no longer justify the exponential increase in LLM token costs?
- Basis in paper: [Inferred] from Figure 4 and the Introduction, which highlight the trade-off between "research comprehensiveness and computational cost" but do not define the point of diminishing returns.
- Why unresolved: The paper demonstrates that higher parameters yield higher scores, but it does not model the cost curve to guide users toward the most economical configuration.
- What evidence would resolve it: A Pareto frontier analysis plotting the cost (tokens/requests) against the RACE Overall Score for various Depth and Breadth settings.

## Limitations
- Limited corpus validation: Minimal direct comparison with related work (FlashResearch, FlowSearch) on identical tasks
- Threshold rigidity: Fixed 30% relevance threshold not dynamically adjusted based on topic complexity or search quality
- Static decomposition: Fixed depth/breadth parameters may miss emergent sub-topics that only become relevant after initial research

## Confidence
- **High**: The core mechanism of hierarchical decomposition with tunable depth/breadth parameters is clearly specified and mathematically tractable
- **Medium**: The claim that Static-DRA achieves "resource-aware" research with explicit user control is supported by the parameter system but requires broader empirical validation
- **Low**: The assertion that Static-DRA is a "pragmatic solution" for real-world research tasks lacks external validation and deployment experiences

## Next Checks
1. **Parameter sensitivity analysis**: Run Static-DRA on diverse research queries with varying depth/breadth configurations; measure RACE scores, report coherence, citation diversity, and user-perceived quality
2. **Dynamic threshold testing**: Implement adaptive relevance thresholds that adjust based on search result quality; compare against fixed 30% threshold on same benchmark
3. **Cross-benchmark validation**: Evaluate Static-DRA on external benchmarks like HotpotQA or multi-hop reasoning tasks to test generalizability beyond DeepResearch Bench scope