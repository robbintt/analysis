---
ver: rpa2
title: Comparison of derivative-free and gradient-based minimization for multi-objective
  compositional design of shape memory alloys
arxiv_id: '2508.14127'
source_url: https://arxiv.org/abs/2508.14127
tags:
- optimization
- alloy
- page
- dataset
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study explores the design of high-entropy shape memory alloys\
  \ (HESMAs) by formulating a multi-objective optimization problem to achieve a target\
  \ martensitic start temperature (Ms) while minimizing cost. Two machine learning\
  \ models\u2014a tree-based ensemble and a neural network\u2014were trained using\
  \ experimental data and physics-informed features."
---

# Comparison of derivative-free and gradient-based minimization for multi-objective compositional design of shape memory alloys

## Quick Facts
- arXiv ID: 2508.14127
- Source URL: https://arxiv.org/abs/2508.14127
- Reference count: 0
- Multi-objective optimization of high-entropy shape memory alloys to achieve target martensitic start temperature while minimizing cost

## Executive Summary
This study compares derivative-free and gradient-based optimization approaches for designing high-entropy shape memory alloys (HESMAs) with target martensitic start temperatures and minimal cost. Two machine learning models - a tree-based ensemble and a neural network - were trained on experimental data to predict Ms temperatures. The tree-based model was paired with the COBYLA optimizer, while the differentiable neural network was paired with TRUST-CONSTR. Results show that while both models achieve comparable prediction accuracy, the gradient-based TRUST-CONSTR approach demonstrates superior convergence reliability and efficiency in finding optimal alloy compositions that satisfy both Ms and cost objectives.

## Method Summary
The research formulates a multi-objective optimization problem to design HESMAs with target martensitic start temperatures (Ms) while minimizing material costs. Two machine learning models are trained: a tree-based ensemble and a neural network, both using experimental data and physics-informed features. The tree-based model employs a derivative-free optimizer (COBYLA), while the neural network, being differentiable, uses a gradient-based optimizer (TRUST-CONSTR). The study evaluates both approaches across a range of target Ms temperatures (50-200°C) and compares their performance in terms of prediction accuracy, convergence behavior, and ability to identify optimal alloy compositions.

## Key Results
- Both tree-based and neural network models predict Ms with comparable accuracy
- TRUST-CONSTR gradient-based optimizer converges more reliably and efficiently than COBYLA
- TRUST-CONSTR consistently identifies alloy compositions meeting both Ms and cost objectives
- Gradient-based approach outperforms derivative-free method in multi-objective compositional design

## Why This Works (Mechanism)
The gradient-based optimization leverages the differentiability of neural networks to efficiently navigate the composition space, while derivative-free methods must explore through function evaluations. The neural network's smooth response surface allows gradient information to guide optimization toward promising regions, reducing the number of evaluations needed. This is particularly effective for multi-objective problems where trade-offs between properties must be balanced.

## Foundational Learning
- Martensitic transformation: Why needed - Central to shape memory behavior; Quick check - Ms temperature prediction accuracy
- Multi-objective optimization: Why needed - Balancing performance vs. cost in alloy design; Quick check - Pareto frontier analysis
- Physics-informed features: Why needed - Improves model generalization with limited data; Quick check - Feature importance analysis
- Differentiable vs non-differentiable models: Why needed - Determines optimizer choice; Quick check - Gradient computation feasibility
- Derivative-free vs gradient-based optimization: Why needed - Different convergence characteristics; Quick check - Convergence rate comparison

## Architecture Onboarding

**Component Map:**
Data (45 experimental alloys) -> ML Models (Tree Ensemble, Neural Network) -> Optimizers (COBYLA, TRUST-CONSTR) -> Alloy Compositions

**Critical Path:**
ML model training → Prediction accuracy validation → Optimizer selection based on model differentiability → Multi-objective optimization → Composition recommendation

**Design Tradeoffs:**
- Model complexity vs. interpretability (neural network vs. tree ensemble)
- Optimizer speed vs. exploration capability (gradient-based vs. derivative-free)
- Physics-informed features vs. pure data-driven approach
- Prediction accuracy vs. optimization efficiency

**Failure Signatures:**
- Poor convergence with COBYLA on complex objective landscapes
- Overfitting in ML models leading to unrealistic predictions
- Gradient vanishing/exploding in neural network training
- Local optima trapping in multi-objective space

**First 3 Experiments:**
1. Train both models and validate Ms prediction accuracy on held-out data
2. Run single-objective optimization (Ms only) to compare optimizer convergence
3. Execute full multi-objective optimization for target Ms = 100°C with cost minimization

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset of only 45 experimental compositions limits model generalization
- Focus on specific Ms range (50-200°C) and cost constraints may not capture full design complexity
- Assumes complete understanding of underlying material science through physics-informed features
- Binary comparison of optimization methods without exploring hybrid approaches

## Confidence

**High Confidence:**
- Gradient-based TRUST-CONSTR optimizer outperforms COBYLA in efficiency and reliability

**Medium Confidence:**
- Framework applicability to other alloy systems beyond the studied HESMAs

**Low Confidence:**
- Long-term stability and performance of predicted alloys without experimental validation

## Next Checks
1. Expand dataset to include more diverse alloy compositions and experimental conditions
2. Validate optimized alloy compositions through experimental synthesis and testing
3. Explore hybrid optimization methods combining derivative-free and gradient-based approaches