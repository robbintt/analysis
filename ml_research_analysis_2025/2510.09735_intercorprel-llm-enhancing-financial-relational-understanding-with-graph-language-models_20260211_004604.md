---
ver: rpa2
title: 'InterCorpRel-LLM: Enhancing Financial Relational Understanding with Graph-Language
  Models'
arxiv_id: '2510.09735'
source_url: https://arxiv.org/abs/2510.09735
tags:
- company
- graph
- supply
- name
- chain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces InterCorpRel-LLM, a graph-language model
  framework for identifying inter-firm relationships such as supply chains and competition
  using a combination of GNNs and LLMs. The method integrates structural graph data
  with financial text, trained on a proprietary dataset from FactSet, using tasks
  like company graph matching, industry classification, and supply relation prediction.
---

# InterCorpRel-LLM: Enhancing Financial Relational Understanding with Graph-Language Models

## Quick Facts
- arXiv ID: 2510.09735
- Source URL: https://arxiv.org/abs/2510.09735
- Reference count: 40
- Primary result: Achieves F1-score of 0.8543 on supply relation prediction versus 0.2287 for text-only baselines

## Executive Summary
This paper introduces InterCorpRel-LLM, a graph-language model framework that identifies inter-firm relationships such as supply chains and competition by combining GNNs with LLMs. The method integrates structural graph data with financial text, trained on a proprietary FactSet dataset, using tasks like company graph matching, industry classification, and supply relation prediction. Experiments show the model significantly outperforms baselines, achieving an F-score of 0.8543 versus 0.2287 on supply relation prediction and strong zero-shot competitor identification, using only a 7B-parameter backbone with lightweight training.

## Method Summary
The method uses a two-stage training approach with frozen Vicuna-7B LLM and pretrained GraphGPT GNN. Stage I performs self-supervised company graph matching to align 1-hop subgraph embeddings with company names. Stage II jointly trains on industry classification and supply relation prediction tasks. The Alignment Module (single FC layer) projects GNN embeddings into LLM token space, enabling the frozen LLM to reason over both text and graph structure. The model uses 128-dim embeddings from Qwen3-Embedding-8B and operates on FactSet supply chain data with 3,211 US firms.

## Key Results
- Supply relation prediction: F1-score of 0.8543 (vs. 0.2287 for text-only)
- Zero-shot competitor identification: F1-score of 0.7774 without competitor-specific training
- Stage I only model achieves F1-score of ~0.56, demonstrating need for both stages

## Why This Works (Mechanism)

### Mechanism 1: Lightweight Cross-Modal Projection
Mapping structural graph embeddings directly into the LLM's token space via a trained projector enables the language model to "read" network topology without expensive re-training. The architecture uses a lightweight Alignment Module (a single fully connected layer) to translate GNN outputs into graph tokens. These tokens are prepended to text tokens, allowing the frozen Vicuna-7B backbone to condition its reasoning on both semantic text and structural neighborhood data.

### Mechanism 2: Curriculum-Based Task Grounding
Performance gains are driven by a two-stage curriculum that first establishes entity-structure grounding before attempting complex relationship inference. Stage I (Company Graph Matching) forces the model to associate specific graph tokens with company names, creating a "structural dictionary." Stage II (Industry/Supply Prediction) then builds upon this dictionary to perform complex reasoning (e.g., predicting links).

### Mechanism 3: Inductive Relational Transfer
Training on supply chain topology induces a generalizable understanding of business ecosystems that transfers zero-shot to competitor identification. By learning to predict supplier-customer links (often vertical relationships), the model implicitly learns industry clusters and peer positioning. When asked to identify competitors (horizontal relationships), the model utilizes the learned structural proximity and industry similarity from supply training to infer rivalry.

## Foundational Learning

- **Concept: Graph Neural Networks (GNNs) & Message Passing**
  - Why needed here: The Graph Module uses a GNN to convert the discrete supply chain topology into continuous embeddings. You must understand that the GNN aggregates information from a node's neighbors (message passing) to create a context-aware vector.
  - Quick check question: If a company has no connections in the supply graph, would the GNN embedding still capture its context? (Answer: Only its self-features, limiting structural reasoning).

- **Concept: Parameter-Efficient Fine-Tuning (PEFT)**
  - Why needed here: The architecture relies on freezing the LLM backbone and training only a tiny fraction of parameters (the projector). Understanding PEFT is critical to grasping why a 7B model can be trained efficiently on specific tasks without catastrophic forgetting.
  - Quick check question: Why is the Vicuna-7B backbone kept "frozen" during the optimization of the Alignment Module?

- **Concept: Contrastive Learning (CLIP-style)**
  - Why needed here: The Graph Module utilizes a contrastive framework to align graph and text representations. Understanding that this pulls "positive" pairs (same firm's graph+text) closer while pushing "negative" pairs apart is key to understanding the embedding quality.
  - Quick check question: In the context of this paper, what constitutes a "positive" pair for the contrastive learner? (Answer: The graph embedding of a firm and the text embedding of that same firm's annual report).

## Architecture Onboarding

- **Component map:** Company Info Producer -> Graph Module -> Alignment Module -> LLM Module
- **Critical path:** Raw Annual Reports -> Summarization -> Embedding -> GNN (with Neighborhood Aggregation) -> Projector -> Token Sequence -> LLM -> Probability Distribution
- **Design tradeoffs:**
  - 128-dim Embedding: Low storage/compute cost, but risks losing nuance in complex financial text
  - Frozen Backbone: High efficiency and stability, but limits the model's ability to fundamentally alter its internal reasoning logic for finance-specific jargon
  - 1-hop Subgraphs: Limits computational complexity (context window), but may miss indirect (multi-hop) dependencies in the supply chain
- **Failure signatures:**
  - Text-Only Hallucination: If the projector outputs near-zero values, the model ignores graph tokens and defaults to LLM internal knowledge
  - Overfitting to Memorization: High performance on "Inductive" (seen firms) but low performance on "Fully Inductive" (unseen firms) indicates the model memorized specific node IDs rather than learning structural patterns
- **First 3 experiments:**
  1. Sanity Check - Token Ablation: Run the model with the Alignment Module disabled or randomized to verify that the performance drop matches the "Text-Only" baselines
  2. Projector Analysis: Visualize the projector output (t-SNE/PCA) for companies in the same industry vs. different industries to confirm that structural separation exists in the projected space
  3. Hop Sensitivity: Test the model using 2-hop neighborhoods instead of 1-hop on a small sample to determine if performance gains justify the increased context window cost

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on proprietary FactSet data, making independent verification difficult
- Alignment Module architecture underspecified (exact dimensions and activation functions not provided)
- Training procedure lacks critical hyperparameters (learning rate, batch size, epoch count, loss weighting)

## Confidence

| Claim | Confidence |
|-------|------------|
| Architectural concept of projecting graph embeddings into LLM token space is technically sound | High |
| Two-stage curriculum approach is logical | Medium |
| Zero-shot competitor identification results generalize beyond FactSet dataset | Low |

## Next Checks
1. Implement the Alignment Module with multiple configurations (different dimensions, activation functions) and test if performance is robust to these choices
2. Reproduce the supply relation prediction task using a publicly available supply chain dataset to verify claims hold beyond FactSet data
3. Test model performance on supply chain predictions for firms across multiple years to assess whether learned patterns persist over time or degrade due to market changes