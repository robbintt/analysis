---
ver: rpa2
title: 'InterGridNet: An Electric Network Frequency Approach for Audio Source Location
  Classification Using Convolutional Neural Networks'
arxiv_id: '2502.10011'
source_url: https://arxiv.org/abs/2502.10011
tags:
- power
- grid
- audio
- classification
- recordings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InterGridNet introduces a novel framework for geolocation classification
  of audio recordings using Electric Network Frequency (ENF) signatures. The method
  employs a shallow RawNet model optimized via Neural Architecture Search (NAS) to
  classify recordings into nine power grid categories based on ENF characteristics.
---

# InterGridNet: An Electric Network Frequency Approach for Audio Source Location Classification Using Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2502.10011
- Source URL: https://arxiv.org/abs/2502.10011
- Authors: Christos Korgialas; Ioannis Tsingalis; Georgios Tzolopoulos; Constantine Kotropoulos
- Reference count: 36
- Primary result: 92% accuracy on SP Cup 2016 dataset for grid location classification using ENF signatures

## Executive Summary
InterGridNet introduces a novel framework for geolocation classification of audio recordings using Electric Network Frequency (ENF) signatures. The method employs a shallow RawNet model optimized via Neural Architecture Search (NAS) to classify recordings into nine power grid categories based on ENF characteristics. Recordings are preprocessed by categorizing them into audio/power and 50/60 Hz groups using spectrogram analysis, then filtered to isolate the relevant ENF signal. The model achieves an overall accuracy of 92% on the SP Cup 2016 dataset, outperforming state-of-the-art methods.

## Method Summary
The framework preprocesses recordings by categorizing them into four groups (Audio 50Hz, Audio 60Hz, Power 50Hz, Power 60Hz) using spectrogram magnitude analysis. Each group is then bandpass filtered around its nominal frequency (49-51 Hz for 50Hz, 59-61 Hz for 60Hz) to isolate the ENF signature. The filtered signals are segmented into 16-second frames with 50% overlap and normalized to [-1, 1]. Four separate shallow RawNet models are trained using NAS-optimized hyperparameters, with architecture consisting of strided convolution, two residual blocks, GRU, and dense layers. Classification decisions use entropy-based rejection (α₁=0.8) and majority voting (α₂=0.75).

## Key Results
- Achieves 92% overall accuracy on SP Cup 2016 dataset for 9-class grid classification
- Outperforms prior state-of-the-art methods (86-88% accuracy)
- Demonstrates effectiveness of deep learning for geolocation estimation using ENF signatures
- Ablation study shows 72% accuracy without bandpass filtering, highlighting preprocessing importance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Isolating the frequency band around the nominal Electric Network Frequency (ENF) is a causal prerequisite for high classification accuracy.
- **Mechanism:** The framework applies a 2 Hz bandpass filter (e.g., 59–61 Hz) to raw audio, stripping away wideband noise and retaining only the grid-specific frequency fluctuations. This forces the model to learn from the ENF signature rather than irrelevant acoustic features.
- **Core assumption:** The informative features for geolocation reside strictly within the immediate frequency neighborhood of the nominal 50 Hz or 60 Hz power signal.
- **Evidence anchors:**
  - [abstract] Mentions filtering to isolate the relevant ENF signal.
  - [section IV-B] Reports that removing bandpass filtering drops accuracy from 92% to 72%, isolating the causal contribution of this preprocessing step.
  - [corpus] Weak direct link; however, "Spectral and Rhythm Feature Performance..." implies spectral isolation is a standard preprocessing efficacy in audio tasks.
- **Break condition:** If recordings have severe sampling rate artifacts or the ENF harmonic used for filtering is corrupted, the isolation fails, and the model input becomes noise.

### Mechanism 2
- **Claim:** Hierarchical data routing (splitting by recording type and nominal frequency) reduces the complexity of the classification boundary.
- **Mechanism:** By separating data into four distinct groups (Audio 50Hz, Audio 60Hz, Power 50Hz, Power 60Hz) before inference, the system prevents the model from having to learn the distinct spectral differences between 50Hz and 60Hz grids or high-SNR Power vs. low-SNR Audio signals. It reduces a 9-class problem into smaller, independent sub-problems.
- **Core assumption:** The distinction between 50Hz and 60Hz grids is trivially separable via spectrogram analysis, and the model should not waste capacity learning it.
- **Evidence anchors:**
  - [abstract] Describes preprocessing by categorizing recordings into audio/power and 50/60 Hz groups.
  - [section III-A] Details the automated grouping method based on average spectrogram magnitude.
  - [corpus] "HMCGeo" supports the efficacy of hierarchical classification strategies for location prediction tasks.
- **Break condition:** If the automated spectrogram analysis misclassifies a 60Hz recording as 50Hz (or vice versa), the signal is passed to the wrong inference pipeline, guaranteeing a misclassification.

### Mechanism 3
- **Claim:** A shallow RawNet architecture using residual blocks and GRU units can extract frame-level embeddings that preserve temporal ENF variations.
- **Mechanism:** The residual blocks extract local spectral features from the raw waveform frame, while the GRU aggregates these frame-level embeddings into a single vector that captures the temporal evolution of the frequency, which is the signature of the specific power grid.
- **Core assumption:** The ENF signature is encoded in the temporal fluctuations of the frequency, requiring a sequential model (GRU) rather than just static spectral features.
- **Evidence anchors:**
  - [abstract] States residual blocks extract frame-level embeddings and are processed for decision-making.
  - [section III-B] Describes the flow: Residual blocks $\rightarrow$ GRU $\rightarrow$ Dense $\rightarrow$ Softmax.
  - [corpus] "Spectral and Rhythm Feature Performance..." confirms CNNs are effective for audio classification, though InterGridNet specifically relies on the raw-waveform processing variant.
- **Break condition:** If the recording length is too short to capture meaningful frequency fluctuation dynamics, the GRU cannot form a representative temporal embedding.

## Foundational Learning

- **Concept: Electric Network Frequency (ENF)**
  - **Why needed here:** This is the core physical phenomenon the model exploits. You must understand that power grids have a nominal frequency (50/60Hz) that fluctuates slightly based on load, creating a unique "fingerprint" for each grid at a specific time.
  - **Quick check question:** Would a recording from a battery-powered device in the same room contain the ENF signal? (Answer: Likely not, unless via electromagnetic induction; usually requires proximity to mains-powered devices).

- **Concept: RawNet Architecture**
  - **Why needed here:** The paper uses a specific DNN topology designed for raw audio (RawNet). Understanding that it combines Convolutional layers (for feature extraction) with GRUs (for sequence aggregation) is vital for debugging the model.
  - **Quick check question:** Why use a GRU after the convolutional blocks instead of Global Average Pooling? (Answer: To capture the temporal sequence of the ENF variations, not just the average spectral content).

- **Concept: Neural Architecture Search (NAS)**
  - **Why needed here:** The authors did not hand-pick all hyperparameters; they used Keras-Tuner. Understanding this explains why the model has specific filter sizes (128, 256) and learning rates.
  - **Quick check question:** If the validation accuracy is poor, should you manually increase the network depth or re-run the search space? (Answer: Re-evaluate the search space constraints defined in Section III-B).

## Architecture Onboarding

- **Component map:** Pre-processor (spectrogram-based grouping) → Filter Bank (±1 Hz bandpass) → Encoder (Shallow RawNet) → Decision Logic (entropy threshold + majority voting)

- **Critical path:** The **Pre-processor → Filter** stage is the highest risk. If the initial 50/60Hz detection fails, the wrong bandpass filter is applied, and the signal is zeroed out or distorted before reaching the neural network.

- **Design tradeoffs:**
  - **Shallow vs. Deep:** Authors chose a shallow RawNet (7M params) over a deeper fusion model (11M+ params), trading potential peak accuracy (96% vs 92%) for a unified, parameter-efficient architecture.
  - **Frame-based vs. Global:** The model uses 16-second frames with majority voting rather than processing the whole file at once, increasing robustness to transient noise but adding complexity to the aggregation logic.

- **Failure signatures:**
  - **High "None" Rate:** If the model classifies too many samples as "None," check the entropy threshold α1 (Equation 1). It may be too conservative (0.8).
  - **Low Accuracy (approx. 72%):** Check if the bandpass filtering is disabled. The paper explicitly links this drop to the absence of filtering.

- **First 3 experiments:**
  1. **Validation of Splitter:** Run the spectrogram-based grouping logic on the validation set to ensure 50/60Hz and Audio/Power categorization accuracy is near 100%.
  2. **Ablation on Filtering:** Train the model on raw frames *without* the bandpass filter to reproduce the 72% baseline and verify the data pipeline is functioning as described.
  3. **Hyperparameter Sensitivity:** Vary the learning rate and β values slightly from the optimized NAS values (Table I) to see if the model is overfitting to the specific validation set or if it is robust.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can transformer-based architectures outperform the optimized shallow RawNet in accuracy or parameter efficiency for ENF-based grid location classification?
  - **Basis in paper:** [explicit] The conclusion states: "Future research will employ a transformer architecture for grid location classification."
  - **Why unresolved:** The current work focuses exclusively on CNN-based residual blocks and GRU layers; the potential of attention-based mechanisms for this specific task remains untested.
  - **What evidence would resolve it:** Comparative benchmarking results on the SP Cup 2016 dataset between the proposed RawNet and a transformer-based model regarding accuracy and inference time.

- **Open Question 2:** Which specific temporal or spectral patterns in the ENF signal does the deep learning model identify as discriminative for each grid?
  - **Basis in paper:** [explicit] The conclusion notes: "To enhance transparency... explainable AI (xAI) techniques will also be integrated to extract specific patterns associated with each grid."
  - **Why unresolved:** Unlike analytical methods, the current deep learning approach acts as a "black box," leaving the exact features driving the 92% accuracy unexplained.
  - **What evidence would resolve it:** Visualization of gradient-weighted class activation maps (Grad-CAM) or similar xAI outputs highlighting signal regions critical to classification.

- **Open Question 3:** How can the entropy-based decision rule be refined to reduce the rate of false "None" classifications for valid inputs?
  - **Basis in paper:** [inferred] The discussion notes that "misclassifications by InterGridNet predominantly categorize samples as 'None' (class N)," identifying this as a vulnerability of the entropy rule (Eq. 1).
  - **Why unresolved:** The current threshold (α₁) prioritizes high confidence, potentially rejecting valid recordings that exhibit borderline entropy levels.
  - **What evidence would resolve it:** An ablation study testing alternative threshold values or probabilistic rejection criteria that lower the false negative rate for the "None" class.

## Limitations
- Sampling rate not explicitly stated, though frame size implies ~1000 Hz
- Bandpass filter type and order are unspecified
- Optimal GRU units not reported (only search range 512-1024)
- Training details (batch size, epochs, early stopping) are missing

## Confidence
- **High confidence:** The 92% accuracy result on SP Cup 2016 dataset and the core claim that shallow RawNet with ENF filtering outperforms prior methods.
- **Medium confidence:** The mechanism claims about preprocessing hierarchy and residual block effectiveness, as these are well-supported but depend on precise implementation details.
- **Low confidence:** Exact hyperparameter values and training procedure details needed for faithful reproduction.

## Next Checks
1. **Sampling rate verification:** Confirm the dataset's sampling rate and verify the 15,999-sample frame size calculation is correct for 16 seconds.
2. **Bandpass filter replication:** Implement the ENF bandpass filtering using a Butterworth or equivalent filter and verify the 59-61 Hz and 49-51 Hz ranges are correctly centered on nominal frequencies.
3. **Preprocessing pipeline accuracy:** Validate the spectrogram-based 50/60Hz categorization on a subset of recordings to ensure correct routing before training.