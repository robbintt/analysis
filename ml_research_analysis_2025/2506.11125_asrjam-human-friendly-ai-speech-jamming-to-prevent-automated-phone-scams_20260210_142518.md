---
ver: rpa2
title: 'ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams'
arxiv_id: '2506.11125'
source_url: https://arxiv.org/abs/2506.11125
tags:
- speech
- audio
- echoguard
- human
- acoustic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the growing threat of AI-driven voice phishing
  scams by introducing ASRJam, a proactive defense framework that disrupts automatic
  speech recognition (ASR) systems used by scammers. The core method, EchoGuard, generates
  adversarial audio perturbations based on natural distortions like reverberation
  and echo, which degrade ASR accuracy while remaining tolerable to human listeners.
---

# ASRJam: Human-Friendly AI Speech Jamming to Prevent Automated Phone Scams

## Quick Facts
- **arXiv ID:** 2506.11125
- **Source URL:** https://arxiv.org/abs/2506.11125
- **Reference count:** 40
- **One-line primary result:** EchoGuard achieves 19.6% higher jamming success rate and 2.12× utility index compared to state-of-the-art ASR jamming attacks while maintaining human perceptual quality.

## Executive Summary
ASRJam introduces EchoGuard, a framework that disrupts automated speech recognition systems used in phone scams while preserving human comprehension. The approach leverages natural acoustic distortions—reverberation, microphone oscillation, and transient attenuation—that degrade ASR accuracy but remain tolerable to human listeners. Through an evolutionary optimization process, EchoGuard generates adversarial perturbations that achieve superior ASR disruption compared to existing methods while maintaining better perceptual quality according to user studies.

## Method Summary
The EchoGuard algorithm combines three signal transformations: (1) reverberation via convolution with room impulse responses optimized through genetic algorithm, (2) microphone oscillation simulating directional variation at 5 Hz using blended impulse responses, and (3) transient attenuation applying Gaussian-shaped amplitude reductions to 30% of 20 ms frames. The system processes audio in real-time at 10 ms frame intervals, optimizing parameters offline to maximize ASR disruption while preserving human intelligibility. The method was evaluated against three state-of-the-art baselines (Kenku, Kenansville, AdvDDoS) on benchmark datasets (TEDLIUM, SPGISpeech, LibriSpeech) using WER and jamming success rate metrics, with user studies measuring perceptual quality.

## Key Results
- EchoGuard achieved 19.6% higher jamming success rate compared to baseline methods
- EchoGuard was rated significantly more pleasant to listen to while maintaining similar clarity
- Whisper model showed highest resistance (only 14% jamming success) among tested ASRs
- EchoGuard achieved 2.12× higher utility index than competing approaches

## Why This Works (Mechanism)

### Mechanism 1: Reverberation Smearing
- Claim: Room impulse responses convolved with speech degrade ASR accuracy more than human intelligibility.
- Mechanism: Convolution with delayed/attenuated reflections blurs phoneme boundaries and spectral-temporal landmarks that ASR relies on, while human auditory systems segregate primary voice from echoes through neural adaptation.
- Core assumption: ASR training datasets underrepresent diverse reverberant conditions, creating a robustness gap.

### Mechanism 2: Microphone Oscillation (Directional Variation)
- Claim: Simulated rotating microphone introduces dynamic directional changes that destabilize ASR spectral-temporal patterns.
- Mechanism: Blending multiple directional impulse responses using time-varying raised-cosine windows creates continuous acoustic variation. Humans compensate via stereo hearing; ASR expects stationary patterns.
- Core assumption: Real-time ASR systems lack mechanisms to handle rapidly shifting directional cues.

### Mechanism 3: Transient Acoustic Attenuation
- Claim: Brief (~20-80 ms) Gaussian-shaped amplitude reductions disproportionately affect ASR while human listeners cognitively interpolate gaps.
- Mechanism: Random selection of 30% of 20 ms frames for attenuation disrupts stable acoustic features ASR uses for phoneme classification, with minimal perceptual cost to humans.
- Core assumption: ASR lacks contextual reconstruction capabilities that humans possess.

## Foundational Learning

- Concept: **Word Error Rate (WER)**
  - Why needed here: Primary metric for quantifying ASR transcription degradation under jamming.
  - Quick check question: If a 100-word reference produces 5 substitutions, 3 deletions, and 2 insertions, what is the WER? (Answer: 10%)

- Concept: **Room Impulse Response (RIR)**
  - Why needed here: Mathematical representation of how an acoustic environment transforms sound; core to EchoGuard's reverberation-based perturbation.
  - Quick check question: What does convolving speech with an RIR simulate? (Answer: Reverberation/echoes in a specific room)

- Concept: **Short-Time Objective Intelligibility (STOI)**
  - Why needed here: Perceptual metric (0-1 scale) used in fitness function to preserve human comprehension while maximizing ASR disruption.
  - Quick check question: Higher STOI indicates what? (Answer: Better predicted human intelligibility)

## Architecture Onboarding

- Component map: Evolutionary Optimizer -> RIR Generator -> Oscillation Blender -> Attenuation Module -> Real-time Pipeline
- Critical path: Parameter optimization (offline) → RIR precomputation → Real-time convolution + oscillation + attenuation → Perturbed audio output
- Design tradeoffs:
  - Lower absorption coefficient → higher ASR degradation but lower pleasantness (tunable via utility index)
  - Rotation frequency: Higher frequencies disrupt ASR more but risk perceptibility
  - Attenuation depth/frequency: Aggressive settings improve jamming but reduce clarity
- Failure signatures:
  - Whisper model shows lowest degradation (~14% jamming success on LibriSpeech) — likely due to large-scale diverse training data
  - Over-attenuation creates "underwater" sound quality
  - Excessive reverberation makes speech mushy for humans
- First 3 experiments:
  1. Reproduce Table III results on DeepSpeech and Whisper with EchoGuard vs. Kenku/Kenansville/AdvDDoS on LibriSpeech test set
  2. Ablate each component (reverberation only, oscillation only, attenuation only) to measure individual contribution to jamming success rate
  3. Run user study (n≥20) with modified absorption coefficients to map pleasantness/clarity tradeoff curve

## Open Questions the Paper Calls Out

- How resilient is EchoGuard against adaptive adversaries who specifically train or fine-tune their ASR models on EchoGuard-augmented data?
- To what extent does EchoGuard's textual degradation actually disrupt LLM reasoning capabilities in scam scenarios?
- How does EchoGuard's effectiveness degrade when transmitted over lossy telephony codecs and real-world network conditions?
- Can EchoGuard's acoustic parameters be dynamically tuned in real-time based on user suspicion levels?

## Limitations

- The fitness function combining WER and STOI lacks mathematical detail, making it difficult to verify parameter optimality
- User study methodology lacks sample size, demographic diversity, and statistical significance testing details
- Results depend on ASR models being trained on clean, non-reverberant data, which may not hold for modern systems
- Long-term effectiveness against evolving ASR systems is not addressed

## Confidence

High confidence in: The core acoustic mechanisms and their general disruptive effect on ASR, signal processing pipeline and real-time implementation details

Medium confidence in: Specific parameter values and their optimality, user study results and utility index comparisons

Low confidence in: Long-term effectiveness against evolving ASR systems and adaptive adversaries

## Next Checks

1. Replicate the parameter optimization process with different random seeds to assess solution stability and convergence properties
2. Test EchoGuard against a broader range of contemporary ASR systems including those with built-in reverberation robustness
3. Conduct a larger-scale user study with diverse demographics and controlled listening environments with statistical power analysis