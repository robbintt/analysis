---
ver: rpa2
title: 'FedRSClip: Federated Learning for Remote Sensing Scene Classification Using
  Vision-Language Models'
arxiv_id: '2501.02461'
source_url: https://arxiv.org/abs/2501.02461
tags:
- learning
- federated
- data
- prompt
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedRSCLIP, the first federated learning framework
  designed for remote sensing image classification using Vision-Language Models (VLMs),
  specifically CLIP. Traditional federated learning faces challenges in handling VLMs
  due to their large parameter sizes, leading to high communication costs and difficulties
  in managing data heterogeneity.
---

# FedRSClip: Federated Learning for Remote Sensing Scene Classification Using Vision-Language Models

## Quick Facts
- arXiv ID: 2501.02461
- Source URL: https://arxiv.org/abs/2501.02461
- Reference count: 40
- First federated learning framework for RS scene classification using VLMs (CLIP)

## Executive Summary
This paper introduces FedRSCLIP, the first federated learning framework designed for remote sensing image classification using Vision-Language Models (VLMs), specifically CLIP. Traditional federated learning faces challenges in handling VLMs due to their large parameter sizes, leading to high communication costs and difficulties in managing data heterogeneity. To address these issues, FedRSCLIP employs Prompt Learning to optimize only a small set of tunable parameters, significantly reducing communication overhead while maintaining model adaptability.

## Method Summary
FedRSCLIP introduces a dual-prompt mechanism for federated learning with Vision-Language Models in remote sensing. The framework employs Prompt Learning to optimize only learnable prompt vectors (instead of full model gradients), drastically reducing communication costs. It introduces Shared Prompts for global knowledge aggregation and Private Prompts for client-specific adaptation, addressing data heterogeneity. Two alignment constraints ensure semantic coherence: Dual Prompt Alignment (via metric learning) and Cross-Modal Feature Alignment (via Optimal Transport). The method is validated on Fed-RSIC, a newly constructed dataset combining three popular RS image classification datasets.

## Key Results
- Achieves 94.46% accuracy on Fed-Optimal dataset with 40 clients (vs 91.94% for best baseline)
- Transmits only 2,048 parameters per round, significantly reducing communication overhead
- Outperforms traditional methods across various federated learning configurations

## Why This Works (Mechanism)

### Mechanism 1: Parameter-Efficient Communication via Prompt Tuning
If you freeze the Vision-Language Model (VLM) backbone and optimize only a small set of input vectors (prompts), you can drastically reduce federated learning communication costs while retaining adaptability. Instead of transmitting millions of model gradients, the system transmits only the learnable prompt vectors (specifically, the "Shared Prompts"). The VLM acts as a fixed feature extractor, while the prompts steer the representation space. The frozen VLM (CLIP) has sufficient pre-trained knowledge to handle remote sensing features, requiring only "steering" rather than full fine-tuning.

### Mechanism 2: Decoupling Global Consensus and Local Drift via Dual Prompts
If the system separates learnable parameters into "Shared" (global) and "Private" (local) sets, it can mitigate the "client drift" caused by non-IID remote sensing data. A **Shared Prompt** is aggregated across all clients (via server averaging) to capture common features. A **Private Prompt** remains local and unshared, allowing the model to adapt to specific client distributions without polluting the global model. The optimal decision boundary for a specific client can be decomposed into a global component (shared) and a local residual (private).

### Mechanism 3: Semantic Coherence via Optimal Transport Alignment
Aligning cross-modal features (image vs. text) and prompt features (shared vs. private) using Optimal Transport (OT) improves representation learning better than standard cosine similarity alone. The **Cross-Modal Feature Alignment Constraint** minimizes the Wasserstein distance between image and text features, treating alignment as a transport problem. The **Dual Prompt Alignment Constraint** uses a metric-learning loss to ensure private prompts do not deviate semantically from shared prompts. There exists a structured geometry in the feature space that can be mapped effectively between modalities and clients using a transport plan.

## Foundational Learning

- **Concept: Vision-Language Models (CLIP)**
  - **Why needed here:** The entire architecture relies on a pre-trained CLIP model to process remote sensing images and text prompts jointly. You must understand how contrastive pre-training maps images and text to a shared latent space.
  - **Quick check question:** If you input an image of a forest and the text "a photo of a forest," should the cosine similarity be high or low?

- **Concept: Federated Averaging (FedAvg)**
  - **Why needed here:** This is the base communication protocol. The server aggregates the "Shared Prompts" using a weighted average. Understanding how local updates are combined is crucial for diagnosing convergence issues.
  - **Quick check question:** In FedAvg, does the server see the raw data or the model gradients?

- **Concept: Prompt Learning (e.g., CoOp)**
  - **Why needed here:** Instead of manual prompts like "a photo of a [CLASS]," the system learns continuous vectors. This is the "tunable knob" of the architecture.
  - **Quick check question:** Are the prompt vectors optimized via backpropagation, or are they hard-coded rules?

## Architecture Onboarding

- **Component map:** Frozen CLIP ViT-Base (Image Encoder + Text Encoder) -> Learnable Shared Prompts + Private Prompts -> Cross-Modal Alignment (OT) + Dual Prompt Alignment -> FedAvg aggregation (Shared only)

- **Critical path:**
  1. Client initializes local Shared Prompt (from server) and Private Prompt (local)
  2. Local Forward Pass: Concatenate Shared and Private Prompts -> Feed to Text Encoder
  3. Compute Alignment Losses (OT and Prompt Alignment)
  4. Backprop: Update Shared and Private Prompts (Backbone is frozen)
  5. Communication: Upload updated Shared Prompts to server; keep Private Prompts local

- **Design tradeoffs:**
  - **Scalability vs. Personalization:** Increasing Private Prompt size allows better local fit but increases local computation and risks overfitting
  - **OT Complexity:** The Optimal Transport alignment is more computationally expensive than simple cosine similarity but provides finer alignment

- **Failure signatures:**
  - **Semantic Drift:** Private prompts diverge too far from shared prompts, indicated by high alignment loss and poor global generalization
  - **Feature Misalignment:** If the OT transport plan fails to converge, the text-to-image matching accuracy will drop significantly

- **First 3 experiments:**
  1. **Sanity Check (Centralized):** Train FedRSCLIP on a single client to ensure the prompt learning mechanism functions correctly without FL noise
  2. **Communication Efficiency:** Compare test accuracy vs. transmitted parameter count against standard FedAvg (ViT-Base) to verify the 2KB transmission advantage
  3. **Heterogeneity Stress Test:** Run the ablation study with/without the Private Prompt on the highest client count (40 clients) to observe resilience to data fragmentation

## Open Questions the Paper Calls Out

### Open Question 1
How does FedRSCLIP perform under extreme non-IID data distributions (e.g., severe label skew), given that the Fed-RSIC experimental setup distributes data evenly across clients? The current evaluation simulates data fragmentation and quantity skew but minimizes class imbalance. It is unclear if the Shared Prompts can converge effectively when clients hold mutually exclusive or heavily skewed subsets of classes, a common real-world scenario.

### Open Question 2
Can the dual-prompt mechanism effectively aggregate knowledge when clients possess fundamentally different data domains (e.g., mixing UCMerced and NWPU datasets) rather than splits of the same dataset? The framework's ability to handle "cross-institutional" collaboration is claimed in the Introduction, but the experiments restrict each federation to a single dataset source. It is unknown if the Shared Prompts can capture a coherent global semantic space when local clients have vastly different feature distributions.

### Open Question 3
What is the local computational overhead of the Cross-Modal Feature Alignment Constraint (based on Optimal Transport) compared to standard prompt tuning? While the paper successfully demonstrates reduced *communication* costs (transmitting only 2,048 parameters), it does not report the *computational* cost (FLOPs or time) of solving the transport plan locally. This is critical for edge devices in remote sensing.

## Limitations
- Missing critical hyperparameters: prompt length (h), scaling factor (s) for alignment constraint, and entropic regularization coefficient (Î»)
- Training duration (communication rounds and local epochs) not specified
- The calculation of the 2,048 parameter transmission claim is unclear for standard ViT-Base dimension
- Fed-RSIC dataset construction details (client splits) not fully specified

## Confidence
- **High Confidence:** Core architectural design and experimental accuracy claims (94.46% on Fed-Optimal)
- **Medium Confidence:** 2,048 parameter transmission claim (requires verification of exact prompt dimension)
- **Low Confidence:** Claim of being "the first" federated learning framework for RS using VLMs

## Next Checks
1. **Sanity Check (Centralized):** Reproduce Table II results on single client to validate prompt learning mechanism
2. **Communication Efficiency Verification:** Calculate exact learnable parameters for Shared Prompts and verify 2,048 transmission claim against baseline FedAvg
3. **Ablation Study Replication:** Replicate Table V ablation (removing Private Prompts) on 40 clients to test heterogeneity handling