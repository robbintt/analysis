---
ver: rpa2
title: Unsupervised Translation of Emergent Communication
arxiv_id: '2502.07552'
source_url: https://arxiv.org/abs/2502.07552
tags:
- translation
- game
- communication
- agents
- unmt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a novel approach to interpreting emergent
  communication (EC) using unsupervised neural machine translation (UNMT) techniques.
  By employing UNMT, the research translates ECs that develop during referential games
  with varying task complexities, driven by the semantic diversity of the environment.
---

# Unsupervised Translation of Emergent Communication

## Quick Facts
- arXiv ID: 2502.07552
- Source URL: https://arxiv.org/abs/2502.07552
- Authors: Ido Levy; Orr Paradise; Boaz Carmeli; Ron Meir; Shafi Goldwasser; Yonatan Belinkov
- Reference count: 32
- This study introduces a novel approach to interpreting emergent communication (EC) using unsupervised neural machine translation (UNMT) techniques.

## Executive Summary
This research introduces a novel approach to interpreting emergent communication (EC) using unsupervised neural machine translation (UNMT) techniques. By employing UNMT, the study translates ECs that develop during referential games with varying task complexities, driven by the semantic diversity of the environment. The findings highlight UNMT's potential to translate EC, showing that task complexity characterized by semantic diversity enhances EC translatability. Conversely, higher task complexity with constrained semantic variability results in pragmatic EC, which, although challenging to interpret, remains suitable for translation. This research marks the first attempt, to our knowledge, to translate EC without relying on parallel data.

## Method Summary
The study employs referential games where agents communicate about images through emergent protocols. Four complexity levels are defined based on distractor sampling strategies (Random, Category, Supercategory, Inter-category). EC messages are collected and translated to natural language using an XLM-based UNMT system pre-trained on English captions (MSCOCO), fine-tuned on EC+English, and refined through back-translation and denoising. Translation quality is evaluated using CLIP score, BLEU, METEOR, and other metrics, alongside EC-specific measures like vocabulary usage, entropy, and compositionality metrics.

## Key Results
- Inter-category game complexity achieved the highest BLEU score (9.21) and ROUGE-L score (0.37).
- Category game complexity had the lowest vocabulary usage (55.95%) due to agents using simplistic communication strategies.
- ECs emerging from different game complexities exhibit distinct communication patterns, with Inter-category complexity achieving the highest translation accuracy.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UNMT can translate emergent communication to natural language without parallel EC-NL pairs by leveraging monolingual corpora and shared embedding spaces.
- Mechanism: A pre-trained English language model provides a linguistic prior. Fine-tuning on an EC corpus aligns EC tokens into a shared embedding space with English. Back-translation (EC→EN→EC) and denoising autoencoding then iteratively refine the mapping, exploiting structural regularities in both languages.
- Core assumption: The emergent communication exhibits sufficient compositional structure and consistency for the UNMT to discover cross-lingual alignments, similar to how UNMT aligns two natural languages.
- Evidence anchors:
  - [abstract] "This research marks the first attempt, to our knowledge, to translate EC without the aid of parallel data."
  - [section 4] "Our work employed the UNMT system by Chronopoulou, Stojanovski, and Fraser (2020) that is implemented in three steps: 1. Pre-training... 2. Fine-tuning... 3. Back-translation and Denoising..."
  - [corpus] Limited direct corpus support for applying UNMT to EC specifically; most related work focuses on EC as a tool for NL translation (Downey et al., 2023) or uses parallel data (Andreas et al., 2017; Yao et al., 2022).
- Break condition: If EC lacks consistent symbol-to-concept mappings or exhibits high message collapse (different images mapped to identical messages without observable similarity), the shared embedding space may fail to align, causing translation to degrade toward noise.

### Mechanism 2
- Claim: Task complexity, defined by the semantic relationship between targets and distractors, shapes the vocabulary usage, entropy, and pragmatic nature of the emergent protocol.
- Mechanism: In referential games, agents must discriminate a target from distractors. When distractors are semantically close (e.g., same category), agents are pressured to encode fine-grained features, often leading to lower vocabulary usage and more pragmatic, concise protocols. When distractors are diverse (e.g., inter-category), agents can succeed by encoding category-level concepts, fostering more diverse vocabularies.
- Core assumption: Agents optimize for task success and communicative efficiency, leading to different strategies under different complexity pressures.
- Evidence anchors:
  - [section 3] Defines four game complexity levels (Random, Category, Supercategory, Inter-category) based on distractor sampling.
  - [section 6, results] "Category game complexity... has the lowest VU (55.95%)... we attribute this finding to... agents might use 'low-level features'... leading to simplistic communication strategies."
  - [corpus] Guo et al. (2021) found that contextual similarity impacts EC expressivity; this paper extends that framework with a broader spectrum of complexity.
- Break condition: If agents can solve the task via memorization or exploit dataset artifacts without developing compositional protocols, the relationship between complexity and EC characteristics weakens.

### Mechanism 3
- Claim: EC translatability is enhanced when the emergent protocol aligns with natural language concept structures, which is more likely under inter-category semantic diversity rather than extreme contextual similarity or complete randomness.
- Mechanism: Inter-category games require agents to discriminate across broad categories with potential feature overlap, encouraging category-level distinctions that map more directly to NL concepts. This conceptual alignment makes the UNMT's task easier than protocols optimized for fine-grained, low-level features or random, unstructured communication.
- Core assumption: UNMT performance depends on the degree of conceptual and structural alignment between the source (EC) and target (English) languages.
- Evidence anchors:
  - [abstract] "task complexity characterized by semantic diversity enhances EC translatability."
  - [section 6] "Inter-category complexity achieved the highest BLEU score (9.21) and ROUGE-L score (0.37)... we speculate this is due to... shaping the information conveyed by the EC to be specific to a category among others... aligning the EC more towards NL."
  - [corpus] No direct external validation; related work on EC-NL translation (Yao et al., 2022) used parallel data, making direct comparison difficult.
- Break condition: If the target natural language lacks vocabulary or structures to express the distinctions encoded in the EC (e.g., highly specialized visual features), translation quality will plateau regardless of conceptual alignment.

## Foundational Learning

- Concept: **Referential Games and Emergent Communication**
  - Why needed here: The entire EC corpus is generated from agents playing referential games. Understanding the Sender-Receiver setup, discrimination task, and how communication protocols emerge is prerequisite to interpreting results.
  - Quick check question: In a referential game with 9 distractors, what pressure does having semantically similar distractors (same category) place on the emergent communication compared to random distractors?

- Concept: **Unsupervised Neural Machine Translation (UNMT) Fundamentals**
  - Why needed here: The paper's core methodological contribution is applying UNMT to EC. Understanding back-translation, denoising autoencoding, and shared embedding spaces is necessary to evaluate the approach.
  - Quick check question: Why does UNMT require iterative back-translation rather than a single-pass alignment, and what role does denoising play in this process?

- Concept: **Compositional Structure in Communication Protocols**
  - Why needed here: The paper uses multiple metrics (TopSim, AMI, BosDis, PosDis) to assess compositionality, and links compositionality to translatability. Understanding what makes a protocol compositional is key to interpreting these findings.
  - Quick check question: What is the difference between Bag-of-Symbols Disentanglement (BosDis) and Positional Disentanglement (PosDis), and what would a low score on each suggest about the EC protocol?

## Architecture Onboarding

- Component map:
  - EC Generation Layer: Sender (ResNet encoder + LSTM) observes image, generates discrete message (6 symbols from 64-symbol vocabulary + EOS). Receiver (shared ResNet + LSTM) ranks candidates. Trained with infoNCE loss via EGG framework.
  - EC Corpus: Messages logged during gameplay form monolingual EC corpus (~117K training images, messages per game type).
  - UNMT Layer: XLM-based transformer (6 layers, 8 heads, 1024 dim). Phase 1: pre-train on English captions (MSCOCO). Phase 2: fine-tune jointly on EC corpus + English captions. Phase 3: back-translation and denoising with word manipulation (shuffle, dropout, blank at 0.1).
  - Evaluation Suite: EC metrics (accuracy, VU, entropy, TopSim, AMI, BosDis, PosDis); translation metrics (BLEU, METEOR, ROUGE-L, BERTScore, CLIP Score, TTR, novelty).

- Critical path:
  1. Define game complexity type → determines distractor sampling strategy.
  2. Train agents (50 epochs, early stopping) → generates EC corpus.
  3. Pre-train UNMT on English captions → linguistic prior.
  4. Fine-tune UNMT on EC + English → shared embedding.
  5. Back-translation/denoising → refine translation.
  6. Evaluate: CLIP score (image-translation alignment), BLEU/METEOR (caption overlap).

- Design tradeoffs:
  - **Shared vs. separate visual encoders**: Paper shares ResNet weights between Sender/Receiver for consistent perception. Tradeoff: may limit diversity of representations; separate encoders could enable more specialized encoding but risk misalignment.
  - **Fixed channel capacity**: Vocabulary size (64) and message length (7) are fixed. Tradeoff: limits expressivity but ensures tractable UNMT; larger vocab/longer messages may produce richer EC but harder translation.
  - **Monolingual English prior**: Uses MSCOCO captions as the sole NL resource. Tradeoff: domain-specific (image descriptions); general-domain corpus might improve fluency but reduce groundedness.
  - **No parallel data assumption**: Avoids biases from EC-NL pairs but relies entirely on UNMT's ability to find structure. Assumption: EC has sufficient regularity.

- Failure signatures:
  - **Random baseline behavior**: BLEU ~0, VU ~100%, high entropy, near-random accuracy → indicates EC never developed meaningful structure.
  - **Message collapse**: High accuracy but low vocabulary usage and high repetition of identical messages for diverse images → suggests agents found non-compositional shortcuts.
  - **Hallucination in translation**: Translations include objects not in the image (e.g., "and a mouse" in Figure 3c) → UNMT over-generalizing from caption length distribution; may indicate insufficient EC-to-concept grounding.
  - **Near-zero cross-seed correlation**: Same test set, different seeds yield uncorrelated translation scores → each instantiation produces a unique EC "dialect" without universal structure.

- First 3 experiments:
  1. **Baseline sanity check**: Replicate the Random agent baseline. Confirm BLEU ~0, VU ~100%. This validates that the UNMT isn't hallucinating structure from noise.
  2. **Single-complexity ablation**: Train EC and UNMT on Inter-category games only. Measure BLEU, CLIP score, and AMI. Compare to paper's reported 9.21 BLEU / 0.191 CLIP. This establishes a working baseline before varying complexity.
  3. **Compositionality-translatability probe**: Correlate AMI scores with BLEU/METEOR across all complexity types. If AMI positively correlates with BLEU (as Figure 5 suggests), this confirms that concept-aligned EC is more translatable. If not, investigate whether disentanglement metrics (BosDis/PosDis) are better predictors.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation of translation quality depends heavily on CLIP score for image-reference alignment and translation metrics like BLEU, which may not fully capture semantic fidelity.
- The assumption that EC exhibits sufficient compositional structure for UNMT to discover alignments is not empirically validated across diverse EC scenarios.
- The study relies on a single EC corpus without external validation across different domains or datasets.

## Confidence
- **High Confidence**: The experimental design and implementation of the referential games and UNMT pipeline are sound, with clear methodology and reproducible results within the controlled setting.
- **Medium Confidence**: The findings on task complexity influencing EC characteristics (vocabulary usage, entropy, translatability) are supported by the data but require further validation across different datasets and EC protocols.
- **Low Confidence**: The claim that inter-category complexity achieves the highest translatability is based on a single experimental setup and may not generalize to other EC domains or communication tasks.

## Next Checks
1. **Cross-Dataset Validation**: Replicate the study using a different image dataset (e.g., CIFAR-100 or ImageNet subsets) to assess whether task complexity effects on EC translatability hold across domains.

2. **Ablation on Visual Encoders**: Train Sender and Receiver with separate visual encoders to determine if shared perception is necessary for effective EC translation or if specialized encoding improves translatability.

3. **Alternative Translation Metrics**: Evaluate translation quality using human judgments or semantic similarity measures (e.g., STS-B) alongside CLIP score to better assess semantic fidelity beyond surface-level alignment.