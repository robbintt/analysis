---
ver: rpa2
title: 'DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational
  AutoEncoder for Robust Radiology Reporting with Missing Modalities'
arxiv_id: '2511.05968'
source_url: https://arxiv.org/abs/2511.05968
tags:
- latent
- shared
- clinical
- missing
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DiA-gnostic VLVAE, a vision-language variational
  autoencoder designed to generate radiology reports from chest X-rays and clinical
  context, while remaining robust to missing modalities. The method disentangles shared
  and modality-specific latent representations using a Mixture-of-Experts encoder
  and enforces orthogonality and alignment via a constrained optimization objective.
---

# DiA-gnostic VLVAE: Disentangled Alignment-Constrained Vision Language Variational AutoEncoder for Robust Radiology Reporting with Missing Modalities

## Quick Facts
- arXiv ID: 2511.05968
- Source URL: https://arxiv.org/abs/2511.05968
- Authors: Nagur Shareef Shaik, Teja Krishna Cherukuri, Adnan Masood, Dong Hye Ye
- Reference count: 14
- Primary result: Achieved BLEU@4 of 0.266 on IU X-Ray and 0.134 on MIMIC-CXR, outperforming state-of-the-art methods

## Executive Summary
DiA-gnostic VLVAE introduces a novel architecture for generating radiology reports from chest X-rays and clinical context while maintaining robustness to missing modalities. The method employs a tri-factor latent decomposition that separates shared and modality-specific features, using a Mixture-of-Experts (MoE) encoder and constrained optimization to enforce orthogonality and alignment. A compact LLaMA-X decoder generates clinically accurate reports, demonstrating superior performance on both IU X-Ray and MIMIC-CXR datasets.

## Method Summary
DiA-gnostic VLVAE combines a custom end-to-end vision-language encoder with a compact LLaMA-X decoder to generate radiology reports. The architecture features a tri-factor latent decomposition into vision-specific (Z_v), language-specific (Z_l), and shared (Z_s) latent variables. The VL-MoE-VAE module employs a Mixture-of-Experts posterior to handle missing modalities, while orthogonality and contrastive alignment constraints ensure disentangled and semantically coherent representations. The system was evaluated on IU X-Ray and MIMIC-CXR datasets, showing robust performance even with missing clinical context.

## Key Results
- Achieved BLEU@4 score of 0.266 on IU X-Ray dataset
- Achieved BLEU@4 score of 0.134 on MIMIC-CXR dataset
- Demonstrated resilience to missing clinical context, with F1 score drop of only 0.18 compared to 0.23 for baseline methods

## Why This Works (Mechanism)

### Mechanism 1
Separating modality-specific and shared latent representations enables robust report generation when clinical context is missing. The tri-factor latent decomposition learns three distinct variables: Z_v (vision-specific), Z_l (language-specific), and Z_s (cross-modal shared). The shared latent Z_s is inferred from both modalities during training but can be approximated from a single modality at inference via the MoE posterior, preserving cross-modal semantics even with incomplete inputs.

### Mechanism 2
Mixture-of-Experts posterior provides principled handling of missing modalities compared to Product-of-Experts approaches. The shared posterior q_φs(Z_s|V,L) is a weighted combination of unimodal experts. At inference, a "null" token for missing modalities causes the router to down-weight that expert, gracefully reducing to a vision-only posterior without architectural changes or imputation.

### Mechanism 3
Joint orthogonality and contrastive alignment constraints create a latent space that is both statistically disentangled and semantically coherent. L_orth enforces uncorrelatedness between Z_v, Z_l, and Z_s via Frobenius norms of cross-covariance matrices after whitening. L_align uses InfoNCE to maximize mutual information I(Z_s; Z_v) and I(Z_s; Z_l), ensuring Z_s retains relevant semantics from both modalities.

## Foundational Learning

- **Variational Autoencoders and ELBO**: Understanding how ELBO balances reconstruction accuracy against KL regularization, and why JSD replaces KL for mixture distributions. *Quick check*: Can you explain why the standard KL divergence term is replaced with Jensen-Shannon Divergence for the MoE posterior, and what "component collapse" means in this context?

- **Mixture-of-Experts Models**: The shared encoder uses MoE to combine unimodal posteriors, and understanding how mixture weights are learned and how the router handles missing inputs is critical for debugging inference behavior. *Quick check*: How does the MoE formulation in Equation 3 differ from a Product-of-Experts approach, and what happens to π_L when language context is missing at inference?

- **Contrastive Learning (InfoNCE)**: The alignment loss L_align uses InfoNCE to maximize mutual information between shared and specific latents; understanding the temperature parameter τ and negative sampling strategy is essential for tuning. *Quick check*: Why does minimizing the InfoNCE loss in Equation 6 increase a lower bound on I(Z_s; Z_v), and what role does the temperature τ play?

## Architecture Onboarding

- **Component map**: Input image V -> EfficientNetB0 -> GCA -> Modality Abstractor -> VL-MoE-VAE (Z_v, Z_l, Z_s) -> LLaMA-X Decoder -> report

- **Critical path**: The shared latent Z_s is the critical junction for missing-modality robustness; if it fails to encode cross-modal semantics, generation quality degrades.

- **Design tradeoffs**: Custom end-to-end encoder (51.1 GFLOPs, BLEU@4=0.134) vs. pre-trained RAD-DINO+CXR-BERT (81.1 GFLOPs, BLEU@4=0.121). The paper chooses efficiency over pre-trained weight leverage.

- **Failure signatures**:
  - Missing context produces incoherent reports: Check if λ_2 (alignment weight) is too low
  - Component collapse in MoE: Verify JSD regularization is active; inspect mixture weights
  - Hallucinated findings: May indicate insufficient disentanglement; increase λ_1 (orthogonality weight)

- **First 3 experiments**:
  1. Reproduce ablation baseline: Train with only L_ELBO (no L_orth, L_align) on IU X-Ray, compare BLEU@4 and F1 to Table 2 values
  2. Missing-modality stress test: Evaluate on MIMIC-CXR test split with 45% missing context; confirm F1 drop is ~0.18
  3. Latent space visualization: Generate t-SNE plots of Z_v, Z_l, Z_s with and without DA constraints; verify separation patterns

## Open Questions the Paper Calls Out
- **Missing Image Modality**: The framework's behavior with missing image input (text-only inference) is not validated experimentally, though mathematically derivable.
- **Hallucination Reduction**: The extent to which disentanglement quantitatively reduces clinical hallucinations compared to standard fusion methods remains unclear.
- **Multi-Modal Scalability**: Whether the MoE architecture and orthogonality constraint effectively scale to integrating more than two modalities (e.g., EHR, tabular data) is unknown.

## Limitations
- The orthogonality constraint assumes non-Gaussianity for independence approximation without validation
- Performance evaluation lacks radiologist review for clinical validity
- Missingness patterns are controlled during training but not evaluated under real-world non-random missingness

## Confidence
- **High**: Architectural novelty and reported dataset performance, given detailed ablation comparisons
- **Medium**: Core claims of disentanglement and missing-modality robustness, supported by controlled ablations but lacking real-world missingness evaluation
- **Low**: Clinical validity due to absence of radiologist evaluation or comparison to clinically deployed systems

## Next Checks
1. Conduct radiologist review comparing DiA-generated reports with human reports on held-out MIMIC-CXR subset, scoring for clinical accuracy, completeness, and hallucination
2. Evaluate on dataset with explicit missingness patterns to test whether Z_s maintains semantic coherence under non-training missingness
3. Perform ablation studies varying λ_1 and λ_2 across a grid to identify if there exists a regime where orthogonality dominates and generation quality degrades