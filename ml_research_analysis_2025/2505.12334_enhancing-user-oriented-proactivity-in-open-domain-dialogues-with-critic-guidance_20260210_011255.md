---
ver: rpa2
title: Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance
arxiv_id: '2505.12334'
source_url: https://arxiv.org/abs/2505.12334
tags:
- user
- chatbot
- dialogue
- background
- critic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for enhancing user-oriented proactivity
  in open-domain dialogue systems by constructing a critic to evaluate proactivity
  and using it to guide dialogue corpus generation with user agents from diverse backgrounds.
  An iterative curriculum learning approach is employed to train the chatbot from
  easy-to-communicate to more challenging users.
---

# Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance

## Quick Facts
- arXiv ID: 2505.12334
- Source URL: https://arxiv.org/abs/2505.12334
- Reference count: 10
- Key outcome: Method improves user-oriented proactivity in open-domain dialogues, with UPC outperforming baselines in relevance, user interest, and response value

## Executive Summary
This paper addresses the challenge of enhancing user-oriented proactivity in open-domain dialogue systems, where chatbots should proactively explore user interests and guide conversations toward user-centered topics. The proposed method constructs an LLM-based critic to evaluate proactivity using three metrics (relevance, interest, value), then uses this critic to guide dialogue corpus generation with diverse synthetic user agents from the ISCO-800 dataset. An iterative curriculum learning approach trains the chatbot from easy-to-communicate users to more challenging ones, resulting in improved user-oriented proactivity and attractiveness in open-domain dialogues.

## Method Summary
The method consists of three main components: (1) constructing a critic using LLM-as-a-judge to score responses on relevance, interest, and value; (2) generating critic-guided dialogues between chatbot and user agents with regeneration for scores below threshold; and (3) iterative curriculum learning using a difficulty measurer to train on easy-to-hard samples across multiple iterations until convergence. The approach uses synthetic user agents from ISCO-800 (800 diverse backgrounds) to create training data without requiring human interaction data, then fine-tunes a base LLM (Qwen1.5-32B) on the filtered corpus.

## Key Results
- UPC achieves 0.677 relevance score and 0.660 interest score, outperforming baselines by 5-10% in human evaluation
- Real user study (62 participants) shows 76-82% preference for UPC over baseline methods
- Iterative training with curriculum learning improves easy sample rate from ~60% to 80%+ across iterations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Critic-guided feedback loops improve response quality by iteratively regenerating low-scoring responses
- Mechanism: LLM-based critic scores each chatbot response on relevance, interest, and value. Responses below threshold receive targeted feedback and are regenerated up to R attempts, filtering low-quality training data
- Core assumption: LLM-as-a-judge scores align with human preferences
- Evidence: Critic-guided corpus shows 23-38% regeneration rate; ablation confirms improvement
- Break condition: If critic scores poorly correlate with human judgments, regenerated responses may not improve user experience

### Mechanism 2
- Claim: Curriculum learning from easy to difficult users accelerates convergence and improves final performance
- Mechanism: Difficulty measurer flags samples as difficult if any metric falls below threshold α or fewer than β metrics improve after feedback; only easy dialogues used in early iterations
- Core assumption: Easy-user responses transfer skills to harder cases
- Evidence: Easy sample rate increases from ~60% to 80%+ across iterations; convergence by iteration 4
- Break condition: If easy responses don't transfer to hard cases, curriculum benefits diminish

### Mechanism 3
- Claim: Diverse synthetic user agents enable robust generalization to unseen real users
- Mechanism: ISCO-800 provides 800 structured user profiles generating diverse communication styles without human data collection
- Core assumption: Synthetic agents adequately approximate real user behavior
- Evidence: Real user evaluation (n=62) shows 76-82% preference for UPC over baseline
- Break condition: If synthetic agents exhibit distributional skew, model may underperform with real users

## Foundational Learning

- Concept: **LLM-as-a-Judge**
  - Why needed: Understanding LLM evaluation enables designing scoring rubrics and interpreting critic reliability
  - Quick check: Can you explain why a 5-point Likert scale with anchor descriptions (1, 3, 5) might reduce score variance compared to unconstrained ratings?

- Concept: **Curriculum Learning**
  - Why needed: Grasping easy-to-hard training schedules helps diagnose slow convergence from premature hard sample exposure
  - Quick check: Given 30% easy and 70% difficult samples, what happens if you train on all data from iteration 1 instead of gradually including difficult samples?

- Concept: **Iterative Self-Improvement / IFT**
  - Why needed: Recognizing model-generated data quality improves as model improves clarifies need for multiple training iterations
  - Quick check: Why might fine-tuning on data from iteration k produce different results than fine-tuning on data from iteration k+2?

## Architecture Onboarding

- Component map: ISCO-800 -> User Agents -> Chatbot -> Critic -> Difficulty Measurer -> Training Scheduler
- Critical path: Load ISCO-800 → instantiate user agents → Chatbot ↔ user agents generate dialogues (T turns) → Critic scores responses; regenerate if scores < 4 → Difficulty Measurer labels easy/difficult → Fine-tune chatbot on easy dialogues → Repeat until convergence
- Design tradeoffs:
  - Critic choice: GPT-3.5 cheaper but may misalign; GPT-4 more accurate but costly
  - Regeneration limit R: Higher R improves quality but increases costs/latency
  - Curriculum vs. uniform sampling: Curriculum reduces early-training noise but may slow early progress
- Failure signatures:
  - High regeneration rate (>40%) across iterations → chatbot not learning from feedback
  - Low easy-sample rate (<50%) → difficulty thresholds too strict
  - Low real-user preference (<60%) → synthetic users insufficiently diverse
- First 3 experiments:
  1. SFT-only baseline on 100 synthetic users to verify poor metrics
  2. Critic ablation comparing CDC vs. random-response selection
  3. Curriculum validation tracking easy-sample rate across iterations 1-4

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does UPC performance generalize to longer conversations beyond 5-turn dialogues?
- Basis: Paper evaluates only 5-turn dialogues without investigating extended multi-turn interactions
- Why unresolved: Longer conversations may reveal fatigue effects or difficulty maintaining proactivity
- What evidence: Experiments with 10, 20, or 50-turn dialogues showing sustained relevance, interest, and value scores

### Open Question 2
- Question: Does training with LLM-simulated user agents lead to overfitting to LLM-like patterns?
- Basis: Paper uses Qwen1.5-72B-Chat for user simulation with limited evidence on distribution shift
- Why unresolved: LLM agents may exhibit more coherent behavior than real humans
- What evidence: Larger-scale study comparing model performance on real vs. simulated users

### Open Question 3
- Question: How robust is the critic-based difficulty measurer to different α and β values?
- Basis: Difficulty measurer uses hyperparameters α and β specified in Appendix B without sensitivity analysis
- Why unresolved: Different values may significantly alter sample classification and training trajectories
- What evidence: Ablation experiments varying α and β systematically

### Open Question 4
- Question: Does critic-guided regeneration introduce systematic biases toward certain response styles?
- Basis: Critic criteria may implicitly favor verbose, informative styles over casual or brief responses
- Why unresolved: Paper doesn't analyze distributional properties of regenerated responses
- What evidence: Analysis of linguistic features and topic distributions across ISCO-800 groups

## Limitations

- Small real user evaluation sample (n=62) limits generalizability of effectiveness claims
- Key hyperparameters (α, β thresholds, regeneration limits R) not specified in main text
- Limited validation of critic alignment with human judgment beyond small sample (300 dialogues)

## Confidence

- **High Confidence**: Core methodology of using LLM critics to filter/regenerate training data is technically sound
- **Medium Confidence**: Curriculum learning approach shows promise but theoretical justification is limited
- **Low Confidence**: Assumption that synthetic agents represent real user diversity needs more causal evidence

## Next Checks

1. Conduct larger-scale human evaluation (n≥200) comparing UPC against baselines across diverse user demographics
2. Perform cross-topic generalization tests on topics not represented in ISCO-800 to assess synthetic agent coverage
3. Implement ablation studies varying α and β thresholds to determine sensitivity of curriculum learning to these parameters