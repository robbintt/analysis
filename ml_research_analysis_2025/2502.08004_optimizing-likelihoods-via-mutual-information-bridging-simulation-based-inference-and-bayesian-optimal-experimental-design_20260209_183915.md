---
ver: rpa2
title: 'Optimizing Likelihoods via Mutual Information: Bridging Simulation-Based Inference
  and Bayesian Optimal Experimental Design'
arxiv_id: '2502.08004'
source_url: https://arxiv.org/abs/2502.08004
tags:
- design
- likelihood
- posterior
- inference
- experimental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes a theoretical connection between simulation-based
  inference (SBI) and Bayesian optimal experimental design (BOED) through mutual information
  optimization. The authors show that maximizing a mutual information lower bound
  is equivalent to minimizing the KL divergence between approximate and true likelihoods,
  enabling simultaneous optimization of experimental designs and amortized inference
  functions.
---

# Optimizing Likelihoods via Mutual Information: Bridging Simulation-Based Inference and Bayesian Optimal Experimental Design

## Quick Facts
- arXiv ID: 2502.08004
- Source URL: https://arxiv.org/abs/2502.08004
- Reference count: 40
- Primary result: SBI-BOED achieves superior calibration and predictive accuracy compared to benchmarks, with SBI-BOED (λ=0.01) achieving median distances of 47.99 (SIR) and 0.60 (BMP) while maintaining near-perfect calibration

## Executive Summary
This paper establishes a theoretical connection between simulation-based inference (SBI) and Bayesian optimal experimental design (BOED) through mutual information optimization. The authors show that maximizing a mutual information lower bound is equivalent to minimizing the KL divergence between approximate and true likelihoods, enabling simultaneous optimization of experimental designs and amortized inference functions. They introduce INCE-λ, a modified InfoNCE bound with regularization parameter λ, and propose using a design distribution to overcome gradient-based optimization challenges in non-differentiable simulators.

## Method Summary
The SBI-BOED method optimizes experimental designs and amortized likelihood functions simultaneously by maximizing a mutual information lower bound. It uses a Neural Spline Flow as the density estimator, a truncated Normal distribution for the design policy, and the INCE-λ objective function. The method employs a design distribution rather than point estimates to enable gradient-based optimization for non-differentiable simulators, and updates both the flow parameters and design distribution parameters jointly using Adam optimizer.

## Key Results
- SBI-BOED (λ=0.01) achieves median distances of 47.99 (SIR) and 0.60 (BMP) while maintaining near-perfect calibration
- SBI-BOED outperforms benchmark methods in both calibration (L-C2ST) and predictive accuracy metrics
- Information gain does not necessarily correlate with downstream prediction accuracy, emphasizing the importance of holistic evaluation metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Maximizing a lower bound of mutual information (MI) between parameters $\theta$ and data $y$ is theoretically equivalent to minimizing the Kullback-Leibler (KL) divergence between the true and approximate likelihoods.
- **Mechanism:** The paper demonstrates that the objective function for mutual information maximization (specifically the InfoNCE bound) decomposes into terms involving the log-likelihood. By optimizing this bound, one implicitly minimizes $D_{KL}(p(y|\theta) || p_\phi(y|\theta))$, effectively training a neural density estimator (likelihood) while simultaneously scoring experimental designs.
- **Core assumption:** The density estimator $p_\phi(y|\theta)$ must be a valid, normalized probability distribution (e.g., a Normalizing Flow) for the KL divergence interpretation to hold.
- **Evidence anchors:** [abstract] "The authors show that maximizing a mutual information lower bound is equivalent to minimizing the KL divergence between approximate and true likelihoods..." [PAGE 4, Theorem 3.1] "...maximizing the lower bound of the Mutual Information... is equivalent to minimizing... $D_{KL}(p(y|\theta)||p_\phi(y|\theta))$..."
- **Break condition:** If the density estimator is unnormalized (e.g., an energy-based model without flow constraints), the equivalence to the specific KL divergence formulation may not hold.

### Mechanism 2
- **Claim:** Regularizing the InfoNCE bound with a parameter $\lambda$ (INCE-$\lambda$) stabilizes likelihood training and improves predictive accuracy, whereas standard MI maximization can lead to miscalibration.
- **Mechanism:** Standard MI optimization can suffer from "sparse rewards" or distribution shifts that degrade the validation likelihood. The INCE-$\lambda$ objective scales the likelihood term $p_\phi(y|\theta)$, biasing the gradient updates to prioritize likelihood accuracy (entropy reduction) over pure information gain, resulting in better-calibrated posteriors.
- **Core assumption:** There is a trade-off between maximizing the tightness of the MI bound and the predictive accuracy of the amortized likelihood; the user must value accuracy/calibration over raw EIG scores.
- **Evidence anchors:** [PAGE 4, Eq. 8] Definition of $L_{NCE-\lambda}$ adding the $\lambda \cdot \log p_\phi(y|\theta_0, \xi)$ term. [PAGE 7, Table 1] SBI-BOED with $\lambda=0.01$ achieves superior median distance and L-C2ST (calibration) compared to non-regularized baselines, even if raw EIG is slightly lower.
- **Break condition:** If $\lambda$ is set too high, the objective essentially becomes maximum likelihood estimation, ignoring the contrastive (design optimization) component entirely.

### Mechanism 3
- **Claim:** Using a distribution over designs (a stochastic policy) enables gradient-based optimization for non-differentiable simulators where direct gradient backpropagation is impossible.
- **Mechanism:** Instead of optimizing a single design vector $\xi$, the method optimizes the parameters $\psi$ of a distribution $p_\psi(\xi)$ (e.g., a truncated Normal). Gradients flow through the likelihood estimator (which is differentiable) with respect to samples drawn from $p_\psi(\xi)$. This bypasses the need for simulator gradients, treating the simulator as a black-box generator of $y$.
- **Core assumption:** The density estimator (Normalizing Flow) provides a smooth enough gradient landscape to guide the design distribution parameters even if the simulator output landscape is rough or discontinuous.
- **Evidence anchors:** [PAGE 4, Section 3.2] "We propose a robust method... without requiring a differentiable simulator. To address the limitations of naive gradient-based design optimization, we leverage a design distribution..." [PAGE 7, Figure 3] Ablation study showing optimization fails without the design distribution ("No Design Distribution" flatlines) compared to "Design Distribution".
- **Break condition:** If the design space is highly multi-modal and the distribution $p_\psi(\xi)$ is unimodal (like a single Gaussian), the optimizer may converge to a sub-optimal local design region.

## Foundational Learning

- **Concept: Normalizing Flows**
  - **Why needed here:** The paper relies on Normalizing Flows (specifically Neural Spline Flows) as the "neural density estimator" $p_\phi(y|\theta)$. You must understand how flows provide exact likelihood computation (required for the MI bound) and invertible transformations.
  - **Quick check question:** Can you explain why a Normalizing Flow allows for calculating the exact log-likelihood $p_\phi(y|\theta)$ while a standard GAN or VAE typically does not?

- **Concept: InfoNCE / Contrastive Learning**
  - **Why needed here:** The core objective function is based on the InfoNCE bound. You need to understand the concept of "contrastive samples" (negative samples) used to estimate mutual information without computing the partition function explicitly.
  - **Quick check question:** In the context of the paper's Equation 4, what do the contrastive samples $\theta_{1:L}$ represent and how do they help estimate the mutual information lower bound?

- **Concept: Bayesian Optimal Experimental Design (BOED)**
  - **Why needed here:** This is the problem setting. You need to grasp the goal of maximizing "Expected Information Gain" (EIG) and how it differs from standard inference (which just fits parameters given data).
  - **Quick check question:** Why is maximizing EIG equivalent to maximizing the mutual information between the parameters $\theta$ and the observations $y$?

## Architecture Onboarding

- **Component map:**
  Simulator -> Design Policy (Truncated Normal) -> Simulator -> Density Estimator (Neural Spline Flow) -> INCE-λ loss -> Optimizer

- **Critical path:**
  1. Sample parameters $\theta$ from prior
  2. Sample design $\xi$ from current Design Policy (not from simulator)
  3. Simulate data $y$ using the Simulator (stop gradient here)
  4. Pass $(\theta, y, \xi)$ into the Density Estimator to get log-likelihood
  5. Compute INCE-$\lambda$ loss using $L$ contrastive samples
  6. Backpropagate gradients to update Density Estimator weights and Design Policy mean/variance

- **Design tradeoffs:**
  - **$\lambda$ (Regularization):** High $\lambda$ improves likelihood accuracy and calibration but may reduce the rate of information gain (EIG). The paper suggests $\lambda=0.01$ or $0.1$ as a sweet spot.
  - **L (Contrastive Samples):** Higher $L$ reduces bias in the MI estimate but increases memory/compute cost linearly.
  - **Design Distribution Variance:** Large initial variance helps exploration but must be decayed to converge on specific optimal designs.

- **Failure signatures:**
  - **Flatlining EIG:** If using point-estimate designs instead of a distribution (Figure 3), gradients vanish. Fix: Switch to the Design Distribution method.
  - **Mode Collapse:** The likelihood estimator might miss modes in the posterior (Two Moons task). This is a known failure of likelihood-based SBI mentioned in Appendix E.
  - **Overconfident/Miscalibrated Posteriors:** High EIG scores but poor L-C2ST or median distance metrics. This indicates the MI objective was prioritized over likelihood accuracy. Fix: Increase $\lambda$.

- **First 3 experiments:**
  1. **Two Moons Validation:** Train the Density Estimator on the "Two Moons" task with different $\lambda$ values. Verify that increasing contrastive samples $L$ improves EIG, while increasing $\lambda$ improves validation log-likelihood (Figure 1).
  2. **Linear Model Scaling:** Run the Noisy Linear Model experiment. Verify that SBI-BOED increases EIG as design dimension $D$ increases. Compare $\lambda=0.0$ vs $\lambda=1.0$ to observe stability differences in high dimensions (Figure 2).
  3. **SIR Ablation:** Implement the SIR model. Run one round with the Design Distribution and one without. Plot the EIG over training steps to confirm that the design distribution prevents the optimization from stalling (Figure 3).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can parameterizing design distributions with sophisticated policy networks improve performance over the simple truncated Normal distributions used in this study?
- **Basis in paper:** [explicit] Appendix A.2 states, "While we used a simple tempered design distribution, they can be parameterized with more sophisticated models akin to policy networks in RL... We leave this for future work."
- **Why unresolved:** The current implementation relies on a basic truncated Normal distribution for $p(\xi)$ to overcome sparse rewards, but more complex policies might capture optimal design regions more efficiently.
- **What evidence would resolve it:** Comparative benchmarks showing convergence rates and final Expected Information Gain (EIG) when using RL-based policy networks versus the truncated Normal approach on complex simulators.

### Open Question 2
- **Question:** Can alternative generative models, such as diffusion models or flow-matching, replace normalizing flows to better handle high-dimensional data in SBI-BOED?
- **Basis in paper:** [explicit] The Discussion notes, "This opens opportunities for BOED to any likelihood-based model used with, for example, diffusion... or flow-matching, each of which may handle higher-dimensional data better..."
- **Why unresolved:** The current method relies on normalizing flows, which may face limitations in scalability or flexibility compared to newer generative architectures.
- **What evidence would resolve it:** Successful application of SBI-BOED using diffusion models on high-dimensional scientific simulators where normalizing flows typically struggle, demonstrating maintained calibration and accuracy.

### Open Question 3
- **Question:** Does pretraining density estimators mitigate mode collapse and instability when jointly optimizing likelihood and posterior networks?
- **Basis in paper:** [explicit] Appendix E notes regarding mode collapse: "Future work may address this with pretraining of one or both of the density estimators to improve stability of estimation."
- **Why unresolved:** Jointly training likelihood and posterior estimators while optimizing designs proved unstable, and standard maximum likelihood training did not resolve mode collapse in the "two moons" task.
- **What evidence would resolve it:** Ablation studies on the "two moons" task showing that pretraining leads to stable convergence and avoids mode collapse without sacrificing the mutual information lower bound.

## Limitations
- The equivalence proof assumes a properly normalized density estimator; extension to unnormalized models requires additional theoretical work
- Optimal λ values appear problem-specific without systematic theoretical guidance
- Design distribution hyperparameters (variance schedule, family choice) significantly impact optimization but lack principled selection criteria

## Confidence
- **High:** The theoretical equivalence between MI maximization and KL minimization is rigorously proven
- **Medium:** Empirical validation is limited to synthetic and moderately complex real-world simulators, warranting caution in practical scalability claims
- **Medium:** INCE-λ regularization's effectiveness is demonstrated empirically but lacks theoretical analysis of optimal λ values across diverse problem domains

## Next Checks
1. Test SBI-BOED on a high-dimensional simulator (D>100) to evaluate scalability beyond the reported Linear Model task
2. Compare SBI-BOED performance when replacing the Normalizing Flow with an unnormalized energy-based model to identify where the KL equivalence breaks
3. Conduct a systematic ablation study varying λ across multiple orders of magnitude (10^-3 to 10^1) on the same simulator to map the stability-accuracy tradeoff surface