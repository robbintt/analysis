---
ver: rpa2
title: Off-Policy Evaluation of Ranking Policies via Embedding-Space User Behavior
  Modeling
arxiv_id: '2506.00446'
source_url: https://arxiv.org/abs/2506.00446
tags:
- ranking
- variance
- behavior
- assumption
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles off-policy evaluation (OPE) in ranking settings
  where the action space grows exponentially with ranking length and unique actions,
  causing high variance in existing estimators. The authors introduce two key assumptions:
  no direct effect on rankings and user behavior model on ranking embedding spaces.'
---

# Off-Policy Evaluation of Ranking Policies via Embedding-Space User Behavior Modeling

## Quick Facts
- arXiv ID: 2506.00446
- Source URL: https://arxiv.org/abs/2506.00446
- Reference count: 40
- One-line primary result: GMIPS estimator with MRIPS variant significantly reduces MSE compared to baselines, particularly as unique actions and ranking length increase

## Executive Summary
This paper addresses off-policy evaluation (OPE) in ranking settings where the action space grows exponentially with ranking length and unique actions, causing high variance in existing estimators. The authors introduce two key assumptions: no direct effect on rankings and user behavior model on ranking embedding spaces. They propose the generalized marginalized IPS (GMIPS) estimator, which leverages ranking embeddings to reduce variance while maintaining unbiasedness under these assumptions. Among GMIPS variants, the marginalized reward interaction IPS (MRIPS) performs best by balancing bias and variance, even when assumptions are violated. Experiments show MRIPS significantly reduces mean squared error (MSE) compared to baselines, particularly as the number of unique actions and ranking length increase. The authors also demonstrate that using SLOPE to select optimal embedding dimensions further improves performance.

## Method Summary
The paper introduces GMIPS (Generalized Marginalized IPS), an off-policy evaluation estimator for ranking policies that operates in embedding space rather than discrete action space. GMIPS assumes no direct effect between ranking actions and rewards given embeddings, allowing variance reduction through marginalization. The MRIPS variant further applies cascade user behavior modeling for doubly marginalized importance weights. The method requires logged bandit data with embeddings, which may need to be learned via supervised learning when not directly observable. SLOPE is used to optimize embedding dimension selection for the bias-variance trade-off.

## Key Results
- GMIPS reduces variance compared to standard IPS by marginalizing importance weights over ranking embeddings
- MRIPS (cascade-based) achieves 96.2% MSE reduction in synthetic experiments compared to baselines
- Performance improvements increase with larger unique action spaces and longer rankings
- SLOPE-based embedding dimension selection further improves MRIPS performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Shifting the evaluation space from discrete actions to continuous embeddings reduces variance if rewards are conditionally independent of actions given the embedding.
- **Mechanism:** Standard IPS suffers from high variance in large action spaces. By introducing the "No Direct Effect" assumption, the estimator marginalizes out high-dimensional actions and computes importance weights over lower-dimensional embeddings, effectively reducing the "support" required.
- **Core assumption:** Assumption 3.2 (No Direct Effect): Ranking action has no causal effect on reward once context and embedding are fixed.
- **Evidence anchors:** Abstract shows GMIPS is unbiased and variance-reducing when assumptions hold. Section 3.3 Theorem 3.7 proves variance reduction is proportional to variance of importance weights conditioned on embeddings.
- **Break condition:** If embeddings fail to capture features causal to reward, Assumption 3.2 is violated, resulting in high bias.

### Mechanism 2
- **Claim:** Applying "doubly marginalized" weights based on cascade behavior reduces variance more effectively than standard embedding marginalization in long rankings.
- **Mechanism:** MRIPS applies a second marginalization based on cascade user model, calculating importance weights only on preceding embeddings rather than full set. This shrinks effective dimension of importance weight, trading small bias for significant variance reduction.
- **Core assumption:** Assumption 3.3 (User Behavior Model): Users reward items based only on current and preceding embeddings.
- **Evidence anchors:** Section 3.2 defines doubly marginal distribution; MRIPS is derived by setting $\Phi_k(e) = e^{(1:k)}$. Section 4.3 shows MRIPS improved by 96.2% MSE reduction and outperforms MSIPS as ranking length grows.
- **Break condition:** If user behavior doesn't follow cascade model, assumption fails, inducing bias proportional to deviation.

### Mechanism 3
- **Claim:** Data-driven embedding dimension selection via SLOPE optimizes bias-variance trade-off by identifying minimal embedding set sufficient for "No Direct Effect" assumption.
- **Mechanism:** High-dimensional embeddings lower bias but increase variance. SLOPE automatically selects subset of embedding dimensions, omitting noisy or irrelevant dimensions to maximize variance reduction while accepting controlled, minimal bias increase.
- **Core assumption:** Monotonicity assumption of SLOPE: Lower dimensions generally increase bias but decrease variance.
- **Evidence anchors:** Abstract states performance improves with SLOPE. Appendix E details SLOPE determines index of hyperparameters based on concentration inequality criteria.
- **Break condition:** If true causal feature is dropped during selection, bias spikes.

## Foundational Learning

- **Concept: Inverse Propensity Scoring (IPS)**
  - **Why needed here:** Paper modifies standard IPS to handle large action spaces. Must understand that IPS re-weights logged data to estimate target policy, and variance explodes in large spaces.
  - **Quick check question:** Why does variance of standard IPS estimator increase as number of unique actions increases?

- **Concept: User Behavior Models (Cascade vs. Independent)**
  - **Why needed here:** Choice between MRIPS (Cascade) and MIIPS (Independent) dictates estimator structure.
  - **Quick check question:** In a "Cascade" model, does reward at position $k$ depend on action at position $k+1$?

- **Concept: Causal Graphs / Assumptions**
  - **Why needed here:** Method relies entirely on causal assumption that $Action \perp Reward | Embedding$. Understanding conditional independence is required to validate if assumption holds for data.
  - **Quick check question:** If embedding $e$ is just unique ID for action $a$, does "No Direct Effect" assumption hold?

## Architecture Onboarding

- **Component map:** Logged Bandit Data $(x, a, e, r)$ -> Embedding function $f: A \to E$ -> GMIPS Estimator Core -> SLOPE Tuner
- **Critical path:** Definition and extraction of embedding $e$. If $e$ is not pre-defined in logs, must implement representation learning pipeline to impute it.
- **Design tradeoffs:**
  - MSIPS: Lower bias, higher variance. Use for short rankings.
  - MRIPS: Higher bias (if cascade fails), lower variance. Use for long rankings/large action spaces.
  - SLOPE: Essential for noisy or high-dimensional embeddings.
- **Failure signatures:**
  - High MSE with low sample size: Likely high variance; switch from MSIPS to MRIPS or reduce embedding dimensions via SLOPE.
  - High MSE with high sample size: Likely high bias; implies Assumption 3.2 or 3.3 is violated. Check if embeddings capture causal features or if user behavior matches assumed model.
- **First 3 experiments:**
  1. Baseline Check: Implement SIPS vs. MRIPS on subset of data with small action space to verify basic functionality.
  2. Stress Test: Increase unique actions ($|A|$) and ranking length ($K$) to observe point where SIPS variance explodes and MRIPS remains stable.
  3. Ablation: Run MRIPS with SLOPE on real-world data. Remove one critical embedding dimension manually to observe bias/variance shift.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can representation learning be effectively integrated into GMIPS framework to estimate embedding structures directly from logged bandit data when embeddings are unobservable?
- **Basis in paper:** Footnote 4 notes "representation learning methods" could be employed if embeddings cannot be observed, but relies on pre-trained surrogate embeddings for experiments.
- **Why unresolved:** Current methodology assumes embeddings are either observable or derived from separate supervised learning tasks, not learned jointly from bandit data.
- **What evidence would resolve it:** Experiments demonstrating MSE performance when embeddings are learned solely from logged bandit feedback.

### Open Question 2
- **Question:** How does GMIPS estimator perform with continuous ranking embeddings using kernel functions compared to discretized approach used in experiments?
- **Basis in paper:** Definition 3.5 states embeddings can be defined in continuous case by utilizing kernel function, yet experiments only validate discretized embeddings.
- **Why unresolved:** Practical trade-off between bias and variance in high-dimensional continuous embedding spaces remains empirically unverified.
- **What evidence would resolve it:** Analysis of GMIPS performance on raw continuous features without discretization.

### Open Question 3
- **Question:** How does relaxing assumption of independent embedding generation across positions affect variance reduction properties of estimator?
- **Basis in paper:** Paper states "We can also assume dependencies, where embedding at one position is influenced by actions at other positions," but limits formulation to independent generation.
- **Why unresolved:** Theoretical variance reduction (Theorem 3.7) relies on current independence structure.
- **What evidence would resolve it:** Theoretical extension and empirical test of GMIPS under dependent embedding generation process.

## Limitations
- Assumption Sensitivity: GMIPS critically depends on "No Direct Effect" assumption; if embeddings fail to capture all causal features, estimator introduces significant bias.
- Model Dependency: MRIPS requires cascade user behavior assumption; paper doesn't extensively explore scenarios where user behavior deviates from cascade models.
- Implementation Complexity: Method requires pre-computed or learned embeddings and representation learning pipeline; specific architecture details for neural network are not fully specified.

## Confidence

- **High Confidence:** Variance reduction mechanism and experimental results showing MSE improvements over baselines. Theoretical foundation for variance reduction via marginalization is well-established.
- **Medium Confidence:** Performance improvements in real-world experiments (EUR-Lex4K, RCV1-2K). While results are promising, reliance on specific embedding models and cascade assumption introduces uncertainty about generalizability.
- **Low Confidence:** Robustness when both assumptions (No Direct Effect and Cascade Behavior) are violated simultaneously. Paper doesn't extensively explore this worst-case scenario.

## Next Checks

1. **Assumption Validation:** Systematically test GMIPS performance when embeddings deliberately omit key causal features to quantify bias introduced when Assumption 3.2 is violated.

2. **Cascade Behavior Assessment:** Conduct experiments where user behavior follows non-cascade patterns (e.g., bottom-up examination) to measure MRIPS performance degradation and compare with alternative user models.

3. **Embedding Sensitivity Analysis:** Vary quality and dimensionality of embeddings systematically to identify minimum embedding quality required for GMIPS to outperform standard IPS, establishing practical deployment thresholds.