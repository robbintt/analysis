---
ver: rpa2
title: Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained
  Prompting
arxiv_id: '2510.02155'
source_url: https://arxiv.org/abs/2510.02155
tags:
- anomaly
- video
- prompts
- prompt
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ASK-HINT is a structured prompting framework that leverages fine-grained,
  action-centric prompts to enhance the reasoning capabilities of frozen vision-language
  models for video anomaly detection. The approach organizes prompts into semantically
  coherent groups (e.g., violence, property crimes, public safety) and formulates
  detailed guiding questions that align model predictions with discriminative visual
  cues.
---

# Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting

## Quick Facts
- arXiv ID: 2510.02155
- Source URL: https://arxiv.org/abs/2510.02155
- Reference count: 40
- Primary result: Training-free VAD method achieving SOTA AUC via structured fine-grained prompting

## Executive Summary
ASK-HINT is a structured prompting framework that leverages fine-grained, action-centric prompts to enhance the reasoning capabilities of frozen vision-language models for video anomaly detection. The approach organizes prompts into semantically coherent groups (e.g., violence, property crimes, public safety) and formulates detailed guiding questions that align model predictions with discriminative visual cues. Experiments on UCF-Crime and XD-Violence datasets demonstrate that ASK-HINT consistently improves AUC over prior baselines, achieving state-of-the-art performance compared to both fine-tuned and training-free methods. The framework provides interpretable reasoning traces toward anomalies and demonstrates strong generalization across datasets and VLM backbones, establishing a new training-free and generalizable solution for explainable video anomaly detection.

## Method Summary
ASK-HINT operates through a three-stage prompting framework using frozen vision-language models without training. First, it generates 3-5 action-centric Yes/No questions per anomaly class using a VLM. Second, it clusters these class-wise prompts semantically using the VLM's text encoder and summarizes each cluster into 2-3 generalized guiding questions, creating a compact prompt set (6 questions for UCF-Crime, 5 for XD-Violence). Third, it applies a structured two-stage inference template: binary classification (Normal/Abnormal) followed by group assignment with rationale when abnormal. The method uses uniform frame sampling (128 frames per video, fps=1 fallback) and a frozen VLM backbone (Qwen2.5-VL-7B-Instruct default) for zero-shot inference.

## Key Results
- ASK-HINT achieves 89.83% AUC on UCF-Crime, outperforming abstract-prompt baseline (74.50%) and fine-tuned methods
- Fine-grained prompting improves AUC by up to 30% over abstract prompting across nearly all crime categories
- ASK-HINT generalizes across different frozen VLM backbones (Qwen2.5-VL-7B, InternVL2.5-8B) with consistent improvements
- The framework provides interpretable reasoning traces with explicit justification for group assignments

## Why This Works (Mechanism)

### Mechanism 1
Fine-grained, action-centric prompts elicit more accurate reasoning from frozen VLMs than abstract anomaly labels. Abstract prompts (e.g., "Is there an anomaly?") provide insufficient visual grounding for VLMs to attend to discriminative features. Action-centric prompts (e.g., "Do you see punching, kicking, or wrestling?") align language queries with concrete visual patterns—human-object interactions, motion primitives, scene dynamics—that the pretrained visual encoder can reliably detect. This reduces ambiguity in the cross-modal alignment space.

### Mechanism 2
Semantically compressing class-wise prompts into a compact, representative set reduces hallucination while maintaining discriminative coverage. Anomaly categories share underlying action primitives (e.g., "setting fire" relates to both Arson and Explosion; "physical confrontation" spans Assault, Robbery, Fighting). By clustering prompts based on semantic similarity and summarizing each cluster into 2-3 generalized questions, the framework extracts shared visual reasoning cues. This compression reduces prompt length, mitigating attention dilution and hallucination effects from irrelevant or redundant prompts, while preserving cross-category generalization.

### Mechanism 3
Structured two-stage inference (binary classification → group assignment with rationale) improves interpretability and constrains the output space. The framework first prompts for normal/abnormal classification using the compressed prompt set, then—if abnormal—assigns the video to one of three semantically coherent groups (Violence/Harm to People, Crimes Against Property, Public Safety Incidents) and requires a short justification. This hierarchical structure provides explicit reasoning traces, reducing free-form generation variance and enabling human verification of decision logic.

## Foundational Learning

- **Zero-shot inference with frozen VLMs**
  - Why needed here: ASK-HINT operates entirely without weight updates; understanding how pretrained vision-language models transfer to downstream tasks via prompting is essential.
  - Quick check question: Can you explain why frozen models can perform new tasks through prompting alone, and what factors limit this transferability?

- **Cross-modal alignment in vision-language models**
  - Why needed here: The mechanism depends on language prompts aligning with visual feature channels in the frozen encoder; misalignment causes poor grounding.
  - Quick check question: What is the role of contrastive pretraining objectives (e.g., CLIP) in creating shared embedding spaces for text and images?

- **Prompt engineering for multimodal models**
  - Why needed here: The core contribution is a structured prompt design strategy; understanding prompt sensitivity and failure modes (hallucination, attention dilution) is critical.
  - Quick check question: Why might longer prompts with more detail sometimes degrade model performance in VLMs?

## Architecture Onboarding

- **Component map:** Prompt Generation Module → Semantic Compression Pipeline → Structured Inference Template → Frozen VLM Backbone

- **Critical path:**
  1. Define anomaly class taxonomy for target dataset.
  2. Generate class-wise action prompts (can be automated with VLM).
  3. Cluster prompts semantically; verify cluster coherence via similarity analysis (e.g., cosine similarity heatmap).
  4. Summarize clusters into compact prompt set Q* (target 5-7 questions).
  5. Implement structured inference template; validate output parsing logic.
  6. Benchmark against abstract-prompt baseline to verify improvement.

- **Design tradeoffs:**
  - **Prompt count vs. hallucination risk**: More prompts increase coverage but risk attention dilution; paper finds 6 prompts optimal for UCF-Crime.
  - **Manual vs. automated prompt generation**: Automated is scalable but may include noise; manual curation improves precision but doesn't scale.
  - **Group granularity**: Three groups (Violence, Property, Public Safety) balance interpretability and discriminability; finer groups increase complexity without proportional gains.

- **Failure signatures:**
  - **Low AUC with full prompt set** (~67% in Table 3): Indicates hallucination from prompt overload; compression required.
  - **High normal-accuracy, low abnormal-accuracy**: Prompts may be too specific, missing novel anomaly patterns; broaden action coverage.
  - **Inconsistent group/rationale outputs**: VLM struggles with instruction following; verify template formatting or switch to stronger backbone.
  - **Cross-dataset transfer degradation >15%**: Prompts overfit to source dataset semantics; need more generic action primitives.

- **First 3 experiments:**
  1. **Baseline comparison**: Implement abstract-prompt baseline ("Is there an anomaly?") vs. fine-grained ASK-HINT prompts on UCF-Crime; measure AUC gap to validate core claim.
  2. **Prompt count ablation**: Sweep from 3 to 12 guiding questions; plot AUC and crime-detection accuracy to find optimal count (replicate Table 5).
  3. **Cross-backbone validation**: Apply ASK-HINT to at least two frozen VLMs (e.g., Qwen2.5-VL-7B and InternVL2.5-8B); verify consistent improvement over abstract baseline (replicate Table 4 pattern).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ASK-HINT framework be extended to incorporate dynamic, context-aware prompting that adapts in real-time to video content?
- Basis in paper: [explicit] The authors explicitly state in the "Limitations and Future Work" section that the current reliance on a static prompt set derived offline may not fully capture novel anomalies in dynamic environments.
- Why unresolved: The current methodology compresses prompts into a fixed set ($Q^*$) prior to inference, which lacks the flexibility to adjust to specific visual contexts as they unfold.
- What evidence would resolve it: The development of an adaptive mechanism that generates or selects prompts on-the-fly based on initial video analysis, demonstrating superior performance on novel or evolving anomaly classes.

### Open Question 2
- Question: Can explicit temporal reasoning mechanisms be integrated into ASK-HINT to better handle evolving events without compromising its training-free nature?
- Basis in paper: [explicit] The paper identifies the lack of temporal modeling as a key limitation, noting the framework struggles to reason over "evolving events" compared to static action cues.
- Why unresolved: While the prompts are action-centric, the current inference relies on uniform frame sampling without a dedicated architecture to process the sequence or causality of events over time.
- What evidence would resolve it: A training-free temporal adapter or prompting strategy that improves detection AUC on anomalies defined by duration or sequence (e.g., "loitering" vs. "passing through") rather than instantaneous actions.

### Open Question 3
- Question: Does incorporating multimodal cues, such as audio, alongside fine-grained visual prompts improve detection accuracy in ambiguous scenarios?
- Basis in paper: [explicit] The authors list "incorporating... multimodal cues" as a specific direction for future work.
- Why unresolved: The current system relies on frozen vision-language models (VLMs), often ignoring the audio streams available in datasets like XD-Violence, potentially missing key cues (e.g., shouting, glass breaking).
- What evidence would resolve it: Experimental results showing that audio-conditioned prompting yields higher accuracy on the XD-Violence dataset compared to the vision-only ASK-HINT baseline.

## Limitations
- The framework depends heavily on the quality and semantic coherence of generated fine-grained prompts, which are not directly evaluated for coverage or relevance.
- The prompt clustering and summarization process relies on VLM-generated outputs, introducing potential variability and hallucination risks.
- Evaluation is limited to two datasets (UCF-Crime, XD-Violence), leaving generalizability to other anomaly detection domains untested.
- The structured reasoning outputs are evaluated qualitatively but not quantitatively against human-annotated explanations.

## Confidence
- **High confidence**: Core mechanism (fine-grained prompts outperform abstract prompts) is well-supported by ablation results (up to 30% AUC gain).
- **Medium confidence**: Generalization across VLM backbones is demonstrated but limited to three models; broader validation needed.
- **Medium confidence**: Interpretability claims rely on qualitative examples without quantitative human evaluation or automated consistency metrics.

## Next Checks
1. **Prompt quality audit**: Manually evaluate the generated fine-grained prompts for semantic relevance and coverage across anomaly categories to assess the reliability of the automated generation pipeline.
2. **Cross-dataset robustness test**: Apply ASK-HINT to a third, unseen video anomaly dataset (e.g., ShanghaiTech) to measure performance drop and prompt adaptability.
3. **Hallucination risk quantification**: Compare the variance in VLM outputs (e.g., group assignment consistency, rationale coherence) across multiple inference runs to measure hallucination severity under different prompt lengths and counts.