---
ver: rpa2
title: Debiasing Reward Models by Representation Learning with Guarantees
arxiv_id: '2510.23751'
source_url: https://arxiv.org/abs/2510.23751
tags:
- latent
- reward
- learning
- variables
- spurious
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses reward model biases in reinforcement learning
  from human feedback (RLHF), such as length bias, sycophancy, and concept bias. These
  biases occur when models learn spurious correlations rather than true human preferences.
---

# Debiasing Reward Models by Representation Learning with Guarantees

## Quick Facts
- **arXiv ID:** 2510.23751
- **Source URL:** https://arxiv.org/abs/2510.23751
- **Reference count:** 30
- **Primary result:** Proposed method CARD identifies and leverages bias-free latent variables to train reward models, making them more robust to biases like sycophancy (worst-case accuracy 0.63 vs 0.47 for vanilla) and concept bias (average bias@C 0.15 vs 0.42).

## Executive Summary
This paper addresses reward model biases in reinforcement learning from human feedback (RLHF), such as length bias, sycophancy, and concept bias. These biases occur when models learn spurious correlations rather than true human preferences. The proposed method, CARD, identifies and leverages bias-free latent variables to train reward models, making them more robust to these biases. The approach is grounded in theoretical identifiability results, showing that bias-free latent variables can be recovered under mild assumptions. Experiments on synthetic and real-world datasets demonstrate CARD's effectiveness, with significant improvements in worst-case accuracy and reduced bias scores compared to vanilla reward models.

## Method Summary
CARD is a two-stage approach that first learns a representation of the input text that is independent of known spurious features (surrogates), then trains a reward model on this bias-free representation. In the first stage, a customized VAE with a normalizing flow prior and HSIC regularizer learns to separate bias-free latents from spurious ones. The second stage trains a simple MLP reward model on the extracted bias-free latents using Bradley-Terry preference learning. The method can handle both known surrogates (like response length) and unknown surrogates through multi-annotator diversity assumptions, with theoretical guarantees on identifiability under specific conditions.

## Key Results
- On sycophancy bias experiments, CARD achieved worst-case accuracy of 0.63 compared to 0.47 for vanilla reward models when distribution shift was introduced
- For concept bias, CARD had a lower average bias@C score (0.15) than vanilla models (0.42), indicating better robustness to spurious correlations
- Synthetic data experiments validated the theoretical identifiability claims, with R² scores around 0.83 between ground truth and learned bias-free latents

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reward model biases can be mitigated by identifying and isolating a "bias-free" subspace of latent variables from the observed text.
- **Mechanism:** The paper proposes a generative model where observed text $T$ is a function of both bias-free latents ($Z_C$) and spurious latents ($Z_S$). The method uses variational inference to learn an encoder that maps text to these latent variables. By conditioning the prior on a spurious surrogate $S$ and enforcing an independence constraint, the encoder learns to separate the factors of variation.
- **Core assumption:** The data-generating process follows a structural equation model where $Z_C$ is independent of $S$, and there is sufficient variability in the data w.r.t. the surrogate (Assumption A1).
- **Evidence anchors:**
  - [abstract]: "propose a principled framework... assumes that the observed data... is generated from both spurious and non-spurious latent variables."
  - [section 3.1]: "Z_C is subspace identifiable... [requires] sufficient variability w.r.t. surrogate."
  - [corpus]: The neighbor paper "Beyond Reward Hacking" supports the general viability of causal factorization for alignment, though specific subspace methods vary.
- **Break condition:** If the variability assumption A1 is violated (e.g., the spurious feature $S$ does not induce sufficient changes in the latent distribution), the subspace $Z_C$ may not be identifiable, causing the disentanglement to fail.

### Mechanism 2
- **Claim:** Enforcing statistical independence between the learned representation and known spurious proxies removes specific biases (e.g., length, sycophancy).
- **Mechanism:** The Variational Autoencoder (VAE) loss includes a Hilbert-Schmidt Independence Criterion (HSIC) regularizer. This term penalizes statistical dependence between the estimated bias-free latents $\hat{Z}_C$ and the surrogate $S$, effectively projecting the representation onto a subspace orthogonal to the spurious features.
- **Core assumption:** A reliable surrogate $S$ (e.g., response length or a "sycophancy trigger" phrase) is available and measurable during training.
- **Evidence anchors:**
  - [section 4]: "independence regularization term uses [HSIC] to enforce the desired independence between the learned bias-free latent variables and the surrogate."
  - [corpus]: The "CoLD" paper explicitly targets length bias via counterfactual guidance, corroborating the efficacy of explicit debiasing terms, though CARD generalizes this via representation learning.
- **Break condition:** If the surrogate $S$ is a noisy proxy (does not fully capture the spurious concept) or if the HSIC weight $\lambda$ is set too low, the representation will retain spurious correlations.

### Mechanism 3
- **Claim:** Biases can be removed even without a known proxy by leveraging the diversity of multiple human labelers.
- **Mechanism:** In the absence of a surrogate, the method assumes access to reward signals from multiple labelers. It posits that the "true" signal is the intersection of factors relied upon by all labelers, while spurious factors vary between them. By enforcing sparsity in the weight matrix connecting latents to rewards, the shared subspace is identified.
- **Core assumption:** (1) Each labeler relies on all bias-free variables ($Z_C \subseteq Z_{A_k}$), and (2) no single spurious variable is shared by all labelers (Corollary 1).
- **Evidence anchors:**
  - [section 3.2]: "shared latent variables... correspond to the true bias-free latent variables."
  - [section 5]: The paper primarily validates the surrogate-based method experimentally; the surrogate-free method is supported theoretically (Theorem 2).
- **Break condition:** If all labelers share a specific bias (e.g., all prefer longer text), the shared subspace will incorrectly include that spurious variable as a "bias-free" feature.

## Foundational Learning

- **Concept: Causal Representation Learning & Identifiability**
  - **Why needed here:** The core theoretical contribution rests on "identifiability"—proving that specific latent variables can be uniquely recovered from data, which is generally impossible in deep learning without specific assumptions (e.g., non-Gaussianity or variability).
  - **Quick check question:** Can you explain why standard VAEs generally fail to recover disentangled factors without specific inductive biases or constraints like those in Theorem 1?

- **Concept: Variational Autoencoders (VAE) & ELBO**
  - **Why needed here:** CARD is implemented as a customized VAE. Understanding the trade-off between reconstruction loss (keeping information) and KL divergence/HSIC (removing information/spurious correlations) is critical for debugging.
  - **Quick check question:** How does adding the HSIC term to the ELBO affect the information bottleneck of the VAE?

- **Concept: Spurious Correlations in RLHF**
  - **Why needed here:** To interpret the results, one must distinguish between "reward hacking" (exploiting the RM) and the specific biases (sycophancy, length) that CARD targets.
  - **Quick check question:** In the sycophancy experiment (Section 5.2), how does the "distribution shift" between training and test sets simulate the failure of a vanilla reward model?

## Architecture Onboarding

- **Component map:** Raw Text $T$ + Surrogate $S$ → BERT Encoder → Sample $\hat{Z}_C$ (discard $\hat{Z}_S$) → Reward Head
- **Critical path:** Raw Text $T$ + Surrogate $S$ → BERT Encoder → Sample $\hat{Z}_C$ (discard $\hat{Z}_S$) → Reward Head
- **Design tradeoffs:**
  - **Theory vs. Practice:** The theory (Theorem 1) requires matching data distributions (achieved via ELBO), but practical implementation adds HSIC for stronger independence enforcement, potentially hurting reconstruction if $\lambda$ is too high.
  - **Surrogate Dependency:** The strongest results require a surrogate $S$. The surrogate-free version requires multi-annotator data, which is scarce.
- **Failure signatures:**
  - **Metric:** High reconstruction loss but low HSIC indicates the model is ignoring content to satisfy the independence constraint.
  - **Metric:** If the "worst-case accuracy" (Table 1) drops significantly under high distribution shift, the disentanglement has failed.
- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Verify identifiability by checking $R^2$ between ground-truth $Z_C$ and learned $\hat{Z}_C$ on synthetic data (Section 5.1).
  2. **Sycophancy Injection:** Train on the QA dataset with injected bias ($p_{train}=0.8$) and test on varying $p_{test}$ to plot "Deviation from Oracle" (Fig 4).
  3. **Ablation (Representation):** Train the reward head using only $\hat{Z}_S$ (spurious) vs $\hat{Z}_C$ (clean) to prove the information split is effective (Table 2).

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several limitations and future directions are implied by the experimental setup and theoretical assumptions.

## Limitations
- The theoretical guarantees rely heavily on Assumption A1 (sufficient variability in the surrogate), which may not hold in real-world datasets where spurious features are subtle or highly correlated with true signals.
- The method's performance is sensitive to hyperparameter choices, particularly the HSIC regularization weight λ and the latent dimensionality, which are not extensively explored in the paper.
- The surrogate-free method, while theoretically sound, requires multi-annotator data, which is often unavailable in practice, limiting its practical applicability.

## Confidence

- **High Confidence:** The synthetic data experiments (Section 5.1) demonstrate that CARD can successfully recover bias-free latents under controlled conditions, validating the core mechanism. The sycophancy bias experiments show a clear improvement in worst-case accuracy (0.63 vs 0.47) when distribution shift is introduced, supporting the claim that CARD mitigates specific biases.
- **Medium Confidence:** The concept bias experiments (Amazon Shoe Reviews) show a reduction in Bias@C score (0.15 vs 0.42), but the synthetic nature of the bias injection and the specific dataset characteristics may limit generalizability. The theoretical identifiability results (Theorem 1) are sound under stated assumptions, but real-world violations of these assumptions are not fully explored.
- **Low Confidence:** The surrogate-free method (Section 3.2) is only validated theoretically (Theorem 2 and Corollary 1). Without empirical validation on real data, its practical effectiveness remains uncertain, especially given the strict assumptions about annotator behavior.

## Next Checks

1. **Robustness to Assumption Violations:** Systematically test CARD's performance when Assumption A1 is violated (e.g., by reducing the variability of the surrogate) to quantify the degradation in bias mitigation.
2. **Hyperparameter Sensitivity Analysis:** Conduct an ablation study on the HSIC weight λ and latent dimensionality to identify stable configurations and potential failure modes.
3. **Real-World Multi-Annotator Validation:** Apply the surrogate-free method to a dataset with multiple human labelers (e.g., a preference dataset with diverse annotator pools) to empirically validate Theorem 2's claims about shared latent variable identification.