---
ver: rpa2
title: 'Sharp Minima Can Generalize: A Loss Landscape Perspective On Data'
arxiv_id: '2511.04808'
source_url: https://arxiv.org/abs/2511.04808
tags:
- minima
- volume
- volumes
- training
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the role of data size in generalization
  by measuring the volumes of minima found in neural network loss landscapes. While
  the volume hypothesis suggests flat minima generalize well due to their large volumes,
  the authors find that minima trained on small datasets can have large volumes yet
  generalize poorly, contradicting the flat minima hypothesis in low-data regimes.
---

# Sharp Minima Can Generalize: A Loss Landscape Perspective On Data

## Quick Facts
- **arXiv ID**: 2511.04808
- **Source URL**: https://arxiv.org/abs/2511.04808
- **Reference count**: 40
- **Primary result**: Minima trained on small datasets can have large volumes yet generalize poorly, contradicting the flat minima hypothesis in low-data regimes

## Executive Summary
This paper challenges the conventional wisdom that flat minima always generalize better by examining how data size affects loss landscape geometry. Through systematic experiments across MNIST, CIFAR10, SVHN, and Fashion MNIST, the authors demonstrate that while the volume hypothesis holds in large-data regimes, small datasets can produce flat minima with large volumes that generalize poorly. They show that increasing dataset size rapidly shrinks the volume of previously flat minima, allowing sharp minima from larger datasets to become the dominant solutions. The work reveals a power-law relationship between minima volume and dataset size spanning three orders of magnitude, suggesting that generalization involves complex interactions between landscape geometry and data quantity rather than flatness alone.

## Method Summary
The authors measure minima volumes in neural network loss landscapes by sampling around trained models and computing the fraction of samples that achieve similar loss values. They systematically vary dataset sizes from very small (dozens of examples) to full training sets across multiple architectures (MLPs, CNNs) and datasets (MNIST, CIFAR10, SVHN, Fashion MNIST). The volume measurements are combined with generalization gap calculations to understand how landscape geometry correlates with performance. The study examines both flat and sharp minima across different training regimes, using consistent optimization procedures and architecture configurations to isolate the effects of data quantity on landscape structure.

## Key Results
- Small datasets can produce flat minima with large volumes that generalize poorly, contradicting the flat minima hypothesis in low-data regimes
- Increasing dataset size causes previously flat minima to shrink rapidly in volume, allowing sharp minima to become the largest-volume solutions
- A power-law relationship exists between minima volume and dataset size spanning three orders of magnitude across all tested datasets
- Generalization in deep learning involves complex interactions between landscape geometry and data quantity rather than flatness alone

## Why This Works (Mechanism)
The mechanism underlying these findings relates to how data quantity shapes the loss landscape geometry. With insufficient data, the loss surface develops broad, flat regions that occupy large volumes in parameter space but correspond to poor generalization due to overfitting. As more data is added, these flat regions contract while the landscape develops sharper, more focused minima that better capture the underlying data distribution. The volume of any given minimum depends critically on the dataset size used during training, with the relationship following a power law that spans multiple orders of magnitude. This dynamic shows that landscape geometry is not an intrinsic property of the architecture but rather emerges from the interaction between model, optimization, and data quantity.

## Foundational Learning
- **Loss landscape geometry**: Understanding how the shape of the loss surface around minima affects generalization. Needed to interpret why flat vs. sharp minima behave differently. Quick check: Can you visualize or compute the curvature around a trained minimum?
- **Generalization gap**: The difference between training and test performance. Essential for measuring whether minima truly capture underlying patterns. Quick check: Can you calculate training vs. test accuracy for a trained model?
- **Volume measurement in parameter space**: Quantifying the region around minima with similar loss values. Critical for testing the volume hypothesis. Quick check: Can you sample around a minimum and measure the fraction with similar loss?
- **Power-law relationships**: Scaling behavior across multiple orders of magnitude. Important for understanding systematic patterns in landscape geometry. Quick check: Can you fit a power law to volume vs. dataset size data?

## Architecture Onboarding

**Component Map**: Data sampling -> Loss landscape measurement -> Volume calculation -> Generalization gap analysis -> Scaling law fitting

**Critical Path**: The essential sequence is training models on varying dataset sizes → measuring volumes around each minimum → computing generalization gaps → analyzing volume-generalization relationships. Each step depends on the previous: training quality affects volume measurement accuracy, which determines the reliability of generalization gap analysis.

**Design Tradeoffs**: The study uses consistent architectures and optimization across conditions to isolate data effects, sacrificing potential performance gains from architecture tuning. Volume measurement precision trades off against computational cost, requiring careful sampling strategies. The choice of synthetic vs. real data affects the ecological validity of findings.

**Failure Signatures**: Inconsistent volume measurements across repeated runs suggest optimization instability. Lack of clear volume-generalization correlation indicates measurement issues or inappropriate architecture choices. Absence of power-law scaling suggests the relationship may not be universal or requires larger parameter ranges.

**First Experiments**:
1. Train a simple MLP on MNIST with varying dataset sizes (10%, 25%, 50%, 100%) and measure volumes around each minimum
2. Compare volume-generalization relationships between MLPs and CNNs on CIFAR10 across the same dataset sizes
3. Test whether synthetic data with controlled properties produces similar volume scaling laws

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Volume measurement approach may not capture full loss landscape complexity due to sampling limitations
- Results focus on small-scale datasets and standard architectures, leaving scalability to larger models unclear
- The study does not fully explore how data distribution characteristics (class balance, feature diversity) affect volume dynamics
- While challenging flatness as sole predictor, the paper does not provide a complete alternative generalization framework for low-data regimes

## Confidence
- High confidence in empirical observations of volume changes with dataset size across tested architectures and datasets
- Medium confidence in the power-law relationship between volume and dataset size, given limited exploration of parameter ranges
- Medium confidence in the claim that flat minima can generalize poorly in low-data regimes, though theoretical explanation could be more rigorous

## Next Checks
1. Test the volume-dataset size relationship on larger architectures (ResNet, Vision Transformers) and more complex datasets (ImageNet) to verify scalability
2. Investigate whether the power-law exponent varies systematically with architecture depth, width, or type of nonlinearity
3. Design controlled experiments with synthetic data distributions to isolate effects of data diversity versus quantity on loss landscape geometry