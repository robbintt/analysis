---
ver: rpa2
title: 'FairGSE: Fairness-Aware Graph Neural Network without High False Positive Rates'
arxiv_id: '2511.12132'
source_url: https://arxiv.org/abs/2511.12132
tags:
- graph
- fairness
- uni00000013
- fairgse
- sensitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the underexplored issue of high False Positive
  Rates (FPR) in fairness-aware Graph Neural Networks (GNNs), where fairness improvements
  often come at the cost of excessive misclassifications. The authors introduce a
  novel framework, FairGSE, which leverages two-dimensional structural entropy (2D-SE)
  to balance message aggregation across sensitive groups and avoid FPR shortcuts.
---

# FairGSE: Fairness-Aware Graph Neural Network without High False Positive Rates

## Quick Facts
- **arXiv ID:** 2511.12132
- **Source URL:** https://arxiv.org/abs/2511.12132
- **Reference count:** 31
- **Primary result:** Reduces FPR by 39% compared to state-of-the-art methods while maintaining fairness and accuracy.

## Executive Summary
This paper addresses the underexplored problem of high False Positive Rates (FPR) in fairness-aware Graph Neural Networks (GNNs). Traditional fairness methods often achieve fairness metrics by predicting all instances as positive, resulting in near-zero fairness gaps but 100% FPR. FairGSE introduces a novel framework that leverages two-dimensional structural entropy (2D-SE) to balance message aggregation across sensitive groups while preventing FPR shortcuts. The method adaptively reweights graph edges to maximize entropy, uses contrastive learning to preserve original graph structure, and employs bootstrapping to mitigate bias propagation.

## Method Summary
FairGSE jointly optimizes three objectives: task classification loss, contrastive learning between original and learned graph views, and 2D-SE maximization. The method learns a weighted adjacency matrix that maximizes entropy between sensitive groups while maintaining classification accuracy through contrastive regularization. A bootstrapping mechanism slowly updates the anchor view with debiased structure from the learner view, creating a self-enhancing fairness loop. The framework theoretically bounds fairness metrics and FPR through entropy maximization, preventing trivial solutions that predict all positive instances.

## Key Results
- Reduces FPR by 39% compared to state-of-the-art fairness methods
- Maintains competitive fairness metrics (ΔSP and ΔEO) while avoiding FPR shortcuts
- Achieves better accuracy-fairness trade-offs than baseline methods on real-world datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Maximizing 2D-SE bounds both group fairness metrics and FPR, preventing the "predict-all-positive" shortcut.
- **Mechanism:** Optimizes edge weights to balance information flow across sensitive groups, reducing mutual information between representations and sensitive attributes.
- **Core assumption:** Graph topology can be modified without destroying task-relevant information; binary sensitive attributes and labels.
- **Evidence anchors:** Abstract confirms 2D-SE usage; Theoretical Analysis provides formal bounds; Corpus supports general bias mitigation but lacks specific validation.
- **Break condition:** If original graph is too sparse or biased, reweighting may fail to converge or disconnect the graph.

### Mechanism 2
- **Claim:** Contrastive learning between learner and anchor views preserves structural integrity while removing bias.
- **Mechanism:** Uses symmetric NT-Xent loss to maximize agreement between projected representations, preventing over-modification that destroys accuracy.
- **Core assumption:** Original graph contains task-relevant structural signals distinct from sensitive attribute biases.
- **Evidence anchors:** Section confirms contrastive learning prevents deviations; Ablation study shows w/o CL has less stable performance; Corpus provides indirect support through FairACE paper.
- **Break condition:** If anchor view contains severe bias, contrastive loss forces learner to re-learn that bias.

### Mechanism 3
- **Claim:** Structure bootstrapping prevents anchor view from re-injecting inherited bias into learner view.
- **Mechanism:** Updates anchor view as slow-moving exponential moving average of learner view, creating self-enhancing debiasing loop.
- **Core assumption:** Learner view successfully learns debiased structure; otherwise, bootstrapping propagates errors.
- **Evidence anchors:** Section states bootstrapping prevents repeated alignment with biased anchor; Ablation study shows w/o SBM has worse fairness on imbalanced Credit dataset; Corpus lacks specific bootstrapping evidence.
- **Break condition:** If decay rate is too low, training becomes unstable; if too high, bias persists too long.

## Foundational Learning

- **Concept:** False Positive Rate (FPR) vs. Fairness Metrics
  - **Why needed here:** Standard fairness metrics can be "gamed" by predicting everyone positive (high FPR), resulting in useless models. Understanding this distinction is critical.
  - **Quick check question:** If a model predicts 100% of applicants as "high risk" to ensure parity, what happens to ΔSP and the FPR? (Answer: ΔSP becomes 0, FPR becomes 100%).

- **Concept:** Structural Entropy (Information Theory)
  - **Why needed here:** Core objective function quantifies uncertainty of random walk confined to sensitive groups, mathematically driving the method.
  - **Quick check question:** In a graph partitioned by sensitive attribute, does higher structural entropy imply more or less connectivity between groups? (Answer: High entropy implies more uniform/random structure, reducing certainty of staying within specific group structure).

- **Concept:** Graph Contrastive Learning
  - **Why needed here:** FairGSE balances maximizing entropy (changes graph) and preserving structure (via contrastive learning).
  - **Quick check question:** In FairGSE, what constitutes the positive pair in the contrastive loss? (Answer: Representations of the same node from Anchor View and Learner View).

## Architecture Onboarding

- **Component map:** Graph Structure Learner -> 2D-SE Calculator -> GNN Encoder/Projector -> Bootstrapping Updater -> Classifier
- **Critical path:** Sample nodes → Generate learner adjacency → Compute 2D-SE loss → Encode both views → Calculate contrastive loss → Backprop total loss → Update anchor via EMA
- **Design tradeoffs:**
  - λ₂ (Entropy weight): Too high distorts graph, destroying accuracy; too low fails to reduce FPR/imbalance
  - τ (Bootstrap decay): 0.9999 used; lower values cause instability, higher values let bias persist
  - FPR vs. Fairness: Method trades "perfect" fairness scores for calibrated FPR
- **Failure signatures:**
  - High FPR on imbalanced data: λ₁ too high, learner copies biased anchor
  - Loss instability: 2D-SE gradients explode on sparse graphs
  - OOM: Storing dense adjacency matrix on large graphs
- **First 3 experiments:**
  1. Vanilla GCN vs. FairGSE on Credit dataset: Verify FairGSE FPR ~41% vs FairSIN ~100%
  2. Disable Graph Structure Learner (w/o GSL) on Credit: Observe FPR rise (Figure 3 shows increase)
  3. Sweep λ₂ on Credit: Confirm "U-shape" curve where FPR decreases then accuracy suffers

## Open Questions the Paper Calls Out

- **Open Question 1:** How can FairGSE be extended to handle multi-class node classification or link prediction tasks?
  - **Basis:** Conclusion explicitly states aim to extend to complex tasks like multi-class or edge prediction
  - **Why unresolved:** Current framework relies on binary labels for FPR definition and binary attributes for structural entropy partition
  - **What evidence would resolve:** Reformulation of 2D-SE and FPR constraint for multi-class settings with experimental validation

- **Open Question 2:** Can FairGSE effectively reduce FPR shortcuts when sensitive attributes are limited or unavailable during training?
  - **Basis:** Conclusion explicitly identifies this gap for limited/unavailable sensitive attributes
  - **Why unresolved:** Core mechanism requires known sensitive attributes to compute optimization objective
  - **What evidence would resolve:** Variant using proxy attributes or inferred sensitive groups, demonstrating robustness against missing data

- **Open Question 3:** How does FairGSE perform on graphs with continuous or multi-valued sensitive attributes without arbitrary binning?
  - **Basis:** Preliminaries restricts sensitive attribute to binary values; 2D-SE relies on discrete partition
  - **Why unresolved:** Current method requires discretization of continuous attributes, potentially introducing information loss
  - **What evidence would resolve:** Extension to continuous attributes (differential entropy) or adaptive binning strategy validated on continuous sensitive features

## Limitations

- Theoretical claims linking 2D-SE maximization to fairness bounds are derived but not empirically validated for all edge cases
- Dataset selection limited to three datasets with binary sensitive attributes and binary labels, limiting generalizability
- Hyperparameter sensitivity around λ₁ and λ₂ suggests method may be brittle to dataset characteristics

## Confidence

- **Theoretical Framework**: Medium - Formal bounds exist but require stronger empirical validation
- **Empirical Results**: Medium - Significant FPR reduction demonstrated, but ablation studies have gaps
- **Generalizability**: Low - Limited to specific dataset types and binary attributes

## Next Checks

1. Test FairGSE on a multi-class fairness dataset (e.g., OGB-MAG240-M) to evaluate performance beyond binary classification
2. Evaluate the method with continuous sensitive attributes (e.g., age as numeric rather than binary) to test the partitioning mechanism
3. Conduct a hyperparameter sensitivity analysis across the full range of λ₁ and λ₂ values to identify robustness boundaries