---
ver: rpa2
title: Reducing Class-wise Confusion for Incremental Learning with Disentangled Manifolds
arxiv_id: '2503.17677'
source_url: https://arxiv.org/abs/2503.17677
tags:
- class
- learning
- uni00000013
- uni00000018
- confusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses class incremental learning (CIL) by targeting
  class-wise confusion arising from inadequate representation and feature overlap.
  The authors propose CREATE, a Confusion-REduced Autoencoder classifier that uses
  lightweight class-specific autoencoders to learn compact manifolds for each class,
  enhancing representation stability and discrimination.
---

# Reducing Class-wise Confusion for Incremental Learning with Disentangled Manifolds

## Quick Facts
- **arXiv ID**: 2503.17677
- **Source URL**: https://arxiv.org/abs/2503.17677
- **Reference count**: 39
- **Primary result**: Achieves up to 5.41% higher accuracy than state-of-the-art methods on CIFAR100 and ImageNet100 with superior parameter efficiency

## Executive Summary
This paper addresses class incremental learning (CIL) by targeting class-wise confusion arising from inadequate representation and feature overlap. The authors propose CREATE, a Confusion-REduced Autoencoder classifier that uses lightweight class-specific autoencoders to learn compact manifolds for each class, enhancing representation stability and discrimination. A confusion-aware separation loss is further introduced to disentangle overlapped features in the latent space. The method outperforms state-of-the-art approaches by up to 5.41% in accuracy on CIFAR100 and ImageNet100, with superior parameter efficiency and consistent performance across incremental phases.

## Method Summary
CREATE tackles class incremental learning by learning compact class-specific manifolds via lightweight auto-encoders for each class. During training, a shared feature extractor processes inputs, which are then passed through all class-specific auto-encoders. Classification is performed by selecting the class whose auto-encoder yields the lowest reconstruction error. The method introduces a confusion-aware separation loss to disentangle overlapping features in latent space and uses knowledge distillation to maintain old auto-encoder performance as features drift. All auto-encoders remain trainable to adapt to feature drift while preserving manifold structure.

## Key Results
- Achieves 5.41% higher accuracy than state-of-the-art methods on CIFAR100 and ImageNet100
- Outperforms DER by 3.93% on CIFAR100 and 2.83% on ImageNet100 using only auto-encoders (no LCR)
- Additional 1.33% gain from confusion-aware separation loss (LCR)
- Demonstrates superior parameter efficiency compared to expansion-based methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using class-specific auto-encoders as manifold learners improves representational capacity beyond single prototype vectors, enabling better capture of intra-class variability.
- Mechanism: Each class gets a dedicated lightweight auto-encoder that learns to compress features into a low-dimensional manifold and reconstruct them. During inference, reconstruction error across all auto-encoders determines class membership—the correct class yields lowest error. This implicitly models distribution rather than relying on a single centroid.
- Core assumption: Features from the same class share recoverable low-dimensional structure that can be learned independently per class without cross-class interference.
- Evidence anchors:
  - [abstract] "employs a lightweight auto-encoder module to learn compact manifold for each class in the latent subspace, constraining samples to be well reconstructed only on the semantically correct auto-encoder"
  - [section 3.2] "The manifolds of each class reside in their respective subspaces, remaining unaffected by others, and thus are disentangled"
  - [corpus] Weak direct validation; related CIL methods use prototypes but not class-specific auto-encoders for manifold learning
- Break condition: When class manifolds are highly non-convex or when feature drift between tasks is so extreme that old auto-encoders cannot adapt via gradient updates.

### Mechanism 2
- Claim: Confusion-aware separation loss (LCR) explicitly pushes apart samples that would otherwise have similar reconstruction errors across multiple auto-encoders.
- Mechanism: Computes confusion score based on gap between smallest and second-smallest reconstruction errors. Samples with small gaps (high confusion) receive higher weights in a contrastive loss that pulls same-class features closer in latent space while pushing different-class features apart.
- Core assumption: Confusion score meaningfully identifies samples at decision boundaries, and weighted contrastive learning in latent space transfers to improved reconstruction-based discrimination.
- Evidence anchors:
  - [abstract] "confusion-aware latent space separation loss that ensures samples are closely distributed in their corresponding low-dimensional manifold while keeping away from the distributions of features from other classes"
  - [section 3.3] Eq. 5-8 showing confusion score definition and weighted contrastive formulation
  - [corpus] No direct external validation; contrastive learning for CIL appears in related work but not with confusion-weighting
- Break condition: When confusion scores are dominated by noise rather than genuine boundary cases, or when negative samples in contrastive loss are insufficiently representative of confusing classes.

### Mechanism 3
- Claim: Maintaining old auto-encoders as trainable (not frozen) allows them to adapt to feature extractor drift while preserving learned manifold structure via distillation.
- Mechanism: When feature extractor ϕ updates for new tasks, old class features shift. Old auto-encoders are kept trainable with knowledge distillation loss on their reconstruction-based logits, allowing manifold re-adaptation without catastrophic forgetting of class geometry.
- Core assumption: Feature drift is gradual enough that auto-encoders can track it via gradient descent, and distillation provides sufficient regularization to prevent manifold collapse.
- Evidence anchors:
  - [section 3.2] "the feature extractor and auto-encoders remain unfrozen during training to adapt to new tasks... If the auto-encoder for an old class is frozen, its subspace will remain unchanged, making it unable to adapt to and match the shifted features"
  - [section 3.2] Eq. 4 showing distillation loss formulation
  - [corpus] No validation; related methods (DER, FOSTER) use expansion rather than trainable adaptation
- Break condition: When feature drift is abrupt (large representation changes between tasks), or when distillation temperature τd is poorly tuned causing either over-regularization or insufficient retention.

## Foundational Learning

- **Concept: Manifold Learning and Auto-encoders**
  - Why needed here: The entire method frames class representation as learning low-dimensional manifolds via auto-encoder reconstruction. Understanding manifold hypothesis (data concentrates on low-dimensional structures) and how auto-encoders approximate manifold recovery is essential.
  - Quick check question: Given a feature space where class A forms two separate clusters, why would a single prototype fail but an auto-encoder potentially succeed?

- **Concept: Catastrophic Forgetting in Incremental Learning**
  - Why needed here: CREATE specifically targets forgetting caused by feature drift and class confusion. Understanding why neural networks forget (parameter interference, representation shift) contextualizes the design choices.
  - Quick check question: If you freeze all old class parameters when learning new classes, what two problems might arise in this method's context?

- **Concept: Knowledge Distillation**
  - Why needed here: The method uses logits-level distillation to preserve old auto-encoder behavior. Understanding soft targets and temperature scaling explains why this helps rather than hurts plasticity.
  - Quick check question: Why distill reconstruction-based logits rather than directly constrain auto-encoder weights or latent representations?

## Architecture Onboarding

- **Component map:**
  - Feature extractor ϕ (ResNet18 backbone, shared across all classes)
  - Class-specific auto-encoders {AE₁, AE₂, ..., AEₙ} where each AEᵢ = encoder fᵢ + decoder gᵢ
  - Each encoder: 1×1 conv (d→32 channels) + tanh
  - Each decoder: 1×1 conv (32→d channels) + tanh
  - Loss modules: LCE (reconstruction-based classification), LKD (distillation), LCR (confusion-aware separation)

- **Critical path:**
  1. Forward pass: Input → ϕ → features h → parallel reconstruction through all AEᵢ → errors εᵢ → softmax probabilities via Eq. 2
  2. New task arrival: Append new AEs, keep old AEs trainable, compute all three losses
  3. Inference: Single forward pass, predict class with minimum reconstruction error (equivalently, highest probability)

- **Design tradeoffs:**
  - Latent dimension (32): Larger captures more information but with diminishing returns (0.07% gain from 32→64 in ablation)
  - Single vs. multi-layer auto-encoders: Single layer sufficient and more parameter-efficient
  - α (error scaling): Set to 0.1; controls sharpness of probability distribution
  - λ (LCR weight): Set to 1; balances separation vs. reconstruction objectives

- **Failure signatures:**
  - Auto-encoder collapse: Reconstruction errors converge to similar values across all classes → check confusion score distribution
  - Manifold interference: Old class accuracy drops sharply after specific new class → examine feature overlap in latent space visualization
  - Over-regularization: Both old and new class accuracy low → distillation temperature may be too aggressive

- **First 3 experiments:**
  1. **Baseline validation:** Run CIFAR100 Base50-Inc10 with only LCE (no LKD, no LCR) to isolate auto-encoder contribution vs. prototype methods
  2. **Ablation sequence:** Add LKD, then add LCR separately to measure individual component gains (paper shows +3.93% from AE alone, additional +1.33% from LCR)
  3. **Drift sensitivity:** Freeze old auto-encoders vs. keep trainable, measure accuracy gap on old classes across 5+ incremental steps to validate the trainable adaptation hypothesis

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the inference latency scale in scenarios involving thousands of classes, given the requirement to pass inputs through every class-specific auto-encoder?
- **Basis in paper**: [Inferred] The method requires calculating reconstruction errors for all auto-encoders to compute the softmax probability (Eq. 2), and experiments were limited to 100 classes.
- **Why unresolved**: The computational cost increases linearly with the number of classes, which may be prohibitive for large-scale, real-time applications.
- **Evidence to resolve**: Benchmarks on large-scale datasets (e.g., ImageNet-1K) measuring inference time per image against the total class count.

### Open Question 2
- **Question**: Can the lightweight 1x1 convolutional auto-encoder architecture effectively model complex distributions in high-resolution or non-image data domains?
- **Basis in paper**: [Inferred] The authors explicitly utilized a "lightweight" structure with 1x1 convolutions, validated only on CIFAR100 and ImageNet100.
- **Why unresolved**: While efficient, 1x1 convolutions may lack the spatial context required to learn disentangled manifolds for complex textures or high-dimensional sequential data.
- **Evidence to resolve**: Experimental results on high-resolution datasets (e.g., pathology images) or modalities like audio/text using the proposed architecture.

### Open Question 3
- **Question**: How does CREATE perform in a pure non-exemplar setting (zero memory) where the feature drift compensation provided by distillation is unavailable?
- **Basis in paper**: [Inferred] The method relies on a memory buffer ($M_t$) for distillation ($L_{KD}$) and updating old auto-encoders.
- **Why unresolved**: It is unclear if the manifold learning stability is inherent to the auto-encoder structure or dependent on rehearsing stored exemplars to correct drift.
- **Evidence to resolve**: Ablation studies setting the memory buffer size to zero and comparing the retention of old class manifolds against non-exemplar baselines.

## Limitations
- Limited to 100-class datasets (CIFAR100, ImageNet100), leaving scalability to thousands of classes unexplored
- No ablation testing frozen vs. trainable auto-encoders to validate the drift adaptation hypothesis
- Confusion score effectiveness depends critically on β and τr hyperparameters without sensitivity analysis

## Confidence
- **High confidence**: Parameter efficiency claims (clearly demonstrated), final accuracy numbers (reported with standard deviations across runs)
- **Medium confidence**: Ablation results showing LCE (+3.93%), LKD contribution, and LCR (+1.33%) gains separately
- **Low confidence**: Theoretical claims about why auto-encoders outperform prototypes for manifold learning, and whether confusion scores reliably identify boundary samples

## Next Checks
1. **Ablation of freezing vs. training**: Run CIFAR100 Base50-Inc10 with frozen old auto-encoders (as would happen in traditional replay methods) versus trainable ones, measuring old-class accuracy decay across 5+ incremental phases to directly validate the drift adaptation hypothesis.
2. **Prototype baseline comparison**: Implement exact DER architecture but replace DER's prototypes with CREATE's auto-encoders (keeping all other components identical) to isolate the auto-encoder contribution from other architectural differences.
3. **Confusion score sensitivity**: Sweep β (2→4→6) and τr (0.1→0.5→1.0) on CIFAR100, measuring LCR loss magnitude and final accuracy to identify whether the reported settings are optimal or conservative choices.