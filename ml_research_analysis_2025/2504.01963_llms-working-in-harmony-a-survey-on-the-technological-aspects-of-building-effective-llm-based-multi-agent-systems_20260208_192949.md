---
ver: rpa2
title: 'LLMs Working in Harmony: A Survey on the Technological Aspects of Building
  Effective LLM-Based Multi Agent Systems'
arxiv_id: '2504.01963'
source_url: https://arxiv.org/abs/2504.01963
tags:
- agents
- llms
- memory
- tasks
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey identifies optimal architectures and frameworks for
  building effective LLM-based multi-agent systems, addressing challenges like scalability,
  real-time responsiveness, and coordination. It highlights the Mixture-of-Agents
  (MoA) architecture for structured collaboration and the ReAct framework for integrating
  reasoning and action, both demonstrating significant performance improvements.
---

# LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems

## Quick Facts
- arXiv ID: 2504.01963
- Source URL: https://arxiv.org/abs/2504.01963
- Reference count: 31
- Multi-agent LLM systems benefit from specialized architectures like MoA and ReAct, with memory solutions tailored to application needs

## Executive Summary
This survey provides a comprehensive overview of architectures, frameworks, and memory systems for building effective LLM-based multi-agent systems. It identifies the Mixture-of-Agents (MoA) architecture as optimal for structured collaboration, where proposer and aggregator roles leverage different LLM strengths. The ReAct framework integrates reasoning and action to mitigate hallucination and improve plan reliability. Memory solutions are application-specific, with short-term and long-term approaches serving distinct needs. The survey provides a roadmap for advancing LLM multi-agent systems, highlighting challenges in scalability, real-time responsiveness, and coordination.

## Method Summary
The survey employed a systematic literature review methodology, searching Google Scholar, IEEE Xplore, and arXiv using targeted keywords across four categories: Architecture, Memory, Planning, and Technologies/Frameworks. The analysis evaluates systems across benchmarks including AlpacaEval 2.0, MT-Bench, HotpotQA, MATH, ALFWorld, and MiniWoB++. The survey identifies optimal architectures and frameworks while addressing challenges like scalability, real-time responsiveness, and coordination in LLM-based multi-agent systems.

## Key Results
- Mixture-of-Agents (MoA) architecture demonstrates significant performance improvements through structured collaboration with specialized proposer and aggregator roles
- ReAct framework effectively mitigates hallucination and error propagation by interleaving reasoning traces with task-specific actions
- Memory solutions must be application-specific, with short-term memory excelling for rapid access to recent information and long-term memory valuable for deep information retention

## Why This Works (Mechanism)

### Mechanism 1
Layered proposer-aggregator architectures produce higher-quality outputs than single-agent or naive multi-agent chaining. The MoA design separates agents into proposers (generating diverse responses) and aggregators (synthesizing responses into coherent outputs). This division exploits the observation that different LLMs have different strengths—some excel at generating diverse ideas, others at integration and synthesis.

### Mechanism 2
Interleaved reasoning and action (ReAct) mitigates hallucination and improves plan reliability compared to separated reasoning-then-acting approaches. ReAct alternates between generating reasoning traces and executing task-specific actions, creating feedback loops where reasoning guides action and action grounds reasoning.

### Mechanism 3
Memory architecture choice (short-term vs. long-term, parametric vs. non-parametric) determines system capability but must be matched to application requirements—no single approach dominates. Different memory systems serve distinct functions: vector databases enable efficient similarity-based retrieval; RAG combines parametric model knowledge with non-parametric external sources.

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) prompting
  - Why needed here: MoA builds on CoT by extending single-agent reasoning traces to multi-agent debate and synthesis. ReAct extends CoT by interleaving reasoning with action.
  - Quick check question: Can you explain why prompting an LLM to "think step by step" improves performance on multi-step reasoning tasks?

- **Concept**: Transformer attention mechanisms
  - Why needed here: The survey traces modern LLMs to the Transformer architecture. Understanding attention helps explain why context window limitations exist and why external memory systems are necessary.
  - Quick check question: Why does a Transformer's computational cost scale quadratically with sequence length, and what does this imply for handling long documents?

- **Concept**: Role-based agent decomposition
  - Why needed here: MoA's proposer/aggregator split, MetaGPT's SOP-based roles, and CAMEL's role-playing approach all assume that decomposing complex tasks into specialized agent roles improves outcomes.
  - Quick check question: Given a complex task (e.g., "build a web application"), how would you decompose it into agent roles, and what information must each role share with others?

## Architecture Onboarding

- **Component map**: [User Query] → [Orchestrator/Router] → [Agent Pool] → [Memory Layer] → [Planning Module] → [Response Synthesis] → [Output]

- **Critical path**:
  1. Start with framework selection (AutoGen, CrewAI, MetaGPT, or LangGraph) based on language preference, workflow complexity, and orchestration needs
  2. Design agent roles before implementing—determine which LLMs will be proposers vs. aggregators based on specialization observations
  3. Select memory system based on context horizon: short-term → simple context passing; long-term → RAG or MemoryBank; structured reasoning → ChatDB
  4. Integrate ReAct-style interleaved reasoning if tasks require external tool use or knowledge retrieval

- **Design tradeoffs**:
  | Decision | Option A | Option B | Tradeoff |
  |----------|----------|----------|----------|
  | Architecture | MoA (layered) | CoA (sequential) | MoA: better quality, higher cost; CoA: lower latency, handles long-context |
  | Planning | ReAct | ToT | ReAct: simpler, faster; ToT: better for deliberative search, more expensive |
  | Memory | RAG (non-parametric) | Fine-tuning (parametric) | RAG: updatable knowledge, retrieval latency; Fine-tuning: faster inference, static knowledge |
  | Framework | AutoGen | LangGraph | AutoGen: conversation-centric, flexible; LangGraph: stateful cyclic workflows, steeper learning curve |

- **Failure signatures**:
  - Hallucination cascade: Agents build on incorrect intermediate conclusions
  - Role collapse: Agents converge to similar responses despite different assigned roles
  - Memory pollution: Retrieved context includes irrelevant or contradictory information
  - Coordination deadlock: Agents wait for inputs that never arrive in sequential architectures

- **First 3 experiments**:
  1. Implement a simple 3-proposer + 1-aggregator MoA system on a reasoning benchmark and measure accuracy vs. single-agent CoT
  2. Build a minimal ReAct agent with Wikipedia API access and compare hallucination rates on fact-verification tasks
  3. Take a fixed multi-agent topology and swap memory backends (in-context only → RAG → ChatDB), measuring retrieval accuracy and latency

## Open Questions the Paper Calls Out

- **Open Question 1**: How can orchestration techniques be advanced to manage the collaboration complexity introduced by scaling the number of agents in MoA architectures?
  - Basis: The authors state that expanding the number of agents "introduces complexity in managing collaboration, which may require more sophisticated orchestration techniques in the future."
  - What evidence would resolve it: Development of an orchestration protocol that maintains or improves output quality while linearly scaling the number of agents.

- **Open Question 2**: Can automated solutions be developed to replace the manual design of action knowledge bases in frameworks like KnowAgent?
  - Basis: The survey notes that "the manual design of action knowledge bases presents a labor-intensive challenge, suggesting the need for automated solutions."
  - What evidence would resolve it: An automated pipeline that generates action knowledge bases with accuracy and utility comparable to human-designed ones.

- **Open Question 3**: How can computational costs and latency be optimized in architectures like Chain-of-Agents (CoA) and Agent Forest that rely on multiple LLM queries?
  - Basis: The paper lists "computational costs" and "latency" as key limitations for these architectures, citing the need for "optimization of the sampling phase."
  - What evidence would resolve it: Algorithms that significantly reduce query counts or latency without sacrificing the performance gains of multi-agent collaboration.

## Limitations

- The survey's descriptive nature lacks quantitative performance benchmarks or ablation studies to validate claimed superiority of approaches like MoA or ReAct
- Evidence anchors are drawn from individual paper abstracts rather than systematic comparative evaluations
- The survey does not address edge cases where multi-agent coordination might fail, such as adversarial environments or highly dynamic contexts

## Confidence

- **High confidence**: The architectural patterns described (MoA, ReAct, memory systems) are well-documented in cited literature and represent established approaches
- **Medium confidence**: The claimed performance improvements are based on individual paper results rather than systematic benchmarking
- **Low confidence**: Insufficient detail on implementation specifics, hyperparameter tuning, or failure mode analysis to enable reliable reproduction

## Next Checks

1. Implement the Mixture-of-Agents architecture on a standard reasoning benchmark (e.g., HotpotQA) and compare against single-agent CoT baselines, measuring both accuracy and latency

2. Take a fixed multi-agent topology and systematically swap between different memory backends (RAG, MemoryBank, in-context only), evaluating on tasks requiring multi-hop reasoning

3. Test whether the claimed proposer/aggregator specialization holds across different model families by training multiple MoA configurations with varying model combinations and analyzing diversity correlation