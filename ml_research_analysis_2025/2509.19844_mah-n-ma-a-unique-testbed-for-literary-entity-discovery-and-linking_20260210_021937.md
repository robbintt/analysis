---
ver: rpa2
title: "Mah\u0101n\u0101ma: A Unique Testbed for Literary Entity Discovery and Linking"
arxiv_id: '2509.19844'
source_url: https://arxiv.org/abs/2509.19844
tags:
- entity
- dataset
- entities
- mentions
- linking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Mah\u0101n\u0101ma is the first large-scale dataset for Entity\
  \ Discovery and Linking (EDL) in Sanskrit, featuring 109K mentions across 5.5K entities\
  \ from the Mah\u0101bh\u0101rata. It captures extreme lexical variation, with one\
  \ entity appearing in over 1,300 distinct forms, and high ambiguity, where 47% of\
  \ entities share names requiring context-based resolution."
---

# Mahānāma: A Unique Testbed for Literary Entity Discovery and Linking

## Quick Facts
- arXiv ID: 2509.19844
- Source URL: https://arxiv.org/abs/2509.19844
- Reference count: 39
- Primary result: First large-scale EDL dataset for Sanskrit with 109K mentions across 5.5K entities from the Mahābhārata

## Executive Summary
Mahānāma is the first large-scale dataset for Entity Discovery and Linking (EDL) in Sanskrit, featuring 109K mentions across 5.5K entities from the Mahābhārata. It captures extreme lexical variation, with one entity appearing in over 1,300 distinct forms, and high ambiguity, where 47% of entities share names requiring context-based resolution. Evaluation of coreference and entity linking models shows limited performance: the best model achieves only 51.57% F1 on global context, and end-to-end linking reaches 64.19% F1 due to poor mention detection. These results highlight the challenges of resolving entities in complex literary narratives and underscore the need for more robust, context-aware resolution systems.

## Method Summary
The paper introduces Mahānāma, a Sanskrit EDL dataset with 109K mentions across 5.5K entities from the Mahābhārata. The dataset includes character-level mention boundaries in unsegmented Sanskrit text, with 39% of mentions embedded within multi-word tokens (MWTs) due to sandhi transformations. Three model architectures are evaluated: LingMess (Longformer-Large), Dual Cache (Longformer-Large with subtoken-level boundary prediction), and mReFiNeD (MuRIL encoder). Evaluation uses CoNLL scorer for coreference (average F1 of MUC, B³, CEAFϕ₄) and InKB micro-F1 for entity linking, with both local (subchapter) and global (full text) evaluation settings.

## Key Results
- Dual Cache achieves 74.76% F1 locally but drops to 51.57% F1 globally
- Mention detection is the primary bottleneck, with mReFiNeD achieving only 60.22% F1
- 39% of mentions occur within merged multi-word tokens requiring subtoken-level processing
- Lexical variation is extreme, with one entity appearing in over 1,300 distinct forms
- 47% of entities share names, requiring context for disambiguation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Entity resolution in literary texts requires context-aware semantic clustering rather than surface-form matching to handle extreme lexical variation.
- **Mechanism:** The dataset reveals that entities appear in vastly different surface forms (e.g., *Arjuna* is referred to as *Savyasācī* or *Aindri*). Models relying on lexical overlap fail to cluster these mentions. The paper suggests that effective resolution depends on modeling deep contextual cues and semantic equivalence, as standard mention-ranking models (e.g., LingMess) achieve high MUC scores (linkage) but low CEAFϕ₄ (entity alignment) (F1 41.80) on global contexts.
- **Core assumption:** Semantic equivalence between distinct names (e.g., *Kaunteyo* = *Yudhiṣṭhira*) can be inferred from surrounding discourse context rather than string similarity.
- **Evidence anchors:** [abstract] Mentions "one entity appearing in over 1,300 distinct forms." [section 7] Qualitative Analysis notes the model splits *Draupadī* mentions (e.g., *yājñasenī* vs. *kṛṣṇā*) based on surface similarity. [corpus] Related work (e.g., Cross-Document Contextual Coreference) confirms resolving references across texts requires "identifying and resolving references... appearing across differing texts," supporting the need for context over surface form.
- **Break condition:** If context windows are too small to capture the co-occurrence of synonymous names, or if the model relies on static embeddings that treat distinct names as unrelated tokens.

### Mechanism 2
- **Claim:** End-to-end linking performance in morphologically rich, unsegmented languages is bottlenecked by mention detection within multi-word tokens (MWTs).
- **Mechanism:** Sanskrit words often merge via *sandhi* (phonetic transformations). 39% of mentions in this dataset are embedded within MWTs (e.g., *arjunāśvisutau*). Standard token-level detectors fail. The paper demonstrates that adapting models (Dual-Cache) to predict subtoken-level boundaries recovers performance, improving average F1 from 70.30 (token) to 74.76 (subtoken).
- **Core assumption:** Character-level or subword-level representations can effectively approximate morphological boundaries in the absence of explicit word segmentation.
- **Evidence anchors:** [section 3.2] "39% of mentions in our dataset occurring within such merged forms." [section 5.2] "Handling Unsegmented Data" details the adaptation of Dual-Cache for subtoken boundary prediction. [corpus] Limited direct evidence in neighbors for this specific *sandhi* mechanism; it appears specific to Sanskrit/morphologically-rich languages in this paper.
- **Break condition:** If the model assumes pre-tokenized input (whitespace separation), performance degrades significantly (as seen in the gap between mention detection F1 of 60.22 for mReFiNeD vs. 83.86 for the adapted Dual-Cache).

### Mechanism 3
- **Claim:** Global resolution in long narratives fails due to the inability to maintain entity state over "bursty" distributions and overlapping spans.
- **Mechanism:** Entities appear in "bursts"—frequent mentions followed by long gaps. When evaluated globally (full test set as one discourse) vs. locally (subchapters), model performance crashes (Dual-Cache CEAFϕ₄ drops to 31.68 F1; Avg F1 to 51.57%). The mechanism failing is the maintenance of a consistent global entity cache or memory over thousands of tokens.
- **Core assumption:** Models must persist entity representations across extended contexts (thousands of tokens) where explicit mentions are sparse.
- **Evidence anchors:** [abstract] "best model achieves only 51.57% F1 on global context." [section 4] "Spread and Burstiness" defines the challenge; Figure 2 shows the intermittent frequency of "Arjuna." [corpus] "Cross-Document Contextual Coreference" and "DELICATE" papers corroborate that standard models struggle with long-range dependencies and long-tail entities in complex narratives.
- **Break condition:** If the model's cache/memory mechanism flushes entities too aggressively (e.g., LRU cache size is too small) or lacks a mechanism to merge local clusters into global identities.

## Foundational Learning

- **Concept:** **Entity Discovery and Linking (EDL)**
  - **Why needed here:** This is the primary task. It differs from standard NER because it involves *discovering* mentions (often in unsegmented text) and *linking* them to a KB, handling both variation and ambiguity.
  - **Quick check question:** Can you distinguish between "mention detection" (finding the span) and "entity disambiguation" (mapping to a KB ID)?

- **Concept:** **Coreference Resolution (CR)**
  - **Why needed here:** The paper uses CR baselines (LingMess, Dual-Cache) to evaluate the dataset's difficulty. Understanding CR clustering (grouping mentions) is vital to interpreting the MUC/B3/CEAF metrics used.
  - **Quick check question:** In the context of this paper, why is CR considered a proxy or sub-component for EDL?

- **Concept:** **Sandhi and Multi-Word Tokens (MWTs) in Sanskrit**
  - **Why needed here:** This is the unique structural challenge of the dataset. Understanding that words merge phonetically (e.g., *a + a = ā*) is required to understand why mention detection is hard.
  - **Quick check question:** Why would a standard whitespace tokenizer fail on the input *arjunāśvisutau*?

## Architecture Onboarding

- **Component map:** Input (unsegmented Sanskrit text) -> Mention Detector (subtoken-level) -> Context Encoder (Longformer-Large) -> Resolver/Linker (CR or EL path) -> Knowledge Base (5.5K entities with English descriptions)
- **Critical path:** Data Ingestion -> Mention Detection (subtoken level) -> Linking/Clustering (context + KB) -> Evaluation (local vs global)
- **Design tradeoffs:**
  - Token vs. Subtoken: Token-level processing is faster but misses ~39% of mentions. Subtoken is required for robustness.
  - CR vs. EL: CR models (like Dual-Cache) handle long context better locally but struggle globally. EL models (mReFiNeD) rely on KB priors which may be sparse for low-resource entities.
  - Global Context: Increasing context window improves theoretical resolution but drastically lowers performance of current architectures.
- **Failure signatures:**
  - Conflated Entities: Distinct entities merged (e.g., *Bhūri* and *Duryodhana* both called *kaurava*). High Conflated Entity % in error analysis.
  - Divided Entities: One entity split into multiple clusters (e.g., *Draupadī* split by name variant). High Divided Entity % (33.2% for Dual-Cache Global).
  - Missed Mentions: Low Mention Detection F1 (e.g., 60.22 for mReFiNeD) due to MWTs.
- **First 3 experiments:**
  1. Baseline Retrieval: Run the provided Dual-Cache baseline on the test set. Verify you can reproduce the local vs. global performance drop (74.76 F1 -> 51.57 F1).
  2. Ablation on Input Segmentation: Evaluate a standard model (e.g., mReFiNeD) on pre-segmented text vs. raw unsegmented text to quantify the cost of MWTs.
  3. Error Analysis of Global Failure: Pick the top "Divided Entity" errors in the global evaluation and analyze the distance (in tokens) between the unlinked mentions to understand the "burstiness" threshold.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can entity resolution models maintain performance when scaling from local subchapter contexts (~470 tokens) to global discourse (~100K+ tokens) in literary texts?
- **Basis in paper:** [explicit] Page 7 shows Dual-Cache's CEAFϕ4 F1 drops from 71.30 (local) to 31.68 (global), reducing average F1 from 74.46% to 51.57%. Authors state this "highlights the need for better global resolution."
- **Why unresolved:** Current cache-based architectures struggle to maintain entity representations across extended narratives with bursty mention distributions (Figure 2 shows entities can have long gaps between mentions).
- **What evidence would resolve it:** Development of a model achieving comparable local and global F1 scores on Mahānāma, particularly improving CEAFϕ4 on global evaluation.

### Open Question 2
- **Question:** How can mention detection be improved for morphologically rich, low-resource languages with high rates of multi-word tokens?
- **Basis in paper:** [explicit] Page 7 shows mReFiNeD's mention detection achieves only 60.22% F1 while disambiguation reaches 93.27% F1, indicating detection is the primary bottleneck. Page 4 notes 39% of mentions occur within merged forms.
- **Why unresolved:** Standard tokenizers assume whitespace delimits words, but Sanskrit uses sandhi (phonetic merging) creating MWTs where entity boundaries are not marked. Subtoken-level prediction improved F1 but remains insufficient.
- **What evidence would resolve it:** A mention detection system achieving >80% F1 on Sanskrit text without requiring gold boundary annotations.

### Open Question 3
- **Question:** What contextual features beyond entity descriptions can improve disambiguation of highly ambiguous entities (47% share names)?
- **Basis in paper:** [explicit] Page 7 ablation shows removing cross-lingual descriptions lowers F1 by only 1.21 points, suggesting "descriptions offer limited contextual benefit." Page 8 shows prior probability causes errors like linking "kaurava" to Duryodhana instead of Bhūri.
- **Why unresolved:** Surface-form similarity and prior probability bias models toward frequent entities, while context-dependent names (e.g., "Savyasācī" for Arjuna) require understanding narrative relationships and cultural cues.
- **What evidence would resolve it:** A model using narrative context that shows significant F1 improvement over description-based approaches, particularly on entities with multiple name variants.

## Limitations

- The extreme lexical variation and morphological complexity observed in Sanskrit may not directly transfer to other languages
- Evaluation relies heavily on three specific model architectures without exploring alternative approaches
- Limited analysis of why models fail on specific error types beyond surface-level metrics
- The dataset's literary nature may not represent other domains requiring EDL

## Confidence

- **High confidence** in the dataset statistics and basic performance measurements
- **Medium confidence** in the mechanisms proposed (semantic clustering for lexical variation, subtoken processing for MWTs, cache/memory limitations for global resolution)
- **Low confidence** in the generalizability of the specific architectural solutions to other domains or languages without further validation

## Next Checks

1. **Controlled ablation on context length:** Systematically evaluate model performance as a function of discourse distance between mentions to quantify the "burstiness" threshold where entity state maintenance breaks down
2. **Cross-linguistic transferability test:** Apply the same MWT-aware subtoken processing approach to another morphologically complex language (e.g., Finnish or Turkish) to determine if the 39% MWT frequency and performance gains are Sanskrit-specific
3. **Error type correlation analysis:** For the top 100 global resolution failures, calculate the correlation between mention distance, lexical similarity, and contextual overlap to determine which factors most strongly predict entity conflation vs. division errors