---
ver: rpa2
title: 'Image-based Geo-localization for Robotics: Are Black-box Vision-Language Models
  there yet?'
arxiv_id: '2501.16947'
source_url: https://arxiv.org/abs/2501.16947
tags:
- geo-localization
- prompt
- vlms
- available
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper conducts a systematic study of Vision-Language Models
  (VLMs) for image-based geo-localization in a black-box setting, addressing the challenge
  of accurately determining geo-coordinates from images without access to model internals.
  The authors evaluate three state-of-the-art VLMs (GPT-4v, IDEFICS-80b-Instruct,
  and LLaVA-13b) across three scenarios: using a fixed prompt, testing prompt sensitivity
  with semantically-equivalent variations, and evaluating robustness to environmental
  variations in query images.'
---

# Image-based Geo-localization for Robotics: Are Black-box Vision-Language Models there yet?

## Quick Facts
- arXiv ID: 2501.16947
- Source URL: https://arxiv.org/abs/2501.16947
- Reference count: 39
- Primary result: VLMs show strong performance at country/region level but struggle with fine-grained street-level localization, particularly on non-public datasets

## Executive Summary
This paper presents a systematic evaluation of black-box Vision-Language Models (VLMs) for image-based geo-localization, a critical task for robotics applications. The authors assess three state-of-the-art VLMs (GPT-4v, IDEFICS-80b-Instruct, and LLaVA-13b) across multiple scenarios using fixed prompts, prompt sensitivity testing, and environmental variation analysis. Their findings reveal that while VLMs excel at broader spatial localization, they face significant challenges with fine-grained accuracy, particularly on non-public datasets and under varying environmental conditions. The study introduces a novel consistency metric to evaluate VLM reliability and highlights the substantial impact of prompt formulation and environmental factors on performance.

## Method Summary
The study evaluates VLMs in a zero-shot setting for geo-localization by presenting images and text prompts to predict latitude/longitude coordinates. Three scenarios are tested: (1) fixed long-form prompts across IM2GPS, Tokyo 24/7, CSN, and LZR datasets; (2) sensitivity to 10 semantically-equivalent prompt variations; and (3) robustness to environmental conditions using day/sunset/night image sets. Coordinates are extracted via regex from VLM responses, with failures assigned infinite error. Accuracy is measured at multiple distance thresholds using Haversine distance, complemented by a consistency metric that accounts for VLM auto-regressive behavior across equivalent inputs.

## Key Results
- VLMs perform well at country/region-level localization but struggle with street-level precision, particularly on non-public datasets
- GPT-4v consistently outperforms other models, while LLaVA-13b shows significant limitations due to smaller model size
- Environmental variations, especially suboptimal lighting, substantially degrade localization accuracy
- Substantial prompt sensitivity exists, with semantically-equivalent prompts yielding different coordinate predictions
- Accuracy and consistency are not always aligned, with some models showing high accuracy but low reliability

## Why This Works (Mechanism)
Vision-Language Models process visual and textual information to reason about spatial relationships and geographical features, leveraging their pretraining on vast multimodal datasets. The auto-regressive generation of coordinates allows VLMs to handle this task in a zero-shot manner without specialized fine-tuning. However, this same mechanism introduces sensitivity to prompt formulation and environmental variations in input images, as the models must infer location from potentially ambiguous visual cues without access to traditional geo-localization priors.

## Foundational Learning
- **Zero-shot learning**: VLMs perform geo-localization without task-specific fine-tuning, relying on general knowledge acquired during pretraining. This is needed because task-specific training data may be unavailable or expensive to collect. Quick check: Verify the model can perform other geo-related tasks without fine-tuning.
- **Haversine distance**: Measures great-circle distance between coordinates on a sphere, providing the metric for geo-localization accuracy. Essential for evaluating how close predicted coordinates are to ground truth. Quick check: Confirm distance calculations match expected values for known coordinate pairs.
- **Consistency metrics**: Quantifies reliability of VLM predictions across semantically-equivalent inputs, addressing the auto-regressive nature of coordinate generation. Needed because high accuracy alone doesn't guarantee dependable performance in robotics. Quick check: Test that identical inputs yield identical outputs.
- **Prompt engineering sensitivity**: Small changes in prompt formulation can significantly impact VLM outputs, requiring careful optimization. Critical because black-box models respond variably to linguistic cues. Quick check: Systematically vary prompts to measure performance variance.
- **Environmental robustness**: Model performance varies with lighting, weather, and time-of-day conditions in input images. Important for real-world deployment where environmental conditions are unpredictable. Quick check: Compare performance across controlled environmental variations.

## Architecture Onboarding

**Component Map**: Image -> VLM -> Text Response -> Coordinate Extraction -> Accuracy/Consistency Metrics

**Critical Path**: The primary workflow flows from input image through the VLM to generate textual location predictions, which are then processed via regex to extract coordinates for evaluation against ground truth using Haversine distance.

**Design Tradeoffs**: The study prioritizes accessibility by using black-box models without internal access, sacrificing the ability to fine-tune or analyze internal representations. This approach tests real-world applicability but limits understanding of failure modes and optimization opportunities.

**Failure Signatures**: 
- Format deviation in VLM output (regex extraction failure)
- Environmental sensitivity (performance degradation under non-optimal lighting)
- Prompt sensitivity (inconsistent outputs for semantically-equivalent prompts)
- Scale mismatch (strong performance at country level, weak at street level)

**First 3 Experiments**:
1. Compare performance of different prompt formulations on the same image set to quantify sensitivity
2. Test environmental robustness by comparing accuracy across day, sunset, and night conditions
3. Evaluate consistency by measuring variance in predictions for semantically-equivalent prompts

## Open Questions the Paper Calls Out
- How can VLM capabilities be algorithmically combined with traditional geo-localization techniques to overcome the lack of fine-grained accuracy in stand-alone black-box models?
- What techniques can mitigate the degradation of VLM geo-localization performance caused by environmental variations such as lighting and weather changes?
- How can the reliability of VLMs be ensured when high geo-localization accuracy does not correlate with high self-consistency?
- To what extent is the performance gap between public and non-public datasets caused by training data contamination versus fundamental model limitations?

## Limitations
- Results are highly sensitive to prompt engineering choices, potentially reflecting prompt optimization rather than pure model capability
- Coordinate extraction via regex introduces hard failure modes that may underestimate actual model performance
- Model size differences (LLaVA-13b vs larger models) confound interpretation of fundamental VLM limitations
- Reliance on specific datasets may not capture full diversity of real-world geo-localization scenarios

## Confidence
- **High Confidence**: VLMs demonstrate stronger performance at country/region level compared to city-level localization; environmental variations significantly impact accuracy; substantial prompt sensitivity exists
- **Medium Confidence**: GPT-4v consistently outperforms other VLMs; consistency metric effectively captures VLM reliability; non-public datasets present greater challenges
- **Low Confidence**: Hybrid approaches will necessarily improve performance; current limitations represent fundamental constraints; regex extraction represents optimal approach

## Next Checks
1. Implement and evaluate fuzzy matching or NLP-based coordinate extraction methods to reduce format sensitivity
2. Conduct systematic prompt ablation studies across multiple semantically-equivalent formulations
3. Test model performance on geographically and environmentally diverse datasets not used in training or validation