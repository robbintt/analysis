---
ver: rpa2
title: On the Neural Feature Ansatz for Deep Neural Networks
arxiv_id: '2510.15563'
source_url: https://arxiv.org/abs/2510.15563
tags:
- networks
- linear
- neural
- weight
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes that the Neural Feature Ansatz (NFA) holds\
  \ for deep linear neural networks under gradient flow dynamics with balanced initialization,\
  \ with exponent \u03B1 = 1/L where L is the network depth. The authors prove that\
  \ for unbalanced initialization, the NFA holds asymptotically when weight decay\
  \ is applied."
---

# On the Neural Feature Ansatz for Deep Neural Networks

## Quick Facts
- arXiv ID: 2510.15563
- Source URL: https://arxiv.org/abs/2510.15563
- Authors: Edward Tansley; Estelle Massart; Coralia Cartis
- Reference count: 40
- Primary result: The Neural Feature Ansatz (NFA) holds exactly for deep linear neural networks under gradient flow with balanced initialization (α = 1/L), and asymptotically with weight decay for unbalanced initialization.

## Executive Summary
This paper establishes rigorous conditions under which the Neural Feature Ansatz (NFA) holds for deep neural networks. The authors prove that for deep linear networks with balanced initialization, the first layer's weight matrix Gramian is proportional to the L-th power of the Average Gradient Outer Product (AGOP) matrix, with exponent α = 1/L. They extend this result to unbalanced initialization cases by showing that weight decay induces asymptotic balancing. The paper also provides counterexamples demonstrating that the NFA can fail for certain nonlinear architectures even when data is perfectly fitted. Numerical experiments validate these theoretical findings across various optimization algorithms and network architectures.

## Method Summary
The paper employs theoretical analysis of gradient flow dynamics in deep linear networks, combined with numerical experiments on synthetic low-rank target functions. The theoretical framework analyzes the relationship between the first layer's weight matrix Gramian and the AGOP matrix under different initialization and regularization conditions. Experiments use synthetic data generated from low-rank functions, with networks trained using various optimization algorithms including gradient descent, SGD, and Adam. Alignment quality is measured using cosine similarity between the first layer's Gramian and the AGOP matrix raised to appropriate powers.

## Key Results
- The NFA holds exactly for deep linear networks under gradient flow with balanced initialization (α = 1/L)
- For unbalanced initialization, weight decay induces asymptotic balancing, making NFA hold over time
- Counterexamples show NFA fails for certain nonlinear architectures even when data is perfectly fitted
- First-layer weight matrix captures low-rank structure of target function when NFA holds

## Why This Works (Mechanism)

### Mechanism 1: Depth-Dependent Alignment in Linear Networks
- **Claim:** Under balanced initialization and gradient flow, the Neural Feature Ansatz (NFA) holds exactly for deep linear networks with an exponent $\alpha = 1/L$.
- **Mechanism:** The "balancedness" property ($W_l W_l^\top = W_{l+1}^\top W_{l+1}$) allows the product of weight matrices in the AGOP ($J^\top J$) to algebraically collapse into the $L$-th power of the first layer's Gram matrix ($W_1^\top W_1$).
- **Core assumption:** Gradient flow dynamics; strictly linear layers; balanced initialization maintained from $t=0$.
- **Evidence anchors:**
  - [Theorem 3.1]: "NFA holds with exponent $\alpha= 1/L$... assuming gradient flow dynamics with balanced weight initialization."
  - [Section 3]: Derivation showing $(J^\top J)^{1/L} = W_1^\top W_1$.
  - [Corpus]: Weak corpus support; related work (Boix-Adsera et al., 2025) suggests alternative derivations, but this specific depth-dependence is unique to this paper.
- **Break condition:** Introducing nonlinear activations or removing the balanced initialization assumption (without补救 measures).

### Mechanism 2: Asymptotic Balancing via Weight Decay
- **Claim:** For unbalanced initialization, applying weight decay ($\lambda > 0$) forces the network to satisfy the NFA asymptotically over time.
- **Mechanism:** Weight decay acts as a regularizer that exponentially suppresses the difference between adjacent layer Gram matrices ($\|W_l W_l^\top - W_{l+1}^\top W_{l+1}\|_F$), driving the system toward the balanced state required for Mechanism 1.
- **Core assumption:** Gradient flow with weight decay ($\lambda > 0$); differentiable loss.
- **Evidence anchors:**
  - [Theorem 3.2]: "$\|A_{f,t} - (W_{1,t}^\top W_{1,t})^L\|_F = O(c_{max} e^{-2\lambda t})$."
  - [Lemma 3.2]: Cites Kobayashi et al. (2024) showing weight decay induces balancedness.
  - [Corpus]: IDInit (arXiv:2503.04626) emphasizes initialization stability, complementing this finding that WD stabilizes layer balance during training.
- **Break condition:** Setting weight decay $\lambda = 0$ with unbalanced initialization; the gap remains constant.

### Mechanism 3: Low-Rank Feature Capture
- **Claim:** If the target function is low-rank, the first-layer weight matrix $W_1$ captures this structure by aligning its singular vectors with the active subspace of the target.
- **Mechanism:** If NFA holds, $W_1^\top W_1 \propto AGOP^\alpha$. Since AGOP captures the input directions of highest variation (derivatives) of the target function, the proportionality forces $W_1$ to share the null space of the target, ignoring irrelevant input dimensions.
- **Core assumption:** The NFA relationship holds (proven for linear, observed empirically for ReLU); target function has low effective dimensionality.
- **Evidence anchors:**
  - [Section 5.2]: "Singular values decay for $W_1^\top W_1$ vs $A_{f^*}$... low-rank structure... is captured by $A_{f^*}$."
  - [Figure 4]: Visual verification of singular value alignment.
  - [Corpus]: Self-similarity Analysis (arXiv:2507.17785) discusses hierarchical structure, relevant to how deep layers might maintain this rank structure.
- **Break condition:** Specific nonlinear counterexamples (Section 4) where gradient discontinuities force $W^\top W \not\propto AGOP^\alpha$.

## Foundational Learning

- **Concept: Matrix Balancing**
  - **Why needed here:** The core theoretical result (Mechanism 1) relies entirely on the algebraic property that adjacent weight matrices have matching Gram matrices ($W_l W_l^\top = W_{l+1}^\top W_{l+1}$).
  - **Quick check question:** If you initialize $W_1$ with PyTorch defaults and $W_2$ with zeros, is the network balanced?

- **Concept: Gradient Flow Dynamics**
  - **Why needed here:** The proofs assume continuous-time differential equations ($\partial W / \partial t$). Practical results depend on how well discrete optimizers (SGD, Adam) approximate this flow.
  - **Quick check question:** Does increasing the learning rate infinitely improve the approximation of gradient flow, or break it?

- **Concept: Average Gradient Outer Product (AGOP)**
  - **Why needed here:** This is the "target" matrix in the NFA relationship ($W^\top W \propto AGOP^\alpha$). It quantifies feature importance based on input sensitivity.
  - **Quick check question:** For a constant function $f(x)=c$, what is the rank of the AGOP matrix?

## Architecture Onboarding

- **Component map:**
  - Input: $x \in \mathbb{R}^d$
  - Core: $L$ linear layers ($W_1 \dots W_L$). In experiments, often implemented as $f(x) = a^\top [W_L \dots W_1 x + b_1]_+ + b_2$ (Deep Linear with final ReLU head)
  - Targets: Low-rank functions $f^*(x) = g(Ax)$

- **Critical path:**
  1. **Initialization:** Enforce balancedness (Alg 1) or verify unbalancedness
  2. **Training:** Apply Gradient Descent/SGD/Adam with Weight Decay ($\lambda \in [10^{-3}, 10^{-2}]$)
  3. **Evaluation:** Compute Cosine Similarity between $W_1^\top W_1$ and $(AGOP)^{1/L}$

- **Design tradeoffs:**
  - **Depth $L$:** Increasing depth reduces exponent $\alpha$ to $1/L$. Experiments show deeper networks align more slowly than shallow ones (Figure 2)
  - **Weight Decay:** Essential for convergence in unbalanced cases, but excessive decay ($\lambda=10^{-2}$) can suppress learning in nonlinear/Gaussian link functions (Figure 6)

- **Failure signatures:**
  - **Exact Interpolation without NFA:** The network achieves 0 loss, but $W_1^\top W_1$ remains Identity while AGOP is dense (Example 1, Section 4)
  - **Stagnation:** Without weight decay in unbalanced init, alignment fails to improve

- **First 3 experiments:**
  1. **Validate Depth Scaling:** Train a 5-layer linear network on synthetic low-rank data. Plot alignment quality (Cosine Sim) vs. exponent $\tilde{\alpha}$. Verify peak is at $\tilde{\alpha}=1$ (corresponding to $\alpha=1/5$)
  2. **Ablate Weight Decay:** Use unbalanced initialization. Train identical networks with $\lambda=0$ vs $\lambda=10^{-3}$. Plot $\|A_f - (W_1^\top W_1)^L\|_F$ over time to observe exponential decay only with WD
  3. **Test Nonlinear Barrier:** Construct the counterexample from Section 4 ($f^*(x) = [x_1]_+ + [x_2]_+$). Train a 2-layer ReLU network. Verify that while loss $\to 0$, the alignment between $W^\top W$ and $AGOP$ remains low

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Neural Feature Ansatz (NFA) hold for wider or deeper nonlinear networks?
- Basis in paper: [explicit] Section 4 explicitly asks, "The question remains of what happens for wider or deeper networks," in the context of nonlinear architectures.
- Why unresolved: The authors provide counterexamples only for narrow, non-overparameterized networks. While specific overparameterized constructions can satisfy the NFA, it is unclear if this holds generally for trained wider/deeper networks.
- What evidence would resolve it: Theoretical characterization of NFA validity conditions for overparameterized nonlinear networks, or empirical studies showing consistent failure/alignment across varying widths.

### Open Question 2
- Question: What is the precise relationship between NFA alignment and generalization performance?
- Basis in paper: [inferred] Section 4 demonstrates that alignment between the model's AGOP and the target function's AGOP is neither necessary nor sufficient for good generalization.
- Why unresolved: The counterexamples provided sever the link between perfect data fitting and NFA alignment, leaving the utility of the NFA for explaining generalization uncertain.
- What evidence would resolve it: Identifying specific settings where NFA alignment correlates with or provably improves generalization bounds, or delineating distinct learning regimes where the link is restored.

### Open Question 3
- Question: Can the low-rank structural properties derived for linear networks be theoretically extended to general nonlinear networks?
- Basis in paper: [inferred] The Conclusion states that numerical results indicate the low-rank behavior observed for linear networks "may be extendable in the future to nonlinear ones."
- Why unresolved: The current proofs rely on linear network properties (constant Jacobian) and gradient flow dynamics, which do not directly transfer to nonlinear settings.
- What evidence would resolve it: A theoretical proof showing that $W_1^\top W_1$ aligns with the low-dimensional subspace of the target function for nonlinear architectures under standard training regimes.

## Limitations

- Nonlinear case confidence is medium - while counterexamples show failure modes, the conditions for general nonlinear NFA validity remain uncharacterized
- Theoretical results rely on gradient flow approximation, but practical implementations use discrete optimizers
- Balanced initialization requirement for exact NFA is restrictive; weight decay provides asymptotic remedy but with uncertain convergence rates

## Confidence

**High Confidence:**
- Linear network results under balanced initialization (Theorem 3.1)
- Weight decay's effect on asymptotic balancing (Theorem 3.2)
- Numerical methodology for computing alignment metrics

**Medium Confidence:**
- Extension to nonlinear ReLU networks
- Generalizability across optimization algorithms
- Weight decay hyperparameter sensitivity

**Low Confidence:**
- Precise conditions for NFA in arbitrary nonlinear architectures
- Gradient flow approximation quality for different optimizers
- Initialization scheme impacts on convergence rate

## Next Checks

1. **Convergence Rate Analysis:** Systematically vary the degree of initialization imbalance and weight decay strength to characterize the exponential convergence rate in Theorem 3.2 across a wider parameter range.

2. **Optimizer Approximation Quality:** Compare the alignment trajectories of gradient flow (analytical solution) versus discrete optimizers (SGD, Adam) on the same linear network setup, quantifying the approximation error as a function of learning rate and batch size.

3. **Nonlinear Architecture Boundaries:** Construct and analyze additional nonlinear counterexamples beyond Section 4, systematically varying activation functions, depth, and data distributions to map the boundary conditions where the NFA fails.