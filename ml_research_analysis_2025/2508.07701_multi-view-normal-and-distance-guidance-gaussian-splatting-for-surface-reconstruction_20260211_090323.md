---
ver: rpa2
title: Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction
arxiv_id: '2508.07701'
source_url: https://arxiv.org/abs/2508.07701
tags:
- reconstruction
- gaussian
- surface
- multi-view
- normal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses geometric inconsistencies and surface fitting
  inaccuracies in 3D Gaussian Splatting (3DGS) when dealing with multi-view scenes.
  The authors propose two novel modules: a multi-view distance reprojection regularization
  module and a multi-view normal enhancement module.'
---

# Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction

## Quick Facts
- arXiv ID: 2508.07701
- Source URL: https://arxiv.org/abs/2508.07701
- Authors: Bo Jia; Yanan Guo; Ying Chang; Benkui Zhang; Ying Xie; Kangning Du; Lin Cao
- Reference count: 35
- Primary result: Achieves lowest Chamfer Distance (0.51) on DTU dataset compared to state-of-the-art methods

## Executive Summary
This paper addresses geometric inconsistencies in 3D Gaussian Splatting when dealing with multi-view scenes by introducing two novel modules: Multi-view Distance Reprojection Regularization and Multi-view Normal Enhancement. The method builds on PGSR and ensures consistent depth estimation and surface normal alignment across nearby views through carefully designed loss functions. Experimental results demonstrate state-of-the-art performance on both DTU surface reconstruction and Mip-NeRF360 novel view synthesis tasks.

## Method Summary
The method extends PGSR with two modules to improve geometric consistency across views. The Multi-view Distance Reprojection Regularization module computes distance loss between nearby views and the same Gaussian surface by back-projecting pixels into 3D space and comparing distances across coordinate systems. The Multi-view Normal Enhancement module ensures view consistency by matching normals of corresponding pixel points in nearby views through local plane fitting. The approach is trained on COLMAP-initialized data with specific loss weights and thresholds, ultimately producing meshes via TSDF fusion.

## Key Results
- Achieves lowest average Chamfer Distance (0.51) on DTU dataset compared to state-of-the-art methods
- Attains highest SSIM (0.844) and lowest LPIPS (0.176) on Mip-NeRF360 dataset
- Highest PSNR (24.92) in outdoor scenes on Mip-NeRF360
- Ablation study shows distance module improves CD by 0.06 and normal module improves PSNR by 0.04

## Why This Works (Mechanism)

### Mechanism 1: Multi-view Distance Reprojection
The module ensures consistent depth estimation by back-projecting a pixel from a reference view into 3D space using depth scaling, then transforming it into the coordinate system of a nearby view to compute distance loss. This forces Gaussians to maintain unified geometric depth across views rather than fitting local artifacts. The core assumption is that the scene geometry is sufficiently rigid that a point valid in one view corresponds to the same physical surface point in another view.

### Mechanism 2: Local Planar Normal Consistency
The method derives surface normals from local depth neighborhoods and aligns them across views by sampling 4 neighbors, fitting a plane, computing normals, and minimizing differences between corresponding views. This forces Gaussians to align with consistent surface planes rather than orienting arbitrarily to minimize single-view color loss. The core assumption is that the surface is locally planar at the scale of the pixel neighborhood sampling.

### Mechanism 3: Implicit Homography Correspondence
The method uses pre-computed homography matrices to efficiently establish multi-view correspondences without expensive runtime feature matching. This enables the distance and normal modules to operate on "virtual" pairs of views. The core assumption is that the scene is planar enough for homography to provide valid pixel-to-pixel maps between views.

## Foundational Learning

- **Concept: Structure-from-Motion (SfM) Priors (COLMAP)**
  - Why needed here: The entire pipeline depends on COLMAP for poses, initial point cloud, and intrinsic/extrinsic matrices
  - Quick check question: Can you explain how a 3D point is transformed from world coordinates to a specific camera's coordinate system using extrinsic matrices?

- **Concept: Alpha-Blending / Volume Rendering**
  - Why needed here: The method builds upon PGSR, which renders depth and distance maps using alpha-blending; understanding how opacity accumulates along a ray explains why "floaters" occur
  - Quick check question: How does the transmittance term T_i in the rendering equation affect the influence of a Gaussian located behind a high-opacity surface?

- **Concept: Chamfer Distance (CD)**
  - Why needed here: This is the primary metric used to validate the paper's contribution, measuring the distance between the reconstructed point cloud and the ground truth
  - Quick check question: If a reconstruction captures the texture perfectly but the surface is shifted inward by 5cm, would the PSNR or Chamfer Distance be more affected?

## Architecture Onboarding

- **Component map:** Multi-view Images → COLMAP (Poses + Sparse Cloud) → PGSR (Planar-based Gaussian Splatting) → MDRR (Distance Loss) + MNE (Normal Loss) → TSDF Fusion → Mesh

- **Critical path:** The calculation of the homography matrix H_r and the subsequent transformation π (Eq. 12). If the implementation of `Pr_to_n` has an indexing error or matrix mismatch, the losses will diverge, forcing Gaussians into incoherent positions.

- **Design tradeoffs:** Accuracy vs. Scalability - the method explicitly limits scope to "small indoor and outdoor scenes" because multi-view constraints rely on overlapping pixel neighborhoods that may not scale well to unbounded landscapes. Weight Sensitivity - the ablation study shows that removing the normal module slightly increases CD but decreases PSNR in some contexts, suggesting a tradeoff where normal smoothing might occasionally over-smooth high-frequency detail to gain stability.

- **Failure signatures:**
  - Black voids/unpopulated regions if the initial point cloud is sparse
  - Projection Artifacts if the homography assumption is violated, potentially creating "ghost" surfaces

- **First 3 experiments:**
  1. Baseline Reproduction: Run on DTU `scan_24` with only L_dist active (set ω_nor=0) to isolate distance module impact
  2. Correspondence Visualization: Visualize pixel correspondences p_r ↔ p_n generated by homography matrix on image pairs
  3. Ablation on View Count: Train on a scene with reduced view overlap to test robustness of "nearby view" assumptions

## Open Questions the Paper Calls Out

- How can the multi-view projection framework be modified to prevent error accumulation in large-scale scenes?
- Does the method's performance degrade significantly when initialized with sparse or noisy SfM point clouds?
- To what extent does the homography-based correspondence assumption fail at sharp depth discontinuities?

## Limitations

- The method is explicitly designed for small indoor and outdoor scenes, with projection errors spreading in large-scale scenes
- Performance is affected by initial point cloud and training set quality, with no validation of recovery capability from sparse/noisy initialization
- The homography-based correspondence mechanism relies on planar scene assumptions that may fail at object boundaries or depth discontinuities

## Confidence

- **High confidence:** CD improvement claims on DTU dataset (0.51 average vs. 0.57 for PGSR)
- **Medium confidence:** PSNR/SSIM/LPIPS improvements on Mip-NeRF360 without statistical significance testing
- **Low confidence:** Scalability claims for large-scale scenes explicitly acknowledged as limitation

## Next Checks

1. Test correspondence quality on DTU validation patches to verify homography validity at object boundaries and textureless regions
2. Run ablation study on scenes with varying levels of geometric complexity to quantify performance degradation on non-planar surfaces
3. Implement visualization of neighbor sampling patterns to confirm that 4-point plane fitting operates at appropriate spatial scales relative to surface features