---
ver: rpa2
title: Hierarchical Task Offloading for UAV-Assisted Vehicular Edge Computing via
  Deep Reinforcement Learning
arxiv_id: '2507.05722'
source_url: https://arxiv.org/abs/2507.05722
tags:
- task
- oading
- computing
- system
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficient task offloading
  in UAV-assisted vehicular edge computing systems, where compute-intensive and delay-sensitive
  applications demand better coordination of heterogeneous resources and adaptation
  to dynamic network conditions. The authors propose a dual-layer architecture integrating
  high-altitude UAVs (HUA V) for global relay and coordination with low-altitude UAVs
  (LUA V) for localized deployment and rapid responsiveness.
---

# Hierarchical Task Offloading for UAV-Assisted Vehicular Edge Computing via Deep Reinforcement Learning

## Quick Facts
- arXiv ID: 2507.05722
- Source URL: https://arxiv.org/abs/2507.05722
- Reference count: 19
- One-line primary result: Hierarchical SAC-based offloading achieves up to 95% task completion rate in UAV-assisted vehicular edge computing

## Executive Summary
This paper addresses the challenge of efficient task offloading in UAV-assisted vehicular edge computing systems, where compute-intensive and delay-sensitive applications demand better coordination of heterogeneous resources and adaptation to dynamic network conditions. The authors propose a dual-layer architecture integrating high-altitude UAVs (HUAV) for global relay and coordination with low-altitude UAVs (LUAV) for localized deployment and rapid responsiveness. They formulate a joint optimization problem to minimize system delay and energy consumption while ensuring task completion rates, and reformulate it as a Markov decision process. A hierarchical soft actor-critic (SAC)-based offloading scheme is introduced, decoupling global decisions (offloading ratios and trajectory planning) from local scheduling (priority-based node selection and resource allocation). Simulations show the approach achieves up to 95% task completion rate, outperforming baselines in system efficiency and convergence speed, with strong robustness in dynamic vehicular environments.

## Method Summary
The method employs a hierarchical reinforcement learning framework with a Soft Actor-Critic (SAC) agent running on the HUAV to handle global decisions including offloading ratios and LUAV trajectory planning, while a priority-based heuristic scheduler manages local node selection and resource allocation. The system models task offloading as a Markov decision process where the state includes vehicle positions, task characteristics, and resource availability, actions include continuous offloading ratios and trajectories, and rewards combine task completion rate with penalties for delay and energy consumption. The approach leverages partial offloading to split tasks across multiple processing nodes and uses a dual-layer relay architecture where the HUAV can route tasks to remote infrastructure when local resources are congested.

## Key Results
- Achieves up to 95% task completion rate in simulated urban vehicular environments
- Outperforms baseline methods including FixedUAV (static trajectories) and DQN-based approaches in both system utility and convergence speed
- Demonstrates strong robustness to dynamic network conditions and vehicle mobility patterns
- Shows diminishing returns on utility when increasing from 2 to 4 LUAVs due to energy consumption trade-offs

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Decoupling of Action Spaces
The system avoids the curse of dimensionality typical in high-mobility VEC networks by separating continuous global planning from discrete local scheduling. The Soft Actor-Critic (SAC) agent manages high-level, continuous variables (offloading ratios $\lambda$ and UAV trajectories $Q$), while a rule-based heuristic handles discrete node selection. This prevents the combinatorial explosion of trying to map every vehicle to every node via DRL. The optimal offloading ratio and trajectory are more sensitive to global network load than specific node-node pairings, which can be resolved via proximity and load heuristics.

### Mechanism 2: Dual-Layer Relay for Load Balancing
The architecture sustains high task completion rates (>90%) by routing delay-tolerant traffic through a High-Altitude UAV (HUAV) to remote, idle infrastructure. The HUAV acts as a relay bridge. When local Low-Altitude UAVs (LUAVs) or Roadside Units (RSUs) are congested, tasks are offloaded via the HUAV to a remote Base Station (BS) or idle RSU. This alleviates "regional computational bottlenecks" by utilizing global resources. The two-hop transmission delay (Vehicle $\to$ HUAV $\to$ Remote Node) plus remote execution time is less than the waiting time at a congested local node for specific delay-tolerant tasks.

### Mechanism 3: Priority-Aware Scheduling
The system maximizes the "task completion rate" metric by explicitly prioritizing tasks based on urgency and complexity rather than simple arrival time (FIFO). Tasks are sorted by priority $K_i(t)$ and max tolerable delay $T^{max}_i(t)$. The scheduler then scores candidate nodes using a weighted sum of distance and remaining resources ($Score_{i,x}$). This ensures constrained resources (LUAVs) are allocated to tasks that contribute most to the success metric. The "score" function weights ($\alpha_s, \beta_s$) correctly approximate the transmission delay and processing speed trade-off for the current network state.

## Foundational Learning

- **Concept: Soft Actor-Critic (SAC)**
  - **Why needed here:** SAC is an off-policy actor-critic algorithm that maximizes expected reward plus entropy. It is crucial here because the environment (vehicle locations) is highly dynamic. The entropy term encourages exploration, preventing the agent from getting stuck in deterministic but suboptimal policies (local maxima) as vehicle density changes.
  - **Quick check question:** How does the temperature coefficient $\alpha$ in SAC prevent the policy from collapsing too quickly to a deterministic strategy in the early training episodes?

- **Concept: Partial Offloading**
  - **Why needed here:** The paper models tasks as divisible (bit-wise), allowing a single task $\tau_i$ to be split: part processed locally, part on an RSU, and part on a UAV. Understanding this is key to interpreting the "offloading ratios" action space.
  - **Quick check question:** If a task is split between the local CPU and a UAV, is the total delay determined by the sum of the delays or the maximum of the parallel execution paths? (See Eq. 18).

- **Concept: Markov Decision Process (MDP)**
  - **Why needed here:** The paper reformulates a continuous optimization problem into an MDP to apply DRL. Understanding the definition of the "State" (vehicle positions, resources) and "Reward" (completion rate minus energy/delay) is necessary to diagnose why the agent makes specific trajectory decisions.
  - **Quick check question:** In the defined state space $s(t)$, why is it critical to include $f^{remain}_x$ (remaining resources) rather than just the static maximum capacity $F^{max}_x$?

## Architecture Onboarding

- **Component map:**
  - Intelligent Vehicles -> Task Generation
  - Vehicles -> HUAV (Relay Path)
  - Vehicles -> LUAVs/RSUs (Local Paths)
  - LUAVs -> HUAV (Overflow)
  - HUAV -> Remote BS/RSUs (Global Relief)

- **Critical path:**
  1. **Observation:** RSUs report traffic $\to$ HUAV predicts hotspots
  2. **Decision (Global):** SAC Agent $\to$ Output Offloading Ratios ($\lambda$) & LUAV Trajectories ($Q$)
  3. **Scheduling (Local):** Priority Sort $\to$ Score Nodes ($Score_{i,x}$) $\to$ Allocate Resource $f^i_x$
  4. **Execution:** Parallel processing across Local/RSU/LUAV/Remote nodes
  5. **Update:** Calculate Reward $r(t)$ (Utility - Cost) $\to$ Store transition $\to$ Update SAC weights

- **Design tradeoffs:**
  - **Utility vs. Energy:** Adding LUAVs improves completion rate but increases system energy consumption ($E_{fly}$). The paper notes diminishing returns on utility when moving from 2 to 4 LUAVs despite higher completion rates due to energy costs.
  - **Complexity vs. Stability:** Hierarchical decoupling simplifies the DRL action space (continuous actions only) but relies on the heuristic scheduler being robust.

- **Failure signatures:**
  - **Mode Collapse:** DQN baseline fails because discrete action spaces cannot handle the fine-grained control needed for trajectory planning.
  - **Resource Starvation:** If all vehicles offload to LUAVs ignoring local/RSU capacity, the "NoPriority" logic causes queue overflows.
  - **Connectivity Loss:** If LUAV trajectory planning doesn't account for speed limits ($v_{max}$) or energy ($E_{max}$), the UAV may move out of optimal range or crash.

- **First 3 experiments:**
  1. **Ablation on Scheduling:** Run `NoPriority` (FIFO) vs. `Proposed` (Priority-based) with fixed UAVs. This isolates the impact of the scheduling heuristic from the trajectory optimization.
  2. **Scalability Stress Test:** Vary vehicle density from 5 to 50 (as per Section IV). Monitor if the "FixedUAV" baseline performance drops off a cliff (indicating lack of adaptability) vs. the SAC method.
  3. **Bandwidth Sensitivity:** Reduce HUAV bandwidth from 100 MHz to 40 MHz. Verify if the system successfully shifts load from the Relay path (HUAV-BS) to local paths (LUAV/RSU) to maintain the 0.875 completion rate observed in simulations.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several critical assumptions and limitations warrant further investigation, particularly regarding LoS assumptions, scalability, and energy management.

## Limitations
- Performance relies on LoS links between vehicles and LUAVs, which may not hold in dense urban environments with frequent NLoS conditions
- Scalability to large vehicle numbers is unproven, as simulations only test up to 50 vehicles with centralized HUAV processing
- Energy constraints are treated as finite budgets without addressing operational logistics for continuous UAV operation and recharging

## Confidence
- **High**: Hierarchical architecture's conceptual validity and dual-layer relay mechanism's ability to alleviate local congestion
- **Medium**: Priority-based scheduling's impact on task completion rates, as the scoring function's optimality is not rigorously proven
- **Low**: Absolute performance numbers due to missing implementation details and absence of real-world validation

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary the SAC entropy coefficient α, discount factor γ, and learning rate to determine their impact on convergence speed and final task completion rates. This would reveal whether the reported 95% completion rate is robust or dependent on specific parameter tuning.

2. **Cross-Environment Generalization Test**: Evaluate the trained SAC agent in mobility scenarios different from the training environment (e.g., highway vs. urban grid, different vehicle densities). This would test whether the hierarchical approach truly learns transferable policies or overfits to specific traffic patterns.

3. **Real-World Implementation Feasibility**: Implement the priority scheduling algorithm on actual edge computing infrastructure with heterogeneous resources (different CPU speeds, network latencies). Measure whether the theoretical node scoring function translates to practical performance gains when accounting for real-world overheads and non-idealities.