---
ver: rpa2
title: 'MedAgentAudit: Diagnosing and Quantifying Collaborative Failure Modes in Medical
  Multi-Agent Systems'
arxiv_id: '2510.10185'
source_url: https://arxiv.org/abs/2510.10185
tags:
- medical
- collaboration
- collaborative
- failure
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study presents a large-scale empirical audit of six multi-agent
  medical AI frameworks across 3,600 cases, revealing critical flaws in collaborative
  reasoning beyond final-answer accuracy. Through a rigorous mixed-methods approach,
  it develops a comprehensive taxonomy of collaborative failures and introduces a
  quantitative auditing framework tracking four key dimensions: information propagation,
  viewpoint dynamics, collaboration quality, and conflict resolution.'
---

# MedAgentAudit: Diagnosing and Quantifying Collaborative Failure Modes in Medical Multi-Agent Systems

## Quick Facts
- arXiv ID: 2510.10185
- Source URL: https://arxiv.org/abs/2510.10185
- Reference count: 40
- This study presents a large-scale empirical audit of six multi-agent medical AI frameworks across 3,600 cases, revealing critical flaws in collaborative reasoning beyond final-answer accuracy.

## Executive Summary
This study presents a large-scale empirical audit of six multi-agent medical AI frameworks across 3,600 cases, revealing critical flaws in collaborative reasoning beyond final-answer accuracy. Through a rigorous mixed-methods approach, it develops a comprehensive taxonomy of collaborative failures and introduces a quantitative auditing framework tracking four key dimensions: information propagation, viewpoint dynamics, collaboration quality, and conflict resolution. The analysis uncovers four dominant failure patterns: flawed consensus driven by shared model deficiencies, suppression of correct minority opinions, ineffective discussion dynamics, and critical information loss during synthesis. Notably, over two-thirds of successes involve superfluous collaboration where all agents agree initially, rendering the process redundant.

## Method Summary
The study employed Python 3.12 to audit 6 medical multi-agent frameworks (ColaCare, ReConcile, MDAgents, MedAgents, MAC, HealthcareAgent) across 3,600 interaction logs from 6 medical datasets (MedQA, PubMedQA, MedXpertQA, PathVQA, VQA-RAD, SLAKE). Using DeepSeek-V3.2-Think as auditor agents, the framework tracked Key Evidential Units (KEUs), viewpoint shift patterns, collaboration quality metrics, and conflict resolution rates. The approach combined quantitative measurement with qualitative taxonomy development validated through human annotation (κ=0.82). Framework instrumentation logged full prompts, responses, agent roles, and interaction rounds for systematic analysis.

## Key Results
- Four dominant failure patterns identified: flawed consensus, suppression of correct minorities, ineffective discussion dynamics, and critical information loss during synthesis
- Over two-thirds of successes involve superfluous collaboration where all agents agree initially
- Key evidential unit retention rates below 60% across most systems, with clinical priority mismatch exceeding 70%
- Framework-specific variation: MDAgents shows 38.46% negative majority assimilation while ReConcile shows 82.37% conflict dropout

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-round collaboration can improve key evidential unit (KEU) retention, but synthesis stages act as structural bottlenecks where critical information is lost.
- Mechanism: The auditing framework tracks KEUs across four stages: propose, synthesis, review, conclusion. In Round 1, retention drops from 100% at proposal to ~36% at conclusion. However, frameworks that support multi-round collaboration show rebound: retention stabilizes at ~70% by Round 2. The mechanism suggests that repeated exposure and cross-checking across rounds helps agents maintain attention on critical evidence, while single-pass synthesis aggressively filters information.
- Core assumption: KEUs identified by the auditor agent accurately represent the evidence required for correct diagnosis.
- Evidence anchors:
  - [abstract] "critical information loss during synthesis" identified as a dominant failure pattern
  - [section 6.2] Figure 7 shows KEU retention rebounding to 70.3% in Round 2; Table 2 shows 4/6 frameworks exceed 40% KEU missing rate
  - [corpus] Related work on clinical AI auditing (arxiv:2507.05755) confirms models can fail catastrophically under distribution shifts, suggesting fragility in evidence handling
- Break condition: If synthesis agents are redesigned to preserve rather than summarize KEUs, or if single-round architectures add explicit KEU-injection prompts, the retention drop may be mitigated.

### Mechanism 2
- Claim: Collaboration dynamics favor conformity over correction; correct minorities are suppressed at higher rates than incorrect majories are corrected.
- Mechanism: The framework classifies viewpoint shifts into four patterns. Successful minority correction (M1) averages ~2-6% across frameworks, while negative majority assimilation (M2)—where a correct minority conforms to an incorrect majority—reaches 38.46% in MDAgents. The mechanism suggests that majority opinions create epistemic pressure, and agents shift toward consensus-based justifications rather than evidence-based ones during extended discussions (voting-based decision rate rises from 20.7% to 35.1% across rounds).
- Core assumption: Self-reported justification types ("evidence_based" vs. "consensus_based") by agents accurately reflect their actual reasoning drivers.
- Evidence anchors:
  - [abstract] "suppression of correct minority opinions" identified as a dominant failure pattern
  - [section 6.2] Table 6 shows M1 rates consistently low (0-6.9%) while M2 rates reach 38.46%; Figure 9 visualizes the asymmetry
  - [corpus] Research on multi-agent failure modes (arxiv:2503.13657) similarly finds that collective systems can converge on incorrect beliefs through interaction
- Break condition: If frameworks implement explicit minority-protection mechanisms (e.g., requiring evidence-based rebuttals before majority decisions), or if voting is replaced with argument-quality-weighted aggregation, the suppression pattern may weaken.

### Mechanism 3
- Claim: Deeper collaboration improves conflict resolution capability, but cross-round memory deficits cause unresolved conflicts to resurface at round boundaries.
- Mechanism: The framework identifies Critical Conflict Points (CCPs)—direct contradictions between agent arguments—and tracks whether they are addressed. Within a single round, dropout rates decline from propose to conclusion, showing intra-round resolution works. Across rounds, final-stage dropout drops from 66.1% (R1) to 31.0% (R3), indicating multi-round deliberation helps. However, dropout rates spike at the start of new rounds (e.g., 89.1% at R2 propose), suggesting agents don't consistently carry forward conflict state.
- Core assumption: The auditor's identification of "substantively addressed" conflicts correlates with genuine resolution rather than superficial acknowledgment.
- Evidence anchors:
  - [abstract] "ineffective discussion dynamics" identified as a dominant failure pattern
  - [section 6.2] Figure 10 shows intra-round decline and cross-round improvement; Table 7 shows framework variation (ReConcile: 82.37% dropout vs. MDAgents: 9.76%)
  - [corpus] AgenTracer (arxiv:2509.03312) notes that complex agent interactions amplify fragility, aligning with observed conflict-handling inconsistencies
- Break condition: If frameworks implement persistent conflict-state memory (e.g., CCPs injected into every subsequent prompt), or if architectures enforce explicit conflict-resolution phases before conclusions, round-boundary spikes may diminish.

## Foundational Learning

- Concept: **Key Evidential Units (KEUs)**
  - Why needed here: The paper's auditing framework hinges on tracking whether critical facts survive through collaboration. KEUs are the atomic units of diagnostic reasoning—the facts that, if lost, break the reasoning chain.
  - Quick check question: Given a medical case, can you identify which 2-3 facts are *necessary* (not just helpful) for the correct diagnosis?

- Concept: **Viewpoint Dynamics Patterns (M1-M4)**
  - Why needed here: The paper operationalizes how opinions shift: M1 (minority corrects majority), M2 (majority suppresses correct minority), M3 (correct majority holds), M4 (minority derails correct majority). Understanding these patterns is essential for diagnosing *why* a system converged on an answer.
  - Quick check question: If 3 of 5 agents initially choose wrong answer A, and 2 choose correct answer B, what pattern applies if the final answer is A? What if it's B?

- Concept: **Process vs. Outcome Auditing**
  - Why needed here: The paper's core thesis is that high accuracy masks flawed processes. Standard benchmarks measure outcomes; this framework measures *how* outcomes are reached (KEU retention, conflict resolution, viewpoint shift justification).
  - Quick check question: Two systems both achieve 85% accuracy. System A has 70% KEU retention and 80% evidence-based decisions. System B has 40% KEU retention and 30% evidence-based decisions. Which is safer for clinical deployment?

## Architecture Onboarding

- Component map: Domain Agents (produce evidence/proposals) -> Meta Agents (synthesize, mediate conflicts) -> Audit Agents (track KEUs, viewpoint shifts, quality, conflicts)
- Critical path: 1. KEU Extraction (Domain Agents) → 2. Initial Proposals → 3. Synthesis (Meta Agent, first major information bottleneck) → 4. Review Round (Domain Agents reassess) → 5. Conflict Resolution (if multi-round) → 6. Final Aggregation (voting vs. evidence-weighted). Failures concentrate at steps 3 (KEU loss), 4-5 (viewpoint suppression), and 6 (bypassing evidence-based evaluation).
- Design tradeoffs:
  - Multi-round vs. single-round: Multi-round improves KEU retention and conflict resolution but increases voting-based decisions (evidence degradation)
  - Role specialization vs. generic agents: Specialized roles don't guarantee diverse outputs (8.4% of failures stem from failed expertise elicitation)
  - Voting vs. argument-quality aggregation: Voting is simpler but bypasses evidence; quality-weighting is more complex but may preserve minority correctness
- Failure signatures:
  - High KEU missing rate (>50%): Synthesis stage is filtering too aggressively
  - High clinical priority mismatch (>70%): Agents aren't internalizing risk-averse clinical norms
  - Low M1 rate (<5%) + high M2 rate (>20%): System suppresses correct minorities; design needs minority-protection mechanisms
  - High conflict dropout at round boundaries: Cross-turn memory is insufficient
- First 3 experiments:
  1. **KEU Injection Test**: Modify the synthesis prompt to require explicit listing of KEUs from proposals. Measure whether KEU retention rate improves in single-round systems.
  2. **Minority Protection Ablation**: Implement a rule requiring that if a minority opinion has higher evidence-quality score than the majority, it cannot be overridden without explicit rebuttal. Measure M1/M2 ratio change.
  3. **Conflict-State Persistence**: Store CCPs from each round and inject them into all subsequent agent prompts. Compare conflict dropout rates at round boundaries vs. baseline.

## Open Questions the Paper Calls Out

- **Question**: How can real-time "circuit breaker" mechanisms be implemented to effectively mitigate catastrophic collaborative failures (such as clinical priority mismatch) without disrupting valid consensus formation?
  - Basis in paper: [explicit] The Future Work section states, "research should focus on developing real-time 'circuit breakers' to mitigate catastrophic failures."
  - Why unresolved: The current study focuses on post-hoc auditing and taxonomy development rather than real-time intervention strategies.
  - What evidence would resolve it: A prototype framework where an auditor agent can pause or redirect collaboration upon detecting specific failure triggers, demonstrating improved safety metrics without loss of accuracy.

- **Question**: Do the observed failure patterns, specifically "suppression of correct minority opinions" and "flawed consensus," persist when auditing proprietary frontier models with higher base capabilities?
  - Basis in paper: [explicit] The Limitations section notes that "the performance and specific failure modes of leading proprietary models might differ" from the open-source models (DeepSeek, Qwen) used in the study.
  - Why unresolved: The empirical audit was restricted to specific open-source LLMs, leaving the generalizability of these collaborative flaws across the model quality spectrum untested.
  - What evidence would resolve it: Replication of the AuditTrail methodology on identical medical datasets using agents powered by proprietary models (e.g., GPT-4, Claude 3.5) to compare failure distribution.

- **Question**: What architectural modifications are required to reverse the trend of "Negative Majority Assimilation" and enable systems to favor evidence-based minority opinions over majority voting?
  - Basis in paper: [inferred] The paper concludes that collaboration currently favors conformity (up to 38% negative assimilation) and that voting-based decision rules often bypass evidence quality.
  - Why unresolved: While the paper quantifies the failure of current architectures to support minorities, it does not propose a specific synthesis mechanism to validate and elevate dissenting views based on evidence quality.
  - What evidence would resolve it: A new meta-agent synthesis protocol that weights arguments by logical soundness and evidential support rather than vote count, showing an increased "Successful Minority Correction" rate.

- **Question**: How do the identified failure modes, such as information loss and clinical priority mismatch, impact human clinical decision-making in human-in-the-loop (HITL) settings?
  - Basis in paper: [explicit] The Future Work section suggests extending the auditing methodology to "human-in-the-loop clinical applications, such as telehealth platforms or decision support systems."
  - Why unresolved: The current study relies on static benchmark datasets which may not reflect the complexity of real-world clinical ambiguity or the interaction dynamics between human clinicians and AI agents.
  - What evidence would resolve it: A user study with medical professionals interacting with the multi-agent systems, measuring how specific machine failures (e.g., missed high-risk diagnoses) correlate with human diagnostic errors.

## Limitations
- The framework relies on auditor agent judgment for critical dimensions like KEU identification and conflict resolution, introducing potential subjectivity despite reported high inter-annotator agreement (κ=0.82)
- Framework-specific analyses show substantial variation (e.g., MDAgents M2 rate of 38.46% vs. ReConcile's 0%), suggesting results may not generalize across all multi-agent architectures without careful adaptation
- The analysis assumes that self-reported agent justifications ("evidence_based" vs. "consensus_based") accurately reflect underlying reasoning processes, which may not hold given known LLM confabulation tendencies

## Confidence
- **High Confidence**: The empirical finding that high accuracy alone is insufficient for clinical trust; the statistical patterns of KEU retention (40%+ missing rates) and viewpoint suppression (low M1, high M2 rates) are robust across frameworks.
- **Medium Confidence**: The proposed taxonomy of collaborative failure modes, while internally validated, requires broader testing across different medical domains and agent architectures.
- **Low Confidence**: The specific quantitative thresholds (e.g., 70% clinical priority mismatch as problematic) lack established clinical validation baselines.

## Next Checks
1. Conduct blinded human expert review of 200 randomly sampled interaction logs to validate auditor agent KEU identification accuracy against gold-standard clinical reasoning.
2. Implement the minority-protection mechanism proposed in Mechanism 2 and measure changes in M1/M2 ratio across all six frameworks.
3. Test cross-framework generalizability by applying the auditing framework to non-medical multi-agent systems (e.g., financial analysis agents) to assess whether failure patterns persist or are domain-specific.