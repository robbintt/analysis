---
ver: rpa2
title: 'Social Construction of Urban Space: Understanding Neighborhood Boundaries
  Using Rental Listings'
arxiv_id: '2506.00634'
source_url: https://arxiv.org/abs/2506.00634
tags:
- neighborhood
- listings
- rental
- topic
- chicago
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes Chicago Craigslist rental advertisements from
  2018-2024 to study how neighborhood boundaries are socially constructed through
  listing agents' language choices. The authors compare traditional string-matching
  with zero-shot large language models for extracting claimed neighborhood identities
  from unstructured rental listings, finding that GPT-4.1 mini achieves 85% accuracy
  compared to 79% for string-matching.
---

# Social Construction of Urban Space: Understanding Neighborhood Boundaries Using Rental Listings

## Quick Facts
- arXiv ID: 2506.00634
- Source URL: https://arxiv.org/abs/2506.00634
- Reference count: 20
- Key result: GPT-4.1 mini achieves 85% accuracy in extracting claimed neighborhood identities from Chicago Craigslist rental listings versus 79% for string-matching

## Executive Summary
This paper investigates how neighborhood boundaries are socially constructed through rental listing agents' language choices by analyzing Chicago Craigslist advertisements from 2018-2024. The authors develop and compare zero-shot large language models against traditional string-matching for extracting claimed neighborhood identities from unstructured rental listings. Their geospatial analysis reveals systematic patterns of neighborhood boundary contestation, including "reputation laundering" where properties claim association with distant, desirable neighborhoods, and linguistic differences showing peripheral listings use more generic property search language instead of specific place-based amenities.

## Method Summary
The study processes 128,764 raw Chicago Craigslist rental ads, deduplicates to 30,531 unique listings, and extracts claimed neighborhood identities using both regex-based string matching and zero-shot GPT-4.1 mini classification with constrained response lists. Listings are geocoded and mapped to official Chicago neighborhood boundaries. A 200-listing validation set enables accuracy comparison (85% vs 79%). LDA topic modeling (k=7) identifies linguistic patterns, and OLS regression examines relationships between topic proportions, unit characteristics, and relative distance from neighborhood centroids. The hierarchical labeling approach prioritizes title claims, then body text, then neighborhood fields.

## Key Results
- GPT-4.1 mini achieves 85% classification accuracy versus 79% for string-matching (Macro F1: 0.70 vs 0.62; Weighted F1: 0.85 vs 0.77)
- Properties systematically claim association with distant, desirable neighborhoods ("reputation laundering")
- Peripheral listings substitute generic property search language for specific place-based amenities in their descriptions

## Why This Works (Mechanism)
The study demonstrates that natural language processing can reveal contested urban spaces invisible to traditional methods by analyzing how listing agents linguistically construct neighborhood boundaries. Zero-shot LLMs capture the nuanced, context-dependent ways that agents describe properties' neighborhood affiliations, while traditional string-matching misses these social constructions due to its rigid pattern-matching approach.

## Foundational Learning
- **Zero-shot classification**: Enables neighborhood extraction without labeled training data by using pre-trained language models to classify text into predefined categories; needed because labeled rental listing data is scarce and expensive to obtain; quick check: verify model outputs match expected neighborhood list format
- **Geospatial centroid analysis**: Calculates neighborhood centers from listing coordinates to measure distance-based boundary contestation; needed to quantify how far listings claim to be from their actual location; quick check: confirm centroid coordinates fall within expected neighborhood boundaries
- **Topic modeling for linguistic analysis**: Uses LDA to identify patterns in listing language that correlate with distance from neighborhood centers; needed to distinguish between place-specific and generic property descriptions; quick check: examine topic coherence and interpretability of top terms

## Architecture Onboarding
- **Component map**: Craigslist scraping -> Deduplication -> Neighborhood labeling (GPT-4.1 mini + string-match) -> Geocoding -> Validation -> Geospatial analysis -> Topic modeling -> Regression analysis
- **Critical path**: Data extraction → NLP-based labeling → Spatial analysis → Linguistic pattern identification
- **Design tradeoffs**: Zero-shot LLM offers higher accuracy but depends on proprietary models and API access; string-matching is reproducible but less accurate; topic modeling reveals patterns but requires parameter tuning
- **Failure signatures**: LLM returns neighborhood names outside Zillow list or malformed output; multiple neighborhood claims in listing body cause label ambiguity; geocoding errors prevent spatial analysis
- **First experiments**: 1) Test LLM labeling pipeline on 50-sample subset; 2) Run preliminary topic model with k=5 to check stability; 3) Calculate centroids for 3-5 neighborhoods to validate spatial analysis approach

## Open Questions the Paper Calls Out
None

## Limitations
- Raw Craigslist dataset not released due to TOS restrictions, preventing exact reproduction
- Unspecified GPT-4.1 mini model version and missing regex patterns introduce uncertainty in replicating labeling pipeline
- Small validation sample (n=200) relative to dataset size introduces potential subjectivity in ground truth establishment

## Confidence
- **High Confidence**: Peripheral listings use more generic property search language (Figure 5); reputation laundering patterns are statistically significant
- **Medium Confidence**: 85% GPT-4.1 mini accuracy claim is credible but depends on manual labels; F1-score differences between models are meaningful but validation-set sensitive
- **Low Confidence**: Exact model version and API parameters for GPT-4.1 mini unspecified; string-matching accuracy (79%) varies with implementation

## Next Checks
1. Test hierarchical labeling approach on separate 200-listing validation set using GPT-4o-mini to assess model robustness
2. Re-run LDA topic model with k=7 and alternative k values (5, 9) to verify topic stability
3. Conduct sensitivity analysis on centroid calculation using median versus mean coordinates to assess robustness to outliers