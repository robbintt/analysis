---
ver: rpa2
title: Similarity-Distance-Magnitude Activations
arxiv_id: '2509.12760'
source_url: https://arxiv.org/abs/2509.12760
tags:
- phi3
- adaptor
- mixtral8x7b
- softmax
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Similarity-Distance-Magnitude (SDM) activation
  function and SDM estimator for improved uncertainty quantification and selective
  classification in neural networks. The SDM activation extends softmax by incorporating
  signals of similarity to training data (via nearest-neighbor matching), distance
  to training distribution, and magnitude relative to decision boundary.
---

# Similarity-Distance-Magnitude Activations

## Quick Facts
- arXiv ID: 2509.12760
- Source URL: https://arxiv.org/abs/2509.12760
- Reference count: 30
- Introduces SDM activation and estimator for selective classification with controlled conditional accuracy under distribution shift

## Executive Summary
This paper presents the Similarity-Distance-Magnitude (SDM) activation function and SDM estimator for improved uncertainty quantification in selective classification. The method augments standard softmax outputs with explicit signals of similarity to training data, distance to training distribution, and magnitude relative to decision boundary. The SDM estimator uses class-wise empirical CDFs over these activations to control admission thresholds, ensuring reliable conditional accuracy under covariate shifts and out-of-distribution inputs. Experiments demonstrate superior performance compared to temperature scaling, conformal predictors, and Bayesian last-layer networks on sentiment and fact-checking tasks.

## Method Summary
The method freezes a pre-trained language model and trains a small 1-D CNN adaptor to project hidden states into a representation space suitable for nearest-neighbor matching. The SDM activation incorporates three signals: similarity (count of consecutive correct nearest neighbors), distance (normalized L2 distance to training points via class-wise CDFs), and magnitude (logit confidence). The SDM estimator partitions the class-wise empirical CDFs of SDM activations to define a "HIGH-RELIABILITY" region where conditional accuracy meets a target threshold α. During inference, predictions are admitted only if they fall within this region, otherwise they are rejected.

## Key Results
- SDM HR estimator maintains conditional accuracy ≥0.95 under covariate shifts where other methods fail
- Superior OOD detection performance compared to temperature scaling, conformal predictors, and Bayesian last-layer networks
- Achieves reliable selective classification with controlled admission rates across sentiment and fact-checking tasks
- Enables interpretability-by-exemplar through dense matching against training data

## Why This Works (Mechanism)

### Mechanism 1: Instance-Based Epistemic Uncertainty Decomposition
The SDM activation decomposes epistemic uncertainty into similarity (depth-matches), distance (to training distribution), and magnitude (logit confidence), providing more reliable uncertainty estimates than softmax alone. The exemplar adaptor projects hidden states into a space where nearest-neighbor lookups correlate with correctness.

### Mechanism 2: Class-Conditional Quantile Filtering
The SDM estimator filters predictions through a data-driven "HIGH-RELIABILITY" region defined by rescaled similarity and class-wise thresholds. It iteratively searches for minimum similarity score such that empirical CDFs exceed target accuracy, admitting only predictions within this region.

### Mechanism 3: Instance-Wise Temperature Scaling
The activation formula effectively uses distance and similarity as dynamic power terms, adjusting output sharpness per-instance. For in-distribution data, the distribution sharpens; for OOD data, the power term nullifies logits, resulting in uniform distribution.

## Foundational Learning

- **Concept: Conformal Prediction & Calibration**
  - Why needed: SDM Estimator relies on class-wise empirical CDFs to guarantee conditional accuracy
  - Quick check: How does "HIGH-RELIABILITY" region differ from standard Temperature Scaling?

- **Concept: k-Nearest Neighbors in Representation Space**
  - Why needed: Similarity and Distance are derived from nearest-neighbor lookups in adaptor's embedding space
  - Quick check: Why does SDM method require caching training embeddings at test time?

- **Concept: Frozen Backbones & Adaptors**
  - Why needed: Isolates uncertainty quantification logic from main model's generative capabilities
  - Quick check: What happens to SDM estimates if you unfreeze and update main LM weights?

## Architecture Onboarding

- **Component map:** Frozen LM -> Exemplar Adaptor -> Support Set Cache -> Similarity/Distance Engine -> SDM Activation Layer -> SDM Estimator

- **Critical path:** Input text → Frozen LM → Adaptor → Logits & Embedding → KNN Search on Support Set → Compute q and d → Apply SDM formula → Check admission thresholds

- **Design tradeoffs:** Memory vs. Compute (store all adapted embeddings), Rigidity (backbone frozen), Conservatism (rejects more points than softmax)

- **Failure signatures:** Total Rejection (q'_min = ∞), OOD Over-confidence (OOD points admitted due to poor distance calibration)

- **First 3 experiments:**
  1. Sanity Check: Train adaptor, verify admitted points meet target accuracy, plot q distributions
  2. Adversarial/OOD Check: Feed noise/shuffled text, verify d→0 and uniform predictions or rejections
  3. Hyperparameter Sensitivity: Vary calibration set size, observe q'_min stability

## Open Questions the Paper Calls Out
- Can updatability property provide performance advantage in continual learning settings?
- Is adding instances with unknown labels to support set more effective than training explicit OOD class?
- Does SDM estimator maintain accuracy and efficiency on multi-class tasks with large label spaces?
- How sensitive is uncertainty estimation to specific adaptor architecture?

## Limitations
- Requires storing all training embeddings for KNN lookups (O(N) memory)
- Only evaluated on binary classification tasks
- Conservative approach may reject too many inputs in low-data regimes
- Relies on frozen backbone; cannot fix fundamental representation issues

## Confidence
- Method description: High
- Experimental results: Medium (binary tasks only)
- Theoretical guarantees: Medium (empirical CDF-based)
- Generalizability to multi-class: Low (not evaluated)

## Next Checks
1. Verify that admitted points in validation set meet target accuracy ≥0.95
2. Test OOD detection by feeding random noise and confirming d→0 and rejection
3. Measure sensitivity of q'_min to calibration set size changes