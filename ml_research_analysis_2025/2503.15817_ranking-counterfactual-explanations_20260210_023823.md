---
ver: rpa2
title: Ranking Counterfactual Explanations
arxiv_id: '2503.15817'
source_url: https://arxiv.org/abs/2503.15817
tags:
- counterfactual
- explanations
- optimal
- minimal
- counterfactuals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of ranking and identifying optimal
  counterfactual explanations in eXplainable AI (XAI). The authors propose a formal
  definition of counterfactual explanations and investigate their properties, including
  their relationship with factual explanations.
---

# Ranking Counterfactual Explanations
## Quick Facts
- arXiv ID: 2503.15817
- Source URL: https://arxiv.org/abs/2503.15817
- Authors: Suryani Lim; Henri Prade; Gilles Richard
- Reference count: 5
- Primary result: Introduces a method to rank counterfactual explanations based on "counterfactual power," identifying optimal explanations in over 80% of cases on 12 real-world datasets.

## Executive Summary
This paper addresses the challenge of ranking and identifying optimal counterfactual explanations in eXplainable AI (XAI). The authors propose a formal definition of counterfactual explanations and investigate their properties, including their relationship with factual explanations. They introduce a method to rank counterfactual explanations based on "counterfactual power," which measures the local reusability of a counterfactual example. Three metrics—typicality, capacity, and universality—are defined to evaluate the quality of counterfactual explanations. Experiments on 12 real-world datasets show that a unique optimal counterfactual can be identified in over 80% of cases. The optimal counterfactual exhibits higher representativeness and can explain a broader range of elements than a random minimal counterfactual, as demonstrated by the three evaluation metrics. The approach is model-agnostic and broadly applicable to categorical datasets.

## Method Summary
The authors propose a formal framework for counterfactual explanations in XAI, introducing the concept of "counterfactual power" to measure the local reusability of counterfactual examples. They define three metrics—typicality, capacity, and universality—to evaluate the quality of counterfactual explanations. The method involves generating counterfactual explanations for a given dataset and then ranking them based on their counterfactual power. The approach is model-agnostic and can be applied to categorical datasets. Experiments are conducted on 12 real-world datasets to validate the effectiveness of the proposed method.

## Key Results
- A unique optimal counterfactual can be identified in over 80% of cases.
- The optimal counterfactual exhibits higher representativeness than a random minimal counterfactual.
- The optimal counterfactual can explain a broader range of elements than a random minimal counterfactual.

## Why This Works (Mechanism)
The proposed method works by introducing a formal definition of counterfactual explanations and their properties. The concept of "counterfactual power" measures the local reusability of a counterfactual example, allowing for the ranking of counterfactual explanations. The three metrics—typicality, capacity, and universality—provide a comprehensive evaluation of the quality of counterfactual explanations. By combining these elements, the method can identify an optimal counterfactual that is both representative and broadly applicable.

## Foundational Learning
- Counterfactual explanations: Why needed - To provide actionable insights for decision-making in XAI; Quick check - Ensure the counterfactual is both feasible and meaningful in the context of the problem.
- Counterfactual power: Why needed - To measure the local reusability of counterfactual examples; Quick check - Verify that the counterfactual power metric accurately reflects the practical utility of the counterfactual.
- Typicality, capacity, and universality metrics: Why needed - To comprehensively evaluate the quality of counterfactual explanations; Quick check - Confirm that these metrics capture the key aspects of counterfactual explanation quality.

## Architecture Onboarding
Component map: Data -> Counterfactual Generator -> Counterfactual Explanations -> Ranking (Counterfactual Power) -> Optimal Counterfactual
Critical path: The critical path involves generating counterfactual explanations and then ranking them based on their counterfactual power to identify the optimal counterfactual.
Design tradeoffs: The model-agnostic approach allows for broad applicability but may limit the method's effectiveness on specific model types. The focus on categorical datasets may restrict the method's applicability to other data types.
Failure signatures: Failure may occur if the counterfactual power metric does not accurately reflect the practical utility of the counterfactual, or if the three evaluation metrics do not comprehensively capture the quality of counterfactual explanations.
First experiments: 1) Generate counterfactual explanations for a simple dataset and rank them using the proposed method. 2) Compare the optimal counterfactual identified by the method with a random minimal counterfactual. 3) Validate the effectiveness of the three evaluation metrics on a diverse set of datasets.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies on 12 real-world datasets, which may not capture the full diversity of data distributions and model architectures.
- The claim that over 80% of cases yield a unique optimal counterfactual needs validation across more diverse settings and model types.
- The practical implications of using the optimal counterfactual for decision-making processes need more investigation.

## Confidence
- High: The theoretical framework for ranking counterfactual explanations is sound.
- Medium: The empirical validation is limited to specific conditions and may not generalize to all settings.
- Low: The scalability of the method to high-dimensional and large-scale datasets is not explicitly addressed.

## Next Checks
1) Test the approach on a wider variety of datasets and model architectures to validate its generalizability.
2) Conduct a thorough comparison with existing counterfactual explanation methods to assess relative performance.
3) Evaluate the method's performance on high-dimensional and large-scale datasets to assess scalability.