---
ver: rpa2
title: Automatically Generating Chinese Homophone Words to Probe Machine Translation
  Estimation Systems
arxiv_id: '2503.16158'
source_url: https://arxiv.org/abs/2503.16158
tags:
- words
- translation
- homophone
- chinese
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for automatically generating
  Chinese homophone words to test the robustness of machine translation (MT) quality
  estimation (QE) models, especially for emotion-loaded user-generated content (UGC).
  The authors leverage self-information from language models to generate homophone
  words that are more likely to be used by netizens, and compare their method with
  an existing percentile score approach.
---

# Automatically Generating Chinese Homophone Words to Probe Machine Translation Estimation Systems

## Quick Facts
- arXiv ID: 2503.16158
- Source URL: https://arxiv.org/abs/2503.16158
- Reference count: 14
- Primary result: Self-information method for generating Chinese homophones outperforms percentile baseline in human evaluation and improves MT QE robustness testing

## Executive Summary
This paper introduces a novel method for automatically generating Chinese homophone words to test the robustness of machine translation (MT) quality estimation (QE) models, especially for emotion-loaded user-generated content (UGC). The authors leverage self-information from language models to generate homophone words that are more likely to be used by netizens, and compare their method with an existing percentile score approach. Human evaluation shows that the self-information method achieves higher correlation with human judgments than the baseline. The generated homophones are used to perturb MT outputs and probe the robustness of QE models including fine-tuned COMET and TransQuest, multi-task learning models, and large language models (LLMs). Results show that LLMs with larger sizes exhibit higher stability and robustness to the perturbations. Specifically, larger models like DeepSeek-67B maintain more consistent QE scores when homophone slang in source text is replaced with generated alternatives, while also reflecting improvements in translation quality. The study concludes that LLMs with larger sizes offer better robustness and stability for QE of emotion-loaded UGC translation.

## Method Summary
The authors propose a self-information-based method for generating Chinese homophones by leveraging language model probabilities. They compute self-information scores for candidate homophones and select those with higher scores, indicating they are more likely to be used in online contexts. The method is evaluated against a baseline percentile score approach through human evaluation of naturalness and appropriateness. Generated homophones are then used to create perturbations in MT outputs, which are fed into various QE models including fine-tuned COMET, TransQuest, multi-task learning models, and LLMs of different sizes. The robustness of these QE models is assessed by comparing their performance on original and perturbed translations.

## Key Results
- Self-information method achieves higher correlation with human judgments than percentile baseline
- Larger LLMs (DeepSeek-67B) maintain more consistent QE scores under homophone perturbations
- LLMs reflect improvements in translation quality when homophone slang is replaced with generated alternatives

## Why This Works (Mechanism)
The method works by leveraging the statistical properties of language models to identify homophones that are more likely to be used in online contexts. By using self-information (negative log probability), the approach prioritizes homophones that are more probable in natural language, making them more effective for probing QE models. The perturbations created by replacing homophones test the QE models' ability to handle non-literal language and slang commonly found in UGC.

## Foundational Learning
- Chinese homophone generation: why needed - to create realistic online slang variations; quick check - compare generated homophones with actual online usage data
- Self-information computation: why needed - to identify probable homophones; quick check - verify that high self-information correlates with natural usage
- QE model robustness testing: why needed - to evaluate performance on non-standard language; quick check - measure score consistency across perturbations
- Language model probabilities: why needed - as foundation for self-information calculation; quick check - ensure probabilities reflect actual usage patterns
- Human evaluation protocols: why needed - to validate naturalness of generated homophones; quick check - assess inter-annotator agreement
- UGC characteristics: why needed - to understand the specific challenges in online translation; quick check - analyze frequency of homophones in UGC datasets

## Architecture Onboarding

Component Map: Language Model -> Self-Information Calculator -> Homophone Generator -> QE Models -> Evaluation Metrics

Critical Path: Chinese text input -> Language model probability computation -> Self-information calculation -> Homophone selection -> MT perturbation -> QE model scoring -> Robustness assessment

Design Tradeoffs: The method trades computational complexity for more realistic homophones. While self-information calculation is more expensive than simple frequency-based methods, it produces homophones that better reflect online usage patterns and are therefore more effective for probing QE models.

Failure Signatures: QE models may show high variance in scores across homophone perturbations, indicating poor robustness to non-literal language. Models may also fail to detect quality improvements when homophones are replaced with more standard terms.

First Experiments:
1. Compare self-information scores with actual usage frequency in online corpora
2. Test QE model performance on manually created homophone variations
3. Evaluate the correlation between self-information scores and human judgments of naturalness

## Open Questions the Paper Calls Out
None

## Limitations
- Potential bias in human evaluation of generated homophones due to subjective interpretation
- Focus on homophone perturbations may not capture full range of UGC translation challenges
- Results based on specific perturbation type may not generalize to all forms of noise

## Confidence
- Larger LLMs maintain consistent QE scores under homophone perturbations: Medium
- Larger models reflect improvements in translation quality: Medium
- LLMs with larger sizes offer better robustness for emotion-loaded UGC translation: Low

## Next Checks
1. Conduct a broader range of perturbation tests, including non-homophone variations such as synonyms, misspellings, and grammatical errors, to assess the general robustness of QE models.
2. Implement a blind human evaluation study where evaluators are unaware of the source of generated homophones to reduce potential bias in naturalness and appropriateness judgments.
3. Perform a longitudinal study to track the performance of QE models on evolving UGC language trends, ensuring that the robustness of larger LLMs holds over time as online language continuously changes.