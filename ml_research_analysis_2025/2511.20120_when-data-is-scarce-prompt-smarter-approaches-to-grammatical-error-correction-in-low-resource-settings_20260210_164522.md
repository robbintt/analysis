---
ver: rpa2
title: '"When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction
  in Low-Resource Settings'
arxiv_id: '2511.20120'
source_url: https://arxiv.org/abs/2511.20120
tags:
- languages
- correction
- language
- grammatical
- indic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates grammatical error correction (GEC) for
  low-resource Indic languages using prompting-based approaches with large language
  models (LLMs). The authors explore zero-shot and few-shot prompting strategies with
  state-of-the-art LLMs including GPT-4.1, Gemini-2.5, and LLaMA-4, demonstrating
  that even basic prompting strategies substantially outperform fine-tuned Indic-language
  models like Sarvam-22B.
---

# "When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings

## Quick Facts
- arXiv ID: 2511.20120
- Source URL: https://arxiv.org/abs/2511.20120
- Authors: Somsubhra De; Harsh Kumar; Arun Prakash A
- Reference count: 14
- Primary result: Prompting-based approaches with LLMs substantially outperform fine-tuned Indic models in low-resource GEC

## Executive Summary
This paper investigates grammatical error correction (GEC) for low-resource Indic languages using prompting-based approaches with large language models (LLMs). The authors explore zero-shot and few-shot prompting strategies with state-of-the-art LLMs including GPT-4.1, Gemini-2.5, and LLaMA-4, demonstrating that even basic prompting strategies substantially outperform fine-tuned Indic-language models like Sarvam-22B. Their experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across Tamil, Hindi, Telugu, Bengali, and Malayalam. The approach achieved leading results in the shared task, ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bengali (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). The findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

## Method Summary
The paper employs zero-shot and few-shot prompting with large language models (GPT-4.1-mini, Gemini-2.5-Flash, LLaMA-4-Maverick) for GEC on five Indic languages. The few-shot approach uses 10 language-matched exemplars per language, with Hindi exemplars manually curated for specific error types while other languages use random sampling. The authors also compare against fine-tuned Sarvam-M 24B using LoRA adaptation. Evaluation uses GLEU, F0.5, and BERTScore metrics with IndicNLP tokenizer for fair script handling. The approach leverages multilingual representations and in-context learning without gradient updates, demonstrating superior performance over traditional fine-tuning approaches.

## Key Results
- LLMs (GPT-4.1, Gemini-2.5, LLaMA-4) substantially outperform fine-tuned Sarvam-22B across all five Indic languages
- Few-shot prompting significantly improves performance over zero-shot, though Dravidian languages show unique sensitivity to exemplar quality
- Gemini-2.5 demonstrates superior tokenizer efficiency for Dravidian languages, correlating with higher GLEU scores
- The approach achieved 1st place in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69) in the shared task

## Why This Works (Mechanism)

### Mechanism 1: In-Context Learning via Few-Shot Exemplars
Claim: Providing k input-output example pairs in the prompt enables LLMs to implicitly infer language-specific grammatical patterns without gradient updates.
Mechanism: The model conditions on demonstration pairs {(x₁, y₁), ..., (xₖ, yₖ)}, inferring task-specific correction patterns through attention over the context window. This bypasses the need for large parallel corpora.
Core assumption: The pre-trained model already encodes sufficient grammatical knowledge of the target language, and examples primarily help with task framing rather than knowledge injection.
Evidence anchors:
- [abstract] "even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B"
- [section 4.2.2] "This allowed the model to infer task-specific patterns and linguistic consistency directly from context."
- [corpus] Related work on "Explanation based In-Context Demonstrations Retrieval" (FMR: 0.517) supports few-shot ICL for GEC, but direct mechanistic validation for Indic languages remains limited.
Break condition: If test errors involve grammar rules not represented in the few-shot exemplars AND not encoded in pre-training data, performance degrades to zero-shot levels.

### Mechanism 2: Multilingual Representational Transfer from Scale
Claim: Large-scale multilingual pre-training yields internal representations that generalize to low-resource Indic grammatical patterns, outperforming smaller language-specific fine-tuned models.
Mechanism: Foundation models with 100B+ parameters and diverse multilingual training data encode cross-lingual syntactic regularities. These representations support grammatical reasoning even for languages with limited training presence.
Core assumption: Grammatical patterns in Indic languages share transferable abstractions with higher-resource languages present during pre-training.
Evidence anchors:
- [abstract] "illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC"
- [section 5.1] Fine-tuned Sarvam-M (24B) "lags significantly...achieving only 13.81 GLEU in Hindi—we attribute this to its limited total parameter capacity compared to the massive sparse architectures of the foundation models"
- [corpus] Evidence weak; corpus neighbors focus on annotation frameworks and instruction tuning rather than scale-transfer mechanisms specifically.
Break condition: If target language grammar exhibits typological features absent from pre-training distribution (e.g., rare agglutinative morphemes), scale-based transfer may not activate.

### Mechanism 3: Tokenizer Efficiency as Performance Moderator
Claim: Lower tokenizer fertility (tokens-per-word ratio) correlates with better GEC performance for morphologically rich Indic languages by preserving context window capacity.
Mechanism: Efficient tokenization reduces sequence fragmentation, enabling more complete grammatical context within fixed context windows and reducing error propagation from subword boundary artifacts.
Core assumption: Tokenization efficiency affects downstream task quality, not just inference speed.
Evidence anchors:
- [section B, Table 5] Gemini achieves lowest fertility for Bengali (1.76) and correlates with top GLEU; LLaMA-4 shows highest fertility for Tamil (5.88) and lower relative performance
- [section 5.1] "Tokenization plays a crucial role in evaluating GEC models for Indic languages"
- [corpus] Corpus references tokenizer-fertility work (Ali et al., 2024) but direct causal linkage to GEC quality remains under-explored.
Break condition: If context windows are sufficiently large or if grammatical errors are local (short-range dependencies), tokenizer efficiency impact diminishes.

## Foundational Learning

- Concept: Sequence-to-Sequence (Seq2Seq) with Conditional Generation
  - Why needed here: GEC is framed as Pθ(y|x)—mapping noisy sentence x to corrected y. Understanding autoregressive generation and teacher forcing is prerequisite to interpreting model behavior.
  - Quick check question: Can you explain why GEC is modeled as conditional generation rather than sequence labeling?

- Concept: In-Context Learning (ICL) vs. Gradient-Based Fine-Tuning
  - Why needed here: The paper's central claim hinges on ICL outperforming LoRA fine-tuning. Understanding the distinction—no weight updates vs. low-rank adapter training—is essential.
  - Quick check question: What is the computational and data difference between providing 10 few-shot examples vs. fine-tuning LoRA adapters?

- Concept: Tokenization Fertility and Morphological Complexity
  - Why needed here: The paper demonstrates that Dravidian languages (Tamil, Malayalam) suffer higher fertility scores, affecting performance. Understanding BPE/SentencePiece behavior with agglutinative scripts informs model selection.
  - Quick check question: Why would a tokenizer fragment Tamil words more than Hindi words, and how does this affect context window utilization?

## Architecture Onboarding

- Component map:
  - Input Layer: Raw Indic text → Model-specific tokenizer (GPT o200k_base / Gemini SentencePiece / LLaMA tokenizer)
  - Prompt Constructor: System instruction + k few-shot exemplars (k=10 in paper)
  - LLM Backbone: GPT-4.1-mini / Gemini-2.5-Flash / LLaMA-4-Maverick (inference-only, no gradient updates)
  - Output Parser: Extract corrected sentence; handle "no-change" cases
  - Evaluation: GLEU (n-gram overlap), F0.5 (precision-weighted), BERTScore (semantic similarity)

- Critical path:
  1. Language identification → select appropriate prompt template (Dravidian vs. Indo-Aryan)
  2. Tokenize with model-specific tokenizer → check fertility (high fertility flags potential issues)
  3. Construct prompt with 10 language-matched exemplars (curated for Hindi; random for others per paper)
  4. Inference → extract output → evaluate with IndicNLP tokenizer for fair metric computation

- Design tradeoffs:
  - Zero-shot vs. Few-shot: Zero-shot faster (no exemplar curation) but lower GLEU; few-shot adds latency but improves accuracy
  - Model selection: Gemini = best tokenizer efficiency for Dravidian; GPT = competitive across all; LLaMA = open-weight but high fertility
  - Prompt design: Detailed instructions (Dravidian prompt) vs. concise instructions (Hindi/Bengali prompt)—trade-off between specificity and over-constraint

- Failure signatures:
  - Output identical to input when corrections needed → prompt failed to specify error type coverage
  - Output changes meaning/semantics → over-correction; add instruction "preserve intended meaning"
  - High GLEU but low BERTScore → surface-level n-gram matches without semantic fidelity
  - Model returns explanations instead of corrected text → prompt missing "output ONLY the corrected sentence"

- First 3 experiments:
  1. Baseline zero-shot: Run all 5 languages with zero-shot prompting; record GLEU/F0.5/BERTScore per language per model to establish floor performance.
  2. Few-shot ablation (k=1, 3, 5, 10): Test Tamil and Hindi with varying exemplar counts to find saturation point; expect diminishing returns beyond k=5 for simpler languages.
  3. Cross-lingual exemplar transfer: Test Hindi GEC with Tamil exemplars (and vice versa) to probe whether exemplar language or grammatical pattern matters more for ICL activation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the quantitative relationship between tokenizer fertility scores and downstream GEC performance for morphologically rich Indic languages?
- Basis in paper: [explicit] The authors state: "we did not conduct a systematic ablation of this relationship here" and propose "a rigorous investigation into tokenizer fertility and its correlation with downstream performance" as future work.
- Why unresolved: The paper demonstrates significant "Tokenization Gap" between models (e.g., Llama 4 shows F=5.88 for Tamil vs. Gemini's F=2.54) but only correlates this with efficiency, not correction quality.
- What evidence would resolve it: Systematic ablation experiments controlling for model architecture while varying tokenizer vocabularies, measuring both fertility and GLEU/F0.5 scores across languages.

### Open Question 2
- Question: Can correction patterns learned from high-resource Indic languages (Hindi, Tamil) transfer effectively to related low-resource languages (Marathi, Kannada) via multilingual joint fine-tuning?
- Basis in paper: [explicit] Future work proposes "evaluating the transferability of learnt correction patterns from Hindi to other related languages such as Marathi and Bengali, and from Tamil or Telugu to low-resource southern languages" and "multilingual joint fine-tuning strategies using shared sub-word representations."
- Why unresolved: Current work only evaluates five languages independently; cross-lingual transfer mechanisms remain unexplored.
- What evidence would resolve it: Experiments training on Hindi-only data, evaluating on Marathi; training on Tamil-only, evaluating on Kannada, with and without shared sub-word vocabulary approaches.

### Open Question 3
- Question: Why does zero-shot prompting outperform few-shot prompting specifically for Dravidian languages (Tamil, Malayalam) but not Indo-Aryan languages?
- Basis in paper: [inferred] The authors hypothesize "few-shot exemplars introduce stylistic noise that disrupts the model's otherwise robust internal multilingual representations" for Dravidian languages, but this is not empirically validated.
- Why unresolved: The paper only notes the phenomenon without controlled experiments isolating the cause; the 10 few-shot examples were randomly sampled for Dravidian languages vs. manually curated for Hindi.
- What evidence would resolve it: Ablation study with (a) manually curated vs. random few-shot examples for all languages, (b) varying number of shots (k=1,3,5,10), and (c) analysis of error types introduced by few-shot exemplars in Dravidian vs. Indo-Aryan contexts.

## Limitations

- Dataset Generalization Risk: Results are based on a single shared task dataset (BHASHA 2025), raising questions about generalizability to other GEC datasets
- Tokenization Impact Uncertainty: While tokenizer fertility correlates with performance, the mechanistic relationship between tokenization efficiency and grammatical correction quality remains under-specified
- Exemplar Selection Bias: Hindi uses manually curated exemplars while other languages use random sampling, creating asymmetry that may inflate Hindi's performance advantage

## Confidence

- Claim Cluster 1: LLMs Outperform Fine-Tuned Models in Low-Resource GEC (High Confidence): The empirical results showing GPT-4.1, Gemini-2.5, and LLaMA-4 outperforming the fine-tuned Sarvam-22B model are well-supported by the data.
- Claim Cluster 2: Few-Shot Prompting Significantly Improves Performance (High Confidence): The paper demonstrates clear performance improvements from zero-shot to few-shot prompting, with the magnitude of improvement being consistent across languages and models.
- Claim Cluster 3: Tokenizer Efficiency Moderates Performance (Medium Confidence): The correlation between low tokenizer fertility and high GLEU scores is well-documented, but the causal mechanisms and magnitude of impact require further investigation.
- Claim Cluster 4: Large-Scale LLMs Enable Multilingual Generalization (Medium Confidence): While the results demonstrate strong performance across diverse Indic languages, the paper doesn't provide mechanistic evidence for why multilingual pre-training enables this generalization.

## Next Checks

1. **Independent Dataset Validation:** Replicate the prompting experiments on at least two additional GEC datasets for Indic languages (e.g., the IIT Bombay corpus or any publicly available alternative) to verify that the reported performance gains generalize beyond the BHASHA dataset.

2. **Tokenization Ablation Study:** Design controlled experiments varying only the tokenizer (using the same model and prompt) to isolate the impact of tokenization efficiency on GEC performance. This should include testing both tokenizers optimized for each language versus shared tokenizers.

3. **Cross-Lingual Exemplar Transfer:** Systematically test whether few-shot exemplars from one Indic language (e.g., Hindi) can effectively enable GEC for another language (e.g., Tamil) to determine whether exemplar language or grammatical pattern similarity drives few-shot success.