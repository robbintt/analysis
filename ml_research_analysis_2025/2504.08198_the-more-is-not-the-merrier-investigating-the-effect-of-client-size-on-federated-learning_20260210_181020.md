---
ver: rpa2
title: 'The More is not the Merrier: Investigating the Effect of Client Size on Federated
  Learning'
arxiv_id: '2504.08198'
source_url: https://arxiv.org/abs/2504.08198
tags:
- clients
- data
- accuracy
- client
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of increasing client numbers
  on federated learning accuracy using the FedAvg algorithm. The authors find that
  test accuracy significantly deteriorates as the number of clients grows, with a
  30% drop observed when increasing from 5 to 100 clients on CIFAR-10 dataset.
---

# The More is not the Merrier: Investigating the Effect of Client Size on Federated Learning

## Quick Facts
- arXiv ID: 2504.08198
- Source URL: https://arxiv.org/abs/2504.08198
- Authors: Eleanor Wallach; Sage Siler; Jing Deng
- Reference count: 29
- Key result: FedAvg accuracy deteriorates significantly (30% drop) as client count increases from 5 to 100 on CIFAR-10

## Executive Summary
This paper investigates how increasing the number of clients affects federated learning accuracy using the FedAvg algorithm. The authors find that test accuracy significantly deteriorates as client count grows, with a 30% drop observed when increasing from 5 to 100 clients on CIFAR-10. To address this issue, they propose Knowledgeable Client Insertion (KCI), which introduces a small number of artificial clients with substantial data to improve training. Experimental results show KCI can achieve up to 45% accuracy improvement compared to standard FedAvg, particularly effective for large client numbers (100 clients).

## Method Summary
The authors use FedAvg on CIFAR-10 with a custom CNN architecture (2 conv layers, 2 FC layers). They vary the number of clients (K ∈ {5, 10, 20, 50, 100}) with IID data partitioning, local epochs E=5, and rounds T=50. KCI introduces m artificial "knowledgeable" clients holding λ proportion of total training data. The knowledgeable clients participate in FedAvg aggregation alongside regular clients, benefiting from weighted averaging based on their larger data contribution.

## Key Results
- FedAvg test accuracy deteriorates by 30% when increasing client count from 5 to 100 on CIFAR-10
- KCI with m=2 knowledgeable clients achieves up to 45% accuracy improvement over standard FedAvg for 100 clients
- The optimal configuration appears to be using two knowledgeable clients regardless of λ value
- KCI shows minimal improvement (5%) when client count is small (K=10)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Test accuracy deteriorates as the number of clients increases in FedAvg due to data fragmentation per client.
- Mechanism: When a fixed dataset is partitioned among more clients, each client receives fewer training samples and potentially fewer class categories. Local model updates become less representative of the global data distribution, leading to slower convergence and lower final accuracy.
- Core assumption: The dataset size is fixed while client count varies; clients train with IID partitioned data.
- Evidence anchors:
  - [abstract] "We find a significant deterioration of learning accuracy for FedAvg as the number of clients increases."
  - [section IV] "This is due to the nature in which data is dispersed amongst clients."
  - [corpus] FedEve paper notes client drift from data heterogeneity as a fundamental FL challenge, though KCI specifically addresses fragmentation rather than non-IID distribution.
- Break condition: If local dataset size scales proportionally with client count (i.e., more total data as clients increase), this degradation mechanism may not apply.

### Mechanism 2
- Claim: Inserting a small number of knowledgeable clients with large local datasets stabilizes and accelerates FedAvg convergence.
- Mechanism: Knowledgeable clients hold a substantial portion (λ-controlled) of the total training data. During FedAvg aggregation, these clients receive proportionally higher weights (n_k/∑n_k) due to their larger data contribution, providing a more representative gradient signal that guides the global model toward the true data distribution.
- Core assumption: The server does not distinguish between artificial and regular clients during aggregation; FedAvg's weighted averaging treats all clients identically based on data volume.
- Evidence anchors:
  - [abstract] "These knowledgeable clients are expected to have accumulated a large set of data samples to help with training."
  - [section V-B] "Allowing one client to train with all of the data greatly improves the accuracy for 100 clients... KCI yields a 45% accuracy increase for 100 clients."
  - [corpus] Fluid Democracy paper explores weighted client selection, but KCI's weighting emerges naturally from FedAvg's data-proportional aggregation rather than explicit selection mechanisms.
- Break condition: If knowledgeable clients' data distributions differ substantially from the global distribution (non-representative sampling), their influence may bias the model away from true optima.

### Mechanism 3
- Claim: Two knowledgeable clients (m=2) consistently outperform one or four, regardless of how total data is divided among them.
- Mechanism: Assumption: Two clients may provide an optimal balance between aggregation stability and gradient diversity. A single client (m=1) may introduce overfitting or insufficient gradient variance, while four clients (m=4) dilute the knowledgeable signal across too many aggregators, re-introducing fragmentation effects.
- Core assumption: The relationship between m and optimal convergence is influenced by FedAvg's aggregation dynamics, not just total data volume.
- Evidence anchors:
  - [section V-B] "When one client receives all of the local data (m=1, λ=1), the accuracy is lower compared to when this data is evenly divided amongst two clients (m=2, λ=0.5)."
  - [section V-B] "This suggests setting m=2 regardless of the amount of local data available to be split amongst clients yields the highest accuracies."
  - [corpus] No direct corroboration found; corpus evidence on optimal client configuration is weak or missing for this specific claim.
- Break condition: The m=2 optimum may not generalize to different dataset scales, model architectures, or extreme client counts (K >> 100).

## Foundational Learning

- Concept: **FedAvg Aggregation Weighting**
  - Why needed here: KCI's effectiveness depends on understanding how FedAvg weights client contributions by data volume (n_k/m_t), making knowledgeable clients inherently more influential.
  - Quick check question: If a client has 10x more data than others, how does this affect its contribution to the global model update?

- Concept: **Data Fragmentation vs. Non-IID Distribution**
  - Why needed here: The paper addresses accuracy degradation from reduced per-client data volume (fragmentation), which is distinct from degradation caused by heterogeneous data distributions (non-IID), though both can co-occur.
  - Quick check question: Would adding more total training data while keeping client count constant produce similar accuracy improvements to KCI?

- Concept: **Client Drift in Federated Optimization**
  - Why needed here: As client count increases, local models may diverge from the global optimum due to limited local data; understanding drift helps diagnose why KCI stabilizes convergence.
  - Quick check question: How does reducing local epochs (E) affect client drift, and how might KCI interact with this?

## Architecture Onboarding

- Component map:
  Central Server -> Regular Clients (K) and Knowledgeable Clients (m) -> Data Partitioner

- Critical path:
  1. Initialize global model w_0
  2. For each round t: distribute w_t to all clients (K + m)
  3. All clients perform local training (E epochs)
  4. Server aggregates using FedAvg: w_{t+1} = Σ(n_k/m_t) × w_k^{t+1}
  5. Repeat for T rounds

- Design tradeoffs:
  - Higher λ: Better accuracy but requires more data accumulation for knowledgeable clients; may reduce privacy benefits if knowledgeable client data is centralized.
  - Higher m (beyond 2): Diminishing returns observed; may dilute knowledgeable signal.
  - Privacy vs. accuracy: KCI suggests reduced local training needs for regular clients, but paper does not empirically validate privacy claims against model inversion attacks.

- Failure signatures:
  - Accuracy plateaus below expected levels with large K (>50) without KCI intervention.
  - KCI provides minimal improvement when K is small (K=10, only 5% gain) or when knowledgeable clients have low λ (<0.1).
  - Convergence instability if knowledgeable clients' data is non-representative of global distribution.

- First 3 experiments:
  1. Baseline replication: Run FedAvg on CIFAR-10 with K ∈ {5, 10, 20, 50, 100} to confirm 30% accuracy drop; validate experimental setup matches paper (E=5, T=50, IID partitioning).
  2. KCI sensitivity to λ: Fix K=100, m=2; vary λ ∈ {0.1, 0.25, 0.5, 1.0} to reproduce accuracy curve and identify practical minimum λ for acceptable performance.
  3. Generalization test: Apply KCI (m=2, λ=0.5) to a different dataset (e.g., MNIST or CIFAR-100) to assess whether m=2 optimum and accuracy gains transfer beyond CIFAR-10.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does KCI effectively protect against privacy attacks such as model inversion attacks, and what is the magnitude of this protection compared to standard FedAvg?
- Basis in paper: [explicit] The authors state "We expect this approach to be able to provide great privacy protection for clients against security attacks such as model inversion attacks" and list "an in depth privacy protection" as future research in Section VI.
- Why unresolved: No privacy experiments were conducted; the claim is theoretical, based on reduced local training needs rather than empirical security analysis.
- What evidence would resolve it: Empirical evaluation of KCI under model inversion attacks and gradient leakage attacks, comparing reconstruction success rates between KCI and standard FedAvg across different client configurations.

### Open Question 2
- Question: How does KCI interact with other FL aggregation techniques beyond FedAvg (e.g., FedProx, SCAFFOLD, MOON)?
- Basis in paper: [explicit] Section VI lists "KCI's interactions with other FL aggregation techniques" as future research, and Footnote 1 states evaluations with other techniques are left to future work.
- Why unresolved: All experiments use only FedAvg aggregation; the generalizability of KCI to other aggregation methods is unknown.
- What evidence would resolve it: Comparative experiments applying KCI across multiple aggregation algorithms (FedProx, SCAFFOLD, MOON) on benchmark datasets, measuring accuracy improvements and convergence behavior.

### Open Question 3
- Question: How does KCI perform under various non-IID data distributions?
- Basis in paper: [explicit] Section VI explicitly lists "KCI's performance under various non-IID data settings" as future research.
- Why unresolved: All experiments use IID data partitioning; real-world FL typically involves heterogeneous, non-IID data distributions.
- What evidence would resolve it: Experiments testing KCI across different non-IID settings (label skew, feature skew, quantity skew) with varying degrees of heterogeneity, comparing performance against baseline FedAvg.

### Open Question 4
- Question: Can existing clients be effectively converted into knowledgeable clients through data injection, and what are the practical constraints?
- Basis in paper: [explicit] Section IV states "it is possible to maneuver existing clients and turn them into knowledgeable clients by injecting more data samples, a process that warrants further investigation."
- Why unresolved: The paper only evaluates inserting artificial knowledgeable clients with data obtained through unspecified "outside channels"; the feasibility of upgrading regular clients is unexplored.
- What evidence would resolve it: Simulations and theoretical analysis of converting regular clients to knowledgeable clients mid-training, including resource requirements, data transfer costs, and impact on convergence.

## Limitations
- KCI's effectiveness critically depends on the representativeness of knowledgeable clients' data and assumptions about data duplication feasibility.
- The paper does not address potential privacy concerns from centralizing data in knowledgeable clients or validate claimed privacy benefits against model inversion attacks.
- The optimal configuration of m=2 knowledgeable clients is presented without theoretical justification or extensive ablation studies across different datasets and model architectures.

## Confidence

- **High confidence**: The core finding that FedAvg accuracy deteriorates significantly with increasing client count (30% drop from 5 to 100 clients) is well-supported by the experimental results and fundamental data fragmentation principles.
- **Medium confidence**: The KCI mechanism's effectiveness (45% accuracy improvement) is demonstrated empirically, but relies on assumptions about data representativeness and FedAvg's aggregation behavior that warrant further validation.
- **Low confidence**: The claim that m=2 knowledgeable clients consistently outperforms other configurations across all λ values lacks theoretical grounding and robust ablation studies beyond the CIFAR-10 dataset.

## Next Checks
1. **Data Overlap Strategy Clarification**: Determine whether KCI implementation involves data duplication (increasing total system data) or redistribution (keeping total data constant), as this fundamentally affects privacy implications and scalability.
2. **Cross-Dataset Generalization**: Validate whether the m=2 optimum and accuracy improvements transfer to different datasets (e.g., MNIST, CIFAR-100) and model architectures to assess generalizability beyond CIFAR-10.
3. **Privacy Impact Assessment**: Conduct empirical analysis to verify the claimed privacy benefits of KCI by testing vulnerability to model inversion attacks on both standard FedAvg and KCI implementations.