---
ver: rpa2
title: 'Languages are Modalities: Cross-Lingual Alignment via Encoder Injection'
arxiv_id: '2510.27254'
source_url: https://arxiv.org/abs/2510.27254
tags:
- khmer
- llink
- arxiv
- decoder
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LLINK treats low-resource non-Latin languages as an auxiliary\
  \ modality, injecting their meaning into a frozen decoder-only LLM via a small set\
  \ of soft slots aligned from a multilingual encoder. By bypassing tokenization fragmentation\
  \ and aligning at the decoder\u2019s hidden state, LLINK achieves a 4.3\xD7 improvement\
  \ in Khmer-to-English retrieval recall (R@1: 0.104 \u2192 0.450) and LLM-as-judge\
  \ preferences of 81.3% over the base model and 63.6% over direct fine-tuning."
---

# Languages are Modalities: Cross-Lingual Alignment via Encoder Injection

## Quick Facts
- arXiv ID: 2510.27254
- Source URL: https://arxiv.org/abs/2510.27254
- Reference count: 18
- Primary result: 4.3× improvement in Khmer-to-English retrieval recall (R@1: 0.104 → 0.450) with LLM-as-judge preferences of 81.3% over base model

## Executive Summary
LLINK treats low-resource non-Latin languages as an auxiliary modality, injecting their meaning into a frozen decoder-only LLM via a small set of soft slots aligned from a multilingual encoder. By bypassing tokenization fragmentation and aligning at the decoder's hidden state, LLINK achieves significant improvements in cross-lingual retrieval and generation quality. The approach shifts computational burden from decoder tokens to encoder projection and soft slots, yielding up to 3× fewer decoder tokens while maintaining semantic coherence, though with some loss in exact numeric or lexical fidelity.

## Method Summary
LLINK aligns cross-lingual representations by projecting encoder embeddings into a decoder's hidden state space at a reserved token position, then expanding to soft slots. The method consists of two stages: Stage A performs contrastive alignment between frozen XLM-R encoder outputs and decoder hidden states using symmetric InfoNCE loss; Stage B injects the projected representation as K=8 soft slots via LoRA adapters. The approach bypasses tokenizer fragmentation (Khmer inflates 6.5× vs English) by replacing fragmented token sequences with fixed-dimension semantic vectors, trained with usage-enforcement to prevent decoder ignoring of injected slots.

## Key Results
- 4.3× improvement in Khmer-to-English retrieval recall (R@1: 0.104 → 0.450)
- LLM-as-judge preferences of 81.3% over base model and 63.6% over direct fine-tuning
- Up to 3× reduction in decoder tokens while maintaining semantic coherence
- Computational shift from O(n²) decoder attention to fixed K-slot attention

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bypassing decoder tokenization via encoder-to-hidden-state alignment reduces cross-lingual retrieval errors by replacing fragmented token sequences with fixed-dimension semantic vectors.
- Mechanism: A frozen XLM-R encoder produces a sentence embedding zF ∈ R^768, which a lightweight MLP projects into the decoder's hidden space at a reserved token position. This replaces ~104 Khmer tokens with 8 soft slots, shifting computational burden from O(n²) decoder attention to a one-time encoder pass plus fixed K-slot attention.
- Core assumption: The multilingual encoder captures sentence-level semantics more robustly than the decoder's subword tokenizer can represent fragmented non-Latin scripts.
- Evidence anchors:
  - [abstract]: "bypassing tokenization fragmentation and aligning at the decoder's hidden state"
  - [Section 4.1]: "A frozen XLM-R encodes a Khmer sentence and we mask–mean pool the token states to a sentence vector zF ∈ R^768... As a result, final latent state at that position is the teacher target hE ∈ R^2048"
  - [Section 6.1]: "Stage A provides the primary improvement by bypassing tokenization inflation and directly aligning to the decoder's representation space, reducing false matches"

### Mechanism 2
- Claim: Aligning to a context-conditioned decoder hidden state (rather than static token embeddings) provides a task-aware target that improves cross-lingual coupling without modifying decoder weights.
- Mechanism: The alignment target hE is extracted at a reserved `<foreign_emb>` token appended after the English instruction. Since the decoder has already processed the instruction context, hE encodes task expectations and answer format, not just language-neutral semantics. The projector learns to map zF into this context-conditioned space via symmetric InfoNCE plus light regularizers.
- Core assumption: The decoder's hidden state at the reserved position carries task-relevant priors that help the projector learn decoder-compatible representations.
- Evidence anchors:
  - [abstract]: "align sentence embeddings from a frozen multilingual encoder to the decoder's latent embedding space at a reserved position via a lightweight contrastive projector"
  - [Section 4.1]: "This fixes (hE) to a known context position and makes the target prompt-dependent but decoder-stable"
  - [Section 7.1]: "Unlike static embedding mapping approaches, we align to hidden states at a reserved position after the decoder has processed the English context"

### Mechanism 3
- Claim: An explicit usage-enforcement objective prevents the decoder from ignoring injected slots, forcing genuine cross-lingual reliance.
- Mechanism: Every third training step, the model computes both L_SFT (with injected slots) and L_zero (slots replaced with base embeddings). The contrast term L_contrast = 0.05 × max(0, L_SFT - L_zero) penalizes cases where removing the foreign signal improves loss. This creates a gradient pressure toward slot utilization.
- Core assumption: The frozen decoder has strong English priors that will otherwise bypass foreign signals, preferring to paraphrase around unknown content.
- Evidence anchors:
  - [abstract]: "trained with minimal adapters so the frozen decoder consumes the signal"
  - [Section 4.2]: "Providing features alone does not guarantee usage, so we add a lightweight usage-contrast"
  - [Section 7.1]: "The usage-enforcement objective also reveals that even well-aligned representations can be ignored without explicit training pressure"

## Foundational Learning

- Concept: **Contrastive learning (InfoNCE)**
  - Why needed here: Stage A alignment uses symmetric InfoNCE to pull encoder projections and decoder hidden states together while pushing apart in-batch negatives. Without understanding contrastive objectives, the role of hard negative queues and symmetric loss formulation will be unclear.
  - Quick check question: Given a batch of 64 paired encoder-decoder representations, can you sketch the InfoNCE loss term for one positive pair against 63 in-batch negatives?

- Concept: **Soft prompt / continuous embeddings**
  - Why needed here: Stage B expands a single vector into K=8 soft slots that function as continuous prompt tokens. Understanding how soft prompts interface with frozen LLMs is prerequisite to grasping why minimal adapters (LoRA) are sufficient for slot consumption.
  - Quick check question: How does a soft prompt token differ from a learned embedding row in a standard vocabulary, and why can it be inserted without retraining the full model?

- Concept: **Tokenizer fragmentation in multilingual models**
  - Why needed here: The paper's core motivation is that Khmer text produces ~6.5× more tokens than English under BPE tokenizers trained on Latin-dominant corpora. This drives the encoder-bypass design.
  - Quick check question: Given a 100-character Khmer sentence tokenizing to 170 tokens and its English equivalent to 25 tokens, what is the approximate attention compute ratio (O(n²)) between the two?

## Architecture Onboarding

- Component map:
  - Frozen XLM-R encoder → mask-mean pool → zF (768-d) → Projector MLP (768→3072→2048) → pF (2048-d) → Slot expander (unit norm → LayerNorm → scale) → K=8 soft embeddings → LoRA adapters → decoder

- Critical path:
  1. Khmer input → XLM-R encoder → mask-mean pool → zF (768-d)
  2. zF → Projector MLP → pF (2048-d)
  3. pF → Slot expander → K=8 soft slots `<f0>`–`<f7>`
  4. Soft embeddings overwrite reserved token rows in input embedding matrix
  5. Decoder processes instruction + soft slots → English output
  6. Loss computation: SFT loss + usage contrast + auxiliaries

- Design tradeoffs:
  - **K=8 slots**: Compromise between capacity (more slots = denser content) and efficiency (more slots = more attention compute). Paper suggests adaptive K as future work.
  - **Stage A vs. joint training**: Two-stage separation isolates alignment quality (retrieval R@1) from generation quality. Joint training might optimize end-task but obscures diagnostic signal.
  - **Context-conditioned vs. static target**: Hidden-state target captures task context but requires instruction at train time; static embedding target would be instruction-agnostic but potentially weaker.

- Failure signatures:
  - **Numeric/lexical drift**: Units (MW→kW), quantities (25→10), exact terms ("games"→"instruments"). Root cause: semantic compression in encoder represents numbers on logarithmic scales where proximate values merge.
  - **Over-paraphrasing**: Model produces semantic gist rather than literal translation. Root cause: slot-based injection preserves meaning, not surface form.
  - **Slot ignored**: Model generates without foreign signal reliance. Diagnostic: L_zero ≤ L_SFT on heldout set indicates usage enforcement failed.
  - **Retrieval good but generation poor**: Stage A succeeded but Stage B undertrained. Check LoRA learning rates and usage-enforcement weight.

- First 3 experiments:
  1. **Alignment probe**: Train only Stage A on 100k parallel pairs. Evaluate retrieval R@1 on heldout 1k pairs. Target: ≥0.40 (paper reports 0.430). If below 0.20, check projector initialization and negative queue size.
  2. **Usage enforcement ablation**: Train Stage B with L_contrast weight = {0, 0.01, 0.05, 0.10}. Measure L_zero - L_SFT gap and generation quality. Target: positive gap (model relies on slots) without degradation in English-only tasks.
  3. **Slot capacity sweep**: Test K = {2, 4, 8, 16} on Q&A vs. translation tasks. Hypothesis: Q&A (meaning extraction) stable at K=4; translation (surface fidelity) may need K≥8 but still lose exact numbers.

## Open Questions the Paper Calls Out

- **Question 1**: Does LLINK's efficacy scale to larger decoder-only models (e.g., 7B, 13B)?
  - Basis in paper: [explicit] Section 7.3 states that scaling to larger decoders "requires investigation" and hypothesizes that stronger English priors in larger models might necessitate adjusted usage enforcement.
  - Why unresolved: Experiments were restricted to LLaMA-3.2-1B; it is unknown if frozen larger models exhibit stronger resistance to the injected foreign signals.
  - What evidence would resolve it: Retrieval (R@1) and preference scores evaluated on 7B and 13B decoder variants.

- **Question 2**: Can hybrid mechanisms effectively mitigate the "lossy semantic compression" that causes numeric fidelity errors?
  - Basis in paper: [explicit] Section 7.3 proposes "hybrid precision mechanisms" (copying, dedicated numeric slots) to address systematic failures where numbers are confused (e.g., "30 MW" vs "1.5 kW").
  - Why unresolved: The current fixed-slot approach compresses sequences into semantic vectors where numerically proximate values become indistinguishable.
  - What evidence would resolve it: Improved exact-match accuracy on a synthetic dataset of numeric/entity-heavy translation tasks.

- **Question 3**: Does the encoder injection method generalize to typologically diverse scripts (e.g., Arabic, Chinese)?
  - Basis in paper: [explicit] Section 7.3 notes that testing on "typologically diverse languages (Arabic RTL, Chinese logographic)" is necessary to validate generalization beyond Khmer.
  - Why unresolved: The current study focuses on Khmer; different scripts may interact differently with the multilingual encoder or alignment projector.
  - What evidence would resolve it: Successful alignment results (comparable R@1) and generation quality for Right-to-Left and logographic languages.

## Limitations
- Relies on synthetic instruction data generated by a strong LLM, with unknown fidelity to real low-resource language tasks
- Acknowledged but unquantified numerical and lexical precision loss in generated outputs
- Evaluation on single language pair (Khmer-English) with unknown generalization to other scripts
- Fixed K=8 slots may be suboptimal for different task types and languages

## Confidence
- **High Confidence**: Stage A contrastive alignment significantly improves cross-lingual retrieval (0.430 R@1 vs. 0.104 baseline)
- **Medium Confidence**: LLM-as-judge preference results (81.3% vs. base, 63.6% vs. fine-tuning) reflect genuine quality improvements
- **Medium Confidence**: Bypassing tokenization fragmentation is the primary driver of improvement
- **Low Confidence**: The method generalizes to languages beyond Khmer without modification

## Next Checks
1. **Synthetic Data Quality Audit**: Manually annotate 100 synthetic instruction examples to verify task representation and Khmer content fidelity, comparing to authentic low-resource datasets if available.

2. **Numerical Precision Evaluation**: Design a test suite of 200 examples containing numbers, units, and named entities to measure exact match accuracy for quantities, unit conversions, and named entity preservation.

3. **Cross-Lingual Generalization Test**: Apply LLINK to two additional low-resource, non-Latin script languages (e.g., Amharic, Burmese) using the same architecture and training procedure to evaluate retrieval R@1 and LLM-as-judge preferences.