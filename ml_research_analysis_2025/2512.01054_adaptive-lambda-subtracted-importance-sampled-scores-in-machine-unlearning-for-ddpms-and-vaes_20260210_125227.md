---
ver: rpa2
title: Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning
  for DDPMs and VAEs
arxiv_id: '2512.01054'
source_url: https://arxiv.org/abs/2512.01054
tags:
- unlearning
- siss
- forget
- forgetting
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Adaptive-lambda SISS, an enhancement to\
  \ the SISS framework for machine unlearning in generative models like DDPMs and\
  \ VAEs. The key limitation of SISS is its static mixing weight \u03BB, which is\
  \ suboptimal because different samples and training stages require varying unlearning\
  \ strengths."
---

# Adaptive-lambda Subtracted Importance Sampled Scores in Machine Unlearning for DDPMs and VAEs

## Quick Facts
- arXiv ID: 2512.01054
- Source URL: https://arxiv.org/abs/2512.01054
- Reference count: 40
- Key outcome: Introduces Adaptive-lambda SISS for machine unlearning in DDPMs and VAEs, treating the mixing weight λ as a learnable latent variable via variational inference to improve forget/retain trade-offs

## Executive Summary
This paper addresses a key limitation in SISS (Subtracted Importance Sampled Scores) for machine unlearning in diffusion models: the static, fixed mixing weight λ between retain and forget objectives. The authors propose treating λ as a latent variable and learning it dynamically using a variational inference framework. A lightweight inference network parameterizes a posterior over λ conditioned on context features derived from the instantaneous SISS loss terms. This enables sample- and stage-adaptive unlearning strength, substantially improving the balance between forgetting unwanted data and preserving generation quality on retained data.

## Method Summary
The method treats λ as a latent variable in a variational inference framework, learning its optimal value dynamically during training. A small neural network (inference network) parameterizes a posterior distribution q_φ(λ|v) conditioned on context features v derived from SISS loss components (retain/forget losses and gradient norms). The diffusion model and λ-inference mechanism are jointly optimized via an ELBO objective that combines the SISS loss with a KL regularization term. This approach enables sample- and stage-adaptive unlearning strength, improving the forget/retain trade-off. The work also extends this adaptive-λ principle to score-based unlearning and introduces a multi-class variant of Score Forgetting Distillation.

## Key Results
- Adaptive-lambda SISS substantially outperforms static-λ SISS on augmented MNIST benchmark
- Achieves stronger removal of forgotten classes while better preserving generation quality on retain set
- Introduces new directions: hybrid SISS+SFD objective and RL formulation treating unlearning as sequential decision process

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Treating λ as a latent variable enables sample- and stage-adaptive unlearning strength
- Mechanism: A lightweight inference network parameterizes q_φ(λ|v) conditioned on context features [L_retain, L_forget, ||∇L_retain||, ||∇L_forget||]. The ELBO objective L_ELBO = E[λ~q_φ][L_SISS(λ)] + β·D_KL(q_φ||p) jointly optimizes diffusion model θ and inference network φ via reparameterization trick.
- Core assumption: Context vector captures sufficient information about current unlearning state to predict optimal λ
- Evidence anchors: [abstract] defines adaptive posterior over λ; [Section 5.1.1] defines ELBO objective; [corpus] SISS framework established in related work
- Break condition: If context features become uninformative (e.g., losses plateau while model still contains forget-set information), inference network cannot differentiate states requiring different λ

### Mechanism 2
- Claim: Importance sampling correction enables unbiased gradient estimation from mixture distribution
- Mechanism: SISS samples noisy latents from mixture q_λ = (1-λ)q(m_t|x_r) + λq(m_t|x_f). Retain and forget losses include importance weights q(m_t|x)/q_λ(m_t|x_r,x_f) with dataset-size scaling factors |D|/|R| and |D|/|F|
- Core assumption: Mixture distribution adequately covers both retain and forget sample regions during reverse diffusion
- Evidence anchors: [Section 4.3] defines L_retain and L_forget with importance weight ratios; [Section 5.1.2] explains calculation simplicity
- Break condition: If λ approaches 0 or 1, mixture degenerates and importance weights explode, causing gradient instability

### Mechanism 3
- Claim: Framing unlearning as MDP with PPO enables learning policy optimizing long-term forget/retain trade-offs
- Mechanism: State S_t = [L_retain,t, L_forget,t, ||∇L_retain,t||, ||∇L_forget,t||, λ_{t-1}, t/T]. Action is λ_t ∈ [λ_min, λ_max]. Reward R_t = -L_SISS(λ_t) - α(λ_t - λ_{t-1})². PPO optimizes policy π_ψ(λ|S)
- Core assumption: Reward function's combination of negative SISS loss and smoothness penalty correctly encodes desired unlearning behavior
- Evidence anchors: [Section 5.3.1] defines MDP formulation; [Section 5.3.3] describes PPO implementation
- Break condition: If environment is non-stationary (θ changes irreversibly during training), policy may overfit to early states and fail to generalize

## Foundational Learning

- Concept: **ELBO and Variational Inference**
  - Why needed here: Adaptive-λ mechanism uses VAE-style ELBO to jointly learn diffusion model and λ-inference network
  - Quick check question: Can you explain why D_KL(q_φ||p) acts as a regularizer preventing posterior from collapsing to extreme λ values?

- Concept: **Denoising Diffusion Probabilistic Models (DDPMs)**
  - Why needed here: SISS operates on reverse diffusion process; understanding forward/reverse SDEs and score functions is essential
  - Quick check question: What does noise prediction ε_θ(m_t, t) represent, and why is it trained to predict added noise?

- Concept: **Reparameterization Trick**
  - Why needed here: Enables backpropagation through stochastic sampling of λ from q_φ(λ|v)
  - Quick check question: How does z = μ + ξ·σ with ξ~N(0,1) allow gradients to flow through random variable?

## Architecture Onboarding

- Component map:
  - Context features v = [L_retain, L_forget, ||∇L_retain||, ||∇L_forget||] -> Inference network φ -> (μ_φ, σ_φ) -> z via reparameterization -> λ = sigmoid(z) -> Mixture sampling q_λ(m_t|x_r, x_f) -> Weighted SISS loss -> ELBO combiner -> Updates to θ and φ

- Critical path:
  1. Sample x_r ~ R, x_f ~ F, t ~ P_T
  2. Compute base losses and gradient norms → construct context v
  3. Inference network outputs (μ_φ, σ_φ); sample λ via reparameterization
  4. Sample m_t from mixture q_λ(m_t|x_r, x_f)
  5. Compute weighted L_retain, L_forget with importance corrections
  6. Compute L_ELBO = L_SISS + β·D_KL
  7. Backprop to update both θ and φ

- Design tradeoffs:
  - Context feature richness vs. compute: Adding embeddings/activations to v may improve adaptivity but increases forward passes
  - KL weight β: Higher β regularizes toward prior (stable but potentially underfitting); lower β allows more extreme λ (riskier but potentially better forgetting)
  - RL vs. VI: RL optimizes long-term but requires many environment steps; VI is per-step efficient but myopic

- Failure signatures:
  - λ collapsing to 0 or 1: Check if KL weight β is too low or if context features are uninformative
  - Retain set degradation: Check if forget loss scaling (1+s) is too aggressive; reduce s
  - Importance weight explosion: Check if λ is near boundaries; constrain λ to [0.1, 0.9] as in RL variant

- First 3 experiments:
  1. **Baseline replication**: Implement Static-λ SISS with λ=0.5 on augmented MNIST; verify FID/KID metrics match paper's baseline before testing adaptive-λ
  2. **Ablation on context features**: Train adaptive-λ with only [L_retain, L_forget] vs. full context including gradient norms; compare convergence speed and final metrics
  3. **β sensitivity sweep**: Run adaptive-λ with β ∈ {0.001, 0.01, 0.1, 1.0}; plot λ trajectories and final forget/retain FID to identify stable operating range

## Open Questions the Paper Calls Out

- Would augmenting the context feature vector with semantic or representation-level features (e.g., embeddings, concept-specific activations) improve the adaptive-λ inference network's ability to determine optimal unlearning strength?
  - Basis in paper: [explicit] "Although this minimal set of features already yielded strong performance, an alternative extension would be to augment v with semantic or representation-level features... we leave this direction for future exploration."
  - Why unresolved: Current feature vector only uses loss values and gradient norms; richer semantic features might better capture sample-specific unlearning requirements
  - What evidence would resolve it: Ablation experiments comparing current features against augmented feature sets on diverse unlearning tasks, measuring FID/KID improvements

- How does Adaptive-λ SISS generalize to larger-scale datasets (CIFAR-10, ImageNet) and higher-capacity diffusion models beyond the augmented MNIST benchmark?
  - Basis in paper: [explicit] "Additional CIFAR-10 and ImageNet results will be included in the final paper."
  - Why unresolved: Current validation is limited to simple MNIST variant; scalability to complex distributions and larger models remains unverified
  - What evidence would resolve it: Benchmark results on CIFAR-10/ImageNet with standard diffusion architectures, comparing to static-λ baselines across forget/retain metrics

- Does the RL-based sequential decision formulation provide sufficient practical benefit over variational inference approach to justify added complexity and training cost?
  - Basis in paper: [inferred] Paper introduces RL as "new direction" but does not report comparative results against simpler adaptive-λ variational method
  - Why unresolved: RL formulation optimizes long-term trajectories but requires policy training; trade-offs remain unclear
  - What evidence would resolve it: Head-to-head comparison of final unlearning quality (FID, KID, SSIM) and wall-clock training time between RL and VI approaches

## Limitations
- MNIST-only evaluation on single contamination scenario provides limited evidence of robustness to diverse forgetting patterns or real-world data distributions
- Inference network architecture underspecified (depth, width, activations) with no sensitivity analyses for critical hyperparameters β and s
- RL extension lacks empirical validation beyond VI-based adaptive-λ results
- Importance sampling scheme stability at λ boundaries not thoroughly examined; no theoretical guarantees for variational approximation quality

## Confidence
- **High Confidence**: Core variational inference formulation and ELBO objective are mathematically sound and internally consistent
- **Medium Confidence**: Empirical results on augmented MNIST benchmark are well-executed, but narrow experimental scope limits generalizability
- **Low Confidence**: RL-based sequential λ selection lacks empirical validation; theoretical properties of adaptive posterior not explored

## Next Checks
1. **Multi-class Unlearning**: Evaluate Adaptive-lambda SISS on multi-class forgetting scenario (e.g., removing multiple digit classes simultaneously) to test scalability and robustness
2. **Hyperparameter Sensitivity**: Conduct systematic sweep of β (KL weight) and s (forget loss scaling) to identify stable operating regimes and quantify impact on forget/retain trade-offs
3. **Out-of-Distribution Generalization**: Test inference network's ability to generalize to unseen forgetting patterns by training on one contamination type and evaluating on another (e.g., train on MNIST digits, test on CIFAR-10 subset removal)