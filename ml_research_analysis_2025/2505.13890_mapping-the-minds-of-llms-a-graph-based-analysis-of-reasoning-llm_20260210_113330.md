---
ver: rpa2
title: 'Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM'
arxiv_id: '2505.13890'
source_url: https://arxiv.org/abs/2505.13890
tags:
- reasoning
- steps
- graph
- prompting
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a graph-based framework for analyzing the
  reasoning process of reasoning LLMs (RLMs). It converts verbose chain-of-thought
  (CoT) outputs into structured reasoning graphs, where nodes represent semantically
  coherent reasoning steps and edges capture logical dependencies.
---

# Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM

## Quick Facts
- arXiv ID: 2505.13890
- Source URL: https://arxiv.org/abs/2505.13890
- Reference count: 22
- Introduces graph-based framework to analyze reasoning LLM behavior through structured reasoning graphs

## Executive Summary
This paper presents a novel graph-based framework for analyzing the reasoning processes of reasoning large language models (RLMs). The approach transforms verbose chain-of-thought (CoT) outputs into structured reasoning graphs, where nodes represent semantically coherent reasoning steps and edges capture logical dependencies. By quantifying graph structure using metrics like exploration density, branching ratio, and convergence ratio, the study reveals that RLM performance strongly correlates with specific structural patterns - higher accuracy links to denser exploration and greater branching/convergence. The framework provides new insights beyond token-level analysis and offers practical guidance for prompt engineering.

## Method Summary
The framework converts CoT outputs into reasoning graphs through semantic node clustering and logical dependency detection. First, reasoning steps are extracted and clustered into semantically coherent nodes using OpenAI embeddings and hierarchical clustering. Edges are then identified between nodes to capture logical dependencies, creating a structured representation of the reasoning process. Quantitative analysis of these graphs employs metrics including exploration density (number of unique nodes per unit length), branching ratio (average number of child nodes per parent), and convergence ratio (frequency of nodes with multiple parents). The approach is validated on GSM8K dataset using DeepSeek-R1 and QwQ-32B models under different prompting strategies.

## Key Results
- RLM performance strongly correlates with graph structure: higher accuracy linked to denser exploration and greater branching/convergence
- Few-shot prompting significantly degrades performance by inducing more linear reasoning structures
- Graph metrics provide insights into RLM behavior beyond token-level analysis

## Why This Works (Mechanism)
The framework works by transforming unstructured reasoning traces into structured graphs that reveal the underlying reasoning architecture. By clustering semantically similar steps and mapping logical dependencies, it exposes patterns invisible in raw token sequences. The structural metrics capture how models explore solution spaces - dense exploration and multiple branches indicate robust reasoning, while linear structures suggest brittle, path-dependent thinking. This structural view enables quantitative correlation between reasoning patterns and performance outcomes.

## Foundational Learning
- **Semantic node clustering**: Grouping reasoning steps by meaning using embeddings
  - Why needed: Raw CoT outputs contain redundant or semantically similar steps
  - Quick check: Verify clusters contain steps addressing the same sub-problem

- **Graph metrics computation**: Calculating exploration density, branching, and convergence ratios
  - Why needed: Quantify structural properties that correlate with reasoning quality
  - Quick check: Ensure metrics vary meaningfully across different reasoning outputs

- **Dependency edge detection**: Identifying logical relationships between reasoning steps
  - Why needed: Capture the reasoning flow beyond simple sequence
  - Quick check: Edges should connect steps that directly influence each other

## Architecture Onboarding
**Component Map**: CoT output -> Step extraction -> Semantic clustering -> Edge detection -> Graph construction -> Metric calculation -> Performance correlation

**Critical Path**: The transformation pipeline from raw CoT to structured graph is essential - any failure in semantic clustering or edge detection breaks the entire analysis.

**Design Tradeoffs**: Semantic clustering using embeddings trades computational cost for accuracy; simpler clustering would be faster but less precise in capturing reasoning semantics.

**Failure Signatures**: Poor semantic clustering produces disconnected nodes; incorrect edge detection creates false dependencies; metric calculation errors yield meaningless correlations.

**First 3 Experiments**:
1. Run framework on simple arithmetic problems with known solution paths
2. Compare graph structures from correct vs. incorrect reasoning outputs
3. Test sensitivity of metrics to different clustering thresholds

## Open Questions the Paper Calls Out
None

## Limitations
- Framework relies on OpenAI embeddings which may not capture all reasoning nuances and could be sensitive to model updates
- Performance correlation analysis limited to single dataset (GSM8K) and two specific RLMs, limiting generalizability
- Focuses on English-language mathematical reasoning, with unknown applicability to other domains or languages

## Confidence
- **High Confidence**: Core methodology for converting CoT to reasoning graphs is sound and reproducible
- **Medium Confidence**: Observed correlations between graph structure and performance are robust within tested dataset but may not generalize
- **Medium Confidence**: Finding that few-shot prompting degrades performance through linear structures is supported but mechanism remains partially speculative

## Next Checks
1. Replicate graph structure-performance correlation analysis across diverse reasoning datasets (coding, commonsense reasoning, scientific domains)
2. Compare framework's node clustering and edge detection against human-annotated reasoning graphs on subset of problems
3. Test whether targeted graph structure interventions (prompt modifications to increase branching) produce measurable performance improvements as predicted