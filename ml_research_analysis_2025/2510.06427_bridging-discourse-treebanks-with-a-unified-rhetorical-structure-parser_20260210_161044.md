---
ver: rpa2
title: Bridging Discourse Treebanks with a Unified Rhetorical Structure Parser
arxiv_id: '2510.06427'
source_url: https://arxiv.org/abs/2510.06427
tags:
- treebanks
- parsing
- discourse
- relation
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces UniRST, the first unified end-to-end RST-style
  discourse parser capable of handling 18 treebanks across 11 languages without modifying
  their original relation inventories. To address inventory incompatibilities, the
  authors propose two training strategies: Multi-Head, which assigns separate relation
  classification layers per inventory, and Masked-Union, which enables shared parameter
  training through selective label masking.'
---

# Bridging Discourse Treebanks with a Unified Rhetorical Structure Parser

## Quick Facts
- arXiv ID: 2510.06427
- Source URL: https://arxiv.org/abs/2510.06427
- Reference count: 17
- Primary result: First unified end-to-end RST-style discourse parser handling 18 treebanks across 11 languages without modifying original relation inventories

## Executive Summary
This paper introduces UniRST, the first unified end-to-end RST-style discourse parser capable of handling 18 treebanks across 11 languages while preserving their original relation inventories. The authors propose two training strategies—Multi-Head (separate classifiers per inventory) and Masked-Union (shared classifier with treebank-specific binary masks)—to address inventory incompatibilities. They establish strong mono-treebank baselines using subtree extraction augmentation for low-resource settings, then demonstrate that UniRST outperforms 16 of 18 mono-treebank baselines while maintaining parameter efficiency through the Masked-Union approach.

## Method Summary
The approach uses a DMRST backbone with XLM-RoBERTa-large encoder, implementing two key strategies for handling heterogeneous treebank inventories. The Multi-Head approach assigns separate relation classification layers per treebank, while Masked-Union enables shared parameter training through selective label masking where invalid labels are zeroed out via large negative logits. Both approaches use treebank-specific LSTM-CRF segmentation heads to capture EDU boundary variations. Data augmentation involves extracting structurally coherent subtrees (≥3 rhetorical relations) from annotated documents at 50% sampling rate to boost low-resource treebank performance.

## Key Results
- UniRST achieves over 40% Full end-to-end F1 on nine corpora across six languages
- Masked-Union approach is both parameter-efficient and strongest, outperforming Multi-Head by 1.1 Full F1 points
- Model outperforms 16 of 18 mono-treebank baselines while preserving original relation inventories
- Treebank-specific segmentation heads are crucial, with 0.3 Full F1 improvement over shared segmentation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masked-Union enables parameter-efficient cross-treebank transfer for overlapping relations while preserving inventory-specific constraints.
- Mechanism: A single shared classifier predicts over a unified label space U (all relations across all treebanks). During training, a binary mask m(k) ∈ {−1×10⁹, 1}^|U| is applied to the logits for each treebank T_k, effectively zeroing out invalid labels while allowing gradient flow for shared relations (e.g., ELABORATION_NS appears across multiple inventories).
- Core assumption: Overlapping relation labels across treebanks encode semantically similar discourse functions that can share representations.
- Evidence anchors:
  - [abstract] "Masked-Union, which enables shared parameter training through selective label masking"
  - [section 3.3] "MU employs a single shared classifier W ∈ R^{d×|U|} that predicts over this unified label space. To enforce inventory constraints, for each treebank T_k, we apply a binary mask m(k)..."
  - [table 4] MU with multiple segmentation heads achieves 74.4 Span F1 vs 73.6 for Multi-Head

### Mechanism 2
- Claim: Treebank-specific segmentation heads are necessary because EDU boundary definitions vary annotation-to-annotation.
- Mechanism: The shared encoder outputs token representations, but each treebank maintains its own LSTM-CRF segmentation module trained only on that treebank's EDU boundaries. This isolates segmentation decisions from cross-treebank label noise while still benefiting from shared contextual representations.
- Core assumption: Segmentation errors cascade into downstream structure and relation prediction; EDU definitions are more treebank-specific than language-specific.
- Evidence anchors:
  - [section 1] "segmentation decisions can be influenced by fine-grained intra-sentential relations"
  - [section 6.2] "UniRST performs best when segmentation is handled by treebank-specific heads, which capture differences in EDU annotation schemes"
  - [table 4] Multiple segmentation heads: 64.8 Full F1 vs single head: 64.5 Full F1 (end-to-end)

### Mechanism 3
- Claim: Subtree extraction augments low-resource treebanks by increasing structural diversity without modifying local annotations.
- Mechanism: From each annotated document, extract all connected subtrees that (1) respect sentence boundaries, (2) contain ≥3 rhetorical relations. Sample 50% of these for training. This multiplies training instances 7.7× across treebanks while preserving valid discourse structure.
- Core assumption: Partial document structures retain learnable discourse patterns; sentence boundaries provide a safe truncation point.
- Evidence anchors:
  - [section 4.1] "For RST-DT, p_aug = 50% produces 5.4 times more training samples"
  - [table 2] eng.oll improves from 89.7→91.2 Seg F1, 51.4→54.1 Span F1 with augmentation
  - [table 2] spa.sctb improves from 74.1→84.1 Seg F1 with augmentation

## Foundational Learning

- Concept: **Rhetorical Structure Theory (RST) fundamentals**
  - Why needed here: UniRST outputs hierarchical trees with EDU nodes connected by nuclearity-marked relations. Without understanding that "ELABORATION_NS" means "Elaboration with Nucleus-Satellite structure," the label masking strategy is opaque.
  - Quick check question: Given a span relation labeled "CONTRAST_NN", what does the "_NN" suffix indicate about the connected EDUs?

- Concept: **Multi-task learning with task-specific heads**
  - Why needed here: The Multi-Head approach assigns separate classifiers per inventory; the Masked-Union approach uses one classifier with constraints. Understanding when to share vs. separate parameters is central to this work.
  - Quick check question: If two treebanks share 80% of their relation labels but differ in nuclearity conventions, which approach (MH or MU) would likely degrade less?

- Concept: **CRF-based sequence labeling**
  - Why needed here: EDU segmentation uses LSTM-CRF to predict boundary tags. The data augmentation strategy must avoid overfitting the segmenter, hence the 50% sampling rate.
  - Quick check question: Why might augmenting with all possible subtrees harm segmentation performance specifically?

## Architecture Onboarding

- Component map:
Input Text → XLM-RoBERTa-large (shared encoder)
         → [Per-treebank] LSTM-CRF Segmenter → EDU spans
         → Shared Recurrent Pointer Network → Tree structure
         → [MU] Shared Biaffine Classifier + Treebank mask → Relation+Nuclearity
         → [MH] Per-inventory Biaffine Classifiers → Relation+Nuclearity

- Critical path:
  1. Verify treebank ID is correctly passed through the batch (required for mask selection in MU)
  2. Check that mask values (−1×10⁹ for invalid, 1 for valid) are applied *before* softmax
  3. Ensure early stopping patience is reduced (3 vs 5) for unified training due to larger combined dataset

- Design tradeoffs:
  - MU vs MH: MU is parameter-efficient (single classifier) and enables explicit transfer on overlapping labels, but assumes label semantics align. MH isolates inventories completely but limits cross-treebank signal to encoder fine-tuning only.
  - Shared vs treebank-specific segmentation: Shared reduces parameters but conflates EDU definitions; treebank-specific adds N segmentation modules (N = number of treebanks) but respects annotation boundaries.

- Failure signatures:
  - If relation F1 drops significantly but span F1 holds: likely mask misapplication or label space construction error
  - If segmentation F1 varies wildly across treebanks in unified model: check that treebank-specific heads are actually being selected per batch
  - If unified model underperforms mono-treebank on large corpora (eng.gum, rus.rrg): expected per paper—these have sufficient data; consider treebank weighting

- First 3 experiments:
  1. **Reproduce Table 2 mono-treebank baseline** for 2-3 treebanks (e.g., eng.rstdt, deu.pcc, spa.sctb) with and without augmentation to validate augmentation benefit magnitude.
  2. **Ablate segmentation head strategy**: Train UniRST-MU with shared vs treebank-specific segmentation on a subset of 5 treebanks; expect ~0.3 Full F1 delta per Table 4.
  3. **Probe label overlap transfer**: Identify a relation appearing in ≥3 treebanks (e.g., ELABORATION_NS). Train MU on treebanks including/excluding one; measure performance delta on held-out treebank for that specific relation class.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can automated treebank filtering or weighted loss strategies effectively mitigate the negative impact of low-quality annotations (e.g., in eng.sts) on unified model performance?
- Basis in paper: [explicit] The authors note that data quality substantially affects performance and suggest that "future work may benefit from treebank filtering or weighting."
- Why unresolved: The current work treats all treebanks uniformly during training, potentially allowing noise from inconsistent corpora to degrade the model.
- What evidence would resolve it: Experiments comparing the current UniRST model against versions trained with quality-based dataset sampling or noise-robust loss functions.

### Open Question 2
- Question: How can downstream applications effectively utilize the heterogeneous relation inventories preserved by the unified parser without requiring manual harmonization?
- Basis in paper: [explicit] The "Limitations" section identifies the need to account for inventory differences in downstream applications as the main limitation of the approach.
- Why unresolved: While the parser successfully maintains distinct label sets (e.g., via Masked-Union), no method is proposed for unifying these outputs for end-tasks like summarization.
- What evidence would resolve it: Development and evaluation of a downstream task framework that can ingest and process the diverse native relation labels produced by UniRST.

### Open Question 3
- Question: Can the unified training paradigm be adapted to significantly improve generalization to out-of-domain genres compared to high-resource mono-treebank models?
- Basis in paper: [inferred] Section 6.2 notes that training on multiple multi-domain treebanks "did not lead to a substantial improvement in out-of-domain performance" on the GENTLE benchmark compared to the eng.gum baseline.
- Why unresolved: The authors hypothesize that treebank-specific annotation schemes limit cross-domain transfer, but it is unclear if different training objectives could overcome this.
- What evidence would resolve it: Ablation studies showing improved transfer learning metrics on unseen genres when using specific regularization or domain-adversarial training techniques within the UniRST framework.

## Limitations

- The effectiveness of Masked-Union depends on semantic consistency across treebanks for overlapping relation labels, which is not empirically validated
- Data augmentation strategy may degrade performance on large documents with complex cross-sentence dependencies
- The 50% augmentation sampling rate appears arbitrary and may not be optimal across all treebanks
- Performance on high-resource mono-treebank baselines remains competitive, suggesting limited benefits of unification for well-resourced languages

## Confidence

**High Confidence**: The claim that UniRST outperforms 16 of 18 mono-treebank baselines is well-supported by the experimental results in Table 5. The observation that Masked-Union is both parameter-efficient and strongest is directly validated through controlled experiments comparing the two training strategies.

**Medium Confidence**: The mechanism claim that treebank-specific segmentation heads are necessary due to EDU boundary definition variations is supported by performance differences (64.8 vs 64.5 Full F1) but could benefit from deeper error analysis showing specific segmentation failures when using shared heads.

**Low Confidence**: The core assumption underlying Masked-Union—that overlapping relation labels across treebanks encode semantically similar discourse functions—is plausible but not directly tested. The paper shows this approach works empirically but doesn't validate whether shared representations actually capture the same discourse semantics across inventories.

## Next Checks

1. **Semantic Alignment Validation**: For relations appearing in multiple treebanks (e.g., ELABORATION_NS), conduct a qualitative analysis comparing how these relations are annotated across treebanks. Sample 50 instances from each treebank and have linguists rate semantic consistency. This would directly test the Masked-Union assumption.

2. **Hyperparameter Sensitivity Analysis**: Re-run the data augmentation experiments varying p_aug from 25% to 75% on a subset of 3-4 treebanks. Measure segmentation and Full F1 performance to determine if 50% is optimal or if the benefit varies significantly with sampling rate.

3. **Cross-Treebank Transfer Probe**: Using the trained UniRST model, extract the representation layer for a specific relation class (e.g., CONTRAST_NN) from documents across different treebanks. Compute similarity metrics (e.g., cosine similarity, Procrustes distance) between these representations to empirically validate whether shared parameters encode similar discourse functions.