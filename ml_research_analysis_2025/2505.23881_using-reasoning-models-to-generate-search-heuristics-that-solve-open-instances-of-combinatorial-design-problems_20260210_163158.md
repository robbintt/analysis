---
ver: rpa2
title: Using Reasoning Models to Generate Search Heuristics that Solve Open Instances
  of Combinatorial Design Problems
arxiv_id: '2505.23881'
source_url: https://arxiv.org/abs/2505.23881
tags:
- each
- instances
- combinatorial
- open
- cpro1
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that reasoning Large Language Models (LLMs)
  can be used to generate search heuristics that solve long-standing open instances
  in combinatorial design problems. The Constructive Protocol CPro1 guides LLMs to
  generate and optimize C code implementing search strategies such as simulated annealing,
  genetic algorithms, tabu search, and depth-first search.
---

# Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems

## Quick Facts
- arXiv ID: 2505.23881
- Source URL: https://arxiv.org/abs/2505.23881
- Authors: Christopher D. Rosin
- Reference count: 40
- Key outcome: Reasoning LLMs solve 7 of 16 open combinatorial design problems

## Executive Summary
This paper demonstrates that reasoning Large Language Models (LLMs) can be used to generate effective search heuristics for solving open instances of combinatorial design problems. The Constructive Protocol CPro1 automates the generation of C code implementing various search strategies including simulated annealing, genetic algorithms, tabu search, and depth-first search. Starting from textual problem definitions and validity verifiers, CPro1 handles hyperparameter tuning and execution feedback. Using o3-mini-high, the approach successfully solves 7 open instances from the 2006 Handbook of Combinatorial Designs, including 3 problems not solved by previous non-reasoning LLM approaches.

## Method Summary
The Constructive Protocol CPro1 is a framework that guides reasoning LLMs to generate and optimize C code implementing search heuristics for combinatorial design problems. The protocol begins with a textual definition and validity verifier for a problem, then automates the generation of search strategies, hyperparameter tuning, and execution feedback. The approach supports multiple search algorithms including simulated annealing, genetic algorithms, tabu search, and depth-first search. The reasoning model iteratively refines the generated code based on execution results, gradually improving solution quality through automated computational experimentation.

## Key Results
- CPro1 solves open instances for 7 of 16 combinatorial design problems from the 2006 Handbook of Combinatorial Designs
- Successfully solves 3 instances (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary Designs) not solved by earlier non-reasoning LLM approaches
- Solves open instances for 3 of 4 problems from recent (Feb. 2025) literature
- Improves state-of-the-art Deletion Codes found by an April 2025 FunSearch study

## Why This Works (Mechanism)
The approach works because reasoning LLMs can engage in iterative refinement of search heuristics through automated computational experimentation. The CPro1 protocol provides a structured framework that guides the model through systematic code generation, execution, and improvement cycles. By starting with formal problem definitions and validity checkers, the system ensures that generated solutions are correct by construction. The reasoning capability allows the model to analyze execution failures and adjust strategies accordingly, while the automated hyperparameter tuning removes the need for manual parameter selection. This combination of structured guidance, automated refinement, and formal correctness checking enables the discovery of effective search heuristics for problems that have resisted previous computational approaches.

## Foundational Learning

**Combinatorial Design Theory**: A branch of combinatorics dealing with arrangements of elements satisfying specific properties. Understanding this field is crucial because the problems being solved are drawn from this domain, and the validity verifiers rely on the mathematical properties of these designs.

*Why needed*: Provides the mathematical foundation for problem formulation and solution validation.
*Quick check*: Can identify basic combinatorial designs (Latin squares, block designs) and their defining properties.

**Search Heuristics**: Meta-algorithms that guide the search for solutions in large combinatorial spaces. Knowledge of these techniques is essential for understanding the generated C code and evaluating the effectiveness of different strategies.

*Why needed*: Enables comprehension of the various search strategies (simulated annealing, genetic algorithms, etc.) that the LLM generates and optimizes.
*Quick check*: Can explain the basic principles of at least three search heuristics and their trade-offs.

**Automated Computational Experimentation**: The systematic approach of generating, executing, and refining code through automated feedback loops. This concept underlies the CPro1 protocol's methodology for discovering effective search strategies.

*Why needed*: Understanding this paradigm is crucial for grasping how the LLM iteratively improves its solutions through repeated experimentation.
*Quick check*: Can describe the basic cycle of generate-execute-evaluate-refine in an automated system.

## Architecture Onboarding

**Component Map**: Problem Definition -> CPro1 Protocol -> Reasoning LLM (o3-mini-high) -> C Code Generator -> Search Heuristic Implementation -> Execution Engine -> Solution Validator -> Feedback Loop -> LLM Refinement

**Critical Path**: The core execution path follows Problem Definition → CPro1 Protocol → Reasoning LLM → C Code Generation → Execution → Solution Validation → Feedback to LLM. This cycle iterates until a valid solution is found or a timeout occurs.

**Design Tradeoffs**: The approach trades manual heuristic design expertise for automated computational experimentation. While this eliminates the need for deep domain-specific knowledge in search algorithm design, it requires significant computational resources and relies heavily on the reasoning capabilities of the LLM. The choice of C as the implementation language provides performance benefits but may limit the complexity of search strategies that can be easily expressed.

**Failure Signatures**: Common failure modes include the LLM generating syntactically incorrect C code, producing search heuristics that get stuck in local optima, or exhausting computational resources without finding a solution. The feedback mechanism should detect these failures and trigger appropriate refinements.

**First 3 Experiments**:
1. Run CPro1 on a simple combinatorial design problem (e.g., Latin square of small order) to verify the basic protocol functionality and code generation pipeline.
2. Test the feedback mechanism by intentionally providing an invalid initial search strategy and observing whether the LLM correctly identifies and fixes the issue.
3. Benchmark the performance of CPro1 on a known solvable instance to establish baseline execution times and resource requirements.

## Open Questions the Paper Calls Out
None

## Limitations
- Narrow focus on 16 combinatorial design problems limits generalizability to broader problem classes
- Heavy reliance on a single reasoning model (o3-mini-high) raises questions about reproducibility with different models
- No detailed analysis of computational resources required or scalability for larger problem instances
- Limited comparison with non-reasoning LLM approaches (only one prior study cited)

## Confidence

**High Confidence**: The core claim that CPro1 successfully solves 7 of 16 open combinatorial design problems using reasoning LLMs is well-supported by the experimental results presented.

**Medium Confidence**: The assertion that reasoning models outperform non-reasoning approaches on these problems is plausible but requires broader comparative studies across different model types and problem sets.

**Medium Confidence**: The claim that this approach addresses problems that have received limited computational attention is reasonable given the specific problems chosen, though the selection criteria could be more rigorously justified.

## Next Checks

1. **Replicate with alternative reasoning models**: Test CPro1 with other reasoning LLMs (o1, DeepSeek-R1, etc.) to verify that results are not model-specific and to establish robustness across different reasoning capabilities.

2. **Broaden problem scope**: Apply the approach to a more diverse set of combinatorial optimization problems beyond design theory to assess generalizability and identify potential limitations in different domains.

3. **Resource efficiency analysis**: Conduct detailed benchmarking of computational resources (CPU/GPU time, memory usage) required by CPro1 across different problem types and compare with traditional optimization approaches to evaluate practical viability.