---
ver: rpa2
title: 'GEP: A GCG-Based method for extracting personally identifiable information
  from chatbots built on small language models'
arxiv_id: '2509.21192'
source_url: https://arxiv.org/abs/2509.21192
tags:
- data
- leakage
- language
- arxiv
- template-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates privacy leakage of small language models
  (SLMs) in chatbot downstream tasks. It develops ChatBioGPT, an SLM-based medical
  chatbot, and proposes GEP, a gradient-based method for extracting personally identifiable
  information (PII).
---

# GEP: A GCG-Based method for extracting personally identifiable information from chatbots built on small language models

## Quick Facts
- arXiv ID: 2509.21192
- Source URL: https://arxiv.org/abs/2509.21192
- Reference count: 15
- Primary result: GEP increases PII leakage detection by up to 60× compared to template-based methods

## Executive Summary
This study investigates privacy leakage in small language models (SLMs) when deployed as chatbots for medical applications. The authors develop ChatBioGPT, an SLM-based medical chatbot, and propose GEP (Greedy Coordinate Gradient-based method), a gradient-based approach for extracting personally identifiable information (PII). Results demonstrate that GEP significantly outperforms traditional template-based extraction methods, revealing substantial PII leakage even with varied insertion formats. The work provides insights into factors affecting leakage and suggests potential defense strategies for SLM-based chatbots.

## Method Summary
The study introduces GEP, a gradient-based optimization method for extracting PII from SLMs. The approach works by iteratively optimizing trigger tokens to maximize the likelihood of generating sensitive information. For template-based PII insertion, GEP uses entry-specific triggers, while for free-style insertion it employs a unified trigger approach trained on partial data. The method assumes correlation between prefix strings and target PII, using gradient descent to discover optimal trigger sequences. ChatBioGPT is created by fine-tuning BioGPT (347M parameters) on Alpaca followed by HealthCareMagic-100k with synthetically inserted PII pairs.

## Key Results
- GEP increases PII leakage detection by up to 60× compared to template-based methods
- Reveals up to 4.53% PII leakage even with free-style PII insertion using unified triggers
- Most successful extractions occur within the first 170 generated tokens and early optimization steps
- Optimal trigger length is approximately 4 tokens for template-based extraction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient-based trigger optimization recovers PII more effectively than template-based queries
- Mechanism: GEP iteratively optimizes trigger tokens by computing gradients with respect to one-hot encodings, selecting top-k candidate tokens that minimize loss for P(s|q,T). Since disease d co-occurs with prefix string s in training data, maximizing P(s|q,T) indirectly increases P(d|q,T), causing the model to generate sensitive disease information
- Core assumption: Prefix string s and disease d share correlated generation probabilities
- Evidence: 60× increase in leakage compared to template-based methods
- Break condition: If s and d are decorrelated in training data, the indirect optimization pathway degrades

### Mechanism 2
- Claim: Unified trigger tokens trained on partial PII data generalize to unseen PII in free-style insertion scenarios
- Mechanism: GEP-unified aggregates gradients across a training subset to learn a single trigger string T that minimizes total loss, then applies this T to held-out validation entries
- Core assumption: A shared trigger pattern exists that can activate disease-generation pathways across multiple patient-disease pairs
- Evidence: 4.53% ASR for free-style insertion with unified triggers
- Break condition: If PII entries have highly divergent syntactic structures, unified triggers fail to transfer

### Mechanism 3
- Claim: PII leakage concentrates early in both optimization steps and token generation positions
- Mechanism: Attack Success Rate peaks in early gradient-descent iterations (before step 40-100) and successful extractions predominantly occur within first 170 generated tokens
- Core assumption: Memorized PII resides in easily-activated regions of the model's probability space
- Evidence: Leakage shrinks with optimization steps and most successful attacks happen before 170th token
- Break condition: If PII is deeply embedded in long-range dependencies, early-generation extraction fails

## Foundational Learning

- Concept: Greedy Coordinate Gradient (GCG)
  - Why needed: GEP builds directly on GCG for adversarial trigger generation; understanding gradient-based token replacement is essential
  - Quick check: Given a loss function L over token embeddings, how would you select candidate tokens for replacement at position n?

- Concept: Memorization vs. Generalization in Language Models
  - Why needed: The study assumes models memorize PII from training data; distinguishing memorization from generalization is critical for interpreting ASR results
  - Quick check: If a model outputs a patient's disease without that exact patient-disease pair in training data, is this memorization or generalization?

- Concept: Attack Success Rate (ASR) as Privacy Metric
  - Why needed: ASR quantifies PII leakage; understanding its computation and limitations is necessary for valid experimental comparisons
  - Quick check: What are two scenarios where ASR could increase without actual privacy risk worsening?

## Architecture Onboarding

- Component map: BioGPT (347M) -> ChatBioGPT (fine-tuned) -> GEP optimizer -> PII extraction
- Critical path:
  1. Fine-tune BioGPT on Alpaca → HealthCareMagic-100k with PII-inserted entries
  2. Initialize trigger tokens T (length 1-16) for each patient name
  3. Compute gradients ∇eT L(q,T), select top-k candidates per position
  4. Generate batch of candidate trigger variations, select lowest-loss variant
  5. Query model with name + updated triggers; check if disease appears in output
  6. Iterate until success or step limit (140 for template-based, 100 for unified)

- Design tradeoffs:
  - Trigger length vs. search complexity: Optimal ~4 for template-based, longer for unified
  - Entry-specific vs. unified triggers: Entry-specific achieves higher ASR (9.07% vs. 4.53%) but requires per-entry optimization
  - Decoding strategy: Beam search performs best for free-style (4.53% ASR); top-k best for template-based (9.07% ASR)

- Failure signatures:
  - ASR near 0%: Template-based query fails on SLM chatbots due to system prompt interference
  - ASR plateaus early: Insufficient trigger length or excessive training steps
  - Unified trigger fails to transfer: Training subset lacks syntactic diversity

- First 3 experiments:
  1. Reproduce baseline ASR for ChatBioGPT using template-based query to verify ~0.1% ASR, then apply GEP to confirm ~6% ASR improvement
  2. Vary trigger token length (1, 2, 4, 8, 12, 16) with greedy decoding on template-based insertion to identify optimal length
  3. Implement GEP-unified on free-style insertion with 500 training / 500 validation split; compare beam search vs. top-k decoding ASR

## Open Questions the Paper Calls Out

1. How do standard defense mechanisms, such as perplexity filtering, impact the efficacy of GEP-based PII extraction? The authors note that triggers are easily recognized by safeguards and suggest exploring performance with defense methodology implementation.

2. Does the GEP extraction method generalize to diverse PII categories (e.g., addresses, phone numbers) and different SLM architectures? The study limits scope to (name, symptom) pairs within medical domain using 347M parameter BioGPT model.

3. To what extent does data imbalance in the training dataset inflate the Attack Success Rate of gradient-based extraction? The authors note that data imbalance may cause frequent terms like 'abdominal pain' to enlarge memorization tendency.

## Limitations

- Trigger-token length selection remains unclear; the paper reports optimal lengths but doesn't provide systematic analysis of how these were determined
- Dataset representativeness concerns; the 1,000 synthetic PII pairs may not reflect real-world medical chatbot usage patterns
- Attack success metrics lack false-positive analysis; ASR is reported without quantifying false positives or distinguishing memorization from general medical knowledge retrieval

## Confidence

**High confidence**: The gradient-based optimization mechanism works as described, with observed ASR improvements of 60× over baseline methods. The early-generation extraction pattern (within 170 tokens) is reproducible and aligns with memorization literature.

**Medium confidence**: The correlation assumption between prefix string "disease or symptom" and actual disease generation is plausible but not rigorously validated. The unified trigger approach shows promise but transferability limitations suggest context dependence.

**Low confidence**: Claims about ChatBioGPT's practical utility are questionable given the severe performance degradation (ASR < 1%) when system prompts interfere with template-based queries.

## Next Checks

1. Validate correlation assumption: Design experiments that systematically vary the presence/absence of the "disease or symptom" prefix string in training data to test whether the gradient optimization pathway actually depends on this correlation.

2. Test transferability limits: Apply GEP-unified to a validation set with explicitly different syntactic structures from the training subset to quantify the approach's generalization boundaries.

3. Compare with memorization baselines: Implement the cue-controlled memorization framework from related work to determine whether GEP's extracted PII represents true memorization versus retrieval of common medical knowledge patterns.