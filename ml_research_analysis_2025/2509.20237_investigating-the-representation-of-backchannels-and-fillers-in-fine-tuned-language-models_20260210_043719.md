---
ver: rpa2
title: Investigating the Representation of Backchannels and Fillers in Fine-tuned
  Language Models
arxiv_id: '2509.20237'
source_url: https://arxiv.org/abs/2509.20237
tags:
- fillers
- backchannels
- fine-tuning
- language
- after
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper examines how transformer-based language models learn\
  \ representations of backchannels and fillers\u2014linguistic elements crucial for\
  \ managing conversational flow but typically underrepresented in NLP datasets. The\
  \ authors propose fine-tuning three types of models (BERT, GPT-2, and larger multilingual\
  \ models like LLaMA-3 and Qwen-3) using three strategies: masking, next-token prediction,\
  \ and turn-taking prediction on English and Japanese dialogue corpora where these\
  \ elements are preserved and annotated."
---

# Investigating the Representation of Backchannels and Fillers in Fine-tuned Language Models

## Quick Facts
- arXiv ID: 2509.20237
- Source URL: https://arxiv.org/abs/2509.20237
- Reference count: 29
- Primary result: Fine-tuning improves LM representations of backchannels/fillers as measured by clustering quality and natural language generation

## Executive Summary
This paper examines how transformer-based language models learn representations of backchannels and fillersâ€”linguistic elements crucial for managing conversational flow but typically underrepresented in NLP datasets. The authors propose fine-tuning three types of models (BERT, GPT-2, and larger multilingual models like LLaMA-3 and Qwen-3) using three strategies: masking, next-token prediction, and turn-taking prediction on English and Japanese dialogue corpora where these elements are preserved and annotated. Clustering analysis reveals that fine-tuning significantly increases silhouette scores, indicating better semantic distinction between different backchannels and fillers.

## Method Summary
The authors fine-tune language models on dialogue corpora with preserved backchannels and fillers using three strategies: masking (BERT), next-token prediction (GPT-2, LLaMA-3, Qwen-3), and turn-taking prediction (TurnGPT framework). They analyze representations using silhouette scores from k-means clustering and evaluate generated dialogue quality through frequency, diversity, perplexity, BERTScore, and BLEUScore metrics. The study uses Switchboard and MapTask for English and BTSJ1000 for Japanese, focusing on the top 15 most frequent backchannels and fillers in each language.

## Key Results
- Fine-tuning increases silhouette scores in k-means clustering, indicating better semantic distinction between backchannels and fillers
- Next-token prediction fine-tuning yields marginally better representations than turn-taking prediction
- Increased context during embedding extraction shows a decreasing trend in silhouette scores, suggesting potential "dilution" effects
- Fine-tuned models generate dialogues with more natural backchannel and filler usage compared to pre-trained models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning dialogue-focused objectives improves LM representation of backchannels/fillers by enabling context-conditioned semantic differentiation.
- Mechanism: Pre-trained LMs treat backchannels/fillers as under-represented tokens with near-random embeddings. Fine-tuning on dialogue corpora where these elements are preserved and annotated forces the model to assign distinct embeddings conditioned on surrounding discourse, as measured by increased silhouette scores in k-means clustering.
- Core assumption: The observed clustering improvement reflects meaningful semantic/pragmatic differentiation rather than overfitting to corpus-specific patterns.
- Evidence anchors: [abstract] "increased silhouette scores in representations from fine-tuned models"; [section 4] "general tendency we can observe is that with different fine-tuning strategies, the average silhouette score increases"

### Mechanism 2
- Claim: Contextual information during embedding extraction exhibits a "dilution" effect where more context compresses backchannel/filler representations into narrower semantic regions.
- Mechanism: When extracting embeddings, adding surrounding utterances encodes content-word information into backchannel/filler vectors, which averages their representations toward functional-word baselines. This reduces cluster separability despite fine-tuning gains.
- Core assumption: The decreasing silhouette trend with increased context reflects semantic compression, not noise from longer sequences.
- Evidence anchors: [section 5] "When context information is added, LMs tend to treat backchannels/fillers as functional words, whose representations would be compressed into more limited regions of the semantic space"

### Mechanism 3
- Claim: Next-token prediction (NTP) fine-tuning yields marginally better backchannel/filler representations than turn-taking prediction (TTP), despite TTP's apparent task relevance.
- Mechanism: NTP directly optimizes token-level predictions including backchannels/fillers, whereas TTP optimizes turn-boundary probability distributions. The token-level objective may provide denser gradient signals for individual discourse marker embeddings.
- Core assumption: The silhouette score difference reflects representation quality rather than TTP's different optimization target.
- Evidence anchors: [section 5] "both strategies help the LM learn backchannels/fillers, with no significant differences between the strategies. However, the embeddings learnt by NTP produce slightly larger silhouette scores"

## Foundational Learning

- Concept: Backchannels vs. Fillers
  - Why needed here: These are distinct conversational phenomena with different pragmatic functions; backchannels (e.g., "uh-huh") provide feedback, fillers (e.g., "um") signal disfluency/turn-holding.
  - Quick check question: In the dialogue "A: Ready? B: Um, sure. A: Okay.", which token is a backchannel and which is a filler?

- Concept: Silhouette Score for Clustering Quality
  - Why needed here: This metric quantifies how well-separated embedding clusters are, serving as the primary evidence for representation improvement.
  - Quick check question: If silhouette score increases from 0.18 to 0.35 after fine-tuning, what does this imply about the embedding space?

- Concept: Masked Language Modeling vs. Autoregressive Objectives
  - Why needed here: The paper uses MASK (BERT), NTP (GPT-2/LLAMA), and TTP (TurnGPT) as different fine-tuning strategies with different inductive biases.
  - Quick check question: Why would masking backchannels force the model to learn their contextual dependencies differently than predicting them autoregressively?

## Architecture Onboarding

- Component map:
  Dialogue corpora (Switchboard, MapTask, BTSJ) -> utterance merging with speaker IDs (<s1>, <s2>) -> tokenization with backchannel/filler special tokens -> three fine-tuning objectives (MASK, NTP, TTP) -> embedding extraction from last hidden layer -> PCA to 100 dimensions -> k-means clustering (k=2-15) -> silhouette score evaluation + NLG metrics

- Critical path:
  1. Data preprocessing with proper backchannel/filler annotation preservation
  2. Fine-tuning with LoRA for 8B models (rank=16, dropout=0.1 on q_proj/v_proj)
  3. Embedding extraction under three context settings (no/one/full context)
  4. Clustering analysis with silhouette optimization

- Design tradeoffs:
  - Model size vs. interpretability: LLaMA-3 8B shows best silhouette scores but requires LoRA; smaller BERT offers comparable results with full parameter updates
  - Context window vs. representation clarity: Full context enables richer semantics but dilutes cluster boundaries
  - Task alignment vs. generality: TTP aligns with turn-management but NTP provides broader token-level learning

- Failure signatures:
  - Silhouette scores remain flat or decrease after fine-tuning -> check data preprocessing (backchannels may have been stripped)
  - Generated dialogue lacks backchannels despite fine-tuning -> verify special token handling in tokenizer
  - High perplexity on backchannel tokens -> model may not have incorporated them into vocabulary properly

- First 3 experiments:
  1. Baseline validation: Extract embeddings from pre-trained LLaMA-3 on 15 frequent English backchannels, compute silhouette scores with no context; expect low cluster separability
  2. Ablation on context setting: Fine-tune LLaMA-3 with NTP, extract embeddings under no/one/full context; expect decreasing silhouette with more context
  3. Cross-lingual transfer check: Apply English-fine-tuned model to Japanese backchannels without retraining; if silhouette remains low, representations are language-specific rather than learning general discourse-marker mechanisms

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does increasing context length "dilute" the representation of backchannels/fillers by merging them with surrounding content words?
- Basis in paper: [inferred] The authors observed decreasing silhouette scores with increased context and hypothesized that LMs treat these tokens as functional words compressed by surrounding content, but did not verify this mechanism.
- Why unresolved: The study only reports the silhouette score drop; it does not isolate the semantic blending or compression of vectors in the latent space.
- What evidence would resolve it: An analysis of cosine similarity between backchannel embeddings and their adjacent content words as context windows expand.

### Open Question 2
- Question: How are the paralinguistic features (pitch, voice quality, emotion) of backchannels/fillers represented in speech models compared to text-based LMs?
- Basis in paper: [explicit] The paper explicitly identifies the gap between language and speech models, noting that "How vocal signals of backchannels/fillers are represented in speech models is a future study."
- Why unresolved: The current experiments rely solely on transcribed text and transformer-based LMs, excluding acoustic data.
- What evidence would resolve it: Applying similar clustering and silhouette analysis to embeddings from speech models like HuBERT or Whisper using annotated audio data.

### Open Question 3
- Question: Do different hidden layers of transformer models capture distinct pragmatic functions of backchannels/fillers better than the final layer?
- Basis in paper: [explicit] The authors restricted their analysis to the last hidden layer and state, "a further step will be analysing the representation of backchannels/fillers in different hidden layers."
- Why unresolved: The methodology focused exclusively on the final layer to limit complexity.
- What evidence would resolve it: Extracting embeddings from intermediate layers (e.g., layers 6-11 in BERT/GPT-2) and comparing their clustering performance against the final layer.

## Limitations

- The paper relies on silhouette scores as the primary metric for representation quality, but doesn't validate whether these improvements translate to functional conversational competence through downstream tasks
- The "dilution" hypothesis for context effects is proposed but not directly tested, leaving alternative explanations for decreasing silhouette scores plausible
- The evaluation depends on detecting pre-specified backchannels/fillers in generated text, which may miss novel variants and lacks precision/recall reporting

## Confidence

**High confidence**: The experimental finding that fine-tuning increases silhouette scores for backchannel/filler embeddings.

**Medium confidence**: The claim that next-token prediction produces marginally better representations than turn-taking prediction.

**Low confidence**: The assertion that increased context "dilutes" backchannel representations toward functional-word baselines.

## Next Checks

1. **Downstream task validation**: Implement a backchannel prediction task where models must choose appropriate backchannels given dialogue context. Compare pre-trained vs. fine-tuned models' accuracy to determine whether silhouette improvements correlate with functional conversational competence.

2. **Context aggregation ablation**: Test alternative methods for incorporating context (e.g., attention-based pooling, hierarchical representations) to isolate whether the decreasing silhouette trend results from semantic compression or suboptimal context aggregation.

3. **Cross-lingual zero-shot transfer**: Fine-tune an English model on English backchannels, then evaluate on Japanese backchannels without retraining. Measure silhouette scores and generation quality to determine whether the learned representations capture general discourse-marker mechanisms or language-specific patterns.