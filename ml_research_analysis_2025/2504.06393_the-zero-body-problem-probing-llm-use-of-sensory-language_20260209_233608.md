---
ver: rpa2
title: 'The Zero Body Problem: Probing LLM Use of Sensory Language'
arxiv_id: '2504.06393'
source_url: https://arxiv.org/abs/2504.06393
tags:
- language
- sensory
- human
- each
- gemini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether language models use sensory language
  similarly to humans by comparing 18 models against human-written stories. The research
  extends an existing dataset with 18,000 stories from six model families (Gemini,
  GPT, Llama, OLMo, Phi, Qwen) and measures sensory language use across twelve axes
  using cognitive science lexicons.
---

# The Zero Body Problem: Probing LLM Use of Sensory Language

## Quick Facts
- arXiv ID: 2504.06393
- Source URL: https://arxiv.org/abs/2504.06393
- Authors: Rebecca M. M. Hicke; Sil Hamilton; David Mimno
- Reference count: 16
- Primary result: Language models significantly differ from humans in sensory language use, with differences attributed to instruction tuning rather than inability to recognize sensory content

## Executive Summary
This study investigates whether large language models use sensory language similarly to humans by comparing 18 models against human-written stories. The research extends an existing dataset with 18,000 stories from six model families (Gemini, GPT, Llama, OLMo, Phi, Qwen) and measures sensory language use across twelve axes using cognitive science lexicons. Results show all models significantly differ from human usage patterns, with Gemini models using more sensory language and most others using less. The study finds that while models can identify sensory content through linear probes, their actual usage differs due to instruction tuning practices.

## Method Summary
The researchers created a comprehensive dataset by collecting 18,000 stories generated by 18 language models from six families, paired with human-written stories from Reddit's r/WritingPrompts. They employed cognitive science lexicons to measure sensory language use across twelve dimensions including touch, smell, sound, and sight. The analysis compared statistical distributions of sensory language between human and model-generated text, while linear probes tested whether models could identify sensory content. Additionally, the team analyzed 700 instances from the Open Preference Optimization dataset to understand how post-training fine-tuning might influence sensory language patterns.

## Key Results
- All 18 language models significantly differ from human sensory language patterns
- Gemini models use more sensory language than humans, while Llama, OLMo, Phi, and Qwen families use less
- Linear probes reveal models can identify sensory content despite not using it similarly
- Post-training fine-tuning (RLHF) appears to discourage certain forms of sensory language use

## Why This Works (Mechanism)
The study's approach works by systematically comparing sensory language patterns across multiple model families and human text using established cognitive science lexicons. By combining statistical analysis of generated stories with linear probe experiments, the researchers can distinguish between models' ability to recognize sensory content and their actual usage patterns. The inclusion of RLHF dataset analysis provides insights into how post-training fine-tuning influences language generation, allowing the team to attribute differences to instruction tuning rather than fundamental limitations in sensory language understanding.

## Foundational Learning
**Cognitive Science Lexicons**
*Why needed:* Provide standardized vocabulary for measuring sensory language across different dimensions
*Quick check:* Verify lexicon coverage matches contemporary usage patterns

**Statistical Distribution Analysis**
*Why needed:* Enable quantitative comparison of sensory language patterns between human and model text
*Quick check:* Confirm distributions follow expected statistical properties

**Linear Probe Classification**
*Why needed:* Test whether models can identify sensory content without affecting generation
*Quick check:* Validate probe accuracy on held-out test sets

**RLHF Dataset Analysis**
*Why needed:* Understand post-training fine-tuning effects on language patterns
*Quick check:* Ensure dataset represents diverse fine-tuning approaches

## Architecture Onboarding

**Component Map**
Story Generation -> Sensory Language Measurement -> Statistical Analysis -> Linear Probe Testing -> RLHF Analysis

**Critical Path**
Model Story Generation → Cognitive Science Lexicon Application → Distribution Comparison → Probe Training → Fine-tuning Analysis

**Design Tradeoffs**
- Computational cost of generating 18,000 stories vs. comprehensive model coverage
- Use of pretrained lexicons vs. potential domain mismatch with modern text
- Focus on English stories vs. broader linguistic generalizability

**Failure Signatures**
- Inconsistent sensory language patterns across model families
- Linear probes failing to detect sensory content despite its presence
- RLHF dataset analysis not reflecting broader fine-tuning practices

**First Experiments**
1. Generate stories from all 18 models and human writers
2. Apply cognitive science lexicons to measure sensory language across twelve dimensions
3. Train linear probes to test models' ability to identify sensory content

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis relies on pretrained cognitive science lexicons that may not capture evolving language patterns
- Study focuses exclusively on English-language stories from a single source (r/WritingPrompts)
- RLHF dataset analysis represents a limited sample (700 instances) that may not capture full spectrum of fine-tuning practices

## Confidence

**High Confidence:** All models significantly differ from human sensory language patterns; linear probes show models can identify sensory content

**Medium Confidence:** Attribution of differences to instruction tuning practices; interpretation that post-training fine-tuning discourages sensory language

**Low Confidence:** Specific claims about which sensory dimensions are most affected by fine-tuning

## Next Checks
1. Conduct cross-linguistic validation using the same analytical framework on non-English story datasets
2. Perform controlled fine-tuning experiments with identical base models fine-tuned with different sensory language emphases
3. Expand RLHF dataset analysis to include more diverse model families and training approaches