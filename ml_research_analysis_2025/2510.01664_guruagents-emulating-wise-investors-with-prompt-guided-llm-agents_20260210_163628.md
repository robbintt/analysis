---
ver: rpa2
title: 'GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents'
arxiv_id: '2510.01664'
source_url: https://arxiv.org/abs/2510.01664
tags:
- ticker
- score
- metric
- prompt
- guruagents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GuruAgents, prompt-guided LLM agents, successfully operationalize\
  \ the strategies of legendary investors by encoding their philosophies into deterministic\
  \ reasoning pipelines and tool-integrated prompts. Using GPT-4o and LangChain frameworks,\
  \ five agents\u2014Buffett, Graham, Greenblatt, Piotroski, and Altman\u2014are designed\
  \ to emulate distinct investment styles."
---

# GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents

## Quick Facts
- **arXiv ID:** 2510.01664
- **Source URL:** https://arxiv.org/abs/2510.01664
- **Reference count:** 27
- **Primary result:** Prompt-guided LLM agents successfully emulate legendary investors' strategies, with the Buffett agent achieving 42.2% CAGR in backtests.

## Executive Summary
GuruAgents operationalize legendary investors' strategies by encoding their philosophies into deterministic reasoning pipelines with tool-integrated prompts. Using GPT-4o and LangChain frameworks, five agents—Buffett, Graham, Greenblatt, Piotroski, and Altman—are designed to emulate distinct investment styles. Backtested on NASDAQ-100 constituents from Q4 2023 to Q2 2025, the Buffett agent achieved the highest performance with a 42.2% CAGR, significantly outperforming benchmarks. The study demonstrates that prompt engineering can translate qualitative investment doctrines into reproducible quantitative strategies, offering a novel approach for systematic automated investing.

## Method Summary
The study constructs five LLM agents using GPT-4o and LangChain/LangGraph frameworks, each representing a legendary investor's philosophy through role-based system prompts. Agents use deterministic tool integration to calculate financial metrics, apply specific scoring formulas, and construct portfolios according to each guru's strategy. The backtesting framework evaluates quarterly rebalancing on NASDAQ-100 constituents from Q4 2023 to Q2 2025, with performance measured by CAGR, Sharpe ratio, MDD, VaR, and CVaR.

## Key Results
- Buffett agent achieved highest performance with 42.2% CAGR and 1.44 Sharpe ratio
- Piotroski agent showed 28.8% CAGR with 1.01 Sharpe ratio
- Graham agent underperformed with 19.1% CAGR and 0.73 Sharpe ratio
- All agents outperformed NASDAQ-100 and S&P 500 benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Role-based persona construction via system prompts induces strategy-specific investment behaviors.
- **Mechanism:** Explicit definition of investor philosophy in prompts biases LLM token selection toward strategy-aligned logic.
- **Core assumption:** LLM has internalized semantic meaning of financial axioms as logical constraints.
- **Evidence anchors:** Agents "exhibit unique behaviors driven by their prompted personas"; role assignment ensures "consistency in agent behavior."

### Mechanism 2
- **Claim:** Deterministic tool integration decouples calculation reliability from LLM's probabilistic generation.
- **Mechanism:** LLM outputs tool calls rather than final answers; external Python functions execute actual arithmetic.
- **Core assumption:** Mapping between philosophy and formal tool definitions is accurate and exhaustive.
- **Evidence anchors:** "Agents rely on these tool outputs for the quantitative evaluation of firms"; tool invocation for "extracting indicators."

### Mechanism 3
- **Claim:** Strict reasoning pipeline enforces portfolio constraints that mimic investor psychology.
- **Mechanism:** Hard-coded selection rules and weighting schemes in prompts force LLM to act as compiler for investment strategy.
- **Core assumption:** Complex philosophies can be reduced to algorithmic scoring rules without losing efficacy.
- **Evidence anchors:** Buffett agent generates "concentrated portfolios... reflecting the prompt's emphasis"; fixed sequence of "Metric collection -> Scoring -> Portfolio construction."

## Foundational Learning

- **Concept: Role-Prompting / Persona Adoption**
  - **Why needed here:** Core innovation is simulating specific "Gurus" through behavioral priors.
  - **Quick check question:** If you remove the specific guru quotes from the system prompt, does the agent's portfolio selection change significantly?

- **Concept: Function Calling / Tool Use (LangChain)**
  - **Why needed here:** System relies on LLM knowing when to call calculator rather than guessing numbers.
  - **Quick check question:** Can you trace the data flow where LLM outputs a function call and receives a JSON result back?

- **Concept: Financial Heuristics (e.g., F-Score, Z-Score)**
  - **Why needed here:** To debug agent, must know if "Tool" correctly calculates metric per Guru's theory.
  - **Quick check question:** Does Piotroski agent correctly treat "NA" signals as 0, and how does that affect final F-Score?

## Architecture Onboarding

- **Component map:** LLM Core (GPT-4o) -> Orchestrator (LangChain/LangGraph) -> Tool Layer (Python functions) -> Prompt Repository (static text files)
- **Critical path:** Data Load (OHLCV + Fundamentals) -> Tool Execution (LLM selects tools -> Tools return Metric DataFrames) -> Scoring (LLM applies logic to generate Score column) -> Weighting (Normalization) -> Output (Markdown table parsed by backtester)
- **Design tradeoffs:** Determinism vs. Adaptability (hard rules for reproducibility vs. LLM's ability to discover novel patterns); Look-back Bias (fixed universe avoids survivorship bias complexity)
- **Failure signatures:** Format Drift (LLM outputs prose instead of Markdown table); Metric Hallucination (LLM invents undefined metric); Tie-breaking Loops (identical scores causing arbitrary selection)
- **First 3 experiments:** 1) Verify Determinism (run Buffett agent twice with temperature=0, confirm identical output); 2) Ablation Study (remove "Key Quotations" from Buffett prompt, check portfolio shift from "Big Tech"); 3) Tool Validation (manually calculate Z-Score for AAPL, compare against `metric_altman` tool output)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can philosophical alignment of GuruAgents be rigorously quantified beyond reproducibility of quantitative outputs?
- **Basis in paper:** Authors state future work is needed to develop "more rigorous metrics to evaluate philosophical alignment."
- **Why unresolved:** Study demonstrates reproducible strategies but lacks formal metric to verify LLM's reasoning strictly adheres to guru's intent.
- **What evidence would resolve it:** New evaluation framework (LLM-as-judge or expert review) scoring agent's decision rationale against canonical texts, independent of returns.

### Open Question 2
- **Question:** Can multi-agent ensemble system synthesize conflicting signals to achieve higher risk-adjusted returns than best single agent?
- **Basis in paper:** Paper proposes "designing an Ensemble of GuruAgents, a multi-agent system that synthesizes their diverse perspectives" as primary future research direction.
- **Why unresolved:** Current study evaluates agents in isolation; combining diverse strategies might smooth volatility or dilute alpha.
- **What evidence would resolve it:** Backtesting meta-strategy aggregating portfolio weights/signals of all five agents, comparing Sharpe ratio and MDD to standalone Buffett agent.

### Open Question 3
- **Question:** To what extent is Buffett agent's superior performance attributable to specific market regime (tech-led bull market) rather than prompt design?
- **Basis in paper:** Backtest period coincides with significant tech rally; Buffett agent concentrated in "Big Tech" while value-focused agents underperformed.
- **Why unresolved:** Short 7-quarter window makes it difficult to distinguish if strategy is robust or benefited from style bias aligned with prompt's "high-quality business" heuristics.
- **What evidence would resolve it:** Extending backtest to include bear markets or value-driven cycles, or testing on broader universe where "moats" are harder to identify.

## Limitations
- Deterministic tool-integration approach assumes perfect mapping between philosophies and metric definitions without validation
- NASDAQ-100 universe represents narrow slice of market capitalization and sector diversity, limiting generalizability
- Backtesting window (Q4 2023-Q2 2025) is relatively short for evaluating long-term investment strategies

## Confidence
- **High Confidence:** Technical implementation of deterministic tool-calling and scoring pipelines is sound and reproducible given detailed appendix
- **Medium Confidence:** Mechanism by which system prompts translate philosophies into quantitative strategies is plausible but requires further validation
- **Low Confidence:** Generalizability to broader market universes, longer time horizons, or different market regimes

## Next Checks
1. **Philosophical Fidelity Test:** Conduct blind test where investment professionals evaluate whether portfolios align with known strategies of human counterparts
2. **Cross-Validation Across Universes:** Replicate backtest using different market universes (S&P 500, Russell 2000) and assess whether agent performance rankings remain consistent
3. **Out-of-Sample Temporal Validation:** Extend backtest to include periods before GPT-4o's knowledge cutoff (2015-2020) to evaluate performance during different market regimes and test robustness across market cycles