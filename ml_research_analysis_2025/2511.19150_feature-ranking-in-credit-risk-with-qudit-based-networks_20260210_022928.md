---
ver: rpa2
title: Feature Ranking in Credit-Risk with Qudit-Based Networks
arxiv_id: '2511.19150'
source_url: https://arxiv.org/abs/2511.19150
tags:
- quantum
- interpretability
- feature
- features
- qudit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a qudit-based quantum neural network (QNN)
  for interpretable credit risk assessment, addressing the challenge of balancing
  predictive accuracy with transparency in financial decision-making. The proposed
  model employs a single qudit and encodes both input features and trainable parameters
  within a unified unitary evolution generated by the full su(d) algebra, enabling
  compact circuit design and intrinsic feature importance attribution through learned
  weight magnitudes.
---

# Feature Ranking in Credit-Risk with Qudit-Based Networks

## Quick Facts
- **arXiv ID**: 2511.19150
- **Source URL**: https://arxiv.org/abs/2511.19150
- **Reference count**: 0
- **Primary result**: Qudit-based quantum neural network achieves 0.667 F1-score on credit risk dataset, balancing interpretability and performance

## Executive Summary
This study introduces a qudit-based quantum neural network (QNN) for interpretable credit risk assessment, addressing the challenge of balancing predictive accuracy with transparency in financial decision-making. The proposed model employs a single qudit and encodes both input features and trainable parameters within a unified unitary evolution generated by the full su(d) algebra, enabling compact circuit design and intrinsic feature importance attribution through learned weight magnitudes. The QNN was benchmarked on a real-world, imbalanced credit risk dataset from Taiwan, comparing performance against logistic regression (LR), random forest (RF), and neural network (NN) models.

The qudit QNN achieved a macro-averaged F1-score of 0.667, closely matching the NN baseline and outperforming LR (0.601) and RF (0.647). Notably, the QNN's feature importance ranking showed strong alignment with LR (edit distance of 20.9), comparable to RF's interpretability while requiring significantly fewer parameters (384 vs 3,927 for RF). A feature-poisoning test demonstrated the QNN's robustness, maintaining an F1-score of 0.632 under corruption conditions. The Weighted Interpretability Score (WIS) analysis revealed that while RF showed slightly better interpretability (WIS=0.953), the QNN preserved moderate interpretability (WIS=0.853) while offering superior robustness.

## Method Summary
The proposed approach uses a single qudit to encode both input features and trainable parameters within a unitary evolution generated by the full su(d) algebra. This design enables compact circuit representation and intrinsic feature importance attribution through the magnitudes of learned weights. The model was trained on a real-world credit risk dataset from Taiwan, which presents class imbalance challenges typical in financial applications. Performance was evaluated against classical baselines including logistic regression, random forest, and neural network models using macro-averaged F1-score as the primary metric. Feature importance was assessed through learned weight magnitudes, and robustness was tested through feature-poisoning experiments where selected features were replaced with Gaussian noise.

## Key Results
- Qudit QNN achieved 0.667 macro-averaged F1-score, closely matching NN baseline (0.667) and outperforming LR (0.601) and RF (0.647)
- Feature importance ranking showed strong alignment with logistic regression (edit distance of 20.9), demonstrating interpretability comparable to RF
- Feature-poisoning test showed robustness with F1-score of 0.632 under corruption conditions
- WIS analysis revealed moderate interpretability (0.853) while requiring 10x fewer parameters than RF (384 vs 3,927)

## Why This Works (Mechanism)
The qudit-based QNN achieves interpretability through the direct mapping of feature importance to the magnitudes of learned unitary weights. By encoding both inputs and parameters in a single qudit's su(d) algebra evolution, the model creates a natural feature attribution mechanism where weight magnitudes directly indicate feature relevance. The compact unitary representation enables efficient parameter sharing while maintaining the expressive power needed for complex decision boundaries in credit risk assessment. The single-qudit architecture reduces circuit depth and parameter count, which both improves generalization and simplifies the interpretability analysis.

## Foundational Learning

**su(d) algebra**: The complete set of generators for d-dimensional unitary operations. *Why needed*: Provides the mathematical foundation for representing all possible quantum operations in the qudit system. *Quick check*: Verify that the learned weights span the full su(d) space during training.

**Feature importance through weight magnitudes**: Direct attribution of feature relevance to the absolute values of learned unitary parameters. *Why needed*: Enables transparent model interpretation without requiring post-hoc explanation methods. *Quick check*: Confirm monotonic relationship between weight magnitudes and feature importance rankings.

**Unitary evolution in credit risk modeling**: Using quantum mechanical evolution to represent sequential decision-making processes. *Why needed*: Captures complex feature interactions and non-linear decision boundaries. *Quick check*: Compare feature interaction terms between quantum and classical models.

## Architecture Onboarding

**Component map**: Input features → Qudit encoding → Unitary evolution (su(d) algebra) → Measurement → Classification output

**Critical path**: Feature encoding → Parameterized unitary gate sequence → State evolution → Measurement basis selection → Prediction

**Design tradeoffs**: Single qudit vs. multiple qubits (compactness vs. potential expressivity), direct weight interpretation vs. black-box quantum operations, parameter efficiency vs. model capacity

**Failure signatures**: Poor performance when features require high-dimensional entanglement, sensitivity to noise in measurement basis selection, breakdown of interpretability when weights become uniformly distributed

**First experiments**: 1) Test feature importance attribution on synthetic datasets with known ground truth, 2) Evaluate performance degradation as feature count increases beyond qudit dimension, 3) Measure circuit depth vs. accuracy tradeoff for different su(d) algebra parameterizations

## Open Questions the Paper Calls Out
None

## Limitations
- Single dataset evaluation limits generalizability across different financial contexts and geographic regions
- Absence of cross-validation and statistical significance testing makes performance differences uncertain
- Simplified feature-poisoning test may not capture real-world adversarial scenarios in credit risk assessment

## Confidence
- **Medium**: Claims about achieving interpretable credit risk assessment with competitive performance
- **Medium**: Assertion that the approach balances interpretability and predictive strength
- **Medium**: Feature importance attribution through weight magnitudes concept

## Next Checks
1. **Cross-dataset validation**: Evaluate the QNN on multiple credit risk datasets from different countries and financial institutions to assess generalizability
2. **Statistical rigor**: Implement k-fold cross-validation with significance testing to determine whether performance differences between models are statistically meaningful
3. **Adversarial robustness testing**: Conduct comprehensive attacks beyond Gaussian noise, including feature manipulation and model inversion attempts, to evaluate real-world security implications