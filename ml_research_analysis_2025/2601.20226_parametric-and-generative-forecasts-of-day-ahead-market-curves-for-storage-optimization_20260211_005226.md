---
ver: rpa2
title: Parametric and Generative Forecasts of Day-Ahead Market Curves for Storage
  Optimization
arxiv_id: '2601.20226'
source_url: https://arxiv.org/abs/2601.20226
tags:
- price
- demand
- supply
- curves
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents two machine learning frameworks for forecasting
  aggregated supply and demand curves in the EPEX SPOT day-ahead electricity market.
  The first is a fast parametric model using XGBoost that forecasts hourly curves
  via eight interpretable parameters, achieving median normalized mean absolute errors
  of 7.2-10.7%.
---

# Parametric and Generative Forecasts of Day-Ahead Market Curves for Storage Optimization

## Quick Facts
- arXiv ID: 2601.20226
- Source URL: https://arxiv.org/abs/2601.20226
- Reference count: 9
- This paper presents two ML frameworks for forecasting EPEX SPOT day-ahead market curves, showing the generative model enables deeper analysis of storage strategy robustness while the fast model provides practical daily predictions.

## Executive Summary
This paper addresses the challenge of forecasting aggregated supply and demand curves in the EPEX SPOT day-ahead electricity market for storage optimization. The authors propose two complementary approaches: a fast parametric model using XGBoost to forecast curves via eight interpretable parameters, and a generative model using denoising diffusion probabilistic models to create synthetic bid-level scenarios. Both frameworks are evaluated on their ability to inform optimal price-maker storage strategies, demonstrating that accounting for market impact prevents negative revenues and enables more robust decision-making under uncertainty.

## Method Summary
The fast parametric model reduces complex curves to eight parameters (plateaus and Chebyshev polynomial coefficients) predicted by eight separate XGBoost regressors. The generative model uses a two-stage DDPM to simulate bid-level marked point processes, generating synthetic price arrivals and volumes conditional on exogenous features. Both models feed into a price-maker storage optimization framework that accounts for the agent's market impact when determining optimal charge/discharge quantities between predetermined hours.

## Key Results
- Fast parametric model achieves median normalized mean absolute errors of 7.2-10.7% across 12 months of out-of-sample testing
- Generative DDPM achieves normalized mean square errors of 1.3-5% and successfully reproduces empirical price-volume distributions
- Accounting for price impact in storage optimization eliminates negative revenue scenarios and compresses optimal spread ranges by approximately 40%
- Storage capacity value analysis shows diminishing returns beyond 1500MW due to cannibalization effects

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reducing complex aggregated supply/demand curves to an 8-parameter representation allows fast, interpretable forecasting for daily operations.
- **Mechanism:** The model decomposes curves into fixed inelastic bounds and an elastic middle segment, fitting a degree-3 Chebyshev polynomial to the elastic segment.
- **Core assumption:** Market curves exhibit consistent structural regularity (two plateaus and a smooth elastic segment) that can be captured by low-order polynomials.
- **Evidence anchors:** "fast parametric model... via eight interpretable parameters... grid-robust representation."
- **Break condition:** Market volatility creating highly irregular curve shapes that a degree-3 polynomial cannot fit.

### Mechanism 2
- **Claim:** Generative modeling via DDPMs captures the joint distribution of bid-level orders, enabling probabilistic scenario generation.
- **Mechanism:** The process treats bids as a marked point process, with a DDPM learning to reverse a noise corruption process to generate synthetic price arrivals and volumes.
- **Core assumption:** Training data contains sufficient samples to model complex dependencies between exogenous features and bid structures.
- **Evidence anchors:** "generative model using denoising diffusion probabilistic models that generates synthetic bid-level scenarios."
- **Break condition:** Generated samples violate physical constraints or fail to reproduce statistical properties of empirical distributions.

### Mechanism 3
- **Claim:** Incorporating a "price-maker" assumption into storage optimization accounts for the agent's own market impact.
- **Mechanism:** Instead of maximizing volume at the observed spread, the optimization solves for the quantity where marginal revenue equals marginal price impact.
- **Core assumption:** Forecast errors across hours are sufficiently independent or characterized by a known distribution to allow tractable expected revenue maximization.
- **Evidence anchors:** "accounting for price impact reduces negative revenues and compresses spreads."
- **Break condition:** Storage capacity is small relative to market liquidity or curve slopes are estimated with high error.

## Foundational Learning

- **Concept: Chebyshev Polynomials**
  - **Why needed here:** Provide numerical stability for curve fitting compared to standard polynomials.
  - **Quick check question:** Can you explain why a degree-3 Chebyshev polynomial is used for the "elastic" segment rather than a higher-degree polynomial?

- **Concept: Marked Point Processes**
  - **Why needed here:** The data structure underlying the generative model for discretizing continuous curves into price arrivals and volumes.
  - **Quick check question:** How does the paper handle the "Dirac mass" at zero volume when adapting data for the DDPM?

- **Concept: Supply Function Equilibrium (SFE)**
  - **Why needed here:** The theoretical framing for price-maker optimization, justifying why the agent must optimize a function of price.
  - **Quick check question:** In the optimization formula, what does the term $\frac{1}{\Gamma'}$ represent in the context of price impact?

## Architecture Onboarding

- **Component map:** EPEX SPOT order book -> 8-Parameter Extraction -> XGBoost Regressors -> Curve Reconstruction (Fast Path)
- **Component map:** EPEX SPOT order book -> Marked Point Process Encoding -> DDPM (Price Model + Volume Model) -> Scenario Aggregation (Generative Path)
- **Component map:** Forecasted Curves -> Storage Optimizer (SFE solver) -> Optimal Bids (Downstream)

- **Critical path:** The most sensitive component is the calibration of forecast error X distributions. Mischaracterization leads to biased expected revenue calculations.

- **Design tradeoffs:** The Fast Model provides daily usability but poor uncertainty quantification. The Generative Model offers scenario-based robustness but is computationally expensive and less suitable for real-time operations.

- **Failure signatures:**
  - Non-monotonicity in parametric model curves if post-processing step fails
  - Negative volumes in generative model outputs requiring truncation
  - Revenue collapse in naive optimization strategies

- **First 3 experiments:**
  1. Implement the 8-parameter extraction on historical data and compute normalized MAE between reconstructed approximation and raw data.
  2. Train the DDPM on a small subset of bid data and visually inspect generated price arrivals against empirical distribution using Q-Q plots.
  3. Run optimization on a single day using both naive and price-maker strategies to verify the "intermediate region" result and avoidance of negative revenues.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal strategy change if the storage agent optimizes block orders across dynamically selected multiple hours rather than fixed pairs?
- Basis in paper: Section 4.1 states a natural extension would be to allow blocks across multiple optimally selected hours.
- Why unresolved: Current framework simplifies optimization to a single spread between two predetermined hours for tractability.
- What evidence would resolve it: An optimization model demonstrating revenue impacts when the agent selects charging/discharging hours dynamically.

### Open Question 2
- Question: How can recursive complex order types, such as linked blocks or minimum income conditions, be integrated into the generative DDPM framework?
- Basis in paper: Section 3.1 notes these orders create recursive, cross-mark constraints outside current scope.
- Why unresolved: Current model treats volume marks as independent conditional on price, failing to capture logical dependencies across hours.
- What evidence would resolve it: A modified DDPM architecture that successfully models cross-hour constraints while maintaining generated curve quality.

### Open Question 3
- Question: Can the generative model improve generalizability by learning the initial offer magnitude endogenously rather than fixing it to historical data?
- Basis in paper: Section 3.1 mentions taking $\tilde{S}_0$ from data "reduces generalizability" and suggests learning it through an additional generative model.
- Why unresolved: Current implementation anchors generated curves to observed values at -500 EUR to simplify evaluation.
- What evidence would resolve it: A model that generates the initial plateau while maintaining accuracy in the negative price range without historical anchoring.

## Limitations

- The 8-parameter curve representation assumes consistent market structure that may break during extreme volatility or regime shifts.
- The generative model's neural network architecture and exact training procedures are underspecified, limiting reproducibility.
- Forecast error distribution calibration relies on BIC selection, but the impact of mis-specification on optimal storage decisions is not quantified.

## Confidence

- **High Confidence:** Fast parametric model methodology and hyperparameter choices are fully specified.
- **Medium Confidence:** 8-parameter representation achieves good empirical performance but may fail during extreme market conditions.
- **Low Confidence:** Generative model's internal architecture and exact data preprocessing pipeline are underspecified.

## Next Checks

1. **Parametric Robustness Test:** Apply 8-parameter extraction to data from market crisis periods (e.g., 2022 energy crisis) to quantify degradation in approximation error.
2. **Generative Sample Validation:** Train a simplified DDPM on synthetic data with known statistical properties to verify it reproduces target distributions before applying to real bid data.
3. **Optimization Sensitivity:** Perform Monte Carlo analysis varying assumed forecast error distribution X to quantify stability of optimal storage quantity q*.