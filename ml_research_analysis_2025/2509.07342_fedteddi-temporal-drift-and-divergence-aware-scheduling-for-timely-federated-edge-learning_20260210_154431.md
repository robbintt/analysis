---
ver: rpa2
title: 'FedTeddi: Temporal Drift and Divergence Aware Scheduling for Timely Federated
  Edge Learning'
arxiv_id: '2509.07342'
source_url: https://arxiv.org/abs/2509.07342
tags:
- data
- clients
- learning
- client
- drift
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses federated edge learning (FEEL) in dynamic
  environments where client data evolves over time with non-i.i.d. characteristics.
---

# FedTeddi: Temporal Drift and Divergence Aware Scheduling for Timely Federated Edge Learning

## Quick Facts
- **arXiv ID:** 2509.07342
- **Source URL:** https://arxiv.org/abs/2509.07342
- **Authors:** Yuxuan Bai; Yuxuan Sun; Tan Chen; Wei Chen; Sheng Zhou; Zhisheng Niu
- **Reference count:** 39
- **Primary result:** 58.4% faster convergence than random scheduling on CIFAR-10

## Executive Summary
FedTeddi addresses federated edge learning in dynamic environments where client data evolves over time with non-i.i.d. characteristics. The algorithm jointly optimizes client scheduling and bandwidth allocation by quantifying temporal drift (data evolution over time) and collective divergence (heterogeneity across clients) using Earth Mover's Distance of class distributions. By balancing plasticity and stability, FedTeddi enables timely adaptation to new data while preventing catastrophic forgetting of previous knowledge.

## Method Summary
The paper proposes a scheduling algorithm that quantifies temporal drift and collective divergence across clients using Earth Mover's Distance (EMD) metrics. FedTeddi jointly optimizes client selection and bandwidth allocation through a weighting mechanism that balances adaptation to new data against preservation of previously learned knowledge. The algorithm schedules clients based on their drift and divergence scores, allocating more bandwidth to clients with higher scores to accelerate learning from relevant data while maintaining stability.

## Key Results
- Achieves 58.4% faster convergence than random scheduling and 38.5% faster than pure drift-aware methods on CIFAR-10
- Maintains higher test accuracy throughout training compared to baseline approaches
- Demonstrates effectiveness on both CIFAR-10 and CIFAR-100 datasets with synthetic temporal drift simulations

## Why This Works (Mechanism)
FedTeddi works by quantifying two key aspects of federated learning dynamics: temporal drift (how client data distributions change over time) and collective divergence (heterogeneity across different clients). The algorithm uses EMD to measure these factors and creates a weighted scheduling strategy that prioritizes clients showing both significant drift and high divergence. This approach ensures the global model adapts to evolving data patterns while maintaining robustness against client heterogeneity, effectively balancing the trade-off between plasticity (adaptation to new data) and stability (preservation of existing knowledge).

## Foundational Learning

**Earth Mover's Distance (EMD):** A metric measuring the minimum "work" required to transform one probability distribution into another. *Why needed:* Quantifies how much client data distributions have changed over time and differ from each other. *Quick check:* Verify EMD calculations on simple synthetic distributions before applying to federated learning.

**Temporal Drift in Federated Learning:** The phenomenon where client data distributions evolve over time due to changing environments or user behavior. *Why needed:* Real-world federated systems must handle non-stationary data distributions. *Quick check:* Monitor class distribution changes across training rounds.

**Plasticity-Stability Trade-off:** The fundamental challenge of adapting to new information while preserving previously learned knowledge. *Why needed:* Critical for preventing catastrophic forgetting in dynamic environments. *Quick check:* Measure performance on both new and old data distributions during training.

**Client Heterogeneity Quantification:** Methods for measuring differences in data distributions across federated clients. *Why needed:* Enables intelligent client selection based on diversity rather than random sampling. *Quick check:* Compare heterogeneity metrics across different client groups.

## Architecture Onboarding

**Component Map:** Data Collection -> EMD Calculation -> Weight Assignment -> Client Scheduling -> Bandwidth Allocation -> Model Update

**Critical Path:** The scheduling algorithm must complete EMD calculations and weight assignments before each communication round to determine which clients to select and how much bandwidth to allocate to each.

**Design Tradeoffs:** The algorithm trades computational overhead (EMD calculations) for improved convergence speed and accuracy. The weighting parameters (λ, γ) control the balance between plasticity and stability, requiring careful tuning for different applications.

**Failure Signatures:** Poor performance may indicate: (1) incorrect EMD calculations due to insufficient data samples, (2) inappropriate weighting parameter settings causing over-adaptation or under-adaptation, or (3) client selection that doesn't reflect true data evolution patterns.

**First Experiments:** 1) Run with synthetic temporal drift on CIFAR-10 to verify convergence improvements over random scheduling. 2) Test sensitivity of weighting parameters (λ, γ) on model performance. 3) Evaluate accuracy maintenance on both original and drifted data distributions.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on image classification benchmarks (CIFAR-10/100) with synthetic temporal drift simulations, limiting generalizability to other data modalities
- Earth Mover's Distance metric assumes access to class distributions that may not be available in privacy-sensitive federated settings
- The weighting mechanism introduces hyperparameters (λ, γ) that require careful tuning, but sensitivity analysis is limited

## Confidence

**Convergence speed improvements (58.4% vs random, 38.5% vs drift-only):** High confidence - supported by extensive experiments across multiple metrics

**Accuracy maintenance throughout training:** Medium confidence - shown for CIFAR datasets but limited to synthetic drift scenarios

**Plastic-stability trade-off mechanism:** Medium confidence - theoretical framework is sound but real-world applicability needs validation

**Scalability to large-scale deployments:** Low confidence - limited to 100 clients, no large-scale deployment results

## Next Checks

1. Test FedTeddi on non-image datasets (text, tabular) with different drift patterns to assess generalizability beyond CIFAR benchmarks

2. Evaluate performance with partial client availability and varying participation rates to validate robustness in real federated settings

3. Conduct ablation studies on the weighting parameters (λ, γ) across different problem domains to understand sensitivity and provide tuning guidelines