---
ver: rpa2
title: 'Compressibility Measures Complexity: Minimum Description Length Meets Singular
  Learning Theory'
arxiv_id: '2510.12077'
source_url: https://arxiv.org/abs/2510.12077
tags:
- loss
- step
- compression
- learning
- quantization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the minimum description length (MDL) principle
  to singular models like neural networks using singular learning theory. The authors
  establish a theoretical framework where model complexity is measured by the local
  learning coefficient (LLC), which captures degeneracy in the loss landscape rather
  than curvature.
---

# Compressibility Measures Complexity: Minimum Description Length Meets Singular Learning Theory

## Quick Facts
- **arXiv ID**: 2510.12077
- **Source URL**: https://arxiv.org/abs/2510.12077
- **Reference count**: 40
- **Key outcome**: Establishes theoretical framework connecting minimum description length (MDL) to singular learning theory, showing that model compressibility is linearly correlated with the local learning coefficient (LLC) for transformer models up to 6.9B parameters.

## Executive Summary
This paper bridges minimum description length (MDL) theory with singular learning theory to provide a theoretical foundation for measuring model complexity through compressibility. The authors prove that for singular models like neural networks, the critical quantization interval needed to achieve a fixed loss tolerance scales linearly with the local learning coefficient (LLC), which captures degeneracy in the loss landscape. Through extensive experiments on Pythia models ranging from 14M to 6.9B parameters, they find strong linear correlations (R² ≥ 0.98) between LLC estimates and compressibility thresholds across training checkpoints, validating the theoretical framework and providing an independent check on LLC estimation practices for large transformer models.

## Method Summary
The method estimates LLC using preconditioned stochastic Langevin dynamics (pSGLD) with fixed hyperparameters (γ=300, nβ=30) across training checkpoints, then correlates these estimates with critical quantization intervals where loss increase equals a tolerance ε=0.5. The theoretical framework shows that for singular models, the critical quantization interval n*_q scales linearly with LLC for fixed loss tolerance. The authors test this relationship across Pythia models (14M-6.9B parameters) using quantization, factorization, and other compression techniques, finding strong linear correlations that validate the theoretical framework and provide independent verification of LLC estimation.

## Key Results
- Strong linear correlation (R² ≥ 0.98) between LLC estimates and critical quantization intervals across Pythia models of all scales
- For quantization, the critical bits per coordinate grows linearly with LLC for fixed loss tolerance
- Models with larger LLCs are less compressible, validating the singular MDL framework
- The relationship holds across training checkpoints and different compression methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Degeneracy in the loss landscape, not curvature, determines compressibility for singular models like neural networks.
- Mechanism: The paper proves that for singular models, the relevant geometric invariant is the local learning coefficient λ, which captures how much parameter "volume" near a minimum produces similar loss. Higher degeneracy (lower λ) means more parameters can vary without increasing loss, enabling coarser quantization grids. Classical MDL assumes regular models where curvature (Hessian) determines volume; this breaks for neural networks with parameter redundancy.
- Core assumption: The sublevel-set volume law (Theorem 2 from Watanabe 2009) holds for neural network loss landscapes, giving Vol({w: K(w) ≤ ε}) ∼ cε^λ.
- Evidence anchors:
  - [Section 3.2]: "In contrast to the classical treatment of MDL, where geometric invariants like the curvature determined by the Hessian appear in the description length, the important geometric feature in the singular case is degeneracy."
  - [Figure 1]: Visual comparison showing regular models with elliptical level sets vs. singular models with degenerate valleys.
  - [Corpus]: Limited direct support; neighbor papers on MDL for neural networks don't address degeneracy explicitly.
- Break condition: If loss landscape has insufficient degeneracy (LLC ≈ d/2), the singular MDL formulation reduces to classical MDL and provides no compression advantage over parameter counting.

### Mechanism 2
- Claim: The critical quantization interval n*_q scales linearly with LLC for fixed loss tolerance.
- Mechanism: From equation (9), the per-coordinate bit budget b*(ε) = (λ/d) log₂(1/ε) + O(log log(1/ε)/d). This linear relationship emerges because: (1) quantization cells have volume ∝ h^d, (2) sublevel sets have volume ∝ ε^λ, and (3) containment requires h^d ≤ ε^λ. Solving gives the linear scaling.
- Core assumption: Quantization error is dominated by local geometry near w*; global loss landscape structure doesn't override local volume considerations.
- Evidence anchors:
  - [Section 3.3]: "For a fixed loss tolerance ε the critical bits per coordinate grows linearly with the LLC."
  - [Section 5]: "We find a linear fit with R² = 0.98 for all the shown models."
  - [Corpus]: "Grokking vs. Learning" mentions compressibility differences but doesn't test LLC correlation.
- Break condition: If quantization interacts with global structure (e.g., causing mode collapse, interfering with batch normalization), the local volume approximation fails.

### Mechanism 3
- Claim: SGLD-based LLC estimation captures meaningful model complexity information for transformers up to 6.9B parameters.
- Mechanism: The estimator (equation 10) computes ˆλ = nβ · [E_β[L_n(w)] - L_n(w*)], where the expectation is over the Gibbs posterior. This measures how much loss increases on average when parameters diffuse within the loss basin. Larger basins (more degeneracy) show smaller loss increase per unit parameter movement.
- Core assumption: SGLD with fixed hyperparameters samples from an effectively truncated posterior that preserves relative LLC comparisons across training checkpoints.
- Evidence anchors:
  - [Section 4.2]: Formal estimator definition with preconditioned SGLD.
  - [Section D.2]: Acknowledges theoretical gaps in SGLD convergence for neural networks and hyperparameter sensitivity.
  - [Corpus]: No direct corpus support for SGLD-based LLC estimation at scale.
- Break condition: If temperature or localization hyperparameters vary systematically with model scale or training step, estimated LLCs may be confounded rather than comparable.

## Foundational Learning

- **Concept: Singular vs. Regular Models**
  - Why needed here: Neural networks violate regularity assumptions (one-to-one parameter-to-distribution mapping, non-singular Fisher information) that classical MDL relies on.
  - Quick check question: Can you explain why ReLU networks have infinitely many equivalent parameterizations that produce identical input-output maps?

- **Concept: Local Learning Coefficient (LLC)**
  - Why needed here: The paper's central construct; measures effective dimensionality accounting for degeneracy, replacing d/2 (parameter count / 2) from regular models.
  - Quick check question: For a 2-parameter model where one parameter is redundant (loss constant along one direction), what would you expect the LLC to be?

- **Concept: Two-Part Codes**
  - Why needed here: The theoretical framework connecting compression to complexity; redundancy = model encoding cost + excess data encoding cost vs. oracle.
  - Quick check question: In a two-part code with grid tolerance ε = a/n, why does the model encoding cost scale as λ log n rather than d log n?

## Architecture Onboarding

- **Component map**: Pythia checkpoint loading -> LLC estimation (pSGLD) -> Compression testing (quantization) -> Correlation analysis
- **Critical path**: Checkpoint loading → LLC estimation (most expensive: ~3.5 hours for 6.9B on H200) → compression sweep → correlation analysis
- **Design tradeoffs**:
  - Higher nβ gives more stable estimates but may truncate posterior differently than theory assumes
  - Smaller loss tolerance ε gives finer-grained complexity signals but requires more compression parameter search
  - Quantization with vs. without loss-minimizing m affects how well you probe local geometry
- **Failure signatures**:
  - LLC estimates that don't increase monotonically with training step (Section D.2 notes Pythia-14M shows instability at step 90k)
  - R² values significantly below 0.95 for LLC vs. critical n_q suggest estimation or theoretical issues
  - Quantization algorithm failures on certain checkpoints (noted in Figure 4 captions)
- **First 3 experiments**:
  1. Replicate the linear correlation on a single Pythia model (e.g., 160M) across 5 checkpoints: estimate LLC, find critical n_q for ε=0.5, verify R² ≥ 0.98.
  2. Sensitivity test: vary nβ (e.g., 20, 30, 40) on one checkpoint to characterize hyperparameter dependence before drawing conclusions.
  3. Alternative compression: test tensor factorization on the same checkpoints to see if the LLC correlation holds across compression schemes (expect weaker correlation per Section C.2).

## Open Questions the Paper Calls Out

- **Open Question 1**: How can we accurately estimate the true local learning coefficient (LLC) for large transformer models, given that current SGLD-based estimates may be systematically biased?
  - Basis in paper: [explicit] "The sensitivity of LLC estimates to hyperparameters and the likely gap between estimated and true values represent the primary limitations of our current framework" (Conclusion); "we lack theoretical knowledge of the true LLC for large transformer models" (Section 2)
  - Why unresolved: SGLD convergence theorems require technical conditions that may not hold for all neural networks; inverse temperature settings affect estimates in ways not fully understood
  - What evidence would resolve it: Comparing SGLD-based estimates against analytically computed LLCs for model classes where ground truth is known, or developing alternative estimation methods with provable guarantees

- **Open Question 2**: Can the singular MDL framework be extended to non-i.i.d. settings and explain capability gains from post-training methods like fine-tuning and reinforcement learning?
  - Basis in paper: [explicit] "Our framework has yet to explain any capabilities gains via post-training methods like various forms of fine-tuning and reinforcement learning" (Section F.2)
  - Why unresolved: Current theory relies on i.i.d. assumptions that are violated by natural language and post-training optimization
  - What evidence would resolve it: Extending SLT results to ergodic/non-stationary settings; empirical studies correlating LLC changes with capability emergence during post-training

- **Open Question 3**: What determines the optimal inverse temperature β for LLC estimation, and how does this hyperparameter affect the relationship between estimated and true LLC values?
  - Basis in paper: [explicit] "We do not fully understand the role of hyperparameters like inverse temperature... SGLD-based estimation appears sensitive to this factor" (Section D.2)
  - Why unresolved: The principled setting β = 1/log n is too small for stable estimation; temperature acts as a "resolution dial" on the loss landscape with effects not yet fully characterized
  - What evidence would resolve it: Systematic studies of how β affects estimates across model scales and training stages; theoretical characterization of the temperature-resolution relationship

## Limitations
- SGLD-based LLC estimation for transformers lacks rigorous theoretical validation and convergence guarantees
- The strong linear correlations could be influenced by systematic biases in the estimation procedure or shared dependencies on hyperparameters
- Results may not generalize to all compression methods, with factorization showing weaker correlations

## Confidence
- **High Confidence**: The theoretical foundation linking singular learning theory to compressibility (Mechanism 1 and 2). The volume law for sublevel sets and its implications for quantization are mathematically rigorous.
- **Medium Confidence**: The practical LLC estimation procedure using pSGLD for transformers. While the method is sound in principle, the paper acknowledges theoretical gaps in convergence guarantees and hyperparameter sensitivity for neural networks.
- **Medium Confidence**: The generalizability of the LLC-compressibility correlation across compression methods. The strong results for quantization may not extend to other compression schemes like pruning or low-rank factorization.

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary SGLD parameters (step size, chain count, temperature) on a single checkpoint to quantify estimation stability and identify potential confounding effects before generalizing to the full model suite.

2. **Cross-Method Consistency Test**: Apply the same correlation analysis between LLC and critical thresholds for tensor factorization and low-rank approximation. Verify whether weaker correlations (as suggested for factorization) persist across different model scales and training stages.

3. **Independent Estimation Validation**: Compare pSGLD-based LLC estimates against an alternative method such as Laplace approximation or random matrix theory approaches to ensure the observed correlations aren't artifacts of the specific estimation technique.