---
ver: rpa2
title: 'Learning Nonlinearity of Boolean Functions: An Experimentation with Neural
  Networks'
arxiv_id: '2502.01060'
source_url: https://arxiv.org/abs/2502.01060
tags:
- functions
- boolean
- nonlinearity
- walsh
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether neural networks can learn to predict
  the nonlinearity of Boolean functions from examples. The authors train encoder-style
  deep neural networks on truth tables of Boolean functions and their nonlinearity
  values, demonstrating that networks can predict nonlinearity with 95% accuracy for
  functions with 4 and 5 variables.
---

# Learning Nonlinearity of Boolean Functions: An Experimentation with Neural Networks

## Quick Facts
- arXiv ID: 2502.01060
- Source URL: https://arxiv.org/abs/2502.01060
- Reference count: 14
- Authors: Sriram Ranga; Nandish Chattopadhyay; Anupam Chattopadhyay
- Key outcome: Neural networks can predict nonlinearity with >95% accuracy for 4-5 variable Boolean functions, but performance degrades severely for higher variable counts.

## Executive Summary
This paper investigates whether neural networks can learn to predict the nonlinearity of Boolean functions from truth table examples. The authors explore two approaches: first, training linear networks to learn the Walsh spectrum transformation, and second, training deep encoder networks for end-to-end nonlinearity prediction. They demonstrate that linear networks can learn Walsh spectrum with minimal examples and exactly N linearly independent samples, while deep encoder networks achieve high accuracy for small variable counts. However, the approach fails to scale to higher variable counts due to exploding resource requirements and inferior efficiency compared to traditional combinatorial algorithms.

## Method Summary
The study uses two neural network approaches to predict Boolean function nonlinearity. For Walsh spectrum learning, a single-layer linear network with N neurons learns the Walsh-Hadamard transformation from truth tables. For end-to-end nonlinearity prediction, encoder-style fully connected networks with progressive halving architectures and ReLU activations are trained. The datasets consist of truth tables as inputs and corresponding nonlinearity values as targets. Training uses standard SGD optimization with MSE loss for Walsh learning and cross-entropy/MSE for end-to-end prediction. The experiments focus on 4-5 variable functions due to computational constraints, with ~30k examples for n=4 and 200k for n=5.

## Key Results
- Linear networks with N neurons can learn Walsh spectrum transformation exactly with N linearly independent training examples
- Deep encoder networks achieve >95% accuracy for nonlinearity prediction on 4 and 5 variable functions
- Performance degrades severely and resource requirements explode for n≥6 variables
- Neural approaches are less efficient than traditional Fast Walsh Transform algorithms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A single-layer linear network can learn the Walsh spectrum transformation from Boolean functions.
- Mechanism: The network learns to approximate the Walsh-Hadamard matrix via gradient descent on a convex loss surface. Since Walsh spectrum computation is an affine transformation, a linear network with N neurons can exactly model it. The weight matrix converges to the Hadamard matrix structure.
- Core assumption: The training set contains at least N linearly independent Boolean function vectors, providing sufficient constraints for a unique solution.
- Evidence anchors:
  - [abstract] "We first show that the sub-problem of calculating the Walsh spectrum of a Boolean function can be learnt by a neural network with a single hidden layer"
  - [section 3.1] "Comparing Eqs. 12 and 14 indicates that the weight matrix of such a network after training should resemble the Walsh Hadamard matrix of order N and the bias vector should converge to the zero vector"
  - [corpus] Related work on Boolean function learnability exists (Tavares et al.), but this specific Walsh-learning mechanism is novel to this paper
- Break condition: Fewer than N linearly independent training examples causes accuracy to drop sharply; convexity guarantees are lost with non-linear activations.

### Mechanism 2
- Claim: Deep encoder-style networks can learn end-to-end nonlinearity prediction, but only for small variable counts (n=4,5).
- Mechanism: Wider and deeper networks provide sufficient capacity to approximate the combined operations of affine transformation, absolute-value, and max/min. ReLU activations enable non-linear mapping from truth table to single nonlinearity value. The network learns an implicit representation that bypasses explicit Walsh spectrum computation.
- Core assumption: Sufficient network depth and width exist to capture the discrete, non-differentiable operations (abs, max) involved in nonlinearity calculation.
- Evidence anchors:
  - [abstract] "deep neural networks are able to learn to predict the property for functions in 4 and 5 variables with an accuracy above 95%"
  - [section 3.2] "we tried out encoder style fully connected networks of depth and width much larger than that in the above network... were able to train networks to learn to predict nonlinearity for functions in 4 and 5 variables"
  - [corpus] Corpus lacks direct precedent for nonlinearity-specific learning; this is exploratory work
- Break condition: Performance degrades severely for n≥6; network parameters and training data requirements explode super-exponentially.

### Mechanism 3
- Claim: The end-to-end approach fails with shallow/linear networks because the loss landscape has many symmetric global minima (2^N factorial permutations of valid weight configurations).
- Mechanism: Gradient descent cannot stably converge to any specific Hadamard matrix row ordering when only scalar nonlinearity labels are provided. The network lacks sufficient signal to distinguish between equivalent weight configurations.
- Core assumption: The non-convex loss surface with multiple equivalent minima creates convergence instability.
- Evidence anchors:
  - [section 3.2] "We did not expect that the loss surface for the network and problem would be in such a way that gradient descent would lead stably to any of the (2^N)! global minima, and that is what we observed as well"
  - [section 3] "nonlinearity can be easily calculated from the Walsh spectrum using a regular program, but learnability by neural networks cannot be claimed directly since it involves operations like abs max which are known to be challenging for neural networks"
  - [corpus] No corpus papers address this specific optimization landscape
- Break condition: Shallow networks with limited capacity cannot escape local minima; increasing depth and width partially compensates.

## Foundational Learning

- Concept: **Boolean Function Representation via Truth Tables**
  - Why needed here: All neural network inputs are truth tables encoded as binary vectors of length N=2^n. Understanding this representation is essential for data preprocessing.
  - Quick check question: Can you convert a 3-variable Boolean function f(x₁,x₂,x₃) = x₁ ⊕ x₂ into its 8-bit truth table?

- Concept: **Walsh Transform and Nonlinearity**
  - Why needed here: Nonlinearity is derived from the Walsh spectrum via nl(f) = 2^(n-1) - (1/2)max|W_f(ω)|. This establishes the computational baseline the network must learn.
  - Quick check question: Given the Walsh spectrum of a 4-variable function, how do you compute its nonlinearity?

- Concept: **Hadamard Matrix Structure**
  - Why needed here: The weight matrices of successfully trained linear networks converge to Walsh-Hadamard matrices. Recognizing this provides interpretability and validation.
  - Quick check question: Construct H₄ from H₂ using the recursive definition. What pattern do you observe?

## Architecture Onboarding

- Component map:
  - Input layer: N neurons (truth table bits, preprocessed as 1/-1 for Walsh learning, 0/1 for end-to-end)
  - Linear Walsh learner: Single hidden layer, N neurons, no activation, outputs N-dimensional Walsh spectrum
  - End-to-end encoder: Progressive halving architecture (e.g., 64→32→16→8→4→2→1 for n=4), ReLU activations, single output neuron for nonlinearity

- Critical path:
  1. Preprocess truth tables (0→1, 1→-1 for Walsh approach; keep as 0/1 for end-to-end)
  2. For Walsh learning: train linear network with ≥N linearly independent examples; validate weights against Hadamard matrix
  3. For end-to-end: start with first hidden layer width >N, depth ≥6 layers; train on large fraction of function space

- Design tradeoffs:
  - Walsh approach: Interpretable, provably generalizable, O(N²) inference; requires post-processing to extract nonlinearity
  - End-to-end approach: Direct prediction, no post-processing; requires much larger networks, scales poorly, less interpretable
  - Memory vs. speed: Neural approach uses more memory and slower inference than Fast Walsh Transform O(N log N)

- Failure signatures:
  - Accuracy ~40%: Network too shallow (try adding layers)
  - Training doesn't converge for end-to-end with linear network: Expected behavior—requires deep network
  - Poor accuracy with <N training examples for Walsh learning: Insufficient linear independence
  - Cannot scale to n≥6: Known limitation; function space grows as 2^(2^n)

- First 3 experiments:
  1. **Walsh spectrum baseline**: Train linear network on n=3 functions with exactly N=8 linearly independent examples. Verify weight matrix converges to H₈. Test generalization on held-out functions.
  2. **Ablation on training set size**: For n=4, train with 4, 8, 12, 16 examples and plot accuracy. Confirm sharp drop below N=16.
  3. **End-to-end capacity sweep**: For n=4, train encoder networks with depths 3, 5, 7, 9 layers. Record train/test accuracy to identify minimum viable architecture.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can neural networks effectively perform nonlinearity testing using only partial truth table entries rather than the full function?
- Basis in paper: [explicit] The conclusion proposes exploring "neural networks to perform nonlinearity testing... by seeing as few entries of its truth table as possible."
- Why unresolved: The current study only experimented with complete truth tables for 4 and 5 variables; partial information scenarios were not investigated.
- What evidence would resolve it: Successful training of a model that predicts linearity with high accuracy given a sparse subset of a Boolean function's inputs.

### Open Question 2
- Question: Is it computationally feasible to scale end-to-end nonlinearity learning to Boolean functions with $n > 5$ variables?
- Basis in paper: [explicit] The abstract warns it is "challenging to extend the idea to higher number of variables," and the experiments failed to converge for $n=6$.
- Why unresolved: Resource requirements (parameters and training data) exploded for $n=5$ (200k parameters), and the authors could not find a feasible solution for higher variables.
- What evidence would resolve it: An architecture that achieves >90% accuracy on 6-variable functions without requiring an exponential increase in model size or training data.

### Open Question 3
- Question: Can a neural network architecture be designed to outperform the Fast Walsh Transform (FWT) in terms of time or space complexity?
- Basis in paper: [explicit] The abstract states it is "not clear whether one can get advantage in terms of time and space complexity over the existing combinatorial algorithms."
- Why unresolved: The trained encoder networks proved less efficient than the standard $O(N \log N)$ FWT algorithm during inference.
- What evidence would resolve it: A model demonstrating lower latency or memory usage than the FWT while maintaining comparable prediction accuracy.

## Limitations
- The paper lacks clarity on whether end-to-end nonlinearity prediction should be treated as regression or classification, creating conceptual tension.
- No ablation studies examine whether the encoder architecture is optimal or if simpler architectures could achieve comparable results.
- The computational overhead of neural approaches versus traditional combinatorial methods is not thoroughly quantified.

## Confidence

- **High confidence**: Claims about linear networks learning Walsh spectrum transformations are well-supported with mathematical grounding and empirical verification.
- **Medium confidence**: Claims about encoder networks successfully learning nonlinearity for n=4,5 are supported by reported accuracies but lack detailed hyperparameter and architectural justification.
- **Low confidence**: Claims about the fundamental difficulty of scaling to n≥6 are based on observed performance degradation rather than systematic investigation of architectural or training limitations.

## Next Checks

1. **Architecture ablation study**: Systematically vary depth and width of encoder networks for n=4 to identify minimum viable architecture that achieves >95% accuracy, testing whether the progressive halving design is necessary.

2. **Regression vs classification comparison**: Implement both formulations for end-to-end prediction and compare performance, evaluating whether treating nonlinearity as continuous or discrete provides advantages.

3. **Computational efficiency benchmark**: Implement the Fast Walsh Transform algorithm and compare inference time and memory usage against the trained neural networks for n=4 and n=5, quantifying the overhead claimed in the paper.