---
ver: rpa2
title: Automated Mosaic Tesserae Segmentation via Deep Learning Techniques
arxiv_id: '2512.18406'
source_url: https://arxiv.org/abs/2512.18406
tags:
- segmentation
- image
- images
- mosaic
- mosaics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automatically segmenting
  mosaic images to extract individual tesserae, a task critical for cultural heritage
  preservation. The authors propose leveraging Segment Anything Model 2 (SAM 2), a
  foundation model for image segmentation, through transfer learning.
---

# Automated Mosaic Tesserae Segmentation via Deep Learning Techniques

## Quick Facts
- **arXiv ID**: 2512.18406
- **Source URL**: https://arxiv.org/abs/2512.18406
- **Reference count**: 26
- **Primary result**: Fine-tuned SAM 2 achieves IoU 91.02% and Recall 95.89% on mosaic tesserae segmentation

## Executive Summary
This paper addresses the challenge of automatically segmenting mosaic images to extract individual tesserae, a task critical for cultural heritage preservation. The authors propose leveraging Segment Anything Model 2 (SAM 2) through transfer learning, as this foundation model outperforms most conventional segmentation models. Due to the lack of annotated datasets in this domain, they create a manually annotated dataset of mosaic images and fine-tune SAM 2 on it. Quantitative results show that the fine-tuned model significantly outperforms the baseline SAM 2 model, with improvements in Intersection over Union from 89.00% to 91.02% and Recall from 92.12% to 95.89%.

## Method Summary
The methodology involves fine-tuning SAM 2 (specifically the sam2_hiera_large variant) for binary segmentation of mosaic tesserae. The image encoder is frozen while only the prompt encoder and mask decoder are trained, using a custom loss function combining Dice Loss and Score Loss. The dataset consists of 19 mosaics (984 augmented images through rotations and flips) with binary mask annotations and point prompts at centroids. Training uses AdamW optimizer with cosine annealing, batch size 4, and 9 epochs. The model is evaluated on metrics including IoU, Dice coefficient, Recall, Precision, and F-measure, showing significant improvements over baseline SAM 2 and prior methods.

## Key Results
- Fine-tuned model improves IoU from 89.00% to 91.02% and Recall from 92.12% to 95.89%
- Achieves 3% higher F-measure compared to prior benchmark methods
- Reduces absolute difference between predicted and actual tesserae count from 0.20 to 0.02
- Demonstrates strong potential for real-time mosaic segmentation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Freezing the image encoder while fine-tuning only the prompt encoder and mask decoder enables effective domain adaptation with limited data.
- **Mechanism:** SAM 2's pre-trained image encoder already captures general visual features (edges, textures, shapes). By freezing it, the model retains this foundational knowledge while the trainable components learn to map domain-specific prompts to mosaic-specific mask outputs. This parameter-efficient approach prevents catastrophic forgetting and reduces computational requirements.
- **Core assumption:** The pre-trained image encoder's feature representations are sufficiently general to capture tesserae boundaries without further adaptation.
- **Evidence anchors:** [abstract] "We propose a method leveraging Segment Anything Model 2 (SAM 2) by Meta AI, a foundation model that outperforms most conventional segmentation models, to automatically segment mosaics." [section II.C] "We choose to train only the prompt encoder and mask decoder, while freezing the image encoder layer."

### Mechanism 2
- **Claim:** The combined Dice Loss and Score Loss function improves segmentation by jointly optimizing spatial overlap and confidence calibration.
- **Mechanism:** Dice Loss directly maximizes overlap between predicted and ground truth masks, handling class imbalance inherent in segmentation. Score Loss penalizes discrepancies between the model's predicted confidence score and actual IoU, encouraging well-calibrated predictions. The combined objective (L_Total = L_Dice + λ·L_Score) creates a feedback loop where the model learns both accurate boundaries and appropriate uncertainty.
- **Core assumption:** The weighting factor λ appropriately balances overlap optimization against confidence calibration for mosaic-specific segmentation.
- **Evidence anchors:** [section II.D.1] "To enhance the model's performance for our specific task of segmenting mosaics, we are designing a loss function based on the Dice Coefficient... we also consider the model's confidence in its prediction by comparing the predicted confidence score to the actual overlap."

### Mechanism 3
- **Claim:** Systematic data augmentation (rotations, flips, crops) enables robust learning despite limited annotated data.
- **Mechanism:** Mosaic tesserae can appear at arbitrary orientations and scales. By applying rotations (90°, 180°, 270°) and flips, the training set expands while preserving semantic content. This forces the model to learn rotation-invariant features and reduces overfitting to specific orientations present in the small original dataset (19 mosaics → 984 augmented images).
- **Core assumption:** Tesserae appearance is approximately rotation-invariant; a tessera at 180° is semantically equivalent to one at 0°.
- **Evidence anchors:** [section II.B.3] "These transformations preserve the semantic content of the data while introducing variations in the orientation, which is vital as the tesserae can appear at arbitrary angles."

## Foundational Learning

- **Concept: Transfer Learning**
  - **Why needed here:** The paper fine-tunes a pre-trained foundation model rather than training from scratch. Understanding transfer learning is essential to grasp why freezing the image encoder is a valid strategy.
  - **Quick check question:** Can you explain why fine-tuning only the later layers (prompt encoder, mask decoder) while freezing early layers (image encoder) might prevent overfitting on a small dataset?

- **Concept: Semantic Segmentation Metrics (IoU, Dice, F-measure)**
  - **Why needed here:** The paper evaluates performance using IoU, Dice coefficient, Recall, Precision, and F-measure. Understanding these metrics is necessary to interpret the reported improvements.
  - **Quick check question:** Given IoU increased from 89.00% to 91.02% and Recall from 92.12% to 95.89%, which metric suggests the fine-tuned model is better at avoiding false negatives?

- **Concept: Loss Function Design for Segmentation**
  - **Why needed here:** The paper introduces a custom combined loss (Dice + Score Loss). Understanding why cross-entropy alone is insufficient for segmentation helps contextualize this design choice.
  - **Quick check question:** Why might Dice Loss be preferred over pixel-wise cross-entropy when segmenting small, irregularly-shaped objects like tesserae?

## Architecture Onboarding

- **Component map:** Input Image → [Image Encoder (frozen)] → Image Embeddings → [Prompt Encoder (trainable)] → Sparse/Dense Embeddings → [Mask Decoder (trainable)] → Raw Logits → Sigmoid → Probability Mask
- **Critical path:** Load pre-trained sam2_hiera_large weights → Freeze image encoder parameters → Initialize AdamW optimizer with lr=10⁻⁵, weight_decay=10⁻⁵ → Forward pass with point prompts (centroids from ground truth masks) → Compute L_Total = L_Dice + λ·L_Score → Backprop through prompt encoder and mask decoder only → Validate using Automatic Mask Generator (grid-based points) → Select checkpoint with best validation metrics
- **Design tradeoffs:** Large vs. small model variant: Authors chose sam2_hiera_large for best segmentation quality despite slower inference and higher memory requirements. Alternative: use sam2_hiera_small for faster inference at potential accuracy cost. Freezing vs. full fine-tuning: Freezing encoder reduces memory/compute but may limit adaptation to highly specialized domains. Full fine-tuning requires significantly more resources.
- **Failure signatures:** High count error (Cnt) with reasonable F-measure: Model is over-segmenting individual tesserae into multiple regions. Low recall with high precision: Model is too conservative, missing damaged or partial tesserae. Validation loss plateauing early: Learning rate may be too low or image encoder features insufficient for domain.
- **First 3 experiments:** 1) Baseline reproduction: Run pre-trained sam2_hiera_large on the mosaic test set without fine-tuning to establish SAM2_base metrics. Compare against reported IoU=89%, Recall=92.12%. 2) Ablation on loss components: Train two variants—(a) Dice Loss only, (b) Dice + Score Loss—to isolate the contribution of confidence calibration. Expect (b) to show better-calibrated predictions. 3) Augmentation impact: Train on original 19 mosaics without augmentation vs. full 984 augmented images. Expect significant degradation without augmentation due to overfitting on limited data.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the proposed segmentation methodology be effectively extended to handle 3D mosaic structures?
- **Basis in paper:** [explicit] The authors explicitly state in the Discussion, "Future work can also explore extensions to 3D mosaics to complement digital restoration tools."
- **Why unresolved:** The current study focuses exclusively on 2D image segmentation and does not experiment with depth data or 3D reconstruction techniques.
- **What evidence would resolve it:** Evaluation of the model's performance on 3D scans or point clouds of mosaic artworks to see if tesserae can be segmented in three dimensions.

### Open Question 2
- **Question:** To what extent can post-processing techniques improve the accuracy of overlapping or fragmented tesserae segmentation?
- **Basis in paper:** [explicit] The paper suggests a future update includes "refining post-processing techniques, such as adjusting inaccurate segmentations by merging fragmented tesserae or better separating overlapping ones."
- **Why unresolved:** The current implementation relies on raw mask predictions, which may struggle with the visual ambiguity of damaged or closely packed tiles without algorithmic refinement.
- **What evidence would resolve it:** A comparative study of segmentation results before and after applying specific merging/separating algorithms on difficult cases.

### Open Question 3
- **Question:** Does increasing the dataset size with museum-grade images significantly enhance model robustness?
- **Basis in paper:** [explicit] The authors note that "Expanding the mosaic dataset, especially with images provided by museums, could substantially improve the robustness and generalization abilities of the model."
- **Why unresolved:** The current dataset is derived from a small set of 19 images augmented via transformations, which may limit the model's exposure to the full diversity of real-world mosaic degradation.
- **What evidence would resolve it:** Benchmarks showing performance stability when training on a larger, non-augmented corpus of high-quality museum data.

## Limitations
- The dataset size (19 original mosaics) remains relatively small despite augmentation, potentially limiting model robustness to extreme mosaic styles or damage patterns.
- The annotation process relies on expert knowledge, raising questions about reproducibility and scalability.
- The evaluation focuses primarily on quantitative metrics without extensive qualitative analysis of failure cases or real-world application constraints.

## Confidence
- **High confidence:** The quantitative improvements (IoU: 89.00% → 91.02%, Recall: 92.12% → 95.89%) are well-supported by the reported methodology and experimental setup.
- **Medium confidence:** The architectural decisions (freezing image encoder, custom loss design) are theoretically sound but lack extensive ablation studies to isolate individual contributions.
- **Medium confidence:** The benchmark comparison against prior methods is compelling, though the exact implementation details of baseline methods are not fully specified.

## Next Checks
1. **Ablation study on loss components:** Systematically evaluate the contribution of Dice Loss versus Score Loss by training variants with only Dice Loss, only Score Loss, and the combined loss to quantify the calibration benefit.
2. **Cross-domain generalization test:** Evaluate the fine-tuned model on mosaics from different historical periods or with different tesserae materials to assess domain transferability beyond the training distribution.
3. **Real-time performance validation:** Measure actual inference latency on standard hardware (not just theoretical capacity) and test the model on damaged or incomplete tesserae that commonly occur in archaeological contexts.