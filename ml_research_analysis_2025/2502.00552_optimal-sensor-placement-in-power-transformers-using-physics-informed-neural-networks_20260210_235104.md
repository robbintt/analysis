---
ver: rpa2
title: Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural
  Networks
arxiv_id: '2502.00552'
source_url: https://arxiv.org/abs/2502.00552
tags:
- temperature
- power
- transformer
- figure
- solution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study proposes a Physics-Informed Neural Network (PINN) framework
  combined with Mixed Integer Linear Programming (MILP) to determine optimal sensor
  placement for monitoring temperature inside power transformers. The approach uses
  PINNs to model heat diffusion in both 1D and 2D transformer geometries, capturing
  temperature distributions accurately.
---

# Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural Networks

## Quick Facts
- **arXiv ID**: 2502.00552
- **Source URL**: https://arxiv.org/abs/2502.00552
- **Reference count**: 40
- **Primary result**: PINN-MILP framework achieves <13% relative L2 error for transformer temperature prediction and identifies optimal sensor locations at stable points with sufficient spacing

## Executive Summary
This paper proposes a Physics-Informed Neural Network (PINN) framework combined with Mixed Integer Linear Programming (MILP) to determine optimal sensor placement for monitoring temperature inside power transformers. The approach uses PINNs to model heat diffusion in both 1D and 2D transformer geometries, capturing temperature distributions accurately. Three sensor placement optimization models are formulated, progressively adding constraints to improve sensor dispersion and coverage. The results show that the proposed method identifies sensor locations at stable temperature points while maintaining sufficient spacing, enabling efficient real-time temperature reconstruction.

## Method Summary
The method trains a PINN to solve the heat diffusion equation with transformer-specific source terms (no-load loss, load-dependent loss, and convective cooling). The PINN takes spatial coordinates, time, ambient temperature, and load factor as inputs, and outputs temperature. A composite loss function combines boundary condition enforcement and physics-informed residual minimization. After training, the PINN computes time-averaged spatial gradients to identify stable temperature points. Three MILP models are then formulated to optimize sensor placement: Model 1 clusters sensors at stable points, Model 2 adds distance constraints to prevent clustering, and Model 3 adds penalty terms for information overlap. The approach is validated in both 1D line and 2D square geometries, achieving relative L2 errors of 0.1306 and 0.0055 for overall and top-oil temperature respectively in 1D, and 0.1278 and 0.0076 in 2D.

## Key Results
- PINN achieves relative L2 errors of 0.1306 (overall temperature) and 0.0055 (top-oil temperature) in 1D geometry
- PINN achieves relative L2 errors of 0.1278 (overall temperature) and 0.0076 (top-oil temperature) in 2D geometry
- MILP Model 3 successfully enforces sensor dispersion while maintaining coverage of stable temperature regions
- 2D model requires longer training (60+ minutes) and higher collocation points (40,400) compared to 1D model

## Why This Works (Mechanism)

### Mechanism 1: Physics-Informed Residual Loss Constrains Solution Space
- Claim: Embedding the heat diffusion PDE as a loss term enables accurate temperature prediction from sparse boundary data.
- Mechanism: The PINN computes a residual f(x,t) = ρcp ∂u/∂t − k∆u − q via automatic differentiation. Minimizing MSE_f forces the network output to satisfy the PDE everywhere, not just at training points. Boundary conditions are enforced via MSE_u.
- Core assumption: The heat diffusion equation with the specified q(x,t) formulation accurately represents transformer thermal dynamics.
- Evidence anchors:
  - [abstract] "simulating and predicting the temperature conditions inside a power transformer using Physics-Informed Neural Networks"
  - [section 2.2] Equations 11-14 define residual f and composite loss MSE = λu·MSEu + λf·MSEf with λf = 10000
  - [corpus] Paper 2926 confirms PINNs are increasingly applied to transformer condition monitoring with physics-based knowledge integration.
- Break condition: If the PDE formulation doesn't capture actual heat transfer (e.g., missing convection modes, incorrect boundary conditions), residual minimization converges to physically wrong solutions.

### Mechanism 2: Time-Averaged Spatial Gradient Identifies Stable Measurement Points
- Claim: Locations minimizing |∇u| over time represent stable temperature regions optimal for sensor placement.
- Mechanism: Stable points are defined where Et∈D|∇·u(x,t)| is minimized—these are positions where temperature changes least over time. Sensors at these locations provide consistent, reliable measurements for reconstructing the full temperature field.
- Core assumption: Temperature stability correlates with information quality for field reconstruction.
- Evidence anchors:
  - [abstract] "optimal placement for temperature sensors...under the constraint of a limited number of sensors"
  - [section 2.3] "A stable point is where the temperature changes the least over time. Therefore, it is defined where the absolute value of the time-averaged temperature change...is at its minimum."
  - [corpus] Paper 74770 (arXiv:2511.15543) proposes a similar physics-informed ML framework for optimal sensor placement based on parameter estimation.
- Break condition: If temperature dynamics shift (different load profiles, ambient conditions), previously stable points may no longer be optimal.

### Mechanism 3: Progressive MILP Constraints Enforce Sensor Dispersion
- Claim: Adding distance and overlap penalties prevents sensor clustering while maintaining coverage of critical regions.
- Mechanism: Model 1 clusters sensors at stable points. Model 2 adds constraint si + sj ≤ 1 for ∥xi − xj∥ < d. Model 3 adds penalty term ci for information overlap when d1 − ∥xi − xj∥ > 0, via big-M formulation.
- Core assumption: The distance parameters d and d1 can be set appropriately based on physical sensor size and measurement overlap characteristics.
- Evidence anchors:
  - [abstract] "combining PINNs with Mixed Integer Optimization Programming"
  - [section 2.3] Equations 15-18 show progressive model development; Figure 8 demonstrates Model 1 clustering vs. Model 3 dispersion
  - [corpus] Paper 13670 (arXiv:2501.16153) discusses MILP integration with PINNs for parabolic PDEs, supporting the combined approach.
- Break condition: If d is set too large, sensors may miss critical stable regions; if d1 is mis-specified, overlap penalties may not reflect actual information redundancy.

## Foundational Learning

- **Concept: Automatic Differentiation in PINNs**
  - Why needed here: The residual f requires computing ∂u/∂t and ∆u from network outputs—this is done via automatic differentiation, not numerical finite differences.
  - Quick check question: Can you explain why autodiff gives exact gradients while finite differences introduce truncation error?

- **Concept: Heat Diffusion PDE with Source Terms**
  - Why needed here: The model embeds q(x,t) = P0 + PK(x,t) − h(u−Ta), combining no-load loss, load-dependent loss, and convective cooling.
  - Quick check question: What happens to the solution if the convective coefficient h is underestimated?

- **Concept: Mixed Integer Linear Programming (Big-M Formulation)**
  - Why needed here: Model 3 uses big-M to linearize the conditional cost ci − M(1−si) ≤ Li ≤ ci + M(1−si) for sensor placement decisions.
  - Quick check question: What is the role of penalty coefficient M=1000 in ensuring constraint satisfaction?

## Architecture Onboarding

- **Component map**: Input layer (spatial coords + time + ambient temp + load factor) -> 4 hidden layers (50 neurons each, tanh) -> Output layer (temperature) -> Loss (λu·MSEu + λf·MSEf) -> Adam optimizer -> L-BFGS-B optimizer -> MILP solver
- **Critical path**: 1) Train PINN on boundary conditions + collocation points until loss converges (~20k epochs) 2) Extract time-averaged spatial gradients ∇u from trained model 3) Run MILP optimization (Model 1/2/3) to identify sensor positions 4) Validate by comparing reconstructed temperature vs. reference
- **Design tradeoffs**: More collocation points (Nf) → higher accuracy but longer training (2D: 40400 points, ~60 min vs 1D: 20000, ~45 min); Higher λf → stronger physics enforcement but potential boundary mismatch; Larger d → better dispersion but may miss optimal stable points; Model 3 most practical but requires tuning d, d1, and M
- **Failure signatures**: Loss plateau early: learning rate too high or insufficient collocation points; Sensors cluster in Model 1: expected behavior, use Model 2 or 3; PINN diverges from reference at later times: may need longer training or more boundary enforcement; 2D training not converged: extend epochs beyond 10k
- **First 3 experiments**: 1) Replicate 1D PINN with 20000 collocation points, validate L2 error ≈0.13 matches paper; confirm top-oil error ≈0.005 2) Run Model 1 vs Model 3 optimization with nmin=5, nmax=10, d=0.05; visualize clustering vs dispersion 3) Extend 2D training to 30k-40k epochs to achieve convergence; compare loss curve to Figure 11

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Does extending the training duration and increasing collocation points fully resolve the convergence issues observed in the 2D model's Adam optimizer phase?
- **Basis**: [explicit] The authors state on Page 15 that "training with Adam has still not properly converged after 10000 epochs" and note that "to obtain more accurate and reliable estimations... it is necessary to train longer."
- **Why unresolved**: The presented 2D results utilize a model that, by the authors' own analysis, had not reached optimal convergence within the tested timeframe.
- **Evidence**: Loss function curves and L2 error metrics for the 2D model trained significantly beyond 20,000 epochs with increased collocation density.

### Open Question 2
- **Question**: How does the framework scale when applied to complex 3D transformer geometries compared to the simplified 1D and 2D domains?
- **Basis**: [inferred] The paper acknowledges that "with higher spatial dimensions the complexity of the problem increases and so does the training time" (Page 15) and currently relies on simplified shapes like lines and squares (Page 3).
- **Why unresolved**: While the method works for lower dimensions, the computational cost and stability of PINNs typically degrade in 3D spaces, which is necessary for practical deployment.
- **Evidence**: Successful training convergence and sensor placement optimization results applied to a 3D transformer geometry.

### Open Question 3
- **Question**: To what extent does the inclusion of distance constraints ($d$) and penalty costs in Model 3 cause the sensors to miss critical hotspots or unstable temperature gradients?
- **Basis**: [inferred] The paper mentions on Page 9 that forcing spacing "may cause the sensors to miss important information if $d$ is set too large," and Model 3 adds further penalty costs.
- **Why unresolved**: The study prioritizes sensor dispersion and stability but does not quantify the trade-off between sensor spread and the potential loss of information regarding localized temperature anomalies.
- **Evidence**: A sensitivity analysis comparing the temperature reconstruction error of Model 3 against Model 1 under varying load conditions.

## Limitations

- The simplified 1D and 2D geometries may not fully capture complex transformer winding geometries, limiting real-world applicability
- The model depends on accurate time-series data for ambient temperature, top-oil temperature, and load factor, which were not fully specified in the paper
- The assumption that temperature stability correlates with optimal sensor placement may not hold under varying load conditions or thermal regimes

## Confidence

- **High Confidence**: The PINN framework's ability to accurately model heat diffusion (L2 errors <0.13) and the basic MILP optimization structure are well-supported by the results and methodology.
- **Medium Confidence**: The claim that stable temperature points provide optimal sensor placement is reasonable but depends on the assumption that temperature stability correlates with measurement utility, which may vary with operating conditions.
- **Low Confidence**: The generalizability of the 1D/2D simplified geometries to actual transformer designs and the robustness of the distance-based dispersion constraints (d, d1) across different transformer types.

## Next Checks

1. **Extended Operating Conditions**: Validate the sensor placement under varying load profiles (e.g., step changes, cyclic loads) to assess whether the identified stable points remain optimal across different operating regimes.

2. **Complex Geometry Testing**: Implement the framework on a 2D cross-section with multiple cooling ducts or a 3D simplified winding geometry to evaluate whether the sensor placement approach scales to more realistic transformer designs.

3. **Real-World Data Integration**: Replace synthetic time-series data with field measurements from an operational transformer to test the framework's performance with actual ambient, top-oil, and load data, and assess the impact on sensor placement recommendations.