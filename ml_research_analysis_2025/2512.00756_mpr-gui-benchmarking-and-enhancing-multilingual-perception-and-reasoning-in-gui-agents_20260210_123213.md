---
ver: rpa2
title: 'MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning
  in GUI Agents'
arxiv_id: '2512.00756'
source_url: https://arxiv.org/abs/2512.00756
tags:
- question
- options
- answer
- type
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of cross-lingual perception and
  reasoning (P&R) performance gaps in large vision-language models (LVLMs) for GUI
  tasks. The authors propose MPR-GUI-Bench, a multilingual benchmark that systematically
  evaluates GUI agents' fine-grained P&R capabilities across eight dimensions, including
  widget function comprehension, spatial reasoning, and integrated reasoning tasks.
---

# MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents

## Quick Facts
- arXiv ID: 2512.00756
- Source URL: https://arxiv.org/abs/2512.00756
- Authors: Ruihan Chen; Qiming Li; Xiaocheng Feng; Xiaoliang Yang; Weihong Zhong; Yuxuan Gu; Zekun Zhou; Bing Qin
- Reference count: 40
- Primary result: Proposes MPR-GUI-Bench benchmark and GUI-XLI cross-lingual intervention method that improves multilingual GUI agent performance by 6.5% on average

## Executive Summary
This paper addresses the significant performance gap in large vision-language models (LVLMs) when handling cross-lingual GUI perception and reasoning tasks. The authors introduce MPR-GUI-Bench, a comprehensive multilingual benchmark that evaluates GUI agents across eight fine-grained perception and reasoning dimensions. The benchmark reveals substantial accuracy differences between English (75.3% FPR-ACC) and other languages (67.7% FPR-ACC). To address this gap, the paper proposes GUI-XLI, a training-free cross-lingual intervention method that modifies hidden states at capability-specific layers using cross-lingual memory, achieving an average 6.5% improvement in multilingual P&R capability across various LVLMs.

## Method Summary
The authors developed a two-pronged approach: first, creating MPR-GUI-Bench as a systematic evaluation framework for cross-lingual GUI agent capabilities, covering eight dimensions including widget function comprehension, spatial reasoning, and integrated reasoning. Second, they introduced GUI-XLI, a training-free cross-lingual intervention method that operates by identifying P&R capability-related layers in LVLMs and applying targeted modifications to hidden states. The method uses a cross-lingual memory component that stores representation difference vectors between English and target languages, enabling the model to better handle non-English GUI interactions without requiring retraining.

## Key Results
- LVLMs show significant performance gaps between English (75.3% FPR-ACC) and non-English languages (67.7% FPR-ACC) on GUI tasks
- GUI-XLI cross-lingual intervention improves multilingual P&R capability by 6.5% on average across various LVLMs
- The method demonstrates consistent improvements across eight evaluated languages and multiple model architectures
- Benchmark reveals specific weaknesses in spatial reasoning and integrated reasoning tasks for non-English languages

## Why This Works (Mechanism)
The GUI-XLI method works by leveraging cross-lingual memory to bridge representation gaps between English and target languages at specific layers responsible for perception and reasoning capabilities. By storing and applying difference vectors from English representations, the intervention helps LVLMs better align their understanding of GUI elements and spatial relationships across languages.

## Foundational Learning

### Cross-lingual representation alignment
- **Why needed**: LVLMs trained primarily on English data struggle with non-English GUI elements due to language-specific visual and semantic differences
- **Quick check**: Verify that representation difference vectors capture meaningful semantic distinctions between English and target language GUI descriptions

### Hidden state modification at capability-specific layers
- **Why needed**: Different P&R capabilities (widget comprehension, spatial reasoning, etc.) are processed at distinct layers in transformer architectures
- **Quick check**: Confirm that targeted layer modifications produce larger improvements than uniform modifications across all layers

### Training-free intervention methodology
- **Why needed**: Avoids computationally expensive fine-tuning while enabling rapid deployment across multiple model architectures
- **Quick check**: Ensure method works across different LVLM architectures without architectural-specific modifications

## Architecture Onboarding

### Component map
GUI-XLI -> Cross-lingual memory (English-target diffs) -> P&R layer identification -> Hidden state modification -> Enhanced multilingual output

### Critical path
1. Benchmark evaluation identifies P&R capability gaps
2. Cross-lingual memory stores representation differences
3. Layer analysis determines P&R-specific processing locations
4. Hidden state modifications applied at identified layers
5. Enhanced multilingual GUI reasoning performance

### Design tradeoffs
- **Pros**: Model-agnostic, no retraining required, immediate applicability
- **Cons**: Heuristic approach without theoretical guarantees, potential overfitting to benchmark patterns

### Failure signatures
- Minimal improvement across languages suggests incorrect P&R layer identification
- Performance degradation indicates over-aggressive hidden state modifications
- Language-specific failures point to insufficient cross-lingual memory coverage

### 3 first experiments
1. Test GUI-XLI on a held-out language family (e.g., Slavic languages) to verify generalization
2. Compare targeted layer modifications versus uniform modifications across all layers
3. Evaluate cross-lingual memory with varying representation difference calculation methods

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark focuses on eight specific languages, limiting generalizability to other language families
- May not capture all real-world GUI interaction complexities, particularly mobile versus desktop edge cases
- Cross-lingual intervention is heuristic without theoretical guarantees of optimality

## Confidence
- **High confidence**: Empirical observation of English vs. non-English performance gaps is well-supported
- **Medium confidence**: GUI-XLI intervention effectiveness relies on specific architectural assumptions
- **Medium confidence**: Benchmark coverage is comprehensive but may not be exhaustive for all practical use cases

## Next Checks
1. **Cross-language generalization test**: Evaluate GUI-XLI on additional languages from different families (Arabic, Hindi, Vietnamese) to assess robustness
2. **Real-world deployment validation**: Test benchmarked models and GUI-XLI-enhanced versions in live application scenarios
3. **Ablation study of cross-lingual memory**: Systematically evaluate individual components and representation difference calculation methods