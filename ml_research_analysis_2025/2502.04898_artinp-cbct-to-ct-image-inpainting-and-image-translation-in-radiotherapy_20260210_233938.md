---
ver: rpa2
title: 'ARTInp: CBCT-to-CT Image Inpainting and Image Translation in Radiotherapy'
arxiv_id: '2502.04898'
source_url: https://arxiv.org/abs/2502.04898
tags:
- cbct
- images
- network
- image
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of enhancing CBCT images for
  adaptive radiation therapy, particularly in complex treatments like TMLI where full-body
  visualization is critical. The proposed ARTInp framework combines image inpainting
  and CBCT-to-CT translation using a dual-network approach: a completion network fills
  anatomical gaps in CBCT volumes and a custom GAN generates high-quality synthetic
  CT (sCT) images.'
---

# ARTInp: CBCT-to-CT Image Inpainting and Image Translation in Radiotherapy

## Quick Facts
- arXiv ID: 2502.04898
- Source URL: https://arxiv.org/abs/2502.04898
- Authors: Ricardo Coimbra Brioso; Leonardo Crespi; Andrea Seghetto; Damiano Dei; Nicola Lambri; Pietro Mancosu; Marta Scorsetti; Daniele Loiacono
- Reference count: 30
- Primary result: Dual-network framework achieving MAE% below 2.5% and PSNR around 27dB on CBCT-to-CT translation

## Executive Summary
The paper addresses the challenge of enhancing CBCT images for adaptive radiation therapy, particularly in complex treatments like TMLI where full-body visualization is critical. The proposed ARTInp framework combines image inpainting and CBCT-to-CT translation using a dual-network approach: a completion network fills anatomical gaps in CBCT volumes and a custom GAN generates high-quality synthetic CT (sCT) images. Trained on a dataset of paired CBCT and CT images from the SynthRad 2023 challenge, ARTInp achieves promising results with an MAE% below 2.5% and PSNR around 27dB on a test set of 18 patients. The framework demonstrates potential for improving CBCT-based workflows in radiotherapy by providing more accurate patient anatomy visualization.

## Method Summary
ARTInp employs a dual-network architecture consisting of a completion network and a GAN-based translation network. The completion network addresses anatomical gaps in CBCT volumes through inpainting, while the GAN generates high-quality synthetic CT images. The framework was trained on paired CBCT and CT images from the SynthRad 2023 challenge dataset. The approach specifically targets the limitations of standard CBCT imaging in radiotherapy, where anatomical visualization is crucial for accurate treatment planning and adaptive therapy.

## Key Results
- Achieved MAE% below 2.5% on test dataset
- Obtained PSNR around 27dB for image quality
- Validated on 18 patient test set from SynthRad 2023 challenge

## Why This Works (Mechanism)
The dual-network approach addresses two critical challenges in CBCT imaging: anatomical gap filling and accurate tissue characterization. By separating these tasks into specialized networks, ARTInp can focus each component on its specific strength - the completion network excels at structural reconstruction while the GAN specializes in realistic tissue appearance generation. This architectural separation allows for more precise control over both geometric and intensity accuracy in the final synthetic CT images.

## Foundational Learning
- CBCT imaging principles - needed for understanding image quality limitations; quick check: compare CBCT vs CT image characteristics
- GAN architectures - needed for synthetic image generation; quick check: review GAN loss functions and training dynamics
- Radiotherapy workflow - needed for clinical context; quick check: understand TMLI treatment requirements
- Image inpainting techniques - needed for anatomical gap filling; quick check: examine different inpainting approaches
- Medical image registration - needed for paired image processing; quick check: review registration accuracy metrics
- Synthetic CT validation - needed for quality assessment; quick check: understand MAE% and PSNR calculations

## Architecture Onboarding
**Component map:** CBCT input -> Completion Network -> GAN -> Synthetic CT output
**Critical path:** CBCT volume → inpainting → translation → validation
**Design tradeoffs:** Dual-network complexity vs. performance gain, real-time applicability vs. accuracy
**Failure signatures:** Poor inpainting leading to anatomical artifacts, GAN mode collapse producing unrealistic tissue patterns
**First experiments:**
1. Test completion network on simple geometric shapes with missing regions
2. Validate GAN output with varying input noise patterns
3. Compare single vs. dual-network performance on synthetic test cases

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation metrics are limited and don't fully capture clinical utility
- No validation of downstream clinical impact or dosimetric accuracy
- No comparison with alternative architectures or baseline methods
- Potential systematic biases in training data not addressed

## Confidence
**Technical implementation:** High confidence - clear description of framework components and training methodology
**Quantitative results:** Medium confidence - metrics reported but limited validation scope
**Clinical relevance:** Low confidence - lacks actual workflow integration and dosimetric validation

## Next Checks
1. Validate performance across different anatomical regions and patient demographics beyond the SynthRad 2023 challenge dataset
2. Conduct dosimetric accuracy assessment comparing synthetic CTs against clinical ground truth for treatment planning
3. Perform head-to-head comparison with established CBCT-to-CT translation methods using identical evaluation metrics and datasets