---
ver: rpa2
title: Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market
arxiv_id: '2503.04521'
source_url: https://arxiv.org/abs/2503.04521
tags:
- inference
- edge
- revenue
- users
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses dynamic pricing for on-demand deep neural
  network (DNN) inference services in edge-AI markets. The authors propose a multi-exit
  device-edge synergistic inference framework to meet personalized performance requirements
  of AI users while maximizing revenue for AI service providers.
---

# Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market

## Quick Facts
- arXiv ID: 2503.04521
- Source URL: https://arxiv.org/abs/2503.04521
- Authors: Songyuan Li; Jia Hu; Geyong Min; Haojun Huang; Jiwei Huang
- Reference count: 40
- Primary result: Achieves approximately 60% higher revenue than state-of-the-art approaches for edge-AI inference services

## Executive Summary
This paper addresses the challenge of dynamic pricing for on-demand deep neural network (DNN) inference services in edge-AI markets. The authors propose a multi-exit device-edge synergistic inference framework that meets personalized performance requirements while maximizing revenue for service providers. The key innovation is an auction-based edge inference pricing mechanism (AERIA) that jointly optimizes DNN model partition, edge inference pricing, and resource allocation through a two-phase approach. Extensive simulations using real-world datasets demonstrate that AERIA significantly outperforms existing approaches while providing high-quality edge inference services.

## Method Summary
The AERIA mechanism operates in two phases: Phase I involves edge inference demand analysis where users solve a local optimization problem to determine their minimum resource requirements while meeting latency and accuracy constraints. Phase II implements a consensus-estimate-based competitive auction that calculates an upper bound revenue, applies randomized consensus estimation for target revenue, and uses Moulin-Shenker cost sharing to determine uniform pricing and winners. The system uses Multi-Exit DNNs to enable tasks to terminate early at shallow layers when confidence criteria are met, reducing computation overhead and enabling more efficient resource allocation.

## Key Results
- Achieves approximately 60% higher revenue compared to state-of-the-art approaches
- Provides theoretically guaranteed incentive compatibility and envy-freeness
- Maintains good competitive ratios with approximately optimal revenue
- Successfully handles personalized performance requirements through multi-exit DNN framework

## Why This Works (Mechanism)

### Mechanism 1: Multi-Exit DNN Inference for Demand Elasticity
If low-complexity tasks exit early at shallow layers, the required edge computation decreases, potentially increasing the bidding density for users. The framework deploys Multi-Exit DNNs where inference terminates when confidence criterion $\sigma$ is met, allowing simple data to bypass deep layer computation and reducing resource requests.

### Mechanism 2: Decoupling Resource Demand from Pricing
If users minimize their resource request locally before participating in the auction, the system achieves better resource utilization without revealing user utility functions. Users solve a local optimization problem to find minimal edge resources needed to meet latency and accuracy constraints, transforming a multi-dimensional bidding problem into a standard resource auction.

### Mechanism 3: Randomized Consensus Estimate for Truthfulness
If the auction uses a randomized function to set target revenue, it prevents users from manipulating price by misreporting budgets. The COCO auction calculates an upper bound revenue and applies a randomized consensus estimate function, ensuring target revenue is statistically close to optimal but independent of any single user's bid, theoretically guaranteeing Incentive Compatibility.

## Foundational Learning

- **Multi-Exit Deep Neural Networks (ME-DNNs)**: Physical substrate of the market; without understanding early exits trade accuracy for computation, one cannot model the supply side. *Quick check:* How does increasing confidence threshold $\sigma$ affect probability of exiting at shallow layer?

- **Auction Theory (Incentive Compatibility & Envy-Freeness)**: Theoretical constraints of the mechanism; AERIA works because it enforces these properties preventing market failure due to lying or unfair pricing. *Quick check:* In a truthful auction, does a user gain advantage by reporting budget lower than true value?

- **Computation-Communication Overlap in Edge Computing**: Essential for understanding latency model; partition point determines balance between local computation, transmission, and edge computation. *Quick check:* If wireless data rate drops to zero, what happens to network transmission latency and overall feasibility of edge offloading?

## Architecture Onboarding

- **Component map:** End Device -> Edge Cluster -> AI Service Provider -> Auctioneer
- **Critical path:** 1) Bidding: Client collects constraints → Solves P2 → Submits resource request and budget 2) Auction Setup: Provider filters bids < reserve price → Sorts users by density 3) Pricing: Provider runs CENTRE for target revenue → Runs REAL for winners and uniform price 4) Execution: Winners offload intermediate feature maps to Edge
- **Design tradeoffs:** Revenue vs. Fairness (chooses uniform price for envy-freeness potentially leaving money on table); Accuracy vs. Latency (stringent confidence ensures accuracy but forces deeper inference raising price and reducing likelihood of meeting latency constraints)
- **Failure signatures:** Low Competitiveness Ratio (actual revenue falls far below theoretical upper bound indicating consensus estimate parameters may be misconfigured); Auction Stagnation (randomization loop iterates excessively indicating unstable revenue bounds)
- **First 3 experiments:** 1) Baseline Validation: Replicate "Impact of System Scale" experiment using Shanghai Telecom dataset to verify ~60% revenue uplift 2) Sensitivity Analysis: Stress test Phase I optimization by varying wireless data rates to observe constraint failures 3) Truthfulness Attack: Simulate scenario where percentage of users misreport budgets to test incentive compatibility guarantee

## Open Questions the Paper Calls Out
- How can AERIA be extended to integrate multi-device co-inference, enabling end devices to collaborate on local inference tasks?
- Is the mechanism robust against users strategically misreporting their inference accuracy requirements (confidence criterion $\sigma_i$) to reduce resource requests?
- How does the competitive ratio and revenue performance change if multiple AI service providers compete independently rather than acting as a unified auctioneer?

## Limitations
- Multi-Exit DNN model fidelity depends on validation set representing runtime data distribution
- Auction parameter sensitivity requires careful calibration of randomized consensus estimate parameters
- Local optimization burden may be computationally expensive for end devices
- Wireless channel modeling uses substituted datasets without explicit path-loss definition

## Confidence

- **Revenue Maximization Claims**: Medium confidence - 60% improvement demonstrated through simulations but depends on model assumptions
- **Theoretical Guarantees**: High confidence for Incentive Compatibility and Envy-Freeness under ideal conditions; Medium confidence for competitive ratio bound
- **Multi-Exit Framework Effectiveness**: Medium confidence - early exits reduce computation but specific accuracy-resource trade-offs require validation on actual deployed models

## Next Checks

1. **Truthfulness Attack Simulation**: Implement scenario where 20-30% of users deliberately misreport budgets to test whether incentive compatibility guarantee holds under realistic manipulation attempts

2. **Distribution Shift Stress Test**: Vary input data distribution during runtime to measure how exit probabilities change and whether latency constraints are violated more frequently

3. **Auction Parameter Robustness**: Systematically vary consensus estimate parameters across multiple simulation runs to identify thresholds where competitive ratio degrades significantly or randomization loop fails to converge