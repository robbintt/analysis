---
ver: rpa2
title: 'AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping'
arxiv_id: '2512.02726'
source_url: https://arxiv.org/abs/2512.02726
tags:
- llms
- data
- anomaly
- detection
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We evaluate whether large language models (LLMs) can serve as anomaly
  detectors for journal entries in double-entry bookkeeping. Prompt-tuning general-purpose
  LLMs on heterogeneous ledger data, we compare them against traditional rule-based
  JETs and unsupervised ML baselines.
---

# AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping

## Quick Facts
- **arXiv ID:** 2512.02726
- **Source URL:** https://arxiv.org/abs/2512.02726
- **Reference count:** 15
- **Key result:** LLM prompt-tuning achieves F1 up to 0.94, precision up to 0.90 on journal entry anomaly detection.

## Executive Summary
AuditCopilot explores whether large language models (LLMs) can serve as anomaly detectors for journal entries in double-entry bookkeeping. By prompt-tuning general-purpose LLMs on structured ledger data and enriching prompts with global statistics and Isolation Forest hints, the method compares favorably against traditional rule-based and unsupervised baselines. Experiments on synthetic and anonymized real-world datasets show strong detection performance while providing interpretable explanations. The approach demonstrates AI-augmented auditing's potential to enhance both accuracy and explainability in financial anomaly detection.

## Method Summary
The method treats each journal entry as a structured JSON record and feeds it to an LLM alongside contextual cues: global dataset statistics (amount percentiles, user/account frequencies) and an Isolation Forest hint (label + anomaly score). The LLM outputs a strict JSON {"anomaly": 0|1, "explanation": "..."}. Prompt-tuning (no weight updates) is used on open-weight models (Mistral-8B, Gemma-2B/7B, Llama-3.1-8B, GPT-5-mini). Synthetic data from Gronewald et al. [2024] and anonymized real-world ledgers are evaluated, with JET-style pseudo-labeling for ground truth and Isolation Forest as baseline.

## Key Results
- Achieved F1 score up to 0.94 and precision up to 0.90 (Mistral-8B on synthetic data).
- Global statistics and Isolation Forest hints significantly reduce false positives and false negatives compared to ablations.
- Provided interpretable natural-language explanations alongside binary anomaly labels.

## Why This Works (Mechanism)
LLMs' strong pattern recognition and contextual understanding allow them to integrate structured transaction features with high-level statistical cues. Prompt-tuning leverages the model's existing reasoning without costly fine-tuning. Including global statistics gives the LLM a broader view of normal vs. anomalous ranges, while the Isolation Forest hint anchors its predictions in an established unsupervised baseline, improving precision and recall.

## Foundational Learning
- **Double-entry bookkeeping:** Every transaction affects two accounts (debit/credit); anomaly detection must respect this balance.
  - *Why needed:* Ensures features and rules match accounting reality.
  - *Quick check:* Verify dataset contains paired debit/credit entries and balanced amounts.
- **Prompt-tuning vs. fine-tuning:** Prompt-tuning keeps model weights frozen, only adjusting input prompts; fine-tuning updates weights.
  - *Why needed:* Reduces computational cost and preserves general knowledge.
  - *Quick check:* Confirm no model weight updates during experiments.
- **Isolation Forest:** Unsupervised tree-based method isolating anomalies by randomly splitting features; outputs anomaly scores/labels.
  - *Why needed:* Provides heuristic labels and scores to guide LLM predictions.
  - *Quick check:* Train IF on features, extract per-instance labels and scores.
- **JET rules:** Traditional rule-based heuristics for detecting accounting anomalies (not detailed in paper).
  - *Why needed:* Baseline for anomaly labeling in synthetic data.
  - *Quick check:* Implement or obtain JET rule set for pseudo-labeling.
- **Structured JSON prompting:** Formatting inputs and outputs as strict JSON for deterministic LLM parsing.
  - *Why needed:* Ensures consistent, machine-readable responses.
  - *Quick check:* Validate all LLM outputs match {"anomaly": 0|1, "explanation": "..."} schema.

## Architecture Onboarding

**Component map:** Dataset (synthetic/real) -> Preprocess (features, stats, IF hints) -> Prompt (JSON template + context) -> LLM inference -> Parse JSON output -> Evaluate (P/R/F1/FP/FN/TN)

**Critical path:** Input transaction → Compute global stats & IF hint → Construct prompt → LLM inference → JSON parsing → Anomaly classification

**Design tradeoffs:** Prompt-tuning preserves model generality but may limit task-specific adaptation; global stats improve recall but require careful computation; IF hints boost precision but depend on baseline quality.

**Failure signatures:**
- Removing global statistics: sharp rise in false negatives (FN 6→306).
- Removing IF hints: spike in false positives (FP 32→1973).
- Invalid LLM outputs: parsing failures or schema mismatches.

**First experiments:**
1. Run LLM inference with and without global statistics; compare recall.
2. Run with and without IF hints; monitor false positive counts.
3. Test different LLM decoding settings (temperature, top_p) to minimize invalid JSON outputs.

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic data used for main evaluation; real-world ledger is unavailable for independent validation.
- JET-based pseudo-labeling and exact Isolation Forest hyperparameters not documented, limiting exact replication.
- Performance may depend on prompt engineering and decoding settings, which are not fully specified.

## Confidence

- **High confidence:** Core claim that prompt-tuned LLMs achieve strong anomaly detection (F1 up to 0.94, precision up to 0.90) on structured journal entry data.
- **Medium confidence:** Impact of global statistics and IF hints, contingent on dataset-specific implementation.
- **Low confidence:** Generalizability to real-world datasets, given only synthetic data tested and real ledger unavailable.

## Next Checks
1. Obtain the Gronewald et al. [2024] synthetic dataset and document its exact feature schema and anomaly labeling mechanism; if necessary, implement JET-based pseudo-labeling to approximate anomalies.
2. Reconstruct the full prompt context (including global statistics and Isolation Forest hints) and run LLM inference with open-weight models; compare precision, recall, and F1 scores with and without each contextual component.
3. Validate the robustness of LLM outputs by logging and analyzing invalid JSON responses, adjusting decoding parameters (temperature, max_tokens, top_p), and applying retry/fallback strategies as needed.