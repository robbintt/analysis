---
ver: rpa2
title: Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture
arxiv_id: '2507.01701'
source_url: https://arxiv.org/abs/2507.01701
tags:
- agents
- blackboard
- agent
- lbmas
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a blackboard-based multi-agent system (bMAS)
  that allows LLM agents with various roles to share information and dynamically collaborate
  through a blackboard interface. Agents are selected based on the current blackboard
  content, and the selection-execution cycle repeats until consensus is reached.
---

# Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture

## Quick Facts
- arXiv ID: 2507.01701
- Source URL: https://arxiv.org/abs/2507.01701
- Authors: Bochen Han; Songmao Zhang
- Reference count: 22
- Key outcome: Blackboard-based multi-agent system (bMAS) with competitive benchmark performance using fewer tokens than state-of-the-art methods

## Executive Summary
This paper introduces a novel blackboard-based multi-agent system (bMAS) architecture that enables dynamic collaboration among LLM agents through a shared blackboard interface. The system selects and executes agents based on blackboard content until consensus is reached, allowing flexible problem-solving without predefined workflows. The authors implement LbMAS with predefined roles (planner, decider, critic, cleaner, conflict-resolver) and dynamic expert generation. Experiments show competitive performance on commonsense knowledge, reasoning, and math datasets while using fewer tokens than both static and dynamic MAS baselines.

## Method Summary
The paper proposes bMAS, a blackboard-based multi-agent system where LLM agents with various roles share information and collaborate dynamically through a blackboard interface. The architecture consists of a blackboard for information sharing, agents selected based on current blackboard content, and a control unit that manages the selection-execution cycle. The system continues this cycle until consensus is reached. The authors implement LbMAS, a concrete bMAS with predefined agents (planner, decider, critic, cleaner, conflict-resolver) and dynamic expert generation capabilities. The approach demonstrates competitive performance on commonsense knowledge, reasoning, and math datasets compared to state-of-the-art static and dynamic MASs while using fewer tokens.

## Key Results
- LbMAS achieves competitive performance on commonsense knowledge, reasoning, and math datasets
- System demonstrates superior token efficiency compared to state-of-the-art static and dynamic MASs
- Blackboard architecture and control unit identified as key components for token efficiency through ablation studies
- Shows potential for complex, dynamic problem-solving without requiring predefined workflows

## Why This Works (Mechanism)
The blackboard architecture enables dynamic information sharing and collaboration among agents with different roles, allowing the system to adapt to problem requirements without rigid workflows. Agents are selected based on blackboard content, ensuring relevance to current problem state. The consensus mechanism ensures quality control while the control unit manages the selection-execution cycle efficiently. This approach reduces redundancy and improves token efficiency compared to traditional multi-agent systems.

## Foundational Learning
- **Blackboard Architecture**: Shared information space enabling dynamic collaboration - needed for flexible agent coordination; quick check: verify blackboard state changes between agent executions
- **Consensus Mechanism**: Quality control process ensuring agreement among agents - needed for reliable output; quick check: monitor consensus iterations and success rates
- **Dynamic Agent Selection**: Context-aware agent activation based on blackboard content - needed for efficient problem-solving; quick check: analyze agent selection patterns across different problem types
- **Control Unit**: Central coordination managing the selection-execution cycle - needed for system orchestration; quick check: verify control unit properly terminates upon consensus
- **Token Efficiency**: Measuring computational resource usage - needed for practical deployment; quick check: compare token usage across different problem complexities
- **Predefined Agent Roles**: Specialized functions (planner, decider, critic, etc.) - needed for systematic problem decomposition; quick check: validate each agent's contribution to final output

## Architecture Onboarding

Component Map:
Blackboard <- Agents (Planner, Decider, Critic, Cleaner, Conflict-resolver) <- Control Unit <- Problem Input

Critical Path:
Problem Input -> Control Unit selects agent -> Agent executes using blackboard -> Blackboard updated -> Control Unit checks consensus -> Repeat until consensus or timeout

Design Tradeoffs:
The system trades flexibility for efficiency, allowing dynamic problem-solving without predefined workflows while maintaining token efficiency through targeted agent selection. The blackboard architecture enables loose coupling between agents but requires careful consensus management.

Failure Signatures:
- Consensus not reached: Indicates agent disagreement or insufficient information on blackboard
- Excessive token usage: Suggests inefficient agent selection or redundant computations
- Agent selection loops: Points to control unit issues or blackboard state instability
- Quality degradation: May indicate poor agent role definition or consensus mechanism weakness

First Experiments:
1. Single-agent baseline test to establish performance floor
2. Static agent configuration test to compare against dynamic selection
3. Consensus mechanism stress test with conflicting inputs

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Lack of public code release preventing independent replication
- Evaluation limited to benchmark datasets without real-world application testing
- Consensus mechanism limitations and failure modes not thoroughly addressed
- Comparison with state-of-the-art methods could include more diverse baselines and metrics

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Core architecture design effectiveness | High |
| Token efficiency improvements from ablation studies | High |
| Benchmark dataset performance claims | Medium |
| Scalability to complex real-world problems | Low |
| Robustness across different agent configurations | Low |

## Next Checks

1. Release implementation code and conduct third-party replication studies across additional benchmark datasets and problem domains
2. Perform extensive testing of consensus mechanism behavior under adversarial or noisy conditions, including systematic failure mode analysis
3. Evaluate system performance on real-world tasks beyond synthetic benchmarks, measuring both solution quality and computational efficiency in practical scenarios