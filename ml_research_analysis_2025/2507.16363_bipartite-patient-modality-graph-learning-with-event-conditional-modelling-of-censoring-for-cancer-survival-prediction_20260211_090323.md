---
ver: rpa2
title: Bipartite Patient-Modality Graph Learning with Event-Conditional Modelling
  of Censoring for Cancer Survival Prediction
arxiv_id: '2507.16363'
source_url: https://arxiv.org/abs/2507.16363
tags:
- survival
- data
- prediction
- censored
- censurv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces a bipartite patient-modality graph learning
  approach with event-conditional modeling of censoring for cancer survival prediction.
  The method addresses two key challenges: handling censored data more effectively
  and maintaining robustness in modality-missing scenarios.'
---

# Bipartite Patient-Modality Graph Learning with Event-Conditional Modelling of Censoring for Cancer Survival Prediction

## Quick Facts
- **arXiv ID:** 2507.16363
- **Source URL:** https://arxiv.org/abs/2507.16363
- **Reference count:** 27
- **Primary result:** Mean C-index of 0.708, outperforming best SOTA by 3.1% on 5 cancer datasets

## Executive Summary
This paper addresses two critical challenges in cancer survival prediction: handling censored data more effectively and maintaining robustness in modality-missing scenarios. The authors propose a bipartite patient-modality graph learning approach that models patient-modality relationships through a graph structure and uses complete-incomplete alignment to extract modality-agnostic features. The method also introduces an event-conditional modeling of censoring (ECMC) module that dynamically selects reliable censored samples using momentum-based confidence scores and incorporates them as uncensored data during training. Evaluated on 5 TCGA cancer datasets, the approach achieves a mean C-index of 0.708, outperforming the best state-of-the-art method by 3.1%.

## Method Summary
The method uses a bipartite patient-modality graph (BPMG) where patient nodes connect to modality nodes (pathological, genomic, clinical). Three independent GraphSAGE models encode modality graphs, with hyperedge attention pooling for fusion. A Siamese Graph Neural Network processes both complete and incomplete versions of the BPMG (the latter simulated via edge dropout) with a complete-incomplete alignment loss to enforce modality-agnostic features. The ECMC module selects high-confidence censored samples using dynamic momentum accumulation confidence (DMAC) and upgrades their status to uncensored with imputed survival times. The model is trained with Adam (lr=0.00003) for 120 epochs, with ECMC disabled during the first 60 epochs (preheating).

## Key Results
- Achieves mean C-index of 0.708 across 5 cancer datasets, outperforming best SOTA by 3.1%
- ECMC module improves mean C-index of 8 baseline methods by 1.3% across the same datasets
- Demonstrates excellent robustness across various modality-missing scenarios
- Maintains good balance between computational cost and predictive performance

## Why This Works (Mechanism)

### Mechanism 1: Complete-Incomplete Alignment for Modality-Agnostic Features
- **Claim:** Aligning representations of complete and incomplete multimodal data forces the model to learn modality-agnostic features, improving robustness when data is missing.
- **Mechanism:** Uses a Siamese GNN to encode both complete and incomplete bipartite graphs, minimizing distance between patient embeddings with loss $L_{Cia}$.
- **Core assumption:** There exists a shared underlying survival risk signal independent of specific modalities that can be isolated via contrastive-like alignment.
- **Evidence anchors:** Abstract mentions "complete-incomplete alignment strategy to explore modality-agnostic features"; Section 2.2 states model should focus on shared features; related work on ModalSurv supports difficulty of multimodal fusion.
- **Break condition:** If alignment loss is ignored or edge dropout rate doesn't match inference-time missingness distribution, embedding space may fragment.

### Mechanism 2: Event-Conditional Modelling of Censoring (ECMC)
- **Claim:** Selectively upgrading high-confidence censored samples to uncensored status increases effective training signal.
- **Mechanism:** ECMC identifies censored samples where model is consistently confident about risk ranking, updates their status from censored to event occurred, and assigns survival time based on local risk optimization.
- **Core assumption:** Censored patients with high predicted risk likely experienced the event shortly after censoring time, providing more informative gradient than standard Cox partial likelihood.
- **Evidence anchors:** Abstract mentions "selects reliable censored data... and incorporates them as uncensored data into training"; Section 2.3 describes iterative process; corpus evidence on dependent censoring supports difficulty of naive handling.
- **Break condition:** If imputed survival times are significantly inaccurate, this could introduce label noise that degrades calibration.

### Mechanism 3: Dynamic Momentum Accumulation Confidence (DMAC)
- **Claim:** Aggregating confidence scores over time dampens noise of single-epoch predictions, providing stable selection criterion for data relabeling.
- **Mechanism:** DMAC calculates confidence based on stability of sample's risk ranking across epochs using $\tau(t) = \lambda\tau(t-1) + (1-\lambda)p(t)$.
- **Core assumption:** Prediction consistency equates to prediction correctness or reliability.
- **Evidence anchors:** Section 2.3 explains use of momentum due to confidence fluctuation; ablation study shows C-index drops from 0.708 to 0.667 without DMAC; corpus evidence is weak on specific momentum mechanisms.
- **Break condition:** If model converges slowly or oscillates, momentum parameter may lag, failing to identify reliable samples until late training.

## Foundational Learning

- **Concept: Censored Data & Cox Proportional Hazards**
  - **Why needed here:** Paper attempts to "fix" information loss from censored patients; understanding why standard regression cannot handle "event happened after time T" labels is crucial for understanding Cox loss and ECMC mechanism.
  - **Quick check question:** If a patient is censored at time $t=10$, does the model know they survived exactly until 10, or only that they survived at least until 10? (Answer: Only that they survived at least until 10)

- **Concept: Bipartite Graphs**
  - **Why needed here:** BPMG structure is fundamental to understanding how model handles missing edges (missing modalities); understanding this structure is key to grasping the complete-incomplete alignment strategy.
  - **Quick check question:** In a bipartite graph connecting Patients to Modalities, can two Patient nodes connect directly to each other? (Answer: No)

- **Concept: Label Noise / Semi-Supervised Learning**
  - **Why needed here:** ECMC effectively treats censored data as weakly supervised data and pseudo-labels it; understanding how pseudo-labeling introduces bias is critical for debugging training loop.
  - **Quick check question:** What happens to model performance if pseudo-labels (imputed survival times) are systematically optimistic (imputing times that are too long)?

## Architecture Onboarding

- **Component map:** Pathological patches (KimiaNet) -> GraphSAGE encoder -> Hyperedge attention pooling -> Bipartite Patient-Modality Graph -> Siamese GNN -> Linear head for survival risk prediction -> ECMC module (plugin)

- **Critical path:** Complete-Incomplete Alignment Loss ($L_{Cia}$); if not weighted correctly ($\beta$), model fails to generalize to missing modalities. Second critical path is Warmup Stage (Epochs 0-60), where ECMC is disabled to allow model stabilization before flipping censored labels.

- **Design tradeoffs:** Robustness vs. Precision (alignment loss forces robustness but may dilute modality-specific signals); Sample Size vs. Label Quality (ECMC increases effective uncensored sample size but risks introducing incorrect survival times)

- **Failure signatures:** Training Instability (sudden spikes in Cox loss after Epoch 60 indicate low-confidence/noisy sample selection); Missing Modality Collapse (C-index drops significantly when modality dropped during inference indicates alignment failure); Overfitting to Censored Data (model predicts all high-risk patients as dying immediately at censoring time indicates over-aggressive ECMC)

- **First 3 experiments:**
  1. Ablation on Alignment: Run CenSurv with and without $L_{Cia}$ loss on dataset with 50% artificially dropped modalities
  2. ECMC Sensitivity: Measure MAE of imputed survival times vs. ground truth using artificially censored uncensored data
  3. Hyperparameter $\lambda$: Sweep momentum parameter in DMAC to assess impact on reliable sample selection

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability of ECMC across cancer types with different censoring patterns remains unproven
- Robustness gains may be dataset-specific given evaluation on only TCGA datasets
- Mechanism assumes high-confidence predictions from censored data reliably indicate true event occurrence, which may not hold for all clinical scenarios

## Confidence

**Major Uncertainties:**
- Generalizability across cancer types with different censoring patterns
- Dataset-specific nature of robustness gains
- Assumption about high-confidence predictions reliably indicating event occurrence

**Confidence Labels:**
- **High Confidence:** Bipartite graph architecture and complete-incomplete alignment strategy are well-defined with supporting ablation results
- **Medium Confidence:** ECMC mechanism's improvement is validated but assumption about momentum-based confidence needs clinical validation
- **Low Confidence:** Long-term stability of pseudo-labeling approach and behavior with different censoring mechanisms beyond TCGA datasets

## Next Checks
1. **External Validation:** Test complete method on non-TCGA cancer datasets with different censoring patterns to verify robustness claims
2. **ECMC Sensitivity Analysis:** Systematically vary momentum parameter Î» and selection thresholds to quantify stability of pseudo-label quality
3. **Clinical Calibration Study:** Evaluate whether model's risk predictions align with actual clinical outcomes across different modality combinations, particularly when using ECMC-updated samples