---
ver: rpa2
title: 'JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection
  Attacks'
arxiv_id: '2509.13266'
source_url: https://arxiv.org/abs/2509.13266
tags:
- graph
- node
- attack
- janus
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of stealthy node injection attacks
  against Graph Neural Networks (GNNs), where attackers add malicious nodes to graphs
  to degrade model performance while avoiding detection. The key challenge is balancing
  attack effectiveness with stealthiness, as existing methods often rely on indirect
  proxy metrics or focus only on local structures, leading to the problem of local
  myopia.
---

# JANUS: A Dual-Constraint Generative Framework for Stealthy Node Injection Attacks

## Quick Facts
- arXiv ID: 2509.13266
- Source URL: https://arxiv.org/abs/2509.13266
- Reference count: 13
- Authors: Jiahao Zhang, Xiaobing Pei, Zhaokun Zhong, Wenqiang Hao, Zhenghao Tang
- Primary result: JANUS outperforms existing methods on eight datasets, achieving high attack success rates while maintaining superior stealthiness against defenses

## Executive Summary
This paper addresses the challenge of stealthy node injection attacks against Graph Neural Networks (GNNs), where attackers add malicious nodes to graphs while avoiding detection. The key innovation is JANUS, a dual-constraint generative framework that simultaneously ensures local authenticity and global consistency. By using Optimal Transport for local feature alignment and mutual information maximization for global semantic consistency, JANUS achieves superior attack effectiveness while maintaining stealthiness. Experiments demonstrate significant improvements over existing methods across multiple datasets and defense mechanisms.

## Method Summary
JANUS is a reinforcement learning-based framework that models node injection as a sequential decision process. It employs a dual-constraint approach: local stealthiness via Optimal Transport to align injected node features with authentic feature distributions, and global consistency via mutual information maximization between structured latent variables and generated structures. The framework uses a generator (Actor) to create malicious nodes and edges, a discriminator with auxiliary network for MI maximization, and a critic for value estimation. The entire system is trained end-to-end under black-box conditions, balancing attack effectiveness with stealthiness metrics.

## Key Results
- JANUS achieves significantly higher attack success rates than baseline methods on eight benchmark datasets
- The framework maintains superior stealthiness metrics (lower Closest Attribute Distance and Smoothness scores) compared to existing approaches
- JANUS demonstrates robustness against advanced defense mechanisms like GNNGuard and FLAG, maintaining high effectiveness even under these protections
- The dual-constraint approach effectively addresses the "local myopia" problem present in previous methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal Transport-based alignment produces injected node features that are geometrically credible samples on the local feature manifold, improving stealthiness.
- Mechanism: For each injected node feature x_inj, JANUS computes the Wasserstein-2 distance to an empirical reference distribution P_orig sampled from high-degree benign nodes in the target's K-hop neighborhood. The Sinkhorn algorithm with entropy regularization provides differentiable gradients. This directly measures transport cost rather than relying on proxy metrics like homophily.
- Core assumption: The feature distribution of high-degree benign neighbors represents an authentic local manifold that defines "natural" features for that region of the graph.
- Evidence anchors:
  - [abstract]: "At the local level, JANUS uses Optimal Transport to align feature distributions, ensuring injected nodes blend seamlessly with the graph's feature manifold."
  - [section]: "Local Stealthiness Strategy" (Page 3) defines the OT loss as L_OT = (1/N_inj) Σ W²₂(P_inj, P_orig), where W₂ is Wasserstein-2 distance.
  - [corpus]: No direct corpus validation for this specific mechanism in neighboring papers.
- Break condition: If the K-hop neighborhood contains mostly adversarial or outlier nodes, the reference distribution will not represent authentic features, causing alignment to fail.

### Mechanism 2
- Claim: Mutual information maximization between structured latent codes and generated structures forces the generator to learn high-level semantic patterns, preventing local myopia.
- Mechanism: JANUS introduces structured latent codes c = [c_disc, c_cont] (discrete semantic categories + continuous attributes). An auxiliary network Q within the discriminator is trained to recover c from graph-level embeddings g of the generated subgraph. Minimizing L_info = -E[log Q(c|g)] maximizes I(c; g), compelling the generator to produce structures whose semantics are predictable from the latent codes—meaning they follow learned patterns from the original graph.
- Core assumption: The original graph's structural semantics can be disentangled into interpretable latent factors that generalize to new injected structures.
- Evidence anchors:
  - [abstract]: "At the global level, it employs structured latent variables and mutual information maximization to ensure injected structures conform to the graph's semantic patterns."
  - [section]: "Latent Coding" (Page 4) describes the InfoGAN-inspired formulation and L_info loss.
  - [corpus]: Related work "Towards Backdoor Stealthiness in Model Parameter Space" discusses stealthiness via latent representations, but not this specific MI mechanism.
- Break condition: If the auxiliary network Q fails to learn meaningful c→g mappings (e.g., due to insufficient training data or overly complex graph patterns), the generator receives no useful gradient signal for semantic consistency.

### Mechanism 3
- Claim: Modeling injection as a sequential MDP optimized via Actor-Critic RL enables joint optimization of attack effectiveness and dual stealthiness constraints under black-box conditions.
- Mechanism: The generator serves as the Actor (policy π_θ), producing actions a_t = (x_inj, e_inj). The Critic V_φ estimates state values. The unified loss L_G = L_policy + λ_OT·L_OT + L_info balances: (1) attack reward (misclassification rate increase), (2) local stealthiness (OT alignment), and (3) global stealthiness (MI constraint). This end-to-end training avoids gradient-dependent white-box assumptions.
- Core assumption: Attack effectiveness and stealthiness are not fundamentally opposed; better stealthiness enables more effective attacks by evading detection and finding naturally deceptive vectors.
- Evidence anchors:
  - [abstract]: "The framework models the attack as a sequential decision process, optimized by a reinforcement learning agent."
  - [section]: "RL-Driven Attack Optimization" (Page 4-5) defines the MDP formulation and unified loss.
  - [corpus]: "Let Graph Be the Go Board" (G²A²C, cited in paper) also uses RL for black-box attacks but lacks dual constraints.
- Break condition: If reward signals are sparse (few successful misclassurations), the policy gradient has high variance; Critic may fail to provide useful advantage estimates.

## Foundational Learning

- Concept: Optimal Transport / Wasserstein Distance
  - Why needed here: The local stealthiness mechanism relies on W₂ distance to quantify how "far" injected features are from the authentic manifold. Understanding coupling matrices and Sinkhorn regularization is essential for debugging the L_OT term.
  - Quick check question: Can you explain why Wasserstein distance is preferred over KL divergence when distributions have non-overlapping support?

- Concept: Variational Mutual Information Maximization (InfoGAN)
  - Why needed here: The global constraint uses I(c; g) maximization to enforce semantic consistency. Understanding the variational lower bound via the auxiliary network Q is critical for implementing and tuning L_info.
  - Quick check question: Why does maximizing I(c; g) encourage disentangled representations, and what role does the auxiliary network play?

- Concept: Actor-Critic Reinforcement Learning
  - Why needed here: The entire framework is trained as an MDP with policy gradients. Understanding advantage functions (A_t = R_t - V_φ(s_t)), value loss, and the interplay between Actor and Critic is necessary for debugging training instability.
  - Quick check question: What is the bias-variance tradeoff in advantage estimation, and how does the Critic reduce variance compared to REINFORCE?

## Architecture Onboarding

- Component map:
  - Graph → State s_t (K-hop subgraph) → Latent encoder → Latent code c → Generator → Action a_t (x_inj, e_inj) → Environment (G, M) → Next state s_{t+1}, reward r_t → Discriminator/D → Auxiliary network Q → Critic V_φ

- Critical path:
  1. Sample target node → construct K-hop subgraph state s_t
  2. Latent encoder samples c from context-aware distribution
  3. Generator produces x_inj (via Gumbel-Softmax for discrete features) and samples e_inj from softmax distribution
  4. Execute injection → environment returns r_t (increase in classification loss + bonus for misclassification)
  5. Compute L_OT for x_inj, L_info from discriminator, and L_policy from advantage
  6. Update Generator, Critic, and Discriminator alternately (Algorithm 1)

- Design tradeoffs:
  - **λ_OT hyperparameter**: Controls attack effectiveness vs. local stealthiness. Paper uses grid search [0.1, 1.0]. Higher λ_OT improves stealthiness but may reduce misclassification rate if over-constrained.
  - **Latent code dimensions**: c_disc dimension = number of classes; c_cont dimension = 15 (paper default). Larger dimensions capture more semantics but increase optimization difficulty.
  - **Injection budget**: Single-node single-edge is most challenging; larger budgets increase effectiveness but risk detection via global anomaly accumulation.

- Failure signatures:
  - **High CAD (Closest Attribute Distance)**: Local OT alignment failing; check if reference distribution P_orig is being sampled correctly from valid neighborhoods.
  - **Clustered injected nodes in t-SNE**: Global MI constraint failing; check if auxiliary network Q is learning meaningful c→g mappings.
  - **Low attack success rate despite high stealthiness**: Policy may be too conservative; reduce λ_OT or increase attack reward scaling.
  - **Training instability (oscillating losses)**: Generator-Discriminator imbalance; try lower discriminator learning rate (paper uses 1e-5 vs. 1e-4 for generator/critic).

- First 3 experiments:
  1. **Ablation on λ_OT**: Run JANUS with λ_OT ∈ {0.1, 0.3, 0.5, 0.7, 1.0} on Citeseer. Plot attack success rate vs. CAD to find Pareto frontier. Compare against ablation variants (w/o local, w/o global) to validate each constraint's contribution.
  2. **Reference distribution sensitivity**: Compare three sampling strategies for P_orig: (a) high-degree K-hop neighbors (paper default), (b) random K-hop neighbors, (c) global random nodes. Measure CAD and misclassification rate to verify the high-degree assumption.
  3. **Defense robustness test**: Evaluate JANUS against GNNGuard and FLAG on Citeseer and OGB-Products (following Table 3). Confirm that dual-constraint stealthiness maintains >55% misclassification rate under GNNGuard, and analyze which defense mechanisms (attention reweighting vs. adversarial training) are more effective against JANUS.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does JANUS scale to significantly larger graphs (millions of nodes) given the computational complexity of Optimal Transport and reinforcement learning training?
- Basis in paper: [inferred] The largest dataset tested (OGB-Products) uses only 10,494 nodes, and the Sinkhorn algorithm for OT has known scalability challenges. No runtime or memory analysis is provided.
- Why unresolved: The paper does not analyze computational complexity or provide empirical scaling studies.
- What evidence would resolve it: Runtime and memory benchmarks on graphs with 100K+ nodes, plus asymptotic complexity analysis of each component.

### Open Question 2
- Question: What is the transferability of JANUS-generated attacks across different GNN architectures beyond the tested two-layer GCN?
- Basis in paper: [inferred] The paper evaluates only against a GCN victim model and mentions surrogate model divergence as a limitation of prior gradient-based methods, but does not test JANUS's transferability to GAT, GraphSAGE, or other architectures.
- Why unresolved: Transferability experiments are limited to defense models, not alternative victim architectures.
- What evidence would resolve it: Attack success rates when JANUS attacks are generated against one architecture and deployed against different GNN types.

### Open Question 3
- Question: How robust is JANUS against detection methods specifically designed to identify the structural patterns introduced by the global mutual information constraint?
- Basis in paper: [inferred] The paper demonstrates effectiveness against GNNGuard and FLAG, but more sophisticated detectors targeting the specific signatures of OT-aligned features or MI-maximized structures remain untested.
- Why unresolved: Only two defense mechanisms are evaluated, neither specifically designed to detect JANUS-style attacks.
- What evidence would resolve it: Detection AUC scores from specialized detectors trained to identify JANUS-generated injection patterns.

### Open Question 4
- Question: What theoretical guarantees, if any, can be established for the stealthiness bounds achieved by the dual-constraint mechanism?
- Basis in paper: [inferred] The paper provides only empirical stealthiness metrics (CAD, Smoothness, t-SNE visualization) without theoretical analysis of when or why the constraints ensure undetectability.
- Why unresolved: The framework relies on empirical validation; no formal analysis connects the OT and MI constraints to provable stealthiness.
- What evidence would resolve it: Formal bounds relating Wasserstein distance and mutual information objectives to detection probability under specific threat models.

## Limitations
- Requires careful hyperparameter tuning, particularly for the λ_OT balance parameter, which may not generalize well across different graph domains
- Sequential injection strategy, while more stealthy, could be computationally expensive for large graphs with many injection targets
- Effectiveness against adaptive defenders who specifically target dual-constraint approaches remains unproven

## Confidence
- **High confidence**: The OT-based local stealthiness mechanism (Mechanism 1) is technically sound and well-supported by the mathematical formulation and experimental results showing improved CAD scores.
- **Medium confidence**: The mutual information maximization for global consistency (Mechanism 2) is theoretically justified but relies on assumptions about latent code learnability that may not hold for all graph types.
- **Medium confidence**: The RL-based joint optimization (Mechanism 3) effectively balances multiple objectives, though the reward design could be sensitive to specific GNN architectures.

## Next Checks
1. Conduct cross-dataset generalization tests to evaluate JANUS performance when training and testing on different graph types, measuring whether the learned latent codes and OT alignments transfer effectively.
2. Perform ablation studies on the mutual information constraint to determine if the same global consistency can be achieved through alternative regularizers, isolating whether MI maximization is essential or if simpler methods suffice.
3. Test against adaptive defenses that explicitly model dual-constraint attack patterns, such as defenses that combine anomaly detection with robust training to see if JANUS's stealthiness holds under active defense adaptation.