---
ver: rpa2
title: Angular Regularization for Positive-Unlabeled Learning on the Hypersphere
arxiv_id: '2512.06785'
source_url: https://arxiv.org/abs/2512.06785
tags:
- learning
- unlabeled
- positive
- angular
- positives
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses positive-unlabeled (PU) learning by introducing
  AngularPU, a geometry-driven framework that operates on the unit hypersphere using
  cosine similarity to a learnable prototype vector. The method avoids explicit negative
  modeling by encouraging unlabeled embeddings to disperse uniformly over the sphere
  via an angular regularizer, while aligning labeled positives toward the prototype.
---

# Angular Regularization for Positive-Unlabeled Learning on the Hypersphere

## Quick Facts
- arXiv ID: 2512.06785
- Source URL: https://arxiv.org/abs/2512.06785
- Reference count: 40
- Primary result: AngularPU achieves SOTA or near-SOTA PU learning performance using hyperspherical embeddings and prototype-based classification without explicit negative modeling.

## Executive Summary
This paper introduces AngularPU, a novel framework for positive-unlabeled (PU) learning that operates on the unit hypersphere using cosine similarity to a learnable prototype vector. The method avoids explicit negative modeling by encouraging unlabeled embeddings to disperse uniformly over the sphere via an angular regularizer, while aligning labeled positives toward the prototype. Theoretical analysis supports the Bayes-optimality of angular decision rules and the stability of prototype learning under von Mises-Fisher assumptions. Experiments on CIFAR-10, STL-10, SVHN, and ADNI datasets demonstrate that AngularPU achieves state-of-the-art or near-state-of-the-art performance in recall and F1 score, particularly in scarce-positive regimes, while maintaining simplicity and interpretability through its single-stage, end-to-end design.

## Method Summary
AngularPU maps embeddings to the unit hypersphere and classifies samples based on their angular distance to a learnable prototype vector. The method uses a two-term loss: a prototype alignment term for labeled positives and an angular regularization term that encourages uniform dispersion of unlabeled embeddings over the sphere. This regularizer is implemented via pairwise angular differences, approximated using batched matrix operations for efficiency. Theoretical analysis establishes that angular decision rules are Bayes-optimal under certain class-conditional distributions and that prototype learning is stable under von Mises-Fisher assumptions. The method is trained end-to-end without explicit negative samples, making it particularly suitable for PU scenarios where negatives are absent or difficult to identify.

## Key Results
- Achieves state-of-the-art or near-state-of-the-art performance on CIFAR-10, STL-10, SVHN, and ADNI datasets in recall and F1 score metrics.
- Outperforms traditional PU methods and recent contrastive learning approaches, especially in scarce-positive regimes.
- Ablation studies confirm the importance of the uniformity regularizer and angular margin in improving separation and robustness.
- Demonstrates superior computational efficiency and interpretability compared to complex PU learning baselines.

## Why This Works (Mechanism)
The method leverages the geometric properties of the hypersphere to implicitly model negative samples without explicit negative labeling. By encouraging unlabeled embeddings to disperse uniformly over the sphere, the method creates a natural separation between positives (clustered around the prototype) and negatives (spread across the sphere). The angular decision rule based on cosine similarity to the prototype provides a simple yet theoretically justified classification boundary. The uniformity regularizer acts as a surrogate for negative modeling, creating a structured embedding space that facilitates discrimination without requiring labeled negatives.

## Foundational Learning
- **Hyperspherical embeddings**: Representing data on the unit hypersphere constrains distances to angular measures, which is crucial for the cosine similarity-based classification. Quick check: Verify embeddings have unit norm after transformation.
- **von Mises-Fisher distribution**: Assumes directional data clusters around a mean direction on the sphere. Why needed: Provides theoretical justification for prototype stability and angular decision rules. Quick check: Validate that positive samples approximately follow vMF distribution.
- **Positive-Unlabeled learning**: Learning from only positive and unlabeled data without explicit negative labels. Why needed: Addresses scenarios where negative labels are expensive, unavailable, or ambiguous. Quick check: Confirm evaluation uses PU-specific metrics (F1, recall).
- **Angular margin**: Introduces separation between decision boundary and prototype. Why needed: Improves robustness and prevents overfitting to noise. Quick check: Compare performance with and without margin in ablation studies.
- **Pairwise angular regularization**: Enforces uniform dispersion of unlabeled samples. Why needed: Creates implicit negative modeling without explicit negative labels. Quick check: Measure uniformity of unlabeled embeddings on the sphere.

## Architecture Onboarding

### Component Map
Input Embeddings -> Unit Sphere Mapping -> Prototype Network -> Loss Computation -> Angular Regularizer -> Gradient Update

### Critical Path
Embeddings → Sphere Mapping → Prototype Alignment + Angular Regularization → Loss → Backpropagation → Prototype Update

### Design Tradeoffs
- Single prototype vs. multiple prototypes: Simplicity and stability vs. ability to handle multi-modal positives
- Pairwise vs. alternative uniformity regularizers: Better theoretical properties vs. computational efficiency
- Angular vs. Euclidean distance: Geometric interpretability vs. potential loss of information

### Failure Signatures
- Poor separation between positive cluster and uniform background
- Prototype instability during training
- Sensitivity to angular margin hyperparameter
- Degraded performance when positive distribution is highly multi-modal

### First Experiments
1. Visualize embedding distributions on the sphere for labeled positives and unlabeled samples to verify separation.
2. Perform ablation study removing the angular regularizer to quantify its impact on performance.
3. Test robustness across different angular margin values to identify optimal settings.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the single-prototype assumption be relaxed to handle multi-modal positive distributions without sacrificing the method's simplicity and stability?
- Basis in paper: [explicit] The conclusion states: "it assumes that positive embeddings form a single dominant directional mode... Future work will explore explicit vMF mixtures to better handle more complex or strongly multi-modal positive distributions."
- Why unresolved: The current formulation uses one learnable prototype μ, which may fail when positives cluster in multiple distinct directions on the hypersphere.
- What evidence would resolve it: Experiments on datasets with known multi-modal positive structures, comparing single-prototype vs. mixture-of-vMF formulations on F1/recall metrics.

### Open Question 2
- Question: How does AngularPU perform when the negative distribution violates the uniformity or isotropy assumptions underlying the theoretical analysis?
- Basis in paper: [inferred] Proposition 4.1 and Remark 1 assume uniform or rotation-invariant negative distributions. Real-world negatives may cluster or exhibit structure, yet this is not empirically tested.
- Why unresolved: The theoretical justification relies on negatives being dispersed, but no experiments systematically vary negative distribution structure.
- What evidence would resolve it: Controlled experiments with synthetically structured negative distributions (e.g., clustered, anisotropic) measuring degradation in AUC and F1 scores.

### Open Question 3
- Question: Can the angular formulation be effectively adapted to semi-supervised or open-set settings where partial negative labels become available?
- Basis in paper: [explicit] The conclusion explicitly identifies this: "Another direction is adapting the angular formulation to semi-supervised or open-set settings where negative sampling becomes partially available."
- Why unresolved: The current method is designed for pure PU settings; integrating limited negative supervision requires modifying the loss formulation and decision boundary.
- What evidence would resolve it: Extension of AngularPU to semi-supervised PU settings with varying proportions of labeled negatives, compared against hybrid PU-PN baselines.

### Open Question 4
- Question: What are the practical scalability limits of the O(|U|²) pairwise regularizer term for very large unlabeled datasets?
- Basis in paper: [inferred] The paper claims the regularizer is "efficiently implemented via batched matrix operations" and scales linearly with dataset size under fixed batches, but provides no empirical analysis of memory/runtime at scale.
- Why unresolved: Quadratic batch complexity may limit maximum batch sizes, potentially affecting gradient quality and regularization effectiveness.
- What evidence would resolve it: Scaling experiments reporting memory usage, training time, and performance metrics across orders of magnitude increases in unlabeled set size.

## Limitations
- Assumes positive samples form a compact cluster around a prototype while unlabeled samples are uniformly distributed, which may not hold in all real-world scenarios.
- Theoretical guarantees rely on idealized conditions (known class-conditional distributions and von Mises-Fisher assumptions) rarely met in practice.
- Empirical validation limited to image datasets and a single medical dataset; broader domain applicability remains untested.
- Method's sensitivity to hyperparameters such as the angular margin and regularization strength is not fully characterized.
- Computational overhead of enforcing uniformity on the sphere is not discussed in detail.

## Confidence
- **High** confidence in theoretical framework and Bayes-optimality claims, supported by rigorous mathematical analysis.
- **Medium** confidence in empirical superiority, given specific data assumptions and evaluation settings on limited datasets.
- **Low** confidence in scalability claims without empirical validation on large-scale datasets.

## Next Checks
1. Test AngularPU on non-image domains (e.g., text or tabular data) to assess generalizability.
2. Conduct robustness analysis under varying levels of class imbalance and label noise.
3. Perform ablation studies to quantify the impact of the angular margin and uniformity regularizer on performance and convergence.