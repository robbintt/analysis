---
ver: rpa2
title: Optimizer Dynamics at the Edge of Stability with Differential Privacy
arxiv_id: '2512.19019'
source_url: https://arxiv.org/abs/2512.19019
tags:
- sharpness
- privacy
- training
- stability
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates how differential privacy (DP) modifies optimization
  dynamics in deep learning by comparing Gradient Descent and Adam against their DP
  variants. DP introduces per-example gradient clipping and Gaussian noise, which
  alter curvature and stability patterns observed in non-private training.
---

# Optimizer Dynamics at the Edge of Stability with Differential Privacy

## Quick Facts
- arXiv ID: 2512.19019
- Source URL: https://arxiv.org/abs/2512.19019
- Reference count: 29
- This work investigates how differential privacy (DP) modifies optimization dynamics in deep learning by comparing Gradient Descent and Adam against their DP variants.

## Executive Summary
This paper examines how differential privacy alters optimization dynamics in deep learning by comparing standard optimizers with their differentially private variants. The study tracks sharpness (maximum Hessian eigenvalue) and loss evolution across learning rates and privacy budgets. Results show that DP substantially reshapes stability dynamics: DP-GD exhibits privacy-dependent stability thresholds rather than fixed 2/η boundaries, while DP-Adam causes raw and preconditioned sharpness to plateau together below the AEoS threshold. These findings reveal that DP induces distinct, privacy-dependent stability regimes that differ qualitatively from classical patterns, highlighting the unpredictability introduced by DP in neural network optimization.

## Method Summary
The study compares optimization dynamics of Gradient Descent vs DP-Gradient Descent and Adam vs DP-Adam on a 3072→200→200→10 fully connected network with tanh activations trained on a CIFAR-10 subset (5,000 examples). Sharpness (maximum Hessian eigenvalue) and preconditioned sharpness are tracked using power iteration. DP settings include ε∈{16, 32, 64}, δ=10⁻⁵, clipping norm C=3.0 using Opacus with ghost clipping and RDP accounting. Experiments run for up to 5,000 epochs with early stopping at 99% training accuracy.

## Key Results
- DP noise injection typically suppresses sharpness growth relative to non-private training, especially at stronger privacy guarantees (smaller ε)
- DP-GD sharpness becomes jointly governed by learning rate and privacy budget, creating privacy-dependent stability thresholds
- DP-Adam causes raw and preconditioned sharpness to plateau together below the AEoS threshold, unlike non-private Adam where raw sharpness continues growing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DP noise injection typically suppresses sharpness growth relative to non-private training, especially at stronger privacy guarantees (smaller ε).
- Mechanism: Gaussian noise calibrated to achieve (ε, δ)-DP perturbs the update direction at every step, pushing trajectories toward flatter regions of the loss landscape and potentially halting curvature growth before reaching classical breakeven points.
- Core assumption: The noise magnitude scales with privacy strength, so smaller ε → larger noise → stronger flattening effect.
- Evidence anchors:
  - [abstract] "DP generally reduces the sharpness and can prevent optimizers from fully reaching the classical stability thresholds"
  - [section 4.3] "smaller ε values result in earlier flattening and substantially lower sharpness, consistent with stronger noise-induced flattening"
  - [corpus] Limited direct corpus support; neighboring papers focus on optimizer design rather than DP-specific sharpness dynamics.
- Break condition: If learning rate is very large combined with weak privacy (large ε), sharpness may exceed non-private thresholds, reversing the suppression effect.

### Mechanism 2
- Claim: The final sharpness under DP is jointly governed by learning rate (η) and privacy budget (ε), creating privacy-dependent stability thresholds rather than fixed 2/η boundaries.
- Mechanism: DP clipping bounds gradient magnitudes while noise injects stochasticity; their interaction with step size determines whether the optimizer stabilizes below, near, or above classical thresholds.
- Core assumption: The stabilization point emerges from the coupled effect of clipping sensitivity and noise scale rather than either component alone.
- Evidence anchors:
  - [abstract] "larger learning rates and privacy budgets approaching, and sometimes exceeding, these thresholds"
  - [section 5.1] "sharpness under DP-GD becomes jointly governed by the learning rate and the privacy budget... the stabilization point shifts with each (η, ε) pair"
  - [corpus] Not directly addressed in corpus neighbors.
- Break condition: If clipping bound C is set extremely large or small, the (η, ε) coupling may weaken or dominate differently.

### Mechanism 3
- Claim: DP-Adam causes raw and preconditioned sharpness to plateau together below the AEoS threshold, unlike non-private Adam where raw sharpness continues growing.
- Mechanism: Clipping and noise constrain the gradient statistics that Adam's preconditioner accumulates, coupling the raw and preconditioned curvature measures and preventing the divergent growth pattern seen in standard AEoS.
- Core assumption: The DP-modified gradients alter both the first and second moment estimates in Adam, changing how the preconditioner rescales curvature.
- Evidence anchors:
  - [abstract] "DP-Adam's raw and preconditioned sharpness plateau together below the AEoS threshold"
  - [section 4.4] "both raw and preconditioned sharpness remain far below the non-private AEoS thresholds... the two curves plateau together"
  - [corpus] Corpus neighbor "DP-MicroAdam" mentions adaptive optimizers in DP settings but does not address sharpness coupling.
- Break condition: If training continues far beyond the experimental horizon (5000 epochs), preconditioned sharpness may eventually approach modified thresholds.

## Foundational Learning

- Concept: Edge of Stability (EoS) — the regime where sharpness (maximum Hessian eigenvalue) approaches and oscillates near 2/η despite classical theory predicting divergence.
  - Why needed here: The paper frames all findings relative to EoS/AEoS behavior; without this baseline, DP's "altered dynamics" cannot be interpreted.
  - Quick check question: For learning rate η=0.1, what is the EoS stability threshold? (Answer: 2/0.1 = 20)

- Concept: Differential Privacy (ε, δ)-DP — a guarantee that any single record's presence changes output probabilities by at most e^ε, with failure probability δ.
  - Why needed here: Understanding how noise scale depends on ε and δ is essential for interpreting why stronger privacy (smaller ε) suppresses sharpness more.
  - Quick check question: Does smaller ε mean stronger or weaker privacy? (Answer: Stronger privacy; smaller ε → more noise required)

- Concept: Preconditioned Sharpness — the maximum eigenvalue of P^(-1)H, where P is Adam's diagonal preconditioner built from gradient second moments.
  - Why needed here: Adam's AEoS behavior is defined by preconditioned sharpness stabilizing at the threshold while raw sharpness grows; DP changes this coupling.
  - Quick check question: In non-private Adam, which sharpness measure stabilizes at the AEoS threshold—raw or preconditioned? (Answer: Preconditioned sharpness)

## Architecture Onboarding

- Component map:
  - CIFAR-10 data -> Subsampling (5,000 examples) -> FC network (3072→200→200→10, tanh) -> Optimizer (GD/Adam/DP variants) -> Power iteration (sharpness estimation) -> Logging (loss, sharpness metrics)

- Critical path:
  1. Choose (ε, δ, C) → determines noise multiplier σ via RDP accounting
  2. Set learning rate η → jointly determines stabilization threshold with ε
  3. Monitor sharpness trajectory → identify whether DP-modified EoS/AEoS regime emerges (flattening vs. progressive sharpening)

- Design tradeoffs:
  - **Higher ε (weaker privacy)** → faster convergence, higher sharpness, closer to non-private thresholds
  - **Lower η + lower ε** → flatter solutions but potentially trapped in local minima; very slow convergence
  - **Large C (weak clipping)** → gradients less distorted but requires more noise to maintain same privacy; may increase sharpness
  - **Adam vs. GD**: Adam's preconditioner adds complexity; DP-Adam shows coupled raw/preconditioned sharpness behavior not seen in DP-GD

- Failure signatures:
  - Sharpness plateaus far below expected threshold with monotonic loss → likely over-regularized (ε too small or η too small)
  - Sharpness exceeds non-private threshold substantially → check if ε is very large (weak privacy) combined with large η
  - Loss barely decreases over many epochs → DP noise dominating signal; consider increasing ε or batch size, or training longer

- First 3 experiments:
  1. **Baseline replication**: Run non-private GD and Adam on CIFAR-10 subset with the paper's architecture (200-200 tanh FCN), confirming EoS and AEoS sharpness trajectories match Figure 1.
  2. **Privacy sweep at fixed η**: For DP-GD with η=0.1, sweep ε ∈ {16, 32, 64} and plot sharpness vs. epoch; verify that higher ε yields higher stabilized sharpness and approaches/exceeds 2/η threshold.
  3. **Learning rate scaling under DP**: For DP-Adam with ε=32, sweep η ∈ {10^-3, 3.2×10^-4, 10^-4} and track both raw and preconditioned sharpness; confirm they plateau together below AEoS threshold and that larger η produces higher sharpness (reversing non-private scaling).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the distinct individual effects of gradient clipping versus Gaussian noise injection on sharpness evolution and stability thresholds?
- Basis in paper: [explicit] The conclusion states that future work will "isolate the separate effects of clipping and noise on sharpness and stability."
- Why unresolved: The standard DP-SGD mechanism applies clipping and noise simultaneously, making their individual contributions to the observed flattening or stabilization of sharpness confounded in the current results.
- What evidence would resolve it: Ablation studies training models with only gradient clipping (no noise) and only noise injection (no clipping) to measure their independent impact on the maximum Hessian eigenvalue.

### Open Question 2
- Question: Do mini-batch DP-SGD and momentum-based variants exhibit an Edge of Stochastic Stability (EoSS), or do they follow the distinct stability regimes observed in full-batch DP-GD?
- Basis in paper: [explicit] The conclusion identifies the need to "investigate batch size effects... mini-batch DP-SGD, and different momentum types" to compare against the full-batch dynamics presented.
- Why unresolved: The study focuses on full-batch settings to align with classical EoS theory, leaving the interaction between DP noise, mini-batch stochasticity, and momentum unexplored.
- What evidence would resolve it: Experiments tracking Batch Sharpness and preconditioned sharpness for DP-SGD across varying batch sizes and momentum coefficients.

### Open Question 3
- Question: Do small learning rates eventually reach a privacy-modified stability threshold given sufficient training time, or is their sharpness growth permanently arrested?
- Basis in paper: [explicit] The authors propose to "explore longer training to determine whether smaller LRs eventually approach DP-modified thresholds."
- Why unresolved: In the experiments, smaller learning rates converged too slowly within the 5,000-epoch budget to determine if they would stabilize or continue progressive sharpening.
- What evidence would resolve it: Extending training duration significantly for small learning rate configurations to observe if sharpness eventually plateaus or crosses the stability threshold.

### Open Question 4
- Question: Do the observed privacy-induced stability regimes, such as the coupled flattening in DP-Adam, persist when scaling to modern architectures and datasets?
- Basis in paper: [explicit] The conclusion lists plans to "test scaling to larger models and datasets."
- Why unresolved: The findings rely on a small 2-layer fully connected network on a subset of CIFAR-10; it is unclear if these dynamics generalize to complex, high-dimensional landscapes like those of ResNets or Transformers.
- What evidence would resolve it: Replicating the sharpness tracking experiments on standard large-scale benchmarks using convolutional or transformer-based architectures.

## Limitations

- The study uses a small, fully-connected model on a CIFAR-10 subset, limiting generalizability to modern architectures and larger-scale problems.
- Critical hyperparameters for Adam (β₁, β₂, ϵ) and power iteration tolerance are unspecified, making exact reproduction challenging.
- The analysis relies on gradient-based sharpness estimates via power iteration without verifying convergence guarantees or stability of estimates.

## Confidence

- **High**: DP noise injection suppresses sharpness growth (Mechanism 1) - supported by multiple experimental observations and consistent with DP theory.
- **Medium**: Privacy-dependent stability thresholds (Mechanism 2) - conceptually sound but requires careful calibration; limited direct validation in corpus.
- **Medium**: DP-Adam's coupled sharpness plateau (Mechanism 3) - distinct from non-private behavior but not fully explained mechanistically; dependent on unspecified Adam hyperparameters.

## Next Checks

1. **Parameter sensitivity**: Sweep Adam's β₁, β₂ values and power iteration convergence thresholds to determine impact on sharpness coupling patterns.
2. **Architecture generalization**: Replicate experiments on a modern CNN (e.g., ResNet-18) trained on full CIFAR-10 to test whether DP-induced stability regimes persist.
3. **Convergence verification**: Implement rigorous power iteration convergence criteria and verify that estimated sharpness values are stable and reproducible across runs.