---
ver: rpa2
title: 'RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated
  Data'
arxiv_id: '2503.18385'
source_url: https://arxiv.org/abs/2503.18385
tags:
- uni00000013
- anomaly
- uni00000011
- anomalies
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RoCA is a time-series anomaly detection method designed to handle
  contaminated training data by integrating normality assumptions from one-class classification
  and contrastive learning. It introduces a novel negative-sample-free contrastive
  learning approach called "sequence contrast" and employs an outlier exposure term
  to identify and utilize latent anomalies in the training data.
---

# RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated Data

## Quick Facts
- **arXiv ID**: 2503.18385
- **Source URL**: https://arxiv.org/abs/2503.18385
- **Reference count**: 40
- **Primary result**: Achieves up to 6% improvement on AIOps datasets and 5-10% improvement on high-dimensional multivariate datasets compared to methods that do not account for contamination

## Executive Summary
RoCA introduces a novel approach to one-class time series anomaly detection that specifically addresses the challenge of contaminated training data. By integrating normality assumptions from one-class classification with contrastive learning techniques, RoCA can effectively learn normal patterns while simultaneously identifying and utilizing latent anomalies present in the training set. The method employs a unique negative-sample-free contrastive learning approach called "sequence contrast" and alternates between updating model parameters and identifying potential anomalies through an outlier exposure term.

## Method Summary
RoCA addresses the fundamental challenge in one-class anomaly detection where training data may contain unlabeled anomalies. The method alternates between two key processes: (1) updating model parameters using a combination of reconstruction loss and contrastive learning objectives, and (2) identifying potential anomalies based on temporary anomaly scores. The contrastive learning component uses a novel "sequence contrast" approach that eliminates the need for negative samples by leveraging temporal relationships within the sequence. An outlier exposure term helps the model distinguish between normal patterns and potential anomalies, allowing it to learn effectively even when the training data is contaminated with up to 30% anomalies.

## Key Results
- Achieves up to 6% improvement on AIOps datasets compared to existing one-class methods
- Demonstrates 5-10% improvement on high-dimensional multivariate datasets
- Shows superior robustness against data noise and outliers in practical applications

## Why This Works (Mechanism)
RoCA works by simultaneously learning normal patterns and identifying anomalies through an iterative optimization process. The sequence contrast mechanism captures temporal dependencies without requiring negative samples, while the outlier exposure term allows the model to distinguish between normal and anomalous patterns even when anomalies are present in the training data. This dual objective approach enables the model to build a more robust representation of normality that can withstand contamination.

## Foundational Learning
- **One-class classification**: Assumes most training data is normal and learns to identify deviations - needed to establish a baseline normality model, quick check: verify data distribution assumptions
- **Contrastive learning**: Learns representations by comparing similar and dissimilar samples - needed to capture complex temporal patterns, quick check: validate embedding quality
- **Sequence modeling**: Processes temporal dependencies in time series data - needed for capturing normal behavior patterns, quick check: test on synthetic temporal data
- **Outlier exposure**: Uses potential anomalies to improve model robustness - needed to handle contaminated training data, quick check: measure contamination detection accuracy
- **Alternating optimization**: Iteratively updates model and identifies anomalies - needed to balance learning and anomaly detection, quick check: monitor convergence behavior

## Architecture Onboarding

**Component Map**: Data Preprocessing -> Sequence Contrast Module -> Outlier Exposure Module -> Anomaly Scoring -> Model Update Loop

**Critical Path**: Input time series → Sequence embedding → Contrastive loss computation → Outlier exposure calculation → Anomaly score generation → Model parameter update

**Design Tradeoffs**: Sequence contrast eliminates need for negative samples but requires careful temporal window selection; outlier exposure improves robustness but may introduce false positives if contamination rate is high

**Failure Signatures**: Poor performance on datasets with high contamination rates (>30%), degraded accuracy when temporal patterns are non-stationary, sensitivity to window size selection

**First Experiments**: 1) Test on synthetic data with controlled contamination levels, 2) Evaluate sensitivity to window size parameter, 3) Compare performance against baseline one-class methods on clean data

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements are primarily evaluated on synthetic datasets with controlled contamination levels
- Real-world applicability across diverse industrial settings requires further validation
- The method's effectiveness on highly heterogeneous real-world applications remains unproven

## Confidence

**High confidence**: The theoretical framework for combining one-class classification with contrastive learning is well-established, and the alternating optimization approach for anomaly identification is methodologically sound.

**Medium confidence**: The performance claims of 5-10% improvement are based on specific benchmark datasets and may not generalize to all anomaly detection scenarios, particularly in highly heterogeneous real-world applications.

**Low confidence**: The robustness claims against various types of noise and contamination need broader validation across different types of time series data and contamination patterns not represented in the current evaluation.

## Next Checks
1. Conduct extensive testing on diverse real-world time series datasets from multiple domains (e.g., healthcare, finance, IoT) with varying contamination levels and types to assess generalizability.

2. Perform ablation studies to quantify the individual contributions of the sequence contrast mechanism and outlier exposure term to the overall performance improvement.

3. Evaluate the method's performance under different contamination ratios and compare against a wider range of state-of-the-art anomaly detection methods, including those specifically designed for noisy data.