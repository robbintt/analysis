---
ver: rpa2
title: 'DistillNote: LLM-based clinical note summaries improve heart failure diagnosis'
arxiv_id: '2506.16777'
source_url: https://arxiv.org/abs/2506.16777
tags:
- note
- admission
- summaries
- clinical
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'DistillNote is a framework for LLM-based clinical note summarization
  that generates admission note summaries to improve heart failure diagnosis. It employs
  three summarization strategies: one-step direct summarization, structured summarization
  that independently extracts clinical insights (chief complaint, medical history,
  exam findings, social history), and distilled summarization that further condenses
  structured summaries.'
---

# DistillNote: LLM-based clinical note summaries improve heart failure diagnosis

## Quick Facts
- arXiv ID: 2506.16777
- Source URL: https://arxiv.org/abs/2506.16777
- Authors: Heloisa Oss Boll; Antonio Oss Boll; Leticia Puttlitz Boll; Ameen Abu Hanna; Iacer Calixto
- Reference count: 40
- DistillNote achieves 79% text compression while maintaining 95.8% of baseline F1-score performance for heart failure diagnosis using LLM-based clinical note summarization

## Executive Summary
DistillNote is a framework that leverages large language models to generate condensed clinical note summaries that improve heart failure diagnosis performance. The framework employs a three-strategy approach: one-step direct summarization, structured summarization that extracts clinical insights across key domains, and distilled summarization that further condenses structured summaries. Evaluated on over 64,000 admission notes, DistillNote demonstrates that structured summaries achieve the highest diagnostic performance (AUROC 0.9149) while distilled summaries provide the best balance of compression (79%) and performance retention (95.8% F1-score).

## Method Summary
DistillNote processes clinical admission notes through three distinct summarization strategies using LLMs. The one-step strategy directly summarizes entire notes, while the structured strategy divides notes into clinical domains (chief complaint, medical history, exam findings, social history) and summarizes each independently. The distilled strategy further condenses structured summaries into concise formats. The framework was evaluated using a Mass General Brigham dataset of 64,153 admission notes, comparing heart failure prediction performance across strategies and measuring summary quality through LLM-as-judge evaluation and limited clinician validation. The divide-and-conquer approach significantly reduced hallucinations compared to one-step summarization.

## Key Results
- Structured summaries achieved the highest diagnostic performance with AUROC of 0.9149 and AUPRC of 0.9089
- Distilled summaries achieved 79% text compression while maintaining 95.8% of baseline F1-score performance
- Divide-and-conquer approach reduced hallucinations by 8.6 percentage points compared to one-step summarization

## Why This Works (Mechanism)
The framework's effectiveness stems from its structured approach to clinical note summarization, which mirrors how clinicians organize and process patient information. By dividing notes into clinically relevant domains (chief complaint, medical history, exam findings, social history), the LLM can focus on extracting key information from each section without being overwhelmed by the complexity of full notes. The distillation stage further enhances efficiency by removing redundancy and focusing on the most diagnostically relevant information. This approach leverages the LLM's ability to understand clinical context while mitigating hallucination risks through domain-specific processing.

## Foundational Learning
- **Clinical note structure**: Understanding how admission notes are organized into clinical domains is essential for effective summarization
  - Why needed: Clinical notes follow specific structures that guide information extraction
  - Quick check: Verify the four domains (chief complaint, medical history, exam findings, social history) are consistently present
- **Heart failure diagnostic features**: Knowledge of key clinical indicators for heart failure diagnosis
  - Why needed: Ensures summaries capture diagnostically relevant information
  - Quick check: Confirm summaries retain key symptoms like dyspnea, edema, and orthopnea
- **LLM hallucination patterns**: Understanding how LLMs generate false information in clinical contexts
  - Why needed: Critical for evaluating summary reliability and safety
  - Quick check: Measure hallucination rates across different summarization strategies
- **Clinical decision support integration**: How summarized notes can be incorporated into diagnostic workflows
  - Why needed: Ensures practical utility beyond academic performance metrics
  - Quick check: Validate that summaries improve diagnostic accuracy in clinical decision support systems
- **Evaluation methodology for clinical summaries**: LLM-as-judge and clinician validation approaches
  - Why needed: Proper evaluation ensures summaries are both accurate and clinically useful
  - Quick check: Compare LLM and clinician evaluations for consistency

## Architecture Onboarding

Component map: Clinical notes -> One-step/Structured/Distilled summarization -> LLM evaluation -> Heart failure prediction

Critical path: Raw clinical notes → Structured summarization → Heart failure prediction → AUROC/AUPRC evaluation

Design tradeoffs: Structured summarization provides highest diagnostic performance but requires more complex processing; one-step is simpler but prone to hallucinations; distilled offers best compression but may lose some diagnostic detail.

Failure signatures: Hallucinations in one-step summaries; loss of critical diagnostic information in distilled summaries; domain misalignment in structured summaries.

Three first experiments:
1. Compare diagnostic performance of one-step vs structured summaries on a held-out test set
2. Measure hallucination rates across all three summarization strategies using a clinical fact-checking dataset
3. Evaluate clinician agreement with LLM-as-judge assessments on summary quality

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to single institutional dataset from Mass General Brigham, potentially limiting generalizability
- LLM-as-judge evaluation may not fully capture clinical nuances compared to comprehensive human validation
- Computational efficiency and real-world implementation costs of the three-stage distillation process were not evaluated

## Confidence
- **High confidence**: Structured summarization superiority for AUROC/AUPRC metrics based on consistent experimental results
- **Medium confidence**: 95.8% F1-score maintenance claim based on LLM-as-judge evaluation
- **Medium confidence**: 79% text compression achievement, though practical utility depends on downstream task performance

## Next Checks
1. Conduct multi-site validation across different healthcare systems with varying documentation practices to assess generalizability
2. Perform comprehensive clinician validation of all three summarization strategies using blinded review methodology
3. Evaluate the framework's performance on rare heart failure presentations and diverse patient populations to assess potential bias