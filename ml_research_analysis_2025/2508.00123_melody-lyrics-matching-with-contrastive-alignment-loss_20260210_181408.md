---
ver: rpa2
title: Melody-Lyrics Matching with Contrastive Alignment Loss
arxiv_id: '2508.00123'
source_url: https://arxiv.org/abs/2508.00123
tags:
- lyrics
- melody
- alignment
- rhyme
- notes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces melody-lyrics matching (MLM), a novel task
  that retrieves potential lyrics for a given symbolic melody from text sources. The
  proposed method employs a self-supervised representation learning framework with
  a contrastive alignment loss, leveraging the abundance of existing songs with paired
  melody and lyrics.
---

# Melody-Lyrics Matching with Contrastive Alignment Loss

## Quick Facts
- **arXiv ID**: 2508.00123
- **Source URL**: https://arxiv.org/abs/2508.00123
- **Reference count**: 31
- **Primary result**: MLM-CAL achieves up to 51.57% Hit@5% on Seg4 using contrastive alignment loss without alignment annotations

## Executive Summary
This paper introduces melody-lyrics matching (MLM), a novel task that retrieves singable lyrics for a given symbolic melody from text sources. The proposed method employs a self-supervised representation learning framework with contrastive alignment loss, leveraging the abundance of existing songs with paired melody and lyrics. A key contribution is the introduction of sylphone, a novel syllable-level representation that captures phonetic features and stress patterns. Experiments on the DALI dataset demonstrate that the proposed MLM-CAL method significantly outperforms baseline approaches in retrieving coherent and singable lyrics, as measured by Hit@K metrics and alignment quality metrics such as stress matching rate and rhyme density.

## Method Summary
The method uses a dual-encoder architecture with two 2-layer transformer encoders (4 heads, 256 dim, 1024 FFN, ~3.7M total params) to process melody and lyrics separately. Melody input is represented as 177-dimensional features (pitch change, duration, onset shift), while lyrics are converted to 43-dimensional sylphone vectors (vowel identity, stress level, end consonants, stopword indicator). The contrastive alignment loss replaces cosine similarity in InfoNCE with negative SDTW alignment cost, minimizing alignment cost for positive pairs and maximizing it for negatives. Length-informed regularization penalizes length mismatch between melody and lyrics sequences. Training uses batch size 32, Adam optimizer with cosine LR schedule, 20 epochs with gradient clipping, and batch-wise Z-score normalization on alignment costs.

## Key Results
- MLM-CAL achieves 51.57% Hit@5% on Seg4, significantly outperforming baseline methods
- Alignment quality metrics show superior stress matching rate and rhyme density compared to baselines
- Length-informed regularization (α=0.75 for Seg12) leads to consistent improvements in Hit@K metrics
- The method successfully retrieves coherent and singable lyrics without requiring alignment annotations

## Why This Works (Mechanism)

### Mechanism 1
Sylphone representation captures melody-lyrics correspondences better than semantic text embeddings by encoding phonetic features at syllable level. Each syllable is represented as a 43-dimensional vector combining vowel identity (15 dims), stress level (3 dims), end consonants (24 dims), and stopword indicator (1 dim). This preserves rhyme information and stress patterns that align with musical features like note duration. The core assumption is that acoustic relationships between melody and lyrics matter more than semantic content for singability.

### Mechanism 2
Contrastive alignment loss enables learning melody-lyrics correspondences without alignment annotations by jointly optimizing retrieval and alignment. Replace cosine similarity in InfoNCE with negative SDTW alignment cost. For positive pairs (same song), minimize alignment cost; for negative pairs (different songs), maximize it. Batch-wise Z-score normalization sharpens contrast between positive and negative alignment scores. The core assumption is that positive melody-lyrics pairs from same song exhibit learnable alignment patterns that generalize to unseen pairings.

### Mechanism 3
Length-informed regularization prevents trivial alignment solutions by penalizing length mismatch between melody and lyrics sequences. Add weighted term to SDTW cost based on normalized length difference. Longer segments benefit more from stronger regularization (α=0.75 for Seg12 vs α=0.5 for Seg4). The core assumption is that matching melody-lyrics pairs tend toward similar sequence lengths despite non-strict one-to-one correspondence.

## Foundational Learning

- **Dynamic Time Warping (DTW) and Soft-DTW**: Aligns variable-length sequences with non-linear temporal correspondence; soft variant provides differentiability for gradient-based learning. Quick check: Can you explain why standard DTW's argmin operation prevents backpropagation?

- **Contrastive Learning (InfoNCE)**: Core training paradigm that learns representations by pulling positive pairs together and pushing negative pairs apart in embedding space. Quick check: What happens to contrastive learning if negative samples are too similar to positive samples?

- **ARPABET Phoneme Notation**: Enables conversion of lyrics to phonetic representation; essential for building sylphone vectors with stress annotations. Quick check: How would you handle out-of-vocabulary words not in CMU Pronouncing Dictionary?

## Architecture Onboarding

- **Component map**: Melody (notes) -> 177-D feature (pitch change + duration + onset shift) -> Melody encoder; Lyrics (text) -> 43-D sylphone (vowel + stress + consonants + stopword flag) -> Lyrics encoder; Embeddings -> Cosine similarity matrix -> SDTW cost -> Length regularization -> Z-score norm -> CAL

- **Critical path**: Sylphone extraction -> Dual encoder training with CAL -> Inference: length-based pre-filtering (50%) -> DTW alignment on remaining candidates

- **Design tradeoffs**: Smaller model (3.7M params) vs. generation systems trades generation capability for efficient retrieval; Segment-level (4/8/12 lines) vs. full-song shorter segments = more training data but less structural context; Length pre-filtering at inference faster but may miss valid candidates with unusual length ratios

- **Failure signatures**: Hit@K near random baseline (0.5% for K=1%): encoder not learning meaningful representations; Extreme FEM scores (>5): alignment collapsing to many-to-one mappings; High rhyme distance with high rhyme density: retrieving rhyming lyrics but wrong structural positions

- **First 3 experiments**: Sylphone ablation: Replace with word-level embeddings or character-level; measure Hit@5% and SMR degradation on Seg4; Regularization sweep: Test α ∈ {0, 0.25, 0.5, 0.75, 1.0} across Seg4/8/12; identify optimal per-segment settings; Negative sampling strategy: Compare random shuffle vs. hard negatives (similar-length wrong lyrics) on validation loss convergence

## Open Questions the Paper Calls Out

- Can the MLM-CAL framework maintain retrieval performance when applied to large-scale, open-domain text corpora (e.g., general web text) rather than a database of existing songs?

- Is the proposed contrastive alignment framework effective when adapted for raw audio input instead of symbolic melody?

- Do the objective alignment metrics (e.g., stress matching rate) correlate with human perceptions of singability and naturalness?

- Would incorporating explicit musical features, such as beats and downbeats, significantly improve stress alignment performance?

## Limitations

- Method requires symbolic melody representations with precise note-level features, limiting applicability to audio-only sources
- Sylphone representation relies on ARPABET phoneme mapping that may not generalize to languages with different phonetic systems
- Length-informed regularization assumes positive pairs exhibit similar sequence lengths, which may not hold for all musical styles
- Evaluation corpus (DALI V2) contains Western popular music, raising questions about generalization to other genres

## Confidence

- **High Confidence**: Empirical improvements in Hit@K metrics and alignment quality (stress matching rate, rhyme density) over baseline methods are well-supported by experimental results
- **Medium Confidence**: Superiority of sylphone representation over semantic text embeddings is demonstrated within experimental context but lacks direct ablation studies
- **Low Confidence**: Claims about general applicability of contrastive alignment loss to other sequence-matching tasks lack external validation

## Next Checks

1. **Phonetic Representation Ablation**: Replace sylphone with word-level semantic embeddings (e.g., BERT) and character-level phonetic features to quantify the specific contribution of the proposed syllable representation to alignment quality and retrieval performance

2. **Cross-Genre Generalization**: Evaluate the trained model on songs from different genres (classical, folk, hip-hop) or non-Western musical traditions to assess robustness to varying melody-lyrics alignment patterns and stress conventions

3. **Negative Sampling Strategy Analysis**: Systematically compare random negative sampling against hard negative mining (e.g., selecting lyrics with similar length but from different songs) to determine optimal negative selection for CAL training stability and convergence