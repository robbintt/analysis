---
ver: rpa2
title: Learning-Based TSP-Solvers Tend to Be Overly Greedy
arxiv_id: '2502.00767'
source_url: https://arxiv.org/abs/2502.00767
tags:
- instances
- nearest-neighbor
- distribution
- density
- solvers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a statistical measure called nearest-neighbor
  density to analyze the implicit biases in learning-based TSP solvers, which tend
  to be overly greedy by always selecting the nearest neighbor nodes. The authors
  verify this behavior through experiments on instances generated from uniform and
  normal distributions, as well as real-world datasets.
---

# Learning-Based TSP-Solvers Tend to Be Overly Greedy

## Quick Facts
- **arXiv ID:** 2502.00767
- **Source URL:** https://arxiv.org/abs/2502.00767
- **Reference count:** 40
- **Primary result:** Neural TSP solvers trained on uniform data develop a "greedy" bias, preferring nearest neighbors; fine-tuning with augmented data improves generalization.

## Executive Summary
This paper reveals that learning-based TSP solvers, when trained on standard uniform random Euclidean datasets, implicitly learn a "greedy" heuristic that prioritizes nearest neighbor nodes. This behavior, quantified by the nearest-neighbor density metric (ρn), causes solvers to perform poorly on structured real-world instances. The authors propose interpretable data augmentation methods and demonstrate that fine-tuning with these augmented datasets significantly enhances solver generalization.

## Method Summary
The authors introduce a statistical measure called nearest-neighbor density (ρn) to analyze implicit biases in learning-based TSP solvers. They generate augmented datasets using distribution shifts (scale-free networks) and instance perturbations (drilling problems with parallel grid patterns). Base solvers (TSP-GNN, TSP-Transformer, POMO, Pointerformer, CycleFormer) are fine-tuned by replacing 1/4 of the original RUE training set with augmented instances. Evaluation uses tour length, Gap (%) relative to CONCORDE exact solver, and defect rate across benchmarks.

## Key Results
- Learning-based TSP solvers trained on uniform random Euclidean data exhibit a "greedy" bias, always selecting nearest neighbor nodes.
- Performance significantly degrades on structured instances (drilling problems, scale-free networks) where nearest neighbor selection is suboptimal.
- Fine-tuning with augmented data that varies ρn improves generalization, reducing performance gaps from ~30% to <1% on drilling instances.
- Achieving universal neural TSP solvers through data augmentation or ensemble methods is computationally infeasible unless P=NP.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Training on uniformly random Euclidean (RUE) datasets causes neural solvers to implicitly learn a "greedy" heuristic (preference for nearest neighbors), which degrades performance on structured instances where such heuristics fail.
- **Mechanism:** The authors demonstrate that RUE instances possess a high **nearest-neighbor density (ρn)** (empirically ≈ 0.87). In these datasets, the nearest neighbor of a node is very likely to be the optimal next step. During optimization, the network minimizes loss/reward by exploiting this high-probability correlation, overfitting to the "nearest neighbor" shortcut feature.
- **Core assumption:** The model's degradation is primarily caused by the statistical properties of the training data rather than architectural limitations.
- **Evidence anchors:** Abstract states "always choosing the nearest neighbor nodes," section 3.2.1 shows performance correlates with ρn, and mechanistic interpretability literature supports analyzing learned geometric patterns.

### Mechanism 2
- **Claim:** Fine-tuning solvers on data augmentation designed to vary ρn forces the model to abandon pure greedy heuristics and learn more robust global construction policies.
- **Mechanism:** By introducing instances where the nearest neighbor is frequently not optimal (drilling problems, scale-free networks), the correlation between proximity and optimality is weakened. The model can no longer rely on the "nearest neighbor" shortcut to minimize loss and must attend to longer-range dependencies or global structural patterns.
- **Core assumption:** The model retains sufficient plasticity during fine-tuning to learn new construction policies without catastrophic forgetting.
- **Evidence anchors:** Abstract mentions fine-tuning enhances generalization abilities, table 3 shows performance gaps dropping significantly after fine-tuning, and literature on generalizable solvers supports the need for robust principles.

### Mechanism 3
- **Claim:** A universal neural TSP solver cannot be achieved solely through data augmentation or efficient ensemble methods due to fundamental computational complexity limits.
- **Mechanism:** The authors prove that generating a complete set of hard instances covering all corner cases is computationally intractable. If one could efficiently generate all such "hard" instances to train a solver, one would effectively solve the co-NP problem of verifying non-optimality for the greedy heuristic.
- **Core assumption:** NP ≠ coNP and P ≠ NP.
- **Evidence anchors:** Section 5.1 states "no efficient complete generator unless NP = CoNP," section 5.2 states "no exact efficient algorithmic coverage unless NP = P," and the computational complexity literature supports these separations.

## Foundational Learning

- **Concept: Nearest-Neighbor Density (ρn)**
  - **Why needed here:** This is the central metric introduced to quantify "greediness" in the data, measuring the probability that a node's nearest neighbor is also its neighbor in the optimal tour.
  - **Quick check question:** If you generate a TSP instance where nodes form a perfect circle, is the ρn high or low? (Answer: High).

- **Concept: Distributional Shift / Out-of-Distribution (OOD) Generalization**
  - **Why needed here:** The paper argues that "learning" is often just memorizing the statistical biases of the training set (RUE), making OOD understanding essential to grasp why models fail on structured instances despite performing well on test sets.
  - **Quick check question:** Why does a model trained on uniform random points likely fail on a "drilling" problem where points align on parallel grid lines? (Answer: The optimal solution requires skipping the nearest neighbor to connect the grid lines efficiently, violating the model's learned bias).

- **Concept: Encoder-Decoder Construction Methods**
  - **Why needed here:** The paper focuses on "end-to-end construction algorithms" (like Pointer Networks, Transformers), requiring understanding that these models build solutions node-by-node to see why a bias toward "nearest neighbor" in the decoder step is critical.
  - **Quick check question:** In an auto-regressive decoder, if the model assigns 90% probability to the nearest neighbor at every step, what happens when the optimal tour requires a "long" jump?

## Architecture Onboarding

- **Component map:** Base Solver -> Input Coordinates -> Metric Layer (ρn calculation) -> Augmentation Module -> Fine-Tuning Loop
- **Critical path:**
  1. **Diagnose:** Calculate ρn of your current training set. If it is >0.85, your model is at risk of "Greedy Bias."
  2. **Validate:** Test your current model on "Drilling" instances. If performance collapses (Gap > 20%), the model is overly greedy.
  3. **Patching:** Implement Algorithm 2 to generate a fine-tuning dataset with ρn ranging from 0.1 to 0.9.
  4. **Fine-Tune:** Retrain the decoder policy on this mixed data.

- **Design tradeoffs:**
  - **Pure RUE Training:** Fast convergence, high benchmark scores on standard datasets, but poor real-world reliability.
  - **Augmented Training:** Slower convergence (conflicting gradients from greedy vs. non-greedy samples), potentially slightly worse performance on pure RUE data (trade-off for robustness), but essential for generalization.
  - **Model Size vs. Data:** A "Large" CycleFormer model actually performed worse on drilling instances than the base model, suggesting that scaling parameters without fixing data bias exacerbates overfitting.

- **Failure signatures:**
  - **The "Zig-Zag" Failure:** On drilling instances (parallel lines), a greedy model zig-zags frantically between lines instead of sweeping one line then the next.
  - **High RUE / Low Drilling Score:** A massive discrepancy between performance on standard validation sets vs. structured datasets indicates the "Greedy Trap."

- **First 3 experiments:**
  1. **Density Audit:** Generate 1,000 RUE instances and 1,000 instances using Algorithm 2. Calculate and plot the distribution of ρn for both. Verify that RUE is tightly clustered around 0.87 and Augmented data is wide (0.1 - 0.9).
  2. **Greedy Probe:** Take a pre-trained TSP-Transformer. Run it on a synthetic "Parallel Line" instance. Visualize the tour. Confirm if it makes sub-optimal short jumps (zig-zags) rather than long optimal jumps.
  3. **Ablation on ρn:** Fine-tune two models: Model A (fine-tuned on RUE data only) vs. Model B (fine-tuned on mixed-density Augmented data). Compare their average tour lengths on the TSPLIB95 benchmark (specifically `a280`, which has grid-like properties).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the expected nearest-neighbor density E(ρn) strictly increase with the number of nodes n, and does it converge to a value greater than 0.87 for instances generated from uniform distributions?
- **Basis:** The authors propose Conjecture 2, stating, "This conjecture could be a significant open problem in probability theory, graph theory, and combinatorial optimization."
- **Why unresolved:** While empirical results suggest an upward trend and convergence, the authors currently lack a formal mathematical proof for the asymptotic behavior of E(ρn) as n → ∞.
- **What evidence would resolve it:** A rigorous mathematical proof validating the monotonicity of the expectation and its convergence limit.

### Open Question 2
- **Question:** How can data representations or model architectures be designed to reduce neural networks' reliance on superficial statistical features (like nearest-neighbor density) when solving combinatorial optimization problems?
- **Basis:** The conclusion identifies this as a critical direction: "How to better design data representations or model architectures to reduce the network’s reliance on superficial features is another critical question..."
- **Why unresolved:** Current learning-based solvers tend to learn "shortcuts" (greedy behaviors) from the statistical properties of training data rather than the underlying combinatorial structure, causing failure on out-of-distribution instances.
- **What evidence would resolve it:** The development of a solver that maintains consistent performance across instances with varying nearest-neighbor densities without relying on extensive data augmentation.

### Open Question 3
- **Question:** How can "fair and appropriate" benchmarks be defined and constructed to effectively evaluate neural solvers on real-world optimization tasks rather than unrepresentative random distributions?
- **Basis:** The conclusion states: "Developing fair and appropriate benchmarks to evaluate neural solvers is one of our future research directions."
- **Why unresolved:** Current standard benchmarks (e.g., random uniform Euclidean) inherently possess high nearest-neighbor densities that mask the greedy biases of solvers, failing to represent complex, structured real-world scenarios.
- **What evidence would resolve it:** The creation of standardized datasets comprising instances with diverse topological structures (e.g., grid-like, scale-free) that correlate with solver robustness in industrial applications.

## Limitations

- **Theoretical bound on universality:** The paper proves that achieving a universal neural TSP solver through data augmentation or ensemble methods is computationally infeasible unless P=NP, establishing a fundamental limit on solver generalization.
- **Computational complexity of augmentation:** Generating a complete set of hard instances to cover all corner cases is NP-hard, making it impossible to create a training set that eliminates all forms of greedy bias.
- **Generalizability to other CO problems:** While the findings apply to TSP solvers, the extent to which similar greedy biases affect neural solvers for other combinatorial optimization problems (like vehicle routing or scheduling) remains unclear.

## Confidence

| Claim | Confidence |
|-------|------------|
| Neural TSP solvers develop greedy bias from uniform training data | High |
| Fine-tuning with augmented data improves generalization | High |
| Universal neural solvers via data augmentation are computationally infeasible | High |
| Nearest-neighbor density is a valid metric for measuring greedy behavior | Medium |

## Next Checks

1. **Verify ρn distribution:** Generate 1,000 RUE instances and calculate the nearest-neighbor density distribution. Confirm it clusters around 0.87 as stated in the paper.

2. **Test greedy failure mode:** Implement Algorithm 2 to generate a drilling instance with parallel grid lines. Run a pre-trained TSP-Transformer and visualize the tour to confirm if it exhibits the zig-zag failure pattern.

3. **Validate fine-tuning improvement:** Fine-tune a TSP-Transformer on mixed data (3/4 RUE + 1/4 augmented) and compare performance on TSPLIB95 benchmark instances, specifically checking if the gap on structured instances like `a280` decreases significantly.