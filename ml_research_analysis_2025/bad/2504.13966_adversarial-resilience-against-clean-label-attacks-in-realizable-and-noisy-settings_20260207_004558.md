---
ver: rpa2
title: Adversarial Resilience against Clean-Label Attacks in Realizable and Noisy
  Settings
arxiv_id: '2504.13966'
source_url: https://arxiv.org/abs/2504.13966
tags:
- setting
- realizable
- agnostic
- clean-label
- learner
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper tackles sequential learning from i.i.d. streams that\
  \ may contain an unknown number of clean\u2011label adversarial examples, allowing\
  \ the learner to abstain when uncertain and treating abstention on adversarial points\
  \ as cost\u2011free."
---

# Adversarial Resilience against Clean-Label Attacks in Realizable and Noisy Settings

## Quick Facts
- **arXiv ID:** 2504.13966  
- **Source URL:** https://arxiv.org/abs/2504.13966  
- **Reference count:** 0  
- **Primary result:** A disagreement‑based learner attains sublinear regret while tolerating any fraction α of clean‑label adversarial examples, with \(O(\sqrt{T\,\mathrm{VC}(\mathcal F)})\) regret in the realizable case and \(O((\eta+α)^{1/3}T^{2/3})\) regret for threshold functions in the agnostic (noisy) case.

## Executive Summary
The paper studies sequential learning from i.i.d. streams that may contain an unknown number of clean‑label adversarial examples. By allowing the learner to abstain on uncertain inputs—and treating abstention on adversarial points as cost‑free—the authors extend the disagreement‑based version‑space framework of Goel et al. (arXiv:2306.13119). They first correct the realizable‑setting analysis and then introduce a clean‑label adversary for the agnostic setting, proving sublinear regret bounds that hold despite stochastic label noise and adversarial contamination.

## Method Summary
The algorithm maintains a **version space** \(V_t\) of hypotheses consistent with all observed labeled data up to round \(t\). For each incoming sample \(x_t\):

1. Query every hypothesis \(h\in V_t\) for its prediction \(h(x_t)\).  
2. **Decision:**  
   - If all predictions agree, output the unanimous label.  
   - Otherwise, **abstain** (cost‑free on adversarial points).  
3. Receive the true label \(y_t\).  
4. **Prune:** Update the version space to \(V_{t+1}= \{h\in V_t : h(x_t)=y_t\}\).

In the **realizable** case the true labeling function belongs to \(\mathcal F\), guaranteeing that \(V_t\) never becomes empty. The analysis shows that the number of abstentions is bounded by the disagreement coefficient, yielding an overall regret of \(O(\sqrt{T\,\mathrm{VC}(\mathcal F)})\) independent of α.

In the **agnostic** case the authors specialize to the class of 1‑D thresholds. They define a clean‑label adversary that can insert adversarial points while the stochastic label noise follows a Bernoulli(\(\eta\)) model. By carefully tracking the shrinkage of the disagreement region under noise, they obtain a regret bound of \(O((\eta+α)^{1/3}T^{2/3})\).

## Key Results
- **Realizable setting:** Regret \(O(\sqrt{T\,\mathrm{VC}(\mathcal F)})\) while tolerating any α‑fraction of clean‑label attacks at zero cost.  
- **Agnostic (noisy) setting for thresholds:** Regret \(O((\eta+α)^{1/3}T^{2/3})\).  
- **Novelty:** First theoretical guarantees for disagreement‑based learners under clean‑label adversaries in noisy environments.  
- **Technical contribution:** Corrected the earlier realizable analysis and introduced a clean‑label adversary model compatible with stochastic noise.

## Why This Works (Mechanism)

**Mechanism 1 – Disagreement‑Based Version Space Learning**  
- **Claim:** Maintaining a version space and predicting only when all hypotheses agree filters adversarial points into disagreement regions.  
- **How:** The algorithm abstains whenever the current hypothesis set disagrees, which naturally quarantines samples that could be adversarial.  
- **Assumption:** Adversarial examples lie within the disagreement region; clean samples in that region are rare.  
- **Break condition:** If an adversary crafts points that fall outside the disagreement region, the filter fails.

**Mechanism 2 – Zero‑Cost Abstention on Adversarial Points**  
- **Claim:** Treating abstention on adversarial inputs as cost‑free lets the learner tolerate arbitrary α without increasing regret.  
- **How:** Regret is charged only for misclassifications on non‑adversarial data and for abstentions on clean data; abstaining on adversarial points incurs no penalty.  
- **Assumption:** The deployment environment accepts abstention and can identify adversarial points for accounting.  
- **Break condition:** If abstention carries operational cost or is disallowed, the guarantees no longer hold.

**Mechanism 3 – Agnostic Extension via Threshold Disagreement**  
- **Claim:** The disagreement‑based approach extends to noisy settings by defining a clean‑label adversary for random labels.  
- **How:** For threshold functions, the algorithm adapts the version‑space shrinkage to handle stochastic label noise, achieving the stated \(O((\eta+α)^{1/3}T^{2/3})\) regret.  
- **Assumption:** Noise is purely stochastic; the hypothesis class (thresholds) provides bounded disagreement regions.  
- **Break condition:** The result is proved only for thresholds; extending to richer classes may require new analysis.

## Foundational Learning
- **Version Space** – Needed to understand how the learner prunes inconsistent hypotheses after each labeled observation.  
  *Quick check:* Given hypothesis class \(H\) and labeled set \(\{(x_i,y_i)\}_{i=1}^n\), what is the version space \(V_n\)?  
- **VC Dimension** – Determines the complexity term in the regret bound; higher VC leads to looser guarantees.  
  *Quick check:* What is the VC dimension of the class of threshold functions on \(\mathbb{R}\)?  
- **Realizable vs. Agnostic Learning** – Distinguishes whether a perfect hypothesis exists (realizable) or labels are noisy (agnostic), affecting which regret bound applies.  
  *Quick check:* In the realizable setting, what assumption is made about the relationship between the true labels and the hypothesis class?  
- **Clean‑Label Adversary** – Defines the threat model where adversarial examples retain the original label but are placed to cause disagreement.  
  *Quick check:* How does a clean‑label adversary differ from a label‑flipping adversary?  
- **Disagreement Region** – The set of inputs where hypotheses in the current version space predict different labels; central to the abstention decision.  
  *Quick check:* For a version space consisting of two thresholds \(t_1<t_2\), describe the disagreement region on the real line.

## Architecture Onboarding
**Component map**  
Version Space Manager → Disagreement Detector → Decision Module → Regret Tracker  

**Critical path**  
1. Receive sample \(x_t\).  
2. Query all hypotheses in the current version space for predictions on \(x_t\).  
3. If predictions are unanimous, Decision Module outputs the label; otherwise it abstains.  
4. Receive true label \(y_t\); Version Space Manager prunes inconsistent hypotheses.  
5. Regret Tracker updates cumulative cost; loop to step 1.

**Design tradeoffs**  
- **Abstention tolerance vs. coverage:** More abstention improves robustness but reduces usable predictions.  
- **Hypothesis class complexity:** Richer classes increase expressive power but worsen regret via larger VC.  
- **Realizable vs. agnostic deployment:** Realizable guarantees are stronger but require the data to be perfectly representable by the class.

**Failure signatures**  
- *Empty version space* → data not realizable or adversarial fraction too high.  
- *Linear regret growth* → version space not shrinking; possible hypothesis‑class mismatch.  
- *Excessive abstention on clean data* → under‑specified hypothesis class or underestimated noise rate.

**First 3 experiments**  
1. Implement the disagreement‑based learner for 1‑D thresholds in a realizable synthetic stream; verify \(O(\sqrt{T\,\mathrm{VC})}\) regret scaling.  
2. Inject varying fractions α of clean‑label adversarial points; confirm that regret remains independent of α.  
3. Add stochastic label noise at rate η and test the agnostic threshold bound \(O((\eta+α)^{1/3}T^{2/3})\).

## Open Questions the Paper Calls Out
**Open Question 1 – Generalizing the agnostic bound.**  
- *Question:* Can the \(O((\eta+α)^{1/3}T^{2/3})\) regret guarantee be extended beyond thresholds to richer hypothesis classes (e.g., linear separators, decision trees) while preserving the same dependence on \(\eta\) and α?  

**Open Question 2 – Cost‑aware abstention.**  
- *Question:* How do the regret guarantees change if abstention incurs a small but non‑zero cost, reflecting realistic deployment constraints?  

**Open Question 3 – Adaptive adversaries.**  
- *Question:* The current clean‑label adversary is static (chooses points before the stream). What regret bounds are achievable against an adaptive clean‑label adversary that observes past learner actions?

## Limitations
- **Class restriction:** The agnostic analysis is proved only for 1‑D threshold functions; no guarantee is provided for higher‑dimensional or non‑linear classes.  
- **Zero‑cost abstention assumption:** Guarantees rely on the ability to treat abstention on adversarial points as free; many real systems penalize abstention.  
- **Adversary model:** The clean‑label adversary is limited to inserting points that retain the true label; more powerful attacks (e.g., label‑flipping or feature‑perturbation) are not covered.  
- **Version‑space emptiness:** In non‑realizable or high‑α regimes the version space may become empty, at which point the algorithm has no fallback strategy.  
- **Dependence on disagreement coefficient:** The regret bound hides constants related to the disagreement coefficient; for complex classes these may be large, weakening practical performance.

## Confidence
- **Technical confidence:** Moderate‑high. The realizable analysis follows well‑established disagreement‑based arguments, and the agnostic bound for thresholds is derived with careful handling of stochastic noise.  
- **Scope confidence:** Low‑moderate. Because the agnostic result is limited to thresholds and assumes zero‑cost abstention, the applicability to broader settings is uncertain.  
- **Reproducibility confidence:** Moderate. The algorithmic description is concrete, but the paper provides limited pseudocode and no public implementation, requiring careful re‑implementation.

## Next Checks
1. **Re‑derive the realizable regret bound** using the disagreement coefficient to verify the \(O(\sqrt{T\,\mathrm{VC}(\mathcal F)})\) claim.  
2. **Validate the agnostic threshold analysis** by reproducing the key lemmas that bound the shrinkage of the disagreement region under stochastic noise and clean‑label contamination.  
3. **Run synthetic experiments** matching the three experiments listed in the Architecture Onboarding section to empirically confirm the theoretical scaling.  
4. **Assess sensitivity to abstention cost** by modifying the regret definition to include a small penalty for abstention and measuring the impact on the bounds.  
5. **Explore extensions** to a simple linear‑separator class to test whether the proof techniques can be adapted beyond thresholds.