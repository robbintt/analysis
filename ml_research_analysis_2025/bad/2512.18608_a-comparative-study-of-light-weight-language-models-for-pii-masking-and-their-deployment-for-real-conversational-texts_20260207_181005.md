---
ver: rpa2
title: A Comparative Study of Light-weight Language Models for PII Masking and their
  Deployment for Real Conversational Texts
arxiv_id: '2512.18608'
source_url: https://arxiv.org/abs/2512.18608
tags:
- masking
- data
- information
- text
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study tackles automated masking of Personally Identifiable\
  \ Information (PII) in conversational text, aiming to replace costly, data\u2011\
  leaking large language models with lightweight alternatives. Researchers fine\u2011\
  tuned two compact transformers\u2014T5\u2011small (encoder\u2011decoder) and Mistral\u2011\
  Instruct\u2011v0.3 (decoder\u2011only)\u2014on a curated English subset of the AI4Privacy\
  \ benchmark, first normalizing 225 noisy tags to a canonical set of 24 categories."
---

# A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts  

## Quick Facts  
- **arXiv ID:** 2512.18608  
- **Source URL:** https://arxiv.org/abs/2512.18608  
- **Reference count:** 32  
- **Primary result:** Fine‑tuned T5‑small and Mistral‑Instruct‑v0.3 achieve frontier‑level PII masking accuracy while using a fraction of the compute of large LLMs; T5‑small offers real‑time deployment with minimal performance loss.  

## Executive Summary  
The paper investigates whether compact transformer models can replace costly, privacy‑risking large language models for automated masking of personally identifiable information (PII) in conversational text. By normalizing 225 noisy tags from the AI4Privacy benchmark to 24 canonical categories and fine‑tuning T5‑small (encoder‑decoder) and Mistral‑Instruct‑v0.3 (decoder‑only), the authors demonstrate that both lightweight models surpass traditional regex and SpaCy baselines and reach performance comparable to state‑of‑the‑art LLMs. Mistral yields higher entity‑level F1 and recall but incurs roughly double the generation latency, whereas T5‑small delivers similar accuracy with far lower inference cost, enabling a real‑time Discord bot deployment. Live testing shows only modest degradation on informal messages, suggesting that well‑tuned small models can provide effective, privacy‑preserving PII masking in production settings.  

## Method Summary  
The authors curated an English subset of the AI4Privacy benchmark, consolidating 225 noisy annotation tags into a clean taxonomy of 24 PII categories. Two compact transformer architectures were fine‑tuned on this dataset: T5‑small (≈60 M parameters) using a sequence‑to‑sequence formulation that outputs masked text, and Mistral‑Instruct‑v0.3 (≈7 B parameters) in a decoder‑only instruction‑following setup. Training employed standard cross‑entropy loss, AdamW optimizer, and early stopping on a held‑out validation split. Baselines included handcrafted regex patterns (F1 ≈ 0.19) and SpaCy NER (F1 ≈ 0.13). Evaluation measured entity‑level precision, recall, and F1 across all 24 categories, as well as inference latency on a single GPU. The best‑performing model (Mistral) was further benchmarked against proprietary frontier LLMs on the same test set.  

## Key Results  
- Both T5‑small and Mistral outperform heuristic baselines (regex, SpaCy) by a large margin.  
- Mistral‑Instruct‑v0.3 achieves the highest entity‑level F1 and recall across most PII types, but its inference latency is roughly twice that of T5‑small.  
- T5‑small maintains comparable accuracy while offering substantially lower computational cost, enabling real‑time deployment in a Discord bot with only modest performance loss on informal messages.  

## Why This Works (Mechanism)  
1. **Domain‑specific fine‑tuning:** Adapting compact models on a curated, high‑quality PII annotation set aligns their internal representations with the nuances of personal data detection, overcoming the generic knowledge gaps of out‑of‑the‑box LLMs.  
2. **Canonical tag normalization:** Reducing 225 noisy tags to 24 well‑defined categories simplifies the learning problem, allowing the models to focus on discriminative features rather than memorizing idiosyncratic label noise.  
3. **Sequence‑to‑sequence masking (T5‑small):** By training the model to generate the masked version of the input, it learns to preserve surrounding context while reliably replacing PII spans, yielding structured outputs suitable for downstream pipelines.  
4. **Instruction‑following decoding (Mistral):** Framing the task as an instruction (“mask all personal data”) leverages the model’s strong zero‑shot reasoning abilities, boosting recall for rare or ambiguous entities at the cost of slower generation.  

## Foundational Learning  
| Concept | Why Needed | Quick Check |
|---------|------------|-------------|
| Transformer fine‑tuning on domain data | Aligns model weights with PII‑specific patterns that generic pre‑training does not capture. | Verify that validation loss decreases and F1 improves after a few epochs. |
| Tag taxonomy consolidation | Removes label noise, reduces class imbalance, and provides a clear supervision signal. | Count unique tags before/after normalization; ensure 24 categories remain. |
| Sequence‑to‑sequence masking | Guarantees output format (masked text) and preserves token alignment for downstream use. | Sample a few inputs and confirm that non‑PII tokens are unchanged. |
| Instruction prompting for decoder‑only models | Exploits the model’s ability to follow natural‑language commands, improving recall on edge cases. | Prompt the model with a simple “mask PII” instruction and inspect output consistency. |
| Latency‑aware model selection | Real‑time applications require bounded inference time; trade‑offs must be quantified. | Measure per‑token generation time on target hardware; compare against a threshold (e.g., 50 ms). |
| Robustness testing on informal text | Conversational data contains slang, emojis, and misspellings that can break detection. | Run a small informal test set and compute F1 drop relative to formal benchmark. |

## Architecture Onboarding  
**Component map**  
Input Text → Preprocessor (tokenization, tag normalization) → Model (T5‑small or Mistral‑Instruct‑v0.3) → Post‑processor (detokenize, apply mask tokens) → Masked Output  

**Critical path**  
The latency‑critical segment is the Model inference step; any slowdown here directly impacts real‑time responsiveness.  

**Design trade‑offs**  
- *Accuracy vs. latency*: Mistral yields higher recall but doubles latency; T5‑small offers a better speed‑accuracy balance for interactive bots.  
- *Model size vs. deployment footprint*: T5‑small fits comfortably on commodity GPUs/CPUs, whereas Mistral may require higher‑end hardware.  
- *Output structure*: T5‑small’s seq2seq output is deterministic and easier to parse; decoder‑only models may produce variable tokenization artifacts.  

**Failure signatures**  
- Sudden spikes in latency (> 2× baseline) → GPU memory pressure or batch size misconfiguration.  
- Unexpected unmasked PII → degradation in validation F1, likely due to drift in input distribution.  
- Tokenization mismatches → misaligned masks causing partial exposure of PII.  

**First three experiments**  
1. **Baseline replication** – Fine‑tune T5‑small on the normalized AI4Privacy subset and verify that entity‑level F1 matches the reported ~0.78.  
2. **Latency profiling** – Run inference on a single GPU (e.g., RTX 3080) for both models with batch size = 1; record per‑sample latency and compare against the paper’s “double latency” claim.  
3. **Informal text robustness** – Assemble a small Discord‑style chat corpus (≈200 messages) and evaluate F1 drop relative to the formal test set for both models.  

## Open Questions the Paper Calls Out  
- How well do the fine‑tuned lightweight models generalize to non‑English languages or multilingual conversational streams?  
- What are the precise hardware and batch‑size conditions under which Mistral’s latency becomes prohibitive, and can optimization (e.g., quantization) close the gap?  
- To what extent does the modest degradation observed in live Discord testing affect user privacy in high‑risk scenarios?  
- How does the performance of these compact models compare to frontier LLMs when evaluated on identical, large‑scale PII benchmarks?  
- Can further tag‑taxonomy refinements (e.g., hierarchical categories) improve recall for rare PII types without sacrificing speed?  

## Limitations  
- Generalizability is demonstrated only on an English subset; cross‑lingual performance remains untested.  
- Latency figures lack detailed hardware specifications and batch‑size context, limiting reproducibility of the cost‑accuracy trade‑off.  
- Live deployment evaluation reports “modest degradation” qualitatively; quantitative metrics for informal text are absent.  

## Confidence  
- Fine‑tuned lightweight models surpass heuristic baselines → **High**  
- Mistral achieves higher entity‑level F1/recall than T5‑small → **Medium**  
- T5‑small enables real‑time deployment with acceptable performance loss → **Medium**  
- Claims of parity with frontier LLMs → **Low**  

## Next Checks  
1. Replicate fine‑tuning on the full multilingual AI4Privacy benchmark and report cross‑lingual F1 to assess generalizability.  
2. Benchmark inference latency and memory usage for both models across multiple hardware configurations (GPU, CPU) and batch sizes, publishing a detailed comparison table.  
3. Conduct a controlled A/B test on a live chat platform, measuring exact precision, recall, and F1 for T5‑small, Mistral, and a state‑of‑the‑art LLM on informal user messages.