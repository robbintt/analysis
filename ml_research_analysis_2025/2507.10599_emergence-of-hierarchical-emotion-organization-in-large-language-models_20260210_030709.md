---
ver: rpa2
title: Emergence of Hierarchical Emotion Organization in Large Language Models
arxiv_id: '2507.10599'
source_url: https://arxiv.org/abs/2507.10599
tags:
- emotion
- emotions
- aroma
- llama
- hierarchical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models exhibit hierarchical organization of emotions
  that aligns with human psychological frameworks, with larger models showing more
  sophisticated structures. The study introduces a tree-construction algorithm that
  analyzes probabilistic relationships between emotions in LLM outputs, revealing
  that models naturally form hierarchical emotion trees.
---

# Emergence of Hierarchical Emotion Organization in Large Language Models

## Quick Facts
- arXiv ID: 2507.10599
- Source URL: https://arxiv.org/abs/2507.10599
- Authors: Bo Zhao; Maya Okawa; Eric J. Bigelow; Rose Yu; Tomer Ullman; Ekdeep Singh Lubana; Hidenori Tanaka
- Reference count: 40
- Primary result: LLMs naturally form hierarchical emotion trees that become more sophisticated with model size and reflect human psychological frameworks

## Executive Summary
This paper introduces a tree-construction algorithm that reveals large language models organize emotions in hierarchical structures aligned with human psychological frameworks. Using conditional probabilities between emotion tokens extracted from model logits, the method constructs emotion trees where larger models (up to 405B parameters) demonstrate richer and more nuanced hierarchies. The research uncovers systematic biases in emotion recognition across demographic personas, with intersectional groups showing compounded misclassification patterns that mirror human biases.

## Method Summary
The authors develop a tree-construction algorithm that analyzes probabilistic relationships between emotions in LLM outputs. They generate 5000 emotion-evoking scenarios using GPT-4o, then extract next-token probabilities over a 135-word emotion vocabulary from Llama model logits. A matching matrix C = Y^T Y captures co-occurrence probabilities between emotion pairs. The algorithm identifies hierarchical relationships by finding emotion pairs where one emotion strongly implies another but not vice versa, creating directed acyclic graphs. The method is validated on emotion data and extended to wine aromas, then applied across model scales and demographic personas.

## Key Results
- Larger LLMs (Llama 405B vs 1.5B) produce significantly richer emotion hierarchies with longer path lengths
- Tree geometry correlates strongly with emotion recognition accuracy (r = 0.84, p < 0.001)
- Systematic biases emerge across demographic personas, with intersectional identities showing compounded misclassification effects
- LLMs replicate human systematic biases, misclassifying emotions as fear for female personas and as anger for Black personas
- Emotion tree structure can serve as a reward signal for bias mitigation

## Why This Works (Mechanism)

### Mechanism 1
Conditional probabilities between emotion tokens extracted from logits reveal hierarchical semantic relationships. Given N sentences and 135 emotion words, construct matrix Y ∈ ℝ^(N×135) of next-token probabilities, then compute matching matrix C = Y^T Y. For emotion pair (a, b), emotion a is a child of b if: (1) C_ab / Σ_i C_ai > t (strong implication), and (2) C_ab / Σ_i C_ib < C_ab / Σ_i C_ai (asymmetry). This captures "a implies b but b does not fully imply a." Core assumption: Next-token probability over emotion words equals the model's estimate of how likely that emotion describes the sentence.

### Mechanism 2
Larger LLMs construct more complex, psychologically-aligned emotion hierarchies as a function of parameter count. Scaling increases representational capacity, enabling finer-grained probability distinctions between related emotions (e.g., "optimism" vs "hope" vs "joy"), yielding longer path lengths and deeper trees. Core assumption: Increased model scale leads to more nuanced probability distributions over semantically related tokens.

### Mechanism 3
Emotion tree geometry predicts emotion recognition accuracy, and both reflect demographic biases that mirror human patterns. When prompting with demographic personas (e.g., "As a [identity], I think..."), the model's conditional probability structure shifts—producing simpler trees and lower accuracy for underrepresented groups. Intersectional identities compound these effects. Core assumption: The prompt-based persona elicits the model's learned associations between demographics and emotional expression patterns from training data.

## Foundational Learning

- **Concept: Conditional probability as hierarchical implication**
  - Why needed here: Understanding why P(parent | child) > P(child | parent) encodes "specific implies general"
  - Quick check question: Given emotions A (specific) and B (general), which conditional probability should be higher if A is a child of B?

- **Concept: Logit extraction from autoregressive LMs**
  - Why needed here: The method requires extracting next-token probability distributions, not just generated text
  - Quick check question: Why can't we infer emotion hierarchies from text outputs alone?

- **Concept: Intersectional bias compounding**
  - Why needed here: Understanding why multi-attribute underrepresentation produces worse-than-additive accuracy drops
  - Quick check question: If accuracy drops 5% for attribute A alone and 3% for attribute B alone, why might the combined drop exceed 8%?

## Architecture Onboarding

- **Component map:** Prompt generator (GPT-4o) → Scenario sentences (N=5000) → Target LLM (Llama variants) → Logit extraction over 135 emotion vocabulary → Matching matrix constructor → C = Y^T Y → Hierarchy extractor → Threshold-based edge selection (t ∈ [0.1, 0.5]) → Evaluation → Tree metrics (path length, depth) + accuracy + human comparison

- **Critical path:** Scenario generation quality → Logit coverage across emotion vocabulary → Threshold selection → Valid DAG structure. If any emotion word has near-zero probability across all scenarios, hierarchy for that emotion will be disconnected.

- **Design tradeoffs:**
  - Threshold t: Lower = denser trees (more edges, potential cycles), higher = sparser trees (may miss valid relationships). Paper uses 0.1–0.5.
  - Emotion vocabulary size: 135 words from Shaver et al. balances coverage with logit extraction complexity. Custom vocabularies require re-validation against psychological frameworks.
  - Scenario count N: 5000 provides stable probability estimates; fewer scenarios increase variance in C matrix.

- **Failure signatures:**
  - Disconnected tree with many isolated nodes → Insufficient scenario diversity or tokenization issues
  - Flat tree (depth ≈ 1) → Threshold too high or model too small (e.g., GPT-2 behavior)
  - Cyclic dependencies → Threshold too low; implement DAG enforcement
  - Persona effects disappear → Prompt template not influencing attention; verify prefix is processed

- **First 3 experiments:**
  1. **Validation:** Apply algorithm to a domain with known hierarchy (e.g., wine aromas per Appendix B) to confirm tree reconstruction matches expert-annotated structure.
  2. **Scaling test:** Run hierarchy extraction across 3+ model sizes on identical scenarios; plot path length vs. parameter count to verify scaling relationship.
  3. **Persona ablation:** For 3 demographic attributes, extract hierarchies with/without persona prefix; quantify edge overlap and accuracy difference to isolate bias contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the principle of using cognitive theories as structural hypotheses be generalized to evaluate LLM representations in abstract domains beyond emotion?
- Basis in paper: The Discussion posits that using cognitive theories to evaluate LLM components "may be of independent interest to the LLM evaluations community."
- Why unresolved: The current study only validates this pipeline for emotion and wine aromas, leaving other cognitive domains unexplored.
- What evidence would resolve it: Applying the matching matrix method to reconstruct established hierarchies in other fields, such as moral foundations or semantic memory, and measuring alignment with human theories.

### Open Question 2
- Question: To what extent are the identified misclassification biases artifacts of the GPT-4o generated scenarios rather than the target LLM's internal representations?
- Basis in paper: The Limitations section notes that the scenarios "were generated by LLMs" and "may be biased," potentially misrepresenting emotions like "surprise."
- Why unresolved: The study relies entirely on synthetic data, which may inherit generation biases that obscure the true emotion understanding of the models being tested.
- What evidence would resolve it: Replicating the hierarchy extraction using a dataset of human-authored emotional scenarios and comparing the resulting tree geometries and bias profiles.

### Open Question 3
- Question: Can the geometry of the emotion tree (e.g., path length) be utilized as a reinforcement learning reward signal to mitigate intersectional biases in emotion recognition?
- Basis in paper: The paper identifies "compounding misclassifications for intersectional, underrepresented groups" and notes that tree distance measures "can also be used as a reward for the model."
- Why unresolved: While the link between tree geometry and performance is established, the paper does not test if explicitly optimizing this geometry can correct the observed biases.
- What evidence would resolve it: Fine-tuning an LLM with a loss function based on emotion tree depth or node distance specifically for minority personas and observing reduced error rates.

## Limitations
- Core algorithmic assumption that next-token probability equals semantic judgment probability lacks empirical validation
- Persona effects rely heavily on prompt engineering that may not capture implicit demographic inference
- Intersectional bias analysis does not establish whether compounding effects are multiplicative, additive, or follow other interaction patterns

## Confidence

**High Confidence:**
- LLMs can construct hierarchical emotion trees using the proposed algorithm
- Larger models produce more complex hierarchies (measured by path length)
- Systematic demographic biases exist in emotion recognition across different personas
- Human studies confirm LLMs replicate human systematic biases

**Medium Confidence:**
- Hierarchy complexity correlates with emotion recognition accuracy
- Intersectional identities show worse-than-additive bias effects
- Model behavior reflects genuine internalization of social perception patterns rather than prompt artifacts

**Low Confidence:**
- Next-token probability equals semantic judgment probability (core algorithmic assumption)
- Scaling relationships between parameter count and hierarchy complexity are causal rather than correlational
- Prompt-based persona effects generalize to implicit demographic inference

## Next Checks

1. **Hierarchy validation on ground truth:** Apply the tree-construction algorithm to a domain with known hierarchical structure (e.g., wine aroma wheel, biological taxonomies, or manually constructed emotion hierarchies) and measure reconstruction accuracy. This validates whether the conditional probability method correctly identifies parent-child relationships when ground truth is available.

2. **Cross-model consistency test:** Run the same 5000 scenarios through three different LLM families (e.g., Llama, Mistral, and GPT series) at comparable scales. Compare resulting hierarchies for edge overlap, depth, and bias patterns to determine if findings are model-specific or reflect broader LLM properties.

3. **Prompt engineering ablation:** For 3-5 demographic attributes, extract hierarchies using (a) explicit persona prefixes, (b) implicit demographic mentions within sentences, and (c) no demographic cues. Quantify differences in tree structure and accuracy to isolate the contribution of prompt engineering versus inherent model associations.