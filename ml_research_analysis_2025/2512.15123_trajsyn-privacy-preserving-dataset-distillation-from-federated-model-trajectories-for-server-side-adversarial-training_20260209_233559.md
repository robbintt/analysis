---
ver: rpa2
title: 'TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories
  for Server-Side Adversarial Training'
arxiv_id: '2512.15123'
source_url: https://arxiv.org/abs/2512.15123
tags:
- adversarial
- training
- client
- data
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of applying adversarial training
  in federated learning (FL) settings, where client data privacy constraints and limited
  computational resources on edge devices prevent both server-side and client-side
  adversarial training. The authors propose TrajSyn, a novel framework that synthesizes
  a proxy dataset from client model trajectories (sequences of model updates) without
  accessing raw client data.
---

# TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training

## Quick Facts
- **arXiv ID:** 2512.15123
- **Source URL:** https://arxiv.org/abs/2512.15123
- **Reference count:** 36
- **Primary result:** Synthesizes proxy datasets from federated model trajectories to enable server-side adversarial training without client computational burden

## Executive Summary
TrajSyn addresses a critical challenge in federated learning: implementing adversarial training while respecting client privacy and computational constraints. The framework synthesizes a proxy dataset from client model trajectories (sequences of model updates) that enables server-side adversarial training without accessing raw client data. This approach transfers the computational burden from resource-constrained edge devices to a more capable server while maintaining privacy guarantees. Experiments demonstrate consistent improvements in adversarial robustness on CIFAR-10, with adversarial accuracy increasing from 41.73% to 51.75% for ConvNet and from 35.31% to 53.09% for AlexNet compared to standard federated learning training.

## Method Summary
TrajSyn operates by collecting model trajectories from client devices during federated learning rounds. These trajectories capture the evolution of model parameters as they learn from private client data. The server uses these trajectories to synthesize a proxy dataset that approximates the statistical properties of the distributed client data. This synthetic dataset enables the server to perform adversarial training without requiring clients to compute adversarial examples locally or share their raw data. The framework leverages the insight that model trajectories contain compressed information about the underlying data distribution, which can be extracted and repurposed for adversarial training purposes.

## Key Results
- Improves adversarial accuracy from 41.73% to 51.75% on ConvNet architecture
- Improves adversarial accuracy from 35.31% to 53.09% on AlexNet architecture
- Maintains clean accuracy while achieving better balance between clean and adversarial performance

## Why This Works (Mechanism)
TrajSyn works by exploiting the information encoded in model parameter trajectories during federated learning. As models train on client data, their parameter updates reflect the statistical properties and decision boundaries learned from that data. By collecting these trajectories, the server gains access to a compressed representation of the distributed dataset without violating privacy constraints. The synthetic dataset distillation process extracts patterns from these trajectories that are sufficient for generating adversarial examples during server-side training. This approach effectively circumvents the computational limitations of edge devices while preserving the privacy guarantees essential to federated learning.

## Foundational Learning
- **Federated Learning:** Distributed training where clients keep data local but share model updates. Why needed: Framework operates within FL constraints.
- **Adversarial Training:** Training models with adversarial examples to improve robustness. Why needed: Goal is to enhance model security against adversarial attacks.
- **Dataset Distillation:** Creating compact synthetic datasets that preserve essential information. Why needed: Enables proxy dataset creation from model trajectories.
- **Model Trajectory Analysis:** Extracting information from sequences of model parameter updates. Why needed: Core mechanism for synthesizing proxy datasets.
- **Privacy-Preserving Machine Learning:** Techniques that protect data privacy during learning. Why needed: Framework maintains privacy while enabling adversarial training.

## Architecture Onboarding

**Component Map:** Client devices -> Model trajectories -> Server synthesis -> Proxy dataset -> Adversarial training

**Critical Path:** The essential workflow begins with clients training local models and sending parameter updates to the server. The server collects these model trajectories across multiple rounds, then applies distillation techniques to synthesize a proxy dataset. This synthetic dataset is used for server-side adversarial training, which generates robust model updates sent back to clients.

**Design Tradeoffs:** The framework trades computational resources between client and server while maintaining privacy. Clients avoid the heavy computational burden of adversarial training, but the server must invest in trajectory collection and dataset synthesis. The quality of synthesized datasets depends on trajectory length and diversity, creating a tradeoff between communication overhead and training effectiveness.

**Failure Signatures:** Poor adversarial robustness despite framework implementation may indicate insufficient trajectory diversity or inadequate synthesis quality. If clean accuracy degrades significantly, the proxy dataset may be introducing harmful artifacts. Communication bottlenecks could occur if trajectories are too large, suggesting a need for trajectory compression techniques.

**First Experiments:**
1. Verify trajectory collection by inspecting parameter update distributions from clients
2. Test proxy dataset synthesis quality by comparing statistics with original client data distributions
3. Validate adversarial training effectiveness by measuring robustness improvements on small test sets

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the formal privacy guarantees of TrajSyn and the potential information leakage through model trajectories. The quality and stability of synthesized datasets across different training dynamics and model architectures remains uncertain, particularly for complex real-world datasets beyond CIFAR-10.

## Limitations
- Evaluation limited to CIFAR-10 with only ConvNet and AlexNet architectures
- Privacy guarantees not formally proven, leaving questions about potential information leakage
- Uncertainty about performance with non-IID data distributions and heterogeneous client settings

## Confidence

**Major Claims Confidence Assessment:**
- Effectiveness of server-side adversarial training using synthesized datasets: **High** (demonstrated on CIFAR-10 with clear quantitative improvements)
- No additional computational burden on clients: **High** (the framework explicitly shifts computation to the server)
- General applicability to any FL deployment: **Medium** (limited empirical validation across diverse settings)

## Next Checks
1. Evaluate TrajSyn on larger, more complex datasets (e.g., ImageNet) and modern architectures (e.g., ResNet, EfficientNet) to assess scalability
2. Conduct formal privacy analysis to quantify potential information leakage from model trajectories and verify differential privacy guarantees
3. Test the framework under non-IID data distributions and heterogeneous client settings to validate robustness in realistic FL deployments