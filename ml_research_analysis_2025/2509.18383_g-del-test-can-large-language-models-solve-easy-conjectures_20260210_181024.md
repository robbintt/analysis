---
ver: rpa2
title: "G\xF6del Test: Can Large Language Models Solve Easy Conjectures?"
arxiv_id: '2509.18383'
source_url: https://arxiv.org/abs/2509.18383
tags:
- gpt-5
- submodular
- algorithm
- proof
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We evaluated GPT-5 on five novel conjectures in submodular maximization,
  each accompanied by one or two source papers. The goal was to test whether GPT-5
  could produce correct proofs for simple yet unsolved problems without extensive
  hints.
---

# GÃ¶del Test: Can Large Language Models Solve Easy Conjectures?

## Quick Facts
- arXiv ID: 2509.18383
- Source URL: https://arxiv.org/abs/2509.18383
- Reference count: 13
- GPT-5 produced nearly correct solutions for 3 out of 5 novel submodular maximization conjectures, with partial success on the remaining two

## Executive Summary
This study evaluates GPT-5's ability to solve novel mathematical conjectures in submodular maximization without extensive hints. The model was tested on five problems, each with one or two source papers. GPT-5 demonstrated meaningful progress on routine reasoning tasks, producing nearly correct solutions for three problems and identifying correct algorithms for others. However, it struggled with problems requiring synthesis across multiple papers, highlighting current limitations in cross-domain reasoning.

## Method Summary
The evaluation tested GPT-5 on five novel conjectures in submodular maximization, each accompanied by source papers. The goal was to assess whether the model could produce correct proofs for unsolved problems without extensive hints. Performance was measured qualitatively, examining solution correctness, originality, and the ability to combine insights from multiple sources.

## Key Results
- GPT-5 produced nearly correct solutions for three simpler problems
- For Problem 2, the model derived a different approximation guarantee that refuted the original conjecture but provided a valid alternative result
- GPT-5 identified the correct algorithm for Problem 5 but failed in the analysis, suggesting higher complexity than anticipated

## Why This Works (Mechanism)
GPT-5 demonstrates the ability to engage with novel mathematical problems by leveraging its training on mathematical literature and pattern recognition capabilities. The model can identify relevant approaches from source papers, apply standard proof techniques, and occasionally generate original insights. However, its performance degrades when problems require synthesizing information across multiple disparate sources, indicating limitations in cross-domain reasoning and deep mathematical understanding.

## Foundational Learning
- **Submodular optimization**: Understanding diminishing returns property and greedy algorithms - why needed: core problem domain; quick check: can explain greedy 1-1/e approximation
- **Approximation algorithms**: Ratio analysis and performance guarantees - why needed: evaluating solution quality; quick check: can compute approximation ratios
- **Mathematical proof techniques**: Induction, contradiction, and reduction methods - why needed: constructing valid arguments; quick check: can identify proof structure in examples
- **Algorithm analysis**: Time/space complexity and correctness proofs - why needed: validating proposed solutions; quick check: can analyze simple algorithm complexity
- **Literature synthesis**: Combining insights from multiple research papers - why needed: solving problems requiring cross-paper knowledge; quick check: can summarize key results from two papers

## Architecture Onboarding
**Component map:** Input processing -> Pattern matching -> Reasoning generation -> Output synthesis
**Critical path:** Problem comprehension -> Relevant paper identification -> Approach selection -> Proof construction -> Validation
**Design tradeoffs:** Broad knowledge coverage vs. deep specialized reasoning; speed of response vs. accuracy of complex proofs
**Failure signatures:** Missing cross-paper connections; incomplete proof steps; incorrect generalization from similar problems
**First experiments:** 1) Test on single-paper problems vs. multi-paper problems; 2) Compare performance with and without source paper access; 3) Evaluate partial solution completion rates

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation scope restricted to five specific problems in submodular maximization
- Assessment relies on qualitative judgment rather than formal verification
- Limited generalizability to broader mathematical domains

## Confidence
**High confidence**: GPT-5's ability to generate meaningful partial solutions and identify correct algorithmic approaches for simpler problems
**Medium confidence**: Characterization of GPT-5's performance on problems requiring cross-paper synthesis
**Low confidence**: Claim that Problem 5's proof is "more difficult than initially expected" without formal complexity analysis

## Next Checks
1. Conduct formal verification of all GPT-5 generated proofs using automated theorem provers
2. Expand evaluation to include problems from diverse mathematical domains beyond submodular optimization
3. Implement controlled experiments comparing GPT-5's performance against human experts on identical problem sets