---
ver: rpa2
title: Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial
  Networks
arxiv_id: '2502.21034'
source_url: https://arxiv.org/abs/2502.21034
tags:
- data
- selectivity
- tabular
- figure
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis proposes a novel GAN-based approach to generate tabular
  data with query selectivity constraints, addressing a key gap in E-commerce stress
  testing. By integrating a pre-trained deep neural network into the GAN framework,
  the method ensures selectivity consistency between real and synthetic data.
---

# Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks

## Quick Facts
- arXiv ID: 2502.21034
- Source URL: https://arxiv.org/abs/2502.21034
- Authors: Youran Zhou; Jianzhong Qi
- Reference count: 0
- Primary Result: Proposed method improves selectivity estimation accuracy by up to 20% and ML utility by up to 6% on five real-world datasets.

## Executive Summary
This paper addresses the challenge of generating high-quality synthetic tabular data for E-commerce stress testing by integrating query selectivity constraints into a GAN framework. The key innovation is the addition of a selectivity loss term, computed using a pre-trained deep neural network, to the GAN's generator loss function. This ensures the generated data not only looks realistic to the discriminator but also preserves specific statistical properties crucial for accurate query execution cost estimation. Experiments on five real-world datasets demonstrate the method's effectiveness, achieving significant improvements over state-of-the-art GANs and a VAE model in both selectivity estimation and machine learning utility.

## Method Summary
The method involves training a GAN-based model (e.g., CTGAN) with a modified loss function that incorporates selectivity constraints. First, the original tabular data undergoes preprocessing using the mRDT method, which includes ordinal encoding for ordinal variables and mode-specific normalization for continuous variables. A pre-trained deep neural network, SelNet, is used to estimate the selectivity of generated data. During GAN training, the generator's loss function is augmented with a selectivity loss term, calculated as the Mean Squared Error between the selectivity of real and generated data. This forces the generator to produce data that satisfies both realism and selectivity constraints, resulting in high-quality synthetic data suitable for E-commerce stress testing.

## Key Results
- Up to 20% improvement in selectivity estimation accuracy compared to state-of-the-art GANs.
- Up to 6% improvement in machine learning utility, measured by classification F1 and regression MSE.
- Method is flexible and compatible with various GAN architectures, including CTGAN and Daisy.
- Outperforms VAE model in both selectivity estimation and ML utility on all five datasets.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating query selectivity constraints improves the fidelity of synthetic tabular data for resource estimation tasks.
- Mechanism: A pre-trained deep neural network (a selectivity estimator) provides a secondary supervision signal to the GAN's generator. The selectivity loss, calculated as the Mean Squared Error (MSE) between the selectivity of generated and real data, is added to the generator's loss function. This forces the generator to produce data that not only looks real to the discriminator but also preserves specific statistical properties (selectivity) crucial for query execution cost estimation.
- Core assumption: The pre-trained selectivity model (SelNet) accurately captures the complex relationship between query objects, thresholds, and selectivity in the original data, and that minimizing MSE on this model translates to meaningful selectivity preservation in the generated data.
- Evidence anchors:
  - [abstract] "We integrate a pre-trained deep neural network to maintain selectivity consistency between real and synthetic data."
  - [section 3.1.3] "To improve the capability of G, we add the Lsel to the Generator Loss LG... thus the G will modify itself to minimize the loss function then the selectivity constraints will be satisfied."
  - [corpus] Related work on Logic Tensor Network-Enhanced GANs (LTN-GAN) similarly enforces logical constraints during generation, supporting the general principle of domain-specific constraint integration for improved output validity.
- Break condition: The selectivity estimator itself is inaccurate or the weight of the selectivity loss term (alpha) is set too high, dominating the adversarial loss and causing training instability or poor data quality.

### Mechanism 2
- Claim: Mode-specific normalization effectively handles non-Gaussian and multi-modal continuous distributions common in tabular data.
- Mechanism: For each continuous column, a Variational Gaussian Mixture (VGM) model identifies the number of modes. Each data point is then normalized based on the mean and standard deviation of the specific mode it belongs to. This transforms a complex multi-modal distribution into a set of simpler, more manageable Gaussian-like distributions for the GAN to learn.
- Core assumption: The continuous features in the tabular data follow a mixture of Gaussian distributions, which the VGM can successfully identify and fit. The paper explicitly states continuous columns "are usually not following a normal distribution but a Multi-modal distribution."
- Evidence anchors:
  - [section 2.1.4] "Mode-specific normalization method normalizes a continuous column with multi-modal distributions."
  - [section 3.1.1] "This method is used since the continuous columns in the real-world are usually not following a normal distribution but a Multi-modal distribution."
  - [corpus] The corpus points to alternative generative models like Diffusion Models for tabular data, which handle complex distributions differently, providing a contrast to the GAN + Mode-specific normalization approach.
- Break condition: A continuous feature has a highly irregular distribution that cannot be well-approximated by a mixture of Gaussians, or the VGM model fails to converge to a meaningful representation.

### Mechanism 3
- Claim: Modified data preprocessing using ordinal encoding for ordinal variables preserves semantic order, improving model learning.
- Mechanism: Instead of one-hot encoding all categorical variables (which loses order information for ordinal data), the method uses ordinal encoding (e.g., small=1, medium=2, large=3). This preserves the inherent ranked relationship between categories, allowing the GAN to learn these relationships more easily.
- Core assumption: The ordinal variables have a clear and meaningful natural order that is relevant to the underlying data generation process and downstream tasks.
- Evidence anchors:
  - [section 3.1.1] "One-hot Encoding may not catch the natural ordered relationship between each response for ordinal data... We decide to use Ordinal Encoding for ordinal variables to maintain the inner ordered relations..."
  - [corpus] No direct corpus evidence was found on the specific impact of ordinal encoding in GANs, indicating a potential niche contribution.
- Break condition: The ordinal variable's order is not numerically meaningful (e.g., 1="red", 2="blue", 3="green"), or the scale of the encoded integers is vastly different from other features, causing training issues.

## Foundational Learning

- **Concept: Generative Adversarial Networks (GANs)**
  - Why needed here: This is the core generative model. You must understand the adversarial dynamic between the Generator (G) and the Discriminator (D), their loss functions, and the concept of training equilibrium and mode collapse.
  - Quick check question: Explain the loss functions for the Generator and Discriminator in a standard GAN. What is mode collapse?

- **Concept: Query Selectivity**
  - Why needed here: This is the specific domain constraint the entire thesis is built around. Understanding selectivity (the fraction of rows returned by a query predicate) is crucial to grasping the problem being solved and the evaluation metric.
  - Quick check question: How is selectivity defined? Why is it important for database query cost estimation?

- **Concept: Variational Gaussian Mixture (VGM) Model**
  - Why needed here: This is the specific technique used to preprocess continuous data (Mechanism 2). You need to understand how it identifies multiple "modes" or clusters within a single column's distribution.
  - Quick check question: What problem does a standard single Gaussian distribution assumption create for real-world tabular data? How does a VGM model address this?

## Architecture Onboarding

- Component map:
  1. **Data Preprocessor (mRDT):** Transforms raw tabular data. Uses Ordinal Encoding for ordinal columns and Mode-Specific Normalization (via VGM) for continuous columns.
  2. **Pre-trained Selectivity Estimator (SelNet):** A separate, pre-trained deep learning model (based on regression) that takes a query object and threshold to predict selectivity. Its weights are frozen during GAN training.
  3. **GAN (Generator G, Discriminator D):** The base generative model (e.g., CTGAN, Daisy). G takes noise and generates synthetic rows; D tries to distinguish them from real rows.
  4. **Loss Function Aggregator:** The module that combines the standard adversarial loss with the selectivity loss from the pre-trained estimator.

- Critical path:
  1. **Pre-train SelNet:** Train the selectivity estimation model on the original dataset until it achieves good predictive accuracy.
  2. **Preprocess Data:** Apply the mRDT transformations to the original dataset.
  3. **Initialize GAN:** Set up the chosen GAN architecture (Generator and Discriminator).
  4. **Adversarial Training with Selectivity Supervision:**
     a. G generates a batch of synthetic data.
     b. D evaluates real and synthetic data, producing adversarial loss.
     c. The synthetic batch is fed into the frozen pre-trained SelNet, along with generated queries, to compute the selectivity loss (MSE).
     d. The combined loss is backpropagated to update G.
     e. D is updated using its own loss.

- Design tradeoffs:
  - **Selectivity Loss Weight (alpha):** A low weight makes the selectivity constraint a minor factor; a high weight may destabilize GAN training or reduce general data quality. The paper uses 0.01.
  - **Base GAN Model:** The method is model-agnostic but the final performance depends on the base model's capabilities (e.g., CTGAN vs. a simpler LSTM-based GAN).
  - **Preprocessing Complexity:** Mode-specific normalization is more computationally intensive than simple min-max scaling but better captures data distributions.

- Failure signatures:
  - **Selectivity Loss Dominates:** GAN loss drops to near zero but generated data looks nothing like real data. This indicates the weight on the selectivity loss is too high.
  - **Mode Collapse:** Generated data has high repetition, as indicated in the thesis for some baseline models.
  - **Poor Correlation Preservation:** Correlation heatmaps of synthetic data look different from original. This suggests the generator is not learning feature inter-dependencies well.

- First 3 experiments:
  1. **Sanity Check (Visual):** Generate a batch of data using the baseline GAN (without selectivity loss) and the proposed GAN. Plot the Cumulative Distribution Function (CDF) for several continuous columns and compare them to the original data.
  2. **Ablation Study (Loss):** Run the full training pipeline. Create a variant without the selectivity loss term. Compare the Selectivity Estimation MSE of the data generated by the full model vs. the ablated model on a held-out set of queries.
  3. **Baseline Comparison:** Compare the proposed model against the base GAN model and at least one other baseline (e.g., VAE) on a downstream machine learning task (e.g., train a classifier on synthetic data and test on real data) to measure Machine Learning Utility.

## Open Questions the Paper Calls Out
None

## Limitations
- **Architecture Specificity:** The paper describes the SelNet architecture generically (AE + FFN + encoder-decoder) without providing specific hyperparameter details, making exact reproduction challenging. The VGM mode selection criteria and query generation procedure are also underspecified.
- **Performance Attribution:** While the paper reports improvements over baselines, the exact contribution of the selectivity loss versus the improved preprocessing (mRDT) is not isolated through rigorous ablation studies.
- **Dataset Scope:** All experiments use UCI or Kaggle datasets. The method's effectiveness on truly high-dimensional, noisy, or sparse real-world E-commerce datasets remains unproven.

## Confidence
- **High Confidence:** The core mechanism of integrating a pre-trained selectivity estimator into the GAN loss function is well-defined and theoretically sound. The general approach of using mode-specific normalization for continuous features is reasonable and described adequately.
- **Medium Confidence:** The reported performance improvements (20% selectivity accuracy, 6% ML utility) are plausible given the described methodology, but the lack of detailed architecture and hyperparameter specifications introduces uncertainty in replication.
- **Low Confidence:** The paper's claims about the method being "flexible and compatible with various GAN architectures" are based on experiments with CTGAN only. The claim of superior performance on E-commerce stress testing is not directly validated with an E-commerce dataset.

## Next Checks
1. **Ablation Study:** Implement a variant of the model without the selectivity loss term. Compare its Selectivity Estimation MSE against the full model on a held-out query set to quantify the contribution of the selectivity supervision.
2. **Architecture Generalization:** Replace the CTGAN base model with a different GAN architecture (e.g., an LSTM-based GAN from the corpus) and retrain the system. Evaluate if the selectivity performance improvements are consistent.
3. **E-commerce Dataset Test:** Apply the complete pipeline (mRDT preprocessing, SelNet training, GAN training) to a real-world E-commerce dataset with known query selectivity requirements. Evaluate the generated data's utility for a stress-testing scenario, such as simulating high-traffic query loads.