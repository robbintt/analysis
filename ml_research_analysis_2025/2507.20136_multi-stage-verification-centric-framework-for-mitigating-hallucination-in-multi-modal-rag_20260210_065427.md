---
ver: rpa2
title: Multi-Stage Verification-Centric Framework for Mitigating Hallucination in
  Multi-Modal RAG
arxiv_id: '2507.20136'
source_url: https://arxiv.org/abs/2507.20136
tags:
- answer
- query
- retrieval
- knowledge
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses hallucination in multimodal question answering,
  especially for egocentric and time-sensitive queries in real-world scenarios. The
  authors propose a multi-stage verification-centric framework that combines lightweight
  query routing, query-aware retrieval with dynamic thresholding, dual-path generation,
  and a structured Chain-of-Verification process.
---

# Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG

## Quick Facts
- arXiv ID: 2507.20136
- Source URL: https://arxiv.org/abs/2507.20136
- Authors: Baiyu Chen; Wilson Wongso; Xiaoqian Hu; Yue Tan; Flora Salim
- Reference count: 20
- Primary result: Third place in CRAG-MM Task 1 with 11.54% truthfulness score and only 2.88% hallucination rate

## Executive Summary
This paper addresses hallucination in multimodal question answering, particularly for egocentric and time-sensitive queries in real-world scenarios. The authors propose a multi-stage verification-centric framework that combines lightweight query routing, query-aware retrieval with dynamic thresholding, dual-path generation, and a structured Chain-of-Verification process. The design prioritizes factual accuracy and reliability over completeness, directly tackling the challenge's severe penalty for hallucinations.

The framework achieved strong performance on the CRAG-MM benchmark, demonstrating its effectiveness in minimizing hallucinations while maintaining coverage. By implementing a structured verification process, the system successfully navigates the trade-off between completeness and accuracy that is critical in multimodal RAG applications where false information can have significant consequences.

## Method Summary
The framework employs a multi-stage approach to mitigate hallucinations in multimodal RAG systems. It begins with lightweight query routing to classify query types, followed by query-aware retrieval with dynamic thresholding to optimize the balance between precision and recall. The system then utilizes dual-path generation to produce multiple answer candidates, which are subsequently processed through a structured Chain-of-Verification mechanism. This verification-centric design prioritizes factual accuracy over completeness, using verification sources to validate generated responses before final output.

## Key Results
- Achieved 11.54% truthfulness score on CRAG-MM benchmark
- Maintained only 2.88% hallucination rate
- Secured third place in Task 1 of CRAG-MM challenge
- Demonstrated strong performance in minimizing hallucinations while maintaining coverage

## Why This Works (Mechanism)
The framework's effectiveness stems from its multi-stage verification-centric design that systematically addresses hallucination at each processing step. The lightweight query routing enables efficient classification and appropriate handling of different query types. Query-aware retrieval with dynamic thresholding optimizes the precision-recall trade-off based on query characteristics. Dual-path generation provides multiple answer candidates for verification, while the structured Chain-of-Verification process rigorously validates responses against trusted sources before final output.

## Foundational Learning
- **Query routing mechanisms**: Essential for understanding how different query types are classified and routed to appropriate processing pipelines. Quick check: Verify routing accuracy across diverse query categories.
- **Dynamic thresholding in retrieval**: Critical for balancing precision and recall based on query context. Quick check: Test threshold sensitivity across different query types.
- **Dual-path generation**: Provides redundancy and multiple answer candidates for verification. Quick check: Compare quality and consistency between generation paths.
- **Chain-of-Verification**: Structured approach to validate generated responses against trusted sources. Quick check: Measure verification accuracy and coverage.
- **Hallucination metrics**: Understanding how hallucination rates are measured and penalized in multimodal QA. Quick check: Verify metric calculation aligns with benchmark standards.
- **Egocentric query handling**: Special considerations for first-person perspective queries in multimodal contexts. Quick check: Test performance on egocentric vs. exocentric queries.

## Architecture Onboarding

**Component Map**: Query Router -> Query-Aware Retriever -> Dual-Path Generator -> Chain-of-Verification -> Output Filter

**Critical Path**: The verification stage is the critical path, as it directly impacts the final output quality and hallucination rate. Any delay or failure in verification cascades to the final answer quality.

**Design Tradeoffs**: The framework prioritizes hallucination reduction over completeness, accepting lower truthfulness scores (11.54%) in exchange for significantly reduced hallucination rates (2.88%). This design choice directly addresses the CRAG-MM challenge's penalty structure but may limit applicability in scenarios requiring comprehensive answers.

**Failure Signatures**: 
- High latency in verification stage indicates potential bottlenecks in source access or processing
- Inconsistent dual-path generation suggests model instability or prompt sensitivity
- Failed query routing leads to inappropriate retrieval strategies and degraded performance
- Dynamic thresholding misconfiguration results in either excessive noise or missed relevant information

**3 First Experiments**:
1. Test query routing accuracy across the full spectrum of CRAG-MM query types to validate classification performance
2. Measure dual-path generation consistency by comparing output similarity and hallucination rates between paths
3. Evaluate verification stage effectiveness by introducing controlled hallucinations and measuring detection rates

## Open Questions the Paper Calls Out
None

## Limitations
- Task-specific optimization for CRAG-MM benchmark may limit generalizability to other multimodal QA scenarios
- Heavy emphasis on minimizing hallucinations comes at the cost of completeness (11.54% truthfulness score)
- Computational efficiency and real-time applicability in production environments not addressed
- Reliance on structured verification assumes access to reliable verification sources

## Confidence

**High Confidence**: The framework's effectiveness in reducing hallucinations for the specific CRAG-MM benchmark task is well-supported by the reported metrics (2.88% hallucination rate, 11.54% truthfulness score, third-place ranking).

**Medium Confidence**: Claims about the framework's general applicability to real-world egocentric and time-sensitive scenarios are supported by the methodology but lack extensive validation beyond the benchmark.

**Low Confidence**: Assertions about the framework's superiority over alternative approaches are difficult to verify due to limited comparative analysis with other hallucination mitigation techniques in the literature.

## Next Checks
1. Cross-dataset generalization testing: Evaluate the framework's performance on diverse multimodal QA datasets beyond CRAG-MM to assess real-world applicability and identify potential overfitting to the benchmark's specific characteristics.

2. Ablation study on verification thresholds: Systematically vary the dynamic thresholding parameters to quantify the trade-off between hallucination reduction and answer completeness, providing clearer guidelines for deployment in different use cases.

3. Real-time performance benchmarking: Measure the computational overhead introduced by the multi-stage verification process, including latency and resource utilization, to determine feasibility for production environments with strict timing requirements.