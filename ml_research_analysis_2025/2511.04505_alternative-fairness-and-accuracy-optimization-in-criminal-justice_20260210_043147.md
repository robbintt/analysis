---
ver: rpa2
title: Alternative Fairness and Accuracy Optimization in Criminal Justice
arxiv_id: '2511.04505'
source_url: https://arxiv.org/abs/2511.04505
tags:
- fairness
- group
- individual
- groups
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the tension between individual and group fairness
  in algorithmic decision-making, particularly in criminal justice. The authors propose
  a modified optimization framework that minimizes a weighted error loss while constraining
  differences in false negative rates across groups within a tolerance bound.
---

# Alternative Fairness and Alternative Accuracy Optimization in Criminal Justice

## Quick Facts
- **arXiv ID:** 2511.04505
- **Source URL:** https://arxiv.org/abs/2511.04505
- **Reference count:** 25
- **Primary result:** Proposed constrained optimization framework relaxes strict fairness parity requirements while maintaining bounded FNR differences across groups

## Executive Summary
This paper addresses the fundamental tension between individual and group fairness in algorithmic decision-making, particularly in criminal justice contexts. The authors propose a modified optimization framework that minimizes a weighted error loss while constraining differences in false negative rates across groups within a tolerance bound τ. This approach aims to make fairness constraints more feasible and improve predictive accuracy compared to strict parity requirements. The paper critiques current fairness definitions through three lenses: biased data, latent affirmative action effects, and the explosion of subgroup constraints. It introduces a Three Pillars Framework for deploying fair algorithms: need-based decisions, transparency and accountability, and narrowly tailored definitions and solutions.

## Method Summary
The paper proposes a constrained optimization approach that modifies standard loss minimization by relaxing exact parity constraints. Instead of requiring identical false negative rates across all groups, the framework allows differences up to a tolerance bound τ. The optimization minimizes a weighted error loss (specifically the sum of weighted false negatives) subject to the constraint that FNR differences between any two groups are bounded by τ. This formulation is designed to be more feasible in practice while still maintaining meaningful fairness guarantees. The approach can be implemented using standard optimization techniques such as logistic regression with Lagrangian multipliers or support vector machines with constrained optimization.

## Key Results
- The modified fairness formulation allows flexibility in error trade-offs while maintaining bounded fairness differences
- Relaxing strict parity constraints makes fairness implementation more feasible in real-world systems
- The Three Pillars Framework provides a comprehensive approach to algorithmic fairness deployment
- The paper identifies critical challenges with current fairness definitions including biased data, latent affirmative action effects, and computational infeasibility of subgroup analysis

## Why This Works (Mechanism)
The approach works by relaxing the strict mathematical requirements of exact parity while maintaining meaningful fairness guarantees. By allowing bounded differences in error rates (controlled by tolerance τ), the optimization problem becomes more tractable and less likely to produce infeasible solutions. This relaxation acknowledges that perfect parity may be mathematically impossible or practically harmful in many real-world scenarios, particularly when baseline error rates differ across groups. The weighted error loss formulation allows decision-makers to prioritize different types of errors based on their specific context and values.

## Foundational Learning
- **Constrained optimization in ML**: Mathematical optimization with constraints on model behavior; needed to enforce fairness while maintaining accuracy
- **False Negative Rate parity**: The requirement that different groups have similar rates of Type II errors; needed as a fairness metric for high-stakes decisions
- **Three Pillars Framework**: Need-based decisions, transparency/accountability, narrowly tailored solutions; needed to provide practical guidance beyond theoretical formulations
- **Latent affirmative action**: Unintended systematic advantaging/disadvantaging of groups when relaxing constraints; needed to understand unintended consequences of fairness interventions
- **Subgroup intersection explosion**: The combinatorial growth of fairness constraints when considering multiple protected attributes; needed to understand scalability limits of fairness approaches

## Architecture Onboarding
**Component Map**: Loss function -> Constraint formulation -> Optimization solver -> Fairness evaluation
**Critical Path**: Define objective function with error weights → Set tolerance bounds τ → Apply constrained optimization → Evaluate fairness-accuracy trade-off
**Design Tradeoffs**: Exact parity (strong fairness guarantee, often infeasible) vs. bounded tolerance (weaker guarantee, more practical)
**Failure Signatures**: Infeasible optimization (τ too strict), latent discrimination (baseline rate differences), computational intractability (too many subgroups)
**First Experiments**: 1) Train with high τ (0.2) and gradually decrease to find feasibility frontier; 2) Compare accuracy-fairness trade-off curves against unconstrained baseline; 3) Test latent affirmative action by analyzing individual group FNRs under different τ values

## Open Questions the Paper Calls Out
**Open Question 1**: How should the tolerance bound τ be selected in a principled manner to avoid either further disadvantaging marginalized groups or engaging in legally controversial affirmative action? The paper notes that setting τ to 5% could either further disadvantage African American applicants or constitute affirmative action leading to legal controversy, but provides no systematic method for choosing τ.

**Open Question 2**: How can the political science concept of "legitimacy" be mathematically formalized and integrated into algorithmic fairness frameworks? The Three Pillars Model invokes legitimacy conceptually but lacks formal mathematical integration and operationalization.

**Open Question 3**: At what level of granularity should subgroup intersection analysis stop before it becomes infeasible or morally unjustified? The paper identifies hundreds of possible intersections but offers no decision procedure for where to draw boundaries, noting issues of computational infeasibility and moral justification.

**Open Question 4**: How does the Three Pillars Model perform in practice compared to existing fairness frameworks on real-world criminal justice data? The paper proposes the framework theoretically but includes no empirical evaluation on actual criminal justice datasets like COMPAS.

## Limitations
- No empirical validation or experimental results are provided to demonstrate the approach's effectiveness
- Key hyperparameters (error weights α, β, tolerance bound τ) are not specified with recommended values
- The optimization algorithm for solving the constrained problem is not specified
- The Three Pillars Framework is described abstractly without concrete implementation details or case studies

## Confidence
- **High confidence**: Theoretical critique of strict fairness definitions and identification of practical challenges
- **Medium confidence**: Modified optimization formulation appears mathematically sound based on standard constrained optimization principles
- **Low confidence**: Practical effectiveness and trade-offs of the proposed approach due to lack of empirical validation

## Next Checks
1. Implement the constrained optimization framework on a standard dataset (COMPAS or Adult) to empirically test the trade-off between accuracy and fairness under different tolerance bounds
2. Compare the performance of the relaxed fairness constraints (tolerance τ > 0) against strict parity requirements to quantify improvements in feasibility and accuracy
3. Test the latent affirmative action effect by analyzing how the relaxation affects different groups when baseline error rates differ significantly