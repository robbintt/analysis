---
ver: rpa2
title: Enabling Vibration-Based Gesture Recognition on Everyday Furniture via Energy-Efficient
  FPGA Implementation of 1D Convolutional Networks
arxiv_id: '2510.23156'
source_url: https://arxiv.org/abs/2510.23156
tags:
- accuracy
- d-cnn
- d-sepcnn
- data
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling real-time, energy-efficient
  gesture recognition on everyday furniture using vibration sensing. The core method
  involves replacing complex spectral preprocessing with raw waveform input, designing
  lightweight 1D convolutional networks (1D-CNN and 1D-SepCNN), applying integer-only
  quantization, and generating hardware accelerators for FPGA deployment.
---

# Enabling Vibration-Based Gesture Recognition on Everyday Furniture via Energy-Efficient FPGA Implementation of 1D Convolutional Networks

## Quick Facts
- arXiv ID: 2510.23156
- Source URL: https://arxiv.org/abs/2510.23156
- Reference count: 30
- Primary result: Achieves 0.970 average accuracy with 9.22 ms latency using 6-bit 1D-CNN on FPGA, consuming under 1.2 mJ per inference

## Executive Summary
This paper presents a real-time, energy-efficient solution for gesture recognition on everyday furniture using vibration sensing. The authors propose replacing complex spectral preprocessing with raw waveform input, designing lightweight 1D convolutional networks (1D-CNN and 1D-SepCNN), applying integer-only quantization, and generating hardware accelerators for FPGA deployment. The system achieves high accuracy while meeting strict latency and energy constraints, making it suitable for long-term edge deployment on resource-constrained devices like the AMD Spartan-7 XC7S25 FPGA.

## Method Summary
The method involves four key innovations: (1) using raw downsampled waveforms instead of spectrograms to reduce input size by 21× without accuracy loss, (2) designing depthwise-separable 1D convolutions to reduce computational cost and memory footprint, (3) applying integer-only quantization for hardware efficiency, and (4) implementing a hardware-aware, constraint-driven search using Optuna to identify optimal model configurations. The approach is trained on vibration data from 4 piezoelectric sensors on furniture, recognizing four swipe gestures (Up, Down, Left, Right) with high accuracy while meeting strict latency (<100 ms) and energy (<50 mJ/inference) constraints.

## Key Results
- 0.970 average accuracy with 9.22 ms latency using 6-bit 1D-CNN on AMD Spartan-7 XC7S25 FPGA
- 0.949 average accuracy with 6.83 ms latency using 8-bit 1D-SepCNN, consuming under 1.2 mJ per inference
- Over 53× speedup compared to CPU-based inference while maintaining competitive accuracy
- Successful deployment on resource-constrained FPGA with 66.67% BRAM utilization for 1D-SepCNN variant

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Raw downsampled waveforms can replace spectral preprocessing without accuracy loss for vibration-based gesture recognition.
- **Mechanism:** Vibration signals from swipe gestures contain temporally localized patterns that remain discriminative when downsampled by 10×. The gesture-relevant signal energy concentrates between 0.25–1.25 seconds, allowing truncation and aggressive downsampling while preserving class-discriminative features. Sliding-window augmentation with fractional offsets compensates for information loss by exposing the model to unsampled waveform segments during training.
- **Core assumption:** The temporal structure of vibration patterns, not high-frequency spectral details, carries the primary gesture-discriminative information.
- **Evidence anchors:** [abstract] "We replace complex spectral preprocessing with raw waveform input... reducing input size by 21× without sacrificing accuracy" [Section III-A] "A factor of 10... is identified as the most favorable configuration, resulting in an input shape of 4410×4... achieving 21× reduction in input dimensionality compared to the spectrogram-based input"
- **Break condition:** Accuracy drops significantly (>5%) when downsampling factor exceeds 10×, or when gesture signatures rely on high-frequency spectral components not captured in downsampled time domain.

### Mechanism 2
- **Claim:** Depthwise-separable 1D convolutions reduce computational cost and memory footprint while maintaining competitive accuracy for sequential vibration signals.
- **Mechanism:** Standard 1D convolutions apply filters across all input channels simultaneously. Depthwise-separable convolution decomposes this into (1) a depthwise stage applying separate filters per channel, and (2) a pointwise stage (1×1 convolution) fusing cross-channel information. This reduces parameters from 296 to 216 (27% reduction) and FLOPs by 33.1% for the tested architecture. The ping-pong buffering mechanism streams intermediate results between stages, reducing BRAM usage from 97.78% to 66.67% on the target FPGA.
- **Core assumption:** Vibration features can be extracted independently per sensor channel before fusion, and cross-channel correlations are efficiently captured by 1×1 convolutions.
- **Evidence anchors:** [Section III-B] "For example, replacing the Conv1D in the first block lowers parameters from 52 to 36 and FLOPs from 84,576 to 49,336" [Section III-C] "BRAM utilization drops from 97.78% to 66.67%... with no additional DSP cost"
- **Break condition:** Tasks requiring dense cross-channel interactions in early layers show significant accuracy degradation (>3%) with separable convolutions, or hardware has abundant BRAM making ping-pong overhead unnecessary.

### Mechanism 3
- **Claim:** Hardware-aware, constraint-driven search identifies quantized model configurations that jointly optimize accuracy, latency, energy, and resource utilization.
- **Mechanism:** The Optuna-based framework uses NSGA-II multi-objective sampling to explore configurations (quantization bitwidth, architecture depth, learning rate, batch size). Progressive constraint pruning eliminates infeasible candidates early: accuracy checks during training, latency checks after RTL simulation, resource checks after synthesis, energy checks after power estimation. This focuses search on the Pareto front of valid deployments rather than exhaustively evaluating all combinations.
- **Core assumption:** The search space can be pruned progressively without missing optimal configurations, and validation metrics during training correlate with final deployment metrics.
- **Evidence anchors:** [Section III-D] "constraint checks are applied progressively to prune invalid configurations as early as possible" [Table III] Selected 6-bit 1D-CNN achieves 0.970 accuracy with 9.22 ms latency; 8-bit 1D-SepCNN achieves 0.949 accuracy with 6.83 ms latency
- **Break condition:** Constraint thresholds are set too aggressively, pruning viable configurations; or validation accuracy poorly predicts test accuracy under cross-subject/cross-table generalization (LOSO setting shows higher variance).

## Foundational Learning

- **Concept:** 1D Convolutions for Time-Series Signals
  - **Why needed here:** Understanding how Conv1D extracts local temporal patterns from multi-channel vibration data is essential for designing and debugging the architecture.
  - **Quick check question:** Given a 4410×4 input and Conv1D with kernel size 3, stride 1, and 8 output channels, what is the output shape and parameter count?

- **Concept:** Quantization-Aware Training (QAT)
  - **Why needed here:** Integer-only deployment requires training with quantization effects simulated in the forward pass; otherwise, accuracy drops significantly post-quantization.
  - **Quick check question:** Why does symmetric vs. asymmetric quantization matter for weights vs. activations, and how does QAT differ from post-training quantization?

- **Concept:** FPGA Resource Types (LUT, BRAM, DSP)
  - **Why needed here:** Deployability depends on fitting within Spartan-7 XC7S25 constraints (14,600 LUTs, 45 BRAM blocks, 80 DSPs); understanding what each resource stores/computes guides architecture choices.
  - **Quick check question:** Which resource type limits a depthwise-separable convolution layer with large intermediate feature maps, and how does ping-pong buffering address this?

## Architecture Onboarding

- **Component map:** 4-channel piezoelectric sensors → 44.1 kHz sampling → 1-second truncation → 10× downsampling → sliding-window augmentation → 4410×4 tensor → 1D-CNN/1D-SepCNN backbone → GlobalAvgPool → Dense → Dense → Integer-only quantization → VHDL generation → AMD Spartan-7 XC7S25

- **Critical path:** Input size reduction (21×) enables model to fit in on-chip BRAM → Integer-only quantization eliminates floating-point units, reducing DSP usage → Ping-pong buffering enables SepCNN deployment under tight BRAM constraints → Constraint-aware search ensures configurations meet accuracy/latency/energy thresholds before synthesis

- **Design tradeoffs:** 1D-CNN vs. 1D-SepCNN: 1D-CNN generalizes better (0.812 vs. 0.687 LOSO accuracy) but higher latency; 1D-SepCNN faster (6.83 ms vs. 9.22 ms) but more resource-intensive in some configurations. Quantization bitwidth: 6-bit offers best accuracy-latency balance; 4-bit fails accuracy constraints; 8-bit increases BRAM usage. Model depth: Deeper models (5 blocks) improve LOSO generalization but increase latency and resource usage.

- **Failure signatures:** BRAM overflow (>100%): Model too deep or channels too wide; reduce num_blocks or output channels. Accuracy collapse on LOSO (<0.60): Overfitting to training subjects; reduce model capacity or add regularization. Latency exceeds 100 ms: Conv layers too large; switch to SepCNN or reduce input length. Power exceeds 500 mW: DSP-heavy layers; verify quantization is integer-only, not mixed-precision.

- **First 3 experiments:**
  1. Reproduce baseline on single subject: Train 1D-CNN with num_blocks=3, 6-bit quantization on Person A (PS split); target >0.95 test accuracy, <10 ms latency, <1.5 mJ energy
  2. Cross-subject generalization test: Apply same configuration to LOSO split; expect accuracy drop to 0.65–0.75; identify confusion patterns in "Left"/"Right" classes
  3. Resource scaling analysis: Sweep num_blocks from 1 to 5 while monitoring LUT/BRAM/DSP utilization; identify knee point where BRAM approaches 100%

## Open Questions the Paper Calls Out
- Can the proposed lightweight models effectively support continuous, compound, and multi-finger gestures?
- How does the system perform when deployed on furniture with diverse geometries and material compositions?
- How can the solution be adapted to perform real-time online inference rather than offline classification?

## Limitations
- Cross-subject and cross-table generalization shows significant accuracy drops (0.812 to 0.687 and 0.769 to 0.645 respectively), suggesting potential overfitting
- The optimal downsampling factor of 10× is identified through experiments but not theoretically justified
- Sliding-window augmentation with fractional offsets is claimed to compensate for information loss, but ablation studies isolating its contribution are lacking

## Confidence
- **High Confidence:** The fundamental claim that integer-only quantization enables real-time FPGA deployment with sub-10 ms latency is strongly supported by measured results and detailed hardware implementation
- **Medium Confidence:** The accuracy claims under cross-subject and cross-table splits are supported by experimental results but show significant variance (LOSO accuracy drops to 0.687)
- **Low Confidence:** The claim that sliding-window augmentation compensates for information loss from downsampling is based on observed accuracy maintenance but lacks isolated ablation studies

## Next Checks
1. **Cross-validation robustness test:** Replicate the LOSO experiments across all five subjects and report confidence intervals to assess the stability of the accuracy claims, particularly for the 1D-SepCNN model which shows the largest generalization gap.

2. **Ablation study on preprocessing:** Systematically compare the proposed raw waveform approach against spectrogram-based input and alternative time-frequency representations to quantify the actual contribution of skipping spectral preprocessing.

3. **Resource utilization verification:** Generate and synthesize the exact VHDL implementations described in the paper on the target XC7S25 FPGA, measuring actual BRAM usage, DSP utilization, and power consumption under real operating conditions.