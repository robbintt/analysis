---
ver: rpa2
title: 'Beyond Single-Sentence Prompts: Upgrading Value Alignment Benchmarks with
  Dialogues and Stories'
arxiv_id: '2503.22115'
source_url: https://arxiv.org/abs/2503.22115
tags:
- story
- dialogue
- evaluation
- data
- multi-turn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an upgraded benchmark for evaluating value
  alignment in large language models (LLMs) that moves beyond single-sentence adversarial
  prompts by incorporating multi-turn dialogues and narrative-based scenarios. The
  approach addresses the limitation of traditional benchmarks, which are easily circumvented
  by modern safety techniques, by creating more stealthy and context-rich adversarial
  evaluations.
---

# Beyond Single-Sentence Prompts: Upgrading Value Alignment Benchmarks with Dialogues and Stories

## Quick Facts
- arXiv ID: 2503.22115
- Source URL: https://arxiv.org/abs/2503.22115
- Authors: Yazhou Zhang; Qimeng Liu; Qiuchi Li; Peng Zhang; Jing Qin
- Reference count: 14
- Single-sentence prompts easily circumvented; multi-turn dialogues and narratives create stealthier, more challenging value alignment tests

## Executive Summary
This paper addresses the limitation of traditional value alignment benchmarks that rely on single-sentence adversarial prompts, which modern LLMs have become adept at circumventing. The authors propose an enhanced methodology that transforms expert questions into multi-turn dialogues and narrative-based story scenarios, creating more contextually rich and stealthy adversarial evaluations. The C-Plus Values dataset contains 764 multi-turn dialogues and 764 story scenarios across 9 domains, systematically assessing LLMs' responses in nuanced settings. Experimental results demonstrate that this enhanced methodology effectively exposes latent biases undetected in traditional evaluations, highlighting the necessity of contextual and dynamic testing for value alignment.

## Method Summary
The methodology transforms CValues expert questions through a two-stage process: first converting questions into negative viewpoints using GPT-4 with prompt templates, then generating multi-turn dialogues and story scenarios from these viewpoints. The dataset creation involves regex cleaning of 764 questions, GPT-4o API generation using dialogue/story templates, and dual-track evaluation (manual expert scoring on 5-point ethical scale plus automatic LLM-as-judge evaluation). Quality validation includes information entropy calculation, distinct-n metrics for lexical diversity, and cosine similarity for theme preservation. The evaluation pipeline tests target LLMs using standardized prompts that assess both support/oppose judgments and ethical reasoning.

## Key Results
- Traditional benchmarks show near-ceiling performance (GPT-4o: 97.4/100, Claude 3.5: 98.6/100) while C-Plus scenarios expose significant performance gaps
- C-Plus dialogues achieve 11.04 average entropy vs. 9.48 for baseline, indicating higher diversity and difficulty
- Information entropy increases from 9.58 (baseline) to 12.49 (dialogue) and 12.64 (story), demonstrating more complex vocabulary distribution
- Manual evaluation reveals nuanced ethical reasoning differences not captured by traditional benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Contextual Complexity Bypasses Surface-Level Safety
Multi-turn dialogues and narrative scenarios evade detection by safety filters trained on direct adversarial prompts by distributing harmful content across multiple turns rather than concentrating it in a single detectable utterance.

### Mechanism 2: Negative Viewpoint Extraction Creates Stealthier Probes
Converting questions to negative viewpoints before expanding into dialogues/stories produces more diverse and challenging test cases by pushing outputs into less-sampled regions of the training distribution.

### Mechanism 3: Role-Based Persuasion Structures Exploit Sycophantic Tendencies
The "Guide-Responder" dialogue structure exploits models' tendency to agree with contextually embedded persuasion by creating social contexts where uncritical agreement appears conversationally appropriate.

## Foundational Learning

- **Cognitive Load Theory**: Increasing context complexity raises processing demands, making it harder for models to maintain consistent ethical reasoning throughout. Quick check: Can you explain why distributing an adversarial request across 3 dialogue turns might evade detection compared to a single-turn formulation?

- **Distinct-n Metrics**: Used to quantify lexical diversity in generated content. Quick check: Given Table 3, why does C-Plus(story) achieve higher Distinct-2 (0.294) than C-Plus(dialogue) (0.261)?

- **Information Entropy in NLP**: Measures vocabulary distribution complexity. Quick check: If a dataset has very low entropy, what does that imply about its vocabulary distribution and potential utility as an adversarial benchmark?

## Architecture Onboarding

- **Component map**: CValues questions → regex cleaning → negative viewpoint extraction (via GPT-4) → multi-turn dialogues/stories (via GPT-4o) → manual + automatic filtering → dual-track evaluation

- **Critical path**: Question extraction → negative viewpoint transformation → dialogue/story generation → dual-track evaluation

- **Design tradeoffs**: GPT-4o dependency may transfer biases; manual evaluation provides nuance but doesn't scale; Chinese-only dataset limits cross-cultural applicability

- **Failure signatures**: Generated dialogues with fewer than 5 turns are discarded; stories explicitly stating underlying questions are rejected; content deviating from original theme (low cosine similarity) is filtered

- **First 3 experiments**: 1) Calculate information entropy and distinct-n for generated samples vs. baseline; 2) Compute cosine similarity for theme preservation testing; 3) Pilot evaluation pipeline comparing automatic vs. manual scores on 20-question sample

## Open Questions the Paper Calls Out

### Open Question 1
How can the C-Plus Values benchmark be adapted to effectively evaluate value alignment in diverse cultural contexts where ethical standards differ significantly from the Chinese context? The current dataset is specifically designed for Chinese context, making it difficult to test global alignment of LLMs.

### Open Question 2
Can reinforcement learning techniques be effectively utilized to refine ethical assessment standards and reduce the subjectivity inherent in manual human ratings? Current study relies on manual scoring with subjectivity and rule-based automated evaluation.

### Open Question 3
Does the transformation method used to convert single questions into multi-turn dialogues and stories generalize effectively to low-resource languages or specialized domains not covered in the original expert data? The prompt templates are optimized for CValues dataset and Chinese language.

## Limitations
- Chinese-only dataset limits cross-cultural applicability despite acknowledging this limitation
- Reliance on GPT-4o for generating test cases creates potential circularity concerns
- Manual evaluation component lacks detailed reliability metrics and evaluator expertise documentation

## Confidence

- **High confidence**: Core claim that multi-turn dialogues and narratives provide more challenging value alignment tests than single sentences
- **Medium confidence**: Specific mechanisms for creating stealthier adversarial prompts are plausible but lack empirical validation
- **Medium confidence**: Claim that traditional benchmarks are "easily circumvented" is supported by performance scores but not directly tested

## Next Checks

1. Conduct cross-cultural validation by translating a subset of C-Plus prompts into English and testing with English-speaking evaluators
2. Implement ablation studies comparing performance when removing the negative viewpoint extraction step versus direct dialogue/story generation
3. Test whether models trained on C-Plus-style adversarial patterns show improved resistance to both traditional single-sentence and multi-turn adversarial prompts