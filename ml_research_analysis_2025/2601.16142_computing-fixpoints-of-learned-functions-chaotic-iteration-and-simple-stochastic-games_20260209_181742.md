---
ver: rpa2
title: 'Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic
  Games'
arxiv_id: '2601.16142'
source_url: https://arxiv.org/abs/2601.16142
tags:
- iteration
- mann
- sequence
- have
- convergence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of computing fixpoints for higher-dimensional
  functions over non-negative reals when the functions are not known precisely but
  can only be approximated, a challenge that frequently occurs in systems with quantitative
  semantics. The authors propose a generalization of the dampened Mann iteration scheme,
  allowing learning rates to converge to zero or not converge at all, and enabling
  the parameters to vary across dimensions.
---

# Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic Games

## Quick Facts
- **arXiv ID:** 2601.16142
- **Source URL:** https://arxiv.org/abs/2601.16142
- **Reference count:** 40
- **Primary result:** Generalized dampened Mann iteration converges to least fixpoint for SSGs using sampled approximations.

## Executive Summary
This paper addresses the challenge of computing fixpoints for high-dimensional functions when only approximations are available, a common problem in systems with quantitative semantics. The authors propose a generalized dampened Mann iteration scheme that allows learning rates to converge to zero or not converge at all, while enabling chaotic iteration strategies where only subsets of components are updated at each step. This approach is proven to converge to the least fixpoint for Simple Stochastic Games (SSGs) and their sampled approximations, significantly extending previous work limited to Markov decision processes. Numerical experiments demonstrate that chaotic iteration performs similarly to standard iteration while providing more flexibility for implementation.

## Method Summary
The method generalizes the dampened Mann iteration scheme by allowing learning rates (αₙ) and dampening factors (βₙ) to vary across dimensions and potentially converge to zero. The iteration updates each component i as: x_{n+1}(i) = (1-βₙ(i)) · (xₙ(i) + αₙ(i) · (fₙ(xₙ) - xₙ(i))). For chaotic iteration, only a subset of components Iₙ are updated at each step, with parameters varying per component. The scheme is proven to converge to the least fixpoint for SSGs using sampled Bellman operators without requiring "normal convergence." Experiments were conducted on 50 randomly generated SSGs with 30 states and up to 5 actions per state, comparing 6 parameter schemes (S1-S6) varying αₙ (constant, 1/n^ε, random) with βₙ = 1/n.

## Key Results
- The generalized scheme converges to the least fixpoint for SSGs using only sampled approximations without requiring normal convergence.
- Chaotic iteration (updating 1 random state per step) performs similarly to full vector updates, with the former requiring approximately d steps to match one full step.
- The extension from MDPs to SSGs is achieved through the continuity of the least fixpoint operator for SSGs.

## Why This Works (Mechanism)

### Mechanism 1
If the ratio of dampening factor to learning rate converges to zero (βₙ/αₙ → 0), the iteration converges to the least fixpoint even if the learning rate itself converges to zero. The "progressing" scheme ensures that while the learning rate may decay, the dampening factor decays faster, prioritizing the update signal over reduction of value magnitude over time.

### Mechanism 2
Chaotic iteration converges if the dampening is "uniform" across all components over time. By tracking state-specific updates through vectorized parameters, the critical condition requires that in any sequence of steps covering all dimensions, the cumulative dampening is sufficient to prevent specific components from "convincing" others of over-approximated values without eventual correction.

### Mechanism 3
The scheme computes the least fixpoint for SSGs using sampled approximations without requiring normal convergence. The proof relies on the continuity of the least fixpoint operator for SSGs, showing lim μ(sup_{k≥n} fₖ) = μf, which allows using sampled Bellman operators directly rather than expensive speedup required for MDPs.

## Foundational Learning

- **Mann Iteration**: The base iterative scheme generalized in the paper. It blends the previous iterate with the function application using a convex combination (learning rate). Quick check: How does adding a dampening factor (1-βₙ) differentiate "dampened Mann iteration" from standard Mann iteration?

- **Simple Stochastic Games (SSGs)**: The primary application domain. Understanding the Bellman operator (max/min over actions) is necessary to see why standard Kleene iteration might fail or be inefficient with approximations. Quick check: In an SSG, which player controls the choice of action in S_{max} states, and how does this affect the Bellman equation?

- **Chaotic Iteration**: The implementation strategy for high-dimensional scalability. It decouples the update frequency of different dimensions (states). Quick check: Does chaotic iteration require updating every component at every step n?

## Architecture Onboarding

- **Component map:** State Store -> Parameter Manager -> Approximator -> Scheduler -> State Store
- **Critical path:** 1) Sample: Generate approximation fₙ from environment/model. 2) Select: Scheduler chooses subset Iₙ (or single index for random chaotic iteration). 3) Compute: Calculate updates for i ∈ Iₙ: x_{n+1}(i) = (1-βₙ(i))(xₙ(i) + αₙ(i)(fₙ(xₙ) - xₙ(i))). 4) Update: Write x_{n+1}, leaving non-selected components unchanged. 5) Advance: Increment parameter counters for updated indices only.
- **Design tradeoffs:** Uniform updates (all dimensions) offer theoretical simplicity but poor scalability. Chaotic updates scale but require careful parameter decay to ensure all components dampen "fairly." Fast decay of αₙ increases robustness to noise but slows convergence in exact settings.
- **Failure signatures:** Stagnation (values stop changing but are not the fixpoint, likely βₙ/αₙ not tending to 0). Oscillation (values bounce without settling, dampening Σβₙ might be insufficient or learning rate αₙ is too high/noisy). Drift (values slowly creep upward/downward indefinitely, approximations fₙ may not be converging to f).
- **First 3 experiments:** 1) Random SSG Validation: Implement the scheme on randomly generated SSGs with βₙ = 1/n. Compare convergence speed of αₙ = 1 (Kleene) vs. αₙ = 1/n^0.5 (progressing). 2) Chaotic vs. Full Sweep: Run chaotic iteration (updating 1 random state per step) vs. full vector update. Verify chaotic iteration requires ≈d steps to match 1 full step. 3) Break Condition Test: Set βₙ = αₙ/2 (violating βₙ/αₙ → 0) on a simple identity function approximation to observe failure to converge to the least fixpoint.

## Open Questions the Paper Calls Out
1. Can dampened Mann iteration guarantee convergence to the least fixpoint for model-free reinforcement learning algorithms (e.g., Q-learning) where fixpoints are not unique?
2. Does the iteration scheme remain convergent when the sequence of approximating functions converges only in the limit-average rather than pointwise?
3. Can data-driven heuristics for selecting components to update improve the efficiency of chaotic dampened Mann iteration?

## Limitations
- The extension from MDPs to SSGs relies heavily on continuity of the least fixpoint operator, but proof details are not fully provided.
- Chaotic iteration's convergence conditions depend sensitively on sampling noise and parameter decay implementation details.
- Random SSG generation process and normalization procedure are not precisely described, affecting reproducibility.

## Confidence
- **High Confidence:** Generalized dampened Mann iteration scheme is mathematically well-defined with clearly stated "progressing" condition for convergence.
- **Medium Confidence:** Extension of fixpoint continuity from MDPs to SSGs is claimed but proof details are not fully provided in the paper.
- **Low Confidence:** Specific random generation procedure for SSGs and normalization method used in experiments are not detailed, making exact reproduction challenging.

## Next Checks
1. Reproduce core numerical experiments: Implement the 6 parameter schemes (S1-S6) on random SSGs, verifying convergence patterns and comparing chaotic vs. full sweep performance.
2. Test break conditions: Systematically violate "progressing" condition (βₙ = αₙ/2) and "uniform dampening" condition (deterministic update pattern cycling too slowly) to observe predicted divergence or stagnation.
3. Validate SSG extension: Implement the scheme on diverse SSGs beyond random generation, including games with different topologies and payoff structures, to empirically test the claimed extension from MDPs.