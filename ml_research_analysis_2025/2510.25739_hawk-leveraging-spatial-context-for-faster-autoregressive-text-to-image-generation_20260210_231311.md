---
ver: rpa2
title: 'Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation'
arxiv_id: '2510.25739'
source_url: https://arxiv.org/abs/2510.25739
tags:
- image
- speculative
- vertical
- draft
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Hawk, a method to accelerate autoregressive\
  \ text-to-image generation using spatial speculative decoding. Hawk addresses the\
  \ slow inference of autoregressive models by employing dual-direction draft heads\u2014\
  horizontal and vertical\u2014to speculate tokens, leveraging the two-dimensional\
  \ spatial structure of images."
---

# Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image Generation

## Quick Facts
- **arXiv ID:** 2510.25739
- **Source URL:** https://arxiv.org/abs/2510.25739
- **Reference count:** 40
- **Primary result:** 1.71× speedup on autoregressive text-to-image generation while preserving FID and CLIP scores

## Executive Summary
Hawk introduces a method to accelerate autoregressive text-to-image generation by leveraging spatial context through dual-direction draft heads. The approach addresses the slow inference of autoregressive models by employing both horizontal and vertical draft heads that speculate tokens, exploiting the two-dimensional spatial structure of images. This spatial speculative decoding expands the sampling space and improves alignment between draft and target models, leading to more accurate and efficient predictions. Experiments demonstrate Hawk achieves significant speedup while maintaining image quality, outperforming existing speculative decoding methods.

## Method Summary
Hawk builds on speculative decoding by adding vertical draft heads to complement standard horizontal speculation. At each generation step T, horizontal heads predict tokens T+1 through T+n while vertical heads predict tokens T+ImageWidth×depth. The method caches vertical predictions across rows and combines them with horizontal candidates to form a spatial sampling pool. Sequential verification ensures distribution preservation while enabling acceleration. The approach is implemented on top of Lumina-mGPT with only draft heads trained (base model frozen).

## Key Results
- Achieves 1.71× inference acceleration over standard autoregressive models
- Maintains near-identical FID (90.71 vs 90.68) and CLIP scores (33.39 vs 33.43) compared to baseline
- Outperforms existing speculative decoding methods on COCO2017 and Flickr30K datasets
- Dual-direction heads show complementary predictions in complex image regions (higher KL divergence)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dual-direction draft heads improve draft-target alignment by exploiting 2D spatial dependencies in images, increasing acceptance rates.
- **Mechanism:** Vertical draft heads predict tokens at position T + ImageWidth × VerticalDepth, complementing horizontal heads that predict T + n. Attention-sinking experiments reveal that image generation attends strongly to spatial-neighboring points from previous rows.
- **Core assumption:** Spatial-neighboring tokens provide predictive signal even when inference-neighboring context is incomplete during speculation.
- **Evidence anchors:** [abstract], [Section 4.1, Figure 1], [corpus]

### Mechanism 2
- **Claim:** Merging horizontal and vertical sampling pools reduces residual rejection probability r(x) compared to single-direction speculation.
- **Mechanism:** At each speculation point T+n, the spatial sampling pool combines HorizSpec(T+n) and VertSpec(T+n). Diverse draft distributions from different heads enable recursive reduction of residual probability.
- **Core assumption:** Horizontal and vertical draft heads produce complementary, non-identical proposal distributions.
- **Evidence anchors:** [Section 5.2, Figure 5], [Section 5.2, Figure 6], [corpus]

### Mechanism 3
- **Claim:** Sequential verification with dual-draft distributions preserves the target model's output distribution while enabling acceleration.
- **Mechanism:** The paper proves that sequential validation—first vertical, then horizontal—maintains p(x) = p_target(x). When vertical tokens are rejected, the adjusted distribution p'_vert(x) is used for horizontal verification.
- **Core assumption:** Verification follows the exact speculative sampling criterion: accept with probability min(1, p_target/p_draft).
- **Evidence anchors:** [Section 4.2], [Table 1], [corpus]

## Foundational Learning

- **Concept: Speculative Decoding**
  - **Why needed here:** Hawk builds directly on speculative decoding's draft-then-verify framework. Without understanding how draft model alignment affects acceptance rates, the spatial innovation won't make sense.
  - **Quick check question:** Given a draft distribution q(x) and target p(x), what is the acceptance probability for token x?

- **Concept: Raster Scan Order in AR Image Generation**
  - **Why needed here:** The paper exploits the mismatch between 1D raster order and 2D spatial structure. Understanding this ordering is essential to see why vertical speculation requires caching across rows.
  - **Quick check question:** In raster order, which tokens precede position (row=r, col=c) in the 1D sequence?

- **Concept: Attention Sinking**
  - **Why needed here:** Section 4.1's attention-sinking experiment motivates the spatial design. The phenomenon explains why vertical neighbors matter despite being distant in token sequence.
  - **Quick check question:** What is the difference between inference-neighboring and spatial-neighboring tokens?

## Architecture Onboarding

- **Component map:** Horizontal Draft Heads -> Vertical Draft Heads -> Speculation Cache -> Spatial Sampling Pool -> Tree Verification Module

- **Critical path:**
  1. At current position T, run all draft heads in single forward pass
  2. Cache vertical predictions indexed by target position
  3. Retrieve cached vertical predictions for current row's speculation points
  4. Build spatial sampling pool → generate candidate tree
  5. Verify sequentially; on rejection, update residual distribution

- **Design tradeoffs:**
  - Cache memory vs. VSD depth: Larger VSD increases cache size quadratically
  - Candidate count vs. verification overhead: More candidates increase tree complexity
  - Vertical depth vs. prediction accuracy: Deeper vertical speculation has lower loss decay but longer dependency chains

- **Failure signatures:**
  - Low acceptance length (<1.5): Likely draft-target misalignment; check head training
  - Quality degradation (FID increase): Verification relaxation or implementation bug
  - Cache underflow: VSD too large for image height or improper indexing
  - Minimal speedup despite acceptance: Verification overhead dominates

- **First 3 experiments:**
  1. Ablate vertical heads: Compare Hawk (spatial) vs. horizontal-only (Medusa baseline). Measure acceptance length and FID on 100 images.
  2. Attention visualization: Replicate Figure 1 on your target model. Confirm spatial-neighbor attention peaks exist before implementing vertical heads.
  3. Cache depth sweep: Test VSD ∈ {1, 2, 3} on 256×256 images. Monitor cache memory, acceptance length, and wall-clock speedup to find Pareto frontier.

## Open Questions the Paper Calls Out
- Can integrating Hawk with more advanced speculative decoding backbones (e.g., Eagle or Hydra) significantly improve upon the reported 1.71× speedup?
- How do specific image content distributions (e.g., vertical vs. horizontal structures) correlate with the relative performance of vertical versus horizontal draft heads?
- Is the reliance on spatial "attention sinking" consistent across different autoregressive architectures, or is it unique to the Lumina-mGPT model family?

## Limitations
- Missing concrete hyperparameter values for horizontal speculation length (n) and vertical speculation depth (VSD)
- Theoretical analysis for residual probability reduction lacks external validation
- Reliance on exact implementation of speculative sampling criterion for distribution preservation guarantees
- Performance depends on specific attention patterns that may not generalize across architectures

## Confidence

- **High Confidence:** Spatial attention patterns - The attention-sinking experiment is directly demonstrated and aligns with established findings
- **Medium Confidence:** Distribution preservation via sequential verification - The proof is sound but relies on exact implementation fidelity
- **Low Confidence:** Residual probability reduction through dual-direction heads - The theoretical analysis is internally consistent but lacks external validation

## Next Checks

1. **KL Divergence Analysis:** Measure KL divergence between horizontal and vertical draft head distributions across different image regions to verify complementary predictions.

2. **Attention Pattern Replication:** Replicate the attention-sinking experiment on the target model to confirm spatial-neighbor attention peaks exist before implementing vertical heads.

3. **Ablation on Vertical Depth:** Systematically vary VSD from 1 to 3 on 256×256 images, measuring acceptance length, cache memory usage, and wall-clock speedup to identify the Pareto frontier.