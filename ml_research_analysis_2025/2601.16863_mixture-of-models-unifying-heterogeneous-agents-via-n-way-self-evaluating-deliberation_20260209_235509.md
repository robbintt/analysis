---
ver: rpa2
title: 'Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating
  Deliberation'
arxiv_id: '2601.16863'
source_url: https://arxiv.org/abs/2601.16863
tags:
- nsed
- agent
- agents
- round
- consensus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a method for combining multiple small language
  models to achieve performance comparable to much larger models. The approach, called
  N-Way Self-Evaluating Deliberation (NSED), treats model selection as a runtime optimization
  problem and formalizes deliberation as a recurrent process where consensus is refined
  over multiple rounds.
---

# Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation

## Quick Facts
- arXiv ID: 2601.16863
- Source URL: https://arxiv.org/abs/2601.16863
- Reference count: 40
- Primary result: Small model ensembles (<20B) achieve performance matching or exceeding 100B+ parameter models using N-Way Self-Evaluating Deliberation

## Executive Summary
This paper introduces a novel approach for combining multiple small language models to achieve performance comparable to much larger models. The method, called N-Way Self-Evaluating Deliberation (NSED), treats model selection as a runtime optimization problem and formalizes deliberation as a recurrent process where consensus is refined over multiple rounds. The approach uses innovative mechanisms like identity masking, diagonal voting masks, and a Quadratic Voting activation function to prevent sycophancy and achieve non-linear consensus.

## Method Summary
The N-Way Self-Evaluating Deliberation (NSED) method combines multiple small language models through a trustless topology that uses identity masking and diagonal voting masks to prevent model bias and sycophancy. The approach formalizes deliberation as a recurrent process with consensus refinement over multiple rounds, using a Quadratic Voting activation function for non-linear consensus building. Model selection is treated as a runtime optimization problem, enabling the ensemble to dynamically choose the most appropriate models for each task.

## Key Results
- Small model ensembles (<20B parameters) achieved performance matching or exceeding state-of-the-art 100B+ parameter models on challenging benchmarks (AIME 2025, LiveCodeBench)
- The protocol demonstrated intrinsic alignment properties, reducing sycophancy scores below that of any individual agent when tested on the DarkBench safety suite
- The method showed effectiveness in combining heterogeneous agents through a trustless topology with identity masking

## Why This Works (Mechanism)
The NSED approach works by treating model selection as an optimization problem at runtime and formalizing deliberation as a recurrent consensus-building process. The trustless topology with identity masking prevents individual models from influencing others based on their identity or reputation. The diagonal voting masks further prevent sycophancy by ensuring models cannot simply agree with the most confident peer. The Quadratic Voting activation function introduces non-linear dynamics to the consensus process, allowing for more nuanced aggregation of diverse opinions.

## Foundational Learning

**Identity Masking**: A technique to hide model identities during deliberation to prevent bias and reputation-based influence
- Why needed: Prevents models from deferring to perceived higher-capability agents or established reputations
- Quick check: Verify models cannot infer peer identities through response patterns or voting behavior

**Diagonal Voting Masks**: Matrix structures that prevent models from simply agreeing with the most confident peer
- Why needed: Avoids sycophancy where models might agree with confident but incorrect answers
- Quick check: Ensure voting patterns show independent reasoning rather than blind agreement

**Quadratic Voting**: A non-linear voting mechanism where vote weight increases quadratically with intensity
- Why needed: Enables more nuanced expression of confidence and prevents simple majority voting
- Quick check: Verify that voting weights follow expected quadratic relationship with confidence scores

**Recurrent Deliberation**: Multiple rounds of consensus refinement where agents iteratively improve their responses
- Why needed: Allows complex problems to be broken down and solved through progressive refinement
- Quick check: Measure improvement in consensus quality across deliberation rounds

**Trustless Topology**: A network architecture where agents operate without requiring trust in each other's outputs
- Why needed: Enables collaboration between potentially adversarial or misaligned models
- Quick check: Test system robustness against adversarial agents attempting to manipulate consensus

## Architecture Onboarding

**Component Map**: Models -> Identity Masking Layer -> Diagonal Voting Masks -> Quadratic Voting Function -> Consensus Refinement Loop -> Output Selection

**Critical Path**: Input Problem -> Model Inference (masked) -> Voting Phase -> Consensus Calculation -> Iteration Decision -> Final Output

**Design Tradeoffs**: The trustless topology adds computational overhead but provides robustness against model bias and manipulation. Identity masking reduces the potential for reputation-based deference but may limit beneficial knowledge transfer. The Quadratic Voting function adds complexity but enables more nuanced consensus building.

**Failure Signatures**: Performance degradation when models have highly correlated errors, breakdown of consensus in highly ambiguous scenarios, potential for cycling in recurrent deliberation without proper termination conditions.

**First Experiments**:
1. Test single-round deliberation vs multi-round deliberation on simple arithmetic problems
2. Compare Quadratic Voting vs linear voting on problems requiring confidence calibration
3. Evaluate identity masking effectiveness by attempting to infer model identities from deliberation patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Performance claims rely heavily on controlled benchmark settings, leaving uncertainty about generalization to open-ended real-world tasks
- Trustless topology and identity masking lack theoretical guarantees against sophisticated adversarial behaviors or collusion
- Quadratic Voting's non-linear properties may introduce optimization challenges in larger ensembles or under distributional shifts

## Confidence

**High confidence**: Empirical performance matching large models on specific benchmarks
**Medium confidence**: Deliberation protocol's effectiveness in preventing sycophancy and ensuring consensus
**Medium confidence**: Runtime optimization formulation for model selection
**Low confidence**: Scalability to heterogeneous ensembles with diverse model families and capabilities

## Next Checks

1. Test NSED on open-ended tasks with diverse model combinations (different architectures, training paradigms) to assess robustness beyond curated benchmarks
2. Conduct adversarial evaluation to probe vulnerabilities in the trustless topology and identity masking against coordinated manipulation attempts
3. Perform ablation studies isolating the impact of each innovation (diagonal voting masks, Quadratic Voting, recurrent deliberation) to quantify individual contributions to performance gains