---
ver: rpa2
title: 'ViT-NeBLa: A Hybrid Vision Transformer and Neural Beer-Lambert Framework for
  Single-View 3D Reconstruction of Oral Anatomy from Panoramic Radiographs'
arxiv_id: '2506.13195'
source_url: https://arxiv.org/abs/2506.13195
tags:
- image
- reconstruction
- each
- cbct
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of reconstructing 3D oral anatomy
  from a single panoramic radiograph, which lacks depth information compared to 3D
  imaging modalities like CBCT. The authors propose ViT-NeBLa, a hybrid Vision Transformer
  and Neural Beer-Lambert model that leverages a novel horseshoe-shaped sampling strategy
  and learnable hash positional encoding to achieve high-fidelity 3D reconstruction
  without requiring intermediate CBCT flattening or dental arch information.
---

# ViT-NeBLa: A Hybrid Vision Transformer and Neural Beer-Lambert Framework for Single-View 3D Reconstruction of Oral Anatomy from Panoramic Radiographs

## Quick Facts
- **arXiv ID:** 2506.13195
- **Source URL:** https://arxiv.org/abs/2506.13195
- **Reference count:** 0
- **Primary result:** Achieves 23.48 dB PSNR, 74.93% SSIM, and 0.4204 LPIPS on single-view 3D reconstruction of oral anatomy from panoramic radiographs

## Executive Summary
This paper addresses the challenge of reconstructing 3D oral anatomy from a single panoramic radiograph, which lacks depth information compared to 3D imaging modalities like CBCT. The authors propose ViT-NeBLa, a hybrid Vision Transformer and Neural Beer-Lambert model that leverages a novel horseshoe-shaped sampling strategy and learnable hash positional encoding to achieve high-fidelity 3D reconstruction without requiring intermediate CBCT flattening or dental arch information. The method significantly outperforms existing state-of-the-art approaches, achieving a PSNR of 23.48 dB, SSIM of 74.93%, and LPIPS of 0.4204, while reducing sampling point computations by 52%.

## Method Summary
ViT-NeBLa combines a hybrid ViT-CNN feature extractor with a learnable hash positional encoding and MLP density predictor to reconstruct 3D oral anatomy from a single panoramic radiograph. The method uses a horseshoe-shaped focal region to constrain ray sampling to 96 points (52% fewer than baseline), with rays tangent to an elliptical trajectory to avoid intersections. A hybrid ViT-CNN architecture captures both global context and local features, which are fused and combined with hash-encoded positional information before being processed by an 8-layer MLP. The model is trained end-to-end using a composite loss function including MSE, projection consistency, and perceptual losses, and refined with a 3D U-Net to produce the final CBCT volume.

## Key Results
- Achieves 23.48 dB PSNR, 74.93% SSIM, and 0.4204 LPIPS on test set
- Reduces sampling point computations by 52% compared to baseline NeBLa
- Outperforms state-of-the-art 3DentAI method (20.05 dB PSNR) by 3.43 dB
- Successfully reconstructs complex oral anatomy without requiring dental arch curves or CBCT flattening

## Why This Works (Mechanism)

### Mechanism 1: Horseshoe-Shaped Non-Intersecting Ray Sampling
Restricting ray sampling to an anatomically-constrained horseshoe region reduces computational overhead while maintaining reconstruction fidelity, conditional on the assumption that all relevant oral anatomy lies within this focal trough. By stimulating rays tangent to an elliptical trajectory and sampling only 96 points within the horseshoe-shaped focal region (vs. 200 points in baseline NeBLa), rays never intersect. This eliminates the need for intermediate density aggregation that intersecting rays require. The non-intersection property means each 3D query point belongs to exactly one ray, simplifying the density prediction to a direct mapping.

### Mechanism 2: Hybrid ViT-CNN Feature Fusion
Combining Vision Transformer global context with CNN local feature extraction yields richer representations for 3D lifting than either architecture alone, conditional on the input image requiring both global anatomical coherence and fine local detail preservation. The ViT encoder-decoder captures long-range dependencies across patches via self-attention (12 layers, 8 attention heads), understanding whole-image context like jaw curvature relationships. Parallel CNN branches (3 conv blocks with Swish activation) extract fine-grained textures and edges. Features are fused via element-wise addition then projected to a shared embedding space. This dual-pathway allows the MLP density predictor to receive both "where anatomical structures are globally" and "what fine details exist locally."

### Mechanism 3: Learnable Multi-Resolution Hash Positional Encoding
Hash-based positional encoding captures high-frequency spatial variations at constant memory cost, enabling finer detail reconstruction than Fourier-based dense encodings, conditional on hash collision rates remaining low for the coordinate space. Rather than storing dense 3D feature grids (memory-prohibitive at fine resolutions), the approach uses 16 learnable hash tables at resolutions from 16 to 256. Each 3D coordinate is hashed via XOR of scaled integer coordinates, retrieving F=2 dimensional features per level. These are concatenated with the original coordinates, yielding a 35-dimensional encoding. Backpropagation adapts hash table entries to specialize for regions demanding high fidelity.

## Foundational Learning

- **Concept: Neural Radiance Fields (NeRF) and Volume Rendering**
  - **Why needed here:** ViT-NeBLa adapts NeRF's implicit representation for medical imaging. Understanding how NeRF predicts density at continuous 3D points and renders via ray integration is essential to grasp why horseshoe sampling and MLP density prediction work.
  - **Quick check question:** Can you explain why NeRF represents scenes as continuous functions rather than discrete voxels, and how that affects memory scaling?

- **Concept: Beer-Lambert Law for X-ray Attenuation**
  - **Why needed here:** The "NeBLa" framework integrates X-ray physics—the Beer-Lambert law relates ray attenuation to tissue density. The synthetic PX generation and projection consistency loss both depend on this physical model.
  - **Quick check question:** If X-ray intensity decreases exponentially with path length through material, how would you compute the total attenuation for a ray passing through a volume with varying densities?

- **Concept: Transformer Self-Attention and Positional Encodings**
  - **Why needed here:** The ViT branch uses patch embeddings + learnable positional encodings + multi-head self-attention. Understanding why transformers need explicit positional information (unlike CNNs with implicit spatial structure) clarifies the hybrid architecture design.
  - **Quick check question:** Why can't a vanilla transformer distinguish between a patch at position (0,0) vs. (7,15) without positional encoding?

## Architecture Onboarding

- **Component map:**
Input PX Image (1×128×256)
    │
    ├─→ [ViT Branch] Patch Embed → 12-layer Encoder-Decoder → E_global
    │                                     │
    └─→ [CNN Branch] 3 Conv Blocks ───────┴─→ Add fusion → E_img (128×256×κ)
                                                                        │
3D Query Points P(r,s) ─→ [Hash Encoder Φ] ─→ Linear ϕ_pos ─→ f_pos     │
                                                                        ↓
                                                                   Element-wise Add
                                                                        │
                                                                   MLP M (8 layers, skip at 4)
                                                                        │
                                                                   Scalar density ρ̂(r,s)
                                                                        │
                                                                   Volume Rendering
                                                                        │
                                                                   Coarse 3D Volume
                                                                        │
                                                                   3D U-Net Refinement
                                                                        │
                                                                   Final ρ (1×128×256×256)

- **Critical path:** The fusion point where `f_img` and `f_pos` combine is the architectural bottleneck—incorrect feature alignment here propagates errors through the entire MLP and refinement pipeline.

- **Design tradeoffs:**
  - **96 vs. 200 sample points:** Memory/speed vs. reconstruction detail. Paper claims 52% savings without fidelity loss, but this is conditional on horseshoe region containing all relevant anatomy.
  - **Hash encoding vs. Fourier:** Memory efficiency vs. potential collision artifacts. Hash tables are learned (adaptable) but may not generalize to out-of-distribution coordinate ranges.
  - **Hybrid ViT-CNN vs. pure CNN:** Computational cost vs. global context. ViT adds significant overhead (12 transformer layers) but provides quantitative gains (Table II).

- **Failure signatures:**
  - Blurred mandibular borders + missing fine foramina → likely issue in CNN local feature branch or perceptual loss not activated
  - Anatomically impossible jaw curvature → ViT global context failing, possibly attention attending to irrelevant regions
  - High LPIPS despite acceptable PSNR → perceptual features misaligned; check VGG feature extraction in loss
  - Discontinuities along ray paths → hash collision artifacts or insufficient MLP capacity

- **First 3 experiments:**
  1. **Ablate each loss term individually** (MSE only, MSE+Proj, MSE+Proj+Perc) on a held-out test set to reproduce Table IV results. This validates the loss contribution claims and establishes baseline before architecture changes.
  2. **Visualize attention maps from ViT encoder** on sample PX inputs to verify global context is attending to anatomically relevant regions (jaw, teeth) rather than background. Correlate attention patterns with reconstruction quality.
  3. **Test horseshoe boundary sensitivity** by systematically expanding/contracting the focal region width. Plot PSNR/SSIM vs. sample points to find the efficiency-quality frontier and validate the 96-point design choice.

## Open Questions the Paper Calls Out

- **Can advanced image-to-image translation techniques (e.g., diffusion models, StyleGAN3) effectively bridge the performance gap between synthetic training data and real panoramic radiographs containing ghost artifacts?**
  - **Basis in paper:** The authors state that a limitation is the "discrepancy between synthetic and original PX images," and suggest future work could leverage techniques like diffusion models or StyleGAN3 to transform real images to resemble synthetic counterparts.
  - **Why unresolved:** The current model trains on synthetic data, leading to suboptimal predictions when inputting noisier real clinical images with ghost artifacts.
  - **What evidence would resolve it:** A study demonstrating improved reconstruction metrics (PSNR/SSIM) on real clinical inputs processed through a new translation module compared to the baseline synthetic-only training.

- **Can integrating an explicit 3D representation, such as Gaussian splatting, with the current implicit volumetric field improve utility for downstream tasks like mesh-based surgical planning?**
  - **Basis in paper:** The conclusion notes that the implicit representation "inherently obscures the explicit geometry favored in downstream workflows" and proposes extending ViT-NeBLa with Gaussian splatting as a next step.
  - **Why unresolved:** While the current implicit representation is memory-efficient, it lacks the immediate geometric interpretability required for specific clinical applications like surgical guides.
  - **What evidence would resolve it:** Successful generation of explicit 3D meshes or surfaces from the model that maintain the accuracy of the implicit field while being compatible with standard surgical planning software.

- **To what extent would implementing dynamic sampling strategies within the focal trough improve prediction accuracy over the current uniform sampling approach?**
  - **Basis in paper:** The authors identify the current uniform sampling within the Region of Interest (ROI) as a limitation and explicitly list "implement[ing] dynamic sampling techniques" as a future aim to achieve more refined predictions.
  - **Why unresolved:** The current method uses a fixed 96-point uniform sample per ray, which may be computationally efficient but potentially less precise than adapting sample density to local anatomical complexity.
  - **What evidence would resolve it:** Comparative results showing that an adaptive/dynamic sampling method yields higher fidelity reconstructions of fine structures (e.g., root canals) without incurring the computational cost of uniformly high sampling rates.

## Limitations
- Relies entirely on synthetic PX data generated from CBCT scans, creating domain gap with real clinical radiographs containing artifacts and noise
- Horseshoe-shaped sampling assumes standard dental anatomy; pathological cases with atypical jaw geometry may fall outside focal region
- No direct comparison with NeBLa baseline makes it difficult to isolate architectural innovations versus sampling strategy impact

## Confidence

- **High:** Horseshoe sampling reduces computations (52%) and maintains PSNR/SSIM metrics; hybrid ViT-CNN design yields measurable improvements over pure CNN (20.05→23.48 dB PSNR); loss formulation components are empirically justified.
- **Medium:** Hash positional encoding enables constant memory at fine resolution; projection consistency loss contributes to reconstruction fidelity; model generalizes across unseen patients within the dataset.
- **Low:** Claims of clinical usability without intermediate CBCT flattening; robustness to real PX domain shift; scalability to more complex oral pathologies.

## Next Checks

1. **Domain Adaptation Test:** Fine-tune ViT-NeBLa on a small set of real PX-CBCT pairs and measure PSNR/SSIM degradation compared to synthetic-only training.
2. **Ablation of Horseshoe Region:** Systematically expand/contract the horseshoe focal region and plot the efficiency-quality frontier to verify the 96-sample design choice.
3. **Pathology Robustness:** Test reconstruction on CBCT volumes containing atypical anatomy (e.g., large cysts, tumors) and quantify coverage of structures outside the default horseshoe boundary.