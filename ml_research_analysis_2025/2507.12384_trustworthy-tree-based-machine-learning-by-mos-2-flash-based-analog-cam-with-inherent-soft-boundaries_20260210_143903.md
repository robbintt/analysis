---
ver: rpa2
title: Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with
  Inherent Soft Boundaries
arxiv_id: '2507.12384'
source_url: https://arxiv.org/abs/2507.12384
tags:
- analog
- tree
- soft
- decision
- device
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of implementing trustworthy and
  robust tree-based machine learning models in hardware, particularly focusing on
  the limitations of sharp decision boundaries in analog content-addressable memory
  (CAM) which are vulnerable to device variations and adversarial attacks. The core
  method involves leveraging the inherent soft boundaries of MoS2 Flash-based analog
  CAM to naturally implement soft decision trees (SDTs), where probabilistic sigmoid-like
  decision boundaries are used instead of hard binary splits.
---

# Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries

## Quick Facts
- **arXiv ID:** 2507.12384
- **Source URL:** https://arxiv.org/abs/2507.12384
- **Reference count:** 40
- **Primary result:** Hardware-software co-design using MoS2 Flash-based analog CAM with inherent soft boundaries achieves 96% accuracy on WDBC and 3-4 orders of magnitude speedup over GPU/CPU for soft decision trees

## Executive Summary
This work addresses the challenge of implementing trustworthy and robust tree-based machine learning models in hardware, particularly focusing on the limitations of sharp decision boundaries in analog content-addressable memory (CAM) which are vulnerable to device variations and adversarial attacks. The core method involves leveraging the inherent soft boundaries of MoS2 Flash-based analog CAM to naturally implement soft decision trees (SDTs), where probabilistic sigmoid-like decision boundaries are used instead of hard binary splits. This hardware-software co-design approach enables efficient parallel computation of path probabilities directly in the analog domain. The primary results demonstrate exceptional robustness: SDT implemented in the fabricated 8×8 MoS2 analog CAM array achieved 96% accuracy on the Wisconsin Diagnostic Breast Cancer dataset and maintained accuracy with only a 0.6% drop under 10% device threshold variation on MNIST, compared to a 45.3% drop for traditional decision trees.

## Method Summary
The method converts hard decision trees to soft decision trees by fitting sigmoid-like decision boundaries to the analog CAM cell behavior, then maps these to programmable threshold voltages in a 2-FET MoS2 Flash-based CAM array. Inputs are normalized to [-1, 1] V and applied through analog inverters to DLs, where cells collectively compute path probabilities via match line discharge curves. A winner-takes-all circuit selects the highest probability path. Training uses gradient descent to optimize thresholds based on a circuit-aware behavioral model, with offline conversion from DT to SDT before hardware deployment.

## Key Results
- 96% accuracy on Wisconsin Diagnostic Breast Cancer dataset using fabricated 8×8 MoS2 analog CAM array
- 0.6% accuracy drop under 10% device threshold variation vs 45.3% drop for traditional decision trees on MNIST
- 3-4 orders of magnitude speedup and 5-6 orders of magnitude energy reduction compared to GPU/CPU implementations

## Why This Works (Mechanism)

### Mechanism 1: Soft Boundary Natural Mapping
The inherent gradual switching behavior of analog CAM cells naturally implements sigmoid-like decision functions required by Soft Decision Trees. Each 2-FET analog CAM cell exhibits a soft (non-abrupt) search boundary due to transistor subthreshold swing physics. Rather than sharpening this—which increases sensitivity to variations—the approach uses this "limitation" as a feature. The match line (ML) voltage discharge curve follows a sigmoid-like function of input voltage: p_i = σ(k(V_in - V_th)), directly representing node probability.

### Mechanism 2: Parallel Path Probability Computation
The analog CAM array computes all root-to-leaf path probabilities in O(1) time through collective cell discharge behavior. Each row maps to one root-to-leaf path. When cells share a match line (ML), the discharge voltage represents the collective effect of node probabilities: V_ML,t ≈ a·∏p_i + b·∑p_i - b(n-1)V_ML,t0. For large arrays, coefficient b→0, yielding near-pure product form. Winner-takes-all (WTA) circuit selects the highest probability path.

### Mechanism 3: Variation Robustness Through Probabilistic Tolerance
Soft tree models in analog CAM exhibit superior robustness to device threshold variations because probabilistic decisions change smoothly rather than flipping abruptly. Hard decision boundaries create "cliffs" where small threshold shifts cause incorrect path selection. Soft boundaries distribute probability mass across paths; small perturbations adjust probability values continuously but rarely change the argmax. Training incorporates the soft boundary behavior, learning robust threshold placements.

## Foundational Learning

- **Concept: Soft Decision Trees (SDTs) vs. Hard Decision Trees**
  - Why needed here: This is the core algorithmic change enabling hardware-software co-design. Understanding why SDTs are computationally expensive on digital hardware (O(2^d) for evaluating all paths vs. O(d) for single-path DT traversal) but map naturally to analog CAM is essential.
  - Quick check question: Why must SDTs evaluate all paths while DTs traverse only one path per inference?

- **Concept: Analog Content-Addressable Memory (CAM) Cell Operation**
  - Why needed here: The 2-FET analog CAM cell design is fundamental—left and right FETs define search boundaries through programmable threshold voltages, and the match line discharge encodes match degree.
  - Quick check question: In a 2-FET analog CAM cell, how do the threshold voltages of the left and right FETs define the search range for an input?

- **Concept: Subthreshold Swing and Soft Boundaries**
  - Why needed here: Understanding why FETs have gradual (not abrupt) switching is essential—the subthreshold swing is a physical limitation that prevents ideal step-function thresholds.
  - Quick check question: What physical mechanism prevents ideal step-function switching in MOSFETs, and how does this create soft boundaries?

## Architecture Onboarding

- **Component map:** 2D MoS2 Flash array -> Match Lines (MLs) -> Data Lines (DLs) -> Winner-Takes-All (WTA) circuit
- **Critical path:** 1) Program threshold voltages to cells based on trained SDT model, 2) Precharge all MLs via Charge Unit, 3) Apply normalized input features to DLs, 4) MLs discharge based on collective cell behavior, 5) Sample ML voltage at predefined time point, 6) WTA circuit selects highest voltage row
- **Design tradeoffs:** Array width vs. error (~1000 columns achievable with <1% probability error), sensing latency vs. boundary softness (longer sampling produces softer curves), tree depth vs. latency (analog CAM maintains O(1) latency), energy (~8.78 nJ/sample at 200nm process)
- **Failure signatures:** High programming error (>0.1V drift), ML curves not fitting sigmoid, multiple MLs with similar voltages, accuracy collapse under variation (>5% drop)
- **First 3 experiments:** 1) Single-cell sigmoid characterization with r² > 0.99, 2) 4-cell row probability validation with RMSE < 0.02, 3) Small SDT deployment (Iris dataset) with accuracy >95% and <1% drop under variation

## Open Questions the Paper Calls Out
- Can the proposed scalable architecture maintain high inference accuracy when physically fabricated at the scale required for complex datasets beyond the demonstrated 8×8 array?
- Can the MoS2 Flash-based analog CAM support in-situ training or online fine-tuning of the soft decision tree thresholds?
- How does the "softness" of the decision boundary—and consequently the model's robustness—vary when implementing this architecture on other threshold-tunable FETs like FeFETs or Si-Flash?

## Limitations
- Device variation modeling assumes independent threshold fluctuations across cells; correlation effects are not characterized
- Scaling beyond 8×8 arrays introduces parasitic effects not fully modeled; 1000-column arrays are projected but unverified
- Training hyperparameters for gradient descent conversion from DT to SDT are not specified, limiting reproducibility

## Confidence
- **High Confidence:** Soft boundary mechanism enabling robustness (direct experimental evidence, 0.6% vs 45.3% accuracy drop under variation)
- **High Confidence:** Parallel path probability computation (model fits experimental data with r²=0.999, RMSE=0.01)
- **Medium Confidence:** Energy and latency projections for scaled arrays (based on scaling assumptions, not direct measurement)
- **Low Confidence:** Generalization to datasets beyond WDBC/MNIST (only three datasets tested)

## Next Checks
1. Characterize threshold variation correlation across neighboring cells; test if robustness holds under correlated variations
2. Fabricate or simulate 128×128 subarray to verify product approximation holds and accuracy scales as projected
3. Systematically vary learning rate and epochs for DT→SDT conversion to determine robustness of final accuracy to training choices