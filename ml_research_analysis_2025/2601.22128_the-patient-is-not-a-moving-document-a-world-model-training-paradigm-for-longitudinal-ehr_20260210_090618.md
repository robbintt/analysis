---
ver: rpa2
title: 'The Patient is not a Moving Document: A World Model Training Paradigm for
  Longitudinal EHR'
arxiv_id: '2601.22128'
source_url: https://arxiv.org/abs/2601.22128
tags:
- clinical
- patient
- jepa
- training
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SMB-Structure, a training paradigm for clinical
  foundation models that explicitly models patient trajectories as dynamical systems
  rather than documents to be summarized. The key innovation is combining supervised
  fine-tuning (SFT) with a Joint-Embedding Predictive Architecture (JEPA), where JEPA
  forces the model to predict future patient states in latent space before observing
  them, compelling the encoder to capture disease dynamics.
---

# The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR

## Quick Facts
- **arXiv ID**: 2601.22128
- **Source URL**: https://arxiv.org/abs/2601.22128
- **Reference count**: 13
- **Key outcome**: SMB-Structure achieves competitive trajectory-level performance on EHR tasks, especially excelling at long-horizon predictions (0.731 AUC) compared to autoregressive baselines (0.719).

## Executive Summary
This paper introduces SMB-Structure, a training paradigm that treats patient trajectories as dynamical systems rather than documents to be summarized. The key innovation is combining supervised fine-tuning (SFT) with a Joint-Embedding Predictive Architecture (JEPA), where JETA forces the model to predict future patient states in latent space before observing them. This compels the encoder to capture disease dynamics rather than deferring reasoning to the decoding step. Validated on 23,319 oncology patients and 19,402 PE patients, SMB-Structure demonstrates superior performance on trajectory-level reasoning tasks, particularly excelling at long-horizon predictions where traditional autoregressive models struggle.

## Method Summary
SMB-Structure trains clinical foundation models using a curriculum approach: first applying supervised fine-tuning (SFT) to ground representations in semantic meaning, then adding Joint-Embedding Predictive Architecture (JEPA) to learn dynamical systems modeling. The method serializes EHR into token sequences with custom clinical delimiters, masks future tokens at 50% ratio, and trains the model to predict latent embeddings of masked sections using a momentum encoder. The model uses LLaMA-3 or Qwen-3 backbone with LoRA fine-tuning, a 2-layer predictor MLP, and momentum encoder with EMA updates (τ=0.996).

## Key Results
- Curriculum (SFT → JEPA) achieves 0.731 AUC on disease progression tasks, outperforming Hybrid (0.719) and SFT-only (0.727)
- JEPA model's advantage increases with time horizon, demonstrating capture of "clinical momentum"
- Adding INSPECT cohort to MSK training significantly boosts chronic oncology task performance (0.735 to 0.746)
- Mask ratio of 0.5 is optimal; 0.25 leaks too much info, 0.75 destroys trajectory logic

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Predicting future patient states in latent space (JEPA) compels the encoder to capture "clinical momentum" (trajectory dynamics) which autoregressive token prediction ignores.
- **Mechanism**: By masking the future and forcing the model to predict the *embedding* of that future (rather than the tokens), the encoder must aggregate the history into a state representation that implies the trajectory.
- **Core assumption**: Disease dynamics can be captured more effectively by predicting abstract state representations than by predicting surface-form clinical text tokens.
- **Evidence anchors**:
  - [abstract] "JEPA forces the model to predict future patient states in latent space... compelling the encoder to capture disease dynamics."
  - [section 3.3.2] "The key distinction from SFT is temporal: the encoder must predict future embeddings without access to the masked tokens, forcing it to encode trajectory dynamics in the context representation."

### Mechanism 2
- **Claim**: Semantic grounding (SFT) must precede dynamical modeling (JEPA) because simultaneous optimization causes "objective interference" between reconstruction and abstraction.
- **Mechanism**: SFT optimizes for high-frequency local details (token accuracy), while JEPA optimizes for abstract state evolution. Joint optimization creates conflicting gradients; curriculum learning allows the model to ground the representation space before learning to simulate it.
- **Core assumption**: The representation space must be semantically structured before it can support meaningful dynamical simulation.
- **Evidence anchors**:
  - [abstract] "The curriculum variant (SFT then JEPA) outperforms joint optimization, confirming that semantic grounding must precede dynamical modeling."
  - [section 4.5.1] "Hybrid (M) lags behind SFT (M)... suggests a fundamental objective interference phenomenon."

### Mechanism 3
- **Claim**: Training on heterogeneous trajectory types (acute PE and chronic oncology) provides "trajectory regularization" that improves generalization, specifically for the JEPA objective.
- **Mechanism**: While token-prediction (SFT) learns dataset-specific statistics, latent-prediction (JEPA) appears to learn universal dynamics of physiological change. Exposure to acute trajectories sharpens the model's sensitivity to subtle progression signals in chronic trajectories.
- **Core assumption**: There exist transferable "dynamics of change" across distinct disease domains that are invisible to surface-level token analysis.
- **Evidence anchors**:
  - [abstract] "Exposing the model to diverse trajectory types... provides trajectory regularization, improving generalization across diseases."
  - [section 4.5.1] "Adding the INSPECT cohort... significantly boosts performance on the chronic... oncology tasks... Hybrid LLaMA mortality prediction jumps from 0.735 to 0.746."

## Foundational Learning

- **Concept: Joint-Embedding Predictive Architecture (JEPA)**
  - **Why needed here**: This is the core deviation from standard LLMs. JEPA predicts *embeddings* (latent features) of masked sections, not the tokens themselves. This forces the model to learn high-level abstractions (semantics/dynamics) rather than pixel/token-level details.
  - **Quick check question**: If I mask the last 50% of a patient's timeline, does JEPA try to predict the ICD codes, or the abstract state vector representing the patient's condition?

- **Concept: Momentum Encoder (EMA)**
  - **Why needed here**: The paper uses an Exponential Moving Average (EMA) of the encoder weights to generate target embeddings. This provides stable, slowly-evolving targets which prevents the model from collapsing to trivial solutions (e.g., making all representations identical).
  - **Quick check question**: Why can't we use the standard online encoder to generate the target embeddings for the JEPA loss? (Answer: Risk of collapse/unstable training).

- **Concept: Dynamical Systems vs. Autoregression**
  - **Why needed here**: The paper frames clinical modeling as "simulation" rather than "summarization." A dynamical system view implies the current state encodes velocity/momentum (where the patient is going), not just position (what the patient has).
  - **Quick check question**: Does a standard autoregressive model (GPT-style) explicitly encode the *rate of change* of a patient's condition in its hidden state before decoding? (Paper argues: No).

## Architecture Onboarding

- **Component map**: EHR tokens → Backbone (LLaMA/Qwen) → Predictor (2-layer MLP) → Predicted embeddings; Momentum Encoder (EMA copy) → Target embeddings; MSE loss on masked positions + Cross-entropy on unmasked tokens

- **Critical path**:
  1. **Serialize**: Convert EHR to token sequence with section tags.
  2. **Mask**: Mask future tokens (50% ratio) for JEPA path.
  3. **Forward (Online)**: Pass masked sequence through Backbone + Predictor to get predicted embeddings.
  4. **Forward (Target)**: Pass *unmasked* sequence through Momentum Encoder to get target embeddings.
  5. **Loss**: MSE between predicted and target embeddings at masked positions (JEPA) + Cross-Entropy on unmasked tokens (SFT).

- **Design tradeoffs**:
  - **Curriculum vs. Hybrid**: Curriculum (SFT → JEPA) is safer and generally higher performance (0.731 AUC vs 0.719). Hybrid saves time but risks objective interference.
  - **Masking Ratio**: 0.5 is optimal. <0.25 leaks too much info; >0.75 destroys trajectory logic.
  - **Predictor Depth**: 2 layers is sufficient. Deeper predictors yield diminishing returns, suggesting the bottleneck is encoder quality, not predictor complexity.

- **Failure signatures**:
  - **Objective Interference**: If training loss fluctuates wildly or SFT performance drops when JEPA starts in a hybrid setup, gradients are conflicting. *Fix*: Switch to Curriculum mode.
  - **Latent Collapse**: If JEPA loss goes to zero but linear probes perform at random chance, the encoder may have collapsed. *Fix*: Increase momentum τ or check EMA update logic.
  - **Overfitting on SFT**: If SFT loss is near zero but JEPA loss is high, the model has memorized tokens but failed to learn dynamics. *Fix*: Increase data diversity or regularization.

- **First 3 experiments**:
  1. **Baseline Sanity Check**: Train SFT-only on a single cohort (MSK). Establish a linear probe baseline.
  2. **Ablation on Masking**: Run curriculum training with mask ratios [0.25, 0.50, 0.75]. Confirm 0.5 yields the best linear probe performance.
  3. **Horizon Validation**: Evaluate linear probes specifically on short-term (30-day) vs long-term (365-day) tasks. Verify that the JEPA model's advantage increases with the time horizon (capturing "momentum").

## Open Questions the Paper Calls Out

- **Can intervention-conditioned world models enable reliable counterfactual reasoning for treatment optimization?**
  - Basis: "Future iterations will extend this framework to intervention-conditioned world models to enable counterfactual reasoning and treatment optimization."
  - Why unresolved: Current model predicts natural disease trajectories but does not explicitly condition on interventions.
  - Evidence needed: Demonstration that intervention-conditioned SMB-Structure can accurately predict differential outcomes under hypothetical treatment alternatives.

- **How well do SMB-Structure embeddings transfer to populations and institutions beyond MSK and Stanford?**
  - Basis: "Our models were trained on data from two institutions (MSK and Stanford) with specific patient demographics; generalization to other populations requires careful validation."
  - Why unresolved: Model may encode institution-specific documentation patterns or treatment protocols.
  - Evidence needed: Evaluation on geographically and demographically distinct health systems showing comparable AUC-ROC across the same task taxonomy.

- **Does SMB-Structure capture dynamics that fine-tuned autoregressive models cannot recover, or does the linear probe constraint limit SFT baselines artificially?**
  - Basis: Evaluation protocol restricts all models to linear probing on frozen embeddings, but paper claims JEPA captures "dynamics not recoverable by autoregressive baselines."
  - Why unresolved: Unclear whether SFT baseline's inferior performance stems from fundamental representation limitations or evaluation constraint.
  - Evidence needed: Comparing SMB-Structure linear probes against fine-tuned autoregressive models (full fine-tuning, not just linear probing) on trajectory-level tasks.

## Limitations
- **Dataset Generalization**: Validated exclusively on oncology and PE cohorts; no validation on other chronic conditions or acute scenarios limits confidence in universal applicability.
- **Implementation Specificity**: Critical hyperparameters (epochs, token sequence rules, decision node sampling) are unspecified, creating significant barrier to faithful reproduction.
- **Linear Probe Dependency**: All performance claims rely on linear probes evaluated on frozen embeddings, which does not measure end-to-end task performance and may overstate practical utility.

## Confidence
- **Mechanism 1 (JEPA captures dynamics)**: Medium - Supported by ablation showing 0.5 mask ratio optimal and JEPA outperforming SFT on long-horizon tasks, but lacks direct visualization of learned trajectory embeddings.
- **Mechanism 2 (Curriculum needed)**: High - Clear empirical evidence showing Curriculum (0.731 AUC) > Hybrid (0.719) and both > SFT-only on cross-cohort tasks.
- **Mechanism 3 (Cross-domain regularization)**: Medium - Supported by performance gains when adding INSPECT cohort, but could reflect dataset size effects rather than genuine dynamical transfer.

## Next Checks
1. **Single-Disease Curriculum Validation**: Reproduce the Curriculum (SFT → JEPA) training on only the MSK oncology cohort. Confirm that adding JEPA improves long-horizon prediction accuracy compared to SFT-only baseline.

2. **Mask Ratio Sensitivity**: Systematically vary the masking ratio (0.25, 0.50, 0.75) during JEPA training. Verify that 0.50 indeed provides optimal balance between trajectory preservation and prediction challenge.

3. **Representation Visualization**: Project learned patient embeddings into 2D space using t-SNE or UMAP. Check whether embeddings of similar trajectories cluster together and whether temporal progression follows interpretable paths, validating the claimed dynamical modeling capability.