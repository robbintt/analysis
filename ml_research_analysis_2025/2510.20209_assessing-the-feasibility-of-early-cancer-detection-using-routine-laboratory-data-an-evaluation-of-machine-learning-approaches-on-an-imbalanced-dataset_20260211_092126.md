---
ver: rpa2
title: 'Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory
  Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset'
arxiv_id: '2510.20209'
source_url: https://arxiv.org/abs/2510.20209
tags:
- cancer
- data
- tumor
- were
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated whether routine canine laboratory data could
  reliably detect cancer early. Using the Golden Retriever Lifetime Study, 126 machine
  learning pipelines were benchmarked on a severely imbalanced dataset (6.3% cancer-positive
  visits).
---

# Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset

## Quick Facts
- arXiv ID: 2510.20209
- Source URL: https://arxiv.org/abs/2510.20209
- Authors: Shumin Li
- Reference count: 0
- Primary result: Routine lab data insufficient for reliable canine cancer detection (AUROC 0.815, F1-score 0.25)

## Executive Summary
This study evaluated whether routine canine laboratory data could reliably detect cancer early. Using the Golden Retriever Lifetime Study, 126 machine learning pipelines were benchmarked on a severely imbalanced dataset (6.3% cancer-positive visits). The best-performing Logistic Regression model achieved an AUROC of 0.815 but poor clinical performance (F1-score = 0.25, PPV = 0.15). While the model ranked patients by risk moderately well and showed high negative predictive value (0.98), its low precision and recall precluded reliable rule-out use. SHAP analysis revealed predictions were driven by non-specific markers like age and inflammation, rather than cancer-specific signals. The study concludes that routine lab data alone are insufficient for clinically reliable cancer detection in dogs, highlighting the need for multi-modal data integration in future AI-based screening tools.

## Method Summary
The study utilized data from the Golden Retriever Lifetime Study, comprising 5,635 visits from 2,644 dogs. The dataset included routine laboratory tests (complete blood count, serum biochemistry, urinalysis) and health status classifications (cancer-positive vs cancer-negative visits). Researchers developed 126 machine learning pipelines combining different preprocessing techniques, classification algorithms, and model architectures. Models were evaluated using stratified 10-fold cross-validation, with performance metrics including AUROC, F1-score, precision, recall, and negative predictive value. The analysis specifically addressed class imbalance through various sampling techniques and cost-sensitive learning approaches.

## Key Results
- Best model achieved AUROC of 0.815 but clinically inadequate F1-score of 0.25
- High negative predictive value (0.98) suggests potential for rule-out screening
- SHAP analysis revealed predictions driven by non-specific markers (age, inflammation) rather than cancer-specific signals
- Severe class imbalance (6.3% positive cases) significantly limited model performance

## Why This Works (Mechanism)
The study demonstrates that machine learning can extract patterns from routine laboratory data that correlate with cancer presence, achieving moderate discrimination (AUROC 0.815). However, the mechanism fails to identify cancer-specific biomarkers, instead relying on general health indicators like age and inflammation markers. This suggests that while statistical relationships exist between routine lab values and cancer status, the underlying biological mechanisms are not specific enough for reliable clinical detection. The severe class imbalance amplifies this limitation, as models struggle to learn from rare positive cases.

## Foundational Learning
- **Class imbalance handling**: Critical for rare disease detection; quick check: compare performance with/without sampling techniques
- **SHAP analysis**: Essential for interpreting black-box models; quick check: verify top features align with domain knowledge
- **Cross-validation**: Necessary for robust performance estimation; quick check: ensure folds maintain class distribution
- **Multi-modal data integration**: Required for improving detection specificity; quick check: assess incremental value of adding new data types

## Architecture Onboarding
- **Component map**: Data preprocessing -> Feature selection -> Model training -> SHAP interpretation -> Performance evaluation
- **Critical path**: Feature engineering and class imbalance handling are most critical for model performance
- **Design tradeoffs**: Simplicity (Logistic Regression) vs complexity (ensemble methods) - simpler models performed comparably
- **Failure signatures**: Low precision/recall despite moderate AUROC indicates model learns general health patterns rather than cancer-specific signals
- **3 first experiments**: 1) Test model on external dataset with different breeds, 2) Add imaging data to assess multimodal improvement, 3) Implement cost-sensitive learning to optimize for clinical utility

## Open Questions the Paper Calls Out
None

## Limitations
- Severe class imbalance (6.3% cancer-positive) inherently constrains model performance
- Single breed (Golden Retrievers) limits generalizability to mixed-breed populations
- Research-grade laboratory protocols may not reflect routine clinical testing conditions
- Retrospective design cannot establish causal relationships between lab abnormalities and cancer

## Confidence
- **High confidence**: Conclusion that routine lab data alone cannot reliably detect cancer in dogs, supported by objective performance metrics and SHAP analysis
- **Medium confidence**: Generalizability to mixed-breed populations and clinical practice, limited by single-breed sampling
- **Low confidence**: Absence of mechanistic understanding of why certain lab markers correlate with cancer risk

## Next Checks
1. External validation using mixed-breed veterinary clinic data with routine laboratory testing protocols
2. Prospective cohort study tracking healthy dogs with elevated risk scores to determine true cancer incidence
3. Integration study combining routine lab data with additional modalities (imaging, genetic markers) to assess incremental predictive value