---
ver: rpa2
title: 'Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative
  Study and An Optimized Framework'
arxiv_id: '2512.18999'
source_url: https://arxiv.org/abs/2512.18999
tags:
- follow-up
- dialogue
- questions
- forms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares end-to-end and modular LLM approaches for medical
  follow-up tasks, highlighting the limitations of direct LLM application in handling
  complex forms. End-to-end methods often fail in long-context, multi-turn interactions,
  leading to information loss and inaccurate extraction.
---

# Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework

## Quick Facts
- arXiv ID: 2512.18999
- Source URL: https://arxiv.org/abs/2512.18999
- Authors: Jinyan Liu; Zikang Chen; Qinchuan Wang; Tan Xie; Heming Zheng; Xudong Lv
- Reference count: 20
- Primary result: Modular framework reduces dialogue turns by 46.73% and token consumption by 80%-87.5% versus end-to-end LLMs

## Executive Summary
This study compares end-to-end and modular LLM approaches for medical follow-up tasks, highlighting the limitations of direct LLM application in handling complex forms. End-to-end methods often fail in long-context, multi-turn interactions, leading to information loss and inaccurate extraction. The proposed modular framework—built on task decomposition, semantic clustering, and structured flow control—improves dialog stability and accuracy. It reduces dialogue turns by 46.73% and lowers token consumption by 80%–87.5% compared to end-to-end methods. These results demonstrate the necessity of integrating external control mechanisms for deploying LLMs in high-stakes medical follow-up scenarios.

## Method Summary
The study evaluates end-to-end LLM chatbots against a proposed modular framework for medical follow-up tasks. Three forms of varying complexity (simple, medium, complex) are tested with three virtual patient personas (concise, verbose, vague) across multiple LLM models. The end-to-end baseline uses a single prompt for the entire dialogue. The experimental modular system decomposes the task into five modules: form structure parsing, semantic clustering, question generation, intent extraction (with RAG augmentation), and rule-driven flow control. Performance is measured by dialogue turn count, token consumption, and extraction accuracy.

## Key Results
- End-to-end systems frequently fail with long forms due to context overload and logic errors
- Modular framework reduces dialogue turns by 46.73% and token usage by 80%-87.5%
- Semantic clustering and structured flow control significantly improve extraction accuracy and stability
- RAG-augmented intent extraction reduces errors in parsing fill-in-the-blank and multiple-choice responses

## Why This Works (Mechanism)
The modular framework succeeds by breaking down the complex medical follow-up task into manageable, specialized components with clear control flow. Instead of overwhelming the LLM with the entire conversation history and form logic, each module handles a specific subtask: parsing form structure, intelligently grouping questions, generating natural language, extracting structured responses, and managing dialogue state. This decomposition reduces cognitive load on the LLM, prevents context truncation errors, and enables precise error handling through external orchestration rather than relying on the LLM's internal reasoning.

## Foundational Learning

- **Concept:** End-to-End vs. Modular Pipelines
  - **Why needed here:** This is the central comparison of the paper. An end-to-end system gives an LLM all instructions and lets it run autonomously, which fails at scale. A modular pipeline breaks the task into steps (generation, extraction, flow control) with external orchestration.
  - **Quick check question:** What are the two primary architectural approaches compared in this study for building a medical follow-up chatbot?

- **Concept:** Semantic Clustering
  - **Why needed here:** This is a key optimization technique. It involves using an LLM to group related questions together to ask them more naturally, which drastically reduces turns. It's not just about asking questions, but asking them intelligently.
  - **Quick check question:** What is the primary benefit of the semantic clustering module in the experimental chatbot system?

- **Concept:** Prompt Engineering & RAG for Intent Extraction
  - **Why needed here:** The paper details a specific method for extracting data from user responses. It combines carefully designed prompts with a RAG system that retrieves similar, pre-parsed examples to guide the LLM's extraction.
  - **Quick check question:** How does the experimental system enhance the LLM's ability to extract structured information (intent) from a patient's natural language response?

## Architecture Onboarding

- **Component map:** Form Structure Parser -> Preprocessing & Semantic Clustering -> Question Generation -> Patient Response -> Intent Extraction -> Flow Control & Question Selection -> (Loop back to Question Generation for next cluster) -> Final Report

- **Critical path:** Form Parsing -> Semantic Clustering -> Question Generation -> Patient Response -> Intent Extraction -> Flow Control -> (Loop back to Question Generation for next cluster) -> Final Report

- **Design tradeoffs:**
  - **Efficiency & Reliability vs. Flexibility:** The modular system gains immense efficiency and reliability (46.73% fewer turns, stable extraction) at the cost of the free-form conversational ability of an end-to-end model. The dialogue is constrained by the form's structure.
  - **Complexity vs. Controllability:** The modular design is more complex to implement (five modules, prompts, RAG system) but provides the controllability required for medical tasks. The end-to-end approach is simpler to prototype but fails in production.

- **Failure signatures:**
  - **End-to-End System:** Premature termination, repetitive questioning, logical jump errors, hallucinated options, and massive token consumption (one session used nearly 200 million tokens)
  - **Modular System:** Potential failure if the RAG-based intent extraction misinterprets a vague answer, or if the rigid flow control ignores a patient's critical unscheduled concern

- **First 3 experiments:**
  1. **Baseline Evaluation:** Run all three forms (simple, medium, complex) with the end-to-end prompt on multiple LLMs (e.g., GPT-4, Qwen-plus). Manually count the frequency of errors: premature stops, logic jump failures, and skipped questions.
  2. **Component Ablation:** Implement the modular system. First, test it without the semantic clustering module (ask questions sequentially). Measure the increase in dialogue turns to quantify the clustering's contribution.
  3. **Extraction Accuracy Test:** For a complex form (Form-3), compare the intent extraction accuracy of a simple prompt vs. the paper's RAG-augmented prompt. Focus specifically on fill-in-the-blank and multiple-choice questions to see if RAG examples reduce extraction errors.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can adaptive flow control mechanisms be developed to replace the current reliance on manual prompt engineering and static rules?
- **Basis in paper:** [explicit] The Discussion notes the method "still relies on rule and prompt design and lacks high-level generalizability," and suggests future research explore "adaptive flow control mechanisms."
- **Why unresolved:** The current modular framework requires manual setup for semantic clustering and flow management, limiting its ability to autonomously handle diverse or unseen form structures.
- **What evidence would resolve it:** A demonstration of a self-adaptive system that dynamically adjusts dialogue flow and question clustering for new medical forms without manual prompt reconfiguration.

### Open Question 2
- **Question:** Does integrating multimodal inputs (e.g., voice, images) compromise the token efficiency and accuracy of the modular framework?
- **Basis in paper:** [explicit] The Conclusion states the current method is "limited to text-based interaction" and explicitly calls for future research to "explore multimodal capabilities to accommodate the demands of more complex medical follow-up scenarios."
- **Why unresolved:** It is unclear if the efficiency gains (80%–87.5% token reduction) and intent extraction accuracy of the text-based pipeline transfer to non-textual inputs like voice or medical images.
- **What evidence would resolve it:** Performance benchmarks of the modular framework when augmented with vision or audio encoders on the same complex forms (Form-2 and Form-3).

### Open Question 3
- **Question:** Can patient-feature-driven personalization be integrated into the modular framework without destabilizing the rigid structured output required for medical forms?
- **Basis in paper:** [explicit] The Discussion suggests future research explore "patient-feature-driven personalization strategies" to bridge the gap between virtual simulations and real patients.
- **Why unresolved:** While personalization may improve engagement (as seen with different virtual patient profiles), it may introduce variability that conflicts with the strict logic and structured extraction required by the forms.
- **What evidence would resolve it:** A study measuring extraction accuracy and dialogue stability when the chatbot dynamically adapts its language style to specific real-world user demographics.

## Limitations

- Critical implementation details (exact prompts, RAG parameters, original forms) are not disclosed, preventing direct replication
- The study only tests one LLM (Qwen-plus) for the modular approach, leaving generalizability to other models uncertain
- "Stability" is based on qualitative error counts rather than a quantified metric across sessions
- The system does not address handling patient concerns outside the structured form, a common real-world scenario

## Confidence

- **High Confidence:** The general finding that end-to-end LLM approaches struggle with long, complex, branching medical forms is well-supported by the described failure modes (premature termination, repetitive questioning, logic errors). The concept of using a modular, control-flow-based architecture for such tasks is sound and well-established in software engineering.
- **Medium Confidence:** The specific performance numbers (turn reduction, token savings) are likely accurate for the tested setup, but their generalizability to other LLMs, forms, or patient types is uncertain without further testing.
- **Low Confidence:** The paper's assertion of the modular system's superior "stability" is based on observed error counts, which are inherently subjective and could be influenced by the specific patient personas used in testing.

## Next Checks

1. **Prompt Replication Check:** Implement the modular system using the described components (semantic clustering, RAG-based extraction, flow control) with your own medical form and patient simulator. Compare the dialogue turn count and token usage against a simple end-to-end prompt. This tests if the architectural approach itself provides the claimed efficiency gains, independent of the exact prompts used in the paper.

2. **LLM Generalization Check:** Run the modular system with a different, high-capability LLM (e.g., GPT-4 or Claude) and compare its performance (turns, tokens, accuracy) to the Qwen-plus results. This verifies if the framework's benefits are model-specific or more broadly applicable.

3. **Real-World Patient Check:** Modify the virtual patient simulator to introduce off-script questions or complaints not present in the form. Run sessions and log how the modular system handles these interruptions compared to the end-to-end approach. This tests the system's robustness to real-world conversational unpredictability, a key limitation not addressed in the original study.