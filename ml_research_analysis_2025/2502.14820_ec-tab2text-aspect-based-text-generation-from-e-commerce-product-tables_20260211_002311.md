---
ver: rpa2
title: 'eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables'
arxiv_id: '2502.14820'
source_url: https://arxiv.org/abs/2502.14820
tags:
- dataset
- product
- data
- computational
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces eC-Tab2Text, a novel dataset for aspect-based
  text generation from e-commerce product tables. The dataset addresses the lack of
  domain-specific resources for generating product reviews from structured tabular
  data in e-commerce.
---

# eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables

## Quick Facts
- arXiv ID: 2502.14820
- Source URL: https://arxiv.org/abs/2502.14820
- Reference count: 36
- Novel dataset for aspect-based text generation from e-commerce product tables with 3,354 queries

## Executive Summary
This paper introduces eC-Tab2Text, a specialized dataset for generating product reviews from structured e-commerce tables given specific aspects. The authors fine-tune three open-source LLMs (LLaMA 2-Chat, Mistral, and StructLM) on this dataset and demonstrate substantial improvements over zero-shot approaches. The work addresses the critical gap in domain-specific resources for Table2Text tasks in e-commerce, showing that tailored datasets significantly enhance the quality and accuracy of aspect-focused product review generation.

## Method Summary
The authors created eC-Tab2Text by scraping product specifications and reviews from Pricebaba for mobile phones, resulting in 1,452 product tables with 3,354 aspect-specific queries. They fine-tuned three 7B parameter LLMs using QLoRA with 4-bit quantization, training with AdamW optimizer on JSON-serialized product specifications. The models were evaluated using traditional NLG metrics (BLEU, ROUGE, METEOR, BERTScore) plus an LLM-based evaluator (PROMETHEUS 2) for correctness, faithfulness, and fluency assessments. The prompt template combines product specifications with requested aspects to generate focused product reviews.

## Key Results
- Fine-tuned models significantly outperform zero-shot baselines across all evaluation metrics
- JSON serialization preserves nested table structure better than alternatives, though with increased token overhead
- Domain-specific fine-tuning on eC-Tab2Text shows substantial improvements over models trained on general-purpose datasets like QTSumm
- Mistral-7B-Instruct-v0.3 achieved the best performance among the tested models

## Why This Works (Mechanism)
The method works because domain-specific training data directly addresses the unique challenges of e-commerce product generation, where accurate attribute representation and aspect-focused content are critical. By fine-tuning on product-specific specifications and reviews, the models learn to map structured table data to natural language while maintaining factual consistency. The JSON serialization preserves the hierarchical nature of product specifications, enabling the model to understand relationships between general attributes and nested characteristics. The aspect-based approach ensures generated content stays focused on user-specified topics rather than producing generic summaries.

## Foundational Learning
- **JSON serialization for structured data**: Converting nested product specifications to JSON preserves hierarchical relationships between attributes, which is essential for maintaining product feature relationships in generated text. Quick check: Verify that all nested attributes are properly represented in the JSON structure.
- **QLoRA quantization**: 4-bit quantization reduces memory requirements while maintaining model performance, enabling fine-tuning on consumer-grade hardware. Quick check: Monitor VRAM usage during training to ensure quantization is properly configured.
- **Aspect-based generation**: Focusing on specific user-requested aspects rather than general summaries ensures relevance and precision in e-commerce applications. Quick check: Compare aspect-focused outputs against generic summaries for relevance.

## Architecture Onboarding

- **Component Map**: Web Scraping & Cleaning -> JSON Serialization -> LLM Backbone -> Fine-Tuning Engine -> Evaluation Framework

- **Critical Path**: The JSON serialization and prompt construction is the critical path. If the mapping from raw product specifications to input JSON format is flawed, the model will be trained on noisy data, compromising its ability to generate accurate, aspect-specific text regardless of the model architecture.

- **Design Tradeoffs**:
  1. Dataset Size vs. Quality: Small but highly focused dataset vs. potential overfitting; domain specificity provides clear benefits over larger general datasets.
  2. Model Size vs. Accessibility: 7B parameter models with 4-bit quantization favor accessibility and reproducibility but may limit performance compared to larger models.
  3. JSON vs. Other Formats: JSON preserves nested structure better than markdown or CSV but increases token count, potentially truncating longer specifications.

- **Failure Signatures**:
  - Hallucination: Generating product features not present in the input table
  - Unfaithful Generation: Output contradicting input data (e.g., wrong battery capacity)
  - Off-Aspect Generation: Providing general summary instead of requested specific aspect
  - Malformed Output: Failing to generate valid JSON, breaking downstream parsing

- **First 3 Experiments**:
  1. Baseline Zero-Shot Evaluation: Run three open-source models and two closed-source models on eC-Tab2Text test set without training to establish performance floor.
  2. Domain-Specific Fine-Tuning: Fine-tune each open-source model on eC-Tab2Text training set and evaluate using text-based metrics and PROMETHEUS 2.
  3. Out-of-Domain Robustness Test: Evaluate models fine-tuned on QTSumm against eC-Tab2Text test set to demonstrate necessity of specialized e-commerce dataset.

## Open Questions the Paper Calls Out
- Can advanced numerical reasoning capabilities in LLMs be improved to better synthesize structured product data (e.g., battery capacity) into qualitative user experiences? Current models struggle to link attributes like battery capacity to battery life.
- Does evaluating text by extracting and verifying attribute-value pairs against source tables provide a more reliable assessment of correctness than standard metrics? Standard metrics often fail to capture factual consistency in structured data generation.
- To what extent do models fine-tuned on mobile phone specifications generalize to other e-commerce product categories? The dataset's restriction to mobile phones limits generalizability to other domains.

## Limitations
- Small dataset size (3,354 queries) may limit fine-tuning effectiveness for larger models
- JSON serialization introduces substantial token overhead that may truncate longer product specifications
- Heavy reliance on Prometheus 2 evaluator whose scoring consistency remains uncertain
- Focus on mobile phones from single source limits generalizability to other e-commerce domains

## Confidence
- **High Confidence**: Domain-specific fine-tuning substantially improves aspect-based text generation from product tables
- **Medium Confidence**: JSON serialization preserves nested table structure better than alternatives
- **Low Confidence**: Generalizability of findings to other e-commerce domains beyond mobile phones

## Next Checks
1. Cross-Domain Generalization Test: Evaluate fine-tuned models on product tables from different e-commerce categories to assess domain transfer capability.
2. Serialization Format Comparison: Implement alternative serialization approaches and conduct ablation studies to quantify JSON token overhead impact.
3. Comprehensive Hallucination Analysis: Develop automated verification system to check generated attribute-value pairs against source tables and systematically measure hallucination rates.