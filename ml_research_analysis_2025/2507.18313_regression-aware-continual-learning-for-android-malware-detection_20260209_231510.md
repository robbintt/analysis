---
ver: rpa2
title: Regression-aware Continual Learning for Android Malware Detection
arxiv_id: '2507.18313'
source_url: https://arxiv.org/abs/2507.18313
tags:
- malware
- regression
- learning
- forgetting
- security
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of security regression in continual
  learning (CL) for Android malware detection. While CL helps mitigate catastrophic
  forgetting, it can still introduce security regression - where previously correctly
  detected malware samples are misclassified after model updates.
---

# Regression-aware Continual Learning for Android Malware Detection

## Quick Facts
- arXiv ID: 2507.18313
- Source URL: https://arxiv.org/abs/2507.18313
- Reference count: 31
- Primary result: PCT reduces security regression NFR by ~50% while maintaining F1 ~85-87% in Android malware detection

## Executive Summary
This paper addresses security regression in continual learning for Android malware detection, where previously correctly detected malware samples become misclassified after model updates. The authors propose adapting Positive Congruent Training (PCT) - a regression-aware penalty that preserves prior predictive behavior - to the CL setting. PCT is model-agnostic and can be integrated with various CL strategies to reduce harmful prediction changes at the sample level.

The approach is evaluated on three Android malware datasets across different CL scenarios, showing that CL strategies without regression mitigation exhibit significant security regression (NFR up to 3.40% for malware). By integrating PCT, these rates are reduced by approximately 50%, achieving NFR values as low as 1.19% while maintaining strong detection performance. The combination of PCT with replay-based methods shows even better results, particularly in reducing malware NFR.

## Method Summary
The paper adapts Positive Congruent Training (PCT) to continual learning for Android malware detection. PCT adds a regression-aware penalty that jointly minimizes classification loss and a regularization term designed to penalize harmful prediction changes at the sample level. The method computes Negative Flip Rate (NFR) to quantify security regression, measuring instances where correct predictions become incorrect after model updates. PCT uses focal distillation with a scaling factor that upweights regularization for samples the old model got right. The approach is model-agnostic and can be integrated with various CL strategies, including experience replay.

## Key Results
- CL strategies without regression mitigation show significant security regression with malware NFR reaching 3.40% on ELSA and 2.92% on Tesseract
- PCT integration reduces NFR by approximately 50%, achieving values as low as 1.19% and 1.75% respectively
- Detection performance remains strong with F1 scores around 85-87% despite regression mitigation
- Combining PCT with replay-based methods shows even better results, particularly in reducing malware NFR

## Why This Works (Mechanism)

### Mechanism 1: Negative Flip Rate Quantification
- Claim: Security regression can be measured by tracking prediction flips from correct to incorrect across model updates.
- Mechanism: NFR counts instances where `f_new(x) ≠ y` AND `f_old(x) = y`, normalized by total samples. This provides a sample-level measure distinct from aggregate forgetting.
- Core assumption: Access to prior model predictions for comparison at update time.
- Evidence anchors:
  - [abstract]: "security regression captures harmful prediction changes at the sample level, such as a malware sample that was once correctly detected but evades detection after a model update"
  - [section III-A]: Eq. (2) and Eq. (3) formally define NFR for single updates and CL sequences
- Break condition: If prior model outputs are unavailable or stale, NFR cannot be computed.

### Mechanism 2: Focal Distillation for Prediction Preservation
- Claim: Penalizing logit divergence on previously correct samples reduces regression while allowing adaptation on others.
- Mechanism: PCT adds `L_PC = Σ[α + β·1(f_old(x)=y)] · ½‖f(x) - f_old(x)‖²` to the classification loss. The β term upweights distillation for samples the old model got right.
- Core assumption: Old model predictions on new data are meaningful anchors (i.e., labels are clean; feature semantics are stable).
- Evidence anchors:
  - [abstract]: "PCT is a regression-aware penalty that preserves prior predictive behavior by jointly minimizing the classification loss and a regularization term"
- Break condition: When old model predictions are unreliable (e.g., label noise, feature distribution shifts that invalidate old logits), distillation anchors may be misleading.

### Mechanism 3: Replay-PCT Synergy
- Claim: Combining PCT with a replay buffer yields lower NFR than either alone.
- Mechanism: Replay provides concrete anchor samples for distillation; PCT constrains prediction drift on those samples.
- Core assumption: Sufficient memory to store representative past samples; buffer is not adversarially poisoned.
- Evidence anchors:
  - [abstract]: "The combination of PCT with replay-based methods shows even better results, particularly in reducing malware NFR"
- Break condition: Very small buffers or non-representative sampling reduce benefit.

## Foundational Learning

- **Concept: Continual Learning Scenarios (DIL vs CIL)**
  - Why needed here: Determining whether your task involves distribution drift over fixed classes (DIL) or new class emergence (CIL) dictates evaluation protocol and buffer requirements.
  - Quick check question: Does your malware task maintain a binary goodware/malware label space over time (DIL), or must it learn new malware families incrementally (CIL)?

- **Concept: Catastrophic Forgetting vs Security Regression**
  - Why needed here: These are distinct—forgetting is aggregate performance drop; regression is sample-level flip from correct to incorrect, which can occur even when overall accuracy improves.
  - Quick check question: If model accuracy stays at 85% before and after an update, has regression occurred? (Answer: Possibly, if specific correct predictions flipped to incorrect while others improved to compensate.)

- **Concept: Knowledge Distillation Basics**
  - Why needed here: PCT uses logit-matching distillation to preserve old model behavior; understanding soft targets vs. hard labels is essential for correct implementation.
  - Quick check question: Why match logits rather than hard predictions? (Answer: Soft targets preserve uncertainty and inter-class relationships, providing richer supervision for consistency.)

## Architecture Onboarding

- **Component map:** Base classifier -> PCT regularizer -> Optional replay buffer -> NFR evaluation module

- **Critical path:**
  1. Train initial model `f_1` on first experience `D_1` using cross-entropy.
  2. For each new experience `D_k`:
     - Compute `f_{k-1}` predictions on `D_k` (and buffer samples if using replay).
     - Train `f_k` with combined loss: `L_CE + λL_PC`.
     - If using replay, sample from buffer and include in each batch.
  3. Evaluate NFR between `f_{k-1}` and `f_k` in backward mode on prior experiences.

- **Design tradeoffs:**
  - Higher α/β → lower NFR but potential recall drop
  - Larger buffer → lower NFR but higher memory and potential privacy concerns
  - Precision/recall shift: PCT integration improves precision while recall may decrease slightly; F1 remains comparable

- **Failure signatures:**
  - High NFR despite low forgetting → PCT not properly integrated (check λ scaling, distillation implementation)
  - Recall drops sharply after PCT → α or β set too high; reduce and re-sweep
  - CIL shows very high NFR/forgetting → replay buffer missing or too small

- **First 3 experiments:**
  1. **Baseline characterization:** Run naive fine-tuning (no CL) on ELSA or TESSERACT to establish upper bound on NFR without mitigation (expect ~3% malware NFR)
  2. **Hyperparameter sweep:** Grid search α, β ∈ [0, 1] with PCT-only (no buffer) to characterize F1 vs. NFR trade-off curve
  3. **Integration validation:** Compare SI+PCT vs. SI+Replay vs. SI+Replay+PCT on TESSERACT backward mode; verify NFR reduction from ~2.9% → ~1.8% → ~1.4%

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset and domain transferability not extensively validated across different security domains or malware feature representations
- PCT effectiveness depends on assumption that old model predictions are reliable anchors, not evaluated under label noise or concept drift
- Buffer size and privacy trade-offs not quantified; alternative memory-efficient strategies not explored

## Confidence
- **NFR Quantification Validity:** High
- **PCT Effectiveness in Reducing Regression:** High  
- **PCT+Replay Synergy:** Medium

## Next Checks
1. **Concept Drift Robustness Test:** Evaluate PCT performance when injected with synthetic label noise (10-30%) or gradual feature distribution shifts to quantify degradation in regression mitigation under unreliable prediction anchors.

2. **Alternative Architecture Validation:** Implement PCT with a CNN feature extractor and transformer-based classifier on the same datasets to verify the "model-agnostic" claim and assess whether architectural changes affect NFR reduction rates.

3. **Memory-Efficient Buffer Alternatives:** Compare PCT performance using coreset-based replay (e.g., k-center greedy selection) versus uniform random sampling with fixed buffer sizes to evaluate trade-offs between NFR reduction and memory efficiency.