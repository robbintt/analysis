---
ver: rpa2
title: A Rectification-Based Approach for Distilling Boosted Trees into Decision Trees
arxiv_id: '2510.18615'
source_url: https://arxiv.org/abs/2510.18615
tags:
- decision
- trees
- tree
- classification
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a rectification-based approach for distilling
  boosted trees into interpretable decision trees, addressing the need for explainable
  AI in high-stakes applications. The core idea is to incrementally correct an initial
  decision tree using a more accurate but less interpretable boosted tree as an oracle.
---

# A Rectification-Based Approach for Distilling Boosted Trees into Decision Trees

## Quick Facts
- arXiv ID: 2510.18615
- Source URL: https://arxiv.org/abs/2510.18615
- Reference count: 40
- Primary result: Presents a rectification-based approach for distilling boosted trees into interpretable decision trees with logical guarantees

## Executive Summary
This paper introduces a novel rectification-based approach for distilling boosted trees into interpretable decision trees, addressing the need for explainable AI in high-stakes applications. The core innovation lies in incrementally correcting an initial decision tree using a more accurate but less interpretable boosted tree as an oracle, ensuring logical convergence toward the boosted tree's behavior. By computing abductive explanations for misclassified instances and generating classification rules to rectify the decision tree, the method achieves better accuracy improvements and logical guarantees compared to retraining-based approaches while enabling faster computation of sufficient reasons for predictions.

## Method Summary
The approach trains an initial decision tree on training data, then incrementally rectifies it using a pre-trained boosted tree oracle. For each misclassified instance, the system computes an abductive explanation (sufficient reason) from the boosted tree, generates a classification rule, and structurally modifies the decision tree to absorb this rule. The rectification process guarantees monotonic reduction of disagreement between the student and teacher models. The rectified decision tree enables faster explanation queries compared to the original boosted tree, effectively compiling the complex logic into a tractable format.

## Key Results
- Rectification provides better accuracy improvements and logical guarantees compared to retraining-based approaches
- Distilled decision trees enable faster computation of sufficient reasons for predictions
- The rectification process ensures monotonic reduction of disagreement between student and teacher models

## Why This Works (Mechanism)

### Mechanism 1: Incremental Logic Rectification via Abductive Explanations
When an interpretable decision tree misclassifies an instance relative to a boosted tree oracle, the system computes an abductive explanation for the instance given the oracle. This explanation serves as the premise for a classification rule that rectifies the decision tree, ensuring logical convergence toward the oracle's behavior. The core assumption is that the abductive explanation generalizes sufficiently well to other instances in the feature space.

### Mechanism 2: Monotonic Reduction of Disagreement
Rectification offers a logical guarantee that the set of instances where the student model disagrees with the teacher strictly decreases with every correction step. Unlike retraining approaches which can suffer from "catastrophic forgetting," the rectification operation only updates classification logic for the region covered by the premise, leaving other classifications untouched.

### Mechanism 3: Knowledge Compilation for Tractable XAI
Distilling a complex boosted tree into a rectified decision tree acts as a "knowledge compilation" step, converting an intractable explanation problem on the boosted tree into a linear or polynomial-time problem on the decision tree. This shifts computational complexity to the compilation phase, enabling efficient subsequent explanation queries.

## Foundational Learning

- **Abductive Explanations (Sufficient Reasons):** Core unit of transfer; difference from feature importance scores is that abductive explanations provide minimal sets of features justifying predictions rather than weighted contributions.
- **Binary Classification Circuits:** Both boosted trees and decision trees are represented as logical circuits; understanding this representation is essential for the rectification operation.
- **Knowledge Compilation:** Provides the cost-benefit logic of the approach; the high "compilation" cost (distillation) is amortized over numerous subsequent explanation requests.

## Architecture Onboarding

- **Component map:** Oracle (P) -> Explainer -> Rectifier -> Student (I) -> Simplifier
- **Critical path:** Discrepancy Detection → Abduction → Rule Formation → Rectification → Simplification
- **Design tradeoffs:** Accuracy vs. Size (tree grows but becomes more accurate), Completeness vs. Tractability (full distillation is impossible; lazy approach balances effort with coverage)
- **Failure signatures:** Infinite Loop/No Convergence (retraining can oscillate), Timeout on Explanation (subset-minimal explanations hang on large trees)
- **First 3 experiments:** Scale Test (plot size vs. correction steps), Break-even Analysis (measure distillation vs. query times), Ablation on Initialization (compare single-node vs. pre-trained starting trees)

## Open Questions the Paper Calls Out

1. Can decision tree minimization algorithms be interleaved with rectification steps to prevent unmanageable tree growth without making the distillation process computationally impractical?

2. Does distilling boosted trees into structured d-DNNF circuits provide a better size-efficiency trade-off for explainability queries than distilling into decision trees?

3. How do different heuristics for selecting misclassified instances and abductive explanations impact the convergence rate and tree size during partial distillation?

## Limitations

- The approach may not scale to datasets with thousands of features due to exponential tree growth
- The effectiveness of tree-specific abductive explanations versus subset-minimal explanations for generalization remains an open question
- The computational overhead of the rectification process itself isn't thoroughly characterized relative to inference time savings

## Confidence

- Core rectification mechanism (Proposition 1-4): High confidence - logically sound with clear proofs
- Empirical accuracy improvements: Medium confidence - results show positive trends but sample sizes are limited
- Explanation efficiency gains: Medium confidence - computational complexity claims are supported but real-world latency measurements are absent
- Scalability of the approach: Low confidence - single dataset demonstrations don't establish generalizability

## Next Checks

1. **Tree Growth Analysis:** Reproduce rectification on a larger dataset and plot tree size versus correction steps to determine growth patterns and identify inflection points where tree bloat negates accuracy gains.

2. **Query Amortization Break-even:** Measure total time for distillation via rectification versus computing sufficient reasons on original boosted tree versus rectified tree to calculate query threshold where rectified tree becomes more efficient.

3. **Generalization of Tree-Specific Explanations:** Compare rectification using tree-specific explanations versus subset-minimal explanations (when feasible) to assess whether efficiency gains come at cost of suboptimal rectification rules.