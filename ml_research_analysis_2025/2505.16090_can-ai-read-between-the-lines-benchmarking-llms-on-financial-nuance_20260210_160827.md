---
ver: rpa2
title: Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance
arxiv_id: '2505.16090'
source_url: https://arxiv.org/abs/2505.16090
tags:
- sentiment
- llms
- financial
- microsoft
- copilot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks LLMs and traditional NLP tools on financial
  sentiment analysis, revealing that LLM-based systems (especially Copilot and ChatGPT-4o)
  outperform traditional tools in detecting nuanced financial sentiment, with accuracy
  up to 82%. However, performance varies significantly by deployment, and reliability
  issues remain, particularly with structured data handling and transparency in tool
  selection.
---

# Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance

## Quick Facts
- arXiv ID: 2505.16090
- Source URL: https://arxiv.org/abs/2505.16090
- Authors: Dominick Kubica; Dylan T. Gordon; Nanami Emura; Derleen Saini; Charlie Goldenberg
- Reference count: 2
- Primary result: LLM-based systems outperform traditional NLP tools in detecting nuanced financial sentiment, with accuracy up to 82%

## Executive Summary
This study benchmarks Large Language Models (LLMs) and traditional NLP tools on financial sentiment analysis, revealing that LLM-based systems significantly outperform traditional tools in detecting nuanced financial sentiment. The research demonstrates that models like Copilot and ChatGPT-4o achieve up to 82% accuracy, while traditional tools struggle with the subtle hedging and forward-looking language common in financial communications. However, performance varies significantly by deployment configuration, and reliability issues remain, particularly with structured data handling and transparency in tool selection.

## Method Summary
The study compares 9 models—Copilot (Desktop, 365, Online), ChatGPT-4o, Gemini 2.0 Flash, Azure Language AI, FinBERT, NLTK, and TextBlob—on the Financial Phrase Bank dataset. LLMs used "Think Deeper" where available, while traditional NLP required preprocessing. Business-line segmentation was performed via Copilot, with sentiment scoring via ChatGPT-4o for scalability. Real-world analysis examined Microsoft earnings calls, correlating segment-level sentiment with stock price movements. SHAP beeswarm plots were used to interpret feature contributions to stock predictions.

## Key Results
- LLM-based systems (especially Copilot and ChatGPT-4o) achieve up to 82% accuracy in financial sentiment classification
- Traditional tools like TextBlob show significant limitations, often defaulting to neutral sentiment and missing implied cues
- Segment-level sentiment analysis (by business line) correlates better with stock price movements than overall transcript sentiment
- Copilot 365 defaults to TextBlob in some configurations without clear user notification

## Why This Works (Mechanism)

### Mechanism 1: Context Retention via Uncleaned Inputs
LLMs outperform traditional NLP libraries when input text retains contextual structure rather than aggressive cleaning. Traditional tools rely on keyword frequency that requires stripping "noise," while LLMs transform text into numerical vectors where hedging and filler words provide positional context for interpreting financial nuance. This mechanism degrades if input text exceeds the LLM's context window, requiring truncation that fragments semantic dependencies.

### Mechanism 2: Segment-Level Sentiment Granularity
Aggregate sentiment scores correlate poorly with stock movement, whereas sentiment isolated by specific business lines provides higher-fidelity signals. Aggregating sentiment dilutes critical negative signals within high-performing segments. This correlation breaks down if segmentation logic misclassifies which text belongs to which business line.

### Mechanism 3: Deployment Configuration as Hidden Variable
The reported accuracy of an "LLM system" depends heavily on deployment interface, which may silently route requests to simpler models or traditional libraries without user notification. Enterprise integrations may default to deterministic Python libraries for stability, reducing accuracy on complex tasks while maintaining the appearance of a unified AI system. This routing failure mode is avoided when using API endpoints with explicit model selection.

## Foundational Learning

- **Concept:** Vector Space Semantics (Cosine Similarity)
  - Why needed: To understand why LLMs handle nuance differently than keyword counters
  - Quick check: If "revenue declined" and "revenue growth slowed" map to similar vectors, how might an LLM struggle to distinguish severity?

- **Concept:** SHAP (SHapley Additive exPlanations)
  - Why needed: To interpret Figure 4's SHAP beeswarm explaining stock predictions
  - Quick check: In the paper's SHAP plot, why do red dots (high positive sentiment) for "Search" segment appear on the negative side of the X-axis?

- **Concept:** Financial Hedging & Forward-Looking Statements
  - Why needed: Financial language is defined by "layered strategy" and "hedging"
  - Quick check: Why would a traditional sentiment analyzer flag "We expect strong growth" as neutral or negative due to the word "expect"?

## Architecture Onboarding

- **Component map:** Raw CSV/Text of Earnings Transcripts -> Segmentation prompt -> LLM/Local Libraries -> Sentiment Aggregation & SHAP visualization
- **Critical path:** Input Formatting is the primary bottleneck; CSVs caused hallucinations requiring conversion to plain text before LLM processing
- **Design tradeoffs:**
  - Copilot App: 82% accuracy but manual input, lacks API
  - Copilot 365: Convenient but defaults to TextBlob (poor nuance detection)
  - ChatGPT-4o via API: 77% accuracy, programmatic access, consistent output, but higher cost
- **Failure signatures:**
  - "Neutral Drift": Outputs cluster around Neutral, indicating TextBlob backend
  - "Format Hallucination": Model invents categories or misreads rows due to CSV structure
- **First 3 experiments:**
  1. Tool-Check A/B Test: Run same 50 sentences through Copilot 365 vs App to verify TextBlob backend
  2. Granularity Threshold: Compare Overall vs Segmented sentiment analysis and correlate with stock moves
  3. CSV vs Text Robustness: Measure error rate in sentiment counting when feeding structured CSV vs flattened text

## Open Questions the Paper Calls Out

- Why does positive sentiment in specific business segments, such as "Search and News Advertising," exhibit an inverse correlation with stock price movements?
- To what extent can human financial domain experts outperform the ~82–85% accuracy ceiling observed in current LLMs?
- How can deployment architectures ensure transparency when systems silently default to simpler NLP tools rather than using full LLM capabilities?

## Limitations
- Exact prompt templates for LLM sentiment analysis are not disclosed, creating reproducibility variability
- Segmentation methodology relies on LLM-based classification that may introduce systematic bias
- Correlation between segment-level sentiment and stock movements lacks statistical significance testing
- Claims about deployment configuration routing are based on limited empirical evidence

## Confidence
- **High Confidence:** LLMs outperform traditional NLP tools on financial sentiment analysis
- **Medium Confidence:** Mechanism explaining LLM advantage through context retention
- **Low Confidence:** Deployment configuration routing claims based on inference rather than documented architecture

## Next Checks
1. Prompt Sensitivity Analysis: Systematically vary prompt structure to quantify performance variation
2. Controlled Segmentation Study: Manually segment transcripts and compare against LLM-segmented versions
3. Deployment Architecture Verification: Test different Copilot configurations to confirm routing to traditional NLP libraries