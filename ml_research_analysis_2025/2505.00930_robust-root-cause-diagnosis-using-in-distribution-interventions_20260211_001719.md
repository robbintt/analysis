---
ver: rpa2
title: Robust Root Cause Diagnosis using In-Distribution Interventions
arxiv_id: '2505.00930'
source_url: https://arxiv.org/abs/2505.00930
tags:
- root
- cause
- nodes
- causal
- anomaly
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IDI is a root cause diagnosis method that identifies causal nodes
  satisfying both an anomaly and a fix condition. Unlike prior approaches that use
  counterfactuals requiring out-of-distribution SCM inference, IDI uses in-distribution
  interventions, making it more robust to anomalies.
---

# Robust Root Cause Diagnosis using In-Distribution Interventions

## Quick Facts
- **arXiv ID:** 2505.00930
- **Source URL:** https://arxiv.org/abs/2505.00930
- **Authors:** Lokesh Nagalapatti; Ashutosh Srivastava; Sunita Sarawagi; Amit Sharma
- **Reference count:** 40
- **Primary result:** IDI outperforms nine baselines in recall@k on PetShop and synthetic datasets by using in-distribution interventions instead of OOD counterfactuals

## Executive Summary
Root Cause Diagnosis (RCD) in cloud microservices identifies which node causes an anomaly at a target node. Traditional methods use counterfactuals requiring out-of-distribution (OOD) SCM inference, which is unreliable under anomalies. IDI instead uses in-distribution interventions: sampling exogenous noise from the empirical training distribution and propagating fixes forward. Theoretical analysis shows IDI’s error is bounded by exogenous noise variance, while counterfactual errors scale with training-anomaly distribution mismatch. On PetShop and synthetic datasets, IDI achieves recall@k up to 1.00 vs. 0.97 for baselines, especially in high-variance and non-linear non-invertible SCMs.

## Method Summary
IDI identifies root causes by first filtering candidate nodes using an anomaly condition (node is anomalous, parents are normal), then evaluating fix impact via in-distribution interventions instead of counterfactuals. It trains structural equations (linear or MLP) and anomaly detectors on normal data, samples exogenous noise from validation residuals, and uses Shapley values to rank candidates. This avoids OOD inference required by counterfactuals, making it more robust to anomalies. The method assumes at most one root cause per simple path and uses Z-score thresholds for anomaly detection.

## Key Results
- IDI achieves recall@1 up to 1.00 vs. 0.97 for best baseline on PetShop benchmark
- Outperforms counterfactual-based methods especially in high-variance and non-linear non-invertible SCMs
- Theoretical bounds show IDI error plateaus at exogenous noise variance while counterfactual error grows with distribution shift

## Why This Works (Mechanism)

### Mechanism 1: In-Distribution Intervention for Fix Assessment
Probing a fitted SCM with in-distribution inputs during fix assessment yields more stable root cause diagnosis than counterfactuals requiring OOD inference. Instead of inverting structural equations to estimate exogenous noise from anomalous inputs, IDI samples exogenous variables from their empirical training distribution and propagates a "fix" value forward through the SCM. This avoids evaluating learned functions on OOD inputs where generalization is unreliable. Core assumption: structural equations trained on normal data can accurately model downstream propagation when inputs stay within the training distribution; exogenous noise has bounded variance. Evidence: Theorem 6 (bound with std(ε) instead of tvd(P, Q) terms) and Fig. 1 illustrating OOD vs. in-distribution inference. Break condition: When exogenous noise variance is very high, the std(ε) term dominates and interventional error may exceed counterfactual error.

### Mechanism 2: Anomaly Condition to Filter Candidates
Restricting root cause search to nodes that are anomalous while their parents are not reduces spurious candidates and ensures downstream fix evaluation remains in-distribution for true root causes. For each ancestor of the target, IDI checks if the node is anomalous and all its parents are normal (e.g., via Z-score thresholds). This isolates likely sources of exogenous perturbation and limits the Shapley analysis to a small candidate set Rcand. Core assumption: the causal graph is known or derivable (e.g., from inverted call graphs); anomaly detectors trained on normal data can separate normal vs. abnormal behavior for each KPI. Evidence: Fig. 2 (pipeline) and Sec. 5 Step 1 for Rcand definition and Z-score usage. Break condition: If multiple root causes share a simple path, downstream nodes may have anomalous parents, violating the anomaly condition's "parents normal" requirement.

### Mechanism 3: Shapley Attribution for Multiple Root Causes
Using Shapley values over subsets of Rcand provides fair credit allocation when multiple root causes exist without violating the per-path-single-cause constraint. IDI evaluates the utility of subsets of Rcand by the reduction in anomaly score at the target after applying fixes. Subsets containing the true root cause(s) yield high utility, and Shapley aggregation ranks individual nodes by their marginal contributions. Core assumption: At most one root cause per simple path; the utility function (anomaly reduction) is well-defined and sensitive to true fixes. Evidence: Sec. 5 (Multiple root causes) and Alg. 1 in Appendix B. Break condition: When Assumption 1 is violated (multiple root causes on the same path), Shapley attribution may misallocate credit or overlook nodes whose parents are anomalously affected.

## Foundational Learning

**Concept: Structural Causal Model (SCM)**
Why needed: IDI's intervention and fix propagation rely on structural equations; understanding additive noise and graph topology is required to implement and debug the SCM.
Quick check: Can you write an additive noise structural equation for a node Xj given its parents PaXj and exogenous εj?

**Concept: Intervention vs. Counterfactual**
Why needed: The paper's core contribution is comparing these two; engineers must distinguish sampling exogenous variables vs. inverting/abducting them.
Quick check: Given a fitted SCM, how would you compute an intervention on Xj and a counterfactual for the same fix value?

**Concept: Total Variation Distance and Distribution Shift**
Why needed: Theoretical bounds contrast tvd(P, Q) terms (large under anomaly shift) with std(ε) terms; understanding this clarifies when interventions are safer.
Quick check: If training data is mostly normal and anomalies are rare, would tvd(P_train, Q_anomaly) be small or large?

## Architecture Onboarding

**Component map:**
Training module -> Fits structural equations per node on Dtrn with graph G; trains per-node anomaly detectors
Inference pipeline -> (1) Identify target anomaly; (2) Filter ancestors into Rcand via anomaly condition; (3) For each subset of Rcand, apply fix and propagate interventionally through the SCM; (4) Compute utility (anomaly score reduction); (5) Rank by Shapley values

**Critical path:**
Step 1: Anomaly detection at target node (φn(xn) = 1)
Step 2: Ancestral traversal to build Rcand (anomalous node, normal parents)
Step 3: Sample fix values from P(Xj|PaXj) for each candidate
Step 4: Forward-propagate intervention through SCM using sampled ε
Step 5: Aggregate utilities and compute Shapley ranking

**Design tradeoffs:**
Linear vs. non-linear SCMs: Linear models are simpler and closed-form; non-linear MLPs capture more complex relationships but may overfit and increase OOD error risk
Shapley approximations: Exact computation is expensive; Monte Carlo approximations trade off accuracy vs. speed
Anomaly threshold choice: Higher thresholds reduce false positives but may miss subtle root causes

**Failure signatures:**
High exogenous noise variance leading to large std(ε) and degraded intervention accuracy
Violations of Assumption 1 (multiple root causes on same path) causing Rcand to exclude true causes
Poorly fitted SCM (high validation error) undermining both intervention and counterfactual estimates

**First 3 experiments:**
1. Toy linear vs. non-linear SCM under varying ε variance: Replicate Fig. 5 to observe when interventional error plateaus vs. counterfactual error grows with tvd(P, Q)
2. PetShop latency scenarios: Run IDI vs. baselines on Low/High/Temporal latency cases to confirm recall improvements and analyze Rcand size vs. Shapley cost
3. Synthetic non-invertible SCM: Test IDI vs. CF Attribution on non-invertible MLPs to validate robustness when abduction is ill-posed

## Open Questions the Paper Calls Out

**Open Question 1:** How can the methodology be adapted to robustly handle scenarios where multiple root causes exist on the same simple path (violating Assumption 1)? Basis: Page 10 states IDI's performance can degrade when Assumption 1 is violated. Why unresolved: The current algorithm assumes set-valued fixes for disjoint paths; overlapping root causes on a single path lead to out-of-distribution evaluations during the fix step. What evidence would resolve it: An algorithm capable of decoupling downstream propagation errors on a shared path or a revised theoretical bound that accounts for dependency conflicts.

**Open Question 2:** Can the theoretical error bounds comparing interventional and counterfactual estimates be rigorously extended from chain graphs to general Directed Acyclic Graphs (DAGs)? Basis: The theoretical analysis explicitly assumes a chain graph, whereas the experiments apply the method to complex cloud topologies and arbitrary synthetic graphs. Why unresolved: The proofs utilize a sequential error propagation structure that may not directly translate to graphs with branching structures, multiple parents, or shared descendants. What evidence would resolve it: A formal derivation of the error bounds for general DAGs or a proof that the chain graph bounds represent the worst-case scenario for arbitrary topologies.

**Open Question 3:** Can a mechanism be developed to dynamically select between interventional and counterfactual estimation based on estimated noise variance and training data scale? Basis: Page 10 notes that for additive noise models with large training data, counterfactual errors converge to zero, while IDI errors plateau at the standard deviation of exogenous variables. Why unresolved: IDI is robust in low-data/high-variance regimes, but the theory suggests counterfactuals are superior in "ideal" high-data conditions; the paper does not propose a method to switch strategies based on these conditions. What evidence would resolve it: A hybrid algorithm that quantifies the trade-off between the OOD generalization error and the noise floor to choose the optimal estimator.

## Limitations

- **Assumption 1 violations:** Performance degrades when multiple root causes exist on the same simple path, potentially excluding true causes
- **High exogenous noise:** In very high variance regimes, IDI's interventional error may exceed counterfactual error as std(ε) dominates
- **Hyperparameter sensitivity:** Method's robustness to Z-score thresholds and Shapley sample size is not fully characterized

## Confidence

**High Confidence:** The core mechanism of using in-distribution interventions instead of OOD counterfactuals for fix assessment is sound and theoretically justified. The empirical improvement in recall on the PetShop benchmark is compelling.

**Medium Confidence:** The superiority of IDI over counterfactuals is demonstrated, but the theoretical bounds and toy experiments suggest this advantage diminishes in very high exogenous noise scenarios. The exact conditions for this breakdown are not fully explored.

**Medium Confidence:** The Shapley attribution for multiple root causes is a reasonable approach, but its effectiveness depends on the validity of Assumption 1. The ablation study on this assumption is promising but limited.

## Next Checks

1. **Robustness to High Exogenous Noise:** Conduct a systematic study varying the exogenous noise variance in synthetic SCMs to precisely quantify when the std(ε) term dominates and interventional error surpasses counterfactual error.

2. **Assumption 1 Violations in Real Data:** Identify or construct a real-world causal graph with multiple root causes on the same path (e.g., from a different cloud benchmark or a known complex system). Evaluate IDI's performance and compare it to a method that does not rely on Assumption 1.

3. **Hyperparameter Ablation:** Perform a comprehensive ablation study on the Z-score threshold for the anomaly condition and the number of samples for the Shapley approximation. Quantify the impact of these choices on recall and computational cost.