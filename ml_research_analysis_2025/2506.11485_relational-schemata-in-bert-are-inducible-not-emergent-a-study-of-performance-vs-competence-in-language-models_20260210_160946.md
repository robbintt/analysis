---
ver: rpa2
title: 'Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance
  vs. Competence in Language Models'
arxiv_id: '2506.11485'
source_url: https://arxiv.org/abs/2506.11485
tags:
- relational
- bert
- relation
- classification
- structure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether BERT encodes abstract relational
  schemata or merely surface-level statistical associations. By comparing classification
  performance with representational structure in CLS embeddings across taxonomic,
  mereological, and functional relations, the research reveals that while pretrained
  BERT enables high classification accuracy (79%), concept pairs do not organize by
  relation type in embedding space.
---

# Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models

## Quick Facts
- arXiv ID: 2506.11485
- Source URL: https://arxiv.org/abs/2506.11485
- Authors: Cole Gawin
- Reference count: 10
- High classification accuracy (79%) does not imply structured relational representations; fine-tuning induces geometric clustering by relation type (ρ = 0.77, 90% accuracy).

## Executive Summary
This study investigates whether BERT encodes abstract relational schemata or merely surface-level statistical associations. By comparing classification performance with representational structure in CLS embeddings across taxonomic, mereological, and functional relations, the research reveals that while pretrained BERT enables high classification accuracy (79%), concept pairs do not organize by relation type in embedding space. Only after fine-tuning does RSA show strong alignment (Spearman's ρ = 0.77) and clear clustering emerge, with accuracy rising to 90%. This dissociation indicates relational schemata are not emergent from pretraining but can be induced through supervised task scaffolding.

## Method Summary
The study uses bert-base-uncased to classify concept pairs into taxonomic, mereological, or functional relations. A balanced subset of 3,600 pairs from ConceptNet (400 samples per label, 1,200 per category) is formatted as "CONCEPT1 [SEP] CONCEPT2". For pretrained evaluation, a logistic regression probe is trained on frozen CLS embeddings. For fine-tuning, the model is supervised with cross-entropy loss and HuggingFace Trainer. Representational similarity analysis (RSA) computes Spearman correlation between model RDMs and ground-truth RDMs across 13 layers. UMAP visualizes embedding clustering.

## Key Results
- Pretrained BERT achieves 79% classification accuracy but shows near-zero RSA alignment (ρ ≈ 0.04), indicating no geometric clustering by relation type.
- Fine-tuned BERT reaches 90% accuracy and strong RSA alignment (ρ ≈ 0.77), with UMAP revealing clear relational clustering.
- Layer-wise RSA analysis shows correlation increases dramatically from layer 5, exceeding ρ = 0.7 by layer 8 and stabilizing above ρ = 0.75 through layers 9-12.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High classification accuracy does not imply structured relational representations
- Mechanism: A probe classifier can decode latent relational signals from embeddings even when those embeddings lack geometric organization by relation type. The classifier exploits distributed associative cues rather than abstract schema-level structure.
- Core assumption: RSA alignment with ground-truth relational categories is a valid proxy for "competence" (structured understanding) versus mere "performance" (decodable signals).
- Evidence anchors:
  - [abstract]: "pretrained BERT enables high classification accuracy (79%)...concept pairs do not organize by relation type in embedding space"
  - [section 5.1-5.2]: Pretrained κ = 0.68 (substantial agreement) but ρ ≈ 0.04 (near-zero RSA alignment)
  - [corpus]: Weak direct support—neighbor papers focus on BERT fine-tuning efficiency and classification performance, not representational structure assessment.
- Break condition: If a linear probe trained on frozen pretrained embeddings cannot achieve above-chance accuracy, the latent signals are not even decodable, and the mechanism fails to initiate.

### Mechanism 2
- Claim: Supervised fine-tuning induces relational schema by reorganizing embedding geometry
- Mechanism: Task-specific gradient updates reshape the [CLS] embedding space so that concept pairs sharing relation type become geometrically proximate. RSA alignment increases as the model internalizes categorical boundaries rather than relying on surface co-occurrence.
- Core assumption: Fine-tuning on a balanced relation classification task provides sufficient signal to override pretraining-derived associative patterns.
- Evidence anchors:
  - [abstract]: "Only after fine-tuning does RSA show strong alignment (Spearman's ρ = 0.77) and clear clustering emerge"
  - [section 5.3]: UMAP shows "no discernible clustering" pretrained but "significant degree of relational clustering" post-fine-tuning
  - [corpus]: Merchant et al. (2020) cited in paper finds BERT semantic relation representations improve substantially with fine-tuning; no direct corpus neighbor replication.
- Break condition: If fine-tuning dataset is severely imbalanced or labels are randomized (control condition), no genuine relational structure emerges—accuracy stays near chance, RSA remains low.

### Mechanism 3
- Claim: Relational structure emerges primarily in middle-to-deep layers during fine-tuning
- Mechanism: Early layers retain morphological/syntactic features; layers 5-8 begin categorical differentiation; layers 9-12 achieve stable schema-level abstraction. Fine-tuning propagates task signal upward, reconfiguring deeper layers most strongly.
- Core assumption: The layer-wise RSA trajectory reflects genuine hierarchical abstraction rather than artifact of gradient flow proximity to the classification head.
- Evidence anchors:
  - [section 5.2, Figure 1]: "Correlation begins to dramatically increase in layer 5; by layer 8, the correlation exceeds ρ = 0.7...through layers 9–12, the Spearman correlation exceeds ρ = 0.75"
  - [section 2.3]: Liu et al. (2019) found deeper layers encode task-specific abstractions
  - [corpus]: Gandikota et al. (2024) cited for layer-wise RSA methodology; corpus neighbors do not directly address this layer-emergence pattern.
- Break condition: If classification head is attached to an early layer (e.g., layer 4) instead of final layer, relational structure may not fully materialize—gradient signal insufficient to reshape deeper representations.

## Foundational Learning

- Concept: Representational Similarity Analysis (RSA)
  - Why needed here: RSA quantifies whether embeddings geometrically reflect relational categories, distinguishing structured competence from decodable-but-unstructured performance.
  - Quick check question: If two concept pairs share the same relation type, should their embeddings be more similar to each other than to pairs from different relation types?

- Concept: Performance vs. Competence (Chomsky)
  - Why needed here: This distinction frames the core hypothesis—behavioral success (accuracy) may not reflect internal structured knowledge (embedding geometry).
  - Quick check question: Can a model correctly classify "wheel-car" as part-whole without understanding the abstract concept of part-whole relations?

- Concept: [CLS] Token as Representation Summary
  - Why needed here: The study uses [CLS] embeddings as the primary representational unit for RSA and classification, assuming it aggregates input-pair semantics.
  - Quick check question: Why might the [CLS] token be preferred over averaged token embeddings for sentence-pair classification tasks?

## Architecture Onboarding

- Component map:
  - Input: "CONCEPT1 [SEP] CONCEPT2" tokenized sequence
  - BERT backbone: 12 transformer layers + embedding layer (13 total)
  - [CLS] token: Aggregated representation extracted from final hidden state
  - Classification head: Linear layer mapping [CLS] to 3 relation classes (taxonomic, mereological, functional)
  - Probe classifier: Logistic regression on frozen [CLS] for pretrained evaluation

- Critical path:
  1. Tokenize concept pair with [CLS] prefix and [SEP] delimiter
  2. Forward pass through BERT (pretrained or fine-tuned)
  3. Extract [CLS] embedding from final layer
  4. Classify via fine-tuned head OR external probe
  5. Compute RSA: build RDM from [CLS] embeddings, correlate with ground-truth RDM

- Design tradeoffs:
  - Pretrained-only: Fast deployment, leverages latent signals, but no guaranteed relational structure (ρ ≈ 0.04)
  - Fine-tuned: Strong structure (ρ ≈ 0.77) and accuracy (90%), but requires labeled data and risks overfitting to specific relation taxonomy
  - Layer selection: Earlier layers preserve generality; deeper layers encode task-specific abstraction but may lose transferability

- Failure signatures:
  - High accuracy with low RSA: Model relies on surface cues (e.g., co-occurrence patterns), not structured understanding
  - Chance-level accuracy with randomized-label control: Confirms genuine relational signal; if accuracy remains high, dataset artifacts are present
  - RSA stuck near zero post-fine-tuning: Insufficient supervision signal, imbalanced data, or architectural constraint preventing schema induction

- First 3 experiments:
  1. Replicate classification accuracy comparison: Train logistic regression on frozen pretrained [CLS] embeddings vs. fine-tuned model's classification head on held-out test set
  2. Layer-wise RSA profiling: Compute Spearman correlation between model RDM and ground-truth RDM for each of the 13 layers post-fine-tuning to identify where structure emerges
  3. Control condition validation: Randomize relation labels across concept pairs, train probe on pretrained embeddings, verify accuracy drops to chance (~33% for 3 classes) and RSA remains near zero

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the inducibility of relational schemata generalize to decoder-based architectures (e.g., LLaMa, Gemma) or vary significantly with model scale?
- Basis in paper: [explicit] The conclusion explicitly calls for research into whether these patterns extend to recent architectures like LLaMa and Gemma and whether scale influences emergence.
- Why unresolved: This study restricted its analysis exclusively to the BERT architecture.
- What evidence would resolve it: Replicating the RSA and fine-tuning protocol on various sizes of LLaMa and Gemma models to observe if structure emerges without supervision.

### Open Question 2
- Question: Are temporal and causal relations subject to the same performance-competence dissociation observed in taxonomic, mereological, and functional relations?
- Basis in paper: [explicit] The conclusion suggests extending the range of tested relations to include temporal or causal relations to provide deeper insight.
- Why unresolved: The current ontology was limited to three high-level relation types.
- What evidence would resolve it: Applying the same representational similarity analysis (RSA) methodology to datasets specifically annotated with temporal and causal relation pairs.

### Open Question 3
- Question: Can training paradigms grounded in cognitive development theory, such as curriculum learning or relational priming, induce relational structure more efficiently?
- Basis in paper: [explicit] The conclusion proposes bridging insights from cognitive development, specifically curriculum learning, to align model learning with human-like abstraction.
- Why unresolved: The current study utilized standard supervised fine-tuning rather than developmental training strategies.
- What evidence would resolve it: Training models using progressive curricula and measuring if RSA alignment appears earlier in training or with less data.

## Limitations

- The core dissociation between classification accuracy and RSA alignment hinges on a single dataset (ConceptNet-derived subset) without external validation on other knowledge bases.
- Layer-wise RSA patterns (emergence in layers 5-8, stability in 9-12) are presented descriptively without statistical significance testing.
- The study assumes [CLS] embeddings adequately capture pair-level semantics, but alternative pooling strategies (mean token, attention-weighted) could yield different RSA trajectories.

## Confidence

- **High confidence**: Performance-competence dissociation (79% accuracy vs. near-zero RSA pretrained) is directly measurable and reproducible with the described methodology.
- **Medium confidence**: RSA increase to ρ = 0.77 post-fine-tuning indicates structural change, but layer-specific emergence claims need statistical validation.
- **Low confidence**: Generalizability of relational schema induction mechanism across datasets, languages, or relation taxonomies is untested.

## Next Checks

1. External validation: Apply the same pretrained/fine-tuned RSA pipeline to a different knowledge base (e.g., WordNet relations) to test whether the dissociation replicates beyond ConceptNet.
2. Layer significance testing: Compute bootstrap confidence intervals for RSA correlations at each layer; determine if the observed jump in layers 5-8 exceeds statistical noise.
3. Control ablation: Replace [CLS] pooling with mean token embeddings; compare RSA trajectories to verify that observed patterns are not artifacts of pooling strategy.