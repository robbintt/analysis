---
ver: rpa2
title: 'Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and
  Optimal Sensor Placement'
arxiv_id: '2512.00396'
source_url: https://arxiv.org/abs/2512.00396
tags:
- gait
- data
- baseline
- sensor
- loso
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates gait detection in Parkinson\u2019s disease\
  \ using 1D CNNs on triaxial accelerometer data from wearable sensors. It compares\
  \ three lightweight CNN architectures\u2014one baseline and two ultra-compact models\
  \ with separable convolutions and residual connections\u2014against a simple magnitude\
  \ threshold baseline."
---

# Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement

## Quick Facts
- **arXiv ID**: 2512.00396
- **Source URL**: https://arxiv.org/abs/2512.00396
- **Reference count**: 7
- **Primary result**: Ultra-light CNNs with depthwise separable convolutions achieve 91.2% F1 on gait detection using 10× fewer parameters than baseline.

## Executive Summary
This paper demonstrates that extremely compact 1D CNNs with depthwise separable convolutions can match or exceed the accuracy of larger models for wearable gait detection in Parkinson's patients. Using 2-second windows from chest-worn accelerometers, the proposed residual separable CNN (533 parameters) achieves PR-AUC=94.5%, F1=91.2%, and MCC=89.4%, comparable to a baseline model with 5,552 parameters. The study validates sensor placement importance, showing chest and thigh locations provide 15-30% higher precision than forearm due to lower non-gait motion contamination. All models run within tight memory and latency budgets on STM32-class MCUs, enabling on-sensor detection that could reduce wireless data transmission by 70%.

## Method Summary
The method employs LOSO validation on 16 Parkinson's patients using BioStampRC21 triaxial accelerometer data resampled to 30 Hz. Three CNN architectures are compared: a standard baseline (5,552 parameters), a non-residual separable model (305 parameters), and a residual separable model (533 parameters). All models use 60-sample (2-second) windows with 75% overlap. Training uses AdamW optimization with class-balanced loss and early stopping on PR-AUC. A magnitude threshold baseline is also evaluated. Sensor placement analysis compares chest, thigh, and forearm positions. Models are profiled for MCU deployment using simulation tools.

## Key Results
- Residual separable CNN (533 params) achieves PR-AUC=94.5%, F1=91.2%, MCC=89.4%, matching baseline (5,552 params) performance
- Smallest model (305 params) achieves similar accuracy with 10× fewer parameters
- Chest and thigh placements yield 15-30% higher precision than forearm due to non-gait motion contamination
- All CNN models run within STM32 memory and latency constraints (sub-10 ms per window)
- Threshold baseline achieves high recall but low precision and high inter-subject variance

## Why This Works (Mechanism)

### Mechanism 1
Depthwise separable 1D convolutions achieve comparable gait detection accuracy to standard convolutions with ~10× fewer parameters on triaxial accelerometer time-series. By decomposing convolution into depthwise (per-axis temporal filtering) followed by pointwise (1×1 cross-channel mixing), the model reduces parameters from O(C_out × C_in × K) to O(C_in × K + C_in × C_out). For 3-axis accelerometer data, this preserves the ability to learn axis-specific gait patterns before fusing them, while dramatically shrinking the model. Core assumption: Temporal patterns within each accelerometer axis are meaningful independently, and cross-axis correlations can be captured efficiently by pointwise convolutions rather than full 3D kernels.

### Mechanism 2
Residual connections with projected skips improve optimization stability and slightly boost performance in ultra-shallow (2-block) CNNs, even with <600 parameters. The 1×1 projection skip (3→8 and 8→16 channels) provides an identity shortcut that aids gradient flow during backpropagation, allowing each block to learn refinements rather than complete transformations. This is particularly valuable under LOSO validation where training data varies significantly across folds. Core assumption: The optimal feature representation is close to identity at each block, with small learned perturbations improving discrimination.

### Mechanism 3
Chest and thigh sensor placements yield 15-30% higher precision than forearm placements because proximal body locations exhibit lower non-gait motion contamination. During gait, the chest and thighs move with the characteristic periodic acceleration of the gait cycle. Forearms experience frequent non-gait arm motions (gesturing, reaching) that produce acceleration patterns with similar periodicity, causing false positives. The threshold method's forearm precision collapses to 42-43% vs 79% on chest. Core assumption: Gait produces a consistent, classifiable acceleration signature at trunk/proximal limb locations that is distinguishable from non-gait activities at those same locations.

## Foundational Learning

- **1D Convolutions for Time-Series**
  - Why needed here: The architectures operate on 60×3 accelerometer windows where 1D kernels slide across time (not spatial axes) to detect gait-period patterns.
  - Quick check question: Given a 60-sample window at 30 Hz, what temporal duration does a kernel size of 9 cover?

- **Depthwise Separable Convolutions**
  - Why needed here: Understanding why Model 1/2 achieve similar accuracy to baseline with 10× fewer parameters requires grasping the depthwise→pointwise factorization.
  - Quick check question: For 8 input channels, 16 output channels, and kernel size 7, how many parameters does a standard convolution vs depthwise separable convolution require?

- **Leave-One-Subject-Out (LOSO) Validation**
  - Why needed here: The paper's generalization claims rest on LOSO, where each fold tests on a completely unseen patient—a stricter test than random splits.
  - Quick check question: Why might LOSO yield lower but more clinically meaningful performance than a random 80/20 split?

## Architecture Onboarding

- **Component map:**
  Input (60, 3) → SepConv1 (8 filters, k=5/9) → BN → ReLU → Pool(2)
                → SepConv2 (16 filters, k=7/9) → BN → ReLU
                → GlobalAvgPool → Dense(2) → Softmax
  Model 2 adds: 1×1 projection skips + residual add before final ReLU at each block.

- **Critical path:** Input windowing → per-axis standardization → SepConv feature extraction → global aggregation → classification. The threshold baseline bypasses all learned features and operates directly on magnitude.

- **Design tradeoffs:**
  - Filter count (8/16 vs 100/40): Lower count reduces parameters 10× but may limit expressivity; empirical LOSO tests show no accuracy loss.
  - Kernel size (5/7/9 vs 10): Larger kernels increase receptive field but add parameters; k=9 with residual connections (Model 2) slightly outperforms k=5/7 (Model 1).
  - Residual vs non-residual: Adds ~228 parameters for ~0.2% F1 gain; worthwhile for edge deployment where inference cost difference is negligible.

- **Failure signatures:**
  - High F1 variance across LOSO folds (σ > 5%) → model overfits to training subject gait patterns; consider data augmentation or regularization.
  - High recall/low precision (threshold pattern) → detector flags too many windows; adjust decision threshold or add negative class mining.
  - Forearm F1 < 80% with chest F1 > 85% → sensor placement issue, not model architecture; relocate sensor or train placement-specific model.
  - Inference latency > 10 ms on target MCU → model too large; reduce filter counts or switch to Model 1.

- **First 3 experiments:**
  1. **LOSO replication on chest data**: Train Model 1 and Model 2 on 15 subjects, test on held-out subject; verify F1=91.0±5% and confirm per-subject variance matches Tables 5-6.
  2. **Sensor placement ablation**: Train on all sensors (train-on-all), evaluate per-position; confirm forearm F1 drops 10–15 points vs chest/thigh as in Table 10.
  3. **MCU deployment profiling**: Export Model 1 and Model 2 to STM32CubeAI or ST Edge AI; measure RAM, flash, and per-window latency on L4/F4/H7 targets to validate Table 9 claims.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed lightweight CNNs be extended to classify specific gait anomalies (e.g., freezing, fluctuations, dyskinesias) on microcontrollers without exceeding memory constraints? The Conclusion states future work could explore integrating these models into a full pipeline to detect specific anomalies like fluctuations and dyskinesias. This remains unresolved because the current study validates binary classification (gait vs. non-gait) only; detecting specific anomalies requires identifying finer-grained features within the gait class, which may demand larger models or different architectures. What evidence would resolve it: A study applying the residual separable CNN (Model 2) to an anomaly-labeled dataset, reporting F1-scores for multi-class detection and confirming the model still fits within the STM32 memory budget.

### Open Question 2
Can learned or attention-based sensor fusion strategies outperform the single best sensor site (chest), given that naive fusion failed? The Abstract and Results note that "naive fusion of all sites does not outperform the best single site," leaving the potential for optimized fusion unexplored. The paper evaluated simple aggregation but did not test architectures capable of suppressing noisy inputs (e.g., from forearms) or dynamically weighting informative sensors (e.g., thighs vs. chest). What evidence would resolve it: A comparative LOSO evaluation using a multi-branch architecture with an attention layer that learns to weight sensor inputs, demonstrating statistically significant F1-score improvements over the chest-only baseline.

### Open Question 3
What is the actual energy consumption and battery life impact of continuous on-sensor inference compared to theoretical latency estimates? The paper relies on simulation tools (ST Edge AI) for latency and memory metrics but does not provide physical power measurements (mAh) or battery life analysis. While MACs and latency correlate with energy, real-world battery life depends on sleep modes, data transmission costs (which the paper aims to reduce), and analog sensor sampling overhead not profiled in the text. What evidence would resolve it: Physical deployment on a wearable device measuring total system power drain during continuous monitoring, comparing the CNN's energy cost against the radio energy savings achieved by filtering non-gait data.

## Limitations

- LOSO validation provides conservative generalization estimates but may not capture all failure modes like sensor drift or inter-session variability
- Absence of baseline model with standard convolutions (same parameter count) makes it difficult to isolate separable convolution benefits
- Sensor placement degradation for forearm is well-documented but paper doesn't explore hybrid sensor fusion or adaptive thresholding that might recover performance

## Confidence

- **High confidence**: CNN models outperform threshold baseline on chest data; parameter efficiency claims (533 vs 5,552 params); MCU deployment feasibility
- **Medium confidence**: LOSO F1 scores (91.2%) generalize to new patients; separable convolutions are the primary driver of efficiency; chest/thigh placements are robustly superior
- **Low confidence**: Residual connections meaningfully improve performance; model robustness to sensor misplacement without retraining; clinical impact of sub-10 ms inference on battery life

## Next Checks

1. **Parameter efficiency ablation**: Train a baseline CNN with identical parameter count to Model 2 but using standard convolutions; compare F1 to isolate separable convolution benefits
2. **Cross-session generalization**: Collect data from the same 16 subjects on different days; evaluate whether LOSO-trained models maintain 90%+ F1 without retraining
3. **Sensor fusion feasibility**: Train a late-fusion model combining chest and forearm data; measure if precision on forearm can be recovered without sacrificing chest performance