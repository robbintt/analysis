---
ver: rpa2
title: Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection
arxiv_id: '2506.00488'
source_url: https://arxiv.org/abs/2506.00488
tags:
- label
- news
- fake
- detection
- propagation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multimodal fake news detection framework
  called GLPN-LLM, which synergizes Large Language Models (LLMs) with global label
  propagation. The framework addresses the challenge of poor performance when directly
  using LLM-generated pseudo labels for fake news detection.
---

# Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection

## Quick Facts
- arXiv ID: 2506.00488
- Source URL: https://arxiv.org/abs/2506.00488
- Reference count: 31
- Primary result: Proposes GLPN-LLM, a multimodal fake news detection framework using LLM-generated pseudo labels with global label propagation, achieving superior performance over state-of-the-art baselines.

## Executive Summary
This paper introduces GLPN-LLM, a multimodal fake news detection framework that synergizes Large Language Models (LLMs) with global label propagation. The framework addresses the challenge of poor performance when directly using LLM-generated pseudo labels by introducing a mask-based global label propagation mechanism. This prevents label leakage during training while allowing effective integration of LLM capabilities through label propagation techniques. Experimental results on three benchmark datasets demonstrate that GLPN-LLM achieves superior performance compared to state-of-the-art baselines.

## Method Summary
GLPN-LLM extracts multimodal features using CLIP encoders, constructs a cross-modal graph based on five similarity metrics, and integrates LLM-generated pseudo labels filtered by confidence scores. During training, a global random mask mechanism prevents label leakage by randomly masking label embeddings. The framework uses a GCN to propagate information across the graph and make final predictions. The method leverages both ground truth labels for training samples and high-confidence pseudo labels for test samples, with a 5% threshold for pseudo label inclusion and a 0.5 mask rate during training.

## Key Results
- GLPN-LLM achieves 88.83% accuracy and 89.03% F1 score on the Twitter dataset, outperforming previous methods.
- The framework shows consistent improvements across all three benchmark datasets (Twitter, PHEME, and Weibo).
- Ablation studies confirm the effectiveness of both the global random mask mechanism and the confidence-based pseudo label filtering.

## Why This Works (Mechanism)

### Mechanism 1: Confidence-Filtered Pseudo Label Injection
- Claim: High-confidence LLM-generated pseudo labels improve detection when filtered and propagated, not when used directly.
- Mechanism: LLM produces detection label and confidence score; only top 5% highest-confidence labels are converted to one-hot vectors and integrated into node features for graph propagation.
- Core assumption: LLM confidence scores correlate meaningfully with label correctness; propagation can smooth remaining errors.
- Evidence anchors:
  - [abstract] "The global label propagation can utilize LLM-generated pseudo labels, enhancing prediction accuracy by propagating label information among all samples."
  - [Section 4.6.2] "Incorporating pseudo labels up to the top 5% of confidence scores yields the highest performance improvements. Increasing the percentage beyond 5%... may even degrade performance due to the inclusion of lower-confidence labels."
  - [corpus] Weak direct evidence. Related work (MVAN, KGAlign) focuses on content/propagation features, not LLM pseudo-labeling strategies.
- Break condition: If LLM confidence scores become miscalibrated or if test set distribution shifts significantly from training, pseudo labels may inject systematic noise.

### Mechanism 2: Global Random Mask Preventing Label Leakage
- Claim: Masking label embeddings during training prevents trivial label copying while allowing information flow through graph structure.
- Mechanism: Each training iteration randomly masks label embeddings (sets to zero) for a subset of nodes (mask ratio ρ=0.5 optimal); loss computed only on masked nodes ensures model learns from propagated signals, not self-labels.
- Core assumption: Graph connectivity encodes meaningful similarity such that neighbors' labels provide signal for masked nodes.
- Evidence anchors:
  - [abstract] "A mask-based mechanism is designed to prevent label leakage during training by ensuring that training nodes do not propagate their own labels back to themselves."
  - [Section 3.5] "This masking prevents label leakage during training by ensuring that training nodes do not propagate their own labels back to themselves."
  - [Section 4.6.1] "A mask rate of 0.5 yields the best performance... suggesting that balancing the availability and masking of label information is crucial."
  - [corpus] No direct corpus evidence for this specific masking mechanism in fake news detection.
- Break condition: If graph edges are poorly constructed (low-quality similarity), masked nodes receive irrelevant or misleading neighbor signals.

### Mechanism 3: Cross-Modal Graph Construction Enabling Multi-Signal Propagation
- Claim: Propagation across a graph built from multiple similarity metrics captures complementary signals for fake news classification.
- Mechanism: Graph edges created when any of five similarity types (concatenated features, image-to-text, text-to-image, image-to-image, text-to-text) exceeds threshold θ=0.95; this allows labels to propagate across modalities and feature spaces.
- Core assumption: Related news items (by any modality) are more likely to share truth labels; threshold sufficiently filters spurious connections.
- Evidence anchors:
  - [Section 3.4] "An edge is created between two nodes i and j if any of the aforementioned similarity scores exceed a predefined threshold (θ=0.95)."
  - [Table 2 ablation] GLPN outperforms FCN-LP baseline, suggesting the mask-based propagation over cross-modal graph provides measurable gains.
  - [corpus] Weak. FCN-LP (Zhao et al., 2023) uses similar graph construction; this paper extends it with LLM pseudo labels and masking.
- Break condition: If threshold is too low (dense graph with noise) or too high (disconnected components), propagation quality degrades.

## Foundational Learning

- Concept: **Label Propagation (LP) on Graphs**
  - Why needed here: Core mechanism for spreading labels; assumes connected nodes share labels.
  - Quick check question: Can you explain why LP can work even with moderate pseudo-label accuracy (cite: Sun et al., 2025 in paper)?

- Concept: **Graph Convolutional Networks (GCNs)**
  - Why needed here: The propagation backbone; operates on the cross-modal graph after feature/label integration.
  - Quick check question: How does a GCN differ from standard LP in terms of learnable parameters?

- Concept: **CLIP Multimodal Embeddings**
  - Why needed here: Provides aligned text-image feature space for similarity computation and graph construction.
  - Quick check question: Why is embedding alignment across modalities important for fake news detection?

## Architecture Onboarding

- Component map:
  CLIP Encoders -> Feature Concatenation -> Cross-Modal Graph -> LLM Pseudo Labels -> Label Integration -> Global Random Mask -> GCN -> Predictions

- Critical path: CLIP features → graph construction → LLM pseudo labels (test only) → label integration → GRM masking (train only) → GCN → predictions

- Design tradeoffs:
  - Higher mask ratio → more robust training but slower convergence
  - More pseudo labels → more signal but more noise; 5% threshold empirically optimal
  - Similarity threshold θ=0.95 → sparse but high-quality graph

- Failure signatures:
  - Accuracy collapses if mask ratio too high (>0.8) or too low (<0.2)
  - Performance plateaus if pseudo label threshold too permissive (>20%)
  - Graph becomes disconnected if similarity threshold too strict

- First 3 experiments:
  1. **Ablation on mask ratio**: Test ρ ∈ {0.1, 0.3, 0.5, 0.7, 0.9} on validation set; expect U-shaped curve with optimum near 0.5.
  2. **Pseudo label threshold sweep**: Test top-k% ∈ {1, 5, 10, 25, 50, 90}; expect performance peak at 5% with degradation beyond.
  3. **Graph connectivity check**: Compute average degree and number of connected components at θ=0.95; if graph is highly disconnected, consider lowering threshold to 0.90.

## Open Questions the Paper Calls Out

- **Question:** How does the computational complexity and detection performance of GLPN-LLM scale when applied to industrial-sized graphs containing millions of nodes, compared to the small-scale benchmarks (max 17k samples) used in this study?
  - Basis in paper: [explicit] The Conclusion states future work will focus on "exploring approaches to improve GLPN-LLM’s scalability to larger and more complex datasets."
  - Why unresolved: The current experiments are limited to relatively small benchmark datasets (Twitter, PHEME, Weibo), and the label propagation mechanism involves graph construction and matrix operations that may not scale linearly.
  - What evidence would resolve it: Performance benchmarks (runtime, memory usage, and F1 score) on large-scale datasets (e.g., >100k nodes) and analysis of computational bottlenecks in the global random masking step.

- **Question:** Can the GLPN-LLM framework be effectively adapted to detect fake news in non-image modalities, such as short-form video or audio content, which are increasingly prevalent on modern social media platforms?
  - Basis in paper: [explicit] The Conclusion identifies a goal of "examining its adaptability across diverse social media platforms and content modalities."
  - Why unresolved: The current method relies on CLIP for joint text-image embedding; the efficacy of the global label propagation mechanism with video/audio encoders (which may have different alignment properties) remains untested.
  - What evidence would resolve it: Experiments replacing CLIP with video-audio encoders on multimodal datasets (e.g., FakeTT or similar) and analysis of whether the cross-modal graph construction remains robust with higher-dimensional or temporal features.

- **Question:** How robust is the confidence-based filtering mechanism against systematic political or cultural bias in LLM-generated pseudo labels, as opposed to random errors?
  - Basis in paper: [inferred] The Limitations section notes the risk that "biased pseudo labels can introduce noise," and the current method filters only by confidence scores (top 5%), not by bias types.
  - Why unresolved: High-confidence LLM outputs can still be systematically biased (e.g., always favoring one political stance), which could propagate errors through the graph structure if not explicitly detected.
  - What evidence would resolve it: Evaluation on datasets with known political leanings where LLM bias is measured, followed by performance comparisons between standard confidence-filtering and bias-aware filtering techniques.

- **Question:** Is the Global Label Propagation mechanism equally effective when coupled with more advanced Graph Neural Network backbones (e.g., GAT, GraphSAGE) compared to the standard GCN used in the current implementation?
  - Basis in paper: [inferred] The Limitations section highlights the "Dependency on Backbone Models" and suggests that limitations in the backbone can impact the label propagation process.
  - Why unresolved: The paper utilizes a standard GCN for the propagation step; it is unclear if the improvements are specific to GCN's smoothing properties or if they generalize to attention-based or sampling-based GNNs.
  - What evidence would resolve it: Ablation studies substituting the GCN layer in Equation 2 with alternative GNN architectures while keeping the GLPN-LLM framework constant, reporting changes in Accuracy and F1.

## Limitations

- The effectiveness of the 5% confidence threshold for pseudo labels is empirically derived but not theoretically justified; results may not generalize if LLM confidence calibration changes.
- The global random mask mechanism introduces randomness that may affect reproducibility across different hardware or seed settings.
- Cross-modal graph construction relies heavily on CLIP embeddings; performance may degrade if CLIP's alignment quality drops or if datasets contain non-standard image-text pairs.

## Confidence

- **High**: The framework architecture (CLIP features + GCN + label integration) is clearly specified and reproducible.
- **Medium**: The claim that GLPN-LLM outperforms baselines is supported by Table 2, but exact implementation details (e.g., GCN layers, dropout rate) are unspecified.
- **Low**: The optimal hyperparameter values (e.g., mask ratio 0.5, pseudo label threshold 5%) are empirically chosen but lack theoretical grounding for generalization.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary mask ratio (ρ ∈ {0.1, 0.3, 0.5, 0.7, 0.9}) and pseudo label threshold (top-k% ∈ {1, 5, 10, 25}) on validation sets to confirm reported optimal values.
2. **Graph Connectivity Diagnostics**: Measure average node degree and number of connected components at θ=0.95; if disconnected, test lower thresholds (e.g., θ=0.90) and report impact on performance.
3. **Label Leakage Verification**: During training, monitor training vs validation accuracy; if training accuracy is near-perfect but validation lags, re-check mask application to ensure labels are properly randomized.