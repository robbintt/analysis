---
ver: rpa2
title: 'CharDiff-LP: A Diffusion Model with Character-Level Guidance for License Plate
  Image Restoration'
arxiv_id: '2510.17330'
source_url: https://arxiv.org/abs/2510.17330
tags:
- license
- plate
- character
- chardiff-lp
- restoration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents CharDiff-LP, a diffusion-based framework for
  license plate image restoration that incorporates character-level guidance to improve
  both restoration quality and recognition accuracy. The method extracts fine-grained
  character priors using external segmentation and OCR modules specialized for low-quality
  images, and employs a novel CHARM module that applies spatially masked cross-attention
  to ensure each character embedding guides only its corresponding region.
---

# CharDiff-LP: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration

## Quick Facts
- arXiv ID: 2510.17330
- Source URL: https://arxiv.org/abs/2510.17330
- Authors: Kihyun Na; Gyuhwan Park; Injung Kim
- Reference count: 40
- Key outcome: CharDiff-LP achieves 28.3% relative CER reduction on Roboflow-LP and improves recognition accuracy under severe degradation

## Executive Summary
CharDiff-LP is a diffusion-based framework for license plate image restoration that incorporates character-level guidance to improve both restoration quality and recognition accuracy. The method extracts fine-grained character priors using external segmentation and OCR modules specialized for low-quality images, and employs a novel CHARM module that applies spatially masked cross-attention to ensure each character embedding guides only its corresponding region. This approach prevents interference between neighboring characters during restoration. Experimental results on Roboflow-LP and Dashcam-LP datasets demonstrate that CharDiff-LP outperforms baseline models, achieving a 28.3% relative reduction in character error rate (CER) compared to the best baseline on Roboflow-LP, and showing strong generalization to real-world degraded images. The framework improves both perceptual quality and text recognition performance, particularly under severe degradation conditions.

## Method Summary
CharDiff-LP introduces a diffusion model with character-level guidance for license plate restoration. The method uses external OCR and segmentation modules to extract character embeddings and bounding box coordinates from degraded input images. These character embeddings are fed into a novel CHARM module that applies spatially masked cross-attention, ensuring each character embedding influences only its corresponding region in the image. This prevents interference between neighboring characters during restoration. The framework operates in a latent space using VQGAN, and employs a U-Net backbone with self-attention layers replaced by CHARM modules. The training uses a combination of reconstruction loss and perceptual loss to optimize both image quality and recognition accuracy.

## Key Results
- 28.3% relative CER reduction on Roboflow-LP compared to best baseline
- Strong performance on Dashcam-LP dataset with real-world degraded images
- Improved perceptual quality and recognition accuracy under severe degradation conditions

## Why This Works (Mechanism)
CharDiff-LP works by incorporating character-level priors into the diffusion process through spatially constrained attention mechanisms. The CHARM module uses a binary mask derived from character bounding boxes to restrict cross-attention to relevant image regions, preventing character embeddings from interfering with neighboring characters. This localized guidance ensures that each character is restored with its correct identity and position, leading to improved recognition accuracy. The use of external OCR and segmentation modules provides robust character embeddings even for severely degraded images, which serve as strong priors for the restoration process.

## Foundational Learning
- **Diffusion Models**: Why needed - to progressively denoise and restore degraded license plate images. Quick check - verify the model can generate realistic license plate images from pure noise.
- **Cross-Attention Mechanisms**: Why needed - to incorporate character embeddings into the restoration process. Quick check - ensure the attention weights are properly constrained by the binary mask.
- **Character-Level Priors**: Why needed - to provide strong guidance for accurate character restoration. Quick check - validate that character embeddings improve recognition accuracy over models without such guidance.
- **VQGAN**: Why needed - to operate in a compressed latent space for efficiency. Quick check - confirm the VQGAN codebook can represent license plate image details adequately.
- **Perceptual Loss**: Why needed - to optimize for both image quality and recognition accuracy. Quick check - verify that perceptual loss improves character recognition metrics.

## Architecture Onboarding

### Component Map
Input Image -> OCR/Segmentation Modules -> Character Embeddings & Bounding Boxes -> CHARM Module -> U-Net Backbone -> Restored Image

### Critical Path
Degraded image → OCR extraction → Character embeddings → CHARM module → U-Net processing → Restored image → Recognition evaluation

### Design Tradeoffs
- External OCR modules add dependency but provide robust character priors
- Spatial masking in CHARM prevents interference but may limit global context
- Latent space operation improves efficiency but may lose fine details

### Failure Signatures
- Character recognition errors due to inaccurate OCR embeddings
- Blurry characters when character priors are weak or ambiguous
- Incorrect character positioning from segmentation errors

### First Experiments
1. Baseline diffusion model without character guidance
2. Model with character embeddings but without spatial masking
3. Model with character embeddings and spatial masking (CHARM module)

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends heavily on accuracy of external OCR and segmentation modules
- Evaluation limited to synthetic degradation patterns on two controlled datasets
- May not generalize well to diverse real-world scenarios with occlusions and reflections

## Confidence
- **High** for architectural design and implementation quality
- **Medium** for quantitative performance improvements on benchmark datasets
- **Low** for real-world deployment robustness without further validation

## Next Checks
1. Test CharDiff-LP on multi-weather and multi-illumination datasets with natural rather than synthetic degradations
2. Conduct ablation studies isolating the impact of CHARM module versus character embeddings on final recognition accuracy
3. Integrate with end-to-end ALPR pipelines to measure system-level performance gains versus isolated image restoration metrics