---
ver: rpa2
title: Extracting Structured Requirements from Unstructured Building Technical Specifications
  for Building Information Modeling
arxiv_id: '2508.13833'
source_url: https://arxiv.org/abs/2508.13833
tags:
- extraction
- entities
- learning
- page
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study integrates Building Information Modeling (BIM) with
  Natural Language Processing (NLP) to automate the extraction of structured requirements
  from unstructured French Building Technical Specification (BTS) documents. The approach
  employs Named Entity Recognition (NER) and Relation Extraction (RE) techniques using
  transformer-based models like CamemBERT and transfer learning with the French language
  model Frcorenewslg, both pre-trained on a large French corpus.
---

# Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling

## Quick Facts
- arXiv ID: 2508.13833
- Source URL: https://arxiv.org/abs/2508.13833
- Reference count: 40
- Authors: Insaf Nahri; Romain Pinquié; Philippe Véron; Nicolas Bus; Mathieu Thorel
- Primary result: CamemBERT and Fr_core_news_lg achieved F1-scores over 90% for NER, while Random Forest achieved F1 scores above 80% for RE

## Executive Summary
This study addresses the challenge of extracting structured requirements from unstructured French Building Technical Specifications (BTS) for Building Information Modeling (BIM). The authors develop a pipeline that combines document segmentation, Named Entity Recognition (NER), and Relation Extraction (RE) using transformer-based models. The approach leverages transfer learning from French language models to overcome data scarcity in the construction domain. The resulting structured requirements are intended to be represented as a knowledge graph for future BIM verification systems.

## Method Summary
The methodology employs a multi-stage pipeline beginning with PDF parsing and cleaning to extract raw text. A rule-based algorithm segments documents based on hierarchical numbering patterns to create "Raw Requirements" containing parent (common) and child (specific) requirements. For NER, two approaches are compared: a rule-based system and transfer learning using CamemBERT and Fr_core_news_lg, both fine-tuned on a hand-crafted annotated dataset. RE is performed using a Random Forest classifier with syntactic features like word count and entity orientation. The pipeline outputs structured JSON representations of extracted entities and their relationships.

## Key Results
- CamemBERT and Fr_core_news_lg achieved F1-scores over 90% for Named Entity Recognition
- Random Forest classifier achieved F1 scores above 80% for Relation Extraction
- Hierarchical document segmentation based on numbering systems was critical for complete requirement extraction
- Adding semantic features to the RE model degraded performance, while syntactic features proved most effective

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical document segmentation based on numbering systems appears to be a necessary precondition for extracting complete formal requirements. By detecting numbering patterns (e.g., 1.1, 1.2), the system merges "Common Raw Requirements" (parent nodes) with "Specific Raw Requirements" (child nodes). This ensures that scattered entities (Concepts and Properties) are co-located in a single text chunk before relation extraction occurs. The core assumption is that the document structure follows a consistent, machine-readable numbering logic; if the formatting is purely visual or inconsistent, this mechanism fails.

### Mechanism 2
Transfer learning from French-specific transformer models (CamemBERT) to a niche domain (Construction) likely mitigates the data scarcity problem typical of specialized NER tasks. The model leverages general French linguistic understanding (pre-training) and adapts it to identify construction-specific entities (Concepts/Properties) using a relatively small hand-crafted annotated dataset (233 requirements). The core assumption is that the syntactic and semantic patterns in general French corpora transfer effectively to the technical, jargon-heavy language of Building Technical Specifications (BTS).

### Mechanism 3
Relation Extraction (RE) between entities relies more heavily on syntactic distance and orientation than semantic embeddings in this specific context. The Random Forest classifier uses features like "Count of Words" and "Orientation" (before/after) to link Concepts to Properties. Notably, adding semantic features (Word2Vec embeddings) degraded performance for Decision Trees and Random Forests. The core assumption is that the physical proximity and grammatical roles of entities are stronger predictors of a relationship than the semantic "meaning" of the intervening text in BTS documents.

## Foundational Learning

**Concept: Transformer-based Masked Language Models (MLMs)**
- Why needed here: Understanding how CamemBERT differs from standard BERT (French corpus training) and how "Masking" helps the model learn context from technical sentences is critical for troubleshooting low-confidence entity predictions.
- Quick check question: Can you explain why a model pre-trained on general French text might struggle with the acronym "CCTP" without fine-tuning?

**Concept: BILOU Tagging Scheme**
- Why needed here: The study uses the Beginning, Inside, Last, Outside, Unit-length scheme to handle multi-word entities (e.g., "Porte vitrée"). Understanding this is required to interpret the evaluation metrics and format the training data correctly.
- Quick check question: How would you tag the phrase "fire rated door" if "fire rated" is an adjective modifying the concept "door"?

**Concept: Feature Engineering for RE**
- Why needed here: Unlike the NER component which uses deep learning, the RE component uses classical ML (Random Forest). You must understand how to construct feature vectors (e.g., "Path Within Parse Tree") manually.
- Quick check question: If two entities appear in different sentences, which feature in the study's custom vector would likely have a high value?

## Architecture Onboarding

**Component map:** PDF Parser -> Raw Text -> Algorithm 1 (Header/Footer removal) -> Algorithm 2 (Hierarchical segmentation) -> Raw Requirements -> CamemBERT/Fr_core_news_lg (NER) -> Entities (C, P) -> Random Forest (RE) -> Relations (R) -> JSON/Knowledge Graph

**Critical path:** The Segmentation Algorithm is the primary bottleneck. If the regex fails to identify the hierarchy, the "Raw Requirement" chunks will be incomplete, causing the downstream NER to miss context and the RE model to fail.

**Design tradeoffs:**
- **Regex vs. Layout Analysis:** The study uses regex for segmentation because PDF-to-HTML conversion failed. This trades robustness (handling varied layouts) for precision with standard numbering.
- **Precision vs. Recall (Rule-based vs. Deep Learning):** Rule-based NER achieved high precision (1.00 for some entities) but lower recall compared to CamemBERT. The architecture favors Deep Learning to maximize generalization.

**Failure signatures:**
- **Ambiguity:** The word "Porte" (Door) is also a verb. Rule-based systems failed here; CamemBERT likely disambiguated via context.
- **Formatting Drift:** Section 3.2 notes that headers/footers are consistent only 92% of the time. Watch for "orphan" text lines that are actually headers mistakenly left in the content stream.

**First 3 experiments:**
1. **Validation of Segmentation:** Run Algorithm 2 on a sample of 20 PDFs. Manually verify if the "Raw Requirements" chunks logically group related properties (verify "Common" vs "Specific" merging).
2. **NER Baseline Check:** Benchmark a standard non-French BERT model against CamemBERT on the annotated test set to quantify the value of the French-specific pre-training.
3. **Feature Ablation for RE:** Retrain the Random Forest model by stripping away "Syntactic" features one by one to confirm the paper's finding that semantic features degrade performance.

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: Can Causal Language Models (CLMs) like GPT and Mistral outperform the current Masked Language Model (MLM) approaches for NER and RE on French BTS documents using zero-shot or few-shot learning?
- Basis in paper: The authors state in Section 5.2 that future work will explore CLMs and prompt engineering to determine if they offer the "best solution for domain-specific tasks without relying on large annotated datasets."
- Why unresolved: The current study focused exclusively on fine-tuning MLMs (CamemBERT) and transfer learning, which required a hand-crafted annotated dataset. The potential of CLMs to perform these tasks with minimal training data remains untested in this specific domain.

**Open Question 2**
- Question: Can LLM-based segmentation replace rule-based numbering algorithms to successfully extract hierarchical requirements from the 28% of BTS documents that currently fail processing?
- Basis in paper: Section 5.2 proposes leveraging LLMs to "extract the hierarchical structure" to handle context better, addressing the limitation in Section 5.1 where the current algorithm fails on documents with inconsistent or missing numbering systems.
- Why unresolved: The current methodology relies on regular expressions and consistent numbering to segment documents. This dependency causes a failure rate of nearly 28% when numbering is inconsistent or absent.

**Open Question 3**
- Question: How effectively can the extracted JSON requirements be automatically formalized into a knowledge graph compliant with SHACL for BIM verification?
- Basis in paper: The Conclusion and Abstract state that outcomes are "intended to be represented as a knowledge graph" and aligned with SHACL for future automated verification systems, but this implementation is noted as "future work."
- Why unresolved: The paper stops at the extraction of semi-formal requirements (JSON format) and defines the logic for mapping these entities to a SHACL graph for model verification as a subsequent step.

## Limitations

- The annotated dataset used for evaluation is relatively small (233 requirements), which may limit generalizability to larger, more diverse BTS corpora.
- The approach is tailored to French BTS documents with specific numbering conventions, requiring significant adaptation for other languages or building specification formats.
- The study focuses on entity extraction and relation linking but does not address downstream applications or validation of the structured requirements in actual BIM workflows.

## Confidence

**High confidence:** The effectiveness of CamemBERT and Fr_core_news_lg for NER (F1-scores over 90%) is well-supported by direct experimental evidence and aligns with established transfer learning principles.

**Medium confidence:** The superiority of Random Forest with syntactic features for RE (F1-score above 80%) is demonstrated, but the finding that semantic features degrade performance appears context-specific and may not generalize to other domains.

**Low confidence:** The claim that hierarchical document segmentation is a "necessary precondition" for extracting complete formal requirements is plausible but not empirically proven across diverse document structures.

## Next Checks

1. **Cross-corpus validation:** Test the complete pipeline on a larger, more diverse set of BTS documents (minimum 100 documents) from multiple sources to verify performance stability and identify edge cases in document structure.

2. **Ablation study on segmentation:** Systematically evaluate the impact of the hierarchical segmentation algorithm by comparing RE performance with and without the "Common" and "Specific" requirement merging, particularly on documents with known numbering inconsistencies.

3. **Downstream BIM integration test:** Implement a prototype BIM system that consumes the structured requirements output and validate whether the extracted entities and relations can successfully drive automated BIM element creation or validation tasks.