---
ver: rpa2
title: Improving Narrative Classification and Explanation via Fine Tuned Language
  Models
arxiv_id: '2509.04077'
source_url: https://arxiv.org/abs/2509.04077
tags:
- narrative
- narratives
- classification
- dominant
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of detecting and explaining
  implicit narratives in news articles, which is critical for media analysis and disinformation
  detection. The authors propose a two-stage approach: first, fine-tuning BERT for
  multi-label classification of narratives with a recall-oriented focus, followed
  by refinement using a GPT-4o pipeline for consistency; second, generating evidence-based
  explanations through a ReACT framework with semantic retrieval and a structured
  taxonomy knowledge base.'
---

# Improving Narrative Classification and Explanation via Fine Tuned Language Models

## Quick Facts
- arXiv ID: 2509.04077
- Source URL: https://arxiv.org/abs/2509.04077
- Reference count: 11
- Primary result: F1 scores of 0.467 for dominant narratives and 0.217 for sub-narratives; improved justification reliability via evidence-based explanations

## Executive Summary
This paper tackles the challenge of detecting and explaining implicit narratives in news articles, a task critical for media analysis and disinformation detection. The authors propose a two-stage approach: first, fine-tuning BERT for multi-label classification of narratives with a recall-oriented focus, followed by refinement using a GPT-4o pipeline for consistency; second, generating evidence-based explanations through a ReACT framework with semantic retrieval and a structured taxonomy knowledge base. Their method improves classification accuracy and enhances justification reliability across multiple languages, with applications in media analysis, education, and intelligence gathering.

## Method Summary
The approach consists of two main components: (1) a fine-tuned BERT model for multi-label narrative classification, optimized for recall using focal loss and adaptive threshold tuning; and (2) a GPT-4o-based pipeline that refines predictions and generates evidence-based explanations using semantic retrieval and a ReACT framework with a taxonomy knowledge base. The method is evaluated on news articles in five languages related to the Ukraine-Russia war and climate change, with separate models for each topic.

## Key Results
- Classification F1 scores: 0.467 for dominant narratives, 0.217 for sub-narratives
- Improved explanation quality via evidence-based justifications, reducing hallucination
- Scalable approach demonstrated even with smaller LLMs

## Why This Works (Mechanism)
The method leverages fine-tuned BERT for robust multi-label classification, with focal loss addressing class imbalance and adaptive thresholding prioritizing recall. The GPT-4o refinement pipeline ensures consistency and reduces hallucination by grounding explanations in retrieved evidence via semantic search and a structured taxonomy. This integration of classification and explanation within a unified framework enables both accurate narrative detection and trustworthy justification.

## Foundational Learning
- **Multi-label classification**: Why needed—news articles often contain multiple narratives; quick check—verify label cardinality distribution
- **Focal loss**: Why needed—addresses class imbalance, especially for rare sub-narratives; quick check—monitor loss per class during training
- **Semantic retrieval**: Why needed—grounds explanations in evidence, reducing hallucination; quick check—inspect overlap between retrieved sentences and generated justifications
- **ReACT framework**: Why needed—combines reasoning and action for structured explanations; quick check—validate Action section contains taxonomy and retrieval references
- **Adaptive threshold tuning**: Why needed—optimizes recall for rare narrative classes; quick check—plot precision-recall curve for different thresholds

## Architecture Onboarding
- **Component map**: BERT classifier -> GPT-4o refinement -> Semantic retrieval -> ReACT explanation generator
- **Critical path**: Fine-tuning BERT -> Threshold tuning for recall -> GPT-4o refinement with taxonomy -> Semantic retrieval + ReACT explanation
- **Design tradeoffs**: Recall vs. precision (threshold tuning); explanation fidelity vs. length (80-word limit); retrieval vs. generation (hallucination risk)
- **Failure signatures**: Low sub-narrative F1 (class imbalance); explanations lacking citations (retrieval failure); predictions inconsistent with taxonomy (refinement failure)
- **First experiments**:
  1. Train BERT with focal loss and analyze per-class F1 to confirm imbalance handling
  2. Test semantic retrieval by verifying top-5 matches for a sample of explanations
  3. Evaluate GPT-4o refinement by comparing pre- and post-refinement classification consistency

## Open Questions the Paper Calls Out
None

## Limitations
- Missing details on adaptive threshold tuning algorithm and target recall/precision trade-off values
- Exact GPT-4o prompt templates and sampling parameters not provided
- Evaluation does not quantify hallucination rates or test robustness to adversarial inputs

## Confidence
- Classification claims: **Medium** (credible given established techniques, but lack of prompt details)
- Explanation quality claims: **Low** (insufficient evaluation of factual accuracy and grounding)
- Scalability/robustness claims: **Medium** (modular architecture plausible, but not empirically validated)

## Next Checks
1. Reconstruct the exact adaptive threshold tuning procedure and GPT-4o prompt templates from provided materials or author correspondence
2. Conduct a qualitative audit of explanation outputs to verify evidence support and low hallucination rates
3. Test pipeline robustness on out-of-domain articles and adversarial inputs to assess generalizability and resilience to subtle narrative manipulations