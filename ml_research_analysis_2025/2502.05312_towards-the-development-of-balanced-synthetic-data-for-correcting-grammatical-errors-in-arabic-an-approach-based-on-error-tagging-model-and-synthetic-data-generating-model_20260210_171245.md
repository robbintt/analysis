---
ver: rpa2
title: 'Towards the Development of Balanced Synthetic Data for Correcting Grammatical
  Errors in Arabic: An Approach Based on Error Tagging Model and Synthetic Data Generating
  Model'
arxiv_id: '2502.05312'
source_url: https://arxiv.org/abs/2502.05312
tags:
- data
- arabic
- error
- synthetic
- errors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of developing grammatical error
  correction (GEC) systems for Arabic, a low-resource language with limited parallel
  data. The authors propose a novel approach based on error tagging and synthetic
  data generation to create large-scale, balanced datasets for Arabic GEC.
---

# Towards the Development of Balanced Synthetic Data for Correcting Grammatical Errors in Arabic: An Approach Based on Error Tagging Model and Synthetic Data Generating Model

## Quick Facts
- arXiv ID: 2502.05312
- Source URL: https://arxiv.org/abs/2502.05312
- Reference count: 40
- Achieved 79.36% F1-score on QALB-14 test set, outperforming previous synthetic data generation methods

## Executive Summary
This study addresses the challenge of developing grammatical error correction (GEC) systems for Arabic, a low-resource language with limited parallel data. The authors propose a novel approach based on error tagging and synthetic data generation to create large-scale, balanced datasets for Arabic GEC. The error tagging model uses DeBERTa-v3 to classify correct sentences into 26 error types, while the synthetic data generation model employs AraT5 to generate incorrect sentences by appending error tags to correct sentences. This approach enables the creation of diverse and realistic grammatical errors. The proposed methodology achieved state-of-the-art results, with an F1-score of 79.36% on the QALB-14 test set, outperforming previous Arabic synthetic data generation methods. The authors generated 30,219,310 synthetic sentence pairs, which are publicly available.

## Method Summary
The authors developed a two-stage approach for Arabic grammatical error correction. First, an error tagging model based on DeBERTa-v3 classifies grammatically correct sentences into 26 error types using multi-label classification with distribution-balanced loss. Second, an AraT5 model generates incorrect sentences by conditioning on the predicted error tags appended as a prefix to correct sentences. The approach uses monolingual clean text from large Arabic corpora as input, producing synthetic parallel data (incorrect→correct) that can be used to train GEC models. The methodology addresses the data scarcity problem in Arabic GEC by generating diverse and realistic grammatical errors at scale.

## Key Results
- Achieved 79.36% F1-score on QALB-14 test set, outperforming previous synthetic data generation methods
- Generated 30,219,310 synthetic sentence pairs covering 26 error types
- Error tagging model achieved 94.06% F1 on QALB-14 test set using DeBERTa-v3
- Synthetic data enabled GEC model to achieve 75.87% F1, surpassing previous transformer-based approaches (62.02% F1)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tag-conditioned generation produces more diverse and realistic errors than rule-based noise injection.
- Mechanism: The error tagging model (DeBERTa-v3) first predicts which of 26 error types could plausibly occur in a grammatically correct sentence. These predicted tags are then concatenated as a prefix to the correct sentence and fed to the synthetic data generation model (AraT5), which produces a corrupted sentence conditioned on those specific error types.
- Core assumption: The error tagging model's predictions on clean sentences reflect plausible error distributions that humans would make; AraT5 can learn the mapping from error-type prefixes to surface-level corruptions.
- Evidence anchors:
  - [abstract] "The error tagging model uses DeBERTa-v3 to classify correct sentences into 26 error types, while the synthetic data generation model employs AraT5 to generate incorrect sentences by appending error tags to correct sentences."
  - [section 4.1] "An error tagging model was designed based on the DeBERTav3 pre-train language model as a multi-label classification task so that we can predict the types of errors (tags) that may appear in correctly constructed sentences."
  - [corpus] Weak direct corpus evidence; neighbor papers focus on GEC systems but not tag-conditioned synthetic generation specifically.
- Break condition: If the error tagging model has low precision on rare error types (e.g., ON, OS in Table 7 show F1=0), the synthetic data will underrepresent or misrepresent those error categories.

### Mechanism 2
- Claim: Multi-label classification with distribution-balanced loss mitigates severe class imbalance in error type prediction.
- Mechanism: The 26 error tags are highly imbalanced (Figure 2). Distribution-Balanced Loss (DB) re-weights each sample's contribution based on inverse class frequency and down-weights easy negative samples via focal loss components, allowing the model to learn meaningful representations for rare error types rather than collapsing to frequent classes.
- Core assumption: The test distribution reflects training imbalance; re-weighting improves generalization rather than overfitting to rare classes.
- Evidence anchors:
  - [section 4.1] "To address imbalances in class distribution, distribution-balanced loss (DB) is used for multi-label text classification... A lower weight is explicitly assigned to instances of negative data that are easy to classify by the DB loss function."
  - [section 6.1] "Micro-Average of 0.908 in the development set and 0.944 in the test set... Macro-average was lower (0.775 in development, 0.804 in test), indicating a decrease in average performance due to some low-performing classes."
  - [corpus] No direct corpus evidence on DB loss specifically for Arabic GEC.
- Break condition: If rare classes have too few training samples (e.g., ON with support=1), no loss re-weighting will produce reliable predictions; synthetic data for those classes will be unreliable.

### Mechanism 3
- Claim: Two-stage fine-tuning of AraT5 (correct→incorrect, then tag-conditioned generation) improves corruption quality over single-stage back-translation.
- Mechanism: First, AraT5 is fine-tuned on parallel GEC data (incorrect→correct). Then, the process is reversed with task prefix "grammar_error" and error tags appended, training the model to generate incorrect sentences from correct ones conditioned on predicted error types. This leverages the model's bidirectional understanding of error-correction pairs.
- Core assumption: The reverse direction (correct→incorrect) generalizes from the forward correction patterns learned in the first fine-tuning stage.
- Evidence anchors:
  - [section 4.2] "We fine-tuned AraT5 two times to generate erroneous sentences. In the first fine-tuning process, the model input is the incorrect sentence and the target is the correct sentence... Our model is then further fine-tuned for a second time to generate syntactic data."
  - [section 6.3] Table 8 shows AraT5 with synthetic data achieving 75.87% F1 vs. 62.02% for transformer-based GEC on QALB-14.
  - [corpus] ArbESC+ and related papers use ensemble/system combination approaches but not this specific two-stage fine-tuning.
- Break condition: If the original parallel corpus (QALB-14/15) contains systematic annotation biases or error-type gaps, the reverse model will inherit and amplify those biases.

## Foundational Learning

- Concept: Multi-label vs. multi-class classification
  - Why needed here: Each sentence can contain multiple simultaneous error types (e.g., orthography + syntax), requiring sigmoid activations per label rather than softmax over mutually exclusive classes.
  - Quick check question: Can a single sentence be tagged with both "OA" (Alif confusion) and "XG" (gender error)? If yes, what activation function should the output layer use?

- Concept: Back-translation for data augmentation
  - Why needed here: The synthetic generation model inverts the standard GEC direction, generating incorrect sentences from correct ones—conceptually similar to back-translation in machine translation but applied to error injection.
  - Quick check question: In standard NMT back-translation, what direction is the synthetic data generation? How does this paper's approach differ?

- Concept: Threshold tuning for imbalanced multi-label prediction
  - Why needed here: The default 0.5 threshold may not optimize F1 for imbalanced labels; the paper tunes thresholds per-label based on validation performance.
  - Quick check question: If error type "PM" (missing punctuation) appears in 50% of sentences but "MT" (verb tense) appears in 2%, should they use the same probability threshold for positive prediction?

## Architecture Onboarding

- Component map: Monolingual clean text → Preprocessing → Error Tagging Model (DeBERTa-v3) → Predicted error tag vector → Synthetic Data Generation Model (AraT5) → Corrupted sentence → GEC Training

- Critical path:
  1. Preprocess monolingual corpus (1.5B words + OSIAN): remove encoding issues, filter short sentences (<10 words), normalize punctuation
  2. Run error tagging model on clean sentences to predict error tags
  3. Format tags as prefix (e.g., `[b a a b ...]` for 26 error types) and concatenate with clean sentence
  4. Generate corrupted sentence via AraT5 synthetic model
  5. Train GEC model on synthetic pairs, fine-tune on gold QALB data

- Design tradeoffs:
  - DeBERTa-v3 (multilingual) vs. AraBERTv02 (Arabic-specific): Paper shows DeBERTa achieves 94.06% F1 vs. 91.05% for AraBERTv02 on QALB-14 test, but requires larger multilingual model
  - Threshold tuning (0.5 default vs. optimized): Table 5 shows optimal thresholds ranging from 0.12 to 0.83 depending on model and dataset
  - Synthetic data scale: 30M pairs generated; training efficiency vs. noise in low-quality synthetic samples

- Failure signatures:
  - Zero F1 on rare error types (ON, OS in Table 7): Indicates insufficient training samples; synthetic data will lack these error types
  - L2 test set underperformance (Table 4, QALB-15-L2): Models trained on L1 (native speaker) data struggle with learner errors; synthetic data may not cover learner-specific error patterns
  - High Hamming loss on MARBERTv02 (0.06-0.08): Suggests dialect/MSA mismatch if applied to formal text

- First 3 experiments:
  1. Reproduce error tagging model on QALB-14 dev set: Train DeBERTa-v3-base with DB loss, compare F1 against AraBERTv02 baseline to validate architecture choice
  2. Ablate threshold tuning: Test fixed threshold (0.5) vs. optimized thresholds to quantify impact on micro vs. macro F1
  3. Generate small-scale synthetic dataset (10K pairs) and evaluate GEC model: Compare against Solyman et al. [10] synthetic data on same correct sentences to isolate generation quality from scale effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the error tagging model's performance on rare error classes (e.g., ON, OS with zero F1 scores) be improved through targeted data augmentation or specialized loss functions beyond Distribution-Balanced Loss?
- Basis in paper: [explicit] The authors state "the model still needs improvement to effectively deal with uneven distributions of classes" and "our synthetic data may be useful in the future for classifying Arabic texts more efficiently and flexibly by solving for rare classes."
- Why unresolved: Despite using Distribution-Balanced Loss, rare classes like ON and OS still achieved zero precision/recall due to extremely limited training samples (support = 1 and 8 in dev set).
- What evidence would resolve it: Experiments comparing the current approach with targeted oversampling, synthetic data focused specifically on rare error types, or alternative loss functions showing improved macro-F1 scores across all 26 error tags.

### Open Question 2
- Question: Would incorporating L2 (non-native speaker) data into the training pipeline improve model performance on mixed L1/L2 test sets like QALB-15?
- Basis in paper: [inferred] The authors note their models were "trained using native-speaker texts (L1 data), whereas the QALB-15 test data has a mix of native (L1) and non-native (L2) speakers" and their model underperformed Solyman et al. [10] on QALB-15 despite outperforming on QALB-14.
- Why unresolved: The current approach uses only L1 data for training, creating a domain mismatch with L2-heavy evaluation sets.
- What evidence would resolve it: Ablation studies comparing models trained on L1-only, L2-only, and mixed L1/L2 synthetic data, evaluated on both QALB-14 and QALB-15 test sets.

### Open Question 3
- Question: How does the grammatical correctness and error distribution of the source monolingual corpora (1.5 billion word corpus, OSIAN) affect the quality and diversity of generated synthetic errors?
- Basis in paper: [inferred] The authors acknowledge that "both corpora contained spelling and grammatical errors" and that "grammatical errors were not corrected because they needed to be annotated by humans," potentially introducing noise into the "correct" sentence inputs.
- Why unresolved: The assumption that monolingual news corpora represent grammatically correct sentences is not validated, and the impact of residual errors on synthetic data quality remains unquantified.
- What evidence would resolve it: Human evaluation of source corpus quality followed by correlation analysis between input correctness and downstream GEC model performance.

### Open Question 4
- Question: Can the proposed error tagging and synthetic data generation methodology generalize effectively to other morphologically rich, low-resource languages beyond Arabic?
- Basis in paper: [inferred] The authors position their work as addressing "low-resource languages such as Arabic" and note the approach is novel for Arabic, but do not test cross-linguistic applicability.
- Why unresolved: The methodology relies on language-specific components (ARETA tool with 26 Arabic-specific error tags, AraT5 model), making generalization uncertain.
- What evidence would resolve it: Replication studies applying the same two-model framework to other low-resource languages (e.g., Hebrew, Farsi) using comparable error taxonomies and language-specific transformers.

## Limitations
- Rare error type coverage: Error tagging model achieves zero F1 on rare classes (ON, OS), leading to underrepresentation in synthetic data
- L2 data mismatch: Models trained on native speaker data underperform on mixed L1/L2 test sets
- Annotation bias inheritance: Synthetic data generation inherits systematic biases from original QALB annotation scheme

## Confidence
**High Confidence Claims:**
- The two-stage fine-tuning approach for AraT5 (correct→incorrect) is technically sound and well-implemented
- Distribution-balanced loss improves multi-label classification performance on imbalanced error types compared to standard cross-entropy
- The methodology achieves state-of-the-art results on QALB-14 test set (F1=79.36%)

**Medium Confidence Claims:**
- Synthetic data quality matches or exceeds human-annotated errors for common error types (orthography, morphology)
- The 26 error tag taxonomy adequately covers Arabic grammatical errors found in learner writing
- The scale of synthetic data (30M pairs) provides meaningful improvements over smaller datasets

**Low Confidence Claims:**
- Synthetic data adequately represents rare error types (ON, OS, SU) for downstream model training
- The approach generalizes to non-native Arabic learner errors beyond native speaker patterns
- Tag-conditioned generation produces more diverse errors than alternative synthetic data methods without empirical comparison on identical source sentences

## Next Checks
1. **Error type coverage validation**: Analyze the distribution of error types in the synthetic dataset and compare against authentic error corpora (QALB, learner data). Calculate the percentage of synthetic pairs containing each error type and identify which types are systematically missing or underrepresented.

2. **Human evaluation of synthetic errors**: Conduct a blind comparison study where native Arabic speakers rate the naturalness and plausibility of errors in synthetic sentences versus authentic QALB errors. Focus specifically on cases where the model predicts rare error types (ON, OS, SU) to assess whether the synthetic errors are grammatically plausible.

3. **Cross-dialect generalization test**: Evaluate the trained GEC model on dialectal Arabic data (from OSIAN or similar) to assess whether the synthetic data generation approach produces errors relevant to non-MSA varieties. Compare performance against a model trained on MSA-only synthetic data to quantify dialectal robustness.