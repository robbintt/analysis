---
ver: rpa2
title: Comparing privacy notions for protection against reconstruction attacks in
  machine learning
arxiv_id: '2502.04045'
source_url: https://arxiv.org/abs/2502.04045
tags:
- privacy
- reconstruction
- mechanism
- which
- bayes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the challenge of comparing privacy mechanisms\
  \ in machine learning that satisfy different formal privacy guarantees, particularly\
  \ focusing on reconstruction attacks. The authors propose a framework using R\xE9\
  nyi Differential Privacy (RDP) to convert between different privacy definitions,\
  \ and introduce Bayes' capacity as a measure specifically suited for reconstruction\
  \ attacks."
---

# Comparing privacy notions for protection against reconstruction attacks in machine learning

## Quick Facts
- arXiv ID: 2502.04045
- Source URL: https://arxiv.org/abs/2502.04045
- Reference count: 40
- Primary result: VMF mechanisms provide better reconstruction protection than RDP-equivalent Gaussian mechanisms but worse utility, with Bayes' capacity better predicting reconstruction accuracy than DP parameters

## Executive Summary
This paper addresses the challenge of comparing privacy mechanisms in machine learning that satisfy different formal privacy guarantees, particularly for reconstruction attacks. The authors propose using Rényi Differential Privacy (RDP) as a unifying framework to convert between different privacy definitions, and introduce Bayes' capacity as a more appropriate measure for assessing reconstruction attack protection. Experiments on MNIST and FashionMNIST datasets demonstrate that while RDP-equivalent Gaussian and von Mises-Fisher (VMF) mechanisms have similar privacy parameters, VMF provides superior reconstruction protection but inferior utility. The work shows that Bayes' capacity correlates better with reconstruction accuracy than traditional DP parameters, making it a more suitable metric for this specific threat scenario.

## Method Summary
The authors develop a framework for comparing privacy mechanisms using RDP to convert between different privacy definitions, enabling fair comparison of mechanisms like Gaussian (providing (ε,δ)-DP) and von Mises-Fisher (providing metric privacy). They introduce Bayes' capacity as an information-theoretic measure specifically suited for reconstruction attacks, computed via integration over continuous domains. The core method involves implementing DP-SGD with configurable noise mechanisms, computing RDP parameters, applying sub-sampling amplification and composition, converting to (ε,δ)-DP for baseline comparison, and computing Bayes' capacity for threat assessment. Experiments validate the framework through gradient norm preservation analysis and reconstruction attack evaluations.

## Key Results
- VMF mechanisms provide better reconstruction protection than RDP-equivalent Gaussian mechanisms
- Bayes' capacity correlates better with reconstruction accuracy than traditional DP parameters
- VMF preserves gradient norms while providing superior reconstruction protection
- The trade-off between reconstruction protection and utility differs significantly between mechanisms

## Why This Works (Mechanism)

### Mechanism 1: RDP-Based Privacy Parameter Conversion
- Claim: Enables fair comparison of mechanisms satisfying different privacy definitions by converting to common (ε,δ)-DP via Rényi Differential Privacy.
- Mechanism: The RDP framework converts VMF mechanism's metric privacy parameters to (α,τ)-RDP, then to (ε,δ)-DP, while accounting for sub-sampling amplification and multi-epoch composition.
- Core assumption: The Rényi divergence for VMF distributions at antipodal directions provides the largest divergence (worst-case privacy loss).
- Evidence anchors: [section III-A] shows RDP computation methodology, [Table I] demonstrates concrete κ→ε mappings with different approaches yielding varying optimal ε values.

### Mechanism 2: Bayes' Capacity for Reconstruction Attack Measurement
- Claim: Bayes' capacity provides a mechanism-agnostic upper bound on reconstruction attack success that correlates with empirical MSE/SSIM metrics better than DP parameters.
- Mechanism: Theorem 4 shows reconstruction risk in DP-SGD equals C_Bayes(D) where D is the noise-adding mechanism, computed via integration over continuous domains. For Gaussian: Theorem 5 formula; for VMF: Theorem 6 formula.
- Core assumption: The adversary has a uniform prior over feasible reconstructions and uses a one-try attack strategy (exact reconstruction goal).
- Evidence anchors: [section VII-C] demonstrates smaller Bayes' capacity values correspond to larger MSE values regardless of mechanism, [Figure 4] shows monotonic Bayes' capacity vs MSE relationship across both mechanisms.

### Mechanism 3: Directional vs. Isotropic Noise Trade-off
- Claim: VMF's directional (angular) noise preserves gradient norms while providing better reconstruction protection but worse utility compared to RDP-equivalent Gaussian noise.
- Mechanism: VMF perturbs gradients on the unit sphere, preserving norm information while randomizing direction, whereas Gaussian adds isotropic noise to all dimensions.
- Core assumption: Norm preservation affects gradient descent dynamics differently than full-vector perturbation, and reconstruction attacks exploit direction more than norm.
- Evidence anchors: [section VII-A] shows Gaussian mechanism outperforms VMF in accuracy while VMF maintains stable low SSIM/high MSE across ε range, [Figure 1] illustrates the divergent utility patterns.

## Foundational Learning

- **Concept: Differential Privacy Variants (Approximate DP vs. Metric Privacy)**
  - Why needed here: The paper's core problem is that ε means different things in (ε,δ)-DP (bounded probability ratio) versus metric privacy (distance-dependent ratio), making direct comparison invalid.
  - Quick check question: Given metric privacy with ε=100 and approximate DP with ε=10, which provides stronger protection? (Answer: Cannot determine without conversion framework)

- **Concept: Rényi Divergence and RDP**
  - Why needed here: RDP provides a unifying mathematical framework that can express both DP variants, enabling parameter conversion through moment accounting.
  - Quick check question: Why does RDP use multiple orders α rather than a single divergence measure? (Answer: Different α capture different tail behaviors of privacy loss distribution)

- **Concept: Information-Theoretic Channel Capacity**
  - Why needed here: Bayes' capacity interprets DP-SGD as an information channel from secrets (training data) to observations (noisy gradients), providing a semantic measure of maximum leakage.
  - Quick check question: Why does Lemma 1 show C_Bayes(C·D) = C_Bayes(D) for deterministic preprocessing C? (Answer: Deterministic operations don't add randomness that could hide or leak information)

## Architecture Onboarding

- **Component map:**
  Training Pipeline: [Data] → [Gradient Computation] → [Clipping] → [Noise Addition] → [Parameter Update]
                                                          ↓
                                          Privacy Mechanism: {Gaussian | VMF}
                                                          ↓
  Comparison Framework: [Mechanism] → [RDP Conversion] → [(ε,δ)-DP Equivalence] → [Utility/Privacy Metrics]
                                                          ↓
                                          Alternative: [Bayes' Capacity Computation]
  
  Attack Evaluation: [Noisy Gradients] → [IGA Attack] → [Reconstructed Images] → [MSE/SSIM Scoring]

- **Critical path:**
  1. Implement DP-SGD with configurable noise mechanisms (Gaussian/VMF)
  2. Compute RDP parameters for each mechanism (Proposition 1 for VMF)
  3. Apply sub-sampling amplification (Theorem 3) and composition (multiply by N epochs)
  4. Convert to (ε,δ)-DP for fair comparison baseline
  5. Compute Bayes' capacity for reconstruction threat assessment
  6. Execute reconstruction attacks to validate theoretical predictions

- **Design tradeoffs:**
  - **Gaussian mechanism**: Higher utility, simpler analysis, well-studied privacy accounting; but weaker reconstruction protection per unit ε
  - **VMF mechanism**: Better reconstruction protection, norm preservation may benefit certain architectures; but lower utility and more complex RDP computation
  - **Privacy metric choice**: (ε,δ)-DP for membership inference focus; Bayes' capacity for reconstruction threat focus—neither alone captures all attack scenarios

- **Failure signatures:**
  - RDP conversion yields non-monotonic ε values: Check numerical stability in Bessel function computation (I_ν(κ))
  - VMF training diverges: Ensure gradient normalization occurs before noise addition (Algorithm 2, line 10)
  - Bayes' capacity doesn't predict reconstruction MSE: Verify continuous domain integration bounds match actual gradient clipping radius
  - Reconstruction attacks fail on both mechanisms equally: Batch size may be too small; try increasing to 64-128

- **First 3 experiments:**
  1. **Baseline equivalence verification**: Train identical MLPs with Gaussian and VMF noise using RDP-equivalent parameters (e.g., κ=100, σ=0.66 → ε≈0.5). Verify they achieve similar ε but divergent utility (expect ~40% accuracy gap on MNIST).
  2. **Bayes capacity correlation test**: Compute C_Bayes for 5 configurations of each mechanism, run IGA attacks, plot C_Bayes vs MSE. Confirm monotonic relationship across mechanisms (not just within each).
  3. **Cross-mechanism calibration**: Fix target reconstruction MSE (e.g., MSE=3.0), find required κ for VMF and σ for Gaussian. Compute resulting ε and C_Bayes for each. Observe which mechanism provides better utility at equivalent reconstruction protection.

## Open Questions the Paper Calls Out
None

## Limitations
- RDP conversion for VMF mechanisms relies on worst-case antipodal direction assumptions that may overestimate privacy loss
- Bayes' capacity computation for VMF involves complex Bessel function integrals that could introduce numerical instability
- Evaluation focuses on gradient norm preservation as the key utility metric, potentially missing other important effects
- Experiments use simple MLP architectures and standard datasets, limiting generalizability

## Confidence
- **High confidence**: RDP-based parameter conversion framework, sub-sampling amplification theorems, Bayes' capacity computation methodology
- **Medium confidence**: Cross-mechanism utility comparison results, particularly the trade-off between norm preservation and reconstruction protection
- **Low confidence**: Optimality of Bayes' capacity as a universal reconstruction attack metric given varying attack strategies and threat models

## Next Checks
1. **Numerical stability verification**: Recompute Bayes' capacity for VMF across a wide range of κ values (1-500) using multiple numerical integration methods to ensure results are consistent and not artifacts of Bessel function approximations.

2. **Architectural generalization test**: Implement the same comparison framework on ResNet architectures trained on CIFAR-10/CIFAR-100 to validate whether the directional noise trade-offs observed in MLPs persist in deeper networks.

3. **Multi-try attack evaluation**: Extend the information-theoretic analysis to k-try reconstruction attacks (where k > 1) and verify whether Bayes' capacity remains a predictive metric or if its relationship with empirical MSE degrades for more sophisticated adversaries.