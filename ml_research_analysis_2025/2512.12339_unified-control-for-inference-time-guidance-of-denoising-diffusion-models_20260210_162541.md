---
ver: rpa2
title: Unified Control for Inference-Time Guidance of Denoising Diffusion Models
arxiv_id: '2512.12339'
source_url: https://arxiv.org/abs/2512.12339
tags:
- reward
- guidance
- diffusion
- sampling
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces UniCoDe, a unified inference-time guidance
  method for denoising diffusion models that combines sampling-based and gradient-based
  approaches. The method addresses the inefficiency of sampling-based approaches by
  integrating local gradient signals during sampling, reducing the number of samples
  required while maintaining high output quality and strong alignment with target
  conditioning.
---

# Unified Control for Inference-Time Guidance of Denoising Diffusion Models

## Quick Facts
- arXiv ID: 2512.12339
- Source URL: https://arxiv.org/abs/2512.12339
- Reference count: 40
- Introduces UniCoDe, a unified inference-time guidance method for denoising diffusion models that combines sampling-based and gradient-based approaches, achieving 3-5x faster inference while maintaining high reward alignment and prior preservation

## Executive Summary
This paper introduces UniCoDe, a unified inference-time guidance method for denoising diffusion models that combines sampling-based (CoDe-style blockwise selection) and gradient-based approaches. The method addresses the inefficiency of sampling-based approaches by integrating local gradient signals during sampling, reducing the number of samples required while maintaining high output quality and strong alignment with target conditioning. UniCoDe employs blockwise gradient guidance alongside blockwise sampling, with extensions including scheduled sampling, multinomial sampling, clustering-based guidance, and support for non-differentiable rewards. The method is evaluated across multiple tasks including Text-to-Image, Text-and-Image-to-Image, and multi-reward scenarios using various reward models. Results show UniCoDe is 3-5 times faster than state-of-the-art baselines while achieving competitive or superior reward alignment and prior preservation, with notable improvements in efficiency and prompt adherence across different diffusion model backbones.

## Method Summary
UniCoDe is a unified inference-time guidance framework that combines sampling-based and gradient-based approaches for denoising diffusion models. The method operates by sampling N=4 noise vectors and denoising them with DDPM for 500 steps, applying gradient guidance every B_g steps (computing clean samples via Tweedie's formula, backpropagating reward, and adding scaled gradients to latent), and applying blockwise sampling every B_s steps (estimating clean samples, computing rewards, and multinomial resampling with temperature). Key hyperparameters include B_s=5, B_g∈{2,4,5}, γ=0.2-0.4, CFG=5, and seed=2024. The method supports various extensions including scheduled sampling, multinomial sampling with temperature, clustering-based guidance, and zero-order optimization for non-differentiable rewards.

## Key Results
- Achieves 3-5× faster inference compared to state-of-the-art baselines while maintaining competitive or superior reward alignment
- Demonstrates strong performance across multiple tasks including Text-to-Image, Text-and-Image-to-Image, and multi-reward scenarios
- Shows improved efficiency and prompt adherence across different diffusion model backbones (SD v1.5 and SD 2.1)
- Maintains good prior preservation (CMMD) while achieving higher reward scores compared to pure sampling-based methods

## Why This Works (Mechanism)
UniCoDe works by intelligently combining the strengths of both sampling-based and gradient-based guidance methods. The sampling-based component provides robust exploration and diversity through blockwise selection, while the gradient-based component offers precise local optimization by leveraging reward signals. By integrating these approaches at different stages of the denoising process, UniCoDe achieves better sample efficiency than pure sampling methods while avoiding the local optima issues of pure gradient methods. The blockwise structure allows for controlled trade-offs between reward alignment and prior preservation, with the gradient scale γ and sampling temperature τ serving as key balancing parameters.

## Foundational Learning
- **Denoising Diffusion Probabilistic Models (DDPM)**: Learn to reverse a gradual noising process by predicting the noise added at each step - needed to understand the base generation process that UniCoDe modifies
- **Inference-time Guidance**: Techniques that steer generation at inference without retraining the model - needed to understand how UniCoDe modifies the sampling process
- **Tweedie's Formula**: Estimates posterior mean from noisy observations - needed for clean sample estimation in both gradient and sampling components
- **Zero-order Optimization**: Optimization using only function evaluations (no gradients) - needed to understand the non-differentiable reward extension
- **Multinomial Resampling**: Sampling with replacement according to a probability distribution - needed for the blockwise selection mechanism
- **Blockwise Processing**: Applying operations to subsets of timesteps - needed to understand the alternating guidance structure

## Architecture Onboarding

**Component Map**
Latent Diffusion Model (SD1.5) -> Tweedie's Formula Estimator -> Reward Models -> Gradient Computation -> Latent Update -> Blockwise Sampling -> Output

**Critical Path**
Noise sampling → DDPM denoising → Tweedie clean sample estimation → Reward computation → Gradient application (every B_g steps) → Multinomial resampling (every B_s steps) → Final image generation

**Design Tradeoffs**
- Sampling vs. gradient: Sampling provides diversity but is computationally expensive; gradients are efficient but can get stuck in local optima
- Prior preservation vs. reward alignment: Higher gradient scale improves reward but increases divergence from the unconditional prior
- Computational efficiency vs. quality: More samples (N) and frequent guidance (lower B_g, B_s) improve results but increase runtime

**Failure Signatures**
- High CMMD with poor image quality: Gradient too aggressive; reduce γ or increase B_g
- Reward plateau despite guidance: Gradient rescaling not applied or rewards computed on wrong latent space
- Non-differentiable rewards degrade performance: Zero-order optimization requires many forward passes (N'=50+)

**First 3 Experiments to Run**
1. Baseline SD1.5 generation with aesthetic guidance to establish reference metrics
2. UniCoDe with N=4, B_s=5, B_g=5, γ=0.2 to verify basic functionality
3. Ablation study varying γ (0.1-0.5) to observe reward-alignment vs prior-preservation tradeoff

## Open Questions the Paper Calls Out
**Open Question 1**: Can training-based gradient approximations (e.g., surrogate models) effectively extend UniCoDe's efficiency gains to non-differentiable reward settings while maintaining a training-free operational framework? The authors note that zero-order optimization is extremely challenging with noisy gradient estimation causing degraded performance, requiring many forward passes and leading to 238× slowdown.

**Open Question 2**: Would dynamic temperature scheduling during sampling improve the exploration-exploitation tradeoff and reward outcomes across diverse tasks compared to fixed temperature? The authors suggest that exploring dynamic temperature scheduling may improve generalization and efficiency, potentially boosting reward outcomes across a wider range of tasks.

**Open Question 3**: Can UniCoDe's performance gains generalize to diffusion model backbones with fundamentally different architectures (e.g., DiT-based models like SDXL, video diffusion models) beyond the tested U-Net-based Stable Diffusion variants? The method's reliance on Tweedie's formula and blockwise gradient application may not transfer directly to different denoising architectures.

**Open Question 4**: What is the theoretical relationship between the increased CMMD (divergence from unconditional prior) and reward alignment in UniCoDe, and is there an optimal operating point that balances both? The paper empirically demonstrates the tradeoff but does not provide theoretical bounds or explain whether the increased divergence represents harmful distribution shift or necessary deviation to achieve target reward alignment.

## Limitations
- The exact temperature parameter τ for multinomial sampling is not explicitly defined in the paper
- The method's performance with non-differentiable rewards degrades significantly (238× slower), limiting practical applicability
- Critical implementation details like gradient rescaling mechanism and K-means clustering initialization remain underspecified

## Confidence
- **High Confidence**: Runtime efficiency improvements (3-5× speedup) and basic functionality across evaluated tasks
- **Medium Confidence**: Relative performance comparisons with baselines
- **Low Confidence**: Claims about superiority in "diverse and challenging tasks" beyond the evaluated benchmarks, and generalizability to different model architectures

## Next Checks
1. **Gradient Integration Verification**: Implement and test the Tweedie's formula-based gradient guidance with varying γ values (0.1-0.5) to confirm the reported trade-off between reward alignment and prior preservation.
2. **Non-Differentiable Reward Benchmarking**: Evaluate UniCoDe's performance with a non-differentiable reward function (e.g., human preference scoring) to quantify the stated 238× slowdown and assess practical viability.
3. **Cross-Backbone Generalization**: Test UniCoDe with SDXL and other diffusion model variants to validate claims about applicability beyond SD1.5, particularly examining whether the proposed hyperparameters (B_s, B_g, γ) require task-specific tuning.