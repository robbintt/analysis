---
ver: rpa2
title: Detecting harassment and defamation in cyberbullying with emotion-adaptive
  training
arxiv_id: '2501.16925'
source_url: https://arxiv.org/abs/2501.16925
tags:
- cyberbullying
- emotion
- detection
- data
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of detecting both harassment
  and defamation in celebrity cyberbullying, particularly under low-resource settings
  where training data is scarce. The authors propose an emotion-adaptive training
  framework (EAT) that transfers knowledge from emotion detection datasets to cyberbullying
  detection tasks.
---

# Detecting harassment and defamation in cyberbullying with emotion-adaptive training

## Quick Facts
- arXiv ID: 2501.16925
- Source URL: https://arxiv.org/abs/2501.16925
- Reference count: 13
- Primary result: Emotion-adaptive training (EAT) improves macro F1, precision, and recall by 20% across nine transformer models in multi-class cyberbullying detection under low-resource settings.

## Executive Summary
This study addresses the challenge of detecting both harassment and defamation in celebrity cyberbullying, particularly under low-resource settings where training data is scarce. The authors propose an emotion-adaptive training framework (EAT) that transfers knowledge from emotion detection datasets to cyberbullying detection tasks. EAT improves average macro F1, precision, and recall by 20% across nine transformer-based models (including BERT, RoBERTa, T5, and LLMs like Llama2/3) in multi-class cyberbullying detection. The approach is particularly effective for detecting indirect cyberbullying forms like defamation, which traditional models struggle with due to data imbalance and contextual complexity. The study also introduces a new celebrity cyberbullying dataset containing harassment and defamation categories.

## Method Summary
The Emotion-Adaptive Training (EAT) framework transfers knowledge from emotion detection to cyberbullying detection through a three-phase process: (1) selecting a source domain dataset (GoEmotions with 58k Reddit comments across 27 emotions), (2) performing domain concept shift by mapping emotions to cyberbullying labels (Anger/Disgust→Harassment, Surprise→Defamation, Gratitude/Joy→Non-cyberbullying), and (3) knowledge transfer via fine-tuning transformer models. The framework uses RoBERTa-base as the backbone, with hyperparameters including batch size 32, learning rate 4e-5, 4 epochs, and token length 400. Models tested include RoBERTa, BERT, DistilBERT, Electra, XLNet, MPNet, T5, Llama2, and Llama3.

## Key Results
- EAT improves average macro F1 by 20% across nine transformer models in multi-class cyberbullying detection
- The approach is particularly effective for detecting defamation, which traditional models struggle with due to data imbalance (only 8% of samples)
- EAT outperforms zero-shot and few-shot learning baselines, with 24.5% and 15.3% improvements respectively in macro F1

## Why This Works (Mechanism)

### Mechanism 1: Domain Similarity
If the source domain (emotion) shares a similar latent feature space with the target domain (cyberbullying), knowledge transfer can mitigate data scarcity. By projecting data from both domains into a shared embedding space using RoBERTa embeddings, the model exploits the high geometric similarity (cosine similarity 0.993) between emotion expression and bullying behavior. This allows the model to reuse feature extractors trained on abundant emotion data for the scarce cyberbullying task.

### Mechanism 2: Concept Shift
Mapping distinct emotion labels to bullying categories aligns the conditional probability distributions ($P(y|x)$), enabling the model to recognize indirect bullying via emotional proxies. The framework manually groups fine-grained emotion labels (e.g., 'Anger', 'Disgust') and maps them to target classes (e.g., 'Harassment'). This forces the model to associate complex, indirect behaviors (like spreading rumors/defamation) with specific emotional markers (like 'Surprise'), effectively teaching the model "how it feels" rather than just "what it says."

### Mechanism 3: Regularization via Transfer
Pre-training on a high-resource source domain acts as a regularizer, preventing the model from overfitting to the limited samples of the target domain. In low-resource settings (e.g., 20 defamation samples), deep models typically overfit or default to the majority class. By first training on a large emotion dataset (GoEmotions, 58k samples), the model learns robust linguistic representations. When fine-tuned on the small cyberbullying set, these representations act as a prior, constraining the parameter space to sensible solutions.

## Foundational Learning

- **Concept: Domain Adaptation (Transfer Learning)**
  - Why needed: The core innovation (EAT) is a domain adaptation technique. Understanding how to bridge the "domain shift" between general emotion text and specific cyberbullying text is required to implement the framework.
  - Quick check: Can you explain why training on one distribution (emotion) might help classify a different distribution (bullying), and when it would fail?

- **Concept: Multi-class Imbalance**
  - Why needed: The paper specifically targets the failure of models on the minority class "Defamation" (8% of data). Standard accuracy metrics are useless here; one must understand Macro F1 and how standard transformers collapse on minority classes without intervention.
  - Quick check: If a model achieves 90% accuracy by predicting only the majority class (Non-bullying), why is Macro F1 the necessary metric to report for this specific paper's claims?

- **Concept: Indirect Cyberbullying (Defamation)**
  - Why needed: Unlike harassment (explicit insults), defamation involves "half-truths or lies." Standard toxic speech detectors (which look for profanity) fail here. Understanding this distinction is crucial for designing the "Concept Shift" label mapping.
  - Quick check: Why does the paper map "Surprise" to "Defamation" instead of "Anger"? What does this imply about the linguistic nature of rumors vs. insults?

## Architecture Onboarding

- **Component map:** GoEmotions (58k samples, 27 emotions) -> Domain Concept Shift (emotion→bullying label mapping) -> RoBERTa/Llama backbone -> Fine-tuning on HDCyberbullying dataset

- **Critical path:** The **Label Mapping strategy** is the most brittle component. The paper notes that "Surprise" was chosen for defamation based on prior literature, but empirical likelihood analysis showed "Approval" might have been better. Incorrect mapping here directly breaks the concept shift mechanism.

- **Design tradeoffs:**
  - Zero-shot vs. Few-shot: Zero-shot (using only emotion data) is safer for privacy but performs worse on "Harassment" than Few-shot (which uses limited bullying data).
  - Dataset Selection: The authors chose GoEmotions for quality/size, but Reddit slang may not generalize to formal celebrity news/defamation.

- **Failure signatures:**
  - Confusion of Context: The model misclassifies "defensive statements" as harassment because they contain "Anger"
  - Positive Sentiment Trap: The model struggles to classify "Defamation" because it often expresses "Joy" or "Gratitude" (e.g., fake news about a celebrity "healing"), which maps to "Non-bullying" in the naive logic.

- **First 3 experiments:**
  1. Baseline Stability Check: Fine-tune RoBERTa on the raw HDCyberbullying dataset with only 10% data. Verify that Macro F1 for Defamation is ≈ 0 (confirming the problem exists).
  2. Emotion Mappings Validation: Train the EAT framework but swap the mapping logic (e.g., map 'Joy' to 'Harassment'). Compare performance to confirm the authors' specific mapping choices are optimal.
  3. Data Scaling Curve: Replicate Figure 9. Plot Macro F1 vs. Training Data Size (72 to 1300 samples) with and without EAT to visualize exactly where the "transfer benefit" diminishes.

## Open Questions the Paper Calls Out

### Open Question 1
What are the most effective emotion indicators for detecting indirect cyberbullying forms like defamation, given that they may manifest as positive emotions (e.g., joy) rather than the expected negative ones? The Error Analysis notes the model classified 70% of defamation as "joy or gratitude," concluding that "more nuanced emotional indicators need to be explored."

### Open Question 2
Can the Emotion-Adaptive Training (EAT) framework be generalized to detect complex cyberbullying forms beyond harassment and defamation, such as outing or frapping? The Limitations section states that the lack of datasets limits the detection of "various forms of cyberbullying... such as outings and frapping, which are more complicated forms."

### Open Question 3
What methodologies can optimize the selection of source domain data to improve the efficiency of transferring knowledge to the cyberbullying target domain? The Limitations section explicitly states that "the selection of more effective source domain data... requires further research."

## Limitations
- EAT's effectiveness critically depends on the assumption that emotional expressions and cyberbullying behaviors occupy geometrically similar feature spaces, which may not generalize beyond celebrity contexts
- The framework's performance gains are demonstrated primarily on celebrity-focused cyberbullying data, which may have distinct characteristics compared to general cyberbullying
- The label mapping strategy appears somewhat arbitrary and may be context-dependent rather than universal

## Confidence

- **High Confidence:** The baseline problem of transformer models failing on minority classes (particularly defamation at 8% prevalence) is well-established and reproducible. The improvement in macro F1 scores when using EAT is empirically demonstrated across nine different transformer architectures.

- **Medium Confidence:** The domain adaptation mechanism works as described for the specific celebrity cyberbullying context tested. The geometric similarity assumption and concept shift mapping show promise but require validation across different domains and languages.

- **Low Confidence:** The generalizability of EAT to non-celebrity contexts, different languages, or other forms of indirect cyberbullying beyond defamation. The optimal emotion-to-bullying label mappings may be context-dependent rather than universal.

## Next Checks

1. **Cross-Domain Transfer Test:** Apply EAT trained on celebrity cyberbullying data to a non-celebrity cyberbullying dataset (e.g., general social media bullying). Measure performance degradation and identify which components (geometry assumption, label mapping, or regularization) break first.

2. **Mapping Sensitivity Analysis:** Systematically test all possible emotion-to-bullying label mappings (27 emotions × 3 classes) rather than the authors' selected mapping. Quantify the variance in performance to determine if the current mapping is truly optimal or just one of many viable options.

3. **Negative Transfer Investigation:** Deliberately introduce noise or bias into the source emotion dataset (e.g., mislabeling common emotions) and measure whether EAT's performance falls below the baseline non-transfer approach. This would validate whether the framework includes sufficient safeguards against harmful transfer.