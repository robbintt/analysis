---
ver: rpa2
title: 'When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing
  the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity'
arxiv_id: '2502.21022'
source_url: https://arxiv.org/abs/2502.21022
tags:
- domain
- anomaly
- source
- target
- normal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces the first fully unsupervised domain adaptation
  (UDA) framework for unsupervised anomaly detection (UAD), addressing the two-fold
  unsupervised curse arising from simultaneously tackling UDA and UAD without labels.
  The core idea leverages anomaly scarcity: anomalies are rare, so a dominant cluster
  in the target domain can be assumed to consist mostly of normal samples.'
---

# When Unsupervised Domain Adaptation meets One-class Anomaly Detection: Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity

## Quick Facts
- arXiv ID: 2502.21022
- Source URL: https://arxiv.org/abs/2502.21022
- Reference count: 40
- This work introduces the first fully unsupervised domain adaptation framework for unsupervised anomaly detection, addressing the two-fold unsupervised curse arising from simultaneously tackling UDA and UAD without labels.

## Executive Summary
This paper addresses the challenge of unsupervised domain adaptation for unsupervised anomaly detection by introducing a novel framework that leverages anomaly scarcity. The method clusters target features using a frozen CLIP visual encoder to identify a dominant cluster assumed to consist mostly of normal samples, then aligns this cluster with normal source features using contrastive learning while enforcing compactness via DSVDD. The approach achieves state-of-the-art performance on four UDA benchmarks, demonstrating that the two-fold unsupervised curse can be effectively mitigated by exploiting the inherent rarity of anomalies in target domains.

## Method Summary
The proposed method tackles unsupervised domain adaptation for anomaly detection by first extracting features from unlabeled target images using a frozen CLIP visual encoder, then clustering these features to identify a dominant cluster presumed to contain mostly normal samples. Source normal features are compressed into a hypersphere using DSVDD, while a contrastive loss aligns the identified target normal cluster with source normal features. This selective alignment avoids contamination from target anomalies while reducing domain shift. The trainable feature extractor is trained on both objectives simultaneously, with inference based on distance to the source normal hypersphere center.

## Key Results
- Achieves average AUC improvements of over 10% on several datasets compared to few-shot methods
- Outperforms both few-shot and zero-shot baselines across four UDA benchmarks (Office-Home, Office31, VisDA, PACS)
- Demonstrates robustness to anomaly ratios up to 50%, with performance degrading beyond this threshold
- Contrastive alignment strategy outperforms MMD and GRL alternatives across all benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Dominant Cluster Identification via Anomaly Scarcity
If anomalies are rare in the target domain, clustering target features identifies a dominant cluster that is predominantly normal. A frozen CLIP visual encoder extracts rich semantic features from unlabeled target images. K-means clustering partitions these features, and the largest cluster is selected as the proxy for normal target samples. This circumvents the need for target labels. The core assumption is that anomalies constitute a small minority in the unlabeled target set. If this fails, the dominant cluster will contain significant anomalies. Performance collapses when target anomaly ratio exceeds 50%.

### Mechanism 2: Source Compactness via DSVDD Hypersphere
Compressing source normal features into a hypersphere creates a reference decision boundary for anomaly detection. The Deep Support Vector Data Description (DSVDD) loss minimizes the distance between source normal features and their mean, effectively learning a compact representation. At inference, samples far from this center are flagged as anomalous. The core assumption is that normal source data is clean and sufficiently representative. The approach also works with alternative losses like MSC, suggesting the mechanism generalizes beyond DSVDD.

### Mechanism 3: Contrastive Alignment of Identified Normal Samples
Aligning source normal features with the identified target normal cluster reduces domain shift while avoiding contamination from target anomalies. A contrastive loss pulls source normal samples and the selected target dominant cluster samples together in the trainable feature space, while pushing apart non-selected target samples. This selectively aligns distributions without contaminating the source normal representation. The alignment strategy outperforms MMD and GRL alternatives but requires more memory for negatives.

## Foundational Learning

- **Concept: One-Class Classification / DSVDD**
  - Why needed here: The source domain provides only normal samples; the model must learn what "normal" looks like without counterexamples.
  - Quick check question: Can you explain why DSVDD uses a hypersphere rather than a hyperplane decision boundary?

- **Concept: Unsupervised Domain Adaptation (UDA)**
  - Why needed here: The core problem is bridging source and target domains without target labels; standard supervised adaptation is impossible.
  - Quick check question: What goes wrong if you naively align all source and target features when target contains anomalies?

- **Concept: Contrastive Learning for Domain Alignment**
  - Why needed here: The alignment mechanism uses InfoNCE-style contrastive loss to selectively pull matched distributions together.
  - Quick check question: In Eq 8, which samples serve as negatives in the contrastive objective, and why?

## Architecture Onboarding

- **Component map:**
  - f (trainable ResNet50) -> feature extractor trained on both domains; used at inference
  - ψ (frozen CLIP-ViT-B32) -> visual encoder for target clustering; discarded at inference
  - K-means -> identifies dominant cluster in ψ(D_t)
  - DSVDD head -> computes hypersphere center μ_{s,n} and enforces source compactness
  - Contrastive alignment -> aligns f(source normal) with f(selected target samples)

- **Critical path:**
  1. Extract target features via CLIP → cluster → select dominant cluster indices
  2. Train f on source with DSVDD loss (compactness)
  3. Simultaneously align f(source normal) with f(target dominant cluster) via contrastive loss
  4. At inference: compute distance to μ_{s,n} in f-space; threshold for anomaly

- **Design tradeoffs:**
  - CLIP vs. trainable f for clustering: CLIP provides richer semantic features for identifying normals but is frozen; f is task-adapted but may not separate normals well early in training
  - K (cluster count): Higher K (8-10) works better; too few clusters conflates normal modes
  - Alignment strategy: Contrastive outperforms MMD and GRL but requires more memory for negatives

- **Failure signatures:**
  - Performance collapses when target anomaly ratio >50%
  - AUC degradation suggests clustering accuracy has dropped—dominant cluster no longer normal-majority
  - If source-only baseline already fails badly, DSVDD may be underfitting or source data is problematic

- **First 3 experiments:**
  1. Run source-only DSVDD on target domain (no adaptation) to establish lower bound; verify implementation matches paper's ~62-78% baseline AUC
  2. Test with K-means K∈{2,5,10} and compare against no-clustering baseline; verify ~5-7% gain from clustering
  3. Replicate Figure 4—vary target anomaly ratio from 10% to 70% and plot both AUC and clustering accuracy; confirms mechanism 1's break point

## Open Questions the Paper Calls Out

### Open Question 1
How can an optimal feature extractor be learned or selected to reliably verify the "dominant cluster existence" hypothesis across diverse domain shifts? The current approach relies on a frozen CLIP encoder and a standard ResNet, but the paper does not establish a theoretical or empirical method for determining the optimal feature space for this specific clustering task.

### Open Question 2
Can the proposed unsupervised alignment framework be effectively extended to fine-grained anomaly detection using local features? The current contrastive alignment and clustering operate on global image features, which may fail to localize defects or handle fine-grained industrial inspection tasks.

### Open Question 3
How can the method be made robust to scenarios where the "anomaly scarcity" assumption is violated (e.g., heavily contaminated target datasets)? Figure 4 and Section 6.3 show a "drastic drop" in performance when the anomaly ratio exceeds 50%, indicating the "dominant cluster" logic fails when anomalies are not scarce.

## Limitations
- The dominant cluster assumption is the method's critical vulnerability, with performance collapse beyond 50% anomaly ratio
- The contrastive alignment mechanism's computational complexity (denominator over entire target set) is not fully specified in implementation
- The method's reliance on CLIP's semantic feature quality means poor feature extraction directly undermines cluster purity and subsequent adaptation performance

## Confidence
- **High confidence:** The DSVDD-based source compactness mechanism and its integration with contrastive learning for domain alignment are well-established components with strong empirical support
- **Medium confidence:** The anomaly scarcity assumption and dominant cluster identification are theoretically sound but may not generalize beyond controlled settings with fixed anomaly ratios
- **Medium confidence:** State-of-the-art claims are supported by comprehensive benchmark comparisons, though ablation studies could be more extensive

## Next Checks
1. Vary anomaly ratio systematically across all four benchmarks with ratios from 10% to 70% in 10% increments to establish dataset-specific break points
2. Test clustering robustness by replacing CLIP with alternative frozen feature extractors (ImageNet-pretrained ResNet, MoCo features) and evaluate clustering accuracy and final AUC
3. Analyze computational overhead by profiling training time and memory usage comparing contrastive alignment versus MMD/GRL baselines to quantify practical scalability limits