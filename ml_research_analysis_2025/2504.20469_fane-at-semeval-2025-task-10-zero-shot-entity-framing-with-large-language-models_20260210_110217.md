---
ver: rpa2
title: 'Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language
  Models'
arxiv_id: '2504.20469'
source_url: https://arxiv.org/abs/2504.20469
tags:
- role
- framing
- prompt
- roles
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates zero-shot entity framing classification using
  large language models (LLMs). The authors propose a two-stage approach: first predicting
  broad narrative roles (Protagonist, Antagonist, Innocent), then refining into fine-grained
  roles.'
---

# Fane at SemEval-2025 Task 10: Zero-Shot Entity Framing with Large Language Models

## Quick Facts
- arXiv ID: 2504.20469
- Source URL: https://arxiv.org/abs/2504.20469
- Reference count: 10
- The authors achieve 89.4% accuracy on main role classification and 34.5% exact match ratio for fine-grained roles using a multi-step zero-shot LLM approach

## Executive Summary
This paper presents a systematic evaluation of zero-shot entity framing classification using large language models (LLMs) for the SemEval-2025 Task 10. The authors propose a two-stage approach that first predicts broad narrative roles (Protagonist, Antagonist, Innocent) before refining into fine-grained roles. They evaluate different input contexts (full text, entity sentences, framing-preserved summaries) and prompt strategies (expert personas, task definitions, rationales). The multi-step approach significantly outperforms single-step prediction, with entity-sentences context and expert persona yielding the best results for fine-grained classification.

## Method Summary
The authors employ a two-stage prediction framework for entity framing classification. First, they predict main roles (Protagonist, Antagonist, Innocent) using various prompt strategies including expert personas (journalist, political analyst, communications expert), task definitions, and Chain-of-Thought reasoning. Second, they refine these predictions into fine-grained roles using the same prompt variations. The study evaluates three input contexts: full news articles, entity-specific sentences, and framing-preserved summaries that maintain the original article's narrative structure. The methodology focuses exclusively on zero-shot performance without any fine-tuning or training data utilization.

## Key Results
- Multi-step prediction approach significantly outperforms single-step prediction for both main and fine-grained role classification
- Entity-Sentences context achieves highest performance for fine-grained roles (34.5% exact match ratio)
- Expert persona prompts with Chain-of-Thought reasoning yield best overall performance
- Framing-preserved summaries excel for main roles while entity-specific contexts are superior for fine-grained roles
- Overall accuracy of 89.4% on main roles and 34.5% exact match ratio for fine-grained roles

## Why This Works (Mechanism)
The multi-step approach works by first establishing a high-level narrative framework through main role classification, then progressively refining this framework into more specific character roles. This hierarchical prediction mirrors human narrative understanding, where broad story elements are identified before detailed character analysis. The entity-sentences context outperforms full-text by reducing noise and focusing the model's attention on relevant information, while expert personas provide contextual knowledge that guides more accurate role assignment. Chain-of-Thought reasoning enables the model to show its reasoning process, leading to more coherent and justified predictions.

## Foundational Learning
- Entity framing in narrative analysis: why needed - to understand how news narratives position individuals within stories; quick check - identify Protagonist, Antagonist, and Innocent roles in sample news articles
- Zero-shot learning with LLMs: why needed - to evaluate model capabilities without task-specific training; quick check - test LLM on new classification tasks without parameter updates
- Prompt engineering strategies: why needed - to optimize LLM performance for specific tasks; quick check - compare different prompt formats on benchmark tasks
- Narrative role classification: why needed - to quantify how entities are portrayed in news narratives; quick check - annotate sample articles with character roles
- Context selection in NLP: why needed - to balance information richness with computational efficiency; quick check - compare model performance on full vs. truncated text inputs

## Architecture Onboarding
Component map: News Article -> Context Extractor -> LLM with Expert Persona -> Main Role Prediction -> LLM with Chain-of-Thought -> Fine-grained Role Prediction
Critical path: The most time-consuming component is the LLM inference, particularly for the multi-step prediction approach which requires two separate inference calls per entity
Design tradeoffs: Zero-shot approach prioritizes flexibility and generalizability over potentially higher performance from fine-tuned models; entity-sentences context trades comprehensiveness for focus and efficiency
Failure signatures: Performance degradation when framing is absent from texts (41.5% of cases), and confusion between similar fine-grained roles requiring nuanced understanding
First experiments:
1. Compare single-step vs. multi-step prediction on a small validation set
2. Test all three context types (full-text, entity-sentences, summaries) on main role classification
3. Evaluate different prompt strategies (expert personas vs. task definitions) for initial predictions

## Open Questions the Paper Calls Out
None specified in the provided content

## Limitations
- Findings are based on a single task dataset, limiting generalizability to other framing or narrative classification tasks
- Zero-shot performance may not reflect the potential of fine-tuning or parameter-efficient adaptation methods
- Limited comparison with other systems, as most competing approaches also use zero-shot LLM predictions
- Computational costs and inference time are not reported, important for practical deployment considerations
- Framing definitions may not be consistently applicable across all news articles, as 41.5% lack any framing

## Confidence
- High confidence in multi-step prediction approach improving accuracy over single-step prediction
- High confidence in entity-sentences context outperforming full-text and summary contexts for fine-grained roles
- Medium confidence in expert personas as optimal prompt strategy, given limited comparative analysis
- Medium confidence in framing-preserved summaries superiority for main roles, as this may be task-specific
- Low confidence in generalizability of these specific findings to other entity framing tasks

## Next Checks
1. Replicate experiments on a different entity framing dataset or general news corpus to assess generalizability
2. Compare zero-shot LLM performance with few-shot prompting or parameter-efficient fine-tuning approaches
3. Conduct ablation studies to determine which specific prompt components contribute most to performance improvements