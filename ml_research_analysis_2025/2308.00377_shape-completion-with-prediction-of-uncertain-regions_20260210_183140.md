---
ver: rpa2
title: Shape Completion with Prediction of Uncertain Regions
arxiv_id: '2308.00377'
source_url: https://arxiv.org/abs/2308.00377
tags:
- uncertain
- object
- shape
- uncertainty
- regions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses shape completion from partial 3D observations,
  focusing on predicting uncertain regions caused by pose ambiguity in partially symmetric
  objects like mugs with handles. The authors propose two novel methods to extend
  any spatial occupancy predictor: a postprocessing method using gradient criteria
  on occupancy scores, and a direct trinary classification method predicting occupied,
  free, and uncertain classes.'
---

# Shape Completion with Prediction of Uncertain Regions

## Quick Facts
- arXiv ID: 2308.00377
- Source URL: https://arxiv.org/abs/2308.00377
- Reference count: 40
- Primary result: Trinary method achieves 49.53% F1 score on uncertain region prediction for novel views of mugs

## Executive Summary
This paper addresses shape completion from partial 3D observations, focusing on predicting uncertain regions caused by pose ambiguity in partially symmetric objects like mugs with handles. The authors propose two novel methods to extend any spatial occupancy predictor: a postprocessing method using gradient criteria on occupancy scores, and a direct trinary classification method predicting occupied, free, and uncertain classes. They evaluate these methods alongside two baseline approaches (Monte Carlo Dropout and Variational Autoencoder) on synthetic and real data from the ShapeNet and BOP Challenge datasets. The trinary method outperforms others in uncertain region segmentation (achieving 49.53% F1 score on novel views and 35.51% on novel instances), while both novel methods improve grasp quality metrics by 15-25% when considering predicted uncertainty. The work demonstrates that accurate uncertain region prediction enhances robotic grasping safety by avoiding potential collisions with occluded object parts.

## Method Summary
The paper extends spatial occupancy prediction to explicitly model uncertain regions arising from pose ambiguity. Two methods are proposed: (1) a binary occupancy network with post-processing using gradient magnitude thresholds to separate extended uncertain regions from surface boundaries, and (2) a direct trinary classification approach that predicts occupied, free, and uncertain classes simultaneously. Both methods are trained on synthetic data generated from ShapeNet mugs with augmentation including noise injection and point removal. Ground-truth uncertain regions are created by randomly transforming objects and comparing 2D projections to identify ambiguous views. The methods are evaluated against Monte Carlo Dropout and VAE baselines on both synthetic and real datasets (BOP Challenge), with performance measured through IoU, F1-score for region segmentation, and grasp quality metrics.

## Key Results
- Trinary method achieves 49.53% F1 score on uncertain region prediction for novel views (vs. 31.76% for binary+gradient, 19.38% for dropout, 18.72% for VAE)
- Both novel methods improve grasp quality metrics by 15-25% when considering predicted uncertainty
- Gradient-based method requires threshold tuning but avoids costly ground-truth uncertainty annotations
- Sim2real gap observed due to real sensor artifacts missing thin structures like handles

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Based Uncertainty Segregation from Surface Boundaries
Post-processing occupancy predictions via gradient magnitude can separate extended uncertain regions from narrow surface boundaries. The method computes |∇p ŷ| at each query point, where ŷ is the predicted occupancy probability. Near the object surface (decision boundary), gradients are large; in extended uncertain regions farther from the surface, gradients are small. An upper threshold on gradient magnitude filters out surface-adjacent regions, leaving only spatially extended uncertain zones.

### Mechanism 2: Direct Trinary Classification Bypasses Post-Hoc Threshold Sensitivity
Explicitly predicting uncertainty as a third class outperforms post-processing binary occupancy scores for uncertain region segmentation. The network learns to map ambiguous observations directly to uncertain labels via supervised training on ground-truth uncertain region annotations.

### Mechanism 3: Uncertainty-Aware Grasp Filtering Reduces Collision Risk
Excluding predicted uncertain regions from grasp planning improves grasp quality by avoiding potential collisions with occluded object parts. Given shape completion and uncertain region predictions, grasp candidates intersecting uncertain regions are filtered out before execution.

## Foundational Learning

- **Concept: Implicit Function Representation for 3D Shapes**
  - Why needed here: The architecture represents shapes as occupancy probabilities at continuous 3D query points rather than explicit meshes. Understanding that the surface is the 0.5 isosurface extracted via Marching Cubes is essential for interpreting gradient-based uncertainty.
  - Quick check question: Given an occupancy network fθ(p, x) and point p, what does fθ(p, x) = 0.7 indicate about p's position relative to the object?

- **Concept: Pose Ambiguity from Partial Symmetry**
  - Why needed here: The core problem arises when objects (e.g., mugs) have rotational symmetry broken by asymmetric parts (handles). When the symmetry-breaking feature is occluded, multiple poses produce identical observations, creating irreducible uncertainty.
  - Quick check question: A cylindrical object with one distinguishing feature is viewed such that the feature is occluded. How many distinct poses could produce the same observation?

- **Concept: Epistemic vs. Aleatoric vs. Objective (Pose) Uncertainty**
  - Why needed here: The paper distinguishes its "objective uncertainty" from model-based epistemic uncertainty. This distinction matters because increasing model capacity or training data cannot reduce pose-induced uncertainty—it's inherent to the observation geometry.
  - Quick check question: Would Monte Carlo Dropout capture the uncertainty from a hidden mug handle? Why or why not?

## Architecture Onboarding

- **Component map:**
  1. Input encoder: PointNet-style encoder processes partial point cloud into latent features
  2. Implicit occupancy decoder: Convolutional Occupancy Network (ConvONet) backbone
  3. Output head (binary): Single scalar per query point → occupancy probability [0,1]
  4. Output head (trinary): Three-class classifier → free/occupied/uncertain
  5. Post-processing (binary+gradient): Compute |∇p ŷ|, threshold, cluster connected components, remove small artifacts
  6. Mesh extraction: Marching Cubes on occupancy grid at threshold τ
  7. Grasp filtering: Remove grasp candidates intersecting uncertain region

- **Critical path:**
  1. Render or capture depth image → project to point cloud with normals
  2. Apply augmentation (Algorithm 1): noise injection, point removal based on viewing angle
  3. Transform to robot world coordinates
  4. Encode point cloud → latent representation
  5. For each query point in 3D grid, predict occupancy (and uncertainty if trinary)
  6. Extract mesh and uncertain region mask
  7. Generate grasps on mesh, filter by uncertain region intersection

- **Design tradeoffs:**
  - Binary + gradient vs. Trinary: Gradient method requires no ground-truth uncertainty labels but needs threshold tuning and underperforms in segmentation accuracy. Trinary requires expensive annotation but achieves superior performance.
  - Resolution vs. memory: Higher voxel grid resolution improves detail but increases memory; implicit representation mitigates but doesn't eliminate this.
  - Coordinate frame: Training in camera coordinates improves generalization to novel shapes but reduces fidelity; robot world coordinates offer a middle ground by removing camera rotation effects.

- **Failure signatures:**
  - Sim2real gap: Real sensor artifacts (missing thin structures like handles due to reflectance/opacity) cause false uncertain regions on object backsides
  - Over-conservative filtering: If uncertain region precision is very low, all grasps may be rejected
  - Gradient threshold mis-calibration: If threshold is too low, uncertain regions include surface noise; if too high, genuine uncertain regions are missed

- **First 3 experiments:**
  1. Validate novel-view generalization: Train on 70% of mug instances, test on held-out views of same instances. Measure IoU/F1 for occupied and uncertain regions.
  2. Test gradient threshold sensitivity: Sweep τu and gradient threshold on validation set. Plot IoU vs. threshold to find optimal operating point.
  3. Grasp quality ablation: Generate grasps with and without uncertain region filtering. Compare IEQ, GCR, GMR, GER metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed uncertainty prediction methods generalize to other object categories beyond mugs?
- Basis in paper: "Future work will consider more object classes and grasping scenarios"
- Why unresolved: Experiments were limited to mugs, which have a specific type of partial symmetry. Other categories may exhibit different symmetry patterns and uncertainty distributions.
- What evidence would resolve it: Evaluation on diverse object categories from ShapeNet (e.g., bottles, bowls, cameras) showing uncertain region prediction performance and grasp quality improvements comparable to mug results.

### Open Question 2
- Question: What techniques can reduce the sim2real gap for uncertain region prediction?
- Basis in paper: "Future work will... further improve sim2real capabilities" and the observed large performance drop due to "effects on surface color, opacity, and reflectance on the depth data"
- Why unresolved: Real depth sensors produce artifacts (missing thin structures like handles) that current simulation does not capture, causing false uncertain region predictions on object backsides.
- What evidence would resolve it: Modified rendering pipeline or domain adaptation techniques achieving uncertain region prediction accuracy on real data closer to synthetic benchmark performance.

### Open Question 3
- Question: Can the gradient threshold for the binary method be automatically determined across varying uncertain region sizes?
- Basis in paper: "the approach with the gradient criterion... does require a proper adjustment of the gradient threshold, in the general setting covering all possible uncertain region sizes with their gradients"
- Why unresolved: Current implementation uses average gradient magnitude as threshold, but optimal threshold likely varies with object scale and uncertain region extent.
- What evidence would resolve it: Adaptive thresholding scheme evaluated across objects with varying handle sizes and positions, showing consistent uncertain region segmentation without manual tuning.

### Open Question 4
- Question: How does prediction accuracy of uncertain regions translate to improved outcomes in applications with specific grasp requirements?
- Basis in paper: "In applications with specific grasp requirements, e.g. regarding the approach direction or the object parts to be touched, the advantage of a more accurate prediction of uncertain regions is likely to make a significant difference."
- Why unresolved: Current grasp evaluation uses a large robot hand where moderate recall suffices; precision of uncertain regions had limited impact on the chosen grasp quality metric.
- What evidence would resolve it: Experiments with task-specific grasping constraints demonstrating that higher uncertain region precision directly enables more successful task completions.

## Limitations

- Ground-truth uncertainty annotation procedure is unspecified, making faithful reproduction difficult
- Sim2real domain gap due to real sensor artifacts missing thin structures like mug handles
- Threshold sensitivity for binary+gradient method requires per-application tuning

## Confidence

- Trinary method outperforms baselines in uncertain region segmentation: High confidence
- Both methods improve grasp quality by 15-25%: Medium confidence
- Uncertain regions from pose ambiguity cannot be reduced by model capacity: High confidence

## Next Checks

1. Gradient threshold sensitivity analysis: Sweep gradient magnitude threshold on validation set and plot IoU vs. threshold to identify optimal operating point and assess robustness to parameter choice.

2. Real data performance gap quantification: Compare performance on synthetic vs. real BOP Challenge datasets (LM, HB, YCB-V, TYOL) to measure sim2real transfer and identify failure modes from sensor limitations.

3. Annotation quality impact study: Train trinary models with varying numbers of random transformations and similarity thresholds for ground-truth generation to assess sensitivity to supervision quality.