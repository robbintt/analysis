---
ver: rpa2
title: 'Understanding the Geospatial Reasoning Capabilities of LLMs: A Trajectory
  Recovery Perspective'
arxiv_id: '2510.01639'
source_url: https://arxiv.org/abs/2510.01639
tags:
- road
- llms
- trajectory
- intersection
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates whether large language models (LLMs) can perform
  geospatial reasoning by reconstructing masked GPS trajectories from road network
  context. The authors introduce GLOBALTRACE, a dataset of over 4,000 real-world trajectories
  across diverse regions and transportation modes, and propose a two-stage prompting
  framework that enables LLMs to generate valid paths without external navigation
  tools.
---

# Understanding the Geospatial Reasoning Capabilities of LLMs: A Trajectory Recovery Perspective

## Quick Facts
- **arXiv ID:** 2510.01639
- **Source URL:** https://arxiv.org/abs/2510.01639
- **Reference count:** 40
- **Primary result:** State-of-the-art LLMs outperform specialized trajectory recovery models and approach Google Maps performance on masked trajectory reconstruction using a two-stage prompting framework.

## Executive Summary
This paper investigates whether large language models can perform geospatial reasoning by reconstructing masked GPS trajectories from road network context. The authors introduce GLOBALTRACE, a dataset of over 4,000 real-world trajectories across diverse regions and transportation modes, and propose a two-stage prompting framework that enables LLMs to generate valid paths without external navigation tools. Experiments show that LLMs achieve strong performance on trajectory recovery tasks, with PoT F1 scores exceeding specialized baselines and approaching commercial navigation systems. The study reveals that LLMs possess latent geospatial knowledge that structured prompting can unlock, demonstrating their potential to enhance navigation by incorporating user preferences and contextual information.

## Method Summary
The research employs a two-stage zero-shot prompting framework for masked trajectory reconstruction. Stage 1 elicits path planning reasoning over road network topology to generate step-by-step navigation plans using road and intersection IDs. Stage 2 grounds these plans against specific road geometries to generate GPS coordinates. The approach uses structured representations including topology-only road networks with directional cues and trajectory context summaries. The GLOBALTRACE dataset provides real-world trajectories across 8 regions and 6 transportation modes. Evaluation uses Point-on-Trajectory F1 (PoT F1) and Mean Absolute Error F1 (MAE F1) metrics, along with path connectivity and geometry adherence measures.

## Key Results
- LLMs achieve 58.7 PoT F1 on trajectory recovery, outperforming specialized models like TrajFM (54.1 PoT F1) and approaching Google Maps (61.1 PoT F1)
- Performance varies significantly by region (up to 40% variance) and activity type, with driving showing highest accuracy
- Zero-shot LLMs match fine-tuned specialized models, demonstrating strong generalization without task-specific training
- Large gap reconstruction remains challenging, with 70% higher MAE compared to small gaps

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Decomposed Reasoning
Decomposing trajectory recovery into path planning and coordinate generation enables LLMs to handle spatial reasoning that would fail in end-to-end prompting. Stage 1 elicits high-level reasoning to select connected road segments; Stage 2 grounds this plan against road geometries to generate coordinates. This separation prevents the model from being overwhelmed by unstructured data and allows explicit verification at each stage.

### Mechanism 2: Compact Topological Representation with Directional Cues
Providing topology-only road networks with pre-computed bearings achieves optimal performance while minimizing token overhead. Removing full geometry reduces information overload; adding directional cues (bearing to destination) guides path selection without constraining it. The model receives essential connectivity plus "sense of direction" rather than overwhelming coordinate lists.

### Mechanism 3: Contextual Movement Pattern Injection
Providing movement summaries (speed, heading, behavior) before/after masked segments improves reconstruction accuracy. Activity type, speed, and direction narratives constrain the solution space, helping models select routes consistent with real-world mobility patterns rather than just geometric feasibility.

## Foundational Learning

- **Concept:** Road network topology representation (graph structure, connectivity, intersection nodes)
  - **Why needed here:** The framework requires encoding road networks as structured graphs with explicit connection information; without understanding adjacency representation, you cannot construct the topology-only input format.
  - **Quick check question:** Given a road network with roads A, B, C where A connects to B at intersection I1, and B connects to C at intersection I2, what is the minimal representation needed for path finding?

- **Concept:** GPS coordinate systems and Haversine distance
  - **Why needed here:** The evaluation metrics (MAE, PoT) use Haversine distance to measure deviation; understanding lat/lon limitations is essential for interpreting results correctly.
  - **Quick check question:** Why is Euclidean distance inappropriate for measuring GPS trajectory errors, and what distance metric should be used instead?

- **Concept:** Bearing/heading calculations
  - **Why needed here:** Stage 2 coordinate generation requires models to follow directional cues; understanding how bearings map to cardinal directions is necessary for validation and error analysis.
  - **Quick check question:** A step says "travel southeast" but generated coordinates show bearing of 70°. What is the angular error, and is this acceptable (<90°)?

## Architecture Onboarding

- **Component map:** Data pipeline -> Road network retrieval -> Stage 1 prompt builder -> Stage 2 prompt builder -> Evaluation suite
- **Critical path:** Road network representation format determines token efficiency and model performance. Start with "Topology-only + Direction" variant as baseline; only add geometry if specific failure modes require it.
- **Design tradeoffs:**
  - Raw network vs. topology-only: Raw provides complete information but overwhelms models (25k+ tokens vs. ~10k)
  - Single-stage vs. two-stage: Single-stage simpler but fails to elicit reasoning (39.9 vs 58.7 PoT F1)
  - Symmetric vs. asymmetric metrics: PoT F1 penalizes both missed coverage and spurious detours; directional analysis reveals recall/precision tradeoffs
- **Failure signatures:**
  - Low connectivity (<60%): Model hallucinates disconnected road segments; tighten schema constraints or add explicit connectivity examples
  - High bearing error (>60°): Coordinate generation ignoring directional cues; verify geometry format or add more in-context examples
  - Regional performance variance >40%: Geographic bias from training data; consider region-specific prompting or data augmentation
- **First 3 experiments:**
  1. Baseline validation: Run GPT-4.1 on small-gap test set with topology-only + direction representation; confirm PoT F1 ≥60% and connectivity ≥70%. If below threshold, debug prompt format.
  2. Context ablation: Remove movement context summaries (speed, heading narratives) and measure performance drop. Expect 5-15% degradation based on activity type complexity.
  3. Representation comparison: Test adjacency-list vs. topology-only formats on 50 development samples. If adjacency-list improves >5% on complex intersections, prioritize readability over token minimality.

## Open Questions the Paper Calls Out
None

## Limitations
- The GLOBALTRACE dataset covers only 8 regions and may not represent full global road network complexity
- Performance drops significantly on large gaps and regions with complex topologies, suggesting current methods struggle with long-range reasoning
- Regional bias analysis reveals up to 40% performance variance, indicating potential training data skew rather than true geographic reasoning capability

## Confidence

**High Confidence:** LLMs can reconstruct short masked trajectory segments using structured road network context; zero-shot performance approaches specialized baselines.

**Medium Confidence:** The two-stage prompting framework is necessary for geospatial reasoning; representation choice (topology-only + direction) significantly impacts performance.

**Low Confidence:** Systematic regional biases reflect LLM training data limitations; contextual movement patterns substantially improve accuracy beyond road topology alone.

## Next Checks
1. Test the framework on synthetic trajectories with controlled gap lengths to isolate the effect of gap size from road network complexity on performance degradation.
2. Conduct cross-lingual evaluation using the same geographic regions but different language contexts to determine if performance variance is truly geographic or language-dependent.
3. Implement an ablation study on the directional cues component by systematically varying bearing error thresholds to quantify the trade-off between guidance precision and token overhead.