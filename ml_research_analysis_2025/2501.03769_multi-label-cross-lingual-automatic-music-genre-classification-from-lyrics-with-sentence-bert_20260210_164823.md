---
ver: rpa2
title: Multi-label Cross-lingual automatic music genre classification from lyrics
  with Sentence BERT
arxiv_id: '2501.03769'
source_url: https://arxiv.org/abs/2501.03769
tags:
- lyrics
- genre
- language
- music
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a cross-lingual multi-label music genre classification
  system that leverages multilingual sentence embeddings from Sentence-BERT (sBERT)
  to classify music genres across languages without requiring translation. The system
  uses a one-vs-all SVM architecture to handle multiple genre labels per lyric and
  is trained on a bilingual Portuguese-English dataset with eight overlapping genres.
---

# Multi-label Cross-lingual automatic music genre classification from lyrics with Sentence BERT

## Quick Facts
- arXiv ID: 2501.03769
- Source URL: https://arxiv.org/abs/2501.03769
- Reference count: 24
- This paper presents a cross-lingual multi-label music genre classification system that leverages multilingual sentence embeddings from Sentence-BERT (sBERT) to classify music genres across languages without requiring translation.

## Executive Summary
This paper presents a cross-lingual multi-label music genre classification system that leverages multilingual sentence embeddings from Sentence-BERT (sBERT) to classify music genres across languages without requiring translation. The system uses a one-vs-all SVM architecture to handle multiple genre labels per lyric and is trained on a bilingual Portuguese-English dataset with eight overlapping genres. The approach demonstrates that training on lyrics in one language and predicting genres in another significantly improves performance over baseline bag-of-words methods, increasing the genrewise average F1-score from 0.35 to 0.69. Dataset centralization is shown to notably improve cross-lingual performance by mitigating domain shifts caused by language differences. This scalable solution advances music information retrieval for underrepresented languages and cultural domains, offering practical applications in recommendation systems and playlist creation.

## Method Summary
The method employs multilingual sentence embeddings from sBERT (specifically paraphrase-multilingual-mpnet-base-v2) to represent song lyrics, followed by averaging these sentence-level embeddings to create a single song representation. A one-vs-all SVM architecture with linear kernels is used for multi-label classification, with hyperparameters tuned via 5-fold cross-validation. To address cross-lingual domain shifts, dataset centralization is applied by subtracting the mean embedding value from both training and test sets. The approach is evaluated on a bilingual Portuguese-English dataset scraped from Vagalume, using bootstrap resampling to ensure robust performance estimates.

## Key Results
- Training on lyrics in one language and predicting genres in another significantly improves performance over baseline bag-of-words methods, increasing the genrewise average F1-score from 0.35 to 0.69.
- Dataset centralization is shown to notably improve cross-lingual performance by mitigating domain shifts caused by language differences.
- The system demonstrates practical scalability for music information retrieval in underrepresented languages, advancing applications in recommendation systems and playlist creation.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual sentence embeddings enable cross-lingual genre transfer by mapping semantically similar content to proximate vector regions across languages.
- Mechanism: sBERT's PARAPHRASE-MULTILINGUAL-MPNET-BASE-V2 model was pre-trained on aligned multilingual corpora, learning to place translations and semantically equivalent sentences near each other in embedding space. This allows a classifier trained on Portuguese embeddings to generalize to English embeddings without explicit translation.
- Core assumption: Genre-relevant semantic features (themes, topics, stylistic markers) are preserved across languages in the embedding space and are sufficiently consistent for classification.
- Evidence anchors:
  - [abstract]: "training on lyrics in one language and predicting genres in another significantly improves performance over baseline"
  - [section] Section I: "multilingual sentence embeddings...specifically trained to map sentence translations in multiple languages to similar vectors without being linked to a translation downstream task"
  - [section] Table III: Training on EN and testing on PT yields F1=0.57 (vs. baseline 0.30); training on PT and testing on EN yields F1=0.68 (vs. baseline 0.44)
  - [corpus]: Music4All A+A (FMR=0.509) addresses multimodal music datasets but focuses on audio-lyrics fusion rather than cross-lingual transfer; limited direct corpus validation of this specific mechanism
- Break condition: If genre signals rely heavily on language-specific idioms, rhyming patterns, or cultural references that do not align in the multilingual embedding space.

### Mechanism 2
- Claim: Dataset centralization mitigates embedding domain shifts caused by language changes, improving cross-lingual classification performance.
- Mechanism: Different languages produce systematically shifted embedding distributions in sBERT. By subtracting the mean embedding value from each corpus (train and test sets), the systematic bias from language is reduced, aligning the distributions and improving classifier transfer.
- Core assumption: The domain shift between languages is primarily a first-order (mean shift) effect that can be corrected via centralization, rather than a higher-order distributional difference.
- Evidence anchors:
  - [abstract]: "Dataset centralization is shown to notably improve cross-lingual performance by mitigating domain shifts"
  - [section] Section II: "centralizing the train and test sets by subtracting their average values. Both variants (with and without centralization) were tested"
  - [section] Table IV vs. Table III: EN→PT cross-lingual F1 improves from 0.57 to 0.69; PT→EN improves from 0.68 to 0.69 with centralization
  - [corpus]: Weak direct corpus evidence; this centralization technique for cross-lingual embeddings is not prominently validated in neighboring papers
- Break condition: If genre-relevant semantic differences between languages are non-linear or cultural (not merely distributional shifts), centralization alone cannot bridge the gap.

### Mechanism 3
- Claim: One-vs-all SVM decomposition enables multi-label genre assignment by treating each genre as an independent binary classification problem.
- Mechanism: Rather than forcing mutual exclusivity, the system trains 8 independent SVM classifiers (one per genre). Each classifier outputs a binary decision, allowing songs to receive multiple genre labels (e.g., "Pop" AND "Rock").
- Core assumption: Genre labels are approximately independent; label correlations either do not exist or are not critical for performance.
- Evidence anchors:
  - [abstract]: "one-vs-all SVM architecture to handle multiple genre labels per lyric"
  - [section] Section I: "a song can be simultaneously labeled as 'Pop' and 'Rock'"
  - [section] Section III: "We trained a one-vs-all classifier for each different genre...ensuring there is the same number of 'positive' and 'negative' samples"
  - [corpus]: Neighbor paper "Comparison of spectrogram scaling in multi-label Music Genre Recognition" (FMR=0.513) also addresses multi-label MGR via audio spectrograms, suggesting multi-label is a recognized problem; no corpus contradiction of one-vs-all approach
- Break condition: If strong label correlations exist (e.g., "Hip Hop" and "Rap" co-occur frequently), a joint modeling approach could outperform independent classifiers.

## Foundational Learning

- Concept: **Sentence Embeddings vs. Bag-of-Words Representations**
  - Why needed here: The paper's core result depends on understanding why sBERT embeddings (F1=0.69) dramatically outperform TF-IDF bag-of-words (F1=0.35) for cross-lingual transfer. BoW is language-specific and relies on vocabulary overlap; sentence embeddings capture semantic meaning in a continuous space designed for cross-lingual alignment.
  - Quick check question: Given that Portuguese and English share few cognates for genre-relevant terms, why would averaging sentence embeddings transfer better than counting word occurrences?

- Concept: **One-vs-All (OvA) vs. Multi-class Classification**
  - Why needed here: Multi-label genre classification requires assigning zero or more labels per instance. Standard softmax multi-class outputs a single label; OvA allows multiple independent binary decisions.
  - Quick check question: If a song belongs to both "Pop" and "Rock," would a softmax classifier ever produce the correct output?

- Concept: **Domain Shift and Distribution Alignment**
  - Why needed here: Centralization is the paper's key intervention for improving cross-lingual performance. Understanding domain shift explains why embeddings from different languages may cluster differently even in a "shared" space, and why mean-centering helps.
  - Quick check question: If Portuguese song embeddings have mean vector μ_PT and English embeddings have μ_EN ≠ μ_PT, what happens when an SVM trained on centered PT data encounters uncentered EN data?

## Architecture Onboarding

- Component map:
  1. **Input**: Raw lyrics text (scraped, language-labeled)
  2. **Pre-processing**: Language detection (LANGDETECT), sentence tokenization (punctuation-based), filtering mislabeled lyrics
  3. **Embedding layer**: sBERT (PARAPHRASE-MULTILINGUAL-MPNET-BASE-V2), 128-token context window, produces 768-dim embeddings per sentence
  4. **Aggregation**: Average pooling of all sentence embeddings → single song embedding
  5. **Optional centralization**: Subtract corpus mean from embeddings (requires unlabeled target-language corpus)
  6. **Classification**: 8 independent linear SVMs (one per genre), C ∈ {0.01, 0.1, 1, 10} via 5-fold CV
  7. **Output**: Binary decisions per genre (multi-label)

- Critical path:
  Lyrics → Sentence tokenization → sBERT embedding (per sentence) → Average pooling → [Optional: subtract corpus mean] → 8× SVM classification → Genre label set

- Design tradeoffs:
  1. **Sentence averaging vs. full-song embedding**: sBERT's 128-token limit forces sentence decomposition; averaging may dilute long-range thematic coherence.
  2. **Centralization requirement**: Requires unlabeled corpus in target language—adds data dependency but improves cross-lingual F1 by ~0.02–0.12.
  3. **One-vs-all vs. structured multi-label**: Simpler implementation, but ignores label correlations (e.g., Pop/Rock co-occurrence).
  4. **Downsampling for balance**: Prevents majority-class bias but discards data—appropriate for evaluation but may underutilize available signal.

- Failure signatures:
  1. **Cross-lingual F1 near baseline (~0.35)**: Domain shift not mitigated → check centralization; verify sBERT model is multilingual variant.
  2. **Translated lyrics underperform original**: Translation artifacts (e.g., OpenNMT dropping expressions) → prefer original-language data.
  3. **Per-genre variance high**: Cultural genre differences (e.g., Brazilian Gospel vs. English Gospel themes) → may require language-specific fine-tuning.
  4. **SVM overfitting on small genres**: Check C hyperparameter; smaller C values regularize more.

- First 3 experiments:
  1. **Replicate baseline (BoW)**: Train on PT, test on EN using TF-IDF → expect F1 ≈ 0.44 ± 0.09 (Table II). Confirms baseline implementation.
  2. **sBERT without centralization**: Train on EN, test on PT → expect F1 ≈ 0.57 ± 0.03 (Table III). Validates embedding quality.
  3. **sBERT with centralization**: Same language pair, apply mean subtraction → expect F1 ≈ 0.69 ± 0.01 (Table IV). Confirms centralization gain.

## Open Questions the Paper Calls Out

- Can embeddings be specifically developed to be more discriminative towards music genres than current general-purpose multilingual sentence embeddings?
  - Basis in paper: [explicit] The conclusion states, "another contribution to this problem would be finding embeddings that are more discriminative towards music genres."
  - Why unresolved: The study utilized pre-trained general-purpose sBERT models (PARAPHRASE-MULTILINGUAL-MPNET), which may not capture nuanced stylistic differences between music genres as effectively as a specialized model.
  - What evidence would resolve it: Training and evaluating a custom embedding model on a music-specific corpus to compare its genre-separation capabilities against the general-purpose baseline.

- How can inherent cultural variations in genre definitions be effectively measured and decoupled from linguistic domain shifts in cross-lingual classification?
  - Basis in paper: [explicit] The conclusion notes that "cultural variations still represent an important challenge for this type of approach" and are "hard to measure."
  - Why unresolved: While dataset centralization mitigates embedding domain shifts, it does not account for cultural differences where identical genre labels (e.g., "Rock") may represent different stylistic traits across languages.
  - What evidence would resolve it: A comparative analysis combining quantitative centralization techniques with qualitative cultural analysis to isolate performance drops caused solely by cultural mismatches.

- How does the proposed method perform on languages lacking the large parallel corpora required for pre-training multilingual sBERT models?
  - Basis in paper: [inferred] The discussion acknowledges that multilingual embeddings rely on "pre-training systems over a large corpora of aligned texts, which could be unavailable for particular languages."
  - Why unresolved: The study focused on Portuguese and English, which are well-resourced; the scalability claims for "underrepresented languages" remain unproven for languages with scarce translation data.
  - What evidence would resolve it: Evaluating the cross-lingual transfer capabilities of the model using low-resource languages that lack extensive aligned text data for embedding pre-training.

## Limitations
- The paper demonstrates cross-lingual transfer on a specific bilingual Portuguese-English dataset with eight genres; generalization to other language pairs or genre taxonomies is untested.
- The centralization method assumes a first-order mean shift as the primary domain difference, but higher-order distributional shifts could limit improvement.
- One-vs-all SVMs ignore label correlations; while adequate for baseline, this may miss nuanced genre relationships.
- No comparison with state-of-the-art cross-lingual sentence embeddings (e.g., XLM-R) or alternative classification architectures is provided.

## Confidence
- High confidence: sBERT embeddings outperform bag-of-words for cross-lingual transfer (clear F1 improvement from 0.35 to 0.69).
- Medium confidence: Dataset centralization improves cross-lingual performance (limited ablation studies; effect size is modest).
- Medium confidence: One-vs-all SVM architecture is sufficient for multi-label genre classification (no comparison to structured multi-label models).

## Next Checks
1. Replicate the baseline TF-IDF vs. sBERT comparison on the bilingual dataset to confirm F1 gains.
2. Test centralization on additional language pairs or music corpora to assess generalizability.
3. Compare one-vs-all SVM results with a structured multi-label model (e.g., binary relevance with label correlations or classifier chains) to quantify the impact of ignoring label dependencies.