---
ver: rpa2
title: Feasibility of Structuring Stress Documentation Using an Ontology-Guided Large
  Language Model
arxiv_id: '2510.01244'
source_url: https://arxiv.org/abs/2510.01244
tags:
- stress
- ontology
- were
- information
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a mental stress ontology (MeSO) and evaluated
  its feasibility for structured stress documentation using an LLM. MeSO was created
  by integrating stress assessment tools and the Transactional Model of Stress, resulting
  in 181 concepts across eight top-level classes.
---

# Feasibility of Structuring Stress Documentation Using an Ontology-Guided Large Language Model

## Quick Facts
- arXiv ID: 2510.01244
- Source URL: https://arxiv.org/abs/2510.01244
- Reference count: 0
- LLM achieved 78.2% accuracy in extracting stress-related information from narrative text using ontology guidance

## Executive Summary
This study develops the Mental Stress Ontology (MeSO) by integrating 11 stress assessment questionnaires and the Transactional Model of Stress, creating 181 concepts across eight top-level classes. The ontology-guided approach is evaluated using Claude Sonnet 4 with zero-shot prompting to extract six categories of stress-related information from 35 Reddit posts. The system achieved 78.2% accuracy in correctly identifying extractable stress-related items, with all correctly extracted items accurately mapped to MeSO concepts. While 24 relevant concepts were not yet represented in the ontology, the results demonstrate that ontology-guided LLMs can support structured and consistent stress documentation in ambient AI systems.

## Method Summary
The study constructed MeSO by extracting concepts from 11 stress assessment questionnaires (266 questions total) using a two-reviewer process, then validating coverage with 58 stress-related texts. The ontology was structured around the Transactional Model of Stress and implemented in Protégé 5.6.1. For evaluation, 35 Reddit posts were processed using Claude Sonnet 4 with zero-shot prompting, where the LLM extracted six categories of stress information (stressor, stress response, coping strategy, duration, onset, temporal profile) and mapped them to MeSO concepts. Two independent human reviewers evaluated all extractions, with a third reviewer resolving disagreements, achieving a weighted kappa of 0.899 for inter-rater reliability.

## Key Results
- 78.2% accuracy in correctly identifying extractable stress-related items (172/220 items)
- 12.3% misclassification rate and 9.5% miss rate in extraction performance
- All correctly extracted items were accurately mapped to MeSO concepts, though 24 relevant concepts were not yet represented in the ontology

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ontology guidance constrains LLM output space, improving mapping consistency to structured concepts.
- Mechanism: MeSO provides 181 concepts across 8 top-level classes that the LLM uses as extraction targets, reducing ambiguity in classification.
- Core assumption: The ontology's concept coverage is sufficiently comprehensive for the target domain.
- Evidence anchors:
  - [abstract] "All correctly extracted items were accurately mapped to MeSO, although 24 relevant concepts were not yet represented in the ontology."
  - [section] Page 9, Table 3: Performance varies by category—Stressor 81.25% correct, Stress Coping Strategy 60% correct.
  - [corpus] Related work (Ontology-Guided Multi-Agent Reasoning, arXiv 2601.21700) shows ontology guidance improves alignment in LLM outputs.
- Break condition: If ontology coverage gaps exceed ~15–20% of extracted concepts, mapping failures accumulate.

### Mechanism 2
- Claim: Zero-shot prompting with ontology definitions enables extraction without task-specific fine-tuning.
- Mechanism: Claude Sonnet 4 received MeSO structure and definitions via prompt, extracting six information categories from narrative text without fine-tuning.
- Core assumption: The LLM's pre-trained knowledge sufficiently overlaps with stress-domain semantics.
- Evidence anchors:
  - [abstract] "Using MeSO, six categories of stress-related information...were extracted from 35 Reddit posts using Claude Sonnet 4."
  - [section] Page 9: "Zero-shot prompting was employed." Table 3 shows 172/220 items correctly extracted (78.2%).
  - [corpus] Corpus evidence on zero-shot ontology-guided extraction is limited; the TextMineX paper (arXiv 2509.15098) uses ontology-guided LLM pipelines but with different task structures.
- Break condition: Performance drops for categories requiring nuanced contextual inference.

### Mechanism 3
- Claim: Hierarchical concept organization supports downstream interoperability but does not eliminate misclassification.
- Mechanism: MeSO's eight top-level classes provide parent concepts for extracted items, enabling standardized representation.
- Core assumption: Hierarchical structure translates to improved downstream clinical utility—this is claimed but not empirically tested.
- Evidence anchors:
  - [abstract] "...offering potential to enhance the consistency and utility of stress documentation in ambient AI systems."
  - [section] Page 12: "Claude Sonnet 4 interpreted expressions of self-harm ideation as indicative of depression rather than frustration."
  - [corpus] Ontology Learning and Knowledge Graph Construction (arXiv 2511.05991) suggests knowledge graph structure impacts RAG performance.
- Break condition: Misclassification rates above ~15% in high-stakes categories may limit clinical applicability.

## Foundational Learning

- Concept: **Ontology classes vs. instances**
  - Why needed here: MeSO defines 181 concepts (classes) organized hierarchically; extracted text items are mapped to these classes.
  - Quick check question: If an extracted phrase "political difference" has no corresponding class in MeSO, is this a coverage gap or an instance-level issue?

- Concept: **Zero-shot prompting**
  - Why needed here: The extraction pipeline uses no fine-tuning; the LLM relies solely on prompt-provided ontology definitions.
  - Quick check question: What happens if the ontology definition in the prompt is ambiguous for a class like "Stress Onset"?

- Concept: **Inter-rater reliability (weighted kappa)**
  - Why needed here: Human reviewers achieved 0.899 kappa, establishing ground-truth quality for LLM evaluation.
  - Quick check question: If kappa were 0.60 instead of 0.899, how would you interpret the 78.2% LLM accuracy?

## Architecture Onboarding

- Component map:
  - MeSO Ontology -> LLM Extractor (Claude Sonnet 4) -> Mapping Layer -> Human Review Interface

- Critical path:
  1. Define ontology scope (stressors, responses, coping, temporal attributes)
  2. Load ontology into prompt with category definitions
  3. Submit narrative text (currently Reddit posts; future: clinical dialogue transcripts)
  4. LLM extracts and maps to MeSO concepts
  5. Human review validates extractions; unmapped concepts feed back to ontology refinement

- Design tradeoffs:
  - Breadth vs. depth: MeSO covers 8 top-level classes but 24 relevant concepts were missing
  - Prompt specificity vs. scalability: Overly detailed prompts reduce errors but compromise scalability
  - Single-LLM vs. multi-LLM evaluation: Only Claude Sonnet 4 was tested

- Failure signatures:
  - Hallucination: 3 cases where extracted information had no textual basis
  - Overinterpretation: Misclassifying self-harm ideation as depression, or venting as help-seeking
  - Contextual inference failure: Missing illness as stressor (6/9 missed stressor cases)

- First 3 experiments:
  1. **Ontology coverage stress test**: Extract from a held-out corpus (e.g., clinical dialogue transcripts) and measure unmapped concept rate; target <10% for feasibility.
  2. **Multi-LLM comparison**: Run the same 35 posts through GPT-4o and Qwen with identical prompts; compare accuracy, misclassification, and hallucination rates.
  3. **Prompt sensitivity analysis**: Systematically vary prompt specificity for the lowest-performing category (Stress Coping Strategy, 60% correct); measure error reduction vs. prompt length tradeoff.

## Open Questions the Paper Calls Out

- Does the MeSO-guided LLM approach maintain performance when applied to real-world clinical dialogue rather than written social media posts? [explicit] The Conclusion states, "Future research should... incorporate real clinical dialogue."

- How does Claude Sonnet 4 compare to other commercial and on-premises LLMs in terms of extraction accuracy and data privacy? [explicit] The Conclusion calls for "systematic comparisons across multiple models including on-premises LLMs, especially given the privacy concerns."

- Can the Mental Stress Ontology (MeSO) be expanded to adequately cover the specific and vague stress concepts currently missing from its hierarchy? [explicit] The Discussion notes "24 relevant concepts were not yet represented" and states they "will be reviewed for possible inclusion."

## Limitations

- Ontology Coverage Gaps: While MeSO contains 181 concepts, 24 relevant concepts were identified but not yet represented, representing approximately 11% of extractable items that cannot be mapped.

- Single LLM Evaluation: The study exclusively evaluated Claude Sonnet 4, limiting generalizability across different LLM architectures.

- Data Domain Mismatch: The evaluation used Reddit posts rather than clinical dialogue transcripts, raising questions about performance transfer to actual healthcare settings.

## Confidence

- High Confidence: The ontology construction methodology and inter-rater reliability (weighted kappa of 0.899) are well-documented and reproducible.
- Medium Confidence: The 78.2% extraction accuracy is reliable for the Reddit dataset tested, but confidence decreases for clinical dialogue transcripts.
- Low Confidence: Claims about enhanced clinical utility and interoperability are speculative as these downstream benefits were not empirically tested.

## Next Checks

1. **Clinical Domain Transfer**: Extract stress-related information from 50 clinical dialogue transcripts and compare mapping accuracy and coverage gaps to the Reddit dataset results. Target: maintain >75% accuracy with <15% unmapped concepts.

2. **Multi-LLM Performance Comparison**: Evaluate the same 35 Reddit posts across three different LLMs (Claude Sonnet 4, GPT-4o, and Qwen) using identical ontology-guided prompts. Measure variance in accuracy, hallucination rates, and misclassification patterns.

3. **Ontology Coverage Expansion**: Conduct a systematic coverage analysis by extracting from a diverse corpus of 100 stress-related texts. For each unmapped concept identified, determine whether it represents a true gap requiring ontology extension or a misclassification requiring prompt refinement.