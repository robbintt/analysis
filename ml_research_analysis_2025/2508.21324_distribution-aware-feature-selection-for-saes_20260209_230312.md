---
ver: rpa2
title: Distribution-Aware Feature Selection for SAEs
arxiv_id: '2508.21324'
source_url: https://arxiv.org/abs/2508.21324
tags:
- features
- batchtopk
- feature
- selection
- sampledsae
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the inefficiency of sparse autoencoders (SAEs)
  in feature selection, particularly the "activation lottery" problem where rare,
  high-magnitude features dominate selection at the expense of more consistent, informative
  features. The authors propose Sampled-SAE, which introduces a two-stage feature
  selection process: first scoring features using batch-level statistics (L2 norm,
  entropy, or squared L2), then restricting the candidate pool before applying Top-K
  selection.'
---

# Distribution-Aware Feature Selection for SAEs

## Quick Facts
- arXiv ID: 2508.21324
- Source URL: https://arxiv.org/abs/2508.21324
- Reference count: 40
- Primary result: Sampled-SAE variants with ℓ=3-5 achieved better probing accuracy and reduced feature absorption compared to BatchTopK on Pythia-160M, while maintaining comparable reconstruction fidelity.

## Executive Summary
This paper addresses the inefficiency of sparse autoencoders (SAEs) in feature selection, particularly the "activation lottery" problem where rare, high-magnitude features dominate selection at the expense of more consistent, informative features. The authors propose Sampled-SAE, which introduces a two-stage feature selection process: first scoring features using batch-level statistics (L2 norm, entropy, or squared L2), then restricting the candidate pool before applying Top-K selection. This allows tuning between global consistency (small ℓ) and fine-grained reconstruction (large ℓ). On Pythia-160M, Sampled-SAE variants with ℓ=3-5 achieved better probing accuracy and reduced feature absorption compared to BatchTopK, while maintaining comparable reconstruction fidelity. The method demonstrates that distribution-aware feature selection can improve interpretability without sacrificing reconstruction quality.

## Method Summary
Sampled-SAE modifies the BatchTopK SAE architecture by introducing a two-stage feature selection process. First, features are scored using batch-level statistics (L2 norm, squared-L2, or entropy) to compute activation magnitudes across the batch. The top Kℓ features form a candidate pool, then standard batch-level Top-K selection is applied within this restricted set. This creates a tunable parameter ℓ that controls the trade-off between global consistency (small ℓ) and fine-grained reconstruction (large ℓ). The method trains with standard SAE hyperparameters: batch size 4,096, learning rate 3e-4, 50k steps, and auxiliary loss weight α=1/32. Scoring functions differ in their inductive biases: L2-norm and squared-L2 favor consistent mid-frequency patterns, while entropy selects specialized features that activate on specific inputs.

## Key Results
- Sampled-SAE with ℓ=3-5 achieved better probing accuracy than BatchTopK while maintaining comparable FVU
- Reduced feature absorption fraction compared to BatchTopK, indicating cleaner concept boundaries
- Different scoring functions (L2-norm, squared-L2, entropy) recovered complementary feature sets with varying activation densities
- No single ℓ value optimized all metrics, demonstrating the importance of the tunable trade-off

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Candidate Filtering
Pre-filtering features by batch-level statistics before Top-K selection reduces dominance by rare high-magnitude activations. For batch activations Z ∈ R^(m×B), compute feature scores q = s_φ(Z), select top Kℓ features as candidates, then apply BatchTopK only within this restricted pool. Small ℓ restricts competition to globally consistent features. Core assumption: Mid-frequency features that fire consistently across tokens are more interpretable than rare spiking features. Break condition: If interpretable concepts primarily manifest as rare high-magnitude features, filtering will discard meaningful structure.

### Mechanism 2: Distribution-Aware Scoring Functions
Different scoring functions (L2-norm, squared-L2, entropy) bias feature selection toward distinct activation patterns. L2-norm rewards consistency (feature firing at magnitude 10 across 50% of samples scores higher than magnitude 100 on 5%). Squared-L2 is sensitive to both frequency and intensity. Entropy rewards specialization—features that concentrate activation on specific inputs. Core assumption: The scoring function's inductive bias aligns with the true distribution of interpretable features in the data. Break condition: If no single scoring bias matches the ground-truth feature distribution, different functions will recover different (possibly incomplete) feature sets.

### Mechanism 3: Tunable Reconstruction-Interpretability Trade-off
The expansion factor ℓ traces a spectrum between global consistency (ℓ≈1) and fine-grained reconstruction (large ℓ). At ℓ=1, all tokens draw from only K globally influential features. As ℓ increases toward n/K, the method recovers BatchTopK with unrestricted competition. This allows practitioners to tune for their priority. Core assumption: Interpretability benefits are worth some reconstruction cost. Break condition: If downstream tasks require fine-grained token-specific features, aggressive filtering will hurt performance regardless of interpretability gains.

## Foundational Learning

- **BatchTopK SAE architecture**: Understanding the baseline selection mechanism is prerequisite. Quick check: Can you explain why BatchTopK selects features at batch level rather than per-token, and what problem this solves?
- **Column subset selection (CSS) in matrix approximation**: The paper frames feature selection as a streaming CSS problem; L2-norm scoring approximates leverage scores from randomized linear algebra. Quick check: Why would column norms provide a reasonable proxy for feature importance in matrix reconstruction?
- **Feature absorption in SAEs**: A key evaluation metric; absorption occurs when hierarchical concepts (A implies B) cause gerrymandered latents ("B except A"). Quick check: How would reducing rare high-magnitude features help maintain cleaner concept boundaries?

## Architecture Onboarding

- **Component map**: Encoder -> Pre-activations Z -> Scoring module s_φ(Z) -> Candidate selector TopK(q, Kℓ) -> BatchTopK layer -> Sparse codes F -> Decoder
- **Critical path**: Scoring function choice → candidate pool size ℓ → which features compete → probing accuracy vs reconstruction trade-off. The scoring function and ℓ are the only new hyperparameters vs standard BatchTopK.
- **Design tradeoffs**: L2-norm vs Squared-L2 (L2-norm more aggressively filters rare spikes; Squared-L2 retains some high-magnitude sensitivity); Small ℓ vs large ℓ (small ℓ improves probing/absorption but increases FVU); Entropy vs norm-based (entropy captures specialization but underperformed BatchTopK on probing).
- **Failure signatures**: Training instability on synthetic data (paper notes "Sampled-SAE training instabilities" with FVE ≈0.99 for BatchTopK but substantially worse for Sampled-SAE); Low cross-seed agreement (MMCS for Sampled-SAE variants much lower than BatchTopK); Reconstruction degradation as ℓ decreases.
- **First 3 experiments**: 1) Reproduce BatchTopK baseline on your target model; 2) Sweep ℓ with L2-norm scoring to find Pareto-optimal point; 3) Compare scoring functions at fixed ℓ using decoder similarity and semantic similarity matching.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can theoretically grounded leverage scores or ridge leverage scores outperform the heuristic L2-norm and entropy scoring functions in feature selection? The current study relies on computationally efficient heuristics without testing the stronger theoretical guarantees offered by leverage scores in matrix approximation.
- **Open Question 2**: Do the trade-offs observed in Sampled-SAE (specifically the benefits of low ℓ values) generalize to larger models and different layers? It is unclear if the "activation lottery" problem scales linearly with model size or if the optimal ℓ spectrum shifts in deeper layers.
- **Open Question 3**: Does promoting mid-frequency features actually improve human interpretability, or does it merely optimize for automated metrics like probing and absorption? The paper relies on automated proxies and admits finding "no evidence that this improves interpretability" despite density improvements.

## Limitations

- Evaluation scope limited to Pythia-160M layer 6 due to computational constraints, raising questions about generalizability to larger models or different layers
- Training instability on synthetic data with substantially worse FVE than BatchTopK, suggesting potential fundamental stability challenges
- Low cross-seed agreement (MMCS values much lower than BatchTopK) indicates poor reproducibility of discovered features

## Confidence

- **High confidence**: Mathematical formulation of Sampled-SAE is correct; FVU and feature density metrics are computed accurately
- **Medium confidence**: Comparative performance claims are supported by experimental results, though evaluation is limited to one model and specific metrics
- **Low confidence**: Claims about improved interpretability assume automated metrics directly translate to better mechanistic understanding, which isn't validated through qualitative feature analysis

## Next Checks

1. **Cross-architecture validation**: Train Sampled-SAE on GPT-2 XL and Llama 7B using identical hyperparameters. Compare ℓ=3-5 performance against BatchTopK to assess scalability and architecture sensitivity.
2. **Stability analysis**: Run 5 independent seeds of Sampled-SAE with ℓ=5 on Pythia-160M. Compute MMCS between all pairs and measure feature set overlap using decoder similarity. Compare against BatchTopK stability.
3. **Feature analysis validation**: Manually examine 50 highest-activating features from Sampled-SAE (ℓ=5) vs BatchTopK using integrated gradients attribution to input tokens. Quantify differences in feature coherence and interpretability through human evaluation.