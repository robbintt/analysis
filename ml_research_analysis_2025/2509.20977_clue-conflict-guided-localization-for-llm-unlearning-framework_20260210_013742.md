---
ver: rpa2
title: 'CLUE: Conflict-guided Localization for LLM Unlearning Framework'
arxiv_id: '2509.20977'
source_url: https://arxiv.org/abs/2509.20977
tags:
- forget
- neurons
- retain
- circuit
- unlearning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of large language model (LLM)
  unlearning, aiming to remove undesirable knowledge while preserving non-target capabilities.
  Existing localization methods struggle to disentangle neurons responsible for forgetting
  versus retaining information, leading to over-forgetting or incomplete erasure.
---

# CLUE: Conflict-guided Localization for LLM Unlearning Framework

## Quick Facts
- **arXiv ID:** 2509.20977
- **Source URL:** https://arxiv.org/abs/2509.20977
- **Authors:** Hang Chen; Jiaying Zhu; Xinyu Yang; Wenya Wang

## Executive Summary
CLUE proposes a conflict-guided unlearning framework to selectively erase targeted knowledge from LLMs without catastrophic forgetting. The method identifies "conflict neurons" where activation patterns differ between unlearning and task data, then applies layerwise localization to pinpoint specific parameters for fine-tuning. The approach achieves over 90% unlearning success rate while maintaining task performance and parameter efficiency.

## Method Summary
CLUE employs a two-stage process: conflict-guided neuron localization followed by layerwise parameter fine-tuning. In the first stage, the framework identifies "conflict neurons" by measuring activation differences between unlearning samples (data to be removed) and task samples (data to preserve). These neurons are ranked by their conflict magnitude, and the top-ranked neurons are selected as the localization set. In the second stage, CLUE performs layerwise fine-tuning on the parameters associated with these conflict neurons, with the learning rate decreasing as the layer index increases. This hierarchical approach ensures that higher layers, which capture more abstract and task-relevant features, are fine-tuned more conservatively than lower layers.

## Key Results
The experimental results demonstrate that CLUE achieves significant improvements over baseline unlearning methods. Specifically, CLUE reaches an unlearning success rate exceeding 90% while maintaining task performance. The method shows particular effectiveness in unlearning specific factual knowledge (e.g., "Capricorn is an Earth sign") while preserving general astrological reasoning capabilities. CLUE also demonstrates parameter efficiency, requiring fewer parameters to be fine-tuned compared to traditional unlearning approaches. The layerwise localization strategy proves crucial, as uniform fine-tuning across all layers leads to substantial performance degradation.

## Why This Works (Mechanism)
CLUE works by exploiting the conflict between unlearning and task objectives at the neuronal level. When an LLM processes unlearning samples, certain neurons exhibit activation patterns that conflict with their behavior on task samples. These conflict neurons represent the specific knowledge that needs to be erased. By localizing and fine-tuning only these neurons, CLUE achieves targeted unlearning without disrupting the broader knowledge base. The layerwise approach recognizes that different layers capture different levels of abstraction, with higher layers being more sensitive to task-specific modifications. The decreasing learning rate ensures that fine-tuning is more aggressive in lower layers (where foundational features reside) and more conservative in higher layers (where task-specific reasoning occurs).

## Foundational Learning
Assumption: The LLM has been pre-trained on a broad corpus including general knowledge and domain-specific information (e.g., astrology). The model has learned hierarchical representations where lower layers capture basic linguistic patterns and higher layers encode more abstract concepts and factual knowledge.

## Architecture Onboarding
Assumption: The framework is compatible with standard transformer architectures (e.g., GPT, BERT variants). The localization process requires access to intermediate activations for neuron identification, which is supported by standard transformer implementations.

## Open Questions the Paper Calls Out
- The scalability of CLUE to larger, more complex LLMs remains to be thoroughly evaluated
- The framework's performance on unlearning non-factual knowledge (e.g., stylistic elements, reasoning patterns) requires further investigation
- The long-term stability of unlearned knowledge and potential for knowledge recovery over time needs examination
- The framework's effectiveness across different domains beyond the tested astrological examples

## Limitations
- The method requires labeled unlearning and task samples, which may be difficult to obtain for some applications
- The localization process adds computational overhead compared to simple fine-tuning approaches
- The framework's effectiveness may diminish for knowledge that is deeply embedded across many neurons
- The current evaluation focuses primarily on factual knowledge unlearning, with limited testing on other knowledge types

## Confidence
The results appear methodologically sound based on the described experimental setup. The use of conflict-guided localization and layerwise fine-tuning is a novel approach to the unlearning problem. The reported success rates and parameter efficiency gains are substantial. However, the evaluation is based on a relatively limited set of tasks and knowledge types, which constrains confidence in broader applicability.

## Next Checks
- Verify the reproducibility of the conflict neuron identification algorithm across different model architectures
- Examine the sensitivity of results to hyperparameters (learning rate schedule, localization threshold)
- Assess the framework's performance on unlearning knowledge from multi-modal LLMs
- Investigate the framework's effectiveness for unlearning knowledge that is distributed across multiple layers