---
ver: rpa2
title: 'EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through
  Label Distribution Learning'
arxiv_id: '2511.20106'
source_url: https://arxiv.org/abs/2511.20106
tags:
- emotion
- speech
- emotional
- multilingual
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EM2LDL, the first multilingual speech corpus
  designed for mixed emotion recognition through label distribution learning. The
  corpus addresses the limitations of existing monolingual and single-label emotion
  corpora by incorporating spontaneous speech with intra-utterance code-switching
  across English, Mandarin, and Cantonese, annotated with fine-grained emotion distributions
  over 32 categories.
---

# EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning

## Quick Facts
- **arXiv ID**: 2511.20106
- **Source URL**: https://arxiv.org/abs/2511.20106
- **Reference count**: 40
- **Primary result**: First multilingual speech corpus for mixed emotion recognition using label distribution learning, with 3,998 utterances annotated with 32-dimensional emotion distributions

## Executive Summary
EM2LDL introduces the first multilingual speech corpus designed for mixed emotion recognition through label distribution learning. The corpus addresses the limitations of existing monolingual and single-label emotion corpora by incorporating spontaneous speech with intra-utterance code-switching across English, Mandarin, and Cantonese. With 3,998 utterances from 231 speakers and fine-grained emotion distributions over 32 categories, EM2LDL provides a versatile testbed for developing adaptive, empathetic systems for affective computing applications.

The corpus includes balanced gender and age distributions, with personality trait annotations for a subset of speakers. Baseline experiments using self-supervised learning models demonstrate robust performance in speaker-independent evaluations across gender, age, and personality dimensions. HuBERT-large-EN achieves optimal results, validating the corpus's potential for advancing emotion recognition research in multilingual and multicultural contexts.

## Method Summary
The study introduces a multilingual speech corpus (EM2LDL) for mixed emotion recognition using label distribution learning (LDL). The corpus contains 3,998 utterances from 231 speakers, featuring spontaneous speech with intra-utterance code-switching across English, Mandarin, and Cantonese. Emotion annotations are 32-dimensional probability distributions derived from 20 annotators, based on Plutchik's wheel of emotions. Baseline experiments use self-supervised learning (SSL) models (HuBERT-large-EN) with mean-pooled embeddings as input features. The training objective combines KL divergence and cosine similarity losses, optimized via Adam with early stopping. Evaluation employs speaker-independent splits (70/10/20) and metrics including KL Divergence, Cosine Similarity, and other distribution-based scores.

## Key Results
- HuBERT-large-EN achieves the best performance across speaker-independent gender-, age-, and personality-based evaluations
- The corpus demonstrates robustness in mixed emotion recognition tasks with code-switched speech
- Baseline experiments validate the effectiveness of label distribution learning for fine-grained emotion recognition

## Why This Works (Mechanism)
The corpus leverages label distribution learning to capture the complexity of mixed emotions in real-world speech. By using probability distributions rather than single labels, the approach better represents the nuanced and overlapping nature of human emotions. The multilingual and code-switched nature of the corpus ensures broader applicability across different linguistic and cultural contexts, while the balanced speaker demographics enhance generalizability.

## Foundational Learning
- **Label Distribution Learning (LDL)**: Why needed - Captures the complexity of mixed emotions by representing them as probability distributions rather than single labels. Quick check - Verify that emotion distributions sum to 1 and are properly normalized.
- **Self-Supervised Learning (SSL)**: Why needed - Provides robust feature representations without requiring extensive labeled data. Quick check - Confirm that SSL embeddings capture meaningful acoustic and linguistic patterns.
- **Code-Switching**: Why needed - Reflects real-world multilingual communication patterns. Quick check - Analyze the frequency and distribution of language switches within utterances.
- **Speaker-Independent Evaluation**: Why needed - Ensures model generalizability across different speakers. Quick check - Verify that no speaker appears in both training and test sets.

## Architecture Onboarding
**Component Map**: SSL Backbone -> Mean Pooling -> Linear Layer (768/1024 â†’ 32) -> Log-Softmax

**Critical Path**: The SSL backbone extracts frame-level embeddings, which are mean-pooled to create utterance-level representations. These are passed through a linear layer to predict 32-dimensional emotion distributions, optimized using the composite loss.

**Design Tradeoffs**: 
- Using pre-trained SSL models vs. training from scratch balances computational efficiency with adaptability
- Label distribution learning captures emotion complexity but requires more annotations than single-label approaches
- Multilingual corpus increases applicability but introduces linguistic variability that may affect model performance

**Failure Signatures**:
- KL divergence instability when predicted probabilities approach zero for ground-truth classes
- Data leakage if speaker IDs are not properly partitioned between train/test sets
- Performance degradation on code-switched utterances if the model hasn't been exposed to sufficient bilingual examples

**First 3 Experiments**:
1. Reproduce speaker-independent splits and verify no speaker overlap between train/test sets
2. Train baseline model using HuBERT-large-EN and evaluate on test set using KL divergence and cosine similarity
3. Analyze emotion distribution predictions to identify systematic biases or failure patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Corpus composition details (language distribution, code-switching patterns) are not fully specified
- Annotation quality metrics (inter-annotator agreement) are not reported
- Limited evaluation of domain adaptation and robustness to unseen acoustic conditions

## Confidence
- **High Confidence**: Corpus construction methodology and technical implementation of baseline experiments
- **Medium Confidence**: Performance metrics and superiority of HuBERT-large-EN, though limited by lack of alternative SSL comparisons
- **Low Confidence**: Claims about corpus utility for mental health monitoring and cross-cultural communication applications

## Next Checks
1. Reproduce speaker-independent splits by verifying exact speaker IDs assigned to train/validation/test sets to prevent data leakage
2. Compute inter-annotator agreement metrics (e.g., Krippendorff's alpha) for emotion annotations to assess label reliability
3. Analyze corpus composition to quantify language distribution and code-switching frequency for understanding representativeness