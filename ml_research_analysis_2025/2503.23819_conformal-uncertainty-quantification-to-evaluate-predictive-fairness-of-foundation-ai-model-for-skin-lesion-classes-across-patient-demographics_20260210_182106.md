---
ver: rpa2
title: Conformal uncertainty quantification to evaluate predictive fairness of foundation
  AI model for skin lesion classes across patient demographics
arxiv_id: '2503.23819'
source_url: https://arxiv.org/abs/2503.23819
tags:
- skin
- prediction
- dataset
- conformal
- cancer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study uses conformal prediction to evaluate algorithmic fairness
  in a foundation model for skin lesion classification across patient demographics
  (sex, age, ethnicity). The authors apply Google DermFoundation, a vision transformer,
  to public skin lesion datasets (ISIC 2019 and ASAN), and use a novel F1-score-based
  dynamic sampling to mitigate class imbalance.
---

# Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics

## Quick Facts
- arXiv ID: 2503.23819
- Source URL: https://arxiv.org/abs/2503.23819
- Reference count: 40
- Primary result: Conformal prediction with F1-score dynamic sampling improves fairness in skin lesion classification across demographics

## Executive Summary
This study applies conformal prediction to evaluate algorithmic fairness in a foundation model for skin lesion classification across patient demographics (sex, age, ethnicity). Using Google DermFoundation, a vision transformer pre-trained on dermatology images, the authors employ a novel F1-score-based dynamic sampling to mitigate class imbalance. Conformal prediction provides both population-level coverage guarantees and individual uncertainty scores. Results show improved fairness with the dynamic sampling approach, achieving 80%+ coverage and high A2 accuracy (>70%) for ground truth among top two predictions across demographics.

## Method Summary
The approach uses Google DermFoundation (frozen ViT backbone) to extract 2048-dimensional embeddings from 64×64 skin lesion images. A lightweight 6-block MLP classifier processes these embeddings, with training stabilized by F1-score-based dynamic sampling that periodically updates class weights based on validation performance. Conformal prediction constructs prediction sets using a held-out calibration set (~500 samples), computing nonconformity scores and taking the 1−α quantile as the threshold. The framework evaluates fairness by analyzing coverage and uncertainty across demographic groups.

## Key Results
- Accuracy improves from 70.33% to 72.49% for six common classes on ISIC 2019
- Conformal prediction sets achieve 80%+ coverage across all demographics
- Ground truth appears in top-2 predictions (A2 accuracy) for >70% of cases across demographics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Conformal prediction provides statistically rigorous uncertainty bounds for individual predictions while guaranteeing population-level coverage.
- Mechanism: A held-out calibration set computes nonconformity scores (deviation between predicted and true labels). The 1-α quantile of these scores defines the threshold for constructing prediction sets. For any new test sample, the model outputs a set of labels whose combined confidence meets the coverage threshold, with set size inversely related to prediction confidence.
- Core assumption: The calibration set is exchangeable with the test distribution (i.i.d. or at least exchangeable).
- Evidence anchors: Abstract states "conformal analysis is method independent and it not only provides a coverage guarantee at population level but also provides an uncertainty score for each individual"; section 2.3 details the nonconformity score calculation and threshold selection.
- Break condition: Calibration set distribution shift violates exchangeability, causing coverage guarantees to degrade.

### Mechanism 2
- Claim: F1-score-based dynamic sampling mitigates class imbalance by reallocating training focus toward poorly performing classes during training.
- Mechanism: After every T epochs, class-wise F1-scores are computed on the validation set. Classes with F1-weight below threshold λ receive baseline sampling weight β; classes above threshold receive weights inversely proportional to their F1-scores.
- Core assumption: Validation F1-scores reliably indicate which classes need more training exposure.
- Evidence anchors: Abstract notes "We used a model-agnostic dynamic F1-score-based sampling during model training, which helped to stabilize the class imbalance"; Algorithm 1 specifies the update rule.
- Break condition: Minority class validation samples are too few for stable F1 estimation, making weights noisy.

### Mechanism 3
- Claim: A frozen foundation model backbone with lightweight classifier head enables computationally efficient deployment while preserving dermatologically-relevant feature representations.
- Mechanism: Google DermFoundation (ViT pre-trained on dermatology images) generates 2048-dimensional embeddings. A 6-block MLP serves as the classification head. The backbone remains frozen; only the MLP is trained.
- Core assumption: DermFoundation embeddings are sufficiently general to capture skin lesion features across diverse patient demographics without fine-tuning.
- Evidence anchors: Section 2.2 states "the advantage of using this model is that it has been specifically pre-trained on extracting robust embeddings from dermatology images"; accuracy improvements shown across datasets.
- Break condition: Downstream task requires features not captured by frozen embeddings, causing performance degradation.

## Foundational Learning

- **Conformal Prediction Theory**
  - Why needed: Understanding how prediction sets are constructed from nonconformity scores and what "coverage guarantee" means statistically.
  - Quick check: Can you explain why conformal prediction requires a separate calibration set distinct from training and test sets?

- **Vision Transformers (ViT) and Foundation Models**
  - Why needed: The DermFoundation model uses transformer architecture; understanding patch embedding and self-attention helps interpret what the embeddings capture.
  - Quick check: What is the difference between a CNN and a ViT in how they process spatial image information?

- **Class Imbalance and Sampling Strategies**
  - Why needed: The F1-dynamic sampler addresses the long-tail distribution of skin lesion classes.
  - Quick check: Why might oversampling minority classes naively cause overfitting, and how does the proposed approach attempt to mitigate this?

## Architecture Onboarding

- **Component map**:
  Input Image (64×64) → DermFoundation API (frozen ViT backbone) → 2048-dim Embedding (JSON storage) → MLP Classifier (6 blocks: FC→BN→ReLU→Dropout) → Softmax Scores → Conformal Prediction Module → Predicted Class and Prediction Set + Uncertainty

- **Critical path**:
  1. Embedding generation: Images preprocessed (resize, augment) and passed through DermFoundation API before training begins.
  2. Sampler initialization: Class frequency weights computed from training data initialize the custom sampler.
  3. Training loop with periodic sampler updates: Every T epochs, compute validation F1-scores and update sampler weights.
  4. Calibration set construction: Reserve ~500-1500 samples never seen during training for conformal calibration.
  5. Inference with conformal sets: For each test sample, output both top prediction and conformal prediction set.

- **Design tradeoffs**:
  - Frozen vs. fine-tuned backbone: Freezing reduces training cost and overfitting risk but may sacrifice task-specific adaptation.
  - Calibration set size: Larger sets give tighter coverage bounds but reduce training data.
  - Coverage level α: Higher coverage produces larger prediction sets (more uncertain).

- **Failure signatures**:
  - Coverage collapse: If conformal sets consistently miss ground truth, check for calibration-test distribution shift.
  - Set explosion: If prediction sets contain many labels for most samples, model uncertainty is high—may indicate insufficient training or poor embeddings.
  - Sampler oscillation: If F1-scores fluctuate wildly between epochs, increase T or smooth weights using exponential moving average.
  - Minority class overfitting: If validation F1 improves but test F1 degrades for minority classes, reduce sampler update frequency.

- **First 3 experiments**:
  1. Train MLP on ISIC embeddings without dynamic sampling, compute conformal prediction sets on held-out test set. Verify coverage matches α=0.2 (80%) and plot prediction set size distribution by class.
  2. Fix α=0.2, vary threshold λ (0.5 to 2.0 in 0.5 increments) and minimum weight β (0.1 to 0.5). Measure per-class F1 and conformal set sizes on ASAN dataset.
  3. Train on ISIC only, compute conformal sets on ASAN test set (and vice versa). Measure coverage degradation and set size changes to test robustness to demographic shift.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the F1-score-based dynamic sampling approach generalize to maintain robustness and fairness when applied to non-dermatological medical imaging tasks or datasets with significantly higher class cardinality?
- Basis in paper: The authors claim the framework is "model agnostic and task agnostic" (Page 3) and "can be generalised to other similar tasks" (Page 15), though they only validate on skin lesion datasets.
- Why unresolved: Experiments are restricted to skin lesions with relatively few classes (8–12), leaving generalization to other modalities unproven.
- What evidence would resolve it: Replication of the study on a different medical imaging dataset (e.g., histopathology or radiology) with a larger number of classes.

### Open Question 2
- Question: Does the provision of individualized conformal prediction sets actually improve diagnostic accuracy or trust for clinicians compared to standard probability outputs?
- Basis in paper: The paper claims to "advance the trustworthiness" (Page 15) and address the "clinical translational bottleneck" (Page 2), but evaluates this using retrospective metrics rather than human-subject experiments.
- Why unresolved: Trustworthiness is asserted based on statistical guarantees (coverage) but is not measured via qualitative or quantitative feedback from medical professionals.
- What evidence would resolve it: A user study measuring dermatologist diagnostic performance and confidence levels when assisted by conformal sets versus standard AI predictions.

### Open Question 3
- Question: How can the method prevent the dilution of ground-truth confidence within large prediction sets when applied to complex multiclass problems?
- Basis in paper: The authors note that for the ASAN dataset, "confidence for the ground-truth label was slightly reduced" due to multiple labels, stating: "For multiclass classification problems... this could be a potential issue" (Page 10).
- Why unresolved: The current implementation distributes the 80% coverage guarantee across all plausible labels, potentially lowering the specific score assigned to the correct class.
- What evidence would resolve it: A modification to the conformal scoring mechanism that prioritizes set compactness or penalizes larger sets without violating marginal coverage.

## Limitations
- Frozen foundation model approach may sacrifice task-specific adaptation that fine-tuning could provide
- Coverage guarantees depend critically on exchangeability assumption between calibration and test sets, not empirically tested for demographic shifts
- Choice of hyperparameters (α=0.2, λ threshold, β minimum weight) appears arbitrary without sensitivity analysis

## Confidence

- **High**: Conformal prediction provides population-level coverage guarantees and individual uncertainty scores
- **Medium**: F1-score-based dynamic sampling improves fairness and accuracy
- **Medium**: Frozen foundation model with lightweight classifier is computationally efficient

## Next Checks

1. **Distribution Shift Robustness**: Test conformal coverage when calibration set demographics differ from test set (e.g., calibrate on ISIC, test on ASAN).

2. **Hyperparameter Sensitivity**: Perform ablation studies on λ threshold, β minimum weight, and α coverage level to identify optimal settings.

3. **Frozen vs. Fine-tuned Backbone**: Compare performance of frozen DermFoundation embeddings against fine-tuned backbone to quantify adaptation benefits.