---
ver: rpa2
title: Probabilistic Skip Connections for Deterministic Uncertainty Quantification
  in Deep Neural Networks
arxiv_id: '2501.04816'
source_url: https://arxiv.org/abs/2501.04816
tags:
- feature
- layer
- network
- collapse
- intermediate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach for deterministic uncertainty
  quantification (UQ) in deep neural networks by identifying intermediate layers that
  maintain both sensitivity and smoothness without requiring spectral normalization
  during training. The key idea is to use neural collapse metrics to find appropriate
  intermediate layers and create probabilistic skip connections (PSCs) that retrofit
  existing models for uncertainty estimation.
---

# Probabilistic Skip Connections for Deterministic Uncertainty Quantification in Deep Neural Networks

## Quick Facts
- arXiv ID: 2501.04816
- Source URL: https://arxiv.org/abs/2501.04816
- Reference count: 40
- Key outcome: PSCs achieve UQ and OOD detection performance comparable to spectral normalization without requiring network retraining.

## Executive Summary
This paper introduces Probabilistic Skip Connections (PSCs) as a method for deterministic uncertainty quantification in deep neural networks. The key insight is that intermediate layers in trained networks can naturally preserve both sensitivity and smoothness properties required for UQ, eliminating the need for spectral normalization during training. By using neural collapse metrics to identify appropriate layers and applying Tucker decomposition for projection, PSCs retrofit existing models for uncertainty estimation. The approach demonstrates competitive performance on standard benchmarks while working effectively even for networks without residual connections.

## Method Summary
PSCs identify intermediate layers that maintain sensitivity and smoothness through neural collapse metrics (NC1 for feature variability suppression, NC4 for semantic preservation). Candidate layers are selected based on NC1 > 0.2 and highest NC4 accuracy. Intermediate representations are projected to lower dimensions using Tucker decomposition on channel-wise covariance tensors, with parameters controlling channel and spatial dimension reduction. Dual probabilistic heads provide feature density estimates for epistemic uncertainty (via QDA) and predictive entropy for aleatoric uncertainty (via Laplace-approximated linear classifier). The method works on pretrained networks without requiring spectral normalization during training.

## Key Results
- PSCs achieve UQ and OOD detection performance comparable to or better than spectral normalization approaches
- The method works effectively for networks without residual connections, expanding applicability
- Competitive accuracy and significantly improved Expected Calibration Error (ECE) compared to baselines
- Outperforms other deterministic UQ methods on Dirty-MNIST dataset

## Why This Works (Mechanism)

### Mechanism 1: Intermediate Layer Identification via Neural Collapse Metrics
The paper uses NC1 (Tr(ΣW)/Tr(ΣT)) as a proxy for feature variability suppression and NC4 (nearest-centroid classifier accuracy) as a proxy for semantic preservation. Layers with NC1 > ε (0.2 cutoff) and high NC4 accuracy are selected as candidates, approximating the bi-Lipschitz condition (sensitivity + smoothness) typically enforced via spectral normalization.

### Mechanism 2: Geometric Preservation through Tucker Decomposition Projection
High-dimensional intermediate representations are projected to lower-dimensional space using Tucker decomposition while preserving sensitivity and smoothness properties. Channel-wise covariance tensors are decomposed (Σc ≈ G ×₁ A ×₂ B ×₃ C), then intermediate representations are projected onto factor matrices with cproj and dproj controlling channel vs. spatial dimension reduction.

### Mechanism 3: Disentanglement via Dual Probabilistic Heads
Feature density captures epistemic uncertainty while predictive entropy captures aleatoric uncertainty. Quadratic discriminant analysis (QDA) fitted to projected feature vectors provides density estimates p(z) for OOD/epistemic uncertainty. A Laplace-approximated linear classifier provides predictive entropy for aleatoric uncertainty.

## Foundational Learning

- **Bi-Lipschitz constraint**: Why needed here - Understanding why spectral normalization is typically required for deterministic UQ (to enforce sensitivity via lower bound and smoothness via upper bound), and how PSCs circumvent this by finding layers that naturally satisfy the constraint.
  - Quick check question: Why does feature collapse (violating the lower Lipschitz bound) prevent deterministic UQ methods from working?

- **Neural Collapse phenomena (NC1-NC4)**: Why needed here - These metrics serve as proxies for identifying suitable intermediate layers; understanding their geometric meaning is essential for interpreting layer selection.
  - Quick check question: If NC1 = 0.15 for a layer, what does this indicate about within-class variance, and would this layer qualify as a PSC candidate?

- **Tucker decomposition for tensors**: Why needed here - The projection step uses Tucker decomposition on channel-wise covariance tensors; understanding factor matrices (A, B, C) and the core tensor (G) is necessary for setting projection parameters correctly.
  - Quick check question: In the projection X̃ = X ×₁ A ×₂ B, what do cproj and dproj respectively control?

## Architecture Onboarding

- **Component map**: Collapse measurement module -> Layer selector -> Projection pipeline -> Dual probabilistic heads
- **Critical path**: 1) Load pretrained network (no SN required) 2) Extract outputs at every layer using training data 3) Compute NC1/NC4 per layer on validation set 4) Select candidate layer(s): highest NC4 with NC1 > 0.2 5) Compute channel-wise moments (mean, covariance) on training data 6) Fit Tucker decomposition on covariance tensor 7) Project all samples to obtain feature vectors Z 8) Fit QDA (class-wise Gaussians) for OOD detection 9) Fit linear classifier with Kronecker-factored Laplace approximation for predictions
- **Design tradeoffs**: 
  - cproj vs dproj: Paper recommends smallest values where NC1/NC4 don't change dramatically; smaller = more compression but higher property loss risk
  - Single vs adjacent layers: If NC1 near cutoff, combine layers by channel-wise concatenation before projection
  - Probabilistic head choice: Paper uses QDA+Laplace but notes "any distance-aware model" (GP, GMM) can substitute
- **Failure signatures**:
  - NC1 < 0.2 at all intermediate layers: Network too deep or aggressively trained; try earlier layer or SN-trained network
  - NC4 low before collapse cutoff: Layer sensitive but semantically weak; may need different architecture
  - iD/OOD feature density overlap after PSC: Re-examine candidate layer selection and projection dimensions
  - Predictive entropy fails to separate ambiguous from clean iD: Check Laplace approximation calibration
- **First 3 experiments**:
  1. Reproduce Figure 3: Train ResNet-50 on CIFAR-10 with/without SN, plot NC1 and NC4 across layers to verify intermediate layers exist with both high NC1 and high NC4
  2. Validate projection preservation: On MNIST with ResNet-18, compute NC1/NC4 at candidate layer, apply Tucker projection with varying cproj/dproj, verify NC1 > 0.2 and NC4 preserved post-projection
  3. End-to-end PSC evaluation: Train on Dirty-MNIST, fit PSC, compare feature density separation (AUROC iD vs OOD) and predictive entropy separation (AUROC clean vs ambiguous) against baseline and SN-trained networks

## Open Questions the Paper Calls Out

### Open Question 1
Can probabilistic skip connections (PSCs) be effectively extended to uncertainty quantification tasks in reinforcement learning or time-series forecasting?
- Basis: "Future work could extend PSCs to other UQ tasks, such as reinforcement learning or time-series forecasting."
- Why unresolved: The current study validates the method exclusively on classification tasks (e.g., CIFAR-10, MNIST).
- Evidence: Empirical demonstrations of PSCs disentangling uncertainty in sequential or decision-making environments.

### Open Question 2
Can projection dimensions ($c_{proj}, d_{proj}$) and the neural collapse cutoff be automated to remove the need for parameter sweeping?
- Basis: "Standardizing projection dimensions for common architectures would facilitate a true drop-in replacement... further exploration of metrics for feature collapse could optimize projection sizes."
- Why unresolved: The current methodology requires manual selection of these hyperparameters based on validation performance.
- Evidence: A heuristic or theoretical bound that sets these parameters optimally without manual tuning.

### Open Question 3
Do alternative metrics provide a more robust signal for identifying intermediate layers than the proposed $NC1$ and $NC4$?
- Basis: "Refining techniques for identifying intermediate layers that maintain feature sensitivity and smoothness could further enhance the robustness... across diverse architectures."
- Why unresolved: The paper proxies sensitivity and smoothness using neural collapse, but suggests this identification technique could be improved.
- Evidence: Comparative analysis showing superior UQ performance when using different criteria to locate the "candidate layer."

## Limitations
- Projection dimension sensitivity: The "smallest values where properties don't change" guidance remains heuristic and architecture-dependent
- Single-layer assumption: The method assumes suitable intermediate layers exist without SN; networks with extreme feature collapse throughout may not have viable candidates
- Direct evidence gaps: Tucker decomposition effectiveness for UQ is not directly validated against alternatives (PCA, random projections)

## Confidence
- **High Confidence**: PSC identification mechanism (NC1/NC4 layer selection), empirical performance on benchmark datasets, ablation showing PSC matches SN without retraining
- **Medium Confidence**: Tucker decomposition's role in preserving UQ properties, the claim that PSCs work "even for networks without residual connections" (limited architectural diversity in experiments)
- **Low Confidence**: Generalization to extremely deep networks or small datasets where neural collapse may occur too early

## Next Checks
1. **Layer Selection Robustness**: Train ResNet-18 on CIFAR-10 without SN and systematically verify that intermediate layers with NC1 > 0.2 and high NC4 consistently exist across random seeds
2. **Projection Ablation**: Compare PSC performance using Tucker decomposition vs. PCA vs. no projection (raw features) on the same candidate layer to isolate the contribution of the projection step
3. **Architecture Stress Test**: Apply PSCs to a non-residual architecture (e.g., DenseNet or MobileNet) to validate the claim about working without skip connections, measuring NC1/NC4 preservation and UQ performance