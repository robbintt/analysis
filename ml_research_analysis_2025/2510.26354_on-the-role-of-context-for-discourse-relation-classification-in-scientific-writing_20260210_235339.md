---
ver: rpa2
title: On the Role of Context for Discourse Relation Classification in Scientific
  Writing
arxiv_id: '2510.26354'
source_url: https://arxiv.org/abs/2510.26354
tags:
- discourse
- context
- scientific
- relation
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how context influences discourse relation
  classification (DRC) in scientific writing, motivated by applications in AI for
  Science. Using two scientific discourse datasets (SciDTB and CovDTB), the authors
  evaluate whether discourse-structured context improves classification accuracy compared
  to adjacent text spans or no context at all.
---

# On the Role of Context for Discourse Relation Classification in Scientific Writing

## Quick Facts
- arXiv ID: 2510.26354
- Source URL: https://arxiv.org/abs/2510.26354
- Reference count: 12
- Key outcome: Discourse-structured context consistently improves DRC accuracy in scientific writing, while adjacent text context often degrades performance.

## Executive Summary
This paper investigates how context influences discourse relation classification (DRC) in scientific writing, motivated by applications in AI for Science. Using two scientific discourse datasets (SciDTB and CovDTB), the authors evaluate whether discourse-structured context improves classification accuracy compared to adjacent text spans or no context at all. Experiments employ both PLM fine-tuning (RoBERTa) and LLM-based inference (GPT-4, Llama 3.1). Results show that discourse-structured context consistently enhances performance, particularly for RoBERTa fine-tuning and GPT-4 inference. In contrast, adjacent text context often degrades results. The analysis identifies relations such as elaboration, comparison, attribution, and temporal as benefiting most from structured context. Overall, the study demonstrates that context, when appropriately defined via discourse structure, significantly improves DRC for scientific texts, offering insights for future AI applications in scientific claim validation.

## Method Summary
The study evaluates discourse relation classification using two scientific discourse datasets (SciDTB and CovDTB) with dependency discourse tree annotations. Three context selection schemes are tested: no context (Default), adjacent text (AD1), and discourse-structured context (OR1). RoBERTa fine-tuning follows Liu and Strube (2023) methodology with 10 random seeds per condition. LLM inference uses GPT-4 and Llama 3.1 with in-context learning (ICL) using one example per class. Macro-F1 is the primary metric, with statistical significance assessed via Wilcoxon Signed Ranked Test with Bonferroni correction. Context is prepended before argument 1 in the input sequence.

## Key Results
- Discourse-structured context (OR1) consistently improves classification accuracy over no context, particularly for RoBERTa fine-tuning and GPT-4 inference
- Adjacent text context (AD1) often degrades performance by introducing irrelevant information
- Relations like elaboration, comparison, attribution, and temporal benefit most from structured context
- LLM-based inference with ICL performs significantly worse than PLM fine-tuning for this task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Discourse-structured context improves DRC accuracy by providing semantically relevant antecedent information
- Mechanism: The dependency discourse tree encodes which EDUs are informatively related. Traversing to the parent node retrieves context that disambiguates relation senses that would otherwise be confused (e.g., "without" signaling condition vs. contrast vs. manner)
- Core assumption: The ground-truth discourse tree correctly identifies the most relevant context for each relation
- Evidence anchors:
  - [abstract] "context, as defined by discourse structure, is generally helpful"
  - [section 5.1] OR1 shows statistically significant improvement for SciDTB (WSRT p < 0.05)
  - [corpus] Weak external validation; corpus neighbors focus on discourse tasks but not specifically on context selection mechanisms
- Break condition: When discourse structures are shallow (61% adjacent relations in SciDTB), structured context provides limited additional signal

### Mechanism 2
- Claim: Adjacent text context degrades performance because it introduces noise without guaranteed relevance
- Mechanism: Preceding sentences may be unrelated to the argument pair under classification. Adding them increases input length without adding discriminative signal, confusing both PLM and LLM classifiers
- Core assumption: Models cannot autonomously filter irrelevant context during classification
- Evidence anchors:
  - [section 5.1] AD1 does not lead to strong performance improvements; hurts CovDTB
  - [section 5.2] GPT4 performance drops with AD1 (32.07→26.19 for CovDTB)
  - [corpus] No corpus papers specifically test adjacent vs. structured context comparison
- Break condition: If adjacent text happens to be discourse-relevant (e.g., in tightly cohesive paragraphs), AD1 may not hurt

### Mechanism 3
- Claim: Explicitly marked relations benefit more from context than implicit relations
- Mechanism: Explicit connectives narrow the relation space; context provides additional disambiguating information for remaining candidates
- Core assumption: The presence of explicit connectives correlates with context utility
- Evidence anchors:
  - [section 6, Table 10] Winning relations show 16.6% (CovDTB) and 28.2% (SciDTB) connective matches vs. losing relations at 7.8% and 25.0%
  - [section 6] Elaboration, comparison, attribution, temporal relations benefit most from structured context
  - [corpus] Insufficient external validation of this hypothesis
- Break condition: For relations at document boundaries (e.g., "findings" at abstract start), no prior context exists regardless of explicit marking

## Foundational Learning

- Concept: **Elementary Discourse Units (EDUs) and Dependency Discourse Structures**
  - Why needed here: The entire context selection mechanism depends on understanding that discourse is segmented into EDUs and organized as dependency trees where parent nodes indicate more important context
  - Quick check question: Given a discourse tree, can you identify which EDU is the parent of a given argument pair?

- Concept: **Explicit vs. Implicit Discourse Relations**
  - Why needed here: The paper reports different error patterns and context benefits for explicit (connective-present) vs. implicit relations; this distinction affects model design
  - Quick check question: In the sentence "The method failed because it lacked training data," is the relation explicit or implicit?

- Concept: **In-Context Learning (ICL) for Classification**
  - Why needed here: LLM experiments use ICL with one-shot examples per class; understanding this is necessary to interpret the lower LLM baselines and replicate the prompting approach
  - Quick check question: What is the difference between fine-tuning a PLM and using ICL with an LLM?

## Architecture Onboarding

- Component map: Data preprocessing (EDU segmentation + context selection) -> Model training/inference -> Macro-F1 evaluation with 10 random seeds (PLM) or single trial (LLM)
- Critical path: Data preprocessing (EDU segmentation + context selection) -> Model training/inference -> Macro-F1 evaluation with 10 random seeds (PLM) or single trial (LLM)
- Design tradeoffs:
  - Oracle context (ORn) requires ground-truth discourse trees—unavailable in production; practical systems need automatic discourse parsing first
  - n=1 context worked best; larger n confused models (footnote 11)
  - RoBERTa outperforms LLMs by 25+ F1 points on CovDTB but requires labeled training data
- Failure signatures:
  - AD1 context causing performance drop indicates wrong context selection
  - Low LLM macro-F1 (7-32 range) suggests ICL alone is insufficient for DRC
  - "findings" and "background" relations losing with context often appear at document start with no prior EDUs
- First 3 experiments:
  1. Replicate RoBERTa baseline on SciDTB/CovDTB with Default (no context) to verify macro-F1 ranges (57-75)
  2. Add OR1 context using provided dependency trees; confirm improvement is statistically significant via WSRT
  3. Test AD1 context on same data; verify performance degradation to establish that context selection—not just more context—matters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does structured context provide greater utility for classifying explicitly marked discourse relations compared to implicit ones in scientific writing?
- Basis in paper: [explicit] Section 6 states, "This raises the potential hypothesis that perhaps context may be more beneficial for DRC of certain explicitly marked relations."
- Why unresolved: The error analysis observed a correlation between winning relations and explicit connectives, but the study did not isolate and compare performance gains for explicit versus implicit relation subsets
- What evidence would resolve it: An ablation study comparing the F1 score improvements of structured context specifically on explicit relations versus implicit relations within the same dataset

### Open Question 2
- Question: Can an automated pipeline using predicted discourse graphs select context effectively without losing the performance gains observed with ground-truth "Oracle" context?
- Basis in paper: [explicit] Footnote 8 in Section 3.2 notes: "in practice we would need an initial method to compute a discourse graph connecting EDUs. We leave this to further work."
- Why unresolved: The beneficial "OR1" results relied on gold-standard annotations (Oracle) to identify context; the impact of using noisy, automatically parsed discourse structures for context selection remains unknown
- What evidence would resolve it: An end-to-end evaluation where the context selection mechanism is driven by an automatic discourse parser rather than human annotations

### Open Question 3
- Question: Does the utility of discourse-structured context increase when applied to full-length scientific documents rather than short abstracts?
- Basis in paper: [explicit] Section 5.3 states: "We posit that when considering longer documents, the effect of structured context in DRC may be more pronounced."
- Why unresolved: The experiments were limited to abstracts (SciDTB, CovDTB), which the authors note often contain simpler, short-distance dependencies (61% adjacent relations) that may require less context
- What evidence would resolve it: A comparative study of DRC performance with and without structured context on full-paper datasets, analyzing the correlation between document length and context utility

### Open Question 4
- Question: Can advanced inference methods, such as chain-of-thought prompting or reasoning models (e.g., GPT-o1), improve the poor baseline performance of LLMs on this task?
- Basis in paper: [explicit] Section 7 states: "In the future, we intend to include LLMs that include some reasoning capability... as well as techniques like chain of thought..."
- Why unresolved: Current results showed that standard LLM inference (even with In-Context Learning) performed poorly (Macro-F1 of 22-32) compared to fine-tuned PLMs, indicating standard prompting is insufficient
- What evidence would resolve it: Benchmarking the performance of reasoning-capable LLMs against the standard zero-shot/few-shot baselines established in the paper

## Limitations

- The study's conclusions depend critically on access to gold discourse trees, which are rarely available outside annotated corpora
- LLM results are based on single trials due to cost constraints, preventing assessment of variance or robustness
- The finding that adjacent text context often hurts performance may be specific to the corpus characteristics (e.g., SciDTB's high proportion of adjacent relations in discourse trees)
- No evaluation of automatic discourse parsing for context selection, leaving practical applicability uncertain

## Confidence

- **High confidence**: Discourse-structured context (OR1) improves classification accuracy over no context, particularly for explicit relations and relations like elaboration, comparison, attribution, and temporal
- **Medium confidence**: Adjacent text context (AD1) generally degrades performance because it introduces irrelevant information
- **Medium confidence**: LLM-based inference with in-context learning is significantly less effective than PLM fine-tuning for this task

## Next Checks

1. **Automatic Discourse Parsing Evaluation**: Replace oracle discourse trees with outputs from an automatic discourse parser (e.g., the parser used in DISRPT 2023) and measure how much performance degrades
2. **Adjacent Context Quality Analysis**: Analyze cases where AD1 context helps versus hurts by examining the semantic similarity between adjacent sentences and the argument pair
3. **LLM Variance Assessment**: Run GPT-4 and Llama 3.1 inference with 5-10 random seeds (or equivalent sampling) to establish confidence intervals around the reported macro-F1 scores