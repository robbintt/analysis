---
ver: rpa2
title: The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions
arxiv_id: '2402.13927'
source_url: https://arxiv.org/abs/2402.13927
tags:
- source
- hedge
- learning
- algorithm
- sources
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how humans learn to trust information sources
  when exposed to diverse, potentially conflicting opinions, often without access
  to ground-truth labels. The authors extend the classic hedge algorithm from machine
  learning to create a "delusional hedge" model that can learn from both labeled and
  unlabeled data by generating a "delusional loss" based on source agreement when
  labels are unavailable.
---

# The Delusional Hedge Algorithm as a Model of Human Learning from Diverse Opinions

## Quick Facts
- arXiv ID: 2402.13927
- Source URL: https://arxiv.org/abs/2402.13927
- Reference count: 5
- Humans effectively incorporate both labeled and unlabeled information in a manner consistent with the delusional hedge algorithm when learning from diverse opinions.

## Executive Summary
This study investigates how humans learn to trust information sources when exposed to diverse, potentially conflicting opinions, often without access to ground-truth labels. The authors extend the classic hedge algorithm from machine learning to create a "delusional hedge" model that can learn from both labeled and unlabeled data by generating a "delusional loss" based on source agreement when labels are unavailable. In two experiments, participants learned to judge fruit edibility based on opinions from three sources with varying accuracy. The delusional hedge model better predicted human behavior than both the standard hedge algorithm (which only learns from labeled data) and a heuristic baseline.

## Method Summary
Participants judged fruit edibility based on opinions from three sources with different decision boundaries. The delusional hedge algorithm updates trust weights using 0-1 loss on labeled trials and a delusional loss (α × trust-weighted disagreement) on unlabeled trials. The model includes hyperparameters for learning rate η and delusional weight α, both fitted per participant via maximum likelihood estimation. Two experiments tested fully unsupervised learning and semi-supervised learning with varying label availability.

## Key Results
- In fully unsupervised conditions, humans showed learning patterns consistent with the delusional hedge model
- Trust judgments in semi-supervised settings aligned with predictions that source agreement with reliable sources influenced learning
- The delusional hedge model better predicted human behavior than standard hedge or heuristic baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Humans can learn source reliability without ground-truth labels by using source agreement as a proxy signal.
- Mechanism: The delusional loss computes disagreement-weighted updates: when source k disagrees with collectively high-trust sources, k's weight decreases proportional to the summed trust of disagreeing sources.
- Core assumption: Source agreement correlates with correctness often enough that consensus among trusted sources provides a usable surrogate for missing labels.
- Evidence anchors: [abstract] "Results indicate that humans effectively incorporate both labeled and unlabeled information..."; [Experiment 1 Results] Middle source received highest trust because it was most frequently in the majority.

### Mechanism 2
- Claim: Trust propagates from verified-accurate sources to sources that consistently agree with them, even on unlabeled trials.
- Mechanism: High trust in Near source "bleeds over" to Middle source on unlabeled trials when Middle consistently agrees—the delusional loss penalizes disagreement with high-trust sources more heavily than disagreement with low-trust sources.
- Core assumption: Agreement patterns on unlabeled data provide incremental evidence about source reliability, not just noise.
- Evidence anchors: [Experiment 2 Discussion] "Unlabelled trials increased the trust given to an initially-untrusted source that often agrees with a more-trusted source."; [Experiment 2 Results] Trust in Middle exceeded Far when Middle agreed with Near more often.

### Mechanism 3
- Claim: Human learners weight labeled and unlabeled information differently, with a tunable sensitivity parameter.
- Mechanism: The α hyperparameter scales delusional loss relative to true 0-1 loss; humans appear to have non-zero α, but the paper fits α per-participant rather than estimating a population value.
- Core assumption: Humans have an implicit α-like mechanism that balances supervised vs. unsupervised learning signals.
- Evidence anchors: [Algorithm 1] "The delusional loss is weighted by a free hyperparameter α > 0"; [Model Fitting] "We tuned the hyperparameters η (and α, if applicable) for each participant using maximum likelihood estimation."

## Foundational Learning

- Concept: **Hedge Algorithm / Weighted Majority Voting**
  - Why needed here: The entire framework extends this classic online learning algorithm; understanding softmax trust updates and regret bounds is prerequisite.
  - Quick check question: Can you explain why the hedge algorithm's regret bound is O(√T log K) and what happens when no labels are available?

- Concept: **Semi-Supervised Learning (SSL)**
  - Why needed here: The core contribution is extending hedge to SSL settings; need to understand why unlabeled data can be informative.
  - Quick check question: What assumptions make unlabeled data useful for learning, and when would adding unlabeled data hurt performance?

- Concept: **0-1 Loss and Expected Loss Under Distributional Assumptions**
  - Why needed here: The delusional loss is defined as expected 0-1 loss under a Bernoulli distribution parameterized by current trust weights.
  - Quick check question: If qt,1 = 0.7, what is the expected 0-1 loss for a source predicting -1?

## Architecture Onboarding

- Component map: **Opinion aggregator -> Loss computer -> Trust weight updater**
- Critical path:
  1. Receive K binary opinions (b1t, ..., bKt)
  2. Aggregate into q_t probabilities
  3. Sample prediction ŷt ~ Bernoulli(qt,1)
  4. If labeled: compute true loss 1[btk ≠ yt]; else compute delusional loss α × qt,-btk
  5. Update cumulative losses, recompute trust weights for next trial
- Design tradeoffs:
  - α = 0 (standard hedge): No learning from unlabeled data, but no risk of reinforcing wrong consensus
  - α high: Fast adaptation to unlabeled data, but vulnerable to systematic source collusion
  - Assumption: Optimal α likely depends on true source accuracy correlation with majority; not analyzed in paper
- Failure signatures:
  - **Uniform trust collapse**: In fully unsupervised settings, standard hedge (α=0) never updates, stuck at uniform trust
  - **Majority-over-accuracy trap**: Delusional hedge favors majority-agreeing sources over accurate minorities when labels are sparse
  - **Trust polarization**: If two high-trust sources systematically disagree, delusional loss can amplify differences
- First 3 experiments:
  1. Replicate Experiment 1 with manipulated source accuracy correlation: Vary whether majority opinion correlates with ground truth; test if human α adapts or stays fixed.
  2. Adversarial source condition: Introduce a source that agrees with majority on unlabeled trials but is wrong on labeled trials; test whether trust propagates incorrectly.
  3. Cross-domain transfer: After learning source trust in one domain (fruit edibility), test whether trust transfers to new domain with same sources; assess whether trust is source-specific or context-dependent.

## Open Questions the Paper Calls Out

- Question: What are the formal regret bounds and convergence guarantees for the delusional hedge algorithm in semi-supervised settings?
- Basis in paper: [explicit] The conclusion states that this work is a starting point that can be "extended through formal analysis of the delusional hedge itself."
- Why unresolved: The authors note the standard hedge algorithm has established worst-case regret bounds ($O(\sqrt{T}\log K)$), but they provide no theoretical proof of convergence or regret bounds for their proposed delusional variant.
- What evidence would resolve it: A mathematical proof characterizing the theoretical regret bound of the delusional hedge algorithm under various ratios of labeled to unlabeled data.

## Limitations
- The experiments use a simplified 1D categorization task with only three sources, limiting ecological validity for complex social learning scenarios.
- The model assumes source reliability is stationary, ignoring real-world dynamics where source trustworthiness may change over time.
- The α parameter is fitted per participant without analyzing population-level distributions or testing whether α varies systematically with supervision level.

## Confidence
- Claim: Delusional hedge better predicts human learning than standard hedge or heuristic baselines - **High**
- Claim: Humans use source agreement as a proxy for correctness when labels are unavailable - **Medium**
- Claim: Trust propagates from reliable to agreeing sources on unlabeled data - **Medium**
- Claim: Humans have an implicit α-like mechanism balancing supervised/unsupervised signals - **Low**

## Next Checks
1. Implement Algorithm 1 exactly as specified and verify trust weight updates match paper's reported patterns
2. Generate stimulus sequences matching Figure 1 setup and reproduce the trust patterns for the three sources
3. Fit η and α parameters per participant using MLE and verify the likelihood ratio tests show delusional hedge outperforms standard hedge