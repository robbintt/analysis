---
ver: rpa2
title: Depth-Wise Activation Steering for Honest Language Models
arxiv_id: '2512.07667'
source_url: https://arxiv.org/abs/2512.07667
tags:
- steering
- honesty
- gaussian
- depth
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of large language models asserting\
  \ falsehoods despite internally representing the correct answer\u2014failures of\
  \ honesty rather than accuracy\u2014which undermines auditability and safety. The\
  \ authors introduce a training-free activation steering method that weights steering\
  \ strength across network depth using a Gaussian schedule."
---

# Depth-Wise Activation Steering for Honest Language Models

## Quick Facts
- arXiv ID: 2512.07667
- Source URL: https://arxiv.org/abs/2512.07667
- Reference count: 6
- Key outcome: Gaussian depth-wise activation steering improves honesty on the MASK benchmark in six of seven models, outperforming uniform, random, and box-filter depth allocations.

## Executive Summary
This paper tackles the problem of large language models asserting falsehoods despite internally representing the correct answer—failures of honesty rather than accuracy. The authors propose a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. Tested on seven models from the LLaMA, Qwen, and Mistral families, the method improves honesty on the MASK benchmark, which separates honesty from knowledge. Equal-budget ablations confirm the Gaussian schedule's superiority over alternative depth allocations. The approach is model-agnostic, requires no fine-tuning, and offers a low-cost control knob for eliciting truthful reporting from models' existing capabilities.

## Method Summary
The authors introduce depth-wise activation steering, which injects steering vectors into residual streams at specific layers, weighted by a Gaussian schedule across depth. This method leverages the observation that honesty failures often occur when models misrepresent internal knowledge rather than lack it. By distributing steering strength according to a Gaussian curve, the approach aims to correct misrepresentations at the right stage of processing. The method is training-free, model-agnostic, and requires only per-layer steering strength injection, making it applicable to any model with accessible activations.

## Key Results
- Gaussian depth scheduling improves honesty on MASK in six of seven evaluated models (LLaMA, Qwen, Mistral families).
- Equal-budget ablations show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations in LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct.
- No fine-tuning or model-specific adaptation is required, making the method broadly applicable and low-cost.

## Why This Works (Mechanism)
The paper does not provide a detailed mechanism for why Gaussian depth scheduling outperforms other allocations. The authors observe empirically that distributing steering strength according to a Gaussian curve is more effective than uniform, random, or box-filter approaches, but do not offer a theoretical or mechanistic explanation for this superiority.

## Foundational Learning
- **Activation steering**: A method to guide model outputs by injecting steering vectors into residual streams at specific layers. Needed to intervene in model processing without retraining. Quick check: Verify that steering vectors are correctly applied at the intended layers.
- **Honesty vs. accuracy**: Honesty refers to truthfully reporting internal knowledge, while accuracy is about correctness. Needed to frame the problem as misrepresentation rather than knowledge gaps. Quick check: Ensure benchmarks distinguish between these concepts.
- **Residual stream manipulation**: Modifying intermediate representations by injecting steering vectors. Needed for the core intervention mechanism. Quick check: Confirm that injected vectors propagate as expected through layers.
- **Gaussian scheduling**: Allocating steering strength according to a Gaussian curve across network depth. Needed to test depth-wise effects on honesty. Quick check: Validate the Gaussian weights sum to the intended total strength.
- **MASK benchmark**: A test suite separating honesty from knowledge in model outputs. Needed to evaluate the method's effectiveness on its intended target. Quick check: Confirm benchmark tasks are correctly labeled and scored.

## Architecture Onboarding
- **Component map**: Input tokens → Embedding layer → Residual stream (L0) → Residual stream (L1) → ... → Residual stream (LN) → Output layer → Logits. Steering vectors injected at each Li.
- **Critical path**: Token embedding → stacked transformer layers with residual connections → steering vector injection → final output. Honesty failures likely occur mid-stack where knowledge is available but not reported.
- **Design tradeoffs**: Gaussian scheduling trades off fine-grained control for simplicity and generality. Uniform or random schedules are simpler but less effective. Learned schedules could be optimal but require training.
- **Failure signatures**: Honesty failures manifest as confident assertions of known falsehoods; steering may over-correct, leading to hedging or underconfidence. Layer-wise probing can reveal where steering has most impact.
- **First experiments**: (1) Apply Gaussian steering to a single model on MASK and verify honesty gains. (2) Test uniform and random schedules on the same model for ablation. (3) Probe layer-wise feature separability to correlate with steering effectiveness.

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does Gaussian depth scheduling improve honesty on safety benchmarks beyond MASK, such as Machiavelli or TruthfulQA?
- Basis in paper: "Future work should validate the approach across a broader range of safety benchmarks, such as Machiavelli [Pan et al., 2023]."
- Why unresolved: Experiments focused solely on MASK; generalizability to benchmarks measuring different aspects of honesty/safety remains untested.
- What evidence would resolve it: Apply the same Gaussian steering protocol to Machiavelli and other benchmarks, reporting comparative gains.

### Open Question 2
- Question: Can activation-level steering methods be adapted for closed-weight models without direct layer access?
- Basis in paper: "The method requires activation-level access to language model's layers and the ability to inject per-layer steering strengths, which restricts its applicability to open-weight models."
- Why unresolved: The approach fundamentally depends on modifying residual streams at specific layers, which is impossible with API-only access.
- What evidence would resolve it: Develop proxy methods (e.g., prompt-based or output-space interventions) that approximate depth-wise effects and test on closed models.

### Open Question 3
- Question: Why does the Gaussian depth schedule outperform uniform, random, and box-filter allocations when total steering budget is held constant?
- Basis in paper: Equal-budget ablations show Gaussian superiority, but the paper does not provide a mechanistic or theoretical explanation for why this specific shape is optimal.
- Why unresolved: The empirical finding is demonstrated, but the underlying cause (e.g., alignment with how representations evolve across layers) remains unexplained.
- What evidence would resolve it: Layer-wise probing of feature separability, or analysis of how steering vectors interact with residual stream geometry across depth.

## Limitations
- Improvements are measured only on the MASK benchmark, limiting generalizability to naturalistic or adversarial settings.
- The method requires activation-level access, restricting use to open-weight models.
- No explanation is provided for why Gaussian scheduling is superior to other depth allocations.

## Confidence
- Honesty gains are demonstrated but only on a single benchmark (Low).
- Gaussian scheduling outperforms baselines in equal-budget ablations (Medium).
- Method is training-free and broadly applicable (High).

## Next Checks
1. Test the Gaussian depth scheduling on adversarial prompt sets and long-form generations to assess robustness beyond MASK.
2. Compare against learned or adaptive depth-weighting methods to evaluate whether the Gaussian form is optimal.
3. Investigate the long-term effects of repeated activation steering on model behavior and representation stability.