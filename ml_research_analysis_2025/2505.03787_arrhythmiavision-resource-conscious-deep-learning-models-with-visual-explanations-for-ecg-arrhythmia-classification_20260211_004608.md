---
ver: rpa2
title: 'ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations
  for ECG Arrhythmia Classification'
arxiv_id: '2505.03787'
source_url: https://arxiv.org/abs/2505.03787
tags:
- arrhythmia
- classification
- arrhythminet
- these
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of real-time, interpretable
  ECG arrhythmia classification for resource-constrained environments like wearable
  devices. The authors propose two lightweight 1D CNN models, ArrhythmiNet V1 and
  V2, inspired by MobileNet's depthwise separable convolutions, achieving memory footprints
  of 302.18 KB and 157.76 KB respectively.
---

# ArrhythmiaVision: Resource-Conscious Deep Learning Models with Visual Explanations for ECG Arrhythmia Classification

## Quick Facts
- **arXiv ID**: 2505.03787
- **Source URL**: https://arxiv.org/abs/2505.03787
- **Reference count**: 40
- **Primary result**: Lightweight 1D CNN models (302KB, 158KB) achieve 0.99/0.98 accuracy on 5-class MIT-BIH arrhythmia classification with interpretable visual explanations.

## Executive Summary
This study addresses the challenge of real-time, interpretable ECG arrhythmia classification for resource-constrained environments like wearable devices. The authors propose two lightweight 1D CNN models, ArrhythmiNet V1 and V2, inspired by MobileNet's depthwise separable convolutions, achieving memory footprints of just 302.18 KB and 157.76 KB respectively. Evaluated on the MIT-BIH Arrhythmia Dataset across five classes, the models achieve high accuracy: 0.99 for V1 and 0.98 for V2. Interpretability is enhanced through integration of SHAP and Grad-CAM, providing clinically meaningful explanations by highlighting key ECG waveform features like the QRS complex and T-wave. The work demonstrates the feasibility of combining computational efficiency, high predictive performance, and transparency in automated ECG analysis systems.

## Method Summary
The authors developed two compact 1D CNN architectures for ECG arrhythmia classification using depthwise separable convolutions to reduce computational complexity while preserving temporal morphology. Both models process 1-second (360-sample) ECG segments after wavelet-based denoising with Symlet 4. ArrhythmiNet V1 uses five convolutional blocks with depthwise separable convolutions, while V2 employs seven bottleneck blocks with skip connections. The models are trained on the MIT-BIH Arrhythmia Dataset with five classes (NSR, LBBB, PVC, APC, RBBB) and evaluated using accuracy, F1-score, sensitivity, and specificity metrics. Interpretability is provided through Grad-CAM for temporal region localization and SHAP for point-wise feature attribution.

## Key Results
- ArrhythmiNet V1 achieves 0.99 accuracy with 302.18 KB memory footprint
- ArrhythmiNet V2 achieves 0.98 accuracy with 157.76 KB memory footprint
- V2 shows faster convergence (59s vs 86s per epoch) and broader temporal context
- Both models demonstrate clinically meaningful explanations highlighting QRS complexes and T-waves

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Depthwise separable convolutions reduce parameter count while preserving ECG morphology detection.
- Mechanism: By decomposing standard convolutions into depthwise (spatial filtering per channel) followed by pointwise (channel mixing), the architecture reduces parameters by factor `1/C_out + 1/k`. For 1D ECG signals, this preserves temporal dynamics while cutting computational cost.
- Core assumption: ECG arrhythmia classification relies more on morphological features (QRS shape, T-wave) than complex cross-channel interactions.
- Evidence anchors:
  - [abstract] "Inspired by MobileNet's depthwise separable convolutional design, these models maintain memory footprints of just 302.18 KB and 157.76 KB."
  - [Section 3.2.1] Equation (1) demonstrates parameter reduction ratio; Table 2 quantifies MAC operation savings.
  - [corpus] Related work on compact networks (arXiv:2412.17852) similarly achieves efficiency through architectural compression, though using different techniques.
- Break condition: If multi-lead ECG inputs are required (current study uses single-lead), cross-lead dependencies may need standard convolutions to capture spatial relationships.

### Mechanism 2
- Claim: Wavelet-based denoising with Symlet 4 preserves clinically relevant QRS and T-wave morphology better than frequency-domain filtering.
- Mechanism: Wavelet decomposition separates signal into approximation and detail coefficients; thresholding detail coefficients suppresses noise while retaining transient morphological features that Fourier methods might smear.
- Core assumption: The diagnostically critical information in ECG signals is localized in time (e.g., QRS spikes) rather than uniformly distributed.
- Evidence anchors:
  - [abstract] "The architectures are specifically designed to preserve the spatial morphology and temporal dynamics of ECG signals."
  - [Section 3.1.2] "This wavelet-based approach helps preserve characteristic features such as QRS complexes and T-wave segments."
  - [corpus] Weak direct evidence—neighboring papers mention signal processing but don't compare wavelet approaches.
- Break condition: If ECG signals contain high-frequency pathological features overlapping with noise spectrum, threshold selection becomes critical and may require adaptive methods.

### Mechanism 3
- Claim: Grad-CAM and SHAP provide complementary interpretability—Grad-CAM for temporal region localization, SHAP for point-wise feature attribution.
- Mechanism: Grad-CAM computes gradients of class scores w.r.t. final convolutional features, producing heatmaps highlighting influential time segments. SHAP uses game-theoretic Shapley values to quantify each time-point's contribution.
- Core assumption: Clinicians need both "where to look" (Grad-CAM) and "how much each feature contributes" (SHAP) for trust and debugging.
- Evidence anchors:
  - [abstract] "These techniques highlight physiologically meaningful patterns—such as the QRS complex and T-wave."
  - [Section 4.2] Grad-CAM captures "highly localized features" (V1) vs. "extended temporal coverage" (V2); SHAP shows "pronounced peaks" at morphological markers.
  - [corpus] arXiv:2508.17294 ("Explainable AI for Arrhythmia detection") similarly applies XAI to ECG but doesn't compare Grad-CAM/SHAP combinations.
- Break condition: If model predictions rely on features outside annotated waveform regions (e.g., noise artifacts learned as discriminative), explanations may mislead rather than clarify.

## Foundational Learning

- Concept: **Depthwise Separable Convolutions**
  - Why needed here: Core architectural efficiency mechanism; understanding the decomposition into depthwise + pointwise operations is essential for modifying or debugging the models.
  - Quick check question: Given input channels=64, output channels=128, kernel size=3, what's the parameter ratio between standard and depthwise separable convolution?

- Concept: **ECG Morphology (PQRST Waveform)**
  - Why needed here: Model interpretability evaluation relies on whether highlighted regions correspond to clinically meaningful features (QRS complex, T-wave, P-wave).
  - Quick check question: What morphological feature distinguishes LBBB (shows "M" pattern) from normal sinus rhythm?

- Concept: **Shapley Values**
  - Why needed here: SHAP explanations require understanding feature attribution from cooperative game theory; interpreting outputs correctly depends on knowing what "contribution" means.
  - Quick check question: If SHAP value for time-point t is 0.15 for class "PVC," what does this quantify?

## Architecture Onboarding

- Component map: Input (360 samples) → Wavelet Denoising → Normalization → [Conv Block × 5] → Global Average Pooling → Softmax (5 classes)

- Critical path: Input preprocessing (wavelet denoising quality) → Feature extraction (depthwise convolutions) → Classification head. The 360-sample input window corresponds to 1 second at 360Hz sampling rate.

- Design tradeoffs:
  - V1 (302KB, 99% accuracy): More localized feature extraction, better for distinct morphological patterns
  - V2 (158KB, 98% accuracy): Broader temporal context, faster convergence (59s vs 86s/epoch), slightly lower NSR recall
  - Paper notes V2 shows "affinity to arrhythmic classes" (more false positives flagging NSR as abnormal)

- Failure signatures:
  - NSR ↔ LBBB confusion (morphological similarity)
  - SHAP responses "diffuse" in misclassification cases
  - Grad-CAM may miss "diffuse morphological alterations" (e.g., PVC) with narrow temporal windows

- First 3 experiments:
  1. **Baseline replication**: Train V1 on MIT-BIH with provided preprocessing; verify ~99% accuracy and 302KB footprint. Check Grad-CAM highlights QRS region for PVC class.
  2. **Ablation on wavelet denoising**: Replace Symlet 4 with raw signal or simple bandpass filter; measure accuracy drop and SHAP attribution shift to noise regions.
  3. **Cross-dataset probe**: Test trained model on a different ECG dataset (e.g., PTB-XL) to assess generalization gap—paper explicitly notes this as a limitation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do ArrhythmiNet models perform on external ECG datasets beyond MIT-BIH, particularly across diverse populations and recording conditions?
- Basis in paper: [explicit] The conclusion states: "Future work will address this limitation by validating our models on external datasets" and the abstract mentions "current limitations related to dataset diversity and generalizability."
- Why unresolved: The study only evaluates on the MIT-BIH Arrhythmia Dataset, which has known class imbalance and may not represent the full spectrum of real-world ECG variability (different populations, noise conditions, recording equipment).
- What evidence would resolve it: Performance metrics (accuracy, F1-score, sensitivity, specificity) on at least 2-3 independent ECG datasets such as PTB-XL, INCART, or AHA databases, with demographic stratification analysis.

### Open Question 2
- Question: Can the qualitative interpretability assessments from Grad-CAM and SHAP be quantified to enable objective comparison of explanation quality across models?
- Basis in paper: [explicit] The conclusion explicitly calls for "refining the XAI framework with more rigorous quantitative assessments."
- Why unresolved: The current XAI evaluation relies on visual inspection and clinical plausibility (e.g., whether QRS complex is highlighted), without quantitative metrics measuring explanation fidelity, consistency, or alignment with ground-truth clinical annotations.
- What evidence would resolve it: Implementation of quantitative XAI metrics such as attribution localization accuracy (IoU with annotated waveform segments), explanation stability tests, or clinical expert scoring systems with inter-rater reliability.

### Open Question 3
- Question: What are the actual latency, energy consumption, and inference throughput when deployed on real embedded hardware platforms?
- Basis in paper: [inferred] The paper reports model size (157-302 KB) and training time, but provides no measurements of on-device inference latency, power draw, or throughput on target wearable/embedded platforms (e.g., ARM Cortex-M, low-power DSPs).
- Why unresolved: Memory footprint alone is insufficient to determine real-time feasibility; computational complexity (MAC operations) and actual hardware performance determine whether the models can meet the stated goal of real-time classification on resource-constrained devices.
- What evidence would resolve it: Benchmarks on representative edge hardware (e.g., STM32, NRF52840, or smartphone processors) reporting inference time per beat, energy per inference, and maximum sustainable sampling rate.

### Open Question 4
- Question: Does extending the architecture to multi-lead ECG inputs improve classification accuracy for arrhythmias that require spatial information across leads?
- Basis in paper: [explicit] The conclusion acknowledges: "The current work is limited to single-lead ECG signals, which may not fully capture the diagnostic information available in multi-lead recordings" and proposes "extending the architectures to process multi-lead ECG inputs."
- Why unresolved: Certain arrhythmias (e.g., some forms of bundle branch blocks, myocardial infarction localization) are diagnosed using lead-specific morphological patterns that single-lead analysis cannot capture.
- What evidence would resolve it: Comparative study using 12-lead or 3-lead ECG datasets showing whether multi-lead extensions improve sensitivity/specificity for classes where spatial information matters, while maintaining efficiency constraints.

## Limitations

- Single dataset validation (MIT-BIH only) limits generalizability across populations and recording conditions
- Qualitative interpretability assessment without quantitative metrics for explanation quality
- No real-world deployment testing on actual embedded hardware platforms

## Confidence

- **High**: Computational efficiency metrics (memory footprint and MAC operations are directly measurable)
- **Medium**: Classification accuracy (single dataset validation, potential overfitting to MIT-BIH distribution)
- **Medium**: Interpretability claims (visual inspection aligns with expected ECG morphology but lacks clinical expert validation)

## Next Checks

1. **Cross-dataset generalization**: Evaluate both models on PTB-XL or CPSC2018 datasets to quantify performance degradation and assess real-world applicability.

2. **Clinical expert review**: Have cardiologists validate whether SHAP and Grad-CAM explanations correctly identify diagnostically relevant features across all five arrhythmia classes.

3. **Noise robustness test**: Introduce varying levels of baseline wander and electrode motion artifacts to assess model performance degradation and whether interpretability tools remain reliable under noisy conditions.