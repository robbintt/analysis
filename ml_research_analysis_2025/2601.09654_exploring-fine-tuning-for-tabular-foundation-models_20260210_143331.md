---
ver: rpa2
title: Exploring Fine-Tuning for Tabular Foundation Models
arxiv_id: '2601.09654'
source_url: https://arxiv.org/abs/2601.09654
tags:
- fine-tuning
- tabular
- zero-shot
- learning
- orionmsp
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically evaluates fine-tuning strategies for
  tabular foundation models across performance, calibration, and fairness. While zero-shot
  inference often matches or exceeds fine-tuned performance, meta-learning provides
  moderate gains, particularly on imbalanced or medium-sized datasets.
---

# Exploring Fine-Tuning for Tabular Foundation Models

## Quick Facts
- **arXiv ID:** 2601.09654
- **Source URL:** https://arxiv.org/abs/2601.09654
- **Reference count:** 32
- **Key outcome:** Zero-shot inference often matches or exceeds fine-tuned performance; meta-learning offers moderate gains, especially on imbalanced or medium-sized datasets; TabPFN benefits most from fine-tuning, while OrionMSP and TabDPT excel in zero-shot and meta-learning regimes.

## Executive Summary
This study systematically evaluates fine-tuning strategies for tabular foundation models across performance, calibration, and fairness. While zero-shot inference often matches or exceeds fine-tuned performance, meta-learning provides moderate gains, particularly on imbalanced or medium-sized datasets. Full supervised fine-tuning frequently degrades accuracy and calibration, with TabPFN being an exception. Parameter-efficient fine-tuning (PEFT) offers a stable alternative, balancing performance gains with efficiency. TabPFN benefits most from fine-tuning, especially in high-dimensional settings, while OrionMSP and TabDPT excel in zero-shot and meta-learning regimes. Overall, fine-tuning is highly model- and data-dependent, with zero-shot inference remaining competitive and preferable in low-data regimes or when calibration and fairness are priorities.

## Method Summary
The study evaluates fine-tuning strategies for six tabular foundation models (TabPFN, TabICL, OrionMSP, OrionBiX, TabDPT, Mitra) across three benchmark suites (TALENT, OpenML-CC18, TabZilla) and nine fairness datasets. Zero-shot inference serves as baseline, with meta-learning using episodic training (48–512 support samples/episode, 5 epochs), supervised fine-tuning (AdamW, LR 1e-5 to 5e-5, ≤10 epochs), and PEFT-LoRA (rank r=8, α=16) as fine-tuning strategies. Performance metrics include accuracy, weighted F1, mean rank, calibration (ECE, MCE, Brier Score), and fairness (SPD, EOD, EOpD). The TabTune library and AutoGluon are used for model implementation, with experiments run on NVIDIA L40S and H200 GPUs.

## Key Results
- Zero-shot inference frequently matches or exceeds fine-tuned performance, especially for OrionMSP and TabDPT
- Meta-learning provides moderate gains, particularly on imbalanced or medium-sized datasets
- Full supervised fine-tuning often degrades accuracy and calibration, except for TabPFN
- PEFT-LoRA offers a stable alternative, balancing performance gains with efficiency
- TabPFN benefits most from fine-tuning, especially in high-dimensional settings

## Why This Works (Mechanism)
Fine-tuning tabular foundation models works by adapting pre-trained representations to specific datasets and tasks. The effectiveness depends on the interplay between model architecture, dataset characteristics, and fine-tuning strategy. Zero-shot inference leverages general tabular understanding, while fine-tuning attempts to specialize this knowledge. Meta-learning provides few-shot adaptation, and PEFT reduces computational overhead while maintaining performance. The study reveals that model architecture significantly influences which fine-tuning approach is most effective, with TabPFN excelling under fine-tuning and OrionMSP/TabDPT performing well with minimal adaptation.

## Foundational Learning
- **Tabular Foundation Models:** Pre-trained models designed to understand tabular data structure and relationships. Needed because traditional ML requires task-specific training, while TFMs aim to generalize across tabular tasks. Quick check: Verify model can perform zero-shot inference on unseen tabular datasets.
- **Meta-Learning:** Episodic training strategy that learns to adapt quickly to new tasks from few examples. Needed for low-data regimes where traditional fine-tuning overfits. Quick check: Confirm episodic support/query split and that model improves with more episodes.
- **Parameter-Efficient Fine-Tuning (PEFT):** Techniques like LoRA that adapt models with minimal parameter updates. Needed to reduce computational costs while maintaining performance gains. Quick check: Verify rank r=8 LoRA configuration and that parameter count is significantly reduced versus full fine-tuning.

## Architecture Onboarding
- **Component Map:** Datasets (TALENT/OpenML-CC18/TabZilla) -> TFMs (TabPFN/TabICL/OrionMSP/OrionBiX/TabDPT/Mitra) -> Fine-Tuning Strategies (Zero-Shot/Meta-Learning/SFT/PEFT) -> Evaluation Metrics (Performance/Calibration/Fairness)
- **Critical Path:** Data preparation → Zero-shot baseline → Meta-learning (48-512 support, 5 epochs) → SFT (AdamW, LR 1e-5-5e-5, ≤10 epochs) → PEFT-LoRA (r=8, α=16) → Metric evaluation
- **Design Tradeoffs:** Zero-shot (no cost, often competitive) vs SFT (high cost, inconsistent gains) vs PEFT (moderate cost, stable improvements) vs Meta-learning (few-shot, moderate gains)
- **Failure Signatures:** SFT causing accuracy drops >5-10% on small datasets; ECE/MCE spikes post-fine-tuning; calibration degradation with SFT
- **First Experiments:** 1) Run zero-shot inference for all TFMs on TALENT benchmark; 2) Implement meta-learning with 48 support samples and measure performance gains; 3) Apply PEFT-LoRA (r=8) to TabPFN and compare against SFT results

## Open Questions the Paper Calls Out
None

## Limitations
- Limited specification of fine-tuning hyperparameters (learning rates, batch sizes, patience thresholds)
- Potential confounding from different data subsets across benchmarks
- Incomplete reporting of which models support PEFT
- Only three fairness datasets explicitly named, with six others unspecified
- No analysis of computational costs or scalability beyond GPU types

## Confidence
- **High:** Zero-shot inference remains competitive across most settings, particularly for OrionMSP and TabDPT
- **Medium:** Magnitude of meta-learning performance gains, due to unspecified episodic training configurations
- **Low:** Claims about fairness improvements, given only three datasets explicitly named

## Next Checks
1. Replicate key findings using TabTune's standardized pipelines to confirm that zero-shot inference matches or exceeds SFT performance for OrionMSP and TabDPT on TALENT and OpenML-CC18 datasets.

2. Systematically vary support set sizes (48-512 samples) in meta-learning to quantify the relationship between few-shot training data and performance gains, particularly on imbalanced datasets.

3. Test PEFT-LoRA with multiple rank configurations (r=4, 8, 16) to establish whether the reported r=8 setting represents an optimal balance between parameter efficiency and performance gains across different model architectures.