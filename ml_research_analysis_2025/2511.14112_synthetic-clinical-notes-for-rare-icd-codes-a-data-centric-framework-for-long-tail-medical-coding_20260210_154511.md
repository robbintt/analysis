---
ver: rpa2
title: 'Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for
  Long-Tail Medical Coding'
arxiv_id: '2511.14112'
source_url: https://arxiv.org/abs/2511.14112
tags:
- codes
- synthetic
- code
- rare
- summaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the long-tail problem in automatic ICD coding,
  where thousands of rare and zero-shot diagnostic codes are severely underrepresented
  in datasets like MIMIC-III, leading to low macro-F1 scores. The authors propose
  a data-centric framework that generates high-quality synthetic discharge summaries
  to improve the representation of rare codes.
---

# Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding

## Quick Facts
- arXiv ID: 2511.14112
- Source URL: https://arxiv.org/abs/2511.14112
- Reference count: 3
- Primary result: Generated 90,000 synthetic discharge summaries covering 7,902 ICD codes, improving macro-F1 by 0.7-0.9 points while maintaining micro-F1

## Executive Summary
This paper addresses the long-tail problem in automatic ICD coding, where thousands of rare and zero-shot diagnostic codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. The authors propose a data-centric framework that generates high-quality synthetic discharge summaries to improve the representation of rare codes. Their method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, they generate 90,000 synthetic notes covering 7,902 ICD codes. Experiments show that fine-tuning state-of-the-art transformer-based models (PLM-ICD and GKI-ICD) on the augmented dataset modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain is marginal relative to computational cost, the results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

## Method Summary
The authors propose a data-centric framework to generate synthetic discharge summaries for rare ICD codes. They first stratify codes into frequency tiers (head, medium, tail, ultra-tail) and allocate synthetic samples using log-inverse allocation that prioritizes rarer codes. For few-shot codes, they retrieve real MIMIC summaries containing the rare code and clone their full multi-label sets. For zero-shot codes, they use hierarchical substitution, identifying sibling codes via ICD taxonomy and transferring their comorbidity patterns. They construct structured prompts combining ICD descriptions, synonyms, hierarchy knowledge, and clinical examples, then generate synthetic notes using an LLM. Finally, they fine-tune PLM-ICD and GKI-ICD models on the augmented dataset and evaluate performance improvements.

## Key Results
- Generated 89,952 synthetic discharge summaries covering 7,902 ICD codes from MIMIC-III
- Improved macro-F1 scores by 0.7-0.9 points while maintaining strong micro-F1 performance
- Outperformed prior state-of-the-art methods on both PLM-ICD and GKI-ICD models
- Demonstrated that synthetic data can improve representation of rare codes in long-tail ICD coding

## Why This Works (Mechanism)

### Mechanism 1: Log-Inverse Allocation
Prioritizes synthetic data generation for rarer codes through log-inverse allocation, improving representation of underrepresented ICD codes. The formula `nsynthetic(c) = min(α· 1/log(nreal + 5) ·M, M)` allocates more synthetic examples to codes with fewer real training examples, with zero-shot codes receiving maximum allocation (M=50) and scaling down for more frequent codes. This assumes synthetic examples provide useful learning signals even without real examples. Break condition: If synthetic examples introduce distribution shift that diverges from real clinical patterns, models may learn spurious correlations.

### Mechanism 2: Hierarchical Substitution
Transfers comorbidity patterns from sibling codes to zero-shot codes via hierarchical substitution, creating clinically plausible multi-label sets. For zero-shot codes, the ICD hierarchy identifies clinically related sibling codes, retrieves real summaries containing these siblings, then substitutes the sibling with the target zero-shot code while preserving all co-occurring comorbidities. This assumes sibling codes in the ICD taxonomy share sufficiently similar comorbidity patterns to justify pattern transfer. Break condition: If sibling codes have meaningfully different comorbidity profiles, substitution introduces clinically implausible combinations.

### Mechanism 3: Knowledge-Injection Prompting
Enriches prompts with structured ICD knowledge (descriptions, synonyms, hierarchy) to produce clinically coherent synthetic discharge summaries. Three knowledge forms extracted from ICD metadata—description knowledge, synonym knowledge from UMLS/SNOMED-CT, and hierarchy knowledge—are structured into multi-part prompts along with de-identified clinical examples to guide LLM generation. This assumes the structured knowledge representation captures sufficient diagnostic nuance for LLMs to generate text accurately reflecting all target codes. Break condition: If generated notes contain hallucinated clinical information or fail to represent all codes in multi-label sets, training amplifies errors.

## Foundational Learning

- **Long-tail distribution in multi-label classification**
  - Why needed here: Understanding why macro-F1 (0.132) lags far behind micro-F1 (0.619) on 8,929 codes is essential to interpreting the paper's motivation and results.
  - Quick check question: If a model achieves 99% micro-F1 but 13% macro-F1 on an 8,929-class problem, what does this reveal about per-class performance variance?

- **ICD taxonomy and hierarchical code relationships**
  - Why needed here: The hierarchical substitution strategy depends on understanding parent-child-sibling relationships in ICD coding systems.
  - Quick check question: Given ICD code N18.23 (CKD stage 3), what makes N18.29 (CKD stage 2) a suitable sibling versus a more distant relative like N19 (unspecified kidney failure)?

- **Multi-label co-occurrence patterns**
  - Why needed here: Discharge summaries contain ~6 co-occurring ICD codes on average; generating realistic synthetic data requires understanding comorbidity structure.
  - Quick check question: Why is generating synthetic notes conditioned on single ICD codes insufficient for this task?

## Architecture Onboarding

- **Component map**: Code Frequency Stratification → Log-Inverse Allocation → Anchor-Based Code Set Construction → Knowledge-Injection Prompting → LLM Generation → Synthetic Dataset → Model Fine-tuning

- **Critical path**:
  1. Stratify codes into head/medium/tail/ultra-tail tiers from MIMIC-III training distribution
  2. For each rare code, construct multi-label set via real retrieval (few-shot) or hierarchical substitution (zero-shot)
  3. Extract description, synonym, and hierarchy knowledge from ICD metadata
  4. Assemble structured prompts with code set + knowledge + clinical examples
  5. Generate synthetic notes (LLM inference)
  6. Fine-tune PLM-ICD or GKI-ICD checkpoints on augmented dataset

- **Design tradeoffs**:
  - M=50 max synthetic notes per code balances augmentation coverage vs. computational cost
  - α=0.5 allocation intensity; higher values increase synthetic proportion but risk over-representation
  - Static ICD metadata extraction vs. runtime knowledge graph querying trades infrastructure complexity for retrieval flexibility

- **Failure signatures**:
  - Vague generated language ("abnormal labs") ambiguously mapping to multiple diagnoses
  - Poor code-note alignment where generated text underrepresents certain codes in multi-label sets
  - Marginal macro-F1 gains (+0.7 to +0.9) relative to computational cost (90,000 LLM generations)

- **First 3 experiments**:
  1. Reproduce frequency stratification on a MIMIC-III subset to validate head/medium/tail/ultra-tail distribution statistics
  2. Test hierarchical substitution on 10-20 zero-shot codes to verify sibling retrieval and comorbidity pattern transfer logic
  3. Generate pilot batch of 100 synthetic notes and manually evaluate code-note alignment by checking explicit representation of each target code in generated text

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can selective augmentation targeting only the most clinically critical rare codes achieve comparable macro-F1 improvements to full-scale augmentation while significantly reducing computational cost?
- **Basis in paper**: Authors state in Limitations: "Future work should explore more parameter-efficient approaches, including: (1) selective augmentation targeting only the most clinically critical rare codes."
- **Why unresolved**: The current framework generates 90,000 synthetic notes using log-inverse allocation across all 7,902 rare codes, but the cost-benefit trade-off remains prohibitive for resource-constrained scenarios.
- **What evidence would resolve it**: Experiments comparing macro-F1 gains per compute-hour between full augmentation and targeted augmentation on curated subsets of clinically critical codes.

### Open Question 2
- **Question**: Would combining synthetic data augmentation with architectural innovations specifically designed for long-tail recognition yield synergistic performance gains beyond either approach alone?
- **Basis in paper**: Authors propose in Limitations: "(2) hybrid methods combining synthetic data with architectural innovations specifically designed for long-tail recognition."
- **Why unresolved**: This work isolates data-centric augmentation as the intervention; it remains unknown whether model architecture changes would compound with synthetic data benefits.
- **What evidence would resolve it**: A factorial experiment crossing synthetic data augmentation (present/absent) with long-tail-specific architectural modifications, measuring interaction effects on macro-F1.

### Open Question 3
- **Question**: Do synthetic notes generated via knowledge-injection prompting introduce clinically inaccurate hallucinations or amplify biases present in the source MIMIC-III distribution?
- **Basis in paper**: Related Work explicitly flags "bias amplification and potential hallucination of clinically inaccurate information" as inherent risks, but the paper reports no clinical validation or bias audit of generated notes.
- **Why unresolved**: The methodology focuses on plausibility through ontology guidance, yet no quantitative or expert evaluation confirms that generated content is clinically accurate or demographically unbiased.
- **What evidence would resolve it**: Clinical expert review of synthetic notes for factual accuracy; statistical comparison of demographic or diagnostic bias metrics between original and synthetic distributions.

### Open Question 4
- **Question**: Does the sibling-substitution strategy for zero-shot codes produce equally effective training signal as the direct cloning strategy used for few-shot codes?
- **Basis in paper**: The methodology applies different code set construction strategies based on code frequency, but results do not disentangle their relative contributions to macro-F1 improvements.
- **Why unresolved**: Aggregated performance metrics mask whether zero-shot augmentation via sibling transfer is inherently noisier or less effective than few-shot augmentation from real examples.
- **What evidence would resolve it**: Stratified performance analysis comparing macro-F1 gains separately for zero-shot codes versus few-shot codes on the extended model.

## Limitations

- The computational cost of generating 90,000 synthetic notes represents a substantial resource investment with only marginal macro-F1 improvements (+0.7 to +0.9)
- The effectiveness of hierarchical substitution depends on the assumption that sibling codes share clinically relevant comorbidity patterns, which may not hold for all clinical conditions
- The paper does not provide clinical validation of synthetic notes for accuracy, coherence, or potential hallucination of clinically inaccurate information

## Confidence

- **High Confidence**: The paper correctly identifies the long-tail distribution problem in ICD coding and demonstrates that synthetic data augmentation can modestly improve macro-F1 metrics while maintaining micro-F1 performance. The frequency stratification and log-inverse allocation formula are clearly specified and mathematically sound.
- **Medium Confidence**: The hierarchical substitution strategy for zero-shot codes is plausible but depends heavily on the assumption that sibling codes share clinically relevant comorbidity patterns. Without corpus validation of this assumption, the effectiveness may vary significantly across different ICD code families.
- **Low Confidence**: The clinical validity and code-note alignment of synthetic discharge summaries cannot be verified without access to generated samples or detailed evaluation metrics. The claim that knowledge-injection prompting produces clinically coherent text requires empirical validation through clinical expert review.

## Next Checks

1. **Generate and validate 100 synthetic notes**: Create a pilot batch of synthetic discharge summaries and conduct expert clinical review to assess code-note alignment, coherence, and potential hallucinated information. This would validate the core knowledge-injection prompting mechanism.

2. **Test hierarchical substitution accuracy**: For 20-30 zero-shot ICD codes, manually verify that retrieved sibling codes are clinically appropriate and that comorbidity pattern transfer produces plausible multi-label sets. This would validate the core assumption of the zero-shot augmentation strategy.

3. **Conduct ablation study on synthetic data impact**: Compare model performance when training with different proportions of synthetic vs. real data to quantify the marginal benefit and determine the optimal synthetic data ratio for balancing macro-F1 improvement against computational cost.