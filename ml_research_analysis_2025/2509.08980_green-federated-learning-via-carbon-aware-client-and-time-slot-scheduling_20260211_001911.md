---
ver: rpa2
title: Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling
arxiv_id: '2509.08980'
source_url: https://arxiv.org/abs/2509.08980
tags:
- carbon
- clients
- time
- training
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the environmental impact of federated learning\
  \ (FL) training by introducing a carbon-aware scheduling approach that strategically\
  \ selects clients and time slots to minimize emissions. The method leverages slack\
  \ time, allowing training to extend into lower-carbon periods, and incorporates\
  \ \u03B1-fair carbon allocation to ensure equitable participation among clients\
  \ while mitigating statistical bias."
---

# Green Federated Learning via Carbon-Aware Client and Time Slot Scheduling

## Quick Facts
- **arXiv ID**: 2509.08980
- **Source URL**: https://arxiv.org/abs/2509.08980
- **Reference count**: 36
- **Primary result**: Introduces carbon-aware scheduling for FL that reduces emissions by 20-60% through slack time while maintaining model accuracy via α-fair allocation and fine-tuning.

## Executive Summary
This paper addresses the environmental impact of federated learning (FL) by introducing a carbon-aware scheduling approach that strategically selects clients and time slots to minimize emissions. The method leverages slack time, allowing training to extend into lower-carbon periods, and incorporates α-fair carbon allocation to ensure equitable participation among clients while mitigating statistical bias. It also introduces unbiased aggregation rules and a fine-tuning phase to counteract temporal and spatial correlation effects in carbon intensity. Experiments using real-world carbon intensity data show that the proposed scheduler outperforms slack-agnostic baselines, achieving higher model accuracy across various carbon budgets, with particularly strong gains under tight carbon constraints.

## Method Summary
The method optimizes client and time slot selection for federated learning to minimize carbon emissions while preserving model accuracy. It formulates an optimization problem that maximizes α-fair carbon allocation across clients, where α controls the trade-off between carbon efficiency and fairness. The scheduler uses slack time (extending training duration) to defer training to lower-carbon periods. It implements unbiased aggregation (U-FedAvg) to compensate for heterogeneous selection frequencies and adds a fine-tuning phase at the end of training to correct for temporal and spatial correlation effects in carbon intensity. The approach is evaluated on MNIST with non-IID data distribution across 7 clients using real-world carbon intensity data from Electricity Maps.

## Key Results
- **20-60% emission reduction**: Slack time (20-236 hours) reduces carbon emissions by 20-60% while maintaining model accuracy.
- **α-fair allocation improves accuracy**: At medium carbon budgets (2 kgCO2e), increasing fairness (smaller α) improves accuracy by +8 pp; under tight budgets (<1 kgCO2e), fairness limits training slots, hurting accuracy.
- **Fine-tuning boosts performance**: Fine-tuning improves accuracy by +3.8 pp when both temporal and spatial correlations are high (ρ_TS > 0.45).

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Deferring training to lower-carbon periods via slack time can substantially reduce emissions without proportionally sacrificing model quality.
- **Mechanism:** The scheduler extends the training window beyond the minimum required rounds (T → T + t_sl), then selects time slots with lower Carbon Intensity (CI) for each client. This exploits temporal variability in grid carbon intensity, which fluctuates based on energy mix (e.g., solar peaks midday, wind varies with weather). By treating time slots as flexible resources, the optimizer selects low-CI slots within the extended window, achieving 20–60% emission reductions with modest slack (t_sl = 20–236 hours).
- **Core assumption:** Carbon intensity forecasts or historical patterns are sufficiently predictive; low-CI slots provide comparable learning value to high-CI slots.
- **Evidence anchors:**
  - [abstract]: "We first quantify the emission savings of a carbon-aware scheduling policy that leverages slack time—permitting a modest extension of the training duration so that clients can defer local training rounds to lower-carbon periods."
  - [Section IV-A, Figure 2]: Shows 20% emission reduction with t_sl = 20 hours, up to 60% with t_sl = 236 hours for individual clients.
  - [corpus]: Related work (FedZero, CAFE) confirms carbon-aware scheduling reduces emissions but often ignores temporal bias; this paper extends with fairness and fine-tuning.
- **Break condition:** If CI is temporally uniform (e.g., grids with stable baseload), slack time yields marginal gains; if forecasts are unreliable, selected slots may not be low-carbon.

### Mechanism 2
- **Claim:** α-fair carbon allocation mitigates statistical bias by guaranteeing each client a strictly positive share of the global carbon budget.
- **Mechanism:** The scheduler solves an optimization (Eq. 6) maximizing a sum of powered utilities: Σ_c [Σ_t (g_max - g^t_c) a^t_c]^α. The fairness parameter α ∈ (0,1] controls the trade-off: α = 1 is carbon-greedy (maximizes low-CI slot selection), while α → 0 enforces near-equal carbon budget per client. This prevents systematic exclusion of high-emission clients whose data may be essential for model generalization, reducing statistical bias from heterogeneous local datasets.
- **Core assumption:** Each client's data contributes non-redundant information; excluding clients harms generalization proportionally to their data distribution divergence.
- **Evidence anchors:**
  - [Section V-A, Figure 5]: At medium carbon budgets (2 kgCO2e), increasing fairness (smaller α) improves accuracy by +8 pp; under tight budgets (<1 kgCO2e), fairness limits training slots, hurting accuracy.
  - [Section V-A, Figure 4]: α = 10^-3 ensures high-emission clients are occasionally selected versus α = 1 where they're systematically excluded.
  - [corpus]: FedZero and CAFE incorporate fairness via statistical utility estimation (requiring all clients to compute gradients each round), incurring overhead; this method avoids utility estimation overhead.
- **Break condition:** If data is IID across clients, exclusion bias is negligible and α ≈ 1 is optimal; under extreme carbon constraints, enforcing fairness may reduce total training slots below viability.

### Mechanism 3
- **Claim:** Combining unbiased aggregation (U-FedAvg) with a fine-tuning phase compensates for selection bias and temporal correlation effects.
- **Mechanism:** Carbon-aware scheduling creates heterogeneous selection frequencies (π_c), biasing standard FedAvg toward over-represented clients. U-FedAvg reweights each client's update by 1/π_c (Eq. 7), restoring unbiased estimation at the cost of slower convergence O(ρ_H/T). Temporal/spatial CI correlations cause last-iterate bias (late updates dominate). A fine-tuning window F(s) with full client selection (a^t_c = 1 for all c) at the end of training mitigates this by ensuring all clients contribute a final, balanced update.
- **Core assumption:** Selection frequencies π_c are known or estimable; fine-tuning's carbon cost is budgeted; clients remain available during fine-tuning.
- **Evidence anchors:**
  - [Section V-B]: U-FedAvg eliminates selection bias but converges more slowly when ρ_H is large.
  - [Section V-C, Figure 6]: Fine-tuning improves accuracy by +3.8 pp when both temporal and spatial correlations are high (ρ_TS > 0.45).
  - [corpus]: Rodio et al. [31] (cited in paper) proves U-FedAvg convergence bounds under correlated client availability; this paper extends to carbon-aware scheduling.
- **Break condition:** If selection frequencies are very low (π_c ≈ 0) for some clients, 1/π_c explodes, causing variance issues; if fine-tuning exceeds budget, it's infeasible.

## Foundational Learning

- **Concept: Federated Averaging (FedAvg)**
  - **Why needed here:** The baseline algorithm being modified; understanding its aggregation rule (Eq. 3) is essential to grasp how selection bias and unbiased aggregation differ.
  - **Quick check question:** Given heterogeneous selection probabilities π_c, does standard FedAvg converge to the global objective F(θ) or a weighted surrogate?

- **Concept: Carbon Intensity (CI) and its Variability**
  - **Why needed here:** The entire scheduling mechanism relies on CI varying across time (hourly, daily patterns) and geography (regional energy mixes).
  - **Quick check question:** Why does France exhibit low, stable CI while Germany shows high variability (Figure 1)?

- **Concept: Statistical Heterogeneity (Non-IID Data)**
  - **Why needed here:** The motivation for α-fair allocation; if data were IID, excluding clients wouldn't introduce bias.
  - **Quick check question:** In a FL system with clients across different countries, what factors cause local datasets to diverge from the global distribution?

## Architecture Onboarding

- **Component map:**
  Central Server -> CarbonScheduler -> Global model θ^(t) -> Selected clients (a^t_c = 1) -> Local SGD updates -> U-FedAvg aggregation -> Updated θ^(t)

- **Critical path:**
  1. Fetch CI traces for all client regions → build cost matrix g^t_c = E_c × CI^t_c.
  2. Solve optimization (Eq. 8) → output A, s (NP-hard but tractable for ~50 clients via MOSEK; larger scale uses greedy (1-1/e)-approximation).
  3. Execute T + s rounds: at each t, broadcast θ^(t) to selected clients (a^t_c = 1), collect updates, aggregate via U-FedAvg (or FedAvg if t ∈ F(s)).
  4. Return final model θ^(T+s).

- **Design tradeoffs:**
  - **Slack time (t_sl) vs. training duration:** More slack → lower emissions, but longer wall-clock time; may increase forgetting for early slots.
  - **Fairness (α) vs. carbon efficiency:** Smaller α → fairer allocation, fewer total slots scheduled; α ≈ 1 → more slots but higher bias risk.
  - **Fine-tuning duration (t_ft) vs. budget:** Longer fine-tuning ensures better bias correction but consumes budget that could support more regular rounds.
  - **U-FedAvg vs. FedAvg:** Unbiased aggregation eliminates selection bias but converges slower under high selection heterogeneity (ρ_H).

- **Failure signatures:**
  - **High variance in updates:** π_c extremely low for some clients → 1/π_c causes gradient explosion. Mitigation: set minimum π_c threshold.
  - **Fine-tuning infeasibility:** Budget too tight → no s satisfies constraints. Mitigation: reduce t_ft or relax fairness (increase α).
  - **Stale CI data:** Using historical CI when actual CI diverges → emissions exceed predictions. Mitigation: integrate 72-hour forecasts with uncertainty margins.
  - **Catastrophic forgetting under long slack:** Early updates overwritten if T + s >> T. Mitigation: cap slack, increase local steps τ, or use replay mechanisms.

- **First 3 experiments:**
  1. **Quantify slack-time savings:** Run scheduler with t_sl ∈ {0, 20, 100, 236} on CI traces from 5+ regions; plot ΔCO2e vs. t_sl. Verify 20–60% reductions match Figure 2.
  2. **Ablate fairness (α):** Fix budget k = 2 kgCO2e, vary α ∈ {10^-3, 10^-2, 10^-1, 1}; measure test accuracy and selection heterogeneity ρ_H. Confirm peak accuracy at intermediate α.
  3. **Validate fine-tuning benefit:** Simulate high-correlation CI profiles (e.g., solar-dominated regions); compare accuracy with t_ft = 0 vs. t_ft = 10. Expect +3–4 pp improvement matching Figure 6.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does uncertainty in Carbon Intensity (CI) forecasting impact the efficacy of the slack-time scheduler?
- **Basis in paper:** [inferred] The evaluation uses historical CI data from 2022 (perfect hindsight), whereas the introduction notes that real-world platforms only provide 72-hour forecasts.
- **Why unresolved:** The proposed optimization relies on accurate future carbon prices; forecasting errors could lead to suboptimal scheduling, negating the theoretical savings demonstrated with historical data.
- **What evidence would resolve it:** Experiments evaluating model accuracy and carbon savings when the scheduler is fed realistic, noisy CI forecast data rather than historical ground truth.

### Open Question 2
- **Question:** How does the scheduler perform in massive-scale cross-device environments regarding computational overhead and approximation quality?
- **Basis in paper:** [explicit] The paper notes that while the exact optimization is solved via MOSEK for experiments, "larger-scale instances" require a greedy algorithm with only a $(1-1/e)$ approximation ratio.
- **Why unresolved:** The trade-off between the computational speed of the greedy approximation and the quality of the client selection schedule was not quantified for federations with thousands or millions of clients.
- **What evidence would resolve it:** Complexity analysis and convergence benchmarks of the greedy approximation applied to large-scale client pools, comparing the solution quality against the optimal solver.

### Open Question 3
- **Question:** Is the unbiased aggregation rule robust to client dropouts (stragglers) during the execution of the pre-computed schedule?
- **Basis in paper:** [inferred] The scheduler pre-computes a fixed binary selection matrix $A$ and assumes selected clients participate. However, the related work acknowledges cross-device clients may be unavailable.
- **Why unresolved:** If a client scheduled for a specific low-carbon time slot fails to participate (due to connectivity issues), the careful balance of the unbiased aggregation weights ($1/\pi_c$) is disrupted, potentially re-introducing bias.
- **What evidence would resolve it:** Simulations modeling stochastic client unavailability to measure the resulting deviation in model accuracy and selection bias compared to the idealized full-participation scenario.

## Limitations
- **Slack time assumptions:** Effectiveness depends on CI variability and forecast accuracy; marginal gains in regions with stable carbon intensity.
- **Fairness constraints:** Under extreme carbon constraints, enforcing fairness may reduce total training slots below viability.
- **Client availability:** Fine-tuning compensation assumes clients remain available during the extended period; client churn could compromise bias-correction mechanism.

## Confidence

- **High Confidence:** Slack-time emission reduction mechanism (20-60% savings with extended training windows are well-supported by experimental data).
- **Medium Confidence:** α-fair allocation benefits under statistical heterogeneity (effectiveness depends on data distribution assumptions not fully validated).
- **Medium Confidence:** Fine-tuning phase effectiveness (benefits shown in experiments but may not generalize to all CI correlation patterns).

## Next Checks

1. **Test scheduler performance on IID versus non-IID data distributions** to quantify the marginal benefit of fairness constraints under varying heterogeneity levels.
2. **Validate carbon savings using actual CI data versus forecasts** to measure prediction error impact on scheduling decisions.
3. **Evaluate fine-tuning effectiveness across different CI correlation structures** (temporal only, spatial only, both) to identify conditions where it provides maximum benefit.