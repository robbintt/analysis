---
ver: rpa2
title: 'LLM-Sketch: Enhancing Network Sketches with LLM'
arxiv_id: '2502.07495'
source_url: https://arxiv.org/abs/2502.07495
tags:
- flow
- llm-sketch
- flows
- heavy
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LLM-Sketch, a novel network sketch algorithm
  that leverages large language models to enhance accuracy in flow size estimation.
  LLM-Sketch addresses the limitations of existing sketches, which struggle with skewed
  traffic distributions and high training costs.
---

# LLM-Sketch: Enhancing Network Sketches with LLM

## Quick Facts
- arXiv ID: 2502.07495
- Source URL: https://arxiv.org/abs/2502.07495
- Reference count: 40
- Key outcome: LLM-Sketch achieves a 7.5× improvement in accuracy over state-of-the-art methods for flow size estimation using a two-tier structure and LLM-based flow classification.

## Executive Summary
LLM-Sketch is a novel network sketch algorithm that leverages large language models to enhance flow size estimation accuracy. The system addresses the limitations of existing sketches, which struggle with skewed traffic distributions and high training costs. By using a two-tier data structure to separate large and small flows, and employing a fine-tuned LLM to predict flow sizes based on packet headers, LLM-Sketch significantly improves accuracy while maintaining memory efficiency. The approach demonstrates substantial gains across three representative tasks: flow size query, heavy hitter query, and hierarchical heavy hitter query.

## Method Summary
LLM-Sketch implements a two-tier sketch structure consisting of a heavy part (key-value table for large flows) and a light part (Count-Min Sketch for small flows). A RoBERTa-based LLM classifier is fine-tuned using LoRA to predict flow sizes from packet headers (with IPs removed for generalizability). The model outputs soft probabilities rather than hard classifications, enabling probabilistic routing to the appropriate tier. The system uses a soft-label regression objective with sigmoid scaling to stabilize training. During operation, incoming packets are routed to either the heavy or light part based on the LLM's prediction, with a lock flag mechanism managing eviction in the heavy part.

## Key Results
- Achieves 7.5× improvement in accuracy over state-of-the-art methods
- Demonstrates effectiveness across flow size query, heavy hitter query, and hierarchical heavy hitter query tasks
- Maintains memory efficiency while significantly improving estimation accuracy
- Shows fast convergence with 1 epoch of training using LoRA fine-tuning

## Why This Works (Mechanism)

### Mechanism 1: Separation of Elephant and Mice Flows
The two-tier data structure reduces collision errors by isolating large flows in a key-value table while small flows use the Count-Min Sketch. This prevents high-volume traffic from overwriting counters for the majority of flows.

### Mechanism 2: Header-Based Flow Size Inference
Fine-tuning a Language Model on packet headers (excluding IPs) enables prediction of flow size potential based on transport-layer features and protocol patterns, rather than relying solely on flow ID-frequency correlations.

### Mechanism 3: Soft-Label Classification Objective
Using continuous soft-label loss (rather than hard binary threshold) stabilizes training and mitigates penalties for borderline classifications, with flows near the threshold receiving labels closer to 0.5.

## Foundational Learning

- **Count-Min Sketch (CMS)**: Baseline "light part" structure that uses hash functions and counters; understanding its collision properties is necessary to quantify LLM-Sketch's improvements.
  - Quick check: In a standard CMS, why does querying the *minimum* of the hashed counters yield the most accurate estimate?

- **LoRA (Low-Rank Adaptation)**: Technique used for efficient LLM fine-tuning by freezing pre-trained weights and adding trainable rank-decomposition matrices.
  - Quick check: How does freezing pre-trained model weights and injecting trainable rank-decomposition matrices reduce memory usage during fine-tuning?

- **Traffic Skew (Zipf's Law)**: Fundamental motivation for two-tier architecture due to the skewed nature of network traffic (few "elephant" flows, many "mice" flows).
  - Quick check: Why does a uniform hash function in a traditional sketch lead to high error rates when processing a highly skewed data stream?

## Architecture Onboarding

- **Component map**: Packet stream -> LLM Classifier (RoBERTa + LoRA) -> Heavy Part (KV table with lock flags) or Light Part (Count-Min Sketch)

- **Critical path**: 1) Packet arrives; check Heavy Part for existing ID. 2) If new, pass header to LLM Classifier to get probability score. 3) Update Lock Flag (probabilistic history). 4) Route to Heavy Part (if predicted large) or Light Part (if predicted small). 5) Handle eviction: If Heavy Part is full, evict unlocked flow with smallest counter.

- **Design tradeoffs**: Latency vs. Accuracy (LLM inference adds computational latency), Generalizability vs. Overfitting (masking IPs prevents overfitting but may discard routing information)

- **Failure signatures**: Concept Drift (accuracy degrades over time requiring periodic re-finetuning), GPU Starvation (backpressure in classifier causing packet drops), Threshold Mismatch (eviction rates spike if heavy threshold doesn't match available memory)

- **First 3 experiments**: 1) Baseline Reproduction: Run Python implementation on CAIDA dataset to reproduce ARE vs. Memory curve. 2) Ablation on Soft Labels: Replace soft-label objective with binary cross-entropy to quantify impact. 3) Latency Profiling: Measure P99 insertion latency against ElasticSketch to define throughput constraints.

## Open Questions the Paper Calls Out

- Can LLM-Sketch achieve line-rate processing speeds on high-speed network links (e.g., 10Gbps+) given Transformer-based model latency?
- How does classifier accuracy degrade over extended timeframes (hours/days) beyond tested 20-minute window, and what is required retraining frequency?
- How do theoretical error bounds hold when assumptions are violated due to memory constraints or prediction oscillation?
- Is the soft-label scaling parameter universally optimal, or does it require tuning for different traffic characteristics?

## Limitations

- Design Scalability: LLM inference may become bottleneck under high throughput (10-40 Mpps) requiring specialized hardware
- Model Adaptability: Static training shows accuracy degradation over time without comprehensive continuous learning solution
- Hyperparameter Sensitivity: Critical parameters (threshold, heavy ratio, lock probability) not thoroughly analyzed for sensitivity across traffic patterns

## Confidence

**High Confidence Claims:**
- Two-tier architecture with separate handling of large/small flows improves accuracy
- LLM-based flow size prediction using packet headers provides meaningful signals
- Soft-label regression objective stabilizes training compared to hard classification

**Medium Confidence Claims:**
- 7.5× accuracy improvement valid for specific datasets and evaluation metrics
- LoRA fine-tuning enables efficient LLM adaptation without full model retraining
- Lock flag mechanism effectively prevents eviction of high-value large flows

**Low Confidence Claims:**
- Approach generalizes well to encrypted traffic with obscured header fields
- System maintains accuracy under varying network conditions without parameter adjustment
- Memory efficiency claims hold when accounting for LLM model storage and computational overhead

## Next Checks

- **Check 1: Throughput Benchmarking** - Measure LLM-Sketch's maximum sustainable packet processing rate (Mpps) under varying traffic loads and compare against baseline sketches like ElasticSketch with and without GPU acceleration.

- **Check 2: Long-term Accuracy Stability** - Deploy LLM-Sketch on continuous traffic stream and monitor accuracy metrics over extended periods (hours to days), implementing retraining schedule to measure accuracy recovery and document trade-off between frequency and sustained accuracy.

- **Check 3: Encrypted Traffic Performance** - Evaluate LLM-Sketch's accuracy when processing traffic with encrypted transport headers (e.g., TLS 1.3) and compare performance against baseline using only flow ID and packet size.