---
ver: rpa2
title: 'NagaNLP: Bootstrapping NLP for Low-Resource Nagamese Creole with Human-in-the-Loop
  Synthetic Data'
arxiv_id: '2512.12537'
source_url: https://arxiv.org/abs/2512.12537
tags:
- data
- language
- corpus
- nagamese
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the severe data scarcity problem for Nagamese
  Creole, an under-resourced Assamese-lexified lingua franca spoken in Nagaland, India.
  The authors introduce NagaNLP, a comprehensive open-source NLP toolkit bootstrapped
  using a novel "LLM-to-human" pipeline.
---

# NagaNLP: Bootstrapping NLP for Low-Resource Nagamese Creole with Human-in-the-Loop Synthetic Data

## Quick Facts
- **arXiv ID:** 2512.12537
- **Source URL:** https://arxiv.org/abs/2512.12537
- **Reference count:** 40
- **Primary result:** NagaNLP achieves 93.81% accuracy (POS) and 0.75 F1-macro (NER) on low-resource Nagamese Creole using LLM-to-human pipeline.

## Executive Summary
This paper addresses the severe data scarcity problem for Nagamese Creole, an under-resourced Assamese-lexified lingua franca spoken in Nagaland, India. The authors introduce NagaNLP, a comprehensive open-source NLP toolkit bootstrapped using a novel "LLM-to-human" pipeline. This approach leverages a state-of-the-art LLM (Gemini) guided by expert interaction to generate a synthetic corpus, which is then rigorously validated and annotated by native speakers. The resulting human-validated hybrid corpus enabled the training of foundational NLP models. NagaNLP achieves a new state-of-the-art for Nagamese, with a 93.81% accuracy and 0.90 F1-macro on Part-of-Speech tagging, and 0.75 F1-macro on Named Entity Recognition. Additionally, a fine-tuned Llama-3.2-3B model, NagaLLaMA, demonstrates strong generative performance with a perplexity of 3.85 on conversational tasks, an order of magnitude better than its few-shot counterpart. The toolkit and all resources are publicly released, providing a foundational resource for Nagamese and a replicable framework for other low-resource languages.

## Method Summary
The NagaNLP pipeline uses a four-stage LLM elicitation process (persona definition, interactive grammatical elicitation, knowledge consolidation, scaled generation) with Gemini 2.5 Pro to generate synthetic conversational data. Native speakers validate and correct this data, which is then used to fine-tune POS/NER models (BERT-multilingual-cased and XLM-RoBERTa) and a generative model (Llama-3.2-3B with LoRA). The approach achieves state-of-the-art results across three tasks: POS tagging (93.81% accuracy), NER (0.75 F1-macro), and generative instruction following (perplexity 3.85).

## Key Results
- NagaNLP achieves 93.81% accuracy and 0.90 F1-macro on Part-of-Speech tagging
- Named Entity Recognition performance reaches 0.75 F1-macro
- NagaLLaMA generative model achieves perplexity of 3.85, a 25x improvement over few-shot baseline
- Human-in-the-loop validation improves POS performance by 9 F1 and NER by 13 F1 compared to raw synthetic data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-stage interactive elicitation enables an LLM to internalize low-resource language grammar before scaled generation.
- Mechanism: A four-stage process—(1) persona/task definition, (2) interactive grammatical elicitation with corrective feedback, (3) knowledge consolidation into structured grammar, and (4) scaled generation with periodic in-context reinforcement—builds a coherent internal representation of Nagamese within Gemini 2.5 Pro, reducing drift and improving consistency during large-scale data production.
- Core assumption: The LLM can form generalizable grammatical hypotheses from limited authentic examples and iterative expert correction.
- Evidence anchors:
  - [section] Section 3.1 details all four stages, including "interactive teaching process" and "synthesized grammar" for consistency.
  - [abstract] "expert-guided LLM (Gemini) generates a candidate corpus, which is then refined and annotated by native speakers."
  - [corpus] Weak direct corpus signal; related work on low-resource creole MT exists (Guinea-Bissau Creole, FMR=0.57), but no external validation of this specific elicitation mechanism.
- Break condition: If the LLM hallucinates grammatical rules or fails to generalize from limited seed texts, generated data will contain systematic errors that propagate through the pipeline.

### Mechanism 2
- Claim: Human-in-the-loop validation is causally necessary for high-quality synthetic corpora in zero-resource settings.
- Mechanism: Native speakers (1) correct grammatical/fluency errors in generated text, (2) validate LLM-generated POS/NER annotations, and (3) adjudicate disagreements, transforming raw synthetic output into gold-standard training data.
- Core assumption: Native speakers can reliably detect and fix LLM-induced artifacts; their corrections reflect authentic linguistic patterns.
- Evidence anchors:
  - [section] Section 5.4.1 ablation: models trained on raw synthetic data drop 9 F1 (POS) and 13 F1 (NER) vs. human-validated data.
  - [section] IAA scores: κ=0.92 (POS), κ=0.88 (NER), indicating high annotation consistency.
  - [corpus] No direct corpus comparison; related work on synthetic data for NER in low-resource languages exists but lacks comparative HiTL ablation.
- Break condition: If annotator pool lacks sufficient dialectal coverage or training, validation quality degrades and annotation inconsistencies emerge.

### Mechanism 3
- Claim: Parameter-efficient fine-tuning (LoRA) transfers multilingual pre-trained representations to an unseen creole with minimal data.
- Mechanism: LoRA adapters applied to Llama-3.2-3B query/key/value and MLP layers enable effective instruction-tuning on the 10K conversational corpus without full parameter updates, leveraging shared subword representations from the lexifier language (Assamese) and code-switched English.
- Core assumption: The pre-trained model has sufficient exposure to related languages (Assamese, Hindi, English) that low-rank adaptation can bridge to Nagamese.
- Evidence anchors:
  - [abstract] "NagaLLaMA...perplexity of 3.85...an order of magnitude improvement over its few-shot counterpart (96.76)."
  - [section] Table 9: translation BLEU 34.97 (Nag→Eng) vs. NLLB proxy at 2.23.
  - [corpus] Related work on Persian Llama adaptation (h-index 63 author) supports cross-lingual LoRA effectiveness, though not creole-specific.
- Break condition: If base model tokenizer fragments Nagamese into meaningless subwords or lacks any related language exposure, LoRA gains will be minimal.

## Foundational Learning

- Concept: **Creole languages and code-switching**
  - Why needed here: Nagamese is an Assamese-lexified creole with frequent English code-switching; standard NLP assumptions about monolingual syntax fail.
  - Quick check question: Can you explain why a creole's mixed lexifier/syntax origins complicate tokenization and annotation schema design?

- Concept: **Synthetic data generation with human validation**
  - Why needed here: The pipeline's core innovation is LLM generation + human curation; understanding both sides is critical for replication.
  - Quick check question: What specific error types does the ablation study show are introduced when human validation is skipped?

- Concept: **Parameter-efficient fine-tuning (LoRA)**
  - Why needed here: NagaLLaMA uses LoRA to adapt a 3B model on 10K pairs; understanding rank/alpha/dropout tradeoffs is essential for experimentation.
  - Quick check question: Why does LoRA target query/key/value and MLP projections specifically for language adaptation tasks?

## Architecture Onboarding

- Component map:
  - Synthetic Generation: Gemini 2.5 Pro (4-stage elicitation → 10K conversational pairs + 214 annotated sentences)
  - Human Validation: 4 native speakers (correction, annotation, adjudication; IAA κ>0.88)
  - Discriminative Models: XLM-RoBERTa-base (NER, 0.75 F1), BERT-multilingual-cased (POS, 0.90 F1)
  - Generative Model: Llama-3.2-3B-Instruct + LoRA (r=16, α=32, dropout=0.05)

- Critical path:
  1. Elicitation phase with native speaker → 2. Scaled generation with reinforcement → 3. Human curation/correction → 4. LLM pre-annotation → 5. Human annotation validation → 6. Transformer fine-tuning (POS/NER) → 7. LoRA instruction-tuning (generative)

- Design tradeoffs:
  - Scale vs. quality: 10K conversational pairs vs. 214 densely annotated sentences—generative needs volume, discriminative needs precision.
  - Automation vs. human effort: LLM pre-annotation reduces workload but requires full human review (13 F1 gap if skipped).
  - Model selection: BERT-multilingual wins POS (0.90 F1), XLM-R wins NER (0.75 F1)—task-specific architecture selection matters.

- Failure signatures:
  - Zero-shot XLM-R: 0.02 F1 (POS), ~0.00 F1 (NER) → confirms no inherent Nagamese knowledge.
  - NLLB Assamese proxy: BLEU 1.64 (Eng→Nag) → proxy languages fail for creoles.
  - Few-shot Llama: perplexity 96.76 → in-context learning insufficient without fine-tuning.

- First 3 experiments:
  1. **Replicate POS baseline**: Train CRF on the 171-sentence training split; target ≥0.91 F1 to validate corpus quality before attempting transformer training.
  2. **Ablate HiTL on small subset**: Train XLM-R on raw synthetic annotations vs. human-validated for NER; expect 10-15 F1 gap confirming pipeline necessity.
  3. **Scale data fraction test**: Fine-tune NagaLLaMA on 25%/50%/75%/100% of conversational data; plot perplexity curve to validate scalability hypothesis before investing in larger generation campaigns.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does the performance of the NagaLLaMA model eventually plateau, or can it be significantly improved by scaling the synthetic conversational corpus beyond the current 10,000 pairs?
  - Basis in paper: [Explicit] The authors state in Section 5.4.2 that "performance has not yet plateaued" and suggest that "generating even more data with our pipeline could lead to further gains."
  - Why unresolved: The experiments concluded at a fixed dataset size (10k pairs), leaving the upper bounds of this specific synthetic data scaling law unexplored.
  - What evidence would resolve it: Training successive versions of NagaLLaMA on 20k, 50k, and 100k pairs to observe if the downward trend in perplexity continues or flattens.

- **Open Question 2:** Is the "LLM-to-human" bootstrapping pipeline effective for low-resource languages that lack a high-resource lexifier (like Assamese) present in the LLM's pre-training data?
  - Basis in paper: [Inferred] The methodology relies on Gemini's ability to learn Nagamese, which is Assamese-lexified. The paper claims a "replicable blueprint," but it is unstated if the pipeline works for languages without lexical overlap with the LLM's training set.
  - Why unresolved: The study only validates the methodology on Nagamese (Assamese-lexified); it does not test the "zero-shot" capability of the *pipeline itself* on a language entirely foreign to the base LLM.
  - What evidence would resolve it: Applying the identical pipeline to a truly isolate or unrelated low-resource language and measuring the quality of the generated synthetic corpus.

- **Open Question 3:** To what extent does the synthetic-hybrid corpus capture natural linguistic diversity compared to organic data, specifically regarding spontaneous code-switching and dialectal variations?
  - Basis in paper: [Inferred] While Section 3.1 details "interactive grammatical elicitation," the generation process is inherently structured. There is an implicit assumption that LLM generation combined with human validation preserves the "messy" naturalness of oral creole dialects better than manual creation.
  - Why unresolved: The paper validates grammatical accuracy (POS/NER) and fluency (Perplexity), but does not quantitatively measure the linguistic diversity or "naturalness" of the synthetic data against a baseline of purely organic text.
  - What evidence would resolve it: A comparative analysis of code-switching frequency and vocabulary richness between the synthetic corpus and a newly collected sample of organic Nagamese social media text.

## Limitations

- The LLM-to-human pipeline lacks external validation of its core elicitation mechanism's effectiveness in internalizing grammar
- The approach's generalizability to other low-resource languages without high-resource lexifiers remains unproven
- Safety and bias concerns for community deployment are not systematically addressed

## Confidence

**High Confidence:**
- The human-in-the-loop validation significantly improves NLP model performance (POS: 93.81% accuracy, NER: 0.75 F1-macro)
- The NagaNLP toolkit achieves state-of-the-art results for Nagamese across all three tasks
- LoRA fine-tuning effectively transfers multilingual representations to Nagamese (perplexity improvement from 96.76 to 3.85)

**Medium Confidence:**
- The four-stage LLM elicitation process is necessary for generating high-quality synthetic data
- The approach is broadly replicable for other low-resource languages
- The specific LoRA hyperparameters (r=16, alpha=32) are optimal for this task

**Low Confidence:**
- The LLM actually internalizes Nagamese grammar versus pattern matching
- The synthetic corpus captures full dialectal variation of Nagamese
- The framework addresses all potential safety and bias concerns for community deployment

## Next Checks

1. **External Validation of Elicitation Mechanism**: Replicate the four-stage elicitation process with a different expert panel and evaluate whether generated data quality remains consistent. Compare grammatical consistency metrics across different elicitation sessions to verify the LLM is learning rather than memorizing.

2. **Cross-Lingual Transfer Study**: Apply the same pipeline to another low-resource creole (e.g., Sango or Papiamento) with similar lexifier relationships. Measure FMR and annotation consistency to determine if the approach generalizes beyond the specific conditions of Nagamese.

3. **Safety and Bias Audit**: Conduct a systematic evaluation of NagaLLaMA for harmful outputs using established benchmarks for language models serving minority communities. Test for representation biases, offensive content generation, and cultural appropriateness across diverse dialectal variants of Nagamese.