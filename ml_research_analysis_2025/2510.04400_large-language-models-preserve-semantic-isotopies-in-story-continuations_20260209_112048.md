---
ver: rpa2
title: Large Language Models Preserve Semantic Isotopies in Story Continuations
arxiv_id: '2510.04400'
source_url: https://arxiv.org/abs/2510.04400
tags:
- isotopies
- isotopy
- text
- which
- lexical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) preserve
  semantic isotopies in story continuations. An isotopy is a cohesive semantic thread
  in text, formed by the repeated co-occurrence of a semantic feature.
---

# Large Language Models Preserve Semantic Isotopies in Story Continuations

## Quick Facts
- **arXiv ID:** 2510.04400
- **Source URL:** https://arxiv.org/abs/2510.04400
- **Authors:** Marc Cavazza
- **Reference count:** 20
- **Key outcome:** LLM-generated story continuations preserve semantic isotopies with coverage balance near optimal (≈1.0), density and spread metrics matching human-authored texts.

## Executive Summary
This paper investigates whether large language models preserve semantic isotopies—cohesive semantic threads formed by repeated co-occurrence of semantic features—when continuing short stories. Using 10,000 ROCStories prompts completed by five LLMs (3B-27B parameters), the study extracts and analyzes isotopies from both primers and continuations. Results show LLM continuations preserve isotopies across multiple structural properties: coverage balance averages near 1.0, isotopy density and spread align with human texts, and semantic relevance is confirmed by high similarity between isotopy labels and story titles. The findings suggest LLMs capture textual semantic properties that transfer from training corpora to generation.

## Method Summary
The study uses ROCStories corpus (first 10,000 stories with titles) as prompts for five LLMs (LLaMA-3.2 3B, Mistral-Nemo 12B, Phi-4 14B, Qwen-2.5 14B, Gemma-3 27B) to generate story continuations (~100 words each, temperature=0.5). GPT-4o extracts up to 2 isotopies per story using a zero-shot Chain-of-Thought prompt (temperature=0) with JSON output. Structural metrics include coverage balance (ratio of post-completion to pre-completion coverage), density (fraction of text words in isotopy), and spread (uniformity via Ripley's K). Semantic relevance is assessed via cosine similarity between isotopy labels and story titles using `mxbai-embed-large-v1`.

## Key Results
- Coverage balance averages near 1.0 across all five LLMs (Kruskal-Wallis H=215.5, p<0.001)
- Isotopy density and spread metrics align with human-authored texts
- High semantic relevance confirmed by similarity between isotopy labels and story titles
- 85% of isotopies score below 0.20 on WordNet path_similarity, confirming reliance on inferential rather than lexical relations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLM-generated continuations preserve semantic isotopies with coverage balance near optimal (≈1.0), suggesting captured textual semantic properties transfer from training corpora to generation.
- **Mechanism:** Distributional co-occurrence patterns learned during pre-training encode paradigmatic relations that manifest as cohesive semantic threads during continuation.
- **Core assumption:** Distributional semantics connects to structural semantics via paradigmatic relations (citing Sahlgren 2006, Mickus 2024).
- **Evidence anchors:** [abstract] "Results show that LLM completion within a given token horizon preserves semantic isotopies"; [Section 5.1] Coverage balance averages near 1.0; [Section 8] "At this stage, it is difficult to hypothesize how such textual properties have been captured during LLM corpus training".

### Mechanism 2
- **Claim:** Nucleus sampling reduces degenerate outputs and may contribute to cohesion, though its interaction with isotopy preservation remains under-specified.
- **Mechanism:** Sampling adapters enhance precision in generation and improve sequence-level quality metrics (MAUVE).
- **Core assumption:** Sampling strategy influences semantic coherence at the sequence level, not just local token selection.
- **Evidence anchors:** [Section 8] "It is generally considered that nucleus sampling may contribute to improve cohesion, although its reduction in repetitive outputs may seem to contradict some basic requirements of isotopy"; [Section 8] Garces Arias et al. (2024) observed nucleus sampling can produce text with inconsistent semantics.

### Mechanism 3
- **Claim:** Isotopy constituents connect via inference (part-whole, situational, action-object) rather than static lexical relations, and LLM extraction with chain-of-thought prompting captures this interpretative aspect.
- **Mechanism:** Zero-shot CoT prompting enables LLMs to reason about semantic relations beyond direct similarity.
- **Core assumption:** LLMs can perform interpretative semantics that go beyond lexical database lookups.
- **Evidence anchors:** [Section 2] Isotopy examples: 'beach' and 'sand' (part-whole), 'picnic' and 'ants' (situational); [Section 6.3] 85% of isotopies score below 0.20 on WordNet path_similarity; [Section 8] Benchmark performance decreased from 69.4% to 61% when removing CoT step.

## Foundational Learning

- **Concept: Isotopy vs. Lexical Chain**
  - Why needed here: Isotopy differs from lexical chains by requiring interpretative inference, not just semantic similarity.
  - Quick check question: Given {itch, allergic, reaction, hives, Benadryl, symptoms}, what inferential relation connects these words that a thesaurus would miss?

- **Concept: Coverage Balance Metric**
  - Why needed here: The paper's key quantitative result hinges on this metric—ratio of post-completion to pre-completion coverage.
  - Quick check question: If an isotopy has pre-completion coverage of 0.4 and post-completion coverage of 0.5, what is the coverage balance score?

- **Concept: Token Horizon Constraints**
  - Why needed here: All claims are conditional on generation length being within a token horizon (~4000 tokens per cited work).
  - Quick check question: Why would isotopy preservation potentially degrade for longer generated texts?

## Architecture Onboarding

- **Component map:** ROCStories primer (10k) → Story completion prompt (5 LLMs, temp=0.5) → Completed stories → GPT-4o isotopy extraction (temp=0, CoT) → Structural metrics (coverage, density, Ripley's K) → Semantic validation (title similarity)

- **Critical path:** GPT-4o isotopy extraction validation (69.4% benchmark accuracy) → this underpins all downstream metric reliability.

- **Design tradeoffs:**
  - Single isotopy per story (11.4% had second isotopy, discarded) → cleaner analysis but loses multi-threaded semantic structure
  - Temperature=0 for extraction vs. temperature=0.5 for generation → deterministic analysis but creative generation
  - 4096-token window uniform across models → may mask size-related differences

- **Failure signatures:**
  - 2.58% ill-formed isotopies (not covering primer) → filtered out before analysis
  - 5.79% removed as outliers via IQR(k=4) for coverage balance → long-tailed distribution suggests heterogeneity
  - Coverage balance variance across models (Cliff δ up to ±0.19) → model-dependent behavior

- **First 3 experiments:**
  1. Replicate GPT-4o benchmark validation on a subset of the 26 multilingual texts to confirm extraction reliability before scaling.
  2. Run completion with temperature varied (0.3, 0.7, 1.0) to test whether isotopy preservation is sampling-dependent.
  3. Extend to non-narrative prompts (e.g., Argilla database mentioned in Section 7) to test generalization beyond story completion.

## Open Questions the Paper Calls Out

- **Open Question 1:** Do LLMs preserve semantic isotopies in generation windows exceeding 4000 tokens? [explicit] The authors state that current literature suggests a "loss of stability beyond a generation horizon of 4000 tokens" and explicitly caution against generalizing findings from short texts too early. Why unresolved: The experiment was restricted to story completions of approximately 134 words. What evidence would resolve it: Replicating the isotopy extraction and analysis pipeline on long-form generated texts (e.g., >4k tokens) to measure if coverage balance and density metrics degrade or persist.

- **Open Question 2:** How do specific decoding strategies, such as nucleus sampling, impact the preservation of semantic isotopies? [explicit] The conclusion notes that while nucleus sampling is thought to improve cohesion, it may contradict isotopy requirements, and explicitly calls for "investigating... decoding issues" in future work. Why unresolved: The study utilized a fixed temperature (0.5) without isolating the causal effect of the decoding method. What evidence would resolve it: An ablation study comparing isotopy density and spread across different decoding strategies (e.g., greedy search vs. various sampling adapters) using identical prompts.

- **Open Question 3:** Is isotopy preservation a general property of LLMs across non-narrative genres? [explicit] The authors acknowledge they focused on story completion and only gathered "anecdotal evidence of isotopy preservation on non-narrative texts." Why unresolved: The reliance on the ROCStories dataset limits the findings to everyday narratives. What evidence would resolve it: Applying the same experimental pipeline to diverse domains (e.g., scientific articles, news reports) and comparing the resulting isotopy structural metrics against the narrative baseline.

## Limitations

- **Methodological dependence on extraction pipeline:** All structural metric interpretations hinge on GPT-4o's isotopy extraction accuracy (69.4% benchmark), which the study acknowledges as a critical unknown.
- **Limited structural diversity:** The analysis focuses exclusively on story continuation tasks using ROCStories, which are specifically designed for narrative coherence.
- **Model size constraints:** Only one model per size tier was tested (3B, 12B, 14B, 27B), making it unclear whether differences stem from architectural choices or scale effects.

## Confidence

**High confidence:** Coverage balance preservation near optimal values (≈1.0) across all five LLMs, confirmed by Kruskal-Wallis test showing systematic differences but consistent near-optimal performance.

**Medium confidence:** Semantic relevance of extracted isotopies (high similarity between isotopy labels and story titles), though this relies on the embedding model and assumptions about title semantics.

**Low confidence:** Claims about mechanism—specifically how LLMs "capture textual semantic properties" during training, which the paper explicitly states is unclear.

## Next Checks

1. **Extraction pipeline validation:** Run GPT-4o on the 26-text linguistic benchmark with and without CoT prompting on a stratified subset of the 10k stories to verify extraction reliability doesn't degrade at scale.

2. **Sampling strategy ablation:** Complete stories using temperature values 0.3, 0.7, and 1.0 to test whether isotopy preservation is robust to sampling parameters or whether the temperature=0.5 finding is an artifact.

3. **Genre generalization test:** Apply the complete pipeline to non-narrative texts from the Argilla database (medical reports, patents, news) mentioned in Section 7 to assess whether isotopy preservation generalizes beyond story completion.