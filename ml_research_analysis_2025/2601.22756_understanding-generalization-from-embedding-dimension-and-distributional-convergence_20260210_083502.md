---
ver: rpa2
title: Understanding Generalization from Embedding Dimension and Distributional Convergence
arxiv_id: '2601.22756'
source_url: https://arxiv.org/abs/2601.22756
tags:
- generalization
- dimension
- embedding
- wasserstein
- intrinsic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how the geometry of learned representations
  controls generalization performance in deep neural networks. The authors develop
  a post-training generalization bound that explicitly depends on the intrinsic dimension
  of embeddings and the Lipschitz constant of the network, rather than on parameter
  counts or hypothesis class complexity.
---

# Understanding Generalization from Embedding Dimension and Distributional Convergence

## Quick Facts
- arXiv ID: 2601.22756
- Source URL: https://arxiv.org/abs/2601.22756
- Reference count: 40
- Primary result: Final-layer embedding dimension strongly predicts generalization performance, with lower intrinsic dimension associated with better generalization across architectures.

## Executive Summary
This paper establishes a post-training generalization bound that explicitly depends on the intrinsic dimension of embeddings and the Lipschitz constant of the network, rather than on parameter counts or hypothesis class complexity. The authors show that the population risk can be bounded by the intrinsic dimension (which governs Wasserstein convergence of empirical to population embedding distributions) and the sensitivity of the downstream mapping (characterized by Lipschitz constants). Experiments across architectures and datasets demonstrate that final-layer embedding dimension is a strong empirical predictor of generalization, with lower intrinsic dimension associated with better performance. The theory explains this observation by showing that at the final layer, architectural sensitivity vanishes and the bound is dominated by embedding dimension.

## Method Summary
The paper develops a generalization bound using distributional convergence in Wasserstein space, where the intrinsic dimension of embeddings controls the rate at which empirical distributions converge to population distributions. The bound depends on both intrinsic dimension and network Lipschitz constants. Experiments validate the theory by extracting embeddings at different layers from trained networks, estimating intrinsic dimension using MLE methods, computing Wasserstein distances between validation and test embedding distributions, and correlating these quantities with generalization gaps. The analysis focuses on final-layer embeddings where the bound simplifies, as well as intermediate layers where both dimension and Lipschitz sensitivity must be considered jointly.

## Key Results
- Final-layer embedding dimension strongly correlates with generalization performance across ResNet, ConvNeXt, and language model architectures
- Lower intrinsic embedding dimension accelerates Wasserstein convergence of empirical to population distributions, reducing generalization gap
- At the final layer, the generalization bound simplifies because architectural sensitivity vanishes (L_L(F) = 1 for identity mapping)
- Narrowing layer width reduces embedding dimension but increases Lipschitz constant, creating a tradeoff with no guaranteed generalization improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lower intrinsic embedding dimension accelerates Wasserstein convergence of empirical to population distributions, reducing generalization gap.
- Mechanism: The empirical embedding distribution converges to its population counterpart at rate n^{-1/(d_k+ε)}, where d_k is the upper Wasserstein dimension. Lower d_k means fewer samples needed to approximate the true distribution, reducing the gap between training and test performance.
- Core assumption: Embeddings satisfy bounded support (Assumption 3.12) and the distribution has finite upper Wasserstein dimension.
- Evidence anchors:
  - [abstract]: "intrinsic dimension...determines the convergence rate of empirical embedding distribution to the population distribution in Wasserstein distance"
  - [Theorem 3.8]: "E[W_p(μ,μ̂_n)] ≤ C n^{-1/s} where s = d*_p(μ) + ε"
  - [corpus]: Weak direct support; related work on distributional embeddings (arXiv:2601.18952) discusses kernel mean embeddings but not dimension-dependent convergence rates.
- Break condition: If embeddings concentrate on manifolds with effectively infinite dimension or unbounded support, convergence guarantees degrade.

### Mechanism 2
- Claim: Network Lipschitz constant L_k(F) amplifies embedding distribution discrepancies into prediction errors.
- Mechanism: The generalization bound includes a sensitivity term L̄_k = L_k(F)M_F + L_k(F*)M_F* that multiplies the Wasserstein distance. Even low-dimensional embeddings can generalize poorly if the downstream mapping is highly sensitive to small perturbations.
- Core assumption: The tail map F_k and Bayes predictor F*_k are locally Lipschitz (Assumption 3.13).
- Evidence anchors:
  - [Section 4.1]: "the factor L̄_k quantifies how discrepancies in the embedding distribution are amplified by downstream mappings"
  - [Figure 5B]: As layer width decreases, embedding dimension drops but Lipschitz constant increases, offsetting gains
  - [corpus]: No direct corpus support for this specific Lipschitz-amplification mechanism in generalization bounds.
- Break condition: If networks are not Lipschitz (e.g., unbounded activations, no weight constraints), the amplification factor becomes unbounded.

### Mechanism 3
- Claim: At the final layer, the generalization bound simplifies because architectural sensitivity vanishes (L_L(F) = 1 for identity mapping).
- Mechanism: At the output layer, the tail map from embeddings to predictions is the identity, eliminating network-dependent amplification. The bound depends only on intrinsic dimension d_L, embedding diameter D_L, and loss-dependent constants.
- Core assumption: Final-layer representation coincides with model output (Z_L = F(X)).
- Evidence anchors:
  - [Corollary 4.2]: "At the final layer...architectural sensitivity disappears from the bound, leaving a dependence only on intrinsic dimension d_L"
  - [Section 5.2-5.3]: Final-layer dimension strongly correlates with generalization across ResNets, ConvNeXts, and language models
  - [corpus]: Weak support; grokking paper (arXiv:2505.15624) notes embedding importance but doesn't address final-layer simplification.
- Break condition: For intermediate layers, must jointly consider both dimension and Lipschitz sensitivity—dimension alone is insufficient.

## Foundational Learning

- Concept: **Wasserstein distance (W_1)**
  - Why needed here: Quantifies how far empirical embedding distribution is from population distribution; directly appears in generalization bound.
  - Quick check question: Given two sets of embeddings from validation and test sets, can you compute W_1 using the Kantorovich-Rubinstein dual?

- Concept: **Upper Wasserstein dimension (d*_p)**
  - Why needed here: Determines the statistical rate n^{-1/(d+ε)} at which empirical measures converge; lower values mean faster convergence.
  - Quick check question: Why does d*_p depend on covering numbers and allow ignoring a τ-fraction of probability mass?

- Concept: **Intrinsic dimension estimation (MLE method)**
  - Why needed here: Practical proxy for Wasserstein dimension; used throughout experiments to correlate with generalization.
  - Quick check question: How does the choice of nearest-neighbor hyperparameter K affect whether you capture local vs. global dimensionality?

## Architecture Onboarding

- Component map:
  - Encoder F_{≤k}: Maps input X to embedding Z_k at layer k
  - Tail map F_k: Maps embedding Z_k to output (becomes identity at final layer)
  - Bayes predictor F*_k: Theoretical optimal mapping from Z_k to output (not learned, used for analysis)
  - Oracle loss g_k(z) = ℓ(F_k(z), F*_k(z)): Smooth surrogate enabling Lipschitz analysis

- Critical path:
  1. Extract embeddings at target layer from trained model
  2. Estimate intrinsic dimension using MLE (Levina-Bickel) with appropriate K
  3. Compute Wasserstein distance between validation and test embedding distributions
  4. Correlate dimension/W_1 with generalization gap
  5. For intermediate layers, additionally estimate Lipschitz constant via spectral norm product

- Design tradeoffs:
  - Narrowing layer width → lower dimension but higher Lipschitz constant (Figure 5); no guaranteed generalization improvement
  - Larger K in dimension estimation → captures global structure, better correlation with generalization (Appendix C.1)
  - Final-layer analysis → simpler (no Lipschitz estimation) but less architectural insight than intermediate layers

- Failure signatures:
  - Dimension estimates vary wildly with K → insufficient samples or high noise in embeddings
  - W_1 doesn't correlate with generalization → may be at intermediate layer with high Lipschitz sensitivity
  - Contradictory dimension-generalization relationship → check that embeddings are from held-out data, not training set

- First 3 experiments:
  1. Replicate Figure 2: Train autoencoder on MNIST, verify W_1 scales as n^{-1/(d+ε)} by varying sample size and bottleneck dimension.
  2. Replicate Figure 3: Extract final-layer embeddings from ResNet-18/34/50/101/152 on CIFAR-10, correlate intrinsic dimension with class-wise generalization gaps.
  3. Intervention experiment: Vary width of a single intermediate layer in MLP, track both dimension and Lipschitz constant to confirm tradeoff mechanism.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can reliable and scalable methods be developed for estimating or bounding Lipschitz constants in deep networks beyond the spectral norm product approximation for simple MLPs?
- Basis in paper: [explicit] The authors state: "Estimating the Lipschitz constants remains challenging in practice, and developing reliable and scalable methods for bounding or estimating Lipschitz constants in deep networks is an important open problem."
- Why unresolved: The paper uses spectral norm products only for ReLU MLPs, which provides an upper bound. For modern architectures with normalization, skip connections, and attention, tractable Lipschitz estimation remains unsolved.
- What evidence would resolve it: New algorithms that provide tight, computable bounds on layer-wise or network-wide Lipschitz constants for ResNets, Transformers, and other modern architectures.

### Open Question 2
- Question: Can the theoretical framework be extended to relax the assumption of Lipschitz continuity of the Bayes predictor while preserving meaningful generalization bounds?
- Basis in paper: [explicit] The authors note: "Assumptions such as Lipschitz continuity of the Bayes predictor are necessary to relate a specific layer's embedding to the output; relaxing these is an important future direction."
- Why unresolved: The Lipschitz assumption on the Bayes predictor enables the Wasserstein-based analysis, but may not hold in practice. The paper does not explore alternative regularity conditions.
- What evidence would resolve it: Generalization bounds derived under weaker assumptions (e.g., Hölder continuity, bounded variation, or distributional smoothness) with empirical validation.

### Open Question 3
- Question: How do the constants (Ck, Dk) in the generalization bound behave, and can they be tightened without sacrificing the dimension-dependent convergence rate?
- Basis in paper: [explicit] "Our bound contains constants that may be loose, yet experiments show that variations in embedding dimension effectively track generalization error."
- Why unresolved: While the scaling n^{-1/(d+ε)} matches empirical behavior, the multiplicative constants are not characterized theoretically, limiting the bound's quantitative predictive power.
- What evidence would resolve it: Refined analysis yielding explicit, data-dependent constants; empirical demonstration that bound values (not just scaling) match observed generalization gaps.

### Open Question 4
- Question: Can embedding-based generalization analysis be adapted to settings where the Bayes predictor is unavailable, such as self-supervised or unsupervised representation learning?
- Basis in paper: [inferred] The introduction criticizes existing metrics for requiring labels, yet the theory relies on the Bayes predictor F* which requires label information to define. The framework thus remains fundamentally supervised.
- Why unresolved: The decomposition uses the Bayes predictor to obtain a smooth surrogate for discrete labels, making the extension to label-free settings non-trivial.
- What evidence would resolve it: A reformulation avoiding the Bayes predictor term, or alternative surrogates applicable to self-supervised objectives, with empirical validation on contrastive learning benchmarks.

## Limitations
- The assumption that embeddings converge at the theoretical rate n^{-1/(d+ε)} requires bounded support, which may not hold for unbounded activation functions or unbounded data.
- Lipschitz sensitivity amplification (Mechanism 2) lacks direct empirical validation beyond the width-sensitivity tradeoff in Figure 5.
- The simplification at the final layer (Mechanism 3) depends on the architecture being "wide enough" to avoid bottleneck-induced sensitivity, but this threshold is not quantified.

## Confidence
- **High**: The empirical correlation between final-layer intrinsic dimension and generalization performance across diverse architectures.
- **Medium**: The theoretical mechanism linking dimension to Wasserstein convergence rates.
- **Low**: The quantitative impact of Lipschitz sensitivity amplification on generalization across different architectural choices.

## Next Checks
1. Test the n^{-1/(d+ε)} scaling empirically by training autoencoders with bottleneck dimensions d∈{16,32,64,128,256,512} on MNIST and measuring Wasserstein distance between train/test embedding distributions at varying sample sizes.
2. Validate the width-sensitivity tradeoff by training a 6-layer MLP on MNIST with layer-3 width ∈{10,20,40,60,80,100} and measuring both intrinsic dimension and spectral norm product to confirm opposing trends.
3. Check robustness of correlation claims by varying the MLE nearest-neighbor hyperparameter K and confirming that dimension-generalization correlation strengthens for larger K values that capture global structure.