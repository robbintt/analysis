---
ver: rpa2
title: 'GroupCoOp: Group-robust Fine-tuning via Group Prompt Learning'
arxiv_id: '2509.23781'
source_url: https://arxiv.org/abs/2509.23781
tags:
- group
- learning
- training
- groupcoop
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GroupCoOp introduces a debiased fine-tuning method for vision-language
  models that improves group robustness by learning group-specific text prompts. It
  addresses subgroup imbalance in fine-tuning datasets by employing group context
  optimization, where each group is represented by learnable text prompts in the embedding
  space.
---

# GroupCoOp: Group-robust Fine-tuning via Group Prompt Learning

## Quick Facts
- arXiv ID: 2509.23781
- Source URL: https://arxiv.org/abs/2509.23781
- Authors: Nayeong Kim; Seong Joon Oh; Suha Kwak
- Reference count: 40
- Key result: Achieves SOTA group robustness by learning group-specific text prompts, training only 0.016% of network parameters

## Executive Summary
GroupCoOp introduces a debiased fine-tuning method for vision-language models that improves group robustness by learning group-specific text prompts. It addresses subgroup imbalance in fine-tuning datasets by employing group context optimization, where each group is represented by learnable text prompts in the embedding space. These prompts serve as classifiers for their respective groups, enabling balanced learning across both majority and minority groups. A pseudo group labeling strategy generates training labels using a group-annotated validation set and confidence-based prediction.

## Method Summary
GroupCoOp addresses group imbalance in vision-language model fine-tuning through a novel approach that learns group-specific text prompts. The method maintains learnable prompts for each group in the embedding space, which act as classifiers to balance learning across different subgroups. During training, these prompts are optimized alongside the model parameters, allowing the system to better capture group-specific characteristics. A pseudo group labeling strategy uses a group-annotated validation set to generate training labels, with predictions weighted by confidence scores. The approach achieves significant parameter efficiency, training only 0.016% of the network's parameters while maintaining or exceeding performance compared to full fine-tuning methods.

## Key Results
- Achieves state-of-the-art results on five benchmarks across five CLIP architectures
- Occasionally outperforms full fine-tuning methods while training only 0.016% of parameters
- Demonstrates improved group robustness across various vision-language tasks

## Why This Works (Mechanism)
GroupCoOp works by introducing group-specific learnable text prompts that act as adaptive classifiers for different subgroups. These prompts allow the model to maintain balanced attention across all groups during fine-tuning, preventing the model from overfitting to majority groups. The pseudo labeling strategy ensures that minority groups receive adequate representation during training by leveraging confident predictions from a group-annotated validation set. The embedding space representation of group prompts enables efficient optimization while maintaining semantic coherence with the underlying vision-language model architecture.

## Foundational Learning
- **Group imbalance in vision-language models**: Understanding how training data bias affects model performance across different subgroups; quick check: evaluate model accuracy across majority vs. minority groups
- **Vision-language model fine-tuning**: Knowledge of how CLIP and similar models are adapted to specific tasks; quick check: measure parameter updates during fine-tuning
- **Prompt learning in NLP**: Familiarity with using text prompts as learnable parameters for task adaptation; quick check: analyze prompt embedding space geometry
- **Pseudo labeling strategies**: Understanding how to generate training labels from model predictions; quick check: evaluate label quality through confidence thresholding
- **Group robustness metrics**: Knowledge of evaluation metrics for subgroup performance; quick check: compare accuracy gaps between groups

## Architecture Onboarding

**Component Map**: Input data -> Group context embedding -> Learnable group prompts -> CLIP model -> Output predictions

**Critical Path**: The most critical path involves the group context embedding and learnable prompts, as these components directly address the group imbalance problem. The pseudo labeling strategy serves as an auxiliary component that enhances training stability.

**Design Tradeoffs**: The main tradeoff is between parameter efficiency and model capacity. GroupCoOp sacrifices some model expressiveness by using only learnable prompts instead of full fine-tuning, but gains significant efficiency. The pseudo labeling strategy trades off potential label noise for improved minority group representation.

**Failure Signatures**: Performance degradation may occur when group labels are highly noisy or when the validation set is too small to provide reliable pseudo labels. The method may also struggle with groups that have very few samples in the training data.

**First Experiments**:
1. Evaluate group accuracy gaps on a balanced test set after fine-tuning
2. Compare parameter counts between GroupCoOp and full fine-tuning approaches
3. Test sensitivity to validation set size and quality

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Reliance on group-annotated validation set may limit real-world applicability
- Performance sensitivity to validation set quality and size not thoroughly explored
- Method may struggle with highly noisy or uncertain group annotations
- Comparison with other debiasing methods could be more comprehensive

## Confidence

**Confidence Labels:**
- Group-specific prompt learning effectiveness: High
- Parameter efficiency claims: High
- State-of-the-art performance claims: Medium
- Real-world applicability with imperfect group labels: Low

## Next Checks
1. Test the method's performance when group labels in the validation set are partially corrupted or missing
2. Evaluate computational overhead during inference when using group prompts compared to standard CLIP inference
3. Assess robustness across different types of group imbalance distributions (e.g., long-tailed vs. random)