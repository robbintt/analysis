---
ver: rpa2
title: 'Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets'
arxiv_id: '2602.00188'
source_url: https://arxiv.org/abs/2602.00188
tags:
- demand
- pricing
- prices
- product
- price
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses dynamic pricing in high-dimensional markets
  with similar products, focusing on interpretability and efficiency. It introduces
  an Additive Feature Decomposition-based Low-Dimensional (AFDLD) demand model where
  product prices are expressed as sums of interpretable attribute-level contributions
  and substitution effects are explicitly modeled.
---

# Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets

## Quick Facts
- arXiv ID: 2602.00188
- Source URL: https://arxiv.org/abs/2602.00188
- Authors: Srividhya Sethuraman; Chandrashekar Lakshminarayanan
- Reference count: 40
- Primary result: ADEPT achieves sublinear regret O(√d T^(3/4)) while providing interpretable attribute-level pricing

## Executive Summary
This paper tackles the challenge of dynamic pricing in markets with similar products where interpretability is crucial for business adoption. The authors introduce an Additive Feature Decomposition-based Low-Dimensional (AFDLD) demand model that expresses product prices as sums of interpretable attribute-level contributions while explicitly modeling substitution effects. The proposed ADEPT algorithm operates directly in attribute space, achieving sublinear regret through a projection-free, gradient-free approach that makes it computationally efficient. The work demonstrates that autonomous pricing agents can achieve both interpretability and efficiency by leveraging structured, attribute-driven representations rather than working directly with high-dimensional product vectors.

## Method Summary
The paper presents an interpretable demand model where prices are decomposed into additive attribute-level components, allowing the algorithm to learn how individual product attributes contribute to pricing decisions. ADEPT operates by iteratively estimating attribute-level contributions and adjusting prices based on observed demand, using a projection-free optimization approach that avoids expensive matrix operations. The algorithm's regret guarantee of O(√d T^(3/4)) is achieved through careful control of exploration-exploitation trade-offs in the attribute space, making it scalable to high-dimensional markets while maintaining interpretability at the attribute level.

## Key Results
- ADEPT learns near-optimal prices with sublinear regret O(√d T^(3/4)) in synthetic and real-world experiments
- The algorithm adapts rapidly to market changes while maintaining interpretable attribute-level price explanations
- Performance comparisons show ADEPT outperforms baseline methods in both pricing accuracy and interpretability metrics

## Why This Works (Mechanism)
The approach succeeds by decomposing the complex pricing problem into interpretable attribute-level components, which reduces the effective dimensionality while preserving essential pricing relationships. By explicitly modeling substitution effects and working directly in attribute space rather than product space, the algorithm avoids the curse of dimensionality that plagues traditional multi-product pricing methods. The projection-free optimization strategy enables efficient learning without requiring expensive matrix inversions or gradient computations, making it practical for real-world deployment.

## Foundational Learning
- Additive demand modeling: Why needed - captures how individual attributes contribute to overall demand; Quick check - verify demand can be expressed as sum of attribute effects
- Attribute-level interpretability: Why needed - enables business stakeholders to understand pricing decisions; Quick check - confirm attribute contributions are meaningful and actionable
- Projection-free optimization: Why needed - avoids computational bottlenecks in high-dimensional settings; Quick check - measure computational efficiency vs projection-based methods
- Substitution effect modeling: Why needed - accounts for how price changes in one product affect demand for similar products; Quick check - validate substitution patterns match market behavior
- Sublinear regret bounds: Why needed - ensures learning efficiency over time; Quick check - verify regret scales as O(√d T^(3/4)) in experiments

## Architecture Onboarding

**Component map:** Attribute decomposition -> Price estimation -> Demand observation -> Attribute contribution update -> Price adjustment

**Critical path:** The algorithm iteratively cycles through attribute decomposition (identifying which attributes matter for pricing), price estimation (setting prices based on current attribute understanding), demand observation (collecting customer response data), and attribute contribution update (refining understanding of attribute importance).

**Design tradeoffs:** The choice between interpretability and raw pricing performance is addressed by working in attribute space rather than product space, sacrificing some optimization potential for transparency. The projection-free approach trades theoretical convergence speed for computational efficiency and scalability.

**Failure signatures:** The model may fail when product attributes cannot be meaningfully decomposed into interpretable components, when substitution effects are too complex for additive modeling, or when market conditions change too rapidly for the sublinear regret guarantees to hold.

**Three first experiments:**
1. Test attribute decomposition accuracy on synthetic datasets with known ground truth attribute contributions
2. Measure computational efficiency comparing ADEPT to projection-based pricing algorithms
3. Validate interpretability by conducting human evaluation studies on attribute-level price explanations

## Open Questions the Paper Calls Out
The paper acknowledges several important open questions: how to extend the approach to non-stationary markets where demand functions change rapidly, whether the attribute decomposition assumption holds for products with complex, non-linear characteristics, and how to scale the method to extremely high-dimensional attribute spaces while maintaining interpretability.

## Limitations
- The assumption that all products can be represented as linear combinations of interpretable attributes may not hold in markets with complex product characteristics
- The sublinear regret bound assumes stationary market conditions and may degrade in highly volatile environments
- Experimental validation is limited to synthetic datasets and a single real-world retail dataset, raising generalizability concerns

## Confidence

High confidence in the mathematical formulation of the AFDLD model and ADEPT algorithm's theoretical guarantees under stated assumptions. Medium confidence in empirical results, as synthetic experiments are controlled but real-world validation is limited to one dataset. Low confidence in robustness claims across diverse market conditions and product categories beyond tested scenarios.

## Next Checks
1. Test ADEPT on multiple diverse real-world datasets from different industries (financial services, airline pricing, industrial equipment) to assess generalizability
2. Evaluate performance under controlled market volatility scenarios with known demand function change rates
3. Compare interpretability quality using standardized metrics (feature importance consistency, human evaluation studies) against other interpretable pricing models