---
ver: rpa2
title: Phishing Email Detection Using Large Language Models
arxiv_id: '2512.10104'
source_url: https://arxiv.org/abs/2512.10104
tags:
- phishing
- email
- prompt
- detection
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of detecting phishing emails
  using Large Language Models (LLMs) while evaluating their vulnerabilities to various
  attack vectors. The core method involves LLM-PEA, a framework that tests LLMs across
  prompt injection, adversarial refinement, and multilingual attacks using three frontier
  models (GPT-4o, Claude Sonnet 4, Grok-3).
---

# Phishing Email Detection Using Large Language Models

## Quick Facts
- arXiv ID: 2512.10104
- Source URL: https://arxiv.org/abs/2512.10104
- Reference count: 40
- Primary result: LLMs achieve >90% phishing detection accuracy but show 4-12% vulnerability to adversarial attacks

## Executive Summary
This study evaluates Large Language Models (LLMs) for phishing email detection using the LLM-PEA framework, testing three frontier models (GPT-4o, Claude Sonnet 4, Grok-3) against various attack vectors. The research demonstrates that while LLMs achieve over 90% accuracy in detecting phishing emails, they remain vulnerable to prompt injection, adversarial refinement, and multilingual attacks. Claude Sonnet 4 shows particularly concerning performance degradation in non-English languages, with false positive rates increasing by 904%.

## Method Summary
The study employs LLM-PEA (Large Language Model Phishing Email Assessment), a systematic evaluation framework that tests frontier LLMs across three attack dimensions: prompt injection, adversarial refinement, and multilingual attacks. The framework assesses model performance using standardized phishing email datasets while applying controlled attack vectors to measure vulnerability. Three leading LLMs (GPT-4o, Claude Sonnet 4, Grok-3) are evaluated under identical conditions to compare their robustness and detection capabilities across different threat scenarios.

## Key Results
- LLMs achieve over 90% accuracy in phishing email detection
- GPT-4o and Claude Sonnet 4 show 4-12% attack success rates for adversarial attacks
- Claude Sonnet 4 experiences 904% increase in false positive rates for non-English languages

## Why This Works (Mechanism)
The effectiveness stems from LLMs' ability to process contextual patterns, semantic relationships, and linguistic cues that distinguish phishing attempts from legitimate communications. These models leverage their training on vast text corpora to identify subtle indicators like urgency language, suspicious links, and social engineering patterns that traditional rule-based systems might miss.

## Foundational Learning
1. **LLM vulnerability taxonomy** - Why needed: Understanding different attack vectors (prompt injection, adversarial refinement, multilingual attacks) is essential for comprehensive security assessment; Quick check: Can you categorize a given attack method into one of these three types?
2. **Phishing detection metrics** - Why needed: Accuracy alone doesn't capture real-world performance; precision, recall, and false positive rates are critical for practical deployment; Quick check: What metric would you prioritize for a high-stakes security application?
3. **Multilingual NLP challenges** - Why needed: Language-specific performance variations can create security gaps; understanding these differences is crucial for global deployments; Quick check: Can you explain why non-English languages might be more vulnerable to certain attacks?

## Architecture Onboarding
**Component Map:** Email input -> Preprocessor -> LLM inference -> Confidence scoring -> Output classification
**Critical Path:** Email parsing → Contextual analysis → Threat pattern recognition → Confidence threshold evaluation
**Design Tradeoffs:** High accuracy vs. computational cost, false positive tolerance vs. security rigor, multilingual support vs. performance consistency
**Failure Signatures:** Unexpected drop in detection rates for specific language pairs, increased false positives in adversarial scenarios, model-specific response patterns to known attack templates
**First Experiments:** 1) Baseline detection accuracy test on clean dataset, 2) Adversarial attack simulation with known vulnerabilities, 3) Cross-language performance comparison

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to three frontier models without testing open-source alternatives
- Multilingual assessment lacks specificity about which non-English languages were tested
- Attack success rates may change as models receive updates and defenses evolve
- No assessment of temporal stability or long-term vulnerability patterns

## Confidence
- High Confidence: LLM performance in standard phishing detection (>90% accuracy)
- Medium Confidence: Specific vulnerability rates to adversarial attacks (4-12% success rates)
- Medium Confidence: Multilingual performance degradation (904% increase in false positives for Claude Sonnet 4)

## Next Checks
1. Cross-Model Validation: Test LLM-PEA framework against broader range of LLM architectures including open-source models
2. Dynamic Attack Evolution Assessment: Conduct longitudinal testing to measure how quickly LLM defenses adapt to known attack patterns
3. Real-World Deployment Simulation: Implement detection system in controlled production environment with live email traffic