---
ver: rpa2
title: 'Trans-XFed: An Explainable Federated Learning for Supply Chain Credit Assessment'
arxiv_id: '2508.13715'
source_url: https://arxiv.org/abs/2508.13715
tags:
- learning
- data
- client
- clients
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses privacy-preserving supply chain credit assessment
  by developing a federated learning framework that handles data silos, class imbalance,
  non-IID distributions, and black-box model interpretability. The core method, Trans-XFed,
  integrates FedProx with a performance-based client selection strategy, transformer-based
  feature extraction, and integrated gradients for explainability.
---

# Trans-XFed: An Explainable Federated Learning for Supply Chain Credit Assessment

## Quick Facts
- arXiv ID: 2508.13715
- Source URL: https://arxiv.org/abs/2508.13715
- Reference count: 35
- Achieved recall of 0.8889 and F1 score of 0.7137 for defaulting samples in just 10 communication rounds

## Executive Summary
This paper addresses privacy-preserving supply chain credit assessment through Trans-XFed, a federated learning framework that tackles data silos, class imbalance, non-IID distributions, and black-box model interpretability. The approach integrates FedProx with a performance-based client selection strategy, transformer-based feature extraction, and integrated gradients for explainability. Homomorphic encryption secures parameter exchange. Experiments on real supply chain credit datasets demonstrate superior performance compared to baselines, achieving faster convergence while maintaining high recall for the critical defaulting class prediction.

## Method Summary
Trans-XFed combines FedProx federated learning with a transformer encoder and performance-based client selection. The central server selects the top 50% of clients based on local F1 scores each round, aggregates encrypted model parameters using weighted averaging, and updates the global model. The transformer encoder captures feature-to-feature relationships through self-attention, while weighted negative log-likelihood loss prioritizes the minority defaulting class. The framework uses CKKS homomorphic encryption to protect privacy during parameter exchange.

## Key Results
- Trans-XFed achieved recall of 0.8889 and F1 score of 0.7137 for defaulting samples in just 10 communication rounds
- FedAvg with NLL achieved similar recall (0.8879) but required 36 rounds, demonstrating PBCS's acceleration benefits
- Explainability analysis revealed distinct attention patterns for defaulting versus non-defaulting samples, with "repayment method" identified as a central feature for default prediction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Performance-based client selection accelerates convergence by prioritizing clients with higher-quality local updates
- Mechanism: The server ranks all K clients by local F1 scores and selects the top M = rK clients (r = 0.5) for training and aggregation
- Core assumption: Clients with higher local F1 scores provide parameter updates that transfer more effectively to the global model
- Evidence anchors: Trans-XFed achieved highest recall (0.8889) and F1 (0.7137) in just 10 rounds vs. 36 rounds for FedAvg

### Mechanism 2
- Claim: Transformer encoder's self-attention mechanism captures feature-to-feature relationships that improve credit risk representation
- Mechanism: Multi-head self-attention (3 heads) computes pairwise attention scores between all features, creating rich embeddings
- Core assumption: Credit default prediction depends on higher-order feature interactions that attention can capture more effectively
- Evidence anchors: Attention patterns showed "repayment method" as central to default prediction with distinct patterns for defaulting vs. non-defaulting samples

### Mechanism 3
- Claim: Weighted Negative Log-Likelihood loss with higher weights for the minority class improves recall for default prediction
- Mechanism: Assigns class weights inversely proportional to class frequency (0.25 for non-defaulters, 0.75 for defaulters)
- Core assumption: False negatives (missing a defaulter) are substantially more costly than false positives in credit assessment
- Evidence anchors: Trans-XFed with NLL achieved recall 0.8889 vs. 0.6059 with Focal loss

## Foundational Learning

- **Federated Learning (FedAvg vs. FedProx)**
  - Why needed here: Trans-XFed builds on FedProx, which adds a proximal term to FedAvg
  - Quick check question: Can you explain how FedProx's proximal term keeps local updates from diverging too far from the global model?

- **Transformer Self-Attention Mechanism**
  - Why needed here: The model's encoder uses multi-head attention to compute feature relationships
  - Quick check question: Given an input matrix X of shape (batch, features), can you describe how scaled dot-product attention computes a (features × features) attention matrix?

- **Integrated Gradients for Explainability**
  - Why needed here: This XAI technique produces feature attribution scores
  - Quick check question: Why does Integrated Gradients require a baseline input, and how does the path integral from baseline to actual input produce attribution scores?

## Architecture Onboarding

- **Component map:** Central server -> PBCS ranking -> Parameter aggregation -> Global model update; Client nodes -> Local training -> Encryption -> Parameter transmission
- **Critical path:** 1) Server broadcasts global weights to all K clients 2) Each client evaluates local F1; server ranks and selects top M = rK clients 3) Selected clients train locally with weighted NLL 4) Clients encrypt updated weights 5) Server aggregates encrypted weights via weighted average 6) Server updates global model; repeat
- **Design tradeoffs:** Selection ratio r=0.5 balances convergence speed against data diversity; μ scheduling (0 → 0.01) balances local freedom with global alignment; Transformer depth (3 heads) reduces computational cost but may limit capacity
- **Failure signatures:** Stagnant global F1 indicates potential client selection bias; high precision but low recall suggests insufficient class weights; indistinguishable attention patterns indicate transformer may not be learning discriminative interactions
- **First 3 experiments:** 1) Reproduce baseline comparison (FedAvg, FedProx, Trans-XFed) on 4-client split 2) Ablate client selection by replacing PBCS with random selection 3) Validate explainability by computing Integrated Gradients attributions and attention heatmaps

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the performance-based client selection strategy introduce a bias that degrades global model generalizability when local data distributions are extremely dissimilar?
- **Basis in paper:** PBCS selects clients with highest local F1 scores to speed up convergence, but high local F1 may indicate overfitting to local data
- **Why unresolved:** Experiments don't explicitly measure trade-off between convergence speed and global accuracy under extreme distribution skewness
- **What evidence would resolve it:** Ablation study simulating extreme Non-IID conditions comparing global model accuracy degradation between PBCS and random selection

### Open Question 2
- **Question:** How does the computational latency of CKKS homomorphic encryption compare to training time savings from reduced communication rounds?
- **Basis in paper:** Claims computational efficiency from faster convergence offsetting encryption overhead, but no empirical time measurements provided
- **Why unresolved:** Without quantitative benchmarks on encryption overhead relative to training time, practical feasibility remains unclear
- **What evidence would resolve it:** Reporting wall-clock time and computational resource usage for encryption, aggregation, and decryption steps versus local training

### Open Question 3
- **Question:** Does the framework maintain convergence stability and performance when scaled to thousands of clients?
- **Basis in paper:** Limited to 4 clients; claims scalability but behavior with massive participant numbers unverified
- **Why unresolved:** PBCS strategy might behave differently with larger client pools, affecting straggler issues and bandwidth saturation
- **What evidence would resolve it:** Simulation results demonstrating performance when increasing clients from 4 to 100+

## Limitations
- Transformer architecture underspecified (number of layers, hidden dimensions, position encoding method)
- PBCS validation scope limited; no comparison to alternative selection strategies
- Encryption overhead quantification missing (CKKS parameters unspecified)

## Confidence
- High confidence in FedProx + PBCS accelerating convergence (direct quantitative comparison)
- Medium confidence in transformer attention capturing meaningful credit risk feature interactions (qualitative patterns shown)
- Medium confidence in weighted NLL improving minority class recall (strong quantitative results but no ablation study)

## Next Checks
1. **Ablate client selection**: Replace PBCS with random client selection (r=0.5) while keeping all else constant; measure convergence speed and final F1 to quantify PBCS contribution
2. **Test attention robustness**: Perturb input features with noise and measure stability of attention patterns; compare against baseline model (e.g., logistic regression with SHAP)
3. **Verify encryption efficiency**: Profile runtime per communication round with and without CKKS encryption; calculate trade-off between privacy protection and computational overhead