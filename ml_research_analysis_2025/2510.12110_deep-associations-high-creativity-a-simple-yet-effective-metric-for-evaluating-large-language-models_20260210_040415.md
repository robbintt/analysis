---
ver: rpa2
title: 'Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating
  Large Language Models'
arxiv_id: '2510.12110'
source_url: https://arxiv.org/abs/2510.12110
tags:
- word
- association
- creativity
- llms
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes PACE (Parallel Association Chain Evaluation),
  a new metric for assessing LLM creativity based on associative distance. The method
  generates three parallel 20-word association chains per seed word, measures semantic
  distances between consecutive words using FastText embeddings, and averages these
  distances across chains and seeds to produce a creativity score.
---

# Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models

## Quick Facts
- **arXiv ID**: 2510.12110
- **Source URL**: https://arxiv.org/abs/2510.12110
- **Reference count**: 40
- **Primary result**: PACE metric achieves Spearman's ρ = 0.739 correlation with human creative writing rankings

## Executive Summary
The paper introduces PACE (Parallel Association Chain Evaluation), a novel metric for assessing LLM creativity based on associative distance. The method generates parallel word association chains and measures semantic distances between consecutive words to produce a creativity score. PACE demonstrates strong correlation with human-annotated creative writing rankings while being simple to implement and free from training data contamination issues. The metric provides insights into how LLMs perform relative to human associative patterns, showing that high-performing models achieve scores comparable to average humans but fall short of professional writers.

## Method Summary
PACE generates three parallel 20-word association chains for each seed word, measuring semantic distances between consecutive words using FastText embeddings. The method averages these distances across chains and seeds to produce a creativity score. The approach evaluates 30 diverse language models and compares results with human data from professionals and average individuals. By focusing on associative distance rather than direct creative output, PACE avoids the training data contamination issues common in creativity evaluation while maintaining strong correlation with human judgments of creative writing quality.

## Key Results
- PACE shows strong correlation with Chatbot Arena Creative Writing rankings (Spearman's ρ = 0.739, p < 0.001) across 30 diverse models
- High-performing LLMs achieve PACE scores comparable to average humans but fall short of professional writers
- Humans demonstrate greater diversity in associative patterns compared to LLMs

## Why This Works (Mechanism)
PACE works by quantifying the semantic distance between consecutive words in generated association chains, which captures the "leap" required for creative thinking. Creative associations often involve connecting seemingly unrelated concepts, and larger semantic distances between words indicate more novel connections. By generating multiple parallel chains and averaging distances, the metric reduces noise while maintaining sensitivity to creative patterns. The use of FastText embeddings provides robust semantic representations that capture word relationships effectively, while the parallel chain structure allows for comprehensive assessment of associative diversity.

## Foundational Learning

### FastText Embeddings
**Why needed**: Provide semantic representations of words to measure associative distances
**Quick check**: Verify that cosine similarity between embeddings correlates with human semantic judgments

### Parallel Chain Generation
**Why needed**: Reduces individual chain variance while capturing diverse associative patterns
**Quick check**: Confirm that multiple chains per seed word improve score stability

### Association Chain Length
**Why needed**: Balances sufficient depth for meaningful associations with computational efficiency
**Quick check**: Test whether 20-word chains capture optimal creative potential without redundancy

## Architecture Onboarding

**Component map**: Seed word selection -> Parallel chain generation -> FastText embedding extraction -> Semantic distance calculation -> Score aggregation

**Critical path**: The metric's effectiveness depends on the quality of FastText embeddings and the ability of models to generate diverse, semantically meaningful association chains

**Design tradeoffs**: Simplicity and efficiency versus comprehensive capture of all creative dimensions; semantic distance focus versus other creativity aspects like novelty or usefulness

**Failure signatures**: Poor performance indicates either embedding quality issues, model inability to generate diverse associations, or problems with the distance calculation methodology

**First experiments**: 
1. Validate correlation between semantic distances and human creativity ratings on a small scale
2. Test different association chain lengths to optimize the metric
3. Compare PACE scores across models with known creativity performance differences

## Open Questions the Paper Calls Out
Major uncertainties remain regarding the generalizability of PACE scores across different linguistic and cultural contexts. The study primarily used English seed words and models, leaving open questions about how the metric performs with multilingual or cross-cultural datasets. Additionally, while FastText embeddings capture semantic similarity effectively, they may not fully represent the nuanced associative processes that underlie human creativity, particularly in metaphorical or abstract thinking.

## Limitations
- Limited generalizability across different linguistic and cultural contexts
- May not fully capture all dimensions of human creativity, particularly metaphorical thinking
- Correlation with creative writing rankings represents a single validation approach

## Confidence
- **High confidence**: Technical implementation and reproducibility of the PACE metric
- **Medium confidence**: Correlation with human creative writing rankings
- **Medium confidence**: Comparison with human associative patterns given limited sample sizes

## Next Checks
1. Validate PACE scores using additional creative task datasets beyond creative writing, including problem-solving and divergent thinking tasks
2. Conduct cross-cultural validation by testing PACE with multilingual seed words and non-English language models
3. Perform longitudinal studies to track how PACE scores change as models are fine-tuned or exposed to different training paradigms