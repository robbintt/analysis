---
ver: rpa2
title: 'From Scarcity to Capability: Empowering Fake News Detection in Low-Resource
  Languages with LLMs'
arxiv_id: '2501.09604'
source_url: https://arxiv.org/abs/2501.09604
tags:
- news
- fake
- dataset
- bangla
- authentic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces BanFakeNews-2.0, an enhanced dataset for Bangla
  fake news detection, addressing the scarcity of resources in low-resource languages.
  It includes 13,000 verified fake news articles and 47,000 authentic articles across
  13 categories, along with a manually curated test set.
---

# From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs

## Quick Facts
- arXiv ID: 2501.09604
- Source URL: https://arxiv.org/abs/2501.09604
- Authors: Hrithik Majumdar Shibu; Shrestha Datta; Md. Sumon Miah; Nasrullah Sami; Mahruba Sharmin Chowdhury; Md. Saiful Islam
- Reference count: 10
- Key result: BLOOM 560M fine-tuned with QLoRA achieves 89% macro F1 on Bangla fake news detection

## Executive Summary
This paper addresses the scarcity of resources for fake news detection in low-resource languages by introducing BanFakeNews-2.0, a comprehensive dataset containing 13,000 verified fake news articles and 47,000 authentic articles across 13 categories. The authors develop benchmark models using traditional linguistic features, transformer-based architectures, and large language models fine-tuned with Quantized Low-Rank Approximation (QLoRA). The best-performing model, BLOOM 560M, achieves a macro F1 score of 89%, demonstrating that QLoRA enables effective fake news detection under compute constraints. The dataset and models are publicly released to advance research in low-resource language misinformation detection.

## Method Summary
The methodology involves dataset curation through web scraping and manual verification by three annotators (achieving 0.93 inter-annotator agreement), followed by deduplication to remove articles with >50% token overlap. Traditional models use TF-IDF with character and word n-grams plus FastText embeddings, classified by SVM. Transformer models include BERT variants (BanglaBERT, SagorBERT, XLM-RoBERTa, m-BERT) with linear classification heads. Large language models (BLOOM 560M, Phi-3 Mini 3.8B, Stable LM 2 1.6B, Llama 3.2 1B) are fine-tuned using QLoRA with 4-bit quantization, rank=8 LoRA adapters, and alpha=32. All models are trained on 70% of the data, validated on 15%, and tested on 15% plus an independent 1,000-article test set.

## Key Results
- BLOOM 560M with QLoRA achieves state-of-the-art 89% macro F1 for Bangla fake news detection
- Character 3-5 grams outperform word n-grams for fake news detection (1-4% F1 advantage)
- Manual verification with majority voting achieves 0.93 inter-annotator agreement
- BanFakeNews-2.0 contains 60,000 articles (13K fake, 47K authentic) across 13 categories

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning LLMs with QLoRA enables effective fake news detection in low-resource languages under compute constraints. 4-bit quantization reduces memory footprint while Low-Rank Adaptation (LoRA) adds trainable adapters (rank=8, alpha=32) that update only a small subset of parameters, preserving multilingual pretraining knowledge while adapting to domain-specific patterns. Core assumption: The multilingual pretraining corpus (ROOTS for BLOOM) transfers sufficient Bangla linguistic knowledge to enable effective downstream classification. Evidence: BLOOM 560M achieves 89% macro F1; QLoRA parameters specified as rank=8, alpha=32. Break condition: If the target low-resource language has minimal representation in the base LLM's pretraining corpus, adapter fine-tuning may fail to overcome foundational knowledge gaps.

### Mechanism 2
Character-level n-grams capture deceptive patterns in Bangla fake news more robustly than word-level features. Character 3-5 grams model subword morphology and orthographic patterns, providing resilience against vocabulary sparsity and obfuscation tactics common in misinformation. Core assumption: Fake news in Bangla exhibits distinctive character-level stylistic signatures that persist across topics and sources. Evidence: C3-Gram model surpassed unigram+bigram+trigram features by 1%, 4%, and 2% higher P, R, and F1 respectively for fake news; character-based models outperformed word-based models. Break condition: If fake news authors adopt sophisticated paraphrasing that alters character-level distributions while preserving deceptive intent, this signal degrades.

### Mechanism 3
Manual source verification with duplicate filtering improves model generalization to unseen test data. Cross-checking by three annotators with majority voting (inter-annotator agreement=0.93) reduces label noise; filtering >50% token overlap increases vocabulary diversity and prevents memorization of near-duplicates. Core assumption: The independent test set (1,000 articles) represents the true distribution of real-world Bangla fake news. Evidence: Each article cross-checked by three annotators achieving 0.93 agreement; duplicates filtered with >50% token overlap threshold. Break condition: If fact-checking sources systematically miss emerging misinformation formats (e.g., AI-generated content), the training distribution diverges from deployment reality.

## Foundational Learning

- **QLoRA (Quantized Low-Rank Adaptation)**
  - Why needed here: Enables fine-tuning LLMs on consumer-grade GPUs by reducing memory from 16-bit to 4-bit while maintaining performance through low-rank adapter matrices.
  - Quick check question: Can you explain why rank=8 in LoRA balances expressiveness against overfitting for small datasets?

- **Class imbalance in fake news datasets**
  - Why needed here: BanFakeNews-2.0 has 47K authentic vs. 13K fake news; macro F1 was used instead of accuracy to prevent majority-class bias.
  - Quick check question: Why would accuracy be misleading if 79% of your data is authentic news?

- **Cross-lingual transfer in multilingual models**
  - Why needed here: BLOOM and m-BERT leverage shared multilingual representations; understanding transfer helps explain why these outperform monolingual BanglaBERT.
  - Quick check question: How does multilingual pretraining on 46 languages potentially benefit a low-resource language like Bangla?

## Architecture Onboarding

- **Component map**: Web scraping → Manual verification (3 annotators, majority vote) → Deduplication (>50% overlap filter) → Train/val/test split (70/15/15) → TF-IDF/SVM or BERT encoder or LLM + LoRA → Classification head

- **Critical path**: Dataset curation (verification + deduplication is bottleneck—allows 0.93 agreement) → Preprocessing (remove English/hyperlinks; keep punctuation for LLMs) → Model selection (BLOOM 560M or m-BERT-unc for best fake-news F1) → Fine-tuning with QLoRA (4-bit, rank=8, alpha=32, paged Adam 8-bit)

- **Design tradeoffs**:
  - BLOOM 560M vs. larger LLMs: Smaller model enables broader deployment; larger models (Phi-3 3.8B) showed lower fake-news recall (58% vs. 69%)
  - Character vs. word n-grams: Character-level robust to morphology but loses semantic coherence; combine both for 86% macro F1
  - Punctuation retention: Essential for transformer context but increases sequence length

- **Failure signatures**:
  - Low fake-news recall with high authentic precision → model biased toward majority class; check class weights
  - Large gap between internal and external test performance → overfitting to training distribution; increase deduplication threshold
  - BanglaBERT underperforming m-BERT → monolingual pretraining data may be insufficient; prefer multilingual encoders

- **First 3 experiments**:
  1. Replicate BLOOM 560M + QLoRA baseline on BanFakeNews-2.0 train split; validate macro F1 ≈ 89% on internal test
  2. Ablate character n-grams vs. word n-grams with SVM; expect 1-4% F1 gap favoring character-level for fake news
  3. Test generalization: Train on original BanFakeNews, evaluate on BanFakeNews-2.0 independent test set; expect significant drop (Table 4 shows 29% → 67% when upgrading training data)

## Open Questions the Paper Calls Out

### Open Question 1
How do emerging large language models (Mistral, Minitron, GPT-4) perform on Bangla fake news detection in zero-shot settings compared to fine-tuned smaller models? Basis: "Testing emerging LLMs like Mistral, Minitron, and GPT 4 in zero-shot settings may provide further insights." Unresolved because study only evaluated smaller fine-tuned LLMs via QLoRA, not zero-shot settings with larger state-of-the-art models. Resolution: Benchmark comparison of zero-shot performance for GPT-4, Mistral, and Minitron against fine-tuned BLOOM 560M on the independent test set.

### Open Question 2
Can models trained on BanFakeNews-2.0 effectively detect fake news synthesized by advanced generative language models? Basis: "Generative language models are becoming more human-like, enabling them to imitate authentic news. However, the proposed dataset and pre-trained models may struggle to differentiate advanced fabricated news from upcoming generative models." Unresolved because dataset contains human-authored fake news, not AI-generated misinformation which may exhibit different linguistic patterns. Resolution: Evaluation of BLOOM and m-BERT models on a curated test set of GPT-4 or similar model-generated Bangla fake news.

### Open Question 3
What data augmentation or transfer learning strategies could improve detection performance for underrepresented categories (lifestyle, medical, religious)? Basis: From limitations: "The low fake news count in some news categories makes it difficult to differentiate" and Table 2 shows lifestyle (308 fake), medical (448 fake), religious (359 fake) have far fewer samples than politics (3,403 fake). Unresolved because category-specific performance was not reported, and the 4.6:1 authentic-to-fake imbalance varies significantly across categories. Resolution: Per-category F1 scores and experiments with targeted augmentation showing improved performance on sparse categories.

### Open Question 4
What computational optimizations are required to deploy these models for real-time fake news monitoring at scale? Basis: "Future work will focus on enhancing dataset features, refining models, and exploring real-time monitoring." Unresolved because paper evaluates classification accuracy but does not address latency, throughput, or resource constraints for streaming deployment scenarios. Resolution: Latency benchmarks and throughput measurements for BLOOM 560M and m-BERT-unc in simulated real-time inference environments.

## Limitations
- QLoRA effectiveness may not transfer to languages with minimal representation in base model pretraining corpus
- Character-level feature superiority demonstrated only on BanFakeNews-2.0, lacking external validation
- Annotation protocol quality controls don't guarantee representation of emerging misinformation formats

## Confidence
- **High Confidence**: BanFakeNews-2.0 provides substantially larger coverage than predecessor (60K vs. 29K articles); class imbalance necessitates macro F1 over accuracy; multilingual BERT variants outperform monolingual BanglaBERT
- **Medium Confidence**: QLoRA with BLOOM 560M achieves state-of-the-art performance (89% F1); character n-grams outperform word n-grams for fake news detection; manual verification with majority voting improves label quality
- **Low Confidence**: Same methodology transfers to other low-resource languages without modification; filtered dataset represents true distribution of Bangla fake news; character-level features remain effective as misinformation tactics evolve

## Next Checks
1. **Cross-Dataset Generalization Test**: Train BLOOM 560M + QLoRA on BanFakeNews-2.0, evaluate on independent Bangla fake news datasets or adversarially crafted test sets with novel misinformation patterns. Measure performance drop and identify failure modes.
2. **Pretraining Coverage Analysis**: Quantify Bangla representation in BLOOM's ROOTS pretraining corpus. Calculate token frequency, domain coverage (news vs. social media), and compare against languages where QLoRA transfers successfully. Validates whether claimed transfer is structurally feasible.
3. **Character vs. Word Feature Ablation on External Data**: Replicate character n-gram superiority experiment on at least one other Bangla fake news dataset or synthetic dataset with controlled deceptive patterns. Confirms whether advantage is dataset-specific or represents fundamental language property.