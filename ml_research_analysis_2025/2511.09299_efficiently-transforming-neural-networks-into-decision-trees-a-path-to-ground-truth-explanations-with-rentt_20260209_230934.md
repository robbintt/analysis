---
ver: rpa2
title: 'Efficiently Transforming Neural Networks into Decision Trees: A Path to Ground
  Truth Explanations with RENTT'
arxiv_id: '2511.09299'
source_url: https://arxiv.org/abs/2511.09299
tags:
- methods
- data
- rentt-fi
- feature
- activation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RENTT provides an exact, scalable algorithm for transforming neural
  networks into equivalent multivariate decision trees, addressing the limitations
  of existing methods that lack exactness, scalability, or interpretability. The algorithm
  efficiently handles fully connected, convolutional, and recurrent networks with
  general activation functions, achieving runtime complexity of O(x^1.3-1.5) and memory
  complexity of O(x^1.7-1.9) for hidden neurons, compared to O(x^18-19) and O(x^8-9)
  for previous approaches.
---

# Efficiently Transforming Neural Networks into Decision Trees: A Path to Ground Truth Explanations with RENTT

## Quick Facts
- arXiv ID: 2511.09299
- Source URL: https://arxiv.org/abs/2511.09299
- Reference count: 22
- Primary result: Exact, scalable algorithm transforming neural networks into equivalent multivariate decision trees with polynomial complexity

## Executive Summary
RENTT provides an exact algorithm for transforming neural networks into equivalent multivariate decision trees, addressing the limitations of existing methods that lack exactness, scalability, or interpretability. The approach achieves polynomial-time complexity (O(x^1.3-1.5) runtime, O(x^1.7-1.9) memory) compared to exponential complexity of previous methods. By transforming networks into interpretable decision trees, RENTT enables ground truth feature importance calculations that reveal significant discrepancies with common approximation methods like LIME, SHAP, and BreakDown, running 300-7,500 times faster while providing mathematically exact explanations.

## Method Summary
RENTT transforms neural networks with piecewise linear activation functions into equivalent multivariate decision trees through linearization and ante-hoc pruning. The algorithm first linearizes the network by treating activation functions as state-dependent linear operators, reducing the network to a single linear equation for each specific activation pattern. It then builds a sparse decision tree using only activation patterns observed in training data, avoiding exponential growth. Feature importance is computed directly from the linear weights stored in tree leaves, providing exact explanations without the approximation errors of traditional methods.

## Key Results
- RENTT achieves polynomial complexity O(x^1.3-1.5) runtime and O(x^1.7-1.9) memory versus O(x^18-19) and O(x^8-9) for previous approaches
- NN-DT equivalence verified with mean squared error below 10^-8 across multiple datasets
- RENTT-FI runs 300-7,500 times faster than LIME, SHAP, and BreakDown while providing exact explanations
- Significant discrepancies found between RENTT-FI and approximation methods, with RENTT-FI showing higher agreement with ground truth

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Neural networks with piecewise linear activation functions can be exactly represented as local linear models in a decision tree
- **Mechanism:** Treats activation functions as state-dependent linear operators, reducing the network to a single linear equation y = D_{N-1}x_0 for each activation pattern
- **Core assumption:** Network uses piecewise linear activation functions
- **Break condition:** Non-piecewise linear activations (Sigmoid, Tanh) break exact transformation unless approximated

### Mechanism 2
- **Claim:** Scalability achieved via ante-hoc pruning that limits tree construction to observed activation patterns
- **Mechanism:** Builds tree nodes only for activation patterns present in training data, reducing complexity from exponential to polynomial
- **Core assumption:** Training data covers relevant activation patterns for inference
- **Break condition:** Test samples triggering unseen patterns cause inference failure

### Mechanism 3
- **Claim:** Ground truth feature importance calculated directly from linear weights in tree leaves
- **Mechanism:** Uses effective weight matrix D_{N-1} from leaf nodes as exact gradient for feature importance
- **Core assumption:** Importance defined as linear contribution within local region
- **Break condition:** Final classification activations not piecewise linear; exactness applies only to logits

## Foundational Learning

- **Concept:** Piecewise Linear Functions (ReLU)
  - **Why needed:** Entire transformation relies on ReLU networks partitioning input space into polytopes where function is locally linear
  - **Quick check:** Explain why ReLU network acts as linear regressor if you freeze active/inactive state of every neuron

- **Concept:** Multivariate Decision Trees
  - **Why needed:** RENTT trees split on linear combinations (w1x1 + w2x2 > b) rather than single features
  - **Quick check:** How does multivariate split differ from univariate split in decision boundary geometry?

- **Concept:** Activation Patterns (Network State)
  - **Why needed:** Core data structure passed between NN and DT; serves as unique identifier for tree paths
  - **Quick check:** If two inputs have identical activation pattern in ReLU network, what can you definitively say about their functional relationship?

## Architecture Onboarding

- **Component map:** Linearizer -> Pattern Extractor -> Tree Builder -> RENTT-FI Module
- **Critical path:** Correct computation of effective matrix D_i = (W_i A_i) D_{i-1}; errors propagate exponentially
- **Design tradeoffs:**
  - Exactness vs. Memory: Exact for pruned tree regarding training/test distribution; complete tree infeasible
  - Interpretability vs. Complexity: Multivariate trees too complex for direct reading; require RENTT-FI aggregation
- **Failure signatures:**
  - Unseen Patterns: Inference crashes if input triggers pruned activation pattern
  - Memory Overflow: Networks >10,000 neurons may exceed RAM despite pruning
  - Approximation Drift: Non-piecewise linear activations approximated violate "ground truth" guarantee
- **First 3 experiments:**
  1. Transform small FcNN to DT and verify NN(x) == DT(x) up to machine precision
  2. Measure RAM and runtime scaling while increasing hidden neurons
  3. Train network on synthetic linear dataset and compare RENTT-FI against LIME/SHAP

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the specific NN size and sample count thresholds where RENTT-FI transformation costs exceed cumulative costs of conventional FI methods?
- **Open Question 2:** Can pruning strategy be developed that retains exactness for unseen deployment data without storing intractable activation patterns?
- **Open Question 3:** Does theoretical correctness of RENTT-FI explanations lead to improved downstream utility for humans compared to approximate methods?
- **Open Question 4:** How can local linear models extracted via RENTT be operationalized to provide counterfactual explanations or quantify adversarial robustness?

## Limitations

- Scalability constraints: Memory requirement O(x^1.7-1.9) remains bottleneck for very large networks
- Distributional assumptions: Ante-hoc pruning assumes training data covers relevant activation patterns
- Activation function restrictions: Exact transformation relies on piecewise linear activations

## Confidence

- **High Confidence:** Core algorithmic mechanism, runtime/memory complexity claims, NN-DT equivalence verification
- **Medium Confidence:** Feature importance comparisons showing consistent patterns across datasets
- **Low Confidence:** Scalability projections for massive networks and practical feasibility of complex architectures

## Next Checks

1. Systematically evaluate frequency of unseen activation patterns on test data across multiple datasets
2. Measure approximation error for non-ReLU activations (Sigmoid, Tanh) in both transformation and feature importance
3. Test algorithm on progressively larger networks (500, 1000, 2000+ hidden neurons) to verify claimed polynomial scaling