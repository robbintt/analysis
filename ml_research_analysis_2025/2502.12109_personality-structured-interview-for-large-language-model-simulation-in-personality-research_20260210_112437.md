---
ver: rpa2
title: Personality Structured Interview for Large Language Model Simulation in Personality
  Research
arxiv_id: '2502.12109'
source_url: https://arxiv.org/abs/2502.12109
tags:
- someone
- shape
- persona
- personality
- gpt-4o
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of simulating human-like personality
  data using large language models (LLMs) by proposing a theory-informed Personality
  Structured Interview (PSI) method. The PSI approach leverages structured interview
  transcripts grounded in psychological theory to guide LLMs in generating personality
  data with enhanced human-like heterogeneity.
---

# Personality Structured Interview for Large Language Model Simulation in Personality Research

## Quick Facts
- arXiv ID: 2502.12109
- Source URL: https://arxiv.org/abs/2502.12109
- Reference count: 40
- Primary result: PSI method improves LLM personality simulation fidelity through structured interview transcripts, achieving Pearson correlations between 0.43-0.52 with human personality distributions

## Executive Summary
This paper addresses the challenge of simulating human-like personality data using large language models by proposing the Personality Structured Interview (PSI) method. Unlike existing approaches that use trait adjectives, PSI leverages structured interview transcripts grounded in psychological theory to guide LLMs in generating personality data with enhanced human-like heterogeneity. The method demonstrates improved alignment with human personality distributions compared to baseline methods, with better structural validity and more realistic behavioral predictions, though effect sizes tend to be amplified compared to human data.

## Method Summary
The PSI method uses psychometric scale-development procedures to create structured interview transcripts targeting specific personality traits. These transcripts are then used as context for zero-shot LLM prompting, where the model generates personality scale responses (1-5 Likert) based on the interview content. The approach was validated against human data from 357 participants who completed the Big Five Inventory-2 (BFI-2) and behavioral scales (OCB, CWB), with evaluation using Pearson correlations, MAE, Heterogeneity Alignment Index (HAI), and confirmatory factor analysis (CFA) with Tucker's Congruence Coefficient.

## Key Results
- PSI yielded Pearson correlations of 0.43-0.52 with human personality distributions, outperforming baseline Persona and Shape methods
- PSI demonstrated lower mean absolute errors and higher HAI scores, indicating better capture of human-like variability
- The method showed better structural validity with higher Tucker's Congruence Coefficients and improved CFA fit indices
- While capturing behavioral patterns, LLM outputs showed stronger effect sizes than human data

## Why This Works (Mechanism)

### Mechanism 1
Narrative-rich context elicits higher heterogeneity in LLM responses than trait-adjective prompting. Standard adjective-based prompting constrains the model to stereotypical central tendencies, while structured interview transcripts introduce lexical diversity and situational nuance, allowing the model to simulate the variance found in human populations rather than an "average" idealization.

### Mechanism 2
Theory-informed question design acts as a latent construct filter, ensuring generated data maintains structural validity. PSI questions were designed via psychometric scale development to target specific traits, and when these validated transcripts are fed to the LLM, the model aligns its understanding of the persona with the established factor structure, resulting in CFA results that mimic human data.

### Mechanism 3
Context grounding facilitates behavioral prediction alignment, but with amplified effect sizes. By grounding simulation in interview data containing behavioral history and values, the LLM can better simulate downstream behaviors, but because LLMs lack human "noise" or random variance, they tend to apply trait-behavior logic more strictly than humans.

## Foundational Learning

- **Five Factor Model (FFM) / Big Five Inventory (BFI-2)**: This is the "ground truth" the paper measures against. Understanding that personality is a latent construct inferred from item responses (not just a label) is essential to interpreting the results. *Quick check:* Can you explain why a Confirmatory Factor Analysis (CFA) is used to validate personality data rather than just checking average scores?

- **Heterogeneity Alignment Index (HAI)**: The paper uses this custom metric to prove their method is better than baselines. It measures the correlation of standard deviations between human and simulated data. *Quick check:* Why is matching the distribution (standard deviation) of responses more difficult for an LLM than matching the mean?

- **Prompt Engineering (Persona vs. PSI)**: The core comparison is between "You are X" (Shape/Persona) and "Here is an interview transcript of X" (PSI). *Quick check:* How does providing narrative evidence (transcripts) reduce the risk of "social desirability bias" in the model's simulation compared to direct instruction?

## Architecture Onboarding

- **Component map:** 357 Human Participants -> 32 Structured Questions -> Transcripts -> Prompt Template -> LLM Output -> Evaluation Engine
- **Critical path:** The Question Design Phase. This is the highest-risk component. If the 32 questions are not rigorously grounded in personality theory and validated by Subject Matter Experts (SMEs), the transcripts will lack the signal required to drive the simulation, causing the entire system to fail.
- **Design tradeoffs:** PSI requires ~34 minutes of interview time compared to "Life Interviews" (120 mins), achieving comparable fidelity with ~25% of the input data. The method prioritizes matching the spread of human responses over matching means.
- **Failure signatures:** "Amplified Effect Sizes" (system works too well, e.g., r=0.58 vs Human r=0.42) indicates lack of noise/irrationality. "Collapsed Variance" (constant outputs) causes HAI calculation failure.
- **First 3 experiments:**
  1. Reproduction of HAI: Run GPT-4o on "Shape" vs. "PSI" prompts for N=50 to verify PSI results in wider standard deviation of scores
  2. Ablation on Questions: Remove questions related to Agreeableness and check if simulated score becomes unmoored
  3. Behavioral Injection: Attempt to simulate "Counterproductive" employee using standard vs. transcript-heavy prompts to check for realistic (subtler) vs. cartoonish behavior

## Open Questions the Paper Calls Out
- Can the PSI framework generalize to simulate other psychological constructs beyond the Big Five personality traits?
- How can the "amplification" of behavioral correlations in LLMs be mitigated to better match human variability?
- Can PSI-based simulations maintain personality consistency over longitudinal or multi-agent interactions?

## Limitations
- The PSI method's advantage may be contingent on the specific interview design; other structured interview formats might not yield similar heterogeneity improvements
- The amplified effect sizes in behavioral predictions could indicate overfitting to theoretical patterns rather than realistic human noise
- The evaluation framework assumes human data represents the ground truth, but human personality measurement itself contains measurement error

## Confidence
- **High Confidence:** PSI improves distribution matching (HAI) compared to baseline methods
- **Medium Confidence:** Structural validity improvements (CFA/TCC) hold across LLMs
- **Low Confidence:** Behavioral prediction results may reflect LLM tendency to "hallucinate" stronger theoretical relationships

## Next Checks
1. **Ablation Study on Question Selection:** Systematically remove subsets of the 32 interview questions and measure degradation in HAI and CFA fit to identify the minimal viable question set
2. **Cross-Context Generalizability:** Apply the PSI method to a different personality framework (e.g., HEXACO model) to test whether the approach generalizes beyond Big Five
3. **Human-in-the-Loop Validation:** Have human raters blind to the data source attempt to distinguish PSI-generated personality profiles from real ones to assess practical indistinguishability