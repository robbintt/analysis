---
ver: rpa2
title: Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV
  Perception
arxiv_id: '2509.09297'
source_url: https://arxiv.org/abs/2509.09297
tags:
- detection
- object
- aerial
- open-set
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a model-agnostic open-set detection framework
  for UAV air-to-air object detection. It combines embedding-space semantic uncertainty
  estimation with GMM-based density modeling, temperature scaling, and spectral normalization
  to enhance out-of-distribution rejection.
---

# Model-Agnostic Open-Set Air-to-Air Visual Object Detection for Reliable UAV Perception

## Quick Facts
- arXiv ID: 2509.09297
- Source URL: https://arxiv.org/abs/2509.09297
- Reference count: 34
- One-line primary result: Improves AUROC by up to 10% over YOLO baselines, achieving 0.98 AUROC on real flight images.

## Executive Summary
This paper presents a model-agnostic framework for open-set detection in UAV air-to-air scenarios, addressing the challenge of detecting known objects (airplanes, helicopters) while rejecting unknown objects (drones) under real-world corruptions. The approach combines embedding-space density modeling with GMMs, temperature scaling, and spectral normalization to enhance out-of-distribution rejection. Evaluated on the AOT aerial benchmark and real-world flight data, the method demonstrates significant improvements in AUROC while maintaining real-time performance (>20 FPS), making it suitable for reliable UAV perception in adverse environments.

## Method Summary
The framework uses a pre-trained detector (RT-DETR-R50) to extract high-level embeddings for each detection, which are then modeled using class-conditional GMMs to estimate semantic uncertainty. Temperature scaling is applied to calibrate classifier outputs, and spectral normalization is optionally used in the backbone to enforce feature-space regularity. At inference, detections are filtered using joint thresholding that combines softmax confidence and GMM entropy, effectively rejecting OOD objects while retaining in-distribution targets. The method is designed to be detector-agnostic, with post-hoc processing that can be applied to any detection model.

## Key Results
- AUROC improvement of up to 10% over YOLO baselines on the AOT dataset
- Achieves 0.98 AUROC on real-world flight images
- Maintains real-time performance (>20 FPS) while improving detection accuracy in adverse aerial environments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding-space density modeling via Gaussian Mixture Models (GMMs) provides a signal for out-of-distribution (OOD) detection that is complementary to softmax confidence.
- **Mechanism:** The framework extracts high-level embeddings for each detection and fits class-conditional GMMs on the training set. At inference, it computes the likelihood of a detection's embedding under these GMMs. If the likelihood is low (or entropy of the posterior is high), the object is flagged as OOD, regardless of the softmax score.
- **Core assumption:** In-distribution (ID) objects form compact, clusterable regions in the embedding space, whereas OOD objects (e.g., drones vs. planes) appear as outliers in this space.
- **Evidence anchors:** [abstract], [section III.B], [corpus]
- **Break condition:** If the backbone features are not discriminative enough for the unknown objects (e.g., unknowns look identical to knowns in the embedding space), density modeling will fail to separate them.

### Mechanism 2
- **Claim:** Spectral normalization (SN) of the backbone enforces feature-space regularity, which improves the reliability of uncertainty metrics like entropy.
- **Mechanism:** By constraining the spectral norm of weight matrices in the backbone, the model enforces a bi-Lipschitz constraint. Assumption: This prevents the feature space from stretching arbitrarily, ensuring that distances and densities (used by GMMs) remain meaningful and stable.
- **Core assumption:** Smoother, Lipschitz-constrained feature mappings prevent overfitting and make the in-distribution density estimation more robust to perturbations.
- **Evidence anchors:** [section III.A], [section IV.C], [corpus]
- **Break condition:** Excessive normalization might restrict model capacity, potentially lowering closed-set accuracy or distorting density estimates (as seen with GMM density in the ablation).

### Mechanism 3
- **Claim:** Joint thresholding combines classifier confidence and density-based uncertainty to effectively filter ambiguous detections.
- **Mechanism:** The method requires a detection to pass two independent checks: a minimum softmax score (confidence) and a maximum GMM entropy threshold (uncertainty). This "AND" logic filters out high-confidence OOD errors (softmax high, density low) and low-confidence ID errors.
- **Core assumption:** Softmax scores and embedding space density provide semi-independent signals of "knownness."
- **Evidence anchors:** [section IV.D], [section IV.C], [corpus]
- **Break condition:** If the two signals become perfectly correlated (e.g., softmax always high when density high), joint thresholding offers no gain over single thresholds.

## Foundational Learning

- **Concept: Open-Set Detection (OSD)**
  - **Why needed here:** Standard detectors force predictions into known classes (e.g., calling a drone a "plane" with high confidence). OSD adds a "reject" option for unknowns.
  - **Quick check question:** How does the model handle an input from a class that was not in the training set?

- **Concept: Temperature Scaling**
  - **Why needed here:** Neural networks are often miscalibrated (over-confident). Temperature scaling is a post-hoc method to sharpen or flatten the softmax distribution to match true accuracy.
  - **Quick check question:** Does increasing the temperature parameter make the softmax output distribution "flatter" (more uncertain) or "sharper"?

- **Concept: Spectral Normalization**
  - **Why needed here:** A regularization technique to stabilize the training of neural networks by limiting the magnitude of weight matrices, often used in GANs and here for uncertainty stability.
  - **Quick check question:** What property of the neural network function does spectral normalization constrain?

## Architecture Onboarding

- **Component map:** Input RGB image -> ResNet-50 (Spectrally Normalized) backbone -> RT-DETR (Transformer-based) detector -> Embedding extraction -> GMMs + Temperature Scaling -> Joint Thresholding output
- **Critical path:** Training RT-DETR on ID data (airplanes, helicopters) with optional SN -> GMM fitting on training embeddings -> Temperature scaling calibration -> Inference with Joint Thresholding
- **Design tradeoffs:** Spectral Norm vs. Accuracy (OOD robustness vs. closed-set mAP), Pruning vs. Recall (aggressive pruning improves OOD rejection but risks missing dim/small targets), Inference Speed (framework claims ~24 FPS)
- **Failure signatures:** High-Confidence False Positives (OOD objects near ID clusters in embedding space), Over-Pruning (valid ID targets rejected), Drift (domain shift invalidates GMM fit)
- **First 3 experiments:** 1) Reproduce Ablation: Train RT-DETR on AOT, fit GMMs, verify Joint Thresholding outperforms Softmax-only baselines on AOT validation set, 2) Corruption Robustness Check: Evaluate on AOT-C to quantify AUROC drop, 3) Real-World Flight Test: Run inference on real-flight subset to verify ~0.98 AUROC claim

## Open Questions the Paper Calls Out

- **Open Question 1:** Can learned score-fusion methods (e.g., shallow MLPs or decision trees) outperform the fixed joint thresholding rule for combining softmax confidence and GMM entropy? Basis: Future work section mentions exploring learned fusion using lightweight classifiers. Evidence: Not yet validated experimentally.

- **Open Question 2:** Does explicit three-class modeling (ID vs. OOD vs. background) improve detection reliability over binary ID/OOD classification in aerial scenarios? Basis: Future work section mentions extending to three-class setting for background clutter. Evidence: Current binary formulation conflates background with true OOD targets.

- **Open Question 3:** Why does spectral normalization degrade GMM density scoring while improving all other methods, and can this inconsistency be reconciled? Basis: Table II shows GMM density AUROC drops from 0.924 to 0.845 with SN. Evidence: Paper only notes this "may distort the assumptions of the GMM density model" without further analysis.

## Limitations

- Lack of explicit threshold values for Joint Thresholding beyond the softmax pruning threshold
- No analysis of failure modes on rare or ambiguous OOD classes
- Limited ablation on the impact of GMM covariance regularization jitter

## Confidence

- **High Confidence:** Overall improvement in open-set detection performance (AUROC, TPR@FPR) is well-demonstrated, especially value of Joint Thresholding and spectral normalization. Real-time performance claim (>20 FPS) is directly supported.
- **Medium Confidence:** Claim that spectral normalization improves OOD robustness is supported, but mechanism is less robustâ€”GMM density degrades with SN, requiring entropy instead. Optimal configuration (best K for GMMs, exact temperature parameters) not fully specified.
- **Low Confidence:** Claim that framework is "model-agnostic" not rigorously validated beyond RT-DETR. Generalization to other detectors (YOLO, Faster R-CNN) implied but not empirically shown. Impact of domain shift between AOT training data and real-world flight data noted but not deeply analyzed.

## Next Checks

1. **Reproduce Joint Thresholding Gains:** Train RT-DETR on AOT, fit GMMs, and verify Joint Thresholding outperforms softmax-only baselines on AOT validation and OOD sets.
2. **Test Model-Agnosticism:** Apply the post-hoc GMM + temperature scaling pipeline to a different detector (e.g., YOLO) and measure AUROC retention.
3. **Analyze Domain Drift:** Evaluate the model on a held-out subset of AOT with significantly different lighting/blur conditions to quantify AUROC drop and assess calibration robustness.