---
ver: rpa2
title: Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with
  Self-Adaptive Memory
arxiv_id: '2505.19469'
source_url: https://arxiv.org/abs/2505.19469
tags:
- dataset
- distillation
- memory
- diffusion
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of dataset distillation, where
  large datasets are compressed into smaller, representative datasets while maintaining
  comparable performance for training deep neural networks. The key challenge is ensuring
  that distilled datasets capture sufficient diversity to represent the original data
  distribution.
---

# Diversity-Driven Generative Dataset Distillation Based on Diffusion Model with Self-Adaptive Memory

## Quick Facts
- arXiv ID: 2505.19469
- Source URL: https://arxiv.org/abs/2505.19469
- Reference count: 0
- The method achieves 56.9% accuracy on ImageWoof with ResNetAP-10 using 50 images per class (3.8% of original dataset).

## Executive Summary
This paper introduces a diversity-driven generative dataset distillation method based on diffusion models with self-adaptive memory. The approach addresses the challenge of dataset distillation by optimizing diffusion models to generate small, representative datasets that maintain high downstream classification accuracy. The key innovation is a self-adaptive memory mechanism that preserves distribution diversity by removing the most similar elements rather than oldest ones, combined with diversity-driven objectives that shape the diffusion model's sampling distribution to cover the original data more effectively.

## Method Summary
The method extends diffusion model training with dataset distillation objectives by incorporating two memory buffers (real and generated latents) that track representative samples from the original and distilled distributions. During training, the model optimizes a combined loss consisting of standard diffusion loss plus diversity terms that pull generated samples toward under-represented regions of the real distribution while pushing them away from already-sampled regions. The self-adaptive memory mechanism maintains diversity by computing similarity vectors for all elements and removing the latent with maximum aggregate similarity, preventing the memory from becoming dominated by redundant samples.

## Key Results
- Achieves 56.9% accuracy on ImageWoof with ResNetAP-10 using 50 images per class (3.8% of original dataset)
- Outperforms state-of-the-art approaches: 56.9% vs 55.1% for Minimax and 48.3% for IDC-1
- Demonstrates particular strength in low IPC settings, with accuracy gains of 1.4-2.4% at IPC=10 compared to baseline methods
- Shows stable performance across different hyperparameter configurations and memory sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-adaptive memory preserves distribution diversity better than FIFO replacement
- Mechanism: Memory sets track representative latents from real and generated distributions. Instead of popping oldest elements, the method computes similarity vectors—summing pairwise cosine similarities for each element—and removes the latent with maximum aggregate similarity. This iteratively forces the memory toward a sparse, diverse representation of the original distribution.
- Core assumption: Aggregate cosine similarity correlates with redundancy; removing high-similarity elements increases coverage without losing tail distributions.
- Evidence anchors:
  - [section 2.3]: "tr = arg max_{i∈[Nr]} Σ_{j=0}^{Nr} σ(zi, zj)" defines the removal criterion explicitly.
  - [table 3]: Max-max strategy outperforms min-min, max-min, and min-max across IPC=10/20/50.
  - [corpus]: Weak direct corpus support—neighbor papers discuss diffusion-based distillation but not self-adaptive memory specifically.

### Mechanism 2
- Claim: Combined diversity loss (L_real + L_gen) explicitly shapes the diffusion model's sampling distribution
- Mechanism: L_real pulls generated latents toward under-represented regions of the real distribution (via min similarity), while L_gen pushes latents away from already-sampled regions (via max similarity). The joint optimization creates a gradient field that expands coverage rather than collapsing to high-density modes.
- Core assumption: The diffusion model can be steered away from mode collapse through auxiliary loss terms without destabilizing denoising training.
- Evidence anchors:
  - [section 2.2]: Eq. 4-6 define the loss formulation; "L_real drives the distilled distribution to fit the original distribution... L_gen makes distilled images distribute more diversely."
  - [figure 1]: Gradient field visualization shows the proposed method covers more of the original distribution than baseline DiT.
  - [corpus]: "Taming Diffusion for Dataset Distillation with High Representativeness" (FMR=0.562) addresses similar diversity concerns in diffusion-based distillation.

### Mechanism 3
- Claim: Low-IPC settings benefit disproportionately from diversity optimization
- Mechanism: When IPC is severely constrained, each synthetic image must carry more information. Standard diffusion models tend to generate prototypical examples, wasting capacity on redundant samples. The diversity loss forces the limited budget to span the distribution more effectively.
- Core assumption: The marginal value of diversity increases as the distillation budget decreases.
- Evidence anchors:
  - [abstract]: "The method shows particular strength in low IPC settings, proving its effectiveness in generating more diverse and representative distilled datasets."
  - [table 1]: At IPC=10 (0.8%), the proposed method achieves 36.2-38.1% accuracy vs. Minimax's 34.3-35.7%; the gap narrows at IPC=50.
  - [corpus]: No direct corpus corroboration for IPC-specific gains; this appears novel to this work.

## Foundational Learning

- Concept: **Latent Diffusion Models (LDMs)**
  - Why needed here: The entire method operates in latent space (VAE-encoded), not pixel space. Understanding how diffusion denoising works on latents is prerequisite to modifying its loss landscape.
  - Quick check question: Can you explain why operating in latent space reduces computational cost compared to pixel-space diffusion?

- Concept: **Dataset Distillation Objectives**
  - Why needed here: The method extends standard diffusion training with distillation-specific losses (L_real, L_gen). Without understanding the goal—compressing a dataset while preserving downstream accuracy—the auxiliary losses appear unmotivated.
  - Quick check question: What is the difference between dataset distillation and knowledge distillation?

- Concept: **Cosine Similarity in High-Dimensional Spaces**
  - Why needed here: The entire memory update mechanism relies on cosine similarity as a diversity proxy. Understanding its properties (bounded [-1,1], scale-invariant) is necessary to debug similarity matrix computations.
  - Quick check question: Why might cosine similarity be preferred over Euclidean distance for comparing latents from a VAE?

## Architecture Onboarding

- Component map:
  - VAE Encoder (E) -> Class Encoder (E_c) -> DiT (Diffusion Transformer) -> Real Memory (M_real) -> Generated Memory (M_gen) -> Loss Aggregator

- Critical path:
  1. Sample real image x → encode to z_0 → add noise to z_t
  2. DiT predicts noise ε_θ → compute L_diffusion
  3. Generate sample ẑ_θ → compute similarity vs. M_real (L_real) and M_gen (L_gen)
  4. Backpropagate combined loss L
  5. Update M_real and M_gen with self-adaptive pruning (remove max-similarity elements)
  6. After training, generate distilled dataset from noise using fine-tuned DiT

- Design tradeoffs:
  - Memory size (N_R, N_G): Larger memory = better distribution coverage but higher compute per batch. Paper uses 64; ablation shows performance is relatively insensitive due to adaptive updates.
  - Loss weights (λ_r, λ_g): λ_g (diversity) set 4x higher than λ_r (representativeness), suggesting diversity is the binding constraint. Ablation shows smooth curves for λ_r but λ_g has an optimal range.
  - Max vs. min pruning strategy: Table 3 confirms max-max (removing most similar) is critical; min-min performs poorly (~23.9% vs 37.7% at IPC=10).

- Failure signatures:
  - Mode collapse: Generated images look similar across samples → λ_g too low or memory update strategy wrong (using min instead of max).
  - Unrealistic artifacts: Generated images have visual distortions → λ_r or λ_g too high relative to L_diffusion.
  - Memory drift: Validation accuracy oscillates → memory size too small or update frequency too high.
  - Poor low-IPC performance: Minimal improvement over baselines → check if L_gen is actually being computed (max over M_gen may be returning same element repeatedly if memory is stale).

- First 3 experiments:
  1. Reproduce IPC=10 on ImageWoof with ResNetAP-10 using default hyperparameters (λ_r=0.002, λ_g=0.008, memory=64). Verify accuracy is in the 37-39% range.
  2. Ablate memory update strategy: Run max-max (proposed), max-min, min-max, min-min at IPC=10. Confirm table 3's pattern holds—this isolates whether adaptive memory is the key innovation.
  3. Visualize gradient fields: Reproduce Figure 1 by t-SNE projecting real latents and overlaying denoising trajectories for DiT baseline vs. proposed method.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the self-adaptive memory mechanism generalize effectively to datasets with significantly different distributions, such as medical imaging or long-tailed data?
- Basis in paper: The experiments are strictly limited to ImageNet subsets (ImageWoof, ImageNette, ImageIDC), which share similar visual features and class balances.
- Why unresolved: It is unclear if the "max-max" update strategy for diversity is optimal for data domains with sparse feature spaces or high class imbalance.
- Evidence: Evaluation results on domain-specific datasets (e.g., ChestX-ray) or long-tailed datasets showing comparable performance gains.

### Open Question 2
- Question: Does the calculation of similarity vectors for self-adaptive memory updates introduce significant computational overhead compared to baseline methods?
- Basis in paper: The method requires calculating the sum of cosine similarities for all memory elements during every update (Eq. 7), unlike the Minimax baseline which pops the oldest element.
- Why unresolved: The paper focuses on accuracy metrics and storage size but does not report training time or FLOPs comparison regarding the memory update step.
- Evidence: A comparison of training time per epoch and total FLOPs between the proposed method and the Minimax baseline.

### Open Question 3
- Question: Do the distilled datasets transfer effectively to downstream models with different inductive biases, such as Vision Transformers (ViT)?
- Basis in paper: The downstream validation is limited to ConvNet-6, ResNet-18, and ResNetAP-10, all of which are CNN-based architectures.
- Why unresolved: It is unknown if the "diverse" features captured by the diffusion model align with the patch-based attention mechanisms of Transformers.
- Evidence: Downstream validation accuracy results when training a ViT model on the distilled datasets.

## Limitations
- Memory update strategy may not generalize well to highly imbalanced datasets where rare classes could be prematurely pruned
- Fixed hyperparameter weights (λ_r=0.002, λ_g=0.008) may require tuning for other domains or image modalities
- Dual memory buffers with pairwise similarity computations scale quadratically with memory size, potentially limiting scalability

## Confidence
- **High confidence**: The diversity-driven mechanism works as claimed in controlled settings (ImageWoof IPC experiments). The mathematical formulation of losses and memory updates is sound.
- **Medium confidence**: Generalizability to other dataset types and model architectures. While results show strong performance, the paper tests only on ImageNet subsets and ConvNets/ResNets.
- **Low confidence**: Claims about "particular strength in low IPC settings" lack corpus support and may be dataset-specific rather than a universal property.

## Next Checks
1. **Memory size ablation**: Test performance across memory sizes (16, 32, 64, 128) on ImageWoof to verify claimed insensitivity and identify the break point where similarity-based pruning fails.
2. **Class imbalance test**: Create an imbalanced variant of ImageWoof (reduce samples for minority classes) and evaluate whether diversity loss maintains minority class representation.
3. **Cross-domain validation**: Apply the method to non-image datasets (e.g., medical imaging or tabular data) to test generalizability beyond natural images.