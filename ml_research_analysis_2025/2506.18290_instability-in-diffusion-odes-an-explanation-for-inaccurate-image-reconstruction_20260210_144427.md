---
ver: rpa2
title: 'Instability in Diffusion ODEs: An Explanation for Inaccurate Image Reconstruction'
arxiv_id: '2506.18290'
source_url: https://arxiv.org/abs/2506.18290
tags:
- instability
- diffusion
- reconstruction
- real
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies instability in the diffusion generation process
  as a key factor amplifying reconstruction errors in diffusion models. The instability
  arises from the sparsity of the generation distribution, where probability mass
  concentrates in scattered small regions while most of the space has negligible density.
---

# Instability in Diffusion ODEs: An Explanation for Inaccurate Image Reconstruction

## Quick Facts
- **arXiv ID:** 2506.18290
- **Source URL:** https://arxiv.org/abs/2506.18290
- **Reference count:** 40
- **Primary result:** Instability in diffusion generation ODEs amplifies reconstruction errors, with probability of instability converging to one as data dimensionality increases

## Executive Summary
This paper identifies instability in diffusion generation processes as a fundamental source of reconstruction error. The authors demonstrate that when diffusion models invert and regenerate images, small numerical errors are dramatically amplified by the sensitive dependence on initial conditions inherent in the generation mapping. Through theoretical analysis and experiments on Stable Diffusion 3.5 and FLUX, they show that this instability arises from the sparsity of generation distributions—where probability mass concentrates in scattered small regions—requiring large gradients to preserve probability relative to the prior Gaussian. The paper proves that for high-dimensional data like images, the probability of encountering this instability approaches one asymptotically.

## Method Summary
The authors employ a three-step process: (1) invert real images to latent noise using ODESolver with Euler method (500 steps), (2) reconstruct images from inverted noise using the same solver, and (3) measure both reconstruction error and instability coefficient. The instability coefficient is estimated by adding small perturbations to the inverted noise and measuring the amplification in reconstruction output. They use 100 MSCOCO 2014 validation images and test multiple diffusion models including Stable Diffusion 3.5 Medium/Large and FLUX.1-dev via the diffusers library. The analysis combines empirical correlation studies with theoretical proofs about asymptotic instability probability in high dimensions.

## Key Results
- Strong positive correlation between instability coefficients and reconstruction errors across multiple diffusion models
- Theoretical proof that probability of instability converges to one as data dimensionality increases
- Demonstrated that instability amplifies reconstruction errors beyond what numerical discretization alone would cause
- Identified sparsity of generation distribution as the root cause requiring large gradients

## Why This Works (Mechanism)

### Mechanism 1: Intrinsic Instability as Error Amplifier
Reconstruction errors are significantly magnified by sensitive dependence on initial conditions where the Jacobian of the generation mapping amplifies perturbations in specific directions. When numerical inversion produces a noise vector slightly different from ideal, the generation process expands this small difference into large reconstruction error. This requires the Jacobian to have singular values > 1.

### Mechanism 2: Sparsity-Induced Gradient Expansion
The instability specifically arises because probability mass in the generation distribution is sparse (concentrated in small regions), necessitating large mapping gradients to satisfy probability preservation relative to the prior Gaussian. To preserve probability mass, small high-density regions in the prior must map to large low-density regions in generation space, requiring large gradients (Jacobian determinants).

### Mechanism 3: Asymptotic Inevitability in High Dimensions
For high-dimensional data like images, the probability of encountering this instability during reconstruction converges to 1 as dimensionality increases. This occurs because the volume of space vastly outstrips the volume of sparse high-density regions, making it increasingly likely that real data samples fall into low probability density regions.

## Foundational Learning

**Concept: Probability Flow ODEs (PF-ODE)**
- Why needed: Reformulates diffusion generation as solving an ODE (dx_t/dt = v(x_t, t)), essential for understanding inversion and numerical errors
- Quick check: Can you explain how a PF-ODE differs from a stochastic differential equation (SDE) in the context of sampling?

**Concept: The Jacobian Matrix and Singular Values**
- Why needed: Quantifies "instability" using Jacobian of generation mapping; singular value > 1 implies expansion (instability)
- Quick check: If the largest singular value of the Jacobian J_G(z) is 5, what happens to a vector of magnitude ε in that direction after passing through G?

**Concept: Push-forward Probability and Change of Variables**
- Why needed: Mechanism 2 relies on push-forward formula (π_gen(B) = π_prior(A)); changes in volume relate to changes in probability density
- Quick check: If a mapping expands a region's volume by a factor of 10, by what factor does the probability density decrease?

## Architecture Onboarding

**Component map:** Real Image → Inversion Process (ODESolver) → Inverted Noise z-hat → Generation Process (ODESolver) → Reconstructed Image x-hat → Diagnostic (Instability Coefficient)

**Critical path:** The transition from Inversion to Generation, where instability property of ODE vector field acts on numerical error of z-hat to produce final reconstruction gap

**Design tradeoffs:**
- Higher-order ODE solvers reduce initial numerical error but do not eliminate error amplification if intrinsic instability coefficient is high
- Step size affects error scaling but instability acts as a multiplier

**Failure signatures:**
- High Instability Coefficient (E_G(z, u) > 1) indicates unstable region
- Distribution mismatch when π_real puts mass on regions where π_gen is low

**First 3 experiments:**
1. Replicate the Perturbation Test: Add small noise Δn to inverted noise z-hat, re-generate, and measure change in output to verify instability
2. Correlation Check: Sample 100 images, run full reconstruction loop, and calculate correlation between reconstruction error and estimated instability coefficient
3. Dimensionality Test: Implement 2D mixture of Gaussians example and visualize "expansion" regions to build intuition for sparsity → large gradients mechanism

## Open Questions the Paper Calls Out

**Open Question 1:** What are the formal necessary and sufficient conditions for instability emergence in diffusion ODEs?
- The paper provides a probabilistic lower bound showing instability is likely but does not define exact boundary conditions required for it to occur

**Open Question 2:** Can training objectives or sampling strategies be explicitly modified to reduce distribution sparsity and thereby mitigate reconstruction instability?
- The paper identifies sparsity as root cause but does not propose specific methods to alleviate this sparsity during model training

**Open Question 3:** What distinct, non-numerical error mechanisms coexist with instability to contribute to reconstruction inaccuracies?
- The paper isolates instability as major factor but acknowledges it may not be sole cause of "pronounced reconstruction discrepancies"

## Limitations

- The specific magnitude of perturbations used to estimate instability coefficients is not specified, which could affect measured correlation
- Asymptotic theoretical results assume specific distributional properties (finite support, positive minimum density) that may not hold for real image data
- The paper does not explore whether alternative ODE solvers or training objectives could mitigate instability effects

## Confidence

- **High confidence:** Empirical demonstration of positive correlation between instability coefficients and reconstruction errors across multiple models
- **Medium confidence:** Theoretical asymptotic results showing probability of instability → 1 as dimensionality increases, given simplifying assumptions
- **Medium confidence:** Sparsity-based explanation for why gradients must be large, though this is more of a plausibility argument than rigorous proof

## Next Checks

1. **Perturbation sensitivity analysis:** Systematically vary perturbation magnitudes to identify the linear regime where instability coefficient measurements are most reliable
2. **Cross-dataset validation:** Test the instability-reconstruction error correlation on non-MSCoco datasets to verify generalizability
3. **Alternative solver comparison:** Implement higher-order ODE solvers (Heun, RK45) and quantify whether they reduce reconstruction error without changing fundamental instability relationship