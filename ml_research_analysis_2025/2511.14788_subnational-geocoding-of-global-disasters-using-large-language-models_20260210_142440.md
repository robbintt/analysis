---
ver: rpa2
title: Subnational Geocoding of Global Disasters Using Large Language Models
arxiv_id: '2511.14788'
source_url: https://arxiv.org/abs/2511.14788
tags:
- disaster
- geocoding
- em-dat
- location
- gadm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a fully automated workflow for geocoding global
  disaster data using large language models. GPT-4o parses unstructured location descriptions
  from the EM-DAT database into hierarchical JSON, which is then geocoded using three
  independent spatial sources (GADM, OpenStreetMap, and Wikidata).
---

# Subnational Geocoding of Global Disasters Using Large Language Models

## Quick Facts
- arXiv ID: 2511.14788
- Source URL: https://arxiv.org/abs/2511.14788
- Reference count: 21
- Primary result: Automated LLM-based geocoding achieves 92% coverage of EM-DAT disasters with 97.9% accuracy on validated benchmarks

## Executive Summary
This study presents a fully automated workflow for geocoding global disaster data using large language models. GPT-4o parses unstructured location descriptions from the EM-DAT database into hierarchical JSON, which is then geocoded using three independent spatial sources (GADM, OpenStreetMap, and Wikidata). A reliability score quantifies spatial agreement across sources. Applied to 14,215 events (2000-2024), the workflow geocodes 92% of records with up to 97.9% individual unit intersection with manually geocoded benchmarks. The approach enables consistent subnational spatial analysis for all disaster types without manual intervention, improving disaster data utility for risk assessment and policy monitoring.

## Method Summary
The method uses GPT-4o to transform unstructured location text into hierarchical JSON structure, then queries three independent geoinformation sources (GADM, OSM, Wikidata) to find spatial matches. Results are cross-checked and re-projected to GADM administrative units, with a reliability score (0-4) quantifying agreement across sources. The workflow processes EM-DAT records from 2000-2024, achieving automated geocoding without manual intervention.

## Key Results
- 92% of 14,215 disaster records successfully geocoded
- 97.9% individual unit intersection with manually geocoded benchmarks
- Reliability score effectively quantifies spatial agreement across sources
- Fully automated workflow eliminates need for manual geocoding

## Why This Works (Mechanism)

### Mechanism 1: LLM-Driven Hierarchical Structuring
GPT-4o transforms inconsistent, unstructured location strings into standardized hierarchical JSON, leveraging in-context learning to infer administrative relationships and normalize text. This works where traditional string-matching fails due to varying granularity and typos.

### Mechanism 2: Multi-Source Spatial Triangulation
Cross-referencing three independent geoinformation sources creates a reliability score that proxies confidence without manual verification. Agreement between sources suggests low ambiguity and higher accuracy.

### Mechanism 3: GADM Re-projection for Harmonization
Re-projecting disparate geometry types onto GADM administrative framework enables consistent global analysis by normalizing points or varying polygon resolutions into a standard hierarchy.

## Foundational Learning

- **Administrative Hierarchy (GADM/ISO)**: Understanding Admin1→Admin2→Admin3 structure (country→province→municipality) is essential for debugging JSON parsing errors. Quick check: If GPT-4o outputs "Paris, Texas" as Admin1: Texas, Admin2: Paris, but your schema expects counties as Admin2, where does the mismatch occur?

- **Fuzzy String Matching (WRatio)**: GADM lookup uses rapidfuzz with 85% threshold to match LLM-cleaned text to official names. Quick check: Why would a fuzzy match score of 84% be rejected even if the location is visually correct?

- **Spatial Intersection vs. Containment**: Reliability score distinguishes between geometry contained within another (high confidence) versus simply intersecting it (lower confidence). Quick check: If a disaster polygon covers two halves of adjacent Admin2 units, would "containment" be a better metric than "intersection" for assigning a single location?

## Architecture Onboarding

- **Component map**: Input (EM-DAT CSV) → Parser (GPT-4o API) → Geocoder (GADM + OSM + Wikidata) → Scorer (Reliability 0-4) → Harmonizer (GADM reprojection) → Output (GeoPackage/GeoJSON)

- **Critical path**: The LLM Parsing stage. If JSON structure is malformed or hierarchy is hallucinated, subsequent geocoding queries will fail or retrieve incorrect geometries.

- **Design tradeoffs**: 
  - Latency vs. Robustness: Using three geocoders and an LLM is computationally expensive but provides redundancy for 92% coverage
  - Precision vs. Recall: Fuzzy matching threshold (85%) and GADM re-projection sacrifice raw OSM precision for global administrative consistency

- **Failure signatures**:
  - "Hallucinated Hierarchy": LLM creates valid JSON but assigns city as region instead of municipality
  - "Geometric Mismatch": OSM returns point for large region (low overlap with GADM polygon)
  - "API Timeout": OSM/Wikidata queries fail, leaving GADM as sole source

- **First 3 experiments**:
  1. Validation Subset: Run pipeline on 8,402 records with manual geocodes and calculate IoU to verify 97.9% claim
  2. Threshold Sensitivity: Vary fuzzy matching threshold (80% vs. 90%) on difficult names to observe trade-off between errors
  3. Parser Ablation: Bypass LLM and use regex splitter for location parsing; compare geocoding success rate

## Open Questions the Paper Calls Out

- Can integrating retrieval-augmented generation (RAG) to cross-reference live news, web searches, or alternative databases improve geocoding accuracy or timeliness compared to static repositories?

- Can the workflow be expanded to perform end-to-end processing, extracting location descriptions directly from raw source documents rather than pre-existing database fields?

- How effectively does this automated workflow transfer to other disaster databases with different reporting standards, such as DesInventar or Internal Displacement Updates?

## Limitations

- Hallucination risk in LLM parsing may inflate geocoding coverage claims through systematic errors in administrative hierarchy assignment
- Reliability score validity as accuracy proxy lacks independent validation beyond initial benchmark comparison
- Geographic knowledge cutoff means GPT-4o may lack knowledge of recent administrative boundary changes

## Confidence

- **High Confidence**: Multi-source geocoding approach and GADM harmonization methodology are technically sound with verifiable 97.9% accuracy on benchmarks
- **Medium Confidence**: 92% geocoding coverage claim depends heavily on unknown LLM parsing performance characteristics
- **Low Confidence**: Reliability score's validity as accuracy proxy lacks comprehensive validation

## Next Checks

1. **Parser Hallucination Audit**: Extract and manually review 100 randomly selected LLM-parsed JSON hierarchies to quantify hallucination rates, specifically measuring false administrative assignments and invented place names.

2. **Reliability Score Calibration**: Test the reliability score against a blind validation set of 500 events where ground truth is known but not used in development. Calculate precision and recall at different score thresholds to determine if the score meaningfully discriminates accuracy.

3. **Temporal Degradation Analysis**: Split the validation set by event year (pre- and post-GPT-4o training cutoff) to measure whether geocoding accuracy decreases for more recent events due to outdated geographic knowledge.