---
ver: rpa2
title: 'HICode: Hierarchical Inductive Coding with LLMs'
arxiv_id: '2509.17946'
source_url: https://arxiv.org/abs/2509.17946
tags:
- themes
- data
- labels
- page
- cited
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces HICode, an LLM-based pipeline for conducting
  deep, nuanced analysis over large-scale text corpora by scaling inductive coding
  methods from qualitative research. HICode consists of two modules: label generation,
  which produces fine-grained, research-question-relevant labels for each text segment
  using a tailored prompt, and hierarchical clustering, which groups labels into meaningful
  themes through iterative LLM prompting.'
---

# HICode: Hierarchical Inductive Coding with LLMs

## Quick Facts
- **arXiv ID**: 2509.17946
- **Source URL**: https://arxiv.org/abs/2509.17946
- **Reference count**: 28
- **Primary result**: HICode achieves 0.72 precision and 0.74 recall in human evaluation on Astro dataset, outperforming TopicGPT

## Executive Summary
HICode is an LLM-based pipeline that scales inductive coding methods for large-scale text analysis by separating label generation from hierarchical clustering. The system produces research-question-relevant labels for each text segment and groups them into meaningful themes through iterative LLM prompting. Validated across three diverse datasets, HICode shows superior performance compared to baselines like TopicGPT, particularly when analysis requires focusing on specific dimensions rather than generic topics. The approach enables researchers to extract nuanced themes from massive document collections while maintaining control over granularity and thematic coherence.

## Method Summary
HICode operates as a two-module pipeline using LLM APIs. First, the label generation module creates fine-grained labels for each text segment based on user-provided background context and coding goals, with outputs limited to concise phrases or "Irrelevant." Second, the hierarchical clustering module iteratively groups these labels into themes by processing batches of 100 labels through LLM prompting, with results feeding into subsequent iterations until convergence. The pipeline supports parallel processing of independent modules and allows researchers to inspect intermediate outputs for granularity control. Evaluation combines automated theme-level and segment-level metrics with human assessments across three datasets.

## Key Results
- On Astro dataset, HICode achieved precision of 0.72 and recall of 0.74 in human evaluation, compared to TopicGPT's 0.18 precision and 0.33 recall
- For Values dataset, HICode achieved precision of 0.96 and recall of 0.57 at the most lenient threshold
- Hierarchical clustering outperformed incremental approaches, showing better precision-recall balance (Astro: precision 0.53 vs 0.19 for incremental)
- Performance remained robust across different LLM choices for generation and clustering modules

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating label generation from clustering enables parallelization and improves controllability
- Mechanism: Label generation runs independently on each text segment, and clustering operates on batches of 100 labels across multiple iterations. This decoupling allows users to inspect intermediate outputs and "walk back to earlier iterations" for finer-grained analysis
- Core assumption: The two-stage decomposition does not lose semantic coherence that would be preserved in a unified process
- Evidence anchors:
  - [abstract] "HICode consists of two modules: label generation...and hierarchical clustering"
  - [Page 3, Pipeline Motivation] "HICode has the benefit that label generation for each text segment and each batch of clustering is entirely independent"
  - [corpus] Related work on AI-assisted qualitative coding (e.g., CollabCoder, LLooM) similarly modularizes stages but emphasizes interactivity over scale
- Break condition: If label generation produces inconsistent or overly granular labels that cannot be meaningfully clustered, the hierarchical stage may produce incoherent themes or excessive fragmentation

### Mechanism 2
- Claim: Research-question-guided prompts produce labels targeted at specific analysis dimensions rather than generic topics
- Mechanism: The label generation prompt requires two user-provided componentsâ€”(1) background context defining the analysis dimension and (2) the inductive coding goal. This constrains the LLM to generate labels that are "observational, concise and clear" and relevant to the research question
- Core assumption: LLMs can follow multi-part instructions to prioritize research-question relevance over surface-level topic extraction
- Evidence anchors:
  - [Page 2, Label Generation] "These parts of the prompt are expected to change across datasets...to allow a researcher to direct the model to focus on a particular research question"
  - [Page 5] On Astro, which requires "focusing on the 'query types' rather than 'query content,'" TopicGPT's performance degraded substantially while HICode maintained higher precision
  - [corpus] Neighbor paper "AI Coding with Few-Shot Prompting for Thematic Analysis" similarly finds prompt design critical for thematic alignment
- Break condition: If the background or goal descriptions are ambiguous, overly broad, or misaligned with the data, labels may drift toward generic summaries or miss the target dimension entirely

### Mechanism 3
- Claim: Hierarchical batch clustering with LLM synthesis produces more precise themes than incremental label updating
- Mechanism: Labels are randomly divided into batches of 100. Each batch is clustered via LLM prompting, with outputs becoming inputs for the next iteration. This continues until convergence or a user-specified threshold. Compared to incremental approaches, hierarchical clustering reduces premature consolidation and allows coarser/finer granularity control
- Core assumption: LLM-based clustering of abstracted labels is more reliable than clustering raw text embeddings, and iterative synthesis preserves semantic relationships
- Evidence anchors:
  - [Page 2-3] "We implement this clustering through repeated rounds of LLM prompting, which our initial experiments found to be more reliable than traditional clustering methods"
  - [Page 5-6, Table 2] On Astro, the incremental approach achieved recall 0.67 but precision only 0.19, while HICode achieved precision 0.53 and recall 0.51
  - [corpus] Weak direct corpus comparison; neighbor papers focus on human-AI collaboration rather than hierarchical vs. incremental clustering specifically
- Break condition: If batches are too small or too large, clustering may over-fragment or over-generalize; if the LLM fails to consistently interpret the clustering instruction across iterations, themes may drift semantically

## Foundational Learning

- Concept: **Inductive vs. Deductive Coding**
  - Why needed here: HICode is designed for inductive codingâ€”deriving labels directly from data without a pre-existing codebook. This contrasts with deductive coding (applying predefined categories) and topic modeling (unsupervised pattern extraction)
  - Quick check question: Can you explain why TopicGPT performs well on the Media Frames Corpus but poorly on Astro, based on the difference between emphasis frames and inductive query-type analysis?

- Concept: **Theme-level vs. Segment-level Metrics**
  - Why needed here: Evaluation uses both theme-level precision/recall (do generated themes match human themes?) and segment-level metrics (do matched themes label the same text segments?). Understanding this distinction is necessary for interpreting Table 2 vs. Table 4
  - Quick check question: Why might a pipeline achieve high theme-level precision but low segment-level recall?

- Concept: **Hierarchical Clustering Convergence**
  - Why needed here: The clustering module iterates until reaching a "pre-determined maximum number of iterations or convergence to a threshold of number of themes." Understanding convergence criteria is necessary for controlling granularity
  - Quick check question: What would happen if you set the convergence threshold too low (e.g., requiring only 3 final themes) on a dataset with 82 human-coded themes like Values?

## Architecture Onboarding

- Component map: Pre-processing (segments) -> Label Generation (LLM prompts) -> Hierarchical Clustering (iterative LLM synthesis) -> Evaluation (automated + human)
- Critical path:
  1. Define background context and coding goal for your dataset
  2. Run label generation on all segments (parallelizable)
  3. Configure batch size (default 100), max iterations, and convergence threshold
  4. Run hierarchical clustering
  5. Inspect intermediate clustering iterations for granularity control
- Design tradeoffs:
  - Hierarchical vs. Incremental: Hierarchical favors precision and parallelization; incremental may achieve higher recall but lower precision and is harder to parallelize
  - Batch size: Smaller batches increase compute cost (more LLM calls); larger batches may lose fine-grained distinctions
  - LLM choice: Ablation suggests generation model choice has minimal impact if clustering model is strong; gpt-4o-mini slightly outperforms llama-3.1-8B for clustering
- Failure signatures:
  - High percentage of "Irrelevant" labels: Prompt may be too narrow or data may not match research question
  - Theme fragmentation (e.g., >50 themes for small dataset): Convergence threshold too lenient or batch size too small
  - Low segment-level recall despite high theme-level precision: Generated themes match human themes semantically but label different text segments
- First 3 experiments:
  1. Replicate the Astro evaluation using the provided code and gpt-4o-mini; verify theme-level precision/recall falls within reported confidence intervals
  2. Ablate batch size (50, 100, 200) on the Values dataset and measure impact on theme count and segment-level recall
  3. Run the pipeline on a new dataset (e.g., 500 interview transcripts) with a custom coding goal; inspect the distribution of "Irrelevant" labels and adjust the background description if >50% are marked irrelevant

## Open Questions the Paper Calls Out

- **Can smaller, specialized models be effectively distilled to perform HICode's specific generation and clustering tasks without significant performance degradation compared to all-purpose LLMs?**
  - Basis: [explicit] The "Pipeline Motivation" section states that separating the modules "facilitates future follow-up work on distilling smaller specialized models for each module, rather than requiring all-purpose LLMs"
  - Why unresolved: The current study relies on general-purpose API-based and open-source models and does not evaluate the feasibility or performance of task-specific distilled models
  - What evidence would resolve it: A comparative benchmark showing that a distilled model achieves comparable theme-level precision and recall to GPT-4o-mini on the Values or Astro datasets

- **How can automated evaluation metrics be improved to better align with human judgments of semantic similarity in inductive coding?**
  - Basis: [explicit] The "Limitations" section notes that "future work is needed to further improve the reliability of evaluation metrics" because standard cosine similarity often fails to capture nuanced matches
  - Why unresolved: The authors demonstrate that automated metrics (e.g., cosine similarity) act as a "conservative estimate," frequently under-counting matches that human evaluators identify as valid
  - What evidence would resolve it: The development of a new metric that correlates strongly with human agreement rates across different thresholds

- **How sensitive is the pipeline's output to variations in the user-provided background information and goal descriptions?**
  - Basis: [explicit] The "Limitations" section acknowledges that the method relies on user prompts and "results may vary by the user's choice of prompt," despite the authors using only one prompt per dataset
  - Why unresolved: The paper does not conduct a sensitivity analysis on the prompt engineering aspect, leaving the robustness of the "Goal of Inductive Coding" input untested
  - What evidence would resolve it: An ablation study measuring the variance in generated themes when the goal description is rephrased or partially omitted for a fixed dataset

## Limitations

- **Reproducibility constraints**: Exact embedding model specification and prompt content for Astro/Values datasets are not disclosed, preventing exact replication of reported metrics
- **Sample size for human evaluation**: Only 30 segments evaluated per dataset for human assessments, limiting statistical power
- **Real-world deployment considerations**: Processing 34,000 documents requires substantial compute resources and multiple LLM calls, though cost-effectiveness versus manual coding is not quantified

## Confidence

- **High confidence** in mechanism claims supported by ablation studies and comparative evaluations across multiple datasets
- **Medium confidence** in human evaluation results due to small sample size and lack of confidence intervals for human metrics
- **Medium confidence** in scalability claims based on single case study rather than systematic evaluation across varying dataset sizes

## Next Checks

1. Replicate the Astro evaluation using the provided code and specified LLM parameters; verify theme-level precision/recall falls within reported confidence intervals
2. Ablate batch size (50, 100, 200) on the Values dataset and measure impact on theme count and segment-level recall to validate batch size tradeoffs
3. Run the pipeline on a new dataset (e.g., 500 interview transcripts) with a custom coding goal; inspect the distribution of "Irrelevant" labels and adjust the background description if >50% are marked irrelevant