---
ver: rpa2
title: 'Automated Business Process Analysis: An LLM-Based Approach to Value Assessment'
arxiv_id: '2504.06600'
source_url: https://arxiv.org/abs/2504.06600
tags:
- process
- business
- prompt
- steps
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an LLM-based approach to automate value-added
  analysis in business processes, decomposing high-level activities into granular
  steps and classifying them according to Lean principles. The method addresses the
  subjectivity and time-consuming nature of manual process analysis.
---

# Automated Business Process Analysis: An LLM-Based Approach to Value Assessment

## Quick Facts
- arXiv ID: 2504.06600
- Source URL: https://arxiv.org/abs/2504.06600
- Reference count: 40
- LLM-based approach achieves 58.7% exact or functionally equivalent step breakdowns and 72% F1 score for overall step classification

## Executive Summary
This paper presents an automated approach to value-added analysis in business processes using large language models. The method decomposes high-level activities into granular steps and classifies them according to Lean principles (Value Adding, Business Value Adding, Non-Value Adding). By employing structured prompting with GPT-3.5-Turbo-0125 on 50 business process models, the approach addresses the subjectivity and time-consuming nature of manual process analysis. The study demonstrates LLMs' potential to augment human expertise in qualitative process analysis while reducing subjectivity and manual effort.

## Method Summary
The method employs GPT-3.5-Turbo-0125 with temperature 0.1 using greedy grid-search optimized structured prompts. It consists of two stages: activity breakdown (decomposing high-level activities into detailed steps) and value-added analysis (classifying steps into VA, BVA, or NVA categories). The approach uses role-based prompting with personas like "Business Process Expert" and "LEAN Analyst," incorporates specific guidelines and few-shot examples, and employs a custom "Comparator LLM" for semantic evaluation rather than exact string matching.

## Key Results
- Achieved 58.7% exact or functionally equivalent step breakdowns compared to 29.0% with zero-shot prompting
- Obtained 72% overall F1 score for step classification, with 50% F1 specifically for identifying non-value-adding steps
- The "Business Process Expert" role achieved the highest functional equivalence (38.9%) compared to zero-shot (29.0%)
- "LEAN Analyst" prompt maximized NVA recall (identifying waste) while balancing overall classification performance

## Why This Works (Mechanism)

### Mechanism 1: Semantic Decomposition via Domain Anchoring
Structured prompting with specific role descriptions enables LLMs to decompose high-level activities into granular steps by accessing domain-specific latent knowledge. The model relies on semantic associations between professional roles and standard operating procedures stored in its pre-training data.

### Mechanism 2: Lean Classification via Verbalized Constraints
Explicitly defining classification criteria in the prompt reduces subjectivity by forcing the model to map semantic descriptions to rigid VA/BVA/NVA buckets. The model performs semantic matching between activity descriptions and provided definitions.

### Mechanism 3: Error Mitigation via Comparator LLMs
Traditional evaluation metrics fail to capture validity of LLM-generated process steps; a secondary "Comparator LLM" is required to evaluate semantic equivalence. This acknowledges multiple "correct" ways to decompose a process.

## Foundational Learning

- **Value-Added Analysis (VAA) & Waste Identification**: Target output requiring definition of three specific categories used in Lean methodology: VA (Customer value), BVA (Business necessity/Compliance), and NVA (Waste). Quick check: "Review loan application for fraud" is BVA (compliance/risk management).

- **Zero-Shot vs. Structured Prompting**: Paper demonstrates clear performance delta. Zero-shot treats LLM as chatbot; structured prompt treats it as system component with defined API (Role, Context, Constraints). Quick check: "Business Process Expert" persona outperforms "Neutral Analyst" by narrowing probability distribution to domain-specific vocabulary.

- **Greedy Grid Search for Prompt Optimization**: Formalizes prompt engineering as hyperparameter search (iterating over Roles, Guidelines, Examples) to isolate which components drive performance. Quick check: "Detailed Guidelines" generally performed better than "Basic Guidelines" for reducing "No Match" rates.

## Architecture Onboarding

- **Component map**: BPMN Process Model -> Decomposition Engine (BPE Role) -> Classification Engine (LEAN Analyst Role) -> Evaluation Layer (Comparator LLM)

- **Critical path**: The Decomposition phase is the bottleneck. Incorrect breakdown (too granular or missed steps) propagates error to subsequent Value-Added Analysis.

- **Design tradeoffs**: Granularity vs. Consistency (fine-grained steps increase detail but introduce higher variance); Recall vs. Precision in Waste (SME prompt maximizes NVA recall but sacrifices overall F1).

- **Failure signatures**: "VA-BVA Confusion" (39.5% of VA steps misclassified as BVA); Hallucinated Context (model may invent steps not in specific process model).

- **First 3 experiments**:
  1. Reproduce Decomposition Baseline: Run zero-shot vs. Structured BPE prompt on single activity, count valid steps.
  2. Stress Test "Lean" Definitions: Modify BVA definitions (remove "compliance" keyword) and measure VA/BVA confusion shift.
  3. Implement "Comparator": Build prompt asking LLM "Is 'Verify ID' semantically equivalent to 'Check Passport'? Answer Yes/No" on test set outputs.

## Open Questions the Paper Calls Out

- **External Data Integration**: Can operational data from event logs improve value-added analysis accuracy compared to static process models alone? Authors suggest future work should leverage external information captured in business process event logs.

- **Prompt Optimization**: Can reinforcement learning or meta-prompting strategies outperform greedy grid search for prompt optimization? Authors identify need to explore reinforcement learning for automated prompt tuning and develop meta-prompting approaches.

- **Process Redesign**: Can the framework be extended to suggest and evaluate process redesigns rather than solely identifying waste? Authors suggest extending approach to "automated process redesign" for comprehensive process improvement.

- **NVA Classification Accuracy**: How can classification accuracy for Non-Value Adding steps be improved given subjectivity and low prevalence? Paper reports lower F1 score (0.50) for NVA class compared to overall score (0.72).

## Limitations

- Dataset representativeness: 50 BPMN models from academic sources may not reflect real-world business complexity or domain-specific jargon.

- Subjective ground truth: Both decomposition and classification tasks are inherently subjective, and ground truth may vary based on annotator expertise.

- Evaluation methodology: The "Comparator LLM" approach introduces secondary source of subjectivity and potential hallucination.

## Confidence

- **High Confidence**: Core claim that structured prompting significantly improves LLM performance in business process decomposition (58.7% vs. 29.0% functional equivalence) is well-supported by ablation study results.

- **Medium Confidence**: Classification results (72% overall F1) are robust, but high confusion between VA and BVA (39.5%) suggests Lean definitions may need refinement for practical use.

- **Low Confidence**: "Comparator LLM" evaluation approach is innovative but lacks external validation; reliability cannot be fully assessed without knowing exact implementation.

## Next Checks

1. **External Dataset Validation**: Apply methodology to real-world business processes from industry partners to test generalizability beyond academic BPMN models.

2. **Human-in-the-Loop Comparison**: Conduct side-by-side study where human experts perform same decomposition and classification tasks, measuring inter-annotator agreement versus LLM-human agreement.

3. **Comparator LLM Reliability Test**: Design controlled experiment where Comparator LLM evaluates outputs from multiple decomposition strategies, cross-validating judgments against human annotators to establish reliability thresholds.