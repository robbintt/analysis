---
ver: rpa2
title: 'CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging
  the Gap Between Trajectory and Language'
arxiv_id: '2505.23837'
source_url: https://arxiv.org/abs/2505.23837
tags:
- candidate
- prediction
- comapoi
- user
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoMaPOI, a collaborative multi-agent framework
  that addresses key challenges in applying LLMs to next POI prediction. CoMaPOI tackles
  the intrinsic difficulty LLMs face in understanding numeric spatiotemporal data
  and the problem of an excessively large candidate POI space.
---

# CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language

## Quick Facts
- arXiv ID: 2505.23837
- Source URL: https://arxiv.org/abs/2505.23837
- Reference count: 40
- Next POI prediction using LLM with 5-10% performance improvement over baselines

## Executive Summary
This paper introduces CoMaPOI, a collaborative multi-agent framework that addresses key challenges in applying LLMs to next POI prediction. CoMaPOI tackles the intrinsic difficulty LLMs face in understanding numeric spatiotemporal data and the problem of an excessively large candidate POI space. It does so through three specialized agents: Profiler, which converts trajectory data into natural language descriptions; Forecaster, which dynamically constrains and refines the candidate POI set; and Predictor, which integrates these inputs to generate high-precision predictions. The framework also employs a Reverse Reasoning Fine-Tuning strategy to enhance each agent's task-specific performance. Extensive experiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that CoMaPOI achieves state-of-the-art performance, improving all metrics by 5% to 10% compared to existing baselines. This work pioneers the investigation of LLM challenges in complex spatiotemporal tasks through tailored collaborative agents.

## Method Summary
CoMaPOI implements a three-agent LLM framework for next POI prediction. The Profiler agent converts raw trajectory data into statistical natural language profiles using four external tools (Toolfreq, Toolcat, Tooltime, Toolloc) that compute frequency, category, time, and location distributions. The Forecaster agent retrieves an initial candidate set via vector similarity (RAG) using BCE embeddings and re-ranks this set based on user profiles. The Predictor agent integrates the trajectory, profile, and refined candidates to generate the final POI prediction. All agents are fine-tuned using a Reverse Reasoning Fine-Tuning strategy that generates synthetic labels for intermediate steps to maximize the likelihood of the ground truth POI. The framework uses Llama3.1-8b as the base model with LoRA fine-tuning (learning rate 1e-4, batch size 16, 200 steps, 50 warm-up steps, weight decay 0.01), and inference uses top_p=1, temp=0 with a fixed trajectory length of 30 points and candidate set size K=25.

## Key Results
- Achieves 5-10% improvement in HR@k, NDCG@k, and MRR metrics compared to existing baselines
- Demonstrates effectiveness across three diverse datasets (NYC, TKY, CA) with varying user and POI counts
- Shows the importance of each component through ablation studies (only SFT performs significantly worse)
- Validates the candidate set size K=25 as optimal through sensitivity analysis

## Why This Works (Mechanism)

### Mechanism 1: Trajectory-to-Language Translation
Converting sparse numeric spatiotemporal data into statistical natural language descriptions bridges the gap between raw trajectory coordinates and LLM semantic understanding. The Profiler agent utilizes statistical tools to aggregate discrete check-in data into structured textual profiles (e.g., "peak hours," "frequent categories"), externalizing the "hard" math for the LLM to process mobility patterns as semantic context rather than raw digits. This assumes LLMs possess stronger semantic reasoning capabilities on textual descriptions than numerical inference capabilities on raw coordinates.

### Mechanism 2: Dynamic Candidate Space Constraint
Constraining the prediction output to a refined subset of candidates significantly reduces error rates compared to a global search over all POIs. The Forecaster agent retrieves an initial candidate set via vector similarity and then re-ranks/truncates this set using user profiles. This provides a high-quality candidate set that lowers the prediction error boundary, assuming the hit rate exceeds a specific lower bound. This addresses the inherent difficulty of predicting a specific POI ID from thousands of options versus selecting from a curated list of 25.

### Mechanism 3: Reverse Reasoning Fine-Tuning (RRF)
Training agents to reverse-engineer the necessary reasoning steps from the ground truth label may align the model's internal representations better than standard supervised fine-tuning. Instead of predicting Y from X, RRF generates synthetic labels for intermediate steps (Profiler descriptions, Forecaster candidates) that maximize the likelihood of the ground truth POI. The model is then fine-tuned on these "ideal" reasoning chains, assuming the quality of reverse-engineered labels is sufficient to guide the model.

## Foundational Learning

- **Concept:** Retrieval-Augmented Generation (RAG)
  - **Why needed here:** The Forecaster agent relies on vector embeddings to reduce the search space from thousands of POIs to a manageable candidate set.
  - **Quick check question:** Can you explain how a vector database retrieves "similar" POIs based on check-in descriptions, and why this is necessary before the LLM processes the list?

- **Concept:** Multi-Agent Orchestration
  - **Why needed here:** The system separates understanding (Profiler), retrieving (Forecaster), and decision-making (Predictor).
  - **Quick check question:** What specific data artifacts does the Profiler pass to the Forecaster, and how does the dependency change if the Profiler is removed?

- **Concept:** LoRA / Parameter-Efficient Fine-Tuning
  - **Why needed here:** The framework requires adapting the LLM to specific spatiotemporal reasoning tasks (via RRF) without retraining the entire model.
  - **Quick check question:** How does LoRA adaptation differ from full fine-tuning, and what does it preserve regarding the base LLM's capabilities?

## Architecture Onboarding

- **Component map:** Raw Trajectory -> Profiler (Tools -> Natural Language Profile & Mobility Patterns) -> Forecaster (RAG + Vector DB -> Refined Candidate Set) -> Predictor (Trajectory + Profile + Candidates -> POI ID)

- **Critical path:** The flow relies on the Profiler successfully converting numeric noise into semantic signal. If the Profile is generic, the Forecaster cannot prune the candidate set effectively, causing the Predictor to hallucinate or select randomly.

- **Design tradeoffs:**
  - Token Budget: Long profiles provide context but consume context window; the paper fixes trajectory length to 30 to manage this.
  - Candidate Size (K): Small K reduces noise but risks excluding the ground truth; the paper finds K â‰ˆ 25 optimal.

- **Failure signatures:**
  - Global Search Fallback: Predictor ignores the candidate set and hallucinates a POI ID (indicates low hit rate in candidate set or weak instruction following).
  - Generic Profiling: Profiler outputs generic text ("User likes food") which fails to constrain the Forecaster.

- **First 3 experiments:**
  1. Candidate Sensitivity: Run inference with varying candidate sizes (K=10, 25, 50) to verify the "lower bound" condition in Eq. 17 on a validation set.
  2. Agent Ablation: Run the system while bypassing the Forecaster (feed raw RAG results to Predictor) to quantify the "noise reduction" value of the Forecaster agent.
  3. RRF vs. Zero-Shot: Compare a vanilla Llama-3.1-8b against the CoMaPOI-tuned model on a "hard" dataset (e.g., sparse check-ins) to isolate the impact of the Reverse Reasoning Fine-Tuning.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the methodology and results, several important questions emerge:

1. Does the Reverse Reasoning Fine-Tuning strategy introduce bias by optimizing agents solely toward the single ground-truth label, potentially penalizing other plausible but unlabeled mobility trajectories?

2. How does the framework perform on users with extensive historical trajectories without the fixed-length truncation applied in the experiments?

3. Can the Forecaster agent recover from a poor initial retrieval, or is the system strictly limited by the recall of the vector database?

## Limitations

- Critical implementation details like exact prompt templates for all three agents are not provided, making reproduction challenging.
- The LoRA configuration details (rank, alpha, target modules) and quantization bits remain unspecified, potentially affecting model adaptation quality.
- The candidate hit rate remains a significant concern, with initial RAG retrieval showing only 18-44% hit rates that depend heavily on the Forecaster's re-ranking capability.
- The methodology assumes trajectory-to-language translation preserves sufficient sequential information, but this assumption isn't empirically validated against alternative representations.

## Confidence

- **High Confidence:** The general multi-agent architecture design and the concept of trajectory-to-language translation are well-established approaches in the literature.
- **Medium Confidence:** The specific implementation details of the RRF fine-tuning and the Forecaster's re-ranking mechanism are plausible given the problem context, but cannot be fully verified without the missing implementation details.
- **Low Confidence:** The exact mechanisms of how the reverse reasoning generates optimal labels, and how the statistical tools aggregate trajectory data into natural language, cannot be independently validated with the information provided.

## Next Checks

1. **Candidate Set Hit Rate Validation:** Systematically measure the percentage of test cases where the ground truth POI appears in the candidate set after Forecaster re-ranking, across different dataset sparsity levels, to verify the theoretical lower bound condition in Eq. 17 holds in practice.

2. **Profiler Information Preservation Test:** Compare prediction accuracy when using raw numeric trajectory data versus the Profiler's natural language descriptions, to quantify how much sequential information is preserved (or lost) in the trajectory-to-language translation process.

3. **RRF Label Quality Audit:** Manually sample 50 reverse-generated profiler descriptions and Forecaster candidate sets, verifying that each logically supports the corresponding ground truth POI and doesn't contain hallucinations or inconsistencies that would mislead the fine-tuning process.