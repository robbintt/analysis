---
ver: rpa2
title: 'Neural Dynamic Modes: Computational Imaging of Dynamical Systems from Sparse
  Observations'
arxiv_id: '2507.03094'
source_url: https://arxiv.org/abs/2507.03094
tags:
- neural
- dynamics
- data
- sparse
- modes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NeuralDMD, a model-free framework that combines
  neural implicit representations with Dynamic Mode Decomposition (DMD) to reconstruct
  continuous spatio-temporal dynamics from sparse, noisy observations. The method
  parameterizes spatial modes with coordinate-based MLPs and learns a low-rank linear
  operator that governs their evolution, yielding interpretable, continuous reconstructions
  that can extrapolate beyond the observation window.
---

# Neural Dynamic Modes: Computational Imaging of Dynamical Systems from Sparse Observations

## Quick Facts
- arXiv ID: 2507.03094
- Source URL: https://arxiv.org/abs/2507.03094
- Reference count: 40
- This paper introduces NeuralDMD, a model-free framework that combines neural implicit representations with Dynamic Mode Decomposition (DMD) to reconstruct continuous spatio-temporal dynamics from sparse, noisy observations.

## Executive Summary
This paper presents NeuralDMD, a novel framework that reconstructs continuous spatio-temporal dynamics from sparse, noisy observations by combining neural implicit representations with Dynamic Mode Decomposition (DMD). The method parameterizes spatial modes with coordinate-based MLPs and learns a low-rank linear operator that governs their evolution, yielding interpretable, continuous reconstructions that can extrapolate beyond the observation window. Experiments on simulated weather data and black hole imaging demonstrate that NeuralDMD outperforms existing methods for both wind field reconstruction and EHT black hole imaging, particularly under extreme sparsity conditions.

## Method Summary
NeuralDMD represents spatial modes as coordinate-based MLPs (neural fields) that map spatial coordinates to mode values, replacing the fixed pixel grid of standard DMD. The method learns a low-rank linear operator that governs temporal evolution through complex eigenvalues, enforcing stable dynamics through decay constraints. Initial state coefficients are treated as learnable parameters optimized over the entire temporal sequence rather than relying solely on the first frame. The framework is trained using MSE or chi-squared loss with Adam optimization, incorporating spectral bias regularization and stability constraints to handle extremely sparse observations.

## Key Results
- Outperforms 3D-VAR for wind field reconstruction, maintaining accuracy at 1% grid sampling
- Achieves L2 errors as low as 0.009 vs. 0.046/0.078 under ngEHT+ coverage for black hole imaging
- Demonstrates robustness to noise and sparsity while providing interpretable modes that reveal underlying dynamics

## Why This Works (Mechanism)

### Mechanism 1: Continuous Spatial Parameterization
Representing spatial modes as coordinate-based MLPs allows the model to infer continuous dynamics from sparse, irregular observations. The implicit representation exploits the spectral bias of neural networks to smooth over gaps in sparse data.

### Mechanism 2: Linear Evolution Constraint
Enforcing a low-rank linear operator to govern temporal evolution prevents overfitting to noise and ensures stable extrapolation. The dynamics are constrained to the form $e^{\Omega t}$, forcing complex data to be explained using simple, coherent structures.

### Mechanism 3: Global Joint Optimization
Treating initial state coefficients as learnable parameters optimized over the entire temporal sequence improves robustness compared to methods that rely solely on the initial frame. This allows the model to leverage information from all time steps to constrain the initial state.

## Foundational Learning

- **Dynamic Mode Decomposition (DMD):** The mathematical core that decomposes spatio-temporal data into spatial modes and temporal eigenvalues. Quick check: Can you explain how a complex eigenvalue $\Omega = \alpha + i\omega$ determines both the oscillation frequency and growth/decay rate of a spatial mode?

- **Neural Implicit Representations:** MLPs that map coordinates to values rather than using discrete arrays. Quick check: Why does passing spatial coordinates through sinusoidal positional encoding help the network learn high-frequency details?

- **Sparsity and Regularization:** Understanding how constraints solve ill-posed inverse problems. Quick check: If you remove the linear dynamics constraint and just use a generic neural network, why would reconstruction likely fail on 1% sparse data?

## Architecture Onboarding

- **Component map:** Inputs (Coords/Latents) → Three MLP branches ($\Theta_w$, $\Theta_\Omega$, $\Theta_b$) → Forward Model (Matrix Multiply/Sum) → Sampling Operator ($S$) → Loss against Observations

- **Critical path:** The forward model computes $I(x,y,t) = \sum w_j e^{\Omega_j t} b_j$ using outputs from the three MLPs, which are then sampled and compared to observations.

- **Design tradeoffs:** Rank ($r$) selection balances capturing dynamics versus overfitting; encoding degree ($L$) trades high-frequency detail for stability; spectrum constraints prevent exploding forecasts.

- **Failure signatures:** Mode collapse (all modes become identical), exploding forecasts (if spectral constraints fail), over-smoothing (if encoding is too low or regularization too strong).

- **First 3 experiments:**
  1. **Orbiting Hotspot:** Verify the forward model math by fitting a simple Gaussian blob moving in a circle.
  2. **Ablation on Constraints:** Train the spectral network without the $\alpha \le 0$ constraint to observe forecasting instability.
  3. **Sparsity Stress Test:** Run the weather model on 10% vs 0.1% sampling to find the breaking point.

## Open Questions the Paper Calls Out

- **Incorporating atmospheric phase delays and closure phase/amplitude observables in VLBI imaging:** The authors note their EHT experiments omit atmospheric phase delays and do not yet incorporate closure phases and amplitudes, identifying this as essential future work.

- **Performance on operational weather data with spatially inhomogeneous sensor networks:** The paper acknowledges that weather experiments assumed perfectly calibrated sensor networks, neglecting spatial inhomogeneity, instrument drift, and data dropouts found in operational systems.

- **Extending to systems with time-varying dynamics:** The current architecture learns a static low-rank linear operator, while the paper notes that time-varying extensions of DMD exist but are not implemented.

## Limitations

- Assumes linear evolution of spatial modes, which may not capture strongly nonlinear dynamics beyond the observation window
- Performance on extreme sparsity (0.1% or lower) is demonstrated but the breaking point is not fully characterized
- Choice of rank (number of modes) is manually selected rather than automatically determined

## Confidence

- **High Confidence:** The core mechanism of combining neural implicit representations with DMD is well-supported by ablation studies and performance comparisons
- **Medium Confidence:** Robustness to noise and extrapolation capabilities are demonstrated but need more extensive testing across diverse dynamical regimes
- **Medium Confidence:** Interpretability of learned modes is claimed but quantitative validation beyond visual inspection is limited

## Next Checks

1. **Extreme Sparsity Test:** Systematically evaluate NeuralDMD on weather data at 0.01%, 0.1%, and 1% sampling to identify the exact breaking point where spectral bias is insufficient

2. **Nonlinear Dynamics Test:** Apply NeuralDMD to a dataset with known strong nonlinearities (e.g., turbulent fluid flow) and compare against ground truth to assess limits of linear evolution assumption

3. **Mode Interpretability Analysis:** Develop quantitative metrics to measure physical interpretability of learned modes (e.g., correlation with known physical quantities) beyond visual inspection