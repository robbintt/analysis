---
ver: rpa2
title: 'Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical
  Notes'
arxiv_id: '2601.21551'
source_url: https://arxiv.org/abs/2601.21551
tags:
- patient
- doctor
- history
- medical
- turn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Note2Chat addresses the challenge of improving large language models
  (LLMs) for multi-turn clinical history taking and diagnosis, a task where current
  models struggle due to their reliance on static, single-turn benchmarks and lack
  of conversational reasoning ability. The method proposes a note-driven framework
  that converts real-world medical notes into structured doctor-patient dialogues
  using a decision tree-guided generation and refinement pipeline, enabling training
  without the need for sensitive dialogue data.
---

# Note2Chat: Improving LLMs for Multi-Turn Clinical History Taking Using Medical Notes

## Quick Facts
- arXiv ID: 2601.21551
- Source URL: https://arxiv.org/abs/2601.21551
- Reference count: 13
- Primary result: +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o on clinical dialogue tasks

## Executive Summary
Note2Chat addresses the challenge of improving large language models (LLMs) for multi-turn clinical history taking and diagnosis, a task where current models struggle due to their reliance on static, single-turn benchmarks and lack of conversational reasoning ability. The method proposes a note-driven framework that converts real-world medical notes into structured doctor-patient dialogues using a decision tree-guided generation and refinement pipeline, enabling training without the need for sensitive dialogue data. It employs a three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning, alongside a novel single-turn reasoning paradigm that treats each dialogue turn as an independent reasoning problem for better interpretability and sample efficiency. Experiments demonstrate substantial improvements, achieving gains of +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o, with the single-turn approach outperforming multi-turn baselines using fewer dialogue turns.

## Method Summary
The framework converts MIMIC-IV discharge notes into synthetic doctor-patient dialogues through a three-component pipeline: finding extraction from History of Present Illness (HPI) sections, decision tree-guided generation mapping symptoms to diagnoses, and critic revision to catch context leakage and missing questions. This creates 8,944 synthetic dialogues without requiring sensitive real patient conversations. The training employs a progressive three-stage fine-tuning strategy: supervised fine-tuning (SFT) on the synthetic dialogues, self-augmentation through simulated interactions with a patient agent, and direct preference optimization (DPO) using a reward function that balances information recall, diagnostic accuracy, and dialogue efficiency. The method introduces a single-turn reasoning paradigm where each dialogue turn includes hidden reasoning blocks containing summaries of accumulated findings and clinical plans, enabling verifiable turn-level supervision.

## Key Results
- Note2Chat achieves +16.9 F1 and +21.0 Top-1 diagnostic accuracy over GPT-4o
- Single-turn reasoning (ST) model outperforms multi-turn (MT) baseline with 46.1 F1 in 17.3 turns vs 43.8 F1 in 27.5 turns
- Progressive three-stage training (SFT → self-augmentation → DPO) shows incremental gains, with DPO adding +3-5 points over self-augmentation alone
- Models struggle with specific symptom categories, particularly Site (13.6% recall for GPT-4o) and Severity (10.1% recall)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Medical notes can serve as silver-standard supervision for training clinical dialogue agents when converted through a structured pipeline.
- **Mechanism:** The pipeline extracts findings from HPI sections, constructs decision trees mapping symptoms to diagnoses, generates dialogues guided by these trees, and applies LLM-based critics to catch context leakage and missing questions. This creates synthetic dialogues without requiring sensitive real patient conversations.
- **Core assumption:** Discharge notes contain clinician-curated summaries that reliably encode which symptom inquiries are diagnostically relevant.
- **Evidence anchors:** [abstract] "convert real-world medical notes into high-quality doctor-patient dialogues using a decision tree-guided generation and refinement pipeline"; [section: Data Curation Pipeline] Details the three-component pipeline; [corpus] CliniChat similarly reconstructs clinical interview dialogues, suggesting the note-to-dialogue approach is an active research direction.

### Mechanism 2
- **Claim:** Progressive fine-tuning through SFT → self-augmentation → DPO improves robustness to imperfect conversation dynamics better than any single training stage alone.
- **Mechanism:** SFT establishes baseline dialogue patterns from idealized note-guided conversations. Self-augmentation exposes the model to diverse imperfect trajectories via self-play, selecting those with highest recall. DPO then optimizes a reward function combining information recall, diagnostic accuracy, and dialogue efficiency.
- **Core assumption:** The reward function correctly captures clinically desirable behavior—particularly the weighting that prevents "lucky guesses" from inflating scores without sufficient information gathering.
- **Evidence anchors:** [abstract] "three-stage fine-tuning strategy combining supervised learning, simulated data augmentation, and preference learning"; [section: Three-Stage Fine-Tuning Strategy] Describes how SFT alone is insufficient, self-augmentation adds +8-10 points, DPO adds final +3-5 points; [corpus] DoctorAgent-RL applies reinforcement learning to clinical dialogue but relies on rigid state-action spaces.

### Mechanism 3
- **Claim:** Reframing multi-turn history taking as a sequence of single-turn reasoning problems improves sample efficiency and enables verifiable turn-level supervision.
- **Mechanism:** Between each dialogue turn, the model generates a hidden reasoning block containing a summary of accumulated findings and a clinical plan justifying the next action. This allows turn-level rewards that directly credit information acquisition rather than only evaluating complete trajectories.
- **Core assumption:** Explicit reasoning blocks improve decision-making rather than adding computational overhead without benefit.
- **Evidence anchors:** [abstract] "single-turn reasoning paradigm that reframes history taking as a sequence of single-turn reasoning problems"; [section: Multi-Turn History Taking via Single-Turn Reasoning] Shows Note2Chat-ST achieves 46.1 F1 in 17.3 turns vs MT's 43.8 F1 in 27.5 turns; [corpus] No direct corpus validation for single-turn decomposition in clinical dialogue specifically.

## Foundational Learning

- **Concept:** Direct Preference Optimization (DPO)
  - **Why needed here:** Replaces reinforcement learning's complex reward modeling by treating preference pairs as a classification objective. Used in the third training stage to optimize for concise, clinically effective conversations.
  - **Quick check question:** Can you explain why DPO avoids needing a separate reward model, and what the preference pairs in this paper contrast (high-reward vs. low-reward dialogue trajectories)?

- **Concept:** Markov Decision Processes (MDPs) in dialogue
  - **Why needed here:** The paper formulates history taking as a partially observable sequential decision process. Understanding states (conversation history), actions (ask/diagnose), and rewards is essential to follow the training design.
  - **Quick check question:** In this framework, what information is included in the state at turn t, and why is the process considered "partially observable" rather than fully observable?

- **Concept:** SOCRATES clinical mnemonic
  - **Why needed here:** The analysis breaks recall by symptom categories (Site, Onset, Character, Radiation, Associated symptoms, Timing, Exacerbating/relieving factors, Severity). Understanding these dimensions helps interpret Figure 2 and why models struggle with certain categories.
  - **Quick check question:** Why might a model achieve high recall on "Onset" but low recall on "Severity," and what does this suggest about training data or questioning strategies?

## Architecture Onboarding

- **Component map:** MIMIC-IV discharge notes → HPI extraction → finding sets → decision tree construction → LLM-guided dialogue synthesis → critic revision → synthetic dialogues → SFT on Qwen2.5-7B → self-augmentation with patient agent → DPO optimization → single-turn reasoning with summary + planning blocks
- **Critical path:** The decision tree quality determines whether generated dialogues reflect valid differential diagnosis workflows. Errors here propagate through all downstream training stages.
- **Design tradeoffs:**
  - **Multi-turn vs. Single-turn:** MT achieves higher recall (55.4%) but requires 27.5 turns; ST achieves better F1 (46.1%) and efficiency (17.3 turns). Choose MT for completeness, ST for efficiency.
  - **Recall vs. Efficiency in reward:** α parameter in Eq. 1 balances information gathering against dialogue length. Higher α penalizes long conversations more aggressively.
- **Failure signatures:**
  - **Context leakage:** Doctor references information patient hasn't revealed (critic catches this during generation)
  - **Low recall on specific categories:** Especially Site (13.6% for GPT-4o) and Severity (10.1%)—suggests inadequate training coverage of these symptom dimensions
  - **Premature diagnosis:** Ending dialogue before sufficient findings gathered; mitigated by weighting diagnostic reward by recall ratio
- **First 3 experiments:**
  1. **Validate the pipeline:** Run the note-to-dialogue pipeline on 50 held-out notes. Manually check 10 dialogues for context leakage, missing findings, and clinical plausibility. Target: <15% error rate on critic-flagged issues.
  2. **Ablate training stages:** Train three models (SFT only, SFT+Self-Aug, SFT+Self-Aug+DPO) on the same data split. Report F1, recall, and Top-1 accuracy on the 500-case test set. Expected: incremental gains matching Table 2 (±2 points).
  3. **Test single-turn reasoning:** Compare Note2Chat-ST against Note2Chat-MT on efficiency metrics. Verify that reasoning blocks accurately summarize conversation history by sampling 20 turns and checking summary completeness against ground-truth dialogue. Target: >90% of key findings mentioned in summaries.

## Open Questions the Paper Calls Out
- **Open Question 1:** To what extent does the performance of Note2Chat generalize to real-world patient interactions compared to the simulated patient agents used in the study? [explicit] The authors state in the Conclusion that the "limited-scale validation with simulated patients is far from conclusive" and acknowledge that the patient agent is simulated (Qwen2.5-32B) rather than human.
- **Open Question 2:** Does the framework maintain its diagnostic efficiency when scaled to the full spectrum of clinical conditions beyond the 10 specific diseases evaluated? [explicit] The Experiments section notes that the scope was "constrained by computational and cost considerations" and focused only on "10 clinically relevant conditions" derived from two major condition groups.
- **Open Question 3:** How does the reliance on "silver-standard" note-derived dialogues impact the model's ability to capture conversational nuances lost during the note-to-dialogue conversion? [inferred] The paper acknowledges using medical notes as a "silver-standard reference" and employs a "Critic and revision" step to fix context leakage, implying potential fidelity issues in the synthetic data generation process.

## Limitations
- Performance evaluation relies on simulated patients rather than real human interactions, limiting generalizability to actual clinical settings
- The framework is constrained to 10 specific clinical conditions due to computational and cost considerations, raising questions about scalability to broader medical domains
- The synthetic data generation pipeline depends on the completeness of medical notes, potentially missing clinically relevant conversational nuances that clinicians document informally or not at all

## Confidence

- **High Confidence:** The three-stage training framework (SFT → self-augmentation → DPO) produces measurable improvements over GPT-4o, with the relative ordering of results being consistent across metrics.
- **Medium Confidence:** The synthetic data generation pipeline successfully converts medical notes into usable dialogue data without significant context leakage, though the clinical validity of these dialogues remains unverified against real patient conversations.
- **Low Confidence:** The single-turn reasoning approach will generalize equally well to other clinical domains or non-medical multi-turn dialogue tasks, as current validation is limited to the specific conditions studied.

## Next Checks
1. **Real-World Dialogue Validation:** Test Note2Chat on actual doctor-patient conversation transcripts (where available) to verify that synthetic training generalizes to authentic dialogue patterns and information gaps.
2. **Clinical Expert Review:** Have board-certified physicians evaluate 50 randomly sampled dialogues for clinical plausibility, completeness of symptom coverage, and adherence to standard diagnostic protocols.
3. **Cross-Domain Transfer:** Apply the single-turn reasoning framework to a non-medical multi-turn dialogue task (e.g., technical support) to determine if the performance gains are specific to clinical reasoning or represent a more general architectural improvement.