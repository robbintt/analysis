---
ver: rpa2
title: 'Don''t Think of the White Bear: Ironic Negation in Transformer Models Under
  Cognitive Load'
arxiv_id: '2511.12381'
source_url: https://arxiv.org/abs/2511.12381
tags:
- rebound
- negation
- suppression
- semantic
- heads
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates ironic rebound in large language models
  (LLMs), where negation instructions paradoxically increase the likelihood of forbidden
  concepts being mentioned. The authors introduce ReboundBench, a dataset of 5,000
  systematically varied negation prompts, and conduct two main experiments: (1) measuring
  rebound strength under different cognitive loads (semantic, syntactic, repetition
  distractors) and (2) testing polarity discrimination between neutral and negative
  framings.'
---

# Don't Think of the White Bear: Ironic Negation in Transformer Models Under Cognitive Load

## Quick Facts
- **arXiv ID**: 2511.12381
- **Source URL**: https://arxiv.org/abs/2511.12381
- **Reference count**: 32
- **Primary result**: Ironic rebound causes LLMs to mention forbidden concepts more often after negation instructions, driven by middle-layer attention heads.

## Executive Summary
This paper investigates ironic rebound in LLMs, where negation instructions paradoxically increase the likelihood of forbidden concepts being mentioned. The authors introduce ReboundBench, a dataset of 5,000 systematically varied negation prompts, and conduct two main experiments: (1) measuring rebound strength under different cognitive loads (semantic, syntactic, repetition distractors) and (2) testing polarity discrimination between neutral and negative framings. Results show that semantic distractors produce the strongest rebound, while repetition supports suppression. Larger models generally exhibit more persistent rebound, with Bloom-560M showing the highest magnitude (28.4 bits). Notably, GPT-OSS-20B breaks the scaling trend by showing minimal rebound. Circuit tracing analysis reveals that rebound arises from a sparse set of middle-layer attention heads that amplify forbidden tokens, while early layers suppress them. Models with stronger polarity separation show more persistent rebound. The findings highlight the fragility of negation-based filters and suggest that ironic rebound emerges from identifiable internal mechanisms rather than being a distributed phenomenon.

## Method Summary
The paper uses ReboundBench, a dataset of 5,000 negation prompts systematically varying topic, target, and distractor type/length. Nine transformer models (GPT-2 Small to GPT-OSS-20B) are evaluated on single-token targets under semantic, syntactic, and repetition distractors of increasing length. The primary metric is surprisal difference (∆s(ℓ) = log₂p(forbidden|ℓ) - μ_base), with suppression score S(L) and polarity discrimination ∆ also measured. Circuit tracing via attention head ablation on Llama-3-8B-Instruct identifies that 15-20 heads (1-2 per layer) in middle layers account for 80%+ of rebound by amplifying forbidden tokens that early layers initially suppress.

## Key Results
- Semantic distractors trigger the strongest rebound, syntactic distractors are weaker, and repetition supports suppression
- Larger models generally exhibit more persistent rebound, with Bloom-560M showing the highest magnitude (28.4 bits)
- GPT-OSS-20B breaks the scaling trend by showing minimal rebound despite being the largest model
- A sparse set of middle-layer attention heads (~15-20 heads) account for 80%+ of total rebound effect
- Models with stronger polarity separation show more persistent rebound (r≈0.44 correlation)

## Why This Works (Mechanism)

### Mechanism 1: Middle-Layer Attention Amplification
Processing begins in early layers (0–7) which suppress the forbidden concept, but in middle layers (8–16), a small number of attention heads (~15–20 heads, or ~1–2 per layer) reverse this effect and amplify the forbidden token's log-probability, creating internal competition where early suppression is partially undone by middle-layer amplification.

### Mechanism 2: Cognitive Load Modulates Suppression Durability
A negation instruction initiates a suppression state that degrades under cognitive load. Semantic distractors (coherent text on the same topic) most strongly disrupt suppression by maintaining activation of the forbidden concept's semantic representation, while repetition distractors reinforce surrounding context and support suppression.

### Mechanism 3: Polarity Separation Correlates with Rebound Persistence
Models with sharper internal distinction between neutral and negative framings of a concept exhibit more persistent rebound effects. High "polarity separation" (Δ = logp(neutral) − logp(negative)) indicates nuanced semantic encoding that may make forbidden concepts more deeply embedded, leading to longer-lived rebound across extended contexts.

## Foundational Learning
- **Concept**: Ironic Rebound (from cognitive psychology)
  - **Why needed here**: This is the paper's central phenomenon—the paradox that suppressing a concept requires internally activating it, which can increase its accessibility.
  - **Quick check question**: Why does trying not to think of a "white bear" make you think of it more?
- **Concept**: Surprisal and Log-Probability
  - **Why needed here**: These are the metrics used to quantify rebound. A positive surprisal difference (Δs(ℓ) > 0) means the forbidden token has become *more* probable.
  - **Quick check question**: If the surprisal difference Δs(ℓ) is positive, has the forbidden token become more or less likely?
- **Concept**: Attention Heads and Layers
  - **Why needed here**: The paper's mechanistic analysis identifies specific attention heads in specific layers as the loci of the rebound effect.
  - **Quick check question**: In which layers are the attention heads that most strongly amplify forbidden tokens primarily located?

## Architecture Onboarding
- **Component map**: Early layers (0–7) → Middle layers (8–16) → Later layers (20+)
- **Critical path**: Negation Instruction → Early Layer Suppression → Middle Layer Amplification (by specific heads) → Increased Forbidden Token Log-Probability at Output
- **Design tradeoffs**: Tension exists between representational quality (nuanced semantic understanding, high polarity separation) and cognitive control stability. Larger models with better semantic representations tend to have more persistent rebound.
- **Failure signatures**: Model mentions a concept it was explicitly told not to, especially after semantic distractor text; anomalous scaling trends (like GPT-OSS-20B's minimal rebound) indicating unique fine-tuning effects.
- **First 3 experiments**:
  1. **Baseline Probe**: Run ReboundBench evaluation on your target model to measure Δs(ℓ) for semantic, syntactic, and repetition distractors.
  2. **Head Ablation Test**: Identify top amplifying heads via ablation scans and disable them to confirm their causal role.
  3. **Framing Alternative**: Compare "do not mention X" against positive framing ("focus on Y instead") to see if alternative phrasings reduce rebound magnitude and persistence.

## Open Questions the Paper Calls Out
- **Question 1**: Why does GPT-OSS-20B break the scaling trend by showing minimal rebound, unlike other large models?
  - **Basis**: Future Work section states the anomalous behavior warrants further investigation.
  - **Why unresolved**: Authors hypothesize fine-tuning on synthetic data or architectural variations but don't test these hypotheses.
  - **Evidence needed**: Comparative analysis of GPT-OSS-20B's training data composition and architecture against other 20B-scale models.

- **Question 2**: Do model rebound patterns reflect genuine cognitive parallels to human ironic rebound, or merely superficial statistical regularities?
  - **Basis**: Future Work section calls for direct behavioral comparisons between human and model rebound patterns.
  - **Why unresolved**: Paper establishes behavioral similarity but cannot distinguish mechanistic convergence from coincidence.
  - **Evidence needed**: Controlled experiments comparing human and model rebound under identical prompt conditions.

- **Question 3**: Can targeted interventions on the identified sparse amplification heads mitigate ironic rebound without degrading overall model capabilities?
  - **Basis**: Circuit analysis shows 15–20 heads account for 80%+ of rebound effect, suggesting potential mitigation.
  - **Why unresolved**: Identification of responsible heads demonstrated, but feasibility and safety of modifying them remains untested.
  - **Evidence needed**: Ablation or modification of identified amplification heads with measurement of both rebound reduction and performance on standard benchmarks.

## Limitations
- Dataset reconstruction required as paper provides only placeholder URLs for ReboundBench
- GPT-OSS-20B is an anomalous outlier that breaks observed scaling trends
- Circuit tracing methodology not fully specified (logit lens vs. activation patching unclear)
- Analysis focused exclusively on English and single-token target concepts

## Confidence
- **High Confidence**: Core phenomenon of ironic rebound exists across models; basic experimental setup and general findings about semantic distractors are well-supported
- **Medium Confidence**: Specific mechanism involving middle-layer attention heads as primary drivers; finding that repetition supports suppression
- **Low Confidence**: Claim that larger models generally exhibit more persistent rebound (undermined by GPT-OSS-20B); correlation between polarity separation and rebound persistence lacks causal demonstration

## Next Checks
1. **Cross-Validation with Alternative Negation Instructions**: Replicate main experiments using alternative negation phrasings to test whether rebound is specific to "do not mention" or represents a more general negation processing phenomenon.

2. **Fine-Grained Circuit Tracing Validation**: Conduct more granular attention head analysis by systematically ablating individual heads within identified middle layers (8–16) to verify consistent identification of key amplifiers across multiple random seeds.

3. **Controlled Cognitive Load Manipulation**: Design experiment varying semantic coherence independently of length - using semantically coherent versus incoherent but topically related text of identical length - to isolate whether semantic coherence or mere topic activation drives rebound intensity.