---
ver: rpa2
title: 'Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in
  Visual Grounding Caused by Pruning'
arxiv_id: '2506.21873'
source_url: https://arxiv.org/abs/2506.21873
tags:
- pruning
- tokens
- visual
- performance
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies misaligned position IDs as a key factor causing
  grounding performance degradation in token-pruned MLLMs. It proposes Grounding-Aware
  Token Pruning (GAP), which corrects these misalignments without additional training,
  memory, or computational overhead.
---

# Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning

## Quick Facts
- **arXiv ID**: 2506.21873
- **Source URL**: https://arxiv.org/abs/2506.21873
- **Reference count**: 33
- **Primary result**: Recovers 90% of original grounding performance without additional training or overhead

## Executive Summary
This paper addresses severe performance degradation in visual grounding tasks caused by token pruning in multimodal large language models (MLLMs). The authors identify misaligned position IDs as the primary culprit and propose Grounding-Aware Token Pruning (GAP), which preserves original position IDs during pruning to maintain spatial relationships. GAP consistently recovers grounding accuracy across five MLLMs and six pruning methods without retraining, memory overhead, or computational cost.

## Method Summary
GAP operates by preserving the original position IDs of retained tokens during pruning rather than reassigning consecutive IDs. The method intercepts the token pruning process, retrieves the original position IDs for selected tokens, and maintains these IDs through the rotary position embedding layer. This preserves the spatial mapping between tokens and their original locations in the visual feature map, which is critical for grounding tasks that require precise localization. GAP is inference-only and compatible with any pruning strategy that outputs a score vector for token selection.

## Key Results
- GAP recovers 90% of original REC accuracy on RefCOCO across five MLLMs and six pruning methods
- Maintains zero additional training, memory, or computational overhead compared to standard pruning
- Works across pruning reduction ratios from 25% to 90% with consistent improvements
- Successfully recovers performance on diverse pruning strategies including CLS-visual, text-visual, random, and spatial scoring

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Preserving original position IDs after token pruning recovers grounding performance.
- Mechanism: GAP retains position IDs from the pre-pruning sequence rather than reassigning them consecutively, maintaining spatial relationships between retained tokens.
- Core assumption: Position IDs are the primary spatial reference for the LLM component in grounding tasks.
- Evidence anchors:
  - [abstract] "misaligned position IDs after pruning as the primary cause of this degradation"
  - [section 4.3] "the position IDs are retained in their original form, as before pruning"
  - [corpus] Nüwa paper confirms spatial integrity issues from token pruning in VLMs (no direct mechanism validation yet)
- Break condition: If position IDs were not the dominant spatial signal (e.g., if vision encoder spatial features were preserved), GAP would show minimal effect.

### Mechanism 2
- Claim: Vision encoder spatial information degrades in deeper layers, forcing LLM reliance on position IDs.
- Mechanism: A linear probe trained to predict position IDs from ViT features shows 98.37% accuracy at Layer 1 but only 2.61% at Layer 23 (the LLM input layer), indicating progressive spatial information loss.
- Core assumption: The LLM cannot recover spatial structure from vision encoder features alone.
- Evidence anchors:
  - [section 4.2.2] "model's ability to predict position IDs decreases in deeper layers, eventually approaching zero"
  - [section 4.2.2] "LLM must rely heavily on its own constructed position IDs to recover spatial structure"
  - [corpus] No direct corroboration found; this is a paper-specific claim.
- Break condition: If alternative spatial encodings were introduced at the projector or LLM input, the position ID reliance would diminish.

### Mechanism 3
- Claim: Pruning-induced misalignment affects grounding more than VQA because grounding requires precise spatial localization.
- Mechanism: Grounding tasks (e.g., RefCOCO) require bounding box prediction tied to absolute token positions, while VQA tasks rely more on semantic content. Pruning breaks the token-to-position mapping critical for spatial outputs.
- Core assumption: VQA tasks are less sensitive to absolute position information than grounding tasks.
- Evidence anchors:
  - [section 4.2] "pruning even 1% of tokens in MiniGPTv2 leads to catastrophic performance drop on RefCOCO, while GQA remains largely unaffected"
  - [section 4.2.1] "both permuted misalignment and shifted misalignment... result in performance degradation on the grounding task RefCOCO"
  - [corpus] FocusUI and Nüwa papers corroborate grounding-specific degradation from token manipulation.
- Break condition: If VQA tasks required fine-grained spatial reasoning (e.g., spatial relationship questions), they would show similar degradation.

## Foundational Learning

- **Concept**: Position IDs in Transformers
  - Why needed here: GAP modifies position ID assignment; understanding how RoPE/sinusoidal embeddings encode order is required to implement correctly.
  - Quick check question: What happens to relative position encoding when you remove tokens and reassign consecutive IDs?

- **Concept**: Visual Token Pipeline in MLLMs
  - Why needed here: GAP operates at the vision-to-LLM boundary; knowing where tokens are generated, pruned, and consumed is essential.
  - Quick check question: At what point does the vision encoder output become LLM input tokens?

- **Concept**: Referring Expression Comprehension (REC) metrics
  - Why needed here: The paper measures success via RefCOCO accuracy; understanding IoU-based grounding evaluation is needed to interpret results.
  - Quick check question: Why would a model predict correct object semantics but wrong bounding box coordinates?

## Architecture Onboarding

- **Component map**:
  Vision Encoder (ViT) -> Token Pruning Module -> Position ID Assignment -> Projector -> LLM

- **Critical path**:
  1. Score computation (CLS-visual, text-visual, random, or spatial)
  2. Top-k token selection and pruning
  3. **GAP intervention**: Retrieve original position IDs for retained tokens
  4. Apply rotary embeddings with preserved IDs (not reassigned)
  5. Feed to LLM for generation

- **Design tradeoffs**:
  - No retraining required: GAP is inference-only but assumes position ID alignment was correct in original training
  - Generalization vs. specialization: GAP is method-agnostic but may underperform on tasks with different spatial requirements (corpus suggests robotics/VLA models may have different failure modes)
  - Token reduction ratio: Higher pruning ratios (>75%) sometimes exceed baseline performance, but this is task-dependent

- **Failure signatures**:
  - Grounding accuracy drops 40-80% with pruning but VQA stays stable → position ID misalignment
  - LLaVA-v1.5 drops from 56.14% to 15.34% on RefCOCO val with 50% pruning → classic signature
  - If GAP does not recover performance, check: (1) position ID implementation in LLM, (2) projector type, (3) whether vision encoder preserves any spatial signal

- **First 3 experiments**:
  1. Reproduce LLaVA-v1.5 + CLS-visual pruning (50% ratio) on RefCOCO val; confirm ~15% accuracy baseline
  2. Apply GAP (preserve original position IDs); verify recovery to ~51% (paper reports 51.42%)
  3. Test on GQA with same setup; confirm minimal degradation (<1% drop) to validate grounding-specific effect

Assumption: GAP implementation requires access to intermediate position ID tensors; frameworks that abstract this may need modification.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What factors contribute to the residual 10% performance loss in REC that GAP fails to recover?
- Basis: [explicit] The abstract and results section consistently report recovering "90% of original performance."
- Why unresolved: The authors identify position misalignment as the primary cause but do not analyze if the semantic content lost in pruned tokens accounts for the remaining gap.
- What evidence would resolve it: A correlation study between the semantic density of the pruned tokens and the final localization error.

### Open Question 2
- Question: Why does GAP occasionally yield higher accuracy than the no-pruning baseline at high reduction ratios (75-90%)?
- Basis: [explicit] Section 5.4 and Figure 4 note that accuracy "surpasses the baseline" in specific high-pruning settings.
- Why unresolved: The paper cites general prior work on sparsity but does not explain why preserving original position IDs during heavy pruning specifically improves grounding over the standard model.
- What evidence would resolve it: Attention visualizations comparing the baseline against GAP to determine if the method acts as a spatial noise filter.

### Open Question 3
- Question: Can the reliance on explicit position ID correction be reduced by improving spatial information retention in the Vision Encoder (ViT)?
- Basis: [inferred] Section 4.2.2 demonstrates that spatial information is lost in deeper ViT layers (Table 2), forcing the LLM to rely on position IDs.
- Why unresolved: It is unclear if the performance drop is purely an LLM alignment issue or if a "spatially-aware" ViT would be inherently robust to pruning misalignments.
- What evidence would resolve it: Evaluating GAP on MLLMs utilizing vision encoders regularized to maintain spatial features in later layers.

## Limitations

- GAP is inference-only and cannot correct fundamental spatial encoding flaws in the original training pipeline
- Validation limited to two grounding datasets; may not generalize to tasks requiring fine-grained spatial reasoning beyond object detection
- Success measured by relative performance recovery rather than absolute metric improvements
- Requires access to intermediate position ID tensors, which may not be available in all frameworks

## Confidence

**High confidence** in the core claim that position ID misalignment causes grounding degradation: The ablation study demonstrates consistent performance drops across multiple misalignment types, and the quantitative probe provides mechanistic evidence of spatial information loss in deeper layers.

**Medium confidence** in the generalizability claim: While GAP works across diverse pruning strategies and reduction ratios, the paper does not test on non-ViT backbones, different modalities, or tasks with alternative spatial encodings.

**Low confidence** in the assertion that GAP has "no additional memory or computational overhead": The paper does not benchmark memory usage across different pruning ratios or model sizes, despite requiring storage of position ID tensors.

## Next Checks

1. **Cross-task generalization test**: Apply GAP to a spatial reasoning VQA subset (e.g., GQA spatial relationship questions) and a pixel-level grounding task (e.g., referring expression segmentation) to verify the position ID hypothesis extends beyond bounding box prediction.

2. **Ablation of spatial signal sources**: Modify the vision encoder to output explicit spatial coordinates alongside tokens and test whether GAP still recovers performance, isolating whether position IDs are truly the dominant spatial signal.

3. **Memory overhead quantification**: Measure peak memory usage and inference latency for GAP across different pruning ratios (25%, 50%, 75%, 90%) and model sizes to empirically verify the "no overhead" claim.