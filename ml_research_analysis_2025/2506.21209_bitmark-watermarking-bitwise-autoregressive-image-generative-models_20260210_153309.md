---
ver: rpa2
title: 'BitMark: Watermarking Bitwise Autoregressive Image Generative Models'
arxiv_id: '2506.21209'
source_url: https://arxiv.org/abs/2506.21209
tags:
- image
- watermark
- bitmark
- images
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces BitMark, the first watermarking scheme for
  bitwise autoregressive image generative models. It embeds watermarks at the bit
  level of the token stream during generation, preserving visual quality and speed
  while being robust to a wide range of removal attacks.
---

# BitMark: Watermarking Bitwise Autoregressive Image Generative Models

## Quick Facts
- arXiv ID: 2506.21209
- Source URL: https://arxiv.org/abs/2506.21209
- Authors: Louis Kerner; Michel Meintz; Bihe Zhao; Franziska Boenisch; Adam Dziedzic
- Reference count: 40
- Primary result: Introduces BitMark, the first watermarking scheme for bitwise autoregressive image generative models, with high radioactivity and robustness to removal attacks

## Executive Summary
This work introduces BitMark, a novel watermarking scheme specifically designed for bitwise autoregressive image generative models. The approach embeds watermarks at the bit level of the token stream during generation, achieving a unique combination of preserving visual quality and generation speed while maintaining robustness against various removal attacks. The method exhibits high radioactivity, meaning models trained on watermarked images also generate watermarked outputs, which helps prevent model collapse. Experimental results demonstrate strong detection performance across multiple models and attacks with minimal impact on image quality and generation speed.

## Method Summary
BitMark operates by embedding watermarks directly into the bit-level token stream during the autoregressive generation process. Unlike traditional watermarking approaches that operate on the final generated images, BitMark intervenes at the bitstream level where individual bits are being selected by the model. This allows for watermark embedding that is inherently robust to many post-processing attacks since the watermark is embedded before image formation is complete. The scheme maintains generation efficiency and visual fidelity while achieving high radioactivity, ensuring that downstream models trained on watermarked outputs will themselves produce watermarked generations.

## Key Results
- BitMark successfully embeds watermarks at the bit level of token streams during generation
- The method preserves both visual quality and generation speed while being robust to various removal attacks
- BitMark exhibits high radioactivity, preventing model collapse by ensuring watermarked outputs propagate through training

## Why This Works (Mechanism)
BitMark's effectiveness stems from its unique approach of embedding watermarks at the bit level during autoregressive generation rather than post-hoc on completed images. By intervening during the token selection process, the watermark becomes an intrinsic part of the generation process itself. This timing is crucial because it means the watermark is embedded before the model has fully formed the image, making it resistant to spatial and pixel-level attacks that would typically remove watermarks applied to finished images. The high radioactivity property emerges naturally from this approach - since the watermark is embedded in the token stream that becomes training data for downstream models, those models inherit the watermarking behavior.

## Foundational Learning
- **Autoregressive image generation**: Models that generate images sequentially, pixel by pixel or token by token - needed to understand where and how watermark embedding can occur; quick check: verify generation proceeds in deterministic order
- **Watermark radioactivity**: Property where watermarked content propagates through training to affect downstream models - needed to ensure long-term watermark persistence; quick check: test if models trained on watermarked data generate watermarked outputs
- **Bit-level operations in neural networks**: Understanding how individual bits are processed during generation - needed to implement precise watermark embedding; quick check: confirm watermark can be embedded without disrupting bit selection logic
- **Robustness against removal attacks**: Ability to withstand common watermark removal techniques - needed for practical deployment; quick check: test against standard attack benchmarks
- **Visual quality preservation**: Maintaining perceptual quality despite watermark embedding - needed for user acceptance; quick check: measure quality metrics before and after watermarking

## Architecture Onboarding

**Component map**: Input prompt -> Autoregressive generator -> Bit selection layer -> BitMark watermark embedding -> Output token stream -> Image reconstruction

**Critical path**: The watermark embedding occurs at the bit selection layer during generation, which is the critical path since this is where the intervention happens before image formation.

**Design tradeoffs**: BitMark trades some implementation complexity for robustness and radioactivity. The bit-level approach is more complex than pixel-level watermarking but provides superior resistance to attacks and ensures propagation through training.

**Failure signatures**: Potential failures include visible artifacts if bit-level embedding disrupts generation too severely, reduced generation speed if the watermarking process adds significant overhead, or low radioactivity if the watermark doesn't properly propagate through training.

**First experiments to run**:
1. Test watermark detection accuracy on watermarked vs non-watermarked outputs
2. Measure generation speed with and without BitMark enabled
3. Evaluate visual quality metrics (PSNR, SSIM) comparing watermarked and original outputs

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- The claim of being "the first watermarking scheme for bitwise autoregressive image generative models" requires verification against existing related works
- Evaluation focuses primarily on standard benchmarks and may not fully represent real-world adversarial scenarios
- Long-term stability of radioactivity property across extended training horizons needs further validation

## Confidence

**High confidence**: BitMark's technical implementation and preservation of visual quality and speed are well-supported by the methodology and experiments presented.

**Medium confidence**: The claim of robustness to a wide range of removal attacks is supported by experiments but may benefit from testing against more diverse and sophisticated attack methods.

**Medium confidence**: The assertion that BitMark exhibits high radioactivity and prevents model collapse is promising but requires further validation across longer training horizons and more diverse datasets.

## Next Checks
1. Conduct a comprehensive comparison with the three related works cited to explicitly demonstrate BitMark's novelty and advantages over existing approaches.
2. Test BitMark's robustness against advanced adversarial attacks, including those specifically designed to target autoregressive generation models, and evaluate performance on out-of-distribution images.
3. Perform extended experiments to validate the long-term stability of BitMark's radioactivity property across multiple training epochs and diverse model architectures to confirm its effectiveness in preventing model collapse.