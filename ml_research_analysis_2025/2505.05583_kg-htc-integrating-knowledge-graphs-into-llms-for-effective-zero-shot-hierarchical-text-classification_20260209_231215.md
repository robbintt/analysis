---
ver: rpa2
title: 'KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical
  Text Classification'
arxiv_id: '2505.05583'
source_url: https://arxiv.org/abs/2505.05583
tags:
- contains
- level
- classification
- text
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KG-HTC integrates knowledge graphs with LLMs to enhance zero-shot
  hierarchical text classification. It addresses challenges of large label spaces
  and long-tail distributions in HTC by retrieving relevant subgraphs from knowledge
  graphs using RAG, then transforming these subgraphs into structured prompts for
  LLM classification.
---

# KG-HTC: Integrating Knowledge Graphs into LLMs for Effective Zero-shot Hierarchical Text Classification

## Quick Facts
- **arXiv ID**: 2505.05583
- **Source URL**: https://arxiv.org/abs/2505.05583
- **Reference count**: 40
- **Key outcome**: KG-HTC integrates knowledge graphs with LLMs to enhance zero-shot hierarchical text classification, improving F1-macro scores by 27.1% on average for first-level classification and showing significantly less performance degradation as taxonomy depth increases.

## Executive Summary
KG-HTC addresses the challenges of zero-shot hierarchical text classification (HTC) by integrating knowledge graphs (KGs) with large language models (LLMs). The method retrieves relevant subgraphs from KGs using retrieval-augmented generation (RAG), then transforms these subgraphs into structured prompts for LLM classification. This approach effectively handles HTC's challenges of large label spaces and long-tail distributions by providing semantic context through structured KG integration.

## Method Summary
KG-HTC retrieves relevant knowledge graph subgraphs using RAG to identify labels connected to the input text. These subgraphs are then transformed into structured prompts that include both the original text and semantic context from the KG. The LLM uses these enriched prompts to classify text into hierarchical categories. The method employs a weighted voting mechanism to aggregate predictions from multiple LLM calls with different subgraph contexts, improving robustness and accuracy.

## Key Results
- KG-HTC improves F1-macro scores by 27.1% on average for first-level classification compared to GPT-3.5-turbo alone
- The method achieves gains of 123.1% and 139.0% at deeper hierarchical levels
- KG-HTC demonstrates state-of-the-art performance on three datasets (WoS, DBpedia, Amazon) with significantly less performance degradation as taxonomy depth increases

## Why This Works (Mechanism)
KG-HTC leverages the semantic richness of knowledge graphs to provide contextual information that helps LLMs disambiguate between similar categories in hierarchical taxonomies. By retrieving and integrating relevant subgraphs, the method supplies structured semantic relationships that guide classification decisions, particularly for long-tail categories that lack sufficient training examples. The RAG-based retrieval ensures that only contextually relevant KG information is incorporated, while the structured prompt transformation makes this information accessible to the LLM in a format it can effectively process.

## Foundational Learning
- **Hierarchical Text Classification**: Classifying text into multi-level category taxonomies; needed because many real-world classification tasks require understanding relationships between categories; quick check: Can you explain why flat classification methods fail for hierarchical taxonomies?
- **Knowledge Graph Integration**: Using semantic networks to provide contextual information; needed to address the semantic ambiguity and long-tail distribution problems in HTC; quick check: What advantages do KGs provide over traditional feature engineering?
- **Retrieval-Augmented Generation (RAG)**: Combining retrieval systems with generative models; needed to efficiently identify relevant KG subgraphs without overwhelming the LLM with irrelevant information; quick check: How does RAG differ from simple KG embedding approaches?

## Architecture Onboarding

**Component Map**: Input Text -> RAG Retriever -> KG Subgraph -> Structured Prompt Generator -> LLM Classifier -> Weighted Voting Aggregator

**Critical Path**: The most critical path is Input Text → RAG Retriever → KG Subgraph → Structured Prompt Generator → LLM Classifier. Each component must function correctly for the system to work, but failures in RAG retrieval or prompt structuring have the most significant impact on overall performance.

**Design Tradeoffs**: The method trades computational overhead (multiple LLM calls and RAG retrievals) for improved accuracy and robustness. The structured prompt approach requires careful design to balance informativeness with prompt length constraints. The weighted voting mechanism adds complexity but improves reliability compared to single predictions.

**Failure Signatures**: Poor RAG retrieval leads to irrelevant KG context and degraded performance. Overly complex or verbose prompts may exceed LLM context limits or confuse the model. Insufficient KG coverage for certain domains results in poor performance on specialized topics. The weighted voting mechanism may fail to converge if subgraph contexts are too diverse.

**First Experiments**:
1. Test KG-HTC on a simple hierarchical dataset with known KG coverage to establish baseline performance
2. Compare performance with and without KG integration on long-tail categories to quantify the benefit
3. Vary the number of retrieved subgraphs (k parameter) to find the optimal balance between context richness and computational efficiency

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but implicit limitations include the approach's generalizability to domains with sparse or noisy KGs, the scalability to extremely large taxonomies, and the performance in few-shot or fine-tuning scenarios beyond zero-shot settings.

## Limitations
- The reported improvements are based on a limited set of three datasets, raising questions about generalizability to other domains
- The approach's performance in few-shot or fine-tuning settings is unknown since the paper focuses on zero-shot scenarios
- No extensive ablation studies on RAG configuration parameters or alternative KG integration strategies are provided

## Confidence

**High**: The core methodology of integrating KG subgraphs with LLMs through structured prompts is technically sound and well-described

**Medium**: The quantitative improvements are substantial but based on a limited dataset corpus

**Medium**: The claim about reduced depth-related degradation is supported but warrants broader validation

## Next Checks

1. Test KG-HTC on additional HTC datasets with varying taxonomy depths and structures (e.g., patents, scientific publications, e-commerce categories) to assess generalizability

2. Conduct systematic ablation studies varying RAG parameters (k-nearest neighbors, retrieval strategies) and KG subgraph sizes to identify optimal configurations

3. Compare performance against recent state-of-the-art few-shot HTC methods to establish relative advantages across different training scenarios