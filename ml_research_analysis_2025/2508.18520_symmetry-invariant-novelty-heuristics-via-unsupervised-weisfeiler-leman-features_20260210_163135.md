---
ver: rpa2
title: Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features
arxiv_id: '2508.18520'
source_url: https://arxiv.org/abs/2508.18520
tags:
- planning
- novelty
- heuristics
- heuristic
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces symmetry-invariant novelty heuristics for
  classical planning using Weisfeiler-Leman Features (WLFs). The core method generalizes
  the quantified-both novelty heuristic framework to use arbitrary feature generators,
  enabling the creation of Weisfeiler-Leman (WL) novelty heuristics that are invariant
  to symmetric states.
---

# Symmetry-Invariant Novelty Heuristics via Unsupervised Weisfeiler-Leman Features

## Quick Facts
- **arXiv ID:** 2508.18520
- **Source URL:** https://arxiv.org/abs/2508.18520
- **Reference count:** 9
- **Primary result:** WL novelty heuristics improve coverage in symmetric domains when combined with informative base heuristics like hadd and hff.

## Executive Summary
This paper introduces symmetry-invariant novelty heuristics for classical planning using Weisfeiler-Leman Features (WLFs). The core method generalizes the quantified-both novelty heuristic framework to use arbitrary feature generators, enabling the creation of Weisfeiler-Leman (WL) novelty heuristics that are invariant to symmetric states. This is achieved by leveraging the graph invariance property of the Weisfeiler-Leman algorithm.

Experiments on the IPC and Hard To Ground benchmark suites show that WL novelty heuristics improve upon informative base heuristics like hadd and hff, particularly in domains with symmetric states such as Childsnack. Combining atoms and WL features (at;wl) yields the best performance, with up to 16% improvement in normalized coverage. However, WL novelty heuristics degrade performance when used with less informative heuristics like hgc. The paper demonstrates that WL features are useful for generating novelty heuristics, though they may sometimes mistake asymmetric states as symmetric, affecting exploration negatively in certain domains.

## Method Summary
The method generalizes the quantified-both (QB) novelty heuristic framework to use arbitrary feature generators. The core insight is to represent states as graphs (Instance Learning Graph) and extract Weisfeiler-Leman features that are invariant to graph isomorphism. The WL novelty heuristic caches the minimum heuristic value seen for each feature and only expands states with novel features. The framework wraps existing heuristics (hadd, hff) and combines atom-based and WL features for improved performance.

## Key Results
- WL novelty heuristics improve coverage over informative base heuristics (hadd, hff) in symmetric domains like Childsnack
- Combining atoms and WL features (at;wl) yields up to 16% improvement in normalized coverage compared to atoms-only novelty
- WL novelty heuristics degrade performance when used with weak heuristics like hgc
- The framework maintains symmetry-invariant exploration while preserving the guidance of informative base heuristics

## Why This Works (Mechanism)
The WL novelty heuristic works by detecting symmetric states through graph isomorphism features. The Weisfeiler-Leman algorithm iteratively refines node colors in a graph representation of the planning state, producing features that are invariant to graph automorphisms. By caching the minimum heuristic value for each feature, the heuristic ensures that only states with novel structural properties are expanded, effectively pruning symmetric search paths while maintaining the guidance of the base heuristic.

## Foundational Learning
**Instance Learning Graph (ILG):** A graph representation of planning states where predicates and objects become nodes connected by labeled edges. *Why needed:* Provides the structural representation required for WL feature extraction. *Quick check:* Verify the ILG transformation correctly represents all predicates and objects with proper edge labels.

**Weisfeiler-Leman Algorithm:** An iterative graph coloring procedure that distinguishes non-isomorphic graphs. *Why needed:* Generates features invariant to graph automorphisms, enabling symmetry detection. *Quick check:* Implement WL with L=2 iterations and verify it produces consistent features for isomorphic graphs.

**Feature Cache C:** A mapping from features to minimum heuristic values seen. *Why needed:* Enables the novelty check by remembering which structural patterns have been explored. *Quick check:* Verify cache updates correctly track minimum heuristic values for each feature.

## Architecture Onboarding

**Component Map:** Planning Problem -> ILG Transformation -> WL Feature Extraction -> Feature Cache -> QB Novelty Heuristic -> GBFS Search

**Critical Path:** The feature generation and cache lookup path is critical for performance. Each state expansion requires ILG construction, WL feature extraction, and cache queries. The cache hit rate directly impacts search efficiency.

**Design Tradeoffs:** The framework trades increased memory usage (for feature caching) against reduced node expansions through symmetry pruning. The choice of L=2 WL iterations balances feature discrimination against computational cost. Combining atom and WL features improves coverage but increases cache size.

**Failure Signatures:** 
- Degraded coverage with weak base heuristics (hgc)
- Increased node expansions in domains requiring distinct exploration of similar states
- Memory constraints approaching 4GB limit on large instances

**First Experiments:**
1. Run GBFS with hff baseline on Childsnack to establish baseline coverage
2. Run GBFS with hff + at;wl novelty on same instances to verify coverage improvement
3. Run GBFS with hgc + at;wl novelty to observe degradation with weak heuristics

## Open Questions the Paper Calls Out

**Open Question 1:** Can the complexity theory of width, serialisation, and subgoaling be extended to generalize the behavior of symmetry-invariant novelty heuristics? The paper notes this remains theoretical, with no formal proofs demonstrating how WL features alter width characterization compared to atom-based features.

**Open Question 2:** How does integration with orthogonal search techniques (lazy evaluation, preferred operators, multiple queues) affect performance? Experiments were restricted to single-queue GBFS, leaving interactions with advanced strategies untested.

**Open Question 3:** To what extent does WL's incompleteness negatively impact exploration by falsely identifying asymmetric states as symmetric? The paper observes performance degradation in some domains but doesn't quantify false positive symmetry detections.

**Open Question 4:** How effective is the Generalised QB framework with alternative feature generators like description logic features or neural embeddings? The study only evaluated atoms and WL features, leaving other representations theoretical.

## Limitations
- Performance degrades significantly with weak base heuristics like hgc
- May misclassify asymmetric states as symmetric, harming exploration in specific domains
- Memory usage increases due to feature caching, potentially approaching 4GB limits on large instances

## Confidence
- **High confidence:** WL novelty improves coverage over base heuristics when used with informative heuristics
- **Medium confidence:** Claim that WL features reduce node expansions compared to atoms-only novelty
- **Medium confidence:** Claim that at;wl outperforms individual at or wl configurations

## Next Checks
1. Perform statistical significance tests (e.g., paired t-tests) across all domains to confirm at;wl improvements are not due to random variation
2. Measure memory usage and cache hit rates for C in Eq. 6-7 across large instances to verify 4GB constraint is respected
3. Identify specific problem instances where WL novelty underperforms atoms-only novelty and analyze whether this stems from symmetric state misclassifications