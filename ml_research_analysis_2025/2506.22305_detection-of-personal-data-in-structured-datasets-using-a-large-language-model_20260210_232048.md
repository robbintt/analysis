---
ver: rpa2
title: Detection of Personal Data in Structured Datasets Using a Large Language Model
arxiv_id: '2506.22305'
source_url: https://arxiv.org/abs/2506.22305
tags:
- data
- personal
- datasets
- dataset
- cassed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting personal data in
  structured datasets while ensuring compliance with privacy regulations like GDPR.
  The authors propose a novel approach leveraging GPT-4o, incorporating contextual
  information from dataset descriptions, column names, and neighboring features to
  improve detection accuracy.
---

# Detection of Personal Data in Structured Datasets Using a Large Language Model

## Quick Facts
- **arXiv ID**: 2506.22305
- **Source URL**: https://arxiv.org/abs/2506.22305
- **Reference count**: 33
- **Primary result**: GPT-4o-based approach outperforms CASSED and Presidio on real-world datasets by incorporating contextual information, achieving Macro F1 scores up to 0.964 on OpenML and 0.829 on medical data.

## Executive Summary
This paper addresses the challenge of detecting personal data in structured datasets while ensuring compliance with privacy regulations like GDPR. The authors propose a novel approach leveraging GPT-4o, incorporating contextual information from dataset descriptions, column names, and neighboring features to improve detection accuracy. They compare their method against established benchmarks—Microsoft Presidio and CASSED—using multiple datasets including DeSSI, Kaggle, OpenML, and MIMIC-Demo-Ext. Results show that while CASSED excels on its training dataset (DeSSI), the GPT-4o-based approach achieves superior performance across real-world datasets, demonstrating the value of contextual information. However, computational demands and privacy concerns regarding cloud-based processing remain limitations requiring further research.

## Method Summary
The method uses GPT-4o with a structured CRSRF (Capacity/Role/Statement/Reason/Format) prompting framework to classify columns in structured datasets as containing personal data or not. The model receives the dataset title, description, column name to classify, names of all other columns, and 10 most frequent values from the target column. Classification is performed column-by-column in a binary fashion (personal/non-personal) based on GDPR definitions. The approach is compared against Microsoft Presidio Analyzer (using NER and regex) and CASSED (a DistilBERT-based model trained on synthetic DeSSI data), using Macro F1 as the primary evaluation metric across multiple datasets.

## Key Results
- GPT-4o achieves superior Macro F1 scores on real-world datasets (OpenML: 0.964, Kaggle: 0.857, MIMIC-Demo-Ext: 0.829) compared to CASSED (0.501, 0.349, 0.674) and Presidio (0.614, 0.440, 0.720)
- CASSED shows severe overfitting to synthetic DeSSI data, performing near-perfectly (0.996) on DeSSI test but poorly on real-world data
- GPT-4o correctly identifies contextual personal data (Cabin, Ticket, Reason Absence) that CASSED fails to detect
- All models show false negative rates too high for practical applications, though GPT-4o maintains lowest false positive rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Incorporating dataset-wide contextual information improves personal data detection accuracy on real-world structured datasets.
- Mechanism: GPT-4o receives not just the target column name and sample values, but also the dataset title, description, and names of all other features. This allows the model to infer that a column like "Device Number" may be personal data when other columns suggest it links to employee records, even if the column values alone appear non-identifying.
- Core assumption: Personal data often requires relational context to identify—individual columns may be non-sensitive in isolation but identifying when combined with other attributes (as highlighted by GDPR's definition).
- Evidence anchors:
  - [abstract] "A key innovation of our method is the incorporation of contextual information: in addition to a feature's name and values, we utilize information from other feature names within the dataset as well as the dataset description."
  - [section 1] "Existing solutions tend not to integrate information across several columns and thereby neglect important information."
  - [section 4.3] Shows GPT-4o correctly identifying "Cabin," "Ticket," and "Reason Absence" as personal in Titanic data using context, while CASSED failed.
  - [corpus] Related paper "Towards Contextual Sensitive Data Detection" (arXiv:2512.04120) explores similar contextual sensitivity concepts, suggesting this is an emerging research direction.
- Break condition: Context provides no discriminative signal when columns are truly independent or when dataset descriptions are missing/misleading.

### Mechanism 2
- Claim: Context-free models trained on synthetic data exhibit severe performance degradation on real-world datasets, suggesting overfitting to synthetic patterns.
- Mechanism: CASSED, trained exclusively on the synthetic DeSSI dataset, achieves near-perfect performance (Macro F1 = 0.996) on DeSSI test data but drops to 0.349–0.501 on Kaggle/OpenML. The synthetic training data may not capture the contextual dependencies and naming conventions present in real datasets.
- Core assumption: Synthetic datasets like DeSSI may have artifacts or limited diversity that models exploit without truly learning robust personal data detection.
- Evidence anchors:
  - [abstract] "CASSED excels on DeSSI, the dataset on which it was trained."
  - [section 5] "One possible explanation is overfitting of CASSED on DeSSI... It could also stem from the synthetic generation of features, where the same underlying patterns may have been used."
  - [section 4.3] CASSED failed to recognize "Email Address" and "marital_status" as personal data—surprising failures suggesting training data gaps.
  - [corpus] No direct corpus evidence on synthetic-to-real transfer in this specific domain; this is an open research question.
- Break condition: If real-world datasets share statistical properties with synthetic training data, performance gaps would narrow.

### Mechanism 3
- Claim: Structured prompting with the CRSRF framework improves LLM classification reliability for personal data detection.
- Mechanism: Prompts are structured into four components: (1) Capacity and Role—defining the LLM as a personal data classifier; (2) Statement—specifying the detection objective; (3) Reason—emphasizing privacy/compliance importance; (4) Format—specifying output structure. Additionally, one-shot learning provides an example classification.
- Core assumption: LLMs benefit from explicit role definition and output format constraints to reduce ambiguity in classification tasks.
- Evidence anchors:
  - [section 3.2.1] "The CRSRF (Capacity and Role, Statement, Reason, Format)... is designed to enhance the effectiveness of prompt-based classification tasks."
  - [section 3.2.2] Describes the three-component prompt structure: Initial Prompt, Example Prompt (one-shot), Data Prompt.
  - [appendix B] Full CRSRF framework specification provided.
  - [corpus] No comparative corpus evidence on CRSRF vs. other prompting strategies for this task.
- Break condition: Poorly designed prompts or missing examples could degrade performance below baseline; framework effectiveness not ablated in this paper.

## Foundational Learning

- Concept: **GDPR Definition of Personal Data**
  - Why needed here: The paper distinguishes between directly identifiable PII (e.g., SSN), indirectly identifiable person-related data (e.g., age + job title), and non-personal data. The detection task fundamentally relies on this legal taxonomy.
  - Quick check question: If a dataset contains only "age" and "favorite color" columns, would either be classified as personal data under GDPR as used in this paper?

- Concept: **Named Entity Recognition (NER) and Column-wise Classification**
  - Why needed here: Baseline methods (Presidio) use NER adapted from text processing. Understanding that CASSED and GPT-4o operate column-by-column on structured data (not document-level text) is essential for comparing approaches.
  - Quick check question: Why does Presidio Analyzer require converting tabular data to text, and what information might be lost in this transformation?

- Concept: **Macro F1 vs. Micro F1 for Imbalanced Data**
  - Why needed here: The evaluation datasets have highly imbalanced personal/non-personal ratios (e.g., MIMIC-Demo-Ext: 43 personal vs. 120 non-personal). Macro F1 weights classes equally, making it more informative for this task.
  - Quick check question: If a model correctly classifies all non-personal columns but misses half the personal columns, which metric (Macro F1 or Micro F1) would better reflect this failure?

## Architecture Onboarding

- Component map:
  Input Layer: Dataset (title, description, all column names, target column + 10 sample values)
       ↓
  Prompt Constructor: CRSRF framework → Initial + Example + Data prompts
       ↓
  LLM Classifier: GPT-4o API call (binary output: personal/non-personal)
       ↓
  Aggregation: Per-column classifications → dataset-level detection

  Baseline Comparison Path:
  - Presidio Analyzer: Column-wise/row-wise text extraction → NER + regex → entity mapping
  - CASSED: DistilBERT embedding (column header + values) → sigmoid classifier

- Critical path: The prompt construction is the highest-leverage component. The choice of which contextual elements to include (dataset description, all feature names, sample value count) directly determines detection capability. The paper uses 10 most frequent values per column—this threshold is not ablated.

- Design tradeoffs:
  - **Context amount vs. token limits**: Including all column names and descriptions increases token usage; DistilBERT-based CASSED is limited to 512 tokens and cannot use context.
  - **Cloud vs. on-premise**: GPT-4o requires sending data to external servers, creating GDPR compliance risks; local models (CASSED) avoid this but sacrifice accuracy.
  - **One-shot vs. zero-shot**: The paper uses one-shot learning; zero-shot may degrade performance but reduces prompt complexity.
  - **Binary vs. multiclass**: The paper collapses 20 CASSED classes to binary (personal/non-personal); this loses granularity (e.g., distinguishing "email" from "phone number").

- Failure signatures:
  - **High false positives on synthetic data**: GPT-4o shows elevated FP rates on DeSSI (non-personal columns classified as personal), potentially due to overly conservative interpretation of "person-related."
  - **High false negatives on real-world data for CASSED**: Fails to detect "Email Address," "marital_status," "Cabin," "Ticket"—suggesting training distribution mismatch.
  - **Privacy leakage via API**: Sending personal data to GPT-4o for classification may violate the very regulations the system aims to support.

- First 3 experiments:
  1. **Ablate context components**: Run GPT-4o with (a) column name + values only, (b) + dataset description, (c) + all feature names. Measure Macro F1 delta on OpenML/Kaggle to quantify context contribution.
  2. **Test smaller local LLMs**: Replace GPT-4o with Llama-3-8B or Mistral-7B running on-premise. Compare accuracy degradation vs. privacy/compliance gain on MIMIC-Demo-Ext.
  3. **False negative mitigation**: Adjust classification threshold or modify prompt to emphasize "when in doubt, classify as personal." Measure FP/FN tradeoff shift on real-world datasets.

## Open Questions the Paper Calls Out

- Can smaller, locally-running Large Language Models (LLMs) achieve detection performance comparable to GPT-4o while mitigating the privacy and computational limitations of cloud-based processing?
- To what extent is the benchmark model CASSED's superior performance on the DeSSI dataset a result of overfitting to synthetic patterns rather than an ability to generalize to real-world data?
- What is the specific contribution of different contextual elements (dataset descriptions vs. neighboring feature names) to the detection accuracy of the GPT-4o model?

## Limitations
- Reliance on GPT-4o creates GDPR compliance risks by requiring sensitive data to be sent to external cloud services
- CASSED's severe overfitting to synthetic DeSSI data raises questions about synthetic data generation methodology
- Manual labeling protocol for evaluation datasets not provided, limiting confidence in ground truth quality

## Confidence
- **High Confidence**: GPT-4o outperforms CASSED and Presidio on real-world datasets (OpenML, Kaggle)
- **Medium Confidence**: Contextual information drives performance improvements
- **Low Confidence**: Explanation for CASSED's poor real-world performance is speculative

## Next Checks
1. Ablate contextual components from GPT-4o prompts to quantify each element's contribution to performance gains
2. Replace GPT-4o with local LLMs to evaluate accuracy-privacy tradeoff on medical data
3. Systematically vary classification thresholds to map false positive/false negative tradeoff space