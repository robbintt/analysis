---
ver: rpa2
title: 'LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation
  of Nonlinear Optimization Problems'
arxiv_id: '2510.15969'
source_url: https://arxiv.org/abs/2510.15969
tags:
- nonlinear
- linear
- problem
- reformulation
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems

## Quick Facts
- arXiv ID: 2510.15969
- Source URL: https://arxiv.org/abs/2510.15969
- Reference count: 34
- Primary result: 85.0% overall success rate (OSR) on ComplexOR-NL dataset using LLM agents for exact linearization

## Executive Summary
LinearizeLLM presents a multi-agent framework that uses large language models to automatically convert nonlinear optimization problems in LaTeX format into exact, solver-ready linear programs. The system decomposes the task into specialized agents for detection, structural ordering, reformulation, and verification, achieving an 85% success rate on a benchmark of 40 complex nonlinear problems. The architecture's key innovation is a bottom-up processing order based on dependency graphs, ensuring that nested nonlinearities are linearized in the correct sequence to avoid introducing spurious terms.

## Method Summary
The framework takes a nonlinear optimization problem in LaTeX as input and processes it through a pipeline of LLM agents. First, a detection agent identifies all nonlinear patterns (Π) and their nesting structure, producing a dependency graph. A deterministic structural policy then sorts these patterns by nesting depth in descending order to determine the linearization sequence. Type-specific reformulation agents (Φτ) apply exact linearization recipes (e.g., McCormick envelopes for bilinear terms, Charnes-Cooper for linear fractional terms) to replace each pattern with linear constraints. Finally, a code generation agent converts the linearized LaTeX model into executable Python code for Gurobi, and a verifier checks that the optimal objective matches the original within a tolerance of 10⁻⁴. The entire system uses Gemini 2.5 Flash with specific hyperparameters and evaluates success using an Overall Success Rate metric.

## Key Results
- 85.0% overall success rate (OSR) on the ComplexOR-NL dataset
- Component metrics: Detection Success Rate (DSR) 95.0%, Reformulation Success Rate (RSR) 96.7%, Compilation Success Rate (CSR) 100%
- Significant improvement over direct linearization approaches, particularly for deeply nested nonlinearities

## Why This Works (Mechanism)
The system succeeds by decomposing a complex symbolic reasoning task into specialized agents that can each focus on their strengths. The detection agent handles pattern recognition and dependency graph construction, the structural policy provides deterministic ordering based on mathematical principles, and the reformulation agents apply exact linearization techniques from optimization theory. This decomposition prevents the cognitive overload that would occur if a single LLM tried to handle detection, ordering, and reformulation simultaneously. The bottom-up processing order ensures that nested terms are linearized before they are used in outer expressions, preventing the introduction of spurious nonlinearities that would compromise equivalence.

## Foundational Learning
- **Mixed-Integer Linear Programming (MILP) and Exact Linearization**
  - Why needed here: The entire system is built to convert nonlinear problems into MILPs. You must understand the difference between linear, nonlinear, and mixed-integer problems, and why exact reformulation (introducing auxiliary variables and linear constraints to maintain equivalence) is preferred over approximation.
  - Quick check question: How would you linearize the constraint `z = x * y` where `x` is a binary variable (0 or 1) and `y` is a continuous variable in the range `[L, U]`?

- **Big-M Method**
  - Why needed here: This is a core technique for reformulating logical conditions and discrete-continuous products (like `x * y` above) into linear constraints. The correct choice of `M` is critical for model tightness and avoiding numerical issues.
  - Quick check question: In the Big-M formulation for `z <= x * y` (where x is binary), what constraint ensures `z <= y` when `x=1` and `z <= 0` when `x=0`?

- **Dependency Graphs and Bottom-Up Processing**
  - Why needed here: The core algorithmic innovation is the structural policy that determines processing order. Understanding why you must process `x*y` before `max(0, x*y)` is key to implementing the agent orchestration correctly.
  - Quick check question: For the expression `log(max(0, x*y))`, what is the dependency graph and what is the correct bottom-up order for reformulation?

## Architecture Onboarding
- **Component map**: Detection Agent -> Structural Policy -> Loop: Reformulation Agents -> Code Generation -> Verifier
- **Critical path**: `Input LaTeX -> Detection Agent -> Structural Policy -> Loop: Reformulation Agents -> Code Generation -> Verifier`. The iterative loop between the structural policy and reformulation agents is the engine of the system.
- **Design tradeoffs**: The choice of a fixed set of supported patterns (e.g., absolute value, bilinear) makes the problem tractable but limits generality. The reliance on a solver-based OSR metric validates correctness but does not formally prove equivalence of the solution set.
- **Failure signatures**:
    - Detection Failure (Low DSR): The LLM misses a nested term or misclassifies a parameter as a variable. *Check:* Detection prompt and context provided.
    - Reformulation Failure (Low RSR): The specialized agent generates an incorrect or incomplete set of linear constraints. *Check:* Reformulation prompt for that specific pattern type.
    - Compilation Failure (Low CSR): The final LaTeX model is syntactically incorrect or the code generation step fails. *Check:* LaTeX output and code generation prompts.
    - Verification Failure (Low OSR): The solver reports an infeasible or unbounded model, or the optimal objective value doesn't match the reference. *Check:* The Big-M values, variable bounds, and any monotone objective transformations.
- **First 3 experiments**:
  1. Ablate the architectural components. Replace the multi-agent system with a single "one-shot" agent to quantify the value of the decomposition. Compare OSR on problems of varying nesting depth.
  2. Ablate the context. Run the full pipeline while systematically withholding parts of the context (parameter names, values, variable definitions) to confirm that numerical grounding is critical for reformulation success.
  3. Test perturbation robustness. Apply the defined LaTeX perturbations (L1-L4) to the input to test the resilience of the detection agent and the overall system to syntactic noise.

## Open Questions the Paper Calls Out
- **Open Question 1**: Can the agent-based architecture be reliably extended to generate valid inexact linearizations (e.g., McCormick envelopes) for general non-convex terms where exact reformulation is impossible?
- **Open Question 2**: How does the LinearizeLLM pipeline perform when instantiated with diverse backend LLMs, particularly open-source models?
- **Open Question 3**: Is empirical optimal objective value matching (OSR) sufficient to validate correctness, or is formal proof of argmin-set equivalence required for safety-critical applications?

## Limitations
- **Dataset accessibility**: The ComplexOR-NL dataset (40 instances with LaTeX formulations, parameter values, and reference solutions) is described but not publicly available, creating a primary reproducibility barrier.
- **Verification assumptions**: OSR metric relies on reference objective values that are not provided; reproducing exact equivalence validation would require re-solving the original NLPs or obtaining reference solutions.
- **Pattern limitations**: The system is designed for a fixed pattern set; performance on unseen nonlinearities or different nesting structures remains untested.

## Confidence
- **High confidence** in the architectural design: The multi-agent decomposition into detection, structural policy, reformulation, and verification is clearly specified and grounded in established MILP linearization theory.
- **Medium confidence** in the evaluation claims: The OSR metric is well-defined, but results depend on the hidden reference solutions and specific LLM behavior under the stated hyperparameters.
- **Low confidence** in general applicability: The system is designed for a fixed pattern set; performance on unseen nonlinearities or different nesting structures remains untested.

## Next Checks
1. **Dataset reconstruction**: Obtain or recreate the ComplexOR-NL instances with full LaTeX formulations, parameter contexts, and reference objective values to enable independent validation.
2. **Ablation study replication**: Replace the multi-agent pipeline with a single "one-shot" LLM agent to quantify the contribution of the structural policy and specialized reformulation agents across varying nesting depths.
3. **Perturbation robustness test**: Apply the defined LaTeX perturbations (L1-L4) to input models and verify that the detection agent maintains performance, confirming resilience to syntactic noise.