---
ver: rpa2
title: 'Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms:
  Introducing the PNGT-26K Dataset'
arxiv_id: '2509.11136'
source_url: https://arxiv.org/abs/2509.11136
tags:
- gender
- names
- persian
- name
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenges of Persian name processing
  in natural language applications, particularly gender detection and username generation,
  due to transliteration inconsistencies and cultural-specific patterns. The authors
  introduce PNGT-26K, a comprehensive dataset of approximately 26,000 Persian names
  with gender associations and English transliterations, systematically curated to
  address the transliteration bottleneck.
---

# Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset

## Quick Facts
- **arXiv ID:** 2509.11136
- **Source URL:** https://arxiv.org/abs/2509.11136
- **Reference count:** 36
- **One-line primary result:** PNGT-26K dataset + Open Gender Detection + Nominalist frameworks for Persian names

## Executive Summary
This paper addresses the challenges of Persian name processing in natural language applications, particularly gender detection and username generation, due to transliteration inconsistencies and cultural-specific patterns. The authors introduce PNGT-26K, a comprehensive dataset of approximately 26,000 Persian names with gender associations and English transliterations, systematically curated to address the transliteration bottleneck. They also present two frameworks: Open Gender Detection, a multimodal probabilistic framework combining name-based and image-based inference for gender prediction, and Nominalist, an agentic AI framework for intelligent username generation that leverages cultural awareness and personalization. The frameworks demonstrate effective performance, with PNGT-26K providing a foundation for developing culturally-aware NLP applications, while Open Gender Detection and Nominalist offer practical solutions for gender detection and username generation, respectively.

## Method Summary
The paper presents PNGT-26K, a Persian name dataset created by merging three existing sources and applying Unicode normalization, LLM validation for transliteration errors, and manual review. Open Gender Detection uses a fusion of name-based inference (Levenshtein distance on PNGT-26K) and image-based inference (CLIP embeddings + SVM classifier) with weighted voting. Nominalist employs a two-agent architecture where a CreatorAgent generates username candidates using rules and LLM inference, while a ReviewerAgent filters and ranks them based on heuristics and uniqueness checks.

## Key Results
- PNGT-26K dataset of ~26K Persian names with gender labels and English transliterations
- Open Gender Detection framework achieves probabilistic gender predictions through multimodal fusion
- Nominalist agentic framework generates culturally-aware usernames using decoupled creator/reviewer agents

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Combining name-based string matching with image-based classification creates a more robust gender prediction system than single-modality approaches for Persian identities.
- **Mechanism:** The "Open Gender Detection" framework implements a fusion logic where name inference (via Levenshtein distance on the PNGT-26K dataset) acts as the primary signal. If name confidence is low, or to confirm high confidence, an image classifier (SVM on CLIP embeddings) validates the prediction using a weighted voting scheme.
- **Core assumption:** The system assumes that the "transliteration bottleneck" causing errors in text analysis can be compensated for by visual signals, and that profile pictures validly represent the user's gender.
- **Evidence anchors:**
  - [abstract]: "Open Gender Detection... combines name-based and image-based inference to provide probabilistic gender predictions."
  - [section 3.2.1, p.4]: "result of the two modules is placed in a vote box, and the fusion logic is applied... to return the final probabilistic guess."
  - [corpus]: Corpus signals (e.g., "MuSeD: A Multimodal Spanish Dataset") support the general efficacy of multimodal detection in social contexts, but do not validate this specific Persian fusion method.
- **Break condition:** If profile pictures are non-human (logos, landscapes) or culturally ambiguous, the image module fails, potentially degrading the fusion result if weights are not tuned to prioritize the name-module during low-confidence visual inputs.

### Mechanism 2
- **Claim:** A multi-agent architecture separating generation (Creator) from evaluation (Reviewer) yields higher quality, culturally relevant usernames than single-pass generative models.
- **Mechanism:** The "Nominalist" framework decouples the task. The CreatorAgent uses deterministic rules (e.g., underscore insertion) and LLM inference to generate candidates. The ReviewerAgent then filters these against heuristics (length, memorability) and an existing username database to score and rank the output.
- **Core assumption:** This mechanism assumes that constraint satisfaction (availability, readability) is best handled by a distinct evaluator agent rather than prompt constraints alone, and that LLMs can inherently understand "cultural awareness" if provided with a name's context.
- **Evidence anchors:**
  - [abstract]: "Nominalist... utilizes agentic AI to help users choose a username... leverages cultural awareness and personalization."
  - [section 3.3.1, p.6]: "The system is composed of two agents, a creator and a reviewer agent... [reviewer] assesses its input for uniqueness, validity, and desirability."
  - [corpus]: Corpus is weak regarding specific agent architectures for usernames; however, "Presumed Cultural Identity" supports the premise that names carry cultural signals LLMs can process.
- **Break condition:** If the ReviewerAgent's heuristics are too generic, they may filter out culturally specific but valid username patterns (e.g., longer compound names common in Persian), causing false negatives.

### Mechanism 3
- **Claim:** Curating a dataset via LLM-assisted validation and Unicode normalization mitigates the "transliteration bottleneck" better than simple aggregation.
- **Mechanism:** The authors use the Hazm library for character-level normalization (unifying Arabic/Persian variants like 'yeh'/'kaf') and employ a local LLM (DeepSeek-R1) to flag misspellings or incorrect transliterations in the compiled dataset, followed by human review.
- **Core assumption:** This relies on the assumption that LLMs have sufficient "knowledge" of Persian naming conventions to act as a preliminary validity filter, reducing manual labor without introducing model hallucinations.
- **Evidence anchors:**
  - [abstract]: "PNGT-26K... systematically curated to address the transliteration bottleneck."
  - [section 3.1.3, p.4]: "employed a local instance of DeepSeek-R1... to label entries that may have been transliterated incorrectly... aligned with previous studies... achieving near-human performance."
  - [corpus]: "Leveraging Online Data to Enhance Medical Knowledge in a Small Persian Language Model" suggests LLMs can be adapted for Persian, but does not prove their efficacy as data cleaners.
- **Break condition:** If the LLM used for cleaning is biased against rare or regional name variants, it may flag valid entries as errors ("misspellings"), shrinking the dataset's diversity.

## Foundational Learning

- **Concept: Unicode Normalization (i18n)**
  - **Why needed here:** Persian text processing is plagued by "one-to-many" character representations (e.g., Arabic 'kaf' vs. Persian 'kaf'). Without normalization (Section 3.1.2), the dataset would contain duplicate entries for the same visual name, breaking lookup accuracy.
  - **Quick check question:** If you search the dataset for "Mohammad" written with Arabic 'yeh' but the dataset stores it with Persian 'yeh', does the lookup fail?

- **Concept: Levenshtein Distance**
  - **Why needed here:** The Name-Based Inference Model (Section 3.2.2) uses *normalized* Levenshtein distance to map user inputs (which may contain typos or non-standard transliterations) to the curated dataset entries.
  - **Quick check question:** Why is the distance *normalized* by the string length, rather than using the raw edit count, when comparing short vs. long names?

- **Concept: CLIP Embeddings**
  - **Why needed here:** The Image-Based Inference Model (Section 3.2.3) moves beyond simple CNNs by using CLIP embeddings, which align images and text in a shared space, allowing the system to handle diverse profile pictures (cartoons, photos) more robustly.
  - **Quick check question:** Why does the framework train an SVM on top of CLIP embeddings rather than using pure zero-shot classification with prompts like "a photo of a man"?

## Architecture Onboarding

- **Component map:**
  - **PNGT-26K:** The data layer; Persian Name + Gender + English Transliteration.
  - **Open Gender Detection:** Python framework. Input: Name/String + Image. Logic: `NameService` (Levenshtein lookup) + `ImageService` (CLIP+SVM) -> `Fusion` (Weighted Vote).
  - **Nominalist:** Agentic framework. Input: Name + Preferences. Logic: `CreatorAgent` (Rules + LLM) -> `ReviewerAgent` (Heuristics + Uniqueness Check) -> Ranked List.

- **Critical path:**
  - For Gender Detection: `Input Name` -> `Normalizer` -> `Levenshtein Search (k=5)` -> `Probability Score`. If score < threshold -> `Invoke Image Module` -> `Fusion`.
  - For Usernames: `Input Name` -> `NameService` (Get English variant) -> `CreatorAgent` (Generate 12 candidates) -> `ReviewerAgent` (Filter/Score) -> `Top K Output`.

- **Design tradeoffs:**
  - **Determinism vs. Creativity:** The CreatorAgent uses a temperature of 0.8 for LLM generation (creative) but the ReviewerAgent uses 0.3 (consistent ranking).
  - **Latency vs. Accuracy:** The fusion logic prioritizes the Name-Based module (fast lookup) and only invokes the Image-Based module (slower inference) if confidence is low.

- **Failure signatures:**
  - **Low Confidence Fusion:** Occurs when Name-module returns low probability (uncommon name) AND Image-module returns low probability (non-human image or ambiguous features).
  - **Reviewer Over-filtering:** The ReviewerAgent might reject all candidates if the "existing usernames database" is not populated or if regex constraints are too strict for non-English name structures.

- **First 3 experiments:**
  1. **Unit Test Name Normalization:** Input 100 variations of "Mohammad" with mixed Arabic/Persian characters and verify they all map to the single normalized entry in PNGT-26K.
  2. **Fusion Sensitivity Analysis:** Run the Open Gender Detection on a test set where you force the Name-module confidence to be "low" and measure the performance shift when relying solely on the Image-module vs. the Weighted Fusion.
  3. **Agent Diversity Check:** Run Nominalist 50 times for the same input name and measure the cosine similarity of the output lists to verify if the CreatorAgent is actually utilizing the temperature setting for diversity or collapsing to repetitive patterns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can transliteration standardization methods be refined to systematically resolve the one-to-many mapping problem inherent in Persian names?
- Basis in paper: [explicit] The conclusion states that future work should focus on "developing more sophisticated transliteration standardization methods."
- Why unresolved: The "transliteration bottleneck" currently fragments digital identity, and the PNGT-26K dataset aggregates existing variants rather than imposing a new standard.
- What evidence would resolve it: A proposed mapping algorithm that reduces variant spellings in a hold-out set of academic or social media databases.

### Open Question 2
- Question: To what extent does incorporating regional naming variations within Persian-speaking communities affect the robustness of gender detection systems?
- Basis in paper: [explicit] The authors explicitly identify "expanding the dataset to include regional variations within Persian-speaking communities" as a direction for future research.
- Why unresolved: The current dataset aggregates names from various sources without stratifying them by specific regions or dialects, potentially masking local nuances.
- What evidence would resolve it: Performance benchmarks of the Open Gender Detection framework when trained on region-specific subsets compared to the aggregated dataset.

### Open Question 3
- Question: Can the integration of semantic gender cues alongside morphological patterns significantly improve gender detection accuracy beyond the current multimodal approach?
- Basis in paper: [explicit] The paper suggests "exploring the integration of semantic gender cues alongside morphological patterns could further improve gender detection accuracy."
- Why unresolved: The current Open Gender Detection framework relies primarily on string distance (morphology) and visual features, omitting the semantic meaning of names.
- What evidence would resolve it: A comparative study evaluating the performance of a semantic-augmented model against the current name-based inference baseline.

## Limitations
- **Limited validation data:** The 160K profile pictures for image-based training are not publicly available, making independent validation difficult
- **Cultural bias assumptions:** Claims about "cultural awareness" in username generation lack rigorous validation with native Persian speakers
- **Threshold sensitivity:** The name-based inference confidence threshold is not specified, potentially causing brittle fusion behavior

## Confidence
- **High Confidence:** PNGT-26K dataset construction methodology (Unicode normalization, LLM validation, manual review) is technically sound
- **Medium Confidence:** Fusion approach for gender detection (name + image) is methodologically reasonable but lacks detailed justification
- **Low Confidence:** Claims about Nominalist's "cultural awareness" and ability to generate contextually appropriate usernames are weakly supported

## Next Checks
1. **Dataset Diversity Audit:** Analyze PNGT-26K for geographic and socioeconomic representation gaps by cross-referencing name origins with Persian dialect databases. Check whether the LLM validation disproportionately flagged regional name variants as "errors."
2. **Fusion Robustness Testing:** Systematically evaluate Open Gender Detection performance when the name module receives low-confidence inputs (uncommon names, heavy transliteration) versus when the image module receives non-human inputs (logos, landscapes). Measure performance degradation patterns.
3. **Username Generation Cultural Validation:** Conduct user studies with native Persian speakers to evaluate whether Nominalist's top-ranked usernames align with actual Persian naming preferences and avoid unintended cultural associations or taboos.