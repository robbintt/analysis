---
ver: rpa2
title: An Edge AI Solution for Space Object Detection
arxiv_id: '2505.13468'
source_url: https://arxiv.org/abs/2505.13468
tags:
- detection
- space
- gelan-vit-se
- edge
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an Edge AI solution for real-time space object
  detection (SOD) to enhance space safety and sustainability. The authors propose
  a hybrid deep learning model, GELAN-ViT-SE, that integrates convolutional neural
  networks (CNNs), Vision Transformers (ViTs), and Squeeze-and-Excitation (SE) blocks
  within the YOLOv9 framework to improve satellite detection accuracy while maintaining
  low computational complexity.
---

# An Edge AI Solution for Space Object Detection

## Quick Facts
- arXiv ID: 2505.13468
- Source URL: https://arxiv.org/abs/2505.13468
- Authors: Wenxuan Zhang; Peng Hu
- Reference count: 5
- One-line result: Edge-optimized hybrid CNN-ViT-SE model achieves 0.751 mAP50 for LEO satellite detection on Jetson Orin Nano

## Executive Summary
This paper presents GELAN-ViT-SE, an edge AI solution for real-time space object detection (SOD) to enhance space safety and sustainability. The authors propose a hybrid deep learning model integrating convolutional neural networks (CNNs), Vision Transformers (ViTs), and Squeeze-and-Excitation (SE) blocks within the YOLOv9 framework to improve satellite detection accuracy while maintaining low computational complexity. The model incorporates channel-wise attention mechanisms through SE blocks to enhance feature extraction for detecting multiple satellites in Low Earth Orbit (LEO). To support this research, the authors introduce the SODv2 dataset, which simulates realistic LEO satellite environments with accurate celestial modeling and annotated satellite detections.

## Method Summary
The authors developed GELAN-ViT-SE by integrating CNN, ViT, and SE blocks within the YOLOv9 detection framework. The model uses a GELAN backbone with layer aggregation for gradient efficiency, applies ViT tokenization with positional embeddings for long-range dependency modeling, and incorporates SE blocks at the last two detection heads to recalibrate channel-wise feature importance. Training was performed on the SODv2 dataset (600 images, 450 training, 150 testing) using Tesla V100-SXM2-32GB with batch size 16 for 1000 epochs. Inference was evaluated on NVIDIA Jetson Orin Nano with batch size 1, measuring accuracy metrics (mAP50, mAP50:95) alongside edge performance metrics (inference time, memory usage, power consumption).

## Key Results
- GELAN-ViT-SE achieves mAP50 of 0.751 and mAP50:95 of 0.274 on 150 test images
- Inference time of 58.88 ms with 2.557 GB peak memory usage on Jetson Orin Nano
- Power consumption of 2028.7 mW while maintaining stable detection performance
- Outperforms baseline GELAN-t model (0.721 mAP50) and GELAN-ViT (0.737 mAP50)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Channel-wise attention via SE blocks improves satellite detection accuracy without increasing computational cost.
- **Mechanism:** The SE block applies global average pooling to compute a channel descriptor $s_c$, which passes through two fully connected layers to generate attention weights $z_c$. These weights are applied element-wise to recalibrate feature channels—amplifying informative channels and suppressing less useful ones before final detection.
- **Core assumption:** Satellite features in LEO imagery have unequal per-channel importance; recalibrating these improves signal-to-noise ratio for detection.
- **Evidence anchors:**
  - [abstract] "The model incorporates channel-wise attention mechanisms through SE blocks to enhance feature extraction for detecting multiple satellites"
  - [section IV, Table I] GELAN-ViT-SE achieves mAP50=0.751 vs. GELAN-ViT at 0.737, both at 5.6 GFLOPs
  - [corpus] Weak direct corroboration; neighbor papers focus on salient object detection (SOD) in terrestrial contexts, not space-specific attention mechanisms
- **Break condition:** If satellite features across channels are uniformly important (e.g., in high-contrast, low-noise imagery), SE-based recalibration provides diminishing returns.

### Mechanism 2
- **Claim:** Hybrid CNN-ViT architecture captures both local edge/texture features and long-range spatial dependencies, improving detection over CNN-only baselines.
- **Mechanism:** The CNN path processes local convolutions efficiently; the ViT path tokenizes patches with positional embeddings, enabling self-attention across distant image regions. Both paths feed detection heads.
- **Core assumption:** Small satellites in LEO imagery require both fine-grained local detail and global context to distinguish from noise/debris.
- **Evidence anchors:**
  - [section I] "models based on CNN often struggle with small object detection due to their limited contextual awareness, while Vision Transformers improve long-range dependency modeling"
  - [section IV, Table I] GELAN-ViT (0.737 mAP50) outperforms GELAN-t (0.721) with lower GFLOPs (5.6 vs 7.3)
  - [corpus] LEAF-Mamba (arXiv:2509.18683) similarly addresses CNN receptive field limitations using state-space models for SOD
- **Break condition:** If computational budget is extremely constrained (<50ms latency strict), the ViT path overhead may outweigh accuracy gains.

### Mechanism 3
- **Claim:** Edge-optimized inference is achieved through architecture efficiency, not model compression, maintaining stable latency and power on embedded hardware.
- **Mechanism:** GELAN's layer aggregation design enables gradient-efficient training and inference without requiring post-hoc quantization or pruning. The model runs directly on Jetson Orin Nano with batch-size-1 inference.
- **Core assumption:** Onboard satellite processors have limited memory (<4GB) and power budgets (~2W), requiring architectures designed for efficiency from inception.
- **Evidence anchors:**
  - [section IV] "inference speed and power consumption were evaluated using a batch size of 1" with GELAN-ViT-SE at 58.88ms, 2.557GB RAM, 2028.7mW
  - [section IV, Table II] All three models maintain <60ms inference and <2.6GB RAM on Jetson Orin Nano
  - [corpus] TOFFE (arXiv:2501.12482) addresses similar edge constraints for high-speed object detection on resource-limited robots
- **Break condition:** If deployment requires sub-30ms latency (e.g., high-speed maneuvering), these models would need additional optimization (pruning/quantization) not explored in this work.

## Foundational Learning

- **Concept: Squeeze-and-Excitation (SE) Blocks**
  - **Why needed here:** The paper's primary contribution is integrating SE blocks into YOLOv9's detection heads. You must understand how global pooling → FC layers → sigmoid produces channel-wise gating.
  - **Quick check question:** Given a 256-channel feature map, what is the dimensionality of the SE block's intermediate representation if the reduction ratio is 16?

- **Concept: Vision Transformer (ViT) Tokenization**
  - **Why needed here:** The hybrid architecture routes features through a ViT encoder. Understanding patch embedding and positional encoding is essential for debugging the dual-path design.
  - **Quick check question:** How does the CLS token aggregate global information in a ViT encoder?

- **Concept: YOLO Detection Heads**
  - **Why needed here:** The GELAN-ViT-SE modifies the last two detection heads. You need to understand how multi-scale heads predict bounding boxes at different resolutions.
  - **Quick check question:** Why does YOLO use multiple detection heads at different feature map scales?

## Architecture Onboarding

- **Component map:**
  Input Image -> Backbone (GELAN conv blocks) -> CNN Path (RepNCSPELAN4) -> Feature Concatenation -> Detection Heads (3 scales) -> Bounding Box + Class Output
                            -> ViT Path (Patch Embed -> Pos Embed -> ViT Encoder) -> Feature Concatenation

- **Critical path:** The SE blocks are applied only to the last two detection heads (RepNCSPELAN4_SE), not the backbone or first head. When debugging accuracy, focus on these modules first.

- **Design tradeoffs:**
  - GELAN-t: Fastest inference (46.14ms), lowest RAM (2.377GB), highest power (2080.7mW), lowest accuracy (0.721 mAP50)
  - GELAN-ViT-SE: Slowest inference (58.88ms), highest RAM (2.557GB), middle power (2028.7mW), highest accuracy (0.751 mAP50)
  - Assumption: The ~12ms latency increase from SE+ViT is acceptable for LEO collision avoidance (which typically operates on second-scale decision horizons).

- **Failure signatures:**
  - Low mAP50 but normal mAP50:95 → SE blocks may not be activating; check FC layer initialization
  - High memory spikes → ViT path not releasing intermediate tensors; verify gradient checkpointing
  - Inconsistent detections across runs → batch normalization mismatch; ensure eval mode during inference

- **First 3 experiments:**
  1. **Ablate SE blocks:** Replace RepNCSPELAN4_SE with standard RepNCSPELAN4 in detection heads to isolate SE contribution (expect ~1-2% mAP50 drop per paper's delta).
  2. **Vary SE reduction ratio:** Test reduction ratios of 8, 16, 32 to trade off accuracy vs. latency; paper uses default but doesn't explore this.
  3. **Cross-dataset validation:** Train on SODv2, test on real satellite imagery (if available) to assess sim-to-real gap—paper acknowledges this as future work.

## Open Questions the Paper Calls Out

### Open Question 1: Generalization Across Diverse Space Object Detection Scenarios
- Question: How does GELAN-ViT-SE perform on diverse datasets beyond the simulated SODv2 environment, such as real satellite imagery or different orbital regimes?
- Basis in paper: [explicit] "A future direction would be to expand the scope of experiments by testing on diverse datasets... to analyze the advantages of each model."
- Why unresolved: Evaluation is limited to one simulated LEO dataset with fixed parameters (500–600 km altitude, 45° FoV, 0–5 km detection range).
- What evidence would resolve it: Benchmark results on additional datasets including real captured imagery, different orbital configurations (MEO, GEO), and varying environmental conditions.

### Open Question 2: Optimal Hyperparameter Configurations
- Question: What hyperparameter settings (SE reduction ratios, batch sizes, SE block placement depth) maximize detection accuracy while preserving computational efficiency?
- Basis in paper: [explicit] "A future direction would be to... explore different hyperparameter configurations to analyze the advantages of each model."
- Why unresolved: The study uses fixed hyperparameters and applies SE blocks only to the last two detection heads without systematic ablation.
- What evidence would resolve it: Comprehensive ablation studies varying SE reduction ratios, testing SE placement across network depths, and grid search over training configurations.

### Open Question 3: Sim-to-Real Transfer Reliability
- Question: To what extent do models trained on the simulated SODv2 dataset transfer to real-world space imagery with actual sensor noise and lighting conditions?
- Basis in paper: [inferred] The SODv2 dataset is entirely simulated; no validation on real captured satellite imagery is presented.
- Why unresolved: Real-world factors—sensor artifacts, Earth albedo variations, eclipse conditions—may cause performance degradation not captured in simulation.
- What evidence would resolve it: Domain adaptation experiments comparing simulated-trained models against fine-tuned models on real satellite imagery, quantifying the sim-to-real gap.

### Open Question 4: Dataset Size Scalability
- Question: Does increasing training data beyond 450 images yield meaningful mAP improvements, or is current performance data-limited?
- Basis in paper: [inferred] The study uses only 600 total images, which is notably small for deep learning; no learning curves or data scaling analysis is provided.
- Why unresolved: It is unclear whether current mAP50 of 0.751 reflects model capacity limits or insufficient training data.
- What evidence would resolve it: Training experiments with progressively larger dataset sizes and analysis of mAP convergence trends.

## Limitations

- Limited validation on real satellite imagery—results are based entirely on synthetic SODv2 dataset with simulated LEO conditions
- No ablation study on SE reduction ratio hyperparameter, which could affect accuracy-latency tradeoff
- Hardware testing limited to single Jetson Orin Nano configuration without power-performance scaling analysis

## Confidence

- **High:** Edge deployment metrics (inference time, memory, power) on Jetson Orin Nano
- **Medium:** mAP50 improvement over baseline models on SODv2 dataset
- **Low:** Generalization to real-world satellite imagery and diverse orbital conditions

## Next Checks

1. **Sim-to-real transfer test:** Train GELAN-ViT-SE on SODv2, evaluate on real satellite imagery from different sensors to quantify domain gap
2. **SE hyperparameter sweep:** Systematically test reduction ratios (8, 16, 32) to identify optimal accuracy-latency tradeoff for different LEO altitudes
3. **Cross-sensor validation:** Evaluate model performance on synthetic data generated with different FoV angles, exposure settings, and noise profiles to assess robustness