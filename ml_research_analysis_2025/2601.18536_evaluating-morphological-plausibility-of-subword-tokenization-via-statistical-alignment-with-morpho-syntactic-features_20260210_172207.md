---
ver: rpa2
title: Evaluating Morphological Plausibility of Subword Tokenization via Statistical
  Alignment with Morpho-Syntactic Features
arxiv_id: '2601.18536'
source_url: https://arxiv.org/abs/2601.18536
tags:
- languages
- boundary
- morphological
- features
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel metric to evaluate morphological plausibility
  of subword tokenization by probabilistically aligning subwords with morpho-syntactic
  features using IBM Model 1. Unlike traditional metrics requiring gold morpheme segmentation,
  this approach leverages morpho-syntactic features from UniMorph, making it applicable
  to 169 languages.
---

# Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features

## Quick Facts
- arXiv ID: 2601.18536
- Source URL: https://arxiv.org/abs/2601.18536
- Reference count: 40
- Primary result: Alignment-based metric achieves 0.94-0.98 Spearman correlation with boundary recall for Czech tokenization

## Executive Summary
This paper introduces a novel evaluation metric for subword tokenization that measures morphological plausibility without requiring gold morpheme segmentation. The approach uses IBM Model 1 to probabilistically align subwords with morpho-syntactic features from the UniMorph database, making it applicable to 169 languages. Unlike traditional boundary-based metrics, this method leverages existing linguistic resources to evaluate whether tokenization preserves meaningful morphological distinctions. Experiments demonstrate strong correlations (0.94-0.98 Spearman) with traditional boundary recall metrics, particularly for morphologically rich languages, validating the approach's effectiveness.

## Method Summary
The method trains subword tokenizers (BPE, WordPiece, Unigram) on 1M sentences from CC100 per language, then aligns generated subwords to morpho-syntactic features using IBM Model 1 for 10 epochs. Alignment scores are computed using various aggregation functions (Sum, Mean, Min, Max, Log) with different feature representations (Joint vs Split). The Split representation, which separates morpho-syntactic features into individual components, generally yields higher correlations with traditional boundary metrics. The approach is evaluated across 10 diverse languages spanning different morphological systems, demonstrating its broad applicability without requiring language-specific gold segmentation.

## Key Results
- Spearman correlations of 0.94-0.98 with boundary recall for Czech tokenization
- Split feature representation consistently outperforms Joint representation across languages
- Strong performance across morphologically diverse languages (Finnish, Armenian, Kannada)
- Log aggregation function produces negative correlations as expected, while Mean/Sum/Max/Min yield positive recall correlations

## Why This Works (Mechanism)
The metric works by leveraging the inherent relationship between subword boundaries and morphological structure. When tokenizers split words at morpheme boundaries, the resulting subwords can be meaningfully aligned with morpho-syntactic features. IBM Model 1 captures these alignments by learning translation probabilities between subwords and features, effectively measuring how well the tokenization preserves morphological information. The approach succeeds because morphological features in UniMorph are systematically related to surface forms, allowing statistical alignment to detect when tokenization respects morphological structure even without explicit morpheme segmentation.

## Foundational Learning
- **IBM Model 1 statistical alignment**: Why needed - provides the core mechanism for aligning subwords to features without supervision. Quick check - verify alignment probabilities show clear peaks rather than uniform distributions.
- **Morpho-syntactic feature representation**: Why needed - UniMorph features encode the linguistic information that correlates with morphological structure. Quick check - ensure feature triples match the format in Table 1.
- **Subword tokenization algorithms**: Why needed - different algorithms (BPE, WordPiece, Unigram) have varying biases toward morphological boundaries. Quick check - verify tokenizer outputs for known morphological cases.
- **Spearman correlation**: Why needed - measures monotonic relationships between alignment scores and traditional metrics. Quick check - confirm correlation coefficients are within expected ranges for the dataset.

## Architecture Onboarding
- **Component map**: CC100 corpus -> Tokenizer training -> Subword generation -> IBM Model 1 alignment -> Alignment score computation -> Spearman correlation with boundary metrics
- **Critical path**: Tokenizer training and IBM Model 1 alignment are the most critical components; alignment quality directly determines metric validity
- **Design tradeoffs**: Split vs Joint feature representations - Split offers better correlations but increases computational complexity; Log aggregation vs others - Log provides negative correlation as expected but Mean/Sum/Max/Min are more interpretable for positive correlations
- **Failure signatures**: Low correlation with boundary recall indicates alignment quality issues; uniform alignment probability distributions suggest insufficient model convergence
- **First experiments**: 1) Train IBM Model 1 for 5, 10, 20, 50 epochs to verify correlation stabilization. 2) Test Split representation on morphologically simple vs complex languages to confirm performance differences. 3) Compare Mean vs Sum aggregation to identify which better captures alignment quality.

## Open Questions the Paper Calls Out
None

## Limitations
- IBM Model 1 implementation details are not fully specified, affecting reproducibility
- Mapping between Universal Segmentations and UniMorph features relies on manual curation without detailed procedure
- CC100 sentence sampling method not specified, potentially affecting tokenizer training consistency
- Limited evaluation to 10 languages, primarily from Indo-European and Uralic families

## Confidence
- Core methodological claim (alignment-based metric validity): Medium - strong correlations reported but implementation uncertainties exist
- Split representation superiority: High - consistently demonstrated across languages
- Generalization to unseen languages: Medium - tested on 10 languages but not cross-linguistically validated beyond this set

## Next Checks
1. **IBM Model 1 Convergence Validation**: Run alignment for varying epoch counts (5, 10, 20, 50) and verify correlation scores stabilize rather than continuing to improve.
2. **Cross-linguistic Robustness Test**: Apply methodology to at least two additional morphologically diverse languages not in original 10 (e.g., Arabic, Native American language) to test generalization.
3. **Feature Granularity Analysis**: Systematically vary feature granularity in Split representation to identify which morpho-syntactic features contribute most to alignment quality.