---
ver: rpa2
title: 'Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG
  Language Model'
arxiv_id: '2502.10707'
source_url: https://arxiv.org/abs/2502.10707
tags:
- learning
- signals
- words
- methods
- heartlang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HeartLang, a self-supervised learning framework
  for ECG language processing. It treats heartbeats as words and rhythms as sentences,
  introducing a QRS-Tokenizer to segment semantically meaningful ECG sentences and
  a ST-ECGFormer backbone network.
---

# Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model

## Quick Facts
- arXiv ID: 2502.10707
- Source URL: https://arxiv.org/abs/2502.10707
- Reference count: 35
- Primary result: Achieves 8.14 average AUC improvement over second-best eSSL methods on PTB-XL with 5,394-word ECG vocabulary

## Executive Summary
HeartLang introduces a self-supervised ECG language model that treats heartbeats as words and rhythms as sentences. The method employs a QRS-Tokenizer to segment ECG signals at heartbeat boundaries and a ST-ECGFormer backbone for representation learning. Through vector-quantized heartbeat reconstruction and masked ECG sentence pre-training, HeartLang learns both form-level and rhythm-level representations. The approach constructs the largest heartbeat-based ECG vocabulary to date (5,394 collective words) and demonstrates strong performance across six public ECG datasets, particularly excelling at capturing fine-grained morphological features.

## Method Summary
HeartLang is a self-supervised learning framework for ECG language processing that treats heartbeats as words and rhythms as sentences. It uses a QRS-Tokenizer to segment semantically meaningful ECG sentences by detecting QRS complexes via bandpass filtering (5-20 Hz) and moving wave integration. The ST-ECGFormer backbone learns representations through vector-quantized heartbeat reconstruction (VQ-HBR) and masked ECG sentence pre-training. The method constructs an ECG vocabulary of 5,394 collective words and achieves strong performance on six public ECG datasets, with 8.14 average AUC improvement over second-best eSSL methods on PTB-XL.

## Key Results
- Achieves 8.14 average AUC improvement over second-best eSSL methods on PTB-XL
- Constructs ECG vocabulary of 5,394 collective words, the largest to date
- Outperforms fixed-size window approaches by 5.36 average macro AUC on PTB-XL
- Maintains strong performance across 1%, 10%, and 100% data regimes on downstream tasks

## Why This Works (Mechanism)

### Mechanism 1: Semantically-Aligned Tokenization via QRS Complex Detection
Segmenting ECG signals at heartbeat boundaries preserves physiological semantics that fixed-window slicing destroys. The QRS-Tokenizer applies bandpass filtering, moving wave integration, and threshold-based peak detection to identify QRS complex indices, then segments each heartbeat using midpoints between adjacent peaks. This approach assumes QRS complexes reliably mark heartbeat boundaries across diverse cardiac conditions and heart rates.

### Mechanism 2: Vector-Quantized Heartbeat Reconstruction for Cross-Subject Generalization
Mapping individual ECG words to a shared discrete vocabulary via VQ enables learning form-level representations that generalize across subjects despite inter-individual physiological variation. The method quantizes heartbeat embeddings by finding nearest neighbors in a learned codebook (8192 entries, 128 dimensions) using cosine similarity, then decodes to reconstruct original ECG sentences via MSE loss.

### Mechanism 3: Masked ECG Sentence Pre-training for Rhythm-Level Representation Learning
Predicting masked collective ECG words from unmasked context learns rhythm-level representations that capture temporal dependencies across heartbeats. The model randomly masks individual words (50% ratio) and predicts their collective ECG word indices via a linear classifier over transformer outputs, using cross-entropy loss.

## Foundational Learning

- **QRS Complex Detection and ECG Morphology**
  - Why needed here: The entire HeartLang pipeline depends on accurate QRS detection to segment heartbeats. Misunderstanding what a QRS complex represents (ventricular depolarization) and how it appears in different conditions will lead to misinterpreting tokenization failures.
  - Quick check question: Given a 12-lead ECG with a wide QRS (>120ms), how would you explain why the QRS-Tokenizer might still correctly identify its peak but produce a semantically ambiguous token?

- **Vector Quantization and Codebook Learning**
  - Why needed here: VQ-HBR is central to form-level representation. Understanding the trade-offs between codebook size, commitment loss, and EMA updates is necessary to diagnose training instability or codebook underutilization.
  - Quick check question: If validation shows only 500 of 8192 codebook entries are actively used, what two hyperparameters would you investigate first?

- **Self-Supervised Pre-training Paradigms (Contrastive vs. Masked Reconstruction)**
  - Why needed here: HeartLang combines VQ-based reconstruction with masked prediction. Distinguishing why masked language modeling-style pre-training is chosen over contrastive learning for rhythm-level representation clarifies the design rationale.
  - Quick check question: Why might contrastive augmentation (e.g., random cropping, noise injection) be problematic for ECG semantic integrity compared to masked prediction?

## Architecture Onboarding

- **Component map:**
  1. **QRS-Tokenizer** (signal → ECG sentences): Bandpass filter → MWI → peak detection → heartbeat segmentation → 12-lead concatenation → padding/truncation to l=256, t=96
  2. **ST-ECGFormer Backbone**: 1-D conv token embedding → spatial embedding SE (12 learnable vectors) + temporal embedding TE (10 learnable vectors) + position embedding PE → pre-LN transformer encoder
  3. **VQ-HBR Module**: Encoder → codebook lookup (cosine similarity, ℓ2-normalized) → decoder → MSE reconstruction + commitment losses
  4. **Masked Pre-training Head**: Mask individual words (50% ratio) → encoder → linear classifier → predict collective word indices (cross-entropy loss)
  5. **Downstream Linear Probe**: Frozen encoder → linear classifier → macro AUC evaluation

- **Critical path:**
  1. Train VQ-HBR first to learn the ECG vocabulary on MIMIC-IV-ECG (800K recordings, 100 epochs, lr=5e-5, batch=512)
  2. Freeze codebook, then run masked pre-training (200 epochs, lr=5e-4, mask ratio=0.5)
  3. For downstream tasks, keep encoder frozen, train only linear classifier (1%/10%/100% data regimes, lr=5e-3, 100 epochs)

- **Design tradeoffs:**
  - **Fixed sentence length l=256 vs. dynamic:** Uniform length enables batch processing but requires padding for bradycardic recordings; truncation risks losing rhythm information for tachycardic recordings.
  - **Codebook size k=8192 vs. smaller:** Larger vocabulary captures finer morphological distinctions (Table 8 shows +1.29 to +4.54 AUC gain over k=64), but increases memory and risk of codebook underutilization.
  - **Mask ratio 50% vs. higher:** Lower ratio preserves more context for irregular rhythms; higher ratio increases pre-training difficulty but may over-regularize simple patterns.

- **Failure signatures:**
  - **Low codebook utilization** (<50% entries active): Indicates codebook collapse; check commitment loss weight and EMA decay rate.
  - **Reconstruction loss plateaus early with high error**: Suggests encoder-decoder capacity mismatch or inadequate token embedding dimension.
  - **Masked prediction accuracy >> downstream performance**: Traditional fixed-window slicing shows higher pre-training accuracy but worse downstream transfer (Section 5.2), indicating overfitting to simpler semantics.
  - **QRS detection failures on CPSC2018/CSN**: Paper attributes weaker results on these datasets to baseline drift disrupting QRS detection (Section 5.1).

- **First 3 experiments:**
  1. **VQ-HBR validation sanity check**: Train VQ-HBR on a 10% subset of MIMIC-IV-ECG; plot reconstruction loss curve and codebook utilization over time. Verify >60% codebook usage by epoch 50.
  2. **Ablation of QRS-Tokenization vs. Fixed Windows**: Pre-train and probe on PTB-XL Superclass using both segmentation strategies; replicate Table 2 to confirm ~5 AUC gap before full-scale training.
  3. **Mask ratio sensitivity**: Run masked pre-training with mask ratios [0.3, 0.5, 0.7] and evaluate linear probe on PTB-XL Rhythm subset; identify optimal ratio for rhythm-level tasks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the QRS-Tokenizer be refined to accurately represent cardiac conditions characterized by irregular or atypical QRS complexes?
- Basis in paper: [explicit] The authors state in Appendix B.3 that the tokenizer "may struggle to accurately represent these atypical patterns" (irregular QRS), leading to performance degradation.
- Why unresolved: The current method relies on standard QRS detection features which fail when the complex itself is the site of the pathology or irregularity.
- What evidence would resolve it: Evaluation of the updated tokenizer on datasets heavily composed of arrhythmias with irregular QRS morphologies (e.g., wide-complex tachycardias).

### Open Question 2
- Question: To what extent does the zero-padding strategy for short intervals degrade model performance on datasets with significant baseline drift?
- Basis in paper: [explicit] Appendix B.3 notes that padding intervals smaller than 96 with zeros "can partially disrupt the characteristics of heartbeats" when baselines deviate substantially from zero.
- Why unresolved: While identified as a cause for weaker performance on datasets like CPSC2018 and CSN, no alternative normalization or padding solution was implemented or tested.
- What evidence would resolve it: A comparative study analyzing performance on raw vs. baseline-corrected ECG signals, or the implementation of adaptive padding strategies.

### Open Question 3
- Question: Does the mapping of morphologically similar heartbeats to different "collective words" based on spatio-temporal context improve diagnostic specificity for subtle anomalies?
- Basis in paper: [inferred] Section 5.3 observes that similar heartbeats are mapped to different words (acting as different "parts of speech") based on context, but the paper does not verify if this semantic richness improves detection of specific clinical subtleties.
- Why unresolved: The visualization confirms the phenomenon occurs, but the clinical utility of this context-dependent splitting over pure morphological clustering is assumed rather than proven.
- What evidence would resolve it: Ablation studies isolating morphological features from spatio-temporal context features to determine their independent contributions to specific diagnostic tasks (e.g., distinguishing ischemic from non-ischemic ST changes).

## Limitations

- QRS detection generalization may fail on datasets with significant baseline wander or irregular QRS morphologies
- Codebook utilization shows only 66% of 8,192 entries are actively used, suggesting potential underutilization
- Fixed temporal window (t=96) may inadequately capture both bradycardic and tachycardic rhythms
- Single-scale temporal modeling without explicit multi-scale aggregation may poorly represent complex arrhythmias

## Confidence

**High Confidence**: VQ-HBR improves form-level representation (Mechanism 2). Strong ablation evidence (59.23→78.94 AUC on PTBXL-Super with 1% data) and clear reconstruction loss optimization support this claim.

**Medium Confidence**: QRS-Tokenizer preserves semantic integrity better than fixed windows (Mechanism 1). Evidence is primarily comparative (+5.36 AUC) but lacks direct validation of semantic preservation or failure mode analysis.

**Medium Confidence**: Masked pre-training learns rhythm-level representations (Mechanism 3). Ablation shows significant drops without pre-training (81.40→90.34 on PTBXL-Rhythm) but lacks comparison to alternative self-supervised objectives.

**Low Confidence**: The ECG vocabulary of 5,394 words is "the largest to date" and semantically meaningful. While the count is specified, semantic validation is weak—no direct comparison to alternative tokenization schemes or human-annotated semantic clusters.

## Next Checks

1. **QRS Detection Robustness Analysis**: Run QRS-Tokenizer on a subset of CPSC2018 with baseline wander; visualize detected QRS peaks against raw signal and compute detection F1-score. Compare downstream performance when using detected vs. ground-truth QRS indices.

2. **Codebook Utilization Dynamics**: During VQ-HBR training, plot (a) reconstruction loss vs. epoch, (b) number of active codebook entries vs. epoch, and (c) commitment loss vs. epoch. Identify whether utilization plateaus below 70% and adjust commitment loss weight accordingly.

3. **Temporal Window Sensitivity**: Evaluate linear probe performance on PTB-XL Rhythm subset using temporal windows t=[64, 96, 128] (0.64s, 0.96s, 1.28s). Plot AUC vs. temporal window length to identify optimal temporal resolution for rhythm-level tasks.