---
ver: rpa2
title: History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation
arxiv_id: '2512.14222'
source_url: https://arxiv.org/abs/2512.14222
tags:
- navigation
- wang
- target
- agent
- hett
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of aerial vision-and-language
  navigation (AVLN), where UAV agents must navigate large-scale urban environments
  using natural language instructions. The proposed History-Enhanced Two-Stage Transformer
  (HETT) framework integrates coarse-grained target prediction with fine-grained action
  refinement, using a historical grid map to maintain structured spatial memory.
---

# History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation

## Quick Facts
- **arXiv ID:** 2512.14222
- **Source URL:** https://arxiv.org/abs/2512.14222
- **Reference count:** 5
- **Primary result:** HETT achieves 14.16%, 10.75%, and 18.00% improvement in success rate across validation and test sets compared to state-of-the-art methods.

## Executive Summary
This paper addresses aerial vision-and-language navigation (AVLN) where UAV agents must navigate large-scale urban environments using natural language instructions. The proposed History-Enhanced Two-Stage Transformer (HETT) framework integrates coarse-grained target prediction with fine-grained action refinement, using a historical grid map to maintain structured spatial memory. Experiments on the CityNav benchmark show HETT achieves significant improvements in success rate across validation and test sets compared to state-of-the-art methods. The authors also refine dataset annotations, which further improves performance metrics.

## Method Summary
The HETT framework operates in two stages: first predicting coarse-grained target positions using global landmarks and a historical grid map, then refining actions via fine-grained visual analysis for precise navigation. The historical grid map dynamically aggregates visual features into a structured spatial memory, preserving navigational context better than sequential memory tokens. The model is trained using DAgger to mimic expert trajectories, with a linear combination of target prediction, action, and progress losses. The architecture uses pretrained Darknet-53 for visual features and implements a 5×5 grid for historical memory.

## Key Results
- HETT achieves 14.16%, 10.75%, and 18.00% improvement in success rate across validation and test sets compared to state-of-the-art methods
- Refined dataset annotations increase success rate from 19.42% to 31.09% on validation-seen and from 9.84% to 19.10% on validation-unseen
- Optimal grid size is 5×5, with larger grids (7×7) introducing noise and reducing performance

## Why This Works (Mechanism)

### Mechanism 1: Coarse-to-Fine Navigation Decomposition
- **Claim:** Decomposing navigation into global target prediction followed by local action refinement appears to improve success rates in large-scale urban environments compared to mono-granularity approaches.
- **Mechanism:** The system first predicts a normalized global coordinate $g_t$ using high-level landmarks and a coarse historical map (Eq. 2-3). Once near this region, it switches to fine-grained refinement, predicting a turning angle $a_t$ and progress indicator $r_t$ based on local visual features (Eq. 6-7).
- **Core assumption:** The optimal navigation strategy requires distinct computational modes for long-range reasoning (global) versus precise localization (local), rather than a unified policy.
- **Evidence anchors:**
  - [abstract] "HETT first predicts coarse-grained target positions... then refines actions via fine-grained visual analysis."
  - [section] Page 4, "Two-Stage Transformer Framework" describes the separation of stages.
  - [corpus] "FlightGPT" identifies generalization and multimodal fusion as key challenges in UAV VLN; the two-stage split may address this by isolating fusion tasks.
- **Break condition:** Performance degrades if the coarse stage prediction is highly inaccurate (large NE), as the fine-grained stage operates primarily on local observations and may lack the context to correct large errors.

### Mechanism 2: Spatially-Structured Historical Memory
- **Claim:** Maintaining a fixed-size grid map for history may preserve navigational context better than sequential memory tokens in long trajectories.
- **Mechanism:** Visual features are aggregated into a Historical Grid Map $M_H$ based on spatial coordinates (Eq. 8). Features within each cell are weighted by relevance to the instruction via attention (Eq. 10-11), creating a spatially-indexed memory $F_t$ rather than a purely sequential one.
- **Core assumption:** Spatial proximity correlates with semantic relevance for navigation cues, and discretizing the environment into a $5 \times 5$ or similar grid retains sufficient geometric precision.
- **Evidence anchors:**
  - [abstract] "...historical grid map is designed to dynamically aggregate visual features into a structured spatial memory..."
  - [section] Page 5, Table 5 shows $5 \times 5$ grid size optimizes performance, while larger ($7 \times 7$) introduces noise.
  - [corpus] "LongFly" also emphasizes spatiotemporal context integration, suggesting spatial memory is a critical mechanism for long-horizon tasks.
- **Break condition:** If the environment requires sub-meter precision over vast distances, the fixed grid resolution may alias critical features, leading to localization failure.

### Mechanism 3: Data Quality Enhancement (Noise Reduction)
- **Claim:** Manual correction of LLM-generated landmark annotations significantly boosts model reliability and convergence.
- **Mechanism:** The authors identified and corrected "Missing" and "Major" landmark extraction errors in the CityNav dataset (Table 1). This ensures the landmark priors $L$ (Eq. 1) provided to the model during training are grounded in reality.
- **Core assumption:** The performance ceiling in AVLN is currently constrained by label noise rather than model capacity or architectural limitations.
- **Evidence anchors:**
  - [abstract] "CityNav dataset annotations are manually refined... SR increasing from 19.42% to 31.09%."
  - [section] Page 3, Figure 2 and Table 1 quantify the specific error types in the original data.
  - [corpus] "AirNav" highlights the lack of naturalness/diversity in existing datasets, supporting the need for higher quality supervision signals.
- **Break condition:** If applied to a dataset with human-curated annotations, this mechanism offers diminishing returns.

## Foundational Learning

- **Concept: Cross-Modal Attention (Transformer)**
  - **Why needed here:** The model fuses text instructions with visual observations using multi-layer transformers (MLT).
  - **Quick check question:** Can you explain how Query, Key, and Value matrices interact to weigh visual features against text tokens?

- **Concept: Aerial VLN (Vision-and-Language Navigation)**
  - **Why needed here:** Unlike indoor VLN, this involves 6-DoF movement, larger scales, and continuous action spaces.
  - **Quick check question:** What distinguishes a "goal-oriented" instruction from a "step-by-step" instruction, and which does this paper address?

- **Concept: Imitation Learning (DAgger)**
  - **Why needed here:** The model is trained using DAgger to mimic expert trajectories.
  - **Quick check question:** Why does purely offline behavioral cloning often fail in interactive navigation tasks?

## Architecture Onboarding

- **Component map:**
  1. RGB-D Observation ($O_t$) -> Visual Encoder (Darknet-53) -> Visual Features ($V_t$)
  2. Text Instruction ($E$) -> Text Encoder (BERT/Transformer) -> Text Features
  3. Pose ($P_t$) -> MLP -> Pose Features
  4. Landmark Priors ($M_L$) -> MLP -> Landmark Features ($L$)
  5. Historical Grid Map ($F_t$) -> Grid-based Feature Aggregation
  6. Multi-Layer Transformer (MLT) -> Fused Features
  7. Output Heads -> Target Predictor ($g_t$), Action Estimator ($a_t$), Progress Estimator ($r_t$)

- **Critical path:**
  1. Encode visual observation ($V_t$).
  2. Update Historical Grid Map ($F_t$) using coordinates.
  3. Fuse $[E; L; F_t; V_t; P_t]$ via Transformer.
  4. Output coordinates (Stage 1) or heading/stop (Stage 2).

- **Design tradeoffs:**
  - **Grid Size ($S_H$):** Paper uses $5 \times 5$. Increasing to $7 \times 7$ reduced performance (Table 5) likely due to feature sparsity/noise.
  - **Pre-reliance:** The model relies on pre-defined landmark polygons (CityRefer); it does not detect landmarks from raw pixels end-to-end.

- **Failure signatures:**
  - **Target Drift:** In Stage 1, if landmarks are misidentified, the agent may converge to the wrong region (Fig. 4).
  - **Premature Stopping:** If progress indicator $r_t$ saturates early due to visual aliasing.

- **First 3 experiments:**
  1. **Baseline Reproduction:** Run `Seq2Seq` and `CMA` baselines on the provided Refined CityNav data to validate the new SR/NE metrics.
  2. **Grid Ablation:** Retrain HETT with Grid Size $0 \times 0$ (no history), $3 \times 3$, and $7 \times 7$ to reproduce the performance curve in Table 5.
  3. **Data Contamination Test:** Train HETT on the *original* (noisy) CityNav data and evaluate on the *refined* validation set to quantify the data quality contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the HETT framework maintain high navigation success rates if the dependency on static geographic priors (landmark polygons) is replaced by purely online environment mapping?
- **Basis in paper:** [explicit] The Conclusion states, "One limitation of HETT is its dependency on pre-defined information. Future work will investigate online environment mapping to enhance navigation robustness."
- **Why unresolved:** The current architecture explicitly conditions on pre-defined landmark contours ($L$) (Eq. 1). Removing this to rely solely on online observations requires fundamental architectural changes to handle the lack of prior structural knowledge.
- **What evidence would resolve it:** Evaluation of Success Rate (SR) and SPL on CityNav using a variant that dynamically generates landmark maps from live visual feeds rather than database lookups.

### Open Question 2
- **Question:** Can the model architecture be adapted to filter or ignore noisy "Missing" or "Major" landmark annotations without relying on the extensive manual dataset refinement described?
- **Basis in paper:** [inferred] The authors manually corrected "Missing" and "Major" errors (Table 1) to ensure reliable supervision. However, the paper does not demonstrate if the Two-Stage Transformer can inherently distinguish between valid instructions and hallucinated LLM-generated landmarks.
- **Why unresolved:** The performance gains (HETT vs. HETT*) are conflated with data quality improvements. It remains unclear if the model can learn robust navigation policies directly from the original, noisy data.
- **What evidence would resolve it:** A training run on the original, unrefined CityNav dataset using noise-robust loss functions or attention mechanisms to down-weight erroneous landmark tokens.

### Open Question 3
- **Question:** Is the fixed-size Historical Grid Map ($5 \times 5$) sufficient for generalizing to unbounded, continuous environments where the spatial range significantly exceeds the training distribution?
- **Basis in paper:** [inferred] The Method section defines a fixed $S_H \times S_H$ grid covering the navigation region. While Table 5 ablates grid size, it assumes a fixed environment scale, potentially limiting transfer to larger, open-world scenarios.
- **Why unresolved:** A static grid risks feature saturation or loss of resolution in larger environments. The paper does not explore dynamic memory allocation or topological graphs that might scale better than the fixed grid structure.
- **What evidence would resolve it:** Generalization experiments on significantly larger maps (beyond the current $32K$ trajectory bounds) monitoring performance degradation relative to the fixed grid capacity.

## Limitations

- The model relies on pre-defined landmark polygons (CityRefer) rather than detecting landmarks from raw pixels end-to-end
- The fixed-size Historical Grid Map may not scale well to unbounded, continuous environments
- Performance improvements are partially attributed to manual dataset refinement rather than purely architectural advances

## Confidence

- **High Confidence:** The core two-stage architecture design and the reported success rate improvements (14.16%, 10.75%, 18.00%) are well-supported by experimental results across multiple validation and test sets.
- **Medium Confidence:** The mechanism explaining how the Historical Grid Map preserves spatial context better than sequential memory is plausible but not rigorously validated against alternative memory architectures.
- **Low Confidence:** The assumption that data quality enhancement alone accounts for the 11.67% SR improvement (19.42% to 31.09%) on validation-seen is difficult to verify without access to the original noisy annotations for controlled experiments.

## Next Checks

1. **Baseline Validation:** Re-run the Seq2Seq and CMA baselines on the Refined CityNav dataset to confirm the reported baseline SR values and ensure the new evaluation metrics are properly implemented.
2. **Grid Resolution Ablation:** Systematically train HETT with different grid sizes (0×0, 3×3, 5×5, 7×7) on the same dataset split to verify the optimal 5×5 configuration and understand the performance degradation at larger sizes.
3. **Data Quality Quantification:** Train an identical HETT model on the original CityNav annotations and evaluate on the refined validation set to isolate and quantify the exact contribution of the data cleaning process to the overall performance gain.