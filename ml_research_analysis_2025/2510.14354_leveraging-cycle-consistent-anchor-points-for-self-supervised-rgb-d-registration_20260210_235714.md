---
ver: rpa2
title: Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration
arxiv_id: '2510.14354'
source_url: https://arxiv.org/abs/2510.14354
tags:
- registration
- points
- point
- anchor
- matching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of self-supervised RGB-D registration
  by leveraging cycle-consistent anchor points. The key idea is to learn cycle-consistent
  keypoints as anchor points to enforce spatial coherence constraints during correspondence
  matching, thereby improving accuracy.
---

# Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration

## Quick Facts
- **arXiv ID**: 2510.14354
- **Source URL**: https://arxiv.org/abs/2510.14354
- **Reference count**: 40
- **Primary result**: Achieves state-of-the-art performance on self-supervised RGB-D registration, surpassing previous methods on ScanNet and 3DMatch datasets.

## Executive Summary
This paper addresses the challenge of self-supervised RGB-D registration by introducing cycle-consistent anchor points as geometric constraints. The method learns salient keypoints that are cycle-consistent across multiple views, using these as reference points to enforce spatial coherence during correspondence matching. A novel pose estimation block combines GRU recurrent units with transformation synchronization to blend historical and multi-view data. Experiments demonstrate that this approach achieves new state-of-the-art results for self-supervised RGB-D registration, approaching the performance of some older supervised methods.

## Method Summary
The method uses cycle-consistent keypoints as anchor points to enforce spatial coherence constraints during matching. It employs a spatial coherence cost function measuring distances relative to these anchor points, combined with a novel pose estimation block that integrates GRU recurrent units with transformation synchronization. The approach iteratively refines correspondences and poses through inner loops (20 iterations) while updating anchor points through outer loops (3 iterations). Training uses a weighted 3D residual loss with self-supervised supervision from reprojection error.

## Key Results
- Achieves state-of-the-art performance on self-supervised RGB-D registration
- Outperforms previous methods on both ScanNet and 3DMatch datasets
- Approaches performance of some older supervised methods
- Demonstrates effectiveness of cycle-consistent anchor points for spatial coherence

## Why This Works (Mechanism)

### Mechanism 1: Cycle-Consistent Anchor Points as Spatial Constraints
The method identifies keypoints that are cycle-consistent across frames through multi-graph matching, then uses these as reference coordinates for measuring spatial relationships during pixel-level matching. Salient points learned via cycle-consistency provide stable geometric references that constrain correspondence search.

### Mechanism 2: Spatial Coherence Cost via Anchor Point Distance Encoding
For candidate correspondence pairs, the spatial coherence cost computes the absolute difference between distances from points to anchor points in their respective frames. This provides SE(3)-invariant information that filters spatially inconsistent correspondences by measuring relative distances to anchor points.

### Mechanism 3: Iterative Refinement with GRU-Based Pose Optimization and Transformation Synchronization
The approach combines temporal history (GRU) with multi-view consistency constraints (synchronization) to yield more accurate and globally consistent pose estimates than single-pair optimization. The GRU hidden state accumulates information across timesteps while transformation synchronization enforces compositional consistency across all frame pairs.

## Foundational Learning

- **Sinkhorn Normalization for Differentiable Matching**: Converts score matrices into doubly stochastic soft assignment matrices, enabling end-to-end gradient flow through the matching process without discrete hard assignments. Quick check: Can you explain why Sinkhorn iteration produces a valid probability distribution over matches, and why the slack row/column handles occlusions?

- **SE(3) Retraction and Lie Algebra Representation**: The GRU outputs 6D pose updates (se(3) Lie algebra) which are converted to SE(3) transformations via exponential map, enabling smooth optimization on the manifold. Quick check: How does representing rotations in Lie algebra (6D vector) avoid gimbal lock and singularities compared to Euler angles?

- **Cycle Consistency in Multi-Graph Matching**: Ensures that matches transit through intermediate frames correctly (A→B→C implies A→C), reducing spurious correspondences through matrix factorization. Quick check: If matches M_AB and M_BC are cycle-consistent with M_AC, what constraint does this impose on the matrix product M_AB × M_BC?

## Architecture Onboarding

- **Component map**: RGB-D Clip → ResNet-18 Backbone → Feature Maps (coarse 1/4, fine 1/2) → Anchor Point Learning (Sinkhorn → Cycle-Consistency via Matrix Factorization) → Pixel Matching Module [with Spatial Coherence Cost + Geometric Cost] ↔ (iterative loop) → Pose Refinement [GRU + Transformation Synchronization] → Registration Loss (weighted 3D residual)

- **Critical path**: 1) Feature extraction (ResNet-18, pre-trained, frozen or fine-tuned) 2) Anchor point matching (Sinkhorn + matrix factorization for cycle consistency) 3) Inner iteration (20x): pixel matching ↔ pose refinement 4) Outer iteration (3x): re-learn anchor points, repeat pipeline

- **Design tradeoffs**: Window size w×w (larger windows capture more context but increase computation); number of anchor points (~50 mentioned, too few reduces coverage, too many increases noise); iteration counts (20 inner for convergence, 3 outer for anchor refinement)

- **Failure signatures**: High correspondence error with low registration error (anchor points localized but matching window too restrictive); inconsistent multi-view registration (transformation synchronization not converging); training instability (spatial coherence cost scaling may need adjustment)

- **First 3 experiments**: 1) Ablate spatial coherence cost (SC): Run without Eq. 4-5 term; expect correspondence accuracy drop (Table IV shows Ours-SC: 2.4° vs 1.9° mean angular error on ScanNet) 2) Vary anchor point count: Test with 25, 50, 100 anchor points to find optimal tradeoff 3) Replace GRU pose block with baseline Kabsch-only: Isolate contribution of temporal reasoning (Table IV shows Ours-PE degradation from 1.9° to 2.2°)

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the method degrade when the assumption of anchor point visibility across views is violated due to occlusion or significant viewpoint changes? The method relies on these points to enforce spatial coherence constraints but does not quantify robustness against partial occlusions where anchor points might disappear.

### Open Question 2
Can the GRU-based pose refinement module provide benefits during test-time inference on sequential video data, despite being discarded in the current implementation? The GRU is trained to incorporate historical information and multi-view consistency, yet it is removed during inference in favor of a single Kabsch algorithm step.

### Open Question 3
To what extent does the reliance on initial feature similarity (ResNet-18) limit the discovery of robust anchor points in low-texture or feature-deprived environments? The initial anchor point learning stage relies on ResNet features, which may be weak in texture-less regions common in indoor scenes.

## Limitations
- Anchor point localization precision and robustness to textureless surfaces or repetitive patterns is not quantitatively validated
- Critical hyperparameters like matching window size and spatial coherence scaling are not fully specified
- Temporal coherence assumptions may break down with rapid motion or large frame gaps

## Confidence

- **High confidence**: The core architectural framework combining cycle-consistent anchor points with iterative refinement is technically sound and well-motivated by geometric principles
- **Medium confidence**: The quantitative claims of state-of-the-art performance are supported by extensive benchmark comparisons, though hyperparameter sensitivity analysis is limited
- **Low confidence**: Claims about approaching older supervised methods lack context about potential domain shifts or benchmark differences

## Next Checks

1. **Anchor point localization robustness**: Evaluate anchor point consistency across varying scene conditions (textureless surfaces, repetitive patterns, occlusion scenarios) and measure localization error distributions

2. **Hyperparameter sensitivity analysis**: Systematically vary matching window size, spatial coherence scaling, and iteration counts to identify performance plateaus and failure thresholds

3. **Temporal coherence validation**: Test performance degradation as frame spacing increases beyond 20 frames, and analyze failure cases with rapid motion or significant viewpoint changes