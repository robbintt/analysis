---
ver: rpa2
title: Training Data Attribution for Image Generation using Ontology-Aligned Knowledge
  Graphs
arxiv_id: '2512.02713'
source_url: https://arxiv.org/abs/2512.02713
tags:
- training
- images
- image
- graph
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for tracing training data influence
  in generative models using ontology-aligned knowledge graphs (KGs). The method extracts
  structured semantic triples from images via multimodal LLMs, guided by domain-specific
  ontologies, and constructs interpretable KGs for both generated and training images.
---

# Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs

## Quick Facts
- arXiv ID: 2512.02713
- Source URL: https://arxiv.org/abs/2512.02713
- Reference count: 24
- This paper introduces a framework for tracing training data influence in generative models using ontology-aligned knowledge graphs (KGs)

## Executive Summary
This paper presents a novel framework for training data attribution in image generation by leveraging ontology-aligned knowledge graphs. The approach extracts structured semantic triples from images using multimodal large language models, guided by domain-specific ontologies, to construct interpretable knowledge graphs for both generated and training images. By comparing these graphs, the framework enables transparent attribution of stylistic and semantic influences, addressing the challenge of understanding how training data shapes generated outputs. The method demonstrates effectiveness across both locally trained models and large-scale black-box models, offering a more interpretable alternative to traditional embedding-based attribution methods.

## Method Summary
The framework operates by first extracting structured semantic triples from images using multimodal LLMs, with extraction guided by domain-specific ontologies to ensure semantic relevance. These triples are then organized into interpretable knowledge graphs for both the generated images and the training dataset. Attribution is achieved by comparing the knowledge graphs of generated images against those of training images to identify semantic and stylistic influences. The ontology alignment ensures that the extracted information follows a consistent semantic structure, while the graph comparison enables transparent tracking of which training data contributed to specific characteristics in the generated outputs.

## Key Results
- Successfully traces training data influence in both locally trained and black-box generative models
- KG-based approach achieves comparable influence detection accuracy to embedding-based methods
- Provides improved interpretability through structured semantic representation of image content
- Enables applications in copyright analysis, dataset transparency, and interpretable AI

## Why This Works (Mechanism)
The framework works by converting unstructured image data into structured semantic representations through ontology-guided extraction. Multimodal LLMs process images to identify entities, relationships, and attributes, which are then organized according to predefined ontological structures. This semantic structuring allows for meaningful comparisons between generated and training images, as similar semantic patterns can be identified and traced back to their sources. The knowledge graph representation captures not just visual similarity but also conceptual relationships, enabling more nuanced attribution than purely statistical methods.

## Foundational Learning
- **Ontology Alignment**: Why needed - Provides semantic structure and consistency for extracted information; Quick check - Verify that extracted triples follow the defined ontological schema
- **Multimodal LLM Extraction**: Why needed - Enables automated semantic understanding of visual content; Quick check - Confirm extracted triples capture meaningful image semantics
- **Knowledge Graph Construction**: Why needed - Transforms unstructured data into comparable structured representations; Quick check - Validate graph connectivity and semantic coherence
- **Graph Comparison Algorithms**: Why needed - Enables attribution by identifying semantic similarities and influences; Quick check - Test comparison accuracy on known influence cases

## Architecture Onboarding
**Component Map**: Image -> Multimodal LLM -> Triple Extraction -> Ontology Alignment -> Knowledge Graph Construction -> Graph Comparison -> Attribution Results

**Critical Path**: The most time-consuming steps are multimodal LLM processing for triple extraction and graph comparison algorithms, as these require significant computational resources for semantic analysis.

**Design Tradeoffs**: The framework trades computational efficiency for interpretability, as knowledge graph construction is more resource-intensive than direct embedding comparisons but provides richer semantic insights.

**Failure Signatures**: Attribution failures occur when ontologies lack coverage for important image concepts, when multimodal LLMs fail to extract relevant triples, or when graph comparison algorithms cannot identify meaningful semantic patterns.

**3 First Experiments**:
1. Test ontology coverage by measuring attribution accuracy across different image domains with varying ontology completeness
2. Evaluate multimodal LLM extraction quality by comparing human-annotated semantic triples against automated extraction
3. Benchmark graph comparison effectiveness by measuring attribution accuracy on controlled datasets with known training influences

## Open Questions the Paper Calls Out
None

## Limitations
- Framework heavily depends on ontology quality and coverage, with potential bias introduced by ontology selection
- Evaluation lacks rigorous quantitative comparisons with embedding-based methods and statistical validation
- No user studies demonstrating practical advantages of KG-based attributions over traditional methods

## Confidence
- High confidence: The general feasibility of using knowledge graphs for semantic representation of images
- Medium confidence: The technical implementation of KG construction from multimodal LLM outputs
- Low confidence: Claims about practical advantages over existing attribution methods and real-world applicability

## Next Checks
1. Conduct systematic ablation studies varying ontology selection, graph construction parameters, and multimodal LLM configurations to quantify their impact on attribution accuracy and consistency
2. Perform controlled user studies with domain experts comparing KG-based attributions to embedding-based methods for practical tasks like copyright analysis and dataset auditing
3. Test the framework across diverse image domains (medical, artistic, scientific) with varying ontology coverage to identify failure modes and robustness boundaries