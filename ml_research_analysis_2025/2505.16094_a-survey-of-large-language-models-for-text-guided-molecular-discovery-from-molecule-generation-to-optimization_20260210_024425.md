---
ver: rpa2
title: 'A Survey of Large Language Models for Text-Guided Molecular Discovery: from
  Molecule Generation to Optimization'
arxiv_id: '2505.16094'
source_url: https://arxiv.org/abs/2505.16094
tags:
- arxiv
- molecule
- molecular
- language
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey presents the first comprehensive review of large language
  models (LLMs) for text-guided molecular discovery, focusing on molecule generation
  and optimization. We introduce a novel taxonomy categorizing approaches based on
  learning paradigms: without LLM tuning (zero-shot prompting, in-context learning)
  versus with LLM tuning (supervised fine-tuning, preference tuning).'
---

# A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization

## Quick Facts
- arXiv ID: 2505.16094
- Source URL: https://arxiv.org/abs/2505.16094
- Authors: Ziqing Wang; Kexin Zhang; Zihan Zhao; Yibo Wen; Abhishek Pandey; Han Liu; Kaize Ding
- Reference count: 40
- Key outcome: First comprehensive review of LLMs for text-guided molecular discovery, introducing taxonomy based on learning paradigms (zero-shot prompting, in-context learning vs. supervised fine-tuning, preference tuning) and identifying key challenges in trustworthy generation, LLM agents, and multi-modal modeling.

## Executive Summary
This survey presents the first comprehensive review of large language models (LLMs) for text-guided molecular discovery, focusing on molecule generation and optimization. The authors introduce a novel taxonomy categorizing approaches based on learning paradigms: without LLM tuning (zero-shot prompting, in-context learning) versus with LLM tuning (supervised fine-tuning, preference tuning). The survey analyzes representative techniques, commonly used datasets, and evaluation protocols while identifying key challenges including trustworthy generation, hallucination mitigation, development of LLM agents for interactive discovery, and multi-modal modeling and alignment.

## Method Summary
The survey systematically reviews existing LLM approaches for molecular discovery through a dual perspective of application and methodology. It categorizes techniques based on whether they require LLM weight tuning, distinguishing between frozen model approaches (zero-shot prompting, in-context learning with retrieval augmentation) and tuned approaches (supervised fine-tuning on instruction-response pairs, preference optimization via DPO/RL). The analysis covers commonly used datasets including SMolInstruct, ChEBI-20, PubChem, and ChEMBL, along with evaluation protocols focusing on validity, novelty, and property constraints. The authors identify future research directions emphasizing frameworks for distinguishing harmful hallucinations from beneficial creative leaps, robust LLM agents for interactive workflows, and architectures unifying chemical topology, geometry, and textual semantics.

## Key Results
- Introduces novel taxonomy separating LLM approaches for molecular discovery into w/o tuning (zero-shot prompting, ICL) and w/ tuning (SFT, preference tuning) paradigms
- Identifies three key challenges: trustworthy generation and hallucination mitigation, development of LLM agents for interactive discovery, and multi-modal modeling and alignment
- Proposes future directions emphasizing frameworks distinguishing harmful fabrications from beneficial creative leaps, robust agents capable of planning and tool interaction, and architectures unifying chemical topology, geometry, and textual semantics

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Injection via In-Context Retrieval
Frozen LLMs lack deep chemical knowledge. By dynamically retrieving similar examples (e.g., from ChEBI-20) and presenting them as few-shot context, the model leverages its pattern-matching capabilities to map textual descriptions to chemical structures without updating weights. The core assumption is that the LLM possesses sufficient prior syntactic understanding of SMILES/SELFIES to adapt to retrieved examples immediately. Break condition: If the retrieval database lacks diversity or the query instruction describes a novel chemical space not represented in retrieved examples, the model may hallucinate invalid structures.

### Mechanism 2: Chemical Domain Alignment via Supervised Fine-Tuning (SFT)
Pre-training on general text establishes broad reasoning, but SFT on datasets like SMolInstruct or ChemData forces the model to learn specific grammar of molecular representations (e.g., SMILES syntax) and semantic mapping between functional descriptions (e.g., "hydrophobic") and structural motifs. The core assumption is that required chemical knowledge is contained within or can be compressed into the instruction dataset without catastrophic forgetting of general reasoning. Break condition: If SFT dataset is noisy or contains invalid SMILES, the model will amplify these errors, leading to low chemical validity rates.

### Mechanism 3: Preference Optimization for Property Constraints
SFT teaches the model to generate chemically valid structures, but not necessarily optimal ones. Preference tuning uses reward signal (or preference pairs of "chosen" vs. "rejected" molecules) to adjust probabilities, prioritizing molecules scoring high on desired metrics while penalizing invalid or suboptimal ones. The core assumption is that reliable reward model or oracle exists to distinguish between preferred and rejected molecular candidates during tuning phase. Break condition: If reward function is sparse or optimization over-rewards specific proxy (e.g., high solubility at cost of synthetic accessibility), the model may suffer from "reward hacking," generating unrealistic structures.

## Foundational Learning

- **Concept: Molecular Representations (SMILES vs. SELFIES)**
  - Why needed here: The survey focuses on "text-guided" discovery, which relies on LLMs processing molecules as strings. Understanding that SMILES are linear text encodings of molecular graphs is critical for debugging tokenization errors or syntax hallucinations.
  - Quick check question: Can you explain why a standard LLM might generate a syntactically invalid SMILES string even if the semantic description is correct?

- **Concept: Frozen vs. Tuned Paradigms**
  - Why needed here: The paper's core taxonomy distinguishes between "w/o Tuning" (ICL) and "w/ Tuning" (SFT/DPO). An engineer must decide whether to invest in complex prompt engineering (Frozen) or data curation and training pipelines (Tuned).
  - Quick check question: If compute resources are scarce but data is proprietary, which paradigm (Zero-Shot/ICL or SFT) is the initial logical choice?

- **Concept: Validity vs. Novelty Metrics**
  - Why needed here: Optimization requires balancing trade-offs. High validity (chemical stability) often conflicts with high novelty (finding new structures). Understanding metrics like QED (drug-likeness) and Validity Rate is essential for defining reward function.
  - Quick check question: If a model generates a structurally unique molecule that violates basic valency rules, does it fail the Validity check or the Novelty check?

## Architecture Onboarding

- **Component map:** Natural Language Instruction + (Optional) Seed Molecule (SMILES/Graph) -> Retrieval Module (Optional) -> Core Engine (Foundation LLM) -> Validation/Oracle (RDKit) -> Feedback Loop (Optional)
- **Critical path:** 1. Data Curation: Assembling instruction pairs (Text -> SMILES) from sources like PubChem/ChEMBL 2. Tokenization: Ensuring tokenizer handles chemical strings (SMILES) without excessive fragmentation 3. SFT: Fine-tuning base model to generate syntactically valid SMILES 4. Alignment: Using RDKit scores as rewards to run DPO/RL for property optimization
- **Design tradeoffs:** String-only vs. Multi-modal: String-only (SMILES) is easier to implement but loses topological info. Multi-modal (Graph+Text) is more robust but requires complex encoders. Hallucination Control: Aggressive constraint enforcement (via Preference Tuning) reduces hallucinations but may lower diversity ("Beneficial creative leaps").
- **Failure signatures:** Syntactic Hallucination: Output contains invalid characters or unbalanced rings/parentheses in SMILES (Check: RDKit parsing failure). Semantic Drift: Generated molecule matches property constraints (e.g., high LogP) but ignores textual description (e.g., "benzene ring" is missing). Mode Collapse: Model repeatedly generates same high-scoring molecule for every prompt.
- **First 3 experiments:** 1. Baseline Zero-Shot Validity: Prompt GPT-4/Llama-3 with "Generate a SMILES string for [Description]" and measure percentage of outputs that parse in RDKit. (Establishes the floor) 2. ICL with RAG: Implement simple retrieval system using ChEBI-20. Retrieve 3 similar molecules, add to prompt, and check if Validity improves. 3. SFT Overfit Test: Fine-tune small LLM on SMolInstruct. Plot "Validity Rate" vs. "Training Steps" to find point where model memorizes training set (Novelty drops to 0).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can frameworks be developed to distinguish between harmful chemical fabrications and beneficial "creative leaps" (controlled hallucinations) in LLM outputs?
- **Basis in paper:** The Conclusion states: "The future challenge lies not in eliminating hallucinations entirely, but in developing frameworks that can distinguish between harmful fabrications and beneficial creative leaps."
- **Why unresolved:** Current evaluation metrics prioritize strict validity and similarity, potentially penalizing novel scaffold generation that emerges from controlled hallucination but could lead to valid, innovative drugs.
- **What evidence would resolve it:** A quantitative framework or metric that successfully identifies chemically plausible "creative" outputs which standard validity checks might reject, validated by successful synthesis or binding of these novel structures.

### Open Question 2
- **Question:** What architectures are necessary to effectively unify 1D text, 2D topology, and 3D geometry for joint reasoning in molecular discovery?
- **Basis in paper:** The Conclusion notes: "Future work should prioritize architectures that unify these representations, allowing joint encoding and reasoning over chemical topology, geometry, and textual semantics."
- **Why unresolved:** Most existing LLMs rely primarily on 1D sequence representations (SMILES), which fail to explicitly encode rich structural and spatial information essential for accurate property prediction and 3D interaction modeling.
- **What evidence would resolve it:** A unified multi-modal model that demonstrates superior performance on 3D-dependent tasks (e.g., binding affinity prediction) compared to text-only or late-fusion models, proving it has learned joint representations.

### Open Question 3
- **Question:** How can we build robust LLM agents capable of planning, reasoning, and interacting with external tools (e.g., docking software) to automate interactive discovery workflows?
- **Basis in paper:** The Conclusion identifies: "Building robust LLM agents that can plan, reason, and interact with both humans and tools could enable more flexible and goal-directed molecular design."
- **Why unresolved:** Current approaches often struggle to maintain context and error-correct over long, multi-step experimental pipelines, limiting their ability to close the loop between computational prediction and experimental validation autonomously.
- **What evidence would resolve it:** An LLM-based agent that successfully completes a multi-step "design-make-test" cycle for a specific target with minimal human intervention, dynamically adjusting its strategy based on tool feedback.

## Limitations

- Data Quality and Availability: Many approaches rely on proprietary or limited datasets, and standardized benchmarks for text-guided molecular discovery remain underdeveloped, creating uncertainty about whether reported improvements generalize.
- Evaluation Protocol Inconsistency: The absence of unified benchmarks makes cross-method comparisons unreliable, as different studies use varying evaluation criteria for validity, novelty, and property scores.
- Hallucination Risk and "Beneficial Creativity": The mechanisms proposed (preference tuning, RAG) show promise but lack rigorous validation of when creative divergence becomes chemically nonsensical.

## Confidence

**High Confidence Claims:**
- The taxonomy distinguishing between w/o tuning (zero-shot/ICL) and w/ tuning (SFT/DPO) approaches is well-supported by the literature
- Retrieval-augmented generation (RAG) improves ICL performance by providing relevant chemical examples
- Supervised fine-tuning on curated instruction-response pairs aligns LLMs with chemical representations

**Medium Confidence Claims:**
- Preference optimization significantly improves property constraint adherence
- The identified challenges represent genuine barriers requiring substantial innovation
- Future directions focusing on distinguishing harmful vs. beneficial creativity will yield practical frameworks

**Low Confidence Claims:**
- Specific performance metrics comparing different approaches are difficult to verify due to inconsistent evaluation protocols
- The effectiveness of multi-modal architectures over string-only representations lacks sufficient empirical validation
- The proposed timeline for solving identified challenges is speculative

## Next Checks

1. **Benchmark Validation Study:** Implement standardized evaluation pipeline using common dataset (e.g., MOSES benchmark with text-guided variants) to compare zero-shot, ICL with RAG, SFT, and preference-tuned approaches under identical conditions.

2. **Hallucination Boundary Experiment:** Design systematic study to quantify "beneficial creativity" threshold by generating molecules across validity-novelty spectrum and having domain experts classify outputs as valid/invalid, obvious/novel, reasonable/hallucination.

3. **Multi-Modal vs. String-Only Comparison:** Implement parallel pipelines using identical base LLMs but different molecular representations (SMILES-only vs. graph+text with molecular encoders) and evaluate both on same text-guided generation tasks with identical constraints.