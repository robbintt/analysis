---
ver: rpa2
title: 'M3TQA: Massively Multilingual Multitask Table Question Answering'
arxiv_id: '2508.16265'
source_url: https://arxiv.org/abs/2508.16265
tags:
- table
- language
- languages
- indo-european
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# M3TQA: Massively Multilingual Multitask Table Question Answering

## Quick Facts
- arXiv ID: 2508.16265
- Source URL: https://arxiv.org/abs/2508.16265
- Authors: Daixin Shu; Jian Yang; Zhenhe Wu; Xianjie Wu; Xianfu Cheng; Xiangyuan Guan; Yanghai Wang; Pengfei Wu; Tingyang Yang; Hualei Zhu; Wei Zhang; Ge Zhang; Jiaheng Liu; Zhoujun Li
- Reference count: 12
- Key outcome: Introduces M3TQA, a benchmark with 4,349 multilingual tables in 97 languages and 42,273 QA pairs, trained via synthetic data and GRPO on Qwen3-8B/Llama-3.1-8B

## Executive Summary
M3TQA addresses the scarcity of multilingual table QA data by creating a benchmark spanning 97 languages and four task types. The authors propose a six-step LLM-based translation pipeline to preserve structural integrity when translating tables, followed by synthetic QA generation using thinking traces from large models. Training combines supervised fine-tuning on synthetic data with Group Relative Policy Optimization to improve reasoning performance, achieving strong results especially for low-resource languages.

## Method Summary
The method involves translating 50 real-world tables (41 Chinese, 9 English) into 97 languages using a six-step LLM pipeline, generating 39,077 synthetic QA pairs with thinking traces, and training smaller models (Qwen3-8B/Llama-3.1-8B) via supervised fine-tuning followed by GRPO. Evaluation covers four task types across all languages using task-specific metrics. The approach leverages synthetic data to overcome annotation scarcity while maintaining performance through reward-based fine-tuning.

## Key Results
- M3TQA dataset includes 4,349 multilingual tables and 42,273 QA pairs across 97 languages
- Models trained on synthetic data with GRPO show 10-20 point gains on low-resource languages
- Thinking traces improve performance by 10.49-15.82 points across training stages
- GRPO generally improves performance but causes regression in Austronesian and Austroasiatic language families

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A multi-stage LLM-based translation pipeline preserves structural and semantic integrity of tabular data across 97 languages.
- Mechanism: Tables are serialized to 2D lists, translated with structural constraints via DeepSeek/GPT-4o, refined through cell-level and global corrections, validated via back-translation with adaptive BLEU scoring, and human-verified. This mitigates translation drift that would otherwise break cell-header relationships.
- Core assumption: LLMs can maintain structural markup (list delimiters) while translating content, and back-translation quality correlates with forward-translation fidelity.
- Evidence anchors:
  - [abstract] "robust six-step LLM-based translation pipeline powered by DeepSeek and GPT-4o, achieving high translation fidelity with a median BLEU score of 60.19"
  - [section] Table translation (Page 2) details serialization, cell correction, global/cell refinement, back-translation validation with adaptive BLEU formula
  - [corpus] MULTITAT paper also uses translation-based multilingual table QA but is limited to 10 languages; no direct corpus evidence for this specific 6-step pipeline
- Break condition: For languages with low BLEU scores (<34), table semantics may be corrupted; for heavily numeric tables, BLEU validation is bypassed, risking undetected errors in formula-referencing cells.

### Mechanism 2
- Claim: Training smaller models on thinking traces from larger multilingual LLMs improves cross-lingual table reasoning, particularly for complex tasks.
- Mechanism: Large models (DeepSeek-R1, GPT-4o) generate explicit reasoning traces wrapped in special tags (plit>...</think). These traces are concatenated with ground-truth answers and used as training targets, teaching smaller models the intermediate reasoning steps rather than just input-output mappings.
- Core assumption: Thinking traces contain transferable reasoning patterns that generalize across languages, and smaller models can internalize these patterns through SFT.
- Evidence anchors:
  - [abstract] "synthetically generated, unannotated QA data can significantly boost performance, particularly for low-resource languages"
  - [section] "Thinking" (Page 4) describes trace extraction and concatenation; Table 5 shows thinking mode adds 10.49–15.82 points across training stages
  - [corpus] No direct corpus evidence for thinking-trace distillation in multilingual table QA; related work focuses on dataset construction
- Break condition: For languages with weak representation in the teacher model (e.g., Niger-Congo languages), thinking traces may contain reasoning errors or hallucinations that propagate to the student model.

### Mechanism 3
- Claim: Synthetic QA data generated by LLMs without human annotation can effectively train models for multilingual table QA when combined with reinforcement learning.
- Mechanism: M3TQA-INSTRUCT (39,077 LLM-generated QA pairs) provides supervised fine-tuning signal; GRPO then optimizes policy using task-specific evaluation metrics (Jaccard, F1, ROUGE-L) as rewards, refining model behavior toward precise answer formats.
- Core assumption: LLM-generated QA pairs, though imperfect, cover sufficient task-relevant patterns to bootstrap learning, and GRPO can correct systematic errors through reward-guided exploration.
- Evidence anchors:
  - [abstract] "synthetically generated, unannotated QA data can significantly boost performance"
  - [section] "Analysis" (Page 8) notes models fine-tuned on entirely LLM-generated data show "substantial improvement on purely human-constructed test sets"; Table 4 shows +10–20 point gains for low-resource languages after SFT+GRPO
  - [corpus] MULTITAT and related benchmarks rely on human annotation; no corpus precedent for fully synthetic multilingual table QA training
- Break condition: If synthetic QA pairs contain systematic translation or reasoning errors concentrated in specific language families, GRPO may amplify these biases rather than correct them (observed degradation in Austronesian/Austroasiatic families post-GRPO).

## Foundational Learning

- **Concept: Table serialization and structural preservation**
  - Why needed here: Tabular data cannot be naively translated as free text; cell-header relationships, numerical formats, and multi-level indexing must survive language transfer.
  - Quick check question: Given a relational table with merged header cells, what serialization format preserves both content and structure for LLM processing?

- **Concept: BLEU scoring and its limitations for short texts**
  - Why needed here: Standard BLEU-2/4 penalizes short cell contents; adaptive BLEU (BLEU-1 for L≤3, averaging for longer texts) is used to validate translation quality without rejecting valid short translations.
  - Quick check question: Why would BLEU-4 be inappropriate for evaluating a 3-token table cell translation?

- **Concept: Group Relative Policy Optimization (GRPO) for structured outputs**
  - Why needed here: GRPO extends PPO with group-based advantage estimation, useful when rewards are sparse or noisy (e.g., exact-match metrics on multilingual outputs).
  - Quick check question: How does GRPO differ from standard PPO when rewards are computed from task-specific evaluation metrics rather than scalar preferences?

## Architecture Onboarding

- **Component map:**
  - 50 source tables (41 Chinese, 9 English) -> 6-step translation pipeline -> 4,349 multilingual tables
  - Hybrid generation (human seed + LLM expansion) -> 2,916 human-curated test pairs + 39,077 synthetic training pairs (M3TQA-INSTRUCT)
  - SFT on M3TQA-INSTRUCT (5 epochs, lr=1e-5, max 12K tokens) -> GRPO (2 epochs, lr=1e-6, group size=5)
  - 4 task types (Numerical Computation/Jaccard, Cell Extraction/Jaccard+coordinates, Factual Verification/F1, Open-Ended/ROUGE-L)

- **Critical path:**
  1. Table translation quality (BLEU threshold filtering removes ~10% of tables)
  2. Entity alignment during QA generation (tables and questions must share translated entity references)
  3. Output format enforcement (strict "T"/"F" for verification, coordinates for extraction, Arabic numerals for computation)

- **Design tradeoffs:**
  - Translation-first vs QA-then-translate: Authors chose to generate QA pairs from source tables then translate, avoiding entity consistency issues (separate translation of tables and QA risks divergent entity names)
  - Thinking vs non-thinking modes: Thinking adds ~30% training overhead (longer sequences) but yields 10–15 point gains; may cause infinite loops on unseen languages
  - Synthetic-only training: Eliminates human annotation cost but requires BLEU filtering and GRPO to mitigate quality variance

- **Failure signatures:**
  - Low-resource languages (Niger-Congo, Austronesian) show 30–40% lower scores than Indo-European even after SFT
  - GRPO causes performance drops in some languages (e.g., Cambodian, multiple Austronesian languages) — cross-lingual interference in shared training
  - Thinking mode triggers disorganization/loops for languages poorly represented in teacher model training data

- **First 3 experiments:**
  1. **Baseline evaluation:** Run Qwen3-8B-nothinking on all 4 task types across 3 language families (Indo-European, Sino-Tibetan, Niger-Congo) to establish pre-training performance gaps
  2. **Translation quality ablation:** Compare models trained on tables filtered at BLEU=34 (current minimum) vs BLEU=50 to measure sensitivity to translation noise
  3. **Thinking trace analysis:** For a low-resource language (e.g., Xhosa), manually inspect thinking traces from the teacher model for reasoning errors before training student models; quantify hallucination rates in traces

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can reinforcement learning algorithms like GRPO be stabilized to prevent performance regression in specific low-resource languages during multilingual fine-tuning?
- Basis in paper: [explicit] The authors observe that while GRPO generally improves performance, it induces regression in Austronesian and Austroasiatic language families, attributing this to the "cross-influence between multiple languages."
- Why unresolved: The paper identifies the symptom (regression) and suggests a cause (cross-lingual interference), but does not propose a modification to the GRPO algorithm or data sampling strategy to mitigate this negative transfer.
- What evidence would resolve it: A demonstration of a modified RL objective or sampling technique that maintains or improves performance on the regressing languages (e.g., Khmer/Cambodian) without sacrificing gains in high-resource languages.

### Open Question 2
- Question: Can "thinking" paradigms (Chain-of-Thought) be effectively adapted for low-resource languages where they currently underperform compared to standard SFT?
- Basis in paper: [inferred] The authors note a dichotomy where thinking modes benefit languages in developed regions (likely high-resource), while SFT is more effective for languages in underdeveloped regions (likely low-resource).
- Why unresolved: The paper establishes that current thinking capabilities are less effective for low-resource languages, but does not determine if this is due to a lack of native reasoning data or fundamental limitations in the model's latent representations for those languages.
- What evidence would resolve it: A training method that successfully elicits high-performance reasoning traces in a low-resource language (e.g., Maori or Xhosa) comparable to its SFT baseline.

### Open Question 3
- Question: Does high translation fidelity (BLEU) guarantee the preservation of complex pragmatic or cultural reasoning required for Open-Ended Questions?
- Basis in paper: [inferred] The dataset relies on a "six-step LLM-based translation pipeline" validated by BLEU scores, but the authors note that "resource asymmetry" challenges equitable development, implying semantic gaps may remain in low-resource targets.
- Why unresolved: While the paper validates lexical similarity via back-translation, it does not isolate whether errors in Open-Ended Question tasks stem from model reasoning failures or subtle semantic distortions introduced by the translation pipeline.
- What evidence would resolve it: A comparative study of model performance on native-language tables versus high-quality translated tables to decouple reasoning ability from translation artifacts.

## Limitations
- Translation pipeline relies on LLM capabilities without independent validation, particularly for short cell contents and numerical tables
- GRPO induces performance regression in several language families (Austronesian, Austroasiatic) due to cross-lingual interference
- Low-resource languages show 30-40% performance gaps even after full training, with potential hallucination propagation from teacher thinking traces

## Confidence
- **High confidence:** Translation pipeline methodology (step-by-step procedure is clearly specified, though implementation details are limited), synthetic data generation process (explicit QA pair creation rules described), and hardware requirements (8×A800 80GB, specific batch sizes and epochs)
- **Medium confidence:** Performance improvements from SFT+GRPO (reported gains are substantial but per-language variations and GRPO-induced regressions suggest sensitivity to hyperparameters not fully explored), and the six-step translation pipeline's ability to preserve semantic integrity (BLEU scores support this but independent verification is absent)
- **Low confidence:** Generalization to truly low-resource languages (performance gaps persist even after full training, and thinking traces may contain hallucinations that propagate to student models), and the claim that synthetic-only training matches human-annotated data quality (benchmarked only against human-curated test sets, not human-annotated training data)

## Next Checks
1. **Translation quality audit:** Manually evaluate 50 randomly selected table translations across 5 low-resource languages (including Niger-Congo and Austronesian families) to verify BLEU scores correlate with semantic preservation, particularly for numerical tables and merged header cells
2. **Thinking trace hallucination analysis:** Sample 100 thinking traces from DeepSeek-R1 for low-resource languages, identify reasoning errors or hallucinations, and quantify their prevalence before student model training to establish baseline error rates
3. **GRPO sensitivity ablation:** Run GRPO with varying group sizes (3, 5, 10) and learning rates (1e-6, 5e-7, 1e-7) on a subset of languages showing post-GRPO degradation to determine optimal hyperparameters and identify conditions causing negative transfer