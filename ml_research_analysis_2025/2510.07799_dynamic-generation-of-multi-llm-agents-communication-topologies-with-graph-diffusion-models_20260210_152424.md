---
ver: rpa2
title: Dynamic Generation of Multi-LLM Agents Communication Topologies with Graph
  Diffusion Models
arxiv_id: '2510.07799'
source_url: https://arxiv.org/abs/2510.07799
tags:
- arxiv
- topologies
- multi-agent
- graph
- communication
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of dynamically designing communication
  topologies for multi-agent systems powered by large language models (LLMs). The
  key problem is that static or hand-crafted topologies often fail to adapt to diverse
  task requirements, leading to either excessive token consumption for simple problems
  or performance bottlenecks for complex ones.
---

# Dynamic Generation of Multi-LLM Agents Communication Topologies with Graph Diffusion Models

## Quick Facts
- arXiv ID: 2510.07799
- Source URL: https://arxiv.org/abs/2510.07799
- Reference count: 40
- Authors: Eric Hanchen Jiang, Guancheng Wan, Sophia Yin, Mengting Li, Yuchen Wu, Xiao Liang, Xinfeng Li, Yizhou Sun, Wei Wang, Kai-Wei Chang, Ying Nian Wu
- One-line result: Proposes GTD, a generative framework that formulates topology synthesis as an iterative construction process, enabling task-adaptive, sparse communication topologies for LLM agents.

## Executive Summary
This paper introduces Guided Topology Diffusion (GTD), a novel approach to dynamically generate communication topologies for multi-agent systems powered by large language models (LLMs). The key innovation is formulating topology synthesis as an iterative denoising process, inspired by conditional discrete graph diffusion models. By leveraging a lightweight proxy model to predict multi-objective rewards and steering the generation in real-time, GTD overcomes the limitations of static or hand-crafted topologies, producing task-adaptive, sparse, and efficient communication structures that significantly improve LLM agent collaboration performance.

## Method Summary
GTD formulates the generation of communication topologies as an iterative denoising process. It uses a lightweight Graph Neural Network (GNN) proxy model trained to predict rewards (e.g., accuracy, utility, cost) from graph structures. During inference, the diffusion generator proposes multiple candidate graphs at each step, and the proxy model selects the best one to guide the next iteration. This zeroth-order optimization approach allows for real-time, task-specific steering without requiring differentiable rewards, enabling the synthesis of sparse, high-performing topologies tailored to diverse task requirements.

## Key Results
- GTD generates highly task-adaptive, sparse, and efficient communication topologies.
- Achieves up to 94.14% accuracy on GSM8K while using significantly fewer tokens.
- Significantly outperforms existing methods in LLM agent collaboration.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Iterative denoising allows the system to navigate complex design trade-offs (e.g., accuracy vs. token cost) more effectively than single-step generative models.
- **Mechanism:** The framework refines a random graph into a structured topology over $T$ steps. By correcting errors gradually, the model can explore a richer design space rather than committing to a structure immediately, allowing it to find Pareto-optimal solutions for multi-objective rewards.
- **Core assumption:** High-performing communication topologies lie on a learnable manifold that can be reached by reversing a Gaussian noising process.
- **Evidence anchors:**
  - [abstract]: "GTD formulates topology synthesis as an iterative construction process... distinguishing GTD from single-step generative frameworks."
  - [section 3.2]: Describes the reverse process $p_\theta(A_{t-1}|A_t, C)$ which learns to denoise a noisy graph $A_t$ back to a clean one.
  - [corpus]: Graph diffusion is increasingly recognized for topology generation in dynamic environments (e.g., "Topology Generation of UAV..."), suggesting the method is sound for structural synthesis.
- **Break condition:** If the noise schedule is too aggressive or the model capacity is too low, the denoising process may fail to converge to a valid or connected graph.

### Mechanism 2
- **Claim:** Decoupling the expensive environment simulation from the generation loop via a surrogate (proxy) model enables real-time, task-specific steering without requiring differentiable rewards.
- **Mechanism:** A lightweight Graph Neural Network (GNN) is trained to predict rewards (utility/cost). During inference, this proxy acts as a guide: at each diffusion step, the generator proposes candidates, and the proxy selects the best one to condition the next step. This bypasses the need to run the actual LLM agents during the graph construction phase.
- **Core assumption:** The surrogate model $P_\phi$ is $\epsilon$-accurate; if the proxy error is high, the guidance pushes the topology toward suboptimal regions (Theorem C.5).
- **Evidence anchors:**
  - [section 4.1]: "To circumvent the computational cost of direct simulation, we first train a surrogate model $P_\phi$..."
  - [section 4.3]: Details the "zeroth-order (ZO) optimization" where the proxy evaluates discrete candidates to steer the trajectory.
  - [corpus]: "Understanding the Information Propagation..." highlights that topology fundamentally governs efficiency, validating the need for a predictor that understands these dynamics.
- **Break condition:** If the distribution of tasks shifts significantly from the training data, the proxy predictions may become uncorrelated with actual LLM performance, leading to misguided topologies.

### Mechanism 3
- **Claim:** Explicitly optimizing for sparsity and cost in the selection objective forces the generation of efficient, non-fully-connected graphs.
- **Mechanism:** The system selects the best candidate graph $A_{0,best}^{(t)}$ by maximizing a composite score (Eq. 8) that includes a negative weight for cost. This incentivizes the diffusion process to prune unnecessary edges that do not contribute to utility.
- **Core assumption:** There exists a sparse subgraph that performs comparably to a dense graph for a given task.
- **Evidence anchors:**
  - [section 5.2]: "GTD generates not only effective but also significantly sparser... topologies... preserving only the most critical communication links."
  - [figure 4]: Visualizes GTD occupying the bottom-right (high accuracy, low token) frontier.
  - [corpus]: "Adaptive Graph Pruning for Multi-Agent Communication" supports the premise that static structures limit adaptation and pruning is beneficial.
- **Break condition:** If the utility weight $w_u$ is set too low relative to the cost weight $w_c$, the model may generate disconnected or trivially simple graphs (e.g., empty graphs) that minimize cost but fail the task.

## Foundational Learning

- **Concept:** **Discrete Graph Diffusion Models**
  - **Why needed here:** You must understand how continuous noise (Gaussian) is mapped to discrete structures (Adjacency Matrices with 0/1 entries) to debug the generation loop.
  - **Quick check question:** How does the model sample a discrete adjacency matrix $A_0$ from the continuous output of the denoising network $G_\theta$? (Hint: Look for Bernoulli sampling in Section 4.3).

- **Concept:** **Zeroth-Order (Gradient-Free) Optimization**
  - **Why needed here:** The proxy model guides the diffusion, but the process is not differentiable end-to-end. Understanding ZO optimization explains why we sample $K$ candidates rather than computing gradients.
  - **Quick check question:** Why can't we use standard backpropagation (first-order optimization) to update the diffusion model's weights using the reward from the proxy model during inference?

- **Concept:** **Multi-Objective Optimization & Pareto Efficiency**
  - **Why needed here:** The system balances competing goals (Accuracy vs. Token Cost). You need to know how to tune the weights $w_u$ and $w_c$ to achieve desired behavior.
  - **Quick check question:** If you increase the penalty for token cost in Equation 8, how should the generated graph's density change?

## Architecture Onboarding

- **Component map:** Dataset Generator -> Proxy Model ($P_\phi$) -> Diffusion Generator ($G_\theta$) -> Inference Engine
- **Critical path:** The interface between the **Diffusion Generator** and the **Proxy Model**. The generator outputs a probability matrix $\hat{A}_0$; this must be sampled into discrete candidates $\{A_{0,k}\}$ for the proxy to score them. If this sampling is too deterministic or too noisy, the guidance fails.
- **Design tradeoffs:**
  - **Candidate Count ($K$):** Higher $K$ improves the quality of the guidance but linearly increases inference latency.
  - **Proxy Complexity:** A deeper GNN proxy is more accurate but slows down the ZO optimization loop.
  - **Diffusion Steps ($T$):** More steps allow finer refinement but cost more compute.
- **Failure signatures:**
  - **Mode Collapse:** The generator produces only "Chain" or "Star" topologies regardless of task complexity.
  - **Proxy Exploit:** The generator creates weird, non-sensical graph structures that trick the proxy into predicting high rewards but fail in actual simulation (distribution shift).
  - **Disconnected Components:** The guided denoising accidentally removes critical edges, leaving isolated agents.
- **First 3 experiments:**
  1. **Sanity Check (Proxy vs. True):** Plot Proxy predicted reward vs. Actual LLM-MAS reward on a held-out test set of topologies. Verify correlation.
  2. **Ablation (Guidance):** Run GTD with "Random Guidance" (selecting candidates randomly) vs. "Proxy Guidance" on a simple benchmark (e.g., GSM8K) to isolate the impact of the ZO optimization.
  3. **Scalability Test:** Measure the inference latency of the topology generation as the number of agents $N$ increases from 5 to 20.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the GTD framework effectively scale to large-scale multi-agent systems (e.g., >50 agents) without suffering from performance degradation or computational bottlenecks?
- Basis in paper: [Inferred] from Figure 6(a), which shows that task accuracy peaks with 4 agents and exhibits diminishing returns or slight degradation with larger teams, suggesting a potential scalability limit in the current architecture.
- Why unresolved: The experiments primarily focus on small teams (3-4 agents), and while Appendix D lists memory usage for 1000 agents, actual task performance and token efficiency at that scale remain unverified.
- What evidence would resolve it: Benchmarks of GTD on complex tasks requiring dozens of specialized agents, demonstrating that the generated topologies remain sparse and the denoising network remains computationally tractable.

### Open Question 2
- Question: Is the framework capable of dynamically rewiring the communication topology in real-time as the task execution progresses, rather than generating a static structure pre-execution?
- Basis in paper: [Inferred] from Figure 2 ("Inference" phase), which depicts the topology synthesis as a one-time generation step that occurs before the multi-agent simulation begins.
- Why unresolved: The current method generates a topology $A_0$ conditioned on the initial task query; it is unclear if the system can adapt the graph if the agents encounter unforeseen complexities or state changes mid-task.
- What evidence would resolve it: An extension of the method where the diffusion process is re-triggered or refined based on intermediate agent outputs, with experiments showing improved performance on tasks with volatile requirements.

### Open Question 3
- Question: How sensitive is the generated topology to the distribution shift between the proxy model's training dataset and the complexity of novel test queries?
- Basis in paper: [Explicit] in Section 4.1, which notes the training dataset is derived from "50 samples from the GSM8K dataset," and Theorem C.5, which explicitly bounds the performance gap by the proxy's approximation error ($\epsilon_{max}$).
- Why unresolved: The paper demonstrates strong performance on math and code benchmarks, but the theoretical dependence on proxy accuracy implies that out-of-distribution tasks could lead to sub-optimal graph generation if the surrogate model fails to generalize.
- What evidence would resolve it: Ablation studies varying the size and domain diversity of the training dataset $D_{gen}$ to measure the correlation between proxy generalization error and final topology utility.

## Limitations
- The primary limitation is the reliance on the proxy model's accuracy. If the proxy model's error $\epsilon$ is high, the zeroth-order optimization can steer the topology generation toward suboptimal regions.
- The paper does not extensively discuss the computational overhead of generating $K$ candidates at each of the $T$ diffusion steps, which could become prohibitive for large agent populations.
- The assumption that high-performing topologies lie on a learnable manifold reachable by reversing a Gaussian noising process is a potential weak point; if the space of valid communication graphs is highly non-convex or disconnected, the diffusion process may fail to converge to optimal solutions.

## Confidence
- **High Confidence:** The core mechanism of using graph diffusion models for topology generation is well-established in related literature (e.g., "Topology Generation of UAV Covert Communication Networks"). The iterative denoising approach for navigating multi-objective trade-offs is also a standard application of diffusion models.
- **Medium Confidence:** The effectiveness of the zeroth-order optimization for guiding the diffusion process with a proxy model is plausible, but the paper's results are heavily dependent on the proxy's accuracy. The claim of significant sparsity gains (up to 90% reduction) is supported by the data but could be sensitive to the specific task and weight settings.
- **Low Confidence:** The assertion that GTD will generalize seamlessly to arbitrary LLM agent tasks is not fully supported. The paper does not provide extensive ablation studies on the sensitivity to hyperparameters like the number of diffusion steps $T$ or the candidate count $K$, which are critical for practical deployment.

## Next Checks
1. **Proxy Generalization Test:** Evaluate the proxy model's predicted reward against the true LLM-MAS reward on a completely new, held-out task set that is disjoint from the proxy's training data. This will quantify the model's robustness to distribution shift.
2. **Scalability and Latency Analysis:** Measure the end-to-end inference time of the GTD pipeline (including proxy evaluation and candidate sampling) as the number of agents $N$ scales from 5 to 50. This will identify the practical limits of the approach.
3. **Hyperparameter Sensitivity Analysis:** Conduct a systematic ablation study varying the number of diffusion steps $T$, the candidate count $K$, and the utility/cost weights $w_u$ and $w_c$. This will determine how sensitive the final topology quality is to these design choices.