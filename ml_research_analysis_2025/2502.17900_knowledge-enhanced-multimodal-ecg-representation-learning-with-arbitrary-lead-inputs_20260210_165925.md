---
ver: rpa2
title: Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead
  Inputs
arxiv_id: '2502.17900'
source_url: https://arxiv.org/abs/2502.17900
tags:
- lead
- learning
- leads
- k-merl
- merl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents K-MERL, a knowledge-enhanced multimodal ECG
  representation learning framework that addresses key limitations in current ECG
  learning approaches. The method extracts structured cardiac knowledge from free-text
  reports using large language models and employs lead-specific processing with dynamic
  masking to handle arbitrary lead combinations.
---

# Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs

## Quick Facts
- arXiv ID: 2502.17900
- Source URL: https://arxiv.org/abs/2502.17900
- Reference count: 30
- Key outcome: 16% average AUC improvement in partial-lead zero-shot classification

## Executive Summary
This paper presents K-MERL, a knowledge-enhanced multimodal ECG representation learning framework that addresses key limitations in current ECG learning approaches. The method extracts structured cardiac knowledge from free-text reports using large language models and employs lead-specific processing with dynamic masking to handle arbitrary lead combinations. Extensive experiments on six external ECG datasets demonstrate state-of-the-art performance, achieving an average 16% AUC improvement in partial-lead zero-shot classification compared to existing methods.

## Method Summary
K-MERL combines knowledge extraction, lead-specific tokenization, and dynamic masking to learn robust ECG representations. The framework uses Llama3.1-70B-Instruct to extract 277 cardiac entities from free-text reports, creating structured binary labels. Each ECG lead is tokenized separately with learnable spatial embeddings, and dynamic lead masking during pre-training enables handling arbitrary lead combinations at inference. The model is trained with contrastive loss plus a cardiac query network that predicts entity labels, achieving superior performance in both zero-shot classification and linear probing tasks across various lead configurations.

## Key Results
- 16% average AUC improvement in partial-lead zero-shot classification
- Single-lead performance (71.61 AUC) outperforms existing methods with 12 leads
- Graceful degradation across 1-12 lead configurations with consistent performance
- State-of-the-art results on six external ECG datasets including PTBXL and CPSC2018

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured cardiac knowledge extracted by LLMs improves ECG-text alignment quality compared to raw free-text reports.
- Mechanism: The LLM extracts positive cardiac-related entities, merges synonyms, and aggregates subtypes into superclasses. This creates a 277-dimensional binary label vector per report. During pre-training, a Cardiac Query Network (FCQ) predicts these labels from ECG features using BCE loss (LCQ), which supplements the standard ECG-report contrastive loss (Lcontrast).
- Core assumption: Entity extraction reduces noise while preserving clinically relevant semantics, and binary labels provide cleaner supervision signals than raw text embeddings.
- Evidence anchors: [abstract] "K-MERL leverages large language models to extract structured knowledge from free-text reports"; [Table 2a] Removing LCQ causes larger performance drop than removing Lcontrast; [corpus] Related work confirms structured knowledge extraction improves medical multimodal learning.

### Mechanism 2
- Claim: Lead-specific tokenization with spatial positional embeddings preserves the unique characteristics of each ECG lead.
- Mechanism: Each lead is tokenized independently into M segments, producing 12×M tokens rather than M aggregated tokens. Learnable lead embeddings (lead1–lead12) are added to capture spatial identity, while shared temporal embeddings (temp1–tempM) capture time information across all leads.
- Core assumption: Leads carry spatially distinct diagnostic information that should not be mixed during tokenization.
- Evidence anchors: [Section 2.2] "Unlike MERL... which generates a single token for a 12-lead ECG temporal segment, we produce tokens separately for each individual lead"; [Table 2b] Removing lead-specific tokenization drops 1-lead AUC from 71.61→68.47; [corpus] ECG domain literature confirms spatial-temporal structure is critical.

### Mechanism 3
- Claim: Dynamic Lead Masking (DLM) during pre-training enables robust handling of arbitrary lead combinations at inference.
- Mechanism: During pre-training, randomly sample number of masked leads from {9,10,11}, then randomly select which leads to mask. Combined with Lead-independent Segment Masking (LSM) at 25% ratio per lead. This exposes the model to diverse lead combinations.
- Core assumption: Random lead masking simulates real-world partial-lead scenarios and forces the model to learn lead-combination-agnostic representations.
- Evidence anchors: [Section 2.3] "This approach ensures the model is exposed to diverse combinations of unmasked and masked leads during pretraining"; [Figure 6a] K-MERL with single lead outperforms MERL with 12 leads; [Table 2d] Removing DLM drops 1-lead AUC from 71.61→67.84; [corpus] Related papers highlight partial-lead clinical scenarios.

## Foundational Learning

- Concept: **Contrastive Learning (InfoNCE-style)**
  - Why needed here: Core training objective (Lcontrast) aligns ECG and text embeddings in shared space.
  - Quick check question: Can you explain why the temperature parameter η=0.07 affects the hardness of negative samples?

- Concept: **Vision Transformer (ViT) Tokenization**
  - Why needed here: ECG signals are split into segments and projected to tokens with positional embeddings.
  - Quick check question: How does adding learnable lead embeddings differ from standard positional embeddings?

- Concept: **ECG Lead Configuration (12-lead, clinical significance)**
  - Why needed here: Understanding why leads I, II, III, aVR, aVL, aVF, V1-V6 have spatial meaning informs the lead-specific design.
  - Quick check question: Why might a single-lead ECG (e.g., Lead I) provide less diagnostic information than full 12-lead?

## Architecture Onboarding

- Component map:
```
Input: ECG signal (12×S) + Report text
  ├─ ECG Encoder (FE): ViT-tiny
  │   ├─ Lead-specific tokenizer (12 leads × M segments)
  │   ├─ Linear projection W: Rp×d
  │   ├─ Lead embeddings: [lead1...lead12] ∈ Rd
  │   ├─ Temporal embeddings: [temp1...tempM] ∈ Rd
  │   └─ Transformer encoder
  ├─ Text Encoder (FT): Med-CPT
  ├─ Cardiac Query Network (FCQ): 4 transformer layers + linear classifier
  └─ Projectors (Pe, Pt): Non-linear projection to shared dimension d

Output: ECG embedding ze, text embedding zt, entity predictions
```

- Critical path:
  1. ECG → Lead-specific tokenization → Add lead/temporal embeddings → ViT encoder → ze
  2. Report → LLM extraction → Entity labels yi
  3. Entity queries Q → Text encoder FT → Query vectors
  4. FCQ(Q, ze) → Entity predictions → BCE loss LCQ
  5. ze, zt → Projectors → Contrastive loss Lcontrast

- Design tradeoffs:
  - Token length 100 optimal (Fig 7a): Larger (200) introduces ambiguity, smaller (25) loses information
  - Mask ratio 25% optimal (Fig 7b): Higher ratios degrade performance
  - 4 transformer layers in FCQ optimal (Table 6b): Diminishing returns beyond this
  - Med-CPT text encoder outperforms BioClinicalBERT/Med-KEBERT (Table 2e): Contrastive pre-training on medical corpus matters

- Failure signatures:
  - Single-lead AUC drops significantly: Check if lead masking strategy was applied correctly
  - Unseen class performance collapses: May indicate entity extraction missed hierarchical relationships
  - Performance fluctuates with lead count: Lead-specific embeddings may not be learning properly

- First 3 experiments:
  1. **Reproduce zero-shot baseline**: Train K-MERL on MIMIC-ECG subset (10K samples), evaluate on PTBXL-Super with 12 leads. Target: AUC within 2% of paper's 76.52.
  2. **Ablate LCQ vs Lcontrast**: Train two variants removing each loss. Verify LCQ removal causes larger drop (per Table 2a).
  3. **Partial-lead stress test**: Evaluate on 1-lead, 3-lead, 6-lead configurations. Verify graceful degradation (per Figure 6a trend).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does K-MERL's performance degrade in real-world clinical settings with extreme noise or artifact interference compared to the relatively clean benchmark datasets?
- Basis in paper: [explicit] The authors state in the Limitations section that "further evaluation is needed to assess K-MERL’s effectiveness in real-world clinical settings, where data quality and noise levels can be more challenging."
- Why unresolved: Current evaluations utilize curated public datasets (PTBXL, CSN) which may not reflect the signal quality of emergency or wearable-device data.
- What evidence would resolve it: Performance metrics (AUC, F1) from prospective studies or tests on noisy, uncurated ECG datasets from wearable devices or emergency transport.

### Open Question 2
- Question: Can the knowledge extraction mechanism be improved to capture highly specialized domain knowledge that general-purpose LLMs might overlook?
- Basis in paper: [explicit] The Limitations section notes the framework's reliance on LLMs "may be limited by the model's ability to capture highly specialized domain knowledge."
- Why unresolved: The study utilized general-purpose Llama3.1 without domain-specific fine-tuning, potentially missing rare or nuanced cardiac entities.
- What evidence would resolve it: A comparative study integrating domain-adapted LLMs or structured knowledge graphs against the current general-purpose approach.

### Open Question 3
- Question: Does the diagnostic performance vary significantly depending on *which* specific leads are missing, rather than just the number of leads available?
- Basis in paper: [inferred] While the paper demonstrates robustness to the *count* of leads (1 to 12) via dynamic masking, it does not analyze performance drops based on specific lead combinations (e.g., missing precordial V1-V6 vs. limb leads).
- Why unresolved: The dynamic lead masking strategy uses random sampling during pre-training, potentially masking the clinical importance of specific lead loss.
- What evidence would resolve it: A fine-grained ablation study evaluating zero-shot performance on specific subsets of missing leads (e.g., single-lead I vs. single-lead V1).

## Limitations

- Performance may degrade in real-world clinical settings with noisy or artifact-contaminated ECG signals
- Knowledge extraction quality depends on LLM's ability to capture specialized domain knowledge
- Scalability to larger entity vocabularies and complex hierarchical relationships is uncertain

## Confidence

**High Confidence Claims:**
- Lead-specific tokenization with spatial embeddings improves performance over lead-agnostic approaches
- Dynamic Lead Masking enables robust zero-shot classification on partial-lead inputs
- Knowledge extraction improves ECG-text alignment quality compared to raw text embeddings

**Medium Confidence Claims:**
- 16% average AUC improvement over existing methods (valid for specific datasets and protocols)
- Superior performance in linear probing tasks (methodologically sound but dependent on knowledge quality)

**Low Confidence Claims:**
- Framework's effectiveness on extremely rare cardiac conditions not well-represented in MIMIC-ECG
- Performance with non-standard lead configurations outside MIMIC-ECG scope

## Next Checks

**Check 1: Entity Extraction Error Analysis**
Run the Llama3.1-70B-Instruct pipeline on 100 randomly sampled MIMIC-ECG reports and manually verify accuracy of extracted cardiac entities, coverage of clinically important diagnostic terms, and frequency of entity extraction failures or hallucinations.

**Check 2: Systematic Lead Configuration Testing**
Evaluate K-MERL on clinically meaningful partial-lead subsets (limb leads only, precordial leads only), non-adjacent lead combinations (Lead I + V3 + aVF), and synthetic lead configurations with known diagnostic value to understand spatial reasoning capabilities.

**Check 3: Knowledge Scalability Experiment**
Test the framework with expanded entity vocabularies (500, 1000 entities) using the same LLM pipeline, multi-label entity prediction instead of binary classification, and entity hierarchies with parent-child relationships to measure computational overhead and performance changes.