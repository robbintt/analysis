---
ver: rpa2
title: Interpreting Multilingual and Document-Length Sensitive Relevance Computations
  in Neural Retrieval Models through Axiomatic Causal Interventions
arxiv_id: '2505.02154'
source_url: https://arxiv.org/abs/2505.02154
tags:
- term
- query
- patching
- retrieval
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study validates and extends work on interpretability in neural
  retrieval models using axiomatic causal interventions. It reproduces key experiments
  on term frequency encoding and applies activation patching to Spanish, Chinese,
  and document-length focused tasks.
---

# Interpreting Multilingual and Document-Length Sensitive Relevance Computations in Neural Retrieval Models through Axiomatic Causal Interventions

## Quick Facts
- **arXiv ID:** 2505.02154
- **Source URL:** https://arxiv.org/abs/2505.02154
- **Reference count:** 18
- **Primary result:** Activation patching validates term frequency localization in CLS token across languages; no clear attention heads for multilingual/length tasks

## Executive Summary
This study validates and extends work on interpretability in neural retrieval models using axiomatic causal interventions. It reproduces key experiments on term frequency encoding and applies activation patching to Spanish, Chinese, and document-length focused tasks. Results confirm that term frequency information is localized across query term occurrences and later concentrated in the CLS token, with similar patterns across languages. Document-length information is also found in the CLS token. While specific attention heads were identified for English term frequency tasks, no clear heads emerged for multilingual or length-focused tasks. The findings support the activation patching method’s effectiveness but highlight challenges in generalization and reproducibility.

## Method Summary
The study employs activation patching to identify causal mechanisms in neural retrieval models by isolating information flow through targeted perturbations. It uses the TAS-B model (DistilBERT-based) and applies axiomatic causal interventions based on TFC1 (term frequency compliance) and LNC1 (length normalization compliance) axioms. The methodology involves creating perturbed document variants, caching activations from perturbed runs, and patching them into baseline runs to measure causal impact. Experiments are conducted across English, Spanish, and Chinese datasets from mMARCO, examining term frequency localization and document length encoding at token, attention head, and layer levels.

## Key Results
- Term frequency information localizes across query term occurrences and concentrates in the CLS token, with similar patterns across English, Spanish, and Chinese
- Document-length information is found in the CLS token, though no specific attention heads were identified for this computation
- Four attention heads (L0H9, L1H6, L2H3, L3H8) were identified for English term frequency tasks, but no clear heads emerged for multilingual or length-focused tasks

## Why This Works (Mechanism)

### Mechanism 1: Term Frequency Localization via Activation Patching
- **Claim:** Term frequency information causally influences relevance scores through specific token positions and is aggregated into the CLS token in later layers.
- **Mechanism:** Activation patching replaces cached activations from a perturbed run (with modified term frequency) into a baseline run. If patching a specific token/layer recovers the perturbed relevance score, that location causally carries term frequency information.
- **Core assumption:** The model follows the TFC1 axiom—higher query term frequency should yield higher relevance scores.
- **Evidence anchors:**
  - [abstract]: "term frequency information is localized across query term occurrences and later concentrated in the CLS token, with similar patterns across languages"
  - [section 6.1.1]: "Following this, the term frequency information is passed to the CLS token, which shows the strongest activation in Layer 5"
  - [corpus]: "Reproducing and Extending Causal Insights Into Term Frequency Computation in Neural Rankers" (FMR 0.544) confirms similar term frequency localization patterns
- **Break condition:** When the model violates TFC1 (relevance decreases despite increased term frequency), the patching metric becomes uninterpretable.

### Mechanism 2: Document Length Encoding in CLS Token
- **Claim:** Document length information is stored primarily in the CLS token pooled representation, consistent with how BERT encodes sequence-level features.
- **Mechanism:** LNC1-based perturbations add non-query tokens to extend document length. Patching reveals which activations causally reduce relevance when length increases without adding relevant terms.
- **Core assumption:** The model should not assign higher relevance to longer documents when query term frequencies remain constant (LNC1 axiom compliance).
- **Evidence anchors:**
  - [abstract]: "Document-length information is also found in the CLS token"
  - [section 6.2.1]: "The append block experiment shows no impact on any token other than the CLS token in the subsequent layers. This is to be expected as document length is not directly connected to any type of token"
  - [corpus]: Weak/no direct corpus evidence on document length mechanisms specifically
- **Break condition:** Single token injections did not produce consistent relevance decreases; required doubling document length with padding tokens.

### Mechanism 3: Attention Head Specialization (English-Only, Task-Specific)
- **Claim:** Four attention heads (L0H9, L1H6, L2H3, L3H8) causally encode term frequency information for English append perturbations, but this pattern does not generalize to multilingual or length-focused tasks.
- **Mechanism:** Individual attention head patching isolates heads whose activations, when replaced, recover the perturbed relevance score.
- **Core assumption:** Term frequency processing is localized to specific heads rather than fully distributed.
- **Evidence anchors:**
  - [abstract]: "no clear heads emerged for multilingual or length-focused tasks"
  - [section 6.1.2]: "reveal the same 4 attention heads that encode the TFC1 axiom, i.e. (Layer 0. Head 9), (1.6), (2.3), (3.8)"
  - [section 7]: "neither extension leads to identifying specific attention heads, which is especially unexpected for the Spanish and Chinese language data"
  - [corpus]: Limited corpus corroboration; attention head interpretability remains underexplored in multilingual retrieval
- **Break condition:** Prepend perturbations, bottom-ranked documents, multilingual inputs, and length-focused tasks all fail to show clear head specialization.

## Foundational Learning

- **Concept:** Axiomatic Information Retrieval (TFC1 and LNC1)
  - **Why needed:** The entire patching methodology depends on designing perturbations that isolate specific retrieval properties (term frequency, length normalization).
  - **Quick check question:** If document A has 3 occurrences of query term Q and document B has 5 (all else equal), which should rank higher per TFC1?

- **Concept:** Activation Patching / Causal Intervention
  - **Why needed:** This is the core interpretability technique—understanding the direction of patching (clean→perturbed vs. perturbed→clean) and the patching impact metric.
  - **Quick check question:** For TFC1-I (term injection), do you cache activations from the baseline or perturbed run?

- **Concept:** Transformer Component Hierarchy (CLS token, residual stream, attention heads, MLP)
  - **Why needed:** Experiments patch at multiple granularities; knowing where sequence-level vs. token-level information lives is essential.
  - **Quick check question:** In BERT-style models, which token typically aggregates sequence-level information for downstream tasks?

## Architecture Onboarding

- **Component map:** Query Encoder -> Document Encoder -> Dot Product -> Ranking Score
- **Critical path:** Create (query, baseline_doc, perturbed_doc) triples → Run model on perturbed input, cache activations → Run model on baseline input, patch cached activations iteratively → Compute patching impact
- **Design tradeoffs:**
  - Append vs. prepend injection: append shows stronger head specialization; prepend better tests "early document" hypothesis
  - Using provided diagnostic dataset vs. recreating: recreation details were insufficient, used original dataset
  - Single-run reporting vs. multiple seeds: paper reports single runs; variance not characterized
- **Failure signatures:**
  - Model violates axiom (relevance doesn't increase/decrease as expected) → patching metric becomes noisy
  - Patching impact scores mix positive/negative values → difficult interpretation
  - Prepend experiments show near-zero attention head impacts → suggests English-append specificity
- **First 3 experiments:**
  1. **Reproduce TFC1-I append block experiment:** Patch residual stream activations by token type; verify CLS token shows strongest Layer 5 activation
  2. **Validate attention head findings:** Patch individual heads for top-10% documents; confirm L0H9, L1H6, L2H3, L3H8 show highest impact
  3. **Test multilingual generalization:** Run identical pipeline on mMARCO Spanish/Chinese; expect block-level patterns to hold but attention head patterns to weaken

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do specialized attention heads for relevance computation exist in multilingual settings, or is the mechanism distributed differently compared to English?
- Basis in paper: [explicit] The authors state, "This could mean that attention in this model works differently for other languages compared to English," noting that specific heads identified in English experiments did not appear in Spanish or Chinese experiments.
- Why unresolved: The extension experiments yielded low impact scores across all attention heads for non-English data, failing to localize the computation to specific components using the current method.
- What evidence would resolve it: Applying alternative interpretability methods (e.g., sparse autoencoders) or circuit analysis to multilingual models to identify if specific heads exist or if the computation is distributed.

### Open Question 2
- Question: How can the activation patching ranking metric be adapted to handle cases where the model violates the underlying retrieval axiom?
- Basis in paper: [explicit] The authors note that the metric assumes a consistent directional change in relevance, but "unexpected cases are not accounted for in the design of the ranking metric," leading to mixed positive/negative scores.
- Why unresolved: The current metric formula assumes the perturbation always increases or decreases relevance relative to the baseline; when the model behaves unpredictably (violating TFC1 or LNC1), the metric becomes uninterpretable.
- What evidence would resolve it: Developing and testing a new patching metric that normalizes for the actual direction of the relevance change observed in the perturbed run.

### Open Question 3
- Question: Can analyzing circuits of interacting components, rather than individual modules, successfully localize document-length information in neural retrievers?
- Basis in paper: [explicit] The conclusion suggests "future research could focus on investigating circuits of components instead of singular modules," as individual head analysis failed to find clear localization for document length.
- Why unresolved: The LNC1 extension showed that while the CLS token holds length information, no specific attention heads were identified, suggesting the mechanism involves complex interactions rather than a single component.
- What evidence would resolve it: A study that patches groups of attention heads and MLP layers simultaneously to identify a sub-network responsible for length normalization.

## Limitations
- The study focuses on a single retrieval model architecture (TAS-B), limiting generalizability across different neural retrieval systems
- Failure to identify consistent attention head patterns for multilingual and length-focused tasks suggests potential methodological constraints or architectural differences across languages
- Term frequency patching experiments show mixed interpretability when the model violates TFC1 axioms, producing uninterpretable patching metrics

## Confidence
- **High Confidence:** Term frequency information localization across query term occurrences and concentration in the CLS token across all tested languages (English, Spanish, Chinese); Document-length information presence in the CLS token; Activation patching method's effectiveness in identifying causal information flow
- **Medium Confidence:** Specific attention head specialization for English term frequency tasks (L0H9, L1H6, L2H3, L3H8); Block-level term frequency patterns in multilingual settings; Layer-wise progression of term frequency information from query tokens to CLS token
- **Low Confidence:** Generalizability of attention head findings across languages and tasks; Single token injection effectiveness for document length experiments; Patching metric interpretability under axiom violations

## Next Checks
1. **Ablation Study on Attention Head Specificity**: Systematically disable the identified attention heads (L0H9, L1H6, L2H3, L3H8) in the English model and measure degradation in term frequency sensitivity to confirm causal importance beyond patching metrics.

2. **Cross-Architecture Validation**: Apply the identical activation patching methodology to a different neural retrieval architecture (e.g., monoBERT or a more recent transformer-based ranker) to test whether observed patterns hold across architectural variants.

3. **Seed Stability Analysis**: Replicate all major experiments across multiple random seeds to quantify variance in patching impact scores and attention head identification, particularly for multilingual and length-focused tasks where results were less consistent.