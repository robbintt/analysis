---
ver: rpa2
title: Knowledge Graph Augmented Large Language Models for Disease Prediction
arxiv_id: '2512.01210'
source_url: https://arxiv.org/abs/2512.01210
tags:
- reasoning
- disease
- paths
- prediction
- kg-guided
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating clinically interpretable
  and grounded reasoning for disease prediction using electronic health records. The
  core method involves a knowledge graph-guided chain-of-thought (CoT) framework that
  maps ICD-9 codes to a biomedical knowledge graph (PrimeKG), extracts disease-relevant
  reasoning paths, and uses these as scaffolds to generate temporally consistent CoT
  explanations.
---

# Knowledge Graph Augmented Large Language Models for Disease Prediction

## Quick Facts
- arXiv ID: 2512.01210
- Source URL: https://arxiv.org/abs/2512.01210
- Reference count: 33
- Primary result: KG-guided CoT fine-tuning on small EHR cohorts (400-1000 cases) achieves AUROC 0.66-0.70 and macro-AUPR 0.40-0.47, outperforming baselines and transferring zero-shot to external cohort with 0.72-0.77 accuracy.

## Executive Summary
This paper addresses the challenge of generating clinically interpretable and grounded reasoning for disease prediction using electronic health records. The core method involves a knowledge graph-guided chain-of-thought (CoT) framework that maps ICD-9 codes to a biomedical knowledge graph (PrimeKG), extracts disease-relevant reasoning paths, and uses these as scaffolds to generate temporally consistent CoT explanations. Lightweight LLMs are then fine-tuned on this KG-anchored supervision corpus. Across ten diseases and small training cohorts (400-1000 cases), the KG-guided models outperform classical baselines, achieving AUROC of 0.66-0.70 and macro-AUPR of 0.40-0.47. They also transfer effectively zero-shot to an external cohort, improving accuracy from ~0.40-0.51 to 0.72-0.77, with blinded clinician evaluations showing strong preference for the KG-guided CoT explanations in clarity, relevance, and correctness.

## Method Summary
The framework generates interpretable disease predictions from structured EHR data by first mapping ICD-9 codes to biomedical knowledge graph (PrimeKG) nodes through a three-stage entity alignment process. For each target disease, relevant clinical features are selected and shortest reasoning paths are extracted from the graph. A large teacher LLM (GPT-4o) generates Chain-of-Thought explanations conditioned on these KG paths and patient features, with the resulting traces filtered to retain only those whose conclusions match ground-truth labels. The filtered CoT corpus is then used to fine-tune smaller, instruction-tuned LLMs (LLaMA-3.1-8B or Gemma-7B), which learn to generate clinically plausible reasoning while making predictions. The approach is evaluated on MIMIC-III with 12,353 labeled visit pairs across 10 diseases, using both held-out test sets and zero-shot transfer to an external cohort.

## Key Results
- KG-guided LLaMA-3.1-8B with 400 training samples achieves AUROC 0.67-0.70 and macro-AUPR 0.40-0.47 across 10 diseases
- Zero-shot transfer to external CRADLE cohort improves accuracy from 0.40-0.51 to 0.72-0.77
- Blinded clinician evaluations show strong preference for KG-guided CoT explanations over baseline models
- KG-anchored supervision acts as effective reasoning prior, enabling data efficiency

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Structured knowledge graph (KG) paths serve as effective scaffolds to reduce hallucination and improve clinical validity in Chain-of-Thought (CoT) reasoning.
- **Mechanism:** The framework maps patient features (ICD-9 codes) to PrimeKG nodes and extracts multi-hop paths. By forcing the LLM to condition its generation on these explicit biomedical relationships (e.g., disease ↔ gene ↔ phenotype) rather than free-form text, the reasoning is anchored in curated medical knowledge.
- **Core assumption:** The relationships in PrimeKG accurately reflect the clinical dependencies required for the prediction task, and the LLM can correctly interpret these graph structures as textual context.
- **Evidence anchors:**
  - [abstract]: "...extracts disease-relevant reasoning paths, and uses these as scaffolds to generate temporally consistent CoT explanations."
  - [method]: "...extract reasoning chains from PrimeKG by computing all shortest paths... [and] use these KG paths as scaffolds to generate temporally consistent CoT explanations..."
  - [corpus]: Neighbor papers (e.g., "Integrating Chain-of-Thought and Retrieval Augmented Generation...") support the general trend of grounding LLMs to reduce hallucinations, though specific PrimeKG efficacy is isolated to this text.
- **Break condition:** If the KG is sparse for specific rare diseases or if the entity alignment (ICD-9 → KG node) fails, the paths will be irrelevant, leading to "garbage in, garbage out" reasoning.

### Mechanism 2
- **Claim:** Label-consistency filtering creates a high-quality supervision corpus for fine-tuning, enabling data efficiency.
- **Mechanism:** The system generates reasoning traces using a teacher LLM (GPT-4o) but discards any trace where the final binary conclusion (Yes/No) contradicts the ground-truth label. This ensures the student model (LLaMA/Gemma) is trained exclusively on reasoning paths that are both logically plausible and outcome-correct.
- **Core assumption:** A reasoning path that ends with the correct label is factually superior to one that ends with an incorrect label, regardless of potential "right answer, wrong reason" scenarios (though clinical validity checks are also applied).
- **Evidence anchors:**
  - [abstract]: "...retaining only samples whose conclusions match observed outcomes."
  - [results]: "With only 400 labeled index visits data, the KG-CoT–tuned LLaMA model attains the best accuracy... suggesting that KG-anchored CoT supervision acts as an effective reasoning prior."
  - [corpus]: Not explicitly covered in provided corpus metadata.
- **Break condition:** If the teacher model consistently fails to generate correct conclusions for difficult cases, the training set may become too small or biased toward "easy" cases, limiting model robustness.

### Mechanism 3
- **Claim:** Lightweight models can learn complex clinical reasoning via fine-tuning on distilled, structured CoT data.
- **Mechanism:** The explicit reasoning steps generated by the large teacher model (GPT-4o) are distilled into smaller 8B/7B parameter models. The paper suggests this allows the smaller models to outperform classical black-box baselines (like XGBoost) by learning the "why" (mechanistic paths) alongside the "what" (prediction).
- **Core assumption:** The reasoning capabilities are contained within the structure of the text data and can be transferred via standard fine-tuning (AdamW), rather than requiring specialized architectural modifications for graph processing.
- **Evidence anchors:**
  - [results]: Table 2 shows LLaMA-3.1-8B + KG-CoT outperforming XGBoost and Random Forest in AUPR and Accuracy.
  - [discussion]: "KG-anchored CoT supervision acts as an effective reasoning prior, helping small LLMs learn clinically meaningful decision boundaries from limited data."
  - [corpus]: "Memorize and Rank..." (neighbor paper) supports the general concept of elevating LLMs for diagnosis via specific training strategies.
- **Break condition:** If the student model capacity is too low to internalize the graph-topology logic expressed in text, it may revert to superficial pattern matching.

## Foundational Learning

- **Concept: Knowledge Graphs (KG) & Entity Alignment**
  - **Why needed here:** The core of this paper relies on mapping messy clinical codes (ICD-9) to clean graph nodes (PrimeKG). Without understanding "nodes," "edges," and "entity resolution" (exact vs. semantic matching), the input pipeline is a black box.
  - **Quick check question:** If an ICD-9 code has no exact match in PrimeKG, what similarity metric does the paper use to find a candidate node?

- **Concept: Chain-of-Thought (CoT) Prompting**
  - **Why needed here:** The paper moves beyond simple classification to generate "reasoning traces." You need to understand how prompt engineering guides an LLM to output intermediate steps before a final answer.
  - **Quick check question:** Does the paper use CoT primarily for human interpretability, as a supervision signal for smaller models, or both?

- **Concept: Data-Centric AI / Knowledge Distillation**
  - **Why needed here:** The innovation is less about a new neural architecture and more about generating a high-quality *dataset* to teach a smaller model. Understanding how a "teacher" model generates training data for a "student" model is crucial.
  - **Quick check question:** How does the "filtering" step ensure the quality of the distilled knowledge before the student model is trained?

## Architecture Onboarding

- **Component map:** Input Layer (MIMIC-III EHR) -> KG Interface (PrimeKG + 3-Stage Entity Mapper) -> Path Miner (Shortest-path extraction + GPT-4o Pruning) -> Data Generator (GPT-4o prompted with paths + patient features) -> Filter (Matches CoT conclusion against Ground Truth) -> Student Model (LLaMA-3.1-8B or Gemma-7B Fine-Tuned on surviving CoT data)

- **Critical path:** The **Entity Mapper → Path Miner** link. If the mapper fails to link a patient's ICD codes to the KG, the Path Miner finds no connection to the target disease, and the resulting CoT lacks specific biomedical evidence.

- **Design tradeoffs:**
  - **GPT-4o vs. Heuristics:** Using GPT-4o for path pruning and validation ensures clinical relevance but introduces cost ($100 API cost cited) and latency compared to simple graph traversal.
  - **Path Length (L=5):** Capping paths at 5 hops limits complexity but avoids "overthinking" or spurious remote connections.
  - **Filtering Strictness:** Strict label matching guarantees logical consistency with outcomes but may reduce the training set size significantly (data efficiency vs. data volume tradeoff).

- **Failure signatures:**
  - **"Trigger-happy" predictions:** Untuned baselines tend to predict "Yes" (positive outcome) too frequently based on weak signals.
  - **Hallucinated Context:** Models inventing clinical details not present in the EHR input.
  - **Empty Paths:** If a disease or feature isn't in PrimeKG, the model falls back to generic reasoning, losing the "Interpretable" advantage.

- **First 3 experiments:**
  1. **Sanity Check the Mapper:** Run the 3-stage mapping pipeline on a sample of MIMIC codes to verify the "LLM-based filtering" (Stage 3) actually corrects semantic mismatches.
  2. **Path Visualization:** For a single "Acute Myocardial Infarction" case, print the extracted PrimeKG paths. Do they make medical sense (e.g., linking hypertension to heart disease)?
  3. **Filtering Ablation:** Train the student model on the *unfiltered* CoT dataset (including mismatched conclusions) vs. the filtered dataset to quantify the performance gain from the strict supervision signal.

## Open Questions the Paper Calls Out
- **Question:** Does integrating unstructured clinical text and additional knowledge graphs improve the nuance and accuracy of the generated reasoning?
  - **Basis in paper:** [explicit] The authors state that future work involves "extending the framework to richer EHR views (notes, medications, labs) and additional KGs" to support more nuanced multimodal reasoning.
  - **Why unresolved:** The current study is restricted to structured ICD-9 codes and a single knowledge graph (PrimeKG), potentially missing contextual information available in clinical notes.
  - **What evidence would resolve it:** A comparison of model performance (AUROC/AUPR) and explanation quality when fine-tuned on a multimodal dataset versus the current structured-only approach.

- **Question:** Can advanced graph traversal methods improve explanation quality compared to the current shortest-path extraction?
  - **Basis in paper:** [explicit] The authors suggest "moving beyond simple shortest paths to richer graph reasoning may improve explanation quality."
  - **Why unresolved:** The current method relies on shortest paths to limit "overthinking," but this heuristic may omit relevant, complex biological mechanisms that require more hops.
  - **What evidence would resolve it:** Ablation studies comparing clinician preference ratings for explanations generated using shortest paths versus those using random walks or subgraph sampling.

- **Question:** How robust is the prediction accuracy to errors in the LLM-driven entity mapping and path selection stages?
  - **Basis in paper:** [inferred] The paper notes that the mapping of ICD-9 codes to KG nodes "relies on GPT-4o and heuristic thresholds," acknowledging that this "may introduce subtle errors during data generation."
  - **Why unresolved:** There is no quantitative analysis of how often the GPT-4o filtering fails or how these potential mapping errors propagate to affect the final prediction labels.
  - **What evidence would resolve it:** A sensitivity analysis measuring the degradation of downstream AUROC when synthetic noise is injected into the entity alignment or path selection steps.

## Limitations
- Reliance on curated biomedical knowledge graph (PrimeKG) that may have sparse coverage for rare diseases or clinical contexts
- Heavy dependence on GPT-4o for semantic validation introduces cost and latency bottlenecks
- CoT filtering mechanism may create data scarcity issues if label-consistency rates are low
- Binary disease prediction simplifies complex temporal dynamics of chronic disease progression
- Zero-shot transfer to CRADLE lacks detailed analysis of domain shift between cohorts

## Confidence
- **High confidence:** The knowledge graph scaffolding mechanism improves clinical interpretability of LLM reasoning (supported by blinded clinician evaluations showing strong preference for KG-guided explanations)
- **Medium confidence:** The data efficiency claims (400-1000 cases achieving competitive performance) are well-supported by the results but may not generalize to diseases outside the 10 studied or to different EHR systems
- **Medium confidence:** The zero-shot transfer results are impressive but require deeper investigation into potential data leakage or cohort similarity between MIMIC-III and CRADLE

## Next Checks
1. **Cross-validation stability:** Perform 5-fold cross-validation on the 400-case training cohort to assess variance in model performance and ensure the reported results aren't from an unusually favorable split.
2. **Knowledge graph coverage analysis:** Quantify the percentage of ICD-9 codes that successfully map to PrimeKG nodes and correlate this coverage rate with model performance across different diseases.
3. **Teacher model ablation:** Train a student model on CoT data generated without the label-consistency filtering to empirically measure the performance gain from the supervision signal quality control.