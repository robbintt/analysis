---
ver: rpa2
title: 'Privacy-Preserving Generative Models: A Comprehensive Survey'
arxiv_id: '2502.03668'
source_url: https://arxiv.org/abs/2502.03668
tags:
- data
- synthetic
- privacy
- metrics
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey systematically analyzes privacy and utility metrics
  for generative models, categorizing privacy attacks into training data, attribute,
  model, and identification-based types. It reviews classification, distance, generalization,
  and differential privacy-based metrics, identifying strengths and weaknesses in
  each.
---

# Privacy-Preserving Generative Models: A Comprehensive Survey

## Quick Facts
- arXiv ID: 2502.03668
- Source URL: https://arxiv.org/abs/2502.03668
- Reference count: 40
- Primary result: Systematic analysis of 100+ papers mapping privacy attacks and utility metrics for generative models, identifying critical gaps in fairness integration and cross-domain metric validation.

## Executive Summary
This survey provides a comprehensive taxonomy of privacy attacks and utility metrics for generative models, categorizing four attack types (training data, attribute, model, identification) and reviewing classification, distance, generalization, and differential privacy-based metrics. The study identifies significant gaps including the lack of fairness metrics in differential privacy mechanisms, domain-specific validation challenges for utility metrics, and the need for unified frameworks balancing formal privacy guarantees with outlier resilience. The analysis of 100+ research publications reveals that current approaches often force trade-offs between theoretical privacy guarantees and practical utility, particularly for underrepresented subgroups.

## Method Summary
The survey conducted a systematic literature review starting with approximately 1,200 papers from top-tier conferences and digital sources, filtered to 100 research publications focused on privacy attacks and utility metrics. Papers were mapped to taxonomies covering attack types, privacy metric categories, and utility metric classifications. The review synthesized gaps in current approaches, particularly regarding fairness in differential privacy and cross-domain metric validation, while critically analyzing strengths and weaknesses of existing measurement frameworks.

## Key Results
- Four attack types systematically identified: training data, attribute, model, and identification-based attacks
- Privacy metrics categorized into classification, distance, generalization, and differential privacy-based approaches
- Utility metrics examined through distributional and individual-level measures, with identified domain-specific validation challenges
- Critical gaps highlighted in fairness metrics integration with differential privacy and cross-domain metric applicability

## Why This Works (Mechanism)
The survey's systematic approach to categorizing privacy attacks and metrics creates a structured framework for understanding the privacy-utility trade-off in generative models. By organizing 100+ publications into coherent taxonomies, it enables researchers to identify gaps in current methodologies and understand the relationships between different attack vectors and measurement approaches. The critical analysis of metric strengths and weaknesses provides actionable insights for selecting appropriate evaluation frameworks based on specific use cases and data types.

## Foundational Learning
- **Privacy-Utility Trade-off**: Understanding the fundamental tension between privacy guarantees and model utility is essential for selecting appropriate measurement frameworks and determining acceptable performance degradation.
- **Differential Privacy Mechanisms**: Knowledge of DP noise addition and its impact on utility, particularly for underrepresented subgroups, is critical for implementing privacy-preserving systems.
- **Cross-Domain Metric Validation**: Recognizing that metrics like PSNR and SSIM are biased toward visual perception helps prevent misinterpretation of synthetic data quality in non-image domains.

## Architecture Onboarding
- **Component Map**: Search Databases -> Filter Publications -> Map to Taxonomies -> Synthesize Gaps -> Recommend Future Directions
- **Critical Path**: The systematic literature review process from initial corpus to final taxonomy mapping represents the core workflow, with each filtering step potentially introducing selection bias.
- **Design Tradeoffs**: Comprehensive taxonomy coverage versus manageable review scope, theoretical rigor versus practical applicability, and cross-domain generalization versus domain-specific accuracy.
- **Failure Signatures**: Taxonomy mismatch with emerging methods (>10% papers requiring "Other" categorization), subjective categorization inconsistencies (inter-rater reliability <0.6), and selection bias from incomplete initial corpus.
- **First Experiments**: 1) Execute search strategy to verify initial corpus size, 2) Apply taxonomy to 20 recent papers for coverage validation, 3) Conduct inter-rater reliability test on 20 random papers from final selection.

## Open Questions the Paper Calls Out
### Open Question 1
How can a standardized framework be developed for selecting privacy metrics that effectively balance formal differential privacy guarantees with the need to handle outliers and worst-case scenarios?
The paper notes that determining the right privacy budget is complicated and that while Differential Privacy offers guarantees, it reduces utility. Distance-based metrics often fail to address worst-case possibilities. A unified metric or benchmarking framework quantifying both theoretical privacy budget and empirical resilience to outlier attacks without significant utility loss would resolve this.

### Open Question 2
How can utility fidelity metrics be adapted or validated for specific data modalities (e.g., audio, genomics) to prevent misinterpretation of synthetic data quality?
The survey states it "remains unclear when their scores are meaningful," specifically questioning image metrics like PSNR for audio fidelity and noting the lack of "one-size-fits-all" solutions. Domain-specific validation studies demonstrating that specific fidelity metrics correlate strongly with downstream task performance for non-image data types would resolve this.

### Open Question 3
How can fairness metrics and debiasing techniques be integrated into differential privacy mechanisms to prevent disparate impacts on underrepresented subgroups?
The paper highlights a significant gap in fairness metrics for generative models and notes that Differential Privacy can disproportionately reduce accuracy for underrepresented subgroups. New algorithms that jointly optimize for privacy and fairness, alongside empirical results showing maintained accuracy across sensitive subgroups compared to non-private baselines, would resolve this.

## Limitations
- Subjective interpretation in taxonomy categorization may vary across reviewers, particularly for ambiguous cases between metric categories
- Without access to specific search strings and inclusion/exclusion criteria, independent validation of corpus completeness and selection bias is challenging
- The framework may not fully capture emerging metric types or hybrid approaches that combine multiple measurement strategies

## Confidence
- **High Confidence**: Categorization of four attack types (Training Data, Attribute, Model, Identification) - well-established in privacy literature
- **Medium Confidence**: Classification of privacy metrics into four categories - reasonable but may not capture emerging metric types
- **Low Confidence**: Mapping of utility metrics to distributional versus individual-level measures - subjective, particularly for dual-purpose metrics like FID

## Next Checks
1. Execute proposed search strategy on IEEE Xplore, arXiv, and ACM DL to verify initial corpus size and examine publication year distribution for recency bias
2. Apply survey's taxonomy to a random sample of 20 recent papers (2024-2025) to measure coverage rate and identify gaps requiring taxonomy expansion
3. Conduct inter-rater reliability test with two independent reviewers categorizing 20 randomly selected papers from the final 100 to ensure consistency