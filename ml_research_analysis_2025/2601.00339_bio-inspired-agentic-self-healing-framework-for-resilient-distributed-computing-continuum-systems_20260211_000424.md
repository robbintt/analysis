---
ver: rpa2
title: Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing
  Continuum Systems
arxiv_id: '2601.00339'
source_url: https://arxiv.org/abs/2601.00339
tags:
- failure
- layer
- reasoning
- self-healing
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes ReCiSt, a bio-inspired agentic self-healing
  framework for Distributed Computing Continuum Systems (DCCS). Inspired by biological
  wound healing, ReCiSt maps the phases of Hemostasis, Inflammation, Proliferation,
  and Remodeling to computational layers: Containment, Diagnosis, Meta-Cognitive,
  and Knowledge.'
---

# Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems

## Quick Facts
- arXiv ID: 2601.00339
- Source URL: https://arxiv.org/abs/2601.00339
- Reference count: 40
- Primary result: ReCiSt framework achieves self-healing within tens of seconds with CPU overhead below 10% using LM-powered agents across four distributed computing failure datasets

## Executive Summary
This paper presents ReCiSt, a bio-inspired agentic self-healing framework for Distributed Computing Continuum Systems (DCCS) that maps biological wound-healing phases to computational layers. The framework implements four sequential layers - Containment, Diagnosis, Meta-Cognitive, and Knowledge - each performing specialized functions from immediate fault isolation to long-term knowledge consolidation. Using language models for causal reasoning and adaptive micro-agent proliferation, ReCiSt demonstrates successful autonomous recovery across public fault datasets while maintaining controlled computational overhead.

## Method Summary
ReCiSt implements a four-layer agent-based framework where Containment agents perform immediate fault isolation through k-neighborhood probing, Diagnosis agents construct causal graphs from heterogeneous logs using LM-driven relation identification, Meta-Cognitive agents generate and score hypotheses through adaptive micro-agent proliferation, and Knowledge agents consolidate learning through semantic topic/partition organization. The framework was evaluated on Cloud Stateless, ZooKeeper, Hadoop, OpenSSH, and BGL datasets using four LLM models (o4-mini, gpt-5.1, gpt-5-mini, gpt-5-nano) implemented in Google Colab with LangChain 1.0.8 and text-embedding-3-small.

## Key Results
- Successful self-healing within tens of seconds across all evaluated datasets
- Controlled CPU overhead below 10% for most model-dataset combinations
- Adaptive micro-agent proliferation ranging from 1-35 calls depending on failure complexity
- Decision quality rates showing model-dependent performance (Best rates: 0-100%, Harmful rates: up to 31.8%)

## Why This Works (Mechanism)

### Mechanism 1: Bio-inspired Phase-to-Layer Mapping for Fault Recovery
The framework sequentially activates four layers - Containment (Hemostasis), Diagnosis (Inflammation), Meta-Cognitive (Proliferation), and Knowledge (Remodeling) - each performing specialized functions: immediate fault isolation, causal analysis, adaptive reasoning with micro-agent spawning, and long-term knowledge consolidation. This phased approach prevents premature recovery actions and ensures causal understanding before correction.

### Mechanism 2: LM-Driven Causal Graph Construction from Heterogeneous Logs
The Diagnosis Layer uses language models to extract structured causal relationships from heterogeneous system logs without domain-specific training data. LMs evaluate pairwise relationships between diagnostic variables extracted from logs, constructing directed causal graphs that inform subsequent recovery actions.

### Mechanism 3: Feedback-Driven Micro-Agent Proliferation Regulation
The Meta-Cognitive Layer dynamically regulates reasoning micro-agent populations based on hypothesis quality scores, improving decision quality while controlling computational overhead. Micro-agents spawn when confidence is low and inhibit when hypotheses exhibit high safety and utility, creating a feedback loop analogous to biological angiogenesis regulation.

## Foundational Learning

### Concept: Causal Graph Construction from Observational Data
- **Why needed here:** The Diagnosis Layer builds causal graphs from logs without intervention data. Understanding that correlation ≠ causation, and that temporal precedence is necessary but not sufficient for causal claims, is essential for evaluating whether LM-extracted edges represent true causality.
- **Quick check question:** Given logs showing "high CPU" followed by "connection timeout," what additional evidence would distinguish correlation from causation?

### Concept: Multi-Agent System Coordination Patterns
- **Why needed here:** ReCiSt deploys monitoring agents, negotiation agents, micro-agents, and evaluator agents across four layers. Understanding agent communication protocols, task delegation, and failure isolation patterns helps debug coordination breakdowns.
- **Quick check question:** If a micro-agent fails to return a hypothesis within timeout, should the Meta-Cognitive Layer spawn additional agents or fall back to a default action?

### Concept: Semantic Embedding Similarity for Knowledge Organization
- **Why needed here:** The Knowledge Layer uses embedding similarity (STS with text-embedding-3-small) to match incoming knowledge to existing topics/partitions. Understanding embedding space geometry, threshold selection, and semantic drift is critical for tuning topic and reasoning thresholds.
- **Quick check question:** If two semantically similar but operationally distinct failure patterns (e.g., "network timeout" vs. "authentication timeout") merge into one partition, what failure modes might result?

## Architecture Onboarding

### Component Map
```
┌─────────────────────────────────────────────────────────────┐
│                    ReCiSt Framework                          │
├──────────────────┬──────────────────────────────────────────┤
│ Containment      │ LM-driven monitoring agents α            │
│ Layer            │ - k-neighborhood probing (Δt heartbeat)  │
│                  │ - Task redistribution to viable nodes    │
├──────────────────┼──────────────────────────────────────────┤
│ Diagnosis        │ Log aggregation Li → Variable extraction │
│ Layer            │ - Causal graph construction G_diag       │
│                  │ - Ensemble sub-trees Ψi (parallel)       │
├──────────────────┼──────────────────────────────────────────┤
│ Meta-Cognitive   │ Micro-agent population A_micro           │
│ Layer            │ - DFS path traversal p(k)                │
│                  │ - Hypothesis scoring Γ(H)                │
│                  │ - Proliferation/inhibition feedback      │
├──────────────────┼──────────────────────────────────────────┤
│ Knowledge        │ Rendezvous Points (local/global RPs)     │
│ Layer            │ - Topic/partition organization Z_RP      │
│                  │ - Semantic similarity matching (STS)     │
│                  │ - Merge/split operations                 │
└──────────────────┴──────────────────────────────────────────┘
```

### Critical Path
1. **Failure detection** (Containment): Agent αi detects node Ni failure via heartbeat timeout → flag Ni ∈ F(t)
2. **Causal analysis** (Diagnosis): Retrieve logs Li, extract Xi, build G_diag, generate sub-trees G_diag
3. **Hypothesis generation** (Meta-Cognitive): Spawn micro-agents, traverse paths, score hypotheses, select H*i
4. **Knowledge propagation** (Knowledge): Encode H*i, match to existing topics/partitions or create new, sync to global RP

**Critical bottleneck:** Diagnosis Layer's O(m_i²) pairwise causal evaluation for nodes with many log variables; Meta-Cognitive Layer's LM inference latency for hypothesis generation.

### Design Tradeoffs
| Decision | Option A | Option B | Paper's Choice | Rationale |
|----------|----------|----------|----------------|-----------|
| Agent deployment | Co-located with nodes | Centralized cloud | Geographically distributed k agents | Balances locality with resource constraints |
| LM model selection | Fast/smaller (gpt-5-nano) | Accurate/larger (gpt-5.1) | Evaluated both | Table I shows gpt-5.1 faster recovery but higher CPU; o4-mini best balance |
| Knowledge storage | Single global RP | Hierarchical local/global | Local + global RPs | Reduces sync overhead while enabling cross-system learning |
| Causal graph depth | Exhaustive search | Early termination | DFS with pruning via hypothesis scores | Controlled by θ_pro and θ_inh thresholds |

### Failure Signatures
| Symptom | Likely Layer | Diagnostic Query |
|---------|--------------|------------------|
| Self-healing time > 10 min | Meta-Cognitive | Check micro-agent call count; if high, hypothesis quality scores may be persistently low |
| CPU > 15% sustained | Diagnosis/Meta-Cognitive | Log size Li may be large; check mi (variable count) and sub-tree depth |
| High harmful response rate (>20%) | Meta-Cognitive | Review Γ scoring weights (w1, w2, w3); C_safe may be underweighted |
| Knowledge not consolidating | Knowledge | Check θ_topic and θ_reason thresholds; may be too stringent, preventing merges |
| Cascading containment failures | Containment | Verify k-neighborhood Ni has sufficient viable nodes with Sj = 11 |

### First 3 Experiments
1. **Baseline calibration on single dataset:** Deploy ReCiSt on Cloud Stateless dataset with all four models (o4-mini, gpt-5.1, gpt-5-mini, gpt-5-nano). Measure self-healing time, CPU usage, and decision quality. Reproduce Table I metrics to validate implementation correctness before multi-dataset deployment.

2. **Threshold sensitivity analysis:** Systematically vary θ_pro (proliferation threshold) and θ_inh (inhibition threshold) on Hadoop dataset. Plot micro-agent invocations vs. recovery time to identify optimal tradeoff between reasoning depth and latency. Expect U-shaped curve: too high θ_pro under-explores, too low over-proliferates.

3. **Knowledge consolidation stress test:** Inject repeated similar failures (e.g., multiple network timeouts) and verify Knowledge Layer partition merging behavior. Check whether semantic similarity (STS) correctly groups related failures and whether global RP synchronization completes within acceptable latency. Monitor for partition explosion (failure to merge) or over-merging (distinct failures incorrectly combined).

## Open Questions the Paper Calls Out
None

## Limitations
- Model identifiers (gpt-5-mini, gpt-5-nano, gpt-5.1, o4-mini) do not correspond to publicly documented models as of 2025, creating uncertainty about reproducibility
- Key operational parameters (proliferation thresholds, knowledge consolidation thresholds, scoring weights, neighborhood size) remain unspecified, significantly impacting system behavior
- Causal inference validity is not validated against ground truth, with substantial uncertainty about whether extracted relationships represent true causation versus correlation

## Confidence

**High Confidence Claims:**
- Bio-inspired four-phase mapping to computational layers is internally consistent and architecturally sound
- Layered separation of concerns (containment, diagnosis, meta-cognitive reasoning, knowledge consolidation) represents valid approach to distributed self-healing
- General methodology of using LMs for adaptive reasoning in distributed systems has theoretical merit

**Medium Confidence Claims:**
- Reported healing times (tens of seconds) and CPU overhead (<10%) are plausible given evaluated datasets and model choices
- Decision quality metrics reflect real variations across models and datasets, though absolute values may shift with different LLM versions
- Feedback-driven micro-agent proliferation effectively balances exploration depth with computational cost

**Low Confidence Claims:**
- Specific numerical results (healing times, CPU percentages, micro-agent counts) require exact threshold values and model specifications
- Causal graphs extracted by LM truly represent system failure causality rather than spurious correlations
- Knowledge consolidation approach successfully prevents both topic explosion and over-merging without extensive parameter tuning

## Next Checks

1. **Threshold Sensitivity Analysis:** Systematically vary θ_pro, θ_inh, θ_topic, and θ_reason on the Hadoop dataset to quantify their impact on micro-agent invocations, healing time, and knowledge partition count. Document the parameter space that achieves the reported CPU <10% constraint while maintaining acceptable healing times.

2. **Causal Graph Validation Study:** Create a synthetic failure dataset with known causal relationships. Apply ReCiSt's Diagnosis Layer and compare the extracted causal graphs against ground truth. Measure precision/recall of causal edge detection and analyze failure modes where LLMs produce spurious or miss true causal relationships.

3. **Cross-Dataset Generalization Test:** Deploy ReCiSt on an additional distributed computing failure dataset (e.g., Kubernetes failure logs) not evaluated in the original paper. Compare healing time, CPU overhead, and decision quality against the reported results to assess framework generalizability beyond the original four datasets.