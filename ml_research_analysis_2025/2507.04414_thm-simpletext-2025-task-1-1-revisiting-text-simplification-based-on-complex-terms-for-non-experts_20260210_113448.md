---
ver: rpa2
title: 'THM@SimpleText 2025 -- Task 1.1: Revisiting Text Simplification based on Complex
  Terms for Non-Experts'
arxiv_id: '2507.04414'
source_url: https://arxiv.org/abs/2507.04414
tags:
- texts
- text
- complex
- original
- terms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of simplifying scientific text
  for non-expert readers, focusing on identifying and replacing complex technical
  terms while preserving overall structure and linguistic complexity. The proposed
  method involves detecting complex scientific terms using a keyphrase extraction
  approach with a complexity threshold, then employing small large language models
  (LLMs) with various prompts to simplify the identified terms.
---

# THM@SimpleText 2025 -- Task 1.1: Revisiting Text Simplification based on Complex Terms for Non-Experts

## Quick Facts
- **arXiv ID**: 2507.04414
- **Source URL**: https://arxiv.org/abs/2507.04414
- **Reference count**: 26
- **Key outcome**: Cost-effective LLM-based term simplification with GPT models outperforming Gemini variants for scientific text simplification

## Executive Summary
This paper addresses the challenge of simplifying scientific text for non-expert readers by focusing on identifying and replacing complex technical terms while preserving overall structure and linguistic complexity. The proposed method employs keyphrase extraction to detect complex scientific terms, then uses small large language models with various prompts to simplify these identified terms. Experiments demonstrate that prompts producing texts closer to the original source yield better evaluation scores, with GPT models generally outperforming Gemini models in this specific simplification task.

## Method Summary
The method involves a two-stage approach to text simplification. First, complex scientific terms are identified using a keyphrase extraction approach with a complexity threshold, effectively detecting technical terminology that may be challenging for non-expert readers. Second, small large language models (LLMs) are employed with various prompts to simplify the identified complex terms. The study tests different prompt formulations and compares model performance between GPT-4.1-nano and Gemini variants. The simplification process specifically targets term replacement while maintaining the original sentence structure and overall linguistic complexity of the source text.

## Key Results
- GPT models consistently outperformed Gemini variants in simplifying scientific terms for non-experts
- Prompts that produced texts closer to the original source yielded better evaluation scores
- Cost-effective small LLM options combined with complex term identification effectively simplify scientific texts

## Why This Works (Mechanism)
The approach works by leveraging LLMs' ability to understand context and generate appropriate simplifications for complex technical terms while maintaining the original text structure. By focusing specifically on term-level simplification rather than wholesale sentence restructuring, the method preserves the scientific content's integrity while making it more accessible. The keyphrase extraction component effectively identifies the most challenging terminology, allowing the LLM to concentrate its simplification efforts where they're most needed.

## Foundational Learning
- **Keyphrase Extraction**: Needed to identify complex technical terms that require simplification; quick check involves comparing extracted terms against domain-specific glossaries
- **Prompt Engineering**: Required to guide LLMs toward appropriate simplification styles