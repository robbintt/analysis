---
ver: rpa2
title: Achieving Unanimous Consensus in Decision Making Using Multi-Agents
arxiv_id: '2504.02128'
source_url: https://arxiv.org/abs/2504.02128
tags:
- consensus
- deliberation
- blockchain
- unanimous
- agreement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel deliberation-based consensus mechanism
  using Large Language Models (LLMs) as rational agents to achieve unanimous consensus
  in blockchain networks. The approach formalizes a multi-round deliberation framework
  where agents iteratively refine their responses through structured discussions,
  ensuring consistency, agreement, liveness, and determinism.
---

# Achieving Unanimous Consensus in Decision Making Using Multi-Agents

## Quick Facts
- arXiv ID: 2504.02128
- Source URL: https://arxiv.org/abs/2504.02128
- Reference count: 40
- Primary result: LLM-based multi-agent deliberation achieves 80% consensus accuracy on GSM8K dataset

## Executive Summary
This paper introduces a novel deliberation-based consensus mechanism using Large Language Models (LLMs) as rational agents to achieve unanimous consensus in blockchain networks. The approach formalizes a multi-round deliberation framework where agents iteratively refine their responses through structured discussions, ensuring consistency, agreement, liveness, and determinism. Experiments demonstrate that larger LLMs (e.g., 70B parameters) achieve higher accuracy and convergence through deliberation compared to smaller models, with consensus accuracy reaching 80% on GSM8K dataset. The system maintains blockchain properties while addressing challenges like malicious nodes, scalability, and resource consumption.

## Method Summary
The paper proposes a multi-agent consensus framework where LLM-based agents engage in structured deliberation rounds to reach unanimous agreement on blockchain decisions. The mechanism employs iterative refinement through discussion, with agents proposing, debating, and converging on solutions. The framework ensures consistency by requiring all agents to reach the same conclusion, agreement through structured dialogue protocols, liveness by guaranteeing eventual convergence, and determinism through reproducible deliberation processes. Agents are modeled as rational decision-makers using LLM capabilities, with larger models (70B parameters) showing superior performance in achieving consensus compared to smaller variants.

## Key Results
- Larger LLM agents (70B parameters) achieve higher consensus accuracy than smaller models
- Consensus accuracy reaches 80% on GSM8K dataset through deliberation-based approach
- Deliberation time correlates with agent count and number of discussion turns
- Prompt generation emerges as the primary contributor to consensus latency

## Why This Works (Mechanism)
The consensus mechanism leverages LLM agents' reasoning capabilities through structured multi-round deliberation, allowing agents to iteratively refine and converge on solutions. The deliberation framework creates a controlled environment where agents can challenge, justify, and modify their positions until unanimous agreement is reached. Larger models benefit from enhanced reasoning depth and contextual understanding, enabling more sophisticated argumentation and better convergence properties. The blockchain integration ensures that consensus decisions are recorded immutably while maintaining the distributed nature of the network.

## Foundational Learning
- **Multi-agent deliberation protocols**: Structured discussion frameworks enabling agents to exchange and refine information; needed to ensure systematic convergence toward consensus rather than random agreement.
- **LLM parameter scaling effects**: Relationship between model size and reasoning capability; needed to explain why larger models achieve better consensus outcomes.
- **Blockchain consensus properties**: Consistency, agreement, liveness, and determinism requirements; needed to validate that the deliberation mechanism preserves essential blockchain characteristics.
- **Adversarial agent modeling**: Strategies for simulating malicious behavior in consensus systems; needed to evaluate system robustness against coordinated attacks.
- **Latency profiling in LLM systems**: Measurement of time contributions from different system components; needed to identify optimization opportunities for practical deployment.

## Architecture Onboarding

**Component Map**: User Query -> Agent Generation -> Deliberation Rounds -> Consensus Validation -> Blockchain Recording

**Critical Path**: Query reception triggers agent instantiation, followed by iterative deliberation rounds where agents exchange responses until consensus threshold is met, then validated and recorded on blockchain.

**Design Tradeoffs**: Larger models provide better accuracy but increase computational cost and latency; more deliberation rounds improve convergence but extend processing time; aggressive consensus thresholds reduce agreement but increase system responsiveness.

**Failure Signatures**: Non-convergence occurs when agents reach logical impasses; malicious agents cause consensus degradation through strategic ambiguity; resource exhaustion manifests as failed agent generations or deliberation timeouts.

**Three First Experiments**:
1. Baseline comparison of consensus accuracy between different LLM sizes on standardized datasets
2. Latency measurement across varying agent counts and deliberation turn limits
3. Attack simulation testing system behavior under coordinated malicious agent strategies

## Open Questions the Paper Calls Out
The paper acknowledges several open challenges including the system's behavior under various attack vectors (sybil attacks, collusion, or sophisticated adversarial strategies), the relationship between consensus quality and system overhead at scale, and the theoretical grounding for why larger models perform better beyond parameter count.

## Limitations
- Experimental validation primarily conducted on synthetic decision-making tasks rather than real-world blockchain scenarios
- Limited empirical validation of resilience against coordinated or intelligent adversarial behavior
- Relationship between consensus quality and system overhead (computational, latency, resource) at scale is not thoroughly characterized

## Confidence

| Claim Cluster | Confidence Level |
|---------------|------------------|
| Consensus Mechanism Validity | Medium |
| Scalability Claims | Low-Medium |
| Security Against Malicious Nodes | Low |

## Next Checks
1. **Real-world Blockchain Integration Test**: Deploy the consensus mechanism on a small-scale permissioned blockchain network with actual transaction validation scenarios to assess practical performance and identify implementation-specific bottlenecks.

2. **Adversarial Robustness Evaluation**: Design and execute stress tests with malicious agents employing strategies like strategic ambiguity, consensus disruption, or coordinated deception to quantify the system's failure thresholds and recovery mechanisms.

3. **Cross-dataset Generalization Study**: Validate consensus accuracy and convergence properties across diverse domains (e.g., medical diagnosis, legal reasoning, financial forecasting) beyond mathematical problem-solving to assess the framework's versatility and domain-specific limitations.