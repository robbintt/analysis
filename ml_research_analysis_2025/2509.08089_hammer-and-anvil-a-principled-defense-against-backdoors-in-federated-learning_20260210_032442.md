---
ver: rpa2
title: 'Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning'
arxiv_id: '2509.08089'
source_url: https://arxiv.org/abs/2509.08089
tags:
- accuracy
- krum
- defense
- attacks
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of backdoor attacks in federated
  learning, where malicious clients can embed hidden behaviors into the global model
  during training. The authors introduce a new adaptive adversary that surpasses existing
  attacks by optimizing updates based on knowledge of all client updates and the aggregation
  algorithm, requiring as few as one or two malicious clients out of 20 to break state-of-the-art
  defenses.
---

# Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning

## Quick Facts
- **arXiv ID:** 2509.08089
- **Source URL:** https://arxiv.org/abs/2509.08089
- **Reference count:** 40
- **Primary result:** Hammer and Anvil (Krum+) successfully defends against adaptive backdoor attacks in federated learning with ASR < 50% and minimal accuracy degradation

## Executive Summary
This paper addresses backdoor attacks in federated learning where malicious clients can embed hidden behaviors into the global model. The authors introduce a new adaptive adversary that can bypass state-of-the-art defenses by optimizing updates based on knowledge of all client updates and the aggregation algorithm. To counter this threat, they propose Hammer and Anvil (HA), a principled defense approach that combines robust-aggregation-based defenses effective against large-magnitude updates with fine-tuning-based defenses effective against small-magnitude updates. The best variant, Krum+, successfully defends against all adaptive and state-of-the-art attacks across multiple scenarios with minimal accuracy degradation.

## Method Summary
The paper proposes Hammer and Anvil (HA), a defense strategy combining robust aggregation (Krum) with post-training fine-tuning (CSFT). The method trains federated models using Krum aggregation to reject large malicious updates, then applies Clipped Super-Fine-Tuning to remove small backdoors. The defense principle targets different attack magnitudes through orthogonal mechanisms - Krum acts as an "Anvil" against large updates while CSFT acts as a "Hammer" against small updates. The approach requires a clean dataset slice (1-4% of training data) for fine-tuning and uses gradient clipping to stabilize the process.

## Key Results
- Adaptive attack can bypass existing defenses with as few as 1-2 malicious clients out of 20
- Standalone Krum aggregation fails against adaptive attacks (ASR > 90%)
- Standalone fine-tuning approaches fail to remove backdoors while maintaining accuracy
- Krum+ (Krum + Clipped Super-Fine-Tuning) achieves ASR < 50% against all adaptive attacks
- Krum+ maintains clean accuracy within 5% of undefended baseline models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** An adaptive adversary can bypass robust aggregation defenses by optimizing malicious updates to minimize their statistical distance from benign updates while retaining malicious payload.
- **Mechanism:** The attacker calculates the mean of benign updates and projects malicious updates onto a sphere around this mean with dynamically scaled radius to be selected by the defense.
- **Core assumption:** The attacker has full knowledge of the aggregation algorithm, defense parameters, and access to all benign client updates.
- **Evidence anchors:** Section 5.3 describes the adaptive attack on Krum, Section 5.2 states the attack principle, and Corpus [SpectralKrum] shows robust aggregators are vulnerable to Byzantine attacks.
- **Break condition:** If the defense uses a metric orthogonal to l2-norm distance or if the attacker lacks visibility into benign updates.

### Mechanism 2
- **Claim:** Defenses can be categorized by the update magnitude they effectively neutralize, creating a "magnitude dichotomy."
- **Mechanism:** Robust aggregation creates a threshold for large updates, while fine-tuning creates a lower bound for small updates. The defense succeeds if the operating window between thresholds is small or non-existent.
- **Core assumption:** The defender has access to a small, clean dataset for fine-tuning.
- **Evidence anchors:** Section 4's Proposition 1 and 2, and Corpus [FLAegis] proposes a two-layer defense.
- **Break condition:** If the adaptive attack finds a magnitude such that it bypasses both the outlier filter and fine-tuning erasure.

### Mechanism 3
- **Claim:** Combining Krum with Clipped Super-Fine-Tuning creates Krum+, a composite defense that closes the magnitude vulnerability window.
- **Mechanism:** Krum rejects large malicious updates while CSFT erases small, stealthy backdoors that survived aggregation. Gradient clipping prevents the super-fine-tuning learning rate from amplifying noise or residual backdoor signals.
- **Core assumption:** Hyperparameters are tuned such that defense thresholds overlap or leave only a negligible gap.
- **Evidence anchors:** Section 5.6 shows Super-Fine-Tuning fails without gradient clipping, Table 1 demonstrates Krum+ effectiveness, and Corpus [DROP] validates fine-tuning variants.
- **Break condition:** If the number of malicious clients approaches Krum's theoretical limit, Krum may select a malicious update as the "center."

## Foundational Learning

- **Concept: Byzantine-Robust Aggregation (Krum)**
  - **Why needed here:** Understanding how Krum selects updates based on local distances to neighbors is necessary to see why projecting a malicious update into the "center" of benign updates bypasses it.
  - **Quick check question:** If an attacker submits an update with a very large l2-norm, will Krum select it? (Answer: Generally no, unless it has enough colluding neighbors).

- **Concept: Super-Fine-Tuning (SFT)**
  - **Why needed here:** The paper modifies SFT with clipping; understanding the base learning rate schedule is necessary to implement the "Hammer."
  - **Quick check question:** Why does standard SFT fail in federated learning according to the paper? (Answer: It is sensitive to the federated model's training LR and epoch count; clipping stabilizes it).

- **Concept: Adaptive Adversaries**
  - **Why needed here:** Unlike static attacks, this attacker changes strategy based on the specific defense state.
  - **Quick check question:** What information does the adaptive attacker in this paper possess that standard attackers do not? (Answer: Knowledge of all other client updates and the defense algorithm).

## Architecture Onboarding

- **Component map:** Server -> Aggregator (FedAvg + Defense) -> Post-Processor (CSFT) <- Malicious Client (Optimizer)
- **Critical path:** Standard FL training loop with clients -> Server receives updates -> Apply Defense 1 (e.g., Krum) to select/aggregate updates -> After training, apply CSFT to final model using clean data
- **Design tradeoffs:** Fine-tuning Data Size: 1% data improves defense success but hurts accuracy more than 4%. Clipping Threshold: Too low clips benign signal; too high lets backdoor survive.
- **Failure signatures:** High ASR, High Accuracy (Krum alone) indicates adaptive attack success. Low Accuracy, Low ASR indicates CSFT clipping is too aggressive. High ASR, Low Accuracy indicates Defense 1 failing or CSFT overfitting.
- **First 3 experiments:** 1) Implement FL with n=20 clients, Badnet-style backdoor trigger, and equal data splits. Reserve 4% samples for fine-tuning. 2) Implement adaptive attack on Krum: project malicious mean toward benign mean with r=1.5×score(w_l)/p. 3) Combine the two. Run adaptive attack but apply CSFT post-aggregation. Verify if ASR < 50% and Accuracy drops < 5%.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the quantitative size of the theoretical "operating window" (δ1 - δ2) where backdoors can succeed?
- **Basis in paper:** Section 4 explicitly poses the research question about the magnitude of δ1 - δ2.
- **Why unresolved:** The paper proves the existence of the window theoretically but does not provide a method to calculate its precise magnitude.
- **What evidence would resolve it:** A theoretical derivation or empirical estimation of the gap between detection and fine-tuning removal thresholds.

### Open Question 2
- **Question:** Can the Hammer and Anvil principle be effectively generalized to non-image data modalities such as text or audio?
- **Basis in paper:** Section 7 states that reproducing results across other data modalities could help further understanding.
- **Why unresolved:** The evaluation is restricted to image classification using specific triggers and architectures.
- **What evidence would resolve it:** Empirical results applying Krum+ against adaptive adversaries in NLP or audio processing tasks.

### Open Question 3
- **Question:** Can alternative defense components outperform the specific Krum+ configuration?
- **Basis in paper:** Section 7 suggests further studies into principled defenses could yield improvements.
- **Why unresolved:** While Krum+ works, the paper does not exhaustively compare all possible pairs of "Hammer" and "Anvil" defenses.
- **What evidence would resolve it:** A comparative ablation study substituting Krum with other robust aggregators or CSFT with other removal techniques.

## Limitations

- The defense requires a clean dataset slice (1-4% of training data), which may not be available in truly privacy-preserving settings
- Theoretical limits of Krum are reached when malicious client ratio approaches n/2, potentially breaking the defense
- The paper only evaluates on CIFAR-10 and MNIST, limiting generalizability to more complex tasks

## Confidence

**High Confidence:**
- The magnitude dichotomy principle is well-supported by theoretical analysis and experimental evidence
- Krum+ successfully defends against adaptive attacks with ASR below 50% while maintaining high accuracy
- The failure modes of single-layer defenses are clearly demonstrated

**Medium Confidence:**
- The specific implementation details of the adaptive attack optimization
- The exact gradient clipping implementation details and their impact
- The generalizability of the defense principle to other federated learning scenarios

**Low Confidence:**
- The performance of Krum+ against adaptive attacks with m > 2 malicious clients
- The defense's effectiveness against non-backdoor poisoning attacks
- The scalability of the approach to larger model architectures

## Next Checks

1. **Adaptive Attack Vulnerability Analysis:** Systematically vary the number of malicious clients (m=1,2,4,8) and measure Krum+'s defense effectiveness against the full adaptive attack.

2. **Gradient Clipping Sensitivity Study:** Perform an ablation study varying the clipping threshold from 1 to 10 on CIFAR-10 to identify the optimal value that balances backdoor removal with accuracy preservation.

3. **Defense Principle Generalization:** Apply the Hammer and Anvil principle to a different defense combination, such as Median-of-Means + Super-Fine-Tuning, to test if the magnitude dichotomy holds across defense types.