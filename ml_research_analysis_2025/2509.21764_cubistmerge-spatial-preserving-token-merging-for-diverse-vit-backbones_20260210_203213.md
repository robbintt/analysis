---
ver: rpa2
title: 'CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones'
arxiv_id: '2509.21764'
source_url: https://arxiv.org/abs/2509.21764
tags:
- token
- spatial
- tokens
- vision
- reduction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CubistMerge addresses the incompatibility between existing token
  reduction methods and spatial architectures that require structured 2D token layouts.
  The method introduces a 2D reduction strategy that preserves spatial structure by
  reducing tokens sequentially in each dimension, a spatial-aware merging algorithm
  that maintains relative positions using path graphs, and a max-magnitude-per-dimension
  token representation that preserves salient features without attention rescaling.
---

# CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones

## Quick Facts
- arXiv ID: 2509.21764
- Source URL: https://arxiv.org/abs/2509.21764
- Reference count: 15
- Key outcome: 1.25× speedup on SAM-H with only 0.7% mIOU drop off-the-shelf

## Executive Summary
CubistMerge introduces a spatial-preserving token merging strategy designed to work across diverse Vision Transformer (ViT) architectures. The method addresses the fundamental incompatibility between existing token reduction techniques and spatial architectures that require structured 2D token layouts. By preserving spatial relationships during token merging, CubistMerge achieves significant computational efficiency gains while maintaining high accuracy across classification, detection, and segmentation tasks.

The approach is particularly notable for its ability to deliver performance improvements "out-of-the-box" without requiring architectural modifications, fine-tuning, or task-specific training. This universality is achieved through a combination of spatial-aware merging algorithms and max-magnitude-per-dimension token representations that preserve salient features while reducing computational complexity.

## Method Summary
CubistMerge addresses the challenge of token reduction in Vision Transformers by introducing three key innovations. First, it employs a 2D reduction strategy that preserves spatial structure by sequentially reducing tokens in each dimension, avoiding the structural damage caused by traditional flattening operations. Second, it implements a spatial-aware merging algorithm that maintains relative positions using path graphs, ensuring that spatial relationships critical for downstream tasks are preserved. Third, it introduces a max-magnitude-per-dimension token representation that captures salient features without requiring attention rescaling.

The method is designed to be architecture-agnostic, working effectively with both spatial architectures (SAM-H, BEiT, Mask2Former) and non-spatial architectures (DeiT, ResNet). This broad compatibility is achieved through careful consideration of how different architectures handle token structure and spatial information. The approach demonstrates that token merging can be performed while maintaining the structural integrity necessary for high-performance vision tasks.

## Key Results
- Achieves 1.25× speedup on SAM-H with only 0.7% mIOU drop without any fine-tuning
- Delivers 1.15× speedup on DeiT-B with no top-1 accuracy drop on ImageNet within one epoch of fine-tuning
- Outperforms existing token reduction methods across classification, detection, and segmentation tasks on both spatial and non-spatial architectures

## Why This Works (Mechanism)
CubistMerge works by preserving spatial relationships during token reduction, which is critical for vision tasks that rely on structured 2D information. The 2D reduction strategy ensures that tokens are merged in a way that maintains their relative positions, preventing the structural damage that occurs with naive flattening approaches. The spatial-aware merging algorithm uses path graphs to track and preserve the spatial relationships between tokens, ensuring that downstream tasks can still leverage the spatial structure.

The max-magnitude-per-dimension token representation is particularly effective because it captures the most salient features in each dimension without requiring complex attention mechanisms or rescaling operations. This approach reduces computational overhead while maintaining the information necessary for accurate predictions. By avoiding attention rescaling, CubistMerge also reduces the computational complexity associated with token merging operations.

## Foundational Learning
- **Token reduction**: Why needed - reduces computational complexity in ViTs; Quick check - measure FLOPs reduction vs accuracy drop
- **Spatial preservation**: Why needed - maintains structural information critical for vision tasks; Quick check - verify mIOU degradation on segmentation tasks
- **Path graphs**: Why needed - tracks spatial relationships during merging; Quick check - validate that merged tokens maintain relative positions
- **Max-magnitude representation**: Why needed - captures salient features efficiently; Quick check - compare feature importance before/after merging
- **Architecture compatibility**: Why needed - enables broad applicability; Quick check - test across diverse ViT variants (DeiT, BEiT, SAM-H)
- **Computational efficiency**: Why needed - enables practical deployment; Quick check - measure wall-clock time improvement vs theoretical speedup

## Architecture Onboarding
**Component map**: Input tokens → 2D reduction strategy → Spatial-aware merging (path graphs) → Max-magnitude-per-dimension representation → Output tokens

**Critical path**: The spatial-aware merging algorithm is the critical path, as it determines how tokens are selected and combined while preserving spatial relationships. This step directly impacts both the computational efficiency and the accuracy of downstream tasks.

**Design tradeoffs**: CubistMerge trades computational efficiency for spatial preservation. The spatial-aware merging algorithm introduces additional overhead compared to naive token reduction methods, but this overhead is justified by the maintained accuracy and applicability to spatial tasks. The max-magnitude representation sacrifices some information density for computational simplicity.

**Failure signatures**: Performance degradation on tasks requiring fine-grained spatial information, particularly when reduction ratios exceed 6×. Architectures with highly non-standard token layouts may experience reduced compatibility. Extreme reduction scenarios may lead to loss of critical spatial relationships.

**First experiments**:
1. Test 2D reduction strategy on SAM-H with 4× token reduction and measure mIOU impact
2. Validate spatial-aware merging on DeiT-B with 2× reduction and measure ImageNet accuracy
3. Compare max-magnitude representation against attention-based methods on BEiT with 3× reduction

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content. However, based on the evaluation and methodology, implicit questions include: How does the approach perform with extreme reduction ratios (8-16×)? What is the impact on specialized vision tasks beyond the evaluated mainstream benchmarks? How does the computational overhead scale with different hardware configurations?

## Limitations
- Performance on extreme token reduction ratios (8-16×) remains unverified, particularly for tasks requiring fine-grained spatial precision
- The computational overhead of spatial-aware merging algorithms is not thoroughly characterized across different hardware platforms
- Claims of universal "out-of-the-box" compatibility require validation on a broader range of backbone variants and specialized vision tasks

## Confidence
- **High confidence**: The core algorithmic innovations (2D reduction strategy, spatial-aware merging, max-magnitude-per-dimension representation) are well-defined and technically sound
- **Medium confidence**: The empirical results on standard benchmarks are reproducible based on provided methodology, but real-world deployment scenarios may reveal limitations
- **Low confidence**: Claims about "any architecture" compatibility and universal out-of-the-box performance require broader validation

## Next Checks
1. Evaluate CubistMerge on extreme token reduction ratios (8-16×) to assess spatial preservation limits and accuracy degradation patterns
2. Benchmark the method on specialized vision tasks (medical imaging, satellite imagery, fine-grained classification) where spatial structure is paramount
3. Characterize the computational overhead and memory footprint of the spatial-aware merging algorithm across different hardware configurations (CPU, GPU, edge devices)