---
ver: rpa2
title: Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding
  from Reconnaissance Reports
arxiv_id: '2511.14010'
source_url: https://arxiv.org/abs/2511.14010
tags:
- hazard
- retrieval
- arxiv
- knowledge
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents MoRA-RAG, a knowledge-grounded LLM framework
  designed to improve multi-hazard understanding from unstructured reconnaissance
  reports. It addresses limitations of existing RAG systems by introducing a Mixture-of-Retrieval
  mechanism that dynamically routes queries across hazard-specific databases and preserves
  contextual coherence through agentic chunking.
---

# Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports

## Quick Facts
- arXiv ID: 2511.14010
- Source URL: https://arxiv.org/abs/2511.14010
- Reference count: 40
- MoRA-RAG achieves 94.5% accuracy on multi-hazard QA from reconnaissance reports

## Executive Summary
This paper introduces MoRA-RAG, a knowledge-grounded LLM framework designed to improve multi-hazard understanding from unstructured post-disaster reconnaissance reports. The framework addresses key limitations of existing RAG systems by implementing a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while preserving contextual coherence through agentic chunking. A verification loop ensures evidence sufficiency and refines queries when needed. The system was evaluated on HazardRecQA, a dataset of 5,776 QA pairs derived from 90 global hazard events, achieving state-of-the-art performance with 94.5% accuracy.

## Method Summary
MoRA-RAG processes unstructured reconnaissance reports through an agentic chunking pipeline that extracts and groups propositions into coherent semantic units, then generates summaries for each chunk. The Mixture-of-Retrieval mechanism uses a router agent to classify queries into hazard categories (earthquake, flood, hurricane, etc.) and allocates retrieval budget proportionally. The system employs a bi-encoder for initial retrieval of top-50 candidates followed by cross-encoder reranking to select the top-5 most relevant chunks. An agentic evaluation loop iterates up to five times, using an evidence evaluator to check sufficiency, performing online search when needed, and refining queries through reflection and rewriting before generating final answers.

## Key Results
- MoRA-RAG achieves 94.5% accuracy on HazardRecQA benchmark
- Outperforms zero-shot LLMs by 30% and state-of-the-art RAG systems by 10%
- Significantly reduces hallucinations across diverse LLM architectures
- Enables open-weight models to perform comparably to proprietary models

## Why This Works (Mechanism)
The framework's effectiveness stems from three key mechanisms: (1) Agentic Chunking preserves semantic coherence by grouping related propositions rather than using fixed-token boundaries, ensuring each chunk contains complete information units; (2) Mixture-of-Retrieval dynamically routes queries to relevant hazard-specific databases based on predicted probabilities, preventing cross-contamination of context between different hazard types; (3) The agentic verification loop with reflection and rewriting capabilities allows the system to recognize when evidence is insufficient and adaptively search for additional information or reformulate queries.

## Foundational Learning
- **Agentic Chunking**: Breaking text into semantic units that preserve context and meaning; needed to prevent information fragmentation that degrades QA performance; quick check: verify chunks contain complete sentences/ideas without abrupt mid-sentence splits
- **Mixture-of-Retrieval Routing**: Dynamic allocation of retrieval budget across hazard categories based on query classification; needed to maintain focus on relevant domains while allowing cross-hazard exploration; quick check: examine router agent output probabilities for sample queries
- **Bi-encoder + Cross-encoder Pipeline**: Two-stage retrieval with initial broad search followed by precision reranking; needed to balance recall and precision in candidate selection; quick check: verify top-5 candidates cover diverse relevant sources
- **Agentic Evaluation Loop**: Iterative refinement with evidence checking, online search, and query rewriting; needed to handle insufficient evidence scenarios and improve answer quality; quick check: monitor iteration count and evidence sufficiency scores
- **RAG Hallucination Reduction**: Using retrieved evidence to ground LLM responses and verify claims; needed for reliable QA from unstructured sources; quick check: compare hallucination rates between MoRA-RAG and baseline RAG systems

## Architecture Onboarding

Component Map:
Agentic Chunking -> Mixture-of-Retrieval -> Agentic Loop (Evidence Evaluator -> Online Search -> Rewriter -> Answer Writer) -> Final Answer

Critical Path: Query → Router Classification → Bi-encoder Retrieval (L=50) → Cross-encoder Reranking (K=5) → Agentic Loop → Answer Generation

Design Tradeoffs: Mixture-of-Retrieval trades computational overhead for improved precision by routing queries to hazard-specific databases, while agentic chunking trades processing time for semantic coherence. The iterative verification loop increases latency but significantly reduces hallucinations and improves accuracy.

Failure Signatures:
- Low accuracy with small models due to information overload in agentic loop
- Context fragmentation when using fixed-token instead of agentic chunking
- Insufficient evidence handling failures when online search capabilities are limited
- Router misclassification leading to retrieval from wrong hazard databases

First 3 Experiments:
1. Implement agentic chunking on sample reports and verify semantic coherence compared to fixed-token chunking
2. Test mixture-of-retrieval routing with sample queries to verify hazard classification accuracy
3. Execute agentic evaluation loop on simple QA pairs to verify iteration logic and evidence sufficiency checking

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on proprietary or unreleased models (GPT-oss-20B, GPT-5-nano) creates reproducibility challenges
- Dataset generation using GPT-5 nano introduces potential bias and dependency on future model capabilities
- Limited exploration of edge cases involving rare hazard types or ambiguous cross-hazard queries
- Performance sensitivity to evaluator agent capabilities across different LLM architectures

## Confidence
- High Confidence: Core methodology (agentic chunking, mixture-of-retrieval, agentic loop) and relative accuracy improvements over baselines
- Medium Confidence: Absolute performance metrics and hallucination reduction claims due to proprietary model dependencies
- Low Confidence: Generalizability to hazard types and report structures beyond the GEER dataset scope

## Next Checks
1. Replace "GPT-oss-20B" with Llama-3-70B or GPT-4o in agentic loop and measure accuracy degradation to assess model dependency
2. Generate HazardRecQA using GPT-4o with Appendix A prompts, then compare question distributions and answer consistency to evaluate generator sensitivity
3. Implement retrieval pipeline using multiple cross-encoders (bge-reranker-base, cohere-rerank, nomic-embed-text) and measure impact on top-5 reranking accuracy