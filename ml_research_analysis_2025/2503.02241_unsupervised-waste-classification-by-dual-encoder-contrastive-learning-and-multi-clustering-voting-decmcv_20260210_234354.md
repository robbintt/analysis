---
ver: rpa2
title: Unsupervised Waste Classification By Dual-Encoder Contrastive Learning and
  Multi-Clustering Voting (DECMCV)
arxiv_id: '2503.02241'
source_url: https://arxiv.org/abs/2503.02241
tags:
- waste
- classification
- data
- dataset
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of automated waste classification,
  which is crucial for improving processing efficiency and reducing environmental
  pollution. Supervised deep learning methods, while effective, rely heavily on large
  labeled datasets that are costly and inefficient to obtain.
---

# Unsupervised Waste Classification By Dual-Encoder Contrastive Learning and Multi-Clustering Voting (DECMCV)

## Quick Facts
- **arXiv ID:** 2503.02241
- **Source URL:** https://arxiv.org/abs/2503.02241
- **Reference count:** 5
- **Key outcome:** DECMCV achieves 93.78% accuracy on TrashNet and 98.29% on Huawei Cloud datasets, outperforming supervised models with minimal labeled data.

## Executive Summary
This paper addresses the challenge of automated waste classification by proposing an unsupervised method that combines dual-encoder contrastive learning with multi-clustering voting. The approach leverages pre-trained ConvNeXt and VisionTransformer models to generate robust feature representations, then uses a consensus-based clustering mechanism to filter high-confidence samples for supervised fine-tuning. On real-world waste classification tasks, the method requires only 50 labeled samples to accurately classify thousands of images, achieving 29.85% higher accuracy than traditional supervised approaches while reducing labeling costs significantly.

## Method Summary
DECMCV uses a two-stage process: first, it employs dual-encoder contrastive learning where ConvNeXt and ViT extract features from waste images, with ViT embeddings serving as positive samples for ConvNeXt inputs. Second, three clustering algorithms (K-means, Agglomerative Clustering, and BIRCH) independently cluster the features, and samples are retained only if all three algorithms agree on the cluster assignment. The high-confidence subset is then used to train a supervised GoogLeNet classifier. The method processes datasets ranging from 2,527 to 14,802 images across multiple waste categories, achieving classification accuracies above 93% while discarding 27-37% of samples during the voting phase.

## Key Results
- Achieves 93.78% accuracy on TrashNet dataset with 6 waste categories
- Reaches 98.29% accuracy on Huawei Cloud dataset with 4 waste categories
- Improves classification accuracy by 29.85% compared to supervised models on real-world waste data
- Successfully labels 4,169 real-world waste images using only 50 manually labeled samples

## Why This Works (Mechanism)

### Mechanism 1: Cross-Architecture Positive Pairing
Using distinct pre-trained architectures (ConvNeXt and ViT) to generate positive pairs for contrastive learning likely yields more robust feature representations than standard augmentation-based pairing. ConvNeXt (CNN-based) and ViT (Transformer-based) possess different inductive biases. By treating the embedding of an image from one encoder as the positive target for the other, the system forces the learned representation to retain features that are invariant across these two distinct architectural "views," filtering out architecture-specific noise. Core assumption: The feature spaces of ConvNeXt and ViT overlap significantly on "waste" features but diverge on noise; forcing alignment does not erase discriminative class information.

### Mechanism 2: Consensus-based Noise Filtration (Voting)
Agreement between fundamentally different clustering algorithms (K-means, AGG, BIRCH) serves as a high-confidence filter, effectively purifying the dataset at the cost of data volume. K-means favors spherical clusters, AGG creates hierarchical links, and BIRCH handles density. If a sample falls into the same semantic cluster across all three geometries, it is statistically likely to be a "core" instance of that class. Ambiguous boundary cases are discarded rather than mislabeled. Core assumption: Discarding 30-40% of the data (the boundary cases) does not destroy the statistical diversity required to train the downstream supervised classifier.

### Mechanism 3: In-Domain Supervised Fine-Tuning
Training a standard supervised model (GoogLeXt) on a dataset labeled by the unsupervised pipeline effectively bridges the domain gap better than transfer learning from public datasets. The unsupervised pipeline labels *target domain* data (real waste from the specific facility). Training a classifier on this "noisy but domain-accurate" data aligns the decision boundary with the actual distribution of the test environment, ignoring the style differences of public datasets. Core assumption: The accuracy of the unsupervised labeling (>90%) exceeds the negative impact of the remaining labeling errors on the supervised model.

## Foundational Learning

- **Concept: Contrastive Learning (SimCLR/MoCo style)**
  - **Why needed here:** The paper relies on "pulling" positive pairs together and "pushing" negatives apart. Understanding that the loss function operates on relative distances in embedding space is key to grasping why the Dual-Encoder works.
  - **Quick check question:** How does the model know which samples are "positive" if the data is unlabeled? (Answer: In this paper, positive pairs are generated by passing the same image through two different encoders, rather than using augmentations of the same encoder).

- **Concept: Clustering Geometries (K-Means vs. Hierarchical)**
  - **Why needed here:** The voting mechanism fails if you don't understand why different algorithms disagree. K-means assumes globular clusters; Hierarchical (AGG) assumes connectivity.
  - **Quick check question:** Why would K-means fail on a crescent-shaped data cluster where AGG might succeed?

- **Concept: Domain Shift / Distribution Mismatch**
  - **Why needed here:** The primary motivation of the paper is that public datasets (TrashNet) look different from real-world trash (lighting, background).
  - **Quick check question:** Why does a model trained on "clean" internet images fail when classifying "dirty" real-world conveyor belt images?

## Architecture Onboarding

- **Component map:** ConvNeXt & ViT -> Projector -> Contrastive Learning -> K-Means + AGG + BIRCH -> Voter -> GoogLeXt
- **Critical path:** The **Dual-Encoder alignment** is the bottleneck. If the projection heads do not successfully align the ConvNeXt and ViT features, the resulting clusters will be indistinguishable noise, and the subsequent voting will discard the majority of the dataset.
- **Design tradeoffs:**
  - **Data Efficiency vs. Coverage:** The system achieves high accuracy (97%+) but discards ~30-40% of the data (Page 17). You are trading dataset size for label purity.
  - **Complexity vs. Robustness:** Running three clustering algorithms and two backbones is computationally expensive compared to a single K-means pass.
- **Failure signatures:**
  - **High Discard Rate (>60%):** Indicates the encoders are not aligned or the data quality is too poor for the clustering geometries.
  - **Cluster Collapse:** Voting returns only 1 or 2 classes out of the expected 4-6. Indicates the contrastive loss has pushed all embeddings into a single tight ball.
- **First 3 experiments:**
  1. **Visualize Embeddings (t-SNE):** Before clustering, project the Dual-Encoder features to 2D. If classes aren't visually separable, do not proceed to clustering (Page 14, Fig 4).
  2. **Ablate the Voter:** Run the pipeline using only K-means vs. the full Voting mechanism. Compare the "Purity" of the resulting clusters (Page 17, Fig 5-b).
  3. **Domain Stress Test:** Train GoogLeXt on the generated labels and test immediately on the *discarded* data. If accuracy is high (>80%), the domain alignment is successful (Page 19).

## Open Questions the Paper Calls Out

- **Open Question 1:** How does DECMCV performance degrade when applied to fine-grained waste classification tasks with significantly more categories than the four to six tested? Basis: The paper simplifies the Huawei Cloud dataset from 43 subcategories into 4 major categories (Page 6) and caps clusters at 50 (Page 9).
- **Open Question 2:** Can the multi-clustering voting mechanism be refined to recover the 27–37% of data currently discarded due to clustering disagreement? Basis: Tables 1 and 2 report high data discard rates (up to 37%) when the three clustering algorithms fail to reach a consensus (Page 10).
- **Open Question 3:** Is the fixed cluster count of 50 optimal for varying dataset scales, or does it introduce hyperparameter sensitivity? Basis: The methodology explicitly sets the cluster number to 50 for all experiments (K-means, AGG, BIRCH) without providing a selection criteria (Page 9).

## Limitations

- High data discard rate (27-37%) may not be viable for all applications, trading coverage for accuracy
- Computational cost of running three clustering algorithms plus dual encoders may be prohibitive in resource-constrained settings
- Method assumes cross-architecture positive pairing reliably generates meaningful features, dependent on initial encoder quality

## Confidence

- **High Confidence:** Core dual-encoder contrastive learning mechanism and reported performance on TrashNet/Huawei Cloud datasets
- **Medium Confidence:** Real-world application results showing 29.85% improvement, dependent on unsupervised labeling quality characterization
- **Low Confidence:** Claims about generalization to different waste domains or efficient scaling to larger datasets with more classes

## Next Checks

1. **Domain Transfer Test:** Train the full DECMCV pipeline on TrashNet, then test on a completely different waste dataset (e.g., from a different country/region) without fine-tuning to assess domain generalization.
2. **Scaling Experiment:** Apply the method to a dataset with 10+ classes and 50,000+ images to evaluate computational efficiency and whether the voting mechanism maintains accuracy as complexity increases.
3. **Failure Mode Analysis:** Intentionally introduce label noise into the TrashNet dataset (e.g., 20% random mislabeling) and measure how the clustering voting mechanism handles corrupted data—does it reject more samples, or does accuracy degrade significantly?