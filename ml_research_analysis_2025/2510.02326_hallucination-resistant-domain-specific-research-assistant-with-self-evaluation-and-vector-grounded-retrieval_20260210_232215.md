---
ver: rpa2
title: Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation
  and Vector-Grounded Retrieval
arxiv_id: '2510.02326'
source_url: https://arxiv.org/abs/2510.02326
tags:
- confidence
- retrieval
- answer
- table
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RA-FSM, a research assistant that uses a
  finite-state machine to control query processing, improving citation fidelity and
  confidence calibration over standard retrieval-augmented models. By gating relevance,
  scoring answerability, decomposing queries, and restricting citations to session-retrieved
  sources, RA-FSM achieves 85% answer correctness and 0.523 citation F1 versus 77%
  and 0.4 for vanilla GPT, with halved calibration error after isotonic regression.
---

# Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval

## Quick Facts
- arXiv ID: 2510.02326
- Source URL: https://arxiv.org/abs/2510.02326
- Reference count: 26
- Introduces RA-FSM, a research assistant using a finite-state machine to control query processing, improving citation fidelity and confidence calibration over standard retrieval-augmented models.

## Executive Summary
This paper introduces RA-FSM, a research assistant designed to reduce hallucinations and improve citation fidelity in domain-specific question answering. By using a finite-state machine to control query processing and grounding answers strictly in retrieved sources, RA-FSM achieves higher answer correctness and better citation quality than standard retrieval-augmented models. The system also includes confidence calibration and self-evaluation mechanisms to further enhance reliability. While it incurs modest latency and cost overhead, RA-FSM offers a practical blueprint for auditable, hallucination-resistant scientific assistants.

## Method Summary
RA-FSM uses a finite-state machine (FSM) to control the query processing pipeline, enforcing strict retrieval-augmented generation (RAG) with session-restricted citations. The system employs a retrieval module to fetch relevant documents, a reasoning module to assess answerability and decompose complex queries, and a grounding module to ensure all claims are backed by retrieved sources. Confidence calibration is performed using isotonic regression on a held-out validation set. The FSM gates each step, preventing hallucination by restricting citations to session-retrieved sources and requiring self-evaluation before finalizing answers.

## Key Results
- RA-FSM achieves 85% answer correctness versus 77% for vanilla GPT-4.
- Citation F1 score improves to 0.523 versus 0.4 for vanilla GPT-4.
- Calibration error is halved after isotonic regression, demonstrating better confidence alignment.

## Why This Works (Mechanism)
RA-FSM works by tightly coupling retrieval and generation through a finite-state machine that enforces strict source grounding. By decomposing complex queries and gating each step, the system ensures that answers are only generated when sufficient evidence is present. The session-restricted citation policy prevents hallucination by disallowing references to sources outside the current retrieval context. Confidence calibration via isotonic regression aligns predicted confidences with actual correctness, improving trustworthiness.

## Foundational Learning
- **Finite-State Machines (FSMs)**: Used to control query processing flow and enforce strict retrieval-grounded generation. Needed to prevent hallucination by gating each step. Quick check: Verify FSM transitions align with retrieval and generation steps.
- **Isotonic Regression**: Applied for confidence calibration to align predicted confidences with empirical correctness. Needed to improve trustworthiness of answers. Quick check: Ensure calibration is performed on a held-out validation set.
- **Vector-Grounded Retrieval**: Ensures all claims are backed by retrieved sources. Needed to enforce strict source grounding and prevent hallucination. Quick check: Confirm retrieved documents are relevant and cited appropriately.

## Architecture Onboarding
- **Component Map**: Query -> FSM -> Retrieval -> Reasoning -> Grounding -> Answer
- **Critical Path**: Retrieval -> Reasoning -> Grounding (each step gated by FSM)
- **Design Tradeoffs**: RA-FSM trades increased latency and cost for improved citation fidelity and reduced hallucination risk.
- **Failure Signatures**: Retrieval failures, overly restrictive citation filtering, or FSM misconfigurations can degrade performance.
- **First Experiments**:
  1. Test FSM transitions with simple queries to ensure correct gating.
  2. Evaluate retrieval quality on a small set of domain-specific queries.
  3. Measure calibration error before and after isotonic regression.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to 100 expert-generated questions from a single domain (computer science), limiting generalizability.
- Reliance on human annotators for correctness and citation quality introduces potential subjectivity.
- Use of isotonic regression assumes availability of a reliable validation set, which may not always be feasible.

## Confidence
- Claim: RA-FSM superiority over vanilla GPT-4 for tested domain and query types. Confidence: High.
- Claim: RA-FSM performance in other domains or with diverse query structures. Confidence: Medium.
- Claim: RA-FSM reduces hallucination risks. Confidence: High.

## Next Checks
1. Test RA-FSM on queries from diverse scientific domains (e.g., biology, physics, social sciences) to assess generalizability.
2. Evaluate long-term retrieval quality over extended sessions with repeated queries.
3. Conduct a user experience study measuring satisfaction and task completion time versus standard models.