---
ver: rpa2
title: 'Flippi: End To End GenAI Assistant for E-Commerce'
arxiv_id: '2507.05788'
source_url: https://arxiv.org/abs/2507.05788
tags:
- product
- user
- query
- queries
- intent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Flippi is an end-to-end GenAI conversational assistant for e-commerce
  that addresses the challenge of navigating vast product landscapes. It uses advanced
  NLP techniques like Query Reformulation, Intent Detection, RAG, Named Entity Recognition,
  and Context Reduction to provide personalized product discovery, decision assistance,
  and offer identification through natural language dialogue.
---

# Flippi: End To End GenAI Assistant for E-Commerce

## Quick Facts
- arXiv ID: 2507.05788
- Source URL: https://arxiv.org/abs/2507.05788
- Authors: Anand A. Rajasekar; Praveen Tangarajan; Anjali Nainani; Amogh Batwal; Vinay Rao Dandin; Anusua Trivedi; Ozan Ersoy
- Reference count: 7
- Primary result: 97% coarse intent accuracy, 90%+ decision assistant accuracy, 94% product comparison relevancy, 1.3M engaged MAU

## Executive Summary
Flippi is an end-to-end conversational AI assistant designed for e-commerce that enables natural language product discovery, decision assistance, and offer identification. The system addresses the challenge of navigating vast product landscapes by leveraging advanced NLP techniques including Query Reformulation, Intent Detection, RAG, Named Entity Recognition, and Context Reduction. Built as a production system with millions of active users, Flippi demonstrates strong performance across multiple evaluation metrics while maintaining conversational engagement.

## Method Summary
Flippi implements an intent-based routing architecture where user queries are first processed by a Standalone Query (SAQ) module to resolve context and generate independent queries, then classified by a fine-tuned DistilBERT model into one of eight coarse intents. The system uses a bi-encoder STS model for context reduction to select relevant product specifications and UGC, with hierarchical fallback from structured catalog data to user reviews. Components are orchestrated through intent-specific flows including search, decision assistance, product comparison, and offer identification, with LLM-based modules for complex reasoning tasks.

## Key Results
- 97% accuracy on coarse intent classification using DistilBERT
- 90%+ accuracy rate for decision assistant helpful answers
- 94% relevancy rate for product comparison responses
- 68% thumbs-up share and 1.3M engaged monthly active users

## Why This Works (Mechanism)

### Mechanism 1
Context fragmentation in multi-turn dialogue is mitigated by converting dependent user queries into context-independent standalone queries before processing. The Standalone Query (SAQ) module leverages an LLM to ingest full session history and current ambiguous input to generate self-contained queries that allow downstream classifiers to operate without complex dialogue state. Core assumption is that LLM can reliably resolve coreference without hallucinating constraints. Break condition occurs at extended turn counts (5+) where SAQ accuracy drops significantly.

### Mechanism 2
Routing efficiency and system latency are optimized by decoupling intent classification from entity extraction using a fine-tuned DistilBERT model. The smaller model predicts one of 8 coarse intents to trigger specific flows, ensuring heavy LLM calls are only executed when necessary. Core assumption is that 8 defined intents cover majority of user needs with sufficient accuracy (~97%) to prevent routing errors. Break condition occurs with ambiguous queries spanning multiple intents that may be misrouted.

### Mechanism 3
Answer reliability for product-specific questions is improved by grounding responses in structured catalog data prioritized over unstructured UGC. The Decision Assistant flow first attempts to answer using factual specifications from product catalog, using bi-encoder STS model to select top 20 relevant specs, only falling back to UGC if generative model fails. Core assumption is structured catalog data is comprehensive and accurate. Break condition occurs with sparse catalog data or irrelevant specs retrieval leading to fallback or hallucination.

## Foundational Learning

- **Concept: Query Reformulation (SAQ)**
  - Why needed here: Users engage in conversational shorthand that downstream systems require complete context-independent sentences to process effectively.
  - Quick check question: If user asks "Show me iPhones" then follows up with "Show me the Pro version," does your system search for "Pro version" or "iPhone Pro"?

- **Concept: Bi-Encoder vs. Cross-Encoder Retrieval**
  - Why needed here: Flippi uses bi-encoder for context reduction to enable fast comparison against thousands of specs, while cross-encoders would be too slow for real-time inference.
  - Quick check question: Why choose bi-encoder for retrieving top 20 specs but potentially more powerful model for generating final answer?

- **Concept: RAG (Retrieval-Augmented Generation)**
  - Why needed here: LLMs don't know current prices or warranty specifics, RAG allows fetching live catalog data to ground responses and reduce factual hallucinations.
  - Quick check question: In Flippi's DA flow, what acts as the "Retriever" and what acts as the "Generator"?

## Architecture Onboarding

- **Component map:** Standalone Query (SAQ) Module (LLM) -> Coarse Intent Model (DistilBERT) -> Intent-specific flows (Search, DA/Compare, Offers/CX)
- **Critical path:** SAQ Module is single point of failure for context; if rewrites "the second one" to wrong product name, ArgsLLM extracts wrong ID and DA answers questions about wrong item.
- **Design tradeoffs:** Latency vs. Accuracy - chose DistilBERT over larger models for high traffic handling; Factuality vs. Engagement - defaults to template response if facts not found, prioritizing safety.
- **Failure signatures:** High Turn Degradation - accuracy drops from ~98% to ~84% in sessions >4 turns; Missing Products in ArgsLLM - empty product list triggers follow-up question loop.
- **First 3 experiments:**
  1. SAQ Unit Test - Input multi-turn conversations with ambiguous pronouns and validate output SAQ query contains correct full product name.
  2. Intent Confusion Matrix - Analyze traffic data to see which intents are most commonly confused and identify needed refinements.
  3. Context Reduction Validation - Measure STS model recall - does top 20 selected specs actually contain answer to user's query?

## Open Questions the Paper Calls Out

### Open Question 1
Can in-house trained LLMs outperform prompt-tuned commercial LLMs on Flippi's e-commerce tasks while reducing latency and cost? The paper relies on commercial LLMs for multiple components and notes exploring in-house trained models promises to further strengthen conversational intelligence.

### Open Question 2
How can multi-turn conversation accuracy be maintained as session length increases beyond 5 turns? Table 3 shows SAQ accuracy drops significantly from 98.65% (turn 1) to 83.96% (turn 5), with no proposed mechanisms to mitigate degradation.

### Open Question 3
What is the long-term impact of Flippi on customer retention and lifetime value compared to traditional search? The paper reports engagement metrics but lacks longitudinal analysis of repeat purchase behavior, churn, or customer lifetime value.

### Open Question 4
How can follow-up question generation be robustly grounded to real-time inventory constraints? The paper notes challenges with suggesting premium brands for low-budget queries and states improving facets service is future direction without validation.

## Limitations

- SAQ module performance degrades significantly in sessions with extended turn counts (5+), dropping from ~98% to ~84% accuracy
- System relies on comprehensive and accurate structured catalog data which may not hold across all e-commerce verticals
- Reported metrics are based on proprietary dataset and internal evaluation framework limiting independent verification

## Confidence

- **High Confidence:** Architectural approach of using DistilBERT for coarse intent classification and hierarchical use of structured catalog data before UGC
- **Medium Confidence:** SAQ module's ability to reliably resolve coreference, though degradation at higher turn counts warrants caution
- **Low Confidence:** Specific LLM models, prompts, and training data details for SAQ, ArgsLLM, and other LLM-dependent modules are not provided

## Next Checks

1. **SAQ Turn-Length Robustness Test:** Evaluate SAQ accuracy on sessions with 4+ turns using diverse test set to quantify degradation and identify failure patterns.

2. **Intent Edge Case Audit:** Manually review queries with low F1 scores to identify common failure modes and assess whether 8-intent schema needs refinement.

3. **Catalog Completeness Impact Analysis:** Measure DA performance on products with sparse specifications to determine frequency of UGC fallback and impact on answer quality.