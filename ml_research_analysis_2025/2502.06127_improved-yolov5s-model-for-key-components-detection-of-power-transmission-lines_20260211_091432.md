---
ver: rpa2
title: Improved YOLOv5s model for key components detection of power transmission lines
arxiv_id: '2502.06127'
source_url: https://arxiv.org/abs/2502.06127
tags:
- detection
- transmission
- yolov5s
- distance
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an improved YOLOv5s model for detecting key
  components of power transmission lines. The authors modified the distance measurement
  in K-means clustering from Euclidean to 1-IoU distance to better match the tall
  and narrow shapes of poles and towers.
---

# Improved YOLOv5s model for key components detection of power transmission lines

## Quick Facts
- arXiv ID: 2502.06127
- Source URL: https://arxiv.org/abs/2502.06127
- Reference count: 40
- mAP@0.5: 98.1% on power transmission line component detection

## Executive Summary
This paper presents an improved YOLOv5s model for detecting key components of power transmission lines including screws, poles, insulators, towers, and vehicles. The authors address three specific challenges: detecting small objects in complex backgrounds, handling objects with extreme aspect ratios, and addressing class imbalance in the dataset. Through modifications including 1-IoU distance clustering, CBAM attention modules, and focal loss, the model achieves state-of-the-art performance with 98.1% mAP while maintaining real-time detection speed of 84.8 FPS on an RTX 2080Ti GPU.

## Method Summary
The improved YOLOv5s model incorporates three key modifications to the original architecture. First, it replaces Euclidean distance with 1-IoU distance in K-means clustering for anchor box generation, better matching the tall and narrow shapes of poles and towers. Second, it adds Convolutional Block Attention Modules (CBAM) to the backbone network to enhance feature representation and improve detection of small objects in complex backgrounds. Third, it applies focal loss to address class imbalance issues, particularly improving recall for minority classes like vehicles and screws. The model was trained on 11,335 images (1920×1080 resolution) augmented from 4,290 original images using ImgAug, with a split of 8:1:1 for training, validation, and testing.

## Key Results
- Achieved 98.1% mAP@0.5 on the power transmission line component detection task
- Improved recall on minority classes: vehicle recall increased from 78.9% to 96.3% with focal loss and data augmentation
- Maintained real-time performance with 84.8 FPS detection rate on RTX 2080Ti
- Outperformed original YOLOv5s and other state-of-the-art detection methods in accuracy

## Why This Works (Mechanism)

### Mechanism 1: 1-IoU Distance for Aspect-Ratio-Sensitive Anchor Matching
The model replaces Euclidean distance with 1-IoU distance in K-means clustering to better match the tall and narrow shapes of poles and towers. Euclidean distance measures only center-point proximity, while 1-IoU measures actual overlap area, capturing shape similarity directly. This produces anchors that better match ground-truth geometry for objects with extreme height-to-width ratios.

### Mechanism 2: CBAM for Feature Saliency Enhancement in Complex Backgrounds
Adding CBAM to the backbone network improves detection of small, dense, or camouflaged targets by learning which channels and spatial locations matter. CBAM applies sequential channel attention (learning "what" features are important) followed by spatial attention (learning "where" to look), suppressing background noise and amplifying target-relevant features.

### Mechanism 3: Focal Loss for Long-Tailed Class Distribution
Focal loss improves recall on minority classes by down-weighting easy negative examples that dominate the loss gradient. Standard cross-entropy loss is overwhelmed by abundant easy examples. Focal loss adds a modulating factor (1-p)^γ that reduces loss contribution from well-classified samples, forcing the optimizer to focus on hard examples—often the underrepresented classes.

## Foundational Learning

- **Concept: Intersection over Union (IoU)**
  - Why needed here: Core to understanding why 1-IoU distance improves anchor clustering for non-square objects
  - Quick check question: Given two boxes with identical centers but one is 10×100 and the other is 20×20, which has higher IoU overlap with a 12×90 ground truth?

- **Concept: Attention Mechanisms (Channel vs. Spatial)**
  - Why needed here: CBAM combines both; understanding the distinction explains why it outperformed SENet (channel-only)
  - Quick check question: If your model detects targets but frequently confuses them with background textures, which attention type would most likely help?

- **Concept: Class Imbalance and Loss Functions**
  - Why needed here: Focal loss is one solution among many (oversampling, weighted loss); knowing alternatives helps diagnose when focal loss is appropriate
  - Quick check question: Your dataset has 10,000 background samples and 100 target samples. Without any intervention, what failure mode would you expect at inference?

## Architecture Onboarding

- **Component map:** Input (640×640 RGB) -> CSPDarknet + CBAM -> PANet -> Detection heads (80×80, 40×40, 20×20) -> Output
- **Critical path:** K-means anchor generation (1-IoU distance) -> Data augmentation via ImgAug -> Training (300 epochs, batch 16, lr 0.01) -> Inference with NMS post-processing
- **Design tradeoffs:** YOLOv5s chosen for speed (84.8 FPS) over larger variants; sacrifice ~2-3% mAP for real-time capability. CBAM adds ~1.5% parameter overhead but improves mAP by 0.8%. Data augmentation 2.6× increased training time but critical for minority classes.
- **Failure signatures:** Low recall on vehicles/screws without focal loss → check class distribution. Missed detections on dark images → verify CBAM is active in backbone. Poor tower localization with overlapping predictions → anchor aspect ratios may need re-clustering.
- **First 3 experiments:** 1) Reproduce baseline YOLOv5s on the provided dataset split to establish mAP reference. 2) Ablate each modification individually (1-IoU only, CBAM only, focal loss only) to isolate contribution. 3) Test on a different power-line dataset (e.g., public insulator dataset from reference [30]) to assess generalization beyond training distribution.

## Open Questions the Paper Calls Out
- How can the proposed component detection model be adapted for fine-grained defect identification, such as distinguishing between intact and broken insulators or missing screws? The current study focuses exclusively on locating and classifying components rather than assessing their functional condition or integrity.
- Can the improved YOLOv5s maintain its real-time detection speed (84.8 FPS) when deployed on the resource-constrained edge computing hardware typically used on UAVs? The computational feasibility of the added CBAM attention mechanism on low-power embedded systems remains unverified.
- How does the 1-IoU distance metric in K-means clustering perform on datasets with diverse object aspect ratios compared to the specific "tall and narrow" distribution of transmission towers? The paper does not isolate the performance impact of the 1-IoU modification on "short" object classes separately from the overall mAP improvement.

## Limitations
- The dataset is proprietary and unavailable for independent verification, limiting reproducibility.
- The paper does not specify focal loss hyperparameters (α and γ values) or exact CBAM insertion points, requiring assumptions that may affect reproducibility.
- Claims are based on comparisons only with YOLOv5s and a limited set of other detectors on the same dataset, without external validation on different power-line datasets.

## Confidence
- **High confidence:** CBAM attention mechanism improves detection accuracy (supported by ablation study in Table 4 and visual evidence in Figure 9)
- **Medium confidence:** 1-IoU distance improves anchor matching for tall/narrow objects (supported by quantitative improvement in Table 3, but mechanism is somewhat self-evident)
- **Medium confidence:** Focal loss addresses class imbalance and improves recall on minority classes (supported by recall improvements in Table 5, but the combined effect with data augmentation is not fully disentangled)

## Next Checks
1. Test the improved model on a public power-line or insulator detection dataset (e.g., from reference [30]) to assess generalization beyond the proprietary training distribution
2. Implement and evaluate each modification (1-IoU clustering, CBAM, focal loss) independently to verify their individual contributions match the reported improvements
3. Verify the class distribution and object aspect ratios in the training data to confirm that the 1-IoU distance and focal loss modifications are appropriately matched to the dataset properties described in the paper