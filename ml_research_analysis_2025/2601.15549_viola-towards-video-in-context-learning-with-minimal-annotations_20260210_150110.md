---
ver: rpa2
title: 'VIOLA: Towards Video In-Context Learning with Minimal Annotations'
arxiv_id: '2601.15549'
source_url: https://arxiv.org/abs/2601.15549
tags:
- learning
- video
- annotation
- in-context
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VIOLA, a framework for video in-context learning
  that reduces annotation costs by combining selective annotation with pseudo-labeling.
  It uses density-uncertainty-weighted sampling to select diverse, representative,
  and informative samples for expert labeling, then generates pseudo-labels for the
  remaining data.
---

# VIOLA: Towards Video In-Context Learning with Minimal Annotations

## Quick Facts
- **arXiv ID**: 2601.15549
- **Source URL**: https://arxiv.org/abs/2601.15549
- **Reference count**: 40
- **Primary result**: Achieves robust video ICL adaptation with minimal annotations using density-uncertainty sampling and confidence-aware retrieval/prompting

## Executive Summary
VIOLA addresses the annotation cost challenge in video in-context learning by combining selective annotation with pseudo-labeling. The framework uses density-uncertainty-weighted sampling to select diverse, representative, and informative samples for expert labeling, then generates pseudo-labels for the remaining data. Confidence-aware retrieval and prompting mechanisms ensure reliable demonstrations are used during inference. Experiments on nine diverse video benchmarks using four MLLMs show that VIOLA significantly outperforms baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.

## Method Summary
VIOLA implements a hybrid pool construction framework for video ICL. First, it extracts InternVideo2 embeddings from unlabeled data and applies GMM clustering with K clusters (where K equals the annotation budget). Within each cluster, it selects one sample maximizing a density-uncertainty score that balances representativeness against model uncertainty. These selected samples receive expert annotations to form the labeled pool D_L. For remaining data, VIOLA performs few-shot inference using D_L as context to generate pseudo-labels, filters them at the 95th percentile confidence threshold, and forms the hybrid pool D_H = D_L ∪ D_P. During inference, it retrieves demonstrations using a composite score of similarity and confidence, then applies confidence-aware prompting that explicitly encodes label source and reliability.

## Key Results
- Improves accuracy by up to 40% on EgoPet compared to random selection baselines
- Reduces false positives on UCF-Crimes while maintaining high recall
- Achieves robust adaptation across varying annotation budgets (B=20 to 100) and model sizes
- Outperforms existing label-efficient frameworks across all nine tested video benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Density-Uncertainty-Weighted Sampling
Selecting samples that balance semantic density with model uncertainty yields more effective demonstrations than diversity-only or uncertainty-only approaches. Gaussian Mixture Models partition the embedding space into K clusters, and within each cluster a selection score weights posterior probability (representativeness) against zero-shot uncertainty (informativeness). One sample per cluster is selected, guaranteeing coverage. Evidence shows λ=0.5 (balanced) outperforms density-only and uncertainty-only on ENIGMA (62.5 vs 60.3/58.5).

### Mechanism 2: Confidence-Aware Retrieval from Hybrid Pool
Retrieving demonstrations using a composite score of similarity and confidence prevents noisy pseudo-labels from degrading context quality. Ground-truth samples receive c_i=1.0, guaranteeing prioritization if semantically relevant. The τ hyperparameter trades off relevance vs. reliability. Ablation shows confidence-aware retrieval alone improves Drive&Act from 16.1% to 17.6%.

### Mechanism 3: Confidence-Aware Prompting with Source Encoding
Explicitly encoding label source and confidence in prompts enables MLLMs to adaptively weight reliance on demonstrations. A formatting function generates different prompt text for ground-truth versus pseudo-labels with confidence scores. This acts as a soft-gating mechanism. Prompting alone improves Drive&Act from 16.1% to 24.3%.

## Foundational Learning

- **In-Context Learning (ICL) for Multimodal Models**: Why needed - VIOLA builds on the premise that MLLMs can adapt to new domains via demonstration-conditioned inference without weight updates. Quick check - Can you explain why ICL avoids backpropagation and what "context slots" means for video inputs?

- **Active Learning Selection Strategies (Diversity vs. Uncertainty)**: Why needed - The density-uncertainty-weighted method synthesizes two classic AL paradigms. Understanding their trade-offs is essential to grasp why outliers harm video ICL specifically. Quick check - Why might diversity-only selection fail for video data with high redundancy and task-irrelevant noise?

- **Semi-Supervised Learning and Pseudo-Labeling**: Why needed - VIOLA's hybrid pool construction depends on generating and filtering pseudo-labels. Confidence thresholding at the 95th percentile is a critical quality-control mechanism. Quick check - What risks arise when pseudo-labels propagate noise into the demonstration pool, and how does VIOLA mitigate this?

## Architecture Onboarding

- **Component map**: Unlabeled Pool (D_U) → [InternVideo2 Encoder] → Embeddings → [GMM Clustering] → K clusters → [Zero-Shot Uncertainty + Density Weighting] → Selection scores → [Oracle/Expert] → Annotated Pool (D_L) → [In-Context Pseudo-Annotation with D_L context] → Pseudo Pool (D_P, filtered at 95th percentile confidence) → Hybrid Pool (D_H = D_L ∪ D_P) → [Confidence-Aware Retrieval: sim^(1-τ) × conf^τ] → Top-K demonstrations → [Confidence-Aware Prompting: source + confidence encoding] → [MLLM Inference] → Prediction

- **Critical path**: GMM clustering quality determines whether selected samples are truly representative; zero-shot confidence estimation must correlate with actual prediction quality; pseudo-annotation uses D_L as context—expert label quality cascades to D_P; retrieval scoring (τ parameter) balances similarity vs. reliability trade-off; prompt formatting must preserve confidence signals for MLLM interpretation

- **Design tradeoffs**: λ (selection balance) - higher λ prioritizes hard/uncertain samples; lower λ favors prototypical examples. Paper uses λ=0.5. τ (retrieval balance) - controls similarity vs. confidence in retrieval. Paper doesn't specify value. Confidence filtering threshold - 95th percentile is aggressive. Budget allocation - smaller budgets increase reliance on pseudo-labels, amplifying noise risk

- **Failure signatures**: Selection captures outliers - if GMM clusters on noisy embeddings, selected samples are unrepresentative; pseudo-label cascading errors - low-quality D_L produces low-quality D_P; retrieval ignores ground truth - if τ is too high and pseudo-labels have inflated confidence; MLLM ignores confidence signals - if model lacks instruction-following strength

- **First 3 experiments**: 1) Validate density-uncertainty selection in isolation - compare λ∈{0, 0.25, 0.5, 0.75, 1} on held-out validation set; measure diversity and downstream ICL accuracy. 2) Ablate confidence-aware retrieval - fix D_H, vary τ∈{0, 0.25, 0.5, 0.75, 1}; compare with and without confidence weighting; measure false positive rate. 3) Test prompting sensitivity across MLLM scales - apply confidence-aware prompting to Qwen2-VL-2B vs. Qwen2-VL-7B; measure whether smaller models benefit less.

## Open Questions the Paper Calls Out
None

## Limitations
- GMM clustering quality depends on embedding space structure and may fail under severe domain shift where semantic relationships become distorted
- Pseudo-label confidence scores may be systematically miscalibrated, potentially amplifying rather than filtering noise
- Effectiveness depends on MLLM instruction-following capability to interpret confidence signals in prompts

## Confidence
- **High confidence**: Overall performance improvements (40% accuracy gains on EgoPet, ROUGE-L improvements on captioning tasks) supported by extensive experiments across nine benchmarks using four MLLM architectures
- **Medium confidence**: Density-uncertainty selection superiority supported by ablation studies but lacks corpus validation for GMM-based selection in video ICL specifically
- **Medium confidence**: Confidence-aware retrieval and prompting mechanisms improving robustness supported by ablation studies but corpus lacks direct validation for confidence-weighted retrieval and confidence-embedded prompting in video MLLMs

## Next Checks
1. Validate clustering quality - implement t-SNE visualization of selected samples across all nine datasets to verify GMM clusters capture meaningful semantic groups rather than outliers
2. Test confidence calibration - measure correlation between pseudo-label confidence scores and actual prediction accuracy on held-out validation set
3. Ablate confidence prompting across scales - compare performance of confidence-aware prompting vs simple prompting across MLLM sizes (2B vs 7B parameters)