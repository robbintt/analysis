---
ver: rpa2
title: 'Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual
  Explanations'
arxiv_id: '2601.20449'
source_url: https://arxiv.org/abs/2601.20449
tags:
- fairness
- recourse
- across
- groups
- group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating fair counterfactual
  explanations (CFs) at individual, group, and hybrid fairness levels for machine
  learning models. The authors propose a model-agnostic reinforcement learning (RL)
  approach using Soft Actor-Critic (SAC) to generate CFs that satisfy fairness constraints
  while preserving CF quality.
---

# Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual Explanations

## Quick Facts
- **arXiv ID:** 2601.20449
- **Source URL:** https://arxiv.org/abs/2601.20449
- **Reference count:** 40
- **Key outcome:** RL-based approach generates fair counterfactuals with 91-98% success rates and 0-11% group disparity

## Executive Summary
This paper addresses the critical challenge of generating fair counterfactual explanations (CFs) that ensure both individual and group fairness in machine learning models. The authors propose a novel model-agnostic reinforcement learning approach using Soft Actor-Critic (SAC) to generate CFs that satisfy fairness constraints while maintaining high quality. Their approach introduces custom reward functions that optimize for equal effectiveness and equal choice of recourse across protected groups. Experiments on three real-world datasets demonstrate that their method achieves high success rates (91-98%) and low proportion differences (0-11%) across groups while maintaining CF quality metrics like validity (91-100%), plausibility, and similarity.

## Method Summary
The paper proposes a reinforcement learning-based approach to generate fair counterfactual explanations using Soft Actor-Critic (SAC). The method treats CF generation as a sequential decision-making problem where the agent iteratively modifies features to achieve the desired outcome. The approach is model-agnostic and introduces custom reward functions that optimize for fairness metrics including Equal Effectiveness (EE) and Equal Choice of Recourse (ECR). The authors evaluate their approach across three datasets (Adult, SSL, Alzheimer) and compare individual, group, and hybrid fairness approaches. Clustering the affected instances into homogeneous subgroups further improves CF quality and fairness maintenance.

## Key Results
- RL-based approach achieves 91-98% success rates in generating valid counterfactuals
- Proportion difference across groups remains low at 0-11% while maintaining CF quality
- Hybrid fairness approach (combining individual and group fairness) provides the best balance, achieving high success rates with low disparity
- Clustering affected data improves CF precision and similarity compared to global generation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reinforcement learning with Soft Actor-Critic (SAC) can generate diverse, valid counterfactuals by treating CF generation as sequential decision-making rather than static optimization.
- **Mechanism:** SAC's entropy regularization maintains stochastic policies, enabling exploration of high-dimensional action spaces. The agent iteratively modifies features (state = change amounts, action = feature index + change magnitude) while maximizing cumulative reward that balances validity, fairness, and proximity.
- **Core assumption:** The sequential decision-making paradigm better captures recourse feasibility than one-shot optimization, as real-world interventions often have dependencies.
- **Evidence anchors:**
  - [abstract] "propose a novel model-agnostic, reinforcement learning based approach to generate CFs that satisfy fairness constraints"
  - [Section IV-D] "The entropy regularization step ensures stochastic policies, making it well-suited for high-dimensional action spaces"
  - [corpus] Weak direct corpus support; related work addresses multi-cost optimization but not RL specifically
- **Break condition:** SAC training fails to converge or reward plateaus before fairness constraints are satisfied.

### Mechanism 2
- **Claim:** Custom reward functions encoding Equal Effectiveness (EE) and Equal Choice of Recourse (ECR) directly optimize fairness metrics without requiring model retraining.
- **Mechanism:** Reward R_EE combines: (1) Average Success Rate across groups, (2) penalty for Proportion Difference, (3) Gower distance similarity penalty, (4) active action count bonus. R_ECR optimizes action diversity per group. R_EE-ECR hybridizes both.
- **Core assumption:** Fairness metrics originally designed for model auditing can be repurposed as generative objectives via reward engineering.
- **Evidence anchors:**
  - [abstract] "We extend existing metrics commonly used for auditing ML models, such as equal choice of recourse and equal effectiveness"
  - [Section IV-C, Eq. 4-6] Formal definitions for EE and ECR
  - [corpus] FACTS reference mentioned as auditing framework
- **Break condition:** Reward components conflict irreconcilably or regularization weights require extensive tuning per dataset.

### Mechanism 3
- **Claim:** Pre-clustering affected instances into homogeneous subgroups improves both CF quality and fairness maintenance.
- **Mechanism:** K-means clustering (k=3) partitions the affected dataset by feature similarity, not protected attributes. CFs generated per-cluster exploit local decision boundary structure, yielding more precise interventions.
- **Core assumption:** Heterogeneity in the full dataset obscures local recourse patterns; subgroups share similar viable action spaces.
- **Evidence anchors:**
  - [Section V-A-5] "Clustering enables the exploitation of local data patterns to identify flexible and varied recourse options"
  - [Takeaway 4] "CFs at cluster level produce more precise and similar outcomes compared to generating them for the entire dataset"
  - [corpus] No direct corpus evidence on clustering for fair CFs
- **Break condition:** Clusters fragment protected groups or cluster boundaries align with sensitive attributes.

## Foundational Learning

- **Concept: Counterfactual Explanations (CFs)**
  - **Why needed here:** CFs provide "what-if" scenarios showing minimal feature changes to flip model predictions. This paper's entire contribution is generating *fair* CFs.
  - **Quick check question:** Given a loan applicant denied (h(x)=0), what constitutes a valid vs. plausible counterfactual?

- **Concept: Soft Actor-Critic (SAC) Algorithm**
  - **Why needed here:** SAC is the RL backbone. Understanding actor-critic architecture and entropy regularization explains why this approach generates diverse CFs.
  - **Quick check question:** How does entropy regularization in SAC encourage exploration versus exploitation in feature space?

- **Concept: Group vs. Individual Fairness Definitions**
  - **Why needed here:** The paper operationalizes hybrid fairness. Distinguishing "similar individuals get similar CFs" (individual) from "groups have equal recourse rates" (group) is essential.
  - **Quick check question:** If two individuals with identical financial profiles but different protected attributes receive different CF costs, which fairness type is violated?

## Architecture Onboarding

- **Component map:** Pre-trained classifier h -> Affected instances extraction -> Optional K-means clustering -> SAC agent with fairness reward function -> CF generation -> Gower distance-based assignment
- **Critical path:**
  1. Train fair classifier (Exponentiated Gradient in-processing)
  2. Extract affected instances (h(x)=0)
  3. Cluster affected data (optional but recommended)
  4. Initialize SAC agent with scenario-specific reward function
  5. Train until convergence (~23k+ timesteps)
  6. Generate n actions per cluster/whole dataset
  7. Assign individuals to best valid CF (lowest Gower distance)
- **Design tradeoffs:**
  - Individual-EE vs. Group-EE: Individual maximizes per-person recourse (highest SR), Group optimizes single action for collective
  - Group-ECR: Maximizes diversity but shows lowest SR (61-79% on Alzheimer) and highest PD (up to 11.1%)
  - Hybrid-EE-ECR: Best balance; maintains high SR (92-100%) with low PD (0-8%)
  - Clustering overhead: More CFs generated but requires per-cluster training
- **Failure signatures:**
  - Low validity (<90%): Check reward weight balance
  - High PD (>10%): Reward not penalizing proportion difference sufficiently
  - Implausible CFs: Feature bounds not enforced
  - SAC non-convergence: Entropy coefficient diverging
- **First 3 experiments:**
  1. Baseline reproduction: Run Individual-EE on Adult dataset targeting 95% ASR with PD <5%
  2. Ablation on regularization weights: Vary C2 (PD penalty) from 0.5 to 2.0 on Alzheimer
  3. Clustering impact assessment: Compare Hybrid-EE-ECR with k=1 vs. k=3 on SSL

## Open Questions the Paper Calls Out
None

## Limitations
- Approach's scalability to datasets with >100 features remains unproven as SAC's performance degrades in high-dimensional action spaces
- Clustering assumption may not hold when protected attributes correlate with cluster features, potentially introducing proxy discrimination
- Fixed k=3 clustering across all datasets lacks justification for optimal cluster number selection

## Confidence
- **High Confidence:** CF validity maintenance (91-100%) and ASR achievement (91-98%) given proper reward tuning
- **Medium Confidence:** Fairness metric improvements (PD 0-11%) assuming no hidden correlations between clustering features and protected attributes
- **Low Confidence:** Hybrid approach's superiority claim without ablation studies comparing to individual EE + post-hoc fairness filtering

## Next Checks
1. Test SAC scalability on high-dimensional datasets (50+ actionable features) with adaptive entropy regularization schedules
2. Conduct sensitivity analysis on clustering k parameter and feature selection for K-means to avoid protected attribute proxies
3. Compare Hybrid-EE-ECR against Individual-EE baseline with post-processing fairness constraints to isolate RL benefit