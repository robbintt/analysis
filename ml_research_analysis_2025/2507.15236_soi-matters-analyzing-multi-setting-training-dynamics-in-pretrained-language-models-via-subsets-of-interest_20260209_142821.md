---
ver: rpa2
title: 'SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language
  Models via Subsets of Interest'
arxiv_id: '2507.15236'
source_url: https://arxiv.org/abs/2507.15236
tags:
- learning
- training
- examples
- performance
- multi-task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Subsets of Interest (SOI), a framework for
  categorizing training examples in language models based on their learning behaviors
  during training. The six SOI categories include unlearned, always correct, one-time
  forgettable, multiple-time forgettable, early-learned, and late-learned examples.
---

# SOI Matters: Analyzing Multi-Setting Training Dynamics in Pretrained Language Models via Subsets of Interest

## Quick Facts
- arXiv ID: 2507.15236
- Source URL: https://arxiv.org/abs/2507.15236
- Reference count: 7
- Primary result: Multi-source learning improves out-of-distribution performance by up to 7%

## Executive Summary
This work introduces Subsets of Interest (SOI), a framework for categorizing training examples in language models based on their learning behaviors during training. The six SOI categories include unlearned, always correct, one-time forgettable, multiple-time forgettable, early-learned, and late-learned examples. Using dataset cartography and SOI transition heatmaps, the authors analyze how examples shift between categories when transitioning from single-setting to multi-setting configurations. Experiments across multi-task, multi-source, and multi-lingual learning show that multi-source learning consistently improves out-of-distribution performance by up to 7%, while multi-task learning shows mixed results. A two-stage fine-tuning approach leveraging SOI-based subset selection further enhances performance, particularly in multi-task settings. The findings offer practical insights for optimizing multi-setting language model training and improving generalization.

## Method Summary
The method categorizes training examples into six Subsets of Interest (SOI) based on their learning dynamics during fine-tuning. A two-stage fine-tuning approach is employed: Stage 1 trains BERT-base or XLM-R-base with shared encoder and task-specific heads for 10 epochs while tracking per-example predictions to compute SOI categories. Stage 2 performs fine-tuning on strategically selected subsets (Strategy III: diagonal heatmap entries excluding ACE→ACE transitions) for 4 epochs. SOI transition heatmaps visualize how examples migrate between learning states when moving from single-setting to multi-setting training configurations.

## Key Results
- Multi-source learning consistently improves out-of-distribution performance by up to 7%
- Two-stage fine-tuning with SOI-based subset selection enhances performance, particularly in multi-task settings where first-stage training caused degradation
- Multi-task learning shows mixed results: sentiment+paraphrase degrades OOD while paraphrase+entailment improves it

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-source learning (same task, different data origins) consistently improves out-of-distribution generalization.
- Mechanism: Training on diverse data distributions for the same task exposes the model to varied stylistic and lexical patterns, reducing overfitting to source-specific artifacts and improving robustness to unseen distributions.
- Core assumption: OOD improvements reflect genuine generalization, not artifact leakage between ID and OOD datasets.
- Evidence anchors:
  - [abstract] "multi-source learning consistently improves out-of-distribution performance by up to 7%"
  - [section 5.1.2] "multi-source learning configuration demonstrated consistent OOD improvements across all six evaluated cases. For Sentiment140, we observed the most significant gain, with a 7% improvement"
  - [corpus] Weak direct support; related work on multi-task learning exists but doesn't specifically validate multi-source OOD gains.
- Break condition: If OOD test sets inadvertently share lexical patterns with multi-source training data, gains may not reflect true generalization.

### Mechanism 2
- Claim: Two-stage fine-tuning with SOI-guided subset selection can recover or improve OOD performance, particularly in multi-task settings where first-stage training caused degradation.
- Mechanism: First-stage multi-setting training may harm OOD for some tasks; second-stage fine-tuning on strategically selected subsets (e.g., diagonal entries excluding ACE→ACE) re-emphasizes informative examples, partially reversing negative transfer.
- Core assumption: The optimal subset selection strategy (method III: diagonal entries excluding ACE→ACE) transfers across multi-task, multi-source, and multi-lingual configurations after tuning on multi-task.
- Evidence anchors:
  - [abstract] "A two-stage fine-tuning approach leveraging SOI-based subset selection further enhances performance, particularly in multi-task settings."
  - [section 5.2.1] "method III produced the highest average out-of-distribution (OOD) performance across various multi-task configurations."
  - [section 5.2.2] "Paraphrase dropped from 62.7% to 57.3% in the first stage, then improved to 58.8%"
  - [corpus] No direct corpus validation of SOI-based subset selection for fine-tuning.
- Break condition: If subset selection overfits to specific OOD characteristics of the evaluation sets, gains may not generalize further.

### Mechanism 3
- Claim: Example forgetting patterns (transitions between SOI categories) reveal training instability that can be exploited for curriculum design.
- Mechanism: SOI transition heatmaps capture how examples migrate between learning states (e.g., ELE→≥2t-FRGE) when moving from single-setting to multi-setting; transitions to "less favorable" categories signal examples that may benefit from focused training.
- Core assumption: SOI category transitions are consistent signals of example difficulty/quality, not noise from random initialization or small epoch counts.
- Evidence anchors:
  - [section 4.3] "Each cell Hi,j in the heatmap records the number of training examples that transitioned from category i (row, under the single-setting) to category j (column, under the multi-setting)."
  - [section 5.2.1] "Transitions representing shifts from more favorable to less favorable learning behaviors (9 out of 36 heatmap transitions: [ACE, ELE, LLE] → 1t-FRGE, [LLE, ELE, ACE, 1t-FRGE] → ≥2t-FRGE, and [ACE, ELE] → LLE)"
  - [corpus] Related work on forgetting dynamics exists (Toneva et al. 2019, Yaghoobzadeh et al. 2021), but SOI's 6-category transition framework is novel.
- Break condition: If 10 epochs is insufficient to stabilize SOI classifications, categories may reflect transient noise rather than meaningful learning dynamics.

## Foundational Learning
- Concept: Dataset Cartography
  - Why needed here: SOI visualization relies on confidence-variability plots to validate category placements (UNE in hard-to-learn, ACE in easy-to-learn regions).
  - Quick check question: Can you explain why high variability and low confidence characterize "hard-to-learn" examples?

- Concept: Forgetting Events (from Toneva et al. 2019, Yaghoobzadeh et al. 2021)
  - Why needed here: SOI's 1t-FRGE and ≥2t-FRGE categories extend prior work on examples that oscillate between correct/incorrect predictions during training.
  - Quick check question: What distinguishes a "forgetting event" from an "unlearned example" in this framework?

- Concept: Multi-Task Learning Transfer
  - Why needed here: The paper's central comparison depends on understanding when task similarity yields mutual OOD benefits versus negative transfer.
  - Quick check question: Why would paraphrase + entailment (similar tasks) show mutual OOD improvement while sentiment + paraphrase (dissimilar) shows mutual degradation?

## Architecture Onboarding
- Component map: Shared encoder (BERT-base or XLM-R) -> task/source/language-specific classification heads -> SOI tracking module -> Transition heatmap generator -> Two-stage fine-tuning pipeline
- Critical path: 1) Run single-setting training with per-epoch prediction logging 2) Compute SOI category assignments for all examples 3) Run multi-setting training with same logging 4) Generate transition heatmaps 5) Extract subset for second-stage fine-tuning based on heatmap criteria
- Design tradeoffs:
  - 10 epochs for first stage balances SOI classification stability with compute cost; fewer epochs may yield noisy category assignments
  - Method III (diagonal excluding ACE→ACE) was selected for best average multi-task OOD; other strategies may outperform in specific configurations
  - Multi-source shows consistent OOD gains but ID gains are marginal (<1%); prioritize based on deployment context
- Failure signatures:
  - OOD performance drops in multi-lingual settings (e.g., En-Fa: 52.8%→48%) suggest language dissimilarity may cause negative transfer
  - Second-stage showing no improvement in multi-source likely indicates first stage already maximized gains
  - Burmese OOD evaluation may underrepresent true multilingual transfer due to XLM-R's weak representation
- First 3 experiments:
  1. Replicate single-source vs. multi-source sentiment analysis on IMDB+Yelp, evaluate on SST-2 OOD; expect ~4-5% OOD gain.
  2. Implement SOI tracking on a 3-epoch pilot run; verify category distributions match paper's cartography (UNE in high-variability/low-confidence region).
  3. Test second-stage fine-tuning on multi-task SE configuration using method III subset selection; check if Entailment OOD recovers from first-stage drop.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do SOI dynamics and training behavior patterns manifest in decoder-based large language models (e.g., GPT, Llama) compared to the encoder-only models studied?
- Basis in paper: [explicit] Authors state: "While our study focused on encoder-based PLMs, future work could apply the SOI framework to large decoder-based language models, such as GPT-style models, to gain insights into their training behaviors and generalization capabilities."
- Why unresolved: The SOI framework was validated only on BERT and XLM-R encoder architectures; decoder-based models have different training objectives (causal language modeling vs. masked language modeling) and scaling properties.
- What evidence would resolve it: Replicating the SOI categorization and transition heatmap analysis on decoder-based LLMs across comparable multi-setting configurations.

### Open Question 2
- Question: How does the SOI framework scale when expanding beyond pairwise combinations to training on three or more tasks, sources, or languages simultaneously?
- Basis in paper: [explicit] Authors note: "expanding beyond pairwise combinations to train models on multiple (three or more) tasks, sources, or languages simultaneously could provide a deeper understanding of scaling trends in multi-setting learning."
- Why unresolved: All experiments used pairwise multi-setting configurations; whether SOI transition patterns and OOD benefits compound or diminish with more complex training remains unknown.
- What evidence would resolve it: Experiments with triplets and larger combinations of tasks/sources/languages, analyzing whether OOD improvements scale linearly or exhibit diminishing returns.

### Open Question 3
- Question: Would curriculum learning strategies that stage training according to SOI categories (e.g., starting with ACE/ELE before introducing FRGE) improve convergence efficiency and final OOD performance?
- Basis in paper: [explicit] Authors propose: "Another direction involves investigating curriculum learning strategies where training is staged according to SOI categories."
- Why unresolved: The current work uses SOI for post-hoc analysis and second-stage fine-tuning subset selection, not for ordered curriculum design during initial training.
- What evidence would resolve it: Comparative experiments where training proceeds in SOI-ordered stages versus standard shuffled training, measuring both convergence speed and OOD generalization.

### Open Question 4
- Question: Are the SOI category boundaries—particularly the ELE/LLE threshold at epoch 5 and ≥2t-FRGE distinction—robust to variations in training duration, or do they require task-specific calibration?
- Basis in paper: [inferred] Section 4.1 notes "All training was conducted over 10 epochs, meaning the ELE/LLE classification is influenced by this hyperparameter." The second-stage fine-tuning strategy selection (method III) may be sensitive to these arbitrary thresholds.
- Why unresolved: The epoch-5 split and 2-time forgetting threshold were not ablated; whether these definitions generalize across different training lengths or optimal cutoffs exist remains untested.
- What evidence would resolve it: Ablation studies varying the ELE/LLE epoch threshold and forgetting count cutoff across different training durations, measuring impact on second-stage fine-tuning effectiveness.

## Limitations
- Unknown hyperparameters (learning rate, batch size, optimizer settings, warmup steps) are not specified, making exact reproduction challenging
- SOI subset selection strategy (diagonal entries excluding ACE→ACE) lacks precise definition, requiring inference from heatmap structure
- Multi-head architecture routing during joint training is only diagrammed without code-level detail

## Confidence
- High Confidence: Multi-source learning consistently improves OOD performance (up to 7%) - supported by direct experimental evidence across six evaluated cases with consistent patterns
- Medium Confidence: Two-stage fine-tuning with SOI-guided subset selection improves multi-task OOD performance - supported by recovery examples (Paraphrase: 57.3%→58.8%) but lacks external validation of the subset selection method
- Low Confidence: Multi-task learning showing mixed results - well-documented, but the underlying mechanism for when positive versus negative transfer occurs remains unclear without deeper analysis of task similarity factors

## Next Checks
1. Reproduce Multi-Source OOD Gains: Run single-source vs. multi-source sentiment analysis on IMDB+Yelp, evaluate on SST-2 OOD; expect ~4-5% OOD gain to verify core multi-source mechanism
2. Validate SOI Category Distributions: Implement SOI tracking on a 3-epoch pilot run; verify category distributions match paper's cartography (UNE in high-variability/low-confidence region) to ensure correct implementation
3. Test Subset Selection Strategy: Implement second-stage fine-tuning on multi-task SE configuration using method III subset selection; check if Entailment OOD recovers from first-stage drop to validate the two-stage approach