---
ver: rpa2
title: 'Riemannian Integrated Gradients: A Geometric View of Explainable AI'
arxiv_id: '2503.00892'
source_url: https://arxiv.org/abs/2503.00892
tags:
- riemannian
- attribution
- space
- methods
- manifold
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Riemannian Integrated Gradients (RIG), a novel
  extension of Integrated Gradients (IG) to Riemannian manifolds. The work addresses
  the problem that existing explainability methods assume data lies on a Euclidean
  manifold, while real-world data may lie on non-Euclidean spaces.
---

# Riemannian Integrated Gradients: A Geometric View of Explainable AI

## Quick Facts
- arXiv ID: 2503.00892
- Source URL: https://arxiv.org/abs/2503.00892
- Authors: Federico Costanza; Lachlan Simpson
- Reference count: 14
- Key outcome: Proposes Riemannian Integrated Gradients (RIG), a novel extension of Integrated Gradients to Riemannian manifolds that generalizes feature attribution to non-Euclidean data manifolds via parallel transport along geodesics

## Executive Summary
This paper introduces Riemannian Integrated Gradients (RIG), a geometric extension of the Integrated Gradients (IG) explainability method to data lying on Riemannian manifolds. The work addresses the limitation that existing explainability methods assume Euclidean geometry, while real-world data often lies on non-Euclidean spaces. RIG computes feature attributions by integrating gradients along geodesics while maintaining geometric consistency through parallel transport. The authors prove that RIG satisfies adapted versions of IG's axioms on Riemannian manifolds and demonstrate that under appropriate basis choice, attributions correspond to eigenvalues of a symmetric endomorphism, providing a rich geometric interpretation.

## Method Summary
RIG extends Integrated Gradients to Riemannian manifolds by computing attributions as path integrals along geodesics with parallel transport. For a neural network F on a Riemannian manifold M, the attribution in direction u at point p is defined as RIG_u(p,F) = -∫_0^1 dF(P_γ(t)u)g(P_γ(t)u, γ'(t))dt, where γ is a length-minimizing geodesic from p to base-point o, and P_γ is the parallel transport operator. This reduces to standard IG when the manifold is Euclidean (parallel transport is identity, geodesics are straight lines). The method satisfies adapted axioms including completeness (sum of attributions equals F(p) - F(o)), isometry invariance, and sensitivity, and provides a natural basis for attributions through eigenvalues of a symmetric endomorphism derived from the path attribution form.

## Key Results
- RIG generalizes IG to Riemannian manifolds while preserving IG's completeness axiom: attributions sum to F(p) - F(o)
- RIG restricts to IG when the Riemannian manifold is Euclidean space (Theorem 1)
- Under an appropriate basis, RIG attributions correspond to eigenvalues of a symmetric endomorphism, providing geometric interpretability
- The path attribution form α_{F,γ} satisfies all adapted IG axioms on Riemannian manifolds (Theorem 2)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RIG generalizes feature attribution to non-Euclidean data manifolds via parallel transport along geodesics.
- Mechanism: The attribution in direction u at point p is computed by integrating the differential of the network F along a geodesic γ from p to base-point o, using parallel-transported vectors P_γu to maintain geometric consistency: RIG_u(p, F) = α_{F,γ}(p)(u, u) = -∫_γ dF(P_γu)g(P_γu, γ′). This reduces to standard IG when the manifold is Euclidean (parallel transport is identity, geodesics are straight lines).
- Core assumption: Data lies on a compact connected Riemannian manifold where geodesics exist between any two points (Hopf-Rinow conditions hold).
- Evidence anchors:
  - [abstract] "RIG restricts to IG when the Riemannian manifold is Euclidean space"
  - [section 3.1] Definition 3 and Theorem 1 with proof showing equivalence in Euclidean case
  - [corpus] Related work on Riemannian PCA and geodesic optimization shows broader interest in manifold-aware methods, but direct empirical validation of RIG is limited
- Break condition: Manifold is non-compact or disconnected; geodesics cannot be computed reliably; curvature is extreme causing numerical instability in parallel transport.

### Mechanism 2
- Claim: The path attribution form α_{F,γ} satisfies adapted completeness axiom: sum of attributions equals F(p) − F(o).
- Mechanism: The bilinear form α_{F,γ}(p)(u, v) = A_{F,γ}(P_γu, P_γv) traces to F(p) − F(o) by Stokes' theorem. This ensures attributions sum to the function difference between explained point and base-point, generalizing IG's completeness property.
- Core assumption: F is smooth on M; integration along γ is well-defined; metric g is parallel (Levi-Civita connection).
- Evidence anchors:
  - [section 3.1] Proposition 2: "tr α_{F,γ}(p) = F(p) − F(o)"
  - [section 3.1] Theorem 2 confirms BAMs defined by path attribution form satisfy Riemannian axioms
  - [corpus] No direct corpus evidence on completeness properties in non-Euclidean settings
- Break condition: F is not differentiable; path crosses singularities; base-point selection is inappropriate for the task.

### Mechanism 3
- Claim: A natural basis for attributions is given by eigenvectors of the symmetric endomorphism Q_{F,γ}(p), with attributions equal to eigenvalues.
- Mechanism: The symmetrized path attribution form α̇_{F,γ} defines a symmetric endomorphism Q_{F,γ}(p) via g(Q_{F,γ}(p)u, v) = α̇_{F,γ}(p)(u, v). Eigenvectors form orthonormal basis; attribution in eigenvector direction equals corresponding eigenvalue. Maximum attribution magnitude is bounded by |λ_n|.
- Core assumption: The endomorphism is diagonalizable with real eigenvalues (guaranteed by symmetry).
- Evidence anchors:
  - [abstract] "attributions correspond to eigenvalues of a symmetric endomorphism"
  - [section 3.2] Proposition 3 bounds attributions by eigenvalues
  - [corpus] Eigenvalue-based analysis appears in related Riemannian methods but specific attribution applications are novel
- Break condition: Degenerate eigenvalues causing non-unique eigenvector basis; numerical precision issues in eigenvalue computation.

## Foundational Learning

- Concept: Riemannian manifold with metric tensor
  - Why needed here: The entire framework assumes data lies on a manifold M with metric g defining distances, angles, and geodesics. Without this, RIG cannot be defined.
  - Quick check question: Can you explain why parallel transport depends on the choice of metric and connection?

- Concept: Parallel transport along curves
  - Why needed here: RIG uses parallel transport P_γ to move tangent vectors along geodesics while preserving inner products. This generalizes constant vector fields in Euclidean space.
  - Quick check question: In what way does parallel transport along a closed curve differ from the identity on a curved manifold?

- Concept: Integrated Gradients (Euclidean)
  - Why needed here: RIG is a generalization of IG. Understanding IG's straight-line path integration and axioms (completeness, sensitivity) is prerequisite to grasping RIG's adaptations.
  - Quick check question: How does IG's choice of base-point affect the attribution, and what role does the straight-line path play?

## Architecture Onboarding

- Component map:
  1. Manifold estimator -> Geodesic solver -> Parallel transport operator -> Attribution integrator -> Eigenbasis computer (optional)

- Critical path:
  1. Estimate manifold structure from data (or assume known geometry)
  2. For each point p to explain: compute geodesic to base-point o
  3. For each direction u in chosen basis: parallel transport u along γ, integrate dF(P_γu) against γ′
  4. Sum attributions to verify completeness property as sanity check

- Design tradeoffs:
  - Base-point selection: Choosing o affects all attributions; paper suggests tangent-aligned base-points [7] but does not prescribe universal rule
  - Basis choice: Coordinate basis vs. eigenbasis—eigenbasis provides geometrically meaningful directions but adds computational cost
  - Geodesic approximation: Exact geodesics may be intractable; approximations introduce error in attributions

- Failure signatures:
  - Attributions do not sum to F(p) − F(o): indicates numerical integration error or geodesic computation failure
  - Extreme attribution magnitudes on low-sensitivity directions: suggests manifold curvature is poorly estimated
  - Non-reproducible attributions under isometries: indicates implementation does not respect isometry invariance (Axiom II)

- First 3 experiments:
  1. Sanity check on Euclidean data: Apply RIG to data known to lie in R^n; verify RIG outputs match standard IG exactly (Theorem 1 validation).
  2. Known manifold test: Use data on a well-understood non-Euclidean manifold (e.g., hyperbolic space H as in [3], or sphere); compare RIG attributions against baseline methods for interpretability.
  3. Robustness to geodesic approximation: Implement with both exact and approximate geodesics; measure attribution deviation as function of approximation error.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does RIG perform empirically on specific non-Euclidean datasets compared to standard Integrated Gradients?
- Basis in paper: [explicit] The conclusion states, "In future work, we seek to experimentally validate RIG on datasets with different geometries."
- Why unresolved: The current work focuses strictly on the theoretical formulation, axiomatic validation, and the proof that RIG restricts to IG in Euclidean space, without providing experimental results.
- What evidence would resolve it: Benchmarking RIG against Euclidean IG on datasets known to lie on manifolds (e.g., hyperbolic taxonomies or spherical data) using faithfulness metrics like infidelity or insertion/deletion scores.

### Open Question 2
- Question: How sensitive are RIG attributions to errors in the estimated manifold metric and geodesic paths?
- Basis in paper: [inferred] The authors note that applying RIG to data requires assuming the manifold hypothesis and utilizing external methods (e.g., Shao et al. [5]) to compute the metric and geodesics, but do not analyze the impact of approximation errors in these steps.
- Why unresolved: The theoretical definition assumes a known Riemannian manifold (M, g); however, in practice, the metric g and geodesic γ are approximations, and the propagation of these estimation errors into the final attribution is uncharacterized.
- What evidence would resolve it: A robustness analysis measuring the variance in RIG attributions when noise is injected into the metric tensor or when different manifold learning algorithms are used to define the geometry.

### Open Question 3
- Question: How should the method handle ambiguity in attributions when multiple length-minimizing geodesics exist between the input point and the base-point?
- Basis in paper: [inferred] Definition 3 defines RIG along "a length-minimising geodesic," relying on the Hopf-Rinow theorem for existence, but does not address uniqueness or the implications of choosing one geodesic over another at cut loci.
- Why unresolved: In regions where geodesics are not unique (e.g., antipodal points on a sphere), the definition implies the attribution depends on the specific path chosen, potentially leading to inconsistent explanations for the same input.
- What evidence would resolve it: A modification of the definition to average over all valid geodesics, or an empirical study showing the variance of attributions in regions of non-unique geodesics.

## Limitations
- No empirical validation on real-world non-Euclidean datasets to demonstrate practical effectiveness
- Computationally intensive geodesic and parallel transport calculations may limit scalability
- Sensitivity to manifold estimation quality not characterized, though critical for practical application

## Confidence
- High: Theoretical derivation of RIG as IG extension, proof of axiom satisfaction, eigenvalue-based interpretation
- Medium: Geometric intuition and mechanism descriptions, but limited empirical verification
- Low: Practical performance on real non-Euclidean datasets, scalability to high dimensions

## Next Checks
1. Implement RIG on synthetic data with known manifold geometry (sphere, hyperbolic space) and compare attributions against ground truth feature importance
2. Test RIG's isometry invariance property by applying known isometries to data and verifying attributions transform accordingly
3. Benchmark RIG's runtime and attribution stability against standard IG on high-dimensional manifold approximations