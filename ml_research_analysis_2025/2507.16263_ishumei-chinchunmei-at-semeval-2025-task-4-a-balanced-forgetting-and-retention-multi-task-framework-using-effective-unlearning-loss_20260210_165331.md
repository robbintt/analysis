---
ver: rpa2
title: 'iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention
  multi-task framework using effective unlearning loss'
arxiv_id: '2507.16263'
source_url: https://arxiv.org/abs/2507.16263
tags:
- e-04
- e-05
- e-06
- unlearning
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of unlearning sensitive information
  from large language models (LLMs) to prevent privacy breaches and copyright violations.
  The core method introduces an Effective Unlearning Loss (EUL), which is the multiplicative
  inverse of the standard supervised fine-tuning (SFT) loss, designed to erase knowledge
  of unwanted data by perturbing model gradients.
---

# iShumei-Chinchunmei at SemEval-2025 Task 4: A balanced forgetting and retention multi-task framework using effective unlearning loss

## Quick Facts
- arXiv ID: 2507.16263
- Source URL: https://arxiv.org/abs/2507.16263
- Authors: Yujian Sun; Tian Li
- Reference count: 40
- Primary result: 5th place finish on SemEval-2025 Task 4 leaderboard using Effective Unlearning Loss (EUL) to balance privacy protection with capability preservation

## Executive Summary
This paper presents iShumei-Chinchunmei, a framework for machine unlearning that removes sensitive information from large language models while maintaining general capabilities. The core innovation is Effective Unlearning Loss (EUL), which uses the multiplicative inverse of standard supervised fine-tuning loss to induce forgetting without the instability of gradient ascent methods. The approach employs a multi-task learning framework that concurrently performs standard fine-tuning on retained data and EUL optimization on data to be forgotten, with data augmentation strategies to address output length distribution imbalances.

## Method Summary
The method introduces Effective Unlearning Loss (EUL) as α × 1/L_ntp, where L_ntp is the standard next-token prediction loss. EUL is applied to forget-set data while standard SFT loss is applied to retain-set data in a multi-task learning framework with alternating batches. Data augmentation via re-segmentation addresses the failure mode where unlearning works for short texts but fails for long texts. The system uses LoRA adapters (rank=8, alpha=32, dropout=0.05) with configuration: epochs=5, lr=1e-4, batch=32, α=1.

## Key Results
- Achieved 5th place ranking on SemEval-2025 Task 4 leaderboard
- EUL with retain-set fine-tuning (RD) maintains MMLU scores around 0.28 while achieving effective forgetting (MIA scores approaching 0)
- Data augmentation provides benefits beyond simple step increases, improving Final Score from 0.255 to 0.421
- Learning rate critically affects performance: lr=1e-4 optimal, lr=1e-6 results in no effective unlearning

## Why This Works (Mechanism)

### Mechanism 1
The multiplicative inverse of standard SFT loss creates effective forgetting gradients without optimization instability. EUL = α × 1/L_ntp. When model output aligns with forgotten information, loss increases significantly; when output deviates, it remains low. This creates gradient perturbation that pushes model away from generating forgotten content without the instability of gradient ascent.

### Mechanism 2
Alternating between EUL optimization on forget data and standard SFT on retain data enables balanced forgetting and retention. Each batch contains data from only one task. Forget-Set Task optimizes with L_EUL; Retain-Set Task uses conventional L_ntp. Alternating prevents gradient interference while allowing both objectives to progress.

### Mechanism 3
Balancing output length distributions through re-segmentation improves unlearning effectiveness across varying text lengths. Long outputs are segmented into individual sentences; portions are incrementally moved into the input to generate shorter-output training samples. This addresses failure mode where unlearning works for short texts but fails for long texts.

## Foundational Learning

- Concept: Gradient Ascent vs. Gradient Descent in Unlearning
  - Why needed here: Paper positions EUL as alternative to gradient ascent, which "can easily lead to model instability." Understanding why gradient ascent pushes parameters into unstable regions is essential to appreciate EUL's design.
  - Quick check question: Why might maximizing loss on forget data cause model instability, and how does EUL's inverse loss avoid this while still achieving forgetting?

- Concept: Catastrophic Forgetting
  - Why needed here: Core challenge is "preserving essential information and capabilities while ensuring the removal of targeted data." Without retain-set fine-tuning, MMLU drops from ~0.28 to ~0.23.
  - Quick check question: What happens to MMLU scores if you apply EUL without any retain-set fine-tuning, based on Table 1 results?

- Concept: Membership Inference Attacks (MIA)
  - Why needed here: MIA scores measure "the extent to which the relevant knowledge is retained or effectively forgotten." Understanding that MIAs distinguish training vs. non-training data is crucial for interpreting MIA≈0.0 vs. MIA≈0.99.
  - Quick check question: In Table 1, what does MIA=0.989 indicate about the EUL-only approach's effectiveness, and why was this result rejected?

## Architecture Onboarding

- Component map: Input Data → Forget Set + Retain Set split → Forget Set → Re-segmentation (DA) → EUL Loss → Gradient Perturbation → Retain Set → Standard SFT Loss → Standard Gradients → Batch-Level Alternating Training (LoRA adapters only) → Evaluation: MIA + TAS + MMLU → Final Score (average)

- Critical path:
  1. Curate forget/retain sets from competition data
  2. Apply re-segmentation to forget set (balance long-tail distribution)
  3. Configure LoRA (Rank=8, Alpha=32, Dropout=0.05)
  4. Set α=1, lr=1e-4, epochs=5, batch=32
  5. Alternate forget-batches (EUL) and retain-batches (SFT)
  6. Monitor all three metrics; MMLU<0.25 signals over-forgetting

- Design tradeoffs:
  - EUL vs. NR (Negative Response replacement): NR improves MMLU but hurts unlearning (overfitting on small datasets). EUL achieves better balance.
  - Learning rate: lr=1e-4 produces best Final (0.421) vs. lr=1e-5 (0.131). Lower rates under-unlearn.
  - DA vs. more steps: DA benefit is NOT just more steps—Table 3 shows DA at 5 epochs (0.421) beats no-DA at matched steps (0.255).
  - With vs. without RD: RD is essential—without it, MMLU collapses (0.229).

- Failure signatures:
  - MMLU collapse: MMLU dropping from ~0.28 to ~0.23 indicates retain-set fine-tuning was omitted.
  - Over-forgetting: High MIA (0.989) with low MMLU (0.229) means unlearning succeeded but model is damaged.
  - Under-forgetting: MIA≈0.0 with lr=1e-6 means no effective unlearning occurred.
  - Numerical instability: EUL² scaling degraded Final from 0.42 to 0.29.

- First 3 experiments:
  1. Run ablation on Table 1 rows: EUL-only, EUL+RD, EUL+RD+DA. Plot MIA vs. MMLU to visualize the forgetting/retention trade-off frontier.
  2. Learning rate sweep: Test lr ∈ {1e-4, 5e-5, 1e-5, 5e-6, 1e-6} with fixed 5 epochs, RD+DA+EUL enabled. Identify the cliff where unlearning fails.
  3. DA mechanism test: For 5 epochs, compare (a) with DA, (b) without DA, (c) without DA but matched training steps. Confirm DA benefit exceeds mere step increase per Table 3.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Effective Unlearning Loss (EUL) performance scale with extended training durations beyond 5 epochs?
- Basis in paper: [explicit] The authors state, "Due to computational resource limitations, we are only able to test results up to a maximum of 5 epochs," while noting that performance increased with the number of epochs.
- Why unresolved: It is unclear if the observed upward trend in performance continues, stabilizes, or if the model eventually suffers from catastrophic forgetting or instability at higher epochs.
- What evidence would resolve it: Experimental results running the same EUL configuration for 10, 20, and 50 epochs on the OLMo models, tracking MMLU and MIA scores.

### Open Question 2
- Question: What are the theoretical gradient properties of the multiplicative inverse loss that prevent the optimization instability associated with gradient ascent?
- Basis in paper: [inferred] The paper claims EUL is a "more stable and effective choice" than gradient ascent to avoid "model instability," but the analysis is primarily empirical, lacking a deep theoretical derivation of the gradient dynamics.
- Why unresolved: The precise mathematical mechanism ensuring stability during "gradient descent" with an inverse loss function is not fully derived.
- What evidence would resolve it: A theoretical analysis or visualizations of the loss landscape and gradient norms comparing EUL against standard gradient ascent over training steps.

### Open Question 3
- Question: Can alternative scaling factors ($\alpha$) or functional transformations improve the balance between forgetting and retention compared to the fixed $\alpha=1$?
- Basis in paper: [inferred] The authors experimented with squaring the loss (EUL2) and found no improvement, but they did not test other values for the scaling factor $\alpha$ or other functional transformations.
- Why unresolved: The search space for the loss function's magnitude and form was limited to $\alpha=1$ and squaring; optimal configurations may exist outside these parameters.
- What evidence would resolve it: An ablation study varying $\alpha$ (e.g., 0.1, 0.5, 2.0) and testing other non-linear transformations of the SFT loss.

## Limitations
- Data augmentation implementation details are not fully specified, making faithful reproduction difficult
- The method's generalizability to other unlearning scenarios, model architectures, or dataset types remains untested
- The claim about EUL's stability advantage over gradient ascent lacks direct empirical comparison

## Confidence
**High Confidence**: The core mechanism of EUL and its integration into multi-task framework is well-specified and produces reproducible results. The importance of retain-set fine-tuning is clearly demonstrated through MMLU degradation patterns.

**Medium Confidence**: The effectiveness of data augmentation through re-segmentation is supported by experimental results, but lack of implementation details makes it difficult to assess whether improvements are due to specific technique or increased data volume.

**Low Confidence**: The generalizability of approach to other unlearning scenarios, model architectures, or dataset types remains uncertain. The paper does not address potential privacy risks from augmented data.

## Next Checks
1. **Gradient Stability Analysis**: Conduct controlled experiments comparing EUL against both standard gradient ascent unlearning and baseline with no forgetting on identical datasets. Measure and report training stability metrics (loss variance, gradient norm statistics) across all three approaches to empirically validate EUL's claimed stability advantage.

2. **Data Augmentation Ablation**: Implement and test alternative data augmentation strategies (simple duplication, paraphrasing, back-translation) alongside re-segmentation approach. Run these at matched training step counts to isolate whether improvements come from specific re-segmentation technique or from increased data diversity in general.

3. **Generalization Cross-Dataset Test**: Apply complete iShumei-Chinchunmei framework (EUL + RD + DA) to different unlearning benchmark with distinct data characteristics. Compare performance drop against original dataset to assess method's robustness and identify failure conditions.