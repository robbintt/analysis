---
ver: rpa2
title: Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration
arxiv_id: '2601.12256'
source_url: https://arxiv.org/abs/2601.12256
tags:
- molecular
- molecule
- language
- collamo
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoLLaMo introduces a relation-aware multimodal projector to integrate
  1D molecular sequences, 2D graphs, and 3D conformations into a unified token space,
  enabling large language models to perform robust molecular reasoning. The relation-aware
  attention mechanism incorporates 2D structural and 3D spatial information to enhance
  fine-grained information exchange.
---

# Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration

## Quick Facts
- arXiv ID: 2601.12256
- Source URL: https://arxiv.org/abs/2601.12256
- Authors: Jinyoung Park; Minseong Bae; Jeehye Na; Hyunwoo J. Kim
- Reference count: 7
- Primary result: CoLLaMo outperforms GPT-4, GPT-4o, and other LMLMs on molecule captioning, property QA, IUPAC prediction, and motif counting, maintaining performance with incomplete modalities.

## Executive Summary
CoLLaMo introduces a relation-aware multimodal projector to integrate 1D molecular sequences, 2D graphs, and 3D conformations into a unified token space, enabling large language models to perform robust molecular reasoning. The relation-aware attention mechanism incorporates 2D structural and 3D spatial information to enhance fine-grained information exchange. Evaluation includes novel molecule-centric metrics like CHARM/RCHARM for hallucination assessment and LLM-based caption quality scoring.

## Method Summary
CoLLaMo builds upon a frozen LLaMA-2-7B LLM with LoRA adaptation, combining three pre-trained molecular encoders: token embeddings for 1D SELFIES, GIN for 2D graphs, and Uni-Mol for 3D conformations. The modality-collaborative projector uses relation-aware cross-attention with 2D shortest-path and 3D Gaussian basis kernel biases, modality dropout, and learnable modality embeddings to compress variable-length molecular encodings into fixed LLM tokens. Training proceeds in two stages: first aligning the projector with encoders while freezing the LLM, then instruction tuning with LoRA adaptation.

## Key Results
- Outperforms GPT-4, GPT-4o, and other LMLMs on molecule captioning, property QA, IUPAC prediction, and motif counting
- Maintains performance even with incomplete modalities, demonstrating improved robustness
- Novel CHARM/RCHARM metrics effectively assess hallucination in molecular descriptions

## Why This Works (Mechanism)

### Mechanism 1: Relation-Aware Attention Bias
Injecting structural and spatial priors into the attention mechanism facilitates more chemically grounded reasoning than treating atoms as an unordered set. The model modifies standard self-attention by adding learnable bias terms derived from shortest path distances (2D) and Euclidean distances via Gaussian Basis Kernels (3D), forcing attention weights to respect actual topological and spatial relationships between atoms.

### Mechanism 2: Robustness via Modality Dropout
Explicitly masking modalities during training forces the projector to learn a unified representation that prevents over-reliance on any single data type. During pretraining, the model randomly drops 1D, 2D, or 3D inputs and adds learnable "modality embeddings" to query tokens, acting as a regularizer that ensures the latent space collapses effectively even with incomplete inputs.

### Mechanism 3: Cross-Modal Projection to Fixed Tokens
Compressing variable-length molecular encodings into a fixed set of "molecule tokens" via cross-attention enables the LLM to process complex structures without architectural modification. Rather than padding or truncating atom sequences, the architecture uses learnable queries to extract information from concatenated 1D/2D/3D representations, aligning molecular features to the LLM's native embedding space.

## Foundational Learning

- **Concept: Cross-Attention vs. Self-Attention**
  - **Why needed here:** The core of the CoLLaMo projector is not standard self-attention. Understanding Cross-Attention (Query from one space, Key/Value from another) is essential to grasp how the model "queries" molecular encoders to generate LLM tokens.
  - **Quick check question:** Does the model attend to text tokens to generate molecular embeddings, or attend to molecular embeddings to generate LLM tokens? (Answer: The latter).

- **Concept: Radial Basis Function (RBF) Kernels**
  - **Why needed here:** The 3D spatial bias is not a raw distance coordinate. It uses Gaussian kernels to convert raw distances into smooth feature vectors.
  - **Quick check question:** Why use a Gaussian kernel on 3D distances instead of just plugging in the raw Euclidean distance? (Hint: Smoothness and learnability of the bias).

- **Concept: Token Alignment / Projectors (Adapters)**
  - **Why needed here:** The "Projector" is the bridge between frozen molecular encoders and the frozen LLM. Understanding that this is the primary trainable component is critical for debugging.
  - **Quick check question:** If the model outputs nonsense, which component is the most likely culprit to retrain first: the frozen GIN encoder, the frozen LLM, or the trainable Projector?

## Architecture Onboarding

- **Component map:**
  1. **Encoders (Frozen):**
     - 1D: Token Embedding (SELFIES vocab)
     - 2D: GIN (Graph Isomorphism Network)
     - 3D: Uni-Mol (Transformer-based conformer encoder)
  2. **Projector (Trainable - Co-Proj):**
     - Co-Attention Layers: Injects 2D and 3D biases
     - Cross-Attention: Compresses multi-modal streams into fixed tokens
     - Modality Dropout: Random masking
  3. **LLM (Partially Trainable):** LLaMA-2-7B with LoRA (Low-Rank Adaptation) for instruction tuning

- **Critical path:** The flow of gradient through the Projector. The encoders are frozen, so the Projector must effectively translate the high-dimensional outputs of GIN/Uni-Mol into the LLM's semantic space. The relation-aware attention mechanism is the differentiating factor here.

- **Design tradeoffs:**
  - Complexity vs. Completeness: Maintaining three separate encoders increases inference cost and complexity compared to single-modality models, but is necessary for handling the "missing modality" robustness.
  - Fixed vs. Variable Tokens: Using a fixed number of unified tokens standardizes input to the LLM but risks losing granular atom-level detail if the compression ratio is too high.

- **Failure signatures:**
  - Hallucination: If the model describes atoms or bonds that do not exist in the input molecule, check if the 2D/3D attention biases are correctly calculated or if modality dropout was too aggressive during training.
  - Modality Collapse: If performance drops significantly when one modality (e.g., 3D) is missing, the model failed to learn the modality embeddings properly.

- **First 3 experiments:**
  1. **Modality Ablation:** Run inference using only 1D, only 2D, and then all modalities. Verify that adding modalities improves "HOMO-LUMO gap" prediction (3D sensitive) and "LogP" (2D sensitive).
  2. **Projector Impact:** Compare "w/o Co-Proj" vs. "w/ Co-Proj" on a captioning task to validate that the unified token space is actually working.
  3. **Robustness Check:** Intentionally mask the 3D input during inference and check if the validity of generated outputs remains high.

## Open Questions the Paper Calls Out
None

## Limitations
- The relation-aware attention mechanism may limit generalizability to non-standard molecular representations.
- The fixed token count creates a potential bottleneck for processing large macromolecules.
- The novel CHARM/RCHARM hallucination metrics rely on LLM-based scoring, which introduces potential circularity and subjective bias.

## Confidence

- **High confidence:** The core architecture design (relation-aware attention with 2D/3D biases) and the two-stage training procedure are technically sound and well-specified.
- **Medium confidence:** The robustness claims under incomplete modalities are supported by ablation studies, but practical significance depends on real-world scenarios.
- **Low confidence:** The generalizability to molecules outside the training distribution (e.g., very large proteins, organometallic complexes) is not thoroughly tested.

## Next Checks

1. **Modality ablation stress test:** Systematically remove each modality (1D, 2D, 3D) during inference and measure performance degradation on property QA tasks, verifying expected patterns.

2. **Hallucination detection validation:** Generate molecule descriptions with known hallucinations and test whether CHARM/RCHARM metrics correctly identify these as hallucinated, comparing against human expert annotations.

3. **Token bottleneck analysis:** Test the model on progressively larger molecules and measure performance degradation as the fixed token count becomes insufficient, quantifying information loss at different molecular sizes.