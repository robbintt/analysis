---
ver: rpa2
title: Improving Multi-turn Task Completion in Task-Oriented Dialog Systems via Prompt
  Chaining and Fine-Grained Feedback
arxiv_id: '2502.13298'
source_url: https://arxiv.org/abs/2502.13298
tags:
- user
- dialog
- realtod
- language
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RealTOD addresses the challenge of reliable multi-turn task completion
  in task-oriented dialog systems, where large language models often struggle with
  generating correct API calls. The framework introduces prompt chaining to enable
  zero-shot generalization by synthesizing schema-aligned in-context examples, and
  fine-grained feedback to verify and correct API calls against domain schemas.
---

# Improving Multi-turn Task Completion in Task-Oriented Dialog Systems via Prompt Chaining and Fine-Grained Feedback

## Quick Facts
- **arXiv ID**: 2502.13298
- **Source URL**: https://arxiv.org/abs/2502.13298
- **Reference count**: 40
- **Primary result**: RealTOD achieves 37.10% improvement in full API accuracy on SGD and 10.32% on BiTOD over state-of-the-art baselines

## Executive Summary
RealTOD addresses the challenge of reliable multi-turn task completion in task-oriented dialog systems, where large language models often struggle with generating correct API calls. The framework introduces prompt chaining to enable zero-shot generalization by synthesizing schema-aligned in-context examples, and fine-grained feedback to verify and correct API calls against domain schemas. Extensive experiments on the SGD and BiTOD datasets with four LLMs show that RealTOD significantly improves full API accuracy, surpassing state-of-the-art baselines by up to 37.10% on SGD and 10.32% on BiTOD. Human evaluations confirm superior task completion, fluency, and informativeness compared to existing methods.

## Method Summary
RealTOD is a framework that improves task-oriented dialog systems through two key mechanisms: prompt chaining and fine-grained feedback. Prompt chaining uses a two-stage process where it first generates schema-aligned example dialogs by mapping from source domains to target domains, then uses these examples as in-context demonstrations for the live conversation. Fine-grained feedback employs an API parser that verifies generated API calls against domain schemas, identifying specific errors (incorrect method names, slot names, or missing required slots) and providing targeted correction prompts to the LLM. The system integrates with various LLMs including GPT-4o, Claude 3.5 Sonnet, DeepSeek-V3, and Llama-3.3-70B-Instruct, and uses a fine-tuned Flan-T5 user simulator for evaluation.

## Key Results
- Full API Call Accuracy improved by 37.10% on SGD dataset compared to state-of-the-art baselines
- Full API Call Accuracy improved by 10.32% on BiTOD dataset compared to state-of-the-art baselines
- Human evaluations show RealTOD outperforms existing methods in task completion, fluency, and informativeness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt chaining enables zero-shot generalization to new domains by synthesizing schema-aligned in-context examples without manual curation.
- Mechanism: Two-stage prompting process—(1) **Example Dialog Generation**: transforms a source-domain dialog into a target-domain dialog using schema mapping between domains; (2) **Task Adaptation**: uses the generated dialog as an in-context demonstration for the live conversation. The LLM receives the target schema Σdy, generated example Tdy, and dialog history Ht at each turn.
- Core assumption: LLMs can perform structural analogical reasoning between domains when schema correspondences are made explicit in the prompt.
- Evidence anchors:
  - [abstract] "Prompt chaining enables zero-shot generalization to new domains by automatically synthesizing a schema-aligned in-context example for the target task."
  - [section: Prompt Chaining] "RealTOD employs a two-stage prompt chaining mechanism... (i) example dialog generation that transforms an example dialog from a source domain into a target domain while maintaining task-specific consistency; and (ii) task adaptation that leverages the generated example dialog for in-context learning."
  - [corpus] ATOD (arxiv:2601.11854) similarly evaluates TOD systems with tool integration, supporting the schema-driven approach, though corpus evidence for this specific chaining mechanism is limited.
- Break condition: When source and target domains have fundamentally incompatible intent structures (e.g., transactional vs. informational intents) such that analogical transfer creates confusion rather than guidance.

### Mechanism 2
- Claim: Fine-grained feedback improves API call correctness by verifying each call against domain schemas and providing targeted correction prompts.
- Mechanism: A generic API parser checks three error types: (i) incorrect method name (method ∉ Id), (ii) incorrect slot name (slot ∉ Si for given intent), (iii) missing required slots (is_required(slot) = True but absent). Upon detection, the parser returns specific diagnostic feedback to the LLM for regeneration.
- Core assumption: LLMs can self-correct when given precise, localized error information rather than generic failure signals.
- Evidence anchors:
  - [abstract] "Fine-grained feedback verifies each generated API call against the domain schema, identifies specific errors, and provides targeted correction prompts."
  - [section: Fine-Grained Feedback] "Upon detecting an error, the parser returns fine-grained feedback specifying the issue, allowing the LLM to correct its response."
  - [corpus] TOD-ProcBench (arxiv:2511.15976) emphasizes strict instruction adherence in TOD, corroborating the need for verification mechanisms, though does not validate the specific feedback approach.
- Break condition: When feedback enters correction loops (LLM alternates between error types without converging) or when error diagnostics exceed context window capacity in long dialogs.

### Mechanism 3
- Claim: Full API Call Accuracy decomposes task completion reliability into diagnosable failure modes, enabling targeted improvement.
- Mechanism: The metric requires exact match on all components—method name, parameter names, parameter values, and operators—counting as correct only when the entire call matches the reference. Sub-metrics (Method Accuracy, Parameter Name Accuracy, Parameter Value Accuracy, Operator Accuracy) isolate specific failure patterns.
- Core assumption: Complete structural correctness of API calls correlates with successful task execution in deployed systems.
- Evidence anchors:
  - [abstract] "We introduce full API Call Accuracy as a robust metric, along with detailed sub-metrics to capture common failure modes."
  - [section: Evaluation Metrics] "An API call is counted as correct only if the method name, parameter names, associated parameter values, and operator match the reference."
  - [corpus] ATOD (arxiv:2601.11854) proposes agentic evaluation frameworks for TOD, supporting task-centric metrics over n-gram similarity.
- Break condition: When API structural correctness does not predict actual execution success (e.g., valid call structure but semantically incorrect values that pass schema validation).

## Foundational Learning

- **Domain Schema Structure (Intents, Slots, Required/Optional)**
  - Why needed here: RealTOD's prompt chaining and feedback mechanisms both depend on schema definitions (Σdx = (dx, Idx, {Si|i∈Idx})) to generate examples and verify API calls.
  - Quick check question: Given a "Book_Restaurant" intent with required_slots=[date, time, party_size] and optional_slots=[cuisine_preference], which parameters must appear in the API call for schema compliance?

- **In-Context Learning with Demonstrations**
  - Why needed here: The prompt chaining mechanism assumes LLMs can generalize from a single schema-aligned example dialog without gradient updates.
  - Quick check question: What is the difference between few-shot prompting with static examples vs. RealTOD's dynamically synthesized examples?

- **API Call Structure in TOD Systems**
  - Why needed here: The fine-grained feedback parser validates API calls of the form API(method=i, parameters={(sm, v), ...}), requiring understanding of method-slot-value hierarchies.
  - Quick check question: In the API call `API(method="Find_Flights", parameters={("origin", "NYC"), ("destination", "LAX"), ("date", "2024-03-15")})`, identify the method, parameter names, and parameter values.

## Architecture Onboarding

- **Component map:**
  - LLM Backbone -> Prompt Chaining Module -> API Parser -> Schema Store -> User Simulator

- **Critical path:**
  1. Load target domain schema Σdy
  2. Generate example dialog Tdy via prompt P1 (source schema → target schema mapping)
  3. For each turn t: construct prompt with schema, example, history Ht, instruction P2
  4. LLM generates response (natural language or API call)
  5. If API call: parser validates against schema → if errors, return feedback → LLM regenerates
  6. Execute validated API call, return results to LLM for response generation

- **Design tradeoffs:**
  - **Zero-shot vs. fine-tuning**: RealTOD trades potential accuracy gains from supervised training for scalability across domains without labeled data
  - **Feedback iterations vs. latency**: Each correction round adds API calls and latency; the paper does not report iteration counts or timeout thresholds
  - **Proprietary vs. open-source models**: Table 2 shows 20-32% Full API Accuracy gap favoring proprietary models, with cost/privacy tradeoffs

- **Failure signatures:**
  - **Hallucinated methods**: LLM generates API calls with method names not in Idx (e.g., "Book_Hotel" in Flights domain)
  - **Missing required slots**: API call lacks is_required(slot)=True parameters
  - **Error propagation across turns**: Figure 3 shows dialog success rate declines from ~60-80% (1 API) to ~10-40% (5-7 APIs) due to interdependent calls
  - **Over-correction loops**: LLM fails to converge after multiple feedback iterations (not quantified in paper)

- **First 3 experiments:**
  1. **Single-domain validation**: Test RealTOD on SGD single-domain dialogs with one API call per conversation to verify prompt chaining generates usable in-context examples
  2. **Feedback ablation**: Run RealTOD with prompt chaining only (no fine-grained feedback) vs. feedback only (no prompt chaining) vs. both to measure individual contributions per Table 4
  3. **Error type analysis**: Log parser-detected error types (method, slot, missing required) across datasets to identify whether specific failure modes dominate, guiding schema design or prompt refinement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can LLM-based TOD systems mitigate the significant decline in dialog success rates observed as the number of interdependent API calls increases in long-horizon tasks?
- Basis in paper: [explicit] The paper concludes that "failures in long-horizon planning across turns" remain a challenge and Figure 3 explicitly shows a downward trend in success rates as API calls increase, stating "Further research is needed to enhance their ability to handle these scenarios."
- Why unresolved: The current framework struggles with error propagation; early mistakes in one domain (e.g., booking a location) adversely affect subsequent dependent calls (e.g., booking transport to that location).
- What evidence would resolve it: A modified architecture or error-recovery mechanism that maintains a flat success rate curve across dialogs with >5 API calls.

### Open Question 2
- Question: How can the framework be enhanced to resolve misalignment issues that occur when integrating external search results with the dialog context?
- Basis in paper: [explicit] The conclusion identifies "misalignment when integrating external search results" as a persistent challenge requiring future research.
- Why unresolved: While RealTOD corrects API call structure, it does not fully address semantic conflicts between the retrieved data and the generated natural language response.
- What evidence would resolve it: A study showing improved consistency metrics between retrieved API results and system responses in complex information-seeking scenarios.

### Open Question 3
- Question: Does the RealTOD framework provide comparable performance gains when applied to newer, reasoning-focused large language models such as DeepSeek R1 or OpenAI o3?
- Basis in paper: [explicit] Appendix B states that due to rapid model development, "it remains an open question how RealTOD would perform with these newer LLMs" compared to the four specific models tested.
- Why unresolved: The study was restricted to specific instruction-tuned models (GPT-4o, Claude, Llama, DeepSeek-V3) due to computational constraints.
- What evidence would resolve it: Experimental results benchmarking RealTOD on reasoning models to see if prompt chaining and feedback yield diminishing or compounding returns.

## Limitations
- Source domain selection for prompt chaining remains unspecified, creating ambiguity in reproducing the schema alignment mechanism
- API execution and result retrieval lack implementation details, particularly how search results are obtained and fed back to the LLM
- LLM sampling parameters (temperature, top_p, max_tokens) were not reported, potentially affecting reproducibility of the exact accuracy figures

## Confidence
- **High confidence**: Conceptual framework and reported performance gains (37.10% on SGD, 10.32% on BiTOD) due to clear methodology and extensive experiments
- **Medium confidence**: Fine-grained feedback mechanism's effectiveness, as the paper lacks iteration count data and convergence analysis
- **Low confidence**: Exact reproduction without source domain selection criteria, API backend implementation, and LLM hyperparameter details

## Next Checks
1. **Reproduce single-domain performance**: Validate RealTOD on SGD single-domain dialogs (one API per conversation) to confirm prompt chaining generates usable in-context examples before tackling multi-domain complexity
2. **Ablation study replication**: Implement RealTOD with prompt chaining only, fine-grained feedback only, and both components to verify individual contribution measurements match Table 4's claims
3. **Error type distribution analysis**: Log and categorize parser-detected errors (method, slot, missing required) across datasets to confirm whether specific failure modes dominate, validating the need for targeted feedback mechanisms