---
ver: rpa2
title: Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks
arxiv_id: '2512.24156'
source_url: https://arxiv.org/abs/2512.24156
tags:
- exploration
- games
- levels
- game
- arc-agi-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a training-free graph-based method for solving
  interactive reasoning tasks in the ARC-AGI-3 benchmark, where agents must discover
  game mechanics through limited interactions without instructions. The approach segments
  visual frames into meaningful components, prioritizes actions based on visual salience,
  and maintains a directed graph of explored states and transitions to systematically
  navigate the state space.
---

# Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks

## Quick Facts
- arXiv ID: 2512.24156
- Source URL: https://arxiv.org/abs/2512.24156
- Authors: Evgenii Rudakov; Jonathan Shock; Benjamin Ultan Cowley
- Reference count: 25
- Primary result: Training-free graph-based method solving 30/52 levels, ranking 3rd on ARC-AGI-3 private leaderboard

## Executive Summary
This paper introduces a training-free graph-based method for solving interactive reasoning tasks in the ARC-AGI-3 benchmark, where agents must discover game mechanics through limited interactions without instructions. The approach segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions to systematically navigate the state space. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning tasks where current LLMs fail to capture task dynamics.

## Method Summary
The proposed method employs a training-free graph-based exploration strategy for interactive reasoning tasks in ARC-AGI-3. It segments visual frames into meaningful components using pre-trained models, then prioritizes actions based on visual salience to guide exploration. The system maintains a directed graph of explored states and transitions, enabling systematic navigation of the state space. By combining visual understanding with structured exploration, the approach discovers game mechanics through limited interactions without requiring explicit instructions. The method operates without task-specific learning during inference, though it relies on pre-trained foundation models for segmentation and visual processing.

## Key Results
- Solves a median of 30 out of 52 levels across six games in ARC-AGI-3 Preview Challenge
- Ranks 3rd on the ARC-AGI-3 private leaderboard
- Substantially outperforms frontier LLM-based agents on interactive reasoning tasks
- Demonstrates effectiveness of graph-structured exploration without task-specific learning

## Why This Works (Mechanism)
The method succeeds by converting unstructured visual exploration into a structured search problem. Visual salience prioritization helps identify relevant game elements quickly, while the directed graph of states and transitions prevents redundant exploration and enables backtracking. The segmentation into meaningful components allows the agent to focus on actionable elements rather than raw pixels. This combination of visual understanding and systematic exploration proves more effective than LLM-based approaches for discovering underlying game mechanics in interactive reasoning tasks.

## Foundational Learning
- **Visual salience detection**: Identifies important visual elements for action prioritization; quick check: validate against human attention maps
- **State space representation**: Converts visual observations into graph nodes; quick check: ensure state equivalence detection works across different visual presentations
- **Graph traversal algorithms**: Enables systematic exploration while avoiding cycles; quick check: verify completeness of coverage within interaction limits
- **Segmentation techniques**: Breaks down complex visuals into actionable components; quick check: test segmentation accuracy across diverse visual styles
- **Interactive reasoning**: Formulates task-solving as state-action exploration; quick check: validate action-effect relationships are captured
- **Foundation model integration**: Leverages pre-trained models for visual understanding; quick check: assess robustness to domain shifts

## Architecture Onboarding

**Component Map**: Visual Input -> Segmentation -> Salience Scoring -> Action Selection -> State Transition -> Graph Update -> Decision Loop

**Critical Path**: The primary execution path flows from visual input through segmentation to action selection, with the graph serving as persistent memory across steps. The most critical components are the salience scoring mechanism (determines exploration efficiency) and the state transition detection (ensures graph accuracy).

**Design Tradeoffs**: The approach trades off learning-based adaptability for computational efficiency and interpretability. By avoiding task-specific training, it achieves immediate generalization but may miss optimal strategies that could be learned. The reliance on pre-trained models enables strong visual understanding while maintaining training-free operation.

**Failure Signatures**: Common failure modes include: (1) incorrect segmentation leading to missed actionable elements, (2) salience scoring that prioritizes irrelevant features, (3) state equivalence detection failures causing graph redundancy, and (4) exploration getting trapped in local optima without discovering global mechanics.

**Three First Experiments**:
1. Visual salience ablation: Compare performance with random vs. salience-based action selection
2. Graph structure impact: Test with and without state transition tracking
3. Segmentation quality analysis: Measure success rates against segmentation accuracy metrics

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Relies on pre-trained foundation models (Segment Anything, CLIP) rather than being truly training-free
- Limited evaluation on only six games from ARC-AGI-3, raising generalizability concerns
- Lacks detailed benchmarking against specific LLM configurations and prompting strategies

## Confidence

**Performance Claims (Medium)**: The 30/52 level success rate and 3rd place ranking are specific and measurable, but the comparison methodology against LLM-based agents lacks detail, and the limited game diversity reduces confidence.

**Methodological Novelty (High)**: The graph-structured exploration approach with visual salience-based action prioritization is clearly defined and represents a novel contribution to interactive reasoning.

**Technical Implementation (High)**: The description provides sufficient detail for understanding the core approach, though some implementation specifics and parameter settings are not fully disclosed.

## Next Checks

1. Conduct controlled ablation study comparing graph-based method against various LLM configurations (few-shot prompting, chain-of-thought, tool-use) on identical game instances to establish true performance differentials.

2. Validate generalizability through cross-testing on an expanded set of ARC-AGI-3 games beyond the six-game subset, with quantitative analysis of success rates across different game mechanics.

3. Open-source the implementation with comprehensive documentation to enable independent reproduction and benchmarking against alternative exploration strategies, particularly learning-based approaches under identical conditions.