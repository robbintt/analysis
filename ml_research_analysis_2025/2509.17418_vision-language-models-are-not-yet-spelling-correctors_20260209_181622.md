---
ver: rpa2
title: Vision Language Models Are Not (Yet) Spelling Correctors
arxiv_id: '2509.17418'
source_url: https://arxiv.org/abs/2509.17418
tags:
- correction
- spelling
- error
- image
- chinese
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ReViCo, the first benchmark for evaluating
  vision-language models (VLMs) on real-world visual spelling correction in Chinese
  and English. The benchmark contains naturally occurring spelling errors collected
  from real-world images and supports fine-grained evaluation at both image and token
  levels.
---

# Vision Language Models Are Not (Yet) Spelling Correctors

## Quick Facts
- arXiv ID: 2509.17418
- Source URL: https://arxiv.org/abs/2509.17418
- Reference count: 39
- Current VLMs fall significantly short of human performance in real-world visual spelling correction

## Executive Summary
This paper introduces ReViCo, the first benchmark for evaluating vision-language models (VLMs) on real-world visual spelling correction in Chinese and English. The benchmark contains naturally occurring spelling errors collected from real-world images and supports fine-grained evaluation at both image and token levels. Comprehensive experiments with open-source models (Qwen, InternVL) and closed-source systems (GPT-4o, Claude) show that current VLMs fall significantly short of human performance, particularly in correction tasks. Two solution paradigms—Joint OCR-Correction pipeline and Background Information enhanced approach—yield consistent performance gains. The analysis highlights fundamental limitations of existing VLM architectures and provides actionable insights for advancing multimodal spelling correction.

## Method Summary
The paper evaluates VLMs on the ReViCo benchmark, which contains naturally occurring spelling errors from real-world images in Chinese and English. Models are tested on four tasks: image-level detection, token-level detection, image-level correction, and token-level correction. The evaluation includes both open-source models (Qwen2.5-VL and InternVL3.5 at various scales) and closed-source models (GPT-4o and Claude-Sonnet-4). Two enhanced approaches are proposed: Joint OCR-Correction (extracting text before correction) and Background Information Enhancement (providing scene context before correction). All models are deployed on 2x NVIDIA A100 GPUs with default settings.

## Key Results
- Current VLMs achieve significantly lower performance than humans in visual spelling correction (GPT-4o: 32% correction accuracy vs humans: 82%)
- Joint OCR-Correction and Background Information Enhancement consistently improve F1 scores across architectures
- Model scale exhibits non-linear effects: larger models tend toward over-correction while smaller models under-correct
- Cascaded architectures (Qwen) underperform native multimodal architectures (InternVL) in utilizing visual context

## Why This Works (Mechanism)

### Mechanism 1: Explicit OCR Grounding Reduces Hallucination
Inserting an explicit text extraction step before correction appears to improve performance by grounding the reasoning process. The "Joint OCR-Correction" pipeline forces the model to commit to a textual transcription before correction, splitting the task into perception and reasoning components. This reduces the cognitive load that often leads to hallucinating non-existent characters.

### Mechanism 2: Contextual Semantic Priming via Background Description
Describing the visual environment prior to correction helps disambiguate visually or phonetically similar characters. By generating a summary of the background information, the model activates relevant semantic clusters in its language backbone, priming it to select correction candidates that fit the scene context.

### Mechanism 3: Native Multimodal Fusion for Fine-Grained Perception
Architectures with native multimodal integration may utilize context more effectively than cascaded architectures for correction tasks. Native architectures process image and text tokens within a unified transformer, potentially avoiding the "projection bottleneck" where fine-grained visual details are lost during the alignment layer.

## Foundational Learning

- **Cascaded vs. Native Multimodal Architectures**: Understanding the difference between separate visual encoders with projection layers versus unified transformer architectures explains why some models lose fine-grained visual details required for spelling correction.
- **Hallucination in Vision-Language Models**: Distinguishing between "reasoning errors" and "perceptual hallucinations" is critical for diagnosing correction failures, where models predict characters not present in the image.
- **Evaluation Metrics for Detection vs. Correction**: The paper distinguishes between identifying if and where an error is (detection) versus fixing it (correction), with high detection not implying high correction capability.

## Architecture Onboarding

- **Component map**: Image Input → Visual Encoder (ViT) → Alignment Layer (Projector for Qwen; Unified Transformer for InternVL) → LLM Backbone → Token Prediction → Correction Logic
- **Critical path**: Image Input → Feature Extraction → Visual-Text Alignment (High failure risk for fine details) → Token Prediction → Correction Logic
- **Design tradeoffs**: Cascaded architectures reuse unimodal backbones efficiently but lose fine visual texture through compression; native architectures better align fine details but are computationally heavier to train.
- **Failure signatures**: Over-correction (small models assume errors exist), Passivity (large models assume images are correct), Attention Miss (model fails to attend to error tokens despite looking at the image).
- **First 3 experiments**: 1) Baseline capability test with direct prompts on QwenVL-32B and InternVL-38B; 2) Joint OCR Ablation implementation to measure hallucination reduction; 3) Attention visualization using Grad-CAM to check if model ignores error tokens or looks but outputs wrong text.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can VLMs effectively leverage background visual cues to disambiguate and correct spelling errors?
- Basis: Section 5.2 explicitly raises this question about leveraging background information.
- Why unresolved: While background enhancement improves F1 scores for larger models, case studies show models still fail to link visual context to text corrections, and smaller models suffer from added noise.
- What evidence would resolve it: A training regime where background-enhanced prompting yields consistent positive gains across all model scales, specifically resolving context-dependent errors.

### Open Question 2
- Question: Why does increasing model scale lead to performance degradation in visual spelling correction?
- Basis: Section 4.2 observes that QwenVL-72B performs worse than QwenVL-32B on token correction, attributing it to larger models' strict adherence to instructions.
- Why unresolved: The paper identifies the counter-intuitive trend but doesn't determine if the failure is due to instruction-tuning overwriting implicit reasoning or fundamental capacity limits.
- What evidence would resolve it: Experiments disentangling instruction-tuning from reasoning capabilities, or a model release where scaling laws hold true for fine-grained visual correction tasks.

### Open Question 3
- Question: What architectural modifications are required to close the performance gap between VLMs and humans in error correction?
- Basis: Abstract and Conclusion highlight "fundamental limitations of existing architectures" and the gap between human (82% success) and GPT-4o (32% success) performance.
- Why unresolved: Proposed solution paradigms improve scores but fail to bridge the massive gap, suggesting current perceptual or fusion mechanisms are insufficient.
- What evidence would resolve it: A model achieving near-human performance (>75% correction accuracy) on the ReViCo benchmark without relying on external tool-augmented pipelines.

## Limitations

- Dataset Scale and Composition: Critical details about total image count, train/test splits, and Chinese/English sample ratios remain unspecified.
- Architectural Attribution Challenges: Performance differences between architectures may be confounded by model scale and training data differences rather than architectural design alone.
- Closed-Source Model Variability: Limited insight into why GPT-4o and Claude-Sonnet-4 perform better, preventing understanding whether they avoid the same failure modes or handle them more gracefully.

## Confidence

**High Confidence**:
- VLMs show significant performance gaps compared to human capabilities in visual spelling correction
- Joint OCR-Correction and Background Information Enhancement consistently improve performance across architectures
- Detection and correction are fundamentally different tasks with distinct difficulty profiles

**Medium Confidence**:
- Cascaded architectures lose fine-grained visual details through projection layers
- Background description improves correction through semantic priming
- Model scale influences correction strategy (smaller models over-correct, larger models under-correct)

**Low Confidence**:
- Native multimodal architectures inherently better utilize context for correction
- Hallucination rates directly correlate with model scale and architectural choices
- Attention patterns directly explain correction failures without confounding factors

## Next Checks

1. **Architectural Ablation Study**: Implement cascaded architecture with varying projection dimensions and native architecture at matched scales to isolate whether performance gap stems from architectural design or model capacity.

2. **Error-Free Subset Analysis**: Systematically evaluate model behavior on error-free images to quantify over-correction rates across scales and architectures, validating the "passivity" vs. "over-correction" dichotomy.

3. **Closed-Source Model Probe**: Design targeted prompts to probe whether GPT-4o and Claude-Sonnet-4 use internal OCR mechanisms or rely on different reasoning strategies, determining if their superior performance comes from architectural advantages or task-specific training.