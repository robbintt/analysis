---
ver: rpa2
title: Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets
arxiv_id: '2504.15360'
source_url: https://arxiv.org/abs/2504.15360
tags:
- fuzzy
- prediction
- conformal
- learning
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of overconfident predictions in
  classical machine learning classifiers, which can be unreliable in real-life scenarios.
  To tackle this, the authors propose integrating conformal learning with fuzzy rule-based
  classification systems to produce more reliable uncertainty quantification.
---

# Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets

## Quick Facts
- arXiv ID: 2504.15360
- Source URL: https://arxiv.org/abs/2504.15360
- Reference count: 32
- Key outcome: IV-T2 fuzzy systems provide better uncertainty quantification and non-empty prediction coverage but require more computational resources and fine-tuning compared to T1 systems

## Executive Summary
This paper addresses overconfident predictions in classical machine learning classifiers by integrating conformal learning with fuzzy rule-based classification systems. The authors propose using conformal prediction to generate prediction sets that guarantee coverage of the true class with a desired significance level, adapted for both Type 1 and interval-valued Type 2 fuzzy sets. A custom fitness function optimizes non-conformal scores for incorrect classes, improving prediction set quality. Results show IV-T2 systems achieve better uncertainty quantification with higher non-empty prediction rates and rule F1 scores, though at the cost of increased computational requirements and parameter sensitivity.

## Method Summary
The approach integrates conformal prediction with fuzzy rule-based classification (FRBC) using both Type 1 (T1) and interval-valued Type 2 (IV-T2) fuzzy sets. The method uses 8 Keel datasets, normalized by z-score, split 80/20 for training/testing with 5-fold cross-validation for conformal calibration. FRBC systems have max 15 rules with max 3 antecedents each, using 3 linguistic labels (low/medium/high) derived from data quantiles. Genetic algorithms optimize rules using Matthew correlation coefficient (MCC) plus an optional L2 regularization term (0.01 multiplier) that penalizes rules firing on incorrect classes. Non-conformity scores are computed as 1 minus the product of predictions and true labels, with IV-T2 intervals ordered using the Ka operator. Prediction sets are constructed by including all classes meeting the quantile threshold for each significance level α ∈ [0.1, 0.9].

## Key Results
- IV-T2 fuzzy systems provide better non-empty prediction coverage (60-100%) compared to T1 systems
- Custom fitness function significantly improves prediction set size and standard deviation, especially for IV-T2 systems
- Rule-wise analysis shows higher significance levels increase recall without hurting precision, with IV-T2 rules achieving better F1 scores
- Average prediction set size ranges from 0.5 to 4.0 depending on significance level

## Why This Works (Mechanism)

### Mechanism 1: Conformal Prediction Sets via Non-Conformity Scores
Conformal prediction produces prediction sets guaranteed to cover the true class with probability ≥1-α under exchangeable data assumptions. The mechanism computes non-conformity scores s_i = 1 - f̂(X_i)Y_i for each calibration sample, finds the quantile threshold q̂ = ceil((n+1)(1-α))/n, and includes all classes where f̂(X_{n+1})_y ≥ 1 - q̂ in the prediction set. Coverage guarantees fail if concept drift occurs or calibration sets diverge from test distribution.

### Mechanism 2: Interval-Type 2 Fuzzy Sets with Admissible Ordering
IV-T2 fuzzy systems capture epistemic uncertainty through interval-valued memberships, producing prediction intervals rather than point estimates. The mechanism defines conformal scores using interval subtraction and orders intervals using the Ka operator: Ka(X) = (1-a)X̄ + aX̄, then applies admissible order ≤_{α,β} to compute quantiles. IV-T2 parameters require careful tuning; undertuning leads to unstable prediction set sizes with high variance.

### Mechanism 3: Custom Fitness Function for Non-Conformal Score Optimization
A fitness function that penalizes rules firing on incorrect classes improves conformal prediction quality. The mechanism augments MCC with L2 term: L2 = Σ_r Σ_i t_{i,r}, where t_{i,r} = Σ_{y∈Y'_i} r(X_i)_y. This reduces rule confusion and improves discrimination in conformal scores. Over-regularization occurs if the multiplier is too large, sacrificing accuracy for prediction set quality.

## Foundational Learning

- **Conformal Prediction Fundamentals**: Core framework for uncertainty quantification; understanding non-conformity scores, calibration sets, and coverage guarantees is prerequisite. Quick check: Given α=0.1 and 100 calibration samples, what quantile defines the prediction threshold?
- **Fuzzy Rule-Based Classification**: The base classifier; understanding firing strength, rule antecedents/consequents, and association degree calculation. Quick check: How does the dominance score combine firing strength with rule confidence?
- **Interval Arithmetic and Ordering**: Required to extend conformal prediction to IV-T2 systems where predictions are intervals. Quick check: Given intervals [0.3, 0.7] and [0.4, 0.6], how would you determine which is "larger" using the Ka operator with α=0.5?

## Architecture Onboarding

- **Component map**: Data preprocessing -> Fuzzy partition definition -> Rule base initialization -> Genetic algorithm optimization -> Non-conformity score collection -> Prediction set construction
- **Critical path**: Define fuzzy partitions from training data quantiles → Initialize random rule population → Optimize rules via genetic algorithm (MCC + L2 fitness) → Collect non-conformity scores via K-fold cross-validation → For inference: compute class scores, apply conformal threshold, output prediction set
- **Design tradeoffs**: T1 is computationally cheaper and more stable; IV-T2 provides better non-empty prediction coverage and rule F1 scores but requires more fine-tuning. Lower α gives larger prediction sets and more non-empty predictions but less informative outputs.
- **Failure signatures**: Empty prediction sets at high significance levels indicate poorly calibrated non-conformity scores or undertuned rules. High variance in prediction set sizes suggests IV-T2 needs more training generations. Rules with high F1 in isolation but poor conformal performance indicate L2 penalty not adequately reducing rule confusion.
- **First 3 experiments**: 1) Baseline T1 vs IV-T2 comparison on Iris dataset, measuring accuracy, prediction set size, and non-empty prediction rate across α ∈ {0.1, 0.3, 0.5}. 2) Fitness function ablation: Train IV-T2 with MCC-only vs MCC+L2 (0.01 multiplier), measuring prediction set size reduction and standard deviation. 3) Rule-wise conformal analysis: For trained IV-T2, analyze per-rule F1 scores across significance levels to identify which rules benefit from higher α.

## Open Questions the Paper Calls Out

### Open Question 1
Does extending genetic optimization budget for IV-T2 systems close the classification accuracy gap with T1 systems while maintaining superior non-empty prediction coverage? The experiments used the same number of generations for both types, leaving the performance ceiling of fully optimized IV-T2 systems undetermined. Ablation studies showing IV-T2 convergence over extended training generations compared to T1 baselines would resolve this.

### Open Question 2
How does integration of General Type-2 (GT2) fuzzy sets affect the trade-off between prediction set efficiency and computational cost in conformal learning? The study was limited to Interval Type-2 sets; GT2 sets introduce a third dimension (secondary membership) which may capture epistemic uncertainty differently but with higher complexity. Comparative benchmarks of GT2 fuzzy systems on the same datasets would resolve this.

### Open Question 3
Can fuzzy rule-based conformal classifiers maintain rule interpretability and reliability when applied to high-dimensional computer vision datasets? The current study used low-dimensional tabular data; it is unclear if the 15-rule limit and simple antecedent structure can model complex visual features without becoming incomprehensible or requiring excessive rules. Application to standard image datasets with semantic analysis of generated fuzzy rules would resolve this.

## Limitations
- Genetic algorithm hyperparameters (population size, generations, mutation/crossover rates) not specified, making faithful reproduction difficult
- Specific α, β values for Ka operator in interval ordering are absent, as is the exact formula for dominance score computation
- Experimental validation lacks statistical significance testing across multiple random seeds

## Confidence
- **High confidence**: Conformal prediction guarantees coverage under exchangeability assumptions; basic T1 fuzzy system implementation
- **Medium confidence**: IV-T2 system performance benefits; custom fitness function effectiveness on IV-T2
- **Low confidence**: Specific hyperparameter choices; generalizability across datasets; statistical significance of performance differences

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary genetic algorithm generations (50-200) and IV-T2-specific parameters to identify minimum viable configurations that achieve stable prediction set sizes
2. **Statistical significance testing**: Run each experiment across 10 random seeds with different train/test splits, apply paired t-tests to compare T1 vs IV-T2 performance metrics
3. **Cross-dataset robustness**: Test the approach on UCI datasets not in the original Keel collection (e.g., Adult, Breast Cancer Wisconsin) to evaluate generalization beyond the initial experimental domain