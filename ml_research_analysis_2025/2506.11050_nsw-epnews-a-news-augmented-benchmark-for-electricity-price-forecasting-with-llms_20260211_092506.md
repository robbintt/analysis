---
ver: rpa2
title: 'NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with
  LLMs'
arxiv_id: '2506.11050'
source_url: https://arxiv.org/abs/2506.11050
tags:
- data
- news
- prices
- prompt
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "NSW-EPNews introduces a multimodal benchmark for electricity price\
  \ forecasting, combining historical price data, temperature readings, and curated\
  \ news summaries from the Australian NEM. The dataset spans 2015\u20132024 and includes\
  \ over 175,000 half-hourly prices, 3.6k prompt-output pairs, and structured news\
  \ annotations."
---

# NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with LLMs

## Quick Facts
- **arXiv ID**: 2506.11050
- **Source URL**: https://arxiv.org/abs/2506.11050
- **Reference count**: 40
- **Primary result**: LLMs exhibit inconsistent accuracy and frequent hallucinations for electricity price forecasting despite advanced prompt engineering

## Executive Summary
NSW-EPNews introduces a multimodal benchmark for electricity price forecasting that combines historical price data, temperature readings, and curated news summaries from the Australian NEM. The dataset spans 2015-2024 and includes over 175,000 half-hourly prices, 3.6k prompt-output pairs, and structured news annotations. Traditional forecasting models show minimal gains from news features, while state-of-the-art LLMs exhibit inconsistent accuracy and frequent hallucinations. Despite advanced prompt engineering, LLMs remain unreliable for high-stakes energy forecasting, highlighting a critical gap between current capabilities and real-world requirements.

## Method Summary
The NSW-EPNews benchmark combines historical electricity price data from the Australian National Electricity Market (NEM) with temperature readings and curated news summaries. The dataset covers the period from 2015 to 2024 and includes over 175,000 half-hourly price points. News articles are processed through automated extraction and summarization pipelines to create structured annotations relevant to electricity markets. The benchmark provides 3.6k prompt-output pairs for evaluation purposes. Traditional forecasting models (ARIMA, Linear Regression, XGBoost) are compared against state-of-the-art LLMs including GPT-4o and Gemini 1.5 Pro, with evaluation focusing on forecast accuracy and hallucination detection.

## Key Results
- Traditional forecasting models (ARIMA, Linear Regression, XGBoost) show minimal gains from incorporating news features
- State-of-the-art LLMs exhibit inconsistent accuracy and frequent hallucinations in electricity price forecasting
- LLMs generate malformed sequences and echo historical prices despite advanced prompt engineering
- Current LLMs remain unreliable for high-stakes energy forecasting applications

## Why This Works (Mechanism)
The benchmark demonstrates that while multimodal information (prices, temperatures, news) contains relevant signals for electricity price forecasting, current LLMs struggle to effectively integrate and reason over this information. The news augmentation provides contextual signals about market events, regulatory changes, and supply-demand dynamics that can influence electricity prices. However, LLMs show difficulty in distinguishing relevant from irrelevant information and maintaining temporal consistency in their forecasts.

## Foundational Learning
- **Electricity market fundamentals**: Understanding supply-demand dynamics, spot pricing mechanisms, and regulatory influences is crucial for interpreting price movements and the relevance of news features
- **Time series forecasting**: Knowledge of traditional forecasting methods (ARIMA, regression models) provides baseline performance expectations and highlights the limitations of news incorporation
- **Multimodal data integration**: Understanding how different data types (numerical prices, categorical news, temporal patterns) interact is essential for evaluating LLM performance
- **Hallucination detection**: Ability to identify when models generate plausible but incorrect information is critical for assessing reliability in high-stakes applications

## Architecture Onboarding

Component map:
Raw data (prices, temperatures, news articles) -> Preprocessing pipeline -> Structured benchmark -> Model evaluation framework -> Performance metrics

Critical path:
Data collection and preprocessing -> Benchmark construction -> Model training and inference -> Evaluation and analysis

Design tradeoffs:
The benchmark prioritizes comprehensive data coverage over real-time processing capabilities. News summarization balances detail with conciseness to maintain relevance while reducing noise. Evaluation focuses on accuracy metrics while also incorporating hallucination detection, recognizing that reliability is as important as precision in energy forecasting.

Failure signatures:
Models may generate prices outside historical ranges, repeat previous patterns without adaptation, or produce temporally inconsistent sequences. News integration may introduce noise rather than signal, particularly when articles are tangentially related to energy markets.

First experiments:
1. Baseline comparison: Evaluate traditional models (ARIMA, Linear Regression, XGBoost) on price-only data versus price + temperature + news features
2. LLM performance isolation: Test LLMs on synthetic price patterns with controlled news inputs to identify hallucination patterns
3. Temporal consistency check: Analyze model outputs for temporal coherence across consecutive forecasting intervals

## Open Questions the Paper Calls Out
None

## Limitations
- Limited error analysis and confidence intervals for LLM performance metrics make statistical significance difficult to assess
- Reliance on news summaries from a single Australian market may limit generalizability to other regions
- Advanced prompt engineering did not substantially improve LLM reliability for high-stakes applications

## Confidence
- High confidence in the benchmark construction methodology and dataset characteristics
- Medium confidence in the comparative performance analysis between traditional models and LLMs
- Low confidence in the generalizability of findings to other electricity markets or forecasting horizons

## Next Checks
1. Conduct cross-market validation by testing the benchmark with electricity price data from different regions (e.g., European markets) to assess generalizability
2. Perform ablation studies to isolate the impact of different news features on model performance across various forecasting horizons
3. Implement statistical significance testing for LLM performance differences and provide confidence intervals for all reported metrics