---
ver: rpa2
title: Spoken Language Understanding on Unseen Tasks With In-Context Learning
arxiv_id: '2505.07731'
source_url: https://arxiv.org/abs/2505.07731
tags:
- fine-tuning
- tasks
- arxiv
- language
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of enabling spoken language
  understanding (SLU) tasks on unseen domains without task-specific annotations. Traditional
  SLU models require supervised data for each task, while speech-text large language
  models (LLMs) show limited zero-shot performance on SLU tasks.
---

# Spoken Language Understanding on Unseen Tasks With In-Context Learning

## Quick Facts
- arXiv ID: 2505.07731
- Source URL: https://arxiv.org/abs/2505.07731
- Authors: Neeraj Agrawal; Sriram Ganapthy
- Reference count: 0
- Primary result: Random-label fine-tuning improves zero/few-shot SLU on unseen tasks by 10.1% to 95.3% over regular fine-tuning

## Executive Summary
This paper addresses the challenge of enabling spoken language understanding (SLU) tasks on unseen domains without task-specific annotations. Traditional SLU models require supervised data for each task, while speech-text LLMs show limited zero-shot performance. The authors propose randomized label fine-tuning, where class definitions are randomly permuted during training to force the model to follow instructions rather than memorize label semantics. This approach, combined with in-context learning using textual demonstrations, significantly improves performance on unseen SLU tasks.

## Method Summary
The approach uses SALMONN speech-text LLM with LoRA fine-tuning. During training, class definitions are randomly permuted across mini-batches, forcing the model to attend to task instructions rather than pre-learned semantic associations. The fine-tuning includes speech encoder, Q-former, and LoRA parameters (r=8, α=32, dropout=0.1). At inference, the model uses in-context learning with text demonstrations and correct class definitions for the unseen target task. The method is evaluated on sentiment analysis, dialogue act classification, and named entity recognition tasks using the SLUE benchmark.

## Key Results
- Relative improvements of 10.1% on SLUE-VoxCeleb, 95.3% on SLUE-HVB, and 64.3% on SLUE-VoxPopuli over regular fine-tuning
- Randomized label fine-tuning enables effective zero-shot and few-shot learning on unseen SLU tasks
- The approach sacrifices some matched-task performance to gain generalization capabilities for mismatched tasks

## Why This Works (Mechanism)

### Mechanism 1
Randomly permuting class definitions during fine-tuning forces the model to attend to task instructions rather than relying on pre-learned semantic associations. During each mini-batch, the mapping between class names and their definitions is randomized, preventing the model from forming fixed label-to-meaning associations and instead training it to map from the provided definition to the correct output.

### Mechanism 2
Task-agnostic fine-tuning on a mismatched task activates emergent instruction-following abilities that transfer across SLU task types. By fine-tuning on any SLU task with randomized labels, the model learns a generalizable "task schema" - how to parse instructions, extract relevant speech features, and map to outputs - without overfitting to task-specific patterns.

### Mechanism 3
Text-based demonstrations combined with speech queries create a cross-modal in-context learning signal that is enhanced by random-label fine-tuning. During fine-tuning, textual few-shot demonstrations with randomized labels accompany speech queries, training the model to ground speech representations using textual context.

## Foundational Learning

- **Concept: In-Context Learning (ICL)** - Why needed: The entire approach relies on the model's ability to learn from demonstrations at inference time without gradient updates. Quick check: Can you explain why ICL differs from standard supervised learning, and what "few-shot prompting" means operationally?

- **Concept: LoRA (Low-Rank Adaptation) Fine-tuning** - Why needed: The paper uses LoRA to efficiently fine-tune the LLaMA backbone within SALMONN. Quick check: What are the key hyperparameters (rank, alpha, dropout) in LoRA, and how do they affect the number of trainable parameters?

- **Concept: Speech-Text LLM Architecture (Encoder → Q-Former → LLM)** - Why needed: SALMONN's architecture determines what components are fine-tuned. Quick check: What is the role of the Q-former in bridging the speech encoder and the text LLM?

## Architecture Onboarding

- **Component map:** Speech audio + text prompt -> BEATs encoder -> Q-former -> LLaMA-13B with LoRA -> Text token generation
- **Critical path:** Construct prompt with randomized class definitions -> Encode speech through BEATs → Q-former → LLM -> Generate label tokens -> Compute cross-entropy loss -> Backpropagate through LoRA parameters, Q-former, and speech encoder
- **Design tradeoffs:** Randomization degree (6 permutations for VoxCeleb, 10 for HVB); text demonstrations vs. speech demonstrations (context window constraints); batch size = 1 (required due to context/model constraints)
- **Failure signatures:** Matched performance drops (expected tradeoff); zero-shot remains near-random on mismatched tasks (check permutation application); few-shot performance degrades with more demonstrations (poor demonstration retrieval)
- **First 3 experiments:** 1) Baseline replication: Run SALMONN with No-FT, Regular FT, and Random-Label FT on Voxceleb → Voxceleb (matched) to verify the tradeoff. 2) Cross-task transfer test: Fine-tune on Voxceleb with random labels, evaluate on HVB mismatched with 0-5 text demonstrations. 3) Ablation on permutation count: Test whether 2, 6, or 10 permutations for Voxceleb affects mismatched performance.

## Open Questions the Paper Calls Out
- **Open Question 1:** What are the theoretical mechanisms by which randomized label fine-tuning prevents semantic collapse and improves instruction following in speech-text LLMs? The paper explicitly states this as a future work direction without formal theoretical explanation.
- **Open Question 2:** Does the efficacy generalize to generative SLU tasks or low-resource languages outside of English classification tasks tested? The experiments are restricted to English classification tasks, leaving generative capabilities and multilingual transfer unverified.
- **Open Question 3:** Is the observed performance improvement dependent on the SALMONN architecture, or does it generalize to other speech-text LLMs? The experiments only use SALMONN, making it unclear if gains are universal or specific to this implementation.

## Limitations
- The approach sacrifices matched-task performance to gain generalization capabilities for mismatched tasks, showing clear tradeoff between specialization and generalization.
- Effectiveness depends on the semantic distinguishability of class definitions - highly overlapping definitions may introduce excessive noise that degrades performance.
- Relies on text demonstrations rather than speech demonstrations due to context window constraints, which may limit effectiveness for tasks where acoustic features are crucial.

## Confidence
- **High confidence:** Empirical demonstration that random-label fine-tuning improves mismatched task performance while sacrificing matched performance
- **Medium confidence:** Mechanism that randomization forces instruction-following rather than label memorization
- **Medium confidence:** Claim of emergent cross-task generalization capabilities

## Next Checks
1. **Permutation sensitivity analysis:** Systematically vary the number of label permutations (2, 4, 6, 10) for VoxCeleb and measure the matched/mismatched performance tradeoff curve to identify optimal randomization degree.

2. **Definition quality ablation:** Create controlled experiments with semantically similar vs. distinct class definitions to measure how definition quality affects random-label fine-tuning effectiveness, isolating the noise vs. signal tradeoff.

3. **Cross-modal demonstration test:** Replace text demonstrations with speech demonstrations (when feasible within context limits) to measure whether audio-based in-context learning further improves performance, particularly for tasks where acoustic features matter.