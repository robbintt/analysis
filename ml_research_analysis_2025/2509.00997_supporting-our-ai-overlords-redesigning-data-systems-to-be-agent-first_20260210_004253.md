---
ver: rpa2
title: 'Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First'
arxiv_id: '2509.00997'
source_url: https://arxiv.org/abs/2509.00997
tags:
- data
- agents
- probes
- agentic
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new architecture for agent-first data systems
  designed to support Large Language Model (LLM) agents as the dominant workload.
  The authors identify that LLM agents employ "agentic speculation" - a high-throughput,
  exploratory process of metadata discovery and solution formulation that poses challenges
  for traditional data systems.
---

# Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First

## Quick Facts
- arXiv ID: 2509.00997
- Source URL: https://arxiv.org/abs/2509.00997
- Authors: Shu Liu; Soujanya Ponnapalli; Shreya Shankar; Sepanta Zeighami; Alan Zhu; Shubham Agarwal; Ruiqi Chen; Samion Suwito; Shuo Yuan; Ion Stoica; Matei Zaharia; Alvin Cheung; Natacha Crooks; Joseph E. Gonzalez; Aditya G. Parameswaran
- Reference count: 22
- Primary result: LLM agents employ "agentic speculation" - a high-throughput, exploratory process that poses challenges for traditional data systems

## Executive Summary
This paper proposes a new architecture for agent-first data systems designed to support Large Language Model (LLM) agents as the dominant workload. The authors identify that LLM agents employ "agentic speculation" - a high-throughput, exploratory process of metadata discovery and solution formulation that poses challenges for traditional data systems. Through case studies on text-to-SQL tasks and multi-database operations, they demonstrate that agentic workloads are high-volume, heterogeneous, redundant, and steerable. The proposed architecture includes an agentic interpreter, probe optimizer, agentic memory store, and shared transaction manager, with innovations in satisficing query optimization and efficient handling of branched updates.

## Method Summary
The paper characterizes agentic workloads through empirical analysis of text-to-SQL tasks using the BIRD benchmark with DuckDB backend and multi-database operations across PostgreSQL, SQLite, MongoDB, and DuckDB. The authors employ GPT-4o-mini and Qwen2.5-Coder-7B-Instruct for BIRD tasks and OpenAI o3 for multi-database tasks, running 50 parallel attempts per problem to measure redundancy. They manually label 44 traces across 22 multi-database tasks into activity types to evaluate the impact of grounding hints. The study focuses on success rates at different parallelism levels, subexpression redundancy analysis, and activity counts with and without grounding hints.

## Key Results
- Agentic workloads exhibit high redundancy with <20% unique sub-plans across 50 parallel attempts on BIRD dataset
- Providing grounding hints reduces total SQL queries by over 20%, with "attempting part of the query" down 36.6%
- Agents create 20× more branches and perform 50× more rollbacks relative to humans in production systems
- Satisficing optimization can return approximate results sufficient for agent decision-making without full query evaluation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agentic speculation exhibits high redundancy across parallel attempts, enabling computation sharing
- Mechanism: When multiple agents explore solutions independently, they generate overlapping query sub-plans. By identifying and sharing common sub-expressions across these attempts, the system can amortize computational cost
- Core assumption: Agents pursuing similar goals will produce structurally similar query patterns even when working independently
- Evidence anchors: Figure 2a shows distinct sub-plans are <10-20% of total across 50 parallel attempts; Figure 2b breaks down redundancy by operator type with uniqueness ratios consistently below 50%

### Mechanism 2
- Claim: Proactive grounding hints from the data system can steer agents toward more efficient exploration paths
- Mechanism: The data system provides auxiliary information (e.g., which tables contain relevant columns, schema conventions) alongside query results, reducing the "grounding gap" agents must close through trial-and-error metadata discovery
- Core assumption: The data system can accurately infer what grounding information is relevant to the agent's intent from the probe brief
- Evidence anchors: Table 1 shows providing expert hints reduced total SQL queries by 18.1%, with "attempting part of the query" down 36.6%

### Mechanism 3
- Claim: Agents exploring hypothetical updates require branch-heavy transaction patterns with efficient fork/rollback semantics
- Mechanism: Agents formulate multiple "what-if" scenarios by forking database state, applying speculative updates, and rolling back failed branches. Copy-on-write with logical isolation allows physical sharing across similar branches
- Core assumption: Most speculative branches share large portions of identical state (same schema, 90%+ identical data)
- Evidence anchors: Neon production data cited: agents create 20× more branches and perform 50× more rollbacks relative to humans

## Foundational Learning

- Concept: Multi-query optimization
  - Why needed here: The probe optimizer must identify shared sub-expressions across hundreds of concurrent agent queries to avoid redundant computation
  - Quick check question: Given 50 SQL queries, can you identify which share common scan or join operations?

- Concept: Approximate query processing (AQP)
  - Why needed here: "Satisficing" optimization requires returning approximate results sufficient for agent decision-making without full query evaluation
  - Quick check question: How would you provide a 95% confidence interval for an aggregate query using only 1% of the data?

- Concept: MVCC (Multi-Version Concurrency Control)
  - Why needed here: Branched updates extend MVCC concepts to support thousands of near-identical snapshots with fast abort/rollback semantics
  - Quick check question: How does copy-on-write enable multiple readers to access different versions of the same data without blocking?

## Architecture Onboarding

- Component map: Agent issues probe with brief -> Agentic Interpreter extracts semantic intent -> Probe Optimizer decides execution plan -> Agentic Memory Store provides cached grounding -> Sleeper Agents may provide auxiliary hints -> Results returned with optional steering information

- Critical path:
  1. Agent issues probe with brief (goal + phase + SQL)
  2. Interpreter extracts semantic intent, consults memory store for cached grounding
  3. Optimizer decides execution plan (which queries, what accuracy, sharing opportunities)
  4. Sleeper agents may provide auxiliary hints or cost feedback
  5. Results returned with optional steering information

- Design tradeoffs:
  - **Accuracy vs. latency**: Satisficing returns faster but may trigger follow-up probes; exact answers cost more upfront
  - **Memory freshness vs. consistency**: Agentic memory store may be stale; aggressive updates improve freshness but add overhead
  - **Branch isolation vs. sharing**: Stronger isolation limits physical sharing; weaker isolation risks cross-contamination

- Failure signatures:
  - Memory store returns stale schema info → agent generates invalid SQL → retry loop
  - Over-aggressive approximation in solution-formulation phase → agent cannot validate answer → repeated probing
  - Branch explosion without cleanup → storage exhaustion from unpruned speculative states

- First 3 experiments:
  1. Measure redundancy: Run BIRD benchmark with 10-50 parallel agent attempts per task; compute unique sub-plan ratios across operator types to validate <20% uniqueness claim
  2. Test steering impact: Compare agent query counts with and without schema hints on multi-database tasks; validate 18-36% reduction claim
  3. Prototype branch manager: Implement copy-on-write fork for a simple key-value store; measure branch creation time and memory overhead with 100 concurrent branches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can natural language briefs (goals, phases, priorities) be automatically translated into concrete accuracy and approximation levels for query execution?
- Basis in paper: Section 4.1 states "Determining how to set accuracy based on this natural language input is an open question and needs to also take into account relative query execution costs."
- Why unresolved: Mapping open-ended NL intent to quantitative parameters requires semantic reasoning about both query semantics and cost-accuracy trade-offs, which existing optimizers do not support.
- What evidence would resolve it: A functional mapping or learned model that, given a brief and probe batch, outputs approximation degrees that reduce total turns-to-solution compared to fixed-default policies, evaluated on agentic workloads.

### Open Question 2
- Question: How should satisficing optimizers decide which queries to execute and to what accuracy to minimize total interaction time across sequential agent turns?
- Basis in paper: Section 5.2 frames the goal as minimizing "total time spent on answering the field agents' probes," noting that over-approximating can increase follow-ups, while exact execution may waste cost upfront.
- Why unresolved: Requires reasoning about future probes and the information gain of partial answers, which depends on agent behavior not known at optimization time.
- What evidence would resolve it: An optimizer that, under simulated agentic speculation traces, achieves lower total latency and fewer follow-up probes than baseline strategies (e.g., always-approximate, always-exact), with robustness across task types.

### Open Question 3
- Question: How can an agentic memory store efficiently share grounded knowledge across agents while preserving access-control boundaries and consistency under data evolution?
- Basis in paper: Section 6.1 highlights privacy concerns from sharing answers across agents and staleness risks when schemas or data change, suggesting these are unresolved challenges.
- Why unresolved: Cross-agent sharing can leak information in aggregate, and stale grounding may mislead agents; no clear protocol exists for scoped sharing and lazy/triggered invalidation.
- What evidence would resolve it: A system design demonstrating quantifiable efficiency gains from reuse, plus correctness guarantees (e.g., no cross-tenant leakage via membership tests) and freshness constraints satisfied despite updates.

## Limitations
- Empirical claims rely heavily on specific LLM models (GPT-4o-mini, Qwen2.5-Coder-7B-Instruct, OpenAI o3) that may not generalize to other agents or domains
- Redundancy analysis may not hold for more complex reasoning tasks or when agents have divergent goals
- Grounding hints mechanism assumes the data system can accurately infer relevant context from natural language briefs—this capability is not fully validated
- Branched update patterns are based on production observations from Neon but lack controlled experiments showing the proposed architecture's effectiveness
- Satisficing optimization concept remains largely theoretical without quantitative comparisons to exact query processing

## Confidence

- **High Confidence**: The characterization of agentic workloads as high-volume, heterogeneous, and redundant is well-supported by the BIRD benchmark analysis and multi-database task traces
- **Medium Confidence**: The proposed probe optimizer's ability to identify and share common sub-expressions across concurrent agent queries is reasonable but requires more extensive validation across diverse workloads
- **Low Confidence**: The satisficing optimization framework and multi-world isolation for branched updates are conceptual contributions without empirical validation

## Next Checks

1. **Generalization Study**: Test redundancy patterns across diverse agent workloads (e.g., code generation, scientific reasoning) to validate that <20% unique sub-plans is a general property of agentic speculation, not specific to text-to-SQL tasks

2. **Hint Quality Analysis**: Systematically evaluate how hint accuracy affects agent performance—measure query reduction when hints are perfectly relevant vs. partially relevant vs. misleading to understand robustness requirements

3. **Branch Overhead Measurement**: Implement the proposed copy-on-write branch manager and measure memory overhead, creation latency, and cleanup costs under realistic workloads (e.g., 100+ concurrent branches with varying degrees of divergence)