---
ver: rpa2
title: Toward Faithful Explanations in Acoustic Anomaly Detection
arxiv_id: '2601.12660'
source_url: https://arxiv.org/abs/2601.12660
tags:
- anomaly
- detection
- error
- interpretability
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the interpretability of autoencoder-based
  models for acoustic anomaly detection, focusing on standard autoencoders (AE) and
  masked autoencoders (MAE). While MAE shows a slightly lower detection performance
  (AUC of 0.864 vs.
---

# Toward Faithful Explanations in Acoustic Anomaly Detection

## Quick Facts
- arXiv ID: 2601.12660
- Source URL: https://arxiv.org/abs/2601.12660
- Reference count: 0
- Primary result: MAE provides more faithful explanations than AE for acoustic anomaly detection

## Executive Summary
This work investigates the interpretability of autoencoder-based models for acoustic anomaly detection, comparing standard autoencoders (AE) with masked autoencoders (MAE). While MAE shows slightly lower detection performance (AUC of 0.864 vs. AE's 0.885), it consistently provides more faithful and temporally precise explanations that better align with true anomalies. The study employs multiple attribution methods including error maps, saliency maps, SmoothGrad, Integrated Gradients, GradSHAP, and Grad-CAM, along with a novel perturbation-based faithfulness metric that replaces highlighted regions with their reconstructions to simulate normal input. Experimental results on real industrial data demonstrate that MAE-based explanations achieve higher faithfulness scores and better F-scores for temporal overlap with human-annotated anomalies, making MAE particularly suited for industrial applications where interpretability and actionable insights are essential.

## Method Summary
The research focuses on autoencoder-based approaches for acoustic anomaly detection, comparing standard autoencoders (AE) and masked autoencoders (MAE). The authors apply various attribution methods including error maps, saliency maps, SmoothGrad, Integrated Gradients, GradSHAP, and Grad-CAM to identify important regions in the input signal. They introduce a perturbation-based faithfulness metric that measures how well explanations align with actual anomalies by replacing highlighted regions with their reconstructions. The methodology is evaluated on an industrial dataset, with human annotations serving as ground truth for anomaly localization. The study specifically examines temporal precision and faithfulness of explanations, providing insights into which methods best capture anomalous regions.

## Key Results
- MAE achieves slightly lower detection performance (AUC 0.864) compared to AE (AUC 0.885) but provides more faithful explanations
- MAE-based explanations, particularly error maps, show better F-scores for temporal overlap with human-annotated anomalies
- The perturbation-based faithfulness metric effectively quantifies explanation quality by measuring performance degradation when replacing highlighted regions
- Masked training improves explanation quality without significantly compromising detection performance

## Why This Works (Mechanism)
The mechanism behind MAE's superior interpretability stems from its masked training approach, which forces the model to learn more robust and generalizable features by reconstructing only visible parts of the input. This training paradigm enhances the model's ability to distinguish between normal and anomalous patterns, resulting in explanations that better align with actual anomalies. The perturbation-based faithfulness metric provides a principled way to evaluate explanation quality by measuring the impact of removing or replacing highlighted regions on the model's ability to detect anomalies. This approach ensures that explanations are not just visually interpretable but also functionally relevant to the detection task.

## Foundational Learning
**Autoencoders for Anomaly Detection**
- Why needed: Learn compressed representations of normal data to identify deviations
- Quick check: Can the model reconstruct normal data accurately while failing on anomalies

**Masked Autoencoders (MAE)**
- Why needed: Improve robustness and generalization by training on incomplete inputs
- Quick check: Does masking enhance feature learning and explanation quality

**Attribution Methods**
- Why needed: Identify which input regions most influence model predictions
- Quick check: Do different attribution methods consistently highlight the same anomalous regions

**Faithfulness Metrics**
- Why needed: Quantify how well explanations align with actual model behavior
- Quick check: Does removing highlighted regions significantly impact detection performance

**Temporal Precision**
- Why needed: Ensure explanations accurately localize anomalies in time
- Quick check: How well do explanation boundaries align with ground truth anomaly timestamps

## Architecture Onboarding

**Component Map**
Input Audio -> Autoencoder (AE/MAE) -> Reconstruction Error -> Attribution Method -> Explanation Output

**Critical Path**
1. Audio signal preprocessing
2. Autoencoder training (with/without masking)
3. Anomaly detection through reconstruction error
4. Attribution method application
5. Explanation evaluation using faithfulness metric

**Design Tradeoffs**
- Detection performance vs. explanation faithfulness
- Model complexity vs. interpretability
- Computational cost of attribution methods
- Temporal resolution vs. explanation clarity

**Failure Signatures**
- Explanations that highlight normal regions
- Temporal misalignment with actual anomalies
- High faithfulness scores despite poor detection performance
- Inconsistent attribution across different methods

**First 3 Experiments**
1. Compare AE and MAE detection performance using AUC
2. Evaluate explanation faithfulness using perturbation metric
3. Measure temporal precision through F-score with human annotations

## Open Questions the Paper Calls Out
None

## Limitations
- Results based on a single industrial dataset, limiting generalizability
- Faithfulness metric assumes reconstruction quality directly correlates with normal behavior
- Human annotations may contain subjective bias
- Perturbation method could introduce artifacts in certain scenarios

## Confidence
High confidence in: detection performance comparisons between AE and MAE, faithfulness metric methodology, temporal precision measurements
Medium confidence in: generalizability across different acoustic domains, the relationship between reconstruction quality and normal behavior
Low confidence in: the optimal threshold for perturbation-based evaluation, the complete elimination of potential artifacts in perturbation method

## Next Checks
1. Test the approach across multiple industrial datasets to verify robustness and generalizability
2. Conduct a controlled experiment varying reconstruction quality independently of anomaly presence to validate the faithfulness metric assumptions
3. Implement cross-validation with multiple human annotators to assess inter-rater reliability and potential annotation bias