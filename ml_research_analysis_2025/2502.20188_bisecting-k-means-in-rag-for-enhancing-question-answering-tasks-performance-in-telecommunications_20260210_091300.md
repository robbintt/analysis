---
ver: rpa2
title: Bisecting K-Means in RAG for Enhancing Question-Answering Tasks Performance
  in Telecommunications
arxiv_id: '2502.20188'
source_url: https://arxiv.org/abs/2502.20188
tags:
- arxiv
- information
- query
- data
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a RAG framework for telecommunications domain
  question-answering using Bisecting K-Means clustering on embeddings to organize
  3GPP document chunks by content. A routing module pre-selects relevant clusters
  for each query, improving retrieval relevance.
---

# Bisecting K-Means in RAG for Enhancing Question-Answering Tasks Performance in Telecommunications

## Quick Facts
- **arXiv ID:** 2502.20188
- **Source URL:** https://arxiv.org/abs/2502.20188
- **Reference count:** 22
- **Primary result:** RAG framework using Bisecting K-Means clustering achieves 66.12% accuracy with phi-2 and 72.13% with phi-3 on TeleQnA benchmark

## Executive Summary
This work proposes a RAG framework for telecommunications domain question-answering using Bisecting K-Means clustering on embeddings to organize 3GPP document chunks by content. A routing module pre-selects relevant clusters for each query, improving retrieval relevance. The framework was evaluated using small language models (phi-2 and phi-3) fine-tuned on the TeleQnA dataset, achieving 66.12% and 72.13% accuracy respectively, with training times under 16 hours. The approach enhances retrieval efficiency and model performance while maintaining computational feasibility for deployment.

## Method Summary
The framework preprocesses 3GPP documents by chunking into 500-character segments, generating embeddings with BAAI/bge-large-en, and applying Bisecting K-Means clustering (18 clusters) to organize chunks by semantic content. A routing module selects top-8 relevant clusters per query by comparing query embeddings to cluster centroids through feed-forward layers and softmax. Retrieved context is used to fine-tune small language models (phi-2, phi-3) on the TeleQnA dataset. Queries are enhanced with extracted telecommunications terms and abbreviations to improve SLM comprehension.

## Key Results
- Achieved 66.12% accuracy with phi-2 and 72.13% with phi-3 on TeleQnA benchmark
- Training completed in under 16 hours on 8 vCPUs, 30GB RAM, 1× NVIDIA L4 (24GB VRAM)
- 500-character chunks outperformed 250-character chunks for phi-2
- Standard fine-tuning outperformed enhanced response fine-tuning despite lower traceability

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Bisecting K-Means clustering organizes document embeddings by semantic content rather than source document structure, improving retrieval relevance.
- **Mechanism:** Bisecting K-Means uses hierarchical divisive approach—starting with one cluster and recursively splitting the cluster with highest SSE to iteratively refine boundaries where internal variability is highest.
- **Core assumption:** Documents with similar embedding vectors contain semantically related information relevant to the same queries.
- **Evidence anchors:**
  - [abstract] "The framework introduces the use of the Bisecting K-Means clustering technique to organize the embedding vectors by contents, facilitating more efficient information retrieval."
  - [section III.C] "This method is a variant of the K-Means algorithm that aims to improve the quality of the clusters formed, offering advantages in the segmentation of large volumes of data."
  - [corpus] Related work (TopClustRAG, arXiv:2506.15246) also employs K-Means clustering post-retrieval for semantic grouping, suggesting clustering-based retrieval is an active research direction, though direct comparisons to Bisecting K-Means are not available in the corpus.
- **Break condition:** If documents span multiple topics per chunk, or if chunk size is too large to capture coherent semantic units, clustering by embedding similarity may group unrelated content.

### Mechanism 2
- **Claim:** The routing module reduces search space by selecting only top-K relevant clusters before fine-grained retrieval.
- **Mechanism:** Query embeddings and cluster centroids are processed through feed-forward layers (both reduced to 256 dimensions), linearly combined, then passed through softmax to produce cluster relevance probabilities. Only top-K clusters (K=8) are searched via FAISS indexing.
- **Core assumption:** Query-cluster similarity at the centroid level is sufficient proxy for chunk-level relevance within those clusters.
- **Evidence anchors:**
  - [abstract] "By leveraging this clustering technique, the system pre-selects a subset of clusters that are most similar to the user's query, enhancing the relevance of the retrieved information."
  - [section III.D] "By concentrating on this subset, the system can efficiently perform searches in the embedding space, narrowing down the relevant chunks of information without needing to search the entire space."
  - [corpus] No direct corpus evidence evaluates routing modules against full-space search; related RAG frameworks (Chat3GPP, arXiv:2501.13954) do not explicitly compare routing efficiency.
- **Break condition:** If relevant chunks are distributed across clusters not selected in top-K, retrieval will miss critical context.

### Mechanism 3
- **Claim:** Query enhancement with domain-specific definitions and abbreviations improves SLM comprehension of telecom terminology.
- **Mechanism:** Two dictionaries (technical terms and abbreviations) are extracted from 3GPP documentation. Queries are augmented inline with definitions before embedding and retrieval.
- **Core assumption:** SLMs like phi-2 lack sufficient telecom-specific knowledge from pre-training; explicit term expansion compensates for this gap.
- **Evidence anchors:**
  - [section III.A] "Language models, such as phi-2, are usually trained with general data, so they might not grasp the specific technical terms found in 3GPP standard documents."
  - [section III.A] "These resources are utilized to expand the query and provide better context when retrieving information relevant to the questions."
  - [corpus] Weak corpus evidence; related telecom RAG papers mention acronym challenges but do not isolate query enhancement as a variable.
- **Break condition:** If query expansion introduces noise or definitions that conflict with user intent, retrieval may retrieve tangentially related chunks.

## Foundational Learning

- **Concept: Embedding-based semantic search**
  - **Why needed here:** The entire retrieval pipeline depends on converting text chunks and queries to dense vectors; misunderstanding embedding space operations will obscure why clustering and similarity search work.
  - **Quick check question:** Given two chunks with cosine similarity 0.92, what does this imply about their semantic relationship?

- **Concept: Hierarchical clustering (divisive approach)**
  - **Why needed here:** Bisecting K-Means differs from flat K-Means; understanding the recursive splitting logic (using SSE as split criterion) is essential to diagnose cluster quality.
  - **Quick check question:** Why would a cluster with high SSE be prioritized for splitting over one with low SSE?

- **Concept: RAG fine-tuning with retrieved context**
  - **Why needed here:** The paper fine-tunes SLMs on training examples that include RAG-retrieved context, not just raw QA pairs. This differs from standard fine-tuning.
  - **Quick check question:** What is the potential risk of fine-tuning on RAG-retrieved context that may occasionally be irrelevant?

## Architecture Onboarding

- **Component map:** 3GPP documents → chunking (500 chars) → embeddings (BAAI bge-large-en) → Bisecting K-Means (18 clusters) → SQLite3 vector DB → User query → query enhancement → embedding → routing module → top-8 cluster selection → FAISS retrieval → context assembly → fine-tuned SLM → response

- **Critical path:**
  1. Chunk size selection (500 chars) directly affects embedding granularity and cluster coherence.
  2. Cluster count (18) determines routing granularity; too few clusters dilute relevance, too many increase routing complexity.
  3. Top-K selection (8) trades recall vs. latency; this is the primary retrieval bottleneck.

- **Design tradeoffs:**
  - Chunk size 500 vs. 250 chars: Figure 3 shows 500 chars outperforms 250 for phi-2, but optimal size may vary by embedding model and document structure.
  - Bisecting K-Means vs. standard K-Means: Figure 4 shows accuracy improvement, but Bisecting K-Means requires more pre-processing iterations.
  - Fine-tuning with enhanced responses (citing 3GPP sections) underperformed standard fine-tuning (Figure 8) but provides traceability—a tradeoff between accuracy and verifiability.

- **Failure signatures:**
  - Low accuracy on acronym-heavy queries → query enhancement dictionary may be incomplete.
  - Retrieval returns irrelevant chunks → routing module may be selecting wrong clusters; check centroid-query similarity distribution.
  - Slow query latency → FAISS search over too many chunks; reduce K or increase cluster granularity.

- **First 3 experiments:**
  1. **Baseline comparison:** Run phi-2 with RAG but no clustering (exhaustive FAISS search) to isolate clustering contribution.
  2. **Cluster count sweep:** Test 18 clusters with fixed K=8 to find optimal cluster granularity for your document set.
  3. **Ablation on query enhancement:** Compare accuracy with and without term/abbreviation expansion to quantify its contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Would integrating knowledge graphs into the RAG framework outperform Bisecting K-Means clustering for information retrieval and reasoning in telecommunications QA?
- **Basis in paper:** [explicit] Future Works states: "Future research could explore novel knowledge representation techniques, such as knowledge graphs, to improve information retrieval and reasoning capabilities."
- **Why unresolved:** Only Bisecting K-Means was implemented; knowledge graphs were suggested but not evaluated.
- **What evidence would resolve it:** A comparative study measuring accuracy and retrieval efficiency between knowledge graph-based and Bisecting K-Means-based RAG on TeleQnA.

### Open Question 2
- **Question:** What data preprocessing techniques for document chunks would most improve embedding quality and retrieval relevance?
- **Basis in paper:** [explicit] Future Works states: "greater emphasis on data preprocessing, particularly cleaning document chunks before converting them to embeddings, could significantly enhance the quality and relevance of the input data."
- **Why unresolved:** Basic chunking was used without systematic exploration of cleaning approaches.
- **What evidence would resolve it:** An ablation study comparing preprocessing pipelines (noise removal, term normalization) with downstream QA accuracy measurements.

### Open Question 3
- **Question:** Could dynamic cluster selection outperform the fixed top-8 cluster selection in the routing module?
- **Basis in paper:** [inferred] The paper uses fixed top-8 selection but Future Works notes "refining the routing module to output a more focused selection of clusters would likely lead to more efficient and accurate responses." Query-adaptive selection was not explored.
- **Why unresolved:** Fixed selection may be suboptimal—some queries need more context, others less.
- **What evidence would resolve it:** Experiments comparing fixed top-K against dynamic selection based on query complexity or confidence scores.

### Open Question 4
- **Question:** Do the performance gains from Bisecting K-Means RAG generalize to larger models like GPT-4?
- **Basis in paper:** [explicit] Future Works states: "using larger language models such as GPT-4 could yield substantial improvements, provided that careful evaluation is conducted to strike an optimal balance between model size, computational resources, and performance gains."
- **Why unresolved:** Only SLMs (phi-2, phi-3, gemma-2-2b) were tested; benefits at larger scales remain unknown.
- **What evidence would resolve it:** Experiments applying the framework across model scales with controlled TeleQnA evaluations.

## Limitations

- The routing module design lacks specification of linear combination weights (α, β) for centroid and query similarity scores, creating ambiguity in the retrieval relevance calculation.
- Training hyperparameters for both the fine-tuning process and routing module feed-forward layers are unspecified, making exact reproduction difficult.
- The evaluation only measures end-task accuracy without decomposing contributions from individual components (query enhancement, clustering, fine-tuning), preventing component-level impact assessment.
- The framework's performance against standard RAG baselines without clustering or routing is not reported, leaving the actual contribution of Bisecting K-Means unclear.

## Confidence

- **High Confidence:** The core framework architecture (chunking → clustering → routing → retrieval → fine-tuning) is clearly specified and internally consistent. The reported accuracy improvements over baseline SLM performance without fine-tuning are well-documented.
- **Medium Confidence:** The mechanism by which Bisecting K-Means improves retrieval relevance is plausible but lacks direct empirical validation against standard K-Means or no-clustering baselines. The query enhancement approach is theoretically sound but lacks isolated evaluation.
- **Low Confidence:** The routing module's specific implementation details (linear combination weights, training procedure) are underspecified, creating uncertainty about exact reproduction. The computational efficiency gains from clustering are asserted but not quantitatively measured against baseline retrieval approaches.

## Next Checks

1. **Component ablation study:** Run phi-2 with standard RAG (no clustering, no routing) to establish baseline accuracy, then incrementally add Bisecting K-Means clustering and routing module to quantify each component's contribution to the 66.12% accuracy.

2. **Cluster quality validation:** For a sample of 100 queries, manually verify whether the top-8 clusters selected by the routing module contain at least one chunk from the source document(s) referenced in the ground truth answer, establishing whether clustering preserves semantic relevance.

3. **Routing weight sensitivity analysis:** Systematically vary α and β in the routing module's linear combination (Ic = αI1 + βI2) across {0.0, 0.3, 0.5, 0.7, 1.0} to determine optimal weighting and test whether the routing module's performance is robust to these unspecified parameters.