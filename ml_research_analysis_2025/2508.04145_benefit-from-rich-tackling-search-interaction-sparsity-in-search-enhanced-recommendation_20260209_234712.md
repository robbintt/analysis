---
ver: rpa2
title: 'Benefit from Rich: Tackling Search Interaction Sparsity in Search Enhanced
  Recommendation'
arxiv_id: '2508.04145'
source_url: https://arxiv.org/abs/2508.04145
tags:
- search
- user
- recommendation
- users
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of sparse search interactions
  in search-enhanced recommendation systems, where most users have limited search
  behavior that limits model effectiveness. The authors propose GSERec, which leverages
  Large Language Models to summarize user search and recommendation preferences, then
  discretizes these preferences into codes using vector quantization.
---

# Benefit from Rich: Tackling Search Interaction Sparsity in Search Enhanced Recommendation

## Quick Facts
- arXiv ID: 2508.04145
- Source URL: https://arxiv.org/abs/2508.04145
- Reference count: 40
- Primary result: GSERec improves NDCG@5 by over 10% for users with sparse search interactions compared to state-of-the-art methods

## Executive Summary
This paper addresses the challenge of sparse search interactions in search-enhanced recommendation systems, where most users have limited search behavior that constrains model effectiveness. The authors propose GSERec, which leverages Large Language Models to summarize user search and recommendation preferences, then discretizes these preferences into shared codes using vector quantization. By constructing user-code graphs and performing message passing, the method propagates information from users with rich search interactions to enhance representations of users with sparse search behavior. Contrastive learning objectives ensure meaningful information transfer during message passing.

## Method Summary
GSERec tackles sparse search interactions through a three-stage pipeline: (1) offline LLM summarization of user preferences using DeepSeek-R1-Distill-Qwen-7B, followed by BGE-M3 encoding into dense vectors; (2) RQ-VAE quantization that discretizes these vectors into L=4 codebook levels with Nc=256 codes each, creating shared preference representations; (3) bipartite user-code graph construction with LightGCN-style message passing to propagate rich-user signals to sparse users. The method combines this with contrastive learning objectives that align search and recommendation representations across three separate loss terms.

## Key Results
- GSERec consistently outperforms existing baselines on three real-world datasets
- Performance gains are particularly pronounced for users with sparse search interactions (>10% improvement in NDCG@5)
- Ablation studies show the user-code graph and contrastive losses are critical components
- t-SNE visualizations demonstrate cleaner separation of search and recommendation embeddings with contrastive alignment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Discretizing user preferences into shared codes enables sparse users to inherit signals from rich users through graph connectivity
- **Mechanism:** LLMs summarize user search and recommendation histories into natural language preference descriptions → embedding model encodes these into dense vectors → RQ-VAE discretizes into L-level codes using hierarchical codebooks. Users sharing codes become neighbors in the user-code graph, regardless of their raw interaction overlap
- **Core assumption:** Users with semantically similar preferences (as captured by LLM summaries) will share at least one code, creating graph edges that enable meaningful information flow even when their behavioral histories have minimal direct overlap
- **Evidence anchors:** [abstract] "we utilize Large Language Models (LLMs) with vector quantization to generate discrete codes, which connect similar users and thereby construct the graph"; [Section 4.1.2] Describes RQ-VAE quantization process with L=4 codebooks, Nc=256 codes each; [corpus] Related work on review sparsity similarly addresses sparse signals through textual representation
- **Break condition:** If LLM summaries fail to capture meaningful preference distinctions, or if codebook granularity is too coarse/fine, users won't connect to truly similar neighbors, making message passing noisy or useless

### Mechanism 2
- **Claim:** LightGCN-style message passing on user-code graphs propagates rich-search users' embeddings to sparse-search users through shared code nodes
- **Mechanism:** Bipartite graphs G_s (user–search-code) and G_r (user–recommendation-code) are constructed. K-layer message passing aggregates from users→codes→users. Each user's enhanced embedding becomes a weighted combination of neighbors' embeddings. Rich users with more informative search representations thus contribute to sparse users who share their codes
- **Core assumption:** The graph structure correctly identifies similar users; otherwise, message passing propagates noise. Also assumes that 2-hop paths (user→code→user) capture meaningful similarity for recommendation
- **Evidence anchors:** [abstract] "Through message passing on this graph, embeddings of users with rich search data are propagated to enhance the embeddings of users with sparse interactions"; [Section 4.2.2] Equation 7 shows normalized aggregation; [Section 5.3.2] Ablation shows "w/o U-C Graph" causes significant performance drop
- **Break condition:** If sparse users have no shared codes with any rich users, or if aggregation weights are dominated by low-quality neighbors, the mechanism fails

### Mechanism 3
- **Claim:** Contrastive learning objectives align search and recommendation representations, ensuring message passing transfers semantically coherent information
- **Mechanism:** Three contrastive losses: (1) L_RQ-CL aligns search/recommendation latent embeddings before quantization; (2) L_U-CL aligns enhanced user embeddings after graph propagation; (3) L_His-CL aligns code sequences with historical behavior representations. InfoNCE loss pulls positive pairs (same user's S&R views) together while pushing apart in-batch negatives
- **Core assumption:** Aligning search and recommendation representations into a shared semantic space improves transfer; the same user's search and recommendation behaviors reflect compatible preferences worth aligning
- **Evidence anchors:** [abstract] "we introduce a contrastive loss to better model user similarities"; [Section 4.1.2] Equation 1 defines L_RQ-CL; [Section 4.2.2] Equation 9 defines L_U-CL; [Section 5.4.2] t-SNE visualization shows cleaner separation with alignment loss
- **Break condition:** If temperature τ is poorly tuned, or if negative samples are too easy/hard, contrastive losses may collapse or provide no gradient signal. Over-alignment could also erase useful modality-specific signals

## Foundational Learning

- **Concept: Vector Quantization (VQ-VAE / RQ-VAE)**
  - **Why needed here:** Converts continuous preference embeddings into discrete codes. Understanding how codebook learning works (commitment loss, codebook explosion/collapse) is essential for debugging the graph construction stage
  - **Quick check question:** Can you explain why the stop-gradient operation in Equation 5 is necessary for stable codebook learning?

- **Concept: Message Passing / Graph Convolution**
  - **Why needed here:** The core mechanism for propagating rich-user signals to sparse users. You need to understand how neighborhood aggregation works, why normalization matters, and how layer depth affects receptive field
  - **Quick check question:** If you increase K from 2 to 4 layers, what happens to the effective neighborhood size and potential for over-smoothing?

- **Concept: Contrastive Learning (InfoNCE)**
  - **Why needed here:** Three separate contrastive losses are used. Understanding positive/negative sampling strategies, temperature scaling, and how these losses interact with the main recommendation loss is critical
  - **Quick check question:** Why does using in-batch negatives (rather than explicit hard negatives) work here, and what happens if your batch is too small?

## Architecture Onboarding

- **Component map:** LLM Preference Summarizer -> Embedding Encoder -> RQ-VAE Quantizer -> User-Code Graphs -> LightGCN Propagation -> Transformer History Modeling -> Cross-Attention Fusion -> Prediction Head
- **Critical path:** 1) Run LLM summarization offline for all users; 2) Train RQ-VAE to convergence (500 epochs, separate from main model); 3) Construct user-code graphs from assigned codes; 4) Train main model with joint loss L_Total = L_rec + λ_U-CL·L_U-CL + λ_His-CL·L_His-CL + λ_Reg·||Θ||²
- **Design tradeoffs:** Codebook size (N_c=256) vs. granularity: larger codebooks give finer user clustering but sparser graphs; Number of codebook levels (L=4): more levels capture finer preference distinctions but increase complexity; Propagation depth (K=2): deeper propagation reaches more neighbors but risks over-smoothing; LLM choice: larger models give better summaries but higher offline cost
- **Failure signatures:** No performance gain for sparse users: check if sparse users have shared codes with rich users; Graph may be disconnected; Codebook collapse: monitor codebook utilization during RQ-VAE training; If only few codes are used, increase N_c or check learning rate; Contrastive loss collapse (loss → 0 too fast): temperature τ too high or negatives too easy; Tune τ; t-SNE shows entangled S&R embeddings: L_U-CL weight too low or not being applied
- **First 3 experiments:** 1) Validate graph connectivity: For sparse users (<10 search interactions), compute statistics on how many rich-user neighbors they have via shared codes. If median is 0, the mechanism cannot work; 2) Ablate propagation depth: Run K∈{1,2,3,4} and plot performance vs. K for sparse users. Look for over-smoothing at higher K; 3) Visualize code assignments: Sample 100 users, show their assigned codes and whether they connect to users with similar ground-truth preferences. This validates whether the LLM+quantization pipeline produces semantically meaningful clusters

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- Synthetic data generation: The paper uses synthetic search behaviors for Amazon datasets following protocols from prior works without explicit details, making exact reproduction challenging
- Offline LLM dependency: LLM-based preference summarization is performed offline with frozen models, creating potential distribution shifts between training and inference
- Cold-start limitation: The paper doesn't address cold-start users with no search or recommendation history at all

## Confidence
- **High confidence** in core mechanisms (vector quantization, graph message passing, and contrastive learning) as these are well-established techniques adapted from prior work
- **Medium confidence** in specific efficacy claims due to unknown synthetic data generation procedures and absence of ablation studies isolating each component's contribution
- **Low confidence** in generalization beyond the three evaluated datasets without cross-dataset validation

## Next Checks
1. **Graph connectivity audit**: For users with <10 search interactions, compute the distribution of rich-user neighbors via shared codes. If >30% have zero rich-user connections, the transfer mechanism is fundamentally broken for a significant user segment
2. **Component ablation hierarchy**: Train ablations removing (a) contrastive losses, (b) graph propagation, and (c) both. This would isolate whether discretization alone provides benefits versus the full GSERec architecture
3. **Cross-dataset generalization**: Apply the exact same hyperparameters to a fourth dataset (e.g., MovieLens with simulated search) to test whether the method's effectiveness transfers beyond the three evaluated domains