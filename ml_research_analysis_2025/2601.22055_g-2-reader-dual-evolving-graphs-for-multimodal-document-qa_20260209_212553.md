---
ver: rpa2
title: '$G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA'
arxiv_id: '2601.22055'
source_url: https://arxiv.org/abs/2601.22055
tags:
- evidence
- graph
- content
- g2-reader
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses two fundamental challenges in multimodal
  document question answering: (1) the representation challenge where flat chunking
  breaks document-native structure and cross-modal alignment, and (2) the retrieval
  challenge where iterative retrieval fails to maintain a persistent global search
  state, leading to looping or drifting. To solve these issues, the authors propose
  G2-Reader, a dual-graph system that evolves a Content Graph to preserve document-native
  structure and cross-modal semantics, and maintains a Planning Graph as an agentic
  directed acyclic graph of sub-questions to track intermediate findings and guide
  stepwise navigation for evidence completion.'
---

# $G^2$-Reader: Dual Evolving Graphs for Multimodal Document QA

## Quick Facts
- arXiv ID: 2601.22055
- Source URL: https://arxiv.org/abs/2601.22055
- Authors: Yaxin Du; Junru Song; Yifan Zhou; Cheng Wang; Jiahao Gu; Zimeng Chen; Menglan Chen; Wen Yao; Yang Yang; Ying Wen; Siheng Chen
- Reference count: 40
- Primary result: Achieves 66.21% average accuracy on VisDoMBench, outperforming strong baselines and standalone GPT-5 (53.08%)

## Executive Summary
G2-Reader addresses the dual challenges of representation and retrieval in multimodal document question answering by introducing a dual-graph architecture. It uses a Content Graph to preserve document-native structure and cross-modal semantics, and a Planning Graph to maintain a persistent global search state for iterative evidence assembly. The system evolves these graphs iteratively using VLMs, enabling stepwise navigation and evidence completion while avoiding the fragmentation and looping issues of flat chunking and iterative retrieval approaches.

## Method Summary
G2-Reader parses multimodal documents into atomic units (text, tables, figures) and builds a Content Graph where nodes represent these units and edges encode structural and semantic relations. The Content Graph is evolved offline using VLMs to refine node attributes and identify cross-modal links. For each query, an initial Planning Graph DAG is created to decompose the question into sub-questions. The system executes nodes topologically, retrieving evidence from the Content Graph, and iteratively refines the Planning Graph based on evidence sufficiency checks until a complete answer can be synthesized.

## Key Results
- Achieves 66.21% average accuracy on VisDoMBench across five multimodal domains
- Outperforms strong baselines including standalone GPT-5 (53.08%)
- Lite variant reduces costs by 73.7% with only 1% accuracy drop
- Fixed iteration limits (T=3 for Content Graph, τ_max=3 for Planning Graph) prevent over-smoothing and over-refinement

## Why This Works (Mechanism)

### Mechanism 1: Structure-Preserving Content Representation via Content Graph
The graph-based representation preserves document-native structure and cross-modal alignment, reducing semantic fragmentation compared to flat chunking. Documents are parsed into nodes and edges, with VLMs iteratively evolving node attributes and edge connections to restore context lost in chunking and create unified semantic space across modalities.

### Mechanism 2: Persistent Search State via Planning Graph
An agentic Directed Acyclic Graph (DAG) of sub-questions maintains persistent global search state, preventing iterative retrieval from looping or drifting. Complex queries are decomposed into DAG of atomic sub-questions, executed topologically with evidence retrieval and sufficiency checking, with refinement targeting identified gaps.

### Mechanism 3: Iterative Co-Evolution of Graphs for Evidence Assembly
The dual-graph system enables iterative, targeted evidence assembly by coupling structured memory (Content Graph) with dynamic reasoning plan (Planning Graph). Content Graph provides stable evidence space while Planning Graph navigates it, with evidence evaluation triggering Planning Graph refinement for more targeted retrievals until sufficient evidence is assembled.

## Foundational Learning

- **Concept: Directed Acyclic Graphs (DAGs) for Reasoning**
  - Why needed: The Planning Graph core is a DAG; understanding DAGs is essential for grasping question decomposition, dependency management, and non-cyclic execution order.
  - Quick check: Can you explain why a DAG (vs. a tree or general graph) is used for Planning Graph, and what property it guarantees for sub-question execution?

- **Concept: Graph Neural Networks (GNNs) / Message Passing**
  - Why needed: Content Graph evolution uses message-passing-like mechanism to update node attributes based on neighbors, helping explain how local representations gain global context.
  - Quick check: In a GNN, how does a node's representation change after one round of message passing from its neighbors? What information does it gain?

- **Concept: Retrieval-Augmented Generation (RAG) Baselines**
  - Why needed: Paper's contribution is improvement over standard RAG; knowing flat chunking limitations (chunk isolation, lack of global state) is crucial to appreciate problem solved.
  - Quick check: What are two main failure modes of iterative retrieval in long contexts that this paper aims to solve?

## Architecture Onboarding

- **Component map:**
  1. Multimodal Parser: Extracts text, tables, and figures from documents
  2. Content Graph Constructor: Builds initial graph from parsed units
  3. Content Graph Evolver: VLM-driven module that iteratively refines node summaries, keywords, and edges (offline)
  4. Decomposer: VLM that creates initial Planning Graph DAG from user query
  5. Worker: VLM that executes single Planning Graph node, retrieving evidence and generating intermediate answer
  6. Evidence Checker: VLM that evaluates if aggregate evidence is sufficient
  7. Reasoner: VLM that synthesizes final answer from query and verified evidence
  8. G^2-Reader Orchestrator: Manages iterative loop of Planning Graph execution and refinement

- **Critical path:**
  1. Offline: Document → Parser → Content Graph Initial → Content Graph Evolved (T=3 iterations)
  2. Online: User Query → Initial Retrieval → Decomposer → Planning Graph (V0)
  3. Loop (up to τ_max times): Orchestrator gets topological order; Worker retrieves from Content Graph & answers; Evidence Checker evaluates; If insufficient, Decomposer refines Planning Graph; If sufficient, break
  4. Final: Reasoner takes query and all verified evidence → Final Answer

- **Design tradeoffs:**
  - Full VLM Evolution vs. Lite (Rule-based) Variant: Lite is 73.7% cheaper with only 1% accuracy drop; tradeoff is cost/latency vs. peak performance
  - Fixed Content Graph vs. Dynamic: Static during inference for stability/efficiency but cannot adapt to query context
  - Retrieval Budget (k): Fixed budget (k=5); increasing k improves recall but may introduce more noise and cost

- **Failure signatures:**
  - Over-smoothing: Content Graph evolution with T>3 degrades performance
  - Over-refinement: Planning Graph refinement beyond τ_max=3 reduces accuracy due to noisy/ redundant sub-questions
  - Evidence Gaps: Evidence Checker may incorrectly flag evidence as sufficient or miss critical gaps

- **First 3 experiments:**
  1. Verify Content Graph quality: Visualize small representative Content Graph; check if nodes are meaningfully segmented and edges connect logically related concepts across modalities
  2. Trace Planning Graph evolution: Run system on known multi-hop question; manually inspect Planning Graph at each iteration and corresponding retrieved evidence; check if refinement logically targets identified gaps
  3. Ablate the Lite variant: Implement rule-based evolution; compare Content Graph structure and downstream QA accuracy against full VLM-based evolution on small validation set; verify 1% accuracy gap consistency

## Open Questions the Paper Calls Out
- How can relation induction within Content Graph be made more reliable to ensure graph topology accurately reflects deep semantic dependencies rather than surface-level proximity?
- Can improved criteria or models for evidence sufficiency checks be developed to enhance Planning Graph's ability to verify information coverage?
- How can inference-time navigation be optimized for broader real-world deployments to reduce latency and cost of multi-agent graph evolution?
- Can adaptive termination criteria be developed to automatically determine optimal number of iterations for Content Graph evolution and Planning Graph refinement?

## Limitations
- VLM evolution stability and reproducibility across different VLM instances is not quantified, with potential hallucination in edge/attribute inference not systematically evaluated
- Graph topology sensitivity to parsing quality and window size for edge initialization could lead to fundamentally flawed topologies
- Generalization beyond VisDoMBench technical/scientific domains remains untested on more general multimodal documents

## Confidence
- Dual-Graph Architecture Effectiveness: High - Ablation study provides strong empirical evidence both graphs are necessary for peak performance
- Content Graph Structure Preservation: Medium - Well-motivated and conceptually sound, but direct evidence showing better preservation than baselines is limited to indirect performance gains
- Planning Graph State Persistence: Medium - DAG structure is logically sound for preventing loops, but VLM's ability to reliably identify and target evidence gaps is not independently validated

## Next Checks
1. Evaluate G2-Reader on diverse multimodal documents outside VisDoMBench (news articles with infographics, financial reports with charts) to test robustness across document types
2. Replace VLM-driven evolution with fixed rule-based method and measure degradation in accuracy and nature of errors introduced
3. Visualize and analyze Content Graph structure for sample documents; quantify metrics like node centrality, edge density, and cross-modal edge proportion to validate parser and evolution process