---
ver: rpa2
title: 'COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road
  Semantic Segmentation'
arxiv_id: '2503.03947'
source_url: https://arxiv.org/abs/2503.03947
tags:
- data
- coarse
- labels
- semantic
- rugd
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semantic segmentation in
  off-road environments, where limited labeled data and domain adaptation issues hinder
  robust performance. The proposed method, COARSE, leverages coarse in-domain labels
  and dense out-of-domain data through a semi-supervised domain adaptation framework.
---

# COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation

## Quick Facts
- arXiv ID: 2503.03947
- Source URL: https://arxiv.org/abs/2503.03947
- Reference count: 40
- Primary result: 9.7% mIoU improvement on RUGD, 8.4% on Rellis-3D using collaborative pseudo-labeling with coarse labels and dense out-of-domain data

## Executive Summary
COARSE addresses semantic segmentation in off-road environments by leveraging coarse in-domain labels and dense out-of-distribution data through a semi-supervised domain adaptation framework. The method uses pretrained vision transformers (DINOv2) with complementary pixel-level and patch-level decoders, enhanced by a collaborative pseudo-labeling strategy. Evaluations on RUGD and Rellis-3D datasets demonstrate significant improvements of 9.7% and 8.4% in mIoU, respectively, compared to using only coarse data. The approach shows effectiveness in unstructured environments and real-world off-road vehicle data.

## Method Summary
COARSE employs a two-stage training pipeline using DINOv2 encoders with two architecturally distinct decoders: PixelDecoder (CNN-based) and PatchDecoder (transformer-based). First, PatchDecoder is trained on coarse in-distribution data while PixelDecoder is trained on both coarse in-distribution and dense out-of-distribution data. Pseudo-labels are generated by retaining only pixels where both decoders agree, filtering uncertain predictions. The final model is trained on these pseudo-labeled data. The method explicitly addresses domain shift between OOD training data and ID deployment environments through this collaborative approach.

## Key Results
- 9.7% mIoU improvement on RUGD dataset compared to using only coarse data
- 8.4% mIoU improvement on Rellis-3D dataset with same comparison
- DINOv2-based models show improvement with OOD data while others yield mixed outcomes
- Pseudo-label density varies from 7% (Rellis) to 13% (RUGD) due to boundary coarsification

## Why This Works (Mechanism)

### Mechanism 1: Collaborative Pseudo-Labeling via Architectural Disagreement
Using two architecturally distinct decoders trained on different data distributions enables higher-quality pseudo-label generation through disagreement-based filtering. The PatchDecoder provides robustness to noisy labels and captures broad environmental classes, while the PixelDecoder captures fine-grained boundaries. Pseudo-labels are generated by retaining only pixels where both decoders agree, filtering uncertain predictions. This works because architectural diversity produces meaningfully different error patterns.

### Mechanism 2: Domain-Independent Feature Extraction via DINOv2
Pretrained vision transformers (DINOv2) produce semantic features that transfer more effectively across domain shifts than supervised alternatives. Self-supervised pretraining on diverse images produces robust representations without task-specific bias, enabling decoders to leverage these features while adapting to off-road domains with minimal labeled data.

### Mechanism 3: Complementary Data-Model Pairing
Assigning different data distributions to each decoder based on their architectural strengths maximizes pseudo-label quality. PixelDecoder receives dense OOD data to learn boundary precision that coarse ID data cannot provide; PatchDecoder uses only coarse ID data since it relies on encoder's internal representation and is resilient to noise.

## Foundational Learning

- **Semi-supervised learning via pseudo-labeling**: The core method generates pseudo-labels from unlabeled data to augment scarce coarse labels. Understanding confidence thresholds and filtering strategies is essential. Quick check: Why does discarding disagreed pixels improve pseudo-label quality rather than reducing coverage?

- **Vision Transformer architectures for dense prediction**: Understanding DINOv2 encoder outputs, patch embedding resolution, and the difference between patch-level (1/14) vs pixel-level decoding is essential. Quick check: What information does the ImgSkip block provide that the DINOv2 encoder cannot?

- **Domain adaptation in semantic segmentation**: The method explicitly addresses domain shift between OOD training data and ID deployment environments. Quick check: Why might naively mixing dense OOD data with coarse ID data degrade performance for some architectures?

## Architecture Onboarding

- **Component map**: DINOv2 encoder (S/B/L) -> PixelDecoder (Multi-Layer Neck + ImgSkip + LateFusion) and PatchDecoder (MaskTransformer variant) -> Pseudo-label generator (disagreement filtering) -> Final segmentation model

- **Critical path**: 1) Train PatchDecoder on coarse ID data only (500 epochs). 2) Train PixelDecoder on coarse ID + dense OOD data (200 epochs). 3) Generate pseudo-labels via disagreement filtering on unlabeled ID data. 4) Train final segmentation model on pseudo-labeled data.

- **Design tradeoffs**: Larger encoders improve pseudo-label quality (L achieves 73.8% vs S at 71.5% on RUGD) but reduce inference speed. Pixel-Patch optimal for diverse datasets; Pixel-Pixel better for lower-diversity datasets. Aggressive boundary removal yields 7-13% density but risks losing critical edge information.

- **Failure signatures**: Overconfident wrong predictions in semantically ambiguous regions; negative transfer when OOD data distribution differs significantly; low pseudo-label density indicates high semantic confusion.

- **First 3 experiments**: 1) Baseline comparison: train on coarse ID only, coarse ID + dense OOD, and pseudo-labels from COARSE. 2) Ablate decoder pairing: compare Pixel-Pixel, Patch-Patch, Pixel-Patch, Patch-Pixel configurations. 3) Scale encoder size: evaluate S/B/L variants on pseudo-label quality and inference speed.

## Open Questions the Paper Calls Out

### Open Question 1
Can the generalization capabilities of DINOv2 be effectively leveraged to develop online pseudo-labeling strategies for off-road segmentation? The current COARSE framework utilizes an offline pseudo-labeling approach rather than updating dynamically during deployment. Implementation of an online adaptation mechanism would show maintained or improved mIoU without catastrophic forgetting.

### Open Question 2
Is the custom "PixelDecoder" architecture optimal for this task compared to other established decoder backbones? The paper demonstrates the decoder works within the COARSE pipeline but does not isolate the decoder's performance against alternatives. An ablation study comparing the custom PixelDecoder against standard convolutional or transformer-based decoders would justify its specific Inception-like design.

### Open Question 3
Does the "density" of pseudo-labels provide a reliable heuristic for active learning and automated annotation guidance? The paper identifies correlation between pseudo-label sparsity and semantic confusion but does not validate the utility of this metric in a closed-loop annotation system. An active learning experiment where human annotators label only images with the lowest pseudo-label density would demonstrate higher performance gains per annotation.

### Open Question 4
How does the performance of COARSE differ when using task-aware human coarse labeling versus the random coarsification strategy used in the experiments? The experiments rely on random polygon generation and boundary removal to simulate coarse data, potentially underestimating the value of strategic, human-selected sparse labels. A comparative study evaluating model performance with human-annotated sparse labels would provide insights.

## Limitations
- The method's effectiveness depends critically on the assumption that architectural disagreement produces reliable confidence filtering, which is not formally analyzed
- The complementary data-model pairing strategy lacks theoretical justification and could fail when OOD data distribution significantly diverges
- The assertion that DINOv2 features are inherently more domain-transferable than supervised alternatives is stated without comparative ablations

## Confidence

**High confidence**: The core performance improvements (9.7% mIoU on RUGD, 8.4% on Rellis-3D) are empirically demonstrated with appropriate baselines.

**Medium confidence**: The mechanism claiming architectural disagreement produces superior pseudo-labels is plausible but not rigorously validated. The paper shows results but doesn't analyze failure modes or provide statistical significance testing.

**Low confidence**: The assertion that DINOv2 features are inherently more domain-transferable than supervised alternatives is stated without comparative ablations using other self-supervised or supervised pretrained models on the same datasets.

## Next Checks

1. **Disagreement analysis**: Analyze the spatial distribution and class-specific patterns of Pixel-Patch disagreements. Are certain classes or semantic regions more prone to disagreement, and does this correlate with actual segmentation errors?

2. **Cross-dataset transferability**: Train on RUGD pseudo-labels and evaluate on Rellis-3D (and vice versa) to assess the generalization capability of the collaborative pseudo-labeling approach across different off-road environments.

3. **Architectural correlation analysis**: Measure the correlation of error patterns between PixelDecoder and PatchDecoder across different classes and image regions. High correlation would invalidate the core assumption of complementary error modes.