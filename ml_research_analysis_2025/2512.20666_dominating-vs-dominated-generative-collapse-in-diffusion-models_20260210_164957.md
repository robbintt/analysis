---
ver: rpa2
title: 'Dominating vs. Dominated: Generative Collapse in Diffusion Models'
arxiv_id: '2512.20666'
source_url: https://arxiv.org/abs/2512.20666
tags:
- prompts
- attention
- across
- generation
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the Dominant-vs-Dominated (DvD) phenomenon
  in text-to-image diffusion models, where one concept in multi-concept prompts overwhelms
  generation while others are suppressed. The authors hypothesize that visual diversity
  disparity in training data causes this imbalance, with low-diversity concepts (landmarks,
  artists, characters) developing rigid visual priors that dominate over high-diversity
  concepts (everyday objects).
---

# Dominating vs. Dominated: Generative Collapse in Diffusion Models

## Quick Facts
- arXiv ID: 2512.20666
- Source URL: https://arxiv.org/abs/2512.20666
- Authors: Hayeon Jeong; Jong-Seok Lee
- Reference count: 40
- One-line primary result: Dominance increases monotonically as training diversity decreases, revealing visual diversity disparity as a cause of multi-concept generation failures.

## Executive Summary
This paper investigates the Dominant-vs-Dominated (DvD) phenomenon in text-to-image diffusion models, where one concept in multi-concept prompts overwhelms generation while others are suppressed. The authors hypothesize that visual diversity disparity in training data causes this imbalance, with low-diversity concepts (landmarks, artists, characters) developing rigid visual priors that dominate over high-diversity concepts (everyday objects). Through controlled experiments using DreamBooth to manipulate visual diversity, they demonstrate that dominance increases monotonically as training diversity decreases. To systematically analyze DvD, they introduce DominanceBench, a benchmark of 300 prompts exhibiting strong dominance behavior.

## Method Summary
The authors fine-tune Stable Diffusion 1.4 using DreamBooth on 120 ImageNet dog images partitioned into 6 subsets (D1–D10) based on breed count. They train separate models for each diversity level and evaluate multi-concept generation by pairing the fine-tuned "dvddog" concept with other objects. DvD Scores are computed using VQA binary questions answered by Qwen2.5-VL. Cross-attention analysis tracks focus scores and attention changes across layers and timesteps. Head ablation studies compare DvD to memorization behavior.

## Key Results
- Dominance increases monotonically as training diversity decreases (D1 > D10)
- 83% of DominanceBench prompts show dominating token receiving maximum attention in layers 8-10 at t=50
- DvD arises from distributed attention mechanisms across multiple heads (48% mitigation via single-head ablation vs. 78% for memorization)
- Focus Score >0.010 in layers 9-10 at t=50 predicts DvD with ~70% detection rate

## Why This Works (Mechanism)

### Mechanism 1: Visual Diversity Disparity → Rigid Priors → Dominance
When a concept is learned from limited visual variations, its representation becomes overfitted to specific patterns, causing it to dominate other concepts in multi-concept compositions. Training on low-diversity data (e.g., landmarks with near-identical appearances) creates strongly reinforced, rigid visual priors. High-diversity concepts develop flexible representations. During multi-concept generation, rigid priors capture disproportionate attention capacity. The strength of a concept's visual prior scales inversely with training data diversity.

### Mechanism 2: Early Attention Saturation in Lower-Resolution Layers
DvD manifests through excessive attention concentration on dominating tokens in lower-resolution layers (8-10) during the first denoising step, with dominated concepts experiencing sharp attention decline. Cross-attention in early timesteps establishes semantic structure. Dominating tokens achieve high focus scores in semantic-processing layers. Once established, this imbalance persists throughout generation—dominated concepts lose influence in the critical window where image structure is determined. Early denoising steps (t=50-40) are structurally determinative; attention patterns set here persist.

### Mechanism 3: Distributed Multi-Head Cooperation (vs. Localized Memorization)
DvD emerges from distributed cooperation across multiple attention heads, unlike memorization which localizes to specific heads amenable to pruning. In memorization, ablating single heads achieves 78% mitigation. In DvD, single-head ablation achieves only 48% mitigation, and multi-head ablation reduces effectiveness further (mitigation drops from ~0.8 to ~0.6), indicating heads compensate for each other. Head-level distribution correlates with neuron-level distribution for the phenomenon.

## Foundational Learning

- **Cross-Attention in Diffusion Models**
  - Why needed here: DvD is fundamentally an attention allocation problem; understanding how text tokens condition image generation via cross-attention is prerequisite to analyzing dominance.
  - Quick check question: Can you explain how cross-attention maps text tokens to spatial regions in the denoising UNet?

- **Timestep Structure in Diffusion**
  - Why needed here: DvD manifests in early timesteps (t=50-40) when semantic structure is established; knowing which timesteps control what is essential.
  - Quick check question: What happens semantically vs. texturally in early vs. late denoising steps?

- **Visual Prior Formation in Large-Scale Training**
  - Why needed here: The root cause is training data diversity shaping concept representations; understanding how repeated exposure to low-diversity images creates rigid priors contextualizes the problem.
  - Quick check question: Why would a model develop a "stronger" prior for the Eiffel Tower than for "coffee mug"?

## Architecture Onboarding

- **Component map:**
  - UNet cross-attention layers 1-16 (SD 1.4 architecture): layers 8-10 are lower-resolution semantic layers critical for DvD; layers 1-6 are downsampling blocks where ablation effects concentrate
  - 16 attention heads per layer: distributed mechanism means no single "culprit" head
  - Focus Score computation: `(max_attention - mean_others) / (entropy / log2N)` — measures concentration vs. dispersion
  - DvD Score: `C1 × (N-C2) / N² × 100` — quantifies dominance via VQA binary questions (threshold ≥36)

- **Critical path:**
  1. Prompt enters text encoder → token embeddings
  2. First denoising step (t=50): cross-attention in layers 8-10 shows elevated focus scores on dominating token
  3. Timesteps 50→40: dominated token shows negative attention change; imbalance locked in
  4. Subsequent timesteps: structure persists; dominated concept absent in output

- **Design tradeoffs:**
  - Entropy-normalized Focus Score (Eq. 2) enables cross-prompt comparison but introduces noise from irrelevant tokens in temporal analysis → use raw attention deviation (∆α) for tracking dynamics within single prompts
  - Head ablation at pre-softmax logits (ε=10⁻⁵) vs. post-softmax: pre-softmax maintains attention mechanism integrity

- **Failure signatures:**
  - DvD Score ≥36 with strong asymmetry (C1≥3, C2<3)
  - Focus Score >0.010 in layers 9-10 at t=50 predicts DvD with ~70% detection rate (37pp discrimination gap over balanced prompts)
  - Attention change curves: dominated token shows negative ∆α immediately; dominating token shows positive ∆α in early intervals

- **First 3 experiments:**
  1. **Reproduce DreamBooth diversity experiment:** Train "dvddog" with D1, D4, D10 variants; generate 10 images per variant for "a dvddog beside a red chair"; plot DvD Scores — should show monotonic increase as diversity decreases
  2. **Attention visualization at t=50:** For a DominanceBench prompt, extract cross-attention maps for all tokens in layers 7-10; verify dominating token has highest focus score and dominated token shows peak at layer 7 then decline
  3. **Single-head ablation sweep:** Ablate each head individually in layers 1-6 for 10 DvD prompts and 10 memorization prompts; compare mitigation rates — expect ~48% for DvD, ~78% for memorization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DvD be mitigated through architectural modifications or training-level interventions without requiring prompt modifications?
- Basis in paper: [explicit] The supplementary material states that "future research should explore architectural modifications or training-level methods that alleviate DvD without modifying prompts," and the Limitations section notes that current findings "advancing toward more reliable and controllable text-to-image generation."
- Why unresolved: The paper establishes that DvD arises from distributed attention mechanisms across multiple heads, making simple solutions like head pruning (effective for memorization) unsuitable for DvD.
- What evidence would resolve it: A training objective or inference-time attention modulation technique that successfully lowers DvD scores on DominanceBench while maintaining image fidelity for the dominant concept.

### Open Question 2
- Question: Do feedforward networks (FFNs) and residual connections act as additional pathways for visual diversity disparity to influence generation?
- Basis in paper: [explicit] The Limitations section explicitly states, "Investigating feedforward networks and residual connections may reveal additional pathways through which visual diversity disparity affects generation."
- Why unresolved: The study focused exclusively on cross-attention mechanisms as the lens for understanding DvD, leaving other architectural components unexplored.
- What evidence would resolve it: Ablation studies or neuron-level analysis of FFN layers showing specific neurons activating for dominant concepts, contributing to the suppression of dominated concepts.

### Open Question 3
- Question: What are the specific inter-head relationships or cooperation patterns that drive the distributed dominance behavior?
- Basis in paper: [explicit] The Limitations section mentions that "exploring inter-head relationships could provide deeper insights and enable more effective mitigation strategies."
- Why unresolved: While the analysis distinguishes DvD as "distributed" versus memorization as "localized," it does not map the specific cooperative structures between heads that sustain dominance.
- What evidence would resolve it: Causal mediation analysis or visualization of attention head interactions identifying functional clusters responsible for the suppression of dominated tokens.

### Open Question 4
- Question: Can balancing visual diversity in the pre-training dataset prevent the formation of rigid visual priors that cause dominance?
- Basis in paper: [inferred] The paper validates visual diversity disparity as the root cause using DreamBooth fine-tuning, but it does not test if curating the original training data (e.g., augmenting low-diversity concepts in LAION) would prevent DvD from emerging in the first place.
- Why unresolved: The methodology simulates the cause via controlled fine-tuning rather than exploring prevention during the initial large-scale training phase.
- What evidence would resolve it: Training a diffusion model on a dataset with artificially diversified examples for typically low-diversity categories (landmarks, characters) and observing a significant reduction in DvD Scores.

## Limitations
- The DreamBooth experiments depend on specific dog breed partitions that are not fully specified, making exact replication difficult
- The VQA-based DvD Score introduces potential measurement noise from evaluator inconsistency
- The corpus analysis reveals no direct validation of the proposed attention dynamics, leaving the early-timestep saturation hypothesis largely ungrounded in external literature

## Confidence
- **High confidence:** The empirical observation that training data diversity affects concept dominance in multi-concept prompts. The monotonic relationship between diversity and dominance is directly measurable and reproducible.
- **Medium confidence:** The causal mechanism linking visual diversity disparity to rigid prior formation. While the DreamBooth results support this, the underlying assumption about prior strength scaling with diversity is not directly validated.
- **Medium confidence:** The attention-based mechanism explaining DvD through early saturation and persistence. The Focus Score patterns are consistent, but the claim that early timesteps are determinative lacks external validation.
- **Medium confidence:** The distributed multi-head cooperation explanation distinguishing DvD from memorization. Head ablation results are statistically significant but do not prove the absence of localized mechanisms.

## Next Checks
1. **External validation of attention dynamics:** Apply the focus score and attention change analysis to prompts from other multi-concept generation benchmarks (e.g., COCO, LAION-Aesthetics) to verify that the observed early saturation pattern generalizes beyond DominanceBench.
2. **Ablation of temporal determinacy:** Conduct experiments where attention is manually rebalanced during timesteps 50-40 (e.g., via attention guidance or classifier-free guidance) to test whether dominance can be prevented if early saturation is disrupted.
3. **Cross-model replication:** Apply the same DreamBooth diversity manipulation and DvD Score evaluation to a different text-to-image model (e.g., SDXL or Kandinsky) to verify that the phenomenon and its underlying causes are architecture-agnostic.