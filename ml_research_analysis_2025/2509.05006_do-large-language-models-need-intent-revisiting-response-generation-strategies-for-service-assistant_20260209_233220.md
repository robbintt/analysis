---
ver: rpa2
title: Do Large Language Models Need Intent? Revisiting Response Generation Strategies
  for Service Assistant
arxiv_id: '2509.05006'
source_url: https://arxiv.org/abs/2509.05006
tags:
- intent
- language
- response
- service
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether explicit intent recognition is
  necessary for high-quality service response generation in large language models
  (LLMs). The authors conduct a rigorous empirical study comparing intent-first and
  direct response generation paradigms across two customer service datasets (BiToD
  and Bitext).
---

# Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant

## Quick Facts
- arXiv ID: 2509.05006
- Source URL: https://arxiv.org/abs/2509.05006
- Reference count: 0
- Primary result: Intent recognition improves service response quality, with fine-tuned two-step pipelines outperforming single-step approaches on automatic metrics

## Executive Summary
This paper investigates whether explicit intent recognition is necessary for high-quality service response generation in large language models (LLMs). The authors conduct a rigorous empirical study comparing intent-first and direct response generation paradigms across two customer service datasets (BiToD and Bitext). Their methodology evaluates multiple configurations: fine-tuned T5 and GPT-4 models in both single-step (direct generation) and two-step (intent recognition + response generation) setups. Results show that while LLMs can handle simple queries directly, incorporating explicit intent recognition—particularly with fine-tuned models—significantly improves response quality, task success rates, and overall performance.

## Method Summary
The authors evaluate four experimental setups: (1) T5 fine-tuned in a two-step pipeline with intent recognition followed by response generation, (2) T5 fine-tuned in a single-step direct generation setup, (3) GPT-4 in a two-step pipeline, and (4) GPT-4 in a single-step direct generation setup. They use the BiToD and Bitext datasets to compare these configurations across automatic metrics including BERTScore, ROUGE-L, and BLEU scores. The study systematically examines whether explicit intent modeling provides benefits over direct response generation, particularly for complex or underspecified service requests.

## Key Results
- Two-step fine-tuned pipelines achieved the highest BERTScore, ROUGE-L, and BLEU scores across both datasets
- Intent recognition significantly improves task success rates for complex service requests
- Direct generation works adequately for simple queries but struggles with underspecified or multi-intent requests
- Fine-tuned models consistently outperform zero-shot GPT-4 across all metrics when explicit intent modeling is used

## Why This Works (Mechanism)
Intent recognition helps LLMs better understand the user's underlying goal, especially for complex or ambiguous service requests. By explicitly modeling the intent before generating responses, the system can structure its reasoning and ensure more accurate, task-oriented outputs. This is particularly valuable when queries are underspecified or contain multiple intents that need to be resolved before generating appropriate responses.

## Foundational Learning

**Intent Recognition**: Identifying the user's underlying goal or purpose from their query. Needed because raw text often doesn't explicitly state what the user wants. Quick check: Can the system correctly categorize "I want to book a flight to Paris" as a booking intent?

**Response Generation**: Creating appropriate, task-oriented responses based on understood intent. Needed to fulfill the user's request effectively. Quick check: Does the generated response address the specific intent identified?

**Fine-tuning vs Zero-shot**: Training models on domain-specific data versus using pre-trained capabilities directly. Needed because service domains have specific terminology and patterns. Quick check: Compare performance on domain-specific queries between fine-tuned and zero-shot approaches.

**Automatic Metrics**: Using metrics like BERTScore, ROUGE-L, and BLEU to evaluate generation quality. Needed for systematic comparison across different approaches. Quick check: Do higher metric scores correlate with better user-perceived response quality?

## Architecture Onboarding

**Component Map**: User Query -> Intent Recognition -> Response Generation -> Final Response

**Critical Path**: The intent recognition step is critical for complex queries, while direct generation may suffice for simple requests. The choice between paths depends on query complexity and model capabilities.

**Design Tradeoffs**: Two-step approaches add latency and computational cost but improve accuracy; single-step approaches are faster but may produce lower-quality responses for complex requests.

**Failure Signatures**: Direct generation fails on multi-intent or underspecified queries; intent recognition may misclassify ambiguous requests, leading to inappropriate responses.

**First Experiments**:
1. Test simple booking queries (e.g., "Book a table for two at 7pm") to verify basic functionality
2. Evaluate complex multi-step requests (e.g., "I need to change my flight and request a refund") to test intent handling
3. Compare inference times between single-step and two-step approaches on identical queries

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies solely on automatic metrics without human judgment or user satisfaction measures
- Results are based on specific customer service domains (BiToD and Bitext), limiting generalizability
- Computational efficiency trade-offs between single-step and two-step approaches are not explored

## Confidence

**High confidence**: The finding that two-step fine-tuned pipelines outperform single-step approaches on automatic metrics is well-supported by empirical results across both datasets.

**Medium confidence**: The claim that intent recognition is "necessary" for high-quality service response generation overstates the evidence, as results show mixed performance depending on model type and task complexity.

**Medium confidence**: The conclusion about LLM capabilities with simple queries is supported, but the boundary between "simple" and "complex" queries is not clearly defined or systematically explored.

## Next Checks

1. Conduct human evaluation studies to assess response quality, task completion rates, and user satisfaction, as automatic metrics may not capture service assistant effectiveness accurately.

2. Test the same experimental setup across additional service domains (technical support, healthcare assistance, financial services) to evaluate generalizability beyond the current datasets.

3. Measure inference latency and computational costs for both single-step and two-step approaches to understand practical deployment trade-offs in real-world service applications.