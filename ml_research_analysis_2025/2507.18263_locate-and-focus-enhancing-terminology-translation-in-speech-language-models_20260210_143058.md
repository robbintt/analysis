---
ver: rpa2
title: 'Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models'
arxiv_id: '2507.18263'
source_url: https://arxiv.org/abs/2507.18263
tags:
- translation
- speech
- terminology
- knowledge
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of accurate terminology translation
  in direct speech translation (ST), where existing methods struggle with noise interference
  and inefficient use of translation knowledge. The proposed Locate-and-Focus method
  first precisely locates speech clips containing terminologies within utterances
  using a sliding window-based retrieval approach, minimizing irrelevant information.
---

# Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models

## Quick Facts
- **arXiv ID**: 2507.18263
- **Source URL**: https://arxiv.org/abs/2507.18263
- **Reference count**: 37
- **Primary result**: Locate-and-Focus improves Term Success Rate by up to 26.4 percentage points in terminology translation

## Executive Summary
This paper introduces Locate-and-Focus, a method to enhance terminology translation accuracy in direct speech translation (ST) models. The approach addresses the challenge of noise interference and inefficient use of translation knowledge by first precisely locating speech clips containing terminologies using a sliding window-based retrieval approach, then associating this targeted knowledge with both utterance and hypothesis in audio and textual modalities. The method significantly improves Term Success Rate while maintaining general translation quality, outperforming existing approaches like SALM and Retrieval-and-Demonstration on a newly collected terminology translation dataset.

## Method Summary
Locate-and-Focus operates in two main stages: precise terminology localization and focused knowledge integration. The method uses a sliding window-based retrieval approach to identify speech clips containing terminologies within utterances, minimizing irrelevant information. It then associates the retrieved translation knowledge with both the source utterance and translation hypothesis across audio and textual modalities, guiding the speech language model to focus on relevant terminology translations. This targeted approach allows the model to leverage translation knowledge more efficiently than previous methods that either retrieve full utterances or use less precise knowledge integration strategies.

## Key Results
- **Term Success Rate (TSR) improvement**: Up to 26.4 percentage points increase over baseline methods
- **General translation quality**: Maintained robust performance while improving terminology accuracy
- **Performance comparison**: Outperformed existing methods including SALM and Retrieval-and-Demonstration on the terminology translation dataset

## Why This Works (Mechanism)
The Locate-and-Focus method succeeds by addressing two critical challenges in terminology translation: noise interference and inefficient knowledge utilization. By precisely locating terminology-containing speech clips, the method eliminates irrelevant information that could distract the model during translation. The targeted association of translation knowledge with both utterance and hypothesis ensures that the speech language model receives focused guidance relevant to the specific terminology being translated, rather than general context that may not be helpful for accurate terminology translation.

## Foundational Learning

1. **Direct Speech Translation (ST)**: Speech-to-text translation without intermediate text transcription. Why needed: Understanding the baseline architecture for terminology translation. Quick check: Verify knowledge of cascaded vs. direct ST approaches.

2. **Sliding Window Retrieval**: A technique for extracting specific segments from continuous speech based on temporal windows. Why needed: Core mechanism for terminology localization. Quick check: Understand window size selection and overlap considerations.

3. **Term Success Rate (TSR)**: Evaluation metric measuring accurate terminology translation. Why needed: Primary performance indicator for this task. Quick check: Compare TSR with general translation quality metrics.

## Architecture Onboarding

**Component Map**: Audio Input -> Sliding Window Retrieval -> Terminology Localization -> Knowledge Association -> Speech Language Model -> Translation Output

**Critical Path**: The retrieval and localization steps form the critical path, as precise terminology identification directly impacts the quality of knowledge association and subsequent translation accuracy.

**Design Tradeoffs**: 
- Precision vs. recall in terminology localization (tighter windows may miss boundary cases)
- Computational overhead of sliding window processing vs. accuracy gains
- Knowledge association complexity vs. model performance improvement

**Failure Signatures**:
- Terminology missed due to inadequate window size
- False positives from similar-sounding words
- Overfitting to specific terminology patterns in training data

**First Experiments**:
1. Test sliding window retrieval accuracy on clean vs. noisy speech samples
2. Compare TSR improvements across different terminology types (proper nouns, technical terms, etc.)
3. Evaluate computational overhead introduction through ablation studies

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends on sliding window retrieval quality, which may struggle with overlapping or ambiguous terminology boundaries
- Computational overhead from additional retrieval and focus steps is not thoroughly addressed
- Performance on languages with different morphological complexity or tonality is not explored
- Generalization beyond the specific terminology translation dataset remains uncertain

## Confidence

**High confidence**:
- Core methodology of sliding window retrieval for terminology localization
- TSR improvements demonstrated through experimental results

**Medium confidence**:
- Claim of maintaining robust general translation quality while improving TSR
- Performance on the specific terminology translation dataset

**Low confidence**:
- Scalability and efficiency for real-time applications
- Performance on languages with different phonetic or morphological characteristics

## Next Checks

1. Evaluate sliding window retrieval accuracy on speech with varying noise levels and overlapping terminology to assess real-world robustness

2. Conduct ablation studies to quantify computational overhead introduced by Locate-and-Focus steps compared to baseline direct speech translation models

3. Test approach on multilingual datasets covering languages with different phonetic structures (tonal languages, agglutinative languages) to assess cross-linguistic generalization