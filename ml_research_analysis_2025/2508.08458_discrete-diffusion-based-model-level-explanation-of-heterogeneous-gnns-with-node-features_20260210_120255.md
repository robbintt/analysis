---
ver: rpa2
title: Discrete Diffusion-Based Model-Level Explanation of Heterogeneous GNNs with
  Node Features
arxiv_id: '2508.08458'
source_url: https://arxiv.org/abs/2508.08458
tags:
- node
- graph
- graphs
- features
- explanation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining predictions made
  by Heterogeneous Graph Neural Networks (HGNNs) on real-world datasets that contain
  actual node features. Existing post-hoc explanation methods either lack model-level
  explanations, ignore node features, or fail to generate realistic and faithful explanations.
---

# Discrete Diffusion-Based Model-Level Explanation of Heterogeneous GNNs with Node Features

## Quick Facts
- **arXiv ID**: 2508.08458
- **Source URL**: https://arxiv.org/abs/2508.08458
- **Reference count**: 40
- **Primary result**: DiGNNExplainer outperforms state-of-the-art baselines in predictive faithfulness (PF) and ground-truth faithfulness (GF) on real-world datasets like DBLP and IMDB while generating more realistic graphs and node features

## Executive Summary
This paper addresses the challenge of explaining predictions made by Heterogeneous Graph Neural Networks (HGNNs) on real-world datasets that contain actual node features. Existing post-hoc explanation methods either lack model-level explanations, ignore node features, or fail to generate realistic and faithful explanations. To overcome these limitations, the authors propose DiGNNExplainer, a model-level explanation approach that synthesizes heterogeneous graphs with realistic node features using discrete denoising diffusion. The method combines discrete diffusion models for both graph structure (DiGress) and node features (DiTabDDPM), which is an extension of TabDDPM for discrete features. DiGNNExplainer outperforms state-of-the-art baselines in terms of both predictive faithfulness (PF) and ground-truth faithfulness (GF) on real-world datasets like DBLP and IMDB. It also generates more realistic graphs and node features, as evidenced by higher cosine similarity scores and better preservation of graph distributions.

## Method Summary
DiGNNExplainer synthesizes heterogeneous graphs with realistic node features using discrete denoising diffusion to provide model-level explanations for HGNNs. The approach combines DiGress, a discrete diffusion model for graph structure, with DiTabDDPM, an extension of TabDDPM for discrete node features. This dual-diffusion approach enables the generation of synthetic but realistic explanations that maintain both structural and feature-level fidelity to the original data. The method operates by learning to denoise discrete representations of both graph structure and node features, producing explanations that can be evaluated using faithfulness metrics while preserving the heterogeneous nature of the input data.

## Key Results
- DiGNNExplainer achieves higher predictive faithfulness (PF) and ground-truth faithfulness (GF) scores compared to state-of-the-art baselines on DBLP and IMDB datasets
- The method generates more realistic synthetic graphs and node features, demonstrated through higher cosine similarity scores with original data
- Better preservation of graph distributions compared to competing approaches, validating the effectiveness of the discrete diffusion approach

## Why This Works (Mechanism)
DiGNNExplainer works by leveraging discrete denoising diffusion probabilistic models that can capture the complex joint distribution of heterogeneous graph structures and node features. The discrete nature of the diffusion process allows it to maintain the categorical or discrete characteristics of real-world graph data while learning to reconstruct the underlying patterns that HGNNs use for predictions. By training separate but coordinated diffusion models for graph structure (DiGress) and node features (DiTabDDPM), the method can synthesize explanations that preserve both the topological relationships and the semantic content of the original data. The model-level explanation capability emerges from the ability to generate multiple synthetic graphs that capture general patterns across different predictions, rather than explaining individual instances in isolation.

## Foundational Learning
- **Heterogeneous Graph Neural Networks (HGNNs)**: Models that operate on graphs with multiple node/edge types, needed because real-world data often contains diverse entity relationships
- **Discrete Denoising Diffusion Probabilistic Models**: Generative models that learn to denoise discrete data representations, required for generating realistic synthetic graph structures and features
- **Post-hoc Explanation Methods**: Techniques that explain pre-trained models without modifying them, essential for understanding black-box HGNN predictions
- **Model-level vs Instance-level Explanations**: Model-level explanations capture general patterns across predictions, needed for understanding overall model behavior rather than individual cases
- **Predictive Faithfulness (PF) and Ground-truth Faithfulness (GF)**: Evaluation metrics that measure how well explanations align with model predictions and ground truth, required for quantitative comparison of explanation quality

## Architecture Onboarding

**Component Map**: DiGNNExplainer -> (DiGress + DiTabDDPM) -> Synthesized Graph + Node Features -> Faithfulness Evaluation

**Critical Path**: Input HGNN model → DiGNNExplainer (DiGress + DiTabDDPM) → Synthesized graph with features → Faithfulness metrics computation → Explanation output

**Design Tradeoffs**: Uses discrete diffusion for realism and faithfulness vs computational efficiency; model-level explanations vs instance-level specificity; combined graph and feature synthesis vs separate approaches

**Failure Signatures**: Poor faithfulness scores indicate insufficient learning of diffusion processes; unrealistic synthetic graphs suggest issues with DiGress; unnatural node features point to DiTabDDPM limitations; computational bottlenecks may arise from iterative denoising steps

**3 First Experiments**:
1. Run DiGNNExplainer on a small heterogeneous graph with known structure to verify basic functionality
2. Compare faithfulness scores of synthesized explanations against ground truth on a validation subset
3. Evaluate cosine similarity between original and synthesized node features to assess feature realism

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on two real-world datasets (DBLP and IMDB), which may not represent the diversity of heterogeneous graph scenarios
- Computational complexity of synthesizing both graph structure and node features using discrete diffusion models could be prohibitive for larger graphs
- Interpretability of the synthesized explanations for end-users is not addressed, as the paper focuses on technical faithfulness metrics

## Confidence
- **High confidence**: The core technical approach of combining discrete diffusion for graph structure (DiGress) and node features (DiTabDDPM) is sound and well-justified
- **Medium confidence**: The claim about generating "more realistic" graphs and features based on cosine similarity scores, while supported by evidence, could benefit from additional qualitative assessments
- **Medium confidence**: The broad applicability claim to various domains with heterogeneous graph data is reasonable but requires validation across more diverse use cases

## Next Checks
1. Test DiGNNExplainer on additional heterogeneous graph datasets with different characteristics (e.g., social networks, biological networks) to assess generalizability beyond DBLP and IMDB
2. Conduct ablation studies to quantify the individual contributions of DiGress and DiTabDDPM to the overall explanation quality, and evaluate performance when using continuous diffusion models instead
3. Perform runtime and scalability analysis on larger heterogeneous graphs to determine practical limitations and identify potential optimizations for real-world deployment