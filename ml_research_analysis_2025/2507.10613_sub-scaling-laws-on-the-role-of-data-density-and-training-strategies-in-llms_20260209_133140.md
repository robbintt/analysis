---
ver: rpa2
title: 'Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs'
arxiv_id: '2507.10613'
source_url: https://arxiv.org/abs/2507.10613
tags:
- training
- scaling
- data
- performance
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper systematically investigates sub-scaling laws in large\
  \ language models, where performance improvements decelerate as model or dataset\
  \ size increases. Through extensive empirical analysis of over 400 models (20M\u2013\
  7B parameters) across different data densities and training strategies, the authors\
  \ identify high data density and non-optimal resource allocation as key factors\
  \ causing sub-scaling."
---

# Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs

## Quick Facts
- arXiv ID: 2507.10613
- Source URL: https://arxiv.org/abs/2507.10613
- Authors: Zhengyu Chen; Siqi Wang; Teng Xiao; Yudong Wang; Shiqi Chen; Xunliang Cai; Junxian He; Jingang Wang
- Reference count: 40
- Primary result: High data density and over-training cause performance gains to decelerate; sub-optimal scaling law with density and OTR decay factors achieves lower prediction error than Chinchilla law.

## Executive Summary
This paper investigates sub-scaling laws in large language models, where performance improvements decelerate as model or dataset size increases. Through extensive empirical analysis of over 400 models (20M–7B parameters) across different data densities and training strategies, the authors identify high data density and non-optimal resource allocation as key factors causing sub-scaling. They propose a new density metric that considers both intra-cluster concentration and inter-cluster separation, and introduce a sub-optimal scaling law that generalizes the Chinchilla scaling law to better predict performance in sub-scaling regimes. The sub-optimal scaling law achieves lower fitting and prediction errors compared to traditional scaling laws across all model sizes, particularly in high-density datasets and over-training scenarios.

## Method Summary
The paper systematically investigates sub-scaling by training 11 model sizes (20M-7B parameters) on three dataset variants with different densities (0.64, 0.56, 0.47) using AdamW optimizer with cosine learning rate schedules. Models are trained across multiple Over-Training Ratios (OTR = D/N) ranging from 5 to 500. The density metric combines intra-cluster concentration and inter-cluster separation using k-means clustering on embeddings. The sub-optimal scaling law L(N,D) = E + λN·RN/N^αN + λD·RD/D^αD incorporates logistic decay factors RD and RN that increase with OTR, generalizing Chinchilla scaling. Batch size and learning rate are scaled as power-laws of loss, remaining robust to sub-scaling.

## Key Results
- High data density (ρ=0.64) causes significant performance deceleration compared to low density (ρ=0.47), with sub-scaling becoming severe as model size increases
- Over-Training Ratio (OTR) threshold of 50 marks transition where scaling exponent stabilizes, preventing further loss reduction per FLOP
- Sub-optimal scaling law achieves prediction MAPE improvements of 2-3× over Chinchilla law across all model sizes, with best performance in high-density and over-training regimes
- Both batch size and learning rate scale reliably with loss value, remaining robust to sub-scaling phenomena

## Why This Works (Mechanism)

### Mechanism 1
High data density causes performance gains to decelerate due to redundant information reducing marginal learning per sample. The paper models information gain as I(n) = I₀·n⁻ᵅ for high-density datasets (vs. linear I(n) = I₀·n for low-density), where redundancy increases mutual information between samples. This yields performance P(n) = P₀(1 - e^(-β·I₀·n⁻ᵅ)), capturing diminishing returns as a power-law decay rather than linear growth. Core assumption: information-theoretic entropy accurately characterizes learning signal in text corpora; redundancy within clusters directly translates to reduced gradient diversity. Evidence: Figure 4 shows 100M and 800M models on high vs. low density datasets, with high density showing "degressive performance increase". Break condition: If data preprocessing removes near-duplicates and ensures cluster separation (low ρ via Eq. 3), information gain approaches linear and sub-scaling is mitigated.

### Mechanism 2
Over-training (training tokens D >> optimal for model size N) triggers sub-scaling through non-optimal compute allocation, altering the loss-compute exponent. The Over-Training Ratio OTR = D/N quantifies allocation strategy. Empirically, when OTR ≤ 50, exponent αₒ decreases with OTR; when 50 < OTR ≤ 1700, αₒ stabilizes (Mean = 0.0521, Std = 0.002). This indicates a regime shift where additional tokens yield negligible loss reduction per FLOP. Core assumption: The Chinchilla-optimal allocation (~20 tokens/parameter) generalizes; deviations follow the logistic decay factors R_D and R_N in the sub-optimal law. Evidence: "when OTR exceeds a threshold of 50, the scaling exponent of loss and the compute budget stabilizes". Break condition: Maintain OTR near Chinchilla-optimal (~20) or explicitly model R_D/R_N decay if over-training is intentional.

### Mechanism 3
The sub-optimal scaling law L(N,D) = E + λ_N·R_N/N^α_N + λ_D·R_D/D^α_D generalizes Chinchilla by accounting for density and over-training via logistic decay factors. R_D = 1 + 1/(1 + exp(-k₁·OTR)) and R_N = 1 + 1/(1 + exp(-k₂·OTR)) increase curvature in the loss surface when OTR grows, correcting traditional law's optimistic predictions. Fitted constants: k₁ = 0.00810, k₂ = 0.00114. Core assumption: The logistic form captures the transition from scaling to sub-scaling regimes; fitting on smaller models (≤7B) extrapolates to larger models. Evidence: Final fitting L = 455.345·R_D/D^0.289 + 61.929·R_N/N^0.272 + 1.372. Break condition: If density metric ρ is miscalculated or OTR is misestimated, decay factors may over/under-correct.

## Foundational Learning

- **Concept: Power-law scaling in neural networks (Kaplan et al., Hoffmann et al.)**
  - Why needed here: The paper extends classical scaling laws (L ∝ N^-α · D^-β) by adding decay factors; understanding the baseline power-law relationship is prerequisite.
  - Quick check question: Given fixed compute C = 6ND, does doubling model size N while halving data D increase, decrease, or leave loss unchanged under Chinchilla-optimal allocation?

- **Concept: Over-training ratio (OTR) and compute-optimal training**
  - Why needed here: OTR = D/N is the central diagnostic for sub-scaling; the paper's threshold analysis (OTR ≈ 50) directly informs training decisions.
  - Quick check question: If a 1B parameter model is trained on 100B tokens, what is its OTR? Is it in the stable or decaying regime per this paper?

- **Concept: Data density metrics (intra-cluster concentration vs. inter-cluster separation)**
  - Why needed here: The proposed density metric (Eq. 1-3) combines cluster-level ρᵢ and dataset-level ρ to predict sub-scaling onset.
  - Quick check question: For a dataset with 10 clusters of equal size, does increasing inter-cluster distance while holding intra-cluster spread constant increase or decrease the dataset density ρ?

## Architecture Onboarding

- **Component map:** Embedding samples → Cluster (k-means) → Compute per-cluster density ρᵢ → Aggregate to dataset density ρ → Train models across OTR values → Fit sub-optimal scaling law with logistic decay factors

- **Critical path:**
  1. Compute density ρ for candidate datasets; prioritize low-ρ data (ρ < 0.5 in The Pile experiments)
  2. Determine target OTR based on compute budget; if OTR > 50, expect sub-scaling and use sub-optimal law for prediction
  3. Fit decay factors k₁, k₂ on early training data (first quarter of tokens) for your specific architecture

- **Design tradeoffs:**
  - Low-density data selection (e.g., ρ = 0.47 vs. 0.64) improves scaling but reduces effective dataset size
  - Over-training (high OTR) trades compute for small model convenience; sub-optimal law predicts 3-8× higher MAPE if ignored
  - Fitting sub-optimal law requires multi-scale experiments; single model size insufficient to estimate R_D and R_N

- **Failure signatures:**
  - Loss curve diverges from fitted law mid-training → likely OTR regime change, refit with higher k₁/k₂
  - Prediction MAPE > 0.02 on validation → density metric may not capture redundancy in your domain
  - Batch size/learning rate scaling breaks → check if loss measurement window is too noisy (apply Gaussian smoothing per Appendix A.3)

- **First 3 experiments:**
  1. **Density ablation:** Train 100M and 500M models on three dataset variants (raw Pile ρ=0.64, deduplicated ρ=0.56, density-selected ρ=0.47); plot loss vs. tokens to confirm sub-scaling severity correlates with ρ
  2. **OTR threshold validation:** For a fixed 500M model, train with OTR ∈ {10, 20, 50, 100, 200}; fit α_C for each and verify stabilization near OTR = 50
  3. **Sub-optimal law extrapolation:** Fit the law on 50M–500M models with OTR ≤ 100; predict loss for 2B model at OTR = 500 and compare against traditional scaling law prediction MAPE

## Open Questions the Paper Calls Out

- **Question:** Do the sub-optimal scaling laws and identified Over-Training Ratio (OTR) thresholds hold for models significantly larger than 7B parameters?
  - Basis: The authors state in the Limitations section: "we plan to perform additional experiments on larger models with more training tokens to ensure the scalability and robustness of our findings."
  - Why unresolved: The empirical analysis capped model size at 7B parameters, leaving the behavior of frontier-scale models (e.g., 70B+) unknown.
  - What evidence would resolve it: Empirical validation of the sub-optimal scaling law fit and OTR stability on models exceeding 7B parameters.

- **Question:** Do the derived scaling laws generalize to model architectures significantly different from the dense Transformers tested?
  - Basis: The Limitations section notes findings "may not universally apply to all types of models, particularly those with significantly different architectures or training algorithms."
  - Why unresolved: The study relied on specific dense configurations; architectures like Mixture-of-Experts (MoE) might exhibit distinct density and allocation dynamics.
  - What evidence would resolve it: Applying the sub-optimal scaling law methodology to non-dense or structurally distinct architectures to test prediction accuracy.

- **Question:** How does the sub-scaling phenomenon interact with model robustness, underfitting, and generalization across diverse domains?
  - Basis: The authors acknowledge that "Other critical factors such as underfitting, model robustness, and generalization across different tasks and domains were not extensively explored."
  - Why unresolved: The study focused primarily on loss values and limited downstream tasks (e.g., MMLU) rather than holistic safety or robustness metrics.
  - What evidence would resolve it: Evaluating sub-scaled models on adversarial robustness benchmarks and out-of-distribution generalization tasks.

## Limitations

- The empirical analysis is restricted to models up to 7B parameters and training tokens up to 500B, which may not fully capture sub-scaling phenomena that emerge at frontier scales (hundreds of billions of parameters).
- The density metric assumes k-means clustering is representative of true information redundancy, but this may not hold for all embedding spaces or domain-specific data distributions.
- The logistic decay functions R_D and R_N are fitted constants (k₁=0.00810, k₂=0.00114) that may not generalize across architectures or training paradigms beyond the specific AdamW setup tested.

## Confidence

**High confidence**: The empirical observation that high data density correlates with performance deceleration is well-supported by controlled experiments showing clear degradation in scaling exponents for high-density datasets. The OTR threshold analysis (OTR≈50) is robust across multiple model sizes and provides actionable guidance for training allocation.

**Medium confidence**: The proposed sub-optimal scaling law achieves lower prediction errors than traditional laws in the tested regime (20M-7B parameters), but extrapolation to much larger models remains unverified. The density metric's ability to capture all forms of redundancy and its universal applicability across domains requires further validation.

**Low confidence**: The specific decay constants k₁ and k₂ may not transfer to different model families, learning rate schedules, or optimizer configurations. The claim that batch size and learning rate scaling remains robust to sub-scaling needs independent verification across diverse architectures.

## Next Checks

1. **Large-scale extrapolation test**: Apply the fitted sub-optimal scaling law to predict loss for 70B and 175B parameter models trained under various OTR regimes, then compare predictions against actual training runs to quantify error growth beyond the 7B parameter limit.

2. **Density metric robustness**: Implement the density computation using alternative clustering methods (HDBSCAN, hierarchical clustering) and embedding models (sentence-BERT, CLIP) to test whether the correlation between ρ and sub-scaling persists across different representations.

3. **Cross-architecture validation**: Train small transformer variants (distilled models, sparse architectures) under identical density and OTR conditions to verify whether the sub-optimal scaling law's decay factors R_D and R_N remain consistent or require architecture-specific adjustment.