---
ver: rpa2
title: 'ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems'
arxiv_id: '2601.00994'
source_url: https://arxiv.org/abs/2601.00994
tags:
- persuasion
- agents
- were
- seed
- simulation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ElecTwit, a realistic simulation framework
  for studying persuasion in multi-agent systems modeled after social media during
  elections. The framework enables agents to post, reply, and like within a political
  context, with each agent given a background in six political topics and Big 5 personality
  traits.
---

# ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems

## Quick Facts
- **arXiv ID**: 2601.00994
- **Source URL**: https://arxiv.org/abs/2601.00994
- **Reference count**: 15
- **Key outcome**: ElecTwit framework reveals comprehensive use of 25 persuasion techniques in LLM agents, with top techniques being Appeal to Credibility, Emotion, and Logic; Gemini 2.5 Flash generated most tags while Claude 3.5 Haiku generated least.

## Executive Summary
This paper introduces ElecTwit, a realistic simulation framework for studying persuasion in multi-agent systems modeled after social media during elections. The framework enables agents to post, reply, and like within a political context, with each agent given a background in six political topics and Big 5 personality traits. Eight LLMs were tested across 11 simulations, with comprehensive use of 25 persuasion techniques observed, dominated by "Appeal to Credibility," "Appeal to Emotion," and "Appeal to Logic." Gemini 2.5 Flash generated the most persuasion tags, while Claude 3.5 Haiku the least. Unique emergent behaviors included "kernel of truth" messages and spontaneous demands for written policy proof ("ink"). The results suggest model architecture and training significantly influence persuasive behavior, and the open-source ElecTwit framework provides a realistic platform for future research on LLM persuasion in social contexts.

## Method Summary
ElecTwit simulates a Twitter-like platform during an election with 16 voters, 2 candidates, and 1 eventor agent. Each agent receives six political topic scores (-100 to 100) and Big 5 personality traits. The framework runs 9 time increments per "day" (9am-5pm) where all agents act simultaneously with a "chance to act" probability. Agents post, reply, and like within 280-character limits, logging interactions in diaries that consolidate daily. After simulation, a separate LLM annotates all messages with 25 persuasion techniques. The framework uses temperature=0 for reproducibility and requires candidates to have cosine similarity between -1 and -0.75 to ensure ideological opposition.

## Key Results
- Observed comprehensive use of 25 specific persuasion techniques across most tested LLMs, with "Appeal to Credibility," "Appeal to Emotion," and "Appeal to Logic" dominating political discourse
- Gemini 2.5 Flash generated the most persuasion tags while Claude 3.5 Haiku generated the least, indicating model architecture significantly influences persuasive behavior
- Emergent collective behaviors included spontaneous demands for written policy proof ("ink") and "kernel of truth" messages, suggesting complex social dynamics beyond explicit instruction

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Realistic social media constraints elicit broader persuasion technique diversity than game-based simulations.
- Mechanism: By imposing platform constraints (280-character limit, unique IDs for replies/likes, 9 time increments representing work hours), agents must produce concise, targeted persuasive messages rather than extended strategic narratives typical of game environments. The political election context provides high-stakes motivation for persuasion without explicit technique incentivization.
- Core assumption: Platform fidelity translates to behavioral fidelity; persuasion observed in ElecTwit generalizes to real social media dynamics.
- Evidence anchors:
  - [abstract]: "We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported."
  - [Section I-B]: "While using games like Among Us [8], [9] provides a snapshot or subset of an LLM's behavior, they do not offer sufficient realism for how agents might behave in the real world."
  - [corpus]: "Persuade Me if You Can" framework similarly evaluates persuasion effectiveness but uses structured persuasion tasks rather than emergent social simulation contexts.
- Break condition: If agents begin exploiting platform mechanics (e.g., generating posts to maximize metrics rather than persuade) or if the 280-character constraint suppresses complex techniques entirely.

### Mechanism 2
- Claim: Agent heterogeneity through political background vectors and personality traits produces divergent persuasive strategies, though correlation with voting behavior remains inconclusive.
- Mechanism: Each agent receives six political topic scores (-100 to 100) plus Big 5 personality trait scores. Candidates are constrained to cosine similarity between -1 and -0.75 to ensure ideological opposition. This creates natural persuasion dynamics where agents advocate from distinct positions.
- Core assumption: Cosine similarity on background vectors meaningfully captures ideological distance that drives persuasive behavior.
- Evidence anchors:
  - [Section III-C1]: Six topics derived from Pew Research surveys conducted a decade apart, showing consistent ideological structuring.
  - [Section IV]: "In Fig. 3, we notice that most of the models kept relatively close to zero, which indicates that the background actually has little to no impact on the model's behavior."
  - [corpus]: No direct corpus evidence on background vector mechanisms in similar frameworks; this remains underexplored.
- Break condition: If background similarity shows no correlation with interaction patterns, or if agents ignore assigned positions entirely.

### Mechanism 3
- Claim: Model architecture and training significantly influence persuasion technique frequency and emergent collective behaviors.
- Mechanism: Different LLMs (Gemini 2.5 Flash, GPT-4.1-mini, Claude 3.5 Haiku, etc.) produce divergent persuasion tag counts and action rates despite identical prompts and environments. Gemini 2.5 Flash generated highest tag counts; Claude 3.5 Haiku generated lowest. The "ink" obsession emerged spontaneously as agents collectively demanded written policy proof.
- Core assumption: Observed differences stem from model architecture/training rather than stochastic variation; temperature was held at zero to isolate architectural effects.
- Evidence anchors:
  - [abstract]: "Gemini 2.5 Flash generated the most persuasion tags, while Claude 3.5 Haiku the least."
  - [Section IV-D]: "'no ink, no vote' became a rallying cry... we suspect 'ink' referred to signed, written policy documents."
  - [corpus]: "It's a TRAP!" benchmark documents persuasion susceptibility variation across models, supporting architecture-dependence claims.
- Break condition: If replication with varied seeds shows high variance within models exceeding between-model differences.

## Foundational Learning

- **Multi-Agent LLM Simulation Design**:
  - Why needed here: ElecTwit coordinates 16 voters + 2 candidates + 1 eventor with synchronous interactions, diaries, and voting—a non-trivial orchestration requiring understanding of prompt engineering, memory management, and action scheduling.
  - Quick check question: Can you explain why synchronous agent actions at each time increment might produce different dynamics than asynchronous, turn-based interactions?

- **Persuasion Technique Taxonomy**:
  - Why needed here: The framework uses 25 persuasion techniques from prior work [8] for post-hoc LLM-based annotation; understanding this taxonomy is essential for interpreting results and extending the framework.
  - Quick check question: What are the top three persuasion techniques observed in ElecTwit, and why might "Appeal to Credibility" dominate political discourse?

- **Cosine Similarity for Agent Background Matching**:
  - Why needed here: Candidate selection enforces cosine similarity between -1 and -0.75 on background vectors; understanding this metric is necessary for configuring simulations and interpreting similarity plots.
  - Quick check question: If two candidate vectors have cosine similarity of 0.9, what does this imply about their ideological positions, and why would this be problematic for simulation dynamics?

## Architecture Onboarding

- **Component map**:
  - Eventor -> Generates events (scandals on days 4, 8)
  - Platform -> Post/comment/like actions with unique IDs, 280-char limit, uniform feed
  - Agents -> Voters (16), Candidates (2), Eventor (1); each with role prompts, background vectors, action limits (10), "chance to act" probability
  - Memory -> Per-agent diaries with daily consolidation for cross-day persistence
  - Evaluation -> Separate LLM annotates messages with 25 persuasion techniques post-hoc
  - Poll Manager -> Non-agent component tracking votes

- **Critical path**:
  1. Eventor generates event (scandal on days 4, 8)
  2. Prompts formatted from events + platform state + polls + diary history
  3. Each voter/candidate LLM generates response
  4. Response parsed: valid IDs → platform actions; invalid → discarded
  5. Diary entries logged; consolidated end-of-day
  6. Post-simulation: All messages submitted to evaluation LLM for persuasion tagging

- **Design tradeoffs**:
  - Uniform feed vs. personalized: Simplified computation but reduces echo chamber emergence potential
  - Synchronous actions: Accelerates simulation but reduces individual behavioral realism
  - LLM-based evaluation: Scalable but inherits LLM biases; no human ground truth
  - Temperature = 0: Reduces variance but may suppress emergent behaviors requiring exploration

- **Failure signatures**:
  - Agents generating actions without valid IDs → interactions not recorded
  - Diary consolidation failure → agents lose context across days
  - Candidate similarity too high → homogeneous campaign discourse
  - Persuasion tagger inconsistencies → technique frequency artifacts

- **First 3 experiments**:
  1. **Baseline replication**: Run same-seed simulation with original three candidate models; verify persuasion technique distribution matches paper (Credibility/Logic/Emotion dominance).
  2. **Temperature sensitivity**: Run 5 simulations per model at temperature 0.3 and 0.7; assess whether persuasion technique diversity increases or whether emergent behaviors like "ink" become more frequent.
  3. **Background impact isolation**: Generate voter agents with maximally divergent vs. similar background vectors to the candidates they're assigned; test whether voting correlation with similarity emerges under controlled conditions (paper found inconclusive results).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does increasing the temperature parameter significantly alter the frequency or diversity of persuasive techniques employed by LLMs in social simulations?
- Basis in paper: [explicit] The authors state in the Conclusion that future work should introduce "temperature parameters to assess the impact of randomness on persuasive outcomes."
- Why unresolved: All reported experiments strictly used a temperature of zero to ensure reproducibility and manage costs, leaving the effects of stochasticity on persuasive behavior untested.
- What evidence would resolve it: Comparative simulations using identical model configurations and seeds run at varying non-zero temperature settings to measure changes in persuasion tag diversity.

### Open Question 2
- Question: To what extent do assigned agent backgrounds (political topics and Big 5 traits) causally influence voting preferences versus model-specific behaviors?
- Basis in paper: [explicit] The authors note conflicting data regarding voter similarity and conclude that "without additional simulations, it remains unclear whether the background impacts a model's voting preferences."
- Why unresolved: The small experiment size resulted in conflicting signals: graphs showed agents kept close to zero similarity, suggesting background had little impact, contradicting the intuitive expectation that backgrounds dictate actions.
- What evidence would resolve it: Large-scale ablation studies where agent backgrounds are systematically randomized or removed to isolate their specific effect on voting alignment from the underlying model bias.

### Open Question 3
- Question: How does the implementation of personalized feeds (algorithmic timelines) alter polarization dynamics compared to the uniform feed used in the current study?
- Basis in paper: [explicit] The Conclusion acknowledges that "simplifications such as uniform feeds... limit generalizability, motivating future extensions with personalized timelines."
- Why unresolved: The ElecTwit platform currently provides a standard, identical feed for all agents to manage complexity, which may artificially suppress or alter the natural formation of echo chambers.
- What evidence would resolve it: A comparative study measuring interaction clustering and polarization indices in simulations using personalized content delivery algorithms versus the standard uniform feed.

## Limitations
- The study's findings are based on only 11 simulations using temperature=0, raising questions about whether observed differences reflect model architecture versus stochastic variation
- Persuasion effectiveness was not measured, only technique frequency, limiting conclusions about actual persuasive success
- The claim that platform fidelity translates to behavioral fidelity remains largely theoretical without real-world validation
- Inconclusive results regarding background vector impact on voting behavior suggest the ideological distance mechanism may not function as intended

## Confidence
- High confidence in reported persuasion technique frequencies and top techniques (Appeal to Credibility, Emotion, and Logic)
- Medium confidence in claims about model architecture influencing persuasive behavior due to limited simulation count
- Low confidence in the "ink" emergent behavior's significance and generalizability

## Next Checks
1. Replicate the simulation with varied seeds across all 8 models to establish whether persuasion technique distributions show high variance within models or consistent between-model differences
2. Conduct human evaluation of a subset of annotated messages to validate the LLM-based persuasion technique classification accuracy
3. Test the framework with asynchronous (turn-based) interactions rather than synchronous actions to assess whether this changes persuasion dynamics or emergent behaviors