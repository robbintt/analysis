---
ver: rpa2
title: Who Said Neural Networks Aren't Linear?
arxiv_id: '2510.08570'
source_url: https://arxiv.org/abs/2510.08570
tags:
- linear
- style
- induced
- linearizer
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Linearizer framework, which enables the
  exact linearization of nonlinear neural networks by embedding linear operators between
  invertible neural networks. By redefining vector space operations through the invertible
  maps, the framework induces new vector spaces where the overall mapping becomes
  linear.
---

# Who Said Neural Networks Aren't Linear?

## Quick Facts
- arXiv ID: 2510.08570
- Source URL: https://arxiv.org/abs/2510.08570
- Authors: Nimrod Berman; Assaf Hallak; Assaf Shocher
- Reference count: 40
- Primary result: Exact linearization of nonlinear neural networks using invertible sandwich architecture enables one-step diffusion sampling, modular style transfer, and structured generative modeling

## Executive Summary
This paper introduces the Linearizer framework, which enables the exact linearization of nonlinear neural networks by embedding linear operators between invertible neural networks. By redefining vector space operations through the invertible maps, the framework induces new vector spaces where the overall mapping becomes linear. This allows direct application of linear algebra tools—such as SVD, pseudoinverse, and idempotent projection—to nonlinear functions. The paper demonstrates several applications: collapsing hundreds of diffusion sampling steps into a single step via one-step flow matching, enforcing global idempotency in generative models, and enabling modular style transfer through linear interpolation of style operators.

## Method Summary
The Linearizer framework sandwiches a linear matrix A between two invertible neural networks (g_x, g_y). The overall function f(x) = g_y⁻¹(A g_x(x)) becomes a linear operator in the "induced" vector spaces defined by the invertible maps. The invertible networks transform the input and output spaces, allowing standard linear algebra operations to be applied directly to the core matrix A. This enables applications like collapsing iterative generative processes into single steps by pre-computing matrix products, enforcing algebraic properties like idempotency through constraints on A, and enabling modular operations through linear interpolation in the latent space.

## Key Results
- Collapses hundreds of diffusion sampling steps into a single step with MSE ~3.0×10⁻⁴ between one-step and multi-step generation
- Demonstrates successful one-step flow matching on MNIST and CelebA datasets
- Enables modular style transfer through linear interpolation of style operators
- Enforces global idempotency in generative models through architectural constraints rather than loss penalties

## Why This Works (Mechanism)

### Mechanism 1
A nonlinear mapping can behave as a linear operator if input and output spaces are transformed by invertible functions. The architecture sandwiches a linear matrix A between two invertible neural networks (g_x, g_y). By defining new vector addition (⊕) and scaling (⊙) operations relative to these invertible maps, the nonlinear function f satisfies the superposition principle in the "induced" vector spaces. The core assumption is that g_x and g_y must be strictly invertible bijections; otherwise, the induced operations do not form a valid vector space. If the invertible networks leak information through numerical instability or non-bijective layers, the induced "linearity" becomes approximate rather than exact.

### Mechanism 2
Iterative generative processes (like diffusion sampling) can be collapsed into a single step by pre-computing the product of linear operators. Because the composition of two Linearizers is also a Linearizer, a sequence of N linear operations A₁, ..., A_N in the latent space can be multiplied into a single matrix B. Applying g⁻¹(B g(x₀)) yields the final result in one pass. The core assumption is that the diffusion process must be trained or distilled into the Linearizer format so that the velocity field is linear in the induced coordinates. If the matrix product results in numerical underflow/overflow due to many steps, or if the integration path requires non-linear corrections not captured by matrix A, the single-step output will diverge from the multi-step baseline.

### Mechanism 3
Algebraic properties like idempotency (projection) and inversion can be enforced structurally rather than via loss penalties. The properties of the overall function f are inherited from the core matrix A. If A is constrained to be idempotent (A²=A), f becomes a global projector. If A has a Moore-Penrose pseudoinverse A†, f has an exact inverse f†. The core assumption is that constraints on A (e.g., binary eigenvalues for projection) must be compatible with the expressiveness required for the data distribution. If the invertible wrapper g distorts the metric significantly, the "projection" in data space may look semantically alien despite satisfying the algebraic definition.

## Foundational Learning

- **Concept:** Invertible Neural Networks (Normalizing Flows)
  - **Why needed here:** The entire framework relies on g_x and g_y being bijections to define the "induced vector space." Without understanding coupling layers or invertible architectures, one cannot implement the "sandwich."
  - **Quick check question:** Can you explain why a standard CNN is not a valid candidate for g in this framework?

- **Concept:** Vector Space Axioms (Linearity)
  - **Why needed here:** The paper redefines "addition" and "scaling." Understanding that linearity is relative to these operations—not just the standard Euclidean ones—is key to grasping why a neural network can be "linear."
  - **Quick check question:** If you have v₁, v₂ in the induced space, how do you compute v₁ ⊕ v₂ using the function g?

- **Concept:** Flow Matching / Diffusion ODEs
  - **Why needed here:** The primary application is collapsing diffusion steps. Understanding the ODE formulation (dx/dt = v(x,t)) is necessary to see how a matrix A_t replaces a neural velocity field.
  - **Quick check question:** In standard diffusion, why does simulating the ODE require many steps, and mathematically what allows the Linearizer to skip them?

## Architecture Onboarding

- **Component map:** Input -> Encoder (g_x) -> Core (A) -> Decoder (g_y⁻¹) -> Output
- **Critical path:** The invertibility of g. If g is not perfectly invertible (numerically), the "induced vector space" collapses, and the theoretical guarantees (Lemma 2) fail.
- **Design tradeoffs:**
  - Expressiveness vs. Structure: Low-rank matrices for A make inversion/collapse easy but may limit the complexity of the mapping f.
  - Training Stability: Invertible networks are often harder to train than standard CNNs; the paper suggests adding isometry/perceptual losses to stabilize g.
- **Failure signatures:**
  - High MSE in One-Step: Suggests the matrix product collapse (integration) is inaccurate; try higher-order integration (RK4) when computing the collapsed matrix B.
  - Idempotency Drift: If f(f(x)) ≠ f(x), the constraint on A (e.g., STE thresholding) is likely leaking gradients or breaking exact binarization.
  - Degenerate Outputs: If g maps distinct inputs to the same latent (non-injective), the system loses information.
- **First 3 experiments:**
  1. **Sanity Check (Linear Interpolation):** Train a small Linearizer on MNIST. Encode two images, interpolate in the *induced* latent space (z = g(x)), and decode. Compare the smoothness to standard pixel interpolation.
  2. **One-Step Collapse:** Train a Linear Flow Matching model. Compute the product matrix B for 100 steps. Generate an image using only g⁻¹(B g(noise)) and compare it to the iterative output (MSE should be ~10⁻⁴ as per paper).
  3. **Structural Idempotency:** Implement the IGN (Idempotent Generative Network) variant. Force matrix A to be diagonal with {0,1} values. Verify if f(f(x)) ≈ f(x) holds exactly without specific idempotency loss terms.

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the precise theoretical expressivity limits of the Linearizer architecture, particularly regarding topological constraints on the null space?
  - **Basis in paper:** The authors state, "the precise expressivity of the Linearizer remains an open theoretical question" and note that null spaces must be either a single point or an infinite subspace (Sec 4.1, Sec 5).
  - **Why unresolved:** The paper demonstrates empirical success but lacks a formal characterization of the function class that can be represented given the constraints imposed by the invertible maps g.
  - **What evidence would resolve it:** A theoretical proof defining the necessary and sufficient conditions for a function to be Linearizer-representable, or a counter-example showing a specific topological configuration the framework cannot capture.

- **Open Question 2:** Can the Linearizer framework be scaled to achieve state-of-the-art performance on high-resolution generative modeling tasks?
  - **Basis in paper:** The conclusion lists "scaling one-step flow matching and IGN to larger datasets and higher resolutions" as a primary future direction (Sec 7).
  - **Why unresolved:** Current experiments are restricted to MNIST and CelebA (64x64), and the authors admit absolute FID is "not yet competitive with state-of-the-art systems" due to a focus on theory over engineering (Sec 3.1).
  - **What evidence would resolve it:** Successful training of Linearizer-based models on datasets like ImageNet or high-resolution text-to-image benchmarks with fidelity metrics matching current leaders (e.g., Consistency Models).

- **Open Question 3:** Can the Linearizer framework be utilized to simulate continuous-time evolution in physical or temporal dynamics using matrix exponentials?
  - **Basis in paper:** The authors explicitly suggest "modeling motion dynamics: by exploiting matrix exponentials, one could simulate continuous-time evolution directly" (Sec 7).
  - **Why unresolved:** The paper focuses on static image generation and style transfer; it validates collapsing discrete steps but does not test the framework's ability to model continuous trajectories in physical systems.
  - **What evidence would resolve it:** Application of the Linearizer to video prediction or physics simulations, demonstrating that continuous evolution can be modeled via the exponential of the core matrix A.

## Limitations

- The framework's exactness depends critically on perfect invertibility of the wrapper networks, with any numerical instability breaking theoretical guarantees
- Current experimental validation is limited to relatively small datasets (MNIST and CelebA at 64x64 resolution), raising questions about scalability
- The practical implementation details for invertible backbones and stability losses are underspecified, making exact reproduction challenging

## Confidence

- **High Confidence:** The core mathematical framework (Lemmas 1-7) and the principle of induced vector spaces through invertible transformations are sound and well-established. The composition property (Lemma 3) is straightforward linear algebra.
- **Medium Confidence:** The experimental demonstrations on MNIST and CelebA are compelling, but the small dataset sizes and limited ablation studies leave questions about scalability to more complex data distributions.
- **Low Confidence:** The practical implementation details for the invertible backbone and stability losses are underspecified. Without precise hyperparameters, reproducing the exact MSE values or FID scores would be challenging.

## Next Checks

1. **Invertibility Stress Test:** Implement gradient checkpointing and precision monitoring in the invertible backbone. Systematically measure information loss (KL divergence between input and reconstructed output) across different coupling architectures and verify that exact bijectivity is maintained throughout training.

2. **Integration Path Sensitivity:** Compare the collapsed operator approach against higher-order integration schemes (RK4) for long trajectories. Quantify the error accumulation as a function of integration step count and trajectory nonlinearity to establish operational limits of the one-step collapse.

3. **Low-Rank Expressiveness Analysis:** Systematically vary the rank of matrix A and measure the trade-off between computational efficiency and sample quality. Determine whether the rank-16 choice is sufficient for more complex datasets or whether the framework requires adaptation for higher-dimensional data.