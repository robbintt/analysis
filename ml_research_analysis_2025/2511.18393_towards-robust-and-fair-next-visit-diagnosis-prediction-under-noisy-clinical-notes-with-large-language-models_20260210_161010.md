---
ver: rpa2
title: Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical
  Notes with Large Language Models
arxiv_id: '2511.18393'
source_url: https://arxiv.org/abs/2511.18393
tags:
- disorders
- other
- clinical
- diseases
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the robustness and fairness of large language
  models (LLMs) for next-visit diagnosis prediction under noisy clinical text conditions.
  It introduces NECHO v3, which combines a clinically grounded label-reduction mapping
  with hierarchical chain-of-thought prompting to improve performance under textual
  degradation.
---

# Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models

## Quick Facts
- **arXiv ID**: 2511.18393
- **Source URL**: https://arxiv.org/abs/2511.18393
- **Authors**: Heejoon Koo
- **Reference count**: 20
- **Primary result**: NECHO v3, combining clinically grounded label-reduction mapping with hierarchical chain-of-thought prompting, improves LLM robustness and fairness for next-visit diagnosis prediction under textual corruption.

## Executive Summary
This study evaluates large language models (LLMs) for next-visit diagnosis prediction under realistic clinical text noise. It introduces NECHO v3, which integrates a clinically grounded label-reduction mapping with hierarchical chain-of-thought prompting to enhance performance under textual degradation. Experiments on MIMIC-IV data demonstrate that LLMs maintain stable aggregate performance under controlled corruptions (lab-value omission, prior-note duplication, OCR jittering, homophone substitution), but minority subgroups (e.g., unknown race, younger adults) exhibit higher variability and fairness disparities. The proposed method improves robustness and reduces subgroup instability, underscoring the need for fairness-aware design in clinical AI deployment.

## Method Summary
The study uses zero-shot LLMs (GPT-4o-mini, Gemini-2.0-Flash) for multi-label diagnosis prediction from longitudinal discharge summaries. ICD-9-CM codes are mapped to a reduced 17-parent/46-child CCS hierarchy. A hierarchical chain-of-thought prompt guides the LLM to first hypothesize parent diagnostic systems, then predict child subcategories. Realistic text corruptions (lab-value omission, prior-note duplication, homophone substitution, OCR jittering) are applied to test robustness. Performance is evaluated via Recall@10, Precision@10, AUPRC, and fairness via TPR/FPR across demographic subgroups, with bootstrapped 95% confidence intervals.

## Key Results
- LLMs maintain stable aggregate performance under realistic textual corruptions (e.g., GPT-4o-mini ~0.36 Recall@10).
- Minority subgroups (unknown race, age 18-40) exhibit higher variability and fairness disparities under noise.
- NECHO v3 (CoT + label reduction + demographic context) enhances robustness and reduces subgroup instability compared to ablated versions.
- Long-tailed diagnoses remain challenging, with persistent low AUPRC even under NECHO v3.

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Chain-of-Thought Prompting
Hierarchical CoT improves robustness by structuring reasoning to emulate clinicians' diagnostic process. The model first hypothesizes high-level diagnostic categories (parent systems), then enumerates specific subcategories (child categories). This two-stage decomposition localizes errors and provides intermediate reasoning traces that act as self-consistency checks under degraded input. The benefit relies on the LLM's ability to follow structured, multi-step reasoning prompts even when input tokens are corrupted.

### Mechanism 2: Clinically Grounded Label-Reduction Mapping
Mapping ICD-9 codes to the CCS hierarchy reduces the output space from thousands to ~60 categories, increasing per-class sample density and making the prediction task more tractable for zero-shot LLMs. This enforces consistency, as predictions must fit within the predefined schema. The effectiveness depends on the reduced label set preserving sufficient clinical discriminative power and the ontology mapping being clinically valid.

### Mechanism 3: Fairness Evaluation Under Corruption
Explicitly evaluating performance and fairness metrics (TPR, FPR) across demographic strata under realistic textual corruptions reveals whether noise disproportionately harms minority subgroups. NECHO v3 reduces the width of confidence intervals (instability) for these subgroups. The approach assumes that simulated corruptions are representative of real-world clinical documentation noise and that subgroup disparities under noise are a proxy for potential real-world inequity.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) Prompting for Reasoning Tasks**
  - **Why needed here**: The paper's core intervention uses hierarchical CoT to guide the LLM's diagnostic reasoning.
  - **Quick check question**: Can you explain the difference between a standard zero-shot prompt and a chain-of-thought prompt for a clinical task?

- **Concept: Clinical Terminology Systems (ICD-9-CM, CCS Hierarchy)**
  - **Why needed here**: The label-reduction mechanism is built upon mapping ICD codes to the CCS hierarchy.
  - **Quick check question**: What is the primary difference between a granular ICD-9 code and a higher-level CCS category?

- **Concept: Fairness Metrics in ML (TPR, FPR, Subgroup Evaluation)**
  - **Why needed here**: The paper's central finding is about fairness disparities under noise.
  - **Quick check question**: Why might aggregate accuracy be a poor indicator of a model's fairness across different patient subgroups?

## Architecture Onboarding

- **Component map**: Raw clinical notes → (optional degradation) → Hierarchical CoT Prompt + Label Schema → LLM Inference → Output Parser → Predicted Diagnoses → Evaluation Suite → Subgroup performance/fairness metrics.

- **Critical path**: Raw clinical notes → (optional degradation) → Hierarchical CoT Prompt + Label Schema → LLM Inference → Output Parser → Predicted Diagnoses → Evaluation Suite → Subgroup performance/fairness metrics.

- **Design tradeoffs**:
  - **Label Granularity vs. Task Tractability**: Reducing to 46 categories improves zero-shot performance but loses the specificity of raw ICD codes.
  - **Prompt Complexity vs. Instruction Following**: A more detailed hierarchical CoT prompt guides reasoning better but increases token count and assumes the LLM can perfectly follow complex instructions.
  - **Simulation Realism vs. Control**: The four corruption types are controlled and isolated. Real-world noise is messier and interacts.

- **Failure signatures**:
  - **Reasoning Collapse**: The LLM ignores the hierarchical prompt and predicts diagnoses not in the allowed schema.
  - **Subgroup Instability**: Very wide confidence intervals for metrics on minority subgroups (Unknown race, age 18-40).
  - **Sensitivity to Prompt Phrasing**: Significant performance changes with minor edits to the CoT prompt.
  - **Low TPR / High FPR Imbalance**: The model fails to identify true conditions (low TPR) while generating many false alarms (high FPR) for a specific subgroup.

- **First 3 experiments**:
  1. **Reproduce Clean vs. Corrupted Baseline**: Run the provided code on a small MIMIC-IV sample with clean notes and with each of the four corruption types. Compare overall Recall@10 to the paper's values.
  2. **Subgroup Fairness Check**: For the same sample, compute Recall@10 and FPR separately for the "White" and "Unknown" race groups under one corruption type (e.g., OCR Jittering). Compare the width of their confidence intervals.
  3. **Ablate a Component**: Remove the demographic information from the prompt and run inference on the clean sample for a single subgroup (e.g., age 18-40). Compare the TPR/FPR to the full model's result.

## Open Questions the Paper Calls Out
- **Open Question 1**: To what extent do the robustness and fairness trends observed in MIMIC-IV generalize to diverse clinical environments and distinct EHR systems?
- **Open Question 2**: How does domain-specific fine-tuning alter the trade-off between overall robustness and subgroup fairness under textual corruption compared to zero-shot prompting?
- **Open Question 3**: How does the simultaneous application of multiple text corruption types (stacked noise) impact the predictive stability of LLMs for diagnosis?
- **Open Question 4**: Can specific prompt engineering or data augmentation strategies be developed to stabilize performance specifically for long-tailed diagnoses in under-represented populations?

## Limitations
- **Degradation Realism**: The four corruption types are synthetically isolated and controlled, not representative of overlapping real-world error patterns.
- **Generalizability of Fairness Findings**: Fairness analysis is limited to three demographic dimensions and specific subgroup definitions, excluding other clinically relevant variables.
- **Ontology Coverage**: The 46-category reduced label set may not capture all clinically relevant diagnoses, particularly for rare conditions or population-specific presentations.

## Confidence
- **High Confidence**: The core finding that LLMs maintain stable aggregate performance under controlled textual corruptions is well-supported.
- **Medium Confidence**: The effectiveness of hierarchical CoT prompting and label-reduction mapping is supported by ablation studies, but the exact contribution of each component is not fully disentangled.
- **Medium Confidence**: The observation of subgroup instability under noise is robust, but the causal mechanisms linking specific corruption types to particular fairness disparities need further investigation.

## Next Checks
1. **Cross-Corpus Validation**: Replicate the robustness and fairness evaluation on a different clinical dataset (e.g., eICU, another hospital system) to test generalizability beyond MIMIC-IV.
2. **Stacked Corruption Testing**: Apply combinations of the four corruption types simultaneously (e.g., OCR jittering + lab-value omission) to assess whether performance degrades more severely than predicted by individual effects.
3. **Alternative Label Granularity**: Test intermediate label-reduction schemes (e.g., 100 vs. 46 categories) to identify the optimal balance between clinical specificity and prediction stability under noise.