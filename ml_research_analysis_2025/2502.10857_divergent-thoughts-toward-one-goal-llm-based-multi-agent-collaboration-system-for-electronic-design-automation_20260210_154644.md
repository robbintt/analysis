---
ver: rpa2
title: 'Divergent Thoughts toward One Goal: LLM-based Multi-Agent Collaboration System
  for Electronic Design Automation'
arxiv_id: '2502.10857'
source_url: https://arxiv.org/abs/2502.10857
tags:
- task
- script
- tool
- flow
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents EDAid, a multi-agent collaboration system for
  automating electronic design automation (EDA) flows using large language models
  (LLMs). The system addresses the challenges of LLM limitations in understanding
  EDA tools and the instability of long-chain tool-calling processes.
---

# Divergent Thoughts toward One Goal: LLM-based Multi-Agent Collaboration System for Electronic Design Automation

## Quick Facts
- arXiv ID: 2502.10857
- Source URL: https://arxiv.org/abs/2502.10857
- Reference count: 28
- Primary result: EDAid achieves 100% accuracy on complex EDA tasks using multi-agent collaboration with divergent thoughts

## Executive Summary
The paper presents EDAid, a multi-agent collaboration system for automating electronic design automation (EDA) flows using large language models (LLMs). The system addresses the challenges of LLM limitations in understanding EDA tools and the instability of long-chain tool-calling processes. EDAid employs multiple agents with divergent thoughts, each controlled by ChipLlama models—expert LLMs fine-tuned for EDA flow automation—and uses few-shot chain-of-thought prompting to enhance reasoning and portability. A decision-making agent selects the optimal solution from the divergent thoughts to ensure reliable and successful EDA flow automation. Experiments demonstrate that EDAid outperforms single-agent systems, achieving state-of-the-art performance on benchmarks like ChatEDA-bench and iEDA-bench, with accuracy reaching 100% for complex tasks.

## Method Summary
EDAid uses a hybrid instruction tuning approach to fine-tune Llama3-8B/70B models on MathInstruct, CodeInstruct, and EDAInstruct datasets to create ChipLlama models. The system employs 3 divergent-thoughts agents, each receiving different few-shot CoT prompts constructed from retrieved EDA tool usage demonstrations. These agents generate multiple planning steps and scripts. A decision-making agent evaluates each candidate script by computing the probability of a "yes" token when prompted to judge script correctness, selecting the highest-confidence solution. The approach is evaluated on ChatEDA-bench and iEDA-bench benchmarks, demonstrating superior performance compared to single-agent baselines.

## Key Results
- EDAid achieves 100% accuracy on ChatEDA-bench for complex tasks, outperforming single-agent baselines (~74%)
- On iEDA-bench, EDAid reaches 100% accuracy while single-agent systems score 50-88%
- The hybrid instruction tuning approach improves cross-platform generalization, increasing iEDA-bench accuracy from 50% to 76% for Llama3-8B
- Multi-agent collaboration with 3 divergent-thoughts agents provides optimal performance, with diminishing returns beyond this number

## Why This Works (Mechanism)

### Mechanism 1: Divergent Thoughts Generation via Few-Shot Sampling
Multiple agents receiving different permutations of retrieved few-shot demonstrations generate meaningfully diverse planning pathways, reducing the probability that all agents produce the same error in long-chain EDA tool-calling processes. For each EDA task, a retrieval module identifies the Top-K most relevant demonstrations from a vector database using cosine similarity on task embeddings. From this pool, multiple demo groups are constructed via random sampling, each forming a distinct few-shot CoT prompt. Each divergent-thoughts agent receives a different prompt, producing varied planning steps and corresponding scripts. The decision-making agent then evaluates correctness across candidates.

### Mechanism 2: Probability-Based Selection via Decision-Making Agent
A decision-making agent can reliably identify correct EDA scripts by computing the probability of a "yes" token when prompted to judge script correctness. The decision-making agent receives the EDA task description and a candidate script, then generates a binary judgment with reasoning. The probability of the final "yes" token (vs. "no") serves as a confidence score. The script with highest "yes" probability is selected. KV caching avoids redundant computation across evaluations.

### Mechanism 3: Hybrid Instruction Tuning for Cross-Platform Generalization
Fine-tuning on a hybrid corpus (math reasoning + code + EDA) transfers logical reasoning and coding skills to EDA flow planning, enabling generalization to unseen platforms. ChipLlama models are fine-tuned on MathInstruct (80K), CodeInstruct (100K), and EDAInstruct (8K). Math develops sequential reasoning; code develops script generation; EDA provides domain knowledge. This hybrid approach transfers to new platforms (e.g., iEDA) despite training primarily on OpenROAD.

## Foundational Learning

- **Concept: Chain-of-Thought (CoT) Prompting**
  - **Why needed here:** EDA flows require decomposing tasks into ordered stages (synthesis → floorplanning → placement → CTS → routing). CoT generates explicit planning steps before script, factorizing the problem.
  - **Quick check question:** How does equation (2) differ from equation (1), and what does C represent?

- **Concept: In-Context Learning with Few-Shot Demonstrations**
  - **Why needed here:** Enables adaptation to new EDA tools without retraining by providing examples in the prompt context. Critical for portability across platforms.
  - **Quick check question:** If you add a new EDA platform, what must you add to the demo database?

- **Concept: Self-Consistency for Multi-Path Reasoning**
  - **Why needed here:** Divergent thoughts build on self-consistency principles—generating multiple reasoning paths and aggregating improves reliability over single-path generation.
  - **Quick check question:** Why does self-consistency require diverse prompts rather than repeated sampling with the same prompt?

## Architecture Onboarding

- **Component map:** User task → Demo Retrieval → 3 Divergent-Thoughts Agents → Decision-Making Agent → Selected Script
- **Critical path:** User task → retrieve demos → create 3 demo groups → generate 3 candidate scripts → decision agent selects best → execute via EDA APIs
- **Design tradeoffs:**
  - Agent count: 3 agents balance coverage vs. latency (diminishing returns beyond 3)
  - Model size: 70B achieves 100%; 8B is faster but 88-94%
  - Closed-source excluded: Decision-making requires logit access
- **Failure signatures:**
  - Wrong parameter to wrong method (e.g., `macro_place_channel` in `global_route` instead of `floorplan`)
  - Skipped stages (e.g., placement without floorplanning)
  - Wrong-stage parameters (CTS params at placement)
  - Incomplete flows (optimize at CTS instead of final)
- **First 3 experiments:**
  1. Single-agent ChipLlama-8B baseline with zero-shot prompting on ChatEDA-bench (~74%)
  2. Few-shot vs zero-shot ablation on both benchmarks to measure portability gains
  3. Multi-agent scaling: test 1, 2, 3 agents to verify saturation point and latency tradeoff

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the inference latency introduced by the multi-agent collaboration system be minimized to meet the efficiency requirements of industrial EDA workflows?
- **Open Question 2:** What is the specific cause of the performance saturation observed when the number of divergent-thoughts agents exceeds three?
- **Open Question 3:** Does hybrid instruction tuning enable reliable generalization to proprietary or structurally distinct EDA tools not represented in the ChatEDA or iEDA benchmarks?

## Limitations

- The 8K-sample EDAInstruct dataset may be too small for comprehensive coverage of all EDA tool combinations and edge cases
- The retrieval database and embedding model specifics are not detailed, making it unclear how robust the demo selection process is
- Decision-making agent reliability depends on the assumption that token probability correlates with actual correctness, which may break down for novel tool combinations

## Confidence

- **High confidence** in the multi-agent divergent thoughts mechanism: The ablation studies and comparison with single-agent baselines provide strong empirical support
- **Medium confidence** in the probability-based decision-making: While Figure 4 shows clear probability differences, there's limited validation that this method consistently selects correct solutions across diverse tasks
- **Medium confidence** in cross-platform generalization: The 26 percentage point improvement on iEDA-bench supports the claim, but the iEDA platform may not represent sufficiently different EDA paradigms

## Next Checks

1. Test EDAid on a completely new EDA platform with no overlap in tool APIs to verify true generalization capability beyond iEDA
2. Perform ablation studies varying the number of retrieved demos (Top-K) and few-shot examples per prompt to optimize retrieval quality impact
3. Evaluate the decision-making agent's selection accuracy when faced with two scripts that have similar "yes" probabilities but opposite correctness to test the robustness of probability-based selection