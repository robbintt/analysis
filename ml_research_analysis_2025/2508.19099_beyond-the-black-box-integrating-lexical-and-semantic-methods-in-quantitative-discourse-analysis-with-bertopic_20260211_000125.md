---
ver: rpa2
title: 'Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative
  Discourse Analysis with BERTopic'
arxiv_id: '2508.19099'
source_url: https://arxiv.org/abs/2508.19099
tags:
- bertopic
- discourse
- lexical
- semantic
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of transparency and methodological
  alignment in quantitative discourse analysis (QDA) when using black-box tools like
  MAXQDA and NVivo. It proposes a hybrid framework combining lexical methods (bag-of-words,
  n-grams, lemmatization via spaCy) with semantic topic modeling (BERTopic with sentence
  embeddings) to enable triangulation, reproducibility, and interpretability.
---

# Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic

## Quick Facts
- arXiv ID: 2508.19099
- Source URL: https://arxiv.org/abs/2508.19099
- Reference count: 1
- Primary result: Hybrid lexical-semantic framework enables transparent, reproducible QDA with complementary insights

## Executive Summary
This paper addresses the challenge of transparency and methodological alignment in quantitative discourse analysis when using black-box tools like MAXQDA and NVivo. It proposes a hybrid framework combining lexical methods (bag-of-words, n-grams, lemmatization via spaCy) with semantic topic modeling (BERTopic with sentence embeddings) to enable triangulation, reproducibility, and interpretability. Using a historical political discourse corpus (95,557 sentences), the authors compare five embedding models and select all-mpnet-base-v2 based on coherence (0.09), topic distribution (584 topics), and neutral silhouette clustering. Manual topic refinement ensures interpretability. Results demonstrate that lexical and semantic approaches complement each other, with lexical methods providing precise term counts and semantic clustering revealing contextual framing. Code-level transparency and researcher agency are emphasized as critical for robust, reproducible QDA.

## Method Summary
The study employs a hybrid approach combining lexical analysis (bag-of-words, n-grams, lemmatization via spaCy) with semantic topic modeling (BERTopic using sentence embeddings). The corpus consists of 95,557 sentences from historical political discourse. Five embedding models were compared, with all-mpnet-base-v2 selected based on coherence score (0.09), topic distribution (584 topics), and silhouette clustering. Manual topic refinement was applied to enhance interpretability. The framework emphasizes researcher agency and code-level transparency for reproducibility.

## Key Results
- Hybrid framework enables triangulation between lexical (precise term counts) and semantic (contextual framing) methods
- all-mpnet-base-v2 embedding model selected based on coherence (0.09) and neutral silhouette clustering
- Manual topic refinement improves interpretability while maintaining methodological transparency
- 584 topics identified, demonstrating comprehensive discourse coverage

## Why This Works (Mechanism)
The framework works by combining two complementary analytical approaches: lexical methods provide precise, interpretable term frequency analysis while semantic methods capture contextual meaning and thematic relationships. BERTopic's sentence embeddings enable clustering of semantically similar discourse segments, while spaCy's lemmatization ensures consistent term analysis. The manual refinement process allows researchers to validate and adjust automated topic assignments, ensuring interpretability without sacrificing methodological rigor.

## Foundational Learning
- **Lexical Analysis**: Why needed - provides precise term frequency and collocation data; Quick check - verify term counts match across tools
- **Semantic Embeddings**: Why needed - captures contextual meaning beyond literal word matches; Quick check - test embedding model coherence scores
- **Topic Modeling**: Why needed - identifies latent thematic structures in discourse; Quick check - validate topic coherence and distinctiveness
- **Manual Refinement**: Why needed - ensures automated results align with researcher interpretation; Quick check - document refinement criteria and inter-rater reliability
- **Code Transparency**: Why needed - enables reproducibility and methodological validation; Quick check - verify all processing steps are documented

## Architecture Onboarding

**Component Map**: Data Preprocessing -> Embedding Model Selection -> Topic Clustering -> Manual Refinement -> Interpretation

**Critical Path**: The pipeline follows sequential processing from raw text through embedding generation, clustering, refinement, and final interpretation. Each stage builds on previous outputs.

**Design Tradeoffs**: Manual refinement improves interpretability but introduces potential subjectivity. Multiple embedding models offer flexibility but require careful selection criteria. The hybrid approach increases complexity but provides complementary insights.

**Failure Signatures**: Poor topic coherence indicates suboptimal embedding model choice. Excessive topic overlap suggests need for parameter tuning. Manual refinement difficulties may indicate unclear research questions or corpus ambiguity.

**3 First Experiments**:
1. Compare topic distributions using different embedding models (all-mpnet-base-v2 vs alternatives)
2. Test coherence scores across various clustering parameters
3. Validate lexical-semantic complementarity with sample discourse segments

## Open Questions the Paper Calls Out
None

## Limitations
- Corpus size and domain specificity may limit generalizability to other analytical contexts
- Manual topic refinement process introduces potential subjectivity without systematic documentation
- Single embedding model selection may not represent optimal configuration for all analytical scenarios

## Confidence
- **High**: Technical implementation of hybrid framework and reproducibility claims
- **Medium**: Claims about methodological complementarity between lexical and semantic approaches
- **Low**: Broader claims about researcher agency and transparency impacts without systematic assessment

## Next Checks
1. Test framework on heterogeneous corpora (different domains, languages, and sizes) to evaluate robustness
2. Conduct inter-rater reliability assessment of manual topic refinement process
3. Compare analytical outcomes across multiple embedding model selections to assess sensitivity