---
ver: rpa2
title: Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using
  Generative Artificial Intelligence
arxiv_id: '2501.19176'
source_url: https://arxiv.org/abs/2501.19176
tags:
- cesm
- images
- ffdm
- biopsy
- virtual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of performing virtual biopsy
  for breast cancer when Contrast-Enhanced Spectral Mammography (CESM) data is missing.
  The authors propose a multimodal deep learning approach that integrates Full-Field
  Digital Mammography (FFDM) and CESM modalities in craniocaudal and mediolateral
  oblique views.
---

# Augmented Intelligence for Multimodal Virtual Biopsy in Breast Cancer Using Generative Artificial Intelligence

## Quick Facts
- arXiv ID: 2501.19176
- Source URL: https://arxiv.org/abs/2501.19176
- Reference count: 40
- This paper addresses the challenge of performing virtual biopsy for breast cancer when Contrast-Enhanced Spectral Mammography (CESM) data is missing, proposing a multimodal deep learning approach that integrates Full-Field Digital Mammography (FFDM) and CESM modalities using generative AI.

## Executive Summary
This study proposes an augmented intelligence framework for breast cancer virtual biopsy that addresses the clinical challenge of missing CESM data. The authors develop a multimodal deep learning approach that combines FFDM and CESM images in both craniocaudal and mediolateral oblique views. When CESM is unavailable, they employ CycleGAN to generate synthetic CESM images from FFDM inputs. Their experiments demonstrate that incorporating CESM modality significantly enhances virtual biopsy performance compared to FFDM alone, and that synthetic CESM images prove effective particularly in multimodal configurations combining FFDM and CESM. The approach achieves AUC values ranging from 70-90% across different experimental settings, with the FFDM+CESM combination consistently outperforming FFDM-only approaches.

## Method Summary
The method involves training CycleGAN models to translate FFDM images to the CESM domain, generating synthetic CESM images when real CESM data is unavailable. For classification, independent ResNet18/50 or VGG16 models are trained on specific view-modality pairs. A late fusion strategy aggregates posterior probabilities from these models using weights based on Matthews Correlation Coefficient (MCC) values calculated from validation sets. The framework handles four input types (FFDM-CC, FFDM-MLO, CESM-CC, CESM-MLO) and generates synthetic versions when needed, with fusion occurring first across views and then across modalities.

## Key Results
- Multimodal configuration (FFDM+CESM) consistently outperformed FFDM-only approaches with AUC values ranging from 70-90% across different experimental settings
- When real CESM data is missing, synthetic CESM images generated by CycleGAN proved effective in multimodal configurations, particularly when combined with FFDM
- The framework achieved its highest performance with ResNet18 architecture and demonstrated robustness to missing modalities through the weighted fusion approach

## Why This Works (Mechanism)

### Mechanism 1
Synthetic CESM images generated by CycleGAN provide sufficient diagnostic signal to improve classification over FFDM-only baselines. The CycleGAN maps FFDM inputs to the CESM domain using adversarial loss, cycle consistency, and identity loss to simulate contrast enhancement that highlights vascular structures invisible in standard mammography. The core assumption is that the "virtual contrast" hallucinated by the generator correlates with physical contrast uptake, preserving the distinction between malignant and benign tissue features.

### Mechanism 2
Late fusion of multimodal, multi-view probabilities using MCC weights effectively handles class imbalance and integrates heterogeneous reliability scores. Rather than fusing raw image data, the architecture aggregates posterior probabilities from independent classifiers trained on specific view-modality pairs, weighted by validation-set MCC values. This gives higher influence to more reliable predictors before the final max-membership decision.

### Mechanism 3
Multimodal configurations (F+Ĉ) are robust to lower quality synthetic data because the FFDM branch provides a structural safety net that the synthetic CESM branch augments. The system averages predictions from the real FFDM branch (high structural fidelity, low contrast info) with the synthetic CESM branch (lower fidelity, high "virtual" contrast info), creating an ensemble effect that cancels out noise from the generative model.

## Foundational Learning

- **Concept: Cycle-Consistent Adversarial Networks (CycleGAN)**
  - **Why needed here:** To understand how the system translates unpaired images from domain A (FFDM) to domain B (CESM) without requiring pixel-perfect aligned training pairs, which are rare in clinical practice.
  - **Quick check question:** How does the "cycle consistency loss" prevent the generator from hallucinating a tumor that doesn't exist in the source FFDM image?

- **Concept: Late Fusion Strategy**
  - **Why needed here:** To understand why the authors chose to fuse probabilities (decisions) rather than feature maps (early fusion). This is critical for handling missing modalities gracefully.
  - **Quick check question:** Why is late fusion generally more robust to missing data than early fusion or joint training?

- **Concept: Matthews Correlation Coefficient (MCC)**
  - **Why needed here:** The paper explicitly uses MCC for weighting fusion rather than standard accuracy or F1-score. Understanding why MCC is preferred for imbalanced medical datasets is key to interpreting the results.
  - **Quick check question:** In a dataset with 75% malignant and 25% benign cases, why might Accuracy be a misleading metric for weighting a classifier's vote compared to MCC?

## Architecture Onboarding

- **Component map:** FFDM-CC, FFDM-MLO, CESM-CC, CESM-MLO → CycleGAN (if CESM missing) → Synthetic CESM-CC/MLO → Independent CNNs (ResNet18/50 or VGG16) → View Fusion (CC+MLO) per modality → Modality Fusion (FFDM+CESM) → Final Decision
- **Critical path:** Data Availability → Generation (if needed) → Inference → Fusion. The MCC-weighted fusion is the critical logic gate determining the final diagnosis.
- **Design tradeoffs:** Real CESM provides upper bound performance (AUC ~88-90%), but synthetic allows scalable screening when contrast agents are contraindicated. ResNet18/50 proved more robust to synthetic data noise than VGG16.
- **Failure signatures:** MLO View Degradation (lower PSNR/SSIM than CC), VGG16 Instability (performance collapses when using >70% synthetic data in unimodal settings).
- **First 3 experiments:**
  1. **Baseline Establishment:** Train and evaluate classifiers on Real FFDM only vs. Real CESM only to quantify the "CESM advantage."
  2. **Generative Validation:** Train CycleGAN on CC/MLO pairs. Quantify fidelity using PSNR/SSIM to ensure synthetic images are "good enough" (target: PSNR > 24dB).
  3. **Robustness Testing (The "Missing Modality" Sim):** Run the full F+C* pipeline, systematically replacing Real CESM with Synthetic CESM (0% -> 100%) to plot the performance degradation curve and verify it stays above the FFDM-only baseline.

## Open Questions the Paper Calls Out

### Open Question 1
Does integrating joint or early fusion strategies yield higher diagnostic accuracy than the weighted late fusion approach used in this study? The current study strictly utilized a late fusion approach based on a weighted average of probabilities; alternative integration points were not tested.

### Open Question 2
Can tailored preprocessing techniques or architectural modifications significantly improve the synthesis quality of CESM images in the mediolateral oblique (MLO) view? Quantitative results show the MLO view has lower PSNR (26.60 dB) and SSIM (0.8303) compared to the CC view (27.71 dB / 0.8669), attributed to "inherent challenges" in the MLO view.

### Open Question 3
Does the proposed multimodal framework maintain its efficacy when applied to larger, multi-center cohorts using architectures optimized specifically for the virtual biopsy task? The current study validated the approach on a single-center dataset using standard architectures (ResNet, VGG), leaving generalizability and architecture optimization unexplored.

### Open Question 4
Does the reduction of images to 256×256 pixels result in the loss of critical diagnostic features, such as micro-calcifications, that would affect clinical utility? The methods state images were "resized to 256 × 256, balancing computational efficiency with sufficient resolution," but they do not analyze if this specific resolution preserves the fine details necessary for detecting subtle malignancy markers.

## Limitations

- The CycleGAN's ability to faithfully translate FFDM to CESM, particularly in the MLO view where synthesis quality is reported lower, represents a primary limitation without quantitative evidence that synthetic CESM preserves the same diagnostic features as real CESM
- The 204-patient dataset represents a single institution's data, raising concerns about generalizability across different scanner manufacturers and patient populations
- The substantial performance gap between real CESM (AUC ~88-90%) and synthetic CESM (AUC ~70-85%) may limit clinical utility when real CESM is unavailable

## Confidence

- **High Confidence:** The multimodal fusion strategy using MCC-weighted late fusion is well-established and the performance improvements over FFDM-only baselines are statistically significant and reproducible
- **Medium Confidence:** The CycleGAN's ability to generate clinically useful synthetic CESM images is supported by experimental results, but lack of radiologist validation and reported MLO view degradation introduce uncertainty
- **Medium Confidence:** The claim that synthetic CESM "proves effective" when real CESM is missing is supported, but the performance gap between real and synthetic CESM is substantial

## Next Checks

1. **Cross-Institutional Validation:** Test the full pipeline (FFDM → synthetic CESM → classification) on a multi-institutional dataset to assess robustness to scanner variability and different patient demographics
2. **Radiologist Study:** Conduct a reader study where radiologists attempt to distinguish between real and synthetic CESM images, and assess whether synthetic images could mislead diagnosis
3. **Ablation on MLO Performance:** Isolate and analyze the performance difference between CC and MLO views when using synthetic CESM to identify if specific anatomical regions or lesion types are particularly vulnerable to generation artifacts