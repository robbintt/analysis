---
ver: rpa2
title: Localizing and Mitigating Memorization in Image Autoregressive Models
arxiv_id: '2509.00488'
source_url: https://arxiv.org/abs/2509.00488
tags:
- memorization
- unitmem
- data
- image
- neurons
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates where memorization occurs within image
  autoregressive (IAR) models and demonstrates that intervening on the identified
  neurons reduces data extraction with minimal impact on image quality. The study
  applies the UnitMem metric to localize memorization across different IAR architectures,
  revealing distinct patterns: V AR models show memorization shifting from early to
  deeper blocks as resolution increases, while RAR models concentrate memorization
  in middle and later blocks.'
---

# Localizing and Mitigating Memorization in Image Autoregressive Models

## Quick Facts
- **arXiv ID:** 2509.00488
- **Source URL:** https://arxiv.org/abs/2509.00488
- **Reference count:** 27
- **Primary result:** UnitMem metric identifies memorization-critical neurons in VAR and RAR models; halving weights of top memorizing neurons reduces data extraction with minimal FID increase.

## Executive Summary
This paper investigates where memorization occurs within image autoregressive (IAR) models and demonstrates that intervening on the identified neurons reduces data extraction with minimal impact on image quality. The study applies the UnitMem metric to localize memorization across different IAR architectures, revealing distinct patterns: V AR models show memorization shifting from early to deeper blocks as resolution increases, while RAR models concentrate memorization in middle and later blocks. By halving the weights of top memorizing neurons (top 10% for V AR-d30, top 5% for RAR-XXL), extractable images were significantly reduced—by 83.6% (from 672 to 110) for V AR-d30 with FID increasing from 1.97 to 2.58, and by 65.3% (from 75 to 26) for RAR-XXL with FID increasing from 1.48 to 5.12. These findings validate UnitMem as an effective tool for pinpointing memorization-critical components and demonstrate practical strategies for mitigating privacy risks in IAR models.

## Method Summary
The study uses the UnitMem metric to quantify memorization at the neuron level in pre-trained VAR (d16, d30) and RAR (Base, XXL) models. For VAR models, activations are collected per scale using teacher-forced inference with 10 forward passes per image (averaged), and UnitMem is computed per neuron. For RAR models, UnitMem is computed per neuron using last-token activations. Data extraction is performed by generating images with a prefix and measuring SSCD similarity against training data (>0.75 threshold). To mitigate memorization, the study halves the weights (not biases) of the top-k% high-UnitMem fc1 neurons: top 10% for V AR-d30, top 5% for RAR-XXL. The impact is measured by changes in extractable images and FID scores.

## Key Results
- UnitMem successfully localizes memorization: VAR-d30 shows shifting from early to deeper blocks; RAR-XXL concentrates in middle/later blocks.
- Halving top 10% V AR-d30 neurons reduces extractable images by 83.6% (672→110) with FID increasing from 1.97 to 2.58.
- Halving top 5% RAR-XXL neurons reduces extractable images by 65.3% (75→26) with FID increasing from 1.48 to 5.12.
- Different intervention thresholds (10% vs 5%) are needed due to architectural differences between VAR and RAR models.

## Why This Works (Mechanism)
The UnitMem metric effectively identifies neurons that contribute most to memorization by measuring activation variability across augmented samples. High-UnitMem neurons show inconsistent responses to small input perturbations, indicating they encode specific training examples rather than general patterns. By halving the weights of these neurons, the model's ability to reproduce exact training examples is reduced while preserving its capacity to generate plausible images. This targeted intervention exploits the observation that memorization is localized to specific components rather than distributed throughout the model.

## Foundational Learning
- **UnitMem metric**: Quantifies neuron-level memorization by measuring activation variability across augmented samples. *Why needed:* Provides granular localization of memorization beyond model-level metrics. *Quick check:* Verify that high-UnitMem neurons correspond to extracted training images.
- **Teacher-forced inference**: Generates predictions using ground-truth tokens at each step rather than model predictions. *Why needed:* Prevents error accumulation during activation collection. *Quick check:* Confirm that teacher-forcing is used during UnitMem calculation.
- **SSCD similarity**: Measures structural similarity between generated and training images for data extraction detection. *Why needed:* Provides quantitative measure of memorization. *Quick check:* Verify that SSCD > 0.75 threshold correctly identifies extracted images.
- **Data augmentation**: Perturbs input during activation collection to reveal memorization. *Why needed:* Distinguishes memorized from general features. *Quick check:* Confirm that 10 augmented passes are averaged per image.
- **Weight intervention vs pruning**: Halving weights preserves model capacity while reducing memorization. *Why needed:* Maintains generation quality while mitigating privacy risks. *Quick check:* Verify that only weights (not biases) are modified.
- **Scale-wise aggregation**: Combines UnitMem scores across different resolution scales. *Why needed:* Enables neuron selection across multi-scale architectures. *Quick check:* Confirm aggregation method (sum or mean) for VAR models.

## Architecture Onboarding

**Component Map:**
VAR: Input -> Scale 1 -> Scale 2 -> ... -> Scale 10 -> Output
RAR: Input -> Encoder -> Decoder -> Output

**Critical Path:**
VAR: Tokenization → Multi-scale autoregressive generation → Output
RAR: Tokenization → Encoder processing → Autoregressive decoding → Output

**Design Tradeoffs:**
- VAR uses explicit multi-scale processing enabling finer-grained analysis but increases complexity
- RAR's unified architecture simplifies analysis but may concentrate memorization differently
- Weight halving preserves capacity vs pruning which may degrade quality more severely

**Failure Signatures:**
- Using raw (not absolute) activations with GELU leads to incorrect UnitMem scores
- Not using teacher-forcing during UnitMem calculation propagates prediction errors
- Incorrect aggregation of scale-wise UnitMem for VAR neuron selection

**First Experiments:**
1. Implement UnitMem metric on a small VAR/RAR model using synthetic data to verify activation statistics
2. Run data extraction on original models to establish baseline extractable images and FID
3. Apply neuron intervention to a subset of neurons and measure impact on both extraction and generation quality

## Open Questions the Paper Calls Out
None

## Limitations
- Unknown training augmentations prevent exact replication of UnitMem activation collection
- Missing details on data extraction procedure (prefix length, candidate identification, tokenization)
- Unclear aggregation method for scale-wise UnitMem in VAR models

## Confidence
- UnitMem effectiveness in localizing memorization: High
- Dramatic reduction in extractable images (83.6% for VAR-d30, 65.3% for RAR-XXL): Medium
- Specific FID increases (1.97→2.58 for VAR-d30, 1.48→5.12 for RAR-XXL): Medium

## Next Checks
1. Implement the exact training augmentations used during the original UnitMem calculation and verify activation statistics match those reported.
2. Reproduce the data extraction pipeline using the referenced Kowalczuk et al. (2025) method, focusing on candidate identification and SSCD threshold application.
3. Run the neuron intervention (top-k% weight halving) on both VAR-d30 and RAR-XXL models and measure the change in extractable images and FID scores to confirm the reported reductions.