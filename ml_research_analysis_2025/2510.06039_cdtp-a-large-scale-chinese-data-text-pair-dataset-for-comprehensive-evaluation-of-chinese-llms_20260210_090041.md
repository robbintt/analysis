---
ver: rpa2
title: 'CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive Evaluation
  of Chinese LLMs'
arxiv_id: '2510.06039'
source_url: https://arxiv.org/abs/2510.06039
tags:
- tasks
- chinese
- performance
- cdtp
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Chinese Data-Text Pair (CDTP) dataset
  and a comprehensive benchmark for evaluating Chinese large language models (LLMs).
  CDTP includes over 7 million text samples paired with 15 million triples across
  four domains, addressing the scarcity of structured data for Chinese NLP.
---

# CDTP: A Large-Scale Chinese Data-Text Pair Dataset for Comprehensive Evaluation of Chinese LLMs

## Quick Facts
- **arXiv ID**: 2510.06039
- **Source URL**: https://arxiv.org/abs/2510.06039
- **Reference count**: 28
- **One-line primary result**: CDTP dataset with 7M text-triple pairs improves Chinese LLM performance across KGC, QA, and T2T tasks

## Executive Summary
This paper introduces the Chinese Data-Text Pair (CDTP) dataset and benchmark for evaluating Chinese large language models. CDTP contains over 7 million text samples paired with 15 million triples across four domains, addressing the scarcity of structured data for Chinese NLP. The benchmark evaluates models on Knowledge Graph Completion, Triple-to-Text Generation, and Question Answering tasks, revealing significant performance variations across tasks and domains. Supervised fine-tuning on CDTP consistently improves results, particularly for structured knowledge tasks, while larger models generally perform better but show reduced gaps after fine-tuning.

## Method Summary
The CDTP dataset construction involved collecting text-triple pairs from Chinese encyclopedias, followed by a rigorous cleaning pipeline to remove redundant triples and descriptions. The benchmark evaluates three tasks: Knowledge Graph Completion (KGC), Triple-to-Text Generation (T2T), and Question Answering (QA). For KGC and QA, queries are formatted as multiple-choice questions with one correct answer and nine distractors drawn from KG neighbors and type-matched entities. Supervised fine-tuning uses DeepSpeed ZeRO Stage 2 with specific hyperparameters (batch size 8, learning rate 9.65e-6, 3 epochs). Evaluation metrics include MRR, Hits@1, F1 for KGC/QA, and BLEU, ROUGE, METEOR for T2T.

## Key Results
- CDTP dataset contains 7M text-triple pairs and 15M triples across four domains (History & Politics, Humanities & Society, Technology & Economics, Nature & Environment)
- SFT on CDTP significantly improves model accuracy and generalization, with larger models benefiting more from fine-tuning
- Models show better performance on KGC tasks compared to QA tasks, suggesting structured relationships help alleviate linguistic ambiguity challenges
- Performance gains from SFT are more pronounced for smaller models, reducing the performance gap between model sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: **Supervised Fine-Tuning (SFT) on CDTP improves model performance by providing high-quality, aligned structured-unstructured data.**
- Mechanism: The CDTP dataset contains over 7 million text-triple pairs. SFT on this data explicitly trains the model to map between structured knowledge (triples) and natural language. This reduces reliance on implicit patterns learned from noisy corpora, thereby improving factual accuracy and consistency in generation and reasoning.
- Core assumption: The model can generalize the learned alignment from CDTP to unseen data, and the dataset's alignment is representative of correct semantic mappings.
- Evidence anchors:
  - [abstract] "Experiments show that supervised fine-tuning on CDTP significantly enhances model accuracy and generalization..."
  - [section 5.2, Observation 4] "...SFT models consistently outperform their base counterparts on the T2T task across all datasets."
  - [corpus] The corpus does not contain direct evidence on CDTP's SFT mechanism.
- Break condition: Performance gains vanish on OOD data, indicating overfitting to the CDTP distribution rather than learning generalizable alignment.

### Mechanism 2
- Claim: **Casting KGC and QA as multiple-choice problems with high-quality distractors isolates relational reasoning from language fluency.**
- Mechanism: For KGC and QA, queries are formatted as multiple-choice questions with one correct answer and nine distractors. These distractors are drawn from KG neighbors and entities of similar type and frequency, then filtered for semantic feasibility and ambiguity. This design forces the model to perform precise relational inference rather than surface-level text matching.
- Core assumption: Distractors are challenging enough to prevent guessing but not so similar as to make the correct answer ambiguous.
- Evidence anchors:
  - [section 4.1] "For QA and KGC, each query is cast as a multiple-choice problem with one correct answer and nine distractors... filtered for semantic feasibility..."
  - [section 5.1, Observation 2] "...all Chinese LLMs consistently outperform in KGC compared to QA tasks... the structured nature of KGC provides explicit semantic relationships that help alleviate these challenges..."
  - [corpus] Corpus evidence on this specific distractor design is weak or missing.
- Break condition: Models achieve high scores by exploiting statistical artifacts in distractor generation rather than true reasoning.

### Mechanism 3
- Claim: **A rigorous data cleaning pipeline enhances alignment quality by removing noise.**
- Mechanism: The pipeline includes data cleaning and quality enhancement stages. It targets and removes "redundant triples" (triples not grounded in text) and "redundant descriptions" (text not grounded in triples). This enforces a stricter semantic correspondence between modalities, creating a cleaner signal for SFT.
- Core assumption: Cleaning heuristics (e.g., position index, web search validation) are effective proxies for semantic alignment and do not discard valid, complex pairs.
- Evidence anchors:
  - [section 3.2] "...we specifically target two prevalent types of noise in our cleaning process: (1) redundant triples... (2) redundant descriptions..."
  - [section 3.2, Table 2 & 3] Shows examples of how triples and descriptions are filtered for lack of mutual grounding.
  - [corpus] The corpus contains a paper on Chinese summarization (CNsum), but its direct relevance to this cleaning mechanism is weak.
- Break condition: A manual review of discarded data reveals many valid pairs, indicating cleaning rules are too aggressive.

## Foundational Learning

- **Concept: Supervised Fine-Tuning (SFT)**
  - Why needed here: SFT on CDTP is the primary experimental method for improving performance.
  - Quick check question: How does updating model parameters on a labeled dataset like CDTP differ from providing examples in a prompt?

- **Concept: Knowledge Graph Triples (Entity-Relation-Entity)**
  - Why needed here: The core structured data in CDTP is triples; understanding this is fundamental to the KGC, QA, and T2T tasks.
  - Quick check question: Given the triple (Apple, CEO, Tim Cook), what are the head entity, relation, and tail entity?

- **Concept: Out-Of-Distribution (OOD) Generalization**
  - Why needed here: The paper claims SFT on CDTP improves robustness on OOD data, which is central to the RQ3 experiments.
  - Quick check question: If a model is fine-tuned on 19th-century literature and tested on social media posts, what kind of evaluation is this?

## Architecture Onboarding

- **Component map**: CDTP Dataset (7M text-triple pairs) -> Data Processing Pipeline (cleaning, quality enhancement) -> Benchmark Tasks (KGC, QA, T2T) -> Evaluation Models (8 Chinese LLMs) -> SFT Framework (e.g., DeepSpeed)

- **Critical path**: 1. Access raw data -> 2. Apply cleaning/filtering rules -> 3. Partition into train/eval sets -> 4. Format for benchmark tasks -> 5. Evaluate base models -> 6. Perform SFT -> 7. Re-evaluate on eval and OOD datasets

- **Design tradeoffs**:
    - **Scale vs. Quality**: Uses a large 7M scale with automated cleaning heuristics over exhaustive manual verification
    - **Task Scope**: Focuses deeply on three specific tasks (KGC, QA, T2T), potentially at the cost of broader coverage
    - **Distractor Complexity**: Designing challenging, semantically feasible distractors is crucial but more computationally expensive

- **Failure signatures**:
    - **Low SFT Gain**: Minimal improvement after fine-tuning. Potential cause: over-aggressive cleaning or suboptimal hyperparameters
    - **Poor OOD Performance**: Failure on datasets like YAGO3-10. Potential cause: CDTP is too narrow or contains dataset-specific biases
    - **KGC/QA Discrepancy**: High T2T performance but low KGC/QA scores. Potential cause: multiple-choice task design or distractors are too difficult for the model

- **First 3 experiments**:
  1. **Baseline Reproduction**: Evaluate all 8 base models on the 4 CDTP sub-datasets for the 3 tasks to reproduce the results in Table 4
  2. **Ablation on Cleaning Rules**: Train a model on an uncleaned version of a CDTP sub-dataset and compare performance to the cleaned version to test the pipeline's contribution
  3. **Distractor Sensitivity Analysis**: Evaluate a single model's KGC performance using different distractor generation strategies (e.g., random vs. type-matched) to assess the evaluation's robustness

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the incorporation of cross-modal signals (e.g., images, audio) alongside text and triples impact the performance and applicability of Chinese LLMs in multimodal settings?
- **Basis in paper**: [explicit] The authors state in Section 6 and Appendix E that the current dataset lacks cross-modal signals, which constrains its applicability, and they outline this as a primary direction for future work.
- **Why unresolved**: The current data collection and processing pipelines were designed exclusively for text-triple alignment and did not extract or integrate non-textual data from the source encyclopedias.
- **What evidence would resolve it**: Experiments evaluating models fine-tuned on an extended version of the CDTP dataset that includes aligned images or audio, specifically measuring performance on multimodal generation tasks.

### Open Question 2
- **Question**: To what extent can extending the dataset beyond factual triples to include metaphorical expressions and pragmatic markers improve the evaluation of deeper linguistic and cultural competencies?
- **Basis in paper**: [explicit] Section 6 and Appendix E note that the dataset focuses on factual knowledge and lacks modeling of sociolinguistic phenomena, such as metaphorical reasoning and cultural context.
- **Why unresolved**: The data cleaning process strictly filtered for alignment between text and structured triples, effectively removing or de-prioritizing nuanced language that does not map easily to structured relations.
- **What evidence would resolve it**: A comparative evaluation of models on a new benchmark subset specifically enriched with culturally embedded references and non-literal language.

### Open Question 3
- **Question**: What specific data augmentation or domain-adaptive pretraining strategies are most effective for maintaining robustness on underrepresented domains and long-tail entities?
- **Basis in paper**: [explicit] The authors highlight in Section 6 and Appendix E that the dataset's coverage is limited by source biases and that future work must address performance on long-tail entities and low-resource domains.
- **Why unresolved**: The current methodology relies on high-frequency relation filtering and encyclopedic sources, which may inherently marginalize specialized or infrequent entities.
- **What evidence would resolve it**: Ablation studies measuring performance degradation on the "tail" of the entity distribution before and after applying targeted domain-adaptive training techniques.

## Limitations

- The cleaning pipeline's impact is demonstrated but not rigorously isolated through ablation studies, making it difficult to quantify its contribution
- The generalizability of SFT improvements to truly out-of-distribution scenarios remains unclear
- The multiple-choice distractor design lacks empirical validation to confirm distractors are appropriately challenging without being misleading

## Confidence

- **High Confidence**: Claims about CDTP's dataset construction (7M text-triple pairs across 4 domains) and the existence of the benchmark framework (KGC, QA, T2T tasks)
- **Medium Confidence**: Claims about SFT's effectiveness on CDTP data are reasonably supported by Table 4 and 5, but the generalizability to other domains and the relative importance of different SFT components (like cleaning) are less certain
- **Low Confidence**: Claims about the specific design choices for distractor generation and their impact on evaluation quality are weakly supported, as the paper lacks detailed empirical validation of these design decisions

## Next Checks

1. **OOD Generalization Stress Test**: Evaluate SFT models on a truly out-of-domain dataset (e.g., general Chinese web text or a different KG like Wikidata) to measure real-world transfer. If performance drops significantly, it suggests CDTP may be too narrow in scope.

2. **Cleaning Pipeline Ablation**: Train a model on a version of CDTP without the cleaning pipeline and compare its performance to the cleaned version. This will isolate the cleaning step's contribution and reveal if it's essential or potentially over-aggressive.

3. **Distractor Design Validation**: Conduct a user study or automated analysis to assess distractor quality. For example, compute the average semantic similarity between gold answers and distractors, or test if models can distinguish them using a simpler baseline (e.g., BM25). This will validate whether the distractors are challenging enough to test reasoning rather than just matching.