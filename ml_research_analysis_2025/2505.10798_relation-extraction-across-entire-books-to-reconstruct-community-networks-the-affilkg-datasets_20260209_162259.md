---
ver: rpa2
title: 'Relation Extraction Across Entire Books to Reconstruct Community Networks:
  The AffilKG Datasets'
arxiv_id: '2505.10798'
source_url: https://arxiv.org/abs/2505.10798
tags:
- club
- social
- text
- relation
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AffilKG, the first dataset collection pairing
  complete book scans with large, labeled knowledge graphs, enabling evaluation of
  how relation extraction errors propagate to graph-level analyses. AffilKG includes
  six datasets featuring affiliation graphs (MEMBER relationships between PERSON and
  ORGANIZATION entities) derived from historical social registers, plus three expanded
  datasets with additional relation types.
---

# Relation Extraction Across Entire Books to Reconstruct Community Networks: The AffilKG Datasets

## Quick Facts
- **arXiv ID:** 2505.10798
- **Source URL:** https://arxiv.org/abs/2505.10798
- **Reference count:** 34
- **Primary result:** Introduces AffilKG, the first dataset collection pairing complete book scans with large, labeled knowledge graphs, enabling evaluation of how relation extraction errors propagate to graph-level analyses.

## Executive Summary
This paper introduces AffilKG, a dataset collection pairing complete book scans with large, labeled knowledge graphs to evaluate how relation extraction errors propagate to graph-level analyses. The datasets include six affiliation graphs derived from historical social registers, featuring MEMBER relationships between PERSON and ORGANIZATION entities. Triplets were generated via semi-automatic extraction using complex regular expressions, validated against manual ground truth. Preliminary experiments show significant variability in model performance across datasets, with edge-triplet F1 scores ranging from 54.0 to 95.9 and club-size relative mean absolute errors (RMAE) from 0.01 to 0.37. The work highlights the need for rigorous evaluation of KG extraction methods for real-world applications in social network analysis.

## Method Summary
The paper constructs bipartite affiliation networks from historical social registers using a pipeline of OCR digitization followed by relation extraction. Ground truth triplets are generated via complex, layout-specific regular expressions validated against manual samples, creating a high-precision benchmark. Large language models are then evaluated against this ground truth using both edge-level F1 scores and graph-level metrics like club-size RMAE. The approach enables measuring how local extraction errors propagate to affect global network structure.

## Key Results
- Edge-triplet F1 scores vary significantly across datasets, ranging from 54.0 to 95.9
- Club-size relative mean absolute errors (RMAE) range from 0.01 to 0.37 across datasets
- Higher edge accuracy generally correlates with lower club-size errors, though exceptions exist
- The Rhodesia dataset shows a disconnect where higher edge accuracy does not correspond to lower graph-level error

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If relation extraction (RE) models are evaluated on connected affiliation graphs rather than disjoint sentence-level triplets, the error propagation from local edges to global network structure (e.g., community size) becomes measurable and significant.
- **Mechanism:** The dataset constructs bipartite graphs (Person-Organization) from complete books. By measuring both edge-level F1 scores and graph-level metrics like Relative Mean Absolute Error (RMAE) for club sizes, the system reveals that high local accuracy does not strictly guarantee high global fidelity, although a general correlation exists.
- **Core assumption:** The "club size" metric serves as a valid proxy for broader graph-level structural integrity and downstream utility in social network analysis.
- **Evidence anchors:**
  - [abstract] "Preliminary experiments show... Higher edge accuracy generally correlates with lower club-size errors, though exceptions exist."
  - [section 3] "AFFILKG is the first ground truth resource to support both micro-level evaluation... and macro-level evaluation based on high-level graph structure."
  - [corpus] "Understanding the Effect of Knowledge Graph Extraction Error on Downstream Graph Analyses..." supports the focus on error propagation.
- **Break condition:** If downstream analyses are structurally agnostic (e.g., simple lookup tasks) or if graphs are extremely sparse, local edge accuracy may be sufficient and this propagation analysis loses utility.

### Mechanism 2
- **Claim:** If ground truth is generated via complex, layout-specific regular expressions (regex) validated against manual samples, it provides a high-precision benchmark for evaluating "noisier" but more scalable methods like LLMs.
- **Mechanism:** The authors reverse-engineered the formatting logic of historical social registers (e.g., titles indicating family roles, brackets linking clubs) into deterministic rules (up to 540 lines of code). This creates a "gold standard" of connected graphs used to score the "silver standard" output of probabilistic models.
- **Core assumption:** The structural patterns in the source texts (social registers) are consistent enough within a single book to be captured by rule-based algorithms with near-perfect accuracy (near 100% P/R noted).
- **Evidence anchors:**
  - [section 2] "Triplers were generated via semi-automatic extraction using complex regular expressions, validated against manual ground truth."
  - [section: Dataset Construction] "automated extractions achieved 100% precision and recall... with the exception of rare cases."
  - [corpus] Weak direct support; corpus papers focus on model performance rather than dataset construction mechanics.
- **Break condition:** If the document layout devolves into pure free-form prose (breaking the regex logic) or if OCR quality degrades below the threshold where structural markers (brackets, colons) are recognizable.

### Mechanism 3
- **Claim:** If LLMs are used for extraction on OCR-derived text, performance variability is driven by the interaction between OCR noise (layout loss) and the model's capacity to resolve entity references (coreference) across semi-structured entries.
- **Mechanism:** The pipeline (Scan -> OCR -> LLM -> Graph) degrades primarily when OCR fails to preserve spatial cues (like vertical lines defining households) and the LLM fails to infer context (e.g., attributing a club to the correct family member based on titles).
- **Core assumption:** The specific "semi-structured" nature of social registers (lists with implicit hierarchy) presents a specific challenge distinct from standard prose, requiring models to handle hierarchical context.
- **Evidence anchors:**
  - [section 3] "Differences between LLMs on the same OCR output range from 5 to 40 points... performance on Rhodesia struggles significantly more."
  - [appendix A.6] "LLMs sometimes omit middle initials... or expand abbreviations," necessitating flexible matching.
  - [corpus] "Are Large Language Models Effective Knowledge Graph Constructors?" frames the general capability gap.
- **Break condition:** If OCR models preserve layout tokens perfectly or if LLMs are specifically fine-tuned on the specific syntactic patterns of social registers, the variability ceiling lowers.

## Foundational Learning

- **Concept: Bipartite Affiliation Networks**
  - **Why needed here:** The entire dataset is structured as Person-Club graphs. You cannot interpret the "club-size RMAE" metric without understanding that nodes belong to two distinct sets and that edges only exist *between* sets, not within them.
  - **Quick check question:** In a bipartite graph of People and Clubs, does a "triangle" (A-B-C-A) imply that A and C are directly connected, or that they share membership in B?

- **Concept: Error Propagation in Pipelines**
  - **Why needed here:** The paper explicitly analyzes how errors in Step 1 (OCR) or Step 2 (LLM Extraction) compound to distort Step 3 (Graph Analysis). You must distinguish between a "detection error" (missing a name) and a "structural error" (misattributing a link).
  - **Quick check question:** If an OCR engine misses a line break, merging two family entries, would this likely cause a False Positive or a False Negative in the resulting graph edges?

- **Concept: Regex vs. Language Models for IE**
  - **Why needed here:** The paper uses Regex for ground truth and LLMs for testing. Understanding the trade-off—Regex is brittle but precise; LLMs are robust but hallucination-prone—is central to the experimental design.
  - **Quick check question:** Why is a rule-based approach preferred for generating the *Ground Truth* over using a high-performing LLM like GPT-4?

## Architecture Onboarding

- **Component map:** Scanned Book Images -> OCR Engine (Google Doc AI or Gemini 1.5 Pro) -> Raw text strings -> Ground-Truth Generator (Human-validated Regex rules) -> Inference Module (1-shot LLM) -> Evaluation Module (Flexible string matcher)
- **Critical path:** The **OCR-to-Text** conversion. If layout markers (indentations, brackets) are lost here, neither the Regex (Ground Truth) nor the LLM (Inference) can correctly resolve entity boundaries.
- **Design tradeoffs:**
  - **Strict vs. Flexible Matching:** The paper uses flexible matching (substrings, abbreviation expansion) to be fair to LLMs. This reduces "penalization" for semantic equivalence but introduces complexity in the evaluation script.
  - **Regex vs. Manual Labeling:** Regex was used for 5 datasets due to scale, but manual labeling was required for Denver. This trades development time (writing 540 lines of regex) against labeling time.
- **Failure signatures:**
  - **Layout Collapse:** High Edge F1 but low structural accuracy (or vice versa) often indicates the model is reading names correctly but misinterpreting the spatial hierarchy (e.g., assigning a child's club to the parent).
  - **OCR Drift:** Significant performance drops specifically in "Rhodesia" or older texts suggest the OCR model struggles with specific font types or degradation.
- **First 3 experiments:**
  1. **OCR Sensitivity Test:** Run the same LLM extraction pipeline on the same book (e.g., Denver) using both Google Doc AI and Gemini outputs. Compare Edge F1 deltas to isolate OCR impact.
  2. **Metric Correlation Check:** For a fixed dataset (e.g., Tennessee), plot Edge F1 against Club-Size RMAE across the 4 LLMs to verify if the paper's "general correlation" holds for the specific model you are testing.
  3. **Regex Robustness Check:** Take a sample page from a dataset not used in the paper (e.g., a different year social register) and apply the provided regex scripts to verify if the rules generalize or overfit to the specific books.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific characteristics of the Rhodesia dataset cause the observed disconnect where higher edge-level triplet accuracy does not correlate with lower graph-level error?
- Basis in paper: [explicit] Page 5 notes that "Higher edge accuracy corresponds to lower club-size errors in Denver and Tennessee, but not in Rhodesia, suggesting other factors at play."
- Why unresolved: The authors identified the anomaly in the results table but did not perform ablation studies to determine if the cause is OCR noise, idiosyncratic text formatting, or entity distribution.
- What evidence would resolve it: An error analysis comparing the types of false positives/negatives in Rhodesia versus the other datasets, specifically analyzing how node degree distributions distort the RMAE metric.

### Open Question 2
- Question: How do relation extraction errors propagate to complex downstream graph analyses, such as community detection or centrality measures, beyond simple club-size calculations?
- Basis in paper: [explicit] Page 5 lists as future work the need to "investigate how LLM errors impact different types of graph analyses relevant to real-world applications."
- Why unresolved: The preliminary experiments were limited to Relative Mean Absolute Error (RMAE) for the top 10 largest clubs as a proxy for structural integrity.
- What evidence would resolve it: A study correlating edge-level F1 scores with the accuracy of community partitioning (e.g., modularity) or shortest-path calculations on the extracted graphs.

### Open Question 3
- Question: To what extent do different OCR architectures impact the final graph structure compared to the choice of Large Language Model (LLM) for extraction?
- Basis in paper: [explicit] Page 5 suggests "Future research should test additional OCR models... [and] investigate how LLM errors impact... analyses."
- Why unresolved: The paper tested only two OCR models (Google Document AI and Gemini) against four LLMs, leaving the error contribution of the OCR step ambiguous, particularly for older or degraded scans.
- What evidence would resolve it: A factorial experiment varying OCR quality (e.g., Tesseract vs. commercial APIs) and LLM size independently to quantify the variance in final KG quality attributable to each pipeline component.

## Limitations
- The evaluation assumes club-size RMAE is a valid proxy for broader graph-level structural integrity, but this relationship may not hold for all downstream applications
- The regex-based ground truth, while precise for specific books, may not generalize to other social register formats without significant adaptation
- The comparison of LLM extraction quality across datasets is limited by using different OCR engines without controlling for this variable

## Confidence
- **High confidence**: The core claim that relation extraction errors propagate to graph-level analyses is well-supported by the correlation data (edge F1 vs. club-size RMAE)
- **Medium confidence**: The dataset construction methodology (regex rules validated on manual samples) is sound, but the brittleness of these rules across different social register formats remains uncertain
- **Medium confidence**: The specific performance numbers (F1 scores ranging from 54.0 to 95.9) are dataset-specific and may not generalize to other document types or OCR qualities

## Next Checks
1. **Cross-dataset regex generalization**: Apply the provided regex scripts to a social register from a different year or region than those in AffilKG to test their brittleness
2. **OCR engine isolation**: Run the same LLM extraction pipeline on identical book content using both Google Document AI and Gemini outputs to quantify OCR's contribution to performance variance
3. **RMAE validity test**: Construct synthetic graphs with controlled edge errors and measure whether club-size RMAE accurately predicts degradation in other graph metrics (e.g., clustering coefficient, betweenness centrality)