---
ver: rpa2
title: 'CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented
  Generation for Edge-Based LLMs'
arxiv_id: '2601.20041'
source_url: https://arxiv.org/abs/2601.20041
tags:
- tonel
- noise
- llms
- edge
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces TONEL, a framework for enhancing Retrieval-Augmented
  Generation (RAG) in edge-based large language models by addressing two challenges:
  environmental noise in computing-in-memory (CiM) architectures and domain adaptability
  without manual labeling. TONEL uses a noise-aware task-oriented optimization strategy
  (NATO) to train a projection model that generates task-specific, noise-resilient
  embeddings compatible with CiM hardware constraints, and a pseudo-label generation
  mechanism (PGM) to enable label-free task adaptation through unsupervised clustering.'
---

# CiMRAG: CiM-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs

## Quick Facts
- arXiv ID: 2601.20041
- Source URL: https://arxiv.org/abs/2601.20041
- Reference count: 0
- Primary result: TONEL framework improves edge-based RAG retrieval accuracy by up to 37.4% under 100% noise while enabling domain adaptation without manual labeling

## Executive Summary
This paper introduces TONEL, a framework for enhancing Retrieval-Augmented Generation (RAG) in edge-based large language models by addressing two challenges: environmental noise in computing-in-memory (CiM) architectures and domain adaptability without manual labeling. TONEL uses a noise-aware task-oriented optimization strategy (NATO) to train a projection model that generates task-specific, noise-resilient embeddings compatible with CiM hardware constraints, and a pseudo-label generation mechanism (PGM) to enable label-free task adaptation through unsupervised clustering. Experimental results on personalization benchmarks (Movie and Rating datasets) demonstrate that TONEL significantly outperforms strong baselines (PCA and RoCR) in terms of MIPS top-1 accuracy, precision@5, and nDCG@5 under various noise levels and CiM devices.

## Method Summary
TONEL employs a noise-aware projection model trained with NATO to generate task-specific, CiM-compatible embeddings. The method consists of three main components: (1) PGM creates pseudo-labels by clustering pretrained document embeddings via K-means, (2) NATO trains a projection model (384→64 dims) with CiMCE loss under hardware-calibrated noise injection, and (3) quantized embeddings enable direct CiM storage for MIPS retrieval. The framework operates without manual labeling by using unsupervised clustering for task supervision, and incorporates simulated INT8 quantization during training to ensure hardware compatibility.

## Key Results
- Under 100% noise on Movie dataset, TONEL (w/ PL) achieves 37.4% relative improvement over RoCR in top-1 accuracy
- Downstream evaluations with Gemma-2B and Llama-3.2-3B show TONEL improves classification accuracy by up to 20.3% and F1 score by up to 22.4% compared to RoCR
- TONEL maintains strong performance across four different CiM devices with varying noise characteristics (σv from 0.0038-0.0151)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting hardware-calibrated noise during projection model training produces embeddings that maintain MIPS ranking fidelity under CiM device variations
- Mechanism: During training, Gaussian noise (η ~ N(0, σv)) measured from real CiM devices is added to quantized embeddings before task prediction. The CiM-aware Cross-Entropy loss (LCiMCE) optimizes model parameters to preserve discriminative boundaries despite perturbations, effectively learning noise-resilient representations through exposure
- Core assumption: Noise distributions observed in training devices generalize to deployment devices with similar NVM technologies
- Evidence anchors:
  - [abstract] "TONEL employs a noise-aware projection model to learn task-specific embeddings compatible with CiM hardware constraints, enabling accurate retrieval under noisy conditions"
  - [section 3.1] "η ~ N(0, σv) refers to the CiM variation noise, modeled as Gaussian with zero mean and a standard deviation σv specific to each value"
  - [corpus] Weak direct support; neighboring papers (DGRAG, HyFedRAG) address edge RAG but not CiM-specific noise resilience
- Break condition: If deployment device exhibits noise distributions (e.g., non-Gaussian, drift patterns) substantially different from training calibration data, resilience gains may degrade

### Mechanism 2
- Claim: Task-oriented supervision through pseudo-labels improves retrieval precision by learning embeddings that cluster semantically similar documents within task-relevant subspaces
- Mechanism: The PGM module applies K-means clustering on pretrained encoder outputs to assign each document to one of K latent task groups. These pseudo-labels (ŷi) serve as supervision for NATO training, guiding the projection model to produce embeddings where task-relevant documents share similar representations, improving MIPS ranking for domain-specific queries
- Core assumption: Cluster structure from pretrained embeddings correlates with task-relevant semantic groupings for target domains
- Evidence anchors:
  - [abstract] "pseudo-label generation mechanism (PGM) to enable label-free task adaptation through unsupervised clustering"
  - [section 3.2] "PGM assigns each document to one of the predefined K groups by clustering their embeddings from the pretrained encoder Enc(.) using an unsupervised clustering algorithm (e.g., the K-means algorithm)"
  - [corpus] Mnemosyne addresses edge-based memory but uses different retrieval structures; no direct validation of clustering-based pseudo-labels for CiM-RAG
- Break condition: If user profile documents span heterogeneous domains where cluster boundaries do not align with task distinctions, pseudo-labels may introduce conflicting supervision signals

### Mechanism 3
- Claim: Dimensionality reduction with hardware-constrained quantization (64-dim, INT8) preserves sufficient MIPS discriminability while enabling direct storage in fixed-size CiM crossbar arrays
- Mechanism: The projection model maps 384-dim FP32 embeddings to 64-dim vectors, then applies simulated INT8 quantization via round-to-nearest with clamping. This produces CiM-friendly vectors matching crossbar array dimensions, eliminating the need for post-hoc compression that could introduce additional noise sensitivity
- Core assumption: Task-relevant information is compressible to 64 dimensions without catastrophic semantic loss for target personalization tasks
- Evidence anchors:
  - [section 3.1] "Since the document embeddings would be stored in a CiM architecture that is implemented as a 'crossbar array' with typically fixed dimensions (e.g., 64×64) and bit precision (e.g., 8-bit integers), we employ a projection model Proj(.) to map them to 64 dimensions"
  - [table 2] TONEL (w/ PL) achieves 0.3883 vs. RoCR's 0.3295 on Movie dataset at 100% noise, demonstrating maintained discriminability
  - [corpus] No corpus papers validate the 64-dim/INT8 constraint specifically for personalization RAG tasks
- Break condition: If downstream tasks require fine-grained semantic distinctions not capturable in 64-dim quantized space, retrieval precision ceiling may be limited regardless of noise resilience

## Foundational Learning

- Concept: Maximum Inner Product Search (MIPS)
  - Why needed here: TONEL optimizes embeddings specifically for MIPS-based retrieval; understanding that similarity is computed via matrix-vector multiplication (s = DT v(Q)) is essential for grasping why noise corrupts stored embeddings directly impacts ranking
  - Quick check question: Can you explain why noise in stored document embeddings D affects MIPS scores but not the query embedding v(Q) at inference time?

- Concept: Computing-in-Memory (CiM) Architecture
  - Why needed here: The entire framework is designed around CiM constraints (crossbar arrays, NVM susceptibility to environmental noise); understanding in-situ computation clarifies the noise injection motivation
  - Quick check question: Why does performing matrix-vector multiplication directly in memory eliminate data movement bottlenecks but introduce noise vulnerability?

- Concept: Quantization-Aware Training
  - Why needed here: TONEL uses simulated INT8 quantization during training (fake quantization); understanding the clamp-and-round operation explains how embeddings are prepared for hardware deployment
  - Quick check question: What information is potentially lost when converting FP32 embeddings to INT8, and how does training with this constraint mitigate that loss?

## Architecture Onboarding

- Component map:
  - Pretrained Encoder (Enc) -> Projection Model (Proj) -> Task Predictor (Pred) -> CiM Array
  - PGM Module: K-means clustering on Enc outputs -> pseudo-labels
  - NATO: CiMCE loss + noise injection -> updated projection weights

- Critical path:
  1. Profile documents → Pretrained encoder → 384-dim embeddings
  2. PGM: K-means clustering → pseudo-labels ŷi
  3. Projection model + quantization + noise injection → task prediction
  4. CiMCE loss backprop → updated projection weights
  5. Inference: queries and documents → projection model → CiM-stored embeddings → MIPS retrieval

- Design tradeoffs:
  - K (cluster count) selection: Higher K captures finer task distinctions but risks over-fragmenting semantic space; paper uses C=15 (Movie) and C=5 (Rating) matching dataset class counts
  - Quantization precision: INT8 enables direct CiM storage but limits dynamic range; projection model training compensates
  - Noise injection level: Must match deployment device characteristics (Table 1 shows σv ranges from 0.0038-0.0151 across devices)

- Failure signatures:
  - MIPS Acc@1 drops sharply for specific domains: Indicates PGM cluster assignments misalign with that domain's task structure
  - Performance degrades on newer CiM devices not in calibration set: Noise distribution mismatch between training and deployment
  - Quantized embeddings cluster uniformly: Projection model collapsed; check learning rate and noise injection magnitude

- First 3 experiments:
  1. **Baseline calibration**: Run TONEL (w/ PL) on Movie dataset with Device-2 noise at 50%/100% noisy documents; verify Acc@1 matches reported ~0.41/0.39 before proceeding to custom datasets
  2. **Ablation on cluster count K**: Train with K=5, 10, 15, 20 on Rating dataset; measure if pseudo-label quality (cluster purity proxy) correlates with downstream F1 to validate PGM effectiveness assumption
  3. **Noise distribution sensitivity**: Train with Device-1 noise (σv=0.010), test on Device-4 noise profile (σv=0.0038-0.0151); quantify robustness gap when training/deployment noise distributions differ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can TONEL be extended to efficiently adapt to rapidly growing and dynamic user profiles without requiring the computationally expensive re-clustering or re-training currently implied by the PGM and NATO modules?
- Basis in paper: [explicit] The conclusion states that future directions include "extending TONEL to better adapt to dynamic user profiles by developing efficient clustering algorithms"
- Why unresolved: The current PGM module relies on K-means clustering over the dataset, which is typically a batch process. The paper does not propose an incremental update mechanism for the projection model or the pseudo-labels as new user data arrives in real-time
- What evidence would resolve it: An extension of TONEL demonstrating an online or incremental learning capability that maintains retrieval accuracy while strictly bounding memory and computation usage as profile size increases

### Open Question 2
- Question: What specific hardware-software co-design strategies are required to deploy the PGM clustering mechanism directly onto resource-constrained CiM edge devices?
- Basis in paper: [explicit] The conclusion highlights the need for "developing efficient clustering algorithms co-designed with specialized hardware architectures, tailored for real-world edge-based LLM applications"
- Why unresolved: While the paper simulates the noise characteristics of CiM devices for the retrieval step (MIPS), the PGM module (clustering for pseudo-labels) is presented as a software optimization step without detailing its execution on the target edge hardware
- What evidence would resolve it: Hardware synthesis or simulation results demonstrating the energy efficiency and latency of running the clustering algorithm on CiM crossbars or a dedicated edge accelerator

### Open Question 3
- Question: Can the performance gap between the unsupervised TONEL (w/ PL) and the supervised upper-bound TONEL (w/ TL) be narrowed by improving the granularity or accuracy of the pseudo-label generation?
- Basis in paper: [inferred] Tables 2 and 3 show a substantial gap between w/ PL (pseudo-labels) and w/ TL (true labels); for instance, on the Movie dataset, w/ TL achieves 0.7034 Acc@1 while w/ PL achieves 0.3883 under 100% noise
- Why unresolved: The study attributes the success of w/ PL to "latent task labels" but does not analyze if the K-means clustering accurately captures the semantic ground truth or if the gap is intrinsic to the noise-resilience loss function
- What evidence would resolve it: A component analysis correlating the purity of the generated clusters (pseudo-labels) with the final retrieval accuracy, or experiments using semi-supervised clustering to isolate the impact of label quality

## Limitations
- Limited CiM device diversity in noise calibration (only 4 devices tested)
- Unclear generalizability of 64-dim constraint to other task types
- Pseudo-label dependency on cluster-task alignment not guaranteed

## Confidence
- Core noise-resilience claims: Medium - significant empirical gains shown but limited device diversity
- PGM effectiveness: Medium - clustering works for benchmark datasets but may not generalize to heterogeneous domains
- Hardware compatibility: Medium - simulated quantization tested but real CiM deployment validation needed

## Next Checks
1. Test TONEL's noise resilience on CiM devices with substantially different noise profiles (e.g., different NVM technologies) to validate generalization assumptions
2. Evaluate retrieval performance with varying embedding dimensions (32, 64, 128) to quantify the tradeoff between hardware constraints and semantic capacity
3. Apply TONEL to multi-domain document collections where cluster boundaries may not align with task distinctions to stress-test PGM assumptions