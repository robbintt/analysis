---
ver: rpa2
title: 'MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity
  Prediction'
arxiv_id: '2507.04893'
source_url: https://arxiv.org/abs/2507.04893
tags:
- agent
- marble
- reasoning
- prediction
- severity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MARBLE addresses accident severity prediction under severe class
  imbalance and incomplete data using a multi-agent system of specialized Small Language
  Models (SLMs) that focus on distinct semantic feature subsets. A central coordinator
  integrates agent predictions via rule-based or LLM-guided logic.
---

# MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction

## Quick Facts
- arXiv ID: 2507.04893
- Source URL: https://arxiv.org/abs/2507.04893
- Reference count: 40
- Primary result: MARBLE achieves ~90% accuracy on accident severity prediction under severe class imbalance, outperforming traditional ML classifiers and advanced prompt-based methods

## Executive Summary
MARBLE addresses the challenge of accident severity prediction under severe class imbalance and incomplete data by deploying a multi-agent system of specialized Small Language Models (SLMs). Each agent focuses on distinct semantic feature subsets (environmental, temporal, location, spatial) while a central coordinator integrates predictions using rule-based or LLM-guided logic. The system demonstrates nearly 90% accuracy versus under 48% for baseline methods, enabled by modular reasoning, lightweight SLM agents, and structured coordination that provides robustness, interpretability, and computational efficiency.

## Method Summary
MARBLE employs a multi-agent architecture where 1 ML agent (Random Forest/GB on full feature space) and 4 SLM agents (Smollm2-1.7B, LLaMA 3.2 1B/3B, Mistral 1.3B) operate on semantically partitioned feature subsets. Each SLM agent receives a focused context via projection functions and generates structured outputs (prediction, confidence, reasoning). The Rule-Based Coordinator aggregates agent outputs using weighted voting with class importance factors (βₖ=1.2 for rare classes) and can override with high-confidence ML predictions. The system is trained on US and UK traffic accident datasets with severe class imbalance (500 samples/class).

## Key Results
- MARBLE achieves ~89% accuracy across datasets, significantly outperforming traditional ML classifiers (under 48%) and advanced prompt-based methods
- Rule-based coordination consistently outperforms LLM-based coordination by up to 23.7 percentage points under imbalanced conditions
- Ablation studies show high sensitivity to agent removal, particularly environmental and ML agents, with accuracy dropping 30-50% when critical agents are removed

## Why This Works (Mechanism)

### Mechanism 1
Semantic feature decomposition reduces reasoning complexity for SLMs on tabular data. Each agent receives only a semantically coherent feature subset (e.g., environmental → weather, visibility; temporal → time-of-day, day-of-week) via projection function πₐ. This constrains the reasoning space, reducing prompt saturation and token consumption while preserving domain-relevant signal. Core assumption: The feature-to-domain mapping correctly reflects how severity-relevant patterns cluster; misaligned partitions would degrade performance.

### Mechanism 2
Rule-based coordination with class-weighted voting stabilizes predictions under severe imbalance. Weighted voting incorporates agent importance weights (w), confidence scores (cₐ), and class importance factors (βₖ=1.2 for rare classes {1,4}). This amplifies signals for underrepresented classes while preventing majority-class dominance. Override logic prioritizes high-confidence ML predictions when thresholds are met. Core assumption: Agent confidences are at least partially calibrated and informative; class importance factors correctly compensate for imbalance.

### Mechanism 3
Hybrid ML+SLM architecture provides complementary signal channels—one statistical, one semantic. The ML agent (a_ML) operates on the full feature space using traditional classification, providing a baseline that captures statistical patterns. SLM agents contribute semantic reasoning traces. Final decision logic can override coordination with high-confidence ML predictions, creating redundancy. Core assumption: ML agent generalizes reasonably despite limited training data (500 samples/class); SLM agents provide orthogonal signal rather than correlated errors.

## Foundational Learning

- **Concept: Multi-Agent System (MAS) decomposition**
  - Why needed: MARBLE's core innovation is decomposing a 4-class classification problem across 5+ specialized agents. Understanding how task decomposition, agent roles, and coordination interact is prerequisite to modifying or extending the architecture.
  - Quick check: Can you explain why a single SLM processing all features would likely fail on this task, and which specific failure mode decomposition addresses?

- **Concept: Class imbalance handling in classification**
  - Why needed: The target datasets have severe imbalance (rare fatal/severe vs. common minor accidents). MARBLE's β-weights, confidence thresholds (τ_coord^rare=0.4 vs. τ_coord^common=0.5), and rare-class boost logic all encode imbalance-aware design choices.
  - Quick check: If you removed the class importance factors (set all βₖ=1.0), what systematic error pattern would you expect to emerge?

- **Concept: LLM/SLM prompting for structured output**
  - Why needed: SLM agents must generate parseable outputs (prediction, confidence, reasoning). Prompt engineering and output extraction are critical infrastructure. Understanding CoT/L2M strategies informs why they're used at agent vs. coordination levels differently.
  - Quick check: What output format should an SLM agent produce to be machine-parseable, and what failure modes occur if the format drifts?

## Architecture Onboarding

- **Component map:**
  Input Feature Vector (x) → Projection Functions (πₐ) → Feature Subsets per Agent → Agent Pool (A) → Coordinator (Φ_RB or Φ_LLM) → Final Decision Logic (F_final) → Output: (Ŷ, C_final)

- **Critical path:** Feature projection → parallel agent inference → confidence-weighted voting → ML override check → final selection. The coordination logic (Eqs. 17-21, 25) is where most failure modes manifest.

- **Design tradeoffs:**
  - Rule-based vs. LLM coordination: RBC is deterministic, faster, and more stable under imbalance; LBC is more expressive but brittle (up to 23.7pp accuracy loss)
  - SLM size vs. latency: 1B-3B parameter models chosen for real-time feasibility; larger models may improve reasoning quality but violate deployment constraints
  - Agent granularity: More agents = finer decomposition but higher coordination complexity; current 5-agent design balances coverage with manageability

- **Failure signatures:**
  - Agent timeout (8s guardrail): returns default low confidence, coordination proceeds with partial signal
  - Output parse failure: extraction function Eₐ fails → agent contribution dropped
  - Confidence miscalibration: all agents overconfident on wrong class → weighted voting amplifies error
  - Context misunderstanding: SLM misinterprets feature semantics, produces plausible but incorrect reasoning

- **First 3 experiments:**
  1. Baseline replication: Run MARBLE with Smollm2-1.7B on the UK/US datasets, verify ~89% accuracy and coordination output distribution matches Table I/II
  2. Ablation study: Systematically remove each agent and measure accuracy drop; confirm environmental agent removal causes largest decline (Figure 2)
  3. Coordination stress test: Evaluate RBC vs. LBC under the six simulated imbalance scenarios (Figure 5), verifying RBC maintains >87% accuracy while LBC degrades under "Rare Fatal" condition

## Open Questions the Paper Calls Out

- **Open Question 1:** How do decentralized or hierarchical multi-agent topologies compare to MARBLE's centralized architecture in terms of robustness and performance? Basis: The authors state exploration of alternative multi-agent system topologies presents opportunities for future research. Why unresolved: Current study is restricted to centralized coordination. Evidence would resolve it: Empirical comparison of decentralized or hierarchical agent setups against the centralized baseline on the same accident severity datasets.

- **Open Question 2:** Can adaptive coordination mechanisms effectively mitigate the instability of LLM-based coordination observed under severe class imbalance? Basis: The Conclusion suggests future work may explore adaptive coordination mechanisms, following the result that LLM-based coordination degrades significantly (to 60% accuracy) under extreme skew. Why unresolved: The paper tested static coordination strategies but did not implement mechanisms that dynamically switch strategies based on confidence or data distribution. Evidence would resolve it: Designing and testing a dynamic coordinator that selects its aggregation logic based on input confidence profiles or detected class rarity.

- **Open Question 3:** What is the precise latency trade-off of MARBLE's multi-agent pipeline compared to monolithic models when deployed in real-time safety systems? Basis: The Limitations section notes that the multi-agent inference pipeline naturally incurs greater computational latency, which may be relevant for applications with stringent real-time constraints. Why unresolved: The study focused primarily on accuracy and class imbalance robustness rather than optimizing for or rigorously benchmarking inference speed. Evidence would resolve it: A comprehensive latency benchmark comparing MARBLE against single-pass models under identical hardware constraints.

## Limitations
- Prompt and calibration details for SLM agents are not fully specified, introducing potential variability in reproduction
- ML agent training specificity (exact sampling method and preprocessing steps) could affect baseline performance and hybrid signal quality
- Correlation and error analysis between agents is lacking, limiting understanding of failure modes and coordination robustness

## Confidence
- **High Confidence:** MARBLE's superior accuracy (~90%) over traditional ML classifiers and advanced prompt-based methods under severe class imbalance
- **Medium Confidence:** Mechanism by which semantic feature decomposition reduces reasoning complexity is logically sound but lacks direct empirical validation
- **Medium Confidence:** Rule-based coordinator's stability advantage over LLM-based coordination under imbalance is demonstrated but doesn't explore edge cases

## Next Checks
1. Reproduce baseline accuracy: Implement MARBLE with Smollm2-1.7B on the UK/US datasets, verifying the ~89% accuracy and coordination output distribution matches reported values
2. Test coordination robustness: Systematically vary class importance factors (βₖ) and confidence thresholds (τ_coord) to quantify their impact on rare-class recall and overall stability
3. Analyze agent error correlations: Conduct a correlation analysis of agent predictions to identify systematic error patterns and test whether ML override logic mitigates these failures