---
ver: rpa2
title: 'LoGoFair: Post-Processing for Local and Global Fairness in Federated Learning'
arxiv_id: '2503.17231'
source_url: https://arxiv.org/abs/2503.17231
tags:
- fairness
- local
- global
- logofair
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving both local and
  global fairness in federated learning, where existing methods often focus on one
  aspect while neglecting the other. The authors propose LoGoFair, a post-processing
  framework that learns the Bayes optimal classifier under local and global fairness
  constraints to strike an optimal accuracy-fairness balance.
---

# LoGoFair: Post-Processing for Local and Global Fairness in Federated Learning

## Quick Facts
- arXiv ID: 2503.17231
- Source URL: https://arxiv.org/abs/2503.17231
- Authors: Li Zhang; Chaochao Chen; Zhongxuan Han; Qiyong Zhong; Xiaolin Zheng
- Reference count: 40
- Key outcome: LoGoFair achieves superior local and global fairness with competitive accuracy in federated learning through a post-processing framework.

## Executive Summary
LoGoFair addresses the challenge of achieving both local and global fairness in federated learning, where existing methods often focus on one aspect while neglecting the other. The authors propose a post-processing framework that learns the Bayes optimal classifier under local and global fairness constraints to strike an optimal accuracy-fairness balance. The method employs a federated post-processing procedure that enables clients to collaboratively optimize global fairness while ensuring local fairness in a model-agnostic manner.

Experiments on three real-world datasets demonstrate that LoGoFair outperforms existing methods in achieving superior local and global fairness with competitive accuracy, while also providing flexibility in adjusting the accuracy-fairness trade-off. The approach effectively addresses the challenges of statistical heterogeneity and model-agnostic settings in federated learning fairness.

## Method Summary
LoGoFair is a two-phase approach that first pre-trains a probabilistic classifier using FedAvg, then applies federated post-processing to optimize fairness constraints. The method solves a bi-level optimization problem that minimizes misclassification risk under local and global fairness constraints (DP and EO). The post-processing phase employs a federated optimization procedure where clients locally update their parameters and share gradient information with the server to learn a global guidance parameter. The framework uses a smoothed objective function to ensure differentiability and stable convergence.

## Key Results
- Outperforms existing methods on three real-world datasets in achieving both local and global fairness
- Maintains competitive accuracy while optimizing fairness metrics
- Demonstrates flexibility in adjusting accuracy-fairness trade-off through constraint parameters
- Effectively handles statistical heterogeneity across clients through Dirichlet partitioning

## Why This Works (Mechanism)
The framework works by decoupling fairness optimization from model training, allowing clients to maintain local fairness while contributing to global fairness through collaborative post-processing. The bi-level optimization structure enables simultaneous optimization of local client parameters and global guidance parameters, ensuring that both local and global fairness constraints are satisfied.

## Foundational Learning
- **Federated Learning Basics**: Understanding distributed model training across clients - needed for grasping the communication protocol and parameter aggregation.
- **Fairness Constraints (DP/EO)**: Demographic Parity and Equal Opportunity definitions - essential for understanding the optimization objectives.
- **Bi-level Optimization**: Hierarchical optimization problems - critical for understanding the two-phase approach and parameter updates.
- **Probability Calibration**: Techniques to ensure predicted probabilities reflect true likelihoods - important for post-processing calibration.
- **Dirichlet Distribution**: Parameter controlling data heterogeneity - key for understanding how clients receive different data distributions.

## Architecture Onboarding
**Component Map**: Pre-trained classifier -> Local calibration -> Federated post-processing -> Fairness-constrained predictions

**Critical Path**: Data partitioning → FedAvg training → Probability calibration → Bi-level optimization → Evaluation

**Design Tradeoffs**: Post-processing vs. in-training fairness optimization (flexibility vs. computational overhead), local vs. global constraint satisfaction (individual client performance vs. system-wide fairness)

**Failure Signatures**: Divergence in bi-level optimization (check learning rates and smoothing parameter), constraint violations (adjust δ values), poor accuracy-fairness balance (tune constraint weights)

**First Experiments**: 1) Verify baseline FedAvg performance on homogeneous data, 2) Test local calibration effectiveness on single client, 3) Validate federated post-processing convergence on simple synthetic data

## Open Questions the Paper Calls Out
None

## Limitations
- Missing precise hyperparameter values for learning rates, communication rounds, and smoothing parameters
- Ambiguity in model-agnostic calibration procedure and exact architecture specifications
- Potential convergence issues with bi-level optimization requiring careful hyperparameter tuning

## Confidence
- **High confidence**: Overall post-processing framework and federated optimization procedure
- **Medium confidence**: Experimental setup reproducibility with uncertain hyperparameter values
- **Medium confidence**: Theoretical formulation sound but practical implementation details require assumptions

## Next Checks
1. Systematically vary learning rates γ_g, γ_l, smoothing β, and constraint thresholds δ_l, δ_g to identify stable configurations
2. Test different probability calibration approaches (temperature scaling vs. Platt scaling) and compare their impact
3. Implement and validate all baseline methods (FedAvg, FairFed, FedFB, FCFL) on the same experimental setup