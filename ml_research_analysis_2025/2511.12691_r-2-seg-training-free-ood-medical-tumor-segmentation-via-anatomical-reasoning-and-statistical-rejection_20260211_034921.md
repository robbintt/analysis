---
ver: rpa2
title: 'R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning
  and Statistical Rejection'
arxiv_id: '2511.12691'
source_url: https://arxiv.org/abs/2511.12691
tags:
- tumor
- dice
- segmentation
- r2-seg
- statistical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'R2-Seg is a training-free framework for robust out-of-distribution
  (OOD) tumor segmentation that addresses the problem of high false positive rates
  in foundation models. It operates via a two-stage Reason-and-Reject process: first,
  an LLM-guided anatomical reasoning planner localizes organ anchors and generates
  multi-scale ROIs to improve the separability of vision embeddings; second, a statistical
  rejection filter using two-sample MMD testing with Benjamini-Hochberg FDR control
  screens candidates against normal tissue to suppress false positives.'
---

# R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection

## Quick Facts
- arXiv ID: 2511.12691
- Source URL: https://arxiv.org/abs/2511.12691
- Reference count: 40
- Primary result: R2-Seg is a training-free framework for robust out-of-distribution (OOD) tumor segmentation that substantially improves Dice, specificity, and sensitivity over both the original BiomedParse model and strong baselines like LoRA fine-tuning.

## Executive Summary
R2-Seg addresses the high false positive rates in foundation models for out-of-distribution tumor segmentation by implementing a two-stage Reason-and-Reject process. The framework uses LLM-guided anatomical reasoning to localize organ anchors and generate multi-scale ROIs, improving vision embedding separability, followed by statistical rejection filtering using two-sample MMD testing with Benjamini-Hochberg FDR control to screen candidates against normal tissue. The method requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center, multi-modal OOD benchmarks, R2-Seg substantially improves segmentation metrics over both the original BiomedParse model and strong baselines.

## Method Summary
R2-Seg is a training-free framework that operates via a two-stage Reason-and-Reject pipeline for out-of-distribution tumor segmentation. First, an LLM planner localizes anchor organs and generates multi-scale ROIs to improve vision embedding separability, constraining the frozen BiomedParse segmentor to these localized crops rather than the full image. Second, a statistical rejection filter uses two-sample MMD testing with Benjamini-Hochberg FDR control to screen tumor candidates against normal tissue features, suppressing false positives. The method maintains strong performance on in-distribution organ segmentation tasks while substantially improving Dice, specificity, and sensitivity on OOD tumor benchmarks.

## Key Results
- R2-Seg substantially improves Dice, specificity, and sensitivity over both the original BiomedParse model and strong baselines like LoRA fine-tuning on multi-center, multi-modal OOD benchmarks
- The framework maintains strong performance on in-distribution organ segmentation tasks while addressing the problem of high false positive rates in foundation models
- R2-Seg is training-free, avoiding catastrophic forgetting and remaining compatible with zero-update test-time augmentation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Constraining segmentation to anatomically-informed ROIs improves vision embedding separability, reducing OOD false positives caused by distribution shift.
- Mechanism: An LLM planner (Φ) translates tumor type → anchor organs (A) → geometric ROI rules (padding δ, scale jitter Γ, squaring) → the frozen segmentor is prompted only within these localized crops rather than the full image.
- Core assumption: Anchor organs remain reliably segmentable under OOD conditions; tumors occur in predictable spatial relationships to normal anatomy.
- Evidence anchors: [abstract] "LLM-guided anatomical reasoning planner localizes organ anchors and generates multi-scale ROIs to improve the separability of vision embeddings"; [section 3.1, Fig. 1] Illustrates that OOD shifts make vision embeddings inseparable, biasing decision boundaries toward false positives; [corpus] "Anatomy-Informed Deep Learning" supports anatomy-aware approaches; direct corpus evidence for LLM-based anatomical planning is weak.
- Break condition: Anchor organ segmentation fails or produces incorrect bounding boxes; tumor location falls outside all planned ROIs.

### Mechanism 2
- Claim: Two-sample MMD testing provides a principled, training-free criterion for rejecting candidates statistically similar to normal tissue.
- Mechanism: For each candidate C_k, extract features ϕ(·) → compute unbiased MMD² between {ϕ(I|C_k)} and {ϕ(I|M_∪)} using Gaussian kernel with median-heuristic bandwidth → permutation test (B shuffles) for p-value → Benjamini–Hochberg FDR control at level α retains only significant candidates.
- Core assumption: Normal tissue and tumor tissue yield statistically distinguishable feature distributions; sufficient samples exist for reliable testing.
- Evidence anchors: [abstract] "statistical rejection filter using two-sample MMD testing with Benjamini-Hochberg FDR control screens candidates against normal tissue"; [section 3.2.3, Eq. 4] Formal MMD² definition and permutation p-value estimation with smoothing (count+1)/(B+1); [section 4.5.1, Table 3] Removing statistical test substantially increases false activations, dropping specificity; [corpus] Limited corpus support for MMD-based filtering; related work uses uncertainty or post-processing heuristics.
- Break condition: Feature distributions of normal and abnormal tissue overlap significantly; insufficient pixels for stable statistical estimates.

### Mechanism 3
- Claim: Hierarchical three-level gating adaptively suppresses low-confidence predictions when tumors are absent.
- Mechanism: L1 existence gate (p_max, positive ratio ρ, KS test p_KS) → L2 candidate gate (area ≥ A_min, mean prob ≥ τ_mean, organ overlap ≥ τ_∩) → L3 case-level score (S_k = P_k/√|C_k| vs τ_case).
- Core assumption: Text-prompted segmentors rarely output empty masks; empty-mask cases can dominate test sets, inflating false positives.
- Evidence anchors: [section 3.2.4] Formal three-level gating policy definition; [section 4.4.2] On tumor-free slices, R²-Seg "produces near-empty masks" while baselines generate dense spurious activations; [section 4.5.2, Table 3] Disabling FPG causes "significant increase in background activations and marked drop in specificity"; [corpus] "Multi-head automated segmentation" addresses hallucinations with gated architectures—similar problem, different approach.
- Break condition: Thresholds (τ_max, τ_ρ, τ_area, τ_mean, τ_∩, τ_case) poorly calibrated; small true lesions rejected.

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD)
  - Why needed here: Core nonparametric test for comparing candidate vs normal tissue feature distributions without distributional assumptions.
  - Quick check question: Given sample sets X and Y, explain why MMD² tests H₀: P_X = P_Y and how the Gaussian kernel enables detecting any distributional difference.

- Concept: False Discovery Rate (FDR) Control (Benjamini–Hochberg)
  - Why needed here: Corrects for multiple hypothesis testing across |K| tumor candidates; guarantees E[FDR] ≤ α under independence/positive dependence.
  - Quick check question: Walk through BH procedure: sort p-values, find i* = max{i: p_(i) ≤ α·i/|K|}, retain candidates 1...i*. Why is this less conservative than Bonferroni?

- Concept: Test-Time Augmentation (TTA) with Max-Fusion
  - Why needed here: Aggregates predictions across geometric transforms (identity, LR flip, TB flip) before statistical screening.
  - Quick check question: Why does max-fusion P_final = max(P_full, max_γ P^(γ)) preserve high-confidence detections better than mean-fusion? What monotonicity property does this yield?

## Architecture Onboarding

- Component map: LLM Planner (Φ) → Prompt Normalizer (Π) → Anchor Segmentor → ROI Constructor → Tumor Segmentor → Candidate Extractor → Statistical Filter → Gating Module
- Critical path: LLM planning → anchor segmentation (must succeed for meaningful ROIs) → ROI construction → tumor segmentation (within ROIs only) → candidate extraction → per-candidate MMD testing → FDR correction → hierarchical gating → final mask
- Design tradeoffs:
  - Training-free: avoids catastrophic forgetting (Figure 5), but cannot learn domain-specific corrections
  - Statistical filtering: principled FDR control, but acknowledged sensitivity/specificity tradeoff (Section 6: "risks rejecting true positives")
  - Multi-scale ROIs: covers varying tumor sizes, increases compute O(|K|·B·(m+n)²)
  - Max-fusion: preserves high-confidence activations, may retain isolated noise peaks
- Failure signatures:
  - 100% sensitivity, ~0% specificity: anchor segmentation likely failed → B_0 = full image
  - Empty masks on true lesions: τ_case or τ_bin too aggressive; verify feature extractor ϕ
  - High Dice variance across organs: check LLM planner outputs appropriate anchors per tumor type
  - Slow inference: check |K| and B; defaults are B permutations with 4k sample cap per region
- First 3 experiments:
  1. Reproduce baseline failure mode: Run BiomedParse zero-shot on one OOD tumor type (bladder MR); expect ~100% sensitivity, ~0% specificity (Table 2) confirming over-prediction.
  2. Ablate statistical testing: Run R²-Seg with MMD step disabled; compare specificity to "R²-Seg wo ST" in Table 3 to quantify filtering contribution.
  3. Test anchor sensitivity: Manually set anchor mask to full image; verify output degrades toward baseline behavior, confirming anatomical reasoning is necessary.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework be modified to simultaneously improve both sensitivity and specificity, rather than trading one for the other?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that while R2-Seg suppresses false positives, "it risks rejecting true positives and missing early radiological biomarkers," adding that "Achieving simultaneous improvement in both sensitivity and specificity remains an open and critical challenge."
- Why unresolved: The current statistical rejection filter (MMD test) is conservative; lowering the bar to catch subtle tumors inevitably re-introduces the false positives the framework was designed to reject.
- What evidence would resolve it: A method that adaptively adjusts rejection thresholds based on lesion size or contrast-to-noise ratio, validated by improved F1-scores on early-stage tumor datasets.

### Open Question 2
- Question: How robust is the anatomical reasoning stage when the foundational model fails to segment the required "anchor organs" due to severe OOD shifts or surgical absence?
- Basis in paper: [inferred] Section 3.2.1 states that the ROI construction relies on anchor masks (M_a) and notes, "When anchors are unreliable or missing, a conservative fallback sets B_0 to the full image frame."
- Why unresolved: If the model falls back to the full image frame, it negates the core "Reason" stage's benefit of enhancing embedding separability, potentially returning performance to the baseline failure mode.
- What evidence would resolve it: Evaluation results on datasets featuring post-surgical anatomies (e.g., nephrectomy) or severe imaging artifacts where anchor organs are absent or unrecognizable.

### Open Question 3
- Question: How does the presence of benign pathologies (e.g., cysts or inflammation) within the "normal tissue" anchor region affect the statistical rejection filter's accuracy?
- Basis in paper: [inferred] Section 3.2.3 assumes the anchor mask M_∪ represents normal tissue to compute the MMD against tumor candidates. It does not account for the anchor organ itself containing heterogeneous non-tumor anomalies.
- Why unresolved: If the control distribution Y (features from M_∪) is contaminated by anomalies, the MMD test may lose statistical power, failing to distinguish actual tumors from the "normal" background.
- What evidence would resolve it: Ablation studies on datasets with high prevalence of benign lesions in anchor organs (e.g., liver cysts when segmenting liver tumors) to measure the change in Type II error rates.

## Limitations
- The method depends critically on accurate anchor organ segmentation, which may fail under severe OOD shifts not encountered during BiomedParse training
- The MMD-based statistical test assumes sufficient pixel samples and distributional separability between normal and tumor tissue, which may not hold for subtle or diffuse tumors
- The framework acknowledges a sensitivity/specificity tradeoff that requires careful threshold tuning per clinical context

## Confidence
- High confidence: The two-stage Reason-and-Reject architecture is sound, and the reported performance improvements over BiomedParse are substantial and well-documented
- Medium confidence: The training-free nature is valid, but generalization depends on LLM planner quality and threshold calibration
- Medium confidence: Statistical filtering via MMD+BH-FDR is principled, but the method acknowledges a sensitivity/specificity tradeoff that requires careful threshold tuning per clinical context

## Next Checks
1. **Anchor sensitivity analysis:** Systematically vary the anchor organ segmentation mask from full image to ground truth to quantify the contribution of anatomical reasoning to performance
2. **Statistical test calibration:** Perform receiver operating characteristic analysis on the MMD test alone to determine optimal FDR thresholds across tumor types and imaging modalities
3. **Cross-modal generalization:** Evaluate R²-Seg on CT-to-MR or MR-to-CT transfer without any domain-specific tuning to test the training-free robustness claim