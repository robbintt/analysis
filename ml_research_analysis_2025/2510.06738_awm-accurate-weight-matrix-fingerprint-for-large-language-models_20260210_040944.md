---
ver: rpa2
title: 'AWM: Accurate Weight-Matrix Fingerprint for Large Language Models'
arxiv_id: '2510.06738'
source_url: https://arxiv.org/abs/2510.06738
tags:
- language
- arxiv
- large
- matrices
- manipulations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting whether a suspect
  LLM is trained from scratch or derived from an existing base model, even after extensive
  post-training modifications like fine-tuning, continued pretraining, reinforcement
  learning, pruning, and multi-modal adaptation. The authors propose AWM, a training-free
  fingerprinting method based on weight matrices that leverages the Linear Assignment
  Problem (LAP) and unbiased Centered Kernel Alignment (CKA) similarity to neutralize
  the effects of parameter manipulations.
---

# AWM: Accurate Weight-Matrix Fingerprint for Large Language Models

## Quick Facts
- **arXiv ID:** 2510.06738
- **Source URL:** https://arxiv.org/abs/2510.06738
- **Reference count:** 40
- **Primary result:** Training-free method detects LLM lineage with perfect classification scores (AUC, pAUC, TPR@1%FPR = 1.0) against 60 positive and 90 negative model pairs, completing in <30s on a 3090 GPU.

## Executive Summary
This paper introduces AWM, a novel method for detecting whether a suspect large language model (LLM) was derived from a known base model, even after extensive post-training modifications. The method leverages the Linear Assignment Problem (LAP) to neutralize permutation and sign-flip attacks on embeddings, combined with Unbiased Centered Kernel Alignment (UCKA) to provide a similarity metric invariant to orthogonal transformations and scaling. AWM achieves perfect classification performance across all metrics on a comprehensive testbed, demonstrating exceptional robustness against fine-tuning, continued pretraining, reinforcement learning, pruning, and multi-modal adaptation.

## Method Summary
AWM is a training-free fingerprinting method that compares weight matrices between a source and suspect LLM. It operates in two stages: first, it extracts a permutation (P) and signature (D) matrix from the intersection of shared vocabulary embeddings using the Hungarian algorithm to solve a Linear Assignment Problem (LAP). Second, it computes Unbiased Centered Kernel Alignment (UCKA) similarity between the transformed source Query/Key matrices and the suspect's Q/K matrices, averaging scores across all layers. This approach neutralizes parameter manipulations while providing a robust similarity metric invariant to orthogonal transformations and scaling.

## Key Results
- Achieves perfect classification scores (AUC, pAUC, TPR@1%FPR = 1.0) on 60 positive and 90 negative model pairs
- Demonstrates exceptional robustness against fine-tuning, continued pretraining, RLHF, pruning, and multi-modal adaptation
- Maintains near-zero false positive rate (<0.5%) while detecting all derived models
- Completes within 30 seconds on a single NVIDIA 3090 GPU
- Outperforms existing methods (GEMINI, Patchen, SeedCR) that fail under various post-training modifications

## Why This Works (Mechanism)

### Mechanism 1: Linear Assignment Problem (LAP) Recovery
The LAP stage extracts permutation (P) and signature (D) matrices from shared word embeddings to neutralize permutation and sign-flip manipulations. The algorithm computes absolute cosine similarity between embedding columns, then uses the Hungarian algorithm to find the permutation maximizing total similarity. The signs of matched cosine similarities reconstruct the signature matrix. This works when models share sufficient vocabulary overlap (≥100 tokens) and manipulations are limited to permutation/sign-flipping combinations.

### Mechanism 2: Unbiased Centered Kernel Alignment (UCKA) for Invariance
UCKA provides a similarity metric between Q/K matrices that is invariant to orthogonal transformations and constant scaling. As an unbiased estimator of HSIC using linear kernels, Theorem 3.1 proves CKA yields identical values for inputs related by orthogonal transformations and scaling. This allows comparison of Q/K matrices without explicitly solving for complex orthogonal transformations allowed by RoPE, handling transformations formalized in Definition 4.1 and Theorem 4.4.

### Mechanism 3: Transformer Architecture Constraints on Manipulations
The architecture of decoder-only Transformers constrains admissible parameter manipulations through residual connections, RMSNorm, and RoPE. Residual connections require manipulations to commute through components (Proposition 4.2), RMSNorm restricts inputs to scaling, permutation, and sign-flipping (Theorem 4.3), and RoPE constrains Q/K manipulations to these plus RoPE-compatible orthogonal matrices (Theorem 4.4). This formalizes the search space for adversarial attacks, allowing AWM to cover all plausible manipulations.

## Foundational Learning

**Concept: Linear Assignment Problem (LAP) and Hungarian Algorithm**
- **Why needed here:** Core of AWM pipeline for aligning embedding dimensions between models to undo permutation/sign-flip attacks
- **Quick check question:** Given a 5x5 matrix of cosine similarities between two sets of 5 embedding vectors, can you manually trace the Hungarian algorithm steps to find the optimal assignment maximizing total similarity?

**Concept: Centered Kernel Alignment (CKA) and HSIC**
- **Why needed here:** Similarity metric used to compare Q/K matrices, invariant to orthogonal transforms and scaling
- **Quick check question:** Explain why standard cosine similarity between flattened weight vectors is not suitable if weights have been rotated by an arbitrary orthogonal matrix. How does CKA solve this?

**Concept: Transformer Components (Residual Connections, RMSNorm, RoPE)**
- **Why needed here:** Theoretical justification for AWM rests on how these components constrain adversarial manipulations
- **Quick check question:** How does a residual connection force a parameter manipulation to propagate unchanged through a Transformer block? Why does RMSNorm restrict the types of manipulations allowed on its input?

## Architecture Onboarding

**Component map:** embedding_loader -> vocab_intersector -> lap_solver -> cka_computer -> similarity_aggregator

**Critical path:** The entire pipeline is critical and strictly sequential. Failure in vocab_intersector (no shared tokens) breaks lap_solver. Failure in lap_solver prevents alignment. Failure in cka_computer yields meaningless scores.

**Design tradeoffs:**
- **Vocabulary Overlap vs. Robustness:** Using all shared tokens provides more robustness but slower LAP; using a subset is faster but potentially less robust (ablations show ~100 tokens sufficient)
- **Kernel Choice (Linear vs. RBF):** Linear kernel is faster; RBF may capture non-linear similarities but adds a hyperparameter
- **Biased vs. Unbiased CKA:** Unbiased is crucial for robustness but more complex to implement

**Failure signatures:**
- **High false positive:** Similarity >50% for independent models indicates CKA threshold too low or Z-score calculation flawed
- **High false negative:** Near-zero similarity for derived models suggests insufficient vocabulary overlap or post-training modifications outside modeled space
- **Computation timeout:** Hungarian algorithm on very large vocabulary intersection may be slow

**First 3 experiments:**
1. Reproduce LAP on Embeddings: Load Llama2-7B and Vicuna-7B, extract embeddings, find intersection, solve LAP, verify recovered P and D make embeddings nearly identical
2. Sanity Check CKA Invariance: Create random matrix M, M' = M @ Random_Orthogonal_Matrix, compute UCKA(M,M) (should be 1.0), UCKA(M,M') (should be near 1.0), UCKA(M,Random_Matrix) (should be near 0)
3. End-to-End Lineage Test: Run full AWM pipeline on Llama2-7B->Vicuna-7B and Llama2-7B->CodeLlama-7b (positive pairs) and Llama2-7B vs Mistral-7B and Llama2-7B vs Qwen-7B (negative pairs), compare scores with paper's Table 1 and 2

## Open Questions the Paper Calls Out

### Open Question 1
Can AWM verify lineage for models created via weight merging (e.g., linear interpolation) rather than sequential derivation? The paper evaluates sequential modifications but excludes "merging," where a model may inherit lineage from multiple distinct parents simultaneously. Merged weights might result in high similarity scores for multiple base models, creating ambiguity that binary "base/offspring" classification cannot resolve. Testing AWM on merged models would determine if it identifies multiple parents or fails to reach detection threshold.

### Open Question 2
Is AWM robust against adversarial perturbations optimized to minimize the UCKA similarity score while preserving utility? While theoretically robust to rotations, an attacker could theoretically add small noise vectors to specifically disrupt the CKA alignment without destroying model performance. Simulating an adversarial attack where weights are perturbed to reduce the AWM score subject to a perplexity constraint would test this vulnerability.

### Open Question 3
How does AWM perform when suspect models use disjoint tokenizers or adversarially shuffled vocabularies? Algorithm 1 depends on the intersection Vocab(A) ∩ Vocab(B) to solve the Linear Assignment Problem; ablations tested small overlap but not empty/disjoint scenarios. Without sufficient shared tokens, the method cannot extract permutation P and signature D from embeddings, causing the alignment pipeline to fail. Evaluating AWM on models with completely new tokenizers would test this limitation.

## Limitations
- **Vocabulary dependence:** Method requires sufficient shared vocabulary overlap; highly specialized models with disjoint vocabularies may be undetectable
- **Semi-orthogonal transformation vulnerability:** While robust to orthogonal transformations, aggressive pruning may create semi-orthogonal transformations outside theoretical guarantees
- **Behavioral assumption:** Method assumes adversarial manipulations preserve model behavior (commute through residual connections), which may not hold for more aggressive attacks

## Confidence

- **High Confidence:** LAP mechanism for extracting permutation/signature matrices from shared embeddings and effectiveness in neutralizing permutation/sign-flip attacks (empirical results and theoretical justification are sound)
- **Medium Confidence:** UCKA invariance claims for Q/K matrices with RoPE encodings (Theorem 3.1 provides proof for general case, but specific application involves additional complexity)
- **Medium Confidence:** Exceptional robustness against all tested post-training manipulations (extensive testbed is impressive, but space of possible manipulations is vast and some techniques may push transformations outside guaranteed space)

## Next Checks

1. **Adversarial Stress Test:** Design and implement an attack applying general orthogonal transformation (not just permutation + sign-flip) to embedding layer, evaluate whether AWM correctly identifies lineage despite this manipulation

2. **Extreme Pruning Scenario:** Test AWM on model pair with aggressive structured pruning (50%+ parameter reduction), measure degradation in similarity scores, assess effectiveness when transformations become semi-orthogonal

3. **Vocabulary Overlap Sensitivity Analysis:** Systematically vary shared vocabulary intersection size (100, 500, 1000, 5000 tokens) between known parent-child pair, measure impact on LAP recovery accuracy and final similarity scores, determine practical minimum vocabulary overlap required