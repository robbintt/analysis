---
ver: rpa2
title: 'ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems'
arxiv_id: '2512.06721'
source_url: https://arxiv.org/abs/2512.06721
tags:
- proactive
- proagent
- user
- assistance
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ProAgent, the first end-to-end proactive
  agent system that leverages massive sensory contexts and LLM reasoning to deliver
  proactive assistance. The system addresses the limitations of reactive LLM agents
  by continuously sensing the environment and deriving hierarchical contexts from
  multi-modal sensor data (vision, audio, motion, location) combined with persona
  cues.
---

# ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems

## Quick Facts
- **arXiv ID**: 2512.06721
- **Source URL**: https://arxiv.org/abs/2512.06721
- **Reference count**: 40
- **Primary result**: Up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and 1.79x lower memory usage over state-of-the-art baselines

## Executive Summary
ProAgent is the first end-to-end proactive agent system that leverages massive sensory contexts and LLM reasoning to deliver proactive assistance. The system addresses limitations of reactive LLM agents by continuously sensing the environment and deriving hierarchical contexts from multi-modal sensor data (vision, audio, motion, location) combined with persona cues. Implemented on AR glasses with an edge server, ProAgent achieves significant improvements in proactive prediction accuracy and tool-calling performance while reducing memory usage. A user study demonstrates a 38.9% improvement in user satisfaction across five dimensions of proactive services.

## Method Summary
ProAgent introduces an on-demand tiered perception strategy that efficiently captures high-cost vision data only when low-cost sensor signals indicate a likely need for service. The system employs a context-aware proactive reasoner with context-aware Chain-of-Thought (CoT) distillation to map sensory contexts to user needs and tool calls. The architecture combines AR glasses for data capture with an edge server for processing, using a custom CAB-Lite dataset for training. The approach includes persona retrieval based on visual context and temporal constraints to prevent repetitive notifications.

## Key Results
- 33.4% higher proactive prediction accuracy compared to state-of-the-art baselines
- 16.8% higher tool-calling F1 score in predictive accuracy
- 1.79x lower memory usage during inference
- 38.9% improvement in user satisfaction across five dimensions in user studies

## Why This Works (Mechanism)

### Mechanism 1: On-Demand Tiered Perception
The system reduces energy and compute overhead by triggering high-cost vision sensors only when low-cost signals indicate a likely need for service. A "dual-mode" strategy uses always-on IMU (motion), GPS (location), and Audio (VAD) as a gating mechanism, switching visual sampling rate from low baseline (e.g., 60s) to high rate (e.g., 5s) during dynamic or high-value interactions.

### Mechanism 2: Context-Aware Chain-of-Thought (CoT) Distillation
Proactive reasoning accuracy improves when the model is fine-tuned to generate explicit situational descriptions ("thoughts") before outputting tool calls. This forces the VLM to ground its tool selection in a semantic interpretation of the visual context rather than directly mapping image pixels to tool APIs.

### Mechanism 3: Context-Aware Persona Retrieval
Injecting relevant user personas into the prompt improves prediction accuracy, but retrieving them based on visual context prevents context window saturation and confusion. A coarse-grained object detection model identifies objects in the scene to classify the scenario, retrieving only the subset of user personas tagged with that scenario.

## Foundational Learning

- **Concept: Vision-Language Models (VLMs) & LoRA**
  - Why needed here: The core "Proactive Reasoner" is a VLM (Qwen2.5-VL or InternVL). Understanding how text and image embeddings align and how LoRA adapts these massive models for specific tasks without full retraining is critical.
  - Quick check question: Can you explain why LoRA is preferred over full fine-tuning for deploying on edge servers like Jetson Orin?

- **Concept: Prompt Engineering vs. Fine-Tuning**
  - Why needed here: The paper compares "In-Context Learning" (ICL) baselines against its fine-tuned "CoT Distillation." You need to understand the trade-off: ICL is zero-shot/easy but heavy, while fine-tuning is upfront cost but lighter/faster at inference.
  - Quick check question: Why might a two-stage pipeline (VLM caption -> LLM reason) introduce more latency than a single-stage VLM reasoner?

- **Concept: Semantic Similarity (BERTScore/Cosine Similarity)**
  - Why needed here: The system uses semantic similarity to enforce "Temporal Constraints" (preventing repetitive notifications) and to match scene objects to the scenario bank.
  - Quick check question: How does using semantic similarity differ from simple string matching when filtering similar proactive outputs over time?

## Architecture Onboarding

- **Component map:** AR Glasses (Camera, Mic, IMU) -> On-Device Perception (YOLO, VAD, Geocoding) -> Persona DB -> Edge Server (VLM Reasoner with LoRA) -> User Display
- **Critical path:** Sensor Trigger (Motion/POI) -> High-Rate Camera Capture -> Coarse Object Detection -> Scenario Classification -> Persona Retrieval -> VLM Inference (Image + Persona) -> Tool Call -> User Display
- **Design tradeoffs:** High frame rates (5s interval) capture more context but saturate VLM inference queue; system defaults to 60s to save power. Training on "Thoughts" improves specific tool use but might reduce model's ability to handle scenarios outside CAB-Lite dataset distribution.
- **Failure signatures:** "Ghost" Proactivity (high proactive score but generic tool call), Stale Context (user moves quickly but adaptive sampling misses transition), Repetition Loop (temporal constraint fails on semantically similar but textually distinct outputs).
- **First 3 experiments:** 1) Tiered Perception Ablation: disable "Agent Reflection" tool and rely solely on sensor-based adaptive sampling. 2) Persona Injection Test: compare performance with no personas, random personas, and retrieved personas. 3) Latency Profiling: measure end-to-end latency on Jetson Orin with different VLM backbones.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation conducted primarily on custom CAB-Lite dataset with simulated user behaviors, which may not fully capture real-world complexity
- System's reliance on AR glasses and edge computing infrastructure may limit immediate reproducibility for researchers without access to similar hardware
- User study details (sample size, demographic diversity, duration) are not fully elaborated, making generalizability difficult to assess

## Confidence
- **High Confidence** in architectural innovations (on-demand tiered perception, context-aware CoT distillation, persona retrieval mechanisms)
- **Medium Confidence** in real-world applicability (translation to diverse real-world scenarios introduces uncertainty)
- **Low Confidence** in long-term user acceptance (proactive systems face unique challenges around user trust over time)

## Next Checks
1. **Real-world deployment study**: Deploy ProAgent with 50+ diverse users over 4+ weeks in varied environments and measure sustained accuracy, user satisfaction, and battery impact.
2. **Cross-dataset generalization test**: Evaluate ProAgent's performance on established multimodal reasoning benchmarks (VQA-CP, GQA) and other agent datasets (ToolFormer, Voyager).
3. **Edge computing scalability analysis**: Profile memory and compute usage across different VLM scales (3B, 7B, 13B parameters) on resource-constrained devices to identify practical limits.