---
ver: rpa2
title: 'DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced
  LLMs'
arxiv_id: '2507.21653'
source_url: https://arxiv.org/abs/2507.21653
tags:
- fraud
- detection
- graph
- node
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of graph-based fraud detection
  using graph-enhanced large language models (LLMs). The core problem is that text-only
  prompting for heterogeneous fraud-detection graphs leads to information overload
  due to exponentially expanding multi-hop neighborhoods with dense textual information,
  which overwhelms the model and suppresses key signals from the target node.
---

# DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs

## Quick Facts
- **arXiv ID:** 2507.21653
- **Source URL:** https://arxiv.org/abs/2507.21653
- **Reference count:** 5
- **Primary result:** Graph-Enhanced LLM method that improves fraud detection AUPRC by up to 6.8% through dual-granularity prompting

## Executive Summary
This paper introduces Dual Granularity Prompting (DGP), a framework that addresses information overload in graph-based fraud detection using Large Language Models. The core insight is that text-only prompting for heterogeneous fraud-detection graphs leads to exponential expansion of multi-hop neighborhoods with dense textual information, overwhelming the model and suppressing key signals from target nodes. DGP preserves fine-grained textual details for the target node while summarizing neighbor information into coarse-grained text prompts using tailored strategies for different data modalities.

Experiments on public YelpReviews and AmazonVideo datasets, plus industrial data, demonstrate that DGP achieves superior fraud detection performance while operating within manageable token budgets. The method improves AUPRC by up to 6.8% over state-of-the-art approaches, striking an impressive balance between token usage and detection accuracy.

## Method Summary
DGP addresses the challenge of graph-based fraud detection by employing a dual-granularity approach to prompt construction. The method uses bi-level semantic abstraction to condense raw node text into fine-grained summaries for the target node, while employing Markov Diffusion Kernel (MDK) to select top-M neighbors and summarize their content into coarse-grained metapath summaries. Numerical features are aggregated through mean pooling. The final prompts combine target text summaries, metapath summaries, and numerical statistics. The approach is evaluated using Qwen3-8B fine-tuned with LoRA, achieving improved fraud detection performance while maintaining efficient token usage.

## Key Results
- Achieves up to 6.8% improvement in AUPRC over state-of-the-art methods
- Maintains manageable token budgets while improving performance
- Demonstrates effectiveness across both public datasets (YelpReviews, AmazonVideo) and industrial data
- Shows that task-agnostic summarization prompts outperform task-aware prompts

## Why This Works (Mechanism)
The effectiveness stems from addressing information overload in graph-based fraud detection. When using LLMs for fraud detection on heterogeneous graphs, multi-hop neighborhoods expand exponentially, creating dense textual information that overwhelms the model. By preserving fine-grained details for the target node while summarizing neighbor information into coarse-grained prompts, DGP enables the LLM to focus on relevant signals without being distracted by verbose neighborhood content. The tailored summarization strategies for different data modalities (bi-level abstraction for text, statistical aggregation for numerical features) ensure effective compression of information into concise, informative prompts that fit within token budget constraints.

## Foundational Learning

**Heterogeneous Graph Construction** - Building graphs with multiple relation types (R-U-R, R-S-R, R-T-R) from tabular data
*Why needed:* Fraud detection requires modeling complex relationships between users, reviews, and other entities
*Quick check:* Verify graph contains expected edge types and node degrees match domain knowledge

**Markov Diffusion Kernel (MDK)** - Algorithm for selecting most relevant neighbors based on graph diffusion properties
*Why needed:* Efficiently identifying which neighbors contain most relevant fraud signals
*Quick check:* Confirm selected neighbors have higher fraud concentration than random sampling

**Bi-level Text Summarization** - Two-tier approach: fine-grained summary for target node, coarse-grained for neighbors
*Why needed:* Balances detail preservation with token budget constraints
*Quick check:* Measure information loss between original and summarized text using semantic similarity metrics

**LoRA Fine-tuning** - Low-Rank Adaptation technique for efficient LLM adaptation
*Why needed:* Enables effective model customization without full fine-tuning costs
*Quick check:* Verify rank parameters (4-32) produce stable convergence across runs

## Architecture Onboarding

**Component Map:** Data → Graph Construction → MDK Selection → Summarization → Prompt Assembly → LoRA Fine-tuning → Classification

**Critical Path:** The bottleneck lies in the summarization stage where token budgets must be carefully managed. The MDK neighbor selection directly impacts both performance (relevant neighbors) and efficiency (fewer tokens needed).

**Design Tradeoffs:** The paper balances between fine-grained detail preservation (better accuracy) and coarse-grained summarization (token efficiency). The optimal point varies by dataset density and fraud signal distribution.

**Failure Signatures:** Token budget overflow occurs when M or K values are too large relative to B. Performance collapse happens when task-aware prompts are used instead of generic ones, likely due to reduced generalization.

**First Experiments:** 1) Vary B_node from 5-25 tokens to find optimal trade-off point. 2) Compare MDK vs. random neighbor selection on detection accuracy. 3) Test different LoRA rank values (4, 8, 16, 32) for convergence stability.

## Open Questions the Paper Calls Out

**Dynamic Graphs Extension** - How to adapt DGP for fraud patterns that evolve over time in dynamic graphs
*Basis:* Explicitly stated in conclusion as future work
*Why unresolved:* Current framework assumes static graphs; temporal evolution requires new strategies for when to re-summarize and how to incorporate temporal signals

**Cross-domain Summarization Effectiveness** - Whether task-agnostic summarization superiority holds across diverse domains and languages
*Basis:* Inferred from Yelp/Amazon results showing task-aware prompts hurt performance
*Why unresolved:* Only two datasets tested; counterintuitive result lacks theoretical explanation

**LLM Backbone Scaling** - How performance scales with different model sizes and architectures
*Basis:* Inferred from exclusive use of Qwen3-8B without exploring other sizes
*Why unresolved:* Smaller models may struggle with semantics; larger models might tolerate longer prompts, changing optimal granularity trade-offs

## Limitations

**Neighbor Selection Specification** - The exact MDK implementation details are not fully specified, including whether diffusion is uniform across metapath types or weighted by edge attributes

**Summarization Model Ambiguity** - Unclear whether the same Qwen3-8B model is used for both summarization and final fine-tuning, or if a different frozen LLM handles initial summarization

**Token Budget Methodology** - The systematic method for determining optimal token budgets across different datasets and graph densities is not detailed

## Confidence

- **High Confidence:** The dual-granularity prompting architecture and its general effectiveness in addressing information overload
- **Medium Confidence:** Specific performance improvements (6.8% AUPRC gains) and task-agnostic vs. task-aware summarization results
- **Low Confidence:** Precise computational efficiency claims due to lack of detailed runtime/memory comparisons

## Next Checks

1. Reproduce the bi-level summarization pipeline using a specified frozen LLM (clarify whether Qwen3-8B or GPT-4) to generate both target node summaries and metapath neighbor summaries, verifying MDK produces consistent top-M results

2. Validate token budget sensitivity by systematically varying B_node and B_meta parameters (e.g., [5, 10, 15, 20, 25] tokens) on YelpReviews subset to confirm reported optimal ranges

3. Test task-aware vs. task-agnostic summarization impact by implementing both prompt styles and measuring actual performance difference on AmazonVideo to verify reported degradation from task-specific prompts