---
ver: rpa2
title: Comparison of neural network training strategies for the simulation of dynamical
  systems
arxiv_id: '2512.03851'
source_url: https://arxiv.org/abs/2512.03851
tags:
- training
- neural
- system
- network
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study compares two training strategies for neural networks
  in dynamical system simulation: parallel training, which uses model predictions
  as inputs during training, and series-parallel training, which uses measured outputs.
  The empirical analysis spans five network architectures across two real-world datasets:
  a pneumatic valve test bench and an industrial robot benchmark.'
---

# Comparison of neural network training strategies for the simulation of dynamical systems

## Quick Facts
- arXiv ID: 2512.03851
- Source URL: https://arxiv.org/abs/2512.03851
- Reference count: 35
- Parallel training consistently achieves superior long-term prediction accuracy across architectures and datasets

## Executive Summary
This study compares two training strategies for neural networks in dynamical system simulation: parallel training, which uses model predictions as inputs during training, and series-parallel training, which uses measured outputs. The empirical analysis spans five network architectures across two real-world datasets: a pneumatic valve test bench and an industrial robot benchmark. Across all architectures and datasets, parallel training consistently achieves superior long-term prediction accuracy, with NRMSE values below the baseline linear model for the industrial robot dataset and significantly lower errors for the pneumatic valve system.

## Method Summary
The paper conducts a comprehensive empirical comparison of training strategies for neural network-based dynamical system simulation. The authors evaluate parallel training against series-parallel training across five architectures (MLP, CNN, LSTM, GRU, RNN) using two industrial datasets. Training performance is assessed through NRMSE metrics, with parallel training showing consistent advantages in long-term prediction accuracy by reducing distributional shift between training and inference phases.

## Key Results
- Parallel training consistently outperforms series-parallel across all architectures and datasets
- Best parallel-trained RNN achieves NRMSE of 0.22 versus 0.64 for series-parallel on pneumatic valve system
- Parallel-trained GRU achieves NRMSE of 0.67 versus 1.76 for series-parallel on industrial robot benchmark

## Why This Works (Mechanism)
Parallel training reduces distributional shift between training and inference by exposing the model to its own predictions during training. This creates a more consistent input distribution, enabling better generalization to long-term predictions where the model must rely on its own outputs rather than measured data.

## Foundational Learning
- **Neural network architectures (MLP, CNN, LSTM, GRU, RNN)**: Different architectures handle temporal dependencies differently, making comparative analysis essential
- **Series-parallel vs parallel training**: Series-parallel uses measured outputs during training, while parallel uses predictions, affecting generalization
- **NRMSE metric**: Normalized Root Mean Square Error provides standardized performance comparison across datasets
- **Distributional shift**: The difference between training input distributions and inference input distributions affects model performance
- **Dynamical system simulation**: Models must predict future states based on current and past measurements

## Architecture Onboarding

**Component Map**
Data -> Preprocessing -> Neural Network -> Training Strategy (Series-Parallel/Parallel) -> Prediction

**Critical Path**
Model architecture selection → Training strategy implementation → NRMSE evaluation → Comparative analysis

**Design Tradeoffs**
- Parallel training improves long-term accuracy but may reduce short-term precision
- Series-parallel training converges faster but suffers from domain shift at inference
- Architecture choice affects both training stability and prediction performance

**Failure Signatures**
- High NRMSE values indicate poor model fit
- Inconsistent performance across architectures suggests dataset-specific challenges
- Divergence between training and validation performance indicates overfitting

**First Experiments**
1. Compare NRMSE between series-parallel and parallel training for a single architecture
2. Evaluate baseline linear model performance for reference
3. Test model performance on both datasets to identify architecture-dataset interactions

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to only two real-world datasets, constraining generalizability
- Testing restricted to specific neural network families (MLP, CNN, LSTM, GRU, RNN)
- No evaluation of computational cost differences between training strategies

## Confidence
- **High**: Core claim that parallel training reduces distributional shift and improves long-term prediction accuracy
- **Medium**: Recommendation of parallel training as default strategy
- **Low**: Extrapolation to novel architectures or substantially different dynamical systems

## Next Checks
1. Test additional dynamical systems with varying timescales and nonlinearities to assess robustness
2. Evaluate training stability and convergence properties across different batch sizes and learning rates
3. Benchmark against state-of-the-art hybrid physics-informed neural network approaches for the same datasets