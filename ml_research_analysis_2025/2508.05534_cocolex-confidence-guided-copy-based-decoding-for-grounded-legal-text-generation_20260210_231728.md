---
ver: rpa2
title: 'CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation'
arxiv_id: '2508.05534'
source_url: https://arxiv.org/abs/2508.05534
tags:
- legal
- arxiv
- cocolex
- context
- decoding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoCoLex, a confidence-guided copy-based decoding
  strategy for grounded legal text generation that dynamically interpolates the model's
  vocabulary distribution with a copy-based distribution derived from retrieved context.
  The method uses a confidence score based on model entropy to balance copying from
  context versus generating new tokens, ensuring greater fidelity to source material.
---

# CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation

## Quick Facts
- **arXiv ID**: 2508.05534
- **Source URL**: https://arxiv.org/abs/2508.05534
- **Reference count**: 27
- **Primary result**: Introduces CoCoLex, an entropy-based confidence-guided copy-based decoding strategy that significantly improves correctness and faithfulness in grounded legal text generation compared to CAD and AdaCAD methods.

## Executive Summary
CoCoLex introduces a confidence-guided copy-based decoding strategy for grounded legal text generation that dynamically balances between model-generated tokens and context-based copying. The method uses normalized entropy as a confidence signal to interpolate between the model's vocabulary distribution and a copy-based distribution derived from retrieved context tokens. Experiments on five legal benchmarks show significant improvements in correctness and faithfulness while maintaining fluency, particularly for long-form generation tasks.

## Method Summary
CoCoLex operates by computing a copy-based distribution at each decoding step through similarity matching between the current hidden state and context token representations, then interpolating this with the model's native distribution using an entropy-based confidence score. The confidence score λ is derived from normalized model entropy and smoothed to prevent erratic behavior. The approach is implemented as a post-training inference-time modification requiring no fine-tuning. An extension, CoCoLex+, enables copying from entire documents by indexing all token representations, providing richer context at the cost of increased memory and inference overhead.

## Key Results
- CoCoLex significantly outperforms CAD and AdaCAD baselines on correctness and faithfulness metrics across five legal benchmarks
- The method shows particular effectiveness for long-form generation tasks where copying from context is more critical
- CoCoLex+ with full-document indexing provides additional improvements, especially for longer documents, though with 2-3x inference overhead
- The approach is complementary to contrastive decoding strategies, suggesting potential for combination

## Why This Works (Mechanism)

### Mechanism 1: Copy-based Distribution via Hidden State Similarity
- Claim: Computing a probability distribution based on similarity to context token representations enables direct token-level copying, improving faithfulness.
- Mechanism: At each decoding step t, the model computes Euclidean L2 distance between the current hidden state h_t and all stored context token hidden states {h_i}. These distances are transformed via exponential decay to similarity scores s_t(i) = exp(-dist_t(i)), then aggregated to form a probability distribution over vocabulary tokens based on which context tokens map to them.
- Core assumption: Hidden state similarity correlates with semantic appropriateness for copying; tokens with similar representations in context are suitable for generation.
- Evidence anchors:
  - [abstract]: "interpolates the model's vocabulary distribution with a copy-based distribution derived from retrieved context"
  - [section 3.1]: "The similarity between h_t and each context vector h_i is computed using the Euclidean L2 distance which is subsequently transformed into similarity scores via an exponential decay"
  - [corpus]: Weak corpus validation; kNN-LM approaches exist but specific copy-based grounding for faithfulness is underexplored in neighbors
- Break condition: If hidden states fail to capture semantic similarity (e.g., using early layers, or poorly calibrated models), copy quality degrades. Table 9 shows layer -25 performs significantly worse than layer -1.

### Mechanism 2: Entropy-based Confidence Gating
- Claim: Using normalized model entropy as a confidence signal enables dynamic balancing between copying (when uncertain) and generating (when confident).
- Mechanism: Compute entropy H_t = -Σ p(y_t)·log p(y_t), normalize by maximum entropy log(|V|), then apply exponential transform λ_t = exp(-H_norm_t). This confidence score interpolates: p(y_t) = λ_t·p_model + (1-λ_t)·p_copy. Smoothing with a running average prevents erratic behavior.
- Core assumption: High entropy indicates uncertainty where copying is safer; low entropy indicates confident generation that should be trusted.
- Evidence anchors:
  - [abstract]: "uses a confidence score based on model entropy to balance copying from context versus generating new tokens"
  - [section 3.2]: "Advanced LLMs are expected to assign low probabilities to tokens that are likely to introduce inaccuracies or hallucinations"
  - [corpus]: Focus-dLLM uses confidence-guided context focusing for diffusion models, suggesting cross-domain relevance of confidence-based approaches
- Break condition: If model is confidently wrong (low entropy but incorrect prediction), confidence gating amplifies errors rather than mitigating them.

### Mechanism 3: Full-Document Indexing (CoCoLex+)
- Claim: Indexing hidden states from entire documents rather than just top-k retrieved chunks provides richer copying vocabulary and improves correctness.
- Mechanism: Documents are chunked with overlapping segments. Each token receives one hidden state from the chunk where it has maximal autoregressive context. During inference, explicit context remains top-k passages, but copying can draw from full document via the indexed hidden states.
- Core assumption: Relevant tokens may exist outside top-retrieved passages; chunking-related issues cause information loss.
- Evidence anchors:
  - [abstract]: "CoCoLex+ enables copying from entire documents rather than just top-retrieved chunks, further improving performance"
  - [section 4.5.1]: "By incorporating representations from the full document, CoCoLex+ enables the model to capture a more comprehensive understanding"
  - [corpus]: Not validated in corpus neighbors; chunking-free retrieval mentioned as alternative approach in broader literature
- Break condition: Very long documents may exceed memory/indexing capacity; inference overhead increases to 2-3x for long documents (Table 5).

## Foundational Learning

- Concept: **kNN-LM (Non-parametric Language Modeling)**
  - Why needed here: CoCoLex's copy mechanism derives from kNN-LM principles—retrieving from external stores and interpolating distributions. Understanding kNN-LM helps grasp why interpolation works.
  - Quick check question: Can you explain how kNN-LM interpolates between parametric model predictions and retrieved neighbor distributions, and why this helps generalization?

- Concept: **Pointer-Generator Networks**
  - Why needed here: CoCoLex conceptually mirrors pointer-generator copying but operates training-free at inference. The key difference is CoCoLex requires no additional training.
  - Quick check question: How does a pointer-generator network learn when to copy vs generate, and what tradeoffs exist compared to CoCoLex's entropy-based gating?

- Concept: **Entropy-based Uncertainty in LLMs**
  - Why needed here: The confidence score derives from normalized entropy. Understanding entropy properties, calibration, and their relationship to hallucination detection is essential.
  - Quick check question: Why normalize entropy by log(|V|) rather than use raw entropy, and what does high vs low entropy indicate about model reliability?

## Architecture Onboarding

- Component map: Context Encoder -> FAISS Index -> Confidence Computer -> Copy Distribution Aggregator -> Distribution Interpolator -> Token Sampler

- Critical path:
  1. Prefill: Encode query + context → store context hidden states in FAISS index
  2. Each decode step: Generate h_t → FAISS lookup top-k similar context tokens → aggregate p_copy → compute entropy → derive λ → interpolate → sample

- Design tradeoffs:
  - Layer selection (-1 vs earlier): Last layer provides contextually refined representations but may be task-specific; earlier layers encode less semantics (Table 9 validates -1 is best)
  - λ clamping [0.2, 0.8]: Prevents degenerate all-copy/all-generate but limits extreme behavior
  - CoCoLex+ indexing: Higher memory and 2-3x inference overhead vs better coverage (Table 5)
  - Smoothing parameter (0.5): Stabilizes λ but may slow response to genuine confidence changes

- Failure signatures:
  - Excessive copying (low fluency): λ consistently too low; check entropy calculation or clamping bounds
  - Low faithfulness despite context: λ too high; model ignoring copy distribution
  - Irrelevant copying: Similarity function (Euclidean vs cosine) mismatch; Table 8 shows Euclidean outperforms cosine
  - Memory overflow with CoCoLex+: Document too long; consider chunk size reduction or approximate indexing

- First 3 experiments:
  1. **Baseline validation**: Implement Regular, CAD, AdaCAD, CoLex (static λ=0.5), and CoCoLex on CUAD subset; verify faithfulness (AlignScore) improvements match paper claims
  2. **Confidence ablation**: Replace dynamic λ with fixed values [0.3, 0.5, 0.7] on CLERC to isolate contribution of entropy-based gating vs static interpolation
  3. **Distractor robustness**: Vary number of retrieved passages (3, 6, 10) on CLERC; verify CoCoLex maintains performance as distractors increase (Table 7 pattern)

## Open Questions the Paper Calls Out
None

## Limitations
- The approach requires significant computational overhead, particularly 2-3x inference time for CoCoLex+ with full-document indexing
- The evaluation focuses exclusively on legal domains, leaving effectiveness on other specialized or general domains unverified
- The entropy-based confidence signal may not reliably indicate copying-necessity for all model architectures or calibration properties

## Confidence
- **High Confidence**: Core entropy-based confidence gating mechanism validated across multiple benchmarks with statistically significant improvements over baselines
- **Medium Confidence**: CoCoLex+ extension showing full-document indexing benefits, though tested on more limited conditions
- **Low Confidence**: Generalization claims to non-legal domains without supporting experiments

## Next Checks
1. **Domain Generalization Test**: Implement CoCoLex on a non-legal specialized domain (e.g., medical or scientific text generation) with similar RAG setup to verify whether the entropy-based confidence signal and copy distribution mechanism transfer effectively beyond legal contexts.

2. **Confidence Signal Robustness**: Systematically evaluate how CoCoLex performs when the underlying model has different calibration properties or when using different model families (e.g., LLaMA, GPT-style models) to test whether entropy reliably indicates copying-necessity across architectures.

3. **Real-world Deployment Simulation**: Conduct a cost-benefit analysis measuring the practical impact of 2-3x inference overhead in CoCoLex+ on document processing pipelines, including memory usage profiles and end-to-end latency for typical legal document lengths encountered in practice.