---
ver: rpa2
title: 'Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable
  and Efficient Transformer Pruning'
arxiv_id: '2510.13832'
source_url: https://arxiv.org/abs/2510.13832
tags:
- pruning
- entropy
- importance
- head
- e-03
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HIES, a pruning criterion that combines gradient-based
  head importance scores with attention entropy to improve both accuracy and stability
  of transformer pruning. By integrating these complementary signals, HIES addresses
  the limitations of HIS-only methods, which overlook attention diversity and lead
  to sharp accuracy drops at high sparsity.
---

# Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning

## Quick Facts
- arXiv ID: 2510.13832
- Source URL: https://arxiv.org/abs/2510.13832
- Reference count: 40
- One-line primary result: HIES achieves up to 15.2% higher accuracy and 2.04× better stability than HIS-only baselines, especially at aggressive pruning ratios (30–50%).

## Executive Summary
This paper proposes HIES, a novel pruning criterion that combines gradient-based head importance scores with attention entropy to improve both accuracy and stability of transformer pruning. By integrating these complementary signals, HIES addresses the limitations of HIS-only methods, which overlook attention diversity and lead to sharp accuracy drops at high sparsity. The approach uses min-max normalization and a tunable weighting parameter to balance the two metrics. Experiments on BERT and LLaMA-27B across diverse tasks show HIES achieves up to 15.2% higher accuracy and 2.04× better stability than HIS-only baselines, especially at aggressive pruning ratios (30–50%). It also demonstrates scalability to larger models and attention variants, and provides a principled risk-decomposition analysis explaining its effectiveness.

## Method Summary
HIES is a pruning criterion that computes a unified score for each attention head by combining Head Importance Score (HIS) and Attention Entropy (AE). HIS is calculated as the dot product of the gradient of the loss with respect to the head's output and the head's output itself, capturing the head's contribution to the loss. AE is the Shannon entropy of the head's attention distribution over tokens, measuring the dispersion of attention. Both metrics are normalized to [0,1] per layer using min-max scaling, then combined as HIES_h = α × dHIS_h + (1−α) × (1 − cAE_h), where α is a task-specific weighting parameter. Heads are ranked by HIES and the lowest-scoring heads are pruned. The method is applied after fine-tuning and uses a small calibration set (32 samples) to compute scores.

## Key Results
- HIES achieves up to 15.2% higher accuracy than HIS-only baselines at aggressive pruning ratios (30–50%).
- HIES provides 2.04× better stability, measured by correlation with unpruned model predictions across pruning ratios.
- The method is scalable to larger models like LLaMA-27B and demonstrates effectiveness across diverse tasks and attention variants.

## Why This Works (Mechanism)

### Mechanism 1: Orthogonal Gradient and Entropy Signals
Integrating Head Importance Score (HIS) and Attention Entropy (AE) into a unified metric, HIES, creates a more robust pruning criterion than HIS alone because the two signals capture statistically orthogonal information about head behavior. HIS measures a head's contribution to loss via gradient magnitude, while AE measures the dispersion of attention across tokens (information distribution). The paper's Lemma 4.3 demonstrates that the gradients of HIS and AE are orthogonal in expectation, meaning they provide non-redundant information. Combining them via `HIESh = αdHISh + (1-α)(1 - cAEh)` leverages both axes simultaneously.

### Mechanism 2: Entropy-Driven Stability and Generalization Gap Control
Incorporating attention entropy into the pruning score (as HIES does) explicitly bounds the expected generalization gap, leading to more stable and robust models, especially under aggressive pruning. The paper's main bound (Equation 6) links the generalization gap to an entropy-based term (Attention Deficit, AD). Pruning heads with high entropy (low deficit) minimizes the increase in this bound. HIES operationalizes this by preferring low-entropy heads (which are more concentrated/specialized), directly controlling the theoretical stability risk.

### Mechanism 3: Delaying the "Sharp-Drop" by Preserving Specialized Low-Entropy Heads
HIES prevents the "sharp accuracy drop" observed in HIS-only pruning by prioritizing the retention of low-entropy heads that focus on decisive tokens, even if their gradient importance (HIS) is not the highest. In aggressive pruning regimes (30%+), many heads with moderate HIS but highly concentrated attention (low entropy) are critical for task performance. HIS alone might prune them. HIES's `(1-α)(1-cAEh)` term boosts their combined score, protecting them from removal. This maintains structural diversity and prevents the "collapse" of the model's ability to attend to key information.

## Foundational Learning

- **Concept: Multi-Head Attention in Transformers**
  - **Why needed here:** The method prunes individual "heads," the parallel attention units within each layer. Understanding that each head computes `softmax(QK^T/√d)V` and that the model's output is a concatenation of all heads is essential to grasp what is being removed and why.
  - **Quick check question:** In a Transformer layer, if you remove one of twelve attention heads, what is the direct effect on the computation flow?

- **Concept: Gradient-Based Saliency/Importance**
  - **Why needed here:** The HIS component is calculated using the gradient of the loss with respect to a head's output. This is a standard technique for estimating feature importance in a single backward pass.
  - **Quick check question:** How does a first-order Taylor expansion justify using gradients as a proxy for the change in loss when a component is removed?

- **Concept: Shannon Entropy in Probability Distributions**
  - **Why needed here:** The AE component is defined as the Shannon entropy of a head's attention distribution over tokens. A low entropy indicates the head "focuses" on few tokens; a high entropy indicates a broad or diffuse attention pattern.
  - **Quick check question:** For an attention head that assigns 99% of its weight to a single token, is its entropy high or low?

## Architecture Onboarding

- **Component map:** Data Batch -> Forward Pass -> (Backward Pass) -> HIS & AE Calculation -> Normalization -> HIES Combination -> Global Ranking -> Mask Generation
- **Critical path:** The entire onboarding flow is `Data Batch → (Forward Pass) → (Backward Pass) → HIS & AE Calculation → Normalization → HIES Combination → Global Ranking → Mask Generation`. The most critical step is obtaining stable and representative gradients and attention maps from a small calibration dataset.
- **Design tradeoffs:**
  - **α (mixing hyperparameter):** Controls the balance between gradient importance (HIS) and attention focus (AE). Higher α prioritizes loss sensitivity; lower α prioritizes head specialization. **Tradeoff:** An α that is too high reverts to the unstable HIS-only behavior; an α that is too low may preserve specialized but ultimately non-critical heads.
  - **Calibration Dataset Size:** A small set is computationally cheap but may yield noisy importance estimates. A large set is more robust but more expensive. The paper shows a small set (e.g., 32 samples) is often sufficient.
  - **Pruning Granularity:** Head pruning is structurally simple and preserves layer topology, but it is less fine-grained than channel pruning.
- **Failure signatures:**
  - **No improvement over baseline:** Indicates the AE signal may not be complementary for this task/model (high correlation with HIS) or the chosen α is suboptimal.
  - **Degraded accuracy at low sparsity (≤10%):** May suggest the model is in a "redundancy regime" where pure HIS is more efficient, and the AE term is adding noise.
  - **Catastrophic accuracy drop:** Suggests the orthogonality assumption has failed severely or the calibration data is not representative of the task.
- **First 3 experiments:**
  1. **Orthogonality Check:** On a held-out validation batch, compute normalized HIS (`u`) and normalized AE (`v`) for all heads. Calculate their correlation. If the correlation is very high (>0.7), the benefits of HIES may be limited for this model/task.
  2. **Alpha Sensitivity Sweep:** Run pruning at a fixed aggressive ratio (e.g., 40%) while sweeping α from 0.1 to 0.9. Plot the resulting accuracy to identify the optimal balance between HIS and AE signals.
  3. **Baselines and Regime Test:** Compare HIES against HIS-only and random pruning baselines. Specifically, test at low (10%), moderate (30%), and high (50%) pruning ratios to confirm the "sharp-drop" mitigation effect appears only in the higher regimes, as claimed.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the HIES criterion be extended to other structured pruning targets beyond attention heads, such as Feed-Forward Networks (FFNs) or entire transformer layers?
- **Basis in paper:** [explicit] The conclusion states HIES has "potential to extend toward broader structured sparsity and large-scale model deployment."
- **Why unresolved:** The paper focuses exclusively on attention heads, and the entropy component (AE) is defined specifically for attention probability distributions; FFNs lack an equivalent "attention" mechanism to measure entropy over.
- **What evidence would resolve it:** A modified formulation of HIES applicable to FFN neurons or layers, demonstrating similar stability and accuracy retention in non-attention components.

### Open Question 2
- **Question:** Is it possible to determine the weighting parameter $\alpha$ automatically or adaptively, eliminating the need for task-specific tuning?
- **Basis in paper:** [explicit] Section 4.1 notes that "To determine the optimal combination... we adopt a task-specific tuning procedure," and Appendix D.8 analyzes sensitivity to this parameter.
- **Why unresolved:** The current methodology requires a sweep or validation set to find the optimal trade-off between importance and entropy, which adds computational overhead and limits "plug-and-play" efficiency.
- **What evidence would resolve it:** The derivation of a theoretical heuristic for $\alpha$ or an adaptive mechanism that sets $\alpha$ based on data statistics without degrading performance relative to the tuned baseline.

### Open Question 3
- **Question:** Does the orthogonality between Head Importance Score (HIS) and Attention Entropy (AE) gradients hold across all attention variants and training stages, or is it specific to the pre-trained/fine-tuned models tested?
- **Basis in paper:** [inferred] Lemma 4.3 relies on the assumption that the cross-covariance matrix is zero ($Cov(\tilde{u}, \tilde{v}) = 0$), which is empirically validated in Appendix D.1 but not theoretically proven as a universal property of transformers.
- **Why unresolved:** If the orthogonality assumption fails in specific architectures (e.g., Grouped Query Attention) or during specific training phases, the theoretical justification for HIES's complementary benefit would weaken.
- **What evidence would resolve it:** A theoretical proof of the orthogonality condition or extensive empirical validation across diverse, untested architectures (e.g., Mamba, RWKV) and training dynamics (e.g., during pre-training).

## Limitations
- Empirical validation relies on specific models (BERT-base, LLA-27B) and tasks; robustness across diverse architectures and domains is untested.
- Hyperparameter α is task-specific and requires validation sweeps, adding computational overhead.
- The orthogonality assumption between HIS and AE may not hold for all architectures or tasks, potentially reducing HIES to a redundant combination.

## Confidence
**High Confidence:** The empirical results showing HIES outperforms HIS-only baselines on BERT and LLaMA-27B across multiple tasks, particularly at aggressive pruning ratios (30-50%), are well-supported by the presented experiments.

**Medium Confidence:** The theoretical analysis linking entropy to generalization gap and stability is sound, but the practical impact of this bound on real-world model performance is not fully validated.

**Low Confidence:** The scalability claims to larger models and attention variants are based on limited experiments (only LLaMA-27B and one attention variant).

## Next Checks
1. **Orthogonality Validation:** On a held-out validation batch, compute normalized HIS and AE for all heads in a new architecture (e.g., Vision Transformer). Calculate their correlation. If the correlation is very high (>0.7), the benefits of HIES may be limited for this model/task, and the orthogonality assumption is violated.

2. **Alpha Sensitivity Sweep:** Run pruning at a fixed aggressive ratio (e.g., 40%) on LLaMA-27B while sweeping α from 0.1 to 0.9. Plot the resulting accuracy to identify the optimal balance between HIS and AE signals and quantify the sensitivity of HIES performance to this hyperparameter.

3. **Generalization Test:** Apply HIES to a diverse set of tasks and architectures not covered in the paper (e.g., multilingual BERT, Longformer on long-document tasks, or a Vision Transformer on image classification). Compare the performance and stability against HIS-only and random pruning baselines to assess the robustness and generalizability of the method.