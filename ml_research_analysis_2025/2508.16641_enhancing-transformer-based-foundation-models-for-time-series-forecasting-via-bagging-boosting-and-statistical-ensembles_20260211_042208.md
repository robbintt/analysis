---
ver: rpa2
title: Enhancing Transformer-Based Foundation Models for Time Series Forecasting via
  Bagging, Boosting and Statistical Ensembles
arxiv_id: '2508.16641'
source_url: https://arxiv.org/abs/2508.16641
tags:
- lag-llama
- prediction
- autogluon
- context
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates statistical and ensemble-based enhancements
  for Transformer-based foundation models in time series forecasting. The proposed
  methods include bootstrap-based bagging, regression-based stacking, prediction interval
  construction, residual modeling, and iterative error feedback to address variance,
  domain-specific bias, and uncertainty quantification limitations.
---

# Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles

## Quick Facts
- arXiv ID: 2508.16641
- Source URL: https://arxiv.org/abs/2508.16641
- Reference count: 30
- Primary result: Statistical ensembles (bagging, stacking, residual modeling) improve Transformer foundation model accuracy by up to 67% on electricity load forecasting

## Executive Summary
This paper addresses accuracy, uncertainty quantification, and bias limitations in Transformer-based foundation models for time series forecasting by integrating statistical ensemble methods. The proposed hybrid framework combines bootstrap-based bagging, regression-based stacking, prediction interval construction, and residual modeling with the Lag-Llama foundation model. Applied to the Belgium Electricity Short-Term Load Forecasting dataset, the statistical enhancements consistently outperform standalone foundation models, achieving up to 54% MSE reduction with bagging and 67% with residual modeling for mid-range contexts.

## Method Summary
The method augments Lag-Llama's probabilistic forecasts with statistical ensembles using the Belgium Electricity dataset. Bootstrap aggregation samples 40 values with replacement from 100 Lag-Llama draws, repeated 100 times to reduce variance. Regression stacking combines Lag-Llama and AutoGluon predictions with time-series cross-validated weights. Prediction intervals are constructed assuming independence between components. Residual modeling trains AutoGluon on historical errors to correct systematic bias. The framework uses chronological 70/10/20 splits across 1-5 week context windows.

## Key Results
- Regression ensembles achieved lowest MSE (196 vs 488 for Lag-Llama alone with 5-week context)
- Bootstrap bagging reduced errors by up to 54% across context lengths
- Prediction intervals achieved near-nominal coverage with widths narrowing as context increased
- Residual modeling provided up to 67% error reduction for mid-range contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bootstrap aggregation reduces forecast variance by averaging across resampled prediction draws.
- Mechanism: The base model generates n=100 probabilistic draws. Sampling b=40 values with replacement and repeating m=100 times produces bootstrap means whose final average stabilizes the point estimate through statistical aggregation.
- Core assumption: Individual forecast draws are independent samples from the model's predicted distribution.
- Evidence anchors:
  - [abstract] "bootstrap-based bagging...bootstrap aggregation markedly reduces long-context errors"
  - [Section 3.1] Algorithm 1 specifies the bootstrap procedure with explicit sample sizes
  - [Section 5, Table 1] MSE reductions of 23-54% across context lengths
  - [corpus] Limited direct corpus validation; neighbor papers focus on architectural enhancements rather than statistical bagging for TSFMs
- Break condition: Variance reduction degrades if forecast draws exhibit high correlation or if the base distribution is misspecified.

### Mechanism 2
- Claim: Regression stacking combines complementary inductive biases from foundation models and statistical/ML ensembles.
- Mechanism: Linear combination ŷ_ens = w₁·ŷ_Lag + w₂·ŷ_AG with weights fit via time-series cross-validated regression exploits Transformer strength in long-range dependencies and AutoGluon strength in local/seasonal structure.
- Core assumption: Component models make independent errors; linear combination is sufficient to capture complementary strengths.
- Evidence anchors:
  - [abstract] "Regression-based ensembles achieve the lowest mean squared error"
  - [Section 3.2] Equation (1) and Algorithm 2 describe the stacking procedure
  - [Section 5, Table 2] Regression ensemble MSE of 196 vs 488 (Lag-Llama) and 203 (AutoGluon) at 5-week context
  - [corpus] Neighbor paper on automated univariate forecasting with regression trees notes bagging/ensemble benefits, supporting general ensemble efficacy
- Break condition: Performance gains diminish if component forecasts are highly correlated or if the linear model underfits the true combination function.

### Mechanism 3
- Claim: Residual modeling corrects systematic bias by learning error patterns and subtracting predicted residuals.
- Mechanism: Train AutoGluon on historical residuals e_t = ŷ_t - y_t, forecast residual ê_t, then adjust via ŷ_adj = ŷ_t - ê_t. This targets domain-specific bias the foundation model fails to capture.
- Core assumption: Residuals contain learnable systematic structure rather than pure noise.
- Evidence anchors:
  - [abstract] "residual modeling corrects systematic bias"
  - [Section 3.4] Algorithm 3 details the residual adjustment procedure
  - [Section 5, Table 3] 67% MSE reduction (180→59) at 3-week context; 1% at 1-week
  - [corpus] DeepBooTS neighbor paper analyzes concept drift through bias-variance lens, supporting bias-correction framing
- Break condition: Correction fails if residuals are approximately white noise or if insufficient history exists to train the residual model (as noted for 5-week context).

## Foundational Learning

- Concept: **Bootstrap aggregation (bagging)**
  - Why needed here: Core technique for variance reduction in probabilistic forecasts; requires understanding of sampling with replacement and the bias-variance tradeoff.
  - Quick check question: If you sample 40 values with replacement from 100 draws, what happens to the variance of the mean compared to a single draw?

- Concept: **Time-series cross-validation**
  - Why needed here: Weight fitting for stacking requires temporal data splits that preserve order; standard k-fold CV causes look-ahead bias.
  - Quick check question: Why must training data precede validation data in time-series model selection?

- Concept: **Prediction interval construction from ensemble variance**
  - Why needed here: The paper assumes independence to compute σ²_ens = w₁²σ²_Lag + w₂²σ²_AG; understanding this assumption is critical for proper uncertainty quantification.
  - Quick check question: If Lag-Llama and AutoGluon forecasts are positively correlated, will the interval be too narrow or too wide?

## Architecture Onboarding

- Component map:
  - Base models (Lag-Llama, AutoGluon) -> Enhancement layer (Bootstrap aggregator, Regression stacker, Residual corrector) -> Output layer (Point forecasts + Prediction intervals)

- Critical path:
  1. Generate Lag-Llama predictions (100 draws per timestep)
  2. Generate AutoGluon predictions (decile outputs)
  3. Apply bootstrap aggregation to Lag-Llama draws
  4. Fit regression weights on training split via time-series CV
  5. Compute ensemble mean and variance for prediction intervals
  6. (Optional) Train residual model and adjust forecasts

- Design tradeoffs:
  - Longer context windows improve Lag-Llama contribution but reduce available residual history
  - More bootstrap samples increase computational cost with diminishing returns
  - Independence assumption for PI construction is an approximation; violations require copula-based or bootstrap calibration

- Failure signatures:
  - Bagging shows no improvement → forecast draws may be highly correlated
  - Regression ensemble underperforms simple average → weights overfit on validation
  - Prediction intervals undercover → component forecasts are dependent (inflate σ_ens)
  - Residual correction increases error → residuals lack learnable structure

- First 3 experiments:
  1. Replicate Table 1 (bagging vs baseline) on a held-out week to verify variance reduction scales.
  2. Fit regression ensemble with 3-fold and 5-fold time-series CV; compare weight stability across folds.
  3. Compute prediction interval coverage on test set; if below 90%, apply 1.1× inflation factor to σ_ens and re-evaluate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the violation of the independence assumption between component forecasts (Lag-Llama and AutoGluon) impact prediction interval calibration, and can copula-based or bootstrap-based methods correct this?
- Basis in paper: [explicit] Section 6 (Limitations) states that the independence assumption used for ensemble variance is an approximation and suggests dependencies may require copula-based or bootstrap-based PI calibration.
- Why unresolved: The current methodology relies on simple variance summation (σ²_ens = w₁²σ²_Lag + w₂²σ²_AG), which may misestimate uncertainty if the component errors are correlated.
- What evidence would resolve it: Empirical comparison of prediction interval coverage and width between the current independence-based method and a copula-based calibration approach on the Belgium Electricity dataset.

### Open Question 2
- Question: Do the performance gains from statistical ensemble techniques (bagging, stacking) transfer to multivariate or multimodal time series settings?
- Basis in paper: [explicit] Section 6 (Conclusion and Future Work) explicitly lists testing on multivariate and multimodal datasets as a direction for future research.
- Why unresolved: The study is restricted to a univariate electricity load dataset; it is unclear if statistical post-processing improves foundation models that already leverage cross-series dependencies.
- What evidence would resolve it: Application of the proposed hybrid framework to a benchmark multivariate dataset (e.g., Solar Power or Traffic) demonstrating consistent MSE reductions over standalone multivariate foundation models.

### Open Question 3
- Question: Can adaptive subsampling strategies reduce the computational cost of bootstrap bagging without degrading the significant variance reduction (up to 54%) observed with fixed bootstrap draws?
- Basis in paper: [explicit] Section 6 (Limitations) notes that computational costs for bagging grow with the number of bootstrap draws and suggests adaptive subsampling may preserve gains at lower cost.
- Why unresolved: The current implementation uses fixed draws (n=100, b=40, m=100), which stabilizes forecasts but may be inefficient for operational deployment.
- What evidence would resolve it: An ablation study comparing runtime and MSE performance between fixed-sample bagging and adaptive subsampling algorithms across different context lengths.

### Open Question 4
- Question: Does incorporating domain-specific constraints into ensemble weighting or residual correction yield measurable improvements over the purely data-driven linear stacking weights?
- Basis in paper: [explicit] Section 6 (Conclusion) identifies the incorporation of domain constraints into ensemble weighting and residual correction as a target for future research.
- Why unresolved: Current weights (w₁, w₂) are learned via linear regression on historical errors, potentially ignoring known physical limits or calendar effects specific to electricity load.
- What evidence would resolve it: A comparison of forecast accuracy (MSE) and physical plausibility between unconstrained regression ensembles and ensembles optimized with constrained programming.

## Limitations

- Performance generalization to non-seasonal datasets is untested; results heavily rely on strong diurnal/weekly patterns in Belgium electricity data
- The independence assumption underlying prediction interval construction is unverified empirically; positive correlation between Lag-Llama and AutoGluon forecasts would lead to under-coverage
- Residual modeling showed negligible gains at 5-week context due to insufficient training history, suggesting method sensitivity to data availability

## Confidence

- High: Bootstrap bagging reduces variance (direct statistical property, observed MSE drops 23-54%)
- Medium: Regression stacking improves accuracy (results strong but dependent on time-series CV quality and component model independence)
- Medium: Prediction intervals achieve nominal coverage (coverage observed but assumption of independence is approximate)

## Next Checks

1. Compute empirical correlation between Lag-Llama and AutoGluon forecasts on test set; if >0.7, apply bootstrap calibration to prediction intervals
2. Test residual modeling on a synthetic dataset with known systematic bias to verify it learns and corrects bias rather than fitting noise
3. Apply the full ensemble pipeline to a non-seasonal dataset (e.g., financial data) to assess performance degradation