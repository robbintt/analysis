---
ver: rpa2
title: A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection
arxiv_id: '2509.02637'
source_url: https://arxiv.org/abs/2509.02637
tags:
- mitotic
- detection
- cancer
- tumor
- sdf-yolo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SDF-YOLO is a lightweight, domain-robust framework for mitotic
  figure detection that simplifies YOLOv11 with a single detection head and coordinate
  attention for small object localization. Trained on human and canine tumor datasets,
  it achieved an AP of 0.799, precision of 0.758, recall of 0.775, F1 of 0.766, and
  FROC-AUC of 5.793 on the MIDOG2025 preliminary test set, demonstrating strong accuracy
  and robustness across domains.
---

# A Single Detect Focused YOLO Framework for Robust Mitotic Figure Detection

## Quick Facts
- arXiv ID: 2509.02637
- Source URL: https://arxiv.org/abs/2509.02637
- Reference count: 0
- AP of 0.799, precision of 0.758, recall of 0.775, F1 of 0.766, and FROC-AUC of 5.793 on MIDOG2025 preliminary test set

## Executive Summary
SDF-YOLO is a lightweight, domain-robust framework for mitotic figure detection that simplifies YOLOv11 with a single detection head and coordinate attention for small object localization. Trained on human and canine tumor datasets, it achieved strong accuracy and robustness across domains, demonstrating AP of 0.799 and FROC-AUC of 5.793 on the MIDOG2025 preliminary test set. The architecture prioritizes efficiency while maintaining performance on consistently-sized objects.

## Method Summary
SDF-YOLO modifies YOLOv11 by removing multi-scale detection heads (P3/P5) and retaining only P4, aligning detection with the consistent ~50×50 pixel scale of mitotic figures. Coordinate Attention is inserted after the C2PSA block to preserve spatial position encoding for small objects. The detection head replaces its second depthwise convolution with a standard 2D convolution to improve cross-channel feature mixing. The framework is trained on MIDOG++, CCMCT, and CMC datasets with custom patch sampling, extensive augmentation, and domain-balanced training.

## Key Results
- Achieved AP of 0.799 on MIDOG2025 preliminary test set
- Precision of 0.758, recall of 0.775, and F1 of 0.766 across all domains
- FROC-AUC of 5.793, indicating strong performance on varying confidence thresholds
- Demonstrated robustness across 4 scanners, 7 tumor types, and both human and canine datasets

## Why This Works (Mechanism)

### Mechanism 1: Single Detection Head Alignment
Removing multi-scale detection heads (P3/P5) and retaining only P4 improves efficiency without sacrificing accuracy for consistently-sized objects. Mitotic figures are annotated at ~50×50 pixels, and at stride 16 (P4), a 640×640 input produces a 40×40 feature grid where each mitosis covers roughly 3×3 cells—sufficient for localization while eliminating redundant scale processing. This assumes target objects exhibit low scale variance across the dataset.

### Mechanism 2: Coordinate Attention for Positional Sensitivity
Coordinate Attention (CA) preserves spatial encoding better than channel-only attention for small object localization. CA decomposes attention along x and y axes, capturing long-range spatial dependencies while re-weighting channels—allowing the network to maintain position-aware features through the backbone-neck junction. This assumes spatial position encodings are degraded during downsampling and need explicit restoration.

### Mechanism 3: Cross-Channel Mixing for Regression Stability
Replacing depthwise convolution with standard 2D convolution in the detection head stabilizes bounding box and confidence score regression. Depthwise convolutions process channels independently; standard convolutions enable cross-channel feature mixing, which may improve the network's ability to jointly optimize localization and classification in a single-scale regime. This assumes single-scale detection requires richer channel interactions to compensate for lost multi-scale context.

## Foundational Learning

- Concept: **Feature Pyramid Networks and Multi-Scale Detection**
  - Why needed here: Understanding why standard YOLO uses P3/P4/P5 heads clarifies what is sacrificed by switching to single-head detection.
  - Quick check question: Can you explain why multi-scale features help detect objects of varying sizes, and what assumptions justify removing them?

- Concept: **Attention Mechanisms (Spatial vs. Channel vs. Coordinate)**
  - Why needed here: CA is the paper's key augmentation; distinguishing it from SE or CBAM attention clarifies its design intent.
  - Quick check question: How does Coordinate Attention differ from Squeeze-and-Excitation in terms of what information it preserves?

- Concept: **Domain Shift in Computational Pathology**
  - Why needed here: The entire framework is designed around robustness to scanner, stain, and tissue variability.
  - Quick check question: Name three sources of domain shift in histopathology and how augmentation strategies might mitigate them?

## Architecture Onboarding

- Component map: `Input (640×640) -> Backbone (C3K2, SPPF, C2PSA) -> Coordinate Attention -> Neck -> Single P4 Head (modified conv) -> Detection Output`
- Critical path: The C2PSA -> Coordinate Attention -> P4 Head sequence is where task-specific adaptations concentrate. Errors here propagate directly to localization accuracy.
- Design tradeoffs: Removed P3/P5 heads reduce parameters and latency but forfeit multi-scale context. CA adds ~1.5% parameters but preserves spatial cues. Standard convolution replacement increases FLOPs in the head but may stabilize regression.
- Failure signatures: High recall, low precision on unseen domains → model overgeneralizing; check color augmentation strength. Systematic localization drift → CA may not be integrating properly; verify insertion point after C2PSA. Performance collapse on smaller objects → single-head assumption violated; reconsider multi-scale.
- First 3 experiments: 1) Ablate Coordinate Attention: Remove CA, retrain on same split, compare AP/F1 to quantify its contribution. 2) Multi-Scale Baseline: Restore P3/P5 heads with identical training config to measure accuracy vs. efficiency tradeoff. 3) Cross-Domain Validation: Train on MIDOG++ only, test on CCMCT/CMC to isolate domain robustness from architecture effects.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SDF-YOLO maintain its performance and generalizability when evaluated on the final MIDOG2025 test set?
- Basis in paper: The authors state that "the assessment was restricted to the preliminary phase... and further validation on the final test set is necessary to confirm generalizability."
- Why unresolved: The reported AP of 0.799 reflects performance only on the preliminary test data; the final test set may introduce unseen scanners or tissue protocols.
- Evidence: Submission results and leaderboard ranking on the official MIDOG2025 final test set.

### Open Question 2
- Question: How can the single-head architecture be adapted for multi-class or multi-scale detection tasks without losing efficiency?
- Basis in paper: The authors note that "broader applications involving multi-class or multi-scale detection may require adapting the architecture."
- Why unresolved: The removal of P3/P5 detection heads was a task-specific simplification for mitosis scale; it is unclear if this design bottlenecks performance for larger or more variable objects.
- Evidence: Benchmarking a modified multi-scale version of SDF-YOLO against the standard YOLOv11 on a multi-class histopathology dataset.

### Open Question 3
- Question: What specific features or data augmentations could mitigate the recall variance observed in Tumor2 domains?
- Basis in paper: The results section highlights that while precision was stable, "recall varied more prominently, particularly for Tumor2" (dropping to 0.714 compared to 0.972 for Tumor1).
- Why unresolved: The paper acknowledges the performance gap across tumor domains but does not isolate the morphological characteristics causing the lower recall for Tumor2.
- Evidence: An error analysis of False Negatives in Tumor2 cases and subsequent performance changes after targeted data augmentation or domain-specific fine-tuning.

## Limitations
- Coordinate Attention integration details remain underspecified, including exact implementation parameters and insertion point
- Patch sampler design lacks clarity on how negative patches are defined and sampled
- Domain generalization claims rely heavily on cross-dataset performance without per-domain hyperparameter tuning

## Confidence
- **High**: Single detection head design for consistently-sized mitoses (well-justified by object scale analysis)
- **Medium**: Cross-channel mixing improvement (internal claim, limited external validation)
- **Medium**: Domain robustness (supported by cross-dataset testing but limited by single training run)
- **Low**: Coordinate Attention contribution (no ablation shown, weak external validation)

## Next Checks
1. **Ablate Coordinate Attention**: Remove CA, retrain under identical conditions, compare AP/F1 to quantify spatial attention contribution
2. **Multi-Scale Baseline**: Restore P3/P5 heads with same training config to measure accuracy-efficiency tradeoff
3. **Cross-Domain Ablation**: Train on MIDOG++ only, test on CCMCT/CMC to isolate domain robustness from architecture effects