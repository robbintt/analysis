---
ver: rpa2
title: A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based
  on Large Language Models Enhanced by Domain Knowledge Retrieval
arxiv_id: '2501.03295'
source_url: https://arxiv.org/abs/2501.03295
tags:
- soft
- data
- sensor
- llms
- auxiliary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLM-FUESS, a novel two-stage framework that
  leverages large language models and in-context learning to replace traditional supervised
  learning in soft sensor modeling. The approach addresses challenges of high development
  costs, training instability, and lack of interpretability in conventional methods.
---

# A Soft Sensor Method with Uncertainty-Awareness and Self-Explanation Based on Large Language Models Enhanced by Domain Knowledge Retrieval

## Quick Facts
- arXiv ID: 2501.03295
- Source URL: https://arxiv.org/abs/2501.03295
- Reference count: 40
- Primary result: MAE reductions up to 62.57% compared to baseline models on industrial datasets

## Executive Summary
This paper introduces LLM-FUESS, a novel two-stage framework that leverages large language models and in-context learning to replace traditional supervised learning in soft sensor modeling. The approach addresses challenges of high development costs, training instability, and lack of interpretability in conventional methods. The framework uses LLM-ZAVS for zero-shot auxiliary variable selection with domain knowledge retrieval, and LLM-UFSS for few-shot soft sensor prediction without parameter updates. Experimental results on industrial datasets demonstrate state-of-the-art predictive performance with MAE reductions up to 62.57% compared to baseline models, strong robustness to missing data (maintaining performance with up to 50% missing values), and effective uncertainty quantification through confidence intervals and scores.

## Method Summary
The LLM-FUESS framework employs a two-stage pipeline: (1) LLM-ZAVS performs zero-shot feature selection using retrieval-augmented generation from industrial knowledge documents to identify relevant auxiliary variables, and (2) LLM-UFSS conducts few-shot prediction through in-context learning, either using fixed random contexts or retrieval-augmented contexts from historical process data. The method converts structured process data into text-based input-output pairs, leverages LLM probabilistic generation for uncertainty quantification, and provides interpretable explanations. Key components include structured prompt templates, vector stores for document and sample retrieval, and JSON-enforced LLM outputs. The framework operates without parameter updates, relying on demonstration quality and retrieval relevance.

## Key Results
- Achieved MAE reductions of 45.93-62.57% compared to baseline models across datasets
- Maintained strong performance with up to 50% missing values in test inputs
- Improved feature selection effectiveness by 44.69-54.41% over random selection methods
- Generated calibrated confidence scores that decrease with higher missing rates

## Why This Works (Mechanism)

### Mechanism 1
In-Context Learning (ICL) enables soft sensor prediction without parameter updates by leveraging few-shot demonstrations. The framework converts structured process data into text-based input-output pairs as context samples. The LLM identifies patterns across these demonstrations through attention mechanisms and applies learned relationships to new test samples, outputting predictions, confidence scores, and explanations. Core assumption: Pretrained LLMs encode sufficient general reasoning and numerical pattern-matching capabilities to transfer to industrial prediction tasks without domain-specific training.

### Mechanism 2
Retrieval-Augmented Generation (RAG) addresses domain knowledge gaps and improves context sample quality through vector-based retrieval. Two vector stores are constructed: (1) Industrial Knowledge Vector Store (IKVS) from documents for feature selection, and (2) Industrial Process Data Vector Store (IPDVS) from historical samples. Test samples query these stores via Euclidean distance similarity to retrieve relevant context. Core assumption: Embedding models can capture semantic and numerical similarity such that retrieved samples or documents are genuinely relevant to the prediction task.

### Mechanism 3
LLM probabilistic generation enables uncertainty quantification through repeated sampling and confidence score elicitation. The framework exploits the conditional probability distribution over tokens by running multiple prediction passes with temperature > 0, aggregating results into confidence intervals. Additionally, explicit prompting instructs the LLM to output a confidence score (0-1). Core assumption: The variance across LLM outputs correlates meaningfully with prediction uncertainty, and self-reported confidence reflects actual accuracy.

## Foundational Learning

- **Concept: In-Context Learning (ICL)**
  - Why needed here: Core paradigm shift from supervised learning to prompting; requires understanding how demonstrations influence LLM outputs without gradient updates.
  - Quick check question: Can you explain why ICL performance depends more on demonstration quality than quantity?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Both LLM-ZAVS and LLM-UFSS use RAG to inject domain knowledge and retrieve similar samples; foundational to the entire architecture.
  - Quick check question: What is the difference between IKVS and IPDVS in terms of content and retrieval purpose?

- **Concept: Soft Sensing**
  - Why needed here: The target application domain; understanding auxiliary vs. primary variables and the industrial constraints (missing data, real-time requirements) is essential.
  - Quick check question: Why is feature/auxiliary variable selection critical before soft sensor modeling?

## Architecture Onboarding

- **Component map:** External documents → IKVS → Global/Local Query → Feature ranking + explanation → Historical DCS data → IPDVS → Context retrieval → ICL prediction + uncertainty + explanation → Prompt templates (AVS-PT, SS-PT) connect both stages with structured fill-in-the-blank inputs

- **Critical path:** 1) Define primary variable and candidate auxiliary variables for your process; 2) Construct IKVS from domain documents; run LLM-ZAVS to select features; 3) Format historical samples as text; build IPDVS; 4) For each test sample, retrieve k similar samples → populate SS-PT → query LLM

- **Design tradeoffs:** Few-shot context (LLM-UFSS-FSC) vs. retrieval-augmented context (LLM-UFSS-RAC): RAC requires sufficient historical data but improves performance; GPT-4o vs. Gemini-1.5-pro: Gemini showed 62.57% lower MAE in ablation; model choice significantly impacts results; Temperature setting: 0 ensures consistency; higher values enable confidence interval estimation

- **Failure signatures:** High ASCS variability in feature selection → inconsistent prompts or weak IKVS relevance; Confidence scores not correlating with error → miscalibrated self-assessment; verify with held-out validation; Performance collapse with missing data >30% → may need imputation or additional context samples

- **First 3 experiments:** 1) Replicate LLM-ZAVS on a single dataset; verify ASCS >0.7 and compare feature selection against Pearson correlation baseline; 2) Run LLM-UFSS-FSC with 5-shot and 10-shot contexts; plot MAE vs. shot count to confirm learning curve; 3) Inject 20% missing values into test inputs; verify prediction MAE degrades gracefully and confidence scores decrease appropriately

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but raises implicit ones around computational efficiency, open-source model alternatives, and handling concept drift in dynamic processes.

## Limitations
- Limited validation on only two industrial datasets (bioprocess and petrochemical) constrains generalization claims
- High dependency on LLM choice creates potential performance bottlenecks and privacy concerns
- Uncertainty calibration validity not thoroughly validated across diverse operating conditions

## Confidence
- **High Confidence:** MAE improvements over baselines (45.93-62.57% reduction) on tested datasets; feature selection effectiveness (54.41-44.69% improvement); missing data robustness (performance maintained with up to 50% missing values)
- **Medium Confidence:** Uncertainty quantification mechanism validity; general industrial applicability beyond tested domains; long-term reliability in production environments
- **Low Confidence:** Performance with highly nonlinear or multimodal distributions; effectiveness with extremely high-dimensional data (>100 features); scalability to real-time systems with sub-second latency requirements

## Next Checks
1. Cross-Dataset Validation: Apply the framework to at least three additional industrial datasets from different domains (e.g., pharmaceutical, chemical, energy) to assess generalization beyond the two tested cases
2. Uncertainty Calibration Testing: Perform calibration analysis by comparing predicted confidence intervals against actual error distributions across multiple operating regimes; compute coverage probability and sharpness metrics
3. Ablation on Document Quality: Systematically vary the relevance and quantity of documents in the IKVS to quantify the impact on feature selection consistency and downstream prediction performance