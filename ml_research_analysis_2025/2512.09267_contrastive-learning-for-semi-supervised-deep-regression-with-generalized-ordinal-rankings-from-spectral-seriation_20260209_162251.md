---
ver: rpa2
title: Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal
  Rankings from Spectral Seriation
arxiv_id: '2512.09267'
source_url: https://arxiv.org/abs/2512.09267
tags:
- samples
- unlabeled
- regression
- learning
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a semi-supervised deep regression method that
  leverages contrastive learning with ordinal rankings derived from spectral seriation.
  The method constructs a feature similarity matrix with both labeled and unlabeled
  samples, then uses a generalized spectral seriation algorithm to obtain accurate
  ordinal rankings of unlabeled samples.
---

# Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation

## Quick Facts
- arXiv ID: 2512.09267
- Source URL: https://arxiv.org/abs/2512.09267
- Authors: Ce Wang; Weihang Dai; Hanru Bai; Xiaomeng Li
- Reference count: 40
- Primary result: Proposes GCLSS method achieving 53.3% R² on IXI brain age dataset and 61.2% R² on BVCC audio quality dataset

## Executive Summary
This paper introduces a semi-supervised deep regression method that combines contrastive learning with ordinal rankings derived from spectral seriation. The approach constructs feature similarity matrices incorporating both labeled and unlabeled samples, then uses generalized spectral seriation algorithms to obtain accurate ordinal rankings for unlabeled data. A memory-based feature selection module reduces feature noise and stabilizes training. Theoretical analysis demonstrates the method's robustness to feature and similarity matrix noise. Experimental results on multiple datasets show the method outperforms state-of-the-art semi-supervised deep regression approaches.

## Method Summary
The method constructs a feature similarity matrix with both labeled and unlabeled samples, then uses a generalized spectral seriation algorithm to obtain accurate ordinal rankings of unlabeled samples. A memory-based feature selection module reduces feature noise and stabilizes training. Theoretical analysis shows the method is robust to feature and similarity matrix noise. The approach leverages labeled samples to regularize ordinal ranking recovery by grounding it in known label relationships.

## Key Results
- Achieves 53.3% R² score on IXI brain age dataset (1/5 labels)
- Achieves 61.2% R² score on BVCC audio quality dataset
- Outperforms state-of-the-art semi-supervised deep regression approaches
- Code is publicly available

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spectral seriation can recover ordinal rankings from feature similarity matrices, enabling pseudo-supervision for unlabeled samples in regression tasks.
- Mechanism: The method constructs a cosine similarity matrix S' from L2-normalized features. The spectral seriation algorithm solves for rankings R' by finding the Fiedler vector (eigenvector of smallest non-zero eigenvalue) of the graph Laplacian L'. The relative ordering of values in this eigenvector provides the ordinal ranking. This ranking then supervises both contrastive learning and prediction losses for unlabeled data.
- Core assumption: Feature similarity reflects label distance relationships—samples with closer labels have higher cosine similarity in feature space.
- Evidence anchors: [abstract] "...an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds."
- Break condition: If feature representations are too noisy (violating the similarity-label correspondence assumption), the recovered rankings become unreliable.

### Mechanism 2
- Claim: Including labeled samples in the similarity matrix regularizes ordinal ranking recovery by grounding it in known label relationships.
- Mechanism: Rather than constructing S' from unlabeled samples only, the method builds a mixed matrix Sm ∈ R^(m+n)×(m+n) with m labeled and n unlabeled samples. The generalized spectral seriation (Corollary III.2) provides a closed-form solution for the "sub-Fiedler vector" that extracts only the unlabeled sample rankings while being constrained by labeled sample positions.
- Core assumption: Labeled features accurately reflect label distances, providing reliable anchors that propagate ordering information to unlabeled samples.
- Evidence anchors: [abstract] "The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable."
- Break condition: If labeled samples are too few or poorly distributed across the label range, regularization is insufficient.

### Mechanism 3
- Claim: Dynamic programming-based feature selection reduces noise in similarity matrices by preferentially using features with lower variance across multiple forward passes.
- Mechanism: Two forward passes generate feature sets {z'ᵢ₁} and {z'ᵢ₂} for the same batch. Four similarity matrices S¹¹, S¹², S²¹, S²² are computed, and their entry-wise variance forms a variation matrix V. Algorithm 1 (DP) selects B' features minimizing total pairwise variance.
- Core assumption: Features with lower variance across passes are more reliable indicators of true sample relationships (less affected by noise/perturbations).
- Evidence anchors: [abstract] "To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction."
- Break condition: If model weights change significantly between passes (e.g., very high learning rate), the variance signal may not reflect true feature reliability.

## Foundational Learning

- **Concept: Graph Laplacian and Fiedler Vector**
  - Why needed here: Spectral seriation relies on eigendecomposition of the graph Laplacian L = D - S (degree matrix minus similarity). The Fiedler vector (second smallest eigenvalue's eigenvector) provides the optimal 1D embedding for seriation.
  - Quick check question: Given a 4×4 similarity matrix with all diagonal entries 1 and off-diagonals 0.5, what is the graph Laplacian, and does the Fiedler vector distinguish the samples?

- **Concept: Contrastive Learning for Regression**
  - Why needed here: Unlike classification contrastive learning (same-class = positive), regression requires continuous distance relationships. The loss L(rk(S[i,:]), rk(-|R' - R'ᵢ|); λ) enforces that similarity ranking matches label-distance ranking.
  - Quick check question: Why can't standard supervised contrastive loss (SupCon) be directly applied when labels are continuous real numbers?

- **Concept: Semi-Supervised Learning Pseudo-Labeling**
  - Why needed here: The ordinal rankings R' serve as pseudo-labels for unlabeled samples, enabling them to contribute to representation learning without ground-truth annotations.
  - Quick check question: How does ranking-based pseudo-supervision differ from direct value pseudo-labeling, and what are the tradeoffs?

## Architecture Onboarding

- **Component map:**
  Input (x, y for labeled; x' for unlabeled) -> Feature Extractor f_ψ (ResNet-18/50) -> Features z, z' → L2 Normalize → ez, ez' -> [Two forward passes for MFSM] -> Similarity Matrices: S (labeled), S' (unlabeled), Sm (mixed) -> Spectral Seriation → Fiedler Vector → Ordinal Rankings R' -> Losses: LSR (supervised regression) + LSC (supervised contrastive) + LUC (unlabeled contrastive) + LUR (unlabeled ranking)

- **Critical path:**
  1. Batch construction: m labeled + n unlabeled samples (paper uses m=16, n=8 for IXI)
  2. MFSM: Two forward passes → variance computation → DP selection of B' features (B'=6 optimal)
  3. Sm construction: Cosine similarity on selected features
  4. Eigendecomposition: Compute Fiedler vector of Laplacian Lm
  5. Extract sub-vector for unlabeled samples → rankings R'
  6. Backprop through all losses

- **Design tradeoffs:**
  - Batch size (n): Larger batches provide more ranking information but shrink perturbation tolerance. Table IV shows optimal at n=8, degrades at 32.
  - B' (selected features): Too large includes noisy features; too small loses ranking information. Table VI shows B'=6 optimal for n=8.
  - Loss weights: λSC=0.1, λUC=0.05, λUR=0.01 (Table V). Unlabeled losses weighted lower to prevent noisy pseudo-supervision from dominating.

- **Failure signatures:**
  - R² drops significantly (e.g., <30% on IXI when comparable methods achieve >40%) → Check if similarity matrix Sm has reasonable structure
  - Training instability (high variance across runs) → MFSM may not be filtering effectively; verify variance matrix V has meaningful spread
  - Rankings R' are constant or near-random → Eigendecomposition may be failing; check if Laplacian is properly normalized

- **First 3 experiments:**
  1. Sanity check: Run on synthetic dataset (Section IV-B) with 100% labels to verify implementation matches supervised baseline; then 50% labels to verify semi-supervised gain.
  2. Ablation batch size: On IXI with 1/5 labels, sweep unlabeled batch size {4, 8, 16, 32} while keeping B'=batch size. Confirm peak at 8 matches Table IV.
  3. Component isolation: Compare (a) CLSS baseline, (b) CLSS + MFSM only, (c) CLSS + labeled regularization only, (d) full GCLSS. Verify both components contribute per Table III pattern.

## Open Questions the Paper Calls Out
None

## Limitations
- Method's reliance on spectral seriation introduces sensitivity to noise in feature representations, which may violate theoretical noise bounds in practice
- MFSM component's effectiveness depends on stable intermediate representations that may not hold with aggressive data augmentation or very high learning rates
- Specific hyperparameter choices (λ weights, B'=6) are presented as optimal without systematic sensitivity analysis across datasets

## Confidence
- **High confidence:** The core mechanism of using spectral seriation for ordinal ranking recovery is theoretically grounded. Experimental results showing consistent improvements over baselines across multiple datasets are reproducible.
- **Medium confidence:** The theoretical noise tolerance bounds may be conservative in practice. The MFSM's dynamic programming approach shows promise in toy experiments but lacks extensive validation on real-world data.
- **Low confidence:** The specific hyperparameter choices are presented as optimal without systematic sensitivity analysis. The generalization of these choices to datasets with different characteristics remains uncertain.

## Next Checks
1. **Noise robustness test:** Systematically vary the noise level in synthetic features and measure how ranking accuracy degrades compared to theoretical bounds from Theorem III.5.
2. **MFSM ablation study:** Remove the MFSM component and measure performance degradation across datasets to quantify its contribution beyond the basic spectral seriation approach.
3. **Cross-dataset hyperparameter transfer:** Apply the IXI-optimized hyperparameters (λ weights, B'=6) to BVCC and synthetic datasets without modification to assess generalization capability.