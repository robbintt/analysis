---
ver: rpa2
title: Bayesian Inference for Correlated Human Experts and Classifiers
arxiv_id: '2506.05636'
source_url: https://arxiv.org/abs/2506.05636
tags:
- experts
- expert
- human
- class
- error
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a Bayesian framework for online querying and
  prediction of correlated human expert labels, leveraging pre-trained classifier
  outputs. It models expert correlation via a joint latent representation, enabling
  simulation-based inference about query utility and posterior distributions over
  unobserved expert labels.
---

# Bayesian Inference for Correlated Human Experts and Classifiers

## Quick Facts
- **arXiv ID:** 2506.05636
- **Source URL:** https://arxiv.org/abs/2506.05636
- **Reference count:** 25
- **Primary result:** Outperforms baselines in minimizing human expert queries while maintaining high accuracy in predicting expert consensus across four real-world image classification tasks

## Executive Summary
This paper introduces a Bayesian framework for online querying and prediction of correlated human expert labels, leveraging pre-trained classifier outputs. The method models expert correlation via a joint latent representation, enabling simulation-based inference about query utility and posterior distributions over unobserved expert labels. By intelligently selecting which expert to query next based on information gain, the framework achieves 0% error with fewer queries on average compared to baselines, demonstrating well-calibrated uncertainty estimates and effective exploration-exploitation trade-offs.

## Method Summary
The approach uses a hierarchical Bayesian model where classifier logits and expert votes are jointly modeled through a multivariate normal latent representation. Expert labels are treated as noisy observations of these latent preferences, with correlation between experts captured through the covariance structure. Online inference proceeds by sampling from the posterior distribution over latent variables given observed classifier outputs and queried expert labels. At each step, the framework computes the expected information gain from querying each remaining expert and selects the one that maximizes expected reduction in entropy about the consensus label.

## Key Results
- Achieves 0% error with fewer queries on average compared to baselines across all four datasets
- Maintains expected calibration error (ECE) below 0.01, indicating well-calibrated uncertainty estimates
- Demonstrates robust performance across diverse image classification tasks (ChestX-Ray, Chaoyang, CIFAR-10H, ImageNet-16H) with varying class counts and expert numbers

## Why This Works (Mechanism)
The method works by jointly modeling the relationship between pre-trained classifiers and human experts through a shared latent space. By capturing correlations between experts, the framework can reason about redundancy in information and avoid querying experts who provide similar information. The Bayesian treatment naturally incorporates uncertainty about expert reliability and correlation structure, allowing for principled exploration-exploitation trade-offs. The simulation-based approach to computing query utility enables sophisticated decision-making beyond simple uncertainty sampling.

## Foundational Learning
- **Multivariate normal modeling:** Needed to capture correlations between multiple experts and classifiers; check by verifying positive definiteness of estimated covariance matrices
- **Additive logistic transformation:** Converts classifier probabilities to unbounded logits for joint modeling; check by ensuring inverse softmax correctly recovers probabilities
- **Bayesian hierarchical modeling:** Allows sharing of statistical strength across experts and classifiers; check by examining posterior distributions for appropriate shrinkage
- **Simulation-based inference:** Computes expected utility through Monte Carlo integration; check by monitoring convergence of utility estimates
- **Information-theoretic query selection:** Uses entropy reduction as objective; check by verifying that selected queries consistently reduce posterior entropy
- **Online Bayesian updating:** Maintains current beliefs as new evidence arrives; check by tracking posterior evolution across queries

## Architecture Onboarding

### Component Map
Classifier logits -> Bayesian model (latent z) -> Expert query selection -> Observed expert label -> Posterior update -> Consensus prediction

### Critical Path
1. Preprocess classifier outputs and expert labels
2. Initialize Bayesian model with priors
3. For each example: sample posterior, select expert, query, update
4. Aggregate expert labels to consensus
5. Evaluate accuracy and query count

### Design Tradeoffs
- **Full vs. diagonal covariance:** Full covariance captures correlations but scales poorly; diagonal is efficient but misses important dependencies
- **Temperature parameter:** Controls expert noise level; too low causes overconfidence, too high causes underconfidence
- **MCMC vs. variational inference:** MCMC provides accurate posteriors but is computationally expensive; variational inference is faster but may underestimate uncertainty
- **Deterministic vs. stochastic query selection:** Deterministic selection is faster but may get stuck in local optima; stochastic allows exploration but adds variance

### Failure Signatures
- MCMC chains not mixing: High R-hat values (>1.01) indicate convergence problems
- Poor calibration: High ECE (>0.02) suggests model mis-specification or insufficient temperature
- Excessive queries: Indicates failure to capture expert correlations or inappropriate utility function
- Singular covariance: Occurs when dimensionality is too high relative to observations

### First Experiments
1. Verify MCMC convergence on synthetic data with known correlation structure
2. Test query selection on simple 2-expert, 2-class problem with controlled correlations
3. Validate calibration by checking ECE on held-out test set with known consensus

## Open Questions the Paper Calls Out
- **Can structured covariance approximations (e.g., low-rank) effectively scale the framework to problems with a large number of classes or agents?** The current multivariate normal model becomes computationally prohibitive as dimensionality increases, and low-rank approximations could provide tractability while maintaining accuracy.
- **How does incorporating heterogeneous query costs for specific agents affect the optimal querying policy and overall cost savings?** The current implementation assumes uniform costs, but real-world settings often have varying costs that could significantly impact query strategies.
- **Can the framework be extended to accept "soft" confidence scores from human experts rather than just hard categorical votes?** Allowing probabilistic expert labels could capture more nuanced uncertainty, though this requires modifying the observation model.

## Limitations
- Covariance matrix inversion becomes computationally expensive as the number of classes and agents grows
- Assumes static expert correlations, not accounting for potential context-dependent variations
- Requires pre-trained classifier outputs, limiting applicability when such models are unavailable or domain-shifted

## Confidence
| Claim | Confidence |
|-------|------------|
| Outperforms baselines in query efficiency | High |
| Maintains well-calibrated uncertainty estimates | High |
| Bayesian framework effectively captures expert correlations | Medium |
| Method generalizes across diverse classification tasks | Medium |
| MCMC-based inference is practical for the tested problem sizes | Low |

## Next Checks
1. Verify MCMC convergence by checking R-hat values and trace plots across all experiments, ensuring values are within ±0.001 as reported
2. Test the effect of varying prior hyperparameters (σ_τ, σ_μ, η) on query efficiency and accuracy to confirm results are not sensitive to specific prior choices
3. Implement a synthetic dataset with known correlation structure to validate that the model correctly recovers correlations and accurately predicts consensus with minimal queries