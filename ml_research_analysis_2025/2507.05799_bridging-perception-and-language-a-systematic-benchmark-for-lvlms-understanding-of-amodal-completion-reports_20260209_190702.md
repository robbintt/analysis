---
ver: rpa2
title: 'Bridging Perception and Language: A Systematic Benchmark for LVLMs'' Understanding
  of Amodal Completion Reports'
arxiv_id: '2507.05799'
source_url: https://arxiv.org/abs/2507.05799
tags:
- llav
- completion
- categories
- images
- lvlms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates large vision-language models (LVLMs) on their\
  \ ability to understand amodal completion\u2014the perceptual phenomenon where occluded\
  \ parts of objects are mentally filled in\u2014using texts describing such experiences.\
  \ A benchmark (VACT) is created with questions classified via Basic Formal Ontology,\
  \ covering object types such as material entities, immaterial boundaries, and qualities."
---

# Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports

## Quick Facts
- arXiv ID: 2507.05799
- Source URL: https://arxiv.org/abs/2507.05799
- Authors: Amane Watahiki; Tomoki Doi; Taiga Shinozaki; Satoshi Nishida; Takuya Niikawa; Katsunori Miyahara; Hitomi Yanaka
- Reference count: 11
- One-line primary result: Commercial LVLMs achieve near-human accuracy on amodal completion understanding, but show category-specific weaknesses and Japanese evidentiality comprehension gaps

## Executive Summary
This study introduces VACT, a benchmark for evaluating large vision-language models (LVLMs) on amodal completion—the perceptual phenomenon where humans mentally complete occluded parts of objects. Using Basic Formal Ontology (BFO) for systematic classification, the benchmark tests models' understanding of text descriptions about completed objects. While commercial models like GPT-4o achieve 93% accuracy (near human baseline of 94%), they struggle with specific categories like color and boundary completion. A striking finding is that some models perform worse on original images than blank images in Japanese, suggesting difficulties interpreting the evidential use of Japanese perceptual verbs. This highlights critical gaps in cross-linguistic evidentiality awareness for multimodal AI systems.

## Method Summary
The study evaluates LVLMs using VACT, a benchmark with 122 validated 2AFC questions tagged with BFO categories covering material entities (objects, parts), immaterial boundaries (2D boundaries, sites), and qualities (color, shape). Models including GPT-4o, Claude 3.5 Sonnet, and LLaVA-NeXT variants are tested in zero-shot mode with both original and blank dummy images. Japanese and English prompts are used, with Japanese human participants (N=101) providing baseline accuracy of 94%. The evaluation examines accuracy by BFO category and compares performance between original and blank image conditions to diagnose visual-linguistic integration.

## Key Results
- Commercial LVLMs achieve near-human accuracy (93% GPT-4o, 94% human baseline) on overall amodal completion understanding
- Color completion emerges as a consistent challenge across all models, with accuracy dropping to 83-86%
- Some LLaVA-NeXT variants and Claude perform worse on original images than blank images specifically in Japanese, suggesting evidential verb comprehension difficulties
- LLaVA-NeXT-110B underperforms smaller variants in Japanese but not English, indicating language-specific deficiencies not resolved by scale
- Category-wise breakdown reveals material entities (objects, parts) are easier than immaterial boundaries and qualities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ontology-grounded classification reveals category-specific LVLM failures that coarse taxonomies miss
- Mechanism: Basic Formal Ontology (BFO) provides formally defined categories with explicit hierarchies, forcing benchmarks to cover distinct completion types rather than conflating them
- Core assumption: BFO categories map cleanly onto perceptual distinctions humans make during amodal completion
- Evidence anchors: [abstract] "benchmark grounded in Basic Formal Ontology to achieve a systematic classification"; [section: Proposed Dataset] "BFO provides clear definition...reducing ambiguity"
- Break condition: If BFO categories don't align with model-internal representations, diagnostic signal degrades to noise

### Mechanism 2
- Claim: Japanese evidential verbs create a language-specific competency gap in LVLMs
- Mechanism: The Japanese perceptual verb "mieru" grammaticalizes into an evidential marker (yoo-ni mieru), indicating visual evidence source while weakening literal "seeing" meaning
- Core assumption: The dummy-image superiority effect in Japanese stems specifically from evidential misinterpretation, not general Japanese language quality
- Evidence anchors: [abstract] "some LLaVA-NeXT variants and Claude perform worse on original images than on blank images in the Japanese setting, suggesting difficulty interpreting the evidential use of Japanese perceptual verbs"
- Break condition: If training data includes sufficient Japanese evidential constructions with visual context, the gap should narrow or disappear

### Mechanism 3
- Claim: Visual input can degrade performance when textual and visual cues conflict in subtle linguistic contexts
- Mechanism: Text-only inference relies on distributional priors—texts affirming AC are likely more common in training data. When original images are presented, visual processing adds signals that may conflict with nuanced linguistic interpretation
- Core assumption: Training data contains affirmative-AC bias (not directly measured)
- Evidence anchors: [section: Discussion, Hypothesis 1] "Texts affirming the existence of amodal completion appear more frequently in the training dataset than those denying it"
- Break condition: If visual AC capability improves, or evidential comprehension strengthens, original images should consistently outperform blanks

## Foundational Learning

- Concept: **Amodal completion (perceptual)**
  - Why needed here: Core phenomenon being evaluated; without understanding that humans perceive occluded parts as whole objects, the benchmark design and error patterns are unintelligible
  - Quick check question: In a photo of a cat behind a fence, why do you perceive "one cat" rather than "three orange horizontal strips"?

- Concept: **Evidentiality (linguistics)**
  - Why needed here: Explains the Japanese-specific anomaly; evidential markers indicate information source and can weaken literal lexical meaning, allowing paradoxical-seeming statements
  - Quick check question: How does "It seems to be raining" differ from "I see rain" in terms of evidential commitment?

- Concept: **Basic Formal Ontology (BFO) taxonomy**
  - Why needed here: Provides the classification scaffold; understanding independent vs. dependent continuants, material vs. immaterial entities, and quality subtypes is necessary to interpret category-wise results
  - Quick check question: Is "the color of an apple" an independent continuant or a dependent continuant, and why?

## Architecture Onboarding

- Component map: VACT benchmark (122 2AFC questions) -> BFO categorization (Mat/Imm/Qua -> Obj/Part/Bou/Site -> Col/Sha) -> Zero-shot prompting (original vs. blank images) -> Model inference -> Category-wise accuracy aggregation

- Critical path: 1) Image + prompt → model → answer selection; 2) Category-wise accuracy aggregation; 3) Original vs. blank comparison (diagnostic for visual contribution); 4) Error type classification (miscompletion vs. no-completion)

- Design tradeoffs:
  - BFO depth vs. coverage: Fine-grained categories reduce per-category sample sizes (12-54 questions), increasing variance
  - Japanese-only human eval: No English human baseline; model-human comparison valid only for Japanese
  - 2AFC format: Forces binary choice; may mask uncertainty calibration

- Failure signatures:
  - Blank > original accuracy in specific language-category combinations → evidential comprehension failure
  - High no-completion error rate when images shown → visual-linguistic conflict, model rejects AC description as incompatible with "seeing"
  - Larger model underperforming smaller variant (LLaVA-110B < 72B) → language-specific deficiency not fixed by scale

- First 3 experiments:
  1. Reproduce the Japanese evidential anomaly: Run VACT with Claude and LLaVA-72B in Japanese with original vs. blank images. Confirm that no-completion error rate increases with original images in boundary and color categories
  2. Isolate evidential construction: Create minimal pairs with "mieru" (evidential) vs. literal perception verbs; test if the blank>original effect tracks evidential usage specifically
  3. Cross-linguistic transfer check: Translate prompts to Korean (another language with grammaticalized evidentials) to test whether the pattern generalizes beyond Japanese

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do some LVLMs (LLaVA-NeXT variants, Claude 3.5 Sonnet) achieve higher accuracy on blank images than on original images specifically in Japanese, but not in English?
- Basis in paper: [explicit] The authors explicitly note this anomaly and hypothesize it stems from difficulty interpreting the evidential use of the Japanese perceptual verb "mieru," which functions as an evidential marker when combined with "yooda."
- Why unresolved: The paper proposes Hypothesis 3 but does not empirically validate whether models fail to recognize evidential usage versus having visual processing limitations
- What evidence would resolve it: Controlled experiments isolating evidential comprehension, such as testing models on sentences with "mieru" in evidential vs. non-evidential contexts without images, or comparing performance across languages with grammaticalized vs. non-grammaticalized evidentials

### Open Question 2
- Question: What causes color completion to be consistently challenging across all LVLMs, including commercial models like GPT-4o (86%) and Claude (83%)?
- Basis in paper: [explicit] The authors highlight that "color completion emerging as a consistent challenge across all models" and note this finding is "critical for deploying LVLM-based systems in real-world scenarios."
- Why unresolved: The paper identifies the weakness but does not investigate whether it stems from limited color representation in training data, difficulties inferring occluded color properties, or other factors
- What evidence would resolve it: Ablation studies varying color vs. shape completion with controlled stimuli, or analysis of attention patterns when models process color-related amodal completion descriptions

### Open Question 3
- Question: How can cross-linguistic differences in evidentiality (grammaticalized in Japanese, lexical in English) be addressed to improve LVLMs' interpretation of perceptual experience descriptions?
- Basis in paper: [inferred] The authors state that "the diversity of evidential expressions across languages may pose a considerable challenge for LVLMs" and identify this as "an important direction for future research."
- Why unresolved: The paper documents the problem but does not propose or test solutions for improving multilingual reasoning about perceptual experiences
- What evidence would resolve it: Comparative evaluations across additional languages with different evidential systems, or fine-tuning experiments targeting evidential comprehension in multimodal contexts

## Limitations
- The VACT dataset itself is not publicly released, making independent validation difficult without recreating the benchmark from scratch
- Training data bias toward affirmative AC descriptions is hypothesized but not empirically verified, leaving the blank>original effect's cause ambiguous
- English human baseline is absent, limiting cross-linguistic performance comparison
- BFO taxonomy alignment with LVLM internal representations remains an assumption without direct validation
- Japanese-specific evidentiality effect requires further controlled probing to isolate from general Japanese language quality issues

## Confidence
- High: Commercial LVLMs achieve near-human accuracy overall on amodal completion understanding
- Medium: Ontology-grounded classification reveals category-specific failure patterns
- Low: Japanese evidential verb comprehension gap is the primary driver of blank>original anomaly (alternative explanations not fully excluded)

## Next Checks
1. Replicate the Japanese evidential anomaly by running VACT with Claude and LLaVA-72B in both Japanese original vs. blank conditions, specifically measuring no-completion error rates in boundary and color categories
2. Create minimal pairs contrasting evidential "mieru" with literal perception verbs to test if the blank>original effect specifically tracks evidential usage
3. Translate VACT prompts to Korean (another language with grammaticalized evidentials) to test whether the blank>original pattern generalizes beyond Japanese