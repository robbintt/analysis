---
ver: rpa2
title: 'SMoFi: Step-wise Momentum Fusion for Split Federated Learning on Heterogeneous
  Data'
arxiv_id: '2511.09828'
source_url: https://arxiv.org/abs/2511.09828
tags:
- smofi
- momentum
- learning
- global
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SMoFi introduces a step-wise momentum fusion framework to address
  gradient divergence in split federated learning with non-IID data. The method synchronizes
  momentum buffers across server-side optimizers at each optimization step, imposing
  consistent constraints on weight updates to improve convergence stability.
---

# SMoFi: Step-wise Momentum Fusion for Split Federated Learning on Heterogeneous Data

## Quick Facts
- **arXiv ID:** 2511.09828
- **Source URL:** https://arxiv.org/abs/2511.09828
- **Reference count:** 40
- **Primary result:** Improves global model accuracy by up to 7.1% and accelerates convergence by up to 10.25× on non-IID split federated learning

## Executive Summary
SMoFi introduces a step-wise momentum fusion framework to address gradient divergence in split federated learning (SFL) with non-IID data. The method synchronizes momentum buffers across server-side optimizers at each optimization step, imposing consistent constraints on weight updates to improve convergence stability. A staleness-aware alignment mechanism maintains effectiveness as training progresses and client participation varies. Extensive experiments demonstrate that SMoFi significantly outperforms baseline methods across multiple datasets and model architectures.

## Method Summary
SMoFi operates in split federated learning where a model is partitioned between client and server. At every local step, the server computes aligned momentum by averaging momentum buffers from all active clients, weighted by their dataset sizes. This aligned momentum is used to update all server-side surrogate models simultaneously, ensuring consistent optimization directions. The method also maintains historical momentum buffers from clients who have finished their local steps, weighted by a polynomial staleness factor to handle varying participation rates. The framework works with both standard momentum SGD and adaptive optimizers like Adam by fusing their respective momentum components.

## Key Results
- Achieves up to 7.1% higher global model accuracy compared to standard SFL baselines
- Accelerates convergence by up to 10.25× in terms of rounds-to-accuracy
- Maintains effectiveness as client count increases, with greater benefits for larger systems
- Outperforms both sequential (SFLV2) and unconstrained parallel (SFLV1) approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Synchronizing momentum buffers across server-side optimizers at every optimization step mitigates weight update inconsistency caused by non-IID data.
- **Mechanism:** In SFL, the server maintains surrogate models for each client. Usually, these models accumulate momentum independently, pushing them toward divergent local optima. SMoFi replaces the independent momentum term with an aligned momentum term calculated as the weighted average of all active server-side momentum buffers. This aligns the optimization trajectories of the surrogate models before weight aggregation occurs.
- **Core assumption:** The primary driver of performance degradation in SFL under non-IID data is the inconsistent optimization direction across clients, which can be corrected by imposing a consistent velocity vector (momentum) server-side.
- **Evidence anchors:**
  - [abstract] "...synchronizing the momentum buffers across server-side optimizers."
  - [section 2.2] Equation 4 reformulates the update rule to use aligned momentum.
  - [corpus] Related work "Local Gradient Regulation" supports the premise that client heterogeneity destabilizes learning.

### Mechanism 2
- **Claim:** A staleness-aware alignment mechanism maintains the effectiveness of momentum fusion as active clients drop out during a round.
- **Mechanism:** Clients finish local steps at different times. If SMoFi only averaged currently active buffers, the "active set" size would shrink to zero, breaking the alignment constraint. SMoFi maintains a historical record of final momentum buffers from finished clients, fusing them with current ones using a polynomial staleness factor, ensuring the denominator of the alignment equation remains constant.
- **Core assumption:** Historical momentum vectors retain relevant directional information for ongoing updates, provided they are decayed appropriately by the staleness factor.
- **Evidence anchors:**
  - [abstract] "...staleness-aware alignment mechanism that imposes constraints... as client participation varies."
  - [section 2.2] Equation 5 defines the fusion of current and historical momentum buffers using $s_\alpha$.
  - [corpus] Corpus evidence for specific "staleness-aware momentum" in SFL is weak.

### Mechanism 3
- **Claim:** Parallel updating of server-side surrogates with step-wise constraints improves convergence speed over sequential updating and accuracy over unconstrained parallel updating.
- **Mechanism:** Standard SFLV1 updates surrogates in parallel but only aggregates weights periodically, allowing divergence. SFLV2 aggregates sequentially (slow). SMoFi retains the parallel structure of SFLV1 for system efficiency but adds the "tight, synchronous" constraint of momentum alignment at every step, approximating the consistency of sequential training without the latency.
- **Core assumption:** The server has sufficient compute to manage parallel surrogates and the communication bandwidth allows for frequent (step-wise) synchronization signals without creating a new bottleneck.
- **Evidence anchors:**
  - [section 2.2] Figure 2 visualizes the difference between SFLV1, SFLV2, and SMoFi.
  - [table 2] Shows SMoFi achieves higher accuracy than SFLV1 and lower wall-clock time than SFLV2.

## Foundational Learning

- **Concept: Split Federated Learning (SFL)**
  - **Why needed here:** SMoFi is specifically designed for the SFL architecture where a model is split at a cut layer $L$. Understanding the difference between client-side and server-side submodels is required to grasp why momentum fusion only happens on the server side.
  - **Quick check question:** In SFLV1, does the server aggregate weights after every local step or every round? (Answer: Usually every round or epoch, SMoFi modifies this logic for momentum).

- **Concept: Stochastic Gradient Descent with Momentum (SGDM)**
  - **Why needed here:** The core innovation is manipulating the momentum buffer rather than just the weights. You must understand that momentum accumulates past gradients to smooth the trajectory.
  - **Quick check question:** Why does standard momentum hurt convergence on non-IID data in FL? (Assumption: It accelerates movement toward distinct local optima, increasing divergence).

- **Concept: Data Heterogeneity (Non-IID)**
  - **Why needed here:** The paper uses a Dirichlet distribution $Dir(\gamma)$ to simulate non-IID data. The mechanism is a direct response to the gradient conflict caused by different data distributions $D_j$.
  - **Quick check question:** What does a smaller concentration parameter $\gamma$ (e.g., 0.2 vs 0.5) imply about the data distribution? (Answer: Higher heterogeneity/imbalance).

## Architecture Onboarding

- **Component map:**
  - **Client:** Holds shallow submodel $f_{W_c}$. Computes activations $A$ and client-side gradients.
  - **Server:** Holds deep submodels $f_{W_s}$ (surrogates).
  - **SMoFi Module:** Resides on the server. Manages momentum buffers, history buffer, and alignment logic.

- **Critical path:**
  1. **Forward:** Client sends activations $A$ to Server.
  2. **Backward:** Server computes gradients.
  3. **Fusion (SMoFi):** Server computes aligned momentum $\bar{m}_s$ using current + historical buffers.
  4. **Update:** Server updates surrogates $W_s$ using $\bar{m}_s$ (not local $m$).
  5. **Cleanup:** If client finishes, save its momentum to history.

- **Design tradeoffs:**
  - **Staleness Factor ($\alpha$):** Default is -0.1. Larger $\alpha$ preserves history but might slow adaptation; smaller $\alpha$ ignores history, risking instability as active set shrinks.
  - **Cut Layer ($L$):** Shallow cut increases SMoFi's impact (more parameters to align). Deep cut reduces server load but diminishes effectiveness.

- **Failure signatures:**
  - **Convergence Plateau:** If accuracy is lower than baselines, check staleness logic. If history isn't cleared between rounds or is weighted incorrectly, stale gradients dominate.
  - **Divergence on IID Data:** If SMoFi performs worse on IID data compared to FedAvg, the alignment constraint might be too aggressive for already consistent data.

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Implement SFLV1 with standard SGDM on CIFAR-10 with Dir(0.2). Verify accuracy is lower than FedAvg (establishing the divergence problem).
  2. **Ablation on Staleness:** Implement SMoFi with $\alpha=0$ (no history) vs. $\alpha=-0.1$ (default). Plot "active client count" vs. "global accuracy" to see if no-history version degrades as clients finish early.
  3. **Scalability Stress Test:** Run SMoFi with 100 clients and then 10 clients. Verify "round-to-accuracy" speedup increases with client count to ensure parallel synchronization overhead is handled correctly.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the staleness factor $\alpha$ be adaptively adjusted during training to optimize the trade-off between current and historical momentum, rather than relying on a fixed hyperparameter?
- **Basis in paper:** Figure 3 demonstrates that the choice of the staleness factor $\alpha$ significantly impacts the trade-off between convergence speed and final accuracy, leading the authors to select a fixed $\alpha = -0.1$ as a compromise.
- **Why unresolved:** The paper relies on a static polynomial staleness function; it does not explore mechanisms to dynamically tune $\alpha$ in response to changing gradient variances or client participation patterns during training.
- **What evidence would resolve it:** An ablation study showing that an adaptive schedule for $\alpha$ consistently outperforms the fixed baseline across various heterogeneity settings.

### Open Question 2
- **Question:** Does SMoFi maintain its performance advantage under pathological data heterogeneity (e.g., single-class clients) where local optimization trajectories may be orthogonal?
- **Basis in paper:** The experiments utilize Dirichlet distributions ($\gamma=0.2$) to simulate heterogeneity, but do not evaluate the "pathological" non-IID setting (e.g., 1 class per client) often used to stress-test FL methods.
- **Why unresolved:** The effectiveness of SMoFi relies on the assumption that synchronizing momentum buffers reduces divergence. If client data distributions are completely disjoint, aligning momentum might introduce noise rather than beneficial constraints.
- **What evidence would resolve it:** Experimental results on a pathological non-IID split comparing SMoFi against standard SFL and FedAvgM baselines.

### Open Question 3
- **Question:** Does step-wise momentum fusion provide theoretical convergence guarantees for adaptive optimizers like Adam, given that the current analysis is restricted to SGDM?
- **Basis in paper:** Theorem 3.5 provides a convergence bound specifically for Momentum SGD ($O(1/N)$), but Figure 4 empirically evaluates SMoFi with Adam and AdamW without providing theoretical justification for these adaptive methods.
- **Why unresolved:** Adaptive methods handle momentum and variance differently. It is unclear if the step-wise fusion of first-order moments conflicts with the adaptive learning rate adjustments of Adam-based optimizers.
- **What evidence would resolve it:** A formal convergence analysis extending the proof to adaptive optimizers, or an empirical study showing that fusing both first- and second-moment estimates does not destabilize the learning rate scaling.

## Limitations
- Performance degrades when the model split moves deeper into the network, limiting the effective range of the method.
- The staleness factor $\alpha=-0.1$ is fixed without sensitivity analysis for highly dynamic participation scenarios.
- The paper does not explore adaptive mechanisms for tuning the staleness factor during training.

## Confidence
- **Mechanism 1 (Momentum Alignment):** High confidence - clear mathematical formulation and direct experimental support.
- **Mechanism 2 (Staleness-Aware Alignment):** Medium confidence - well-defined algorithm but limited direct evidence in SFL literature.
- **Mechanism 3 (Parallel vs Sequential Trade-off):** High confidence - strong empirical results in Table 2 support the claimed improvements.

## Next Checks
1. **Staleness Ablation Study:** Implement SMoFi with $\alpha=0$ (ignore history) and $\alpha=-0.5$ (aggressive decay). Measure if accuracy drops significantly as client count increases.
2. **Split Point Sensitivity:** Re-run CIFAR-10 experiment with cut layer $L$ moved deeper (e.g., $L=4$ or $L=6$). Quantify degradation in SMoFi's relative performance.
3. **IID Data Baseline:** Run SMoFi on CIFAR-10 with $Dir(0.5)$ or IID data. Verify the method does not harm convergence speed or accuracy when heterogeneity is reduced.