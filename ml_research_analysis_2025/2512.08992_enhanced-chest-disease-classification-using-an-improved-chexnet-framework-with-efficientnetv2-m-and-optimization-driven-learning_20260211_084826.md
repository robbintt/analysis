---
ver: rpa2
title: Enhanced Chest Disease Classification Using an Improved CheXNet Framework with
  EfficientNetV2-M and Optimization-Driven Learning
arxiv_id: '2512.08992'
source_url: https://arxiv.org/abs/2512.08992
tags:
- learning
- chest
- training
- classification
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents an improved chest disease classification framework
  using EfficientNetV2-M with advanced optimization techniques including AdamW, cosine
  annealing, automatic mixed precision, and exponential moving average. This approach
  addresses limitations in the original CheXNet architecture, which used DenseNet-121
  and exhibited computational inefficiency and poor single-label classification performance.
---

# Enhanced Chest Disease Classification Using an Improved CheXNet Framework with EfficientNetV2-M and Optimization-Driven Learning

## Quick Facts
- arXiv ID: 2512.08992
- Source URL: https://arxiv.org/abs/2512.08992
- Reference count: 0
- Test accuracy: 96.45%, macro-averaged F1-score: 91.08%

## Executive Summary
This study presents an improved chest disease classification framework that addresses limitations in the original CheXNet architecture. By replacing DenseNet-121 with EfficientNetV2-M and incorporating advanced optimization techniques including AdamW, cosine annealing, automatic mixed precision, and exponential moving average, the model achieves superior performance on five-class chest X-ray classification. The framework demonstrates 96.45% test accuracy and 91.08% macro-averaged F1-score while reducing training time by 11.4% compared to the baseline, despite having 6.8 times more parameters.

## Method Summary
The method employs EfficientNetV2-M as the backbone architecture with ImageNet pre-trained weights, replacing the original DenseNet-121. The model uses a single fully connected layer for 5-class classification (Cardiomegaly, COVID-19, Normal, Pneumonia, Tuberculosis). Training incorporates AdamW optimizer with cosine annealing learning rate schedule, automatic mixed precision for computational efficiency, and exponential moving average for weight smoothing. The dataset consists of 18,080 balanced chest X-ray images (3,616 per class) constructed from NIH ChestX-ray8, COVID-19 Radiography Database, and TB Chest X-ray Database using a two-stage balancing strategy of undersampling the dominant Normal class and augmenting minority classes.

## Key Results
- Achieved 96.45% test accuracy and 91.08% macro-averaged F1-score on five-class chest disease classification
- Near-perfect classification for COVID-19 (99.95%) and tuberculosis (99.97%)
- Reduced training time by 11.4% compared to DenseNet-121 baseline despite 6.8x more parameters
- Improved performance stability by 22.7% through EMA regularization

## Why This Works (Mechanism)

### Mechanism 1: EfficientNetV2-M Architectural Optimization
Replacing DenseNet-121 with EfficientNetV2-M improves the accuracy-efficiency trade-off through architectural innovations. The model uses Fused-MBConv blocks in early stages (Stages 1-3) that replace depthwise separable convolutions with regular 3x3 convolutions, reducing memory access overhead and accelerating training. Squeeze-and-Excitation modules in later stages (Stages 4-6) perform adaptive channel-wise feature recalibration, amplifying diagnostically relevant features while suppressing noise. This architecture leverages ImageNet pre-trained features transferable to chest X-ray gray-scale images.

### Mechanism 2: Optimization-Driven Regularization (AdamW + EMA)
The combination of AdamW and Exponential Moving Average stabilizes training and improves generalization on the medical dataset. AdamW decouples weight decay from the gradient update, preventing regularization from being tied to the learning rate and leading to better convergence. EMA maintains a shadow copy of model weights as an exponential moving average of trained weights, and using these smoothed weights during validation acts as ensemble-like regularization, reducing noise and validation variance. This is particularly effective for the relatively small dataset of 18,080 images.

### Mechanism 3: Class-Balanced Single-Label Focus
The framework addresses single-label classification limitations by converting the problem into a mutually exclusive 5-class task on a balanced dataset. By undersampling the dominant Normal class (60k -> 3.6k) and augmenting minority classes, the model learns discriminative features for rare diseases (TB, Cardiomegaly) rather than biasing toward the majority. This approach improves macro-averaged metrics but risks "Normal" class confusion due to lost variance from aggressive undersampling.

## Foundational Learning

- **Concept:** Transfer Learning & Fine-Tuning
  - **Why needed here:** The dataset (18k images) is too small to train a 6.8x parameter model from scratch without severe overfitting. The paper relies on ImageNet1K pre-training.
  - **Quick check question:** Are you freezing the backbone or training end-to-end? (This paper trains end-to-end).

- **Concept:** Macro-Averaged F1-Score
  - **Why needed here:** Accuracy is misleading in class-imbalanced medical data. The paper balances the dataset, but Macro-F1 ensures we verify performance on all disease classes equally, not just the majority.
  - **Quick check question:** If the model achieves 96% accuracy but misses all TB cases, is it successful? (Macro-F1 would drop significantly).

- **Concept:** Automatic Mixed Precision (AMP)
  - **Why needed here:** Training deep models (EfficientNetV2-M) is computationally expensive. AMP allows faster training by using float16 for math and float32 for stability.
  - **Quick check question:** Does your GPU have Tensor Cores? (Required for AMP speedup).

## Architecture Onboarding

- **Component map:** Input (224x224) -> EfficientNetV2-M Backbone (Fused-MBConv -> MBConv-SE) -> Global Average Pooling -> FC Layer (1280 -> 5) -> Softmax. Auxiliary Components: AdamW Optimizer, Cosine Annealing Scheduler, AMP Scaler, EMA Shadow Weights.

- **Critical path:**
  1. Data Prep: Implement the 2-stage balancing (Undersample Normal, Augment others) exactly as described.
  2. Initialization: Load ImageNet weights for backbone; Random/He init for the FC head.
  3. Training Loop: Forward pass (AMP enabled) -> Loss Calc -> Backward (Scaled) -> Optimizer Step (AdamW) -> Update EMA weights.
  4. Validation: Switch model to evaluation mode; replace current weights with EMA shadow weights for metric calculation.

- **Design tradeoffs:**
  - Accuracy vs. Stability: The paper trades higher parameter count (6.8x larger than DenseNet) for better stability/accuracy, assuming access to decent hardware (Tesla T4).
  - Information Loss: Undersampling "Normal" class improves recall for diseases but lowers "Normal" precision (confusion matrix shows 12% false positives for Normal).

- **Failure signatures:**
  - "Normal" Collapse: If validation accuracy stalls at 20% (random guessing), check if the dataset balancing failed (model predicting only majority class).
  - EMA Lag: If EMA validation loss is worse than raw model loss, the EMA decay rate (0.999) might be too high for a short training run.
  - AMP Overflow: If loss becomes NaN, reduce the initial learning rate or check AMP dynamic scaling logic.

- **First 3 experiments:**
  1. Baseline Replication: Run the DenseNet-121 baseline on the balanced dataset to verify the 95.30% accuracy benchmark locally.
  2. Ablation (Optimizer): Run EfficientNetV2-M with standard Adam vs. AdamW to isolate the impact of decoupled weight decay on convergence speed.
  3. Ablation (Architecture): Run EfficientNetV2-M without the SE modules or Fused-MBConv to validate the specific architectural claims vs. the optimization tricks.

## Open Questions the Paper Calls Out

### Open Question 1
How does the EfficientNetV2-M framework perform on external validation across diverse hospitals, geographic regions, and imaging equipment not represented in the training data? The study used only three source datasets; no external institutional validation was conducted to assess real-world generalizability. Prospective multi-center validation across geographically diverse hospitals with varying imaging protocols, reporting performance metrics stratified by institution and population demographics, would resolve this.

### Open Question 2
Can the framework be extended to multi-label classification for concurrent pathologies without degrading single-label performance? The current architecture and loss function are designed exclusively for single-label tasks; multi-label capability was not explored. A multi-label variant trained and evaluated on datasets with co-occurring disease labels, comparing per-class F1-scores against the single-label baseline, would provide evidence.

### Open Question 3
What explainability mechanisms can be integrated to provide clinically interpretable justifications for model predictions? The study focused on predictive performance; no interpretability methods were implemented or evaluated. Integration of attention visualization or uncertainty estimation with radiologist evaluation of whether highlighted regions correspond to clinically relevant pathological features would address this.

## Limitations

- The paper does not specify batch size, exact preprocessing pipeline, or random seed settings for deterministic reproducibility.
- The claim that EMA "increased performance stability by 22.7%" lacks a clear definition of how stability is quantified.
- The dataset balancing strategy (undersampling Normal class) may discard potentially useful variance, potentially harming "Normal" classification at deployment.
- The 6.8x parameter increase versus DenseNet-121 could impact deployment feasibility in resource-constrained settings.

## Confidence

- **High Confidence:** Test accuracy (96.45%) and macro-F1 (91.08%) metrics, as these are standard and verifiable outputs from a trained model.
- **Medium Confidence:** The claim that EfficientNetV2-M reduces training time by 11.4% versus DenseNet-121, assuming similar hardware and implementation quality.
- **Low Confidence:** The claim that EMA "increased performance stability by 22.7%" without a clear definition of the stability metric used.

## Next Checks

1. Replicate the ablation study: Train EfficientNetV2-M with standard Adam versus AdamW on the same balanced dataset to isolate the impact of decoupled weight decay.
2. Implement and test the exact 2-stage balancing strategy (undersample Normal to 3,616, augment others) to confirm the target 18,080-image balanced dataset.
3. Run a diagnostic experiment to quantify the effect of EMA on validation stability: Compare validation loss variance over epochs with and without EMA weight averaging.