---
ver: rpa2
title: 'EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection'
arxiv_id: '2512.11506'
source_url: https://arxiv.org/abs/2512.11506
tags:
- claim
- greenwashing
- company
- knowledge
- claims
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EmeraldMind is a knowledge graph-augmented framework for greenwashing
  detection. It builds the EmeraldGraph knowledge graph from ESG reports to provide
  domain-specific context for fact-checking sustainability claims.
---

# EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection

## Quick Facts
- arXiv ID: 2512.11506
- Source URL: https://arxiv.org/abs/2512.11506
- Reference count: 40
- EmeraldMind achieves 62-77% coverage while maintaining 85-93% accuracy, outperforming generic LLM baselines.

## Executive Summary
EmeraldMind addresses the challenge of detecting greenwashing in corporate sustainability claims by leveraging a domain-specific knowledge graph augmented with ESG report evidence. The framework constructs the EmeraldGraph knowledge graph from parsed ESG reports to provide structured, verifiable context for fact-checking sustainability claims. By combining schema-based subgraph extraction with document retrieval and employing a hybrid LLM-as-a-judge approach, EmeraldMind demonstrates superior performance in identifying deceptive environmental claims while maintaining high accuracy and coverage rates.

## Method Summary
EmeraldMind operates in two stages: evidence store construction and knowledge-powered reasoning. The system parses ESG reports using PyMuPDF and a Vision Language Model to extract entities and relations, then populates a labeled property graph (EmeraldGraph) and vector store (EmeraldDB) with company-specific ESG data. For reasoning, claims are grounded to target companies, and evidence is retrieved through schema-based subgraph extraction (k-hop traversal filtered by entity types) and document retrieval. Three variants exist: EM-KGRAG (graph-only), EM-RAG (document-only), and EM-HYBRID (LLM judge selects between the two). The framework uses gemma-27b-it for classification, prometheus-7b-v2.0 as judge, and prometheus-13b-v1.0 for justification quality evaluation.

## Key Results
- EmeraldMind variants achieve 62-77% coverage while maintaining 85-93% accuracy on semi-synthetic claims.
- EM-HYBRID achieves the highest overall accuracy (up to 70.59%) by combining graph and document evidence.
- LLM-based justification quality evaluation shows EmeraldMind consistently produces more informative, logical, and accurate explanations than baselines.

## Why This Works (Mechanism)

### Mechanism 1
Schema-based subgraph extraction improves evidence relevance over naive neighborhood expansion by grounding claims to target companies and key claim elements (KPIs, numeric values, goals), then performing bounded k-hop traversal filtered by entity type and embedding similarity. Shortest paths between the company anchor and retrieved nodes form reasoning chains rather than disconnected facts. Core assumption: ESG claims can be reliably decomposed into schema-mappable entities, and relevant evidence lies within k-hop neighborhoods of the grounded company node.

### Mechanism 2
Hybrid retrieval combining graph evidence and document chunks yields higher overall accuracy than either source alone by using LLM-as-a-judge to compare justifications from graph-derived and document-derived sources, selecting the superior justification and its associated verdict. This leverages graph precision for structured KPIs and document coverage for contextual narrative. Core assumption: Justification quality correlates with classification accuracy, and LLM judge preferences align with ground truth.

### Mechanism 3
Domain-specific knowledge stores enable higher coverage while maintaining accuracy compared to generic LLM baselines by capturing company-specific ESG entities (KPIs, facilities, goals) absent from generic KBs and preserving provenance metadata. Retrieval is restricted to company-matching chunks/nodes, reducing noise and grounding verdicts in verifiable sources. Core assumption: ESG reports contain sufficient evidence to assess most claims; company-scoped retrieval improves signal-to-noise ratio.

## Foundational Learning

- **Property graphs with typed schemas**: EmeraldGraph uses a labeled property graph with entity types, relation types, and attribute domains to enforce structural constraints during population and retrieval. Quick check: Given a node with τ(v) = Facility, what schema constraint prevents it from having a "reportsKPI" edge directly?

- **Embedding-based similarity search with thresholding**: Schema-based retrieval ranks candidate nodes by cosine similarity between node embeddings and claim-derived key elements, filtering by threshold before path computation. Quick check: What happens to retrieval precision if threshold τ is set too low (e.g., 0.1)?

- **Responsible abstention in classification**: EmeraldMind explicitly supports an "abstain" verdict when evidence is insufficient, avoiding ungrounded predictions that undermine trust. Quick check: How does high abstention rate affect the "overall accuracy" metric defined as accuracy × coverage?

## Architecture Onboarding

- **Component map**: Information Extraction (PDF parser + VLM) → Schema Extraction (data-driven + regulatory + claim-driven) → Knowledge Population (EmeraldGraph + EmeraldDB) → Claim Grounding → (parallel) Schema-Based Context Retrieval (EmeraldGraph) + Document Retrieval (EmeraldDB) → Classification & Justification (EM-KGRAG / EM-RAG / EM-HYBRID)

- **Critical path**: Claim grounding to schema-based retrieval is the bottleneck—if company entity linking fails, subsequent retrieval returns empty or irrelevant subgraphs.

- **Design tradeoffs**: Graph-only (EM-KGRAG) offers higher accuracy on structured claims but lower coverage (49-60%); Document-only (EM-RAG) provides higher coverage (62-77%) but slightly lower accuracy; Hybrid (EM-HYBRID) achieves best overall accuracy but requires running both pipelines and LLM judge inference.

- **Failure signatures**: High abstention rate (>50%) suggests schema mismatch or missing ESG reports for queried companies; low justification ILORA scores (readability/logicality <3) indicate retrieval returning irrelevant chunks or disconnected graph paths; claim grounding failures manifest as "company not found" errors or incorrect entity type assignments.

- **First 3 experiments**: (1) Reproduce claim grounding accuracy by sampling 20 claims and manually verifying company node linking and KPIObservation extraction against ground truth; (2) Ablate retrieval parameters by varying k-hop depth (1, 2, 3) and top-n nodes per type (1, 3, 5) on held-out claims to measure precision/recall tradeoffs; (3) Probe abstention boundary by identifying claims where EM-HYBRID abstains and analyzing whether missing evidence is due to schema gaps, report unavailability, or retrieval threshold misconfiguration.

## Open Questions the Paper Calls Out

- **How do specific graph retrieval strategies, such as varying hop limits and schema constraints, quantitatively influence detection performance and context efficiency?**: Section 8 explicitly states future work should investigate how graph retrieval strategies influence performance. This remains unresolved because the current implementation uses fixed heuristics without ablation studies on how these hyperparameters affect the trade-off between retrieval noise and evidence completeness.

- **Can alternative fusion techniques for integrating textual and graph evidence yield higher accuracy than the current LLM-as-a-judge verifier?**: Section 8 proposes to explore alternative hybrid methods for integrating textual and graph evidence. The current EM-HYBRID approach selects the "best" output from two separate pipelines rather than fusing the evidence itself, potentially missing synergistic reasoning opportunities.

- **Does the framework's high performance on semi-synthetic claims generalize to complex, legally verified real-world greenwashing instances?**: Section 6 notes the scarcity of real-world benchmarks, necessitating the creation of the "EmeraldData" semi-synthetic dataset, while Section 7 shows the "GreenClaims" real-world subset is very small (51 samples). Synthetic claims may lack the linguistic ambiguity or subtle deception tactics found in actual corporate communications.

## Limitations
- Framework's reliance on semi-synthetic claims and limited dataset (620 claims) raises concerns about generalizability to real-world greenwashing scenarios.
- Study does not validate performance on claims requiring evidence beyond ESG reports, such as regulatory filings or news articles.
- LLM-based judge for hybrid selection introduces potential bias without clear criteria for handling contradictory evidence.

## Confidence
- **High**: Schema-based subgraph extraction improves evidence relevance
- **Medium**: Hybrid retrieval achieves highest accuracy
- **Low**: Domain-specific knowledge stores enable higher coverage while maintaining accuracy

## Next Checks
1. Test EmeraldMind on real-world greenwashing claims from diverse sources to assess robustness beyond semi-synthetic data.
2. Evaluate the LLM judge's bias by comparing its selections against human annotations for contradictory graph and document evidence.
3. Assess abstention patterns by analyzing claims where evidence is insufficient—determine if this stems from schema gaps, report unavailability, or retrieval misconfiguration.