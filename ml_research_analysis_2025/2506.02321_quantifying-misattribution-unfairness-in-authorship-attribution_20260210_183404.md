---
ver: rpa2
title: Quantifying Misattribution Unfairness in Authorship Attribution
arxiv_id: '2506.02321'
source_url: https://arxiv.org/abs/2506.02321
tags:
- authors
- authorship
- author
- attribution
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness in authorship attribution by introducing
  a measure of misattribution risk, the Misattribution Unfairness Index (MAUIk), which
  quantifies how often authors are incorrectly ranked in the top k results for texts
  they did not write. The authors evaluate five embedding-based authorship models
  on three datasets and find that all models exhibit high levels of unfairness, with
  some authors being misattributed at rates far exceeding random chance.
---

# Quantifying Misattribution Unfairness in Authorship Attribution

## Quick Facts
- **arXiv ID:** 2506.02321
- **Source URL:** https://arxiv.org/abs/2506.02321
- **Reference count:** 18
- **Primary result:** Introduced MAUIk metric showing all tested authorship models exhibit high unfairness, with some authors being misattributed far above random chance.

## Executive Summary
This paper addresses fairness in authorship attribution by introducing the Misattribution Unfairness Index (MAUIk), a metric that quantifies how often authors are incorrectly ranked in top-k results for texts they did not write. The authors evaluate five embedding-based authorship models on three datasets and find that all models exhibit high levels of unfairness, with some authors being misattributed at rates far exceeding random chance. They also show that authors closer to the centroid of the embedding space are at higher risk of misattribution. The findings highlight the need for fairness-aware evaluation and modeling in authorship attribution systems, especially for forensic or legal applications where misattribution can have serious consequences.

## Method Summary
The paper evaluates five embedding-based authorship attribution models (SBERT, LUAR, Wegmann, StyleDist, MPNetAR) on three datasets (Reddit, Blogs, Fanfiction). Each model embeds documents into vectors, and authors are represented by aggregating their document embeddings. For each query document, the system ranks all haystack authors by cosine similarity and logs which non-query authors appear in the top-k. MAUIk is computed by comparing the actual top-k appearances to the expected count under random assignment. The metric is normalized to range from 0 (fair) to 1 (maximally unfair).

## Key Results
- All five tested models exhibit high unfairness with MAUIk values significantly above 0
- No clear relationship exists between model accuracy (R@8, MRR) and fairness (MAUIk)
- Authors positioned closer to the centroid of the embedding space face systematically higher misattribution risk
- Embedding distribution shape mediates unfairness independent of model accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Authors positioned closer to the centroid of the embedding space face systematically higher misattribution risk.
- **Mechanism:** Query embeddings that are moderately distant from all authors tend to have higher cosine similarity with centroid-adjacent authors by geometric necessity—these "central" authors occupy a region that attracts more non-target queries.
- **Core assumption:** Queries are drawn randomly from the haystack population, so an author's average rank should not systematically correlate with their embedding position.
- **Evidence anchors:**
  - [abstract] "risk of misattribution is higher for authors closer to the centroid (or center) of the embedded authors"
  - [section 3.3] "We see strong correlations between authors' distance to the centroid and their risk of misattribution, as measured by their average rank over all queries"
  - [corpus] Limited direct corroboration; related work on fairness in retrieval (e.g., FairSHAP) addresses feature-level bias but not spatial embedding geometry.
- **Break condition:** If queries are highly non-random (e.g., always targeting outlier authors), the centroid effect could diminish or reverse.

### Mechanism 2
- **Claim:** Embedding distribution shape mediates unfairness, independent of model accuracy.
- **Mechanism:** Models that spread embeddings more uniformly (higher variance in distance-to-centroid) reduce the "gravitational pull" of central authors. Wegmann exhibits flatter distance distributions and lower MAUIk despite worse R@k.
- **Core assumption:** Distance-to-centroid variance approximates embedding space dispersion and collision probability.
- **Evidence anchors:**
  - [abstract] "unfairness relates to how the models embed the authors as vectors in the latent search space"
  - [section 3.3 + Figure 2] "distance distributions vary considerably across different models"
  - [corpus] No corpus papers directly analyze embedding geometry in authorship; gap in external validation.
- **Break condition:** If a model uses a non-cosine distance metric or projects to a non-Euclidean space, this relationship may not hold.

### Mechanism 3
- **Claim:** Accuracy and fairness are decoupled—high attribution accuracy does not guarantee fair misattribution distribution.
- **Mechanism:** Standard loss functions optimize for correct rankings without penalizing uneven misattribution burdens. A model can achieve high MRR by reliably ranking the true author high, while consistently misranking the same subset of "fall guy" authors.
- **Core assumption:** Loss functions do not encode fairness constraints.
- **Evidence anchors:**
  - [abstract] "all models exhibit high levels of unfairness with some authors being misattributed at rates far exceeding random chance"
  - [section 3.2] "no clear relationship between how good a model is in correctly attributing authors and how fair it is"
  - [corpus] Individual user fairness measures in recommender systems (e.g., "Measuring Individual User Fairness") similarly find accuracy-fairness tradeoffs.
- **Break condition:** If fairness-aware loss terms are added, this decoupling may weaken.

## Foundational Learning

- **Concept:** Cosine similarity ranking in embedding spaces
  - **Why needed here:** MAUIk and all attribution performance depend on cosine-based retrieval; understanding why central authors attract more queries requires geometric intuition.
  - **Quick check question:** If all author embeddings lie on a hypersphere, what happens to cosine similarity when a query lies exactly at the centroid?

- **Concept:** Recall@k and Mean Reciprocal Rank (MRR)
  - **Why needed here:** These are the baseline effectiveness metrics; MAUIk is designed to complement, not replace them.
  - **Quick check question:** If a system ranks the true author 2nd for 50% of queries and 1st for 50%, what is its MRR?

- **Concept:** Individual vs. group fairness
  - **Why needed here:** MAUIk is an individual fairness metric (each author should bear equal misattribution risk), not group fairness (demographic parity).
  - **Quick check question:** Could a system have low MAUIk (fair individually) but high group-level disparity? Under what conditions?

## Architecture Onboarding

- **Component map:** Encoder -> Author index -> Ranker -> MAUIk evaluator
- **Critical path:**
  1. Encode all haystack authors (average or pool their document embeddings).
  2. Encode query documents.
  3. Retrieve top-k via cosine similarity.
  4. Log which non-query authors appear in top-k.
  5. After Nq queries, compute MAUIk = Σ max(0, ck_j - Ek) / (k × (Nq - Ek)).

- **Design tradeoffs:**
  - **k selection:** Lower k (e.g., 5) is more sensitive to extreme unfairness; higher k (e.g., 20) captures broader distribution. Report multiple k.
  - **Author embedding aggregation:** Averaging documents per author smooths intra-author variance but may obscure stylistic range.
  - **Random vs. realistic queries:** Random queries provide a neutral fairness baseline; realistic query distributions (e.g., stylistically similar authors) may shift the "fair" reference.

- **Failure signatures:**
  - MAUIk ≈ 1.0: Same k authors ranked top for nearly all queries (severe collapse).
  - MAUIk ≈ 0.0 but low MRR: Model is "fairly bad"—ranks randomly.
  - High MAUIk + high MRR: Model is accurate but unfair; forensic deployment risk.

- **First 3 experiments:**
  1. **Reproduce MAUIk for all five models on Reddit subset:** Compute MAUIk@10 and plot author distance-to-centroid vs. mean rank. Verify Figure 1 correlation.
  2. **Ablate embedding aggregation:** Compare per-author mean vs. max-pooling of document embeddings; measure impact on MAUIk and MRR.
  3. **Test fairness-aware re-ranking:** Implement a simple penalty for authors who have already appeared in top-k frequently; trade MAUIk reduction against MRR loss.

## Open Questions the Paper Calls Out

- **Question:** How does the stylistic or demographic "relatedness" of query authors to haystack authors affect the baseline of fairness, compared to the random permutation baseline used in MAUI?
- **Basis in paper:** [explicit] The authors state in the Limitations section that the "anticipated 'fair' ranking... is not entirely random, but rather a function of authors' relatedness to the query," which is not accounted for in the current metric.
- **Why unresolved:** The paper benchmarks fairness against a uniform random probability (Ek) for simplicity, acknowledging that this ignores legitimate reasons (e.g., shared dialect) why an innocent author might rank higher.
- **What evidence would resolve it:** A recalibrated fairness metric that adjusts the expected ranking probability (Ek) based on the semantic or stylistic similarity between the query and the haystack authors.

## Limitations
- The assumption that random queries provide a neutral fairness baseline may not hold in realistic forensic settings where queries are stylistically constrained.
- The analysis focuses on centroid distance without examining other embedding space properties (e.g., density, manifold curvature) that could explain misattribution patterns.
- The paper identifies the geometrical cause of unfairness but does not propose a mitigation strategy to fix the embedding distribution while maintaining high performance.

## Confidence
- **High confidence:** MAUIk metric formulation and its mathematical properties; empirical finding that accuracy and fairness are decoupled across models.
- **Medium confidence:** The centroid distance correlation with misattribution risk; claim that embedding distribution shape mediates unfairness.
- **Low confidence:** Generalization of findings to non-random query distributions; assumption that embedding geometry alone explains fairness patterns without considering textual features.

## Next Checks
1. **Query distribution sensitivity:** Evaluate MAUIk when queries are drawn from stylistically similar author subsets (e.g., genre-specific) rather than randomly; test if centroid effect persists.
2. **Embedding space analysis:** Compute additional geometric properties (e.g., local density, intrinsic dimensionality) for each author and correlate with MAUIk to determine if centroid distance is the primary mediator.
3. **Cross-domain validation:** Apply MAUIk to a code authorship attribution dataset to test if fairness-fairness patterns hold across different text domains and embedding models.