---
ver: rpa2
title: 'AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering:
  Current Developments and Future Directions'
arxiv_id: '2511.17743'
source_url: https://arxiv.org/abs/2511.17743
tags:
- fmea
- engineering
- failure
- design
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This review examines the integration of Artificial Intelligence
  (AI) and ontologies to address the limitations of traditional Failure Mode and Effects
  Analysis (FMEA) in complex systems engineering. By leveraging machine learning,
  natural language processing, and large language models, the research enhances failure
  prediction, classification, and prioritisation, while ontologies provide a formal
  framework for knowledge representation, enabling semantic reasoning, traceability,
  and interoperability.
---

# AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions

## Quick Facts
- arXiv ID: 2511.17743
- Source URL: https://arxiv.org/abs/2511.17743
- Reference count: 40
- Primary result: AI and ontologies transform FMEA from manual to intelligent, integrated methodology with improved consistency and explainability

## Executive Summary
This review examines how artificial intelligence (AI) and ontologies can address traditional Failure Mode and Effects Analysis (FMEA) limitations in complex systems engineering. The research integrates machine learning, natural language processing, and large language models to enhance failure prediction, classification, and prioritization, while ontologies provide formal frameworks for knowledge representation enabling semantic reasoning, traceability, and interoperability. The combined approach transforms FMEA from a static, manual process into a dynamic, intelligent, and model-integrated methodology. Key findings include improved risk prioritization consistency (precision and recall up to 0.892), automated extraction of failure information from unstructured data, and enhanced explainability through ontology-grounded AI reasoning.

## Method Summary
The paper synthesizes existing research on AI-ontology integration for FMEA enhancement, drawing from multiple case studies and implementations. Methods reviewed include AutoML pipelines for RPN prediction (using models like Random Forest, SVM, AdaBoost), NLP techniques (BERT, LSTM, transformers) for extracting failure data from maintenance logs, and LLMs (GPT-3.5/4/4o, Gemini) for automated FMEA generation. Ontology formalization uses OWL/RDF with Protégé, while semantic reasoning employs HermiT reasoner. The approach validates AI outputs against ontological constraints to ensure consistency and explainability, creating hybrid frameworks that combine machine learning predictions with formal engineering knowledge representation.

## Key Results
- Improved consistency in risk prioritization with precision and recall up to 0.892
- Automated extraction of failure information from unstructured data sources
- Enhanced explainability through ontology-grounded AI reasoning and traceable decision-making

## Why This Works (Mechanism)

### Mechanism 1: Semantic Grounding for Explainability
Ontologies reduce AI "black box" opacity by constraining outputs to domain-validated logic, enhancing trust in failure predictions. The ontology defines formal relationships and axioms (e.g., a specific FailureMode must be linked to at least one Component), and AI predictions are validated against this structure. If an AI suggests a failure cause violating ontological axioms, it's flagged, forcing AI outputs to align with verifiable engineering knowledge. Core assumption: the formal engineering knowledge representation is accurate and complete enough to serve as valid constraint.

### Mechanism 2: Knowledge Extraction via Hybrid NLP and Ontological Mapping
NLP models automate structured FMEA data extraction from unstructured text (maintenance logs, repair reports), which is normalized using an ontology. An NLP pipeline parses unstructured text to identify entities (component names, failure modes), which are mapped to ontology classes, resolving synonyms and jargon. This populates a structured knowledge graph from which failure chains can be inferred, reducing manual data entry. Core assumption: NLP models are sufficiently accurate for technical domain jargon and ontology provides comprehensive coverage.

### Mechanism 3: Probabilistic Risk Prioritization with ML-Augmented RPNs
ML models automate and improve RPN calculation consistency by learning from historical FMEA data and operational metrics. Instead of subjective expert estimates for Severity, Occurrence, and Detection, an ML model trained on past FMEAs correlated with actual failure outcomes predicts S, O, and D scores for new failure modes. This produces data-driven, dynamic RPNs updated as new operational data becomes available. Core assumption: sufficient high-quality historical data exists to train a reliable predictive model.

## Foundational Learning

- **Concept: Failure Mode and Effects Analysis (FMEA)**
  - Why needed here: The entire framework enhances this core reliability engineering process. Understanding its traditional manual form (identifying failure modes, causes, effects, calculating RPN) shows what AI-ontology synergy is automating.
  - Quick check question: Can you list the three factors used to calculate a traditional Risk Priority Number (RPN)?

- **Concept: Ontologies**
  - Why needed here: They provide the formal, semantic backbone for the system. Understanding defining classes, properties, and axioms to create shared, machine-readable vocabulary is necessary for reasoning and interoperability.
  - Quick check question: What is the key difference between a simple database and an ontology in terms of representing knowledge?

- **Concept: Model-Based Systems Engineering (MBSE)**
  - Why needed here: The review positions AI-ontology FMEA within broader MBSE context. This shift from document-centric to model-centric engineering, where unified digital model integrates requirements, design, analysis, and verification, is essential context.
  - Quick check question: In MBSE, how is the "single source of truth" for a system typically represented and shared across disciplines?

## Architecture Onboarding

- **Component map:** Data Layer (legacy FMEA spreadsheets, CAD models, unstructured maintenance logs) -> Knowledge Representation Layer (Domain Ontology in OWL/RDF, instantiated as Knowledge Graph) -> AI/ML Layer (NLP models, ML classifiers, LLMs) -> Integration/Reasoning Layer (Semantic reasoners, Hybrid AI-Ontology framework) -> Application Layer (Intelligent FMEA tool)

- **Critical path:** Building and populating the domain ontology. Without this semantic foundation, AI models will produce unstructured, untraceable outputs, and the system won't achieve interoperability or explainability.

- **Design tradeoffs:**
  - Ontology Detail vs. Scalability: Highly detailed ontology improves reasoning accuracy but increases development cost and computational load
  - AI Model Performance vs. Explainability: Complex deep learning models may offer superior predictive performance but can be black boxes, contradicting explainability goals
  - Automation vs. Human-in-the-Loop: Full automation speeds up process but risks missing nuanced failures; human validation is essential for high-stakes decisions

- **Failure signatures:**
  - Siloed AI Recommendations: AI generates valid failure modes that cannot be mapped to any ontology class or property
  - Stale Ontology: System repeatedly flags valid, novel AI-identified failure modes as "invalid" due to outdated ontology
  - Over-Confidence in ML RPNs: Teams blindly accept ML-predicted RPNs without validation, missing underlying training data biases

- **First 3 experiments:**
  1. Baseline & Vocabulary Extraction: Apply pre-trained NLP model to legacy FMEA reports to extract key entities, manually map to simple initial ontology to measure extraction accuracy
  2. Ontology-ML RPN Validation: Train ML model (Random Forest) on historical FMEA data to predict RPN scores, compare predictions against expert-assigned RPNs
  3. Failure Chain Trace: Manually construct small FMEA knowledge graph for single subsystem, use reasoner to automatically trace failure chain from component cause to system effect, compare to manual documentation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can robust validation pipelines be developed to prevent semantic drift and hallucinations in hybrid LLM-ontology FMEA systems?
- Basis in paper: Section 7.3 highlights risks of hybrid models producing "semantic drift, hallucination, or misalignment with engineering logic"
- Why unresolved: Current research lacks established benchmarks for reasoning fidelity and certification frameworks to assess semantic correctness
- What evidence would resolve it: Creation of explainable AI frameworks grounded in domain ontologies providing auditable, traceable justifications for automated risk predictions

### Open Question 2
- Question: What methodologies are required to transition from manual ontology construction to scalable, modular, and standardised engineering ontologies?
- Basis in paper: Section 7.2 states scalability is currently limited by manual processes and "absence of domain-wide standards for ontology structure"
- Why unresolved: Without agreed-upon ontological patterns for functions and failure modes, organizations must develop bespoke models, limiting reuse
- What evidence would resolve it: Development of automated ontology generation and alignment tooling underpinned by common, version-controlled patterns

### Open Question 3
- Question: How can semantic interoperability be achieved across heterogeneous engineering domains and disparate modeling languages (e.g., SysML, UML)?
- Basis in paper: Section 7.1 identifies "inconsistent terminology" and "incompatible standards" as primary barriers to integrating system models with FMEA artefacts
- Why unresolved: Integration is hindered by fragmented modeling practices and requires coordinated efforts among academia, industry, and tool vendors
- What evidence would resolve it: Successful alignment with formal semantic standards, such as those promoted by the Industrial Ontologies Foundry (IOF), enabling cross-domain data integration

## Limitations

- Methodological heterogeneity across sources limits quantitative aggregation and generalizability of claims
- Most evidence drawn from single-case implementations rather than comparative studies
- Lack of standardized public FMEA datasets means reported performance depends on proprietary or domain-specific data

## Confidence

- **High confidence:** Ontology's role in providing semantic grounding for explainability is well-supported by multiple sources with explicit statements about rule-based reasoning
- **Medium confidence:** NLP-based knowledge extraction is plausible and supported by domain-specific case studies but lacks broad validation across different FMEA contexts
- **Low confidence:** Claims about LLM-driven ontology evaluation based on single related paper (Tsaneva et al., 2024) not deeply detailed in corpus, making this mechanism most speculative

## Next Checks

1. Replicate Sader et al.'s AutoML RPN prediction using publicly available failure classification datasets to verify claimed precision/recall metrics independently
2. Test ontology grounding by constructing small FMEA knowledge graph and running semantic consistency checks to verify whether AI-generated failure modes are properly constrained by ontological axioms
3. Validate NLP extraction accuracy by comparing automated entity recognition from maintenance logs against expert-annotated ground truth across multiple domains (automotive, aerospace, medical)