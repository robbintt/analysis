---
ver: rpa2
title: 'Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable
  Model Interpretability'
arxiv_id: '2508.18154'
source_url: https://arxiv.org/abs/2508.18154
tags:
- robustness
- noise
- methods
- across
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the robustness of Class Activation Maps (CAMs)
  under input perturbations, a critical issue for reliable model interpretability.
  The authors propose a novel framework that evaluates CAM robustness through two
  key properties: consistency (stability under class-preserving perturbations) and
  responsiveness (sensitivity to class-changing perturbations).'
---

# Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable Model Interpretability

## Quick Facts
- **arXiv ID:** 2508.18154
- **Source URL:** https://arxiv.org/abs/2508.18154
- **Reference count:** 40
- **Primary result:** Proposed framework evaluates CAM robustness through consistency (stability under class-preserving perturbations) and responsiveness (sensitivity to class-changing perturbations), finding GradCAM++ most robust across four models, seven datasets, and eight perturbation types.

## Executive Summary
This paper addresses the critical gap in evaluating Class Activation Maps (CAMs) under input perturbations, proposing a novel framework that assesses CAM robustness through two key properties: consistency (stability under class-preserving perturbations) and responsiveness (sensitivity to class-changing perturbations). The method employs Rank-Biased Overlap (RBO) to measure rank stability of salient regions and trains a classifier to assess responsiveness. Experiments across four models (ResNet50, VGG19, Inception, ViT), seven datasets, and eight perturbation types show that GradCAM++ consistently achieves the highest robustness scores, while EigenCAM and AblationCAM are least robust. The framework is model- and perturbation-agnostic, offering a comprehensive, quantitative approach to evaluating and comparing CAM methods under noise, with practical implications for selecting robust explanations in real-world applications.

## Method Summary
The framework evaluates CAM robustness through two complementary metrics: Consistency and Responsiveness. Consistency measures the median RBO (Rank-Biased Overlap) between segment rankings of original and perturbed images when the predicted class remains unchanged. Responsiveness quantifies how well CAM changes when the class prediction changes, measured as the AUC of a binary classifier trained to predict class change from RBO scores. The overall robustness metric is the product of Consistency and Responsiveness. Images are segmented using QuickShift into superpixels, CAMs are generated for both original and perturbed images, and segment-level rankings are compared using RBO with persistence parameter p=0.9.

## Key Results
- GradCAM++ consistently outperforms other CAM methods across all datasets and perturbation types in overall robustness scores
- EigenCAM and AblationCAM show the lowest robustness, with EigenCAM achieving high consistency but failing responsiveness when classes change
- Vision Transformers (ViT) exhibit significantly higher variance in RBO scores compared to convolutional models, indicating less stable explanations
- The dual-factor framework successfully distinguishes between methods that are merely stable (high consistency) versus those that are both stable and responsive (high robustness)

## Why This Works (Mechanism)

### Mechanism 1: Rank-Based Semantic Stability via RBO
- Claim: Using Rank-Biased Overlap (RBO) instead of pixel-wise norms (like L1) provides a more reliable measure of explanation stability under perturbation.
- Mechanism: RBO computes the similarity between the ranked lists of salient image segments (superpixels) from original and perturbed images. By using a persistence parameter (p=0.9), it weights agreement at the top of the list (most relevant features) more heavily than the bottom. This allows the metric to tolerate global intensity shifts if the relative importance of regions remains constant.
- Core assumption: The semantic validity of an explanation is better captured by the ranking of high-intensity regions than by pixel-perfect intensity matching.
- Evidence anchors:
  - [abstract] "Employs Rank-Biased Overlap (RBO) to measure rank stability of salient regions..."
  - [section 1, page 3] Figure 2 demonstrates that normalized L1 values deviate significantly or inconsistently compared to RBO when CAM intensity changes.
  - [corpus] Related work like CF-CAM suggests clustering filters to improve gradient reliability, supporting the view that raw gradients/pixels are noisy and structural/rank aggregation is needed.
- Break condition: If the segmentation algorithm fails to produce coherent regions for specific image types (e.g., low-contrast medical images), the ranking itself becomes meaningless.

### Mechanism 2: Dual-Factor Robustness Decomposition
- Claim: A robust explanation must satisfy two independent constraints: stability when the decision is unchanged (Consistency) and sensitivity when the decision is flipped (Responsiveness).
- Mechanism: The framework separates perturbations based on whether they flip the model's predicted class.
    1. **Consistency**: If prediction is unchanged, high overlap (RBO) between original and perturbed CAMs is required.
    2. **Responsiveness**: If prediction changes, the CAM *should* change (low RBO).
    3. **Product**: The final score is C × R. A method that is merely stable (high C) but fails to change when the class changes (low R, like EigenCAM) receives a low final score.
- Core assumption: A "robust" explanation is not just stable; it must faithfully reflect the model's decision logic, meaning it *must* change if the model output changes.
- Evidence anchors:
  - [abstract] "...assesses CAM robustness through two key properties: consistency... and responsiveness..."
  - [section 2.5, page 10] "Responsiveness (R) captures the semantic sensitivity of the CAM... when the predicted class changes due to noise, a meaningful CAM should also change significantly."
  - [corpus] DiffGradCAM explores class probability differences, aligning with the need for CAMs to reflect class-specific decision dynamics rather than static features.
- Break condition: If the model architecture is inherently non-robust (e.g., ViT with high variance), distinguishing "unfaithful explanation" from "unstable model" becomes difficult.

### Mechanism 3: Classifier-Based Sensitivity Quantification
- Claim: Responsiveness can be quantitatively measured by the Area Under the Curve (AUC) of a binary classifier trained to predict "class change" from RBO scores.
- Mechanism: The framework treats Responsiveness as a detection task. It collects pairs of (RBO score, Class_Change_Boolean). A linear classifier is trained on these pairs. If low RBO scores consistently predict that the class has changed, the AUC will be high (high Responsiveness).
- Core assumption: There exists a monotonic relationship where significant changes in explanation structure (low RBO) correlate with changes in model decision.
- Evidence anchors:
  - [section 2.5, page 10] "We define Responsiveness as the Area Under the Curve (AUC) of this classifier."
  - [section 4, page 21] Tables 4-7 show the resulting product scores, effectively differentiating methods like GradCAM++ (high AUC/Consistency) from EigenCAM.
  - [corpus] AR2 discusses repair for robustness against corruptions; this mechanism acts as a "diagnostic" tool to see if the explanation logic repairs itself or breaks under stress.
- Break condition: If the perturbation set is insufficient to flip classes frequently, the classifier will lack positive training samples for "class change," invalidating the AUC calculation.

## Foundational Learning

- Concept: **Superpixel Segmentation (e.g., QuickShift)**
  - Why needed here: The framework does not compare raw pixels; it compares *regions*. You must understand how images are divided into coherent segments (superpixels) to calculate the mean intensity and subsequent rankings.
  - Quick check question: If an image has a large uniform area, how does that affect the number of segments and the stability of the mean intensity calculation?

- Concept: **Rank-Biased Overlap (RBO)**
  - Why needed here: This is the core distance metric. Unlike standard correlation, RBO handles indefinite rankings (lists of different lengths or missing items) and allows weighting top ranks higher.
  - Quick check question: Why would we care more about the overlap of the top-5 salient segments than the bottom-5?

- Concept: **Class-Preserving vs. Class-Changing Perturbations**
  - Why needed here: The entire logical structure of the paper relies on bifurcating noise based on its impact on the classifier's output label.
  - Quick check question: Does adding Gaussian noise always constitute a "class-changing" perturbation? (Answer: No, it depends on severity/model robustness).

## Architecture Onboarding

- Component map: Image I -> QuickShift Segmentation -> Segments S -> Perturbation Engine -> I' -> Model M -> y, y' -> CAM Generator -> CAM(I), CAM(I') -> Ranker -> Ranks R, R' -> Evaluator -> RBO -> Classifier -> AUC
- Critical path: The **Responsiveness calculation** is the bottleneck. It requires accumulating enough "class change" instances to train a valid binary classifier. If perturbations are too weak to flip classes, Responsiveness cannot be computed.
- Design tradeoffs:
  - **Segmentation Granularity**: Too few segments lose detail; too many make rankings noisy and computation expensive. (Paper uses matched-count configurations for fairness).
  - **RBO Persistence (p)**: Set to 0.9 to emphasize top ranks. Lowering this makes the metric more forgiving of noise in lower-saliency regions.
  - **Model Choice**: CNNs (ResNet/VGG) show stable results; ViT shows high variance, requiring careful interpretation of results.
- Failure signatures:
  - **" Blind Stability"**: A CAM method like EigenCAM produces nearly identical maps for clean and adversarial images. This yields high Consistency (if class doesn't change) but terrible Responsiveness (fails to detect class change).
  - **Noisy Rankings**: If segmentation is unstable, RBO scores fluctuate wildly regardless of CAM quality.
- First 3 experiments:
  1. **Sanity Check (RBO vs L1)**: Reproduce Figure 2. Take a reference image, add noise, compute CAMs, and verify that L1 distance is inconsistent while RBO tracks semantic rank shifts.
  2. **Consistency Baseline**: Run 1000 ImageNet images through ResNet50 with low Gaussian noise. Plot the distribution of Consistency scores for GradCAM vs. EigenCAM to verify EigenCAM's stability.
  3. **Responsiveness Validation**: Apply PGD adversarial attacks (which force class changes) and confirm that the RBO score drops significantly, allowing the binary classifier to achieve high AUC.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CAM robustness differ across domain-specific medical imaging modalities (CT, MRI, X-ray)?
- Basis in paper: [explicit] The authors state in the limitations that "we have not specifically studied modality-specific scenarios such as CT, MRI, or X-ray imaging" and note that these modalities "exhibit distinct structural and intensity characteristics."
- Why unresolved: The current evaluation uses only dermatoscopic images (Melanoma dataset) and general photography datasets; no radiology or volumetric imaging was tested.
- What evidence would resolve it: Application of the robustness framework to diverse medical imaging datasets across CT, MRI, and X-ray modalities, reporting consistency and responsiveness scores for each.

### Open Question 2
- Question: What is the relationship between adversarial training of classification models and the robustness of their CAM explanations?
- Basis in paper: [explicit] Appendix A.6 notes that "adversarial training is a well-established strategy for improving classification robustness" but "its impact on CAM robustness remains underexplored," despite showing preliminary results on one adversarially trained ResNet-50.
- Why unresolved: Only one adversarially trained model was tested; the study does not vary training robustness levels or model architectures to establish a general relationship.
- What evidence would resolve it: Systematic evaluation across multiple adversarial training methods (e.g., TRADES, MART), robustness levels (ε values), and architectures, correlating classification robustness gains with CAM robustness metric changes.

### Open Question 3
- Question: Can the computational cost of CAM robustness evaluation be reduced without compromising metric fidelity?
- Basis in paper: [inferred] The limitations section acknowledges "our framework requires the explicit computation of CAMs to assess robustness, which is computationally intensive," and the runtime analysis shows ~0.445s per image-CAM-noise combination.
- Why unresolved: No approximation methods or sampling strategies were explored; the current approach requires full CAM computation for all images, methods, and noise types.
- What evidence would resolve it: Comparison of the full RBO-based metric with approximate methods (e.g., subset sampling, lower-resolution CAMs, or proxy correlation metrics) to quantify speed-fidelity trade-offs.

## Limitations

- **Medical imaging applicability**: The framework has not been validated on domain-specific medical imaging modalities like CT, MRI, or X-ray, which exhibit distinct structural and intensity characteristics
- **Adversarial training impact**: The relationship between model adversarial training and CAM robustness remains unexplored, with only preliminary results on a single adversarially trained model
- **Computational efficiency**: The framework requires explicit CAM computation for all images, methods, and noise types, making it computationally intensive without exploring approximation strategies

## Confidence

- **High confidence**: The dual-factor decomposition (consistency × responsiveness) provides a logically sound framework for evaluating CAM robustness. The experimental methodology and comparative results are reproducible.
- **Medium confidence**: The superiority of GradCAM++ over other methods is well-supported, but the performance gap with methods like HiResCAM and XGradCAM requires deeper investigation to determine if differences are statistically significant across all datasets.
- **Medium confidence**: The assumption that RBO better captures semantic stability than L1 distance is empirically validated but not theoretically proven.

## Next Checks

1. **Statistical significance testing**: Apply paired t-tests or bootstrapping to verify that GradCAM++'s performance advantage over EigenCAM and AblationCAM is statistically significant across all datasets and perturbations.
2. **Parameter sensitivity analysis**: Systematically vary the RBO persistence parameter p and classifier type to assess robustness of the framework to hyperparameter choices.
3. **Cross-architecture validation**: Extend experiments to include additional model families (e.g., EfficientNet, ConvNeXt) to verify whether observed patterns generalize beyond the four architectures tested.