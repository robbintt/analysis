---
ver: rpa2
title: Noise-Aware Named Entity Recognition for Historical VET Documents
arxiv_id: '2601.00488'
source_url: https://arxiv.org/abs/2601.00488
tags:
- training
- data
- entity
- recognition
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Named Entity Recognition
  (NER) in historical Vocational Education and Training (VET) documents that are affected
  by OCR-induced noise. The authors propose a noise-aware training approach using
  synthetic OCR error injection and transfer learning to improve NER robustness.
---

# Noise-Aware Named Entity Recognition for Historical VET Documents

## Quick Facts
- arXiv ID: 2601.00488
- Source URL: https://arxiv.org/abs/2601.00488
- Reference count: 13
- Primary result: Artificially corrupted training data achieved 77.9% F1, outperforming noisy (77.5%) and clean (75.2%) models on historical VET documents

## Executive Summary
This paper addresses Named Entity Recognition (NER) in historical German Vocational Education and Training (VET) documents affected by OCR-induced noise. The authors propose a noise-aware training approach using synthetic OCR error injection combined with domain-adaptive pre-training. Three models are compared: trained on naturally noisy data, clean data, and artificially corrupted data. The synthetically corrupted model achieved the highest F1 score (77.9%), demonstrating that controlled error injection during training improves robustness to real OCR noise beyond training on naturally noisy data alone.

## Method Summary
The approach uses multi-stage fine-tuning with synthetic OCR error injection. First, a domain-adaptive pre-training (DAPT) stage uses taxonomy data (KldB job classifications, ESCO skills) to prime the model with domain vocabulary. Second, three final models are fine-tuned on annotated VET documents: one on naturally noisy OCR output, one on clean corrected text, and one on artificially corrupted text where controlled errors (substitutions, deletions, insertions) are injected based on empirical OCR error patterns. The training pipeline includes class weighting and oversampling to address label imbalance, and uses the dbmdz/bert-base-german-cased model as the base architecture.

## Key Results
- Artificially corrupted model achieved highest F1 score of 77.9%
- Clean model (trained on corrected text) achieved lowest F1 score of 75.2%
- Naturally noisy model achieved intermediate F1 score of 77.5%
- DAPT improved recognition for job titles and groups that benefited from taxonomy-derived training data

## Why This Works (Mechanism)

### Mechanism 1
Training on synthetically corrupted data improves NER robustness to OCR noise beyond training on naturally noisy data alone. Controlled perturbations are injected into clean training text based on empirically observed OCR error patterns, exposing the model to a wider distribution of noisy variants during training. This encourages learned representations that generalize across corrupted and clean token forms. The synthetic error distributions approximate real OCR error characteristics well enough to transfer to inference-time noise. Break condition: If synthetic error distribution diverges significantly from actual OCR error characteristics, performance gains may not transfer.

### Mechanism 2
Multi-stage fine-tuning with domain-adaptive pre-training on external taxonomies improves recognition for entities with available structured data. An intermediate pre-training stage on taxonomy-derived data provides entity-aware weight initialization before final fine-tuning on annotated documents. This primes the model with domain vocabulary and entity boundary signals. The taxonomy data, though lacking negative labels and OCR noise, provides transferable entity recognition patterns. Break condition: If annotation conventions differ between taxonomy data and target data, pre-training may introduce conflicting signals.

### Mechanism 3
Class weighting and oversampling mitigate label imbalance, preventing class collapse toward majority "O" labels. Inverse-frequency class weights and oversampling of token windows containing positive entity labels rebalance the loss function to provide stronger gradients for rare entities. This prevents the model from degenerating into predicting only "O" labels. Break condition: If positive examples are too few or too homogeneous, oversampling may cause memorization rather than generalization.

## Foundational Learning

- Concept: **Noise-Aware Training (NAT)**
  - Why needed here: Historical scanned documents contain OCR errors that corrupt entity tokens. Models trained only on clean text fail to recognize corrupted variants at inference time.
  - Quick check question: Can you explain why training on clean text and testing on noisy text produces lower recall than training on noisy text directly?

- Concept: **Domain-Adaptive Pre-training (DAPT)**
  - Why needed here: General-purpose BERT has limited exposure to VET-specific terminology. DAPT bridges this gap before task-specific fine-tuning.
  - Quick check question: What is the key difference between DAPT and standard fine-tuning in terms of data characteristics and training objectives?

- Concept: **BIO Tagging Scheme**
  - Why needed here: NER requires identifying entity spans (multi-token sequences), not just individual tokens. BIO encoding provides this structure.
  - Quick check question: How would the tag sequence look for the entity "pharmaceutical technical assistant" under BIO encoding?

## Architecture Onboarding

- Component map: dbmdz/bert-base-german-cased -> DAPT on KldB/ESCO taxonomy data -> Three final models (noisy, clean, artificial)
- Critical path: 1) Empirical OCR error analysis -> build error injection probability table; 2) DAPT pre-training on taxonomy data -> save intermediate checkpoint; 3) Fine-tune three model variants on annotated VET documents; 4) Evaluate on held-out test set
- Design tradeoffs: Synthetic noise doubles training data size vs. increased training cost; taxonomy data provides vocabulary coverage but lacks "O" labels and noise; token simplification was tested and degraded performance (F1: 77.5% â†’ 63.3%)
- Failure signatures: Clean model shows lower recall than noisy model (model becomes "conservative" with unfamiliar noisy tokens); skills entity underperforms (38.5% F1) due to mismatch between ESCO "learnable skills" and VET "prerequisite skills"; confusion between job titles vs. job title groups, and skills vs. activities
- First 3 experiments: 1) Replicate three-model comparison to validate baseline F1 scores (target: artificial > noisy > clean); 2) Ablate DAPT: train model directly from base BERT without intermediate pre-training, compare F1 per entity type; 3) Increase synthetic noise augmentation factor beyond 2x and measure performance changes

## Open Questions the Paper Calls Out

### Open Question 1
Does the noise-aware training approach maintain its robustness when applied to historical documents processed by OCR engines other than Tesseract? The current experimental results are based exclusively on documents digitized using the Tesseract OCR engine. Comparative benchmarking on datasets generated by alternative OCR engines would resolve this.

### Open Question 2
Does redefining the SKILL entity to distinguish between "prerequisite" and "learnable" skills significantly improve recognition accuracy? The current model struggles because the annotated VET data contains prerequisite skills, whereas the additional training data (ESCO) primarily contains learnable skills. Experimental results from a model trained on data re-annotated to explicitly separate these skill sub-categories would resolve this.

### Open Question 3
Does integrating layout analysis and table recognition into the document processing pipeline substantially improve NER performance on pages with complex structures? The current pipeline often fails to recognize entities correctly when the reading order is ambiguous or disrupted by table formatting and line breaks. Evaluation of NER recall before and after implementing layout analysis modules would resolve this.

## Limitations
- Synthetic OCR error patterns may not generalize to documents processed by different OCR engines or with different degradation characteristics
- DAPT benefits are highly dependent on alignment between pre-training taxonomy data and target annotation conventions
- Class imbalance mitigation addresses symptoms but not underlying data scarcity problem with only 1,509 entities across 68 pages

## Confidence

**High Confidence:** The core finding that synthetic noise injection improves NER robustness over both clean and naturally noisy training baselines (77.9% vs 77.5% vs 75.2% F1). This is directly measured on the held-out test set with clear methodology described.

**Medium Confidence:** The mechanism by which DAPT improves performance for job titles and job title groups. While higher F1 scores are shown for these entities and DAPT usage is explained, ablation studies to isolate DAPT's contribution are not conducted.

**Low Confidence:** The claim that this approach is "easily transferable to other languages and contexts." No empirical evidence for cross-lingual transfer is provided, and the approach relies heavily on German-specific resources.

## Next Checks

1. **Ablation of DAPT contribution:** Train and evaluate a model directly from base BERT without intermediate pre-training on taxonomy data. Compare entity-level F1 scores to determine how much of the performance gain is attributable to DAPT versus other factors like synthetic noise injection or class weighting.

2. **Cross-OCR engine validation:** Apply the trained models to documents processed by a different OCR engine (or different degradation type) to test whether the synthetic error patterns generalize beyond the specific OCR characteristics used during training.

3. **Data scaling experiment:** Increase the size of the annotated training set while maintaining the same 70:20:10 split ratio. Measure whether the relative performance ordering of noisy vs. clean vs. artificial models remains consistent as data availability changes.