---
ver: rpa2
title: 'Visual Reasoning at Urban Intersections: FineTuning GPT-4o for Traffic Conflict
  Detection'
arxiv_id: '2502.20573'
source_url: https://arxiv.org/abs/2502.20573
tags:
- traffic
- conflict
- prompt
- intersections
- conflicts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study fine-tuned GPT-4o to detect traffic conflicts at unsignalized
  urban intersections using drone video frames. The model was trained on a balanced
  dataset of 700 labeled observations and evaluated with structured prompts to analyze
  sequential traffic scenes.
---

# Visual Reasoning at Urban Intersections: FineTuning GPT-4o for Traffic Conflict Detection

## Quick Facts
- arXiv ID: 2502.20573
- Source URL: https://arxiv.org/abs/2502.20573
- Reference count: 40
- Primary result: Fine-tuned GPT-4o achieved 77.14% accuracy in detecting traffic conflicts at unsignalized intersections

## Executive Summary
This study fine-tuned GPT-4o to detect traffic conflicts at unsignalized urban intersections using drone video frames. The model was trained on a balanced dataset of 700 labeled observations and evaluated with structured prompts to analyze sequential traffic scenes. Fine-tuning significantly improved performance, achieving 77.14% accuracy with the optimized prompt, compared to 58.43% in a zero-shot setting. Manual evaluation of the model's conflict explanations and recommendations scored 89.9% and 92.3% accuracy, respectively. These results demonstrate that fine-tuned MLLMs like GPT-4o can provide scalable, real-time traffic management insights with actionable recommendations for intersection safety.

## Method Summary
The researchers fine-tuned GPT-4o using a balanced dataset of 700 labeled observations (350 conflict, 350 no-conflict) extracted from drone footage at unsignalized intersections. Each observation consisted of three sequential frames captured at 0.5-second intervals. The model was trained on 504 observations, validated on 56, and tested on 140. Two structured prompt variants were evaluated: a basic prompt and a detailed prompt that explicitly encoded intersection layout and priority rules. The fine-tuned model with the detailed prompt achieved 77.14% accuracy, compared to 58.43% in a zero-shot setting.

## Key Results
- Fine-tuned GPT-4o with optimized prompt achieved 77.14% accuracy in conflict detection
- Zero-shot GPT-4o performance was significantly lower at 58.43% accuracy
- Manual expert evaluation rated conflict explanations at 89.9% and recommendations at 92.3% accuracy

## Why This Works (Mechanism)

### Mechanism 1: Fine-Tuning Induces Domain-Specific Visual-Semantic Alignment
Fine-tuning MLLMs on specialized traffic datasets improves conflict detection by aligning general visual reasoning with domain-specific concepts like vehicle trajectories and intersection priority. The 504 labeled frame pairs adjust model weights to reduce the semantic gap between general visual features and task-specific conflict indicators.

### Mechanism 2: Context-Rich Prompting Structures Visual Reasoning
Detailed prompts that encode domain rules and scene layout enhance performance by providing logical constraints that the model combines with visual perception. Specifying "West-East (main) road has priority" and temporal frame information helps the model perform structured spatial-temporal analysis.

### Mechanism 3: Sequential Frame Analysis Enables Temporal Conflict Prediction
Three consecutive frames at 0.5-second intervals allow the model to perceive motion and trajectory, essential for predicting future conflict states that are not yet collisions. This spatiotemporal data enables trajectory extrapolation to identify potential right-of-way violations.

## Foundational Learning

- **Multimodal Large Language Models (MLLMs)**: These models fuse visual and textual data into shared representations, enabling simultaneous processing of image frames and textual prompts. Quick check: How does an MLLM combine a textual prompt with image frames to produce a binary output?

- **Zero-Shot vs. Fine-Tuned Performance**: The study demonstrates performance differences between pre-trained models and those adapted to specific domains. Quick check: Why might a general internet-trained model fail at traffic conflict detection without fine-tuning?

- **Prompt Engineering for Structured Reasoning**: Prompt content directly affects model performance by providing context, rules, and constraints. Quick check: What specific information in Prompt 2 caused superior performance over Prompt 1?

## Architecture Onboarding

- **Component map**: Drone video -> Frame extraction (3 frames @ 0.5s) -> Manual labeling -> GPT-4o MLLM -> Fine-tuning (504 samples) -> Structured prompts -> Binary output + explanation + recommendation -> Expert evaluation

- **Critical path**: Prompt design -> fine-tuning loop. The quality of prompts and fine-tuning data determines detection accuracy. Failures in either component will degrade performance.

- **Design tradeoffs**: 
  - Small dataset (700 obs) vs. generalizability across intersection types
  - Detailed prompt (P2) complexity vs. inference speed and cost
  - GPT-4o capability vs. GPT-4o-mini performance/cost tradeoff

- **Failure signatures**: 
  - High false negatives indicating missed conflict detection
  - Inconsistent reasoning with coincidentally correct but flawed explanations
  - Occlusion issues where critical conflict precursors are not visible

- **First 3 experiments**:
  1. Establish baseline with zero-shot GPT-4o and GPT-4o-mini using both prompts
  2. Fine-tune GPT-4o on 504 training samples with detailed prompt (P2), validating on 56 samples
  3. Evaluate fine-tuned model on 140 test samples using both prompts, analyzing confusion matrices

## Open Questions the Paper Calls Out
- Real-time deployment via live traffic feeds
- Joint use of MLLMs such as Gemini or LLaVA
- Exploring new MLLM architectures
- Addressing blind spots in conflict detection

## Limitations
- Small dataset size (700 observations) limits generalizability across diverse intersection types
- Reliance on clear aerial visibility creates vulnerability to occlusion, lighting changes, and weather
- Binary conflict classification oversimplifies complex traffic scenarios with partial right-of-way violations

## Confidence
- Fine-tuning performance improvement: High confidence (clear numerical comparison with defined metrics)
- Prompt engineering effectiveness: Medium confidence (performance differences documented but mechanism relies on assumptions)
- Real-time scalability claims: Low confidence (no timing measurements provided)

## Next Checks
1. Test model generalization on intersections with different layouts, road widths, and vehicle compositions not present in training data
2. Conduct systematic experiments varying prompt wording while maintaining semantic content to assess robustness to linguistic variations
3. Implement timing benchmarks measuring end-to-end inference latency under realistic drone video frame rates and processing constraints