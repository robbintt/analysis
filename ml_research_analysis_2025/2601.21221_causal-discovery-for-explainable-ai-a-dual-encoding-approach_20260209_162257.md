---
ver: rpa2
title: 'Causal Discovery for Explainable AI: A Dual-Encoding Approach'
arxiv_id: '2601.21221'
source_url: https://arxiv.org/abs/2601.21221
tags:
- causal
- discovery
- methods
- relationships
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of applying causal discovery\
  \ to datasets with mixed categorical and continuous variables, where standard one-hot\
  \ encoding can cause numerical instability in conditional independence tests. The\
  \ authors propose a dual-encoding approach that runs the Fast Causal Inference (FCI)\
  \ algorithm twice\u2014once with drop-first encoding and once with drop-last encoding\u2014\
  then merges the results through majority voting to produce a stable causal graph."
---

# Causal Discovery for Explainable AI: A Dual-Encoding Approach

## Quick Facts
- **arXiv ID:** 2601.21221
- **Source URL:** https://arxiv.org/abs/2601.21221
- **Reference count:** 10
- **Primary result:** Dual-encoding FCI approach produces stable causal graphs on mixed data by mitigating rank-deficiency from one-hot encoding.

## Executive Summary
This paper tackles the challenge of applying causal discovery to datasets with mixed categorical and continuous variables, where standard one-hot encoding can cause numerical instability in conditional independence tests. The authors propose a dual-encoding approach that runs the Fast Causal Inference (FCI) algorithm twice—once with drop-first encoding and once with drop-last encoding—then merges the results through majority voting to produce a stable causal graph. Applied to the Titanic dataset, this method successfully identifies a unified causal structure that aligns with established explainable AI methods such as SHAP and pruned decision trees. The resulting graph highlights Sex, Pclass, and Age as the primary causal drivers of survival, with consistent edge orientations across encoding strategies.

## Method Summary
The approach uses supervised entropy-based discretization for continuous variables, then applies FCI twice with different one-hot encoding schemes (drop-first and drop-last). The resulting graphs are merged via majority voting, with edges retained if present in at least one graph and orientations kept consistent when both agree. Edges are annotated with Pearson correlation coefficients to indicate supportive or opposing relationships. The method validates results by comparing the causal structure to SHAP feature importance rankings and decision tree split hierarchies.

## Key Results
- Dual-encoding FCI produces stable causal graphs on Titanic dataset despite encoding-induced numerical instability
- Unified graph consistently identifies Sex, Pclass, and Age as primary causal drivers of survival
- Discovered structure aligns with SHAP importance rankings and decision tree split hierarchies

## Why This Works (Mechanism)

### Mechanism 1: Rank Recovery via Complementary Encoding
- Claim: Running FCI with drop-first and drop-last encoding resolves the singular covariance matrix problem that plagues one-hot encoding in conditional independence tests.
- Mechanism: One-hot encoding creates collinear columns (dummy variables sum to a constant), producing rank-deficient covariance matrices that cannot be inverted for Fisher's z-test. Dropping different reference categories yields two distinct full-rank matrices, each enabling valid partial correlation estimation.
- Core assumption: True causal relationships are robust to the arbitrary choice of reference category; edges that appear consistently across encodings reflect genuine structure rather than encoding artifacts.

### Mechanism 2: Majority Voting for Graph Consolidation
- Claim: Merging encoding-specific graphs via majority voting produces unified causal structures that are stable across encoding choices.
- Mechanism: Edges appearing in at least one graph are retained; edges appearing in both with consistent orientation become directed edges; conflicting orientations revert to undirected edges. This filters encoding-specific artifacts while preserving robust structure.
- Core assumption: Spurious edges are encoding-specific whereas genuine causal edges survive both encoding choices with consistent directionality.

### Mechanism 3: Convergent Validation with XAI Baselines
- Claim: Discovered causal structures can be validated by alignment with decision tree split hierarchies and SHAP feature importance rankings.
- Mechanism: Causal drivers identified by FCI (Sex, Pclass, Age) should correspond to features with high discriminative importance. Decision trees reveal split priority; SHAP quantifies global feature contribution.
- Core assumption: Causal importance correlates with predictive importance—features that directly cause outcomes are also discriminative for classification.

## Foundational Learning

- **Concept: Conditional Independence Testing (Fisher's z-test)**
  - Why needed here: FCI's entire adjacency-detection phase depends on CI tests. Understanding why invertible covariance matrices are required clarifies why dual-encoding is necessary.
  - Quick check question: Given variables X, Y, and conditioning set Z, how would you interpret P(X ⊥ Y | Z) = true in terms of partial correlation, and what matrix operation does this require?

- **Concept: Constraint-Based Causal Discovery (PC vs. FCI)**
  - Why needed here: The paper uses FCI specifically because it relaxes causal sufficiency via bidirected edges. Knowing when to use FCI vs. PC is critical for architecture decisions.
  - Quick check question: What graphical symbol does FCI introduce that PC cannot produce, and what real-world phenomenon does it represent?

- **Concept: One-Hot Encoding and Rank Deficiency**
  - Why needed here: The core technical problem is numerical instability from collinear dummy variables. Understanding the linear algebra clarifies why dropping *any* category resolves singularity.
  - Quick check question: If you have a categorical variable with 3 levels encoded as [A, B, C] dummy columns, why does A + B + C = 1 (constant) cause matrix inversion to fail?

## Architecture Onboarding

- **Component map:** Preprocessing (discretization) -> Dual one-hot encoding (drop-first/drop-last) -> FCI × 2 runs -> Graph merging (majority voting) -> Edge annotation (Pearson r) -> Validation (SHAP + decision tree)
- **Critical path:** Discretization bin boundaries directly affect which CI tests pass/fail (bin choice = relationship granularity) -> Encoding choice determines which partial correlations are computable -> Merging threshold (majority vs. unanimity) determines final graph density and confidence
- **Design tradeoffs:** Finer discretization captures nonlinear relationships but reduces per-bin sample size, weakening CI test power; Permissive merging (edge in ≥1 graph) increases recall but may retain encoding-specific artifacts; Computational cost is 2× FCI runs; acceptable for moderate datasets, costly for high-dimensional data
- **Failure signatures:** High proportion of undirected edges in merged graph -> insufficient statistical power for consistent orientation; Substantially different graph densities between encodings -> high encoding sensitivity, dual-approach may be unreliable; No alignment with SHAP/tree baselines -> discovered structure may not correspond to discriminative features
- **First 3 experiments:**
  1. **Encoding sensitivity audit:** Compare drop-first-only, drop-last-only, and merged graphs side-by-side. Quantify edge overlap rate and orientation consistency.
  2. **Synthetic ground truth test:** Generate mixed-type data with known causal DAG. Measure precision/recall of edge recovery for single vs. dual encoding.
  3. **Discretization sensitivity analysis:** Vary bin count (e.g., 3, 5, 10 bins for Age) and assess stability of discovered edges. Identify which relationships are robust vs. artifact-prone.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How sensitive are the discovered causal structures to variations in entropy-based binning strategies and significance thresholds?
- Basis in paper: [explicit] The Conclusion states future work will "investigate the sensitivity of discovered structures to different significance thresholds," and Limitations notes discretization choices affect structure.
- Why unresolved: The current study relies on a fixed significance level ($\alpha=0.01$) and specific supervised binning without quantifying how much the graph topology changes with these parameters.
- What evidence would resolve it: A systematic sensitivity analysis measuring structural consistency (e.g., Structural Hamming Distance) across varying binning granularities and p-value thresholds.

### Open Question 2
- Question: Does the dual-encoding strategy improve structural accuracy compared to modern causal discovery algorithms designed specifically for mixed data?
- Basis in paper: [explicit] Limitations states that the authors "have not conducted controlled comparisons against modern mixed-data causal discovery methods."
- Why unresolved: The method was validated in isolation and against non-causal baselines (SHAP, trees), leaving its relative performance against specialized mixed-data algorithms unknown.
- What evidence would resolve it: Benchmarking the dual-encoding FCI approach against state-of-the-art mixed-data methods on datasets with known ground truth.

### Open Question 3
- Question: How can the unified causal graphs be operationalized within argumentation frameworks to generate instance-level explanations?
- Basis in paper: [explicit] The Discussion and Conclusion specify future work will "integrate these causal graphs with argumentation frameworks to generate instance-level explanations."
- Why unresolved: The paper currently provides global explanations but lacks a defined mechanism for translating the global causal topology into local, case-specific arguments.
- What evidence would resolve it: A proposed architecture mapping causal edges to argument components and a qualitative evaluation of the resulting instance-level explanations.

## Limitations
- Method validated only on a single real-world dataset (Titanic) without ground truth verification
- Inherits standard constraint-based discovery assumptions (causal sufficiency, absence of hidden confounders)
- Majority voting lacks principled probabilistic grounding and treats both encodings symmetrically
- Validation through SHAP/decision tree alignment is suggestive but not confirmatory of causal validity

## Confidence
- **High:** One-hot encoding causes rank-deficient covariance matrices in CI tests; dual encoding resolves this
- **Medium:** Majority voting reliably consolidates encoding-specific causal graphs
- **Medium:** Alignment with SHAP and decision tree hierarchies supports the validity of discovered structures

## Next Checks
1. **Synthetic ground truth test:** Generate mixed-type data from known DAGs and measure precision/recall of edge recovery for single vs. dual encoding
2. **Encoding sensitivity audit:** Systematically compare drop-first-only, drop-last-only, and merged graphs; quantify edge overlap rates and orientation consistency
3. **Discretization sensitivity analysis:** Vary bin count for continuous variables and assess stability of discovered edges to identify encoding-robust vs. artifact-prone relationships