---
ver: rpa2
title: 'DatBench: Discriminative, Faithful, and Efficient VLM Evaluations'
arxiv_id: '2601.02316'
source_url: https://arxiv.org/abs/2601.02316
tags:
- evaluation
- discriminative
- evaluations
- datbench
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a framework for evaluating vision-language
  models (VLMs) that addresses key limitations in existing benchmarks. The authors
  identify three desiderata for effective VLM evaluation: faithfulness to real-world
  usage, discriminability between models of varying quality, and computational efficiency.'
---

# DatBench: Discriminative, Faithful, and Efficient VLM Evaluations

## Quick Facts
- arXiv ID: 2601.02316
- Source URL: https://arxiv.org/abs/2601.02316
- Reference count: 35
- Key result: New VLM evaluation framework achieving 13× speedup while maintaining discriminative power

## Executive Summary
This paper addresses critical limitations in existing vision-language model (VLM) evaluation practices by proposing DatBench, a framework that balances faithfulness to real-world usage, discriminability between model qualities, and computational efficiency. The authors systematically transform and filter evaluation data rather than discarding existing benchmarks, resulting in evaluation suites that are both more rigorous and more sustainable as VLMs scale. The work reveals important insights about how language priors mask true multimodal capabilities and demonstrates that inference-time scaling can actually degrade perceptual performance.

## Method Summary
The methodology centers on four key interventions applied to existing benchmarks: converting multiple-choice questions to generative tasks (reducing accuracy by up to 35%), filtering out questions that don't require visual input (removing up to 70% of samples), removing mislabeled or ambiguous examples (up to 42% in some datasets), and selecting high-discriminative samples to maximize signal per compute unit. This transformation process creates two evaluation suites: DatBench for rapid iteration with 13× average speedup, and DatBench-Full for comprehensive final reporting. The approach preserves discriminative power while dramatically improving efficiency through careful data curation rather than wholesale benchmark replacement.

## Key Results
- Achieves 13× average speedup (up to 50×) compared to existing evaluation suites
- Maintains discriminative power while reducing computational requirements
- Reveals "overthinking penalty" where inference-time scaling degrades perceptual performance
- Demonstrates systematic masking of multimodal capabilities by language priors across popular benchmarks

## Why This Works (Mechanism)
The framework works by addressing fundamental mismatches between how VLMs are trained and how they're evaluated. Multiple-choice formats allow models to exploit language priors rather than true visual understanding, while "blindly solvable" questions test language models rather than multimodal reasoning. By converting to generative tasks and filtering out non-visual questions, the evaluation better matches the intended use case of VLMs. The discriminative sample selection ensures that computational resources are focused on questions that actually distinguish between model capabilities, rather than wasting compute on trivially easy or impossible questions.

## Foundational Learning

**Vision-Language Model Evaluation** - why needed: Traditional benchmarks often conflate language understanding with multimodal reasoning
 - quick check: Does the task require visual input to solve?

**Discriminative Power Analysis** - why needed: Ensures evaluation questions can actually distinguish between model qualities
 - quick check: Do top models show varied performance on selected samples?

**Computational Efficiency Metrics** - why needed: As models scale, evaluation cost becomes prohibitive for iterative development
 - quick check: Can evaluation be completed within reasonable compute budgets?

**Multimodal Capability Isolation** - why needed: Prevents language priors from masking true visual understanding
 - quick check: Do models perform similarly on visual vs. text-only versions?

**Inference Scaling Behavior** - why needed: Understanding how model performance changes with computational budget
 - quick check: Does performance improve monotonically with increased inference steps?

## Architecture Onboarding

**Component Map**: Data Collection -> Question Filtering -> Format Transformation -> Discriminative Selection -> Benchmark Assembly

**Critical Path**: The filtering and transformation steps are critical, as errors here directly impact evaluation validity. The discriminative selection must be performed after format transformation to ensure fair comparison.

**Design Tradeoffs**: Balancing evaluation comprehensiveness against computational efficiency requires careful sample selection. More aggressive filtering improves efficiency but risks removing genuinely challenging multimodal questions.

**Failure Signatures**: Poor discriminative power indicates insufficient filtering of trivially easy questions. High computational cost suggests inadequate sample selection. Systematic performance gaps between visual and text-only versions indicate remaining language priors.

**First Experiments**:
1. Compare model rankings on original vs. transformed datasets to verify format conversion impact
2. Test filtering criteria on known multimodal vs. language-only questions to validate heuristics
3. Evaluate sample efficiency by measuring discriminative power at different subset sizes

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the generalizability of its filtering methodology across different VLM architectures and the potential for false positives/negatives in automated filtering decisions. The completeness of the "blindly solvable" detection heuristics remains uncertain, as does the optimal balance between evaluation comprehensiveness and computational efficiency for different use cases.

## Limitations
- Transformation from multiple-choice to generative formats may not capture all strengths of classification-trained models
- Automated filtering heuristics could inadvertently remove genuinely multimodal samples
- Assumes current top-performing models represent the true ceiling of VLM capabilities

## Confidence

**High confidence**: Identification of faithfulness, discriminability, and efficiency as core desiderata for VLM evaluation

**Medium confidence**: Quantitative impact estimates (35% accuracy drop, 70% sample removal) due to dataset-specific variations

**Medium confidence**: "Overthinking penalty" observation requires further controlled experiments to rule out confounding factors

**Low confidence**: Completeness of filtering methodology and characterization of false positive/negative rates

## Next Checks
1. Conduct ablation studies comparing model rankings across different transformation and filtering thresholds
2. Perform human evaluation studies on filtered vs. unfiltered questions to validate automated decisions
3. Test "overthinking penalty" across different model families and task types with controlled inference parameters