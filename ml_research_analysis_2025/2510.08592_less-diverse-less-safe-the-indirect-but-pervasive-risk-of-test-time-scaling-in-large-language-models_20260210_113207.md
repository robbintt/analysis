---
ver: rpa2
title: 'Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling
  in Large Language Models'
arxiv_id: '2510.08592'
source_url: https://arxiv.org/abs/2510.08592
tags:
- arxiv
- less
- diversity
- llms
- autodan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work identifies a critical failure mode in Test-Time Scaling
  (TTS) methods for large language models: TTS systems are highly sensitive to candidate
  diversity. By reducing the diversity of candidate responses, TTS is more likely
  to produce unsafe outputs.'
---

# Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models

## Quick Facts
- **arXiv ID**: 2510.08592
- **Source URL**: https://arxiv.org/abs/2510.08592
- **Reference count**: 26
- **Key outcome**: Test-Time Scaling methods are highly sensitive to candidate diversity—reducing diversity increases unsafe outputs, even bypassing existing safety guardrails.

## Executive Summary
This work identifies a critical vulnerability in Test-Time Scaling (TTS) systems: their implicit reliance on diverse candidate pools for safety. When candidate diversity is reduced, TTS systems become significantly more likely to produce unsafe outputs. The authors introduce REFDIV, a reference-guided diversity stress test that steers candidate responses toward harmful outputs while reducing diversity. Through extensive experiments across multiple open-source models and TTS strategies, REFDIV consistently increases attack success rates beyond state-of-the-art jailbreak attacks, with vulnerabilities transferring to closed-source models and bypassing existing safety guardrails.

## Method Summary
REFDIV is a genetic algorithm-based stress test that reduces candidate diversity in TTS systems to induce unsafe outputs. It operates in two phases: reference-guided steering followed by entropy minimization. The fitness function dynamically weights between maximizing divergence from a reference set of affirmative tokens and minimizing token-level Shannon entropy. This curriculum-based approach avoids premature convergence and effectively drives candidates toward harmful clustering. The attack is evaluated across multiple TTS strategies (Best-of-N, MCTS) and reward models, demonstrating consistent vulnerability transfer across model architectures.

## Key Results
- Reducing candidate diversity by modest amounts significantly increases unsafe outputs in TTS systems
- REFDIV consistently outperforms state-of-the-art jailbreak attacks across all tested models and strategies
- The vulnerability transfers across TTS strategies (Best-of-N ↔ MCTS) and to closed-source models (GPT-4.1, o3-mini, Gemini-2.5-Pro)
- Existing safety guardrails (LlamaGuard, OpenAI Moderation) fail to detect REFDIV-generated prompts in ~82% of cases

## Why This Works (Mechanism)

### Mechanism 1: TTS Diversity-Safety Coupling
TTS systems implicitly rely on diverse candidate pools to maintain safety; constraining diversity compromises the selection mechanism's ability to filter harmful outputs. TTS strategies aggregate multiple candidate generations before selection, making them sensitive to perturbations that shift the distribution of candidate responses. When candidates become homogeneous, reward models cannot effectively distinguish harmful from safe responses.

### Mechanism 2: Entropy-Minimizing Curriculum Attack
A two-phase optimization (reference-guided steering → pure entropy minimization) induces mode collapse more effectively than direct adversarial prompting. The fitness function uses dynamic weighting that shifts from reference-guided diversity early in optimization to pure Shannon entropy minimization later, avoiding premature convergence to suboptimal adversarial regions.

### Mechanism 3: Cross-Strategy Transferability via Architectural Universality
Diversity-based vulnerabilities transfer across TTS strategies and to closed-source models because they exploit the fundamental TTS architecture (multi-candidate selection) rather than model-specific parameters. Both Best-of-N and MCTS aggregate multiple candidates before selection, inheriting similar sensitivity profiles to diversity reduction.

## Foundational Learning

- **Concept: Test-Time Scaling (TTS)**
  - Why needed here: The paper analyzes a failure mode specific to TTS methods; understanding that TTS allocates inference compute to explore multiple reasoning paths is essential.
  - Quick check question: Explain how Best-of-N differs from greedy decoding, and why MCTS might explore the solution space more systematically.

- **Concept: Shannon Entropy as a Diversity Proxy**
  - Why needed here: The attack's core insight is using token-level entropy to measure candidate pool diversity; lower entropy indicates more homogeneous responses.
  - Quick check question: If candidate set A has entropy H=4.2 and set B has H=2.1, which is more diverse? Why might low entropy increase the probability that TTS selects a harmful response?

- **Concept: Genetic Algorithms for Prompt Optimization**
  - Why needed here: REFDIV uses a population-based GA with crossover and mutation to evolve adversarial prompts; understanding evolutionary optimization explains how prompts are iteratively refined without gradient access.
  - Quick check question: In a GA, what role does the fitness function play? How does crossover differ from mutation in generating new candidate prompts?

## Architecture Onboarding

- **Component map**:
  - Original query → TTS pipeline (LLM generates N candidates → Reward model scores each → Selection strategy picks final output)
  - REFDIV (Initialize population → Evaluate fitness → Select parents → Crossover + mutation → New population → Repeat)

- **Critical path**: The fitness function F(x,t) = (αt-1)·norm(ΔDFS(x)) - αt·norm(DFS(x)) with dynamic weighting α(t) = exp(ln2·(t-1)/(T-1)) - 1 smoothly shifts from reference-guided to pure entropy minimization. This curriculum behavior is essential to the attack's effectiveness.

- **Design tradeoffs**:
  1. Population size (m=32) vs. computational cost
  2. Iterations (T=25) vs. convergence quality—early stopping risks weak attacks
  3. Reference set C* choice: too specific may overfit, too generic may not steer effectively
  4. Entropy vs. ASR: aggressive entropy minimization may produce unnatural prompts detectable by perplexity filters

- **Failure signatures**:
  1. Entropy doesn't decrease over iterations → fitness function not optimizing; check α(t) schedule and normalization
  2. ASR plateaus early → population converged prematurely; increase mutation rate or population size
  3. High perplexity in outputs → prompts flagged by defenses; reduce aggressive token substitutions
  4. Low cross-model transfer → source model may be too susceptible, generating weak queries; use Llama3.1-8B as source

- **First 3 experiments**:
  1. Replicate entropy-ASR correlation: Run REFDIV on Llama3.1-8B with Best-of-N. Plot Shannon entropy and ASR over 25 iterations. Expect entropy initially stable/high, then decreases sharply while ASR increases.
  2. Test cross-strategy transfer: Take successful prompts from Experiment 1. Evaluate ASR on Mistral-7B with MCTS. Compare against prompts optimized directly on Mistral-7B+MCTS. Expect comparable ASR.
  3. Evaluate guardrail bypass: Pass REFDIV-generated prompts through Llama-Guard-3 and OpenAI Moderation API. Measure false negative rate. Expect high bypass rate (~82% ASR against guardrails).

## Open Questions the Paper Calls Out

- How can TTS algorithms be explicitly redesigned to verify safety without relying on the tacit assumption of high candidate diversity?
- Do structured prompting methods like Tree-of-Thought or Self-Refine exhibit the same vulnerability to diversity reduction as search-based methods?
- Can guardrail classifiers be trained to detect the linguistic patterns of diversity-reduction attacks without flagging benign low-diversity inputs?

## Limitations
- The generalizability of diversity-safety coupling across different reward model architectures remains unclear
- REFDIV's effectiveness depends heavily on the choice of reference set C*, which is only vaguely specified
- Cross-strategy transferability results are based on limited comparisons and may not extend to all TTS methods
- Evaluation focuses on English-language harmful queries, leaving multilingual and domain-specific robustness questions open

## Confidence
- **High confidence**: The core empirical finding that reducing candidate diversity increases unsafe outputs in TTS systems
- **Medium confidence**: The mechanistic explanation linking entropy minimization to harmful clustering
- **Medium confidence**: The architectural universality argument for transferability

## Next Checks
1. **Reward model architecture ablation**: Test whether the diversity-safety coupling persists when using reward models with absolute safety thresholds rather than relative ranking.

2. **Reference set sensitivity analysis**: Systematically vary the affirmative token set C* to determine how reference choice affects attack effectiveness and false positive/negative rates.

3. **Multilingual and domain-specific transfer**: Evaluate REFDIV on non-English harmful queries and domain-specific safety-critical applications to assess generalizability beyond English general-purpose benchmarks.