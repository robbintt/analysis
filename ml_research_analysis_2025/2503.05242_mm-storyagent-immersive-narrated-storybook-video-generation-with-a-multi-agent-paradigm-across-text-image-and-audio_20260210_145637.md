---
ver: rpa2
title: 'MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent
  Paradigm across Text, Image and Audio'
arxiv_id: '2503.05242'
source_url: https://arxiv.org/abs/2503.05242
tags:
- story
- agent
- image
- writing
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents MM-StoryAgent, a multi-agent framework for generating
  narrated storybook videos. The core idea is to improve story quality and modality
  alignment by using a multi-agent, multi-stage writing pipeline for stories and modality-specific
  agents to generate images, speech, music, and sound effects.
---

# MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio

## Quick Facts
- arXiv ID: 2503.05242
- Source URL: https://arxiv.org/abs/2503.05242
- Reference count: 35
- Primary result: Multi-agent framework generates narrated storybook videos with improved story quality and cross-modal alignment

## Executive Summary
MM-StoryAgent presents a multi-agent framework for generating narrated storybook videos that addresses the limitations of single-prompt approaches in creating coherent and aligned multimodal content. The system uses a multi-stage writing pipeline with specialized agents for story generation, image creation, speech synthesis, music composition, and sound effects. By decomposing the complex task of storybook video generation into modular components, the framework achieves better story quality, improved cross-modal alignment between text, images, and audio, and produces more engaging content compared to direct prompting baselines.

## Method Summary
The framework employs a multi-agent paradigm where different specialized agents handle distinct aspects of storybook video generation. The story-writing agents collaborate through a multi-stage pipeline to produce high-quality narratives based on input settings. Separate modality-specific agents then generate corresponding images, speech, music, and sound effects. LLMs orchestrate the process, ensuring coherence across modalities while generative models handle the actual content creation. The modular design allows for independent improvement of each component and facilitates future extensions.

## Key Results
- Objective metrics show improved story quality with attractiveness, warmth, and education scores of 3.79 vs 3.58 for baseline
- Cross-modal alignment significantly improved with CLIP scores increasing from 0.432 to 0.512 and CLAP scores from 0.612 to 0.721
- The framework is open-source and provides a modular architecture for future development

## Why This Works (Mechanism)
The multi-agent approach succeeds by decomposing a complex multimodal generation task into specialized sub-tasks, allowing each agent to focus on its domain expertise. This specialization enables better quality control and alignment between modalities compared to monolithic approaches. The multi-stage writing pipeline allows for iterative refinement of story content, while the separation of concerns between different agents reduces interference and improves overall coherence. The use of LLMs as orchestrators provides the reasoning capabilities needed to maintain narrative consistency across different media types.

## Foundational Learning

**Multi-Agent Systems** - Multiple autonomous agents working together to solve complex problems by dividing tasks and coordinating efforts. Needed to handle the complexity of multimodal storybook generation where different aspects require specialized processing. Quick check: Each agent should have a clear responsibility and communication protocol.

**Cross-Modal Alignment** - Ensuring semantic consistency and coherence between different media types (text, images, audio). Critical for creating immersive storybook experiences where all elements support the narrative. Quick check: Alignment metrics like CLIP and CLAP scores should improve when the system works correctly.

**Story Generation Pipelines** - Structured workflows for creating narrative content through multiple stages of planning, drafting, and refinement. Required to produce high-quality stories that serve as the foundation for the multimodal output. Quick check: The pipeline should allow for iterative improvement and coherence checking.

## Architecture Onboarding

**Component Map**: Input Settings -> Story Writing Agents -> Image Generation Agent -> Speech Generation Agent -> Music Generation Agent -> Sound Effects Agent -> Integrated Storybook Video

**Critical Path**: The core workflow follows the sequence from input settings through story generation to final multimodal output, with each agent processing its specific output and passing it to the next stage.

**Design Tradeoffs**: The modular approach trades off some efficiency for improved quality and alignment, allowing independent optimization of each component but potentially increasing overall complexity and inference time.

**Failure Signatures**: Poor cross-modal alignment indicates issues with agent coordination or insufficient semantic understanding; low story quality suggests problems with the writing pipeline; missing or poor audio indicates failures in the audio generation components.

**First Experiments**: 1) Test individual agent performance in isolation to establish baselines, 2) Evaluate cross-modal alignment metrics on generated content, 3) Compare story quality metrics between single-prompt and multi-agent approaches.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies heavily on subjective human ratings which may not capture all aspects of story quality or user engagement
- The dataset contains only 1,567 stories, potentially limiting generalizability of results
- Cross-modal alignment metrics have known limitations in fully capturing semantic coherence between modalities
- The approach focuses primarily on children's storybooks, with unclear generalization to other genres

## Confidence

**High Confidence**: The core methodology of using multi-agent, multi-stage writing for story generation is technically sound and well-implemented. The modular design allowing separate agents for different modalities is a clear contribution.

**Medium Confidence**: The reported improvements in objective metrics and cross-modal alignment scores are convincing within the experimental setup, but the reliance on human evaluation introduces some uncertainty about the magnitude and consistency of these improvements.

**Medium Confidence**: The claim that MM-StoryAgent outperforms the direct prompting baseline is supported by the experiments, though the comparison is limited to one baseline and specific evaluation metrics.

## Next Checks
1. Conduct ablation studies to quantify the contribution of each component to overall performance, and test the system's performance without specific agents to understand their individual impact.

2. Evaluate the framework on a more diverse set of storytelling domains beyond children's storybooks, including adult fiction, educational content, and different cultural contexts, to assess generalizability.

3. Perform user studies with larger sample sizes and varied demographics to validate the subjective evaluation results, and include metrics for user engagement, retention, and comprehension beyond the current attractiveness/warmth/education scores.