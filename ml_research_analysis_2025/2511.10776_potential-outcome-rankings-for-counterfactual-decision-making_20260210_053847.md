---
ver: rpa2
title: Potential Outcome Rankings for Counterfactual Decision Making
arxiv_id: '2511.10776'
source_url: https://arxiv.org/abs/2511.10776
tags:
- assumption
- action
- bounds
- outcome
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces new counterfactual decision-making metrics:
  the probabilities of potential outcome ranking (PoR) and the probability of achieving
  the best potential outcome (PoB). PoR identifies the most probable ranking of potential
  outcomes for an individual, while PoB determines the action most likely to yield
  the top-ranked outcome.'
---

# Potential Outcome Rankings for Counterfactual Decision Making

## Quick Facts
- arXiv ID: 2511.10776
- Source URL: https://arxiv.org/abs/2511.10776
- Authors: Yuta Kawakami; Jin Tian
- Reference count: 25
- Key outcome: Introduces PoR and PoB metrics for counterfactual decision-making that identify the most probable ranking of potential outcomes and the action most likely to yield the best outcome

## Executive Summary
This paper introduces two novel counterfactual decision-making metrics: the probability of potential outcome ranking (PoR) and the probability of achieving the best potential outcome (PoB). These metrics shift focus from traditional expected outcome optimization to identifying the most probable ranking of outcomes and the action most likely to achieve the top-ranked outcome for an individual. The authors establish theoretical identification results under rank invariance assumptions and derive bounds for these metrics. Through numerical experiments and a medical case study, they demonstrate that PoR and PoB can reveal different optimal actions compared to expected outcome ranking, particularly when preferences are heterogeneous or the cost of suboptimal decisions is high.

## Method Summary
The authors develop a framework for estimating PoR and PoB by leveraging observational data under rank invariance assumptions. They establish identification theorems that characterize when these metrics can be identified from observed data, and derive both point and interval estimators. The estimation approach involves calculating the probability distribution over potential outcome rankings for each action, then identifying the most probable ranking (PoR) and the action with highest probability of achieving the best outcome (PoB). The method accounts for confounding through standard causal inference techniques while incorporating the additional structure provided by rank invariance. Numerical experiments evaluate estimator accuracy across different sample sizes and numbers of actions, revealing a linear degradation in performance as the action space grows.

## Key Results
- PoR identifies the most probable ranking of potential outcomes for an individual, while PoB determines the action most likely to yield the top-ranked outcome
- Under rank invariance assumptions, the authors establish identification theorems and derive both point and interval estimators for these metrics
- Estimator accuracy degrades linearly as the number of actions increases, with convergence rates of O(K^(3/2)N^(-1/2))
- Real-world medical data demonstrates that PoR and PoB can reveal different optimal actions compared to traditional expected outcome ranking

## Why This Works (Mechanism)
The approach works by shifting from aggregate expected value optimization to individual-level probability distributions over outcome rankings. By assuming rank invariance - that the relative ordering of potential outcomes remains consistent across individuals with similar observed characteristics - the method can identify the probability distribution over rankings from observational data. This allows decision-makers to assess not just the expected outcome of different actions, but the likelihood of achieving various outcome configurations. The PoR metric reveals the most probable scenario for an individual, while PoB identifies the action that maximizes the probability of the best possible outcome. This probabilistic framing better accommodates individual preferences and heterogeneous treatment effects that are often ignored in traditional expected value approaches.

## Foundational Learning
**Rank Invariance**: The assumption that the relative ordering of potential outcomes is preserved across individuals with similar observed characteristics
- Why needed: Enables identification of individual-level probability distributions from observational data
- Quick check: Verify that treatment effects are relatively homogeneous within covariate strata

**Counterfactual Decision-Making**: Framework for determining optimal actions based on potential outcomes under different interventions
- Why needed: Provides the theoretical foundation for causal decision-making under uncertainty
- Quick check: Ensure all relevant confounders are measured and adjusted for

**Probability of Potential Outcome Ranking (PoR)**: The probability distribution over possible rankings of potential outcomes for a given individual
- Why needed: Captures the full uncertainty about outcome configurations rather than just expected values
- Quick check: Confirm that the estimated ranking distribution sums to 1

## Architecture Onboarding

**Component Map**: Observational Data -> Confounder Adjustment -> Rank Invariance Modeling -> Probability Distribution Estimation -> PoR/PoB Calculation -> Decision Recommendation

**Critical Path**: The core computational path involves (1) estimating propensity scores or outcome models, (2) applying rank invariance to construct the joint distribution over potential outcomes, (3) calculating the probability distribution over rankings for each action, and (4) identifying the most probable ranking and best action.

**Design Tradeoffs**: The approach trades computational complexity for richer decision information. While expected outcome methods require only point estimates of conditional expectations, PoR/PoB requires full probability distributions over rankings, increasing computational demands but providing more nuanced guidance. The rank invariance assumption simplifies identification but may not hold in settings with highly heterogeneous treatment effects.

**Failure Signatures**: The method may fail when rank invariance is severely violated (highly heterogeneous treatment effects), when there are unmeasured confounders, or when the number of actions is large relative to sample size (leading to unstable probability estimates). Poor performance is indicated by wide confidence intervals or unstable estimates across bootstrap samples.

**First Experiments**: (1) Verify rank invariance holds within observed covariate strata using residual analysis; (2) Compare PoR/PoB recommendations to expected outcome recommendations on synthetic data with known ground truth; (3) Assess estimator stability by varying sample size and action space dimensions

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes rank invariance, which may be violated in settings with heterogeneous treatment effects
- Estimator accuracy degrades linearly as the number of actions increases, potentially limiting applicability in high-dimensional action spaces
- Validation is based on a single medical dataset, limiting generalizability to other domains and settings

## Confidence
- **High** confidence in theoretical identification results and asymptotic properties (mathematically derived)
- **Medium** confidence in empirical results (limited validation across datasets)
- **Low** confidence in practical applicability for high-dimensional action spaces (largely theoretical)

## Next Checks
1. Test robustness of PoR/PoB metrics under violations of rank invariance using simulation studies with known ground truth
2. Evaluate performance on multiple diverse real-world datasets across different domains to assess generalizability
3. Investigate computational efficiency and estimator performance in high-dimensional action spaces (K > 10) to better understand practical limitations