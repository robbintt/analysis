---
ver: rpa2
title: 'Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search'
arxiv_id: '2509.07969'
source_url: https://arxiv.org/abs/2509.07969
tags:
- arxiv
- turns
- visual
- reasoning
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces Mini-o3, a visual search system that generates
  deep, multi-turn reasoning trajectories (up to tens of steps) and achieves state-of-the-art
  performance on challenging visual search tasks. The method employs three key components:
  a challenging Visual Probe Dataset designed to require trial-and-error exploration,
  an iterative cold-start data collection pipeline that synthesizes diverse reasoning
  patterns via in-context learning, and an over-turn masking strategy in reinforcement
  learning that avoids penalizing over-turn trajectories to enable test-time scaling
  of interaction depth.'
---

# Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search
## Quick Facts
- arXiv ID: 2509.07969
- Source URL: https://arxiv.org/abs/2509.07969
- Authors: Xin Lai; Junyi Li; Wei Li; Tao Liu; Tianjian Li; Hengshuang Zhao
- Reference count: 40
- Primary result: Achieves 48.0% accuracy on VisualProbe-Hard, outperforming DeepEyes (35.1%) by enabling test-time scaling of interaction turns to tens of steps

## Executive Summary
Mini-o3 is a visual search system that generates deep, multi-turn reasoning trajectories to achieve state-of-the-art performance on challenging visual search tasks. The system introduces a custom Visual Probe Dataset requiring trial-and-error exploration, an iterative cold-start data collection pipeline for synthesizing diverse reasoning patterns, and an over-turn masking strategy in reinforcement learning that enables test-time scaling of interaction depth. Despite training with only six interaction turns, Mini-o3 produces trajectories that naturally scale to tens of turns at inference time, with accuracy improving as the number of turns increases.

The key innovation is the over-turn masking technique, which avoids penalizing over-turn trajectories during reinforcement learning training, allowing the system to develop complex reasoning patterns without overfitting to short trajectories. This approach enables Mini-o3 to handle challenging visual search scenarios that require extensive exploration and reasoning, achieving significantly better performance than existing open-source models on the VisualProbe-Hard benchmark.

## Method Summary
Mini-o3 employs a three-component approach to enable deep reasoning in visual search. First, it uses a challenging Visual Probe Dataset designed to require trial-and-error exploration, forcing the model to develop sophisticated search strategies. Second, an iterative cold-start data collection pipeline synthesizes diverse reasoning patterns through in-context learning, creating training data that captures complex multi-turn interactions. Third, an over-turn masking strategy in reinforcement learning training avoids penalizing trajectories that take extra turns to reach correct answers, enabling the model to learn from longer, more thorough reasoning paths. The system trains with short trajectories (six turns) but naturally scales to tens of turns at inference time, with accuracy improvements directly correlated to increased interaction depth.

## Key Results
- Achieves 48.0% accuracy on VisualProbe-Hard benchmark, significantly outperforming DeepEyes (35.1%) and other open-source models
- Successfully scales interaction turns from 6 during training to 30+ at inference time while maintaining accuracy improvements
- Demonstrates that over-turn masking is essential for enabling complex reasoning without overfitting to short trajectories
- Shows natural improvement in accuracy as interaction turns increase, validating the effectiveness of deep reasoning scaling

## Why This Works (Mechanism)
The over-turn masking strategy is the critical mechanism enabling Mini-o3's success. By not penalizing trajectories that take extra turns to reach correct answers during reinforcement learning training, the system learns to value thorough exploration over brevity. This approach prevents the model from developing shortcuts that might work on simple problems but fail on complex visual search tasks requiring deep reasoning. The iterative cold-start pipeline ensures diverse reasoning patterns are captured in training data, while the Visual Probe Dataset provides challenging scenarios that necessitate multi-turn exploration. Together, these components create a system that can naturally extend its reasoning depth at test time, unlike traditional approaches that are constrained by their training trajectory length.

## Foundational Learning
- **Trial-and-error exploration**: Why needed - Visual search often requires systematic testing of hypotheses; Quick check - Model can identify and correct false assumptions through multiple interaction turns
- **In-context learning for data synthesis**: Why needed - Creates diverse, realistic reasoning patterns for training; Quick check - Generated trajectories show varied approaches to similar problems
- **Over-turn masking in RL**: Why needed - Prevents premature convergence to suboptimal short-path strategies; Quick check - Model maintains performance while extending interaction depth beyond training limits
- **Multi-turn trajectory scaling**: Why needed - Complex visual search problems require deep reasoning; Quick check - Accuracy improves monotonically with interaction turn count
- **Visual Probe Dataset design**: Why needed - Provides challenging scenarios that require sophisticated search strategies; Quick check - Baseline models struggle significantly on the hardest test set
- **Reinforcement learning with masking**: Why needed - Balances exploration of long trajectories with efficient learning; Quick check - Model learns from both successful short and successful long paths

## Architecture Onboarding
- **Component map**: Visual Probe Dataset -> Cold-start Data Collection -> RL Training with Over-turn Masking -> Inference Scaling
- **Critical path**: Data synthesis pipeline feeds training examples to RL system, which learns to generate and extend reasoning trajectories using over-turn masking to avoid penalizing thorough exploration
- **Design tradeoffs**: Prioritizes reasoning depth over inference speed, accepts computational overhead for accuracy gains, trades immediate efficiency for long-term reasoning capability
- **Failure signatures**: Short training trajectories lead to poor performance on complex queries, lack of data diversity causes overfitting to specific patterns, incorrect masking strategy results in inefficient exploration
- **3 first experiments**: 1) Ablation test removing over-turn masking to measure impact on trajectory scaling, 2) Training with fixed 6-turn limit to compare against test-time scaling performance, 3) Evaluation on real-world visual search datasets to assess generalization beyond synthetic data

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on custom Visual Probe Dataset and synthetic data collection pipeline that may not capture full diversity of real-world visual search scenarios
- Over-turn masking technique may introduce bias toward accepting incorrect intermediate steps that ultimately lead to correct answers, potentially limiting reliability in safety-critical applications
- Training methodology requires access to powerful base model capable of in-context learning for data synthesis, which may not be available to all research groups
- Performance gains from scaling interaction turns at test time have not been thoroughly characterized across different types of visual search problems or evaluated for computational efficiency trade-offs

## Confidence
- State-of-the-art performance claim (48.0% vs 35.1% on VisualProbe-Hard): High confidence based on reported results and comparison methodology
- Over-turn masking essential for complex reasoning without overfitting: Medium confidence, supported by ablation studies but long-term generalization effects require further validation
- Natural scaling to tens of interaction turns with accuracy improvements: Medium confidence, scaling behavior may depend on specific problem characteristics not fully explored

## Next Checks
1. Evaluate Mini-o3's performance on diverse, real-world visual search datasets beyond the synthetic Visual Probe Dataset to assess generalization capabilities
2. Conduct comprehensive computational efficiency analysis comparing Mini-o3's performance against baselines when scaling interaction turns from 6 to 30+, including memory usage and inference time measurements
3. Perform ablation studies isolating effects of each component (Visual Probe Dataset, cold-start pipeline, over-turn masking) on different types of visual search problems to determine their relative contributions to performance gains