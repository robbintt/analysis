---
ver: rpa2
title: 'KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs'
arxiv_id: '2507.13666'
source_url: https://arxiv.org/abs/2507.13666
tags:
- response
- representative
- responses
- gpt-4
- cascade
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes KiC, a keyword-inspired cascade framework that
  reduces API costs for free-form text generation by intelligently routing queries
  between a weaker and a stronger LLM. Instead of relying on exact text matching,
  KiC selects a representative response using keyword-weighted TF-IDF and evaluates
  semantic consistency across multiple outputs.
---

# KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs

## Quick Facts
- **arXiv ID:** 2507.13666
- **Source URL:** https://arxiv.org/abs/2507.13666
- **Reference count:** 24
- **Primary result:** Achieves 97.53% of GPT-4's accuracy while reducing API costs by 28.81% on average through intelligent query routing

## Executive Summary
This paper introduces KiC, a keyword-inspired cascade framework designed to reduce API costs for free-form text generation using large language models. The framework intelligently routes queries between a weaker and stronger LLM by generating multiple responses from the weaker model, selecting a representative response using keyword-weighted TF-IDF, and evaluating semantic consistency across outputs. If responses are sufficiently consistent, it uses the weaker model's output; otherwise, it escalates to the stronger model. The approach demonstrates significant cost savings while maintaining high accuracy, even outperforming GPT-4 on one dataset.

## Method Summary
KiC employs a cascading approach that leverages both weaker and stronger LLMs to optimize cost and accuracy. For each query, the system first generates multiple responses from a weaker LLM, then selects a representative response using keyword-weighted TF-IDF analysis. It evaluates semantic consistency across these multiple outputs, and if they meet a predefined threshold, returns the weaker model's response. Otherwise, it escalates the query to a stronger LLM. This approach intelligently balances cost efficiency with quality assurance by using the cheaper model when its outputs are consistent, and only resorting to the more expensive model when necessary.

## Key Results
- Achieved 97.53% of GPT-4's accuracy while reducing API costs by 28.81% on average
- Outperformed GPT-4 on one dataset, demonstrating complementary model performance
- Demonstrated effectiveness across three different benchmarks

## Why This Works (Mechanism)
The framework works by exploiting the observation that weaker LLMs can produce consistent and accurate outputs for many queries, making it unnecessary to use expensive models for all requests. By generating multiple responses and checking their semantic consistency, KiC can identify when the weaker model is performing reliably. The keyword-weighted TF-IDF approach helps select the most representative response from multiple outputs, ensuring quality selection without requiring additional LLM calls. This cascading mechanism effectively uses the stronger model as a backup only when the weaker model's outputs lack consistency, optimizing the cost-quality trade-off.

## Foundational Learning

### Keyword-weighted TF-IDF
- **Why needed:** To select the most representative response from multiple LLM outputs without requiring additional LLM calls
- **Quick check:** Verify that the selected response captures the main themes across all generated outputs

### Semantic consistency evaluation
- **Why needed:** To determine whether multiple outputs from the weaker model are reliable enough to use
- **Quick check:** Ensure consistency scores correlate with actual output quality across different query types

### Cascade routing logic
- **Why needed:** To intelligently decide when to use cheaper vs. more expensive models
- **Quick check:** Validate that the routing mechanism correctly identifies scenarios requiring stronger models

## Architecture Onboarding

### Component map
KiC -> Keyword-weighted TF-IDF selector -> Semantic consistency evaluator -> Weaker LLM -> Stronger LLM

### Critical path
Query → Multiple weaker LLM responses → TF-IDF selection → Consistency check → Return weaker output OR escalate to stronger LLM

### Design tradeoffs
Uses keyword-based selection instead of embedding-based similarity to reduce computational overhead, accepting potential limitations in capturing nuanced semantic relationships. Balances the number of weaker LLM responses against cost and latency considerations.

### Failure signatures
- Inconsistent outputs from weaker LLM may lead to unnecessary escalation
- Keyword-weighted TF-IDF may miss semantic nuances in diverse query types
- Threshold settings may be suboptimal for certain domains

### First experiments
1. Test keyword-weighted TF-IDF selection against random selection across diverse query types
2. Vary the number of weaker LLM responses to find optimal cost-quality balance
3. Test different semantic consistency thresholds to optimize cascade accuracy

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, though several uncertainties remain regarding the robustness of the keyword-weighted TF-IDF selection method across diverse domains and query types.

## Limitations
- Performance may degrade on domains with different keyword distributions or queries requiring nuanced understanding
- Semantic consistency assumption may not hold for subjective or creative generation tasks
- Multiple LLM calls per query could introduce latency concerns not captured in current analysis

## Confidence

- **Cost reduction claims:** High - Well-supported by empirical results across multiple benchmarks
- **Outperformance of GPT-4:** Medium - Demonstrated but requires further validation for generalization
- **Keyword-weighted TF-IDF effectiveness:** Medium - Shows reasonable performance but lacks comparison with alternative methods

## Next Checks

1. Test KiC's performance on diverse domain-specific text generation tasks (medical, legal, creative writing) to assess generalizability
2. Implement latency measurements for the complete KiC pipeline to quantify cost-quality-time trade-offs
3. Compare keyword-weighted TF-IDF selection against embedding-based semantic similarity methods for improved quality consistency