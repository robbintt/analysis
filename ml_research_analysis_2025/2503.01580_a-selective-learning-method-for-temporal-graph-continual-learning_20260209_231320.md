---
ver: rpa2
title: A Selective Learning Method for Temporal Graph Continual Learning
arxiv_id: '2503.01580'
source_url: https://arxiv.org/abs/2503.01580
tags:
- learning
- gsub
- gold
- temporal
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of updating models in temporal
  graphs with open-class dynamics, termed temporal graph continual learning (TGCL).
  Existing methods either ignore new classes or fail to account for the evolution
  of old-class data, leading to inefficiency or forgetting.
---

# A Selective Learning Method for Temporal Graph Continual Learning

## Quick Facts
- **arXiv ID:** 2503.01580
- **Source URL:** https://arxiv.org/abs/2503.01580
- **Reference count:** 40
- **Primary result:** Proposes Learning Towards the Future (LTF), a selective learning framework for temporal graph continual learning that significantly improves average precision (AP) and average forgetting (AF) on real-world datasets.

## Executive Summary
This paper addresses the challenge of updating models in temporal graphs with open-class dynamics, termed temporal graph continual learning (TGCL). Existing methods either ignore new classes or fail to account for the evolution of old-class data, leading to inefficiency or forgetting. To tackle TGCL, the authors propose a selective learning framework called Learning Towards the Future (LTF) that selects and learns representative subsets of old-class data. LTF derives an upper bound on the error caused by approximating the full old-class data with a subset and transforms it into objectives for subset selection and learning. Experiments on three real-world datasets (Yelp, Reddit, and Amazon) validate the effectiveness of LTF on TGCL, showing significant improvements in average precision (AP) and average forgetting (AF) compared to baseline methods while maintaining high efficiency.

## Method Summary
LTF operates on top of temporal graph backbone models (TGAT or DyGFormer) to handle TGCL. For each new period, it extracts embeddings from the previous model to partition old data and greedily select two subsets: $G_{sub}$ (minimizing classification error + MMD) and $G_{sim}$ (minimizing MMD only). The model is then trained on new data combined with $G_{sub}$, with a distribution alignment loss enforcing the embeddings of $G_{sub}$ to match those of $G_{sim}$. This approach theoretically bounds the error from using subsets while maintaining efficiency through submodular optimization.

## Key Results
- LTF achieves significant improvements in average precision (AP) compared to baseline methods (Finetune, Joint) on Yelp, Reddit, and Amazon datasets.
- The framework effectively reduces average forgetting (AF), demonstrating successful preservation of old-class knowledge.
- Random partitioning strategy outperforms K-means for subset selection, preserving global distribution better.
- The distribution alignment component is critical for generalization, with consistent performance degradation when removed.

## Why This Works (Mechanism)

### Mechanism 1: Error Upper Bound Approximation
The paper derives an upper bound on classification error when approximating full historical data with a subset. This bound decomposes error into subset's own error, distribution discrepancy (HÎ”H divergence), and prediction difference between old and new models. By minimizing this bound, subset selection becomes a proxy for learning on full distribution.

### Mechanism 2: Greedy Submodular Optimization
The selection objective combines empirical classification error and distribution matching (MMD), proven to be a monotone submodular function. This guarantees a greedy algorithm achieves a solution within $(1-1/e)$ of optimal without exhaustive search.

### Mechanism 3: Distribution Alignment via Regularization
A secondary "similarity subset" is selected to minimize MMD with full old data. During training, a distribution alignment loss forces embeddings of the primary training subset to match the distribution of this reference subset (via stop-gradient), ensuring generalization.

## Foundational Learning

- **Concept: Temporal Graph Networks (TGNs)**
  - Why needed: LTF operates on top of TGL backbone models (like TGAT or DyGFormer) that generate node embeddings from temporal events.
  - Quick check: Can you explain how a TGAT model aggregates neighbor information differently than a static GNN?

- **Concept: Catastrophic Forgetting**
  - Why needed: This is the core problem LTF solves - why fine-tuning on new data destroys previously learned knowledge about old classes.
  - Quick check: Why does minimizing loss on new class data typically increase error on old class data in a shared classifier?

- **Concept: Maximum Mean Discrepancy (MMD)**
  - Why needed: MMD is the core metric used in selection phase and alignment loss to measure distance between distributions without explicit density estimation.
  - Quick check: How does the "kernel trick" allow MMD to measure non-linear differences between two sets of embeddings?

## Architecture Onboarding

- **Component map:** Backbone Encoder (Frozen/Unfrozen) -> Greedy Selector -> Buffers ($G_{sub}$, $G_{sim}$) -> Loss Aggregator
- **Critical path:** Partitioning old data -> Embedding extraction using previous model -> Selection of $G_{sub}$ and $G_{sim}$ -> Training on new data + buffers with distribution alignment
- **Design tradeoffs:**
  - Partition Size: Larger improves selection quality but increases computational complexity quadratically
  - Buffer Size: Increasing training subset size improves performance monotonically but requires more memory
  - Random vs Clustered Partition: Random outperforms K-means by preserving global distribution better
- **Failure signatures:**
  - High Training Time: Likely caused by partition size too large, making greedy selection step quadratic
  - High Forgetting on Dense Graphs: Verify balance hyperparameter $\alpha$ is tuned; Amazon requires higher error weighting
- **First 3 experiments:**
  1. Sanity Check: Run Finetune vs Joint baselines to establish performance envelope
  2. Component Ablation: Run LTF with only Error selection, only Distribution selection, then both combined
  3. Partition Robustness: Verify different partition sizes (2500 vs 5000 vs 10000) to find GPU memory vs AP tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can LTF be adapted for link prediction tasks involving new user profiles or content categories?
- Basis: Appendix M mentions similar challenges exist in "other temporal graph tasks, such as link prediction with new user profiles or content categories."
- Why unresolved: Current selection objective and error upper-bound are derived specifically for node classification, relying on node labels which may not translate directly to link prediction structures.
- What evidence would resolve it: Extension of theoretical upper-bound to link prediction and empirical validation on link prediction datasets.

### Open Question 2
- Question: Does random partitioning remain effective on graphs with highly skewed or community-based temporal distributions?
- Basis: Section 3.2 mentions using "random partition" but notes "Kmeans or Hierarchical clustering alter data distribution."
- Why unresolved: Random partitioning assumes sufficient sample size to approximate distribution, but this may fail if temporal events are bursty or strictly confined to specific communities.
- What evidence would resolve it: Experiments on synthetic datasets with varying degrees of community structure or temporal skew.

### Open Question 3
- Question: How does the method perform in scenarios involving "concept drift" where old classes effectively disappear or merge?
- Basis: Problem definition assumes disjoint new classes and focuses on "maintaining up-to-date knowledge of old classes," but doesn't address removal or obsolescence of classes over time.
- Why unresolved: Memory buffer is designed to preserve knowledge, but if an old class becomes irrelevant or its distribution changes to match a new class, preservation mechanism might hinder learning of new concepts.
- What evidence would resolve it: Evaluation on datasets with explicitly defined class death or merging events.

## Limitations

- The RBF kernel bandwidth $\gamma$ for MMD is described as "properly parameterized" but lacks precise specification, creating ambiguity in reproducibility.
- While theoretical guarantees are established, empirical validation focuses on downstream metrics rather than measuring actual distribution discrepancy reduction.
- Distribution alignment component's effectiveness relies heavily on reference subset size, which is not thoroughly explored for edge cases where the subset is small.

## Confidence

- **High Confidence:** Core mechanism of error upper bound derivation and transformation into submodular objectives is mathematically sound.
- **Medium Confidence:** Empirical validation across three datasets demonstrates effectiveness, but lack of comparison against state-of-the-art TGCL methods limits benchmarking claims.
- **Low Confidence:** Distribution alignment component's effectiveness relies heavily on reference subset size, which is not thoroughly explored for edge cases.

## Next Checks

1. Implement the greedy selector with a tuned RBF kernel bandwidth and verify the monotonic increase in the witness function during selection.
2. Run an ablation study isolating the distribution alignment loss to quantify its impact on forgetting across all three datasets.
3. Test the algorithm's robustness to non-random partitioning (e.g., temporal clustering) to validate the assumption that random partitioning preserves global distribution.