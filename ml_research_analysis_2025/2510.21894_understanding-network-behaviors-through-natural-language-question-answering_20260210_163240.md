---
ver: rpa2
title: Understanding Network Behaviors through Natural Language Question-Answering
arxiv_id: '2510.21894'
source_url: https://arxiv.org/abs/2510.21894
tags:
- network
- language
- configuration
- reasoning
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of understanding network behaviors
  using natural language (NL) queries, addressing the complexity of large-scale networks
  with diverse router configurations. It introduces NetMind, a framework that employs
  a tree-based configuration chunking strategy to preserve semantic coherence in lengthy
  router configurations, a unified fact graph intermediate representation to normalize
  vendor-specific configurations, and a hybrid imperative-declarative language to
  reduce reasoning burden on large language models (LLMs).
---

# Understanding Network Behaviors through Natural Language Question-Answering

## Quick Facts
- arXiv ID: 2510.21894
- Source URL: https://arxiv.org/abs/2510.21894
- Reference count: 40
- One-line primary result: NetMind achieves ~85% F1 accuracy on NL network behavior QA without performance degradation as network scale increases.

## Executive Summary
This paper addresses the challenge of understanding complex network behaviors through natural language queries, where large-scale networks with heterogeneous router configurations create significant context and reasoning burdens for large language models (LLMs). The proposed NetMind framework introduces a tree-based configuration chunking strategy to preserve semantic coherence, a unified fact graph intermediate representation to normalize vendor-specific syntax, and a hybrid imperative-declarative query language to reduce LLM reasoning burden. Experiments demonstrate that NetMind significantly outperforms existing methods across diverse network scales, with the best-performing LLM variant (Qwen3-32B) achieving an average F1 score of around 85% without suffering performance degradation as network size increases.

## Method Summary
NetMind employs a three-stage pipeline to understand network behaviors from natural language queries. First, it parses router configurations into semantically coherent chunks using a tree-based dependency linking approach that preserves cross-block references through root-to-leaf path extraction. Second, it constructs a unified fact graph intermediate representation where LLMs extract explicit facts from configuration chunks and protocol-specific rules deduce implicit facts, normalizing heterogeneous vendor syntax into a common semantic structure. Third, it generates hybrid imperative-declarative programs where LLMs produce code mixing Datalog predicates for routine queries with Python for complex logic, which a unified runtime executes to produce answers.

## Key Results
- Qwen3-32B achieves ~85% average F1 score on NL network behavior QA, significantly outperforming direct, RAG, and imperative-only approaches
- NetMind maintains consistent performance across network scales (32-197 routers) without degradation, while baselines fail on medium/large networks
- Tree-based chunking preserves semantic coherence, achieving Graph Match Ratio of 0.8485 vs 0.4494 for baseline on fact extraction
- Hybrid imperative-declarative language outperforms both pure imperative and pure declarative approaches across all question types

## Why This Works (Mechanism)

### Mechanism 1: Tree-Based Configuration Chunking
- Claim: Decomposing lengthy router configurations into semantically coherent chunks preserves contextual dependencies that fixed-length chunking destroys, enabling LLMs to process network-scale inputs without information fragmentation.
- Mechanism: Configuration files are parsed into functional blocks (e.g., interface definitions, route maps), then linked via reference-based dependencies (e.g., a BGP policy referencing a route map, which references an IP prefix list). Root-to-leaf paths in this dependency tree form self-contained chunks that include both usage and full definition of all referenced entities.
- Core assumption: Network operators structure configurations with identifiable syntactic boundaries (indentation, comment delimiters) and cross-block references follow naming conventions amenable to regex-based matching.
- Evidence anchors:
  - [abstract] "tree-based configuration chunking strategy to preserve semantic coherence while enabling efficient partitioning"
  - [section 4.2] Algorithm 1 details the three-stage process: block identification, dependency linking, and path extraction
  - [corpus] Limited corpus support; neighbor papers address LLM QA broadly but not network-specific chunking
- Break condition: Vendor formats without clear block delimiters, or heavily obfuscated/minified configurations would disrupt regex-based parsing.

### Mechanism 2: Fact Graph Intermediate Representation
- Claim: Normalizing heterogeneous vendor configurations into a unified fact graph enables both symbolic inference (via Datalog rules) and graph algorithms (topology traversal), abstracting away syntax variations while preserving semantic structure.
- Mechanism: LLMs extract explicit facts (e.g., Router(R1), Interface(Fa0/0, 10.0.0.71/31)) from configuration chunks into a Datalog-like fact base. Protocol-specific rules then deduce implicit facts (e.g., RouteEdge from matching subnets, BGPPeer from neighbor configurations). Facts become nodes; relationships become edges in a unified graph.
- Core assumption: Fine-tuned LLMs can reliably map vendor-specific syntax to a predefined fact schema, and protocol rules are complete enough to deduce implicit behaviors correctly.
- Evidence anchors:
  - [abstract] "unified fact graph intermediate representation to normalize vendor-specific configurations"
  - [section 4.3, Table 2] Llama3.1-8B-SFT achieves 0.8485 average Graph Match Ratio vs. 0.4494 for baseline
  - [corpus] Neighbor paper on logical forms (arXiv:2502.09589) supports hybrid symbolic-neural approaches for reasoning tasks
- Break condition: Novel configuration primitives outside the predefined fact schema, or protocols with incomplete rule coverage, would yield missing or incorrect implicit facts.

### Mechanism 3: Hybrid Imperative-Declarative Query Language
- Claim: Offloading routine network queries to declarative predicates (e.g., ExistPath, TraceRoute) while reserving imperative Python for complex logic reduces LLM code-generation error rates by constraining the solution space.
- Mechanism: LLMs generate programs mixing Datalog predicates (executed by a Datalog solver or routing simulator) with Python control flow. Declarative predicates handle well-defined queries; imperative code handles numerical comparisons, multi-step logic, and result aggregation. A unified runtime executes both.
- Core assumption: LLMs generate syntactically correct hybrid code more reliably than pure Python, and the predefined predicate set covers most query types without forcing awkward workarounds.
- Evidence anchors:
  - [abstract] "hybrid imperative-declarative language to reduce the reasoning burden on LLMs"
  - [section 5.6, Figure 5] Hybrid language outperforms both imperative-only and declarative-only baselines across four question types
  - [corpus] KBQA agentic reasoning paper (arXiv:2510.25101) supports hybrid logical query generation with LLMs
- Break condition: Queries requiring predicates outside the defined set, or complex multi-hop reasoning exceeding current predicate composability, may force verbose imperative workarounds.

## Foundational Learning

- Concept: **Datalog and Declarative Logic Programming**
  - Why needed here: The fact graph IR and hybrid language rely on Datalog-style facts and rules. Understanding how Datalog separates data (facts) from logic (rules), and how inference derives new facts, is essential to grasp why implicit facts like RouteEdge are computable.
  - Quick check question: Given facts Parent(Alice, Bob) and Parent(Bob, Carol), and rule Grandparent(X, Z) ← Parent(X, Y) ∧ Parent(Y, Z), what fact can be derived?

- Concept: **BGP and OSPF Protocol Basics**
  - Why needed here: The paper's fact extraction and rule deduction assume familiarity with routing concepts—BGP attributes (local preference, AS path), OSPF costs, neighbor relationships. Without this, the fact schema and implicit deduction rules will seem arbitrary.
  - Quick check question: In BGP, what attribute typically determines exit path selection before AS path length is considered?

- Concept: **LLM Context Windows and Chunking Tradeoffs**
  - Why needed here: The tree-based chunking mechanism directly addresses LLM context limits. Understanding why naive fixed-length chunking disrupts semantic coherence (splitting a route map from its referenced prefix list) clarifies why dependency-aware chunking matters.
  - Quick check question: A 50k-token configuration is split into 4k-token chunks. A route map at chunk boundary references a prefix list in the previous chunk. What information loss occurs at inference time?

## Architecture Onboarding

- Component map: Raw vendor configurations -> Tree-based chunking (Algorithm 1) -> LLM fact extraction (Llama3.1-8B-SFT) -> Fact base -> Rule-based implicit deduction -> Fact graph IR -> LLM generates hybrid code (Qwen3-32B) -> Runtime executes declarative (Datalog/simulator) + imperative (Python) -> Answer returned

- Critical path: Chunking quality -> fact extraction accuracy -> fact graph completeness -> code generation correctness. Errors propagate; fact graph gaps cause downstream query failures even with perfect code.

- Design tradeoffs:
  - Chunking granularity: Larger chunks preserve more context but may exceed token limits; smaller chunks risk fragmenting dependencies.
  - Fact schema breadth: More predicates cover more query types but increase LLM extraction complexity and fine-tuning data requirements.
  - Hybrid language expressiveness: More declarative predicates simplify common queries but constrain flexibility; more imperative freedom increases error risk.

- Failure signatures:
  - Zero F1 on large networks in Direct/RAG modes indicates context overflow or semantic fragmentation (Table 1).
  - Low Graph Match Ratio on fact extraction (Table 2 baseline ~0.45) indicates chunking or extraction failures.
  - Declarative-only failures on OrderedPath/KConnected (Figure 5) indicate queries requiring imperative computation beyond available predicates.

- First 3 experiments:
  1. **Validate chunking integrity**: Run tree-based chunking on a multi-vendor configuration (Cisco + Huawei). Verify each root-to-leaf path contains complete definitions for all referenced entities. Compare against fixed-length chunking to identify broken references.
  2. **Test fact extraction accuracy**: Feed chunked paths to Llama3.1-8B-SFT. Compute Graph Match Ratio against human-annotated ground truth. Identify missing or hallucinated facts; check whether errors stem from chunking gaps or model limitations.
  3. **Evaluate hybrid code generation**: Submit 20 NL queries spanning all four types (ExistPath, OrderedPath, LoadBalance, KConnected) to Qwen3-32B. Execute generated code. Manually verify answers against known network state. Log failures by type (syntax error, wrong predicate, logic error).

## Open Questions the Paper Calls Out

- **Open Question 1**: How can reinforcement learning be effectively integrated to enhance the reasoning and code generation capabilities of NetMind for complex network management scenarios?
  - Basis in paper: [explicit] Section 6 (Conclusion) states, "In future work, we plan to incorporate reinforcement learning to further enhance the reasoning and code generation capabilities."
  - Why unresolved: The paper establishes the current hybrid framework but leaves the integration of RL for policy optimization as a future direction to improve accuracy.
  - What evidence would resolve it: Experimental results demonstrating improved F1 scores or reduced latency when an RL-based component is applied to the code generation phase.

- **Open Question 2**: To what extent does NetMind's performance generalize to real-world, manually authored router configurations that contain non-standard syntax or legacy noise?
  - Basis in paper: [inferred] Section 5.1 notes that the benchmark configurations were "synthesized" using NetComplete rather than collected from operational networks, potentially limiting the evaluation of the system's robustness to human-authored idiosyncrasies.
  - Why unresolved: Synthesized configurations are structurally consistent, whereas real-world files often include vendor-specific hacks, comments, or deprecated commands that may break the tree-based chunking or fact extraction.
  - What evidence would resolve it: Evaluation of the framework on a benchmark of raw, uncleaned configuration files from production networks.

- **Open Question 3**: Can the fact graph intermediate representation generalize to unseen network device vendors without requiring extensive fine-tuning on new configuration syntaxes?
  - Basis in paper: [inferred] Table 2 shows that without specific fine-tuning (SFT), even large models like Qwen3-32B fail to extract facts on medium/large networks (GMR of 0.0), suggesting the extraction process is heavily dependent on the specific training data.
  - Why unresolved: The system relies on a fine-tuned model (Llama3.1-8B-SFT) for extraction; it is unclear if the extraction rules are robust enough to handle zero-shot translation of syntax from minor or unseen vendors.
  - What evidence would resolve it: Zero-shot extraction performance metrics (GMR) on configuration formats from vendors not represented in the SFT dataset.

- **Open Question 4**: Is the proposed hybrid imperative-declarative language sufficiently expressive to handle counterfactual "what-if" queries (e.g., "If link X fails...")?
  - Basis in paper: [inferred] While the paper claims to handle "complex topologies," the benchmark (Section 5.1) and Appendix A.2 focus strictly on static factual queries like ExistPath and TraceRoute, leaving dynamic state analysis unverified.
  - Why unresolved: Network verification often requires reasoning about hypothetical topology changes, which demands a different handling of state in the fact graph and execution backend than static queries.
  - What evidence would resolve it: Evaluation of the system on a dataset of counterfactual questions requiring the simulation of link failures or policy changes.

## Limitations

- The 471 configuration-to-fact annotation pairs used for fine-tuning are not publicly released, creating a significant barrier to reproducing the fact extraction component.
- Complete prompt templates for fact extraction and code generation are truncated in the appendix, leaving ambiguity in implementation details.
- The integration details between the Datalog solver and Python runtime are unspecified, potentially affecting the hybrid execution layer.
- Vendor-specific configuration nuances across five different vendors may not be fully captured in the synthesis process, potentially introducing brittleness.

## Confidence

- **High confidence** in the chunking mechanism's theoretical soundness and empirical validation (clear algorithm, strong GMR results)
- **Medium confidence** in the fact graph IR approach (relies on fine-tuning quality and rule completeness)
- **Medium confidence** in the hybrid language approach (strong ablation results but implementation details are sparse)

## Next Checks

1. **Chunking integrity validation**: Implement tree-based chunking on a multi-vendor configuration (Cisco + Huawei) and verify that each root-to-leaf path contains complete definitions for all referenced entities. Compare against fixed-length chunking to quantify reference breakage rates.
2. **Fact extraction accuracy measurement**: Fine-tune Llama3.1-8B with LoRA using a small curated dataset of 50 configuration-to-fact pairs. Compute Graph Match Ratio against ground truth and identify systematic extraction failures.
3. **Hybrid code generation robustness**: Test Qwen3-32B on 30 NL queries spanning all four question types (ExistPath, OrderedPath, LoadBalance, KConnected). Measure execution success rate and answer accuracy, logging failures by type to identify weak spots in the hybrid language design.