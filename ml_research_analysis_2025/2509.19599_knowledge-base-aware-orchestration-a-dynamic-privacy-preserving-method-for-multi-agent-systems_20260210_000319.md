---
ver: rpa2
title: 'Knowledge Base-Aware Orchestration: A Dynamic, Privacy-Preserving Method for
  Multi-Agent Systems'
arxiv_id: '2509.19599'
source_url: https://arxiv.org/abs/2509.19599
tags:
- agent
- orchestration
- orchestrator
- agents
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Knowledge Base-Aware (KBA) Orchestration,
  a dynamic method for improving task routing in multi-agent systems by leveraging
  each agent's private knowledge base. The core idea is to augment static agent descriptions
  with real-time, privacy-preserving relevance signals generated when agents assess
  task compatibility against their own knowledge.
---

# Knowledge Base-Aware Orchestration: A Dynamic, Privacy-Preserving Method for Multi-Agent Systems

## Quick Facts
- **arXiv ID:** 2509.19599
- **Source URL:** https://arxiv.org/abs/2509.19599
- **Reference count:** 40
- **Primary result:** KBA achieves 87.1% accuracy with minimal descriptions and up to 95.0% with detailed descriptions, outperforming static baselines (43.6%–68.6%).

## Executive Summary
This paper introduces Knowledge Base-Aware (KBA) Orchestration, a dynamic method for improving task routing in multi-agent systems by leveraging each agent's private knowledge base. The core idea is to augment static agent descriptions with real-time, privacy-preserving relevance signals generated when agents assess task compatibility against their own knowledge. When initial routing confidence is low, agents are probed in parallel to return lightweight acknowledgments without exposing underlying data, which populates a shared semantic cache for future routing. Experimental results show that KBA significantly outperforms traditional static description-driven orchestration, achieving 87.1% accuracy with minimal descriptions and up to 95.0% with detailed descriptions, compared to 43.6%–68.6% for the baseline. While KBA incurs higher computational costs due to dynamic probing, the use of semantic caching mitigates this overhead. Overall, KBA provides a more adaptive, accurate, and scalable approach to multi-agent orchestration, especially in environments where agent capabilities evolve over time.

## Method Summary
KBA Orchestration dynamically routes queries to appropriate agents by combining static agent descriptions with real-time knowledge base probing. The orchestrator first attempts a semantic cache lookup; if no match is found, it scores agents using an LLM over their descriptions. If the top score exceeds a configurable confidence threshold, it routes directly; otherwise, it issues parallel probes to all candidate agents. Each agent searches its private knowledge base and returns a lightweight OK/KO acknowledgment without exposing content. The orchestrator routes based on the probe responses and updates the cache. This approach improves accuracy over static routing while preserving privacy and enabling adaptation to evolving agent capabilities.

## Key Results
- KBA achieves 87.1% accuracy with minimal (Basic) descriptions versus 43.6% for baseline.
- With detailed (Detailed) descriptions, KBA reaches 95.0% accuracy versus 68.6% for baseline.
- KBA incurs higher latency (567s vs. 106s) due to probing, but semantic caching mitigates repeated overhead.

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Knowledge Probing Replaces Static Description Matching
- **Claim:** When orchestrator confidence is low, querying agents' private knowledge bases for lightweight relevance signals improves routing accuracy over static descriptions alone.
- **Mechanism:** The orchestrator issues parallel probes to candidate agents. Each agent searches its KB and returns a binary ACK (OK/KO) without exposing content. The orchestrator routes based on which agent signals capability.
- **Core assumption:** Agents can accurately assess task relevance against their KB via similarity search or LLM classification, and will truthfully report capability.
- **Evidence anchors:**
  - [abstract]: "When static descriptions are insufficient for a clear routing decision, the orchestrator prompts the subagents in parallel. Each agent then assesses the task's relevance against its private KB, returning a lightweight ACK signal without exposing the underlying data."
  - [Section 3.1.3]: "Agents respond with a simple, lightweight acknowledgment (e.g., OK/KO) based on a search of their private knowledge base... without exposing any content."
  - [corpus]: Related work (CASTER, TCAndon-Router) confirms routing accuracy gains from dynamic/context-aware strategies, though standardized probing protocols remain underexplored.
- **Break condition:** If agents' internal retrieval is noisy, incomplete, or if OK/KO thresholds are poorly calibrated, probing may return false positives/negatives, degrading accuracy below baseline.

### Mechanism 2: Semantic Caching Amortizes Probing Cost
- **Claim:** Caching successful routing decisions keyed by query embeddings reduces repeated probing overhead for semantically similar queries.
- **Mechanism:** After a correct routing decision, the query embedding and chosen agent are stored. Future queries within a similarity threshold reuse the cached route without probing.
- **Core assumption:** Semantically similar queries should route to the same agent, and the embedding model captures task intent reliably.
- **Evidence anchors:**
  - [abstract]: "These collected signals populate a shared semantic cache, providing dynamic indicators of agent suitability for future queries."
  - [Section 3.1.5]: Defines invalidation spheres in embedding space and threshold trade-offs (precision vs. coverage).
  - [corpus]: Corpus evidence on semantic caching in orchestration is limited; related papers focus more on routing logic than caching strategies.
- **Break condition:** Cache thrashing occurs if queries are semantically similar but require different agents, or if invalidation thresholds are too aggressive/conservative, leading to stale or over-purged entries.

### Mechanism 3: Confidence-Based Escalation Gates Probing Expense
- **Claim:** Only invoking probing when initial routing confidence is below threshold τ constrains computational overhead while preserving accuracy gains.
- **Mechanism:** LLM assigns confidence scores to each agent based on static descriptions. If top score exceeds τ, route directly; otherwise, escalate to probing.
- **Core assumption:** The LLM can reliably signal its own uncertainty, and τ is appropriately tuned for the domain.
- **Evidence anchors:**
  - [Section 3.1.2]: "If the top score exceeds a configurable threshold (τ), the query is routed directly to that agent. Otherwise, the routing is considered uncertain and escalated to the probing tool."
  - [Section 4.4.1]: Temperature variation (0.2–0.8) showed minor accuracy changes, suggesting confidence calibration is relatively stable.
  - [corpus]: Assumption: Corpus papers do not explicitly address confidence-gated escalation mechanisms.
- **Break condition:** If τ is set too high, probing is underutilized and accuracy degrades; if too low, probing overhead becomes prohibitive.

## Foundational Learning

- **Concept: Semantic Embedding Spaces**
  - **Why needed here:** Both cache lookup and KB retrieval rely on vector similarity; misunderstanding embedding geometry leads to misconfigured thresholds.
  - **Quick check question:** Can you explain why cosine similarity of 0.85 might cluster "reset my password" with "change my email" but not with "book a meeting room"?

- **Concept: Multi-Agent Orchestration Patterns (Deterministic vs. Description-Driven)**
  - **Why needed here:** KBA builds on description-driven orchestration; understanding its failure modes (ambiguity, staleness) clarifies why probing is necessary.
  - **Quick check question:** Given two agents with overlapping descriptions, would deterministic routing help or hurt? Why?

- **Concept: Privacy-Preserving Signaling**
  - **Why needed here:** The OK/KO mechanism must not leak KB content; understanding what constitutes a "lightweight signal" is critical for secure implementation.
  - **Quick check question:** If an agent returns "Partial Content" with a confidence score, what additional risk does this introduce compared to binary OK/KO?

## Architecture Onboarding

- **Component map:**
  - Orchestrator (LLM-based router with confidence scoring)
  - Semantic Cache (embedding store with similarity lookup and invalidation)
  - Probing Coordinator (issues parallel probes, aggregates responses)
  - Agent Pool (7 domain agents with private KBs, each exposing a `HandleProbeRequest` interface)

- **Critical path:**
  1. Query → Semantic Cache lookup
  2. Cache miss → Confidence-based initial routing
  3. Low confidence → Parallel probing to all candidate agents
  4. Agents perform local KB search → return OK/KO
  5. Orchestrator selects agent → updates cache

- **Design tradeoffs:**
  - **Accuracy vs. Latency:** Probing adds ~5x latency (567s vs. 106s in experiments); tune τ to balance.
  - **Cache precision vs. coverage:** Higher invalidation thresholds reduce false positives but risk stale routes.
  - **Description effort vs. probing reliance:** KBA is robust to poor descriptions, but detailed descriptions still improve accuracy (95.0% vs. 87.1%).

- **Failure signatures:**
  - **Repeated misrouting of semantically similar queries:** Cache invalidation threshold too high or embedding model drift.
  - **All agents return KO:** KBs are incomplete or probing thresholds too strict.
  - **Multiple agents return OK for ambiguous queries:** ResolveAmbiguity logic needed (user prompt or secondary scoring).

- **First 3 experiments:**
  1. **Baseline calibration:** Run description-driven routing on your agent pool with Basic/Generic descriptions; measure accuracy and latency.
  2. **Threshold sweep:** Vary τ (e.g., 0.5, 0.7, 0.9) and measure probing frequency, accuracy, and token cost.
  3. **Cache invalidation stress test:** Simulate KB updates; verify invalidation spheres correctly purge affected entries without over-deleting.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can KBA Orchestration detect and exclude adversarial agents that falsely report task relevance to manipulate routing?
- **Basis in paper:** [explicit] Section 5.4 notes that the evaluation "assumed cooperative agents" and that "adversarial or misconfigured agents could misreport capabilities, raising trust and governance concerns."
- **Why unresolved:** The current framework relies on the truthfulness of the lightweight ACK signal (OK/KO) and lacks verification mechanisms or reputation scoring for agent behavior.
- **What evidence would resolve it:** A simulation introducing agents with randomized or maliciously high confidence scores to test system resilience, followed by a protocol that weights agent reliability over time.

### Open Question 2
- **Question:** What are the optimal standardized implementation patterns for the agent-side OK/KO signaling mechanism to ensure consistent latency across diverse architectures?
- **Basis in paper:** [explicit] Section 5.4 states, "we did not define standardized patterns for implementing the OK/KO signaling mechanism," which introduces "variability in performance."
- **Why unresolved:** The paper treats the agent-side retrieval process as a "black box," leaving the specific architectural choices (e.g., embedding search vs. LLM classifier) undefined and their efficiency trade-offs unquantified.
- **What evidence would resolve it:** A comparative benchmark of different internal retrieval implementations to establish best practices that minimize the latency penalty of the probing phase.

### Open Question 3
- **Question:** How can the semantic cache invalidation threshold be dynamically optimized to balance coverage against precision in changing knowledge environments?
- **Basis in paper:** [explicit] Section 3.1.5 highlights the "threshold optimization challenge" regarding the invalidation hypersphere radius, and Section 5.4 calls for "advancing cache management strategies."
- **Why unresolved:** The paper mathematically formalizes the invalidation boundary but does not provide a validated method for automatically setting or adjusting the threshold (θ_inv) based on domain specificity or staleness.
- **What evidence would resolve it:** An adaptive algorithm that tunes invalidation thresholds based on query drift or feedback loops, demonstrating reduced cache staleness without excessive false positive invalidations.

### Open Question 4
- **Question:** Does parallel probing maintain acceptable latency when scaling to large agent pools (e.g., hundreds of agents), or does synchronization overhead negate the efficiency benefits?
- **Basis in paper:** [explicit] Section 5.4 identifies that "probing incurs synchronization costs when scaling to very large agent pools, potentially creating latency bottlenecks."
- **Why unresolved:** The empirical evaluation was limited to 7 agents; the paper acknowledges that the synchronization penalty in large-scale systems remains a key practical challenge.
- **What evidence would resolve it:** Stress-test results from a deployment with 100+ agents, quantifying the correlation between pool size, probing latency, and the hit-rate of the semantic cache.

## Limitations
- Probing incurs significant latency overhead (5x increase) compared to static routing, which may not be acceptable in latency-sensitive applications.
- The system assumes truthful agent responses; no mechanism exists to detect or mitigate adversarial or malfunctioning agents.
- Semantic cache invalidation is not dynamically optimized; poor threshold tuning can cause stale routes or excessive cache purges.

## Confidence
- **High Confidence:** The core claim that KBA improves routing accuracy over static description-driven orchestration is strongly supported by the experimental results (87.1% vs. 43.6% for Basic descriptions; 95.0% vs. 68.6% for Detailed descriptions).
- **Medium Confidence:** The claim that KBA is robust to poor descriptions and provides a practical trade-off between accuracy and computational cost is supported, but the latency increase (5x) is significant and may not be acceptable in all production contexts.
- **Low Confidence:** The long-term viability of the semantic cache and the probing mechanism's resilience to agent KB drift or adversarial queries are not tested; the paper does not address how often the cache or KB probing thresholds need re-tuning.

## Next Checks
1. **Probing Robustness Test:** Systematically inject noisy or adversarial queries (e.g., semantically ambiguous, out-of-scope) to measure false positive/negative rates in agent OK/KO responses and evaluate if the probing mechanism degrades below baseline.
2. **Cache Invalidation Stress Test:** Simulate KB updates and measure cache hit accuracy over time; quantify the trade-off between invalidation threshold (θ) and stale route frequency.
3. **Confidence Threshold Sensitivity:** Conduct a grid search over τ (e.g., 0.3 to 0.9) and plot the accuracy-latency-cost Pareto frontier to identify the optimal operating point for different deployment scenarios.