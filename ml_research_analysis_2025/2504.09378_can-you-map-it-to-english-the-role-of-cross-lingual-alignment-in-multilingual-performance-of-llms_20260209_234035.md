---
ver: rpa2
title: Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual
  Performance of LLMs
arxiv_id: '2504.09378'
source_url: https://arxiv.org/abs/2504.09378
tags:
- alignment
- english
- layer
- token
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how the ability of large language models
  (LLMs) to align their representations of non-English text with English representations
  impacts their performance on natural language understanding (NLU) tasks. The authors
  introduce three instance-level metrics - DALI, DALIst, and MEXAT - to quantify representation
  alignment between English and non-English NLU samples.
---

# Can you map it to English? The Role of Cross-Lingual Alignment in Multilingual Performance of LLMs

## Quick Facts
- arXiv ID: 2504.09378
- Source URL: https://arxiv.org/abs/2504.09378
- Authors: Kartik Ravisankar; Hyojung Han; Sarah Wiegreffe; Marine Carpuat
- Reference count: 40
- Primary result: Cross-lingual alignment with English in middle layers correlates with and causally drives successful multilingual NLU task performance.

## Executive Summary
This paper investigates how the ability of large language models to align their representations of non-English text with English representations impacts their performance on natural language understanding tasks. The authors introduce three instance-level metrics - DALI, DALIst, and MEXAT - to quantify representation alignment between English and non-English NLU samples. Through extensive experiments across three benchmarks, nine languages, and three distinct LLMs, they demonstrate that samples exhibiting successful cross-lingual transfer consistently show higher cross-lingual alignment than transfer failures, particularly in middle layers. Activation patching experiments provide causal evidence that semantically equivalent English activations in these middle layers can correct non-English failures, with effects specifically tied to semantic alignment rather than simple target-token prediction.

## Method Summary
The study introduces three novel metrics (DALI, DALIst, MEXAT) to quantify cross-lingual alignment at the instance level by comparing representations of parallel English and non-English NLU samples. For each sample pair, they extract last-token embeddings across all transformer layers and compute cosine similarity between premise+option representations. They analyze alignment differences between transfer-success (TS) and transfer-failure (TF) samples, identifying layers where alignment peaks (λ_max). Activation patching experiments then test whether patching English activations at specific layers and token positions (last vs. penultimate) can causally correct TF instances, comparing semantically equivalent patches against control patches sharing only the target token. The methodology systematically varies languages, benchmarks, metrics, and LLMs to establish robustness.

## Key Results
- Incorrect NLU predictions are strongly associated with lower representation alignment with English in middle layers, with ∆TS-TF(alignment) positive in 30/33 language-benchmark-metric combinations.
- Activation patching in middle layers (14-25) causally corrects non-English failures, with strongest effects at the last token position before language-specific decoding.
- Semantically equivalent English patches produce more confident corrections (lower entropy) than control patches that primarily inject next-token bias.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instance-level cross-lingual alignment with English correlates with successful multilingual NLU task performance.
- Mechanism: When non-English inputs produce representations similar to their parallel English counterparts, the model makes correct predictions. Misaligned representations lead to transfer failures.
- Core assumption: Semantically equivalent text should yield similar internal representations regardless of language.
- Evidence anchors:
  - [abstract]: "Results show that incorrect NLU predictions are strongly associated with lower representation alignment with English in the model's middle layers."
  - [section 4.1]: "The ∆TS-TF(alignment) is consistently positive in 30 out of the 33 (language × benchmark × alignment metric) combinations."
  - [corpus]: Kargaran et al. (2025) demonstrate similar language-level correlation between MEXA alignment scores and multilingual task accuracy.

### Mechanism 2
- Claim: English middle-layer activations encode language-agnostic semantic representations that causally correct non-English failures when patched.
- Mechanism: Middle layers (14-25) aggregate semantic features before language-specific decoding. Patching English activations at these layers provides the "correct" semantic representation.
- Core assumption: Middle layers host a shared concept space where English representations encode task-relevant semantics.
- Evidence anchors:
  - [abstract]: "Activation patching experiments demonstrate that semantically equivalent English activations in middle layers causally correct non-English failures, with strongest effects in layers 14-25."
  - [section 4.2]: "hEng corresponding to the last token in the middle layers encodes a language-agnostic representation that is sufficient to steer the non-English samples towards the gold token."
  - [corpus]: Wendler et al. (2024) and concurrent work (Dumas et al., 2025) show implicit English pivot and language-agnostic concept representations in middle layers.

### Mechanism 3
- Claim: Semantic alignment mediates corrections beyond simple target-token production; semantically equivalent patches produce lower-entropy, more confident predictions.
- Mechanism: Control patches (same target token, different semantics) can flip predictions but operate via next-token bias injection. Equivalent patches provide genuine semantic grounding.
- Core assumption: Hidden states encode both conceptual content and output-target information.
- Evidence anchors:
  - [section 4.3]: "In layer 14 of the penultimate token patching, 41.2% (out of 68.9% total flips) can be flipped only by patching semantically equivalent English sample activation."
  - [section 5.3]: "Flips triggered by semantically equivalent English patches are consistently associated with lower output entropy... yielding more confident predictions than control patches that primarily inject a next-token bias."

## Foundational Learning

- Concept: **Cosine similarity of transformer representations**
  - Why needed here: All alignment metrics rely on comparing representation vectors; anisotropy makes raw scores hard to interpret.
  - Quick check question: If two unrelated sentences have cosine similarity 0.85, what does DALI do to handle this?

- Concept: **Activation patching / causal mediation**
  - Why needed here: Core technique for testing whether English representations causally influence non-English correctness.
  - Quick check question: When patching h_λ_Eng to h_λ_X at layer 14, what downstream computation uses the patched value?

- Concept: **Multiple-Choice Question Answering (MCQA) token positions**
  - Why needed here: Patching requires aligned token positions across languages; penultimate vs. last token captures different decision stages.
  - Quick check question: Why does last-token patching maintain effectiveness in later layers while penultimate token patching drops off?

## Architecture Onboarding

- Component map: Residual stream → Layer-wise attention+MLP updates → Middle layers (14-25) = semantic aggregation zone → Later layers = language-specific output preparation → Final unembedding to vocabulary logits. DALI/DALIst/MEXAT measure cross-lingual alignment at each layer. Patching intervenes by replacing h_λ at specified token positions.

- Critical path: Extract last-token embeddings across all layers → compute DALI/DALIst/MEXAT comparing parallel English/non-English pairs → identify λ_max where alignment peaks → run activation patching on TF instances at layers 14-25 → compute flip rates and compare equivalent vs. control patches → analyze entropy differences.

- Design tradeoffs: DALI offers simplicity but limited discriminative power for 2-option tasks; DALIst adds intra-lingual constraint for stricter filtering; MEXAT uses larger contrastive pool (2N-2 samples) for lower false-positive rate but requires more computation. Last-token patching captures next-token prediction directly; penultimate token captures decision-before-commitment but may miss late-stage corrections.

- Failure signatures: (1) High DALI but low DALIst indicates anisotropy-driven false positives; (2) Control patches achieving similar flip rates to equivalent patches suggests layer encodes target-token not semantics; (3) Penultimate token patching showing steep flip-rate decline after layer 25 indicates decision already executed.

- First 3 experiments:
  1. Replicate DALI/DALIst/MEXAT alignment analysis on a held-out language-benchmark pair; verify ∆TS-TF(alignment) remains positive and statistically significant at λ_max.
  2. Run activation patching on TF instances across layers 0-32 at both last and penultimate tokens; plot flip rates and mean logit trajectories to localize the semantic aggregation window (expect peak 14-25).
  3. Perform control patching with semantically unrelated English samples sharing the same target token; compute ∆(% Flip) to identify layers where semantic content (not just target) drives corrections; cross-check with entropy analysis.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on parallel NLU benchmarks constrains generalizability to settings without exact semantic equivalence across languages.
- Activation patching experiments operate under controlled conditions with pre-selected TF instances, limiting real-world applicability.
- Focus on three specific LLM families (LLaMA-3 8B, Qwen2.5 7B, mGPL-4.5B) limits conclusions about architectural differences or scaling effects.

## Confidence

**High Confidence:** The core finding that cross-lingual alignment correlates with task performance is well-supported by consistent statistical significance across 30 of 33 language-benchmark-metric combinations. The causal demonstration that English middle-layer activations can correct non-English failures is strongly evidenced by systematic layer-specific effects.

**Medium Confidence:** The claim that semantic alignment specifically drives confident corrections is supported by entropy analysis and flip rate differentials, but corpus evidence for this distinction is limited. The interpretation of middle layers hosting language-agnostic semantic representations requires additional architectural validation.

**Low Confidence:** Generalizability to non-parallel tasks, different LLM architectures, and languages with greater typological distance from English remains uncertain. The assumption that parallel sentences always produce semantically equivalent internal representations is not empirically validated for the specific model families studied.

## Next Checks

1. **Cross-Architectural Validation:** Replicate the alignment analysis and activation patching experiments on additional LLM families to test whether the identified middle-layer semantic aggregation window (layers 14-25) is architecture-dependent or universal.

2. **Non-Parallel Task Extension:** Design an experiment using non-parallel multilingual NLU tasks where semantic equivalence must be established through translation or semantic similarity measures, then test whether the same alignment-performance correlation holds without exact parallel data.

3. **Real-World Correction Pipeline:** Implement a practical system that monitors non-English predictions, identifies low-alignment instances using DALI/DALIst/MEXAT, and automatically applies middle-layer English patching to improve accuracy, measuring end-to-end performance gains on a representative multilingual application.