---
ver: rpa2
title: 'CMT-Bench: Cricket Multi-Table Generation Benchmark for Probing Robustness
  in Large Language Models'
arxiv_id: '2510.18173'
source_url: https://arxiv.org/abs/2510.18173
tags:
- bowler
- balls
- runs
- batsman
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CMT-Bench, a diagnostic benchmark for probing
  robustness in LLM-driven text-to-table generation. Built from live cricket commentary,
  it requires dynamic table generation across two evolving schemas (batsmen and bowlers)
  under complex game rules.
---

# CMT-Bench: Cricket Multi-Table Generation Benchmark for Probing Robustness in Large Language Models

## Quick Facts
- arXiv ID: 2510.18173
- Source URL: https://arxiv.org/abs/2510.18173
- Authors: Ritam Upadhyay; Naman Ahuja; Rishabh Baral; Aparna Garimella; Vivek Gupta
- Reference count: 40
- Key outcome: Introduces CMT-Bench for probing LLM robustness in dynamic text-to-table generation using live cricket commentary

## Executive Summary
CMT-Bench introduces a diagnostic benchmark for evaluating robustness in LLM-driven text-to-table generation. Built from live cricket commentary, it requires dynamic table generation across two evolving schemas (batsmen and bowlers) under complex game rules. The benchmark evaluates model robustness along three dimensions: extractive-cue ablation, temporal prefixing, and entity-form perturbations. Across diverse long-context LLMs, results show large drops without extractive summaries, monotonic degradation with input length, and consistent accuracy drops under entity-form changes.

## Method Summary
CMT-Bench constructs text-to-table generation tasks from live cricket commentary using regex-based parsing for deterministic ground truth. The benchmark evaluates three perturbation conditions: extractive-cue ablation (removing dismissal summary cues), temporal prefixing (testing performance across different commentary segments), and entity-form perturbations (swapping entity names and role descriptions). Evaluation uses Hungarian alignment for schema-matching predictions, computing cell/row/column accuracy with significance testing via blocked permutation and energy distance metrics.

## Key Results
- Large drops without extractive summaries (-42% avg. cell accuracy, -87% avg. row accuracy)
- Monotonic degradation with input length across all tested LLMs
- Up to 16% increase in batsman-bowler table Jaccard similarity under entity-entanglement, indicating role confusion
- Distributional tests confirm significant shifts in numeric error patterns under perturbations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs achieve high text-to-table accuracy primarily by extracting embedded summary cues rather than maintaining state over temporal narratives.
- Mechanism: Dismissal lines provide aggregated statistics that models copy directly, bypassing incremental aggregation across ball-by-ball events.
- Core assumption: High performance with summaries reflects extraction capability, not genuine temporal state tracking.
- Evidence anchors:
  - [abstract]: "large drops without extractive summaries"
  - [Section 4.1]: "Model performance drops significantly (-42% avg. on cell level and -87% avg. on row level) when summary cues are removed"
  - [corpus]: Weak support; evolveQA paper shows LLMs struggle with evolving knowledge but doesn't address extraction shortcuts specifically.
- Break condition: Models maintain high accuracy without summaries via explicit state-tracking architectures.

### Mechanism 2
- Claim: Performance degrades monotonically with input length due to error accumulation in cumulative state tracking.
- Mechanism: Without extractive shortcuts, models must aggregate counts across ~9,000 tokens; small errors in early events compound through later ones.
- Core assumption: The monotonic decline indicates genuine state-tracking failure, not just attention dilution.
- Evidence anchors:
  - [abstract]: "monotonic degradation with input length"
  - [Section 4.2]: "batsman accuracy now declined monotonically with increasing input length, demonstrating that performance gains under summaries were largely extractive"
  - [corpus]: HI-SQL paper mentions multi-table complexity but doesn't address temporal accumulation mechanisms.
- Break condition: Architectural interventions (explicit state memory, chunked aggregation) flatten the accuracy curve over context length.

### Mechanism 3
- Claim: Models encode entity-role mappings through surface-form memorization rather than contextual inference.
- Mechanism: Standard "bowler to batsman" syntax is learned as a lexical pattern; paraphrasing or name substitution breaks this shortcut, causing role confusion.
- Core assumption: Increased Jaccard similarity between swapped batsman/bowler tables (13-16%) indicates systematic role confusion, not random noise.
- Evidence anchors:
  - [Section 4.3]: "We observe up to 13% for anonymized variant and up to 16% increase for entity-entanglement in similarity scores"
  - [Section 5.2]: "Entity-entanglement shows the highest drift in distribution"
  - [corpus]: evolveQA paper touches on entity-specific memorization but not for structured generation tasks.
- Break condition: Models correctly resolve roles under entanglement through contextual inference from delivery descriptions and batting actions.

## Foundational Learning

- **Concept: State Tracking in Sequential Data**
  - Why needed here: Cricket scorecards require cumulative aggregation; each ball's statistics depend on all prior events.
  - Quick check question: Can you compute a batsman's strike rate after ball 250 given only balls 241-250?

- **Concept: Schema Invariance vs. Surface Form Sensitivity**
  - Why needed here: The benchmark tests whether models understand entity roles (bowler vs. batsman) independent of naming conventions or phrasing.
  - Quick check question: If "Muzarabani to Tamim" becomes "Between Tamim and Muzarabani," who is bowling?

- **Concept: Distributional Testing for Reasoning Drift**
  - Why needed here: Accuracy alone cannot distinguish random noise from systematic shifts in reasoning patterns.
  - Quick check question: If error variance increases but mean accuracy stays constant, is the model's reasoning still sound?

## Architecture Onboarding

- **Component map**:
  - Commentary Parser -> Ball-level event extraction (regex-based, monotonicity-filtered)
  - Ground Truth Generator -> Schema-constrained aggregation (balls→overs, runs→S/R, maidens from 6-consecutive 0-run deliveries)
  - Perturbation Suite -> 3 semantics-preserving transformations (extractive ablation, temporal slicing, entity-form changes)
  - Evaluation Layer -> Hungarian-aligned cell/row/column accuracy + blocked permutation test with energy distance

- **Critical path**:
  1. Filter commentary with entity + action presence checks
  2. Parse events via regex (over.ball notation, run tokens, extras handling)
  3. Apply perturbations to generate test variants
  4. Run ZS-CoT prompting (temperature 0.1, top-p 0.1)
  5. Align predictions via Hungarian algorithm (0.35 similarity threshold)
  6. Compute distributional shift via energy distance with blocked permutation test (B=2000)

- **Design tradeoffs**:
  - Regex parsing vs. LLM extraction: Regex chosen for deterministic ground truth (99.7% validation match)
  - Fixed schema vs. open generation: Fixed schema enables precise numeric evaluation; limits generalization to hierarchical/merged-cell tables
  - Blocked permutation vs. simple significance testing: Blocked design controls for column-wise difficulty

- **Failure signatures**:
  - High with-summary accuracy + steep drop without → extractive shortcut reliance
  - Monotonic accuracy decline over overs → state-tracking failure
  - Increased batsman-bowler table Jaccard similarity → role confusion
  - Significant energy distance (p < 0.005) under perturbation → reasoning drift

- **First 3 experiments**:
  1. Establish baseline: Run Gemini-2.5-Flash on full ODI commentary with summaries (expect ~89% cell accuracy)
  2. Ablate summaries: Same input without dismissal cues (expect ~40-point cell accuracy drop)
  3. Probe entanglement: Apply entity-entanglement perturbation; measure role confusion via cross-table Jaccard similarity

## Open Questions the Paper Calls Out
None

## Limitations
- Fixed two-table schema and regex-based ground truth limit generalizability to more complex table structures with merged cells or hierarchical nesting
- Perturbation suite, while semantics-preserving by design, may introduce subtle artifacts that models exploit differently than human annotators
- Distributional shift tests cannot distinguish between genuine reasoning failures and legitimate alternative solution paths

## Confidence

**High Confidence**: The observed performance drops without extractive summaries (-42% cell accuracy, -87% row accuracy) are robustly measured across multiple LLMs and input conditions. The monotonic accuracy decline with input length is consistently observed.

**Medium Confidence**: The interpretation that extractive shortcuts explain high with-summary performance requires additional validation. Alternative explanations (attention mechanisms, summary-enhanced context understanding) cannot be fully ruled out.

**Low Confidence**: The surface-form memorization hypothesis for entity-role mapping relies primarily on Jaccard similarity increases (13-16%) that could partially reflect statistical artifacts rather than systematic role confusion.

## Next Checks
1. **Architectural Intervention Study**: Implement a chunked state-tracking architecture that explicitly maintains cumulative statistics and compare its performance profile against baseline LLMs across all perturbation conditions.

2. **Human Annotation Benchmark**: Recruit cricket domain experts to generate tables from the same commentary subsets under summary ablation and entity-entanglement conditions. Compare human vs. LLM performance patterns.

3. **Cross-Domain Transfer**: Apply the same perturbation suite to text-to-table generation tasks in other sequential domains (e.g., baseball scoring, financial time series, election results) to test whether extractive shortcut reliance is cricket-specific or a general LLM limitation.