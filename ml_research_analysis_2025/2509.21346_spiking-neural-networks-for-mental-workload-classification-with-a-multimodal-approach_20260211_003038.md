---
ver: rpa2
title: Spiking Neural Networks for Mental Workload Classification with a Multimodal
  Approach
arxiv_id: '2509.21346'
source_url: https://arxiv.org/abs/2509.21346
tags:
- classification
- performance
- cognitive
- were
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluated the use of spiking neural networks (SNNs)
  for mental workload classification using a multimodal dataset of EEG, heart rate
  variability, electrodermal activity, and skin temperature. Traditional machine learning
  models such as logistic regression, multilayer perceptron, and support vector machines
  were compared against two SNN architectures: a hybrid SNN with backpropagation and
  a biologically-inspired SNN with fixed first-layer weights and a delta learning
  rule.'
---

# Spiking Neural Networks for Mental Workload Classification with a Multimodal Approach

## Quick Facts
- **arXiv ID**: 2509.21346
- **Source URL**: https://arxiv.org/abs/2509.21346
- **Reference count**: 26
- **Primary result**: Multimodal SNN (EEG+HRV+EDA+Temp) achieves 84.3% accuracy, outperforming logistic regression baseline of 77.8%

## Executive Summary
This study evaluates spiking neural networks (SNNs) for mental workload classification using a multimodal dataset of EEG, heart rate variability, electrodermal activity, and skin temperature. The research compares traditional machine learning models (logistic regression, MLP, SVM) against two SNN architectures: a hybrid SNN with backpropagation and a biologically-inspired SNN with fixed first-layer weights and delta learning rule. Results demonstrate that multimodal integration consistently improves classification accuracy across all models, with the hybrid SNN achieving 88.4% accuracy and the bio-inspired SNN reaching 84.3%, both significantly outperforming the logistic regression baseline of 77.8%.

## Method Summary
The study uses physiological data from 10 participants performing arithmetic tasks (easy vs. hard) from an open-source dataset. Features are extracted from 60-second sliding windows with 80% overlap, including EEG power spectral density bands, HRV metrics, EDA peaks, and skin temperature statistics. Two SNN architectures are implemented: a hybrid model with backpropagation-trained first layer and delta-rule second layer, and a bio-inspired model with fixed random projections in the first layer and local delta learning in the second. Traditional ML baselines include logistic regression, multilayer perceptron, and support vector machines with RBF kernels. All models are evaluated using accuracy, F1-score, precision, and recall metrics with stratified cross-validation.

## Key Results
- Multimodal integration improved classification accuracy for all models compared to EEG-only approaches
- SVM RBF achieved the highest accuracy at 96.0% with multimodal features
- Hybrid SNN reached 88.4% accuracy, outperforming the logistic regression baseline of 77.8%
- Bio-inspired SNN achieved 84.3% accuracy with multimodal features, significantly outperforming the baseline
- Statistical analysis confirmed both SNN models significantly outperformed the logistic regression baseline

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multimodal signal integration (EEG + HRV + EDA + TEMP) improves classification accuracy by capturing complementary autonomic and neural responses to cognitive load.
- **Mechanism:** EEG provides high-temporal resolution neural data, while peripheral signals (HRV, EDA) reflect slower autonomic nervous system arousal. Fusing these features creates a higher-dimensional representation where linearly inseparable patterns in a single modality become distinguishable.
- **Core assumption:** The physiological signals are temporally aligned and the 60-second sliding window effectively captures the relevant cognitive states across all modalities.
- **Evidence anchors:** [abstract] "...multimodal integration improved classification accuracy for all models..." [results] "Compared to the EEG-only models, multimodal LR accuracy increased from 67.5% (EEG) to 77.9%... MLP performance improved from 76.3% (EEG) to 93.5%." [corpus] Related work confirms the "Heart-Brain Connection" and "Cross-Modal" models improve physiological computing.

### Mechanism 2
- **Claim:** A hybrid Spiking Neural Network (SNN) architecture achieves higher accuracy than a biologically-constrained SNN by optimizing feature extraction layers via backpropagation.
- **Mechanism:** The hybrid model updates the first layer (fc1) weights using the Adam optimizer (standard backprop) to learn optimal representations, while retaining a biologically plausible delta learning rule for the output layer (fc2). This allows the network to "sculpt" the feature space better than fixed random projections.
- **Core assumption:** The gradient-based optimization in the first layer does not invalidate the event-driven efficiency goals for the specific hardware implementation targeted in future work.
- **Evidence anchors:** [section II.C.3.a] "The fc1 weights are updated using the Adam optimizer via standard backpropagation... fc2 weights are updated using a delta learning rule." [results] "The hybrid SNN... achieved an accuracy of 88.4%... higher than... Bio-inspired SNN [84.3%]." [corpus] Weak direct evidence in corpus; primarily supported by internal experimental comparison.

### Mechanism 3
- **Claim:** A bio-inspired SNN with fixed first-layer weights can classify mental workload effectively by leveraging sparse connectivity and high-dimensional random projections.
- **Mechanism:** The first layer (fc1) uses fixed weights and a connection probability parameter ($p_{conn} = 0.1$) to project inputs into a sparse, high-dimensional space. The second layer (fc2) learns a linear readout using a local delta rule based on spike counts, avoiding global error backpropagation.
- **Core assumption:** The random projection in the first layer preserves enough separability for the cognitive load classes without weight tuning.
- **Evidence anchors:** [results] "Bio-inspired SNN... reached 84.3%... outperforming the logistic regression baseline of 77.8%." [results] "Analysis of connection probability $p_{conn}$ trends... suggested that lower connectivity enhanced classification accuracy." [corpus] "Unveiling the Heart-Brain Connection" suggests complex interactions; this SNN mechanism offers a low-compute method to handle such complexity.

## Foundational Learning

- **Concept: Leaky Integrate-and-Fire (LIF) Neurons**
  - **Why needed here:** This is the fundamental unit of the SNNs used. Understanding how membrane potential ($V(t)$), threshold ($V_{th}$), and decay ($\tau$) convert continuous physiological features into discrete spikes is required to interpret the architecture.
  - **Quick check question:** If the membrane time constant $\tau$ is set too low relative to the input signal frequency, will the neuron fire more or less easily? (Answer: Less, because the potential decays too fast to reach threshold).

- **Concept: Delta Learning Rule (Spike-based)**
  - **Why needed here:** The paper utilizes a specific local learning rule ($\Delta W = \eta \cdot (S^\top \cdot \Delta)$) for the bio-inspired SNN rather than standard backpropagation. Distinguishing this from gradient descent is key to understanding the hardware constraints.
  - **Quick check question:** In this specific delta rule, what represents the error signal? (Answer: The difference between the target label and the sum of output spikes).

- **Concept: Power Spectral Density (PSD) & Asymmetry**
  - **Why needed here:** The paper relies on specific EEG features (Basic PSD, PSD + Asy) rather than raw waves. Knowing that "Asymmetry" compares left vs. right hemisphere power helps explain why the "PSD + Asy" feature set outperformed basic PSD.
  - **Quick check question:** Why might adding "Asymmetry" features improve classification over "Basic PSD" alone? (Answer: Cognitive load often manifests as lateralized brain activity, which PSD averages out).

## Architecture Onboarding

- **Component map:** Inputs(23 features) -> LIF Encoder -> Hybrid: fc1(Adam) -> LIF -> fc2(Delta Rule) OR Bio-inspired: fc1(Fixed, $p_{conn}=0.1$) -> LIF -> fc2(Delta Rule)
- **Critical path:** The definition of the "Easy" vs "Hard" labels on the 60-second windows and the subsequent spike encoding parameters ($\tau$, $dt$, threshold) determine if the SNN receives distinguishable input.
- **Design tradeoffs:**
  - Hybrid vs. Bio-inspired: Hybrid offers ~4% accuracy gain but requires backprop (computationally expensive on neuromorphic hardware). Bio-inspired sacrifices accuracy for extreme local learning and fixed-weight efficiency.
  - Connectivity ($p_{conn}$): Lower connectivity (0.1) improved accuracy, suggesting redundancy in the input features and the benefit of sparsity.
- **Failure signatures:**
  - Drop in Bio-inspired performance: If using EEG-only features, the fixed random projection fails to separate classes (accuracy drops to ~73%).
  - MLP/SVM outperforming SNN: If strict 1ms time steps are not required for the application, traditional ML (SVM RBF at 96%) is currently superior in raw accuracy.
- **First 3 experiments:**
  1. **Baseline Replication:** Train the Logistic Regression model on the 23 multimodal features to verify the 77.8% baseline using the specified preprocessing (PSD + Asy).
  2. **Spike Sensitivity Analysis:** Implement the Bio-inspired SNN and sweep the membrane time constant ($\tau$) and connection probability ($p_{conn}$) to replicate the finding that sparsity aids classification.
  3. **Modality Ablation:** Run the Hybrid SNN on "EEG-only" vs. "All Modalities" to quantify the delta in accuracy specifically attributed to the physiological sensors (HRV/EDA/Temp).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific latency and energy consumption metrics when the proposed SNN architectures are deployed on physical neuromorphic hardware?
- Basis in paper: [explicit] The conclusion states that "neuromorphic hardware implementations should be investigated for real-time cognitive load monitoring."
- Why unresolved: The current study is simulation-based (using `snntorch` and Python) and does not provide empirical data on power usage or inference speed on an actual chip.
- What evidence would resolve it: Implementation of the bio-inspired SNN on a mixed analog/digital neuromorphic processor to measure real-time energy efficiency.

### Open Question 2
- Question: Does leveraging raw, unprocessed physiological signals directly improve the bio-inspired SNN's ability to identify cognitive load biomarkers compared to the pre-extracted features used?
- Basis in paper: [explicit] The conclusion suggests future research should focus on "leveraging raw signals to identify novel biomarkers for cognitive load detection and spike encoding."
- Why unresolved: This study relied exclusively on pre-computed features (PSD, HRV metrics) rather than processing continuous time-series data directly.
- What evidence would resolve it: A comparative study where the SNN processes raw EEG and physiological streams as input, bypassing the feature extraction pipeline.

### Open Question 3
- Question: Can alternative biologically inspired learning rules enhance the classification performance of the fixed-weight SNN beyond the delta learning rule utilized?
- Basis in paper: [explicit] The discussion notes that "exploring biologically inspired learning rules could enhance SNN performance."
- Why unresolved: The study was limited to a hybrid backpropagation method and a delta learning rule; other local learning rules were not assessed.
- What evidence would resolve it: Experiments integrating mechanisms such as spike-timing-dependent plasticity (STDP) into the SNN architecture to test for accuracy improvements.

## Limitations

- **Participant Selection Variability:** Random selection of 10 out of 24 participants introduces significant variance in reported accuracies (e.g., Bio-inspired SNN std dev is 11%), potentially affecting result generalizability.
- **Specific SNN Implementation Details:** Exact mechanism for "directly integrating feature values" into membrane dynamics and full hyperparameter search grids for SNN-specific parameters are not fully specified, complicating exact replication.
- **Baseline Model Hyperparameters:** While general grid search ranges are mentioned for traditional ML models, specific configurations used for MLP/SVMs are not enumerated, limiting direct comparison validation.

## Confidence

- **High Confidence:** The multimodal integration mechanism improving accuracy (Mechanism 1) is well-supported by experimental results showing consistent improvements across all model types when adding peripheral signals.
- **Medium Confidence:** The hybrid SNN's ~4% accuracy advantage over the bio-inspired model is internally validated but lacks strong external corpus support, as specific SNN implementations for this multimodal fusion are less common in the literature.
- **Medium Confidence:** The bio-inspired SNN's ability to classify mental workload with fixed weights is demonstrated but may be sensitive to the specific random projections and feature set used.

## Next Checks

1. **Participant Subset Analysis:** Re-run the entire experiment pipeline (including baselines) with multiple different random subsets of 10 participants to quantify the variance and assess stability of the reported accuracy differences between SNN architectures.

2. **Input Integration Verification:** Implement and test both the described "direct feature integration" into LIF membrane dynamics and a standard weighted synaptic current approach to determine which implementation yields results matching the reported paper.

3. **SNN Hyperparameter Sensitivity:** Systematically sweep the LIF membrane time constant (Ï„) and the bio-inspired SNN's connection probability (p_conn) across the full grid search range to reproduce the finding that lower connectivity enhances accuracy and identify optimal parameters.