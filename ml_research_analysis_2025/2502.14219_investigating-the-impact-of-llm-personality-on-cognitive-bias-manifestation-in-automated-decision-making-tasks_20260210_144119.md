---
ver: rpa2
title: Investigating the Impact of LLM Personality on Cognitive Bias Manifestation
  in Automated Decision-Making Tasks
arxiv_id: '2502.14219'
source_url: https://arxiv.org/abs/2502.14219
tags:
- bias
- personality
- biases
- traits
- effect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how LLM personality traits influence cognitive
  bias manifestation in automated decision-making. Six biases were identified as prevalent,
  while sunk cost and group attribution biases showed minimal impact.
---

# Investigating the Impact of LLM Personality on Cognitive Bias Manifestation in Automated Decision-Making Tasks

## Quick Facts
- arXiv ID: 2502.14219
- Source URL: https://arxiv.org/abs/2502.14219
- Reference count: 24
- Six prevalent biases identified (anchoring, framing, decoy effect, risk aversion, status quo, endowment effect), with minimal sunk cost and group attribution effects

## Executive Summary
This study investigates how Big Five personality traits influence cognitive bias manifestation in LLM decision-making. Six biases were found to be prevalent across tested models, while sunk cost and group attribution showed minimal impact. Personality traits significantly affected bias manifestation, with Conscientiousness and Agreeableness generally enhancing bias mitigation effectiveness. The research employed four LLMs and tested eight cognitive biases across various personality traits and mitigation strategies, highlighting the importance of personality-driven bias dynamics for improving AI fairness and reliability.

## Method Summary
The study used Big Five personality trait prompts (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) to investigate their effects on eight cognitive biases in LLM decision-making. Two synthetic datasets were employed: Student Admission Dataset (13,465 prompts) and custom BiasEval Dataset (4,585 scenarios). Models were tested with and without awareness-based mitigation prompts ("Be mindful of not being biased"). Bias was quantified through selection rate differences and valuation ratios, comparing responses across personality conditions.

## Key Results
- Anchoring, framing, decoy effect, risk aversion, status quo, and endowment effect biases were prevalent across all tested models
- Sunk cost and group attribution biases showed minimal influence across all personality traits and models
- Conscientiousness and Agreeableness generally enhanced bias mitigation effectiveness, suggesting greater responsiveness to corrective measures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompted personality traits systematically modulate cognitive bias manifestation through trait-consistent response patterns
- Mechanism: Big Five personality prompts induce trait-specific reasoning tendencies that interact with decision-making heuristics, amplifying or attenuating bias expression depending on trait-bias alignment
- Core assumption: Prompted personality elicits stable, trait-consistent reasoning patterns rather than superficial stylistic changes
- Evidence anchors: [abstract] "Personality traits play a crucial role in either amplifying or reducing biases"; [section 3.1] "GPT-4o shows the highest anchoring bias, particularly for Agreeableness (0.338)"
- Break condition: Effect disappears when personality prompts are removed; baseline behavior returns; trait effects vary inconsistently across architectures

### Mechanism 2
- Claim: Conscientiousness and Agreeableness traits enhance awareness-based debiasing efficacy through increased responsiveness to corrective instructions
- Mechanism: Models prompted with Conscientiousness (diligence, organization) and Agreeableness (cooperation, compliance) show greater alignment with explicit bias-awareness instructions
- Core assumption: Trait-induced compliance or deliberation translates to more careful processing of mitigation instructions
- Evidence anchors: [abstract] "Conscientiousness and Agreeableness may generally enhance the efficacy of bias mitigation strategies"; [section 3.3] "Models with Conscientiousness prompts are overall more effective"
- Break condition: Awareness prompts fail to reduce bias regardless of personality; Conscientiousness/Agreeableness show no differential mitigation effects

### Mechanism 3
- Claim: Bias manifestation and personality-bias interactions are architecture-dependent
- Mechanism: Different LLM architectures exhibit distinct baseline bias profiles and respond differently to personality prompting—larger models show stronger bias tendencies, smaller or open models show greater variability
- Core assumption: Observed differences stem from architectural factors (scale, training data, alignment) rather than random variation
- Evidence anchors: [section 3.1] "Llama3-70B and GPT-4o exhibit higher baseline bias"; [section 5] "Personality-driven bias modulation is highly architecture-dependent"
- Break condition: All architectures show identical bias-personality patterns; model size/alignment shows no correlation with bias expression

## Foundational Learning

- Concept: **Big Five Personality Model (OCEAN)**
  - Why needed here: The entire experimental framework uses Big Five traits as the personality induction mechanism; understanding trait definitions is essential for interpreting bias-trait interactions
  - Quick check question: Which Big Five trait is characterized by organization, diligence, and dependability—and which bias does it help mitigate?

- Concept: **Cognitive Bias Taxonomy in Decision-Making**
  - Why needed here: The study tests eight biases across three categories; distinguishing these categories helps predict which biases may co-occur or respond to similar interventions
  - Quick check question: Name two biases in the "Fast Decision-Making Under Uncertainty" category and explain why sunk cost fallacy showed minimal effect

- Concept: **Awareness-Based Debiasing (Zero-Shot Mitigation)**
  - Why needed here: The primary mitigation strategy tested is a simple prompt instruction; understanding zero-shot debiasing constraints is critical for interpreting why some personality-trait combinations succeed while others fail
  - Quick check question: Why might Conscientiousness-prompted models respond better to awareness-based debiasing than Extraversion-prompted models?

## Architecture Onboarding

- Component map: Personality Prompting Layer -> Bias Elicitation Layer -> Mitigation Intervention Layer -> Measurement Layer
- Critical path: 1) Select target bias and construct paired scenarios, 2) Apply personality prompt, 3) Apply optional mitigation prompt, 4) Collect model decisions, 5) Compute bias metric, 6) Compare against baseline to derive mitigation effect
- Design tradeoffs:
  - Prompted vs. inherent personality: Experimental control vs. ecological validity
  - Synthetic datasets vs. real-world scenarios: Controlled testing vs. generalization uncertainty
  - Awareness-based vs. fine-tuning mitigation: Cost/feasibility vs. robustness
- Failure signatures:
  - Negative bias values: Indicates over-correction (model avoids bias so strongly it reverses direction)
  - Zero sunk cost effect across all conditions: May indicate dataset design failure
  - Inconsistent reversed-personality effects: Suggests personality induction is unstable
- First 3 experiments:
  1. Baseline bias profiling: Run all eight bias tests on target model without personality prompts
  2. Single-trait mitigation test: Test Conscientiousness vs. Agreeableness vs. no-personality on one prevalent bias
  3. Architecture comparison pilot: Run identical protocol on two model variants (e.g., 8B vs. 70B parameters)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do personality-driven cognitive biases evolve across different training paradigms and model architectures beyond the four specific LLMs tested?
- Basis in paper: [explicit] The authors conclude future research must "investigate how biases evolve across different training paradigms and model architectures"
- Why unresolved: Study restricted to GPT-4o, GPT-4o-mini, and two Llama 3 variants, leaving generalizability uncertain
- What evidence would resolve it: Replicating framework across diverse model families (Claude, Gemini, Mistral) and training methods

### Open Question 2
- Question: Are advanced debiasing techniques like fine-tuning or reinforcement learning more effective than zero-shot prompting strategies used?
- Basis in paper: [explicit] Study's "debiasing approach is limited to awareness-based prompts, which may be less effective than fine-tuning or reinforcement learning"
- Why unresolved: Research relied exclusively on simple prompt instructions rather than modifying model weights
- What evidence would resolve it: Comparative experiments measuring bias reduction in fine-tuned models versus awareness-based approach

### Open Question 3
- Question: Do observed bias-personality dynamics persist in real-world, unstructured interactions compared to synthetic datasets?
- Basis in paper: [inferred] Authors note "experiments use structured prompts and synthetic datasets, which may not fully capture how biases emerge in real-world applications"
- Why unresolved: BiasEval and Student Admission datasets utilize controlled, synthetic scenarios lacking real-world complexity
- What evidence would resolve it: Validating findings using naturalistic data or live user interactions rather than templated synthetic profiles

## Limitations
- Personality effects may be prompt-specific artifacts rather than stable trait representations
- Synthetic datasets limit generalizability to authentic decision-making contexts
- Awareness-based mitigation is weaker than finetuning or RLHF methods

## Confidence
- High confidence: Baseline bias identification and prevalence rankings
- Medium confidence: Personality-trait interactions with specific biases, particularly Conscientiousness and Agreeableness effects
- Low confidence: Architecture-specific personality responsiveness patterns due to limited model diversity

## Next Checks
1. **Personality Stability Test**: Run identical personality prompts across 3-5 different task domains to verify trait-consistent response patterns persist
2. **Real-World Dataset Validation**: Apply personality-bias protocol to a real-world decision dataset to assess synthetic dataset findings transfer
3. **Alternative Mitigation Comparison**: Test same personality-bias combinations using stronger mitigation approaches to determine if personality effects remain consistent across intervention strength