---
ver: rpa2
title: Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation
  Models
arxiv_id: '2508.02812'
source_url: https://arxiv.org/abs/2508.02812
tags:
- policy
- data
- variables
- learning
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of distributionally robust evaluation
  and learning in multi-armed bandits, where traditional methods often produce overly
  conservative policies due to overly broad uncertainty sets. The authors propose
  a novel approach that uses structural equation models (SEMs) to create more tailored
  uncertainty sets by modeling specific distribution shifts.
---

# Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation Models

## Quick Facts
- arXiv ID: 2508.02812
- Source URL: https://arxiv.org/abs/2508.02812
- Reference count: 40
- Primary result: SEM-based uncertainty sets produce tighter, more plausible worst-case bounds than distance-based DRO balls, yielding more accurate evaluations and robust policies

## Executive Summary
This paper addresses distributionally robust evaluation and learning in multi-armed bandits where traditional DRO methods produce overly conservative policies due to overly broad uncertainty sets. The authors propose using structural equation models (SEMs) to create tailored uncertainty sets by modeling specific distribution shifts through causal mechanisms. By identifying which variables shift using conditional independence testing and encoding these shifts as constraints in a mathematical program, the SEM approach provides more accurate worst-case evaluations and learns lower-variance, more robust policies compared to traditional DRO methods, particularly for larger shifts.

## Method Summary
The method works by first using conditional independence tests to identify which variables shift across environments, then fitting SEMs per distribution to extract parameter bounds. These bounds are encoded as constraints in a mathematical program that finds the worst-case distribution. The key innovation is using SEMs to restrict uncertainty sets to plausible causal mechanisms rather than distance-based balls, and separating worst-case distribution identification from policy optimization under positivity assumptions.

## Key Results
- SEM approach provides more accurate worst-case evaluations than DRO across synthetic and voting datasets
- Learns lower-variance, more robust policies compared to traditional DRO methods
- Can learn optimal policies if SEM is well-specified, while traditional DRO converges to local maxima
- Particularly effective for larger distribution shifts where traditional methods become overly conservative

## Why This Works (Mechanism)

### Mechanism 1: SEM-Constrained Uncertainty Sets
SEM-based uncertainty sets produce tighter, more plausible worst-case bounds than distance-based (KL/Wasserstein) balls. Instead of admitting all distributions within radius r of P₀ (which includes implausible shifts like negative ages), SEMCP encodes shifts as bounded perturbations to coefficients β, intercepts, and noise terms ε in structural equations. This restricts uncertainty to causal mechanisms that can plausibly change.

### Mechanism 2: Conditional Independence Testing for Shift Detection
Kernel-based conditional independence tests identify which variables shift across environments. For each variable Sᵢ, test Sᵢ ⊥⊥ B | Pa(Sᵢ) where B is a dataset indicator. If independence fails, Sᵢ belongs in W (shifted variables); otherwise in V (unshifted). Only shifted variables are modeled.

### Mechanism 3: Decoupled Worst-Case Distribution and Policy Learning
The worst-case distribution can be found before policy optimization, enabling convergence to optimal policies (under well-specification). Since actions A don't affect ancestors, and positivity ensures all action values have been observed, worst-case β and ε values are determined per-action independently of π.

## Foundational Learning

- **Structural Equation Models (SEMs)**
  - Why needed here: SEMs encode how each variable depends on its causal parents plus noise. Without this, you can't parameterize distribution shifts as bounded changes to β, ε.
  - Quick check question: Given variables Y, X₀, X₁, can you write Y = ε_Y + β_Y + β_{YX₀}·f_{X₀} + β_{YX₁}·f_{X₁}?

- **Distributionally Robust Optimization (DRO)**
  - Why needed here: Baseline approach defines uncertainty sets via distance metrics (KL, Wasserstein). Understanding why these produce conservative policies motivates SEM constraints.
  - Quick check question: Why does a KL-ball with radius r include implausible distributions?

- **Auxiliary Variable Method (AVM) for Bilinear Terms**
  - Why needed here: SEMs produce β·f terms that are bilinear. AVM reformulates these as linear constraints with variable bounds for commercial solvers.
  - Quick check question: How do you reformulate constraint l_β · v_z ≤ v_{Wz} ≤ u_β · v_z?

## Architecture Onboarding

- **Component map:**
  1. Causal Discovery Module — PC algorithm → DAG G with parent sets Pa(Sᵢ)
  2. Shift Detection Module — Kernel CIT on concatenated datasets → W (shifted), V (unshifted)
  3. SEM Fitting Module — DoWhy GCM → per-distribution β, ε parameters
  4. Bounds Computation — min/max across distributions → l, u bounds for Eq. 5
  5. Mathematical Program Solver — MOSEK with RSOME wrapper → worst-case distribution
  6. Policy Learner — Direct method + policy iteration → π*

- **Critical path:**
  1. Learn/use causal graph (PC + background knowledge)
  2. Detect shifted variables via CIT (Section 4.1)
  3. Fit SEMs per distribution subset (DoWhy)
  4. Extract bounds and build constraints (Eq. 7)
  5. Solve for worst-case distribution (MOSEK)
  6. Run policy iteration on worst-case reward function

- **Design tradeoffs:**
  - Well-specified vs. mis-specified graphs: Well-specified graphs give optimal policies; mis-specified still outperform DRO but with degraded accuracy
  - Binary vs. continuous variables: Binary requires MIP with SOS2 constraints for sigmoid approximation — slower but tractable
  - Full vs. sampled data for optimization: Paper downsamples to 1000 samples per node for tractability

- **Failure signatures:**
  - DRO/fDRO converge to local maxima with high variance
  - KL-ball too large → worst-case includes extreme, implausible reward shifts (DRO estimate = -86 on synthetic)
  - Graph misspecification → SEMCP still works but with reduced accuracy

- **First 3 experiments:**
  1. Replicate Fig. 1 (synthetic): Implement SEMCP on provided synthetic DAG; verify worst-case evaluation accuracy vs. DRO/fDRO/TA
  2. Ablate shift detection: Skip CIT, mark all variables as shifted vs. only ground-truth shifted; measure evaluation error and solve time
  3. Test misspecification sensitivity: Randomly flip 1-3 edges in DAG; plot evaluation error vs. number of wrong edges

## Open Questions the Paper Calls Out

### Open Question 1
How can the SEM-constrained mathematical program approach be effectively extended to reinforcement learning (RL) settings that utilize disentangled representations?
- Basis: Authors state in Conclusion: "Future work includes extending the SEM method to reinforcement learning with disentangled representations."
- Why unresolved: Current work focuses exclusively on multi-armed bandits and offline evaluation, leaving sequential decision-making and state-dependency of RL unaddressed.
- What evidence would resolve it: An algorithm that adapts SEM constraints for Markov Decision Processes (MDPs) and empirical results showing robust policy evaluation in an RL environment.

### Open Question 2
Does the SEM-constrained approach remain computationally tractable and accurate in high-dimensional settings such as robotics, compared to standard distributionally robust optimization?
- Basis: Authors note in Conclusion that while causal modeling is useful for personalization, "it would be expensive for high-dimensional settings like robotics."
- Why unresolved: Current experimental validation is limited to synthetic datasets and a voting dataset with relatively few variables.
- What evidence would resolve it: A complexity analysis of the mathematical program as variable dimensionality increases, alongside experiments on a high-dimensional control task.

### Open Question 3
How does replacing the minimax robustness formulation with Bayesian model averaging affect the performance and conservatism of the learned policies?
- Basis: Conclusion states: "this work focuses on traditional minimax robustness, though future work could put a prior over the uncertainty set and use Bayesian model averaging."
- Why unresolved: Paper strictly utilizes worst-case (minimax) optimization and does not explore probabilistic approaches to handling the uncertainty set.
- What evidence would resolve it: A modified algorithm that places a prior over the SEM parameters and a comparative study of worst-case return versus average return against the minimax baseline.

## Limitations
- Relies heavily on correctly specified causal graphs and identified parent sets
- Requires non-negative normalized data to prevent linearization errors in the mathematical program
- For binary variables, SOS2 constraints add computational complexity
- Requires pre-specified bounds for optimization variables that may be conservative if poorly estimated

## Confidence
- **High Confidence**: SEMs create tighter uncertainty sets than distance-based DRO balls, well-supported by theoretical arguments and synthetic experiments
- **Medium Confidence**: Conditional independence testing for shift detection works as described, though performance depends on sample size
- **Medium Confidence**: Decoupling of worst-case distribution and policy learning under positivity assumptions is theoretically justified

## Next Checks
1. Ablate shift detection: Skip conditional independence testing and mark all variables as shifted versus only ground-truth shifted variables; measure impact on evaluation error and computational runtime
2. Test misspecification sensitivity: Systematically introduce 1-3 random edge flips in the DAG; plot evaluation error against number of wrong edges
3. Verify data normalization impact: Run experiments with unnormalized data to demonstrate solver infeasibility/unboundedness issues