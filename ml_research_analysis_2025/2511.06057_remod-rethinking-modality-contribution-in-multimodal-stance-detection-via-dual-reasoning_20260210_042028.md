---
ver: rpa2
title: 'ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection via
  Dual Reasoning'
arxiv_id: '2511.06057'
source_url: https://arxiv.org/abs/2511.06057
tags:
- stance
- mind
- experience
- reasoning
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses multimodal stance detection, aiming to identify
  user attitudes towards targets using both text and image data. Existing methods
  often simply fuse modalities without explicitly reasoning about their varying contributions,
  which can lead to errors, especially in cases involving irony or logical fallacies.
---

# ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection via Dual Reasoning

## Quick Facts
- arXiv ID: 2511.06057
- Source URL: https://arxiv.org/abs/2511.06057
- Reference count: 13
- Key outcome: State-of-the-art multimodal stance detection using dual reasoning with experience pools

## Executive Summary
This paper addresses multimodal stance detection, aiming to identify user attitudes towards targets using both text and image data. Existing methods often simply fuse modalities without explicitly reasoning about their varying contributions, which can lead to errors, especially in cases involving irony or logical fallacies. To tackle this, the authors propose ReMoD, a framework that employs a dual-reasoning paradigm inspired by human cognition. ReMoD first uses an intuitive stage to form an initial stance hypothesis by querying Modality and Semantic Experience Pools, then refines this hypothesis in a reflective stage using Modality-CoT and Semantic-CoT reasoning chains. These experience pools are continuously updated during training and recalled at inference to guide stance decisions. Extensive experiments on the MMSD benchmark show that ReMoD significantly outperforms most baseline models, achieving state-of-the-art results and demonstrating strong generalization capabilities, particularly in zero-shot settings.

## Method Summary
ReMoD is a dual-reasoning framework for multimodal stance detection built on Qwen-2.5-VL-32B. It consists of three main components: (1) Multimodal Knowledge Perception extracts text entities via MLLM, retrieves Wikipedia knowledge, and segments images using SAM; (2) Experience-Driven Intuitive Reasoning queries Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) using BGE-VL-CLIP embeddings with α=0.7 weighting, τ=0.7 threshold, and top-k=3 retrieval to form initial stance hypotheses; (3) Meta-cognitive Reflective Reasoning uses Modality-CoT and Semantic-CoT to scrutinize initial predictions and update experience pools. The framework is evaluated on the MMSD benchmark across five domains with both in-target and zero-shot settings.

## Key Results
- Achieves state-of-the-art performance on the MMSD benchmark with significant improvements over baseline models
- Demonstrates strong generalization capabilities, particularly in zero-shot settings with 4.24% macro-F1 improvement when using MEP
- Shows effectiveness of dual reasoning approach through ablation studies on experience pools and reasoning components

## Why This Works (Mechanism)

### Mechanism 1: Experience Pool Retrieval for Prior-Guided Inference
- Claim: Retrieving historically successful reasoning patterns improves stance prediction by providing context-aware guidance rather than learning fusion weights from scratch.
- Mechanism: The Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) store key-value pairs where keys are bimodal embeddings and values contain experiential data. At inference, cosine similarity retrieves top-k relevant experiences via a weighted Modality Relevance Score (α=0.7 for text).
- Core assumption: Past reasoning patterns generalize to semantically similar new samples.
- Evidence anchors:
  - [abstract]: "intuitive stage queries the Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) to form an initial stance hypothesis, prioritizing historically impactful modalities"
  - [section 3.2.1]: Formal definition of MRS: S(Ej) = α·Su(qu, Ej) + (1−α)·Sv(qv, Ej)
  - [corpus]: Limited direct corpus validation; "Exploring Vision Language Models for Multimodal Stance Detection" confirms VLMs struggle with cross-modal reasoning, suggesting retrieval-based approaches address an open gap.
- Break condition: When retrieved experiences fall below relevance threshold τ (<0.7), indicating no applicable prior knowledge exists for the input.

### Mechanism 2: Reflective Chain-of-Thought for Error Correction
- Claim: Explicit reasoning chains (CoT) can correct intuitive errors by diagnosing prediction failures and synthesizing external knowledge, particularly for irony and logical fallacies.
- Mechanism: Modality-CoT evaluates accuracy of initial text-only, vision-only, and multimodal predictions to distill adaptive fusion strategies (I_m). Semantic-CoT synthesizes internal rationales with external Wikipedia knowledge (K_u, K_v) to rectify shallow interpretations (I_s).
- Core assumption: Errors in intuitive judgment are detectable through structured self-diagnosis.
- Evidence anchors:
  - [abstract]: "reflective stage uses Modality-CoT and Semantic-CoT reasoning chains" to "refine stance judgments"
  - [section 3.3.1]: "This insight is not merely a summary, but an adaptive fusion strategy that dictates how to dynamically balance unimodal and multimodal cues"
  - [corpus]: No direct corpus evidence for CoT-specific gains in MSD; assumption is transferred from text-only stance detection literature.
- Break condition: When CoT reasoning premises are themselves flawed (e.g., incorrect external knowledge retrieval) or when computational budget prevents multi-step reasoning.

### Mechanism 3: Experience Pool Evolution for Self-Improvement
- Claim: Continuously refining experience pools during training enables cumulative learning and improves zero-shot generalization.
- Mechanism: New insights (I_m, I_s) are fused with retrieved prior experiences via re-reasoning prompts. If no similar experience exists (below threshold), new entries are appended. This creates a compact, coherent knowledge base.
- Core assumption: Experience accumulation correlates with improved reasoning quality over time.
- Evidence anchors:
  - [abstract]: "dual experience structures are continuously refined during training and recalled at inference"
  - [Table 3 ablation]: w/o MEP causes 4.24% macro-F1 drop in zero-shot (73.78→66.95 on MTSE), demonstrating MEP's role in generalization
  - [corpus]: No corpus studies validate experience pool evolution as a mechanism; this appears novel to this framework.
- Break condition: When experience pools grow unbounded (retrieval latency) or accumulate contradictory entries without reconciliation.

## Foundational Learning

- **Concept: Dual-Process Theory (Kahneman, 2011)**
  - Why needed here: The entire framework maps System 1 (fast, intuitive) to pool querying and System 2 (slow, reflective) to CoT reasoning. Understanding this cognitive model clarifies design rationale.
  - Quick check question: Why would a purely fusion-based approach (no explicit reasoning) fail on ironic text-image pairs?

- **Concept: Chain-of-Thought (CoT) Prompting**
  - Why needed here: Modality-CoT and Semantic-CoT are core reasoning modules. You must understand how intermediate reasoning steps improve final predictions.
  - Quick check question: What is the difference between a direct classification prompt and a CoT prompt for stance detection?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Experience pool retrieval follows RAG principles—query encoding, similarity matching, threshold filtering—applied to bimodal embeddings.
  - Quick check question: If the relevance threshold τ is set too low (e.g., 0.3), what type of errors would you expect?

## Architecture Onboarding

- **Component map:**
  Input (text, image) -> Multimodal Knowledge Perception -> Experience Pool Retrieval -> Initial Hypothesis -> Reflective Scrutiny -> Final Stance -> Pool Update (training only)

- **Critical path:**
  Input (text, image) → Knowledge Perception → Pool Retrieval → Initial Hypothesis → Reflective Scrutiny → Final Stance → Pool Update (training only)

- **Design tradeoffs:**
  - **Threshold τ=0.7**: Higher values improve precision but may return insufficient experiences; lower values introduce noise
  - **Top-k=3**: Balances context richness against distraction risk
  - **α=0.7**: Prioritizes text modality in retrieval, reflecting text's dominant role in stance expression (validated by text-only baselines outperforming vision-only)

- **Failure signatures:**
  - **Consistent irony misclassification**: MEP lacks sarcasm-related experiences → manually inject ironic exemplars
  - **High prediction variance on similar inputs**: SEP contains conflicting entries → add deduplication logic
  - **Slow inference (>10s/sample)**: Multiple MLLM calls (knowledge, intuitive, reflective) → consider caching or distillation

- **First 3 experiments:**
  1. **Retrieval quality audit**: Manually inspect top-3 retrieved experiences for 20 samples; verify semantic relevance and actionable strategy content
  2. **Pool contribution ablation**: Compare empty pools vs. pools populated after 1 epoch vs. full training; measure macro-F1 delta
  3. **Threshold sensitivity**: Sweep τ ∈ {0.5, 0.6, 0.7, 0.8, 0.9} on validation set; plot performance vs. retrieval hit rate to identify optimal operating point

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the computational overhead and inference latency of the dual-reasoning framework be reduced to support real-time applications without sacrificing the accuracy gained from the multi-stage meta-cognitive process?
- Basis in paper: [explicit] The authors explicitly state in the Limitations section that the framework involves "significant computational overhead" due to multiple calls to the large multimodal model, making it unsuitable for real-time use, and suggest future work on knowledge distillation.
- Why unresolved: The current implementation prioritizes reasoning depth over speed, and the paper does not experiment with model compression or efficient inference techniques.
- What evidence would resolve it: A study demonstrating a distilled or pruned version of the model that retains SOTA performance on the MMSD benchmark while operating within real-time latency constraints.

### Open Question 2
- Question: How does the continuous accumulation of experiences in the Modality and Semantic Experience Pools affect retrieval efficiency and model stability over extended periods of operation?
- Basis in paper: [inferred] The paper describes the experience pools as "continuously refined" and appended to if no relevant experience exists (Section 3.3.2), but the experiments evaluate performance on fixed benchmarks rather than long-term memory accumulation.
- Why unresolved: As the pools grow indefinitely, the "modal synergistic retrieval" mechanism may suffer from increased latency or "catastrophic forgetting" where new insights overwrite crucial past data.
- What evidence would resolve it: Experiments simulating long-term usage where the pool size grows orders of magnitude larger than the training set, analyzing retrieval speed and classification accuracy over time.

### Open Question 3
- Question: Would replacing the fixed relevance threshold ($\tau$) with a dynamic, learnable gating mechanism improve the quality of retrieved experiences across diverse target domains?
- Basis in paper: [inferred] Section 4.6 analyzes the impact of different fixed thresholds (0.1 to 0.9) and identifies a trade-off where low thresholds introduce noise and high thresholds are too restrictive.
- Why unresolved: A static threshold may not be optimal for all domains (e.g., politics vs. health) which likely have varying densities of relevant historical experiences in the pools.
- What evidence would resolve it: A comparative study where $\tau$ is dynamically predicted by the model based on the input query's similarity to the existing knowledge base distribution.

## Limitations

- **Computational overhead**: The framework involves significant computational overhead due to multiple calls to the large multimodal model, making it unsuitable for real-time use.
- **Experience pool management**: As experience pools grow indefinitely, retrieval efficiency may degrade and there's risk of accumulating contradictory entries without reconciliation.
- **Threshold sensitivity**: The fixed relevance threshold (τ=0.7) may not be optimal across all target domains, requiring manual tuning for different applications.

## Confidence

- **High**: Core mechanism and in-target performance claims
- **Medium**: Zero-shot generalization claims and experience pool evolution impact
- **Low**: Real-world applicability due to computational cost and latency issues

## Next Checks

1. Validate retrieved experience relevance by manually inspecting top-3 examples across 20 diverse samples to ensure semantic and strategic alignment.
2. Test experience pool contribution by comparing performance with empty pools, epoch-1 pools, and fully trained pools to quantify learning gains.
3. Sweep relevance threshold τ across [0.5, 0.9] and measure both retrieval hit rate and macro-F1 to identify the optimal trade-off between precision and recall.