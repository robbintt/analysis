---
ver: rpa2
title: 'Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN'
arxiv_id: '2601.17912'
source_url: https://arxiv.org/abs/2601.17912
tags:
- fairness
- tabpfn
- causal
- datasets
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the fairness of TabPFN, a foundation model
  for tabular data pre-trained on synthetic datasets generated via structural causal
  models. The authors conduct comprehensive empirical evaluations comparing TabPFN
  and its fine-tuned variant (FT-TabPFN) against classical baselines (LR, RF, MLP)
  across four datasets (Heart, Bank, Law, Adult), focusing on accuracy, fairness metrics
  (EO, DP), and robustness to spurious correlations and missing-not-at-random (MNAR)
  covariate shifts.
---

# Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN

## Quick Facts
- arXiv ID: 2601.17912
- Source URL: https://arxiv.org/abs/2601.17912
- Authors: Qinyi Liu; Mohammad Khalil; Naman Goel
- Reference count: 25
- This study investigates the fairness of TabPFN, a foundation model for tabular data pre-trained on synthetic datasets generated via structural causal models.

## Executive Summary
This empirical study evaluates TabPFN, a foundation model for tabular data, under the lens of algorithmic fairness. The authors compare TabPFN and its fine-tuned variant against classical baselines across four datasets, focusing on accuracy, fairness metrics, and robustness to spurious correlations and missing-not-at-random (MNAR) covariate shifts. While TabPFN demonstrates high predictive accuracy and robustness to spurious correlations, fairness improvements are moderate and inconsistent, particularly under MNAR shifts. The findings suggest that causal pre-training alone is insufficient to ensure algorithmic fairness in real-world scenarios.

## Method Summary
The study compares five models—TabPFN (zero-shot), FT-TabPFN (fine-tuned), logistic regression, random forest, and MLP—on four tabular datasets (Heart, Bank, Law, Adult). Models are evaluated on accuracy, demographic parity (DP), and equalized odds (EO). Experiments include spurious correlation tests (adding a correlated feature that flips between train/test) and MNAR tests (removing 70% of specific subgroups). TabPFN uses in-context learning with 5000 subsampled examples, while FT-TabPFN undergoes 10 epochs of fine-tuning. All models are evaluated with five random seeds.

## Key Results
- TabPFN achieves high predictive accuracy (e.g., ~0.99 on Bank) and robust performance under spurious correlations due to SCM-based pre-training.
- Fairness improvements are moderate and inconsistent; EO varies widely (0.08–0.59) and DP is unstable (0.38–0.42) under MNAR shifts.
- Causal pre-training alone is insufficient to ensure algorithmic fairness in real-world scenarios, especially under MNAR selection bias.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** SCM-based pre-training improves robustness to spurious correlations but does not guarantee fairness improvements.
- **Mechanism:** TabPFN is pre-trained on millions of synthetic datasets generated via structural causal models (SCMs), which encode stable causal dependencies rather than dataset-specific correlations. This prior encourages the model to prefer invariant causal relationships over statistical shortcuts during inference.
- **Core assumption:** Synthetic SCM distributions sufficiently approximate the causal structure of real-world tabular tasks.
- **Evidence anchors:** [abstract] "pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM)"; [section 2.2] "the SCM-based prior grounds the model in stable causal dependencies, potentially mitigating reliance on spurious correlations"; [corpus] "Does TabPFN Understand Causal Structures?" investigates whether pre-training transfers to real causal discovery—findings pending.
- **Break condition:** When spurious features are causally entangled with true predictors in ways the SCM prior does not model, or when real-world selection mechanisms deviate substantially from synthetic distributions.

### Mechanism 2
- **Claim:** In-context learning with causal priors provides regularization in low-data regimes, improving accuracy-fairness tradeoffs.
- **Mechanism:** TabPFN uses real task-specific data only at inference time (in-context learning), approximating Bayesian inference over plausible causal mechanisms. This avoids overfitting to biased or undersampled patterns in small training sets.
- **Core assumption:** The meta-learned prior generalizes across diverse causal structures encountered during pre-training.
- **Evidence anchors:** [section 2.2] "its Bayesian-style inference can potentially provide regularization against overfitting to biased or undersampled data"; [section 4, RQ1] "at 500 samples on Adult, average DP for TabPFN and FT-TabPFN is significantly lower than other baselines"; [corpus] Real-TabPFN shows continued pre-training on real data boosts performance, suggesting synthetic priors have limits.
- **Break condition:** When training size exceeds the pre-training regime (>10k samples), fairness metrics exhibit greater variability (Fig. 1), indicating prior mismatch.

### Mechanism 3
- **Claim:** Causal pre-training cannot compensate for systematic under-representation in MNAR selection bias scenarios.
- **Mechanism:** MNAR selection creates covariate shift where inclusion probability depends on unobserved outcomes and observed attributes. SCM-based priors cannot recover causal relationships from subpopulations that are systematically missing from the training data.
- **Core assumption:** Synthetic pre-training data includes diverse causal structures but cannot anticipate all real-world selection mechanisms.
- **Evidence anchors:** [abstract] "causal pre-training alone is insufficient to ensure algorithmic fairness in real-world scenarios"; [section 4, Table 3] "under MNAR, EO varies widely (0.08–0.59) and DP is unstable (0.38–0.42) across datasets"; [corpus] No direct corpus evidence on MNAR specifically; neighbor papers focus on accuracy and causal structure understanding, not fairness under selection bias.
- **Break condition:** When selection bias creates entangled scenarios (imbalanced sensitive attributes + missing causal data), fairness interventions beyond pre-training are required.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs)**
  - **Why needed here:** TabPFN's pre-training data is generated from SCMs, which define how variables causally relate. Understanding SCMs is essential to interpret why causal pre-training helps with spurious correlations but not MNAR selection.
  - **Quick check question:** Can you explain why a variable being marginally correlated with an outcome does not imply it causes that outcome?

- **Concept: In-Context Learning (ICL)**
  - **Why needed here:** TabPFN uses real data only at inference time, treating training examples as context for a transformer. This distinguishes it from classical models that learn weights from the target dataset.
  - **Quick check question:** How does ICL differ from traditional fine-tuning, and what does this imply for data privacy?

- **Concept: Group Fairness Metrics (Demographic Parity, Equalized Odds)**
  - **Why needed here:** The paper evaluates fairness via DP (prediction independent of sensitive attribute) and EO (prediction independent of sensitive attribute conditional on true label). These metrics capture different fairness intuitions and cannot both be satisfied simultaneously except in trivial cases.
  - **Quick check question:** Given two groups with different base rates, why might enforcing DP harm calibration or accuracy?

## Architecture Onboarding

- **Component map:** Synthetic tabular datasets generated from SCMs -> Transformer pre-training -> In-context learning at inference -> Fine-tuning (optional) -> Fairness and accuracy evaluation
- **Critical path:** Data preprocessing (standardization, one-hot encoding) -> identical across all models -> Context construction for TabPFN: subsample 5000 training examples as context at inference -> Metric computation: EO and DP averaged over sensitive attributes; compare against LR, RF, MLP baselines
- **Design tradeoffs:** TabPFN vs. FT-TabPFN: Zero-shot TabPFN preserves fairness better in small-data regimes; FT-TabPFN achieves higher accuracy but fairness fluctuates more with scale. Sample size regime: TabPFN validated for ≤10k samples; beyond this, fairness becomes unstable while accuracy remains competitive. Spurious robustness vs. MNAR fairness: Causal pre-training helps with the former but not the latter—deployers must add fairness interventions for MNAR scenarios.
- **Failure signatures:** Spurious correlation collapse: Law dataset shows anomalously low consistency (<0.62) and accuracy (<0.56) post-flip despite high baseline accuracy—caused by extreme attribute/label imbalance fostering proxy reliance. MNAR fairness degradation: EO ranges from 0.08 (near-optimal) to 0.59 (severe disparity); DP oscillates 0.38–0.42 across datasets, indicating pre-training does not stabilize fairness under selection bias. Scale-induced variability: EO and DP fluctuate as training size increases beyond 10k (Fig. 1), suggesting prior-task mismatch.
- **First 3 experiments:** Replicate spurious correlation test on a new dataset: Add Z_spur with train/test correlation reversal; measure flip consistency, accuracy drop, and EO/DP change for TabPFN vs. LR baseline. Small-sample fairness benchmark: On a 500-sample subset of Adult or Law, compare TabPFN, FT-TabPFN, and RF on accuracy + DP + EO; verify whether TabPFN's fairness advantage holds. MNAR stress test with controlled selection: Construct a synthetic MNAR scenario where a known subgroup is under-sampled; test whether causal imputation or fairness regularization recovers fairness where TabPFN does not.

## Open Questions the Paper Calls Out

- **Question:** Can integrating causal imputation for missing attributes effectively mitigate the fairness degradation observed in TabPFN under Missing-Not-at-Random (MNAR) covariate shifts?
  - **Basis in paper:** [explicit] The conclusion explicitly suggests "Future work could explore integrating causal imputation for missing attributes..."
  - **Why unresolved:** The study found that while TabPFN is robust to spurious correlations, it shows unstable fairness metrics (EO/DP) under MNAR shifts (e.g., EO varying 0.08–0.59).
  - **What evidence would resolve it:** Empirical results showing that a TabPFN variant with causal imputation maintains stable EO and DP scores on the Bank and Heart datasets under simulated MNAR conditions.

- **Question:** How can dynamic fairness regularization be implemented within TabPFN to address the inconsistent fairness improvements seen in entangled scenarios without sacrificing predictive accuracy?
  - **Basis in paper:** [explicit] The conclusion proposes "developing dynamic fairness regularization" to address the identified limitations.
  - **Why unresolved:** The paper demonstrates that causal pre-training alone is insufficient for fairness, particularly where improvements are moderate and fluctuate across datasets.
  - **What evidence would resolve it:** A fine-tuning protocol or loss function modification that yields consistent improvements in Demographic Parity across all four benchmark datasets without reducing the high accuracy (e.g., ~0.99 on Bank) reported in the paper.

- **Question:** What specific properties of the Law dataset cause the "anomalously low" flip consistency in TabPFN, and does this indicate a general failure mode for imbalanced datasets?
  - **Basis in paper:** [inferred] The results section notes "anomalously low consistency (<0.62)" for Law, hypothesizing extreme imbalance and proxy reliance as causes, but does not confirm the mechanism.
  - **Why unresolved:** This anomaly contradicts the model's otherwise robust performance under spurious correlations (Table 2), yet the root cause remains unverified.
  - **What evidence would resolve it:** An ablation study varying sensitive attribute imbalance ratios in the Law dataset to isolate the trigger for the observed consistency collapse.

## Limitations

- The study's findings are constrained by the synthetic nature of the pre-training data, which may not fully capture the complexity of real-world causal structures and selection mechanisms.
- The MNAR experiments use simplified subgroup removal criteria that may not reflect the nuanced selection biases present in actual datasets.
- The evaluation focuses on a limited set of fairness metrics (DP and EO), potentially overlooking other important aspects of algorithmic fairness.

## Confidence

- **High Confidence:** TabPFN achieves high predictive accuracy and robust performance under spurious correlations due to its SCM-based pre-training.
- **Medium Confidence:** Causal pre-training provides regularization in low-data regimes, improving accuracy-fairness tradeoffs, but the benefits diminish with larger training sizes.
- **Low Confidence:** Causal pre-training alone is insufficient to ensure algorithmic fairness under MNAR selection bias, but the specific mechanisms and potential remedies require further investigation.

## Next Checks

1. Evaluate TabPFN's performance on datasets with more complex and realistic selection biases to assess the generalizability of the MNAR findings.
2. Investigate the impact of different pre-training scales and continued pre-training on real-world data to determine if these approaches can enhance fairness performance.
3. Expand the evaluation to include additional fairness metrics, such as Equal Opportunity Difference and Disparate Impact, to provide a more comprehensive assessment of algorithmic fairness.