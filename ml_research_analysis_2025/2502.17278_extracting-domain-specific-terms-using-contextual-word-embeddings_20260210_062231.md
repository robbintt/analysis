---
ver: rpa2
title: Extracting domain-specific terms using contextual word embeddings
arxiv_id: '2502.17278'
source_url: https://arxiv.org/abs/2502.17278
tags:
- terms
- domain
- term
- corpus
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a machine learning approach to terminology
  extraction that combines linguistic, statistical, and contextual features derived
  from ELMo embeddings. Unlike traditional systems that rely on predefined part-of-speech
  patterns, the authors propose a shallow filter based on linguistic characteristics
  of terms, allowing for greater flexibility.
---

# Extracting domain-specific terms using contextual word embeddings

## Quick Facts
- arXiv ID: 2502.17278
- Source URL: https://arxiv.org/abs/2502.17278
- Authors: Andraž Repar; Nada Lavrač; Senja Pollak
- Reference count: 9
- Key result: F1 scores of 0.530-0.594 across four domains, outperforming previous state-of-the-art

## Executive Summary
This paper introduces a machine learning approach to terminology extraction that combines linguistic, statistical, and contextual features derived from ELMo embeddings. Unlike traditional systems that rely on predefined part-of-speech patterns, the authors propose a shallow filter based on linguistic characteristics of terms, allowing for greater flexibility. The method uses a support vector machine classifier trained on three feature types: linguistic (POS-based), statistical (termhood measures), and contextual (domain vs. general corpus embeddings). Evaluated on the RSDO5 corpus for Slovenian across four domains, the approach achieves F1 scores between 0.530 and 0.594, significantly outperforming previous state-of-the-art methods. The contextual embeddings prove especially valuable for low-frequency terms. Error analysis reveals some false positives could still be valid terms in semi-automatic extraction settings. The method is practical for moderate-sized corpora and adaptable to other languages with minimal changes.

## Method Summary
The method combines three feature types in a linear SVM classifier: linguistic features based on universal POS tags (69 dimensions), statistical features measuring termhood via frequency ratios (3 dimensions), and contextual features derived from ELMo embeddings averaged over domain and general corpora (1,027 dimensions). Candidates are generated using a shallow linguistic filter with 6 rules applied to n-grams up to 11 tokens. The model is trained using leave-one-domain-out cross-validation on the RSDO5 corpus (biomechanics, linguistics, chemistry, veterinary). ELMo embeddings are computed for the top 200K tokens from the general reference corpus (ccGigafida) and for each lemma in the domain corpus, with averaging performed via AllenNLP.

## Key Results
- F1 scores of 0.530-0.594 across four domains, outperforming previous state-of-the-art (LUIZ) which achieved 0.380-0.434
- Contextual embeddings improve low-frequency term detection, with contextual-only features yielding precision >0.630 but near-zero recall
- Shallow linguistic filter achieves maximum recall of 0.86-0.93 per domain, more flexible than rigid POS patterns
- All three feature types are necessary for optimal performance; removing any reduces F1 scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual embeddings capture semantic differences in how terms are used across domain-specific versus general corpora.
- Mechanism: ELMo generates context-sensitive vectors for each word occurrence. Averaging these across a domain corpus and a general reference corpus (Gigafida 2.0) produces two embeddings per lemma. Domain-specific terms exhibit greater divergence between these embeddings than common words, measured via cosine similarity (elmoSim).
- Core assumption: Terms shift meaning or usage context between specialized and general language more than non-terms do.
- Evidence anchors:
  - [abstract] "contextual features derived from ELMo embeddings... prove that contextual word embeddings are valuable for improving term extraction"
  - [section 4.2.3] "we hypothesize that domain-specific terms are used in different contexts in domain-specific corpora compared to general corpora"
  - [corpus] Limited. No direct corpus comparison validates the semantic-shift assumption. Related work on embedding-based term extraction exists, but causal evidence for this specific mechanism is internal to the study.
- Break condition: If target domain uses highly similar vocabulary/register to the general corpus (e.g., popular science texts), elmoSim will have reduced discriminative power.

### Mechanism 2
- Claim: A shallow linguistic filter preserves candidate coverage while reducing noise compared to rigid POS-pattern lists.
- Mechanism: Instead of enumerating ADJ+NOUN, NOUN+NOUN, etc., the filter applies 6 rules: minimum 4 characters; unigrams must be NOUN/PROPN; multi-words must end with NOUN/PROPN; must start with ADJ/ADV/NOUN/PROPN; exclude closed-class and punctuation; exclude comma/underscore. Maximum recall: 0.86–0.93 across domains.
- Core assumption: Most valid terms conform to these broad constraints; non-terms violating them are safely excluded.
- Evidence anchors:
  - [abstract] "shallow filter based on linguistic characteristics of terms, allowing for greater flexibility"
  - [section 4.1] "maximum recall per domain is 0.91...0.93" with Table 2 showing filtered candidates vs. gold standard
  - [corpus] No external corpus evidence. The filter was derived from RSDO5 analysis itself, creating a potential circularity risk if applied to other corpora without validation.
- Break condition: Domains with frequent verbal or adverbial terms (e.g., "to google", "on-demand") will lose valid candidates to the start/end POS constraints.

### Mechanism 3
- Claim: Combining linguistic, statistical, and contextual features in a linear SVM leverages complementary signals.
- Mechanism: Linguistic features (69-dim POS vectors), statistical features (3-dim: general freq, domain freq, length), and contextual features (1,024-dim ELMo + 3 derived metrics) are concatenated. Ablation shows removing any group reduces F1; contextual-only still yields precision >0.630.
- Core assumption: Feature types capture non-redundant information; linear kernel suffices for high-dimensional separation.
- Evidence anchors:
  - [section 5.3] "removing each feature type does reduce the F1 scores in all domains...using only statistical and pattern features produces almost no correct predictions"
  - [Table 6] Contextual-only (C): F1 near 0; Contextual+Pattern (C+P): 0.433–0.560; All three (C+P+S): 0.530–0.594
  - [corpus] Weak. No theoretical justification for why SVM outperformed Random Forest and MLP on this feature set.
- Break condition: If contextual embeddings are noisy (e.g., small domain corpus averaging <5 occurrences per lemma), statistical features become primary signal—SVM may underperform frequency-based baselines.

## Foundational Learning

- Concept: Contextual vs. Static Word Embeddings
  - Why needed here: ELMo's defining property is context-sensitivity; the same surface form receives different vectors in different sentences. Understanding this distinguishes the approach from Word2Vec/GloVe-based term extraction.
  - Quick check question: If you see "bank" in a finance document and "bank" in a geology document, will a static embedding give them the same vector? What about ELMo?

- Concept: Termhood vs. Unithood
  - Why needed here: The statistical features directly implement Vintar's termhood formula (domain frequency vs. general frequency). Unithood (collocational stability) is less central here but appears in related work.
  - Quick check question: A phrase like "of the" has high unithood but low termhood. Why would it be a poor term candidate?

- Concept: Precision-Recall Tradeoff in ATE
  - Why needed here: The paper optimizes F1, but Table 5 shows pattern-based approaches have higher precision (0.694) than the proposed method (0.650) in biomechanics, with lower recall. System choice depends on downstream use case.
  - Quick check question: In a semi-automatic terminology portal where domain experts review suggestions, would you prioritize precision or recall?

## Architecture Onboarding

- Component map: Classla preprocessing -> Shallow filter -> Feature extraction -> Linear SVM -> Inference
- Critical path: Computing ELMo embeddings on the general reference corpus (ccGigafida top 200k tokens). This is a one-time cost but dominates runtime. Domain-specific embedding computation for a 50k–100k word corpus takes ~30 minutes on a standard laptop.
- Design tradeoffs:
  - Flexibility vs. precision: Shallow filter admits longer/non-standard candidates but increases false positives (e.g., general words like "sistem", "proces" predicted as terms).
  - Computational cost vs. low-frequency coverage: ELMo enables detection of rare terms but requires averaging over all occurrences; hapax legomena (freq=1) have noisy embeddings.
  - Single-domain training vs. cross-domain generalization: Model trained on 3/4 domains; performance varies modestly (F1 0.530–0.594), suggesting reasonable generalization but domain-specific tuning may help.
- Failure signatures:
  - False positives from general vocabulary (e.g., "leto", "mesto")—likely due to similar domain/general embedding distributions for high-frequency non-terms.
  - Lemmatization errors propagating to features (e.g., "regrgrposs", "mehanovsprejemnik")—Classla pipeline quality bounds system performance.
  - Near-zero F1 when using only statistical+pattern features without contextual—ablation shows these are insufficient alone.
- First 3 experiments:
  1. **Baseline ablation**: Reproduce Table 6 on a held-out domain. Confirm that contextual features alone yield precision >0.6 but near-zero recall, and that all three feature types are needed for F1 >0.5.
  2. **Filter sensitivity**: Vary the 6 filter rules (e.g., relax end-with-NOUN constraint). Measure impact on candidate pool size, maximum recall, and final F1. Identify which rules are most restrictive.
  3. **Embedding layer comparison**: The paper uses ELMo's first LSTM layer. Compare to the weighted average of all three layers (as suggested in Section 6) on a single domain to estimate potential gains before full re-training.

## Open Questions the Paper Calls Out
None

## Limitations
- Shallow linguistic filter shows maximum recall of 0.91-0.93 per domain, meaning 7-9% of valid terms are never considered as candidates
- Reliance on ELMo embeddings averaged across entire corpora may be computationally expensive for larger domains
- System produces false positives from general vocabulary (e.g., "sistem", "proces"), indicating remaining precision challenges
- Lemmatization errors from Classla pipeline directly impact feature extraction quality

## Confidence
- **High Confidence**: ELMo-based contextual features improve low-frequency term detection compared to statistical features alone; ablation study clearly shows all three feature types are necessary for optimal performance
- **Medium Confidence**: Shallow filter achieves claimed maximum recall rates (0.86-0.93) as shown in Table 2, though derivation from RSDO5 itself raises circularity concerns
- **Low Confidence**: Mechanism by which contextual embeddings capture domain-specific semantics (elmoSim) is plausible but not directly validated against gold semantic annotations

## Next Checks
1. **Filter Coverage Validation**: Systematically vary each of the 6 shallow filter rules and measure the impact on maximum recall and final F1 scores to identify which rules are most restrictive
2. **ELMo Layer Comparison**: Compare current approach (first LSTM layer only) against weighted average of all three ELMo layers on a single domain to validate suggested improvement
3. **Cross-Lingual Transfer Test**: Apply trained model to a different Slavic language with available ELMo embeddings to test method's adaptability claim and language-independence of feature engineering