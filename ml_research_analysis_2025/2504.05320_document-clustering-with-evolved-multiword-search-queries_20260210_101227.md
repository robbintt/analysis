---
ver: rpa2
title: Document clustering with evolved multiword search queries
arxiv_id: '2504.05320'
source_url: https://arxiv.org/abs/2504.05320
tags:
- documents
- clustering
- query
- queries
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents eSQ, a novel document clustering method based
  on evolved multi-word search queries using a genetic algorithm. Unlike traditional
  clustering algorithms that rely on similarity measures between documents, eSQ generates
  clusters by evolving search queries where each query returns a set of documents
  as a cluster.
---

# Document clustering with evolved multiword search queries

## Quick Facts
- arXiv ID: 2504.05320
- Source URL: https://arxiv.org/abs/2504.05320
- Authors: Laurence Hirsch; Robin Hirsch; Bayode Ogunleye
- Reference count: 40
- Outperforms k-means++ and other clustering methods on 8 datasets with higher V-measure and Adjusted Rand Index scores

## Executive Summary
This paper presents eSQ, a novel document clustering method that uses evolved multi-word search queries generated by a genetic algorithm. Unlike traditional clustering algorithms that rely on similarity measures between documents, eSQ generates clusters by evolving search queries where each query returns a set of documents as a cluster. The approach aims to provide interpretable and modifiable clustering results. The method includes a second stage using KNN to assign all documents to clusters, addressing the coverage limitation of the genetic algorithm phase.

## Method Summary
eSQ uses a genetic algorithm to evolve search queries that define document clusters through set operations rather than vector similarity. Each query is represented as a chromosome of word indices from a TF-IDF filtered wordlist. The GA maximizes a fitness function based on "unique hits" - documents returned by exactly one query. An intersection ratio constraint ensures multi-word queries maintain semantic coherence. After evolution, a KNN stage assigns unassigned documents to clusters, providing complete coverage while maintaining interpretability.

## Key Results
- Achieves higher V-measure and Adjusted Rand Index scores than k-means++ and other clustering methods
- Produces interpretable, modifiable search query clusters
- Demonstrates effectiveness across 8 different datasets
- Shows the approach is suitable for information retrieval applications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Optimizing for "unique hits" drives cluster separation without requiring explicit distance metrics between documents.
- **Mechanism:** The genetic algorithm (GA) maximizes a fitness score defined as the count of documents returned by exactly one query (`uniqueHits`). By rewarding solutions where document sets do not overlap, the system effectively enforces cluster separation (low inter-cluster similarity) using set theory rather than geometric distance.
- **Core assumption:** Maximizing the count of uniquely matched documents correlates with semantic relevance and meaningful topic separation.
- **Evidence anchors:**
  - [abstract] "queries are optimized to maximize the number of documents returned and to minimize the overlap between clusters"
  - [section 3.4] "uniqueHits as the count of documents returned by exactly one query in the set of queries... the higher the value the better the fitness."
- **Break condition:** If documents in the collection are highly multi-topical (e.g., a single document discusses "sports" and "space" equally), this mechanism may fail as it forces hard boundaries where none exist naturally.

### Mechanism 2
- **Claim:** Constraining query evolution via an "intersect ratio" ensures multi-word queries maintain semantic coherence.
- **Mechanism:** When the GA adds a second word to a query, it validates that the new word shares a minimum percentage of documents (intersection ratio) with the root word. This ensures that `Word A` (root) and `Word B` (new) appear in the same context, preventing the GA from simply adding high-frequency words to artificially boost hit counts.
- **Core assumption:** Words that co-occur in the same subset of documents belong to the same semantic category.
- **Evidence anchors:**
  - [section 3.2.2] "constrain the query construction such that the set of documents returned by any additional query words intersect with the set returned by the root word."
  - [section 4.1] "The rationale for the intersect requirement is to create a mechanism which allows GAs to produce queries... retrieving related documents ideally from a single category."
- **Break condition:** If the root word is polysemous (e.g., "bank"), the intersection constraint might filter out valid related words (e.g., "money") if they appear in different contexts (e.g., "river bank") that dilute the intersection ratio.

### Mechanism 3
- **Claim:** A two-stage hybrid process (Evolution + KNN) resolves the trade-off between cluster explainability and coverage.
- **Mechanism:** The GA creates highly interpretable "core" clusters covering ~70% of the data. The subsequent K-Nearest Neighbors (KNN) stage treats these core clusters as labeled training data to classify the remaining "unassigned" documents, ensuring 100% coverage.
- **Core assumption:** The documents matched by the evolved queries are representative enough to serve as ground truth for the outliers.
- **Evidence anchors:**
  - [abstract] "once the search query evolution is completed a second stage is performed whereby a KNN algorithm is applied to assign all unassigned documents"
  - [section 3.7] "The clusters produced by the GA generated search queries have a drawback in that many of the documents are not returned by any query... we include a second stage whereby the query generated clusters are used as labelled training sets."
- **Break condition:** If the initial GA clusters are sparse or biased, the KNN stage will propagate these errors, classifying ambiguous documents into incorrect groups.

## Foundational Learning

- **Concept:** **Inverted Index & Set Operations**
  - **Why needed here:** Unlike vector-space models (k-means), this architecture relies on direct set membership (document lists for specific terms) to define clusters.
  - **Quick check question:** If Query A returns {Doc1, Doc2} and Query B returns {Doc2, Doc3}, what is the `uniqueHits` count for this set of queries? (Answer: 2; Doc1 and Doc3 are unique, Doc2 is a duplicate).

- **Concept:** **Genetic Algorithms (Selection & Chromosomes)**
  - **Why needed here:** The core logic relies on representing search queries as integer chromosomes (indices into a wordlist) that evolve over generations via crossover and mutation.
  - **Quick check question:** In this paper, a chromosome `[5, 0, 4]` maps to indices in a wordlist. If mutation changes `0` to `1`, what effectively happens to the search query?

- **Concept:** **TF-IDF (Term Frequency-Inverse Document Frequency)**
  - **Why needed here:** Used to filter the search space. The GA only selects from the "top 100 words" sorted by TF-IDF to ensure evolution focuses on meaningful, discriminative terms.
  - **Quick check question:** Why would a common stop word like "the" have a low IDF and likely be excluded from the GA's wordlist?

## Architecture Onboarding

- **Component map:** Pre-processor -> Indexer -> GA Core -> Evaluator -> Expander
- **Critical path:**
  1. **Initialization:** Calculate TF-IDF -> Create Wordlist
  2. **Evolution (Loop):** Generate Population -> Fire Queries -> Count Unique Hits -> Select/Reproduce -> Repeat 100x
  3. **Finalization:** Extract best queries -> Assign docs -> Run KNN on remainder

- **Design tradeoffs:**
  - **Speed vs. Interpretability:** The paper notes eSQ is significantly slower (~885ms vs ~26ms for k-means++) because it evaluates full set operations rather than vector math. You pay for the explainable query output with latency.
  - **Purity vs. Coverage:** The GA phase produces high V-measure (pure) clusters but leaves ~30% of docs unassigned. The KNN phase adds coverage but slightly dilutes the V-measure.

- **Failure signatures:**
  - **The "Runaway k" Effect:** If the penalty term (`k * 0.02`) is too low, the GA may evolve excessive queries to maximize hits, resulting in fragmented clusters.
  - **Generic Queries:** If the intersect ratio is too low, queries evolve into lists of generic high-frequency terms that return the whole corpus.

- **First 3 experiments:**
  1. **Intersect Ratio Ablation:** Run the system on a validation set with `intersect_ratio = 0.0` vs `0.5`. Confirm that 0.0 produces incoherent multi-topic queries while 0.5 stabilizes them.
  2. **Wordlist Size Sensitivity:** Reduce the TF-IDF wordlist from 100 to 20 words. Observe if the GA fails to find valid clusters due to a lack of building blocks.
  3. **KNN Boundary Analysis:** Visualize the documents assigned by KNN vs. those assigned by Queries. Check if KNN is "reaching" too far to assign outliers, which would suggest the `k` penalty or intersect ratio needs tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does adding conjunction and negation operators to the query representation improve clustering performance over the current disjunctive-only model?
- Basis in paper: [explicit] The authors state, "Currently the algorithm only generates disjunctive queries... We would like to experiment with more complex queries which include conjunction, negation."
- Why unresolved: The current implementation restricts queries to logical OR operations to simplify the genetic algorithm's search space.
- What evidence would resolve it: Comparative experiments measuring V-measure on the same datasets using GA-evolved conjunctive and negated queries.

### Open Question 2
- Question: How does the algorithm's performance scale with the required number of clusters ($k$), specifically regarding the fitness penalty and convergence speed?
- Basis in paper: [inferred] The paper notes a limitation: "the datasets we have used have a maximum number of 8 categories and we have not tested the system where a large number of clusters would be required."
- Why unresolved: The fitness function includes a linear penalty for $k$, which may over-penalize valid high-$k$ solutions or fail to converge efficiently in larger search spaces.
- What evidence would resolve it: Testing the method on datasets with significantly more ground-truth categories (e.g., $k > 20$) to observe performance trends.

### Open Question 3
- Question: Can the eSQ method be effectively adapted for clustering non-textual data such as images?
- Basis in paper: [explicit] The authors list a recommendation: "We are investigating the possibility of applying the algorithm to cluster other media such as images."
- Why unresolved: The algorithm relies on text-specific concepts like Apache Lucene indices and TF-IDF wordlists, which do not directly transfer to visual data.
- What evidence would resolve it: A modified eSQ framework applied to an image dataset (e.g., using feature tags), showing competitive accuracy against standard image clustering baselines.

## Limitations
- The method's reliance on single-term document matching creates challenges with multi-topic documents
- Fixed 100-word TF-IDF vocabulary may exclude domain-specific terminology crucial for certain datasets
- The KNN stage introduces a black-box component that undermines interpretability advantage

## Confidence
- **High confidence** in the core mechanism that set-theoretic fitness maximization drives cluster separation through query optimization
- **Medium confidence** in the intersection ratio's effectiveness for maintaining semantic coherence
- **Low confidence** in the generalizability of the TF-IDF wordlist filtering across diverse datasets

## Next Checks
1. **Multi-topic document stress test**: Evaluate eSQ on datasets known for multi-topic documents (e.g., news articles covering multiple events) to measure how well the intersection ratio constraint handles polysemy and topic overlap.

2. **Vocabulary sensitivity analysis**: Systematically vary the TF-IDF wordlist size (10, 50, 100, 200 words) across all 8 datasets to determine the minimum vocabulary required for stable performance and identify any dataset-specific thresholds.

3. **KNN error propagation audit**: For each dataset, calculate the classification confidence of KNN-assigned documents by measuring their distance to cluster centroids, then determine what percentage of KNN assignments have low confidence scores that might indicate misclassification.