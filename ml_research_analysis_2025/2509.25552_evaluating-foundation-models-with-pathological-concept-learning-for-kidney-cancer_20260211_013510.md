---
ver: rpa2
title: Evaluating Foundation Models with Pathological Concept Learning for Kidney
  Cancer
arxiv_id: '2509.25552'
source_url: https://arxiv.org/abs/2509.25552
tags:
- concept
- cancer
- concepts
- pathological
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study develops a pathological concept learning framework for
  kidney cancer using foundation models and graph neural networks to identify interpretable
  clinical concepts from whole slide images. By leveraging TNM staging guidelines
  and pathology reports, the framework constructs comprehensive pathological concepts
  and trains graph neural networks to identify them from WSI features.
---

# Evaluating Foundation Models with Pathological Concept Learning for Kidney Cancer

## Quick Facts
- **arXiv ID:** 2509.25552
- **Source URL:** https://arxiv.org/abs/2509.25552
- **Reference count:** 17
- **Primary result:** Achieves 0.718 C-Index for survival prediction using interpretable pathological concepts from WSIs

## Executive Summary
This study develops a pathological concept learning framework for kidney cancer using foundation models and graph neural networks to identify interpretable clinical concepts from whole slide images. By leveraging TNM staging guidelines and pathology reports, the framework constructs comprehensive pathological concepts and trains graph neural networks to identify them from WSI features. The approach achieves 0.718 C-Index for survival prediction and demonstrates explainability by identifying key risk factors like "Invades pelvicaliceal system" as most significant for mortality. The method also shows fairness across gender and race subgroups, with no significant bias detected.

## Method Summary
The framework extracts deep features from whole slide images using foundation models (UNI, CONCH, HIPT, CHIEF), constructs pathological graphs to capture spatial correlations, and trains graph neural networks to identify these concepts. The method processes TCGA-RCC dataset (KIRC, KIRP, KICH) with 775 subjects, extracting 30 binary concepts from pathology reports using GPT-3.5 based on TNM guidelines. Features are extracted from WSI patches using OTSU masking, then aggregated through a GNN with attention-based MIL pooling. The predicted concept probabilities serve as input to a Cox proportional hazards model for survival analysis, with training using Adam optimizer and cosine annealing.

## Key Results
- Achieves 0.718 C-Index for survival prediction using pathological concepts
- Demonstrates explainability by identifying "Invades pelvicaliceal system" as most significant mortality risk factor
- Shows fairness across gender and race subgroups with no significant bias detected
- Identifies "Grade: Nuclear Grade 4" as having highest predictive power among grade-related concepts (AUC=0.825)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Incorporating human-interpretable pathological concepts as a bottleneck enables explainable survival analysis by mapping visual features to clinically meaningful risk factors.
- **Mechanism:** The model predicts predefined pathological concepts from WSI features. These predicted concepts then serve as the sole input for a Cox proportional hazards (CoxPH) model. This architecture forces the model's learned representation to align with these clinical concepts, making the final survival prediction transparent.
- **Core assumption:** The selected concept set is sufficiently comprehensive to capture visual information critical for survival. The foundation models can extract features that meaningfully map to these concepts.
- **Evidence anchors:**
  - [abstract] "The approach...demonstrates explainability by identifying key risk factors like 'Invades pelvicaliceal system' as most significant for mortality."
  - [section] Page 3, Explainable survival analysis: "In contrast, the explainability of pathological concepts allows for a fully transparent decision-making process in survival analysis."
  - [corpus] No direct corpus evidence.

### Mechanism 2
- **Claim:** A Graph Neural Network (GNN) effectively integrates spatial context from whole slide images (WSIs) to identify concepts requiring global information fusion.
- **Mechanism:** The method constructs a graph from WSI patches where nodes are patch-level features and edges represent spatial adjacency. The GNN learns to propagate information across this graph, aggregating local patch features into a global representation necessary for concepts like "Tumor confined to kidney >7 cm."
- **Core assumption:** Spatial adjacency is the most critical relationship for determining target concepts. A simple graph based on adjacency is sufficient to model tissue architecture.
- **Evidence anchors:**
  - [abstract] "...construct pathological graphs to capture spatial correlations, and trained graph neural networks to identify these concepts."
  - [section] Page 5, Specific concept learning performance: "These concepts require global information fusion rather than localized patch-level embeddings, highlighting the effectiveness of our GNN-based approach..."
  - [corpus] No direct corpus evidence.

### Mechanism 3
- **Claim:** Pre-trained pathology foundation models (e.g., UNI, CONCH) provide effective, general-purpose feature representations transferable to the downstream task of pathological concept identification.
- **Mechanism:** The model uses the frozen weights of foundation models to convert raw image patches into high-dimensional feature vectors. These vectors serve as input to the GNN, transferring knowledge learned from large, diverse pathology datasets.
- **Core assumption:** Features learned by foundation models on their pre-training datasets are transferable and relevant to the specific, fine-grained pathological concepts in this kidney cancer study.
- **Evidence anchors:**
  - [abstract] "...we extract deep features from whole slide images using foundation models..."
  - [section] Page 4, Overall concept learning performance: Table 2 shows performance of different foundation models (HIPT, UNI, CONCH, CHIEF), with UNI achieving highest performance.
  - [corpus] Paper 61014 ("Evaluating New AI Cell Foundation Models on Challenging Kidney Pathology Cases...") supports foundation model evaluation in kidney pathology.

## Foundational Learning

- **Concept: Concept Bottleneck Models (CBMs)**
  - **Why needed here:** This is the core architectural principle. Understanding that CBMs force a model to predict human-interpretable intermediate concepts before making a final prediction is essential to grasping how this system achieves explainability.
  - **Quick check question:** Can you explain how a Concept Bottleneck Model differs from a standard end-to-end neural network in terms of its intermediate outputs?

- **Concept: Cox Proportional Hazards (CoxPH) Model**
  - **Why needed here:** The paper uses CoxPH for the final survival analysis step. Understanding that it's a regression model for time-to-event data that assumes a multiplicative effect of covariates (the concepts) on baseline hazard is necessary to interpret the results.
  - **Quick check question:** In the CoxPH model, what does a positive coefficient for a pathological concept indicate about its relationship to patient mortality risk?

- **Concept: Multiple Instance Learning (MIL) in Computational Pathology**
  - **Why needed here:** The paper uses Attention-Based Multiple Instance Learning (ABMIL) for aggregating features. MIL is a standard paradigm in pathology where a slide (bag) has a label, but individual patches (instances) do not.
  - **Quick check question:** In the context of MIL for pathology, what represents a "bag" and what represents an "instance"?

## Architecture Onboarding

- **Component map:** WSI -> Patching -> Foundation Model (Feature Extraction) -> Graph Construction (Nodes=patches, Edges=adjacency) -> GNN (Spatial Aggregation) -> CBM (Concept Prediction) -> Attention-based MIL (Aggregation) -> CoxPH (Survival Prediction)
- **Critical path:**
    1. **Concept Definition:** Define the set of pathological concepts from TNM guidelines and pathology reports using GPT-3.5. This step defines the "labels" for the CBM.
    2. **Feature Extraction:** Use a foundation model (e.g., UNI) to convert raw WSI patches into feature vectors. This is a frozen, pre-processed step.
    3. **Concept Learning GNN:** Train the GNN and CBM layers to predict the multi-label concept set from the WSI graph features. This is the primary training loop.
    4. **Explainable Survival Analysis:** Train a CoxPH model on the *predicted concepts* from the trained CBM. The coefficients of this model provide the explainability.

- **Design tradeoffs:**
    -   **Interpretability vs. Performance:** The bottleneck architecture sacrifices some potential predictive power of a black-box model for the guarantee of interpretability. The paper claims performance is "comparable to black-box models," but this is a tradeoff.
    -   **Foundation Model Choice:** The choice of feature extractor (UNI vs. others) significantly impacts performance (Table 2). UNI is best but may be larger or slower than HIPT.
    -   **Graph Construction:** Using simple adjacency for graph edges is computationally efficient but may miss complex, long-range spatial dependencies in tissue.

- **Failure signatures:**
    -   **Low AUC for certain concepts:** As seen with "Surgical margins free of neoplasm" (Page 5), concepts requiring very localized or specific tissue context not present in patches will fail. This indicates the patch-based graph approach is insufficient for those concepts.
    -   **Overfitting in Survival Model:** If CoxPH is trained on too many concepts with limited data, it may overfit. The paper uses â„“2 regularization to mitigate this.
    -   **Concept Leakage/Redundancy:** The paper notes overlap between some concepts (e.g., grade-related concepts). This can make the model's explanation ambiguous.

- **First 3 experiments:**
    1. **Foundation Model Benchmark:** Reproduce Table 2 by swapping the foundation model (UNI, CONCH, etc.) while keeping the GNN and CBM architecture fixed. This isolates the impact of feature quality.
    2. **Concept Ablation:** Train the survival model by removing the top-performing concept (e.g., "Invades pelvicaliceal system") and observe the drop in C-Index. This quantifies the importance of that concept for survival.
    3. **Graph vs. No-Graph (ABMIL only):** Compare the performance of the full GNN-based model against a model that uses only ABMIL for feature aggregation (skipping the GNN step). This tests the value of the explicit spatial modeling via the graph.

## Open Questions the Paper Calls Out

- **Question:** Does refining the definitions of overlapping pathological concepts (e.g., between grade or renal vein invasion) significantly improve the model's predictive accuracy?
- **Basis in paper:** [explicit] The authors note in Section 3.2 that "There is overlap between some of the concepts... refining these definitions could likely improve performance."
- **Why unresolved:** The current study utilizes the concept set as generated by GPT-3.5 and TNM guidelines without manually resolving semantic overlaps between specific features.
- **What evidence would resolve it:** Ablation studies comparing model performance using the current concept set versus a curated set where overlapping concepts are merged or explicitly redefined.

- **Question:** Can the framework effectively learn concepts that require specific tissue slides (e.g., surgical margins) which are often missing in public datasets?
- **Basis in paper:** [explicit] The paper states that concepts like "Surgical margins free of neoplasm" showed lower performance "attributed to... such concepts require the analysis of very specific tissue slides which may not be available in public datasets."
- **Why unresolved:** The TCGA dataset used for training does not guarantee the presence of slides containing the specific anatomical structures required for every concept.
- **What evidence would resolve it:** Evaluating the model on a purpose-built dataset where slides containing surgical margins are explicitly included and verified for all samples.

- **Question:** To what extent does the potential noise in GPT-3.5 extracted labels limit the upper bound of the model's visual concept learning capability?
- **Basis in paper:** [inferred] The methodology relies on GPT-3.5 to process pathology reports for concept labels (776 out of 947), which may introduce extraction errors that the paper does not quantify or correct.
- **Why unresolved:** The paper assumes the GPT-extracted text labels are reliable ground truth for training the visual GNN, but provides no error analysis of the text extraction process itself.
- **What evidence would resolve it:** A comparison of model convergence and performance when trained on GPT-generated labels versus a gold-standard set of labels manually verified by pathologists.

## Limitations

- **Concept Definition Reliability:** The paper relies on GPT-3.5 to extract 30 pathological concepts from pathology reports, which may introduce errors or inconsistencies that aren't validated against expert pathology review.
- **Graph Construction Details:** While the paper mentions constructing "pathological graphs," it does not specify the exact graph topology or edge construction strategy, making it difficult to assess whether the spatial relationships modeled are optimal.
- **Limited Concept Coverage:** The paper acknowledges that some important concepts may be missing from the 30-concept set, particularly those requiring specialized staining or genetic testing, potentially restricting the model's ability to capture all relevant risk factors.

## Confidence

**High Confidence:** The overall framework architecture and its core components (foundation model feature extraction, GNN-based concept learning, CoxPH survival analysis) are well-specified and reproducible. The performance metrics reported (C-Index of 0.718, fairness across subgroups) are directly measurable from the described methodology.

**Medium Confidence:** The claim of "comparable to black-box models" for survival prediction requires external validation against specific baseline models. While the C-Index of 0.718 is reasonable for this task, direct comparison with state-of-the-art black-box approaches is not provided.

**Low Confidence:** The clinical validity of the model's explanations depends entirely on the accuracy of the concept definitions extracted by GPT-3.5. Without expert validation of these concept labels, the interpretability claims cannot be fully trusted for clinical decision-making.

## Next Checks

1. **Concept Label Validation:** Conduct a blinded review where expert pathologists manually label a subset of 50-100 pathology reports for the 30 concepts and compare these labels against the GPT-3.5 extracted labels. Calculate inter-rater reliability to establish the trustworthiness of the automated concept extraction process.

2. **Edge Construction Sensitivity:** Implement and test multiple graph construction strategies (k-NN with k=3,5,7; radius-based adjacency; Delaunay triangulation) while keeping all other components constant. Compare concept learning performance across these graph variants to identify whether the current unspecified graph topology is optimal.

3. **External Dataset Validation:** Apply the trained model to an independent kidney cancer dataset (e.g., from a different hospital or country) to test generalization. Evaluate both concept prediction accuracy and survival prediction performance to assess whether the model's explanations remain valid and consistent across different populations and imaging protocols.