---
ver: rpa2
title: 'LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs'
arxiv_id: '2511.07379'
source_url: https://arxiv.org/abs/2511.07379
tags:
- temporal
- loretta
- edges
- degree
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces LoReTTA, a low-resource adversarial poisoning
  framework for continuous-time dynamic graphs (CTDGs). The method operates in two
  phases: first, sparsifying the graph by removing high-impact edges using temporal
  importance heuristics, and second, replacing them with strategically sampled negative
  edges while preserving node degrees and temporal plausibility.'
---

# LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs

## Quick Facts
- arXiv ID: 2511.07379
- Source URL: https://arxiv.org/abs/2511.07379
- Reference count: 40
- Key outcome: Introduces LoReTTA, a low-resource adversarial poisoning framework for continuous-time dynamic graphs (CTDGs), achieving 29.47% average performance degradation across four benchmark datasets and four TGNN models.

## Executive Summary
LoReTTA is a novel adversarial poisoning framework designed for continuous-time dynamic graphs (CTDGs). It operates in two phases: first, sparsifying the graph by removing high-impact edges using temporal importance heuristics, and second, replacing them with strategically sampled negative edges while preserving node degrees and temporal plausibility. Evaluated across four benchmark datasets and four state-of-the-art TGNN models, LoReTTA achieves an average performance degradation of 29.47%. It outperforms 11 baseline attacks, evades four leading anomaly detection systems, and remains robust against four defense methods. The approach is computationally efficient, requiring no surrogate models, and adheres to realistic attack constraints.

## Method Summary
LoReTTA employs a two-phase poisoning methodology for CTDGs. In the first phase, it sparsifies the graph by identifying and removing edges with high temporal importance using heuristics that consider edge recency and node activity patterns. In the second phase, it injects strategically sampled negative edges to replace the removed ones, maintaining node degrees and ensuring temporal plausibility. The framework is designed to be computationally efficient, avoiding the need for surrogate models, and operates under realistic attack constraints. It has been evaluated on four benchmark datasets and four TGNN models, demonstrating significant performance degradation while evading state-of-the-art anomaly detection systems and defenses.

## Key Results
- Achieves 29.47% average performance degradation across four benchmark datasets and four TGNN models
- Outperforms 11 baseline attacks in effectiveness
- Evades four leading anomaly detection systems and remains robust against four defense methods
- Computationally efficient, requiring no surrogate models and adhering to realistic attack constraints

## Why This Works (Mechanism)
LoReTTA exploits the temporal nature of CTDGs by strategically removing and replacing edges based on their importance over time. By focusing on high-impact edges and injecting negative ones that preserve node degrees and temporal plausibility, it disrupts the graph's structure without triggering anomaly detection. The two-phase approach ensures that the attack is both effective and stealthy, maintaining computational efficiency by avoiding surrogate models. This method leverages the inherent trade-offs in TGNN models between temporal dynamics and structural integrity, causing significant performance degradation while remaining undetected.

## Foundational Learning

**Continuous-Time Dynamic Graphs (CTDGs)**
Why needed: CTDGs model real-world systems where interactions evolve over time, such as social networks or transportation systems.
Quick check: Verify understanding of how CTDGs differ from static graphs and the importance of temporal information in TGNNs.

**Temporal Importance Heuristics**
Why needed: These heuristics identify edges that have the most significant impact on the graph's structure and model performance over time.
Quick check: Confirm ability to explain how temporal importance is calculated and its role in edge selection for poisoning.

**Negative Edge Injection**
Why needed: Replacing removed edges with negative ones maintains node degrees and temporal plausibility, ensuring the attack remains stealthy.
Quick check: Ensure comprehension of how negative edges are sampled and their impact on graph structure and model performance.

## Architecture Onboarding

**Component Map**
Edge Importance Calculator -> Edge Sparsification Module -> Negative Edge Generator -> Graph Injection Module

**Critical Path**
The critical path involves calculating edge importance, sparsifying the graph by removing high-impact edges, generating negative edges, and injecting them back into the graph. This sequence ensures that the attack is both effective and stealthy, maintaining the graph's structural integrity while disrupting model performance.

**Design Tradeoffs**
The framework balances attack effectiveness with stealth by carefully selecting edges to remove and inject. It trades off between computational efficiency (avoiding surrogate models) and attack strength, ensuring that the attack remains practical and undetected.

**Failure Signatures**
Potential failure modes include:
- Detection by anomaly detection systems due to unusual edge patterns
- Ineffective poisoning if negative edges are not well-distributed or temporally plausible
- Computational overhead if edge importance calculation is not optimized

**3 First Experiments**
1. Test edge importance calculation on a small synthetic CTDG to verify heuristic accuracy
2. Evaluate the impact of edge sparsification on graph structure and model performance
3. Assess the stealthiness of negative edge injection by testing against a simple anomaly detector

## Open Questions the Paper Calls Out
- Scalability of LoReTTA to very large graphs (>100K nodes) and its performance on non-transportation domains
- Impact of the attack on edge-level and graph-level predictions beyond node classification
- Effectiveness of the attack against a wider variety of defense mechanisms
- Practical feasibility of executing the attack without detection in real-world systems

## Limitations
- Evaluation focuses on node-level classification tasks, leaving questions about impact on edge-level or graph-level predictions
- Specific configurations and hyperparameters of anomaly detectors used in evaluation are not fully detailed
- Assumption of knowledge of edge importance heuristics could be a practical limitation in real-world deployments

## Confidence

**High Confidence:**
- The core two-phase poisoning methodology (edge sparsification followed by strategic negative edge injection) is well-defined and experimentally validated
- The computational efficiency claim is supported by the absence of surrogate model requirements

**Medium Confidence:**
- Performance degradation metrics (29.47% average) are based on limited datasets and may not generalize to other domains or larger-scale graphs
- The robustness against defenses needs further validation on more diverse defense mechanisms

**Low Confidence:**
- The practical feasibility of executing the attack without detection in real-world systems is uncertain, given the simplified assumptions about attack constraints and system dynamics

## Next Checks
1. Test LoReTTA on larger-scale CTDGs (>100K nodes) to evaluate scalability limits and computational overhead
2. Evaluate the attack's impact on edge-level and graph-level prediction tasks beyond node classification
3. Conduct ablation studies to quantify the contribution of each heuristic in the edge selection process and test sensitivity to heuristic parameter variations