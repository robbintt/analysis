---
ver: rpa2
title: 'CoRA: Covariate-Aware Adaptation of Time Series Foundation Models'
arxiv_id: '2510.12681'
source_url: https://arxiv.org/abs/2510.12681
tags:
- cora
- forecasting
- series
- time
- covariates
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoRA, a covariate-aware adaptation framework
  for Time Series Foundation Models (TSFMs). The core idea is to leverage frozen foundation
  model backbones as embedding extractors for multi-modal covariates (time series,
  text, images), then apply a Granger Causality Embedding (GCE) to automatically evaluate
  and weight the causal influence of each covariate.
---

# CoRA: Covariate-Aware Adaptation of Time Series Foundation Models

## Quick Facts
- arXiv ID: 2510.12681
- Source URL: https://arxiv.org/abs/2510.12681
- Reference count: 40
- CoRA achieves a 31.1% MSE reduction on covariate-aware forecasting tasks compared to state-of-the-art methods.

## Executive Summary
This paper introduces CoRA, a covariate-aware adaptation framework for Time Series Foundation Models (TSFMs). The core idea is to leverage frozen foundation model backbones as embedding extractors for multi-modal covariates (time series, text, images), then apply a Granger Causality Embedding (GCE) to automatically evaluate and weight the causal influence of each covariate. These weighted embeddings are integrated through a zero-initialized condition-injection mechanism, preserving the pre-trained model's knowledge while progressively incorporating exogenous information. CoRA outperforms state-of-the-art covariate-aware deep forecasters with full or few-shot training samples, demonstrating strong compatibility across various TSFMs and extending to multi-modal covariates.

## Method Summary
CoRA adapts pre-trained TSFMs to incorporate exogenous multi-modal covariates through a frozen backbone approach. The method extracts embeddings from frozen foundation models (TSFM for time series, ViT for images, LLM for text), projects them to a unified space, and applies a Granger Causality Embedding to weight covariates based on their predictive influence. These weighted embeddings are injected into the TSFM head via a zero-initialized Adaptive Layer Normalization (adaLN) module. This design preserves the pre-trained model's knowledge while enabling progressive incorporation of covariate information. The framework is trained end-to-end with all adaptation parameters initialized to zero, ensuring training starts from the pre-trained model's state.

## Key Results
- Achieves 31.1% MSE reduction on covariate-aware forecasting tasks compared to state-of-the-art methods
- Demonstrates strong compatibility across various TSFMs without requiring architectural changes
- Extends to multi-modal covariates (time series, text, images) while maintaining performance gains
- Shows effectiveness with both full and few-shot training samples

## Why This Works (Mechanism)

### Mechanism 1: Frozen Foundation Model Embeddings for Multi-Modal Covariates
- **Claim:** Freezing the pre-trained TSFM backbone and using it as an embedding extractor preserves pre-trained knowledge while producing representations that are more informative than raw covariate data.
- **Mechanism:** CoRA freezes the TSFM backbone (and other modality-specific FMs like ViT for images, Qwen3-Embedding for text). It passes multi-modal covariates through these frozen models to extract embeddings before the last layer. This process is assumed to transfer the powerful representational learning from pre-training to the covariate data without altering the original TSFM's weights, avoiding catastrophic forgetting.
- **Core assumption:** The embeddings extracted from frozen foundation models capture sufficient predictive information about the covariates and are compatible with the TSFM's internal representation space.
- **Evidence anchors:**
  - [abstract] "With preserved backbones of foundation models as frozen feature extractors, the outcome embeddings from foundation models are empirically demonstrated more informative than raw data."
  - [page 4, 3.1] "...extract per-step embeddings from corresponding frozen models..."
  - [corpus] Related work like UniCA (Han et al., 2025) also adapts TSFMs, but CoRA argues UniCA "inject covariate-aware modules that alter the embeddings away from the pre-trained embedding space" [page 2, 1]. TFMAdapter explores "lightweight instance-level adaptation."

### Mechanism 2: Granger Causality Embedding (GCE) for Principled Covariate Selection
- **Claim:** A trainable Granger Causality Embedding (GCE) can automatically and effectively weight covariates based on their causal predictive influence on the target variate, outperforming naive aggregation.
- **Mechanism:** A trainable weight vector $W_{GC}$ is applied to the aligned covariate embeddings. A softmax is applied to produce a probability distribution, which is then multiplied by the embeddings to select and scale them. This is grounded in the concept of Granger causalityâ€”prioritizing covariates that improve prediction error.
- **Core assumption:** A static or learnable global weight per covariate is sufficient to capture the causal influence across time steps and different prediction horizons.
- **Evidence anchors:**
  - [abstract] "CoRA employs a novel Granger Causality Embedding (GCE) to automatically evaluate covariates regarding their causal predictability..."
  - [page 5, 3.2] "...we use Granger Causality Embedding $W_{GC} \in \mathbb{R}^N$ to evaluate and gate each covariate..."
  - [corpus] Direct comparisons in the corpus are limited.

### Mechanism 3: Zero-Initialized Condition-Injection via AdaLN
- **Claim:** Injecting covariate information using a zero-initialized Adaptive Layer Normalization (adaLN) module ensures training starts from the pre-trained model's state, preventing instability and catastrophic forgetting.
- **Mechanism:** The weighted covariate embedding $H$ is passed through a lightweight MLP to generate scaling and shifting parameters. These parameters modulate the target variate's embedding before and after the TSFM head. Crucially, the MLP and projection matrices are zero-initialized. This means at step 0, the injected signal is neutral, and the model's output is identical to the pre-trained TSFM's.
- **Core assumption:** AdaLN is an effective mechanism for fusing continuous conditioning information into a transformer-like architecture.
- **Evidence anchors:**
  - [page 5, 3.2] "...the overall model is identical to the pre-trained TSFM."
  - [corpus] This is contrasted with prior TSFM adaptation methods like ChronosX and AdaPTS which "introduce trainable modules without zero-initialization" [page 2, 1].

## Foundational Learning

- **Concept: Granger Causality**
  - **Why needed here:** This is the theoretical core of CoRA's GCE module. You must understand that Granger causality is about predictive utility (X helps predict Y) rather than philosophical cause-and-effect.
  - **Quick check question:** If two time series are perfectly correlated but one is a lagged version of the other, which one Granger-causes the other, and why would that matter for a forecasting model?

- **Concept: Zero-Initialization & Catastrophic Forgetting**
  - **Why needed here:** This is the central justification for the adaLN module's design. Starting adaptation from a pre-trained state is critical for foundation models to avoid destroying their learned knowledge.
  - **Quick check question:** If you add a new, randomly initialized trainable module to a pre-trained model, what is the initial output of that module likely to be, and how does that affect the first few steps of backpropagation compared to a zero-initialized module?

- **Concept: Foundation Model Adaptation (PEFT)**
  - **Why needed here:** CoRA is an adaptation framework. Understanding the broader context of Parameter-Efficient Fine-Tuning helps frame CoRA's contribution.
  - **Quick check question:** What is the main architectural difference between adapting an LLM with LoRA and adapting a TSFM with CoRA, as highlighted in the paper's introduction?

## Architecture Onboarding

- **Component map:**
  - Target Variate -> Frozen TSFM Backbone -> Target Embedding
  - Covariates (Time Series, Text, Images) -> Frozen Feature Extractors (TSFM/LLM/ViT) -> Modality Embeddings
  - Modality Embeddings -> Projection Layers (Zero-initialized) -> Aligned Embeddings
  - Aligned Embeddings -> Granger Causality Embedding -> Weighted Embedding H
  - Weighted Embedding H -> Zero-initialized MLP -> Modulation Parameters
  - Modulation Parameters + Target Embedding -> AdaLN Module -> Forecast

- **Critical path:**
  1. **Extract & Align:** Pass all inputs through frozen FMs. Project covariate embeddings to a common dimension. **Do not** backpropagate into the frozen FMs.
  2. **Select & Weight:** Compute $H$ using the softmax of $W_{GC}$ multiplied by the aligned embeddings.
  3. **Generate Modulation:** Feed $H$ into the zero-initialized MLP. Ensure the MLP's output starts at zero.
  4. **Modulate & Predict:** Apply the adaLN formula to the TSFM head and generate the forecast.

- **Design tradeoffs:**
  - **Frozen vs. Fine-tunable Backbone:** Frozen for preservation and efficiency. May not adapt well to vast domain shifts.
  - **Zero-Init vs. Standard Init:** Ensures stable start. Might slow down initial learning.
  - **AdaLN vs. Concatenation:** AdaLN is more effective for continuous values but may be less expressive for very complex interactions.

- **Failure signatures:**
  - **Performance degrades:** Likely failed to zero-initialize the projection or MLP layers. Check initialization code.
  - **No improvement over zero-shot:** GCE weights may not be learning, or projection layers are misaligned. Check gradients.
  - **Overfitting on small data:** MLP might be too large. Increase regularization.

- **First 3 experiments:**
  1. **Ablation on Zero-Initialization:** Train the same model but with Xavier initialization for the adaLN MLP and projection layers. Compare MSE/MAE on a benchmark (e.g., EPF).
  2. **Ablation on Covariate Selection:** Replace the GCE mechanism with a simple mean aggregation ($H = \text{Mean}(\hat{E})$). This validates the importance of principled weighting.
  3. **Cross-Modality Test:** Setup a multi-modal experiment (e.g., using the RT-1 or Time-MMD dataset). Run CoRA using only time-series covariates vs. using all modalities. Compare performance to verify the benefit of multi-modal fusion.

## Open Questions the Paper Calls Out

- **Question:** How can temporal dynamics within non-time-series modalities (text and images) be effectively preserved and fused without relying on simple aggregation?
- **Basis in paper:** [Explicit] The Limitations section states: "At present, CoRA applies a simple mean aggregation along the temporal dimension, which inevitably discards fine-grained temporal dynamics... Future work could investigate more sophisticated fusion strategies."
- **Why unresolved:** The current design treats text and image sequences as static snapshots averaged over time, potentially losing critical time-dependent cues present in the auxiliary modalities.
- **What evidence would resolve it:** A comparative study showing that a sequential cross-attention mechanism for multimodal covariates outperforms the mean aggregation strategy on datasets with high temporal variance in image/text content.

- **Question:** Does the Softmax normalization in the Granger Causality Embedding (GCE) constrain the model's ability to utilize multiple independently causal covariates?
- **Basis in paper:** [Inferred] Equation 6 defines the covariate weighting as `Softmax(W_GC)`. This forces the weights to sum to 1, creating a competitive distribution rather than an independent assessment of causal strength.
- **Why unresolved:** In scenarios where multiple covariates have high, independent predictive power (Granger-cause the target), Softmax might force the model to suppress the weight of strong predictors to satisfy the probability distribution.
- **What evidence would resolve it:** An ablation study replacing Softmax with Sigmoid normalization or a raw magnitude weighting, demonstrating improved performance on datasets with many strongly correlated covariates.

- **Question:** To what extent does the freezing of foundation model backbones hinder optimal cross-modal alignment compared to parameter-efficient fine-tuning (PEFT)?
- **Basis in paper:** [Inferred] Section 3.1 explicitly freezes all backbones (TSFM, LLM, Vision) to preserve pre-trained knowledge. However, the embeddings from diverse models may reside in unaligned latent spaces, relying solely on the lightweight projection layers (Eq. 5) for alignment.
- **Why unresolved:** While freezing prevents catastrophic forgetting, it may limit the "expressiveness" of the covariate representations relative to the target time series, potentially leaving performance gains on the table.
- **What evidence would resolve it:** Experiments applying LoRA or Adapter modules to the frozen backbones, comparing the resulting forecast accuracy and training efficiency against the strictly frozen CoRA baseline.

## Limitations

- The zero-initialization design, while theoretically sound for preventing catastrophic forgetting, lacks empirical ablation demonstrating that standard initialization would indeed cause catastrophic forgetting in this specific context.
- The paper claims embeddings from frozen foundation models are "more informative than raw data," but provides limited quantitative evidence comparing frozen embeddings directly against raw data baselines in the same experimental setup.
- The Granger Causality Embedding assumes static, global weights per covariate, which may oversimplify scenarios where covariate influence is highly dynamic or non-linear across time steps and prediction horizons.
- Cross-modal alignment relies on linear projections without explicit attention to potential modality-specific normalization or domain adaptation requirements.

## Confidence

- **High:** The core mechanism of frozen backbone + zero-initialized adaLN for covariate injection is well-founded theoretically and has strong empirical support (31.1% MSE reduction, compatibility across TSFMs).
- **Medium:** The GCE mechanism's effectiveness is demonstrated but could benefit from deeper ablation studies isolating its contribution from other components.
- **Low:** The claim that frozen embeddings are universally "more informative than raw data" lacks direct empirical validation within the paper's experiments.

## Next Checks

1. **Zero-Initialization Ablation:** Train CoRA with standard initialization for the adaLN MLP and projection layers to empirically verify that zero-initialization prevents catastrophic forgetting and improves stability.
2. **GCE Mechanism Isolation:** Replace the Granger Causality Embedding with simple mean aggregation of aligned embeddings to quantify the specific contribution of principled covariate weighting to overall performance.
3. **Modality-Specific Analysis:** Conduct experiments on the RT-1 or Time-MMD datasets to isolate the contribution of each modality (time series, text, images) and validate that multi-modal fusion provides consistent benefits across different covariate types.