---
ver: rpa2
title: Lung Cancer Classification from CT Images Using ResNet
arxiv_id: '2510.16310'
source_url: https://arxiv.org/abs/2510.16310
tags:
- lung
- cancer
- images
- classification
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a deep learning approach using a pre-trained
  ResNet-50 model for multi-class classification of lung cancer from CT images, addressing
  the challenge of limited predictive efficacy in automated lung cancer classification
  systems. The model was adapted with custom layers and fine-tuned on a dataset of
  15,000 lung CT images from the LC25000 histopathological image dataset, achieving
  a test accuracy of 98.8%.
---

# Lung Cancer Classification from CT Images Using ResNet

## Quick Facts
- arXiv ID: 2510.16310
- Source URL: https://arxiv.org/abs/2510.16310
- Reference count: 22
- Primary result: ResNet-50 model achieved 98.8% test accuracy for multi-class lung cancer classification

## Executive Summary
This study presents a deep learning approach using a pre-trained ResNet-50 model for multi-class classification of lung cancer from CT images, addressing the challenge of limited predictive efficacy in automated lung cancer classification systems. The model was adapted with custom layers and fine-tuned on a dataset of 15,000 lung CT images from the LC25000 histopathological image dataset, achieving a test accuracy of 98.8%. The model demonstrated high precision and recall across three classes—benign, adenocarcinoma, and squamous cell carcinoma—with benign tissues perfectly classified. The results represent a notable enhancement over prior models on the same dataset, highlighting the effectiveness of deep learning in distinguishing between benign and malignant lung tissues.

## Method Summary
The study used a pre-trained ResNet-50 model with ImageNet weights, removing the final classification layer and adding custom layers: Dense(128) followed by Dense(3, softmax output). The model was trained on the LC25000 histopathological image dataset (15,000 images, 5,000 per class) split into 10,200 training, 2,550 validation, and 2,250 test images. Training was performed for 18 epochs with early stopping (from 25 max epochs), batch size 25, and learning rate 0.001. The model was implemented in Python 3.5.3 using TensorFlow and Scikit-learn on Google Colab/Kaggle with P100 GPU.

## Key Results
- Achieved 98.8% test accuracy for three-class lung cancer classification
- Perfect classification (100% accuracy) for benign tissues
- High precision and recall across all classes, with benign tissue perfectly classified
- Minimal overfitting observed through training/validation curves

## Why This Works (Mechanism)

### Mechanism 1
Transfer learning from ImageNet pre-training provides effective feature initialization for histopathological image classification. The pre-trained ResNet-50 architecture leverages hierarchical convolutional features learned from 1,000 ImageNet object classes, where early layers capture edges and textures while deeper layers capture abstract patterns. These learned representations transfer to lung tissue classification because low-level visual features (edges, textures, gradients) are shared across domains. This mechanism assumes histopathological tissue patterns share sufficient visual primitives with natural images for transfer to be beneficial.

### Mechanism 2
Residual connections enable effective gradient flow in deep networks, supporting robust feature learning without degradation. Skip connections bypass intermediate layers, allowing gradients to flow directly during backpropagation, which mitigates vanishing gradients in the 50-layer architecture and enables learning of identity mappings when deeper layers don't improve performance. This mechanism assumes deeper representations improve classification discriminability for histopathological patterns.

### Mechanism 3
Benign-malignant tissue structural differences are sufficiently distinct for deep features to achieve near-perfect separation on benign class. The saliency maps reveal that benign tissue feature patterns differ markedly from malignant patterns at the classification layer, while malignant classes (adenocarcinoma, squamous cell carcinoma) share more similar features, causing occasional inter-class confusion. This mechanism assumes histopathological preparation and imaging quality are consistent across classes.

## Foundational Learning

- **Transfer Learning with Pre-trained CNNs**: Why needed here - Understanding why ImageNet weights help medical image classification and knowing what transfers and what requires fine-tuning. Quick check: What layers would you freeze vs. fine-tune if your target dataset has 1,000 images vs. 100,000 images?

- **Multi-class Classification Metrics (Precision, Recall, F1)**: Why needed here - The paper reports per-class metrics; understanding why F1 is preferred over accuracy for imbalanced or high-stakes classification. Quick check: If benign has 100% recall but adenocarcinoma has 90% recall, what does this imply for clinical deployment?

- **Overfitting Detection via Training/Validation Curves**: Why needed here - The paper emphasizes minimal overfitting via curve analysis; early stopping was used at epoch 18 of 25. Quick check: If validation loss starts increasing while training loss decreases, what should you do?

## Architecture Onboarding

- **Component map**: Input (224×224×3) → Lambda preprocessing → ResNet50v2 (frozen backbone, 23.5M params) → Dense(128, activation inferred) → Dense(3, softmax output)

- **Critical path**:
  1. Data loading: Batch size 25, images resized to 224×224
  2. Forward pass through ResNet backbone (pre-trained, frozen initially)
  3. Feature vector (2048-dim) → Dense(128) → Dense(3)
  4. Loss computation, backpropagation (fine-tuning custom layers first)
  5. Early stopping at epoch 18 based on validation performance

- **Design tradeoffs**:
  - Depth vs. overfitting: Deeper backbone improves features but risks overfitting on 15K images; mitigated by transfer learning and early stopping
  - Three-way vs. binary classification: Multi-class provides clinical subtype differentiation but increases confusion between malignant subtypes (17 misclassifications between adenocarcinoma and squamous)
  - Frozen vs. fine-tuned backbone: Paper doesn't specify whether backbone was fully frozen or partially fine-tuned—this affects computational cost and overfitting risk

- **Failure signatures**:
  - High training accuracy with low validation accuracy → overfitting; reduce model capacity or increase regularization
  - Poor benign recall → likely data quality issue or class imbalance not addressed
  - High confusion between malignant subtypes → consider hierarchical classification (benign vs. malignant first, then subtype)

- **First 3 experiments**:
  1. Baseline replication: Reproduce the exact architecture on LC25000 lung subset; verify ~98.8% test accuracy with same train/val/test split
  2. Backbone ablation: Compare frozen backbone vs. partial fine-tuning (last 10-20 layers) vs. full fine-tuning; measure accuracy and training time tradeoffs
  3. Class confusion analysis: Isolate the 17 misclassified malignant samples; visualize saliency maps to understand why adenocarcinoma and squamous confuse; test if data augmentation or class-specific regularization improves separation

## Open Questions the Paper Calls Out

- **Can the adapted ResNet-50 architecture maintain high performance when expanded to include additional lung cancer classes (e.g., Small-cell Lung Carcinoma) and trained on larger datasets?** The current study restricted classification to three specific classes found in the LC25000 dataset, but future works could investigate larger datasets with more cancer classes and types.

- **Does the high test accuracy (98.8%) achieved on the LC25000 dataset translate to clinically acceptable performance on external, real-world CT imaging datasets?** The model was trained and tested exclusively on the LC25000 dataset, which consists of histopathological images, yet the paper frames the problem around CT scans, requiring validation on actual CT data from clinical settings.

- **How does the model's decision-making process align with radiological or pathological features, and can this explainability be improved to assist clinicians?** While saliency maps were generated, the visual similarity of features in the final classification layer suggests the "black box" nature of the model remains a barrier to understanding why specific predictions are made.

## Limitations

- Unclear fine-tuning strategy for backbone layers (frozen vs. partial vs. full fine-tuning)
- Relatively small dataset (15,000 images) for deep learning despite being substantial
- No comparison against contemporary architectures or ensemble methods
- Confusion between malignant subtypes (17 inter-class misclassifications)

## Confidence

- **High Confidence**: Test accuracy of 98.8% with proper train/val/test splits and per-class metrics; benign classification perfection supported by feature maps
- **Medium Confidence**: Transfer learning mechanism's effectiveness assumed from ResNet literature rather than empirically validated in this domain; 17 inter-malignant class confusions documented but not deeply analyzed
- **Low Confidence**: Claims about computational efficiency and exact impact of early stopping lack quantitative support

## Next Checks

1. **Fine-tuning Strategy Validation**: Systematically test three scenarios (frozen backbone, fine-tuning last 20 layers, full fine-tuning) and compare accuracy, training time, and overfitting metrics across all three.

2. **Cross-dataset Generalization**: Evaluate the trained model on an independent lung CT dataset (e.g., LIDC-IDRI or another pathology repository) to verify if the 98.8% accuracy generalizes beyond LC25000.

3. **Malignancy Confusion Analysis**: Conduct targeted experiments with class-specific data augmentation on adenocarcinoma and squamous samples; measure if confusion reduction exceeds 50% while maintaining overall accuracy.