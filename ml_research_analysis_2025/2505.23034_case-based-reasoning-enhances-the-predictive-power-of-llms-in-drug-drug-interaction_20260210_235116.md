---
ver: rpa2
title: Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction
arxiv_id: '2505.23034'
source_url: https://arxiv.org/abs/2505.23034
tags:
- drug
- interaction
- cases
- knowledge
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CBR-DDI, a framework that leverages case-based
  reasoning (CBR) to enhance large language models (LLMs) for drug-drug interaction
  (DDI) prediction. The core idea is to construct a knowledge repository of historical
  DDI cases enriched with pharmacological insights, combining drug associations from
  biomedical knowledge graphs (KGs) and interaction mechanisms distilled by LLMs.
---

# Case-Based Reasoning Enhances the Predictive Power of LLMs in Drug-Drug Interaction

## Quick Facts
- **arXiv ID:** 2505.23034
- **Source URL:** https://arxiv.org/abs/2505.23034
- **Reference count:** 40
- **Primary result:** CBR-DDI improves DDI prediction accuracy by up to 28.7% over baselines without requiring LLM fine-tuning

## Executive Summary
This paper introduces CBR-DDI, a novel framework that enhances large language models (LLMs) for drug-drug interaction (DDI) prediction by integrating case-based reasoning (CBR). The approach constructs a knowledge repository of historical DDI cases enriched with pharmacological insights from biomedical knowledge graphs and LLM-extracted interaction mechanisms. CBR-DDI employs a hybrid retrieval mechanism combining semantic and structural similarity to find relevant cases, then uses dual-layer knowledge-enhanced prompting to guide LLM reasoning. The framework demonstrates state-of-the-art performance on DrugBank and TWOSIDES datasets, achieving significant accuracy improvements while maintaining interpretability and flexibility without requiring LLM fine-tuning.

## Method Summary
CBR-DDI operates by first building a knowledge repository of historical DDI cases, enriched with pharmacological insights extracted from biomedical knowledge graphs and LLM-generated interaction mechanisms. When predicting new drug interactions, the framework uses a hybrid retrieval mechanism that combines semantic similarity (based on drug embeddings) with structural similarity (from knowledge graph connections) to identify relevant historical cases. These retrieved cases are then incorporated into dual-layer knowledge-enhanced prompts that guide the LLM's reasoning process, combining case-specific insights with general pharmacological knowledge. The framework is designed to work with off-the-shelf LLMs without requiring any fine-tuning, making it both flexible and interpretable.

## Key Results
- Achieves up to 28.7% improvement in accuracy over baseline models
- Demonstrates state-of-the-art performance on DrugBank and TWOSIDES datasets
- Maintains high interpretability through case-based reasoning approach
- Achieves results without requiring LLM fine-tuning

## Why This Works (Mechanism)
The framework leverages the complementary strengths of case-based reasoning and large language models. CBR provides access to a rich repository of historical drug interaction cases with detailed pharmacological context, while LLMs excel at reasoning over complex relationships and generating novel insights. By combining semantic and structural similarity in retrieval, CBR-DDI can find cases that are both topically relevant and connected through known drug relationships. The dual-layer prompting mechanism ensures that both case-specific details and broader pharmacological knowledge inform the LLM's predictions, leading to more accurate and interpretable results than either approach alone.

## Foundational Learning
- **Case-Based Reasoning (CBR)**: Why needed - to leverage historical drug interaction cases; Quick check - framework uses retrieved cases to inform predictions
- **Biomedical Knowledge Graphs**: Why needed - to capture structural relationships between drugs; Quick check - KG associations are part of case enrichment
- **Hybrid Retrieval Mechanism**: Why needed - to find both semantically and structurally similar cases; Quick check - combines drug embeddings with KG connections
- **Dual-Layer Knowledge-Enhanced Prompting**: Why needed - to incorporate both case-specific and general knowledge; Quick check - guides LLM reasoning with multiple knowledge sources
- **LLM-Based Mechanism Extraction**: Why needed - to distill interaction mechanisms from complex pharmacological data; Quick check - enriches cases with LLM-generated insights
- **Drug-Drug Interaction Prediction**: Why needed - critical for medication safety and clinical decision-making; Quick check - evaluated on established DDI datasets

## Architecture Onboarding

**Component Map:**
Drug Pair Input -> Hybrid Retrieval -> Case Selection -> Dual-Layer Prompting -> LLM Prediction -> Output

**Critical Path:**
Drug Pair Input -> Hybrid Retrieval (semantic + structural similarity) -> Top-K Case Selection -> Dual-Layer Prompt Construction -> LLM Inference -> DDI Prediction Output

**Design Tradeoffs:**
The framework prioritizes interpretability and flexibility over raw computational efficiency. By avoiding LLM fine-tuning, it maintains generalizability but may sacrifice some performance gains possible with task-specific adaptation. The hybrid retrieval mechanism adds complexity but improves case relevance compared to single-modality approaches.

**Failure Signatures:**
- Poor retrieval quality leading to irrelevant case selection
- LLM misinterpreting pharmacological context in prompts
- Knowledge graph incompleteness affecting structural similarity calculations
- Overreliance on historical cases when novel interactions occur

**First Experiments:**
1. Baseline comparison: Evaluate against standard LLM predictions without CBR enhancement
2. Retrieval ablation: Compare hybrid retrieval against semantic-only and structural-only approaches
3. Prompting ablation: Test single-layer versus dual-layer knowledge-enhanced prompting

## Open Questions the Paper Calls Out
None

## Limitations
- Performance improvements based on comparisons with potentially limited baseline models
- Hybrid retrieval mechanism may face scalability challenges with larger drug repositories
- LLM-based mechanism extraction may introduce variability in case enrichment quality
- Limited evaluation of generalizability to rare or previously unseen drug combinations

## Confidence

**High Confidence:**
- Core methodology combining CBR with LLMs is technically sound
- Experimental validation on established datasets (DrugBank and TWOSIDES)
- Well-defined architecture with clear components and interactions

**Medium Confidence:**
- Interpretability claims supported by architecture but not extensively validated in clinical settings
- Flexibility advantage over fine-tuning approaches is theoretically sound
- Performance gains impressive but baseline comparisons may not represent full state-of-the-art

## Next Checks
1. Evaluate CBR-DDI's performance on rare or previously unseen drug combinations to assess generalizability beyond training distributions
2. Conduct ablation studies to quantify individual contributions of knowledge graph associations versus LLM-extracted mechanisms
3. Implement real-time case retrieval benchmarks to assess practical scalability with larger drug repositories