---
ver: rpa2
title: 'QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging
  Inverse Problems'
arxiv_id: '2507.14760'
source_url: https://arxiv.org/abs/2507.14760
tags:
- uncertainty
- quantile
- qutcc
- prediction
- conformal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QUTCC improves uncertainty quantification for imaging inverse problems
  by learning a full conditional quantile distribution and applying non-uniform, nonlinear
  conformal calibration. Unlike prior methods that scale fixed quantile bounds linearly,
  QUTCC trains a U-Net with a quantile embedding to predict arbitrary quantiles, enabling
  tighter, adaptive uncertainty intervals.
---

# QUTCC: Quantile Uncertainty Training and Conformal Calibration for Imaging Inverse Problems

## Quick Facts
- **arXiv ID**: 2507.14760
- **Source URL**: https://arxiv.org/abs/2507.14760
- **Reference count**: 38
- **Primary result**: QUTCC produces smaller uncertainty intervals while maintaining statistical coverage for imaging inverse problems.

## Executive Summary
QUTCC is a method for uncertainty quantification in imaging inverse problems that combines quantile regression with conformal calibration. The method learns a full conditional quantile distribution using a shared-weight U-Net architecture conditioned on a quantile parameter, then applies iterative conformal calibration to adjust prediction bounds. Unlike prior approaches that scale fixed quantile bounds linearly, QUTCC independently optimizes lower and upper quantile parameters to achieve target coverage while minimizing interval width.

## Method Summary
QUTCC trains an Attention U-Net to predict arbitrary quantiles of the conditional distribution of ground truth images given noisy measurements. The network takes both the noisy image and a quantile parameter $q \in (0,1)$ as inputs, with $q$ encoded using sinusoidal positional encoding similar to diffusion models. Training uses the pinball loss to optimize for specific quantiles sampled uniformly during training. After training, conformal calibration independently searches for optimal quantile parameters to achieve target coverage on a held-out calibration set. The method can also estimate pixel-wise probability density functions by differentiating the learned quantile function.

## Key Results
- QUTCC achieves smaller uncertainty intervals than prior methods while maintaining statistical coverage on synthetic Gaussian and Poisson denoising tasks
- The method successfully identifies hallucinations and out-of-distribution regions in real-noise denoising and MRI reconstruction tasks
- QUTCC estimates pixel-wise probability density functions without requiring Gaussian assumptions

## Why This Works (Mechanism)

### Mechanism 1: Simultaneous Quantile Regression via Shared Weights
A single network conditioned on a quantile value can approximate the full conditional distribution of an image. The model learns a mapping $f_\theta(y, q)$ where $q$ is an input embedding. During training, $q$ is sampled uniformly and the network is optimized using the Pinball Loss, forcing the shared weights to learn the geometry of the uncertainty distribution around the mean image. Core assumption: network capacity is sufficient to model monotonicity across $q$. Break condition: underfitting causes quantile crossing where lower quantile predictions exceed upper ones.

### Mechanism 2: Iterative, Asymmetric Conformal Calibration
Adaptive, non-linear scaling of bounds produces tighter intervals than linear scaling. QUTCC performs binary search over the quantile input space to find optimal values $q^*_{lower}$ and $q^*_{upper}$ independently to satisfy the risk $\alpha$. Because bounds are found independently, the resulting interval is asymmetric and tight to the specific noise shape. Core assumption: the calibration dataset is exchangeable with the test data. Break condition: if the calibration set is too small or non-representative, the searched $q^*$ values will fail to provide target coverage.

### Mechanism 3: Derivative-based Density Recovery
The learned quantile function can be differentiated to approximate a pixel-wise probability density function without Gaussian assumptions. By querying the trained network at multiple $q$ values, one constructs the inverse CDF. The derivative $\frac{\partial \hat{x}}{\partial q}$ represents the rate of change of pixel intensity across probability mass, and the probability density is the reciprocal of this derivative. Core assumption: the quantile function is smooth enough for finite difference approximation. Break condition: if the noise distribution is extremely complex or multi-modal and quantile sampling resolution is too low, the derivative approximation fails.

## Foundational Learning

- **Concept**: **Quantile Regression & Pinball Loss**
  - **Why needed here**: Standard regression minimizes MSE (mean). To know uncertainty (variance/tails), you must optimize for specific percentiles. Pinball loss is the core mathematical tool that forces a model to output a specific quantile.
  - **Quick check question**: If $q=0.9$ and the model predicts $\hat{x} > x$, does the loss penalize heavily or lightly? (Answer: Lightly, or specifically $(1-q)$ weight, because we want the 90th percentile to be an overestimate 90% of the time).

- **Concept**: **Conformal Prediction (Risk Control)**
  - **Why needed here**: Raw neural network uncertainty estimates are usually uncalibrated. Conformal prediction uses a calibration set to mathematically guarantee coverage regardless of the model architecture.
  - **Quick check question**: What happens to the prediction interval width if we require a higher confidence level (e.g., moving from $\alpha=0.1$ to $\alpha=0.01$)? (Answer: The interval must widen to ensure the ground truth is captured more often).

- **Concept**: **Conditional Neural Networks (FiLM/Embeddings)**
  - **Why needed here**: Standard U-Nets map $y \to x$. QUTCC maps $(y, q) \to x$. Understanding how to inject a scalar $q$ into a deep network is necessary to implement the "Simultaneous Quantile" architecture.
  - **Quick check question**: Why use a sinusoidal embedding for $q$ instead of just concatenating the scalar? (Answer: It allows the network to learn high-frequency variations in the quantile function more easily, similar to positional encodings in Transformers).

## Architecture Onboarding

- **Component map**: Inputs (Measurement Image $y$ + Scalar Quantile $q \in (0,1)$) -> Attention U-Net Backbone -> Sinusoidal Quantile Embedding Layer -> Output (Reconstructed Image $\hat{x}_q$)
- **Critical path**:
  1. During training, sample random $q$ per batch
  2. Encode $q$ to vector $e_q$
  3. Inject $e_q$ into U-Net down/upsampling blocks
  4. Compute Pinball Loss $L_q(x, \hat{x})$
  5. Run Algorithm 1 on calibration set adjusting $q_{lower}/q_{upper}$ to hit risk $\alpha$
- **Design tradeoffs**:
  - Inference Speed vs. Richness: To get a single uncertainty interval, you need 2 forward passes ($q_{lower}, q_{upper}$). To get a full PDF, you need $N$ passes. This is slower than a single-pass ensemble but faster than training multiple models.
  - Shared Weights: Using one network for all quantiles ensures non-crossing better than independent networks but makes the optimization landscape more complex.
- **Failure signatures**:
  - Quantile Crossing: Visualizing $\hat{x}_{0.1} > \hat{x}_{0.9}$. Suggests network capacity is too low or learning rate is too high.
  - Constant Bounds: If the uncertainty map is constant regardless of input, the quantile embedding might not be properly connected to the attention layers (ablation check).
  - Under-coverage: If test risk $\gg \alpha$, the calibration set likely violates exchangeability (different noise distribution than test set).
- **First 3 experiments**:
  1. Sanity Check (Synthetic Gaussian): Train on Gaussian noise. Check if $q=0.5$ output matches MSE output, and if recovered PDFs match the Gaussian bell curve.
  2. Crossing Analysis: Plot intensity vs. quantile for a single pixel. Verify the curve is monotonic (non-decreasing).
  3. Calibration Sweep: Vary the size of the calibration set $N_c$. Plot "Interval Width" vs. "Calibration Set Size" to see how much data is needed to stabilize the bounds.

## Open Questions the Paper Calls Out
- Can QUTCC be extended to quantify uncertainty across multiple measurements or temporal frames to handle sample movement? The authors state this would be an interesting future direction.
- How robust is the conformal calibration when the test distribution deviates from the calibration distribution (distribution shift)? The authors identify distribution shifts as an interesting future direction.
- Can the training procedure be adapted to function without paired ground truth data? The authors note that paired data may not be available in many applications.

## Limitations
- The method requires paired data for both training and conformal calibration steps, which may not be available in many applications
- The calibration set must be exchangeable with the test data for coverage guarantees to hold
- No systematic study of calibration set size vs. interval stability is presented

## Confidence
- **Quantile Regression with Pinball Loss**: High confidence. Well-grounded in prior work with explicit mathematical formulation
- **Adaptive Conformal Calibration**: Medium confidence. Clearly defined but real-world efficacy depends on calibration set representativeness
- **PDF Recovery via Derivatives**: Low confidence. Relies on smooth quantile functions but no analysis provided for multi-modality or derivative instability

## Next Checks
1. **Quantile Crossing Test**: During validation, monitor the frequency and magnitude of quantile crossing events. Report crossing rates across noise levels to quantify distribution shape fidelity.
2. **Calibration Set Size Sweep**: Systematically vary the calibration set size $N_c$ and measure interval width stability and coverage accuracy. Plot these metrics to identify minimum $N_c$ for reliable calibration.
3. **Derivative-Based PDF Robustness**: For synthetic multi-modal noise, compare recovered PDFs against ground truth using metrics like KL divergence. Test sensitivity to quantile sampling resolution and finite-difference step size.