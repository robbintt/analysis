---
ver: rpa2
title: 'Towards One-shot Federated Learning: Advances, Challenges, and Future Directions'
arxiv_id: '2505.02426'
source_url: https://arxiv.org/abs/2505.02426
tags:
- learning
- one-shot
- federated
- data
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: One-shot federated learning (One-shot FL) addresses the communication
  overhead challenge in traditional federated learning by enabling model training
  in a single round of communication. This survey systematically examines the methodologies,
  challenges, and future directions of One-shot FL, highlighting its potential for
  resource-constrained and privacy-sensitive applications.
---

# Towards One-shot Federated Learning: Advances, Challenges, and Future Directions

## Quick Facts
- arXiv ID: 2505.02426
- Source URL: https://arxiv.org/abs/2505.02426
- Reference count: 40
- One-shot federated learning addresses communication overhead in traditional FL by enabling model training in a single communication round

## Executive Summary
One-shot federated learning (One-shot FL) represents a paradigm shift in federated learning by addressing the critical challenge of communication overhead through single-round model training. This comprehensive survey systematically examines methodologies, challenges, and future directions of One-shot FL, highlighting its potential for resource-constrained and privacy-sensitive applications. The paper provides a structured framework covering optimization algorithms, knowledge distillation-based ensemble methods, data heterogeneity, and adversarial robustness, while analyzing 79 relevant papers to identify critical research gaps and opportunities.

## Method Summary
The survey employs a systematic literature review methodology, analyzing 79 papers to synthesize the current state of One-shot FL research. It categorizes existing approaches into optimization-based methods, knowledge distillation techniques, and ensemble aggregation strategies. The analysis framework examines technical challenges including data heterogeneity, privacy preservation, adversarial robustness, and scalability. The paper also provides open-source codes and benchmark datasets to facilitate research reproducibility and validation across different application domains.

## Key Results
- One-shot FL enables model training through single-round communication, significantly reducing communication overhead compared to traditional multi-round FL
- Data-free approaches using synthetic data generation and ensemble aggregation techniques show promise for addressing data heterogeneity challenges
- Critical challenges remain in privacy-accuracy trade-offs, scalability, and developing standardized benchmarks for evaluating One-shot FL approaches

## Why This Works (Mechanism)
One-shot FL works by fundamentally restructuring the federated learning process to eliminate iterative communication rounds. Instead of repeatedly exchanging model updates between central servers and clients, One-shot FL aggregates knowledge in a single round through techniques like knowledge distillation, ensemble methods, and synthetic data generation. This approach leverages the complementary strengths of local client models while minimizing communication costs, making it particularly suitable for resource-constrained environments and applications requiring rapid deployment.

## Foundational Learning
- Federated Learning Basics: Understanding distributed model training without centralized data sharing is essential for grasping One-shot FL's communication optimization goals
- Knowledge Distillation: This technique enables model compression and transfer of knowledge from multiple local models to a global model in a single round
- Privacy-Preserving Techniques: Differential privacy, homomorphic encryption, and secure aggregation methods are critical for maintaining data confidentiality in One-shot settings
- Data Heterogeneity Management: Synthetic data generation and data-free approaches address the challenge of non-IID data distributions across clients
- Adversarial Robustness: Ensuring model security against attacks in the single-round communication constraint requires specialized defensive mechanisms

## Architecture Onboarding
- Component Map: Local Clients -> Model Training -> Knowledge Aggregation -> Global Model
- Critical Path: The single communication round between local training and global aggregation represents the most critical sequence where optimization and privacy mechanisms must function effectively
- Design Tradeoffs: Accuracy vs. communication efficiency, privacy vs. model utility, and computational cost vs. performance represent the primary balancing decisions
- Failure Signatures: Significant accuracy drops, privacy breaches, or model convergence failures typically indicate issues in the single-round aggregation process or inadequate handling of data heterogeneity
- First Experiments: 1) Benchmark One-shot FL against traditional FL on standard datasets measuring communication rounds and accuracy, 2) Test privacy-preserving mechanisms under simulated adversarial attacks, 3) Evaluate synthetic data generation approaches for handling non-IID data distributions

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can auditing or verification techniques be designed to operate effectively in One-shot FL with only limited device data and a single communication round?
- Basis in paper: Section 6.1.1 asks, "How to design auditing or verification techniques that can operate effectively with only limited device data in a single round of training?"
- Why unresolved: Traditional verification relies on centralized datasets or multi-round testing, which are incompatible with the strict single-round constraint of One-shot FL.
- What evidence would resolve it: A framework capable of validating model reliability and generalization using only local data or synthetic proxy data within a single interaction.

### Open Question 2
- Question: Can privacy-preserving aggregation methods (e.g., homomorphic encryption) or regularization techniques be applied in One-shot FL without significantly sacrificing model utility?
- Basis in paper: Section 6.1.4 explicitly asks, "can we leverage privacy-preserving aggregation methods... without sacrificing model utility? Furthermore, can regularization techniques... be selectively applied?"
- Why unresolved: Current methods like differential privacy introduce noise that severely degrades model performance in the single-round setting, creating a steep accuracy cost for privacy guarantees.
- What evidence would resolve it: Empirical results demonstrating that a new aggregation method maintains competitive accuracy (e.g., minimal performance drop) while satisfying strict privacy guarantees in a one-shot setting.

### Open Question 3
- Question: How can federated optimization algorithms be designed to combine physical constraints (e.g., PDEs/ODEs) for Scientific Machine Learning within the One-shot FL framework?
- Basis in paper: Section 6.3.3 suggests the "potential value of fusion is that it can design federated optimization algorithms that combine physical constraints."
- Why unresolved: Integrating physical laws into distributed learning usually requires iterative refinement; adapting this for a single round while ensuring predictions conform to physical laws is unexplored.
- What evidence would resolve it: Successful training of Physics-Informed Neural Networks (PINNs) across decentralized scientific data using a single-shot communication protocol.

## Limitations
- Analysis of 79 papers may not capture the complete landscape of rapidly evolving One-shot FL research
- Effectiveness of proposed methodologies is primarily evaluated through theoretical analysis and limited empirical studies
- Challenges in benchmarking and reproducibility exist despite provision of open-source codes and datasets

## Confidence
- High: The identification of communication overhead as a critical challenge in traditional FL and the potential of One-shot FL to address this issue is well-established in the literature
- Medium: The proposed frameworks for data-free approaches and ensemble aggregation techniques show promise but require more extensive validation across diverse application domains
- Medium: The analysis of privacy-accuracy trade-offs is theoretically sound but needs empirical validation with real-world datasets and privacy attacks

## Next Checks
1. Conduct systematic experiments comparing One-shot FL approaches against traditional FL across multiple datasets and model architectures to quantify the communication efficiency gains and accuracy trade-offs
2. Implement and test the proposed privacy-preserving mechanisms against state-of-the-art adversarial attacks in federated settings to validate their robustness claims
3. Evaluate the scalability of One-shot FL methods in realistic IoT and satellite communication scenarios with network constraints and device heterogeneity