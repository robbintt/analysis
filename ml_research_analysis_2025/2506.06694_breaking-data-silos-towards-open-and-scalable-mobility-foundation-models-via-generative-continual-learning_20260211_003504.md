---
ver: rpa2
title: 'Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models
  via Generative Continual Learning'
arxiv_id: '2506.06694'
source_url: https://arxiv.org/abs/2506.06694
tags:
- mobility
- data
- learning
- movegcl
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of training mobility foundation
  models in the presence of data silos, privacy constraints, and heterogeneous urban
  datasets. It proposes MoveGCL, a generative continual learning framework that enables
  collaborative model evolution across distributed data holders without exchanging
  raw data.
---

# Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning

## Quick Facts
- arXiv ID: 2506.06694
- Source URL: https://arxiv.org/abs/2506.06694
- Reference count: 40
- Primary result: MoveGCL achieves performance on par with centralized joint training for mobility foundation models while preserving data privacy.

## Executive Summary
This paper addresses the challenge of training mobility foundation models in the presence of data silos, privacy constraints, and heterogeneous urban datasets. It proposes MoveGCL, a generative continual learning framework that enables collaborative model evolution across distributed data holders without exchanging raw data. MoveGCL uses synthetic trajectory replay from a frozen teacher model, knowledge distillation, a mobility-pattern-aware Mixture-of-Experts (MoE) architecture, and layer-wise progressive adaptation to retain prior knowledge and adapt to new cities. Evaluated on six global urban datasets, MoveGCL achieves performance on par with centralized joint training, demonstrating robustness to data order and strong privacy preservation. The method provides a scalable, privacy-preserving pathway toward Open Mobility Science, enabling cross-institutional AI collaboration for urban sustainability.

## Method Summary
MoveGCL is a generative continual learning framework for training mobility foundation models across distributed data silos. The approach uses a frozen teacher model to generate synthetic trajectories that approximate historical data distributions, which are then mixed with real data from new cities for training a student model. The framework employs a mobility-pattern-aware Mixture-of-Experts (MoE) architecture that routes trajectory patterns to specialized experts based on handcrafted mobility features (jump distance, waiting time, radius of gyration, city ID). A layer-wise progressive adaptation strategy gradually unfreezes model layers from outer to inner positions to preserve generalizable knowledge while adapting to new urban domains. The model is trained using cross-entropy loss on new data combined with knowledge distillation loss on synthetic replay data.

## Key Results
- MoveGCL achieves accuracy parity with centralized joint training across six US cities (Atlanta, Chicago, Los Angeles, New York, Seattle, Washington D.C.)
- The framework demonstrates robustness to data order, maintaining performance regardless of training sequence
- Layer-wise progressive adaptation prevents catastrophic forgetting, while full fine-tuning fails to retain prior knowledge
- MoE architecture with mobility-aware routing effectively handles urban heterogeneity without increasing computational cost linearly

## Why This Works (Mechanism)

### Mechanism 1: Generative Replay for Non-IID Continual Learning
The framework retains a copy of the model from the previous round as a "teacher." When learning a new city, the teacher generates pseudo-trajectories conditioned on the temporal structure of new data but the spatial semantics of old data. These are mixed with real new data to create the training set. This allows the student model to learn current-city behaviors while retaining knowledge. If the generative capacity of the teacher degrades significantly for sparse or complex mobility patterns, the synthetic data will introduce noise, causing the student model to "forget" by learning from corrupted historical distributions.

### Mechanism 2: Mobility-Pattern-Aware Mixture-of-Experts (MoE)
Instead of routing tokens based solely on hidden states, MoveGCL computes a routing weight using a composite vector containing jump distance, waiting time, radius of gyration, and city ID. This directs similar trajectory patterns to specific experts regardless of the city of origin. If sampling rates or data quality vary drastically between cities, engineered features like "waiting time" may become inconsistent, leading to erratic routing where experts fail to specialize effectively.

### Mechanism 3: Layer-Wise Progressive Adaptation
The training epochs are divided into stages. In Stage 1, only the input/output MoE blocks are unfrozen. Subsequent stages progressively unfreeze the central blocks. This allows the model to adjust high-level abstractions first while preserving low-level feature extractors until later. If the new city's mobility logic contradicts the base model's fundamental pre-training, restricting updates to outer layers may limit the model's ability to fit the new data, resulting in underfitting.

## Foundational Learning

- **Concept: Catastrophic Forgetting**
  - Why needed here: This is the central problem MoveGCL solves. In sequential training, optimizing for City B typically degrades performance on City A because the weights relevant to City A are overwritten.
  - Quick check question: Can you explain why standard fine-tuning fails when training on a sequence of non-stationary datasets?

- **Concept: Knowledge Distillation**
  - Why needed here: MoveGCL uses KL-divergence loss to force the new "student" model to mimic the probability distribution of the old "teacher" model on synthetic data. This is the mathematical guard against forgetting.
  - Quick check question: How does minimizing the KL-divergence between Teacher and Student outputs differ from standard cross-entropy loss on ground-truth labels?

- **Concept: Mixture of Experts (MoE) Scaling**
  - Why needed here: To scale to hundreds of cities without a linear increase in computation, the model activates only a sparse subset of parameters (experts) per trajectory.
  - Quick check question: In an MoE layer, how does the "Top-K" gating mechanism balance computational efficiency with model capacity?

## Architecture Onboarding

- **Component map:** Trajectory Sequence -> Unified Location Encoder (POI + Heat + LatLon) + Mobility Encoder (Feature vector) -> MoE Transformer Blocks (Router conditions on mobility features) -> Deep & Cross Network (DCN) Decoder

- **Critical path:** The Mobility-Aware Router. It is the bridge between the heterogeneous input features and the sparse expert backbone. If the feature embeddings are not normalized or learned correctly, the routing collapses, and experts fail to specialize.

- **Design tradeoffs:**
  - Replay Volume: Paper suggests 20%. Lowering this risks forgetting; increasing it risks biasing the model towards old data and slowing convergence on new cities.
  - Freezing Strategy: The paper argues for progressive unfreezing. A standard "unfreeze all" approach results in the "MoveGCL (FullTune)" failure mode shown in results.

- **Failure signatures:**
  - Collapse of Diversity: If generated trajectories loop or lack diversity, the distillation loss will collapse the student model into a trivial solution.
  - Routing Imbalance: If >80% of inputs route to a single expert, the MoE benefits are lost, and the model reverts to a dense Transformer behavior.

- **First 3 experiments:**
  1. Teacher-Student Fidelity: Run the generative replay loop on a single hold-out city. Measure the KL-divergence between Teacher and Student on synthetic data vs. real data to verify the proxy quality.
  2. Routing Visualization: Visualize expert activation maps for different cities (e.g., New York vs. Los Angeles). Verify that specific experts correlate with specific mobility features (e.g., "short trips" expert vs. "commuter" expert).
  3. Ablation on Progressive Adaptation: Compare "Unfreeze All at Once" vs. "Layer-wise" on a sequence of 3 cities. Plot the accuracy drop on City 1 after training on City 3 to quantify the forgetting rate.

## Open Questions the Paper Calls Out
None

## Limitations
- The model's generalization to radically different urban contexts (developing-world cities with informal transport, cities with multimodal dominance like cycling) remains untested.
- The core assumption that synthetic trajectories from a frozen teacher adequately represent historical data is plausible but not rigorously validated through distributional similarity tests.
- The computational and routing complexity of adding experts for hundreds of cities is not empirically demonstrated, raising concerns about scalability.

## Confidence

- **High Confidence:** The core mechanism of using generative replay with knowledge distillation to mitigate catastrophic forgetting is well-established in continual learning literature. The empirical results showing performance parity with centralized training are robust within the tested domain (US cities with automobile-centric mobility).

- **Medium Confidence:** The layer-wise progressive adaptation strategy is logically sound and shows empirical benefit, but the specific schedule (outer-to-inner layer unfreezing) lacks direct corpus validation for mobility models.

- **Low Confidence:** The mobility-pattern-aware MoE routing's reliance on handcrafted features (jump distance, waiting time, radius of gyration) as universal descriptors of travel behavior is the weakest link, as these features may not generalize across cities with vastly different transport modes.

## Next Checks

1. **Cross-Cultural Generalization Test:** Evaluate MoveGCL on a dataset from a non-US city with significantly different transport modes (e.g., Amsterdam for cycling dominance, Tokyo for high-density rail usage). Measure performance drop and analyze expert routing behavior to identify feature scaling issues.

2. **Generative Replay Quality Audit:** Implement a distributional similarity test comparing real vs. synthetic trajectories. Compute KL divergence and Wasserstein distance for key mobility statistics (trip length distributions, temporal patterns). Identify thresholds below which replay quality degrades model performance.

3. **Large-Scale Scalability Simulation:** Design a synthetic experiment simulating continual learning on 100+ cities. Track expert utilization rates, routing entropy, and computational overhead. Identify the point at which the MoE router's sparsity benefits are lost due to routing collapse or feature embedding degradation.