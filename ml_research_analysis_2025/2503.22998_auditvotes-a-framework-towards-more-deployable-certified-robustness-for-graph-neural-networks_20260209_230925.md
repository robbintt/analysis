---
ver: rpa2
title: 'AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph
  Neural Networks'
arxiv_id: '2503.22998'
source_url: https://arxiv.org/abs/2503.22998
tags:
- graph
- accuracy
- certified
- smoothing
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AuditVotes addresses the accuracy-robustness trade-off in certifiably
  robust Graph Neural Networks (GNNs) by introducing a framework that combines augmentation
  and conditional smoothing with randomized smoothing. The augmentation component
  de-noises randomized graphs through graph rewiring techniques, while the conditional
  smoothing uses prediction confidence to filter low-quality votes, improving both
  data quality and prediction consistency.
---

# AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks

## Quick Facts
- arXiv ID: 2503.22998
- Source URL: https://arxiv.org/abs/2503.22998
- Reference count: 40
- Key outcome: AuditVotes significantly improves clean accuracy by 437.1% and certified accuracy by 409.3% on Cora-ML when defending against edge insertion attacks

## Executive Summary
AuditVotes addresses the accuracy-robustness trade-off in certifiably robust Graph Neural Networks (GNNs) by introducing a framework that combines augmentation and conditional smoothing with randomized smoothing. The augmentation component de-noises randomized graphs through graph rewiring techniques, while the conditional smoothing uses prediction confidence to filter low-quality votes, improving both data quality and prediction consistency. Experimental results show that AuditVotes significantly improves clean accuracy by 437.1% and certified accuracy by 409.3% on Cora-ML when defending against edge insertion attacks, while maintaining high computational efficiency and broad applicability across different smoothing schemes and datasets.

## Method Summary
AuditVotes is a framework that wraps around randomized smoothing for GNNs. It consists of three main components: (1) augmentation pre-processing that de-noises randomized graphs through graph rewiring techniques, (2) a base GNN classifier that predicts labels on the augmented graphs, and (3) conditional smoothing that filters low-confidence predictions before majority voting. The augmentation predicts edge existence from node features using methods like Jaccard similarity, auto-encoders, or multi-head attention, then applies adaptive thresholds to prune spurious edges and recover missing edges. The conditional smoothing discards predictions with confidence below a threshold, improving voting consistency and strengthening certification bounds.

## Key Results
- Clean accuracy improved by 437.1% on Cora-ML with edge insertion attacks
- Certified accuracy improved by 409.3% on Cora-ML with edge insertion attacks
- Outperforms state-of-the-art baselines in both clean and certified accuracy across Cora-ML, Citeseer, and PubMed datasets

## Why This Works (Mechanism)

### Mechanism 1: Noise-Adaptive Graph Rewiring Augmentation
The augmentation pre-processing recovers clean graph structure from randomized noise, restoring data quality without compromising certification. It predicts edge existence from node features and applies adaptive thresholds to prune spurious edges and recover missing edges. The number of edges to add/remove is estimated from noise parameters using expected graph sparsity.

### Mechanism 2: Confidence-Based Conditional Smoothing
Filtering low-confidence predictions before voting improves prediction consistency, which directly strengthens certification bounds. The filtering function discards predictions with confidence ≤ θ, ensuring only valid votes participate in majority voting. This increases the probability gap between top-class and runner-up classes, widening the certified radius.

### Mechanism 3: Certified Robustness Preservation Under Conditional Filtering
The theoretical guarantees survive augmentation and filtering because the likelihood ratio between clean and perturbed distributions is unaffected by the filtering function. The filter doesn't change which region a sample falls into—only whether it's counted. The linear programming certification is adapted to work with conditional probabilities.

## Foundational Learning

- **Randomized Smoothing**: Why needed: The entire framework wraps around randomized smoothing. Quick check: Given a base classifier f and noise distribution ϕ, can you write the definition of the smoothed classifier g and explain why g is robust?

- **Graph Structure and Homophily**: Why needed: Augmentation methods rely on node feature similarity to predict edges. Homophily assumption underlies JacAug, FAEAug, and SimAug effectiveness. Quick check: For a citation network, would you expect high or low homophily? How does random edge addition affect homophily?

- **Certification via Linear Programming**: Why needed: Theorem 1 reduces certification to an LP problem. Understanding the vectors s, t and how they encode worst-case classifiers is essential for debugging certification failures. Quick check: In the LP formulation, what do the vectors s and t represent? Why does μ_ra,rb > 0 guarantee robustness?

## Architecture Onboarding

- **Component map:** Input Graph G -> Randomization ϕ(G) [adds noise with p+, p−] -> Augmentation A(·) [JacAug / FAEAug / SimAug] -> Base Classifier f [GCN / APPNP] -> Confidence Filter h(·) [threshold θ] -> Majority Voting [valid votes only] -> Certification [Theorem 1 LP]

- **Critical path:** Pre-compute edge intensity matrix once per test graph, set adaptive thresholds using Equations 14-15 based on p+, p− and training sparsity, draw N randomized graphs, apply augmentation, run classifier, filter by confidence threshold θ, compute p_A, p_B via Clopper-Pearson bounds, solve LP for μ_ra,rb.

- **Design tradeoffs:** JacAug vs FAEAug vs SimAug (free vs trained but captures complex patterns), confidence threshold θ (higher → fewer but higher-quality votes), noise levels p+, p− (higher noise → larger certified radius but lower clean accuracy).

- **Failure signatures:** OOM error (high p+ creates dense graphs), abstain (N_v too low from aggressive filtering), low certified accuracy despite high clean accuracy (p_A - p_B gap too small), certification fails on edge addition (augmentation may not recover from added spurious edges).

- **First 3 experiments:** 1) Reproduce baseline: Run SparseSmooth with GCN on Citeseer with (p+=0.2, p−=0.6). Confirm clean accuracy ~14.7%. 2) Ablate augmentation only: Add SimAug (no confidence filter). Expect clean accuracy ~70%+, certified accuracy improvement ~400%. 3) Full AuditVotes: Add confidence filter with θ=0.2. Expect marginal improvement in certified accuracy with negligible runtime overhead.

## Open Questions the Paper Calls Out

- **Can the performance of AuditVotes be further improved by developing more sophisticated, adaptive architectures for the augmentation and filtering components?** The paper suggests exploring more advanced designs of augmentation methods and filtering functions, as current implementations are described as "simple yet effective strategies."

- **How does AuditVotes maintain robustness and theoretical certification when the attacker is capable of perturbing node features in addition to the graph structure?** The current framework assumes static feature matrix X, but feature poisoning could theoretically degrade the augmenter's ability to de-noise the graph.

- **Can the augmentation and smoothing components be trained in an end-to-end manner to directly optimize the certified radius?** The current two-stage training approach may result in a sub-optimal trade-off between graph reconstruction quality and final model's certified robustness.

## Limitations

- Framework performance is sensitive to hyperparameter tuning (thresholds τ, ξ, and θ) which may not generalize across different graph domains without careful calibration
- Augmentation component may fail when node features are uninformative for edge prediction or graphs have low homophily
- Confidence filtering assumes high-confidence predictions are genuinely more robust, which may not hold if base classifier is systematically overconfident on incorrect predictions

## Confidence

- **High confidence:** Theoretical foundation for conditional smoothing preserving certification guarantees (Theorem 1)
- **Medium confidence:** Empirical improvements in clean accuracy (437.1% on Cora-ML) and certified accuracy (409.3%)
- **Low confidence:** Generalization of results to other graph types and attack scenarios beyond edge insertion

## Next Checks

1. **Cross-dataset validation:** Test AuditVotes on datasets with varying homophily levels (e.g., Texas, Cornell) to assess robustness when node features poorly predict edge existence

2. **Ablation on confidence filter:** Compare certified accuracy with and without confidence filtering across multiple confidence threshold values to quantify marginal benefit and identify optimal θ ranges

3. **Adversarial filtering attack:** Evaluate whether an adaptive adversary can manipulate confidence scores to bypass filtering mechanism, potentially undermining certification guarantees