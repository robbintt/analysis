---
ver: rpa2
title: 'Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect on
  Human-Like Agenda Generation'
arxiv_id: '2503.19752'
source_url: https://arxiv.org/abs/2503.19752
tags:
- agents
- task
- personality
- agent
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SANDMAN, an architecture using Large Language
  Models (LLMs) to generate human-like behavior in deceptive agents for cybersecurity.
  It proposes a method to induce personality traits based on the five-factor model
  (OCEAN) into LLMs, which influences task planning and behavior generation.
---

# Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect on Human-Like Agenda Generation

## Quick Facts
- arXiv ID: 2503.19752
- Source URL: https://arxiv.org/abs/2503.19752
- Reference count: 13
- Personality induction via OCEAN traits significantly affects LLM task planning outputs (5–7 tasks with p ≤ 0.05 deviations)

## Executive Summary
This paper introduces SANDMAN, an LLM-based architecture for generating human-like deceptive agents in cybersecurity honeypots. The system induces personality traits based on the five-factor OCEAN model to influence task planning and behavior generation. Experimental results demonstrate that induced personality traits produce statistically significant deviations in task duration and frequency across multiple conditions, with Conscientiousness increasing work task duration by approximately 20 minutes. These findings validate that personality-driven LLMs can produce diverse, contextually rich behaviors for improved cyber deception strategies.

## Method Summary
The SANDMAN architecture employs a modular memory system (semantic, episodic, procedural, working) with a Decision Engine coordinating task generation. Personality traits are induced using combined "naive + words-based" prompt schemas that prime LLMs with trait descriptors. The Bootstrap Task generates schedules using randomized task lists passed through GPT-3.5-Turbo at Temperature=0.7. The Machine Personality Inventory (MPI) validates trait induction by measuring trait scores against neutral baselines. The system currently uses static scheduling but proposes future dynamic replanning capabilities.

## Key Results
- Personality induction via combined prompt schemas produced statistically significant MPI scores (p ≤ 0.05) across all OCEAN traits
- Induced Conscientiousness increased work task duration from 63.9 minutes to 85.1 minutes with reduced variance
- Each personality condition showed 5–7+ tasks with statistically significant deviations in frequency (p ≤ 0.05)
- Bootstrap Task randomization achieved task-position correlation (ρ) of 0.43 with system message, indicating adequate randomization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured OCEAN-based prompts induce statistically measurable personality effects in LLM task planning outputs.
- Mechanism: Combined "naive + words-based" prompt schema ("Imagine you are a/an X person characterised by being Y") primes LLM's latent behavioral associations, propagating through schedule generation.
- Core assumption: LLMs encode sufficient personality-behavior correlations from pre-training data for OCEAN traits to systematically influence planning outputs.
- Evidence anchors: MPI validation shows p ≤ 0.05 scores vs. control; SAC framework confirms generalizability across LLMs.

### Mechanism 2
- Claim: Induced personality traits produce statistically significant deviations in task duration and frequency across at least 5–7 tasks per condition.
- Mechanism: Bootstrap Task passes personality-primed prompts with randomized task lists to GPT-3.5-Turbo, biasing duration/frequency decisions.
- Core assumption: Temperature=0.7 preserves sufficient stochasticity for personality effects to emerge without collapsing into deterministic outputs.
- Evidence anchors: Positive Conscientiousness increased Work task duration from 63.9m to 85.1m; each condition showed 5–7+ tasks with p ≤ 0.05 deviations.

### Mechanism 3
- Claim: Modular memory architecture enables persistent, context-aware behavior across decision cycles.
- Mechanism: Semantic memory stores profiles; episodic memory logs decisions; working memory maintains active context; Decision Engine grounds each planning cycle.
- Core assumption: Memory retrieval provides sufficient context for LLMs to maintain consistent behavioral patterns across sessions.
- Evidence anchors: Architecture diagram shows interconnected memory modules; limited corpus evidence for this specific integration.

## Foundational Learning

- Concept: Five-Factor Model (OCEAN) personality traits
  - Why needed here: Understanding which traits map to which behavioral changes is essential for designing effective deceptive personas.
  - Quick check question: Which OCEAN trait would you induce to make an agent schedule more frequent breaks and personal time?

- Concept: LLM prompting strategies (naive vs. words-based vs. combined)
  - Why needed here: The paper's prompt schema combines both approaches; knowing when each is effective helps refine persona induction.
  - Quick check question: Why might "You are conscientious" (naive) alone produce weaker effects than adding trait descriptors like "organized, disciplined, thorough"?

- Concept: CoALA cognitive architecture framework
  - Why needed here: SANDMAN is explicitly CoALA-inspired; understanding memory types clarifies component roles.
  - Quick check question: Which memory type stores the agent's personality profile, and which stores yesterday's task decisions?

## Architecture Onboarding

- Component map: Bootstrap Task -> LLM API -> Task List -> Decision Engine -> Generators -> Channels
- Critical path: Bootstrap Task (PlanScheduleTask) → LLM generates schedule → Task List populated → Decision Engine selects task → Generator creates content → Channel executes in environment
- Design tradeoffs: Static scheduling vs. dynamic replanning; single-agent isolation vs. multi-agent interaction; Temperature tuning (0.7 balances variance vs. coherence)
- Failure signatures: High task-position correlation (ρ > 0.6) indicates insufficient randomization; MPI scores failing p ≤ 0.05 indicate weak induction; rejected schedules (>10 per 500) suggest prompt-template issues
- First 3 experiments:
  1. Replicate Table 1 MPI validation on a different LLM (e.g., Llama 3) to confirm schema transferability
  2. Vary Temperature (0.3, 0.5, 0.7