---
ver: rpa2
title: Optimizing delivery for quick commerce factoring qualitative assessment of
  generated routes
arxiv_id: '2510.08671'
source_url: https://arxiv.org/abs/2510.08671
tags:
- delivery
- routing
- routes
- language
- vehicle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of optimizing last-mile delivery
  in India's rapidly growing e-commerce market, where routes generated by conventional
  Vehicle Routing Problem (VRP) solvers often produce suboptimal results due to unstructured
  addresses, incomplete maps, and computational constraints. The research proposes
  a novel framework that uses Large Language Models (LLMs) to qualitatively evaluate
  VRP-generated routes against policy-based criteria, allowing logistics operators
  to identify and prioritize more efficient delivery plans.
---

# Optimizing delivery for quick commerce factoring qualitative assessment of generated routes

## Quick Facts
- arXiv ID: 2510.08671
- Source URL: https://arxiv.org/abs/2510.08671
- Authors: Milon Bhattacharya; Milan Kumar
- Reference count: 6
- Primary result: LLM-based route evaluation achieves 79% accuracy (open-source) to 86% accuracy (proprietary) in identifying operationally problematic delivery routes

## Executive Summary
This study addresses the challenge of optimizing last-mile delivery in India's rapidly growing e-commerce market, where routes generated by conventional Vehicle Routing Problem (VRP) solvers often produce suboptimal results due to unstructured addresses, incomplete maps, and computational constraints. The research proposes a novel framework that uses Large Language Models (LLMs) to qualitatively evaluate VRP-generated routes against policy-based criteria, allowing logistics operators to identify and prioritize more efficient delivery plans. Experiments using 400 synthetically generated routes showed that open-source LLMs achieved 79% accuracy in identifying routing issues, while proprietary reasoning models reached up to 86% accuracy. The results demonstrate that LLM-based evaluation can serve as an effective and scalable layer of assessment beyond traditional distance and time metrics, with significant implications for improving cost efficiency, delivery reliability, and sustainability in last-mile logistics.

## Method Summary
The framework generates synthetic delivery routes in Bengaluru using OpenStreetMap data, clustering delivery points and solving VRP problems with Google OR Tools using crow-flying distance approximations. Routes are visualized as images overlaid on OSM basemaps, then evaluated by vision-language models (via Ollama) against four binary policy questions about geographic constraints (water bodies, railway crossings, pedestrian areas, parks/forests). A secondary LLM (Mixtral-8x7B) parses the unstructured outputs into standardized format, which are compared against human-annotated ground truth. The approach tests both open-source models (gemma3:12b) and proprietary reasoning models to quantify the trade-off between accuracy and computational cost.

## Key Results
- Open-source LLMs identified routing issues with 79% accuracy using 38.4s inference time per route
- Proprietary reasoning models achieved up to 86% accuracy with 60s inference time
- Model size showed inconsistent correlation with performance, suggesting architectural factors beyond parameter count drive accuracy
- Batch processing of four policy questions per image provided computational efficiency without significant accuracy loss
- Quantized models suffered from spatial differentiation failures, particularly with closely spaced route and geographic features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-modal LLMs can identify practical routing issues that conventional VRP solvers miss by evaluating route images against natural language policy criteria.
- Mechanism: The system renders VRP-generated routes as visual overlays on OpenStreetMap basemaps, then prompts vision-language models to answer binary questions about route feasibility (e.g., "Does the route cross a water body?"). The LLM's visual reasoning capability detects spatial conflicts that distance-matrix optimization cannot capture.
- Core assumption: LLMs trained on general image datasets possess sufficient geospatial reasoning to interpret map symbology and spatial relationships, even without specialized cartographic training.
- Evidence anchors:
  - [abstract]: "open-source LLMs identified routing issues with 79% accuracy, while proprietary reasoning models achieved reach upto 86%"
  - [section 6.5]: Lists four evaluation questions (water body, railway crossing, pedestrian area, park/forest) derived from grounded theory survey of 20 delivery riders
  - [corpus]: Limited direct corpus support; neighbor papers focus on VRP optimization algorithms rather than LLM-based evaluation
- Break condition: Fails when map resolution is insufficient for feature identification, or when route segments are too spatially close for smaller models to differentiate (see Figure 7 where mistral-small3.2 incorrectly identifies railway intersection)

### Mechanism 2
- Claim: Conventional VRP solvers produce operationally suboptimal routes when distance matrices rely on approximations that ignore real-world geographic constraints.
- Mechanism: VRP solvers optimize against a distance matrix typically computed using crow-flying or approximate road distances. These approximations cannot encode qualitative constraints like "avoid pedestrian zones" or "minimize railway crossings," producing routes that are mathematically optimal but practically inefficient.
- Core assumption: The distance matrix is the critical bottleneck—computational constraints prevent exhaustive pairwise distance calculation across large delivery volumes, forcing approximations that lose ground-truth spatial information.
- Evidence anchors:
  - [abstract]: "effectiveness in real-world scenarios is limited due to unstructured addresses, incomplete maps, and computational constraints in distance estimation"
  - [section 2]: "large volume of orders prohibits exhaustive pair-wise distance calculation, which in turn require approximations for finding the distances"
  - [section 7.0.1]: "In our experiments, the use of line/crow-flying distance was used to create the distance matrix. The resulting order fulfillment schedule looked in-efficient, when reviewed by human annotators"
  - [corpus]: Neighbor papers address VRP optimization but do not challenge the fundamental distance-matrix limitation
- Break condition: When map data is complete with all constraints pre-encoded, or when delivery volumes are small enough to permit exhaustive distance computation

### Mechanism 3
- Claim: Open-source quantized models can achieve practical route evaluation accuracy (>70%) on commodity hardware, enabling scalable deployment without proprietary API dependencies.
- Mechanism: The framework uses locally-hosted models via Ollama with 25GB GPU memory budget. Despite quantization-induced information loss, models like gemma3:12b achieve 79% accuracy by leveraging transferable visual reasoning from general pre-training.
- Core assumption: The marginal accuracy gain from larger proprietary models (86% vs. 79%) may not justify the cost and latency for production use cases where "good enough" screening is valuable.
- Evidence anchors:
  - [Table 2]: gemma3:12b achieves 0.79 accuracy with 38.4s inference time vs. GPT-5 at 0.86 accuracy with 60s inference
  - [section 8.0.2]: Acknowledges quantization error and that "model's ability to differentiate between closely spaced features reduces as model size decreases"
  - [section 8.0.3]: "models with higher inference time tend to produce higher accuracy. However, the correspondence of model size with its performance on our task does not show a clear trend"
  - [corpus]: No corpus papers specifically address quantization trade-offs for geospatial LLM tasks
- Break condition: When fine-grained spatial differentiation is critical (e.g., distinguishing adjacent parallel roads vs. crossing paths), smaller models fail disproportionately

## Foundational Learning

- Concept: Vehicle Routing Problem (VRP) fundamentals
  - Why needed here: The entire framework presupposes understanding that VRP is NP-hard, requires distance matrices, and produces mathematically optimal but not necessarily operationally feasible solutions
  - Quick check question: Can you explain why a route minimizing total distance might still be operationally problematic?

- Concept: Multi-modal vision-language model architectures
  - Why needed here: The mechanism relies on understanding how images are tokenized (tiles → embeddings), how vision and text embeddings are fused (early vs. late fusion), and why quantization affects spatial reasoning
  - Quick check question: What is the difference between early and late fusion in vision-language models, and how might this affect map interpretation?

- Concept: Quantization and knowledge distillation trade-offs
  - Why needed here: Paper explicitly uses quantized/distilled models and documents performance degradation; understanding this helps set realistic accuracy expectations
  - Quick check question: Why would a 7B quantized model perform worse than a 12B quantized model on spatial reasoning tasks, even if both fit in the same GPU memory?

## Architecture Onboarding

- Component map:
  1. Data Generation Layer: OpenStreetMap (Bengaluru) → Cluster sampling (K≈20,000 clusters, n=10-20 delivery points) → Location selection
  2. Route Generation Layer: Google OR Tools VRP solver → Distance matrix (crow-flying approximation) → Routing order output
  3. Visualization Layer: OSMX library → Driving directions → Route overlay on basemap → PNG image export
  4. Evaluation Layer: Vision-language model (via Ollama) → Policy question prompts → Binary classification per question
  5. Post-processing Layer: Mixtral-8x7B response parser → Structured output extraction → Accuracy comparison against human labels

- Critical path:
  Route quality depends on **both** (1) VRP optimization accuracy AND (2) LLM evaluation accuracy. A false negative in LLM evaluation allows a bad route to proceed; a false positive rejects a viable route. The 79-86% accuracy range suggests ~15-20% of routes will be misclassified, requiring human-in-the-loop verification for production.

- Design tradeoffs:
  - Model size vs. latency: gemma3:12b (38s) vs. llama3.2-vision (117s)—2x slower for 2x worse accuracy
  - Batched vs. sequential questions: Paper batches 4 questions per image to save token budget; unbatched would increase accuracy but multiply inference time by ~4x
  - Open-source vs. proprietary: 7 percentage point accuracy gain (79%→86%) at cost of API dependency and data egress
  - Image resolution vs. inference cost: Higher resolution improves small-feature detection but increases token count and latency

- Failure signatures:
  1. Map symbology confusion: Railway lines shown as single vs. double hatched lines cause inconsistent detection (Figure 6)
  2. Spatial proximity errors: Closely spaced route and railway line confused by smaller models (Figure 7)
  3. Output format inconsistency: LLMs return unstructured text, JSON, or markdown unpredictably, requiring secondary parsing model
  4. Inference time blowout: Some models (llama3.2-vision) take >100s per route, unsuitable for batch processing of large delivery volumes

- First 3 experiments:
  1. Reproduce baseline with single open-source model: Pull gemma3:12b via Ollama, generate 10 routes from provided GitHub dataset, run evaluation prompts, compare accuracy against provided labels to validate environment setup
  2. Ablate question batching: Compare accuracy when asking 4 questions separately vs. batched on same 10 routes to quantify token-budget vs. accuracy trade-off
  3. Test failure mode triggers: Generate synthetic routes with known conflicts (route visibly crossing water body in high-contrast rendering) vs. edge cases (route within 50m of railway but not crossing) to map precision/recall boundaries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the qualitative feedback provided by LLMs be utilized to automatically refine and improve the route generation process itself?
- Basis in paper: [explicit] The conclusion states that future research should explore "methods to use LLM feedback to directly refine and improve the route generation process itself."
- Why unresolved: The current study focused on using LLMs as a post-hoc evaluation layer to critique pre-generated routes, rather than integrating them into the solver's optimization loop.
- What evidence would resolve it: An experiment demonstrating that LLM critiques can modify VRP constraints or objective functions to yield routes with higher operational feasibility scores without manual intervention.

### Open Question 2
- Question: Does the LLM evaluation framework maintain its effectiveness when applied to real-time operational data rather than synthetic datasets?
- Basis in paper: [explicit] The conclusion suggests expanding the framework by "testing with real-time operational data."
- Why unresolved: The current validation was performed on 400 synthetically generated routes created using OpenStreetMap to ensure replicability, which may not capture the full complexity of live logistics environments.
- What evidence would resolve it: Successful deployment and accuracy measurement of the framework using live data streams from active delivery fleets.

### Open Question 3
- Question: What is the precise trade-off between model size (quantization/distillation) and the visual reasoning capability required to identify specific geospatial features like railway lines?
- Basis in paper: [explicit] The authors note in the limitations that smaller models suffer from quantization errors and state, "In subsequent studies we would attempt to quantify this trade-off between model size and performance."
- Why unresolved: The study observed that smaller models often hallucinate features (e.g., confusing route intersections with railway lines) but did not define the minimum model parameters required for reliable geospatial reasoning.
- What evidence would resolve it: A benchmark study plotting model parameter counts against accuracy scores for specific map symbology tasks.

## Limitations
- Map rendering quality and symbology significantly impact model accuracy, with inconsistent detection of railway lines based on map styling
- Secondary parsing model required to handle unstructured LLM outputs introduces additional complexity and potential failure points
- Current evaluation uses synthetic data rather than real-world delivery scenarios, limiting generalizability to operational environments
- Quantization errors in smaller models cause spatial reasoning failures, particularly for closely spaced geographic features

## Confidence

- **High confidence**: The fundamental mechanism of using vision-language models to detect geographic constraints beyond distance optimization is well-supported by the experimental results and logical framework
- **Medium confidence**: The quantitative accuracy claims (79% for open-source, 86% for proprietary models) are methodologically sound but may not generalize across regions or map providers
- **Medium confidence**: The cost-benefit analysis of open-source vs. proprietary models is reasonable but lacks comprehensive latency and accuracy trade-off data across diverse operational scenarios
- **Low confidence**: The paper's claims about sustainability improvements through route optimization lack direct empirical validation

## Next Checks

1. **Geographic generalization test**: Replicate the evaluation pipeline using OSM data from a different urban region (e.g., European or North American city) to assess accuracy degradation and identify map-specific failure modes
2. **Quantization ablation study**: Systematically compare quantized vs. full-precision model performance on spatially challenging cases (closely spaced features, ambiguous symbology) to quantify the true cost of deployment efficiency
3. **Human-in-the-loop workflow validation**: Measure the actual time and accuracy improvement when integrating LLM evaluation into existing logistics operations, including false positive/negative handling overhead and operational impact on delivery efficiency