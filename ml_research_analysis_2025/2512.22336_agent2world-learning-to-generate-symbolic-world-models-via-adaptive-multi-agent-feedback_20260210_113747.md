---
ver: rpa2
title: 'Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent
  Feedback'
arxiv_id: '2512.22336'
source_url: https://arxiv.org/abs/2512.22336
tags:
- self
- state
- world
- action
- reward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AGENT2WORLD introduces a multi-agent framework that generates symbolic
  world models through interactive execution. The approach addresses the challenge
  of training LLMs for world model generation, where correctness is behavioral and
  verifiable supervision is scarce.
---

# Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback

## Quick Facts
- arXiv ID: 2512.22336
- Source URL: https://arxiv.org/abs/2512.22336
- Reference count: 40
- Primary result: Achieves 30.95% F1 score improvement on world model generation through multi-agent interactive feedback

## Executive Summary
AGENT2WORLD introduces a multi-agent framework that generates symbolic world models through interactive execution. The approach addresses the challenge of training LLMs for world model generation, where correctness is behavioral and verifiable supervision is scarce. The framework uses three specialized agents: a Deep Researcher for knowledge synthesis, a Model Developer for implementation, and a Testing Team for adaptive evaluation through unit tests and simulation. This interactive loop exposes behavior-level errors that static validation misses.

The framework achieves state-of-the-art performance across three benchmarks, improving F1 scores by 30.95% after fine-tuning on multi-turn training trajectories generated through verifier-guided rejection sampling. This demonstrates that interactive feedback can effectively train more capable world model generators. The approach bridges the gap between static verification and behavioral correctness in symbolic world model generation.

## Method Summary
AGENT2WORLD employs a multi-agent framework where specialized agents collaborate to generate and validate symbolic world models. The Deep Researcher synthesizes relevant knowledge, the Model Developer implements executable code, and the Testing Team conducts adaptive evaluation through unit tests and simulations. The framework uses verifier-guided rejection sampling to generate high-quality training trajectories from multi-turn interactions. This interactive execution-based approach exposes behavioral errors that traditional static validation misses, enabling more robust world model generation.

## Key Results
- Achieves 30.95% F1 score improvement after fine-tuning on multi-turn training trajectories
- State-of-the-art performance across three benchmarks in symbolic world model generation
- Demonstrates effectiveness of interactive multi-agent feedback in training world model generators

## Why This Works (Mechanism)
The framework succeeds by creating a behavioral verification loop that traditional static methods cannot achieve. Interactive execution reveals subtle errors in world models that only manifest during actual use, such as incorrect causal relationships or missing edge cases. The multi-agent structure allows specialization where each agent can focus on its core competency - knowledge synthesis, implementation, or testing - while the adaptive feedback mechanism continuously refines the generated models based on behavioral evidence rather than just syntactic correctness.

## Foundational Learning

**Symbolic World Models**: Formal representations of how systems behave using logical rules and relationships. Needed because it provides the structured knowledge representation that can be executed and tested. Quick check: Can the model represent cause-effect relationships that can be programmatically verified.

**Interactive Execution**: Running generated models in simulated environments to observe actual behavior. Needed because static analysis cannot capture all behavioral nuances. Quick check: Does the model behave correctly under various test scenarios.

**Verifier-Guided Rejection Sampling**: Selective generation of training examples based on quality verification. Needed because high-quality training data is crucial for fine-tuning performance. Quick check: Are generated examples behaviorally correct and diverse.

## Architecture Onboarding

**Component Map**: Deep Researcher -> Model Developer -> Testing Team -> Feedback Loop -> Model Improvement

**Critical Path**: Knowledge synthesis → Code implementation → Behavioral testing → Error identification → Model refinement

**Design Tradeoffs**: Specialization vs. coordination overhead; interactive feedback vs. computational cost; behavioral verification vs. static validation speed

**Failure Signatures**: Incorrect causal relationships in world models; missing edge cases in test scenarios; coordination failures between agents; computational bottlenecks in interactive loops

**3 First Experiments**:
1. Verify Deep Researcher can synthesize accurate knowledge for simple domain
2. Test Model Developer's ability to convert symbolic knowledge to executable code
3. Validate Testing Team's capacity to identify behavioral errors in basic world models

## Open Questions the Paper Calls Out
The paper acknowledges several open questions regarding the generalizability of the framework beyond tested symbolic domains, the scalability of the adaptive multi-agent feedback mechanism to more complex knowledge bases, and the practical deployment viability given computational and verification requirements.

## Limitations
- Limited evaluation to three specific benchmarks raises questions about performance on more complex, real-world world models
- Framework's dependence on high-quality synthetic training data may limit applicability in domains where verification is difficult or ambiguous
- Computational overhead of maintaining multiple specialized agents may impact practical deployment, though not explicitly addressed in evaluation

## Confidence
- High confidence: Framework's ability to generate executable symbolic world models and achieve measurable F1 score improvements on tested benchmarks
- Medium confidence: Scalability of multi-agent feedback mechanism to more complex domains and larger knowledge bases
- Medium confidence: Practical deployment viability given computational and verification requirements

## Next Checks
1. Test AGENT2WORLD on open-world, less structured domains to evaluate robustness beyond controlled benchmarks
2. Conduct ablation studies isolating the contribution of each agent (Deep Researcher, Model Developer, Testing Team) to quantify their individual impact
3. Measure computational efficiency and resource requirements at scale to assess practical deployment constraints