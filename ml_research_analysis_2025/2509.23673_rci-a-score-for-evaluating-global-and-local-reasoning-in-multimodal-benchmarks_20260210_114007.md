---
ver: rpa2
title: 'RCI: A Score for Evaluating Global and Local Reasoning in Multimodal Benchmarks'
arxiv_id: '2509.23673'
source_url: https://arxiv.org/abs/2509.23673
tags:
- reasoning
- dataset
- benchmarks
- global
- patch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Region Comprehension Index (RCI), a novel
  metric designed to evaluate whether multimodal benchmarks assess global or local
  visual reasoning. RCI works by comparing a model's performance on full images versus
  image patches of varying granularities (2x2 and 3x3 splits).
---

# RCI: A Score for Evaluating Global and Local Reasoning in Multimodal Benchmarks

## Quick Facts
- arXiv ID: 2509.23673
- Source URL: https://arxiv.org/abs/2509.23673
- Reference count: 40
- Key outcome: RCI reveals most multimodal benchmarks favor localized reasoning and exhibit central spatial biases

## Executive Summary
The Region Comprehension Index (RCI) is a novel metric that evaluates whether multimodal benchmarks require global or local visual reasoning by comparing model performance on full images versus image patches. When applied to 13 widely-used benchmarks, RCI revealed that most favor localized reasoning and exhibit significant central spatial biases. This suggests many current benchmarks may not adequately test the global reasoning needed for real-world applications like autonomous driving or medical imaging. RCI provides practitioners with an actionable tool for diagnosing and mitigating these biases, enabling the construction of more robust, enterprise-ready multimodal datasets and benchmarks aligned with actual deployment needs.

## Method Summary
RCI computes Maximum Patch Performance (MPP) by evaluating each patch independently and taking the best result, then compares it to Full Image Performance (FIP). The formula RCI_n = 1 - (MPP_n / FIP) yields positive values when full images outperform patches (global reasoning required) and negative values when patches match or exceed full-image performance (local shortcuts available). The framework also analyzes spatial bias by computing per-patch contribution fractions to generate heatmaps showing which image regions dominate task success.

## Key Results
- Most multimodal benchmarks exhibit RCI values indicating strong local reasoning bias (RCI ≤ -0.30)
- Central image regions (e.g., Patch 5 in 3x3 grids) consistently dominate model performance across benchmarks
- Cross-model RCI correlations are high (r ≥ 0.91), demonstrating robustness across architectures
- RCI effectively identifies datasets requiring global reasoning (ChartQA, GQA) versus those allowing local shortcuts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Patch-level performance comparison reveals whether tasks require global integration or can be solved with localized cues.
- Mechanism: RCI computes Maximum Patch Performance (MPP) by evaluating each patch independently and taking the best result, then compares it to Full Image Performance (FIP). The formula RCI_n = 1 - (MPP_n / FIP) yields positive values when full images outperform patches (global reasoning required) and negative values when patches match or exceed full-image performance (local shortcuts available).
- Core assumption: If a task genuinely requires integrating information across an image, no single patch should enable high performance. Conversely, if localized cues suffice, the best patch should perform comparably to the full image.
- Evidence anchors:
  - [abstract] "RCI systematically compares reference-model performance on image patches versus full images, revealing if tasks require holistic image understanding or can be solved with partial or localized visual cues."
  - [section 3.2] "RCI_n = 1 - MPP_n / FIP" and "If MPP_n is much less than FIP, the tasks in the dataset needs information from multiple regions (global reasoning). If MPP_n is close or more to FIP, the tasks in the dataset can be solved well with individual patches (localized reasoning)."
  - [corpus] Weak direct corpus support; related work on multimodal reasoning (DriveLMM-o1, TangramPuzzle) addresses spatial reasoning evaluation but uses different methodological approaches.
- Break condition: If FIP falls below chance threshold (chance + Δ_min), RCI becomes uninterpretable and should not be applied.

### Mechanism 2
- Claim: Central spatial biases in benchmarks can be systematically detected through patch-wise contribution analysis.
- Mechanism: For each patch position across the dataset, the framework computes the fraction of total correct predictions originating from that patch when evaluated in isolation. Systematic overrepresentation of central patches (e.g., Patch 5 in 3×3 grids) indicates benchmark design flaws where critical information concentrates in specific regions.
- Core assumption: A well-designed benchmark requiring global reasoning should distribute task-relevant information across image regions, producing relatively uniform patch contributions.
- Evidence anchors:
  - [section 4.2.4] "Figure 3 and 4 clearly indicates a strong central bias across benchmarks, with the center patch (Patch 5) consistently contributing the highest to model performance."
  - [section 3.3] "For every patch position, we compute the fraction of total correct predictions (or score) resulting from that patch when used in isolation. This reveals if particular regions, such as the image center: dominate task success."
  - [corpus] TangramPuzzle benchmark addresses compositional spatial reasoning but focuses on task design rather than dataset auditing methodology.
- Break condition: Assumption requires sufficient sample sizes per patch to yield stable contribution estimates; small datasets may produce noisy distributions.

### Mechanism 3
- Claim: RCI trends are robust across reference model architectures, enabling efficient auditing with smaller models.
- Mechanism: The spatial reasoning dependencies measured by RCI are intrinsic to dataset structure rather than model-specific behaviors. Cross-model correlations (r ≥ 0.91) between InternVL-2.5, Qwen2-VL, and Molmo architectures demonstrate that the same dataset biases are detected regardless of model choice.
- Core assumption: Dataset-level reasoning requirements manifest consistently across different model architectures and scales.
- Evidence anchors:
  - [section 4.2.1] "As shown in Figure 2, RCI values are highly correlated across architectures (r ≥ 0.91), demonstrating that the global versus local reasoning dependencies measured by RCI are intrinsic to the datasets, rather than artifacts of specific model choices."
  - [appendix A.5.1] "High intra-model and intra-family correlations (r ≥ 0.86) persist even as model size increases."
  - [corpus] No direct corpus validation of cross-model robustness claims; this appears to be a novel contribution.
- Break condition: Assumption may break for fundamentally different model architectures (e.g., non-transformer vision encoders) not tested in the study.

## Foundational Learning
- Concept: Global vs. Local Visual Reasoning
  - Why needed here: The entire RCI framework depends on distinguishing tasks that require integrating information distributed across an image (global) from those solvable with isolated region analysis (local).
  - Quick check question: Given a chart with axes, legend, and data points, would answering "Which quarter had highest revenue?" require processing multiple image regions or could one patch suffice?

- Concept: Multimodal Benchmark Evaluation Metrics
  - Why needed here: RCI builds on understanding what existing metrics (CIDEr, BLEU, CLIPScore) measure and their limitations in capturing spatial reasoning dependencies.
  - Quick check question: Why would a caption similarity metric like CIDEr fail to detect whether a VQA benchmark allows localized shortcut solutions?

- Concept: Spatial Bias and Shortcut Learning
  - Why needed here: The paper's diagnostic value hinges on recognizing how dataset artifacts (e.g., consistent placement of key information) enable models to exploit shortcuts rather than develop genuine reasoning.
  - Quick check question: If 80% of objects-of-interest in a detection benchmark appear in the central 30% of images, what failure mode might a trained model exhibit at deployment?

## Architecture Onboarding
- Component map: Image → Patch Partitioner → Reference Model Evaluator (parallel for all patches + full image) → Performance Aggregator → RCI Calculator → Interpretation Layer
- Critical path: Image → Patch Partitioner → Reference Model Evaluator (parallel for all patches + full image) → Performance Aggregator → RCI Calculator → Interpretation Layer
- Design tradeoffs:
  - Patch granularity (n=2 vs n=3): n=3 reveals sharper spatial biases but increases compute by ~2.25×; n=4+ risks fragmenting semantic content and artificially inflating RCI
  - Reference model selection: Smaller models (1-2B parameters) efficient and correlate well with larger variants, but absolute RCI values may shift slightly
  - Validity threshold (Δ_min): Conservative thresholds reduce false interpretations but may exclude borderline-valid datasets
- Failure signatures:
  - RCI ≈ 0 with low FIP: Model at chance; validity check failed
  - RCI increasing sharply at n≥5: Patch fragmentation artifact, not genuine global reasoning signal
  - Highly variable patch contributions with small sample sizes: Insufficient data for stable bias estimates
  - Cross-model RCI correlation < 0.7: Dataset may have model-specific artifacts rather than structural biases
- First 3 experiments:
  1. Reproduce RCI computation on a held-out benchmark (e.g., GQA subset) with n=2 and n=3 using InternVL-2.5-1B, verifying correlation with reported values (expected RCI ≈ -0.21 to -0.27).
  2. Apply spatial bias analysis to generate patch contribution heatmaps for a domain-specific dataset (e.g., medical imaging), comparing central vs. peripheral patch contributions to assess design quality.
  3. Test validity threshold sensitivity by synthetically degrading model performance on a high-RCI dataset (e.g., ChartQA) and confirming RCI becomes uninterpretable when FIP approaches chance levels.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the RCI framework be effectively extended to quantify temporal biases and multi-frame dependencies in video datasets?
- Basis in paper: [explicit] Section C.2 ("Expanding to Multi-Image and Video Understanding") proposes extending RCI to video to analyze how dataset biases evolve over time.
- Why unresolved: The current methodology relies on spatial patching (2x2, 3x3) of static images; video requires assessing reasoning across sequential frames rather than isolated spatial regions.
- What evidence would resolve it: A "Temporal RCI" formulation where high scores accurately predict performance degradation when specific keyframes are obscured or removed.

### Open Question 2
- Question: Does training models on RCI-filtered datasets (removing samples solvable by local cues) improve generalization to real-world, out-of-distribution tasks?
- Basis in paper: [explicit] Section C.2 ("RCI for Dataset Optimization") asks if integrating RCI into the training pipeline can filter localized samples to improve dataset fairness and model generalization.
- Why unresolved: The paper establishes RCI as a diagnostic for existing benchmarks but has not empirically validated it as an intervention for dataset construction.
- What evidence would resolve it: A comparative study showing models trained on high-RCI subsets achieve higher accuracy on unseen, global-reasoning-heavy benchmarks compared to models trained on unfiltered data.

### Open Question 3
- Question: Can the dependency on reference model architecture be eliminated by using model ensembles to compute RCI?
- Basis in paper: [explicit] Section C.1 notes that "absolute RCI values may still reflect reference model choices" and suggests exploring "model ensembles or standardized model sets" to address this.
- Why unresolved: While RCI trends are robust, the absolute values fluctuate depending on the specific MLLM used (e.g., InternVL vs. Molmo), complicating standardization.
- What evidence would resolve it: A demonstration that an ensemble-based RCI computation yields consistent absolute scores (low variance) across a diverse set of architectural backbones.

## Limitations
- The validity threshold assumption (FIP > chance + 1.0 pp) is heuristic and may exclude challenging datasets
- Cross-modal domain applicability remains untested; spatial reasoning framework may not generalize to non-visual modalities
- Patch fragmentation artifacts at higher granularity (n > 3) could produce misleading RCI values

## Confidence
- High Confidence: The core mechanism of comparing patch-level vs. full-image performance to detect localized reasoning is methodologically sound and well-supported by empirical results across 13 benchmarks.
- Medium Confidence: Spatial bias detection through patch contribution analysis is validated, but the clinical significance of observed central biases across diverse real-world applications requires further investigation.
- Medium Confidence: Cross-model robustness claims are supported by correlation analysis, but the assumption that dataset-level reasoning requirements manifest consistently across all model architectures warrants broader testing.

## Next Checks
1. **Threshold Sensitivity Analysis**: Systematically vary Δ_min from 0.5 to 2.0 percentage points across benchmarks to quantify how the validity threshold affects RCI interpretability and which datasets become excluded at different thresholds.
2. **Cross-Modal Extension Study**: Apply RCI to at least two non-visual multimodal benchmarks (e.g., audio-visual or text-image) to test whether the patch-based decomposition approach remains meaningful and diagnostically useful outside the visual domain.
3. **Model Architecture Stress Test**: Evaluate RCI on at least three fundamentally different model architectures (e.g., convolutional, transformer, and hybrid vision encoders) to establish when and how cross-model correlations break down, providing practical guidance on acceptable model diversity for reference model selection.