---
ver: rpa2
title: Evaluating Privacy-Utility Tradeoffs in Synthetic Smart Grid Data
arxiv_id: '2506.11026'
source_url: https://arxiv.org/abs/2506.11026
tags:
- data
- synthetic
- privacy
- diffusion
- ctgan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper evaluates privacy-utility trade-offs in synthetic smart\
  \ grid data for dynamic tariff classification. Four synthetic data generation methods\u2014\
  WGAN, CTGAN, Diffusion Models, and Gaussian noise augmentation\u2014are compared\
  \ in terms of classification utility, distribution fidelity, and privacy leakage."
---

# Evaluating Privacy-Utility Tradeoffs in Synthetic Smart Grid Data

## Quick Facts
- arXiv ID: 2506.11026
- Source URL: https://arxiv.org/abs/2506.11026
- Reference count: 40
- Primary result: Diffusion models achieve highest utility (macro-F1 up to 88.2%), while CTGAN provides strongest privacy protection (PRS = 0.16)

## Executive Summary
This paper evaluates privacy-utility trade-offs in synthetic smart grid data for dynamic tariff classification. Four synthetic data generation methods—WGAN, CTGAN, Diffusion Models, and Gaussian noise augmentation—are compared in terms of classification utility, distribution fidelity, and privacy leakage. Diffusion models achieve the highest utility (macro-F1 up to 88.2%), while CTGAN provides the strongest privacy protection with the lowest privacy risk score (PRS = 0.16). WGAN shows the weakest performance in both utility and privacy. CTGAN full-synthetic data best preserves distributional fidelity and offers the strongest defense against reconstruction attacks.

## Method Summary
The study uses UK Power Networks Low Carbon London dataset (2011–2014) with 167M half-hourly readings from 5,567 households, extracting 24 behavioral features including usage ratios, peak hour ratios, and load entropy. Labels are derived via PCA on standardized features with 75th percentile threshold. Four generators are compared: WGAN-GP (3-layer MLP, 100 epochs), DDPM Diffusion (3-layer MLP, T=100 steps), CTGAN via SDV (batch=500, 300 epochs), and Gaussian noise injection. Evaluation uses nested 5×3 CV with randomized search over five classifiers (DT, RF, KNN, SVM, XGB). Metrics include macro-F1 for utility, KL/JS divergence for fidelity, and MIA AUC/PRS for privacy robustness.

## Key Results
- Diffusion models achieve highest utility with macro-F1 up to 88.2%
- CTGAN provides strongest privacy protection with PRS = 0.16
- WGAN shows weakest performance in both utility and privacy
- CTGAN full-synthetic best preserves distributional fidelity
- Semi-synthetic approaches leak almost as much as real data

## Why This Works (Mechanism)

### Mechanism 1
Structured generative architectures (Diffusion, CTGAN) achieve better privacy-utility tradeoffs than simpler approaches (WGAN, Gaussian noise) because architectural constraints that improve generation quality also reduce overfitting to specific training records.

### Mechanism 2
Full-synthetic regimes provide stronger privacy protection than semi-synthetic augmentation because generators trained without access to real samples at inference time cannot leak specific training points.

### Mechanism 3
Mode collapse in WGAN architectures causes simultaneous utility and privacy degradation because reduced sample diversity limits downstream classifier generalization while retaining enough structure for partial reconstruction.

## Foundational Learning

- **Generative Adversarial Networks (GANs) vs Diffusion Models**: Understanding training dynamics explains performance differences. Quick check: Can you explain why GANs suffer from mode collapse while diffusion models do not?

- **Membership Inference Attacks (MIA) and Reconstruction Attacks**: Understanding threat models is essential for interpreting PRS and AUC metrics. Quick check: What information does an adversary have access to in a "posterior-only black-box" threat model?

- **Tabular Data Synthesis Challenges**: CTGAN's design specifically addresses mixed categorical/continuous features and class imbalance. Quick check: Why does conditional generation on discrete columns help with tabular data synthesis?

## Architecture Onboarding

- **Component map**: Real Data → Feature Engineering → Synthetic Generator (WGAN/CTGAN/Diffusion/Noise) → Synthetic Data (Full/Semi regime) → Fidelity Metrics, Utility Metrics, Privacy Metrics

- **Critical path**: Start with CTGAN full-synthetic for privacy-critical releases. Use Diffusion full-synthetic when utility is paramount and some leakage is tolerable. Avoid WGAN full-synthetic due to mode collapse risks.

- **Design tradeoffs**:
  - CTGAN Full-Synthetic: Best privacy (PRS=0.16), strong utility (82.5%), best fidelity (KL=0.44)
  - Diffusion Full-Synthetic: Best utility (88.2%), moderate privacy (PRS=0.98), good fidelity (KL=1.44)
  - Gaussian Noise: Good utility (81.6%), but high privacy risk (PRS=1.0) due to low distributional shift

- **Failure signatures**:
  - KL divergence >3.0 indicates distributional drift
  - Reconstruction ρ >0.7 indicates privacy vulnerability
  - Macro-F1 <60% on full-synthetic indicates generator failure
  - MIA AUC >0.65 suggests insufficient privacy protection

- **First 3 experiments**:
  1. Generate synthetic data with all four methods, compute KL/JS divergence against held-out real data
  2. Run reconstruction attacks on full-synthetic outputs, target PRS<0.3 for public release
  3. Train classifiers on synthetic data, evaluate on real test set, ensure macro-F1 within 10% of real-data baseline

## Open Questions the Paper Calls Out

### Open Question 1
Can time-aware generative architectures (e.g., TimeGAN, TiDE, CSDI) improve the fidelity and controllability of synthetic smart meter data compared to the tabular models evaluated? The current study uses tabular generative models that do not explicitly model temporal ordering; the potential gains from sequence-level architectures remain untested.

### Open Question 2
Can differentially private training mechanisms (e.g., DP-SGD, PATE) be integrated into CTGAN or Diffusion models to provide certified privacy guarantees while maintaining predictive utility? Current privacy evaluation relies on empirical attacks without formal guarantees.

### Open Question 3
How sensitive are the classification results to the choice of responsiveness label construction method (PCA-based thresholding vs. alternative strategies)? The binary labels are heuristically derived; it is unclear whether findings hold under alternative labeling approaches.

## Limitations
- Exact feature engineering formulas and random seeds are not specified
- Shadow model architectures for MIA attacks lack detailed specifications
- No code repository provided for exact reproduction

## Confidence

| Claim | Confidence |
|-------|------------|
| CTGAN achieves best privacy-utility tradeoff | High |
| Diffusion models achieve highest utility | High |
| WGAN suffers from mode collapse | Medium |
| Semi-synthetic data leaks as much as real data | High |

## Next Checks
1. Verify feature engineering formulas for load_entropy, load_factor_low, and other behavioral features match paper specifications
2. Test reconstruction attacks on CTGAN full-synthetic outputs to confirm PRS < 0.3 threshold
3. Validate macro-F1 scores on real test set when training classifiers on synthetic data to ensure utility retention