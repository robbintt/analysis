---
ver: rpa2
title: 'SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language
  Models'
arxiv_id: '2512.01148'
source_url: https://arxiv.org/abs/2512.01148
tags:
- social
- tasks
- visual
- task
- socialfusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates "social degradation," a phenomenon where
  visual-linguistic pre-training impairs vision encoders'' ability to represent nuanced
  social information. Through controlled experiments comparing visual encoders before
  and after VLM pre-training, the authors demonstrate that pre-training consistently
  degrades performance on five visual social interaction understanding tasks: gesture
  analysis, gaze estimation, facial expression recognition, social situation analysis,
  and conversation dynamics analysis.'
---

# SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models

## Quick Facts
- arXiv ID: 2512.01148
- Source URL: https://arxiv.org/abs/2512.01148
- Reference count: 33
- Pre-trained vision encoders consistently underperform on social tasks after VLM pre-training due to reduced linear decodability of social features

## Executive Summary
This paper identifies "social degradation" - a phenomenon where visual-linguistic pre-training impairs vision encoders' ability to represent nuanced social information. Through controlled experiments comparing visual encoders before and after VLM pre-training, the authors demonstrate that pre-training consistently degrades performance on five visual social interaction understanding tasks: gesture analysis, gaze estimation, facial expression recognition, social situation analysis, and conversation dynamics analysis. The degradation primarily stems from reduced linear decodability of social features, with gradient conflict playing a secondary role. To address this, the authors propose SocialFusion, a unified framework that learns minimal connections between frozen visual encoders and language models, achieving positive transfer across all five tasks while setting new state-of-the-art results on HaGRIDv2 and PISC benchmarks.

## Method Summary
SocialFusion uses a frozen CLIP ViT-336 visual encoder with a 3-layer MLP connector (4096 hidden units) to project visual features to LLM space, which is then processed by a frozen Llama 3.2 1B with LoRA adapters (rank 32). Bounding box information is embedded as binary masks added to visual features. For classification tasks, the model generates text tokens; for gaze estimation, it outputs heatmaps via linear projection and transposed convolution. The model is trained jointly on all five social tasks with task-specific prompts, using AdamW optimizer (lr=2e-4) with cosine decay. The approach prevents social degradation by preserving the original encoder's social feature representations while learning minimal connections to the LLM.

## Key Results
- SocialFusion achieves positive transfer across all five social tasks, while existing VLMs exhibit negative transfer when jointly trained
- Sets new state-of-the-art results on HaGRIDv2 and PISC benchmarks
- Linear probes show 4-5% accuracy drops on visual encoders after VLM pre-training across multiple architectures (Qwen2-VL, MolmoE, Sail-VL)
- Minimal connector architecture prevents feature overwriting while enabling sufficient projection for social reasoning

## Why This Works (Mechanism)

### Mechanism 1: Frozen Visual Encoder Preserves Social Feature Decodability
- Claim: Using a visual encoder that has NOT undergone VLM pre-training preserves the linear decodability of social features, which is the primary factor in social degradation.
- Mechanism: Standard VLM pre-training on large-scale general visual-textual data appears to restructure visual representations in ways that make fine-grained social cues (gaze, expression, gesture) less linearly separable. By freezing a pre-trained vision encoder (CLIP in the paper) and only learning the connection to the LLM, the original social representations remain intact.
- Core assumption: The degradation occurs during the visual-linguistic alignment phase of VLM pre-training, not during the original vision encoder training.
- Evidence anchors:
  - [abstract]: "revealing that both play a role in the degradation, especially the former [decodability], which is significantly compromised in the VLM pre-training process"
  - [Section 3.3, Table 5]: Linear probes on encoders before VLM pre-training outperform post-pre-training encoders on 4 of 5 tasks for Qwen2-VL, all 5 for MolmoE, and most tasks for Sail-VL
  - [corpus]: Weak direct evidence—corpus papers discuss VLM degradation broadly but not specifically social feature decodability
- Break condition: If the task requires learning NEW social concepts not present in the frozen encoder's pre-training data, this mechanism alone will fail; if gradient conflicts are actually the dominant factor (contrary to paper's finding), freezing won't help.

### Mechanism 2: Minimal Connector Prevents Representation Overwriting
- Claim: A lightweight 3-layer MLP connector, learned from scratch, provides sufficient projection from visual to linguistic space without degrading source representations.
- Mechanism: Complex connector architectures (or full fine-tuning) can override or distort the encoder's learned features. A minimal connector with frozen backbone and LLM forces the model to learn only the necessary alignment, not feature reconstruction.
- Core assumption: Social features are already well-encoded in the frozen visual encoder; only projection to LLM space is needed.
- Evidence anchors:
  - [Section 3.4]: "We want the majority of the processing to take place in the LLM and learn a minimal connector between the two main components. Therefore, we opted for a straightforward three-layer MLP"
  - [Section 4.4]: "SocialFusion beats all baselines on all datasets except PISC" in joint training
  - [corpus]: OTTER paper notes that "fine-tuning pre-trained VLMs... degrading the pre-trained semantic features"—consistent with minimal connector rationale
- Break condition: If tasks require significant visual feature transformation that a 3-layer MLP cannot provide, performance will plateau; if the hidden dimension (4096) is insufficient for complex social reasoning, scaling may be needed.

### Mechanism 3: Joint Training Exploits Cross-Task Social Synergies
- Claim: Training all five social tasks simultaneously enables positive transfer when social degradation is avoided, because social tasks share underlying "atomic social competencies."
- Mechanism: Tasks like gaze estimation and LAM (looking-at-me detection) share gaze-related features; gesture and social situation analysis share body language cues. Joint training allows shared representations to strengthen rather than compete.
- Core assumption: Social tasks have genuine synergies that emerge only with multi-task training—not just shared low-level features but higher-order social reasoning.
- Evidence anchors:
  - [Section 4.5, Table 6]: Pairwise training shows some synergies (LAM+GazeFollow improves GazeFollow), but full joint training yields broader positive transfer, suggesting "a more general social training effect"
  - [abstract]: "it exhibits positive transfer across all five social tasks, leveraging synergies between them"
  - [corpus]: No direct corpus evidence on multi-task social transfer; corpus papers focus on single-task or general VLM capabilities
- Break condition: If tasks have conflicting gradient directions (gradient conflict degree > 1), joint training would harm performance; this paper finds GCD < 1 for all encoders, but results may not generalize to other task combinations.

## Foundational Learning

- **Linear Representation Probing**
  - Why needed here: The paper uses linear probes to isolate whether social degradation is a representation problem (encoder-level) vs. an adaptation problem (connector/LLM-level). Understanding this distinction is critical for debugging VLM performance issues.
  - Quick check question: If a linear probe on frozen visual features achieves high accuracy but the full model fails on the task, where does the problem likely lie? (Answer: In the connector or LLM adaptation, not the encoder)

- **Negative Transfer in Multi-Task Learning**
  - Why needed here: The core problem statement. Negative transfer occurs when joint training on multiple tasks degrades performance compared to single-task training. Understanding gradient conflict and task interference helps diagnose why.
  - Quick check question: What does a Gradient Conflict Degree (GCD) > 1 indicate? (Answer: Task gradients point in opposing directions, causing interference)

- **Frozen vs. Fine-tuned Components in VLMs**
  - Why needed here: SocialFusion's design relies on freezing both the visual encoder and LLM, training only the connector and LoRA adapters. This is a specific architectural choice with tradeoffs vs. full fine-tuning.
  - Quick check question: What are the parameter efficiency gains of LoRA (rank 32) vs. full LLM fine-tuning? (Answer: LoRA adds only rank × 2 × hidden_dim parameters per layer, typically <1% of full model parameters)

## Architecture Onboarding

- **Component map:**
  - Image → CLIP ViT-336 (frozen) → feature map (24×24×d_v) → binary mask bbox embedding → flatten → 3-layer MLP connector (dv→4096→4096→dl) → LLM embedding space → Llama 3.2 1B (frozen + LoRA rank 32) → text tokens OR gaze heatmap

- **Critical path:**
  1. Image → CLIP encoder → feature map (24×24×d_v)
  2. Bounding boxes → binary mask → element-wise add to feature map
  3. Feature map → flatten → MLP connector → LLM embedding space
  4. Task prompt (text) + visual tokens → LLM (with LoRA) → text tokens OR gaze heatmap

- **Design tradeoffs:**
  - CLIP vs. DINOv2 encoder: CLIP better overall; DINOv2 stronger on gaze tasks but weaker on others (Table 8)
  - Frozen encoder/LLM vs. fine-tuning: Freezing prevents degradation but limits adaptation to new visual domains
  - Single connector vs. task-specific heads: Single unified connector enables cross-task transfer but may underperform specialized architectures

- **Failure signatures:**
  - **Negative transfer**: Joint training performs worse than single-task training (baseline VLMs show 2-7/10 metrics with positive transfer vs. 10/10 for SocialFusion)
  - **Social degradation**: Visual encoder after VLM pre-training shows lower linear probe accuracy than before (Table 5)
  - **Gaze heatmap collapse**: If gaze loss weight λ is too low, model ignores heatmap task; if too high, classification tasks suffer

- **First 3 experiments:**
  1. **Reproduce social degradation finding**: Take Qwen2-VL's visual encoder before and after VLM pre-training; run linear probes on AffectNet and GazeFollow. Expect ~5-15% accuracy drop on post-pre-training encoder.
  2. **Verify positive transfer**: Train SocialFusion jointly on all 5 tasks vs. individually; compare PISC Domain mAP. Expect ~2-3 point improvement in joint training (Table 1: 91.7 → 94.4).
  3. **Ablate connector depth**: Test 1-layer vs. 3-layer vs. 5-layer MLP connectors on joint training. Hypothesis: Deeper connectors may start overwriting features, showing diminishing returns or degradation.

## Open Questions the Paper Calls Out
None

## Limitations
- Study is limited to five specific social tasks using CLIP-based encoders; generalizability to other social tasks or VLM architectures remains untested
- The frozen-encoder approach may fail on tasks requiring novel social concept learning not present in the original CLIP training data
- Alternative explanations for social degradation (catastrophic forgetting, representation compression) were not fully explored

## Confidence
- **High confidence**: SocialFusion framework achieves positive transfer across all five tested social tasks, outperforming existing VLMs that show negative transfer
- **Medium confidence**: Social degradation is primarily caused by reduced linear decodability of social features during VLM pre-training
- **Medium confidence**: Minimal connector architecture (3-layer MLP) is optimal for preventing feature overwriting while enabling sufficient projection

## Next Checks
1. Test SocialFusion on novel social tasks not in the original five (e.g., social role recognition, group dynamics understanding) to verify generalizability beyond the controlled setting
2. Evaluate degradation patterns across different VLM architectures (DINOv2, SigLIP, or custom-trained encoders) to determine if CLIP-specific phenomena drive the findings
3. Implement ablation studies varying connector architecture complexity and λ heatmap loss weighting systematically to identify optimal hyperparameters across the social task spectrum