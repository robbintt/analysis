---
ver: rpa2
title: 'Biased Minds Meet Biased AI: How Class Imbalance Shapes Appropriate Reliance
  and Interacts with Human Base Rate Neglect'
arxiv_id: '2511.14591'
source_url: https://arxiv.org/abs/2511.14591
tags:
- human
- bias
- biases
- participants
- reliance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examined how AI class imbalance interacts with human
  base rate neglect (BRN) in decision-making. In a within-subject experiment (N=46),
  participants classified diseases using an AI tool trained on balanced vs.
---

# Biased Minds Meet Biased AI: How Class Imbalance Shapes Appropriate Reliance and Interacts with Human Base Rate Neglect

## Quick Facts
- arXiv ID: 2511.14591
- Source URL: https://arxiv.org/abs/2511.14591
- Reference count: 40
- Primary result: Class imbalance disrupts appropriate reliance calibration and amplifies human base rate neglect in AI-assisted decision-making

## Executive Summary
This study examines how AI class imbalance interacts with human base rate neglect (BRN) in decision-making contexts. Through a within-subject experiment with 46 participants classifying diseases using AI tools trained on balanced versus unbalanced data, the researchers found that class imbalance significantly disrupted appropriate reliance calibration, reducing AI reliance from 55% to 12% in unbalanced conditions. More critically, unbalanced AI amplified BRN over time, causing participants to increasingly select the overrepresented disease even before receiving AI advice, while balanced AI mitigated this cognitive bias.

## Method Summary
The study employed a within-subject experimental design where 46 participants classified diseases using an AI tool under two conditions: balanced and unbalanced class distributions. Participants made repeated decisions while receiving AI advice, allowing researchers to track changes in reliance patterns and decision-making strategies over time. The experimental setup controlled for confounding variables while isolating the effects of class imbalance on human-AI interaction and cognitive bias expression.

## Key Results
- Class imbalance reduced appropriate reliance from 55% to 12% (RAIR metric)
- Unbalanced AI amplified base rate neglect over time, with participants increasingly selecting the overrepresented disease pre-advice
- Balanced AI mitigated base rate neglect, demonstrating the potential for well-designed AI to counteract human cognitive biases

## Why This Works (Mechanism)
The mechanism underlying these findings involves the interaction between algorithmic bias and human cognitive limitations. When AI systems are trained on unbalanced datasets, they not only perform poorly on minority classes but also provide advice that reinforces existing human biases. The unbalanced AI's tendency to over-recommend the majority class interacts with humans' natural tendency to underweight base rates (BRN), creating a compounding effect where both AI and human biases reinforce each other. Conversely, balanced AI provides more representative advice that helps humans maintain better statistical reasoning.

## Foundational Learning
- **Appropriate Reliance Calibration**: The alignment between AI advice quality and human trust in that advice; critical for effective human-AI collaboration and ensuring users neither over-rely nor under-rely on AI systems
- **Base Rate Neglect**: The cognitive bias where people underweight statistical base rates when making probability judgments; quick check: assess whether participants consider disease prevalence in their decisions
- **Class Imbalance Effects**: How skewed training data distributions affect AI performance and user trust; why needed: understanding real-world AI deployment challenges
- **Human-AI Interaction Dynamics**: The bidirectional influence between user behavior and AI recommendations; quick check: track how user decisions evolve with repeated AI interaction
- **Cognitive Bias Amplification**: How algorithmic outputs can reinforce or mitigate existing human biases; why needed: designing AI systems that don't perpetuate or worsen human errors

## Architecture Onboarding
- **Component Map**: Human decision-maker -> AI advice receiver -> AI classifier (balanced/unbalanced) -> Disease classification task
- **Critical Path**: User receives disease symptoms -> AI provides classification advice -> User makes final decision -> System records reliance and accuracy
- **Design Tradeoffs**: Simulated medical task vs. real-world complexity; controlled experimental conditions vs. ecological validity
- **Failure Signatures**: Over-reliance on majority class recommendations; progressive abandonment of statistical reasoning; decreased calibration accuracy over time
- **First 3 Experiments**: 1) Test with medical professionals vs. novices to assess expertise effects; 2) Vary advice presentation formats (verbal vs. numerical confidence); 3) Introduce real-time feedback mechanisms to examine adaptive learning

## Open Questions the Paper Calls Out
None

## Limitations
- Sample size of 46 participants may limit generalizability to broader populations
- All participants recruited from university pools, potentially lacking diversity in cognitive styles and medical decision-making experience
- Simulated medical diagnosis task with fictional diseases may not fully translate to real-world high-stakes domains

## Confidence
- High confidence: Class imbalance disrupts appropriate reliance calibration
- Medium confidence: Unbalanced AI amplifies human base rate neglect over time
- Medium confidence: Balanced AI mitigates base rate neglect

## Next Checks
1. Replicate the study with a larger, more diverse sample including medical professionals and laypersons with varying levels of medical knowledge
2. Test the same paradigm across multiple high-stakes domains (medical diagnosis, financial risk assessment, legal decision-making) to assess generalizability
3. Conduct follow-up experiments with real-time eye-tracking or think-aloud protocols to better understand the cognitive mechanisms underlying the observed effects