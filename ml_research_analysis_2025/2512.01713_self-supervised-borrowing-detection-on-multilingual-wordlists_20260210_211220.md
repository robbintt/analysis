---
ver: rpa2
title: Self-Supervised Borrowing Detection on Multilingual Wordlists
arxiv_id: '2512.01713'
source_url: https://arxiv.org/abs/2512.01713
tags:
- similarity
- data
- list
- miller
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a fully self-supervised approach for detecting
  borrowings in multilingual wordlists, addressing the lack of methods that do not
  require labeled data or manual thresholds. The core idea is to combine PMI similarities
  derived from a global correspondence model with a lightweight contrastive learning
  component trained on phonetic feature vectors, and to use Gaussian Mixture Models
  for automatic threshold selection.
---

# Self-Supervised Borrowing Detection on Multilingual Wordlists

## Quick Facts
- arXiv ID: 2512.01713
- Source URL: https://arxiv.org/abs/2512.01713
- Reference count: 15
- Primary result: Fully self-supervised borrowing detection method combining PMI similarity and contrastive learning, achieving up to 0.849 F1 in controlled experiments

## Executive Summary
This paper introduces a novel self-supervised approach for detecting borrowings in multilingual wordlists, addressing the long-standing challenge of borrowing detection without labeled data or manual thresholds. The method leverages PMI similarities from a global correspondence model combined with a lightweight contrastive learning component trained on phonetic feature vectors. Gaussian Mixture Models are used for automatic threshold selection, making the entire pipeline unsupervised. Experiments demonstrate that PMI alone outperforms existing measures like NED and SCA, while the combined approach achieves performance comparable to or better than supervised baselines, with particular success in controlled datasets like NorthEuraLex.

## Method Summary
The approach combines two complementary components: PMI similarity derived from a global correspondence model and contrastive learning trained on phonetic feature vectors. The PMI component measures semantic similarity between words across languages using a global model trained on cognate detection data. The contrastive learning component learns to distinguish borrowings from native words by encoding phonetic features into a representation space where positive pairs (true borrowings) are closer than negative pairs. Gaussian Mixture Models are employed to automatically select classification thresholds without supervision. The method is implemented as a command-line tool for exploratory research and scales to various dataset sizes without requiring labeled training data.

## Key Results
- PMI similarity alone improves over existing measures (NED, SCA) for borrowing detection
- Combined PMI + contrastive learning approach achieves F1 scores up to 0.849 in favorable conditions
- Ablation studies confirm importance of phonetic feature encoding, temperature settings, and avoiding overly destructive augmentations
- Method works without supervision and scales to various dataset sizes
- Performance comparable to or better than supervised baselines in controlled experiments

## Why This Works (Mechanism)
The method succeeds by leveraging the complementary strengths of semantic and phonetic information. PMI similarity captures long-range semantic patterns and cross-linguistic correspondences that are robust to phonetic variation, while contrastive learning on phonetic features learns fine-grained distinctions between borrowed and native word forms. The Gaussian Mixture Model provides principled, data-driven threshold selection that adapts to the specific distribution of similarities in each dataset. This combination allows the system to detect borrowings without requiring labeled examples or manual threshold tuning, addressing a fundamental limitation of previous approaches that relied on supervised learning or arbitrary cutoffs.

## Foundational Learning
- PMI (Pointwise Mutual Information): Measures association strength between word pairs across languages; needed to capture semantic similarity patterns without supervision; quick check: verify PMI values correlate with known cognates
- Contrastive Learning: Trains representations to bring similar items closer and push dissimilar items apart; needed to learn discriminative features for borrowing detection; quick check: ensure embedding space separates borrowings from native words
- Gaussian Mixture Models: Probabilistic models for clustering data into multiple components; needed for automatic threshold selection without labeled data; quick check: verify GMM components correspond to borrowing vs. native word distributions
- Phonetic Feature Vectors: Numerical representations of phonetic properties; needed to provide contrastive learning with meaningful input signals; quick check: confirm phonetic features capture relevant variation for borrowing detection
- Correspondence Models: Global models learned from cognate data; needed to provide PMI similarities across languages; quick check: validate model performance on held-out cognate pairs
- Self-Supervised Learning: Learning without labeled examples; needed to enable borrowing detection on uncurated data; quick check: compare performance against supervised baselines

## Architecture Onboarding

Component Map: PMI Model -> Contrastive Learner -> GMM Threshold Selector -> Classification Output

Critical Path: Raw wordlists → Phonetic Feature Extraction → PMI Similarity Computation → Contrastive Training → GMM Threshold Selection → Borrowing Classification

Design Tradeoffs: The method trades some potential accuracy for complete self-supervision, avoiding the need for labeled training data. The choice of phonetic features and augmentation strategies significantly impacts contrastive learning performance. PMI computation requires a pre-trained correspondence model, introducing a dependency but enabling cross-linguistic similarity measurement.

Failure Signatures: Poor performance may indicate: insufficient phonetic feature representation, inappropriate temperature settings in contrastive loss, overly destructive data augmentations, or failure of the PMI model to capture relevant cross-linguistic patterns. The GMM may fail to find appropriate thresholds if the similarity distributions are not well-separated.

First Experiments:
1. Evaluate PMI similarity alone on a controlled dataset with known borrowings to establish baseline performance
2. Train contrastive learning component with different temperature settings and augmentations to find optimal configuration
3. Apply the full pipeline to a dataset with minimal curation to test robustness to real-world conditions

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Evaluation restricted to controlled datasets (NorthEuraLex, curated cognates) rather than natural, uncurated wordlists
- Performance on low-resource or highly diverse language families (African, Papuan) not demonstrated
- Assumes clean phonetic transcriptions; robustness to noisy or inconsistent data untested
- Reliance on global PMI similarity may be sensitive to quality and coverage of underlying correspondence model

## Confidence

High confidence in PMI similarity as standalone indicator (consistent ablation results, NED/SCA comparison)
Medium confidence in combined approach matching/surpassing supervised baselines (limited dataset diversity, no independent validation)
Medium confidence in scalability to uncurated large-scale wordlists (controlled experiments only)

## Next Checks

1. Test on uncurated datasets like UniMorph or multilingual lexical databases with variable transcription quality
2. Cross-linguistic validation on language families not represented in training/development data, comparing performance across families of varying genetic and areal diversity
3. Benchmark against best-performing supervised models on same datasets, reporting precision-recall trade-offs and computational overhead