---
ver: rpa2
title: 'Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation
  Framework for Long-Horizon Manipulation Skills'
arxiv_id: '2509.18597'
source_url: https://arxiv.org/abs/2509.18597
tags:
- pose
- block
- blocks
- task
- skill
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a human-in-the-loop lifelong skill learning
  framework for robotic code generation, addressing the challenges of noisy LLM outputs,
  limited context windows, and poor generalization in long-horizon manipulation tasks.
  The framework encodes user corrections into reusable skills stored in external memory,
  uses Retrieval-Augmented Generation with a hint mechanism for dynamic in-context
  learning, and employs a user-designed curriculum for capability extension.
---

# Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills

## Quick Facts
- arXiv ID: 2509.18597
- Source URL: https://arxiv.org/abs/2509.18597
- Authors: Yuan Meng; Zhenguo Sun; Max Fest; Xukun Li; Zhenshan Bing; Alois Knoll
- Reference count: 40
- One-line primary result: Achieved 0.93 success rate on long-horizon tasks, up to 27% better than baselines

## Executive Summary
This paper introduces a human-in-the-loop lifelong skill learning framework for robotic code generation, addressing challenges of noisy LLM outputs, limited context windows, and poor generalization in long-horizon manipulation tasks. The framework encodes user corrections into reusable skills stored in external memory, uses Retrieval-Augmented Generation with a hint mechanism for dynamic in-context learning, and employs a user-designed curriculum for capability extension. Experiments on Ravens, Franka Kitchen, and MetaWorld benchmarks, as well as real-world settings, demonstrate a 0.93 success rate—up to 27% higher than baselines—and a 42% efficiency improvement in feedback rounds. The framework robustly solves extremely long-horizon tasks like "build a house," which requires planning over 20 primitives.

## Method Summary
The framework consists of three core components: skill encoding, retrieval-augmented code generation with a hint mechanism, and curriculum-based capability extension. When the agent encounters failure, human feedback is collected and encoded into reusable skills stored in external memory. During task execution, the system retrieves relevant skills and uses a hint mechanism to guide the LLM in generating appropriate code. The curriculum extension component allows users to progressively add new capabilities. The approach combines dynamic in-context learning with lifelong learning principles to handle long-horizon manipulation tasks effectively.

## Key Results
- Achieved 0.93 success rate on long-horizon manipulation tasks
- Outperformed baselines by up to 27% in success rate
- Reduced feedback rounds by 42% through efficient skill reuse
- Successfully completed "build a house" task requiring planning over 20 primitives

## Why This Works (Mechanism)
The framework addresses three core challenges in robotic code generation: noisy LLM outputs through human feedback encoding, limited context windows through skill-based retrieval, and poor generalization through curriculum extension. By converting corrections into reusable skills stored externally, the system builds a knowledge base that improves with each interaction. The hint mechanism provides targeted guidance during code generation, while the curriculum allows systematic capability growth. This human-in-the-loop approach creates a virtuous cycle where each failure becomes a learning opportunity, enabling the agent to handle increasingly complex tasks over time.

## Foundational Learning
- **Skill Encoding**: Converting user corrections into reusable functions - needed for knowledge retention and generalization; quick check: can encoded skills be successfully retrieved and applied to similar tasks
- **Retrieval-Augmented Generation**: Using external memory to augment LLM context - needed to overcome context window limitations; quick check: does retrieval improve code quality for long-horizon tasks
- **Curriculum Design**: Progressive capability extension through user guidance - needed for systematic skill growth; quick check: does curriculum extension enable solving progressively harder tasks
- **Human-in-the-Loop Feedback**: Iterative correction and refinement process - needed to handle LLM uncertainty and task complexity; quick check: does feedback reduce failure rates over time
- **Long-Horizon Planning**: Decomposing complex tasks into sequential primitives - needed for handling tasks requiring 20+ steps; quick check: can system plan and execute multi-step sequences reliably

## Architecture Onboarding
Component Map: Human Feedback -> Skill Encoder -> External Memory -> Retriever -> Hint Generator -> LLM -> Robot Controller -> Environment -> Success/Failure Signal -> Human Feedback

Critical Path: Task Request -> Skill Retrieval -> Hint Generation -> Code Generation -> Execution -> Feedback Collection -> Skill Encoding

Design Tradeoffs: Fixed vs. dynamic skill granularity (current: function-level); local vs. global skill retrieval (current: context-aware retrieval); immediate vs. delayed feedback incorporation (current: real-time encoding)

Failure Signatures: Skill retrieval misses (system fails to find relevant skills); hint generation errors (inappropriate guidance provided); code generation failures (syntactically correct but semantically wrong); feedback encoding issues (poor skill representation)

First Experiments:
1. Test skill retrieval accuracy on held-out tasks using benchmark datasets
2. Validate hint mechanism effectiveness through ablation studies comparing with and without hints
3. Evaluate curriculum extension by measuring success rate growth across progressive task difficulty levels

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can knowledge from feedback be stored and reused most effectively for robotic skill learning?
- Basis in paper: [explicit] Authors explicitly state this as "the first question" motivating their approach, noting that existing methods store corrected knowledge in improper formats, restricting generalization.
- Why unresolved: While skills are proposed as a storage format, the optimal granularity, parameterization, and compositional structure for reusable skills remain underexplored.
- What evidence would resolve it: Systematic comparison of different skill representations (e.g., flat code vs. parameterized functions vs. hierarchical skill trees) on retention, transfer, and compositional generalization across diverse task distributions.

### Open Question 2
- Question: What type of feedback is most efficient during human-robot interaction for long-horizon manipulation tasks?
- Basis in paper: [explicit] Authors explicitly state this as "the second question" motivating their approach, comparing language feedback from LLMs vs. human-provided corrections.
- Why unresolved: The paper demonstrates that human feedback outperforms LLM feedback, but does not disentangle the relative contributions of feedback modality (language vs. demonstration), specificity, or timing.
- What evidence would resolve it: Controlled studies varying feedback type, granularity, and timing while measuring convergence speed, final performance, and user burden across standardized task suites.

### Open Question 3
- Question: How does the framework scale to dual-arm collaboration and more complex robotic setups?
- Basis in paper: [explicit] The conclusion explicitly identifies this as future work: "extending to dual-arm collaboration and more complex robotic setups."
- Why unresolved: The current framework is demonstrated on single-arm tabletop manipulation; coordination, skill sharing, and conflict resolution in multi-arm or mobile manipulation settings are unaddressed.
- What evidence would resolve it: Extension of the framework to dual-arm or mobile platforms with evaluation on collaborative manipulation benchmarks, measuring success rate, skill reuse efficiency, and feedback requirements.

## Limitations
- Reliance on simulated environments raises questions about real-world robustness across diverse physical setups
- Manual selection of correction examples for skill encoding introduces potential biases that may not scale efficiently
- Framework performance under low-quality or inconsistent human feedback remains unexplored
- Curriculum design depends heavily on human expertise, limiting accessibility for non-expert users

## Confidence
- **High Confidence**: The reported performance improvements (0.93 success rate, 27% over baselines) and efficiency gains (42% fewer feedback rounds) are well-supported by the experimental methodology and benchmark results.
- **Medium Confidence**: The framework's ability to generalize to extremely long-horizon tasks like "build a house" is convincing within the tested environments but may require further validation in more complex, unstructured real-world settings.
- **Medium Confidence**: The hint mechanism and retrieval-augmented generation show promise, but their scalability and robustness in diverse, noisy scenarios remain underexplored.

## Next Checks
1. **Real-World Transfer**: Validate the framework's performance on physical robots in varied environments (e.g., different lighting, textures, or object configurations) to assess robustness beyond simulation.
2. **Scalability of Skill Encoding**: Test the system's ability to handle a large, continuously growing library of skills without significant degradation in retrieval accuracy or execution efficiency.
3. **Human Feedback Quality**: Investigate how the framework performs under low-quality or inconsistent human feedback, and explore automated methods to mitigate potential biases in skill encoding.