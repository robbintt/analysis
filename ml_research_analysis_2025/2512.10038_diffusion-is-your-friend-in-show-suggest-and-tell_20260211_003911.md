---
ver: rpa2
title: Diffusion Is Your Friend in Show, Suggest and Tell
arxiv_id: '2512.10038'
source_url: https://arxiv.org/abs/2512.10038
tags:
- diffusion
- image
- suggestion
- captioning
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a new paradigm for diffusion models in image
  captioning by using them as suggestion modules rather than replacements for autoregressive
  models. The proposed Show, Suggest and Tell (SST) architecture integrates a discrete
  denoising diffusion model to generate suggestions that guide an autoregressive captioning
  model.
---

# Diffusion Is Your Friend in Show, Suggest and Tell

## Quick Facts
- arXiv ID: 2512.10038
- Source URL: https://arxiv.org/abs/2512.10038
- Reference count: 40
- Primary result: SST achieves 125.1 CIDEr-D on MS-COCO 2014 test set, outperforming both autoregressive and diffusion SOTA

## Executive Summary
This paper proposes a novel hybrid architecture for image captioning that uses a discrete diffusion model as a suggestion engine for an autoregressive (AR) model, rather than replacing it. The key insight is that diffusion models can extract a richer semantic context by processing the superset of all tokens from reference captions, which the AR model then uses to guide its sequential generation. The architecture achieves state-of-the-art performance (125.1 CIDEr-D) without reinforcement learning, demonstrating that diffusion and AR models can be effectively combined when diffusion is used as a bidirectional semantic context provider rather than a direct caption generator.

## Method Summary
The method trains a discrete diffusion model (Suggestion Module) on the superset of unique tokens from all reference captions per image, learning to denoise corrupted token sets into meaningful suggestions. These suggestions are aggregated into a single dense vector via a Reduce Layer and concatenated to each decoder layer input of an AR captioning model. This integration strategy prevents the AR model from copying imperfect suggestions directly, instead using them as global semantic context. The AR model generates the final caption sequentially, conditioned on both visual features and the suggestion context.

## Key Results
- SST achieves 125.1 CIDEr-D on MS-COCO 2014 test set without RL
- Suggestion quality directly correlates with caption performance (F1 51.8% vs CIDEr-D 125.1)
- Reduce+Concatenation integration outperforms cross-attention (124.9 vs 122.2 CIDEr-D)
- Training on 5 reference captions per image significantly improves suggestion recall (45.4% vs 26.9%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A discrete diffusion model can serve as an effective suggestion engine by extracting a richer, superset of semantic tokens from all available reference captions.
- **Mechanism:** The Suggestion Module is trained on the set of all unique tokens from the five human-provided reference captions for an image. Because diffusion models are non-autoregressive, they can process this entire set at once, learning to predict nouns, verbs, and adjectives that may appear in only one reference but describe the image well. This set of suggestions provides the AR model with a bidirectional, globally-aware semantic context it would otherwise miss due to its sequential, single-reference training.
- **Core assumption:** The set of unique tokens from all reference captions for an image contains meaningful semantic information that a single caption often omits.
- **Evidence anchors:** [Section III-A] defines the superset target, [Section IV-C, Table II] shows 5-reference training achieves 45.4% recall vs 26.9% for 1-reference, [Section IV-G] demonstrates improved scenario understanding.
- **Break condition:** If the Suggestion Module cannot achieve reasonable F1 scores on the token set, its output becomes noise, failing to provide actionable guidance.

### Mechanism 2
- **Claim:** An aggregated integration strategy is crucial to leverage suggestions without inducing harmful exposure bias in the autoregressive model.
- **Mechanism:** The Reduce Layer uses a learned weighted average to collapse all suggestion embeddings into a single dense context vector, which is concatenated to the input of each decoder layer. This forces the AR model to treat suggestions as global semantic signal rather than individual tokens to copy.
- **Core assumption:** Autoregressive models are susceptible to exposure bias and will copy from available text, even if that text contains errors.
- **Evidence anchors:** [Section III-C.2] explains the need to prevent direct access, [Section IV-D, Table IV] shows cross-attention (122.2-122.8) underperforms Reduce+Concatenation (124.9).
- **Break condition:** Performance degrades if cross-attention is used, as the model learns faulty "copy-paste" behavior from imperfect suggestions.

### Mechanism 3
- **Claim:** The iterative refinement of the diffusion process is superior to direct prediction for generating high-quality suggestions.
- **Mechanism:** A direct prediction model defaults to generic words (function words) to minimize loss, achieving high precision (83.0%) but very low recall (26.3%). The diffusion framework succeeds through iterative denoising steps that allow the model to refine its output and predict more complex, semantically meaningful nouns and verbs.
- **Core assumption:** The mapping from visual features to relevant tokens is complex enough that single-step prediction is insufficient for high recall.
- **Evidence anchors:** [Section IV-E, Table V] shows direct prediction yields 39.2% F1 vs ~51.8% for diffusion methods.
- **Break condition:** Using direct prediction results in too-generic suggestions to provide meaningful guidance.

## Foundational Learning

- **Concept:** Discrete Denoising Diffusion Probabilistic Models (D3PM)
  - **Why needed here:** The Suggestion Module is implemented as a D3PM. Understanding how a forward process corrupts a discrete token set and a neural network learns to reverse it is fundamental to the proposal.
  - **Quick check question:** How does the forward process in a discrete diffusion model transform the target token set $x_0$ over time?

- **Concept:** Autoregressive (AR) Captioning & Exposure Bias
  - **Why needed here:** The proposed architecture augments an AR model. Understanding the AR model's sequential, causal nature and its inherent weakness (exposure bias) explains why "Reduce+Concatenation" integration is critical.
  - **Quick check question:** What is "exposure bias" in an autoregressive model, and why would giving it direct access to imperfect suggestion tokens trigger this failure mode?

- **Concept:** Precision vs. Recall in a Set Prediction Task
  - **Why needed here:** The paper evaluates the Suggestion Module using Precision, Recall, and F1 score. Understanding this trade-off is key to analyzing ablation results.
  - **Quick check question:** In the context of the Suggestion Module, what does a high Precision but low Recall score indicate about the quality of suggestions?

## Architecture Onboarding

- **Component map:** Image -> Visual Backbone -> Suggestion Module (Diffusion Denoising) -> Reduce Layer -> Integration Module -> Autoregressive Decoder -> Final Caption

- **Critical path:** The architectural innovation is concentrated in the Suggestion Module's design (trained on a superset of tokens) and the Reduce Layer's integration strategy.

- **Design tradeoffs:**
  - **Diffusion vs. Direct Prediction:** Diffusion is chosen despite slower inference because it provides the recall necessary for meaningful suggestions (direct prediction is fast but fails on diverse semantics)
  - **Integration Strategy:** Cross-attention is more expressive but leads to performance degradation due to exposure bias; Reduce+Concatenation is less expressive but provides robust context
  - **Suggestion Granularity:** Single tokens (1-grams) are most effective; predicting longer n-grams lowers overall F1 score

- **Failure signatures:**
  - **Low Recall / High Precision Suggestions:** Model only predicts generic words ("a", "the", "on") - indicates diffusion setup issues
  - **Copy-Paste Behavior:** Final caption is non-sensical jumble of suggested tokens - indicates using cross-attention instead of Reduce Layer
  - **Performance Degradation:** Model with suggestions performs worse than baseline AR - suggests suggestions are too noisy or integration is disruptive

- **First 3 experiments:**
  1. **Baseline Validation:** Train chosen AR model (e.g., ExpansionNet v2) without suggestions to establish baseline (~123.3 CIDEr-D)
  2. **Suggestion Module Ablation:** Train Suggestion Module using standard diffusion vs. direct prediction baseline; verify diffusion improves recall (targeting 45.4% vs 26.9% recall gap)
  3. **Integration Ablation:** Compare CIDEr-D scores when integrating suggestions via (A) Cross-Attention vs. (B) Reduce+Concatenation; confirm (B) yields higher score

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** At what threshold of suggestion quality (F1 score) does a direct cross-attention (copy) mechanism outperform the current "Reduce + Concatenation" integration strategy?
- **Basis in paper:** [explicit] Section IV-H states that if the suggestion module achieves better F1 scores, we can allow the autoregressive model to copy directly from suggestions, as the current integration was designed to prevent copying due to noise.
- **Why unresolved:** Current Suggestion Module's F1 score (51.8%) is too low, making cross-attention detrimental due to noise and exposure bias.
- **What evidence would resolve it:** Ablation studies comparing integration strategies using higher-quality suggestion module or Oracle with varying preservation probabilities to identify crossover point.

### Open Question 2
- **Question:** How can discrete diffusion frameworks be fundamentally adapted to optimize for unordered set-based token prediction rather than sequential generation?
- **Basis in paper:** [explicit] Section V notes that missing "obvious" suggestions is likely caused by the fact that "discrete diffusion framework was originally designed for sequences, which is not the case of Equation [1]" (which defines target as set of unique tokens).
- **Why unresolved:** Standard diffusion models rely on sequential dependencies that don't exist in the set-of-tokens formulation, limiting ability to capture diverse semantics.
- **What evidence would resolve it:** Development and validation of permutation-invariant diffusion objective that outperforms current strategies on suggestion F1 metric.

### Open Question 3
- **Question:** Can the suggestion module effectively serve as a mechanism for monitoring epistemic uncertainty and providing explainability?
- **Basis in paper:** [explicit] Section V states: "If the suggestion module is performing well enough, it can be used to monitor epistemic uncertainty... We believe this is a topic worth exploring in the future."
- **Why unresolved:** While diffusion process generates multiple potential tokens, it hasn't been tested whether variance or confidence of suggestions correlates reliably with model uncertainty or failure modes.
- **What evidence would resolve it:** Experiments correlating consistency of suggested tokens against ground truth uncertainty metrics or adversarial examples.

## Limitations

- The paper relies on previously published numbers for SOTA comparisons, making exact quantitative improvements difficult to verify
- The specific implementation details of the reparametrized discrete diffusion formulation are not fully specified in the main paper
- The effectiveness of the Reduce+Concatenation strategy is demonstrated but the exact mechanism by which it prevents exposure bias could be more thoroughly analyzed

## Confidence

**High Confidence:**
- The Suggestion Module benefits from training on a superset of unique tokens from all reference captions (demonstrated by clear recall improvements in Table II)
- The Reduce+Concatenation integration strategy outperforms cross-attention (validated by direct comparison in Table IV)
- The iterative refinement of diffusion is necessary for capturing diverse semantic tokens (shown by the direct prediction baseline failure in Table V)

**Medium Confidence:**
- The final reported CIDEr-D of 125.1 represents a 2.5-point improvement over diffusion SOTA, as this relies on correctly interpreting and comparing against published numbers
- The claim that AR models suffer from exposure bias when given direct access to suggestions is supported by the ablation but could benefit from more direct analysis

**Low Confidence:**
- The specific implementation details of the reparametrized discrete diffusion training objective and the exact AR model hyperparameters, which are critical for exact reproduction but only referenced from prior work

## Next Checks

1. **Implement and validate the Suggestion Module's training objective**: Reconstruct the discrete diffusion training loop with the reparametrized loss and verify that training on 5 references yields significantly higher recall than training on 1 reference on a held-out validation set (targeting the 45.4% vs 26.9% recall gap from Table II).

2. **Isolate the integration mechanism's impact**: Using a fixed, pre-trained Suggestion Module, conduct a controlled experiment comparing the three integration strategies (Reduce+Concatenation, Cross-Attention, and No Suggestions) to confirm that Reduce+Concatenation yields the highest CIDEr-D score.

3. **Analyze the exposure bias mechanism**: Perform a qualitative analysis of captions generated with and without the Reduce Layer. Compare the frequency of copied suggestion tokens, the coherence of the output, and the presence of non-sensical word combinations to directly demonstrate that cross-attention leads to a "copy-paste" failure mode while Reduce+Concatenation maintains linguistic structure.