---
ver: rpa2
title: Reliable Conversational Agents under ASP Control that Understand Natural Language
arxiv_id: '2502.09237'
source_url: https://arxiv.org/abs/2502.09237
tags:
- arxiv
- movie
- user
- talk
- attitude
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a framework for reliable conversational agents
  that "understand" natural language by leveraging Large Language Models (LLMs) only
  as parsers to translate text to knowledge, while using Answer Set Programming (ASP)
  for reasoning. The approach addresses the limitations of LLMs in fact-based conversations,
  including lack of understanding, reliability, and tendency to hallucinate.
---

# Reliable Conversational Agents under ASP Control that Understand Natural Language

## Quick Facts
- arXiv ID: 2502.09237
- Source URL: https://arxiv.org/abs/2502.09237
- Reference count: 28
- Primary result: Task-specific chatbot (AutoConcierge) achieved 89.33% accuracy in predicate extraction from natural language

## Executive Summary
This work presents a framework for reliable conversational agents that "understand" natural language by leveraging Large Language Models (LLMs) only as parsers to translate text to knowledge, while using Answer Set Programming (ASP) for reasoning. The approach addresses the limitations of LLMs in fact-based conversations, including lack of understanding, reliability, and tendency to hallucinate. The framework has been applied to develop task-specific chatbots like AutoConcierge for restaurant recommendations and socialbots like AutoCompanion for movie/book discussions.

## Method Summary
The framework uses LLMs (GPT-3.5/4) as semantic parsers to convert natural language into structured predicates, while ASP performs all reasoning tasks. The system maintains conversation context through accumulated predicate state, checks consistency, and generates responses based on ASP reasoning. Two variants were developed: AutoConcierge for task-oriented restaurant recommendations and AutoCompanion for social chatbot interactions about movies and books. The CKT (Conversational Knowledge Template) module encodes domain-specific rules for completeness checks and action selection.

## Key Results
- 89.33% accuracy in predicate extraction from natural language (GPT-3.5 with 11-shot prompting on E2E dataset)
- Successful implementation of AutoConcierge for restaurant recommendations with context maintenance
- Development of AutoCompanion socialbot for movie/book discussions with RCC (Relevant Consistent Concept) for topic transitions

## Why This Works (Mechanism)

### Mechanism 1
Restricting LLMs to parsing-only roles (natural language ↔ predicates) reduces hallucination and improves reliability in fact-based conversations. The LLM performs semantic parsing, translating user input into structured predicates such as `require('price range', ['cheap'])`. All reasoning is delegated to ASP, which follows explicitly defined logical rules rather than probabilistic generation. Core assumption: Parser accuracy is sufficiently high that errors do not propagate significantly into downstream reasoning.

### Mechanism 2
ASP provides formal verification of conversation state, ensuring logical consistency and detecting missing information before action. After parsing, ASP code evaluates whether required information is present, whether predicates are mutually consistent, and what action should follow. Core assumption: The ASP rules correctly and exhaustively encode domain constraints and conversational logic.

### Mechanism 3
Explicit, accumulated predicate state across turns enables coherent multi-turn dialogue without reliance on LLM context memory. Each user input adds or updates predicates in a persistent state representation. This accumulated state, not the LLM's internal context, drives reasoning at each turn. Core assumption: Predicate updates merge correctly without unresolvable conflicts, and the state representation remains manageable as conversations lengthen.

## Foundational Learning

- **Answer Set Programming (ASP)**: Why needed: ASP is the reasoning engine. You must understand logic programming basics, stable model semantics, and how to represent knowledge as rules and facts. Quick check: Can you write an ASP rule that detects a missing required predicate and triggers a query action?

- **Semantic Parsing to Predicates**: Why needed: The architecture hinges on converting natural language into structured predicates. Understanding predicate structure (name, argument types, value domains) is essential for defining ontologies and debugging parser output. Quick check: Given "I want cheap Italian food except pasta," can you sketch predicates capturing preference, cuisine, and exclusion?

- **Conversational State Management**: Why needed: Multi-turn dialogues require tracking accumulated user preferences, negations, and context. Without explicit state, the system cannot maintain coherence. Quick check: If a user first says "no spicy food" and later "actually, Thai is fine," how would you represent and update the predicate state?

## Architecture Onboarding

- **Component map**: LLM Parser (GPT-3.5/4) → predicates → ASP Reasoner → action/answer → LLM Generator → NL response. Update System maintains persistent state. CKT encodes domain rules. RCC manages topic transitions for socialbots.

- **Critical path**: 1. Define ontology: predicates, domains, value types. 2. Write CKT rules in ASP for your target domain. 3. Craft few-shot prompts for LLM parser with concrete predicate examples. 4. Implement update system for state persistence and conflict handling. 5. Connect pipeline: NL → LLM parser → predicates → ASP reasoner → instruction → LLM generator → NL.

- **Design tradeoffs**: Rigidity vs. flexibility: Strict ASP rules ensure consistency but require exhaustive domain pre-definition. Parser accuracy ceiling: 89.33% on E2E is promising; complex or ambiguous utterances may still fail. Scalability: Current framework is domain-specific; generalization requires templating and modularizing CKTs.

- **Failure signatures**: LLM outputs malformed or out-of-ontology predicates → ASP fails to interpret. Incomplete CKT rules → system loops asking for already-provided information. State update conflicts → contradictory predicates not detected or resolved. Missing ontology coverage → user intent not captured in any predicate.

- **First 3 experiments**: 1. Parser validation: Test LLM prompt on 50+ domain utterances; measure predicate extraction accuracy against manual annotations. 2. Single-turn reasoning check: Provide parsed predicates to ASP; verify it correctly identifies missing fields and generates appropriate follow-up questions. 3. Multi-turn state accumulation: Simulate a 5-turn conversation; after each turn, inspect accumulated predicate state for correctness and consistency.

## Open Questions the Paper Calls Out

### Open Question 1
How can a "trainer chatbot" be implemented to allow the system to learn new functions and update its ontology dynamically through interaction with a human coach? The author explicitly identifies this as a specific research goal in Section 3 and Section 5. The current framework relies on pre-defined predicates and manually constructed Conversational Knowledge Templates (CKTs) for each domain. Evidence would be a demonstration of the system successfully integrating a new, unprogrammed task solely through natural language instruction.

### Open Question 2
Can the framework be generalized to fit most tasks while maintaining a scalable architecture, or is it limited to narrow domains? The abstract and Section 5 state that future work is focused on making the chatbot "scalable" and "general enough to fit most tasks." The provided examples are relatively narrow; a generalized template that abstracts the ASP reasoning and CKT generation has not yet been presented. Evidence would be a successful deployment of a single framework architecture across multiple, diverse domains without requiring extensive, domain-specific re-engineering.

### Open Question 3
How does the system handle reasoning failures when the LLM parser produces incorrect or hallucinated predicates (the ~10.67% error rate)? The paper reports 89.33% accuracy in predicate extraction, implying a failure rate, but does not detail how the ASP reasoner recovers from or detects these semantic errors during conversation. ASP is a strict reasoning engine; input predicates that are syntactically correct but semantically wrong could lead to logically valid but factually nonsensical responses. Evidence would be analysis of system behavior in error scenarios, specifically showing robustness rather than silent reasoning failures.

## Limitations
- Parser accuracy ceiling (89.33%) leaves room for error propagation into reasoning
- ASP rules and CKT/RCC modules lack complete specifications, making coverage assessment difficult
- Socialbot component (AutoCompanion) lacks detailed validation and scalability testing

## Confidence

- **High Confidence**: The mechanism of using ASP for formal reasoning and consistency checking is sound and well-established in the literature. The core architectural separation of parsing (LLM) and reasoning (ASP) is clearly defined and technically feasible.

- **Medium Confidence**: The 89.33% parser accuracy is reported but based on a single dataset (E2E) and prompt configuration (11-shot). Generalizability to other domains or more complex utterances is uncertain. The effectiveness of predicate-based state management for multi-turn dialogue is demonstrated in examples but not systematically evaluated.

- **Low Confidence**: The socialbot component (AutoCompanion) lacks detailed validation, and the scalability claims for future work are not substantiated with experiments or prototypes.

## Next Checks

1. **Parser Robustness Test**: Evaluate the LLM parser on a diverse set of complex, ambiguous, and out-of-domain utterances to measure accuracy degradation and identify failure patterns.

2. **ASP Rule Coverage Audit**: Conduct a systematic review of CKT/RCC rule completeness for a target domain, checking for missing constraints or edge cases that could lead to inconsistent states.

3. **Multi-turn Dialogue Scalability Test**: Simulate extended conversations (10+ turns) with conflicting or evolving user preferences to assess state update system performance and conflict resolution effectiveness.