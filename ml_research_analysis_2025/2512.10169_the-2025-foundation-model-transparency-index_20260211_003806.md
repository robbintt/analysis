---
ver: rpa2
title: The 2025 Foundation Model Transparency Index
arxiv_id: '2512.10169'
source_url: https://arxiv.org/abs/2512.10169
tags:
- companies
- data
- transparency
- indicators
- fmti
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The 2025 Foundation Model Transparency Index reveals declining
  transparency among major AI companies, with average scores falling from 58 to 40
  out of 100. The study evaluates 13 leading companies on 100 indicators covering
  data acquisition, model properties, and downstream impacts.
---

# The 2025 Foundation Model Transparency Index

## Quick Facts
- arXiv ID: 2512.10169
- Source URL: https://arxiv.org/abs/2512.10169
- Reference count: 32
- Primary result: Average transparency scores fell from 58 to 40 out of 100 across 13 major AI companies

## Executive Summary
The 2025 Foundation Model Transparency Index reveals declining transparency among major AI companies, with average scores falling from 58 to 40 out of 100. The study evaluates 13 leading companies on 100 indicators covering data acquisition, model properties, and downstream impacts. While IBM leads with a score of 95, companies like xAI and Midjourney score only 14. The most opaque areas include training data, compute usage, and post-deployment impacts, with B2B companies consistently more transparent than B2C companies.

## Method Summary
The FMTI uses 100 binary indicators across three domains (Upstream, Model, Downstream) to score transparency. Seven companies submitted private transparency reports while six were evaluated using public sources and AI-assisted research. Two independent researchers scored each indicator (89.4% agreement), with companies given opportunity to rebut scores. The 2025 update introduced stricter definitions, with 55 new indicators reflecting current AI landscape including agent protocols and training data provenance.

## Key Results
- Average scores declined from 58 to 40 out of 100
- IBM achieved highest score at 95; xAI and Midjourney lowest at 14
- B2B companies consistently outperformed B2C companies in transparency
- Upstream domains (training data, compute) remain most opaque
- 55 new indicators and stricter definitions contributed to score declines

## Why This Works (Mechanism)

### Mechanism 1: The Reputational Feedback Loop
Direct engagement and public ranking incentivize companies to disclose non-public information. FMTI scores companies → Companies review initial scores → Reputational concern triggers release of previously withheld data → Final scores increase. This assumes companies perceive low transparency scores as reputational or market liabilities. Evidence shows companies clarified 18.9 indicators on average, yielding 9.71 point increases. Break condition: Companies explicitly decline participation or refuse to engage during rebuttal phase.

### Mechanism 2: Business Model Alignment
Enterprise-focused (B2B) business models structurally incentivize higher transparency compared to consumer (B2C) models. B2B clients require due diligence → Developers build documentation to close sales → Higher scores on upstream/downstream indicators. This assumes regulatory and client pressure drives transparency more than competitive openness. Evidence shows top 3 companies are enterprise-focused. Break condition: A consumer-facing company adopts a "safety-first" branding strategy necessitating high transparency.

### Mechanism 3: Regulatory Anticipation
Proximity to regulatory frameworks correlates with disclosure quality in specific domains. Policy mandates specific summaries → Companies align internal reporting → Spillover effects improve public transparency scores. This assumes companies prefer standardizing reporting once rather than maintaining separate public and private compliance regimes. Evidence shows EU AI Act signatories score slightly higher, mostly in downstream domains. Break condition: Companies find "alternative means of compliance" avoiding public disclosure.

## Foundational Learning

- **Concept:** Transparency vs. Openness
  - **Why needed here:** The paper distinguishes between "transparency" (information access) and "openness" (weight access). A model can be open-weight but opaque if it hides training data.
  - **Quick check question:** Can a closed-source model be transparent? (Yes, e.g., Writer scored 72 without releasing weights).

- **Concept:** Indicator Specificity ("Raising the Bar")
  - **Why needed here:** The 2025 index introduced stricter definitions, contributing to score declines independent of actual company behavior changes.
  - **Quick check question:** Why did average scores drop from 58 to 40? (Partly methodology: broad "text generation" descriptions no longer satisfy capability indicators).

- **Concept:** Hybrid Information Gathering
  - **Why needed here:** The architecture relies on both voluntary self-reporting and manual/automated auditing. Understanding the "hybrid" nature is critical to interpreting the score gap between participants and non-participants.
  - **Quick check question:** Why do self-reporting companies score higher? (They disclose non-public information; FMTI-prepared reports are limited to public data).

## Architecture Onboarding

- **Component map:** Indicators (100 total) → Dual-track ingestion (Company Reports vs. FMTI Search/AI Agent) → Binary scoring by two researchers (89.4% agreement) → Company Response phase for rebuttal

- **Critical path:** Definition updating → Engagement convincing companies to submit reports → Validation resolving discrepancies between FMTI research and company claims

- **Design tradeoffs:**
  - Inclusion vs. Accuracy: Including non-participating companies broadens coverage but yields lower/incomplete scores
  - Agent vs. Human: AI agent found more information (mean 13 additional indicators) but hallucinated false positives requiring manual vetting

- **Failure signatures:**
  - Verbosity without substance: Long reports acknowledging opacity without scoring points
  - Regression: Companies disclosing data one year but omitting it the next

- **First 3 experiments:**
  1. A/B Test Retrieval: Run AI agent vs. human auditor on ground truth documents to measure false positive rate
  2. Sensitivity Analysis: Re-score high-performer using only public data to quantify "participation bonus"
  3. Domain Correlation: Check if high Upstream scores predict high Downstream scores

## Open Questions the Paper Calls Out

- When is transparency genuinely at odds with other organizational values (e.g., security, competitive advantage), and what are the costs of these tradeoffs?
- How will EU AI Act enforcement specifically impact disclosure rates in currently opaque upstream domains like training data and compute?
- To what extent do business model incentives (B2B vs. B2C) causally determine transparency practices compared to factors like open-weight release strategies?

## Limitations

- Private data dependency: Scores for participating companies rely heavily on non-public information, making independent verification impossible
- Temporal instability: High volatility with some companies regressing significantly without clear public explanation
- Indicator interpretation variance: Binary scoring creates potential for systematic bias despite high agreement rates

## Confidence

- **High confidence**: Methodology description and indicator definitions are explicit and reproducible for public data sources
- **Medium confidence**: Conclusions about B2B vs B2C transparency incentives are supported by data but rely on correlation rather than experimental evidence
- **Low confidence**: Interpretation of score declines as reflecting actual transparency deterioration is uncertain given stricter definitions

## Next Checks

1. Re-score validation: Select 3 high-scoring companies and attempt to replicate scores using only public sources
2. Temporal consistency check: Identify which companies disclosed specific information in 2024 but omitted it in 2025, then search for public statements
3. Domain independence test: Analyze whether companies scoring high on Upstream indicators systematically score high on Downstream indicators