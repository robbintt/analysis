---
ver: rpa2
title: 'CCCI: Code Completion with Contextual Information for Complex Data Transfer
  Tasks Using Large Language Models'
arxiv_id: '2503.23231'
source_url: https://arxiv.org/abs/2503.23231
tags:
- code
- data
- ccci
- completion
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CCCI, a retrieval-augmented code completion
  method that improves accuracy by integrating contextual information into large language
  models (LLMs) for data transfer tasks. The method classifies input DTOs as local
  or external, retrieves hierarchical data structures, matches fields semantically,
  constructs structured prompts, and generates code.
---

# CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models

## Quick Facts
- arXiv ID: 2503.23231
- Source URL: https://arxiv.org/abs/2503.23231
- Authors: Hangzhan Jin; Mohammad Hamdaqa
- Reference count: 40
- Primary result: Achieved 49.1% Build Pass rate and 41.0% CodeBLEU score on 289 Java snippets from a Warehouse Management System

## Executive Summary
This paper introduces CCCI, a retrieval-augmented code completion method that improves accuracy by integrating contextual information into large language models for data transfer tasks. The approach classifies input DTOs as local or external, retrieves hierarchical data structures from both source files and compiled dependencies, matches fields semantically, constructs structured prompts, and generates compilable code. Evaluated on a real-world Warehouse Management System, CCCI achieved significant improvements over baseline prompts without contextual information, demonstrating robust performance across six different LLMs.

## Method Summary
CCCI is a retrieval-augmented code completion pipeline that enhances LLM performance for Java data transfer tasks. The method first classifies DTOs as local or external, then uses JavaParser for local source files and Java Reflection for compiled JARs to extract hierarchical class structures. A hybrid matcher performs exact field matching followed by semantic matching via embeddings and cosine similarity. The Constructor component builds structured prompts with task definitions, DTO schemas, field mappings, and coding rules. The Completer invokes LLMs with specified generation parameters to produce compilable code.

## Key Results
- Build Pass rate improved from 0.0% to 49.1% compared to baseline prompt
- CodeBLEU score achieved 41.0% (vs 16.9% baseline)
- Results consistent across six LLMs: GPT-4o, Gemini-pro-1.5, Claude-3.5-haiku, Llama-3.1-405b, Qwen-2.5-coder-32b, Deepseek-3
- Evaluated on 289 Java snippets from a Warehouse Management System with 111 tables and 9 external dependencies

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Context Retrieval
The system classifies DTOs as local or external, then applies different extraction strategies—JavaParser for source files and Java Reflection for compiled JARs—to recursively retrieve class hierarchies, field types, annotations, and comments. This structured context is flattened into text representations for the LLM. Core assumption: explicit hierarchical structure information is the primary missing context causing code completion failures in data transfer scenarios.

### Mechanism 2: Hybrid Field Matching
Exact matching transfers fields with identical names automatically. Semantic matching generates embeddings from class definitions, computes cosine similarity between source and target DTOs, and ranks correspondences to identify non-identical but conceptually aligned fields. Core assumption: semantic similarity via embeddings captures domain-level equivalence even when naming conventions differ across modules.

### Mechanism 3: Structured Prompt Construction
The Constructor component organizes retrieved context into a standardized prompt format: task definition, input/output DTO structures, field mapping table, and rules such as using BeanUtils.copyProperties for exact matches. This reduces ambiguity in generation. Core assumption: LLMs perform better with explicitly structured context than with raw code dumps.

## Foundational Learning

- **Data Transfer Objects (DTOs) and Object-Relational Mapping**: Needed because the entire CCCI method assumes familiarity with DTOs as containers for data transfer between layers. Quick check: Given a UserDTO containing an AddressDTO, can you sketch how a mapper would flatten address.city into a target UserResponseDTO.city field?

- **Retrieval-Augmented Generation (RAG) for Code**: Needed because CCCI is fundamentally a RAG approach—retrieving structured context before generation. Quick check: If you retrieve an irrelevant class definition from a dependency, how might that affect the LLM's generated mapping code?

- **Embedding Similarity and Cosine Distance**: Needed because semantic field matching relies on embedding representations and cosine similarity to align fields across DTOs without exact name matches. Quick check: Two fields have embeddings [0.8, 0.6] and [0.6, 0.8]. Compute the cosine similarity. What threshold might indicate a valid match?

## Architecture Onboarding

- **Component map**: Project Source + Task Definition → [Classifier] → Local vs External tags → [Retriever] → JavaParser (local) | Reflection (external) → Hierarchical class info → [Matcher] → Exact match + Semantic embeddings → Field mapping table → [Constructor] → Structured prompt → [Completer] → LLM inference → Generated code

- **Critical path**: Retriever → Matcher → Constructor. If retrieval misses nested class structures or external dependency definitions, downstream matching fails, producing incomplete prompts.

- **Design tradeoffs**:
  1. Decompilation vs. Source Access: Reflection can extract structure from compiled JARs but loses comments. Trade-off: broader coverage vs. reduced semantic signals.
  2. Exact vs. Semantic Matching Priority: Exact matching is fast and precise but brittle; semantic matching adds flexibility but introduces false positives.
  3. Prompt Token Budget: Including full hierarchical context improves accuracy but risks truncation.

- **Failure signatures**:
  1. 0% Build Pass on baseline: Indicates LLM has insufficient context to resolve types, methods, or external class references.
  2. Low Edit Similarity with high CodeBLEU: Code is syntactically similar but requires substantial manual correction.
  3. Claude-3.5-haiku underperformance: Weak instruction-following capability.

- **First 3 experiments**:
  1. Reproduce the Classifier on your own project: Run file search and classification logic against a multi-module Java project with external JAR dependencies.
  2. Ablate the semantic matcher: Disable semantic matching and compare Build Pass rates on 50 snippets to quantify contribution beyond exact matching.
  3. Test prompt truncation sensitivity: For large DTO hierarchies, progressively remove outer context layers and measure when Build Pass drops.

## Open Questions the Paper Calls Out

### Open Question 1
Can CCCI be effectively adapted for complex domains beyond data transfer tasks, such as Service Mashup? The conclusion states that CCCI principles "apply to broader scenarios, such as Service Mashup" but evaluation is limited to data transfer tasks.

### Open Question 2
How can CCCI be enhanced to capture custom code exception handling to reduce performance variability? Section 4.3.1 identifies "Custom Code Exception Handling" as a main factor contributing to CodeBLEU score variability.

### Open Question 3
Does the CCCI approach generalize to programming languages other than Java? The methodology relies specifically on "JavaParser" and "Java Reflection Mechanism" to extract hierarchical data structures.

### Open Question 4
Can the CCCI prompt structure be optimized to support models with weaker instruction-following capabilities? Section 4.4 notes that Claude-3.5-haiku "significantly underperforms" due to weaker instruction-following capabilities.

## Limitations

- Performance heavily depends on quality of context retrieval, particularly for external compiled dependencies; no metrics reported on obfuscated or poorly documented libraries.
- Semantic matching precision is unquantified; paper demonstrates successful field alignments but provides no false positive/negative analysis.
- Embedding model used for semantic matching is unspecified, making reproduction and evaluation on different datasets difficult.

## Confidence

- **High Confidence**: Build Pass rate improvement (49.1% vs 0% baseline) and CodeBLEU score gains (41.0% vs 16.9%) are well-documented with clear methodology and consistent across six different LLMs.
- **Medium Confidence**: Hierarchical context retrieval mechanism is theoretically sound and empirically validated on the Warehouse Management System dataset, but generalizability to other enterprise domains remains uncertain.
- **Low Confidence**: Semantic matching precision and recall are not quantified; approach assumes embedding similarity captures semantic equivalence without analysis of false positives/negatives.

## Next Checks

1. **Semantic Matching Precision Analysis**: Implement logging of cosine similarity scores for all field pairs, manually verify 100 random matches, and calculate precision/recall metrics.

2. **External Dependency Robustness Testing**: Test CCCI on a multi-project Java codebase with varying dependency quality levels: well-documented libraries, obfuscated production code, and mixed-quality open-source dependencies.

3. **Prompt Token Budget Sensitivity**: Systematically truncate hierarchical context from the prompt in layers and measure when Build Pass rate drops below 25%.