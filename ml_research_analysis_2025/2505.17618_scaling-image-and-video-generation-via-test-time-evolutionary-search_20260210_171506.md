---
ver: rpa2
title: Scaling Image and Video Generation via Test-Time Evolutionary Search
arxiv_id: '2505.17618'
source_url: https://arxiv.org/abs/2505.17618
tags:
- evosearch
- arxiv
- generation
- diffusion
- scaling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EvoSearch, a test-time scaling framework that
  treats denoising in diffusion and flow models as an evolutionary search problem.
  By leveraging specialized selection and mutation mechanisms along the denoising
  trajectory, EvoSearch iteratively improves sample quality without additional training.
---

# Scaling Image and Video Generation via Test-Time Evolutionary Search

## Quick Facts
- arXiv ID: 2505.17618
- Source URL: https://arxiv.org/abs/2505.17618
- Reference count: 40
- Primary result: EvoSearch achieves consistent improvements across image and video generation tasks, enabling SD2.1 to surpass GPT-4o and Wan 1.3B to outperform the 10× larger Wan 14B model

## Executive Summary
This paper proposes EvoSearch, a test-time scaling framework that treats denoising in diffusion and flow models as an evolutionary search problem. By leveraging specialized selection and mutation mechanisms along the denoising trajectory, EvoSearch iteratively improves sample quality without additional training. Experiments show EvoSearch consistently outperforms baselines across image and video generation tasks, achieving higher diversity and better generalization to unseen metrics. Notably, it enables SD2.1 to surpass GPT-4o and allows Wan 1.3B to outperform the 10× larger Wan 14B model with equivalent inference time.

## Method Summary
EvoSearch transforms diffusion and flow model sampling into an evolutionary search problem by treating the denoising trajectory as a search space. The method uses a population of latent states evolved through selection and mutation at scheduled timesteps. For flow models, it converts deterministic ODE sampling to stochastic SDE sampling to enable exploration. At each evolution step, candidates are evaluated by fully denoising to x₀ and computing rewards. Tournament selection preserves elite candidates while mutation generates novel states—using Gaussian-preserving mutation for initial noise and SDE-based mutation for intermediate states. The population progresses along the trajectory, caching intermediate states to avoid redundant computation.

## Key Results
- EvoSearch consistently outperforms Best-of-N and Particle Sampling baselines across image and video generation tasks
- SD2.1 achieves higher ImageReward than GPT-4o while maintaining better diversity
- Wan 1.3B surpasses the 10× larger Wan 14B model in human evaluation with equivalent inference time
- Better generalization to unseen metrics compared to baselines that over-optimize specific rewards

## Why This Works (Mechanism)

### Mechanism 1: Active State Space Exploration via Evolutionary Operators
EvoSearch achieves higher sample quality than passive filtering by actively generating novel candidate states through mutation rather than being constrained to a fixed initial candidate pool. At each evolution step, the algorithm preserves elite candidates while mutating remaining candidates to explore neighboring regions in latent space. For initial Gaussian noise: `x_child = √(1-β²)·x_parent + β·ε` preserves high-reward region density while adding controlled exploration. For intermediate states: `x_child = x_parent + σ_t·ε` uses the SDE diffusion coefficient to inject stochasticity proportional to the denoising stage. The method relies on local smoothness in reward landscapes—high-quality samples form discoverable regions rather than isolated points.

### Mechanism 2: Dynamic Population Movement Along Denoising Trajectory
The framework progressively advances the evolution schedule from initial noise toward later denoising steps, reducing redundant computation while maintaining search effectiveness. Evolution schedule T specifies checkpoint timesteps, and after optimizing x_T, subsequent generations start from cached intermediate states x_{t_i} rather than re-denoising from scratch. This "moving forward" approach enables each subsequent generation to begin directly from the cached intermediate state, eliminating redundant denoising computations. Early denoising steps have greater influence on final output quality, making computation investment more efficient at the beginning of the trajectory.

### Mechanism 3: Unified SDE Framework via ODE-to-SDE Transformation
Converting deterministic flow model sampling (ODE) to stochastic sampling (SDE) enables application of test-time search methods that require stochasticity for exploration. The flow ODE `dx_t = u_t(x_t)dt` is reformulated as SDE `dx_t = [u_t(x_t) - σ²_t/2 · ∇log p_t(x_t)]dt + σ_t·dw`, where dw injects stochasticity at each step. This transformation unifies diffusion and flow models under a common stochastic framework, allowing the same evolutionary operators to be applied across architectures. The method relies on accurate score function computation from the learned velocity for practical sampling.

## Foundational Learning

- **Concept: Stochastic Differential Equations in Diffusion Models**
  - **Why needed here:** Understanding how SDE formulation enables stochastic sampling in both diffusion and flow models is essential for grasping why mutation operations work and how ODE-to-SDE transformation functions.
  - **Quick check question:** Can you explain why adding a Brownian motion term (dw) to a deterministic ODE creates opportunities for exploration that weren't possible before?

- **Concept: Evolutionary Algorithm Operators (Selection, Mutation, Elitism)**
  - **Why needed here:** EvoSearch adapts classic EA operators to the denoising domain. Tournament selection maintains diversity; elitism preserves best solutions; mutation must be designed differently for Gaussian noise vs. intermediate denoising states.
  - **Quick check question:** Why does preserving m elite parents help prevent premature convergence, and why might the optimal mutation rate differ between x_T (Gaussian) and x_t (partially denoised)?

- **Concept: Test-Time Scaling and Reward Over-Optimization**
  - **Why needed here:** The paper positions EvoSearch against methods that suffer from reward hacking/mode collapse. Understanding why passive filtering (Best-of-N) and fixed-pool resampling (Particle Sampling) have exploration limitations clarifies the design motivation.
  - **Quick check question:** If a test-time scaling method achieves very high reward scores but low diversity (measured by L2 distance in CLIP feature space), what failure mode has likely occurred?

## Architecture Onboarding

- **Component map:**
  EvoSearch Framework -> Initialization Module -> Sample k_start Gaussian noises {x_i^T}
  EvoSearch Framework -> Evolution Loop (at each t ∈ T) -> Fitness Evaluation: Denoise → x_0 → Reward(x_0) -> Selection: Tournament selection + Elite preservation (m candidates) -> Mutation: If generation=0: Gaussian-preserving (Eq. 7) Else: SDE-based (Eq. 8) -> Continue denoising children
  EvoSearch Framework -> Denoising Engine -> Diffusion models: DDIM scheduler -> Flow models: sde-dpmsolver++ (ODE-to-SDE transformed)
  EvoSearch Framework -> Reward Module (plug-in) -> ImageReward, ClipScore, VideoReward, etc.

- **Critical path:**
  1. Implement ODE-to-SDE transformation for flow models (verify stochasticity is injected correctly)
  2. Implement mutation operators separately for initial noise vs. intermediate states (verify Gaussian property is preserved for Eq. 7)
  3. Implement tournament selection with elite preservation (verify population diversity doesn't collapse)
  4. Implement evolution schedule with state caching (verify redundant computation is eliminated)
  5. Integrate reward model for fitness evaluation (verify evaluated on fully denoised x_0, not predicted)

- **Design tradeoffs:**
  - **Population size (k_start vs. later k_t):** Paper finds k_start has larger impact—allocate more compute to early generations
  - **Evolution schedule granularity:** Uniform intervals work well; more checkpoints increase compute linearly but with diminishing returns
  - **Mutation rate (β, σ_t):** Higher rates expand search space but risk destroying useful parent information; paper uses β=0.3
  - **Elite size (m):** Too few elites → premature convergence; too many → reduced exploration (m ≪ k_t, exact value not specified)
  - **Reward model choice:** Training-aligned rewards may over-optimize; paper shows better generalization to unseen metrics than baselines

- **Failure signatures:**
  - **Mode collapse:** All outputs converge to similar images despite different prompts → mutation rate too low or elite size too large
  - **Quality degradation with scaling:** Performance decreases as NFEs increase → reward over-optimization; check diversity metrics (L2 distance in CLIP space)
  - **No improvement over baseline:** Evolution not occurring → check if mutation is actually being applied; verify tournament selection is stochastic, not deterministic
  - **Compute explosion:** Inference time exceeds reasonable bounds → check state caching is working; verify not re-denoising from x_T at each generation
  - **Flow model incompatibility:** Method doesn't work on flow models → verify ODE-to-SDE transformation; check σ_t values in scheduler

- **First 3 experiments:**
  1. **Sanity check on small-scale:** Implement on SD2.1 with simple reward (ImageReward), T={50, 40, 30}, K={20, 10, 10}, 10 prompts from DrawBench. Compare: (a) baseline (no scaling), (b) Best-of-N with equivalent NFEs, (c) EvoSearch. Verify EvoSearch achieves higher reward with similar or better diversity.
  2. **Ablation on mutation rate:** Test β ∈ {0.1, 0.3, 0.5, 0.7} on 50 prompts. Plot reward vs. diversity (CLIP L2 distance). Identify optimal β that balances quality and diversity (paper uses 0.3 but optimal may depend on model/reward).
  3. **Cross-architecture validation:** Apply to a flow model (Flux.1-dev if available, or another rectified flow model) with ODE-to-SDE transformation. Compare performance to diffusion model results. Verify the framework generalizes across architectures as claimed.

## Open Questions the Paper Calls Out

- **Can incorporating prior knowledge into mutation strategies improve search efficiency beyond random Gaussian noise?**
  - **Basis:** The authors state in the "Limitations and Future Work" section that "developing more informative mutation strategies with prior knowledge can further improve the search efficiency."
  - **Why unresolved:** The current implementation relies on unstructured Gaussian noise ($\epsilon \sim \mathcal{N}(0, I)$) for mutation, which treats all directions in the latent space equally without utilizing structural information.
  - **What evidence would resolve it:** A comparative study demonstrating that a mutation strategy based on data-driven priors (e.g., manifold constraints) achieves equivalent or higher reward scores with significantly fewer Neural Function Evaluations (NFEs) than the random baseline.

- **What is the shared geometric or structural relationship between "golden noises" (high-reward initial noises) and high-reward intermediate denoising states?**
  - **Basis:** The authors identify "understanding the shared structure between golden noises and intermediate denoising states" as a promising future direction in the conclusion.
  - **Why unresolved:** While the paper observes local similarity in rewards (via Moran's I and t-SNE), the precise mechanism connecting the quality of the initial Gaussian noise to the quality of intermediate states remains empirically observed but theoretically unclear.
  - **What evidence would resolve it:** A theoretical analysis or quantitative metric that successfully predicts the trajectory quality of intermediate states based solely on the properties of the initial noise distribution.

- **How can intermediate denoising states be interpreted to explain the success or failure of specific evolutionary trajectories?**
  - **Basis:** The authors note that "The inherent complexity of interpreting denoising states makes it an interesting open research question."
  - **Why unresolved:** The high dimensionality of the latent space makes it difficult to semantically understand why a specific mutation leads to a higher fitness score, limiting the ability to debug or refine the evolutionary process heuristically.
  - **What evidence would resolve it:** The development of visualization techniques or attribution methods that map specific features in the intermediate state $x_t$ to the predicted reward, allowing for targeted intervention rather than stochastic search.

## Limitations

- The evolutionary framework relies on the assumption that reward landscapes in diffusion/flow latent spaces exhibit sufficient spatial autocorrelation for mutation-based exploration to be effective
- The ODE-to-SDE transformation assumes accurate score estimation from velocity, which may not hold for all flow model implementations
- The optimal mutation rates (β=0.3 for initial noise, σ_t for intermediate states) are empirical choices that may not generalize across all model architectures or reward functions

## Confidence

- **High confidence**: The core evolutionary search framework works as described, demonstrated by consistent improvements across multiple image and video models (SD2.1, Wan 1.3B, Flux.1-dev) and metrics (ImageReward, ClipScore, VideoReward, HPSv2)
- **Medium confidence**: Claims about SD2.1 surpassing GPT-4o and Wan 1.3B outperforming 10× larger Wan 14B are supported by quantitative results but depend on specific reward model versions and evaluation protocols that are not fully specified
- **Medium confidence**: The assertion that EvoSearch enables "better generalization to unseen metrics" is supported by the diversity maintenance analysis but requires further validation across truly unseen evaluation criteria

## Next Checks

1. **Landscape correlation analysis**: Systematically measure Moran's I and other spatial autocorrelation metrics across different diffusion models, denoising schedules, and reward functions to quantify when evolutionary exploration is expected to succeed or fail

2. **Mutation rate sensitivity**: Conduct comprehensive ablation studies varying β and σ_t across multiple orders of magnitude to identify robust parameter ranges and test the claim that 0.3 is near-optimal

3. **Cross-architecture stress test**: Apply EvoSearch to additional flow models beyond Flux.1-dev and test on reward functions not used during development to validate generalization claims and identify architecture-specific failure modes