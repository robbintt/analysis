---
ver: rpa2
title: Effects of Gabor Filters on Classification Performance of CNNs Trained on a
  Limited Number of Conditions
arxiv_id: '2601.11918'
source_url: https://arxiv.org/abs/2601.11918
tags:
- gabor
- cnns
- filters
- images
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the impact of Gabor filter preprocessing
  on the classification accuracy of CNNs trained on limited datasets. The motivation
  was to improve accuracy and reduce the size of CNNs for edge devices in robot vision
  applications, where training data is limited due to variations in object appearance
  from different camera positions, distances, and lighting conditions.
---

# Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions

## Quick Facts
- arXiv ID: 2601.11918
- Source URL: https://arxiv.org/abs/2601.11918
- Reference count: 15
- Primary result: Gabor preprocessing improved accuracy by ~7% for AlexNet and reduced required CNN depth under limited training data

## Executive Summary
This study investigated whether Gabor filter preprocessing could improve CNN classification accuracy when trained on limited datasets captured from varying camera distances. The motivation stems from robot vision applications where training data is scarce due to object appearance variations from different viewing conditions. Gabor filters, inspired by biological visual systems, were used to extract orientation, scale, and phase features before CNN processing. Results showed that multi-scale Gabor preprocessing improved classification accuracy, particularly for shallower networks like AlexNet, suggesting the filters can enhance generalization and reduce required CNN depth when training data is limited.

## Method Summary
The method involves preprocessing grayscale input images with Gabor filter banks (4 orientations × 1-2 scales × 1-2 phases), followed by rectification (separating positive and negative filter responses), and standardization before feeding into standard CNN architectures (ResNet18, MobileNetV2, AlexNet). The experimental setup uses a custom 8400-image dataset of 10 objects captured from different camera distances, with models trained on specific distances and tested on unseen distances to evaluate generalization. Training uses SGD with cosine decay for 50 epochs with standard augmentations.

## Key Results
- Multi-scale Gabor preprocessing improved AlexNet accuracy by ~7% (68.59% vs 61.92% baseline)
- Gabor preprocessing shifted peak classification accuracy to earlier network layers, suggesting architectural depth compensation
- Effects were most pronounced for shallower networks (AlexNet) with minimal impact on deeper architectures (ResNet18, MobileNetV2)

## Why This Works (Mechanism)

### Mechanism 1: Orientation-Selective Feature Extraction
- Claim: Gabor filters provide structured orientation-selective features that reduce the learning burden on early CNN layers.
- Mechanism: The filters enhance edge features at specific orientations (θ = 0, π/4, π/2, 3π/4) before CNN processing, analogous to primary visual cortex simple cells. This explicit extraction allows CNNs to receive partially-processed features rather than raw pixels.
- Core assumption: Orientation features are fundamental to object discrimination and are learned more efficiently when provided explicitly rather than learned from scratch under data scarcity.

### Mechanism 2: Multi-Scale Phase-Orthogonal Feature Enhancement
- Claim: Combining Gabor filters with orthogonal phases (0, π/2) and multiple scales (σ values) improves feature discriminability over single-filter approaches.
- Mechanism: Orthogonal phases capture both light-to-dark and dark-to-light edge transitions; multi-scale captures spatial frequency variations. The rectification step separates positive and negative filter responses.
- Core assumption: Objects present discriminative features at multiple spatial frequencies that single-scale approaches incompletely capture.

### Mechanism 3: Architectural Depth Compensation
- Claim: Gabor preprocessing shifts peak discriminability to shallower layers, potentially enabling smaller CNNs to match deeper network performance under limited training conditions.
- Mechanism: Pre-extracted orientation/scale features increase effective representational capacity at earlier layers. The linear SVM probe analysis shows comparable accuracy achieved 1-2 blocks earlier in ResNet18 with Gabor preprocessing.
- Core assumption: Early CNN layers trained on limited data inadequately learn orientation features; explicit provision bypasses this learning bottleneck.

## Foundational Learning

- **Gabor Filter Parameters (σ, λ, θ, ϕ)**
  - Why needed here: The paper's configurations differ only in these parameters; understanding their effects is essential for reproduction and extension.
  - Quick check question: Which parameter controls orientation selectivity, and which controls spatial frequency?

- **Feature Hierarchy in CNNs**
  - Why needed here: The depth compensation mechanism relies on understanding how features evolve across layers and why early layers matter for limited-data scenarios.
  - Quick check question: Why might early CNN layers fail to learn adequate orientation features when training data is limited?

- **Generalization Under Covariate Shift**
  - Why needed here: The evaluation explicitly tests generalization from training distances to unseen test distances—a form of covariate shift.
  - Quick check question: Why does training on images from one camera distance not guarantee performance at other distances?

## Architecture Onboarding

- **Component map:**
  Input (grayscale) → Gabor filter bank (4 orientations × 1-2 scales × 1-2 phases) → Rectification (positive/negative separation) → Standardization → CNN backbone → Classification head

- **Critical path:**
  1. Configure Gabor parameters (σ, λ, θ, ϕ) per Table I
  2. Apply filters to extract orientation features
  3. Rectify and standardize outputs before CNN input layer
  4. Train CNN on preprocessed data from limited conditions

- **Design tradeoffs:**
  - More orientations/scales → better accuracy but increased preprocessing computation and channel count
  - Fixed Gabor filters → no learning required, but may not adapt to domain-specific features (corpus suggests learnable filterbanks may offer advantages)
  - Grayscale input → loses color information but simplifies preprocessing

- **Failure signatures:**
  - No accuracy improvement on deeper architectures (ResNet18, MobileNetV2)—suggests architecture already has sufficient capacity
  - Inconsistent results across training distance conditions—may indicate filter parameters not tuned for specific scale range
  - Worse performance than baseline—possible over-regularization or inappropriate filter parameters for target domain

- **First 3 experiments:**
  1. Replicate Table IV results on the distance-limited dataset using AlexNet with and without multi-scale Gabor preprocessing to validate the claimed ~7% average improvement.
  2. Ablate individual filter configurations (single-scale vs multi-scale; single-phase vs dual-phase) to isolate contribution of each component.
  3. Test on out-of-distribution conditions (different lighting, not just different distances) to evaluate whether Gabor preprocessing generalizes beyond the specific covariate shift tested in the paper.

## Open Questions the Paper Calls Out

- **Open Question 1**
  - Question: Does Gabor filter preprocessing maintain its generalization benefits when applied to datasets with significant lighting variations?
  - Basis in paper: [inferred] The introduction identifies lighting as a major factor altering object appearance in real-world robot vision, but the experiment restricted data acquisition to a "simple darkroom," leaving this specific condition untested.
  - Why unresolved: The study isolated camera distance as the variable, so it is unclear if the extracted orientation features are robust against the shadows and contrast changes common in uncontrolled environments.
  - What evidence would resolve it: A replication of the experiment using the same distance-constrained dataset but with variable lighting intensities and angles.

- **Open Question 2**
  - Question: To what extent does increasing the diversity of Gabor filter phases and scales beyond the tested sets improve generalization?
  - Basis in paper: [explicit] The conclusion notes that neurons responding to "various scales and various phases" exist in the visual nervous system and suggests that "simulating this property could help CNNs achieve the strengths of the VNS."
  - Why unresolved: The study tested a limited set of parameters (two phases, two scales); it is unknown if a denser or more biologically accurate filter bank would yield significant accuracy gains or merely increase computational cost.
  - What evidence would resolve it: Comparative trials expanding the filter bank (e.g., 4 phases, 4 scales) on the same limited dataset to measure the marginal utility of additional filters.

- **Open Question 3**
  - Question: Is the effectiveness of Gabor preprocessing dependent on the specific architectural depth or inductive bias of the CNN used?
  - Basis in paper: [inferred] The results showed distinct improvements for AlexNet (shallow) but negligible differences for ResNet18 and MobileNetV2 (deep), suggesting the preprocessing may be redundant for architectures with strong built-in feature extraction.
  - Why unresolved: The paper does not determine if the lack of improvement in deeper models is due to the saturation of features or the inability of those specific architectures to utilize the fixed Gabor features effectively.
  - What evidence would resolve it: An ablation study analyzing the feature similarity between early convolutional layers of deep nets and the Gabor filters to confirm redundancy.

## Limitations
- Custom dataset not publicly available, preventing exact replication of results
- Fixed Gabor filter parameters may not generalize across different domains
- Limited evaluation to camera distance variations without testing other domain shifts

## Confidence
- **High confidence**: The mechanism of orientation-selective feature extraction (Mechanism 1) is well-supported by biological evidence and the observed accuracy improvements, particularly for shallower architectures like AlexNet.
- **Medium confidence**: The multi-scale phase-orthogonal enhancement (Mechanism 2) shows empirical support in the AlexNet results but lacks direct validation in related literature and may be architecture-dependent.
- **Low confidence**: The architectural depth compensation claim (Mechanism 3) relies heavily on the linear SVM probe analysis, which provides indirect evidence. The observed shift in accuracy peaks requires further validation across diverse architectures.

## Next Checks
1. **Dataset reproduction**: Attempt to recreate the experimental conditions using publicly available datasets (e.g., MNIST, CIFAR) by simulating distance-based domain shift through controlled image transformations, to verify the ~7% accuracy improvement trend.
2. **Parameter sensitivity analysis**: Systematically vary Gabor filter parameters (σ, λ, θ) and evaluate their impact on classification accuracy across different architectures to identify optimal configurations for various object types and scales.
3. **Cross-domain generalization**: Evaluate the preprocessing pipeline on additional domain shift scenarios including lighting variations, occlusion patterns, and sensor noise to determine whether the benefits extend beyond the camera distance scenario tested in the paper.