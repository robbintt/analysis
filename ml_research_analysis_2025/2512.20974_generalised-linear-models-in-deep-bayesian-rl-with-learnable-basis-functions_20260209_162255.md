---
ver: rpa2
title: Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions
arxiv_id: '2512.20974'
source_url: https://arxiv.org/abs/2512.20974
tags:
- glibrl
- learning
- methods
- deep
- bayesian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a deep Bayesian reinforcement learning method
  called GLiBRL, which uses learnable basis functions to enable efficient and accurate
  learning of transition and reward models with fully tractable marginal likelihood
  and Bayesian inference. The key idea is to model the transition and reward functions
  as generalized linear models, where the basis functions are learned from the data.
---

# Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions

## Quick Facts
- **arXiv ID:** 2512.20974
- **Source URL:** https://arxiv.org/abs/2512.20974
- **Reference count:** 40
- **Primary result:** GLiBRL improves VariBAD success rate by up to 2.7x on MetaWorld ML10/45 benchmarks using learnable basis functions and exact marginal likelihood optimization.

## Executive Summary
This paper introduces GLiBRL, a deep Bayesian reinforcement learning method that uses learnable basis functions to enable efficient and accurate learning of transition and reward models with fully tractable marginal likelihood and Bayesian inference. The key innovation is modeling transition and reward functions as generalized linear models where basis functions are learned from data, avoiding the need to optimize the challenging evidence lower bound (ELBO) used in other deep BRL methods. GLiBRL is evaluated on challenging MetaWorld ML10/45 benchmarks and demonstrates substantial improvements over state-of-the-art deep BRL methods, including VariBAD, MAML, RL2, SDVT, TrMRL, and ECET.

## Method Summary
GLiBRL models transition and reward functions as generalized linear models with learnable basis functions φ_T and φ_R that project raw states and actions into feature spaces. The method uses Normal-Wishart priors conjugate to matrix normal likelihoods, enabling closed-form Bayesian inference without Monte Carlo sampling. The exact marginal log-likelihood is optimized directly rather than using ELBO, and model noise parameters are inferred as random variables rather than fixed hyperparameters. The policy network takes the flattened posterior parameters as input and is trained jointly with the basis functions using PPO. Task dimensions are D_T=16 and D_R=256, with regularization parameters λ_T=5e-3 and λ_R=1e-3.

## Key Results
- GLiBRL improves VariBAD success rate by up to 2.7x on MetaWorld ML10/45 benchmarks
- Achieves consistent outperformance over representative deep BRL and meta-RL methods including MAML, RL2, SDVT, TrMRL, and ECET
- Dynamic noise inference reduces L1 prediction errors compared to fixed-noise ablation
- Maintains low prediction errors while improving task performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If transition and reward dynamics can be mapped to a linear feature space, GLiBRL enables closed-form Bayesian inference without Monte Carlo sampling.
- **Mechanism:** The architecture uses neural networks (φ_T, φ_R) as "learnable basis functions" to project raw states and actions into feature matrices (C_T, C_R). By treating the relationship between these features and task parameters (θ) as a GLM with Matrix Normal likelihood, the system utilizes Normal-Wishart conjugate priors to compute posterior updates and marginal likelihood analytically.
- **Core assumption:** The complex non-linearities of the environment can be sufficiently captured by the basis functions such that the remaining relationship to task parameters is linear.
- **Evidence anchors:** Abstract states "enables efficient and accurate learning... with fully tractable marginal likelihood"; section 3.1 states "place Normal-Wishart priors conjugate to matrix normals on θ_T, θ_R for tractable inference".
- **Break condition:** If basis functions fail to linearize the problem, conjugate prior assumptions may lead to overconfident or incorrect posteriors.

### Mechanism 2
- **Claim:** Optimizing the exact marginal likelihood mitigates "posterior collapse" and high-variance gradient issues associated with ELBO optimization.
- **Mechanism:** Unlike Variational BRL methods that maximize ELBO requiring approximate sampling, GLiBRL directly maximizes exact log marginal likelihood. This explicitly measures how well the model explains data, avoiding amortization gaps and high-variance estimates inherent in ELBO optimization.
- **Core assumption:** The exact marginal likelihood landscape is navigable via standard gradient descent and offers better training signal than ELBO surrogate.
- **Evidence anchors:** Abstract states "avoids the need to optimize the challenging evidence lower bound (ELBO)"; section 4 states "ELBOs are difficult to optimise and may result in indistinctive task parameters".
- **Break condition:** If dataset size scales massively, computing exact likelihood might become bottleneck compared to stochastic variational methods.

### Mechanism 3
- **Claim:** Inferring model noise as random variable (Bayesian inference) rather than fixed hyperparameter improves predictive accuracy on unseen tasks.
- **Mechanism:** GLiBRL places Wishart distribution on noise parameters (T_σ, R_σ), allowing dynamic adaptation of uncertainty estimation as data arrives, unlike fixed-noise models which use static learning rate equivalent.
- **Core assumption:** Environment noise is not constant across tasks or time steps and benefits from online estimation.
- **Evidence anchors:** Section 5.4 states "GLiBRL performs Bayesian inference on model noises... which has been shown empirically to reduce the error of prediction"; figure 2 shows GLiBRL achieving lower L1 prediction errors.
- **Break condition:** If data is extremely sparse, noise inference might overfit to outliers or fail to converge to sensible values.

## Foundational Learning

- **Concept:** **Conjugate Priors (Normal-Wishart)**
  - **Why needed here:** The core innovation is avoiding iterative sampling. Understanding how Normal-Wishart priors combine with Gaussian likelihoods to produce closed-form posteriors is necessary to comprehend Equations 9-13.
  - **Quick check question:** Can you derive the posterior distribution for a Gaussian mean with unknown variance using a Normal-Wishart prior?

- **Concept:** **Bayes-Adaptive MDPs (BAMDPs)**
  - **Why needed here:** The agent operates in augmented state space (S × B) where "belief" is statistical distribution. Understanding that policy depends on this belief state is crucial for Algorithm 1.
  - **Quick check question:** How does dimensionality of belief state b_t affect input complexity of policy network π^+_ψ?

- **Concept:** **Basis Function Regression**
  - **Why needed here:** The method relies on mapping inputs to feature space where linear regression solves task.
  - **Quick check question:** If neural network φ stops gradients, how would that affect learning of basis functions?

## Architecture Onboarding

- **Component map:** Raw states/actions -> Feature Networks (φ_T, φ_R) -> Feature Matrices (C_T, C_R) -> Bayesian Layer -> Posterior Parameters -> Policy Network (π^+_ψ) -> Actions
- **Critical path:** The gradient flow from marginal log-likelihood loss (Eq. 15) back through basis functions φ. If regularization λ is too high, basis functions will output near-zeros, flattening likelihood and stalling learning.
- **Design tradeoffs:**
  - Task Dimensionality (D_T, D_R): Higher dimensions (e.g., 256) lower prediction error but increase compute cost of matrix inversions (O(D²)) during online belief updates.
  - Regularization: Essential to prevent unbounded basis function values, but excessive regularization reduces model's expressiveness.
- **Failure signatures:**
  - Instability in Prediction Error: If "GLiBRL wo NI" baseline outperforms full model, check initialization of Wishart degrees of freedom (ν).
  - Posterior Collapse: If KL divergence between posteriors and priors approaches 0 early in training, basis functions may be insufficient to distinguish tasks.
- **First 3 experiments:**
  1. Sanity Check (Toy Data): Verify closed-form update equations by fitting known linear function with synthetic data to ensure analytic gradients match numerical gradients.
  2. Basis Function Visualization: Visualize outputs of φ_T on simple MetaWorld task (e.g., reaching) to ensure they discriminate states meaningfully rather than outputting zeros.
  3. Ablation on Noise: Replicate comparison in Section 5.4 (Fixed Noise vs. Inferred Noise) on single environment to verify dynamic noise inference actually lowers L1 prediction error.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on successful linearization through learned basis functions is significant constraint - if basis functions fail to capture true non-linearities, closed-form inference will produce incorrect posteriors
- Claim of computational efficiency over ELBO-based methods is not empirically validated - paper doesn't compare training times or sample complexities
- Method appears sensitive to initialization and regularization parameters (λ_T, λ_R, ν priors), though ablation studies on these hyperparameters are absent

## Confidence
- **High confidence** in mathematical correctness of GLM framework and closed-form updates (Equations 9-15)
- **Medium confidence** in MetaWorld results due to strong empirical performance and multiple ablations, but lacking comparison of computational efficiency
- **Low confidence** in claim of avoiding ELBO optimization issues without direct comparison to VariBAD's training dynamics and posterior collapse

## Next Checks
1. **Robustness to Initialization:** Systematically vary initialization of M_T, M_R, and degrees of freedom ν_T, ν_R to test sensitivity to prior specification
2. **Computational Benchmarking:** Measure wall-clock time per training iteration and total training time for GLiBRL vs. VariBAD and other baselines on same hardware
3. **Basis Function Visualization:** For simple MetaWorld task (e.g., reach-v0), visualize learned feature representations from φ_T and φ_R to confirm they discriminate states and actions meaningfully rather than collapsing to uninformative patterns