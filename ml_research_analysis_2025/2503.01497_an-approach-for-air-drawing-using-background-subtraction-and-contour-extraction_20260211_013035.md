---
ver: rpa2
title: An Approach for Air Drawing Using Background Subtraction and Contour Extraction
arxiv_id: '2503.01497'
source_url: https://arxiv.org/abs/2503.01497
tags:
- image
- drawing
- background
- pointer
- position
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an image processing-based approach for air
  drawing using background subtraction and contour extraction. The method addresses
  the problem of detecting pointer positions in the air for drawing applications without
  requiring sensor-based devices.
---

# An Approach for Air Drawing Using Background Subtraction and Contour Extraction

## Quick Facts
- arXiv ID: 2503.01497
- Source URL: https://arxiv.org/abs/2503.01497
- Reference count: 5
- Key outcome: Image processing-based air drawing method achieving 100ms latency (50ms faster than sensor-based), with 98% OCR accuracy

## Executive Summary
This paper presents an image processing-based approach for air drawing that tracks finger/hand position in webcam frames using background subtraction and contour extraction. The method avoids sensor-based devices by using a webcam feed at 28 FPS, preparing a background model from the first 100-150 frames, and identifying pointer position as the topmost point of the largest contour. Hand detection using Haar cascades filters false contours. The system supports multiple operational modes including drawing, erasing, color selection, and text detection via OCR integration with Tesseract. While offering a simpler and cheaper alternative to sensor-based approaches with faster latency, the method remains sensitive to environmental noise and camera movement.

## Method Summary
The approach initializes by capturing 100-150 frames to create a running average background model using dst(x,y) = (1-α)·dst(x,y) + α·src(x,y) with α=0.8. For each live frame, a Haar cascade hand detector scans the ROI; if hand is detected, background subtraction is performed and the resulting image is thresholded into a binary mask. Contours are extracted from this mask, and the pointer position is determined as the topmost point of the largest contour, transformed to canvas coordinates. The system operates in multiple modes including draw, erase, move, color selection, clear, save, and detect (OCR). OCR integration uses Tesseract for text detection with 98% accuracy, and the optimal pointer diameter is determined to be 4 pixels for the 420×720 frame resolution.

## Key Results
- Latency of 100ms achieved, 50ms faster than sensor-based methods
- OCR text detection accuracy of 98% when using 4-pixel pointer diameter
- Optimal background model achieved with 100-150 frame initialization window
- System enables real-time air drawing with multiple operational modes

## Why This Works (Mechanism)

### Mechanism 1: Running Average Background Modeling
Accumulating a temporal average of initial frames creates a static background reference that, when subtracted from live frames, isolates moving foreground elements (the hand). The system computes a weighted running average over the first 100-150 frames using dst(x, y) = (1 − α) ∗ dst(x, y) + α ∗ src(x, y) with α = 0.8. This background model is then subtracted from incoming frames to produce a residual image, which is thresholded into a binary mask.

### Mechanism 2: Contour Top-Point as Pointer Proxy
The topmost point of the largest contour in the binary mask serves as a computationally cheap proxy for fingertip position. After thresholding, contours are extracted from the binary image. The contour with the largest area is selected, and its topmost pixel (minimum y-coordinate) is transformed to canvas coordinates via linear scaling.

### Mechanism 3: Haar Cascade Pre-filtering for False Contour Suppression
Pre-validating hand presence with a Haar cascade classifier reduces spurious contours from non-hand motion. Before contour extraction, a Haar cascade scans the ROI. Contour processing proceeds only if a hand is detected, filtering noise from shadows or background motion.

## Foundational Learning

### Concept: Background Subtraction (Running Average Method)
- Why needed here: Core to foreground isolation; understanding how α and frame count affect noise sensitivity is essential for tuning
- Quick check question: If lighting changes after background initialization, will the pre-computed model still produce clean binary masks? Why or why not?

### Concept: Contour Extraction and Selection
- Why needed here: Pointer position depends entirely on correct contour detection and the largest-area heuristic
- Quick check question: Given a binary mask with three contours of areas 500, 1200, and 300 pixels, which is selected as the pointer and how is its position determined?

### Concept: Haar Cascade Limitations
- Why needed here: Acts as the gatekeeper; understanding its failure modes helps diagnose unresponsive drawing
- Quick check question: What hand orientations or lighting conditions might cause a Haar cascade to fail detection?

## Architecture Onboarding

### Component Map:
Webcam (28 FPS, 420×720) → ROI Extraction → [Modes ROI] + [Drawing ROI] → Initialization (100–150 frames) → Running Average → Background Model → (per frame, after init) Haar Cascade Hand Detector → (hand detected?) Background Subtraction → Binary Threshold → Contour Extraction → Largest Contour → Top Point → Coordinate Transform → Canvas + VUI Mode Handler (Draw/Erase/Move/Color/Clear/Save/Detect) → (Detect mode) Tesseract OCR

### Critical Path:
1. Background model initialization (frames 1–150) → Must complete before drawing begins
2. Haar detection → Background subtraction → Contour extraction → Pointer transform → Canvas render

### Design Tradeoffs:
- Speed vs. Robustness: 100ms latency (50ms faster than sensor-based per paper) traded against sensitivity to noise and camera movement
- Haar vs. Modern Hand Detectors: Haar is cheap but less robust than Mediapipe (mentioned in conclusion as alternative for moving cameras)
- Pointer Size: 4 pixels optimal for 420×720 frame; smaller degrades OCR, larger reduces precision

### Failure Signatures:
- No drawing despite hand motion: Haar cascade failing → Check lighting, hand orientation, cascade confidence threshold
- Spurious marks on canvas: Corrupted background model → Check for camera movement or dynamic background elements
- OCR accuracy degradation: Pointer size mismatch → Validate 4-pixel diameter for current frame dimensions

### First 3 Experiments:
1. Baseline calibration test: Run through 150-frame initialization; verify background model captures static ROI; test drawing registration
2. Haar rejection test: Introduce non-hand objects (cups, books) into ROI; verify cascade suppresses drawing. Test multiple hand orientations for detection reliability
3. Noise sensitivity test: After calibration, introduce controlled lighting changes and small camera shifts; document threshold at which binary mask quality degrades

## Open Questions the Paper Calls Out

### Open Question 1
How does the integration of hand landmark detection (specifically Mediapipe) affect the system's stability and accuracy when the camera is moving or the background is non-static? The authors explicitly state that the current approach "comes short with a noisy environment and moving camera" and note that "the solution to hand tracking on moving cameras using hand landmark detection is publicly available by Mediapipe." This remains unresolved as they propose the current static-background method as a simpler, cheaper alternative but acknowledge this specific failure case without implementing or testing the cited solution.

### Open Question 2
To what extent does combining image completion models with the current contour extraction method improve the continuity and recognition accuracy of air-drawn characters? The conclusion states that "by combining state-of-the-art models like image completion, our approach has the potential to open new applications for air drawing." The authors identify image completion as a potential enhancement to handle the disjointed nature of raw contour drawing, but they do not implement or validate this integration in the current study.

### Open Question 3
Can adaptive background subtraction algorithms maintain real-time latency (approx. 100ms) while effectively filtering out environmental noise such as lighting changes or shadows? The paper notes the system is "sensitive to environmental noise" and relies on a running average with a fixed weight (α=0.8) for background preparation. It is unclear if a more robust, adaptive background model could be employed without breaking the 100ms latency constraint.

### Open Question 4
What is the mathematical relationship between pointer diameter, frame resolution, and OCR detection accuracy? The authors mention that "detection is related to the size of the pointer" and identify "4 pixels of pointer diameter" as the best fit for a specific resolution, but they do not generalize this finding. The pointer size is treated as a heuristic determined by experiment for a specific frame dimension (420, 720), leaving the optimal configuration for higher resolutions or different screen sizes undefined.

## Limitations
- Background model sensitivity to camera movement and dynamic lighting changes
- Haar cascade reliability issues with varying hand orientations and lighting conditions
- Contour heuristic fragility with multiple hands or non-hand objects in frame

## Confidence

**High Confidence**:
- Core methodology description (running average BGS → contour extraction → pointer top-point)
- Reported latency (100ms) and comparison to sensor-based methods (50ms faster)
- Basic system architecture and operational modes

**Medium Confidence**:
- OCR accuracy claim (98%) - dependent on unstated Tesseract configuration and controlled drawing conditions
- Background subtraction noise reduction - mechanism described but not quantified across varying conditions
- Haar cascade effectiveness - described but lacks performance metrics or alternative validation

**Low Confidence**:
- Generalization to moving cameras (paper mentions Mediapipe as future alternative but doesn't validate current approach)
- Performance under varying lighting conditions
- Robustness to multiple hands or occlusions

## Next Checks

1. **Background Initialization Robustness Test**: Capture 150-frame background with a static setup, then introduce controlled camera shifts (1-5 pixels) and lighting changes. Document the threshold at which binary mask quality degrades and false contours appear.

2. **Haar Cascade Detection Coverage Test**: Systematically test the Haar cascade across a diverse set of hand images varying in size (10-200 pixels), orientation (0-180 degrees), and lighting (bright, dim, backlit). Record detection rate and false positive rate.

3. **Contour Heuristic Failure Analysis**: Create test scenarios with multiple hands, large objects (books, cups), and varying hand orientations. For each, record whether the correct fingertip position is identified as the topmost point of the largest contour.