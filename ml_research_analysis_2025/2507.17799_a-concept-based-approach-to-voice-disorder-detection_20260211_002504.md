---
ver: rpa2
title: A Concept-based approach to Voice Disorder Detection
arxiv_id: '2507.17799'
source_url: https://arxiv.org/abs/2507.17799
tags:
- concept
- voice
- concepts
- concept-based
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting voice disorders using
  deep learning models while maintaining interpretability, a critical requirement
  in healthcare applications. The authors propose using concept-based models, specifically
  Concept Bottleneck Models (CBM) and Concept Embedding Models (CEM), to classify
  pathological versus euphonic voices.
---

# A Concept-based approach to Voice Disorder Detection

## Quick Facts
- arXiv ID: 2507.17799
- Source URL: https://arxiv.org/abs/2507.17799
- Authors: Davide Ghia; Gabriele Ciravegna; Alkis Koudounas; Marco Fantini; Erika Crosetti; Giovanni Succo; Tania Cerquitelli
- Reference count: 40
- Primary result: Concept-based models achieve 87.76% (CBM) and 87.30% (CEM) accuracy for voice disorder detection while maintaining interpretability

## Executive Summary
This paper addresses the challenge of detecting voice disorders using deep learning models while maintaining interpretability, a critical requirement in healthcare applications. The authors propose using concept-based models, specifically Concept Bottleneck Models (CBM) and Concept Embedding Models (CEM), to classify pathological versus euphonic voices. These models incorporate interpretable concepts such as dysphonia levels, roughness, and breathiness, extracted from patient anamnesis data using large language models (LLMs). The models are trained on the Italian Pathological Voice (IPV) dataset and evaluated using 10-fold cross-validation.

## Method Summary
The authors propose a concept-based approach for voice disorder detection using HuBERT as a pre-trained audio encoder with max pooling. They extract 14 clinical concepts from unstructured patient anamnesis using few-shot prompting with Gemini-pro LLM, filtering to 9 predictable concepts. The CBM architecture uses a bottleneck layer with sigmoid activation to predict concepts before final classification, while CEM uses continuous embeddings. Both models are trained with joint loss weighting concept prediction (λ=0.9) and task classification. The system is evaluated against a conventional end-to-end transformer baseline on the IPV dataset.

## Key Results
- CBM achieves 87.76% accuracy and CEM achieves 87.30% accuracy on binary voice disorder classification
- Both concept-based models perform comparably to end-to-end transformer baseline (91.33% accuracy)
- Ideal CBM using ground truth concepts achieves 90.5% accuracy, validating concept sufficiency
- Concept predictor accuracy is approximately 84.5%, indicating labeling noise limits performance

## Why This Works (Mechanism)

### Mechanism 1
Constraining classification through a bottleneck of human-understandable concepts forces the model to justify predictions, trading marginal accuracy for high interpretability. The model maps audio features to predefined clinical concepts via bottleneck layer, then classifies pathology based only on these concepts. This works under the assumption that selected concepts are necessary and sufficient for diagnosis. If concepts are noisy or incomplete, the bottleneck creates an information choke point causing accuracy to drop significantly below end-to-end baselines.

### Mechanism 2
Structured clinical concepts can be reliably extracted from unstructured text using LLMs to generate supervision signals where human labeling is scarce. The authors use few-shot prompting with Gemini-pro to parse non-standardized medical PDFs into JSON format representing 14 candidate concepts. This converts text data into ground truth labels for training. The approach assumes textual anamnesis accurately reflects acoustic properties at recording time. If anamnesis is ambiguous or temporally mismatched with audio, LLM generates confusing labels leading to high training loss.

### Mechanism 3
Using continuous vector embeddings for concepts (CEM) rather than binary scalars (CBM) preserves information about concept uncertainty or ambiguity, potentially recovering accuracy lost in standard bottlenecks. CEM generates two embeddings weighted by probability instead of single 0/1 output, allowing downstream classifier to utilize nuances even with uncertain binary classification. This assumes audio encoder latent space contains information gradients mapping to concept states better than simple binary decision boundaries. With small datasets, CEM may overfit or perform worse than simpler CBM.

## Foundational Learning

- **Concept: Concept Bottleneck Models (CBM)**
  - Why needed here: This is the core architecture replacing the standard "black box" DNN. Understanding that prediction y is a function of concepts c (y = f(c)), not input x, is critical to grasping the paper's contribution to explainability.
  - Quick check question: If a CBM predicts "Pathological," can you trace exactly which input feature (concept) caused that decision? (Yes, by inspecting the bottleneck layer activations).

- **Concept: Few-Shot Prompting (LLMs)**
  - Why needed here: The paper relies on this technique to bootstrap the dataset. Without understanding how JSON schema and examples guide the LLM, one cannot reproduce the labeling process or diagnose labeling errors.
  - Quick check question: Why did authors include "allowed values" (e.g., "yes"/"no") in the prompt? (To constrain output format and ensure consistency for downstream JSON parser).

- **Concept: Self-Supervised Speech Representation (HuBERT)**
  - Why needed here: The voice disorder dataset is too small (385 samples) to train a deep transformer from scratch. HuBERT provides pre-trained feature extractor.
  - Quick check question: Why is Max Pooling applied over HuBERT output frames in this architecture? (To aggregate frame-level features into single utterance-level representation, prioritizing local peaks corresponding to vocal characteristics).

## Architecture Onboarding

- **Component map:** Audio Waveform (16kHz) + Anamnesis Text → HuBERT (pre-trained transformer) → Max Pooling → Neck (CBM: Linear Layer + Sigmoid / CEM: Embedding Layer + Scoring Function) → Head (Linear Layers) → Binary Output

- **Critical path:** The alignment between audio features and LLM-extracted concept labels. The authors note that "Ideal CBM" (using ground truth concepts) achieves 90.5% accuracy, while learned CBM achieves 87.7%. The performance gap is almost entirely attributed to concept predictor's error (~84.5% accuracy). Improving system requires improving concept prediction from audio, not necessarily final classifier.

- **Design tradeoffs:**
  - Accuracy vs. Interpretability: Standard "black box" transformer (91.3%) outperforms concept models (~87%). The ~4% drop is the "cost" of knowing why the model made a decision.
  - CBM vs. CEM: The paper shows negligible difference between simple Bottleneck and complex Embedding model. CBM is preferred here for simplicity and clearer interpretability.

- **Failure signatures:**
  - Concept Accuracy < 80%: Model is likely struggling to correlate LLM's text labels with acoustic signal. Check for data alignment errors or ambiguous prompt instructions in labeling phase.
  - High Task Accuracy, Low Concept Accuracy: This suggests the model is "cheating"—using patient-provided concepts (like "Gender" or "Smoking") to infer result without actually analyzing audio quality (roughness/breathiness).

- **First 3 experiments:**
  1. Ideal CBM Baseline: Train task classifier using ground truth concept labels directly (skip audio-to-concept step) to validate that 9 selected concepts are theoretically sufficient for diagnosis.
  2. LLM Label Validation: Run Gemini labeling pipeline on validation set and manually compare extracted JSON against human expert annotation to measure "label noise" rate.
  3. Ablation on Loss Weight (λ): Vary weighting between Concept Loss and Task Loss (currently weighted 0.9/0.1) to see if forcing better concept representations improves or degrades final task accuracy.

## Open Questions the Paper Calls Out

- Does incorporating sustained vowel recordings, alongside read sentences, improve concept prediction accuracy and final classification performance? The authors state this as a direction for future work, as current experiments utilized only CAPE-V sentence recordings while sustained vowel /a/ recordings were present but unused.

- Can the proposed concept-based architecture transfer effectively to other voice disorder datasets, such as AVFAD, without significant loss in performance? The authors note that concept-based models could be evaluated on different datasets, but validation was restricted to IPV dataset.

- Can linking concept predictions to a generative model produce clinically viable, report-like documents that enhance interpretability for medical professionals? The paper suggests concept predictions could be linked to an LLM to produce report-like documents including vocal analysis description, but has not integrated this natural language generation component.

## Limitations

- The LLM-based concept extraction pipeline (Gemini-pro) lacks independent validation against clinical gold standards, making it difficult to distinguish between model error and concept-label noise
- The 385-sample dataset is small for deep learning; performance estimates may be optimistic given 10-fold cross-validation variance is not reported
- No ablation studies isolating the contribution of individual concepts to model performance

## Confidence

- **High confidence:** CBM and CEM architectures can achieve comparable accuracy to end-to-end models while maintaining interpretability through concept bottlenecks
- **Medium confidence:** The specific concept set (dysphonia, roughness, breathiness, etc.) is sufficient for voice disorder detection, based on the 90.5% "Ideal CBM" baseline
- **Low confidence:** The few-shot LLM labeling pipeline reliably converts unstructured clinical notes into concept labels without introducing significant noise

## Next Checks

1. **Concept-label validation:** Manually annotate 50 random samples with ground truth concept labels and compare against LLM-extracted labels to quantify labeling error rate
2. **Concept importance analysis:** Perform ablation studies removing individual concepts to identify which contribute most to task accuracy and interpretability
3. **Generalization testing:** Evaluate the trained models on an independent voice disorder dataset (different population or recording conditions) to assess real-world robustness