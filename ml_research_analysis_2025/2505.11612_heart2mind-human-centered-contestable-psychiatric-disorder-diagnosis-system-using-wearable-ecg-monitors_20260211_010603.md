---
ver: rpa2
title: 'Heart2Mind: Human-Centered Contestable Psychiatric Disorder Diagnosis System
  using Wearable ECG Monitors'
arxiv_id: '2505.11612'
source_url: https://arxiv.org/abs/2505.11612
tags:
- contestable
- psychiatric
- disorder
- system
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Heart2Mind presents a human-centered contestable psychiatric disorder
  diagnosis system that integrates wearable ECG monitoring with AI-driven diagnostics.
  The system leverages cardiac biomarkers, particularly heart rate variability (HRV)
  and R-R intervals (RRI), to detect psychiatric conditions such as schizophrenia
  and bipolar disorder.
---

# Heart2Mind: Human-Centered Contestable Psychiatric Disorder Diagnosis System using Wearable ECG Monitors

## Quick Facts
- **arXiv ID**: 2505.11612
- **Source URL**: https://arxiv.org/abs/2505.11612
- **Reference count**: 40
- **Primary result**: MSTFT achieves 91.7% accuracy on HRV-ACC dataset using leave-one-out cross-validation

## Executive Summary
Heart2Mind presents a human-centered psychiatric diagnosis system that integrates wearable ECG monitoring with AI-driven diagnostics. The system leverages cardiac biomarkers, particularly heart rate variability (HRV) and R-R intervals (RRI), to detect psychiatric conditions such as schizophrenia and bipolar disorder. A novel Multi-Scale Temporal-Frequency Transformer (MSTFT) processes RRI time series through integrated time-frequency domain analysis, achieving 91.7% accuracy. The system incorporates Self-Adversarial Explanations (SAEs) to detect inconsistencies in model predictions and employs contestable Large Language Models (LLMs) to enable clinicians to validate or contest AI decisions through natural language interaction.

## Method Summary
Heart2Mind processes wearable ECG-derived R-R interval time series through a Multi-Scale Temporal-Frequency Transformer (MSTFT) that combines dilated temporal convolutions with learnable wavelet frequency blocks, fused via cross-attention. The system implements Self-Adversarial Explanations (SAEs) to detect prediction inconsistencies by comparing attention-based and gradient-based explanations, and integrates contestable LLMs to enable clinical oversight. The approach addresses subjective psychiatric assessment limitations while maintaining transparency and human oversight.

## Key Results
- MSTFT achieves 91.7% accuracy, 91.6% precision, 91.8% recall, and 0.940 AUC on HRV-ACC dataset using leave-one-out cross-validation
- SAEs successfully detect inconsistencies, with incorrect predictions showing significantly higher discrepancy counts (7.67 for FP, 7.0 for FN) compared to correct predictions (4.83)
- Contestable LLMs successfully contested erroneous predictions, with gemma-3-instruct (27B) overturning 3 out of 6 incorrect predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-scale temporal-frequency fusion may improve RRI classification by capturing complementary patterns across domains.
- Mechanism: The MSTFT processes RRI sequences through parallel pathways—dilated temporal convolutions capture rhythm patterns at multiple scales, while learnable wavelet convolutions extract spectral features. Cross-attention fusion then integrates these representations before self-attention refinement and classification.
- Core assumption: Psychiatric conditions produce detectable autonomic signatures distributed across both temporal dynamics and frequency content of RRI signals.
- Evidence anchors:
  - [abstract] "A novel Multi-Scale Temporal-Frequency Transformer (MSTFT) processes RRI time series through an integrated time-frequency domain analysis, achieving 91.7% accuracy"
  - [Section 4.2] Details the temporal convolutions with dilated rates, wavelet transform blocks, cross-attention fusion, and self-attention mechanisms
  - [corpus] Limited external validation; neighboring papers focus on different modalities (fMRI, social media language, gait) rather than ECG-based approaches
- Break condition: If autonomic dysfunction patterns are inconsistent across populations or masked by noise artifacts, the fusion benefits may not generalize.

### Mechanism 2
- Claim: Discrepancies between attention-based and gradient-based explanations appear to correlate with prediction errors.
- Mechanism: SAEs compute attention-based explanation maps (averaged attention weights from transformer layers) and gradient-based maps (CAM-style gradients). The absolute difference identifies regions where the model attends but gradients show weak contribution—flagging potential unfaithfulness.
- Core assumption: Model faithfulness can be approximated by agreement between two explanation paradigms; disagreement signals unreliable reasoning.
- Evidence anchors:
  - [abstract] "SAEs successfully detect inconsistencies in model predictions by comparing attention-based and gradient-based explanations"
  - [Section 5.3.1] "Incorrect predictions (FP and FN) presented a markedly different pattern... FP cases demonstrated a substantially higher mean discrepancy count of 7.67... FN cases averaged 7.0"
  - [corpus] No direct corpus validation of this specific SAE mechanism in psychiatric contexts
- Break condition: If attention and gradient explanations diverge for legitimate reasons (e.g., complex multi-feature decisions), false positive flags may overwhelm clinical review capacity.

### Mechanism 3
- Claim: LLMs with structured clinical prompts can validate correct predictions and contest some erroneous ones without domain-specific fine-tuning.
- Mechanism: The contestable LLM receives patient profile, baseline MSTFT prediction, HRV metrics, and regional discrepancy metrics. Using a structured prompt (Template 1), it reasons step-by-step and may retain or overturn the initial prediction based on clinical patterns in the data.
- Core assumption: Pre-trained LLMs encode sufficient medical knowledge about HRV-psychiatric relationships to make meaningful contestation decisions.
- Evidence anchors:
  - [abstract] "LLMs enable clinicians to validate correct predictions and contest erroneous ones"
  - [Section 5.3.2] "all three contestable LLMs successfully contested at least one erroneous prediction... gemma-3-instruct (27B) showing the strongest performance by overturning 3 out of 6 incorrect predictions"
  - [corpus] Motion2Meaning and ConGaIT papers similarly explore contestable LLM frameworks for clinical interpretation, suggesting growing interest but limited mature validation
- Break condition: If LLMs lack reliable medical knowledge or hallucinate clinical justifications, contestation may introduce new errors rather than correcting them.

## Foundational Learning

- Concept: Heart Rate Variability (HRV) and Autonomic Nervous System (ANS) dysfunction
  - Why needed here: The entire diagnostic premise rests on psychiatric disorders producing measurable ANS dysregulation visible in HRV metrics (RMSSD, SDNN, LF/HF power).
  - Quick check question: Can you explain why reduced parasympathetic tone (lower HRV) might correlate with psychiatric conditions like schizophrenia or bipolar disorder?

- Concept: Transformer attention mechanisms and cross-attention
  - Why needed here: MSTFT uses cross-attention to fuse temporal and frequency features, and SAEs extract attention weights for explanation generation.
  - Quick check question: How does cross-attention differ from self-attention, and why might it help integrate multi-domain features?

- Concept: Explainable AI faithfulness vs. interpretability
  - Why needed here: SAEs assume explanation faithfulness (does the explanation reflect actual reasoning?) matters more than mere interpretability.
  - Quick check question: Why might attention weights alone be insufficient as a faithful explanation of model reasoning?

## Architecture Onboarding

- Component map:
  - **CMI (Cardiac Monitoring Interface)**: BLE connection to Polar H9/H10 → real-time ECG/HR/RRI streaming → encrypted storage
  - **MSTFT Model**: Input preprocessing (noise augmentation, positional encoding) → Temporal blocks (dilated convolutions + stochastic skips) || Frequency blocks (wavelet convolutions) → Cross-attention fusion → Self-attention → Classifier head
  - **SAEs**: Extract attention maps + gradient maps → DTW alignment → Discrepancy detection → HRV metric extraction per region
  - **Contestable LLMs**: Structured prompt with prediction + HRV metrics + discrepancies → LLM inference → Retain/overturn decision with justification

- Critical path: Raw RRI → MSTFT classification → SAE discrepancy detection (if >5-7 regions) → LLM contestation (if flagged) → Clinician review. The 5-7 discrepancy threshold is empirically observed but not rigorously validated.

- Design tradeoffs:
  - LOOCV provides robust evaluation for small clinical datasets but limits statistical power for error analysis (only 6 incorrect predictions in study)
  - Larger LLMs (27B) show better contestation but slower inference (~38s vs ~10s), impacting real-time clinical utility
  - Grouping schizophrenia and bipolar disorder together as "treatment" simplifies binary classification but loses diagnostic granularity

- Failure signatures:
  - High discrepancy count (>5) with correct prediction: Model may be robust but explanations are unreliable
  - Low discrepancy count with incorrect prediction: SAEs will fail to flag these errors
  - LLM retains clearly erroneous prediction: Knowledge gaps in pre-training or prompt engineering issues

- First 3 experiments:
  1. Reproduce MSTFT performance on HRV-ACC dataset with 5-fold and LOOCV, verifying reported metrics and examining per-class confusion patterns
  2. Implement SAE pipeline on a held-out test set, calibrating discrepancy threshold using ROC analysis against known errors
  3. Ablate each LLM with identical inputs, comparing justification quality and latency to identify optimal model for clinical deployment constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can domain-specific optimization of LLMs improve the accuracy of contesting erroneous predictions compared to general-purpose models?
- Basis in paper: [explicit] Section 6.2.1 notes that current LLMs exhibit inconsistent medical knowledge, and Section 7 states future work should "explore domain-specific optimization of LLMs for enhanced clinical accuracy."
- Why unresolved: The study used general-purpose models (Llama, Phi, Gemma) which successfully contested some errors but failed on others due to limitations in their pre-trained medical knowledge.
- What evidence would resolve it: Comparative performance metrics between general-purpose and medically fine-tuned LLMs on the specific task of validating or overturning AI diagnoses based on HRV metrics.

### Open Question 2
- Question: How can adaptive thresholds for Self-Adversarial Explanations (SAEs) be calibrated to account for case-specific complexity?
- Basis in paper: [explicit] Section 6.2.1 states, "Future work should explore adaptive thresholds that account for case-specific complexity," as the current threshold (approx. 5–7 discrepancies) provides only a useful starting point.
- Why unresolved: The current discrepancy threshold is heuristic; fixed thresholds may not be robust across diverse patient populations or varying signal qualities.
- What evidence would resolve it: Development and validation of a dynamic thresholding algorithm that reduces false positives/negatives in flagging unreliable predictions compared to the static method.

### Open Question 3
- Question: Does the integration of additional physiological signals (e.g., skin conductance, EEG) improve diagnostic performance over ECG-only approaches?
- Basis in paper: [explicit] Section 6.1 states future research "should integrate additional physiological signals... [as] wearables mostly rely on general physiological signals, they are not self-sufficient."
- Why unresolved: The current Heart2Mind system relies exclusively on cardiac biomarkers (HRV/RRI), which may miss relevant autonomic or neurological data available in other modalities.
- What evidence would resolve it: Experimental results from a multi-modal version of the MSTFT model showing statistically significant improvements in classification accuracy over the RRI-only baseline.

## Limitations
- Small dataset size (60 participants) limits statistical power and generalizability
- Binary classification approach groups schizophrenia and bipolar disorder together, sacrificing diagnostic specificity
- SAE discrepancy threshold (5-7 regions) is empirically chosen but lacks rigorous validation across populations

## Confidence
- **High Confidence**: MSTFT architecture implementation, SAE discrepancy detection mechanism, and basic HRV-psychiatric association literature are well-established and reproducible.
- **Medium Confidence**: The 91.7% accuracy claim and SAE effectiveness on the specific HRV-ACC dataset are likely reproducible given access to the data, though generalization remains uncertain.
- **Low Confidence**: LLM contestation decisions, clinical utility in real-world settings, and the system's ability to maintain performance across diverse populations require substantial additional validation.

## Next Checks
1. Conduct external validation on independent HRV datasets with larger sample sizes and diverse demographics to assess generalizability beyond the 60-participant HRV-ACC cohort.
2. Implement ablation studies systematically varying the SAE discrepancy threshold across a range of values, using ROC analysis to identify optimal operating points for different clinical contexts.
3. Perform head-to-head comparison between MSTFT+SAE+LLM pipeline and established psychiatric diagnostic tools in a controlled clinical trial, measuring both diagnostic accuracy and clinician acceptance metrics.