---
ver: rpa2
title: Evaluating the Feasibility and Accuracy of Large Language Models for Medical
  History-Taking in Obstetrics and Gynecology
arxiv_id: '2504.00061'
source_url: https://arxiv.org/abs/2504.00061
tags:
- accuracy
- medical
- infertility
- chatgpt-4o-mini
- diagnostic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology

## Quick Facts
- arXiv ID: 2504.00061
- Source URL: https://arxiv.org/abs/2504.00061
- Reference count: 0
- Primary result: Evaluated LLM feasibility for infertility history-taking

## Executive Summary
This study evaluates the use of large language models for medical history-taking in obstetrics and gynecology, specifically for infertility cases. The authors developed a comprehensive questionnaire covering 1,107 patient questions across 80 infertility cases, with 66 questions on basic patient information and 11 on clinical symptoms. The evaluation compared the model's performance against clinician assessments, focusing on completeness and accuracy of history-taking.

## Method Summary
The authors constructed a dataset of 1,107 patient questions organized into 80 infertility cases. These questions were categorized into 66 basic patient information questions and 11 clinical symptom questions. The LLM's responses were evaluated by comparing them against clinician assessments for completeness and accuracy. The evaluation framework measured the model's ability to generate comprehensive medical histories based on the structured questionnaire format.

## Key Results
- LLM demonstrated ability to generate structured medical histories for infertility cases
- Performance evaluated against clinician assessments for completeness
- Questionnaire-based approach showed promise for systematic history-taking

## Why This Works (Mechanism)
The approach leverages structured questionnaires to guide LLM responses, ensuring systematic coverage of medical history components. By organizing questions into basic patient information and clinical symptoms, the model can generate comprehensive histories that follow clinical workflows. The LLM's natural language processing capabilities enable it to interpret patient responses and organize them into coherent medical histories.

## Foundational Learning
- Medical history-taking protocols: why needed - ensures systematic patient evaluation; quick check - verify coverage of essential clinical elements
- Structured data organization: why needed - enables consistent model responses; quick check - validate question categorization accuracy
- Clinical validation methods: why needed - ensures medical accuracy; quick check - confirm clinician assessment reliability
- Natural language processing for medical data: why needed - handles unstructured patient responses; quick check - test response interpretation accuracy

## Architecture Onboarding
Component map: Patient Questions -> LLM Processing -> Structured History -> Clinician Validation
Critical path: Question formulation → Model response generation → History compilation → Clinical review
Design tradeoffs: Structured questionnaires vs. open-ended conversation, comprehensive coverage vs. response time
Failure signatures: Missing critical symptoms, misinterpreting patient responses, incomplete history compilation
First experiments: 1) Test question comprehension with sample patients, 2) Validate history structure against clinical standards, 3) Compare response completeness across different question types

## Open Questions the Paper Calls Out
None

## Limitations
- No ground truth data for 80 infertility cases, making accuracy verification impossible
- Lack of comparison with existing clinical history-taking tools or human clinicians
- Evaluation focuses only on questionnaire-based interactions, not complex clinical conversations

## Confidence
- Feasibility claims: Medium - technical implementation appears sound but clinical validation insufficient
- Accuracy claims: Low - lack of external validation and unclear ground truth standards

## Next Checks
1. Collect a validation dataset of real patient-clinician interactions in infertility care to establish ground truth for model evaluation
2. Conduct a blinded comparison between LLM-generated histories and those taken by experienced clinicians, using standardized clinical accuracy metrics
3. Test the model's performance across different clinical scenarios beyond infertility, including emergency situations and diverse patient populations