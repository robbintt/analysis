---
ver: rpa2
title: Introducing Fractional Classification Loss for Robust Learning with Noisy Labels
arxiv_id: '2508.06346'
source_url: https://arxiv.org/abs/2508.06346
tags:
- loss
- noise
- label
- learning
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Fractional Classification Loss (FCL),
  a robust loss function designed to handle label noise in deep learning. FCL is built
  within the active-passive loss framework, using the fractional derivative of Cross-Entropy
  as its active component and Mean Absolute Error as its passive component.
---

# Introducing Fractional Classification Loss for Robust Learning with Noisy Labels

## Quick Facts
- **arXiv ID**: 2508.06346
- **Source URL**: https://arxiv.org/abs/2508.06346
- **Reference count**: 35
- **Primary result**: Introduces FCL with learnable fractional order μ, achieving state-of-the-art performance on MNIST, CIFAR-10, and CIFAR-100 under symmetric and asymmetric label noise without manual hyperparameter tuning.

## Executive Summary
This paper presents the Fractional Classification Loss (FCL), a novel loss function designed to handle label noise in deep learning by integrating fractional calculus with the active-passive loss framework. The key innovation is treating the fractional derivative order μ as a learnable parameter, allowing the loss to dynamically adjust its robustness to label noise during training. FCL combines the fractional derivative of Cross-Entropy as an active component with Mean Absolute Error as a passive component, eliminating the need for manual hyperparameter tuning. Experiments demonstrate superior performance compared to existing robust loss functions across multiple datasets and noise types.

## Method Summary
FCL is built within the active-passive loss framework, using the fractional derivative of Cross-Entropy as its active component and Mean Absolute Error as its passive component. The fractional derivative order μ is treated as a learnable parameter that is updated via gradient descent once per epoch using accumulated gradients. During training, μ dynamically adjusts based on noise levels - moving toward 1 in high-noise environments (behaving like MAE for robustness) and toward 0 in low-noise settings (behaving like CE for faster convergence). The loss function is implemented as L_FCL = L_FCE + L_MAE, where L_FCE involves the gamma function and log-probabilities, and both network weights and μ are optimized jointly.

## Key Results
- FCL consistently achieves state-of-the-art performance under both symmetric and asymmetric label noise
- The learnable μ parameter automatically adapts to different noise levels without manual tuning
- Performance is superior to existing methods that rely on fixed hyperparameters
- The method eliminates the need for grid search over robustness coefficients (α, β)
- Achieves better stability when compared to mistuned baselines on CIFAR-100 with 60% symmetric noise

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Noise Tolerance via Learnable Fractional Order
The loss function dynamically calibrates its robustness to label noise by learning the fractional derivative order μ as a model parameter. In high-noise environments, the optimization pushes μ toward 1, making the loss behave like Mean Absolute Error to dampen the impact of erroneous gradients. In low-noise settings, μ moves toward 0, behaving like Cross-Entropy to maximize convergence speed. This adaptive mechanism prevents the trivial minimization issues seen when learning standard weighting coefficients.

### Mechanism 2: Gradient Asymmetry Reshaping
FCL creates a trade-off where penalties on difficult/mislabeled examples are reduced while penalties on easy/clean examples are increased. As μ increases, the gradient magnitude for samples with low output probability p(k|x) (typically noisy) decreases, while the gradient for high probability samples increases. This suppresses the "memorization" of noisy labels which often requires high-gradient updates on outliers, preventing the model from overfitting to noise while maintaining confidence on valid data.

### Mechanism 3: Active-Passive Decomposition
Combining a fractional active loss (FCE) with a passive loss (MAE) enforces noise tolerance while mitigating the underfitting issues common in purely robust loss functions. The Active-Passive Loss framework separates the objective into maximizing probability at the true label (active) and minimizing probability at incorrect labels (passive). FCL uses the fractional derivative for the active part to control the "aggressiveness" of the learning without needing a separate passive weighting coefficient.

## Foundational Learning

- **Concept: Fractional Calculus (Power Rule)**
  - Why needed here: The paper defines its novel loss using the fractional derivative of a power function. Understanding that μ interpolates the derivative order (where μ=1 is standard derivative and μ=0 is the identity) is required to grasp the loss shape.
  - Quick check question: If the loss term is u^(1-μ), does increasing μ make the loss curve flatter or steeper near the origin?

- **Concept: Active-Passive Loss (APL) Framework**
  - Why needed here: FCL is defined explicitly within this framework. One must distinguish between "Active" (driving target probability up) and "Passive" (driving others down) to understand why MAE is combined with the Fractional CE.
  - Quick check question: In standard APL, you tune coefficients α and β. Which parameter in FCL replaces the need for these two?

- **Concept: Symmetric vs. Asymmetric Label Noise**
  - Why needed here: The experiments evaluate performance on these two distinct noise types. Symmetric noise is random flipping; asymmetric is structured flipping (e.g., truck → automobile).
  - Quick check question: Which noise type is more likely to cause a model to learn incorrect semantic correlations rather than just random memorization?

## Architecture Onboarding

- **Component map**: Inputs (logits f(x) and labels y) -> Softmax Layer (computes probabilities p(k|x)) -> FCL Module (Passive Path: computes MAE, Active Path: computes Fractional CE using Eq 11, Learnable Parameter: scalar μ) -> Optimizer (standard for weights, distinct update for μ)

- **Critical path**: Implementing the fractional derivative calculation (Eq 11) and its gradient w.r.t μ (Eq 27), ensuring numerical stability of log(log(p)) when p → 0 or p → 1, scheduling the update for μ (accumulate gradient over epoch, update once, fixed for first 5 epochs)

- **Design tradeoffs**: Robustness vs. Speed (FCL takes ~1.37x longer than CE due to complex gradient calculations), Tuning vs. Automation (eliminates grid search for robustness coefficients but introduces initialization sensitivity for μ)

- **Failure signatures**: Slow Convergence (if μ rapidly escalates to 1.0 early, causing underfit behavior), Numerical NaNs (gradients involving log(-log(p)) can explode if p saturates), Gradient Collapse (if μ learning rate is too high, causing oscillation)

- **First 3 experiments**: 1) Sanity Check (Noiseless): Train on clean MNIST/CIFAR-10 to verify μ converges to low values (≈ 0), 2) Hyperparameter Sensitivity: Run ablation on initial μ value (0, 0.5, 1) on 40% symmetric noise dataset, 3) Baselines Comparison: Compare against SCE and GCE on CIFAR-100 with 60% symmetric noise using mistuned hyperparameters

## Open Questions the Paper Calls Out
- Can integrating fractional order operators into the temporal-difference error of reinforcement learning algorithms enhance adversarial robustness?
- Does the application of fractional order operators within Graph Neural Networks (GNNs) improve robustness against noise in graph classification and regression tasks?
- How does FCL perform on datasets containing real-world, instance-dependent label noise compared to the synthetic noise tested in the study?

## Limitations
- The mechanism depends heavily on the gradient of the fractional derivative being a reliable signal for noise level, which may break down in complex datasets
- Numerical stability of log(log(p)) operations remains a practical concern, particularly when probabilities saturate
- The claim of eliminating hyperparameter tuning is partially true - while μ is learned, its initialization and learning rate still represent hyperparameters

## Confidence
- Adaptive noise tolerance via learnable μ: **High** - Well-supported by experiments showing μ converging to different values under different noise levels
- Gradient asymmetry reshaping mechanism: **Medium** - Theoretically plausible but relies on assumptions about label noise distribution
- Active-passive decomposition benefits: **Medium** - The framework is established, but specific combination with fractional derivatives needs more ablation studies

## Next Checks
1. Sanity check on clean data: Train FCL on uncorrupted MNIST/CIFAR-10 to verify that μ converges to low values (near 0) and that performance matches or exceeds standard Cross-Entropy

2. Ablation on initialization sensitivity: Run experiments with different μ initializations (0, 0.5, 1.0) on a dataset with 40% symmetric noise to confirm all converge to similar final accuracies and μ values

3. Baselines with mistuned hyperparameters: Compare FCL against SCE and GCE on CIFAR-100 with 60% symmetric noise, using intentionally suboptimal hyperparameters for the baselines