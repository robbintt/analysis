---
ver: rpa2
title: On the Role of Contextual Information and Ego States in LLM Agent Behavior
  for Transactional Analysis Dialogues
arxiv_id: '2512.17060'
source_url: https://arxiv.org/abs/2512.17060
tags:
- agents
- agent
- information
- memory
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Multi-Agent System architecture integrating
  Transactional Analysis (TA) theory with contextual information retrieval to improve
  the psychological realism of LLM-based agents. Each agent is structured into three
  ego states (Parent, Adult, Child), each with distinct knowledge structures and reasoning
  styles.
---

# On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues

## Quick Facts
- arXiv ID: 2512.17060
- Source URL: https://arxiv.org/abs/2512.17060
- Reference count: 7
- Agents with ego-state-specific memory banks show more psychologically consistent behavior than those without

## Executive Summary
This paper presents a Multi-Agent System architecture that integrates Transactional Analysis (TA) theory with contextual information retrieval to enhance the psychological realism of LLM-based conversational agents. Each agent is structured into three ego states (Parent, Adult, Child), each with distinct knowledge structures and reasoning styles, and accesses dedicated memory banks during interactions. Controlled experiments comparing agents with and without memory access showed that memory-enabled agents exhibited more diverse ego state activations and more psychologically consistent behaviors, particularly showing increased Parent-to-Child dynamics. The results suggest that combining TA-structured ego states with contextual information retrieval represents a promising direction for developing more human-like conversational agents capable of authentic social interaction.

## Method Summary
The architecture implements three ego state sub-agents (Parent, Adult, Child) as independent ReAct agents with distinct system prompts defining their personas and reasoning styles. Each ego state has dedicated memory banks implemented using FAISS vector stores containing JSON records with context, reaction, emotions, and tone metadata. During conversations, all three ego states generate candidate responses in parallel, optionally querying their respective memory banks via natural language embedding similarity. A meta-decision LLM selects the final response based on life script alignment. The system was evaluated through controlled experiments comparing memory-enabled versus memory-disabled conditions in workplace dialogue scenarios, measuring ego state activation distributions and psychological consistency.

## Key Results
- Memory-enabled agents showed increased Child ego state responses (John: 10→15) and Parent ego state responses (Taylor: 8→18) compared to memory-disabled conditions
- Parent-to-Child transaction dynamics emerged more frequently in memory-enabled conditions, reflecting more psychologically consistent behavior
- The integration of ego state-specific memory retrieval with life script-guided selection produced more diverse response patterns than either component alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partitioning agent personality into distinct ego state modules enables generation of diverse response perspectives rather than defaulting to statistically probable LLM outputs.
- Mechanism: Each ego state receives a distinct system prompt defining its persona and reasoning style (authority/rules for Parent, logic/facts for Adult, emotions/needs for Child). All three generate candidate responses in parallel, which are then evaluated by a meta-decision process.
- Core assumption: TA theory's ego states map meaningfully onto separable information processing patterns that LLMs can emulate via prompt engineering.
- Evidence anchors:
  - [abstract] "each agent is divided into three ego states... treated as separate knowledge structures with their own perspectives and reasoning styles"
  - [Section 3.1] "Each module is an independent LLM-powered ReAct agent... Behavior is shaped through a specific system prompt"
  - [corpus] Related work (Games Agents Play, TACLA) confirms TA-integration is an emerging pattern, though validation remains limited to single scenarios
- Break condition: If ego state prompts produce indistinguishable outputs, or if the meta-decision consistently defaults to one state regardless of context, the partition provides no behavioral benefit.

### Mechanism 2
- Claim: Dedicated memory banks per ego state increase psychologically consistent ego state activation by providing state-specific contextual cues.
- Mechanism: Each ego state queries its own FAISS vector store using natural language queries. Retrieved memories (context, reaction, emotion, tone) are incorporated into that state's reasoning, producing responses that better align with the agent's life script—making them more likely to be selected.
- Core assumption: Memories indexed by ego state provide retrieval results that strengthen character-consistent responses more than generic retrieval would.
- Evidence anchors:
  - [Section 4.3] "in the Memory ON condition, John exhibited an increase in Child ego state responses (from 10 to 15)... while Taylor's engagement from her Parent more than doubled (from 8 to 18)"
  - [Section 4.3] "retrieved information provides stronger, more specific cues for producing a response that is more psychologically consistent"
  - [corpus] InsurAgent and SPARK demonstrate domain-specific retrieval improves behavioral modeling, but ego-state-partitioned memory remains untested beyond this work
- Break condition: If retrieved memories are irrelevant, generic, or contradictory to the ego state's character, they may degrade rather than enhance response quality.

### Mechanism 3
- Claim: Life script-guided meta-decision selection creates complementary transaction dynamics (e.g., Parent-to-Child) that mirror human interpersonal patterns.
- Mechanism: A final LLM decision-maker selects among ego state candidates based on life script alignment. When memory retrieval produces responses strongly matching an agent's script (e.g., John's "I Never Quite Succeed"), non-Adult states are selected more frequently, triggering complementary responses in conversational partners.
- Core assumption: The meta-decision LLM can reliably evaluate life script alignment, and such alignment correlates with psychologically realistic behavior.
- Evidence anchors:
  - [Section 3] "a final decision-making process, performed by an overarching LLM agent, guided by the life script, selects the most contextually appropriate response"
  - [Section 4.3] "This pattern, where a change in an ego state by one agent prompts a complementary ego state shift in the other, was also observable in Memory OFF condition, but less frequently"
  - [corpus] No corpus evidence directly validates life script-driven selection; this mechanism is novel to this architecture
- Break condition: If the meta-decision process is opaque or unreliable, or if life scripts are underspecified, selection becomes arbitrary and transaction dynamics fail to emerge.

## Foundational Learning

- Concept: **Transactional Analysis (TA) ego states**
  - Why needed here: The entire architecture presupposes understanding that Parent, Adult, and Child represent distinct knowledge structures—not just mood states—with characteristic reasoning patterns and memory stores.
  - Quick check question: Can you explain why a "Parent-to-Child" transaction differs from an "Adult-to-Adult" transaction, and what behavioral cues would distinguish them?

- Concept: **Retrieval-Augmented Generation (RAG) with vector similarity**
  - Why needed here: Each ego state's memory access depends on FAISS vector search; understanding embedding-based retrieval is essential for debugging why certain memories are (or aren't) surfaced.
  - Quick check question: Given a query about "feeling overwhelmed by deadlines," what characteristics would make a memory embedding rank highly for a Child ego state's memory bank?

- Concept: **ReAct agent pattern**
  - Why needed here: Each ego state sub-agent uses the ReAct (Reasoning + Acting) framework to decide when to query memory versus respond directly.
  - Quick check question: In a ReAct cycle, what signals would cause an ego state agent to invoke its memory retrieval tool versus proceeding directly to response generation?

## Architecture Onboarding

- Component map:
  - Conversational input -> Three ego state sub-agents (Parent, Adult, Child) -> Each ego state (optionally) queries its dedicated FAISS memory bank -> Each ego state generates candidate response -> Meta-decision LLM evaluates candidates against life script -> Final response selected

- Critical path:
  1. Conversational input arrives → all three ego states receive same context
  2. Each ego state (optionally) queries its dedicated memory bank via embedding similarity
  3. Each ego state generates a candidate response incorporating its prompt + retrieved context
  4. Meta-decision LLM evaluates all three candidates against life script → selects one
  5. Selected response becomes agent output; conversation continues

- Design tradeoffs:
  - **Parallel vs. sequential ego state activation**: Current design generates all three simultaneously (higher latency, richer candidate pool) versus could activate dynamically based on context
  - **Predefined vs. learned memories**: Paper uses handcrafted memories; future work suggests reinforcement learning for memory formation
  - **LLM-based vs. algorithmic meta-decision**: Current selection is another LLM call; authors propose weighted fusion mechanism for transparency

- Failure signatures:
  - **Adult dominance**: If >80% of responses come from Adult state, ego state partition is not functioning as intended (may indicate weak prompts or life script)
  - **Memory irrelevant to context**: If retrieved memories don't match query semantics, check embedding quality or memory bank content
  - **Uniform responses across ego states**: Prompts may be insufficiently differentiated, or base LLM is overriding persona instructions

- First 3 experiments:
  1. **Ablation replication**: Run Memory ON vs. Memory OFF with identical scenarios; verify ego state distribution shifts match paper's findings (John's Child +5, Taylor's Parent +10)
  2. **Memory bank swap test**: Give Parent ego state access to Child's memory bank (and vice versa); observe whether response character follows the prompt or the memory—this reveals which component dominates behavior
  3. **Life script variation**: Run same scenario with John's life script changed to "I Always Succeed"; measure whether ego state selection and transaction patterns shift accordingly

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a transparent, algorithmic mechanism replace the current LLM-based selection process to better simulate internal psychological conflicts?
- Basis in paper: [explicit] The authors state that an "essential step involves the development of a more transparent, algorithmic mechanism to replace the current LLM-based selection of the final response."
- Why unresolved: The current decision mechanism relies on an opaque LLM call; the authors propose a weighting system based on metrics like "emotional stamps" but have not yet implemented it.
- What evidence would resolve it: An agent architecture where the final response is a fusion of ego state outputs determined by explicit, calculated weights rather than a generative prompt.

### Open Question 2
- Question: Can agents effectively generate and modify their own ego state memories dynamically during interactions, rather than relying on predefined static memory banks?
- Basis in paper: [explicit] The authors identify the reliance on predefined content as a limitation and intend to "investigate approaches that enable agents to automatically generate and modify their ego state memories during conversations."
- Why unresolved: The experiments utilized static, manually defined JSON records, which limits the agent's ability to learn and adapt from new experiences over time.
- What evidence would resolve it: A system demonstrating dynamic memory updates—potentially via reinforcement learning—that results in evolving behavior distinct from the initial preset.

### Open Question 3
- Question: Does the inclusion of advanced Transactional Analysis concepts such as "discounting," "strokes," and "stamp collecting" improve the psychological realism of agent interactions?
- Basis in paper: [explicit] The authors "intend to include more Transactional Analysis (TA) concepts like discounting... strokes... and stamp collecting patterns" in future iterations.
- Why unresolved: The current implementation is limited to basic ego states and life scripts, omitting these specific theoretical mechanisms for handling recognition and negative emotional accumulation.
- What evidence would resolve it: Comparative dialogue analysis showing that agents implementing these concepts produce behaviors judged as more psychologically consistent by TA practitioners.

### Open Question 4
- Question: Do the observed effects generalize to diverse social scenarios and withstand validation by human domain experts?
- Basis in paper: [explicit] The authors note the need for "conducting broader testing with different scenarios and possibly including TA practitioner judges."
- Why unresolved: The study was restricted to a single workplace dialogue scenario (22 dialogues) and relied on automated analysis without human clinical validation.
- What evidence would resolve it: Successful replication of psychologically consistent behaviors across varied social contexts, validated through qualitative evaluation by Transactional Analysis experts.

## Limitations

- The architecture's psychological realism claims depend heavily on the quality of ego state prompt engineering and memory bank content, both of which are underspecified in the paper.
- The meta-decision mechanism's reliability in evaluating life script alignment remains unvalidated, and observed behavioral changes could reflect prompt-based steering rather than genuine ego state dynamics.
- The controlled scenario's workplace context may not generalize to other domains or more complex interpersonal dynamics.

## Confidence

- **High confidence**: The memory retrieval mechanism functions as described and improves response diversity when implemented with proper vector similarity and memory bank structure.
- **Medium confidence**: The ego state partition produces distinct response patterns, but whether these represent meaningful psychological differentiation versus prompt-based variation requires further validation.
- **Low confidence**: The life script-guided meta-decision reliably selects psychologically consistent responses; current evidence shows correlation but not causation.

## Next Checks

1. **Memory content dependency test**: Systematically vary memory bank contents while holding prompts constant to isolate memory's effect on ego state activation patterns.
2. **Cross-scenario generalization**: Apply the architecture to non-workplace scenarios (therapy sessions, family interactions) to assess whether ego state dynamics transfer across contexts.
3. **Human evaluation of psychological consistency**: Have trained Transactional Analysis practitioners rate responses for psychological realism and ego state authenticity, comparing ratings between memory-enabled and disabled conditions.