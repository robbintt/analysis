---
ver: rpa2
title: How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks
  in the Real World
arxiv_id: '2506.05382'
source_url: https://arxiv.org/abs/2506.05382
tags:
- adversarial
- attack
- attacks
- eclipse
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates black-box adversarial attacks in computer
  vision under three realistic properties: robustness to compression, stealthiness
  to automatic detection, and stealthiness to human inspection. It introduces ECLIPSE,
  a novel attack method that uses Gaussian blurring on estimated gradients and a local
  surrogate model to mask relevant regions.'
---

# How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks in the Real World

## Quick Facts
- arXiv ID: 2506.05382
- Source URL: https://arxiv.org/abs/2506.05382
- Reference count: 40
- Primary result: ECLIPSE maintains 89% low-confidence loss after JPEG compression and achieves human visual stealthiness comparable to the best-performing attack

## Executive Summary
This paper introduces ECLIPSE, a novel black-box adversarial attack method designed to remain effective under three realistic constraints: robustness to JPEG compression, stealthiness to automatic detection, and stealthiness to human inspection. The method combines gradient estimation via hill climbing with a local surrogate model to generate targeted perturbations that evade detection while maintaining attack success. Experiments on the Animals-10 dataset demonstrate that ECLIPSE outperforms existing methods across all three properties, achieving particularly strong results in maintaining low confidence scores after compression and evading automatic detection systems.

## Method Summary
ECLIPSE operates in a black-box setting using query access to confidence scores. The method employs a two-branch architecture: a local surrogate model (DenseNet201) generates GradCAM heatmaps to identify important regions, while an optimization loop uses hill climbing to estimate gradients from the remote target model (ResNet152V2). Gaussian blurring is applied to estimated gradients to create coarse perturbations that are robust to compression. The attack iteratively updates a candidate adversarial example within an L∞ budget, using the surrogate's heatmap to focus perturbations on relevant image regions while avoiding obvious visual artifacts.

## Key Results
- ECLIPSE maintains 89% of examples with low-confidence loss (<0.3) after JPEG compression
- Achieves random-chance detection performance with AUC of 0.50 against automatic detection systems
- 62.55% of adversarial examples rated as indistinguishable or slightly visible by human evaluators
- Outperforms existing methods (SimBA, SimBA-DCT, Square Attack) across all three evaluation properties

## Why This Works (Mechanism)
ECLIPSE works by combining gradient estimation with spatial masking and smoothing. The local surrogate model's GradCAM heatmap identifies which image regions are most important for classification, allowing the attack to focus perturbations where they matter most. Gaussian blurring of estimated gradients creates coarse, low-frequency perturbations that are naturally more robust to JPEG compression, which removes high-frequency components. This combination of focused, smoothed perturbations allows the attack to maintain effectiveness while appearing more natural to both automatic detectors and human observers.

## Foundational Learning
- **Black-box Adversarial Attacks (Query-Based)**: Essential because ECLIPSE operates without direct gradient access, requiring gradient estimation from confidence scores. Quick check: Can you explain the difference between white-box attacks (using true gradients) and black-box attacks that must estimate gradients from confidence scores?
- **JPEG Compression and Frequency-Domain Disruption**: Critical for understanding why many adversarial perturbations fail when images are compressed. Quick check: How does JPEG compression's quantization of high-frequency components affect small, high-frequency adversarial noise patterns?
- **Explainability via GradCAM**: Necessary to understand how ECLIPSE uses GradCAM heatmaps from a local surrogate to guide attack focus. Quick check: What does a GradCAM heatmap represent, and how might it differ between two models trained on the same task but with different architectures?

## Architecture Onboarding
- **Component map**: Local Surrogate Model -> GradCAM Heatmap -> Perturbation Mask -> Optimization Loop (Hill Climbing) -> Remote Target Model -> Confidence Scores -> Gaussian Blurred Gradients -> Adversarial Example
- **Critical path**: The gradient estimation and blurring step is most critical for performance. The fidelity of this estimated, blurred gradient directly determines update quality and climb efficiency.
- **Design tradeoffs**: Primary tradeoff between query efficiency and stealth (masking reduces queries but increases detectability). Secondary tradeoff between robustness and visual stealth (Gaussian blurring improves robustness but may increase visibility).
- **Failure signatures**:
  - Convergence Failure: Exhausts query budget without achieving target confidence (may indicate poor surrogate-target alignment)
  - Non-Robust Perturbation: Success in crafting adversarial example but confidence drops after JPEG compression
  - Mask Collapse: Perturbable area shrinks too rapidly, trapping optimization in local minimum
- **First 3 experiments**:
  1. Baseline Property Evaluation: Run ECLIPSE, SimBA, SimBA-DCT, and Square Attack on 50 Animals-10 images, measuring median confidence loss after JPEG compression, ROC AUC for spectral detection, and human visibility scores.
  2. Ablation Study: Implement ECLIPSE variants without Gaussian blur, without local surrogate mask, and without both, comparing performance on three key metrics.
  3. Surrogate Mismatch Sensitivity: Use different local surrogate (e.g., ResNet instead of DenseNet) and measure impact on query efficiency and attack success rate.

## Open Questions the Paper Calls Out
- **Physical deployment robustness**: Can ECLIPSE maintain effectiveness when adversarial examples are printed and recaptured? The current study is digital-only and doesn't account for physical-world noise, lighting variations, or printing artifacts.
- **Beyond additive perturbations**: Could non-additive techniques like altering brightness or color dynamics improve stealthiness while maintaining robustness? ECLIPSE currently uses additive noise within L∞ bounds.
- **Label-only adaptation**: Can ECLIPSE methodology be adapted for label-only settings where confidence scores are unavailable? The current hill climbing depends on fine-grained fitness scores (confidence) unavailable in many real-world APIs.

## Limitations
- Critical hyperparameters remain underspecified (Gaussian blur standard deviation, coordinate sampling size, mask reset threshold)
- Claim of "stealthiness" is relative and dependent on chosen evaluation metrics
- Does not explore potential biases in human survey methodology or automatic detection systems

## Confidence
- **High Confidence**: Overall methodology for evaluating real-world attack properties and core ECLIPSE algorithm design
- **Medium Confidence**: Ablation study results, but impact of missing hyperparameters on reported metrics remains uncertain
- **Low Confidence**: Relative nature of "stealthiness" claims and lack of exploration of evaluation method biases

## Next Checks
1. **Hyperparameter Sensitivity**: Reproduce ablation study while systematically varying Gaussian blur σ, sampling size s, and min_area threshold to quantify impact on query efficiency, compression robustness, and detection evasion.
2. **Surrogate Mismatch Robustness**: Replace DenseNet201 surrogate with ResNet50 and evaluate whether ECLIPSE maintains performance, testing resilience to surrogate-target misalignment.
3. **Human Study Validation**: Conduct independent human survey with larger, more diverse evaluator pool to confirm reported visual stealthiness scores, particularly the 62.55% indistinguishable/slightly visible rate.