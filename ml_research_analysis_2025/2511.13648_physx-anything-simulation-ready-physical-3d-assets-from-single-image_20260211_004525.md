---
ver: rpa2
title: 'PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image'
arxiv_id: '2511.13648'
source_url: https://arxiv.org/abs/2511.13648
tags:
- physical
- geometry
- physx-anything
- arxiv
- assets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "PhysX-Anything is the first framework to generate simulation-ready\
  \ physical 3D assets from a single image. It introduces a VLM-based generative pipeline\
  \ with a new 3D representation that reduces geometry tokens by 193\xD7, enabling\
  \ explicit geometry learning within standard VLM token budgets without special tokens."
---

# PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image

## Quick Facts
- arXiv ID: 2511.13648
- Source URL: https://arxiv.org/abs/2511.13648
- Reference count: 36
- Primary result: First framework to generate simulation-ready physical 3D assets from single images

## Executive Summary
PhysX-Anything introduces the first framework capable of generating simulation-ready physical 3D assets from single images. The method leverages a VLM-based generative pipeline with a novel 3D representation that reduces geometry tokens by 193×, enabling efficient processing within standard VLM token budgets. The framework introduces PhysX-Mobility, a comprehensive dataset containing over 2K real-world objects across 47 categories with rich physical annotations, and demonstrates strong performance in generating assets that can be directly used for contact-rich robotic policy learning in MuJoCo simulations.

## Method Summary
The framework employs a Vision-Language Model (VLM) based generative pipeline that creates physical 3D assets from single images. The key innovation is a new 3D representation that dramatically reduces geometry tokens by 193× compared to previous approaches, allowing explicit geometry learning within standard VLM token budgets without requiring special tokens. This efficiency gain is achieved through a novel representation scheme that captures essential geometric information while minimizing token usage. The method is trained on PhysX-Mobility, a newly created dataset containing over 2K real-world objects with 47 categories and rich physical annotations, enabling the model to learn both geometric and physical properties of objects simultaneously.

## Key Results
- Achieves significant improvements in absolute scale accuracy (error reduced from 43.44 to 0.30)
- Demonstrates strong generative performance and generalization on both PhysX-Mobility and in-the-wild images
- Successfully validates generated assets for contact-rich robotic policy learning in MuJoCo simulations

## Why This Works (Mechanism)
The framework's effectiveness stems from its efficient 3D representation that enables geometry learning within standard VLM constraints, the comprehensive PhysX-Mobility dataset providing rich physical annotations, and the integration of visual and physical understanding through VLM-based generation. The 193× reduction in geometry tokens allows the model to focus on essential geometric features while maintaining computational efficiency, and the physical annotations enable generation of assets that behave realistically in simulation environments.

## Foundational Learning
- VLM-based generation: Combines visual and language understanding for 3D asset creation; needed for integrating semantic and geometric information; quick check: verify VLM token allocation and usage patterns
- 3D representation compression: Reduces geometry tokens by 193× while preserving essential information; needed for efficient processing within VLM constraints; quick check: compare generated geometry fidelity across compression levels
- Physical annotations: Provides physical properties (mass, friction, etc.) for objects; needed for simulation-ready assets; quick check: validate physical property extraction accuracy

## Architecture Onboarding

**Component Map**: Image Input -> VLM Processing -> 3D Representation Compression -> Physical Property Integration -> MuJoCo Simulation Output

**Critical Path**: The critical path flows from image input through VLM processing, where the novel 3D representation compression occurs, followed by physical property integration, resulting in simulation-ready 3D assets.

**Design Tradeoffs**: The primary tradeoff involves balancing geometric fidelity with computational efficiency through the 193× token reduction. This enables standard VLM processing but may sacrifice fine geometric details for complex objects.

**Failure Signatures**: Potential failures include loss of geometric detail in complex objects, inaccurate physical property estimation, and poor generalization beyond the 47 categories in PhysX-Mobility dataset.

**First Experiments**: (1) Test geometry fidelity preservation across varying object complexity levels, (2) Validate physical property accuracy through simulation stress tests, (3) Evaluate cross-dataset generalization on objects outside the 47 categories.

## Open Questions the Paper Calls Out
None

## Limitations
- Relies on specific VLM architecture and predefined token budgets that may constrain performance on complex geometries
- 193× token reduction could sacrifice geometric fidelity for objects with intricate details
- Evaluation focuses on specific metrics without comprehensive validation across diverse physical interaction scenarios

## Confidence
- High: Novel 3D representation and its efficiency benefits
- Medium: Generative performance improvements on PhysX-Mobility dataset
- Medium: Generalization capabilities on in-the-wild images

## Next Checks
1. Systematic evaluation of geometric fidelity loss due to token reduction across varying object complexity levels
2. Comprehensive physical simulation testing beyond contact-rich robotic tasks, including scenarios involving gravity, friction, and dynamic interactions
3. Ablation studies quantifying the contribution of each component (VLM knowledge, new representation, dataset size) to final performance