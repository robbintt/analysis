---
ver: rpa2
title: 'ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction
  using LLMs'
arxiv_id: '2510.22590'
source_url: https://arxiv.org/abs/2510.22590
tags:
- atomic
- temporal
- atom
- facts
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ATOM introduces a parallel and scalable approach for constructing
  and updating temporal knowledge graphs from unstructured text. It decomposes documents
  into atomic facts to improve exhaustivity and stability, then builds and merges
  atomic TKGs in parallel.
---

# ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs

## Quick Facts
- arXiv ID: 2510.22590
- Source URL: https://arxiv.org/abs/2510.22590
- Reference count: 40
- Primary result: 18% higher exhaustivity and 33% better stability than baselines with >90% latency reduction

## Executive Summary
ATOM introduces a parallel and scalable approach for constructing and updating temporal knowledge graphs from unstructured text. It decomposes documents into atomic facts to improve exhaustivity and stability, then builds and merges atomic TKGs in parallel. The method distinguishes observation time from validity periods, enabling more accurate temporal modeling. Experiments show ATOM achieves 18% higher exhaustivity and 33% better stability than baselines, with over 90% latency reduction, demonstrating strong scalability for dynamic TKG construction.

## Method Summary
ATOM constructs dynamic temporal knowledge graphs (DTKGs) through a three-module pipeline: (1) atomic fact decomposition using LLMs to split documents into self-contained facts with observation timestamps, (2) parallel 5-tuple extraction from each atomic fact using temperature=0 LLMs, and (3) parallel pairwise merging of atomic TKGs using cosine similarity thresholds for entity/relation resolution. The approach separates observation time (when data arrives) from validity periods (when facts are true), enabling more accurate temporal modeling while maintaining scalability through LLM-independent merging operations.

## Key Results
- 18% higher factual exhaustivity (0.72 vs 0.405 baseline) and 31% higher factual-temporal exhaustivity (0.354 vs 0.176)
- 33% better stability (Jaccard similarity ~0.55 vs ~0.21 baseline) across multiple LLM runs
- >90% latency reduction compared to state-of-the-art methods (Graphiti and iText2KG)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Atomic fact decomposition improves exhaustivity by mitigating LLM "forgetting effects" in longer contexts.
- Mechanism: Documents are split into minimal, self-contained snippets before 5-tuple extraction, reducing information loss that occurs when LLMs process complex, multi-fact paragraphs.
- Core assumption: LLMs prioritize salient facts and omit peripheral relationships when context length increases.
- Evidence anchors:
  - [abstract] "ATOM splits input documents into minimal, self-contained 'atomic' facts, improving extraction exhaustivity"
  - [Section 4.3] Figure 3 shows factual exhaustivity drops from ~0.8 to ~0.4 as token count increases from 57 to 9,728 across all tested LLMs; atomic facts maintain higher exhaustivity than direct 5-tuple extraction.
  - [corpus] Weak direct evidence—neighbor papers focus on TKG reasoning/querying, not construction exhaustivity.
- Break condition: If input texts are already atomic (short, single-claim sentences), decomposition provides marginal benefit and may increase cost without proportional gain.

### Mechanism 2
- Claim: Atomic facts improve extraction stability across multiple LLM runs by reducing output variance.
- Mechanism: Shorter, unambiguous contexts constrain the LLM's generation space, yielding more consistent 5-tuple sets across independent executions with identical prompts.
- Core assumption: Stochasticity in LLM outputs correlates with context complexity and length.
- Evidence anchors:
  - [abstract] "~17% better stability"
  - [Section 4.4, Table 1] Jaccard similarity across runs: atomic facts (F) achieve 0.552 and 0.534 for Runs 2 and 3 vs. lead paragraphs (L) at 0.212 and 0.218—a ~33% relative improvement.
  - [corpus] No direct neighbor evidence on stability metrics in TKG construction.
- Break condition: If LLM temperature is set >0 or models with higher inherent variability are used, stability gains may diminish.

### Mechanism 3
- Claim: Parallel architecture with LLM-independent merging enables scalable dynamic TKG construction.
- Mechanism: 5-tuple extraction from atomic facts and pairwise TKG merging execute in parallel; entity/relation resolution uses cosine similarity thresholds rather than LLM calls, avoiding context overflow and sequential bottlenecks.
- Core assumption: Embedding-based similarity sufficiently approximates semantic equivalence for entity and relation resolution.
- Evidence anchors:
  - [abstract] "over 90% latency reduction"
  - [Section 4.6, Figure 4] ATOM achieves 93.8% latency reduction vs. Graphiti and 95.3% vs. iText2KG for 2,300+ atomic facts; Module-3 accounts for only 13% of total latency.
  - [corpus] Neighbor papers address TKG reasoning/forecasting but do not evaluate construction latency.
- Break condition: If entity/relation ambiguity is high within a domain (e.g., "Apple" company vs. fruit), threshold-based merging may produce false positives without human-in-the-loop validation.

## Foundational Learning

- Concept: Temporal Knowledge Graphs (TKGs) with dual-time modeling
  - Why needed here: ATOM distinguishes observation time (when data arrives) from validity periods (when facts are true), preventing temporal misattribution.
  - Quick check question: Given a news article published Jan 23 stating "the virus spread to 10 countries last week," which timestamp should represent validity start vs. observation time?

- Concept: Entity and relation resolution via embedding similarity
  - Why needed here: Merging atomic TKGs requires identifying when two entities or relations refer to the same concept without LLM calls.
  - Quick check question: If cosine similarity between "gpt-5:model" and "gpt-3.5:model" embeddings is 0.82 and θE=0.8, would ATOM merge them? What tradeoff does this illustrate?

- Concept: Parallel pairwise merging (divide-and-conquer)
  - Why needed here: ATOM uses iterative pairwise merges of atomic TKGs to achieve O(n log n) merging complexity with thread-level parallelism.
  - Quick check question: Given 17 atomic TKGs, how many parallel merge iterations until convergence to a single TKG?

## Architecture Onboarding

- Component map:
  - **Module-1 (Atomic Fact Decomposition)**: LLM-based splitting of documents into self-contained facts with observation timestamps.
  - **Module-2 (Atomic TKG Construction)**: Parallel 5-tuple extraction (entity, relation, entity, t_start, t_end) from each atomic fact; embeddings generated for entities and relations.
  - **Module-3 (Parallel Merge & DTKG Update)**: Binary merge via entity/relation resolution (cosine similarity thresholds θE=0.8, θR=0.7) and temporal resolution; iterative pairwise parallel merging until single TKG; merge with existing DTKG.

- Critical path: Module-1 → Module-2 (parallel) → Module-3 (parallel merge) → DTKG update. Latency dominated by LLM API calls in Modules 1 and 2.

- Design tradeoffs:
  - Exhaustivity vs. precision: Atomic decomposition increases recall (~31% factual, ~18% factual-temporal) but reduces precision (~9% factual) due to inferred facts.
  - Cost vs. quality: Full ATOM pipeline costs ~2.5× more than direct extraction (Table T.2) due to decomposition step and increased output tokens.
  - Threshold-based resolution vs. accuracy: LLM-independent merging improves scalability but may merge semantically distinct entities with high embedding similarity.

- Failure signatures:
  - Hallucinated atomic facts during decomposition (not present in source text).
  - Unassigned temporal information propagating as missing t_start/t_end in 5-tuples.
  - Semantic drift when similar but distinct entities cross thresholds (e.g., "Apple" company vs. fruit if labels are missing).
  - Temporal misattribution if observation time is incorrectly set to validity start.

- First 3 experiments:
  1. **Exhaustivity baseline**: Run direct 5-tuple extraction on lead paragraphs vs. atomic fact decomposition for a 50-article subset; compute R_f and R_f,t to quantify information loss.
  2. **Stability test**: Execute extraction pipeline 5 times on identical input with temperature=0; compute Jaccard similarity across runs to validate atomic fact stability claims.
  3. **Latency scaling**: Measure wall-clock time for Module-3 merging with 100, 500, 1000 atomic TKGs across 4 vs. 8 threads; verify parallel speedup and identify bottlenecks.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can error propagation in the atomic fact decomposition phase be reduced to minimize inferred facts (hallucinations) without significantly lowering factual recall?
- **Basis in paper:** [explicit] The authors note in Section 6 that the LLM may generate "inferred facts not present in the source text" and fail to assign temporal information, leading to decreased precision.
- **Why unresolved:** The paper prioritizes high exhaustivity (recall) through decomposition, which inherently creates a trade-off with precision that the current method does not fully resolve.
- **What evidence would resolve it:** A modified prompt or fine-tuned model that maintains high recall while reducing the hallucination rate in the "Atomic Fact" output compared to the current baseline.

### Open Question 2
- **Question:** Would a supervised entity/relation resolution classifier effectively prevent the erroneous merging of semantically distinct but similar entities better than the current threshold-based approach?
- **Basis in paper:** [explicit] Section 6 states that the distance-metric-based merging can occasionally merge distinct entities (e.g., "gpt-5:model" vs. "gpt-3.5:model") and suggests a supervised classifier as a potential improvement.
- **Why unresolved:** The current method relies on cosine similarity thresholds ($\theta_E, \theta_R$), which struggle with distinct entities that share high semantic similarity in vector space.
- **What evidence would resolve it:** Comparative benchmarks showing a supervised classifier yields higher F1-scores for entity/relation resolution specifically for highly similar named entities compared to the distance-metric approach.

### Open Question 3
- **Question:** Can the cost and latency of the ATOM pipeline be optimized by fine-tuning smaller, open-weight models for 5-tuple extraction without degrading the quality of the constructed TKG?
- **Basis in paper:** [explicit] Section 6 acknowledges that ATOM entails higher costs due to the decomposition step and suggests mitigating this by "using or fine-tuning open-weight models."
- **Why unresolved:** The current implementation relies on high-cost proprietary models (Claude, GPT) to ensure the stability and exhaustivity required for the atomic decomposition strategy.
- **What evidence would resolve it:** Experiments demonstrating that a fine-tuned open-source model (e.g., Llama, Mistral) achieves comparable stability and exhaustivity scores to GPT-4/Claude on the 2020-COVID-NYT dataset at a lower cost.

## Limitations
- Gold standard dependency: Evaluation relies on semi-manually annotated gold standard, introducing potential human bias and limiting reproducibility
- Threshold sensitivity: Fixed cosine similarity thresholds may not generalize across domains, risking false positives for semantically distinct but similar entities
- Cost-quality tradeoff: ATOM incurs ~2.5× higher cost than direct extraction, raising questions about cost-effectiveness for all use cases

## Confidence
- **High Confidence**: Parallel architecture effectiveness (latency reduction >90%) and stability improvements (~17% Jaccard similarity gains) - supported by direct experimental comparisons with Graphiti and iText2KG baselines
- **Medium Confidence**: Atomic fact decomposition improving exhaustivity (~31% factual gain) - based on controlled experiments with token count variation but dependent on gold standard quality
- **Low Confidence**: Threshold-based entity/relation resolution avoiding LLM calls - while latency gains are clear, the accuracy trade-offs in complex domains with high entity ambiguity are not fully characterized

## Next Checks
1. **Cross-Domain Threshold Calibration**: Test ATOM on biomedical or technical domains with high entity ambiguity (e.g., "Apple" company vs. fruit, gene symbols) to evaluate whether θE=0.8 and θR=0.7 generalize or require domain-specific tuning
2. **Cost-Benefit Analysis**: Quantify the practical impact of ATOM's 2.5× cost increase by measuring downstream performance improvements in TKG reasoning tasks (link prediction, query answering) compared to direct extraction methods
3. **Temporal Resolution Stress Test**: Evaluate ATOM's performance on documents with complex temporal references (e.g., "last week," "before the merger") to assess accuracy in converting relative to absolute timestamps and preventing temporal misattribution