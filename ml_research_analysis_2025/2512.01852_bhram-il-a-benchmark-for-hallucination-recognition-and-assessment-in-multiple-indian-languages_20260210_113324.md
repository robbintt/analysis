---
ver: rpa2
title: 'BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple
  Indian Languages'
arxiv_id: '2512.01852'
source_url: https://arxiv.org/abs/2512.01852
tags:
- languages
- language
- hallucination
- questions
- indian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BHRAM-IL, a multilingual benchmark for evaluating
  hallucination detection in Indian languages (Hindi, Gujarati, Marathi, Odia) alongside
  English. The dataset comprises 36,047 curated questions across nine categories covering
  factual, numerical, reasoning, and linguistic tasks.
---

# BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages

## Quick Facts
- arXiv ID: 2512.01852
- Source URL: https://arxiv.org/abs/2512.01852
- Authors: Hrishikesh Terdalkar; Kirtan Bhojani; Aryan Dongare; Omm Aditya Behera
- Reference count: 5
- Primary result: Even top multilingual LLMs achieve only modest hallucination detection scores (0.23-0.385) across Indian languages, with severe performance gaps in mathematics and Odia

## Executive Summary
This paper introduces BHRAM-IL, a comprehensive multilingual benchmark designed to evaluate hallucination detection capabilities of large language models across Indian languages (Hindi, Gujarati, Marathi, Odia) and English. The dataset comprises 36,047 curated questions spanning nine categories including factual, numerical, reasoning, and linguistic tasks. Through systematic evaluation of 14 state-of-the-art multilingual LLMs on 10,265 questions, the authors reveal persistent performance limitations, with English consistently outperforming Indian languages and mathematics showing the widest accuracy gap. The benchmark exposes critical challenges in multilingual alignment and regional language support that remain largely unaddressed in current LLM architectures.

## Method Summary
The authors constructed BHRAM-IL by curating 36,047 questions across nine categories including factual, numerical, reasoning, and linguistic tasks in four Indian languages plus English. They evaluated 14 state-of-the-art multilingual LLMs using both English and native-language prompts on a subset of 10,265 questions, measuring cross-lingual and factual hallucinations through multiple scoring metrics including primary score, language-corrected fuzzy score, and adjusted fuzzy score. The evaluation framework systematically compares model performance across languages, categories, and prompt types to identify systematic patterns in hallucination susceptibility and language-specific degradation.

## Key Results
- Even best-performing models achieve only modest hallucination detection scores (primary score: 0.23, language-corrected fuzzy score: 0.385)
- English consistently outperforms Indian languages, with Hindi leading among Indic languages and Odia showing greatest degradation
- Mathematics exhibits widest performance gap across languages, while chronological ordering is most challenging category
- Native prompts reduce language hallucinations but lower overall accuracy, revealing complex trade-offs in multilingual prompting strategies

## Why This Works (Mechanism)
The benchmark's effectiveness stems from its comprehensive coverage of diverse linguistic and cognitive tasks across multiple languages, combined with systematic evaluation protocols that isolate hallucination types. By using both English and native prompts, the framework reveals how language-specific factors influence hallucination patterns. The multi-metric scoring system captures different aspects of hallucination behavior, from direct factual accuracy to nuanced language-specific errors. The large-scale question set spanning nine distinct categories ensures robust assessment across various reasoning domains and task complexities.

## Foundational Learning
**Multilingual Language Models**: AI systems trained to process multiple languages simultaneously, required for evaluating cross-lingual hallucination patterns
- Why needed: Essential for understanding how language-specific factors affect hallucination behavior
- Quick check: Verify model supports all target languages in evaluation

**Hallucination Detection Metrics**: Multiple scoring methods including primary score, language-corrected fuzzy score, and adjusted fuzzy score
- Why needed: Different metrics capture distinct aspects of hallucination behavior and language-specific errors
- Quick check: Compare metric consistency across model evaluations

**Cross-lingual Prompting**: Using both English and native language prompts to evaluate model responses
- Why needed: Reveals how prompt language affects hallucination rates and model performance
- Quick check: Test response consistency across different prompt languages

## Architecture Onboarding
**Component Map**: Data Collection -> Question Categorization -> Model Evaluation -> Scoring Metrics -> Analysis
**Critical Path**: Question curation → Category assignment → Prompt generation → Model inference → Hallucination scoring → Performance analysis
**Design Tradeoffs**: Native prompts reduce language hallucinations but decrease overall accuracy vs English prompts improve accuracy but increase cross-lingual errors
**Failure Signatures**: Severe performance degradation in Odia, mathematics tasks showing largest gaps, native prompts reducing accuracy despite better language alignment
**First Experiments**:
1. Test additional Indian languages beyond the four included to assess generalizability
2. Expand evaluation to full 36,047-question dataset for score stability verification
3. Conduct ablation studies isolating prompt language, tokenization, and architecture effects

## Open Questions the Paper Calls Out
None

## Limitations
- Relatively small test subset (10,265 questions from 36,047 total) may limit generalizability of findings
- Complex trade-offs between native prompt usage and overall accuracy require deeper investigation
- Benchmark reveals patterns but doesn't fully explain underlying causes of language-specific hallucination differences

## Confidence
High: Comparative ranking of languages and categories, general observation that all models struggle with hallucination detection
Medium: Specific numerical scores and performance differences between models given small test subset
Low: Interpreting native prompt effects and bidirectional trade-off between language-specific and overall performance

## Next Checks
1. Expand evaluation to the full 36,047-question dataset to verify score stability and identify potential sampling biases
2. Test additional Indian languages beyond the four included to assess generalizability of observed patterns
3. Conduct ablation studies isolating the effects of prompt language, tokenization, and model architecture on hallucination rates across language pairs