---
ver: rpa2
title: GNNs as Predictors of Agentic Workflow Performances
arxiv_id: '2503.11301'
source_url: https://arxiv.org/abs/2503.11301
tags:
- workflow
- agentic
- gnns
- workflows
- performances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using Graph Neural Networks (GNNs) to predict
  agentic workflow performance, aiming to avoid repeated costly LLM invocations. It
  introduces FLORA-Bench, a large-scale benchmark with 600k workflow-task pairs across
  coding, math, and reasoning domains.
---

# GNNs as Predictors of Agentic Workflow Performances

## Quick Facts
- **arXiv ID**: 2503.11301
- **Source URL**: https://arxiv.org/abs/2503.11301
- **Reference count**: 21
- **Primary result**: GNNs predict agentic workflow performance with accuracy 0.78 and utility 0.72, accelerating optimization by 125x

## Executive Summary
This paper introduces FLORA-Bench, a large-scale benchmark with 600k workflow-task pairs across coding, math, and reasoning domains, and demonstrates that Graph Neural Networks (GNNs) can effectively predict the success of agentic workflows. The method encodes workflows as graphs, leveraging GNNs to generate graph-level embeddings that, combined with task embeddings, predict workflow success. Extensive experiments show GNNs achieve strong performance (average accuracy 0.78, utility 0.72), are robust to different LLMs, and significantly accelerate workflow optimization by 125x with minimal performance loss. The approach outperforms alternatives like LLMs in efficiency and effectiveness, supporting GNNs' adoption for automating agentic workflow optimization.

## Method Summary
The method encodes agentic workflows as graphs where nodes represent workflow components and edges capture dependencies. GNNs process these graph representations to generate embeddings at the graph level. These embeddings are combined with task embeddings to form the input for a performance predictor that estimates workflow success probability. The approach leverages the structural information captured in the workflow graph to make predictions without requiring actual LLM execution, enabling rapid evaluation and optimization of workflow candidates.

## Key Results
- GNNs achieve average accuracy of 0.78 and utility of 0.72 in predicting workflow performance
- Prediction models are robust across different LLM configurations and domains
- Workflow optimization accelerated by 125x compared to execution-based evaluation with minimal performance degradation

## Why This Works (Mechanism)
The method works by leveraging GNNs' ability to capture structural and relational patterns in agentic workflows. Workflows are naturally represented as graphs with components as nodes and dependencies as edges. GNNs excel at learning representations from such graph-structured data, encoding both local component properties and global workflow topology into embeddings. When combined with task-specific information, these embeddings enable accurate prediction of whether a given workflow will successfully solve a task, without requiring expensive LLM inference for each candidate workflow.

## Foundational Learning

**Graph Neural Networks (GNNs)**: Neural architectures designed to process graph-structured data by aggregating information from neighboring nodes.
*Why needed*: Workflows have inherent graph structure that requires specialized processing beyond traditional neural networks.
*Quick check*: Verify GNN can propagate information across workflow dependency chains.

**Graph-level embeddings**: Fixed-size vector representations that capture the entire graph's structure and node features.
*Why needed*: Performance prediction requires a single representation summarizing the complete workflow.
*Quick check*: Confirm embedding size remains constant regardless of workflow size.

**Workflow encoding as graphs**: Converting agentic workflows into graph representations with components as nodes and dependencies as edges.
*Why needed*: Provides structured input format for GNNs to process workflow information.
*Quick check*: Ensure all workflow components and dependencies are represented in the graph.

## Architecture Onboarding

**Component map**: Workflow Graph -> GNN Encoder -> Graph Embedding -> Predictor -> Performance Score

**Critical path**: Workflow encoding and GNN processing represent the core computational path for generating predictions.

**Design tradeoffs**: The approach balances prediction accuracy against computational efficiency, favoring rapid evaluation over perfect prediction. Static workflow encoding simplifies prediction but may miss dynamic execution behaviors.

**Failure signatures**: Poor performance occurs when workflows have complex dynamic elements, non-standard execution patterns, or when the training data lacks sufficient diversity in workflow structures.

**First experiments**:
1. Validate GNN embeddings capture workflow structural differences by visualizing embeddings for different workflow types
2. Test predictor accuracy on held-out workflows from FLORA-Bench to establish baseline performance
3. Compare prediction speed against actual workflow execution time across workflow sizes

## Open Questions the Paper Calls Out
None

## Limitations
- FLORA-Bench dataset generation used specific prompting strategies that may not generalize to all real-world scenarios
- Static workflow prediction cannot capture dynamic aspects like intermediate failures or feedback loops
- The 125x speedup claim assumes negligible GNN prediction overhead, which may vary in production environments

## Confidence

**High**: GNN prediction accuracy (0.78) and utility (0.72) on FLORA-Bench are directly measured results from extensive experiments.

**Medium**: Claims about robustness to different LLMs, as testing was limited to a specific set of models.

**Low**: Broader claims about GNN superiority over all alternative prediction methods, as comparison was restricted to a limited set.

## Next Checks

1. Test GNN predictions on real-world agentic workflows outside FLORA-Bench to assess external validity
2. Evaluate prediction accuracy on workflows with dynamic elements and feedback loops
3. Benchmark the complete optimization pipeline including GNN training time in resource-constrained environments