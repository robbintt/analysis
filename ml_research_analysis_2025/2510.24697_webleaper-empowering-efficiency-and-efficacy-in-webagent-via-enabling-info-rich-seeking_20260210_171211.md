---
ver: rpa2
title: 'WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich
  Seeking'
arxiv_id: '2510.24697'
source_url: https://arxiv.org/abs/2510.24697
tags:
- entities
- agent
- reasoning
- task
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses low search efficiency in LLM-based information-seeking
  agents, caused by sparse target entities in training tasks. To overcome this, the
  authors propose WebLeaper, a framework that constructs high-coverage IS tasks and
  generates efficient solution trajectories.
---

# WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking

## Quick Facts
- arXiv ID: 2510.24697
- Source URL: https://arxiv.org/abs/2510.24697
- Reference count: 37
- Primary result: Proposed WebLeaper framework improves information-seeking agent performance on five benchmarks (BrowserComp, GAIA, xbench-DeepSearch, WideSearch, Seal-0) with 73.2 on GAIA, 38.8 on BrowseComp, and 72.0 on xbench-DeepSearch.

## Executive Summary
This paper addresses low search efficiency in LLM-based information-seeking agents caused by sparse target entities in training tasks. The authors propose WebLeaper, a framework that constructs high-coverage IS tasks and generates efficient solution trajectories. By formulating IS as a tree-structured reasoning problem and creating three task variants (Basic, Union, Reverse-Union), WebLeaper embeds more target entities within constrained contexts. Using Wikipedia tables, they synthesize tasks requiring integration of multiple information sources and curate training trajectories using Information-Seeking Rate (ISR) and Information-Seeking Efficiency (ISE) metrics. Experiments show consistent improvements in both effectiveness and efficiency over strong baselines.

## Method Summary
WebLeaper constructs information-seeking tasks from Wikipedia tables by first cleaning ~2M tables to retain only large, well-formed ones (10-200 rows, 3-20 columns). It then generates three task variants: Basic tasks from 3-layer reasoning trees, Union tasks via maximal biclique enumeration on bipartite graphs of trees vs. relations, and Reverse-Union tasks that obfuscate anchor entities with descriptive clues. The framework filters trajectories using dual criteria (ISR > 0.3 and ISE > 0.1) before training a Qwen3-30B-A3B-Thinking-2507 model with two-stage training: supervised fine-tuning on filtered trajectories followed by reinforcement learning with Group Relative Policy Optimization (GRPO) using a hybrid reward system combining F-score-based rewards for WebLeaper tasks and binary rewards for legacy tasks.

## Key Results
- WebLeaper achieves 73.2 on GAIA, 38.8 on BrowseComp, and 72.0 on xbench-DeepSearch benchmarks
- Reverse-Union variant shows superior performance due to increased reasoning complexity and entity density
- Dual-criterion trajectory filtering (ISR+ISE) outperforms single-metric filtering on complex tasks
- WebLeaper achieves Pareto improvement: higher accuracy with fewer average action rounds compared to baselines

## Why This Works (Mechanism)

### Mechanism 1: Entity Density Stabilizes Efficiency Training Signal
Increasing target entities per task reduces variance in efficiency metrics, providing more reliable gradients for learning efficient search behavior. The paper proves ISE variance scales as O(1/n) where n is the number of target entities. With sparse entities, ISE measurements are noisy—agents get inconsistent feedback on whether their search was efficient. By synthesizing tasks with ~100+ entities per question, ISE becomes a stable training signal, allowing the model to reliably learn which action patterns lead to efficient discovery.

### Mechanism 2: Dual-Criterion Trajectory Filtering Eliminates Efficiency-Accuracy Tradeoff
Filtering trajectories by both ISR (coverage) AND ISE (efficiency) simultaneously produces training data where accuracy and efficiency correlate positively rather than being treated as tradeoffs. Prior work filtered primarily by task completion, creating datasets where inefficient-but-successful trajectories teach agents that exhaustive search is acceptable. WebLeaper's coverage criterion (ISR > 0.3) and efficiency criterion (ISE > 0.1) jointly eliminate both incomplete trajectories and unnecessarily long ones, teaching the model that efficient search patterns are prerequisites for success.

### Mechanism 3: Reverse-Union Prevents Keyword-Matching Shortcuts
The Reverse-Union task variant forces agents to perform multi-step deduction before initiating search, preventing surface-level keyword matching strategies. Standard Union tasks can be solved by searching entity sets and intersecting—no deep reasoning required. Reverse-Union obscures the anchor entity behind descriptive clues, requiring the agent to first deduce the anchor, then use it as a pivot. This compels the model to integrate retrieval with reasoning rather than treating search as a separate lookup phase.

## Foundational Learning

- **Concept: ReAct Framework for Agent Trajectories**
  - Why needed here: WebLeaper models agent behavior as sequential thought-action-observation tuples. Understanding this interleaving is prerequisite to grasping how ISR/ISE are computed per-trajectory and how GRPO optimizes policy over action sequences.
  - Quick check question: Given a trajectory with 5 thoughts, 5 actions, and 5 observations, which component would you modify to change the agent's search strategy?

- **Concept: F-score as Balanced Precision-Recall**
  - Why needed here: The hybrid reward system uses weighted F-score to combine soft precision and soft recall. Understanding how F-score balances these helps interpret why ω > 1 prioritizes recall (entity coverage) over precision.
  - Quick check question: If an agent retrieves 50 entities but only 25 are in the ground truth (size 40), what are precision, recall, and F1-score?

- **Concept: GRPO (Group Relative Policy Optimization)**
  - Why needed here: WebLeaper uses GRPO rather than standard PPO for RL fine-tuning. GRPO estimates advantage via group-relative rewards rather than learned value functions—critical for understanding why this is more practical for agent training.
  - Quick check question: In GRPO, if you sample k=4 trajectories with rewards [0.2, 0.5, 0.3, 0.6], what is the standardized advantage for the trajectory with reward 0.5?

## Architecture Onboarding

- **Component map**: Wikipedia Tables → [Data Cleaning Pipeline] → Basic Tasks (tree structure) → Union Algorithm (biclique enum) → Union Tasks → Reverse-Union Generator → Reverse-Union Tasks → Open-source Agent → [Trajectory Generation] → Raw Trajectories → ISR + ISE Filtering → Curated Trajectories → SFT on Curated Data → RL with Hybrid Reward → Final Agent

- **Critical path**:
  1. Table cleaning: Filter 2M Wikipedia tables to retain only large, well-formed, structurally homogeneous tables
  2. Maximal biclique enumeration: Find maximal union groups for Union task synthesis with appropriate k_min and m_min settings
  3. Trajectory filtering thresholds: α=0.3 (ISR) and β=0.1 (ISE) are critical for sufficient training data

- **Design tradeoffs**:
  - Entity count vs. task difficulty: More entities stabilizes ISE but increases task complexity
  - Soft vs. hard matching: LLM-as-judge for semantic similarity is more accurate but slower than exact match
  - Hybrid reward complexity: Adds implementation overhead but maintains compatibility with legacy benchmarks

- **Failure signatures**:
  - All Basic tasks perform poorly: Shortcut learning—model memorizes single-source lookup patterns
  - ISR high but ISE low on validation: Model learned to find entities but inefficiently
  - Reverse-Union tasks unsolvable: Clues too ambiguous
  - RL reward plateaus early: Could indicate reward hacking or insufficient exploration

- **First 3 experiments**:
  1. Baseline comparison: Train Qwen3-30B-A3B-Thinking on WebSailor-V2-5k only vs. WebSailor-V2-5k + WebLeaper-Reverse-Union-5k on BrowseComp and GAIA
  2. Ablation on trajectory filtering: Compare ISR-only, ISE-only, and ISR+ISE filtering strategies on WideSearch
  3. Efficiency-efficiency frontier: Plot performance vs. average action rounds for WebLeaper vs. baseline

## Open Questions the Paper Calls Out

### Open Question 1
How can single-source "Basic" tasks be modified to prevent models from learning superficial shortcuts while retaining high entity density? The authors mitigated this by adopting "Union" tasks but did not explore regularization techniques to salvage the "Basic" single-source training paradigm.

### Open Question 2
Does the Maximal Biclique Enumeration algorithm used for task synthesis face computational limits when scaling beyond curated Wikipedia tables? The paper uses ~2 million tables, but generalizing this to the entire web may render the exact enumeration algorithm intractable.

### Open Question 3
Does the inter-dependency of reasoning steps in "Reverse-Union" tasks violate the i.i.d. assumption required for the ISE metric's stability? Proposition 1 proves ISE variance is O(1/n) by assuming steps to discover entities are i.i.d., but Reverse-Union tasks require deducing an anchor entity before finding others, creating temporal dependencies.

## Limitations
- The variance reduction mechanism relies on i.i.d. entity independence assumption that may not hold for semantically related entities
- Hybrid reward system's ω parameter and soft matching thresholds are not fully specified, creating potential for reward hacking
- No ablation on trajectory filtering threshold sensitivity (α=0.3, β=0.1)

## Confidence
- **High**: Task synthesis methodology (Basic/Union/Reverse-Union construction), ISR/ISE metric formulation, experimental benchmark results
- **Medium**: Variance reduction mechanism for ISE stability, dual-criterion trajectory filtering benefits, Reverse-Union reasoning complexity claims
- **Low**: Specific hybrid reward implementation details, exact GRPO hyperparameters, LLM prompt specifications for task generation

## Next Checks
1. **Ablation study on filtering thresholds**: Vary α ∈ [0.2, 0.4] and β ∈ [0.05, 0.15] to measure impact on training data volume and final performance—test if WebLeaper's gains persist across threshold ranges
2. **Mechanistic verification of efficiency gains**: Track average action rounds and entity discovery rate per round on BrowseComp—confirm that WebLeaper learns more efficient search patterns, not just better accuracy
3. **Generalization to other domains**: Apply WebLeaper's trajectory filtering methodology to non-Wikipedia sources (e.g., news articles, scientific papers)—test if efficiency gains transfer beyond structured table data