---
ver: rpa2
title: Theoretical Analysis of Relative Errors in Gradient Computations for Adversarial
  Attacks with CE Loss
arxiv_id: '2507.22428'
source_url: https://arxiv.org/abs/2507.22428
tags:
- attacks
- attack
- adversarial
- loss
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes floating-point computation errors in gradient-based
  adversarial attacks using the cross-entropy loss. It systematically examines four
  attack scenarios (unsuccessful/successful untargeted and targeted attacks) and identifies
  relative gradient errors caused by underflow and rounding as key contributors to
  overestimation of model robustness.
---

# Theoretical Analysis of Relative Errors in Gradient Computations for Adversarial Attacks with CE Loss

## Quick Facts
- arXiv ID: 2507.22428
- Source URL: https://arxiv.org/abs/2507.22428
- Reference count: 40
- Primary result: T-MIFPE loss function minimizes floating-point errors in adversarial gradient computations, achieving near-optimal attack results in 100 iterations versus 4900+ required by existing benchmarks.

## Executive Summary
This paper addresses a critical limitation in adversarial attack effectiveness: floating-point computation errors in gradient calculations. The authors demonstrate that cross-entropy loss gradients suffer from underflow and rounding errors that create relative errors, leading to overestimated model robustness. They propose T-MIFPE, a theoretically optimal loss function that incorporates an adaptive scaling factor to minimize these errors. Extensive experiments on MNIST, CIFAR-10, and CIFAR-100 show T-MIFPE outperforms existing loss functions in attack potency while requiring significantly fewer iterations.

## Method Summary
The T-MIFPE loss function dynamically computes an optimal scaling factor t* for each attack iteration based on the current logits. This scaling factor is derived from the mathematical analysis of floating-point error propagation in cross-entropy gradient computation. The method involves sorting logits, computing B and S values, and selecting t* based on the attack phase (untargeted/targeted × unsuccessful/successful). The scaled logits are then passed through standard cross-entropy loss with gradient detachment applied to prevent backpropagation through the scaling factor itself. This approach is integrated into PGD attacks with cosine step-size decay and momentum.

## Key Results
- T-MIFPE achieves near-optimal robust accuracy results using only 100 PGD iterations, compared to 4900+ iterations required by RobustBench AA benchmark
- Outperforms CE, C&W, DLR, and MIFPE losses across multiple datasets (MNIST, CIFAR-10, CIFAR-100)
- Theoretical analysis identifies floating-point underflow and rounding as key contributors to overestimation of model robustness
- Scenario-specific t* adaptation handles different attack phases effectively

## Why This Works (Mechanism)

### Mechanism 1: Floating-point errors induce relative gradient errors that reduce attack effectiveness
Cross-entropy loss computations suffer from floating-point truncation errors that create relative errors in computed gradients. When gradient magnitudes approach machine epsilon, relative error approaches 1.0, effectively randomizing update directions. The truncation error ε creates a relative error δ = ε / |gradient|, which becomes dominant when gradients are small.

### Mechanism 2: Optimal scaling factor t* minimizes relative error by maximizing gradient coefficient
There exists a theoretically optimal scaling factor t* that maximizes the coefficient term g(t), thereby minimizing the upper bound of relative error. For unsuccessful untargeted attacks, g(t) = c(1 - p^c_π1) where c = t/Δ_value. The optimal t* is found at the root of g'(t) = 0.

### Mechanism 3: Scenario-specific t* adaptation handles attack phase transitions
Different attack phases (unsuccessful vs. successful, untargeted vs. targeted) require different t* formulations. Each scenario has a distinct g(t) function with its own bounded optimum or monotonic behavior. The attack must correctly identify which phase it's in to apply the appropriate t* formula.

## Foundational Learning

- **Concept**: Cross-entropy loss gradient structure
  - Why needed: Understanding how CE decomposes into coefficient terms and logit differences is essential for tracing where floating-point errors enter
  - Quick check: Given logits [3.0, 1.5, 0.5] and true class 0, compute softmax probability p_0 and explain which term in ∇CE becomes smallest (most error-prone)

- **Concept**: Floating-point truncation and underflow thresholds
  - Why needed: The paper explicitly bounds errors using ε_max and λ (underflow threshold). Knowing these constants validates the theoretical bounds
  - Quick check: What is the smallest positive normalized 32-bit float? At what exponent does underflow occur for exp(-x)?

- **Concept**: PGD attack iteration mechanics
  - Why needed: T-MIFPE modifies the loss function within PGD iterations. Understanding projection and update step clarifies where T-MIFPE plugs in
  - Quick check: In PGD with ε=8/255, step size α=2/255, and ℓ∞ norm, what happens to perturbation [0.04, -0.03, 0.05] after projection?

## Architecture Onboarding

- **Component map**: Input x, y → Model f_θ → Logits z → Sort & compute Δ, B, S → Detect attack phase (4 scenarios) → Compute optimal t* → Scale logits → Compute L_T-MIFPE → Backprop → PGD update → Project

- **Critical path**: The t* computation requires sorted logits and correctly identified attack phase. A bug in either produces wrong scaling, potentially increasing gradient error rather than decreasing it.

- **Design tradeoffs**: Adaptive t* is theoretically optimal but requires per-iteration computation versus fixed T=1 (MIFPE) which is faster but suboptimal. Detachment of Δ_value is essential to prevent gradients from flowing through the scaling factor itself.

- **Failure signatures**: Robust accuracy higher than CE baseline indicates t* computation bug or wrong phase detection. NaN/Inf in t* caused by extreme logit values requires numerical stability checks. No improvement over MIFPE suggests t* ≈ 1 consistently.

- **First 3 experiments**:
  1. Validate t* behavior: On single CIFAR-10 image, log t* values across 100 PGD iterations. Confirm t* varies dynamically and correlates with reduced δ^sup compared to T=1.
  2. Ablation on phase detection: Run T-MIFPE with forced phase misclassification. Compare robust accuracy to correct phase detection.
  3. Precision sensitivity: Run T-MIFPE in 16-bit, 32-bit, and 64-bit modes. Verify 64-bit shows smallest improvement over CE.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the T-MIFPE loss function improve attack potency in targeted adversarial attack scenarios?
- Basis in paper: Section 7 (Limitations) explicitly states that while theoretical analysis was provided for targeted attacks, "we did not conduct experimental comparisons for targeted attack scenarios."
- Why unresolved: The paper derives distinct optimal scaling factors for both untargeted and targeted phases, but empirical validation is currently restricted to untargeted attacks.

### Open Question 2
- Question: What is the computational overhead of dynamically computing the optimal scaling factor t* at every iteration?
- Basis in paper: The method requires recomputing t* based on logits for every attack iteration, unlike the static scaling factor in MIFPE.
- Why unresolved: The paper claims high efficiency (achieving results in 100 iterations) but does not quantify the added latency of the dynamic calculation per step.

### Open Question 3
- Question: Is T-MIFPE effective when integrated into attack frameworks other than Projected Gradient Descent (PGD)?
- Basis in paper: The experimental section relies exclusively on the PGD attack framework to validate the loss function.
- Why unresolved: The benefits of minimizing floating-point errors may interact differently with other optimization algorithms or decision-based attacks not tested in the paper.

## Limitations
- Limited experimental validation for targeted attack scenarios despite theoretical analysis
- Does not quantify computational overhead of dynamic t* computation
- Only validated within PGD attack framework, not tested with alternative attack methods

## Confidence

- **Mechanism 1 (Floating-point error causation)**: Medium - Theoretical derivation is sound, but empirical validation showing T-MIFPE specifically reduces relative error magnitude is limited
- **Mechanism 2 (Optimal scaling factor)**: High - Mathematical optimization is rigorous with clear maxima identification in Figure 1
- **Mechanism 3 (Scenario-specific adaptation)**: Medium - Derivations are complete, but practical benefit of adaptive versus fixed scaling across attack phases needs more extensive ablation

## Next Checks

1. **Error magnitude validation**: Instrument T-MIFPE to measure and compare relative gradient errors (δ^sup) against CE and MIFPE baselines during attack iterations. Confirm theoretical error reduction translates to empirical improvement.

2. **Phase detection robustness**: Create adversarial examples specifically designed to trigger phase misclassification. Evaluate whether T-MIFPE maintains benefits under deliberate phase confusion attacks.

3. **Cross-precision comparison**: Run identical attack scenarios using 16-bit, 32-bit, and 64-bit floating-point precision. Quantify how relative error reduction scales with precision and verify the diminishing returns predicted by theory.