---
ver: rpa2
title: Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions
arxiv_id: '2507.10809'
source_url: https://arxiv.org/abs/2507.10809
tags:
- out-of-domain
- event
- causal
- intervention
- cause
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of inferring causal relationships
  in temporal event sequences when out-of-domain interventions occur. Existing methods
  fail to account for how such external interventions can shift causal dynamics between
  events.
---

# Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions

## Quick Facts
- **arXiv ID**: 2507.10809
- **Source URL**: https://arxiv.org/abs/2507.10809
- **Reference count**: 0
- **Key outcome**: A new causal framework and Transformer-based neural network that effectively infers causal relationships in temporal event sequences when out-of-domain interventions occur, significantly outperforming baselines in both ATE estimation and process fitting.

## Executive Summary
This paper addresses the problem of inferring causal relationships in temporal event sequences when out-of-domain interventions occur. Existing methods fail to account for how such external interventions can shift causal dynamics between events. The authors propose a new causal framework that extends average treatment effect (ATE) to capture these shifts, using propensity score-based estimation to adjust for confounding. They design a Transformer-based neural network model that integrates out-of-domain intervention information, enabling both long-range dependency modeling and local pattern capture. Extensive experiments on simulated and real-world datasets show that the proposed method significantly outperforms baselines in ATE estimation (lower bias and MSE) and process fitting (lower NLL, RMSE, and MAE), while aligning with established medical literature.

## Method Summary
The paper introduces a causal framework that extends average treatment effect (ATE) to capture shifts in causal relationships caused by out-of-domain interventions. The framework models cause and outcome events as binary variables at discrete time points, while interventions are represented as binary vectors indicating the presence of various out-of-domain factors. The authors define ATE with intervention shifts using propensity score-based estimation, leveraging a logistic regression model to estimate the probability of cause events given historical information and interventions. The neural network architecture employs a Transformer backbone for long-range dependency modeling, augmented with local pattern capture through dilated convolutions and multi-head self-attention. The model uses positional encoding to handle temporal information and integrates intervention features through a gating mechanism.

## Key Results
- The proposed method achieves lower ATE estimation bias and MSE compared to baselines on both simulated and real-world datasets
- Process fitting performance shows significantly lower NLL, RMSE, and MAE than competing approaches
- The model successfully aligns with established medical literature in predicting glucose-insulin causal relationships under various intervention conditions

## Why This Works (Mechanism)
The framework works by explicitly modeling how external interventions modify the causal relationship between cause and outcome events, rather than treating them as mere confounders. By extending ATE to account for intervention-induced shifts, the method captures the dynamic nature of causal effects in temporal sequences. The propensity score-based estimation adjusts for confounding by balancing the distribution of covariates between treatment groups, while the Transformer architecture enables effective modeling of complex temporal dependencies. The combination of global context through self-attention and local pattern capture through dilated convolutions allows the model to learn both long-range and fine-grained causal patterns.

## Foundational Learning
- **Causal inference with interventions**: Why needed - to understand how external factors modify causal relationships beyond simple confounding; Quick check - verify the extended ATE formulation correctly captures intervention effects in controlled simulations
- **Propensity score estimation**: Why needed - to balance covariate distributions and reduce confounding bias; Quick check - validate that propensity scores effectively equalize treatment and control group characteristics
- **Temporal causal modeling**: Why needed - to capture dynamic causal relationships in event sequences; Quick check - confirm that the model accurately reconstructs known temporal causal patterns in synthetic data
- **Transformer architecture for sequences**: Why needed - to model long-range dependencies in temporal data; Quick check - test that self-attention layers effectively capture distant causal relationships
- **Dilated convolutions for local patterns**: Why needed - to capture fine-grained temporal patterns alongside global context; Quick check - verify that dilated convolutions improve local pattern detection in controlled experiments
- **Positional encoding**: Why needed - to preserve temporal ordering information in the Transformer; Quick check - confirm that removing positional encoding degrades temporal pattern recognition

## Architecture Onboarding

**Component map**: Event sequence → Positional Encoding → Transformer Layers → Dilated Convolutions → Self-Attention → Intervention Integration → Outcome Prediction

**Critical path**: Historical event data → Transformer self-attention → Dilated convolution features → Intervention gating → Causal effect estimation

**Design tradeoffs**: The architecture balances global context capture (Transformer) with local pattern detection (dilated convolutions), but this increases model complexity and computational cost. The binary intervention representation is simple but may not capture intervention intensity.

**Failure signatures**: 
- Poor performance when interventions are highly correlated with causes (violates unconfoundedness assumption)
- Degradation in accuracy for very sparse event sequences due to insufficient temporal context
- Overfitting when intervention types vastly outnumber available training samples

**3 first experiments**:
1. Test the model on a synthetic dataset with known intervention effects to verify accurate ATE estimation
2. Evaluate performance on irregularly sampled event sequences to assess temporal robustness
3. Compare against a variant without dilated convolutions to measure the contribution of local pattern capture

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the proposed causal framework be extended to handle continuous or ordinal cause and intervention variables rather than being limited to binary occurrence indicators?
- Basis in paper: [explicit] "Future work should extend the framework to continuous intervention variables for more fine-grained modeling and improved estimation precision." (Page 10)
- Why unresolved: The current theoretical definition of ATE and the propensity score estimator rely on binary states ($c_w^t, v_w^t \in \{0,1\}$), which simplifies the analysis but ignores the intensity or dosage of events.
- What evidence would resolve it: A generalized mathematical formulation of Theorem 2 for continuous variables, validated on datasets where intervention "dosage" (e.g., insulin amount) varies.

### Open Question 2
- Question: How can the estimation framework be adapted to maintain accuracy when out-of-domain interventions open backdoor causal paths between the cause and outcome events?
- Basis in paper: [inferred] "if interventions open backdoor causal paths between cause and outcome events, estimation accuracy may be compromised, requiring careful domain knowledge for intervention selection." (Page 10)
- Why unresolved: The current unconfoundedness assumption (Assumption 2) may fail if the intervention variable creates a spurious association between cause and outcome, a scenario the current propensity score adjustment does not explicitly handle.
- What evidence would resolve it: A simulation study demonstrating that the estimator becomes biased when backdoor paths are artificially introduced, and a proposed correction method that mitigates this bias.

### Open Question 3
- Question: Can hierarchical intervention modeling effectively mitigate the combinatorial explosion of intervention types without losing the ability to detect specific causal shifts?
- Basis in paper: [inferred] "Grouping related interventions and modeling their effects hierarchically could mitigate the combinatorial explosion problem..." (Page 20)
- Why unresolved: As the number of distinct out-of-domain interventions increases, the binary vector representation suffers from data sparsity, making it difficult to estimate propensity scores for rare intervention combinations.
- What evidence would resolve it: Empirical results on a high-dimensional dataset showing that a hierarchical model outperforms the flat binary model in ATE estimation bias and variance.

## Limitations
- The framework assumes reliable detection and characterization of out-of-domain interventions, which may not hold in all real-world scenarios
- Reliance on propensity score estimation requires available and correctly specified covariates, with potential bias if this assumption is violated
- Performance in highly sparse or irregularly sampled event sequences remains uncertain despite strong results on tested datasets

## Confidence
- **High confidence**: The mathematical framework for extending ATE and the propensity score-based estimation approach
- **Medium confidence**: The Transformer-based neural network architecture and its integration of intervention information
- **Medium confidence**: The experimental results showing performance improvements over baselines
- **Low confidence**: The framework's robustness to unmeasured confounding and its performance in highly irregular temporal data

## Next Checks
1. Test the framework on datasets with varying levels of intervention intensity and temporal irregularity to assess robustness across different regimes
2. Evaluate performance when key covariates for propensity score estimation are partially missing or noisy to understand sensitivity to data quality
3. Apply the method to longitudinal medical datasets with known intervention patterns to validate alignment with clinical expectations and existing medical literature