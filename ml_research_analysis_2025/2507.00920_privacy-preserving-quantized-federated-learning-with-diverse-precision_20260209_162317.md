---
ver: rpa2
title: Privacy-Preserving Quantized Federated Learning with Diverse Precision
arxiv_id: '2507.00920'
source_url: https://arxiv.org/abs/2507.00920
tags:
- learning
- algorithm
- quantization
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of preserving privacy in federated
  learning (FL) while maintaining learning utility under quantization heterogeneity
  across devices. The authors propose a novel differentially private stochastic quantization
  (DP-SQ) method that simultaneously achieves differential privacy (DP) guarantees
  and minimizes quantization distortion.
---

# Privacy-Preserving Quantized Federated Learning with Diverse Precision

## Quick Facts
- **arXiv ID**: 2507.00920
- **Source URL**: https://arxiv.org/abs/2507.00920
- **Reference count**: 40
- **Primary result**: Novel DP-SQ quantizer achieves both ϵ-differential privacy guarantees and bounded quantization distortion simultaneously, with up to 80% testing accuracy compared to 41% for baseline methods.

## Executive Summary
This paper addresses the challenge of preserving privacy in federated learning (FL) while maintaining learning utility under quantization heterogeneity across devices. The authors propose a novel differentially private stochastic quantization (DP-SQ) method that simultaneously achieves differential privacy (DP) guarantees and minimizes quantization distortion. The key innovation is an optimization framework that determines quantization probabilities based on DP requirements while minimizing expected distortion, resulting in bounded distortion unlike prior approaches. To handle quantization heterogeneity, the authors introduce a cluster size optimization technique combined with a linear fusion approach that assigns weights proportionally to effective signal-to-noise ratios.

## Method Summary
The method introduces DP-SQ quantizer that assigns quantization probabilities via constrained optimization to achieve ϵ-DP while minimizing expected distortion. For heterogeneous quantization, devices are grouped by quantization resolution, and cluster sizes are optimized via linear integer programming to minimize learning error bounds under bandwidth constraints. Fusion weights are assigned proportionally to effective SNR, automatically upweighting devices with higher quantization resolution and better channel conditions. The approach is evaluated on MNIST with two-layer MLP against DLG attacks and compared with conventional LaplaceSQ-FL methods.

## Key Results
- DP-SQ achieves bounded quantization distortion (orders of magnitude lower than LaplaceSQ) while providing ϵ-DP guarantees
- Cluster size optimization combined with SNR-based fusion maintains stable performance across different privacy requirements
- DLG attack evaluation shows SSIM values remaining near zero even after 40 attack iterations
- Learning utility maintained with up to 80% testing accuracy compared to 41% for LaplaceSQ-FL baseline
- Privacy-utility tradeoff effectively resolved through joint optimization of quantization probabilities and aggregation weights

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The proposed DP-SQ achieves both ϵ-differential privacy guarantees and bounded quantization distortion simultaneously.
- **Mechanism:** For input value `a` in interval `[qi, qi+1)`, the quantizer assigns `a` to either `qi` or `qi+1` with optimized probability `p* = e^ϵ/(e^ϵ + 1)`. The probability is determined by solving a constrained optimization that minimizes expected distortion subject to the DP constraint `e^(-ϵ) ≤ p/(1-p) ≤ e^ϵ`.
- **Core assumption:** Input values lie within predefined quantization range `[a, ā]`, and gradient updates can be clipped to this range without catastrophic information loss.
- **Evidence anchors:** Abstract states the method "simultaneously achieves differential privacy (DP) guarantees and minimizes quantization distortion"; Section II-B establishes the optimization framework for determining `p` to ensure ϵ-DP while minimizing expected quantization distortion.
- **Break condition:** If clipping constant `C` is set too small relative to actual gradient magnitudes, or if ϵ approaches 0, the quantizer degenerates to uniform random assignment, causing unbounded learning error growth over many rounds.

### Mechanism 2
- **Claim:** The linear fusion approach with effective SNR-based weighting improves aggregation accuracy under heterogeneous quantization resolutions and noisy links.
- **Mechanism:** Fusion weights `ωm,u*` are assigned proportionally to effective SNR `θm,u = 1/(E[||Qbm,ϵ1,m,u(ṽm,u,t) - ṽm,u,t||²₂] + dσ²m,u)`. This automatically upweights devices with higher quantization bits `bm` (lower quantization distortion) and lower channel noise variance `σ²m,u`.
- **Core assumption:** Channel noise `nm,u,t` follows Gaussian distribution with zero mean and is independent of quantization noise; devices within the same group have statistically similar noise characteristics.
- **Evidence anchors:** Abstract mentions "linear fusion approach that assigns weights proportionally to effective signal-to-noise ratios"; Section III-C shows solution implies fusion weights are assigned proportionally to effective SNR `θm,u`.
- **Break condition:** If link noise estimates are inaccurate or highly time-varying, static SNR weights will misallocate aggregation importance, potentially upweighting noisy or corrupted updates.

### Mechanism 3
- **Claim:** Cluster size optimization via linear integer programming minimizes learning error bound while satisfying bandwidth constraints.
- **Mechanism:** The deviation term `∆` in the convergence bound scales linearly with cluster sizes `{cm}`. The optimization problem minimizes `Σm (cm/gm) * Σu [8C²/(2bm-1)² + σ²m,u]` subject to total bit budget `Σm bm·cm ≤ B`, device availability constraints, and total participant count `Σm cm = N`.
- **Core assumption:** Devices are sampled uniformly from each group, and the gradient distribution is stationary across rounds so that optimal cluster sizes remain valid throughout training.
- **Evidence anchors:** Abstract mentions "cluster size optimization technique combined with a linear fusion approach"; Section IV-B states the problem is linear integer programming solvable using branch-reduce-and-bound algorithm.
- **Break condition:** If device availability is highly dynamic or groups have non-uniform data distributions, the pre-computed optimal cluster sizes may not reflect actual contribution quality.

## Foundational Learning

- **Concept: Differential Privacy (ϵ-DP)**
  - **Why needed here:** The entire privacy guarantee rests on understanding how ϵ controls the privacy-utility tradeoff. Smaller ϵ means stronger privacy but requires more noise/randomization, which degrades model accuracy.
  - **Quick check question:** Given two neighboring datasets differing by one sample, can you explain why `Pr[M(A) ∈ S] ≤ e^ϵ · Pr[M(A') ∈ S]` provides privacy protection?

- **Concept: Stochastic Quantization**
  - **Why needed here:** Unlike deterministic quantization, stochastic quantization provides the randomness source for DP guarantees while also enabling communication compression. Understanding the probability mapping is essential for implementing the quantizer.
  - **Quick check question:** For a value `a = 2.3` with quantization levels `{2.0, 2.5}`, how would deterministic vs. stochastic quantization differ in their outputs?

- **Concept: Federated Learning Convergence Analysis**
  - **Why needed here:** The cluster size optimization derives from the convergence bound (Theorem 1). You need to understand how gradient variance, quantization error, and aggregation weights contribute to the learning error upper bound.
  - **Quick check question:** In the bound `E[||wt - w*||²₂] ≤ (t₀/t)E[||wt₀ - w*||²₂] + m₃,t + (t-4)∆`, what does the `(t-4)∆` term imply about long training runs?

## Architecture Onboarding

- **Component map:**
Fusion Center -> Global model wt storage -> Cluster optimizer (LIP solver) -> Fusion weight calculator -> Aggregator -> wt+1 = wt + Σm Σu ωm,u(Qbm,ϵ1,m,u(·) + nm,u,t)
Device dm,u in Group Gm -> Local dataset Dm,u -> Local trainer (L-step mini-batch SGD) -> Clipper -> DP-SQ quantizer -> Transmitter over noisy channel

- **Critical path:**
1. Initialize w₀, set DP parameters {ϵ1,m,u}, clipping constant C
2. Each round: FC solves LIP (Eq. 27) to get cluster sizes {cm}
3. Select devices randomly from each group per cluster sizes
4. Devices perform L local SGD iterations, compute model difference vm,u,t
5. Apply ℓ₁-norm clipping, then DP-SQ quantization
6. FC receives quantized updates with channel noise
7. Compute fusion weights using Eq. 14, aggregate updates
8. Repeat until convergence or max rounds T

- **Design tradeoffs:**
- Smaller ϵ1,m,u → stronger privacy but higher quantization distortion (bounded, unlike Laplace noise)
- Larger clipping constant C → less clipping bias but higher quantization error term `8dC²/(2bm-1)²`
- More local iterations L → better local convergence but potential drift from global optimum
- Higher bit allocation to one group → fewer devices can participate under bit budget B

- **Failure signatures:**
- Training loss plateaus early + high final loss → Check: clipping constant C may be too aggressive; SNR estimates may be stale
- SSIM values increase during DLG attack → Check: ϵ1,m,u may be too large; quantization probabilities not computed correctly
- Learning error bound (Eq. 26) grows with t → Expected for large ∆; cluster sizes may need re-optimization
- Testing accuracy degrades after initial improvement → Deviation term (t-4)∆ becoming dominant; reduce ∆ via better cluster allocation

- **First 3 experiments:**
1. **Validate DP-SQ distortion bound:** Implement the quantizer with b ∈ {4, 5, 6} bits and ϵ₁ ∈ {0.1, 0.5, 1.0, 1.5}. Measure expected distortion `E[|Qb,ϵ1(a) - a|²]` against LaplaceSQ baseline. Expected: ~2.5 orders of magnitude lower distortion at ϵ₁ = 0.1, b = 6.
2. **Privacy protection assessment:** Run DLG attack (40 iterations) on single data point reconstruction. Compare SSIM between SQ-FL (no DP) and Algorithm 1 (ϵ1,m,u = 10⁻⁶). Expected: SQ-FL SSIM → 0.3+; Algorithm 1 SSIM → ~0.01.
3. **Learning utility comparison:** Train 2-layer MLP on MNIST with M=2 groups (b₁=2 bits, b₂=4 bits), N=10 devices/round, T=20 rounds. Compare Algorithm 1+FWO+CSO vs. LaplaceSQ-FL across ϵ1,m,u ∈ {10⁻⁶, 32×10⁻⁶}. Expected: Proposed method maintains ~80-90% accuracy; LaplaceSQ-FL degrades to ~41% under strict privacy.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the learning error bound be modified to prevent the deviation term $\Delta$ from causing unbounded error growth as the number of federated learning rounds $t$ increases?
- **Basis in paper:** [inferred] Theorem 1 establishes an upper bound where the error scales with $(t-4)\Delta$. The authors note this term "grows unbounded as $t$ increases," suggesting the current theoretical guarantee weakens over long training periods.
- **Why unresolved:** The current analysis relies on Assumption 5 (bounded bias) and the accumulation of quantization distortion and noise, which sum up over iterations without a mechanism to diminish the aggregate $\Delta$ term relative to $t$.
- **What evidence would resolve it:** A modified theoretical proof showing a vanishing or bounded error term as $t \to \infty$, or an empirical study demonstrating stable convergence over significantly more than T=20 rounds.

### Open Question 2
- **Question:** Does the proposed cluster size optimization and linear fusion technique maintain learning utility and convergence guarantees when local data is distributed in a non-IID manner across devices?
- **Basis in paper:** [inferred] In Section III-A, the network model explicitly assumes data elements are "i.i.d. across devices." The convergence analysis in Section IV relies on this assumption to bound gradient errors and establish the linear relationship between cluster sizes and learning error.
- **Why unresolved:** Non-IID data typically introduces gradient drift (client drift) which alters the dynamics of model aggregation. The current bounds rely on the stochastic gradient being an unbiased estimator of the global gradient (Assumption 3), which may not hold under high data heterogeneity.
- **What evidence would resolve it:** A convergence analysis that explicitly accounts for data heterogeneity (e.g., using a dissimilarity bound) or simulations on standard non-IID datasets (e.g., CIFAR-10 with Dirichlet distribution) showing maintained accuracy.

### Open Question 3
- **Question:** Can the differentially private stochastic quantizer be improved by utilizing non-uniform quantization levels to further minimize expected distortion for non-uniform data distributions?
- **Basis in paper:** [inferred] Section II-B defines the quantization levels as "uniformly spaced in the interval." While the probability $p$ is optimized for DP, the levels themselves are fixed and equidistant, which is suboptimal if the source data (model updates) is not uniformly distributed.
- **Why unresolved:** The optimization problem in (5) minimizes distortion subject to DP constraints but treats the quantization grid as a fixed constraint. Optimizing the grid geometry would turn the linear programming problem into a non-linear or mixed-integer challenge.
- **What evidence would resolve it:** A comparative analysis showing that a Lloyd-Max or density-aware quantizer achieves lower expected distortion $E[|Q(a)-a|^2]$ for the same $\epsilon$-DP budget compared to the proposed uniform quantizer.

## Limitations

- **Cluster size optimization**: The branch-reduce-and-bound solver for the linear integer programming problem (Eq. 27) is not specified, and optimal cluster sizes `{cm}` used in experiments are not reported, making exact reproduction difficult.
- **Learning rate schedule**: Theorem 1 requires specific constants `L` and `μ` for the step size `ηt = 8/(Lμt)`, but these are not provided, creating ambiguity in the convergence analysis.
- **Fusion weight computation**: The expected quantization distortion term `E[||Qbm,ϵ1,m,u(bvm,u,t) - bvm,u,t||²₂]` for fusion weights (Eq. 14) lacks closed-form derivation, requiring numerical estimation.

## Confidence

- **High confidence**: DP-SQ quantizer mechanism (Lemma 3 with closed-form probability `p* = e^ϵ1/(e^ϵ1 + 1)`), DLG attack methodology, and basic fusion weight proportionality to SNR.
- **Medium confidence**: Convergence bound interpretation (Theorem 1) and cluster size optimization formulation, though implementation details are missing.
- **Low confidence**: Exact experimental configurations (learning rates, solver parameters, device sampling strategy) due to incomplete specification.

## Next Checks

1. **Quantizer validation**: Implement DP-SQ with b ∈ {4, 5, 6} bits and ϵ1 ∈ {0.1, 0.5, 1.0, 1.5}, measure expected distortion against LaplaceSQ baseline. Expected: ~2.5 orders of magnitude lower distortion at ϵ₁ = 0.1, b = 6.
2. **Privacy protection test**: Run DLG attack (40 iterations) on single data point reconstruction. Compare SSIM between SQ-FL (no DP) and Algorithm 1 (ϵ1,m,u = 10⁻⁶). Expected: SQ-FL SSIM → 0.3+; Algorithm 1 SSIM → ~0.01.
3. **Learning utility benchmark**: Train 2-layer MLP on MNIST with M=2 groups (b₁=2 bits, b₂=4 bits), N=10 devices/round, T=20 rounds. Compare Algorithm 1+FWO+CSO vs. LaplaceSQ-FL across ϵ1,m,u ∈ {10⁻⁶, 32×10⁻⁶}. Expected: Proposed method maintains ~80-90% accuracy; LaplaceSQ-FL degrades to ~41% under strict privacy.