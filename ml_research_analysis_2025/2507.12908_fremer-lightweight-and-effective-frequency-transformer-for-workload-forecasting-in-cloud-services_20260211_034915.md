---
ver: rpa2
title: 'Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting
  in Cloud Services'
arxiv_id: '2507.12908'
source_url: https://arxiv.org/abs/2507.12908
tags:
- frequency
- forecasting
- fremer
- workload
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Fremer, an efficient and effective frequency-domain
  transformer model for workload forecasting in cloud services. Fremer addresses the
  limitations of existing transformer-based models by leveraging frequency domain
  representations to capture multi-periodic patterns in workload series.
---

# Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services

## Quick Facts
- arXiv ID: 2507.12908
- Source URL: https://arxiv.org/abs/2507.12908
- Reference count: 40
- Outperforms state-of-the-art models with 5.5% MSE, 4.7% MAE, and 8.6% SMAPE improvements while reducing parameter scale and computational costs

## Executive Summary
This paper introduces Fremer, a frequency-domain transformer model that addresses limitations of existing transformer-based workload forecasting approaches by leveraging frequency domain representations. The model captures multi-periodic patterns in cloud workload series through three key innovations: Learnable Linear Padding to resolve frequency resolution misalignment, Complex-valued Spectrum Attention to capture global dependencies across frequency combinations, and Frequency Filters to handle noise and overfitting. Extensive experiments on four newly released cloud workload datasets and three public benchmarks demonstrate superior performance with significant reductions in computational costs. The paper also releases four high-quality workload datasets collected from ByteDance's cloud services.

## Method Summary
Fremer transforms the forecasting problem into the frequency domain using real-valued Fast Fourier Transform (rFFT). The model applies Learnable Linear Padding to extend input sequences, Complex-valued Spectrum Attention to capture dependencies across frequency combinations, and Frequency Filters to separate trend and noise components. After processing in the frequency domain, the model uses inverse FFT to return to the time domain for forecasting. The architecture is trained with Adam optimizer (LR=1e-3) for 20 epochs using MSE loss, and evaluated on normalized data using MSE and MAE metrics, with SMAPE calculated on raw data.

## Key Results
- Achieves average improvements of 5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE compared to state-of-the-art models
- Reduces parameter scale and computational costs while maintaining superior forecasting accuracy
- In Kubernetes auto-scaling tests, improves average latency by 18.78% and reduces resource consumption by 2.35%
- Releases four high-quality cloud workload datasets (FaaS, IaaS, PaaS, RDS) with 10-min or 5-min granularity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Frequency domain transformation distinguishes multi-scale periodic patterns and high-frequency noise more effectively than time-domain approaches
- **Mechanism:** rFFT maps temporal autocorrelations into distinct frequency bins, while Frequency Filters remove high-frequency noise and isolate low-frequency trends
- **Core assumption:** Workload signals are composed of distinct periodic frequencies, with noise concentrated in the high-frequency spectrum
- **Evidence anchors:** Abstract mentions "multi-periodic patterns"; Section 4.2 discusses deep learning prioritizing low-frequency information; corpus supports spectral filtering efficacy
- **Break condition:** If workload data lacks distinct periodicity (e.g., pure random walk or highly irregular burst traffic), frequency decomposition may isolate noise rather than signal

### Mechanism 2
- **Claim:** Learnable Linear Padding resolves frequency resolution misalignment when input window length differs from full sequence length
- **Mechanism:** LLP uses learned linear layer to pad input L to L+T, ensuring frequency bins of input match target forecast spectrum
- **Core assumption:** Linear extrapolation provides sufficient proxy to extend spectral resolution without introducing significant artifacts
- **Evidence anchors:** Section 4.1 states "frequency resolution is determined by length of series"; Figure 4 visualizes misalignment; corpus evidence is weak/missing for this specific mechanism
- **Break condition:** If linear projection creates discontinuous step at boundary, it might introduce high-frequency artifacts (Gibbs phenomenon) that pollute the spectrum

### Mechanism 3
- **Claim:** Complex-valued Spectrum Attention reduces computational complexity while capturing relationships between frequency combinations (harmonics)
- **Mechanism:** Projects frequency points into smaller set of "frequency combinations" using complex-valued dot-product attention
- **Core assumption:** Semantic information in frequency domain is localized in groups of frequencies rather than single frequency bins
- **Evidence anchors:** Abstract mentions "global dependencies across frequency combinations"; Section 4.3 states single frequency points scarcely carry semantic meaning; corpus discusses spectral bias
- **Break condition:** If projection dimension is too small, model may "blur" distinct but important frequencies together, losing fine-grained periodic details

## Foundational Learning

- **Concept: Discrete Fourier Transform (DFT) Resolution**
  - **Why needed here:** Understanding that frequency "bins" are determined by total duration of signal is essential to grasp why Learnable Linear Padding is necessary
  - **Quick check question:** If I double the input sequence length, how does the frequency resolution change? (Answer: Resolution doubles; bins become narrower)

- **Concept: Spectral Bias**
  - **Why needed here:** Paper explicitly designs filters to combat tendency of neural networks to prioritize low-frequency components over high-frequency components
  - **Quick check question:** Why might a standard Transformer fail to capture a sharp daily spike in a long weekly sequence? (Answer: It fits the low-frequency weekly trend first, treating daily spike as noise)

- **Concept: Complex-valued Operations**
  - **Why needed here:** CSA operates on complex spectrum (magnitude and phase); standard real-valued attention cannot directly process phase information
  - **Quick check question:** What information is lost if you only feed magnitude of FFT into neural network? (Answer: Phase information, meaning you lose temporal location of events)

## Architecture Onboarding

- **Component map:** Raw time series X -> LLP (pad L→L+T) -> rFFT (complex spectrum) -> Frequency Filters (HPF/LPF) -> F-RIN (normalization) -> CSA (complex-valued attention over L'=L/5 combinations) -> irFFT (back to time domain) -> concatenate saved Trend component

- **Critical path:** Learnable Linear Padding is the most delicate initialization step; if padding weights don't approximate smooth continuation of signal, resulting FFT may be dominated by high-frequency edge artifacts

- **Design tradeoffs:**
  - Filter Thresholds: Hard thresholds (top 1% high freq, bottom 3% low freq) reduce overfitting but risk removing legitimate micro-seasonality
  - Complexity vs. Accuracy: Reduction to L' frequency combinations boosts speed but creates information bottleneck if L' is too small

- **Failure signatures:**
  - "Blurry" Forecasts: Model outputs mean trend but misses spikes when High-Pass Filter threshold is too aggressive
  - Phase Drift: Predicted spikes happen at wrong times when Complex-valued Attention fails to converge on phase relationships
  - Edge Artifacts: Start of forecast looks discontinuous with input history when LLP padding fails to bridge spectral gap

- **First 3 experiments:**
  1. Replace Learnable Linear Padding with standard zero-padding; measure MSE drop on highly periodic dataset (PaaS) to validate frequency alignment hypothesis
  2. Sweep High-Pass Filter threshold (top 0.5%, 1%, 5%) on noisy dataset (IaaS) to find point where signal loss exceeds noise reduction benefits
  3. Compare inference latency (ms) and memory footprint against PatchTST on long sequence (L=1440) to verify claimed O((L')^2/H) efficiency gain

## Open Questions the Paper Calls Out
- How can Fremer be adapted for distributed deployment architectures to handle massive scale of cloud forecasting tasks?
- Can modeling cross-channel dependencies in frequency domain improve performance for workloads with strong inter-series correlations?
- How robust is proactive auto-scaling performance when assumption of linear relationship between workload and resource consumption is violated?

## Limitations
- Lacks comparison against recent advanced forecasting models like N-HiTS and Autoformer
- Frequency resolution misalignment problem appears novel but lacks strong corpus validation
- Real-world Kubernetes auto-scaling results tested on ByteDance's internal infrastructure, limiting external verification

## Confidence
- Core frequency-domain approach: High
- Learnable Linear Padding necessity: Medium
- Computational efficiency claims: Medium
- Real-world auto-scaling results: Medium

## Next Checks
1. Implement zero-padding baseline to quantitatively measure impact of Learnable Linear Padding on frequency resolution and forecasting accuracy
2. Conduct comprehensive ablation study sweeping Frequency Filter thresholds across all datasets to identify optimal parameter ranges
3. Benchmark inference latency and memory usage against N-Beats, Autoformer, and PatchTST on long sequences (L≥1440) to verify claimed efficiency gains