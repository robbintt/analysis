---
ver: rpa2
title: 'Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of Frozen
  Language Models'
arxiv_id: '2503.16779'
source_url: https://arxiv.org/abs/2503.16779
tags:
- tool
- tools
- learning
- cotools
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Chain-of-Tools (CoTools), a method for leveraging
  frozen large language models to effectively utilize massive unseen tools during
  chain-of-thought reasoning. The core idea is to use the semantic representation
  capability of frozen LLMs to determine when and which tools to call, without modifying
  the model's original reasoning abilities.
---

# Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of Frozen Language Models

## Quick Facts
- **arXiv ID:** 2503.16779
- **Source URL:** https://arxiv.org/abs/2503.16779
- **Reference count:** 12
- **Primary result:** Method enables frozen LLMs to effectively utilize massive unseen tools during chain-of-thought reasoning, achieving 10.4% top-1 accuracy on unseen tools in STQuestions.

## Executive Summary
This paper presents Chain-of-Tools (CoTools), a method for leveraging frozen large language models to effectively utilize massive unseen tools during chain-of-thought reasoning. The core idea is to use the semantic representation capability of frozen LLMs to determine when and which tools to call, without modifying the model's original reasoning abilities. CoTools consists of three components: a Tool Judge that decides when to call tools, a Tool Retriever that selects the most suitable tool based on query and answer context, and a Tool Calling module that executes the selected tool and integrates the result. Experiments on four benchmarks show CoTools outperforms baselines, particularly in scenarios with massive unseen tools.

## Method Summary
CoTools leverages frozen LLMs by training lightweight modules on top of hidden states. The Tool Judge uses a gated MLP to score when tool invocation is needed during token generation. The Tool Retriever employs contrastive learning with query and tool encoders (sharing dimension-selective weights) to match reasoning context with tool descriptions. The Tool Calling module uses few-shot prompts to execute tools and inject results back into the reasoning chain. The method handles massive unseen tools by computing tool vectors from descriptions at inference time.

## Key Results
- CoTools achieves 10.4% top-1 and 33.7% top-5 accuracy on unseen tools in STQuestions benchmark
- Outperforms ToolkenGPT baseline significantly on unseen tool scenarios
- Achieves top-1 accuracy of 93.8% on STQuestions seen tools
- Shows graceful degradation with increasing tool count, maintaining reasonable accuracy

## Why This Works (Mechanism)

### Mechanism 1: Hidden-State-Based Tool Triggering
A frozen LLM's hidden states encode sufficient semantic signal to determine when tool invocation is needed during token generation. At each token generation step, the Tool Judge computes a scalar score from the current hidden state using a gated MLP. If the score exceeds threshold θ, tool retrieval is triggered; otherwise, normal token generation proceeds.

### Mechanism 2: Contrastive Tool Retrieval from Frozen Semantics
Query vectors and tool vectors derived from frozen LLM hidden states can be aligned via contrastive learning to enable accurate tool selection, including for unseen tools. The Query Encoder and Tool Encoder transform hidden states into retrieval vectors with residual connections. Training uses in-batch contrastive loss; at inference, the tool with highest dot-product similarity is selected.

### Mechanism 3: Dimension-Selective Semantic Weighting
Only a subset of hidden-state dimensions drives tool retrieval, and learning which dimensions matter improves interpretability without full-model tuning. A learnable weight vector W_dim applies per-dimension weighting before normalization. Analysis shows ~38% of dimensions receive weight >1; using only these dimensions, top-1 accuracy drops only 1.4%.

## Foundational Learning

- **Concept: Hidden States as Semantic Representations**
  - Why needed here: CoTools relies on extracting meaningful semantic vectors from the frozen model at each generation step
  - Quick check question: Can you explain why the hidden state at position t differs from the embedding of token x_t alone?

- **Concept: Contrastive Learning for Retrieval**
  - Why needed here: The Tool Retriever is trained with in-batch contrastive loss
  - Quick check question: Given a batch with queries Q={q1,q2} and tools T={t1,t2}, where (q1,t1) and (q2,t2) are correct pairs, what is the contrastive objective?

- **Concept: Chain-of-Thought (CoT) Reasoning**
  - Why needed here: CoTools operates during CoT generation; tool calls are interleaved with reasoning steps
  - Quick check question: Why might interleaving tool calls within CoT be more flexible than pre-planning all tool invocations?

## Architecture Onboarding

- **Component map:** Foundation Model (frozen) -> Tool Judge -> Query Encoder -> Tool Encoder -> Tool Calling -> Foundation Model (continue)
- **Critical path:** Input query with ICL/CoT prompt → Foundation Model generates token t with hidden state h_t → Tool Judge scores h_t; if score > θ, proceed to retrieval → Encode query context with E_Q; encode all tool descriptions with E_T → Retrieve top tool via dot-product; invoke via Tool Calling module → Append tool result; continue generation
- **Design tradeoffs:** Freezing the foundation model preserves CoT/reasoning but limits end-to-end optimization; contrastive training on limited tools may not cover edge cases; tool vector precomputation enables fast retrieval but requires recomputation when tool descriptions change
- **Failure signatures:** Tool Judge never triggers (check BCE loss convergence and threshold θ); Tool Retriever selects wrong tool among similar tools (check if tool descriptions are discriminative); Unseen tool accuracy near zero (verify tool descriptions are properly encoded)
- **First 3 experiments:** Tool Judge sanity check on GSM8K-XL (log score distribution at gold tool-call positions vs. non-call positions); Retriever ablation on tool count on KAMEL (evaluate retrieval accuracy with tool pool sizes {30, 60, 100, 234}); Unseen tool generalization on STQuestions (compare top-1/top-5 accuracy vs. ToolkenGPT)

## Open Questions the Paper Calls Out
- How can the framework be extended to handle tools that return multiple values, requiring the model to select the specific value relevant to the reasoning chain?
- How does the framework perform when applied to large-scale sets of fully executable, real-world tools versus synthetic or knowledge-base-derived tools?
- Can advanced reasoning structures like Tree of Thoughts significantly improve tool selection and invocation accuracy?

## Limitations
- Does not handle tools with multiple return values requiring value selection
- Not tested on large-scale real-world executable toolsets
- Relies on frozen LLM semantics which may not generalize to all tool domains

## Confidence

| Claim | Confidence |
|-------|------------|
| CoTools can effectively trigger tool calls using frozen LLM hidden states | High |
| Contrastive learning enables accurate tool retrieval including for unseen tools | Medium |
| Dimension-selective weighting improves interpretability without significant accuracy loss | High |
| Method generalizes well to massive unseen tools | Medium |
| Performance degrades gracefully with increasing tool count | High |

## Next Checks
1. Verify Tool Judge correctly triggers on GSM8K-XL by examining score distributions at tool-call vs. non-call positions
2. Test Tool Retriever accuracy degradation with increasing tool pool sizes on KAMEL benchmark
3. Validate unseen tool generalization by comparing top-1/top-5 accuracy on STQuestions test split with 837 unseen tools against ToolkenGPT baseline