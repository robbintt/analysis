---
ver: rpa2
title: 'LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer
  Integration'
arxiv_id: '2507.23167'
source_url: https://arxiv.org/abs/2507.23167
tags:
- ensemble
- confidence
- arxiv
- learning
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of combining predictions from
  multiple Large Language Models (LLMs) where different models excel in different
  domains and exhibit varying levels of confidence. Traditional ensemble methods like
  voting or probability averaging fail to account for these context-dependent reliability
  differences.
---

# LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration

## Quick Facts
- arXiv ID: 2507.23167
- Source URL: https://arxiv.org/abs/2507.23167
- Authors: Jizhou Guo
- Reference count: 4
- Primary result: LENS learns confidence from layer-wise internal states and outperforms traditional ensemble baselines on 5/6 datasets

## Executive Summary
LENS addresses the challenge of combining predictions from multiple LLMs by learning to estimate each model's confidence from its internal representations. Traditional ensemble methods fail to account for context-dependent reliability differences between models. The proposed method extracts layer-wise probability distributions using a logit lens technique, then trains lightweight linear predictors to estimate confidence for each model. Experiments on six diverse question-answering datasets demonstrate consistent improvements over baseline ensemble strategies.

## Method Summary
LENS learns per-model confidence by analyzing internal representations from each LLM layer. For each model, layer-wise hidden states are projected through the language modeling head to produce probability distributions over answer choices. These distributions are concatenated across layers to form rich feature vectors, which are fed into linear confidence predictors trained on held-out development data. During inference, the system selects the prediction from the most confident model using a Max Confidence strategy. The approach requires no modifications to base LLMs and can be applied to any models with accessible internal states.

## Key Results
- Max Confidence selection strategy achieves best performance on 5 out of 6 datasets (CoinFlip, BoolQ, PrOntoQA, SWAG, MathQA)
- LENS consistently outperforms traditional ensemble baselines including Majority Vote and Probability Max
- The method demonstrates effectiveness across diverse question-answering tasks including math, commonsense reasoning, and fact verification
- Linear confidence predictors trained on modest development sets (250 samples) provide sufficient accuracy for ensemble selection

## Why This Works (Mechanism)

### Mechanism 1: Layer-wise Internal Representations Encode Confidence Signals
Layer-wise probability trajectories contain distinguishable patterns between correct and incorrect predictions. The logit lens technique projects hidden states at each layer through the LM head to produce probability distributions, which are concatenated to create rich features. A linear predictor learns to map these features to confidence scores via sigmoid activation. The core assumption is that correct predictions exhibit identifiable convergence patterns across layers, while incorrect predictions show different trajectories.

### Mechanism 2: Max Confidence Selection Leverages Context-Dependent Reliability
Instead of aggregating all predictions, the system selects the answer from the single most confident model. This approach implicitly weights models by their estimated reliability in each specific context. The core assumption is that at least one model will be reliably confident when correct, and that the learned confidence scores accurately distinguish between correct and incorrect predictions.

### Mechanism 3: Lightweight Linear Predictors Provide Sufficient Expressiveness
Per-model linear confidence predictors trained on binary correctness labels are sufficient to learn useful confidence patterns. The linear functional form is computationally efficient while providing enough expressiveness to capture confidence signals from the concatenated layer-wise features. The core assumption is that the development set distribution generalizes to test data and that the linear form adequately captures the relationship between internal states and correctness.

## Foundational Learning

- **Concept**: Logit Lens
  - Why needed here: Essential for extracting layer-wise probability features from internal states
  - Quick check question: Given a hidden state at layer l, what two operations produce the logits over answer choices?

- **Concept**: Binary Cross-Entropy Loss
  - Why needed here: Used to train confidence predictor as binary classifier predicting correctness
  - Quick check question: If a model's prediction is correct and the predictor outputs confidence 0.3, what is the BCE contribution for this sample?

- **Concept**: Ensemble Diversity
  - Why needed here: LENS assumes models have complementary strengths; if models are redundant, confidence weighting provides no benefit
  - Quick check question: If all five LLMs always agree on the same answer, what ensemble accuracy would Majority Vote, Probability Max, and Max Confidence each achieve?

## Architecture Onboarding

- **Component map**: Input Query → N LLMs in parallel → Internal Representation Extractor (per model) → Feature Constructor → Confidence Predictor (per model) → Ensemble Selector

- **Critical path**: Hidden state extraction → logit lens projection → feature concatenation → confidence scoring → max selection. Errors in logit lens propagate to all downstream components.

- **Design tradeoffs**:
  - Linear vs. non-linear confidence predictor: Linear is simple and efficient but may underfit complex patterns
  - Max Confidence vs. weighted averaging: Selection avoids noise from miscalibrated predictions but discards potentially useful information
  - Number of ensemble models: More models increase diversity but also computational cost and potential redundancy

- **Failure signatures**:
  - Confidence predictor validation accuracy near 50%: Predictor is not learning useful patterns; check feature extraction and data quality
  - Max Confidence underperforms Majority Vote consistently: Models may be systematically overconfident on errors
  - Crashes on certain model architectures: Not all models expose layer-wise hidden states identically

- **First 3 experiments**:
  1. Train confidence predictor on one dataset and evaluate on held-out split to verify learning
  2. Run Max Confidence with randomly initialized predictors to confirm learning is necessary
  3. Train predictors using only early layers, only late layers, and all layers to identify informative depths

## Open Questions the Paper Calls Out

- Can confidence predictors trained on one dataset transfer effectively to unseen tasks in a zero-shot manner?
- Does the integration of Chain-of-Thought (CoT) prompting or Self-Consistency enhance the effectiveness of LENS confidence estimation?
- Do non-linear or more sophisticated confidence predictor architectures yield significant performance improvements over the lightweight linear layer?

## Limitations

- Reliance on exposed layer-wise hidden states limits applicability to models with accessible internals
- Linear confidence predictor may underfit complex confidence patterns without validation against more complex architectures
- Max Confidence strategy assumes at least one model is reliably confident when correct, without analysis of systematic overconfidence risks

## Confidence

- **High Confidence**: Experimental methodology and empirical finding that Max Confidence outperforms baselines on 5/6 datasets
- **Medium Confidence**: Theoretical justification for layer-wise representations encoding confidence signals is plausible but unproven
- **Low Confidence**: Sufficiency of linear predictor architecture and analysis of weighted averaging alternatives are absent

## Next Checks

1. Systematically ablate layers in confidence predictor to identify most informative depth ranges
2. Compare Max Confidence against weighted averaging and Bayesian model averaging
3. Evaluate calibration of confidence scores using reliability diagrams and expected calibration error