---
ver: rpa2
title: Enhancing Generalization in Chain of Thought Reasoning for Smaller Models
arxiv_id: '2501.09804'
source_url: https://arxiv.org/abs/2501.09804
tags:
- domain
- reasoning
- prada
- language
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of preserving chain-of-thought
  (CoT) reasoning generalization when distilling from large language models (LLMs)
  to smaller ones. During distillation, smaller models often overfit and memorize
  CoT paths rather than generalize, hurting performance on unseen domains.
---

# Enhancing Generalization in Chain of Thought Reasoning for Smaller Models

## Quick Facts
- arXiv ID: 2501.09804
- Source URL: https://arxiv.org/abs/2501.09804
- Authors: Maxwell J. Yin; Dingyi Jiang; Yongbing Chen; Boyu Wang; Charles Ling
- Reference count: 7
- Key outcome: PRADA framework improves chain-of-thought reasoning generalization in smaller models, achieving over 10% accuracy gains on SV AMP and GSM8K datasets

## Executive Summary
This paper addresses a critical challenge in knowledge distillation: smaller language models often overfit to specific chain-of-thought (CoT) reasoning paths during distillation from larger models, leading to poor generalization on unseen domains. The authors propose PRADA, a principled fine-tuning framework that combines prompt learning and domain-adversarial fine-tuning to recover domain-invariant features and improve adaptability. The method significantly outperforms existing CoT distillation approaches, demonstrating enhanced cross-domain generalization while maintaining the reasoning capabilities of the teacher model.

## Method Summary
PRADA addresses CoT reasoning generalization through a two-stage fine-tuning approach. First, it employs prompt learning to extract domain-invariant features from the CoT reasoning paths. Second, it applies domain-adversarial fine-tuning to further enhance the model's ability to adapt to new domains. The framework is designed to prevent smaller models from memorizing specific reasoning paths during distillation, instead encouraging them to learn generalizable reasoning patterns. The optimization objective explicitly incorporates both source and target domain data to learn domain-invariant representations.

## Key Results
- PRADA achieves over 10% accuracy improvement on SV AMP and GSM8K datasets compared to baseline CoT distillation methods
- The framework demonstrates superior cross-domain generalization while maintaining teacher model reasoning capabilities
- PRADA effectively addresses the overfitting problem where smaller models memorize specific CoT paths rather than learning generalizable reasoning patterns

## Why This Works (Mechanism)
PRADA works by forcing the student model to learn domain-invariant features through adversarial training, preventing overfitting to specific CoT patterns. The prompt learning component extracts meaningful representations from the reasoning paths, while the domain-adversarial fine-tuning component ensures these features remain consistent across different domains. This two-pronged approach allows the smaller model to generalize better to unseen domains by focusing on the underlying reasoning structure rather than memorizing specific examples.

## Foundational Learning
- **Chain-of-Thought Reasoning**: Why needed - Enables step-by-step problem solving; Quick check - Verify model can break down simple arithmetic problems
- **Knowledge Distillation**: Why needed - Transfers capabilities from large to small models; Quick check - Confirm teacher accuracy exceeds student baseline
- **Domain Adaptation**: Why needed - Enables model to perform across different problem types; Quick check - Test on both seen and unseen domain variants
- **Prompt Learning**: Why needed - Extracts meaningful representations from CoT paths; Quick check - Ensure prompts capture reasoning structure
- **Adversarial Training**: Why needed - Promotes domain-invariant feature learning; Quick check - Verify domain classifier cannot distinguish source from target
- **Generalization Gap**: Why needed - Core problem PRADA addresses; Quick check - Compare performance on train vs. test domains

## Architecture Onboarding
**Component Map**: Input -> Prompt Extractor -> Feature Transformer -> Domain Classifier -> Output
**Critical Path**: CoT path extraction → Prompt-based feature learning → Domain-adversarial fine-tuning → Generalization evaluation
**Design Tradeoffs**: Computational overhead vs. generalization improvement; Target domain data requirement vs. pure source-only training
**Failure Signatures**: Overfitting to specific reasoning paths; Poor performance on unseen domains; Domain classifier achieving perfect accuracy
**First Experiments**:
1. Test basic CoT distillation without PRADA to establish baseline overfitting
2. Apply PRADA to a single arithmetic task (MultiArith) and measure domain generalization
3. Compare PRADA against pure prompt learning and pure domain-adversarial approaches

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the observed ranking of transfer learning difficulty (e.g., AQUA > GSM8K > MultiArith) be generalized to non-arithmetic reasoning domains, and what specific latent features determine this hierarchy?
- Basis in paper: The authors state in the "Difficulty of Transfer Learning" section: "this generalization difficulty based on domain-agnostic features is worth studying on other datasets."
- Why unresolved: The paper empirically identifies a difficulty ranking within arithmetic tasks but does not validate if this hierarchy persists across the symbolic or commonsense reasoning tasks also tested in the paper.
- What evidence would resolve it: A cross-category analysis measuring transfer efficiency between arithmetic, symbolic, and commonsense domains to identify if dataset complexity or reasoning type drives the difficulty ranking.

### Open Question 2
- Question: How does PRADA perform in a Source-Free Domain Adaptation (SFDA) setting where unlabeled target domain data is inaccessible during the training phase?
- Basis in paper: The optimization objective (Equation 4) explicitly sums losses over both source ($N_s$) and target ($N_t$) datasets, indicating the method relies on access to target domain data for the adversarial classifier.
- Why unresolved: Real-world deployment often involves scenarios where target data is private or unavailable during training; the current framework's reliance on target data samples for the domain classifier limits its applicability to such scenarios.
- What evidence would resolve it: An ablation study comparing the standard PRADA framework against a variant trained strictly on source data (setting $N_t = 0$ or using synthetic target proxies) to quantify the performance gap.

### Open Question 3
- Question: Is the student model's failure on high-difficulty datasets (e.g., AQUA) primarily a result of the student's parameter capacity limits or the teacher model's low accuracy on these specific tasks?
- Basis in paper: The paper notes that for AQUA and GSM8K, "the teacher model gets below 65% accuracy" and suggests these tasks appear "too difficult for any small student model," conflating task difficulty with teacher performance.
- Why unresolved: It is unclear if PRADA fails to bridge the generalization gap on these tasks because the student cannot learn invariant features, or simply because the teacher provides low-quality/noisy reasoning paths (low fidelity distillation).
- What evidence would resolve it: Experiments using a stronger teacher model (or ground-truth rationales) on the AQUA dataset to see if student accuracy scales with teacher quality or plateaus due to student size.

## Limitations
- Evaluation primarily limited to synthetic CoT reasoning tasks (SVAMP, GSM8K) with unclear generalizability to real-world applications
- Domain-adversarial fine-tuning assumes domain alignment between source and target distributions, which may not hold in practice
- Effectiveness of prompt learning as a feature extractor for domain invariance remains underexplored across different task types

## Confidence
- High confidence in the core problem identification (CoT overfitting during distillation)
- Medium confidence in PRADA's effectiveness on tested benchmarks
- Low confidence in generalizability to non-mathematical reasoning tasks
- Medium confidence in the technical soundness of the domain-adversarial approach

## Next Checks
1. Evaluate PRADA on diverse reasoning tasks beyond mathematical problems (e.g., commonsense reasoning, code generation, multi-hop QA) to assess cross-domain generalization.
2. Conduct ablation studies to quantify the individual contributions of prompt learning versus domain-adversarial fine-tuning components.
3. Measure inference-time latency and computational overhead when applying PRADA compared to baseline CoT distillation methods.