---
ver: rpa2
title: 'Quantifying Emotional Tone in Tolkien''s The Hobbit: Dialogue Sentiment Analysis
  with RegEx, NRC-VAD, and Python'
arxiv_id: '2512.10865'
source_url: https://arxiv.org/abs/2512.10865
tags:
- emotional
- dialogue
- chapter
- tolkien
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study analyzed emotional tone in Tolkien\u2019s The Hobbit\
  \ dialogue using computational methods. Dialogue was extracted with regular expressions,\
  \ preprocessed, and scored with the NRC-VAD lexicon for valence, arousal, and dominance."
---

# Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python

## Quick Facts
- arXiv ID: 2512.10865
- Source URL: https://arxiv.org/abs/2512.10865
- Reference count: 2
- Primary result: Emotional tone analysis of The Hobbit dialogue shows positive valence, low arousal, increasing dominance across chapters

## Executive Summary
This study applies computational methods to quantify emotional tone in Tolkien's The Hobbit by analyzing character dialogue. Using regular expressions to extract dialogue from the text, the research applies the NRC-VAD lexicon to score valence, arousal, and dominance dimensions. The analysis reveals a generally positive and calm emotional tone with gradual increases in dominance throughout the narrative. Emotional peaks and troughs align with key narrative events, demonstrating how digital philology can uncover subtle emotional structures in literature.

## Method Summary
The methodology extracts dialogue using regular expressions to capture text between double quotes, then preprocesses it through tokenization, contraction expansion, and stopword removal. Chapter-level emotional scores are computed using the NRC-VAD lexicon, which provides continuous values for valence, arousal, and dominance dimensions. The analysis focuses exclusively on dialogue rather than full text, based on research showing narration and dialogue express "disparate emotions" with near-zero correlation. Results are visualized through line graphs showing emotional trajectories and word clouds highlighting emotionally significant vocabulary.

## Key Results
- Dialogue analysis shows predominantly positive valence (high positivity) throughout The Hobbit
- Arousal scores remain low, indicating a generally calm emotional tone with occasional peaks during tense narrative moments
- Dominance scores gradually increase across chapters, suggesting characters gain agency as the story progresses
- Emotional trajectory aligns with narrative events, with humor and relief balancing moments of danger

## Why This Works (Mechanism)

### Mechanism 1: Dialogue-Only Extraction via RegEx
- Claim: Isolating dialogue from narration captures more direct emotional expression than full-text analysis
- Mechanism: Regular expressions detect text enclosed in double quotation marks, filtering narrator voice; chapters are split by detecting "chapter" + space + digits patterns
- Core assumption: Dialogue and narration express "disparate emotions" with arc correlations near zero (citing Vishnubhotla et al. 2024)
- Evidence anchors: [abstract] "Dialogue was extracted with regular expressions, then preprocessed, and scored"; [section 2.3] "Following Vishnubhotla et al. (2024), who demonstrate that narration and dialogue 'largely express disparate emotions' with arc correlations 'close to 0', this study focuses exclusively on dialogue"
- Break condition: If dialogue contains embedded narration, indirect speech, or malformed quotation marks, extraction accuracy degrades

### Mechanism 2: NRC-VAD Lexicon Scoring
- Claim: Pre-scored word-emotion mappings enable dimension-level emotional trajectory tracking
- Mechanism: Each token maps to three continuous scores (0-1) for valence (positive/negative), arousal (excited/calm), and dominance (control/powerlessness); chapter-level averages computed via NumPy/Pandas
- Core assumption: Word-level emotional scores aggregate meaningfully to chapter-level sentiment despite context sensitivity
- Evidence anchors: [abstract] "scored using the NRC-VAD lexicon to quantify emotional dimensions"; [section 2.6] "The NRC-VAD Lexicon...includes more than 55,000 English words and phrases rated by human annotators on these three emotional dimensions" with "very high reliability"
- Break condition: Contextual meanings (e.g., Gollum's "precious" = obsession, not affection) contradict static lexicon scores; named entities lack entries

### Mechanism 3: Extended Stopword Filtering
- Claim: Standard stopword lists are insufficient for literary dialogue analysis
- Mechanism: Extended GitHub-sourced stopword list removes high-frequency non-emotional words ("would", "could", "may") beyond NLTK defaults, reducing word cloud noise
- Core assumption: High-frequency words without emotional valence create noise that obscures sentiment-bearing terms
- Evidence anchors: [section 2.4.2] "The NLTK stopword list was found to be insufficient, as in previous analyses words like 'would', 'could', 'may'...still appeared frequently in the word clouds, creating noise"; [section 2.4.2, Figure 1] Visual comparison demonstrates noise reduction after extended stopword removal
- Break condition: Over-aggressive filtering may remove domain-relevant terms; character/place names may carry implicit emotional weight not captured by generic lists

## Foundational Learning

- Concept: **Regular Expressions for Structured Text Extraction**
  - Why needed here: Pattern-based extraction isolates chapters (`chapter \d+`) and dialogue (`"[^"]*"`) from unstructured prose
  - Quick check question: Write a regex that captures text between double quotes while handling escaped quotes (`\"`).

- Concept: **Lexicon-Based Sentiment Analysis (VAD Framework)**
  - Why needed here: NRC-VAD maps 55K+ words to three orthogonal emotional dimensions; understanding lexicon limitations (context-blindness, named entity gaps) is critical for interpretation
  - Quick check question: Why would "precious" (valence ≈ 0.83) produce incorrect sentiment scores for Gollum's dialogue in Chapter 5?

- Concept: **Text Preprocessing Pipeline Design**
  - Why needed here: Contraction handling ("don't" → "not") preserves negation signals; normalization ensures case-insensitive matching; tokenization enables word-level lexicon lookup
  - Quick check question: What happens to sentiment scores if contractions like "can't" are tokenized without explicit negation handling?

## Architecture Onboarding

- Component map:
  Raw .txt file → [Chapter Extraction] → chapters/chapter_X.txt → [Dialogue Extraction via RegEx] → dialogues/chapter_X_dialogues.csv → [Preprocessing Pipeline] → Tokenization → Normalization → Contraction expansion → Punctuation removal → Extended stopword filtering → [NRC-VAD Lexicon Lookup] → Per-word VAD scores → [Aggregation] → Chapter-level mean VAD scores (NumPy/Pandas) → [Visualization] → Matplotlib/Seaborn line charts + WordCloud

- Critical path: Dialogue extraction accuracy → Stopword filtering quality → NRC-VAD coverage → Chapter aggregation

- Design tradeoffs:
  - Lexicon vs. ML models: Lexicon offers interpretability and transparency; ML captures context but requires labeled training data
  - Dialogue-only vs. Full text: Isolates character voice but sacrifices narrator emotional framing
  - Standard vs. Extended stopwords: More filtering reduces noise but risks removing domain-specific meaningful terms

- Failure signatures:
  - Word clouds dominated by "would/could/may/come" → insufficient stopword list
  - Sudden chapter-level VAD spikes → single high-scoring word overwhelming aggregated mean
  - Missing chapters in output → regex pattern doesn't match actual chapter header format
  - "Precious" producing high valence in Gollum chapters → lexicon context-blindness not mitigated

- First 3 experiments:
  1. Validate extraction accuracy: Manually compare extracted dialogue from Chapter 5 against source text; measure precision/recall for quotation detection
  2. Stopword list benchmarking: Generate word clouds with NLTK-only vs. extended stopwords; quantify noise reduction via non-emotional word frequency
  3. Lexicon coverage audit: Calculate percentage of dialogue tokens with NRC-VAD entries; identify high-frequency OOV (out-of-vocabulary) terms including proper nouns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can context-aware sentiment models effectively resolve the dissonance between lexicon-assigned scores and semantic irony, such as the high valence of "precious" in Gollum's dialogue?
- Basis in paper: [explicit] Section 6 notes that "precious" (valence≈0.83) appears with menacing connotations in Chapter 5, and suggests future research incorporate "context-aware sentiment models" to address this.
- Why unresolved: The current methodology relies on the static NRC-VAD lexicon, which assigns fixed scores to words regardless of speaker intent or narrative context.
- What evidence would resolve it: A comparative analysis scoring the same dialogue using both the NRC-VAD lexicon and a context-aware model (e.g., BERT) fine-tuned to detect irony or specific character voice patterns.

### Open Question 2
- Question: To what extent do the emotional trajectories of the narrative voice diverge from those found in the character dialogue?
- Basis in paper: [explicit] The conclusion suggests "compare dialogue and narration sentiment... to explore how emotional tone differs between the narrator's voice and the characters' speech."
- Why unresolved: The study explicitly filtered out narration to focus exclusively on dialogue, leaving the relationship between the two unquantified in this specific context.
- What evidence would resolve it: Applying the same NRC-VAD pipeline to the non-dialogue text segments and statistically comparing the resulting valence and arousal curves against the dialogue data.

### Open Question 3
- Question: Do the emotional pacing and dominance trajectories in *The Hobbit* differ significantly from *The Lord of the Rings*?
- Basis in paper: [explicit] Section 6 proposes "comparative studies could also contrast *The Hobbit* with *The Lord of the Rings* to trace shifts in emotional pacing and maturity."
- Why unresolved: The current analysis is limited to a single novel; it does not empirically test Tolkien's qualitative description of *The Lord of the Rings* as "more terrifying" against *The Hobbit's* "light-hearted" nature.
- What evidence would resolve it: A cross-text analysis applying the same extraction and scoring methodology to *The Lord of the Rings* to compare aggregate VAD scores and the volatility of emotional arcs.

### Open Question 4
- Question: Is the observed emotional rhythm of "tension and comfort" preserved or flattened in translations of *The Hobbit*?
- Basis in paper: [explicit] Section 6 suggests examining "translations and adaptations to see how tone changes across languages and media."
- Why unresolved: The analysis relies solely on the English source text, leaving the transferability of these specific emotional peaks and troughs across linguistic boundaries unverified.
- What evidence would resolve it: Running the sentiment analysis pipeline on translated versions (e.g., French, German) using appropriate native lexicons to compare the synchronization of emotional peaks with the original English text.

## Limitations
- Static lexicon cannot capture contextual meanings, irony, or character-specific word usage (e.g., "precious" in Gollum's dialogue)
- Dialogue extraction assumes consistent double-quote formatting and may miss embedded narration or indirect speech
- Extended stopword list lacks validation for literary text and may over-filter domain-relevant terms

## Confidence
- **High Confidence**: General emotional trajectory findings (positive/negative valence shifts, dominance increases) align with known narrative arc
- **Medium Confidence**: Specific numerical VAD scores per chapter are methodologically valid but subject to lexicon limitations
- **Low Confidence**: Claims about precise emotional correlations between specific chapters and narrative events require qualitative validation

## Next Checks
1. **Extraction Accuracy Validation**: Manually compare 10% of extracted dialogue passages from Chapters 1, 5, and 19 against source text to calculate precision and recall
2. **Lexicon Coverage Audit**: Calculate percentage of dialogue tokens with NRC-VAD entries; identify top 20 most frequent out-of-vocabulary words
3. **Context-Blindness Stress Test**: Select 5 passages where lexicon scores clearly contradict intuitive emotional reading; compute alternative VAD scores using context-aware methods