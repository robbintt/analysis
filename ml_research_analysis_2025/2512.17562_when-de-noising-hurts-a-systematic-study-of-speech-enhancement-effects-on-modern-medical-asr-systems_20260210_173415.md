---
ver: rpa2
title: 'When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on
  Modern Medical ASR Systems'
arxiv_id: '2512.17562'
source_url: https://arxiv.org/abs/2512.17562
tags:
- noise
- enhancement
- speech
- semwer
- noisy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically evaluates MetricGAN-plus-voicebank denoising
  on four modern ASR systems (OpenAI Whisper, NVIDIA Parakeet, Google Gemini Flash
  2.0, Parrotlet-a) using 500 medical speech recordings under nine noise conditions.
  The research tests whether speech enhancement preprocessing improves ASR performance,
  measuring results using semantic WER (semWER).
---

# When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems

## Quick Facts
- arXiv ID: 2512.17562
- Source URL: https://arxiv.org/abs/2512.17562
- Reference count: 4
- Primary result: Speech enhancement degrades ASR performance across all tested medical ASR systems

## Executive Summary
This study systematically evaluates the impact of speech enhancement preprocessing on modern automatic speech recognition systems in medical contexts. Using 500 medical speech recordings under nine noise conditions, the research tests four state-of-the-art ASR models (OpenAI Whisper, NVIDIA Parakeet, Google Gemini Flash 2.0, Parrotlet-a) with and without MetricGAN-plus-voicebank denoising. The results consistently demonstrate that de-noising preprocessing harms ASR accuracy rather than improving it, contradicting conventional wisdom about speech enhancement benefits.

The findings suggest that modern ASR systems possess sufficient internal noise robustness to handle challenging acoustic conditions without external enhancement. This challenges the traditional approach of preprocessing audio before ASR and indicates that enhancement algorithms may remove critical acoustic features necessary for accurate transcription. The implications are particularly significant for clinical deployments where transcription accuracy directly impacts patient care and medical documentation.

## Method Summary
The study conducted a comprehensive evaluation using 500 medical speech recordings tested under nine distinct noise conditions, creating 40 total test scenarios (4 ASR models Ã— 10 conditions including clean and enhanced versions). The primary metric was semantic word error rate (semWER), which measures semantic understanding rather than exact word matching. MetricGAN-plus-voicebank served as the speech enhancement method, and results were compared across original noisy audio and enhanced versions to assess the impact of denoising preprocessing on ASR performance.

## Key Results
- Original noisy audio consistently outperformed enhanced audio across all 40 test conditions
- Absolute semWER degradation from enhancement ranged from 1.1% to 46.6%
- All four tested ASR models showed degraded performance with speech enhancement
- Enhancement preprocessing was harmful regardless of noise type or ASR model architecture

## Why This Works (Mechanism)
Modern ASR systems have evolved to incorporate sophisticated internal noise robustness mechanisms that may render external speech enhancement counterproductive. The findings suggest these models can extract relevant features from noisy audio that enhancement algorithms might inadvertently remove. This indicates a paradigm shift where the traditional assumption that "cleaner audio equals better ASR" may no longer hold for advanced deep learning-based systems.

## Foundational Learning
- Semantic Word Error Rate (semWER): Measures semantic understanding rather than exact word matching; needed to capture true comprehension accuracy in medical contexts; quick check: compare against standard WER to validate semantic focus.
- Speech Enhancement Algorithms: Traditional preprocessing methods that attempt to remove noise; needed to understand baseline assumptions being challenged; quick check: verify enhancement actually reduces noise levels.
- Noise Robustness in ASR: Internal mechanisms modern ASR systems use to handle acoustic variations; needed to explain why enhancement may be harmful; quick check: test ASR performance across varying noise levels.

## Architecture Onboarding
- Component Map: Audio Input -> Speech Enhancement (optional) -> ASR Model -> Output Transcription
- Critical Path: The study focuses on whether the speech enhancement component adds value or introduces degradation in the pipeline.
- Design Tradeoffs: Traditional wisdom favors preprocessing enhancement for cleaner input, but this study reveals that modern ASR internal robustness may make this counterproductive.
- Failure Signatures: Enhancement consistently increases semantic WER across all tested configurations and noise conditions.
- First Experiments: 1) Test additional enhancement algorithms beyond MetricGAN, 2) Evaluate on real-world clinical recordings, 3) Analyze acoustic feature changes between enhanced and original audio.

## Open Questions the Paper Calls Out
None

## Limitations
- Results are limited to one specific speech enhancement method (MetricGAN-plus-voicebank)
- Evaluation focused on medical domain recordings which may not generalize to other contexts
- Artificially introduced noise conditions may not reflect real-world clinical acoustic environments
- Semantic WER metric may not capture all aspects of clinical transcription accuracy

## Confidence
- High confidence: Systematic methodology with 500 recordings and 40 test conditions provides robust evidence
- Medium confidence: Interpretation about internal noise robustness is reasonable but needs broader validation
- Low confidence: Claims about acoustic feature removal are speculative without direct acoustic analysis

## Next Checks
1. Test additional speech enhancement algorithms beyond MetricGAN-plus-voicebank to determine if results generalize across enhancement techniques.
2. Evaluate the same ASR models on real-world clinical recordings with naturally occurring noise to validate laboratory findings in authentic deployment scenarios.
3. Conduct acoustic feature analysis comparing enhanced versus original noisy audio to identify which specific acoustic characteristics are being altered by enhancement and potentially contributing to performance degradation.