---
ver: rpa2
title: 'Clustering Approaches for Mixed-Type Data: A Comparative Study'
arxiv_id: '2511.19755'
source_url: https://arxiv.org/abs/2511.19755
tags:
- data
- variables
- clustering
- https
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares six clustering methods for mixed-type data
  (continuous, nominal, ordinal) using four simulation models with varied experimental
  factors such as cluster overlap, sample size, and variable types. Methods tested
  include distance-based approaches (k-prototypes, PDQ, convex k-means) and probabilistic
  models (KAMILA, MBN, LCM).
---

# Clustering Approaches for Mixed-Type Data: A Comparative Study

## Quick Facts
- **arXiv ID**: 2511.19755
- **Source URL**: https://arxiv.org/abs/2511.19755
- **Reference count**: 40
- **Primary result**: KAMILA, LCM, and k-prototypes performed best for clustering mixed-type data across various simulation scenarios

## Executive Summary
This study evaluates six clustering methods for mixed-type data (continuous, nominal, ordinal) through systematic comparison using four simulation models with varied experimental factors. The methods tested include distance-based approaches (k-prototypes, PDQ, convex k-means) and probabilistic models (KAMILA, MBN, LCM). KAMILA emerged as the most robust performer across diverse scenarios, particularly when cluster overlap, sample size, and variable type proportions varied significantly. The study reveals that clustering effectiveness is highly context-dependent and that current methods struggle with strong variable interactions relative to cluster membership.

## Method Summary
The authors conducted a comprehensive comparative analysis of six clustering methods using simulated datasets with mixed variable types. Four simulation models were designed to vary cluster overlap, sample size, and variable type proportions. Performance was evaluated using adjusted rand index (ARI) across multiple experimental conditions. The methods included three distance-based approaches (k-prototypes, PDQ, convex k-means) and three probabilistic models (KAMILA, MBN, LCM). All methods were implemented in R, and results were analyzed to identify patterns in performance relative to data characteristics and clustering context.

## Key Results
- KAMILA achieved the highest adjusted rand index values across most simulation scenarios, demonstrating superior robustness
- LCM and k-prototypes showed strong performance, particularly in scenarios with balanced variable type proportions
- PDQ and MBN consistently underperformed compared to other methods across all experimental conditions
- All methods struggled when strong interactions existed between variables alongside explicit dependence on cluster membership

## Why This Works (Mechanism)
The study systematically varies experimental factors to isolate how different clustering methods respond to specific data characteristics. By using simulation models with controlled parameters, the authors can attribute performance differences to method-specific properties rather than dataset idiosyncrasies. The comparison framework allows identification of which algorithms are most robust to variations in cluster structure, sample size, and variable composition.

## Foundational Learning
- **Adjusted Rand Index (ARI)**: A measure of clustering similarity that accounts for chance agreement, essential for comparing clustering results against ground truth
- **k-prototypes algorithm**: Combines k-means and k-modes to handle mixed data types by using different distance measures for continuous and categorical variables
- **KAMILA (K-means clustering with Automated Mixed-type data)**: A probabilistic model that handles mixed data through Bayesian inference and variable-specific distributions
- **LCM (Latent Class Model)**: A mixture model that assumes variables are independent given the cluster membership
- **Cluster overlap**: The degree to which clusters share similar data points, affecting the difficulty of correct cluster assignment
- **Variable type ratio**: The proportion of continuous versus nominal variables in the dataset, which can impact algorithm performance

## Architecture Onboarding
**Component Map**: Simulation models -> Clustering methods -> Performance evaluation -> Analysis
**Critical Path**: Generate mixed-type data → Apply clustering algorithms → Compute ARI scores → Analyze performance patterns
**Design Tradeoffs**: Distance-based methods offer computational efficiency but may struggle with complex dependencies; probabilistic models provide better theoretical grounding but can be computationally intensive
**Failure Signatures**: Poor performance when variable interactions are strong relative to cluster structure; degradation with high cluster overlap; sensitivity to variable type proportions
**First Experiments**: 1) Test KAMILA on a small mixed-type dataset with known structure, 2) Compare k-prototypes and KAMILA on data with high cluster overlap, 3) Evaluate performance sensitivity to increasing continuous variable proportion

## Open Questions the Paper Calls Out
### Open Question 1
- **Question**: How can clustering algorithms be developed to effectively handle strong interactions between variables alongside explicit dependence on cluster membership?
- **Basis in paper**: [explicit] The authors state that in scenarios with strong interactions, "none of the evaluated methods demonstrated satisfactory performance."
- **Why unresolved**: Current methods, both distance-based and probabilistic, generally assume variable independence or fail to model complex dependencies relative to cluster membership.
- **What evidence would resolve it**: A method that achieves high Adjusted Rand Index (ARI) scores on simulation models (like M3) that specifically contain these strong interactions.

### Open Question 2
- **Question**: How does the inclusion of ordinal variables affect the performance of mixed-type clustering methods, and is treating them as continuous or nominal appropriate?
- **Basis in paper**: [explicit] The authors acknowledge ordinal variables were not considered in the study despite being frequent in real-world datasets, and treating them as continuous may impact performance.
- **Why unresolved**: The simulation models were limited to continuous and nominal types; thus, the behavior of algorithms like KAMILA or k-prototypes on ordinal data remains unknown.
- **What evidence would resolve it**: A comparative study using simulation models that incorporate ordinal variables with varying distributions to evaluate existing distance metrics and probabilistic models.

### Open Question 3
- **Question**: Can nonhierarchical methods like CUBT or DIVCLUS-T be integrated to solve the lack of interpretability and determination of the optimal number of clusters?
- **Basis in paper**: [explicit] The authors note that current literature "barely addresses relevant concerns such as the optimal number of clusters or the interpretability of the results."
- **Why unresolved**: The compared methods focus primarily on partitioning accuracy (ARI) without providing inherent interpretability (e.g., decision rules) or robust selection of $K$.
- **What evidence would resolve it**: A benchmark study showing that interpretable clustering trees can achieve comparable recovery rates while providing clear variable importance and optimal cluster selection.

## Limitations
- Performance assessments rely entirely on simulated data, which may not capture real-world complexity and noise patterns
- The study focuses on adjusted rand index as the sole performance metric, overlooking other potentially relevant measures like cluster stability
- Limited evaluation of interpretability and optimal cluster number determination, which are practical concerns in real applications

## Confidence
- **High**: Relative performance rankings of KAMILA, LCM, and k-prototypes across tested scenarios
- **Medium**: Claim that KAMILA is least affected by variable type ratios
- **Low**: Assertion that all methods are "available in R" without independent verification

## Next Checks
1. Validate key findings using multiple real-world mixed-type datasets with known ground truth structures
2. Test the sensitivity of performance rankings to alternative clustering quality metrics beyond adjusted rand index
3. Evaluate computational efficiency and scalability of top-performing methods across increasingly large sample sizes and variable counts