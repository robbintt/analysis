---
ver: rpa2
title: 'LEC: Linear Expectation Constraints for False-Discovery Control in Selective
  Prediction and Routing Systems'
arxiv_id: '2512.01556'
source_url: https://arxiv.org/abs/2512.01556
tags:
- uni00000013
- uni00000011
- uni00000014
- uni00000003
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LEC, a principled framework for false-discovery
  rate control in selective prediction and routing systems. LEC reformulates selective
  prediction as a decision problem governed by a linear expectation constraint over
  selection and error indicators, enabling the computation of a calibrated threshold
  that maximizes coverage under a finite-sample sufficient condition.
---

# LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems

## Quick Facts
- arXiv ID: 2512.01556
- Source URL: https://arxiv.org/abs/2512.01556
- Reference count: 40
- One-line primary result: LEC provides principled FDR control for selective prediction and routing systems, achieving tighter risk bounds and higher sample retention than confidence interval methods.

## Executive Summary
This paper introduces LEC (Linear Expectation Constraints), a framework for false-discovery rate (FDR) control in selective prediction and two-model routing systems. LEC reformulates selective prediction as a decision problem governed by a linear expectation constraint over selection and error indicators, enabling computation of a calibrated threshold that maximizes coverage under a finite-sample sufficient condition. The approach yields tighter risk bounds and higher sample retention compared to confidence interval-based methods. In two-model routing, LEC jointly calibrates model-specific thresholds to ensure system-level FDR control, adaptively delegating uncertain samples to a stronger model. Evaluations across multiple QA and VQA datasets demonstrate that LEC consistently achieves valid FDR control at tighter risk levels while retaining significantly more correct predictions.

## Method Summary
LEC calibrates uncertainty thresholds for selective prediction and routing systems by reformulating FDR control as a linear expectation constraint E[Z(λ) - αS(λ)] ≤ 0, where Z is the joint selection-error indicator and S is the selection indicator. For a given risk level α, the framework computes the largest threshold λ satisfying a finite-sample sufficient condition (Σ(err_i - α) ≤ -1 over accepted calibration points) to maximize coverage. In two-model routing, LEC jointly calibrates model-specific thresholds (λ^(a), λ^(b)) to ensure system-level FDR control by maximizing the total number of accepted correct samples subject to the joint constraint. The method is UQ-agnostic and requires only calibration data with ground-truth labels, model predictions, and uncertainty scores.

## Key Results
- LEC achieves valid FDR control at tighter risk levels while retaining significantly more correct predictions than confidence interval-based methods
- In two-model routing, LEC increases the number of accepted correct samples and improves cost-efficiency by prioritizing the primary model
- Joint calibration of model-specific thresholds is necessary for system-level FDR guarantees in routing scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reformulating selective prediction as a linear expectation constraint enables finite-sample FDR control.
- Mechanism: The FDR definition Pr(err|selected) ≤ α is algebraically rearranged into E[Z − αS] ≤ 0, where Z is the joint selection-error indicator and S is the selection indicator. This transforms a conditional probability constraint into an unconditional linear expectation inequality, which can be verified on finite calibration data.
- Core assumption: Calibration and test samples are exchangeable.
- Evidence anchors:
  - [abstract] "...reinterprets selective prediction as a decision problem governed by a Linear Expectation Constraint over selection and error indicators."
  - [section 3.2] "FDR control...is equivalent to a constraint on the expectation of a linear functional...E[Z(λ) − αS(λ)] ≤ 0."
  - [corpus] Corpus contains related work (COIN) using confidence intervals for FDR control, but LEC's linear formulation is distinct and explicitly contrasted.
- Break condition: The linear decomposition relies on deterministic selection; if selection becomes stochastic or multi-model without joint calibration, the inequality may no longer hold at the system level.

### Mechanism 2
- Claim: A finite-sample sufficient condition derived from the linear constraint yields a calibrated, coverage-maximizing threshold.
- Mechanism: From the exchangeability assumption, a "+1" correction is applied to the empirical linear constraint (Σ(err_i − α) ≤ −1 over accepted calibration points). The largest threshold satisfying this condition is selected, maximizing the number of accepted samples while maintaining validity.
- Core assumption: The calibration set is sufficiently representative of test data under exchangeability.
- Evidence anchors:
  - [abstract] "...establish a finite-sample sufficient condition...to compute an FDR-constrained, coverage-maximizing threshold."
  - [section 3.2] Theorem 3.1 and Eq. (7) define the calibrated threshold as the supremum of the feasible set Λ_α.
  - [corpus] Related work on split conformal prediction (SCP) uses exchangeability for coverage guarantees, but LEC adapts it for FDR-specific constraints.
- Break condition: If the feasible set Λ_α is empty, the target risk level α is deemed infeasible for the model, and the system must abstain on all inputs.

### Mechanism 3
- Claim: Joint calibration of model-specific thresholds in a two-model routing system preserves system-level FDR guarantees.
- Mechanism: The linear expectation constraint is applied to system-level indicators S and Z, which aggregate selection and error across both models. Joint threshold search over (λ^(a), λ^(b)) ensures the overall system satisfies the FDR constraint, even though thresholds are model-specific.
- Core assumption: The routing policy is deterministic and selects at most one model's prediction per input; calibration data is exchangeable at the system level.
- Evidence anchors:
  - [abstract] "In two-model routing, LEC calibrates model-specific thresholds jointly to ensure system-level FDR control..."
  - [section 3.3] Theorem 3.2 and Eq. (11) define the joint calibration procedure and its guarantee.
  - [corpus] Related routing work (Trust or Escalate, UCB-based methods) is cited and compared; LEC's joint calibration is shown to be necessary for valid system-level guarantees in experiments.
- Break condition: Independently calibrating thresholds per model without joint optimization violates the system-level FDR constraint, as shown in routing experiments.

## Foundational Learning

- Concept: **False Discovery Rate (FDR)**
  - Why needed here: The entire framework is built around controlling the proportion of incorrect predictions among those accepted. Without this concept, the objective and guarantees are unclear.
  - Quick check question: If a system accepts 100 predictions and 10 are wrong, what is the FDR? (Answer: 0.10)

- Concept: **Selective Prediction / Abstention**
  - Why needed here: LEC operates in the selective prediction paradigm, where the system can choose to accept or abstain from a prediction. Understanding this trade-off is central.
  - Quick check question: What does a system do when a prediction's uncertainty exceeds the calibrated threshold? (Answer: It abstains or, in routing, delegates to another model.)

- Concept: **Exchangeability and Split Calibration**
  - Why needed here: All theoretical guarantees (Theorems 3.1 and 3.2) rely on the exchangeability assumption between the held-out calibration set and test data. This is a core assumption from conformal prediction theory.
  - Quick check question: If the data distribution shifts significantly between calibration and test time, does LEC's guarantee still hold? (Answer: No, the exchangeability assumption would be violated.)

## Architecture Onboarding

- Component map:
  - Calibration Data -> Uncertainty Quantifier (UQ) -> LEC Calibration Module -> Threshold(s) -> Test-Time Decision Engine
  - Test-Time Decision Engine -> Routing Policy (optional) -> Secondary Model

- Critical path:
  1. **Calibration Phase**: Collect calibration set → For each sample, get model prediction, uncertainty score, and error label → Apply LEC calibration (single or joint) to find threshold(s) → Validate feasibility (non-empty Λ_α).
  2. **Deployment Phase**: For a test input → Get primary model's prediction and uncertainty → If uncertainty ≤ calibrated threshold, accept; else if in routing mode, query secondary model and apply its threshold → If neither condition met, abstain.
  3. **Monitoring**: Periodically re-evaluate FDR on a fresh test set to ensure guarantees hold; recalibrate if data drift is suspected.

- Design tradeoffs:
  - **Calibration size vs. threshold stability**: Larger calibration sets yield more stable thresholds but reduce data available for training or testing.
  - **Risk level (α) vs. coverage**: Lower α (stricter FDR control) typically reduces the number of accepted samples (lower coverage). LEC aims to maximize coverage for a given α.
  - **Primary vs. secondary model choice**: In routing, the secondary model should have better accuracy or more discriminative uncertainty. The tradeoff is between acceptance rate gain and additional inference cost.
  - **UQ method choice**: More informative uncertainty (e.g., semantic entropy) can lead to higher power, but may require more compute. LEC is designed to be UQ-agnostic.

- Failure signatures:
  - **Infeasible threshold**: For a given α, no threshold satisfies the finite-sample condition. System must abstain on all inputs. This suggests the model/UQ is poorly calibrated or the risk level is too low.
  - **Test-time FDR exceeds α**: This indicates a violation of exchangeability (e.g., data drift) or an implementation error in the calibration or decision logic.
  - **Power is significantly lower than baselines**: While FDR control is valid, the system may be overly conservative. Check if the UQ method is appropriate or if the calibration set is too small.
  - **Routing imbalance**: If the secondary model handles nearly all routed samples, it may indicate that the primary model's threshold is too low or that the secondary model's uncertainty profile is not complementary.

- First 3 experiments:
  1. **Validate FDR control**: Replicate the single-model experiment on CommonsenseQA or TriviaQA. Split data 50/50 calibration/test. Verify that over 500 random splits, the mean test-time FDR is ≤ α for α ∈ {0.05, 0.1, 0.15}. Compare realized FDR to target α to assess tightness.
  2. **Benchmark against UCB methods**: Implement UCB-HFD and UCB-CLP baselines from the paper. On the same data, compare LEC's power (proportion of admissible samples accepted) to the baselines at each α. Confirm LEC achieves higher power while maintaining valid FDR.
  3. **Test two-model routing**: Set up a routing system with two LLMs (e.g., Qwen2.5-3B and LLaMA-3.1-8B). Compare three strategies: (a) LEC-Routing with joint calibration, (b) independent per-model LEC without joint calibration, and (c) UCB-based routing. Measure system-level FDR, total acceptance rate, and allocation ratio between models to confirm the necessity and efficiency of joint calibration.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions does multi-model routing (with more than two models) provide strictly greater benefits in accepted correct samples compared to optimal two-model routing, and does the feasible threshold search scale efficiently?
- Basis in paper: [explicit] Appendix B outlines LEC's extension to general multi-model routing systems but states: "exploring this broader setting empirically is left for future work." The main text limits experiments to two-model routing.
- Why unresolved: The paper proves theoretical extension exists but provides no empirical characterization of when additional models help, nor addresses the algorithmic complexity of searching over multi-dimensional threshold vectors.
- What evidence would resolve it: Empirical comparison across routing depths (2, 3, 4+ models), measuring both sample retention gains and calibration computational cost.

### Open Question 2
- Question: What formal conditions characterize when two-model routing under LEC yields strictly more accepted correct predictions than using the stronger model alone with its individually calibrated threshold?
- Basis in paper: [explicit] The conclusion states: "Future work may explore tighter characterizations of when routing yields maximal benefits." Table 2 shows routing sometimes but not always outperforms individual models.
- Why unresolved: The paper empirically demonstrates routing benefits but does not theoretically characterize the uncertainty distribution properties or model capability gaps that determine when routing helps.
- What evidence would resolve it: Theoretical analysis connecting uncertainty-calibration alignment, model accuracy gaps, and routing benefit; controlled experiments varying these factors systematically.

### Open Question 3
- Question: Can the LEC framework be extended to control risk measures other than FDR (e.g., FNR, expected loss, or weighted asymmetric costs) while maintaining finite-sample guarantees?
- Basis in paper: [explicit] The conclusion states: "Future work may...extend the framework to task-specific risk measures beyond FDR." Appendix B briefly mentions the linear expectation constraint "can generalize naturally to a broad class of task-specific risk metrics that take a ratio form."
- Why unresolved: The paper's theorems and algorithms are specific to FDR; the generalization to other ratio-form metrics is sketched but neither formalized nor empirically validated.
- What evidence would resolve it: Formal theorem statements and finite-sample conditions for alternative risk measures; empirical validation showing valid control on asymmetric cost settings.

## Limitations

- **UQ Method Dependency**: LEC's performance is contingent on the informativeness of the uncertainty quantifier, with no guidance provided on optimal UQ selection.
- **Exchangeability Assumption**: All theoretical guarantees rest on calibration and test sets being exchangeable, with no discussion of robustness to domain shift or data drift.
- **Scaling to Multiple Models**: Joint calibration is only proven for two-model routing; extension to systems with more than two models requires new theoretical development and may introduce computational complexity.

## Confidence

- **High Confidence**: FDR control via linear expectation constraint, finite-sample calibration, and joint threshold search in two-model routing.
- **Medium Confidence**: Generalization to arbitrary UQs and downstream tasks; practical robustness to exchangeability violations.
- **Low Confidence**: Extension to multi-model routing systems beyond two models.

## Next Checks

1. **Exchangeability Robustness**: Simulate covariate shift between calibration and test sets. Measure how quickly LEC's realized FDR exceeds α as the degree of shift increases. Compare to a baseline like COIN.
2. **UQ Sensitivity Analysis**: Replace PE/SE with a less informative UQ (e.g., uniform randomness) and verify that LEC still controls FDR (albeit at lower power). This confirms the framework's agnosticism to UQ quality.
3. **Multi-Model Extension Feasibility**: Design a three-model routing experiment. Attempt joint calibration over three thresholds and assess whether the system-level FDR constraint is satisfied. Identify theoretical or computational barriers to scaling.