---
ver: rpa2
title: Leveraging Open-Source Large Language Models for encoding Social Determinants
  of Health using an Intelligent Router
arxiv_id: '2405.19631'
source_url: https://arxiv.org/abs/2405.19631
tags:
- sdoh
- data
- codes
- code
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces an intelligent router architecture that leverages
  multiple open-source large language models (LLMs) to extract Social Determinants
  of Health (SDOH) codes from unstructured medical notes. The router dynamically selects
  the optimal model for each SDOH classification task, achieving 96.4% average accuracy
  across 13 codes, including homelessness and food insecurity, outperforming GPT-4o.
---

# Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router

## Quick Facts
- arXiv ID: 2405.19631
- Source URL: https://arxiv.org/abs/2405.19631
- Reference count: 18
- Achieves 96.4% average accuracy across 13 SDOH codes using intelligent router architecture

## Executive Summary
This study introduces an intelligent router architecture that leverages multiple open-source large language models (LLMs) to extract Social Determinants of Health (SDOH) codes from unstructured medical notes. The router dynamically selects the optimal model for each SDOH classification task, achieving 96.4% average accuracy across 13 codes, including homelessness and food insecurity, outperforming GPT-4o. A synthetic data generation and validation paradigm addresses data paucity and privacy concerns, enabling training without access to protected health information. The approach demonstrates that open-source models, when intelligently routed, can match or exceed the performance of closed-source models in clinical coding tasks.

## Method Summary
The method extracts SDOH codes from unstructured clinical notes using a multi-stage pipeline. First, sentences containing "Social History" sections are extracted from MIMIC-III notes. Synthetic positive examples are generated using Claude-3-opus with self-verification to filter implausible sentences. Multiple open-source LLMs are benchmarked on each SDOH code to identify per-code leaders. A router model is trained to map SDOH keywords to the optimal model. During inference, input notes are routed through the appropriate model for classification. The system handles 13 SDOH codes including homelessness, food insecurity, imprisonment, and unemployment, using a combination of manually labeled and synthetically generated training data.

## Key Results
- Router achieves 96.4% average accuracy across 13 SDOH codes
- Outperforms GPT-4o (91.9% accuracy) on same task
- Synthetic data generation pipeline successfully filters implausible examples (7-51% drop rate during verification)
- Different open-source models show complementary strengths across SDOH codes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Routing inputs to specialized models based on task type improves accuracy over single-model approaches.
- Mechanism: A trained "Oracle Router" accepts an SDOH keyword/phrase as input and outputs the open-source LLM demonstrating optimal performance for that specific classification task. The router exploits the fact that different models have different strengths based on their pre-training data composition.
- Core assumption: Models have non-overlapping failure modes and complementary strengths that can be systematically mapped to task types.
- Evidence anchors:
  - [abstract]: "uses a language model router to direct medical record data to open-source LLMs that demonstrate optimal performance on specific SDOH codes"
  - [section]: Figure 7 shows "LLMs exhibit differential performance on SDOH coding task"—different models achieve best performance on different codes
  - [corpus]: Hari & Thomson [11,12] propose related "intelligent composer" and "real-time routing" concepts; limited direct replication evidence in corpus
- Break condition: If all models converge to similar performance distributions on a task type, routing provides no marginal benefit over a single well-chosen model.

### Mechanism 2
- Claim: LLM-generated synthetic data with self-verification can address training data scarcity in privacy-sensitive clinical domains.
- Mechanism: Claude-3-opus generates synthetic sentences from reference examples using two prompt strategies (one avoiding explicit SDOH keywords), then self-verifies whether generated sentences contain evidence of target codes. Sentences failing verification are discarded.
- Core assumption: LLMs can generate clinically plausible examples and reliably judge their validity for specific coding tasks.
- Evidence anchors:
  - [abstract]: "A synthetic data generation and validation paradigm addresses data paucity and privacy concerns, enabling training without access to protected health information"
  - [section]: Figure 4 shows Claude dropped 7–51 synthetic samples per code during self-verification, demonstrating the validation filter functions
  - [corpus]: No direct corpus evidence for this specific self-validation approach; neighboring papers do not address synthetic data generation
- Break condition: If synthetic data introduces systematic distributional shifts not present in real clinical text, router may overfit to synthetic patterns.

### Mechanism 3
- Claim: Models trained on different data domains naturally develop complementary strengths that can be leveraged without fine-tuning.
- Mechanism: Open-source models from different providers (Meta, Nous, Zero-One) exhibit variable accuracy across SDOH codes because their pre-training corpora differ in domain coverage and lexical patterns.
- Core assumption: Pre-training data composition is a primary driver of task-specific performance, and these differences persist without task-specific fine-tuning.
- Evidence anchors:
  - [section]: "Language models are trained on distinct data domains and show differential performance on tasks including the identification of specific SDOH codes"
  - [section]: Figure 7 shows "unemployment" achieves high accuracy across models while "relative needing care" shows variable/lower accuracy—suggesting code-specific difficulty varies
  - [corpus]: Bommasani et al. [15] discuss foundation model training data implications; Wang et al. [14] note "mixed-quality data" effects in open-source models
- Break condition: If a task requires domain knowledge absent from all candidate models' training distributions, no model will achieve adequate performance.

## Foundational Learning

- Concept: **Social Determinants of Health (SDOH) and Z-codes**
  - Why needed here: The target extraction task requires understanding what SDOH codes represent (housing, food security, incarceration, etc.) and why they're typically documented in free-text "Social History" sections rather than structured EHR fields.
  - Quick check question: Why does the paper state that Z-codes are "infrequently coded" in patient EHRs and must instead be "inferred from clinical notes"?

- Concept: **Open-source vs. Closed-source LLMs in Healthcare Contexts**
  - Why needed here: The entire architecture is motivated by PHI/privacy constraints that make commercial API-based models problematic. Understanding this tradeoff is essential for evaluating whether the complexity of routing is justified.
  - Quick check question: What specific privacy and data governance concerns would lead a hospital system to prefer running a 34B parameter model locally over using GPT-4o via API?

- Concept: **Ensemble Routing vs. Traditional Ensemble Methods**
  - Why needed here: This system's core innovation is selective routing rather than voting or averaging; understanding why task-specific selection outperforms aggregation is foundational.
  - Quick check question: How does the router's approach (selecting one best model per task) differ from a majority-vote ensemble, and what are the inference cost implications?

## Architecture Onboarding

- Component map:
  - **Router Model**: Trained classifier mapping SDOH keyword → optimal model name
  - **Downstream Model Pool**: 15+ open-source LLMs accessed via Together API (Nous-Hermes-2-Yi-34B, Yi-34B-Chat, Llama-2-13b-chat-hf, etc.)
  - **Synthetic Data Pipeline**: Claude-3-opus for generation + self-verification loop
  - **Validation Set Construction**: ~33% positive (gold + synthetic) / ~67% negative splits, ~1000 sentences per code
  - **Inter-Model Annotation Scheme**: GPT-4o + Claude-3-opus + Nous-Hermes for labeling expanded dataset with 2-of-3 agreement

- Critical path:
  1. Extract sentences from clinical notes containing "Social History" sections
  2. Generate synthetic positive examples via Claude with verification loop
  3. Benchmark all candidate models on each SDOH code to identify per-code leaders
  4. Train router on synthetic + gold data to map SDOH keywords → best models
  5. Deploy: input note → extract sentences → router selects model → model classifies

- Design tradeoffs:
  - Synthetic data scale vs. clinical authenticity: Claude may generate less realistic clinical language
  - Router complexity vs. static lookup: If model-to-code mapping is stable, a simple dictionary may suffice
  - Number of candidate models vs. inference latency and maintenance burden
  - Inter-model annotation vs. human labeling: Faster but may propagate systematic errors

- Failure signatures:
  - Router consistently selects the same model across all codes (routing not adding value)
  - High synthetic-test accuracy but low real-note performance (distribution shift in synthetic data)
  - Specific SDOH codes with <80% accuracy across all models (task inherently ambiguous or data-poor)
  - High false-positive rates on negative samples (models over-predicting presence of codes)

- First 3 experiments:
  1. Replicate Figure 7 on 50–100 manually labeled notes to verify differential model performance exists for your target SDOH codes before building router infrastructure.
  2. Implement synthetic data generation pipeline with Claude; measure drop rate during verification (analogous to Figure 4) to assess generation quality and estimate required generation volume.
  3. Build router as a simple static lookup table first (mapping code → best model from benchmark); compare against trained router to determine if learned routing adds value over fixed assignment.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent does the use of inter-model annotation for the 8,000-note dataset introduce circularity or bias compared to human clinical judgment?
- **Basis in paper:** [inferred] The authors explicitly replaced human medical coders with a consensus scheme involving GPT-4o, Claude, and Nous-Hermes to label the expanded dataset.
- **Why unresolved:** Model-generated ground truth may align artificially well with model predictions, potentially inflating reported accuracy metrics relative to human clinical standards.
- **What evidence would resolve it:** A comparative analysis of router performance against a "gold standard" subset of the 8,000 notes manually verified by human experts.

### Open Question 2
- **Question:** Does the synthetic data generation pipeline using Claude-3-opus propagate specific artifacts or limitations into the router's training distribution?
- **Basis in paper:** [inferred] The study relies on a closed-source model (Claude) to generate and self-verify synthetic sentences to address data paucity.
- **Why unresolved:** While the method addresses privacy constraints, it is unclear if synthetic examples capture the linguistic complexity and nuance of actual clinical notes.
- **What evidence would resolve it:** Ablation studies comparing router performance when trained on synthetic data versus de-identified real-world data.

### Open Question 3
- **Question:** Can the intelligent router architecture generalize effectively to non-ICU clinical settings or contemporary EHR documentation styles?
- **Basis in paper:** [inferred] All training and validation data were sourced exclusively from the MIMIC-III database, which is specific to ICU patients and covers the period 2001–2012.
- **Why unresolved:** The routing system may have overfitted to the linguistic patterns and clinical vocabulary specific to historical ICU notes.
- **What evidence would resolve it:** External validation of the router on modern datasets (e.g., MIMIC-IV) or diverse non-ICU clinical records.

## Limitations

- The router's added value beyond static model-to-code mapping cannot be assessed without more implementation details
- Synthetic data generation quality and clinical authenticity remains unverified despite verification filtering
- The 96.4% average accuracy claim aggregates results across 13 codes, but differential performance suggests routing benefit may be code-specific rather than universal

## Confidence

- **High confidence**: The differential performance of open-source models across SDOH codes is well-established by the benchmarking results
- **Medium confidence**: The synthetic data generation and validation paradigm works as described, though clinical authenticity remains unverified
- **Low confidence**: The router's added value beyond static model-to-code mapping cannot be assessed without more implementation details

## Next Checks

1. Test the router on a completely different clinical dataset (not MIMIC-III) to verify that model-to-code performance mappings remain stable across institutions and documentation styles.

2. Compare router performance against a static lookup table where each SDOH code is permanently assigned to its best-performing model from the benchmark—this isolates whether learned routing provides value over simple fixed assignment.

3. Implement the synthetic data pipeline and measure the clinical authenticity of generated sentences through blinded clinician review, quantifying whether synthetic positives match real clinical language patterns.