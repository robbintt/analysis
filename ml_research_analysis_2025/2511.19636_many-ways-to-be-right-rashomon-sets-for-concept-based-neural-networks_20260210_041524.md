---
ver: rpa2
title: 'Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks'
arxiv_id: '2511.19636'
source_url: https://arxiv.org/abs/2511.19636
tags:
- concept
- rashomon
- diversity
- cbms
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Rashomon CBMs address the challenge of finding multiple deep neural
  networks that achieve similar accuracy but rely on different reasoning pathways.
  By introducing lightweight adapter modules and a diversity-regularized training
  objective, the framework efficiently constructs a diverse set of concept-based models
  without retraining from scratch.
---

# Many Ways to be Right: Rashomon Sets for Concept-Based Neural Networks

## Quick Facts
- arXiv ID: 2511.19636
- Source URL: https://arxiv.org/abs/2511.19636
- Reference count: 40
- Primary result: Rashomon CBMs construct diverse sets of concept-based models with similar accuracy but different reasoning pathways through lightweight adapter modules and diversity regularization

## Executive Summary
Rashomon CBMs addresses the challenge of finding multiple deep neural networks that achieve similar accuracy but rely on different reasoning pathways. By introducing lightweight adapter modules and a diversity-regularized training objective, the framework efficiently constructs a diverse set of concept-based models without retraining from scratch. The method inserts model-specific adapters into a shared backbone, jointly optimizing all models to minimize the worst-performing model's losses while encouraging concept diversity. Experiments on four datasets show that Rashomon CBMs maintain competitive accuracy while revealing rich diversity in concept utilization and layer-wise reasoning.

## Method Summary
The framework constructs a Rashomon slice of M concept-based models sharing a frozen backbone (ViT-S/16 or ResNet-18) while maintaining distinct reasoning pathways through model-specific LoRA adapters inserted into attention projections. Each model independently predicts concepts and final labels, with joint training optimizing a worst-case loss combined with diversity regularization. The diversity loss encourages different concept predictions across models using cosine similarity. Model-axis gradient checkpointing enables memory-efficient training of multiple parallel models. The approach reveals that diversity concentrates in deeper layer adapters while maintaining competitive accuracy across all models.

## Key Results
- Maintains competitive accuracy while achieving concept CKA similarity below 0.2 (indicating high diversity)
- Layer-wise analysis shows diversity concentrates in deeper layer adapters
- Prediction hamming distances between models in the slice range from 0.1-0.3
- Successfully applied to four datasets with both human-annotated and CLIP-discovered concepts

## Why This Works (Mechanism)
The method works by exploiting the Rashomon phenomenon in deep learning where multiple models can achieve similar accuracy through different reasoning pathways. By sharing a frozen backbone and only varying adapter modules, the framework constrains models to use the same feature extractor while allowing diverse concept utilization. The diversity regularization directly optimizes for distinct concept predictions, preventing models from collapsing to identical representations. Joint optimization with worst-case loss ensures all models remain competitive while the diversity term encourages exploration of different solution spaces.

## Foundational Learning
- **Concept Bottleneck Models**: Models that first predict human-interpretable concepts before making final predictions. Needed because Rashomon CBMs builds on CBM framework. Quick check: Verify concept predictions are interpretable and meaningful.
- **LoRA Adapters**: Low-rank adaptation modules that modify pre-trained model behavior with minimal additional parameters. Needed for efficient model multiplicity without full retraining. Quick check: Confirm adapter dimensions (rank=8) and insertion points.
- **Model-axis Gradient Checkpointing**: Memory optimization technique that trades computation for reduced memory by checkpointing intermediate activations. Needed to enable training multiple models simultaneously. Quick check: Monitor GPU memory usage scales sublinearly with M.
- **Cosine Similarity Diversity**: Measures angle between concept prediction vectors to encourage diverse reasoning. Needed to quantify and optimize for conceptual diversity. Quick check: Calculate pairwise cosine similarities between model concept predictions.
- **SHAP Values**: Method for attributing model predictions to input features. Needed to analyze how different models use concepts differently. Quick check: Compare SHAP similarity scores across models.

## Architecture Onboarding

**Component Map**
Shared Backbone -> LoRA Adapters (M sets) -> Per-concept MLPs (M sets) -> Linear Classifier (M sets) -> Diversity Loss Computation

**Critical Path**
Input Image → Frozen Backbone → Model-specific LoRA Adapters → Per-concept Predictions → Diversity Regularization → Final Classification

**Design Tradeoffs**
- Shared backbone vs full retraining: Enables efficient training but may limit diversity potential
- Worst-case loss vs average loss: Ensures all models remain competitive but may slow convergence
- Cosine similarity diversity vs other metrics: Simple to compute but may not capture all forms of diversity
- LoRA rank=8: Balances parameter efficiency with representational capacity

**Failure Signatures**
- All models converge to identical concept predictions (concept CKA > 0.8)
- Some models consistently underperform (large gap between best and worst loss)
- Diversity loss fails to decrease over training epochs
- Memory usage scales linearly with M instead of sublinearly

**First Experiments**
1. Train single model with diversity regularization to verify concept CKA decreases
2. Compare memory usage with and without model-axis checkpointing for M=5 models
3. Visualize concept predictions for 2-3 models to verify they use different reasoning

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: How can the number of models M in the Rashomon slice be determined adaptively rather than specified by the user?
- Basis in paper: [explicit] Appendix E states that "determining an adaptive or data-driven criterion" for M remains an open question.
- Why unresolved: The current framework requires the user to fix the slice size a priori.
- What evidence would resolve it: An algorithm that automatically expands the slice until a redundancy or stability threshold is reached.

**Open Question 2**
- Question: Can the framework be integrated with Concept Bottleneck Models that use probabilistic embeddings or hierarchical structures?
- Basis in paper: [explicit] Appendix E suggests the framework "can potentially also be applied... to include probabilistic embeddings or concept hierarchy structure."
- Why unresolved: Current experiments are limited to standard deterministic concept vectors.
- What evidence would resolve it: Successful application of the adapter-based diversity training on hierarchical or probabilistic CBM architectures.

**Open Question 3**
- Question: Does introducing sparsity regularization improve the usability of individual models within the slice?
- Basis in paper: [explicit] Appendix E speculates that loss modifications like "introducing sparsity regularization may improve the usability."
- Why unresolved: The current loss function optimizes for accuracy and diversity but not necessarily for model simplicity.
- What evidence would resolve it: Experiments showing that sparsity constraints lead to models relying on fewer concepts while maintaining diversity and accuracy.

## Limitations
- Requires human-annotated or automatically discovered concepts, limiting applicability to datasets without concept annotations
- Memory usage still scales with M even with checkpointing, though sublinearly
- Diversity regularization may sometimes trade off against final task accuracy
- Current framework requires specifying M upfront without adaptive determination

## Confidence

| Claim | Confidence |
|-------|------------|
| Framework architecture and training methodology | High |
| Diversity metrics and evaluation procedures | Medium |
| Exact hyperparameters for concept discovery and dynamic scheduling | Low |

## Next Checks
1. Verify that model-axis gradient checkpointing is properly implemented to confirm memory efficiency claims (target ~3GB memory usage for M=10 models)
2. Test different initial α values and update schedules to ensure concept diversity doesn't collapse to identical representations
3. Validate that concept CKA and SHAP similarity metrics consistently capture meaningful differences in reasoning pathways across multiple runs