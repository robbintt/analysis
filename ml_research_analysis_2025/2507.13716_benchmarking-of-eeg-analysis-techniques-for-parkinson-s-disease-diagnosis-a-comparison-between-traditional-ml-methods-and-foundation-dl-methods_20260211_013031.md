---
ver: rpa2
title: 'Benchmarking of EEG Analysis Techniques for Parkinson''s Disease Diagnosis:
  A Comparison between Traditional ML Methods and Foundation DL Methods'
arxiv_id: '2507.13716'
source_url: https://arxiv.org/abs/2507.13716
tags:
- parkinson
- disease
- learning
- deep
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks traditional ML and DL models for Parkinson's
  disease diagnosis using EEG data from an oddball task. A unified seven-step preprocessing
  pipeline was applied, followed by subject-wise cross-validation.
---

# Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods

## Quick Facts
- arXiv ID: 2507.13716
- Source URL: https://arxiv.org/abs/2507.13716
- Reference count: 34
- Primary result: XGBoost (accuracy: 0.79, AUC: 0.86) outperformed other ML models; CNN–LSTM hybrids achieved best DL performance (accuracy: 0.73, recall: 0.92, F1: 0.77)

## Executive Summary
This study benchmarks traditional machine learning and deep learning models for Parkinson's disease diagnosis using EEG data from an oddball task. The research applies a unified seven-step preprocessing pipeline followed by subject-wise cross-validation to ensure fair comparison. Traditional classifiers including XGBoost achieved strong performance, while hybrid CNN–LSTM architectures demonstrated superior ability to capture both spatial and temporal EEG patterns. The results establish a robust, reproducible baseline for future EEG-based neurodiagnostic studies.

## Method Summary
The study uses EEG data from 146 participants (98 PD, 48 controls) from the Iowa dataset for Cross-modal Oddball Task. A 7-step preprocessing pipeline includes FIR band-pass filtering (1–50 Hz), 60 Hz notch filtering, channel exclusion, common average reference, FASTER artifact correction, ICA component removal, and epoching from -1.0 to +2.5s. Multitaper PSD analysis aggregates spectral power into delta, theta, alpha, beta, and gamma bands. Subject-wise 70/30 train/test splits with 5-fold cross-validation prevent data leakage. Traditional ML models (XGBoost, SVM, RF, k-NN, LR) use flattened feature vectors, while DL models (CNN, CNN-GAP, LSTM, TCN, CNN–LSTM hybrids) use 4D arrays (samples × time × frequency × channels).

## Key Results
- XGBoost achieved the highest overall accuracy (0.79) and AUC (0.86) among traditional ML methods
- CNN–LSTM hybrid models achieved the best DL performance with accuracy 0.73, recall 0.92, and F1-score 0.77
- CNN with Global Average Pooling (GAP) significantly improved performance over standard CNN, raising accuracy to 0.62 and AUC to 0.72
- Traditional ML methods showed superior calibration (XGBoost log loss: 0.53) compared to DL models

## Why This Works (Mechanism)

### Mechanism 1: Spatiotemporal Pattern Modeling
Hybrid CNN–LSTM architectures achieve superior PD classification by jointly modeling spatial spectral patterns and temporal sequence dynamics. Convolutional layers extract localized frequency-channel patterns while LSTM layers capture how these features evolve across the cue-response window. PD-related EEG changes manifest as both localized spectral features and slower temporal dynamics.

### Mechanism 2: Non-linear Spectral Interactions
XGBoost achieves strong performance on handcrafted spectral features by capturing non-linear interactions across frequency bands and channels. Gradient-boosted decision trees model complex dependencies in power-band features without requiring manual transformations. EEG spectral features exhibit non-linear interactions that linear models fail to capture.

### Mechanism 3: Global Pattern Emphasis
Global Average Pooling (GAP) improves CNN robustness by emphasizing distributed pathological patterns over localized activations. GAP averages over spatial/temporal dimensions of final feature maps, retaining global structure when discriminative information is diffuse across brain regions. This reduces overfitting to local idiosyncrasies and subject-specific noise.

## Foundational Learning

- **Subject-wise cross-validation**: Essential for EEG data due to high inter-subject variability; random shuffling inflates performance by leaking information across trials from the same subject. *Quick check: If you randomly shuffle all trials before splitting, why might your accuracy be artificially high?*

- **Spectral decomposition (multitaper PSD)**: Transforms raw EEG time series into physiologically interpretable frequency band features linked to PD pathology. *Quick check: Why might spectral features be more robust than raw voltage samples for cross-subject classification?*

- **Long-range temporal dependencies**: PD affects neural dynamics over extended time windows requiring models that capture sequence evolution beyond local patterns. *Quick check: Why would a model that only sees 100ms windows struggle to detect cognitive-state differences in an oddball task?*

## Architecture Onboarding

- **Component map**: Preprocessing pipeline (FIR band-pass → notch filter → channel exclusion → common average reference → FASTER → ICA → epoching → augmentation → multitaper PSD → band aggregation → normalization) → ML branch (flattened features → XGBoost/SVM/k-NN/RF/LR) → DL branch (4D arrays → CNN/CNN-GAP/LSTM/TCN/CNN–LSTM hybrids)

- **Critical path**: 1) Subject-wise split FIRST to prevent leakage, 2) Fit normalization parameters ONLY on training folds, 3) Apply identical preprocessing to all models for fair comparison, 4) Use held-out test set for final evaluation only

- **Design tradeoffs**: XGBoost offers calibrated probabilities and interpretability vs. CNN–LSTM's higher recall crucial for screening. Standard CNN overfits to local features vs. GAP's improved generalization. LSTM captures long-range dependencies but trains slower vs. TCN's faster parallelization.

- **Failure signatures**: CNN without GAP achieving near-chance accuracy (0.44) indicates overfitting to local noise. High recall but very low precision (LR: recall 0.92, precision 0.51) suggests class imbalance handling issues. Large gap between CV and test performance indicates data leakage.

- **First 3 experiments**: 1) Replicate preprocessing pipeline on single subject to verify epoch quality and artifact removal, 2) Train XGBoost baseline with subject-wise CV to establish reference performance, 3) Implement CNN–LSTM hybrid with early stopping to compare recall vs. XGBoost

## Open Questions the Paper Calls Out

1. **Subject-specific adaptation techniques**: Would personalization improve model generalization and performance for EEG-based Parkinson's diagnosis? The study used population-level models without adaptation despite known inter-subject variability.

2. **Performance scaling with larger datasets**: How would results change with multi-center datasets across both ML and DL approaches? The study used single-center data with 146 participants, and DL advantage may shift with more data.

3. **Generalization to different cognitive paradigms**: Would findings extend beyond the oddball task to other EEG paradigms? The study focused exclusively on novelty detection, while PD alterations may manifest differently across tasks.

4. **TCN architecture optimization**: Can TCN's conservative recall be improved through modifications or hyperparameter optimization? TCN received less exploration than CNN-LSTM hybrids with fixed hyperparameters.

## Limitations

- Architectural details for CNN–LSTM hybrids are partially specified, requiring assumptions about layer configurations
- DL model implementations lack complete hyperparameter specifications compared to exhaustively tuned ML models
- Performance differences may be influenced by implementation choices rather than inherent algorithmic superiority
- Single-center dataset limits generalizability across different recording environments and populations

## Confidence

- XGBoost performance claims: High - well-supported by results and consistent with ML literature
- CNN–LSTM superiority claims: Medium - results show improved recall but architectural details are incomplete
- GAP mechanism claims: Low - performance improves but theoretical justification lacks direct empirical validation

## Next Checks

1. Implement and test multiple Hyb1/Hyb2 variants with different layer configurations to determine which architectural choices drive performance gains
2. Conduct ablation studies removing temporal components from CNN–LSTM models to quantify the contribution of sequence modeling
3. Perform subject-wise calibration analysis comparing predicted probabilities to observed frequencies across both ML and DL models