---
ver: rpa2
title: 'From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature
  Learning'
arxiv_id: '2510.24812'
source_url: https://arxiv.org/abs/2510.24812
tags:
- have
- data
- inequality
- training
- follows
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates weak-to-strong generalization, where a
  stronger model trained under supervision from a weaker model can outperform its
  teacher. The authors analyze this phenomenon in a structured binary classification
  setting, using linear CNNs as weak models and two-layer ReLU CNNs as strong models.
---

# From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning

## Quick Facts
- arXiv ID: 2510.24812
- Source URL: https://arxiv.org/abs/2510.24812
- Authors: Junsoo Oh, Jerry Song, Chulhee Yun
- Reference count: 40
- Primary result: Theoretical analysis of weak-to-strong generalization showing two regimes (data-scarce and data-abundant) with distinct overfitting behaviors

## Executive Summary
This paper investigates weak-to-strong generalization, where a stronger model trained under supervision from a weaker model can outperform its teacher. The authors analyze this phenomenon in a structured binary classification setting, using linear CNNs as weak models and two-layer ReLU CNNs as strong models. Their theoretical analysis reveals two distinct regimes: data-scarce and data-abundant. In the data-scarce regime, weak-to-strong generalization occurs via benign overfitting or fails via harmful overfitting depending on dataset size. In the data-abundant regime, early stopping enables generalization, but overtraining degrades performance. The authors prove that weak models can achieve near-optimal performance and characterize conditions for transitions between overfitting behaviors. Their experiments support these findings, showing harmful overfitting with limited data, benign overfitting with moderate data, and early generalization with abundant data that deteriorates with overtraining.

## Method Summary
The paper analyzes weak-to-strong generalization in a structured binary classification setting using a Gaussian mixture model. The weak model consists of a linear convolutional neural network (CNN), while the strong model uses a two-layer ReLU CNN. The theoretical analysis employs Gaussian complexity to bound the generalization error of both models and identifies two distinct regimes based on dataset size. In the data-scarce regime, the strong model either achieves benign overfitting or suffers from harmful overfitting depending on the amount of training data. In the data-abundant regime, early stopping is necessary for successful weak-to-strong generalization. The authors prove that weak models can achieve near-optimal performance and characterize the conditions for transitions between overfitting behaviors.

## Key Results
- In data-scarce regime: Weak-to-strong generalization occurs via benign overfitting or fails via harmful overfitting depending on dataset size
- In data-abundant regime: Early stopping enables generalization, but overtraining degrades performance
- Weak models can achieve near-optimal performance with bounded generalization error

## Why This Works (Mechanism)
Weak-to-strong generalization occurs through feature learning in the strong model. The weak linear model provides feature representations that the strong ReLU model can exploit. In the data-scarce regime, the strong model's capacity allows it to fit the training data either successfully (benign overfitting) or catastrophically (harmful overfitting). In the data-abundant regime, early stopping prevents the strong model from overfitting while still benefiting from the feature representations learned from the weak model.

## Foundational Learning
- **Gaussian Complexity**: Measures the complexity of function classes; needed to bound generalization error and compare weak vs strong models
- **Benign vs Harmful Overfitting**: Different failure modes in high-dimensional settings; quick check: benign overfitting achieves near-optimal error despite perfect training fit, harmful overfitting diverges
- **Early Stopping**: Regularization technique that halts training before overfitting occurs; quick check: monitors validation error to determine optimal stopping point
- **Feature Learning**: Strong models learn useful representations from weak model features; quick check: weak model's feature map quality determines strong model's generalization
- **VC Dimension**: Measures model capacity; needed to understand when overfitting occurs in different regimes
- **Convex Optimization**: Required for analyzing linear weak models; quick check: ensures convergence to global optimum

## Architecture Onboarding

**Component Map**: Gaussian Mixture Model -> Linear CNN (Weak) -> Two-layer ReLU CNN (Strong) -> Classification

**Critical Path**: Input data → Weak model feature extraction → Strong model training → Early stopping (if needed) → Final classification

**Design Tradeoffs**: Linear vs nonlinear feature extraction (simplicity vs expressiveness), dataset size vs model capacity (underfitting vs overfitting), early stopping vs full training (generalization vs performance)

**Failure Signatures**: Harmful overfitting (perfect training accuracy but poor test performance), lack of weak-to-strong generalization (strong model performs worse than weak model), early stopping too late (overfitting after stopping point)

**First Experiments**:
1. Vary dataset size to observe transition between harmful and benign overfitting
2. Compare performance with and without early stopping in data-abundant regime
3. Test different weak model architectures to assess feature representation quality

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes Gaussian input distributions, which may not reflect real-world data
- Results are specific to linear and two-layer ReLU CNN architectures
- Focus on feature learning through neural networks may overlook other mechanisms for weak-to-strong generalization

## Confidence

**High Confidence**: The theoretical characterization of weak-to-strong generalization in the data-scarce and data-abundant regimes appears robust within the stated assumptions. The mathematical proofs and experimental validation support the main claims about overfitting behavior and the role of early stopping.

**Medium Confidence**: The practical implications for real-world applications may be limited due to the simplified assumptions. While the theoretical framework is sound, translating these findings to more complex models and distributions requires additional investigation.

**Low Confidence**: The paper does not address potential computational costs or scalability issues that might arise when applying these theoretical insights to larger models or datasets.

## Next Checks
1. Test the theoretical predictions with non-Gaussian input distributions and alternative neural network architectures to assess the robustness of the results.
2. Conduct experiments with larger models and more complex datasets to evaluate the practical applicability of the findings.
3. Investigate the impact of different regularization techniques on weak-to-strong generalization beyond early stopping.