---
ver: rpa2
title: LLM Unlearning with LLM Beliefs
arxiv_id: '2510.19422'
source_url: https://arxiv.org/abs/2510.19422
tags:
- unlearning
- always
- bs-t
- bs-s
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work tackles the issue of spurious unlearning in large language\
  \ models, where gradient ascent methods suppress target responses but redistribute\
  \ probability mass to semantically related rephrasings, leading to incomplete forgetting.\
  \ The proposed bootstrapping framework addresses this by incorporating the model\u2019\
  s own high-confidence predictions\u2014its model beliefs\u2014into the unlearning\
  \ objective."
---

# LLM Unlearning with LLM Beliefs

## Quick Facts
- arXiv ID: 2510.19422
- Source URL: https://arxiv.org/abs/2510.19422
- Authors: Kemou Li; Qizhou Wang; Yue Wang; Fengpeng Li; Jun Liu; Bo Han; Jiantao Zhou
- Reference count: 40
- Key outcome: Addresses spurious unlearning by incorporating model beliefs into unlearning objectives, achieving better forgetting while preserving utility

## Executive Summary
This work tackles the fundamental challenge of spurious unlearning in LLMs, where traditional gradient ascent methods suppress target responses but fail to prevent probability mass from redistributing to semantically related rephrasings. The authors propose a bootstrapping framework that leverages the model's own high-confidence predictions (model beliefs) to create more effective unlearning objectives. By incorporating these beliefs at both token and sequence levels, the approach achieves more comprehensive forgetting of target content while maintaining model utility.

## Method Summary
The proposed framework introduces two bootstrapping approaches: BS-T (token level) and BS-S (sequence level). BS-T forms a soft target by mixing the one-hot label with high-probability token predictions from the model itself, while BS-S augments the unlearning set with entire high-confidence generations. Both methods aim to suppress not only the original targets but also their semantic neighborhoods, preventing probability mass from shifting to paraphrased alternatives. The framework is theoretically grounded with analysis showing how BS-T reshapes gradient dynamics to mitigate the squeezing effect that causes spurious unlearning.

## Key Results
- BS-T and BS-S consistently outperform state-of-the-art baselines in forgetting metrics across TOFU, MUSE, and WMDP benchmarks
- Both methods preserve model utility while achieving more thorough unlearning than existing approaches
- BS-S demonstrates the most comprehensive unlearning by incorporating high-confidence sequence generations
- The framework works effectively across multiple model families including LLaMA-2, LLaMA-3, and Zephyr

## Why This Works (Mechanism)
The bootstrapping approach works by incorporating model beliefs into the unlearning objective, which helps prevent the redistribution of probability mass to semantically related alternatives. When traditional gradient ascent suppresses a target response, the model's probability mass often shifts to paraphrased versions or semantically similar content. By including high-confidence predictions from the model itself in the unlearning process, the framework creates a more comprehensive suppression that covers the target's semantic neighborhood. This prevents the squeezing effect where suppression of one form leads to emergence of another form.

## Foundational Learning

### Gradient ascent for unlearning
**Why needed:** Traditional unlearning uses gradient ascent to maximize loss on target content, but this can create spurious effects where probability mass redistributes rather than truly forgetting.
**Quick check:** Verify that gradient ascent alone causes probability mass to shift to semantically related content.

### Model calibration and beliefs
**Why needed:** The quality of model beliefs directly impacts unlearning effectiveness - poorly calibrated beliefs could reinforce biases.
**Quick check:** Test unlearning effectiveness with models of varying calibration quality.

### Semantic neighborhood in probability space
**Why needed:** Understanding how probability mass redistributes to semantically related content is crucial for comprehensive unlearning.
**Quick check:** Map probability distributions before and after unlearning to identify mass redistribution patterns.

## Architecture Onboarding

### Component map
Input targets -> Model belief generation -> BS-T/BS-S objective formulation -> Gradient ascent optimization -> Fine-tuned model

### Critical path
1. Identify target content to be unlearned
2. Generate model beliefs (high-confidence predictions)
3. Formulate bootstrapping objective (BS-T or BS-S)
4. Apply gradient ascent optimization
5. Evaluate forgetting and utility preservation

### Design tradeoffs
- BS-T offers computational efficiency but may miss some semantic variations
- BS-S provides more comprehensive unlearning but at higher computational cost
- Soft targets in BS-T balance between hard suppression and belief incorporation
- Sequence-level augmentation in BS-S captures broader semantic context

### Failure signatures
- Incomplete forgetting of target content
- Significant utility degradation
- Probability mass redistribution to paraphrased alternatives
- Model beliefs reinforcing rather than correcting biases

### Exactly 3 first experiments
1. Compare BS-T vs traditional gradient ascent on simple paraphrasing tasks
2. Evaluate BS-S effectiveness on sequence-level target suppression
3. Test scalability of BS-S with increasing unlearning set size

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Effectiveness depends on quality of model beliefs, which may be influenced by training data biases
- BS-S computational overhead could limit scalability for very large unlearning sets
- Theoretical analysis of BS-T gradient dynamics lacks formal convergence guarantees
- Evaluation focuses on benchmark datasets that may not reflect real-world unlearning scenarios

## Confidence

**High confidence:** Experimental results showing improved forgetting across multiple benchmarks and model families are well-supported.

**Medium confidence:** Theoretical analysis of BS-T's gradient dynamics is plausible but lacks formal mathematical guarantees.

**Low confidence:** Scalability claims for BS-S computational overhead are not fully substantiated with runtime analysis.

## Next Checks
1. Conduct ablation studies to quantify impact of model belief quality on unlearning effectiveness, including experiments with models of varying calibration quality.

2. Perform runtime and memory profiling for BS-S on progressively larger unlearning sets to establish concrete scalability bounds.

3. Evaluate unlearning effectiveness on out-of-distribution prompts and real-world scenarios where target information appears in varied linguistic contexts.