---
ver: rpa2
title: Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large
  Language Models
arxiv_id: '2510.12080'
source_url: https://arxiv.org/abs/2510.12080
tags:
- randomness
- random
- llms
- tasks
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the capabilities of large language models
  (LLMs) in generating high-quality randomness for tasks requiring entropy, such as
  cryptography, simulations, and scheduling. Through a series of experiments involving
  direct and indirect randomness tasks, NIST randomness tests, and shuffling tasks,
  the study evaluates multiple LLMs including GPT-4o, Gemini 1.5 Pro, and others.
---

# Evaluating the Quality of Randomness and Entropy in Tasks Supported by Large Language Models

## Quick Facts
- **arXiv ID**: 2510.12080
- **Source URL**: https://arxiv.org/abs/2510.12080
- **Reference count**: 13
- **Primary result**: Most LLMs fail >50% of NIST randomness tests; local Python PRNGs outperform LLMs with >87% test pass rates

## Executive Summary
This paper investigates whether large language models can generate high-quality randomness suitable for cryptographic, simulation, and scheduling tasks. Through comprehensive experiments involving direct random number generation, password creation, and shuffling tasks, the study evaluates multiple state-of-the-art LLMs against NIST randomness test suites and entropy metrics. The findings reveal significant limitations in LLM randomness generation capabilities, with most models exhibiting statistical biases and failing to meet established randomness standards. The research highlights the current gap between LLM performance and traditional pseudorandom number generators for entropy-critical applications.

## Method Summary
The study employs a multi-faceted evaluation approach to assess LLM randomness quality. LLMs are prompted to generate 10,000 random 8-bit integers using temperature=0 for reproducibility, with outputs evaluated against the NIST Statistical Test Suite across nine different tests (Monobit, Frequency in block, Run Test, Longest run of Ones, Binary Rank, Linear Complexity, Serial Test, Spectral, Sign). Additional experiments include random password generation and card shuffling tasks, with shuffling quality measured through entropy calculations based on pairwise card distances. The experiments compare multiple LLMs (GPT-4o, Gemini 1.5 Pro, Mistral Large, Gemma2 27b, Llama 3.1 8b, Phi-3) against local Python random number generators as baseline references.

## Key Results
- Local Python random number generators consistently outperform LLMs, achieving >87% NIST test pass rates compared to LLMs' <50% pass rates
- Gemini 1.5 Pro exhibits strong bias toward specific numbers (e.g., 161 appears >10% of the time in sequences)
- Temperature=0 setting reveals that standard LLM parameters like temperature do not reliably improve statistical randomness quality
- Entropy-based shuffling evaluation shows LLMs produce suboptimal mixing patterns compared to algorithmic shuffling

## Why This Works (Mechanism)
The study demonstrates that LLM randomness generation is fundamentally limited by their training objectives and architecture. Unlike dedicated pseudorandom number generators designed specifically for statistical randomness, LLMs are trained to predict the next token in sequences, which creates inherent biases in their output distributions. The observed performance gaps suggest that current LLM architectures are not optimized for generating high-quality random numbers, particularly for applications requiring strong statistical properties.

## Foundational Learning
- **NIST Statistical Test Suite**: Standard battery of tests for evaluating randomness quality in binary sequences. Why needed: Provides objective, widely-accepted metrics for measuring statistical properties of random outputs. Quick check: Verify test suite installation and run sample binary sequence to confirm expected p-value distributions.

- **Entropy measurement in shuffling**: Quantitative assessment of mixing quality using pairwise card distance calculations. Why needed: Traditional randomness tests don't capture practical shuffling effectiveness for applications like card games or load balancing. Quick check: Calculate entropy for known shuffling algorithms (perfect shuffle, random swap) to establish baseline performance.

- **Temperature in LLM sampling**: Parameter controlling randomness in token selection during generation. Why needed: Determines the balance between deterministic output and stochastic variation in LLM responses. Quick check: Generate sequences at temperature=0 and temperature=1 to observe output variability differences.

## Architecture Onboarding

**Component Map**: LLM API -> Prompt Processing -> Output Generation -> Format Normalization -> Statistical Analysis Pipeline -> NIST Tests -> Result Aggregation

**Critical Path**: Prompt generation → LLM API call → Output parsing → Binary conversion → NIST test execution → p-value analysis → Pass/fail classification

**Design Tradeoffs**: Temperature=0 ensures reproducibility but may limit natural randomness; NIST tests provide rigorous statistical validation but don't capture all practical randomness requirements; multiple model evaluation provides comparative insights but increases computational cost

**Failure Signatures**: Code output instead of random values; inconsistent output formatting across models; sequence length mismatches; p-values clustering near thresholds indicating systematic biases

**First 3 Experiments**: 1) Generate 10,000 random integers from each model and verify output format compliance 2) Run Monobit and Frequency tests as initial screening 3) Compare model-specific bias patterns using frequency distribution analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can entropy-based sampling or parallel chain-of-thought decoding significantly improve the quality of randomness in LLM outputs to match local PRNG standards?
- Basis in paper: The abstract and conclusion explicitly list "entropy-based sampling and parallel chain-of-thought decoding" as suggested potential improvements to address the identified limitations.
- Why unresolved: The experiments in the paper evaluate standard LLM configurations; the proposed improvements are theoretical or future implementations that were not benchmarked in this study.
- What evidence would resolve it: A comparative study applying these specific decoding strategies to the tested models, followed by the same NIST randomness test suite analysis.

### Open Question 2
- Question: To what extent do standard generation parameters, such as temperature and top-p, actually influence the statistical quality of randomness versus mere output variability?
- Basis in paper: Section 4.2 states that while it is often assumed adjusting temperature improves randomness, "our experiments suggest that this might not always be the case," and highlights the need for alternative approaches.
- Why unresolved: The study primarily relied on a temperature of 0 for reproducibility (Section 5), leaving the efficacy of higher temperatures or other sampling parameters for passing statistical randomness tests largely unexplored.
- What evidence would resolve it: A systematic ablation study measuring NIST pass rates and entropy scores across a range of temperature and top-p values for the same tasks.

### Open Question 3
- Question: Which specific architectural components or training data characteristics are primarily responsible for the observed biases in LLM randomness generation?
- Basis in paper: Section 6 notes that the "lack of access to the internal workings" of closed-weight models limits the understanding of these factors, and Section 4.1.2 identifies specific biases (e.g., Gemini favoring the number 161) without identifying their root cause.
- Why unresolved: The paper treats LLMs as black boxes (Section 3), identifying *that* they fail but not *why* specific numerical biases emerge from the model weights or training corpus.
- What evidence would resolve it: Analysis of open-weight models (e.g., Llama 3.1 8b) to correlate specific attention head patterns or training data frequencies with the failure rates in NIST tests.

## Limitations
- The study's temperature=0 setting may not reflect real-world LLM usage where temperature tuning is common for balancing creativity and determinism
- Evaluation relies entirely on NIST statistical tests, which may not capture all practical aspects of randomness quality needed for cryptographic or simulation applications
- Absence of cryptographic randomness evaluation (e.g., next-bit predictability tests) represents a significant limitation for applications requiring true security guarantees

## Confidence

**High confidence** in the finding that local Python random number generators outperform LLMs across all tested conditions, given the large performance gap (>30 percentage points in NIST test pass rates) and consistent results across multiple experiments.

**Medium confidence** in the relative ranking of LLM models for randomness generation, as performance differences are observed but the sample size per model and exact experimental conditions remain partially unspecified.

**Medium confidence** in the entropy-based shuffling evaluation methodology, as the pairwise distance metric is novel but its correlation with practical shuffling quality requires additional validation.

## Next Checks

1. Replicate the NIST test suite evaluation with additional random number generation runs per model to