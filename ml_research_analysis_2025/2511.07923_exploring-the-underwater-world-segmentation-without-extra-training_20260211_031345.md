---
ver: rpa2
title: Exploring the Underwater World Segmentation without Extra Training
arxiv_id: '2511.07923'
source_url: https://arxiv.org/abs/2511.07923
tags:
- uni00000013
- uni00000014
- uni00000015
- underwater
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Earth2Ocean, a training-free open-vocabulary
  segmentation framework for underwater scenes. The method combines geometric-guided
  visual mask generation and category-visual semantic alignment to adapt terrestrial
  vision-language models to underwater conditions without additional training.
---

# Exploring the Underwater World Segmentation without Extra Training

## Quick Facts
- arXiv ID: 2511.07923
- Source URL: https://arxiv.org/abs/2511.07923
- Reference count: 40
- Key result: Training-free open-vocabulary segmentation framework achieving >6 point mIoU improvement on underwater benchmarks

## Executive Summary
Earth2Ocean introduces a novel training-free approach for underwater semantic segmentation by adapting terrestrial vision-language models to underwater environments. The framework combines geometric-guided visual mask generation with category-visual semantic alignment to overcome the domain gap between terrestrial and underwater imagery. Extensive experiments on the UOVSBench benchmark demonstrate significant performance improvements while maintaining computational efficiency during inference.

## Method Summary
Earth2Ocean leverages existing vision-language models without additional training by implementing a two-stage adaptation process. First, geometric-guided visual mask generation identifies underwater-specific structures and patterns. Second, category-visual semantic alignment bridges the semantic gap between terrestrial and underwater concepts. The method processes input images through geometric feature refinement and enhanced semantic alignment modules to produce accurate segmentation masks for underwater scenes.

## Key Results
- Achieves >6 point mIoU improvement on UOVSBench benchmark
- Maintains state-of-the-art performance across multiple backbone architectures
- Demonstrates efficient inference with competitive computational requirements

## Why This Works (Mechanism)
The framework succeeds by effectively adapting terrestrial vision-language models to underwater conditions through geometric feature refinement and semantic alignment. The geometric-guided mask generation captures underwater-specific visual patterns and structures, while the semantic alignment component ensures proper mapping between terrestrial concepts and their underwater counterparts. This dual approach addresses both the visual and semantic challenges of underwater segmentation without requiring domain-specific training data.

## Foundational Learning

**Vision-Language Models**: Pre-trained models that understand both visual content and textual descriptions, crucial for open-vocabulary tasks. Quick check: Verify the model can generate accurate masks for novel categories.

**Geometric Feature Refinement**: Process of extracting and enhancing spatial patterns specific to underwater environments. Quick check: Confirm geometric features capture underwater-specific structures like coral formations or fish schools.

**Semantic Alignment**: Mapping between terrestrial concepts and their underwater equivalents to bridge domain gaps. Quick check: Validate alignment accuracy for underwater-specific categories.

**Open-Vocabulary Segmentation**: Segmentation approach that can handle novel or unseen categories without explicit training. Quick check: Test on categories not present in training data.

**Domain Adaptation**: Techniques for adapting models trained on one domain (terrestrial) to perform well on another domain (underwater). Quick check: Measure performance degradation when applying terrestrial models directly to underwater data.

## Architecture Onboarding

**Component Map**: Input Image -> Geometric Feature Extraction -> Visual Mask Generation -> Semantic Alignment -> Output Segmentation

**Critical Path**: The geometric feature extraction and semantic alignment modules form the core pipeline, with visual mask generation serving as the intermediary step that combines geometric and semantic information.

**Design Tradeoffs**: Training-free approach sacrifices potential performance gains from domain-specific fine-tuning for broader applicability and reduced computational overhead during training.

**Failure Signatures**: Performance degradation occurs in extreme low-visibility conditions, highly turbid waters, or when geometric priors don't match underwater scene characteristics.

**First Experiments**:
1. Baseline comparison: Apply terrestrial model directly to underwater data without adaptation
2. Geometric-only evaluation: Test performance using only geometric-guided mask generation
3. Semantic-only evaluation: Test performance using only category-visual semantic alignment

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Geometric guidance assumptions may fail in turbid or highly variable underwater conditions
- Semantic alignment quality depends on terrestrial vision-language model coverage of underwater concepts
- Limited validation beyond UOVSBench benchmark dataset
- Computational efficiency claims need verification across different deployment scenarios

## Confidence
High confidence: Methodological framework and UOVSBench experimental setup
Medium confidence: State-of-the-art claims across multiple backbones
Low confidence: Training-free approach adaptability to extreme underwater conditions

## Next Checks
1. Test Earth2Ocean on datasets capturing extreme underwater conditions (zero-visibility, strong backscatter) to assess geometric guidance limitations
2. Conduct cross-dataset validation by training on UOVSBench and evaluating on marine biology datasets to verify semantic alignment generalization
3. Perform computational profiling with different input resolutions and compare against trained underwater segmentation models to validate efficiency claims under real-world deployment constraints