---
ver: rpa2
title: 'JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing
  Text in the Music Industry'
arxiv_id: '2504.20849'
source_url: https://arxiv.org/abs/2504.20849
tags:
- diversity
- text
- https
- texts
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of repetitive and monotonous text
  generation in marketing content by developing methods to increase diversity while
  maintaining quality. The authors introduce JaccDiv, a novel reference-free metric
  using Jaccard similarity to quantify diversity between generated texts, and benchmark
  various large language models including T5, GPT-3.5, GPT-4, and Llama2 using techniques
  like fine-tuning, few-shot learning, and zero-shot approaches.
---

# JaccDiv: A Metric and Benchmark for Quantifying Diversity of Generated Marketing Text in the Music Industry

## Quick Facts
- arXiv ID: 2504.20849
- Source URL: https://arxiv.org/abs/2504.20849
- Reference count: 40
- Primary result: Novel JaccDiv metric and benchmark methods achieve high-quality, diverse marketing text generation using adaptive logit bias and input randomization

## Executive Summary
This paper addresses the problem of repetitive and monotonous text generation in marketing content by developing methods to increase diversity while maintaining quality. The authors introduce JaccDiv, a novel reference-free metric using Jaccard similarity to quantify diversity between generated texts, and benchmark various large language models including T5, GPT-3.5, GPT-4, and Llama2 using techniques like fine-tuning, few-shot learning, and zero-shot approaches. They also experiment with prompt engineering strategies such as data ordering, alternate instructions, and adaptive logit bias to enhance diversity. Results show that GPT-3.5 and GPT-4 achieve high quality scores (0.829-0.886 on G-Eval metrics), while adaptive logit bias and shuffled input data significantly improve diversity scores (JaccDiv 0.985-0.994). Human evaluation confirms JaccDiv correlates with perceived diversity, and GPT-4 with adaptive logit bias achieves the highest diversity score (0.885) among tested models. The work demonstrates effective strategies for generating diverse marketing content and provides a practical diversity evaluation metric applicable beyond the music industry.

## Method Summary
The methodology combines JaccDiv, a reference-free diversity metric using pairwise n-gram Jaccard similarity, with various LLM prompting techniques including adaptive logit bias, input shuffling, and alternate instructions. The benchmark uses an industrial dataset of 440 band profiles filtered to 359 samples, with 50 bands selected for evaluation. Models tested include T5-small, Flan-T5-Base (prefix-tuned), GPT-3.5-turbo-1106, GPT-4-turbo-1106, and LLaMa2-13b-chat. Quality is assessed via G-Eval (GPT-4-based) across multiple criteria, while diversity is measured by JaccDiv. Adaptive logit bias penalizes frequently used tokens across generations, and input randomization disrupts template-like output patterns.

## Key Results
- GPT-4 achieves highest quality scores (0.886 G-Eval) among tested models
- Adaptive logit bias and data shuffling significantly improve diversity scores (JaccDiv 0.985-0.994)
- GPT-4 with adaptive logit bias achieves highest diversity score (0.885) in human evaluation
- Temperature above 1.6 causes catastrophic randomness and quality degradation

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Logit Bias for Cross-Generation Diversity
- Claim: Penalizing frequently used tokens from previous generations increases lexical diversity across outputs.
- Mechanism: Track token frequency across generations → compute bias values proportional to usage → apply negative bias (-100 to 0) to top 100 most frequent tokens in subsequent prompts. This directly suppresses the model's tendency to reuse successful patterns.
- Core assumption: Repetition across samples stems from the model's preference for high-probability token sequences; suppressing these forces exploration of alternative vocabulary.
- Evidence anchors:
  - [abstract] "adaptive logit bias...significantly improve diversity scores (JaccDiv 0.985-0.994)"
  - [Section 5.2] "The Logit bias experiments had a strong effect on the diversity... Less used tokens among the top 100 were successfully limited"
  - [corpus] Related work "A Penalty Goes a Long Way" (arXiv:2507.15092) confirms prompt-based penalties affect lexical diversity under length variations—mechanism aligns but with different implementation
- Break condition: If bias values exceed -50 for high-frequency tokens, words may be missing mid-sentence, degrading quality. Monitor for incoherent outputs.

### Mechanism 2: N-gram Jaccard Similarity for Diversity Quantification
- Claim: Pairwise Jaccard similarity over n-grams provides a computable, interpretable diversity metric that correlates with human judgment.
- Mechanism: For each text pair, extract bi-grams through n-grams → compute Jaccard similarity (intersection/union) → average across all pairs. Diversity = 1 - similarity.
- Core assumption: Lexical overlap (n-gram sharing) is a sufficient proxy for perceived diversity in marketing contexts; semantic similarity is secondary.
- Evidence anchors:
  - [abstract] "Human evaluation confirms JaccDiv correlates with perceived diversity"
  - [Section 5.3] Table 3 shows GPT-4 with Adaptive Logit Bias scored highest by both JaccDiv (0.9903) and Human (0.885), though human scores are consistently stricter
  - [corpus] "QUDsim" (arXiv:2504.09373) addresses discourse-level similarity—suggests JaccDiv captures lexical but not structural/discourse diversity
- Break condition: When texts vary significantly in length, Jaccard similarity becomes unreliable. The paper notes texts were "generally of similar length" during experiments.

### Mechanism 3: Input Order Randomization
- Claim: Shuffling structured input data (genres, locations, etc.) before prompting reduces template-like output patterns.
- Mechanism: Present same data fields in randomized order → model attends to different elements first → generates varied sentence structures and word ordering.
- Core assumption: Models tend to follow input order in output generation; breaking this pattern disrupts learned templates.
- Evidence anchors:
  - [Section 5.2] "This method had a significant impact on the diversity of GPT3.5 and LLaMa2... shuffling the order of the input didn't impact quality"
  - [Section 4.3] "if the music genres were specified as Pop, Jazz, Lounge the models would by default use the same order when describing each genre"
  - [corpus] Weak direct evidence—corpus focuses on detection/profiling rather than generation diversity techniques
- Break condition: GPT-4 showed inverse behavior—diversity slightly decreased with shuffling. This technique is model-dependent and requires empirical validation per model.

## Foundational Learning

- Concept: **Logit manipulation at inference time**
  - Why needed here: Understanding how to directly bias token probabilities is essential for controlling output without retraining
  - Quick check question: What range of logit bias values suppresses tokens without causing incoherence?

- Concept: **Reference-free evaluation metrics**
  - Why needed here: Traditional metrics like ROUGE require ground-truth references; marketing text has no single "correct" output
  - Quick check question: Why does JaccDiv compare texts to each other rather than to a reference?

- Concept: **Temperature vs. determinism tradeoff**
  - Why needed here: Randomness parameters affect diversity but introduce quality risks above certain thresholds
  - Quick check question: At what temperature threshold did the authors observe "catastrophic randomness"?

## Architecture Onboarding

- Component map:
Input Data → Preprocessing (shuffle/format) → Prompt Construction → LLM API (with optional logit bias) → Generated Text → N-gram Extraction → Pairwise Jaccard Matrix → Diversity Score
                                                              ↓
                                                 G-Eval (GPT-4) → Quality Score

- Critical path:
  1. Token frequency tracking across previous generations
  2. Adaptive bias computation for current prompt
  3. N-gram diversity computation post-generation

- Design tradeoffs:
  - **Fixed vs. Adaptive Logit Bias**: Fixed is simpler but over-penalizes; adaptive scales bias by frequency but requires state management
  - **Quality vs. Diversity**: Higher logit penalties increase diversity but risk missing words mid-sentence (observed at -50 fixed bias)
  - **Model selection**: GPT-4 highest quality (0.886) but less responsive to shuffling; GPT-3.5 more responsive to prompt variations

- Failure signatures:
  - Word omission mid-sentence → logit bias too aggressive
  - All outputs begin identically → input ordering not shuffled or prompt too prescriptive
  - JaccDiv near 1.0 but texts appear repetitive → n-gram level too granular, semantic repetition not captured
  - Few-shot performance collapses (0.320 for GPT-4 few-shot) → example quality issues, translated data loses nuance

- First 3 experiments:
  1. Establish baseline: Run GPT-3.5/GPT-4 with base prompt on 50 samples, compute JaccDiv and G-Eval scores to establish quality-diversity starting point
  2. Ablate logit bias strength: Test -25, -50, -75 bias values on top 100 tokens; identify threshold where quality degrades (measure via G-Eval fluency)
  3. Validate JaccDiv-human correlation: Have 2 annotators score diversity on subset using highlighted n-gram interface; compute Cohen's kappa against JaccDiv scores

## Open Questions the Paper Calls Out
None

## Limitations
- JaccDiv metric captures lexical but not semantic or discourse-level diversity
- Model-specific behavior requires individual calibration of diversity techniques
- Adaptive logit bias introduces state management complexity and quality degradation risks

## Confidence

**High Confidence Claims:**
- GPT-4 achieves highest quality scores (0.886 G-Eval) across tested models
- Adaptive logit bias and data shuffling significantly improve diversity metrics (JaccDiv 0.985-0.994)
- Human evaluation confirms JaccDiv correlates with perceived diversity, though human scores are consistently stricter
- Quality degrades at temperatures above 1.6, establishing clear operational boundaries

**Medium Confidence Claims:**
- JaccDiv provides a practical, reference-free diversity metric applicable beyond music industry
- N-gram range of 2-5 captures sufficient lexical variation for marketing text evaluation
- GPT-4 with adaptive logit bias achieves optimal diversity-quality tradeoff (0.885 diversity score)

**Low Confidence Claims:**
- Universal applicability of input order randomization across all LLM architectures
- Adaptive logit bias mechanism generalizes well to domains beyond structured marketing text
- Quality-diversity tradeoff curve remains stable across different text lengths and genres

## Next Checks

1. **Semantic Diversity Validation**: Design a controlled experiment using texts with high lexical diversity but low semantic variation (e.g., synonym substitutions in template sentences) to test whether JaccDiv can distinguish between true diversity and superficial variation. Compare JaccDiv scores with semantic similarity metrics like sentence transformers.

2. **Cross-Domain Generalization Test**: Apply the complete methodology (adaptive logit bias, input shuffling, JaccDiv) to a different structured text generation task such as product descriptions or financial summaries. Evaluate whether the same bias thresholds (-50) and parameter settings maintain quality-diversity balance across domains.

3. **State Management Impact Analysis**: Systematically vary the token frequency tracking window (last 10, 50, 100 generations) and measure the impact on both diversity scores and output coherence. Document the relationship between historical token suppression and current generation quality to establish optimal state retention parameters.