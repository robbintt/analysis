---
ver: rpa2
title: Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware
  Optimization
arxiv_id: '2501.13924'
source_url: https://arxiv.org/abs/2501.13924
tags:
- unknown
- samples
- h-score
- fpr95
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Adaptive Entropy-aware Optimization (AEO),
  the first framework designed for Multimodal Open-set Test-time Adaptation (MM-OSTTA).
  The method addresses the challenge of adapting pre-trained multimodal models to
  target domains containing unknown classes by amplifying the entropy difference between
  known and unknown samples during online adaptation.
---

# Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization

## Quick Facts
- **arXiv ID:** 2501.13924
- **Source URL:** https://arxiv.org/abs/2501.13924
- **Reference count:** 28
- **Primary result:** AEO framework improves H-score by 22.07% on EPIC-Kitchens for multimodal open-set test-time adaptation

## Executive Summary
This paper introduces Adaptive Entropy-aware Optimization (AEO), the first framework designed for Multimodal Open-set Test-time Adaptation (MM-OSTTA). The method addresses the challenge of adapting pre-trained multimodal models to target domains containing unknown classes by amplifying the entropy difference between known and unknown samples during online adaptation. AEO introduces two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). UAE dynamically adjusts entropy optimization based on sample uncertainty, while AMP exploits cross-modal interactions to enhance separation between known and unknown classes. The authors establish a new benchmark using existing datasets across action recognition and 3D semantic segmentation tasks with five modalities.

## Method Summary
AEO introduces a novel approach to test-time adaptation for multimodal models operating in open-set conditions. The framework consists of two main components: UAE, which adaptively switches between entropy minimization and maximization based on sample uncertainty, and AMP, which exploits cross-modal prediction discrepancies to enhance unknown class rejection. The method processes batches of multimodal data through modality-specific feature extractors and a fused classifier, computing entropy-based weights to guide the optimization direction. UAE applies a Tanh-weighted entropy loss that pushes high-confidence samples toward low entropy (known classes) and high-uncertainty samples toward high entropy (unknown classes). AMP further refines this by maximizing prediction discrepancy between modalities for unknown samples while minimizing it for known samples, leveraging the assumption that unknown samples lack coherent cross-modal features.

## Key Results
- AEO increases H-score by 22.07% on EPIC-Kitchens compared to baseline methods
- The framework achieves strong results in long-term and continual adaptation scenarios
- Performance improvements are demonstrated across five different modalities in both action recognition and 3D semantic segmentation tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Adaptively switching between entropy minimization and maximization based on sample uncertainty amplifies the distribution gap between known and unknown classes.
- **Mechanism:** The framework calculates a normalized entropy $H(\hat{p})$ for incoming samples. It computes a weight $W_{ada} = \text{Tanh}(\beta \cdot (H(\hat{p}) - \alpha))$. If $H(\hat{p}) > \alpha$ (high uncertainty), the weight is positive, maximizing entropy (pushing the sample toward the "unknown" high-entropy region). If $H(\hat{p}) < \alpha$ (high confidence), the weight is negative, minimizing entropy (pushing the sample toward the "known" low-entropy region).
- **Core assumption:** The paper assumes that known and unknown samples are linearly separable in the entropy space such that a threshold $\alpha$ can reliably distinguish them probabilistically.
- **Evidence anchors:** [abstract]: "UAE dynamically adjusts entropy optimization based on sample uncertainty." [section 3.2]: "The UAE loss... maximizes $H(\hat{p})$ when $H(\hat{p}) > \alpha$... and minimizes $H(\hat{p})$ when $H(\hat{p}) < \alpha$." [corpus]: Corpus neighbors explore uncertainty for open-set tasks (e.g., "Open-Set LiDAR Panoptic Segmentation Guided by Uncertainty-Aware Learning"), supporting the viability of uncertainty as a signal, though the specific Tanh-weighting mechanism is unique to this work.
- **Break condition:** If the domain shift is so extreme that known classes also exhibit high entropy (overlap with the unknown distribution), the threshold $\alpha$ may invert the optimization, degrading accuracy.

### Mechanism 2
- **Claim:** Exploiting cross-modal prediction discrepancy enhances the model's ability to reject unknown samples by enforcing disagreement for uncertain inputs.
- **Mechanism:** For samples identified as likely unknown (high entropy), the Adaptive Modality Prediction Discrepancy Optimization (AMP) maximizes the distance $Dis(\hat{p}_1, \hat{p}_2)$ between predictions from different modalities (e.g., Video vs. Audio). For likely known samples, it minimizes this distance to ensure consistency.
- **Core assumption:** Unknown samples lack coherent cross-modal features, causing modality-specific predictions to diverge naturally, whereas known samples share consistent semantic content across modalities.
- **Evidence anchors:** [abstract]: "AMP... encourages diverse predictions between modalities for unknown samples while maintaining consistent predictions for known samples." [section 3.3]: "We propose maximizing the prediction discrepancy between modalities for unknown samples to encourage uncertainty." [corpus]: "Enhancing Multi-view Open-set Learning via Ambiguity Uncertainty Calibration" discusses view-induced biases in open-set scenarios, providing context for why cross-modal management is critical.
- **Break condition:** If the multimodal backbone fails to extract meaningful features for one modality (e.g., dark camera in night driving), the discrepancy signal may become noisy or misleading.

### Mechanism 3
- **Claim:** The entropy difference ($H_{unknown} - H_{known}$) functions as a reliable proxy for adaptation performance.
- **Mechanism:** Rather than solely optimizing for accuracy, the method treats the "entropy gap" as the primary optimization target. By widening this gap, the Maximum Softmax Probability (MSP) threshold becomes more effective at separating classes.
- **Core assumption:** Standard Test-Time Adaptation (TTA) methods like Tent fail because they uniformly minimize entropy, collapsing the gap and making unknown samples look confident.
- **Evidence anchors:** [section 3.1]: "The entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance." [figure 2]: Shows a direct correlation where a larger entropy difference leads to a lower False Positive Rate (FPR95). [corpus]: Corpus literature on "Stabilizing Open-Set Test-Time Adaptation" supports the general difficulty of open-set TTA, validating the need for mechanisms beyond standard entropy minimization.
- **Break condition:** In the absence of unknown samples in a batch, the maximization term has no target, potentially altering the gradient dynamics if not balanced correctly by the batch statistics.

## Foundational Learning

- **Concept: Test-Time Adaptation (TTA)**
  - **Why needed here:** You must understand how to update model parameters (usually BatchNorm or heads) using only the current test batch without labels. AEO modifies the standard TTA objective (Entropy Minimization).
  - **Quick check question:** Why does standard entropy minimization (Tent) harm performance in an open-set scenario?

- **Concept: Open-Set Recognition (OSR)**
  - **Why needed here:** You need to grasp that the model must not only classify $C$ known classes but also detect inputs that do not belong to any of them, typically using a confidence score threshold.
  - **Quick check question:** What metric does the paper use to measure the trade-off between classifying knowns and detecting unknowns?

- **Concept: Multimodal Fusion**
  - **Why needed here:** The method relies on distinct feature extractors (e.g., Video and Audio) converging. AMP operates on the interaction between these modality-specific prediction heads.
  - **Quick check question:** How does the "discrepancy" between modalities serve as a signal for the "unknownness" of a sample?

## Architecture Onboarding

- **Component map:** Multimodal Input -> Feature Extractors $g_k$ -> Fused Classifier $h$ + Modality-Specific Classifiers $h_k$ -> AEO Module -> Weighted Loss -> Backpropagation

- **Critical path:**
  1. Forward pass: Generate fused prediction $\hat{p}$ and modality predictions $\hat{p}_1, \hat{p}_2$.
  2. Entropy Analysis: Compute entropy $H(\hat{p})$ to determine if the sample is "likely known" or "likely unknown."
  3. Loss Computation: Apply UAE (adaptively min/max entropy) and AMP (modulate discrepancy).
  4. Update: Backpropagate using the weighted loss.

- **Design tradeoffs:**
  - **Threshold Sensitivity:** The hyperparameter $\alpha$ (entropy threshold) is critical. If set too low, known samples might be treated as unknown (harming accuracy); if too high, unknowns are treated as known (harming detection).
  - **Modality reliance:** The method assumes equal reliability of modalities. If LiDAR is robust but Camera is noisy (e.g., Night scenario), forcing consistency/discrepancy might introduce noise.

- **Failure signatures:**
  - **Score Collapse:** If the entropy gap does not increase, the plot of Score Distributions (Fig 6) will show significant overlap, leading to high FPR95.
  - **Negative Adaptation:** If accuracy drops significantly compared to the source-only model, check if $W_{ada}$ is incorrectly maximizing entropy for known classes (likely an $\alpha$ issue).

- **First 3 experiments:**
  1. **Entropy Gap Visualization:** Run the source model on a target batch without adaptation. Plot histograms of entropy for known vs. unknown classes to confirm they are separable enough to justify the AEO assumption.
  2. **UAE vs. AMP Ablation:** Isolate the two components. Test if UAE alone improves H-score, and verify if AMP provides the additional boost claimed in Table 7.
  3. **Threshold Scan:** Sweep the $\alpha$ hyperparameter on a validation split of the target domain to find the "sweet spot" before running the full online adaptation.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The framework's effectiveness heavily depends on the assumption that known and unknown classes are linearly separable in entropy space, which may not hold under extreme domain shifts.
- The threshold parameter α requires careful tuning and may need to be adaptive across different target domains rather than fixed.
- The cross-modal discrepancy signal (AMP) assumes consistent feature quality across modalities, but in real-world scenarios like nighttime driving or occluded sensors, this assumption could break down.

## Confidence
- **High Confidence:** The entropy-based adaptation mechanism (UAE) has strong theoretical grounding in open-set literature and the ablation studies clearly demonstrate its contribution to performance improvements.
- **Medium Confidence:** The multimodal discrepancy optimization (AMP) shows promising results but relies on assumptions about cross-modal feature consistency that need more rigorous validation across diverse failure modes.
- **Medium Confidence:** The claim of being the "first framework" for MM-OSTTA needs verification against emerging concurrent work, as the field is rapidly evolving.

## Next Checks
1. **Cross-Modal Robustness Test:** Evaluate AEO performance when one modality is systematically degraded (e.g., low-light conditions for camera, high noise for audio) to assess AMP's reliability under modality failure.

2. **Threshold Sensitivity Analysis:** Conduct systematic sweeps of the α parameter across multiple target domains to establish whether a universal threshold exists or if domain-specific calibration is required.

3. **Unknown Class Distribution Impact:** Test AEO's performance when unknown classes are not uniformly distributed in entropy space—for example, when some unknown classes have low entropy due to semantic similarity to known classes.