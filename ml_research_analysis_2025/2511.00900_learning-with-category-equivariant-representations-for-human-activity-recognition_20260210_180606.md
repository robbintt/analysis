---
ver: rpa2
title: Learning with Category-Equivariant Representations for Human Activity Recognition
arxiv_id: '2511.00900'
source_url: https://arxiv.org/abs/2511.00900
tags:
- total
- axes
- group
- poset
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a category-equivariant learning framework for
  human activity recognition that explicitly models temporal shifts, amplitude drift,
  and sensor hierarchies as symmetries. It formulates a product category of a group
  (time shifts and per-sensor gains) and a poset (sensor hierarchy) and builds representations
  as natural transformations commuting with both.
---

# Learning with Category-Equivariant Representations for Human Activity Recognition

## Quick Facts
- arXiv ID: 2511.00900
- Source URL: https://arxiv.org/abs/2511.00900
- Reference count: 23
- Primary result: Category-equivariant learning improves OOD accuracy by ~46 percentage points on UCI HAR under realistic test-time perturbations

## Executive Summary
This paper proposes a category-equivariant learning framework for human activity recognition that explicitly models temporal shifts, amplitude drift, and sensor hierarchies as symmetries. It formulates a product category of a group (time shifts and per-sensor gains) and a poset (sensor hierarchy) and builds representations as natural transformations commuting with both. The method applies per-sensor RMS normalization, axis-to-magnitude pooling, and low-frequency Fourier magnitudes to yield a compact, interpretable feature map. On the UCI HAR benchmark, this approach improves out-of-distribution accuracy by approximately 46 percentage points (≈3.6×) over a raw time-series baseline under realistic test-time perturbations (timing shifts, gain drift, orientation changes). Theoretical analysis proves exact invariance for group-invariant blocks and provides robustness bounds for non-equivariant baselines, showing that structured equivariance offers both interpretability and strong robustness.

## Method Summary
The method uses UCI HAR dataset with tri-axial accelerometer and gyroscope, applying RMS normalization to eliminate amplitude drift sensitivity, axis-to-magnitude pooling for orientation invariance, and low-frequency FFT magnitude bins for time-shift invariance. These fixed operators form a compact 74-dimensional feature map (3k + 2, with k=24 frequency bins) that commutes with the product category of time shifts, per-sensor gains, and sensor hierarchies. A multinomial logistic regression classifier is trained on these features without data augmentation, achieving strong out-of-distribution robustness through built-in invariance rather than learned adaptation.

## Key Results
- Category-equivariant learning improves OOD accuracy by ~46 percentage points on UCI HAR under realistic test-time perturbations
- The method provides provable invariance guarantees under group-invariant blocks and robustness bounds for non-equivariant baselines
- Feature dimension reduced from 768 (raw baseline) to 74 while maintaining interpretability

## Why This Works (Mechanism)

### Mechanism 1: Gain Invariance via RMS Normalization
- Claim: Per-sensor RMS normalization eliminates amplitude drift sensitivity by projecting signals onto unit spheres before feature extraction
- Mechanism: The normalization ẋ = x/‖x‖₂ is homogeneous: for any gain λ > 0, normalize(λx) = normalize(x). The amplitude scalar a = ‖x‖₂ is retained separately and transforms equivariantly (a → λa)
- Core assumption: Sensor gain drift is multiplicative and approximately constant within each window; the class label is gain-invariant
- Evidence anchors:
  - [abstract] "remain stable under realistic distortions such as time shifts, amplitude drift"
  - [Section 2.3, Eq. 1] "bxs := xs / ‖xs‖₂" with proof of gain invariance
  - [corpus] Related work "CatEquiv" (arXiv:2511.01139) applies similar RMS normalization with reported robustness gains
- Break condition: If gain varies non-multiplicatively (e.g., clipping, quantization) or carries class information, normalization may discard discriminative signal

### Mechanism 2: Time-Shift Invariance via Fourier Magnitudes
- Claim: Low-frequency FFT magnitude bins are exactly invariant to circular time shifts, providing provable robustness to temporal misalignment
- Mechanism: Circular shift multiplies each FFT coefficient by e^{-2πirt/T} (unit-modulus phase). Taking absolute values removes phase: |FFT(τ_t x)[r]| = |FFT(x)[r]|. Only k=24 low-frequency bins are retained
- Core assumption: Temporal shifts are circular within the window; class-relevant information lives in magnitude spectrum (phase discarded)
- Evidence anchors:
  - [abstract] "remain stable...time shifts"
  - [Section 2.3, Prop. 3c] "Taking absolute values removes this phase, yielding |dτ_t m[r]| = |bm[r]|"
  - [corpus] Weak direct evidence; classical signal processing (Oppenheim & Schafer ref. [15]) provides theoretical grounding
- Break condition: Non-circular shifts (boundary effects), time-warping, or phase-dependent class structure break invariance guarantees

### Mechanism 3: Orientation Invariance via Axis-to-Magnitude Pooling
- Claim: Computing per-sample magnitude √(x² + y² + z²) from tri-axial signals is invariant to SO(3) rotations, handling device pose variation
- Mechanism: For any rotation R ∈ SO(3), ‖R·x‖₂ = ‖x‖₂ by orthogonality. The poset structure (axes → magnitude → total) ensures this pooling is natural: transport-then-pool equals pool-then-transport
- Core assumption: Orientation is label-invariant; discriminative information survives magnitude projection
- Evidence anchors:
  - [abstract] "device orientation changes"
  - [Section 2.3, Prop. 3b] "m_R(n) = √‖Rbx(n)‖²₂ = m(n)" using RᵀR = Id₃
  - [corpus] No direct corpus validation for this specific mechanism; assumption based on geometric argument
- Break condition: If axis-specific patterns matter (e.g., direction of motion), magnitude pooling discards discriminative information

## Foundational Learning

- Concept: **Category theory basics (functor, natural transformation)**
  - Why needed here: The paper formalizes equivariance as naturality: representations Φ are natural transformations between data functor X and model functor Y. Understanding "commuting squares" is essential
  - Quick check question: Given functors F, G: C → D and morphism f: A → B in C, what does the naturality square for transformation η require?

- Concept: **Group-equivariant representations**
  - Why needed here: The M = C_T × Λ component is a group; group invariance means Φ(g·x) = Φ(x). Fourier magnitudes are a classical construction
  - Quick check question: Why does the Fourier magnitude achieve shift-invariance while the raw Fourier coefficients do not?

- Concept: **Posets and thin categories**
  - Why needed here: Sensor hierarchy (axes → magnitude → total) is a poset—there is at most one morphism between any two objects. Naturality on generators implies global naturality (Lemma 2)
  - Quick check question: In a thin category, if naturality holds on all generating morphisms, why does it hold on all composites?

## Architecture Onboarding

- Component map: Input (R^T)³ per sensor → RMS normalize → axis-to-magnitude pooling → rFFT magnitude → extract bins 1-24 → concatenate ACC_spec, GYRO_spec, (ACC+GYRO)/2, a_ACC, a_GYRO
- Critical path:
  1. Verify ‖x‖₂ > 0 before normalization (zero-signal handling)
  2. Confirm rFFT output is real-valued magnitude (not complex)
  3. Ensure poset naturality: mean-aggregation at TOTAL matches 1/|S| scaling
- Design tradeoffs:
  - k (frequency bins): Higher k retains more information but reduces invariance to non-circular effects; paper shows similar results for k ∈ {16, 24, 32}
  - Amplitude scalars: Retaining a_s adds equivariant (not invariant) information—useful if gain magnitude carries signal
  - Log transform on a_s: Applied downstream; stabilizes classification but breaks strict naturality
- Failure signatures:
  - Zero-division on silent windows: Check ‖x‖₂ before normalization
  - Boundary artifacts: Circular shift assumption violated if activity spans window edges
  - Over-smoothing: Excessive pooling destroys discriminative high-frequency content
- First 3 experiments:
  1. **Ablation by component**: Disable each mechanism (RMS, magnitude pooling, FFT) individually to quantify contribution on OOD test set
  2. **Perturbation sweep**: Vary gain range (e.g., [0.5, 2.0]), shift magnitude (±32 samples), rotation distribution to map robustness boundaries
  3. **In-distribution vs. OOD gap**: Compare all models on unperturbed test data to verify invariance does not sacrifice baseline accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can learnable layers with built-in naturality constraints replace the fixed operators (RMS normalization, axis-to-magnitude pooling, Fourier magnitudes) while preserving category-equivariance guarantees?
- Basis in paper: [explicit] "On the modeling side, learnable layers with built-in naturality—imposing the commuting constraints during training—can replace fixed operators while preserving guarantees."
- Why unresolved: The current framework uses fixed, hand-crafted operators; learnable equivariant layers could improve expressiveness but require new training methodologies
- What evidence would resolve it: Implementation of learnable category-equivariant layers that satisfy naturality constraints during training, evaluated on HAR benchmarks

### Open Question 2
- Question: How does the framework extend to richer symmetry classes such as time-warp semigroups or sensor-specific semigroups beyond the current Group×Poset formulation?
- Basis in paper: [explicit] "Richer symmetry classes (e.g., time-warp semigroups, photometric or sensor-specific semigroups) and also deeper hierarchies (multi-scale spatial partitions, taxonomies) should broaden applicability."
- Why unresolved: Current formulation only handles circular time shifts and per-sensor gains; real-world distortions may involve non-uniform time warping
- What evidence would resolve it: Formal category-theoretic treatment of time-warp semigroups with empirical validation on HAR tasks with elastic timing distortions

### Open Question 3
- Question: Can the category-equivariant framework scale to spatio-temporal graphs and multi-modal sensor networks beyond the current two-sensor setup?
- Basis in paper: [explicit] "Future work includes extensions to spatio-temporal graphs and multi-modal sensor networks."
- Why unresolved: The paper only evaluates on UCI HAR with ACC and GYRO sensors; scalability to larger sensor hierarchies is untested
- What evidence would resolve it: Application to multi-modal datasets with complex sensor topologies, demonstrating maintained robustness gains

### Open Question 4
- Question: What is the trade-off between the discriminative power lost by discarding phase information and the robustness gained from time-shift invariance?
- Basis in paper: [inferred] The paper notes that "Time-shift invariance obtained through spectral magnitudes necessarily discards phase information" and that discrimination must arise from other components or increasing k
- Why unresolved: The explicit trade-off between invariance and discriminability is acknowledged but not quantified across varying k values or phase-preserving alternatives
- What evidence would resolve it: Systematic ablation varying k and comparing against phase-preserving equivariant representations on a phase-sensitive task

## Limitations

- The framework's exact invariance relies on assumptions (circular shifts, multiplicative gain drift, phase-invariant classes) that may not hold in practice
- Orientation invariance via magnitude pooling may discard discriminative axis-specific patterns for complex 3D activities
- Generalization claims to other datasets and activities are speculative, with current validation limited to the relatively simple UCI HAR benchmark

## Confidence

- **High confidence**: Theoretical framework (natural transformations, equivariance proofs), baseline methodology, and UCI HAR experimental setup are well-specified
- **Medium confidence**: Robustness gains on OOD perturbations are substantial and reproducible, but exact baselines and preprocessing details require clarification
- **Low confidence**: Generalization claims to other datasets and activities are speculative; the UCI HAR benchmark is relatively simple compared to real-world HAR deployments

## Next Checks

1. **Ablation study**: Systematically disable each invariance mechanism (RMS normalization, Fourier magnitudes, axis pooling) to quantify individual contributions to OOD robustness
2. **Perturbation boundary analysis**: Systematically vary shift magnitude, gain ranges, and rotation distributions to map the exact limits of the claimed invariance
3. **Cross-dataset generalization**: Test the exact method (no retraining) on at least one other HAR dataset (e.g., WISDM or Opportunity) to assess true out-of-distribution robustness