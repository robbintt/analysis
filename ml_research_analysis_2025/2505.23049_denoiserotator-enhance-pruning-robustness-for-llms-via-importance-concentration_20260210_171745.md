---
ver: rpa2
title: 'DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration'
arxiv_id: '2505.23049'
source_url: https://arxiv.org/abs/2505.23049
tags:
- importance
- pruning
- denoiserotator
- orthogonal
- sparsegpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DenoiseRotator, a method that enhances the
  robustness of large language model (LLM) pruning by concentrating parameter importance
  before pruning. Instead of just selecting which weights to remove, DenoiseRotator
  uses learnable orthogonal transformations to reshape the distribution of importance
  scores, minimizing their information entropy to make models more amenable to pruning.
---

# DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration

## Quick Facts
- **arXiv ID:** 2505.23049
- **Source URL:** https://arxiv.org/abs/2505.23049
- **Reference count:** 40
- **Primary result:** Consistently improves pruning robustness across multiple LLMs and sparsity levels.

## Executive Summary
DenoiseRotator is a method that enhances the robustness of large language model pruning by concentrating parameter importance before pruning. The approach uses learnable orthogonal transformations to reshape the distribution of importance scores, minimizing their information entropy to make models more amenable to pruning. This method can be integrated with existing pruning techniques like Magnitude, SparseGPT, and Wanda. Evaluated on multiple LLMs under 50% unstructured and 2:4 semi-structured sparsity, DenoiseRotator consistently improves perplexity and zero-shot accuracy. For example, on LLaMA3-70B with SparseGPT at 2:4 semi-structured sparsity, it reduced the perplexity gap to the dense model by 58%, narrowing degradation from 8.1 to 3.4 points.

## Method Summary
DenoiseRotator enhances pruning robustness by concentrating parameter importance before pruning. It inserts learnable orthogonal matrices R1 (layer-level) and R2 (attention-level) into Transformer layers, then trains them to minimize the information entropy of normalized importance scores. The method uses QR decomposition reparameterization to maintain orthogonality during training, with the original model weights frozen. After training for 2000 steps with Adam at lr=0.01 in bfloat16, the rotations are merged into weights and standard pruning is applied. The approach was evaluated across multiple LLMs (Mistral, LLaMA3, Qwen2.5) under 50% unstructured and 2:4 semi-structured sparsity constraints.

## Key Results
- Consistently improves perplexity and zero-shot accuracy across multiple LLMs and pruning methods
- On LLaMA3-70B with SparseGPT at 2:4 semi-structured sparsity, reduced perplexity gap by 58% (from 8.1 to 3.4 points)
- Effective across 50% unstructured and 2:4 semi-structured sparsity constraints
- Integrates with existing pruning methods including Magnitude, SparseGPT, and Wanda

## Why This Works (Mechanism)
DenoiseRotator works by concentrating parameter importance through entropy minimization before pruning. By reshaping the distribution of importance scores using learnable orthogonal transformations, the method makes the pruning process more effective and less damaging to model performance. The entropy minimization forces the model to identify and preserve the most critical parameters while allowing less important ones to be pruned, resulting in better retention of model capabilities after sparsity is applied.

## Foundational Learning

**Orthogonal Matrices** - Why needed: Maintain parameter importance distribution while allowing flexible reshaping during training. Quick check: Verify R^T R ≈ I after each training step.

**Information Entropy** - Why needed: Quantifies the spread of importance scores to identify concentration opportunities. Quick check: Monitor entropy values during training to ensure they decrease.

**QR Decomposition Reparameterization** - Why needed: Enables stable training of orthogonal matrices by maintaining orthogonality constraints. Quick check: Ensure gradient flow through QR decomposition is active and effective.

**Hessian Computation** - Why needed: Provides second-order information about parameter importance for pruning decisions. Quick check: Verify H = XX^T computation from calibration data is correct.

## Architecture Onboarding

**Component Map:** Calibration data → Hessian computation → Orthogonal rotation training → Merge rotations → Pruning → Evaluation

**Critical Path:** The training of orthogonal rotations is the critical path, as it directly determines the effectiveness of importance concentration and subsequent pruning robustness.

**Design Tradeoffs:** Uses bfloat16 for memory efficiency versus potential precision loss; freezes original weights to prevent interference with rotation learning; employs entropy minimization which may over-concentrate importance in some cases.

**Failure Signatures:** Orthogonality drift during training (R^T R deviates from identity); entropy plateau indicating training stagnation; excessive memory usage on large models.

**First Experiments:**
1. Verify orthogonality maintenance by monitoring ‖R^⊤R - I‖ throughout training
2. Check entropy reduction trajectory to ensure training is progressing
3. Test memory usage on target hardware to confirm feasibility for large models

## Open Questions the Paper Calls Out
None

## Limitations
- Memory requirements for large models like LLaMA3-70B (requires ~30 GB VRAM)
- Potential for over-concentration of importance leading to brittleness
- No analysis of long-term stability after fine-tuning or extended training

## Confidence
- Core claims (pruning robustness improvement): **High** - quantitatively demonstrated with specific perplexity improvements
- Generalizability to other pruning methods: **Medium** - shown effective across multiple techniques but not exhaustive
- Long-term stability: **Low** - no ablation studies or extended performance analysis provided

## Next Checks
1. Implement ablation studies to assess impact of entropy minimization on task-specific fine-tuning stability
2. Conduct experiments to verify orthogonality stability by monitoring R^⊤R deviation over training steps
3. Test method on broader range of pruning techniques including dynamic and block-level pruning scenarios