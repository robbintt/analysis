---
ver: rpa2
title: 'MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction
  Modelling'
arxiv_id: '2508.05492'
source_url: https://arxiv.org/abs/2508.05492
tags:
- chest
- trauma
- clinical
- moma
- alcohol
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mixture-of-Multimodal-Agents (MoMA), a novel
  architecture for clinical prediction using multimodal electronic health record (EHR)
  data. MoMA leverages specialized LLM agents to convert non-textual modalities like
  medical images and lab results into structured textual summaries, which are then
  integrated by an aggregator agent with clinical notes to form a unified multimodal
  summary.
---

# MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling

## Quick Facts
- **arXiv ID:** 2508.05492
- **Source URL:** https://arxiv.org/abs/2508.05492
- **Reference count:** 40
- **Primary result:** MoMA architecture outperforms state-of-the-art methods on three clinical prediction tasks using multimodal EHR data

## Executive Summary
This paper introduces Mixture-of-Multimodal-Agents (MoMA), a novel architecture for clinical prediction using multimodal electronic health record (EHR) data. MoMA leverages specialized LLM agents to convert non-textual modalities like medical images and lab results into structured textual summaries, which are then integrated by an aggregator agent with clinical notes to form a unified multimodal summary. This summary is used by a predictor agent to generate clinical predictions. Evaluated on three clinical prediction tasks (chest trauma severity, multitask trauma severity, and unhealthy alcohol use screening) using real-world datasets, MoMA outperforms current state-of-the-art methods. Key results include macro-F1 scores near 0.85 and micro-F1 scores above 0.90 for trauma tasks, and an AUROC of around 0.75 for alcohol screening.

## Method Summary
MoMA decomposes multimodal clinical data processing into specialized LLM agents for different modalities. The system includes an image agent for medical images, a labs agent for laboratory results, and a text agent for clinical notes. These agents generate structured textual summaries that are passed to an aggregator agent, which synthesizes the information into a unified multimodal summary. A predictor agent then uses this summary to generate clinical predictions. The architecture is designed to handle the heterogeneity of EHR data while maintaining interpretability and flexibility across different clinical tasks. The system is trained using a combination of synthetic and real-world data, with evaluation on multiple clinical prediction benchmarks.

## Key Results
- Trauma severity prediction: macro-F1 ~0.85, micro-F1 >0.90
- Unhealthy alcohol use screening: AUROC ~0.75
- Outperforms state-of-the-art methods across all three clinical prediction tasks
- Demonstrates enhanced accuracy and flexibility across various tasks and subgroups

## Why This Works (Mechanism)
MoMA works by decomposing the complex task of multimodal clinical prediction into specialized subtasks handled by different LLM agents. Each agent is optimized for its specific modality (images, labs, text), allowing for more accurate and contextually appropriate processing of each data type. The aggregator then synthesizes these modality-specific insights into a comprehensive clinical picture. This decomposition allows the system to leverage the strengths of LLMs for each modality while maintaining a coherent overall prediction. The architecture's flexibility allows it to adapt to different clinical tasks and data distributions without requiring extensive retraining.

## Foundational Learning
- **Multimodal fusion techniques**: Needed because EHR data includes diverse modalities that must be integrated; quick check: compare joint vs. late fusion performance
- **LLM-based data summarization**: Required to convert non-textual clinical data into structured text; quick check: evaluate summary quality with clinical experts
- **Agent-based architectures**: Essential for decomposing complex clinical reasoning into specialized components; quick check: ablation study removing individual agents
- **Clinical prediction modeling**: Fundamental for framing the problem and evaluating performance; quick check: compare against established clinical risk scores
- **Electronic health record structure**: Critical for understanding data sources and their clinical relevance; quick check: verify data extraction accuracy
- **Reinforcement learning for agent coordination**: Important for optimizing the aggregator's synthesis strategy; quick check: measure contribution of each agent's output

## Architecture Onboarding

**Component Map:** Image Agent -> Labs Agent -> Text Agent -> Aggregator Agent -> Predictor Agent

**Critical Path:** Input data flows through modality-specific agents (Image, Labs, Text) to generate summaries, which are then processed by the Aggregator to create a unified multimodal summary, finally fed to the Predictor for clinical outcome prediction.

**Design Tradeoffs:** The architecture trades computational efficiency for flexibility and accuracy by using multiple specialized agents rather than a single monolithic model. This increases inference time but allows for better handling of heterogeneous data and easier adaptation to new tasks. The reliance on LLM-generated summaries introduces potential hallucination risks but enables processing of unstructured clinical data without extensive feature engineering.

**Failure Signatures:** Poor performance may manifest as inconsistent predictions across similar cases, particularly when dealing with rare clinical presentations. The system may struggle with modalities where LLM summarization quality is low, and performance may degrade when training data distribution differs significantly from the evaluation set. Clinical reasoning errors may propagate through the agent chain if early agents generate inaccurate summaries.

**First Experiments:**
1. Evaluate each agent's output quality independently using clinical expert review
2. Conduct ablation studies by removing individual agents to quantify their contribution
3. Test performance on out-of-distribution clinical cases to assess generalization

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, though several are implied: how the architecture performs with different LLM models, the optimal balance between agent specialization and generalization, and how to handle modalities beyond the three tested (images, labs, text).

## Limitations
- Evaluation relies heavily on simulated multimodal data with only 17 real trauma cases for the primary task
- System's computational cost for real-time clinical deployment is not addressed
- Comparison against simpler baselines may overstate MoMA's advantages without including more competitive multimodal fusion approaches
- Potential hallucination risks from LLM-generated summaries were not thoroughly evaluated

## Confidence
- **High confidence in:** The architectural design and technical implementation of the MoMA system
- **Medium confidence in:** The relative performance improvements over baseline methods
- **Low confidence in:** Real-world clinical utility and scalability of the approach

## Next Checks
1. Evaluate MoMA on larger real-world clinical datasets with verified ground truth labels across multiple institutions to assess generalizability
2. Compare MoMA against state-of-the-art multimodal fusion architectures (e.g., cross-attention models, modality-specific encoders with late fusion) rather than just simpler baselines
3. Conduct ablation studies to quantify the contribution of each agent component and assess the impact of LLM summary quality on final prediction accuracy