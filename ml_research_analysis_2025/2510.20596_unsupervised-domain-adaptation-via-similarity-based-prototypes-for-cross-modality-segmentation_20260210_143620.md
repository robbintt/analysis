---
ver: rpa2
title: Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality
  Segmentation
arxiv_id: '2510.20596'
source_url: https://arxiv.org/abs/2510.20596
tags:
- domain
- prototypes
- segmentation
- adaptation
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses unsupervised domain adaptation for cross-modality
  medical image segmentation, where models trained on one imaging modality (e.g.,
  MRI) need to generalize to another (e.g., CT) without target-domain annotations.
  The proposed method uses similarity-based prototypes within an embedding space to
  explicitly align features across domains.
---

# Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation

## Quick Facts
- arXiv ID: 2510.20596
- Source URL: https://arxiv.org/abs/2510.20596
- Authors: Ziyu Ye; Chen Ju; Chaofan Ma; Xiaoyun Zhang
- Reference count: 27
- Primary result: 77.5% average Dice score for MRI→CT cardiac segmentation

## Executive Summary
This paper proposes an unsupervised domain adaptation method for cross-modality medical image segmentation using similarity-based prototypes. The approach addresses the challenge of adapting segmentation models trained on one imaging modality (e.g., MRI) to work on another (e.g., CT) without target-domain annotations. The method introduces class-wise similarity losses and prototype contrastive learning to explicitly align features across domains through an embedding space.

The proposed framework combines image-level translation with feature-level prototype alignment in a unified cycle structure. By maintaining feature dictionaries and computing class-wise prototypes, the method enables robust cross-domain alignment while mitigating class-missing issues. Experiments on the MMWHS dataset demonstrate state-of-the-art performance for MRI→CT cardiac segmentation with 77.5% Dice score and 5.1 ASD, outperforming existing approaches including SIFAv2 and DSFN.

## Method Summary
The method employs a cycle-GAN inspired architecture with two generators (G_S and G_T) for bidirectional image translation between source and target domains. Each generator contains an encoder, skip-connections, ASPP module, and decoder, with two additional heads: a segmentation head and a projection head. The core innovation lies in using similarity-based prototypes within an embedding space, where class-wise prototypes are computed via masked average pooling of projection features using segmentation predictions.

Training involves multiple loss components: cycle consistency, LSGAN adversarial losses, supervised segmentation loss (source only), class-wise similarity loss (intra-class and inter-class), and contrastive loss via feature dictionaries. Feature dictionaries store prototypes from multiple images, enabling contrastive learning to align prototypes across domains. The method uses a "Mean Top-k" strategy for similarity calculation, averaging the k highest similarity values for robustness. During inference, predictions are averaged from both the target-domain and translated outputs.

## Key Results
- Achieves 77.5% average Dice score and 5.1 ASD on MMWHS MRI→CT cardiac segmentation
- Outperforms state-of-the-art methods: SIFAv2 (74.1%), DSFN (75.8%), EntMin (72.5%)
- Ablation studies show 1.3% Dice improvement from similarity loss and 0.7% from contrastive learning
- Optimal dictionary size found at S=400, with S=200 and S=600 underperforming
- Class-wise results show LVC at 81.7%, RV at 75.3%, and MYO at 64.3% Dice scores

## Why This Works (Mechanism)

### Mechanism 1: Class-wise Similarity Loss for Explicit Feature Alignment
The method uses a class-wise similarity loss L_sim = L_sc + L_dc that explicitly regularizes features to cluster around class prototypes. This creates a structured embedding space where semantic meaning dominates modality-specific appearance through cosine similarity between pixel embeddings and their class prototypes. The intra-class term minimizes feature discrepancy within the same class, while the inter-class term maximizes separation between different class prototypes.

### Mechanism 2: Prototype Contrastive Learning via Feature Dictionaries
Feature dictionaries B_s and B_t store class-wise prototypes from multiple images, enabling contrastive learning to further align prototypes across domains. The contrastive loss pulls same-class prototypes from different samples closer while pushing different-class prototypes apart. The "Mean Top-k" strategy averages the k highest similarity values, providing robustness against noisy prototypes and preventing class-missing problems.

### Mechanism 3: Dual-Module Cycle Structure with Synergistic Image-Feature Alignment
The framework combines image-level translation with feature-level prototype alignment in a unified cycle structure. Two generators G_S and G_T perform bidirectional translation while maintaining semantic structure. Source-domain supervision grounds prototype learning, while target-domain prototypes are computed via high-confidence pseudo-labels. This dual approach provides complementary domain adaptation signals that address both appearance and semantic alignment.

## Foundational Learning

- **Metric Learning and Prototype-based Classification**: Understanding why minimizing intra-class distance while maximizing inter-class distance creates a more transferable representation across domains is essential for grasping the similarity loss mechanism.
- **Contrastive Learning with Memory Banks**: The feature dictionaries function as memory banks storing prototypes across batches. Understanding how contrastive learning leverages negative samples and temperature scaling is critical for the dictionary-based approach.
- **Unsupervised Domain Adaptation Paradigms**: The method combines image-level translation (CycleGAN-style) with feature-level alignment. Distinguishing these paradigms clarifies why both are needed for effective cross-domain adaptation.

## Architecture Onboarding

- **Component map**:
  ```
  Input x_s/x_t → G_S/G_T (Encoder E + Image Generator T + Segmentation Head F + Projection Head P)
               → Outputs: x̂ (translated image), ŷ (segmentation), ẑ (embedding)
               
  ẑ + ŷ → Class-wise Average → Prototypes c → Store in Dictionary B_s/B_t
  
  Training losses:
    - L_cycle: Cycle consistency (x_s→t→s ≈ x_s)
    - L_seg: Supervised segmentation loss (source only)
    - L_img_adv, L_seg_adv: Adversarial alignment
    - L_sim: Similarity loss (intra-class + inter-class)
    - L_cl: Contrastive loss via dictionaries
  ```

- **Critical path**:
  1. Source image x_s passes through G_S → produces ŷ_s (supervised by ground truth), ẑ_s
  2. Compute prototypes c_s via class-wise average of ẑ_s using ŷ_s supervision
  3. Store c_s in B_s, compute L_sim (align ẑ_s to c_s) and L_cl (contrastive with B_s)
  4. Translate x_s→t via G_S, pass through G_T → produces pseudo-supervision for target-side prototype computation
  5. Target image x_t processed similarly without ground truth; high-confidence predictions supervise prototypes

- **Design tradeoffs**:
  - Dictionary size S: Larger = more diversity but slower updates. Paper finds S=400 optimal for MMWHS
  - Top-k vs. Max: Mean Top-k provides robustness; paper uses k=20
  - Temperature τ: Controls contrastive loss sharpness; paper uses τ=1
  - Loss weights: λ_1=0.05 (similarity), λ_2=0.02 (contrastive) — similarity loss weighted higher

- **Failure signatures**:
  - Low Dice with high ASD: Segmentation correct in region but boundaries not smooth
  - Specific classes underperforming: Class-missing problem or insufficient prototype diversity
  - Training instability: Adversarial losses dominating; check discriminator learning rates

- **First 3 experiments**:
  1. Baseline without proposed losses: Disable L_sim and L_cl, train with L_base only. Expected: ~74.5% Dice
  2. Ablation of L_sim only: Enable similarity loss, disable contrastive loss. Expected: ~75.2% Dice
  3. Dictionary size sensitivity: Test S ∈ {200, 400, 600}. Expected: Peak at 400

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed prototype alignment framework be effectively adapted for domain generalization tasks where target domain data is completely unavailable during the training phase? The current framework relies on accessing unlabeled target domain data to compute target prototypes and enforce the cycle consistency and contrastive losses. Successful application to a domain generalization benchmark without modification requiring target data statistics would resolve this question.

### Open Question 2
Can the method be augmented to improve boundary smoothness and Average Surface Distance (ASD) to match or exceed entropy minimization techniques? The authors note that while their Dice score is superior, the average ASD of 5.1 is "slightly worse than EntMin [5]," suggesting the generated results "may be not smooth on the boundary regions." An ablation study incorporating a boundary-aware loss term demonstrating a statistically significant reduction in ASD metrics would resolve this question.

### Open Question 3
Is the method robust across different dataset modalities and adaptation directions, specifically CT→MRI, as opposed to the reported MRI→CT? The authors state, "In the future, we will test our method with different datasets," as the experiments were restricted solely to the MMWHS MRI→CT task. Reporting benchmark results on the CT→MRI task using the MMWHS dataset or applying the method to other cross-modality sets would resolve this question.

## Limitations

- Architectural details remain underspecified (exact ResBlock configurations, ASPP dilation rates, projection head dimensions)
- Confidence threshold for pseudo-label selection not explicitly defined, critical for target-domain prototype quality
- No ablation on discriminator architecture or adversarial loss variants
- Cross-dataset generalization not evaluated

## Confidence

- **High Confidence**: Dice score improvements over baselines (77.5% vs 74.1-75.8%), ablation showing benefit of similarity loss and contrastive learning components, dictionary size optimization (S=400 optimal)
- **Medium Confidence**: Mechanism claims about explicit feature alignment being superior to implicit methods, prototype contrastive learning effectiveness - supported by ablation but limited by architectural underspecification
- **Low Confidence**: Generalizability to other cross-modality tasks beyond MRI→CT cardiac segmentation, robustness to different pseudo-label confidence thresholds

## Next Checks

1. **Architectural Fidelity Test**: Reproduce with exact architectural specifications from [50] (DRANet) to verify whether performance gains persist when structural differences are eliminated
2. **Confidence Threshold Sensitivity**: Systematically vary pseudo-label confidence threshold (0.7→0.95) and measure impact on target-domain prototype quality and final Dice scores
3. **Cross-Modality Transfer**: Apply the method to CT→MRI adaptation or MRI→Ultrasound tasks on MMWHS or other public datasets to assess domain transfer capability beyond the original direction