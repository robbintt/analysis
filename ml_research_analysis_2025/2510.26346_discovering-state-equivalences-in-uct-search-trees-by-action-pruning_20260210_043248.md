---
ver: rpa2
title: Discovering State Equivalences in UCT Search Trees By Action Pruning
arxiv_id: '2510.26346'
source_url: https://arxiv.org/abs/2510.26346
tags:
- state
- abstraction
- abstractions
- which
- asap
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of discovering state equivalences
  in UCT search trees to improve sample efficiency. While state-action pair abstractions
  are relatively easy to find, state abstractions are difficult due to constraining
  conditions, especially in noisy or large action space settings.
---

# Discovering State Equivalences in UCT Search Trees By Action Pruning

## Quick Facts
- arXiv ID: 2510.26346
- Source URL: https://arxiv.org/abs/2510.26346
- Reference count: 40
- Key outcome: IPA-UCT consistently outperforms OGA-UCT across domains with only minor runtime overhead

## Executive Summary
This paper addresses the challenge of discovering state equivalences in UCT search trees to improve sample efficiency. While state-action pair abstractions are relatively easy to find, state abstractions are difficult due to constraining conditions, especially in noisy or large action space settings. The authors propose Ideal Pruning Abstractions in UCT (IPA-UCT), a modification of OGA-UCT that trades minor accuracy for finding many more state abstractions. IPA-UCT uses a novel framework called IPA, which generalizes both ASAP and introduces p-ASAP as a broader abstraction framework. The key innovation is using UCB-based pruning to approximate the set of optimal actions, enabling more state abstractions. Experimental results show IPA-UCT consistently outperforms OGA-UCT and its variants across a wide range of test domains and iteration budgets, with a clear advantage when fine-tuning parameters per task is not feasible. The method has only minor runtime overhead and provides theoretical soundness guarantees.

## Method Summary
IPA-UCT modifies the OGA-UCT framework by introducing UCB-based pruning to approximate the set of optimal actions. The method computes $J_{UCB}(s) = \{a \in A(s) \mid UCB(a) \ge Q_{max}\}$ to identify potentially optimal actions, then groups states if their non-pruned action sets match. This relaxes the strict conditions required for state equivalence, allowing discovery of significantly more state abstractions than standard methods. The approach trades minor accuracy for finding many more abstractions, using aggregate statistics across abstracted nodes to reduce variance in value estimates. IPA-UCT inherits the recency counter mechanism from OGA-UCT to trigger abstraction updates after a node is visited $K=3$ times.

## Key Results
- IPA-UCT consistently outperforms OGA-UCT and its variants across diverse IPPC domains and board games
- Performance gains are most pronounced when fine-tuning parameters per task is not feasible
- Runtime overhead is minimal (5-9%) due to maintaining state recency counts and scanning for abstract matches
- The method successfully identifies state equivalences in domains where OGA-UCT fails, particularly in noisy environments

## Why This Works (Mechanism)

### Mechanism 1
Pruning suboptimal actions relaxes the strict conditions required for state equivalence, allowing the discovery of significantly more state abstractions than standard methods. Standard ASAP frameworks require a bijective match between all actions of two states to abstract them. IPA-UCT approximates the set of optimal actions ($J^*$) using $J_{UCB}$. It then groups states if their non-pruned (potentially optimal) actions match, ignoring clearly suboptimal actions that would otherwise prevent abstraction. Core assumption: The true optimal action(s) are retained within the non-pruned set $J_{UCB}$; pruning does not discard the maximizer. Break condition: If $\lambda_p$ is set too low or visit counts are insufficient, the optimal action may be pruned, leading to "faulty" abstractions that group states with different values.

### Mechanism 2
Upper Confidence Bounds (UCB) serve as a viable proxy for identifying the set of optimal actions required for the pruning mechanism. IPA-UCT calculates $J_{UCB}(s) = \{a \in A(s) \mid UCB(a) \ge Q_{max}\}$. This retains actions whose upper confidence bound overlaps with the best-known value, effectively filtering out actions that are statistically unlikely to be optimal. Core assumption: The UCB value provides a reliable separation between optimal and suboptimal actions given sufficient visits. Break condition: In domains with massive action spaces, visits per action may be too low for UCB to distinguish optimal actions, causing the pruning set $J_{UCB}$ to be unreliable.

### Mechanism 3
Sharing statistics across abstracted nodes reduces variance in value estimates, improving sample efficiency. Once states are grouped via the IPA framework, their visit counts and return sums are aggregated. The tree policy uses these aggregate statistics for UCB calculation, effectively treating distinct states as identical for decision-making. Core assumption: The aggregated states are "value-equivalent" (or near-equivalent), so merging their distributions improves the signal-to-noise ratio rather than introducing bias. Break condition: If non-equivalent states are erroneously grouped (faulty abstraction), the bias introduced into the Q-values degrades performance compared to no abstraction.

## Foundational Learning

- **Concept: UCB (Upper Confidence Bounds)**
  - Why needed here: You cannot understand the pruning mechanism $J_{UCB}$ without grasping how UCB balances exploitation (Q-value) and exploration (sqrt term). The pruning threshold relies on the UCB score, not just the raw Q-value.
  - Quick check question: If an action has a low Q-value but high uncertainty (few visits), will $J_{UCB}$ likely keep or prune it?

- **Concept: MDP Abstraction (State & Action)**
  - Why needed here: The paper builds a hierarchy of frameworks (ASAP $\to$ p-ASAP $\to$ IPA). You need to distinguish between grouping states (merging nodes) vs. state-action pairs (merging edges) to follow the algorithmic modification.
  - Quick check question: In the IPA framework, are two states abstracted if they share some equivalent actions, or all equivalent actions?

- **Concept: OGA-UCT (On-the-Go Abstractions)**
  - Why needed here: IPA-UCT is a modification of OGA-UCT. You must understand the "recency counter" mechanism which triggers the abstraction update checks, as IPA-UCT inherits this update logic.
  - Quick check question: Does OGA-UCT rebuild the entire abstraction tree every iteration, or does it update incrementally?

## Architecture Onboarding

- **Component map:** MCTS Core -> Abstraction Engine -> Pruning Module
- **Critical path:**
  1. **Backup Phase:** Increment `RecencyCount`
  2. **Update Trigger:** When `RecencyCount` exceeds threshold $K$, call `update_state_abstraction`
  3. **Pruning & Matching:** Compute $J_{UCB}$ (Eq. 6), compare non-pruned actions against neighbors to find the largest valid abstract group (Pseudocode 1, Ln 31-43)
  4. **Propagation:** If abstraction changes, parent nodes may need re-evaluation

- **Design tradeoffs:**
  - **$\lambda_p$ (Pruning Constant):**
    - *Low $\lambda_p$ (e.g., 0):* Aggressive pruning. High risk of grouping non-equivalent states (bias), but finds maximum abstractions (low variance). Best for low iteration budgets.
    - *High $\lambda_p$ (e.g., $\infty$):* No pruning. Defaults to standard OGA-UCT behavior (safe but few state abstractions).

- **Failure signatures:**
  - **"No state abstractions found":** Likely $\lambda_p$ is too high, or the domain has zero value-equivalent states (e.g., Sailing Wind)
  - **Performance degradation:** Likely $\lambda_p$ is too low, causing "faulty prunings" where optimal actions are dropped, grouping states with different values
  - **High variance in results:** The domain may have high stochasticity where $\epsilon_t$ thresholds for action abstraction are too tight, preventing the bootstrapping needed for IPA

- **First 3 experiments:**
  1. **Replicate Navigation Grid (Fig 2):** Run IPA-UCT vs. OGA-UCT on the 5x4 grid to visually confirm that IPA detects the 2-4 and 7-9 equivalences that OGA misses
  2. **Ablation on $\lambda_p$:** Run a sweep (0, 0.25, 0.5, 1, 2) on a noisy domain (e.g., Cooperative Recon) to observe the "sweet spot" trade-off between risk and abstraction rate
  3. **Sanity Check vs. Random (RSTATE-OGA):** Ensure IPA-UCT outperforms the random abstraction baseline to verify that the detected equivalences are meaningful and not just overfitting to noise

## Open Questions the Paper Calls Out

### Open Question 1
How can the pruning constant $\lambda_p$ be automatically tuned or adapted online for specific environments? The conclusion explicitly states that finding a single universally effective $\lambda_p$ is impossible and lists automatically detecting the correct value as an avenue for future work. What evidence would resolve it: An adaptive algorithm that dynamically adjusts $\lambda_p$ during search, matching the performance of the best hand-tuned parameters across diverse domains.

### Open Question 2
Can state abstractions be discovered without prerequisite action abstractions to capture symmetry-based equivalences? The authors note in the conclusion that IPA-UCT fails to detect many state abstractions arising from symmetry because it relies on detecting action abstractions, suggesting a "new automatic abstraction paradigm" is required. What evidence would resolve it: A modified abstraction framework capable of identifying symmetric state equivalences directly, improving performance on domains like Game of Life or SysAdmin.

### Open Question 3
Can the abstraction mechanism be generalized to search graphs containing cycles rather than being restricted to directed acyclic graphs (DAGs)? The conclusion lists the restriction to directed acyclic search graphs as a specific limitation of the method. What evidence would resolve it: An extension of the IPA framework that maintains theoretical guarantees (soundness) and performance in MCTS implementations that do not enforce a DAG structure.

## Limitations
- Theoretical soundness guarantees assume perfect identification of optimal actions ($J^*$), which is not achieved in practice with the UCB approximation
- Performance is highly sensitive to the pruning parameter $\lambda_p$, requiring careful tuning that the paper claims to avoid
- Validation focuses on fixed iteration budgets rather than real-time planning scenarios where abstraction overhead might become prohibitive

## Confidence
- **High:** The core mechanism of using UCB-based pruning to identify candidate optimal actions and relax state abstraction conditions is technically sound and well-documented
- **Medium:** Experimental results showing consistent improvement across domains are compelling, but lack of statistical significance testing weakens empirical claims
- **Low:** Theoretical guarantees assume perfect $J^*$ identification, and the paper does not quantify the gap between idealized and practical implementations

## Next Checks
1. **Ablation Study on $\lambda_p$:** Run IPA-UCT with $\lambda_p \in \{0, 0.1, 0.25, 0.5, 1, 2, 4\}$ on a noisy domain (e.g., Cooperative Recon) to empirically determine optimal pruning aggressiveness
2. **Statistical Significance Testing:** Re-run key experiments with 30+ trials per configuration and compute confidence intervals and p-values to verify improvements are statistically significant
3. **Edge Case Verification:** Test IPA-UCT on domains with zero state equivalences (e.g., Sailing Wind) to confirm graceful degradation to OGA-UCT performance without introducing bias