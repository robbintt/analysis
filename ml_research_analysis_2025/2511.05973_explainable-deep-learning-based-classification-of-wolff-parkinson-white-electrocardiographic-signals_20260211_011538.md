---
ver: rpa2
title: Explainable Deep Learning-based Classification of Wolff-Parkinson-White Electrocardiographic
  Signals
arxiv_id: '2511.05973'
source_url: https://arxiv.org/abs/2511.05973
tags:
- regions
- leads
- lead
- localization
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a deep learning model for localizing Wolff-Parkinson-White
  accessory pathways across 24 cardiac regions using 12-lead ECGs. The model is trained
  on a large synthetic dataset generated via a cardiac digital twin, and integrated
  with eXplainable AI techniques (Grad-CAM, Guided Backpropagation, Guided Grad-CAM)
  to interpret predictions.
---

# Explainable Deep Learning-based Classification of Wolff-Parkinson-White Electrocardiographic Signals

## Quick Facts
- arXiv ID: 2511.05973
- Source URL: https://arxiv.org/abs/2511.05973
- Authors: Alice Ragonesi; Stefania Fresca; Karli Gillette; Stefan Kurath-Koller; Gernot Plank; Elena Zappon
- Reference count: 40
- Primary result: 95% accuracy, 94.32% sensitivity, and 99.78% specificity in localizing accessory pathways across 24 cardiac regions using 12-lead ECGs

## Executive Summary
This study presents a deep learning model for localizing Wolff-Parkinson-White accessory pathways across 24 cardiac regions using 12-lead ECGs. The model is trained on a large synthetic dataset generated via a cardiac digital twin, and integrated with eXplainable AI techniques (Grad-CAM, Guided Backpropagation, Guided Grad-CAM) to interpret predictions. The best-performing model achieves 95% accuracy, 94.32% sensitivity, and 99.78% specificity. XAI outputs align with known depolarization patterns, validating physiological plausibility. Lead V2 is identified as most informative for localization, followed by aVF, V1, and aVL. The approach improves spatial resolution over traditional methods and enhances clinical interpretability through explainable predictions.

## Method Summary
The method employs a 2D fully convolutional network trained on 8,842 synthetic 12-lead ECGs generated from a single-subject cardiac digital twin. ECGs are formatted as 200×12×1 tensors representing the QRS complex window (100-300ms). The network architecture consists of three convolutional blocks (Conv→BatchNorm→ReLU) with 128, 192, and 128 filters respectively, using 9×9 kernels with stride 1, followed by global average pooling and a fully connected layer for 24-class output. eXplainable AI is implemented via Guided Grad-CAM, combining Grad-CAM's class-discriminative localization with Guided Backpropagation's high-resolution sensitivity to produce lead-specific saliency maps that highlight diagnostically relevant ECG features.

## Key Results
- 95% classification accuracy, 94.32% sensitivity, and 99.78% specificity across 24 cardiac regions
- XAI outputs align with known depolarization patterns, validating physiological plausibility
- Lead V2 identified as most informative for localization, followed by aVF, V1, and aVL
- Misclassifications concentrated near region boundaries (39/44 errors had true class as second-highest probability)

## Why This Works (Mechanism)

### Mechanism 1: Cardiac Digital Twin Generates Physiologically Grounded Training Data
A personalized virtual heart model simulates accessory pathways at multiple locations using universal ventricular coordinates, generating labeled ECGs with known ground truth. This overcomes the scarcity of clinical WPW data by creating a large, physiologically realistic database from a single subject's cardiac anatomy.

### Mechanism 2: 2D FCN Representation Preserves Lead-Temporal Structure for Feature Extraction
Treating 12-lead ECGs as 2D images (time × leads) with single-channel 2D kernels enables both accurate classification and interpretable saliency maps. Square 2D kernels jointly encode temporal and inter-lead dependencies, allowing the network to learn relationships between leads while maintaining a one-to-one correspondence between saliency map columns and ECG leads.

### Mechanism 3: Guided Grad-CAM Produces Physiologically Aligned Saliency Maps
Guided Grad-CAM combines Grad-CAM's class-discriminative coarse localization with Guided Backpropagation's high-resolution sensitivity, producing saliency maps that preserve both temporal and lead-specific resolution when using 2D input. This allows XAI outputs to highlight ECG regions (delta wave, QRS complex) that correspond to known depolarization patterns.

## Foundational Learning

- **Wolff-Parkinson-White Syndrome and Accessory Pathways**
  - Why needed here: Understanding that APs bypass the AV node and cause pre-excitation (delta wave, shortened PR interval) is essential to interpret why specific ECG features are diagnostically relevant.
  - Quick check question: Can you explain why the delta wave morphology changes depending on AP location?

- **12-Lead ECG Spatial Projections**
  - Why needed here: The model exploits lead-specific information (V2, aVF, aVL, V1); understanding which cardiac regions each lead "views" helps validate XAI outputs.
  - Quick check question: Which leads are most sensitive to right ventricular vs. left ventricular activation changes?

- **Grad-CAM vs. Guided Backpropagation**
  - Why needed here: The paper combines these methods; understanding their individual strengths (coarse localization vs. fine-grained sensitivity) is necessary to interpret saliency outputs.
  - Quick check question: Why does Grad-CAM alone collapse the lead dimension when applied to 1D multi-channel inputs?

## Architecture Onboarding

- **Component map:**
  Input (200×12×1 ECG) → 3 Conv blocks (Conv2D→BatchNorm→ReLU, 128→192→128 filters, 9×9 kernels, stride 1) → Global Average Pooling → Fully Connected (24 classes) → Softmax output

- **Critical path:**
  1. Data formatting as 2D image (T×L×1) is required for lead-specific saliency maps
  2. Stride=1 in all layers preserves input dimensions for direct saliency-to-ECG mapping
  3. XAI analysis performed only on correctly classified test samples

- **Design tradeoffs:**
  - Multi-channel 1D FCN achieved slightly higher accuracy (95.48%) but cannot produce lead-specific saliency maps
  - 2D FCN (95.03%) selected as best overall due to interpretability capability
  - Stacked 1D input (91.98%) performed worst—loses explicit lead structure

- **Failure signatures:**
  - Misclassifications concentrated near region boundaries (39/44 errors had true class as second-highest probability)
  - Reduced sensitivity in mid-ventricular regions (2, 9, 10, 23) due to lower sample density from physiological constraints
  - Saliency maps may reflect inter-lead interactions rather than fully independent lead contributions

- **First 3 experiments:**
  1. Reproduce 2D FCN training on the synthetic dataset; verify ~95% accuracy and compute per-region sensitivity/specificity.
  2. Generate Guided Grad-CAM saliency maps for correctly classified samples; visually confirm alignment with delta wave and QRS complex.
  3. Compute lead importance index across all 24 regions; verify V2, aVF, aVL, V1 ranking matches reported findings.

## Open Questions the Paper Calls Out
- Can the deep learning model trained on single-subject synthetic data generalize to accurately localize accessory pathways in real clinical ECGs?
- Is the high importance of lead V2 identified by XAI a consistent physiological marker or an artifact of the specific subject's heart orientation?
- How does the framework perform when classifying cases with multiple accessory pathways or coexisting structural heart disease?

## Limitations
- Dataset generalization remains unclear since all training data derive from a single-subject cardiac digital twin
- Architectural selection focused on 2D FCN for XAI compatibility rather than optimizing pure classification accuracy
- Physiological plausibility of XAI interpretations relies on visual inspection rather than quantitative metrics

## Confidence
- High confidence in 95% accuracy and 99.78% specificity claims
- Medium confidence in 94.32% sensitivity claim (computed across 24 classes with class imbalance)
- Medium confidence in XAI physiological alignment claims (visual validation but limited quantitative metrics)
- Low confidence in clinical generalization claims (single-subject training data, no external validation)

## Next Checks
1. Test model performance on clinically acquired WPW ECGs from multiple subjects to assess cross-subject generalization
2. Quantify correlation between XAI-highlighted features and known pre-excitation patterns using automated morphological feature detection
3. Perform ablation study comparing 2D vs 1D multi-channel architectures on clinical dataset to determine if XAI benefits outweigh minor accuracy loss