---
ver: rpa2
title: Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English
arxiv_id: '2508.19270'
source_url: https://arxiv.org/abs/2508.19270
tags:
- vietnamese
- english
- phoneme
- recognition
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of cross-lingual phoneme recognition
  between Vietnamese and English, particularly handling tonal Vietnamese and stress-based
  English phonemes in code-switching scenarios. The authors construct a bilingual
  phoneme set that maps English words to Vietnamese syllables, accommodating both
  standard and localized (Vietlish) pronunciations.
---

# Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English

## Quick Facts
- **arXiv ID:** 2508.19270
- **Source URL:** https://arxiv.org/abs/2508.19270
- **Reference count:** 27
- **Primary result:** Achieves PER scores of 16.7% (FOSD), 8.85% (Vivos), 13.02% (CmV), 22.4% (VLSP 2020) on Vietnamese datasets and 7.02%-28.55% on synthetic bilingual datasets

## Executive Summary
This paper addresses cross-lingual phoneme recognition between Vietnamese and English, focusing on the challenge of handling tonal Vietnamese and stress-based English phonemes in code-switching scenarios. The authors construct a bilingual phoneme set that maps English words to Vietnamese syllables, accommodating both standard and localized (Vietlish) pronunciations. They design an end-to-end system using a PhoWhisper pre-trained encoder with a Transformer decoder for phoneme recognition.

The approach demonstrates significant performance improvements over baselines, achieving strong PER scores across multiple Vietnamese datasets and synthetic bilingual datasets. The work is particularly relevant for Vietnamese-English code-switching applications, where traditional monolingual approaches struggle with pronunciation variations and mixed-language content.

## Method Summary
The authors develop a cross-lingual phoneme recognition system that handles both Vietnamese and English by creating a unified bilingual phoneme set. They map English words to Vietnamese syllables to accommodate pronunciation variations, including Vietlish pronunciations. The system uses a PhoWhisper pre-trained encoder combined with a Transformer decoder in an end-to-end architecture. The approach is evaluated on multiple Vietnamese datasets (FOSD, Vivos, CmV, VLSP 2020) and synthetic bilingual datasets created using text-to-speech generation.

## Key Results
- Achieved PER scores of 16.7% (FOSD), 8.85% (Vivos), 13.02% (CmV), and 22.4% (VLSP 2020) on Vietnamese datasets
- Obtained PER scores of 7.02% (IEV), 16.21% (Vietlish), and 28.55% (En native) on synthetic bilingual datasets
- Demonstrated superior performance in handling both tonal and stress-based phoneme recognition in cross-lingual settings
- Outperformed baseline approaches significantly across all test datasets

## Why This Works (Mechanism)
The system works by leveraging a pre-trained PhoWhisper encoder that has learned robust speech representations, combined with a Transformer decoder that can handle the specific characteristics of the bilingual phoneme set. The unified phoneme mapping allows the model to recognize both Vietnamese tonal phonemes and English stress-based phonemes within the same framework, making it particularly effective for code-switching scenarios where speakers alternate between languages.

## Foundational Learning

**Tonal Phonemes (Vietnamese)**
- *Why needed:* Vietnamese uses six distinct tones that change word meaning, requiring precise pitch contour recognition
- *Quick check:* Verify tone recognition accuracy on minimal pairs that differ only in tone

**Stress-based Phonemes (English)**
- *Why needed:* English relies on syllable stress patterns rather than tones for meaning differentiation
- *Quick check:* Test recognition of words with shifting stress patterns (e.g., "record" noun vs verb)

**Code-switching Patterns**
- *Why needed:* Natural speech often involves switching between languages within the same utterance
- *Quick check:* Evaluate performance on alternating language segments within single utterances

**Bilingual Phoneme Mapping**
- *Why needed:* Creates a unified representation space for both languages' phonetic systems
- *Quick check:* Verify that cross-lingual phoneme mappings preserve phonetic distinctions

**Transformer Decoder Architecture**
- *Why needed:* Handles sequential dependencies in phoneme sequences effectively
- *Quick check:* Compare with RNN-based decoder performance on long phoneme sequences

## Architecture Onboarding

**Component Map:**
PhoWhisper Encoder -> Transformer Decoder -> Phoneme Output

**Critical Path:**
Audio input → PhoWhisper feature extraction → Positional encoding → Transformer decoder layers → Phoneme prediction

**Design Tradeoffs:**
- Pre-trained encoder vs from-scratch training (speed vs customization)
- Fixed bilingual phoneme set vs adaptive phoneme discovery
- TTS synthetic data vs natural recordings (control vs realism)

**Failure Signatures:**
- Poor performance on rare phoneme combinations
- Degradation in code-switching boundaries
- Difficulty with speaker accent variations not in training data

**3 First Experiments:**
1. Evaluate on naturally recorded code-switching speech datasets rather than TTS-generated data
2. Conduct human evaluation of Vietnamese phoneme recognition accuracy using standardized criteria
3. Test the approach on additional tonal versus stress-based language pairs

## Open Questions the Paper Calls Out
None

## Limitations
- Results based on synthetic TTS-generated bilingual datasets rather than natural code-switching recordings
- Lack of human evaluation for Vietnamese phoneme recognition accuracy
- Focus limited to Vietnamese-English language pair, limiting generalizability to other tonal-stress language combinations
- PhoWhisper encoder pre-training details not fully specified, making it difficult to assess architecture contributions

## Confidence
- **High:** Internal consistency of results across multiple Vietnamese datasets
- **Medium:** Performance on synthetic bilingual datasets due to lack of natural speech validation
- **Medium:** Vietnamese phoneme recognition accuracy without human linguistic validation

## Next Checks
1. Evaluate the model on naturally recorded code-switching speech datasets rather than TTS-generated data to assess real-world performance
2. Conduct human evaluation of Vietnamese phoneme recognition accuracy using standardized Vietnamese linguistic criteria
3. Test the approach on additional tonal versus stress-based language pairs (e.g., Mandarin-English or Thai-English) to evaluate generalizability