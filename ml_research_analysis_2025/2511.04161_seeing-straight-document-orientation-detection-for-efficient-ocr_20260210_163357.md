---
ver: rpa2
title: 'Seeing Straight: Document Orientation Detection for Efficient OCR'
arxiv_id: '2511.04161'
source_url: https://arxiv.org/abs/2511.04161
tags:
- rotation
- arxiv
- image
- document
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of accurate document orientation
  detection for OCR preprocessing. It introduces OCR-Rotation-Bench (ORB), a new benchmark
  with 1157 rotated images spanning English and 11 Indic languages.
---

# Seeing Straight: Document Orientation Detection for Efficient OCR

## Quick Facts
- arXiv ID: 2511.04161
- Source URL: https://arxiv.org/abs/2511.04161
- Reference count: 40
- Primary result: 96% accuracy on English and 92% on Indic languages for document orientation detection

## Executive Summary
This paper introduces OCR-Rotation-Bench (ORB), a new benchmark for document orientation detection spanning 12 languages, and proposes a lightweight rotation classification pipeline built on the Phi-3.5-Vision encoder. The method achieves high accuracy in detecting document rotation angles and significantly improves downstream OCR performance, particularly for rotated documents. The work addresses a critical preprocessing step in document understanding systems, demonstrating substantial gains when orientation correction is explicitly applied before OCR.

## Method Summary
The authors propose a four-class rotation detection pipeline that uses Phi-3.5-Vision as the backbone encoder with dynamic image cropping to handle variable document layouts. The system classifies document images into one of four rotation categories (0°, 90°, 180°, 270°) and is trained and evaluated on the newly introduced ORB benchmark, which contains 1157 rotated images across English and 11 Indic languages. The approach is designed to be lightweight and efficient for real-world deployment in document processing pipelines.

## Key Results
- 96% accuracy on ORB-En benchmark for English documents
- 92% accuracy on ORB-Indic benchmark for Indic languages
- Up to 4× improvement in OCR performance on open-source systems
- 14% improvement on closed-source OCR models when rotation correction is applied

## Why This Works (Mechanism)
The proposed method works by leveraging a strong vision encoder (Phi-3.5-Vision) that has been pretrained on diverse visual data, allowing it to capture discriminative features for orientation classification. The dynamic image cropping module helps focus the model on relevant document regions, reducing background noise and improving robustness to varying document layouts. The four-class classification approach provides a good balance between granularity and computational efficiency for real-world document processing scenarios.

## Foundational Learning
- Document Orientation Detection: Understanding the problem of identifying and correcting rotated document images before OCR processing. This is needed because OCR systems typically assume upright text, and rotation can significantly degrade recognition accuracy. Quick check: Test the method on documents with various rotation angles to verify classification accuracy.

- Vision Encoders for Document Understanding: Knowledge of how vision models like Phi-3.5-Vision can be adapted for document-specific tasks. This is needed because document images have different characteristics than natural images, requiring specialized feature extraction. Quick check: Compare performance with other vision encoders on the same task.

- OCR Pipeline Integration: Understanding how preprocessing steps like orientation detection integrate into complete OCR workflows. This is needed to evaluate the practical impact of rotation correction on end-to-end document processing. Quick check: Measure OCR accuracy with and without rotation correction on the same document sets.

## Architecture Onboarding

**Component Map:** Document Image -> Dynamic Cropping -> Phi-3.5-Vision Encoder -> Rotation Classification Head -> Orientation Correction

**Critical Path:** The core processing pipeline follows Document Image → Dynamic Cropping → Phi-3.5-Vision → Classification, where each stage is essential for the final output. The dynamic cropping helps reduce irrelevant information, the vision encoder extracts meaningful features, and the classification head produces the rotation prediction.

**Design Tradeoffs:** The choice of a four-class classification (rather than continuous angle prediction) simplifies the problem and reduces computational complexity but may not handle documents with non-standard orientations. The use of Phi-3.5-Vision provides strong performance but introduces dependency on a proprietary model. Dynamic cropping adds robustness but increases processing time slightly.

**Failure Signatures:** The system may struggle with documents containing minimal text, documents with complex layouts where text appears at multiple angles, or documents with very small text that becomes unreadable after rotation correction. Ambiguous cases where text could be read in multiple orientations may also cause misclassification.

**3 First Experiments:**
1. Test rotation detection accuracy on documents with text in different font sizes and styles
2. Evaluate performance degradation when applying rotation correction to already correctly oriented documents
3. Measure inference time and memory usage across different document resolutions

## Open Questions the Paper Calls Out
None

## Limitations
- The ORB benchmark contains only 1157 images, which may limit statistical robustness of the reported performance metrics
- High accuracy improvements on closed-source OCR systems cannot be independently verified due to lack of access to the underlying models
- The method focuses on four discrete rotation angles and may not generalize well to documents with arbitrary or non-standard orientations

## Confidence
- High confidence: Core methodology and ORB benchmark construction
- Medium confidence: Multilingual performance claims, especially for less-resourced Indic languages
- Medium confidence: OCR performance improvement metrics, particularly for closed-source systems

## Next Checks
1. Evaluate the proposed method on larger-scale document datasets to assess statistical robustness of the reported improvements
2. Test the rotation detection pipeline with alternative vision encoders (e.g., open-source CLIP variants) to establish model independence
3. Conduct ablation studies examining the contribution of the dynamic cropping module versus the base Phi-3.5-Vision encoder