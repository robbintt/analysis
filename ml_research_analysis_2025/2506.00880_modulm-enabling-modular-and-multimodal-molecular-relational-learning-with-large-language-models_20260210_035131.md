---
ver: rpa2
title: 'ModuLM: Enabling Modular and Multimodal Molecular Relational Learning with
  Large Language Models'
arxiv_id: '2506.00880'
source_url: https://arxiv.org/abs/2506.00880
tags:
- molecular
- modulm
- learning
- interaction
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ModuLM introduces a modular framework for benchmarking LLM-based
  molecular relational learning, supporting diverse molecular inputs (1D SMILES, 2D
  graphs, 3D conformations), 50+ model configurations, and systematic evaluation.
  On DDI tasks, it achieves AUC-ROC up to 0.982 and accuracy up to 0.964; on SSI tasks,
  MAE as low as 0.340 and RMSE down to 0.601; on CSI tasks, MAE down to 15.42.
---

# ModuLM: Enabling Modular and Multimodal Molecular Relational Learning with Large Language Models

## Quick Facts
- arXiv ID: 2506.00880
- Source URL: https://arxiv.org/abs/2506.00880
- Authors: Zhuo Chen; Yizhen Zheng; Huan Yee Koh; Hongxin Xiang; Linjiang Chen; Wenjie Du; Yang Wang
- Reference count: 40
- One-line primary result: Achieves AUC-ROC up to 0.982 on DDI tasks, MAE as low as 0.340 on SSI tasks

## Executive Summary
ModuLM introduces a modular framework for benchmarking LLM-based molecular relational learning, supporting diverse molecular inputs (1D SMILES, 2D graphs, 3D conformations), 50+ model configurations, and systematic evaluation. On DDI tasks, it achieves AUC-ROC up to 0.982 and accuracy up to 0.964; on SSI tasks, MAE as low as 0.340 and RMSE down to 0.601; on CSI tasks, MAE down to 15.42. The framework enables dynamic model assembly and ablation studies, highlighting the importance of multimodal data and interaction layers over model scale. ModuLM addresses the lack of standardized LLM-MRL benchmarking by providing extensible, reproducible experiments.

## Method Summary
ModuLM is a modular framework for benchmarking LLM-based molecular relational learning that supports three molecular input types (1D SMILES, 2D molecular graphs, and 3D conformations) and 50+ model configurations. The pipeline consists of a modular encoder (Uni-Mol, GIN, etc.) → interaction layer (cross-attention, bilinear fusion, etc.) → alignment layer (MLP or Q-Former) → LLM backbone (DeepSeek, LLaMA, Galactica) → prediction head. Training uses LoRA adapters with AdamW optimizer, cosine decay learning rate schedule, and a 7:2:1 data split. The framework includes incremental pre-training with structure similarity-guided grouping followed by task-specific fine-tuning.

## Key Results
- Achieves state-of-the-art AUC-ROC of 0.982 and accuracy of 0.964 on drug-drug interaction tasks
- Reaches MAE as low as 0.340 and RMSE down to 0.601 on solute-solvent interaction tasks
- Demonstrates MAE of 15.42 on chromophore-solvent interaction tasks
- Shows 3D molecular conformation encoding consistently improves results across all tasks
- Reveals inverse scaling phenomenon where smaller LLM models (1.5B) can outperform larger ones (14B) for molecular tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Incorporating 3D molecular conformations provides spatial geometric constraints that improve prediction accuracy in molecular relational learning (MRL) tasks involving steric interactions.
- **Mechanism:** 1D SMILES strings and 2D graphs often fail to capture the specific 3D orientation (conformation) required for biochemical binding (e.g., drug-target or solvent-solute). By using encoders like Uni-Mol or EGNN (Equivariant Graph Neural Networks), the model captures spatial distances and angles, allowing the LLM to reason over actual binding feasibility rather than just topological connectivity.
- **Core assumption:** The specific downstream task (e.g., DDI, SSI) is dependent on spatial orientation or steric hindrance, rather than purely electronic or topological properties.
- **Evidence anchors:**
  - [abstract] "...3D conformations and interaction layers consistently improving results."
  - [section 4.2] "Notably, models that incorporate 3D molecular conformation information achieve the best results."
  - [corpus] Neighbor paper "3D-GSRD" (arXiv:2510.16780) supports the difficulty and value of extending learning to 3D geometries.
- **Break condition:** If the dataset consists of molecules where 3D geometry is highly flexible or irrelevant to the interaction (e.g., simple ionic interactions in a vacuum), the computational cost of 3D encoding may outweigh performance gains.

### Mechanism 2
- **Claim:** Explicit interaction layers (e.g., Cross-Attention, Bilinear Fusion) extract relational features between molecular pairs more effectively than implicit reasoning within the LLM.
- **Mechanism:** Instead of relying solely on the LLM to infer relationships from concatenated embeddings, explicit interaction layers mathematically fuse the features of two molecules (e.g., via attention weights between substructures) before they reach the LLM. This pre-processes the "relation" so the LLM focuses on semantic inference rather than structural alignment.
- **Core assumption:** The specific interaction (e.g., reaction, binding) is driven by localized substructure interactions that can be captured by attention or bilinear operations.
- **Evidence anchors:**
  - [section 3.3.1] "The Interaction Layer... serves two main functions: capturing... relationships between different molecular entities."
  - [table 7] Ablation study shows "w/o Interaction" results in a drop in Accuracy (e.g., ChChMiner drops from 0.968 to 0.955).
  - [corpus] Neighbor "Representational Alignment..." (arXiv:2502.07027) discusses functional compatibility of binding sites, aligning with the need for substructure interaction modeling.
- **Break condition:** If the relationship between molecules is purely additive or independent (no direct physical interaction), complex interaction layers might overfit to noise.

### Mechanism 3
- **Claim:** "Structure Similarity-guided Grouping" during pre-training aligns the LLM's latent space with chemical structural hierarchies, improving fine-tuning efficiency.
- **Mechanism:** By grouping structurally similar molecules during the incremental pre-training phase, the model learns to associate LLM token embeddings with specific chemical scaffolds and functional groups. This creates a prior knowledge base that generalizes better to unseen molecules than random or purely textual pre-training.
- **Core assumption:** Structural similarity correlates with functional/interaction similarity, a standard QSAR assumption.
- **Evidence anchors:**
  - [section 3.2] "...grouping strategy based on structural similarity... enhancing the LLM's understanding of this class of molecules."
  - [section 4.1] States that experimental backbones were pretrained using this approach.
  - [corpus] Explicit corpus evidence for this specific pre-training mechanism is weak; most neighbors focus on contrastive or multimodal learning rather than similarity-guided grouping specifically.
- **Break condition:** If the fine-tuning dataset contains novel scaffolds (Out-of-Distribution) that do not resemble the groups in the pre-training set, the structural prior may offer limited benefit.

## Foundational Learning

- **Concept:** **Equivariant Graph Neural Networks (EGNNs) / 3D Conformation Encoders**
  - **Why needed here:** ModuLM relies heavily on 3D encoders (e.g., Uni-Mol, PaiNN, EGNN) to handle spatial coordinates. Without understanding rotational equivariance (preserving physics under rotation), one cannot debug why a 3D model fails or succeeds.
  - **Quick check question:** If I rotate a molecule's 3D coordinates, should the predicted interaction energy change? (Answer: No. If your model says yes, it lacks equivariance.)

- **Concept:** **Projection/Alignment Layers (Projector vs. Q-Former)**
  - **Why needed here:** The framework uses MLPs or Q-Formers to map molecular embeddings to the LLM's token space. Understanding this is crucial for diagnosing modality misalignment.
  - **Quick check question:** Does the model use a static linear map (MLP) or a trainable query mechanism (Q-Former) to translate the molecule into "words" for the LLM?

- **Concept:** **LoRA (Low-Rank Adaptation)**
  - **Why needed here:** The paper uses LoRA for efficient fine-tuning of the LLM backbones. Understanding parameter freezing and rank updates is necessary to set up the training configs correctly.
  - **Quick check question:** Which weights are being updated during fine-tuning: the entire LLM, or just the injected low-rank matrices and the projection layers?

## Architecture Onboarding

- **Component map:** Input (SMILES/Graphs/Conformations) → Encoder (Uni-Mol/GIN/...) → Interaction Layer (Cross-Attention/Bilinear) → Alignment (MLP/Q-Former) → LLM Backbone (DeepSeek/LLaMA/Galactica) → Output (Classification/Generation)

- **Critical path:**
  1. Data must be loaded with the `use_3d` flag set correctly in the config to enable 3D conformer generation.
  2. The `graph3d` parameter in the JSON config must match a valid encoder key (e.g., "unimol").
  3. Prompt templates (Table 9 in paper) must be selected (Direct vs. CoT) to match the training mode.

- **Design tradeoffs:**
  - **Uni-Mol vs. GIN:** Uni-Mol offers 3D spatial awareness (high accuracy) but requires conformer generation (slow). GIN is fast (topology only) but may miss steric clash effects.
  - **DeepSeek-1.5B vs. 14B:** The paper notes (Section 4.2) that larger models do not always perform better for MRL tasks due to over-generalization; smaller models may adapt better via fine-tuning.
  - **MLP vs. Q-Former:** Q-Former allows more flexible cross-modal querying but adds significant training complexity and parameters compared to a simple linear MLP projector.

- **Failure signatures:**
  - **"Modality Gap":** The LLM ignores the molecular embedding and hallucinates an answer based only on the text prompt. (Check if the projection layer is trained/frozen correctly).
  - **Conformer Noise:** 3D models performing worse than 2D models, often due to RDKit generating low-quality or unrealistic 3D conformations.
  - **Interaction Dropout:** Performance dropping to baseline levels, indicating the Interaction Layer is bypassed or gradients are not flowing through it.

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Run Experiment 1.1 (Galactica-1.3B, SMILES only) vs. Experiment 1.8 (DeepSeek-1.5B, 3D Uni-Mol) on a DDI dataset to verify the data pipeline and reproduce the "3D > 1D" gain claimed in the paper.
  2. **Ablation of Interaction:** Turn off the `Interaction` layer (set to `Mean` or `None`) and measure the performance drop on the SSI (Solute-Solvent) task to validate the mechanism.
  3. **Backbone Swap:** Keep the encoder (e.g., GIN) fixed and swap backbones (LLaMA vs. DeepSeek) to observe the variance in "task specialization" mentioned in Section 4.2.

## Open Questions the Paper Calls Out

- **Open Question 1:** Why do smaller LLM backbones (e.g., 1.5B parameters) frequently outperform larger models (e.g., 14B parameters) in Molecular Relational Learning tasks?
  - **Basis in paper:** [explicit] The authors observe an "inverse scaling" phenomenon where "larger model sizes do not necessarily lead to better performance," hypothesizing that larger LLMs' strong generalization ability may hinder task-specific adaptation during fine-tuning.
  - **Why unresolved:** The paper identifies the trend and offers a hypothesis regarding task specialization but does not conduct a deep analysis of the optimization dynamics or feature representation shifts that cause this behavior.
  - **Evidence would resolve it:** A comparative analysis of the loss landscapes and feature space geometry of small versus large backbones during the fine-tuning phase on MRL datasets.

- **Open Question 2:** What is the optimal architectural configuration among the 50,000+ possible model combinations supported by ModuLM?
  - **Basis in paper:** [explicit] The authors explicitly state that "a comprehensive exploration of all possible model combinations is beyond the scope of this study and is intended as a key direction for future research."
  - **Why unresolved:** The high dimensionality of the modular search space (encoders, interactions, LLMs) makes a full grid search computationally prohibitive for a single study.
  - **Evidence would resolve it:** The application of Neural Architecture Search (NAS) or Bayesian optimization strategies within the ModuLM framework to identify top-performing configurations across diverse MRL tasks.

- **Open Question 3:** How does the uncertainty or quality of generated 3D molecular conformations affect the robustness of ModuLM's interaction predictions?
  - **Basis in paper:** [inferred] The framework generates 3D conformations using RDKit to feed 3D encoders (like Uni-Mol), but the paper does not analyze how variance in these generated geometries influences the final prediction accuracy.
  - **Why unresolved:** Molecular conformations are probabilistic approximations; the paper treats them as definitive inputs without quantifying the sensitivity of the "Interaction Layers" to structural noise.
  - **Evidence would resolve it:** An ablation study measuring performance variance when using different sets of sampled conformations (e.g., lowest energy vs. random samples) for the same molecular pairs.

## Limitations

- **Conformer Quality Dependency:** Performance improvements from 3D encoding depend on RDKit-generated conformers being chemically valid and representative of bioactive states, with no specified parameters for conformer generation.
- **Pre-training Strategy Verification:** The "Structure Similarity-guided Grouping" pre-training strategy's contribution remains partially unverified without access to pre-trained weights or detailed training curves.
- **Interaction Layer Complexity Trade-off:** The computational overhead versus accuracy gains of explicit interaction layers across different molecular pair complexities is not systematically explored.

## Confidence

**High Confidence** (Strong evidence, clear mechanism):
- The modular architecture design enabling systematic ablation studies
- The superiority of 3D molecular encoding over 1D/2D representations for tasks requiring spatial reasoning
- The effectiveness of explicit interaction layers over implicit LLM reasoning

**Medium Confidence** (Reasonable evidence but with assumptions):
- The specific performance metrics achieved (0.982 AUC-ROC, 0.340 MAE) without independent reproduction
- The claim that smaller LLM models (1.5B) can outperform larger ones (14B) for molecular tasks
- The structural similarity-guided pre-training strategy's contribution to fine-tuning efficiency

**Low Confidence** (Limited verification possible from provided information):
- The generalizability of results to novel molecular scaffolds not present in pre-training data
- The robustness of 3D conformer generation across diverse chemical spaces
- The computational efficiency claims relative to existing molecular ML methods

## Next Checks

1. **Conformer Quality Control Experiment:** Run the same 3D encoding experiments (Exp 1.8) with varying conformer generation parameters (e.g., 10 vs. 100 conformers per molecule, different energy thresholds) to establish the sensitivity of performance to conformer quality and determine if improvements are robust to conformer noise.

2. **Out-of-Distribution Generalization Test:** Evaluate the best-performing ModuLM configuration on a held-out test set containing molecular scaffolds not present in any training or validation data to verify the structural similarity-guided pre-training actually enables generalization rather than memorization.

3. **Interaction Layer Complexity Analysis:** Systematically vary the size and complexity of the interaction layer (e.g., linear vs. bilinear vs. attention-based) across different molecular pair complexities and measure both accuracy and computational overhead to establish when explicit interaction layers are justified versus simpler approaches.