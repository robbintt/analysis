---
ver: rpa2
title: Design Principles for Sequence Models via Coefficient Dynamics
arxiv_id: '2510.09389'
source_url: https://arxiv.org/abs/2510.09389
tags:
- linear
- coefficients
- attention
- principle
- readout
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops a unifying framework for sequence models based
  on the observation that most architectures compute outputs as linear combinations
  of past value vectors, with coefficients produced by autonomous linear dynamical
  systems driven by impulse inputs from the keys. The framework captures softmax attention,
  linear attention, state space models, and various gated architectures as special
  cases, providing a common mathematical language for comparing them.
---

# Design Principles for Sequence Models via Coefficient Dynamics

## Quick Facts
- arXiv ID: 2510.09389
- Source URL: https://arxiv.org/abs/2510.09389
- Reference count: 40
- Primary result: Framework unifies sequence models through coefficient dynamics, deriving six design principles linking architectural choices to model properties

## Executive Summary
This paper presents a unifying mathematical framework for sequence models based on the observation that most architectures compute outputs as linear combinations of past value vectors, with coefficients produced by autonomous linear dynamical systems driven by impulse inputs from the keys. The framework captures softmax attention, linear attention, state space models, and various gated architectures as special cases, providing a common language for comparing them. Six design principles are derived that link architectural choices to model properties including efficiency, input selectivity, positional information encoding, and training stability. Experimental validation on MAD benchmark tasks demonstrates these principles in practice, showing that kernel approximations of softmax attention hinder input selectivity, that non-identity evolution matrices can replace positional embeddings, and that proper scaling ensures training stability.

## Method Summary
The method develops a general framework where sequence models are expressed as linear combinations of value vectors with coefficients $\alpha_{i,j}$ generated by autonomous linear dynamical systems. For each key position $j$, a latent state $h_{i,j}$ evolves according to $h_{i,j} = A_i h_{i-1,j} + b_i u_i$, where the input $u_i$ is the key $k_j$ (impulse) at time $j$. The attention coefficient is computed as $\alpha_{i,j} = \phi(q_i^T h_{i,j})$, where $\phi$ is a readout map. This framework unifies diverse architectures by varying the parameters $A, b, \phi, \eta$. The six design principles are validated through controlled experiments on the MAD benchmark (Fuzzy In-context Recall, Selective Copying, Noisy Recall) and Wikitext-103, using 2-layer models with embedding dimension 128, 16 heads, and interleaved SwiGLU MLPs.

## Key Results
- Demonstrates that linear readout maps enable efficient $O(L)$ implementation while nonlinear maps provide better input selectivity
- Shows that evolution matrices beyond identity embed positional information, potentially eliminating need for positional embeddings
- Proves that scaling parameters must be $O(1/\sqrt{n})$ for training stability in unbounded readout maps or unstable dynamics
- Validates that kernel approximations of softmax attention hinder input selectivity compared to exact softmax
- Establishes that normalization factors must counteract coefficient growth when using unbounded readout maps or unstable dynamics

## Why This Works (Mechanism)

### Mechanism 1: Coefficient Dynamics via Impulse Response
- Claim: Sequence models function by computing output coefficients $\alpha_{i,j}$ as outputs of linear dynamical systems initialized with impulse inputs (the keys)
- Mechanism: Each key position $j$ drives an autonomous system $h_{i,j} = A_i h_{i-1,j} + b_i u_i$ with impulse input $u_i = k_j$ at $t=j$, and output $\alpha_{i,j} = \phi(q_i^T h_{i,j})$
- Core assumption: Sequence mixing is fundamentally a linear combination of values with data-dependent coefficients
- Evidence anchors: [abstract] defines framework; [Section 3] Eq (3a-c) formalize dynamics; [corpus] [111033] discusses RNN training alignment
- Break condition: If attention coefficients cannot be modeled as linear combinations of transformed keys

### Mechanism 2: The Readout Trade-off (Efficiency vs. Selectivity)
- Claim: Choice of readout map $\phi$ creates trade-off between computational efficiency and input selectivity
- Mechanism: Linear $\phi$ enables recursive $O(L)$ computation; nonlinear $\phi$ (softmax) prevents this but provides better suppression of irrelevant tokens through larger zero-level sets
- Core assumption: Gradient descent finds solutions more easily when suppression behavior corresponds to large regions of parameter space
- Evidence anchors: [abstract] states trade-off; [Section 4.1] Principle 1 & 2 with Lemma 1 & 2; [corpus] [96093] discusses linear RNN limits
- Break condition: If efficient algorithms are developed for specific nonlinear $\phi$, or if linear $\phi$ provides sufficient selectivity via gating

### Mechanism 3: Evolution Matrices for Positional Information
- Claim: Positional information is inherently linked to structure of evolution matrix $A_t$
- Mechanism: $A_t = I$ yields position-agnostic evolution requiring explicit positional embeddings; $A_t \neq I$ (e.g., diagonal decay) encodes temporal gap $i-j$ in key transformation
- Core assumption: Evolution matrix encodes time-dependent transformations of the key
- Evidence anchors: [abstract] states positional embedding role; [Section 4.2] Principle 3 & Lemma 3; [corpus] [110376] analyzes SSM vs Transformer information flow
- Break condition: If keys already contain positional information (e.g., via convolutions)

## Foundational Learning

**Linear Dynamical Systems**
- Why needed: Core mathematical lens - must understand state evolution $h_{t+1} = A h_t + B u_t$ to grasp coefficient generation
- Quick check: How does the system respond if the input is an impulse (non-zero at one time step)?

**Zero-Level Sets (Geometry)**
- Why needed: Critical for Principle 2 - understanding why certain activation functions allow easier input suppression
- Quick check: Why is it easier to set $\alpha=0$ with ReLU ($\phi(x)=0$ for $x<0$) than with Identity ($\phi(x)=0$ only if $x=0$)?

**Computational Complexity (Recurrent vs. Parallel)**
- Why needed: Essential for Principle 1 - understanding why linear readout enables parallel scans vs quadratic softmax attention
- Quick check: Can you compute $\sum_{j=1}^i x_j$ recursively? What if it were $\sum_{j=1}^i \exp(x_j)$?

## Architecture Onboarding

**Component map:** Inputs -> Projections ($W_Q, W_K, W_V$) -> Dynamics: $K$ as impulse into system ($A_t$, $b_t$) -> Readout: $Q$ dot-product with $H$ through $\phi$ -> Normalization: $\eta_i$ stabilizes outputs -> Output: Linear combination of $V$ using coefficients $\alpha/\eta$

**Critical path:** Choice of $\phi$ (Readout) and $A_t$ (Evolution) determines model class (Softmax Attn vs. SSM vs. Linear Attn)

**Design tradeoffs:**
- Efficiency vs. Selectivity: Use Linear $\phi$ (Identity) for speed (SSMs), or Nonlinear $\phi$ (Softmax) for recall/selectivity (Transformers)
- Stability: Scaling $b_j$ must be $O(1/\sqrt{n})$. If $\phi$ is unbounded (Exp) or $A_t$ is unstable, $\eta_i$ must grow to counteract it

**Failure signatures:**
- Exploding outputs/Variance: Check scaling $b_j$ (Principle 5) or Normalization $\eta_i$ (Principle 6)
- Poor Recall with Linear Models: Check if $\phi$ allows robust suppression (Principle 2) or if $A_t$ allows sufficient state complexity
- Need for Positional Embeddings in RNNs: Check if $A_t$ is Identity (Principle 3)

**First 3 experiments:**
1. Validate Scaling (Principle 5): Train with $b_j = 1$ vs $b_j = 1/\sqrt{n}$ on synthetic recall task; expect instability with incorrect scaling
2. Ablate Readout Maps (Principle 2): Compare Softmax, ReLU, Identity on "Selective Copying" task; measure fraction of near-zero coefficients
3. Test Positional Encoding (Principle 3): Run "Noisy In-Context Recall" with $A_t=I$ (needs PE) vs $A_t=\lambda I$ (no PE needed); validate non-identity $A$ replaces PE

## Open Questions the Paper Calls Out
None

## Limitations
- Framework's generality rests on assumption that all sequence models can be expressed as linear combinations of value vectors with coefficients from linear dynamical systems
- Paper doesn't fully address empirical difficulty of learning complex state evolution matrices compared to simpler alternatives
- Analysis assumes idealized conditions without numerical constraints that affect real-world implementations

## Confidence

**High Confidence:**
- Mathematical framework correctly captures known architectures as special cases
- Efficiency-selectivity trade-off for readout maps is well-supported by theory and experiments
- Scaling requirement of $O(1/\sqrt{n})$ for training stability is empirically validated

**Medium Confidence:**
- Non-identity evolution matrices inherently embed positional information relies on specific key structure assumptions
- Evolution matrix structure fundamentally limits key transformations is mathematically proven but may have practical workarounds

**Low Confidence:**
- Specific normalization factor requirements for unbounded readout maps or unstable dynamics lack precise theoretical characterization
- Practical advantage of replacing positional embeddings with structured evolution matrices in real architectures

## Next Checks

1. **Optimization Difficulty of Complex Evolution Matrices**: Systematically compare training curves and final performance when using identity vs non-identity evolution matrices on standard benchmarks, controlling for initialization and optimization hyperparameters. Measure both convergence speed and final accuracy.

2. **Scaling Sensitivity Analysis**: Conduct thorough investigation of the $O(1/\sqrt{n})$ scaling requirement by testing wider range of scaling factors (both smaller and larger) on multiple tasks. Include synthetic experiments isolating effect of scaling on training stability vs model capacity.

3. **Multi-Head Extension Validation**: Extend theoretical analysis to explicitly handle multi-head attention, deriving how coefficient dynamics framework applies when multiple independent attention mechanisms are combined. Validate experimentally that design principles hold when aggregating across heads.