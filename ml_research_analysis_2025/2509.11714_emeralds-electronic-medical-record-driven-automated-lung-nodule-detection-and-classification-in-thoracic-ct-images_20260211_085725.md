---
ver: rpa2
title: 'EMeRALDS: Electronic Medical Record Driven Automated Lung Nodule Detection
  and Classification in Thoracic CT Images'
arxiv_id: '2509.11714'
source_url: https://arxiv.org/abs/2509.11714
tags:
- lung
- nodule
- features
- medical
- nodules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces EMeRALDS, an end-to-end computer-aided diagnosis
  (CAD) system that integrates lung nodule detection (CADe) and classification (CADx)
  for early lung cancer screening in thoracic CT images. The system uses Segment Anything
  Model 2 (SAM2) with text prompts encoded by CLIP for automated, zero-shot nodule
  segmentation, achieving a Dice score of 0.92 and IoU of 0.85 in 2D analysis.
---

# EMeRALDS: Electronic Medical Record Driven Automated Lung Nodule Detection and Classification in Thoracic CT Images

## Quick Facts
- arXiv ID: 2509.11714
- Source URL: https://arxiv.org/abs/2509.11714
- Reference count: 0
- Primary result: End-to-end CAD system for lung nodule detection and classification with 0.94 accuracy

## Executive Summary
EMeRALDS presents an integrated computer-aided diagnosis system combining lung nodule detection (CADe) and classification (CADx) for early lung cancer screening. The system leverages zero-shot learning through Segment Anything Model 2 (SAM2) with CLIP-based text prompts for automated nodule segmentation, achieving high performance metrics. By incorporating radiomic features and synthetic electronic medical records into the classification pipeline, EMeRALDS demonstrates improved diagnostic accuracy compared to existing methods. The system shows promise for scalable, automated lung cancer screening in clinical workflows.

## Method Summary
EMeRALDS employs a dual-phase approach for lung nodule analysis. The detection phase uses SAM2 with CLIP-encoded text prompts for zero-shot segmentation of lung nodules in CT images, achieving Dice score of 0.92 and IoU of 0.85. The classification phase extracts nodule patches combined with radiomic features and synthetic EMR data, processing them through a CLIP-based architecture to predict malignancy. This integration of clinical context data with imaging features enables comprehensive analysis for early cancer detection.

## Key Results
- Segmentation performance: Dice score of 0.92 and IoU of 0.85 in 2D analysis
- Classification accuracy: Specificity of 0.97 and overall accuracy of 0.94
- Outperformed state-of-the-art methods in comparative analysis

## Why This Works (Mechanism)
The system's effectiveness stems from the integration of advanced vision-language models with radiomic and clinical data. Zero-shot learning through SAM2 and CLIP eliminates the need for extensive labeled training data while maintaining high segmentation accuracy. The combination of imaging features with synthetic EMR data provides a more comprehensive representation of patient risk factors, enhancing classification performance beyond what imaging alone can achieve.

## Foundational Learning
- Zero-shot learning: Enables model adaptation to new tasks without task-specific training, crucial for handling diverse nodule presentations without extensive labeled datasets
- CLIP architecture: Bridges vision and language domains, allowing text prompts to guide segmentation and feature extraction
- Radiomic feature extraction: Quantifies imaging characteristics beyond visual assessment, providing quantitative descriptors for malignancy prediction
- Synthetic data generation: Augments limited clinical datasets while preserving privacy, though clinical relevance requires validation
- Vision transformer architectures: Process CT images as sequences of patches, enabling integration with language models for multimodal analysis

## Architecture Onboarding

Component map: CT image -> SAM2 + CLIP text prompts -> Nodule segmentation -> Feature extraction -> Radiomic + Synthetic EMR -> CLIP classifier -> Malignancy prediction

Critical path: The integration of SAM2 segmentation with CLIP-based classification represents the system's core innovation, enabling end-to-end analysis without intermediate manual steps.

Design tradeoffs: Zero-shot learning reduces dependency on labeled data but may struggle with highly heterogeneous presentations; synthetic EMR integration enhances clinical context but requires validation of real-world applicability.

Failure signatures: Poor segmentation quality in heterogeneous nodule presentations, misclassification due to insufficient clinical context representation, performance degradation with varying CT acquisition protocols.

First experiments:
1. Evaluate segmentation performance across varying nodule sizes and densities
2. Test classification accuracy with different synthetic EMR generation parameters
3. Assess computational efficiency and inference time for clinical deployment

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- Lack of validation on diverse external datasets limits generalizability claims
- High performance metrics require independent verification on multi-institutional data
- Computational efficiency and scalability for clinical deployment not demonstrated

## Confidence

| Claim Cluster | Confidence |
|---|---|
| CADe/CADx integration effectiveness | Medium |
| Zero-shot segmentation performance | Medium |
| Classification accuracy claims | Medium |
| Clinical workflow integration potential | Low |

## Next Checks

1. External validation on multi-institutional, multi-scanner datasets with varying acquisition protocols and patient demographics
2. Prospective clinical trial comparing EMeRALDS performance against radiologist interpretation in actual screening workflows
3. Analysis of model behavior and performance degradation across different CT dose levels and reconstruction algorithms