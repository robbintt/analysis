---
ver: rpa2
title: 'AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative Contracts'
arxiv_id: '2506.01063'
source_url: https://arxiv.org/abs/2506.01063
tags:
- contract
- schema
- contracts
- structured
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents CDMizer, a template-driven LLM and RAG-based
  framework for converting unstructured OTC financial derivative contracts into structured
  Common Domain Model (CDM) representations. The method uses depth-based retrieval
  and hierarchical generation to ensure syntactic correctness and schema adherence
  while preserving hierarchical and contextual relationships.
---

# AI4Contracts: LLM & RAG-Powered Encoding of Financial Derivative Contracts

## Quick Facts
- **arXiv ID**: 2506.01063
- **Source URL**: https://arxiv.org/abs/2506.01063
- **Reference count**: 5
- **Primary result**: Template-driven LLM+RAG framework achieves 100% syntactic correctness and 91.40% semantic coverage for converting unstructured financial contracts to CDM

## Executive Summary
This paper introduces CDMizer, a framework that transforms unstructured OTC financial derivative contracts into structured Common Domain Model (CDM) representations using a template-driven approach with LLM and RAG components. The method addresses the challenge of maintaining syntactic correctness and schema adherence while preserving semantic relationships in hierarchical contract data. Experiments on 30 synthetic contracts demonstrate significant improvements over baseline methods, achieving perfect schema adherence and substantially higher semantic coverage scores.

## Method Summary
CDMizer uses a template-driven approach where it first parses the CDM JSON schema and existing examples to create minimal templates by pruning irrelevant fields. The framework then recursively traverses these templates using a depth threshold (d=4) to break complex objects into manageable sub-trees, prompting an LLM to populate each section. RAG is employed to retrieve structurally similar CDM examples before each LLM prompt, providing contextual guidance. The populated fragments are validated against the CDM schema and merged back into the template structure. An LLM-powered evaluation framework assesses completeness and accuracy of the generated CDM representations.

## Key Results
- CDMizer achieves 100% syntactical correctness and schema adherence across all contract types
- Semantic coverage scores: 91.40% with RAG vs 89.40% without RAG on average
- Outperforms baseline methods with <65% syntactical correctness and 88.2% schema adherence
- Template-enforced constraints prevent token overflows and ensure structural compliance

## Why This Works (Mechanism)

### Mechanism 1: Schema-Constrained Template Scaffolding
If generation is restricted to filling pre-validated schemas rather than generating structure and content simultaneously, syntactic correctness and adherence approach 100%. The system parses the CDM JSON schema and existing examples to prune irrelevant fields, creating a minimal "template" that acts as a deterministic scaffold. The LLM populates placeholders within this rigid structure rather than generating the JSON hierarchy itself. Core assumption: required output fields can be determined a priori from existing examples. Evidence: 100% Syntactical Correctness and Schema Adherence in Table 1.

### Mechanism 2: Depth-Bounded Hierarchical Decomposition
If complex objects are decomposed into sub-trees based on a depth threshold (d), semantic extraction accuracy improves by reducing cognitive load and token overflow risks. The system recursively traverses the JSON template, pausing traversal when encountering sub-structures where the deepest subtree is â‰¤ d to prompt the LLM. This isolates the LLM's focus to small, manageable logic blocks rather than the entire contract. Core assumption: LLMs perform better on localized, well-defined sub-tasks. Evidence: Optimal performance at d=4 validated in Section 7.2.

### Mechanism 3: RAG-Guided Semantic Alignment
If retrieval-augmented generation (RAG) is used to inject structurally similar CDM examples into the prompt, semantic coverage improves compared to relying solely on the LLM's parametric knowledge. Before populating a template section, a query retrieves relevant chunks from a knowledge base of CDM examples, providing the LLM with "ground truth" patterns for specific field values. Core assumption: the vector store contains high-quality examples structurally resembling the target contract segment. Evidence: 91.40% vs 89.40% semantic coverage with vs without RAG.

## Foundational Learning

- **JSON Schema & Validation**: Why needed - CDMizer relies on the difference between syntactic correctness (valid JSON) and schema adherence (valid CDM). Quick check: Can you explain why a JSON file might be syntactically correct but fail schema adherence?

- **Recursive Tree Traversal**: Why needed - The population algorithm is a depth-first traversal. Understanding how the algorithm dives into nested objects and backtracks is essential for debugging the population logic. Quick check: How does the algorithm decide when to stop diving deeper and trigger an LLM prompt?

- **Parameter-Efficient Fine-Tuning (PEFT) vs. RAG**: Why needed - The paper contrasts fine-tuning (Baseline) with template+RAG approach. Understanding token limits and "rigid mimicking" behaviors of fine-tuning explains why the architectural shift was necessary. Quick check: Why did fine-tuning result in "metadata-heavy" CDMs that lacked essential contract details?

## Architecture Onboarding

- **Component map**: Schema Parser -> Template Creator -> Traversal Engine -> RAG Interface -> LLM Worker -> Validator
- **Critical path**: Template Creation is the constraint. If pruning removes a necessary field not in example set, no amount of LLM prompting can recover it later.
- **Design tradeoffs**: Determinism vs. Flexibility (template guarantees structure but limits LLM to known fields); Context Window vs. Precision (higher d gives more context but increases hallucination risk).
- **Failure signatures**: Empty Fields (LLM returns null/placeholders due to irrelevant RAG context); Extraneous Info (LLM hallucinates fields not in template); Schema Drift (baseline models generating CDM-invalid keys).
- **First 3 experiments**: 1) Vary Depth (d=2,3,4,5) on Interest Rate Swap to observe inflection point; 2) Ablate RAG to measure delta in "Uncaptured Information" for legal clauses; 3) Noise Test by polluting RAG knowledge base with irrelevant contract types.

## Open Questions the Paper Calls Out

- **Robust evaluation methods**: Developing more robust evaluation methods beyond LLM-based validation. Unresolved because current framework relies on LLMs evaluating themselves, producing inconsistent scores. Evidence: Creation and validation of a non-LLM benchmark or human-annotated ground truth dataset would resolve this.

- **Real-world generalization**: Extending framework to handle nuanced language and implicit cross-references in actual OTC contracts. Unresolved because experiments rely on synthetic contracts lacking real-world complexity. Evidence: Performance metrics from processing actual, non-synthetic OTC derivative contracts would resolve this.

- **Executable smart contracts**: Converting generated CDM representations into executable smart contracts for automated validation and enforceability. Unresolved because paper focuses only on data structuring, not code generation. Evidence: A functional pipeline translating CDM JSON to deployed smart contract code would resolve this.

## Limitations

- Performance claims based on synthetic contracts rather than real-world documents, potentially underestimating complexity and variability
- RAG effectiveness heavily dependent on quality and representativeness of CDM example corpus
- Semantic coverage metric relies on LLM-based evaluation introducing potential subjectivity and inconsistency

## Confidence

- **High confidence**: Schema-constrained template scaffolding - deterministic nature and 100% syntactical correctness results provide strong empirical support
- **Medium confidence**: Depth-bounded hierarchical decomposition - supported by ablation testing showing optimal performance at d=4, but theoretical justification could be stronger
- **Medium confidence**: RAG-guided semantic alignment - shows measurable improvement but performance degrades with noisy retrievals, suggesting brittleness

## Next Checks

1. Test CDMizer on real-world OTC contracts from multiple financial institutions to validate synthetic-to-real generalization gap
2. Conduct ablation studies on the RAG retrieval component by systematically varying quality and relevance of retrieved examples to establish robustness thresholds
3. Perform cross-validation with human experts to establish ground truth for semantic coverage metrics and validate LLM-based evaluation framework