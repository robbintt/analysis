---
ver: rpa2
title: 'Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box
  Predictions under Convex Losses'
arxiv_id: '2511.18789'
source_url: https://arxiv.org/abs/2511.18789
tags:
- wild
- lemma
- have
- refitting
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a doubly wild refitting method to evaluate\
  \ excess risk in high-dimensional empirical risk minimization (ERM) with general\
  \ convex losses. The method works by constructing two sets of artificially perturbed\
  \ outcomes\u2014wild responses\u2014by adding carefully scaled noise to gradient\
  \ vectors of the loss function."
---

# Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses

## Quick Facts
- arXiv ID: 2511.18789
- Source URL: https://arxiv.org/abs/2511.18789
- Authors: Haichen Hu; David Simchi-Levi
- Reference count: 40
- Key outcome: Introduces doubly wild refitting method to evaluate excess risk in high-dimensional ERM with general convex losses, handling non-symmetric noise and model-free settings without requiring function class complexity.

## Executive Summary
This paper addresses the challenge of evaluating excess risk for black-box machine learning models trained via empirical risk minimization under general convex losses. The key innovation is a doubly wild refitting method that constructs two sets of artificially perturbed outcomes by adding carefully scaled noise to gradient vectors of the loss function. The model is retrained twice on these perturbed datasets to obtain two wild predictors. This approach provides a data-driven upper bound on excess risk without requiring knowledge of function class complexity, making it particularly valuable for evaluating opaque machine learning systems like deep neural networks and generative models.

## Method Summary
The method works by computing gradients ∇₁ℓ(f̂(xᵢ), yᵢ) at each data point for a trained predictor f̂, then constructing "wild responses" yᵢ^⋄ and yᵢ^♯ such that their gradients satisfy ∇₁ℓ(f̂(xᵢ), yᵢ^⋄) = ∇₁ℓ(f̂(xᵢ), yᵢ) - 2ρ₁εᵢg̃ᵢ. Two separate refitting steps are performed on these perturbed datasets, yielding wild predictors f^⋄_{ρ₁} and f^♯_{ρ₂}. The wild optimism terms Opt^⋄ and Opt^♯ are then computed and used to bound the empirical process, providing a computable upper bound on excess risk. The approach handles non-symmetric noise distributions and general convex losses, extending prior work limited to symmetric noise and scalar outputs.

## Key Results
- Provides first model-free excess risk evaluation method for high-dimensional ERM under general convex losses with non-symmetric noise
- Theoretical guarantee: High-probability upper bound on excess risk via Theorem 5.2 using wild optimism terms and pilot error bounds
- Extends wild refitting beyond symmetric noise assumption, handling arbitrary Rademacher perturbations

## Why This Works (Mechanism)

### Mechanism 1
- Perturbing gradient vectors (rather than predictions directly) enables model-free excess risk bounds under general convex losses
- Core assumption: Loss function ℓ(z,y) is β-smooth, μ-strongly convex in z, with -∇₁ℓ(z,y) continuous, coercive, and monotone in y
- Evidence: Section 4 explains gradient perturbation preserves local geometry while enabling non-asymptotic empirical process bounds
- Break condition: Fails if loss lacks monotonicity or coercivity properties required for resolvent computation

### Mechanism 2
- Two separate refitting steps (doubly wild) are necessary and sufficient to handle non-symmetric noise distributions
- Core assumption: Gradient noise ∇₁ℓ(f*(x), y) is conditionally zero-mean and σ²-sub-Gaussian along all directions
- Evidence: Abstract states method perturbs gradient vectors with carefully chosen scaling; section 4 contrasts with single-refitting methods limited to symmetric noise
- Break condition: Fails under highly heavy-tailed noise violating sub-Gaussian assumption

### Mechanism 3
- Wild optimism terms provide computable, data-driven upper bounds on true optimism without requiring function class complexity measures
- Core assumption: Fixed-design setting with well-specified model (f* ∈ F) for radius estimation
- Evidence: Section 5.1 proves empirical process can be bounded by computable wild optimism terms from Algorithm 1 outputs
- Break condition: Theorem 5.2 requires known radius r ≥ r̂ₙ = ||f̂ - f†||ₙ; radius estimation procedure in Theorem 5.3 needed if unknown

## Foundational Learning

**Bregman divergence and convex loss decomposition**
- Why needed: Proof of Proposition 3.8 decomposes excess risk using Bregman divergence D_ℓ(·, yᵢ), connecting population risk to empirical excess risk plus true optimism
- Quick check: Given β-smooth, μ-strongly convex loss ℓ, can you write the Bregman-based decomposition of ℓ(f̂(x), y) around point f*(x)?

**Sub-Gaussian random vectors and directional concentration**
- Why needed: Assumption 3.6 requires gradient noise to be σ²-sub-Gaussian along all directions; Lemmas A.4 and A.7 provide concentration bounds
- Quick check: If d-dimensional random vector X is σ²-sub-Gaussian along every direction, what is high-probability bound on max_{i≤n} ||Xᵢ||₂?

**Empirical processes and Rademacher symmetrization**
- Why needed: Core technical challenge is bounding empirical processes Wₙ(r), Tₙ(r), Zₙ^ε(r) without knowing function class complexity
- Quick check: Why does introducing Rademacher variables {εᵢ} in Lemma D.2 help bound expected supremum of empirical process?

## Architecture Onboarding

Training Dataset D₀ → [ERM Algorithm A] → Original predictor f̂ → Compute gradients g̃ᵢ = ∇₁ℓ(f̂(xᵢ), yᵢ) → Generate Rademacher sequence {εᵢ} → Perturbation -2ρ₁εᵢg̃ᵢ and +2ρ₂εᵢg̃ᵢ → Wild responses {yᵢ^⋄} and {yᵢ^♯} → Dataset D^⋄ = {(xᵢ, yᵢ^⋄)} and D^♯ = {(xᵢ, yᵢ^♯)} → [ERM Algorithm A] → Wild predictor f^⋄_{ρ₁} and f^♯_{ρ₂} → Compute Opt^⋄, Opt^♯, ||f^⋄ - f̂||ₙ, ||f^♯ - f̂||ₙ → Excess risk bound (Theorem 5.2)

Critical path: (1) Compute gradients at all n points; (2) Solve for wild responses via resolvent of monotone operator; (3) Refit model twice; (4) Compute wild optimism terms and apply Theorem 5.2 bound

Design tradeoffs:
- Noise scales ρ₁, ρ₂: Larger scales increase perturbation magnitude, potentially destabilizing refitted predictors
- Computational cost: Requires 3× model training (original + 2 refits), potentially prohibitive for large neural networks
- Fixed vs. random design: Current theory covers fixed-design only; random-design extension is future work

Failure signatures:
- Pilot error dominance: If Bₙ^⋄(f̂) or Bₙ^♯(f̂) terms dominate wild optimism, bound becomes loose
- Radius estimation failure: If ||f^⋄_{ρ₁} - f̂||ₙ or ||f^♯_{ρ₂} - f̂||ₙ grow unboundedly as ρ varies, well-specification assumption violated
- Resolvent computation non-convergence: PPA may fail if loss monotonicity is violated or numerical precision insufficient

First 3 experiments:
1. **Synthetic validation with known excess risk**: Generate data from known distribution with oracle access to f*, train simple model, apply Algorithm 1, verify Theorem 5.2 bound empirically across multiple random seeds
2. **Noise scale sensitivity analysis**: Sweep ρ₁ = ρ₂ over [0.1, 1.0, 10.0], plot wild optimism values, pilot error estimates, final excess risk bound to identify optimal ρ
3. **Deep network stress test**: Apply method to pretrained ResNet on CIFAR-10 subset using cross-entropy loss, measure runtime breakdown and assess bound informativeness

## Open Questions the Paper Calls Out

**Random-design extension**
- Question: Can the method be extended from fixed-design to random-design setting where covariates are stochastic?
- Basis: Section 6 explicitly states current analysis focuses on fixed-design; extending to random-design is important and technically challenging
- Why unresolved: Current guarantees rely on fixed covariates; random covariates introduce dependencies complicating gradient perturbation arguments
- Resolution: Theoretical derivation of excess risk bounds for ERM under random design using refitting method

**Pilot error characterization**
- Question: Can pilot error terms (B_n^⋄ and B_n^♯) be rigorously characterized or bounded rather than treated as heuristics?
- Basis: Section 6 notes paper provides useful explanation but rigorous characterization is highly valuable
- Why unresolved: Paper includes these terms without tight, non-asymptotic upper bound derived from wild refitting outputs
- Resolution: Theorem providing high-probability upper bound for pilot error terms scaling favorably with dimension and sample size

**Data-efficient variant**
- Question: Can a data-efficient variant be constructed that doesn't require full data memorization and perturbation for every data point?
- Basis: Section 6 states existing methods require full data memorization; designing data-efficient variant would be appealing
- Why unresolved: Current algorithm computes wild responses and retrains on entire dataset twice, computationally prohibitive for massive datasets
- Resolution: Modified algorithm using subsampling or sketching to approximate wild responses with provable guarantees

## Limitations
- No practical guidance for selecting noise scales ρ₁ and ρ₂, requiring manual tuning
- Computationally expensive, requiring 3× model training and solving resolvent equations for wild response generation
- Theoretical guarantees rely on fixed-design setting and well-specification assumptions that may not hold in practice

## Confidence
- Model-free excess risk bounds via wild optimism: High confidence from formal proofs
- Extension to non-symmetric noise: Medium confidence; theoretically well-supported but lacks empirical validation
- Practical applicability: Low confidence; no empirical validation, computational cost concerns, and unclear hyperparameter selection

## Next Checks
1. Implement prototype on synthetic problem with known excess risk to verify Theorem 5.2 bounds empirically and assess computational tractability
2. Conduct sensitivity analysis across different noise scales ρ to identify practical selection criteria and understand tradeoff between bound tightness and computational stability
3. Test method on non-convex deep learning problem (e.g., ResNet on CIFAR-10) to evaluate whether convex loss assumptions and theoretical guarantees remain meaningful in practice