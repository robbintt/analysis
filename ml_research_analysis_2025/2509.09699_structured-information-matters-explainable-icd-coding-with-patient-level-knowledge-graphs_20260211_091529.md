---
ver: rpa2
title: 'Structured Information Matters: Explainable ICD Coding with Patient-Level
  Knowledge Graphs'
arxiv_id: '2509.09699'
source_url: https://arxiv.org/abs/2509.09699
tags:
- entityt
- graph
- patient
- coding
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a structured patient-level knowledge graph for
  ICD coding. It extracts clinical entities and relationships from discharge summaries
  to create a graph that retains 90% of information while reducing text size to 23%.
---

# Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs

## Quick Facts
- **arXiv ID:** 2509.09699
- **Source URL:** https://arxiv.org/abs/2509.09699
- **Reference count:** 40
- **Primary result:** Patient-level knowledge graphs improve ICD coding performance by up to 3.20% Macro-F1

## Executive Summary
This paper addresses the challenge of accurate and explainable ICD coding by constructing patient-level knowledge graphs from discharge summaries. The authors extract clinical entities and relationships to create structured representations that retain 90% of information while reducing text size by 77%. By integrating these knowledge graphs into a PLM-ICD model, they achieve significant performance improvements over text-only baselines while providing enhanced explainability through attention visualization.

## Method Summary
The approach constructs patient-level knowledge graphs by extracting clinical entities (e.g., Problem, Treatment, Test) and their relationships from discharge summaries using exact string matching. The resulting graphs maintain semantic relationships while drastically reducing document size. These structured representations are integrated into a PLM-ICD model, where graph nodes serve as additional input alongside the original text. The model processes both modalities through separate encoders and combines them for ICD code prediction. The authors also introduce ablation studies and case-based analysis to evaluate the contribution of different entity types and demonstrate improved explainability.

## Key Results
- Knowledge graphs retain 90% of information while reducing text size to 23% of original
- PLM-ICD with knowledge graphs achieves up to 3.20% improvement in Macro-F1 scores
- Clinical Relationship and Problem entities identified as most impactful through ablation studies
- Enhanced explainability demonstrated through case studies with more accurate attention highlighting

## Why This Works (Mechanism)
The paper leverages structured clinical knowledge representation to improve both performance and interpretability in ICD coding. By extracting entities and relationships from discharge summaries, the knowledge graphs capture the core clinical narrative while eliminating redundant information. This structured representation allows the model to focus on clinically relevant relationships rather than raw text patterns. The exact string matching approach, while simple, provides a clear mapping between clinical concepts and their relationships, enabling the model to learn meaningful attention patterns that align with clinical reasoning.

## Foundational Learning
- **Clinical entity extraction:** Why needed - to identify relevant medical concepts; Quick check - verify entity coverage across different document types
- **Knowledge graph construction:** Why needed - to represent clinical relationships structurally; Quick check - validate graph connectivity and completeness
- **PLM-ICD integration:** Why needed - to combine structured and unstructured clinical information; Quick check - test separate encoder contributions
- **Attention-based explainability:** Why needed - to provide interpretable predictions; Quick check - evaluate attention alignment with clinical reasoning

## Architecture Onboarding

**Component map:** Clinical Text -> Entity Extractor -> Knowledge Graph Builder -> PLM Encoder + Graph Encoder -> ICD Code Predictor

**Critical path:** The critical path flows from raw discharge summary through entity extraction to knowledge graph construction, then to dual encoding (text and graph), and finally to ICD code prediction. The entity extraction and graph construction stages are most critical as they directly impact the quality of structured input.

**Design tradeoffs:** The authors chose exact string matching for entity extraction for simplicity and interpretability, trading off coverage for precision. They opted for separate encoders for text and graph representations to preserve modality-specific features, rather than forcing early fusion.

**Failure signatures:** Performance degradation may occur when clinical entities are expressed using synonyms or abbreviations not captured by exact matching. The model may struggle with complex temporal relationships not explicitly encoded in the graph structure.

**First experiments:** 1) Test entity extraction coverage on a validation set with clinical synonyms, 2) Compare performance with different graph pruning strategies, 3) Evaluate attention visualization quality with clinical experts

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Exact string matching may miss semantically equivalent entities with different surface forms
- Entity importance findings may reflect dataset-specific patterns rather than universal principles
- Attention-based explainability demonstration limited to three case studies without systematic evaluation

## Confidence
**High confidence:** The 90% information retention with 77% size reduction is supported by the provided data. The 3.20% Macro-F1 improvement over baseline is well-documented. The graph structure and entity types are clearly defined.

**Medium confidence:** The generalizability of which entity types matter most across different clinical document types. The clinical relevance of the attention visualizations beyond their visual appeal.

**Low confidence:** The robustness of the exact matching approach to clinical language variation. Whether the explainability benefits persist across diverse clinical scenarios.

## Next Checks
1. Test entity extraction performance on a held-out dataset with clinical entity synonyms and abbreviations
2. Conduct user studies with clinical experts to validate whether attention visualizations actually improve interpretability
3. Evaluate model performance across different clinical document types (e.g., progress notes vs discharge summaries) to assess generalizability