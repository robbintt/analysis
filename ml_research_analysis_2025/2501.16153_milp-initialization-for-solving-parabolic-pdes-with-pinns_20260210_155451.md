---
ver: rpa2
title: MILP initialization for solving parabolic PDEs with PINNs
arxiv_id: '2501.16153'
source_url: https://arxiv.org/abs/2501.16153
tags:
- pinn
- pre-training
- neural
- weights
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the slow convergence speed of Physics-Informed
  Neural Networks (PINNs) for solving partial differential equations (PDEs), particularly
  in realistic systems. The authors propose using Mixed-Integer Linear Programming
  (MILP) for optimal initialization of PINN weights to accelerate convergence.
---

# MILP initialization for solving parabolic PDEs with PINNs

## Quick Facts
- **arXiv ID:** 2501.16153
- **Source URL:** https://arxiv.org/abs/2501.16153
- **Reference count:** 23
- **Primary result:** Boundary pre-training with MILP achieves ~40% faster PINN convergence and lower MSE for transformer heat diffusion

## Executive Summary
This paper addresses the slow convergence of Physics-Informed Neural Networks (PINNs) when solving partial differential equations (PDEs) in realistic systems. The authors propose using Mixed-Integer Linear Programming (MILP) to optimally initialize the first layer weights of PINNs, significantly accelerating convergence. Tested on a 1D transient heat diffusion equation modeling power transformer temperature distribution, the boundary pre-training method demonstrates substantial improvements: achieving lower mean squared error (MSE) values with reduced variance across multiple test runs while decreasing training time by approximately 40% compared to vanilla PINN initialization.

## Method Summary
The authors propose a two-phase training approach where MILP is used to pre-train the first layer of a PINN for optimal initialization. The PINN architecture consists of an input layer with 5 neurons, one hidden layer (32 or 60 neurons with tanh activation), and one output neuron. During pre-training, the tanh activation is approximated using a saturation function, and the first layer weights and biases ($W_1, b_1, b_2$) are optimized while keeping $W_2$ fixed. Two pre-training strategies are investigated: one using only boundary conditions and another incorporating physics. After MILP initialization, standard training proceeds with ADAM followed by L-BFGS-B. The approach is tested on a heat diffusion equation for power transformer temperature modeling, comparing vanilla PINN with boundary pre-trained PINN on convergence time and final MSE.

## Key Results
- Boundary pre-training with MILP reduces training time by approximately 40% compared to vanilla PINN
- Achieves lower mean squared error (MSE) values with reduced variance across multiple test runs
- MILP initialization enables more accurate and efficient capture of temperature distributions in the transformer model

## Why This Works (Mechanism)
The MILP pre-training phase provides a structured initialization that respects the physical constraints encoded in the boundary conditions. By optimizing the first layer weights to satisfy boundary conditions through a linearized approximation of the activation function, the network starts from a solution that already satisfies some of the PDE constraints. This reduces the optimization landscape complexity that the subsequent ADAM and L-BFGS-B phases must navigate, allowing faster convergence to a solution that satisfies both the physics and boundary conditions.

## Foundational Learning
- **Physics-Informed Neural Networks (PINNs):** Neural networks trained to solve PDEs by incorporating physical laws as loss terms. *Why needed:* Core methodology being accelerated. *Quick check:* Can implement basic PINN for simple ODE.
- **Mixed-Integer Linear Programming (MILP):** Optimization framework handling both continuous and discrete variables with linear constraints/objectives. *Why needed:* Enables structured initialization through constraint satisfaction. *Quick check:* Can formulate and solve small MILP problem.
- **Big-M Method:** Technique for modeling logical constraints in MILP using large constant M. *Why needed:* Approximates nonlinear tanh activation with linear constraints. *Quick check:* Can implement big-M constraints correctly in small example.
- **Two-phase Training (ADAM → L-BFGS-B):** Hybrid optimization combining first-order and second-order methods. *Why needed:* Standard PINN training approach being accelerated. *Quick check:* Can implement and compare both optimizers.

## Architecture Onboarding

**Component Map:** Input features → First layer (MILP-initialized) → Hidden layer (tanh) → Output layer

**Critical Path:** Data preprocessing → MILP pre-training (first layer) → ADAM optimization → L-BFGS-B refinement → Prediction

**Design Tradeoffs:** The paper chooses to optimize only the first layer to limit MILP complexity while still gaining convergence benefits. This balances initialization quality against computational overhead of the MILP phase.

**Failure Signatures:** Poor MILP initialization leads to slow convergence or local minima. Discontinuous predictions suggest incorrect implementation of the saturation function approximation. Solver timeouts indicate need for smaller datasets or different big-M values.

**First Experiments:**
1. Implement basic PINN for simple ODE and verify it converges with random initialization
2. Implement MILP formulation for first-layer initialization on small synthetic dataset
3. Compare convergence curves for vanilla vs. MILP-initialized PINN on the heat equation

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead of MILP pre-training phase not fully characterized relative to runtime gains
- Results dependent on specific transformer dataset that may not be publicly available
- Performance gains may not generalize to all PDE types or higher-dimensional problems

## Confidence
- **High Confidence:** MILP pre-training methodology and boundary condition implementation are clearly described and reproducible
- **Medium Confidence:** Performance improvements are plausible but require careful parameter tuning for verification
- **Low Confidence:** Exact magnitude of improvements may vary significantly with data quality and solver performance

## Next Checks
1. **Data Sensitivity Analysis:** Validate approach using both synthetic data and subsampled real transformer measurements to assess robustness
2. **Solver Performance Benchmarking:** Compare different MILP solvers and big-M value ranges to identify optimal configurations
3. **End-to-End Runtime Comparison:** Measure total computation time including MILP pre-training to determine if 40% training time reduction holds when accounting for initialization overhead