---
ver: rpa2
title: 'Sy-FAR: Symmetry-based Fair Adversarial Robustness'
arxiv_id: '2509.12939'
source_url: https://arxiv.org/abs/2509.12939
tags:
- adversarial
- fairness
- sy-far
- robustness
- symmetry
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sy-FAR addresses unfair adversarial robustness in ML models by
  promoting symmetry in misclassification patterns between classes. It introduces
  a symmetry-based regularizer that encourages models to misclassify adversarial examples
  from class i to j at the same rate as from j to i, thereby reducing directional
  bias.
---

# Sy-FAR: Symmetry-based Fair Adversarial Robustness

## Quick Facts
- **arXiv ID:** 2509.12939
- **Source URL:** https://arxiv.org/abs/2509.12939
- **Reference count:** 40
- **Primary result:** Sy-FAR improves fair adversarial robustness by enforcing symmetry in misclassification patterns between classes, achieving better fairness metrics while maintaining or improving robust accuracy compared to baselines like FAAL and SpecNorm.

## Executive Summary
Sy-FAR addresses unfair adversarial robustness in machine learning models by promoting symmetry in misclassification patterns between classes. It introduces a symmetry-based regularizer that encourages models to misclassify adversarial examples from class i to j at the same rate as from j to i, thereby reducing directional bias. Evaluated on face recognition and object classification tasks under realistic eyeglass and mask attacks, Sy-FAR consistently improves fair source- and target-class adversarial robustness while maintaining or improving benign and robust accuracy. It also achieves faster training and greater stability compared to leading methods like FAAL and SpecNorm. Theoretically, Sy-FAR ensures symmetry for arbitrary subgroups, addressing group-level fairness without requiring explicit group definitions.

## Method Summary
Sy-FAR is a regularization technique that promotes fair adversarial robustness by enforcing symmetry in pairwise misclassification rates between classes. It adds a symmetry loss term to the standard adversarial training objective, penalizing the absolute difference between $C_{ij}$ (misclassification rate i→j) and $C_{ji}$ (j→i), weighted by total error mass. The soft confusion matrix is constructed from softmax probabilities of adversarial examples, making the regularization differentiable. This approach ensures that no class is systematically disadvantaged in being attacked (source) or impersonated (target). The method is evaluated on face recognition datasets (PubFig) and object classification (CIFAR-10/100), showing improved fairness metrics while maintaining or improving robust accuracy.

## Key Results
- Sy-FAR consistently improves fair source- and target-class adversarial robustness compared to FAAL and SpecNorm baselines.
- Achieves superior stability (lower variance) and faster training compared to alternative approaches.
- Maintains or improves benign and robust accuracy while reducing asymmetry gaps between classes.
- Theoretical guarantees ensure symmetry for arbitrary subgroups without requiring explicit group definitions.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enforcing symmetry in pairwise misclassification rates balances directional bias in adversarial settings.
- **Mechanism:** The regularizer penalizes the absolute difference between $C_{ij}$ (misclassification rate i→j) and $C_{ji}$ (j→i), weighted by total error mass. By minimizing this gap, the model adjusts decision boundaries so neither class is systematically disadvantaged.
- **Core assumption:** Class resemblance and feature overlap are fundamentally symmetric relations; if i resembles j, j resembles i.
- **Evidence anchors:** Abstract states "symmetry is desirable because class resemblance is a symmetric relation in most domains"; Section 4.1 illustrates symmetric confusion matrices produce equal robust accuracy across classes.
- **Break condition:** If class features are not symmetric (e.g., hierarchical classification), enforcing strict symmetry may distort the learned feature space.

### Mechanism 2
- **Claim:** Optimizing pairwise class symmetry mathematically guarantees symmetry for arbitrary subgroups without explicit group labels.
- **Mechanism:** The soft confusion matrix is linear. Summing symmetric pairwise rates ($C_{ij} = C_{ji}$) over sets of classes (subgroups) preserves the equality. Therefore, minimizing pairwise asymmetry propagates to aggregate group-level symmetry.
- **Core assumption:** Subgroups are finite partitions of the class set, and confusion matrix normalization remains consistent across batches.
- **Evidence anchors:** Abstract states "Symmetry between individuals induces symmetry between any set of sub-groups"; Section 7.2 Theorem 1 formally proves symmetric matrix $C$ implies subgroup symmetry.
- **Break condition:** If inference-time subgroups are defined by features not present in training class set, the guarantee weakens.

### Mechanism 3
- **Claim:** Symmetry regularization acts as a smoother optimization objective, reducing training instability compared to spectral or bilevel methods.
- **Mechanism:** Unlike spectral normalization (global constraints) or reweighting schemes (sensitive to worst-case samples), the symmetry loss is a differentiable aggregation over the batch confusion matrix, providing a more consistent gradient signal.
- **Core assumption:** Batch size is sufficient to approximate confusion matrix statistics (contains enough examples per class).
- **Evidence anchors:** Section 6.5 notes Sy-FAR achieves superior stability (lower variance) and posits symmetry acts as a smoother objective; Section 6.4 notes FAAL is nearly 5x slower due to bilevel optimization.
- **Break condition:** If batch size is too small to populate confusion matrix (rare classes), loss becomes noisy and optimization may destabilize.

## Foundational Learning

- **Concept:** Adversarial Training
  - **Why needed here:** Sy-FAR is a regularization term added on top of the standard adversarial training framework; understanding the base loss (benign + adversarial) is required to see where the symmetry term fits.
  - **Quick check question:** How does the loss function in Equation (4) differ from standard Projected Gradient Descent (PGD) adversarial training?

- **Concept:** Soft Confusion Matrix
  - **Why needed here:** Standard confusion matrices are discrete (counts) and non-differentiable. Sy-FAR requires a differentiable proxy to propagate gradients for symmetry.
  - **Quick check question:** How is the soft confusion matrix $C_{ij}$ constructed from the softmax outputs $p_b$ in Section 4.2?

- **Concept:** Source vs. Target Fairness
  - **Why needed here:** The paper distinguishes between unfairness in being attacked (source) and being impersonated (target). Sy-FAR addresses both simultaneously via symmetry.
  - **Quick check question:** In Figure 5, how do the off-diagonal columns differ between FAAL and Sy-FAR, and what does that imply for target-class fairness?

## Architecture Onboarding

- **Component map:** Input Pipeline -> Adversary (PGD/Eyeglass) -> Forward Pass (clean + adversarial) -> Soft Confusion Module -> Loss Aggregator (Clean + Adversarial + Symmetry Loss)
- **Critical path:** The accumulation of the Soft Confusion Matrix. This step must occur before the loss calculation and requires masking/normalization to handle varying class counts per batch (the $n_i$ term).
- **Design tradeoffs:**
  - **Robustness vs. Fairness:** Increasing $\lambda_{sym}$ improves fairness (symmetry) but may slightly impact raw robust accuracy if symmetry constraint forces model to equalize error rates suboptimally.
  - **Computational Overhead:** While low, the $O(K^2)$ memory for confusion matrix grows with classes.
- **Failure signatures:**
  - **NaN Loss:** Division by zero if class i has zero samples in batch ($n_i=0$). Mitigated by $\max(n_i, 1)$ normalization.
  - **Stagnant Symmetry:** If $\lambda_{sym}$ is too low compared to $\lambda_{adv}$, dominant adversarial loss overrides symmetry pressure.
  - **Target Sink Persistence:** If specific classes are inherently "generic" (visually average faces), symmetry might be hard to enforce without degrading benign accuracy.
- **First 3 experiments:**
  1. **Ablation on $\lambda_{sym}$:** Run Sy-FAR on reduced PubFig subset with varying symmetry weights to find Pareto frontier between robust accuracy and asymmetry gap.
  2. **Batch Size Sensitivity:** Test stability of $L_{sym}$ with small batch sizes (16 vs 128) to verify if soft confusion matrix estimate remains stable.
  3. **Target-Class Audit:** Train Sy-FAR and baselines, then specifically measure "Target Confusion Share" ($T_j$) to confirm if Sy-FAR prevents specific classes from becoming "impersonation sinks."

## Open Questions the Paper Calls Out

- **Open Question 1:** How does Sy-FAR perform when applied to highly imbalanced or noisy real-world datasets?
  - **Basis in paper:** Section 8 states that extending Sy-FAR to imbalanced or noisy datasets is an "important next step," as experiments used controlled, balanced conditions.
  - **Why unresolved:** Real-world data often contains significant bias and label noise not present in controlled experimental setup.
  - **What evidence would resolve it:** Evaluation results on benchmarks with heavy class imbalance or stochastic label noise.

- **Open Question 2:** Can the symmetry regularization approach be generalized to non-vision domains like natural language or audio?
  - **Basis in paper:** Section 8 suggests extending the method to other modalities while acknowledging need for domain-specific definitions of symmetric behavior.
  - **Why unresolved:** Definition of "class resemblance" as symmetric relation may not translate directly to semantic or acoustic feature spaces.
  - **What evidence would resolve it:** Successful application of domain-adapted Sy-FAR regularizer to text or audio classification tasks.

- **Open Question 3:** How can Sy-FAR be modified to maintain fairness guarantees in open-world or continuous-class domains?
  - **Basis in paper:** Section 8 highlights that theoretical guarantees assume finite class space, which may not hold for open-set or streaming scenarios.
  - **Why unresolved:** Current theoretical proofs depend on fixed partitions of classes, potentially failing when new, unseen classes emerge.
  - **What evidence would resolve it:** Theoretical framework extending symmetry proofs to continuous spaces and empirical validation on open-set datasets.

## Limitations
- The theoretical guarantee of subgroup symmetry relies on the assumption that class labels capture all relevant group attributes, which may not hold for intersectional fairness concerns.
- Paper demonstrates effectiveness primarily on face recognition and object classification tasks, with limited testing on domains where class features are inherently asymmetric.
- Lack of specified hyperparameters (λ_clean, λ_adv, λ_sym, learning rate, batch size) which are critical for exact reproduction.

## Confidence
- **High confidence:** The core mechanism of enforcing pairwise misclassification symmetry (Mechanism 1) is well-supported by mathematical formulation and empirical results showing reduced asymmetry gaps.
- **Medium confidence:** The claim that symmetry regularization provides smoother optimization (Mechanism 3) is supported by stability metrics but lacks direct comparison with spectral methods' gradient landscapes.
- **Medium confidence:** The theoretical proof of subgroup symmetry (Mechanism 2) is mathematically sound but assumes class labels adequately represent subgroup identities.

## Next Checks
1. **Ablation study on λ_sym:** Run Sy-FAR with λ_sym ∈ {0.01, 0.1, 1.0} on reduced PubFig subset to identify Pareto frontier between robust accuracy and asymmetry gap.
2. **Batch size sensitivity:** Test Sy-FAR stability with varying batch sizes (16 vs 128) to verify soft confusion matrix estimate consistency and identify minimum batch size for stable symmetry loss computation.
3. **Target-class audit:** After training Sy-FAR and baselines, specifically measure Target Confusion Share (T_j) for each class to confirm Sy-FAR prevents specific classes from becoming "impersonation sinks."