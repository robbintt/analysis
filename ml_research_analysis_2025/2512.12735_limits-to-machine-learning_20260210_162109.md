---
ver: rpa2
title: Limits To (Machine) Learning
arxiv_id: '2512.12735'
source_url: https://arxiv.org/abs/2512.12735
tags:
- page
- values
- toos
- bound
- lower
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper identifies a fundamental statistical limitation in\
  \ high-dimensional machine learning: even with large samples, complex models cannot\
  \ recover the true data-generating process due to finite-sample constraints. The\
  \ authors formalize this as the Limits-to-Learning Gap (LLG), a data-driven lower\
  \ bound on the gap between observed and true out-of-sample R\xB2."
---

# Limits To (Machine) Learning

## Quick Facts
- arXiv ID: 2512.12735
- Source URL: https://arxiv.org/abs/2512.12735
- Authors: Zhimin Chen; Bryan Kelly; Semyon Malamud
- Reference count: 40
- Primary result: Finite-sample constraints prevent high-dimensional ML models from recovering true parameters, even with large samples

## Executive Summary
This paper identifies a fundamental statistical limitation in high-dimensional machine learning, showing that finite-sample constraints prevent models from recovering the true data-generating process, regardless of sample size. The authors introduce the Limits-to-Learning Gap (LLG), a data-driven lower bound on the gap between observed and true out-of-sample R². Through rigorous theoretical proofs and empirical validation using financial forecasting data, they demonstrate that LLG corrections can dramatically increase estimates of predictability, suggesting true R² values 10-20 times higher than standard ML models achieve.

## Method Summary
The authors develop a statistical framework that formalizes the finite-sample limitations of high-dimensional learning. They derive a one-sided confidence interval for true R² and prove that the LLG represents a fundamental bound on predictability in high-dimensional settings. The framework is empirically validated using financial forecasting data, where standard ML models achieve certain R² levels, but LLG corrections suggest substantially higher true predictability. The approach also provides refinements to Hansen-Jagannathan bounds and offers insights into excess volatility through rational learning models.

## Key Results
- LLG provides a data-driven lower bound on the gap between observed and true out-of-sample R²
- Finite-sample constraints prevent true parameter recovery regardless of sample size
- LLG corrections suggest true R² values 10-20 times higher than standard ML models achieve in financial forecasting
- Framework refines Hansen-Jagannathan bounds and explains excess volatility through rational learning

## Why This Works (Mechanism)
The mechanism works because high-dimensional models face fundamental statistical limitations that persist even with large samples. The LLG captures the irreducible error between what models can learn from finite data and the true underlying data-generating process. This limitation arises from the curse of dimensionality and the finite-sample constraints inherent in statistical estimation, creating a gap that cannot be closed through traditional methods of increasing sample size or model complexity.

## Foundational Learning
- **High-dimensional statistics**: Understanding the behavior of statistical models when the number of parameters approaches or exceeds the sample size. Needed to grasp why traditional asymptotic results fail. Quick check: Verify understanding of the dimensionality/sample size relationship.
- **Finite-sample theory**: Statistical properties that hold for any sample size, not just asymptotic limits. Essential for understanding the fundamental constraints. Quick check: Explain why asymptotic normality assumptions may fail.
- **Hansen-Jagannathan bounds**: Theoretical constraints on asset pricing models based on volatility bounds. Critical for the financial applications. Quick check: Derive basic HJ bounds for a simple asset pricing model.
- **Confidence interval construction**: One-sided confidence intervals for R² in high-dimensional settings. Necessary for interpreting LLG results. Quick check: Construct a one-sided CI for a simple regression.

## Architecture Onboarding

**Component Map**: Data Generation -> LLG Calculation -> Confidence Interval Construction -> Model Evaluation -> Bounds Refinement

**Critical Path**: The theoretical derivation of LLG bounds -> empirical validation through financial forecasting -> application to Hansen-Jagannathan bounds refinement

**Design Tradeoffs**: The framework trades computational complexity for theoretical rigor, providing bounds that may be conservative but are guaranteed to hold under specified conditions.

**Failure Signatures**: Overestimation of predictability when LLG corrections are applied without proper statistical validation; misapplication to settings with fundamentally different data-generating processes.

**First Experiments**:
1. Verify LLG calculations on synthetic data with known ground truth
2. Compare LLG-corrected predictions against standard ML models on benchmark datasets
3. Test bounds refinement on simple asset pricing models with simulated data

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical demonstration relies on specific financial market conditions that may not generalize
- Theoretical framework assumes specific data-generating processes that may not capture all real-world complexities
- Practical implications of bounds refinement require further empirical validation across different asset classes

## Confidence

**Generalizability**: Medium - claims about fundamental limitations are well-supported theoretically, but empirical demonstration is domain-specific

**Universal Applicability**: Medium - theoretical framework is rigorous but assumes specific model specifications that may not hold in all applications

**Practical Implementation**: Medium - LLG framework is theoretically sound but requires careful statistical validation for specific applications

## Next Checks

1. Test LLG framework across multiple high-dimensional domains beyond finance (e.g., genomics, climate modeling)
2. Compare LLG-corrected predictions against alternative approaches for handling high-dimensional data
3. Validate theoretical bounds using synthetic data with known ground truth across varying sample sizes and dimensionality levels