---
ver: rpa2
title: Exploiting Vulnerabilities in Speech Translation Systems through Targeted Adversarial
  Attacks
arxiv_id: '2503.00957'
source_url: https://arxiv.org/abs/2503.00957
tags:
- adversarial
- speech
- target
- attack
- music
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first adversarial attack study on speech
  translation systems, demonstrating two novel approaches to compromise these models
  through imperceptible audio manipulations. The first method injects adversarial
  perturbations into source audio, enhanced through Multi-language Enhancement and
  Target Cycle Optimization to improve semantic attack effectiveness across languages.
---

# Exploiting Vulnerabilities in Speech Translation Systems through Targeted Adversarial Attacks

## Quick Facts
- **arXiv ID**: 2503.00957
- **Source URL**: https://arxiv.org/abs/2503.00957
- **Reference count**: 40
- **Primary result**: First adversarial attack study on speech translation systems demonstrating two novel approaches that force targeted mistranslations across multiple languages with ~50% over-the-air success rates

## Executive Summary
This paper presents the first systematic study of adversarial attacks on speech translation systems, demonstrating two novel approaches that can force targeted mistranslations through imperceptible audio manipulations. The first method injects adversarial perturbations into source audio, enhanced through Multi-language Enhancement and Target Cycle Optimization to improve semantic attack effectiveness across languages. The second method generates adversarial music using diffusion-based models that can mislead translation systems while remaining imperceptible to human listeners. Experiments show both attacks successfully force targeted mistranslations across multiple languages and models, with over-the-air attack success rates around 50% in physical testing. The findings reveal systemic vulnerabilities in current speech translation architectures and highlight the need for more robust defense mechanisms.

## Method Summary
The paper presents two distinct adversarial attack methods targeting speech translation systems. The first method uses white-box gradient optimization to inject imperceptible perturbations into source audio, forcing specific mistranslations through cross-entropy loss minimization with teacher forcing. This is enhanced with Multi-language Enhancement (summing losses across multiple target languages) and Target Cycle Optimization (refining target phrases via cyclic translation). The second method employs a diffusion-based approach to generate adversarial music by optimizing latent noise and rhythm embeddings, using SharpnessLoss to stabilize optimization for non-speech inputs. Both methods constrain perturbations to maintain perceptual quality while achieving high attack success rates across multiple languages and translation models.

## Key Results
- Perturbation-based attacks achieve semantic similarity scores (ESIM) above 0.7 and attack success rates above 80% across multiple languages
- Multi-language Enhancement significantly improves transfer to unseen languages by optimizing perturbations toward the semantic center of multilingual representations
- Physical over-the-air attacks achieve approximately 50% success rates, demonstrating practical real-world vulnerability
- Both attacks maintain high perceptual quality with PESQ scores above 2.0 and VSIM scores above 0.8, indicating minimal audible distortion

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Based Perturbation Optimization with Teacher Forcing
- **Claim:** Targeted adversarial perturbations can force specific mistranslations when optimized via white-box gradients through the encoder-decoder pipeline.
- **Mechanism:** The attack computes cross-entropy loss between the decoder's autoregressive token predictions and the target text tokens. Gradients backpropagate through the text decoder and speech encoder to the input audio, yielding perturbations δ that shift the model's internal representations toward the target semantics. A bandpass filter constrains δ to the 1–4 kHz range, reducing perceptibility by avoiding very low and high frequencies.
- **Core assumption:** Attacker has white-box access to model parameters and gradients; the model's gradient paths remain stable across optimization steps.
- **Evidence anchors:**
  - [abstract] "the first method injects adversarial perturbations into source audio, enhanced through Multi-language Enhancement and Target Cycle Optimization to improve semantic attack effectiveness across languages"
  - [section IV-A, Algorithm 1] Formal loss L(δ) and iterative optimization with δ ← ϵ·tanh(δ) followed by bandpass[1k,4k](δ)
  - [corpus] Related work on ASR adversarial attacks (Carlini et al., 2018; Schönherr et al., 2018) provides precedent, but corpus does not confirm the specific Multi-language Enhancement mechanism for ST.

### Mechanism 2: Semantic Manipulation via Diffusion-Based Music Generation
- **Claim:** Adversarial music, generated by optimizing latent noise and rhythm embeddings in a diffusion model, can encode target semantics that trigger specific translations while remaining perceptually natural.
- **Mechanism:** A latent diffusion model (eDMG) generates music via a reverse denoising process conditioned on text, chord, and beat embeddings. The attack optimizes the initial latent noise ω_T and chord/beat encoder parameters to produce music that, when fed to the ST model, yields the target translation. SharpnessLoss replaces cross-entropy to sharpen the autoregressive distribution at each decoding step, stabilizing optimization for non-speech inputs.
- **Core assumption:** The ST model treats music inputs as within-distribution and maps them to its semantic space; the diffusion model's latent space is sufficiently expressive to encode adversarial semantics.
- **Evidence anchors:**
  - [abstract] "the second method generates adversarial music using diffusion-based models that can mislead translation systems while remaining imperceptible to human listeners"
  - [section IV-B, Algorithm 2] Optimization of ω_T, θ_c, θ_b with SharpnessLoss; reverse diffusion process detailed
  - [corpus] MAIA paper on music adversarial attacks supports feasibility of diffusion-based adversarial music, but does not confirm the specific SharpnessLoss mechanism for ST.

### Mechanism 3: Cross-Lingual Transfer via Shared Semantic Space
- **Claim:** Perturbations optimized on multiple "Seen" languages transfer to "Unseen" languages because modern ST models align diverse languages in a shared semantic space.
- **Mechanism:** By optimizing perturbations against target texts in multiple languages simultaneously, the perturbation is pushed toward a more central position in the model's language-agnostic semantic space. This centralization improves generalization to languages not included during optimization. Target Cycle Optimization further refines target phrases to those more centrally represented in the model's semantic space via cyclic translation.
- **Core assumption:** The ST model's multilingual representations are sufficiently aligned that perturbations targeting one language region affect others; the semantic space is continuous rather than fragmented.
- **Evidence anchors:**
  - [abstract] "These attacks prove effective across multiple languages and translation models, highlighting a systemic vulnerability"
  - [section V-B, Tab. IV] ESIM/NSCORE/ASR improve for Unseen languages as the number of Seen languages increases
  - [corpus] Universal acoustic attacks on Speech-LLMs suggest cross-lingual transfer is plausible in speech+LLM systems, but corpus does not directly validate the semantic center argument for ST.

## Foundational Learning

- **Autoregressive Text Decoding with Teacher Forcing**
  - Why needed here: The ST models (Seamless, Canary) generate translations token-by-token; the perturbation attack uses teacher forcing to align predictions with target tokens during optimization.
  - Quick check question: Given a sequence of predicted tokens z*_{<m} and target tokens tgt_text, write the cross-entropy loss for position m.

- **Adversarial Optimization and Perturbation Budgeting**
  - Why needed here: The attack must craft perturbations small enough to be imperceptible (ϵ constraint) yet effective; understanding gradient-based optimization and projection (e.g., tanh + bandpass) is essential.
  - Quick check question: How does bandpass filtering in the 1–4 kHz range help preserve speech quality while allowing adversarial signals?

- **Latent Diffusion Models for Conditional Audio Generation**
  - Why needed here: The music-based attack optimizes within the latent space of a diffusion model; understanding forward/reverse diffusion, VAE priors, and conditioning is necessary to interpret and extend the approach.
  - Quick check question: In a reverse diffusion step, what role do the chord encoder, beat encoder, and text encoder play in steering the denoising process?

## Architecture Onboarding

- **Component map:**
  - Target ST models: Canary (speech encoder + autoregressive text decoder); Seamless family (speech encoder + AR text decoder + NAR unit decoder + vocoder for speech-to-any)
  - Attack modules: Perturbation optimizer (gradient descent on δ with ϵ-projection and bandpass filter); Diffusion-based music generator (VAE encoder, MuNet denoiser, chord/beat/text encoders)
  - Evaluation: ESIM (BERT-based semantic similarity), NSCORE (NLI-based entailment), ASR (success rate over semantic thresholds)

- **Critical path:**
  1. Load target ST model in inference mode with gradient access
  2. Initialize perturbation δ or music latent ω_T and conditioning (chord c, beat b, prompt text τ)
  3. For perturbation: Forward audio + δ through encoder, compute decoder loss with teacher forcing, backprop to δ, project and filter
  4. For music: Run reverse diffusion to generate audio, forward through ST encoder-decoder, compute SharpnessLoss, backprop to ω_T, θ_c, θ_b
  5. Iterate until translation matches target semantics or max iterations reached
  6. Optionally simulate over-the-air distortions (reverb, noise) during optimization for robustness

- **Design tradeoffs:**
  - Perturbation strength (ϵ) vs. perceptibility: Higher ϵ improves ASR but lowers PESQ/MOS scores
  - Number of Seen languages vs. optimization cost: More languages improve transfer but increase per-iteration computation
  - Music style prompt vs. attack stealth: Different prompts (Techno, Classical, Orchestral) yield similar ASR but differ in perceptual naturalness
  - White-box assumption vs. real-world feasibility: Physical over-the-air attacks drop to ~50% ASR, suggesting a gap between ideal and practical success

- **Failure signatures:**
  - Low ESIM/NSCORE despite high ϵ: Target phrase may be semantically misaligned with model's internal representations; try Target Cycle Optimization
  - Perceptible distortion (low PESQ/MOS): Perturbation may have energy outside 1–4 kHz or ϵ too high; tighten bandpass or reduce budget
  - Poor transfer to Unseen languages: Optimize with more Seen languages or refine target text via cycle translation
  - Music attack yields low confidence predictions: Switch from cross-entropy to SharpnessLoss to sharpen autoregressive distributions

- **First 3 experiments:**
  1. **Baseline perturbation attack:** Choose one source–target language pair (e.g., EN→FR), set ϵ=0.1, optimize for 5 target phrases. Report ESIM, NSCORE, ASR, PESQ, VSIM. Confirm attack is feasible and establish perceptibility baseline.
  2. **Multi-language Enhancement ablation:** Repeat experiment 1 while varying the set of Seen languages (EN only, EN+ZH, EN+ZH+DE, EN+ZH+DE+FR). Measure ASR on Unseen languages to quantify transfer gains.
  3. **Physical over-the-air robustness:** Generate adversarial music with simulated room impulse responses and background speech. Play through consumer speaker, record with microphone and phone, feed to ST model. Compare ASR to digital-only setup to quantify real-world degradation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can effective defense mechanisms be developed that remove adversarial perturbations without compromising the semantic integrity and usability of the original speech?
- Basis in paper: [explicit] Section VI concludes that while signal processing defenses (e.g., MP3 compression, resampling) can mitigate attacks, they "do not fully restore the semantic integrity of the original speech" and may reduce usability.
- Why unresolved: Current defensive preprocessing introduces distortions that break the adversarial pattern but also degrade the legitimate audio signal quality.
- What evidence would resolve it: A defense algorithm that preserves high speaker similarity (VSIM) and perceptual quality (PESQ) while reducing the Attack Success Rate (ASR) to near zero.

### Open Question 2
- Question: Can these targeted adversarial attacks be successfully executed in strictly black-box settings where the attacker lacks access to model parameters and gradients?
- Basis in paper: [explicit] Section III.A explicitly states, "We assume that the attacker has access to the model's parameters and can obtain gradients in our white-box investigation."
- Why unresolved: The optimization process relies heavily on gradient backpropagation, and it is unclear if the perturbations transfer effectively without this internal access.
- What evidence would resolve it: A successful targeted attack generated using only query access to the API, without white-box knowledge of the Seamless or Canary model weights.

### Open Question 3
- Question: How can the robustness of adversarial music be improved to achieve higher success rates in physical over-the-air attacks?
- Basis in paper: [explicit] Section V.C.5 notes that in physical over-the-air tests, the "adversarial music achieves an attack success rate of approximately 50%," leaving a significant failure rate.
- Why unresolved: The adversarial signals are currently susceptible to environmental distortions, reverberation, and device hardware limitations during transmission.
- What evidence would resolve it: A method for generating adversarial music that maintains a high Attack Success Rate (e.g., >80%) when played over consumer-grade speakers and captured by microphones.

## Limitations
- **White-box assumption**: Both attack methods critically depend on white-box access to model gradients, which may not be available in deployed systems
- **Physical-world gap**: Over-the-air attack success rates drop to ~50%, indicating significant degradation from ideal conditions
- **Transfer generalization limits**: Cross-lingual transfer effectiveness depends on the degree of semantic alignment across languages, which may vary significantly for distant language pairs

## Confidence
- **High Confidence**: Basic gradient-based adversarial perturbation optimization on speech translation systems is well-established and reproducible
- **Medium Confidence**: Multi-language Enhancement and Target Cycle Optimization mechanisms for improving cross-lingual transfer are supported by experimental results but theoretical justification remains speculative
- **Medium Confidence**: Diffusion-based music attack mechanism shows promising results but optimization details (particularly SharpnessLoss) are less detailed than perturbation attack

## Next Checks
1. **Robustness to Acoustic Variations**: Conduct systematic testing across different room acoustics, speaker distances, background noise levels, and recording devices to quantify the gap between ideal and practical success rates and identify environmental factors that most degrade attack effectiveness.

2. **Black-Box Transfer Evaluation**: Implement a black-box version of both attacks where gradients are estimated through query-based methods rather than direct access. Measure attack success rates against different ST model architectures to assess portability and identify model-specific vulnerabilities.

3. **Semantic Space Analysis**: Perform detailed analysis of multilingual semantic space alignment in target ST models by visualizing embedding representations of source and target phrases across languages to validate theoretical basis for cross-lingual transfer and identify vulnerable language pairs.