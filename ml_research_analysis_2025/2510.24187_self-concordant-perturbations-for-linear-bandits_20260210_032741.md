---
ver: rpa2
title: Self-Concordant Perturbations for Linear Bandits
arxiv_id: '2510.24187'
source_url: https://arxiv.org/abs/2510.24187
tags:
- self-concordant
- regret
- sc-ftpl
- have
- proposition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Self-Concordant FTPL (SC-FTPL), a new algorithm
  for adversarial linear bandits that combines self-concordant regularization with
  FTPL-based sampling. The key innovation is the introduction of self-concordant perturbations,
  probability distributions that replicate the properties of self-concordant barriers
  within an FTPL framework.
---

# Self-Concordant Perturbations for Linear Bandits

## Quick Facts
- **arXiv ID**: 2510.24187
- **Source URL**: https://arxiv.org/abs/2510.24187
- **Reference count**: 0
- **Primary result**: Introduces SC-FTPL algorithm achieving O(d√(n lnn)) regret on hypercube and Euclidean ball

## Executive Summary
This paper introduces Self-Concordant FTPL (SC-FTPL), a novel algorithm for adversarial linear bandits that combines self-concordant regularization with Follow-the-Perturbed-Leader (FTPL) sampling. The key innovation is the introduction of self-concordant perturbations - probability distributions designed to replicate the properties of self-concordant barriers within an FTPL framework. This approach achieves optimal regret bounds of O(d√(n lnn)) on both the d-dimensional hypercube and Euclidean ball, representing a √d improvement over previous self-concordant FTRL methods on the hypercube while maintaining O(d) per-round computational complexity.

## Method Summary
The SC-FTPL algorithm operates by adding self-concordant perturbations to the cumulative loss estimates before selecting actions via a linear optimization oracle. These perturbations are carefully designed probability distributions that preserve the key properties of self-concordant barriers when used within the FTPL framework. The algorithm maintains a regularized cumulative loss estimate and samples perturbations from distributions that mirror the curvature properties of standard self-concordant barriers. This allows the algorithm to achieve the same regret guarantees as self-concordant FTRL while benefiting from the computational efficiency of FTPL-based approaches. The per-round complexity remains linear in d due to the sampling-based nature of the action selection process.

## Key Results
- Achieves O(d√(n lnn)) regret on both d-dimensional hypercube and Euclidean ball
- √d improvement over previous self-concordant FTRL methods on the hypercube
- Matches optimal regret bounds up to logarithmic factors
- Maintains O(d) per-round computational complexity

## Why This Works (Mechanism)
The SC-FTPL algorithm works by introducing perturbations that preserve the essential curvature properties of self-concordant barriers while enabling efficient sampling. The self-concordant perturbations are designed such that when added to cumulative loss estimates, they create an optimization landscape that mimics the behavior of self-concordant regularization. This allows the algorithm to benefit from the strong theoretical guarantees of self-concordant barriers while maintaining the computational efficiency of FTPL. The perturbations effectively trade off exploration and exploitation in a way that prevents the adversary from exploiting predictable patterns in the algorithm's behavior.

## Foundational Learning

**Self-concordant barriers**: Special functions used in optimization that have controlled curvature properties. Needed because they enable strong regret guarantees in bandit settings. Quick check: Verify that the barrier satisfies the self-concordance inequality |∇²f(x)[h,h]| ≤ 2∇f(x)[h] for all vectors h.

**Follow-the-Perturbed-Leader (FTPL)**: A bandit algorithm framework that adds random perturbations to cumulative losses before optimization. Needed because it provides computational efficiency compared to FTRL. Quick check: Confirm that perturbations are drawn from distributions with appropriate tail bounds.

**Adversarial linear bandits**: Online learning setting where losses are linear functions chosen by an adversary. Needed as the problem domain where the algorithm operates. Quick check: Verify that the action set is convex and compact.

**Regret bounds**: Measures of algorithm performance comparing cumulative loss to the best fixed action in hindsight. Needed to quantify the algorithm's effectiveness. Quick check: Confirm that the bound scales as O(d√(n lnn)) for the given problem parameters.

## Architecture Onboarding

**Component map**: Action set (hypercube/Euclidean ball) -> Self-concordant perturbations -> Cumulative loss estimation -> Linear optimization oracle -> Action selection

**Critical path**: The algorithm's performance critically depends on the quality of the self-concordant perturbations and the accuracy of the linear optimization oracle. The perturbation sampling step must be efficient to maintain O(d) complexity.

**Design tradeoffs**: The main tradeoff is between the theoretical strength of self-concordant regularization and the computational efficiency of FTPL. The self-concordant perturbations represent a compromise that preserves the key properties of self-concordant barriers while enabling efficient sampling.

**Failure signatures**: Poor performance may occur if the perturbations fail to adequately replicate self-concordant barrier properties, or if the linear optimization oracle is inaccurate. The algorithm may also suffer if the perturbation distributions have heavy tails or insufficient concentration.

**First experiments**: 1) Verify that self-concordant perturbations sample correctly and efficiently for d=10,50,100. 2) Test regret scaling on synthetic linear bandit problems with varying dimensions. 3) Compare SC-FTPL against standard FTPL and self-concordant FTRL on both hypercube and Euclidean ball domains.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical foundation for self-concordant perturbations lacks complete formal proofs
- Computational complexity analysis assumes efficient sampling that may be challenging in practice
- Performance guarantees rely on specific properties of the perturbation distributions that require further validation

## Confidence
- **High**: Regret bounds of O(d√(n lnn)) on both domains
- **Medium**: √d improvement over self-concordant FTRL on hypercube
- **Medium**: Computational complexity claims

## Next Checks
1. Implement the self-concordant perturbation sampling mechanism and measure actual runtime complexity for d=100-1000 to verify the claimed O(d) per-round complexity.
2. Conduct experiments comparing SC-FTPL against standard FTPL and self-concordant FTRL on synthetic linear bandit problems with varying dimensions (d=10, 50, 100) to empirically verify the √d improvement.
3. Develop a formal proof establishing that the proposed perturbation distributions preserve the key properties of self-concordant barriers when used in the FTPL framework.