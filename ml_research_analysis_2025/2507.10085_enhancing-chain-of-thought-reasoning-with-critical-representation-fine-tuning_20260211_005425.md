---
ver: rpa2
title: Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning
arxiv_id: '2507.10085'
source_url: https://arxiv.org/abs/2507.10085
tags:
- representations
- head
- layer
- critical
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving chain-of-thought
  reasoning in large language models by introducing Critical Representation Fine-Tuning
  (CRFT). CRFT identifies and optimizes critical representations through information
  flow analysis, focusing on representations that either integrate significant information
  from preceding layers or regulate subsequent layers.
---

# Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning

## Quick Facts
- arXiv ID: 2507.10085
- Source URL: https://arxiv.org/abs/2507.10085
- Reference count: 21
- Primary result: LLaMA-2-7B accuracy improved by 18.2% on GSM8K with only 0.016% of model parameters

## Executive Summary
This paper introduces Critical Representation Fine-Tuning (CRFT), a parameter-efficient method for improving chain-of-thought reasoning in large language models. CRFT identifies and optimizes critical representations through information flow analysis, focusing on representations that integrate significant information from preceding layers or regulate subsequent layers. The approach operates in a low-rank linear subspace while freezing the base model, achieving substantial accuracy improvements on arithmetic and commonsense reasoning benchmarks with minimal parameter overhead.

## Method Summary
CRFT identifies critical representations using attention and saliency scores, distinguishing between Self-Referential (high diagonal attention, indicating information accumulation) and Multi-Referential (high column average, indicating regulatory influence) representations. The method applies low-rank interventions exclusively to these critical representations through a learnable projection matrix and linear layer, freezing the base model. Training uses a batch size of 2 with gradient accumulation of 16, AdamW optimizer, learning rate of 9e-4, and linear decay schedule over 12 epochs for arithmetic and 6 epochs for commonsense tasks.

## Key Results
- LLaMA-2-7B accuracy improved by 18.2% on GSM8K benchmark
- One-shot accuracy improved by 16.4% on commonsense reasoning tasks
- Only 0.016% of model parameters are trainable during fine-tuning
- Early layer interventions (layers 0-15) outperform later layers for reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1: Critical Representation Identification via Information Flow
CRFT analyzes attention and saliency matrices to identify two types of critical representations: (1) **Self-referential** (high diagonal attention), indicating information accumulation, and (2) **Multi-referential** (high column average), indicating strong regulatory influence on subsequent tokens. The method assumes that representations dominating attention flow or self-accumulating information are causal bottlenecks for reasoning accuracy.

### Mechanism 2: Targeted Low-Rank Subspace Intervention
The method freezes the base model and applies a learnable intervention $\Phi(h) = h + R^T(Wh + b - Rh)$ exclusively to tokens identified as critical. This projects the representation into a low-rank subspace to learn an optimized update direction, operating under the assumption that reasoning corrections can be captured by linear transformations in a low-dimensional subspace of the hidden state.

### Mechanism 3: Attention Sink Mitigation and Flow Enrichment
By modifying critical representations, particularly in earlier layers, the model redistributes attention weights to reduce the dominance of the initial token ($h_0$) and foster broader, more relevant attention across the sequence. This addresses the "attention sink" phenomenon where excessive information concentrates in the first token, hindering complex reasoning capabilities.

## Foundational Learning

**Transformer Information Flow (Attention Mechanisms)**: Understanding how Query, Key, and Value matrices interact to form attention weights is essential since CRFT relies on interpreting these scores to locate "critical" tokens. *Quick check*: Can you explain how the softmax of $QK^T$ creates the attention matrix, and why high values on the diagonal (self-attention) might indicate information accumulation?

**Parameter-Efficient Fine-Tuning (PEFT) and ReFT**: CRFT modifies the base ReFT paradigm, requiring understanding of the distinction between weight tuning (LoRA) and representation tuning (ReFT). *Quick check*: What is the fundamental difference between adding an adapter to a weight matrix (LoRA) versus intervening on a hidden state vector (ReFT)?

**Saliency Maps**: The paper uses "saliency scores" (gradient × attention) as an alternative to raw attention for identifying critical representations. *Quick check*: How does multiplying the attention score by the gradient of the loss with respect to that score indicate the "importance" of a token to the final output?

## Architecture Onboarding

**Component map**: Base LLM (Frozen) → Identification Module → Intervention Module → Subspace Merger

**Critical path**: Input Sequence → Layer 0 Intervention (Highest Impact) → Intermediate Layers → Final Output. The paper notes that intervening in the first half of layers (0-15) yields better results than later layers, as earlier features propagate more effectively.

**Design tradeoffs**: 
- Thresholds (α, β): A threshold of 0.01 improves accuracy (more interventions) but increases computation; 0.05 is the default for efficiency.
- Identification Strategy: "Union" strategies capture more critical nodes but require maintaining a fixed budget of intervention parameters.

**Failure signatures**:
- Random Selection: If critical representations are selected randomly instead of by flow analysis, performance drops significantly (e.g., 32.1% critical vs. ~26% random on GSM8K).
- Over-intervention: Setting the number of intervention representations too high (e.g., >20) hinders learning the update direction.

**First 3 experiments**:
1. Baseline vs. Random: Compare CRFT (using SAF/MAF) against a version where interventions are placed at random token positions to validate the "critical" hypothesis.
2. Layer Ablation: Run the model intervening only on layers 0-15 vs. 16-31 vs. all layers to confirm the finding that earlier layers are more critical for reasoning.
3. Noise Sensitivity: Add small Gaussian noise (0.01) to the identified critical representations of the base model to observe the drop in accuracy, confirming their sensitivity.

## Open Questions the Paper Calls Out

**Open Question 1**: Can representations with negative impacts on reasoning be explicitly identified and prioritized for correction, rather than uniformly modifying all critical representations? The authors note that prioritizing correction of representations with negative impacts could be more effective, though identifying such representations remains challenging.

**Open Question 2**: Would non-linear optimization subspaces outperform the current low-rank linear subspace approach for representing critical representation updates? The paper suggests exploring alternative optimization methods beyond linear spaces to enhance the framework.

**Open Question 3**: Can CRFT be effectively combined with weight-based PEFT methods like LoRA for additive performance gains? The paper compares CRFT against LoRA as separate baselines but does not explore their combination, leaving open whether representation-level and weight-level interventions are complementary.

**Open Question 4**: What is the principled basis for selecting optimal thresholds (α and β) for identifying critical representations, beyond empirical tuning? The paper conducts ablation studies on threshold values but offers no theoretical justification for why certain values are optimal or how they might generalize across models and tasks.

## Limitations

- The method's performance on non-mathematical reasoning tasks is less pronounced compared to arithmetic benchmarks.
- Critical representation identification relies on fixed thresholds without sensitivity analysis, potentially making the method brittle to threshold selection.
- The assumption that reasoning corrections can be captured within a low-rank subspace is not empirically validated.

## Confidence

**High Confidence**:
- The core architectural design of CRFT (identifying critical representations via information flow and applying low-rank interventions) is clearly specified and reproducible.
- The efficiency claims (0.016% of parameters) are verifiable and directly tied to the methodology.
- The baseline comparison against random intervention selection is rigorous and supports the "critical" hypothesis.

**Medium Confidence**:
- The performance improvements on GSM8K (+18.2%) and few-shot learning (+16.4%) are impressive but rely on specific dataset construction choices (Math10K, Commonsense60K) that are incompletely specified.
- The attention sink mitigation mechanism is theoretically sound but lacks direct causal evidence linking critical representation editing to improved attention distribution.

**Low Confidence**:
- The extension to few-shot learning scenarios is promising but based on a single prompt template without ablation studies on different prompting strategies.
- The comparison with other PEFT methods (LoRA, PrefixTuning) could be more comprehensive, particularly regarding computational overhead during inference.

## Next Checks

1. **Threshold Sensitivity Analysis**: Systematically vary α and β (0.01, 0.05, 0.1) and measure the impact on both accuracy and computational cost to validate whether the chosen thresholds are optimal or if the method is sensitive to hyperparameter selection.

2. **Attention Distribution Verification**: Conduct controlled experiments where Gaussian noise is added to either critical or non-critical representations (identified via CRFT) to measure the differential impact on attention patterns and final accuracy, providing causal evidence for the attention sink mitigation claim.

3. **Cross-Domain Transfer Test**: Apply CRFT trained on Math10K to a completely different reasoning domain (e.g., logical reasoning or code generation) without further fine-tuning to test whether the method learns general reasoning capabilities or task-specific patterns.