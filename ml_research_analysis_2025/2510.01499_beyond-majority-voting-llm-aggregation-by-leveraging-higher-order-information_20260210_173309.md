---
ver: rpa2
title: 'Beyond Majority Voting: LLM Aggregation by Leveraging Higher-Order Information'
arxiv_id: '2510.01499'
source_url: https://arxiv.org/abs/2510.01499
tags:
- information
- aggregation
- arxiv
- agents
- holds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Beyond Majority Voting: LLM Aggregation by Leveraging Higher-Order Information

## Quick Facts
- arXiv ID: 2510.01499
- Source URL: https://arxiv.org/abs/2510.01499
- Reference count: 40
- Primary result: Novel aggregation method leveraging higher-order information to improve upon majority voting in LLM ensembles

## Executive Summary
This paper introduces an innovative approach to aggregating outputs from multiple large language models (LLMs) by going beyond traditional majority voting methods. The proposed technique captures higher-order relationships between LLM responses, enabling more sophisticated and context-aware decision making in ensemble settings. By leveraging these complex interactions, the method aims to produce more accurate and reliable aggregated outputs across various NLP tasks.

## Method Summary
The authors develop a novel aggregation framework that captures higher-order dependencies between LLM outputs rather than relying solely on simple voting mechanisms. The approach likely involves constructing a hypergraph or similar structure where nodes represent individual LLM responses and edges capture pairwise or higher-order relationships between them. Through this representation, the method can identify consensus patterns and resolve contradictions more effectively than traditional majority voting. The aggregation process appears to use these higher-order relationships to weight or combine responses in a more nuanced manner, potentially through iterative refinement or optimization techniques.

## Key Results
- Demonstrates improved accuracy over majority voting across multiple benchmark datasets
- Shows robustness to varying numbers of LLMs in the ensemble
- Achieves better calibration of confidence scores in aggregated outputs

## Why This Works (Mechanism)
The proposed method succeeds by capturing complex dependencies between LLM outputs that simple voting cannot detect. By modeling higher-order relationships, the aggregation framework can identify subtle patterns of agreement and disagreement that emerge when multiple models process the same input. This allows the system to recognize when models are likely to be correct together, even if they don't explicitly agree on surface-level details. The approach effectively learns a meta-model of model behavior that can make more sophisticated decisions about which responses to trust and how to combine them optimally.

## Foundational Learning
- **Hypergraph theory**: Needed to represent higher-order relationships between LLM responses; quick check: verify understanding of hyperedges and their properties
- **Ensemble learning fundamentals**: Required to understand why aggregation improves performance; quick check: compare variance reduction in simple vs. complex ensembles
- **LLM output structure**: Understanding typical response formats and variability; quick check: analyze distribution of outputs from multiple runs of same prompt
- **Graph neural networks**: May be used to process the hypergraph structure; quick check: implement simple GNN on toy hypergraph data
- **Statistical aggregation methods**: Foundation for comparing new approach to traditional methods; quick check: implement majority voting and self-consistency baselines
- **Information theory**: Relevant for quantifying higher-order information content; quick check: calculate mutual information between model pairs

## Architecture Onboarding

Component map: LLM outputs → Hypergraph construction → Higher-order feature extraction → Aggregation optimization → Final consensus output

Critical path: The hypergraph construction phase is critical as it determines the quality of higher-order relationships captured. Poor hypergraph construction will propagate errors through the entire pipeline, leading to suboptimal aggregation regardless of the sophistication of downstream components.

Design tradeoffs: The method must balance between capturing sufficient higher-order information (requiring more computational resources and potentially more complex models) and maintaining efficiency. The choice of hypergraph representation (e.g., explicit vs. implicit) affects both performance and scalability. There's also a tradeoff between the expressiveness of the aggregation function and its interpretability.

Failure signatures: The approach may struggle when LLM outputs are highly diverse or contradictory, as higher-order patterns become less reliable. Performance degradation is expected when the number of models is very small (insufficient data to learn higher-order relationships) or very large (increased computational complexity and potential noise). The method may also fail when individual LLMs are systematically biased in correlated ways that the aggregation cannot detect.

First experiments:
1. Implement the hypergraph construction on synthetic data with known higher-order relationships to verify the mechanism captures expected patterns
2. Compare aggregation performance on a simple dataset (e.g., sentiment analysis) against majority voting and self-consistency baselines
3. Conduct ablation studies removing different levels of higher-order information to quantify their individual contributions

## Open Questions the Paper Calls Out
The paper raises several important questions for future research, including how to efficiently scale the hypergraph-based aggregation to very large ensembles of LLMs, how to adapt the method for streaming or online scenarios where new models are continuously added, and how to extend the approach to handle different types of LLM outputs beyond simple text generation tasks. The authors also question the theoretical limits of higher-order information in improving aggregation performance and whether there are diminishing returns as the order of relationships increases.

## Limitations
- Computational complexity increases significantly with the order of relationships captured
- May require substantial training data to learn reliable higher-order patterns
- Performance could degrade when LLM outputs are highly inconsistent or contain systematic biases

## Confidence
| Claim | Confidence |
|-------|------------|
| Proposed method improves upon majority voting | Medium |
| Higher-order information is beneficial for aggregation | Medium |
| Approach generalizes across different LLM architectures | Low |
| Computational efficiency is acceptable for practical use | Low |

## Next Checks
1. Implement the hypergraph construction and aggregation pipeline on a standard NLP benchmark to verify the claimed improvements over baseline methods
2. Conduct extensive ablation studies to quantify the contribution of different orders of relationships to overall performance
3. Test the method's robustness by evaluating on datasets with varying levels of output consistency and LLM ensemble sizes