---
ver: rpa2
title: 'ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students'' Cognitive
  Abilities'
arxiv_id: '2508.14377'
source_url: https://arxiv.org/abs/2508.14377
tags:
- llms
- reading
- wdbi
- educational
- difficulty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces ZPD-SCA, a benchmark for evaluating LLMs'
  ability to align reading materials with students' cognitive development stages.
  The benchmark, annotated by 60 "Special Grade" teachers, assesses whether LLMs can
  accurately classify Chinese texts into elementary, middle, and high school difficulty
  levels.
---

# ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities

## Quick Facts
- arXiv ID: 2508.14377
- Source URL: https://arxiv.org/abs/2508.14377
- Reference count: 40
- Primary result: LLMs show substantial performance gaps in zero-shot classification of Chinese texts by cognitive difficulty, but improve significantly with in-context examples

## Executive Summary
This study introduces ZPD-SCA, a benchmark for evaluating LLMs' ability to align reading materials with students' cognitive development stages. The benchmark, annotated by 60 "Special Grade" teachers, assesses whether LLMs can accurately classify Chinese texts into elementary, middle, and high school difficulty levels. Experiments reveal that LLMs perform poorly in zero-shot scenarios, with some models even scoring below random guessing. However, performance improves significantly with in-context learning, indicating that task-specific training is needed rather than inherent capability issues. The study highlights limitations in current LLMs' ability to assess text difficulty aligned with student cognitive abilities and provides a foundation for improving educationally aligned LLM applications.

## Method Summary
The study evaluates 10 LLMs on the ZPD-SCA benchmark, a dataset of 4.7M Chinese characters across 12 genres, annotated by 60 "Special Grade" teachers (top 0.15% nationwide). Each text is reviewed by ≥20 annotators. The task involves three-way classification of texts into elementary, middle, or high school difficulty levels based on cognitive alignment. Two evaluation settings are used: Zero-shot (ZP) with task description only, and In-Context Learning (CL) with 2 elementary examples. Metrics include Accuracy, F1, CLME (Cross-Level Migration Concentration), and WDBI (Weighted Directional Bias Index). Fine-tuning is conducted on Qwen32B using LoRA with rank=32, learning rate=5e-4, batch size=8, for 5 epochs.

## Key Results
- Zero-shot accuracy ranges from 31.3% to 82.8%, with many models performing below random guessing (33%)
- In-context learning improves performance substantially, with F1 scores increasing from 0.53 to 0.86 on average
- Models exhibit systematic directional bias, typically overestimating text difficulty relative to student ability
- Fine-tuning reduces bias closer to zero (WDBI from -0.0502) while maintaining high accuracy
- Error analysis reveals challenges in assessing "Thematic Depth" and "Logical Reasoning" even with in-context examples

## Why This Works (Mechanism)

### Mechanism 1: Latent Capability Activation via Context
LLMs possess latent knowledge about text complexity and cognitive alignment, but require in-context examples to bridge the gap between general language understanding and educational specificity. Zero-shot prompting fails to trigger the specific "educator persona" or cognitive mapping required. Providing in-context examples acts as a calibration signal, aligning the model's internal probability space with the specific boundaries of student cognitive stages.

### Mechanism 2: Semantic-Cognitive Decoupling
LLMs rely heavily on semantic similarity and surface-level linguistic features, failing to decouple these from the deeper cognitive demands required by the ZPD framework. The embedding space shows semantic overlap between Middle and High school texts, but models struggle to distinguish these levels because they conflate "semantic similarity" with "cognitive difficulty."

### Mechanism 3: Directional Bias Calibration
Models exhibit a systematic "directional bias," typically overestimating text difficulty relative to student ability, which is mitigated by exposing the model to the distribution of human cognitive norms via examples. Pre-training on vast, complex internet data shifts the model's baseline for "simple" text, and in-context learning provides a reference frame for "what a 10-year-old can understand."

## Foundational Learning

- **Concept: Zone of Proximal Development (ZPD)**
  - Why needed: The ZPD-SCA benchmark is built explicitly on this educational theory. Without understanding ZPD (the gap between what a student can do alone vs. with help), the task of "aligning text difficulty" is just text classification, not cognitive assessment.
  - Quick check: Does the model treat "difficulty" as a static text property, or as a relationship between the text and a specific student's developmental stage?

- **Concept: In-Context Learning (ICL) vs. Zero-Shot**
  - Why needed: The paper's central finding is the massive performance delta between these two modes. An engineer must understand that ICL here isn't just "improving accuracy," but "unlocking" the specific SCA mapping capability.
  - Quick check: If you run the same prompt with 0 examples vs. 2 examples, do you expect the model's reasoning to change, or just its confidence? (The paper suggests the reasoning/capability changes).

- **Concept: Weighted Directional Bias Index (WDBI)**
  - Why needed: Standard metrics like Accuracy hide how the model fails. WDBI reveals if the system is systematically undervaluing student intelligence (overestimating difficulty), a critical failure mode for educational tools.
  - Quick check: If a model has 60% accuracy but a high positive WDBI, is it "safe" to deploy in a classroom? (No, it might constantly recommend materials that are too simple).

## Architecture Onboarding

- **Component map:** Ground Truth (ZPD-SCA Dataset) → Input (Chinese text segments) → Model Layer (LLMs) → Prompting Strategy (ZP vs CL) → Evaluation (Accuracy/F1, CLME, WDBI)

- **Critical path:**
  1. Data Prep: Sampling texts and ensuring strict agreement from 60 expert annotators
  2. Prompt Engineering: Designing ZP and CL templates (iterative refinement using GPT-4o/Qwen-max)
  3. Inference: Running 3-way classification (Elementary/Middle/High)
  4. Metric Calc: Calculating WDBI to check for directional bias

- **Design tradeoffs:**
  - Generalizability vs. Specificity: General LLMs (GPT-4o) struggle with nuance of Chinese educational stages compared to specific models (Qwen) or fine-tuned smaller models
  - Cost vs. Performance: Annotating with top 0.15% teachers is expensive but creates high-trust benchmark
  - Prompt Complexity: Adding examples (CL) is more effective than complex zero-shot instructions for this task

- **Failure signatures:**
  - Random Guessing: Accuracy ~33% in 3-class task (seen in GLM/Qwen-max Zero-Shot)
  - Mode Collapse: Predicting "Middle School" for nearly all inputs (observed in GLM Zero-Shot)
  - Overestimation: High positive WDBI (labeling simple texts as "High School")

- **First 3 experiments:**
  1. Baseline Establishment: Run Qwen-max or GLM in Zero-Shot mode to verify if accuracy is below random guessing
  2. CL Sensitivity Test: Add 2 elementary-level examples and measure delta in WDBI to see if model corrects overestimation bias
  3. Semantic vs. Cognitive Probe: Use separate embedding model to check semantic overlap of misclassified samples

## Open Questions the Paper Calls Out

1. **How can pre-training or fine-tuning data be optimized to internalize cognitive alignment, reducing the models' reliance on in-context examples?**
   - Basis: The Discussion section states that "addressing this issue remains an open challenge" and necessitates "focused training approaches"
   - Why unresolved: Current LLMs lack sufficient exposure to educational tasks during pre-training
   - What evidence would resolve it: Demonstrating high zero-shot accuracy on cognitive alignment tasks comparable to few-shot baselines

2. **What specific training strategies are required to improve LLM assessment of "Thematic Depth" and "Logical Reasoning"?**
   - Basis: Analysis notes that in-context learning "falls short in addressing... Thematic Depth and Logical Reasoning"
   - Why unresolved: Current prompting techniques successfully mitigate errors in "Emotional Complexity" but fail to correct deeper comprehension errors
   - What evidence would resolve it: Significant reduction in error rates for these specific categories following targeted intervention

3. **Can the systematic "directional bias" (tendency to overestimate text difficulty) be eliminated while maintaining high classification accuracy?**
   - Basis: The paper highlights that even top models display "systematic directional biases"
   - Why unresolved: Models may rely on superficial complexity features rather than modeling the student's Zone of Proximal Development
   - What evidence would resolve it: A WDBI score approaching zero alongside high F1 scores across all evaluated genres

## Limitations

- **Dataset Dependency and Generalizability**: The ZPD-SCA benchmark relies on expert annotations from a specific cultural context (Chinese educational system), limiting generalizability to other educational systems or languages.
- **Prompt Engineering Opacity**: The paper doesn't provide final prompt templates, creating a reproducibility gap that could affect interpretation of performance differences.
- **Model Selection Bias**: Focus on Chinese-language models may limit conclusions about LLMs broadly, as performance differences between models suggest model-specific factors rather than universal LLM limitations.

## Confidence

- **High Confidence**: The empirical finding that LLMs perform significantly better with in-context examples than zero-shot is well-supported by the data.
- **Medium Confidence**: The interpretation that performance improvement stems from "latent capability activation" rather than learned reasoning is plausible but not definitively proven.
- **Low Confidence**: The claim that current LLMs have fundamental "blind spots" in educational assessment is overstated, as performance can be substantially improved through relatively simple in-context learning.

## Next Checks

1. **Cross-Cultural Transfer Validation**: Test whether models trained on or evaluated with ZPD-SCA can generalize to reading difficulty assessment in other educational systems (e.g., US Common Core standards or European CEFR framework).

2. **Prompt Ablation Study**: Systematically vary the number and selection of in-context examples to determine the minimum effective prompt configuration and test whether the performance gain comes from specific example content or simply the presence of any examples.

3. **Fine-Tuning Generalization Test**: Conduct extensive fine-tuning with varying dataset sizes and evaluate on held-out test sets from different genres and difficulty distributions to determine whether observed improvements are robust or overfit to the specific ZPD-SCA distribution.