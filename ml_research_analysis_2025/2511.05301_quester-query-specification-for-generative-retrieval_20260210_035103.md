---
ver: rpa2
title: 'QUESTER: Query Specification for Generative Retrieval'
arxiv_id: '2511.05301'
source_url: https://arxiv.org/abs/2511.05301
tags:
- query
- retrieval
- arxiv
- quester
- bm25
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach for generative retrieval
  that reframes the problem as query specification generation, where a lightweight
  LLM generates keyword queries for a BM25 search engine. The method, called QUESTER,
  is trained using reinforcement learning (GRPO) with a reward based on SoftNDCG and
  cross-encoder assessments.
---

# QUESTER: Query Specification for Generative Retrieval

## Quick Facts
- arXiv ID: 2511.05301
- Source URL: https://arxiv.org/abs/2511.05301
- Reference count: 16
- Primary result: QUESTER improves BM25 by +4.0 nDCG@10 in-domain and +5.3 out-of-domain using a 4B LLM with ≈28ms latency

## Executive Summary
This paper introduces QUESTER, a novel approach to generative retrieval that reframes the problem as query specification generation. Rather than directly generating ranked document lists, QUESTER uses a lightweight LLM to generate keyword queries that are then processed by a BM25 search engine. The model is trained using reinforcement learning with a reward based on SoftNDCG and cross-encoder assessments. Results show significant improvements over BM25 baseline and competitive performance with larger models while maintaining strong efficiency (≈28ms per query).

## Method Summary
QUESTER treats generative retrieval as a query specification generation task where a lightweight LLM generates keyword queries for a BM25 search engine. The approach uses reinforcement learning (specifically GRPO) to optimize the query generator, with rewards computed from SoftNDCG scores using a cross-encoder to assess document relevance. The model balances effectiveness and efficiency by leveraging the strengths of both generative models and traditional IR methods. Training involves generating multiple query candidates per input and selecting the best-performing one based on the reward signal.

## Key Results
- QUESTER improves BM25 by +4.0 nDCG@10 in-domain and +5.3 out-of-domain
- 4B model achieves highest average nDCG@10 (45.5) while maintaining ≈28ms latency
- Outperforms larger models in latency while remaining competitive on effectiveness
- Strong zero-shot performance across multiple datasets

## Why This Works (Mechanism)
QUESTER works by decomposing the generative retrieval problem into two stages: query generation and document retrieval. The lightweight LLM generates query specifications that are optimized for BM25's term-matching mechanism rather than directly predicting relevance scores. This decomposition allows the model to leverage BM25's efficiency and proven effectiveness while the LLM focuses on generating discriminative query terms. The reinforcement learning framework with SoftNDCG reward enables optimization of ranking quality rather than just individual document relevance.

## Foundational Learning
- **SoftRank**: Differentiable approximation of ranking metrics that enables gradient-based optimization - needed for training with ranking objectives, quick check: verify ν parameter tuning
- **GRPO (Group Relative Policy Optimization)**: Reinforcement learning variant for optimizing generation policies - needed for training query generator, quick check: examine batch size effects
- **Cross-encoder architecture**: Model that jointly encodes query-document pairs for relevance assessment - needed for reward computation, quick check: test different cross-encoder sizes
- **KL regularization**: Prevents mode collapse in RL training by encouraging diversity - needed for stable training, quick check: tune β weight

## Architecture Onboarding

**Component Map**: Input Text -> Query Generator (LLM) -> BM25 Engine -> Ranked List -> Cross-Encoder -> SoftNDCG Reward -> GRPO Update

**Critical Path**: Query generation → BM25 retrieval → cross-encoder scoring → SoftNDCG computation → GRPO update

**Design Tradeoffs**: 
- Uses lightweight LLM for efficiency vs. larger models for potentially better generation
- Two-stage approach trades direct optimization for proven retrieval baseline
- Reinforcement learning vs. supervised learning for better alignment with ranking metrics

**Failure Signatures**:
- Poor query generation leading to low BM25 recall
- Mode collapse in query generation due to insufficient KL regularization
- Reward hacking if cross-encoder is poorly calibrated

**First Experiments**:
1. Test query generation quality by comparing generated queries to human-written ones
2. Evaluate BM25 retrieval quality with ground-truth queries vs. generated queries
3. Measure sensitivity to ν parameter in SoftNDCG reward computation

## Open Questions the Paper Calls Out
None specified in the provided material.

## Limitations
- SoftNDCG reward depends heavily on ν parameter tuned per dataset without clear theoretical justification
- Cross-encoder reward introduces black-box dependency that may not generalize to new domains
- Zero-shot evaluation limited to IR community benchmarks, leaving real-world applicability uncertain
- GRPO implementation uses small batch sizes (8 queries) that may limit exploration

## Confidence

**Effectiveness improvements**: High - consistent results across multiple datasets with statistical significance
**Efficiency claims**: Medium - clear latency measurements but limited hardware details
**Generalizability to non-IR domains**: Low - limited evaluation scope, cross-encoder reward may not transfer well

## Next Checks
1. Test cross-domain generalization by evaluating on non-IR corpora (e.g., medical literature, legal documents) with different query distributions and vocabulary
2. Compare reward computation using different cross-encoder architectures (varying sizes, training objectives) to assess robustness to this critical component
3. Implement and measure on CPU-only inference to validate the claimed efficiency advantages for deployment scenarios without GPU access