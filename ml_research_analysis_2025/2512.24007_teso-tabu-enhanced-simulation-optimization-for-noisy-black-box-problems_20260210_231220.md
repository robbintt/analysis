---
ver: rpa2
title: TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems
arxiv_id: '2512.24007'
source_url: https://arxiv.org/abs/2512.24007
tags:
- teso
- simulation
- optimization
- memory
- tabu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TESO, a Tabu-Enhanced Simulation Optimization
  framework designed for noisy black-box problems. TESO combines short-term Tabu List
  memory to prevent cycling and encourage diversification, with long-term Elite Memory
  to guide intensification by perturbing high-performing solutions.
---

# TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems

## Quick Facts
- arXiv ID: 2512.24007
- Source URL: https://arxiv.org/abs/2512.24007
- Authors: Bulent Soykan; Sean Mondesire; Ghaith Rabadi
- Reference count: 30
- Key outcome: TESO achieved best mean objective 2.53 on M/M/3 queue, outperforming PRS (4.11), TESO-noElite (2.89), and TESO-noTabu (2.72)

## Executive Summary
TESO introduces a Tabu-Enhanced Simulation Optimization framework specifically designed for noisy black-box problems where objective function evaluations are stochastic. The method combines short-term Tabu List memory to prevent cycling and encourage diversification with long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. Evaluated on an M/M/3 queue optimization problem with 300 trials and 30 simulation replications per evaluation, TESO demonstrated superior performance with mean objective 2.53, lowest standard deviation (0.07), and consistent convergence across runs.

## Method Summary
TESO operates by maintaining two memory structures: a Tabu List (capacity 15) storing recently evaluated candidates to prevent cycling, and an Elite Memory (capacity 10) storing top-performing solutions for intensification. The algorithm generates candidates through either diversification (random sampling) or intensification (perturbing elite solutions with decaying noise η from 0.2 to 0.01). Each candidate undergoes n_rep=30 simulation replications to estimate mean performance. The tabu check uses hashable representations, while aspiration allows exceptional candidates to override restrictions. The method terminates after budget exhaustion or 50 consecutive iterations without improvement.

## Key Results
- TESO achieved best mean objective value of 2.53 on M/M/3 queue problem
- TESO demonstrated lowest standard deviation (0.07) indicating superior reliability
- Ablation studies showed each component's value: TESO-noTabu (2.72), TESO-noElite (2.89), PRS (4.11)

## Why This Works (Mechanism)

### Mechanism 1: Tabu List prevents cycling and promotes diversification
The Tabu List stores hashable representations of recently evaluated candidates (capacity 15). Before evaluation, candidates are checked against the list; if present and not meeting aspiration, they're skipped. This forces exploration of new regions rather than re-evaluating noisy variations. Assumes cycling is detrimental in stochastic environments where noise can mislead search. Evidence: TESO achieved 2.53 vs TESO-noTabu's 2.72 with lower std (0.07 vs 0.16).

### Mechanism 2: Elite Memory enables guided intensification
Elite Memory stores candidate-performance pairs (x, μ) with capacity 10. During intensification, elite solutions are selected and perturbed using adaptive noise η. This concentrates computational budget on refining promising regions. Assumes mean estimates from 30 replications are reliable for identifying high-performing regions. Evidence: TESO achieved 2.53 vs TESO-noElite's 2.89; std 0.07 vs 0.21.

### Mechanism 3: Aspiration criterion preserves solution quality
When a candidate's hash is in the Tabu List, the algorithm checks if it significantly improves upon f_best. If yes, tabu restriction is overridden. This prevents discarding genuinely superior solutions due to administrative blocking. Assumes aspiration correctly identifies exceptional candidates despite noise. Evidence: Aspiration mechanism implemented in Algorithm 1, line 11.

## Foundational Learning

- **Simulation Optimization (SO) fundamentals**: TESO operates on J(x) = E_ω[f(x, ω)] where f(x, ω) is stochastic. Understanding single replications provide only noisy estimates explains why TESO uses n_rep=30 and mean-based comparisons. Quick check: If you run a simulation once at x₁ and get 3.2, then run it again and get 3.8, which value represents J(x₁)?

- **Exploration vs. Exploitation trade-off**: TESO's dual-memory architecture explicitly manages this: Tabu List forces exploration by blocking recent solutions; Elite Memory drives exploitation by perturbing good solutions. Quick check: What would happen if TESO only used Elite Memory with no Tabu List?

- **Tabu Search principles**: TESO adapts deterministic TS concepts (tabu tenure, aspiration) to stochastic settings. Standard TS assumes deterministic evaluations; TESO redefines "best move" and "aspiration" to operate on noisy mean estimates. Quick check: Why can't standard Tabu Search be directly applied to problems where f(x, ω) varies randomly each evaluation?

## Architecture Onboarding

- **Component map**: Initialization -> Candidate Generation -> Tabu Check -> Stochastic Evaluation -> Memory Updates -> Adaptive Control
- **Critical path**: 1) Generate candidate (diversification/intensification), 2) Tabu/aspiration filtering, 3) Stochastic evaluation (n_rep simulations), 4) Update f_best, T, E, 5) Adapt η and check termination
- **Design tradeoffs**: Tabu capacity C_T=15 (larger increases diversification but may block good regions), Elite capacity C_E=10 (larger preserves diversity, smaller focuses exploitation), Replications n_rep=30 (higher reliability vs budget consumption)
- **Failure signatures**: Cycling without progress (increase C_T), Stagnation (increase p_div or check E updates), High variance (increase n_rep or tighten aspiration), Slow convergence (adjust η decay schedule)
- **First 3 experiments**: 1) Baseline replication on M/M/3 to verify ~2.53 mean objective, 2) Ablation validation to confirm performance gaps, 3) Noise sensitivity test reducing n_rep to measure degradation

## Open Questions the Paper Calls Out

- **Generalizability to complex landscapes**: Future work must test TESO on problems with higher dimensions and multimodality since current experiments were limited to a single, unimodal problem class. What evidence would resolve it: Empirical results from testing TESO on standard multimodal benchmark functions or complex simulation models with high decision variable counts.

- **Adaptive parameter tuning**: Developing adaptive mechanisms for internal parameters like Tabu List capacity to reduce manual tuning sensitivity. What evidence would resolve it: A comparative study showing adaptive variant achieves statistically similar or better results than fixed-parameter version across diverse problems without manual tuning.

- **Hybridization with surrogate models**: Exploring integration with surrogate models to improve convergence speed for computationally expensive simulations. What evidence would resolve it: Implementation of TESO-Surrogate hybrid demonstrating reduced computational budget requirements to reach specific error thresholds compared to standard TESO.

## Limitations

- Sparse validation beyond single benchmark problem limits generalizability claims
- No characterization of parameter sensitivity across problem variations
- Minimal related work on tabu mechanisms in noisy SO limits comparative validation

## Confidence

- **High Confidence**: Ablation study results showing TESO outperforming variants are internally consistent and demonstrate integrated memory architecture's value within tested problem domain
- **Medium Confidence**: Mechanism descriptions are logically coherent but specific implementations lack sufficient detail for complete verification
- **Low Confidence**: Claims about broad applicability to "noisy black-box problems" are weakly supported given validation on only one benchmark

## Next Checks

1. **Cross-problem validation**: Test TESO on at least two additional noisy black-box problems (different queueing systems, noisy continuous optimization benchmarks) to assess generalizability beyond M/M/3

2. **Parameter sensitivity analysis**: Systematically vary C_T, C_E, and n_rep to identify robust operating regions and quantify trade-offs between exploration/exploitation and computational budget

3. **Noisy simulation fidelity study**: Vary simulation replication count (n_rep = 10, 20, 30, 50) to empirically determine minimum required for reliable mean estimation given specific noise characteristics of M/M/3 problem