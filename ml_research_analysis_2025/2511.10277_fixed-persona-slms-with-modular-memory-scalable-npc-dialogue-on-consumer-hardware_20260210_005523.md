---
ver: rpa2
title: 'Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer
  Hardware'
arxiv_id: '2511.10277'
source_url: https://arxiv.org/abs/2511.10277
tags:
- memory
- dialogue
- small
- knowledge
- latency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a modular NPC dialogue system using small language
  models (SLMs) fine-tuned with fixed personas and paired with runtime-swappable memory
  modules. The system enables multiple distinct NPC instances from a single model,
  preserving character identity while supporting long-term context and knowledge retrieval.
---

# Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware

## Quick Facts
- arXiv ID: 2511.10277
- Source URL: https://arxiv.org/abs/2511.10277
- Authors: Martin Braas; Lukas Esterle
- Reference count: 7
- Single model with modular memory achieves 93% factual accuracy, 100% context retention, and 100% world knowledge retrieval for NPC dialogue

## Executive Summary
This paper introduces a modular NPC dialogue system that combines small language models (SLMs) fine-tuned with fixed personas and runtime-swappable memory modules. The architecture enables multiple distinct NPC instances from a single model while preserving character identity and supporting long-term context and knowledge retrieval. The system was evaluated across three open-source SLMs (DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct) with synthetic persona datasets, demonstrating real-time performance on consumer hardware.

## Method Summary
The system uses SLMs fine-tuned with fixed personas, paired with runtime-swappable memory modules for long-term context and knowledge retrieval. Multiple NPC instances are supported through modular memory architecture, where memory swaps and retrievals occur in under 0.03s and 0.042s respectively. The evaluation tested three different SLMs with synthetic datasets to assess factual accuracy, context retention, and world knowledge retrieval capabilities.

## Key Results
- Mistral-7B-Instruct achieved 93% factual accuracy, 100% context retention, and 100% world knowledge retrieval
- Memory swaps completed in under 0.03 seconds and retrievals in under 0.042 seconds
- System validated on consumer hardware with negligible grammar errors

## Why This Works (Mechanism)
The modular memory architecture enables runtime swapping of persona-specific knowledge while maintaining a single fine-tuned SLM base model. This separation allows for efficient memory management and context preservation across different NPC instances. The fixed-persona training ensures character consistency, while the modular memory provides scalable long-term knowledge storage without requiring model retraining.

## Foundational Learning
- SLM fine-tuning with fixed personas: Required for character identity preservation across dialogue sessions; verified by consistent persona adherence in test scenarios
- Runtime memory swapping: Enables multiple NPC instances from single model; validated by sub-0.03s swap times
- Context retention mechanisms: Maintains dialogue history without model retraining; confirmed through 100% retention metrics
- World knowledge retrieval: Supports NPC-specific knowledge bases; demonstrated by 100% retrieval accuracy
- Consumer hardware optimization: Ensures real-time performance; evidenced by low-latency operations
- Modular memory architecture: Separates persona knowledge from base model; tested through successful multi-NPC deployment

## Architecture Onboarding

Component Map:
Fine-tuned SLM -> Modular Memory Interface -> Runtime Memory Manager -> Context Storage
                                                                     -> Knowledge Base

Critical Path:
Memory request → Memory manager lookup → Context/knowledge retrieval → SLM context injection → Response generation

Design Tradeoffs:
- Model size vs. response quality (Mistral-7B-Instruct provided best balance)
- Memory module size vs. retrieval speed
- Persona specificity vs. model generalization

Failure Signatures:
- Slow response times (>0.05s) indicating memory bottleneck
- Inconsistent persona adherence suggesting inadequate fine-tuning
- Memory leaks or corruption from improper module swapping

First Experiments:
1. Single NPC dialogue with memory retrieval timing measurement
2. Multi-NPC context switching validation
3. Memory module stress test with rapid swaps

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Evaluation limited to three specific SLMs and synthetic datasets
- No testing of long-term memory stability over extended gameplay sessions
- Performance metrics may vary under real-world hardware and workload conditions

## Confidence

High confidence in:
- Technical feasibility of runtime memory swapping and retrieval on consumer hardware

Medium confidence in:
- Factual accuracy and context retention metrics under controlled evaluation setup

Low confidence in:
- Long-term memory stability and cross-scenario generalizability claims

## Next Checks
1. Test system with additional SLM architectures and larger, more diverse datasets to assess performance bounds
2. Conduct long-duration gameplay simulations to evaluate memory module stability and potential degradation over time
3. Deploy system in real game environment with multiple concurrent NPCs to measure performance under realistic hardware and workload conditions