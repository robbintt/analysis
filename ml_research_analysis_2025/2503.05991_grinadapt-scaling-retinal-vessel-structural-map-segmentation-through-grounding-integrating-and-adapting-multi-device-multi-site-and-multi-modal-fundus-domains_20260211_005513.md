---
ver: rpa2
title: 'GrInAdapt: Scaling Retinal Vessel Structural Map Segmentation Through Grounding,
  Integrating and Adapting Multi-device, Multi-site, and Multi-modal Fundus Domains'
arxiv_id: '2503.05991'
source_url: https://arxiv.org/abs/2503.05991
tags:
- grinadapt
- domains
- images
- label
- octa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the problem of generalizing deep learning models
  for retinal vessel segmentation across multiple imaging devices, sites, and modalities.
  The proposed GrInAdapt framework addresses this by leveraging multi-view images
  through three steps: grounding images via registration, integrating predictions
  to refine labels, and adapting the source model using a teacher-student framework.'
---

# GrInAdapt: Scaling Retinal Vessel Structural Map Segmentation Through Grounding, Integrating and Adapting Multi-device, Multi-site, and Multi-modal Fundus Domains

## Quick Facts
- arXiv ID: 2503.05991
- Source URL: https://arxiv.org/abs/2503.05991
- Reference count: 40
- Primary result: Achieves 4% Dice score increase and 0.42 ASSD reduction over state-of-the-art domain adaptation methods

## Executive Summary
This paper presents GrInAdapt, a framework for generalizing deep learning models for retinal vessel segmentation across multiple imaging devices, sites, and modalities. The approach addresses the challenge of domain shift by leveraging multi-view images through a three-step process: grounding images via registration to a common anchor space, integrating predictions from complementary views to refine labels, and adapting the source model using a teacher-student framework. Experiments on a large-scale multi-device, multi-site, and multi-modal dataset demonstrate significant performance improvements over existing domain adaptation methods, with consistent gains across different sites and resolutions.

## Method Summary
GrInAdapt addresses source-free multi-target domain adaptation for retinal vessel segmentation by first registering multi-view images to a common anchor space using vessel probability maps, then integrating predictions from complementary modalities through region-specific averaging, and finally adapting the source model via a teacher-student framework with EMA updates. The method leverages 3D Res-UNet with IPN v2 architecture, trains for 3 epochs on integrated pseudo-labels, and handles 5 target domains from the AI-READI dataset. The integration step selectively excludes certain modalities (like CFP in the Macula region) to avoid artifacts, while the adaptation phase uses a cosine-weighted loss schedule that gradually shifts from integrated labels to teacher confidence.

## Key Results
- Achieves 4% Dice score increase and 0.42 ASSD reduction compared to state-of-the-art domain adaptation methods
- Maintains consistent performance improvements across different sites and imaging resolutions
- Successfully handles multi-modal data integration with specific rules for Macula, Optic Disc, and Other regions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Aligning multi-view target images to a common anchor space via registration enables aggregation of structural information across devices with different resolutions and fields-of-view.
- **Mechanism:** Uses predicted binary vessel probability maps to estimate affine transformations that map "moving" images to an "anchor" image, normalizing coordinate space to align 6x6mm scans with 12x12mm scans.
- **Core assumption:** Source model's predicted vessel masks are sufficiently accurate to serve as anatomical structure proxies during registration.
- **Evidence anchors:** Abstract mentions "grounding images to a common anchor space via registration"; Section 3.1 details using predicted binary vessel probability maps for registration.
- **Break condition:** Initial source model predictions too noisy or structurally erroneous, causing registration failure.

### Mechanism 2
- **Claim:** Region-wise integration of predictions reduces modality-specific artifacts by averaging them out using complementary views.
- **Mechanism:** Divides retina into three regions (Macula, Optic Disc, Other) and selectively averages predictions from specific modalities for each region.
- **Core assumption:** Imaging artifacts and noise are uncorrelated across different devices or modalities, allowing averaging to suppress random noise while reinforcing true vessel signal.
- **Evidence anchors:** Abstract states "integrating predictions to refine labels"; Section 3.2 describes region-specific inclusion/exclusion logic.
- **Break condition:** All available views for a subject suffer from the same systematic artifact, preventing noise removal through averaging.

### Mechanism 3
- **Claim:** Dynamic teacher-student adaptation loop allows self-correction by treating integrated labels as high-quality pseudo-ground truth.
- **Mechanism:** Initializes student model with source weights, uses integrated labels as pseudo-supervisor while teacher model (EMA of student) provides consistency regularization.
- **Core assumption:** Integrated label is significantly closer to ground truth than source model's raw prediction.
- **Evidence anchors:** Abstract mentions "adapting the source model using a teacher-student framework"; Section 3.3 describes loss function and EMA updates.
- **Break condition:** Integrated label contains systematic errors, causing student model to amplify those errors through confirmation bias.

## Foundational Learning

- **Concept:** Spatial Transformation (Affine Registration)
  - **Why needed here:** The "Grounding" step depends entirely on aligning images; understanding translation, rotation, and scaling matrix derivation is critical.
  - **Quick check question:** Can you explain why one might register predicted masks instead of raw intensity images when dealing with cross-domain data?

- **Concept:** Pseudo-labeling & Confirmation Bias
  - **Why needed here:** GrInAdapt trains on its own predictions (refined via integration); understanding feedback loop risks is critical.
  - **Quick check question:** If the integrated pseudo-label is wrong for a specific vessel, how does the loss function prevent the model from learning that error?

- **Concept:** Ensemble Averaging & Uncertainty
  - **Why needed here:** The "Integrating" step uses averaging to refine labels.
  - **Quick check question:** Why does averaging softmax probabilities of multiple models generally produce better results than taking the single "best" model's prediction?

## Architecture Onboarding

- **Component map:** Source Model -> Registration Module -> Integration Layer -> Adaptation Loop
- **Critical path:** Source Prediction → Registration → Integration → Adaptation. Registration quality is the primary bottleneck.
- **Design tradeoffs:** Simple affine transform chosen over deformable methods for robustness; hard-coded heuristics preferred over end-to-end learning for specific classes like FAZ.
- **Failure signatures:** Registration failure (high translation/scaling factors or keypoint detection failure); FAZ shrinkage during integration.
- **First 3 experiments:**
  1. Unit Test Registration: Run AKAZE registration on paired images and overlay predicted masks visually to verify alignment.
  2. Ablation on Integration Strategy: Compare Dice scores using only source prediction vs. integrated label to isolate integration contribution.
  3. Hyperparameter Sensitivity: Modify cosine annealing schedule to test impact of trusting integrated label vs. teacher confidence.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** To what extent would employing advanced, potentially deformable registration techniques improve the accuracy of the grounding phase compared to the currently used key-point based affine registration?
- **Basis in paper:** Authors explicitly state in the Conclusion that they plan to explore advanced registration techniques to reduce annotation burdens.
- **Why unresolved:** Current implementation uses simple automated key-point based registration with affine transforms, and exploration of more sophisticated methods is identified as a necessary future step.
- **What evidence would resolve it:** Comparative analysis evaluating performance when grounding module is swapped with deformable registration algorithm on the same dataset.

### Open Question 2
- **Question:** How robust is the framework when the strict assumption of "subject-level multi-target image pairs" is relaxed, such as when a patient lacks data from one or more target domains or modalities?
- **Basis in paper:** Methodology relies on assumption that each subject has images in every target domain, and only subjects with all images successfully registered are used.
- **Why unresolved:** Current label integration strategy depends on averaging predictions from multiple views, but it's unclear if consensus mechanism fails or degrades gracefully with missing views.
- **What evidence would resolve it:** Ablation study simulating missing modalities/views for random subjects, reporting degradation curve of integrated label quality and final adaptation performance.

### Open Question 3
- **Question:** Can the integration strategy effectively incorporate auxiliary modalities other than Color Fundus Photography (CFP), such as Fluorescein Angiography (FA) or wide-field Scanning Laser Ophthalmoscopy (SLO)?
- **Basis in paper:** Authors mention in Conclusion the goal to incorporate additional modalities and state framework is flexible enough to incorporate auxiliary modalities, though current study is limited to CFP and OCTA.
- **Why unresolved:** While architecture theoretically supports additional modalities, region-wise merging rules were heuristically defined for CFP, and new modalities may require different fusion heuristics.
- **What evidence would resolve it:** Experiments integrating FA or SLO data into AI-READI dataset pipeline, analyzing whether these modalities provide complementary cues that improve Dice score for specific vessel types.

## Limitations
- Dataset access barrier due to AI-READI being a controlled-access dataset, creating significant reproducibility challenges
- FAZ label instability requiring hard-coded heuristics to prevent shrinkage during integration
- Registration dependency with 25.8% subject exclusion rate due to failure, potentially introducing selection bias

## Confidence
- **High Confidence:** Core mechanisms of registration, integration, and teacher-student adaptation are well-defined with clear equations and robust quantitative improvements
- **Medium Confidence:** Claim that "imperfect vessel mask predictions can be effective" for registration is supported empirically but not deeply analyzed
- **Low Confidence:** Claim that method is "device-agnostic" is overstated given geometric constraints and registration failure rate

## Next Checks
1. **Ablation on Registration Quality:** Run adaptation pipeline on same patients using three conditions (full integration, no integration, ground truth) to quantify cost of registration failures
2. **Domain Generalization Test:** Apply trained GrInAdapt model to held-out domain without adaptation and compare to baseline fine-tuned only on that domain
3. **FAZ-Specific Evaluation:** Conduct per-class analysis measuring exact shrinkage ratio in integrated labels vs. individual predictions, testing if heuristic threshold prevents under-segmentation without causing over-segmentation elsewhere