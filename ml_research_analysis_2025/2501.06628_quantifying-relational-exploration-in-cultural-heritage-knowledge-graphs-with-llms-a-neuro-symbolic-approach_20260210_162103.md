---
ver: rpa2
title: 'Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with
  LLMs: A Neuro-Symbolic Approach'
arxiv_id: '2501.06628'
source_url: https://arxiv.org/abs/2501.06628
tags:
- knowledge
- interestingness
- explanations
- graph
- cultural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a neuro-symbolic approach to relational exploration
  in cultural heritage knowledge graphs, integrating Large Language Models (LLMs)
  for explanation generation and a novel mathematical framework to quantify the interestingness
  of relationships. The method addresses the limitations of existing graph-based and
  knowledge-based approaches by balancing semantic relatedness and contextual relevance
  through a weighted scoring system.
---

# Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach

## Quick Facts
- **arXiv ID**: 2501.06628
- **Source URL**: https://arxiv.org/abs/2501.06628
- **Reference count**: 28
- **Primary result**: Achieves precision 0.70, recall 0.68, F1-score 0.69, outperforming baselines by combining semantic relatedness and contextual relevance via neuro-symbolic LLM integration.

## Executive Summary
This paper introduces a neuro-symbolic approach for relational exploration in cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) to generate natural language explanations of interesting relationships. The method combines semantic relatedness and contextual relevance through a weighted scoring system to quantify relationship interestingness. Evaluated on the WCH-LOD dataset, the approach demonstrates superior performance over baseline graph-based and knowledge-based methods, with strong correlation between interestingness scores and explanation quality.

## Method Summary
The method employs a three-stage pipeline: (1) Connection Discovery using SPARQL CONSTRUCT queries to identify candidate relationships, (2) Interestingness Scoring using I(r) = α × SR(e1,e2) + (1-α) × CR(r,U) where SR measures path-based semantic relatedness and CR measures cosine similarity between LLM embeddings of relationship descriptions and user context, and (3) Explanation Generation using a fine-tuned Llama-2-7B LLM with structured prompts that incorporate entities, scores, and context. The approach balances graph-structural proximity with user-specific relevance through the tunable α parameter.

## Key Results
- Achieves F1-score of 0.69, significantly outperforming graph-based (0.26) and knowledge-based (0.43) baselines
- Shows strong correlation (0.65) between interestingness measure and explanation quality
- LLM-generated explanations demonstrate high quality with BLEU 0.52, ROUGE-L 0.58, and METEOR 0.63 scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weighted combination of semantic relatedness and contextual relevance produces more meaningful relationship rankings than either signal alone.
- Mechanism: Interestingness score I(r) = α × SR(e1, e2) + (1−α) × CR(r, U) balances graph-structural proximity (shorter, more diverse paths indicate stronger semantic bonds) with user-specific relevance (cosine similarity between relationship embeddings and user context embeddings). The α parameter allows tuning between domain-intrinsic importance and personalization.
- Core assumption: Semantic relatedness and contextual relevance are complementary and linearly combinable; cosine similarity on LLM embeddings adequately captures user intent alignment.
- Evidence anchors:
  - Strong correlation (0.65) between interestingness measure and explanation quality validates effectiveness.
  - F1-score improves from 0.26 (graph baseline) and 0.43 (knowledge baseline) to 0.69 with the proposed approach.
  - Neighbor paper ExKG-LLM similarly leverages LLMs for KG expansion, supporting the neuro-symbolic integration pattern.
- Break condition: If α cannot be meaningfully tuned per user or domain, or if embedding similarity fails to capture nuanced user preferences, the ranking may degrade to either purely structural or purely context-driven, losing the balance benefit.

### Mechanism 2
- Claim: Providing structured, context-rich prompts to LLMs yields higher-quality, personalized natural language explanations than template-based or path-based approaches.
- Mechanism: The LLM receives entity descriptions, relationship type, interestingness score, and user context in a structured prompt, explicitly instructed to avoid generic statements. This constraints the generation space while allowing semantic flexibility. The interestingness score acts as a salience signal within the prompt.
- Core assumption: LLMs can incorporate numerical scores and structured context into coherent, non-generic explanations; prompt design sufficiently constrains hallucinations.
- Evidence anchors:
  - BLEU (0.52), ROUGE-L (0.58), and METEOR (0.63) scores exceed baselines.
  - Prompt structure explicitly includes interestingness score and user context; LLM instructed to reflect both.
  - Neighbor paper ATR4CH also combines LLMs with structured ontological guidance, suggesting prompt-to-structure integration is an emerging pattern.
- Break condition: If the LLM ignores numerical interestingness signals or over-relies on prior training data rather than prompt context, explanations may become generic or misaligned with the computed relevance.

### Mechanism 3
- Claim: Pre-filtering candidate relationships via SPARQL pattern matching before interestingness scoring and LLM explanation reduces combinatorial explosion and focuses computation on domain-relevant connections.
- Mechanism: SPARQL CONSTRUCT queries identify predefined relationship patterns (e.g., "person X created painting depicting place Y"), producing a candidate set. Interestingness scoring then ranks these candidates, and only top-k proceed to LLM explanation generation. This three-stage pipeline constrains the search space at each step.
- Core assumption: Predefined SPARQL patterns cover the majority of interesting relationship types in the domain; pruning at the SPARQL stage does not discard high-value unexpected connections.
- Evidence anchors:
  - Algorithm 1 describes SPARQL-based connection discovery generating candidate instances.
  - Evaluation focuses on curated subsets (paintings, painters, museums, places, events), suggesting domain-specific pattern coverage.
- Break condition: If novel or cross-domain relationships fall outside predefined SPARQL patterns, they will never reach the interestingness or LLM stages, limiting serendipitous discovery.

## Foundational Learning

- Concept: **Semantic Relatedness in Knowledge Graphs**
  - Why needed here: The SR(e1, e2) formula uses path length and diversity to quantify intrinsic entity relatedness. Understanding graph traversal and path-based metrics is essential to interpret and tune this component.
  - Quick check question: Given two entities connected by 3 short paths of length 2 and 10 longer paths of length 5, would SR be higher or lower than if only the 3 short paths existed?

- Concept: **Vector Embeddings and Cosine Similarity**
  - Why needed here: Contextual relevance CR(r, U) is computed as cosine similarity between LLM-generated embeddings of the relationship description and user context. This is the neural component linking user intent to graph content.
  - Quick check question: If v(r) and v(U) are orthogonal vectors, what is CR(r, U), and how would that affect I(r) when α = 0.5?

- Concept: **Prompt Engineering for Structured LLM Inputs**
  - Why needed here: The explanation generation mechanism depends on carefully structured prompts that inject entities, scores, and context. Understanding how to format and constrain LLM inputs directly impacts output quality.
  - Quick check question: What happens to explanation specificity if the interestingness score is omitted from the prompt?

## Architecture Onboarding

- Component map:
  1. SPARQL Engine -> Graph Database (Neo4j) -> Embedding Model (Sentence Transformer all-mpnet-base-v2) -> Interestingness Scorer -> LLM (Fine-tuned Llama-2-7B) -> Faceted Search Interface (SPARQL Faceter)

- Critical path:
  1. User submits query/context -> SPARQL queries extract candidate relationships.
  2. For each candidate: compute SR (path analysis on Neo4j), compute CR (embeddings via Sentence Transformer), combine into I(r).
  3. Rank candidates by I(r), select top-k.
  4. For top-k: construct structured prompt, invoke Llama-2-7B for explanation.
  5. Return ranked results with explanations to user interface.

- Design tradeoffs:
  - SPARQL pattern specificity vs. coverage: Narrower patterns reduce noise but may miss novel connections.
  - α tuning: High α favors domain-intrinsic semantics; low α favors personalization. Default or auto-tuned values may not suit all user types.
  - Top-k cutoff: Small k reduces LLM cost but may exclude relevant lower-ranked connections; large k increases latency and cost.
  - LLM choice: Llama-2-7B is open-source and fine-tunable but may have lower capacity than larger proprietary models.

- Failure signatures:
  - Low precision/recall: Likely SPARQL patterns too broad/narrow, or α poorly tuned for user segment.
  - Generic explanations: Prompt may lack sufficient context; interestingness score not influencing LLM; embedding model failing to capture user intent.
  - Slow response: Path enumeration (SR computation) expensive for densely connected entities; LLM invocation on large k.
  - Missing unexpected connections: SPARQL patterns overly restrictive; consider expanding pattern set or adding exploratory graph traversal.

- First 3 experiments:
  1. Ablation on α: Run evaluation with α ∈ {0.0, 0.25, 0.5, 0.75, 1.0} on held-out queries. Measure precision, recall, F1, and explanation quality. Identify optimal α per user segment (novice vs. expert).
  2. Prompt variation: Test prompt variants (with/without interestingness score; with/without user context) on same candidate set. Compare BLEU, ROUGE-L, METEOR to quantify contribution of each prompt component.
  3. SPARQL pattern coverage: Manually annotate a sample of "interesting" relationships not captured by current patterns. Measure recall gap; design additional patterns and re-evaluate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can user interaction data be utilized to automatically refine the mathematical framework's interestingness score function?
- Basis in paper: Section 6 states the aim to "develop more advanced techniques for automatically refining the interestingness score function based on user interactions and feedback."
- Why unresolved: The current framework computes interestingness using a static formula based on semantic relatedness and contextual relevance (Eq. 1), without a mechanism for dynamic adjustment based on user feedback.
- What evidence would resolve it: A study demonstrating an improved correlation between system-calculated scores and user-rated relevance after implementing an adaptive feedback loop.

### Open Question 2
- Question: Can reinforcement learning effectively optimize the Large Language Model to generate more personalized explanations than the current prompting method?
- Basis in paper: Section 6 outlines a plan to "explore reinforcement learning to fine-tune the LLM for generating more personalized explanations."
- Why unresolved: The current implementation relies on a fine-tuned Llama-2-7B model using structured prompts (Fig. 4), rather than a policy optimized via reinforcement learning.
- What evidence would resolve it: Comparative metrics (e.g., METEOR, user satisfaction scores) between the current baseline and an RL-fine-tuned model in a user study.

### Open Question 3
- Question: Does the framework maintain computational efficiency and accuracy when scaled to the full WCH-LOD dataset (135 million triples) or larger knowledge graphs?
- Basis in paper: Section 6 notes that "Further work on the scalability of the framework to larger and more complex knowledge graphs will be also considered."
- Why unresolved: The evaluation focused on a "specific subset" of preprocessed entities rather than the complete dataset.
- What evidence would resolve it: Performance benchmarks (latency, recall) demonstrating the system's viability when processing the entire 135 million triples without pre-filtering.

## Limitations
- The approach relies heavily on predefined SPARQL patterns that may not capture novel or cross-domain relationships, potentially limiting serendipitous discovery.
- The effectiveness of the interestingness measure depends critically on the choice of α parameter, which is left user-configurable without clear default or optimization guidance.
- The LLM explanation generation process, while showing strong quantitative metrics, lacks detailed evaluation of factual accuracy and grounding to the KG.

## Confidence
- **High confidence**: The mathematical formulation of the interestingness score and its correlation with explanation quality (0.65) is well-supported by quantitative results.
- **Medium confidence**: The claim that combining semantic relatedness and contextual relevance produces superior rankings is supported by F1-score improvements (0.69 vs. 0.26 and 0.43 baselines), but depends on the specific dataset and user context formulation.
- **Low confidence**: The assertion that LLM-generated explanations are consistently higher quality than template-based approaches, while supported by BLEU/ROUGE/METEOR scores, lacks direct comparison to alternative explanation generation methods and does not address potential hallucination issues.

## Next Checks
1. **Ablation study on α parameter**: Systematically evaluate the impact of different α values (0.0, 0.25, 0.5, 0.75, 1.0) on precision, recall, and F1-score across different user segments to identify optimal configurations.
2. **Factual accuracy audit**: Manually review a random sample of LLM-generated explanations to assess the rate of factual errors or hallucinations compared to the source KG triples.
3. **Pattern coverage analysis**: Identify and catalog interesting relationships that fall outside current SPARQL patterns to quantify the gap in novel connection discovery and develop additional pattern templates.