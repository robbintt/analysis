---
ver: rpa2
title: 'iPad: Iterative Proposal-centric End-to-End Autonomous Driving'
arxiv_id: '2505.15111'
source_url: https://arxiv.org/abs/2505.15111
tags:
- proposal
- driving
- planning
- should
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of inefficiency and limited
  planning awareness in end-to-end autonomous driving systems that rely on dense bird's-eye
  view (BEV) grid features. The proposed solution, iPad (Iterative Proposal-centric
  Autonomous Driving), centers the entire framework around a sparse set of candidate
  future trajectories (proposals).
---

# iPad: Iterative Proposal-centric End-to-End Autonomous Driving

## Quick Facts
- arXiv ID: 2505.15111
- Source URL: https://arxiv.org/abs/2505.15111
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on NAVSIM and CARLA Bench2Drive while being over 10× more computationally efficient than prior methods

## Executive Summary
This paper addresses the challenge of inefficiency and limited planning awareness in end-to-end autonomous driving systems that rely on dense bird's-eye view (BEV) grid features. The proposed solution, iPad (Iterative Proposal-centric Autonomous Driving), centers the entire framework around a sparse set of candidate future trajectories (proposals). The core method introduces ProFormer, a BEV encoder that iteratively refines proposals and their associated features through proposal-anchored attention, effectively fusing multi-view image data. Extensive experiments on NAVSIM and CARLA Bench2Drive benchmarks demonstrate that iPad achieves state-of-the-art performance while being over 10× more computationally efficient than prior leading methods.

## Method Summary
iPad operates by maintaining N=64 candidate trajectories (proposals) through iterative refinement. The core ProFormer module uses deformable attention anchored to the four corner points of each proposal's bounding box to extract features from multi-view images. The model iteratively refines proposals over K=4 steps, with shared weights across iterations. Two lightweight, proposal-centric auxiliary tasks (mapping and prediction) are trained to improve planning quality. The system uses ResNet-34 backbone, Adam optimizer with LR 1e-4, batch size 64, and trains for 20 epochs on NAVSIM and CARLA datasets.

## Key Results
- Achieves 91.7 PDMS on NAVSIM benchmark, outperforming prior state-of-the-art methods
- Demonstrates 10× computational efficiency improvement compared to UniAD method
- Shows logarithmic scaling of performance with iteration count (K=1 to K=4)
- Maintains high driving score (98.1) and success rate (97.3) on CARLA Bench2Drive

## Why This Works (Mechanism)

### Mechanism 1: Proposal-Anchored Spatial Attention
Focusing image feature extraction on regions surrounding candidate trajectories improves planning quality while reducing computation. ProFormer uses the predicted four corner points of each proposal trajectory as spatial anchors, projecting them to image coordinates and sampling features only at those locations via deformable attention. This bypasses dense BEV grid construction. The core assumption is that planning-relevant information is spatially localized around candidate trajectory corridors rather than distributed uniformly across the scene.

### Mechanism 2: Iterative Refinement with Shared Weights
Progressive refinement of proposals across iterations improves trajectory accuracy through feedback between prediction and feature extraction. Each iteration predicts proposals from current queries, uses those proposals as spatial anchors to extract image features, and updates queries. Weights are shared across iterations, similar to autoregressive models. The MoN loss with discount factor λ enforces gradual improvement. The core assumption is that initial proposals initialized from ego state provide sufficient coarse guidance that can be progressively refined.

### Mechanism 3: Proposal-Centric Auxiliary Task Supervision
Auxiliary tasks that predict only planning-relevant information (passability and collision risks for each proposal) improve planning without dense scene modeling overhead. The mapping head predicts on-road/on-route probability for each proposal state. The prediction head forecasts only the first at-fault and likely-to-collide agents via time-to-collision analysis. The core assumption is that most scene elements are irrelevant to the immediate planning decision; only objects with potential collision interactions matter.

## Foundational Learning

- **Concept: Deformable Attention**
  - Why needed here: ProFormer builds on deformable attention (from Deformable DETR) to sample sparse points around proposal anchors rather than computing attention over all spatial locations.
  - Quick check question: Can you explain how deformable attention samples a small number of learnable offset points around a reference location, versus standard attention over all keys?

- **Concept: Bird's-Eye View (BEV) Representations**
  - Why needed here: iPad operates in BEV space but uses sparse proposal queries instead of dense BEV grids. Understanding BEVFormer's spatial cross-attention is prerequisite to understanding ProFormer's modifications.
  - Quick check question: How does lifting 2D image features to BEV through depth projection enable spatial reasoning across multiple camera views?

- **Concept: Multi-Modal Trajectory Planning**
  - Why needed here: iPad maintains N=64 proposals to capture the inherent multi-modality of driving decisions (multiple valid trajectories for a given scene).
  - Quick check question: Why do deterministic planners like Transfuser suffer from modal collapse, and how does scoring diverse proposals mitigate this?

## Architecture Onboarding

- **Component map**: Multi-view images -> Scene Encoder -> ProFormer iteration 0→1→2→3 → Scorer → Best proposal
- **Critical path**: Multi-view images → Scene Encoder → ProFormer iteration 0→1→2→3 → Scorer → Best proposal
- **Design tradeoffs**:
  - Proposal count N=64: Higher values improve multi-modal coverage but scale linearly with memory/compute
  - Iteration count K=4: More iterations improve accuracy (Figure 3) but increase latency proportionally
  - Proposal-centric vs. general auxiliary tasks: Focused tasks reduce computation 10× (vs UniAD) but may miss rare edge cases
  - No historical frames: Maintains efficiency but limits handling of occlusions and agent dynamics
- **Failure signatures**:
  - Low DAC: Mapping auxiliary task may be undertrained; verify BCE loss on passability predictions
  - Low TTC: Prediction auxiliary task failing to identify collision-relevant agents; check collision ground-truth generation
  - Mode collapse: MoN loss discount λ may be too high/low; proposal diversity not being enforced
  - High latency: Reduce N or K; verify deformable attention is using sparse sampling correctly
- **First 3 experiments**:
  1. Reproduce NAVSIM baseline with default hyperparameters (N=64, K=4, ResNet-34), train 20 epochs on navtrain, evaluate PDMS on navtest. Target: ~91.7 PDMS per Table 1.
  2. Ablation iteration count: Run K=1, 2, 3, 4 and plot PDMS vs. K. Verify logarithmic scaling relationship from Figure 3.
  3. Auxiliary task comparison: Swap proposal-centric mapping/prediction for general tasks (as in Transfuser). Compare DAC and EP metrics per Table 4 row transitions.

## Open Questions the Paper Calls Out

### Open Question 1
How can historical image and status data be integrated into the iPad framework to resolve occlusion issues without negating the computational efficiency gains achieved by the sparse proposal architecture? The authors explicitly list as a limitation: "we do not incorporate historical image and status information... utilizing historical data could help address occlusion issues." This remains unresolved because adding history increases dimensionality and complexity, potentially disrupting the "sparse" nature of the proposal-centric attention mechanism.

### Open Question 2
To what extent does the performance of iPad generalize to real-world closed-loop driving scenarios, specifically regarding the "distribution shift" and "unpredictable human behavior" noted by the authors? Section 5 states the work "lacks real-world closed-loop evaluations" and that "closed-loop performance remains uncertain due to the distribution shift." All reported results derive from simulation environments, and real-world dynamics involve sensor noise, latency, and human unpredictability not fully modeled in these environments.

### Open Question 3
Does training the Scorer using a "non-reactive" log-replay simulator limit the model's ability to negotiate interactive scenarios where other agents react to the ego vehicle's movements? Section 3.3 and Appendix C describe the ground-truth score calculation where "other agents follow their recorded trajectory," ignoring potential reactions to the ego vehicle. Real driving is interactive; optimizing plans based on the assumption that other cars will not react to the ego vehicle could lead to overly aggressive or suboptimal planning in dense traffic.

## Limitations

- ProFormer architecture details are underspecified (number of heads, hidden dimensions, layer normalization)
- Data preprocessing assumptions about nuPlan to NAVSIM conversion are not fully described
- Generalization boundary uncertainty as all results derive from simulation environments

## Confidence

- **High confidence**: The core efficiency claim (10× reduction) is supported by direct comparison with UniAD and is fundamental to the proposal-centric design. The iterative refinement mechanism is well-grounded in established transformer literature.
- **Medium confidence**: Performance improvements on NAVSIM and Bench2Drive are robust within the reported benchmarks, but the absolute metrics depend on benchmark-specific scoring functions that may not reflect real-world driving quality.
- **Medium confidence**: The proposal-centric auxiliary task design shows measurable improvements in DAC and EP metrics, but the ablation studies could benefit from testing on more diverse driving scenarios.

## Next Checks

1. **Real-world validation**: Test iPad on real-world driving datasets (nuScenes, Argoverse) to verify the efficiency gains and performance improvements hold outside simulation environments.

2. **Failure case analysis**: Systematically evaluate iPad's performance in edge cases where proposals fall outside predicted corridors, such as sudden pedestrian crossings or emergency vehicle scenarios.

3. **Scalability assessment**: Measure computational scaling as proposal count N increases beyond 64 and iteration count K exceeds 4 to determine optimal operating points for different computational budgets.