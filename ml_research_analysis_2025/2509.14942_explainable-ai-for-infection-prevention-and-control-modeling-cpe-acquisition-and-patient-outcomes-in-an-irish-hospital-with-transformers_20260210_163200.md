---
ver: rpa2
title: 'Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition
  and Patient Outcomes in an Irish Hospital with Transformers'
arxiv_id: '2509.14942'
source_url: https://arxiv.org/abs/2509.14942
tags:
- patient
- features
- data
- ward
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents an explainable AI framework for modeling CPE
  acquisition and patient outcomes in an Irish hospital using EMR data. Transformer-based
  models, especially TabTransformer, consistently outperformed traditional methods
  across three clinical tasks (AUROC 0.834 for 30-day readmission, 0.728 for in-hospital
  mortality, 15.463 RMSE for LOS).
---

# Explainable AI for Infection Prevention and Control: Modeling CPE Acquisition and Patient Outcomes in an Irish Hospital with Transformers

## Quick Facts
- **arXiv ID:** 2509.14942
- **Source URL:** https://arxiv.org/abs/2509.14942
- **Reference count:** 40
- **Primary result:** Transformer models, especially TabTransformer, outperformed traditional methods in predicting CPE acquisition and patient outcomes, with AUROC 0.834 for 30-day readmission and 0.728 for in-hospital mortality.

## Executive Summary
This study presents an explainable AI framework for modeling CPE acquisition and patient outcomes in an Irish hospital using EMR data. Transformer-based models, especially TabTransformer, consistently outperformed traditional methods across three clinical tasks (AUROC 0.834 for 30-day readmission, 0.728 for in-hospital mortality, 15.463 RMSE for LOS). For CPE risk prediction, TabTransformer achieved the highest sensitivity (0.425) despite class imbalance. Explainability analysis via Integrated Gradients revealed that historical admissions, ward-level contact features, and patient residence were key predictors. Embedding visualizations showed CPE-positive patients formed distinct clusters. The framework offers actionable insights for infection prevention and supports targeted screening strategies.

## Method Summary
The study used anonymized EMR data (Jan 2018â€“Feb 2022) from an Irish acute hospital to predict 30-day readmission, in-hospital mortality, LOS, and CPE acquisition risk. Features included patient demographics, ICD-10 codes (generalized to 3-5 digits), ward transitions, and contact network metrics (degree, centrality, PageRank). TabTransformer was benchmarked against XGBoost, TabNet, ResNet, TabPFN, and CoreBEHRT. Training used stratified 5-fold cross-validation with chronological 90/10 splits, Focal Loss, Random Oversampling, and Balanced Batch Sampling to handle the 0.2% CPE prevalence. BioBERT embeddings were integrated for ICD-10 code text descriptions.

## Key Results
- TabTransformer achieved highest sensitivity (0.425) for CPE acquisition prediction despite extreme class imbalance
- Integrated Gradients revealed "Previous LOS Total" and "Area of Residence" as top CPE risk factors
- Network features like "Ward PageRank" and "Ward Closeness Centrality" ranked in top tier for CPE prediction
- Embedding visualizations showed CPE-positive patients formed distinct clusters
- TabTransformer outperformed traditional methods across all clinical tasks (AUROC 0.834 for readmission, 0.728 for mortality)

## Why This Works (Mechanism)

### Mechanism 1: Contextual Categorical Embeddings
The TabTransformer architecture improves prediction accuracy for high-cardinality categorical variables (e.g., Admission Ward, Area of Residence) by generating contextual embeddings rather than static vector representations. Standard one-hot encoding treats categories as orthogonal, but the Transformer's self-attention layers allow the embedding of a specific ward to be modified by the context of the patient's history and demographics. This allows the model to learn that "Ward A" implies a different risk profile for a patient with high "Ward PageRank" than for an isolated patient. Core assumption: The semantic relationships between categorical medical concepts (wards, residence areas) can be captured through co-occurrence and interaction patterns within the patient record, similar to natural language context.

### Mechanism 2: Structural Exposure via Network Features
Integrating graph-derived features, specifically centrality measures like "Ward PageRank," provides a proxy for transmission pressure that raw visit counts do not capture. By constructing a daily patient contact network based on ward co-location and calculating metrics like closeness centrality, the model encodes the structural "position" of a patient in the hospital's flow. A high PageRank suggests a patient has moved through highly connected wards, statistically increasing exposure risk. Core assumption: Ward-level co-location is a sufficient approximation for physical contact or exposure to pathogens. (Assumption: Room-level or bed-level data would be more precise but was unavailable).

### Mechanism 3: Gradient-based Attribution for Clinical Validity
Integrated Gradients (IG) provides reliable feature importance for deep tabular models by satisfying the "sensitivity" axiom, ensuring that features which truly change the prediction output are highlighted. Unlike simple attention weights which can be noisy, IG computes the path integral of gradients from a baseline (e.g., an "average" or "healthy" patient) to the actual input. This isolates the specific features (e.g., "Previous LOS Total") that pushed the prediction toward a positive CPE result. Core assumption: The selected baseline input is representative of a "neutral" state; if the baseline is biased, attributions will be skewed.

## Foundational Learning

- **Concept: Deep Tabular Learning (TabTransformer)**
  - **Why needed here:** Traditional tree-based models (XGBoost) struggle with high-cardinality categorical data without heavy manual encoding. You need to understand how Column Embeddings + Multi-Head Attention work to debug why the model prioritizes "Area of Residence."
  - **Quick check question:** Can you explain how the attention mechanism in TabTransformer differs from the feature importance calculation in a Gradient Boosting Decision Tree?

- **Concept: Class Imbalance Handling (Focal Loss & Sampling)**
  - **Why needed here:** CPE-positive cases were only 0.2% of the dataset. Standard Cross-Entropy loss would result in a model that always predicts "Negative."
  - **Quick check question:** Why does the paper use Focal Loss in conjunction with Random Oversampling, rather than just Oversampling alone?

- **Concept: Graph Metrics for Temporal Snapshots**
  - **Why needed here:** The model uses "Ward PageRank" calculated from daily contact networks. You need to understand that this is not a static graph property of the hospital, but a dynamic property of the specific patient cohort on that day.
  - **Quick check question:** If a patient stays in an isolated ward for 7 days, how would their "Ward Degree" compare to a patient rotating through 3 high-traffic wards?

## Architecture Onboarding

- **Component map:** Input Layer (Categorical + Numerical + Graph) -> Embedding Encoder (MLP for numerical/ICD, Lookup for categorical) -> Backbone (TabTransformer with Self-Attention) -> Head (MLP for classification/regression) -> XAI Module (Integrated Gradients)

- **Critical path:** The primary failure mode is the **Data Preprocessing -> Feature Engineering** step. If ICD codes are not truncated (generalized) or Graph metrics are calculated on the wrong time-window, the model sees noise. Ensure the "Contact Network" logic correctly flags "Exposed" patients based on the definition in Section 2.3.4.

- **Design tradeoffs:**
  - **Transformer vs. Tree Models:** The paper shows TabTransformer beats XGBoost slightly on AUROC (0.781 vs 0.755) but is harder to interpret natively. IG is required to bridge the gap.
  - **Precision vs. Sensitivity:** The model achieves high Sensitivity (0.425) for CPE but low Precision (AUPRC is low). This is a deliberate choice for a screening tool (better to over-screen than miss a case), but limits use for definitive diagnosis.

- **First 3 experiments:**
  1. **Baseline Reproduction:** Train XGBoost and TabTransformer on the provided data splits (Section 4.1) using only raw EMR data (no graph features) to quantify the specific contribution of the network features.
  2. **Ablation on "Area of Residence":** Since "Area of Residence" is a top predictor (Section 5.2.1), run an experiment removing this feature to check for data leakage (e.g., does a specific region map directly to a referral clinic for CPE?).
  3. **IG Baseline Sensitivity:** Calculate IG attributions using a "zero-vector" baseline vs. a "training-mean" baseline to see if the stability of feature importance holds, verifying the XAI robustness.

## Open Questions the Paper Calls Out
- Can the proposed explainable AI framework be validated and generalized across multi-institutional datasets like MIMIC-III/IV? The authors state in Section 7, "future work should explore multi-institutional datasets, such as MIMIC-III/IV, to validate our findings in broader settings."
- Can precision-oriented methods (e.g., cost-sensitive learning, ensemble strategies) significantly improve AUPRC for CPE acquisition tasks compared to the current TabTransformer approach? The authors note in Section 7 that "modest precision-recall performance highlights a limitation" and suggest "precision-oriented methods... should be explored."
- Do autoregressive foundation models (e.g., NOSOS) outperform the current static TabTransformer in forecasting HCAIs by better capturing temporal dynamics? Section 7 identifies "autoregressive longitudinal modeling" and foundation models like NOSOS as a "promising direction" to address data imbalance and missing data.

## Limitations
- Study is based on a single Irish hospital's EMR data, limiting generalizability to other healthcare settings
- Low prevalence (0.2%) of CPE-positive cases and reliance on ward-level co-location as transmission proxy may limit external validity
- Model's risk predictions have not been validated to translate into improved clinical outcomes or resource allocation decisions

## Confidence
- **High Confidence:** Transformer models (particularly TabTransformer) outperforming traditional methods on all three clinical tasks, including AUROC scores of 0.834 for 30-day readmission and 0.728 for in-hospital mortality
- **Medium Confidence:** The claim that "Area of Residence" and "Previous LOS Total" are key predictors, as these findings are based on Integrated Gradients attributions which can be sensitive to baseline selection
- **Low Confidence:** The clinical utility of the CPE screening tool, given the low Precision despite high Sensitivity, and the absence of prospective validation in real screening programs

## Next Checks
1. **External Validation:** Apply the model to EMR data from a different hospital or country to assess performance stability and identify potential data leakage or overfitting to the source institution
2. **Feature Ablation for Clinical Relevance:** Systematically remove "Area of Residence" and "Previous LOS Total" features to test whether their importance is due to data leakage (e.g., referral patterns) rather than genuine clinical risk factors
3. **Prospective Screening Trial:** Conduct a prospective study where the model's CPE risk predictions are used to trigger targeted screening, measuring the ratio of true positives identified versus routine screening to quantify resource efficiency gains