---
ver: rpa2
title: 'Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained
  Instance-Tailored Steering'
arxiv_id: '2510.27206'
source_url: https://arxiv.org/abs/2510.27206
tags:
- user
- fints
- steering
- methods
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Fints, an inference-time personalization
  framework for large language models (LLMs) that dynamically adapts model behavior
  to individual user preferences. The method addresses limitations of existing approaches
  by treating personalization as a sample-level activation shift rather than parametric
  updates.
---

# Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering

## Quick Facts
- arXiv ID: 2510.27206
- Source URL: https://arxiv.org/abs/2510.27206
- Authors: Kounianhua Du; Jianxing Liu; Kangning Zhang; Wenxiang Jiao; Yuan Lu; Jiarui Jin; Weiwen Liu; Yong Yu; Weinan Zhang
- Reference count: 40
- This paper introduces Fints, an inference-time personalization framework for large language models (LLMs) that dynamically adapts model behavior to individual user preferences.

## Executive Summary
Fints presents an inference-time personalization framework that enables large language models to adapt to individual user preferences without model retraining. The approach constructs personalized steering vectors by contrasting model activations under relevant and irrelevant contexts, then dynamically selects and combines these vectors during inference based on semantic similarity. This method achieves significant performance improvements across diverse personalization tasks while maintaining low computational overhead and instant adaptability, particularly excelling in data-sparse and fast-changing distribution scenarios where traditional methods struggle.

## Method Summary
Fints addresses limitations of existing personalization approaches by treating personalization as a sample-level activation shift rather than parametric updates. The framework constructs personalized steering vectors from user data by contrasting model activations under relevant and irrelevant contexts, using fine-grained hooking that separately extracts signals from attention and MLP layers. During inference, an input-aware aggregation module dynamically selects and combines the most relevant steering vectors based on semantic similarity to the current query. This approach enables superior performance across diverse personalization tasks including short-to-long text generation and web function calling, particularly excelling in data-sparse scenarios with fewer than 10 examples per user.

## Key Results
- Superior performance across diverse personalization tasks including short-to-long text generation and web function calling
- Significant improvements in data-sparse scenarios with fewer than 10 examples per user
- Maintains low computational overhead and instant adaptability without model retraining

## Why This Works (Mechanism)
The framework leverages the observation that user preferences manifest as distinct activation patterns in LLM layers. By constructing steering vectors through activation contrasts between relevant and irrelevant contexts, Fints captures nuanced user-specific behavioral patterns. The fine-grained hooking approach isolates signals from different layer types (attention vs MLP), enabling more precise personalization. The input-aware aggregation mechanism ensures that only contextually relevant steering vectors influence the current prediction, preventing interference from unrelated user preferences.

## Foundational Learning
- **Activation-based steering**: Modifying model behavior through activation space perturbations rather than parameter updates - needed to avoid costly retraining while maintaining personalization capability
- **Semantic similarity-based vector selection**: Matching user preference vectors to current context using embedding similarity - needed to ensure relevance of personalization signals
- **Fine-grained layer-wise hooking**: Separating signals from attention and MLP layers - needed to capture different types of behavioral patterns in the model
- **Instance-tailored personalization**: Adapting to individual user preferences rather than population-level patterns - needed for true personalization rather than general preference modeling
- **Zero-parameter personalization**: Achieving behavioral changes without updating model weights - needed for instant adaptability and low computational overhead
- **Activation contrast learning**: Constructing personalization signals by contrasting relevant vs irrelevant contexts - needed to isolate true preference signals from noise

## Architecture Onboarding

**Component Map:**
User Data -> Steering Vector Construction -> Input-Aware Aggregation -> LLM Inference

**Critical Path:**
1. User data collection and context labeling
2. Steering vector construction via activation contrast
3. Semantic similarity matching during inference
4. Dynamic vector aggregation and application

**Design Tradeoffs:**
- **Pro**: No model retraining required, enabling instant adaptability
- **Con**: Computational overhead of maintaining per-user steering vectors
- **Pro**: Works effectively with minimal user data (fewer than 10 examples)
- **Con**: Potential degradation in highly nuanced or contradictory preference scenarios
- **Pro**: Low inference-time parameter modifications
- **Con**: Reliance on quality of semantic similarity matching

**Failure Signatures:**
- Poor performance when user preferences are highly contradictory across contexts
- Degradation when semantic similarity matching fails to capture nuanced preferences
- Computational bottlenecks when managing large numbers of per-user steering vectors
- Reduced effectiveness when user data distributions shift rapidly

**First Experiments:**
1. Benchmark Fints against parametric fine-tuning methods using identical datasets and compute budgets
2. Evaluate steering vector drift and performance decay over extended usage periods
3. Test semantic similarity-based vector selection on adversarial or contradictory user preference scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- The effectiveness of the semantic similarity-based vector selection mechanism may degrade in cases where user preferences are highly nuanced or contradictory across different contexts
- The computational overhead of maintaining per-user steering vectors and performing dynamic aggregation during inference is not fully quantified
- The evaluation focuses primarily on specific personalization tasks but does not extensively test cross-domain generalization or long-term personalization stability

## Confidence
- **High confidence**: The core technical approach of using activation-based steering vectors without parameter updates is well-established in related work
- **Medium confidence**: Performance improvements on reported benchmarks, though limited to specific task types
- **Medium confidence**: Claims about data-sparse scenario effectiveness, pending verification of dataset sizes and distribution characteristics
- **Low confidence**: Generalization claims to arbitrary personalization scenarios without supporting evidence

## Next Checks
1. Benchmark Fints against parametric fine-tuning methods using identical datasets and compute budgets to quantify true efficiency gains
2. Evaluate steering vector drift and performance decay over extended usage periods to assess long-term personalization stability
3. Test the semantic similarity-based vector selection mechanism on adversarial or contradictory user preference scenarios to verify robustness