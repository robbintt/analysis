---
ver: rpa2
title: 'Towards Spectroscopy: Susceptibility Clusters in Language Models'
arxiv_id: '2601.12703'
source_url: https://arxiv.org/abs/2601.12703
tags:
- after
- math
- clusters
- token
- grammar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces susceptibility clustering as a method to\
  \ discover interpretable structure in language models by treating the model's response\
  \ to data perturbations as a spectrum to be analyzed. The approach measures susceptibilities\u2014\
  covariances between component-level observables and data distribution perturbations\u2014\
  using localized Gibbs posteriors via SGLD."
---

# Towards Spectroscopy: Susceptibility Clusters in Language Models

## Quick Facts
- arXiv ID: 2601.12703
- Source URL: https://arxiv.org/abs/2601.12703
- Reference count: 40
- Primary result: Introduces susceptibility clustering to discover interpretable structure in language models by treating response to data perturbations as a spectrum to analyze

## Executive Summary
This paper introduces susceptibility clustering as a method to discover interpretable structure in language models by treating the model's response to data perturbations as a spectrum to be analyzed. The approach measures susceptibilities—covariances between component-level observables and data distribution perturbations—using localized Gibbs posteriors via SGLD. Theoretically, susceptibilities decompose into modes of the data distribution, explaining why tokens following contexts "for similar reasons" cluster together. Empirically, applying this methodology to Pythia-14M identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation.

## Method Summary
The methodology computes susceptibility vectors for context-continuation pairs using preconditioned SGLD sampling from a localized Gibbs posterior, then clusters these vectors via iterative conductance-based graph clustering. The process involves three main steps: (1) compute susceptibility vectors χ_xy via pSGLD with specific hyperparameters, (2) preprocess and build a symmetrized k-NN graph with self-tuning RBF weights, and (3) apply iterative clustering using personalized PageRank to find low-conductance subsets. The approach is validated by comparing clusters to SAE features from Pythia-70M, showing 50% overlap, and by demonstrating persistence of interpretable structure across model scales.

## Key Results
- Identifies 510 interpretable clusters in Pythia-14M ranging from grammatical patterns to code structure to mathematical notation
- Half of these clusters match SAE features from Pythia-70M, validating that both methods recover similar structure
- Clusters persist across model scales (241-358 clusters in 410M and 1.4B models), suggesting they reflect genuine patterns in the data distribution rather than artifacts of the small model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token sequences that "follow for similar reasons" cluster together in susceptibility space because susceptibilities decompose as a weighted sum over data distribution modes.
- Mechanism: The conditional distribution q(y|x) admits a singular value decomposition into modes (α, β). Each token pair (x,y) has propensity weights sαβ(xy) measuring how strongly each mode explains that continuation. The susceptibility vector decomposes as χxy = Σ sαβ(xy)χαβ − χ̄, where χαβ is the model's learned response to that mode. If two token pairs share similar propensity profiles, their susceptibility vectors are nearby.
- Core assumption: The data distribution has a sparse, approximately diagonal mode structure so that token pairs are explained by few dominant modes.
- Evidence anchors:
  - [abstract] "Theoretically, it shows that susceptibilities decompose into modes of the data distribution, with tokens following contexts 'for similar reasons' clustering together."
  - [Section 2.3] Equation (5) and Lemma B.3 provide the formal decomposition.
  - [corpus] Related work "Structural Inference" (Baker et al. 2025) establishes susceptibility foundations; no direct external validation of mode-susceptibility link beyond this theoretical framework.
- Break condition: If propensity profiles are dense with no diagonal dominance, token pairs won't cleanly separate by mode; clusters become meaningless mixtures.

### Mechanism 2
- Claim: Sampling from the localized Gibbs posterior via pSGLD—rather than Gaussian noise—is necessary to capture loss landscape geometry that encodes internal structure.
- Mechanism: The quenched posterior pβ(w) ∝ exp(−nβL(w))φ(w) is shaped by loss landscape curvature around the trained weights. Susceptibilities compute covariances under this posterior, which depend on how component observables covary with loss under the true loss geometry. Gaussian noise ignores this structure.
- Core assumption: Internal structure is encoded in the geometry of the loss landscape, not just local weight values.
- Evidence anchors:
  - [Section B.2] Definition of quenched posterior and its role in susceptibility computation.
  - [Appendix H] Gaussian posterior susceptibilities show 87% variance in first PC vs 71% for true susceptibilities; fewer clusters (288 vs 510); no opening/closing quote separation.
  - [corpus] No external papers directly compare posterior vs Gaussian sampling for this application.
- Break condition: If the loss landscape near the trained weights is degenerate or the posterior is too diffuse, covariance estimates become noise.

### Mechanism 3
- Claim: Low-conductance subsets of the susceptibility k-NN graph correspond to interpretable functional clusters because computational similarity manifests as geometric proximity.
- Mechanism: Preprocess susceptibility vectors (column standardize, then row-center to remove uniform mode). Build symmetrized k-NN graph with self-tuning RBF weights. Use personalized PageRank from seed nodes to rank vertices, then find minimum-conductance prefixes. Iterate, removing discovered clusters, to avoid the dense main body overwhelming peripheral structures.
- Core assumption: Susceptibility geometry reflects computational role rather than token identity.
- Evidence anchors:
  - [Section 3.2] Algorithm 1 and parameter table; conductance definition.
  - [Section 4.1] Context sensitivity: same token (*, ., /, (, $) separates into different clusters by function. Functional grouping: different tokens (h, u, y, o, w) cluster together when serving same role.
  - [corpus] SAE comparison in Lan et al. (2025) shows 50% overlap, providing cross-method validation.
- Break condition: If susceptibility space is dominated by token identity or surface features, functional separation fails.

## Foundational Learning

- Concept: Singular Value Decomposition of conditional distributions
  - Why needed here: The theoretical framework treats q(y|x) as a matrix indexed by contexts and continuations, with SVD revealing "modes" that explain why continuations follow contexts.
  - Quick check question: Given a 3×2 conditional distribution matrix with rows [1,0], [0,1], [0.5,0.5], what do the two modes capture?

- Concept: Stochastic Gradient Langevin Dynamics (SGLD)
  - Why needed here: Susceptibilities require sampling from a tempered posterior centered at trained weights; pSGLD with RMSProp preconditioning provides this.
  - Quick check question: Why must SGLD include noise scaled to step size, unlike standard SGD?

- Concept: Graph conductance and personalized PageRank
  - Why needed here: The clustering algorithm identifies low-conductance sets via PageRank orderings; conductance measures how well-separated a cluster is from the graph.
  - Quick check question: For a k-NN graph, does a conductance of 0.1 indicate a good or poor cluster?

## Architecture Onboarding

- Component map:
```
Data (780K token pairs from 13 Pile subsets)
    ↓
Susceptibility computation (pSGLD sampling, covariance estimation per component)
    ↓
Preprocessing (column standardize, row-center)
    ↓
Graph construction (k=45 NN, self-tuning RBF weights)
    ↓
Iterative clustering (ACL local clustering via PageRank, conductance thresholding)
    ↓
510 clusters → interpretation (LLM labeling, SAE comparison)
```

- Critical path:
  1. pSGLD hyperparameters (γ=300, nβ=3, ε=1e-5) must be tuned to ensure stable posterior sampling without drifting from trained weights.
  2. Row-centering during preprocessing is essential—it projects out the uniform mode that would otherwise dominate Euclidean distances.
  3. The 0.99 main-body threshold in clustering prevents early iterations from returning the entire dense core; only after removal do peripheral structures become discoverable.

- Design tradeoffs:
  - Higher k in k-NN graph increases connectivity but may merge distinct clusters; k=45 chosen empirically.
  - Lower conductance threshold yields purer clusters but may fragment coherent structures.
  - Larger models (410M, 1.4B) yield fewer clusters (241-249 vs 510), possibly due to noisier high-dimensional metrics or response to more modes diluting cluster structure.

- Failure signatures:
  - Gaussian baseline check: If clusters from nβ=0 (Gaussian) look similar to nβ>0, the posterior is not capturing loss landscape structure.
  - Main-body dominance: If >90% of points end up in a single cluster, row-centering failed or conductance threshold is too permissive.
  - Token-identity clustering: If clusters are monolithic in y-token (e.g., all commas together regardless of context), susceptibility geometry isn't reflecting computational role.

- First 3 experiments:
  1. **Context sensitivity sanity check**: For a token with multiple functions (e.g., `.` as decimal, sentence-end, abbreviation), verify it appears in multiple distinct clusters with appropriate contexts.
  2. **Gaussian baseline comparison**: Run susceptibility computation with nβ=0, apply identical clustering, compare number of clusters, average cluster size, and token entropy. Expect ~40% fewer clusters and lower entropy.
  3. **SAE feature matching**: For a random sample of 20 clusters, compute activation frequency of top SAE features on cluster tokens. Expect >80% activation frequency on matched features, <5% on random baseline clusters.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can susceptibility analysis identify interpretable structure in frontier-scale language models, or does the method fail to scale beyond 1.4B parameters?
- Basis in paper: [explicit] The conclusion states that "The question of whether susceptibility analysis scales to frontier systems remains open, but these results are encouraging."
- Why unresolved: The authors demonstrate persistence of clusters up to 1.4B parameters, but computational costs and noise in higher-dimensional parameter spaces make the feasibility at frontier scales (e.g., 70B+ parameters) unknown.
- What evidence would resolve it: Successful application of the conductance-based clustering algorithm to a model with parameters exceeding 10B, yielding a similar density of interpretable clusters to Pythia-14M.

### Open Question 2
- Question: Can the susceptibility relationship be inverted to identify specific data distribution modifications that produce desired structural changes in a model?
- Basis in paper: [explicit] The conclusion notes that susceptibilities measure the response to data shifts and that "this relationship can be inverted to find data modifications that produce desired structural changes... We leave exploration of this direction to future work."
- Why unresolved: The paper establishes the theoretical link between data perturbations and internal structure, but has not yet demonstrated the reverse causal path (using susceptibilities to guide training data interventions).
- What evidence would resolve it: An experiment where susceptibility analysis informs the curation of a fine-tuning dataset, resulting in a predictable modification of a specific circuit or feature.

### Open Question 3
- Question: Does dictionary learning on susceptibility vectors recover more fine-grained structure in larger models compared to the conductance-based clustering used on Pythia-14M?
- Basis in paper: [inferred] In Section 4.5, the authors note that clustering yields fewer clusters in larger models (241–358 vs 510) and suggest "Techniques such as dictionary learning on susceptibility vectors may be necessary to recover more structure in larger models."
- Why unresolved: The current conductance-based method may fail to capture overlapping or dense structure in high-dimensional susceptibility spaces, but the utility of dictionary learning in this specific context remains untested.
- What evidence would resolve it: A comparative analysis on Pythia-70M or larger showing that dictionary learning identifies a significantly higher number of valid, interpretable features than the conductance-based approach.

### Open Question 4
- Question: What accounts for the 50% of susceptibility clusters that do not match SAE features: are they distinct structural elements, or artifacts of the different decomposition methodologies?
- Basis in paper: [inferred] In Section 4.4, the authors find a 50.8% match rate but "caution against overinterpreting the match rate," noting that SAE features and clusters assign token pairs differently (multiple features vs. single cluster assignment).
- Why unresolved: The overlap validates consistency for half the clusters, but leaves the nature of the divergence for the other half ambiguous—specifically whether they represent different levels of abstraction or orthogonal views of the model.
- What evidence would resolve it: A qualitative analysis of "unmatched" susceptibility clusters to determine if they correspond to polysemantic SAE features or functional groupings that SAEs typically fail to isolate.

## Limitations

- The theoretical decomposition linking susceptibility space to data distribution modes relies on assumptions about sparse mode structure that aren't empirically validated beyond the observed clustering patterns.
- The method's sensitivity to hyperparameters (k-NN connectivity, conductance threshold, SGLD sampling parameters) means results could shift substantially with different settings.
- The claim that clusters reflect "genuine patterns in the data distribution" rather than model artifacts is supported by scale-robustness but lacks direct causal evidence.

## Confidence

- **High confidence**: The clustering algorithm correctly identifies low-conductance subsets in the susceptibility graph (ACL local clustering is well-established).
- **Medium confidence**: The Gaussian posterior baseline comparison is methodologically sound and shows meaningful differences, supporting the claim that loss landscape geometry matters.
- **Medium confidence**: SAE feature matching (50% overlap) validates the interpretability of clusters, though the metric is coarse and doesn't guarantee semantic alignment.
- **Low confidence**: The claim that clusters reflect "genuine patterns in the data distribution" rather than model artifacts is supported by scale-robustness but lacks direct causal evidence.

## Next Checks

1. **Controlled generation experiment**: Take seed tokens from different functional clusters (e.g., decimal vs sentence-ending `.`), generate continuations, and evaluate whether outputs follow cluster-specific patterns (syntactic correctness for decimals, semantic coherence for sentence endings). This would directly test if susceptibility clusters capture functional computational roles.

2. **Cross-model transferability**: Apply the same susceptibility clustering to a different small model (e.g., OPT-125M) trained on the same data. If similar functional clusters emerge despite different architecture and training, this strengthens the data-distribution hypothesis.

3. **Mode decomposition validation**: For a small conditional distribution matrix (e.g., 5×5), compute the SVD, identify dominant modes, and verify that token pairs with similar propensity profiles to those modes cluster together in susceptibility space. This would provide ground-truth validation of the theoretical mechanism.