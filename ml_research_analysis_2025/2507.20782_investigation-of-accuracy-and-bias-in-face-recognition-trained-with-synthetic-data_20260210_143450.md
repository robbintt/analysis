---
ver: rpa2
title: Investigation of Accuracy and Bias in Face Recognition Trained with Synthetic
  Data
arxiv_id: '2507.20782'
source_url: https://arxiv.org/abs/2507.20782
tags:
- synthetic
- datasets
- face
- data
- recognition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the impact of synthetic data on face recognition
  (FR) accuracy and fairness, focusing on whether high accuracy and demographic fairness
  can be achieved simultaneously. The authors generate a balanced synthetic dataset,
  FairFaceGen, using two text-to-image models (Flux.1-dev and Stable Diffusion v3.5)
  and combine them with multiple identity augmentation methods (Arc2Face and four
  IP-Adapters).
---

# Investigation of Accuracy and Bias in Face Recognition Trained with Synthetic Data

## Quick Facts
- arXiv ID: 2507.20782
- Source URL: https://arxiv.org/abs/2507.20782
- Authors: Pavel Korshunov; Ketan Kotwal; Christophe Ecabert; Vidit Vidit; Amir Mohammadi; Sebastien Marcel
- Reference count: 40
- Primary result: Synthetic data, when properly balanced and augmented, can achieve lower demographic bias than real datasets in face recognition, though accuracy still lags behind.

## Executive Summary
This paper investigates whether synthetic data can simultaneously achieve high accuracy and demographic fairness in face recognition systems. The authors develop FairFaceGen, a balanced synthetic dataset generated using text-to-image models (Flux.1-dev and Stable Diffusion v3.5) combined with identity augmentation methods (Arc2Face and IP-Adapters). By equalizing identity counts and image-per-identity ratios, they ensure fair comparisons between synthetic and real datasets. The study reveals that while synthetic data still trails real datasets in challenging benchmarks like IJB-B/C, demographically balanced synthetic datasets show strong potential for bias mitigation, with SD35-based data achieving the lowest bias across racial groups.

## Method Summary
The authors generate a balanced synthetic dataset called FairFaceGen using two text-to-image models (Flux.1-dev and Stable Diffusion v3.5) combined with multiple identity augmentation methods (Arc2Face and four IP-Adapters). They ensure fair comparisons by equalizing identity counts and image-per-identity ratios across datasets. The study evaluates synthetic data performance against real datasets on face recognition accuracy and fairness metrics, with particular focus on demographic bias across racial groups. The experimental design includes ablation studies to assess the impact of different augmentation methods and synthetic data generation approaches.

## Key Results
- Synthetic data still lags behind real datasets in generalization on challenging benchmarks like IJB-B/C
- SD35-based synthetic data achieved the lowest bias (standard deviation of accuracy across racial groups) among all datasets tested
- The number and quality of intra-class augmentations significantly affect both FR accuracy and fairness
- Demographically balanced synthetic datasets demonstrate strong potential for bias mitigation

## Why This Works (Mechanism)
Assumption: The demographically balanced synthetic data works because it eliminates sampling bias present in real datasets, where certain demographic groups may be underrepresented. By equalizing identity counts and image-per-identity ratios during synthetic data generation, the model receives balanced training signals across all racial groups, preventing the optimization process from favoring majority groups.

Unknown: The exact mechanisms by which specific augmentation methods (Arc2Face vs IP-Adapters) contribute differently to bias reduction remain unclear. The study shows that SD35-based data achieves the lowest bias, but doesn't fully explain why this particular combination of text-to-image model and augmentation strategy is most effective for fairness.

## Foundational Learning
Unknown: The paper doesn't explicitly discuss whether the findings reveal fundamental principles about synthetic data generation for fairness. However, the consistent observation that balanced synthetic datasets can outperform real datasets in bias metrics suggests a foundational insight: carefully controlled synthetic data generation may be more effective at achieving demographic fairness than collecting and curating real-world data.

## Architecture Onboarding
None

## Open Questions the Paper Calls Out
None

## Limitations
- The controlled synthetic data generation process may not capture full real-world diversity in lighting, occlusions, and extreme poses
- The study focuses on specific text-to-image models (Flux.1-dev and Stable Diffusion v3.5) that may not represent the full spectrum of synthetic data capabilities
- Fairness evaluation primarily addresses racial groups, potentially overlooking other dimensions like age, gender expression, and intersectional factors
- The gap between synthetic and real data performance on challenging benchmarks (IJB-B/C) suggests limitations in synthetic data's ability to capture complex real-world variations

## Confidence
- High Confidence: SD35-based synthetic data achieving lowest bias among all tested datasets, including real datasets
- Medium Confidence: Hybrid approaches combining synthetic and real data may be optimal for practical FR systems
- Medium Confidence: Number and quality of intra-class augmentations significantly affect both FR accuracy and fairness

## Next Checks
1. Test FairFaceGen dataset and augmentation strategies across multiple FR architectures (ArcFace, CosFace, transformer-based models) to assess generalizability
2. Conduct real-world deployment tests with synthetic-real hybrid approach in diverse operational environments
3. Extend fairness evaluation to include additional demographic factors (age, gender expression, accessories) and intersectional fairness metrics