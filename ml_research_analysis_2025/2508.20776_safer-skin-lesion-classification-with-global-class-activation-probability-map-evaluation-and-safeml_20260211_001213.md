---
ver: rpa2
title: Safer Skin Lesion Classification with Global Class Activation Probability Map
  Evaluation and SafeML
arxiv_id: '2508.20776'
source_url: https://arxiv.org/abs/2508.20776
tags:
- prediction
- lesion
- class
- predictions
- skin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving trust and safety
  in skin lesion classification models, which despite high accuracy, remain distrusted
  by medical professionals. The authors propose Global Class Activation Probabilistic
  Map Evaluation (GCAPM), a method that analyzes activation probability maps across
  all classes at the pixel level, providing more comprehensive and reliable explanations
  compared to existing CAM-based methods that focus only on the predicted class.
---

# Safer Skin Lesion Classification with Global Class Activation Probability Map Evaluation and SafeML

## Quick Facts
- arXiv ID: 2508.20776
- Source URL: https://arxiv.org/abs/2508.20776
- Authors: Kuniko Paxton; Koorosh Aslansefat; Amila AkagiÄ‡; Dhavalkumar Thakker; Yiannis Papadopoulos
- Reference count: 40
- Primary result: GCAPM framework detects misdiagnosed skin lesions with 75% accuracy and correctly identifies reliable predictions with 90% accuracy

## Executive Summary
This paper addresses the challenge of improving trust and safety in skin lesion classification models, which despite high accuracy, remain distrusted by medical professionals. The authors propose Global Class Activation Probabilistic Map Evaluation (GCAPM), a method that analyzes activation probability maps across all classes at the pixel level, providing more comprehensive and reliable explanations compared to existing CAM-based methods that focus only on the predicted class. The approach is combined with SafeML principles to detect abnormal diagnoses and uncertain predictions, particularly important in clinical and mobile health settings where ground truth labels may not be available.

## Method Summary
The framework uses GCAPM to compute Grad-CAM for every class and performs pixel-wise argmax to assign each pixel to a specific class, creating a unified map showing dominant class attention at each location. This is combined with spatial quality metrics (Attribute Sensitivity and Attribute False Positive Rate) that compare the GCAPM output against ground-truth segmentation masks. A meta-classifier (SVM) is trained on feature vectors containing prediction probability, Att Sensitivity, and Att FPR to identify potentially unreliable predictions. The system was tested on ISIC 2017 and 2019 datasets using MobileNetV2 and Vision Transformers, with runtime testing under data degradation conditions (Gaussian blur).

## Key Results
- GCAPM effectively visualizes model attention across multiple classes, reducing misdiagnosis risk
- The framework successfully identifies correct predictions with approximately 90% accuracy under various data degradation conditions
- Selective predictor detected misdiagnosed cases with 75% accuracy
- Moderate-to-strong correlation (0.48 to 0.66) between Att Sensitivity and F1 Score for MobileNet models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Analyzing activation competition across *all* classes (rather than just the predicted class) exposes hidden diagnostic conflicts that standard explainability methods miss.
- **Mechanism:** GCAPM computes Grad-CAM for every class c, then performs pixel-wise argmax to assign each pixel to a specific class, creating a unified map where the dominant class at each location is visualized.
- **Core assumption:** If a model misclassifies an image but focuses on the correct lesion area, standard CAM (showing only the predicted class) appears valid. The assumption is that *incorrect* predictions often exhibit high activation for the wrong class in the lesion area, which is only visible when mapping all classes simultaneously.
- **Evidence anchors:** [Section 3.1]: "The class c that shows the highest attention at a pixel position (h,w) is selected... This makes it possible to visualize which class each pixel is most strongly associated with." [Section 5.1]: "GCAPM effectively highlights instances where the model attends to different classes within the lesion... often overlooked by conventional approaches."
- **Break condition:** If the model's features are highly entangled (e.g., features for "Melanoma" are universally subset of features for "Nevus"), the pixel-level argmax may fail to differentiate class dominance, resulting in a noisy map.

### Mechanism 2
- **Claim:** The spatial quality of the explanation (how much it overlaps with the actual lesion) correlates with prediction accuracy, serving as a proxy for trust.
- **Mechanism:** The framework computes "Attribute Sensitivity" (Att Sensitivity) and "Attribute False Positive Rate" (Att FPR) by comparing the GCAPM output against ground-truth segmentation masks. These metrics quantify whether the model is "looking" at the right spot.
- **Core assumption:** Correct predictions are statistically more likely to have high attention overlap with the lesion ground truth (High Att Sensitivity) compared to incorrect predictions.
- **Evidence anchors:** [Section 5.2]: "In particular, for MobileNet, inaccurate predictions tend to cluster in areas with low attribute sensitivity..." [Table 1]: Shows moderate-to-strong correlation (0.48 to 0.66) between Att Sensitivity and F1 Score for MobileNet models.
- **Break condition:** If the model uses valid "contextual" features (e.g., skin texture outside the lesion) that are diagnostically relevant but fall outside the segmentation mask, Att Sensitivity will be low, potentially flagging a correct prediction as risky.

### Mechanism 3
- **Claim:** A meta-classifier using explainability metrics can effectively identify misdiagnoses in deployment scenarios where ground truth labels are unavailable.
- **Mechanism:** A Selective Predictor (SVM) is trained on the feature vector [Prediction Probability, Att Sensitivity, Att FPR]. At runtime, if the meta-classifier predicts the original diagnosis is inaccurate, the system flags it for human intervention (SafeML integration).
- **Core assumption:** The statistical relationship between (Attention Quality + Prediction Confidence) and accuracy holds steady even under data distribution shift (e.g., blurry images).
- **Evidence anchors:** [Abstract]: "...detecting misdiagnosed cases with 75% accuracy." [Section 5.3]: "Selective predictor identified correct predictions with approximately 90% accuracy... and successfully flagged inaccurate predictions with over 75% accuracy."
- **Break condition:** If the runtime data drift is semantic (e.g., a new type of lesion presentation) rather than just quality degradation (blur), the relationship between the training attention metrics and safety may decouple.

## Foundational Learning

- **Concept: Class Activation Mapping (CAM)**
  - **Why needed here:** The entire GCAPM method is built on top of Grad-CAM. You cannot understand the "Global" modification without understanding how standard CAM highlights pixel importance for a single class via gradient weighting.
  - **Quick check question:** How does Grad-CAM differ from raw pixel gradients in terms of localization granularity?

- **Concept: Semantic Segmentation Metrics (IoU / Sensitivity)**
  - **Why needed here:** The paper repurposes segmentation metrics (Sensitivity, FPR) to evaluate the *quality* of the explanation, not the classification itself. Understanding True Positives in the context of pixel overlap is vital.
  - **Quick check question:** In the context of this paper, does "False Positive" refer to a wrong class label or attention on non-lesion background skin?

- **Concept: Data Drift & Out-of-Distribution (OOD) Detection**
  - **Why needed here:** The "SafeML" component is fundamentally about detecting when input data deviates from training data (drift) to trigger safety mechanisms.
  - **Quick check question:** Why is prediction probability alone often insufficient for detecting data drift in high-stakes medical diagnosis?

## Architecture Onboarding

- **Component map:** Image -> Base Classifier -> Class Scores **AND** GCAPM Map. (GCAPM Map + Lesion Mask) -> Att Metrics (Sens/FPR). (Class Scores + Att Metrics) -> Safety Monitor -> Final Decision.
- **Critical path:** Image -> Base Classifier -> Class Scores **AND** GCAPM Map. (GCAPM Map + Lesion Mask) -> Att Metrics (Sens/FPR). (Class Scores + Att Metrics) -> Safety Monitor -> Final Decision.
- **Design tradeoffs:**
  - **Compute vs. Safety:** GCAPM requires generating N CAM maps (where N is class count) per inference, increasing computation cost linearly compared to standard CAM.
  - **Architecture Compatibility:** The paper notes ViT explainability is less intuitive; the mechanism relies on Grad-CAM adaptations that may be less stable for Transformers than CNNs (MobileNet).
- **Failure signatures:**
  - **High Confidence + Low Sensitivity:** The model is sure of its prediction but looking at the wrong thing (background/artifacts). *Action:* Reject/Flag.
  - **Low Sensitivity + Low FPR:** The model is looking at nothing specific (diffuse attention). *Action:* Flag as uncertain.
- **First 3 experiments:**
  1. **Sanity Check (Zero-Note):** Pass a completely blank (black) image through the GCAPM pipeline. The Att Sensitivity should be near 0, and the Safety Monitor should ideally flag this as invalid input.
  2. **Single-Class vs. Global:** Visualize Grad-CAM for the predicted class vs. the full GCAPM map on a known "risky" case (e.g., a lesion with a ruler marker). Verify that GCAPM highlights the ruler as a competing "class" or region if the model has learned a shortcut.
  3. **Drift Simulation:** Apply Gaussian blur to a validation set (as done in the paper) and plot the degradation of the Safety Monitor's rejection accuracy vs. the Base Classifier's accuracy drop.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the GCAPM framework perform regarding fairness and generalization when evaluated across diverse skin tone populations?
- **Basis in paper:** [explicit] The authors state in Section 6.2 that future work must focus on "evaluating fairness and generaliztion by analysing the impact of skin tone variations on diagnoses," noting that current datasets mainly contain light skin tones.
- **Why unresolved:** The current study relied on ISIC 2017/2019 datasets which lack diversity in skin tones, limiting the validation of the framework's robustness in realistic, diverse environments.
- **What evidence would resolve it:** Experimental results showing GCAPM's safety monitoring performance remains consistent across specific skin tone categories (e.g., Fitzpatrick scale types) using more diverse datasets.

### Open Question 2
- **Question:** How can the transparency and reliability of Vision Transformer (ViT) interpretations be improved within the GCAPM framework?
- **Basis in paper:** [explicit] Section 6.3 notes that "explainability of attention layers is not always intuitive or interpretable" for ViTs and that "explainability research specific to ViT remains at early stages."
- **Why unresolved:** While GCAPM works with ViTs, the underlying self-attention mechanisms are difficult to interpret, potentially masking whether the model is focusing on clinically relevant features or spurious correlations.
- **What evidence would resolve it:** Development and validation of ViT-specific interpretability methods that offer transparent, reliable interpretation comparable to CNN-based Grad-CAM.

### Open Question 3
- **Question:** Can the GCAPM safety evaluation be effectively adapted for commercial or proprietary "black-box" models where internal access is restricted?
- **Basis in paper:** [inferred] Section 6.3 states the method "assumes access to the internal structure of the model, potentially limiting applicability to commercial and proprietary systems."
- **Why unresolved:** The current methodology relies on extracting activation maps from specific layers, a requirement that fails if the model architecture is hidden or inaccessible to the developer.
- **What evidence would resolve it:** A functional implementation using model-agnostic approaches (like SMILE, mentioned in the paper) that achieves comparable anomaly detection performance without internal layer access.

## Limitations
- Limited validation on broader skin lesion datasets beyond ISIC 2017/2019
- Unknown generalization of GCAPM to other medical imaging domains
- Lack of comparison with state-of-the-art multi-class CAM methods

## Confidence

- **High confidence:** Mechanism 1 (GCAPM effectiveness in revealing multi-class activation conflicts)
- **Medium confidence:** Mechanism 2 (correlation between attention quality and prediction accuracy)
- **Medium confidence:** Mechanism 3 (meta-classifier performance in detecting misdiagnoses)

## Next Checks
1. **Cross-dataset validation:** Test GCAPM framework on external skin lesion datasets (e.g., Derm7pt) to verify generalization beyond ISIC datasets
2. **Ablation study:** Evaluate GCAPM performance against Grad-CAM for the predicted class only on the same safety metrics to quantify added value
3. **Clinical relevance testing:** Conduct physician evaluation study comparing GCAPM explanations versus standard CAM for real diagnostic decision-making scenarios