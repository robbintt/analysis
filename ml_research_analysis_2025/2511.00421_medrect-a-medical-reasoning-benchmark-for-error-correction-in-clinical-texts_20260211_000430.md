---
ver: rpa2
title: 'MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts'
arxiv_id: '2511.00421'
source_url: https://arxiv.org/abs/2511.00421
tags:
- error
- medical
- reasoning
- clinical
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MedRECT introduces the first cross-lingual benchmark for medical
  error correction, spanning Japanese and English clinical texts. Built via a scalable
  automated pipeline from Japanese Medical Licensing Examinations and curated English
  data, it yields 663 Japanese and 458 English samples with balanced error/no-error
  ratios.
---

# MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts

## Quick Facts
- arXiv ID: 2511.00421
- Source URL: https://arxiv.org/abs/2511.00421
- Reference count: 40
- Introduces first cross-lingual benchmark for medical error correction with 663 Japanese and 458 English samples

## Executive Summary
MedRECT introduces the first cross-lingual benchmark for medical error correction, spanning Japanese and English clinical texts. Built via a scalable automated pipeline from Japanese Medical Licensing Examinations and curated English data, it yields 663 Japanese and 458 English samples with balanced error/no-error ratios. Evaluation of 9 LLMs shows reasoning models outperform non-reasoning models by up to 13.5% in error detection and 51.0% in sentence extraction. Cross-lingual analysis reveals 5–10% performance gaps, smaller for reasoning models. Targeted LoRA fine-tuning yields asymmetric gains (+0.078 Japanese, +0.168 English) while preserving reasoning capabilities. The fine-tuned model exceeds human expert performance on structured medical error correction tasks. MedRECT provides a reproducible framework and resources for developing safer, globally equitable medical AI systems.

## Method Summary
The benchmark uses an automated synthesis pipeline that transforms Japanese Medical Licensing Examination (JMLE) multiple-choice questions into clinical texts with injected errors. DeepSeek-R1-0528 and Qwen3-235B-A22B-Thinking-2507 generate synthetic clinical scenarios, which are filtered through multi-model validation (11 models voting) and LLM-as-judge screening. The final dataset contains 663 Japanese and 458 English samples. For fine-tuning, LoRA (rank=64, α=128) is applied to Qwen3-32B using bilingual training data (5,538 Japanese + 2,439 English samples with reasoning chains). Evaluation uses error detection F1, sentence extraction accuracy, and error correction metrics (ROUGE-1, BERTScore, BLEURT).

## Key Results
- Reasoning models outperform non-reasoning models by up to 13.5% in error detection and 51.0% in sentence extraction
- Cross-lingual performance gaps of 5–10% between Japanese and English, smaller for reasoning models
- LoRA fine-tuning yields asymmetric improvements: +0.078 F1 for Japanese, +0.168 F1 for English
- Fine-tuned model exceeds human expert performance on structured medical error correction tasks

## Why This Works (Mechanism)

### Mechanism 1
Reasoning models outperform non-reasoning models on error localization because explicit step-by-step reasoning processes support precise identification of erroneous sentences within complex clinical narratives. Reasoning models generate intermediate verification steps that compare clinical findings against diagnostic/treatment logic before producing final outputs, enabling more accurate localization than direct end-to-end prediction. Core assumption: The performance difference stems from reasoning processes rather than model scale or training data alone. Evidence anchors: [abstract] "reasoning models substantially outperform standard architectures, with up to 13.5% relative improvement in error detection and 51.0% in sentence extraction"; [section 5.1] "Qwen3-32B think vs. no-think comparison reveals particularly large gaps in History taking sentence extraction (68.1% vs. 36.2%)"; [corpus] Related work on Japanese medical LLMs (Kawakami et al., 2025) confirms reasoning preference optimization improves reliability, supporting the mechanism. Break condition: If reasoning models were evaluated with substantially lower inference compute or fewer reasoning tokens, the performance gap would narrow significantly.

### Mechanism 2
LoRA fine-tuning produces asymmetric cross-lingual gains because medical reasoning patterns transfer across languages while language-specific generation benefits more from structured training. Training on Japanese clinical scenarios teaches transferable error detection reasoning (identifying inconsistencies between symptoms, findings, and conclusions), which then applies to English data. English error correction benefits more because generation quality is more sensitive to fine-tuning than binary detection. Core assumption: The asymmetry reflects genuine cross-lingual transfer rather than overfitting to the training distribution. Evidence anchors: [abstract] "targeted LoRA fine-tuning yields asymmetric improvements...Japanese: +0.078, English: +0.168"; [section 5.2] "despite being trained primarily on Japanese medical data, with particularly strong English sentence extraction accuracy of 90.9%"; [corpus] No directly comparable cross-lingual transfer studies found in corpus; mechanism remains conditional pending replication. Break condition: If the English training data contained higher-quality reasoning traces than the Japanese data, the asymmetry would reflect data quality differences rather than transfer mechanisms.

### Mechanism 3
The automated synthesis pipeline with multi-model validation filtering produces benchmark samples at appropriate difficulty levels because consensus-based filtering removes ambiguous and trivial samples. Validation models vote on each sample; samples retained only if accuracy falls within 1/11–7/11 range for detection and extraction. This removes samples that are too easy (all models correct) or ambiguous (high variance in model responses). Core assumption: Model consensus correlates with sample quality and clinical validity. Evidence anchors: [section 3.2.1] "For ERROR samples, we applied a stricter standard...gap between detection and extraction accuracy was minimal (≤3/11)"; [section A.3] "retained 663 out of 720 samples (92.1%) for MEDRECT-ja"; [corpus] No corpus evidence on validity of multi-model filtering; approach is novel and requires independent validation. Break condition: If validation models share systematic biases (e.g., common training data), the filtering would reinforce those biases rather than ensuring quality.

## Foundational Learning

- **LoRA (Low-Rank Adaptation)**: The paper uses LoRA fine-tuning with rank=64, α=128 to adapt Qwen3-32B for medical error correction while preserving reasoning capabilities. Understanding parameter-efficient fine-tuning is essential to replicate results. Quick check: Why does LoRA preserve base model capabilities better than full fine-tuning?

- **Medical Error Taxonomy (8 categories)**: The benchmark evaluates performance across error types (diagnosis, monitoring/management, physical findings, procedures, medication selection, test interpretation, history taking, dosage). Performance varies significantly by category. Quick check: Which error type shows the largest performance variance across models, and why might that be?

- **Cross-Lingual Evaluation Metrics**: The paper uses language-specific tokenizers (MeCab for Japanese, whitespace for English) and multilingual embedding models (BERTScore with language settings). Metric comparability is critical for valid cross-lingual claims. Quick check: Why might ROUGE-1 scores not be directly comparable across Japanese and English?

## Architecture Onboarding

- **Component map**: Source JMLE questions → Synthesis → Filtering → Deduplication → Screening → Final benchmark; Training data → Reasoning synthesis (DeepSeek-R1-0528) → Meta-reference filtering → LoRA fine-tuning
- **Critical path**: 1. Source JMLE questions → Synthesis → Filtering → Deduplication → Screening → Final benchmark; 2. Training data → Reasoning synthesis (DeepSeek-R1-0528) → Meta-reference filtering → LoRA fine-tuning
- **Design tradeoffs**: Automated vs. manual annotation reduces cost and enables scalability but may miss nuanced clinical errors; Multi-model filtering reduces individual model bias but introduces computational overhead and may filter valid edge cases; Bilingual training improves cross-lingual transfer but may dilute language-specific optimization
- **Failure signatures**: High false positive rate—models (including GPT-5, Claude) incorrectly flag correct texts as errors (Sample 3, Table 5); fine-tuned model shows improvement but still 62.0% detection accuracy vs. human 81.3%; Medication dosage errors—all models struggle with numerical precision (Table 4); Qwen3-32B+LoRA achieves only 27.3% accuracy; Cross-lingual performance drop—5-10% gap from English to Japanese across most models
- **First 3 experiments**: 1. Reproduce baseline evaluation on MEDRECT-ja using provided benchmark data and zero-shot prompt; verify error detection F1 and sentence extraction accuracy match reported values within tolerance; 2. Ablate reasoning effort on Qwen3-32B (think vs. no-think) to quantify reasoning contribution independent of model architecture; 3. Fine-tune smaller model (e.g., Qwen3-8B) with same LoRA configuration to test whether gains scale down; compare asymmetric transfer patterns

## Open Questions the Paper Calls Out

- **Generalization to clinical practice**: To what extent do synthetic errors generated from licensing examination questions represent the diversity and complexity of errors found in actual clinical practice? The authors acknowledge that their "synthetic error generation approach... may not fully represent the diversity of errors encountered in actual clinical practice." This leaves a gap between exam performance and real-world utility.

- **Metric validity**: How well do automated metrics (e.g., BERTScore, BLEURT) correlate with expert clinical judgment when assessing the correctness of generated medical corrections? While the benchmarks provide automated scores, the qualitative alignment between a high BLEURT score and a clinically safe/valid correction remains unquantified.

- **Cross-lingual transfer mechanisms**: What specific mechanisms enable the observed asymmetric cross-lingual transfer, where fine-tuning on Japanese data yields higher gains for English error correction? Results show English performance improved more than Japanese (+0.168 vs +0.078) despite Japanese training data being more than twice as large, leading the authors to suggest transfer but leaving the mechanism unexplained.

## Limitations
- Automated quality filtering reliability is novel and lacks independent validation; the approach assumes model consensus correlates with sample quality but validation models may share systematic biases
- Cross-lingual metric comparability issues arise from language-specific tokenizers and embedding models, potentially affecting claims about performance gaps
- Generalization to clinical practice may be limited as the benchmark relies on Japanese Medical Licensing Examination content rather than real-world clinical errors

## Confidence

- **High confidence**: Error detection and sentence extraction performance improvements from reasoning models (up to 13.5% and 51.0% relative gains) are well-supported by ablation studies and consistent across error types
- **Medium confidence**: Cross-lingual performance gaps (5-10%) and asymmetric LoRA transfer benefits (+0.078 Japanese, +0.168 English) are supported by experimental results but depend on metric comparability assumptions
- **Low confidence**: Claims about automated synthesis pipeline producing appropriately difficult samples rely heavily on the multi-model consensus approach, which is novel and lacks external validation

## Next Checks
1. Validate cross-lingual metric comparability by conducting controlled experiments comparing Japanese and English performance using identical error types and sentence structures translated between languages
2. Test filtering methodology robustness by examining samples near the 1/11 and 7/11 thresholds and comparing with human expert validation on a random subset
3. Replicate asymmetric transfer by fine-tuning the same LoRA configuration on smaller models (Qwen3-8B, Qwen3-4B) and different base architectures to determine whether gains scale down