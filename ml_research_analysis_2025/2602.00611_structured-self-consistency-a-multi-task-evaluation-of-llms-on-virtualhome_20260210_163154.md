---
ver: rpa2
title: Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome
arxiv_id: '2602.00611'
source_url: https://arxiv.org/abs/2602.00611
tags:
- action
- object
- obj1
- goal
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates Large Language Models (LLMs) on the VirtualHome
  benchmark, addressing the challenge of structured generation in embodied AI. The
  authors introduce Structured Self-Consistency (SSC), a decoding framework that combines
  schema-constrained sampling, semantic canonicalization, and structure-aware voting
  to improve output validity and execution success.
---

# Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome
## Quick Facts
- arXiv ID: 2602.00611
- Source URL: https://arxiv.org/abs/2602.00611
- Reference count: 40
- OPENPANGU-7B gains up to +581% relative improvement in Transition Modeling with SSC

## Executive Summary
This paper evaluates Large Language Models (LLMs) on the VirtualHome benchmark, addressing the challenge of structured generation in embodied AI. The authors introduce Structured Self-Consistency (SSC), a decoding framework that combines schema-constrained sampling, semantic canonicalization, and structure-aware voting to improve output validity and execution success. Experiments on two 7B-parameter models—OPENPANGU-7B and QWEN2.5-7B-INSTRUCT—across four tasks (Goal Interpretation, Action Sequencing, Subgoal Decomposition, Transition Modeling) show that SSC consistently boosts performance, with up to +581% relative improvement in Transition Modeling for OPENPANGU-7B. The results demonstrate that SSC acts as a "cognitive rectifier," unlocking latent reasoning capabilities in models with weaker instruction alignment by enforcing structural correctness during inference.

## Method Summary
The paper evaluates LLMs on the Embodied Agent Interface (EAI) benchmark within VirtualHome across four structured output tasks. The core contribution is Structured Self-Consistency (SSC), an inference-time decoding strategy that generates multiple diverse samples (N=5, T=0.7), canonicalizes them according to task-specific schemas, and selects the most consistent valid output via structure-aware voting. The evaluation uses OPENPANGU-7B and QWEN2.5-7B-INSTRUCT models, measuring Task Success Rate, Execution Success Rate, F1/Precision/Recall (for goal/transition tasks), and Schema Validity Rate. The methodology leverages task-specific system prompts and canonicalization functions (Φ) to ensure semantic equivalence and schema compliance, deployed via vLLM with a 4096-token context window.

## Key Results
- OPENPANGU-7B shows up to +581% relative improvement in Transition Modeling with SSC
- SSC consistently improves Task and Execution Success Rates across all four tasks
- QWEN2.5-7B-INSTRUCT gains are more modest, indicating SSC's effectiveness is model-dependent
- Schema Validity Rate increases significantly, confirming structural correctness of outputs

## Why This Works (Mechanism)
SSC improves LLM performance on structured tasks by generating multiple diverse samples and selecting the most consistent valid output. This acts as a "cognitive rectifier," enforcing structural correctness and unlocking latent reasoning capabilities in models with weaker instruction alignment. The mechanism leverages diversity sampling, schema-constrained canonicalization, and structure-aware voting to filter and refine outputs, ensuring semantic equivalence and compliance with task-specific schemas.

## Foundational Learning
- Embodied AI in VirtualHome: Simulated environment for household task execution; needed to contextualize the evaluation benchmark and task complexity.
- Structured Output Generation: Generating JSON/PDDL following schemas; critical for tasks like Action Sequencing and Transition Modeling where format adherence is essential.
- Semantic Canonicalization: Normalizing semantically equivalent outputs (e.g., order-invariant sets); needed to compare and vote over model samples fairly.
- Schema-Constrained Sampling: Sampling under structural constraints; ensures outputs are valid and comparable.
- Structure-Aware Voting: Aggregating over valid canonical forms; improves robustness by leveraging consensus among diverse samples.

## Architecture Onboarding
- Component Map: EAI benchmark -> Model (OPENPANGU-7B/QWEN2.5-7B-INSTRUCT) -> SSC Inference (N=5, T=0.7) -> Canonicalizer Φ -> Structure-Aware Voting -> Evaluation Metrics
- Critical Path: Input instruction -> Model sampling -> Canonicalization (Φ) -> Voting -> Output selection
- Design Tradeoffs: Diversity vs. consistency (N=5, T=0.7 balances exploration and convergence); strictness of Φ (too strict causes parse errors, too lenient reduces validity).
- Failure Signatures: High JSON/PDDL parse errors (Φ too strict or outputs drift); small SSC gains (low diversity or semantic collisions in canonicalization).
- First Experiments: (1) Reconstruct Φ for Goal Interpretation and verify schema compliance; (2) Run SSC vs. greedy on small EAI subset to confirm success rate gains; (3) Log raw outputs, Φ(y)=⊥ rates, and voting clusters to diagnose failure modes.

## Open Questions the Paper Calls Out
None

## Limitations
- Canonicalization function details per task are underspecified, affecting reproducibility.
- Evaluation harness for VirtualHome execution and success criteria is not fully detailed.
- Gains are model-dependent, with weaker models benefiting more than well-aligned ones.

## Confidence
- Experimental setup and baseline results: High
- SSC methodology: Medium (due to incomplete canonicalization and evaluation harness details)
- Reported improvements: Medium (dependent on correct implementation of schema-constrained sampling and voting)

## Next Checks
1. Reconstruct the canonicalization function Φ for at least one task (e.g., Goal Interpretation) and verify it correctly handles the structured output schema and semantic equivalence as described.
2. Implement the SSC inference pipeline (N=5, T=0.7, structure-aware voting) and run on a small held-out subset of EAI to confirm task success rate improvements over greedy decoding.
3. Instrument the evaluation to log raw model outputs, Φ(y)=⊥ rates, and voting cluster distributions to diagnose potential failure modes (e.g., semantic collisions, low diversity).