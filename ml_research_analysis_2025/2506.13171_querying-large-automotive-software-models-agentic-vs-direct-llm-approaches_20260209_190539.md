---
ver: rpa2
title: 'Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches'
arxiv_id: '2506.13171'
source_url: https://arxiv.org/abs/2506.13171
tags:
- software
- agent
- file
- available
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper compares two approaches for querying large software
  models using large language models (LLMs): direct prompting with the full model
  in context versus an agentic approach using tool-augmented agents. The agentic approach,
  which uses incremental file access, achieves accuracy comparable to direct prompting
  while significantly reducing token usage, making it more efficient for large models.'
---

# Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches

## Quick Facts
- **arXiv ID**: 2506.13171
- **Source URL**: https://arxiv.org/abs/2506.13171
- **Reference count**: 39
- **Primary result**: Agentic approaches with incremental context loading achieve comparable accuracy to direct prompting while reducing token usage by ~99%, making them viable for large models.

## Executive Summary
This paper compares direct full-context prompting with agentic ReAct-based approaches for querying large automotive software models. Using a timing analysis metamodel from the automotive domain, the study evaluates four LLMs across 20 questions covering class inspection, inheritance chains, and semantic queries. The agentic approach achieves comparable accuracy to direct prompting for capable models while dramatically reducing token consumption, though weaker models fail with the agentic approach. The findings demonstrate that while direct prompting works for models fitting in context, agentic approaches are the only viable solution for larger models due to their efficiency.

## Method Summary
The study evaluates two approaches on INCHRON's am2inc Ecore metamodel (384 classes, ~118K tokens): direct prompting with the full model in context versus an agentic approach using ReAct framework with file-access tools. The agentic method uses incremental file access with 50-line windows and 2-line overlap, allowing selective context loading. Four LLMs are tested: GPT-4o mini, GPT-4.1 mini, o4-mini, and Gemini 2.5 Flash Preview. Accuracy is measured via binary correct/incorrect scoring and Ragas FactualCorrectness metric, with GPT-4.1 mini as the LLM-as-a-Judge evaluator. The evaluation covers 20 manually created questions across four categories: direct class inspection, single inheritance chains, multiple inheritance chains, and semantic queries.

## Key Results
- Agentic approach reduces token usage by ~99% (from ~118K to ~639-783 tokens) while maintaining comparable accuracy for capable models
- GPT-4.1 mini and o4-mini achieve 90% accuracy with agentic approach; GPT-4o mini drops from 45% to 10% accuracy
- Direct prompting works well for models fitting in context but becomes infeasible for larger models
- Agentic approach is the only viable solution for models exceeding context window limits

## Why This Works (Mechanism)

### Mechanism 1
Incremental context loading via tool-augmented agents reduces token consumption by ~99% while maintaining comparable accuracy to full-context prompting for capable models. The agent receives only a directory path initially, then selectively retrieves relevant file fragments using tools (search_file, open_file, scroll operations). This avoids loading the entire model (~118K tokens) into the context window. Only models with strong tool orchestration capabilities (GPT-4.1 mini, o4-mini) maintain accuracy; weaker models (GPT-4o mini) drop from 45% to 10% accuracy.

### Mechanism 2
Windowed file access with 50-line windows and 2-line overlap enables traversal of large files within limited context windows while preserving type definition completeness. The agent views files through fixed-size windows rather than loading entire files. Most Ecore type definitions fit within 1-2 windows, minimizing scroll operations. The small overlap prevents boundary-crossing definitions from being split.

### Mechanism 3
The ReAct framework enables iterative reasoning-tool loops that compensate for partial context visibility, but requires models with sufficient working memory to maintain state coherence across tool calls. The agent interleaves reasoning traces ("Thought:") with tool invocations ("Action:"), allowing it to plan multi-step queries. GPT-4.1 mini and o4-mini (90% accuracy) succeed by maintaining goal state across 10-20 tool calls; GPT-4o mini (10% accuracy) fails by entering unproductive scroll loops.

## Foundational Learning

- **Concept**: ReAct (Reasoning + Acting) Framework
  - **Why needed here**: The agentic approach relies on this pattern where LLMs alternate between reasoning traces and tool calls. Understanding this helps diagnose why some models spiral into unproductive loops.
  - **Quick check question**: Can you explain why a model might correctly reason "I need to find the Frequency class" but then execute the wrong tool (scroll_down instead of search_file)?

- **Concept**: Ecore Metamodel Format (XML-based)
  - **Why needed here**: The experimental model uses Ecore XML format, which is more token-intensive than alternatives like PlantUML. Token counts (~118K for 384 classes, 13,572 lines) directly stem from this format choice.
  - **Quick check question**: Why would switching from Ecore XML to PlantUML change the feasibility threshold for direct prompting?

- **Concept**: Context Window Constraints for Local Deployment
  - **Why needed here**: Automotive privacy/compliance requirements drive the need for small, locally-deployable LLMs. Understanding token limits (e.g., GPT-4o mini: 128K input) clarifies why agentic approaches become necessary for larger models.
  - **Quick check question**: If a production automotive model has 500K tokens, which approach(es) remain viable and why?

## Architecture Onboarding

- **Component map**: Question + Directory Path → Agent (ReAct loop) → Tool Layer → Windowed File Views → Accumulated Context → Answer

- **Critical path**: Question → search_file (locate class) → open_file at line → scroll as needed → extract fields → traverse inheritance (repeat for base classes) → synthesize answer

- **Design tradeoffs**:
  - Window size: Larger windows reduce scroll operations but increase per-step token cost
  - Iteration limit: Higher limits accommodate complex queries but risk runaway costs
  - Tool selection: General-purpose file tools vs. domain-specific model navigation tools (the latter could improve accuracy per Section V)
  - Model selection: Stronger reasoning models (o4-mini) maintain accuracy in agentic mode; weaker models require direct prompting when feasible

- **Failure signatures**:
  - **Recursive error**: Agent exceeds 100 iterations without producing answer (15 occurrences; GPT-4o mini: 13, o4-mini: 2)
  - **Incomplete inheritance traversal**: Agent stops after 1-2 inheritance levels, missing inherited fields
  - **Tool selection error**: Using scroll_down repeatedly instead of search_file for targeted lookup
  - **Overgeneralization**: Including semantically similar but incorrect classes in membership queries

- **First 3 experiments**:
  1. **Baseline calibration**: Run direct prompting with a 384-class Ecore model that fits in context. Measure accuracy and token usage across all 4 question categories (direct class inspection, single inheritance, multiple inheritance, semantic queries). Use GPT-4.1 mini as reference.
  2. **Agent failure mode analysis**: Run the same questions through the agentic approach with GPT-4o mini. Log all tool calls and identify where agents enter unproductive loops. Test if search_file-first prompting reduces recursive errors.
  3. **Scale threshold detection**: Create progressively larger model subsets (50, 100, 200, 384 classes). Plot accuracy and token curves for both approaches to identify the crossover point where direct prompting becomes infeasible.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can agentic workflows reliably support textual modifications of software models while preserving structural consistency? The current study focused exclusively on read-only querying tasks; modification introduces risks of state corruption and constraint violations that were not tested.

- **Open Question 2**: How does the performance of the agentic approach generalize to diverse modeling formats (e.g., UML, AUTOSAR) and multi-file project structures? The evaluation was limited to a single Ecore metamodel contained in one file, threatening external validity.

- **Open Question 3**: Do domain-specific model navigation tools yield higher accuracy than general-purpose file access tools for inheritance-heavy queries? The current agent used generic commands (scroll, search) which led to failure cases involving incomplete inheritance traversal.

## Limitations

- The evaluation relies on a single automotive timing-analysis metamodel, limiting generalizability to other model types or domains.
- The agentic approach uses general file-access tools rather than model-specific navigation tools, which may limit accuracy.
- All experiments use small, locally-deployable LLMs, excluding larger frontier models that might perform differently under the same constraints.

## Confidence

- **High confidence**: The efficiency advantage of agentic approaches for large models is well-supported with 99% token reduction clearly demonstrated.
- **Medium confidence**: The accuracy parity claim is supported for capable models (GPT-4.1 mini, o4-mini at 90% accuracy) but not for weaker models (GPT-4o mini drops from 45% to 10%).
- **Low confidence**: The generalizability to other metamodel types, domains, or tool architectures remains unproven due to single dataset and general-purpose tool selection.

## Next Checks

1. **Cross-domain validation**: Test the agentic approach on non-automotive software models (e.g., Java class hierarchies, UML diagrams) to assess generalizability. Use the same question categories but with models from different domains to identify whether the approach depends on automotive-specific model characteristics.

2. **Domain-specific tool comparison**: Implement model-aware navigation tools (e.g., "find_class_by_name", "get_parent_classes", "list_attributes") and compare accuracy against the current general-purpose file tools. This would determine whether the observed accuracy limitations stem from tool architecture rather than the agentic approach itself.

3. **Context window threshold analysis**: Systematically vary model sizes (50, 100, 200, 384, 500+ classes) and plot accuracy-token curves for both approaches across all four LLMs. This would identify precise crossover points where each approach becomes optimal and validate the scalability claims.