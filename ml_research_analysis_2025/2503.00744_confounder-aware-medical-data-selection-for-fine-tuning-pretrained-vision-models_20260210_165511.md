---
ver: rpa2
title: Confounder-Aware Medical Data Selection for Fine-Tuning Pretrained Vision Models
arxiv_id: '2503.00744'
source_url: https://arxiv.org/abs/2503.00744
tags:
- data
- uni00000003
- selection
- medical
- confounding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of selecting representative, high-quality
  medical imaging data for fine-tuning pre-trained vision models, addressing challenges
  like annotation costs, privacy concerns, and the confounding effects of uncontrolled
  variables. The authors propose a confounder-aware medical data selection approach
  that first identifies potential confounding variables in the data using pre-trained
  vision models and feature clustering, then employs a distance-based sampling strategy
  to select minimal yet representative subsets.
---

# Confounder-Aware Medical Data Selection for Fine-Tuning Pretrained Vision Models

## Quick Facts
- arXiv ID: 2503.00744
- Source URL: https://arxiv.org/abs/2503.00744
- Reference count: 0
- This paper proposes a method to select high-quality medical imaging data for fine-tuning pretrained vision models while mitigating confounding variables.

## Executive Summary
This paper addresses the challenge of selecting representative, high-quality medical imaging data for fine-tuning pre-trained vision models, particularly in the presence of confounding variables that can introduce bias. The authors propose a confounder-aware data selection approach that uses pre-trained vision models and feature clustering to identify potential confounders, then employs distance-based sampling to select minimal yet representative subsets that preserve the dataset's natural distribution. Experiments across three medical imaging modalities show the method consistently outperforms state-of-the-art baselines, with notable efficiency gains - achieving better performance than full training sets with only 16 samples per class in one case.

## Method Summary
The method uses a two-stage approach: first, it extracts features from training images using a frozen MAE-ViT-Base encoder pretrained on ImageNet, then applies dimensionality reduction (to R²) and class-wise DBSCAN clustering to identify confounder-based groups. Second, for each class, it computes cluster centers, sorts samples by distance to center, and uniformly samples from each cluster proportional to its size. The selected coreset is then used to fine-tune a trainable ViT-Base model using AdamW optimizer. Critical parameters include manual calibration of DBSCAN hyperparameters (epsilon, min_samples) per dataset.

## Key Results
- The method consistently outperformed state-of-the-art data selection baselines across three medical imaging modalities
- With only 16 samples per class, achieved better performance than using the full training set on one dataset
- Uniform distance-based sampling within clusters outperformed closest, furthest, and median sampling strategies
- The approach demonstrates efficiency gains while maintaining or improving model generalization

## Why This Works (Mechanism)

### Mechanism 1: Latent Space Confounder Disentanglement
If pre-trained vision features effectively separate domain-specific confounders, clustering can isolate these distinct distributions prior to selection. A pre-trained encoder (MAE) transforms raw images into latent vectors, dimensionality reduction maps these to 2D space, and DBSCAN groups samples. The authors posit that these clusters often correspond to unobserved confounding variables (e.g., specific ultrasound machines), allowing the selection process to "see" and control for hidden variables. This mechanism assumes the variance in pre-trained latent space correlates strongly with confounding variables rather than just the pathological target.

### Mechanism 2: Distribution-Preserving Proportional Sampling
Sampling proportionally from identified confounder clusters preserves the natural data distribution while preventing any single confounder from dominating the training gradient. Instead of random sampling, the method calculates allocation for each cluster based on its size relative to the total class size. This ensures that if a specific confounder represents 30% of the raw data, it represents roughly 30% of the selected coreset. The core assumption is that the "natural distribution" contains a signal-to-noise ratio superior to a biased subset.

### Mechanism 3: Uniform Distance-Based Coverage
Selecting samples uniformly based on their distance to the cluster center captures the diversity of the intra-cluster variance better than selecting only "prototypical" (closest) or "hard" (furthest) samples. Within a cluster, samples are sorted by distance to the center, and the algorithm selects points at uniform intervals across this sorted list. This avoids the redundancy of picking only the cluster core or only the outliers, trading potential rapid convergence for stability and generalization.

## Foundational Learning

- **Concept: Confounding Variables in Medical Imaging**
  - Why needed here: The entire method rests on identifying and controlling variables (like machine type or lighting) that correlate with both the input and the outcome but are not causal. Without this, models learn spurious correlations (e.g., "all images from Machine A are cancerous").
  - Quick check question: Can you distinguish between a "selection bias" and a "confounding variable" in the context of a multi-hospital dataset?

- **Concept: Coreset Selection (Data Distillation/Pruning)**
  - Why needed here: The paper aims to reduce the data footprint. Understanding the trade-off between informativeness and redundancy is key to understanding why they choose a "minimal representative subset" rather than just cleaning the data.
  - Quick check question: How does the goal of a coreset differ from simply filtering out "noisy" labels?

- **Concept: DBSCAN (Density-Based Spatial Clustering)**
  - Why needed here: The authors use DBSCAN to identify confounder clusters. Unlike K-Means, DBSCAN does not require specifying the number of clusters beforehand, which is crucial since the number of confounders is usually unknown.
  - Quick check question: Why is the `epsilon` (neighborhood size) parameter critical for this method, and what happens if it is set too low?

## Architecture Onboarding

- **Component map:**
  Feature Encoder (MAE-ViT-Base, frozen) -> Projection Head (dimensionality reduction to R²) -> Clustering Engine (DBSCAN) -> Sampler (proportional allocation + uniform distance selection) -> Downstream Model (ViT-Base, trainable)

- **Critical path:**
  The method requires manual calibration of the clustering algorithm (DBSCAN) to align with anticipated confounders. The separation of confounders depends entirely on the pre-trained encoder's ability to represent domain shifts.

- **Design tradeoffs:**
  Automation vs. Accuracy: The authors note the limitation of manual calibration for clustering parameters. An automated approach would be faster but might miss clinically relevant confounder distinctions. Uniform vs. Hard Mining: By choosing uniform sampling, the method favors distribution preservation over focusing on "hard" examples, trading potential rapid convergence for stability and generalization.

- **Failure signatures:**
  Over-clustering: If DBSCAN is too sensitive, it splits single confounders into many clusters, leading to redundant sampling and wasted budget. Under-clustering: If DBSCAN merges distinct confounders into one cluster, the bias remains uncorrected. Projection Collapse: If dimensionality reduction mixes class signal with confounder signal, the selection will fail to isolate the bias.

- **First 3 experiments:**
  1. Baseline Efficiency: Compare the Confounder-Aware method vs. Random Sampling and "Moderate" sampling at very low data regimes (8-16 samples/class) to verify efficiency claims.
  2. Ablation on Sampling Strategy: Replicate Table 1 to confirm that Uniform sampling outperforms Median/Closest strategies on a new dataset.
  3. Cross-Domain Validation: Test generalization by fine-tuning on the selected coreset from one hospital and testing on a held-out hospital to measure true confounder mitigation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the parameter calibration for the clustering algorithm be automated to eliminate the reliance on manual tuning while ensuring accurate confounder alignment?
- Basis in paper: The conclusion states that a current limitation is the "requirement for manual calibration of clustering algorithm parameters to yield optimal alignment with anticipated clustering outcomes."
- Why unresolved: The current method depends on human judgment to set parameters that define what constitutes a confounder cluster, preventing fully automated deployment in diverse clinical settings.
- What evidence would resolve it: An algorithm or heuristic that automatically determines optimal clustering parameters based on intrinsic data properties and achieves comparable performance to the manually calibrated baseline.

### Open Question 2
- Question: Can the confounder-aware selection strategy be effectively generalized to 3D medical imaging modalities (e.g., CT, MRI) or dense prediction tasks like segmentation?
- Basis in paper: The experiments are confined to 2D "classification fine-tuning tasks" across three specific datasets, leaving the efficacy on volumetric data or pixel-level tasks unstated.
- Why unresolved: 3D data introduces higher dimensionality and different confounding structures, and segmentation requires different labeling constraints that may affect the clustering and sampling logic.
- What evidence would resolve it: Successful application of the method on a 3D dataset (e.g., BraTS) or a segmentation benchmark, showing performance gains over random sampling similar to the 2D classification results.

### Open Question 3
- Question: To what extent does the choice of the pre-trained feature extractor impact the detection of clinically relevant confounders?
- Basis in paper: The method relies on "pre-trained vision foundation models" for feature extraction before clustering. While an ablation study compares different models, it does not explore if generic models miss domain-specific confounders that a medical-specific foundation model would capture.
- Why unresolved: Generic models pre-trained on ImageNet might cluster based on low-level visual cues rather than high-level semantic confounders specific to medical physics or biology.
- What evidence would resolve it: A comparative analysis of the resulting clusters when using generic versus medical-domain specific backbones, correlated with known ground-truth confounders.

## Limitations
- The method requires manual calibration of DBSCAN hyperparameters for each dataset, which is impractical for large-scale deployment
- Performance gains are demonstrated primarily on small sample regimes (8-32 samples per class), with diminishing returns at larger sizes
- The method's effectiveness depends heavily on the pre-trained encoder's ability to disentangle confounders from pathological features
- The dimensionality reduction method is unspecified (only output dimension R² is mentioned)

## Confidence

- **High confidence:** The core mechanism of using distance-based uniform sampling within confounder clusters is well-validated through ablation studies
- **Medium confidence:** Claims about preserving natural data distribution are supported by experimental results but lack theoretical guarantees
- **Medium confidence:** Efficiency claims (better performance with fewer samples) are demonstrated but may not generalize to all medical imaging tasks

## Next Checks

1. Test the method's performance on a multi-site dataset with known confounders to validate actual confounder mitigation
2. Conduct experiments varying the dimensionality reduction method to assess sensitivity to this critical choice
3. Evaluate the method's performance in an out-of-distribution setting where test data comes from different confounder distributions than training data