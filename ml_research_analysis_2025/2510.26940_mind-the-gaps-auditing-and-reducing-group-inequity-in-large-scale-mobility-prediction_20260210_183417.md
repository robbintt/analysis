---
ver: rpa2
title: 'Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility
  Prediction'
arxiv_id: '2510.26940'
source_url: https://arxiv.org/abs/2510.26940
tags:
- accuracy
- fairness
- group
- prediction
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first large-scale audit of fairness in
  next-location prediction models, revealing systematic disparities in predictive
  accuracy across racial and ethnic groups. The authors introduce Size-Aware K-Means
  (SAKM) to generate demographically grounded proxy labels without individual-level
  demographic data, enabling fairness evaluation in unlabeled settings.
---

# Mind the Gaps: Auditing and Reducing Group Inequity in Large-Scale Mobility Prediction

## Quick Facts
- **arXiv ID**: 2510.26940
- **Source URL**: https://arxiv.org/abs/2510.26940
- **Reference count**: 27
- **One-line primary result**: FGIS reduces Total Demographic Parity Violations by up to 40% in early training stages with minimal accuracy trade-offs

## Executive Summary
This paper presents the first large-scale audit of fairness in next-location prediction models, revealing systematic disparities in predictive accuracy across racial and ethnic groups. The authors introduce Size-Aware K-Means (SAKM) to generate demographically grounded proxy labels without individual-level demographic data, enabling fairness evaluation in unlabeled settings. Building on these labels, they propose Fairness-Guided Incremental Sampling (FGIS), a lightweight data sampling strategy that prioritizes underrepresented or underperforming groups during incremental data collection. Evaluated on MetaPath2Vec and transformer-encoder models, FGIS reduces Total Demographic Parity Violations by up to 40% in early training stages with minimal accuracy trade-offs, demonstrating that model-agnostic data-centric interventions can significantly improve equity in mobility prediction.

## Method Summary
The paper combines a fairness auditing methodology with a data sampling intervention for mobility prediction. SAKM generates proxy demographic labels by clustering users in latent mobility space while enforcing census-derived group proportions through Lagrangian penalties. FGIS then samples training data proportionally to group performance and representation, using weights computed as the inverse of current accuracy times representation raised to a fairness parameter β. The method is evaluated through incremental learning where models are retrained from scratch after each batch, showing significant TDPV reduction in early stages.

## Key Results
- SAKM calibration curves show clusters match census-derived proportions within small margins across all groups
- FGIS reduces Total Demographic Parity Violations by up to 40% in early training stages with minimal accuracy trade-offs
- Improvements are most significant in early sampling stages, with TDPV reduction of 30-50% early and 10-35% sustained

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAKM enables fairness evaluation without individual demographic labels by generating proxy group assignments that match census-derived proportions.
- Mechanism: SAKM extends standard k-means by introducing Lagrangian penalties during the assignment step. The cost function becomes `cost(xi, g) = ||xi - μg||² + λg`, where λg is updated iteratively as `λg ← λg + η·(ng/N - πg)`, penalizing deviations from target proportions. The algorithm runs over all k! permutations of target proportions to resolve label ambiguity.
- Core assumption: Users' latent mobility patterns cluster in ways that correlate with demographic groups, and census priors provide reasonable approximation of true group distributions.
- Evidence anchors:
  - [abstract]: "we introduce Size-Aware K-Means (SAKM)—a clustering method that partitions users in latent mobility space while enforcing census-derived group proportions"
  - [section]: Figure 7 calibration curves show SAKM clusters match target distribution within small margin across all groups
  - [corpus]: Related work on distribution-free fairness auditing (Empirical Likelihood-Based Fairness Auditing) supports feasibility of proxy-label approaches
- Break condition: If mobility patterns don't correlate with demographic geography, proxy labels will misclassify users and interventions may target wrong groups.

### Mechanism 2
- Claim: FGIS reduces disparity by dynamically weighting group sampling based on both current accuracy and representation.
- Mechanism: Sampling weights computed as `wg ∝ [zg · (xg + 1)]^(-β)`, where zg is current group accuracy and xg is current representation. This reflects a first-order approximation of expected fairness gain: groups with low accuracy and few samples are prioritized.
- Core assumption: Groups with lower accuracy and fewer samples benefit more from additional data (diminishing returns on already-well-represented groups).
- Evidence anchors:
  - [abstract]: "FGIS reduces Total Demographic Parity Violations by up to 40% in early training stages with minimal accuracy trade-offs"
  - [section]: "larger β values consistently reduce TDPV, with improvements of up to 30% (transformer) and 50% (MetaPath2Vec) in early iterations"
  - [corpus]: Group-based optimization approaches (Infinite Sampling) validate the general approach of weighted group-level training
- Break condition: If model capacity is saturated or groups have fundamentally different optimal representations, oversampling won't improve underperforming groups.

### Mechanism 3
- Claim: Fairness-aware sampling is most effective in low-data regimes before model convergence.
- Mechanism: By prioritizing underperforming groups during early incremental data collection, the model learns more equitable representations before overfitting to majority patterns. After batch 4, all strategies converge to similar accuracy, suggesting the intervention's value is front-loaded.
- Core assumption: Early training samples disproportionately influence final learned representations; correcting distribution early prevents entrenched bias.
- Evidence anchors:
  - [abstract]: "Improvements are most significant in early sampling stages, highlighting the potential for fairness-aware strategies to deliver meaningful gains even in low-resource settings"
  - [section]: Figure 2 shows TDPV reduction of 30-50% early, sustaining 10-35% by final step; Figure 3 shows Pareto dominance of high-β trajectories
  - [corpus]: Fair active learning literature supports the general principle of strategic early-stage data selection
- Break condition: If early intervention distorts data distribution so severely that downstream accuracy degrades significantly, the fairness-utility tradeoff may be unacceptable.

## Foundational Learning

- Concept: Total Demographic Parity Violations (TDPV)
  - Why needed here: TDPV is the primary fairness metric used throughout; computed as sum of pairwise accuracy differences: `TDPV = Σ|zgi - zgj|`
  - Quick check question: Can you explain why TDPV uses pairwise differences rather than variance, and what a TDPV of 0.174 (statewide ZCTA level) means in practical terms?

- Concept: Constrained Clustering with Lagrangian Optimization
  - Why needed here: SAKM's core innovation; requires understanding how penalty terms enforce size constraints
  - Quick check question: How does the λg multiplier control cluster size, and what happens if step-size η is set too large?

- Concept: Incremental Learning with Batch Retraining
  - Why needed here: FGIS operates in a practical setting where models are retrained after each batch, not per-sample
  - Quick check question: Why does FGIS use mini-batches (m=50) within larger batches (B=1000) rather than updating weights after every user?

## Architecture Onboarding

- Component map:
  Data Layer -> SAKM Module -> FGIS Sampler -> Model Layer -> Evaluation

- Critical path:
  1. Obtain census data for target region → set target proportions π
  2. Generate user mobility embeddings from trajectory features
  3. Run SAKM with k! permutation search (24 permutations for k=4) → validate calibration
  4. Initialize FGIS with z^(0)g estimates (paper uses 0.1)
  5. For each round: sample batch → retrain model → update group accuracies → recompute weights
  6. Monitor TDPV trajectory; expect 30-50% early reduction plateauing to 10-35% sustained

- Design tradeoffs:
  - **β (fairness weight)**: Higher = more equity, potential early accuracy drop (Figure 1 shows β=100 reduces early accuracy ~2-3%)
  - **Mini-batch size m**: Smaller = more responsive weights, higher overhead (paper uses m=50, B=1000)
  - **Permutation search**: k! complexity; tractable for k=4, prohibitive for k>7
  - **Model choice**: MetaPath2Vec achieves ~50% Acc@20 vs Transformer's ~28%, but both show similar relative TDPV reduction patterns

- Failure signatures:
  - SAKM calibration curves show >10% deviation from census targets → proxy labels unreliable
  - TDPV increases with higher β (should decrease) → weight formula may be misimplemented
  - Overall accuracy drops >5% at convergence → β too aggressive for data distribution
  - Group accuracies diverge over time despite oversampling → fundamental representation problem

- First 3 experiments:
  1. **SAKM Validation**: Run SAKM on your dataset with census priors. Plot calibration curves (predicted vs. target proportions). If R² < 0.8 across groups, proxy labeling may not capture demographic structure.
  2. **β Sensitivity Analysis**: Run FGIS with β ∈ {0, 10, 50, 100} for 10 iterations. Plot TDPV vs. accuracy trajectories. Identify the β where TDPV reduction plateaus without accuracy loss exceeding your tolerance.
  3. **Timing Ablation**: Compare (a) FGIS from iteration 1, (b) uniform sampling until iteration 5 then FGIS, (c) uniform throughout. Quantify whether early intervention is necessary as claimed, or if late-stage correction works.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does FGIS effectively reduce disparities in geographies with spatial structures different from Texas?
- Basis in paper: [explicit] The authors state, "In future work, we plan to extend our evaluation to additional geographies."
- Why unresolved: The intervention is currently validated only on Texas data.
- What evidence would resolve it: Evaluation on non-US or non-Texas mobility datasets with distinct urban layouts.

### Open Question 2
- Question: Can adaptive β-scheduling optimize the fairness-utility tradeoff better than manual selection?
- Basis in paper: [explicit] The paper proposes exploring "adaptive β-schedules" to replace the current "manually selected hyperparameter."
- Why unresolved: A static β cannot react to changing disparity levels during training.
- What evidence would resolve it: A dynamic adjustment algorithm showing superior TDPV reduction over fixed baselines.

### Open Question 3
- Question: Do SAKM proxy clusters align with actual individual-level demographics?
- Basis in paper: [explicit] The authors suggest future work "validate SAKM against ground-truth surveys."
- Why unresolved: SAKM relies on census aggregates, lacking verification of individual alignment.
- What evidence would resolve it: Cluster purity analysis using a dataset with self-reported demographic labels.

### Open Question 4
- Question: How sensitive is the audit to violations of the intra-region uniformity assumption?
- Basis in paper: [inferred] The method assumes accuracy is constant across groups within a single ZCTA.
- Why unresolved: If groups in the same region have distinct mobility patterns, aggregate accuracy estimates may mask local inequities.
- What evidence would resolve it: Comparison of estimated vs. actual group accuracy in regions with high demographic variance.

## Limitations

- **Data access bottleneck**: The Texas Mobility Dataset is not publicly available, preventing independent replication. While synthetic data could approximate trajectories, the specific demographic-geographic correlations that make SAKM effective are dataset-specific and cannot be guaranteed.
- **Proxy label fidelity**: SAKM's effectiveness depends on mobility patterns correlating with demographic geography. The paper shows calibration curves matching census proportions, but without ground truth demographic labels, we cannot validate that SAKM clusters represent true demographic groups rather than correlated geographic patterns.
- **Hyperparameter sensitivity**: Key SAKM parameters (η, τ) and FGIS parameters (β tuning, mini-batch size) are under-specified. The paper uses β=100 for strong results but doesn't provide a principled method for selecting β beyond empirical sweeps.

## Confidence

- **High confidence**: The general fairness-utility tradeoff observed (TDPV reduction up to 40% with minimal accuracy loss) is supported by multiple experiments across models. The core insight that early-stage data sampling significantly impacts final fairness outcomes is well-established in related literature.
- **Medium confidence**: The specific TDPV reduction percentages (30-50% early, 10-35% sustained) depend heavily on dataset characteristics and implementation details that aren't fully specified. The SAKM calibration success is demonstrated but not independently verified.
- **Low confidence**: Claims about FGIS being "model-agnostic" are somewhat overstated - while the sampling strategy works across different model architectures, the magnitude of fairness gains likely depends on how well the model can learn from the reweighted data distribution.

## Next Checks

1. **Ground truth audit**: If possible, obtain a small labeled subset of the Texas Mobility Dataset to validate SAKM proxy labels against true demographics. Measure classification accuracy of SAKM assignments and re-run FGIS with verified labels to confirm the mechanism.
2. **Sensitivity analysis**: Systematically vary β from 0 to 200 in increments of 25, running 5 random seeds each. Plot TDPV reduction vs. accuracy drop to identify the Pareto frontier and test whether the claimed 40% TDPV reduction consistently occurs without >2% accuracy loss.
3. **Early intervention test**: Compare FGIS starting at iteration 1 versus starting at iteration 5 (uniform sampling first). If early intervention provides no additional benefit beyond late-stage correction, the paper's emphasis on "low-resource settings" may be overstated.