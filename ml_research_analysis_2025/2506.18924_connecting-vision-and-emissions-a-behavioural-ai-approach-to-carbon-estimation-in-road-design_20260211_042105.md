---
ver: rpa2
title: 'Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation
  in Road Design'
arxiv_id: '2506.18924'
source_url: https://arxiv.org/abs/2506.18924
tags:
- vehicle
- emissions
- detection
- traffic
- emission
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an enhanced YOLOv8-based framework for real-time
  vehicle detection, license plate recognition, and carbon emission estimation in
  urban traffic environments. The system uses YOLOv8 for vehicle detection and segmentation,
  followed by a deep OCR model to extract license plate numbers, which are validated
  via a simulated vehicle registration API.
---

# Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design

## Quick Facts
- **arXiv ID**: 2506.18924
- **Source URL**: https://arxiv.org/abs/2506.18924
- **Reference count**: 39
- **Primary result**: Enhanced YOLOv8-based framework for real-time vehicle detection, license plate recognition, and carbon emission estimation in urban traffic environments.

## Executive Summary
This paper introduces an enhanced YOLOv8-based framework for real-time vehicle detection, license plate recognition, and carbon emission estimation in urban traffic environments. The system uses YOLOv8 for vehicle detection and segmentation, followed by a deep OCR model to extract license plate numbers, which are validated via a simulated vehicle registration API. By integrating visual classification with emission factor mapping, the framework provides per-vehicle CO2 estimates directly from traffic camera feeds. Experimental results show a mean Average Precision (mAP@0.5) of 0.71% for bounding boxes and 0.70% for segmentation masks, with OCR accuracy up to 99%.

## Method Summary
The framework employs YOLOv8 for vehicle detection and segmentation, followed by a deep OCR model to extract license plate numbers. These are validated through a simulated vehicle registration API. The system integrates visual classification with emission factor mapping to provide per-vehicle CO2 estimates directly from traffic camera feeds. The approach combines behavioral AI and computer vision for automated, vehicle-specific carbon emission monitoring.

## Key Results
- Mean Average Precision (mAP@0.5) of 0.71% for bounding boxes and 0.70% for segmentation masks
- OCR accuracy up to 99%
- Feasibility demonstrated for automated, vehicle-specific carbon emission monitoring from traffic camera feeds

## Why This Works (Mechanism)
The system leverages behavioral AI and computer vision to automate carbon emission monitoring by detecting vehicles, recognizing license plates, and estimating emissions. The YOLOv8 model provides real-time detection and segmentation, while OCR extracts plate numbers for vehicle identification. Integration with emission factor mapping allows per-vehicle CO2 estimation, creating a non-intrusive alternative to traditional emission tracking methods.

## Foundational Learning
- **YOLOv8 object detection**: Real-time vehicle detection and segmentation in traffic scenes. Needed for accurate vehicle identification and localization. Quick check: Evaluate mAP@0.5 on validation set.
- **OCR for license plates**: Extracting vehicle identification from images. Needed to link visual data to specific vehicles. Quick check: Test OCR accuracy across varying lighting and plate formats.
- **Emission factor mapping**: Converting vehicle data to CO2 estimates. Needed for per-vehicle emission calculation. Quick check: Validate emission estimates against ground-truth data.

## Architecture Onboarding

**Component map**: Traffic camera feed -> YOLOv8 detection -> Segmentation mask generation -> OCR license plate extraction -> Simulated registration API validation -> Emission factor mapping -> CO2 estimation

**Critical path**: Vehicle detection (YOLOv8) -> License plate OCR -> Emission factor mapping

**Design tradeoffs**: Real-time processing vs. detection accuracy; simulated vs. real vehicle registration database; visual classification vs. direct emission measurement

**Failure signatures**: Low mAP values indicate detection/segmentation issues; OCR errors suggest plate recognition failures; emission factor mapping inaccuracies point to classification errors

**First experiments**: 1) Test YOLOv8 detection and segmentation on diverse traffic scenarios. 2) Validate OCR accuracy across varying lighting and plate formats. 3) Compare emission estimates against ground-truth sensor data.

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Low mAP@0.5 values (0.71% detection, 0.70% segmentation) suggest precision issues in complex traffic scenarios
- OCR accuracy claims require validation under real-world conditions
- Emission factor mapping methodology not detailed, raising questions about estimation accuracy
- No real-world validation or comparison with ground-truth emission data

## Confidence
- **Detection/segmentation performance**: Low - notably low mAP values and lack of real-world testing
- **OCR accuracy claims**: Low - 99% figure requires validation across varying conditions
- **Emission estimation methodology**: Low - unclear mapping process and no validation against ground truth

## Next Checks
1. Conduct field tests using live traffic camera feeds in diverse urban environments to assess detection and segmentation performance under real conditions.
2. Validate OCR accuracy and license plate matching using a real vehicle registration database rather than a simulated API.
3. Compare the system's per-vehicle CO2 estimates against ground-truth emission data from calibrated sensors or official emission inventories to verify accuracy.