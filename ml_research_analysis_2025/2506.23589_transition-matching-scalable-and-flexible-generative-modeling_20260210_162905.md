---
ver: rpa2
title: 'Transition Matching: Scalable and Flexible Generative Modeling'
arxiv_id: '2506.23589'
source_url: https://arxiv.org/abs/2506.23589
tags:
- matching
- fhtm
- transition
- flow
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Transition Matching (TM), a discrete-time
  continuous-state generative modeling paradigm that unifies diffusion/flow models
  and continuous autoregressive generation. The key innovation is decomposing generation
  into simpler Markov transitions with expressive non-deterministic kernels and arbitrary
  supervision processes.
---

# Transition Matching: Scalable and Flexible Generative Modeling

## Quick Facts
- **arXiv ID**: 2506.23589
- **Source URL**: https://arxiv.org/abs/2506.23589
- **Reference count**: 40
- **Primary result**: Introduces Transition Matching (TM) unifying diffusion/flow models and continuous autoregressive generation with 7× faster sampling than flow matching

## Executive Summary
Transition Matching (TM) presents a novel discrete-time continuous-state generative modeling framework that unifies diffusion/flow models with continuous autoregressive generation. The key innovation lies in decomposing generation into simpler Markov transitions with expressive non-deterministic kernels and arbitrary supervision processes. The authors propose three variants: Difference Transition Matching (DTM) for efficient image generation, Autoregressive Transition Matching (ARTM), and Full History Transition Matching (FHTM) for causal generation. Notably, FHTM achieves state-of-the-art performance on text-to-image tasks as the first fully causal model to match or surpass flow-based methods in continuous domains.

## Method Summary
The Transition Matching framework establishes a Markov transition framework for continuous generative modeling that bridges diffusion/flow models and continuous autoregressive generation. The core idea involves learning a series of simpler Markov transitions with expressive non-deterministic kernels, where each transition is parameterized to handle arbitrary supervision processes. Three specific variants are introduced: DTM generalizes flow matching to discrete time with significant sampling efficiency gains, ARTM extends continuous autoregressive methods with improved quality, and FHTM enables fully causal generation that matches or exceeds flow-based performance on text-to-image tasks. The framework achieves CLIPScore of 21.2 on a 350M image dataset, outperforming flow matching (21.0) while requiring only 16 backbone forwards versus 128 for flow matching.

## Key Results
- DTM achieves state-of-the-art image quality with 7× faster sampling than flow matching
- FHTM is the first fully causal model to match or surpass flow-based methods on text-to-image tasks in continuous domains
- On a 350M image dataset, DTM achieves CLIPScore of 21.2 compared to 21.0 for flow matching
- DTM requires only 16 backbone forwards versus 128 for flow matching

## Why This Works (Mechanism)
The framework works by decomposing complex generative tasks into simpler Markov transitions that can be learned efficiently. By using expressive non-deterministic kernels and allowing arbitrary supervision processes, the model can capture complex distributions while maintaining computational efficiency. The discrete-time formulation enables better control over the generation process compared to continuous-time approaches, while the unification of different generative modeling paradigms provides flexibility in handling various types of supervision and generation requirements.

## Foundational Learning
- **Markov transitions**: The core building block representing state changes; needed for decomposing complex generation into simpler steps; quick check: verify transition kernels satisfy Markov property
- **Non-deterministic kernels**: Allow for stochastic generation while maintaining expressiveness; needed for capturing complex distributions; quick check: test kernel behavior under different noise levels
- **Supervision processes**: Arbitrary conditioning mechanisms that guide generation; needed for flexible control over generation; quick check: verify conditioning affects generated samples appropriately
- **Discrete-time formulation**: Enables efficient computation compared to continuous-time approaches; needed for practical implementation; quick check: compare sampling efficiency with continuous-time baselines
- **Causal generation**: Ensuring generation can proceed without future information; needed for real-time applications; quick check: verify no future information leakage in generation process
- **CLIPScore evaluation**: Standard metric for image generation quality; needed for benchmarking against state-of-the-art; quick check: correlate CLIPScore with human evaluation

## Architecture Onboarding

**Component Map**: Input data -> Markov transitions -> Non-deterministic kernels -> Supervision processes -> Generated output

**Critical Path**: Data preprocessing → Transition kernel learning → Supervision integration → Sampling generation → Quality evaluation

**Design Tradeoffs**: The framework balances expressiveness (through non-deterministic kernels) against computational efficiency (through discrete-time formulation). The choice between DTM, ARTM, and FHTM depends on whether speed, quality, or causality is prioritized.

**Failure Signatures**: Poor performance may indicate: inadequate kernel expressiveness, improper supervision process design, or insufficient training data. Sampling artifacts could suggest issues with kernel stability or discretization errors.

**3 First Experiments**:
1. Test DTM on a small image dataset to verify the 7× speedup claim and basic functionality
2. Evaluate ARTM's quality improvement over standard autoregressive methods on a controlled dataset
3. Validate FHTM's causality by checking for future information leakage during generation

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Theoretical guarantees are primarily established for Gaussian transition kernels, with limited analysis for non-Gaussian cases
- Empirical evaluation relies heavily on a single large-scale image dataset without systematic ablation studies across diverse domains
- Computational efficiency claims lack detailed wall-clock time measurements across different hardware configurations
- Behavior under distribution shift and out-of-distribution inputs remains unexplored

## Confidence
**High Confidence**: The unification of diffusion/flow models with continuous autoregressive generation through the Markov transition framework is theoretically sound and well-supported by the mathematical formulation.

**Medium Confidence**: The empirical performance claims, particularly the 7× speedup over flow matching and CLIPScore improvements, are credible but would benefit from more extensive benchmarking.

**Low Confidence**: Claims about the framework's applicability to arbitrary supervision processes and potential for other domains beyond images are speculative without supporting experiments.

## Next Checks
1. **Cross-domain generalization**: Evaluate DTM, ARTM, and FHTM on at least two non-image domains (e.g., medical imaging, scientific data, or time series) to assess the framework's versatility.

2. **Distribution shift robustness**: Test model performance under distribution shift scenarios (e.g., fine-tuning on subsets of data, synthetic corruptions) to understand generalization limits and failure modes.

3. **Theoretical analysis of non-Gaussian kernels**: Provide formal convergence guarantees or error bounds for the proposed non-Gaussian transition kernels, particularly for the ARTM and FHTM variants.