---
ver: rpa2
title: Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation
arxiv_id: '2505.09263'
source_url: https://arxiv.org/abs/2505.09263
tags:
- anomaly
- anomalies
- images
- detection
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of anomaly detection in industrial
  inspection, where real-world anomaly data is scarce. The authors propose a few-shot
  Anomaly-driven Generation (AnoGen) method that guides a diffusion model to generate
  realistic and diverse anomalies using only a few real anomalies.
---

# Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation

## Quick Facts
- **arXiv ID**: 2505.09263
- **Source URL**: https://arxiv.org/abs/2505.09263
- **Reference count**: 40
- **Primary result**: Generates realistic anomalies using 1-3 support samples, improving anomaly detection segmentation by 5.8% AU-PR for DRAEM and 1.5% for DeSTSeg on MVTec

## Executive Summary
This paper addresses the challenge of training anomaly detection models when real anomaly data is scarce. The authors propose AnoGen, a few-shot anomaly-driven generation method that learns anomaly distributions from 1-3 support samples and uses a pre-trained diffusion model to generate realistic, spatially-controllable anomalies. The method improves anomaly detection performance on the MVTec dataset, with segmentation models achieving 5.8% and 1.5% AU-PR improvements. The approach consists of three stages: embedding optimization, bounding-box-conditioned generation, and weakly-supervised training.

## Method Summary
AnoGen generates synthetic anomalies to address data scarcity in industrial inspection. The method uses a pre-trained Latent Diffusion Model (LDM) and learns a 768-dimensional embedding vector from 1-3 support anomalies via mask-guided optimization. This embedding guides the LDM to generate realistic anomalies on normal images within user-specified bounding boxes. A weakly-supervised training approach handles the imprecision of bounding-box annotations by filtering high-confidence normal pixels. The generated anomalies are then used to train downstream anomaly detection models (DRAEM and DeSTSeg), improving their performance on the MVTec dataset.

## Key Results
- Improves segmentation performance by 5.8% AU-PR for DRAEM and 1.5% for DeSTSeg on MVTec dataset
- Successfully generates semantically consistent anomalies that enhance downstream model performance
- Demonstrates effectiveness of few-shot learning approach with only 1-3 support anomalies per defect type
- Shows that combining generated anomalies with existing synthetic anomalies achieves optimal performance (73.2% AU-PR)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A compact embedding vector (~768 parameters) can capture anomaly distribution from 1-3 support samples when optimized via mask-guided diffusion loss.
- Mechanism: The paper freezes a pre-trained Latent Diffusion Model and optimizes only an embedding vector `v` using the noise prediction loss `L'LDM = E[||(ε - εθ(ε(Ia^T), t, v)) ⊙ Ma^T||²]`. The mask `Ma^T` focuses gradient signals on anomaly regions rather than the entire object, preventing the embedding from collapsing to represent the object class (e.g., "bottle") instead of the anomaly (e.g., "broken").
- Core assumption: The pre-trained diffusion model's learned representation space is sufficiently expressive that a low-dimensional probe (the embedding) can steer it to novel concepts without weight updates.
- Evidence anchors:
  - [abstract]: "we learn the anomaly distribution based on a few given real anomalies and inject the learned knowledge into an embedding"
  - [section 4.1]: "Without the guidance of the mask, the distribution represented by the embeddings is biased towards the entire object ('bottle'), failing to generate anomaly ('broken')"
  - [corpus]: Weak/indirect—neighbor papers discuss few-shot anomaly detection but not embedding optimization in diffusion models.

### Mechanism 2
- Claim: Bounding-box-conditioned inpainting enables spatially controllable anomaly generation while preserving background integrity.
- Mechanism: During denoising, the method replaces regions outside the bounding box with the noisy version of a normal image: `zt = zt^n ⊙ (1 - Mbox) + z't ⊙ Mbox`. This forces the diffusion model to inpaint only within the box, using the learned embedding for semantic guidance. The box serves dual purposes: spatial control and weak supervision (bounding box as pseudo-label).
- Core assumption: The diffusion model's inpainting capability generalizes to industrial anomaly patterns not seen during pre-training.
- Evidence anchors:
  - [abstract]: "we use the embedding and given bounding boxes to guide the diffusion model to generate realistic and diverse anomalies on specific objects"
  - [section 4.2]: "For the inference image at each step in the denoising process, the area within the box will be retained, and the area outside the box will be replaced by the noisy version of In"
  - [corpus]: No direct validation; inpainting for anomaly generation is novel per this work.

### Mechanism 3
- Claim: Weakly-supervised training with confidence thresholding mitigates label noise from bounding-box supervision.
- Mechanism: Since bounding boxes contain both anomalous and normal pixels, the method filters high-confidence normal predictions within boxes using threshold τ. Pixels with predicted normal probability `p̂(i,j) ≥ τ` have loss set to 0: `L'seg = Mbox ⊙ (1 - δ) ⊙ Lseg + (1 - Mbox) ⊙ Lseg`. This prevents forcing normal pixels inside boxes to be classified as anomalous.
- Core assumption: The anomaly detector produces calibrated confidence scores; high-confidence predictions reliably indicate true normals.
- Evidence anchors:
  - [abstract]: "we propose a weakly-supervised anomaly detection method to train a more powerful model with generated anomalies"
  - [section 6.2]: "τ has a significant impact on segmentation tasks... when τ = 0.9, the pixel-level AU-PR reaches 73.2%, whereas when τ = 1.0 and τ = 0.8, the performance decreases to 68.9% and 65.4%"
  - [corpus]: Weak—neighbor papers don't address weak supervision for anomaly segmentation.

## Foundational Learning

- **Concept: Latent Diffusion Models (LDMs)**
  - Why needed here: The entire generation pipeline builds on a pre-trained LDM. Understanding how LDMs compress images to latent space, inject conditions via cross-attention, and denoise iteratively is essential for debugging embedding learning and generation quality.
  - Quick check question: Can you explain why LDMs operate in latent space rather than pixel space, and how cross-attention conditions the denoising process?

- **Concept: Few-Shot Learning via Embedding Optimization**
  - Why needed here: The method adapts to new anomaly types by optimizing only an embedding (not model weights). This is analogous to textual inversion or prompt tuning in vision-language models.
  - Quick check question: Why is embedding optimization preferred over fine-tuning when only 1-3 samples are available?

- **Concept: Weakly-Supervised Segmentation**
  - Why needed here: Bounding boxes are cheaper annotations than pixel masks, but introduce label ambiguity. Understanding how to train with imprecise labels (e.g., ignoring high-confidence normals) is critical for Stage 3.
  - Quick check question: What happens if you train a segmentation model with bounding box masks as ground truth without any filtering mechanism?

## Architecture Onboarding

- **Component map**: Pre-trained LDM (frozen) -> Embedding optimization (mask-guided loss) -> Inpainting controller (bounding box) -> Weakly-supervised detector training
- **Critical path**: Support anomalies → Embedding optimization (mask-guided loss) → Freeze embedding → Sample normal image + bounding box → Inpainting-guided generation → Weakly-supervised detector training
- **Design tradeoffs**:
  - Embedding size vs. expressiveness: 768 dims balance few-shot learnability and concept capacity
  - τ threshold: Higher values (0.9-0.95) reduce false positives but may miss subtle anomalies; lower values increase recall but introduce noise
  - Number of support anomalies (k-shot): k=1 risks overfitting to specific instance; k≥3 improves diversity but requires more data
- **Failure signatures**:
  - Generated anomalies resemble object class rather than defect → Embedding learned object distribution instead of anomaly (check mask-guided loss)
  - Detector misclassifies normal pixels inside boxes → τ too low or detector underconfident
  - Generated anomalies lack diversity → Embedding overfitted to support set; increase k or add augmentation
- **First 3 experiments**:
  1. Embedding ablation: Train embeddings with and without mask-guided loss; visualize generated images to confirm anomaly vs. object focus
  2. τ sensitivity sweep: Evaluate pixel-level AU-PR with τ ∈ {0.8, 0.9, 0.95, 1.0} to find optimal threshold for your dataset
  3. k-shot analysis: Compare generation quality and downstream performance with k ∈ {1, 3, 5} support anomalies to assess data efficiency

## Open Questions the Paper Calls Out

- **Question**: How can the anomaly generation process be modified to produce pixel-level precise annotations rather than bounding boxes?
- **Basis in paper**: [explicit] The authors state in the Limitation section: "In our future work, we will explore how to obtain more precise annotations when generating anomaly images so that they can be more easily and widely used in anomaly detection."
- **Question**: What is the optimal balance between semantically consistent generated anomalies and out-of-distribution synthetic anomalies for maximizing model generalization?
- **Basis in paper**: [inferred] Table 4 shows that combining DRAEM's synthetic anomalies (which have a semantic gap) with AnoGen's generated anomalies achieves the best performance (73.2% AU-PR), surpassing either method alone.
- **Question**: Does initializing the anomaly embedding with the generic token "defect" limit the diversity or speed of convergence for distinct anomaly types?
- **Basis in paper**: [inferred] Section 5.1 notes the embedding `v` is initialized using the text encoder on the word "defect," but the paper does not analyze the sensitivity of the final generation quality or optimization speed to this specific initialization.

## Limitations

- The paper does not specify the exact pre-trained LDM checkpoint used, only citing the LDM paper [42], which could lead to variations in generation quality and downstream performance.
- Bounding box size constraints are only partially specified (one example for "hazelnut-hole"), leaving 14 categories without clear parameters.
- The weakly-supervised threshold τ=0.9 is identified as critical but lacks sensitivity analysis across different anomaly types or detector architectures.
- The embedding optimization stage (6000 iterations) and learning rate (0.005) appear arbitrary without justification or convergence analysis.

## Confidence

- **High confidence**: The overall framework of combining few-shot embedding optimization with inpainting and weak supervision is internally consistent and methodologically sound. The performance improvements (5.8% AU-PR for DRAEM, 1.5% for DeSTSeg) are measurable and reproducible given the same experimental setup.
- **Medium confidence**: The claim that mask-guided loss prevents object-level bias relies on a single ablation result. While the qualitative explanation is reasonable, broader validation across different anomaly types would strengthen this mechanism.
- **Low confidence**: The paper's assertion that bounding-box conditioning works for anomaly generation is not directly validated - no comparison to unconditional generation or alternative conditioning methods is provided. The inpainting approach is assumed to work without explicit justification.

## Next Checks

1. **Embedding Ablation**: Train embeddings with and without mask-guided loss on 2-3 anomaly types. Visualize generated images to confirm that unmasked training produces object-level features rather than anomaly-specific features.
2. **τ Sensitivity Sweep**: Evaluate downstream segmentation performance with τ ∈ {0.8, 0.85, 0.9, 0.95, 0.98} on 3-4 defect categories to identify optimal thresholds and understand the trade-off between precision and recall.
3. **k-shot Analysis**: Compare generation quality and downstream detector performance using k ∈ {1, 3, 5} support anomalies across 4-5 defect types to quantify the data efficiency and identify when additional support samples cease to provide meaningful improvement.