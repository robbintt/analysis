---
ver: rpa2
title: 'Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating
  Event Tables to Queueing Dynamics'
arxiv_id: '2509.05839'
source_url: https://arxiv.org/abs/2509.05839
tags:
- event
- time
- service
- transformer
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a data-driven framework for queueing network
  modeling using autoregressive sequence models trained on event-stream data. Instead
  of manually specifying arrival processes, service mechanisms, or routing logic,
  the approach learns conditional distributions of event types and times, effectively
  transforming queueing modeling into a sequence distribution learning problem.
---

# Data-Driven Stochastic Modeling Using Autoregressive Sequence Models: Translating Event Tables to Queueing Dynamics

## Quick Facts
- arXiv ID: 2509.05839
- Source URL: https://arxiv.org/abs/2509.05839
- Reference count: 40
- Key outcome: A framework for queueing network modeling using autoregressive sequence models trained on event-stream data, replacing manual model specification with sequence distribution learning.

## Executive Summary
This paper introduces a data-driven framework for queueing network modeling that leverages autoregressive sequence models, specifically Transformers, to learn the conditional distributions of event types and inter-event times directly from event-stream data. By treating queueing dynamics as a sequence prediction problem, the approach eliminates the need for manually specifying arrival processes, service mechanisms, or routing logic. The framework is validated across diverse queueing systems, including Markovian and non-Markovian queues, non-stationary arrivals, tandem networks, and a call center case study with abandonment, demonstrating strong performance in simulation accuracy, uncertainty quantification, and counterfactual analysis.

## Method Summary
The method learns a generative simulator for queueing networks by modeling the joint distribution of event types and inter-event times as an autoregressive sequence. Synthetic event tables are generated via the Ciw library, each consisting of initial states and sequences of event types and inter-event times. A decoder-only Transformer (1.5M params) is trained to minimize negative log-likelihood, with event types embedded and inter-event times processed via Time2Vec or discretization. During inference, the model generates trajectories by sampling from the learned conditional distributions, enabling simulation, uncertainty quantification, and counterfactual analysis by conditioning on control variables like staffing levels.

## Key Results
- Transformer models achieve near-optimal prediction losses and closely match true performance distributions across M/M/1, G/G/1, and G/M/1 queues.
- The framework accurately captures system dynamics in a call center case study with abandonment and supports robust counterfactual analysis under varying staffing levels.
- The approach is computationally accessible, requiring only modest GPU resources, and performs well even with limited training data.

## Why This Works (Mechanism)

### Mechanism 1: Distribution Learning via Autoregressive Factorization
The system dynamics of a queueing network can be learned by factorizing the joint distribution of event types and inter-event times into conditional probabilities, replacing structural modeling with sequence prediction. The framework treats the queueing process as a jump process represented by an event table, with a Transformer model parameterizing conditional distributions by minimizing negative log-likelihood. Theoretically, minimizing KL divergence bounds the error in performance metrics. This relies on the assumption that the underlying stochastic process can be fully characterized by the history of observed events and inter-event times.

### Mechanism 2: Implicit Uncertainty Quantification
Autoregressive sampling generates a distribution of trajectories that naturally captures system uncertainty without requiring explicit Bayesian inference over model parameters. The model learns the conditional distribution P(Next | History), and sampling from this distribution during simulation generates varied trajectories. The variance across these trajectories empirically approximates the posterior uncertainty over performance metrics, effectively performing Bayesian inference implicitly. This assumes the training data exhibits sufficient variability that the model learns to associate context variability with outcome variability.

### Mechanism 3: Counterfactual Simulation via Policy Conditioning
The model can evaluate counterfactual scenarios (e.g., changing staffing levels) by conditioning the generative process on control variables included as input tokens. Control variables like staffing level N are embedded as tokens prepended to the input sequence, and the model learns P(Event | History, π). By fixing the history and altering π during inference, the model generates trajectories consistent with the "what-if" scenario. This relies on the assumption that the model has observed sufficient variation in the control variables during training to learn their causal impact on event dynamics.

## Foundational Learning

- **Concept: Autoregressive Sequence Modeling (Transformers)**
  - Why needed here: This is the core engine replacing the mathematical model. You must understand how masked self-attention allows the model to process variable-length histories to predict the next token.
  - Quick check question: Given a sequence of event tokens, how does the model ensure that the prediction of the t-th event only depends on events 1 to t-1?

- **Concept: Discrete-Event Simulation & Queueing Physics**
  - Why needed here: To structure the input data (event tables) and validate the output. You need to know that a "state" in a queue (e.g., number of customers) is inferred from the sequence of arrivals and departures.
  - Quick check question: If a sequence starts with `Arrival` and `Departure`, what is the queue length after the `Departure`? (Answer: 0).

- **Concept: Continuous Distribution Parameterization**
  - Why needed here: Unlike standard text models that predict discrete tokens, this model must predict continuous inter-event times. Understanding how to parameterize a distribution (e.g., Exponential rate λ) vs. discretizing time is crucial for implementation.
  - Quick check question: How would you calculate the loss for a predicted inter-event time distribution versus the actual observed time?

## Architecture Onboarding

- **Component map:** Event Table -> Tokenizer (Event Embeddings + Time2Vec/Discretized Time) -> Decoder-only Transformer (Masked Self-Attention) -> Event Head (Softmax) + Time Head (Parametric/Discrete)

- **Critical path:**
  1. Data Prep: Convert raw logs into (State, Time, Event) tuples.
  2. Embedding: Pass Time through Time2Vec and Events through nn.Embedding. Sum them.
  3. Forward Pass: Pass through Transformer blocks with causal masking.
  4. Loss: Sum of Negative Log-Likelihood (NLL) for Time + Cross-Entropy for Event Type.
  5. Sampling: Autoregressively sample T ~ P(T|H) then E ~ P(E|H, T).

- **Design tradeoffs:**
  * Time Representation: Riemann (Discretized) is flexible for general distributions (G/G/1) but computationally heavy; Parametric is efficient but assumes distribution shape (e.g., Exponential for M/M/1).
  * Conditional Modeling: Predicting Event then Customer Type conditionally is better than a joint index because it reduces the output space size.

- **Failure signatures:**
  * Physics Violation: Generating a `Departure` event when the queue length (inferred from history) is 0.
  * Time Drift: Predicted inter-event times collapsing to zero or exploding to infinity, often due to poor initialization or learning rate scheduling in the continuous head.
  * Deterministic Loops: The model getting stuck in a repeating pattern of events, indicating a failure to capture stochasticity (temperature during sampling too low).

- **First 3 experiments:**
  1. M/M/1 Sanity Check: Train on synthetic M/M/1 data. Plot the distribution of generated inter-arrival times vs. the theoretical exponential distribution.
  2. State Inference: Feed the model a history with a known queue state (e.g., 5 arrivals, 0 departures). Verify the model assigns near-zero probability to a `Departure` event.
  3. Counterfactual Staffing: Train with staffing level N as a control token. Generate trajectories for N=2 vs N=5 and compare the average waiting time distributions.

## Open Questions the Paper Calls Out
None

## Limitations
- The framework cannot handle unobserved state variables not captured in the event history, limiting its applicability when critical system information is missing.
- Performance degrades when counterfactual scenarios require significant extrapolation beyond training data, raising concerns about robustness in out-of-distribution policy evaluation.
- The paper does not fully address computational complexity of discretized time representations for high-precision continuous-time modeling, nor does it provide extensive runtime comparisons across hardware configurations.

## Confidence

- **High Confidence:** The autoregressive factorization approach for distribution learning (Mechanism 1) is well-grounded in established theory and the empirical results demonstrate strong performance across multiple queueing models.
- **Medium Confidence:** The implicit uncertainty quantification (Mechanism 2) is conceptually sound and theoretically supported by Theorem 1, but practical calibration of uncertainty estimates in real-world scenarios with limited data diversity remains an open question.
- **Medium Confidence:** Counterfactual simulation via policy conditioning (Mechanism 3) is demonstrated effectively in the call center case study, but the robustness of this approach to significant extrapolation beyond training data is not fully explored.

## Next Checks
1. **Cross-validation for limited data:** Systematically test model performance as training data is reduced (e.g., 50%, 25%, 10% of original) to quantify the minimum data requirements for reliable uncertainty estimation and counterfactual analysis.
2. **Sensitivity to Time Discretization:** For G/G/1 and non-stationary experiments, explicitly test the impact of varying the number of time bins and bin widths on prediction accuracy and computational cost to provide clearer guidance on the discretization tradeoff.
3. **Hidden State Robustness:** Design a controlled experiment where a key system variable (e.g., customer priority or server efficiency) is partially observed or completely unobserved in the event stream. Evaluate the model's ability to infer or approximate this variable's impact on system dynamics.