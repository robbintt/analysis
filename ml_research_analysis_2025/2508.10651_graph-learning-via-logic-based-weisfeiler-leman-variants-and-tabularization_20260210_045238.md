---
ver: rpa2
title: Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization
arxiv_id: '2508.10651'
source_url: https://arxiv.org/abs/2508.10651
tags:
- graph
- player
- then
- datasets
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel graph classification approach that
  transforms graph data into tabular format using variants of the Weisfeiler-Leman
  (WL) algorithm. The method enriches node labels with neighborhood information via
  logical frameworks, enabling the use of efficient tabular classifiers like random
  forests.
---

# Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization

## Quick Facts
- arXiv ID: 2508.10651
- Source URL: https://arxiv.org/abs/2508.10651
- Authors: Reijo Jaakkola; Tomi Janhunen; Antti Kuusisto; Magdalena Ortiz; Matias Selin; Mantas Šimkus
- Reference count: 40
- Primary result: Logic-based Q-WL variants achieve SOTA graph classification accuracy while being 40-60× faster than GNNs/GTs

## Executive Summary
This paper introduces a novel graph classification approach that transforms graph data into tabular format using variants of the Weisfeiler-Leman (WL) algorithm. The method enriches node labels with neighborhood information via logical frameworks, enabling the use of efficient tabular classifiers like random forests. The authors develop a comprehensive theoretical framework characterizing the expressive power of various WL variants through modal logic and generalized bisimulation games. Experimental results on 14 benchmark datasets show the approach achieves accuracy matching state-of-the-art graph transformers while being 40-60x faster than GNNs and GTs, and more memory-efficient than graph kernels.

## Method Summary
The approach transforms graphs into tabular representations using logic-parametrized Weisfeiler-Leman variants, then applies standard tabular classifiers. The method runs Q-WL (depth 0-10) with five variants: Full (exact counting), Plain (set membership), Majority (>50%), Interval (25%/50%/75%), and Hybrid (Majority + ∃≥1,∃≥2,∃≥3). After d rounds, it collects all unique colors/types across the dataset and counts occurrences per graph to form fixed-length feature vectors. Random Forest classifiers (default sklearn parameters) are trained on these matrices. The framework provides theoretical guarantees through modal logic characterization and bisimulation game equivalence, with experiments showing competitive accuracy against GNNs, graph transformers, and graph kernels across 14 benchmark datasets.

## Key Results
- Achieves accuracy matching state-of-the-art graph transformers on 14 benchmark datasets
- Runs 40-60× faster than GNNs and GTs while maintaining competitive accuracy
- More memory-efficient than graph kernels, requiring no GPU acceleration
- Strong performance across diverse domains (bioinformatics, social networks, chemistry) without hyperparameter tuning

## Why This Works (Mechanism)
The method works by converting graph structure into high-dimensional sparse feature vectors that capture neighborhood patterns through logical quantification. Q-WL variants relax the exact counting requirement of standard WL, trading precision for efficiency while maintaining discriminative power through modal logic characterizations. The tabularization enables use of highly optimized random forest implementations that scale well to high-dimensional sparse data. The theoretical framework ensures that expressive power is preserved through equivalence with modal logics and bisimulation games, while practical variants like Majority and Interval reduce computational overhead by avoiding exact multiset comparisons.

## Foundational Learning
**Weisfeiler-Leman Algorithm**
- Why needed: Core iterative relabeling procedure that captures graph structure through neighborhood aggregation
- Quick check: Can implement 1-WL with multiset hashing and verify color refinement across simple graphs

**Generalized Quantifiers**
- Why needed: Define Q-WL variants by relaxing counting constraints with logical operators
- Quick check: Understand how ∃≥k and >50% quantifiers transform multiset comparison semantics

**Modal Logic Characterization**
- Why needed: Provides theoretical foundation linking WL variants to logical expressiveness
- Quick check: Can map WL color refinement steps to modal logic model checking procedures

**Bisimulation Games**
- Why needed: Characterize expressive power through game-theoretic equivalence
- Quick check: Understand how winning strategies in bisimulation games correspond to WL distinguishing power

## Architecture Onboarding
**Component Map**
Q-WL Algorithm -> Type Collection -> Feature Vector Construction -> Random Forest Classifier

**Critical Path**
1. Run Q-WL for d rounds with variant-specific quantifier rules
2. Collect all unique types/colors across dataset
3. Build (n_graphs × n_types) feature matrix with occurrence counts
4. Train Random Forest with default parameters

**Design Tradeoffs**
- Full Q-WL: Maximum expressiveness but higher computational cost
- Plain/Majority: Reduced precision for faster computation
- Random Forest: Simple, fast, handles high-dimensional sparse data well
- Fixed depth stopping: Avoids unbounded type growth while maintaining performance

**Failure Signatures**
- Feature explosion: Type count grows exponentially → memory overflow
- Type misalignment: Inconsistent column ordering across graphs → meaningless features
- Performance gap: Large accuracy difference between Full and Plain variants indicates need for precise counting

**3 First Experiments**
1. Implement 1-WL with multiset hashing and verify on small test graphs
2. Compare Full vs Plain variant accuracy on a single dataset to validate theoretical expressiveness gap
3. Measure type growth rate across rounds to determine optimal depth stopping criterion

## Open Questions the Paper Calls Out
**Open Question 1**
Do quantifiers detecting specific local structures (e.g., triangles) provide empirical benefits over the current simple weakenings of graded modal logic? The conclusion states that "more expressive quantifiers (e.g., those detecting local structures like triangles) remain unexplored." The authors limited their empirical testing to five variants defined by simple weakenings.

**Open Question 2**
How do alternative tabular classifiers compare to Random Forests when applied to the logic-based tabularizations? The conclusion notes that "systematically comparing different tabular classifiers... is left for future work." The experiments exclusively used Random Forests to handle the sparse, high-dimensional feature vectors resulting from the Q-WL process.

**Open Question 3**
Can the specific parameters for Interval WL and Hybrid WL be optimized or learned rather than randomly assigned? In Section 3.3, the authors admit the parameters (intervals like 25%, 50%; k values like 3) were "simply randomly picked before running the experiments." The study did not perform sensitivity analysis or tuning on the quantifier definitions themselves.

## Limitations
- Implementation complexity: Q-WL variants require nuanced logical definitions that may be challenging to reproduce exactly
- Discrete labels only: Strong performance on discrete-labeled graphs may not translate to real-world scenarios with continuous attributes
- Type explosion risk: Feature growth can become unbounded across rounds, potentially causing memory issues
- Limited hyperparameter tuning: Fixed random forest parameters and randomly chosen quantifier thresholds

## Confidence
- Theoretical framework and expressive power analysis: **High**
- Experimental methodology and baseline comparisons: **Medium**
- Practical applicability and speed claims: **Medium**

## Next Checks
1. Verify type alignment mechanism: Implement and test the hashing/labeling scheme across multiple graphs to ensure consistent column ordering in the tabular representation
2. Benchmark edge case handling: Test interval-based variants on graphs with small node degrees to validate tie-breaking and rounding behavior
3. Reproduce ablation study: Compare Full vs Plain vs Majority variants on a single dataset (e.g., Peptides-func) to verify the reported performance gaps