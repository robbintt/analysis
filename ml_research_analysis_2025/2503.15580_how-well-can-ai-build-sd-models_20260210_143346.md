---
ver: rpa2
title: How Well Can AI Build SD Models?
arxiv_id: '2503.15580'
source_url: https://arxiv.org/abs/2503.15580
tags:
- expected
- message
- feedback
- polarity
- incorrect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces two evaluation metrics\u2014technical correctness\
  \ (causal translation) and adherence to instructions (conformance)\u2014to assess\
  \ how well AI can build system dynamics models. The authors developed an open-source\
  \ platform called sd-ai to facilitate collaborative development of AI tools for\
  \ dynamic modeling and tested 11 different large language models (LLMs) on these\
  \ metrics."
---

# How Well Can AI Build SD Models?

## Quick Facts
- arXiv ID: 2503.15580
- Source URL: https://arxiv.org/abs/2503.15580
- Reference count: 0
- Key outcome: AI models can translate textual descriptions into causal loop diagrams with varying success rates, with GPT-4.5-preview achieving 92.9% and o1 reaching 100% in causal translation accuracy.

## Executive Summary
This study evaluates how effectively AI can construct system dynamics models by testing 11 large language models on their ability to translate textual descriptions into causal loop diagrams. The researchers developed two evaluation metrics—technical correctness (causal translation) and adherence to instructions (conformance)—to assess AI performance systematically. The open-source sd-ai platform was created to facilitate collaborative development of AI tools for dynamic modeling. Results show significant variation in model performance, with GPT-4.5-preview performing best overall and o1 achieving perfect causal translation, while highlighting important limitations in handling positive polarity for decreasing terms.

## Method Summary
The researchers created a systematic evaluation framework using two metrics: technical correctness (measuring causal translation accuracy) and conformance (assessing adherence to instructions). They tested 11 different large language models using the open-source sd-ai platform, which enables collaborative development of AI tools for system dynamics modeling. The evaluation focused on translating textual descriptions into causal loop diagrams, a fundamental task in system dynamics. Performance was measured across multiple dimensions including causal link identification and polarity accuracy, with particular attention to how models handle decreasing terms and positive polarity relationships.

## Key Results
- GPT-4.5-preview achieved the highest overall success rate at 92.9% across evaluation metrics
- o1 model achieved perfect 100% accuracy in causal translation specifically
- GPT-4o identified all causal links but struggled with positive polarity in decreasing terms
- Significant performance variations exist across different LLM models for system dynamics tasks
- The study launches the BEAMS Initiative to standardize evaluation measures for AI in system dynamics modeling

## Why This Works (Mechanism)
The study demonstrates that AI can effectively translate structured textual descriptions into formal system dynamics representations by leveraging the pattern recognition capabilities of large language models. The technical correctness metric captures the model's ability to understand and represent causal relationships accurately, while the conformance metric ensures adherence to modeling instructions. The open-source sd-ai platform provides a standardized environment for collaborative development and testing of AI tools in dynamic modeling contexts.

## Foundational Learning
- **Causal Loop Diagrams (CLDs)**: Visual representations of feedback structures in systems; needed for understanding system dynamics relationships; quick check: can identify reinforcing and balancing loops
- **Technical Correctness Metric**: Measures accuracy of causal translation from text to model; needed to evaluate AI's ability to represent system relationships; quick check: can identify correct polarity and causal links
- **Conformance Metric**: Assesses adherence to modeling instructions and requirements; needed to ensure AI follows systematic modeling approaches; quick check: can verify instruction-following behavior
- **System Dynamics Modeling**: Methodology for understanding complex system behavior over time; needed context for AI tool development; quick check: can distinguish stocks, flows, and feedback loops
- **Large Language Models (LLMs)**: AI models trained on extensive text data for natural language understanding; needed for automated model construction; quick check: can process and interpret system descriptions
- **BEAMS Initiative**: Effort to standardize evaluation measures for AI in system dynamics; needed for responsible tool development; quick check: can identify standardized evaluation criteria

## Architecture Onboarding
Component Map: sd-ai platform -> LLM models -> Evaluation metrics (Technical Correctness, Conformance) -> BEAMS Initiative
Critical Path: Textual input → LLM processing → Causal loop diagram generation → Metric evaluation → Performance scoring
Design Tradeoffs: Computational cost vs. accuracy, model complexity vs. interpretability, standardization vs. flexibility
Failure Signatures: Incorrect causal polarity, missed feedback loops, non-adherence to instructions, improper handling of decreasing terms
First Experiments:
1. Test GPT-4.5-preview on increasingly complex system descriptions to identify performance thresholds
2. Evaluate o1 model's perfect causal translation across diverse domain scenarios
3. Compare cost-performance ratios of GPT-4o against higher-performing models for practical applications

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions in the provided content.

## Limitations
- Evaluation metrics were specifically designed for this study, limiting direct comparison with other research
- Testing was limited to 11 LLM models, which may not capture the full range of model capabilities
- The study focuses only on causal loop diagram generation, representing a narrow subset of system dynamics modeling tasks
- Cost-effectiveness analysis is based on limited testing under computational constraints

## Confidence
- High confidence in technical correctness metric design and application across models
- Medium confidence in generalizability of results across different system dynamics modeling tasks
- Medium confidence in cost-effectiveness analysis due to limited computational testing

## Next Checks
1. Test evaluation metrics with domain experts to validate technical correctness scoring accuracy, particularly for causal polarity assessment
2. Expand testing to include more diverse system dynamics modeling scenarios beyond causal loop diagram generation
3. Conduct longitudinal studies to assess AI-generated model accuracy and utility when applied to real-world system dynamics problems over time