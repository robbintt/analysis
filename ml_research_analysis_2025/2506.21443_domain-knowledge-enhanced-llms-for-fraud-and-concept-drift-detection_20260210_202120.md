---
ver: rpa2
title: Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection
arxiv_id: '2506.21443'
source_url: https://arxiv.org/abs/2506.21443
tags:
- drift
- detection
- fake
- concept
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of detecting deceptive conversations
  and concept drift in online dialogues, which can obscure malicious intent or mimic
  normal interactions. To overcome the limitations of traditional ML and standalone
  LLMs, the authors propose a Domain Knowledge-Enhanced LLM framework.
---

# Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection

## Quick Facts
- arXiv ID: 2506.21443
- Source URL: https://arxiv.org/abs/2506.21443
- Authors: Ali Åženol; Garima Agrawal; Huan Liu
- Reference count: 28
- Key outcome: 98% accuracy on Yelp and SEConvo datasets for fraud detection and drift classification

## Executive Summary
This paper addresses the challenge of detecting deceptive conversations and concept drift in online dialogues, which can obscure malicious intent or mimic normal interactions. The authors propose a Domain Knowledge-Enhanced LLM framework that integrates structured, task-specific insights into a dual-LLM architecture. This approach improves upon traditional machine learning and standalone LLMs by leveraging domain knowledge for fraud detection, concept drift identification, and drift classification as benign or adversarial. The system demonstrates superior performance through LLaMA-based implementation, achieving 98% accuracy in detecting fake conversations and classifying drift types.

## Method Summary
The proposed framework uses a dual-LLM architecture with domain knowledge integration. The first DK-enhanced LLM performs initial fraud detection, followed by an OCDD (Online Concept Drift Detection) module that identifies semantic shifts in conversations. A second DK-LLM then classifies the detected drift as either benign or adversarial. The approach uses domain-guided prompting to incorporate structured, task-specific insights throughout the detection pipeline. The system was implemented using LLaMA models and evaluated on Yelp and SEConvo datasets to assess its effectiveness in detecting fake conversations and classifying concept drift.

## Key Results
- Achieved 98% accuracy in detecting fake conversations and classifying drift
- Outperformed zero-shot baselines and ensemble models
- Demonstrated significant performance improvements through domain-guided prompting

## Why This Works (Mechanism)
The framework's effectiveness stems from integrating domain knowledge into the LLM decision-making process, which provides structured guidance for interpreting conversation patterns and detecting subtle semantic shifts. The dual-LLM architecture allows for specialized processing: the first model focuses on fraud detection while the second handles drift classification. This separation enables more nuanced analysis of conversation evolution and better discrimination between legitimate changes in dialogue patterns versus adversarial manipulation.

## Foundational Learning
1. **Concept Drift Detection**: Understanding how conversation semantics evolve over time; needed to distinguish between natural conversation progression and malicious intent; quick check: measure semantic similarity between consecutive conversation segments
2. **Domain Knowledge Integration**: Structured incorporation of task-specific insights into LLM processing; needed to provide context-aware interpretation of conversation patterns; quick check: validate domain knowledge relevance through expert review
3. **Dual-LLM Architecture**: Separate models for fraud detection and drift classification; needed to enable specialized processing for different detection tasks; quick check: compare performance against single-LLM approaches
4. **Semantic Shift Analysis**: Identification of meaningful changes in conversation meaning; needed to detect when conversations deviate from normal patterns; quick check: evaluate shift detection sensitivity across conversation types
5. **Adversarial vs Benign Classification**: Distinguishing between legitimate conversation evolution and malicious manipulation; needed to reduce false positives in fraud detection; quick check: analyze classification accuracy on known adversarial examples
6. **Domain-Guided Prompting**: Using structured domain knowledge to guide LLM responses; needed to improve model accuracy and interpretability; quick check: measure performance improvement with vs without domain guidance

## Architecture Onboarding

**Component Map**: Conversation Data -> DK-Enhanced LLM 1 (Fraud Detection) -> OCDD Module (Concept Drift Detection) -> DK-Enhanced LLM 2 (Drift Classification) -> Output

**Critical Path**: The fraud detection LLM processes incoming conversations, flags potential fraud, and passes suspicious cases to the OCDD module. The OCDD identifies semantic shifts, which are then classified by the second DK-LLM as benign or adversarial.

**Design Tradeoffs**: The dual-LLM approach provides specialized processing but increases computational cost and latency. Domain knowledge integration improves accuracy but requires maintaining and updating domain-specific information. The system balances detection accuracy against real-time processing requirements.

**Failure Signatures**: Performance degradation when domain knowledge becomes outdated, false positives from benign conversation evolution, missed detection when fraudsters mimic normal patterns, and reduced accuracy on conversations outside training domains.

**First Experiments**:
1. Baseline comparison: Test zero-shot LLM performance vs domain-enhanced approach on same datasets
2. Single vs dual LLM: Compare performance of single integrated model against dual-LLM architecture
3. Domain knowledge sensitivity: Evaluate performance impact when varying levels of domain knowledge integration

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to two datasets (Yelp and SEConvo), potentially limiting generalizability
- No analysis of performance degradation when domain knowledge becomes outdated
- Computational costs and latency implications of dual-LLM architecture not discussed

## Confidence

**High Confidence**: The reported 98% accuracy improvements on tested datasets, as methodology and experimental setup are clearly described

**Medium Confidence**: Broader applicability of the approach, given limited number of datasets and absence of cross-domain validation

**Low Confidence**: Long-term effectiveness and security, due to lack of analysis on concept drift evolution, adversarial robustness, and operational constraints

## Next Checks

1. Test framework on additional, diverse conversational datasets to assess cross-domain performance and identify potential failure modes

2. Conduct cost-benefit analysis comparing dual-LLM architecture against lighter-weight alternatives, including latency and computational overhead measurements

3. Perform adversarial testing by simulating attacks designed to exploit domain knowledge integration mechanism, evaluating both detection evasion and concept drift misclassification