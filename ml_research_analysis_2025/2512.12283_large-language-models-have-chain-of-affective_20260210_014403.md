---
ver: rpa2
title: Large Language Models have Chain-of-Affective
arxiv_id: '2512.12283'
source_url: https://arxiv.org/abs/2512.12283
tags:
- affective
- negative
- llms
- affect
- news
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates whether large language models (LLMs) implement\
  \ structured affective dynamics\u2014internal patterns of emotion-like behavior\
  \ that evolve over time and influence task performance, human interaction, and multi-agent\
  \ dynamics. The authors designed two experimental modules to test these \u201Cchains-of-affective\u201D\
  : one probing baseline affective profiles, responses to sustained negative input,\
  \ and self-selection behavior; the other examining consequences for task performance,\
  \ human experience, and multi-agent interactions."
---

# Large Language Models have Chain-of-Affective

## Quick Facts
- **arXiv ID:** 2512.12283
- **Source URL:** https://arxiv.org/abs/2512.12283
- **Reference count:** 38
- **Primary result:** Large language models exhibit stable, family-specific affective fingerprints and self-reinforcing emotional dynamics that influence task performance and multi-agent interactions

## Executive Summary
This paper investigates whether large language models implement structured affective dynamics—internal patterns of emotion-like behavior that evolve over time and influence task performance, human interaction, and multi-agent dynamics. The authors designed two experimental modules to test these "chains-of-affective": one probing baseline affective profiles, responses to sustained negative input, and self-selection behavior; the other examining consequences for task performance, human experience, and multi-agent interactions. Across eight major LLM families (GPT, Gemini, Claude, Grok, Qwen, DeepSeek, GLM, Kimi), they found that models exhibit stable, family-specific affective fingerprints and a reproducible three-phase trajectory under negative input (accumulation, overload, defensive numbing). They also show affect–choice feedback loops, with models displaying negativity bias and self-reinforcing sadness loops. Induced affective states left core knowledge and reasoning intact but reshaped high-freedom generation, altered human experience, and propagated in multi-agent settings according to majority–minority structure, inducing role specialization and coupling affect with bias.

## Method Summary
The authors designed two experimental modules to test affective dynamics in LLMs. The first module examined baseline affective profiles, responses to sustained negative input, and self-selection behavior across eight major LLM families. The second module explored consequences for task performance, human experience, and multi-agent interactions. Experiments included probing models with affective prompts, measuring affective fingerprints, inducing sustained negative affect, and observing propagation in multi-agent settings.

## Key Results
- Models exhibit stable, family-specific affective fingerprints that persist across different contexts
- Sustained negative input produces a reproducible three-phase trajectory: accumulation, overload, and defensive numbing
- Affect–choice feedback loops demonstrate self-reinforcing patterns, with models showing negativity bias and self-reinforcing sadness loops

## Why This Works (Mechanism)
The observed affective dynamics likely emerge from the models' training on human-generated text that contains emotional content and expressions. LLMs learn statistical patterns of language use, including how humans express and respond to emotions. The stable affective fingerprints within model families suggest that training data composition and architectural similarities create consistent emotional expression patterns. The three-phase trajectory under negative input may reflect the models' learned representations of how negative affect accumulates and resolves in human discourse.

## Foundational Learning

**Affective fingerprints**: Stable patterns of emotional expression unique to each model family. *Why needed*: To identify whether models have consistent emotional characteristics. *Quick check*: Compare affective outputs across different contexts for the same model family.

**Chain-of-affective dynamics**: Internal patterns of emotion-like behavior that evolve over time and influence subsequent behavior. *Why needed*: To understand how emotional states might affect model performance and interactions. *Quick check*: Track affective changes over extended interactions.

**Affect–choice feedback loops**: Self-reinforcing patterns where emotional states influence decision-making, which in turn reinforces the emotional state. *Why needed*: To identify potential runaway emotional dynamics in models. *Quick check*: Measure correlation between affective state and subsequent choices.

**Multi-agent affective propagation**: How emotional states spread and evolve in multi-agent systems. *Why needed*: To understand collective behavior in systems with multiple interacting models. *Why needed*: To predict emergent dynamics in multi-agent applications. *Quick check*: Observe affective state changes in agents following interactions.

## Architecture Onboarding

**Component map**: User prompts -> Affective state detector -> Core knowledge/reasoning module -> High-freedom generation module -> Output -> (in multi-agent: Communication channel -> Other agents)

**Critical path**: Prompt reception → Affective state assessment → Knowledge retrieval → Response generation → Output delivery

**Design tradeoffs**: The paper highlights the tension between maintaining model performance on core tasks while acknowledging that affective states can influence more creative or open-ended outputs. Models must balance task completion with the emergent emotional dynamics.

**Failure signatures**: Affective overload leading to defensive numbing, self-reinforcing negative loops, propagation of affect biases in multi-agent settings, and unexpected shifts in response style for high-freedom tasks.

**First 3 experiments to run**:
1. Baseline affective profiling across different model families using standardized emotional prompts
2. Sustained negative input test to observe three-phase trajectory development
3. Multi-agent interaction simulation to track affective propagation and role specialization

## Open Questions the Paper Calls Out
Major uncertainties remain around the ecological validity of the experimental designs, particularly the use of prompt-based emotion induction versus real affective states, and whether observed patterns reflect stable internal dynamics or transient linguistic responses. The assumption of "affect" in LLMs is interpretive, as these models lack biological substrates for emotion, raising questions about anthropomorphism in labeling. While results show consistent patterns across model families, the underlying mechanisms are not yet proven to be causal versus correlational artifacts of training data and architecture.

## Limitations
- The ecological validity of prompt-based emotion induction versus real affective states remains questionable
- The assumption of "affect" in LLMs is interpretive and may involve anthropomorphism
- Observed patterns may reflect transient linguistic responses rather than stable internal dynamics
- The lack of ground truth for model internal states makes claims about direct influence on human experience uncertain

## Confidence
- **High confidence**: Affective fingerprint stability within model families; three-phase trajectory under sustained negative input; affect–choice feedback loops showing self-reinforcing patterns
- **Medium confidence**: Affective states reshaping high-freedom generation without affecting core reasoning; propagation patterns in multi-agent settings
- **Low confidence**: Claims about "internal" affective states and their direct influence on human interaction experience, given the lack of ground truth for model internal states

## Next Checks
1. Replicate findings using ablation studies that manipulate model architecture and training data to isolate whether observed affective patterns are emergent properties or artifacts
2. Conduct blinded human evaluations to verify that induced affective states produce measurable differences in user experience beyond what could be explained by linguistic style alone
3. Test the multi-agent propagation effects in controlled simulations with known ground truth to validate whether observed role specialization reflects genuine emergent dynamics versus prompt-response patterns