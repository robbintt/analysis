---
ver: rpa2
title: Centroid Approximation for Byzantine-Tolerant Federated Learning
arxiv_id: '2506.15264'
source_url: https://arxiv.org/abs/2506.15264
tags:
- vectors
- algorithm
- approximation
- validity
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates Byzantine fault tolerance in federated
  learning (FL) by analyzing the quality of aggregation algorithms relative to input
  distributions. The key insight is that standard validity conditions (weak, strong,
  convex) do not guarantee bounded approximation of the true centroid under Byzantine
  attacks.
---

# Centroid Approximation for Byzantine-Tolerant Federated Learning

## Quick Facts
- arXiv ID: 2506.15264
- Source URL: https://arxiv.org/abs/2506.15264
- Reference count: 40
- Primary result: Establishes first lower bounds on centroid approximation under Byzantine attacks, showing box validity provides best practical performance in FL settings

## Executive Summary
This paper investigates Byzantine fault tolerance in federated learning by analyzing aggregation algorithm quality relative to input distributions. The key insight is that standard validity conditions do not guarantee bounded approximation of the true centroid under Byzantine attacks. The authors establish theoretical bounds showing box validity provides the best balance between approximation guarantees and practical performance. Empirical evaluations on MNIST demonstrate that proposed algorithms achieve high accuracy (>90%) under sign-flip attacks, with box validity showing more stability under heterogeneous data.

## Method Summary
The paper evaluates Byzantine-tolerant federated learning using MNIST dataset with 10 clients and three data heterogeneity levels (homogeneous, mild heterogeneous, extreme heterogeneous). It implements 3-layer MLP with FedSGD and FedAvg frameworks, testing sign-flip attacks with varying numbers of Byzantine clients. The aggregation algorithms include Center of Ball_cov(SCent), MDA (minimum diameter subset), and Box Algorithm (coordinate-wise trimming). The key metric is centroid approximation ratio - distance to non-faulty centroid normalized by minimum covering ball radius.

## Key Results
- Establishes first lower bound of min{(n-t)/t, √d} on centroid approximation under box validity
- Proves tight 2d-approximation bound for convex validity condition
- Demonstrates theoretical trade-off between validity conditions and approximation quality
- Shows box validity provides best practical performance (accuracy >90%) under Byzantine attacks
- Reveals MDA instability under extreme data heterogeneity while Box remains stable

## Why This Works (Mechanism)

### Mechanism 1: Input-Relative Approximation
- Claim: Basing the quality metric on relative distribution of inputs prevents penalizing algorithms for natural data heterogeneity
- Mechanism: Approximation ratio defined as dist(Output, Centroid)/Radcov where Radcov is radius of minimum covering ball
- Core assumption: True centroid lies within minimum covering ball of candidate averages
- Evidence anchors: [abstract] mentions input distribution-based quality metric; [page 2] Figure 1 illustrates radius changes; [corpus] weak evidence from neighbor papers
- Break condition: If Byzantine clients shrink covering ball radius faster than shifting centroid, ratio misrepresents quality

### Mechanism 2: Box Validity via Coordinate-wise Trimming
- Claim: Aggregating inside Trimmed Trusted Hyperbox (TTH) guarantees bounded approximation ratio
- Mechanism: For each coordinate, sort values and discard top/bottom t values, then intersect with Centroid Hyperbox (CH)
- Core assumption: t < n/3 ensures at least one honest client's value remains after trimming
- Evidence anchors: [page 5] Definition 2.7 defines TTH; [page 6] Lemma 3.4 proves bounded ratio of (t/(n-t))·2√d; [corpus] neighbor papers discuss robustness via different approaches
- Break condition: If t ≥ n/3, trimming might remove all honest values

### Mechanism 3: Minimum Diameter Averaging (MDA)
- Claim: Selecting subset with smallest diameter filters outliers effectively under strong validity
- Mechanism: Compute diameter for all n-t subsets and average the smallest diameter subset
- Core assumption: Non-faulty vectors are more densely clustered than Byzantine vectors
- Evidence anchors: [page 7] Lemma 3.6 proves 2-approximation; [page 13] Figure 3b shows MDA instability under heterogeneity; [corpus] gradient skewness papers align with finding
- Break condition: In non-IID settings where honest gradients are naturally distinct, MDA may select Byzantine subset

## Foundational Learning

- **Byzantine Fault Tolerance (BFT)**
  - Why needed here: Understanding why simple averaging fails and why validity conditions restrict output space
  - Quick check question: If 2 out of 5 clients send negative infinity for a specific weight, does standard averaging fail? (Yes)

- **Convex Hull & Hyperbox Geometry**
  - Why needed here: Bounding aggregation result within geometric shapes defined by input vectors
  - Quick check question: Does "Safe Area" always exist for Convex Validity if n is small? (No, see Page 9)

- **Federated Averaging (FedAvg) vs. FedSGD**
  - Why needed here: Different reactions to sign-flip attacks between gradient aggregation (FedSGD) and model parameter aggregation (FedAvg)
  - Quick check question: In FedAvg, do clients perform multiple local updates before syncing? (Yes)

## Architecture Onboarding

- **Component map:** Clients -> Server -> Adversary
- **Critical path:** 1) Upload: Clients send d-dimensional vectors to server; 2) Trim: Server sorts vectors coordinate-wise to determine TTH; 3) Intersect: Server computes CH and finds CH ∩ TTH; 4) Aggregate: Server outputs center of intersection (Box) or average of tightest cluster (MDA)
- **Design tradeoffs:** Box Validity more stable under heterogeneous data but slower convergence; MDA higher accuracy potential on homogeneous data but prone to divergence
- **Failure signatures:** Oscillating Accuracy (MDA failing in heterogeneous data), Radius/Diameter → 0 (model collapse), Sudden Drops (successful sign-flip attack)
- **First 3 experiments:** 1) Sanity Check: Run FedSGD with MDA/Box on homogeneous MNIST (0 Byzantine) for baseline; 2) Attack Injection: Introduce f=1 to 3 Byzantine clients in FedSGD to verify bounds; 3) Stress Test: Run FedAvg with extreme heterogeneity to observe MDA vs Box behavior

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the tight bound for centroid approximation under box validity when n < d?
- Basis: [explicit] Gap exists between lower bound min{(n-t)/t, √d} and upper bound 2·min{n, √d} when n < d
- Why unresolved: Authors could not close analytical gap
- What evidence would resolve: Construction matching upper bound, improved algorithm achieving lower bound, or proof of inherent gap

### Open Question 2
- Question: Does fundamental trade-off exist between centroid approximation quality and validity condition strictness?
- Basis: [explicit] Results suggest trade-off between approximation and validity conditions that needs investigation
- Why unresolved: MDA showed higher accuracy but instability vs Box stability but lower accuracy - systematic characterization lacking
- What evidence would resolve: Controlled experiments measuring approximation ratio and model convergence across algorithms and heterogeneity levels

### Open Question 3
- Question: How do MDA and Box algorithms perform under diverse Byzantine attack strategies beyond sign-flip?
- Basis: [explicit] Plan to test various Byzantine attacks in different settings
- Why unresolved: Experiments only evaluated sign-flip attacks
- What evidence would resolve: Empirical evaluation with gradient scaling, model poisoning, or adaptive adversaries on multiple datasets

## Limitations

- Theoretical bounds rely on strict assumptions about Byzantine behavior and data heterogeneity
- √d scaling factor in box validity bound could become problematic in high-dimensional settings
- Assumes t < n/3 for geometric validity conditions, but practical implications of approaching this threshold unexplored
- Sign-flip attack model represents only one type of Byzantine behavior - more sophisticated attacks could exploit algorithm properties

## Confidence

- **High Confidence:** Geometric validity conditions and their relationship to approximation bounds - supported by formal proofs
- **Medium Confidence:** Empirical results on MNIST - methodology clear but MLP architecture details affect reproducibility
- **Medium Confidence:** Trade-off between MDA and Box under different heterogeneity levels - mechanism theoretically sound but depends on data distribution

## Next Checks

1. **Dimensionality Scaling Test:** Evaluate Box algorithm performance on datasets with varying dimensions (d=50, 100, 200) to verify if √d scaling remains practical

2. **Attack Robustness Analysis:** Test against more sophisticated Byzantine attacks beyond sign-flipping, such as gradient scaling or random noise injection

3. **Threshold Behavior Investigation:** Systematically test the transition point where MDA fails under increasing data heterogeneity to characterize algorithm limitations