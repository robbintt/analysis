---
ver: rpa2
title: Differentiable Adversarial Attacks for Marked Temporal Point Processes
arxiv_id: '2501.10606'
source_url: https://arxiv.org/abs/2501.10606
tags:
- adversarial
- event
- noise
- time
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of designing adversarial attacks
  for marked temporal point processes (MTPPs), a powerful model for continuous-time
  event sequences. The key difficulty lies in generating imperceptible perturbations
  that can effectively degrade model performance, due to the sequential nature of
  temporal data and the complex relationship between noise and distance metrics.
---

# Differentiable Adversarial Attacks for Marked Temporal Point Processes

## Quick Facts
- arXiv ID: 2501.10606
- Source URL: https://arxiv.org/abs/2501.10606
- Authors: Pritish Chakraborty; Vinayak Gupta; Rahul R; Srikanta J. Bedathur; Abir De
- Reference count: 11
- Key outcome: Introduces PERMTPP, a novel differentiable adversarial attack framework for marked temporal point processes that achieves up to 50% improvement in mark prediction accuracy over existing methods.

## Executive Summary
This paper addresses the challenge of designing adversarial attacks for marked temporal point processes (MTPPs), a powerful model for continuous-time event sequences. The key difficulty lies in generating imperceptible perturbations that can effectively degrade model performance, due to the sequential nature of temporal data and the complex relationship between noise and distance metrics. The authors propose PERMTPP, a novel differentiable adversarial attack framework that overcomes these challenges through a two-stage approach. Experimental results on four real-world datasets demonstrate that PERMTPP significantly outperforms existing adversarial attack methods, achieving up to 50% improvement in mark prediction accuracy and substantial increases in mean absolute error. The framework also shows strong defensive capabilities when used for adversarial training, providing robustness against various attack strategies.

## Method Summary
The paper proposes PERMTPP, a novel differentiable adversarial attack framework for marked temporal point processes. The method employs a two-stage approach: first, it uses a Gumbel-Sinkhorn network to learn a soft permutation matrix that reorders events while maintaining differentiability; then, it adds temporal noise to the permuted sequence, constrained to preserve the event order. This approach allows for controlled perturbation generation while maintaining the ability to optimize the adversarial objective. The framework is designed to overcome the challenges of generating imperceptible perturbations in sequential temporal data while effectively degrading model performance.

## Key Results
- PERMTPP achieves up to 50% improvement in mark prediction accuracy compared to existing adversarial attack methods
- The framework significantly increases mean absolute error in event prediction
- PERMTPP demonstrates strong defensive capabilities when used for adversarial training, providing robustness against various attack strategies

## Why This Works (Mechanism)
The paper introduces a novel approach to adversarial attacks on marked temporal point processes by addressing the fundamental challenge of generating imperceptible perturbations in sequential temporal data. The mechanism works through a two-stage process: first, a Gumbel-Sinkhorn network learns a soft permutation matrix to reorder events while maintaining differentiability; second, temporal noise is added to the permuted sequence with constraints to preserve event order. This approach allows for controlled perturbation generation that can effectively degrade model performance while maintaining the ability to optimize the adversarial objective through backpropagation. The method overcomes the complex relationship between noise and distance metrics in temporal data by separating the permutation and noise addition steps, enabling more effective and targeted attacks.

## Foundational Learning
1. **Marked Temporal Point Processes (MTPPs)**: Why needed - Fundamental model for continuous-time event sequences with associated marks; Quick check - Understand how MTPPs model temporal dependencies and mark distributions
2. **Gumbel-Sinkhorn Network**: Why needed - Enables differentiable learning of permutation matrices for event reordering; Quick check - Verify understanding of how this network maintains differentiability while performing permutations
3. **Adversarial Attacks in Temporal Data**: Why needed - Different from traditional adversarial attacks due to sequential nature of temporal data; Quick check - Compare and contrast with adversarial attacks on static data

## Architecture Onboarding

**Component Map**: Input Sequence -> Gumbel-Sinkhorn Network -> Soft Permutation Matrix -> Temporal Noise Addition -> Perturbed Sequence -> MTPP Model

**Critical Path**: The critical path involves the input sequence passing through the Gumbel-Sinkhorn network to generate a soft permutation matrix, which is then applied to the sequence before adding constrained temporal noise. This perturbed sequence is then fed into the MTPP model for evaluation.

**Design Tradeoffs**: The paper balances between generating effective adversarial perturbations and maintaining the imperceptibility of the attacks. The two-stage approach (permutation followed by noise addition) allows for more controlled and targeted attacks but may introduce additional computational complexity compared to single-stage methods.

**Failure Signatures**: Potential failure modes include: (1) inability to generate effective perturbations if the permutation step fails to reorder events meaningfully, (2) loss of imperceptibility if temporal noise constraints are not properly enforced, and (3) reduced attack effectiveness if the Gumbel-Sinkhorn network fails to learn an optimal soft permutation matrix.

**3 First Experiments**:
1. **Baseline Comparison**: Compare PERMTPP against existing adversarial attack methods on mark prediction accuracy and mean absolute error
2. **Ablation Study**: Evaluate the impact of the permutation step and temporal noise addition separately to understand their individual contributions to attack effectiveness
3. **Robustness Evaluation**: Test the defensive capabilities of PERMTPP through adversarial training and assess its performance against various attack strategies

## Open Questions the Paper Calls Out
None

## Limitations
- Computational efficiency and training time of the proposed method are not detailed
- Generalizability to datasets beyond the four specific ones used in experiments is uncertain
- Limited analysis of potential defense strategies against the proposed attack

## Confidence

| Claim Cluster | Confidence Level |
|---------------|------------------|
| Performance Improvement Claims | Medium |
| Differentiability and Optimization | High |
| Robustness and Defense | Low |

## Next Checks
1. Conduct a detailed analysis of the computational complexity and training time of PERMTPP compared to existing adversarial attack methods
2. Evaluate the performance of PERMTPP on a diverse set of marked temporal point process datasets, including those from different domains
3. Develop and evaluate various defense strategies against PERMTPP, such as adversarial training, input preprocessing, and model architecture modifications