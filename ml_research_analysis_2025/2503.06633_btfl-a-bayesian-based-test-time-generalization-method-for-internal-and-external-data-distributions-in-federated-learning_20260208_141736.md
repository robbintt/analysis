---
ver: rpa2
title: 'BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External
  Data Distributions in Federated learning'
arxiv_id: '2503.06633'
source_url: https://arxiv.org/abs/2503.06633
tags:
- test
- learning
- btfl
- distribution
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BTFL, a Bayesian-based test-time generalization
  method for federated learning that addresses the challenge of balancing personalization
  and generalization when encountering both internal (IND) and external (EXD) data
  distributions during testing. The core innovation is a dual-Bayesian framework that
  interpolates predictions between local and global model heads using a probability-based
  approach, avoiding costly optimization by leveraging analytical solutions from Beta-Bernoulli
  processes and Bayesian updates.
---

# BTFL: A Bayesian-based Test-Time Generalization Method for Internal and External Data Distributions in Federated learning

## Quick Facts
- **arXiv ID:** 2503.06633
- **Source URL:** https://arxiv.org/abs/2503.06633
- **Reference count:** 40
- **One-line primary result:** A Bayesian-based test-time generalization method for federated learning that achieves 1.88%-3.15% higher accuracy than baselines while reducing inference time by 4X-12X across CIFAR10, OfficeHome, and ImageNet datasets.

## Executive Summary
This paper introduces BTFL, a Bayesian-based test-time generalization method for federated learning that addresses the challenge of balancing personalization and generalization when encountering both internal (IND) and external (EXD) data distributions during testing. The core innovation is a dual-Bayesian framework that interpolates predictions between local and global model heads using a probability-based approach, avoiding costly optimization by leveraging analytical solutions from Beta-Bernoulli processes and Bayesian updates. BTFL employs a two-head architecture storing local and global knowledge, with a novel characteristic Bayesian update that rectifies likelihood estimation using entropy-based adjustments.

## Method Summary
BTFL operates in federated learning by training a feature extractor and two classifier heads (local and global) across clients. At test time, it uses a dual-Bayesian framework to interpolate predictions between heads based on whether samples come from internal (IND) or external (EXD) distributions. The method consists of three key modules: Historical Bayesian Update (HBU) that accumulates distribution-shift evidence via Beta-Bernoulli updates, Characteristic Bayesian Update (CBU) that refines interpolation coefficients using entropy-rectified likelihood estimates, and Discretized-Prediction Interpolation (DPI) that computes final predictions. The approach avoids optimization at test time by leveraging analytical Bayesian solutions, making it efficient while maintaining strong performance across both IND and EXD scenarios.

## Key Results
- BTFL achieves 1.88%-3.15% higher accuracy than baseline methods on CIFAR10, OfficeHome, and ImageNet datasets
- Inference time reduced by 4X-12X compared to optimization-based test-time adaptation methods
- BTFL maintains accuracy robustness across all 5 test scenarios (Original, Shifted IND, Shifted EXD, Synthetical) while other methods degrade significantly in mixed distribution scenarios

## Why This Works (Mechanism)

### Mechanism 1: Dual-Head Knowledge Storage with Bayesian Interpolation
- Claim: BTFL balances personalization (IND) and generalization (EXD) by interpolating predictions from two heads using a probability-based coefficient derived from Bayesian inference.
- Mechanism: A local head trained on client-specific data captures personalized knowledge for IND samples; a global head aggregated from all clients captures generalized knowledge for EXD samples. Instead of heuristic weighting, BTFL models the interpolation coefficient `m` as a parameter of a binomial distribution B(n, m), where `m` represents P(x ∼ EXD). The final prediction `Y_int = e·Y_g + (1-e)·Y_l` integrates over the posterior distribution of `m`.
- Core assumption: The mixing coefficient can be modeled probabilistically, and output-space interpolation approximates optimal knowledge blending when both heads share a frozen feature extractor.
- Evidence anchors:
  - [abstract]: "BTFL employs a two-head architecture storing local and global knowledge, with a novel characteristic Bayesian update that rectifies likelihood estimation using entropy-based adjustments."
  - [Section 3]: "We turn the interpolation problem into a parameter estimation problem for a binomial distribution B(n, m)..."
  - [Section 4.2]: "BTFL mainly includes three modules to process the feature z of sample x at test time: Information Extraction, Information Analysis, and Interpolation Prediction."
  - [corpus]: Related work (pFedBBN, FedCTTA) confirms test-time adaptation with dual knowledge sources is an active research direction, though corpus lacks direct Bayesian interpolation comparisons.
- Break condition: If feature distributions between IND and EXD overlap significantly such that likelihood estimates become unreliable, the entropy-based rectification may fail to distinguish sources.

### Mechanism 2: Historical Bayesian Update (HBU) via Beta-Bernoulli Process
- Claim: HBU accumulates distribution-shift evidence from the test data stream using conjugate Beta-Bernoulli updates, providing a time-series prior for the interpolation coefficient.
- Mechanism: Initialize prior p(m) as uniform Beta(1,1). For each test sample, detect whether it conforms to IND or EXD using likelihood ratio τ = Q_l/Q_g and entropy inspection π. Update (α, β) counts accordingly: Beta(m; α, β) posterior becomes the new prior. A pruning threshold λ prevents prior stagnation.
- Core assumption: Test samples arrive in streams with temporally correlated distribution characteristics; entropy serves as a proxy for model confidence and distribution alignment.
- Evidence anchors:
  - [abstract]: "...avoiding costly optimization by leveraging analytical solutions from Beta-Bernoulli processes and Bayesian updates."
  - [Section 4.3]: "p(m | α, β) = Beta(m; α, β)... The result is deduced from the conjugate relationship between binomial distribution and beta distribution."
  - [Section 4.3, Eq. 11]: Event detection formula using τ and π to update α and β.
  - [corpus]: Weak direct evidence; corpus papers focus on test-time adaptation but don't specifically validate Beta-Bernoulli for FL.
- Break condition: If test data oscillates rapidly between IND and EXD (non-stationary), the accumulated prior may lag behind true distribution, causing systematic interpolation bias.

### Mechanism 3: Characteristic Bayesian Update (CBU) with Entropy-Rectified Likelihood
- Claim: CBU refines the interpolation coefficient for each sample by computing a posterior P(x ∼ EXD | ẑ) using discretized likelihood estimates rectified by entropy differences.
- Mechanism: Features are discretized via finite scalar quantization (FSQ) to {0,1}^d. Local and global Discretised-Likelihood Estimators (DLEs) approximate q(ẑ|x ∼ IND) and q(ẑ|x ∼ EXD). To handle high-dimensional variance and likelihood inaccuracies, apply geometric averaging (exponent 1/d) and entropy-based rectification: modify τ to τ̂ using exp((H_l - H̄_l)/H_l) and exp((H_g - H̄_g)/H_g) as exponents.
- Core assumption: Feature dimensions are approximately independent after training; entropy differences reflect relative model reliability for the current sample.
- Evidence anchors:
  - [abstract]: "...with a novel characteristic Bayesian update that rectifies likelihood estimation using entropy-based adjustments."
  - [Section 4.4, Eq. 15]: "We modify τ to τ̂ as the following form..." incorporating entropy rectification.
  - [Section 4.1]: Discretised-Likelihood Estimators use FSQ to enable tractable likelihood estimation.
  - [corpus]: No direct corpus validation of entropy-rectified likelihood for test-time FL; this appears novel to BTFL.
- Break condition: If feature independence assumption is violated (e.g., highly correlated dimensions from convolutional layers), the product-form likelihood approximation degrades.

## Foundational Learning

- Concept: **Federated Learning (FL) and Personalized FL**
  - Why needed here: BTFL operates in an FL setting where clients collaboratively train a global model while maintaining local data privacy. Understanding FedAvg aggregation, local training, and the personalization-generalization trade-off is essential.
  - Quick check question: Can you explain why a purely personalized model might fail on out-of-distribution samples from other clients?

- Concept: **Bayesian Inference and Conjugate Priors (Beta-Bernoulli)**
  - Why needed here: HBU relies on conjugate prior relationships to derive analytical posterior updates without optimization. Understanding Beta distribution properties and how it serves as a prior for binomial parameters is critical.
  - Quick check question: If you observe 3 IND samples and 2 EXD samples in a test batch starting from Beta(1,1), what is the posterior distribution for m?

- Concept: **Test-Time Adaptation (TTA)**
  - Why needed here: BTFL is fundamentally a TTA method—it adapts at inference time without gradient-based optimization. Distinguishing TTA from training-time adaptation methods clarifies design constraints.
  - Quick check question: Why might entropy minimization be insufficient for TTA in FL scenarios with label distribution shifts?

## Architecture Onboarding

- Component map:
  Feature Extractor (frozen) -> Local Head + Global Head -> Local DLE + Global DLE -> HBU Module -> CBU Module -> DPI Module -> Final Prediction

- Critical path:
  1. Training phase: Clients train feature extractor + local head; compute local DLE and entropy thresholds (H̄_l, H̄_g)
  2. Server aggregates global head parameters and global DLE
  3. Test time per sample: Extract z → compute Y_l, Y_g, H_l, H_g → discretize to ẑ → compute Q_l, Q_g → HBU updates (α, β) → CBU computes τ̂ and posterior → DPI integrates to get e → output Y_int

- Design tradeoffs:
  - **Pruning threshold λ**: Controls historical prior strength; too low → prior stagnates; too high → overly responsive to noise (λ=16 in experiments)
  - **FSQ discretization**: Binary discretization enables tractable likelihood but loses feature precision; assumes independence
  - **Batch size sensitivity**: BTFL is robust to batch size=1 (unlike FedTHE's EMA approach); verified in Table 1

- Failure signatures:
  - **Prior stagnation**: If λ is too high relative to test stream length, (α, β) grow unbounded and new information has negligible effect
  - **Likelihood collapse**: If Q_l ≈ Q_g (features indistinguishable), CBU relies heavily on entropy rectification; if entropies are similar, posterior becomes uninformative
  - **Head mismatch**: If local head severely overfits to a narrow IND, even low interpolation weight on global head may not recover EXD performance

- First 3 experiments:
  1. **Sanity check with controlled IND/EXD streams**: Generate test streams with known mixing ratios (e.g., 70% IND, 30% EXD). Verify that e averages correlate with true mixing ratio. Plot e distribution over time.
  2. **Ablation on entropy rectification**: Compare BTFL full vs. variant without entropy rectification (use raw τ instead of τ̂). Measure accuracy gap on shifted IND and shifted EXD subsets.
  3. **Prior sensitivity analysis**: Vary λ from 5 to 50 on Synthetical test set. Identify point where accuracy degrades due to prior stagnation vs. noise sensitivity.

## Open Questions the Paper Calls Out

- **Privacy of DLE transmission**: To what extent does the transmission of local Discretised-Likelihood Estimators (DLEs) compromise client data privacy compared to standard model weight updates? The paper claims Federated Learning maintains data privacy, but it does not analyze the potential for membership inference attacks or reconstruction attacks using these explicit statistical summaries (DLEs) of local features.

- **Independence assumption sensitivity**: How does performance degrade when the assumption of independence between feature dimensions is violated in complex, non-ideal models? The paper relies on this independence for the Discretised-Likelihood Estimator calculation but provides no sensitivity analysis on the error introduced when this assumption fails.

- **Synthetical data optimization**: Can the interpolation strategy be dynamically adapted to improve accuracy in the "Synthetical" test scenario where IND and EXD boundaries are ambiguous? BTFL shows a bimodal distribution of interpolation coefficients for Synthetical data, suggesting uncertainty. The current Bayesian update may struggle when the "historical" prior fluctuates rapidly in mixed distributions.

## Limitations

- The independence assumption for feature dimensions may not hold in complex models, potentially degrading likelihood estimation accuracy
- Prior stagnation can occur when the pruning threshold λ is too high relative to test stream length, causing historical evidence to overwhelm new observations
- The privacy implications of transmitting Discretised-Likelihood Estimators (DLEs) are not formally analyzed, potentially compromising client data privacy

## Confidence

- **High**: Dual-head architecture feasibility, general Bayesian framework
- **Medium**: Entropy-rectified likelihood mechanism
- **Low**: Practical utility of HBU in rapidly shifting distributions

## Next Checks

1. **Sanity check with controlled IND/EXD streams**: Generate test streams with known mixing ratios (e.g., 70% IND, 30% EXD). Verify that the interpolation coefficient e correlates with the true mixing ratio. Plot the distribution of e over time to ensure it reflects the stream's characteristics.

2. **Ablation on entropy rectification**: Compare BTFL full vs. a variant without entropy rectification (use raw likelihood ratio τ instead of τ̂). Measure the accuracy gap on shifted IND and shifted EXD subsets to quantify the impact of entropy-based adjustments.

3. **Prior sensitivity analysis**: Vary the pruning threshold λ from 5 to 50 on the Synthetical test set. Identify the point where accuracy degrades due to prior stagnation versus noise sensitivity. Log α+β over time to ensure pruning triggers correctly.