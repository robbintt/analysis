---
ver: rpa2
title: 'Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting'
arxiv_id: '2510.09152'
source_url: https://arxiv.org/abs/2510.09152
tags:
- moclip
- adamw
- training
- replay
- logits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in LLM post-training,
  where domain specialization degrades general capabilities. It introduces Logits
  Replay + MoClip, a two-stage framework that records dynamic Top-K token subsets
  during Stage 0 and replays them in Stage 1 with exact renormalized losses to reduce
  computation and implicit regularization.
---

# Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting

## Quick Facts
- **arXiv ID:** 2510.09152
- **Source URL:** https://arxiv.org/abs/2510.09152
- **Reference count:** 34
- **Primary result:** Improves domain performance on Communication Technology and NL2SQL tasks while preserving general reasoning and reducing training cost by over 40%

## Executive Summary
This paper addresses catastrophic forgetting in LLM post-training, where domain specialization degrades general capabilities. It introduces Logits Replay + MoClip, a two-stage framework that records dynamic Top-K token subsets during Stage 0 and replays them in Stage 1 with exact renormalized losses to reduce computation and implicit regularization. To stabilize training under sparse supervision, MoClip caps gradient-momentum angles and applies arctan2-based rescaling. Empirically, the method improves domain performance on Communication Technology and NL2SQL tasks while preserving general reasoning (MMLU, BBH, GPQA, MATH) and reduces training cost by over 40%, offering a scalable path for domain adaptation without sacrificing generalization.

## Method Summary
The method employs a two-stage framework: Stage 0 collects dynamic Top-K token subsets from the base model's forward pass, selecting tokens that cover a probability threshold (typically 95%) while always including the gold label. Stage 1 replays these subsets during fine-tuning with restricted, renormalized softmax losses. The MoClip optimizer enhances stability by clipping gradient-momentum angle deviations (to 45°) and applying arctan2-based magnitude scaling to prevent destabilizing updates. This approach reduces computational overhead by 37% per step while maintaining or improving domain performance and general capability retention across multiple benchmarks.

## Key Results
- Achieves 92.1% retention on general benchmarks (MMLU, BBH, GPQA, MATH) while improving domain-specific tasks
- Reduces per-step training time by 37% (0.81s to 0.51s) through restricted vocabulary computation
- Outperforms standard fine-tuning baselines on Communication Technology tasks (DataComm, Wireless, CloudCore) and NL2SQL (Spider, Birds)
- Maintains stability with lowest loss variance (0.048) and gradient-norm CV (0.09) among tested optimizers

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Top-K Logits Compression
Compressing supervision to adaptive token subsets reduces forgetting without requiring external data replay. During Stage 0, the base model's forward pass identifies entropy-adaptive candidate sets per position. High-confidence predictions yield small K (few tokens), while ambiguous positions expand toward K_max=200. The gold token is always included, ensuring correctness labels are preserved. This creates implicit regularization by filtering out low-probability tokens that introduce noisy gradients.

### Mechanism 2: Gradient Bias Control via Coverage Threshold
The gradient bias from restricted vocabularies is bounded by the probability mass excluded from the Top-K set, making it controllable via the threshold τ. When computing cross-entropy over restricted set S instead of full vocabulary V, the logit-space gradient becomes g_z^S(j) = p̃(j) - y(j) for j∈S and 0 otherwise. The bias relative to full softmax is ‖Δg_z‖₁ = 2ρ where ρ is the outside probability mass. By selecting S to cover cumulative mass ≥τ, bias is bounded by 2(1-τ).

### Mechanism 3: MoClip Optimizer Geometry Constraints
Capping gradient-momentum rotation angles and applying arctan²-based magnitude scaling prevents destabilizing updates while maintaining plasticity. The optimizer decomposes gradients into parallel and orthogonal components relative to momentum, clips perpendicular components to enforce angle constraints, and applies arctan² scaling to bound update magnitudes regardless of variance estimates.

## Foundational Learning

- **Momentum-based optimization (Adam/AdamW)**: MoClip modifies Adam's update rule; understanding first/second moment estimates (m_t, v_t) is prerequisite to grasping why angle clipping and arctan² rescaling help. *Quick check:* Can you explain why Adam uses bias correction (m̂_t = m_t/(1-β₁ᵗ)) and what problem the ϵ term solves in standard Adam?

- **Softmax cross-entropy and logit-space gradients**: The restricted vocabulary method computes gradients ∂L/∂z over a subset of logits; understanding that g_z = p - y (probability minus one-hot label) is essential. *Quick check:* For a 3-class problem with logits z = [2.0, 1.0, 0.5] and true label y = 1 (class 1), what is the logit-space gradient g_z?

- **Catastrophic forgetting and gradient interference**: The method's goal is balancing plasticity (learning new domains) with stability (retaining general capabilities); understanding why fine-tuning degrades prior knowledge informs why bias control and angle clipping matter. *Quick check:* Why does full fine-tuning with AdamW on domain data cause MMLU to drop from 59.8 to 55.1 on Qwen3-4B (Table 2)?

## Architecture Onboarding

- **Component map**: Stage 0 (Logits Collection) -> Stage 1 (Replay Fine-tuning) -> MoClip Optimizer (Angle Clipping -> Arctan² Scaling -> Weight Decay)
- **Critical path**: Stage 0 runs once (~0.21s/batch on Qwen3-4B), Stage 1 runs N epochs (per-step time reduced from 0.81s to 0.51s), total training ~3.6h vs ~12h for AdamW
- **Design tradeoffs**: τ (coverage threshold) vs K_max for gradient bias vs storage, Δ_max (angle threshold) for stability vs convergence speed, bucket-based vs random position sampling for rare token coverage
- **Failure signatures**: Loss spikes during training (Δ_max too large), poor NL2SQL accuracy (random position selection misses rare tokens), slow convergence (Δ_max=30° too conservative), forgetting despite Logits Replay (τ too low), memory overflow (storing full logits)
- **First 3 experiments**:
  1. Validate Stage 0 collection overhead: Run Stage 0 forward pass on small domain dataset, measure time/storage, confirm median |S_t| ≈ 100
  2. Ablate Δ_max on stability: Train with MoClip varying Δ_max ∈ {30°, 45°, 60°, 90°}, measure loss variance and gradient-norm CV
  3. End-to-end comparison: Train with (a) AdamW SFT, (b) Logits Replay + AdamW, (c) Logits Replay + MoClip, evaluate on domain/general benchmarks

## Open Questions the Paper Calls Out

- **Transfer to parameter-efficient tuning**: Can the method extend to LoRA/adapters where striking the right balance between plasticity and stability remains crucial for practical adoption?
- **Multi-modal scaling**: How does the framework adapt to vision-language models where Top-K selection and renormalization may not directly apply to continuous embedding spaces?
- **Optimal τ for skewed distributions**: What is the optimal trade-off between coverage threshold τ and gradient bias when training data has highly skewed token distributions?
- **Logits reuse across runs**: Can Stage 0 logits be efficiently amortized across multiple fine-tuning runs with different hyperparameters or target domains?

## Limitations

- **Underspecified probability threshold τ**: The paper states median |S_t| ≈ 100 but does not report the exact τ value used, which is critical for gradient bias control
- **Ambiguous bucket sampling details**: The "5 buckets by token confidence" method lacks specification of how positions are assigned to buckets and sampled
- **Unclear arctan2 scaling scope**: Whether element-wise scaling applies per parameter or per layer is not explicitly clarified, affecting correctness verification

## Confidence

- **High confidence**: MoClip's stability benefits (angle clipping + arctan2 scaling) are well-supported with clear geometric interpretation and direct empirical validation (Figure 3)
- **Medium confidence**: Logits Replay effectiveness is supported by ablation studies but theoretical justification for why dynamic Top-K compression preserves capabilities is less rigorous
- **Low confidence**: Computational efficiency claims rely on comparisons with unspecified baselines without detailed wall-clock measurements for direct comparison

## Next Checks

- **Check 1: Verify τ sensitivity on gradient bias and stability**: Systematically vary τ ∈ {0.90, 0.92, 0.95, 0.98, 0.99} on a small CT dataset, measure median |S_t|, loss variance, and MMLU retention to replicate theoretical bias bounds
- **Check 2: Characterize bucket sampling effectiveness on rare token coverage**: Implement random, bucket-based, and last-token strategies, train on NL2SQL data, measure Spider accuracy and position frequency distribution
- **Check 3: Isolate MoClip contribution to stability**: Train Logits Replay + MoClip (no angle clipping) vs Logits Replay + AdamW vs full fine-tuning, measure per-epoch loss variance, gradient-norm CV, and MMLU retention trajectory