---
ver: rpa2
title: Conformal Data Contamination Tests for Trading or Sharing of Data
arxiv_id: '2507.13835'
source_url: https://arxiv.org/abs/2507.13835
tags:
- data
- conformal
- contamination
- test
- storey
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses data contamination detection in collaborative
  machine learning scenarios where agents share data without prior distributional
  assumptions. A novel conformal data contamination test framework is proposed to
  identify agents whose data exceeds a contamination threshold while controlling the
  false discovery rate via the Benjamini-Hochberg procedure.
---

# Conformal Data Contamination Tests for Trading or Sharing of Data

## Quick Facts
- **arXiv ID:** 2507.13835
- **Source URL:** https://arxiv.org/abs/2507.13835
- **Reference count:** 7
- **Primary result:** Conformal data contamination test framework with FDR control for identifying contaminated data agents in collaborative ML

## Executive Summary
This paper introduces a novel framework for detecting contaminated data sources in collaborative machine learning scenarios without requiring distributional assumptions. The approach uses conformal outlier detection to compute contamination p-values for each agent and applies the Benjamini-Hochberg procedure to control the false discovery rate while selecting collaboration partners. The framework is evaluated on MNIST and FEMNIST datasets, demonstrating improved personalization accuracy compared to random selection and performance close to an oracle that knows contamination factors.

## Method Summary
The method works by first splitting local data into training and calibration sets, then fitting a class-wise One-Class SVM on the training split to compute conformal scores. These scores are used to generate conformal p-values for each agent's samples, which are aggregated using one of four test statistics (Storey, Quantile, Fisher, or Sum) to produce per-agent contamination p-values. The Benjamini-Hochberg procedure is then applied to these p-values to select clean agents for collaboration. The framework provides distribution-free guarantees and handles various contamination types including label noise, feature noise, and class mixture scenarios.

## Key Results
- Proposed method improves personalization accuracy compared to random selection on MNIST and FEMNIST datasets
- Achieves performance close to an oracle that knows contamination factors
- Provides distribution-free guarantees for contamination detection through conformal outlier detection
- Demonstrates effectiveness across different contamination types (label noise, feature noise, class mixture)

## Why This Works (Mechanism)

### Mechanism 1
Testing H₀: πk ≤ πth using conformal p-values provides distribution-free guarantees for detecting contaminated data sources. Conformal scores are computed on test data from each agent and compared against a calibration set to generate conformal p-values. These m p-values per agent are aggregated via test statistics into a single contamination p-value using binomial mixture distributions. Core assumption: Exchangeability of calibration and test data; proper outlier distributions where Pk cannot be decomposed as a mixture containing P₀.

### Mechanism 2
Storey conformal data contamination p-values are PRDS, enabling FDR control via Benjamini-Hochberg when selecting collaboration partners. After computing contamination p-values for K agents, the BH procedure ranks them and applies an adaptive threshold q*·j/K. This bounds the expected proportion of agents incorrectly rejected among all rejections. Core assumption: Independence between test sets from different agents; Storey p-values specifically.

### Mechanism 3
The contamination model P̃k = (1−πk)P₀ + πkPk allows flexible contamination detection via four complementary test statistics with different hyperparameter sensitivities. Storey counts p-values exceeding λ; Quantile uses the (m−i₀)-th order statistic; Fisher combines via −2log; Sum adds p-values directly. Each produces valid p-values through binomial mixing over possible inlier counts. Core assumption: Conformal scores separate inliers from outliers effectively; hyperparameters (λ, i₀) are well-chosen for the contamination type.

## Foundational Learning

- **Conformal Prediction and P-values**: The entire framework converts arbitrary score functions into valid statistical tests without distributional assumptions. Quick check: Given calibration scores {s₁,…,sₙ} and test score s_{n+1}, how is the conformal p-value computed?

- **Benjamini-Hochberg FDR Control**: Selecting among K agents requires controlling false discoveries across multiple simultaneous hypothesis tests. Quick check: What condition must p-values satisfy for BH to guarantee FDR control at level q*·K₀/K?

- **Exchangeability**: Validity of conformal p-values depends critically on exchangeability between calibration and test data. Quick check: Would data collected sequentially from a drifting distribution violate exchangeability?

## Architecture Onboarding

- **Component map**: Calibration splitter -> Conformal score function -> P-value generator -> Test statistic aggregator -> Contamination p-value calculator -> BH selector

- **Critical path**: 
  1. Fit score function on first ℓ local samples
  2. Compute scores for calibration (n−ℓ) and all incoming m test points per agent
  3. Generate conformal p-values via Eq. 2
  4. Aggregate into per-agent contamination p-values via Eq. 3–6
  5. Apply BH (Procedure 1, line 8) to select agents for subsequent rounds

- **Design tradeoffs**: 
  - ℓ vs n−ℓ: Larger ℓ improves score quality; smaller n−ℓ yields coarser p-values
  - Test statistic: Storey/Quantile require hyperparameter tuning; Fisher/Sum are hyperparameter-free
  - m size: Larger m increases power but raises initial data exchange cost

- **Failure signatures**: 
  - P-values not superuniform under null: Check exchangeability or score function bugs
  - FDR exceeds nominal: Verify using Storey statistic (only formally proven PRDS)
  - Low power: Score function may poorly separate inliers/outliers
  - Storey performs poorly: λ likely mis-specified

- **First 3 experiments**:
  1. Replicate MNIST label-noise (digits 1,4,7; ℓ=60, n=100, m=40) to verify p-values are superuniform at π=πth
  2. Ablate ℓ/(n−ℓ) ratio on synthetic Gaussian data to quantify power-precision tradeoff
  3. Compare all four statistics on your domain data to identify robust default

## Open Questions the Paper Calls Out

- **Can the theoretical FDR control guarantees be extended to the Quantile, Fisher, and Sum conformal data contamination p-values?** The PRDS property, necessary for FDR control via BH, is currently only proven for Storey p-values. A formal proof showing Quantile/Fisher/Sum p-values satisfy PRDS would resolve this.

- **How can the data sharing framework be adapted to handle continual learning scenarios with online data acquisition policies?** The current framework is designed for discrete rounds of data sharing. A modified algorithm that dynamically updates conformal p-values and contamination thresholds as new data streams arrive would address this.

- **Can the conformal data contamination test be integrated with incentive mechanisms to ensure truthful reporting in real-world data markets?** The current paper assumes passive data provision, but in a market setting, agents might manipulate data to maximize profit. A mechanism design robust against strategic manipulation would resolve this.

## Limitations

- FDR control proof is formally established only for the Storey statistic, not for Quantile, Fisher, or Sum statistics
- Performance depends critically on hyperparameter choices (λ, i₀) which vary with contamination type and separation quality
- Framework assumes binary classification for OCSVM scores, potentially limiting multi-class applications

## Confidence

- **High confidence**: Distribution-free p-value construction via conformal scores, basic FDR control framework using BH procedure, synthetic data contamination methodology
- **Medium confidence**: FDR guarantees specifically for Storey statistic, empirical performance improvements over random selection, hyperparameter sensitivity patterns
- **Low confidence**: FDR guarantees for Quantile/Fisher/Sum statistics, generalization to non-binary classification tasks, performance in non-stationary data environments

## Next Checks

1. **Exchangeability test**: Evaluate performance when calibration and test data come from temporally drifted distributions to assess robustness to exchangeability violations

2. **FDR validation**: Conduct extensive experiments comparing actual FDR vs. nominal FDR across all four test statistics using synthetic data with known contamination factors

3. **Hyperparameter sensitivity analysis**: Systematically vary λ and i₀ across multiple contamination types and separation levels to identify robust default choices and quantify performance degradation from suboptimal settings