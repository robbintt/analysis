---
ver: rpa2
title: 'Context as a Tool: Context Management for Long-Horizon SWE-Agents'
arxiv_id: '2512.22087'
source_url: https://arxiv.org/abs/2512.22087
tags:
- context
- arxiv
- agent
- preprint
- management
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CAT, a context management paradigm that elevates
  context maintenance to a callable tool integrated into the decision-making process
  of agents. CAT formalizes a structured context workspace consisting of stable task
  semantics, condensed long-term memory, and high-fidelity short-term interactions,
  and enables agents to proactively compress historical trajectories into actionable
  summaries at appropriate milestones.
---

# Context as a Tool: Context Management for Long-Horizon SWE-Agents

## Quick Facts
- arXiv ID: 2512.22087
- Source URL: https://arxiv.org/abs/2512.22087
- Reference count: 14
- Key outcome: Introduces CAT, a context management paradigm for long-horizon software engineering agents, achieving 57.6% solved rate on SWE-Bench-Verified

## Executive Summary
This paper introduces CAT, a context management paradigm that elevates context maintenance to a callable tool integrated into the decision-making process of agents. CAT formalizes a structured context workspace consisting of stable task semantics, condensed long-term memory, and high-fidelity short-term interactions, and enables agents to proactively compress historical trajectories into actionable summaries at appropriate milestones. Experiments on SWE-Bench-Verified demonstrate that SWE-Compressor, trained using CAT's trajectory-level supervision framework, significantly outperforms ReAct-based agents and static compression baselines while maintaining stable and scalable long-horizon reasoning under a bounded context budget.

## Method Summary
CAT formalizes context management as a callable tool within the agent's decision-making process, establishing a structured context workspace with three components: stable task semantics, condensed long-term memory, and high-fidelity short-term interactions. The system introduces milestone-triggered compression, allowing agents to proactively compress historical trajectories into actionable summaries at appropriate points. SWE-Compressor is trained using a trajectory-level supervision framework that leverages human-curated or gold-standard summaries. The architecture enables agents to maintain bounded context budgets while preserving critical information needed for task completion across long-horizon software engineering tasks.

## Key Results
- SWE-Compressor achieves 57.6% solved rate on SWE-Bench-Verified
- Significantly outperforms ReAct-based agents on long-horizon software engineering tasks
- Maintains stable performance under bounded context budgets while preserving critical task information

## Why This Works (Mechanism)
CAT works by treating context management as an active decision-making tool rather than passive storage. By structuring the context workspace into task semantics, long-term memory, and short-term interactions, the system creates clear boundaries for what information to preserve versus compress. The milestone-triggered compression mechanism ensures that context is compressed at strategic points when the agent has sufficient understanding to identify what information is truly critical. This proactive approach prevents the accumulation of irrelevant context while maintaining the fidelity of task-relevant information throughout the execution process.

## Foundational Learning
- Context workspace architecture: Understanding the three-part structure (task semantics, long-term memory, short-term interactions) is crucial because it defines how information flows and is prioritized within the system. Quick check: Can you map which types of information belong to each component?
- Milestone-triggered compression: This concept is needed because it determines when and how context is compressed, directly impacting information retention and task success. Quick check: Identify what triggers a compression milestone in the system.
- Trajectory-level supervision: This learning framework is essential for training the compression model to identify and preserve critical information. Quick check: Explain how gold-standard summaries are used to train the compression model.

## Architecture Onboarding

Component Map:
CAT System -> Context Workspace (Task Semantics + Long-term Memory + Short-term Interactions) -> Milestone Detection -> Context Compression -> Decision-Making Tool

Critical Path:
Task initiation -> Context workspace population -> Milestone detection -> Context compression -> Decision-making with compressed context -> Task completion

Design Tradeoffs:
- Bounded context budget vs. information retention: The system must balance resource constraints with the need to preserve critical task information
- Compression frequency vs. milestone accuracy: More frequent compression reduces context size but risks compressing before sufficient understanding is achieved
- Model complexity vs. real-time performance: More sophisticated compression models may achieve better information preservation but could impact execution speed

Failure Signatures:
- Premature compression leading to loss of critical task information
- Missed milestones resulting in context overflow and degraded performance
- Incorrect task semantics identification causing poor compression decisions

First Three Experiments:
1. Baseline comparison: Run CAT against ReAct-based agents on simple long-horizon tasks to establish performance differential
2. Compression timing ablation: Vary the frequency of compression milestones to determine optimal timing for different task types
3. Context budget sensitivity: Test performance across different context budget sizes to identify the minimum viable budget for stable operation

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on SWE-Bench-Verified, limiting generalizability to other long-horizon software engineering tasks
- Does not address potential failures in scenarios where context compression pipeline might discard critical information
- Bounded context budget is mentioned but not thoroughly explored for different budget sizes

## Confidence

High confidence in the architectural contributions of CAT and the structured context workspace design, as these are well-formalized and demonstrated through comparative experiments.

Medium confidence in the practical scalability and robustness of SWE-Compressor, given that the evaluation is limited to a single benchmark and does not extensively test failure modes or edge cases.

Low confidence in the claims about context compression not discarding critical information, as the paper lacks detailed analysis of what types of information might be lost during compression and how this impacts task completion.

## Next Checks

1. Test CAT on additional long-horizon benchmarks beyond SWE-Bench-Verified to assess generalizability and identify potential domain-specific limitations.

2. Conduct ablation studies varying the context budget size to determine the sensitivity of CAT's performance to resource constraints and identify the minimum viable budget.

3. Implement and evaluate a failure analysis framework to systematically identify what types of information are most commonly lost during compression and how this correlates with task failure modes.