---
ver: rpa2
title: 'UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal Scene
  Translation'
arxiv_id: '2502.11132'
source_url: https://arxiv.org/abs/2502.11132
tags:
- image
- fake
- news
- detection
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: UNITE-FND reframes multimodal fake news detection as a unimodal
  text classification task by converting visual content into structured textual descriptions
  using six specialized prompting strategies with Gemini 1.5 Pro. This approach eliminates
  the need for complex multimodal architectures, achieving 92.52% accuracy on binary
  classification while reducing computational costs by over 10x compared to state-of-the-art
  multimodal models.
---

# UNITE-FND: Reframing Multimodal Fake News Detection through Unimodal Scene Translation

## Quick Facts
- arXiv ID: 2502.11132
- Source URL: https://arxiv.org/abs/2502.11132
- Reference count: 40
- Primary result: 92.52% accuracy on binary fake news detection using unimodal text classification

## Executive Summary
UNITE-FND reframes multimodal fake news detection as a unimodal text classification task by converting visual content into structured textual descriptions using six specialized prompting strategies with Gemini 1.5 Pro. This approach eliminates the need for complex multimodal architectures, achieving 92.52% accuracy on binary classification while reducing computational costs by over 10x compared to state-of-the-art multimodal models. The framework introduces Uni-Fakeddit-55k, a curated dataset of 55,000 samples processed through multimodal-to-unimodal translation, and proposes five novel metrics for evaluating image-to-text conversion quality.

## Method Summary
The framework converts multimodal fake news detection into a unimodal text classification task by processing images through six prompting strategies (Scene Graph, Relational Mapping, Descriptive Translation, Structured Image Description, Aesthetic-based, and Attribute-based) using Gemini 1.5 Pro. The resulting textual descriptions are concatenated with news titles to create structured text inputs. A DeBERTa-v3-large model is then fine-tuned on this unimodal data using specified hyperparameters (batch_size=4, grad_accum=4, epochs=3, lr=1e-5). The approach achieves comparable accuracy to multimodal methods while requiring significantly less computational resources.

## Key Results
- Achieves 92.52% accuracy on binary classification using DeBERTa-v3-large
- Reduces computational costs by over 10x compared to multimodal models
- Enables deployment on consumer hardware with as little as 0.2-8.7GB VRAM
- Introduces Uni-Fakeddit-55k dataset with 55,000 curated samples

## Why This Works (Mechanism)
UNITE-FND leverages the superior text understanding capabilities of large language models by converting visual information into structured textual descriptions. This unimodal approach bypasses the computational complexity of multimodal architectures while maintaining high accuracy. The six prompting strategies ensure comprehensive visual information capture, and the concatenation of news titles with image descriptions creates rich contextual inputs for the text classifier.

## Foundational Learning
- **Multimodal-to-unimodal translation**: Converting visual content to structured text enables leveraging advanced text models for fake news detection. Quick check: Verify image descriptions capture key objects and relationships.
- **Prompt engineering for VLMs**: Six specialized prompting strategies ensure comprehensive visual information extraction. Quick check: Compare CIQS scores across different prompting strategies.
- **Efficient fine-tuning**: Using DeBERTa-v3-large with gradient accumulation and FP16 enables high performance on limited hardware. Quick check: Monitor GPU memory usage during training.
- **Dataset curation methodology**: Creating Uni-Fakeddit-55k from Fakeddit ensures balanced, high-quality training data. Quick check: Verify class distribution matches original Fakeddit dataset.
- **Evaluation metrics for image-to-text quality**: Five novel metrics (IPR, SCS, ISS, PSD, AI) assess translation quality beyond standard accuracy. Quick check: Correlate CIQS scores with downstream classification performance.
- **Hardware-aware model selection**: Matching model size to available VRAM enables deployment across devices. Quick check: Test training on different hardware configurations.

## Architecture Onboarding

**Component map**: Gemini 1.5 Pro (VLM) -> Text Concatenation -> DeBERTa-v3-large (Text Classifier)

**Critical path**: Image → VLM Prompting → Structured Text → Tokenization → Classification → Accuracy

**Design tradeoffs**: Multimodal architecture complexity vs. unimodal efficiency; image description richness vs. computational cost; model size vs. hardware requirements.

**Failure signatures**: 
- Overfitting on small datasets (mitigated by 3 epochs)
- GPU memory overflow (use gradient checkpointing or smaller models)
- API rate limits for VLM processing (process in batches or use smaller subsets)

**3 first experiments**:
1. Process 1,000 Fakeddit samples through Structured Image Description prompt and verify output quality
2. Fine-tune DeBERTa-v3-large on 10,000 samples with batch_size=4, grad_accum=4 to establish baseline
3. Compare accuracy across all six prompting strategies on a validation subset

## Open Questions the Paper Calls Out
- **Adaptive framework development**: Can a dynamic selection mechanism be developed to choose optimal prompting strategies based on input image characteristics? The paper suggests future work in adaptive prompt optimization.
- **Adversarial robustness**: How does the image-to-text translation layer perform against adversarial attacks compared to end-to-end multimodal architectures? The paper identifies mitigating adversarial vulnerabilities as crucial for responsible deployment.
- **CIQS correlation reliability**: Does the Composite Information Quality Score reliably correlate with downstream classification accuracy? The paper notes discrepancies where high CIQS doesn't always yield best accuracy.

## Limitations
- Dependency on proprietary Gemini 1.5 Pro API introduces cost and reproducibility constraints
- Evaluation limited to Fakeddit-derived data without cross-dataset validation
- Specific generation parameters for VLM not disclosed, affecting reproducibility

## Confidence
- **Multimodal-to-unimodal translation effectiveness**: High
- **Dataset curation and evaluation metrics**: Medium
- **Generalizability across domains**: Low

## Next Checks
1. Cross-dataset validation: Test UNITE-FND on two additional multimodal fake news datasets to evaluate generalizability beyond Fakeddit-derived data
2. Prompt strategy ablation: Conduct controlled experiments varying Gemini 1.5 Pro generation parameters to determine impact on downstream classification accuracy
3. Consumer hardware benchmark: Reproduce training pipeline on hardware spanning 0.2GB-8.7GB VRAM to verify computational efficiency claims