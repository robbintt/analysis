---
ver: rpa2
title: Interpreting vision transformers via residual replacement model
arxiv_id: '2509.17401'
source_url: https://arxiv.org/abs/2509.17401
tags:
- features
- arxiv
- feature
- circuit
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first comprehensive, large-scale analysis
  of vision transformer (ViT) features across all layers and multiple model variants,
  revealing how ViTs represent visual information. The authors introduce the residual
  replacement model, which replaces ViT computations with interpretable sparse autoencoder
  (SAE) features in the residual stream, enabling scalable, faithful, and parsimonious
  circuit discovery.
---

# Interpreting vision transformers via residual replacement model

## Quick Facts
- arXiv ID: 2509.17401
- Source URL: https://arxiv.org/abs/2509.17401
- Authors: Jinyeong Kim; Junhyeok Kim; Yumin Shim; Joohyeok Kim; Sunyoung Jung; Seong Jae Hwang
- Reference count: 40
- This paper presents the first comprehensive, large-scale analysis of vision transformer (ViT) features across all layers and multiple model variants, revealing how ViTs represent visual information.

## Executive Summary
This work introduces the residual replacement model, which replaces ViT computations with interpretable sparse autoencoder (SAE) features in the residual stream, enabling scalable, faithful, and parsimonious circuit discovery. Through manual annotation of 6.6K features, the authors show that ViT features are broadly interpretable, evolving from low-level patterns (color, texture) to high-level semantics (objects, parts). The residual replacement model improves circuit faithfulness by up to 1.6x and demonstrates utility in debiasing spurious correlations, such as reducing the model's reliance on graffiti features for freight car classification.

## Method Summary
The method involves training TopK sparse autoencoders on the residual stream of vision transformers across all layers to extract interpretable features. Edge-based circuit discovery is then performed using attribution patching with LibraGrad gradient correction to identify feature-to-feature influence paths. The approach bypasses attention module complexity by operating directly on the residual stream, enabling scalable circuit construction. Human annotation validates feature interpretability, and ablation studies demonstrate the model's utility in identifying and mitigating spurious correlations.

## Key Results
- Residual replacement model improves circuit faithfulness by up to 1.6x compared to node-based methods
- Features evolve consistently from low-level patterns (color, texture) to high-level semantics (objects, parts) across layers
- Ablating spurious features improves AUC by 6.0% while maintaining accuracy in freight car classification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** TopK sparse autoencoders (SAEs) decompose polysemantic ViT residual stream activations into monosemantic, interpretable features across all layers.
- **Mechanism:** The SAE applies a sparsity constraint (selecting top-k activations) that forces the model to represent each input as a linear combination of a small number of features, each with a decoder vector that tends to align with a single semantic concept (e.g., "green color," "curve detector," "Granny Smith").
- **Core assumption:** Features that are sparsely activated and have high mutual information with interpretable visual patterns correspond to meaningful internal representations used by the ViT.
- **Evidence anchors:**
  - [abstract] "extracted via sparse autoencoders" from "6.6K features across all layers"
  - [section 2.1] Equation (1) defines TopK SAE mapping; section 2.2 shows features are significantly more interpretable than raw neurons (Figure 2a)
  - [corpus] Weak/no direct corpus evidence; neighbors focus on ViT applications, not interpretability mechanisms
- **Break condition:** If SAE reconstruction error (FVU) exceeds 0.15, features may not faithfully represent the original activations; if interpretability scores drop significantly in middle layers, the decomposition may fail for abstract concepts.

### Mechanism 2
- **Claim:** The residual replacement model constructs faithful and parsimonious circuits by tracking feature-to-feature influence via the residual stream, using edge-based attribution patching with gradient correction.
- **Mechanism:** By treating the residual stream as a communication channel and estimating edge importance via attribution patching (gradient-based approximation of causal effects), the method identifies which upstream features causally influence downstream features. Edge-based selection (vs. node-based) and LibraGrad gradient correction reduce noise and improve causal alignment.
- **Core assumption:** The residual stream preserves enough information flow to bypass attention module complexity, and gradient-based attribution approximates true causal effects sufficiently for circuit discovery.
- **Evidence anchors:**
  - [abstract] "residual replacement model... replaces ViT computations with interpretable features in the residual stream"
  - [section 3.1] Equation (2) defines edge importance; section 3.2/Table 1 shows edge-based discovery + gradient correction improves faithfulness from 64.9% to 94.1% (ViT)
  - [corpus] No direct corpus evidence; neighbors do not address circuit discovery methods
- **Break condition:** If ViT gradients remain excessively noisy even after LibraGrad correction, edge importance estimates may be unreliable; if token aggregation hides critical token-to-token interactions, circuits may miss key mechanisms.

### Mechanism 3
- **Claim:** Ablating spurious features identified in the residual replacement model reduces reliance on spurious correlations while maintaining task accuracy.
- **Mechanism:** By analyzing circuits for classes with known spurious correlations (e.g., "freight car" associated with "graffiti"), the method identifies features that activate on spurious cues. Ablating these features (replacing with median activation) removes their contribution to the final prediction without retraining.
- **Core assumption:** Spurious features are sufficiently localized to specific SAE features and generalize across images within a class.
- **Evidence anchors:**
  - [abstract] "identifies and mitigates spurious correlations, improving AUC by 6.0%"
  - [section 4/Table 2] Ablating a single spurious feature (e.g., graffiti feature L9#2371) improves AUC from 0.854 to 0.904 with accuracy maintained at ~0.848
  - [corpus] No direct corpus evidence; neighbors do not address debiasing via interpretability
- **Break condition:** If spurious correlations are distributed across many features or layers, single-feature ablation may be insufficient; if ablated features also contribute to legitimate predictions, accuracy may drop.

## Foundational Learning

- **Concept: Sparse Autoencoders / Dictionary Learning**
  - Why needed here: Core technique for decomposing polysemantic neurons into interpretable features; the entire method hinges on SAE quality.
  - Quick check question: Can you explain how a sparsity constraint (e.g., TopK) encourages monosemantic feature learning?

- **Concept: Residual Stream in Transformers**
  - Why needed here: The residual replacement model operates on the residual stream as the primary information channel; understanding its role is essential for bypassing attention complexity.
  - Quick check question: In a transformer, how does the residual stream enable modules (attention, FFN) to read from and write to a shared representation?

- **Concept: Mechanistic Interpretability / Circuit Analysis**
  - Why needed here: The goal is to construct human-interpretable circuits; familiarity with circuit concepts (nodes, edges, faithfulness, completeness) is prerequisite.
  - Quick check question: What does it mean for a circuit to be "faithful" to the original model's computation?

## Architecture Onboarding

- **Component map:** Input image → ViT backbone (12 layers for ViT-B/16) → Residual stream at each layer → Trained TopK SAE per layer → Sparse feature activations → Edge importance estimation (attribution patching + LibraGrad) → Circuit discovery (edge-based, top-k selection) → Human interpretation / Spurious feature ablation.

- **Critical path:** (1) Train SAEs with acceptable FVU (<0.15) on residual streams; (2) Validate feature interpretability via human annotation; (3) Compute edge importance for target prediction; (4) Extract circuit and evaluate faithfulness/completeness/causality.

- **Design tradeoffs:** (a) Parsimony vs. faithfulness—smaller k yields simpler circuits but may miss mechanisms; (b) Token aggregation vs. detail—averaging over tokens enables scalability but loses token-specific interactions; (c) Edge-based vs. node-based discovery—edge-based improves causality but requires more computation.

- **Failure signatures:** (a) Low interpretability scores in middle layers (abstract features); (b) Noisy gradients leading to unstable edge importance (mitigated by LibraGrad); (c) Low faithfulness (<70%) suggests SAE reconstruction or circuit discovery issues; (d) High completeness loss after ablation indicates critical features were removed.

- **First 3 experiments:**
  1. Train TopK SAEs on a single ViT layer (e.g., Layer 5) with varying k and expansion rate; evaluate FVU and feature interpretability on 200 random images.
  2. For a single image class (e.g., "Granny Smith"), construct a circuit with top-3 features per layer; manually inspect feature interpretations and edge importance to validate the low-level-to-high-level progression.
  3. Identify a known spurious correlation in a validation set image, locate the corresponding feature in the circuit, ablate it, and measure changes in AUC and accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the explicit functions of attention heads and feed-forward networks (FFNs) be incorporated into the residual replacement model to provide a more fine-grained mechanistic understanding of ViTs?
- Basis in paper: [explicit] The authors state in the Limitations section that the residual replacement model "only indirectly captures the roles of attention and feed-forward modules via gradient-based methods, and thus does not explicitly explain their functions."
- Why unresolved: The current framework bypasses these modules to ensure the circuit is parsimonious and human-interpretable, trading off module-level detail for scalability.
- What evidence would resolve it: An extension of the residual replacement model that constructs sub-circuits for attention heads or FFNs while maintaining high faithfulness and low computational cost.

### Open Question 2
- Question: How can critical token-to-token interactions, particularly those involving the [CLS] token, be scalably modeled and interpreted within the residual replacement framework?
- Basis in paper: [explicit] The authors note that while they aggregate tokens for scalability, "understanding how the [CLS] token interacts with other tokens could provide valuable insights into the model's behavior. We leave the investigation of such interactions to future work."
- Why unresolved: Modeling all patch interactions results in excessively large, uninterpretable circuits; current methods average activations to avoid this complexity.
- What evidence would resolve it: A method that identifies and visualizes sparse, high-importance inter-token circuits without requiring $O(T^2)$ complexity for interpretation.

### Open Question 3
- Question: Can the dataset of 6.6K manually annotated features be leveraged to train or benchmark automatic interpretability methods for vision models?
- Basis in paper: [explicit] The authors identify that manual annotation involves subjectivity and suggest that "An exciting direction for future work is to leverage our feature annotation data to advance and evaluate automatic interpretability methods."
- Why unresolved: Automated methods using models like CLIP often miss subtle concepts, while manual methods are unscalable and prone to human bias.
- What evidence would resolve it: An automated interpretation pipeline that achieves high correlation with human annotations on a held-out set of features or successfully identifies novel, verified features missed by current automated baselines.

## Limitations

- The method primarily captures indirect effects through the residual stream, not explicitly modeling attention head or FFN functions
- Token aggregation may hide critical token-to-token interactions, particularly involving the [CLS] token
- Results are demonstrated primarily on ViT-B/16 and ImageNet-1K, limiting generalizability to other architectures and domains

## Confidence

**High Confidence:**
- The residual replacement model improves circuit faithfulness compared to node-based methods (up to 1.6x improvement with edge-based + gradient correction)
- Sparse autoencoders can extract interpretable features from ViT residual streams, with interpretability scores significantly higher than raw neurons
- Ablating spurious features reduces reliance on spurious correlations while maintaining task accuracy (6.0% AUC improvement in freight car example)

**Medium Confidence:**
- The low-level-to-high-level feature progression across layers is a consistent pattern across ViT variants
- The method scales effectively to 6.6K features and multiple model variants as claimed
- LibraGrad gradient correction provides meaningful noise reduction in edge importance estimation

**Low Confidence:**
- The residual replacement model will generalize equally well to larger ViT architectures or non-ImageNet domains
- Single-feature ablation will be sufficient for complex spurious correlations distributed across multiple features
- The 94.1% faithfulness score is representative across diverse image classes and prediction targets

## Next Checks

1. **Cross-architecture validation**: Apply the residual replacement model to ViT-Huge and Swin Transformer architectures on ImageNet and a non-natural image dataset (e.g., medical imaging or satellite imagery) to assess generalizability.

2. **Multi-feature spurious correlation ablation**: For classes with known multiple spurious correlations (e.g., animal species with background biases), identify and ablate all correlated features simultaneously, measuring changes in AUC, accuracy, and feature importance distributions.

3. **Token-level circuit analysis**: Compare edge importance scores and circuit structures when using token aggregation versus token-specific analysis on a subset of images, to quantify information loss from averaging and identify critical token-level interactions.