---
ver: rpa2
title: 'RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning
  over Graph'
arxiv_id: '2505.03173'
source_url: https://arxiv.org/abs/2505.03173
tags:
- video
- frames
- graph
- reasoning
- frame
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of understanding long videos
  using Large Multi-modal Models (LMMs), which struggle due to limited context length
  and lack of explicit memory mechanisms. The proposed solution, RAVU (Retrieval Augmented
  Video Understanding), introduces a novel framework that constructs a spatio-temporal
  graph as long-term memory from video frames and performs compositional reasoning
  over this graph to retrieve relevant frames for answering complex queries.
---

# RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph

## Quick Facts
- arXiv ID: 2505.03173
- Source URL: https://arxiv.org/abs/2505.03173
- Authors: Sameer Malik; Moyuru Yamada; Ayush Singh; Dishank Aggarwal
- Reference count: 10
- Primary result: Up to 76.7% accuracy on NExT-QA and 67.41% on EgoSchema, outperforming state-of-the-art methods

## Executive Summary
RAVU addresses the challenge of understanding long videos with Large Multi-modal Models (LMMs) by constructing a spatio-temporal graph as long-term memory from video frames. The framework performs compositional reasoning over this graph to retrieve relevant frames for answering complex queries. Experiments demonstrate superior performance with limited retrieved frames (5-10), achieving state-of-the-art results on NExT-QA and EgoSchema datasets. The method is particularly effective for multi-hop reasoning and tracking objects across frames.

## Method Summary
RAVU constructs a spatio-temporal graph representation from video frames to serve as long-term memory for tracking entities and their actions across time. The framework generates rich frame and entity descriptions using an LMM, converts them into a graph structure, and decomposes queries into reasoning steps executed on the graph. The approach involves two main stages: graph generation (offline) and compositional reasoning (online). For graph generation, entities are detected in each frame and tracked across time, then an LMM generates descriptions that are converted into per-frame graphs and connected temporally. For compositional reasoning, queries are decomposed into sequential reasoning steps using predefined functions, which are executed on the graph to retrieve relevant frames for answer generation by an LMM.

## Key Results
- Achieves 76.7% accuracy on NExT-QA and 67.41% on EgoSchema datasets
- Outperforms state-of-the-art methods with limited retrieved frames (5-10)
- Particularly effective for multi-hop reasoning and object tracking across frames
- Shows superior performance in localization accuracy with two-stage retrieval (embedding filtering + LLM reranking)

## Why This Works (Mechanism)

### Mechanism 1: Spatio-Temporal Graph as Compressible Long-Term Memory
Converting video frames into a structured spatio-temporal graph preserves entity relationships and temporal dynamics while drastically reducing token footprint for LMMs. Entities are detected and tracked across frames, then converted into per-frame graphs with temporal connections. The core assumption is that bounding box matching reliably maintains consistent entity identity across frames despite occlusion and motion blur. Evidence shows this approach outperforms direct LMM processing of long videos, though entity tracking quality is a bottleneck when objects are occluded for extended periods or when multiple visually similar entities confuse the tracker.

### Mechanism 2: Compositional Reasoning via Query-to-Graph Operations
Decomposing complex queries into sequential graph operations enables multi-hop reasoning that similarity-based retrieval cannot achieve. An LLM breaks down queries using manually crafted in-context examples covering temporal, descriptive, and causal question types, then predefined functions execute these steps on the graph. The core assumption is that the manually designed reasoning function set sufficiently covers the query space for target datasets. Evidence shows this approach handles queries like "What did the boy do after drinking juice?" through sequential inference steps. The method fails when queries require reasoning operations outside the predefined function set or when the graph lacks necessary relational structure.

### Mechanism 3: Two-Stage Retrieval with Semantic Reranking
Combining embedding-based candidate filtering with LLM semantic reranking improves localization accuracy over single-stage similarity search. Stage 1 uses text embeddings to filter top-k nodes by cosine similarity, while Stage 2 uses an LLM to compare textual descriptions against the grounding phrase for precise semantic matching. The core assumption is that embedding similarity provides reasonable recall while LLM judgment adds necessary precision for disambiguation. Evidence shows the proposed reranking achieves 70.57% localization accuracy versus 58.69% (text embedding) and 60.87% (CLIP) on causal questions. The approach fails if the correct frame is excluded from top-k (recall failure) or if the LLM hallucinates a match during semantic comparison (precision failure).

## Foundational Learning

- **Concept: Scene Graphs for Video Representation**
  - Why needed here: RAVU builds on scene graph literature where nodes represent objects/entities and edges capture spatial/interaction relationships. Understanding this representation is prerequisite to grasping how the memory structure is built and queried.
  - Quick check question: Given a frame showing "a person pouring water from a blue bottle into a glass," what would be the nodes and edges in a scene graph?

- **Concept: Multi-Hop Reasoning**
  - Why needed here: The paper explicitly targets queries requiring sequential inference steps (e.g., "What happened after X did Y to Z?"). Distinguishing single-hop retrieval from multi-hop compositional reasoning is essential for understanding why RAVU decomposes queries.
  - Quick check question: Why does "What color is the shirt?" require different retrieval logic than "What did the person do after putting down the red cup?"

- **Concept: Entity Re-Identification Across Frames**
  - Why needed here: RAVU's temporal graph depends on maintaining consistent entity IDs across frames via tracking. Without this, temporal edges would connect unrelated entities, breaking multi-hop reasoning.
  - Quick check question: What failure modes occur when a tracker assigns a new ID to the same person after they walk behind an obstruction?

## Architecture Onboarding

- **Component map:** Entity Detection & Tracking -> Description Generation -> Graph Construction -> Event Chunking -> Query Decomposition -> Graph Retrieval Engine -> Answer Generation

- **Critical path:** Offline: Video → Entity Detection → Description Generation → Graph Construction → Event Chunking (stored as memory). Online: Query → Decomposition → Reasoning Execution over Graph → Frame Retrieval → LMM Answer Generation. The graph is built once per video; retrieval is per-query. Query decomposition and reasoning execution are the primary online latency contributors.

- **Design tradeoffs:**
  - Token cost vs. decomposition quality: Query breakdown averages 3,465 tokens/question due to in-context examples. Fine-tuning could reduce this but requires curated training data.
  - Graph expressiveness vs. hallucination: LMM-generated graphs are more expressive than fixed-vocabulary annotations but risk hallucinated relations. VidOR annotations achieve 75.16% vs SAM2-based 70.86% on temporal questions.
  - Retrieval frame count vs. context limit: 5-10 frames balances coverage with LMM context. More frames increase cost and noise risk.

- **Failure signatures:**
  - Tracking collapse: ID switches cause temporal edges to connect wrong entities → retrieval follows incorrect object through time
  - Safety filter rejection: Gemini blocked 144/5000 NExT-QA questions, creating coverage gaps
  - Hallucinated graph relations: LMM describes interactions not present in frames → false positives in retrieval
  - Function coverage gaps: Queries requiring unimplemented reasoning operations fail silently or produce irrelevant retrievals

- **First 3 experiments:**
  1. Baseline reproduction on NExT-QA: Implement BlindQA, All-frames (1 fps), CLIP-based retrieval (k=5), and text-based retrieval (k=5) with Gemini 1.5 Flash as the fixed reasoning model. Evaluate on the 4,596 non-blocked questions to validate the reported gap (RAVU 74.6% vs CLIP 72.3%).
  2. Retrieval stage ablation: Using the 381 manually annotated localization questions, compare: (a) embedding-only retrieval, (b) embedding + text reranking, (c) full pipeline. Measure precision@1 for frame localization.
  3. Tracking quality sensitivity analysis: Run RAVU on a held-out subset using (a) SAM2 predictions, (b) ground-truth VidOR tracklets. Compute correlation between tracking error rate and QA accuracy degradation to quantify the tracking bottleneck.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the predefined reasoning functions (e.g., `localize_node`) be effectively replaced by neural networks to improve generalization without manual engineering?
- Basis in paper: [explicit] The introduction states, "While we implement various reasoning steps to cover a wide range of queries, it is possible to employ neural networks for each step."
- Why unresolved: The current implementation relies on manually designed reasoning functions to decompose queries and execute steps on the graph. The paper proposes the possibility of using neural networks but does not implement or validate this approach.
- What evidence would resolve it: A comparative study evaluating the performance gap between the current hand-crafted reasoning functions and a learned neural module on the NExT-QA and EgoSchema benchmarks.

### Open Question 2
- Question: To what extent does the hallucination of relations in the LLM-generated graph degrade performance compared to human-annotated graphs?
- Basis in paper: [explicit] Section 5.4 notes that despite the generated graph being more expressive, its performance is inferior to human-annotated graphs, which is "attributed to the presence of hallucinations in our graph."
- Why unresolved: The paper identifies hallucinations as a cause for the performance drop compared to ground truth but does not propose or test a method to filter or correct these hallucinations automatically.
- What evidence would resolve it: An ablation study measuring QA accuracy where the generated graph is corrected or filtered for hallucinations compared to the raw LLM-generated output.

### Open Question 3
- Question: How does the accuracy of the entity tracking module (e.g., SAM2) impact the final VideoQA performance?
- Basis in paper: [explicit] Section 5.4 states that "entity tracking performance may be a critical bottleneck" and that confusion between visually similar entities leads to inconsistent IDs.
- Why unresolved: The authors identify tracking as a bottleneck and compare SAM2 against VidOR annotations, but they do not isolate the error propagation from tracking failures to the final reasoning step.
- What evidence would resolve it: Experiments using ground-truth tracklets (perfect tracking) versus predicted tracklets to quantify the specific loss in QA accuracy attributable to tracking errors.

### Open Question 4
- Question: Can fine-tuning the LMM significantly reduce the high token cost associated with the query breakdown process?
- Basis in paper: [explicit] Section 5.2 highlights that the query breakdown is expensive (3,465 tokens per question) due to in-context examples and suggests the cost "can be significantly reduced through finetuning."
- Why unresolved: The paper identifies the cost inefficiency of using in-context learning for query decomposition but does not implement the proposed fine-tuning solution to verify if efficiency can be improved without losing accuracy.
- What evidence would resolve it: A comparison of token consumption and QA accuracy between the current prompt-based breakdown and a fine-tuned model on the query breakdown task.

## Limitations
- Entity tracking quality is a critical bottleneck, with SAM2 performance (70.86%) significantly below ground-truth annotations (75.16%) on temporal questions
- Query decomposition and reasoning function coverage depend on manually curated in-context examples not provided in the paper
- The method shows safety filter rejections, with Gemini blocking 144/5000 NExT-QA questions

## Confidence

- **High confidence:** The core retrieval augmentation mechanism (graph-based memory + compositional reasoning) is technically sound and empirically validated. The performance improvements on NExT-QA and EgoSchema are robust against the stated baselines.
- **Medium confidence:** The attribution of gains to specific components (e.g., semantic reranking vs. embedding filtering) is less certain. Ablation studies show relative improvements, but the exact contribution of each stage is not isolated.
- **Low confidence:** The generalizability of the manually designed reasoning function set to other video QA datasets or real-world applications is unknown. The function coverage appears dataset-specific.

## Next Checks

1. **Function coverage stress test:** Create a test suite of complex queries that probe the boundaries of the predefined reasoning functions (e.g., counterfactual reasoning, multi-object causality). Measure failure rates to identify coverage gaps.

2. **Retrieval quality analysis:** Using the 381 manually annotated localization questions, perform a fine-grained breakdown: (a) measure recall@10 for correct frames in embedding filtering, (b) measure precision@1 for LLM reranking on the filtered set, (c) identify failure modes (omission vs. hallucination) in each stage.

3. **Tracking bottleneck quantification:** Run RAVU on a subset of videos with varying object tracking difficulty (occlusion frequency, motion speed, visual similarity). Correlate tracking error rate (ID switches/video) with QA accuracy degradation to establish a quantitative relationship.