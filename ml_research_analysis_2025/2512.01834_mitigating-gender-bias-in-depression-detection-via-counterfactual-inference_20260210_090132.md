---
ver: rpa2
title: Mitigating Gender Bias in Depression Detection via Counterfactual Inference
arxiv_id: '2512.01834'
source_url: https://arxiv.org/abs/2512.01834
tags:
- depression
- gender
- bias
- causal
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Audio-based depression detection models often exhibit gender bias
  due to imbalanced training data, where females are over-represented and diagnosed
  more frequently. This study proposes a Counterfactual Debiasing Framework grounded
  in causal inference to mitigate such bias.
---

# Mitigating Gender Bias in Depression Detection via Counterfactual Inference

## Quick Facts
- **arXiv ID:** 2512.01834
- **Source URL:** https://arxiv.org/abs/2512.01834
- **Reference count:** 29
- **Primary result:** Counterfactual debiasing reduces EA to 0.013/0.007 and improves DI to 0.719/0.745 while increasing F1-scores to 0.644/0.804 and accuracies to 0.702/0.830

## Executive Summary
This study addresses gender bias in audio-based depression detection models, which often exhibit skewed predictions due to imbalanced training data where females are over-represented and diagnosed more frequently. The authors propose a Counterfactual Debiasing Framework based on causal inference that identifies and removes the direct causal effect of gender on predictions. By employing counterfactual inference during the inference phase, the method significantly reduces gender bias while enhancing overall detection performance. Experiments using two advanced acoustic backbones (STA-based and NetVLAD-based) on the DAIC-WOZ dataset demonstrate substantial improvements in both fairness metrics and classification accuracy compared to existing debiasing strategies.

## Method Summary
The framework constructs a causal graph distinguishing a spurious direct path (G→D representing gender bias) from an indirect path (G,C→F→D where acoustic features capture genuine pathological signals). A learnable parameter ε represents the model's output under "empty" input conditions. During training, the model learns to predict depression labels while simultaneously learning the counterfactual baseline. At inference, the Total Indirect Effect (TIE) is computed by subtracting the counterfactual prediction from the factual prediction, effectively removing the direct gender effect while preserving authentic acoustic pathological features.

## Key Results
- EA reduced from 0.029→0.013 (STA) and 0.034→0.007 (NetVLAD)
- DI improved from 2.635→0.719 (STA) and 1.917→0.745 (NetVLAD)
- F1-scores increased from baseline to 0.644 (STA) and 0.804 (NetVLAD)
- Accuracies improved to 0.702 (STA) and 0.830 (NetVLAD)

## Why This Works (Mechanism)

### Mechanism 1: Causal Graph Decomposition of Prediction Paths
- **Claim:** Gender bias arises from a direct causal path G→D that bypasses authentic acoustic features
- **Core assumption:** Gender information can influence predictions independently of acoustic cues
- **Evidence:** Causal graph in Fig. 2(a) shows explicit G→D arrow alongside G,C→F→D path

### Mechanism 2: Counterfactual Intervention for Bias Estimation
- **Claim:** The direct gender effect can be estimated by simulating a counterfactual scenario where acoustic cues are "removed"
- **Core assumption:** A single global parameter ε can approximate the model's behavior under "no information"
- **Evidence:** ε represented by global learnable parameter in Eq. 9

### Mechanism 3: Total Indirect Effect (TIE) Inference for Debiasing
- **Claim:** Subtracting the direct effect from total effect yields predictions that rely primarily on authentic acoustic pathological features
- **Core assumption:** The indirect path through F genuinely encodes depression-relevant acoustic features
- **Evidence:** EA drops from 0.029→0.013 (STA) and 0.034→0.007 (NetVLAD)

## Foundational Learning

- **Concept: Causal Graphs and Intervention**
  - **Why needed:** Understanding how to decompose prediction into causal components is essential for grasping why bias is defined as G→D rather than correlation
  - **Quick check:** In the causal graph, which arrow represents the "spurious correlation" the paper aims to eliminate?

- **Concept: Counterfactual Reasoning (do-calculus intuition)**
  - **Why needed:** The method relies on asking "what would the model predict if gender were held constant but acoustic inputs were absent?"
  - **Quick check:** Why must F be "intervened" to its state under G=̄g rather than simply set to zero?

- **Concept: Additive Nonlinear Fusion (log-sigmoid)**
  - **Why needed:** The fusion function h(D_g, D_F_g,c) = log σ(D_g + D_F_g,c) determines how bias and signal logits combine
  - **Quick check:** Why is log σ used instead of raw addition for combining D_g and D_F_g,c?

## Architecture Onboarding

- **Component map:**
  - M_G (Gender-only MLP) -> maps gender g → logit D_g
  - M_F (Fusion backbone) -> maps (g, c) → logit D_F_g,c
  - ε (Global parameter) -> represents "empty input" baseline
  - Fusion h -> log-sigmoid combining D_g + D_F_g,c

- **Critical path:**
  1. Training: Input (g, c) → M_G produces D_g; M_F produces D_F_g,c and D_F_ε
  2. L_cls updates M_G and M_F to predict depression labels
  3. L_kl updates only ε to match p(d|g,c) with p(d|g,̄c)
  4. Inference: TIE = h(M_G(g), M_F(g,c)) - h(M_G(g), M_F(ε))

- **Design tradeoffs:**
  - ε vs. explicit empty input: ε is efficient but assumes single-point approximation
  - Joint vs. separate training: Joint allows L_kl to shape ε but risks conflicting objectives
  - STA vs. NetVLAD backbone: STA captures temporal dynamics; NetVLAD aggregates variable-length inputs

- **Failure signatures:**
  - EA > 0.02 after training: M_G not capturing sufficient bias or ε poorly calibrated
  - Male-F1 drops below baseline: Over-correction removing genuine signal
  - DI → 1.0 but F1 drops significantly: Fairness achieved via performance degradation
  - Training instability with L_kl: ε diverging

- **First 3 experiments:**
  1. Baseline bias quantification: Run "None" condition; record EA, DI, Male-F1 vs. Female-F1 gap
  2. Ablate L_kl: Train without KL loss; compare EA to full method
  3. Visualize D_g by gender: Plot distribution of M_G outputs for male vs. female samples

## Open Questions the Paper Calls Out
- **Extension to multimodal:** Can the framework be extended to a unified multimodal setting to disentangle gender bias across audio, visual, and linguistic cues simultaneously?
- **Generalization to wild data:** Does the method's effectiveness generalize to "in-the-wild" data or other languages outside the specific structure of DAIC-WOZ clinical interviews?
- **Intersectional biases:** Can the causal graph formulation be adapted to mitigate intersectional biases or other attributes (e.g., age, ethnicity) without compromising detection performance?

## Limitations
- The learnable parameter ε approximation's validity across different contexts and datasets remains unverified
- The method's performance on more balanced datasets or those with different gender-imbalance patterns is unknown
- The assumption that gender has a direct causal effect may not hold for all depression detection models

## Confidence
- **High confidence:** The causal graph framework and TIE inference mechanism are mathematically sound and consistently implemented
- **Medium confidence:** The empirical results on DAIC-WOZ dataset show meaningful bias reduction, but generalizability requires further validation
- **Low confidence:** The approximation of counterfactual inference through ε is novel and lacks direct validation from related work

## Next Checks
1. **Cross-dataset validation:** Test the framework on multiple depression detection datasets with varying gender distributions
2. **Ablation study:** Systematically vary the KL loss weight and ε initialization to determine sensitivity to hyperparameters
3. **Feature attribution analysis:** Use SHAP or similar methods to verify that TIE predictions rely more heavily on acoustic features than gender-correlated artifacts compared to baseline models