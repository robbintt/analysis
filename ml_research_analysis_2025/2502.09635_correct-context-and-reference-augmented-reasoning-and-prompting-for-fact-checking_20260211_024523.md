---
ver: rpa2
title: 'CORRECT: Context- and Reference-Augmented Reasoning and Prompting for Fact-Checking'
arxiv_id: '2502.09635'
source_url: https://arxiv.org/abs/2502.09635
tags:
- evidence
- prompt
- sentences
- claim
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CORRECT, a fact-checking model that integrates
  contextual and referential documents into evidence reasoning using a three-layer
  evidence graph. The method constructs intra- and cross-layer reasoning to learn
  unified evidence embeddings and employs evidence-conditioned prompt embeddings for
  claim verification.
---

# CORRECT: Context- and Reference-Augmented Reasoning and Prompting for Fact-Checking

## Quick Facts
- arXiv ID: 2502.09635
- Source URL: https://arxiv.org/abs/2502.09635
- Reference count: 40
- This paper introduces CORRECT, a fact-checking model that integrates contextual and referential documents into evidence reasoning using a three-layer evidence graph.

## Executive Summary
This paper introduces CORRECT, a fact-checking model that integrates contextual and referential documents into evidence reasoning using a three-layer evidence graph. The method constructs intra- and cross-layer reasoning to learn unified evidence embeddings and employs evidence-conditioned prompt embeddings for claim verification. Experiments on four datasets (FEVEROUS-S, BearFact, Check-COVID, SciFact) show that CORRECT achieves state-of-the-art performance, with Macro F1 scores up to 88.41% on gold evidence and 75.35% on retrieved evidence settings. Ablation studies confirm the effectiveness of the three-layer graph and prompt-based approach.

## Method Summary
CORRECT is a fact-checking model that constructs a three-layer evidence graph consisting of evidence sentences, contextual documents (same source), and referential documents (cited/hyperlinked sources). The model employs intra-layer reasoning to aggregate evidence sentences and cross-layer reasoning to integrate contextual and referential information into unified evidence embeddings. A key innovation is the use of evidence-conditioned continuous prompt embeddings that are learned specifically for each claim based on its evidence profile. The model uses a nested architecture with 12-step Transformer encoding and contrastive loss for training, achieving state-of-the-art performance on four fact-checking datasets.

## Key Results
- Achieves state-of-the-art Macro F1 scores up to 88.41% on gold evidence settings
- Maintains strong performance (75.35% Macro F1) even with BM25-retrieved evidence
- Ablation studies confirm all three layers (evidence, context, reference) contribute meaningfully to performance
- Evidence-conditioned prompt embeddings outperform discrete natural language prompts

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A three-layer heterogeneous graph structure with explicit intra- and cross-layer reasoning pathways enables more complete evidence interpretation than treating all documents uniformly.
- **Mechanism:** Evidence sentences reside on one layer; contextual documents (same source) and referential documents (cited/hyperlinked sources) occupy separate layers. Intra-layer reasoning aggregates multiple evidence sentences via type-specific attention (Eq. 2-4). Cross-layer reasoning uses separate projection parameters (W1 vs. W2, b1 vs. b2) to aggregate context and reference embeddings into evidence representations while preserving semantic distinctions between document types.
- **Core assumption:** Contextual and referential documents provide non-redundant information that resolves ambiguities (acronyms, coreference, scope) not present in evidence sentences alone.
- **Evidence anchors:** Abstract: "we construct a three-layer evidence graph with evidence, context, and reference layers. We design intra- and cross-layer reasoning to integrate three graph layers into a unified evidence embedding"; Section: Page 4, Eq. 5-6 show separate aggregation for contextual (ĉ) and referential (r̂) documents with reference-specific parameters W2, b2; Corpus: Weak external validation—neighbor papers discuss multi-hop reasoning (GraphCheck, RAMA) but do not specifically validate the three-layer heterogeneous structure.
- **Break condition:** If evidence sentences are already self-contained (no acronyms, no coreference ambiguity), contextual and referential layers provide diminishing returns; ablation shows removing context/reference layers degrades performance but evidence-only still achieves ~70-80% of full performance (Fig. 4a).

### Mechanism 2
- **Claim:** Asymmetric multi-head self-attention with virtual tokens enables bidirectional information flow from graph-augmented embeddings to token-level representations while preventing evidence embeddings from being overwritten.
- **Mechanism:** Graph-aggregated embeddings (intra-layer evidence aggregation ĥe, cross-layer context ĥc, reference ĥr) are concatenated as virtual tokens to the evidence sentence embedding matrix (Eq. 6). In the subsequent Transformer step, Keys (K) and Values (V) include these virtual tokens, but Queries (Q) do not (Eq. 7). This allows evidence tokens to attend to graph-level information while ensuring context/reference signals enhance rather than replace original evidence semantics.
- **Core assumption:** One-directional influence (graph → tokens) is sufficient; bidirectional overwriting would lose fine-grained token-level evidence signals.
- **Evidence anchors:** Section: Page 4, Eq. 7: "Keys K and values V are augmented with virtual tokens, but queries Q are not, to avoid context and reference embeddings being overwritten by evidence sentence embedding"; Section: Page 3-4: "We design type-specific attention" (Eq. 2) with separate parameters for evidence-evidence vs. evidence-reference aggregation; Corpus: No direct external validation of asymmetric attention for fact-checking; transformer attention mechanisms broadly validated but this specific pattern is novel.
- **Break condition:** If the Transformer depth L is too shallow (<4 steps per ablation conventions), graph signals may not propagate sufficiently to token representations; if L is too deep, over-smoothing may occur.

### Mechanism 3
- **Claim:** Evidence-conditioned continuous prompt embeddings outperform discrete natural language prompts by learning task-specific representations that adapt to each claim's evidence profile.
- **Mechanism:** Base prompt embeddings {hm} are initialized from mean-pooled word embeddings of training claims grouped by label (Eq. 10-11). Evidence embedding hE is projected through tanh-scaled transformations (α, β) and combined with base prompts via element-wise product and summation: πm = hm ⊙ (αx + 1) + βx. These claim-specific prompts are prepended to claim tokens and processed by a shared claim encoder. Contrastive loss (Eq. 13) aligns claim-prompt representations with evidence embeddings for the correct label.
- **Core assumption:** Continuous prompt embeddings can encode verification-relevant patterns that discrete text cannot capture; initialization from label-grouped training claims provides better starting points than random initialization.
- **Evidence anchors:** Abstract: "we design evidence-conditioned prompt encoder, which produces unique prompt embeddings for each claim"; Section: Page 5, Eq. 10-11: πm = hm ⊙ (αx + 1) + βx with temperature-scaled tanh projections; Section: Page 5: "Our initialization produces better results, because evidence graph separates different sets of prompt embeddings and provides a more informative starting point"; Corpus: Weak—neighbor papers use discrete prompts (ProToCo, ProgramFC mentioned in baselines) but no external validation of evidence-conditioned continuous prompts.
- **Break condition:** If number of prompt embeddings M is too small (M=2 in ablation), insufficient claim-evidence interaction capacity; if M is too large (M=16), overfitting occurs (Fig. 4b). If initialization is random rather than label-grouped, optimization becomes unstable.

## Foundational Learning

- **Graph Neural Networks (GNNs) with heterogeneous graphs:**
  - Why needed here: The three-layer evidence graph uses type-specific parameters and attention mechanisms; understanding message passing, aggregation functions, and heterogeneous graph handling is essential for implementing intra/cross-layer reasoning.
  - Quick check question: Can you explain why using separate projection weights (W1 vs. W2) for different edge types preserves semantic distinctions in a heterogeneous graph?

- **Prompt tuning vs. discrete prompting:**
  - Why needed here: CORRECT replaces handcrafted text prompts with learnable continuous embeddings; understanding the difference between discrete natural language prompts and continuous prompt vectors explains why this mechanism avoids prompt engineering brittleness.
  - Quick check question: What is the key difference between prompting an LLM with "Is this claim true or false?" versus prepending learned embedding vectors to the input representation?

- **Transformer architecture with [CLS] tokens and virtual tokens:**
  - Why needed here: The model uses [CLS] token representations as sentence/document embeddings and introduces virtual tokens for graph-aggregated signals; understanding how attention operates over augmented sequences is necessary for implementing the asymmetric MSA mechanism.
  - Quick check question: When virtual tokens are added to a Transformer input, how does the self-attention mechanism allow original tokens to incorporate information from these virtual tokens?

## Architecture Onboarding

- **Component map:**
  1. **Evidence Encoder (Transformer-based, 12 steps, d=768):** Processes evidence sentences, contextual documents, and referential documents separately
  2. **Three-Layer Graph Module:** Evidence layer (fully connected), Context layer (linked to evidence), Reference layer (linked to evidence via citations)
  3. **GNN Aggregation:** Type-specific attention with parameters W1/b1 (intra-evidence), W2/b2 (cross-reference)
  4. **Asymmetric MSA Layer:** Virtual token concatenation + query-only Transformer step (Eq. 7)
  5. **Evidence-Conditioned Prompt Encoder:** Projects hE → α, β → combines with base prompts
  6. **Claim Encoder (shared with Evidence Encoder):** Processes [claim tokens + prompt embeddings]
  7. **Contrastive Loss Module:** Aligns claim embeddings with evidence embeddings per label

- **Critical path:**
  Evidence Retrieval → Three-Layer Graph Construction → Per-Document Transformer Encoding (steps 1-L) → At each step: GNN Aggregation → Virtual Token Concatenation → Asymmetric MSA → Final Evidence Embedding hE (mean-pooled [CLS]) → Prompt Encoder generates πm,y for each label y → Claim + Prompts → Claim Encoder → Claim Embeddings hx,y → Contrastive Loss (Eq. 13)

- **Design tradeoffs:**
  - **Three layers vs. unified graph:** Separate layers preserve document type semantics but increase implementation complexity; ablation shows all three contribute (Fig. 4a)
  - **M=8 prompt embeddings:** Balances representation capacity vs. overfitting risk; M=2 too low, M=16 overfits (Fig. 4b)
  - **Shared encoder for evidence and claims:** Reduces parameters but may conflate document and claim representation learning
  - **BM25 for retrieval vs. neural retrieval:** Simpler but may retrieve noisy evidence; retrieved evidence setting scores ~13-23 points lower than gold evidence (Table 3)

- **Failure signatures:**
  - **Context/reference not available:** Model degrades to evidence-only reasoning; ensure dataset provides identifiers (PubMed ID, CORD ID, S2ORC ID) or contextual documents
  - **Random prompt initialization:** Optimization unstable; verify initialization uses label-grouped mean-pooled word embeddings (Page 5 algorithm)
  - **Retrieved evidence quality poor:** Macro F1 drops significantly (e.g., BearFact: 59.88 → 44.25); consider better retrieval or evidence filtering
  - **Insufficient Transformer depth:** Graph signals may not propagate; use L≥12 per implementation details

- **First 3 experiments:**
  1. **Reproduce ablation study (Fig. 4a):** Train CORRECT with one layer removed at a time on Check-COVID or FEVEROUS-S; verify that all three layers contribute and that removing evidence layer causes largest degradation
  2. **Prompt initialization comparison:** Compare label-grouped initialization vs. random initialization on SciFact 5-shot setting; expect ~2-5 Macro F1 difference per Fig. 4c
  3. **Gold vs. retrieved evidence gap analysis:** Run inference with gold evidence and BM25-retrieved evidence on the same test claims; analyze which claim types (acronym-heavy, coreference-dependent) show largest performance gaps to identify retrieval failure modes

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the three-layer evidence graph architecture be effectively extended to incorporate multi-modal evidence, such as tables or images, for fact-checking?
  - Basis in paper: [explicit] The Conclusion explicitly states, "A future work is to extend three-layer graph to a multi-modal graph for fact-checking," and the Limitations section notes the model currently cannot reason over tabular evidence.
  - Why unresolved: The current model is designed exclusively for textual reasoning, and it is unclear how cross-layer reasoning mechanisms would function with non-textual data nodes.
  - What evidence would resolve it: A study applying the model to datasets containing tabular or visual evidence (e.g., the full FEVEROUS dataset), demonstrating how heterogeneous data types are integrated into the unified evidence embedding.

- **Open Question 2:** To what extent does performance degrade when the corpus lacks explicit identifiers (e.g., PubMed IDs) or hyperlinks for retrieving referential documents?
  - Basis in paper: [inferred] The Limitations section acknowledges the model assumes contextual/referential documents are available or identifiable via specific IDs. Real-world claims often lack such structured metadata.
  - Why unresolved: The experiments utilize datasets with established citation networks (S2ORC) or hyperlinks, potentially setting an upper bound on performance that may not hold for general web claims.
  - What evidence would resolve it: Experiments on a domain where referential documents must be retrieved purely via semantic search (without IDs), compared against the current gold-standard retrieval performance.

- **Open Question 3:** How robust is the cross-layer reasoning mechanism when retrieved referential documents contain irrelevant or adversarial noise?
  - Basis in paper: [inferred] The paper demonstrates that removing the reference layer hurts performance, implying the references are useful. However, it does not analyze how the attention mechanism handles low-quality or misleading references.
  - Why unresolved: The attention mechanism aggregates references, but without testing against noisy data, it is uncertain if the model can effectively filter out unhelpful context.
  - What evidence would resolve it: An ablation study where varying levels of random or adversarial text are injected into the reference layer to measure the stability of the verdict prediction.

- **Open Question 4:** What are the computational trade-offs regarding training and inference latency introduced by the nested graph-augmented Transformer architecture?
  - Basis in paper: [inferred] The Methodology describes a complex architecture involving L Transformer steps and graph neural networks for every claim, but the paper focuses solely on effectiveness (F1 scores) rather than efficiency.
  - Why unresolved: The "nested" nature of the encoding suggests significant computational overhead compared to single-pass models, which is critical for real-time applications.
  - What evidence would resolve it: A comparative analysis of wall-clock time and memory consumption between CORRECT and baseline models like MultiVerS or Transformer-XH.

## Limitations

- **Critical Dependencies:** The method relies heavily on availability of contextual and referential documents through identifiers like PubMed IDs and CORD IDs. Without these, the three-layer graph cannot be constructed and performance degrades significantly to evidence-only reasoning.
- **Implementation Complexity:** The nested architecture with intra-layer, cross-layer, and asymmetric MSA operations introduces significant complexity. The asymmetric attention mechanism (Keys/Values include virtual tokens, Queries exclude them) is particularly subtle and may be prone to implementation errors.
- **Evaluation Scope:** The method is validated only on single-sentence evidence claims with well-structured citation networks. It remains unclear how the approach would perform on multi-sentence claims, claims with implicit evidence, or domains with sparse citation networks.

## Confidence

- **High Confidence:** The effectiveness of the three-layer evidence graph structure and the importance of contextual/referential documents (ablation shows all three layers contribute meaningfully; removing any layer degrades performance). The overall training procedure and contrastive loss formulation.
- **Medium Confidence:** The asymmetric multi-head self-attention mechanism's specific implementation details (Query/Key/Value separation with virtual tokens). The exact impact of different prompt embedding counts (M=2 vs M=8 vs M=16) on generalization.
- **Low Confidence:** The initialization method's superiority over random initialization (only shown on SciFact 5-shot, no broader validation). The specific hyperparameters (L=12, d=768, τ=100) and their sensitivity to dataset characteristics.

## Next Checks

1. **Robustness to Document Availability:** Run the model on datasets where contextual/referential documents are artificially removed (setting retrieval success rate to 0%). Measure the performance gap to identify how much the method degrades without the three-layer structure. This will reveal whether the method can gracefully degrade to evidence-only reasoning.

2. **Cross-Domain Generalization:** Test the model on a dataset from a domain with different citation patterns (e.g., news articles with hyperlinks instead of academic citations). This will validate whether the three-layer structure and prompt initialization generalize beyond biomedical and Wikipedia domains.

3. **Hyperparameter Sensitivity Analysis:** Systematically vary L (Transformer steps), M (prompt embeddings), and τ (temperature) on the scientific datasets. This will determine whether the reported values are optimal or if the method is sensitive to these choices, affecting reproducibility and practical deployment.