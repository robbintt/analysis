---
ver: rpa2
title: Detecting Multiple Diseases in Multiple Crops Using Deep Learning
arxiv_id: '2507.02517'
source_url: https://arxiv.org/abs/2507.02517
tags:
- diseases
- disease
- leaf
- tomato
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting multiple diseases
  across multiple crops in India's agriculture sector using deep learning. The authors
  created a unified dataset with 93,136 images covering 17 crops and 34 diseases from
  various online repositories.
---

# Detecting Multiple Diseases in Multiple Crops Using Deep Learning

## Quick Facts
- arXiv ID: 2507.02517
- Source URL: https://arxiv.org/abs/2507.02517
- Authors: Vivek Yadav; Anugrah Jain
- Reference count: 40
- One-line primary result: Proposed ResNet9 model achieves 99.03% accuracy on 51-class multi-crop disease detection dataset.

## Executive Summary
This paper addresses the challenge of detecting multiple diseases across multiple crops in India's agriculture sector using deep learning. The authors created a unified dataset with 93,136 images covering 17 crops and 34 diseases from various online repositories. They proposed a deep learning model based on ResNet9 architecture, which uses residual blocks with skip connections to efficiently extract features and classify diseases. The model was trained on the unified dataset and achieved a detection accuracy of 99.03%, outperforming existing state-of-the-art methods that handle fewer crops and diseases. This approach provides a scalable solution for Indian farmers to detect crop diseases early and improve yield.

## Method Summary
The method involves creating a unified dataset of 93,136 images from 17 crops and 34 diseases sourced from online repositories, then training a ResNet9 architecture on this data. The model uses residual blocks with skip connections to efficiently learn disease features while maintaining computational efficiency for deployment on mobile/edge devices. Training was conducted for 5 epochs using Adam optimizer with learning rate 0.001, weight decay 0.0001, and cosine annealing scheduler on Google Colab T4 TPU.

## Key Results
- ResNet9 model achieves 99.03% overall classification accuracy
- Outperforms state-of-the-art methods handling fewer crops and diseases
- Successfully detects 51 classes (17 crops Ã— 34 diseases + healthy variants)
- Model is computationally efficient for deployment on mobile/edge devices

## Why This Works (Mechanism)

### Mechanism 1
A unified, multi-source dataset enables a single model to generalize across diverse crops and diseases. By consolidating 93,136 images from various repositories, the model is exposed to wider visual feature distributions, lighting conditions, and disease stages, forcing convolutional layers to learn robust feature representations that are common across different plants rather than overfitting to single-source characteristics.

### Mechanism 2
ResNet9 architecture provides efficient balance of depth and feature-reuse through residual blocks with skip connections. These connections allow the network to learn residual mappings (differences between input and desired output) rather than direct mappings, mitigating vanishing gradient problems and accelerating training convergence while maintaining computational efficiency suitable for mobile deployment.

### Mechanism 3
Extremely short training cycle (5 epochs) combined with strong regularization prevents overfitting on large dataset. The low learning rate (0.001), weight decay (0.0001), and cosine annealing scheduler, combined with early stopping at 5 epochs, acts as dataset-level regularization given the 93k image size, suggesting rapid convergence capability.

## Foundational Learning

- **Convolutional Neural Networks (CNNs) for Image Feature Extraction**
  - Why needed here: The entire model is a CNN. Understanding how convolutional layers use learnable filters to scan images and activate on features like edges, textures, and colors is fundamental.
  - Quick check question: If you input a 256x256 RGB image into a convolutional layer with a 3x3 kernel, what is the primary operation being performed at each step?

- **The Vanishing Gradient Problem and Skip Connections**
  - Why needed here: The core justification for using ResNet architecture is solving the vanishing gradient problem that makes deep networks hard to train.
  - Quick check question: In a very deep network, what happens to the error signal (gradient) as it is backpropagated to earlier layers, and how does a "skip connection" help preserve this signal?

- **Classification Metrics for Imbalanced Datasets (F1-Score)**
  - Why needed here: The paper reports high accuracy (99.03%), but the dataset is imbalanced with some classes having very few images. Accuracy can be misleading; F1-score is more reliable.
  - Quick check question: Why can a model achieve 99% accuracy on a dataset where 99% of images belong to a single class, and how does the F1-score address this issue?

## Architecture Onboarding

- **Component map**: Image Input (3x256x256) -> Conv Layers -> Residual Blocks -> Max Pool -> Flatten -> FC Layer -> Softmax -> Class Probabilities (51)
- **Critical path**: `Image Input (3x256x256) -> Conv Layers -> Residual Blocks -> Max Pool -> Flatten -> FC Layer -> Softmax -> Class Probabilities (51)`
- **Design tradeoffs**:
  - Breadth vs. Depth (Dataset): Maximizing dataset breadth (17 crops, 34 diseases) creates highly imbalanced dataset, leading to catastrophic failures on low-data classes
  - Efficiency vs. Power (Model): Selecting ResNet9 over ResNet50/101 prioritizes inference speed and lower computational cost for mobile deployment, reducing representational capacity
  - Training Speed vs. Optimality (Training): Limiting training to 5 epochs is extreme regularization for speed, risking undertraining on complex patterns

- **Failure signatures**: Catastrophic class failure with Wheat-Healthy F1-score of 0.129 and Wheat-Septoria F1-score of 0.6538, indicating extreme data imbalance or poor data quality for Wheat subset

- **First 3 experiments**:
  1. Targeted Data Augmentation for Wheat: Rebalance dataset by upsampling Wheat images or applying heavy augmentation to underperforming classes
  2. Training Duration Ablation: Run training for 10, 15, and 25 epochs while plotting training vs. validation loss to determine if 5-epoch limit prevented optimal performance
  3. Edge Device Latency Benchmark: Measure inference time and memory footprint on mid-range smartphone or Raspberry Pi to validate efficiency claims

## Open Questions the Paper Calls Out

- **Open Question 1**: To what extent does the inclusion of rice crops and the application of new deep learning architectures improve upon the current model's classification capabilities? The conclusion states future work will extend the dataset to include rice and perform better classification with proposed or new deep learning models.

- **Open Question 2**: Can specific data augmentation or resampling strategies mitigate the poor classification performance observed in minority classes like Wheat? Table 2 shows Wheat has significantly fewer images than other crops, with Table 4 reporting correspondingly low metrics (e.g., Wheat-Healthy F1-score of 0.129).

- **Open Question 3**: How robust is the proposed detection method when applied to uncurated images captured in real-world Indian field conditions, as opposed to the online repository data used for training? The paper aims to cover India's landscape using datasets merged from various online repositories yet claims to provide a solution for scalable field detection.

## Limitations
- Extreme class imbalance with catastrophic failure on minority classes like Wheat-Healthy (F1-score 0.129) despite 99.03% overall accuracy
- Unusually short 5-epoch training duration raises questions about whether model is truly optimized or has memorized dominant patterns
- Limited validation on real-world field conditions versus curated online repository data
- No direct performance comparisons with specific benchmark papers in the literature

## Confidence
- **High Confidence**: ResNet9 architecture with residual connections is technically sound and reported 99.03% accuracy is reproducible with specified implementation
- **Medium Confidence**: Claim of outperforming state-of-the-art methods is based on comparison to methods handling fewer crops/diseases, but direct performance comparisons are not provided
- **Low Confidence**: Practical utility for Indian farmers is overstated given catastrophic failure on critical classes like Wheat-Healthy essential for real-world deployment

## Next Checks
1. **Wheat Class Performance Audit**: Create balanced subset containing only Wheat images and evaluate model's ability to distinguish healthy vs. diseased to reveal if 99% accuracy masks complete failure on important crops

2. **Extended Training Analysis**: Retrain model for 15-25 epochs while monitoring validation loss curves to determine if 5-epoch limit prevented convergence to optimal weights, particularly for rare classes

3. **Cross-Dataset Generalization Test**: Evaluate trained model on independent Indian agriculture dataset or held-out images from different lighting/conditions to assess real-world robustness beyond curated training data