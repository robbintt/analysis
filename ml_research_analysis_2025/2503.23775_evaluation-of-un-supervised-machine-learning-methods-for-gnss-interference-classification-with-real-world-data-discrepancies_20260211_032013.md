---
ver: rpa2
title: Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference
  Classification with Real-World Data Discrepancies
arxiv_id: '2503.23775'
source_url: https://arxiv.org/abs/2503.23775
tags:
- data
- gnss
- dataset
- interference
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of classifying GNSS interference
  signals in real-world scenarios, where data discrepancies arise from variations
  in jammers, recording environments, and sensor characteristics. The authors propose
  a comprehensive evaluation of supervised and unsupervised machine learning methods,
  including cross-validation across multiple datasets, outlier detection, domain adaptation,
  and pseudo-labeling techniques.
---

# Evaluation of (Un-)Supervised Machine Learning Methods for GNSS Interference Classification with Real-World Data Discrepancies

## Quick Facts
- **arXiv ID**: 2503.23775
- **Source URL**: https://arxiv.org/abs/2503.23775
- **Reference count**: 13
- **Primary result**: Large ResNet18 model achieves 99.9% accuracy on real-world highway data but drops significantly on controlled indoor datasets; domain adaptation methods achieve up to 90% accuracy in bridging environment gaps.

## Executive Summary
This paper addresses the challenge of classifying GNSS interference signals across datasets with significant environmental and sensor variations. The authors evaluate supervised and unsupervised machine learning methods, including cross-validation across multiple datasets, outlier detection, domain adaptation, and pseudo-labeling techniques. Their experiments reveal that while deep neural networks perform exceptionally well within homogeneous datasets, performance degrades substantially when transferring models between controlled and real-world environments due to data discrepancies. The study demonstrates that domain adaptation methods like DANN and Deep CORAL can bridge this gap, while pseudo-labeling significantly reduces the need for labeled data. The research provides practical insights for deploying GNSS interference detection systems in real-world conditions.

## Method Summary
The paper evaluates machine learning methods for GNSS interference classification using publicly available datasets containing spectrograms and time-series data from high-frequency snapshots and low-cost sensors. The primary model is a ResNet18 architecture trained with SGD optimizer (LR=0.01, momentum=0.9, batch size=64) for 200 epochs. Data augmentation includes random flips, noise injection, intensity scaling, and zooming. Domain adaptation techniques (DANN, Deep CORAL) are applied to align feature distributions between controlled and real-world datasets. Pseudo-labeling uses ensemble voting with four ResNet18 models to generate labels for unlabeled data, reducing labeled data requirements. Outlier detection methods like Isolation Forest identify interference anomalies. The evaluation spans multiple datasets with different recording conditions to assess cross-domain generalization.

## Key Results
- Large ResNet18 model achieves 99.9% accuracy on real-world highway dataset 1 but drops significantly on controlled indoor datasets due to data shift
- Pseudo-labeling reduces labeled data requirements by up to 30% while maintaining classification accuracy through ensemble consensus voting
- Domain adaptation methods (DANN and Deep CORAL) achieve up to 90% accuracy in bridging controlled and real-world environments
- Isolation Forest performs well on real-world data for outlier detection, though accuracy drops to 50-70% in multipath-heavy environments
- Data augmentation improves model robustness across different datasets and recording conditions

## Why This Works (Mechanism)

### Mechanism 1
Domain adaptation methods can bridge the distribution gap between controlled indoor environments and real-world highway datasets for GNSS interference classification. Methods like DANN (Domain-Adversarial Neural Network) and Deep CORAL minimize discrepancy between source and target domain feature embeddings by aligning first-order (MMD) or second-order (CORAL) statistics, encouraging representations that are discriminative for classification but invariant to domain shifts. The core assumption is that source domain (controlled) and target domain (real-world) share relevant interference features despite different recording conditions (antenna, sampling rate, multipath effects). Evidence shows domain adaptation methods like DANN and Deep CORAL achieve up to 90% accuracy in bridging controlled and real-world environments. The method breaks when domain shift is too severe, such as when novel interference types not present in source data appear in the target environment.

### Mechanism 2
Pseudo-labeling with ensemble voting can reduce labeled data requirements by approximately 30% while maintaining classification accuracy. Multiple ResNet18 models trained on a small labeled subset generate predictions on unlabeled data; when models reach consensus (softmax threshold ≥0.9), pseudo-labels are assigned and appended to the training set for retraining. Consensus filtering reduces error propagation from incorrect pseudo-labels. The core assumption is that unlabeled data follows similar distribution to labeled data, and model consensus correlates with prediction correctness. Evidence shows pseudo-labeling reduces the need for labeled data by up to 30%, with accuracy only marginally increasing with more labeled data when consensus is high. The method breaks when consensus threshold is too low, allowing incorrect pseudo-labels to propagate and degrade model performance, or when datasets are highly imbalanced and models bias toward majority class predictions.

### Mechanism 3
Isolation Forest and similar outlier detection methods effectively identify GNSS interference anomalies in low-cost sensor data streams. Isolation Forest constructs random trees to isolate anomalies; interference signals require fewer splits to isolate than normal GNSS signals due to their distinct spectral and temporal patterns (e.g., chirp signatures, noise anomalies). The core assumption is that interference samples are "few and different" from normal GNSS signal distributions. Evidence shows outlier detection methods such as Isolation Forest perform well on real-world data, achieving high accuracy on controlled and real-world highway datasets. The method breaks when multipath effects in challenging environments (e.g., Seetal Alps) create interference-like patterns in normal data, reducing accuracy to 50-70%.

## Foundational Learning

- **Domain Adaptation & Distribution Shift**
  - Why needed here: The central challenge is that models trained on controlled indoor data fail on real-world highway data due to distributional differences in antenna characteristics, multipath effects, and environmental factors.
  - Quick check question: Can you explain why maximum mean discrepancy (MMD) alignment differs from second-order CORAL alignment for time-series domain adaptation?

- **Semi-Supervised Learning & Pseudo-labeling**
  - Why needed here: Labeling GNSS interference data is expensive and legally restricted; pseudo-labeling leverages abundant unlabeled highway data.
  - Quick check question: What is the risk of "confirmation bias" in self-training pseudo-labeling, and how does ensemble voting mitigate it?

- **GNSS Signal Representations (Spectrograms & Time-Series)**
  - Why needed here: The paper converts raw IQ snapshots to spectrograms (frequency-domain images) and processes low-cost sensor time-series; understanding these representations is essential for model design.
  - Quick check question: Why might a chirp interference appear differently in spectrogram form versus raw IQ time-series, and how does this affect CNN vs. RNN model selection?

## Architecture Onboarding

- **Component map:**
  Input (GNSS snapshots/spectrograms or low-cost time-series) -> ResNet18 backbone -> Softmax classifier -> (Optional: Domain adaptation module) -> Pseudo-labeling ensemble

- **Critical path:**
  1. Start with controlled indoor data for baseline training
  2. Apply domain adaptation (Deep CORAL or DANN) before real-world deployment
  3. Use pseudo-labeling iteratively (7-10 repeats) when labeled target data is scarce
  4. Validate with few-shot target risk (5-10 labeled samples) for hyperparameter selection

- **Design tradeoffs:**
  Large ResNet18 vs. smaller models: Large models (11M params) outperform FCN/MLP significantly on complex data, but may overfit on small datasets. High vs. low softmax threshold: 0.9 threshold yields fewer but more accurate pseudo-labels; 0.5 includes more data but introduces noise. Domain adaptation vs. data augmentation: DA methods (DANN, CORAL) more effective for controlled→real transfer; augmentation helps cross-dataset generalization.

- **Failure signatures:**
  Training on indoor data, testing on highway: Accuracy drops to near-random (<20%) without DA. Multipath-heavy environments (Seetal Alps): Outlier detection degrades to 50-70%. Imbalanced highway dataset: F2-score significantly lower than accuracy (model predicts majority "no interference" class).

- **First 3 experiments:**
  1. Baseline cross-validation: Train ResNet18 on each dataset individually, test on all others to quantify domain gap magnitudes
  2. Domain adaptation comparison: Apply Deep CORAL, DANN, and MMD from controlled large-scale dataset to real-world highway dataset 1; measure accuracy improvement
  3. Pseudo-labeling sweep: Test ensemble voting with 10%, 30%, 50% labeled data at thresholds 0.5, 0.8, 0.9; track convergence iterations and final accuracy

## Open Questions the Paper Calls Out

- Can an uncertainty-based voting mechanism improve pseudo-label selection accuracy compared to the current probability-threshold voting?
- Can disentanglement techniques extract GNSS-specific features to facilitate the generation of arbitrary amounts of training data?
- How effective are diffusion models for unsupervised data augmentation and interference mitigation in GNSS signals?

## Limitations

- Domain adaptation generalization may fail on entirely novel interference types or extreme environmental conditions not present in training data
- Pseudo-labeling reliability depends on high consensus accuracy and may degrade with incorrect pseudo-labels over time
- Outlier detection accuracy drops significantly in multipath-heavy environments like the Seetal Alps, limiting real-world applicability

## Confidence

- **High Confidence**: Baseline ResNet18 performance metrics, controlled dataset results, and the fundamental observation that domain adaptation improves cross-dataset generalization
- **Medium Confidence**: Domain adaptation effectiveness claims (DANN/CORAL achieving 90% accuracy), pseudo-labeling data reduction estimates (30%), and outlier detection performance on real-world highway data
- **Low Confidence**: Extrapolation of results to novel interference types not present in training data, performance in extreme multipath environments, and the scalability of pseudo-labeling approaches to highly imbalanced datasets

## Next Checks

1. **Novel Interference Type Test**: Validate domain adaptation and pseudo-labeling methods on a held-out dataset containing interference types never seen during training to assess true generalization capability
2. **Ensemble Outlier Detection**: Implement and evaluate hybrid outlier detection approaches combining Isolation Forest, ABOD, and COPOD specifically for multipath-heavy environments to improve the 50-70% accuracy floor
3. **Long-term Pseudo-labeling Stability**: Conduct multi-epoch pseudo-labeling experiments tracking model performance over time to quantify the impact of potential error propagation from incorrect pseudo-labels