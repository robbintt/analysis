---
ver: rpa2
title: 'Two Heads are Better than One: Distilling Large Language Model Features Into
  Small Models with Feature Decomposition and Mixture'
arxiv_id: '2511.07110'
source_url: https://arxiv.org/abs/2511.07110
tags:
- feature
- market
- features
- different
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of slow inference speeds when
  applying large language models (LLMs) to market-making tasks in financial trading.
  The authors propose Cooperative Market Making (CMM), a novel framework that decomposes
  complex LLM features into simpler components across three orthogonal dimensions:
  layer, task, and data type/market regime.'
---

# Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture

## Quick Facts
- arXiv ID: 2511.07110
- Source URL: https://arxiv.org/abs/2511.07110
- Authors: Tianhao Fu; Xinxin Xu; Weichen Xu; Jue Chen; Ruilong Ren; Bowen Deng; Xinyu Zhao; Jian Cao; Xixin Cao
- Reference count: 18
- Primary result: 6.3× lower latency (0.3s vs 1.9s) while achieving higher profitability metrics including 31.39×10³ EPnL versus 30.47×10³ for the LLM baseline

## Executive Summary
This paper addresses slow inference speeds when applying large language models (LLMs) to market-making tasks by introducing Cooperative Market Making (CMM). The framework decomposes complex LLM features into simpler components across three orthogonal dimensions: layer, task, and data type/market regime. Each specialized component is learned by dedicated lightweight models, which are then integrated using a novel Hájek-MoE mechanism that quantifies each model's contribution through projection-based confidence scores.

The approach was evaluated on four real-world market datasets, demonstrating superior performance compared to existing distillation methods and RL-based market-making strategies. The framework achieves significant latency reduction while maintaining or improving profitability metrics, making it practical for real-time financial trading applications.

## Method Summary
CMM employs a three-step approach: First, a normalized fluorescent probe analyzes the LLM's internal mechanisms to identify layer-wise feature specializations. Second, Orthogonal Feature Decomposition Distillation (OFDD) decomposes the LLM's features across three dimensions - layer, task, and data type/market regime - training specialized small models for each component. Third, a Hájek-MoE integrates these models using a kernel function-generated common feature space to quantify each model's contribution through projection-based confidence scores, enabling adaptive ensemble fusion.

## Key Results
- 6.3× lower latency (0.3s vs 1.9s) compared to baseline LLM
- Higher profitability metrics (31.39×10³ EPnL vs 30.47×10³ EPnL)
- Superior performance compared to existing distillation methods and RL-based market-making strategies
- Effective decomposition across layer, task, and data dimensions
- Robust performance across four real-world market datasets

## Why This Works (Mechanism)

### Mechanism 1: Normalized Fluorescent Probe for Mechanistic Analysis
Noise-perturbation analysis identifies which LLM modules influence specific outputs, revealing layer-task specializations. Inject normalized noise into module parameters, measure output perturbation, and compute attribution scores across modules. The Causal Attribution Map identifies the most influential module per output.

### Mechanism 2: Orthogonal Feature Decomposition Distillation (OFDD)
Decomposing complex LLM features along three orthogonal dimensions (layer, task, data/market regime) enables small models to capture simplified features that collectively approximate the full feature space. Three parallel decompositions: layer (shallow→mid-price, middle→spread, deep→volume), task (separate prediction heads), and data (volatility-banded training).

### Mechanism 3: Hájek Projection-Based Mixture-of-Experts (Hájek-MoE)
A kernel-based projection mechanism quantifies each expert's contribution by measuring alignment with the consensus vector, enabling adaptive ensemble fusion. Map each expert's output to 2D space via kernel function, compute consensus vector as mean projection, and calculate confidence scores based on scalar projection.

## Foundational Learning

**Mechanistic Interpretability via Perturbation**
- Why needed here: Understanding the probe requires grasping how noise injection reveals functional module specialization
- Quick check question: Can you explain why averaging across Gaussian and uniform noise distributions improves attribution robustness?

**Feature Space Orthogonality**
- Why needed here: OFDD assumes layer, task, and data dimensions can be decoupled; understanding orthogonality clarifies when decomposition is valid
- Quick check question: What would happen to expert specialization if two decomposition dimensions were highly correlated?

**Kernel-Based Projection for Ensemble Weighting**
- Why needed here: Hájek-MoE uses kernel projection to compute expert confidence; understanding this enables debugging and extension
- Quick check question: How does the scalar projection C_i differ from standard softmax-based gating in traditional MoE?

## Architecture Onboarding

**Component map:**
Teacher LLM (LLaMA-3.1) -> Normalized Fluorescent Probe -> OFDD Module -> Hájek-MoE -> Inference Pipeline

**Critical path:**
1. Run probe on teacher LLM to identify layer-task specializations
2. Partition training data by volatility bands (low/medium/high)
3. Train specialized small models on each (layer, volatility) combination
4. Train Hájek kernel on validation data to learn meaningful projections
5. Deploy ensemble with real-time confidence computation

**Design tradeoffs:**
- Expert granularity: More decomposition → simpler features per expert but more models to train/coordinate
- Kernel complexity: Deeper kernel may capture richer alignment but increases inference latency
- Volatility banding: Fewer bands simplifies training; more bands enables finer regime adaptation

**Failure signatures:**
- Experts cluster chaotically in PCA visualization (orthogonal decomposition failed)
- Confidence scores flat/uniform across experts (kernel projection uninformative)
- Performance degrades sharply under volatility regime shifts (experts overfit training bands)
- Inference latency exceeds 0.5s (ensemble overhead too high for real-time trading)

**First 3 experiments:**
1. Probe validation: Run normalized fluorescent probe on different LLM architecture to verify layer-task specialization patterns generalize
2. Ablation on decomposition dimensions: Train variants with only layer, only task, only data decomposition; measure performance gap vs full OFDD
3. Kernel function sensitivity: Replace 2-layer MLP kernel with linear projection, RBF kernel, attention-based gating; compare confidence score distributions and final PnL

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the observed layer-wise feature specialization (shallow layers for mid-price, middle for spread, deep for volume) generalize to LLM architectures other than LLaMA 3.1?
- Basis in paper: The methodology relies on the "Normalized Fluorescent Probe" revealing specific functional roles for layers in LLaMA 3.1, but it does not validate if this spatial decomposition is universal or model-specific
- Why unresolved: Architectural differences in attention mechanisms or embedding spaces in other models (e.g., GPT, Gemini) might distribute financial feature logic differently across depths
- What evidence would resolve it: Applying the proposed probe to diverse LLM backbones to verify if the depth-task correlation remains consistent

### Open Question 2
- Question: Is the 2-dimensional kernel space used in Hájek-MoE sufficient to capture complex expert interactions without information loss?
- Basis in paper: The method maps expert features into a 2D vector space to compute the consensus vector, but the paper does not ablate the dimensionality of this projection
- Why unresolved: Reducing high-dimensional feature spaces to 2 dimensions risks collapsing distinct expert contributions into indistinguishable vectors, potentially oversimplifying the gating mechanism
- What evidence would resolve it: An ablation study varying the kernel output dimensionality to measure the impact on alignment scores and final PnL

### Open Question 3
- Question: Can the volatility-based data decomposition effectively handle market regimes with structural breaks different from the training period (2021-2022)?
- Basis in paper: The data decomposition relies on categorizing input by historical 5-day volatility bands, assuming stable statistical properties
- Why unresolved: Financial markets often undergo "regime shifts" where historical volatility metrics fail to capture sudden liquidity crises or structural changes
- What evidence would resolve it: Testing the model on out-of-sample data containing "black swan" events or structural regime changes to see if the static volatility bands fail

## Limitations

**Probe reliability across architectures**: The normalized fluorescent probe relies on consistent layer-task attribution across noise types but lacks validation across different LLM architectures or market domains.

**Orthogonality assumption validity**: The OFDD framework assumes layer, task, and data dimensions are sufficiently orthogonal, but the paper doesn't provide quantitative measures demonstrating low inter-dimensional coupling.

**Kernel projection robustness**: Hájek-MoE's confidence scores depend on the kernel function preserving discriminative information in 2D projection, but the paper doesn't explore kernel sensitivity or provide ablation studies.

## Confidence

**High confidence**: Execution speed improvements (0.3s vs 1.9s) and baseline profitability comparison (31.39×10³ vs 30.47×10³ EPnL), as these are direct empirical measurements.

**Medium confidence**: The orthogonal decomposition framework's general validity, as the probe methodology is sound but lacks cross-architecture validation.

**Low confidence**: Long-term stability under market regime changes and robustness to model architecture variations, as the paper doesn't include stress tests across multiple market conditions or LLM architectures.

## Next Checks

1. **Probe transferability validation**: Apply the normalized fluorescent probe to at least two different LLM architectures (e.g., GPT-class and Mistral) on the same market dataset. Measure consistency in layer-task specialization patterns and test whether CMM's decomposition strategy remains optimal.

2. **Orthogonality correlation analysis**: Compute pairwise correlation coefficients between layer activations, task predictions, and volatility band features across the training dataset. Quantify the degree of inter-dimensional coupling and test whether CMM performance degrades as correlation increases.

3. **Regime shift stress testing**: Create synthetic market conditions with sudden volatility regime changes and measure CMM's adaptation speed. Compare expert confidence score dynamics and final PnL before/after regime shifts against both the baseline LLM and traditional MoE methods.