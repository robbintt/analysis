---
ver: rpa2
title: Geometric Deep Learning for Automated Landmarking of Maxillary Arches on 3D
  Oral Scans from Newborns with Cleft Lip and Palate
arxiv_id: '2501.15737'
source_url: https://arxiv.org/abs/2501.15737
tags:
- landmarks
- point
- such
- learning
- cleft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The study developed a geometric deep learning pipeline to automate\
  \ landmarking of maxillary arches in 3D oral scans of newborns with cleft lip and\
  \ palate. The method uses a multi-view consensus CNN approach trained on 90 manually\
  \ annotated 3D models and tested on 10 unseen cases, achieving 94.44% accuracy with\
  \ a mean absolute error of 1.676 \xB1 0.959 mm."
---

# Geometric Deep Learning for Automated Landmarking of Maxillary Arches on 3D Oral Scans from Newborns with Cleft Lip and Palate

## Quick Facts
- **arXiv ID**: 2501.15737
- **Source URL**: https://arxiv.org/abs/2501.15737
- **Reference count**: 0
- **Primary result**: 94.44% accuracy with 1.676 ± 0.959 mm MAE on 16 anatomical landmarks in UCLP newborn 3D oral scans

## Executive Summary
This study presents a geometric deep learning pipeline that automates landmarking of maxillary arches in 3D oral scans of newborns with unilateral cleft lip and palate (UCLP). The approach uses a multi-view consensus CNN architecture that renders 3D meshes into 2D projections, predicts landmark positions as heatmaps, and triangulates 3D coordinates via ray consensus. Trained on 90 manually annotated models and tested on 10 unseen cases, the method achieves clinically acceptable accuracy while reducing manual landmarking time from ~45 minutes to under 6 minutes per batch. The pipeline shows particular promise for reducing clinician workload in UCLP diagnosis and treatment planning.

## Method Summary
The pipeline processes 3D STL mesh models of maxillary arches by rendering them into multiple 2D views from different camera angles. A two-stack hourglass neural network with residual blocks predicts 16 heatmaps per view, one for each anatomical landmark. The 2D landmark predictions are converted to 3D rays and combined via consensus triangulation to produce final 3D coordinates. The model was trained on 90 equally balanced pre- and post-UCLP treatment scans, validated on 10 unseen cases, and evaluated using mean absolute error (MAE) and accuracy thresholds. The approach leverages 2D CNN architectures rather than native 3D geometric deep learning, making it computationally efficient while maintaining accuracy.

## Key Results
- Achieved 94.44% accuracy with 1.676 ± 0.959 mm mean absolute error on 16 anatomical landmarks
- Reduced manual landmarking time from ~45 minutes to under 6 minutes for a batch of 10 models
- Demonstrated consistent performance across pre- and post-treatment scan variations
- Maintained clinically acceptable precision for UCLP treatment planning applications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Multi-view consensus enables 3D landmark estimation without native 3D convolution architectures
- **Mechanism**: Each 3D mesh is rendered into multiple 2D views; the CNN predicts landmark positions per view as "rays"; ray intersection consensus triangulates the final 3D coordinate
- **Core assumption**: The number and angular distribution of 2D views provide sufficient geometric coverage for accurate triangulation
- **Evidence anchors**: Multi-view consensus CNN approach trained on 90 manually annotated 3D models; 3D mesh split into multiple views with ray-based triangulation
- **Break condition**: If view angles are sparse or occluded, ray consensus may converge to incorrect 3D positions, especially for landmarks on smooth surfaces

### Mechanism 2
- **Claim**: Stacked hourglass networks with residual blocks learn spatial landmark representations via heatmap regression
- **Mechanism**: Input images pass through residual blocks (3×3 convolutions + batch normalization), followed by downsampling, intermediate refinement, and upsampling to produce 16 heatmaps—one per landmark
- **Core assumption**: Heatmap peaks provide a differentiable, spatially robust signal for landmark localization compared to direct coordinate regression
- **Evidence anchors**: Achieving 94.44% accuracy with 1.676 ± 0.959 mm MAE; network produces 16 heatmaps with initial feature extraction, down sampling, intermediate refinement, and final up sampling
- **Break condition**: If landmarks lie in regions with low textural distinctiveness, heatmap peaks may be ambiguous or diffuse

### Mechanism 3
- **Claim**: Training on balanced pre-/post-treatment scans enables generalization from limited data by exposing the model to morphological variation
- **Mechanism**: The 90-model training set is equally split between pre- and post-UCLP treatment scans, ensuring the model sees a range of arch shapes and cleft geometries
- **Core assumption**: Pre-/post-treatment variation is representative of the anatomical diversity the model will encounter; landmark definitions remain consistent across treatment states
- **Evidence anchors**: Trained on 90 models, equally balanced between pre- and post-UCLP treatment; small dataset (<100 samples) with few-shot learning strategies
- **Break condition**: If deployed on anatomies outside the pre-/post-treatment distribution, performance may degrade

## Foundational Learning

- **Concept**: Geometric Deep Learning (GDL) on non-Euclidean data
  - **Why needed here**: The paper frames its contribution within GDL, though the implementation uses multi-view 2D CNNs rather than native 3D graph convolutions
  - **Quick check question**: Can you explain why a standard CNN cannot directly operate on a 3D mesh or point cloud?

- **Concept**: Heatmap-based landmark regression
  - **Why needed here**: The hourglass network outputs probability heatmaps, not (x, y) coordinates directly
  - **Quick check question**: How does taking the argmax of a heatmap differ from regressing coordinates, and what are the tradeoffs for localization precision?

- **Concept**: Multi-view 3D reconstruction via ray consensus
  - **Why needed here**: The core pipeline converts 2D predictions back to 3D via triangulation
  - **Quick check question**: Given two camera views and a point detected in each, how would you compute the corresponding 3D location?

## Architecture Onboarding

- **Component map**: STL 3D mesh -> Multi-view renderer (generates 2D projections) -> Two-stack hourglass network with residual blocks + batch norm + dropout -> 16-channel heatmap output -> Ray consensus / triangulation -> 3D landmark coordinates -> MAE and accuracy evaluation

- **Critical path**: View generation quality (number of views, angular coverage) -> Heatmap resolution and peak sharpness -> Consensus algorithm robustness to outlier predictions

- **Design tradeoffs**: Multi-view 2D approach vs. native 3D GDL (simpler to implement, leverages mature 2D CNN tools, but introduces projection artifacts and view-selection sensitivity) vs. Heatmap regression vs. coordinate regression (more robust to spatial ambiguity, but requires careful post-processing and resolution tuning) vs. Small dataset (<100 samples) (enables rapid experimentation but limits generalization claims; augmentation and pre-/post-treatment balance are compensating strategies)

- **Failure signatures**: High error on smooth, featureless regions (landmarks 5, 6, 9, 10: anterior/widest points on cleft edges) -> Reduced accuracy on outlier arch volumes (very large or small arches) -> Skewed error distribution (skewness = 1.32) with occasional high-error outliers

- **First 3 experiments**: View ablation (reduce number of 2D views to identify minimum for <2mm MAE) -> Landmark-specific error analysis (isolate landmarks 5, 6, 9, 10 to test additional views or augmentation) -> Cross-population validation (train on UCLP, test on bilateral CLP or older infant scans to quantify generalization bounds)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the multi-view consensus CNN pipeline be effectively generalized to elderly and adolescent populations with significantly different maxillary arch morphology?
- **Basis in paper**: The conclusion identifies "adapting the pipeline for elderly and adolescent populations" as a promising avenue for future research
- **Why unresolved**: The current study was trained and validated exclusively on 3D scans from newborns with unilateral cleft lip and palate, limiting its applicability to other age groups
- **What evidence would resolve it**: Successful replication of accuracy metrics (e.g., >94%) on external datasets comprising adolescent or geriatric subjects

### Open Question 2
- **Question**: How does the performance of the proposed multi-view 2D-based pipeline compare to native non-Euclidean geometric models that operate purely in 3D space?
- **Basis in paper**: The authors state the pipeline could function as a "base of comparison for later non-Euclidian models that operate purely in 3D space"
- **Why unresolved**: This study utilized a multi-view approach (rendering 3D scans into 2D images) rather than processing the raw geometric data directly
- **What evidence would resolve it**: A comparative benchmark study evaluating the current method against native 3D deep learning architectures (e.g., PointNet) on the same dataset

### Open Question 3
- **Question**: Can model robustness be improved for "outlier arch volumes" and smooth anatomical regions that currently suffer from higher localization errors?
- **Basis in paper**: The results section notes that errors were frequent in smooth regions lacking distinct features (landmarks 5, 6, 9, 10) and that the model performed "less accurately on outlier arch volumes"
- **Why unresolved**: The limited training set (N=90) may not adequately capture the full variance of anatomical shapes, leading to failures in feature-less areas or extreme sizes
- **What evidence would resolve it**: Reduced error variance in smooth regions and outlier cases after expanding the training dataset or incorporating shape-context features

## Limitations
- Small sample size (90 training, 10 test samples) constrains generalizability despite balanced pre-/post-treatment split
- Multi-view approach introduces view-selection sensitivity without systematic exploration or view-ablation studies
- Performance on anatomies outside the UCLP spectrum (bilateral cleft, older populations, different ethnic backgrounds) remains unverified
- No comparative experiments with baseline methods to validate claimed superiority

## Confidence

- **High confidence**: The multi-view consensus mechanism works as described for the UCLP population tested; the reported MAE and accuracy metrics are reproducible given the stated architecture and dataset
- **Medium confidence**: The generalizability to broader cleft populations and the clinical utility of <2mm error rates; the sufficiency of 8-16 views for robust landmark detection
- **Low confidence**: Claims about the method's superiority over existing approaches, as no comparative experiments with baseline methods are presented

## Next Checks
1. **Cross-population validation**: Test the trained model on bilateral cleft cases and older infant scans to quantify performance degradation and identify population-specific limitations
2. **View-ablation study**: Systematically reduce the number of 2D views (12 → 8 → 4) while measuring MAE and accuracy to determine the minimum viable configuration and identify view-critical landmarks
3. **Clinical threshold validation**: Survey clinicians to establish whether 2.56 mm accuracy meets practical treatment planning requirements, and test the model's performance on clinically challenging cases (severe clefts, post-surgical anomalies)