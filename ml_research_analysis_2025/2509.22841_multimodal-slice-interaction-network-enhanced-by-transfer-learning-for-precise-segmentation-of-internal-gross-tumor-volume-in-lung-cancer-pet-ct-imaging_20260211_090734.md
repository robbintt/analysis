---
ver: rpa2
title: Multimodal Slice Interaction Network Enhanced by Transfer Learning for Precise
  Segmentation of Internal Gross Tumor Volume in Lung Cancer PET/CT Imaging
arxiv_id: '2509.22841'
source_url: https://arxiv.org/abs/2509.22841
tags:
- segmentation
- igtv
- tumor
- lung
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of accurately segmenting internal
  gross tumor volume (IGTV) in lung cancer PET/CT imaging, which is critical for radiation
  therapy planning but hindered by limited annotated datasets and weak PET signal
  at tumor boundaries. The authors propose a transfer learning framework that pre-trains
  on a large-scale gross tumor volume (GTV) dataset and fine-tunes on a private IGTV
  dataset.
---

# Multimodal Slice Interaction Network Enhanced by Transfer Learning for Precise Segmentation of Internal Gross Tumor Volume in Lung Cancer PET/CT Imaging

## Quick Facts
- **arXiv ID:** 2509.22841
- **Source URL:** https://arxiv.org/abs/2509.22841
- **Reference count:** 36
- **Primary result:** 58.2% improvement in Dice score (0.609 vs 0.385) for IGTV segmentation using transfer learning from GTV pre-training and 2.5D slice interaction modeling

## Executive Summary
This paper addresses the critical challenge of accurately segmenting Internal Gross Tumor Volume (IGTV) in lung cancer PET/CT imaging, which is essential for precise radiation therapy planning. The key difficulty stems from limited annotated datasets and weak PET signal at tumor boundaries. The authors propose a transfer learning framework that leverages extensive GTV annotations to pre-train a segmentation model, then fine-tunes it on a smaller IGTV dataset. A novel Slice Interaction Module (SIM) is introduced to model inter-slice relationships through attention mechanisms, significantly improving boundary delineation. The approach achieves a Dice coefficient of 0.609 on private IGTV data, representing a substantial 58.2% improvement over baseline methods.

## Method Summary
The method employs a CIPA-Mamba backbone architecture with a novel Slice Interaction Module (SIM) to process 2.5D inputs (three consecutive PET/CT slice pairs). The model is pre-trained on the large-scale PCLT20k GTV dataset (21,930 PET/CT pairs) and fine-tuned on a private IGTV dataset (LUCID-PET/CT, 1,067 pairs). The SIM module combines channel attention, spatial attention, and depthwise convolutions with fixed empirical weights (α=0.3, β=0.3, γ=0.4) to aggregate contextual information from adjacent slices. Training uses AdamW optimization with cosine learning rate scheduling, data augmentation including affine transforms and random crops, and mixed-precision training on NVIDIA A100 GPUs.

## Key Results
- Achieved Dice coefficient of 0.609 on private IGTV dataset, representing 58.2% improvement over baseline score of 0.385
- Outperformed standard 2D baseline (Dice 0.387) and 2.5D baseline without SIM (Dice 0.532)
- Demonstrated effectiveness of transfer learning from GTV to IGTV task with finetuning improving Dice from 0.387 to 0.532
- Showed 2.5D approach with three consecutive slices provides better context than single-slice processing

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pre-training on large-scale GTV data creates a robust initialization for the data-scarce IGTV task
- **Mechanism:** The network learns fundamental tumor morphologies and texture features from abundant source domain (GTV). During fine-tuning, these low-level features are reused, allowing the model to focus its limited capacity on learning specific boundary nuances and motion-encompassing characteristics of target domain (IGTV)
- **Core assumption:** GTV and IGTV share sufficient underlying anatomical and metabolic features such that the mapping learned from GTV acts as a beneficial prior for IGTV
- **Evidence anchors:** Abstract mentions transfer learning methodology; Section V Table II shows finetuning improves Dice from 0.387 to 0.532
- **Break condition:** Performance degrades if source domain (GTV) possesses systematically different noise profiles or tumor stage distributions than target IGTV domain, leading to negative transfer

### Mechanism 2
- **Claim:** Slice Interaction Module (SIM) recovers boundary information lost in single-slice 2D views by modeling inter-slice continuity
- **Mechanism:** By processing three consecutive slices simultaneously, the model exploits high correlation between adjacent axial slices. SIM explicitly aggregates this context via attention and convolutions, allowing the model to disambiguate true tumor boundaries from noise or weak PET signals in central slice by referencing adjacent slices
- **Core assumption:** Relevant spatial context for defining IGTV boundary is contained strictly within immediate adjacent slices (±1 slice)
- **Evidence anchors:** Abstract introduces SIM to model inter-slice relationships; Section IV.C describes 2.5D input configuration and SIM branches
- **Break condition:** Mechanism fails in edge cases where tumor spans fewer than 3 slices or if slice thickness is too large, causing adjacent slices to lack relevant anatomical correspondence

### Mechanism 3
- **Claim:** Combination of Channel and Spatial attention with Depthwise convolutions in SIM creates refined boundary-aware feature map
- **Mechanism:** Channel Attention branch weights importance of feature maps (answering "what" is important), Spatial Attention branch identifies "where" in slice to look, and Slice Relation branch models local dependencies. Weighted residual fusion ensures original signal is preserved while amplifying relevant contextual cues
- **Core assumption:** Fixed empirical weights (α=0.3, β=0.3, γ=0.4) are optimal for balancing these features across diverse tumor morphologies
- **Evidence anchors:** Section IV.C Equations define specific fusion mechanism and weights; Section V shows Baseline 2.5D + SIM outperforms standard Baseline 2.5D (0.609 vs 0.532 Dice)
- **Break condition:** Fixed weights may be sub-optimal for tumors with vastly different sizes or signal intensities compared to validation set used for tuning

## Foundational Learning

- **Concept:** IGTV vs. GTV Distinction
  - **Why needed here:** You cannot understand transfer learning challenge without knowing that GTV is visible static tumor, while IGTV includes respiratory motion. Model must learn to expand/predict IGTV based on GTV features
  - **Quick check question:** Does the target label (IGTV) represent static anatomical boundary or motion envelope of tumor?

- **Concept:** Mamba / State Space Models (SSM)
  - **Why needed here:** Base architecture is CIPA with Mamba, not standard CNN or Transformer. You need to understand that Mamba offers global context with linear complexity, critical for handling high-resolution medical images efficiently
  - **Quick check question:** Why would authors choose Mamba-based architecture over standard U-Net or Transformer for this segmentation task? (Hint: Long-range dependencies vs. computational cost)

- **Concept:** 2.5D Segmentation Strategy
  - **Why needed here:** Paper argues 2D is insufficient and 3D is potentially too computationally expensive or memory-heavy. 2.5D is the compromise
  - **Quick check question:** How does input tensor shape B×3×H×W differ from standard 2D input or 3D volumetric input?

## Architecture Onboarding

- **Component map:** Input (Concatenated 3-slice PET/CT pairs, 6 channels) -> Encoder (Mamba-based CIPA backbone) -> SIM (Channel Attention, Spatial Attention, Slice Relation branches) -> Fusion (Weighted residual addition) -> Output (IGTV segmentation mask)

- **Critical path:**
  1. Data Prep: Aligning PET/CT and ensuring consecutive slices are loaded correctly as single sample
  2. Pre-training: Running GTV training loop to convergence to establish "Pre-trained" checkpoint
  3. SIM Injection: Modifying architecture to accept 3 slices and inserting SIM block before loading pre-trained weights

- **Design tradeoffs:**
  - Context vs. Complexity: Using 3 slices increases memory usage and inference time compared to 2D, but captures necessary inter-slice geometry
  - Fixed vs. Learnable Weights: SIM uses fixed fusion weights (α,β,γ). This reduces tuning complexity but might limit adaptability to different scanner protocols

- **Failure signatures:**
  - "Leakage" from adjacent organs: High uptake in heart causing false positives
  - Missing peripheral slices: Model struggles with first/last slices of volume where It-1 or It+1 is missing
  - Diminishing returns: Fixed 3-slice window may miss long-range anatomical context

- **First 3 experiments:**
  1. Ablation on Input Depth: Compare Dice scores for 1-slice (2D) vs. 3-slice (2.5D) vs. 5-slice inputs to validate specific choice of "3" slices
  2. SIM Weight Sensitivity: Test if making α,β,γ learnable parameters improves performance over fixed empirical weights
  3. Transfer Source Validation: Pre-train on generic dataset (ImageNet or synthetic data) vs. specific PCLT20K GTV dataset to quantify value of specific domain transfer

## Open Questions the Paper Calls Out
- **Question:** Can full 3D architectures or dynamic slice selection significantly improve IGTV delineation over fixed 3-slice 2.5D approach?
- **Question:** To what extent do false positives caused by adjacent organ uptake impact clinical utility of model in actual radiotherapy planning?
- **Question:** Does transfer learning approach generalize effectively to external IGTV datasets with different scanner protocols or patient demographics?

## Limitations
- Data accessibility: Core LUCID-PET/CT dataset is private, preventing independent verification of claimed 58.2% Dice improvement
- Generalizability: 3-slice window may not capture long-range anatomical dependencies in large tumors or motion patterns beyond ±1 slice
- Comparison baseline: Only 2D and 2.5D baselines tested; no 3D volumetric approaches included, limiting claims about optimal context window size

## Confidence
- **High confidence:** Transfer learning from GTV to IGTV improves segmentation (supported by ablation showing finetuning improves Dice from 0.387 to 0.532)
- **Medium confidence:** 2.5D SIM module provides meaningful boundary context (empirical improvement from 0.532 to 0.609 Dice, but no ablation on SIM components)
- **Medium confidence:** Specific choice of 3 slices is optimal (stated as rationale but not experimentally validated against other window sizes)

## Next Checks
1. **Ablation on input depth:** Systematically compare 1-slice (2D), 3-slice (current), and 5-slice inputs to empirically determine optimal context window for boundary recovery
2. **SIM component analysis:** Test whether making α, β, γ learnable parameters improves performance over fixed empirical weights, and evaluate individual SIM branch contributions
3. **External validation:** Apply pre-trained + finetuned model to independent, publicly available PET/CT lung cancer dataset to assess generalizability beyond private LUCID cohort