---
ver: rpa2
title: 'No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of
  LLMs'
arxiv_id: '2602.02103'
source_url: https://arxiv.org/abs/2602.02103
tags:
- accuracy
- answer
- reasoning
- figure
- planning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the latent planning capacity of Large Language
  Models (LLMs) during Chain-of-Thought (CoT) reasoning. To probe the internal planning
  horizon, we introduce Tele-Lens, a transformation-based method that leverages low-rank
  adapters to predict teleological information from hidden states, including subsequent
  tokens, final answers, and reasoning lengths.
---

# No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs

## Quick Facts
- arXiv ID: 2602.02103
- Source URL: https://arxiv.org/abs/2602.02103
- Reference count: 40
- LLMs exhibit myopic planning horizons during Chain-of-Thought reasoning

## Executive Summary
This work investigates whether Large Language Models (LLMs) employ global planning during Chain-of-Thought (CoT) reasoning by probing hidden states for teleological information. Using Tele-Lens, a low-rank adapter-based method, the authors predict subsequent tokens, final answers, and reasoning lengths from intermediate hidden states across 12 diverse tasks. Results reveal that LLMs primarily conduct local transitions rather than global planning, with precise final-answer information only emerging one step before completion for compositional tasks. These findings enable improved uncertainty estimation and automatic CoT necessity detection through early answer gist signals.

## Method Summary
Tele-Lens employs low-rank adapters (rank 256) with GeLU activation to transform hidden states into predictions of teleological information. The method injects positional offsets (up to 8 tokens) to probe future information content. Models are trained for approximately 5K steps using batch size 8000 and learning rate 1e-3 with linear decay. The study examines Qwen3-32B (off-the-shelf) and GRPO-trained Qwen2.5-7B-Instruct across 12 tasks including Parity, Cycle, Subsum, GSM8K, MATH, AIME, MuSR, Zebra, CSQA, MMLU, QuALITY, and GPQA. Hidden states are sampled at 5-10% for training/development and fully retained for testing up to 16,384 tokens per sequence.

## Key Results
- LLMs show myopic planning horizons, conducting local transitions rather than global planning
- Precise final-answer planning only emerges one step before completion for compositional reasoning tasks
- Early hidden states encode coarse answer gist rather than precise reasoning plans for simpler tasks
- Uncertainty calibration improves by up to 9% using critical pivot positions instead of global aggregates
- CoT necessity can be automatically recognized, enabling up to 16.2% CoT bypass with negligible performance degradation

## Why This Works (Mechanism)
The paper leverages the fact that intermediate hidden states during CoT reasoning may encode teleological information about future reasoning steps. By training lightweight adapters to extract this information, the authors can probe the latent planning capacity of LLMs without requiring architectural modifications or extensive retraining. The low-rank parameterization allows efficient adaptation while maintaining compatibility with frozen LLMs.

## Foundational Learning

**Chain-of-Thought reasoning**: A prompting technique where models generate intermediate reasoning steps before producing final answers. Needed to understand the context where planning is being probed. Quick check: Can the model solve problems without explicit CoT prompts?

**Teleological information**: Information about purpose, goals, or future states in a reasoning process. Critical for understanding what the probing method is attempting to extract. Quick check: Does the probing method recover known future information from hidden states?

**Low-rank adapters**: Parameter-efficient modules that modify model behavior through low-rank matrix decomposition. Essential for the probing method's efficiency and compatibility. Quick check: Does the adapter train successfully without overfitting?

**Hidden state probing**: The technique of extracting information from intermediate model representations. Central to the paper's methodology. Quick check: Do hidden states contain meaningful signals about future reasoning steps?

**Uncertainty calibration**: The process of aligning predicted probabilities with actual correctness rates. Important for the downstream applications. Quick check: Does the calibration metric improve when using pivot positions?

## Architecture Onboarding

**Component map**: Input data -> CoT generation -> Hidden state extraction -> Tele-Lens adapter training -> Teleological prediction -> Uncertainty calibration/Bypass detection

**Critical path**: The probing pipeline (data generation → hidden state collection → adapter training → evaluation) is most critical for validating the core claim about myopic planning horizons.

**Design tradeoffs**: Low-rank adapters balance parameter efficiency against probe expressiveness; sampling 5-10% of hidden states reduces storage costs but may miss rare patterns; multi-choice conversion of math problems enables consistent evaluation but may introduce artificial constraints.

**Failure signatures**: Adapter overfitting (dev set performance degrades); random probing accuracy on compositional tasks at early positions (expected behavior); inability to extract any teleological information (indicates probe failure).

**First experiments**:
1. Verify Tele-Lens can accurately predict subsequent tokens at the final position (should be near-perfect)
2. Test coarse gist detection on early positions of simple tasks (should show non-random performance)
3. Validate adapter training stability across random seeds on a single task

## Open Questions the Paper Calls Out
None

## Limitations
- Probing method may not capture all forms of latent planning due to low-rank adapter constraints
- Results may not generalize beyond Qwen model family to other architectures or model sizes
- Task diversity is reasonable but excludes open-ended reasoning domains where CoT might function differently
- Interpretation of "planning" versus "pattern completion" remains somewhat ambiguous

## Confidence

**Major claim confidence:**
- Core planning horizon findings (Medium): Supported by systematic probing but interpretation depends on probe quality
- Uncertainty calibration improvements (High): Direct empirical demonstration with clear metrics
- CoT necessity detection (Medium): Promising results but dependent on probe reliability

## Next Checks

1. **Probe robustness test**: Validate Tele-Lens accuracy across multiple random seeds and training runs to establish statistical significance of the observed planning horizon patterns, particularly the critical transition at the final reasoning step.

2. **Cross-architecture generalization**: Replicate key experiments (final-answer probing accuracy progression) on at least one additional LLM family (e.g., GPT-4, Claude) to assess whether the myopic planning phenomenon extends beyond Qwen models.

3. **Control for representation capacity**: Compare probing performance against baseline models that receive the same information through different mechanisms (e.g., prefix-tuning or direct answer supervision) to isolate whether observed patterns reflect genuine planning limitations versus architectural constraints.