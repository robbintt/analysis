---
ver: rpa2
title: 'Joint Communication Scheduling and Velocity Control for Multi-UAV-Assisted
  Post-Disaster Monitoring: An Attention-Based In-Context Learning Approach'
arxiv_id: '2510.05698'
source_url: https://arxiv.org/abs/2510.05698
tags:
- data
- collection
- velocity
- sensor
- aic-vds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of joint communication scheduling
  and velocity control for multi-UAV-assisted post-disaster monitoring, such as tsunami
  response. The key problem is minimizing data loss due to transmission errors and
  buffer overflows in ground sensors while managing UAV velocities and data collection
  schedules in real-time.
---

# Joint Communication Scheduling and Velocity Control for Multi-UAV-Assisted Post-Disaster Monitoring: An Attention-Based In-Context Learning Approach

## Quick Facts
- **arXiv ID**: 2510.05698
- **Source URL**: https://arxiv.org/abs/2510.05698
- **Reference count**: 33
- **Primary result**: AIC-VDS achieves 91% lower packet loss than maximum channel gain baseline with 3 UAVs and 20 ground sensors

## Executive Summary
This paper addresses the challenge of minimizing data loss in post-disaster monitoring scenarios using multiple UAVs for data collection from ground sensors. The authors propose AIC-VDS, an Attention-Based In-Context Learning framework that jointly optimizes UAV scheduling and velocity control. The system uses an attention mechanism to compress high-volume sensor data and an LLM to generate control policies through In-Context Learning, eliminating the need for model retraining. AIC-VDS significantly outperforms traditional baselines including MADQN and maximum channel gain approaches.

## Method Summary
The AIC-VDS framework consists of three main components: an attention module for sensor data compression, an edge LLM for policy generation, and UAVs for data collection and velocity control. The attention module processes sensor feature vectors (queue length, battery, channel condition) to compute importance scores and select the top-k sensors for LLM input. The LLM receives a structured prompt containing task descriptions, examples, and the current environment state, then generates scheduling and velocity actions. The system operates in a feedback loop where UAVs execute LLM-generated actions and log results for continuous improvement. The method is evaluated through customized Python simulations using probabilistic LoS channel models, J=10 ground sensors in a 100mÃ—100m area, I=3 UAVs, and 30 time steps per episode.

## Key Results
- AIC-VDS achieves 91% lower packet loss compared to maximum channel gain baseline with I=3 UAVs and J=20 ground sensors
- Increasing UAVs from 3 to 5 reduces packet loss by 83%, demonstrating scalability benefits
- The framework successfully uses real LLM APIs (GPT-4o-mini, Llama-3) without retraining requirements

## Why This Works (Mechanism)

### Mechanism 1
Attention-based context pruning enables LLMs to process high-volume, redundant sensor data by filtering for task-critical information. An attention module processes sensor feature vectors to compute scalar importance scores, selecting only the top-k sensors for the LLM prompt, reducing input overhead. The core assumption is that attention weights effectively correlate with sensor urgency and serve as a valid proxy for LLM decision-making needs.

### Mechanism 2
In-Context Learning allows pre-trained LLMs to generate adaptive multi-UAV control policies from natural language task descriptions and examples without parameter retraining. The system constructs a prompt containing task description, examples, and current environment state, enabling the LLM to infer solutions by recognizing patterns. The core assumption is that the pre-trained LLM possesses sufficient reasoning and generalization capabilities to solve the joint optimization problem from examples and descriptions alone.

### Mechanism 3
Joint optimization of scheduling and velocity control, guided by LLM-generated policies, minimizes packet loss by proactively managing trade-offs between buffer overflows and transmission errors. The LLM generates actions based on a holistic view of system state, allowing for proactive control that avoids both buffer overflows from slow movement and transmission errors from poor channels. The core assumption is that the system's state representation captures key variables determining packet loss and the LLM correctly models their interactions.

## Foundational Learning

- **In-Context Learning (ICL)**: Why needed - This is the core method for deploying LLMs for optimization without retraining. An engineer must understand how to craft effective prompts with task descriptions and examples. Quick check - How does providing task descriptions and examples in a prompt enable an LLM to solve a new, unseen optimization problem without updating its weights?

- **Attention Mechanisms**: Why needed - The system uses an attention module for data compression. Understanding how query, key, and value vectors compute importance scores is crucial for interpreting the model's data selection process. Quick check - In this system, how do the computed attention weights determine which sensor data is "most salient" and therefore selected for the LLM's input?

- **Probabilistic Channel Models**: Why needed - The system's performance depends on wireless communication quality. Understanding the probabilistic LoS model is key to interpreting channel conditions and transmission error probabilities. Quick check - How do environmental constants and elevation angle influence the probability of establishing a Line-of-Sight link between a UAV and a ground sensor?

## Architecture Onboarding

- **Component map**: UAVs -> Attention Module -> Edge LLM -> UAVs (via structured prompt)
- **Critical path**: Data is collected by UAVs -> Processed by Attention Module -> Sent to Edge LLM via structured prompt -> LLM generates Schedule & Velocity -> UAVs execute actions -> Results are logged for feedback
- **Design tradeoffs**:
  - LLM Size vs. Latency: Larger models offer better reasoning but higher latency; GPT-4o-mini is used as compromise
  - Compression Granularity vs. Information Loss: Aggressive attention-based pruning reduces LLM overhead but risks discarding critical information
  - Number of UAVs vs. Cost: More UAVs reduce packet load per UAV, lowering loss but increasing system cost
- **Failure signatures**:
  - High Packet Loss with Saturated Queues: LLM scheduling policy fails to clear queues fast enough
  - High Transmission Error Rate: LLM scheduling sensors with poor channel conditions
  - Erratic Velocity Changes: Instability in LLM's output or failure to converge on stable policy
- **First 3 experiments**:
  1. **Ablation Study on Attention**: Run system with and without attention module to quantify impact on LLM inference latency and packet loss
  2. **LLM Comparison**: Test different underlying LLMs to evaluate performance on optimization task
  3. **Scalability Test**: Vary number of ground sensors and UAVs to determine system's breaking point

## Open Questions the Paper Calls Out

### Open Question 1
Can the AIC-VDS framework maintain robustness and solution quality during physical deployment? The paper concludes that further work is needed to evaluate convergence, solution quality, and robustness under real-world operational conditions. This remains unresolved because the evaluation relies entirely on customized Python simulations and probabilistic channel models that may not capture hardware failures or physical signal propagation complexity.

### Open Question 2
Can lightweight, local LLMs bridge the performance gap with cloud-based models to ensure operation in disconnected disaster zones? The authors note that lightweight models like LLaMA-3-8B showed much lower performance compared to GPT-4, forcing reliance on proprietary cloud APIs that may lack robust connectivity in disaster scenarios. This trade-off contradicts the need for autonomy in post-disaster environments where infrastructure is damaged.

### Open Question 3
Does LLM inference latency induce control instability in high-velocity or highly dynamic scenarios? Figure 8 illustrates significant variance and periodic spikes in inference latency across different UAVs on identical trajectories. While the paper asserts feasibility, the impact of these random delays on velocity control loop timing constraints was not mathematically analyzed for worst-case scenarios.

## Limitations
- No analysis of prompt sensitivity or how different example sets affect performance
- Limited scalability testing beyond the reported I=3, J=20 configuration
- No robustness testing against adversarial sensor conditions or communication failures
- Performance metrics focus solely on packet loss without considering energy consumption trade-offs

## Confidence

**High Confidence Claims**:
- AIC-VDS achieves 91% lower packet loss compared to maximum channel gain baseline
- Attention mechanism effectively compresses sensor data from 20 sensors to top-k
- System works with real LLM APIs (GPT-4o-mini, Llama-3) without retraining

**Medium Confidence Claims**:
- Joint optimization of scheduling and velocity provides better performance than sequential optimization
- The 83% packet loss reduction from 3 to 5 UAVs scales predictably
- LLM-based decisions outperform traditional reinforcement learning approaches

**Low Confidence Claims**:
- Generalization to significantly larger sensor networks (J >> 20)
- Performance under extreme environmental conditions (severe weather, obstacles)
- Real-world deployment feasibility beyond controlled simulations

## Next Checks

1. **Prompt Sensitivity Analysis**: Systematically vary the task description and example demonstrations in the ICL prompt to determine which components most strongly influence packet loss performance and velocity control decisions.

2. **Scalability Breakpoint Test**: Incrementally increase the number of ground sensors from J=20 to J=100+ while monitoring LLM inference latency, attention module processing time, and packet loss metrics to identify system scaling limits.

3. **Robustness Under Adversarial Conditions**: Introduce sensor failure modes, extreme battery depletion scenarios, and simulated communication jamming to evaluate AIC-VDS's ability to maintain acceptable performance under stress conditions.