---
ver: rpa2
title: Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using
  SAM2
arxiv_id: '2507.23272'
source_url: https://arxiv.org/abs/2507.23272
tags:
- segmentation
- tumor
- breast
- dice
- sam2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the use of Segment Anything Model 2 (SAM2)
  for 3D tumor segmentation in breast MRI with minimal input. By propagating a single
  bounding box annotation across slices using three different tracking strategies,
  the authors find that center-outward propagation yields the most accurate segmentations.
---

# Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2

## Quick Facts
- arXiv ID: 2507.23272
- Source URL: https://arxiv.org/abs/2507.23272
- Authors: Solha Kang; Eugene Kim; Joris Vankerschaver; Utku Ozbulak
- Reference count: 27
- Primary result: SAM2 achieves 0.57-0.71 Dice scores for 3D breast tumor segmentation using minimal input

## Executive Summary
This study explores the use of Segment Anything Model 2 (SAM2) for 3D tumor segmentation in breast MRI with minimal input. By propagating a single bounding box annotation across slices using three different tracking strategies, the authors find that center-outward propagation yields the most accurate segmentations. Despite being a zero-shot model not trained for volumetric medical data, SAM2 achieves strong performance, with mean Dice scores of 0.57 using bounding box input and 0.71 using segmentation mask input. The work demonstrates that foundation models like SAM2 can support 3D medical image analysis in resource-constrained settings, offering an accessible alternative to commercial AI tools.

## Method Summary
The study applies SAM2 to 3D breast MRI segmentation by treating sequential axial slices as video frames and using the model's video tracking functionality. The approach uses zero-shot inference without task-specific training, starting with a single bounding box or segmentation mask on one slice and propagating predictions across the tumor-positive volume using three strategies: bottom-to-top, top-to-bottom, and center-outward. Center-outward propagation begins at the middle tumor slice and tracks bidirectionally, leveraging the typically largest and clearest tumor cross-section at the volumetric center. The method was evaluated on the Duke Breast Cancer Dataset with MAMA-MIA extension, using volumetric Dice Similarity Coefficient as the primary metric.

## Key Results
- Center-outward propagation strategy yields the most consistent and accurate segmentations compared to top-down or bottom-up approaches
- SAM2 achieves mean Dice scores of 0.57 with bounding box input and 0.71 with segmentation mask input
- Despite being zero-shot and not trained on volumetric medical data, SAM2 demonstrates strong performance for 3D segmentation
- Segmentation failures commonly occur with multiple small scattered lesions rather than single well-defined tumors

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Center-outward propagation yields more accurate 3D tumor segmentation than top-down or bottom-up approaches when using slice-wise tracking.
- **Mechanism:** Tumors are typically largest and most clearly defined at their central slice. Initializing segmentation from this "most reliable" frame provides a higher-quality starting mask, reducing accumulated tracking errors as the model propagates toward peripheral slices where tumor boundaries become ambiguous.
- **Core assumption:** Tumor morphology follows a roughly contiguous spatial structure with maximal cross-sectional area near the volumetric center.
- **Evidence anchors:**
  - [abstract] "center-outward propagation yields the most consistent and accurate segmentations"
  - [Section 3, results] Center-outward shows higher median Dice scores and right-skewed distribution; yields best performance for majority of patients
  - [corpus] MOIS-SAM2 paper addresses multilesion tracking but does not compare propagation strategies; weak comparative evidence
- **Break condition:** Fragmented or multi-focal tumors where no single clear "center" exists; small scattered lesions defeat the spatial coherence assumption.

### Mechanism 2
- **Claim:** SAM2's video object tracking functionality can be repurposed for volumetric medical image segmentation without task-specific training.
- **Mechanism:** SAM2 treats sequential MRI slices as video frames, using the predicted mask from slice N-1 as contextual guidance for slice N. This temporal tracking mechanism transfers to the spatial z-dimension of 3D volumes, enabling zero-shot propagation.
- **Core assumption:** Adjacent MRI slices share sufficient visual continuity that video-tracking priors trained on natural video generalize to axial medical imaging.
- **Evidence anchors:**
  - [abstract] "Despite being a zero-shot model not trained for volumetric medical data, SAM2 achieves strong performance"
  - [Section 2.3] "SAM2 is applied in a slice-wise fashion... using the predicted mask from the previous slice as contextual guidance for the next"
  - [corpus] MedVL-SAM2 and Medical SAM2 papers similarly adapt SAM2 for medical volumetric data, suggesting transferability is reproducible
- **Break condition:** Large inter-slice spacing or motion artifacts that break visual continuity; domain shift becomes too severe.

### Mechanism 3
- **Claim:** Providing a segmentation mask as the initial prompt improves tracking accuracy compared to a bounding box.
- **Mechanism:** Segmentation masks encode precise boundary information, whereas bounding boxes include irrelevant background pixels. The mask provides a more informative prior for the tracking model, reducing ambiguity about what constitutes the target object.
- **Core assumption:** The user or pre-processing step can provide an accurate initial mask for at least one slice.
- **Evidence anchors:**
  - [Section 3, Comparison to Mask-based Tracking] "mean Dice score across all patients increasing from 0.57 (bounding box tracking) to 0.71 (segmentation mask tracking)"
  - [Section 3] "nearly all patients, segmentation accuracy improves with mask-based guidance"
  - [corpus] No direct comparison found in neighbor papers; this appears novel to this study
- **Break condition:** When initial mask quality is poor or erroneous, errors propagate rather than correct.

## Foundational Learning

- **Concept: Volumetric Dice Similarity Coefficient**
  - Why needed here: This is the evaluation metric; understanding that it aggregates all voxel-level predictions across the 3D volume before computing overlap prevents misinterpretation of slice-level vs volume-level performance.
  - Quick check question: If a model perfectly segments 50% of slices but misses the other 50% entirely, would the volumetric Dice be 0.5? (Answer: Likely lower, since the formula penalizes false negatives and false positives simultaneously.)

- **Concept: Zero-shot / Foundation Models**
  - Why needed here: SAM2 is not trained on medical data; understanding zero-shot transfer explains why performance is impressive but also why failure modes exist.
  - Quick check question: What does "zero-shot" mean in this context? (Answer: The model performs the task without any task-specific training or fine-tuning on breast MRI data.)

- **Concept: Propagation vs. Independent Slice Prediction**
  - Why needed here: The core innovation is treating 3D segmentation as a tracking problem, not independent 2D problems; propagation error accumulation is the key failure mode to understand.
  - Quick check question: Why does the order of slice processing matter for propagation but not for independent prediction? (Answer: Propagation uses previous predictions as input for the next slice; errors compound along the chain.)

## Architecture Onboarding

- **Component map:** Input layer (bounding box or mask) -> SAM2 core (pretrained vision transformer) -> Propagation controller (orchestrates slice order) -> Output aggregator (collects masks, computes volumetric Dice)

- **Critical path:**
  1. Identify tumor-positive slice range from bounding box annotations
  2. Select starting slice based on propagation strategy (center slice for center-outward)
  3. Provide initial prompt (box or mask) to SAM2 on starting slice
  4. For each subsequent slice in propagation order: feed previous mask as prompt, run SAM2 inference, store output
  5. Aggregate all masks into 3D volume; evaluate with volumetric Dice

- **Design tradeoffs:**
  - **Bounding box vs. mask input:** Box is faster/cheaper to annotate (0.57 Dice); mask requires more effort but improves accuracy (0.71 Dice)
  - **Propagation direction:** Center-outward more robust but requires knowing tumor extent a priori; top-to-bottom simpler but accumulates more error
  - **Zero-shot vs. fine-tuning:** No training cost and immediate deployment; but domain-specific performance ceiling

- **Failure signatures:**
  - Multiple small scattered lesions instead of single mass (Fig. 7): model loses spatial coherence, fragments or drops lesions
  - Low correlation found between Dice and tumor volume/slice count/initial area: failure is not predictable from simple tumor properties
  - Peripheral slices: tracking quality degrades farther from initialization point

- **First 3 experiments:**
  1. **Reproduce propagation strategy comparison:** Run all three strategies (B-to-T, T-to-B, center-outward) on a held-out subset; verify center-outward advantage and quantify margin.
  2. **Ablate prompt type:** Compare bounding box vs. mask initialization across same patients; confirm ~0.14 Dice improvement and identify cases where box fails but mask succeeds.
  3. **Characterize failure mode:** Manually annotate whether failed cases (Dice < 0.3) are multi-focal vs. unifocal; quantify correlation to validate the authors' qualitative claim.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can lightweight pre-selection strategies or uncertainty-aware mechanisms improve SAM2's robustness for fragmented, multi-focal tumor presentations?
- Basis in paper: [explicit] Authors identify that "segmentation failures commonly occurred in cases with multiple small lesions scattered across slices, rather than a single large, well-defined tumor" and suggest incorporating "lightweight pre-selection strategies to better handle fragmented tumor presentations, or integrating uncertainty-aware mechanisms."
- Why unresolved: The current single-bounding-box propagation approach assumes spatial coherence across slices, which breaks down when tumors are dispersed rather than consolidated.
- What evidence would resolve it: A comparative study evaluating pre-selection or uncertainty modules on the subset of multi-focal cases, showing improved Dice scores over baseline SAM2.

### Open Question 2
- Question: How does SAM2 compare to medical-specific foundation models like MedSAM2 for volumetric breast tumor segmentation under identical minimal-input conditions?
- Basis in paper: [explicit] "One natural extension is to evaluate and compare the performance of other segmentation foundation models, such as MedSAM2, which are specifically adapted for medical images and volumetric data."
- Why unresolved: This study only evaluated general-purpose SAM2; medical-specific variants may have inductive biases better suited to volumetric medical data.
- What evidence would resolve it: Head-to-head comparison on the same dataset (MAMA-MIA) using identical propagation strategies and input types, reporting Dice scores and failure mode distributions.

### Open Question 3
- Question: What anatomical, imaging, or tumor characteristics actually predict SAM2 segmentation success or failure in breast MRI?
- Basis in paper: [inferred] The authors tested three variables (slice count, tumor volume, initial area) and found no meaningful correlations (low RÂ² values of 0.072, 0.002, 0.141), leaving the factors driving performance unexplained.
- Why unresolved: Understanding failure predictors is critical for clinical deployment and determining when human oversight is most needed.
- What evidence would resolve it: Multivariate regression or machine learning analysis incorporating tumor shape descriptors, contrast-to-noise ratios, lesion boundary sharpness, and breast density to identify significant predictors of Dice score.

## Limitations

- The study is limited to a single institution's dataset (Duke Breast Cancer Dataset with MAMA-MIA extension), constraining assessment of cross-site and scanner variability.
- SAM2 was trained on natural images, not medical data, raising questions about performance on diverse tumor morphologies and acquisition protocols not represented in the training set.
- The claim that SAM2 handles multi-focal tumors poorly is based on qualitative observations without systematic analysis of failure cases or quantification of multi-focal lesion prevalence.

## Confidence

- **High confidence:** The comparative advantage of center-outward propagation over top-down/bottom-up strategies is well-supported by quantitative results showing consistent Dice score improvements across most patients.
- **Medium confidence:** The absolute performance metrics (0.57-0.71 Dice) are impressive for zero-shot transfer but should be interpreted cautiously without comparison to supervised medical models or commercial tools.
- **Low confidence:** The claim that SAM2 handles multi-focal tumors poorly is based on qualitative observations in Figure 7 without systematic analysis of failure cases or quantification of multi-focal lesion prevalence in the dataset.

## Next Checks

1. Test the three propagation strategies on a multi-center breast MRI dataset with varying scanner parameters to assess robustness to domain shift.
2. Compare SAM2's zero-shot performance against fine-tuned models and commercial AI tools on the same dataset to establish competitive positioning.
3. Conduct a systematic analysis of failure cases to quantify the prevalence of multi-focal tumors and characterize other failure modes (e.g., motion artifacts, slice spacing effects).