---
ver: rpa2
title: 'FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks'
arxiv_id: '2511.16216'
source_url: https://arxiv.org/abs/2511.16216
tags:
- question
- answer
- pair
- figure
- solution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FlipVQA-Miner, an automated pipeline for extracting
  high-quality Question-Answer (QA) and Visual Question-Answer (VQA) pairs from educational
  documents such as textbooks and exercise materials. The core idea is to combine
  a layout-aware OCR tool (MinerU) with an LLM-based semantic parser to bridge the
  gap between raw PDF content and structured AI-ready supervision data.
---

# FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks

## Quick Facts
- arXiv ID: 2511.16216
- Source URL: https://arxiv.org/abs/2511.16216
- Authors: Zhen Hao Wong; Jingwen Deng; Hao Liang; Runming He; Chengyu Shen; Wentao Zhang
- Reference count: 15
- Primary result: Automated pipeline extracting high-quality QA/VQA pairs from textbooks with F1 scores above 0.98 for text and over 0.96 for image placement

## Executive Summary
This paper presents FlipVQA-Miner, an automated pipeline for extracting high-quality Question-Answer (QA) and Visual Question-Answer (VQA) pairs from educational documents such as textbooks and exercise materials. The core innovation combines a layout-aware OCR tool (MinerU) with an LLM-based semantic parser to bridge the gap between raw PDF content and structured AI-ready supervision data. By separating structural parsing from semantic reasoning, the pipeline achieves superior accuracy while reducing computational costs by approximately 3.8x compared to direct LLM prompting.

The pipeline first extracts fine-grained structural content from PDFs, then uses an LLM to group, pair, and insert images into coherent QA/VQA pairs. Experiments demonstrate robust performance across diverse document types—including interleaved, long-distance, and multi-column layouts—achieving F1 scores above 0.98 for text extraction and over 0.96 for image placement. The method enables scalable use of authentic human-authored educational content, offering a practical and low-hallucination alternative to synthetic data for improving reasoning-oriented LLM training.

## Method Summary
FlipVQA-Miner is a two-stage pipeline that extracts structured QA and VQA pairs from educational PDFs. First, MinerU 2.5 (a layout-aware OCR model) converts PDFs into structured JSON with content blocks and spatial metadata. Second, an LLM (Gemini-2.5-pro) performs semantic reconstruction via three operations: grouping fragmented blocks, pairing questions with answers across pages using hierarchical metadata, and inserting images at semantically appropriate positions. The LLM outputs block identifiers rather than reconstructed content, which are then substituted back with original content to produce final QA/VQA pairs.

## Key Results
- Achieves F1 scores above 0.98 for text extraction across multiple benchmarks
- Achieves F1 scores above 0.96 for image placement accuracy
- Reduces computational cost to $0.012 per question versus $0.046 for direct LLM prompting
- Successfully handles complex layouts including interleaved QA pairs, long-distance dependencies, and multi-column formats

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating structural parsing from semantic reasoning improves extraction accuracy while reducing computational cost.
- Mechanism: MinerU (layout-aware OCR) first converts PDFs into structured JSON with content blocks and spatial metadata. The LLM then operates on block identifiers rather than raw text, outputting IDs instead of reconstructed content. This division of labor exploits MinerU's specialized training for document layout while preserving the LLM's capacity for semantic operations.
- Core assumption: MinerU's layout detection is more accurate than general-purpose LLMs at parsing structured documents, and identifier-based operations sufficiently preserve semantic relationships for downstream tasks.
- Evidence anchors:
  - [abstract]: "combining layout-aware OCR with LLM-based semantic parsing"
  - [section 3.2]: "Our method costs $0.012 per question, while the direct prompting method costs $0.046 per question"
  - [corpus]: Related work on layout-aware document understanding (LAD-RAG, MonkeyOCR) supports the architectural separation pattern, though comparative cost analysis is limited to this paper's claims.

### Mechanism 2
- Claim: Identifier-based semantic operations enable reliable cross-page and cross-document QA pairing.
- Mechanism: Each text or image block receives a unique identifier. The LLM performs three operations: (1) Grouping—merging fragmented blocks belonging to the same question/answer; (2) Pairing—extracting hierarchical metadata (chapter titles, question numbers) to match questions with answers across pages; (3) Inserting—placing images at semantically appropriate positions relative to their associated text.
- Core assumption: Hierarchical metadata (titles, numbering) is sufficiently consistent within educational documents to serve as reliable pairing signals, and LLMs can infer implicit relationships from structural cues.
- Evidence anchors:
  - [section 3.2]: "Merge fragmented text blocks that belong to the same question or answer"
  - [figure 2]: Demonstrates successful extraction where question, figure, and answer span different pages and separate companion books
  - [corpus]: LAD-RAG (FMR=0.60) similarly emphasizes cross-page dependency resolution, supporting the mechanism's broader applicability.

### Mechanism 3
- Claim: Authentic human-authored educational content provides lower-hallucination training data than synthetic generation.
- Mechanism: Textbook and exercise materials contain naturally curated QA pairs reflecting genuine human reasoning patterns and pedagogical intent. By extracting these directly rather than generating synthetic pairs, the pipeline avoids hallucination propagation, stylistic uniformity, and limited diversity that characterize self-generated LLM training data.
- Core assumption: The extraction process introduces less noise than synthetic generation would, and the structural imperfections from OCR are negligible for downstream training purposes.
- Evidence anchors:
  - [section 1]: "vast quantities of authentic human-authored content... remain underutilized"
  - [section 4.3.1]: "MinerU achieves a text F1 score above 94 on multiple benchmarks, indicating that such minor errors introduce minimal noise"
  - [corpus]: No direct corpus evidence comparing extraction noise vs. synthetic hallucination rates; this remains a paper-specific claim requiring external validation.

## Foundational Learning

- Concept: **Layout-aware OCR vs. traditional text extraction**
  - Why needed here: Understanding why MinerU preserves tables, equations, spatial metadata, and reading order—information lost by tools like Tesseract that treat documents as flat text streams.
  - Quick check question: Given a two-column PDF with embedded figures, what specific information would a layout-aware OCR preserve that a traditional OCR would not?

- Concept: **Instruction tuning data quality requirements**
  - Why needed here: The paper positions extraction as an alternative to synthetic data generation; understanding why synthetic data suffers from hallucination and uniformity clarifies the value proposition.
  - Quick check question: Name two failure modes common in LLM-generated instruction datasets that human-authored educational content might avoid.

- Concept: **Multimodal VQA structure and image-text alignment**
  - Why needed here: The pipeline explicitly handles image insertion; understanding how visual context relates to textual questions is essential for debugging extraction failures.
  - Quick check question: If a question references "the figure below" but the figure appears on the next page, what mechanism must the pipeline employ to correctly associate them?

## Architecture Onboarding

- Component map:
  ```
  Raw PDF → [MinerU 2.5: Layout-aware parsing] → Structured JSON (blocks + IDs + spatial metadata)
           → [LLM: Semantic reconstruction] → Three operations (Grouping, Pairing, Inserting)
           → [Reconstruction: ID substitution] → Structured VQA pairs (Markdown/JSON output)
  ```

- Critical path:
  1. **PDF structural quality**—Degraded scans or unusual fonts cause MinerU failures that propagate downstream
  2. **Block ID assignment**—Inconsistent ID schemes break LLM's ability to reference content
  3. **LLM prompt engineering**—The extraction prompt (Appendix B) encodes all semantic rules; deviations cause parsing failures
  4. **ID-to-content reconstruction**—Must maintain exact correspondence between IDs and original content

- Design tradeoffs:
  - **Specialized vs. general OCR**: MinerU provides higher accuracy for structured documents but adds dependency on a specific tool
  - **Cost vs. directness**: Identifier-based approach reduces LLM token costs (~3.8x cheaper) but introduces a two-stage pipeline with more failure points
  - **Manual vs. automated evaluation**: Paper uses human evaluation for quality assessment; scaling would require automated metrics

- Failure signatures:
  - **Incomplete pairs**: Questions without answers or vice versa (check LLM pairing logic)
  - **Misplaced images**: Images not associated with their referencing questions (check inserting operation)
  - **Cross-page breaks**: Multi-part questions split incorrectly (check grouping heuristics)
  - **OCR artifacts**: Formula errors or garbled text (check MinerU preprocessing)

- First 3 experiments:
  1. **Baseline validation**: Run pipeline on a simple single-column textbook with interleaved QA pairs; manually verify extraction accuracy against ground truth
  2. **Stress test—cross-document pairing**: Provide question PDF and answer PDF as separate inputs; measure pairing accuracy when answers exist in a different document
  3. **Ablation—direct LLM prompting**: Compare identifier-based extraction against direct LLM prompting on the same documents; quantify cost and accuracy differences to validate the architectural separation claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can FlipVQA-Miner's authentic QA pairs effectively replace synthetic data in Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to reduce hallucinations in domain-specific reasoning?
- Basis in paper: [explicit] Section 6 (Future Work) explicitly calls for investigating "how these authentic QA pairs can be leveraged to build large-scale training datasets... especially in domains where synthetic data remains unreliable."
- Why unresolved: The paper validates the extraction quality (structure/alignment) but does not conduct training experiments to measure the downstream impact on model reasoning or factual grounding compared to synthetic baselines.
- What evidence would resolve it: A comparative study training LLMs on extracted textbook data versus synthetic data (e.g., Alpaca), measuring hallucination rates and reasoning accuracy on benchmarks.

### Open Question 2
- Question: How can the pipeline be adapted to automatically verify the semantic correctness and difficulty of extracted items for benchmark curation, particularly for non-verifiable question types like proofs?
- Basis in paper: [explicit] Section 6 notes that extracted items often "lack automatically verifiable answers" (like proofs) and outlines a plan to develop a multi-stage curation pipeline for "modeling difficulty, quality, and diversity."
- Why unresolved: The current pipeline focuses on structural extraction and grouping; it lacks a mechanism to assess the pedagogical value or semantic validity of the content it extracts, relying instead on manual filtering for evaluation.
- What evidence would resolve it: An automated filtering mechanism that successfully classifies question types (e.g., filtering out context-dependent or proof-based questions) and correlates extracted content with human-defined difficulty ratings.

### Open Question 3
- Question: Is the semantic reconstruction capability robust when transferring the LLM component from high-performance proprietary models (Gemini-2.5-pro) to smaller, open-source models?
- Basis in paper: [inferred] Section 4.1 specifies the use of Gemini-2.5-pro for semantic parsing "leveraging its robust instruction-following ability," but does not test the pipeline's sensitivity to the choice of LLM.
- Why unresolved: The success of the "Grouping" and "Pairing" stages relies heavily on the LLM's reasoning capacity; it is unknown if the cost-efficiency claims hold if a cheaper, less capable model fails to resolve long-distance dependencies.
- What evidence would resolve it: An ablation study replacing Gemini-2.5-pro with open-source models (e.g., Llama-3 or Qwen-2) to measure the degradation in F1 scores for long-distance QA pairing.

## Limitations

- The pipeline relies on MinerU 2.5, a specific layout-aware OCR tool that is not open-sourced, creating dependency and scalability concerns
- The cross-page pairing mechanism assumes consistent hierarchical metadata (chapter titles, numbering) that may not hold for informal or poorly structured educational materials
- Claims about lower-hallucination benefits compared to synthetic data lack direct empirical comparison and require validation through training experiments

## Confidence

- **High Confidence**: The architectural separation claim (specialized OCR + LLM semantic parsing) is well-supported by cost analysis (0.012 vs 0.046 per question) and performance metrics (F1 > 0.98 for text, > 0.96 for images)
- **Medium Confidence**: The cross-page pairing mechanism works on tested documents, but its generalizability to inconsistent numbering schemes or ambiguous references is unverified
- **Low Confidence**: The claim that extracted data introduces less hallucination than synthetic generation lacks direct evidence—this requires comparative hallucination analysis

## Next Checks

1. **Document diversity stress test**: Apply the pipeline to a dataset containing varied document types (historical scans, informal materials, inconsistent layouts) and measure failure rates to assess robustness beyond the tested educational corpus
2. **Hallucination comparison study**: Generate a synthetic QA dataset of comparable size using an LLM, then conduct a blind human evaluation to compare hallucination rates and diversity between synthetic and extracted datasets
3. **MinerU accessibility audit**: Obtain or replicate MinerU's functionality with alternative layout-aware OCR tools to verify whether the performance claims depend on specific proprietary components or represent a general architectural pattern