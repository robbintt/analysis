---
ver: rpa2
title: 'Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction:
  Benchmark, Insights and Approaches'
arxiv_id: '2601.20307'
source_url: https://arxiv.org/abs/2601.20307
tags:
- label
- prediction
- online
- delayed
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the delayed feedback problem in post-click gross
  merchandise volume (GMV) prediction for online advertising. The challenge is that
  the true GMV, which includes multiple purchases over a time window, is not known
  until well after the click event.
---

# Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches

## Quick Facts
- arXiv ID: 2601.20307
- Source URL: https://arxiv.org/abs/2601.20307
- Reference count: 31
- A new dual-branch model (READER) with a routing mechanism improves GMV prediction accuracy by 2.19% and AUC by 0.86% over strong baselines on a newly constructed benchmark dataset.

## Executive Summary
This paper addresses the delayed feedback problem in post-click gross merchandise volume (GMV) prediction for online advertising, where the true GMV—accumulated from multiple purchases over a time window—is not immediately known. To tackle this, the authors introduce TRACE, a benchmark dataset with complete purchase sequences, and propose READER, a novel dual-branch model that separately models single-purchase and repurchase samples. READER incorporates debiasing strategies such as label calibration and partial label unlearning to handle incomplete labels during online training. Experimental results on TRACE demonstrate significant improvements over strong baselines in both accuracy and ranking quality.

## Method Summary
The authors propose READER, a two-stage approach for delayed feedback GMV prediction. In the first stage, pretraining on historical data with known ground-truth GMV labels, all model components—shared encoder, dual towers (single-purchase and repurchase), sample router, and label calibrator—are trained offline. In the second stage, online learning, partial GMV labels arrive sequentially with each purchase event; the router predicts whether a click will lead to multiple purchases and routes samples to specialized towers via a three-zone scheme, while the calibrator dynamically adjusts regression targets to mitigate underestimation. After the attribution window closes, ground-truth alignment and partial label unlearning are applied to further reduce residual bias.

## Key Results
- READER achieves 2.19% improvement in accuracy (ACC) and 0.86% improvement in AUC over strong baselines on the TRACE benchmark.
- The sample router achieves >80% AUC in predicting repurchase likelihood, confirming the distributional discrepancy between single-purchase and repurchase samples.
- Ablation studies show that both the hybrid routing mechanism and label calibration contribute to performance gains, with PLU further reducing average log relative error (ALPR).

## Why This Works (Mechanism)

### Mechanism 1: Repurchase-Aware Dual-Branch Routing
- Claim: Separate modeling of single-purchase and repurchase samples improves GMV prediction accuracy.
- Mechanism: A router predicts whether an ad click will lead to multiple purchases (probability `r`). Samples are routed to specialized expert towers via a three-zone scheme: low-confidence (`r ≤ 0.1`) → single-purchase tower; high-confidence (`r ≥ 0.9`) → repurchase tower; ambiguous → weighted interpolation of both outputs. This allows each tower to specialize on distinct label distributions.
- Core assumption: The feature space contains sufficient signal to predict repurchase likelihood before the final GMV is observed.
- Evidence anchors:
  - [abstract]: "the label distribution of repurchase samples substantially differs from that of single-purchase samples, highlighting the need for separate modeling"
  - [section 3.3.2]: Two-sample Kolmogorov–Smirnov test yields p-value of 0.00, confirming distributional discrepancy; router achieves >80% AUC on held-out test data
  - [corpus]: Weak direct support. Corpus focuses on CTR prediction, budget allocation, and bidding—not GMV delayed feedback. No comparable dual-branch repurchase routing.
- Break condition: If router accuracy falls below chance-level, routing adds noise; expect degradation vs. single-tower baseline.

### Mechanism 2: Label Calibration for Partial Observations
- Claim: Calibrating observed partial GMV labels toward estimated final GMV reduces systematic underestimation during online training.
- Mechanism: A label calibrator network takes features `x`, elapsed time `Δt`, and observed purchase count `N_t` to predict the log-gap `δ = log(1+y*) - log(1+y(t))`. The calibrated pseudo-label `ỹ(t) = exp(log(1+y(t)) + δ̂) - 1` replaces raw partial labels for the repurchase tower, providing closer-to-ground-truth supervision.
- Core assumption: The gap between partial and final GMV follows a learnable function of time, purchase count, and features.
- Evidence anchors:
  - [abstract]: "READER dynamically calibrates the regression target to mitigate under-estimation caused by incomplete labels"
  - [section 3.3.1]: Only 40% of final GMV realized at first purchase; 60%+ after 1 day; early-stage labels severely underestimate
  - [section 5.3.1]: Ablation shows calibrator alone improves AUC (+0.0019) and substantially reduces ALPR
  - [corpus]: No corpus papers address GMV label calibration for delayed feedback. Analogous bias-correction appears in CVR delayed feedback work, but not for continuous regression targets.
- Break condition: If elapsed time or purchase count provide little predictive signal for the gap, calibrator may introduce noise; monitor ALPR on held-out repurchase samples.

### Mechanism 3: Partial Label Unlearning + Ground-Truth Alignment
- Claim: After the attribution window closes, combining ground-truth fitting with explicit unlearning of inflated pseudo-labels reduces residual bias.
- Mechanism: When `y*` becomes available, perform Ground-Truth Alignment (GRA) using `y*` as target. Then apply Partial Label Unlearning (PLU) by *maximizing* the loss against the last calibrated pseudo-label `ỹ(t_N^p)`, which tends to overestimate `y*`. This counteracts label inflation while preserving patterns from earlier updates.
- Core assumption: The calibrator's correction at the last purchase systematically overshoots ground truth; unlearning corrects this without erasing useful learning.
- Evidence anchors:
  - [section 4.2.2]: "PLU prevents the label inflation in the last purchase from misleading the training process"
  - [section 5.3.1]: Adding PLU on top of Calib+GRA yields best ACC (0.2612) and lowest ALPR (0.7523), with no AUC loss
  - [corpus]: No corpus evidence for unlearning strategies in delayed feedback; concept is novel to this GMV setting.
- Break condition: If PLU weight `λ₂` is too aggressive, model may unlearn valid signal; tune `λ₂` and monitor held-out metrics.

## Foundational Learning

- Concept: **Delayed Feedback in Conversion Modeling**
  - Why needed here: GMV prediction inherits the delayed feedback problem from CVR—labels arrive after attribution window—but with added complexity of cumulative, continuous targets.
  - Quick check question: Can you explain why using partial labels directly causes systematic underestimation in online training?

- Concept: **Mixture-of-Experts / Multi-Branch Routing**
  - Why needed here: READER uses a router to select between expert towers; understanding soft vs. hard routing, and interpolation zones, is essential for debugging.
  - Quick check question: What happens to gradients in the "hybrid" routing zone when `τ₁ < r < τ₂`?

- Concept: **Machine Unlearning Basics**
  - Why needed here: PLU draws from unlearning literature—maximizing loss on specific samples to reverse their influence.
  - Quick check question: How does unlearning differ from simply excluding a sample from training?

## Architecture Onboarding

- Component map:
  - Shared Encoder (`f_θ`) -> Single-Purchase Tower (`f_S`) and Repurchase Tower (`f_R`)
  - Sample Router (`φ`) -> outputs repurchase probability `r`
  - Label Calibrator (`ψ`) -> outputs log-gap `δ̂`
  - Training Orchestrator -> manages two-stage regime and loss aggregation

- Critical path:
  1. **Pretraining**: Train all components on historical data with complete labels (`y*` known). Router trained on `N>1` binary label; calibrator trained on repurchase subset.
  2. **Online Learning**: For each incoming purchase event:
     - Router predicts `r`; route sample per (5).
     - Calibrator generates `δ̂`; compute calibrated label `ỹ(t)`.
     - Update predictor and router via `L_online`.
  3. **Attribution Window Close**: Apply GRA + PLU using `y*`.

- Design tradeoffs:
  - **Hard vs. Hybrid Routing**: Hard routing (`r<0.5 → S, else R`) is simpler but degrades all metrics (Table 7). Hybrid routing with interpolation zones handles uncertainty.
  - **Shared-Bottom vs. Independent Towers**: Shared-bottom allows knowledge transfer; independent towers isolate but require more data (Table 6).
  - **Online Calibrator Updates**: Paper freezes calibrator online (footnote 2); updating yielded marginal gains but adds complexity.

- Failure signatures:
  - **Router collapse**: If `r` saturates near 0 or 1 for all samples, one tower receives no data → underfit. Check `r` distribution.
  - **Calibrator overfit**: If calibrator overestimates gaps, `ỹ(t)` inflates → ALPR increases. Monitor calibrator MAE on validation.
  - **PLU overcorrection**: If `λ₂` too high, model oscillates between GRA and PLU → training instability, divergent loss.

- First 3 experiments:
  1. **Replicate Online-Single vs. Offline-Single**: Verify online training advantage on TRACE subset. Confirm AUC gap (~0.011) per Table 3.
  2. **Ablate Router**: Replace hybrid routing with hard routing; expect ACC drop (~0.0024) per Table 7.
  3. **Ablate Calibrator**: Disable calibration on repurchase tower; expect ALPR increase and AUC drop per Table 5.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can more advanced routing strategies be developed to further improve the performance of repurchase-aware dual-branch models?
- Basis in paper: [explicit] The authors state in Section 5.3.3 that "developing more advanced routing strategies is a promising direction for future improvement."
- Why unresolved: The paper only compared hard routing against a specific hybrid routing strategy with fixed zones, leaving potential improvements via dynamic or attention-based gating unexplored.
- What evidence would resolve it: A new routing mechanism that achieves statistically significant performance gains over the proposed hybrid routing on the TRACE benchmark.

### Open Question 2
- Question: Is it possible to train the sample router and the GMV predictor jointly without suffering from gradient entanglement?
- Basis in paper: [inferred] Section 4.1.2 states the router is fully decoupled because "joint learning the routing decision with GMV regression causes gradient entanglement and inter-tower interference."
- Why unresolved: The current design prioritizes stability over end-to-end optimization; it remains unknown if techniques exist to disentangle these gradients for a unified model.
- What evidence would resolve it: An architectural modification or loss function that allows the router to be trained jointly with the predictor while maintaining convergence stability and prediction accuracy.

### Open Question 3
- Question: Do dynamic or learnable routing thresholds outperform the fixed thresholds ($\tau_1=0.1, \tau_2=0.9$) utilized in the hybrid routing mechanism?
- Basis in paper: [inferred] Section 4.1.3 sets $\tau_1$ and $\tau_2$ to fixed constants without an ablation study on these values or a discussion on adapting them to different data distributions.
- Why unresolved: It is unclear if these specific thresholds are optimal for all traffic patterns or if they should adapt to the evolving label distribution mentioned in Section 3.3.1.
- What evidence would resolve it: An ablation study demonstrating that learnable thresholds adapt to temporal shifts and improve AUC/ACC compared to the static configuration.

## Limitations

- **Dataset Generalization:** TRACE is constructed from Alibaba Taobao traffic. Its feature distributions, user behavior patterns, and purchase dynamics may not transfer to other e-commerce or advertising platforms. The empirical gains of READER hinge on specific label distributions (high proportion of multi-purchase events) and attribution-window assumptions (7 days). No external validation on independent delayed-feedback GMV datasets is provided.

- **Hyperparameter Sensitivity:** Key thresholds (τ₁=0.1, τ₂=0.9), calibration and unlearning weights (λ₁=0.1, λ₂=0.5), and network architectures are fixed without systematic sensitivity analysis. Performance could degrade if optimal values differ in other domains or if pretraining data differs in scale or quality.

- **Offline Evaluation Constraints:** All comparisons use held-out historical data with known final GMV. Online A/B testing results are not reported, leaving uncertainty about real-world impact and whether model complexity justifies operational overhead.

## Confidence

- **Mechanism 1 (Dual-Branch Routing):** Medium confidence. Evidence (KS test, router AUC) supports distributional discrepancy and learnability, but ablation impact (~0.24% ACC gain) is modest. No comparison to more sophisticated routing or mixture-of-experts baselines.
- **Mechanism 2 (Label Calibration):** Medium confidence. Ablation shows consistent improvement in ALPR and AUC; however, calibration gains depend on quality of the calibrator training set and may not generalize.
- **Mechanism 3 (Partial Label Unlearning):** Low confidence. Concept is novel and ablation shows benefit, but the rationale for maximizing loss on the final calibrated label is heuristic; no theoretical justification or robustness check against over-aggressive unlearning.

## Next Checks

1. **Cross-Dataset Validation:** Apply READER to a delayed-feedback GMV or conversion-value dataset from a different platform (e.g., public e-commerce logs, other DSPs). Compare performance retention to TRACE results; test distributional robustness of router and calibrator.

2. **Router and Calibration Ablation under Varying Delay:** Systematically vary the attribution window length (e.g., 3, 7, 14 days) and measure the degradation in router accuracy and calibrator MAE. Identify at which point routing or calibration ceases to provide benefit.

3. **Online A/B Test Simulation:** Implement a counterfactual policy evaluation using historical TRACE logs to simulate online serving of READER vs. baselines. Measure lift in GMV and ROI under realistic latency and feedback-delay constraints.