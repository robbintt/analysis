---
ver: rpa2
title: 'Riemannian Lyapunov Optimizer: A Unified Framework for Optimization'
arxiv_id: '2601.22284'
source_url: https://arxiv.org/abs/2601.22284
tags:
- learning
- direction
- optimization
- target
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Riemannian Lyapunov Optimizers (RLOs), a unified
  geometric framework for understanding and designing optimization algorithms. The
  key innovation is reinterpreting optimization as a closed-loop controlled dynamical
  system evolving on a Riemannian manifold, with the Normally Attracting Invariant
  Manifold (NAIM) serving as the geometric skeleton organizing training dynamics into
  fast residual alignment and slow manifold evolution.
---

# Riemannian Lyapunov Optimizer: A Unified Framework for Optimization

## Quick Facts
- arXiv ID: 2601.22284
- Source URL: https://arxiv.org/abs/2601.22284
- Reference count: 40
- Primary result: RLO-Λ achieves 73.98% ImageNet top-1 accuracy on ResNet-50, outperforming AdamW (73.87%) and Lion

## Executive Summary
This paper introduces Riemannian Lyapunov Optimizers (RLOs), a geometric framework that unifies understanding and design of optimization algorithms. The key insight is reinterpreting optimization as a controlled dynamical system on a Riemannian manifold, where training dynamics organize around a Normally Attracting Invariant Manifold (NAIM). The framework recovers existing optimizers (SGD, Adam, Lion) as special cases while enabling principled design of new algorithms through component choices of manifold geometry, direction field, and fiber contraction rate.

## Method Summary
RLOs treat optimization as a closed-loop control system where parameter updates follow a Riemannian trajectory toward a target manifold Λ defined by a direction field Φ. The method uses a strict Lyapunov function V = f(θ) - f* + (α/h_k)‖z‖²_g to certify convergence, where z = v - Φ(y, gradf) is the alignment residual. A backstepping controller synthesizes control input u = ∇̇Φ - λ·gradf - (1/τ)z to make V̇ < 0, which discretizes to the RLO algorithm. Three variants are proposed: RLO (simple gradient-based), RLO-Λ (uses tanh saturation), and RLO-Lifted (adds fiber contraction parameter η < 1).

## Key Results
- RLO-Λ achieves 73.98% top-1 accuracy on ImageNet ResNet-50 vs 73.87% for AdamW and 71.42% for Lion
- RLO variants show 16+ percentage point advantages over AdamW in early convergence on vision transformers
- Factorial ablation studies demonstrate global normalization provides learning rate adaptation but is not the primary source of efficacy
- Sign-based optimizers (Lion, RLO variants) achieve 91.2-91.9% accuracy on CIFAR-10 with appropriate normalization
- RLO-Lifted (η=0.7) excels on large ViT-B/16 (76.47%) but underperforms on smaller ViT-S/16 (71.43%)

## Why This Works (Mechanism)

### Mechanism 1: Two-Time-Scale Separation via NAIM
The system defines a target manifold Λ = {(θ, v) : v = Φ(y, gradf)} where velocity should match a constructed direction field. A "thick tube" dynamics emerges: fast fiber contraction (controlled by η) aligns velocity v → d, while slow drift along Λ performs actual optimization. The residual z = v - d contracts exponentially as z_{k+1} ≈ (1-η_k)z_k. This separation ensures stable optimization by decoupling rapid alignment from slow parameter descent.

### Mechanism 2: Lyapunov-Certified Control Synthesis
A strict Lyapunov function V = f(θ) - f* + (α/h_k)‖z‖²_g provides convergence certification and guides control law design via Riemannian backstepping. The control input u = ∇̇Φ - λ·gradf - (1/τ)z is synthesized to make V̇ < 0, canceling destabilizing cross-coupling ⟨gradf, z⟩_g while injecting dissipation. Discretization yields the fiber contraction update ṽ_{k+1} = (1-η_k)v_k + η_k d_k. Under PL conditions, V contracts linearly to a noise floor ∝ ‖δ_k‖².

### Mechanism 3: Optimizer Instantiation via Geometric Components
Classic optimizers (SGD, AdamW, Lion) emerge as specific instantiations of (M, g, Φ, Ψ, η). The metric g defines geometry (Euclidean vs. adaptive diagonal), Φ defines the target manifold (gradient graph, hypercube corners via sign, smooth saturation via tanh), Ψ updates internal state (momentum EMA, second-moment estimates), and η sets contraction rate. AdamW ↔ adaptive metric g_k = diag(√s_k)^{-1}, Φ = momentum; Lion ↔ Φ = sign(m), η = 1.

## Foundational Learning

- **Riemannian Manifolds, Tangent Spaces, Retraction, Vector Transport**
  - Why needed here: The entire framework is built on optimization over M with metric g. Understanding how tangent vectors move between tangent spaces (via T) and map back to the manifold (via R) is essential for interpreting the update rules.
  - Quick check question: Given a point θ ∈ M and a tangent vector ξ ∈ T_θM, explain what R_θ(ξ) and T_{θ→φ}(ξ) compute and why both are needed for iterative optimization.

- **Lyapunov Stability and Strict Lyapunov Functions**
  - Why needed here: The core theoretical contribution is a strict Lyapunov function V certifying convergence. Understanding V̇ < 0 as a stability certificate—and why "strict" matters for discrete-time systems—is critical.
  - Quick check question: What does it mean for V to be a strict Lyapunov function in discrete time? How does the PL condition enable linear convergence rates?

- **Nonlinear Control / Backstepping**
  - Why needed here: The control law u is derived via Riemannian backstepping, treating velocity v as a virtual control and residual z as tracking error. Familiarity with cascaded control design clarifies why the control law has feedforward, descent coupling, and dissipation terms.
  - Quick check question: In backstepping, why is the cross-term ⟨gradf, z⟩_g problematic for stability, and how does the control law design eliminate it?

## Architecture Onboarding

- **Component map:** M (Manifold) → g (Metric) → Φ (Direction Field) → Ψ (State Transition) → η (Lifting Parameter) → Global Normalization
- **Critical path:**
  1. Compute gradient g_k
  2. Geometric Phase: Ψ updates internal state → Φ constructs target direction d_k
  3. Dynamic Phase: Fiber contraction ṽ_{k+1} = (1-η)v_k + η d_k → retraction θ_{k+1} = R(-h_k ṽ_{k+1}) → vector transport v_{k+1}
  4. Hyperparameter schedule for h_k, η_k

- **Design tradeoffs:**
  - η near 1 vs. η < 1: η=1 eliminates residual (fast tracking, less smoothing); η<1 provides inertial regularization but may slow adaptation
  - Smooth vs. discontinuous Φ: Smooth Φ (tanh) more stable without global normalization; discontinuous (sign) comparable with normalization but fragile otherwise
  - Global normalization: Automatic LR scaling (~100× for ResNet-18) but introduces sensitivity; disabling requires manual LR tuning but more predictable behavior

- **Failure signatures:**
  - Learning rate mismatch with normalization: GN enabled with large LR → divergence; GN disabled with small LR → near-random performance
  - Discontinuous Φ without normalization: Severe final-accuracy degradation with high loss variance
  - Small η on small models: RLO-Lifted (η=0.7) underperforms on ViT-S/16 due to over-smoothing

- **First 3 experiments:**
  1. Validate NAIM mechanism: Replicate factorial ablation on your architecture with η ∈ {0.7, 1.0} × {GN enabled, disabled}, confirming the ~100× LR shift and modest performance gap when each variant uses optimal LR.
  2. Characterize Φ smoothness: Compare tanh vs. sign direction fields with GN disabled to verify smooth Φ provides robustness; measure training loss variance as stability indicator.
  3. Establish η sensitivity for your model scale: Run η sweep {0.3, 0.5, 0.7, 0.9, 1.0} to determine if your model benefits from inertial smoothing (larger models) or fast tracking (smaller models).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal lifting parameter $\eta$ theoretically depend on model capacity or the geometric properties of the loss landscape?
- Basis in paper: Section 6.1 observes that RLO-Lifted performs well on ViT-B/16 but poorly on ViT-S/16, noting that "the optimal lifting parameter $\eta$ may depend on model capacity in ways that warrant further investigation."
- Why unresolved: While Appendix H.3 empirically confirms that smaller models prefer $\eta \approx 1.0$, the paper does not provide a theoretical mechanism linking model scale to the required fiber contraction rate.
- What evidence would resolve it: A theoretical analysis deriving optimal $\eta$ as a function of loss landscape curvature or noise variance, or the derivation of an adaptive $\eta$ law within the Lyapunov framework.

### Open Question 2
- Question: Can the RLO framework provide convergence guarantees for general non-convex functions without relying on the Polyak-Lojasiewicz (PL) condition?
- Basis in paper: Theorem 3.1 establishes linear convergence and uniform ultimate boundedness "If, in addition, $f$ satisfies the Polyak-Lojasiewicz (PL) condition," which is a strong assumption that may not hold for general deep learning tasks.
- Why unresolved: The stability (boundedness) is guaranteed under weaker smoothness assumptions, but the convergence rate guarantees explicitly depend on the PL condition, leaving the behavior in highly non-convex settings theoretically open.
- What evidence would resolve it: A convergence proof for RLO under generic non-convexity or empirical density measurements showing RLO trajectories satisfy PL-like conditions locally even when global PL is absent.

### Open Question 3
- Question: Does the geometric formulation of RLO provide performance benefits when optimizing on non-Euclidean manifolds compared to standard adaptive methods?
- Basis in paper: The paper title and Section 2 define the optimizer using Riemannian concepts (retractions, vector transport), yet all experimental validation (ImageNet, ResNet, ViT) is conducted in Euclidean space where these operators are trivial.
- Why unresolved: It is unclear if the "unified geometric principle" translates to computational advantages or improved convergence when the parameter manifold $\mathcal{M}$ is strictly non-Euclidean (e.g., in constrained optimization or hyperbolic networks).
- What evidence would resolve it: Comparative benchmarks of RLO against standard Riemannian optimization algorithms (like Riemannian Adam) on tasks involving non-trivial manifold constraints.

## Limitations
- Theoretical scope is limited to PL-condition functions; convergence guarantees don't extend to general non-convex landscapes
- Sign-based optimizers show significant instability without global normalization, limiting practical deployment
- Hyperparameter sensitivity requires careful tuning of η, γ, λb, and per-model LR/WD schedules

## Confidence
- **High Confidence:** The geometric framework correctly unifies existing optimizers (SGD, AdamW, Lion) as special cases of (M, g, Φ, Ψ, η)
- **Medium Confidence:** Empirical ImageNet results show RLO-Λ outperforms AdamW and Lion, but gains are modest (1-2 percentage points)
- **Low Confidence:** The claim that RLO provides a "unified framework for understanding and designing optimization algorithms" is aspirational; framework hasn't been validated beyond vision tasks

## Next Checks
1. Stress-test NAIM stability: Systematically vary η and disable global normalization on ResNet-50 ImageNet training, measuring tube thickness ‖v-d‖ and training loss variance
2. Scale sensitivity validation: Replicate the η sweep (0.3-1.0) across model scales (ViT-S/16, ViT-B/16, ResNet-50) to verify hypothesis about inertial smoothing benefits
3. Cross-task generalization: Apply RLO-Λ to non-vision task (e.g., masked language modeling with BERT) to test framework benefits beyond vision domain