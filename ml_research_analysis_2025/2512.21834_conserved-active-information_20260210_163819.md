---
ver: rpa2
title: Conserved active information
arxiv_id: '2512.21834'
source_url: https://arxiv.org/abs/2512.21834
tags:
- information
- active
- system
- search
- theory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces conserved active information (I \u2295),\
  \ a symmetric extension of active information that quantifies net information gain/loss\
  \ across the entire search space while respecting No-Free-Lunch conservation principles.\
  \ The method addresses the limitation of active information (AIN) and Kullback-Leibler\
  \ (KL) divergence, which only measure local information changes without accounting\
  \ for global system organization."
---

# Conserved active information

## Quick Facts
- arXiv ID: 2512.21834
- Source URL: https://arxiv.org/abs/2512.21834
- Reference count: 40
- Primary result: Introduces conserved active information (I⊕) as a symmetric measure that quantifies net information gain/loss across entire search spaces while respecting No-Free-Lunch conservation principles.

## Executive Summary
This paper introduces conserved active information (I⊕), a symmetric extension of active information that quantifies net information gain or loss across entire search spaces rather than just local target regions. The measure addresses limitations of Kullback-Leibler divergence and standard active information by capturing how ordered or disordered the entire system becomes when transitioning from baseline to improved distributions. The authors establish three distinct information regimes - harmful, mild, and strong knowledge - under uniform baseline conditions, providing a framework for understanding information redistribution in search and optimization problems.

## Method Summary
The method defines conserved active information as I⊕ = H(X₂) - H(X₁), where H represents total information computed as the integral of log(p₁(x)/p₂(x)) over the entire search space. This differs from KL divergence by being potentially positive, negative, or zero, allowing detection of three regimes based on target probability relationships: q < p < 0.5 (harmful), p ≤ q ≤ 1-p (mild), and q > 1-p (strong). The approach leverages No-Free-Lunch conservation principles, showing that target improvements must be balanced by system-wide information changes. For Bernoulli cases, I⊕ simplifies to log(p/q) + log((1-p)/(1-q)), enabling analytical study of regime boundaries.

## Key Results
- Theorem 3 formally establishes three information regimes under uniform baseline conditions based on target probability relationships.
- When q < p, I⊕ > 0 indicating increased system order despite target difficulty.
- When p ≤ q ≤ 1-p, I⊕ ≤ 0 showing target ease at system disorder cost.
- Active information tensorizes for product spaces, enabling tractable high-dimensional computation.

## Why This Works (Mechanism)

### Mechanism 1: Global-Local Information Decomposition
- Claim: Conserved active information (I⊕) reveals information regimes hidden from KL divergence by measuring total system information change rather than target-local changes.
- Mechanism: I⊕ = H(X₂) - H(X₁) = ∫_X log(p₁(x)/p₂(x)) dμ computes the net information difference across the entire search space. Unlike KL divergence (always non-negative), I⊕ can be positive, negative, or zero, distinguishing three regimes: harmful (q < p < 0.5, I⊕ > 0), mild (p ≤ q ≤ 1-p, I⊕ ≤ 0), and strong (q > 1-p, I⊕ > 0).
- Core assumption: The baseline P₁ is uniform (maxent) and the target T satisfies |T| ≪ |X|/2.
- Evidence anchors:
  - [abstract] "We introduce conserved active information I⊕, a symmetric extension of active information that quantifies net information gain/loss across the entire search space, respecting No-Free-Lunch conservation."
  - [Section III, Theorem 3] Formal establishment of three regimes under uniform baseline with conditions on q relative to p and 1-p.
  - [corpus] Weak direct evidence; neighbor papers focus on active learning variants rather than information-theoretic search measures.
- Break condition: Non-uniform baseline distributions violate Theorem 3's regime boundaries; continuous spaces require Radon-Nikodym derivatives.

### Mechanism 2: Conservation Principle via Order-Disorder Trade-off
- Claim: When I⊕ < 0, information redistributes internally (no external input needed); when I⊕ > 0, external information infusion is required to sustain the system.
- Mechanism: The No-Free-Lunch theorems imply gains on target T must be offset by losses elsewhere. I⊕ = I+(T) + I+(T^c) captures this balance. In the mild knowledge regime (p ≤ q ≤ 1-p), target ease comes at system disorder cost (I⊕ ≤ 0). In the strong knowledge regime (q > 1-p), both target and system improve (I⊕ > 0), indicating external "work."
- Core assumption: Information behaves analogously to thermodynamic free energy—conserved in closed systems but improvable with external input.
- Evidence anchors:
  - [Section III, Corollary 4] "If I+ < 0, then I⊕ > 0. On the other hand, if I+ > 0, then I⊕ > 0 only when q > 1-p."
  - [Section IV, Discussion] Thermodynamic analogy: "Positive conserved active information signals an infusion of external 'work' (problem-specific knowledge), reducing global disorder."
  - [corpus] Weak; no corpus papers address thermodynamic analogies or NFL-based conservation.
- Break condition: Open systems with uncontrolled external inputs violate the conservation assumption; multi-target optimization may not decompose cleanly.

### Mechanism 3: AIN Tensorization Enables High-Dimensional Decomposition
- Claim: Active information tensorizes, enabling tractable computation in product spaces where naive probability differences fail.
- Mechanism: For n-dimensional product spaces with independent measures, I+(A₁ × ... × Aₙ) = Σᵢ I+(Aᵢ). This additive property makes AIN preferable to P₂(A) - P₁(A) for high-dimensional search spaces common in machine learning and optimization.
- Core assumption: Component measures are independent and factorable.
- Evidence anchors:
  - [Section II, Property P3] "AIN tensorizes. That is, for an n-dimensional Cartesian product A = A₁ × ··· × Aₙ... log[P₂(A)/P₁(A)] = Σᵢ log[P₂ᵢ(Aᵢ)/P₁ᵢ(Aᵢ)]."
  - [Section II] Explicit comparison: property P3 makes AIN desirable over P₂(A) - P₁(A) which does not tensorize.
  - [corpus] Weak; corpus papers on active learning do not address tensorization properties.
- Break condition: Non-independent component measures; non-Cartesian search space structures.

## Foundational Learning

- Concept: **Kullback-Leibler (KL) Divergence**
  - Why needed here: The paper positions I⊕ as revealing information hidden from KL; understanding KL's non-negativity and asymmetry is prerequisite.
  - Quick check question: Can you explain why KL(P₂ ∥ P₁) ≥ 0 always, and why it cannot order distributions?

- Concept: **Active Information (I+)**
  - Why needed here: I⊕ extends AIN; you must understand I+ = log(P₂(T)/P₁(T)) before grasping the global extension.
  - Quick check question: Given baseline P₁(T) = 0.1 and improved P₂(T) = 0.4, what is the active information I+(T)?

- Concept: **No-Free-Lunch Theorems**
  - Why needed here: The conservation principle motivating I⊕ derives from NFL theorems about average search performance.
  - Quick check question: Why does NFL imply that outperforming random search on some problems requires underperforming on others?

## Architecture Onboarding

- Component map: P₁ (baseline) -> P₂ (alternative) -> I⊕ calculator -> Regime classifier
- Critical path: Verify uniform baseline → compute p = P₁(T) → compute q = P₂(T) → check regime boundaries (q < p, p ≤ q ≤ 1-p, q > 1-p) → compute I⊕ → interpret conservation vs. infusion requirement
- Design tradeoffs:
  - Symmetry vs. directionality: I⊕(P₁, P₂) ≠ I⊕(P₂, P₁) in general; regime interpretation depends on which distribution is baseline
  - Uniform baseline simplification: Theorem 3 assumes maxent baseline; non-uniform baselines require custom regime analysis
  - Continuous vs. discrete: Radon-Nikodym derivatives required for continuous X; numerical integration may be needed
- Failure signatures:
  - I⊕ computation returns NaN: Check for P₁(x) = 0 where P₂(x) > 0 (support mismatch)
  - Regime classification contradicts I+ sign: Verify p = P₁(T) computed correctly under uniform assumption
  - I⊕ doesn't sum to zero across partition: Check measure-theoretic consistency; Lemma 1 extension may be incomplete
- First 3 experiments:
  1. **Bernoulli validation**: Implement Example 2 with X = {0,1}, varying p ∈ (0,1) and q ∈ (0,1); verify saddle surface matches Fig. 3 and I⊕ = 0 at q ∈ {p, 1-p}
  2. **Markov chain convergence test**: Implement Example 3 with d-regular graph random walk; verify stationary distribution achieves q = |T|/|X| in mild knowledge regime with I⊕ ≤ 0
  3. **Regime boundary stress test**: For uniform baseline with varying |T|/|X| from 10⁻⁶ to 0.4, sweep q/p ratios and confirm I⊕ sign transitions at q = p and q = 1-p boundaries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can conserved active information I⊕ be formally connected to thermodynamic quantities (e.g., free energy, entropy production) to characterize far-from-equilibrium systems?
- Basis in paper: [explicit] The authors state "a natural extension of conserved active information is its thermodynamic implications, where analogies between information theory and thermodynamics are particularly fruitful."
- Why unresolved: The paper proposes replacing "information" with "energy" but provides only informal analogies rather than rigorous mathematical connections.
- What evidence would resolve it: A formal theorem linking I⊕ to specific thermodynamic quantities, with empirical validation on physical systems.

### Open Question 2
- Question: Can the ability to achieve the "strong knowledge" regime (q > 1-p with I⊕ > 0) autonomously serve as a necessary condition for artificial general intelligence (AGI)?
- Basis in paper: [explicit] The authors conjecture that "true AGI could be characterized by the machine's autonomous ability... to transition into the 'strong knowledge' regime... without external scaffolding."
- Why unresolved: This is presented as a conjecture without formal proof or empirical validation on existing AI systems.
- What evidence would resolve it: Empirical measurement of I⊕ across diverse LLM architectures on standardized tasks, showing correlation with independent AGI benchmarks.

### Open Question 3
- Question: How do the three regimes of I⊕ generalize to non-uniform baseline distributions P₁?
- Basis in paper: [inferred] Theorem 3 establishes regimes explicitly "under uniform baseline" with P₁ ~ U(N). No results are provided for non-maxent baselines.
- Why unresolved: Many real-world search problems have structured baseline knowledge that is non-uniform, yet the theoretical framework only covers the uniform case.
- What evidence would resolve it: A generalized theorem characterizing I⊕ regimes under arbitrary P₁, with examples showing qualitative differences from the uniform case.

## Limitations
- Theorem 3's regime classification only applies under uniform baseline assumptions, limiting real-world applicability.
- The strong knowledge regime requiring external "work" remains theoretical without experimental validation across diverse problem domains.
- No formal bounds or decision rules are derived for when bias crosses from "mild" to "strong knowledge" requiring intervention.

## Confidence
- **High Confidence**: The mathematical derivation of I⊕ = H(X₂) - H(X₁) and its relationship to KL divergence is well-established through Lemma 1 and Proposition 2.
- **Medium Confidence**: The three-regime classification (harmful, mild, strong) is formally proven for uniform baselines but requires empirical validation for non-uniform cases.
- **Medium Confidence**: The thermodynamic analogy and conservation principle interpretation are conceptually sound but lack quantitative experimental support.

## Next Checks
1. **Non-uniform baseline validation**: Test Theorem 3's regime boundaries when P₁ is not uniform (e.g., Gaussian baseline) to identify regime prediction accuracy degradation.
2. **High-dimensional tensorization test**: Implement n-dimensional product space examples to verify the additive property of active information and assess computational tractability for large n.
3. **Real-world search optimization**: Apply I⊕ to benchmark optimization problems (e.g., Rastrigin, Ackley functions) to measure practical utility beyond theoretical regimes.