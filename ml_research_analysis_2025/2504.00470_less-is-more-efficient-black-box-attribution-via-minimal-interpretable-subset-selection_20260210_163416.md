---
ver: rpa2
title: 'Less is More: Efficient Black-box Attribution via Minimal Interpretable Subset
  Selection'
arxiv_id: '2504.00470'
source_url: https://arxiv.org/abs/2504.00470
tags:
- attribution
- insertion
- methods
- score
- regions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of efficient black-box attribution
  by reformulating it as a submodular subset selection task. The proposed method,
  LIMA, introduces a novel submodular function that evaluates subset importance based
  on semantic consistency, collective effect, model confidence, and regional effectiveness.
---

# Less is More: Efficient Black-box Attribution via Minimal Interpretable Subset Selection

## Quick Facts
- **arXiv ID:** 2504.00470
- **Source URL:** https://arxiv.org/abs/2504.00470
- **Reference count:** 40
- **One-line primary result:** LIMA achieves state-of-the-art attribution faithfulness, with 36.3% higher Insertion and 39.6% higher Deletion AUC than baselines, while being 1.6× faster.

## Executive Summary
This paper addresses the efficiency challenge in black-box attribution by reformulating it as a submodular subset selection problem. The proposed method, LIMA, introduces a novel composite submodular function that evaluates subset importance based on semantic consistency, collective effect, model confidence, and regional effectiveness. A bidirectional greedy search algorithm is designed to efficiently rank input sub-regions, achieving state-of-the-art attribution faithfulness while significantly improving computational efficiency. Experiments across eight foundation models and six datasets demonstrate LIMA's effectiveness in identifying critical input regions and explaining model prediction errors.

## Method Summary
LIMA reformulates black-box attribution as a submodular subset selection task, where the goal is to identify the most influential input regions. The method uses a bidirectional greedy search algorithm to efficiently rank sub-regions based on a composite submodular function that combines semantic consistency, collaboration, confidence, and effectiveness scores. The search process simultaneously identifies the most important regions (forward search) and the least important regions (reverse search), reducing computational complexity while maintaining attribution accuracy. The approach works with various region division methods (SLICO or SAM) and generalizes across different modalities and model architectures.

## Key Results
- LIMA achieves 36.3% higher Insertion AUC and 39.6% higher Deletion AUC than state-of-the-art baselines
- 1.6× faster than naive greedy search while maintaining or improving attribution quality
- Provides 86.1% higher confidence when explaining model prediction errors across foundation models
- Generalizes well across different modalities and model architectures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reformulating attribution as a submodular subset selection task allows identification of critical input regions with diminishing returns
- **Mechanism:** The submodular property ensures that adding elements to smaller sets yields higher marginal gains, allowing greedy approximation within bounded error without exhaustive search
- **Core assumption:** The importance of input regions exhibits diminishing marginal returns
- **Evidence anchors:** [abstract] "reformulates the attribution of important regions as an optimization problem for submodular subset selection"
- **Break condition:** If feature interactions are highly non-linear such that adding a region decreases the value of previously selected regions

### Mechanism 2
- **Claim:** Bidirectional greedy search improves computational efficiency by simultaneously finding most and least important regions
- **Mechanism:** Maintains forward set (accumulating high-value regions) and reverse set (accumulating low-value candidates), reducing search space significantly
- **Core assumption:** Elements showing minimal marginal gain early are likely globally least important
- **Evidence anchors:** [abstract] "1.6 times faster than naive greedy search"
- **Break condition:** If parameter n_p is too low, algorithm may prematurely discard elements that gain value later

### Mechanism 3
- **Claim:** Composite submodular function captures collective effects better than simple confidence thresholds
- **Mechanism:** Function combines four weighted scores: Consistency, Collaboration, Confidence, and Effectiveness to capture complex interactions
- **Core assumption:** Linear combination is sufficient to model complex non-linear interactions
- **Evidence anchors:** [section] Table 14 shows removing Consistency or Collaboration scores drops Insertion AUC significantly
- **Break condition:** If weights are not tuned for specific model architecture, balance may skew results

## Foundational Learning

- **Concept:** Submodularity and Greedy Optimization
  - **Why needed here:** Core efficiency relies on mathematical property of submodularity and diminishing returns
  - **Quick check question:** If adding feature A to set B yields gain G, will adding feature A to a superset of B yield a gain greater than or less than G?

- **Concept:** Perturbation-based Attribution (Black-box)
  - **Why needed here:** LIMA is framed against baselines like RISE and LIME using masking and output observation
  - **Quick check question:** What is the primary difference between white-box methods (using gradients) and the black-box approach used in this paper?

- **Concept:** Semantic Segmentation vs. Superpixels
  - **Why needed here:** Choice between SAM (semantic) and SLICO (superpixel) fundamentally changes attribution results
  - **Quick check question:** Why might using "semantic" regions lead to better explanations than regular grid patches?

## Architecture Onboarding

- **Component map:** Input Division -> Function Evaluator -> Search Engine -> Scorer
- **Critical path:** The Search Engine loop, specifically the step `arg max F(S_forward U {alpha})` requires querying the black-box model for every candidate region in the current iteration
- **Design tradeoffs:**
  - SLICO vs. SAM: SLICO is faster and controllable; SAM provides better semantic boundaries but risks large mixed regions
  - Speed vs. Accuracy (n_p): Higher n_p increases accuracy but reduces speed
  - Sparsity: Fewer regions increase speed but may miss fine-grained details
- **Failure signatures:**
  - Noisy Attribution: Background context suppression when model relies on context
  - Large Region Suppression: SAM might produce giant masks mixing positive and negative features
  - Slow Inference: Large |V| and high n_p create O(|V|^2) bottleneck
- **First 3 experiments:**
  1. Baseline Efficiency Test: Compare LIMA with Naive Greedy on single GPU for 1.6x speedup verification
  2. Division Ablation: Compare SLICO vs. SAM attribution quality and boundary cleanliness
  3. Misclassification Diagnosis: Verify LIMA highlights ground truth objects with high confidence in model errors

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can SAM integration be optimized to ensure fine-grained detail while maintaining semantic coherence?
- **Basis in paper:** [explicit] Section 6.3.1 observes SAM segments are "too large, lacking fine-grained detail"
- **Why unresolved:** Coarse SAM regions currently degrade Insertion AUC performance
- **What evidence would resolve it:** Dynamic segmentation strategy showing improved Insertion scores over SLICO

### Open Question 2
- **Question:** Can attribution efficiency and accuracy be preserved when scaling to larger sub-region counts for high-resolution inputs?
- **Basis in paper:** [explicit] Section 6.5.4 notes larger sub-regions improve performance but raise execution time
- **Why unresolved:** Bidirectional greedy search faces computational overhead as search space grows
- **What evidence would resolve it:** Algorithmic modification reducing time complexity while maintaining optimality bounds

### Open Question 3
- **Question:** To what extent does manual tuning of weighting factors impact performance across different modalities?
- **Basis in paper:** [inferred] Section 4.2 sets fixed weights based on "experience" without verifying modality-specific optimality
- **Why unresolved:** Relative importance of scores likely varies between spectrograms and natural images
- **What evidence would resolve it:** Sensitivity analysis comparing fixed versus learned weights across multimodal datasets

## Limitations

- Submodularity assumption may not hold for all model architectures with highly non-linear feature interactions
- Bidirectional greedy search effectiveness depends heavily on parameter n_p requiring extensive tuning
- Composite scoring function assumes linear weighting of complex interactions may oversimplify decision boundaries

## Confidence

- **High Confidence:** Computational efficiency improvements (1.6x speedup) and bidirectional greedy search mechanism are well-specified and directly measurable
- **Medium Confidence:** Attribution faithfulness improvements (+36.3% Insertion, +39.6% Deletion) rely on comparison metrics that may vary based on implementation details
- **Low Confidence:** Generalization across modalities and error explanation claims (86.1% higher confidence) require more rigorous validation

## Next Checks

1. **Break Condition Test:** Systematically evaluate LIMA's performance when submodularity assumption is violated by testing on models with known non-monotonic feature interactions
2. **Weight Sensitivity Analysis:** Conduct ablation studies varying the λ weights across different model architectures to identify optimal configurations and assess robustness
3. **Error Explanation Validation:** Collect diverse model misclassifications and verify whether LIMA consistently highlights ground truth objects with high confidence, confirming ability to diagnose model failures