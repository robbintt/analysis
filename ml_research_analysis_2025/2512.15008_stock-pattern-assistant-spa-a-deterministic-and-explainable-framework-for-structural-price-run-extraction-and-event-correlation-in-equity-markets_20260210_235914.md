---
ver: rpa2
title: 'Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for
  Structural Price Run Extraction and Event Correlation in Equity Markets'
arxiv_id: '2512.15008'
source_url: https://arxiv.org/abs/2512.15008
tags:
- event
- runs
- events
- pattern
- structural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Stock Pattern Assistant (SPA), a deterministic
  framework for extracting monotonic price runs, aligning them with public events,
  and generating explainable historical narratives. SPA uses daily OHLCV data and
  a normalized event stream to produce transparent, reproducible structural decompositions
  of equity price movements without relying on hyperparameter tuning or predictive
  modeling.
---

# Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets

## Quick Facts
- arXiv ID: 2512.15008
- Source URL: https://arxiv.org/abs/2512.15008
- Reference count: 13
- Primary result: Deterministic, explainable framework for extracting monotonic price runs and aligning them with public events to generate historical narratives without predictive modeling.

## Executive Summary
This paper introduces the Stock Pattern Assistant (SPA), a deterministic framework for extracting monotonic price runs, aligning them with public events, and generating explainable historical narratives. SPA uses daily OHLCV data and a normalized event stream to produce transparent, reproducible structural decompositions of equity price movements without relying on hyperparameter tuning or predictive modeling. Evaluated on four equities (AAPL, NVDA, SCHW, PGR), SPA consistently generates stable run segmentation and event-contextualized narratives, with ablation studies showing each component—deterministic segmentation, event alignment, and constrained LLM explanation—contributes to interpretability. The framework achieves 100% directional monotonicity in runs versus 75% for a PLR baseline, offering a reproducible, audit-friendly lens for historical market structure analysis.

## Method Summary
SPA extracts maximal contiguous monotonic runs from daily price data using sign-based directional segmentation, ensuring 100% directional monotonicity by construction. Events are temporally aligned to runs via a symmetric window (±δ days, default δ=2). A constrained LLM generates descriptive narratives from structured run summaries, with explicit guardrails forbidding prediction, advice, or causal claims. The framework is deterministic except for LLM phrasing and operates in O(T) time complexity. Inputs include daily OHLCV data and normalized event streams; outputs are segmented runs, event alignments, and compliant historical narratives.

## Key Results
- Achieves 100% directional monotonicity in runs versus 75% for a PLR baseline
- Consistently generates stable run segmentation across AAPL, NVDA, SCHW, PGR
- Ablation studies show each component contributes to interpretability
- Maintains interpretability scores while avoiding predictive modeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sign-based directional segmentation produces 100% monotonic runs by construction.
- Mechanism: Daily price differences are mapped to directional labels (+1, -1, 0). Maximal contiguous intervals with consistent sign become runs. This avoids threshold tuning and ensures platform-invariance.
- Core assumption: Monotonic runs are semantically meaningful units of market structure, not just mathematical artifacts.
- Evidence anchors: [abstract] "achieves 100% directional monotonicity in runs versus 75% for a PLR baseline"; [section 4.2] "Using only the sign of price differences—rather than thresholds, smoothing windows, or statistical filters—ensures determinism"

### Mechanism 2
- Claim: Symmetric temporal windows provide event context without implying causation.
- Mechanism: Each run R_k gets a correlation window W_k = [s_k - δ, e_k + δ]. Events with timestamps in this window are attached. The paper explicitly avoids causal language ("coincided with" not "caused").
- Core assumption: Market-relevant information typically manifests within 1–3 trading days of an event.
- Evidence anchors: [abstract] "attach relevant public events through a symmetric correlation window"; [section 4.4] "SPA does not infer that events cause price movements; the window captures temporal co-occurrence only"

### Mechanism 3
- Claim: Constrained LLM prompts generate compliant historical narratives from structured run summaries.
- Mechanism: A JSON object (ticker, direction, duration, events) is passed to an LLM with a fixed system prompt forbidding prediction, advice, and causal claims. Outputs are descriptive only.
- Core assumption: Prompt constraints reliably suppress unwanted LLM behaviors across diverse inputs.
- Evidence anchors: [section 4.5] "The system prompt explicitly forbids speculation or prediction... narratives must reference only provided fields"; [appendix A] Example outputs show consistent descriptive framing

## Foundational Learning

- Concept: **Monotonic run as an atomic structure**
  - Why needed here: SPA's core unit is a maximal directional segment; understanding maximality and boundary conditions is essential for debugging segmentation.
  - Quick check question: Given prices [100, 102, 103, 101, 99], how many runs exist and what are their directions?

- Concept: **Temporal correlation ≠ causal inference**
  - Why needed here: The framework is designed for regulated environments where causal claims require stricter methodology.
  - Quick check question: An earnings announcement falls within δ = 2 days of a downward run. What can and cannot be concluded?

- Concept: **Guardrailed generation**
  - Why needed here: The explanation layer's compliance value depends on understanding how prompt constraints map to output guarantees.
  - Quick check question: List three types of statements the system prompt explicitly forbids.

## Architecture Onboarding

- Component map: Raw OHLCV -> directional labels -> run boundaries -> aligned events -> structured JSON -> narrative output
- Critical path: Each stage is deterministic except the LLM layer
- Design tradeoffs:
  - Granularity vs. interpretability: Shorter runs capture more structure but increase cognitive load
  - δ-window size: Larger windows capture more events but risk spurious alignments
  - Assumption: The paper does not provide theoretical justification for δ = 2 as optimal
- Failure signatures:
  - MAE > 0 indicates implementation drift or data corruption
  - Non-monotonic runs suggest preprocessing errors in sign assignment
  - LLM outputs containing "will," "should," or "caused" indicate guardrail bypass
- First 3 experiments:
  1. Reproduce run detection on AAPL sample data; verify run count and durations match Table 1
  2. Run ablation comparing full SPA vs. no-event-alignment; confirm interpretability score delta per Figure 6
  3. Test δ-sensitivity: align events with δ ∈ {0, 1, 2, 3, 4} on a single ticker; observe alignment rate trajectory per Appendix D

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the SPA's deterministic run-extraction logic be effectively extended to intraday or tick data to capture microstructure dynamics without succumbing to market noise?
- Basis in paper: [explicit]
- Why unresolved: The current framework and evaluation rely exclusively on daily OHLCV data. The paper explicitly states in the Limitations and Future Work sections that extending SPA to intraday bars requires "careful handling of noise and liquidity effects" which has not yet been implemented or tested.
- What evidence would resolve it: An implementation of SPA using minute-level or tick-level data across various liquidity regimes, demonstrating that the monotonic run segmentation remains robust against bid-ask bounce and high-frequency noise.

### Open Question 2
- Question: Do the deterministic structural runs and event-alignment features generated by SPA provide statistically significant predictive signal when used as inputs for downstream supervised machine learning models?
- Basis in paper: [explicit]
- Why unresolved: The paper strictly positions SPA as a backward-looking, descriptive tool for historical analysis and explicitly denies any forecasting capability. The authors list "integrating SPA with predictive models" as a specific avenue for future work, but no experiments were conducted to validate utility in forecasting.
- What evidence would resolve it: A benchmark experiment where SPA features (run length, event density, directional magnitude) are fed into standard predictive architectures (e.g., Transformers, Gradient Boosting) to measure improvements in forecasting volatility or drawdowns compared to raw price inputs.

### Open Question 3
- Question: How does the stability and interpretability of SPA's segmentation hold up under extreme market crisis regimes compared to the standard volatility periods evaluated in the study?
- Basis in paper: [explicit]
- Why unresolved: The evaluation is limited to a six-month period in 2025. The authors explicitly note in the "Robustness and Threats to Validity" section that this window "does not include crisis conditions" and that behavior may shift during "extreme volatility regimes."
- What evidence would resolve it: A retrospective evaluation of SPA applied to historical crisis periods (e.g., the 2008 Financial Crisis or the COVID-19 market crash) to analyze if the run segmentation fragments excessively or if the event-alignment window remains meaningful during chaotic price action.

### Open Question 4
- Question: Does the use of SPA-generated narratives quantifiably improve the efficiency or accuracy of human analysts in identifying market regimes compared to traditional manual charting?
- Basis in paper: [explicit]
- Why unresolved: The paper relies on an internal rubric for "interpretability scores" rather than external human evaluation. The authors explicitly state that they "have not conducted formal user studies measuring comprehension, workflow efficiency, or preference relative to existing tools."
- What evidence would resolve it: A controlled user study with professional analysts, measuring the time taken to identify historical price drivers and the accuracy of their structural analysis when using SPA versus standard technical analysis toolkits.

## Limitations

- Event data source and granularity not specified, limiting generalizability of alignment results
- No theoretical or empirical justification for default δ = 2 window choice
- LLM guardrail reliability not empirically validated across diverse inputs or versions

## Confidence

- Deterministic run extraction with 100% monotonicity: High confidence
- Interpretability improvement over baseline: Medium confidence
- Event alignment provides meaningful context: Low confidence

## Next Checks

1. Replicate run detection and verify monotonicity on AAPL sample data from Yahoo Finance
2. Test δ-window sensitivity quantitatively by varying δ from 0 to 4 trading days on a single ticker
3. Validate LLM guardrail effectiveness using adversarial test cases with speculative prompts and ambiguous event descriptions