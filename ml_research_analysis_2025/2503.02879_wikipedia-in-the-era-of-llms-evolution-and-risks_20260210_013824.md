---
ver: rpa2
title: 'Wikipedia in the Era of LLMs: Evolution and Risks'
arxiv_id: '2503.02879'
source_url: https://arxiv.org/abs/2503.02879
tags:
- wikipedia
- llms
- pages
- impact
- year
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the impact of large language models (LLMs)
  on Wikipedia through both direct and indirect analyses. Direct effects are assessed
  by analyzing page views, word frequencies, and linguistic style changes across different
  Wikipedia categories.
---

# Wikipedia in the Era of LLMs: Evolution and Risks

## Quick Facts
- arXiv ID: 2503.02879
- Source URL: https://arxiv.org/abs/2503.02879
- Reference count: 40
- Primary result: LLMs have influenced Wikipedia content by approximately 1%-2%, with indirect risks to translation benchmarks and RAG systems

## Executive Summary
This paper investigates how large language models (LLMs) impact Wikipedia through direct content analysis and indirect system effects. The study finds that while LLM influence on Wikipedia is measurable (1%-2% impact on certain categories), it remains relatively limited. However, indirect effects are more concerning: LLM-revised content can inflate machine translation benchmark scores through distributional alignment, and potentially degrade retrieval-augmented generation systems by introducing information loss and semantic drift.

## Method Summary
The research analyzes Wikipedia pages from 8 categories, tracking page views, word frequencies, and linguistic styles from 2020-2025. Direct LLM impact is estimated by comparing word frequency changes in LLM-revised text against baseline frequencies. Indirect effects are examined through simulations: machine translation benchmarks are contaminated with LLM translations to test score inflation, and Wikinews articles are revised by LLMs to evaluate RAG system degradation. The study uses GPT-4o-mini and Gemini-1.5-Flash for revisions, and tests with NLLB, mT5, and Helsinki-NLP MT models plus BERT+FAISS for retrieval.

## Key Results
- LLM influence on Wikipedia is quantifiable at 1%-2% for certain categories based on word frequency analysis
- Machine translation benchmarks show inflated scores when evaluated against LLM-generated reference translations
- RAG systems demonstrate reduced accuracy when querying LLM-revised knowledge bases due to information loss and semantic drift
- Scientific category page views show slight decline, though LLM connection remains unclear

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated content alters word frequency distributions in Wikipedia articles, enabling quantitative impact estimation.
- Mechanism: Frequency-based estimation formula compares observed word frequencies against pre-LLM baseline frequencies, weighted by rate of change when LLMs revise text.
- Core assumption: Word frequency shifts are primarily attributable to LLM influence rather than organic language evolution.
- Evidence anchors: Frequency increase of "crucial" and "additionally" (ChatGPT preferences) post-2023; 1%-2% impact estimate.
- Break condition: If organic language drift independently produces similar frequency changes without LLM exposure, attribution fails.

### Mechanism 2
- Claim: LLM-revised benchmark content inflates machine translation evaluation scores through stylistic alignment.
- Mechanism: LLM translations exhibit stylistic patterns similar to their training distribution, causing MT models to score higher when evaluated against them.
- Core assumption: Score inflation indicates benchmark contamination rather than genuine translation improvement.
- Evidence anchors: MT models achieve higher scores on GPT-processed benchmarks compared to original benchmarks.
- Break condition: If higher scores reflect genuinely clearer language rather than distributional matching, inflation claim weakens.

### Mechanism 3
- Claim: LLM-processed content degrades RAG retrieval effectiveness through information loss and semantic drift.
- Mechanism: LLM revision can merge facts, omit entities, introduce ambiguous abbreviations, or add misleading modifiers, reducing similarity matching and causing misinterpretation.
- Core assumption: Accuracy drops stem from content degradation rather than retrieval system limitations.
- Evidence anchors: Case studies showing specific failure modes: information fusion, keyword omission, abbreviation ambiguity, modifier introduction.
- Break condition: If retrieval systems improve to handle paraphrased content, or if fact-preserving revision prompts are used, degradation may be mitigated.

## Foundational Learning

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: Evaluates whether LLM-contaminated knowledge bases undermine RAG systems that retrieve external context before generation.
  - Quick check question: If a Wikipedia article about Apollo missions was rewritten by an LLM and lost "Apollo 11 landed July 20, 1969," would a RAG system querying "When did humans first land on the Moon?" succeed or fail?

- Concept: **BLEU/ChrF/COMET Metrics**
  - Why needed here: Demonstrates that benchmark contamination can inflate these translation quality scores, potentially reversing model rankings.
  - Quick check question: If Model A scores BLEU=70 on original benchmarks but BLEU=85 on LLM-contaminated benchmarks while Model B shows opposite pattern, which model is actually better?

- Concept: **Distributional Shift in Benchmarks**
  - Why needed here: Core thesis depends on understanding how training/test distribution mismatches affect model comparison validity.
  - Quick check question: Why would a machine translation model trained on web-scraped data perform unusually well on LLM-generated test sets?

## Architecture Onboarding

- Component map: Wikipedia Corpus (2020-2025) → Page View Analytics → Word Frequency Analysis → LLM Impact Estimator (η) → Linguistic Style Metrics (CTTR, readability, parse depth)
- Critical path: Word frequency impact estimation (Section 4.2, Equation 1) quantifies direct LLM influence and motivates downstream concerns about benchmarks and RAG.
- Design tradeoffs: Using Featured Articles provides higher quality baseline but less representativeness; first-section-only analysis offers cleaner text but loses context; Wikinews enables controlled experiments but smaller scale than Wikipedia.
- Failure signatures: Negative impact values suggest baseline frequency calculation error; MT scores decreasing on contaminated benchmark requires verification of language pair matching; RAG accuracy exceeding 100% indicates potential data leakage.
- First 3 experiments: 1) Replicate word frequency analysis on arXiv abstracts with known LLM exposure dates; 2) Extend MT contamination with human evaluation; 3) Test fact-preserving revision prompts for RAG mitigation.

## Open Questions the Paper Calls Out
- Is the observed decline in page views for scientific categories causally linked to LLM usage? The paper notes correlation but requires further investigation to isolate from other variables like curriculum changes or search algorithm updates.
- How does increasing LLM presence impact human editor engagement and Wikipedia community sustainability? The study focused on content analysis rather than behavioral changes in the human contributor base.
- Do negative effects of LLM-revised content on RAG accuracy generalize from Wikinews to full Wikipedia corpus? The smaller dataset may limit generalization across Wikipedia's diverse domain structures.

## Limitations
- Attribution uncertainty: Difficulty isolating LLM influence from organic language evolution in word frequency changes
- Corpus scale: RAG experiments on Wikinews may not generalize to full Wikipedia's complexity and scale
- Baseline comparison: Using Featured Articles provides quality baseline but may not represent general Wikipedia content

## Confidence
- Word frequency impact estimation: Medium - methodology sound but attribution not fully isolated
- MT benchmark contamination: High - clear distributional matching effects observed
- RAG degradation: Medium - plausible failure modes demonstrated but limited by corpus scale

## Next Checks
1. Replicate word frequency impact estimation on a different corpus (e.g., arXiv abstracts) with known LLM exposure dates to validate formula's generalizability and control for organic drift
2. Extend MT contamination experiments with human evaluation to confirm whether inflated scores reflect genuine quality improvements or artifactual distributional matching
3. Test whether prompt engineering for "fact-preserving revision" mitigates RAG accuracy degradation observed in simulations