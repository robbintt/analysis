---
ver: rpa2
title: 'Property-Preserving Hashing for $\ell_1$-Distance Predicates: Applications
  to Countering Adversarial Input Attacks'
arxiv_id: '2504.16355'
source_url: https://arxiv.org/abs/2504.16355
tags:
- image
- distance
- then
- lpips
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the first property-preserving hashing (PPH)\
  \ scheme for \u21131-distance predicates on images, designed to counter adversarial\
  \ input attacks that evade perceptual hashing. The scheme uses \u21131-error correcting\
  \ codes to construct a hash family where the hash of two similar images preserves\
  \ their asymmetric \u21131-distance with high probability, making it difficult for\
  \ adversaries to generate perceptually similar but hash-dissimilar images without\
  \ significantly degrading image quality."
---

# Property-Preserving Hashing for $\ell_1$-Distance Predicates: Applications to Countering Adversarial Input Attacks

## Quick Facts
- arXiv ID: 2504.16355
- Source URL: https://arxiv.org/abs/2504.16355
- Reference count: 40
- Introduces the first property-preserving hashing (PPH) scheme for ℓ1-distance predicates on images to counter adversarial input attacks

## Executive Summary
This paper presents the first property-preserving hashing (PPH) scheme for ℓ1-distance predicates on images, designed to counter adversarial input attacks that evade perceptual hashing. The scheme uses ℓ1-error correcting codes to construct a hash family where the hash of two similar images preserves their asymmetric ℓ1-distance with high probability. By setting appropriate thresholds, the scheme forces attackers to introduce significant perceptual distortion to evade detection, as many adversarial attacks rely on ℓ2-distance objectives. Experimental results on the Imagenette dataset demonstrate effectiveness against various attacks while maintaining computational efficiency.

## Method Summary
The scheme associates each n-element image vector with a polynomial σ_x(z) over finite field Z_p. The hash h(x) stores σ_x(z) mod (z^{t+1}). For evaluation, it computes σ_x^{-1}(z)·σ_y(z) mod (z^{t+1}) and runs the extended Euclidean algorithm until degree conditions indicate whether ∥y.-x∥₁ < t₊ and ∥x.-y∥₁ ≤ t₋. The construction is based on polynomials associated with image vectors and employs the extended Euclidean algorithm for evaluation. The scheme provides (1,m,n)-robust PPH guaranteeing zero false negatives for the asymmetric predicate, though 0-correctness relies on empirically small but non-negligible error ≈ p^{-δ}.

## Key Results
- Successfully forces adversarial attacks to introduce significant perceptual distortion (high LPIPS values) to evade detection
- Achieves efficient O(t²) time per evaluation with hash digest length approximately t log₂ n
- Demonstrates effectiveness against FGSM and PGD attacks on Imagenette dataset
- Processes 224×224 RGB images in about 13 seconds per image when divided into blocks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The construction preserves asymmetric ℓ1-distance predicates in the hash domain.
- Mechanism: Associate each n-element image vector with a polynomial σ_x(z) over finite field Z_p. The hash h(x) stores σ_x(z) mod (z^{t+1}). For evaluation, compute σ_x^{-1}(z)·σ_y(z) mod (z^{t+1}) and run the extended Euclidean algorithm (EEA) until degree conditions indicate whether ∥y.-x∥₁ < t₊ and ∥x.-y∥₁ ≤ t₋. Theorem 3 guarantees that when distances satisfy thresholds, EEA output degrees exactly match σ_{y.-x} and σ_{x.-y} degrees.
- Core assumption: The probability of one-sided errors when distances exceed thresholds can be bounded by p^{-δ} for chosen δ≥0 (Eq. 15, empirically validated but not analytically proven).
- Evidence anchors:
  - [abstract] "The scheme uses ℓ1-error correcting codes to construct a hash family where the hash of two similar images preserves their asymmetric ℓ1-distance with high probability."
  - [section] Theorem 3 and Construction 1 (pages 7–9)
- Break condition: When polynomial degree t approaches image dimension n, compression degrades and computation time grows as O(t²).

### Mechanism 2
- Claim: Adversarial evasion attacks must introduce significant perceptual distortion to evade detection.
- Mechanism: Many adversarial attacks (FGSM, PGD) use ℓ₂-distance objective functions. Proposition 1 establishes ∥x-y∥₂ ≤ ∥x-y∥₁ ≤ √n·∥x-y∥₂. By setting threshold t appropriately, any successful evasion requires ℓ₁ perturbation ≥ t, which forces ℓ₂ perturbation ≥ t/√n, degrading image quality (measured by LPIPS).
- Core assumption: Adversarial attacks predominantly use ℓ₂-norm objectives; other attack vectors (e.g., structured perturbations) may require separate analysis.
- Evidence anchors:
  - [abstract] "Since many adversarial attacks use ℓ2-distance (related to ℓ1-distance) as the objective function to perturb the input image, by appropriately choosing the threshold t, we can force the attacker to add considerable noise to evade detection."
  - [section] Table 2: FGSM with ε=0.1 produces LPIPS=0.5596 and NAD=1.1287
- Break condition: If an attacker uses non-ℓ₂ objectives (e.g., ℓ_∞ bounded attacks) or semantic transformations not captured by ℓ₁ distance, the bound may not hold.

### Mechanism 3
- Claim: The scheme provides (1,m,n)-robust PPH guaranteeing zero false negatives for the asymmetric predicate.
- Mechanism: By Proposition 14, for all vectors a sampled via samp(), when P_as(x,y)=1 (distances within thresholds), eval_h outputs 1 with probability 1. This holds even for adversarially chosen inputs given h, making it robust against evasion attacks per Definition 2.
- Core assumption: 0-correctness (preventing false positives) relies on empirically small but non-negligible error ≈ p^{-δ}, not formally proven.
- Evidence anchors:
  - [abstract] "A key feature of PPH is its strong correctness guarantee, i.e., the probability that the predicate will not be correctly evaluated in the hash domain is negligible."
  - [section] Proposition 14 (page 9)
- Break condition: If δ is set too small or p is small relative to image size, collision probability increases.

## Foundational Learning

- Concept: ℓ₁-distance and asymmetric variants
  - Why needed here: The predicate is defined on one-sided ℓ₁ distances (∥y.-x∥₁, ∥x.-y∥₁), not standard ℓ₁.
  - Quick check question: Given vectors x=(2,1,0,4), y=(3,0,1,4), compute both asymmetric ℓ₁ distances.

- Concept: Extended Euclidean Algorithm (EEA) for polynomials
  - Why needed here: The core evaluation uses EEA on polynomials ˜σ_{x,y}(z) and z^{t+1} to recover distance information.
  - Quick check question: Run EEA on r_{-1}=z^3+1 and r_0=z^2+2z+1 over Z_5; find r_1, r_2.

- Concept: Finite field arithmetic (Z_p)
  - Why needed here: All polynomial operations occur in Z_p where p>n (prime).
  - Quick check question: Why must p>n for Construction 1?

## Architecture Onboarding

- Component map:
  - samp(1^λ) -> h(x) -> eval_h(X,Y)
  - samp selects prime p>n and distinct non-zero elements a₁,…,aₙ from Z_p
  - h(x) computes σ_x(z) mod (z^{t+1}) (hash digest, O(n t²) time)
  - eval_h runs EEA on polynomials and outputs predicate result (O(t²) time)

- Critical path: The EEA stopping condition (deg(r_k)<t₊ and deg(r_{k-1})≥t₊) and subsequent degree check (deg(u_k)≤t₋-δ) determine predicate output. Errors here cause false positives/negatives.

- Design tradeoffs:
  - Larger t: better adversarial robustness but larger digests (≈t log₂ n) and slower computation
  - Smaller p: faster arithmetic but higher collision probability
  - Block division: processing large images as 1000 blocks parallelizes computation (~0.013s per block) but increases total work

- Failure signatures:
  - False negatives: EEA terminates too early; check threshold parameters t₊, t₋, δ
  - False positives: deg(u_k)≤t₋-δ when it shouldn't; verify p is large enough and δ≥3
  - Timeout: O(t²) growth; for t>5000, consider blocking or GPU acceleration

- First 3 experiments:
  1. Reproduce Table 2: Run FGSM/PGD on 100 Imagenette images with ε∈{0.01,0.1,0.3}, measure LPIPS vs. NAD, verify LPIPS>0.3 when NAD forces t≈869,122
  2. Measure compression: For 224×224 RGB images, compute actual digest sizes at t=0.01qn vs. theoretical bound t log₂ n
  3. Stress-test collisions: Generate random image pairs with NAD>t/50, run eval_h, measure false positive rate against predicted p^{-δ}

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a robust property-preserving hash (RPPH) scheme be constructed for the exact (symmetric) ℓ1-distance predicate?
- Basis in paper: [explicit] The conclusion states: "It remains an open problem to find a robust PPH for the exact ℓ1-distance predicate."
- Why unresolved: The current construction handles only the asymmetric ℓ1-distance predicate and achieves robustness only for one-sided errors (1-correctness).
- What evidence would resolve it: A provably secure construction that achieves negligible error in both directions (0-correctness and 1-correctness) for the symmetric ℓ1-distance predicate, or a formal impossibility result.

### Open Question 2
- Question: Can a robust PPH scheme be constructed for the Euclidean (ℓ2) distance predicate?
- Basis in paper: [explicit] The conclusion states: "There may also be interest in finding a robust PPH scheme for the Euclidean distance predicate." The abstract also mentions this avenue.
- Why unresolved: The current work focuses on ℓ1-distance; ℓ2-distance requires a fundamentally different approach since the asymmetric decomposition technique does not directly apply.
- What evidence would resolve it: A new PPH construction with provable correctness bounds for ℓ2-distance, or a demonstration that existing techniques can be adapted with rigorous analysis.

### Open Question 3
- Question: Is further compression possible for large threshold values t, particularly for robust PPH families?
- Basis in paper: [explicit] The conclusion notes: "our theoretical results show that further compression may be possible, especially when t is large."
- Why unresolved: The lower bounds in Section 3 apply to non-robust PPH; it is unclear whether robust PPH families face stricter bounds or if improved constructions exist.
- What evidence would resolve it: Tighter lower bounds specifically for robust ℓ1-distance PPH, or a new construction achieving compression closer to the non-robust bounds for large t.

### Open Question 4
- Question: Can the probability bound in Equation 15 (Pr[deg(q_{k+1}) ≥ δ+1] ≈ p^{-δ}) be proven analytically?
- Basis in paper: [explicit] In Section 4.2, the authors state: "Unfortunately, we do not have an analytical proof of this, which we leave as an open problem."
- Why unresolved: The empirical simulations in Figure 3 strongly support the bound, but a rigorous mathematical proof is lacking.
- What evidence would resolve it: A formal proof showing that the probability is bounded by p^{-δ} under the random coefficient model, or a counterexample demonstrating where the approximation fails.

### Open Question 5
- Question: What is the formal security (computational hardness) of inverting the σ-polynomial to recover the original image?
- Basis in paper: [inferred] Section 5.3 discusses inversion attacks and provides a heuristic complexity argument (O(q^n)), but no formal reduction or security proof is given.
- Why unresolved: The analysis relies on the combinatorial complexity of solving for image pixels from polynomial coefficients, but adversarial algorithms could exploit algebraic structure.
- What evidence would resolve it: A formal reduction from a known hard problem (e.g., polynomial system solving or lattice problems) to image inversion, or a cryptanalytic attack demonstrating polynomial-time inversion.

## Limitations
- The probability bound (p^{-δ}) for error rates is empirically validated but not analytically proven
- Performance against non-ℓ₂ adversarial objectives and semantic transformations beyond ℓ₁ distance remains untested
- Exact surrogate model architecture for generating adversarial examples is unspecified

## Confidence

- **High Confidence**: Theoretical construction and correctness proof (Proposition 14) for asymmetric ℓ₁-distance predicate, and ℓ₁-ℓ₂ distance relationship (Proposition 1)
- **Medium Confidence**: Empirical results demonstrating attack prevention (Table 2) and compression bounds, as they depend on unvalidated error probability assumption
- **Low Confidence**: Scheme's robustness against diverse adversarial objectives and semantic transformations not explicitly tested

## Next Checks

1. **Error Probability Validation**: Systematically vary δ and p for Imagenette dataset, measure empirical false positive rates, and compare against theoretical p^{-δ} bound
2. **Adversarial Objective Robustness**: Test against ℓ_∞ bounded attacks and semantic attacks, measuring LPIPS and NAD to assess performance degradation
3. **Scaling Analysis**: Evaluate on larger images (512×512) and larger t values, measuring digest size growth, computation time, and collision rates to validate O(t²) complexity and compression bounds