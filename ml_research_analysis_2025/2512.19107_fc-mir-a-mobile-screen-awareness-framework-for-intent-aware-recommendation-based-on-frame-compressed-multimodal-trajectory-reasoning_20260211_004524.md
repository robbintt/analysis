---
ver: rpa2
title: 'FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation
  based on Frame-Compressed Multimodal Trajectory Reasoning'
arxiv_id: '2512.19107'
source_url: https://arxiv.org/abs/2512.19107
tags:
- intent
- user
- arxiv
- video
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of real-time mobile UI trajectory
  analysis for intent recognition and recommendation, which is hindered by computational
  overhead and redundant frame processing. The authors propose FC-MIR, a framework
  that uses keyframe sampling and adaptive concatenation to reduce visual redundancy
  and enhance inference efficiency.
---

# FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning

## Quick Facts
- **arXiv ID**: 2512.19107
- **Source URL**: https://arxiv.org/abs/2512.19107
- **Reference count**: 40
- **Primary result**: Training-free compression retains performance at 50%-60% rates for mobile UI trajectory analysis

## Executive Summary
FC-MIR addresses real-time mobile UI trajectory analysis for intent recognition and recommendation by using training-free keyframe compression and adaptive stitching to reduce visual redundancy while preserving semantic content. The framework integrates state-of-the-art MLLMs or fine-tuned models for trajectory summarization and intent prediction, extending tasks to include post-prediction operations and search suggestions. Experiments demonstrate that compression methods retain performance at 50%-60% rates, with both closed-source and fine-tuned MLLMs showing strong intent summarization capabilities, though generating "surprising" suggestions remains challenging without user memory integration.

## Method Summary
The framework uses blur detection (Laplacian variance threshold Γ=100) to filter low-quality frames, followed by two-stage similarity detection (pHash for global similarity, SSIM sliding window for local structure) to remove near-duplicates without requiring model training. For scroll trajectories, adaptive stitching combines ORB feature detection with KNN matching (k=2) and Lowe's ratio test (τ=0.5) to merge overlapping frames into composite images while preserving context. The system supports both closed-source MLLMs (Doubao, GPT-4o) and fine-tuned Qwen3-VL variants for intent summarization and suggestion generation, with GRPO fine-tuning optimizing semantic and format quality.

## Key Results
- Compression method retains performance at 50%-60% compression rates with ROUGE-1 improving from 0.52 to 0.54 at 57% compression
- Stitched keyframe sequences at 44% compression achieve comparable ROUGE-L (0.46) to full video (0.47)
- Intent summarization quality positively correlates with suggestion usefulness (R²=0.2178, p < 0.001)

## Why This Works (Mechanism)

### Mechanism 1: Training-Free Keyframe Compression
Redundant frame removal preserves intent recognition accuracy while reducing token load through blur detection (Laplacian variance threshold Γ=100) and two-stage similarity detection (pHash + SSIM sliding window) that filters near-duplicates without requiring model training.

### Mechanism 2: Adaptive Stitching for Scroll Trajectories
Stitching scroll sequences into composite images preserves trajectory context better than discrete keyframe sequences using ORB feature detection, KNN matching with Lowe's ratio test (τ=0.5), and median-based overlap calculation to algorithmically merge frames without semantic loss.

### Mechanism 3: Intent Summarization as Suggestion Quality Predictor
Better trajectory summarization correlates with more useful suggestions through linear regression analysis showing Y = 0.4668X + 3.4225 (p < 0.001), where X is summarization quality and Y is suggestion utility, enabling easier-to-evaluate summarization as a proxy for suggestion effectiveness.

## Foundational Learning

- **Perceptual hashing (pHash)**: Enables O(1) global frame similarity comparison via DCT-based hash comparison (Hamming distance), critical for real-time mobile processing. *Quick check: Given two frames with Hamming distance 5 between their pHashes, would you consider them duplicates? (Answer: Depends on threshold; typical threshold is 8-12 for 64-bit hashes)*

- **Structural Similarity Index (SSIM)**: Provides perceptually-aligned local similarity measurement that pHash's global approach may miss, catching subtle UI changes (e.g., button state changes, text input). *Quick check: Why use SSIM instead of pixel-wise MSE for detecting meaningful UI changes? (Answer: SSIM accounts for luminance, contrast, and structure; MSE treats all pixel differences equally, failing on brightness shifts that don't change semantic content)*

- **Lowe's ratio test for feature matching**: Filters ambiguous ORB matches by requiring best match distance to be significantly smaller than second-best (ratio < 0.5), reducing false stitching alignments. *Quick check: If the ratio test threshold were increased to 0.8, what would happen to stitching quality? (Answer: More matches accepted, including ambiguous ones; stitching errors increase, especially on repetitive UI patterns)*

## Architecture Onboarding

- **Component map**: Frame capture -> Blur filter -> Similarity filter -> (optional) Stitch -> MLLM inference -> Intent/suggestion output
- **Critical path**: Frame capture → blur check → similarity check → (optional) stitch → MLLM inference → intent/suggestion output. The similarity check and stitching are parallel branches; stitching is triggered only when scroll behavior is detected.
- **Design tradeoffs**: Resolution: 384px (25% faster) vs. 512px (better text recognition); 886px showed negligible gain with 2.5× inference time. Compression ratio: 50-60% is empirically safe; 70%+ loses detail; 35-45% sometimes improves over uniform sampling. Last-frame-only: Minimal input (5% compression) but insufficient for next-action prediction in most scenarios.
- **Failure signatures**: Missing numerical details in intent (e.g., price filter "500-900" not captured) → increase resolution or reduce compression. Suggestions focus on cross-app actions rather than in-context depth → insufficient trajectory context; increase keyframe count. Stitching artifacts on popup overlays → disable stitching when non-scroll UI changes detected.
- **First 3 experiments**: 1) Baseline compression sweep: Run blur+similarity filtering at thresholds producing 30%, 50%, 70% compression on 20 held-out trajectories; measure ROUGE-1/2/L and SBERT against ground truth intent descriptions to find your device's optimal point. 2) Stitching ablation on scroll-heavy trajectories: Isolate trajectories with >3 scroll actions; compare keyframe-only vs. stitched output on object detail accuracy metric. 3) Last-frame vs. sequence suggestion quality: For 10 incomplete trajectories, generate suggestions using only final frame vs. compressed sequence; score on usefulness and novelty to validate that your use case requires full trajectory processing.

## Open Questions the Paper Calls Out

1. **Personalized user memory integration**: How can personalized, long-term user memory banks be effectively constructed and integrated to improve the "Novelty" and "Usefulness" of intent-aware suggestions? The Conclusion states future research includes "constructing more personalized and long-term user memory banks" to address the current struggle with generating useful or "surprising" suggestions. Evidence: Experiments demonstrating improved "Novelty/Surprise" and "Usefulness" scores (currently low at 0.53–0.74) when a memory module is added.

2. **Token-level vs pixel-level compression**: Can token-level frame compression methods outperform the proposed pixel-level stitching without exceeding the computational constraints of mobile devices? The Conclusion identifies "exploring token-level frame compression methods" as a future direction, while cautioning that "this may increase the computational load on mobile devices." Evidence: A comparative analysis of inference latency and battery consumption on mobile hardware between pixel-based and token-based compression.

3. **Multilingual generalization**: To what extent does the FC-MIR framework generalize to English or multilingual mobile environments compared to the Chinese-specific dataset used? The Limitations section notes the dataset is "primarily based on a Chinese environment" and that "suggestion and agency capabilities in English environments have not been tested." Evidence: Benchmark results on an English-language UI trajectory dataset showing comparable performance in intent summarization and suggestion generation.

## Limitations
- Framework effectiveness depends heavily on threshold optimization for specific datasets, limiting cross-platform generalization
- Stitching mechanism assumes predictable vertical overlap that breaks down with rapid non-linear scrolling and partial screen overlays
- Moderate correlation (R²=0.2178) between intent summarization quality and suggestion usefulness suggests other factors beyond trajectory understanding influence recommendation quality

## Confidence

**High Confidence**: The compression mechanism's effectiveness (50-60% compression with retained performance) is well-supported by multiple experiments showing consistent ROUGE score improvements over baselines.

**Medium Confidence**: The adaptive stitching mechanism shows promise in controlled experiments (44% compression with stitched composites matching full video performance), but limited corpus evidence for scroll-specific stitching in UI contexts means real-world performance may vary significantly.

**Low Confidence**: The generalizability of the framework to non-Chinese UIs, different application domains, or languages other than Chinese is not established. The correlation between summarization quality and suggestion usefulness, while statistically significant, explains only a modest portion of variance.

## Next Checks
1. **Cross-Platform Validation**: Test FC-MIR on at least two additional datasets from different platforms (iOS, Western apps) and languages to assess threshold transferability and identify platform-specific failure modes in blur detection and similarity filtering.

2. **Real-Time Performance Benchmark**: Measure actual inference latency on mobile devices across different compression ratios, documenting the trade-off between computational cost and suggestion quality to identify the practical deployment sweet spot for various use cases.

3. **Personalization Capability Assessment**: Implement a user profile integration layer and evaluate whether adding user history/context data improves "surprising" suggestion scores beyond the 0.53-0.74 range observed with trajectory-only information.