---
ver: rpa2
title: 'Stochastic Streets: A Walk Through Random LLM Address Generation in four European
  Cities'
arxiv_id: '2509.12914'
source_url: https://arxiv.org/abs/2509.12914
tags:
- streets
- llms
- numbers
- random
- madrid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study examined whether large language models (LLMs) can generate
  random street addresses in four European cities: Amsterdam, Madrid, Paris, and Rome.
  Using six state-of-the-art models, 1,000 prompts per city were issued, asking for
  random addresses with uniform selection of streets and numbers.'
---

# Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities

## Quick Facts
- arXiv ID: 2509.12914
- Source URL: https://arxiv.org/abs/2509.12914
- Reference count: 8
- Primary result: LLM address generation shows significant street selection bias and non-random patterns

## Executive Summary
This study examined whether large language models can generate random street addresses in four European cities (Amsterdam, Madrid, Paris, Rome) using six state-of-the-art models with 1,000 prompts per city. The research revealed significant limitations in LLM address generation capabilities, with models showing strong biases toward specific streets rather than uniform random selection. Some models produced invalid addresses, and street selection patterns were inconsistent with true randomness, often favoring certain streets regardless of their prominence. While number generation showed better uniformity across most models, certain models exhibited clear biases toward specific numbers.

## Method Summary
The researchers issued 1,000 prompts per city to six state-of-the-art LLMs, asking for random addresses with uniform selection of streets and numbers. They evaluated the outputs by analyzing street selection frequencies, number distributions, and visualizing the geographic clustering of generated addresses on city maps. The methodology focused on measuring randomness by checking if outputs showed uniform distribution patterns, with particular attention to whether models selected streets proportionally or showed systematic biases.

## Key Results
- LLMs repeatedly selected a small subset of streets, with the most frequent street appearing over 200 times
- Iconic or major streets were not always favored in selection patterns
- Most models produced more uniform distributions for street numbers than street names
- Visualization revealed geographic clustering of selected streets, confirming non-random patterns

## Why This Works (Mechanism)
The observed biases in LLM address generation stem from the models' training data composition and internal knowledge representation. LLMs learn statistical patterns from their training corpora, which means streets appearing more frequently in training data are more likely to be generated. The models lack true randomization mechanisms and instead rely on learned probability distributions, leading to systematic selection patterns. This reflects fundamental limitations in how LLMs generate structured data versus their strength in producing coherent text based on learned patterns.

## Foundational Learning
- Random address generation requires uniform probability distribution - why needed: ensures fairness and prevents systematic bias in data generation; quick check: compare frequency histograms against uniform distribution expectations
- LLM training data composition influences output patterns - why needed: understanding data sources helps predict and explain model behavior; quick check: analyze training corpus statistics for overrepresented locations
- Geographic knowledge representation in LLMs - why needed: reveals how location-based information is encoded and retrieved; quick check: map generated addresses to verify spatial coherence
- Structured data generation limitations - why needed: distinguishes between text generation and structured data production capabilities; quick check: compare output validity rates across different data formats
- Statistical validation methods for randomness - why needed: provides objective measures for evaluating generation quality; quick check: apply chi-square tests to frequency distributions

## Architecture Onboarding
Component map: LLM architecture -> Prompt processing -> Knowledge retrieval -> Text generation -> Output validation

Critical path: Prompt input → Context processing → Pattern matching in training data → Probability-based selection → Text synthesis → Address formatting

Design tradeoffs: Models optimized for coherent text generation rather than structured random data production, prioritizing fluency over uniformity

Failure signatures: Non-uniform street selection frequencies, geographic clustering of outputs, invalid address formats, systematic number biases

First experiments:
1. Compare address generation across models with identical prompts to isolate model-specific biases
2. Test address generation for cities outside training data to measure knowledge limitations
3. Evaluate impact of prompt engineering (e.g., specifying "truly random") on output distributions

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size of 1,000 prompts per city may not capture full address diversity
- Exclusive focus on four European capital cities limits geographic generalizability
- Evaluation relied on surface-level plausibility rather than comprehensive database validation

## Confidence
- Street selection bias findings: High confidence due to clear statistical patterns across multiple models
- Number distribution uniformity: Medium confidence due to less rigorous evaluation methods
- Geographic clustering interpretations: High confidence in visualization results, speculative on causation

## Next Checks
1. Expand to 10,000+ prompts per city to test whether observed biases persist at larger scales
2. Validate generated addresses against official city address registries to distinguish plausible vs. real addresses
3. Conduct cross-model analysis to determine if shared biases reflect common training data sources or fundamental LLM limitations