---
ver: rpa2
title: 'Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning
  Approach for Bangla Hate Speech Identification'
arxiv_id: '2511.07304'
source_url: https://arxiv.org/abs/2511.07304
tags:
- hate
- subtask
- bangla
- speech
- multitask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of fine-grained Bangla hate
  speech detection, which remains difficult due to limited annotated resources and
  complex linguistic features. The authors participated in the BLP 2025 shared task,
  tackling three subtasks: hate type classification, target group identification,
  and joint detection of type, severity, and target.'
---

# Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning Approach for Bangla Hate Speech Identification

## Quick Facts
- arXiv ID: 2511.07304
- Source URL: https://arxiv.org/abs/2511.07304
- Reference count: 14
- Primary result: 72.75% micro-F1 (1A), 72.69% micro-F1 (1B), 72.62% weighted micro-F1 (1C)

## Executive Summary
This paper addresses fine-grained Bangla hate speech detection through transformer ensemble methods and multitask learning. The authors tackle three subtasks: hate type classification, target group identification, and joint detection of type, severity, and target. Using BanglaBERT, MuRIL, and IndicBERTv2 models with soft and weighted voting ensembles, they achieve competitive results placing 7th-10th on the BLP-2025 leaderboard. Their approach demonstrates that transformer ensembles and multitask learning can effectively advance hate speech detection in low-resource settings, though class imbalance remains a fundamental challenge.

## Method Summary
The authors employ transformer-based ensemble methods for Bangla hate speech detection across three subtasks. For subtasks 1A (hate type classification) and 1B (target group identification), they use soft voting ensembles averaging probability distributions from three models: BanglaBERT, MuRIL, and IndicBERTv2. For subtask 1C (joint detection), they implement multitask learning with three classification heads sharing a transformer backbone, using weighted voting ensemble with empirically determined weights (0.5/0.3/0.2). All models are fine-tuned with AdamW optimizer (lr=2e-5, batch=16, epochs=3) and evaluated on 35,522 training, 2,512 development, and 10,200 test samples.

## Key Results
- Subtask 1A: 72.75% micro-F1 (9th place)
- Subtask 1B: 72.69% micro-F1 (10th place)
- Subtask 1C: 72.62% weighted micro-F1 (7th place)
- Ensemble methods consistently outperform individual models by 4-5 percentage points
- Multitask learning shows task interference but captures complementary signals

## Why This Works (Mechanism)

### Mechanism 1: Soft Voting Ensemble Diversity
Soft voting ensembles improve classification by averaging probability distributions across diverse transformer models. Three models with different pretraining corpora produce complementary error patterns, reducing variance particularly for borderline cases between overlapping categories. Each model captures linguistically distinct representations from monolingual Bangla corpus versus multilingual Indian language coverage.

### Mechanism 2: Multitask Learning Interdependencies
Multitask learning captures interdependencies between hate type, severity, and target through shared representations. A single transformer backbone feeds three classification heads, with gradients from all three loss terms jointly updating shared weights. This enables learning features that serve multiple objectives simultaneously, though sometimes introducing task interference.

### Mechanism 3: Performance-Weighted Voting
Performance-weighted voting outperforms uniform averaging for complex multitask prediction. Development set performance determines voting weights (MuRIL: 0.5, BanglaBERT: 0.3, IndicBERTv2: 0.2), with higher-weighted models contributing more to final predictions. This prioritizes empirically stronger performers based on development set rankings.

## Foundational Learning

- **Concept: Transformer Fine-Tuning for Classification**
  - Why needed here: All base models require task-specific adaptation via classification heads. Understanding how pretrained representations transfer to downstream tasks is essential.
  - Quick check question: Can you explain why adding a linear classification head on top of BERT's [CLS] token enables multi-class prediction?

- **Concept: Ensemble Diversity Sources**
  - Why needed here: Ensemble gains require model disagreement. Here, diversity comes from different pretraining corpora (Bangla monolingual vs. multilingual Indian).
  - Quick check question: If you fine-tuned three identical BanglaBERT models with different random seeds, would you expect similar ensemble gains? Why or why not?

- **Concept: Multitask Loss Weighting**
  - Why needed here: Subtask 1C combines three losses. The choice of α, β, γ affects which task dominates gradient updates.
  - Quick check question: If severity has 3 classes but type has 6 classes, should severity receive higher loss weight to compensate? What factors inform this decision?

## Architecture Onboarding

- **Component map:**
  Input Text → Preprocessing (remove Bangla digits, tokenize, pad/truncate to 128) → Three parallel branches → BanglaBERT (monolingual) → Classification Head → IndicBERTv2 (12 lang) → Classification Head → MuRIL (17 lang) → Classification Head → Soft Voting (average probs) for 1A/1B → Weighted Voting (0.5/0.3/0.2) for 1C

- **Critical path:**
  1. Load pretrained weights from HuggingFace (csebuetnlp/banglabert, google/muril-base-cased, ai4bharat/IndicBERTv2-MLM-only)
  2. Add task-specific classification head(s)
  3. Fine-tune on training split (35,522 samples) with AdamW, lr=2e-5, batch=16, epochs=3
  4. Evaluate on dev split to determine ensemble weights (for 1C)
  5. Inference: run all models, aggregate via soft/weighted voting

- **Design tradeoffs:**
  - Soft vs. Weighted Voting: Soft voting is simpler but assumes equal model capability. Weighted voting adapts to performance but requires dev set tuning and risks overfitting.
  - Single-task vs. Multitask: Multitask reduces inference cost but introduces task interference. Paper shows cases where single-task correctly predicts "Profane" but multitask drifts to "Abusive."
  - Model Count: Three models balance diversity vs. computational overhead. Adding more models increases latency with diminishing returns.

- **Failure signatures:**
  - Class imbalance: Minority classes (Sexism: 122 samples, Religious Hate: 676) show near-zero recall. Confusion matrices show systematic underprediction.
  - Implicit hate: Sarcasm and indirect attacks consistently misclassified as "None."
  - Target confusion: "Organization" vs. "Community" boundary unclear; "Society" frequently confused with "Individual."
  - Severity drift: Multitask models overpredict "Severe" when correct label is "Mild" or "Little to None."

- **First 3 experiments:**
  1. Reproduce baseline: Fine-tune single BanglaBERT on Subtask 1A with paper hyperparameters. Verify micro-F1 ≈ 71.0% on dev set.
  2. Ablate ensemble: Compare soft voting (all three models) vs. best single model. Quantify ensemble gain (paper shows ~4-5 point improvement).
  3. Stress test imbalance: Oversample minority classes (Sexism, Religious Hate) or apply focal loss. Measure recall improvement on dev set for underrepresented categories.

## Open Questions the Paper Calls Out

### Open Question 1
Would data augmentation or class re-weighting strategies significantly improve recall for severely underrepresented categories like Sexism (122 training instances) and Religious Hate (676 instances)? The authors acknowledge this need but don't implement any augmentation or re-weighting techniques. Comparative experiments using oversampling, synthetic data generation, or loss re-weighting would resolve this.

### Open Question 2
Can dynamic or learned weighting mechanisms outperform the fixed weights (0.5, 0.3, 0.2) used in the weighted voting ensemble for Subtask 1C? The authors acknowledge this limitation but only use static weights based on development set rankings. Implementation of attention-based stacking, meta-learning weight prediction, or uncertainty-based weighting would provide evidence.

### Open Question 3
To what extent do the proposed ensemble and multitask approaches generalize to other Bangla hate speech datasets and domains beyond the BLP-2025 shared task data? All experiments use a single dataset without cross-dataset or cross-domain validation. Evaluation on other Bangla hate speech corpora would strengthen generalizability claims.

### Open Question 4
Can cross-lingual transfer from higher-resource languages improve fine-grained Bangla hate speech detection, particularly for underrepresented categories? While multilingual models are used, explicit cross-lingual transfer strategies are not investigated. Experiments using translate-train, multilingual fine-tuning with auxiliary English or Hindi hate speech data would resolve this.

## Limitations

- Severe class imbalance limits performance ceiling, with minority classes (Sexism: 122 samples, Religious Hate: 676) showing near-zero recall
- Fixed weighting strategy for ensemble voting lacks rigorous justification and sensitivity analysis
- Multitask learning shows evidence of task interference, with models drifting from correct "Profane" predictions to "Abusive" in joint training

## Confidence

- **High Confidence**: Ensemble methodology and implementation details are clearly specified and reproducible. Reported performance metrics are verifiable through published code and dataset.
- **Medium Confidence**: Transformer ensembles and multitask learning are effective for Bangla hate speech detection in low-resource settings, though absolute performance is fundamentally limited by class imbalance.
- **Low Confidence**: The specific weighting scheme (0.5/0.3/0.2) is optimal. No sensitivity analysis shows how performance varies with different weight combinations or validates dev-set rankings generalize to test data.

## Next Checks

1. Reproduce baseline ensemble gains: Fine-tune single BanglaBERT for Subtask 1A with paper hyperparameters and verify micro-F1 ≈ 71.0% on dev set. Then compare soft voting ensemble vs. best single model to quantify the 4-5 point improvement.

2. Stress test imbalance handling: Apply oversampling or focal loss to minority classes (Sexism, Religious Hate) and measure recall improvement on dev set. This validates whether ensemble gains are limited by data distribution.

3. Validate weighted voting sensitivity: Systematically vary ensemble weights for Subtask 1C (e.g., test combinations like [0.4/0.4/0.2], [0.6/0.2/0.2]) and measure performance impact. This determines whether fixed [0.5/0.3/0.2] weights are genuinely optimal.