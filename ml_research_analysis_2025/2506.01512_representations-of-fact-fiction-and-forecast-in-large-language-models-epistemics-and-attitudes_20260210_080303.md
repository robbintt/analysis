---
ver: rpa2
title: 'Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics
  and Attitudes'
arxiv_id: '2506.01512'
source_url: https://arxiv.org/abs/2506.01512
tags:
- peanut
- llms
- slot
- number
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates the linguistic knowledge of epistemic modality
  in large language models (LLMs) by designing controlled stories to test their ability
  to generate appropriate epistemic expressions. The experiments focus on two main
  types of epistemic expressions: modal auxiliaries (may/might vs must/have to) and
  attitude verbs (know, believe, doubt).'
---

# Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes

## Quick Facts
- **arXiv ID:** 2506.01512
- **Source URL:** https://arxiv.org/abs/2506.01512
- **Reference count:** 40
- **Key outcome:** Medium-parameter LLMs (70-72B) outperform small ones (7-8B) in epistemic modality tasks, but struggle with possibility modals and belief attribution, revealing insufficient semantic knowledge of uncertainty.

## Executive Summary
This paper evaluates large language models' linguistic knowledge of epistemic modality through controlled story-based experiments. The study focuses on two main types of epistemic expressions: modal auxiliaries (may/might vs must/have to) and attitude verbs (know, believe, doubt). Through systematic testing across different model sizes and families, the research reveals that LLMs' performance in generating appropriate epistemic expressions is limited and not robust. Medium-parameter models significantly outperform small-parameter ones, with better handling of necessity modals compared to possibility modals, and superior performance in reporting facts versus beliefs under different certainty levels.

## Method Summary
The study employs controlled stories to evaluate LLMs' epistemic reasoning capabilities through two main experiments. Experiment 1 tests modal auxiliaries using 150 stories from five templates (hidden object, Whodunnit, city travel, grocery store promotion, fictional characters) with three story types (base, 1-shot, counterfactual) and three QA formats. Experiment 2 examines attitude verbs using 30 stories from the ToMi dataset with eight statements per story covering facts, beliefs, and varying certainty levels. Models tested include Llama3-8B/70B-Instruct, Llama3.1-8B/70B-Instruct, Qwen2-7B/72B-Instruct, and Qwen2.5-7B/72B-Instruct via Huggingface Transformers on Nvidia A100 GPUs. Evaluation uses greedy decoding with accuracy, paired accuracy, and joint accuracy metrics, analyzed through logistic regression with sum-to-zero effect coding.

## Key Results
- Medium-parameter models (70-72B) significantly outperform small-parameter ones (7-8B) across all epistemic modality tasks.
- Necessity modals (must/have to) are handled more accurately than possibility modals (may/might) by all models tested.
- LLMs demonstrate better performance in reporting facts compared to beliefs under varying degrees of epistemic certainty.

## Why This Works (Mechanism)
LLMs' performance in epistemic modality tasks depends on their ability to track contextual information and generate appropriate linguistic expressions based on evidential certainty. The mechanism relies on the models' internal representations of possibility versus necessity, which are tested through controlled narratives that either leave multiple options open or eliminate alternatives. Success requires understanding the semantic distinction between different epistemic expressions and applying this knowledge consistently across varied contexts.

## Foundational Learning
- **Epistemic modality**: The linguistic expression of possibility, necessity, and certainty about states of affairs. Needed to understand how language encodes uncertainty and knowledge claims.
- **Modal auxiliaries**: Verbs like "may," "might," "must," "have to" that express epistemic possibility and necessity. Quick check: Identify which modals express possibility vs necessity in example sentences.
- **Attitude verbs**: Verbs like "know," "believe," "doubt" that report mental states and epistemic certainty. Quick check: Distinguish between fact-reporting and belief-reporting uses.
- **Greedy decoding**: A deterministic decoding strategy that selects the highest probability token at each step. Quick check: Verify output matches expected single-word responses without explanations.
- **Sum-to-zero effect coding**: A statistical technique for comparing categorical variables in regression analysis. Quick check: Confirm model comparisons account for baseline performance differences.

## Architecture Onboarding
**Component Map:** Controlled stories → LLM inference (greedy decoding) → QA format processing → Accuracy calculation → Statistical analysis

**Critical Path:** Story generation → Model input → Token prediction → Output parsing → Metric computation

**Design Tradeoffs:** 
- Template complexity vs. experimental control
- Model size vs. computational cost
- Decoding strategy vs. output consistency

**Failure Signatures:**
- Outputs containing explanations instead of single answers
- Inconsistent handling of necessity vs. possibility within same story
- Systematic bias toward "has to" regardless of context

**First 3 Experiments:**
1. Generate 10 base stories using hidden object template, run through Qwen2.5-7B-Instruct, verify ~72% accuracy
2. Test necessity vs. possibility conditions within same story, check paired accuracy differences
3. Compare model outputs for fact vs. belief statements in ToMi dataset, measure certainty level performance

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Controlled stories may not capture real-world epistemic reasoning complexity
- Greedy decoding may systematically bias results compared to sampling methods
- Focus on only two epistemic expression families leaves gaps in understanding other epistemic constructions

## Confidence
- **High confidence:** Medium-parameter models consistently outperform small-parameter ones
- **Medium confidence:** Necessity modals are better handled than possibility modals
- **Medium confidence:** LLMs are better at reporting facts than beliefs

## Next Checks
1. Reconstruct the three missing story templates (city travel, grocery store promotion, fictional characters) using provided examples, generate new stories, and verify accuracy patterns hold across all five template types.
2. Repeat experiments using alternative decoding strategies (top-k sampling with temperature=0.7, beam search with beam width=5) and compare performance orderings.
3. Translate ToMi dataset stories into a morphologically rich language (e.g., German or Russian) and evaluate whether epistemic modality limitations persist across languages.