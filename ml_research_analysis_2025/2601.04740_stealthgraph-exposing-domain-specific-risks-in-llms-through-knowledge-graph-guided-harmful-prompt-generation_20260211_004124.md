---
ver: rpa2
title: 'StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided
  Harmful Prompt Generation'
arxiv_id: '2601.04740'
source_url: https://arxiv.org/abs/2601.04740
tags:
- harmful
- prompts
- prompt
- domain
- safety
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'StealthGraph tackles the challenge of generating realistic, domain-specific
  harmful prompts for LLM safety evaluation. It combines knowledge-graph-guided generation
  with dual-path obfuscation rewriting: first, domain entities and harmful categories
  are used to produce explicit prompts, then direct and context-enhanced rewriting
  converts these into stealthy, implicit variants.'
---

# StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation

## Quick Facts
- **arXiv ID**: 2601.04740
- **Source URL**: https://arxiv.org/abs/2601.04740
- **Reference count**: 40
- **Primary result**: StealthGraph achieves 84.92% attack success on successfully obfuscated prompts, substantially outperforming explicit benchmarks (23.92% average) and enhancing safety alignment.

## Executive Summary
StealthGraph addresses the challenge of generating realistic, domain-specific harmful prompts for LLM safety evaluation. It combines knowledge-graph-guided generation with dual-path obfuscation rewriting: domain entities and harmful categories are used to produce explicit prompts, then direct and context-enhanced rewriting converts these into stealthy, implicit variants. Experiments across medicine, finance, law, and education show that StealthGraph substantially outperforms explicit benchmarks and enhances safety alignment training.

## Method Summary
StealthGraph extracts domain subgraphs from Wikidata via SPARQL queries, filters entities by Wikipedia sitelink thresholds, and uses them as few-shot context to synthesize explicit harmful prompts. A dual-path obfuscation pipeline then rewrites these into implicit variants using direct LLM instructions and context-card-enhanced rewriting based on neighboring KG entities. Generated prompts are filtered by harmfulness (Granite-Guardian-3.1-8B), fluency (GPT-2), and a quality model (intent preservation + fluency). Final attack success is evaluated via a 3-model LLM-as-Judge ensemble.

## Key Results
- StealthGraph achieves 84.92% average attack success on successfully obfuscated prompts across four domains.
- Dual-path obfuscation (45.06% OSR) outperforms single-path methods under sufficient iteration budgets.
- Safety alignment training reduces attack success under implicit threats while preserving general capability (MMLU ~42–44).

## Why This Works (Mechanism)

### Mechanism 1
Knowledge graphs constrain generation toward domain-relevant high-risk entities. Domain subgraphs are constructed from Wikidata using root nodes expanded via SPARQL queries over four relations (P31, P279, P361, P527). Popularity filtering via Wikipedia sitelinks thresholds removes noisy entities. Retrieved entities and harmful categories are fed as few-shot context to a synthesis model. Core assumption: domain expertise required for harmful misuse correlates with entities having structured relationships in public knowledge bases.

### Mechanism 2
Dual-path rewriting escapes local optima in obfuscation search more effectively than single paths under sufficient iteration budgets. Two independent rewriting paths operate from the same explicit prompt. The direct path instructs the LLM to rewrite naturally. The context-card path constructs domain-context cards from neighboring KG entities. Paths alternate per iteration; candidates are filtered by a quality model and validated against a target model. Core assumption: context cards provide semantic cues that enable qualitatively different rewrites than direct instruction alone.

### Mechanism 3
Implicit prompts achieve higher attack success rates because they evade keyword-based defenses while preserving harmful intent. Explicit prompts contain surface-level indicators that trigger refusal. Obfuscation rewrites using domain-specific terminology and structural transformations reduce lexical triggers while semantic preservation constraints maintain intent. Core assumption: safety mechanisms rely partially on surface-level lexical patterns rather than deep intent understanding.

## Foundational Learning

- **Knowledge Graphs (RDF/SPARQL)**:
  - Why needed here: Domain subgraphs are extracted via SPARQL queries over Wikidata relations; understanding graph traversal, entity-relation structures, and query construction is required to customize domains.
  - Quick check question: Can you write a SPARQL query to retrieve all subclasses of "disease" (Q12136) with at least 50 Wikipedia sitelinks?

- **LLM-as-a-Judge Evaluation**:
  - Why needed here: Attack success rate and obfuscation success are determined by multi-model voting rather than keyword heuristics.
  - Quick check question: Why might a 3-model voting panel reduce evaluation variance compared to a single classifier?

- **Retrieval-Augmented Generation (RAG) Principles**:
  - Why needed here: Entity-centric RAG retrieves subgraph context to ground harmful prompt generation; understanding context injection and few-shot prompting is essential.
  - Quick check question: How does entity-centric retrieval differ from chunk-based document retrieval in terms of grounding specificity?

## Architecture Onboarding

- **Component map**:
  SPARQL extraction -> synthesis model (LLaMA-3.1-70B-finetune) -> harmfulness/PPL filtering -> dual-path obfuscation (direct + context-card) -> quality model filtering -> obfuscation success check -> ASR evaluation

- **Critical path**:
  SPARQL extraction → synthesis → harmfulness/PPL filtering → dual-path obfuscation loop → obfuscation success check → ASR evaluation. The obfuscation loop is the primary computational cost center.

- **Design tradeoffs**:
  - Iteration budget κ: Higher κ improves OSR but increases cost (κ=10 yields 29.03% OSR at 4.01 avg iterations; κ=18 yields 36.75% at 6.44 iterations).
  - Sitelink threshold T: Higher T reduces noise but may miss niche domain entities; current values (20–80) are domain-tuned.
  - Single vs. dual-path: Dual-path requires maintaining two prompt templates and context-card construction overhead.

- **Failure signatures**:
  - Low OSR despite high κ: Check quality model calibration—overly strict intent preservation may reject valid rewrites.
  - High PPL in outputs: Review fluency constraint thresholds; may indicate rewriting drift into unnatural phrasing.
  - Domain coverage gaps: Verify root node selection and SPARQL relation coverage.

- **First 3 experiments**:
  1. Replicate Table 7 ablation on a single domain with κ ∈ {6, 10, 18} to validate dual-path OSR gains and iteration efficiency tradeoffs.
  2. Swap Granite-Guardian for an alternative harmfulness classifier to assess filtering sensitivity and its downstream impact on ASR.
  3. Extend to a new domain (e.g., cybersecurity) by defining root nodes in Wikidata, setting sitelink threshold T, and running the full pipeline on LLaMA-3.1-8B to measure cross-domain generalization.

## Open Questions the Paper Calls Out
None

## Limitations
- Fine-tuning data and weights for synthesis model (LLaMA-3.1-70B-finetune, safety-unaligned) are not explicitly confirmed in released assets.
- Quality model Mqual (intent_preserved, is_fluent) and obfuscation evaluator Mobf_eval implementation details are not fully specified.
- Exact neighbor selection logic for context cards in dual-path rewriting is unclear, potentially affecting rewrite diversity.

## Confidence
- Knowledge-graph-guided generation improves domain-specific coverage: **High**
- Dual-path obfuscation outperforms single-path under sufficient iteration budgets: **Medium**
- Implicit prompts achieve higher ASR due to evasion of keyword-based defenses: **High**
- Safety alignment training reduces attack success while preserving capability: **Medium**

## Next Checks
1. Validate dual-path iteration efficiency: Replicate Table 7 ablation on a single domain (e.g., medicine) with κ ∈ {6, 10, 18} to confirm that dual-path OSR gains plateau beyond κ=10 and that iteration costs scale as reported.
2. Assess filtering sensitivity: Replace Granite-Guardian-3.1-8B with an alternative harmfulness classifier (e.g., NoBEL) and rerun the synthesis pipeline to measure impact on downstream ASR and OSR, checking if results are robust to classifier choice.
3. Test cross-domain generalization: Apply the full pipeline to a new domain (e.g., cybersecurity) by defining root nodes in Wikidata, setting sitelink threshold T, and running on LLaMA-3.1-8B to measure whether OSR/ASR improvements generalize beyond the original four domains.