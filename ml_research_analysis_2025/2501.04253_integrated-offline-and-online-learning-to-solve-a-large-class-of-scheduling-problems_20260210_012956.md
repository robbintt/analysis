---
ver: rpa2
title: Integrated Offline and Online Learning to Solve a Large Class of Scheduling
  Problems
arxiv_id: '2501.04253'
source_url: https://arxiv.org/abs/2501.04253
tags:
- instances
- time
- jobs
- problems
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a unified machine learning approach to solve
  single-machine scheduling problems with non-decreasing min-sum objectives. The method
  leverages a time-indexed formulation and a deep neural network (DNN) to predict
  continuous solutions, which are then converted to feasible discrete solutions.
---

# Integrated Offline and Online Learning to Solve a Large Class of Scheduling Problems

## Quick Facts
- **arXiv ID:** 2501.04253
- **Source URL:** https://arxiv.org/abs/2501.04253
- **Authors:** Anbang Liu; Zhi-Long Chen; Jinyang Jiang; Xi Chen
- **Reference count:** 40
- **Primary result:** Unified ML approach solves single-machine scheduling problems with up to 1000 jobs, achieving 1-2% gap to LP lower bounds in under 100 seconds per instance.

## Executive Summary
This paper proposes a unified machine learning approach to solve single-machine scheduling problems with non-decreasing min-sum objectives. The method leverages a time-indexed formulation and a deep neural network (DNN) to predict continuous solutions, which are then converted to feasible discrete solutions. Key innovations include: (1) a unified DNN architecture using starting costs as inputs to handle diverse objective functions, (2) offline training using specially constructed large instances with easily obtainable optimal solutions, and (3) online single-instance learning to fine-tune the DNN for specific instances. The approach is tested on problems with up to 1000 jobs, showing that the integrated offline and online learning method achieves high-quality solutions (within 1-2% of lower bounds) in under 100 seconds per instance, outperforming benchmark approaches.

## Method Summary
The approach uses a unified DNN architecture (UMSNN) to predict time-window probabilities for job scheduling. During offline training, the model learns from specially constructed large instances where optimal solutions are derived by scaling smaller instances. The UMSNN architecture combines 1D-CNNs for cost and release date inputs, an MLP for processing times, and a Transformer Encoder core. For inference, predicted time windows are converted to schedules using greedy or sampling heuristics. Online fine-tuning adapts the model to specific instances using a feasibility surrogate and Polyak stepsize optimization.

## Key Results
- Unified DNN architecture handles diverse min-sum objectives (e.g., weighted completion time, weighted tardiness) using starting costs as inputs
- Offline training on specially constructed instances with easily obtainable optimal solutions enables handling of large instances (n ≤ 1000)
- Integrated offline and online learning achieves high-quality solutions (within 1-2% of LP lower bounds) in under 100 seconds per instance
- Online single-instance learning improves solution quality by 0.2% on average compared to offline-only training

## Why This Works (Mechanism)
The method works by leveraging the time-indexed formulation to convert the scheduling problem into a continuous prediction task. The DNN predicts time-window probabilities for each job, which are then converted to discrete schedules. The unified architecture handles diverse objectives through starting costs, while offline training on scaled instances provides rich data for learning. Online fine-tuning adapts the model to specific instances, improving solution quality. The approach exploits the structure of min-sum objectives to achieve efficient learning and inference.

## Foundational Learning
- **Time-Indexed Formulation**: Represents schedules as binary variables indicating job completion times. Why needed: Enables conversion of scheduling to continuous prediction. Quick check: Verify the formulation correctly captures all constraints and objectives.
- **Neural Network for Scheduling**: Uses DNN to predict continuous solutions that are then converted to discrete schedules. Why needed: Handles the combinatorial complexity of scheduling. Quick check: Test prediction accuracy on small instances with known optimal solutions.
- **Offline and Online Learning Integration**: Combines batch training on large instances with instance-specific fine-tuning. Why needed: Balances generalization and customization. Quick check: Compare performance with and without online fine-tuning on held-out instances.
- **Feasibility Surrogate**: Smooth approximation of scheduling constraints for gradient-based optimization. Why needed: Enables backpropagating through discrete scheduling decisions. Quick check: Verify surrogate approximates true feasibility well for various schedules.
- **Polyak Stepsize Optimization**: Adaptive learning rate based on gradient information during online fine-tuning. Why needed: Stabilizes convergence during instance-specific optimization. Quick check: Monitor convergence behavior with different step sizes.
- **Special Instance Construction**: Scales small instances to create large instances with easily obtainable optimal solutions. Why needed: Enables supervised learning on problems where optimal solutions are otherwise intractable. Quick check: Verify scaling preserves solution quality and problem structure.

## Architecture Onboarding
- **Component Map**: Input features (starting costs, processing times, release dates) → 1D-CNNs and MLP feature extractors → Transformer Encoder → MLP Output Head → Time-window probabilities
- **Critical Path**: Input preprocessing → Feature extraction → Temporal encoding → Output prediction
- **Design Tradeoffs**: Unified architecture vs. specialized models for each objective; offline training on scaled instances vs. direct training on large instances
- **Failure Signatures**: Overfitting to special instance structure; instability in online learning due to surrogate approximation errors
- **Three First Experiments**:
  1. Train and test on small instances with known optimal solutions to verify basic functionality
  2. Test on scaled instances to verify special instance construction and learning
  3. Implement and test online fine-tuning on a single instance to verify feasibility surrogate and Polyak stepsize

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of experimental comparison with specialized MIP solvers on generic instances
- Missing implementation details for online learning surrogate gradient calculation
- Performance claims unverified on instances that don't follow the "special instance" structure

## Confidence
- **High Confidence**: Offline training methodology and neural network architecture description are detailed and reproducible
- **Medium Confidence**: The core approach of using DNNs to predict time-indexed solutions is technically sound and innovative
- **Low Confidence**: The performance claims on generic instances and the practical benefit over existing solvers remain unverified due to missing experimental validation

## Next Checks
1. **Reproduce Online Learning Component**: Implement the full online fine-tuning procedure with the feasibility surrogate and Polyak stepsize calculation, then validate the reported improvement from 1.61% to 1.41% gap on test instances.
2. **Benchmark Against MIP Solvers**: Run the method on standard scheduling benchmark instances (e.g., PSPLIB) and compare both solution quality and runtime against CPLEX/Gurobi with standard MIP formulations.
3. **Test on Generic Instances**: Generate and test the method on randomly constructed instances that do not follow the "special instance" structure to verify generalization beyond the scaling artifact.