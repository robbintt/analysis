---
ver: rpa2
title: 'One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale
  Advertising Image Generation'
arxiv_id: '2602.02033'
source_url: https://arxiv.org/abs/2602.02033
tags:
- user
- group
- image
- preference
- product
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating advertising images
  that cater to diverse user groups rather than applying a one-size-fits-all approach.
  The authors propose One Size, Many Fits (OSMF), a framework that clusters users
  based on product-aware attributes and generates tailored images for each group using
  a Group-aware Multimodal Large Language Model (G-MLLM).
---

# One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation

## Quick Facts
- arXiv ID: 2602.02033
- Source URL: https://arxiv.org/abs/2602.02033
- Reference count: 40
- One-size-fits-all advertising image generation fails diverse user groups

## Executive Summary
This paper addresses the challenge of generating advertising images that cater to diverse user groups rather than applying a one-size-fits-all approach. The authors propose One Size, Many Fits (OSMF), a framework that clusters users based on product-aware attributes and generates tailored images for each group using a Group-aware Multimodal Large Language Model (G-MLLM). The model is trained with a novel Group-DPO method to align group-wise preferences, enhancing click-through rates (CTR) for each segment. Experiments on a large-scale GAIP dataset show that OSMF outperforms existing methods, achieving higher CTR and better group preference modeling.

## Method Summary
OSMF clusters users into product-aware groups using a Product-Aware Attribute Generator (PAAG) that encodes user attributes, product text, and images. These group embeddings are fed into a Group-aware Multimodal Large Language Model (G-MLLM) that conditions image generation on group preferences. The framework employs Group-DPO, a preference alignment method that fine-tunes the model using group-wise click data to maximize CTR. Image generation uses ControlNet-Inpaint with Stable Diffusion, producing customized ads for each user segment. The approach is trained end-to-end on GAIP, a large-scale dataset of user-product interactions.

## Key Results
- OSMF achieves 10.8% CTR lift over baseline "one-size-fits-all" approach
- NDCG@5 decreases with increasing K (better preference modeling) for OSMF
- Group-DPO fine-tuning shows 3.2% CTR improvement over standard DPO

## Why This Works (Mechanism)
OSMF works by explicitly modeling user group preferences rather than treating all users identically. By clustering users into product-aware groups and conditioning the generation model on these group embeddings, the framework can capture nuanced preference differences. The Group-DPO fine-tuning aligns the model with actual click behavior patterns within each group, ensuring generated images resonate with specific user segments. This targeted approach addresses the limitation of generic advertising that fails to account for diverse user preferences.

## Foundational Learning
- **Product-Aware Attribute Generation**: Creates user embeddings by combining demographic, behavioral, and product-specific features. Why needed: Captures the relationship between users and specific products they might click. Quick check: Verify embeddings change meaningfully when product context changes.
- **Group Clustering via K-Means**: Partitions users into K clusters per product based on attribute similarity. Why needed: Identifies distinct preference groups for targeted generation. Quick check: Silhouette scores should be positive and increase with K up to optimal point.
- **Multimodal Group Conditioning**: Prepends group embeddings to input sequences in G-MLLM. Why needed: Allows the model to generate images aligned with specific group preferences. Quick check: Generated images for different groups should show clear visual differences.
- **Group-DPO Preference Alignment**: Fine-tunes the model using group-wise click preference data. Why needed: Aligns generation with actual user behavior patterns within groups. Quick check: CTR should increase after fine-tuning.
- **ControlNet-Inpaint for Image Generation**: Uses conditional generation to create advertising images. Why needed: Enables high-quality, controllable image synthesis from text prompts. Quick check: Generated images should be visually coherent and match prompts.
- **CTR-based Reward Signal**: Uses click-through rate as the primary metric for evaluation. Why needed: Directly measures advertising effectiveness. Quick check: Higher CTR should correlate with better preference alignment.

## Architecture Onboarding

**Component Map:**
PAAG (user→embeddings) -> K-Means clustering -> Group embeddings -> G-MLLM (pre-training) -> GRM (CTR prediction) -> Group-DPO fine-tuning -> ControlNet-Inpaint (image generation)

**Critical Path:**
User attributes → PAAG encoding → K-Means clustering → Group embeddings → G-MLLM with group tokens → Group-DPO fine-tuning → Image generation via ControlNet

**Design Tradeoffs:**
- Fixed K clusters per product vs adaptive clustering: Simpler implementation but may miss nuanced groups
- Pre-training on group-centric tasks vs direct CTR fine-tuning: Better general representation learning but requires more compute
- Using CTR as sole reward vs multi-objective: Direct business metric alignment but may miss other engagement signals

**Failure Signatures:**
- NDCG@5 not decreasing with K → Groups not distinct enough, check clustering quality
- Group-DPO degrades CTR → Reward model inaccurate, verify GRM predictions
- Generated images inconsistent with prompts → ControlNet configuration issues

**First Experiments:**
1. Verify PAAG clustering produces distinct groups by checking silhouette scores and NDCG@5 across K values
2. Train GRM on CTR prediction and evaluate Pair Accuracy on held-out click pairs
3. Test group conditioning by generating images for extreme percentile groups (15th vs 95th) and comparing visual differences

## Open Questions the Paper Calls Out
None

## Limitations
- K-Means clustering assumes spherical clusters and may not capture complex preference structures
- The approach requires substantial click data per product to form meaningful groups
- ControlNet-Inpaint configuration details are not fully specified, potentially affecting reproducibility

## Confidence

**High confidence:** The overall framework architecture (PAAG clustering, G-MLLM conditioning, Group-DPO fine-tuning) is clearly described and internally consistent.

**Medium confidence:** The empirical results showing CTR improvement and preference alignment are convincing, though the offline metrics (NDCG@5, AUROC) depend on the quality of the reward model and dataset splits.

**Medium confidence:** The GAIP dataset appears substantial, but the clustering methodology's sensitivity to parameter choices is unclear.

## Next Checks

1. Implement the PAAG clustering pipeline and verify that NDCG@5 decreases with increasing K (indicating more distinct group preferences).
2. Train the CTR prediction model (GRM) and evaluate Pair Accuracy on held-out click pairs to ensure reward signal quality before Group-DPO.
3. Test the group conditioning mechanism by generating images for extreme user groups (15th vs 95th percentiles) and evaluating visual distinctiveness.