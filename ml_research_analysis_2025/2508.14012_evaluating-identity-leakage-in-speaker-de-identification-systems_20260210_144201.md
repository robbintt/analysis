---
ver: rpa2
title: Evaluating Identity Leakage in Speaker De-Identification Systems
arxiv_id: '2508.14012'
source_url: https://arxiv.org/abs/2508.14012
tags:
- speaker
- speech
- identity
- systems
- sdid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates identity leakage in speaker de-identification
  (SDID) systems, which aim to conceal speaker identity while preserving speech intelligibility.
  The authors introduce a multi-metric benchmark combining equal error rate (EER),
  cumulative match characteristic (CMC) hit rates, and embedding-space similarity
  analysis (via CCA and Procrustes alignment) to comprehensively quantify residual
  identity leakage.
---

# Evaluating Identity Leakage in Speaker De-Identification Systems

## Quick Facts
- arXiv ID: 2508.14012
- Source URL: https://arxiv.org/abs/2508.14012
- Reference count: 0
- All evaluated SDID systems leak identity information to varying degrees

## Executive Summary
This paper introduces a comprehensive multi-metric benchmark to evaluate identity leakage in speaker de-identification (SDID) systems. The framework combines equal error rate (EER), cumulative match characteristic (CMC) hit rates, and embedding-space similarity analysis to quantify residual privacy risks. Results show that current state-of-the-art SDID systems fail to fully obscure speaker identity, with the best-performing system achieving only slightly better than random guessing performance. The findings demonstrate that single-metric evaluations are insufficient for privacy claims and that identity leakage persists across diverse architectural approaches.

## Method Summary
The evaluation framework uses the Mixer 3 corpus with 223 native American English speakers, preprocessing audio by removing initial greetings and segmenting into 10s, 30s, and 60s chunks. Three complementary metrics are computed: EER for binary verification, CMC hit rates for rank-based retrieval, and embedding-space similarity via CCA and Procrustes alignment. Three speaker identification models (TitaNet-L, ECAPA-TDNN, OLIVE) extract x-vector embeddings for evaluation. The framework includes three trial sets: original vs de-identified (privacy), de-identified vs de-identified (consistency), and cross-profile comparisons (distinctness).

## Key Results
- All SDID systems leak identity information, with VOXLET achieving only 12.29% rank-1 hit rate and 45.05% rank-50 hit rate
- Systems show decoupled privacy levers: some suppress local retrieval while preserving global alignment, others show opposite patterns
- Pseudo-profile consistency varies widely (20-44% EERs), creating secondary privacy risks through clustering and synthetic origin detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-metric evaluation reveals privacy leakage patterns that single metrics miss.
- Mechanism: Three complementary perspectives—EER (binary verification), CMC (rank-based retrieval), and embedding-space similarity (CCA/Procrustes)—expose distinct leakage facets. Local nearest-neighbor structure and global manifold alignment can decouple, meaning a system may suppress rank-1 retrieval while preserving sub-space overlap, or vice versa.
- Core assumption: Each metric captures orthogonal privacy dimensions; no single metric proxies the others.
- Evidence anchors:
  - [abstract] "benchmark that quantifies residual identity leakage with three complementary error rates"
  - [section 4] "removing local identity cues and rotating the global manifold are orthogonal privacy levers; optimizing one does not guarantee the other"
  - [corpus] Limited direct corpus support for multi-metric decoupling; related work focuses on attack methodologies rather than evaluation frameworks.
- Break condition: If metrics become highly correlated (e.g., CCA consistently predicts CMC rank-1), the multi-metric approach adds redundancy without insight.

### Mechanism 2
- Claim: Residual identity leakage persists in all evaluated SDID systems despite architectural diversity.
- Mechanism: SDID systems attempt to disentangle speaker identity from content through latent perturbation, pseudo-embedding substitution, or token conversion. However, speaker recognition models can still extract identity traces from de-identified speech embeddings, as measured by above-random CMC hit rates and non-trivial CCA correlations.
- Core assumption: The speaker identification models used are representative of attacker capabilities and are not overfitted to specific SDID artifacts.
- Evidence anchors:
  - [abstract] "all state-of-the-art speaker de-identification systems leak identity information"
  - [section 3.6.1] "VOXLET is the most permissive, achieving a rank-1 hit rate of 12.29% and a rank-50 hit rate of 45.05%"
  - [corpus] "VoxGuard" paper similarly critiques EER-only evaluation, suggesting consensus on residual leakage.
- Break condition: If an SDID system achieves EER ≈ 50%, CMC rank-50 ≈ random baseline (2.2%), and CCA-MeanTop10 < 0.5 across all SID models.

### Mechanism 3
- Claim: Pseudo-profile consistency and distinctness introduce secondary privacy vectors.
- Mechanism: SDID systems generate synthetic pseudo-voices per speaker. High within-profile consistency (low Trial-2 EER) enables tracking; poor cross-profile distinctness (high cross-profile EER) allows clustering of de-identified utterances, revealing synthetic origin and enabling linkage attacks.
- Core assumption: Attackers have access to multiple de-identified segments from the same speaker and can exploit consistency patterns.
- Evidence anchors:
  - [section 3.4] "most SDID systems yield (20–44)% EERs...suggesting pseudo-identities are often acoustically inconsistent and confusable"
  - [section 3.5] "This overlap is not benign: it enables clustering of de-identified utterances and reveals that the speech is synthetic"
  - [corpus] "You Are What You Say" paper explores linguistic content leakage, complementing pseudo-profile analysis.
- Break condition: If pseudo-voices are both internally inconsistent (EER ≈ 50%) and cross-profile indistinguishable (EER ≈ 50%), the clustering attack vector collapses.

## Foundational Learning

- Concept: **Equal Error Rate (EER)**
  - Why needed here: Interpreting Trial-1 results requires understanding that EER ≈ 50% indicates strong anonymization (verification is random), while lower EER means recognizability persists.
  - Quick check question: If a system achieves EER = 35% on Trial-1, has it fully obscured the speaker's identity?

- Concept: **Cumulative Match Characteristic (CMC)**
  - Why needed here: CMC hit-rate at rank-k reveals search-rank leakage—useful when attackers can narrow candidates to a shortlist rather than binary verification.
  - Quick check question: Why might a system with low rank-1 hit rate still pose privacy risks at rank-50?

- Concept: **Canonical Correlation Analysis (CCA) & Procrustes Alignment**
  - Why needed here: These quantify linear sub-space overlap and global manifold similarity between original and de-identified embeddings, revealing whether identity traces persist at a structural level.
  - Quick check question: If CCA-MeanTop10 = 0.85 but CMC rank-1 = 3%, what does this suggest about where identity information remains?

## Architecture Onboarding

- Component map:
  Input pipeline: Streaming speech -> SDID system (latent perturbation / pseudo-embedding / token conversion) -> de-identified output
  Evaluation pipeline: Original + de-identified audio -> SID models (TitaNet-L, ECAPA-TDNN, OLIVE) -> x-vector embeddings -> EER / CMC / CCA / Procrustes metrics
  Trial design: Trial-1 (orig vs de-ID), Trial-2 (consistency), Cross-profile (distinctness)

- Critical path:
  1. Extract embeddings from both original and de-identified segments using multiple SID architectures
  2. Compute EER for each trial set (target: 50% for Trial-1, ~0% for Trial-2 and cross-profile)
  3. Run CMC analysis (target: rank-1 < 1%, rank-50 < 15%) and embedding-space similarity (target: CCA < 0.6)
  4. Compare results across SID models to ensure architecture-agnostic privacy

- Design tradeoffs:
  - **Local vs global privacy**: Systems like SHADOW/PHORTRESS suppress local retrieval but retain sub-space overlap; Baseline/RASP do the opposite
  - **Consistency vs unlinkability**: High pseudo-voice consistency aids naturalness but enables tracking; instability reveals synthetic origin
  - **SID model diversity**: Using multiple SID architectures increases evaluation robustness but raises compute cost

- Failure signatures:
  - EER significantly below 50% on Trial-1 -> direct identity linkage possible
  - CMC rank-50 > 25% -> attacker can narrow to shortlist with non-trivial success
  - CCA-MeanTop10 > 0.8 -> global sub-space preserved, enabling attribute inference
  - Trial-2 EER near 50% -> pseudo-voices acoustically inconsistent, detectable as synthetic
  - Cross-profile EER near 50% -> pseudo-profiles overlap, enabling clustering attacks

- First 3 experiments:
  1. **Baseline establishment**: Run evaluation pipeline on unmodified Mixer 3 corpus to confirm SID models achieve low EER (3–5%) without SDID, validating the attack models.
  2. **Single-metric vs multi-metric comparison**: For each SDID system, plot EER against CMC rank-1 and CCA-MeanTop10 to visualize metric decoupling and identify systems where single-metric evaluation would misrepresent risk.
  3. **Pseudo-profile stress test**: Generate 8 pseudo-profiles per speaker, evaluate cross-profile EER and consistency across all SID models to quantify the secondary privacy vector from clustering and synthetic detection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SDID systems be jointly optimized to suppress both local identity cues (neighborhood retrieval) and global embedding alignment, given that current systems show these as decoupled privacy levers?
- Basis in paper: [explicit] "This decoupling confirms that removing local identity cues and rotating the global manifold are orthogonal privacy levers; optimizing one does not guarantee the other."
- Why unresolved: Systems like Baseline/RASP suppress rank-1 leakage but preserve strong global alignment (CCA ≈ 0.87), while SHADOW/PHORTRESS do the opposite; no system succeeds at both.
- What evidence would resolve it: Development of an SDID system achieving both rank-1 CMC near random baseline (≈0.5%) and CCA-MeanTop10 near random (≈0.46).

### Open Question 2
- Question: What causes the observed inconsistency in pseudo-voices across utterances, and can it be mitigated without compromising cross-profile distinctness?
- Basis in paper: [inferred] Trial set 2 shows most SDID systems yield 20–44% EERs for pseudo-identity consistency, indicating "acoustically inconsistent and confusable" pseudo-voices that may "expose the synthetic origin of the speech."
- Why unresolved: The paper documents the instability but does not investigate its root causes or potential fixes.
- What evidence would resolve it: Ablation studies identifying which architectural components or training procedures cause pseudo-voice drift, coupled with modified systems demonstrating stable pseudo-voices while maintaining cross-profile EERs near 0%.

### Open Question 3
- Question: Do the observed leakage patterns generalize across diverse languages, speaker populations, and recording conditions beyond native American English speakers?
- Basis in paper: [inferred] Evaluation data is limited to 223 native American English speakers from the Mixer 3 corpus; no analysis of language, accent, or channel variability on leakage metrics is provided.
- Why unresolved: Speaker embeddings and de-identification effectiveness may vary with phonological and prosodic features of different languages or speaker demographics.
- What evidence would resolve it: Replication of the multi-metric evaluation suite on multilingual corpora (e.g., VoxLingua, MLS) and varied channel conditions, comparing leakage magnitudes across conditions.

## Limitations

- The specific SDID system implementations are not publicly available, preventing exact replication of reported leakage patterns
- Evaluation is limited to a single corpus (Mixer 3) with native American English speakers, raising questions about generalizability to other languages and demographics
- The attacker model assumes access to powerful SID architectures but does not explore weaker attacker capabilities or domain adaptation scenarios

## Confidence

**High Confidence**: The multi-metric evaluation framework design and its theoretical foundations are sound. The mechanism that complementary metrics capture orthogonal privacy dimensions is well-supported by the theoretical analysis and the observation that systems exhibit different leakage patterns across metrics.

**Medium Confidence**: The claim that all SDID systems leak identity information is based on the reported results, but cannot be independently verified due to the lack of public implementations. The secondary privacy vectors from pseudo-profile consistency and distinctness are plausible but rely on assumptions about attacker access to multiple de-identified segments.

**Low Confidence**: The generalizability of the findings to other speaker populations, languages, and attack scenarios remains uncertain due to the single-corpus evaluation.

## Next Checks

1. **Metric Correlation Analysis**: For each SDID system, compute Pearson/Spearman correlation coefficients between EER, CMC rank-1, and CCA-MeanTop10 across multiple SID models. This validates whether the metrics truly capture orthogonal privacy dimensions or exhibit redundancy.

2. **Cross-Corpus Validation**: Apply the evaluation framework to a different speaker corpus (e.g., VoxCeleb, LibriSpeech) with different demographic characteristics to test the generalizability of the leakage patterns and privacy rankings.

3. **Weak Attacker Scenario**: Repeat the evaluation using only the weakest SID model (ECAPA-TDNN) and explore degraded performance through domain mismatch or reduced model capacity to understand privacy under realistic attacker constraints.