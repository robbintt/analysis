---
ver: rpa2
title: 'Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue'
arxiv_id: '2509.15061'
source_url: https://arxiv.org/abs/2509.15061
tags:
- framework
- embodied
- action
- training
- instruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of embodied agents that passively
  execute ambiguous instructions without clarification, limiting their real-world
  collaboration with humans. The authors propose Ask-to-Clarify, a framework that
  first resolves instruction ambiguity through multi-turn dialogue with a Vision-Language
  Model (VLM), then generates low-level actions end-to-end using a diffusion model.
---

# Ask-to-Clarify: Resolving Instruction Ambiguity through Multi-turn Dialogue

## Quick Facts
- arXiv ID: 2509.15061
- Source URL: https://arxiv.org/abs/2509.15061
- Authors: Xingyao Lin; Xinghao Zhu; Tianyi Lu; Sicheng Xie; Hui Zhang; Xipeng Qiu; Zuxuan Wu; Yu-Gang Jiang
- Reference count: 34
- Primary result: Achieves 95.0%, 98.3%, and 90.0% average success rates across task types on 8 real-world tasks

## Executive Summary
This paper addresses the critical limitation of embodied agents that execute ambiguous instructions without clarification, which severely limits their effectiveness in real-world human collaboration. The authors propose Ask-to-Clarify, a framework that enables agents to resolve instruction ambiguity through multi-turn dialogue with a Vision-Language Model before executing actions. The framework first engages in dialogue to clarify ambiguous instructions, then generates low-level actions using a diffusion model, achieving state-of-the-art performance on real-world tasks. The system demonstrates robust performance under challenging conditions including low-light environments and visual distractors.

## Method Summary
Ask-to-Clarify introduces a novel framework that bridges Vision-Language Models (VLMs) with diffusion-based action generation through a connection module. The system first detects instruction ambiguity and initiates multi-turn dialogue to resolve it, then translates clarified instructions into executable actions. A two-stage knowledge-insulation training strategy preserves the VLM's interaction capabilities while fine-tuning the diffusion expert for task execution. During inference, a signal detector enables seamless switching between clarification and action-taking modes, allowing the agent to dynamically respond to instruction clarity.

## Key Results
- Achieves 95.0%, 98.3%, and 90.0% average success rates across three task types
- Outperforms state-of-the-art Vision-Language Agents on 8 real-world tasks
- Demonstrates strong performance under low-light conditions and with visual distractors
- Performs on par with external VLM baselines in ambiguity-solving ability

## Why This Works (Mechanism)
The framework works by introducing an intermediate dialogue phase that resolves ambiguity before action execution. This approach addresses the fundamental limitation of current embodied agents that either fail silently on ambiguous instructions or execute potentially incorrect actions. By leveraging the reasoning capabilities of VLMs for clarification and the precision of diffusion models for action generation, the system creates a feedback loop that ensures both understanding and execution quality. The connection module serves as a crucial bridge, adapting observations based on clarified instructions to ensure the diffusion model receives contextually appropriate input.

## Foundational Learning

**Vision-Language Models (VLMs)**: Multi-modal models that process both visual and textual inputs, essential for understanding instructions in context and detecting ambiguity. Why needed: Without VLMs, the system cannot identify or resolve ambiguous instructions that require visual understanding.

**Diffusion Models for Action Generation**: Generate continuous action trajectories from noise, providing smooth and natural movements for embodied agents. Quick check: Verify that the diffusion model produces temporally consistent action sequences when given clear instructions.

**Multi-turn Dialogue Systems**: Enable iterative clarification of instructions through back-and-forth communication, essential for resolving complex ambiguities. Quick check: Ensure dialogue maintains context across multiple turns and converges on clear instructions.

## Architecture Onboarding

**Component Map**: Signal Detector -> VLM Dialogue Module -> Connection Module -> Diffusion Action Generator

**Critical Path**: Instruction Reception → Ambiguity Detection → Multi-turn Dialogue → Connection-based Observation Adjustment → Action Generation → Execution

**Design Tradeoffs**: The framework trades computational overhead from dialogue for improved execution accuracy. While the two-stage training approach preserves VLM capabilities, it requires careful balance to prevent catastrophic forgetting.

**Failure Signatures**: 
- Persistent ambiguity detection failures lead to unnecessary dialogue loops
- Connection module misalignment causes action generation from incorrect observations
- Diffusion model drift when given poorly structured input from the connection module

**First 3 Experiments**:
1. Test the signal detector's ability to distinguish between clear and ambiguous instructions across diverse task types
2. Evaluate the connection module's effectiveness in adjusting observations based on clarified instructions
3. Measure the system's performance on tasks requiring 2+ rounds of clarification versus single-round scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on 8 specifically designed tasks that may not capture full real-world complexity
- Reliance on VLMs for ambiguity detection and resolution may not generalize to novel instruction patterns
- Connection module effectiveness depends heavily on quality of instruction-based observation adjustments
- Framework performance under extended multi-round clarification sequences remains uncertain

## Confidence

**High confidence**: Framework architecture soundness; rigorous evaluation methodology using standardized metrics; substantial performance improvements over baselines.

**Medium confidence**: Generalization to unseen tasks and environments; robustness under varying conditions beyond tested scenarios.

**Low confidence**: Long-term interaction dynamics; performance with nested or compound ambiguities; multi-round dialogue effectiveness beyond tested cases.

## Next Checks

1. **Cross-environment validation**: Test framework on at least 20 additional tasks spanning different domains to assess generalization beyond current 8-task evaluation set.

2. **Multi-round interaction stress test**: Design scenarios requiring 4+ rounds of clarification to evaluate framework performance under extended dialogue sequences and potential VLM reasoning drift.

3. **Adversarial ambiguity evaluation**: Create test cases with misleading visual cues, ambiguous language patterns, and conflicting instruction types to stress-test ambiguity detection and resolution capabilities under challenging conditions.