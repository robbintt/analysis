---
ver: rpa2
title: 'ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning
  for French Toxicity Detection'
arxiv_id: '2508.11281'
source_url: https://arxiv.org/abs/2508.11281
tags:
- toxicity
- arxiv
- toxic
- french
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces TOXIFRENCH, a new dataset of 53,622 French\
  \ online comments annotated via a semi-automated pipeline, and demonstrates that\
  \ small language models (SLMs) can outperform larger models in French toxicity detection.\
  \ The authors propose a novel Chain-of-Thought (CoT) fine-tuning strategy using\
  \ a dynamic weighted loss that progressively emphasizes the model\u2019s final decision."
---

# ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection

## Quick Facts
- arXiv ID: 2508.11281
- Source URL: https://arxiv.org/abs/2508.11281
- Reference count: 40
- Primary result: Small language models outperform larger models in French toxicity detection through CoT fine-tuning

## Executive Summary
This paper introduces TOXIFRENCH, a comprehensive dataset of 53,622 French online comments annotated for toxicity detection. The authors demonstrate that small language models (SLMs) can achieve superior performance compared to larger models through a novel Chain-of-Thought fine-tuning strategy. The approach employs a dynamic weighted loss function that progressively emphasizes the model's final decision, resulting in a 10% improvement in balanced accuracy. The 4B parameter model trained with this method outperforms established models like GPT-4o and Gemini-2.5 on the benchmark while showing strong cross-lingual generalization capabilities.

## Method Summary
The authors developed a semi-automated annotation pipeline to create the TOXIFRENCH dataset, combining automated filtering with human validation. They introduced a Chain-of-Thought fine-tuning strategy that uses dynamic weighted loss, gradually shifting emphasis from reasoning steps to the final classification decision. This approach was applied to a 4B parameter language model, which was then evaluated against both larger and smaller models on the toxicity detection task. The methodology includes cross-lingual testing to assess generalization capabilities beyond the French dataset.

## Key Results
- TOXIFRENCH dataset contains 53,622 French online comments with toxicity annotations
- 4B model fine-tuned with CoT approach achieves 10% improvement in balanced accuracy
- Small language models outperform larger models (GPT-4o, Gemini-2.5) on French toxicity detection
- Strong cross-lingual generalization demonstrated across multiple languages

## Why This Works (Mechanism)
The CoT fine-tuning strategy works by leveraging intermediate reasoning steps during training, allowing the model to develop a more structured approach to toxicity detection. The dynamic weighted loss function gradually shifts the model's focus from the reasoning process to the final decision, preventing overfitting to intermediate steps while maintaining the benefits of structured thinking. This approach is particularly effective for toxicity detection because it requires nuanced understanding of context and subtle linguistic cues, which the chain-of-thought process helps capture. The progressive emphasis on final decisions ensures the model learns to make accurate judgments while still benefiting from the reasoning framework.

## Foundational Learning
- Semi-automated annotation pipelines: Why needed - To create large-scale labeled datasets efficiently while maintaining quality. Quick check - Evaluate inter-annotator agreement and label consistency.
- Chain-of-Thought prompting: Why needed - To improve reasoning capabilities in language models for complex classification tasks. Quick check - Compare performance with and without CoT on reasoning-heavy examples.
- Dynamic weighted loss functions: Why needed - To balance learning between intermediate reasoning steps and final predictions. Quick check - Analyze loss curve evolution during training.
- Cross-lingual generalization: Why needed - To ensure models work effectively across different language contexts. Quick check - Test performance on multilingual toxicity datasets.
- Balanced accuracy metrics: Why needed - To properly evaluate performance on imbalanced toxicity detection tasks. Quick check - Compare balanced vs. standard accuracy across different datasets.

## Architecture Onboarding
Component map: Input text -> Tokenization -> CoT reasoning steps -> Dynamic loss calculation -> Parameter updates -> Final classification
Critical path: The model processes input through CoT steps, with the dynamic loss function determining how much emphasis is placed on each step versus the final output during backpropagation.
Design tradeoffs: Smaller models with CoT fine-tuning vs. larger models without CoT - balancing computational efficiency with performance gains.
Failure signatures: Over-reliance on reasoning steps (low final accuracy), overfitting to training data patterns, poor cross-lingual generalization.
First experiments: 1) Train baseline model without CoT fine-tuning, 2) Vary dynamic loss weighting parameters, 3) Test cross-lingual transfer to English toxicity datasets.

## Open Questions the Paper Calls Out
None

## Limitations
- Semi-automated annotation pipeline may introduce label noise despite human validation
- 10% improvement claim depends heavily on specific evaluation methodology
- Comparison between SLMs and larger models may be influenced by architectural differences beyond size

## Confidence
High Confidence: CoT fine-tuning improves toxicity detection performance; dataset creation methodology and basic performance comparisons are well-documented.
Medium Confidence: 4B models can consistently outperform larger models like GPT-4o and Gemini-2.5 in French toxicity detection; generalization to other scenarios needs further validation.
Low Confidence: "State-of-the-art" performance across all relevant French toxicity detection benchmarks is not fully established; evaluation scope appears limited.

## Next Checks
1. Conduct blind human evaluation comparing model predictions against expert annotations on a held-out test set to validate the 10% balanced accuracy improvement.
2. Test the 4B model's performance on established multilingual toxicity detection benchmarks (e.g., Jigsaw's datasets) to assess cross-lingual generalization beyond TOXIFRENCH.
3. Perform ablation studies varying dynamic weighted loss parameters and CoT prompting strategies to quantify their individual contributions to performance gains and establish approach robustness.