---
ver: rpa2
title: 'Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative Next-User
  Modeling'
arxiv_id: '2506.15267'
source_url: https://arxiv.org/abs/2506.15267
tags:
- next-user
- user
- retrieval
- users
- cold-start
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Next-User Retrieval, a framework designed
  to address the item cold-start problem in recommendation systems. By leveraging
  lookalike modeling, it uses a transformer-based model to generate potential users
  likely to interact with cold-start items, based on sequences of users who have already
  interacted with the item.
---

# Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative Next-User Modeling

## Quick Facts
- **arXiv ID**: 2506.15267
- **Source URL**: https://arxiv.org/abs/2506.15267
- **Reference count**: 14
- **Primary result**: Increases daily active users by 0.0142% and publications by 0.1144% on Douyin platform

## Executive Summary
This paper introduces Next-User Retrieval, a framework addressing item cold-start problems in recommendation systems through lookalike modeling. The method uses a transformer-based model to generate potential users likely to interact with cold-start items by analyzing sequences of users who have already interacted with the item. By treating item features as prefix prompts and employing a causal attention mechanism, the system can generate first-user predictions even for items with no prior interactions. The framework integrates item features, models unidirectional user relationships, and is trained with a combined loss function including contrastive, cross-entropy, and auxiliary losses. Offline and online experiments on Douyin's platform demonstrate significant improvements in recommendation performance.

## Method Summary
The Next-User Retrieval framework generates potential user embeddings for cold-start items by processing sequential user interactions through a transformer encoder-decoder architecture. It uses item features (ID, category) as prefix prompts and sequential user IDs (up to 50) as input tokens, processed with causal attention where prefix tokens remain unmasked. The decoder generates a "next-user" embedding representing the likely next interacted user, which is compared against requesting users via dot-product similarity in HNSW retrieval. The model is trained with a combined loss function including contrastive loss for embedding similarity learning, cross-entropy over exposed-but-not-interacted samples, and auxiliary loss for UID reconstruction. At inference, next-user embeddings are indexed via HNSW and matched to requesting user embeddings for real-time retrieval.

## Key Results
- Achieves 0.11-0.26% relative gains in offline Recall@20/50 metrics
- Online A/B tests show 0.0142% increase in daily active users and 0.1144% increase in publications
- Ablation study shows -14.15% Recall@20 when masking prefix prompts, demonstrating their importance
- Successfully scales to Douyin's platform with seamless integration into existing HNSW-based retrieval systems

## Why This Works (Mechanism)

### Mechanism 1: Sequential User Embedding as Lookalike Signal
- Claim: Users who sequentially interact with a cold-start item encode latent preference patterns that can predict future similar users
- Mechanism: Maps sequential user IDs to embeddings, processes through causal attention, generates "next-user" embedding compared to requesting users via dot-product similarity
- Core assumption: Positive interactions in chronological order reveal stable, generalizable item appeal patterns
- Evidence: Abstract confirms transformer-based generation from interaction sequences; section 2.3 describes chronological UID storage; lookalike modeling literature supports seed-user-to-audience extension
- Break condition: When item appeal is highly idiosyncratic or sequence length is zero

### Mechanism 2: Prefix Prompts Enable Zero-Interaction Generation
- Claim: Item features (ID, category) serve as prefix prompts that bootstrap next-user generation for items with no prior interactions
- Mechanism: Prefix embeddings are unmasked in causal attention, allowing model to condition first-user generation solely on item features
- Core assumption: Item ID and category embeddings encode sufficient prior knowledge to infer likely user segments
- Evidence: Section 2.3 explains prefix prompt usage for zero-interaction items; Table 1 shows -14.15% Recall@20 when masking prefix prompt
- Break condition: When item features are entirely new and category is missing or uninformative

### Mechanism 3: Contrastive Loss Bridges Generation to HNSW Retrieval
- Claim: Contrastive loss transforms generative task into embedding-space similarity learning, making outputs directly compatible with HNSW-based retrieval
- Mechanism: Contrastive loss pulls generated next-user embedding closer to ground-truth while pushing away from random negatives
- Core assumption: Embedding similarity is valid proxy for interaction probability; HNSW can efficiently find nearest neighbors
- Evidence: Section 2.4 describes contrastive loss enabling seamless HNSW integration; abstract confirms combined loss for retrieval compatibility
- Break condition: When embedding space is poorly calibrated or HNSW index quality degrades at scale

## Foundational Learning

- **Lookalike Modeling**:
  - Why needed: Entire framework built on extending seed user signals to potential audiences for cold-start items
  - Quick check: Can you explain why seed users alone might be insufficient without sequential modeling?

- **Causal (Unidirectional) Attention**:
  - Why needed: Model must generate tokens conditioned only on preceding tokens, not future ones
  - Quick check: How does causal attention differ from bidirectional self-attention, and why is unidirectionality motivated here?

- **Contrastive Learning**:
  - Why needed: Bridges generative output to retrieval without softmax over billions of users
  - Quick check: What role does the temperature parameter play in contrastive loss?

- **HNSW (Approximate Nearest Neighbor)**:
  - Why needed: Enables real-time retrieval over massive user/item embedding spaces
  - Quick check: What is the tradeoff between recall and latency in ANN indexing?

## Architecture Onboarding

- **Component map**: Feature Engineering -> Transformer Encoder-Decoder -> Loss Computation -> Serving (HNSW indexing and matching)

- **Critical path**:
  1. Collect and store sequential UIDs in real-time (exposure-grained feature system)
  2. Construct prefix prompt from item features
  3. Run transformer encoder-decoder to generate next-user embedding
  4. Index embeddings in HNSW; compute dot-product similarity at serving time

- **Design tradeoffs**:
  - Sequence length capped at 50 (latency/storage constraints) — longer sequences may improve recall but increase serving cost
  - Only UID stored for sequential users (no contextual features) — reduces storage but limits signal richness
  - Cross-entropy loss reuses exposed-but-not-interacted samples — adds signal but introduces label noise

- **Failure signatures**:
  - Sudden recall drop: Check prefix prompt masking or sequence length reduction
  - Low retrieval quality for brand-new items: Verify prefix prompt features are populated
  - HNSW latency spikes: Monitor index freshness and embedding dimension growth

- **First 3 experiments**:
  1. Ablate prefix prompt (set to zero/mask) and measure Recall@20/50 vs. baseline — expect -10-15% relative drop per Table 1
  2. Reduce max sequence length from 50 to 25 and observe impact on recall and serving latency
  3. Disable auxiliary loss and compare generated UID embedding quality via reconstruction error (Eq. 7)

## Open Questions the Paper Calls Out
None

## Limitations
- Offline experiments evaluated only on 7-day holdout period, not capturing long-term performance or item lifecycle effects
- Performance at extreme cold-start (sequence length near zero) not fully characterized, with heavy reliance on prefix prompts
- Modest absolute improvements in online results (0.0142% DAU, 0.1144% publications) may reflect platform-specific dynamics

## Confidence
- Offline results: Medium (strong recall gains but limited temporal scope)
- Online results: Medium (statistically significant but modest absolute improvements)
- Core architectural claims: High (well-motivated and technically sound)

## Next Checks
1. **Temporal validation**: Run the model on a 30-60 day holdout period to assess performance stability and identify any degradation patterns as items age
2. **Extreme cold-start analysis**: Systematically evaluate model performance across interaction count buckets (0-5, 5-10, 10-20) to quantify prefix prompt reliability at different cold-start stages
3. **Component attribution**: Design a full factorial ablation study varying prefix prompt presence, sequence length, and each loss component to isolate their individual contributions to the observed gains