---
ver: rpa2
title: Dialogue-based Explanations for Logical Reasoning using Structured Argumentation
arxiv_id: '2502.11291'
source_url: https://arxiv.org/abs/2502.11291
tags:
- dialogue
- tree
- argument
- arguments
- argumentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a generic argumentation-based framework for
  explaining inconsistency-tolerant logical reasoning. The core idea is to represent
  logical arguments as tree structures and define collective attacks to capture non-binary
  conflicts in knowledge bases.
---

# Dialogue-based Explanations for Logical Reasoning using Structured Argumentation

## Quick Facts
- **arXiv ID:** 2502.11291
- **Source URL:** https://arxiv.org/abs/2502.11291
- **Reference count:** 40
- **Primary result:** Dialogue-based explanations using structured argumentation can explain inconsistency-tolerant reasoning in logic, handling non-binary conflicts that traditional methods cannot.

## Executive Summary
This paper proposes a generic argumentation-based framework for explaining inconsistency-tolerant logical reasoning. The core idea is to represent logical arguments as tree structures and define collective attacks to capture non-binary conflicts in knowledge bases. The authors translate various logics into proof-oriented argumentation frameworks and introduce explanatory dialogue models as dialectical proof procedures. These dialogues allow agents to exchange arguments and counter-arguments, with successful dialogues serving as explanations for query answers. The framework is shown to be sound and complete for different semantics, and is more expressive and intuitive than existing explanation formalisms. It can handle cases where traditional approaches fail, such as when multiple facts jointly cause inconsistency.

## Method Summary
The framework translates any logic definable by a consequence operator into a Proof-oriented Structured Argumentation Framework (P-SAF) with tree-structured arguments and collective attacks. It then uses a dialogue game between Proponent and Opponent agents to determine query acceptance under inconsistency-tolerant semantics. The trace of successful dialogues forms "dialectical proof trees" that serve as explanations. The method is implemented by first constructing the P-SAF from a knowledge base, then running the dialogue protocol until a winning condition is met (defensive, non-redundant, and finite dialogue trees depending on the desired semantics).

## Key Results
- The framework is sound and complete for credulous, grounded, and skeptical semantics under the specified conditions
- Collective attacks enable handling of non-binary conflicts without generating redundant arguments
- Dialogue trees provide intuitive explanations that reveal the reasoning process behind query answers
- The framework generalizes across multiple logics through the use of consequence operators

## Why This Works (Mechanism)

### Mechanism 1: Generalization via Consequence Operators
- **Claim:** If a logic can be defined by a consequence operator (satisfying expansion and idempotence), it can be translated into the proposed Proof-oriented Structured Argumentation Framework (P-SAF) to handle inconsistencies generically.
- **Mechanism:** The system abstracts specific logical rules into a generic consequence operator CN. Arguments are defined as tree-derivations where leaves are facts and roots are consequences. This decouples the argumentation machinery from the specific logical language.
- **Core assumption:** The underlying logic allows for the definition of a consequence operator that generates derivations in a tree structure, and finiteness is required for practical computation (Axiom A3).
- **Evidence anchors:** [abstract] "shows how any such logic can be translated to argumentation." [section 2] Definition 2.1 defines the consequence operator axioms.
- **Break condition:** The logic is non-Tarskian in a way that violates the minimal axioms, or argument construction becomes non-terminating due to cyclic dependencies.

### Mechanism 2: Collective Attacks for N-ary Conflicts
- **Claim:** Adopting "collective attacks" (sets of arguments attacking a single argument) allows the framework to model conflicts involving more than two formulas (n-ary) without generating redundant arguments.
- **Mechanism:** Unlike binary attacks where a single argument must neutralize another, P-SAF allows a set of arguments X to attack argument A if the union of their conclusions is inconsistent with A. This prevents the need to create artificial intermediate arguments just to satisfy binary attack requirements.
- **Core assumption:** Conflicts in the knowledge base can be non-binary (e.g., {A, B, C} is inconsistent, but no pair is).
- **Evidence anchors:** [abstract] "fail to be expressive enough for non-binary conflicts... translated to... P-SAF with collective attacks." [section 3.1] Definition 3.5 formalizes collective attacks.
- **Break condition:** The system faces purely binary conflicts, where the overhead of managing sets of arguments introduces computational complexity without representational gain.

### Mechanism 3: Dialectical Proof Trees as Explanation
- **Claim:** If a dialogue between a Proponent and Opponent terminates successfully, the resulting "dialectical proof tree" serves as a sound and complete explanation for query acceptance under inconsistency-tolerant semantics.
- **Mechanism:** The system computes acceptance via a dialogue game. The Proponent claims a query; the Opponent attacks with conflicting facts; the Proponent counter-attacks. If the Proponent has the "last word," the query is credulously accepted. The trace of this interaction forms the explanation.
- **Core assumption:** The user interprets the conflict/defense structure as a valid explanation, and the "patient" condition holds (arguments are fully constructed before being attacked).
- **Evidence anchors:** [section 4.2] Definition 4.2 describes the construction of Dialogue Trees from utterances. [section 5.2] Theorem 5.14 proves soundness for admissible semantics based on "last-word" trees.
- **Break condition:** The dialogue enters an infinite loop (e.g., cyclic arguments), failing to produce a finite explanation.

## Foundational Learning

- **Concept: Consequence Operator (CN)**
  - **Why needed here:** This is the mathematical glue that allows the framework to be "logic-agnostic." You must understand CN(X) to see how the paper moves from specific rules (like Datalog) to generic arguments.
  - **Quick check question:** If X ⊆ CN(X) holds, does adding a formula to X always increase the size of CN(X)? (Hint: Consider consistency/inconsistency).

- **Concept: Maximal Consistent Subsets (MCS)**
  - **Why needed here:** The paper's definition of "inconsistency-tolerant semantics" relies entirely on reasoning over MCSs (repairs). The argumentation framework is designed to mimic this behavior.
  - **Quick check question:** If a Knowledge Base has no conflicts, how many MCSs does it have?

- **Concept: Structured Argumentation (vs. Abstract)**
  - **Why needed here:** Unlike Dung's abstract frameworks (circles and arrows), this paper deals with the internal structure of arguments (trees of formulas) to provide explanations.
  - **Quick check question:** In abstract argumentation, an attack is just a relation. In this structured framework, what logical property defines an attack?

## Architecture Onboarding

- **Component map:** Logic Instantiator -> P-SAF Builder -> Dialogue Engine -> Tree Constructor
- **Critical path:** User Query → Logic Instantiator (find relevant arguments) → Dialogue Engine (Proponent selects best argument; Opponent identifies conflicts) → Tree Constructor (visualizes the proof)
- **Design tradeoffs:**
  - Generic vs. Efficient: The framework drops minimality/consistency constraints on arguments to support general logics, which may increase the number of generated arguments compared to specialized frameworks.
  - Completeness: The dialogue model is sound but incomplete for logics with cyclic dependencies unless "cycle-restricted" conditions are applied.
- **Failure signatures:**
  - Infinite Loop: The dialogue does not terminate (Example 5.20). Fix: Implement cycle detection or restrict the underlying logic dependency graph to be acyclic.
  - Empty Defense: The Proponent cannot find a "last-word" state; the query is not credulously accepted.
- **First 3 experiments:**
  1. Basic Propositional Translation: Implement a simple CN for Propositional Logic. Verify that the system translates a simple contradiction into collective attacks.
  2. Dialogue Simulation: Run a manual dialogue trace for the University example. Confirm the "last-word" condition is met for the query Re(v).
  3. Completeness Check: Try to compute an argument for a query involving a cyclic rule and observe if the dialogue model fails to terminate or requires specific cycle-restricted handling.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the P-SAF framework be extended to incorporate preference relations, specifically to instantiate ASPIC+ with preferences?
  - Basis in paper: [explicit] The authors state, "Note that the definition of collective attacks holds if we only consider ASPIC+ without preferences... We leave the case of preferences for future work."
  - Why unresolved: The current attack definitions and dialogue models are designed for frameworks without preferences, limiting the applicability to systems where arguments have varying strength or priority.
  - Evidence: A formal extension of the attack relations or dialogue protocols that successfully integrates a preference ordering while maintaining soundness and completeness.

- **Open Question 2:** What is the computational complexity of generating dialogical explanations and dialectical proof trees within the P-SAF framework?
  - Basis in paper: [explicit] The conclusion notes, "It would be interesting to analyze the complexity of computing the explanations empirically and theoretically."
  - Why unresolved: The paper focuses on establishing the soundness and completeness of the dialogue model but does not provide an analysis of the computational resources required to generate these explanations.
  - Evidence: Formal complexity proofs (e.g., NP-hardness) or empirical benchmarks showing runtime performance on large, inconsistent knowledge bases.

- **Open Question 3:** Does the proposed dialogue-based explanation model qualitatively improve user understanding compared to existing set-based or proof-based methods?
  - Basis in paper: [explicit] The authors state, "From practice... we will perform experiments with our approach in real-data applications. We then qualitatively evaluate our explanation by human evaluation."
  - Why unresolved: The paper approaches the problem from a theoretical viewpoint and lacks experimental validation regarding the actual impact on human users' comprehension or trust.
  - Evidence: Results from user studies measuring task success rates, subjective understanding, or explanation satisfaction when using the dialogue trees versus standard justification sets.

## Limitations
- Practical scalability concerns due to argument enumeration and collective attack detection complexity in large KBs
- Dialogue strategy specification is left open, requiring implementation decisions that may affect outcomes
- Cannot guarantee termination for cyclic dependencies without external cycle restrictions

## Confidence
- **High confidence:** The theoretical foundation linking consequence operators to argumentation frameworks is well-established and the soundness proofs for the dialogue model are rigorous.
- **Medium confidence:** The expressiveness claims for handling non-binary conflicts are supported by examples but lack comprehensive empirical validation across diverse KB structures.
- **Medium confidence:** The explanation quality of dialogue trees depends on user interpretation of conflict structures, which is not formally evaluated.

## Next Checks
1. **Complexity profiling:** Implement the framework and measure argument generation time and dialogue length as a function of KB size and conflict density to identify practical scalability limits.
2. **Strategic dialogue simulation:** Design and test different agent strategies (e.g., minimal attack selection vs. maximal coverage) to evaluate their impact on dialogue termination and explanation quality.
3. **User comprehension study:** Conduct a small-scale evaluation where users interpret dialogue trees from different KB examples to assess whether the conflict-defense structure effectively communicates the reasoning behind query answers.