---
ver: rpa2
title: Generalized Proof-Number Monte-Carlo Tree Search
arxiv_id: '2506.13249'
source_url: https://arxiv.org/abs/2506.13249
tags:
- node
- tree
- search
- proof
- games
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Generalized Proof-Number Monte-Carlo Tree Search (GPN-MCTS) addresses
  the limitations of MCTS in games with narrow winning paths by integrating PNS to
  guide exploration. The key innovations are: tracking proof numbers per player (eliminating
  disproof numbers and enabling multi-player games), evaluating three bias formulas
  (PNRank, PNMax, PNSum) for UCT selection, and combining with Score Bounded MCTS
  to handle score bounds rather than just win/loss outcomes.'
---

# Generalized Proof-Number Monte-Carlo Tree Search

## Quick Facts
- arXiv ID: 2506.13249
- Source URL: https://arxiv.org/abs/2506.13249
- Reference count: 29
- One-line primary result: GPN-MCTS achieves 80% win rate against standard MCTS on 8 of 11 tested board games by integrating proof-number search guidance.

## Executive Summary
Generalized Proof-Number Monte-Carlo Tree Search (GPN-MCTS) addresses the limitations of MCTS in games with narrow winning paths by integrating PNS to guide exploration. The key innovations are: tracking proof numbers per player (eliminating disproof numbers and enabling multi-player games), evaluating three bias formulas (PNRank, PNMax, PNSum) for UCT selection, and combining with Score Bounded MCTS to handle score bounds rather than just win/loss outcomes. Experiments on 11 board games show GPN-MCTS achieves 80% win rate against standard MCTS on 8 games, with Knightthrough scoring 63.2% and others above 60%. The PNMax and PNSum formulas are computationally cheaper than PNRank while maintaining performance. The method adds minimal overhead compared to standard MCTS.

## Method Summary
GPN-MCTS modifies MCTS selection by adding proof-number bias terms to the UCB1 formula. Each player maintains their own proof number tree where nodes where the player moves are OR nodes (any winning child suffices) and all other nodes are AND nodes (all children must be proven). Three bias formulas are evaluated: PNRank (requires sorting), PNMax (normalizes by min/max range), and PNSum (normalizes by sum of sibling proof numbers). The method integrates with Score Bounded MCTS to handle score bounds rather than just win/loss outcomes. Per-player proof numbers are tracked during backpropagation with early-stop optimization when a child's proof number equals or exceeds the parent's current value.

## Key Results
- GPN-MCTS wins 80% of games against standard MCTS on 8 of 11 tested games
- PNMax and PNSum formulas achieve comparable or better performance than PNRank with lower computational cost
- Cpn values require game-specific tuning, with optimal values ranging from 0.1 to 5.0+ across tested games
- The method adds minimal overhead, with Cpn=0 variants showing ~50% win rate against baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tracking proof numbers per player rather than root-player-only disproof numbers improves search symmetry and generalizes to N-player games.
- Mechanism: Each player maintains their own proof number tree. For player p's proof tree, nodes where p moves are OR nodes (any winning child suffices), while all other nodes are AND nodes (all children must be proven). This eliminates separate disproof logic and creates paranoid-style opponent modeling.
- Core assumption: Each player is primarily interested in proving their own win, and opponents act to prevent that win rather than maximize their own outcome.
- Evidence anchors:
  - [abstract] "we track proof numbers per player... generalizes the technique to be applicable to games with more than two players"
  - [Section 3.1] "reduces code complexity in the sense that we no longer need to encode separate logic for handling disproof numbers, and the search behaviour becomes more symmetric"
  - [corpus] Weak direct support; neighbor papers focus on parallelization and robustness, not per-player proof tracking.
- Break condition: Games where players have mixed incentives (not purely win/lose) or where paranoid assumptions fail may not benefit.

### Mechanism 2
- Claim: Simpler UCT-PN bias formulas (PNMax, PNSum) achieve comparable or better performance than PNRank with lower computational cost.
- Mechanism: PNMax normalizes proof numbers by min/max range among siblings; PNSum normalizes by sum of sibling proof numbers. Both avoid O(|I| log |I|) sorting per backpropagation. The bias term is: `Cpn × bias(i, I)` added to UCB1.
- Core assumption: Magnitude differences in proof numbers carry meaningful information about subtree provability (contradicting the original PNRank justification).
- Evidence anchors:
  - [Section 3.2.2-3.2.3] Formulas (4) and (5) define PNMax and PNSum with properties (a)-(d)
  - [Table 1] PNMax achieves 92.4% win rate on Ataxx (vs 89.5% PNRank), PNMax superior on Surakarta by 20+ percentage points
  - [corpus] No direct comparison; neighbor papers do not evaluate alternative bias functions.
- Break condition: High-branching-factor games where PNSum becomes overly sensitive to sibling count; games where ranking, not magnitude, truly matters.

### Mechanism 3
- Claim: Integrating GPN-MCTS with Score Bounded MCTS enables score bounds (not just win/loss) while reusing proven-subtree infrastructure.
- Mechanism: Score Bounded MCTS stores [lower, upper] payoff bounds per node. GPN-MCTS uses proof numbers for selection bias while Score Bounded handles subtree solving and final move selection—avoiding redundant proof trees for multiple outcomes.
- Core assumption: The computational overhead of maintaining both proof numbers and score bounds is justified by improved move selection in games with draws or multiple outcomes.
- Evidence anchors:
  - [Section 3.4] "GPN-MCTS works well when combined with the Score Bound method, and there is no significant loss of quality"
  - [Table 1] SB variants generally match or exceed non-SB variants (e.g., Ataxx PNRank+SB: 92.0% vs PNRank: 89.5%)
  - [corpus] Related work on Score Bounded MCTS cited (Cazenave & Saffidine 2011), but no corpus papers evaluate this integration.
- Break condition: Games with continuous or many-valued outcomes where discrete proof trees poorly capture value gradients.

## Foundational Learning

- Concept: **MCTS Selection with UCB1**
  - Why needed here: GPN-MCTS modifies the UCB1 selection formula by adding a proof-number bias term; understanding the base formula is prerequisite.
  - Quick check question: Given node visit counts np=100 and ni=10, compute the exploration term `C × sqrt(ln(np)/ni)` for C=√2.

- Concept: **AND/OR Trees in Proof-Number Search**
  - Why needed here: GPN-MCTS computes proof numbers differently for OR nodes (player to move) versus AND nodes (opponent to move).
  - Quick check question: In an AND node with children having proof numbers [3, 5, 2], what is the parent's proof number?

- Concept: **Score Bounded MCTS**
  - Why needed here: The recommended implementation combines GPN-MCTS with Score Bounded; understanding how score bounds propagate is essential.
  - Quick check question: If a terminal node has game-theoretic value 0.7, what are its initial lower and upper bounds?

## Architecture Onboarding

- Component map:
  - TREEPOLICY -> Selection loop with needRecalc check and BESTUCTPNCHILD
  - EXPAND -> Node creation with per-player proof number initialization
  - BACKUP -> Dual backpropagation—MCTS statistics AND proof number updates
  - UPDATEPROOFNUMBER -> OR-node (min of children) vs AND-node (sum of children) logic

- Critical path:
  1. Selection encounters `needRecalc=true` node → call `UPDATECHILDRENPNSCORES`
  2. Expansion creates node → initialize proof numbers per player
  3. Backpropagation updates both score sums and proof numbers with early-stop optimization
  4. UCT-PN formula combines v_i + exploration + Cpn × bias

- Design tradeoffs:
  - **PNRank vs PNMax vs PNSum**: PNRank requires sorting; PNMax/PNSum are O(|I|) but may over/under-weight proof magnitude differences
  - **Cpn tuning**: Game-specific; optimal values range from 0.1 to 5.0+ across tested games (Table 1 shows win rates can drop 50+ points with wrong Cpn)
  - **Lazy recalculation**: Reduces overhead but adds flag management complexity

- Failure signatures:
  - Win rate ~50% at Cpn=0 indicates overhead without benefit
  - Win rate dropping sharply at high Cpn (e.g., Surakarta: 60.6%→15.2% as Cpn increases) suggests over-biasing
  - Games with no narrow winning paths (e.g., Connect Four in preliminary tests) show no improvement or degradation

- First 3 experiments:
  1. **Overhead baseline**: Run GPN-MCTS with Cpn=0 against baseline MCTS to confirm overhead is negligible (should be ~50% win rate per Table 1)
  2. **Cpn sweep**: Test Cpn ∈ {0.1, 0.5, 1.0, 2.0, 5.0} on target game to find peak; expect significant variance across games
  3. **Bias formula comparison**: For the best Cpn, compare PNRank vs PNMax vs PNSum to determine which suits the game's branching structure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal Cpn value for a given game-UCT-PN formula combination, and can it be predicted from game characteristics?
- Basis in paper: [explicit] The paper states "the best Cpn values greatly differ for various games" and that "the spread of the winrate between the best and worst choice of Cpn is vast," with peak performance potentially occurring "at every point of the spectrum of tested values."
- Why unresolved: The tested range {0.0, 0.1, 0.5, 1.0, 2.0, 5.0} was insufficient to capture optimal values for all games, and no principled method for predicting optimal Cpn was proposed.
- What evidence would resolve it: A systematic study across a wider range of Cpn values, combined with analysis correlating optimal Cpn with quantifiable game properties (branching factor, game length, tactical depth).

### Open Question 2
- Question: Can domain knowledge be integrated into GPN-MCTS to improve performance on games where it currently shows no benefit or degrades results?
- Basis in paper: [explicit] "For some games, introducing domain knowledge is required to shape the search tree in such a way that narrow and forced paths emerge. Testing if transferring such knowledge to GPN-MCTS framework is possible and it will positively influence results for such games is one of the promising paths for future work."
- Why unresolved: The authors only briefly note that GPN-MCTS worsens results on Connect Four and Diagonals, without exploring remedies.
- What evidence would resolve it: Experiments on problematic games (Connect Four, Diagonals, Pentago, Pentalah) using domain-specific initialization or move ordering heuristics within GPN-MCTS.

### Open Question 3
- Question: How does GPN-MCTS perform in multi-player games, and does the proof-number-per-player generalization provide meaningful improvements over standard MCTS in such settings?
- Basis in paper: [explicit] "We have considered the application of GPN-MCTS in these domains as future research" after noting the technique generalizes to games with more than two players but experiments were limited to two-player games.
- Why unresolved: No multi-player experiments were conducted, despite the algorithm being designed to handle this case.
- What evidence would resolve it: Systematic evaluation on 3+ player games (e.g., Chinese Checkers, Hearts) comparing GPN-MCTS against baseline MCTS with Score Bounded enhancements.

### Open Question 4
- Question: Can a meta-selection mechanism automatically choose the best UCT-PN bias formula (PNRank, PNMax, or PNSum) for a given game without manual tuning?
- Basis in paper: [inferred] The paper concludes "there is no clear winner on which of the formulas is the best" and "the actual amount of this improvement depends on the particular pick," suggesting formula selection remains game-dependent and manual.
- Why unresolved: While the authors compare three formulas, they provide no guidance on when each is appropriate or how to automate selection.
- What evidence would resolve it: Development and validation of a classifier or meta-learner that predicts optimal formula based on game features or initial search statistics.

## Limitations
- Experimental evaluation covers only 11 games, mostly win/loss games, limiting generalizability to continuous or many-valued outcomes.
- Specific game configurations and starting positions within Ludii are not fully detailed, affecting reproducibility.
- The paper does not test games where GPN-MCTS currently shows no benefit or degrades results, leaving gaps in understanding domain limitations.

## Confidence
- **High Confidence**: Per-player proof number tracking mechanism is well-supported by claims and elimination of separate disproof logic.
- **Medium Confidence**: Performance claims of simpler bias formulas are supported by Table 1 results, but lack corpus validation introduces uncertainty.
- **Low Confidence**: Claim about PNSum sensitivity in high-branching-factor games is speculative without direct experimental evidence.

## Next Checks
1. **Overhead Baseline Verification**: Run GPN-MCTS with Cpn=0 against baseline MCTS to confirm the overhead is negligible, expecting ~50% win rate.
2. **Cpn Sensitivity Analysis**: Conduct a grid search of Cpn values (0.1, 0.5, 1.0, 2.0, 5.0) on target games to identify the optimal setting and observe performance variance.
3. **Bias Formula Comparison**: For the best Cpn, compare PNRank vs PNMax vs PNSum on games with varying branching structures to determine which formula is most effective.