---
ver: rpa2
title: 'Beyond Uncertainty Sets: Leveraging Optimal Transport to Extend Conformal
  Predictive Distribution to Multivariate Settings'
arxiv_id: '2511.15146'
source_url: https://arxiv.org/abs/2511.15146
tags:
- distribution
- prediction
- conformal
- predictive
- transport
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of extending conformal prediction
  to multivariate outputs with vector-valued scores. The key innovation is a framework
  that leverages optimal transport (OT) to define a valid multivariate ranking, enabling
  finite-sample, distribution-free coverage guarantees.
---

# Beyond Uncertainty Sets: Leveraging Optimal Transport to Extend Conformal Predictive Distribution to Multivariate Settings

## Quick Facts
- arXiv ID: 2511.15146
- Source URL: https://arxiv.org/abs/2511.15146
- Reference count: 32
- This paper presents the first framework for constructing multivariate conformal predictive distributions with finite-sample calibration guarantees using optimal transport.

## Executive Summary
This paper addresses the fundamental challenge of extending conformal prediction to multivariate outputs by developing a novel framework based on optimal transport (OT). Rather than scalarizing vector-valued scores, the method "conformalizes" the OT quantile region by defining each candidate's rank via an augmented transport map that includes the candidate itself. This preserves exchangeability and enables exact finite-sample coverage guarantees. A key computational insight is proving that the optimal assignment is piecewise-constant across a fixed polyhedral partition of the score space, making prediction sets tractable to compute via fast cell lookups. The framework is extended to construct the first multivariate Conformal Predictive Distributions (CPDs) with finite-sample calibration, generalizing the Dempster-Hill procedure to multivariate settings.

## Method Summary
The method constructs multivariate prediction sets by treating the conformal ranking problem as an optimal transport assignment between calibration scores and a discrete spherical uniform target distribution. For each candidate output, an augmented transport map is computed that includes the candidate in the source distribution. The method proves this assignment is piecewise-constant across a fixed polyhedral partition, enabling efficient computation. The framework is extended to create multivariate CPDs by using semi-discrete OT with randomization within Laguerre cells, generalizing the 1D Dempster-Hill rule. This yields the first multivariate predictive distributions with exact finite-sample calibration guarantees, avoiding data splitting, parametric assumptions, and the curse of dimensionality associated with learning OT maps.

## Key Results
- Proves that the optimal assignment is piecewise-constant across a fixed polyhedral partition, enabling tractable computation of multivariate prediction sets
- Constructs the first multivariate conformal predictive distributions with exact finite-sample calibration guarantees
- Achieves distribution-free coverage without data splitting or parametric assumptions on the underlying data distribution
- Provides both conservative and exact randomized versions, with the latter yielding valid multivariate distributions where any derived uncertainty region has guaranteed coverage

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Including the candidate test point in the optimal transport computation preserves exchangeability, enabling finite-sample coverage guarantees for multivariate prediction sets.
- **Mechanism:** For each candidate z ∈ ℝ^d, the method computes an augmented transport map T^z_{n+1} on the source distribution μ_Z = (1/(n+1))(∑δ_{Z_i} + δ_Z) → target ν_{n+1}. The candidate's "rank" is the norm ∥ψ(Z)∥ where ψ(Z) = T^z_{n+1}(Z) is the assigned target point. By construction, when Z = Z_{n+1} (the true test point), the assigned target follows the discrete spherical uniform distribution, yielding a valid probability integral transform.
- **Core assumption:** Exchangeability of (Z_1, ..., Z_n, Z_{n+1}) — no distributional assumptions beyond this.
- **Evidence anchors:**
  - [abstract]: "a candidate's rank is defined via a transport map computed for the calibration scores augmented with that candidate's score—a step crucial for preserving validity"
  - [section 4.1.1, p.17-18]: Defines augmented source measure μ_Z and proves Proposition 4.1 that P(Z_{n+1} ∈ Q_{r_{α,n+1}}) ≥ 1-α
  - [corpus]: Klein et al. (2025) "Multivariate Conformal Prediction using Optimal Transport" uses pre-fit transport with three-way splitting — this paper explicitly contrasts its approach as avoiding learned maps to retain exact validity
- **Break condition:** If data are not exchangeable (e.g., strong temporal drift, adversarial distribution shift), the finite-sample guarantee does not apply. The method does not address online/adversarial settings.

### Mechanism 2
- **Claim:** The optimal assignment function is piecewise-constant across a fixed polyhedral partition of the score space, reducing an infinite problem to finite computation.
- **Mechanism:** The cost function f_k(Z) = ¯c(Z,k) + C_k is quadratic in Z, where C_k is the pre-computed optimal n→n assignment cost with target column k removed. The decision region R_k = {Z: f_k(Z) ≤ f_ℓ(Z) ∀ℓ} is a convex polyhedron defined by affine half-spaces. The partition {R_k} is fixed once calibration data and target grid are set. At test time, membership is O(n) per dimension to check.
- **Core assumption:** Discrete target distribution on fixed grid points; no ties in costs (generic position).
- **Evidence anchors:**
  - [abstract]: "we prove that the resulting optimal assignment is piecewise-constant across a fixed polyhedral partition of the score space"
  - [section 4.3, Proposition 4.4, p.20]: R_j = {Z: ⟨Z, U_k - U_j⟩ ≤ β_{j,k}} proved as convex polyhedron
  - [corpus]: Weak direct evidence — corpus papers on OT-based CP don't address this tractability theorem
- **Break condition:** Pre-computation requires O(n^4) worst-case (n+1 assignments of O(n³) each). For n > 10,000 calibration points, this becomes prohibitive without approximation (e.g., Sinkhorn regularization), which would compromise exact validity.

### Mechanism 3
- **Claim:** Semi-discrete optimal transport with randomization within Laguerre cells yields the first multivariate conformal predictive distributions with exact finite-sample calibration.
- **Mechanism:** The continuous target U is partitioned into equal-mass Laguerre cells A_k via semi-discrete OT. The randomized map ̃T_{n+1}(Z_i, τ_i) ~ U(·|A_{σ*(i)}) samples uniformly within each cell. This generalizes the 1D Dempster-Hill rule (gaps → cells), and ̃T_{n+1}(Z_{n+1}, τ) ~ U exactly, giving the multivariate PIT.
- **Core assumption:** Continuous target distribution U (spherical uniform); equal-mass cells U(A_k) = 1/(n+1); i.i.d. auxiliary randomness τ.
- **Evidence anchors:**
  - [abstract]: "the latter resulting in a multivariate generalization of the classical Dempster-Hill procedure"
  - [section 5.2, Theorem 5.1, p.27]: Proves P^{(n+1)}(̃T_{n+1}(Z_{n+1}, τ) ∈ B) = U(B)
  - [corpus]: No corpus evidence on multivariate CPDs — this appears to be a genuinely novel contribution
- **Break condition:** Sampling uniformly within high-dimensional Laguerre cells may be non-trivial. Monotonicity of the full predictive distribution map is only proven for residual scores S(x,y) = y - ŷ(x), not general score functions.

## Foundational Learning

- **Concept: Split Conformal Prediction and Exchangeability**
  - **Why needed here:** The entire validity argument hinges on exchangeability of calibration + test points. Without this, the probability integral transform argument fails.
  - **Quick check question:** Given calibration scores Z_1, ..., Z_n and test score Z_{n+1}, what distribution does the empirical CDF F_n(Z_{n+1}) follow if points are exchangeable?

- **Concept: Monge-Kantorovich Optimal Transport**
  - **Why needed here:** The core construction uses Brenier maps to push source distributions to target distributions, generalizing the CDF to multivariate settings.
  - **Quick check question:** What is the pushforward constraint T_♯μ = ν, and why does Brenier's theorem guarantee a unique gradient-of-convex solution when μ is absolutely continuous?

- **Concept: Probability Integral Transform (PIT)**
  - **Why needed here:** Validity is characterized as the transformed variable being uniform: F(Z) ~ Uniform[0,1]. This paper constructs multivariate analogues where T*(Z) ~ Uniform(ball).
  - **Quick check question:** If a predictive distribution G_n+1 is "valid," what is the distribution of G_n+1(Y_{n+1})?

## Architecture Onboarding

- **Component map:**
  Calibration scores {Z_1,...,Z_n} → Target grid construction {U_j} (spherical uniform discretization) → Pre-compute C_k = min_{σ: [n]→[n+1]\{k}} Σ∥Z_i - U_{σ(i)}∥² for each k → Construct polyhedral partition {R_k} via half-space intersections → Test time: For query Z, find k* = argmin_k f_k(Z), return ψ(Z) = U_{k*}

- **Critical path:** The pre-computation stage solving n+1 assignment problems dominates cost. The target grid construction (choosing n_S, n_R, n_o) affects both geometry and the coverage threshold r_{α,n+1} = j_α/n_R where j_α = ⌈((n+1)(1-α) - n_o)/n_S⌉.

- **Design tradeoffs:**
  - **Exact vs. approximate solvers:** Hungarian algorithm gives exact O(n³) per assignment; Sinkhorn gives O(n²) but loses theoretical validity
  - **Discrete vs. semi-discrete formulation:** Discrete is simpler but produces set-valued CDFs; semi-discrete with randomization gives continuous predictive distributions
  - **Conservative vs. randomized:** Conservative version yields P(coverage) ≥ 1-α; randomized version yields P(coverage) = 1-α exactly but requires auxiliary randomness

- **Failure signatures:**
  - **Unbounded regions:** If r ≥ 1, some active cells R_k may be unbounded (Proposition 4.5 only guarantees boundedness for r < 1)
  - **Numerical instability:** Polyhedral boundaries depend on differences ∥U_k∥² - ∥U_j∥² and C_k - C_j; floating-point errors can misclassify boundary points
  - **Monotonicity violation:** For non-residual score functions, y ↦ T_{n+1}(y) may not be monotone, invalidating CPD interpretation

- **First 3 experiments:**
  1. **2D Gaussian validation:** Generate Z_i ~ N(0, Σ) with correlated covariance; verify empirical coverage matches 1-α across α ∈ {0.1, 0.2, ..., 0.5}; visualize polyhedral partition and compare shape to elliptical sets from Mahalanobis-norm scalarization
  2. **Ablation on calibration set size:** Test n ∈ {50, 100, 500, 1000}; measure pre-computation time, prediction set volume, and coverage gap |P(coverage) - (1-α)|; identify where O(n⁴) becomes limiting
  3. **Multi-output regression benchmark:** Apply to a multi-task dataset (e.g., energy prediction with multiple outputs); compare against: (a) ℓ₂-norm scalarization + standard CP, (b) Mahalanobis CP, (c) this method; report set volume, coverage, and whether directional information is preserved in the prediction region shape

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the necessary and sufficient conditions for a general vector-valued score function to yield a monotone (or cyclically monotone) multivariate conformal predictive distribution map?
- **Basis in paper:** [explicit] Section 4.5 and Section 6 explicitly state that characterizing these conditions beyond the specific case of the residual score $S(x,y) = y - \hat{y}(x)$ remains an open problem.
- **Why unresolved:** The authors prove monotonicity for residual scores but note that even for general affine score functions with positive semi-definite matrices, Euclidean monotonicity is not guaranteed, making the general characterization difficult.
- **What evidence would resolve it:** A theoretical derivation establishing the precise class of score functions for which the composed map $y \mapsto T_{n+1}(S(X_{n+1}, y))$ preserves the cyclical monotonicity required for a valid predictive distribution.

### Open Question 2
- **Question:** Does the framework maintain valid finite-sample calibration guarantees when the exact optimal transport pre-computation is replaced by regularized or approximate solvers (e.g., Sinkhorn)?
- **Basis in paper:** [explicit] Section 6 notes that while approximations like the Sinkhorn algorithm can reduce the $O(n^4)$ complexity, "The consequences of such approximations on the final calibration are not known; we leave it for future work."
- **Why unresolved:** Approximating the costs $\hat{C}_k$ results in an approximate polyhedral partition where the assignment of test points may no longer be exact, potentially violating the exchangeability assumptions used to prove coverage.
- **What evidence would resolve it:** A theoretical analysis quantifying the coverage error introduced by specific approximation tolerances, or a modified algorithm that accounts for approximation uncertainty to restore exact finite-sample guarantees.

### Open Question 3
- **Question:** Can the multivariate predictive distribution construction be extended to the full conformal prediction setting where the underlying predictive model is refitted for every candidate output?
- **Basis in paper:** [explicit] Section 6 and Remark 4.1 explicitly highlight this limitation, stating that current monotonicity results are "currently limited to the split-CP setting; they do not apply to the full CP setting."
- **Why unresolved:** In full conformal prediction, the model parameters (and thus the score function) depend on the candidate $y$, disrupting the monotonicity properties established for the fixed split-conformal predictor.
- **What evidence would resolve it:** A proof demonstrating that the map remains monotone under the model refitting procedure of full CP, or a theoretical result identifying specific model classes where this property holds.

## Limitations
- **Computational scaling:** The O(n⁴) pre-computation for n calibration points becomes prohibitive beyond n ≈ 1,000, and the paper doesn't address approximation strategies that preserve validity
- **Implementation gaps:** The polyhedral partition representation and efficient union computation for d ≥ 2 dimensions are described as "easily computable" without algorithmic details
- **Monotonicity restriction:** Monotonicity of the predictive distribution is only established for residual score functions, not general score transformations

## Confidence
- **High confidence:** The exchangeability-based validity argument and piecewise-constant assignment theorem (Mechanism 1 and 2) - these follow directly from classical OT theory and are well-proven
- **Medium confidence:** The semi-discrete randomized CPD construction (Mechanism 3) - while the theoretical framework is sound, practical implementation details for high-dimensional Laguerre cell sampling are not fully specified
- **Medium confidence:** The computational complexity claims - the O(n⁴) bound is derived but practical implementations with approximate solvers would need validation

## Next Checks
1. **Scaling validation:** Implement the method for increasing calibration set sizes (n = 100, 500, 1000, 2000) and measure pre-computation time, prediction set volumes, and coverage gaps; identify the exact n where O(n⁴) becomes impractical and test whether approximate solvers (e.g., Sinkhorn) maintain validity within acceptable bounds
2. **Multi-output regression benchmark:** Apply to a real multi-output dataset (e.g., UCI Energy dataset with multiple targets); compare against Mahalanobis CP, ℓ₂-norm scalarization CP, and evaluate whether directional information in the score space is preserved in the prediction region shape
3. **Boundary behavior analysis:** Systematically test the method's behavior near distributional boundaries - generate data with strong correlations, outliers, and adversarial configurations; verify that the polyhedral partition correctly captures the geometry and that coverage guarantees hold in these challenging scenarios