---
ver: rpa2
title: Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species
  Plant Identification
arxiv_id: '2507.06093'
source_url: https://arxiv.org/abs/2507.06093
tags:
- images
- species
- test
- training
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We address multi-species plant identification in vegetation quadrat
  images by fine-tuning a Vision Transformer on single-label data and adapting it
  to multi-label inference without additional training. Our method tiles high-resolution
  quadrat images into 4x4 grids matching the model's 518px receptive field, classifies
  each tile independently, and aggregates predictions via majority vote.
---

# Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification

## Quick Facts
- arXiv ID: 2507.06093
- Source URL: https://arxiv.org/abs/2507.06093
- Reference count: 21
- Achieved macro-averaged F1 of 0.348 on PlantCLEF 2025 private leaderboard, ranking second

## Executive Summary
This work addresses multi-species plant identification in high-resolution quadrat images by adapting a Vision Transformer trained on single-label data to multi-label inference without additional training. The approach tiles images into 4x4 grids, classifies each tile independently, and aggregates predictions via majority voting. To improve robustness to domain shifts, the method applies visual clustering to identify coherent image groups and re-weights tile-level probabilities using cluster-specific Bayesian priors, further refined with geolocation filtering. The pipeline achieves strong performance on the PlantCLEF 2025 challenge, demonstrating the effectiveness of scale-aware tiling and prior re-weighting for zero-shot transfer.

## Method Summary
The method fine-tunes a Vision Transformer on single-label plant species data, then adapts it to multi-label quadrat images without retraining. High-resolution quadrat images are tiled into 4x4 grids matching the model's 518px receptive field, with each tile classified independently. Predictions are aggregated via majority vote across tiles. To address domain shift, PaCMAP + K-Means clustering identifies three coherent image groups, and cluster-specific Bayesian priors re-weight tile-level probabilities. Geolocation filtering further refines candidate species lists, enabling effective zero-shot transfer from single- to multi-label plant recognition.

## Key Results
- Achieved macro-averaged F1 of 0.348 on PlantCLEF 2025 private leaderboard
- Ranked second in the competition
- Demonstrates effectiveness of scale-aware tiling and prior re-weighting for zero-shot transfer

## Why This Works (Mechanism)
The method works by decomposing high-resolution quadrat images into manageable tiles that match the Vision Transformer's receptive field, enabling effective local species detection. By aggregating tile predictions through majority voting, the approach captures multi-species presence within each quadrat. The visual-cluster priors address domain shift by identifying coherent image groups and re-weighting predictions based on cluster-specific Bayesian probabilities, while geolocation filtering further refines results by incorporating spatial context. This combination allows effective zero-shot adaptation from single-label to multi-label inference without additional training.

## Foundational Learning
- **Vision Transformer (ViT)**: A transformer-based architecture for image classification that processes patches of images using self-attention mechanisms. Why needed: Provides strong feature extraction for plant species recognition. Quick check: Verify tile size matches model's receptive field.
- **Visual Clustering (PaCMAP + K-Means)**: Dimensionality reduction and clustering techniques to identify coherent groups in image data. Why needed: Enables domain adaptation by grouping similar image distributions. Quick check: Report silhouette scores for cluster quality.
- **Bayesian Priors**: Probability distributions that encode prior knowledge for updating predictions. Why needed: Allows incorporation of domain-specific information through cluster-specific re-weighting. Quick check: Validate prior stability across different data splits.

## Architecture Onboarding

**Component Map**
Preprocessing (tile generation) -> ViT model (tile classification) -> Visual clustering (domain grouping) -> Bayesian prior re-weighting -> Geolocation filtering -> Final prediction

**Critical Path**
The critical path for inference is: Image tiling → ViT classification of each tile → Majority vote aggregation → Bayesian prior re-weighting → Geolocation filtering → Final species list. Each stage must complete successfully for accurate multi-label prediction.

**Design Tradeoffs**
Tile size vs. receptive field matching: 4x4 tiling with 518px tiles balances local detail capture against computational efficiency. Single-label to multi-label adaptation without retraining trades potential fine-tuning gains for zero-shot flexibility. Cluster-based priors versus direct fine-tuning on multi-label data balances domain adaptation with training simplicity.

**Failure Signatures**
Poor cluster quality (low silhouette scores) indicates priors may not capture meaningful domain shifts. Mismatched tile size to receptive field causes loss of contextual information. Geolocation filtering failure occurs when metadata is incomplete or noisy. Majority voting breakdown happens when species distribution is highly imbalanced across tiles.

**3 First Experiments**
1. Validate that 518px tile size matches the ViT model's receptive field by testing with different tile dimensions
2. Measure cluster quality using silhouette scores to confirm visual clusters capture meaningful domain groups
3. Perform ablation by removing geolocation filtering to quantify its contribution to final performance

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Cluster quality and stability metrics are not reported, making it unclear whether priors capture meaningful domain shifts
- Geolocation filtering effectiveness is asserted but not independently validated
- Tile size assumption (518px) may not generalize to different plant species or imaging conditions
- No validation of label noise in single-label training data that could propagate to multi-label predictions

## Confidence
- Core pipeline (ViT fine-tuning + tiling + majority vote): High
- Visual-cluster priors: Medium
- Geolocation filtering: Medium

## Next Checks
1. Report cluster stability and quality metrics (e.g., silhouette scores) for the visual-cluster priors
2. Perform ablation study removing geolocation filtering to quantify its contribution
3. Test the pipeline on an external, geographically distinct plant dataset to assess domain transfer