---
ver: rpa2
title: 'Muon: Training and Trade-offs with Latent Attention and MoE'
arxiv_id: '2509.24406'
source_url: https://arxiv.org/abs/2509.24406
tags:
- muon
- training
- batch
- efficiency
- adamw
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a theoretical and empirical analysis of the\
  \ Muon optimizer for training small to medium transformer-based language models\
  \ (30M\u2013200M parameters). The key contribution is demonstrating that Muon expands\
  \ the Pareto frontier in the compute-time trade-off by maintaining superior data\
  \ efficiency at large batch sizes, achieving 48\u201352% compute reduction compared\
  \ to AdamW while maintaining or improving final perplexity."
---

# Muon: Training and Trade-offs with Latent Attention and MoE

## Quick Facts
- arXiv ID: 2509.24406
- Source URL: https://arxiv.org/abs/2509.24406
- Authors: Sushant Mehta; Raj Dandekar; Rajat Dandekar; Sreedath Panat
- Reference count: 23
- Key outcome: Muon achieves 48–52% compute reduction vs AdamW while maintaining/improving perplexity on 30M–200M parameter transformers

## Executive Summary
This paper presents Muon, an optimizer that expands the compute-time Pareto frontier for transformer-based language models by maintaining superior data efficiency at large batch sizes. The key insight is spectral normalization via orthogonalization that prevents gradient explosion while permitting larger learning rates. When combined with Multi-Head Latent Attention (MLA) and Mixture-of-Experts (MoE), Muon achieves multiplicative efficiency gains: 68% memory reduction, 3.2× inference speedup, and 8–12% perplexity improvement on small-to-medium scale models.

## Method Summary
Muon implements matrix sign function normalization through Newton-Schulz iterations (K=5 with coefficients 3.4445, -4.7750, 2.0315) applied to momentum matrices, constraining their spectral norm to 1. This provides automatic step-size control while treating weight matrices as geometric objects on the Stiefel manifold. The optimizer includes RMS scaling (s=0.2√n) for magnitude matching with AdamW and decoupled weight decay (λ∈{0.05, 0.1}). Training uses cosine decay with 0.5–2% warmup, gradient clipping 1.0, bfloat16 compute with float32 accumulation, and focuses on 2D weight matrices while leaving biases, embeddings, and scalars untouched.

## Key Results
- 48–52% compute reduction vs AdamW while maintaining or improving final perplexity on 30M–200M parameter models
- Non-decreasing token consumption ratio R_L(B) shows Muon's advantage persists at large batch sizes
- Combined with MLA and MoE: 68% memory reduction, 3.2× inference speedup, 8–12% perplexity improvement
- O(1/√T) convergence rate proven with spectral regularization preventing gradient explosion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spectral normalization via orthogonalization prevents gradient explosion while permitting larger learning rates.
- Mechanism: Muon applies `msign(M) = M(M^T M)^{-1/2}` to the momentum matrix, which constrains the spectral norm of updates to 1 uniformly. This bounded spectrum provides automatic step-size control, preventing runaway updates while allowing more aggressive optimization.
- Core assumption: Loss function L is L-smooth (gradients are Lipschitz continuous).
- Evidence anchors:
  - [abstract] "spectral regularization properties that prevent gradient explosion"
  - [Section 2.3] Theorem 2 proof sketch: "The key insight is that ∥msign(Mt)∥2 = 1 uniformly, providing automatic step-size control"
  - [corpus] "On the Convergence Analysis of Muon" (arXiv:2505.23737) provides independent convergence analysis supporting bounded spectral properties
- Break condition: If loss landscape has sharp curvature beyond L-smoothness assumptions, spectral normalization alone may not prevent instability; momentum hyperparameter β becomes critical.

### Mechanism 2
- Claim: Matrix-structured updates exploit weight matrix geometry better than vectorized AdamW updates.
- Mechanism: Muon treats weight matrices as geometric objects on the Stiefel manifold (for square matrices) or spectrally-constrained matrices, performing natural gradient descent in this geometry rather than treating parameters as flattened vectors.
- Core assumption: Matrix structure encodes meaningful geometric information lost by vectorization.
- Evidence anchors:
  - [abstract] "connection to natural gradient descent on the Stiefel manifold"
  - [Section 2.4] Proposition 5: "Muon performs a natural gradient descent on the Stiefel manifold"
  - [corpus] LiMuon (arXiv:2509.14562) validates that matrix-aware optimization scales to large models
- Break condition: Highly non-square matrices (m ≪ n or m ≫ n) may reduce geometric benefits; the paper only tests m/n ratios typical of transformer layers.

### Mechanism 3
- Claim: Superior data efficiency at large batch sizes enables compute-time tradeoffs unavailable to AdamW.
- Mechanism: Token consumption ratio R_L(B) = T_L,AdamW(B) / T_L,Muon(B) remains non-decreasing with batch size B. This means Muon's relative advantage persists or grows in the post-critical-batch-size regime where AdamW shows diminishing returns.
- Core assumption: The non-decreasing R_L(B) property generalizes across scales and tasks (validated here on 30M-200M models).
- Evidence anchors:
  - [abstract] "maintaining superior data efficiency at large batch sizes"
  - [Section 3.1] Equation 12 defining R_L(B) and its non-decreasing behavior
  - [corpus] Corpus confirms "Practical Efficiency of Muon for Pretraining" (cited as [2]) established this finding at larger scales
- Break condition: Very small batch sizes may not show advantage; break condition occurs below the regime where AdamW's efficiency degrades (batch sizes < critical batch size).

## Foundational Learning

- Concept: Matrix Sign Function and Polar Decomposition
  - Why needed here: Muon's core operation is computing `msign(M)` via polar decomposition; understanding this explains why updates are spectrally bounded.
  - Quick check question: If M = UΣV^T (SVD), what is msign(M) and what constraint does it satisfy on its singular values?

- Concept: Spectral Norm vs Frobenius Norm
  - Why needed here: Muon normalizes under spectral norm (largest singular value = 1) rather than Frobenius norm, which preserves rank structure and prevents gradient explosion differently.
  - Quick check question: Why does ∥U∥₂ = 1 provide different guarantees than ∥U∥_F = 1 for controlling gradient updates?

- Concept: Stiefel Manifold and Orthogonal Constraints
  - Why needed here: The paper claims Muon performs natural gradient descent on the Stiefel manifold for square matrices; understanding this geometric framing explains the optimizer's inductive bias.
  - Quick check question: What is the Stiefel manifold and why does optimization on it differ from unconstrained Euclidean optimization?

## Architecture Onboarding

- Component map: Gradient → Momentum update → Newton-Schulz orthogonalization (K=5 iterations) → RMS scaling → Weight update with decay
- Critical path: The Newton-Schulz coefficients and iteration count are the most sensitive implementation details.
- Design tradeoffs:
  - K=5 iterations balances accuracy vs compute (K=3 underperforms, K=10 marginally better but higher cost)
  - RMS matching enables hyperparameter transfer from AdamW but assumes similar update magnitude scales
  - Memory: 50% reduction vs AdamW (one momentum matrix vs first+second moments)
- Failure signatures:
  - Loss spikes with no RMS matching (Table 2: 7 spikes vs 0)
  - Slower convergence with K<5 Newton-Schulz iterations (22k vs 17k steps to target)
  - Instability with Taylor coefficients vs optimized coefficients
- First 3 experiments:
  1. Replicate Table 2 ablation: Compare full Muon vs "no orthogonalization" on M model to validate spectral regularization claim.
  2. Batch size sweep: Replicate Figure 2 on your model scale to confirm R_L(B) > 1 is non-decreasing for your data distribution.
  3. Architecture combination test: Compare MHA+Muon vs MLA+Muon vs MoE-MLA+Muon to validate multiplicative gains (targeting Table 3 metrics: memory, inference speed, perplexity).

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset dependency: Absolute perplexity numbers and training dynamics heavily depend on specific corpus used
- Scale extrapolation gap: Benefits demonstrated on 30M-200M models may not generalize to very large models where second-order effects dominate
- Architecture specificity: Multiplicative gains with MLA and MoE demonstrated only on decoder-only transformers

## Confidence
- High confidence: Compute-time Pareto frontier expansion (48-52% reduction) and O(1/√T) convergence rate
- Medium confidence: Stiefel manifold connection and spectral norm equivalence (mathematically rigorous but rely on L-smoothness assumptions)
- Low confidence: muP-based hyperparameter transfer beyond tested scales and universality of Newton-Schulz coefficients

## Next Checks
- Check 1: Dataset robustness validation - Replicate M model training on different language modeling datasets to verify 48-52% compute reduction holds across data distributions
- Check 2: Architecture generalization test - Implement Muon for BERT-style encoder models and encoder-decoder architectures to validate benefits extend beyond decoder-only transformers
- Check 3: Scale boundary exploration - Train 500M-1B parameter models using muP scaling to monitor degradation in R_L(B) properties and convergence stability