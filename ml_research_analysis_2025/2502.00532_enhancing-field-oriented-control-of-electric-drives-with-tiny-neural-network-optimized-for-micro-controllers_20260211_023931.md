---
ver: rpa2
title: Enhancing Field-Oriented Control of Electric Drives with Tiny Neural Network
  Optimized for Micro-controllers
arxiv_id: '2502.00532'
source_url: https://arxiv.org/abs/2502.00532
tags:
- control
- speed
- tinyfc
- test
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a neural network-enhanced Field-Oriented Control
  (FOC) system for Permanent Magnet Synchronous Motors (PMSMs) optimized for microcontroller
  deployment. The proposed TinyFC neural network augments traditional PI controllers
  to address their limitations in handling nonlinear dynamics and system uncertainties.
---

# Enhancing Field-Oriented Control of Electric Drives with Tiny Neural Network Optimized for Micro-controllers

## Quick Facts
- arXiv ID: 2502.00532
- Source URL: https://arxiv.org/abs/2502.00532
- Authors: Martin Joel Mouk Elele; Danilo Pau; Shixin Zhuang; Tullio Facchinetti
- Reference count: 30
- Primary result: Tiny neural network reduces PMSM speed control overshoot by 87.5% and deviation by 60% on microcontroller

## Executive Summary
This paper presents a neural network-enhanced Field-Oriented Control (FOC) system for Permanent Magnet Synchronous Motors (PMSMs) optimized for microcontroller deployment. The proposed TinyFC neural network augments traditional PI controllers to address their limitations in handling nonlinear dynamics and system uncertainties. Through advanced optimization techniques including pruning, hyperparameter tuning, and 8-bit quantization, the model was reduced to 1,400 parameters while maintaining effectiveness. Experimental results demonstrated significant performance improvements: the pruned model achieved up to 87.5% reduction in overshoot and 60% reduction in average deviation compared to PI-only control.

## Method Summary
The TinyFC model takes three inputs—reference speed, measured speed, and PI-predicted quadrature current—and outputs a compensation term to correct the PI controller's predictions. The network architecture consists of two branches with five fully connected layers each, including residual connections, trained to minimize MSE loss. Ground truth data was adjusted using threshold saturation for step signals and exponential decay rectification for ramp/step combinations to eliminate overshoots in the training data. The model was optimized through Bayesian hyperparameter optimization, PCA-based projection pruning, and 8-bit post-training quantization using ST Edge AI Developer Cloud tools, targeting deployment on an STM32G474RE microcontroller.

## Key Results
- Pruned TinyFC model achieved 87.5% reduction in overshoot compared to PI-only control
- Average deviation reduced by 60% with TinyFC augmentation
- Optimized model meets real-time constraints with 207.4μs inference time on STM32G474RE MCU
- Model reduced to 1,400 parameters while maintaining effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The TinyFC network improves system response by operating as a residual feedforward compensator that corrects the inherent lag and oscillation of the baseline PI controller.
- **Mechanism:** The network predicts a compensation term (Δi_q) based on reference speed, measured speed, and the PI's own output. By adding this term to the PI output, the system actively cancels the transient errors the linear controller fails to address, effectively dampening the response.
- **Core assumption:** The PI controller's structural limitations can be approximated and counteracted by a static feedforward network without requiring recurrent memory states.
- **Evidence anchors:** The abstract mentions the network "augments traditional PI controllers to address their limitations," and section 4 describes the architecture where TinyFC outputs an adjustment value for the PI's prediction.
- **Break condition:** If system dynamics change significantly such that the PI behaves differently than training distribution, the feedforward correction may become out-of-phase, potentially destabilizing the loop.

### Mechanism 2
- **Claim:** Performance gains are contingent on "Ground Truth Rectification" during training, where the network learns an idealized response rather than mimicking the flawed PI behavior.
- **Mechanism:** The authors modified the training dataset by capping overshoots and smoothing transitions using thresholding and exponential decay. This forces the network to learn a "corrected" form of the quadrature current that adheres to physical constraints, effectively teaching the network to suppress the oscillations present in the raw PI data.
- **Core assumption:** The heuristics used for signal rectification accurately represent the optimal motor response for specific test cases.
- **Evidence anchors:** Section 4 details the adjustment of reference quadrature current to eliminate sections containing overshoots, and section 6 notes that the pruned model further reduced oscillations.
- **Break condition:** If manual thresholding is set too aggressively, the network may learn a response that is too slow, failing to meet rise-time requirements.

### Mechanism 3
- **Claim:** Real-time feasibility is achieved via aggressive optimization (Pruning/Quantization), though it introduces a tradeoff between model size and inference stability.
- **Mechanism:** 8-bit quantization and PCA-based pruning reduce memory footprint and MACC operations. While this lowers latency from what a larger network would require, the paper notes that aggressive optimization can degrade control stability even if MSE is low, because low-level weight precision impacts smoothness of the control signal.
- **Core assumption:** The STM32G474RE MCU can tolerate the inference latency within the speed control loop cycle.
- **Evidence anchors:** The abstract highlights 8-bit quantization and pruning reduced the model to 1,400 parameters, and section 6.3 shows quantized pruned model has higher latency than TinyFC model.
- **Break condition:** If speed loop frequency is increased beyond approximately 2-3 kHz, the 300+ μs latency of quantized models will exceed control period, causing jitter or loop failure.

## Foundational Learning

- **Concept:** **Field-Oriented Control (FOC) & D-Q Reference Frame**
  - **Why needed here:** The paper assumes the reader understands that FOC transforms motor currents into Direct (i_d) and Quadrature (i_q) components to control torque and flux independently. TinyFC specifically targets the i_q reference adjustment.
  - **Quick check question:** Why does the controller aim to keep i_d (direct current) at zero in this context?

- **Concept:** **PI Control Limitations (Nonlinearity & Overshoot)**
  - **Why needed here:** The core motivation is that fixed-gain PI controllers struggle with the nonlinear nature of PMSMs, leading to overshoot and oscillation which TinyFC aims to fix.
  - **Quick check question:** Why would a "simple" PI controller produce overshoot during rapid speed transitions in a PMSM?

- **Concept:** **Post-Training Quantization (PTQ) vs. Float32**
  - **Why needed here:** The paper relies on converting 32-bit floating-point weights to 8-bit integers to fit the model onto the microcontroller. Understanding this is critical to interpreting the "Deployability" metrics.
  - **Quick check question:** How does reducing weight precision from 32-bit float to 8-bit integer affect the RAM footprint and mathematical precision of the control signal?

## Architecture Onboarding

- **Component map:** Reference Speed → TinyFC Network → Summing Junction → Current Loop Update → Motor
- **Critical path:** Input Sensor Reading → [TinyFC Inference ~207μs] → Current Loop Update. The inference must complete within the slower speed control loop cycle, not the faster PWM cycle.
- **Design tradeoffs:**
  - HPO vs. Pruning: Hyperparameter Optimization achieved the smallest model (340 params) but failed in the control loop (unstable). Pruning (600-873 params) worked better but resulted in higher inference times than HPO models.
  - Quantization vs. Latency: Quantization lowered Flash usage but increased inference time (e.g., Test Case 2 Pruned: 215μs → Quantized: 361μs), likely due to overhead of dequantization operations on the MCU.
- **Failure signatures:**
  - HPO Instability: The paper notes the HPO model increased overshoot, likely because optimizing purely for MSE failed to capture temporal stability required in closed control loop.
  - Timing Violation: If the model is deployed in a loop faster than 2kHz, the reported >300μs latency will cause the system to miss control deadlines, leading to motor stalling or vibration.
- **First 3 experiments:**
  1. Baseline Profiling: Run the PI-only controller in Simulink on provided test cases to record baseline overshoot and deviation metrics.
  2. Dataset Ablation: Train a version of TinyFC using raw PI data vs. the author's rectified dataset to observe impact of ground-truth shaping mechanism on overshoot reduction.
  3. Latency Budget Test: Deploy the "Pruned TinyFC" model on the NUCLEO-G474RE and toggle a GPIO pin high/low around the inference call to verify the ~200μs timing budget on an oscilloscope under load.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can a fully data-driven TinyNN model be developed to replace PI controllers entirely, achieving a unified control system free from traditional methods?
- **Basis in paper:** The conclusion states, "Future works could focus on developing a fully data-driven TinyNN model to replace the PI controllers, achieving a unified control system free from traditional methods."
- **Why unresolved:** The current TinyFC architecture is designed as a supportive compensator that corrects the PI controller's output, meaning the system still relies on the traditional controller's baseline functionality.
- **What evidence would resolve it:** A control system where the TinyNN generates motor inputs directly from sensor data without a PI controller in the loop, demonstrating stable operation on the target MCU.

### Open Question 2
- **Question:** How can physics-informed neural networks (PINNs) be utilized to create loss functions that better capture system stability than Mean Squared Error (MSE)?
- **Basis in paper:** Section 7 notes that "Limitations in using MSE suggest exploring physics-informed neural networks (PINNs) to better model input dependencies through physics-based loss functions."
- **Why unresolved:** The authors found that minimizing MSE during training did not guarantee optimal performance in the control loop, as MSE fails to account for the physical impact of current changes on system stability.
- **What evidence would resolve it:** A comparative study showing that a TinyFC model trained with a physics-based loss function achieves superior damping and stability compared to the current MSE-trained model.

### Open Question 3
- **Question:** How can the TinyFC inference latency be reduced to strictly meet the 30 kHz (33.33μs) real-time constraint of the PWM loop?
- **Basis in paper:** Section 5 identifies a key challenge: the PWM operates at 30 kHz (33.33μs cycle), yet Table 5 shows the optimized model inference times range from 144μs to 371μs.
- **Why unresolved:** While the paper claims to meet "real-time constraints," the reported inference times significantly exceed the PWM update period, suggesting the control loop may effectively run at a lower frequency or suffer jitter.
- **What evidence would resolve it:** Optimization results demonstrating inference execution in <33μs on the STM32G474RE, or a clarification of the scheduling mechanism that allows a 200μs inference to manage a 30kHz signal without instability.

## Limitations
- The specific network architecture parameters (layer sizes, neuron counts) are not fully specified beyond total parameter count
- HPO-generated models showed instability despite good MSE scores, suggesting the training methodology may not adequately capture closed-loop dynamics
- Inference time differences between quantized and non-quantized models raise questions about whether quantization benefits outweigh timing penalties

## Confidence
- **High Confidence:** The core mechanism of using residual compensation to correct PI controller limitations is well-supported by experimental results (87.5% overshoot reduction, 60% deviation reduction)
- **Medium Confidence:** The optimization pipeline (pruning + quantization) successfully reduces model size to 1,400 parameters while maintaining real-time feasibility on resource-constrained microcontrollers
- **Low Confidence:** The HPO approach failed to produce stable controllers despite achieving low MSE, suggesting the optimization methodology needs refinement for control applications

## Next Checks
1. **Closed-Loop Validation:** Deploy the pruned TinyFC model on actual hardware and measure overshoot reduction under varying load conditions, not just simulation
2. **Architecture Sensitivity:** Systematically vary layer dimensions while maintaining ~1,400 parameters to determine if the specific architecture is critical to performance
3. **Timing Under Load:** Profile inference latency on the STM32G474RE under realistic operating conditions (including ADC sampling, PWM generation) to verify the 207.4μs budget is maintained in practice