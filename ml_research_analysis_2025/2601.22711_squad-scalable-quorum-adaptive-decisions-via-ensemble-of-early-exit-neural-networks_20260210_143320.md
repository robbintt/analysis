---
ver: rpa2
title: 'SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural
  networks'
arxiv_id: '2601.22711'
source_url: https://arxiv.org/abs/2601.22711
tags:
- exit
- search
- early
- neural
- ensemble
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SQUAD introduces a quorum-based early exit framework that improves
  uncertainty estimation in deep neural networks by aggregating predictions from multiple
  early-exit learners rather than relying on single-model confidence scores. The approach
  incrementally collects votes from parallel learners ordered by computational cost,
  halting computation when a statistically significant consensus is reached via a
  t-test.
---

# SQUAD: Scalable Quorum Adaptive Decisions via ensemble of early exit neural networks

## Quick Facts
- arXiv ID: 2601.22711
- Source URL: https://arxiv.org/abs/2601.22711
- Reference count: 32
- Improves accuracy by up to 5.95% over state-of-the-art dynamic solutions while reducing latency by up to 70.60%

## Executive Summary
SQUAD introduces a quorum-based early exit framework that improves uncertainty estimation in deep neural networks by aggregating predictions from multiple early-exit learners rather than relying on single-model confidence scores. The approach incrementally collects votes from parallel learners ordered by computational cost, halting computation when a statistically significant consensus is reached via a t-test. To optimize the ensemble, SQUAD employs QUEST, a Neural Architecture Search method that selects early-exit learners with hierarchical diversity, ensuring complementarity at every intermediate layer. Experimental results demonstrate superior trade-offs between accuracy and efficiency compared to static ensembles and state-of-the-art dynamic solutions.

## Method Summary
SQUAD combines quorum-based consensus with neural architecture search to create adaptive early exit networks. The method uses K parallel learners, each containing E sequential blocks with Early Exit Classifiers (EECs) after each block. During inference, learners vote incrementally in order of computational complexity, with a one-sided t-test validating statistical significance of the consensus. The QUEST NAS framework discovers diverse ensembles by training a supernet with joint loss across all exits, then using SVGD-RD search to balance accuracy and diversity. The approach is evaluated on CIFAR-10, CIFAR-100, and ImageNet16-120, showing substantial improvements in both accuracy and computational efficiency.

## Key Results
- Reduces inference latency by up to 70.60% compared to static ensembles
- Improves accuracy by up to 5.95% over state-of-the-art dynamic solutions at comparable computational cost
- Achieves higher Pairwise Predictive Disagreement (PPD) at all exits compared to NESBS, demonstrating superior hierarchical diversity
- Maintains better calibration (lower Expected Calibration Error) while achieving earlier exits on easier samples

## Why This Works (Mechanism)

### Mechanism 1: Quorum-Based Consensus with T-Test Validation
- **Claim**: Aggregating predictions from multiple early-exit learners with statistical validation improves uncertainty estimation and reduces premature exits compared to single-model confidence thresholds.
- **Mechanism**: At each exit stage, predictions from EECs are collected. Majority voting determines the consensus class. A one-sided t-test computes the Lower Confidence Bound (LCB) on the confidence scores of agreeing branches. If LCB exceeds threshold τ_conf, early exit triggers.
- **Core assumption**: Ensemble consensus with variance-aware validation captures uncertainty more reliably than single-model softmax scores; DNN overconfidence (high ECE) makes self-assessment unreliable.
- **Evidence anchors**: [abstract]: "halting the computation at that exit if the consensus is statistically significant"; [section 4.4]: "The majority voting acts as a stronger requirement for the winning class than the soft voting, but could hide the uncertainty of the learners, which is screened by the t-test."

### Mechanism 2: Incremental MACs-Aware Voting Protocol
- **Claim**: Ordering learners by computational cost and collecting votes incrementally reduces unnecessary computation while maintaining decision quality for easy samples.
- **Mechanism**: Learners are sorted by MACs complexity. Votes accumulate until a pivot branch is identified—where the outcome is decided regardless of remaining branches. Computation halts on quorum reached (≥⌊K/2⌋+1 votes for leading class) or quorum infeasibility.
- **Core assumption**: Lighter learners can form valid consensus for easier samples; heavier learners serve as consultants only when needed.
- **Evidence anchors**: [abstract]: "collecting intermediate predictions incrementally in order of computational complexity"; [section 4.2]: "To simulate this first-come first-vote mechanism, we estimate latency via Multiply-Accumulate operations (MACs)."

### Mechanism 3: QUEST NAS for Hierarchical Diversity
- **Claim**: Neural Architecture Search can discover ensembles that maximize diversity at every intermediate layer—not just at the final output—enabling robust early-exit decisions.
- **Mechanism**: QUEST trains an early-exit supernet using modified SNAS with joint loss across all exits. It computes a variational posterior distribution via backpropagation from all exits simultaneously. SVGD-RD search then balances driving force (accuracy) and repulsive force (diversity) to sample complementary architectures.
- **Core assumption**: Standard ensemble diversity at output level is insufficient; robust early-exit voting requires "hierarchical diversity" at each exit gate.
- **Evidence anchors**: [abstract]: "QUEST... selects early-exit learners with optimized hierarchical diversity, ensuring learners are complementary at every intermediate layer"; [Table 2]: QUEST achieves higher PPD than NESBS at all exits across datasets.

## Foundational Learning

- **Concept: Early Exit Neural Networks (EENNs)**
  - Why needed: SQUAD builds directly on EENNs as the backbone architecture; understanding confidence-based exit triggers is prerequisite.
  - Quick check question: In a standard EENN with confidence threshold τ=0.9, what happens when an intermediate classifier outputs max softmax probability 0.85?

- **Concept: Ensemble Diversity Metrics (PPD, ECE)**
  - Why needed: QUEST optimizes hierarchical diversity using PPD; ECE measures calibration reliability that SQUAD aims to improve.
  - Quick check question: If two ensemble members always predict the same class for all samples, what is their Pairwise Predictive Disagreement (PPD) score?

- **Concept: Differentiable NAS (DARTS, SNAS)**
  - Why needed: QUEST extends SNAS with early-exit awareness; understanding continuous relaxation and Gumbel-Softmax is essential.
  - Quick check question: How does SNAS make architecture sampling differentiable, and why does DARTS require post-hoc discretization while SNAS does not?

## Architecture Onboarding

- **Component map**: Input x → K parallel learners (L₁...L_K) → E sequential blocks each → Early Exit Classifiers (EECs) → Exit Test module (quorum voting + t-test) → Output ŷ or forward to next exit

- **Critical path**: 1. Input x processed in parallel across K learners; 2. At exit e, EEC predictions collected in MACs-sorted order; 3. Majority voting identifies pivot branch and consensus class ŷ_e; 4. T-test computes LCB on confidence scores from agreeing branches S_e; 5. If LCB > τ_conf → return ŷ_e; else forward representations to exit e+1; 6. If exit E reached without trigger → forced prediction

- **Design tradeoffs**: Ensemble size K: Larger K improves uncertainty estimation but increases parallel overhead; Threshold τ_conf: Lower values permit more early exits but risk calibration errors; Exit criterion: T-test is stricter (higher accuracy, higher MACs) vs. mean confidence (more permissive); Assumption: Search time (8h for QUEST vs. 36h for NACHOS) trades off against architecture optimality

- **Failure signatures**: High ECE at early exits (>5%): Poorly calibrated EECs; Low PPD at any exit: Learners making correlated errors; >50% samples reaching final exit: Exit criteria too strict; F_MT ≈ F_M × K: No early exits occurring

- **First 3 experiments**: 1. Ablation on exit criterion: Compare t-test vs. mean confidence on CIFAR-10 with τ_conf ∈ {0.8, 0.85, 0.9, 0.95}; 2. Hierarchical diversity validation: Compute PPD at each exit for QUEST ensemble vs. random ensemble; 3. Latency profiling by difficulty: On ImageNet16-120, measure exit distribution and pivot branch statistics

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the traditional sense. The methodology and results are presented as solutions to specific problems in uncertainty estimation and computational efficiency for early exit neural networks. The paper focuses on demonstrating the effectiveness of SQUAD and QUEST rather than identifying unresolved research directions.

## Limitations

- **Architecture disclosure**: The exact early-exit neural network architectures discovered by QUEST are not publicly available, preventing exact replication and architectural analysis.
- **Dataset ordering assumption**: SQUAD requires MACs-aware ordering of learners for incremental voting, but the paper only specifies this order once without explicitly stating it matches the MACs-sorted listing.
- **Cross-dataset generalization**: The threshold values (τ_conf = 0.95 for CIFAR-10, 0.6 for CIFAR-100, 0.3 for ImageNet16-120) show substantial variation across datasets, suggesting the method requires dataset-specific tuning.

## Confidence

- **High confidence**: The quorum voting mechanism with t-test validation is well-specified and theoretically sound. The computational efficiency gains (70.60% MACs reduction) are clearly demonstrated through the incremental voting protocol.
- **Medium confidence**: The QUEST NAS methodology is described in sufficient detail for conceptual understanding, but missing architectural details and hyperparameter specifications limit reproducibility.
- **Low confidence**: The claim of "hierarchical diversity" improvements requires validation through the requested diversity metrics analysis, as the current presentation lacks sufficient empirical evidence at intermediate exits.

## Next Checks

1. **Diversity validation**: Compute Pairwise Predictive Disagreement (PPD) at each exit for QUEST-selected ensembles versus random ensembles of the same architectures on CIFAR-10. Verify that QUEST achieves significantly higher PPD at Exit 0 (4.08% vs N/A) and Exit 1 (3.15% vs 2.27%) compared to NESBS.

2. **Threshold sensitivity**: Systematically vary τ_conf across CIFAR-10, CIFAR-100, and ImageNet16-120 to determine whether the reported values represent optimal points or if the method is oversensitive to hyperparameter tuning.

3. **Mode collapse detection**: Monitor the SVGD-RD search process for evidence of mode collapse by tracking architectural similarity metrics across sampled ensembles. Verify that the repulsive force parameter δ = -1.3 effectively maintains diversity throughout the 1000-epoch search.