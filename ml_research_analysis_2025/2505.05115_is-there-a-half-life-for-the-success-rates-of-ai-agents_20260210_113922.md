---
ver: rpa2
title: Is there a half-life for the success rates of AI agents?
arxiv_id: '2505.05115'
source_url: https://arxiv.org/abs/2505.05115
tags:
- rate
- success
- time
- task
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates the success rates of AI agents on tasks
  of varying durations, building on recent empirical work by Kwa et al. (2025).
---

# Is there a half-life for the success rates of AI agents?

## Quick Facts
- arXiv ID: 2505.05115
- Source URL: https://arxiv.org/abs/2505.05115
- Authors: Toby Ord
- Reference count: 0
- Primary result: AI agents show exponentially declining success rates with task duration, characterized by a half-life for each agent

## Executive Summary
This study investigates whether AI agents exhibit a "half-life" for success rates on tasks of varying durations, building on recent empirical work by Kwa et al. (2025). The research analyzes AI agent performance on a suite of research-engineering tasks, modeling success probability as a constant hazard rate per minute of task duration. This model predicts exponential decline in success rates with task length, allowing prediction of performance across different task durations. The findings suggest that longer tasks involve more sequential subtasks where failure at any point fails the whole task, providing insights into the underlying mechanisms of AI agent failures.

## Method Summary
The study analyzes AI agent performance on 170 software engineering, cybersecurity, reasoning, and machine learning tasks of varying durations. The core method involves modeling the probability of success as a constant hazard rate per minute of task duration, which predicts exponentially declining success rates with task length. This approach allows calculation of a unique half-life for each agent - the task duration at which success probability drops to 50%. The empirical data is compared against this constant hazard rate model to assess fit quality and predictive power.

## Key Results
- AI agents show exponentially declining success rates with task duration, following a constant hazard rate model
- The model predicts that if an agent has 50% success on 60-minute tasks, it would have 25% on 120-minute tasks, 12.5% on 240-minute tasks, etc.
- Human performance shows different scaling behavior with task length compared to AI agents, potentially indicating different underlying mechanisms

## Why This Works (Mechanism)
The constant hazard rate model works because it captures the fundamental nature of sequential task completion by AI agents. Each minute of task duration represents additional sequential subtasks, where failure at any point causes overall task failure. This creates a multiplicative probability structure where success rates decline exponentially rather than linearly with task length.

## Foundational Learning
- Hazard rate theory: Understanding constant vs. declining hazard rates is crucial for modeling sequential task completion probabilities. Why needed: Provides the mathematical framework for analyzing time-dependent success rates. Quick check: Verify that hazard rate remains constant across different task durations.
- Exponential decay: The mathematical relationship between time and probability decay underlies the half-life concept. Why needed: Enables prediction of success rates for arbitrary task durations. Quick check: Confirm that log(success rate) vs. task duration yields a straight line.
- Survival analysis: Statistical techniques for analyzing time-to-event data apply to task completion modeling. Why needed: Provides established methods for analyzing success/failure timing data. Quick check: Ensure proper handling of censored data points.

## Architecture Onboarding

Component map: Task duration → Sequential subtasks → Individual failure points → Overall task failure

Critical path: Task assignment → Subtask execution → Failure detection → Success/failure classification → Duration recording

Design tradeoffs: The model assumes task independence and constant hazard rates, which simplifies analysis but may miss task-specific variations or learning effects.

Failure signatures: Exponential decline in success rates, half-life calculation, deviation from constant hazard rate indicating task complexity factors.

First experiments:
1. Test model on diverse task types (creative, physical, multi-agent) to assess generalizability
2. Vary subtask complexity while holding duration constant to isolate complexity effects
3. Compare individual vs. aggregate human performance to distinguish true declining hazard rates from mixture artifacts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the constant hazard rate model generalize to task suites beyond the research-engineering tasks studied here?
- Basis in paper: [explicit] "Whether this model applies more generally on other suites of tasks is unknown and an important subject for further work."
- Why unresolved: The study only analyzed one task suite (170 software engineering, cybersecurity, reasoning, and ML tasks), which may not represent real-world performance.
- What evidence would resolve it: Testing the exponential decay model on diverse task suites (e.g., creative tasks, physical tasks, multi-agent interactions) and comparing fit quality.

### Open Question 2
- Question: Do humans exhibit fundamentally different scaling behavior (declining hazard rate) compared to AI agents, or is the observed difference a methodological artifact?
- Basis in paper: [explicit] "Intriguingly, this human survival curve seems to be noticeably better than a constant hazard rate... This could indicate a different scaling behaviour... which would be well worth investigating."
- Why unresolved: The observed human deviation from exponential decay could instead result from aggregating humans with different ability levels, which produces thicker-tailed decay curves.
- What evidence would resolve it: Individual-level human performance analysis to distinguish true declining hazard rates from mixture artifacts.

### Open Question 3
- Question: Does an exponential decay curve fit the METR data better than the log-logistic distribution used by Kwa et al.?
- Basis in paper: [explicit] "Ideally one would conduct a formal statistical analysis on how well an exponential decay curve fits METR's data compared to the log-logistic they use."
- Why unresolved: Both distributions fit the data similarly well visually, but no formal model comparison has been conducted.
- What evidence would resolve it: Statistical tests (e.g., AIC/BIC comparison, likelihood ratio tests) quantifying relative fit quality across all six agents.

## Limitations
- The model assumes task independence and constant hazard rates, which may not hold for all task types
- Analysis focuses primarily on research-engineering tasks, limiting generalizability to other domains
- Doesn't account for potential learning effects or improvements in agent capabilities over time
- Human performance comparison is preliminary and requires more rigorous experimental design

## Confidence

High confidence:
- The exponential decline model fits the empirical data well and provides a useful framework for understanding AI agent performance scaling

Medium confidence:
- The interpretation that sequential subtask failures drive the observed pattern, as this requires further validation across different task types and agent architectures
- The claim about differences between AI agents and human performance scaling, given the limited scope of current comparisons

## Next Checks
1. Test the constant hazard rate model across diverse task domains (e.g., creative writing, mathematical reasoning, game playing) to assess generalizability
2. Conduct controlled experiments varying the number and type of sequential subtasks within tasks of equal duration to isolate the effect of task complexity from pure time dependency
3. Implement a longitudinal study tracking the same agents over time to determine if the half-life metric remains stable or changes with agent training and experience