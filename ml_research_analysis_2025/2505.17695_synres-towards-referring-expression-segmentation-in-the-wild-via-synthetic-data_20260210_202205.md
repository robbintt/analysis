---
ver: rpa2
title: 'SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic
  Data'
arxiv_id: '2505.17695'
source_url: https://arxiv.org/abs/2505.17695
tags:
- synthetic
- synres
- segmentation
- data
- expressions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces WildRES, a new benchmark for Referring Expression
  Segmentation (RES) designed to address complex real-world scenarios involving multi-target
  shared attributes and single-target expressions with many attributes. The benchmark
  spans diverse domains including autonomous driving and robotics.
---

# SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data

## Quick Facts
- arXiv ID: 2505.17695
- Source URL: https://arxiv.org/abs/2505.17695
- Reference count: 40
- State-of-the-art RES performance on WildRES benchmark

## Executive Summary
SynRES introduces a synthetic data generation pipeline for Referring Expression Segmentation (RES) that addresses complex real-world scenarios involving multi-target shared attributes and single-target expressions with many attributes. The approach generates densely paired synthetic training data through three key innovations: dense caption-driven synthesis, Image-Text Aligned Grouping for reliable semantic alignment, and domain-aware augmentations. Experiments demonstrate significant improvements over state-of-the-art RES models, achieving 2.0% gIoU gains on WildRES-ID and 3.8% on WildRES-DS.

## Method Summary
SynRES operates through a three-step pipeline to generate synthetic RES training data. First, it creates attribute-rich image-mask-expression triplets by generating distinctive captions for real images using CoCa, then synthesizing images with Text-to-Image models (SANA) based on composite prompts. Second, it refines pseudo-masks through Image-Text Aligned Grouping, clustering expressions whose predicted masks spatially agree and averaging within clusters to reduce noise. Third, it applies domain-aware augmentations including mosaic composition (compositing 1 real with 3-8 synthetic images) and superclass replacement text augmentation. The pipeline fine-tunes RES models with a 9:3:3:1:4 ratio across semantic segmentation, RES, VQA, ReasonSeg, and SynRES data.

## Key Results
- SynRES improves gIoU by 2.0% on WildRES-ID validation and 3.8% on WildRES-DS
- Consistent improvements across multiple RES models (LISA, GSVA, GLaMM)
- 25% SynRES data achieves 98.5% of full performance, indicating effective augmentation
- Ablation studies confirm each innovation contributes independently to performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dense caption-driven synthesis produces attribute-rich training triplets that improve discrimination among objects sharing similar categories.
- Mechanism: For a given real image-mask pair, the pipeline generates n distinctive textual expressions via CoCa captioning, concatenates them into composite prompts, and feeds these to a Text-to-Image model (SANA) to synthesize images containing multiple attribute combinations.
- Core assumption: T2I models can render multiple specified attributes in a single synthetic image and that these rendered attributes are learnable by RES models.
- Evidence anchors: Abstract states "dense caption-driven synthesis for attribute-rich image-mask-expression triplets"; Section 4.1 describes composite prompt construction.
- Break condition: If T2I models fail to consistently render specified attributes, or if synthetic images exhibit systematic artifacts not present in real data.

### Mechanism 2
- Claim: Image-Text Aligned Grouping reduces pseudo-mask noise by clustering expressions whose predicted masks spatially agree, then averaging within clusters.
- Mechanism: For each synthetic image, a pretrained RES model generates pseudo-masks from expressions. Pairwise mIoU is computed across masks; expression pairs with mIoU above threshold τ are grouped into consensus clusters. Masks within each cluster are averaged and binarized.
- Core assumption: Semantically aligned expressions will produce spatially overlapping masks even if individual predictions are noisy; averaging cancels uncorrelated errors.
- Evidence anchors: Abstract mentions "reliable semantic alignment mechanisms rectifying caption-pseudo mask inconsistencies"; Section 4.2 details the grouping process.
- Break condition: If errors are correlated across expressions, averaging will not cancel them and may reinforce incorrect masks.

### Mechanism 3
- Claim: Domain-aware augmentations (mosaic composition and superclass replacement) improve generalization to multi-target and domain-shifted scenarios.
- Mechanism: Mosaic augmentation composites 1 real image with 3-8 synthetic images into grids, forcing the model to handle multiple targets and bridging the synthetic-real domain gap. Superclass replacement substitutes specific nouns with broader terms, reducing vocabulary bias.
- Core assumption: Models overfit to specific category words; replacing them with superclasses shifts attention to residual attributes.
- Evidence anchors: Abstract mentions "domain-aware augmentations incorporating mosaic composition and superclass replacement"; Table 4 shows ablation results.
- Break condition: If superclass replacement introduces ambiguity when multiple objects of the same superclass exist in one image.

## Foundational Learning

- Concept: Referring Expression Segmentation (RES) — mapping a natural language query to a binary segmentation mask.
  - Why needed here: SynRES targets RES-specific failure modes and assumes familiarity with the standard RES formulation.
  - Quick check question: Given an image of three dogs and the query "the dog with a red collar," which pixels should the mask include?

- Concept: IoU (Intersection over Union) and gIoU/cIoU metrics.
  - Why needed here: Step 2's grouping threshold τ is based on mIoU; evaluation uses gIoU and cIoU.
  - Quick check question: If predicted mask A covers 100 pixels and ground truth B covers 120 pixels with 80 overlapping, what is the IoU?

- Concept: Domain shift and synthetic-to-real transfer.
  - Why needed here: WildRES-DS evaluates cross-domain generalization; SynRES explicitly addresses this gap.
  - Quick check question: Why might a model trained only on COCO-style images fail on autonomous driving scenes even if object categories overlap?

- Concept: Pseudo-labeling and noise robustness.
  - Why needed here: Step 2 generates pseudo-masks from a pretrained RES model; grouping and averaging reduce noise before training.
  - Quick check question: If pseudo-masks have 30% pixel-level noise, would averaging 5 independent predictions reduce error?

## Architecture Onboarding

- Component map: Real image + mask → CoCa captioning → n distinctive expressions → SANA T2I → m synthetic images per expression → pretrained RES (LISA) → pseudo-masks → pairwise mIoU → consensus grouping → averaged binary masks → mosaic augmentation + superclass replacement → final training triplets

- Critical path: Expression quality from CoCa determines attribute richness; mIoU threshold τ=0.65 gates which expression groups are retained; mosaic composition determines multi-target exposure; superclass replacement probability p controls vocabulary debiasing strength

- Design tradeoffs: Higher m increases diversity but raises generation cost (paper uses m=6, n=5 expressions); strict τ improves mask quality but reduces dataset size (ablation shows robust performance from τ=0.55-0.75); superclass replacement helps debiasing but can introduce ambiguity

- Failure signatures: Over-segmentation beyond ground truth when visually similar objects are adjacent; performance drop if mosaic augmentation is disabled (ablation: gIoU 41.3 → 39.1); degradation below baseline if both visual and text augmentations are removed (gIoU 41.3 → 35.5 < 37.1 baseline)

- First 3 experiments: 1) Reproduce baseline RES model (LISA-7B) on WildRES-ID validation to confirm performance gap; 2) Generate small-scale SynRES subset (25% of full data) and verify gIoU improvement; 3) Ablate superclass replacement (set p=0) on held-out subset to quantify vocabulary bias reduction

## Open Questions the Paper Calls Out

- How can synthetic data generation be optimized for complex queries with diverse attributes and cross-domain generalization in RES? The paper states this remains underexplored and primarily validates one pipeline approach without systematic comparison of alternative synthesis strategies.

- How can multi-target RES models better handle high-density scenes with proximate, visually similar objects? Limitations identify failure cases with over-segmentation in adjacent similar objects, noting current mosaic augmentation struggles with such arrangements.

- Why do Many Attribute scenarios show inconsistent improvements and sometimes performance degradation even with SynRES augmentation? Table 1 shows LISA-7B achieves -0.7 gIoU change on Many Attribute test subset despite overall gains, suggesting gaps in how synthetic expressions capture real-world attribute complexity.

## Limitations

- Over-segmentation beyond ground truth boundaries occurs when visually similar objects appear immediately adjacent to targets, with current mosaic augmentation struggling to generate sufficient object density for training.

- Performance degradation on Many Attribute scenarios (-0.7 gIoU for LISA-7B) despite overall gains, indicating synthetic data may not fully capture the complexity of real-world attribute-rich queries.

- Limited analysis of domain shift measurement across WildRES-DS's three diverse domains, with no per-domain performance breakdown or analysis of which types of domain shift are most challenging.

## Confidence

- **High confidence**: Core observation that SynRES improves RES performance on WildRES benchmarks (gIoU +2.0% on WildRES-ID, +3.8% on WildRES-DS) is well-supported by experimental results and ablation studies.

- **Medium confidence**: Claim that each innovation independently contributes to performance gains is supported by ablation studies, but interactions between components are not fully explored.

- **Low confidence**: Assertion that SynRES specifically addresses "complex real-world scenarios" is demonstrated through benchmark performance but lacks qualitative analysis of failure cases or comparative studies on simpler benchmarks.

## Next Checks

1. **Component-wise failure analysis**: Systematically disable each SynRES innovation on a held-out subset of WildRES to quantify independent contributions and identify which component is most critical for different query types.

2. **Synthetic data quality audit**: Generate a small synthetic dataset (50-100 images) and conduct human evaluation to assess synthetic image quality, pseudo-mask alignment, and realism of multi-target scenarios created by domain-aware augmentations.

3. **Cross-dataset generalization study**: Evaluate SynRES-trained models on established RES benchmarks (RefCOCO+, RefCOCOg) to determine if the approach overfits to WildRES's specific challenges or provides general improvements to RES performance across diverse query types.