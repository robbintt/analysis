---
ver: rpa2
title: Early Stopping Chain-of-thoughts in Large Language Models
arxiv_id: '2509.14004'
source_url: https://arxiv.org/abs/2509.14004
tags:
- es-cot
- answer
- reasoning
- final
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ES-CoT, an inference-time method that shortens
  chain-of-thought reasoning by detecting answer convergence and stopping early. The
  approach tracks consecutive identical step answers and halts generation when the
  run length exhibits a sharp increase beyond previous runs, using a statistical test.
---

# Early Stopping Chain-of-thoughts in Large Language Models

## Quick Facts
- arXiv ID: 2509.14004
- Source URL: https://arxiv.org/abs/2509.14004
- Reference count: 20
- Primary result: Reduces chain-of-thought tokens by ~41% while maintaining accuracy

## Executive Summary
This paper introduces ES-CoT, an inference-time method that shortens chain-of-thought reasoning by detecting answer convergence and stopping early. The approach tracks consecutive identical step answers and halts generation when the run length exhibits a sharp increase beyond previous runs, using a statistical test. Evaluated on five reasoning datasets with three large language models, ES-CoT reduces token usage by about 41% on average while maintaining accuracy comparable to standard chain-of-thought prompting. When combined with self-consistency, it further improves accuracy and reduces tokens by up to 24%.

## Method Summary
ES-CoT implements early stopping during chain-of-thought generation by appending "The final answer is" to each reasoning step and monitoring for answer convergence. The method tracks runs of consecutive identical answers, computing run-length differences D = ⟨d₁, d₂, ...⟩ where dᵢ = rᵢ₊₁ - rᵢ. Generation terminates when the latest difference dₙ₋₁ exceeds a threshold (default 10) AND a t-test confirms it's significantly larger than previous differences (p < 0.05). The approach requires no retraining and integrates seamlessly with existing strategies like self-consistency.

## Key Results
- Reduces token usage by ~41% on average across five reasoning datasets
- Maintains accuracy comparable to standard chain-of-thought prompting
- When combined with self-consistency, improves accuracy while reducing tokens by up to 24%
- Works with QwQ-32B, Llama-3.1-8B, and Qwen2.5-7B models

## Why This Works (Mechanism)

### Mechanism 1: Answer Convergence via Monotonicity
The probability P(X_t = X_T) increases monotonically with step count t, as intermediate step answers progressively stabilize toward the final answer. This convergence suggests later steps are more likely to resemble the final output than earlier steps.

### Mechanism 2: Run-Length Phase Transition (The Run-Jump Test)
A statistically significant spike in consecutive identical answer lengths ("run length") serves as a reliable stopping signal. The algorithm detects when run-length differences show a sharp increase, indicating the model has locked onto its final answer rather than temporary repetition.

### Mechanism 3: Error Bound Contraction
Theoretical analysis shows that as run-length differences increase, the upper bound on the error between early-stopped and full-generation answers approaches zero, providing formal justification for the stopping criterion under specific distributional assumptions.

## Foundational Learning

- **Chain-of-Thought (CoT) Dynamics**: Understanding that CoT is a sequence of steps delimited by newlines is essential for implementing ES-CoT's intervention.
  - Quick check: Can you identify how the paper defines a "step" in the generation process?

- **Statistical Significance Testing (t-test)**: The core "Run-Jump Test" relies on t-tests to distinguish true convergence signals from random noise.
  - Quick check: How does the algorithm determine if a "jump" in run length is a true signal versus random noise?

- **Self-Consistency (SC)**: Understanding SC is necessary to replicate ES-CoT+SC results showing improved accuracy.
  - Quick check: How does early stopping interact with the sampling process in Self-Consistency to maintain or improve accuracy?

## Architecture Onboarding

- **Component map**: LLM Generator -> Step Parser -> Answer Injection -> State Tracker -> Termination Gate
- **Critical path**: The injection of the "final answer" prompt and subsequent parsing occur at every reasoning step, directly impacting inference speed.
- **Design tradeoffs**:
  - Hyperparameter d_min: Lower values prioritize efficiency but risk accuracy; higher values prioritize accuracy
  - Prompt overhead: Injected tokens count toward total generation, slightly offsetting efficiency gains
  - Assumption violation: Non-deterministic tasks make the method unsuitable
- **Failure signatures**:
  - Premature Termination: Stops after a short, repetitive loop before reasoning completes
  - Non-Triggering: Complex tasks with frequent answer switches never meet stopping conditions
- **First 3 experiments**:
  1. Baseline Efficiency: Run ES-CoT vs. Standard CoT on MATH500, measure token reduction and accuracy drop
  2. Hyperparameter Sensitivity: Vary d_min (3, 5, 10, 15) on validation set to find optimal accuracy/token trade-off
  3. Integration Test: Implement ES-CoT + Self-Consistency (10 samples) and verify token savings with maintained accuracy

## Open Questions the Paper Calls Out

### Open Question 1
Can ES-CoT hyperparameters be adaptively tuned based on instance-level features? The paper suggests adjusting d_min and significance level based on problem difficulty or domain, but this remains unexplored.

### Open Question 2
How does ES-CoT perform on tasks without deterministic answers? The run-length jump criterion may be unreliable when multiple valid solutions exist.

### Open Question 3
Can early stopping incorporate ground-truth-related signals to prevent premature commitment to incorrect answers? ES-CoT currently optimizes for consistency with the model's own output, not correctness.

### Open Question 4
Does ES-CoT generalize to closed-source models and reasoning domains beyond mathematics? Evaluation was limited to three open-source LLMs on math/logical benchmarks.

## Limitations
- Assumes deterministic final answers; may fail on tasks with high answer entropy
- Fixed hyperparameters may not optimize efficiency-accuracy tradeoff across all problem types
- Limited evaluation to open-source models and mathematical reasoning domains

## Confidence
- Method validity: High - clear theoretical foundation and empirical validation
- Reproducibility: Medium - key details specified but some implementation specifics unclear
- Generalizability: Low - limited to specific model types and reasoning domains

## Next Checks
1. Implement ES-CoT on a small benchmark (MATH500 subset) to verify basic functionality and measure token reduction
2. Test sensitivity to d_min parameter by running experiments with values 5, 10, and 15 on same dataset
3. Verify integration with self-consistency by implementing ES-CoT+SC and comparing accuracy to standard SC baseline