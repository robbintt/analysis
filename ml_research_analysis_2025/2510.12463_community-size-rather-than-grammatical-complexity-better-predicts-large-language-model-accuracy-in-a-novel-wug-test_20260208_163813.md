---
ver: rpa2
title: Community size rather than grammatical complexity better predicts Large Language
  Model accuracy in a novel Wug Test
arxiv_id: '2510.12463'
source_url: https://arxiv.org/abs/2510.12463
tags:
- language
- complexity
- llms
- english
- linguistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether Large Language Models (LLMs) exhibit
  human-like morphological generalization abilities in a multilingual Wug Test across
  Catalan, English, Greek, and Spanish. It also examines whether linguistic complexity
  or community size (and thus training data availability) better predicts LLM accuracy.
---

# Community size rather than grammatical complexity better predicts Large Language Model accuracy in a novel Wug Test

## Quick Facts
- arXiv ID: 2510.12463
- Source URL: https://arxiv.org/abs/2510.12463
- Reference count: 40
- LLMs perform similarly to humans in morphological generalization, but accuracy is primarily determined by community size and data availability rather than linguistic complexity.

## Executive Summary
This study investigates whether Large Language Models exhibit human-like morphological generalization abilities across Catalan, English, Greek, and Spanish using a multilingual Wug Test. The research examines whether linguistic complexity or community size (as proxy for training data availability) better predicts LLM accuracy. Results show that LLMs achieve similar accuracy to humans in morphological generalization, but their performance is primarily driven by community size and data availability rather than grammatical complexity. Spanish and English, with larger speaker communities and more training data, showed higher accuracy than Greek and Catalan, regardless of complexity. The findings suggest that LLM behavior is driven more by resource richness than by structural linguistic sensitivity.

## Method Summary
The study used a Wug Test paradigm with 30 nonce words per language (15 two-syllable, 15 three-syllable) balanced for grammatical gender, created by altering initial consonants of real lexical items. Human participants (40 native speakers per language) completed the task via PCIbex Farm platform, while six models (ChatGPT-3.5, ChatGPT-4, Grok 3, BERT, DeepSeek, Mistral) were evaluated through manual API prompting and programmatic evaluation. Responses were coded against morphophonological targets, and mixed-effects logistic regression compared effects of linguistic complexity (Grambank fusion/informativity scores) versus community size (z-scored). Model fit was compared via AIC and log-likelihood.

## Key Results
- LLMs achieved similar accuracy to humans in morphological generalization across all tested languages
- Community size was a better predictor of LLM accuracy than linguistic complexity
- Greek outperformed Catalan despite being more complex, likely due to Greek's higher morphological regularity
- Models did not consistently align with complexity-based predictions

## Why This Works (Mechanism)

### Mechanism 1: Distributional Pattern Extraction Scales with Training Data Volume
- Claim: LLM accuracy on morphological generalization correlates more strongly with training data availability than with grammatical complexity
- Core assumption: Community size serves as a reasonable proxy for training data volume
- Evidence: AIC comparison showed Community Size model (277.858) outperformed Complexity Score model (290.659)

### Mechanism 2: Structural Regularity Moderates Accuracy When Resources Are Comparable
- Claim: When languages have similar speaker populations, morphological regularity predicts higher accuracy
- Core assumption: The fusion/informativity complexity metrics capture morphological difficulty relevant to LLM processing
- Evidence: Greek, despite being most complex and having fewer speakers than Spanish, outperformed Catalan because its morphology is more regular

### Mechanism 3: Surface-Level Parity Without Mechanistic Alignment
- Claim: LLMs achieve human-like accuracy through distributional learning without replicating human cognitive mechanisms
- Core assumption: Different error patterns between humans and models indicate different underlying processes
- Evidence: Humans produced "real-word substitutions," "typos," and "inserted irrelevant words" - errors not observed in models

## Foundational Learning

- **Wug Test Paradigm**: Core experimental method for assessing rule generalization; understanding it is prerequisite to interpreting all results
  - Quick check: Can you explain why "wugs" demonstrates rule application rather than memorization?

- **Mixed-Effects Logistic Regression (GLMM)**: Primary statistical framework for analyzing accuracy with crossed random effects
  - Quick check: Why include both participants and items as random effects rather than just aggregating by language?

- **Fusion and Informativity as Complexity Metrics**: Operationalizes "linguistic complexity" using Grambank features
  - Quick check: Would a language with high fusion but low informativity be considered more or less complex than one with the reverse profile?

## Architecture Onboarding

- **Component map**: Stimulus generation -> Human evaluation (PCIbex) -> Model evaluation (API prompting) -> Annotation (binary accuracy) -> GLMM analysis
- **Critical path**: 1. Generate language-specific nonce words 2. Administer identical prompts to humans and models 3. Code responses against targets 4. Run GLMMs comparing complexity vs. community size 5. Compare model fit via AIC
- **Design tradeoffs**: Using community size as proxy for training data is pragmatically necessary but imperfect; excluding BERT improves model assumptions but reduces generalizability
- **Failure signatures**: Floor-level performance (BERT), consistent insertion of irrelevant words, orthographic/stress errors in otherwise correct responses
- **First 3 experiments**: 1. Replicate with morphology-specific complexity metric 2. Control for tokenization artifacts 3. Extend to low-resource languages with strong digital presence

## Open Questions the Paper Calls Out

- **Morphology-specific complexity metrics**: Would morphology-specific complexity indices better predict LLM generalization than holistic grammatical measures? The authors suggest constructing "dedicated indices of morphological complexity" for future work.

- **Agglutinative and polysynthetic languages**: Does the primacy of community size over complexity persist in languages with agglutinative or polysynthetic morphologies? The authors state the current sample restricts generalizability.

- **Digital corpus size vs. population**: Is actual digital corpus size a more accurate predictor of LLM accuracy than speaker population estimates? The authors acknowledge this relationship is "not strictly linear" and influenced by geopolitical factors.

## Limitations

- Community size serves as an imperfect proxy for training data availability, with the relationship influenced by geopolitical factors
- Grambank complexity metrics measure overall grammatical complexity rather than morphology-specific features
- The study excludes low-resource languages with strong digital presence that could help decouple community size from training data effects

## Confidence

- **High confidence**: That LLM accuracy correlates more strongly with community size than linguistic complexity
- **Medium confidence**: That structural regularity predicts accuracy when resources are comparable
- **Medium confidence**: That surface-level accuracy parity masks fundamentally different underlying mechanisms from human cognition

## Next Checks

1. Replicate with morphology-specific complexity metrics using only nominal inflection features from Grambank
2. Control for tokenization artifacts by comparing BPE vs. character-level models on the same task
3. Extend to low-resource languages with high digital presence (e.g., Basque vs. Swahili) to disentangle community size from training data availability