---
ver: rpa2
title: 'GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set'
arxiv_id: '2511.18146'
source_url: https://arxiv.org/abs/2511.18146
tags:
- sinhala
- emotion
- comments
- data
- comment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents GeeSanBhava, a high-quality annotated dataset
  of 63,471 Sinhala song comments from YouTube, manually tagged using Russell's Valence-Arousal
  model by three independent annotators. The annotators achieved a substantial inter-annotator
  agreement (Fleiss' kappa = 84.96%).
---

# GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set

## Quick Facts
- arXiv ID: 2511.18146
- Source URL: https://arxiv.org/abs/2511.18146
- Reference count: 0
- 63,471 manually annotated Sinhala song comments achieving 84.96% inter-annotator agreement

## Executive Summary
This study presents GeeSanBhava, a comprehensive annotated dataset of 63,471 Sinhala song comments from YouTube, manually tagged using Russell's Valence-Arousal model by three independent annotators. The research developed machine learning and deep learning models for Sinhala comment classification, with an optimized Multi-Layer Perceptron (MLP) achieving a ROC-AUC score of 0.887 after extensive hyperparameter tuning. The study addresses the significant gap in Sinhala natural language processing resources and provides a valuable foundation for future research in low-resource language sentiment analysis and music emotion recognition.

## Method Summary
The researchers collected 63,471 Sinhala song comments from YouTube videos and manually annotated them using Russell's Valence-Arousal model with three independent annotators. They achieved substantial inter-annotator agreement (Fleiss' kappa = 84.96%). The team developed both machine learning and deep learning models for comment classification, ultimately optimizing an MLP model with three layers (256, 128, and 64 neurons) through hyperparameter tuning. The dataset and trained models were made publicly available for future research in Sinhala NLP and music emotion recognition.

## Key Results
- MLP model achieved ROC-AUC score of 0.887 after hyperparameter optimization
- Three-layer architecture with 256, 128, and 64 neurons
- Inter-annotator agreement of 84.96% (Fleiss' kappa) indicates substantial consistency
- Publicly available dataset and models for Sinhala NLP research

## Why This Works (Mechanism)
The success of this approach stems from the systematic application of Russell's Valence-Arousal model for sentiment annotation, which provides a theoretically grounded framework for categorizing emotional content. The manual annotation by three independent annotators ensures high-quality labeled data, while the substantial inter-annotator agreement validates the annotation scheme's reliability. The MLP architecture with carefully tuned hyperparameters effectively captures the patterns in Sinhala text sentiment, and the focus on music video comments provides domain-specific insights into emotional expression in this context.

## Foundational Learning

**Russell's Valence-Arousal Model**: A psychological framework for categorizing emotions based on two dimensions - valence (pleasantness) and arousal (intensity). Why needed: Provides a systematic approach to sentiment annotation in low-resource languages. Quick check: Ensure annotators understand the dimensional nature of emotion rather than discrete categories.

**Inter-annotator Agreement Metrics**: Statistical measures like Fleiss' kappa that quantify consistency among multiple annotators. Why needed: Validates annotation quality and reliability in sentiment analysis tasks. Quick check: Calculate agreement for each annotation category to identify potential ambiguities.

**Hyperparameter Tuning**: The systematic optimization of model parameters (layer sizes, learning rates, etc.) to improve performance. Why needed: Critical for achieving optimal performance in deep learning models. Quick check: Use cross-validation to ensure tuning generalizes across dataset subsets.

## Architecture Onboarding

**Component Map**: Raw YouTube Comments -> Preprocessing Pipeline -> MLP Model (256-128-64 neurons) -> Sentiment Classification -> ROC-AUC Evaluation

**Critical Path**: The data collection and annotation process represents the most critical path, as the quality and quantity of labeled data directly determines model performance. The manual annotation by three annotators and the substantial inter-annotator agreement (84.96%) validate this foundation.

**Design Tradeoffs**: The study chose MLP over more complex architectures due to the relatively small dataset size (63,471 comments) for a low-resource language. This tradeoff balances model complexity with available training data to prevent overfitting while maintaining reasonable performance (ROC-AUC 0.887).

**Failure Signatures**: Potential failures include poor generalization to non-music video contexts, sensitivity to annotation inconsistencies in the 15% ambiguous cases, and limitations in capturing nuanced sentiment expression in informal YouTube comments.

**First Experiments**:
1. Test model performance on a held-out validation set stratified by valence-arousal quadrants
2. Compare MLP performance against simpler baselines (logistic regression, SVM) to validate architecture choice
3. Perform error analysis on misclassified comments to identify systematic weaknesses

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size of 63,471 comments is relatively small for robust deep learning model training in low-resource languages
- Focus exclusively on music video comments limits generalizability to other Sinhala comment contexts
- Annotation scheme using Russell's Valence-Arousal model may not capture full nuance of informal YouTube comments

## Confidence

**Dataset quality and annotation process**: High
**Model performance metrics**: Medium (limited by dataset size and domain specificity)
**Generalizability of findings**: Low (restricted to music video comments in Sinhala)

## Next Checks

1. Conduct cross-domain validation by testing the model on Sinhala comments from non-music video sources to assess generalizability.
2. Perform ablation studies to determine the impact of different model architectures and hyperparameters on performance.
3. Implement active learning with the existing model to identify and annotate additional ambiguous comments, potentially expanding the dataset and improving model robustness.