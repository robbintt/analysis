---
ver: rpa2
title: 'Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language
  Models'
arxiv_id: '2502.12420'
source_url: https://arxiv.org/abs/2502.12420
tags:
- merging
- task
- code
- tasks
- scaling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently merging large
  language models (LLMs) that have been fine-tuned for specialized tasks, without
  the need for costly retraining. The authors propose Sens-Merging, a sensitivity-guided
  coefficient adjustment method that enhances existing model merging techniques by
  operating at both task-specific and cross-task levels.
---

# Sens-Merging: Sensitivity-Guided Parameter Balancing for Merging Large Language Models

## Quick Facts
- arXiv ID: 2502.12420
- Source URL: https://arxiv.org/abs/2502.12420
- Authors: Shuqi Liu; Han Wu; Bowei He; Xiongwei Han; Mingxuan Yuan; Linqi Song
- Reference count: 17
- Primary result: Sensitivity-guided merging of fine-tuned LLMs outperforms both uniform baselines and individual fine-tuned models, particularly on code generation tasks

## Executive Summary
This paper introduces Sens-Merging, a novel approach for merging multiple fine-tuned large language models that have been specialized for different tasks. The method addresses the challenge of parameter interference during merging by analyzing parameter sensitivity within individual tasks and evaluating cross-task transferability. By operating at both task-specific and cross-task levels, Sens-Merging determines optimal merging coefficients that preserve specialized capabilities while enabling general performance improvements. The approach is evaluated on three widely adopted fine-tuned models (general knowledge, mathematical reasoning, and code generation) derived from LLaMA2-7B/13B and Mistral 7B families, demonstrating significant performance gains across all task categories.

## Method Summary
Sens-Merging combines task-specific sensitivity scaling with cross-task transferability analysis to determine optimal merging coefficients. The method first computes parameter sensitivity using first-order Taylor expansion, where sensitivity is defined as the change in loss when setting a parameter to zero. Layer-wise sensitivities are aggregated and normalized to produce task-specific scaling factors. Simultaneously, cross-task scaling coefficients are computed by measuring L2 distance between logits from different task models on calibration samples. The final merging coefficients combine these factors using softmax normalization, with the merged model computed as the weighted sum of task vectors (θ_SFT - θ_base) added to the pretrained backbone.

## Key Results
- Sens-Merging significantly improves performance across general knowledge, mathematical reasoning, and code generation tasks
- When combined with DARE, Sens-Merging enables merged models to outperform specialized fine-tuned models on code generation tasks
- Task-specific scaling alone achieves +21.36% improvement on MATH benchmark
- The method demonstrates that simply adding more models does not guarantee better performance, with Chat+Math outperforming Chat+Math+Code in some configurations

## Why This Works (Mechanism)

### Mechanism 1: Task-Specific Layer-wise Sensitivity Scaling
Parameters within each layer demonstrate varying levels of importance for specific tasks, and weighting layers by sensitivity preserves critical capabilities during merging. Uses first-order Taylor expansion approximation where parameter sensitivity S_j = |θ_j^T · ∇L(x)| estimates the loss change if that parameter were zeroed. Layer-wise sensitivities are aggregated and L2-normalized to produce task-specific scaling factors α_l_i per layer per model.

### Mechanism 2: Cross-Task Logits Alignment Scaling
Task-specific models contribute unequally to merging based on their transferability, measurable via output distribution similarity. Computes L2 distance between logits from different task models on calibration samples (g_i,j = ||f_θi(x) - f_θj(x)||_2). Models whose outputs align better with other tasks' expert models receive higher cross-task scaling coefficients, reflecting shared representations.

### Mechanism 3: Sensitivity-Weighted Task Vector Combination
Jointly considering within-task parameter importance and cross-task transferability via softmax-normalized combination produces more effective merging coefficients than uniform weighting. Multiplies task-specific (α_l_i) and cross-task (τ_i) factors, applies temperature-controlled softmax (σ_l_i = Softmax(τ_i · α_l_i, T)), then merges: θ_M = θ_base + Σ K · σ_l_i · (θ_SFT - θ_base).

## Foundational Learning

**Concept: Task Vectors**
- Why needed here: Sens-Merging operates on task vectors (θ_SFT - θ_PRE), not raw weights, representing task-specific knowledge as directional updates from the pretrained backbone.
- Quick check question: Why compute task vectors as differences rather than using fine-tuned weights directly?

**Concept: First-Order Taylor Approximation for Importance**
- Why needed here: The sensitivity computation approximates loss change without expensive per-parameter ablation, relying on gradient-parameter dot products.
- Quick check question: What does a high value of |θ_j · ∂L/∂θ_j| suggest about parameter θ_j's role in the model?

**Concept: Logits Alignment as Transfer Proxy**
- Why needed here: Cross-task scaling uses output distribution similarity to infer which models transfer well to other tasks' domains.
- Quick check question: If Model A's logits closely match Model B's on B's task data, what does this imply about shared representations?

## Architecture Onboarding

**Component map:**
Input: K fine-tuned models, pretrained backbone θ_base, calibration samples
├── Task-Specific Scaling (per model i)
│   ├── Forward-backward pass on calibration samples → gradients ∇L
│   ├── Parameter sensitivity: S_j = |θ_j^T · ∇L| per parameter
│   ├── Layer aggregation: s_l = Σ_{j∈layer l} S_j
│   └── L2 normalize: α_l_i = s_l / ||s||_2
├── Cross-Task Scaling
│   ├── For each model pair (i,j): g_i,j = ||logits_i - logits_j||_2 on task j samples
│   ├── Aggregate per model: τ_i = Σ_{j≠i} g_i,j
│   └── L1 normalize: τ_i = τ_i / ||τ||_1
├── Coefficient Fusion
│   ├── Element-wise product: combined = τ_i · α_l_i
│   └── Softmax with temperature: σ_l_i = FreeSoftmax(combined, T)
└── Merge
    └── θ_M^l = θ_base^l + Σ_i K · σ_l_i · (θ_SFT_i^l - θ_base^l)

**Critical path:**
1. Calibration sample selection (impacts both sensitivity and alignment quality)
2. Gradient computation (forward-backward pass per model)
3. Pairwise logits comparison (O(K²) forward passes)
4. Temperature-tuned softmax normalization
5. Task vector weighted summation

**Design tradeoffs:**
- Task-specific vs. cross-task dominance: Table 4 shows task-specific scaling excels on specialized tasks (MATH +21.36%) but cross-task scaling provides broader gains (+5.37 avg); combining both achieves best overall
- Model count: Table 5 shows Chat+Math (2 models) can outperform Chat+Math+Code (3 models), contradicting "more is better"
- Temperature T: Controls coefficient distribution sharpness; requires tuning

**Failure signatures:**
- Specialized task performance drops when cross-task scaling dominates (e.g., math reasoning -4.8 pts in ablation)
- Code models consistently receive lowest cross-task coefficients (0.12-0.18 in Table 6), potentially underweighted
- Uniform performance across tasks suggests scaling factors aren't differentiating effectively

**First 3 experiments:**
1. Replicate Task Arithmetic baseline merging Chat/Math/Code on LLaMA2-7B; verify average ~29.03 matches Table 1
2. Ablate task-specific scaling only (no cross-task); expect MATH improvement but limited general gains per Table 4
3. Sweep softmax temperature T ∈ {0.1, 0.5, 1.0, 2.0}; observe coefficient distribution and performance tradeoffs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Sens-Merging be adapted to handle heterogeneous model merging where the source models possess different architectures?
- Basis in paper: [explicit] The "Limitations" section states that the current implementation focuses on homogeneous merging and identifies extending Sens-Merging to heterogeneous architectures as a direction for future research
- Why unresolved: The current methodology relies on direct parameter subtraction and addition (task vectors), which requires identical parameter shapes and indices across models
- What evidence would resolve it: A modified algorithm that aligns parameters across different architectures (e.g., using permutation or projection) while maintaining the sensitivity-guided coefficient benefits

### Open Question 2
- Question: Does the effectiveness of Sens-Merging hold for fully fine-tuned models where weight divergences are significantly larger than in LoRA-based adaptations?
- Basis in paper: [explicit] The authors note the method is primarily validated on LoRA fine-tuned models with constrained weight differences and may require adaptations for fully fine-tuned models
- Why unresolved: Large weight divergences in full fine-tuning might violate the first-order Taylor expansion assumptions used to calculate parameter sensitivity
- What evidence would resolve it: Benchmark results comparing Sens-Merging performance on fully fine-tuned checkpoints (e.g., full weight updates) versus LoRA checkpoints on the same tasks

### Open Question 3
- Question: Can the trade-off between task-specific scaling (specialization) and cross-task scaling (generalization) be dynamically optimized?
- Basis in paper: [inferred] The paper explicitly identifies distinct trade-offs where task-specific scaling excels in math but offers limited general benefit, while cross-task scaling achieves broader gains at the cost of peak performance
- Why unresolved: The current method combines these factors using a fixed normalization approach, but does not offer a mechanism to tune the balance based on specific user requirements for specialization vs. generalization
- What evidence would resolve it: Introduction of a hyperparameter that successfully interpolates between task-specific and cross-task scaling dominance, validated by a Pareto frontier of performance results

### Open Question 4
- Question: What factors determine when adding models to a merge results in negative transfer, as seen when merging two models outperformed three?
- Basis in paper: [inferred] The analysis of Table 5 notes that "simply adding more models does not guarantee better performance," yet the specific mechanics of this interference are not fully isolated
- Why unresolved: While Sens-Merging measures cross-task transferability, it does not explicitly model or predict when the integration of an additional model (e.g., Code) will degrade the capabilities of an existing pair (e.g., Chat & Math)
- What evidence would resolve it: A predictive metric derived from task vector geometry or gradient conflicts that correlates with the performance drops observed when increasing the number of merged models

## Limitations
- The method is primarily validated on LoRA fine-tuned models and may require adaptations for fully fine-tuned models with larger weight divergences
- The approach focuses on homogeneous model merging and does not address heterogeneous architectures
- Code models consistently receive the lowest cross-task transferability coefficients, potentially underrepresenting their specialized capabilities

## Confidence

**High confidence:** Task-specific sensitivity scaling mechanism and its effectiveness on specialized tasks (MATH gains of +21.36%). The mathematical formulation using Taylor expansion is well-grounded.

**Medium confidence:** Cross-task transferability estimation via logits alignment. While intuitively reasonable, the assumption that logits distance correlates with representational overlap lacks direct validation.

**Medium confidence:** The joint sensitivity-guided merging consistently outperforms uniform baselines across all task types, with statistically significant improvements on most benchmarks.

**Low confidence:** Claims about superiority over fine-tuning for code generation, as the comparison baseline (code-specific fine-tuning) is not described in sufficient detail to assess fairness.

## Next Checks

1. Conduct systematic ablation on calibration sample count (10, 50, 100, 500 samples) to determine sensitivity of results to this hyperparameter.

2. Test whether logits alignment-based cross-task scaling systematically underweights specialized models by evaluating merging with cross-task scaling disabled.

3. Perform temperature sweep (T ∈ {0.1, 0.5, 1.0, 2.0}) to analyze its impact on coefficient distribution and task-specific performance tradeoffs.