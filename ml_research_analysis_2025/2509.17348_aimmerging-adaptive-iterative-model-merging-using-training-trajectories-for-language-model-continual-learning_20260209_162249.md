---
ver: rpa2
title: 'AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for
  Language Model Continual Learning'
arxiv_id: '2509.17348'
source_url: https://arxiv.org/abs/2509.17348
tags:
- merging
- learning
- knowledge
- forgetting
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses continual learning (CL) for large language
  models (LLMs) by introducing AIMMerging, a novel framework that leverages learning
  and forgetting signals from training trajectories to adaptively schedule model merges.
  The method dynamically adjusts the timing and frequency of iterative fusion based
  on these signals, using a merge controller and a rehearsal-based knowledge fusion
  module.
---

# AIMMerging: Adaptive Iterative Model Merging Using Training Trajectories for Language Model Continual Learning

## Quick Facts
- **arXiv ID**: 2509.17348
- **Source URL**: https://arxiv.org/abs/2509.17348
- **Reference count**: 40
- **Primary result**: 80% relative improvement on forward transfer (FWT) and 59% on backward transfer (BWT) for continual learning

## Executive Summary
This paper addresses continual learning (CL) for large language models (LLMs) by introducing AIMMerging, a novel framework that leverages learning and forgetting signals from training trajectories to adaptively schedule model merges. The method dynamically adjusts the timing and frequency of iterative fusion based on these signals, using a merge controller and a rehearsal-based knowledge fusion module. Extensive experiments on three benchmarks with models ranging from 770M to 13B parameters show significant performance improvements: 80% relative improvement on forward transfer (FWT) and 59% on backward transfer (BWT), surpassing state-of-the-art methods. AIMMerging effectively balances retaining historical knowledge and acquiring new knowledge, demonstrating strong generalization and robustness.

## Method Summary
AIMMerging is a continual learning framework that monitors learning and forgetting signals during training to adaptively schedule model merges. It uses a merge controller that tracks parameter changes (learning signal) and historical loss on a rehearsal buffer (forgetting signal). The controller adjusts the merge interval dynamically: decreasing it during rapid learning phases and increasing it during convergence. If the forgetting signal exceeds a threshold, an early merge is triggered. The fusion module combines task vectors from new and historical knowledge using signal-based weights. Implemented within the LoRA framework, AIMMerging fine-tunes the model on memory before each merge to preserve historical knowledge while acquiring new capabilities.

## Key Results
- 80% relative improvement in forward transfer (FWT) on the Standard CL benchmark
- 59% improvement in backward transfer (BWT) compared to state-of-the-art methods
- Significant gains across three benchmarks with models ranging from 770M to 13B parameters
- Outperforms baseline methods including ER-Adam, ER-Momentum, and Others with 7.6%, 4.6%, and 4.9% OP gains respectively

## Why This Works (Mechanism)

### Mechanism 1
Dynamically adjusting the merge interval based on the rate of parameter change prevents the model from drifting too far during rapid learning phases while avoiding unnecessary interference during convergence. The controller monitors the learning signal $\Lambda_b$ (normalized absolute parameter changes) via a sliding window. If upward trends dominate (rapid learning), the interval $S$ is reduced ($S/\gamma_{learn}$). If downward trends dominate (convergence), $S$ is increased. This aligns merging frequency with the model's plasticity.

### Mechanism 2
Triggering immediate merges upon detecting spikes in historical loss is more effective for mitigating catastrophic forgetting than waiting for fixed schedule checkpoints. A "forgetting signal" monitors loss on a rehearsal buffer. If historical loss exceeds a dynamic threshold $\delta_{b+1}$, the controller overrides the scheduled interval to force an early merge, explicitly prioritizing stability when degradation is detected.

### Mechanism 3
Weighting the fusion of new vs. historical task vectors based on the relative strength of learning and forgetting signals balances plasticity and stability better than static weighting. The fusion module calculates weights $\alpha_1$ (new) and $\alpha_2$ (past) based on the proportion of learning trends $P_{new}$ and forgetting triggers $P_{past}$. High forgetting triggers increase the weight of the historical task vector $\tau_{past}$ in the update step $\hat{\theta}$.

## Foundational Learning

- **Concept: Task Vectors & Model Merging**
  - **Why needed here**: The entire framework operates by manipulating "task vectors" ($\tau = \theta_{new} - \theta_{old}$). You must understand that model weights can be added/subtracted to control behavior before diving into the adaptive controller.
  - **Quick check question**: Can you explain why adding a task vector to a pre-trained model might induce a new capability without retraining?

- **Concept: Catastrophic Forgetting (Stability-Plasticity Dilemma)**
  - **Why needed here**: The "forgetting signal" and merge intervals exist specifically to manage the trade-off between acquiring new skills (plasticity) and retaining old ones (stability).
  - **Quick check question**: If a model trains on Task B, why does its performance on Task A typically degrade, and how does merging (vs. fine-tuning) theoretically mitigate this?

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed here**: The paper explicitly implements this within the LoRA framework (modifying $Q, V$ etc.). You need to know that these are low-rank matrices inserted into the frozen backbone, as the "parameter changes" tracked are primarily within these adapters.
  - **Quick check question**: In a LoRA setup, which parameters are actually changing during training, and how does that reduce the memory footprint?

## Architecture Onboarding

- **Component map**: Training Data + Rehearsal Buffer -> Controller (calculates Learning Signal and Forgetting Signal) -> Decision (Next Merge Step) -> Fusion Module (computes Task Vectors and Merge Weights) -> State (maintains Current Weights and Sliding Window History)

- **Critical path**:
  1. **Training Iteration**: Update LoRA weights on new task batch; compute loss on memory batch (no grad)
  2. **Monitoring**: Update sliding window for parameter norms; check memory loss against threshold
  3. **Decision**: Does step count == `S` OR is `Forgetting Signal` active?
  4. **Fusion**: If yes, compute $\tau_{new}$ (current - previous merge) and $\tau_{past}$ (fine-tune on memory - current). Apply $\hat{\theta} = \theta_{prev} + \alpha_1 \tau_{new} + \alpha_2 \tau_{past}$

- **Design tradeoffs**:
  - **Reactivity vs. Stability**: A small sliding window ($L_w$) makes the controller sensitive to noise (merging too often), while a large window creates lag
  - **Memory Overhead**: Unlike rehearsal-free methods, this requires a buffer (2% of data per task) to calculate the forgetting signal

- **Failure signatures**:
  - **Oscillation**: Merging happens every step (interval $S$ crashes to $S_{min}$). Usually caused by a forgetting threshold that is too tight or a learning signal that never stabilizes
  - **Stagnation**: Model fails to learn new tasks. Likely caused by excessive merging or $P_{past}$ weighting dominating $P_{new}$

- **First 3 experiments**:
  1. **Baseline Validation**: Reproduce Table 1 (Standard CL Benchmark) comparing Fixed Interval vs. AIMMerging to verify the controller is actually adjusting $S$ dynamically (check the logs for interval changes)
  2. **Ablation on Buffer Size**: Run Table 5 setup to see how small the rehearsal buffer can get before the forgetting signal becomes unreliable
  3. **Signal Visualization**: Reproduce Figure 7 for a single task. Plot `Learning Signal` and `Merge Interval S` on the same axis to confirm inversely correlated behavior

## Open Questions the Paper Calls Out

1. Can alternative metrics, such as gradient information or other internal indicators, capture learning and forgetting states more effectively than the current metrics of parameter change and historical loss?

2. Can fully automated optimization methods be developed to determine merging intervals and thresholds, removing the need for semi-heuristic manual tuning?

3. Is it possible to develop a memory-free variant of AIMMerging that maintains performance without relying on a rehearsal buffer?

## Limitations

- The forgetting signal relies on a small rehearsal buffer as a proxy for historical knowledge retention, with no analysis of buffer size sensitivity
- The 80% relative improvement in FWT appears unusually high for CL research, suggesting either exceptional methodological strength or potential overstatement
- The framework requires setting hyperparameters such as $S_{min}, S_{max}$, and sliding window sizes ($L_w$) manually

## Confidence

- **High confidence**: The adaptive merge interval mechanism based on learning signal trends (Λ) is well-grounded in established CL principles of plasticity-stability trade-off
- **Medium confidence**: The forgetting signal and early merge triggering show strong empirical results but rely on assumptions about rehearsal buffer representativeness that aren't thoroughly validated
- **Low confidence**: The claimed 80% FWT improvement and "state-of-the-art" positioning across all metrics requires careful benchmarking verification

## Next Checks

1. **Buffer size sensitivity**: Run the Standard CL benchmark with rehearsal buffer sizes of 1%, 5%, and 10% to determine the minimum effective buffer size and verify the forgetting signal remains reliable as buffer shrinks

2. **Signal correlation analysis**: For a single task, collect and plot the learning signal (Λ), forgetting signal activations, and actual task performance over time to verify that parameter change magnitude correlates with meaningful knowledge acquisition rather than gradient noise

3. **Baseline replication verification**: Reproduce the key results from Table 1 comparing Fixed Interval vs. AIMMerging, but also include a variant where the merge interval is randomized rather than adaptive, to isolate the benefit of adaptive scheduling from simply having frequent merges