---
ver: rpa2
title: 'BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents'
arxiv_id: '2510.23458'
source_url: https://arxiv.org/abs/2510.23458
tags:
- confidence
- answer
- arxiv
- tool
- attempt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates confidence calibration in large language
  model (LLM)-based web agents during complex, multi-turn interactions. It proposes
  BrowseConf, a test-time scaling method that uses verbalized confidence scores to
  dynamically allocate computational resources, triggering additional attempts only
  when confidence falls below a calibrated threshold.
---

# BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents

## Quick Facts
- **arXiv ID:** 2510.23458
- **Source URL:** https://arxiv.org/abs/2510.23458
- **Reference count:** 10
- **Primary result:** Achieves competitive accuracy to fixed-budget baselines while reducing average attempts per question by 50-80% using confidence-guided test-time scaling.

## Executive Summary
BrowseConf introduces a test-time scaling method that dynamically allocates computational resources for web agents based on verbalized confidence scores. The approach uses confidence thresholds to determine when to trigger additional attempts during multi-turn web browsing tasks, achieving significant efficiency gains while maintaining accuracy. By calibrating these thresholds on a validation set, BrowseConf can accept high-confidence answers early and avoid unnecessary rollouts, reducing average attempts by 50-80% compared to fixed-budget approaches.

## Method Summary
BrowseConf implements three variants of confidence-guided test-time scaling for web agents: BrowseConf-Zero (restart from scratch), BrowseConf-Summary (propagate trajectory summaries), and BrowseConf-Neg (constrain model to avoid previous low-confidence answers). The method elicits verbalized confidence scores (0-100) from the agent after each multi-turn browsing attempt, calibrates a threshold τ on a validation set using relative accuracy improvement, and accepts answers when confidence meets or exceeds τ. Knowledge propagation mechanisms allow subsequent attempts to benefit from information in low-confidence attempts, improving efficiency. The approach is evaluated on BrowseComp and BrowseComp-zh benchmarks using gpt-oss-120b and DeepSeek-V3.1 models.

## Key Results
- BrowseConf-Neg achieves 54.5% accuracy on BrowseComp using gpt-oss-120b with only 3.88 average attempts versus 70.3% accuracy for Pass@10 with 10 attempts
- Confidence scores strongly correlate with accuracy: near-zero accuracy for confidence <70% and more than double the overall accuracy for confidence >95%
- BrowseConf achieves competitive accuracy to fixed-budget baselines while reducing average attempts per question by 50-80%
- BrowseConf-Summary consistently requires the fewest rollouts and BrowseConf-Neg often yields the highest accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Verbalized confidence scores provide a meaningful *relative* signal of answer quality in multi-turn agentic tasks, even though models are poorly calibrated in absolute terms.
- **Mechanism:** Models implicitly encode task-level uncertainty into their verbalized confidence. When a model has navigated a long action sequence and gathered strong evidence, it reports higher confidence; when the trajectory is incomplete or contradictory, confidence drops.
- **Core assumption:** The correlation between verbalized confidence and correctness generalizes across agentic tasks and remains stable under the same prompting protocol.
- **Evidence anchors:** Accuracy approaches zero for confidence scores below 70% but more than doubles the overall average for scores above 95%.

### Mechanism 2
- **Claim:** A calibrated confidence threshold can dynamically allocate test-time compute, triggering retries only when needed, achieving competitive accuracy with 50–80% fewer attempts.
- **Mechanism:** BrowseConf calibrates a threshold τ on a validation set by selecting the minimum τ that ensures ≥k% relative accuracy improvement for samples exceeding τ. At inference, if Ci ≥ τ, the answer is accepted; otherwise, a new attempt is launched.
- **Core assumption:** The validation set distribution is representative of the test distribution; the relative accuracy improvement criterion transfers.
- **Evidence anchors:** BrowseConf-Neg attains 54.5% accuracy... with only 3.88 average attempts versus 70.3% accuracy for Pass@10 with 10 attempts.

### Mechanism 3
- **Claim:** Propagating structured information from low-confidence attempts to subsequent attempts improves efficiency and, for negative constraints, accuracy.
- **Mechanism:** Three variants: (1) BrowseConf-Zero restarts from scratch; (2) BrowseConf-Summary carries forward extracted entities, contradictions, and unexplored URLs; (3) BrowseConf-Neg explicitly provides previous low-confidence answers as incorrect constraints.
- **Core assumption:** Low-confidence attempts still contain useful partial information (evidence, URLs, reasoning) that can guide future attempts without inducing error propagation.
- **Evidence anchors:** BrowseConf-Summary consistently requires the fewest rollouts... BrowseConf-Neg... often yields the highest accuracy.

## Foundational Learning

- **Concept: Confidence Calibration**
  - **Why needed here:** Understanding that models can be overconfident yet still provide useful relative signals is essential for interpreting BrowseConf's design.
  - **Quick check question:** If a model reports 90% confidence but only achieves 50% accuracy in that bin, is the confidence signal useless? (Answer: No—it can still rank relative quality.)

- **Concept: Test-Time Scaling (TTS)**
  - **Why needed here:** BrowseConf is a TTS method; understanding baselines like Pass@k, self-consistency, and best-of-N clarifies what BrowseConf improves upon.
  - **Quick check question:** How does fixed-budget TTS differ from adaptive TTS? (Answer: Fixed-budget applies the same number of rollouts to every query; adaptive varies based on a signal like confidence.)

- **Concept: Multi-Turn Agentic Workflows**
  - **Why needed here:** Web agents execute long action-observation sequences; confidence is assessed after these sequences, not after single turns.
  - **Quick check question:** Why is confidence estimation harder in agentic settings than single-turn QA? (Answer: Error accumulation, context forgetting, and external tool dependencies introduce more uncertainty sources.)

## Architecture Onboarding

- **Component map:** Query → Agent execution (multi-turn browsing) → Final answer + confidence → Check Ci ≥ τ → If yes: return; If no: generate summary/negatives → Launch next attempt → Repeat until threshold met or N exhausted.

- **Critical path:** Query → Agent execution (multi-turn browsing) → Final answer + confidence → Check Ci ≥ τ → If yes: return; If no: generate summary/negatives → Launch next attempt → Repeat until threshold met or N exhausted.

- **Design tradeoffs:**
  - **Zero vs Summary vs Neg:** Zero is simplest but least efficient; Summary minimizes rollouts but risks error propagation; Neg maximizes accuracy but requires explicit incorrect answer handling.
  - **Threshold strictness (k%):** Higher k improves accuracy but increases attempts; diminishing returns above k=10.
  - **Maximum attempts N:** Higher N provides more chances but with diminishing per-attempt value.

- **Failure signatures:**
  1. **Context length overflow:** Treated as failure (confidence = -1); handled per variant.
  2. **Overconfident wrong answers:** If model reports high confidence on incorrect answers, BrowseConf terminates early with wrong output.
  3. **Summary-induced error fixation:** BrowseConf-Summary can anchor on incorrect evidence from low-confidence attempts.

- **First 3 experiments:**
  1. **Threshold sensitivity analysis:** Run BrowseConf-Zero on a held-out set with k ∈ {5, 10, 20} to plot accuracy vs. average attempts; confirm diminishing returns pattern.
  2. **Variant comparison:** On BrowseComp or equivalent, compare Zero, Summary, and Neg on same model; measure accuracy, average attempts, and interaction count reduction.
  3. **Cross-dataset calibration transfer:** Calibrate τ on SailorFog-QA, test on BrowseComp-zh to assess distribution shift robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does BrowseConf generalize to non-agentic or single-turn tasks where confidence calibration patterns may differ from long-horizon web browsing?
- Basis in paper: The paper states "research on confidence in complex multi-turn interactions is limited" and focuses specifically on "DeepResearch" tasks, leaving other domains unexplored.
- Why unresolved: The correlation between verbalized confidence and accuracy was established only for multi-turn web agents; whether these findings transfer to simpler tasks or other agentic domains remains unknown.
- What evidence would resolve it: Experiments applying BrowseConf to standard single-turn benchmarks (MMLU, GSM8K) and other multi-turn agentic tasks, comparing calibration patterns and efficiency gains.

### Open Question 2
- Question: What types of fine-grained feedback from failed attempts would most effectively guide subsequent agent reasoning beyond summaries and negative constraints?
- Basis in paper: The conclusion states: "Future work could explore integrating more fine-grained feedback from previous attempts to further guide agent reasoning."
- Why unresolved: The three proposed variants represent coarse feedback strategies; intermediate approaches (e.g., partial trajectory reuse, error-specific hints, webpage relevance signals) are unexplored.
- What evidence would resolve it: Systematic comparison of feedback mechanisms—such as retaining visited URLs, error taxonomy tagging, or retrieved evidence aggregation—measuring accuracy gains and token efficiency on BrowseComp.

### Open Question 3
- Question: Why does verbalized confidence remain predictive of relative accuracy despite models being systematically overconfident?
- Basis in paper: The paper notes "models exhibit poor calibration" with "verbalized confidence scores substantially exceed[ing] their actual task accuracies," yet "a strong positive correlation...is observed."
- Why unresolved: The mechanism enabling ordinal reliability without calibration is unclear—whether it stems from consistent overconfidence patterns, task-specific heuristics, or internal uncertainty representations is not investigated.
- What evidence would resolve it: Analysis probing whether overconfidence magnitude correlates with specific error types, comparison with alternative confidence signals (token entropy, consistency-based), and evaluation across model scales to identify when ordinal reliability emerges.

### Open Question 4
- Question: How sensitive is BrowseConf to distributional shift between the calibration validation set (SailorFog-QA) and target benchmarks?
- Basis in paper: Threshold τ is selected using SailorFog-QA but applied to BrowseComp; the paper does not analyze whether optimal k% values transfer across datasets with different difficulty distributions.
- Why unresolved: If confidence-accuracy relationships differ between datasets, a single calibrated threshold may be suboptimal; the approach assumes similar uncertainty profiles across information-seeking tasks.
- What evidence would resolve it: Cross-dataset calibration experiments (train on SailorFog-QA, test on BrowseComp vs. other benchmarks), analysis of threshold robustness under domain shifts, and adaptive threshold selection strategies.

## Limitations

- The method depends on model-internal confidence signals that are poorly calibrated in absolute terms, potentially limiting generalization across different domains or prompting strategies
- BrowseConf assumes low-confidence attempts contain useful information for subsequent attempts, which may not hold for adversarial or highly ambiguous queries where initial trajectories are fundamentally flawed
- The performance gains come at the cost of increased inference time during the threshold evaluation phase, which is not explicitly quantified in the paper

## Confidence

**High Confidence Claims:**
- Confidence scores show strong correlation with accuracy (approaching zero for <70% confidence, doubling accuracy for >95%)
- BrowseConf achieves competitive accuracy to fixed-budget baselines while reducing average attempts by 50-80%
- Confidence-based adaptive scaling outperforms fixed-budget approaches in the BrowseComp benchmark

**Medium Confidence Claims:**
- The relative accuracy improvement criterion effectively calibrates thresholds for diverse k% settings
- Knowledge propagation from low-confidence attempts improves efficiency (BrowseConf-Summary and BrowseConf-Neg variants)
- The method generalizes across different models (gpt-oss-120b and DeepSeek-V3.1)

**Low Confidence Claims:**
- BrowseConf will maintain performance advantages when deployed on substantially different distributions than SailorFog-QA
- The specific threshold calibration methodology will transfer to other agentic task types beyond web browsing
- Context length overflow handling (confidence=-1) is optimal for all failure scenarios

## Next Checks

1. **Distribution Shift Robustness:** Calibrate τ on SailorFog-QA and evaluate BrowseConf on a distinctly different dataset (e.g., medical QA or legal document analysis) to assess generalization of the confidence-accuracy correlation and threshold calibration.

2. **Ablation of Knowledge Propagation:** Systematically disable the summary and negative constraint mechanisms in BrowseConf variants to quantify their exact contribution to efficiency gains versus potential error propagation costs.

3. **Threshold Calibration Sensitivity:** Test multiple threshold selection criteria beyond relative accuracy improvement (e.g., F1-score maximization, calibration error minimization) to determine if the proposed method is optimal or if simpler approaches could achieve similar results.