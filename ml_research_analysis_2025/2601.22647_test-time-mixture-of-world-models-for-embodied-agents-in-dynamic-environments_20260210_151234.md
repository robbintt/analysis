---
ver: rpa2
title: Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments
arxiv_id: '2601.22647'
source_url: https://arxiv.org/abs/2601.22647
tags:
- world
- object
- tmow
- unseen
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Test-time Mixture of World Models (TMoW)
  framework that enables embodied agents to adapt to dynamic environments by reconfiguring
  world model mixtures at test time. The key idea is to use multi-granular prototype-based
  routing that compares input observations with hierarchical prototypes across object-to-scene
  levels, allowing test-time refinement to adapt to unseen domains and distilled mixture-based
  augmentation to create new world models from few-shot demonstrations.
---

# Test-Time Mixture of World Models for Embodied Agents in Dynamic Environments

## Quick Facts
- arXiv ID: 2601.22647
- Source URL: https://arxiv.org/abs/2601.22647
- Reference count: 40
- Primary result: 27.21% improvement in zero-shot adaptation and 25.66% gain in few-shot expansion over state-of-the-art baselines

## Executive Summary
This paper introduces Test-time Mixture of World Models (TMoW), a framework enabling embodied agents to adapt to dynamic environments by reconfiguring world model mixtures at test time. The key innovation is multi-granular prototype-based routing that compares input observations with hierarchical prototypes across object-to-scene levels, allowing test-time refinement to adapt to unseen domains and distilled mixture-based augmentation to create new world models from few-shot demonstrations. The approach achieves significant performance improvements on VirtualHome, ALFWorld, RLBench, and real-world robotic scenarios without costly retraining.

## Method Summary
TMoW uses a Llama-3.2-1B base LLM with LoRA adapters as domain-specific world models, routing through a Message Passing Neural Network (MPNN) that builds hierarchical graph representations. The router computes cosine similarity between input embeddings and per-domain prototypes at multiple layers (0, 4, 8, 12 use GCN; others use MLP), applies top-K selection (K=3 default), and normalizes weights. Test-time prototype refinement updates prototypes via similarity-weighted interpolation, while distilled mixture-based augmentation constructs new adapters from few-shot demonstrations by distilling knowledge from weighted mixtures of existing models.

## Key Results
- 27.21% improvement in Success Rate over SayCanPay in zero-shot adaptation scenarios
- 25.66% gain in few-shot expansion scenarios compared to baselines
- TMoW-Object achieves 76.17% SR on unseen domains vs. 71.40% for SayCanPay

## Why This Works (Mechanism)

### Mechanism 1: Multi-Granular Prototype-Based Routing
Hierarchical prototypes at object-to-scene levels enable partial knowledge sharing across domains that differ globally but share local patterns. A Message Passing Neural Network (MPNN) progressively aggregates graph representations across layers—early layers capture local object affordances (high routing entropy, multiple models active), while deeper layers specialize to scene-level patterns (lower entropy, fewer models). Routing scores are computed via cosine similarity between input embeddings and per-domain prototypes at each layer, then sparsified via top-K selection. The core assumption is that domains exhibit complementary overlap: they may differ at some granularity levels while matching at others (e.g., kitchens and offices share object affordances despite different layouts).

### Mechanism 2: Test-Time Prototype Refinement
Updating prototypes during inference via similarity-weighted interpolation enables zero-shot adaptation without retraining. For each input, the system computes domain embedding E^(l) and refines each prototype as: p̄_j = (1-α·sim)·p_j + α·sim·Δp_j, where Δp_j is a weighted sum of all prototypes based on prototype-prototype similarity. This densifies prototype space around frequently encountered features. The core assumption is that unseen domains can be expressed as interpolations or compositions of seen domain prototypes (smoothly varying feature space).

### Mechanism 3: Distilled Mixture-Based Model Augmentation
New world models can be constructed from few-shot demonstrations by distilling knowledge from weighted mixtures of existing models. Given few-shot data D', the system computes routing weights over existing models, initializes new adapter m' = Σ w̄_j·m_j, then fine-tunes with teacher-forcing loss. The new prototype is extracted from the demonstration data directly. The core assumption is that relevant knowledge fragments exist within the current model pool and can be extracted via routing weights; few-shot data provides sufficient signal to consolidate fragments.

## Foundational Learning

- **Mixture-of-Experts (MoE) with sparse routing:**
  - Why needed here: TMoW extends MoE by making routing test-time adaptive; understanding standard MoE (expert specialization, top-K gating, load balancing) is prerequisite.
  - Quick check question: Can you explain why standard MoE routing is considered "fixed after training" and how that limits domain adaptation?

- **Graph Neural Networks (GNNs) and Message Passing:**
  - Why needed here: The router uses MPNN to build hierarchical prototypes from observation graphs; oversmoothing and layer-wise aggregation are critical design considerations.
  - Quick check question: What is the oversmoothing problem in deep GNNs, and how does TMoW's hybrid GCN/MLP design address it?

- **Knowledge Distillation:**
  - Why needed here: Model augmentation distills from weighted expert mixtures; understanding soft targets, teacher-student training, and data efficiency is essential.
  - Quick check question: Why does initializing the student as a weighted mixture of teachers (rather than random) improve few-shot learning efficiency?

## Architecture Onboarding

- **Component map:**
  Base LLM (Llama-3.2-1B) + LoRA adapters as domain-specific world models -> MPNN-based graph processor -> Multi-granular prototype bank -> Top-K router (K=3 default) -> Test-time refinement module -> Distillation module

- **Critical path:**
  1. Observation → graph construction (V, E, R)
  2. MPNN forward pass → layer-wise domain embeddings E^(l)
  3. Similarity computation → raw routing scores w_j^(l)
  4. Top-K sparsification + softmax → normalized weights w̄_j^(l)
  5. Weighted adapter combination at each layer → action prediction
  6. (Optional) Prototype refinement after each step
  7. (Optional) Distillation when few-shot data available

- **Design tradeoffs:**
  - K=3 optimal: lower K (single expert) loses knowledge sharing; higher K (5+) introduces noise from irrelevant models
  - Refinement rate α: too low (<0.5) converges slowly and harms performance; α≥0.5 robustly improves SR
  - GCN layers (0, 4, 8, 12): strategic placement prevents oversmoothing while capturing multi-granularity

- **Failure signatures:**
  - Routing entropy collapses to single expert: likely domain completely out of distribution; check prototype similarity distribution
  - Performance degrades with refinement: α too low or prototypes poorly initialized; inspect similarity-weighted updates
  - Distillation fails to improve over scratch: routing weights not capturing relevant knowledge; verify prototype-domain alignment

- **First 3 experiments:**
  1. **Ablate routing granularity:** Compare TMoW-Object vs. TMoW-Scene vs. full multi-granular on unseen domains; expect multi-granular to show 15-20% SR improvement.
  2. **Sweep refinement rate α:** Test α ∈ {0.1, 0.3, 0.5, 0.7, 0.9} on held-out unseen domains; expect performance floor at α<0.5, ceiling at α≥0.5.
  3. **Verify top-K sensitivity:** Compare K=1, 3, 5, 7 on zero-shot adaptation; expect K=3 optimal, K>5 degrading toward K=1 baseline.

## Open Questions the Paper Calls Out

### Open Question 1
How can the framework be modified to handle highly non-stationary environments, specifically multi-agent settings where other agents continuously alter environment dynamics? The current TMoW framework assumes world models that capture environment dynamics which are likely static or single-agent centric; the test-time refinement relies on interpolating existing static knowledge rather than predicting adversarial or independent agent behaviors.

### Open Question 2
How can the safety and interpretability of the routing decisions be enhanced for reliable deployment in safety-critical applications? While the paper explains how the router selects models via cosine similarity of prototypes, it does not provide mechanisms to audit why a specific mixture is safer than others or how to constrain routing to prevent unsafe model combinations during test-time refinement.

### Open Question 3
Does the performance advantage of TMoW over baselines persist when scaling the base LLM beyond the 1B parameter size used in experiments? It is unclear if the relative improvement comes from the efficient parameter isolation of the MoE or simply from the base model's inability to handle diverse tasks alone; if the base model is large enough to "solve" all domains, the MoE routing might become redundant or less impactful.

### Open Question 4
How does the system prevent "prototype drift" or capacity saturation during continuous expansion when hundreds of new world models are added? As more models are added via distilled mixture-based augmentation, the average distance between prototypes might shrink, potentially making routing noisy or causing the model to confuse domains that share similar multi-granular features.

## Limitations
- Limited real-world validation: only 8 scenes and 29 episodes on a single Franka robot
- Performance depends on assumptions about feature space continuity that may not hold for truly novel domains
- Test-time refinement effectiveness depends on α≥0.5, which appears dataset-dependent

## Confidence

- **High confidence:** The hierarchical prototype routing mechanism with multi-granular abstraction layers is well-supported by layer-wise entropy analysis and ablation studies
- **Medium confidence:** Test-time refinement claims (7.44% improvement) are supported by ablation but depend on interpolation assumptions
- **Medium confidence:** Few-shot augmentation (18.39% improvement) is validated through direct comparison with scratch training

## Next Checks

1. **Feature space continuity test:** Systematically evaluate TMoW on domains with controlled feature overlap reduction to identify the interpolation mechanism's breaking point
2. **Real-world generalization benchmark:** Deploy TMoW across multiple robot platforms and environments with varying sensor configurations
3. **Computational overhead analysis:** Measure the runtime overhead of test-time routing and refinement across different K values and refinement rates for real-time deployment assessment