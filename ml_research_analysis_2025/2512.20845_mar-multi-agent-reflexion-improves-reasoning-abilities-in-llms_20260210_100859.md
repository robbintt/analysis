---
ver: rpa2
title: MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs
arxiv_id: '2512.20845'
source_url: https://arxiv.org/abs/2512.20845
tags:
- reflexion
- reasoning
- multi-agent
- hotpotqa
- debate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper identifies a key failure mode in single-agent Reflexion:\
  \ the model repeatedly reinforces its own flawed reasoning, leading to \u201Cdegeneration\
  \ of thought\u201D and mode collapse. To address this, the authors introduce Multi-Agent\
  \ Reflexion (MAR), which replaces single-agent self-reflection with a structured\
  \ debate among diverse persona-driven critics (e.g., Verifier, Skeptic, Logician,\
  \ Creative)."
---

# MAR:Multi-Agent Reflexion Improves Reasoning Abilities in LLMs

## Quick Facts
- arXiv ID: 2512.20845
- Source URL: https://arxiv.org/abs/2512.20845
- Reference count: 4
- Single-agent Reflexion suffers from mode collapse and degeneration of thought, limiting reasoning improvement

## Executive Summary
The paper identifies a key failure mode in single-agent Reflexion: the model repeatedly reinforces its own flawed reasoning, leading to "degeneration of thought" and mode collapse. To address this, the authors introduce Multi-Agent Reflexion (MAR), which replaces single-agent self-reflection with a structured debate among diverse persona-driven critics (e.g., Verifier, Skeptic, Logician, Creative). These critics analyze failed attempts from different perspectives, and a judge synthesizes their critiques into a unified reflection. On HotPotQA, MAR improves Exact Match accuracy from 44% to 47%; on HumanEval, it raises pass@1 from 76.4% to 82.6%. The gains stem from reducing confirmation bias and introducing more diverse, corrective reasoning, though at the cost of higher computational overhead.

## Method Summary
MAR implements a multi-agent debate framework where an Actor attempts tasks while maintaining episodic memory. When the Evaluator detects failure (via EM score for HotPotQA or execution failure for HumanEval), it triggers a debate among 3-4 persona-driven critics who analyze the failure from different perspectives. The debate proceeds through up to 2 rounds of agreement/disagreement, after which a judge synthesizes the diverse critiques into a "Consensus Reflection" that gets injected back into the Actor's memory. This structured debate replaces single-agent self-reflection, aiming to prevent the confirmation bias and mode collapse observed in standard Reflexion.

## Key Results
- HotPotQA Exact Match: 44% (single-agent Reflexion) → 47% (MAR)
- HumanEval pass@1: 76.4% (single-agent Reflexion) → 82.6% (MAR)
- Ablation study shows each MAR component (personas, debate, judge) contributes to performance gains
- MAR produces more diverse reasoning paths and prevents mode collapse compared to single-agent Reflexion

## Why This Works (Mechanism)
MAR addresses the degeneration-of-thought problem in single-agent Reflexion by introducing diverse, conflicting perspectives through multiple persona-driven critics. Instead of a single agent reinforcing its own flawed reasoning, MAR creates a structured debate where different cognitive approaches (skepticism, logical analysis, creative thinking, verification) compete and challenge each other. The judge synthesis ensures these diverse perspectives are integrated into a coherent reflection rather than creating confusion. This multi-perspective approach prevents the model from getting stuck in local minima of flawed reasoning patterns and introduces corrective feedback that single-agent reflection cannot provide.

## Foundational Learning

**Reflexion**: Self-reflective reasoning loop where models analyze failures and adjust strategies - needed because standard prompting lacks error-correction mechanisms; quick check: verify single-agent Reflexion baseline works before adding MAR complexity.

**Episodic Memory**: Structured storage of past attempts and reflections that models can retrieve and build upon - needed to maintain context across multiple trials; quick check: confirm memory contains complete task history including failed attempts.

**Persona-driven Agents**: Systematically varied agent roles with distinct reasoning styles - needed to ensure diverse perspectives in debate rather than homogeneous thinking; quick check: verify each persona produces distinctly different critiques of the same failure.

**Judge Synthesis**: Mechanism to integrate conflicting perspectives into coherent guidance - needed because unstructured debate could confuse rather than help the Actor; quick check: ensure consensus reflection is actionable and specific rather than vague compromise.

## Architecture Onboarding

**Component Map**: Actor -> Evaluator -> Debate Coordinator -> [Persona Critics] -> Judge -> Consensus Reflection -> Actor Memory

**Critical Path**: Task attempt → Evaluation → Debate (if failed) → Judge synthesis → Memory update → Next attempt

**Design Tradeoffs**: MAR trades computational efficiency (4× LLM calls per trial) for reasoning diversity and improved error correction; single-agent Reflexion is faster but prone to mode collapse.

**Failure Signatures**: Mode collapse manifests as nearly identical incorrect solutions across retries; judge synthesis failure shows as vague or contradictory reflections that don't guide improvement.

**First Experiments**:
1. Implement single-agent Reflexion baseline and verify it exhibits mode collapse on a small task set
2. Add MAR debate with one persona to verify debate mechanism works before scaling to full multi-persona setup
3. Run MAR ablation study removing judge synthesis to verify its contribution to performance gains

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead is substantial (4× LLM calls per trial in HotPotQA)
- Gains are incremental (44% → 47% EM, 76.4% → 82.6% pass@1) rather than transformative
- Missing critical implementation details: judge coordinator prompts and specific "difficult" question subset

## Confidence

**High confidence**: The existence of the degeneration-of-thought problem in single-agent Reflexion, and that MAR's multi-agent structure introduces more diverse reasoning perspectives

**Medium confidence**: The quantitative improvement figures (44% → 47% EM, 76.4% → 82.6% pass@1), as these depend on specific implementation details that are partially unspecified

**Medium confidence**: The ablation study results, as they show relative improvements but don't establish absolute performance baselines

## Next Checks

1. Implement MAR with the provided persona prompts and test on a small, publicly available subset of HotPotQA questions to verify the debate mechanism works as described and produces more diverse reasoning paths than single-agent Reflexion

2. Conduct a controlled ablation study where each MAR component (personas, debate, judge) is removed individually to verify the reported contribution of each element to overall performance

3. Measure token-level similarity between consecutive attempts in both single-agent Reflexion and MAR to empirically verify the "degeneration of thought" claim and demonstrate that MAR produces more diverse solution attempts