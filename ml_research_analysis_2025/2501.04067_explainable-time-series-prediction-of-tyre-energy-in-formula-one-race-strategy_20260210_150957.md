---
ver: rpa2
title: Explainable Time Series Prediction of Tyre Energy in Formula One Race Strategy
arxiv_id: '2501.04067'
source_url: https://arxiv.org/abs/2501.04067
tags:
- time
- tyre
- series
- data
- race
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors train multiple deep learning models, including RNNs,
  LSTMs, GRUs, and a Transformer-based Temporal Fusion Transformer, to forecast tyre
  energy in Formula One races using telemetry data. They also incorporate XGBoost
  and linear regression as baselines.
---

# Explainable Time Series Prediction of Tyre Energy in Formula One Race Strategy

## Quick Facts
- arXiv ID: 2501.04067
- Source URL: https://arxiv.org/abs/2501.04067
- Authors: Jamie Todd; Junqi Jiang; Aaron Russo; Steffen Winkler; Stuart Sale; Joseph McMillan; Antonio Rago
- Reference count: 29
- Primary result: XGBoost outperforms deep learning models for tyre energy forecasting; TFT generalizes better to unseen tracks

## Executive Summary
This paper presents a comprehensive study of deep learning and tree-based models for forecasting tyre energy in Formula One races using telemetry data. The authors evaluate multiple architectures including RNNs, LSTMs, GRUs, Temporal Fusion Transformers (TFT), XGBoost, and linear regression, training them to predict the next tyre energy values from past covariate data such as speed, steering angle, and throttle position. XGBoost achieves the lowest RMSE scores, while TFT shows superior adaptability to unseen tracks. The study also incorporates explainable AI methods (TIME for feature importance and CausalImpact for counterfactuals) to validate that model predictions align with domain knowledge, particularly showing steering angle as the most important feature.

## Method Summary
The authors train multiple deep learning models and XGBoost to forecast tyre energy in F1 races using telemetry data at 0.1s resolution from 2020-2023 seasons. Models take past covariate data (100-step sliding window of features like speed, steering angle, throttle, brake, gear, track temperature, etc.) as input and predict the next tyre energy values for all four tyres. The study compares four deep learning architectures (RNN, LSTM, GRU, TFT) against XGBoost and linear regression baselines. Track state encoding is tested using one-hot, exclude, ordered, and green-flag-only strategies. Hyperparameter tuning is performed via Ray Tune and Optuna, with evaluation metrics focusing on RMSE and SMAPE across seen and unseen tracks.

## Key Results
- XGBoost achieves the lowest RMSE (4.78) and outperforms all deep learning models in overall accuracy
- TFT adapts better to unseen tracks compared to GRU/LSTM models, showing superior generalization
- Feature importance rankings align with domain expectations, with steering angle identified as the most important variable
- XGBoost captures lap trends more closely but requires significantly more RAM (up to 1TB) than other models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gradient-boosted decision trees (XGBoost) outperform deep learning sequence models in raw accuracy for this specific telemetry-to-energy mapping task.
- **Mechanism:** XGBoost likely captures the complex non-linear interactions between instantaneous telemetry covariates (speed, steering angle) and the target energy without the overhead of learning temporal representations from a 100-step sliding window, which may introduce noise or optimization difficulties for the RNNs/Transformers on this tabular dataset.
- **Core assumption:** The primary predictive signal lies in the immediate feature interactions and short-term trends rather than long-term temporal dependencies requiring deep recurrent states.
- **Evidence anchors:**
  - [abstract] "XGBoost outperforming all others."
  - [section] "XGBoost outperformed all trained deep learning models by a considerable margin... XGBoost captures the trends of the lap far more closely."
  - [corpus] [24] "Studies have shown that Transformer-based models may not be as effective... with simple baselines outperforming the state-of-the-art."
- **Break condition:** If real-time inference latency becomes a hard constraint (XGBoost required "far more RAM" and rigid training) or if the relationship becomes strictly sequential over longer horizons.

### Mechanism 2
- **Claim:** The Temporal Fusion Transformer (TFT) exhibits superior adaptability to unseen tracks compared to GRU/LSTM models.
- **Mechanism:** The TFT's variable selection network and attention mechanisms allow it to generalize the physics of car dynamics (e.g., how steering affects energy) independent of specific track layouts, whereas GRU/LSTM models appear to overfit to the sequence of turns in the training tracks.
- **Core assumption:** The underlying physics relating telemetry to tyre energy are consistent across tracks, even if the sequence of inputs varies.
- **Evidence anchors:**
  - [abstract] "TFT adapts better to unseen tracks."
  - [section] "Green-flag TFT is significantly stronger for unseen events... GRU outperforms TFT for seen races."
  - [corpus] Weak direct evidence in neighbors; inferred from TFT architecture design [15] referenced in paper.
- **Break condition:** If a new track has fundamentally different surface characteristics or telemetry noise profiles not present in the "unseen" test set (e.g., wet races, which were excluded).

### Mechanism 3
- **Claim:** Explainable AI (XAI) methods align model behavior with physical intuition, validating that the models are learning domain-relevant features rather than spurious correlations.
- **Mechanism:** Perturbation-based importance (TIME) identifies that the model activates primarily on high-variance physical inputs like `SteeringWheelAngle`, which matches the physics-based definition of tyre energy (derived from forces/slip).
- **Core assumption:** The "ground truth" tyre energy values are accurate and consistently calculated from the physics model.
- **Evidence anchors:**
  - [abstract] "Feature importance rankings align with domain expectations (e.g., steering angle is most important)."
  - [section] "SteeringWheelAngle... is the most important variable... ranking of the variables is logical."
  - [corpus] "Explainable-AI powered stock price prediction" (neighbor) suggests XAI validation is a standard verification step in time series, though domain alignment is unique to this paper.
- **Break condition:** If the XAI methods (e.g., CausalImpact) are applied to events with low statistical power or high noise, leading to low confidence intervals (e.g., the "57.5%" probability cited for the safety car event).

## Foundational Learning

- **Concept: Past Covariates vs. Autoregression**
  - **Why needed here:** Unlike standard forecasting (e.g., stock prices), this task predicts *future* tyre energy using *only* past telemetry (covariates like speed/brake) and explicitly excludes past ground-truth energy values as inputs.
  - **Quick check question:** If you fed the model the tyre energy from $t-1$, would this still be a "covariate-only" problem?

- **Concept: Track State Encoding**
  - **Why needed here:** F1 races have non-continuous states (Safety Car, Red Flag). The paper tests four encoding strategies (one-hot, exclude, etc.) because these states fundamentally alter car behavior (dropping speed to 60% under Safety Car).
  - **Quick check question:** Why might filtering *out* non-green-flag data (the "Green-flag" encoding) improve generalization to unseen tracks?

- **Concept: Sliding Window Inference**
  - **Why needed here:** The models accept a window of 100 time steps (10 seconds) to predict the *next* single step. Understanding this context window is critical for structuring the input tensors.
  - **Quick check question:** If the sampling rate changed from 0.1s to 0.01s, how would you adjust the window size to maintain the same temporal context?

## Architecture Onboarding

- **Component map:** Input: Telemetry Tensor (Batch, 100 steps, Features) + Track State Encoding -> Backbone: TFT (Variable Selection + Attention) OR XGBoost (Flattened Window Features) -> Output: 4 Regression Heads (Front-Left, Front-Right, Rear-Left, Rear-Rear Energy) -> XAI Layer: TIME (Perturbation) or TFT Built-in Importance

- **Critical path:**
  1. Data Alignment: Merging serialised telemetry with tabular energy calculations at 0.1s resolution.
  2. Hyperparameter Search: Specifically tuning the "Track State Encoding" and "Gradient Clipping" (which varied wildly from 0.12 to 0.81).
  3. Evaluation: Split by "Seen" vs. "Unseen" tracks to test generalization, not just random shuffle.

- **Design tradeoffs:**
  - XGBoost: Best accuracy (RMSE ~4.78) but requires 1TB RAM and trains on the full set (not iterative).
  - TFT: Slightly lower accuracy (RMSE ~5.3) but generalizes better to unseen tracks and supports incremental updates.
  - STS (Single-Track Specialist): Overfits to one circuit; best for pre-race simulation but useless for live generalization.

- **Failure signatures:**
  - High SMAPE at corner exits/apexes (rapid energy changes).
  - Poor performance on Monaco (low degradation, unique layout).
  - XGBoost memory overflow on standard hardware.

- **First 3 experiments:**
  1. **Baseline Linear Regression:** Verify the problem is non-linear (Paper shows Linear RMSE ~7.9 vs XGBoost ~4.8).
  2. **Track Encoding Ablation:** Compare "One-Hot" vs. "Exclude" track state on the GRU/LSTM models to confirm sensitivity to race conditions.
  3. **Unseen Track Test:** Train on 2020-2022 data, test on a 2023 street circuit (e.g., Miami) to verify TFT vs. GRU generalization gap.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the models be optimized for low-latency inference on live telemetry streams during a race?
- **Basis in paper:** [explicit] The authors state, "Enhancing our models to process real-time data and compute predictions on the fly will extend their use to live races."
- **Why unresolved:** The current implementation is limited to post-race analysis due to iterative processing requirements, and the best-performing model (XGBoost) required massive RAM (up to 1024 GB), which may be prohibitive for real-time trackside hardware.
- **What evidence would resolve it:** Successful deployment of the model in a live testing environment or benchmarks demonstrating inference latency lower than the 0.1s data resolution.

### Open Question 2
- **Question:** Do the generated explanations (feature importance and counterfactuals) effectively increase race strategists' trust and decision-making quality?
- **Basis in paper:** [explicit] The authors propose "user studies with race strategists to determine their effectiveness along typical XAI properties such as faithfulness... and trust."
- **Why unresolved:** While the paper validates that the explanations align with domain knowledge (e.g., steering angle importance), it does not empirically validate if these explanations actually help human strategists make better decisions.
- **What evidence would resolve it:** Results from user studies measuring strategy adjustment accuracy and self-reported trust levels when strategists utilize the XAI tools.

### Open Question 3
- **Question:** Which specific covariates or additional data sources (e.g., practice sessions) most significantly improve forecasting accuracy?
- **Basis in paper:** [explicit] The authors note future work involves "reconsidering which covariates could be added or removed" and "extending the modelsâ€™ capabilities to handle practice and qualifying session data."
- **Why unresolved:** The study evaluated a fixed set of telemetry inputs but did not perform ablation studies to identify redundant features or assess the marginal value of adding session types outside of grand prix races.
- **What evidence would resolve it:** Ablation study results showing RMSE changes with specific feature removal, or performance comparisons after augmenting the training set with practice/qualifying data.

## Limitations
- Data pipeline opacity: Exact tyre energy computation from raw telemetry and feature scaling procedures are not fully disclosed
- XGBoost deployment barriers: Requires 1TB RAM and rigid full-dataset training approach
- Limited safety car validation: Green-flag encoding strategy lacks validation on actual interrupted race conditions
- Low confidence XAI results: 57.5% probability for safety car counterfactual suggests insufficient statistical power

## Confidence
- **High confidence**: XGBoost achieves the lowest overall RMSE (4.78), and feature importance rankings align with domain expectations (steering angle as primary predictor). The generalization advantage of TFT on unseen tracks is consistently observed.
- **Medium confidence**: The mechanism explaining TFT's superior generalization (variable selection and attention networks) is architecturally sound but lacks direct empirical validation in this paper. The claim that RNNs overfit to training track sequences is inferred from performance gaps rather than explicitly tested.
- **Low confidence**: The effectiveness of CausalImpact counterfactual explanations for the safety car event (57.5% probability) suggests insufficient statistical power or high noise in the intervention analysis.

## Next Checks
1. **Data pipeline verification**: Reconstruct the tyre energy calculation from raw telemetry and verify the feature scaling approach used in the original experiments.
2. **Green-flag encoding robustness**: Test the Green-flag encoding strategy on a race with actual safety car deployment to validate generalization claims under realistic interrupted conditions.
3. **Cross-track generalization stress test**: Train models on 2020-2022 data and evaluate on a 2023 street circuit (e.g., Las Vegas) to confirm whether TFT maintains its generalization advantage over GRU/LSTM in a novel track environment.