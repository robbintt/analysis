---
ver: rpa2
title: 'The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation'
arxiv_id: '2511.12804'
source_url: https://arxiv.org/abs/2511.12804
tags:
- alignment
- owner
- public
- preferences
- curation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a formal framework for analyzing long-term\
  \ alignment dynamics in recursive generative AI systems. It models the interaction\
  \ between two curators\u2014a Model Owner and Public User\u2014using a Bradley-Terry-based\
  \ two-stage curation mechanism."
---

# The Alignment Game: A Theory of Long-Horizon Alignment Through Recursive Curation

## Quick Facts
- **arXiv ID**: 2511.12804
- **Source URL**: https://arxiv.org/abs/2511.12804
- **Reference count**: 3
- **One-line primary result**: Formal framework analyzing recursive curation dynamics reveals three convergence regimes and proves fundamental impossibility theorem about diversity preservation.

## Executive Summary
This paper introduces a formal framework for analyzing long-term alignment dynamics in recursive generative AI systems. It models the interaction between two curators—a Model Owner and Public User—using a Bradley-Terry-based two-stage curation mechanism. The analysis reveals three convergence regimes (consensus collapse, compromise on shared optima, and asymmetric refinement) and proves a fundamental impossibility theorem showing that no recursive BT-based curation can simultaneously preserve diversity, ensure symmetric influence, and eliminate initialization dependence. Experiments on synthetic and text-based alignment games validate the theoretical predictions, demonstrating exponential convergence with shrinking support across all scenarios.

## Method Summary
The method implements a two-stage recursive curation process using Bradley-Terry selection weights. In each iteration, the Model Owner curates a pool of K samples using their reward function, the model is updated to approximate this curated distribution, then the Public User curates from the updated model using their reward function with pool size M. This process repeats with dataset accumulation. The framework is tested on synthetic R² spaces with circular reward regions and on text data using GPT-2 models, tracking convergence metrics across 100 iterations (synthetic) or ~20 iterations (text).

## Key Results
- Three distinct convergence regimes identified: consensus collapse (perfect alignment), compromise on shared optima (partial alignment), and asymmetric refinement (disjoint alignment)
- Exponential convergence proven across all regimes with explicit bounds
- Fundamental impossibility theorem showing trade-off between diversity preservation, symmetric influence, and initialization independence
- First-mover advantage established: Owner determines feasible support, Public refines within constraints

## Why This Works (Mechanism)

### Mechanism 1: BT-Weight Amplification Drives Exponential Convergence
- Claim: The Bradley-Terry selection weight H^p_{K,r}(x) causes exponential decay of probability mass outside curator-optimal regions, regardless of alignment regime.
- Mechanism: At each iteration, the BT weight multiplies the current distribution by a term proportional to E[exp(r(x)) / (exp(r(x)) + Σexp(r(Y_j)))]. Content with lower reward survives with probability that shrinks geometrically across rounds. This compounds into exponential suppression p_t(X \ B_η(A)) ≤ Ce^{-ct}.
- Core assumption: The idealized dynamics p_{t+1} ≈ p̃_t hold (minimal optimization error, no catastrophic forgetting).
- Evidence anchors:
  - [abstract] "demonstrating exponential convergence with shrinking support across all scenarios"
  - [Theorems 1, 3, 4] Provide explicit exponential bounds for all three alignment regimes
  - [corpus] Weak direct validation; related work (Ferbach et al. 2024, Shumailov et al. 2023) documents collapse in recursive training but not specifically BT-driven mechanisms
- Break condition: If pool size K=1, BT-weight collapses to deterministic selection; if optimization error dominates (p_{t+1} far from p̃_t), convergence rate predictions become unreliable.

### Mechanism 2: Sequential Curation Creates Structural First-Mover Advantage
- Claim: The Owner's position first in the curation sequence determines the feasible support; the Public can only refine within Owner-imposed constraints.
- Mechanism: Owner curation selects from full distribution p_t using r_O, producing p̃_t concentrated near A_O. Model training makes p_{t+1} ≈ p̃_t. Public curation then selects from p_{t+1} using r_P, but content outside A_O has already been suppressed. In disjoint alignment, this yields A_{P|O} = argmax_{x∈A_O} r_P(x)—the "best of the worst."
- Core assumption: Two-stage sequence is fixed; no mechanism for Public to influence Owner's selection criteria.
- Evidence anchors:
  - [Theorem 4] "Owner determines the support while the Public refines within it" with two-stage exponential suppression proof
  - [Disjoint Alignment section] "Owner's first-mover advantage allows it to determine the feasible region"
  - [corpus] No direct validation; corpus lacks sequential multi-agent curation work
- Break condition: If Public curation occurs before Owner curation, advantage reverses. If pool sizes differ dramatically (K >> M or M >> K), influence balance may shift.

### Mechanism 3: Consensus Collapse Through Intersection Filtering
- Claim: In partial alignment, only the intersection of curator optima survives; curator-specific content is exponentially suppressed even when individually valued.
- Mechanism: Each curation stage applies its BT-weight independently. Content in A_O \ A_P survives Owner curation but is suppressed by Public curation. Content in A_P \ A_O survives Public curation but has already been suppressed by Owner curation. Only A_shared = A_O ∩ A_P passes both filters repeatedly.
- Core assumption: Both curators apply BT selection consistently; no content receives protected status.
- Evidence anchors:
  - [Theorem 3] "only the intersection survives" with formal statement
  - [Figure 2, Partial Alignment panel] Shows satisfaction rates converging only within overlap region
  - [corpus] Weak; "The Burden of Interactive Alignment" (arXiv:2510.16368) addresses inconsistent preferences but not recursive filtering specifically
- Break condition: If one curator's BT selection is softened (e.g., temperature → ∞), intersection constraint weakens. If curators have veto power rather than probabilistic selection, dynamics differ.

## Foundational Learning

- **Bradley-Terry Model for Preference Aggregation**
  - Why needed here: The entire framework builds on BT pairwise comparison; understanding how exp(r(x)) / Σexp(r(Y_j)) converts rewards to selection probabilities is essential.
  - Quick check question: Given two items with rewards r(A)=2, r(B)=1, what is P(A preferred over B) under the BT model?

- **Weak Convergence of Probability Measures**
  - Why needed here: Theorems describe convergence using weak limits (p_t → p_∞ weakly); distinguishing this from pointwise or strong convergence matters for interpreting "collapse."
  - Quick check question: If p_t converges weakly to δ_{x*}, what happens to the variance of samples from p_t as t → ∞?

- **Social Choice Theory Fundamentals (Arrow's Theorem, Strategyproofness)**
  - Why needed here: The impossibility theorem (Theorem 5) and strategyproofness result (Theorem 6) connect to classic social choice; framing alignment as voting clarifies why "fair" aggregation is structurally hard.
  - Quick check question: In a voting system, what does "strategyproofness" mean, and why is sequential voting typically not strategyproof?

## Architecture Onboarding

- **Component map:** Initial Distribution p_0 -> Owner BT Curation -> Curated Distribution p̃_t -> Model Training -> Public BT Curation -> Final Distribution p̂_t -> Dataset Update: D_{t+1} = D_t ∪ samples from p̂_t -> (loop)

- **Critical path:** Owner curation → model update → Public curation. The Owner's BT-weight determines what enters training; the Public's BT-weight determines what persists. Both multiply; neither undoes.

- **Design tradeoffs:**
  - Pool sizes (K, M): Larger pools increase selection pressure (faster convergence, faster diversity loss)
  - Temperature in BT: Higher temperature softens selection, preserving diversity but slowing alignment
  - Data accumulation vs. replacement: Paper references (Gerstgrasser et al. 2024) showing accumulation mitigates collapse—consider hybrid schemes

- **Failure signatures:**
  - Mode collapse: Variance of generated content → 0 within ~20-50 iterations; check via entropy or unique-ngram rate
  - Intersection-only survival: Content valued by one curator but not both vanishes; monitor per-curator "satisfaction" metrics
  - Path dependence: Different p_0 produce different p_∞; test by rerunning with shuffled initialization

- **First 3 experiments:**
  1. **Replicate synthetic R² experiment with your own reward functions.** Define circular or Gaussian reward regions for Owner/Public, run 100 iterations, plot KDE of final distribution. Validate that intersection emerges in partial alignment.
  2. **Measure convergence rate vs. pool size.** Vary K∈{10, 50, 100, 500} while holding other parameters fixed. Confirm exponential decay rate c scales with K (larger pools → faster convergence).
  3. **Test initialization dependence.** Run the same alignment game with three different p_0 (uniform, concentrated near A_O, concentrated near A_P). Report whether p_∞ differs in each case—this directly probes the impossibility theorem's "initial distribution independence" criterion.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the identified convergence regimes (consensus collapse, compromise, asymmetric refinement) change when scaling from two agents to an n-agent ecosystem with heterogeneous preferences?
- Basis in paper: [explicit] The authors state, "The next step is to model this as an n-agent game with heterogeneous agents."
- Why unresolved: The current theory strictly covers a two-faction dyadic interaction (Owner vs. Public), whereas multi-agent systems introduce complex coalition dynamics and potential new instability modes not present in the simplified model.
- What evidence would resolve it: A formal characterization of n-agent alignment games showing whether "consensus collapse" persists or fragments into coalition-based outcomes.

### Open Question 2
- Question: Does the impossibility theorem (trading off diversity, symmetry, and independence) hold when agent preferences are endogenous and evolve based on the model's previous outputs?
- Basis in paper: [explicit] The paper requests future research to "explore this co-evolutionary dynamic, where the outputs of one generation's model actively shape the preferences of the agents who curate the next."
- Why unresolved: The current theoretical proofs rely on the assumption of static reward functions $r_O, r_P$; relaxing this assumption to allow co-evolution breaks the fixed-point analysis used in the theorems.
- What evidence would resolve it: Convergence analysis of recursive games where reward functions are updated via feedback loops, specifically testing if dynamic preferences mitigate or accelerate diversity loss.

### Open Question 3
- Question: Can recursive curation mechanisms based on non-Bradley-Terry preference models circumvent the structural trade-offs between diversity and symmetric influence?
- Basis in paper: [explicit] The authors note, "Future work must extend this analysis to more complex preference models" beyond the BT model.
- Why unresolved: The impossibility theorem is derived specifically from the mathematical properties of the BT model; it is unknown if alternative preference representations (e.g., handling intransitive preferences) avoid these specific trilemmas.
- What evidence would resolve it: Theoretical proofs or empirical validation using alternative preference models (e.g., classification-based or multi-dimensional) that demonstrate the simultaneous preservation of diversity and symmetric influence.

## Limitations

- Theoretical framework validated primarily on simplified reward landscapes (circular Gaussians in synthetic space, coarse-grained text metrics)
- Model update step abstracted as black box; GMM and GPT-2 fine-tuning generalization behavior could alter convergence predictions
- Impossibility theorem proven under idealized BT dynamics; real-world curation noise, feedback delays, or multi-modal preferences may break assumptions

## Confidence

- **High confidence**: Mechanism 1 (BT-weight amplification driving exponential convergence) — backed by formal theorems and explicit exponential bounds
- **Medium confidence**: Mechanism 2 (first-mover advantage) and Mechanism 3 (consensus collapse) — derived from theorems but lack direct empirical isolation; supported by synthetic plots but not rigorously tested under perturbed conditions
- **Medium confidence**: Impossibility theorem — mathematically sound, but real-world violations may arise from bounded rationality, non-BT curation rules, or adaptive temperature schedules

## Next Checks

1. **Perturbation robustness test**: Add Gaussian noise (σ=0.1) to BT selection probabilities and rerun synthetic alignment games. Measure whether exponential convergence rate degrades or regimes shift—this tests the fragility of the idealized dynamics.

2. **Multi-modal preference test**: Define two disjoint reward regions for each curator (e.g., two circles for Owner, two for Public). Run the game and check whether the intersection filter still applies or if the system can preserve multiple optima—this probes whether the impossibility theorem holds under richer preference structures.

3. **Asymmetric curation test**: Swap the curation order (Public first, then Owner) in the disjoint alignment scenario. Track final distribution support and compare with original—this directly tests the "first-mover advantage" claim and its reversibility.