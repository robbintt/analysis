---
ver: rpa2
title: 'ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding
  Language Models'
arxiv_id: '2601.18796'
source_url: https://arxiv.org/abs/2601.18796
tags:
- embedding
- abstract
- embeddings
- training
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Embedding Language Models (ELMs) align large language models to
  embedding spaces, enabling text generation from arbitrary embeddings. This work
  develops an open-source ELM architecture and training framework, training ctELM
  to interpret clinical trial embeddings.
---

# ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models

## Quick Facts
- **arXiv ID:** 2601.18796
- **Source URL:** https://arxiv.org/abs/2601.18796
- **Reference count:** 40
- **Key outcome:** Embedding Language Models (ELMs) align large language models to embedding spaces, enabling text generation from arbitrary embeddings. This work develops an open-source ELM architecture and training framework, training ctELM to interpret clinical trial embeddings. ctELM achieves up to 0.87 Semantic Consistency for reconstructing abstracts and 0.89 for comparing trials, outperforming Vec2Text baselines. Generated abstracts from novel (interpolated) embeddings fool human experts 44% of the time. ctELM outputs are also responsive to Concept Activation Vectors representing trial subject sex and age, demonstrating controlled generation along clinically meaningful directions.

## Executive Summary
ctELM introduces an open-source Embedding Language Model (ELM) architecture that decodes and manipulates clinical trial embeddings into coherent text. By training a 2-layer MLP adapter to project external embeddings into a frozen LLM's token space, ctELM generates abstracts, sections, and plain language summaries from embeddings alone. The model achieves high Semantic Consistency (up to 0.87) and can generate plausible content for interpolated embeddings, fooling human experts 44% of the time. Additionally, ctELM demonstrates controlled generation along clinically meaningful directions using Concept Activation Vectors for age and sex, enabling semantic manipulation of trial descriptions.

## Method Summary
ctELM uses a frozen LLM (Llama-3.1-8B-Instruct) with a trainable 2-layer MLP adapter to project clinical trial embeddings (from bge-large-en-v1.5) into the token embedding space. The adapter enables next-token prediction conditioned on embeddings, trained via multi-task learning (reconstruction, comparison, summarization) on PubMedRCT abstracts. Training uses LoRA adapters and negative log-likelihood loss, with performance evaluated via Semantic Consistency and human expert validation.

## Key Results
- Semantic Consistency up to 0.87 for abstract reconstruction and 0.89 for trial comparisons
- 44% human expert acceptance rate for generated abstracts from interpolated embeddings
- Concept Activation Vectors successfully control generated content for age and sex attributes
- Outperforms Vec2Text baseline (0.66 SC) on embedding-to-text tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A learned MLP adapter can project external embeddings into the token embedding space of a frozen LLM, enabling conditional generation from dense vectors.
- **Mechanism:** The adapter A transforms embeddings Z_emb → Z_base via W₁(σ(W₀Z_emb + b₀)) + b₁, allowing the transformer to attend to embedding-derived "pseudo-tokens" alongside real tokens. Gradients from next-token prediction shape A to preserve semantic content while aligning to the LLM's representational geometry.
- **Core assumption:** The LLM's token embedding space is sufficiently expressive to represent arbitrary document semantics, not just tokenizable content.
- **Evidence anchors:**
  - [abstract] "ELMs extend language models by adding an adapter layer that aligns an embedding space of interest to the model's own token embedding space"
  - [section 3.2] "The adapter ensures that the embeddings Z_emb produced by the external embedding model E_emb are projected into the embedding space Z_base"
  - [corpus] Related work on embedding inversion (Vec2Text) uses similar projection strategies but iteratively; corpus evidence for single-pass adapter efficacy is sparse outside Tennenholtz et al. 2024.
- **Break condition:** If the embedding model encodes information orthogonal to the LLM's pretraining distribution (e.g., highly specialized visual or acoustic features), the adapter may fail to find a meaningful mapping.

### Mechanism 2
- **Claim:** Multi-task training on embedding-conditioned objectives (reconstruction, comparison, summarization) improves robustness to novel embeddings more than single-task inversion.
- **Mechanism:** Diverse tasks force the model to extract different aspects of the embedding's semantic content, creating redundant pathways for interpretation. This regularizes against overfitting to reconstruction patterns specific to training documents.
- **Core assumption:** Embeddings encode disentangleable semantic attributes that can be independently queried.
- **Evidence anchors:**
  - [abstract] "can accurately describe and compare unseen clinical trials from embeddings alone"
  - [section 4.5/Table 2] "Increasing the number of tasks does not degrade performance on individual tasks despite fewer training samples per task"
  - [corpus] Multi-task learning for text embeddings has limited direct precedent; corpus does not provide strong comparative evidence.
- **Break condition:** If tasks require contradictory representations (e.g., one task rewards detail, another rewards abstraction), performance may plateau or degrade across all tasks.

### Mechanism 3
- **Claim:** Linear directions in the embedding space identified by Concept Activation Vectors (CAVs) can be added to embeddings to control generated content along semantic axes.
- **Mechanism:** A linear classifier (SVM) separates embeddings by a concept (e.g., male vs. female subjects); the vector orthogonal to the decision plane is added to embeddings with coefficient α. The adapter preserves this directional structure, so modified embeddings decode to concept-shifted text.
- **Core assumption:** Embedding spaces are approximately linear with respect to high-level semantic attributes.
- **Evidence anchors:**
  - [abstract] "generated abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects"
  - [section 5.2/Figures 2-3] "Modification successfully changes subject demographics along the expected axes... Both CAVs can even induce intermediate values"
  - [corpus] Bolukbasi et al. 2016 demonstrated linear gender axes in word embeddings; extension to document embeddings is plausible but not extensively validated in corpus.
- **Break condition:** If concepts are nonlinearly entangled (e.g., sex and age co-vary with disease type), linear CAVs may produce incoherent or contradictory outputs.

## Foundational Learning

- **Concept: Text embeddings as fixed-length semantic representations**
  - Why needed here: ctELM operates on pre-computed embeddings; understanding that embeddings compress variable-length documents into dense vectors is prerequisite to grasping why inversion is non-trivial.
  - Quick check question: Given two similar documents, would you expect their embeddings to have high cosine similarity? Why might reconstruction still be difficult?

- **Concept: Next-token prediction with mixed modalities**
  - Why needed here: ctELM trains via standard language modeling loss, but inputs contain both text tokens and projected embeddings. Understanding how attention mechanisms integrate these is essential.
  - Quick check question: If an embedding replaces the first token position, how does the self-attention mechanism access its information at later positions?

- **Concept: Linear separability in high-dimensional spaces**
  - Why needed here: CAVs assume concepts correspond to linear directions. Understanding why high-dimensional spaces often permit linear separation helps evaluate when this approach will succeed.
  - Quick check question: In a 1024-dimensional embedding space, is a binary classification problem more or less likely to be linearly separable than in 10 dimensions? What risks does this introduce?

## Architecture Onboarding

- **Component map:** Embedding Model (E_emb: frozen) → Document → Embedding (z ∈ R^1024) → Adapter MLP (2-layer, trainable) → Projected Embedding (z' ∈ R^4096) → Base LLM (M_base: frozen weights + LoRA adapters) → Generated Text

- **Critical path:**
  1. Pre-compute embeddings for all training documents using frozen E_emb
  2. Initialize adapter A with random weights
  3. Format training instances as prompt + embedded representation → target output
  4. Train using negative log-likelihood, updating A and LoRA parameters only
  5. For inference: embed document (or interpolate/perturb), pass through A, concatenate with task prompt

- **Design tradeoffs:**
  - One-phase vs. two-phase training: 1P is faster (~13h on H100 for 1.2M samples) and competitive; 2P may help on smaller data but doubles training time
  - Embedding model choice: Domain-specific models (PubMedBERT) underperformed general models (bge-large) in experiments, possibly due to fewer parameters/dimensions
  - Repetition penalty: 1.2 improves emb2abs coherence but may reduce fluency for other tasks

- **Failure signatures:**
  - Repetitive generation (loops, "S-s-s-s..."): Reduce temperature or increase repetition penalty
  - Low semantic consistency (<0.70): Check embedding model compatibility; verify adapter dimensionality matches base LLM
  - CAV edits produce incoherent text: Concept may be nonlinearly entangled; try smaller α values or nonlinear manifold methods
  - Generated abstracts fail plausibility test: May indicate training data distribution shift; check for domain mismatch

- **First 3 experiments:**
  1. **Baseline sanity check:** Train 1-task model (emb2abs only) on 10K samples; verify SC > 0.75 on held-out set. If lower, debug adapter architecture or embedding pipeline.
  2. **Interpolation robustness test:** Generate 50 interpolated embeddings from test pairs; compute SC against original abstracts. Expect ~0.02-0.04 drop from non-interpolated performance.
  3. **CAV validation:** Train sex CAV, apply with α ∈ {-1, -0.5, 0.5, 1}, use extraction agent to verify subject sex changes. If <70% success rate, investigate data collection for CAV training or try nonlinear probes.

## Open Questions the Paper Calls Out

- **Question:** To what extent do ELMs trained on clinical trial abstracts generalize to other biomedical text formats?
- **Basis in paper:** [Explicit] The authors state in the Limitations that because ELMs train to specific data manifolds, "it is not clear how well ctELM would generalize to other data from the biomedical domain (such as full articles or clinical notes)."
- **Why unresolved:** The current study focused exclusively on structured abstracts from PubMedRCT, leaving the model's performance on longer, unstructured, or distinct clinical documentation untested.
- **What evidence would resolve it:** Zero-shot or fine-tuning performance metrics (Semantic Consistency) of ctELM on datasets of full-text articles and electronic health record (EHR) notes.

## Limitations
- **Embedding Injection Mechanism:** The exact method for incorporating dense embeddings into the LLM's token stream remains underspecified, representing a critical implementation gap.
- **Domain Transfer Generalizability:** Model performance on other embedding types or domains is unclear, with domain-specific models underperforming general models.
- **Concept Activation Vector Limitations:** Linear CAV approach may fail for complex, nonlinearly entangled concepts, potentially producing incoherent outputs.

## Confidence
- **High Confidence:**
  - ELM architecture with adapter MLP can project embeddings to token space and enable conditional generation
  - Multi-task training improves robustness to novel embeddings compared to single-task inversion
  - CAV directions in embedding space can control generated content along semantic axes
- **Medium Confidence:**
  - ctELM outperforms Vec2Text baselines (0.87 vs 0.66 SC for emb2abs)
  - Generated abstracts from interpolated embeddings achieve 44% human expert acceptance
  - Clinical trial embeddings support linear CAV manipulation for age and sex concepts
- **Low Confidence:**
  - Claims about generalizability to other embedding types or domains
  - Performance consistency across different embedding model choices
  - Long-term stability and robustness of generated clinical content

## Next Checks
1. **Embedding Injection Format Validation:** Implement and test multiple embedding injection methods (special tokens, direct token replacement, prefix encoding) to determine which approach yields optimal Semantic Consistency. Compare performance across injection strategies on a held-out validation set.

2. **Nonlinear Concept Probe Evaluation:** Develop and test nonlinear concept probes (e.g., small MLPs, manifold learning) alongside linear CAVs to identify when concepts are linearly separable. Apply to age and sex concepts to quantify performance differences and failure modes.

3. **Cross-Domain Embedding Transfer:** Train ctELM on clinical trial embeddings, then evaluate performance on embeddings from other domains (news articles, scientific papers, patents). Measure Semantic Consistency drop and analyze failure patterns to assess domain transferability limits.