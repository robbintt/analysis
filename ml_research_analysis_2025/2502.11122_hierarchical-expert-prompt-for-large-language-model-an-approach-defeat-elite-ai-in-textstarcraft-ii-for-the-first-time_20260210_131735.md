---
ver: rpa2
title: 'Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite
  AI in TextStarCraft II for the First Time'
arxiv_id: '2502.11122'
source_url: https://arxiv.org/abs/2502.11122
tags:
- supply
- game
- time
- nexus
- build
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces Hierarchical Expert Prompt (HEP), a method
  that integrates expert-level tactical knowledge into large language models (LLMs)
  to improve decision-making in the complex StarCraft II environment. HEP combines
  two key components: the Expert Tactic Prompt (ETP), which injects tactical knowledge
  into the model, and the Hierarchical Decision Prompt (HDP), which organizes decision-making
  into a priority-based framework.'
---

# Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite AI in TextStarCraft II for the First Time

## Quick Facts
- **arXiv ID:** 2502.11122
- **Source URL:** https://arxiv.org/abs/2502.11122
- **Reference count:** 40
- **Primary result:** HEP achieves 75% win rate vs VeryHard and defeats Elite AI for first time in TextStarCraft II

## Executive Summary
The paper introduces Hierarchical Expert Prompt (HEP), a method that integrates expert-level tactical knowledge into large language models (LLMs) to improve decision-making in the complex StarCraft II environment. HEP combines two key components: the Expert Tactic Prompt (ETP), which injects tactical knowledge into the model, and the Hierarchical Decision Prompt (HDP), which organizes decision-making into a priority-based framework. This approach enables the LLM to better understand game situations and handle tasks of varying importance. Experiments demonstrate that HEP significantly improves the LLM's performance, achieving a 75% win rate against VeryHard opponents and defeating Elite AI for the first time in TextStarCraft II. The method consistently outperformed baseline approaches across all tested difficulty levels while maintaining reasonable computational costs.

## Method Summary
HEP combines Expert Tactic Prompt (ETP) and Hierarchical Decision Prompt (HDP) to enhance LLM decision-making in TextStarCraft II. ETP injects structured expert knowledge through predefined tactical schemas (Name, Key Buildings, Key Timing), while HDP enforces a priority queue for macro-economic expansion over routine unit production. The system prompt concatenates role instructions, ETP tactics, HDP logic, legal action library, and game observations. The LLM outputs structured text responses following a data extraction → priority check → decision flow. GPT-3.5 backend with few-shot examples interprets game state and generates macro-level build commands, while micro-operations remain scripted.

## Key Results
- HEP achieved 75% win rate against VeryHard difficulty AI opponents
- First successful defeat of Elite-level AI by an LLM in TextStarCraft II
- Consistently outperformed baseline approaches across all tested difficulty levels

## Why This Works (Mechanism)

### Mechanism 1
Injecting structured expert heuristics (ETP) compensates for the LLM's lack of domain-specific "muscle memory" regarding build orders and technology trees. The system prompt defines a standardized "Expert Tactic" schema (Name, Key Buildings, Key Timing). This forces the LLM to map the current game state to a high-level strategy (e.g., "Carrier tactic") before generating granular actions, effectively constraining the decision space to viable expert trajectories.

### Mechanism 2
Hierarchical Decision Prompting (HDP) resolves resource contention by enforcing a strict priority queue for macro-economic expansion over routine unit production. The prompt creates a "Priority" class (Nexus/Assimilator) and a "Routine" class. It implements a logic gate: *If Priority task exists, suppress Routine tasks (except Probes/Pylons).* This prevents the LLM from spending resources on low-impact units when critical infrastructure is missing.

### Mechanism 3
Enforced data extraction and ordered reasoning (Chain of Summary + Extraction) reduces hallucination by grounding the LLM's context window in numerical facts. The prompt instructs the model to explicitly list relevant data (e.g., "Worker supply: 21") *before* generating analysis. This forces the attention mechanism to attend to specific tokens in the observation, preventing the model from acting on "prior" expectations or example text.

## Foundational Learning

- **StarCraft II Macro-Economics (BO/Macros)**: Understanding build orders and timing windows is essential because HEP's priority logic assumes Nexus and Assimilators are structural prerequisites for late-game units.
  - *Quick check:* Why does the prompt forbid building an Assimilator before the 25th worker?

- **Prompt Engineering (Chain of Thought vs. Hierarchical)**: HEP moves beyond simple CoT to hierarchical control flow (check priority -> branch A or B). Distinguishing "reasoning" from "control flow" is essential.
  - *Quick check:* How does HDP differ from standard Chain-of-Thought prompting in terms of action suppression?

- **TextStarCraft II Environment**: The architecture separates macro decisions (LLM) from micro-operations (scripted). The LLM only outputs text. You must understand that the LLM does not control the units directly, only the high-level build queue.
  - *Quick check:* Does the LLM control the aiming of the Carriers, or just the decision to build them?

## Architecture Onboarding

- **Component map:** Environment (TextStarCraft II) -> Controller (Python Loop) -> Brain (LLM via API) -> Prompt Assembler (concatenates Role + ETP + HDP + Legal Action Library + Observation) -> Parser (extracts ACTION tags)

- **Critical path:** 1. Observation: `Env.get_obs()` generates L1 summary text 2. Prompting: `Get_HEP_message()` constructs system prompt 3. Inference: LLM generates text following HEP structure 4. Execution: Parser identifies `<BUILD NEXUS>` tags; environment executes

- **Design tradeoffs:** HEP increases token usage by ~36% due to large system prompts and forced data extraction steps. The strict HDP logic prevents flexible resource dumping, which might be suboptimal in niche scenarios requiring partial spending.

- **Failure signatures:** Hallucination Loop (outputs "At 01:59" when game time is actually 05:00), Resource Float (gas/mins max out while army supply is 0), Invalid Actions (outputs `<BUILD CARRIER>` without prerequisite Fleet Beacon).

- **First 3 experiments:**
  1. Sanity Check: Run `CoS` (Chain of Summary) vs `HEP` on `Harder` difficulty. Verify HEP win rate >50%.
  2. Ablation 1 (No HDP): Remove "Priority" analysis block. Plot "Estimated Total Gas Amount" curve. Verify it matches "w/o Priority" curve in Fig 8b.
  3. Tactic Switch Test: Force game time >8 mins. Check `Current Tactic` field in LLM output to see if it switches from "Zealot & Stalker" to "Carrier".

## Open Questions the Paper Calls Out

### Open Question 1
How does HEP performance and latency scale when the expert tactic database is expanded significantly?
- Basis: Appendix A.1.1 states it's possible to add more tactics.
- Why unresolved: Only two tactics were tested; impact of larger knowledge base unmeasured.
- What would resolve it: Evaluation with 10+ diverse strategies.

### Open Question 2
Can HEP generalize to non-Protoss races (Terran or Zerg) without architectural modifications?
- Basis: Section 4.1 explicitly states agents played Protoss vs Zerg using Protoss-specific rules.
- Why unresolved: Hard-coded Protoss mechanics leave adaptability to different economic structures untested.
- What would resolve it: Successful application in Terran vs. Protoss or Zerg vs. Terran matchups.

### Open Question 3
Is HEP effective in environments requiring high-frequency micro-management rather than automated abstraction?
- Basis: Section 2.1 notes TextStarCraft II "liberates LLM from high-speed micro-operations by handing over these operations automatically."
- Why unresolved: Method relies on macro-focused text abstraction; unclear if LLMs can handle granularity and speed for direct unit control.
- What would resolve it: Testing in full SC2LE where LLM must output micro-level commands.

## Limitations
- HEP increases token usage by ~36% compared to baseline methods
- Strict HDP logic may prevent optimal resource allocation in niche scenarios requiring partial spending
- Expert tactics and decision logic are hard-coded for Protoss race, limiting generalization to other races

## Confidence
High: Win rates vs AI (75% vs VeryHard), first Elite AI defeat claim, ablation study showing HDP/ETP importance
Medium: Token usage increase claim (Table 2), effectiveness of data extraction in reducing hallucination (Appendix C.2)
Low: Scalability with expanded tactic database (only tested with 2 tactics), generalization to non-Protoss races (only tested with Protoss), performance in high-frequency micro environments (method abstracts micro-operations)

## Next Checks
1. Verify HEP achieves >50% win rate against Harder difficulty as baseline comparison
2. Run ablation test without HDP and confirm gas collection curve matches Figure 8b
3. Check tactic switching by forcing game time >8 minutes and observing Current Tactic field output