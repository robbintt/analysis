---
ver: rpa2
title: 'Representation-Aware Unlearning via Activation Signatures: From Suppression
  to Knowledge-Signature Erasure'
arxiv_id: '2601.10566'
source_url: https://arxiv.org/abs/2601.10566
tags:
- erasure
- knowledge
- unlearning
- arxiv
- type
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of selective knowledge erasure
  from large language models (LLMs), a critical requirement for GDPR compliance and
  model safety. The core problem is that current unlearning methods often conflate
  behavioral suppression with true knowledge removal, allowing latent capabilities
  to persist beneath surface-level refusals.
---

# Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure

## Quick Facts
- arXiv ID: 2601.10566
- Source URL: https://arxiv.org/abs/2601.10566
- Reference count: 36
- Primary result: Achieves near-oracle erasure (FQ ≈ 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), breaking the stability-erasure tradeoff

## Executive Summary
This paper introduces the Knowledge Immunization Framework (KIF), a representation-aware architecture that achieves true knowledge erasure from LLMs by targeting internal activation signatures rather than surface outputs. Unlike prior methods that achieve only behavioral suppression, KIF combines dynamic suppression of subject-specific representations with parameter-efficient adaptation to enable durable unlearning without full model retraining. The framework addresses GDPR compliance and model safety requirements by operationalizing the distinction between obfuscation and true erasure through a comprehensive dual-metric evaluation protocol.

## Method Summary
KIF implements a three-stage pipeline: (1) activation-signature extraction using contrastive analysis between on-topic activations and synthetic Gaussian noise to identify linearly separable signature directions in mid-to-late MLP layers; (2) Knowledge Suppression Capsules that apply rank-one geometric constraints to attenuate activations along signature directions while preserving orthogonal information; (3) a Self-Healing Loop that distills behavioral suppression and representation-level attenuation into a global LoRA adapter through a composite loss function combining DPO, factual unlikelihood, name-token unlikelihood, KL divergence, and EWC regularization.

## Key Results
- Achieves Type I erasure (FQ ≈ 0.99) across both standard foundation models (Llama & Mistral) and reasoning-prior models (Qwen & DeepSeek) spanning 3B to 14B parameters
- Breaks the stability-erasure tradeoff by preserving utility at oracle levels (MU = 0.62) with minimal drift (<1% on 6/8 benchmarks)
- Reveals fundamental architectural divergence in reasoning-prior models, showing capacity-dependent U-curves (unstable at 3B, obfuscation at 8B, erasure at 14B)
- Demonstrates scale-independent true erasure in standard models with <3% utility drift

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Subject-specific factual knowledge produces linearly separable activation signatures in mid-to-late MLP layers, enabling targeted suppression without broad distribution shifts.
- **Mechanism:** Contrastive analysis between on-topic activations (positive set) and synthetic Gaussian noise (negative set) extracts a primary signature direction d via Mean Difference. This direction is validated through Cohen's d effect-size testing with bootstrap resampling; only signatures with 95% CI not crossing zero are retained.
- **Core assumption:** Factual associations are stored as localized, linearly accessible relations within MLP weights, as hypothesized by Meng et al. (2023)'s rank-one knowledge editing work.
- **Evidence anchors:**
  - [Section 3.2] "A 95% confidence interval not crossing zero confirms statistical significance... subject-specific signatures through a contrastive framework"
  - [Table 11] Layer-wise validation shows near-perfect separability (AUC-ROC ≈ 1.0, Cohen's d > 5) in layers 26-30 of the model
  - [Corpus] Sparse-Autoencoder-Guided Internal Representation Unlearning (arXiv:2509.15631) independently validates representation-level unlearning approaches, though uses different extraction methodology

### Mechanism 2
- **Claim:** The Knowledge Suppression Capsule implements a rank-one geometric constraint that attenuates activations along the signature direction while preserving orthogonal information, maintaining general utility.
- **Mechanism:** The capsule applies h′ = h + α⟨h, d⟩d where α is initialized to -1 for suppression. This decomposes into h′ = h⊥ + (1+α)h∥, acting as identity on (d-1) orthogonal directions. A sigmoid gate σ(k(z-τ)) triggers suppression only when the standardized projection z exceeds threshold τ, isolating interventions to statistically significant activations.
- **Core assumption:** Subject-specific representations occupy a low-rank subspace that can be surgically attenuated without disrupting semantically adjacent knowledge.
- **Evidence anchors:**
  - [Section 3.3] "The capsule acts as an identity on the (d-1) orthogonal directions, ensuring non-target information remains numerically untouched"
  - [Table 2] Zero-shot capability retention shows <1% drift on 6/8 benchmarks post-unlearning, with small improvements on HellaSwag (+0.16) and TruthfulQA (+0.51)
  - [Corpus] MLLMEraser (arXiv:2510.04217) demonstrates activation steering for test-time unlearning, providing convergent evidence for inference-time intervention viability

### Mechanism 3
- **Claim:** The composite loss function in the Self-Healing Loop enforces both behavioral suppression (token-level) and representation-level attenuation, which are jointly necessary for Type I erasure rather than obfuscation.
- **Mechanism:** Three loss components operate in concert: (1) DPO with scaling factor w anchors behavior to refusal; (2) Name-Token Unlikelihood (LN-TUL) penalizes aggregate probability mass on subject name tokens within refusals, preventing soft leakage; (3) Generic Unlikelihood (LUL) applies factual unlikelihood on the target output. Stability is enforced via KL divergence and EWC regularization on a pool of ~800 benign prompts.
- **Core assumption:** Neither token-level penalties nor representation-level pressure alone suffices; true erasure requires simultaneous optimization at both levels.
- **Evidence anchors:**
  - [Table 4, Ablation] "Removing Name-Token Unlikelihood (NT-UL) reverts Llama 8B to Type III instability (SMR 3.33%)... Removing Generic Unlikelihood shifts the model toward Type II (EL10 remains elevated at 0.098)"
  - [Section 4.3] "This interplay reveals the underlying mechanism: token-level penalties enforce behavioral constraints at the output surface, while representation-level penalties enforce true knowledge attenuation in latent space"
  - [Corpus] Step-by-Step Reasoning Attack (arXiv:2506.17279) reveals that "erased" knowledge can be recovered through reasoning chains, supporting the claim that surface suppression alone is insufficient

## Foundational Learning

- **Concept:** MLP layer function in transformer architectures (specifically SwiGLU gating)
  - **Why needed here:** KIF targets intermediate tensors A_gate, A_up, Y_down within MLP blocks rather than full block outputs. Understanding the three-projection structure is essential for signature extraction and capsule placement.
  - **Quick check question:** Can you explain why the paper extracts signatures from gate/up/down projections separately rather than from the residual stream?

- **Concept:** Preference optimization (DPO/NPO) objectives
  - **Why needed here:** The Self-Healing Loop adapts DPO with a scaling factor w. Understanding how preference optimization differs from gradient ascent is necessary to interpret why KIF achieves smoother unlearning.
  - **Quick check question:** How does the w scaling factor in KIF's DPO variant differ from standard DPO, and what problem does it solve for unlearning?

- **Concept:** Mechanistic interpretability via activation patching
  - **Why needed here:** The paper builds on Meng et al. (2023)'s causal tracing methodology. Understanding how localized edits propagate through transformer layers is foundational to KIF's design philosophy.
  - **Quick check question:** What does the rank-one hypothesis claim about how factual knowledge is stored, and how does KIF exploit this?

## Architecture Onboarding

- **Component map:** [Prompt Dataset] → [Activation Probing Pipeline] → [Signature Analysis Module] → [Knowledge Suppression Capsules] → [Self-Healing Loop: Composite Loss] → [Global LoRA Adapter] → [Unlearned Model]

- **Critical path:**
  1. Dataset construction (5 prompt types × templates per triple) → activation quality depends on coverage
  2. Signature extraction (contrastive analysis + Cohen's d validation) → if signatures fail validation, downstream fails
  3. Capsule placement (top-k layers with strongest separability, typically layers 26-30) → incorrect layer selection causes utility collapse
  4. Self-Healing Loop hyperparameters (τ=3.0, k=1.6, λ-weights) → sensitive to model family

- **Design tradeoffs:**
  - **Signature specificity vs. generalization:** Stricter effect-size thresholds yield more surgical erasure but may miss distributed representations in reasoning models
  - **Capsule count vs. inference overhead:** More capsules increase coverage but add O(d) projection cost per forward pass
  - **Unlearning aggressiveness vs. stability:** Higher λ_UL and λ_NTUL improve erasure but risk Type III instability; the paper uses λ_UL=0.03, λ_NTUL=0.02 as calibrated defaults
  - **Standard vs. reasoning model treatment:** Reasoning models exhibit capacity-dependent U-curve (unstable at 3B, obfuscation at 8B, erasure at 14B); requires family-specific threshold tuning

- **Failure signatures:**
  - **Type II Obfuscation:** SMR ≤ 5% but EL10 > 1.0 → model internally recognizes target but suppresses output; capsule triggers but LoRA distillation failed to erase representation
  - **Type III Instability:** SMR > 5% → capsule threshold τ too low or signature insufficiently discriminative; manifests as inconsistent refusals
  - **Utility collapse:** >5% drift on retain benchmarks → signature captures collateral semantic content; requires re-extraction with stricter effect-size thresholds

- **First 3 experiments:**
  1. **Signature validation probe:** Before capsule construction, verify layer-wise AUC-ROC > 0.95 and Cohen's d > 2.0 on a held-out subject; if layer 0-5 show separability, dataset has prompt leakage (templates too obvious)
  2. **Single-subject erasure with ablation:** Apply KIF to one subject with (full) and without (NT-UL removed) name-token unlikelihood; compare EL10 ratios to confirm compositional loss requirement for your target model family
  3. **Cross-family scaling test:** Run KIF on 3B and 7B/8B variants of the same family; if 3B shows Type III but 7B shows Type I, your target family has reasoning-like entanglement requiring capacity threshold verification

## Open Questions the Paper Calls Out

- **Question:** Is the Knowledge Immunization Framework (KIF) robust against adversarial recovery vectors such as jailbreaking or subsequent fine-tuning?
  - **Basis in paper:** [explicit] The authors state in the Limitations section that they "were not able to assess robustness against adversarial recovery vectors," while the Ethical Consideration notes a lack of "mathematical guarantee of irrecoverability against extreme adversarial fine-tuning."
  - **Why unresolved:** Resource constraints and the focus on immediate unlearning metrics prevented the inclusion of red-teaming or relearning attack simulations in the evaluation.
  - **What evidence would resolve it:** Stress-testing KIF-unlearned models using jailbreak attacks (e.g., prompt injection) and measuring knowledge recovery rates after continued pre-training or fine-tuning on related domains.

- **Question:** Does KIF maintain its performance characteristics when applied to larger, full-precision models beyond 14B parameters?
  - **Basis in paper:** [explicit] The Limitations section notes that resource constraints "limited our scope to 4-bit quantized models (up to 14B parameters), leaving performance on larger, full-precision models to be verified."
  - **Why unresolved:** The experiments were restricted by hardware (One RTX A6000), forcing the use of quantization and limiting the scale of the model architectures tested.
  - **What evidence would resolve it:** Replicating the KIF pipeline on 70B+ parameter models (e.g., Llama-3-70B) in full precision (FP16/BF16) and reporting Forget Quality (FQ) and Model Utility (MU).

- **Question:** Does the observed utility improvement ("latent pruning") result from the removal of high-interference traces, or does it create "semantic holes" in the model's contextual understanding?
  - **Basis in paper:** [explicit] The discussion section describes the "latent pruning" hypothesis as "speculative" and acknowledges concerns that surgical erasure "may create 'semantic holes,' whose entanglement may cause unintended degradation of broader contextual understanding."
  - **Why unresolved:** While metrics show utility gains (e.g., TruthfulQA +0.51), the paper lacks a mechanistic analysis to confirm if this is beneficial de-noising or unintended semantic degradation.
  - **What evidence would resolve it:** Targeted probing of knowledge clusters related to the forget set and specific "semantic hole" detection benchmarks to verify the integrity of the model's general world knowledge.

## Limitations

- **Dataset and Signature Extraction:** The effectiveness of signature extraction relies on contrastive analysis with synthetic Gaussian noise, which may not capture the full distribution of irrelevant knowledge across diverse domains beyond the 11 musician subjects tested.
- **Family-Specific Architectural Divergence:** The paper identifies fundamental architectural differences between standard and reasoning models but provides limited mechanistic explanation for the observed capacity-dependent U-curves in reasoning model behavior.
- **Hyperparameter Sensitivity:** The Self-Healing Loop relies on calibrated defaults (τ=3.0, k=1.6, λ-weights) that lack systematic sensitivity analysis and may require family-specific tuning for new model architectures.

## Confidence

**High Confidence:** The representation-aware signature extraction methodology and capsule implementation are technically sound and well-documented. The dual-metric evaluation protocol (FQ, MU, SMR, EL10) provides a rigorous framework for distinguishing obfuscation from true erasure. The ablation studies convincingly demonstrate the compositional nature of the loss function.

**Medium Confidence:** The core empirical results showing KIF achieving Type I erasure (FQ ≈ 0.99, MU = 0.62) while breaking the stability-erasure tradeoff are robust for the tested model families and scales. However, the generalization to broader knowledge domains and model architectures requires additional validation.

**Low Confidence:** The mechanistic explanation for reasoning model divergence and the claimed capacity-dependent U-curve behavior are primarily observational. The paper does not provide sufficient theoretical grounding or additional empirical evidence to fully support these claims, particularly the assertion that reasoning models exhibit "fundamental architectural divergence" rather than simply different training dynamics.

## Next Checks

**1. Cross-Domain Signature Transferability:** Apply KIF to erase knowledge across diverse domains (scientific facts, historical events, technical procedures) using the same 11 musician subjects as training seeds. Measure signature transferability by computing Cohen's d and AUC-ROC for signatures trained on musician knowledge when applied to erase knowledge about scientists, historical figures, or technical concepts.

**2. Reasoning Model Architecture Analysis:** Conduct a systematic study of MLP layer architecture differences between standard and reasoning models by analyzing the layer-wise signature separability patterns. Compare the distribution of effect sizes across layers, the dimensionality of signature directions, and the correlation between reasoning capability and unlearning stability.

**3. Hyperparameter Sensitivity and Auto-tuning:** Implement an automated hyperparameter optimization framework that searches the space of τ, k, and λ weights for each model family. Report the sensitivity of Type I erasure achievement to these parameters and develop a heuristic or small neural network that predicts optimal hyperparameters based on model architecture characteristics.