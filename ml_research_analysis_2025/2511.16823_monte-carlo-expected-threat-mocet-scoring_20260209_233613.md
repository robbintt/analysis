---
ver: rpa2
title: Monte Carlo Expected Threat (MOCET) Scoring
arxiv_id: '2511.16823'
source_url: https://arxiv.org/abs/2511.16823
tags:
- mocet
- success
- threat
- expected
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a new framework, MOCET, to assess real-world
  biosecurity risks from LLMs by translating model-generated instructions into expected
  threat scores. MOCET models multi-step bioweapon assembly protocols as Bernoulli
  trials, computes success probabilities using a k-NN method on semantic embeddings,
  and weights outcomes by expected casualties from historical events.
---

# Monte Carlo Expected Threat (MOCET) Scoring

## Quick Facts
- arXiv ID: 2511.16823
- Source URL: https://arxiv.org/abs/2511.16823
- Reference count: 38
- Authors: Joseph Kim; Saahith Potluri
- One-line primary result: A framework that translates LLM-generated biosecurity instructions into interpretable expected harm scores using Monte Carlo simulation

## Executive Summary
MOCET provides a novel framework for assessing real-world biosecurity risks from LLMs by translating model-generated instructions into expected threat scores. The framework models multi-step bioweapon assembly protocols as Bernoulli trials, computes success probabilities using a k-NN method on semantic embeddings, and weights outcomes by expected casualties from historical events. Applied to a fine-tuned Llama-3-8B model, MOCET generated non-zero risk scores (e.g., 18.94 for Sarin, 0.58 for Anthrax), indicating unlocked misuse potential despite marginal academic benchmark drops. Human expert ratings confirmed protocol feasibility.

## Method Summary
MOCET evaluates LLM-enabled biosecurity threats through a Monte Carlo simulation framework that decomposes protocols into discrete steps, estimates individual step success probabilities using k-nearest neighbors on semantic embeddings, and aggregates weighted outcomes. The framework treats each step as a Bernoulli trial, computes overall protocol success as the product of step probabilities, and weights successful outcomes by expected casualties from historical bioweapon events. MOCET scores are calculated for individual incidents and scaled by occurrence rates using FBI mass murder statistics to produce cumulative risk assessments.

## Key Results
- MOCET generated non-zero risk scores for fine-tuned Llama-3-8B model: 18.94 for Sarin, 0.58 for Anthrax
- Model-human rating divergences observed: 1.18% vs 16.5% for Anthrax protocol feasibility
- Implementation complexity: ~10 lines of code per model, scalable to thousands of models
- Framework shows ~10% deviation in step probabilities resulting in only ~1% error in final score

## Why This Works (Mechanism)

### Mechanism 1
Decomposing multi-step bioweapon protocols into Bernoulli trials enables tractable probability estimation for otherwise complex real-world attack chains. Each LLM-generated instruction step is modeled as a binary success/failure event (X_i ∈ {0,1}). The overall protocol success probability E[Y] equals the product of individual step probabilities across m categories: E[Y] = ∏(j=1 to m) p_j^(n_j). This reduces an intractable physical simulation problem to a chain of conditional probabilities.

### Mechanism 2
k-NN on semantic embeddings provides a data-driven, instance-based estimate of step success probability that outperforms manual categorical assignment. Text descriptions of protocol steps are embedded using all-mpnet-base-v2. For each target step, k nearest neighbors from a historical dataset are retrieved, and their known success rates are averaged to estimate p_i ≈ (1/k) Σ X_j. This creates dynamic, context-sensitive "categories" rather than static bins.

### Mechanism 3
Monte Carlo aggregation with harm weighting produces an interpretable, scalable threat metric comparable to public health statistics. N Monte Carlo trials sample from step probability distributions. Each successful outcome is weighted by W (expected casualties from historical bioweapon events). MOCET = (1/N) Σ W(Y_i)·E[Y_i]. Cumulative MOCET scales by occurrence rate (FBI mass murder data).

## Foundational Learning

- **Bernoulli Processes and Multiplicative Probability Chains**
  - Why needed here: MOCET's core assumption is that protocol success = product of step success probabilities. Understanding how small individual failures compound is essential for interpreting scores.
  - Quick check question: If a 10-step protocol has 0.80 success probability per step, what is the overall success rate? (~10.7%—illustrates why protocols are fragile)

- **Instance-Based Learning (k-NN) for Probability Calibration**
  - Why needed here: The k-NN embedding approach dynamically estimates p_i per step. Understanding locality assumptions helps diagnose when estimates are trustworthy.
  - Quick check question: If k=5 neighbors have outcomes [1,1,0,1,0], what is the estimated success probability? (0.60—simple averaging, but sensitive to neighborhood quality)

- **Monte Carlo Estimation of Expected Value**
  - Why needed here: MOCET uses MC sampling to approximate E[W·Y] over complex distributions. Understanding variance and convergence is critical for score reliability.
  - Quick check question: How many MC trials are needed to estimate a probability of 0.01 within ±10% relative error at 95% confidence? (~38,000 trials—illustrates sample complexity for rare events)

## Architecture Onboarding

- Component map: LLM Prompt Interface -> Protocol Decomposer -> Embedding Encoder -> k-NN Probability Estimator -> Monte Carlo Engine -> Harm Weighting Function -> MOCET Aggregator -> Human Validation Layer

- Critical path: LLM output → step parsing → embedding → k-NN lookup → probability assignment → MC simulation → weighted aggregation. The k-NN probability estimator is the highest-risk component; garbage historical data → garbage scores.

- Design tradeoffs:
  - k selection: Low k → noisy estimates; high k → over-smoothing. Paper uses k=20 after validation.
  - Harm function W: Historical averages may underweight tail events; alternative: expert elicitation or worst-case bounds.
  - Occurrence rate scaling: FBI mass murder data (30/year in 2017) may not reflect biothreat frequency; sensitivity analysis recommended.

- Failure signatures:
  1. Non-zero MOCET with zero human feasibility → k-NN embedding space misaligned with physical reality
  2. Huge variance across MC trials → insufficient N or highly uncertain step probabilities
  3. Model/human rating divergence >10x → categorical probability approximation breaking down

- First 3 experiments:
  1. Baseline validation: Replicate k-NN calibration on WMDP/MMLU—verify that predicted accuracy correlates with actual correctness (p << 0.01 as claimed).
  2. Sensitivity analysis: Vary k ∈ {5,10,20,40} and N ∈ {1000,10000,100000} on a fixed protocol; observe score stability.
  3. Adversarial test: Prompt Dolphin model with deliberately infeasible protocols (e.g., fictional agents); verify MOCET yields near-zero scores.

## Open Questions the Paper Calls Out

- **Multi-turn prompting effects**: How does multi-turn or best-of-n prompting affect MOCET scores compared to zero-shot assessments? The framework only evaluates single zero-shot outputs despite real malicious actors likely iterating on prompts.

- **k-NN validation scope**: Can k-NN probability estimation, validated on academic benchmarks, accurately predict biosecurity protocol step success? Semantic similarity in embedding space may not correlate with actual step success for bioweapon assembly.

- **Ground truth calibration**: Which is more accurate when model and expert estimates diverge sharply (e.g., 1.18% vs. 16.5% for Anthrax)? Neither automated nor expert estimates have been calibrated against real-world outcomes.

## Limitations
- Multiplicative Bernoulli assumption may underestimate protocol resilience if actors can recover from individual failures
- k-NN probability estimator depends critically on representativeness and quality of historical step-outcome data
- Harm weighting function uses historical averages that may systematically underweight catastrophic tail events

## Confidence

- **High**: The mathematical framework (Bernoulli decomposition, MC aggregation) is sound and validated on standard benchmarks (WMDP, MMLU)
- **Medium**: The k-NN embedding approach shows statistical significance (p << 0.01) on general benchmarks but lacks direct validation on biosecurity-specific protocols
- **Low**: Absolute MOCET scores depend on historical harm data that may not capture future maximum casualties or evolving threat landscapes

## Next Checks

1. **Protocol recovery analysis**: Test whether multi-turn LLM prompting can significantly increase protocol success rates beyond the multiplicative model's predictions.

2. **Historical dataset audit**: Analyze the distribution of step types and outcomes in the k-NN training data; quantify coverage gaps for novel or complex bioweapon procedures.

3. **Expert calibration study**: Conduct blinded human feasibility ratings on a larger set of LLM-generated protocols; compare MOCET scores to expert consensus to identify systematic over/underestimation patterns.