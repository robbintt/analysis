---
ver: rpa2
title: 'Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to
  Prediction Tasks'
arxiv_id: '2505.22538'
source_url: https://arxiv.org/abs/2505.22538
tags:
- uncertainty
- loss
- learning
- measures
- epistemic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a flexible framework for uncertainty quantification
  in machine learning using proper scoring rules. The authors decompose proper scoring
  rules into divergence and entropy components to define total, aleatoric, and epistemic
  uncertainty measures.
---

# Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks

## Quick Facts
- arXiv ID: 2505.22538
- Source URL: https://arxiv.org/abs/2505.22538
- Reference count: 40
- Primary result: Different uncertainty measures (total, aleatoric, epistemic) derived from proper scoring rules are optimal for different downstream tasks - selective prediction (total uncertainty), OoD detection (mutual information), and active learning (zero-one epistemic uncertainty).

## Executive Summary
This paper introduces a flexible framework for uncertainty quantification in machine learning using proper scoring rules. The authors decompose proper scoring rules into divergence and entropy components to define total, aleatoric, and epistemic uncertainty measures. They demonstrate that different uncertainty measures are optimal for different downstream tasks. For selective prediction, aligning the uncertainty loss with the task loss and using total uncertainty as the rejection criterion yields the best performance. In out-of-distribution detection, mutual information (based on log-loss) performs best. For active learning, the epistemic uncertainty measure based on the zero-one-loss consistently outperforms other measures. The framework generalizes existing approaches and enables task-specific customization of uncertainty quantification.

## Method Summary
The method decomposes strictly proper scoring rules into entropy (aleatoric) and divergence (epistemic) components to create three uncertainty measures: Total (TU), Aleatoric (AU), and Epistemic (EU). A second-order distribution (distribution over first-order distributions) is generated using methods like Dropout, Ensembles, or Laplace approximation. The appropriate uncertainty measure is then computed based on the downstream task - TU for selective prediction, log-based EU for OoD detection, and zero-one EU for active learning. The framework is evaluated across multiple datasets (CoverType, CIFAR-10, MNIST variants) with different model architectures and uncertainty representation methods.

## Key Results
- For selective prediction, aligning uncertainty loss with task loss and using total uncertainty yields optimal AULC performance
- In OoD detection, mutual information (log-loss EU) achieves the highest AUROC
- For active learning, zero-one epistemic uncertainty consistently outperforms other measures across multiple datasets
- The framework generalizes existing approaches and enables task-specific customization of uncertainty quantification

## Why This Works (Mechanism)

### Mechanism 1: Scoring Rule Decomposition
A strictly proper scoring rule $\ell$ guarantees that the expected loss $L_\ell$ is minimized only by the true distribution. This expected loss decomposes into Entropy $H_\ell(\theta)$ (aleatoric uncertainty) and Divergence $D_\ell(\hat{\theta}, \theta)$ (epistemic uncertainty). By applying this decomposition to a second-order distribution, the authors derive generalized measures for Total, Aleatoric, and Epistemic uncertainty. The validity relies on the scoring rule being strictly proper.

### Mechanism 2: Task-Loss Alignment (Selective Prediction)
Proposition 4.1 proves that ordering test instances by their expected task loss minimizes the expected AULC. The expectation of the task loss over the second-order distribution is mathematically equivalent to the Total Uncertainty (TU) measure derived from that same loss. Therefore, if the task evaluates accuracy using zero-one loss, the uncertainty measure should also be instantiated with zero-one loss.

### Mechanism 3: Information Gain via Zero-One Epistemic Uncertainty (Active Learning)
The 0-1 EU measures the expected reduction in misclassification error if the true label were known. It is minimized only when all sampled distributions agree on the argmax (most likely class). In contrast, log-loss based EU can remain high even if samples agree on the class but disagree on confidence. For active learning, class disagreement is often the most salient signal for informativeness.

## Foundational Learning

- **Concept: Strictly Proper Scoring Rules**
  - Why needed here: The entire framework relies on the property that the expected score is optimized only when the predicted probability matches the true probability. Without this, the decomposition into "true risk" (aleatoric) and "excess risk" (epistemic) is invalid.
  - Quick check question: Does the Brier score incentivize the forecaster to predict the true probability distribution, or just the correct class label? (Answer: The true distribution).

- **Concept: Second-Order Distributions**
  - Why needed here: To distinguish aleatoric from epistemic uncertainty, one must model uncertainty about the probability distribution itself. A first-order distribution $P(Y|X)$ captures aleatoric uncertainty, while a second-order distribution $Q(\theta)$ captures epistemic uncertainty.
  - Quick check question: In a standard neural network, do we have a first-order or second-order distribution? (Answer: First-order; we get a point estimate of probabilities. We need ensembles/Bayesian methods to lift this to second-order).

- **Concept: Divergence vs. Entropy**
  - Why needed here: The paper equates Entropy to Aleatoric Uncertainty (irreducible noise) and Divergence to Epistemic Uncertainty (reducible error due to lack of knowledge). Understanding this mapping is required to select the right measure for the right task.
  - Quick check question: If I collect more training data, which component should theoretically decrease: the divergence or the entropy? (Answer: The divergence/epistemic component).

## Architecture Onboarding

- **Component map:** Sampling -> Aggregation -> Instantiation -> Computation -> Action
- **Critical path:**
  1. Generate $M$ predictions $\theta_m$ for input $x$ using the chosen Bayesian approximation
  2. Compute the mean prediction $\bar{\theta} = \frac{1}{M}\sum \theta_m$
  3. Select the loss $\ell$ based on the downstream task
  4. Calculate EU as $\mathbb{E}[\max_k \theta_k - \theta_{\text{argmax}\bar{\theta}}]$ for Zero-One
  5. Select top-k instances with highest EU for labeling

- **Design tradeoffs:**
  - Log-Loss (Mutual Information) vs. Zero-One EU: Log-loss is strictly proper and sensitive to calibration; Zero-One is not strictly proper but focuses purely on class correctness. Use Zero-One for efficiency in Active Learning; use Log-Loss for detecting covariate shift (OoD).
  - Total vs. Epistemic Uncertainty: For Selective Prediction, the paper argues Total Uncertainty (TU) is theoretically optimal. For Active Learning, Epistemic Uncertainty (EU) is required because Aleatoric Uncertainty (noise) cannot be reduced by labeling.

- **Failure signatures:**
  - Stagnant Active Learning: Using Log-loss EU for Active Learning might query instances where it is confident in the class but uncertain in the probability. Switch to Zero-One EU.
  - Poor Selective Prediction: Using Aleatoric Uncertainty to reject instances may reject noisy-but-important data points. Switch to Total Uncertainty.
  - OoD Blindness: Using Zero-One EU for OoD detection might miss anomalies where the direction of the probability vector shifts but the argmax remains the same. Log-Loss (MI) is safer here.

- **First 3 experiments:**
  1. Selective Prediction Alignment: Train RandomForest on CoverType, compute TU with all three losses, sort by uncertainty, plot loss-rejection curves. Verify zero-one TU matches zero-one task loss best.
  2. Active Learning Efficiency: Implement AL loop on MNIST, compare "Query by Committee" vs. "Query by Zero-One EU", plot test error vs. number of labeled instances. Zero-One EU should converge faster.
  3. OoD Validation: Train ResNet on CIFAR-10, use Ensemble, compute EU with all losses, evaluate AUROC vs CIFAR-100. Confirm log-based EU yields highest AUROC.

## Open Questions the Paper Calls Out

- Does aligning the model's training loss with the downstream task's uncertainty loss improve performance? The authors did not discuss the training loss and suggest exploring the connection between the proper loss used during training and uncertainty measure performance.
- How does the choice of uncertainty representation method (e.g., Dropout vs. Laplace approximation) interact with the choice of scoring rule? The paper notes that different representation methods produce different second-order distributions but does not isolate how this affects scoring rule effectiveness.
- Can a formal theoretical connection be established between the zero-one epistemic uncertainty measure and optimal performance in active learning? While empirically demonstrated, the paper provides only an intuitive explanation rather than a formal proof for why zero-one EU works best in active learning.

## Limitations

- The theoretical decomposition assumes strictly proper scoring rules, but empirical results show log-loss EU works best for OoD detection without testing whether strict properness is truly necessary.
- The claim that zero-one EU "consistently outperforms" other measures in active learning across all tested datasets is based on limited trials (3 seeds).
- The empirical claim that TU-Log and TU-Brier achieve the same AULC in selective prediction is stated without showing this equivalence directly.

## Confidence

- High: The decomposition framework and Proposition 4.1 (selective prediction ordering) are mathematically rigorous.
- Medium: Empirical results showing task-specific superiority of different uncertainty measures are internally consistent but lack ablation studies.
- Low: The claim that zero-one EU consistently outperforms other measures in active learning across all tested datasets is based on limited trials.

## Next Checks

1. Test Strictly Properness Necessity: Implement a "quasi-proper" scoring rule that is not strictly proper and verify that its divergence component no longer reliably tracks epistemic uncertainty.
2. Cross-Domain Active Learning: Replicate the active learning experiment on CIFAR-10 instead of MNIST/FashionMNIST to test whether zero-one EU's advantage generalizes to high-dimensional, real-world data.
3. Selective Prediction AULC Verification: For selective prediction, explicitly compute and compare the AULC curves for TU-Log and TU-Brier on CoverType to verify the theoretical claim that they achieve identical performance when the task loss is log-loss.