---
ver: rpa2
title: Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders
arxiv_id: '2505.01134'
source_url: https://arxiv.org/abs/2505.01134
tags:
- modalities
- distributions
- consensus
- generative
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoDE (Consensus of Dependent Experts), a
  novel method for aggregating multimodal distributions in variational autoencoders
  (VAEs) that accounts for dependence between modalities. Unlike existing approaches
  like Product of Experts (PoE) and Mixture of Experts (MoE) that assume independence,
  CoDE leverages Bayesian inference through the experts' error of estimation to capture
  correlations between modalities.
---

# Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders

## Quick Facts
- arXiv ID: 2505.01134
- Source URL: https://arxiv.org/abs/2505.01134
- Reference count: 40
- Key outcome: Introduces CoDE, a method for aggregating multimodal distributions in VAEs that accounts for dependence between modalities, achieving better generative coherence and quality than existing approaches.

## Executive Summary
This paper addresses the challenge of aggregating expert distributions in multimodal variational autoencoders (VAEs) by introducing the Consensus of Dependent Experts (CoDE) method. Unlike traditional approaches like Product of Experts (PoE) and Mixture of Experts (MoE) that assume independence between modalities, CoDE leverages Bayesian inference to capture correlations between modalities through the experts' error of estimation. The authors develop CoDE-VAE, which optimizes each Evidence Lower Bound (ELBO) term associated with different modality subsets by learning contribution weights, eliminating the need for sub-sampling techniques that harm performance in existing methods.

## Method Summary
CoDE-VAE introduces a novel approach to multimodal VAE aggregation by treating expert estimates as observed data with Gaussian error. The method constructs a covariance matrix Σ_k for the error of estimation that includes off-diagonal elements representing correlation between modalities. Through Bayesian inference, CoDE computes a consensus distribution that accounts for these dependencies, then optimizes each subset-specific ELBO term with learned contribution weights π_k. This approach avoids sub-sampling during training while maintaining computational feasibility through efficient matrix operations. The model is evaluated across multiple datasets including MNIST-SVHN-Text, PolyMNIST, and CUB, demonstrating superior performance in both generative coherence and quality metrics.

## Key Results
- CoDE-VAE achieves better trade-offs between generative coherence and quality compared to state-of-the-art multimodal VAEs
- The method reduces the generative quality gap as the number of modalities increases, reaching unimodal VAE quality with 4-5 modalities
- CoDE-VAE achieves classification accuracy comparable to or better than existing multimodal VAEs while eliminating the need for sub-sampling techniques
- Ablation studies confirm benefits of modeling dependence between expert distributions and learning contribution weights for each ELBO term

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modeling the stochastic dependence between expert distributions yields a more accurate approximation of the joint posterior than assuming independence.
- Mechanism: CoDE constructs a covariance matrix Σ_k for error of estimation, including off-diagonal elements representing correlation. By inverting this matrix during Bayesian aggregation, the joint distribution q(z|X_k) can lean more heavily on reliable experts while correcting for shared noise, avoiding the "over-optimistic" variance underestimation of PoE.
- Core assumption: Errors of estimation across modalities are correlated because all modalities originate from the same underlying object and follow a multivariate Gaussian distribution.
- Evidence anchors: [abstract] mentions leveraging Bayesian inference through experts' error of estimation; [section 3.1] defines error formulation e_k ~ N(0, Σ_k); corpus context from "Hellinger Multimodal Variational Autoencoders" notes existing methods use independence assumptions.

### Mechanism 2
- Claim: Learning contribution weights (π_k) of each subset-specific ELBO term improves optimization by prioritizing subsets with lower uncertainty.
- Mechanism: Standard multimodal VAEs sum ELBOs equally. CoDE-VAE introduces learnable weights π via a categorical distribution and maximizes entropy of their posterior. This automatically assigns higher weights to subsets X_k with lower average trace in their covariance matrix (more confident/precise distributions).
- Core assumption: Subsets of modalities provide unequal information; subsets with more confident estimates should drive optimization more than vague ones.
- Evidence anchors: [abstract] mentions optimizing ELBO terms by learning contribution weights; [section 3.2] defines final objective function L(X) summing terms weighted by π_k; corpus context from "Bridging the inference gap in Multimodal Variational Autoencoders" implies need for better weighting mechanisms.

### Mechanism 3
- Claim: Avoiding sub-sampling during optimization preserves generative quality as the number of modalities increases.
- Mechanism: Many existing methods rely on sub-sampling modalities during training to manage complexity, which harms joint distribution approximation. CoDE-VAE computes ELBO terms for all subsets without sub-sampling, maintaining tight log-likelihood bounds.
- Core assumption: Computational overhead of calculating consensus distributions for all subsets is manageable and preferable to performance loss from sub-sampling.
- Evidence anchors: [abstract] states the approach eliminates need for sub-sampling techniques that harm performance; [section 4.2] demonstrates CoDE-VAE minimizes generative quality gap as modality count increases; corpus context from "Multi-Component VAE with Gaussian Markov Random Field" highlights existing strategies rely on simplified aggregation.

## Foundational Learning

- Concept: Product of Experts (PoE) vs. Mixture of Experts (MoE)
  - Why needed here: CoDE is proposed as alternative to these standard aggregation methods. PoE multiplies densities (leading to overly sharp posteriors if experts overlap) while MoE averages them (leading to vague posteriors).
  - Quick check question: If two experts disagree on a latent variable's value, does PoE tend to find a compromise (average) or a region where both are confident (intersection)?

- Concept: Bayesian Inference with Gaussian Error Models
  - Why needed here: CoDE's core (Lemma 2) relies on treating expert estimates as observed data with Gaussian error to derive posterior distribution for "true" latent variable.
  - Quick check question: In this framework, what does the off-diagonal term ρ in covariance matrix Σ physically represent regarding relationship between Expert A and Expert B?

- Concept: Evidence Lower Bound (ELBO) Decomposition
  - Why needed here: Paper modifies standard multimodal ELBO by summing terms across powerset of modalities. Understanding trade-off between reconstruction term (likelihood) and regularization term (KL divergence) is essential to grasp why weighting π_k matters.
  - Quick check question: Does CoDE-VAE ELBO treat KL divergence term for each subset equally, or does it scale them?

## Architecture Onboarding

- Component map: Encoders (Experts) -> CoDE Aggregation Layer -> Latent z -> Decoders -> Reconstruction
- Critical path:
  1. Forward pass inputs through Encoders to get expert estimates
  2. Construct Σ_k and perform matrix inversion (Lemma 2) to get q(z|X_k)
  3. Sample z via reparameterization
  4. Reconstruct via Decoders
  5. Compute Loss: Weighted sum of subset ELBOs using π_k and β (regularization)

- Design tradeoffs:
  - Precision vs. Speed: CoDE requires matrix inversion (Σ⁻¹) adding computational overhead compared to simple PoE multiplication, though paper notes it is "affordable"
  - Fixed vs. Learned ρ: Paper finds ρ via cross-validation. Learning end-to-end might be more adaptive but risks instability if Σ becomes non-invertible

- Failure signatures:
  - Numerical Instability: If Σ_k is ill-conditioned (highly correlated experts with low variance), inversion fails
  - Mode Collapse: If ρ is set too high without proper calibration, consensus might over-fit to one dominant modality
  - Vanishing Coherence: If learned weights π_k incorrectly prioritize unimodal subsets over joint set, generative coherence may drop

- First 3 experiments:
  1. Toy Example Verification: Reproduce Figure 1. Generate two Gaussian experts with known μ, σ and defined ρ. Confirm CoDE recovers true parameter θ better than MoE/PoE
  2. Ablation on ρ: Train CoDE-VAE on MNIST-SVHN with ρ=0 (PoE baseline) vs. ρ=0.6 (Optimal). Plot log-likelihood vs. Coherence to verify "Pareto front" improvement shown in Figure 2
  3. Generative Quality Gap Test: Train on PolyMNIST with increasing M (2 to 5 modalities). Compare FID scores against standard VAE to verify "quality gap" remains closed (Figure 3)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the correlation parameter ρ be treated as a learnable variable to be optimized jointly with network weights, rather than being selected via cross-validation?
- Basis in paper: [explicit] Appendix C states that cross-validating ρ "can be computationally costly" for large datasets
- Why unresolved: Current implementation treats ρ as hyperparameter found by discrete search over grid of values
- What evidence would resolve it: Modification of CoDE framework allowing ρ to be updated via gradient descent during training, demonstrating comparable or superior performance without overhead of grid search

### Open Question 2
- Question: Does modeling negative correlations between expert distributions improve performance in specific contexts, such as adversarial or conflicting modalities?
- Basis in paper: [explicit] Page 4 notes that CoDE does not impose restrictions on negative ρ values, but authors only cross-validate positive values assuming experts share positive correlations
- Why unresolved: Authors assume modalities are different sources of information about same object (implying positive correlation) and did not test scenarios where negative dependence might be beneficial
- What evidence would resolve it: Experiments on multimodal datasets containing conflicting signals where optimal ρ is empirically determined to be negative

### Open Question 3
- Question: Can CoDE Bayesian inference framework be generalized to non-Gaussian likelihoods (e.g., Bernoulli, Categorical) while maintaining closed-form solutions?
- Basis in paper: [explicit] Appendix C states, "it is not clear how multimodal VAEs can be trained with different choices [of likelihoods/priors] than the ones we make for these"
- Why unresolved: Derivation of Lemma 2 relies on conjugacy of Gaussian distributions for posterior calculation
- What evidence would resolve it: Theoretical extension or approximation method for h(θ_k|μ_k) that handles non-Gaussian experts without sacrificing "principled Bayesian" nature of aggregation

## Limitations
- Computational overhead of matrix inversion for large modality sets is not extensively analyzed
- Cross-validation of correlation parameter ρ is performed but sensitivity to this choice is not explored
- Paper does not address potential numerical instability issues that may arise when covariance matrix becomes ill-conditioned

## Confidence
- **High Confidence**: Mathematical derivation of CoDE consensus distribution and its improvement over PoE/MoE in capturing dependence between modalities is well-supported by theoretical framework
- **Medium Confidence**: Experimental results demonstrating CoDE-VAE's superior performance in log-likelihood estimation and generative quality are compelling, but lack of detailed computational cost analysis limits confidence in scalability
- **Low Confidence**: Claims about benefits of learning contribution weights (π_k) are based on ablation studies, but mechanism for entropy optimization of these weights is not fully explained, raising questions about practical implementation

## Next Checks
1. **Computational Overhead Analysis**: Quantify additional computational cost of CoDE's matrix inversion compared to PoE/MoE as number of modalities increases. Determine scalability limits of CoDE-VAE.

2. **ρ Sensitivity Study**: Conduct comprehensive sensitivity analysis of CoDE's performance to different values of correlation parameter ρ. Explore whether adaptive learning of ρ during training is feasible and beneficial.

3. **Numerical Stability Investigation**: Investigate numerical stability of CoDE's matrix inversion step. Analyze condition numbers of covariance matrices and explore regularization techniques to mitigate potential instability issues.