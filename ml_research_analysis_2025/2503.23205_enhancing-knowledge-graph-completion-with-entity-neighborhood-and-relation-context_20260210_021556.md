---
ver: rpa2
title: Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation
  Context
arxiv_id: '2503.23205'
source_url: https://arxiv.org/abs/2503.23205
tags:
- entity
- relation
- context
- knowledge
- kgc-erc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KGC-ERC addresses the problem of incomplete knowledge graphs by
  integrating entity neighborhood and relation context into a generative language
  model for knowledge graph completion. The framework enriches the input sequence
  with sampled contextual information from both the entity's neighbors and other triples
  involving the same relation, using a sampling strategy to select relevant context
  within token constraints.
---

# Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context

## Quick Facts
- arXiv ID: 2503.23205
- Source URL: https://arxiv.org/abs/2503.23205
- Reference count: 31
- KGC-ERC achieves MRR of 0.386 and H@1 of 0.360 on Wikidata5M with only 60M parameters

## Executive Summary
KGC-ERC addresses incomplete knowledge graphs by integrating entity neighborhood and relation context into a generative language model for knowledge graph completion. The framework enriches input sequences with sampled contextual information from both the entity's neighbors and other triples involving the same relation, using a sampling strategy to select relevant context within token constraints. Experiments demonstrate that this approach outperforms state-of-the-art baselines across multiple datasets, with particular emphasis on the importance of relation context and customized sampling strategies for enhancing model performance.

## Method Summary
KGC-ERC reformulates knowledge graph completion as a sequence-to-sequence generation task using a T5 model. For each query triple (h, r, ?), the method samples entity neighborhood pairs (up to 50 diverse relation-entity pairs) and relation context triples (up to 50 samples with cardinality-specific strategies) to enrich the input sequence. The Selector module implements entity neighborhood sampling by grouping neighbors by relation type and selecting diverse pairs, while relation context sampling uses cardinality-based strategies (1-n, n-1, n-n, 1-1) to optimize context selection. The verbalized input is truncated to 512 tokens and fed to T5 for autoregressive decoding, with 500 sampling runs generating candidate entities that are filtered and ranked.

## Key Results
- Achieves MRR of 0.386 and H@1 of 0.360 on Wikidata5M dataset
- Outperforms state-of-the-art baselines across Wikidata5M, Wiki27K, and FB15K-237-N datasets
- Ablation studies show relation context contributes 1.1% MRR improvement and sampling strategy adds 0.4% MRR
- With entity descriptions, MRR improves to 0.433 on Wikidata5M

## Why This Works (Mechanism)

### Mechanism 1
Incorporating both entity neighborhood and relation context provides complementary signals that improve generative KGC beyond either context alone. Entity neighborhood reveals attributes and relationships of the target entity, while relation context shows how the query relation typically behaves across different entity pairs, constraining the generative model's search space from both entity-centric and relation-centric perspectives. Evidence shows removing relation context drops MRR from 0.386 to 0.375.

### Mechanism 2
Relation-type-specific sampling captures more useful context than uniform random sampling. Different relation cardinalities (1-n, n-1, n-n, 1-1) have distinct prediction challenges, and the customized sampling strategy provides more informative training signals. Random sampling reduces MRR from 0.386 to 0.382, demonstrating the importance of cardinality-aware context selection.

### Mechanism 3
Converting KGC to sequence-to-sequence generation with enriched context enables scalable inference without scoring all entities. Traditional structure-based methods must score all entities for each query, while generative models produce candidate entities directly via autoregressive decoding. Multiple sampling runs generate a candidate set far smaller than the full entity vocabulary, leveraging the language model's learned patterns.

## Foundational Learning

- **Knowledge Graph Structure**: Understanding triples (h, r, t), entities, relations, and neighborhoods is prerequisite to implementing the Selector and Verbalization modules. Quick check: Given triples (Paris, capital-of, France) and (Berlin, capital-of, Germany), what is the cardinality of "capital-of" and what context would relation sampling prioritize?

- **Sequence-to-Sequence Models**: KGC-ERC builds on T5, requiring understanding of encoder-decoder architecture, teacher forcing, and autoregressive decoding. Quick check: Why does autoregressive decoding require multiple sampling runs to produce a candidate set, rather than a single forward pass?

- **Context Window Constraints**: The 512-token limit necessitates the sampling strategy, requiring understanding of tokenization and context truncation effects. Quick check: If entity neighborhood produces 200 tokens and relation context produces 400 tokens, how should sampling be adjusted to fit the 512-token limit?

## Architecture Onboarding

- **Component map**: Input Triple (h, r, ?) -> Selector Module -> Verbalization -> Truncation (512 tokens max) -> T5 Encoder-Decoder -> Autoregressive Decoding (500 samples) -> Valid Entity Filtering & Deduplication -> Candidate Scoring & Ranking

- **Critical path**: The Selector determines what context the model sees. Poor sampling leads to poor context and wrong generation. Validate sampling outputs before training.

- **Design tradeoffs**: More context samples vs. fitting token limit (50/50 values are data-driven but may need tuning); entity descriptions add 50-100 tokens but improve MRR from 0.386 to 0.433; customized vs. random sampling adds complexity but improves MRR by ~1%.

- **Failure signatures**: Generated text doesn't map to any entity (check verbalization format); low recall (increase sampling runs, check context relevance); training loss plateaus early (verify target triple excluded from sampling); model generates generic entities (context may be insufficient).

- **First 3 experiments**:
  1. Validate Selector output by running on 50 random triples from training set, manually verifying entity neighborhood diversity and relation context relevance.
  2. Ablation replication by training three models on Wiki27K: (a) full KGC-ERC, (b) without relation context, (c) with random sampling.
  3. Token budget sensitivity by varying entity neighborhood samples (10, 30, 50) and relation context samples (10, 30, 50) on FB15K-237-N.

## Open Questions the Paper Calls Out

- How can adaptive sampling techniques be developed to dynamically select context more aligned with the specific query, replacing the current static heuristics? The current Selector relies on fixed rules rather than learning which specific neighbors or contexts are most relevant.

- To what extent does the pre-classification of relation cardinalities impact the robustness of the relation context sampling strategy? The paper doesn't analyze performance when relations are misclassified or discuss the computational cost of cardinality pre-processing.

- What is the trade-off between information loss and model efficiency when truncating the concatenated input to the 512-token limit for entities with dense neighborhoods? The paper doesn't quantify the volume of high-value contextual data discarded during truncation for highly connected entities.

## Limitations

- Token budget constraints create fundamental tradeoffs between context richness and model input size, potentially excluding relevant information for entities with dense neighborhoods.
- Generative recall is capped by the 500 sampled candidates, meaning the approach cannot recover if the correct entity falls outside sampled outputs.
- Relation cardinality classification directly drives the sampling strategy, but relations can exhibit mixed cardinality patterns and classification thresholds are not specified.

## Confidence

- **High Confidence**: Experimental results demonstrating KGC-ERC's superiority over baselines are well-supported by data with consistent gains across all datasets.
- **Medium Confidence**: Proposed mechanisms are theoretically sound but rely on assumptions that may not hold universally, with limited external validation across diverse KG structures.
- **Low Confidence**: Claims about scalability and efficiency relative to structure-based methods are reasonable but not empirically validated with actual inference time comparisons or memory usage analysis.

## Next Checks

1. **Cardinality Classification Validation**: Implement the cardinality classification scheme on Wikidata5M and manually verify classifications for 100 randomly selected relations to assess classification accuracy and identify problematic relation types.

2. **Sampling Strategy Ablation**: Conduct systematic ablation testing by varying the sampling allocation (e.g., 30/30, 40/40, 50/50, 60/40) and random sampling baselines to measure impact on MRR/Hits@k across different relation cardinalities.

3. **Recall Ceiling Analysis**: Measure the absolute recall of KGC-ERC by comparing generated candidate sets against all possible correct answers to quantify how often the correct entity appears in the 500 samples and identify relation/entity types where recall drops significantly.