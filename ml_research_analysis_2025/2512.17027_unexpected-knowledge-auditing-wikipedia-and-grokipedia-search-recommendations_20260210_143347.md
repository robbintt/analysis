---
ver: rpa2
title: 'Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations'
arxiv_id: '2512.17027'
source_url: https://arxiv.org/abs/2512.17027
tags:
- wikipedia
- grokipedia
- query
- search
- recommendations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first large-scale comparative analysis
  of search recommendation behavior in Wikipedia and Grokipedia. The authors systematically
  audited both platforms using nearly 10,000 neutral English words and their substrings
  as queries, collecting over 70,000 search recommendations.
---

# Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations

## Quick Facts
- arXiv ID: 2512.17027
- Source URL: https://arxiv.org/abs/2512.17027
- Reference count: 35
- Primary result: Both Wikipedia and Grokipedia frequently surface weakly related or unexpected content from innocuous queries, with Grokipedia showing slightly higher semantic alignment than Wikipedia

## Executive Summary
This paper presents the first large-scale comparative analysis of search recommendation behavior in Wikipedia and Grokipedia. The authors systematically audited both platforms using nearly 10,000 neutral English words and their substrings as queries, collecting over 70,000 search recommendations. They found that both platforms frequently surface weakly related or unexpected content, even from innocuous queries, with Grokipedia showing slightly higher semantic alignment (0.30 vs 0.27 cosine similarity) than Wikipedia. The two platforms often produce substantially different recommendation sets for the same query (Jaccard similarity ≈ 0.17). Through multi-stage trajectory analysis, they demonstrated that unexpected recommendations persist and can become more pronounced across sequential exploration steps. Both platforms exhibited topical polarization in their recommendations, with sensitive categories (adult, conspiracy, extremism) appearing despite seemingly unrelated queries. The study challenges assumptions about encyclopedic search engines reliably constraining exploration to semantically proximate content and highlights platform-specific design choices shaping user navigation.

## Method Summary
The study used ~9,900 neutral English words from Google's 10,000 most common words list plus all character-by-character substrings as queries. Selenium scraping collected top-5 search recommendations per query from both Wikipedia and Grokipedia (v0.1). Semantic alignment was measured using Word2Vec embeddings and cosine similarity. Topical classification into 9 categories (entertainment, economics, science, law, geography, conspiracy, extremism, adult, other) was performed using Gemini-2.0-flash LLM, achieving 88% human agreement on 100 samples. Multi-stage trajectory analysis used depth-3 DFS to construct transition graphs and analyze topical drift across exploration steps.

## Key Results
- Both platforms frequently generate weakly related recommendations from innocuous queries
- Grokipedia shows higher semantic alignment (0.30) than Wikipedia (0.27)
- Jaccard similarity of ~0.17 indicates ~83% of recommendations are platform-unique
- Unexpected recommendations persist and amplify through multi-stage exploration
- Both platforms exhibit topical polarization with sensitive categories appearing from unrelated queries

## Why This Works (Mechanism)

### Mechanism 1: Substring-triggered retrieval
Query auto-completion systems match prefixes against article titles and content; shorter prefixes (e.g., "resp" → "responsibility for the September 11 attacks") have exponentially more lexical matches, increasing probability of including unexpected but lexically adjacent results. The system does not enforce semantic proximity constraints.

### Mechanism 2: Multi-stage trajectory amplification
The recommendation graph constructed from depth-first traversal shows that transition probabilities from sensitive topics (adult, conspiracy, extremism) back to neutral topics are lower than transitions into sensitive topics from neutral starting points. The paper models this as a Markov-like process where probability mass accumulates in certain topic clusters.

### Mechanism 3: Platform-specific corpus structure
Wikipedia's human-curated link structure produces different co-occurrence patterns than Grokipedia's AI-generated content. Jaccard similarity of ~0.17 indicates ~83% of recommendations are platform-unique. Grokipedia's higher semantic alignment may reflect AI-generated articles having more predictable lexical patterns.

## Foundational Learning

- **Cosine similarity on word embeddings**: Used to quantify semantic distance between queries and recommendations. Understanding that 0.27-0.30 similarity indicates weak semantic relationship (random pairs often score 0.1-0.3; synonyms 0.5-0.7) is essential for interpreting results. *Quick check: If two words have cosine similarity of 0.15, are they semantically related? What about 0.65?*

- **Jaccard similarity for set comparison**: Used to measure recommendation overlap between platforms (intersection over union). A score of 0.17 means only ~17% of recommendations are shared. *Quick check: Two sets have 5 items each, with 1 item in common. What is their Jaccard similarity?*

- **Transition probability matrices and Markov chains**: Multi-stage analysis constructs a topical transition graph where edge weights represent transition probabilities. Understanding that repeated application of transition matrix reveals steady-state distributions helps explain why polarization amplifies. *Quick check: If probability of staying in the same topic is 0.7 and transitioning to any other topic is 0.3, what happens after 5 steps if you start in topic A?*

## Architecture Onboarding

- **Component map**: Query Input Layer (substring prefixes) → Search/Index Retrieval → Candidate Generation → Ranking/Filtering → Top-5 Recommendations → User Selection → Next Query (feedback loop)
- **Critical path**: 1) Generate query set: 10,000 most common English words + all substrings 2) Collect recommendations: Selenium scraping of top-5 per query per platform 3) Compute semantic alignment: Word2Vec embeddings, average cosine similarity 4) Topical classification: Gemini-2.0-flash with 9-category taxonomy 5) Trajectory analysis: DFS to depth 3, construct transition graph G, compute transition probabilities
- **Design tradeoffs**: Using substrings better mimics user behavior but dramatically increases data collection (20,000 queries from 10,000 words). LLM-based classification scales but introduces model-specific biases. DFS depth 3 balances computational tractability with capturing meaningful trajectory drift.
- **Failure signatures**: Low Jaccard similarity between platforms for same queries indicates algorithmic/content divergence. Noxious content surfacing from innocuous substrings indicates lack of semantic guardrails. Multi-stage polarization increase indicates recommendation system has no session-level coherence enforcement.
- **First 3 experiments**:
  1. Add secondary ranking layer that penalizes recommendations with cosine similarity < 0.3 to query; measure reduction in unexpected results
  2. Apply Wikipedia's search algorithm to Grokipedia's content corpus; measure whether recommendation patterns shift toward Wikipedia-like behavior
  3. Modify DFS traversal to periodically "reset" by re-injecting original query with probability p at each step; measure how polarization curves change as p varies from 0 to 0.5

## Open Questions the Paper Calls Out

- **Temporal evolution**: Longitudinal studies could track how recommendation behavior evolves over time, detecting shifts in platform design, ranking strategies, or content coverage. This study is limited to a fixed snapshot (Grokipedia v0.1).
- **User perception**: How do users perceive unexpected recommendations as useful serendipity, confusion, or noise during information seeking? The study examines system outputs but does not directly model user behavior or user perception.
- **Multilingual generalization**: Do the observed patterns of polarization and semantic drift generalize to multilingual inputs and diverse cultural contexts? The query set is restricted to approximately 9,900 neutral English words.

## Limitations

- Corpus representativeness: ~10,000 English words and substrings may not capture full diversity of user search behavior or non-English queries
- Classification reliability: LLM-based topical classification with 9-category taxonomy may oversimplify complex topical relationships despite 88% human agreement
- Platform access: Grokipedia's availability and API access are unclear, with only version 0.1 mentioned

## Confidence

- **High confidence**: Comparative methodology and core finding that both platforms surface weakly related content from innocuous queries
- **Medium confidence**: Interpretation of semantic alignment scores and topical polarization patterns
- **Low confidence**: Trajectory amplification mechanism and quantification of polarization increase per step

## Next Checks

1. Add secondary ranking layer that penalizes recommendations with cosine similarity < 0.3 to query; measure reduction in unexpected results
2. Apply Wikipedia's search algorithm to Grokipedia's content corpus; measure whether recommendation patterns shift toward Wikipedia-like behavior
3. Modify DFS traversal to periodically "reset" by re-injecting original query with probability p at each step; measure how polarization curves change as p varies from 0 to 0.5