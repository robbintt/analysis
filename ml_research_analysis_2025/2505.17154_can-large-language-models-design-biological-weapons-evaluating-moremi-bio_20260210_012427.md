---
ver: rpa2
title: Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio
arxiv_id: '2505.17154'
source_url: https://arxiv.org/abs/2505.17154
tags:
- toxic
- proteins
- toxicity
- available
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that large language models (LLMs) can be
  used to design novel toxic proteins and small molecules with high similarity to
  known bioweapons when safety guardrails are removed. Using Moremi Bio Agent, researchers
  generated 1,020 toxic proteins and 5,000 toxic small molecules, which showed high
  toxicity scores through computational assessment.
---

# Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio

## Quick Facts
- arXiv ID: 2505.17154
- Source URL: https://arxiv.org/abs/2505.17154
- Reference count: 40
- Key outcome: Large language models can generate novel toxic proteins and small molecules with high similarity to known bioweapons when safety guardrails are removed

## Executive Summary
This study demonstrates that large language models can be used to design novel toxic proteins and small molecules with high similarity to known bioweapons when safety guardrails are removed. Using Moremi Bio Agent, researchers generated 1,020 toxic proteins and 5,000 toxic small molecules, which showed high toxicity scores through computational assessment. ToxinPred2 and CSM-Toxin tools indicated strong potential for toxicity, with ML scores ranging from 0.93 to 1.00. t-SNE clustering revealed structural similarities to known toxins like ricin and diphtheria toxin. These findings challenge claims that LLMs cannot design bioweapons, highlighting the urgent need for robust biosecurity measures and governance frameworks.

## Method Summary
The study employed the Moremi Bio Agent, a foundation model-based biodesign tool, to generate novel toxic proteins and small molecules. Researchers prompted the model without safety guardrails to design toxic substances. Generated entities were evaluated using ToxinPred2 (for proteins) and CSM-Toxin/ADMET AI (for small molecules) to assess toxicity potential. Structural similarity to known toxins was analyzed using BLAST sequence alignment and t-SNE clustering for dimensionality reduction and visualization of molecular features.

## Key Results
- Generated 1,020 novel toxic proteins and 5,000 toxic small molecules without safety constraints
- Computational toxicity scores ranged from 0.93 to 1.00 for generated proteins, comparable to or exceeding known toxins
- t-SNE clustering showed structural similarities between generated compounds and known toxins like ricin and diphtheria toxin
- BLAST analysis revealed high sequence identity (0.95-0.98) between top-generated proteins and known toxins

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based biodesign tools can generate novel toxic proteins and small molecules when safety guardrails are removed.
- Mechanism: The Moremi Bio Agent leverages foundation model knowledge of biological sequences and molecular structures to generate de novo compounds. When prompted without safety constraints, it produces entities that optimization algorithms score as high-toxicity.
- Core assumption: The model has internalized sufficient representations of toxicological structure-activity relationships from training data to generalize to novel toxic compounds.
- Evidence anchors:
  - [abstract] "Prompting Moremi Bio Agent without the safety guardrails to specifically design novel toxic substances, our study generated 1020 novel toxic proteins and 5,000 toxic small molecules."
  - [section 3.1] "We leveraged Moremi Bio Agent to further design one thousand and twenty (1,020) novel toxic proteins and 5,000 toxic small molecules without safety guardrails."
  - [corpus] Neighbor paper "Contemporary AI foundation models increase biological weapons risk" corroborates dual-use concerns, though direct replication data is limited.
- Break condition: If guardrails function correctly or model lacks biological design capabilities, toxic output generation would be blocked or negligible.

### Mechanism 2
- Claim: Computational toxicity assessment tools can predict toxicity likelihood for AI-generated biological entities.
- Mechanism: Generated proteins are evaluated using ToxinPred2 (ML classifiers, MERCI motif search, BLAST similarity) and CSM-Toxin, producing composite toxicity scores. Small molecules use ADMET AI for LD50 prediction.
- Core assumption: In silico toxicity predictions from these tools correlate with actual biological toxicity, which remains unvalidated experimentally in this study.
- Evidence anchors:
  - [abstract] "ToxinPred2 and CSM-Toxin tools indicated strong potential for toxicity, with ML scores ranging from 0.93 to 1.00."
  - [section 4.2/Table 1] MolSeq1-10 achieved ML scores 0.93-1.00, comparable to or exceeding benchmark toxins (Ricin: 0.89, Diphtheria: 0.83).
  - [corpus] "seqme" library paper addresses biological sequence evaluation metrics but does not directly validate toxicity prediction tools.
- Break condition: If computational predictions poorly correlate with in vitro/in vivo toxicity, reported scores overstate actual risk.

### Mechanism 3
- Claim: t-SNE clustering reveals structural and physicochemical similarity between generated toxins and known bioweapons.
- Mechanism: High-dimensional molecular features are projected to 2D space; proximity indicates shared structural motifs or compositional features associated with toxicity.
- Core assumption: Proximity in t-SNE space reflects functional similarity rather than artifact of dimensionality reduction.
- Evidence anchors:
  - [section 4.1] "In both figures 4 and 5, the newly generated proteins and compounds fall within or near clusters of known toxins and harmful compounds."
  - [section 5] BLAST results showed high identity scores (0.95-0.98) and E-values (0.00) for top-ranked toxic proteins compared to Ricin, Diphtheria toxin.
  - [corpus] Corpus evidence for t-SNE validation in toxin clustering is weak; no direct neighbor papers address this method.
- Break condition: If clustering reflects non-toxic features or embedding artifacts, visual proximity does not indicate actual toxicity similarity.

## Foundational Learning

- Concept: Dual-use AI in biotechnology
  - Why needed here: Understanding that beneficial AI tools (drug discovery) can be repurposed for harm is essential context for interpreting this study's risk claims.
  - Quick check question: Can you explain why the same model architecture that accelerates therapeutic design might also generate harmful compounds?

- Concept: In silico toxicity prediction (ToxinPred2, CSM-Toxin, ADMET AI)
  - Why needed here: The study relies entirely on computational toxicity scores; understanding their limitations is critical for interpreting results.
  - Quick check question: What validation steps would be required to confirm that a high ML toxicity score corresponds to actual biological toxicity?

- Concept: t-SNE dimensionality reduction for molecular similarity
  - Why needed here: The clustering analysis is primary evidence for structural similarity; understanding its assumptions prevents overinterpretation.
  - Quick check question: Why might two compounds appear close in t-SNE space yet have different biological functions?

## Architecture Onboarding

- Component map: User prompt → Safety guardrail status → Entity generation → Toxicity scoring → Similarity analysis → Risk assessment output
- Critical path: Moremi Bio Agent generates sequences → ToxinPred2/CSM-Toxin evaluate toxicity → BLAST and t-SNE analyze similarity to known toxins
- Design tradeoffs:
  - Guardrail strength vs. legitimate therapeutic design flexibility
  - Computational toxicity speed vs. experimental validation accuracy
  - Open model access vs. misuse risk mitigation
- Failure signatures:
  - High false-positive rate in toxicity prediction (blocking benign compounds)
  - Guardrails bypassed via adversarial prompting
  - Clustering artifacts from t-SNE parameter choices
- First 3 experiments:
  1. Replicate toxicity scoring on a held-out set of known benign proteins to establish false-positive baseline.
  2. Test guardrail robustness using adversarial prompts that attempt to generate toxic outputs indirectly.
  3. Validate a subset of high-scoring generated proteins using in vitro cytotoxicity assays to assess prediction correlation.

## Open Questions the Paper Calls Out
None

## Limitations
- Computational toxicity predictions lack experimental validation; in silico scores may not correlate with actual biological activity
- Structural similarity in t-SNE projections may reflect non-toxic features or dimensionality reduction artifacts
- Study does not establish whether generated entities could be synthesized or deployed in practice
- Limited information on guardrail bypass methods and their reproducibility

## Confidence
- **High confidence**: LLMs can generate novel protein and small molecule sequences when prompted without safety constraints
- **Medium confidence**: Computational toxicity tools can identify features associated with known toxins in generated compounds
- **Low confidence**: Generated compounds represent actual bioweaponizable threats requiring experimental validation

## Next Checks
1. Conduct in vitro cytotoxicity assays on top-scoring generated proteins to establish correlation between computational predictions and biological activity
2. Perform adversarial prompting tests to evaluate guardrail robustness against sophisticated bypass attempts
3. Replicate t-SNE clustering analysis using alternative dimensionality reduction methods (UMAP, PCA) to assess result stability