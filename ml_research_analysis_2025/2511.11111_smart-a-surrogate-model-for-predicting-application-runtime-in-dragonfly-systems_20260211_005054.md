---
ver: rpa2
title: 'SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems'
arxiv_id: '2511.11111'
source_url: https://arxiv.org/abs/2511.11111
tags:
- network
- dragonfly
- time
- node
- iteration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SMART, a surrogate model designed to predict
  application runtime in Dragonfly interconnect networks used in high-performance
  computing systems. SMART integrates graph neural networks (GNNs) and large language
  models (LLMs) to capture both spatial topology and temporal dynamics of network
  traffic from port-level router data.
---

# SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems

## Quick Facts
- arXiv ID: 2511.11111
- Source URL: https://arxiv.org/abs/2511.11111
- Reference count: 7
- Primary result: GNN+LLM model achieves 3.19% MAPE on Dragonfly network runtime prediction, outperforming LSTM, DCRNN, MEAN, and LAST baselines

## Executive Summary
This paper introduces SMART, a surrogate model that predicts application runtime in Dragonfly interconnect networks used in high-performance computing systems. SMART combines graph neural networks (GNNs) and large language models (LLMs) to capture both spatial topology and temporal dynamics from port-level router data. Evaluated on a 1,056-node Dragonfly system, SMART consistently outperforms existing baselines with low mean absolute percentage error (MAPE) across multiple HPC workloads and job placement strategies, while maintaining fast inference times suitable for hybrid simulation workflows.

## Method Summary
SMART integrates a 2-layer GCN encoder to capture spatial topology of the Dragonfly network with a GPT-2-based Time-LLM to capture long-range temporal dependencies in iteration times. The model processes temporal graphs constructed from router port data, where nodes represent ports and edges capture intra-router and inter-router connections. GNN embeddings are processed through a temporal transformer, while historical iteration times are processed through the LLM with prompt-based contextual information. The spatial and temporal embeddings are concatenated and passed through a linear layer to predict the next iteration time. The model is trained on high-fidelity PDES simulation data and includes online tuning capability for improved accuracy during inference.

## Key Results
- Achieves 3.19% MAPE on MILC workload with contiguous job placement on D1 dataset
- Outperforms LSTM (5.72% MAPE), DCRNN (4.23% MAPE), MEAN (4.78% MAPE), and LAST (6.21% MAPE) baselines
- Provides fast inference time (~0.5 seconds) suitable for hybrid simulation workflows
- Ablation studies confirm both GNN and LLM components are essential for optimal performance

## Why This Works (Mechanism)

### Mechanism 1: GNN-Based Spatial Encoding of Network Topology
- Claim: GCN-based encoding captures the hierarchical connectivity structure of Dragonfly networks, enabling the model to learn how topology affects workload interference and iteration times.
- Mechanism: The GNN encoder processes temporal graphs G_t = (V, E, X(t)) where nodes represent router ports and edges capture both intra-router and inter-router connections. The GCN propagation rule H^(l+1,t) = σ(D̃^(-1/2) Ã D̃^(-1/2) H^(l,t) W^(l)) aggregates neighborhood information, producing embeddings that reflect spatial dependencies in the network.
- Core assumption: Application runtime is significantly influenced by network topology and the spatial distribution of congestion across router ports.
- Evidence anchors:
  - [abstract]: "SMART integrates graph neural networks (GNNs) and large language models (LLMs) to capture both spatial topology and temporal dynamics of network traffic from port-level router data."
  - [Our Methodology - GNN Encoder]: "The GNN Encoder is a Graph Convolutional Network (GCN)... applied to each graph G_t to capture individual spatial dependencies."
  - [corpus]: Related work (RouteNet-Fermi, xnet in references) has demonstrated GNN effectiveness for network performance modeling, though not specifically for Dragonfly runtime prediction at this scale.
- Break condition: If network topology has minimal impact on runtime (e.g., under-subscribed networks with no congestion), or if the graph construction fails to capture the relevant connectivity patterns.

### Mechanism 2: LLM-Based Long-Range Temporal Pattern Recognition
- Claim: LLMs (specifically GPT-2 with Time-LLM framework) capture long-range temporal dependencies in iteration time sequences that traditional sequence models miss, using patch embedding and contextual prompting.
- Mechanism: Historical iteration times {y_(t-TinLLM), ..., y_t} are patched, embedded via linear projection, transformed through multi-head attention to match LLM embedding space, and processed with prompt prefixes containing task instructions and statistics (min, max, median). The LLM generates embeddings E(t) ∈ R^(|Va|×dllm) capturing temporal patterns.
- Core assumption: Iteration time sequences contain learnable patterns (trends, periodicity, contextual structure) that LLMs can extract better than specialized time-series models, and prompting provides useful inductive bias.
- Evidence anchors:
  - [abstract]: "SMART integrates graph neural networks (GNNs) and large language models (LLMs)... to capture both spatial and temporal patterns."
  - [LLM-powered Forecasting]: "LLMs in SMART enable contextual prompting, incorporating task-specific and domain knowledge alongside time-series data. This helps capture long-range dependencies."
  - [Temporal Model Comparisons]: "SMART with Time-LLM outperforms both alternatives [Autoformer, DLinear] on MILC and NN workloads."
  - [corpus]: Time-LLM (Jin et al. 2024, cited in paper) demonstrated LLM effectiveness for time-series forecasting; corpus shows related surrogate modeling work but limited direct evidence for LLM+GNN combinations in HPC networks.
- Break condition: If iteration times are purely stochastic with no exploitable patterns, or if the prompting strategy fails to provide meaningful context.

### Mechanism 3: Joint Spatio-Temporal Feature Integration with Learned Weighting
- Claim: Concatenating GNN-derived spatial embeddings with LLM-derived temporal embeddings, followed by end-to-end training, allows the model to automatically learn the relative importance of spatial versus temporal features.
- Mechanism: Temporal embeddings Z(t)_a (filtered for active nodes) are concatenated with reduced-dimension LLM embeddings F(t), creating combined feature vectors that encode both spatial topology and temporal patterns. A final linear layer produces predictions ŷ_(t+1). The integration is learned end-to-end rather than requiring manual tuning.
- Core assumption: Spatial and temporal features provide complementary information; neither alone is sufficient for accurate prediction.
- Evidence anchors:
  - [Final Integration]: "For each active node, the reduced-dimensional hidden state from the LLM is concatenated with the corresponding node embedding from the GNN... Rather than manually tuning the balance... SMART learns this integration end-to-end."
  - [Ablation Study - Tables 8-11]: GNN-only model shows MAPE degradation (e.g., 3.68 vs 3.19 for MILC on D1-Cont); LLM-only model also underperforms (e.g., 4.02 vs 3.19).
  - [corpus]: Limited corpus evidence for this specific GNN+LLM integration pattern in network surrogate modeling; this appears novel to this paper.
- Break condition: If spatial and temporal features are highly redundant (one subsumes the other), or if the concatenation approach fails to capture their interaction.

## Foundational Learning

- **Concept: Graph Neural Networks (GNNs) and Message Passing**
  - Why needed here: SMART uses GCN to encode Dragonfly topology. Understanding how GNNs aggregate neighbor information is essential for debugging spatial encoding failures and interpreting node embeddings.
  - Quick check question: Given a 3-layer GCN on the Dragonfly graph, what is the effective receptive field of a node after all layers? (Answer: 3-hop neighborhood in the constructed graph)

- **Concept: Transformer Attention for Temporal Sequences**
  - Why needed here: SMART uses a transformer decoder to process the sequence of GNN embeddings. Understanding attention mechanisms helps diagnose why certain historical iterations may be over/under-weighted.
  - Quick check question: In the transformer's scaled dot-product attention, what happens to attention weights when query and key vectors are orthogonal? (Answer: Attention approaches uniform distribution via softmax)

- **Concept: Prompting Strategies for LLMs on Numerical Data**
  - Why needed here: SMART uses Prompt-as-Prefix (PaP) with statistics to guide the LLM. Understanding how prompts affect LLM behavior is critical for improving prediction accuracy.
  - Quick check question: If iteration times have a sudden regime shift (e.g., new job starts), would the current prompt template (using global min/max/median) help or hurt prediction? (Answer: Potentially hurt—global statistics may obscure recent regime changes; consider windowed statistics)

## Architecture Onboarding

- **Component map:**
  Input: Temporal graphs {G_(t-TinGNN), ..., G_(t-1)} + Historical iteration times {y_(t-TinLLM), ..., y_t}
     ↓
  [GNN Encoder (2-layer GCN)] → Node embeddings H(t) ∈ R^(|V|×128) per timestep
     ↓
  [Temporal Transformer (2 enc, 2 dec layers, 8 heads)] → Z(t) ∈ R^(|V|×128)
     ↓
  [LLM Module (GPT-2, 32 layers, 768 hidden)]
     Input: Patched iteration times + prompt prefix
     Output: E(t) ∈ R^(|Va|×768) → F(t) ∈ R^(|Va|×128) via linear projection
     ↓
  [Integration Layer] Concatenate Z(t)_a and F(t) → Linear → ŷ_(t+1)

- **Critical path:**
  1. Construct temporal graphs from router port data (aggregated over iteration windows)
  2. Run GNN encoder on each graph in the lookback window (TinGNN=2 works best)
  3. Process GNN embeddings through transformer to get temporal node embeddings
  4. In parallel, process historical iteration times through LLM with prompting (TinLLM=8 works best)
  5. Filter transformer output to active nodes, concatenate with LLM output, predict

- **Design tradeoffs:**
  - **TinGNN vs TinLLM:** Shorter TinGNN (2) works best; longer TinLLM (8) works best. Paper suggests GNN captures recent spatial dynamics while LLM captures longer temporal patterns.
  - **Online tuning (Ft=8 vs Ft=∞):** Ft=8 (update every 8 iterations) consistently improves MAPE but adds backprop overhead during inference. Trade-off depends on how stationary the workload is.
  - **LLM backbone choice:** GPT-2 was chosen; Table 12 shows Time-LLM outperforms Autoformer/DLinear on 2/3 workloads but not LAMMPS. Consider workload-specific model selection.

- **Failure signatures:**
  - **High MAPE on specific workloads:** LAMMPS shows lower MAPE than MILC (1.88% vs 3.51% on D2-Cont). Paper attributes this to MILC's higher latency sensitivity. If you see reverse pattern, check network congestion levels.
  - **Random placement worse than contiguous:** Expected, due to higher variability. If prediction degrades significantly under random placement (Tables 5 shows std dev increases 26× for LAMMPS), verify the model was trained on mixed placement data or use online tuning.
  - **Ablation reveals LLM contributes more than GNN:** On D1, removing LLM hurts more than removing GNN for some configurations. If GNN-only performs close to full model, the topology may be under-utilized—check edge construction and feature aggregation.

- **First 3 experiments:**
  1. **Replicate ablation on D1:** Train GNN-only (remove LLM, Table 8), LLM-only (remove GNN, Table 10), and full SMART. Compare MAPE to verify both components contribute. If either ablation matches full model, investigate whether the removed component is actually being used.
  2. **Hyperparameter sensitivity sweep:** Vary TinGNN ∈ {2, 4, 8}, TinLLM ∈ {2, 4, 8}, and patch length ∈ {1, 2, 4} on a held-out workload. Paper shows robustness (Figure 4), but verify on your data distribution.
  3. **Online tuning ablation:** Compare Ft=∞ (no tuning), Ft=8, and Ft=4 on D2-Rand (highest variability). Measure both MAPE improvement and inference time overhead to find practical operating point for your hybrid simulation needs.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can SMART extend its prediction capability to multi-step forecasting horizons rather than the single-step predictions currently implemented?
  - Basis in paper: [explicit] The conclusion states, "In future work, we plan to extend the model's forecasting horizon..."
  - Why unresolved: The current problem formulation defines the objective solely as predicting the next application iteration time ($y_{t+1}$) using a linear output layer.
  - What evidence would resolve it: Evaluation of prediction error (MAPE) across a range of future timesteps ($t+2, t+3, \dots$) without intermediate ground-truth corrections.

- **Open Question 2:** How well does SMART generalize to alternative network topologies, such as Fat-Tree, compared to the 1D Dragonfly topology used in this study?
  - Basis in paper: [explicit] The authors claim the "modular architecture of SMART allows for straightforward adaptation to other network topologies" like Fat Tree, but provide no experimental validation.
  - Why unresolved: All experiments are restricted to a 1,052-node 1D Dragonfly network, leaving the model's efficacy on non-Dragonfly graph structures unverified.
  - What evidence would resolve it: Benchmarking SMART against baselines using datasets generated from Fat-Tree or Torus topologies.

- **Open Question 3:** Is SMART robust to the noise and non-deterministic hardware behaviors found in physical HPC systems, given that it was trained solely on simulation data?
  - Basis in paper: [inferred] The paper relies entirely on synthetic data from CODES simulations. While the simulations are "high-fidelity," they may not capture the full stochastic nature of physical hardware (e.g., thermal throttling or transient failures).
  - Why unresolved: The model is trained and validated exclusively on flit-level PDES traces, which are idealized representations of network behavior.
  - What evidence would resolve it: A transfer learning study or validation experiment using runtime traces collected from physical Dragonfly interconnect hardware.

## Limitations

- The model's performance heavily depends on the quality of temporal graph construction from router port data, which is not fully specified in the paper (exact node features and aggregation functions are unclear).
- The LLM component, while effective, significantly increases memory requirements and may not be feasible on smaller GPU setups without modification.
- Online tuning (Ft=8) improves accuracy but adds computational overhead during inference, creating a trade-off between prediction quality and runtime efficiency that wasn't fully characterized across different workload types.

## Confidence

- **High confidence** in the overall methodology and reported MAPE improvements over baselines, supported by extensive ablation studies and hyperparameter sensitivity analysis.
- **Medium confidence** in the specific architectural choices (GNN layers=2, LLM patch size=2, etc.) as optimal, since only limited hyperparameter sweeps were reported and results may not generalize to different Dragonfly configurations.
- **Low confidence** in the model's ability to handle workloads with highly dynamic network behavior beyond the tested MILC, LAMMPS, and NN applications, as the paper doesn't explore edge cases like bursty traffic patterns or adaptive routing changes.

## Next Checks

1. **Architecture sensitivity validation**: Perform a comprehensive hyperparameter sweep on held-out validation data to verify the robustness of the reported architectural choices (TinGNN, TinLLM, patch lengths, number of GNN layers) and identify if the current settings are truly optimal or locally optimal.

2. **Scalability stress test**: Evaluate SMART's performance and memory usage on progressively larger Dragonfly networks (beyond 1,056 nodes) to assess computational complexity scaling and identify potential bottlenecks in the GNN+LLM integration.

3. **Generalization to unseen network conditions**: Test the model on synthetic workloads with controlled network interference patterns (varying congestion levels, routing algorithm changes, mixed application types) to assess robustness beyond the three workloads studied.