---
ver: rpa2
title: Hierarchical Text Classification Using Black Box Large Language Models
arxiv_id: '2508.04219'
source_url: https://arxiv.org/abs/2508.04219
tags:
- hierarchical
- classification
- text
- label
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores using black-box large language models (LLMs)\
  \ accessed via APIs for hierarchical text classification (HTC), a task where texts\
  \ are assigned to structured label hierarchies. The study evaluates three prompting\
  \ strategies\u2014Direct Leaf Label Prediction (DL), Direct Hierarchical Label Prediction\
  \ (DH), and Top-down Multi-step Hierarchical Label Prediction (TMH)\u2014in both\
  \ zero-shot and few-shot settings."
---

# Hierarchical Text Classification Using Black Box Large Language Models

## Quick Facts
- arXiv ID: 2508.04219
- Source URL: https://arxiv.org/abs/2508.04219
- Reference count: 21
- Primary result: Few-shot prompting improves LLM HTC accuracy, with DH strategy best for deep hierarchies

## Executive Summary
This paper investigates using black-box large language models (LLMs) accessed via APIs for hierarchical text classification (HTC), where texts are assigned to structured label hierarchies. The study evaluates three prompting strategies—Direct Leaf Label Prediction (DL), Direct Hierarchical Label Prediction (DH), and Top-down Multi-step Hierarchical Label Prediction (TMH)—in both zero-shot and few-shot settings. Experiments on two datasets show that few-shot prompting consistently improves accuracy compared to zero-shot, and LLMs, especially the DH strategy, tend to outperform traditional machine learning models on deeper hierarchies. However, API costs increase significantly due to higher input tokens required for deeper hierarchies, highlighting a trade-off between accuracy and computational cost.

## Method Summary
The paper applies black-box LLMs to hierarchical text classification using three prompting strategies: DL (predict leaf labels only), DH (predict full hierarchical paths in one shot), and TMH (predict level-by-level with constrained candidates). Experiments use GPT-4o-mini on two datasets with 2-3 level hierarchies, comparing zero-shot and few-shot (1-20 examples) settings. Performance is measured via per-level accuracy and conditional accuracy metrics, with cost analysis based on input and output token counts.

## Key Results
- Few-shot prompting consistently improves classification accuracy compared to zero-shot across all strategies
- LLMs, especially DH strategy, outperform traditional ML models on deeper hierarchies
- API costs increase significantly with hierarchy depth due to higher input token requirements
- DH strategy achieves highest accuracy on 3-level hierarchy (APR dataset) but at highest token cost

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Few-shot prompting improves HTC accuracy over zero-shot by providing in-context label space grounding.
- **Mechanism:** Labeled examples in the prompt condition the model on the specific label vocabulary and task framing, reducing ambiguity about what categories exist and how they should be applied.
- **Core assumption:** The LLM's pre-training distribution overlaps sufficiently with the domain; examples primarily refine task specification rather than transfer new knowledge.
- **Evidence anchors:** [abstract]: "few-shot setting consistently improves classification accuracy compared to a zero-shot setting"; [section 5.2, Table 2/3]: ACC improvements from 0-shot to 5-shot across all strategies.

### Mechanism 2
- **Claim:** Direct Hierarchical Label Prediction (DH) strategy outperforms alternatives on deeper hierarchies by explicitly encoding path structure in candidate labels.
- **Mechanism:** Formatting candidates as "Parent > Child" paths makes hierarchical relationships visible to the LLM in a single forward pass, allowing joint reasoning about parent-child coherence.
- **Core assumption:** The LLM can parse and reason about structured delimiter-separated paths; path format is understood from pre-training or prompt instructions.
- **Evidence anchors:** [abstract]: "LLMs, especially DH strategy, tend to outperform the machine learning model on a dataset with a deeper hierarchy"; [section 5.2, Table 3]: DH achieves ACC₁=0.868 on APR (3-level hierarchy) vs. DL's 0.690.

### Mechanism 3
- **Claim:** Top-down Multi-step (TMH) strategy preserves hierarchical consistency at deeper levels by conditioning child predictions on correct parent predictions.
- **Mechanism:** Sequential level-by-level prediction with constrained candidate sets reduces the effective label space at each step, trading some first-level accuracy for higher conditional accuracy at deeper levels.
- **Core assumption:** Parent predictions are sufficiently accurate to avoid cascading errors; the Levenshtein distance fallback adequately handles label matching failures.
- **Evidence anchors:** [section 5.2, Table 3]: TMH achieves highest P(pTrue₃|pTrue₂)=0.853 at 20-shot on APR, suggesting strong consistency when parents are correct.

## Foundational Learning

- **Concept: Hierarchical Text Classification (HTC)**
  - **Why needed here:** The entire paper is defined by this task—classifying text into labels organized as a DAG (typically a tree), where predictions may be evaluated at each depth level separately or as full paths.
  - **Quick check question:** Given a taxonomy "Science > Biology > Genetics," would predicting only "Genetics" be sufficient, or must the full path be correct for a true positive?

- **Concept: In-Context Learning / Few-Shot Prompting**
  - **Why needed here:** The core intervention is providing 1–20 labeled examples in the prompt to improve classification without fine-tuning. Understanding how examples condition model behavior is essential.
  - **Quick check question:** If you double the number of few-shot examples from 10 to 20, should you expect linear accuracy gains? Why or why not?

- **Concept: Token Economics for API-Based LLMs**
  - **Why needed here:** The paper explicitly analyzes cost tradeoffs; prompt tokens scale with hierarchy depth and few-shot count, while completion tokens remain stable. Cost-aware prompting strategy selection is a practical constraint.
  - **Quick check question:** For a 3-level hierarchy with 300 leaf labels, which strategy (DL, DH, or TMH) would likely incur the highest input token cost per query at 5-shot?

## Architecture Onboarding

- **Component map:** DL: Input text + examples + all leaf labels → single prompt → normalized output → label mapping
- **Critical path:** Parse hierarchy → construct prompt based on strategy and few-shot count → call LLM API → normalize output → map to labels → compute accuracy metrics
- **Design tradeoffs:** Accuracy vs. Cost (DH best accuracy but highest cost); Depth vs. Robustness (shallow favor simple models, deep favor hierarchy-aware); Simplicity vs. Consistency (DL simplest but loses consistency, TMH enforces but risks errors)
- **Failure signatures:** Label mismatch (addressed by normalization and Levenshtein matching); Cost explosion (prompt tokens exceed budget for deep hierarchies); Cascading errors in TMH (wrong parent guarantees child failure); Overfitting to few-shot examples (diminishing returns beyond 5–10 shots)
- **First 3 experiments:** 1) Baseline comparison on your dataset: Implement DL, DH, TMH with 0-shot and 5-shot; compare ACC and token costs. 2) Few-shot scaling curve: Test 0, 1, 3, 5, 10, 20-shot for best strategy; plot accuracy vs. cost. 3) Error analysis on hierarchical consistency: Compute ratio of child errors following correct vs. incorrect parents in TMH.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the Direct Hierarchical (DH) prompting strategy perform on label hierarchies significantly deeper than the two- to three-level structures tested in this study?
- **Basis in paper:** [explicit] The authors state in the conclusion, "Our analysis was limited to... datasets with only two- to three-depth hierarchies. While deeper hierarchies may benefit from DH, further experiments on more complex datasets are needed."
- **Why unresolved:** It remains unclear if the accuracy improvements observed in the DH strategy scale linearly or degrade due to context window limitations and prompt complexity as the hierarchy depth increases.
- **What evidence would resolve it:** Experimental results applying the three prompting strategies to datasets with five or more hierarchical levels, measuring accuracy and token cost relative to depth.

### Open Question 2
- **Question:** How does the cost-effectiveness of black-box API prompting compare to fine-tuning open-source "white box" LLMs for hierarchical text classification?
- **Basis in paper:** [explicit] The authors explicitly list this as a limitation: "restricting the study to black box LLMs limits our findings; future work should include... fine-tuned white box LLMs to better understand cost-effectiveness and performance trade-offs."
- **Why unresolved:** The study focused solely on inference costs (API tokens) using GPT-4o-mini, without comparing the upfront computational costs of training or fine-tuning self-hosted models against the long-term costs of API usage.
- **What evidence would resolve it:** A comparative analysis measuring total operational cost (training + inference) and accuracy between few-shot API calls and fine-tuned open-source models (e.g., Llama) on identical HTC tasks.

### Open Question 3
- **Question:** Can the Top-down Multi-step (TMH) strategy be improved to prevent error propagation without relying on simple string-matching heuristics like Levenshtein distance?
- **Basis in paper:** [inferred] The paper notes that in the TMH strategy, if the LLM outputs a label not in the candidate set, the system identifies the "closest matches using Levenshtein distance," suggesting the LLM frequently fails to adhere strictly to the provided label schema.
- **Why unresolved:** The reliance on a post-hoc string distance fix indicates the LLM often hallucinates or reformats labels, which introduces noise and potential errors in subsequent hierarchical steps.
- **What evidence would resolve it:** An ablation study comparing the current Levenshtein fallback against constrained decoding techniques or error-correcting prompts to measure the reduction in error propagation rates.

## Limitations
- Evaluation limited to two datasets with only 2-3 level hierarchies
- No analysis of LLM model variability (different models, parameter sizes)
- Cost analysis based on token counts rather than real billing data
- Levenshtein fallback in TMH may mask systematic prediction errors

## Confidence

- **High**: Few-shot prompting consistently improves accuracy over zero-shot across all strategies and datasets
- **Medium**: DH strategy outperforms alternatives on deeper hierarchies; TMH maintains consistency at deeper levels when parents are correct
- **Low**: Cost scaling predictions accurately reflect real API billing; TMH's Levenshtein matching adequately handles all prediction mismatches

## Next Checks

1. **Cross-dataset hierarchy depth validation**: Test all three strategies on datasets with 4+ hierarchy levels (e.g., patent classification or product taxonomies) to confirm DH's advantage on deeper structures and identify the depth threshold where TMH becomes preferable.

2. **Cost-benefit tradeoff analysis with real billing**: Measure actual API costs (including per-token pricing variations across models) versus accuracy gains for each strategy at different few-shot settings to identify optimal cost-performance points.

3. **Error propagation isolation in TMH**: Design an experiment where parent predictions are held constant (using oracle parents) while varying child prediction strategies to quantify how much of TMH's accuracy comes from parent quality versus the multi-step approach itself.