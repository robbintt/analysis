---
ver: rpa2
title: 'ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme
  Weather Analytics'
arxiv_id: '2504.19066'
source_url: https://arxiv.org/abs/2504.19066
tags:
- weather
- extreme
- reasoning
- ewra
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ClimaEmpact, a framework for extreme weather
  analytics using small language models (SLMs). It combines ExtremeWeatherNews, a
  dataset of news articles for 60 extreme weather events, and EWRA, a reasoning-aware
  alignment method that transfers advanced reasoning capabilities from LLMs to SLMs.
---

# ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics

## Quick Facts
- arXiv ID: 2504.19066
- Source URL: https://arxiv.org/abs/2504.19066
- Reference count: 40
- Primary result: EWRA outperforms standard fine-tuning, achieving 5.2% improvement in Spearman correlation for vulnerability/impact/emergency assessment

## Executive Summary
ClimaEmpact introduces a framework for extreme weather analytics using small language models (SLMs) through domain-aligned reasoning. The system combines ExtremeWeatherNews (127k sentences from 60 events) with EWRA (Extreme Weather Reasoning Alignment), a two-stage curriculum fine-tuning method. EWRA transfers advanced reasoning from LLMs to SLMs by first training on implicit reasoning prompts then explicit ones with definitions. The framework addresses three ranking tasks: vulnerability/impact assessment, topic labeling, and emotion analysis. Experiments show 3B models with EWRA outperform both smaller models and standard fine-tuning baselines, achieving strong correlation with human judgments while maintaining computational efficiency.

## Method Summary
The framework uses Qwen2.5-3B-Instruct with LoRA fine-tuning trained on ExtremeAlign, a dataset of 30k samples generated by Qwen2.5-32B-Instruct. Training follows a two-stage curriculum: implicit prompts (reasoning without rigid definitions) for one epoch, then explicit prompts (with definitions) for one epoch. The method uses QK-only attention matrix updates while freezing value matrices and MLPs to preserve factual knowledge. Input data comes from scraped Google News RSS feeds filtered by Flair NER for location mentions. Evaluation uses Spearman correlation for ranking tasks, Jaccard index for topic coverage, and BERTScore for explanation quality.

## Key Results
- EWRA achieves 5.2% improvement in Spearman correlation over ReasonExplicit-SFT for vulnerability/impact/emergency assessment
- 3B model outperforms 1.5B model significantly (0.8230 vs 0.7140 SRC on Vulnerability task)
- EWRA shows higher BERTScore (0.9161) compared to Direct-SFT (0.7910) on explanation quality
- Zero-shot approach dominates EWRA on subtopic labeling recall, suggesting coverage limitations

## Why This Works (Mechanism)

### Mechanism 1: Curriculum Order Effect
The two-stage implicit-to-explicit curriculum improves performance by first developing flexible reasoning patterns before enforcing strict definitions. This prevents premature overfitting to rigid templates. Evidence shows ReverseEWRA degrades performance (SRC drops from 0.8230 to 0.7070), confirming order matters. The mechanism assumes SLMs need unstructured reasoning warm-up before precision training.

### Mechanism 2: Process-Level Alignment
By aligning SLMs to generate intermediate reasoning tokens rather than just final labels, the model develops richer internal representations. Standard fine-tuning maps input→label, while EWRA maps input→[reasoning, label]. This creates better semantic alignment with human evaluators. The approach assumes teacher LLM reasoning is high-quality enough to serve as ground truth.

### Mechanism 3: Selective Parameter Updates
QK-only fine-tuning preserves pre-trained factual knowledge while adapting reasoning dynamics. The hypothesis is that factual knowledge resides in value matrices/MLPs while reasoning is managed by query/key matrices. This allows domain adaptation without catastrophic forgetting. The approach assumes knowledge and reasoning are sufficiently disentangled in transformer architectures.

## Foundational Learning

- **Concept: Curriculum Learning**
  - Why needed: EWRA relies on specific training order (Implicit then Explicit) as a hyperparameter
  - Quick check: If trained on Explicit data first, would the model learn definitions faster or just memorize format?

- **Concept: Knowledge Distillation vs. Reasoning Alignment**
  - Why needed: This paper distinguishes itself by matching process (tokens) not just outputs (logits)
  - Quick check: Why is generating reasoning tokens computationally more expensive than label prediction?

- **Concept: Spearman Rank Correlation**
  - Why needed: Authors avoid accuracy for ranking metric since vulnerability is probability distribution
  - Quick check: Why might Spearman be better than exact match accuracy for [0.9,0.05,0.05] vs [0.8,0.1,0.1]?

## Architecture Onboarding

- **Component map:** Google News RSS feeds & Newspaper3k -> Flair NER filtering -> Qwen2.5-32B-Instruct rationale generation -> ExtremeAlign dataset -> Qwen2.5-3B-Instruct with LoRA -> Dashboard output

- **Critical path:** Alignment data generation - 32B model takes 1 min per sample, creating potential bottleneck

- **Design tradeoffs:**
  - SLM Size: 3B outperforms 1.5B (0.8230 vs 0.7140 SRC) but needs more VRAM
  - Fine-tuning vs RAG: Chose fine-tuning over RAG to reduce hallucination for nuanced queries

- **Failure signatures:**
  - Zero-shot dominance on subtopic labeling (0.7727 vs 0.7149) suggests EWRA suppresses label coverage
  - Reverse curriculum causes performance collapse (SRC drops from 0.823 to 0.707)

- **First 3 experiments:**
  1. Verify "Implicit First" hypothesis by training two models with EWRA vs ReverseEWRA order
  2. Probe QK vs Full fine-tuning by comparing hallucination rates in factual content
  3. Check label coverage by comparing unique subtopics predicted by Zero-shot vs EWRA

## Open Questions the Paper Calls Out

1. Can EWRA extend to generative tasks like temporal summarization and scenario simulation?
2. How to optimize curriculum ordering when different tasks prefer different training orders?
3. How well does EWRA generalize across linguistic and geographical contexts beyond English?
4. Does domain-aligned fine-tuning outperform RAG approaches in reducing hallucinations?

## Limitations

- Dataset limited to 60 events from 2022-2023, raising generalizability concerns for other timeframes and regions
- Entire framework depends on teacher model quality without validation of generated reasoning
- Performance characteristics on out-of-distribution events (different years/regions) remain untested

## Confidence

**High Confidence**
- EWRA's two-stage curriculum provides measurable benefits over reversed ordering and standard fine-tuning
- QK-only fine-tuning preserves factual knowledge while adapting reasoning capabilities
- Framework achieves state-of-the-art results on defined tasks within test set

**Medium Confidence**
- Teacher LLM reasoning quality is sufficient for effective SLM alignment
- Performance gaps would persist when scaled to different domains or extended timeframes
- Fine-tuning trade-off is optimal for this domain over RAG approaches

**Low Confidence**
- Performance on out-of-distribution events would match in-distribution performance
- Zero-shot dominance reflects fundamental EWRA limitation rather than evaluation artifact
- Computational efficiency gains remain significant at scale with real-time requirements

## Next Checks

1. Evaluate trained EWRA model on 2020-2021 and 2024 events to assess temporal generalization
2. Implement human validation for 10% of teacher-generated alignment data to identify systematic biases
3. Test EWRA framework with multi-modal inputs combining text with satellite imagery or meteorological data