---
ver: rpa2
title: 'MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue
  Resolution'
arxiv_id: '2506.12728'
source_url: https://arxiv.org/abs/2506.12728
tags:
- reasoning
- issue
- resolution
- data
- localization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MCTS-R EFINE , an enhanced Monte Carlo Tree
  Search (MCTS) algorithm that generates high-quality Chain-of-Thought (CoT) data
  for large language models (LLMs) in repository issue resolution tasks. The approach
  addresses two key limitations in existing methods: inadequate rejection sampling
  mechanisms and lack of systematic validation for intermediate reasoning steps.'
---

# MCTS-Refined CoT: High-Quality Fine-Tuning Data for LLM-Based Repository Issue Resolution

## Quick Facts
- arXiv ID: 2506.12728
- Source URL: https://arxiv.org/abs/2506.12728
- Authors: Yibo Wang; Zhihao Peng; Ying Wang; Zhao Wei; Hai Yu; Zhiliang Zhu
- Reference count: 40
- Primary result: MCTS-R EFINE generates high-quality CoT data that enables LLMs to achieve SOTA performance on SWE-bench Lite (28.3%) and Verified (35.0%) repositories

## Executive Summary
This paper introduces MCTS-REFINE, an enhanced Monte Carlo Tree Search algorithm that generates high-quality Chain-of-Thought data for large language models in repository issue resolution tasks. The approach addresses key limitations in existing methods by employing exact-match rejection sampling and a reflection mechanism that dynamically validates and corrects intermediate reasoning steps. By decomposing issue resolution into three verifiable subtasks—File Localization, Fault Localization, and Patch Generation—the framework ensures granular quality control throughout the reasoning process. Experiments demonstrate that LLMs fine-tuned with MCTS-REFINE-generated data achieve state-of-the-art performance on SWE-bench benchmarks.

## Method Summary
MCTS-REFINE modifies standard MCTS by replacing the simulation phase with rejection sampling and refinement. The framework generates CoT data through a five-phase loop: Selection (UCB-based traversal), Expansion (generating b=3 child nodes with LLM-assigned rewards), Rejection Sampling (exact-match validation against ground truth), Refinement (Feedback and Optimization sub-phases for error correction), and Backpropagation (updating visit counts with α=0.5 weighting). The approach uses DeepSeek-v3 for CoT synthesis and enforces strict sampling protocols where intermediate outputs must exactly match verified developer patches. The resulting dataset is used for supervised fine-tuning of Qwen2.5 models, achieving superior performance on SWE-bench Lite and Verified benchmarks.

## Key Results
- Fine-tuned Qwen2.5-72B-Instruct achieves 28.3% resolution rate on SWE-bench Lite and 35.0% on SWE-bench Verified
- MCTS-REFINE data enables 81.8% file localization, 68.0% function localization, and 63.0% line localization accuracy on 72B model
- Strict exact-match filtering produces higher quality training data than soft metrics (Jaccard Similarity, CodeBLEU)
- Performance surpasses baseline SWE-Fixer-Qwen-72B on both SWE-bench Lite and Verified benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Exact-Match Rejection Sampling Filters Defective Reasoning Chains
Strict exact-match validation against ground truth removes CoT instances containing erroneous intermediate steps that soft metrics fail to detect. The system samples only reasoning paths where outputs precisely match verified developer patches, eliminating "near-miss" CoT data that appears semantically similar but contains logical errors.

### Mechanism 2: Reflection Phase Enables Intermediate Error Correction
Augmenting MCTS with a reflection mechanism (Feedback + Optimization sub-phases) corrects reasoning errors during search rather than discarding entire paths. After expansion, the Feedback sub-phase compares the current reasoning path against ground truth to generate corrective suggestions, while the Optimization sub-phase modifies only the current step while preserving the reasoning chain structure.

### Mechanism 3: Subtask Decomposition Provides Verifiable Intermediate Ground Truth
Decomposing issue resolution into File Localization → Fault Localization → Patch Generation with independent ground-truth criteria enables granular quality control. Each subtask has unambiguous success criteria (exact file match, exact method/class match, exact patch match), ensuring models learn correct reasoning at each stage rather than end-to-end guessing.

## Foundational Learning

- Concept: Monte Carlo Tree Search (Selection, Expansion, Simulation, Backpropagation)
  - Why needed here: MCTS-REFINE modifies standard MCTS by replacing Simulation with Rejection Sampling + Refinement; understanding the base algorithm is prerequisite.
  - Quick check question: Can you explain why UCB balances exploration vs exploitation in node selection?

- Concept: Chain-of-Thought (CoT) Prompting and Data Quality
  - Why needed here: The paper's central claim is that CoT quality—not quantity—determines fine-tuning success; understanding what constitutes "quality" CoT is essential.
  - Quick check question: What distinguishes a high-quality CoT from one with correct output but flawed intermediate reasoning?

- Concept: Supervised Fine-Tuning vs. Reinforcement Learning for Code Tasks
  - Why needed here: The paper uses SFT on MCTS-generated CoT; understanding why SFT (not RL) is chosen clarifies the data-quality-first philosophy.
  - Quick check question: Why might SFT on filtered CoT outperform RL with imperfect reward signals for issue resolution?

## Architecture Onboarding

- Component map: Input (issue + repo context) → Subtask Selection → MCTS loop (Selection → Expansion → Rejection Sampling → Refinement → Backpropagation) → Accepted CoT → Fine-tuning dataset (MCOT)

- Critical path: Input (issue + repo context) → Subtask Selection → MCTS loop (up to T=50 iterations) → Accepted CoT → Fine-tuning dataset (MCOT)

- Design tradeoffs:
  - Exact-match filtering: Higher precision but potentially lower data yield vs. soft metrics
  - Branching factor b=3: Broader exploration vs. computational cost
  - Maximum iterations T=50: Thorough search vs. generation time
  - LoRA for 72B (due to compute constraints): Lower cost vs. potentially suboptimal vs. full fine-tuning

- Failure signatures:
  - Low data retention after exact-match filtering indicates overly strict criteria or weak base model
  - Refinement phase generates contradictory feedback (oscillation without convergence)
  - Disproportionate success on localization vs. patch generation suggests subtask imbalance

- First 3 experiments:
  1. Reproduce data synthesis: Run MCTS-REFINE on 1,000 issue-PR pairs; measure retention rate and iteration-to-acceptance distribution
  2. Ablate reflection: Compare full MCTS-REFINE vs. MCTS without Refinement phase on SWE-bench Verified subset (n=100)
  3. Localization-only evaluation: Test fine-tuned models on File/Fault Localization accuracy before end-to-end issue resolution to isolate subtask contributions

## Open Questions the Paper Calls Out

### Open Question 1
Does full-parameter fine-tuning of the 72B model significantly outperform the LoRA-based adaptation used in this study? The authors state, "replacing LoRA with full-parameter fine-tuning on our CoT dataset could further improve the model's issue resolution capability," citing computational constraints as the reason for using LoRA.

### Open Question 2
Can the CoT data generated by MCTS-REFINE effectively generalize to agent-based frameworks (e.g., OpenHands) in addition to the pipeline-based AGENTLESS framework? The paper evaluates performance exclusively within the AGENTLESS pipeline framework.

### Open Question 3
How does the computational cost and data generation latency of MCTS-REFINE compare to single-turn prompting methods when scaling beyond the 20,000 sample subset? The authors mention selecting 20,000 Issue-PR pairs specifically to "reduce computational overhead" and limit MCTS iterations to T=50.

## Limitations

- Dataset Generalization: The study relies on SWE-Fixer-Train-110K and SWE-bench benchmarks, which may not fully represent the diversity of real-world repository issues.

- Reflection Mechanism Robustness: The paper claims the reflection phase corrects errors without introducing new ones, but provides limited empirical evidence for multi-step corrections.

- Scalability to Larger Models: While MCTS-REFINE works with 72B models using LoRA, the computational cost of generating training data scales with model size, with viability for models larger than 72B uncertain.

## Confidence

- High Confidence: The decomposition of issue resolution into three verifiable subtasks with clear ground-truth criteria is well-justified and technically sound.
- Medium Confidence: The claim that exact-match filtering produces higher quality training data than soft metrics is supported but could benefit from ablation studies on downstream performance.
- Low Confidence: The assertion that reflection corrections are consistently reliable without introducing downstream errors lacks sufficient empirical validation in the paper.

## Next Checks

1. Error Propagation Analysis: Track whether corrections made in the reflection phase introduce new errors in subsequent reasoning steps across 1,000 randomly sampled CoT instances.

2. Data Yield Quantification: Measure the exact acceptance rate after rejection sampling and analyze whether the strict criteria result in insufficient training data for certain subtask types.

3. Cross-Benchmark Transfer: Evaluate models fine-tuned with MCTS-REFINE data on alternative repositories and issue types not present in SWE-bench to assess generalization limits.