---
ver: rpa2
title: Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis
arxiv_id: '2510.13437'
source_url: https://arxiv.org/abs/2510.13437
tags:
- fuzzy
- rule
- systems
- rules
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a novel hybrid fuzzy regression approach,\
  \ HIT2-MTSK, which combines the interpretability of Mamdani systems with the accuracy\
  \ of TSK models. The method introduces a dual-component rule structure with both\
  \ fuzzy and crisp (TSK function) parts, along with two dominance types\u2014one\
  \ for fuzzy and one for crisp components\u2014to enhance both accuracy and explainability."
---

# Hybrid Interval Type-2 Mamdani-TSK Fuzzy System for Regression Analysis

## Quick Facts
- **arXiv ID:** 2510.13437
- **Source URL:** https://arxiv.org/abs/2510.13437
- **Reference count:** 10
- **Primary result:** HIT2-MTSK outperforms traditional fuzzy methods on 4 out of 6 benchmark datasets with RMSE improvements ranging from 0.4% to 19%

## Executive Summary
This paper proposes HIT2-MTSK, a novel hybrid fuzzy regression approach that combines the interpretability of Mamdani systems with the accuracy of TSK models. The method introduces a dual-component rule structure with both fuzzy and crisp (TSK function) parts, along with two dominance types—one for fuzzy and one for crisp components—to enhance both accuracy and explainability. The approach uses interval type-2 fuzzy sets for fuzzification and Ant Colony Optimization (ACO) for rule selection. Experiments on six benchmark datasets show HIT2-MTSK outperforms traditional fuzzy methods in 4 out of 6 datasets and achieves the best overall score in 1 dataset, with RMSE improvements ranging from 0.4% to 19%. The method is further validated on the California Housing dataset, demonstrating superior performance over Mamdani FRBS and other explainable models while maintaining interpretability.

## Method Summary
HIT2-MTSK combines Mamdani-style linguistic interpretability with TSK mathematical precision through a hybrid rule structure. The method uses interval type-2 fuzzy sets for fuzzification, generating three linguistic terms (Low, Medium, High) per feature based on data distribution. Each rule contains both a fuzzy label (Mamdani) and a polynomial function (TSK), where the TSK output is constrained within the bounds of the corresponding fuzzy set to maintain interpretability. Ant Colony Optimization selects an optimal subset of rules based on dual dominance weights—one measuring fuzzy support/confidence and another measuring inverse RMSE. The final prediction is computed as a weighted average of rule outputs using firing strengths and rule weights, with TSK coefficients trained only on samples where rule firing strength exceeds zero.

## Key Results
- HIT2-MTSK outperformed traditional fuzzy methods on 4 out of 6 benchmark datasets
- RMSE improvements ranged from 0.4% to 19% compared to baseline methods
- The approach achieved the best overall score on 1 dataset (California Housing)
- California Housing validation showed superior performance over Mamdani FRBS while maintaining interpretability

## Why This Works (Mechanism)

### Mechanism 1: Bounded TSK Output for Interpretability
The system constrains the crisp output of TSK rules within the bounds of Mamdani fuzzy sets, preserving linguistic interpretability while increasing precision. This prevents linguistically nonsensical predictions while avoiding the coarse granularity of pure centroid defuzzification. The assumption is that the TSK function is well-tuned enough that its raw output usually falls within valid bounds, making clipping a safeguard rather than a constant distorter.

### Mechanism 2: Dual Dominance Weighting
The system assigns two weights to each rule: one based on fuzzy support/confidence and another based on inverse RMSE. This balances data coverage with local precision, preventing selection of rules that are merely popular but imprecise or mathematically accurate but only applicable to outliers. The assumption is that optimizing for these two metrics simultaneously leads to better generalization than optimizing for accuracy alone.

### Mechanism 3: ACO for Rule Selection
Ant Colony Optimization prunes redundant rules by selecting subsets that minimize global RMSE. Pheromone trails reinforce effective rule combinations while evaporation removes poorly performing rules. The assumption is that the combinatorial search space is small enough for ACO to navigate effectively without getting stuck in local optima.

## Foundational Learning

- **Concept: Mamdani vs. TSK Fuzzy Inference**
  - **Why needed here:** The core contribution is hybridizing these two types. Mamdani outputs are fuzzy sets (good for words, bad for precision), while TSK outputs are linear equations (good for precision, bad for explainability).
  - **Quick check question:** If a rule outputs $y = 2x + 3$, is it Mamdani or TSK? (Answer: TSK)

- **Concept: Interval Type-2 (IT2) Fuzzy Sets**
  - **Why needed here:** The paper uses IT2 sets to handle uncertainty with upper and lower membership functions (Footprint of Uncertainty) rather than single crisp values.
  - **Quick check question:** Does an Interval Type-2 set represent the membership grade as a single number or an interval? (Answer: Interval)

- **Concept: Rule Firing Strength (T-norm)**
  - **Why needed here:** To understand how the TSK equation is conditioned on fuzzy input. Firing strength determines rule contribution to the final weighted average.
  - **Quick check question:** If a rule has two antecedents with membership grades 0.8 and 0.5, what is the firing strength using minimum T-norm? (Answer: 0.5)

## Architecture Onboarding

- **Component map:** Numerical data -> IT2 Fuzzification -> Hybrid Rule Generation -> ACO Selection -> Weighted Inference
- **Critical path:** The definition of TSK Consequent bounds. TSK coefficients are trained only on samples where rule firing strength > 0. Small or noisy subsets lead to unstable local equations.
- **Design tradeoffs:**
  - Polynomial Degree (D2 vs. D3): Higher order increases precision on complex data but risks overfitting on simple data
  - Rule Granularity: More fuzzy sets increase resolution but exponentially increase rule base size, slowing down ACO
- **Failure signatures:**
  - Horizontal Banding: Discrete steps in output indicate TSK component may not be active
  - Boundary Clipping: Predictions clustering at fuzzy set min/max values indicate TSK extrapolation being clamped
- **First 3 experiments:**
  1. **Sanity Check (Concrete Dataset):** Replicate result to confirm bounding logic implementation
  2. **Ablation on Polynomial Order:** Run Diabetes dataset with D2 and D3 to understand TSK sensitivity
  3. **Visual Inspection (California Housing):** Plot Actual vs. Predicted to verify hybrid mechanism smoothing output distribution

## Open Questions the Paper Calls Out

### Open Question 1
Can alternative meta-heuristic optimization techniques outperform Ant Colony Optimization in selecting the optimal rule subset? The paper suggests future research could focus on optimization enhancements through other approaches such as meta-heuristic techniques, but ACO was the only method benchmarked.

### Open Question 2
Does tailored pre-processing and feature selection significantly improve performance on datasets with limited input features? The authors suggest domain-specific adaptations for future work, noting the Diabetes dataset was inherently limited in input features, but experiments used datasets directly without domain-specific pre-processing.

### Open Question 3
What is the optimal method for determining the polynomial degree of the TSK component to prevent overfitting? The paper shows D2 outperformed D3 on Diabetes, suggesting higher complexity may not always lead to better results, but does not propose a mechanism to adaptively select degree based on data characteristics.

## Limitations
- Exact implementation details of IT2 fuzzification parameters and ACO hyperparameters are not fully specified
- The bounding mechanism may lead to output clipping if TSK consistently extrapolates beyond linguistic boundaries
- Dual dominance weighting may struggle with datasets exhibiting strong inverse correlations between coverage and accuracy
- The claim of improved interpretability requires more rigorous qualitative validation beyond quantitative metrics

## Confidence

- **High Confidence:** The general hybrid architecture combining Mamdani interpretability with TSK precision is well-founded in fuzzy systems literature. ACO for rule selection is a standard optimization approach.
- **Medium Confidence:** Experimental results showing HIT2-MTSK outperforming traditional methods on 4/6 datasets are compelling, though small sample size limits generalizability. RMSE improvements (0.4% to 19%) are meaningful but require independent replication.
- **Low Confidence:** The specific mechanism by which the bounding equation preserves interpretability without significantly degrading accuracy is not empirically validated beyond reported results. The claim that this approach maintains explainability while achieving superior accuracy needs more rigorous qualitative assessment.

## Next Checks
1. **Sanity Check on Polynomial Degree Sensitivity:** Run Diabetes dataset with both D2 and D3 variants to verify if higher-order polynomials cause overfitting as suggested.
2. **Visual Analysis of Prediction Distribution:** Train on California dataset and create actual vs. predicted scatter plots to check for horizontal banding or boundary clipping effects.
3. **Ablation Study on Dual Dominance:** Implement variants with only fuzzy support weighting and only error-based weighting to quantify each component's contribution to overall performance.