---
ver: rpa2
title: 'Computational Blueprints: Generating Isomorphic Mathematics Problems with
  Large Language Models'
arxiv_id: '2511.07932'
source_url: https://arxiv.org/abs/2511.07932
tags:
- problem
- problems
- generation
- isomorphic
- cbit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles the challenge of generating mathematically isomorphic
  variants of practice problems for personalized education, aiming to provide scalable,
  pedagogically valid exercises. Existing automatic problem generation methods lack
  guarantees of correctness and structural consistency for direct educational deployment,
  often requiring costly expert verification.
---

# Computational Blueprints: Generating Isomorphic Mathematics Problems with Large Language Models

## Quick Facts
- **arXiv ID:** 2511.07932
- **Source URL:** https://arxiv.org/abs/2511.07932
- **Reference count:** 25
- **Key outcome:** Framework shifts LLM from generating individual problems to producing executable generator programs, achieving 17.8% lower error rate than expert-authored items in deployment.

## Executive Summary
This work addresses the challenge of generating mathematically isomorphic variants of practice problems for personalized education. Traditional automatic problem generation lacks guarantees of correctness and structural consistency, requiring costly expert verification. The authors propose the Isomorphic Math Problem Generation (IMPG) task, supported by a benchmark dataset and automatic verification toolkit. Their framework, Computational Blueprints for Isomorphic Twins (CBIT), decomposes generation into symbolic constraint encoding and deterministic text realization, achieving superior accuracy and cost-effectiveness while maintaining high success rates even for difficult problems.

## Method Summary
The CBIT framework transforms the LLM's role from producing individual problems to authoring computational generators. The process involves: (1) extracting problem templates with variable slots, (2) generating skeleton code with placeholder variables, (3) prompting an LLM to complete the constraint logic ensuring mathematical relationships, and (4) executing the resulting program with different seeds to produce verified isomorphic variants. This approach embeds correctness in the program logic itself, eliminating the need for separate post-hoc verification.

## Key Results
- CBIT achieves 0.83 Mean Per-Problem Success Rate (MPSR) at K=100 variants vs. 0.32 for BIT and 0.01 for AIC-Batch
- Cost per success (CPS) of 6.0 tokens compared to 50.0 for AIC-Batch and 30.7 for BIT
- Large-scale deployment to 6,732 learners demonstrated 17.8% lower error rate than expert-authored items
- Success rate maintained even for difficult problems with tight mathematical relationships

## Why This Works (Mechanism)

### Mechanism 1: Meta-Level Program Synthesis
Shifting LLM output from direct problem text to executable generator programs improves both correctness and cost-efficiency at scale. The LLM authors a parameterized program (the "blueprint") that, when executed with different random seeds, deterministically produces verified isomorphic variants. Mathematical correctness is embedded in the program logic itself rather than verified post-hoc.

### Mechanism 2: Template-Driven Structural Isomorphism
Enforcing template-guided text realization from symbolic abstractions guarantees structural consistency across all generated variants. Source problems are decomposed into invariant linguistic templates and variable numerical slots. The LLM generates only symbolic abstractions (numerical values satisfying constraints), which are deterministically interpolated into fixed templates.

### Mechanism 3: Constraint-Embedded Generation
Encoding symbolic relationships as program constraints eliminates the verification-rejection cycle and guarantees correctness by construction. Rather than generating first and verifying second, CBIT requires the generator program to only produce values satisfying encoded relationships. Verification becomes intrinsic to execution.

## Foundational Learning

- **Isomorphic Problem Generation**: Understanding that "isomorphic" means preserving mathematical structure while varying only surface numerical values—not creating novel problems. *Quick check:* Given "If 3x + 5 = 14, find x," would changing coefficients to 2x + 7 = 15 produce an isomorphic problem?

- **Symbolic Constraint Encoding**: The framework relies on expressing mathematical relationships as formal constraints that programs can verify—e.g., "the roots must sum to the coefficient" expressed as `sy_05 = sy_08 + sy_09`. *Quick check:* For a problem about two dice, what symbolic constraint ensures the sum equals 7?

- **Template-Slot Decomposition**: Separating fixed linguistic structure from variable numerical slots is the architectural foundation enabling deterministic text realization. *Quick check:* In "A train travels ___ miles in ___ hours at constant speed," which parts belong to the template vs. slots?

## Architecture Onboarding

- **Component map**: Original problem (Q, S, A tuple) → Template extractor → Skeleton code generator → LLM Layer → Generator program → Execution Layer → Symbolic abstractions → Template interpolator → Isomorphic problems
- **Critical path**: Template extraction from source problem → Skeleton code generation → LLM completes constraint logic → Generator program execution produces infinite verified variants
- **Design tradeoffs**: Higher initial effort (template/skeleton creation) but near-zero marginal cost per problem generated; sacrifices creative variation for mathematical correctness and structural consistency; generator programs are human-readable and editable
- **Failure signatures**: Constraint over-specification (zero valid variants), template parsing errors (LaTeX delimiter assumptions break), logical structure mismatch (logic puzzles without numerical variation), duplicate generation (same seed produces same output)
- **First 3 experiments**: 1) Single-problem end-to-end test with 10 seeds and token measurement; 2) Difficulty scaling test comparing success rates across problem categories; 3) Template extraction robustness test on problems with varying LaTeX formatting

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the construction of problem templates and skeleton code be fully automated to remove the reliance on manual heuristics? The authors note exploring automated template construction represents a valuable direction for further study.

- **Open Question 2**: Can the CBIT framework be generalized to problems where correctness relies on logical structure rather than numerical values? The paper notes that tasks whose correctness depends solely on logical structure fall outside the current scope.

- **Open Question 3**: Is the framework robust to math problems using non-LaTeX notations or different parsing delimiters? The authors assume LaTeX notation delimited by dollar signs, noting that domains with different conventions may require more elaborate parsing strategies.

## Limitations

- Current framework relies on manual heuristics for template extraction, creating a bottleneck when scaling to new domains or formats
- Over-constrained problems with tight mathematical relationships may leave too few feasible numerical variants
- Framework scope excludes problems where correctness depends purely on logical structure without numerical variation

## Confidence

- **High Confidence**: The core mechanism of shifting from direct generation to program synthesis is well-supported by empirical results and deployment data
- **Medium Confidence**: The claim that templates can be extracted heuristically is supported by implementation but lacks rigorous evaluation of extraction failure rates
- **Low Confidence**: The assertion that CBIT "eliminates" verification needs careful qualification—verification is still needed for template integrity and edge cases

## Next Checks

1. **Template Robustness Test**: Apply CBIT to 100+ problems from diverse mathematical subdomains (algebra, geometry, calculus) and measure template extraction success rate and failure modes

2. **Constraint Complexity Scaling**: Systematically vary problem constraint tightness and dimensionality, measuring generator success rates and identifying failure thresholds

3. **Cross-Domain Transfer**: Adapt CBIT to a non-math educational domain (e.g., chemistry stoichiometry or physics problems) and evaluate whether the same template-program synthesis approach maintains effectiveness