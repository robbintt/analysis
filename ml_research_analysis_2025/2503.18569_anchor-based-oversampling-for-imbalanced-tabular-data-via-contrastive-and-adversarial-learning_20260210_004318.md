---
ver: rpa2
title: Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial
  learning
arxiv_id: '2503.18569'
source_url: https://arxiv.org/abs/2503.18569
tags:
- samples
- class
- minority
- data
- majority
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Anch-SCGAN, a novel oversampling framework
  for imbalanced tabular data using contrastive and adversarial learning. The method
  first selects anchor samples near the decision boundary and trains an MLP classifier
  to provide class representations.
---

# Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning

## Quick Facts
- arXiv ID: 2503.18569
- Source URL: https://arxiv.org/abs/2503.18569
- Reference count: 40
- Primary result: Anch-SCGAN improves AUC by 16.96% over original data and 2.6-3.3% over baseline GAN methods on 16 imbalanced datasets

## Executive Summary
This paper introduces Anch-SCGAN, a novel oversampling framework for imbalanced tabular data using contrastive and adversarial learning. The method first selects anchor samples near the decision boundary and trains an MLP classifier to provide class representations. It then employs a customized Conditional GAN with two generators (minority and majority) and a discriminator enhanced with class-specific features from the pre-trained MLP. A novel anchor loss based on contrastive learning and a stabilizing scoring strategy are incorporated to improve sample quality and training stability. Experimental results show Anch-SCGAN outperforms existing methods, achieving significant improvements in minority class classification.

## Method Summary
Anch-SCGAN uses a multiphase approach: first, it identifies anchor samples near the decision boundary using K-NN preprocessing, then trains an MLP classifier on these anchors to extract class-specific features. The framework employs a dual-generator CGAN architecture where one generator creates minority class samples and another creates majority class samples. The discriminator is enhanced with frozen MLP features to provide class-aware gradients. A novel anchor loss based on N-pair contrastive objectives ensures generated samples maintain class-specific geometry. The system includes a stabilization mechanism that adjusts loss weighting based on classifier confidence to prevent training collapse.

## Key Results
- Achieves 16.96% average AUC improvement over original imbalanced data
- Outperforms baseline GAN-based methods by 2.6-3.3% in AUC
- Achieves highest F1-scores on 14 out of 16 tested datasets
- Shows consistent performance across datasets with imbalance ratios ranging from 1.86 to 85.88

## Why This Works (Mechanism)

### Mechanism 1: Boundary-Focused Generation
Focusing generation on boundary-adjacent "anchor" samples improves classifier performance more than global oversampling. The system uses K-NN preprocessing to identify instances near the decision boundary, trains an MLP classifier on these anchors to create a prior knowledge model, and uses this model to guide the GAN to generate samples in critical decision regions rather than safe, dense regions. Core assumption: samples distant from the decision boundary contribute little to defining class separation. Evidence: KNN-based anchor selection algorithm identifies minority samples with majority neighbors as anchors. Break condition: K-NN distance metrics may fail in high-dimensional or sparse datasets.

### Mechanism 2: Contrastive Loss for Mode Preservation
Contrastive loss prevents mode collapse by forcing generated samples to maintain class-specific geometry. The architecture employs an anchor loss based on N-pair contrastive objectives, requiring the generator to minimize distance between generated samples and real anchor samples of the same class while maximizing distance to the opposite class. Core assumption: feature space allows meaningful distance metrics that correlate with class identity. Evidence: Anchor loss is added to standard GAN loss with coefficient λ. Break condition: If anchor samples used for contrastive comparison are outliers, the generator will be penalized for creating valid central samples.

### Mechanism 3: Dual-Generator Architecture
Decoupling generators stabilizes training in imbalanced settings by preventing the majority class from dominating gradient updates. Anch-SCGAN uses separate generators for minority and majority classes, with a pre-trained MLP providing class-specific feature injection to the discriminator. This ensures the discriminator provides useful gradients to the minority generator even when data is scarce. Core assumption: single generator struggles to map distinct latent spaces to highly imbalanced class distributions. Evidence: Two generators are trained sequentially in a cyclical process. Break condition: If the discriminator becomes too strong too quickly, it may distinguish real from fake for the minority class before the minority generator learns, causing gradient vanishing.

## Foundational Learning

- **Mode Collapse in GANs**: Understanding why standard GANs prefer generating majority class samples over minority ones if trained on imbalanced data is key to appreciating the anchor loss contribution
- **Contrastive Learning (N-pair Loss)**: Understanding how "pulling" similar samples and "pushing" dissimilar ones shapes the latent space is key to understanding the anchor loss
- **Boundary/Safe-Level Sampling**: The "Anchor" selection is a variation of boundary sampling (e.g., Borderline-SMOTE); understanding the risk of selecting only boundary samples for training a classifier

## Architecture Onboarding

- **Component map**: Raw Data → Anchor Selection → Train Prior MLP → Filter Noise → Train Anch-SCGAN → Finetune on Anchors
- **Critical path**: The system flows from raw data through anchor selection, MLP training for feature extraction, noise filtering, dual-generator GAN training, and final finetuning
- **Design tradeoffs**: K-NN parameter k-value requires balancing between selecting too few anchors (starving the model) and including safe samples (diluting boundary focus); finetuning on anchors helps precision but can be unstable on very small datasets
- **Failure signatures**: Drift occurs when generated minority samples overlap majority clusters in t-SNE (indicates contrastive loss is too weak or λ is too low); oscillation occurs when loss values diverge (paper suggests using the score coefficient C₀(x) to dampen this)
- **First 3 experiments**: 
  1. Visual Validation: Run Anchor Selection on a 2D toy dataset (e.g., imbalanced moons) to verify it correctly identifies boundary instances
  2. Ablation (Loss): Train Anch-SCGAN with λ = 0 (no contrastive loss) and compare F1-score against full model
  3. Hyperparameter Sensitivity: Reproduce Table 9 findings on Yeast dataset by varying k (3, 7, 11) to observe trade-off between anchor quantity and boundary precision

## Open Questions the Paper Calls Out

### Open Question 1: Representation Learning Architecture
Can employing an autoencoder or other representation learning architectures significantly improve the quality of class representations compared to the current pre-trained MLP? The current framework relies on a standard MLP for feature extraction, and the potential for more sophisticated representation learning techniques remains untested.

### Open Question 2: Anchor Selection Refinement
How can clustering or advanced preprocessing techniques be integrated to refine the anchor sample selection scheme beyond the current KNN-based approach? The current selection relies on a nearest-neighbor parameter k, which may be sensitive to local noise or varying data densities.

### Open Question 3: Finetuning Performance Degradation
Why does the finetuning phase with anchor samples degrade performance on datasets with high imbalance ratios and small sample sizes? The paper notes performance declined on Ecoli4, Glass2, and Yeast6 datasets, which are characterized by high imbalance and small sample counts, but lacks explanation for this specific data profile.

### Open Question 4: Adaptive k Parameter
Is it possible to develop an adaptive mechanism for determining the optimal k parameter in anchor selection based on dataset characteristics? The current methodology relies on manual tuning or a default value (k=5), which may not be optimal across datasets with vastly different imbalance ratios or feature dimensions.

## Limitations

- Anchor selection depends heavily on K-NN distance metrics that may fail in high-dimensional or sparse datasets where distance becomes less meaningful
- Dual-generator architecture is presented as key innovation but lacks extensive validation against single-generator alternatives in the tabular domain
- Anchor loss formulation requires clustering to select positive/negative pairs, but critical implementation details (number of clusters, specific algorithm) are underspecified

## Confidence

- **High confidence**: Overall experimental framework and performance improvements (16.96% AUC gain) are well-documented
- **Medium confidence**: Contrastive learning mechanism's contribution is supported by ablation studies, though exact sampling strategy remains unclear
- **Low confidence**: Dual-generator architecture's superiority claim lacks strong corpus support for tabular data specifically

## Next Checks

1. **Ablation Study**: Remove the anchor loss component (set λ=0) and measure performance degradation to quantify its specific contribution
2. **Distance Metric Sensitivity**: Test the anchor selection algorithm with different distance metrics (Euclidean vs. cosine) on a high-dimensional dataset to assess robustness
3. **Generator Architecture Comparison**: Implement a single-generator baseline with identical hyperparameters to directly compare against the dual-generator design on datasets with varying imbalance ratios