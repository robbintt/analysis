---
ver: rpa2
title: 'Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective'
arxiv_id: '2509.02281'
source_url: https://arxiv.org/abs/2509.02281
tags:
- modality
- learning
- modalities
- training
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses modality imbalance in multimodal learning,
  where dominant modalities overshadow weaker ones, limiting effective information
  integration. The authors propose Unidirectional Dynamic Interaction (UDI), a novel
  training strategy that abandons joint loss in favor of sequential, decoupled training.
---

# Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective

## Quick Facts
- **arXiv ID:** 2509.02281
- **Source URL:** https://arxiv.org/abs/2509.02281
- **Reference count:** 30
- **Primary result:** Unidirectional Dynamic Interaction (UDI) training strategy outperforms joint loss methods on six datasets, achieving up to 83.19% accuracy on CREMA-D and 99.11% on CGMNIST.

## Executive Summary
This paper addresses modality imbalance in multimodal learning, where dominant modalities overshadow weaker ones, limiting effective information integration. The authors propose Unidirectional Dynamic Interaction (UDI), a novel training strategy that abandons joint loss in favor of sequential, decoupled training. UDI first trains the highest-performing modality (anchor) to convergence, then uses its representations to guide other modalities through unsupervised consistency and complementarity losses, dynamically balanced by a gradient-based controller. This approach prevents hidden competition and enables directed information flow. Experiments on six datasets demonstrate UDI's superiority, achieving up to 83.19% accuracy on CREMA-D and 99.11% on CGMNIST, outperforming state-of-the-art imbalance mitigation methods. Ablation studies confirm the effectiveness of decoupled optimization and dynamic weighting in enhancing multimodal learning performance.

## Method Summary
UDI employs a two-phase sequential training strategy. First, the highest-performing modality is trained independently to convergence and frozen as the anchor. Second, remaining modalities are trained as followers using a composite loss function combining classification loss with unsupervised consistency (Jensen-Shannon divergence with frozen anchor predictions) and complementarity losses (minimizing mutual information between anchor and follower features). A dynamic controller adjusts the weights of these unsupervised losses based on their gradient alignment with the primary classification task. This unidirectional approach prevents gradient competition while ensuring followers learn both anchor-guided stability and modality-specific complementary features.

## Key Results
- UDI achieves state-of-the-art performance on six datasets, with accuracy improvements of 2.37% on CREMA-D, 0.86% on Kinetics-Sounds, 1.02% on CGMNIST, and 0.57% on UCF101.
- Dynamic weighting of unsupervised losses significantly improves performance over static weighting schemes, demonstrating the importance of gradient-aligned training.
- Ablation studies confirm that both the decoupled optimization strategy and dynamic controller are essential for optimal performance, with UDI outperforming all baseline methods including joint loss and traditional multimodal training.

## Why This Works (Mechanism)

### Mechanism 1: Elimination of Gradient Competition via Sequential Decoupling
Sequentially training modalities prevents strong modalities from suppressing weak ones by removing conflicting gradient updates inherent in joint loss optimization. Instead of a joint loss $L_{total} = \sum L_m$, UDI isolates the highest-performing modality (Anchor) and trains it to convergence first. This removes "hidden competition" where dominant gradients override weaker ones. The core assumption is that modality imbalance is primarily an optimization artifact caused by conflicting gradients in a shared objective, rather than data insufficiency.

### Mechanism 2: Directed Knowledge Transfer via Unsupervised Consistency
Forcing the follower modality's output distribution to align with the frozen anchor's output allows the follower to inherit semantic stability while learning its own representations. Uses Jensen-Shannon (JS) divergence between anchor predictions $\hat{y}^a$ and follower predictions $\hat{y}^m$. This acts as a knowledge distillation mechanism where the "teacher" (anchor) guides the "student" (follower) without shared parameters. The core assumption is that the anchor modality has already converged to a robust decision boundary that generalizes well.

### Mechanism 3: Feature Diversification via Mutual Information Minimization
Minimizing Mutual Information (MI) between anchor and follower features forces the follower to learn unique, complementary features rather than redundant ones. Minimizes an upper bound of MI, $\hat{I}_v(f^a; f^m)$. By making feature distributions independent ($p(f^a, f^m) \approx p(f^a)p(f^m)$), the follower is discouraged from simply copying the anchor's representation. The core assumption is that information that is not shared (independent) is likely to be complementary for the classification task.

### Mechanism 4: Gradient-Aligned Dynamic Weighting
Static weighting of loss terms is suboptimal; weighting unsupervised losses based on their alignment with the primary task gradient improves convergence. Computes inner product between the classification gradient $g_{cls}$ and unsupervised gradients ($g_{con}, g_{com}$). Weights $\alpha$ are normalized positive alignments. If a loss term pushes parameters in a direction opposing the task, its weight drops. The core assumption is that gradients that point in the same "direction" contribute positively to the immediate learning goal.

## Foundational Learning

### Concept: Modality Imbalance (Gradient Competition)
**Why needed here:** The core problem UDI solves. One must understand that in standard joint training, gradients from a modality with lower loss (stronger) can dominate the parameter updates, effectively silencing the weaker modality. **Quick check question:** In a joint loss $L = L_a + L_v$, if $|\nabla L_a| \gg |\nabla L_v|$, which modality's features are effectively updated?

### Concept: Mutual Information (MI) & Variational Bounds
**Why needed here:** Used to enforce complementarity. One must grasp that MI measures dependency. Minimizing it encourages independence (disentanglement) of feature representations. Since true MI is intractable for high dimensions, the paper uses a variational upper bound (CLUB estimator). **Quick check question:** Why does minimizing $I(X; Y)$ encourage $X$ and $Y$ to contain different information?

### Concept: Knowledge Distillation (Soft Labels)
**Why needed here:** The consistency loss $L_{con}$ uses JS divergence on soft predictions. This is mathematically similar to distillation, where a "teacher" network guides a "student." **Quick check question:** Why use soft labels (probabilities) rather than hard labels for the consistency loss? (Hint: entropy/dark knowledge).

## Architecture Onboarding

### Component map:
Encoders ($\psi_a, \psi_m$) -> Classifiers -> MI Estimator ($Q_\phi$) -> Dynamic Controller

### Critical path:
1. **Phase 1 (Anchor):** Train $\psi_a$ via standard Cross Entropy. Freeze $\psi_a$.
2. **Phase 2 (Follower):**
    - Train MI Estimator $Q_\phi$ to approximate $p(f^m|f^a)$.
    - Calculate $L_{cls}$, $L_{con}$ (JS), $L_{com}$ (MI).
    - Calculate Gradients.
    - **Dynamic Controller:** Compute $\alpha$ values based on gradient alignment.
    - Update Follower using weighted sum $L_{total}$.

### Design tradeoffs:
- **Training Time vs. Stability:** Sequential training takes longer (cannot parallelize modalities fully) but ensures stability.
- **Anchor Selection:** Paper selects the best validation performer. A poor anchor choice degrades performance (Table 4), but performance is often robust.
- **MI Estimation:** Accurate MI estimation requires training the $Q_\phi$ network sufficiently. Poor estimation leads to weak complementarity signals.

### Failure signatures:
- **Mode Collapse:** If $L_{con}$ dominates excessively, the follower simply mimics the anchor and adds no new info (Accuracy saturates at Anchor level).
- **Gradient Instability:** If the Dynamic Controller oscillates wildly, check the batch size used for gradient estimation (paper uses 1 mini-batch/epoch).

### First 3 experiments:
1. **Anchor Ablation:** Run UDI on CREMA-D using the *weaker* modality as the anchor. Compare accuracy against the "best anchor" protocol to quantify sensitivity.
2. **Controller Robustness:** Fix $\alpha_{con} = \alpha_{com} = 0.5$ vs. Dynamic Controller on a noisy dataset (Kinetics-Sounds) to visualize the smoothing effect of the controller.
3. **Feature Visualization:** Extract t-SNE plots of follower features before and after the "Complementary" loss is enabled to visually confirm feature diversification.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several are implied by the limitations and discussion sections.

## Limitations
- Sequential decoupling strategy assumes unimodal convergence to a good optimum is feasible, but in highly noisy or ambiguous modalities, this anchor selection could propagate errors.
- The variational MI estimator's performance is sensitive to the choice of Qφ architecture, which is not fully specified.
- The dynamic controller's effectiveness relies on stable gradient estimates from single mini-batches, which may not generalize to highly stochastic training regimes.

## Confidence
- **High Confidence:** The core claim that joint loss optimization causes gradient competition between modalities is well-supported by empirical ablation (Fig. 1) and literature consensus.
- **Medium Confidence:** The effectiveness of the gradient-aligned dynamic weighting scheme is supported by ablation studies, but the specific inner-product controller design lacks strong external validation.
- **Medium Confidence:** The mutual information minimization approach for feature complementarity is theoretically grounded but assumes that independent features are necessarily complementary for the classification task.

## Next Checks
1. **Anchor Robustness Test:** Systematically vary the anchor modality selection across datasets and measure sensitivity of final accuracy to anchor choice.
2. **Controller Stability Analysis:** Replace the gradient-product controller with static weights on a noisy dataset and compare training stability and final performance.
3. **MI Estimator Sensitivity:** Experiment with different architectures and training strategies for Qφ to quantify the impact of MI estimation accuracy on final model performance.