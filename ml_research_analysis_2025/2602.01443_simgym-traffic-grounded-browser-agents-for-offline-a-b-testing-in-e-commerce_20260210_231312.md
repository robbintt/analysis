---
ver: rpa2
title: 'SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce'
arxiv_id: '2602.01443'
source_url: https://arxiv.org/abs/2602.01443
tags:
- agents
- agent
- persona
- behavioral
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SimGym enables rapid offline A/B testing of e-commerce UI changes
  using synthetic buyers powered by LLM agents. It extracts per-shop buyer profiles
  and intents from production clickstream data, generates traffic-grounded personas,
  and simulates cohort-weighted shopping sessions in live browsers.
---

# SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce

## Quick Facts
- **arXiv ID:** 2602.01443
- **Source URL:** https://arxiv.org/abs/2602.01443
- **Reference count:** 32
- **Primary result:** SimGym achieves 69% directional alignment and 0.64 Pearson correlation for add-to-cart rate changes in e-commerce A/B testing

## Executive Summary
SimGym introduces a synthetic buyer platform that enables rapid offline A/B testing of e-commerce UI changes without exposing real customers to potentially suboptimal interfaces. The system extracts per-shop buyer profiles and intents from production clickstream data, generates traffic-grounded personas, and simulates cohort-weighted shopping sessions in live browsers. Experiments on 20 diverse shops show SimGym reduces experiment cycles from weeks to under an hour while maintaining strong alignment with real human outcomes.

## Method Summary
SimGym extracts per-shop buyer profiles from production clickstreams, identifies behavioral archetypes, and simulates cohort-weighted shopping sessions in live browsers. The system uses a six-stage pipeline: session clustering, product preference extraction, intent generation, buyer behavior aggregation, persona construction across five dimensions, and prompt composition. Agents perceive pages via accessibility trees, maintain episodic memory of the full session, and operate under structured guardrails. The approach predicts real human A/B test outcomes with 69% directional alignment and 0.64 Pearson correlation for add-to-cart rate changes.

## Key Results
- 69% directional alignment with human A/B test outcomes for add-to-cart rates
- 0.64 Pearson correlation between predicted and actual magnitude of conversion changes
- Reduces experiment cycles from weeks to under an hour while avoiding exposure of real buyers to suboptimal interfaces

## Why This Works (Mechanism)

### Mechanism 1: Traffic-Grounded Persona Extraction
Per-shop persona generation from production clickstreams predicts real A/B outcomes better than generic or donor-based personas. The six-stage pipeline clusters sessions, extracts product preferences, constructs multi-dimensional behavioral archetypes, and composes agent prompts calibrated to observed conversion propensities. Historical clickstream distributions are assumed representative of future buyer behavior during UI changes.

### Mechanism 2: Episodic Session Memory
Full-session memory passed to LLM at each step enables coherent navigation and is necessary for predictive validity. Agents accumulate reasoning, actions, outcomes, and errors into a session log that persists across the perceive-plan-act loop, allowing agents to recognize previously viewed products and avoid redundant actions. Human-like shopping decisions require context of what has already been explored.

### Mechanism 3: Accessibility Tree Perception
Using accessibility trees rather than raw HTML or screenshots preserves semantic structure while reducing token consumption. Hierarchical view of page elements with unique DOM-mapped IDs enables unambiguous action targeting across diverse storefront themes. Semantic structure suffices for shopping decisions; visual styling is secondary.

## Foundational Learning

- **Concept: A/B Testing Statistical Significance**
  - Why needed here: SimGym's value proposition is reducing weeks-long experiments; understanding why A/B tests take time grounds the problem.
  - Quick check question: Can you explain why detecting a 2% conversion lift might require thousands of sessions?

- **Concept: LLM Agent Memory Architectures**
  - Why needed here: Memory ablation caused 5.7× increase in timeouts; understanding episodic vs. retrieval-augmented memory is critical.
  - Quick check question: What happens when an agent cannot remember it already viewed a product page?

- **Concept: Behavioral Clustering and Persona Design**
  - Why needed here: k=5 clusters chosen via elbow method; understanding feature engineering for clickstream data is foundational.
  - Quick check question: What clickstream features would distinguish a "budget" buyer from a "premium" buyer?

## Architecture Onboarding

- **Component map:** Production clickstream → Session clustering (k-means, k=5) → Parallel tracks: (1) Intent generation (LLM-extracted categories) + (2) Persona construction (5 behavioral dimensions) → Prompt composition → Live browser agent (accessibility tree perception, episodic memory, guardrails) → A2C rate comparison

- **Critical path:** Persona grounding quality → Memory implementation → Sample size (600 agents/shop per Section 4.1 bootstrap analysis)

- **Design tradeoffs:**
  - Accessibility tree vs. screenshot: Lower tokens but misses visual-only changes
  - Full-session memory vs. sliding window: Coherence vs. context length limits
  - Per-shop personas vs. donor pools: Accuracy vs. cold-start cost

- **Failure signatures:**
  - Loop detection: Repeated identical actions (>3 identical consecutive)
  - Timeout cascade: >50% agents hitting step limits indicates navigation failure
  - Alignment collapse: Correlation <0.3 suggests persona mismatch or memory failure

- **First 3 experiments:**
  1. Replicate memory ablation on 5 shops: verify 45%→90% goal completion delta
  2. Test k=3, k=7 clustering: measure alignment rate sensitivity to cluster count
  3. Compare accessibility tree vs. screenshot perception on visually-heavy theme changes: quantify blind spots

## Open Questions the Paper Calls Out

### Open Question 1
Can end-to-end learning of personas directly from raw session data capture behavioral patterns more effectively than the current explicit feature engineering pipeline? The current implementation relies on manually defined dimensions and LLM-based extraction; the authors have not yet tested learned latent representations against this structured approach.

### Open Question 2
Can SimGym be utilized as the inner loop for an automated optimization system that iteratively proposes and validates UI changes? The paper validates SimGym as an evaluation tool but does not demonstrate its efficacy in guiding an autonomous design generation loop.

### Open Question 3
Does incorporating visual perception via Vision-Language Models (VLMs) improve predictive validity for theme changes that are primarily aesthetic rather than structural? Current agents may miss subtle visual cues that affect human conversion but do not alter DOM structure.

## Limitations
- Assumes historical clickstream distributions remain stable during UI changes
- Accessibility tree perception may miss visual-only changes affecting human behavior
- Memory implementation faces context window constraints for extended sessions

## Confidence
- **High Confidence:** Memory ablation results (45%→90% goal completion) and alignment rate measurements (69% with 0.64 correlation)
- **Medium Confidence:** Causal mechanism linking persona grounding to improved predictive validity relies on implicit assumptions about clickstream representativeness
- **Low Confidence:** Accessibility tree approach's blind spots for visual-only UI changes were not empirically validated

## Next Checks
1. **Seasonality Stress Test:** Apply SimGym to shops during known promotional periods and measure alignment rate degradation
2. **Visual-Only UI Validation:** Design experiments where UI changes affect only visual elements while preserving semantic structure
3. **Context Window Boundary Analysis:** Systematically vary session lengths to identify where memory truncation begins affecting agent coherence