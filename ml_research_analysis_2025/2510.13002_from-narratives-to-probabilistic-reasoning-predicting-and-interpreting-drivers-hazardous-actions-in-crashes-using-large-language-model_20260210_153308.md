---
ver: rpa2
title: 'From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers''
  Hazardous Actions in Crashes Using Large Language Model'
arxiv_id: '2510.13002'
source_url: https://arxiv.org/abs/2510.13002
tags:
- crash
- drivers
- probability
- page
- driver
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an LLM-based framework to automatically identify
  Driver Hazardous Actions (DHA) in two-vehicle crashes using Michigan crash data.
  A fine-tuned Llama 3.2 1B model was trained on contextualized crash narratives and
  compared against conventional machine learning classifiers.
---

# From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model

## Quick Facts
- arXiv ID: 2510.13002
- Source URL: https://arxiv.org/abs/2510.13002
- Reference count: 0
- Developed LLM framework achieving 80% accuracy in predicting driver hazardous actions from crash narratives

## Executive Summary
This study introduces an LLM-based framework for automatically identifying Driver Hazardous Actions (DHA) in two-vehicle crashes using Michigan crash data. The research team fine-tuned Llama 3.2 1B on contextualized crash narratives and compared it against conventional machine learning classifiers. The LLM achieved 80% overall accuracy, significantly outperforming baseline models and demonstrating particular strength in predicting prevalent DHA classes. A novel probabilistic reasoning approach was developed to quantify how DHAs shift under hypothetical risky scenarios, revealing actionable insights about distraction and driver demographics' impact on hazardous behavior.

## Method Summary
The researchers developed a framework that processes police crash narratives to predict driver hazardous actions using fine-tuned language models. They employed Llama 3.2 1B, trained on Michigan crash data from 2020-2023, and compared its performance against traditional machine learning classifiers. The methodology included contextual embedding of narrative descriptions, multi-class classification of DHAs, and a probabilistic reasoning component that analyzes how hazardous actions change under different hypothetical scenarios such as increased distraction or varying driver demographics.

## Key Results
- LLM achieved 80% overall accuracy in predicting driver hazardous actions
- Significantly outperformed conventional machine learning baselines
- Probabilistic reasoning revealed distraction increases unsafe driving probabilities
- Teen drivers showed elevated speed and stopping violations in analysis
- Framework demonstrated scalability and interpretability for traffic safety applications

## Why This Works (Mechanism)
The approach leverages LLMs' natural language understanding capabilities to extract nuanced behavioral patterns from unstructured crash narratives that traditional feature-based classifiers miss. By contextualizing entire crash descriptions rather than isolated features, the model captures complex relationships between driver actions, environmental factors, and crash outcomes. The probabilistic reasoning component extends beyond simple classification to model how different risk factors interact and influence driver behavior patterns.

## Foundational Learning
**Crash Narrative Processing**: Converting unstructured police reports into structured hazard predictions requires understanding narrative context and implicit behavioral cues - essential for capturing real-world driver decision-making patterns.

**Multi-class Classification**: Predicting specific hazardous actions rather than binary outcomes provides granular safety insights but requires handling class imbalance and ensuring robust performance across rare but critical behaviors.

**Probabilistic Reasoning**: Moving beyond deterministic predictions to model uncertainty and scenario-based risk helps identify intervention points and understand how multiple risk factors compound driver behavior risks.

## Architecture Onboarding

**Component Map**: Crash Narratives -> Llama 3.2 1B Fine-tuning -> DHA Classification -> Probabilistic Scenario Analysis

**Critical Path**: Narrative input → Contextual embedding → Classification layer → Probability distribution output → Scenario adjustment → Risk quantification

**Design Tradeoffs**: Smaller 1B parameter model chosen for efficiency and faster inference vs. larger models that might capture more nuanced patterns but require more resources and training data.

**Failure Signatures**: Performance degradation on rare DHA classes, sensitivity to narrative style variations across jurisdictions, potential bias amplification from training data demographics.

**First Experiments**:
1. Test model on narratives from different states to assess geographic generalizability
2. Validate probabilistic reasoning against real-world intervention data
3. Conduct ablation studies removing narrative context vs. using structured data only

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Limited to Michigan crash data, potentially missing regional reporting variations
- Model performance may be inflated without detailed cross-validation results
- Hypothetical scenarios in probabilistic reasoning may oversimplify real-world behavior
- No testing of generalizability to other jurisdictions or reporting systems

## Confidence
- Model performance claims (High): 80% accuracy well-supported by confusion matrix
- Probabilistic reasoning insights (Medium): Methodology sound but hypothetical scenarios may lack real-world complexity
- Generalizability to other contexts (Low): Limited to single state with no external validation

## Next Checks
1. Test the model on crash narratives from at least three different states to assess geographic generalizability and reporting style variations.
2. Implement k-fold cross-validation with detailed performance breakdowns by crash severity levels to identify potential performance degradation in less severe incidents.
3. Conduct a blinded expert review where traffic safety analysts evaluate the model's DHA predictions against actual crash reconstruction findings to assess practical reliability.