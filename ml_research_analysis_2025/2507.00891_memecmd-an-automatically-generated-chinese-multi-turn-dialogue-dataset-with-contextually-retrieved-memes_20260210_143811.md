---
ver: rpa2
title: 'MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with
  Contextually Retrieved Memes'
arxiv_id: '2507.00891'
source_url: https://arxiv.org/abs/2507.00891
tags:
- meme
- dialogue
- memes
- retrieval
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MemeCMD, an automatically generated Chinese
  multi-turn dialogue dataset with contextually retrieved memes. The authors construct
  a large-scale meme library annotated with scenarios, emotions, and motivations using
  MLLM, then develop a dual-agent dialogue generation framework with a retrieval strategy
  that selects contextually appropriate memes based on semantic similarity across
  these dimensions.
---

# MemeCMD: An Automatically Generated Chinese Multi-turn Dialogue Dataset with Contextually Retrieved Memes

## Quick Facts
- **arXiv ID:** 2507.00891
- **Source URL:** https://arxiv.org/abs/2507.00891
- **Reference count:** 40
- **Primary result:** Introduced MemeCMD, an automatically generated Chinese multi-turn dialogue dataset with contextually retrieved memes using dual-agent generation and multi-dimensional retrieval

## Executive Summary
This paper presents MemeCMD, a large-scale Chinese multi-turn dialogue dataset with automatically inserted memes. The authors construct a meme library annotated with scenarios, emotions, and motivations using MLLM, then develop a dual-agent dialogue generation framework with a retrieval strategy that selects contextually appropriate memes based on semantic similarity across these dimensions. To ensure natural usage, they implement an adaptive threshold decay mechanism that spaces meme insertions over conversation turns. Experiments demonstrate that their retrieval-based selection strategies (Greedy and Sampling) outperform random selection in both LLM-as-a-judge and cross-modal embedding-based evaluations.

## Method Summary
The authors first annotate 6,023 Chinese memes with four dimensions (S+, S-, E, Ψ) using MLLM. They then build a dual-agent dialogue generation system with news-based or role-based initialization, where agents generate conversations in four phases with evolving prompts. A summary agent extracts the same four dimensions from dialogue history, and a meme aligner computes a weighted retrieval score combining scenario similarity, scenario penalization, implicit semantic matching, and motivation alignment. Memes are selected when a decayed threshold is exceeded, with exponential decay controlling insertion frequency. The dataset is evaluated using LLM-as-a-Judge on five dimensions and cross-modal semantic consistency via CLIP embeddings.

## Key Results
- Retrieval-based selection strategies (Greedy and Sampling) achieve semantic consistency scores of 90.33-91.56
- Random selection achieves only 68.39-68.75 semantic consistency across dataset variants
- Adaptive threshold decay mechanism effectively spaces meme insertions over conversation turns
- Four-dimensional retrieval (scenario, emotion, motivation) outperforms single-dimension approaches

## Why This Works (Mechanism)

### Mechanism 1: Multi-dimensional Semantic Alignment for Meme Retrieval
The retrieval strategy jointly matches scenario, emotion, and motivation dimensions to produce contextually appropriate meme selections. The Meme Aligner computes a weighted retrieval score combining four components: scenario similarity, scenario penalization for forbidden contexts, implicit semantic matching, and motivation alignment. This multi-dimensional approach captures the communicative functions that make memes contextually appropriate, using cosine similarity in embedding space for semantic relevance.

### Mechanism 2: Adaptive Threshold Decay for Natural Meme Frequency
An exponential decay function (θ_i,t = θ₀ + Δ·e^(-λk_i,t)) controls when memes are inserted, where k is turns since last meme. This creates high penalties immediately after sending, then gradually decays toward base threshold. The mechanism assumes human meme usage follows an exponential recovery pattern—users avoid consecutive meme turns but gradually become willing to send another, producing more realistic meme spacing than fixed thresholds.

### Mechanism 3: Dual-Agent Dialogue Generation with Phased Prompting
Staged prompt construction (initial → early → middle → late phases) produces more coherent multi-turn dialogues. Early turns include full context, middle turns add topic-extension instructions, and late turns remove explicit context to encourage free-form conversation. This approach assumes that removing explicit initialization over time allows conversations to diverge naturally while maintaining character coherence through accumulated history.

## Foundational Learning

- **Concept:** Cross-modal embedding alignment
  - Why needed: Retrieval strategy requires projecting meme annotations and dialogue summaries into shared semantic space for similarity computation
  - Quick check: Can you explain why cosine similarity rather than Euclidean distance is used for comparing semantic embeddings?

- **Concept:** Multi-turn dialogue context modeling
  - Why needed: Summary Agent must extract S, E, Ψ from accumulated dialogue history, not just current utterance
  - Quick check: What information would be lost if you only used current utterance instead of full dialogue history for meme retrieval?

- **Concept:** Threshold-based decision boundaries with decay
  - Why needed: Adaptive threshold decay controls when memes are inserted, balancing expressiveness with naturalness
  - Quick check: How does exponential decay function differ from linear decay, and what conversational behavior does each encourage?

## Architecture Onboarding

- **Component map:** Meme Library (6,023 images + MLLM annotations) → Summary Agent (per-turn S, E, Ψ extraction) → Meme Aligner (4-dimension scoring) → Adaptive Threshold → Meme Selector (Greedy/Sampling)

- **Critical path:** Meme Library annotation quality directly impacts retrieval precision; Summary Agent extraction accuracy determines context alignment; Threshold parameters (θ₀=0.7, Δ=0.2, λ=1) control insertion frequency

- **Design tradeoffs:** Greedy selection maximizes relevance but causes repetitive meme usage; Sampling from Top-K increases diversity but may select lower-relevance candidates; News-based initialization scales automatically but limits scenario diversity; Role-based requires manual construction

- **Failure signatures:** High retrieval scores but low human-rated appropriateness (embedding-semantic gap); Memes clustering at same score (insufficient discriminative power); Consecutive meme insertions (threshold decay not triggering correctly)

- **First 3 experiments:** 1) Reproduce LLM-as-a-Judge evaluation on held-out subset to validate scoring components (ablate each of α, δ, β, γ); 2) Vary θ₀, Δ, λ parameters and measure meme frequency distribution vs. human baseline; 3) Test retrieval on existing Chinese meme dialogue datasets (MOD) to assess cross-dataset generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed retrieval strategy and adaptive threshold decay mechanism effectively generalize to diverse, real-world human-human dialogue datasets?
- Basis: The authors state in the Conclusion: "Future work will validate our retrieval strategy across diverse real-world dialogue datasets."
- Why unresolved: Current dataset (MemeCMD) is entirely synthetic, generated by dual LLM agents rather than collected from human interactions
- What evidence would resolve it: Successful application of retrieval pipeline to existing human-annotated multi-turn dialogue corpora (e.g., StickerInt or MOD) showing similar semantic consistency scores without significant performance degradation

### Open Question 2
- Question: To what extent do automated evaluation metrics (LLM-as-a-Judge and cross-modal embeddings) correlate with human preferences regarding humor and emotional resonance?
- Basis: Authors acknowledge that "current MLLMs exhibit significant limitations in understanding emotional or implicit intent... thereby limiting their efficacy in evaluating emotional consistency" and that expert-driven assessment is the "ideal evaluation approach" but is too costly
- Why unresolved: Paper relies on automated proxies for evaluation, explicitly noting that MLLMs struggle with communicative functions and affective nuances of memes
- What evidence would resolve it: Comparative study measuring correlation coefficient between paper's automated scores and human ratings on "gold standard" subset

### Open Question 3
- Question: Can fine-tuning LLMs on MemeCMD effectively improve their ability to generate contextually diverse and humorous responses in downstream conversational applications?
- Basis: Conclusion outlines goal to "leverage this approach as a scalable solution for... enriching LLM-generated responses with contextual diversity and engaging humor"
- Why unresolved: Paper focuses on construction of dataset and retrieval mechanism but does not present results on training or fine-tuning dialogue model on this data to measure improvements in response generation
- What evidence would resolve it: Training standard conversational model on MemeCMD and demonstrating through human evaluation that it produces more engaging or appropriately humorous responses compared to baseline

## Limitations
- Retrieval performance heavily depends on quality of MLLM-generated meme annotations, with limited validation of annotation accuracy
- Weight parameters for retrieval scoring function are not specified, making equal weighting assumption unclear
- Exponential decay parameters are fixed without sensitivity analysis, raising questions about generalizability across different conversation styles
- Dataset is entirely synthetic, limiting validation of real-world applicability

## Confidence

- **High Confidence:** Dual-agent generation framework with phased prompting is well-specified and reproducible; Retrieval evaluation methodology (LLM-as-a-Judge and cross-modal embedding) is clearly defined
- **Medium Confidence:** Retrieval strategy's superiority over random selection is demonstrated, but relative performance of Greedy vs. Sampling lacks comprehensive comparison; Adaptive threshold mechanism's effectiveness is supported by design logic but limited empirical validation
- **Low Confidence:** Claim that multi-dimensional semantic alignment produces more appropriate selections than single-dimension approaches lacks direct ablation studies; Naturalness of meme frequency compared to human conversation is asserted but not benchmarked against human data

## Next Checks

1. Conduct ablation studies removing each retrieval dimension (scenario, emotion, motivation) to quantify their individual contributions to overall performance
2. Compare exponential threshold decay mechanism against linear decay and fixed threshold approaches using human evaluation of meme naturalness
3. Test retrieval strategy on existing Chinese multimodal dialogue datasets (e.g., MOD) to assess cross-dataset generalization beyond automatically generated corpus