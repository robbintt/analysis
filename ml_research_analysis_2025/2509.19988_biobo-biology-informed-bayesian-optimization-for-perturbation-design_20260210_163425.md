---
ver: rpa2
title: 'BioBO: Biology-informed Bayesian Optimization for Perturbation Design'
arxiv_id: '2509.19988'
source_url: https://arxiv.org/abs/2509.19988
tags:
- recall
- gene
- rmse
- spearman
- acquisition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BioBO improves genomic perturbation design by integrating multimodal
  gene embeddings with enrichment analysis into Bayesian optimization. It enhances
  surrogate modeling using fused gene representations (Achilles, Gene2Vec, GenePT)
  and augments acquisition functions with biologically-informed priors from pathway
  enrichment.
---

# BioBO: Biology-informed Bayesian Optimization for Perturbation Design

## Quick Facts
- arXiv ID: 2509.19988
- Source URL: https://arxiv.org/abs/2509.19988
- Reference count: 40
- BioBO improves genomic perturbation design by integrating multimodal gene embeddings with enrichment analysis into Bayesian optimization, achieving 25-40% better labeling efficiency than standard BO.

## Executive Summary
BioBO addresses the challenge of efficiently identifying optimal genomic perturbations for cellular phenotype changes by integrating biological knowledge into Bayesian optimization. The method combines multimodal gene embeddings (Achilles, Gene2Vec, GenePT) with pathway enrichment analysis-derived priors to guide exploration toward functionally relevant genes while maintaining BO's theoretical exploration-exploitation balance. BioBO achieves 25-40% better labeling efficiency than standard BO, with the best performance using BioUCB-HM and fused gene embeddings. The approach provides interpretable pathway-level explanations and outperforms conventional BO in 23 out of 24 experimental settings.

## Method Summary
BioBO integrates multimodal gene embeddings (Achilles, Gene2Vec, GenePT) with pathway enrichment analysis into Bayesian optimization for genomic perturbation design. The method uses a Bayesian Neural Network (BNN) surrogate trained on concatenated, L2-normalized gene embeddings to model phenotype predictions with uncertainty. At each BO iteration, enrichment analysis of top-labeled genes generates biologically-informed priors that augment acquisition functions through the πBO framework, with decaying influence as more data accumulates. This balances exploration of uncertain regions with exploitation of biologically promising candidates, improving labeling efficiency by 25-40% over standard BO while providing interpretable pathway-level explanations.

## Key Results
- BioBO achieves 25-40% better labeling efficiency than standard BO in genomic perturbation design
- Best performance achieved with BioUCB-HM and fused gene embeddings across 23 out of 24 experimental settings
- Fused multimodal embeddings improve surrogate model predictions specifically near the optimum (Spearman correlations 0.31-0.64), not globally
- Pathway enrichment-derived priors guide exploration while maintaining theoretical BO guarantees through decaying prior mechanism

## Why This Works (Mechanism)

### Mechanism 1
Fusing multimodal gene embeddings improves BO performance by enhancing surrogate model predictions specifically near the optimum, not globally. Concatenated embeddings (Achilles, Gene2Vec, GenePT) capture complementary biological relationships—functional dependencies, gene ontology relations, and literature-derived knowledge. This enriched representation enables the BNN surrogate to better discriminate high-value genes in the target phenotype's relevant region of the embedding space. Core assumption: The embedding fusion preserves discriminative information near the optimum that single modalities miss, and the optimum lies in a region where fused features are more informative.

### Mechanism 2
Pathway enrichment-derived priors guide exploration toward genes in functionally relevant pathways while preserving BO's theoretical exploration-exploitation balance through a decaying prior mechanism. At each iteration, top-k labeled genes undergo enrichment analysis against pathway databases (GO or Hallmark). Unlabeled genes in significantly enriched pathways (adjusted p < 0.05) receive higher prior probability π(x), computed from combined scores (odds ratio × -log p-value). This prior multiplies the base acquisition function and decays as labeled data accumulates (factor β/L_n), eventually ceding control to the data-driven surrogate. Core assumption: The pathways enriched by early high-performing genes contain additional undiscovered high-performing genes, and enrichment signals are not purely spurious.

### Mechanism 3
The πBO framework's decaying prior provides a no-harm guarantee, ensuring BioBO asymptotically matches standard BO even with misleading enrichment signals. The prior exponent β/L_n causes π(x)^{β/L_n} → 1 as labeled data L_n grows, making the augmented acquisition function converge to the base form. This bounds the regret of BioBO relative to standard BO by factor C_{π,n} = (max_x π(x) / min_x π(x))^{β/L_n}, which decays to 1. Core assumption: The base acquisition function (EI, UCB, TS) has known convergence guarantees and the prior is bounded away from zero.

## Foundational Learning

- **Bayesian Neural Networks (BNNs) as Surrogate Models**
  - Why needed here: BioBO uses BNNs to model f(x) with calibrated uncertainty, which acquisition functions (UCB, EI, TS) require for balancing exploration-exploitation. Understanding how BNNs differ from standard NNs is essential for debugging surrogate quality.
  - Quick check question: Given a BNN with weight uncertainty, can you explain how Monte Carlo forward passes produce both a mean prediction μ(x) and uncertainty σ(x)?

- **Gene Set Enrichment Analysis (Hypergeometric Test)**
  - Why needed here: The prior π(x) depends on enrichment p-values, odds ratios, and multiple testing correction. Without understanding why enrichment indicates biological relevance, you cannot diagnose prior quality issues.
  - Quick check question: Given a pathway of 200 genes, 10,556 total genes, and 5 of your top-100 genes in this pathway, is this over-represented compared to random expectation (roughly)?

- **Acquisition Function Trade-offs (UCB, EI, TS)**
  - Why needed here: Each acquisition function balances exploration (uncertainty) vs. exploitation (predicted value) differently. The enrichment prior modifies this balance, so understanding base behavior is prerequisite to interpreting BioBO results.
  - Quick check question: In UCB (μ + κσ), what happens to search behavior if κ is set very high (e.g., 10) vs. very low (e.g., 0.1)?

## Architecture Onboarding

- **Component map**:
  - Input Layer: Gene IDs → Embedding lookup (Achilles + Gene2Vec + GenePT) → L2-normalize → Concatenate → d-dim vector
  - Surrogate Model: BNN (2-layer MLP, width 64, ReLU, Bayesian weights with N(0,1) prior) → 100 MC samples → μ(x), σ(x)
  - Prior Computation: Current labeled top-k genes → Enrichment vs. GO/Hallmark → Adjusted p-values + odds ratios → Combined scores → π(x) for unlabeled genes (Eq. 6)
  - Acquisition: α_aug(x) = α_base(x) × π(x)^{β/L_n} → Normalize → Select top-B
  - Loop: New labels appended to D_n → Retrain BNN → Recompute π → Next batch

- **Critical path**:
  1. Embedding coverage: Genes missing from any modality reduce Fusion benefits (paper uses 10,556-gene intersection)
  2. Pathway database: Genes not in any GO/Hallmark pathway receive uniform π(x), gaining no prior boost
  3. Decay rate β: Too high = over-trust noisy enrichment; too low = ignore useful biology. Paper uses β=1 for IFN-γ, β=0.1 for IL-2

- **Design tradeoffs**:
  - GO vs. Hallmark: GO is comprehensive but noisier; Hallmark is curated, smaller. Table 1 shows BioUCB-HM generally outperforms BioUCB-GO.
  - Aggregation (mean vs. max): Mean averages pathway scores; max takes strongest single pathway. Both viable; mean is default.
  - Temperature t: Controls prior sharpness. t→∞ gives uniform prior (ablates EA); t=0.1 is default.

- **Failure signatures**:
  - BO converges to suboptimal genes: Check if π(x) is overly peaked (low t) or β too high for early cycles; surrogate may be over-exploiting biased prior.
  - No improvement over random baseline: Verify embeddings are correctly loaded and concatenated; check BNN training (loss decreasing, reasonable validation LL).
  - Enrichment prior hurts performance: Ensure Bonferroni correction applied; verify pathway gene sets match your gene universe; check for pathway database version mismatches.
  - High variance across seeds: Expected due to stochastic BNN inference and MC sampling; aggregate over 7+ seeds as paper does.

- **First 3 experiments**:
  1. **Baseline sanity check**: Run standard UCB with Achilles-only embeddings on IFN-γ dataset. Confirm cumulative top-k recall at cycle 20 is ~0.077 and exceeds random (~0.050). This validates the surrogate and acquisition implementation.
  2. **Fusion ablation**: Compare Fusion embeddings vs. each single modality (Achilles, Gene2Vec, GenePT) on IL-2. Expect Fusion to outperform, with the gap visible in mid-cycles (6–12). Log both global LL and LL@top-1% to confirm local improvement mechanism.
  3. **Prior sensitivity analysis**: Test BioUCB-HM with β ∈ {0.01, 0.1, 0.5, 1.0, 5.0} on IFN-γ using Achilles embeddings. Plot cumulative recall at cycle 20 vs. β. Identify optimal β and verify that even suboptimal β does not underperform base UCB (no-harm check).

## Open Questions the Paper Calls Out
- Can BioBO be extended to effectively incorporate broader biological knowledge sources, such as single-cell profiles or alternative literature-derived embeddings, to further enhance perturbation design?
- To what extent does BioBO mitigate the "bias toward known biology" inherent in enrichment analysis when identifying novel targets in underexplored genomic regions?
- Does explicitly optimizing the surrogate model for local predictive performance near the optimum yield more consistent improvements in BO efficiency than optimizing for global accuracy?

## Limitations
- Optimal embedding fusion strategy is dataset-dependent; Fusion does not uniformly outperform single modalities across all phenotypes, suggesting limited generalizability
- Pathway enrichment priors show dataset-specific effectiveness (GO vs. Hallmark, β tuning), indicating biological priors may not transfer across perturbation types
- No comparison to modern acquisition variants like q-EI or look-ahead BO, limiting claims about optimality among acquisition strategies

## Confidence

- **High confidence** in surrogate modeling improvements (BNN with fused embeddings improves local predictions near optimum with clear statistical evidence)
- **Medium confidence** in enrichment prior benefits (improvements shown but highly dataset-specific and dependent on tuning parameters)
- **Low confidence** in theoretical guarantees (πBO convergence proofs assume myopic acquisitions; extension to non-myopic variants not verified)

## Next Checks
1. Test BioBO on a novel perturbation phenotype outside the GeneDisco benchmark to assess cross-dataset generalization
2. Implement q-EI acquisition variant to determine if BioBO advantages persist with non-myopic acquisition functions
3. Perform ablation studies on embedding modalities for specific pathways to identify when Fusion provides minimal benefit