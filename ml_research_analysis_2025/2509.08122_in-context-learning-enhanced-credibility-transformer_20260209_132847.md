---
ver: rpa2
title: In-Context Learning Enhanced Credibility Transformer
arxiv_id: '2509.08122'
source_url: https://arxiv.org/abs/2509.08122
tags:
- transformer
- credibility
- context
- training
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an In-Context Learning Enhanced Credibility
  Transformer (ICL-Credibility Transformer) that combines classical credibility theory
  with modern Transformer architectures to improve insurance pricing predictions.
  The key innovation is integrating context information from similar instances through
  an outcome token decorator and ICL Transformer layer, allowing the model to dynamically
  enhance predictions based on peer-group data without retraining.
---

# In-Context Learning Enhanced Credibility Transformer

## Quick Facts
- arXiv ID: 2509.08122
- Source URL: https://arxiv.org/abs/2509.08122
- Authors: Kishan Padayachy; Ronald Richman; Salvatore Scognamiglio; Mario V. Wüthrich
- Reference count: 3
- Primary result: Out-of-sample Poisson deviance loss of 23.710 (ICL-Credibility Transformer) vs 23.743 (base Credibility Transformer)

## Executive Summary
This paper introduces an In-Context Learning Enhanced Credibility Transformer (ICL-Credibility Transformer) that combines classical credibility theory with modern Transformer architectures to improve insurance pricing predictions. The key innovation is integrating context information from similar instances through an outcome token decorator and ICL Transformer layer, allowing the model to dynamically enhance predictions based on peer-group data without retraining. The approach maintains a frozen decoder from the base Credibility Transformer to preserve learned representations while enabling context-aware adjustments. On the French MTPL dataset, the model achieves a Poisson deviance loss of 23.710 (out-of-sample), outperforming the base Credibility Transformer's 23.743. Theoretical analysis reveals that attention weights function as adaptive credibility factors generalizing Buhlmann credibility to non-linear settings. The model also demonstrates zero-shot generalization capability to novel categorical levels (e.g., new vehicle models or regions) not seen during training, addressing a critical practical challenge in actuarial applications.

## Method Summary
The method employs a three-phase training approach: (1) Train a base Credibility Transformer on the French MTPL dataset with early stopping, obtaining encoder and decoder weights; (2) Freeze the decoder, add an outcome token decorator and ICL Transformer layer, then fine-tune on context-target batch pairs; (3) Optionally unfreeze all components for joint fine-tuning with strong regularization. Context is constructed by retrieving K nearest neighbors (K=64) from training data for each target chunk using FAISS cosine similarity on L2-normalized CLS tokens, creating batches of size c=1000. The outcome decorator incorporates response information into context CLS tokens using a Bühlmann-style credibility weighting v/(v+κ). At inference, similar training instances are retrieved as context for each test chunk, and causal masking prevents target-target interaction in the ICL layer.

## Key Results
- Out-of-sample Poisson deviance loss of 23.710 for ICL-Credibility Transformer vs 23.743 for base Credibility Transformer
- Zero-shot generalization capability to novel categorical levels not seen during training
- Attention weights function as adaptive credibility factors generalizing Bühlmann credibility to non-linear settings
- Frozen decoder preserves learned representations while enabling context-aware adjustments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention weights function as adaptive credibility factors that generalize Bühlmann credibility to non-linear settings.
- Mechanism: The cross-attention in the ICL Transformer layer computes softmax-normalized weights (a_i,j) that blend instance-specific CLS token information with outcome-decorated context tokens. Proposition 3.1 shows this produces h_i = a_i,i · z_FNN^V(c_cred(x_i)) + Σ_j∈context a_i,j · z_FNN^V(decorated token_j), structurally analogous to Bühlmann's αY + (1-α)μ_0 but with data-driven, feature-similarity-dependent weights.
- Core assumption: Feature similarity in the CLS token embedding space correlates with shared risk characteristics, making context instances informative for target predictions.
- Evidence anchors:
  - [abstract] "Theoretical analysis reveals that attention weights function as adaptive credibility factors generalizing Bühlmann credibility to non-linear settings."
  - [section 3] Proposition 3.1 and derivation showing attention weights satisfy credibility structure with a_i,i + Σ a_i,j = 1.
  - [corpus] Limited direct corpus support for this specific credibility-attention connection; corpus papers focus on general ICL mechanisms rather than actuarial applications.
- Break condition: If context instances are not meaningfully similar to targets (poor retrieval), attention weights will distribute uniformly or attend to irrelevant patterns, degrading predictions.

### Mechanism 2
- Claim: The outcome token decorator enables supervised signal propagation from context batch to target batch through the ICL Transformer.
- Mechanism: Context batch CLS tokens are decorated with encoded response information via c_decor(x_j) = c_cred(x_j) + [v_j/(v_j + κ)] · z_FNN1(Y_j), where the credibility coefficient κ controls how much outcome information is incorporated. This decorated token then participates in cross-attention, allowing target instances to "observe" similar cases' outcomes.
- Core assumption: Responses Y_j from similar instances provide meaningful signal for predicting target responses; the encoding dimension 2b is sufficient to preserve both feature and outcome information.
- Evidence anchors:
  - [abstract] "integrating context information from similar instances through an outcome token decorator"
  - [section 2.1.2] Equation (2.4) defines the decorated token with Bühlmann-style credibility weighting.
  - [corpus] Müller et al. (2024) referenced for TabICL achieving improvements through ICL, though not identical mechanism.
- Break condition: If κ is poorly tuned (too small → overfit to context noise; too large → outcome signal attenuated), or if responses are highly heterogeneous even among similar instances, decoration provides little benefit.

### Mechanism 3
- Claim: Freezing the decoder during ICL training preserves learned representation-calibration mappings and constrains ICL to operate within the existing CLS token space.
- Mechanism: The decoder z_decod from Phase 1 training remains frozen during Phase 2, forcing the ICL Transformer and outcome decorator to produce tokens compatible with the pre-learned decoder's expectations. This creates an information bottleneck that regularizes ICL adjustments.
- Core assumption: The Phase 1 encoder-decoder has learned a sufficiently rich CLS token representation space; ICL adjustments are refinement rather than reconstruction.
- Evidence anchors:
  - [abstract] "maintains a frozen decoder from the base Credibility Transformer to preserve learned representations"
  - [section 2.1.4] Lists four benefits: calibration preservation, implicit regularization, transfer learning efficiency, gradient flow simplification.
  - [corpus] No direct corpus validation; this appears to be a novel architectural constraint specific to this work.
- Break condition: If the frozen decoder's mapping from tokens to predictions is incompatible with the ICL-adjusted token distribution, predictions become miscalibrated. Phase 3 unfreezing addresses this but requires careful regularization.

## Foundational Learning

- Concept: **Bühlmann credibility theory**
  - Why needed here: The paper explicitly grounds its mechanism in classical actuarial credibility, where individual experience Y is weighted against collective prior μ_0 via credibility factor α = v/(v+κ). Understanding this formula is essential for interpreting both the outcome decorator (Equation 2.4) and the attention-weight-as-credibility interpretation.
  - Quick check question: Given credibility coefficient κ=1000 and case weight v=500, what proportion of the prediction comes from individual vs. collective information?

- Concept: **Transformer self-attention and CLS tokens**
  - Why needed here: The architecture builds on the FT-Transformer with a CLS token that aggregates input information. The ICL mechanism operates on these CLS token representations. Understanding Q/K/V attention, softmax normalization, and how CLS tokens encode sequence information is prerequisite.
  - Quick check question: In a self-attention layer with query Q and key K, what does the softmax(QK^T/√d) operation compute and why is temperature scaling √d used?

- Concept: **In-context learning as implicit meta-learning**
  - Why needed here: The paper frames ICL as a form of transfer learning where context examples (demonstrations) enable adaptation without weight updates. Understanding why providing labeled examples in the input can substitute for gradient descent helps explain why this architecture works.
  - Quick check question: What is the difference between in-context learning and few-shot fine-tuning? Why does ICL not require backpropagation through the context examples?

## Architecture Onboarding

- Component map:
  1. **Credibility Transformer Encoder** (from Richman et al. 2025a): Tokenizes tabular features (categorical embeddings + continuous feature FNN), applies Transformer layers with CLS token, outputs 2b-dimensional credibilitized CLS token c_cred(x).
  2. **Outcome Token Decorator**: FNN z_FNN1 maps response Y → 2b-dim; decorated token = c_cred + [v/(v+κ)]·z_FNN1(Y) for context instances only.
  3. **ICL Transformer Layer**: Standard Transformer encoder layer with causal masking M (prevents target-target interaction), takes concatenated [context; target] decorated tokens, outputs ICL-adjusted tokens.
  4. **Frozen Decoder**: FNN z_decod maps 2b-dim CLS token → prediction μ (e.g., Poisson rate). Frozen in Phase 2, optionally unfrozen in Phase 3.

- Critical path:
  1. Phase 1: Train base Credibility Transformer end-to-end with early stopping → obtain fitted encoder c_cred and decoder z_decod.
  2. Phase 2: Freeze decoder; insert outcome decorator + ICL Transformer; train on context-target batch pairs with loss only on target set.
  3. Phase 3 (optional): Unfreeze all components; fine-tune with small learning rate and strong regularization.
  4. Inference: For each target chunk, retrieve K nearest neighbors from training set (cosine similarity in CLS token space), construct context batch, forward pass with causal masking.

- Design tradeoffs:
  - **Context batch size c vs. retrieval precision**: Larger c provides more information but increases computation and may include less-relevant instances. Paper uses c=1000 with K=64 neighbors per target.
  - **Linearized vs. non-linear ICL**: Linearized version (queries/keys exclude response info) preserves strict Bühlmann interpretation but underperforms slightly (23.723 vs 23.676 out-of-sample after fine-tuning).
  - **Frozen vs. unfrozen decoder**: Freezing stabilizes training but may limit expressivity; unfreezing improves performance but risks overfitting and requires careful regularization.

- Failure signatures:
  - **Attention sink to context**: If attention weights concentrate on a few context instances regardless of similarity, check retrieval quality and κ setting.
  - **CLS token collapse**: After Phase 2, if CLS tokens cluster tightly (Figure 3a shows "squashing"), the encoder may have deferred too much to the ICL layer—consider larger embedding dimension or Phase 3 fine-tuning.
  - **Zero-shot failure on new categories**: If predictions on unseen levels default to global mean, ensure the "unseen" token was present during training (paper sacrificed 20% of training exposure for this).

- First 3 experiments:
  1. **Baseline reproduction**: Train base Credibility Transformer on French MTPL; verify out-of-sample Poisson deviance ~23.74. Confirm CLS token embeddings capture risk structure via PCA visualization.
  2. **Ablation on κ**: Train ICL-Credibility Transformer with κ ∈ {100, 500, 1000, 5000}; plot context credibility weight v/(v+κ) vs. out-of-sample loss. Identify optimal κ range.
  3. **Zero-shot validation**: Hold out one Region from training; train with "unseen" token on 15-20% of remaining data; compare ICL predictions vs. baseline on held-out region. Measure degradation relative to full-information model.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the dynamic selection of context batches be justified to regulators to ensure transparency and fairness?
- Basis in paper: [explicit] The authors state regulators will demand transparency regarding why specific policies are used as context to ensure no bias is introduced.
- Why unresolved: Current explanation frameworks are insufficient for dynamic, instance-specific peer groups used in pricing.
- What evidence would resolve it: A framework for explaining context selection that satisfies regulatory standards for actuarial fairness.

### Open Question 2
- Question: How can the nearest-neighbor retrieval process be scaled efficiently to real-world portfolio sizes?
- Basis in paper: [explicit] The authors note that scaling the retrieval process to large portfolios may present a computational challenge.
- Why unresolved: Real-time inference on massive datasets requires retrieval mechanisms faster than current approximate search methods allow.
- What evidence would resolve it: Benchmarking the model on datasets significantly larger than French MTPL with low inference latency.

### Open Question 3
- Question: Can the ICL-Credibility Transformer be effectively applied to individual claims reserving?
- Basis in paper: [explicit] The conclusion identifies individual claims reserving as a potential field where context is formed by similar developed claims.
- Why unresolved: The current architecture is validated for pricing (frequency), whereas reserving involves different data structures and target variables.
- What evidence would resolve it: Empirical validation showing improved reserve accuracy when using ICL with similar historical claims as context.

## Limitations

- The mechanism depends critically on the quality of context retrieval—if CLS embeddings poorly discriminate risk profiles, the ICL layer cannot compensate.
- The zero-shot generalization result is promising but narrow, demonstrating robustness to only one held-out categorical feature with modest improvement over baseline.
- The frozen decoder constraint may limit the model's capacity to adapt to complex context-target relationships despite regularization benefits.
- The theoretical analysis assumes linear features, yet the experimental model uses non-linear FNN embeddings and Transformer layers, creating a gap between theory and practice.

## Confidence

- **High confidence**: The base Credibility Transformer architecture and three-phase training procedure are well-specified and reproducible. The retrieval mechanism (FAISS cosine similarity on L2-normalized CLS tokens) is standard and clearly described.
- **Medium confidence**: The theoretical connection between attention weights and Bühlmann credibility holds under Proposition 3.1's assumptions (linear features, linear ICL), but the paper extends this interpretation to the non-linear experimental model without rigorous justification. The zero-shot generalization capability is demonstrated but only for one categorical dimension.
- **Low confidence**: Claims about the frozen decoder's benefits (calibration preservation, implicit regularization) are stated but not empirically validated. The paper does not compare against alternative ICL approaches (e.g., TabICL) on the same dataset.

## Next Checks

1. **Context retrieval quality analysis**: For a stratified sample of test instances, visualize the distribution of retrieval similarity scores and compute the correlation between top-K context instances' base predictions and target predictions. Determine whether high-similarity contexts actually have similar risk profiles or if the CLS embedding space is noisy.

2. **Cross-categorical generalization**: Repeat the zero-shot experiment for each categorical feature (Area, VehGas, VehBrand, Region) individually, holding out one level at a time. Measure the degradation in Poisson deviance when the target instance's feature is held out versus when it's present in context. This will reveal whether the model genuinely learns to rely on context or simply memorizes feature-outcome mappings.

3. **Attention weight distribution validation**: For test predictions where ICL improves upon base CT, plot the attention weight distributions across context instances. Verify that weights concentrate on truly similar instances (high retrieval similarity) rather than distributing uniformly or attending to outliers. Compute the correlation between attention weight magnitude and context-target similarity for improved predictions.