---
ver: rpa2
title: 'CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud
  and Local LLMs'
arxiv_id: '2510.15455'
source_url: https://arxiv.org/abs/2510.15455
tags:
- task
- cloud
- local
- page
- open
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CORE, a collaborative framework that combines
  cloud-based and local LLMs to reduce unnecessary UI exposure in mobile agents while
  maintaining task accuracy. The framework employs layout-aware block partitioning,
  co-planning between local and cloud models, and co-decision-making with multi-round
  accumulation to selectively transmit only task-relevant UI elements to the cloud.
---

# CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs

## Quick Facts
- arXiv ID: 2510.15455
- Source URL: https://arxiv.org/abs/2510.15455
- Authors: Gucongcong Fan; Chaoyue Niu; Chengfei Lyu; Fan Wu; Guihai Chen
- Reference count: 40
- Reduces UI exposure by up to 55.6% while maintaining task accuracy

## Executive Summary
This paper presents CORE, a collaborative framework that combines cloud-based and local LLMs to reduce unnecessary UI exposure in mobile agents while maintaining task accuracy. The framework employs layout-aware block partitioning, co-planning between local and cloud models, and co-decision-making with multi-round accumulation to selectively transmit only task-relevant UI elements to the cloud. Experiments on DroidTask and AndroidLab datasets show CORE achieves significant privacy gains with minimal impact on task success rates.

## Method Summary
CORE operates through three main phases: partitioning, co-planning, and co-decision-making. First, the UI XML hierarchy is parsed to create semantically related blocks based on ancestor paths. The local LLM then processes each block separately to generate sub-task candidates, which the cloud LLM selects or revises. Finally, the local LLM probabilistically ranks blocks by relevance, and the cloud LLM iteratively receives top-ranked blocks until sufficient information is provided for decision-making. This asymmetric collaboration leverages the local model's full-page access and the cloud model's superior reasoning while minimizing UI exposure.

## Key Results
- Reduces UI exposure by up to 55.6% on DroidTask and 34.96% on AndroidLab datasets
- Maintains task success rates within 4.9% and 3.06% of GPT-4o baseline respectively
- Significantly reduces sensitive UI element exposure by 70.49% and 38.84% on respective datasets
- Overall latency 1.5-1.66× baseline due to local processing overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partitioning UI elements based on XML tree ancestry groups semantically related elements, enabling more targeted filtering than arbitrary segmentation.
- Mechanism: Depth-first traversal extracts important nodes while recording ancestor paths; elements sharing ancestors at a selected tree depth are grouped into blocks. This preserves UI design intent rather than disrupting logical clusters.
- Core assumption: UI elements under the same ancestor container node are more likely to belong to the same logical or visual region due to layout design conventions.
- Evidence anchors:
  - [section 3.1] "Many unimportant nodes skipped during traditional processing (e.g., layout containers like FrameLayout) act as shared ancestors of multiple important elements. The elements under the same ancestor container node are more likely to belong to the same logical or visual region due to the UI layout design."
  - [abstract] Describes "layout-aware block partitioning, which groups semantically related UI elements based on the XML screen hierarchy."
  - [corpus] Limited external validation; neighbor papers (EcoAgent, LightAgent) address device-cloud collaboration but don't specifically test XML-hierarchy partitioning.
- Break condition: Fails when XML structure is flat (few container nodes), unbalanced, or doesn't reflect user-perceived groupings—e.g., Settings app in evaluation showed limited reduction due to layout structure.

### Mechanism 2
- Claim: Co-planning improves sub-task accuracy by having the local LLM propose candidates from each block and the cloud LLM select or revise them, indirectly inferring page context without direct UI access.
- Mechanism: Local LLM processes each block separately (divide-and-conquer) to generate sub-task candidates; cloud LLM receives candidates plus task history and selects the best one or generates a corrected version. This leverages local's full-page access and cloud's stronger reasoning.
- Core assumption: The local LLM can produce useful high-level abstractions about block functionality without leaking specific element details, and the cloud LLM can piece together page context from these abstractions.
- Evidence anchors:
  - [section 3.2] "The sub-task candidate derived from each block represents high-level abstractions over the block's UI elements... the cloud LLM can piece together an approximate understanding of the overall page layout and content."
  - [ablation, section 4.3] Removing co-planning causes 9.79% success rate drop and 6.93% reduction drop: "This ablation underscores the critical role of sub-task co-planning in guiding the local LLM to better rank UI blocks."
  - [corpus] PRISM (arXiv:2511.22788) proposes semantic sketch collaboration between edge and cloud, conceptually similar but not directly validating this specific mechanism.
- Break condition: Fails when local LLM generates irrelevant or misleading candidates across all blocks, leaving cloud with no good options; observed in weaker local models (LLaMA 3.1-8B baseline at 9.79% success).

### Mechanism 3
- Claim: Co-decision-making with multi-round accumulation provides fault tolerance against local misranking while maintaining privacy gains.
- Mechanism: Local LLM probabilistically scores blocks for relevance; top-ranked block sent to cloud. If cloud deems information insufficient (returns index=-1), next-ranked block is accumulated iteratively until confident decision possible.
- Core assumption: Local LLM's ranking, even if imperfect, has positive correlation with actual relevance, so top blocks are more likely useful than random ordering.
- Evidence anchors:
  - [section 3.3] "If the cloud LLM considers the selected block insufficient for a proper decision, it will incrementally ask the local LLM for additional blocks until the provided information is judged to be adequate."
  - [ablation, section 4.3] Random ranking causes 17.48% success drop vs. 32.87% drop when removing multi-round entirely, showing ranking value and accumulation's recovery role.
  - [corpus] No direct external validation of this specific accumulation pattern; GauDP addresses multi-agent coordination but in diffusion policy context.
- Break condition: Fails when task requires context from multiple dispersed blocks that local LLM ranks poorly; or when cloud LLM's sufficiency threshold is miscalibrated (too aggressive or too conservative).

## Foundational Learning

- Concept: **XML-based UI representation and Android view hierarchy**
  - Why needed here: CORE relies on parsing XML to extract UI elements and their structural relationships; understanding how Android layouts map to XML trees is essential for implementing and debugging block partitioning.
  - Quick check question: Given an Android XML with nested LinearLayouts containing buttons and text views, can you trace which elements share a parent container and would be grouped together?

- Concept: **Device-cloud collaborative inference patterns**
  - Why needed here: CORE's core innovation is asymmetric collaboration—local has full UI access but weak reasoning; cloud has strong reasoning but no direct UI access. Understanding this split informs why each component exists and where failures propagate.
  - Quick check question: In a device-cloud system, if the edge model provides filtered summaries to the cloud for final inference, what happens if the filtering is too aggressive? What if it's too conservative?

- Concept: **Probabilistic scoring and normalization for ranking**
  - Why needed here: Local LLM outputs probability scores for block relevance that must sum to 1. Understanding calibration and normalization helps diagnose ranking failures.
  - Quick check question: A local model outputs raw scores [3.2, 0.8, 1.5] for three blocks. How do you normalize these to probabilities? What if one block consistently dominates?

## Architecture Onboarding

- Component map:
  - On-device preprocessing: XML parser → ancestor path extraction → block partitioning (selects first depth level yielding ≥3 blocks)
  - Co-planning: Local LLM (block-by-block sub-task generation) → candidate aggregation → Cloud LLM (sub-task selection/revision)
  - Co-decision-making: Local LLM (block scoring/ranking) → iterative block upload → Cloud LLM (element selection + sufficiency check) → action execution
  - State management: History H_t accumulates across steps; multi-round accumulation within a step until cloud confident

- Critical path: Co-planning accuracy → local ranking quality → number of accumulation rounds → privacy-accuracy tradeoff. If co-planning fails, local misranks blocks, triggering more accumulation rounds, reducing privacy gains and potentially degrading decisions.

- Design tradeoffs:
  - **Privacy vs. accuracy**: Higher reduction rates correlate with larger success drops (DroidTask: 55.6% reduction, 4.9% drop; AndroidLab: 34.96% reduction, 3.06% drop—though best setting varies by dataset)
  - **Latency vs. reduction**: Overall latency 1.5–1.66× GPT-4o baseline due to local processing overhead; limiting blocks to ≤3 reduces latency ~10–15% but also reduces privacy gains
  - **Local model strength vs. collaboration benefit**: Stronger local models (Gemma2-9B > Qwen2.5-7B > LLaMA3.1-8B) yield better success rates and reduction rates, but even weak models gain substantially over standalone baselines

- Failure signatures:
  - **Block partitioning failures**: Apps with flat/unbalanced XML yield few blocks, limiting reduction (e.g., Settings, Pimusic in evaluation)
  - **Co-planning failures**: Local model generates irrelevant sub-task candidates → cloud selects poor sub-task → local misranks blocks → more accumulation rounds needed
  - **Accumulation loops**: If cloud consistently returns index=-1, check if local ranking is inverted or if task genuinely requires full-page context (CORE may be unsuitable for such tasks)
  - **Token cost surprises**: On complex apps (AndroidLab), reduced upload volume offsets extra communication overhead, potentially lowering total token cost vs. baseline

- First 3 experiments:
  1. **Baseline comparison on single app**: Pick one app from DroidTask (e.g., Clock with simple UI). Run GPT-4o baseline, local-only (Gemma2-9B), and CORE (GPT-4o + Gemma2-9B). Compare success rate, reduction rate, and per-step block count. Verify 55–60% reduction with minimal accuracy loss on simple tasks.
  2. **Ablation on block partitioning**: Replace layout-aware partitioning with equal-split (e.g., divide all elements into 3 groups). Expect ~7% success drop and ~2% reduction drop per Section 4.3. Confirm XML hierarchy is being leveraged correctly.
  3. **Multi-round accumulation stress test**: On a task requiring cross-block context (e.g., Calendar event creation involving date picker + title input + save button), log number of accumulation rounds per step. If rounds consistently high (>3), investigate whether co-planning is generating misleading sub-tasks or if task genuinely requires broad context.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can CORE be adapted to pure vision-based GUI agents that do not rely on XML accessibility trees?
- Basis in paper: [explicit] The conclusion states: "Looking forward, the rapid development of multimodal GUI agents opens opportunities for extending CORE beyond XML to vision-based pipelines...future work will explore pure-visual pipelines and broader multimodal integrations."
- Why unresolved: Current CORE relies on XML tree structure for layout-aware block partitioning. Vision-based agents require different spatial reasoning and segmentation approaches.
- What evidence would resolve it: A version of CORE using visual segmentation instead of XML parsing, evaluated on the same benchmarks with comparable reduction and success rates.

### Open Question 2
- Question: What is the minimum capability threshold for local LLMs to make CORE effective?
- Basis in paper: [inferred] Table 1 shows dramatic performance variance with different local models (Gemma2-9B: 69.23% success vs. LLaMA3.1-8B: 49.65% on DroidTask). The local-only baselines range from 9.79% to 32.87% success.
- Why unresolved: The paper demonstrates correlation but does not systematically characterize the minimum local model requirements or whether fine-tuning smaller models could bridge the gap.
- What evidence would resolve it: Controlled experiments varying local model size/capability while holding other factors constant, or fine-tuning experiments on mobile agent-specific tasks.

### Open Question 3
- Question: How can sensitive element detection be performed without introducing additional privacy risks from cloud-based classification?
- Basis in paper: [inferred] The privacy analysis uses Qwen2.5-Max (a cloud LLM) to classify sensitive UI elements. This creates a potential circular dependency where privacy protection relies on cloud services.
- Why unresolved: The paper quantifies privacy benefits but delegates sensitive element identification to another cloud model, which may itself constitute a privacy exposure.
- What evidence would resolve it: An on-device sensitive element classifier, or analysis showing the classification queries reveal negligible private information compared to full UI exposure.

## Limitations

- Framework effectiveness heavily depends on XML hierarchy reflecting logical UI groupings, which may not hold for apps with flat or non-hierarchical layouts
- Exact heuristics for identifying "important nodes" during XML traversal are only summarized, not explicitly defined
- Accumulation mechanism's sufficiency threshold is not quantified, making it difficult to predict when excessive accumulation rounds might occur

## Confidence

- **High Confidence**: Core mechanism claims (layout-aware partitioning, co-planning, co-decision-making) are well-supported by ablation studies showing measurable impact on success rates and reduction rates
- **Medium Confidence**: Privacy claims regarding sensitive element reduction are supported but lack detailed breakdown of what constitutes "sensitive" elements or how false positives/negatives in filtering might affect user experience
- **Medium Confidence**: Latency claims (1.5-1.66× baseline) are reported but lack comparison of per-step breakdown or discussion of network variability effects

## Next Checks

1. **Layout Structure Validation**: Test CORE on apps with known flat XML hierarchies (e.g., simple list-based interfaces) to quantify the reduction in effectiveness when XML structure doesn't reflect logical groupings

2. **Accumulation Threshold Analysis**: Instrument the framework to log cloud LLM sufficiency decisions and measure distribution of accumulation rounds across different task types to identify when the mechanism triggers excessive iterations

3. **Cross-Device Performance**: Evaluate CORE on lower-end devices (e.g., older Android versions with weaker GPUs) to assess whether local processing overhead negates privacy benefits in resource-constrained environments