---
ver: rpa2
title: Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning
  with Continuous Action Space
arxiv_id: '2508.15764'
source_url: https://arxiv.org/abs/2508.15764
tags:
- agents
- agent
- detection
- action
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses decentralized detection of adversarial attacks
  in multi-agent reinforcement learning (MARL) with continuous action spaces. It proposes
  a detector that uses deep neural networks to model the actions of other agents as
  multivariate Gaussian distributions based on local observations.
---

# Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space

## Quick Facts
- arXiv ID: 2508.15764
- Source URL: https://arxiv.org/abs/2508.15764
- Reference count: 40
- Primary result: Decentralized detector for MARL with continuous actions using Gaussian modeling and CUSUM achieves AUC-ROC > 0.95 on PettingZoo benchmarks.

## Executive Summary
This paper addresses the challenge of detecting adversarial attacks in multi-agent reinforcement learning systems with continuous action spaces. The proposed method models each agent's actions as multivariate Gaussian distributions conditioned on local observations, then uses a two-sided CUSUM procedure on a normality score to detect anomalies in real-time. Evaluated across four PettingZoo environments against various attacks, the detector achieves high AUC-ROC scores (>0.95) and outperforms discrete-action baselines, particularly when using full covariance matrices to capture action correlations.

## Method Summary
The detection framework trains RNN-based predictor networks (NETij) for each observer-target agent pair to model the conditional distribution of actions as multivariate Gaussians. These networks output mean vectors and Cholesky factors of covariance matrices based on observation histories. A normality score derived from the log-likelihood of actual actions is computed and monitored using a two-sided CUSUM procedure, with theoretical mean and variance characterized for optimal threshold selection. The system is trained on normal cooperative behavior and deployed to detect deviations caused by adversarial attacks.

## Key Results
- AUC-ROC scores exceed 0.95 against most impactful attacks (ACT, FGSM) across all tested environments
- Full covariance modeling (PGC) significantly outperforms diagonal covariance (I-PGC) when action dimensions are correlated
- Parameter sharing reduces required models from K(K-1) to K while maintaining high detection accuracy
- Detector remains effective in multi-victim scenarios and against various attack types, though DYN attacks show lower AUC (~0.91)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modeling agent actions as multivariate Gaussian distributions enables effective detection of adversarial attacks in continuous action spaces.
- Mechanism: A recurrent neural network (NETij) learns to predict the parameters (mean μ and full covariance matrix Σ) of a Gaussian distribution representing agent j's expected actions, conditioned on agent i's observation history. The full (non-diagonal) covariance captures correlations between action dimensions.
- Core assumption: The conditional distribution of an agent's actions, given another agent's observations, can be sufficiently approximated by a multivariate Gaussian distribution.
- Evidence anchors:
  - [abstract] "The proposed detector utilizes deep neural networks to approximate the normal behavior of agents as parametric multivariate Gaussian distributions."
  - [section 4.1] "We propose to approximate the action distribution f ij(.|τ i t ) of agent j from agent i's point of view by a dj-dimensional Gaussian distribution... parameterized by its mean, µij t (τ i t )... and its covariance matrix, Σij t (τ i t )..."
  - [corpus] Corpus papers discuss adversarial robustness (e.g., "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning") but do not validate the Gaussian assumption for this specific detection task.
- Break condition: The Gaussian assumption becomes a poor fit if the true conditional action distribution is highly multi-modal or non-Gaussian (e.g., a mixture model), potentially reducing detection accuracy.

### Mechanism 2
- Claim: A normalized log-likelihood based "normality score" provides a stable, time-invariant signal for detecting behavioral deviations.
- Mechanism: The detector computes a score z = log( f(actual_action) / max(f(x)) ). If the action follows the predicted Gaussian, this score is directly related to the Mahalanobis distance. Crucially, the *expected value* of this score (E[z] = -d/2) is constant and independent of time or state, simplifying the detection problem.
- Core assumption: The predicted Gaussian distribution accurately reflects the statistics of the agent's normal behavior.
- Evidence anchors:
  - [abstract] "Based on the predicted density functions, we define a normality score and provide a characterization of its mean and variance."
  - [section 4.2] "Proposition 1 shows that, although the distribution of predicted actions varies over time, as long as the actions of agent j follow the conditional distribution expected by observer agent i, the expected value of the normality score remains constant."
  - [corpus] Evidence from corpus papers is weak for this specific statistical property.
- Break condition: The mean of the normality score will drift or become state-dependent if the predicted distribution does not match the true distribution of agent actions.

### Mechanism 3
- Claim: A Cumulative Sum (CUSUM) procedure applied to the normality score enables real-time, low-latency detection of mean shifts caused by attacks.
- Mechanism: The CUSUM algorithm accumulates positive and negative deviations of the normality score from its known theoretical mean. It is designed to detect a persistent shift in the mean of a sequence. An alert is triggered when the cumulative deviation exceeds a threshold.
- Core assumption: CUSUM remains robust despite temporal dependencies in the normality score sequence. The attack induces a detectable shift in the mean of the normality score.
- Evidence anchors:
  - [abstract] "...we employ a two-sided CUSUM procedure for detecting deviations of the normality score from its mean, serving as a detector of anomalous behavior in real-time."
  - [section 4.2] "We thus propose to apply CUSUM on the normality score ztij combined with Proposition 1 for detection. As shown in Section 5, it performs well despite samples not being independent."
  - [corpus] Corpus evidence for the CUSUM method itself is weak or missing.
- Break condition: If an adaptive adversary (like DYN) crafts attacks to minimize deviation of the normality score from its expected mean, CUSUM performance will degrade, potentially increasing miss rates.

## Foundational Learning

### Concept: Dec-POMDP (Decentralized Partially Observable Markov Decision Process)
- Why needed here: The paper's system model is a Dec-POMDP. Understanding that each agent has partial observations (oi) and acts based on a local history (τi) is fundamental to why detection must be based on local observation sequences.
- Quick check question: Can an agent directly observe the full state `S` of the environment?

### Concept: Multivariate Gaussian Distribution & Covariance
- Why needed here: The core detection mechanism models action probabilities using multivariate Gaussians. The explicit use of a non-diagonal covariance matrix to capture action dimension correlations is a key design choice.
- Quick check question: In a 2D action space, what does a non-zero off-diagonal element in the covariance matrix Σ represent?

### Concept: CUSUM (Cumulative Sum) Algorithm
- Why needed here: The detection decision rule is a two-sided CUSUM. Understanding that it's a sequential analysis technique for detecting change points in a time series by accumulating deviations from a target mean is critical.
- Quick check question: What is the primary advantage of using CUSUM over a simple threshold on the instantaneous score for detecting persistent changes?

## Architecture Onboarding

### Component map:
- **Trained MARL Policies** → **Predictor Network (NETij)** → **Normality Score Calculator** → **Two-Sided CUSUM** → **Decision Logic**

### Critical path:
1. Collect data from normal MARL execution.
2. Train all required NETij predictor networks by maximizing log-likelihood (Eq. 4).
3. Deploy detector alongside MARL agents.
4. For each time step, generate observation for observer, predict action distribution for target, receive target's actual action, compute normality score, update CUSUM, and check for alert.

### Design tradeoffs:
- **Full vs. Diagonal Covariance:** A full covariance matrix (PGC) captures action correlations but has higher output complexity (d + d*(d+1)/2 outputs). Diagonal covariance (I-PGC) is simpler (2d outputs) but performs poorly when action dimensions are correlated.
- **Parameter Sharing:** Sharing predictor network weights across all observers of a single target reduces the number of models from K(K-1) to K, improving sample efficiency, but requires agent symmetry and homogeneous observation spaces.
- **Sensitivity Parameter (w):** The CUSUM parameter `w` controls the detection sensitivity. A lower `w` makes the detector more sensitive to smaller deviations but may increase false positives.

### Failure signatures:
- **High False Positive Rate:** If the Gaussian model is a poor fit for normal behavior, the normality score's mean may drift, triggering spurious alerts.
- **Missed "Stealthy" Attacks:** The DYN (Dynamic Adversary) attack is specifically designed to evade this detector by keeping the normality score near its expected mean. Detection of such attacks may be poor (e.g., AUC < 0.91 in Pistonball vs. ~0.999 for ACT).
- **Detection Latency:** Less impactful attacks (e.g., GRAD) take longer to trigger a detection, as they cause smaller shifts in the score's mean.

### First 3 experiments:
1. Implement a simple 2-agent MARL task with correlated action dimensions. Train a single predictor network with a diagonal covariance and compare its training loss and detection AUC against a predictor with a full covariance to empirically validate the importance of modeling correlations.
2. Generate normal agent data and train a predictor. Plot the histogram of the calculated normality score (z) against its theoretical distribution (Gaussian with mean -d/2, variance d/2) to verify Proposition 1.
3. Implement the CUSUM detector with the trained predictor. Subject the agent to a simple "random action" attack and plot the trajectory of the cumulative sum (c+) to observe how quickly it detects the anomaly compared to a simple threshold on the raw score.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the decentralized PGC detector be effectively adapted to handle multi-modal action distributions where a single Gaussian approximation fails?
- Basis in paper: [explicit] Appendix A acknowledges that in environments where the conditional action distribution is multi-modal, a single Gaussian may be a poor approximation, and "a centralized approach might be needed."
- Why unresolved: The current neural network architecture is constrained to outputting a single mean vector and covariance matrix, which cannot represent the distinct peaks of a multi-modal policy distribution.
- What evidence would resolve it: A modification of the detector (e.g., using Mixture Density Networks) that maintains high AUC-ROC scores in environments designed to induce multi-modal agent behaviors, without relying on centralized data collection.

### Open Question 2
- Question: How can the computational complexity of the detection framework be minimized for heterogeneous MARL systems where parameter sharing is inapplicable?
- Basis in paper: [explicit] Section 5.7 notes that parameter sharing is applicable "only to environments where the dimension of all agents' observations is the same," implying a gap in scalability for diverse agent types.
- Why unresolved: Without parameter sharing, the system requires training and maintaining |K| × |K_i| distinct predictor networks, which becomes resource-intensive in complex, heterogeneous teams.
- What evidence would resolve it: A training methodology or network architecture that generalizes across agents with different observation and action spaces, achieving comparable detection performance with significantly fewer unique model parameters.

### Open Question 3
- Question: Is there a theoretically optimal stopping rule for the normality score sequence that accounts for temporal dependencies better than the heuristic CUSUM application?
- Basis in paper: [inferred] Section 4.2 states that while CUSUM is optimal for i.i.d. samples, the normality scores z_t are not independent, and the complexity of dependencies makes deriving an optimal stopping rule "infeasible."
- Why unresolved: The current approach relies on a heuristic application of CUSUM which lacks theoretical optimality guarantees for dependent data streams, potentially leaving room for improved detection speed or accuracy.
- What evidence would resolve it: The derivation of a detection algorithm with provable optimality bounds for the specific dependency structure of the normality scores, or empirical evidence showing a statistically significant reduction in detection delay compared to the two-sided CUSUM baseline.

## Limitations
- The Gaussian assumption for action distributions is primarily justified empirically rather than theoretically, potentially limiting effectiveness for non-Gaussian behaviors.
- High computational overhead requires training K(K-1) predictor networks, with parameter sharing only applicable to symmetric agent teams.
- Detection performance against adaptive attacks (DYN) shows significant degradation with AUC dropping to ~0.91 compared to ~0.999 for simpler attacks.

## Confidence

### High Confidence:
- The statistical framework (Gaussian modeling + normality score + CUSUM) is internally consistent with sound mathematical derivations.

### Medium Confidence:
- The claim that CUSUM works well despite temporal dependencies is based on empirical observation without deep theoretical analysis.
- Superiority of full covariance models is well-supported but lacks analysis of training complexity tradeoffs.

### Low Confidence:
- N/A (no claims identified as low confidence)

## Next Checks

1. **Evaluate Detection Latency:** For each attack type, report the average number of steps between the start of an attack and the first detection (alert). This metric is crucial for understanding the practical utility of the detector in real-time scenarios.

2. **Test with Non-Gaussian Action Distributions:** Create a synthetic MARL environment where the true conditional action distribution is a known mixture of Gaussians (e.g., a bimodal distribution). Evaluate the detector's performance to empirically test the limits of the Gaussian assumption.

3. **Analyze CUSUM Parameters:** Perform a sensitivity analysis on the CUSUM parameters (w, β). Report how the detection performance (AUC-ROC, FPR, detection delay) changes with different values of w and β to understand the detector's robustness to parameter tuning.