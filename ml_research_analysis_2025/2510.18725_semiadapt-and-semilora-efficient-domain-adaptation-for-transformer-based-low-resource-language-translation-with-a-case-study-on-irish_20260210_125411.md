---
ver: rpa2
title: 'SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based
  Low-Resource Language Translation with a Case Study on Irish'
arxiv_id: '2510.18725'
source_url: https://arxiv.org/abs/2510.18725
tags:
- domain
- translation
- irish
- language
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SemiAdapt and SemiLoRA, two efficient semi-supervised
  domain adaptation methods for low-resource neural machine translation. The approaches
  use zero-shot classifiers to assign sentence-level domain labels during training
  and then apply domain embedding centroids for efficient inference-time domain assignment,
  eliminating the need for classifiers at inference.
---

# SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish

## Quick Facts
- **arXiv ID:** 2510.18725
- **Source URL:** https://arxiv.org/abs/2510.18725
- **Reference count:** 0
- **Primary result:** SemiLoRA matches or outperforms full-model fine-tuning for English-to-Irish domain adaptation while training only ~1.4% of parameters.

## Executive Summary
This paper introduces SemiAdapt and SemiLoRA, two semi-supervised domain adaptation methods for low-resource neural machine translation. The approaches use zero-shot classifiers to assign sentence-level domain labels during training and then apply domain embedding centroids for efficient inference-time domain assignment, eliminating the need for classifiers at inference. Experiments on English-to-Irish translation show that SemiLoRA, a parameter-efficient LoRA-based method, can match or even outperform full-model fine-tuning while requiring significantly fewer trainable parameters. SemiAdapt, applied to full-model fine-tuning, also improves domain-specific translation performance. Both methods are particularly effective for larger and noisier corpora. The study demonstrates that sentence-level domain labeling leads to better performance than dataset-level labeling. All models and code are released as open resources, aiming to make domain adaptation more accessible for low-resource language translation.

## Method Summary
SemiAdapt and SemiLoRA address domain adaptation for low-resource neural machine translation by first using a zero-shot NLI classifier (bart-large-mnli) to assign sentence-level domain labels during training. The corpus is then split by these labels, and domain-specific adapters are trained using either full-model fine-tuning (SemiAdapt) or LoRA-based parameter-efficient fine-tuning (SemiLoRA). At inference time, domain assignment is performed via cosine similarity between input embeddings and pre-computed domain centroid embeddings, eliminating the need for a classifier during serving. The methods are evaluated on English-to-Irish translation across four domains (general, legal, wiki/news, medical/COVID-19) using BLEU scores as the primary metric.

## Key Results
- SemiLoRA achieves substantial improvements over standard LoRA, with gains of 11 BLEU in the medical domain, 1.7 BLEU in the wiki/news domain, and 3.5 BLEU in the legal domain.
- SemiLoRA matches or exceeds full-model fine-tuning performance while training only ~1.4% of parameters (8.65M out of 623.72M total).
- Sentence-level domain labeling produces better translation quality than dataset-level labeling, particularly on larger and noisier corpora.
- The centroid-based domain assignment at inference eliminates the computational overhead of running a classifier during serving.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sentence-level domain labeling produces cleaner domain splits than dataset-level labeling, improving translation quality on larger/noisier corpora.
- **Mechanism:** A zero-shot NLI classifier (bart-large-mnli) assigns domain labels per sentence, filtering out domain-misaligned pairs. This reduces noise where sentences from a medical corpus contain domain-agnostic content (e.g., "What is added by this report?").
- **Core assumption:** The zero-shot classifier's domain assignments are sufficiently accurate to improve over source-based labeling.
- **Evidence anchors:**
  - [Section 4.3]: "This suggests that large, noisy datasets could benefit from a more granular approach to domain labelling... supported by our results from the SemiLoRA and SemiAdapt experiments, where better translation performance was recorded across each of the domains."
  - [Section 4.1]: "We hypothesise that this preprocessing technique will form better domain groupings and consequently improve domain adaptation performance."
  - [corpus]: Weak direct validation. Related work (TULUN, Beyond Vanilla Fine-Tuning) addresses low-resource MT but does not specifically validate sentence-level vs. dataset-level labeling efficacy.
- **Break condition:** If zero-shot classifier accuracy is poor for a given domain or language pair, noise reduction may fail or introduce new mislabeling errors.

### Mechanism 2
- **Claim:** Domain embedding centroids enable inference-efficient domain assignment without requiring a classifier at inference time.
- **Mechanism:** During training, centroid embeddings are computed per domain. At inference, input sentence embeddings are compared to centroids via cosine similarity; the nearest centroid determines domain routing. This removes the computational overhead of running a classifier during serving.
- **Core assumption:** Semantic similarity between input embeddings and domain centroids correlates with appropriate domain assignment for translation routing.
- **Evidence anchors:**
  - [Section 4.1]: "SemiLoRA involves computing centroid embeddings for each domain in the training split and comparing them with the embeddings of input sentences... Domains are essentially assigned based on the semantic similarity of a given input sentence and the average representation for each domain label."
  - [Section 4.2]: "SemiLoRA achieves substantial improvements over LoRA, with gains of 11 BLEU in the medical domain, 1.7 BLEU in the wiki/news domain, and 3.5 BLEU in the legal domain."
  - [corpus]: No direct corpus validation of centroid-based routing vs. classifier-based routing in NMT.
- **Break condition:** If domains share significant semantic overlap (e.g., legal and general domains), centroid-based assignment may misroute inputs to wrong adapters.

### Mechanism 3
- **Claim:** LoRA-based PEFT with domain-specific adapters can match or exceed full-model fine-tuning while training only ~1.4% of parameters.
- **Mechanism:** LoRA freezes pre-trained weights and injects trainable low-rank matrices into attention (q_proj, k_proj, v_proj, out_proj) and feed-forward (fc1, fc2) layers. Domain-specific adapters are trained separately and can be swapped at inference.
- **Core assumption:** The rank-16 decomposition captures sufficient representational capacity for domain-specific translation adjustments.
- **Evidence anchors:**
  - [Section 4.2]: "SemiLoRA achieves considerable improvements over full-model fine-tuning... SemiLoRA falls slightly short (0.7 BLEU) of SemiLoRA on the medical domain, despite the SemiLoRA adapter being 1.39% (8.65M parameters) of the NLLB-200 model's full size (623.72M parameters)."
  - [Table 2]: SemiLoRA achieves 51.29 BLEU on medical domain vs. 50.61 for SemiAdapt (full-model).
  - [corpus]: Related work (Can Smaller LLMs do better?) explores PEFT for summarization but does not validate LoRA specifically for NMT domain adaptation.
- **Break condition:** If domains require substantial vocabulary or syntactic changes beyond adapter capacity, LoRA may underperform full fine-tuning.

## Foundational Learning

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed here: Core technique enabling parameter-efficient domain adaptation. Must understand weight freezing, rank selection, and adapter injection points.
  - Quick check question: What happens to base model weights during LoRA training—frozen or updated?

- **Concept: Zero-Shot Classification with NLI Models**
  - Why needed here: Enables sentence-level domain labeling without labeled training data. Requires understanding of NLI entailment as proxy for classification.
  - Quick check question: How does a zero-shot NLI classifier assign domain labels without domain-specific training examples?

- **Concept: Embedding Centroids and Cosine Similarity**
  - Why needed here: Core mechanism for inference-time domain routing without classifiers.
  - Quick check question: Given embeddings for sentences in a domain, how would you compute the centroid and use it to classify a new input?

## Architecture Onboarding

- **Component map:**
  - nllb-200-distilled-600M base model -> bart-large-mnli zero-shot classifier (training only) -> LoRA adapters (rank=16, α=16) -> domain centroid store -> cosine similarity routing

- **Critical path:**
  1. Run zero-shot classifier on English sentences to assign domain labels (training only)
  2. Split parallel corpus by sentence-level domain labels
  3. Fine-tune base model on general domain first
  4. Train domain-specific LoRA adapters (or full-model variants) on each split
  5. Compute domain embedding centroids from training splits
  6. At inference: embed input → compare to centroids via cosine similarity → route to matching adapter

- **Design tradeoffs:**
  - 3-domain vs. 4-domain classification: 3-domain with confidence threshold outperforms on general domain but underperforms on specific domains
  - LoRA vs. full-model: LoRA enables parallel adapter training on single GPU; full-model requires more compute but may achieve slight gains on some domains
  - Sentence-level vs. dataset-level labeling: Sentence-level produces better BLEU across domains but adds preprocessing overhead

- **Failure signatures:**
  - Very low BLEU on large domains (e.g., 0.58 BLEU for legal in domain-by-dataset setup) suggests model memorization failure or domain mismatch
  - Poor general domain performance with centroid routing may indicate centroid noise from heterogeneous data
  - Full-model fine-tuning outperforming LoRA by >5 BLEU suggests adapter rank may be insufficient

- **First 3 experiments:**
  1. Replicate 4-domain SemiLoRA on a subset of the corpus to validate centroid-based routing vs. classifier-based routing on held-out evaluation set.
  2. Ablate sentence-level vs. dataset-level labeling on a single domain (e.g., medical) to isolate noise-reduction effect.
  3. Test LoRA rank sensitivity (r=8 vs. r=16 vs. r=32) on one domain to identify representational capacity requirements.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can combining SemiLoRA or SemiAdapt with a fully fine-tuned base model improve translation performance on noisy general-domain data?
- **Basis in paper:** The authors note that SemiLoRA struggles with noisy general data and state: "Combining a base model fine-tuned on the entire dataset with SemiLoRA for domain adaptation requires further exploration" and "we will continue experimenting with domain adaptation strategies, including combining SemiLoRA and SemiAdapt with a fully fine-tuned base model."
- **Why unresolved:** The experiments showed poor general-domain performance for SemiLoRA/SemiAdapt, suggesting the current two-stage approach (general pre-training then domain adaptation) may be suboptimal for handling domain-agnostic data.
- **What evidence would resolve it:** BLEU score comparisons between (1) current SemiLoRA/SemiAdapt pipelines and (2) variants that first full-dataset fine-tune the base model before applying domain-specific adapters or fine-tuning.

### Open Question 2
- **Question:** Do SemiLoRA and SemiAdapt transfer effectively to other low-resource languages beyond Irish?
- **Basis in paper:** The conclusion states: "For future work, we plan to extend our investigation of SemiLoRA and SemiAdapt to other LRLs and additional downstream tasks, such as dialogue generation."
- **Why unresolved:** All experiments were conducted exclusively on English-to-Irish translation using NLLB-200; it remains unknown whether the embedding-centroid domain assignment approach generalizes across languages with different morphological complexity, vocabulary sparsity, or parallel data availability.
- **What evidence would resolve it:** Replicating the SemiLoRA/SemiAdapt methodology on 3-5 other low-resource language pairs (e.g., English-to-Welsh, English-to-Maltese) and comparing domain-specific BLEU scores against full-model fine-tuning baselines.

### Open Question 3
- **Question:** What quality assessment and filtering methods can effectively leverage web-crawled Irish text for SemiLoRA/SemiAdapt training?
- **Basis in paper:** The limitations section states: "We therefore plan to investigate quality assessment and filtering methods to better leverage web-crawled sentence pairs" and notes that only 59% of Irish text in mC4 is correct natural language.
- **Why unresolved:** The study excluded web-crawled data entirely to maintain linguistic integrity, limiting available training data; no filtering experiments were conducted.
- **What evidence would resolve it:** Evaluating translation performance after training SemiLoRA/SemiAdapt on filtered web-crawled data using methods such as misalignment detection, language identification confidence thresholds, or fluency classifiers.

### Open Question 4
- **Question:** How sensitive are SemiLoRA and SemiAdapt to different heuristics for defining domain categories?
- **Basis in paper:** The conclusion states: "In addition, we wish to experiment further with different heuristics for defining domains."
- **Why unresolved:** The paper only tested two configurations (3-domain with confidence threshold and 4-domain without), and results varied substantially; optimal domain granularity and labeling strategies remain unclear.
- **What evidence would resolve it:** Ablation studies varying (1) the number of domains (e.g., 2, 4, 6, 8), (2) domain label definitions, and (3) confidence thresholds, measuring impact on domain-specific and overall BLEU scores.

## Limitations
- The centroid-based domain assignment method performs poorly on noisy general-domain data, suggesting limitations for handling domain-agnostic content.
- The study only evaluates on English-to-Irish translation, limiting generalizability to other language pairs or more resource-rich languages.
- Web-crawled parallel data was excluded due to quality concerns, potentially limiting the available training data for low-resource scenarios.

## Confidence
- **SemiLoRA parameter efficiency claim:** High - Supported by explicit parameter count comparisons and BLEU performance metrics.
- **Sentence-level vs. dataset-level labeling superiority:** Medium - Supported by results but could benefit from more controlled ablation studies.
- **Centroid-based inference routing effectiveness:** Medium - Shows practical benefits but limited direct comparison with classifier-based routing.

## Next Checks
1. Validate the domain centroid assignment mechanism by comparing its domain predictions against the zero-shot classifier on a held-out test set.
2. Reproduce the 3-domain SemiLoRA results on a smaller subset of the corpus to verify the core methodology before scaling up.
3. Implement and test LoRA rank sensitivity (r=8 vs. r=16 vs. r=32) on a single domain to identify the minimum effective rank for this task.