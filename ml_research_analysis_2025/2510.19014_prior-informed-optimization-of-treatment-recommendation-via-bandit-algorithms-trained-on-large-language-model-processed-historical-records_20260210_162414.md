---
ver: rpa2
title: Prior-informed optimization of treatment recommendation via bandit algorithms
  trained on large language model-processed historical records
arxiv_id: '2510.19014'
source_url: https://arxiv.org/abs/2510.19014
tags:
- data
- treatment
- clinical
- patient
- bandit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study integrates Large Language Models (LLMs), Conditional
  Tabular Generative Adversarial Networks (CTGAN), T-learner counterfactual models,
  and contextual bandit approaches to provide customized clinical recommendations.
  The system processes unstructured medical narratives into structured data (93.2%
  accuracy via LLM extraction), generates realistic synthetic patient data (55% accuracy
  via two-sample verification), and employs T-learners to forecast patient-specific
  treatment responses (84.3% accuracy).
---

# Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records

## Quick Facts
- **arXiv ID:** 2510.19014
- **Source URL:** https://arxiv.org/abs/2510.19014
- **Reference count:** 7
- **Primary result:** LLM+CTGAN+T-learner+KernelUCB framework achieves 0.60-0.61 average reward scores in 5,000-round simulations for stage III colon cancer treatment recommendation

## Executive Summary
This study presents an integrated framework combining Large Language Models (LLMs), Conditional Tabular Generative Adversarial Networks (CTGAN), T-learner counterfactual models, and contextual bandit approaches to provide customized clinical recommendations. The system processes unstructured medical narratives into structured data (93.2% accuracy via LLM extraction), generates realistic synthetic patient data (55% accuracy via two-sample verification), and employs T-learners to forecast patient-specific treatment responses (84.3% accuracy). Testing on stage III colon cancer datasets showed that the KernelUCB approach achieved 0.60-0.61 average reward scores across 5,000 rounds, outperforming other reference methods. This framework overcomes cold-start limitations in online learning environments and improves computational effectiveness, advancing toward individualized medicine adapted to specific patient characteristics.

## Method Summary
The method integrates four components: (1) LLM-based few-shot extraction converts unstructured clinical narratives to structured features (93.2% accuracy using DeepSeek-R1 8B with temperature 0.2), (2) CTGAN generates synthetic patient data preserving joint distributions (validated via two-sample test AUC 0.55), (3) T-learner counterfactual models predict outcomes for each treatment arm using XGBoost with IPTW weighting (84.3% accuracy), and (4) KernelUCB contextual bandit initialized with T-learner priors selects treatments, achieving 0.60-0.61 average reward over 5,000 rounds. The framework addresses cold-start by using synthetic data and prior counterfactual estimates to bootstrap exploration.

## Key Results
- LLM extraction achieves 93.2% accuracy converting unstructured clinical narratives to structured features using few-shot prompting
- T-learner counterfactual models forecast patient-specific treatment responses with 84.3% accuracy using XGBoost with IPTW weighting
- KernelUCB contextual bandit with prior-informed initialization achieves 0.60-0.61 average reward scores across 5,000 simulation rounds
- Two-sample test confirms CTGAN synthetic data validity with AUC 0.55, near-random classification indicating realistic generation

## Why This Works (Mechanism)

### Mechanism 1: Few-Shot LLM Extraction Converts Unstructured Notes to Structured Features
Open-source LLMs with few-shot prompting can extract structured clinical variables from narrative notes without domain-specific fine-tuning, achieving 93.2% accuracy. The LLM receives 3-5 exemplar pairs and learns extraction patterns in-context using temperature=0.2 with greedy decoding to ensure reproducibility.

### Mechanism 2: CTGAN Synthetic Data Addresses Cold-Start via Distribution Matching
CTGAN-generated synthetic patients enable bandit warm-start by preserving joint distributions of clinical features, validated via two-sample test (AUC=0.55, near-random). Generator and discriminator train adversarially using Wasserstein loss with gradient penalty, with variational Gaussian mixture models handling multimodal continuous variables.

### Mechanism 3: Prior-Informed Bandits Bootstrap Exploration via Counterfactual Estimates
Initializing bandit algorithms with T-learner counterfactual predictions as priors reduces early exploration regret and accelerates convergence to optimal treatment policies. Separate XGBoost models per treatment arm using IPTW-weighted loss correct selection bias, providing prior reward estimates that narrow initial confidence bounds.

## Foundational Learning

- **Concept: Exploration-Exploitation Trade-off in Contextual Bandits**
  - Why needed: Bandit must balance trying new treatments vs. using current best estimates to maximize patient outcomes
  - Quick check: Given a patient context, why might a bandit choose a treatment with lower estimated reward?

- **Concept: Counterfactual Inference and Selection Bias**
  - Why needed: T-learners estimate outcomes under treatments patients didn't receive, requiring correction for confounding in observational data
  - Quick check: Why can't we simply compare outcomes between patients who received Treatment A vs. Treatment B to determine which is better?

- **Concept: Generative Adversarial Networks for Tabular Data**
  - Why needed: CTGAN differs from image GANs by handling mixed categorical/continuous variables, multimodal distributions, and imbalanced categories
  - Quick check: Why might a GAN trained on clinical data fail to generate realistic rare disease cases?

## Architecture Onboarding

- **Component map:** [Raw Clinical Notes] → [LLM Few-Shot Extraction] → [Structured Tabular Data] → [CTGAN Synthetic Augmentation] → [Combined Real + Synthetic Dataset] → [T-Learner Counterfactual Models (XGBoost per arm)] → [Treatment Outcome Simulator] → [New Patient Context] → [Prior-Informed Contextual Bandit] → [Treatment Recommendation]

- **Critical path:** LLM extraction quality → synthetic data fidelity → counterfactual accuracy → bandit prior quality → online reward. Errors propagate forward; validation at each stage is essential.

- **Design tradeoffs:**
  - LinUCB (0.36 reward) vs. KernelUCB (0.61 reward) vs. NeuralBandit (0.57 reward): Choose based on data size and non-linearity
  - Real vs. Synthetic data ratio: More synthetic helps cold-start but risks distribution shift
  - Exploration parameter α/β: Higher values (α=0.5) converged faster in this domain

- **Failure signatures:**
  - Extraction failures: Empty/missing fields in structured output, hallucinated values
  - Synthetic data collapse: All generated patients resemble majority subgroup
  - Counterfactual bias: T-learner accuracy varies significantly across treatment arms
  - Bandit cold-start persistence: Reward curve flat for >100 rounds

- **First 3 experiments:**
  1. Validate extraction pipeline: Run LLM on held-out notes with manual ground truth, compute per-field accuracy
  2. Synthetic data sanity check: Train classifier on real data only, evaluate on synthetic data; if performance drops >10%, synthetic distribution differs on task-relevant features
  3. Ablate prior initialization: Compare bandit performance with vs. without prior-informed warm-start, measure cumulative regret difference in first 200 rounds

## Open Questions the Paper Calls Out

- How do prior-informed bandit algorithms perform in prospective clinical settings compared to in-silico simulations? (Requires prospective clinical trial measuring real patient outcomes and safety metrics)
- Does integration of multi-dimensional reward structures (adverse events, cost, quality of life) alter optimal treatment policies? (Requires comparative study analyzing policy convergence with vector-based rewards)
- How can uncertainty from LLM-based feature extraction be mathematically propagated to initialize confidence bounds of contextual bandit algorithms? (Requires modified architecture where LLM confidence scores modulate initial variance parameters)

## Limitations

- The proprietary dataset and unspecified few-shot examples create a gap between theoretical claims and practical implementation
- The T-learner's counterfactual accuracy (84.3%) is reported without confidence intervals or analysis of treatment-specific performance
- The clinical significance and generalizability of the 0.60-0.61 average reward scores are difficult to assess without understanding the reward scale or comparison to standard care

## Confidence

- **High confidence:** Technical integration of LLMs, CTGAN, T-learners, and contextual bandits is methodologically sound
- **Medium confidence:** Reported accuracies (93.2% extraction, 84.3% counterfactual prediction) are plausible but unverified without access to data and prompts
- **Low confidence:** Clinical significance and generalizability of 0.60-0.61 average reward scores are difficult to assess

## Next Checks

1. Apply few-shot LLM extraction to held-out clinical notes with manual ground truth to measure per-field accuracy and identify systematic failure modes
2. Train predictive model on real data only, evaluate on synthetic data; if performance drops >10%, synthetic data may not preserve treatment-relevant distributions
3. Compare bandit performance with and without T-learner prior initialization, measuring cumulative regret difference in first 200 rounds to quantify cold-start benefit