---
ver: rpa2
title: Mechanistic Interpretability of RNNs emulating Hidden Markov Models
arxiv_id: '2510.25674'
source_url: https://arxiv.org/abs/2510.25674
tags:
- dynamics
- rnns
- latent
- transitions
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses how RNNs can generate discrete, stochastic
  transitions between latent states through continuous dynamics. A training pipeline
  was developed to fit RNNs to Hidden Markov Models (HMMs), using Sinkhorn divergence
  to handle probabilistic outputs.
---

# Mechanistic Interpretability of RNNs emulating Hidden Markov Models

## Quick Facts
- **arXiv ID**: 2510.25674
- **Source URL**: https://arxiv.org/abs/2510.25674
- **Reference count**: 40
- **One-line primary result**: RNNs trained to emulate HMMs develop structured connectivity implementing self-induced stochastic resonance, with noise-integrating populations and kick neurons generating discrete-like transitions via orbital dynamics.

## Executive Summary
This study investigates how recurrent neural networks (RNNs) can generate discrete, stochastic transitions between latent states through continuous dynamics. By training RNNs to emulate Hidden Markov Models (HMMs) using a Sinkhorn divergence loss, the authors discover a surprising solution: in the absence of input, RNN activity collapses to a single fixed point, but under stochastic input, trajectories form closed orbits with slow regions (clusters) corresponding to distinct output probabilities. Mechanistic analysis reveals a structured connectivity motif—mutually excitatory loops with cross-inhibition between "noise-integrating populations" and "kick neurons"—that implements transitions via self-induced stochastic resonance (SISR). This dynamical motif generalizes across multiple HMM architectures, suggesting a compositional principle for RNNs to emulate complex discrete latent structures.

## Method Summary
The study trains vanilla RNNs to emulate HMMs by minimizing Sinkhorn divergence between predicted and target sequence distributions. RNNs receive i.i.d. Gaussian noise inputs and use Gumbel-Softmax for differentiable categorical sampling. Training continues until a characteristic "double descent" in the loss curve emerges (~500-1000 epochs). The resulting RNNs exhibit orbital dynamics where the orbit radius scales linearly with input variance. Mechanistic analysis identifies structured connectivity between noise-integrating populations and kick neurons that implement transitions. The framework is tested on linear-chain, fully-connected, and cyclic HMMs with 2-3 states.

## Key Results
- Trained RNNs develop noise-sustained orbital dynamics under stochastic input, with orbit radius scaling linearly with noise variance
- Structured connectivity emerges featuring "noise-integrating populations" and "kick neurons" that implement transitions via self-induced stochastic resonance
- The same dynamical motif generalizes across multiple HMM architectures (linear-chain, fully-connected, cyclic)
- PCA analysis reveals slow regions along orbits corresponding to distinct emission probabilities, separated by fast transitions

## Why This Works (Mechanism)

### Mechanism 1: Self-Induced Stochastic Resonance (SISR)
RNNs harness internal noise as a computational signal to generate quasi-periodic transitions between discrete-like states without external periodic forcing. Two complementary sub-circuits interact: slow "noise-integrating populations" (~70 neurons each) accumulate stochastic input over time while in cluster zones, and fast-responding "kick neurons" (small triplets) fire sharply when accumulated noise crosses a threshold, initiating deterministic transitions to the next cluster. The oscillation period is governed by the interplay between noise variance and slow integration dynamics. This mechanism operates in a regime with time-scale separation between slow and fast subsystems. Evidence shows the network shifts into a regime of stochastic resonance during training, and ablation of kick-neurons or their noise input eliminates transitions, reverting to fixed-point behavior.

### Mechanism 2: Noise-Sustained Orbital Dynamics
Continuous RNN state spaces implement discrete HMM-like behavior through orbital dynamics where stochastic input sustains rotation along closed trajectories. Without input, the RNN has a single fixed point. Gaussian input pushes activity outward while recurrent dynamics pull inward, creating a stable limit cycle. The orbit radius scales linearly with input variance. Along orbits, slow regions ("clusters") correspond to distinct emission probabilities, separated by fast deterministic transitions. The output readout axes align with the orbital plane to encode emission probabilities. Second-order perturbation terms dominate dynamics under unbiased Gaussian input, creating the orbit-sustaining force. Perturbative analysis confirms the linear relationship between orbit radius and noise variance.

### Mechanism 3: Kick Circuit Connectivity
A specific recurrent connectivity motif—mutually excitatory loops with cross-inhibition—enables noise-driven, direction-selective state transitions. Two noise-integrating populations form self-exciting, mutually inhibiting loops. Each population projects excitatorily to one "kick-neuron" triplet and inhibitorily to the opposing triplet. Kick neurons have pre-activations that are strongly negative in clusters (ReLU outputs zero), near-zero in kick-zones (threshold-sensitive), and positive during transitions. This gates when noise can trigger a transition. The ReLU threshold nonlinearity at near-zero pre-activations is essential for noise-sensitivity in kick-zones. Causal interventions show that silencing kick-neurons or ablating noise-drive from integrating populations traps trajectories in clusters.

## Foundational Learning

- **Concept: Hidden Markov Models (HMMs)**
  - **Why needed here:** HMMs define the target behavior—discrete latent states with stochastic transition probabilities and emission distributions. Understanding the gap between discrete HMM structure and continuous RNN dynamics is central.
  - **Quick check question:** Can you explain why an HMM with 3 latent states and transition matrix T produces different emission statistics than a deterministic 3-state automaton?

- **Concept: Fixed Points and Stability in Dynamical Systems**
  - **Why needed here:** The paper's core finding is that trained RNNs have a single fixed point without input but exhibit orbital dynamics under noise. Understanding linear stability analysis (eigenvalues, Jacobians) is essential for interpreting the mechanism.
  - **Quick check question:** For a discrete-time system, what condition on eigenvalues determines whether a fixed point is stable?

- **Concept: Sinkhorn Divergence / Optimal Transport**
  - **Why needed here:** The training pipeline uses Sinkhorn divergence (not MSE or cross-entropy) to compare probabilistic output sequences, enabling gradient-based learning of stochastic behaviors.
  - **Quick check question:** Why would standard cross-entropy loss be problematic when training an RNN to match the distribution of sequences from an HMM, rather than matching specific token sequences?

## Architecture Onboarding

- **Component map:** Gaussian noise input -> ReLU-RNN core -> linear readout -> Gumbel-Softmax sampling -> Sinkhorn loss
- **Critical path:** Initialize RNN -> sample sequences from target HMM -> feed Gaussian noise -> collect output trajectories -> compute Sinkhorn divergence -> train until double-descent pattern emerges -> verify orbital dynamics via PCA
- **Design tradeoffs:** Higher input dimensionality (d ≥ 100) improves convergence but increases compute; hidden size > 150 gives marginal benefits; gradient clipping (0.3–0.9) required for stability; Gumbel-Softmax temperature fixed at 1
- **Failure signatures:** No orbital dynamics (loss doesn't show second descent, PCA shows only fixed-point convergence); overfitting (training/validation loss diverge); unstable training (exploding gradients despite clipping)
- **First 3 experiments:**
  1. Replicate the 2-state linear-chain HMM training with |h|=150, d=100; visualize latent trajectories via PCA before and after the training transition epoch
  2. Ablate the identified kick-neurons post-training and confirm trajectories get trapped in clusters
  3. Vary input noise variance (σ²) and verify linear scaling of orbit radius as claimed in Figure 3D

## Open Questions the Paper Calls Out

- **Does the identified "dynamical primitive" scale to model naturalistic behaviors characterized by asymmetric transition graphs and high-dimensional emission profiles?**
  - The study is restricted to small, symmetric HMM topologies (linear-chain, cyclic, fully-connected) with only 2-3 emission classes, which may not capture the complexity of unconstrained animal behavior. Successful training and mechanistic analysis of RNNs on datasets like animal motion capture would resolve this.

- **Do biological neural circuits employ distinct "noise-integrating" and "kick-neuron" populations to implement discrete behavioral state transitions via self-induced stochastic resonance?**
  - This work provides a computational hypothesis but does not validate the existence of this specific circuit motif in biological tissue. Electrophysiological recordings identifying functionally coupled inhibitory/excitatory sub-populations in cortex would be needed.

- **Is the orbital dynamical solution dependent on the vanilla RNN architecture and ReLU activation, or does it generalize to gated architectures like LSTMs and GRUs?**
  - The study exclusively analyzes vanilla RNNs; gating units (sigmoid/tanh) might suppress the specific noise-driven instability required for the stochastic resonance mechanism. Training LSTMs or GRUs on the same task would test generalizability.

## Limitations
- Limited mechanistic validation scope: The kick circuit mechanism is demonstrated on a single 2-state linear-chain HMM; generalization to complex cyclic and fully-connected HMMs is asserted but not mechanistically verified
- Absence of ablation studies: Systematic quantification of the necessity and sufficiency of each circuit component for emergent dynamics is lacking
- Reliance on continuous dynamics: The fidelity of the RNN's emulation of the target HMM's transition probabilities and emission distributions is not quantified beyond qualitative trajectory analysis

## Confidence
- **High Confidence**: Trained RNNs develop orbital dynamics (limit cycles) under stochastic input, with orbit radius scaling linearly with noise variance
- **Medium Confidence**: A specific recurrent connectivity motif (kick circuits) is the primary mechanism for generating transitions between discrete-like states (well-supported for 2-state case, requires further validation for complex HMMs)
- **Medium Confidence**: The RNN has a single fixed point without input (supported by activity collapse observation, but stability analysis is not provided)

## Next Checks
1. **Cross-HMM Circuit Analysis**: Perform mechanistic analysis of trained RNNs for cyclic and fully-connected HMMs to identify whether the same kick circuit motif is present and responsible for transitions
2. **Systematic Ablation Study**: Execute ablation experiments on the 2-state HMM RNN, silencing kick neurons, isolating noise-integrating populations, and removing cross-inhibitory connections to establish component necessity
3. **HMM Fidelity Quantification**: Develop metrics to compare transition and emission statistics of trained RNNs directly to target HMMs, such as computing KL divergence between empirical and target transition matrices