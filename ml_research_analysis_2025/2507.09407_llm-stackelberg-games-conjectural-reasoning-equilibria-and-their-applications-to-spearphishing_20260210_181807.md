---
ver: rpa2
title: 'LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications
  to Spearphishing'
arxiv_id: '2507.09407'
source_url: https://arxiv.org/abs/2507.09407
tags:
- reasoning
- follower
- sender
- equilibrium
- leader
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLM-Stackelberg games, a framework that integrates
  large language models into sequential decision-making between a leader and follower.
  Unlike classical Stackelberg models that assume complete information and full rationality,
  this approach uses structured prompts to capture bounded rationality, epistemic
  uncertainty, and meta-cognitive adaptation.
---

# LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing

## Quick Facts
- arXiv ID: 2507.09407
- Source URL: https://arxiv.org/abs/2507.09407
- Reference count: 14
- Primary result: Introduces LLM-Stackelberg games with reasoning and conjectural reasoning equilibria; demonstrates 25.4% spearphishing success rate in case study.

## Executive Summary
This paper introduces LLM-Stackelberg games, a framework that integrates large language models into sequential decision-making between a leader and follower. Unlike classical Stackelberg models that assume complete information and full rationality, this approach uses structured prompts to capture bounded rationality, epistemic uncertainty, and meta-cognitive adaptation. Two equilibrium concepts are defined: reasoning and behavioral equilibrium, which align internal prompt-based reasoning with observable behavior, and conjectural reasoning equilibrium, which accounts for epistemic uncertainty through parameterized models of an opponent's response. The framework is illustrated through a spearphishing case study, where an LLM attacker generates messages targeting an LLM recipient using structured reasoning prompts. Results show that under equilibrium, the attacker achieves a 25.4% expected success rate per message against a skeptical receiver, demonstrating the framework's ability to model strategic deception and cognitive adaptation in adversarial settings.

## Method Summary
The method implements LLM-Stackelberg games where a sender agent selects a reasoning prompt to generate messages, and a receiver agent selects a prompt to evaluate them. The sender forms a conjectural model of the receiver's response distribution and updates this model via KL divergence minimization to achieve conjectural consistency. The framework defines reasoning equilibrium (optimal prompt selection) and behavioral equilibrium (resulting observable actions), with conjectural reasoning equilibrium adding belief update dynamics. Implementation requires defining prompt vocabularies with controlled slots (tone, authority, action, trigger), implementing LLM policies with temperature-controlled sampling, optimizing prompts under conjectured models, and iterating until equilibrium conditions are satisfied.

## Key Results
- Framework successfully models sequential decision-making between LLM agents using structured reasoning prompts
- Achieves 25.4% expected spearphishing success rate under equilibrium against skeptical receiver
- Demonstrates conjectural consistency through KL minimization between sender's beliefs and observed receiver behavior
- Provides formal definitions for reasoning, behavioral, and conjectural reasoning equilibria in LLM-Stackelberg games

## Why This Works (Mechanism)

### Mechanism 1: Prompt-as-Cognitive-Substrate
Structured reasoning prompts function as cognitive substrates that encode agent beliefs, heuristics, and processing styles, inducing probabilistic behaviors via LLM sampling. Each agent selects a reasoning prompt from a controlled vocabulary, constraining LLM generation to transform abstract assumptions about bounded rationality into concrete, configurable prompt procedures. The core assumption is that the LLM's internal distribution plus prompt structure reliably captures intended cognitive traits.

### Mechanism 2: Two-Layer Equilibrium Coupling
Equilibrium emerges from coupling a reasoning-level equilibrium (prompt selection) with a behavioral-level equilibrium (observable actions), ensuring internal cognition aligns with external behavior. Sender selects optimal prompt given anticipated receiver response, receiver selects optimal prompt given message, and the pair induces behavioral strategies. Consistency requires that prompts generating these behaviors are themselves optimal.

### Mechanism 3: Conjectural Modeling with KL-Minimization
Under epistemic uncertainty, the sender forms a parameterized conjecture of the receiver's response model and refines it by minimizing KL divergence to observed behavior. Sender posits conjecture class with parameters, generates messages, observes responses, and updates parameters via argmin_ξ E_m[KL(˜μξ(·|m) ∥ σ*D(·|m))], ensuring conjectural consistency.

## Foundational Learning

- **Classical Stackelberg Games**: Why needed - framework extends classical leader-follower sequential games; prerequisite understanding of rational response sets and mixed Stackelberg equilibrium. Quick check - Can you define the rational response set R_D(m, I_D) and explain why the leader optimizes against the worst-case response?

- **Epistemic vs. Aleatoric Uncertainty**: Why needed - paper explicitly distinguishes epistemic uncertainty (model/parameter uncertainty about opponent) from aleatoric uncertainty (stochastic outcomes); conjectural equilibria address the former. Quick check - In the spearphishing case, is the receiver's click probability epistemic or aleatoric uncertainty from the sender's perspective?

- **Prompt Engineering for LLMs**: Why needed - prompts are the control interface for agent cognition; understanding how prompt structure constrains generation is essential. Quick check - Given the prompt vocabulary X = {[Tone], [Authority], [Action], [Trigger]}, how would you construct a prompt targeting a risk-averse recipient?

## Architecture Onboarding

- Component map:
  Sender Agent: IA (private info) → νA (prompt policy) → x (reasoning prompt) → LLM_A → m (message) → [transmit]
  Receiver Agent: m (received) + ID (private info) → νD (prompt policy) → y (reasoning prompt) → LLM_D → d (action: click/ignore)
  Conjecture Module (Sender-side): Ξ (parameter space) → ˜μξ (conjectured response model) → [KL update loop with observed d]

- Critical path:
  1. Define prompt vocabularies X, Y with controlled slots (tone, authority, trigger)
  2. Implement LLM policies γA, γD with temperature-controlled sampling
  3. For sender: optimize x ∈ X using conjectured model ˜μξ
  4. For receiver: optimize y ∈ Y given message and utility uD
  5. Update conjecture ξ via KL minimization against observed/simulated responses
  6. Iterate until (x*, y*, ξ*) satisfy equilibrium conditions

- Design tradeoffs:
  - Prompt vocabulary granularity: Finer slots capture more cognitive nuance but increase optimization complexity
  - Conjecture class richness: Larger Ξ improves approximation but requires more data for KL estimation
  - LLM temperature: Higher temperature increases exploration but introduces behavioral variance

- Failure signatures:
  - Conjecture-reality gap: ˜μξ predictions consistently mismatch observed σ*D (visible in calibration plots)
  - Prompt optimization instability: x* varies significantly across runs for identical IA
  - Equilibrium non-convergence: No fixed point after N iterations; behavior oscillates

- First 3 experiments:
  1. Baseline calibration: Fix receiver prompt y (e.g., skeptical evaluation), measure sender's conjectured vs. actual click rates across diverse messages; quantify KL divergence
  2. Prompt space sweep: Systematically vary [Tone], [Authority], [Trigger] slots; plot sender utility surface to identify equilibrium candidates
  3. Conjecture update loop: Initialize ξ randomly, run 100 simulated interactions, update ξ via KL minimization; measure convergence rate and final equilibrium utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions do LLM-Stackelberg reasoning and conjectural reasoning equilibria exist, and can efficient algorithms compute them?
- Basis in paper: [inferred] The paper defines equilibrium concepts formally but provides no existence theorems, uniqueness guarantees, or computational methods beyond the illustrative case study.
- Why unresolved: The equilibrium conditions involve nested optimization over continuous prompt spaces and KL divergence minimization, making analytical characterization difficult; the paper only demonstrates equilibrium existence empirically through one scenario.
- What evidence would resolve it: Theorems establishing sufficient conditions for existence/uniqueness; convergence analysis for iterative belief-updating algorithms; computational complexity bounds for finding equilibrium prompts.

### Open Question 2
- Question: How do reasoning prompts and conjectural beliefs evolve in repeated interactions, and does dynamic consistency between belief updates and behavioral optimality emerge?
- Basis in paper: [explicit] The conclusion states: "dynamic extensions of the framework can capture how reasoning prompts and conjectures evolve over time, leading to dynamic consistency between belief formation and behavioral optimality."
- Why unresolved: The current formulation models single-shot interactions; the framework does not specify update rules for prompts x_t, conjecture parameters ξ_t, or how agents integrate observed outcomes into subsequent reasoning.
- What evidence would resolve it: Formal dynamic game extension with explicit update dynamics; empirical demonstration of convergence or limit cycles in multi-round LLM-Stackelberg games; characterization of steady-state learning behavior.

### Open Question 3
- Question: How robust are equilibrium outcomes to misspecification of the conjecture hypothesis class Ξ when the follower's true response lies outside the parameterized family?
- Basis in paper: [inferred] The conjectural consistency condition minimizes KL divergence within Ξ, but assumes the true response σ*_D can be approximated within this class; no analysis addresses model misspecification error.
- Why unresolved: The paper does not bound approximation error when Ξ is too restrictive, nor analyze how equilibrium strategies degrade under systematic conjecture errors.
- What evidence would resolve it: Sensitivity analysis showing how equilibrium utilities change as true responses deviate from the hypothesis class; theoretical bounds on regret from misspecified conjectures.

### Open Question 4
- Question: How does the framework extend to multi-agent settings beyond two-player leader-follower interactions, and what equilibrium concepts govern such games?
- Basis in paper: [inferred] The paper mentions the formulation "naturally generalizes to multi-agent cognition" but provides no formal extension; real-world misinformation and recommendation systems involve multiple strategic agents with potentially misaligned objectives.
- Why unresolved: Multi-agent Stackelberg games introduce additional equilibrium selection problems and higher-order belief reasoning that current definitions do not capture.
- What evidence would resolve it: Formal extension to N-player LLM-Stackelberg games; equilibrium definitions for networked or hierarchical agent structures; empirical validation in multi-sender or multi-receiver phishing scenarios.

## Limitations
- LLM-specific prompt-behavior mapping not empirically validated beyond authors' internal testing
- Equilibrium computation feasibility not demonstrated; optimization over prompt spaces may be computationally challenging
- Spearphishing case study generalization limited to one recipient profile with single 25.4% success rate result

## Confidence

- **High confidence**: The formal game-theoretic framework (definitions of reasoning/behavioral/conjectural equilibria) is mathematically coherent and extends classical Stackelberg games appropriately.
- **Medium confidence**: The conjectural consistency mechanism (KL minimization between ˜μξ and σ*D) is theoretically sound, but practical implementation details are underspecified.
- **Low confidence**: Empirical validation is limited to a single spearphishing scenario with one recipient profile, lacking independent verification across multiple scenarios.

## Next Checks

1. **Prompt-behavior calibration**: Systematically vary sender prompt parameters (tone, authority, trigger) while keeping receiver prompt fixed. Measure and compare sender's predicted vs. actual click rates across multiple runs to quantify the reliability of the prompt-behavior mapping.

2. **Conjecture convergence analysis**: Implement the conjecture update loop with different initializations of ξ. Track KL divergence values across iterations and plot convergence curves. Test whether the algorithm consistently reaches the same equilibrium or exhibits sensitivity to initialization.

3. **Cross-profile generalization**: Replicate the spearphishing equilibrium computation for three distinct recipient profiles (e.g., risk-averse academic, deadline-sensitive executive, compliance-trained professional). Compare equilibrium utilities and conjectured response models to assess framework robustness across recipient types.