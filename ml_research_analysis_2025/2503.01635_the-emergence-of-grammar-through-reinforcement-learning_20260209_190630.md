---
ver: rpa2
title: The Emergence of Grammar through Reinforcement Learning
arxiv_id: '2503.01635'
source_url: https://arxiv.org/abs/2503.01635
tags:
- message
- language
- learning
- form
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel application of reinforcement learning
  theory to model the emergence of grammatical systems through language evolution.
  The authors demonstrate that speakers' message preferences, encoded as probability
  distributions over messages in a given context, interact with a reinforcement learning
  rule (Harley-Roth-Erev formula) to drive the emergence of syntax and semantic composition.
---

# The Emergence of Grammar through Reinforcement Learning

## Quick Facts
- arXiv ID: 2503.01635
- Source URL: https://arxiv.org/abs/2503.01635
- Reference count: 40
- One-line primary result: Reinforcement learning drives the emergence of grammatical systems by converging languages to express the most probable messages

## Executive Summary
This paper presents a novel framework for understanding how grammatical systems emerge through language evolution using reinforcement learning theory. The authors demonstrate that speakers' preferences for expressing certain messages, encoded as probability distributions, interact with the Harley-Roth-Erev (HRE) reinforcement learning formula to drive the emergence of syntax, semantic composition, and grammatical markers. Through analytical proofs and numerical simulations, they show that languages naturally evolve to efficiently express the most probable messages, and they extend the model to account for multiple dependents, collective lexicons, recursion, word order, and the emergence of obligatory grammatical markers. The model is supported by case studies from the history of English.

## Method Summary
The authors model language emergence as a reinforcement learning process where speakers have stable probability distributions over messages they wish to express in context. The HRE formula p(i|c) = ci/(c1+...+cI+α) governs production decisions, with counts updated based on utterance success. They prove convergence theorems showing languages evolve to express the most probable messages, and extend the model with forgetting factors, similarity-weighted learning for verbs, and form competition for grammatical markers. Both analytical proofs and numerical simulations (10,000+ runs) investigate convergence speed and behavior under various conditions.

## Key Results
- Languages converge to express the most probable messages, creating stable semantic composition rules
- Optional grammatical markers become obligatory when they mark less frequent (more informative) meanings
- Atypical verbs assimilate to typical argument structures via similarity-weighted learning
- Two case studies from English history support predictions about the emergence of reflexive pronouns and progressive aspect marking

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Languages converge to express the most probable messages, creating stable semantic composition rules.
- **Mechanism:** The HRE formula creates positive feedback: higher-probability messages generate more utterance opportunities, incrementing their counts faster. As counts diverge, probability ratios amplify until one message dominates.
- **Core assumption:** Speakers have stable message probability distributions over what to express in context.
- **Evidence anchors:** Fundamental Theorem proves ci/c1→0 for i≠1 when p(m1|s)>p(mi|s); abstract states speakers' preferences drive syntax emergence.
- **Break condition:** If message probabilities are exactly equal and no forgetting is applied, convergence fails.

### Mechanism 2
- **Claim:** Optional grammatical markers become obligatory when they mark less frequent (more informative) meanings.
- **Mechanism:** Learners track form-meaning co-occurrence. If the unmarked form's dominant meaning is more frequent (p>0.5), the marked form becomes obligatory for the minority meaning via convergence dynamics.
- **Core assumption:** Learners track form-meaning associations independently of message frequencies.
- **Evidence anchors:** Theorem 4 shows categoricalization when p>0.5; Theorem 5 shows stable variation when p<0.5; case studies show p>0.5 for English reflexives and progressive.
- **Break condition:** If the marked meaning is more frequent (p<0.5), categoricalization fails; stable variation persists.

### Mechanism 3
- **Claim:** Atypical verbs assimilate to typical verbs' argument structures via similarity-weighted learning.
- **Mechanism:** Learning for a new verb incorporates counts from semantically similar verbs, weighted by similarity coefficient γ. Decaying similarity ensures convergence.
- **Core assumption:** Learners can judge semantic role similarity across verbs.
- **Evidence anchors:** Simulations show atypical verbs assimilate when γ≥0.03 with forgetting; decaying similarity ensures convergence even with very low similarity.
- **Break condition:** Without decaying similarity, very low γ values cause perpetual indecision.

## Foundational Learning

- **Concept:** Markov processes and stochastic approximation
  - **Why needed here:** Language histories are modeled as Markov processes; convergence proofs rely on stochastic approximation theory.
  - **Quick check question:** Can you explain why ci/c1→0 almost surely implies probability convergence?

- **Concept:** Bayes' rule for interpretation
  - **Why needed here:** Hearer interpretation of utterances uses Bayesian inference to invert the production model.
  - **Quick check question:** Given p(u|m) from HRE and p(m), how do you compute p(m|u)?

- **Concept:** Reinforcement learning basics (Law of Effect, cumulative payoffs)
  - **Why needed here:** The entire framework builds on the HRE formula from behavioral psychology.
  - **Quick check question:** Why does adding α to the denominator slow initial learning?

## Architecture Onboarding

- **Component map:** Message Probabilities (p(m|s)) → Production Decision (HRE formula) → Utterance → State of Learning (counts c_i) ← Update Step (+1 on success) → [Optional] Forgetting (ν) → Down-weight past counts → [Optional] Similarity (γ) → Cross-verb count sharing

- **Critical path:** 1) Initialize counts c0_i > 0 and α ≥ 0. 2) Sample message from p(m|s). 3) Compute utterance probability via HRE. 4) Produce utterance stochastically. 5) Update counts. 6) Repeat until convergence (|p(u*|mi) - 1| < ε).

- **Design tradeoffs:**
  - **α (initial resistance):** High α delays convergence but doesn't prevent it. Use α≈0 for fast emergence, α≫c0 for realistic slow emergence.
  - **ν (forgetting):** ν≈0.99-0.999 speeds convergence and handles equal probabilities, but introduces stochasticity. ν=1 (no forgetting) is deterministic but slow.
  - **γ (similarity):** High γ speeds verb acquisition but risks over-generalization. Low γ requires decaying similarity to converge.

- **Failure signatures:**
  - Counts remain bounded (ci↛∞): Check p(mi|s)>0 and initial c0_i>0.
  - No convergence with equal message probabilities: Add forgetting factor ν<1.
  - Perpetual indecision with low similarity: Add decaying similarity factor.
  - Wrong form wins in competition: Check p(unmarked meaning) > 0.5; if not, variation is correct behavior.

- **First 3 experiments:**
  1. Replicate Fundamental Model convergence: Set p(m1)=0.6, p(m2)=0.3, p(m3)=0.1; verify 10,000 runs all converge to m1 within 10^6 steps. Plot histograms like Figure 3.
  2. Test forgetting with equal probabilities: Set p(m1)=p(m2)=0.5, ν=0.99; verify ~50% converge to each. Test ν=0.999 vs ν=0.99 to measure speed difference.
  3. Validate Form Competition Model: Implement the "cat-ACC" model with p(SUBJ)=0.6; verify accusative becomes obligatory. Re-run with p(SUBJ)=0.4; verify stable variation at predicted rate (1-2p)/(1-p)=1/3.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Fundamental Model's predictions about syntax emergence be empirically tested against historical corpus data from languages undergoing grammaticalization?
- **Basis in paper:** "The Fundamental Model accounts for the emergence of syntax itself, and so it is difficult to find good data to test the model, although this could be an area of future research." (Section 5.7)
- **Why unresolved:** Early stages of syntax emergence predate written records, making direct empirical validation challenging.
- **What evidence would resolve it:** Corpus analysis of languages with recently emergent syntactic constructions, or controlled laboratory experiments simulating language emergence with human participants.

### Open Question 2
- **Question:** How do network effects such as speaker population structure, language contact, and dialect formation influence the convergence properties of the reinforcement learning models?
- **Basis in paper:** "All members of the speech community witness every utterance, hence we ignore network effects such as diffusion, language contact and dialect formation." (Section 3.1)
- **Why unresolved:** Current models assume a fully connected homogeneous population, which is an idealization not true of actual speech communities.
- **What evidence would resolve it:** Agent-based simulations incorporating realistic social network structures, compared against documented patterns of linguistic change in geographically or socially structured populations.

### Open Question 3
- **Question:** Under what precise conditions does the Model with Similarity fail to converge, and can convergence be guaranteed without requiring decaying similarity?
- **Basis in paper:** The paper introduces decaying similarity to solve convergence problems but notes "we were unable to demonstrate convergence within a reasonable time under all conditions" (Section 4.2.3) before proposing this fix.
- **Why unresolved:** The mathematical characterization of the convergence failure region and whether decaying similarity is necessary or merely sufficient remains unclear.
- **What evidence would resolve it:** Analytical proof identifying the exact parameter ranges where convergence fails, or demonstration that alternative mechanisms achieve the same result.

## Limitations
- The theoretical framework is well-defined but several implementation details remain underspecified, particularly regarding exact parameters used in numerical simulations.
- Model predictions are mathematically proven under idealized conditions, but real-world validation is limited to two historical case studies without direct evidence for the reinforcement learning mechanism itself.
- The assumption of stable message probability distributions and independent learning of form-meaning associations may not fully capture the complexity of actual language acquisition and use.

## Confidence
- **High confidence:** The mathematical convergence proofs and basic model behavior (Fundamental Model, Form Competition Model with p>0.5)
- **Medium confidence:** The extension to multiple dependents and collective lexicon models, as these build directly on proven foundations
- **Low confidence:** The atypical verb assimilation mechanism and the general applicability to all grammatical phenomena, given limited empirical validation

## Next Checks
1. **Empirical validation of convergence predictions:** Test the model's predictions against diachronic corpora beyond the two case studies presented, examining whether grammaticalization patterns match the predicted outcomes based on message frequency distributions.

2. **Simulation parameter sensitivity analysis:** Systematically vary forgetting factor ν, similarity coefficient γ, and initial conditions to map the full space of convergence behaviors and identify parameter regimes where the model breaks down.

3. **Cross-linguistic generalization test:** Apply the form competition model to languages with known optional case marking systems where the frequency of marked vs unmarked meanings can be estimated, predicting whether categoricalization should occur.