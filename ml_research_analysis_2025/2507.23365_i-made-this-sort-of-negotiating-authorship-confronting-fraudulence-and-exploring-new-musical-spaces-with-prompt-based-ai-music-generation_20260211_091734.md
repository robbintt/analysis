---
ver: rpa2
title: '"I made this (sort of)": Negotiating authorship, confronting fraudulence,
  and exploring new musical spaces with prompt-based AI music generation'
arxiv_id: '2507.23365'
source_url: https://arxiv.org/abs/2507.23365
tags:
- music
- have
- platforms
- https
- last
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the role of authorship in prompt-based AI music
  generation through two experimental albums that interrogate AI's creative capacities.
  Using Suno and Udio, the author created "Music from the Spam Folder" (remixing spam
  text) and "A Difficult Christmas" (targeting AI's inability to produce "unpolished"
  music).
---

# "I made this (sort of)": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation

## Quick Facts
- arXiv ID: 2507.23365
- Source URL: https://arxiv.org/abs/2507.23365
- Authors: Bob L. T. Sturm
- Reference count: 7
- Primary result: AI music generation platforms show strong text-setting capabilities but struggle to produce "unpolished" performances due to training data bias

## Executive Summary
This paper explores authorship and creative identity through two experimental albums created using prompt-based AI music generation platforms (Suno and Udio). The author investigates AI's creative capacities by attempting to generate music from spam emails and deliberately "unpolished" performances, while using a large language model to interview himself about the process. The work reveals AI's strength in semantic text-setting but its fundamental limitation in generating amateur or imperfect performances, while also examining the psychological experience of feeling fraudulent when creating with AI tools.

## Method Summary
The author created two albums: "Music from the Spam Folder" (remixing spam text) and "A Difficult Christmas" (targeting AI's inability to produce "unpolished" music). Using Suno and Udio, the author generated audio from text prompts, curated the outputs, and remixed them in a digital audio workstation. To explore authorship and identity, ChatGPT 4o was seeded with liner notes and manuscripts to interview the author iteratively, with the author responding and the cycle continuing.

## Key Results
- AI platforms demonstrate sophisticated cross-modal conditioning, effectively translating text semantics into musical structures
- Current models cannot generate "unpolished" or "novice" performances due to polish bias from training on professional music
- LLM-mediated self-reflection functions as external scaffolding for articulating tacit thoughts about creative identity
- The author's identity evolved through sampling, remixing, and visual integration, reinserting human agency into AI-generated work

## Why This Works (Mechanism)

### Mechanism 1: Semantic Text-Setting via Cross-Modal Conditioning
Prompt-based music generation platforms translate input text into coherent musical structures through cross-modal attention mechanisms or joint embedding spaces where textual semantics and phonetics condition audio generation. The model learns robust mapping between linguistic rhythm/meaning and musical phrasing during training.

### Mechanism 2: The "Polish" Bias of Training Distributions
State-of-the-art models struggle with "unpolished" performances because they minimize loss functions that reward high-fidelity, in-tune, rhythmically tight performancesâ€”characteristics prevalent in their training data. "Imperfection" is treated as noise to be minimized rather than a valid feature class.

### Mechanism 3: LLM-Mediated Elicitation of Tacit Knowledge
Using an LLM seeded with project context to interview an author functions as "digital therapy," aiding articulation of tacit thoughts. The LLM acts as a high-quality paraphrasing engine, synthesizing scattered inputs into coherent inquiry lines.

## Foundational Learning

- **Concept: Latent Space Navigation**
  - Why needed here: To understand the author's description of "search and discovery" in AI music
  - Quick check question: Does the model store actual audio files, or mathematical representations (vectors) of audio features?

- **Concept: Curatorial vs. Generative Authorship**
  - Why needed here: The paper wrestles with the shift from creating to selecting music
  - Quick check question: In the "curatorial" loop, does the human modify the audio waveform directly, or only the parameters that generate it?

- **Concept: Simulacra and "Pseudoplunderphonics"**
  - Why needed here: The author uses Baudrillard's concept of "simulacra" and "plunderphonics" to define their role
  - Quick check question: How does "pseudoplunderphonics" differ from traditional sampling, given the machine learning pipeline intermediary?

## Architecture Onboarding

- **Component map:** Input Interface (Text + Style Prompts) -> Generative Core (Suno/Udio) -> Post-Processing Layer (DAW) -> Reflective Layer (LLM)
- **Critical path:** Prompt Generation -> Curation -> Remixing is the primary value stream, with Generative Core acting as high-speed simulator
- **Design tradeoffs:**
  - Control vs. Quality: Platforms offer high-quality outputs but limit control over specific articulations
  - Speed vs. Identity: Rapid generation leads to fraudulence; re-inserting identity via visuals/remixing is labor-intensive
- **Failure signatures:**
  - "Polished" Failure: Attempts to generate "bad" or "novice" performances result in clean, professional outputs
  - "Hallucinated" Feature: Model inserts creative elements not present in prompt
- **First 3 experiments:**
  1. Constraint Testing: Attempt to generate specific "unpolished" traits to confirm polish bias boundary
  2. Text-Setting Stress Test: Input abstract/gibberish text to evaluate phonetic vs. semantic mapping
  3. The "Reinsertion" Loop: Transform raw generation (video, heavy sampling) to see modification required for authorship

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the "spam-to-music" creation process reproducible by others, or does the author's curation provide a distinctive fingerprint?
- Basis in paper: The author states, "I do not believe the results would sound much different from most of the tracks on my album, but perhaps this is something that could be tested."
- Why unresolved: The author's role as mix of "editor" and "author" remains untested whether curation constitutes unique artistic signature
- What evidence would resolve it: User study with identical spam prompts, blind listening test to distinguish author's tracks from crowd-sourced results

### Open Question 2
- Question: How can Music Information Retrieval (MIR) systems and datasets be expanded to formally describe "unpolished" or "non-expert" musical performance?
- Basis in paper: The author notes gap in field: "As of yet, I have found no music descriptors... similar to 'non-expert', 'novice', 'unskilled', 'nonvirtuosic', 'nonmusical', 'unpracticed', and 'unpolished'."
- Why unresolved: Current research and datasets biased toward professional music, leaving amateurism unrepresented in AI training and analysis
- What evidence would resolve it: Construction and validation of labeled dataset targeting amateur performance characteristics and retrieval system capable of identifying these features

### Open Question 3
- Question: Does LLM-mediated self-reflection introduce "flattery" biases that inflate perceived importance or coherence of artistic work compared to human-led critique?
- Basis in paper: While author found LLM method "practical and provocative," they noted responses "bordered on flattering, perhaps inflating the importance of my work."
- Why unresolved: Paper relies on this method but lacks empirical validation of objectivity compared to human expert
- What evidence would resolve it: Comparative analysis of interview transcripts generated by LLM versus human expert measuring differences in sentiment, critical depth, and inflation of artistic intent

## Limitations

- Core claims about AI's inability to generate "unpolished" music are phenomenological observations from two specific albums rather than systematic experiments
- LLM-mediated reflection process lacks independent verification of whether similar insights would emerge for other users or contexts
- Paper acknowledges this as artistic exploration rather than controlled study, limiting generalizability

## Confidence

- **High confidence**: Author's personal experience of fraudulence when using AI music generation, and observation that AI excels at text-setting while failing to produce deliberately unpolished performances
- **Medium confidence**: Claim that "polish bias" stems from training on commercially released music (logically sound but inferred about internal model behavior)
- **Low confidence**: Generalizability of LLM-mediated self-reflection as research method (based on single case study with no comparative analysis)

## Next Checks

1. Conduct controlled generation experiments systematically varying prompt descriptors for "novice," "beginner," "unpolished" versus "professional" to quantify polish bias boundary
2. Test text-setting hypothesis with controlled input texts varying in phonetic complexity and semantic content to determine whether model responds more to linguistic rhythm or meaning
3. Replicate LLM interview process with multiple subjects across different creative domains to assess whether therapeutic/cognitive scaffolding effect generalizes beyond single case