---
ver: rpa2
title: 'From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for
  Multivariate Time-Series Multi-class Classification'
arxiv_id: '2510.19514'
source_url: https://arxiv.org/abs/2510.19514
tags:
- sparse
- counterfactual
- class
- clinical
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a prototype-driven framework for generating
  sparse counterfactual explanations tailored to 12-lead ECG classification models.
  The method combines SHAP-based rule extraction, Dynamic Time Warping (DTW), and
  medoid clustering to identify representative prototypes, which are then aligned
  to query R-peaks and optimized for sparsity.
---

# From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification

## Quick Facts
- **arXiv ID:** 2510.19514
- **Source URL:** https://arxiv.org/abs/2510.19514
- **Reference count:** 40
- **Primary result:** Sparse counterfactual explanations for 12-lead ECG classification using prototype alignment and SHAP-driven optimization

## Executive Summary
This paper presents a prototype-driven framework for generating sparse counterfactual explanations tailored to 12-lead ECG classification models. The method combines SHAP-based rule extraction, Dynamic Time Warping (DTW), and medoid clustering to identify representative prototypes, which are then aligned to query R-peaks and optimized for sparsity. This approach modifies only 78% of the original signal while maintaining 81.3% validity across all classes and achieving 43% improvement in temporal stability. Class-specific performance ranges from 98.9% validity for myocardial infarction to 13.2% for hypertrophy, with validation stability consistently high (>0.99). The framework supports near real-time generation (<1 second) of clinically valid counterfactuals and integrates visualizations evaluated by three cardiology experts.

## Method Summary
The framework trains a CNN–GRU–RealNVP model on PTB-XL ECG data, computes SHAP attributions to extract interval rules, clusters single-label samples using DTW-based distances, and selects medoids as prototypes. For queries, it aligns the prototype's R-peaks to the query's R-peaks via piecewise-linear interpolation, then iteratively sparsifies the modification mask to minimize signal changes while ensuring prediction flip. The method achieves high validity and sparsity while preserving temporal stability, validated on five diagnostic classes with expert review.

## Key Results
- Achieves 81.3% overall validity for counterfactual explanations across all classes
- Reduces signal modification to 78% of original through sparsity optimization
- Improves temporal stability by 43% compared to non-aligned approaches
- Class-specific validity ranges from 98.9% (MI) to 13.2% (HYP) due to prototype availability

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Using real patient medoids as prototypes anchors counterfactuals in physiologically plausible data manifolds, reducing the risk of synthetic artifacts.
- **Mechanism:** Instead of generating synthetic signals via gradient descent, the system retrieves the "medoid" (most central instance) from a cluster of real ECGs belonging to the target class. This ensures the baseline counterfactual is a verified, recorded physiological signal.
- **Core assumption:** The training data contains representative samples for all target classes that form coherent morphological clusters.
- **Evidence anchors:**
  - [Section 3.2]: "By selecting medoids (actual training instances) rather than abstract centroids, we ensure that every explanation is anchored in a real, verifiable patient record."
  - [Section 5.4]: Limitations acknowledge that for minority classes like HYP, the small number of single-label samples (23) severely degrades performance, validating that the mechanism relies on prototype availability.
  - [Corpus]: `ProtoECGNet` (neighbor) supports the efficacy of prototype-based reasoning in ECG, though this paper focuses specifically on counterfactual generation rather than classification.

### Mechanism 2
- **Claim:** R-peak based piecewise-linear alignment preserves cardiac cycle morphology, directly improving the temporal stability and clinical validity of the explanation.
- **Mechanism:** The mechanism aligns the prototype's time axis to the query's R-peaks using linear interpolation. This adapts the prototype to the query's heart rate and rhythm without distorting the internal structure of the QRS complexes, ensuring the comparison is cycle-synchronized.
- **Core assumption:** The ECG signals have detectable R-peaks; the mechanism falters with arrhythmias lacking clear R-peaks (e.g., atrial fibrillation).
- **Evidence anchors:**
  - [Section 3.3.1]: Describes the warping function $x_{aligned}[t]$ which maps prototype segments to query R-peak intervals.
  - [Table 3]: Shows "Temporal stability" improves drastically from 0.5304 (Original) to 0.7593 (Aligned Sparse), a 43% gain attributed directly to this alignment.
  - [Corpus]: `UniCoMTE` (neighbor) also targets ECG explainability, suggesting alignment with physiological markers (like peaks) is a growing trend for validity in this domain.

### Mechanism 3
- **Claim:** Sparsity optimization minimizes cognitive load by isolating only the segments that drive the class prediction change.
- **Mechanism:** An iterative process creates a binary modification mask. It starts with a low keep-ratio and attempts to replace only masked regions of the query with prototype values. If the prediction doesn't flip, the mask expands. This acts as a filter to remove irrelevant signal differences.
- **Core assumption:** The model's decision boundary is smooth enough that a small, localized perturbation can trigger a class flip without changing the whole signal.
- **Evidence anchors:**
  - [Section 3.3.2]: Defines the optimization objective $\min_m ||m||_0$ subject to valid prediction.
  - [Table 3]: Reports "Sparsity ratio" drops to 0.7800 (Aligned Sparse), meaning only 78% of the signal needs modification compared to the "Original" full replacement.
  - [Abstract]: Claims the framework generates counterfactuals that "modify only 78% of the original signal."

## Foundational Learning

- **Concept: Dynamic Time Warping (DTW)**
  - **Why needed here:** The paper uses DTW to cluster ECGs. You cannot understand how prototypes are selected without grasping that DTW measures similarity between time series that may vary in speed (heart rate), unlike Euclidean distance.
  - **Quick check question:** If two ECGs are identical in shape but one has a faster heart rate, will standard Euclidean distance fail to match them? (Answer: Yes, DTW is required to warp the time axis).

- **Concept: SHAP (SHapley Additive exPlanations)**
  - **Why needed here:** The system initializes the search for important features using SHAP values. Understanding that SHAP allocates "credit" to input features for the output prediction is crucial for understanding the "Rule Extraction" phase.
  - **Quick check question:** Does a high SHAP value indicate a feature is positively or negatively correlated with the prediction, or just influential? (Answer: Influential; the sign indicates direction).

- **Concept: Medoid vs. Centroid**
  - **Why needed here:** The paper explicitly chooses "medoids" (actual data points) over "centroids" (mathematical averages).
  - **Quick check question:** Why is a mathematical average of multiple ECG signals potentially dangerous for clinical explanations? (Answer: Averaging waveforms can smooth out critical diagnostic features like sharp ST-elevations, creating a non-physiological signal).

## Architecture Onboarding

- **Component map:** Raw ECG Data -> SHAP Calculation -> Rule Extraction (PHAR) -> DTW Distance Matrix -> MDS Clustering -> Medoid Selection (Prototypes) -> Prototype Retrieval (Target Class) -> R-peak Alignment -> Sparsity Optimization -> Output

- **Critical path:** The **Sparsity Optimization** loop (Section 3.3.2) is the inference bottleneck. While prototypes are pre-computed, the iterative masking process determines the real-time latency (<1s claim).

- **Design tradeoffs:**
  - **Validity vs. Sparsity:** The "Aligned Sparse" method achieves high sparsity and temporal stability but sacrifices ~18% validity compared to the "Original" method (Table 3).
  - **Prototype Purity vs. Coverage:** The system filters for *single-label* samples to create clear prototypes. This improves clarity for the dominant class (MI) but severely limits the available prototypes for comorbidities or minority classes (HYP).

- **Failure signatures:**
  - **HYP Class Failure:** Expect very low validity (~13.2%) for Hypertrophy counterfactuals. This is likely not a bug in the alignment code, but a data issue: only 23 single-label HYP samples remained after filtering (Section 5.1.2), causing prototype mismatch.
  - **Arrhythmia Failure:** The R-peak alignment (Section 3.3.1) assumes detectable peaks. Signals with flatlines or chaotic atrial fibrillation may fail alignment.

- **First 3 experiments:**
  1. **Verify Prototype Availability:** Before running full tests, query the prototype database size for each class. If a class has <50 prototypes, expect low validity.
  2. **Ablation on Alignment:** Run the pipeline using "Sparse" (no alignment) vs. "Aligned Sparse" on a small validation set of Normal vs. MI cases. Visually inspect if the "Sparse" output has jagged, misaligned QRS complexes.
  3. **Stress Test Sparsity:** Input a signal that is already near the decision boundary. The sparsity optimization should modify a very small percentage of the signal (<10%). If it modifies >90%, the decision boundary may be highly non-linear or the prototype is a poor match.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can integrating rhythm-agnostic alignment strategies extend the framework's validity to complex arrhythmias with irregular rhythms or absent R-peaks?
- **Basis in paper:** [explicit] The authors state that the reliance on R-peak alignment "limits the method's scope" and that "Future application to arrhythmia-specific tasks would require integrating rhythm-agnostic alignment strategies."
- **Why unresolved:** The current method assumes a definable cardiac cycle, causing it to fail on irregular rhythms like atrial fibrillation which do not conform to standard R-peak detection.
- **What evidence would resolve it:** A demonstration of the framework successfully generating valid, physiologically plausible counterfactuals for arrhythmia datasets (e.g., atrial fibrillation) using a modified alignment technique.

### Open Question 2
- **Question:** Does relaxing the single-label exclusivity constraint or using synthetic augmentation improve counterfactual validity for underrepresented classes like Hypertrophy (HYP)?
- **Basis in paper:** [explicit] The paper notes that validity drops for classes like HYP due to limited single-label samples and suggests "future work should investigate... synthetic prototype augmentation... and relaxed filtering criteria that retain informative multi-label samples."
- **Why unresolved:** The current filtering removes ambiguous multi-label cases to ensure prototype purity, but this exacerbates data scarcity for minority classes, leading to poor validity (13.2% for HYP).
- **What evidence would resolve it:** Comparative experiments showing improved validity metrics for HYP and other minority classes when multi-label samples are included or prototypes are synthetically enhanced.

### Open Question 3
- **Question:** What are the optimal weights for the composite quality metric $Q$ (aggregating validity, sparsity, stability, and margin) that best align with clinician-assessed explanation quality?
- **Basis in paper:** [explicit] The authors propose a composite metric $Q$ but note that "determining the optimal weights... for a given clinical application" is a challenge, adding that future work will use "grid search and Bayesian optimization" to align $Q$ with expert feedback.
- **Why unresolved:** The relative importance of validity vs. sparsity vs. stability varies by clinical context, and currently, these weights are undefined, making automated selection of the "best" counterfactual ambiguous.
- **What evidence would resolve it:** A user study with clinicians ranking counterfactuals, followed by an analysis deriving the weight configuration that maximizes correlation between the metric $Q$ and clinical preference.

## Limitations
- Prototype availability directly impacts validity, with minority classes severely degraded by single-label filtering
- R-peak alignment assumes detectable, stable peaks and likely fails on arrhythmic signals
- DTW-based prototype generation requires ~89 hours for full PTB-XL dataset

## Confidence
- **High Confidence:** Sparsity mechanism (78% signal modification), temporal stability improvement (43% gain), real-time generation capability (<1s)
- **Medium Confidence:** Validity metrics (81.3% overall), class-specific validity variations, clinical expert evaluation
- **Low Confidence:** Performance on arrhythmic data, scalability beyond PTB-XL, generalization to other time-series domains

## Next Checks
1. **Arrhythmia robustness test:** Evaluate counterfactual generation on AFIB and irregular rhythm samples to quantify R-peak alignment failure rates.
2. **Prototype sensitivity analysis:** Systematically vary single-label filtering thresholds and measure impact on validity across all classes, particularly minority conditions.
3. **Cross-dataset validation:** Apply framework to alternative ECG datasets (e.g., CPSC2018, MIT-BIH) to assess generalization beyond PTB-XL characteristics.