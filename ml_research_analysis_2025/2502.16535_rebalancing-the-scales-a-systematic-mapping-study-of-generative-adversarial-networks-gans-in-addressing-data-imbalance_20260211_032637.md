---
ver: rpa2
title: 'Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial
  Networks (GANs) in Addressing Data Imbalance'
arxiv_id: '2502.16535'
source_url: https://arxiv.org/abs/2502.16535
tags:
- data
- https
- gans
- imbalanced
- oversampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic mapping study analyzed 3041 papers on Generative
  Adversarial Networks (GANs) for imbalanced data, identifying 100 key studies across
  domains like healthcare, finance, and cybersecurity. GAN-based oversampling emerged
  as the primary method, with advanced architectures and variants like CTGAN and CGAN
  improving performance.
---

# Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance

## Quick Facts
- arXiv ID: 2502.16535
- Source URL: https://arxiv.org/abs/2502.16535
- Reference count: 40
- Primary result: GAN-based oversampling is the dominant approach for imbalanced data, with CTGAN and CGAN variants leading performance improvements

## Executive Summary
This systematic mapping study analyzed 3041 papers to identify 100 key studies on GAN applications for imbalanced data. The research reveals that GAN-based oversampling has emerged as the primary method for addressing class imbalance, particularly in domains like healthcare, finance, and cybersecurity. The study identifies CTGAN and CGAN as the most effective variants, with hybrid approaches combining GANs with traditional methods like SMOTE gaining momentum. Performance evaluation relies heavily on classification metrics such as F1 score and AUC-ROC, though statistical fidelity measures remain underutilized.

## Method Summary
The study conducted a systematic mapping of 3041 papers using strict inclusion/exclusion criteria, ultimately analyzing 100 key studies. The methodology involved database searches across multiple platforms, quality assessment, and categorization of findings across domains, GAN variants, preprocessing techniques, and evaluation metrics. The research focuses on structured/tabular data applications, identifying trends in publication venues, research focus areas, and methodological approaches. Key findings include the dominance of GAN-based oversampling, prevalence of specific GAN architectures, and evaluation metric preferences.

## Key Results
- GAN-based oversampling dominates with 83/100 studies, making it the primary approach for addressing class imbalance
- CTGAN and CGAN variants constitute 43% of all GAN variants used, effectively handling tabular data with mixed feature types
- Research interest peaked in 2023, with IEEE Xplore as the leading publication platform
- Hybrid approaches combining GANs with SMOTE or clustering are gaining momentum (17 studies) due to improved handling of class overlap and data noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GAN-based oversampling may improve classifier performance on imbalanced tabular datasets by augmenting minority class representation
- Mechanism: A generator network learns the minority class distribution and produces synthetic samples, while a discriminator provides adversarial feedback to improve sample quality. The balanced dataset is then used for downstream classification
- Core assumption: The generator can capture the true underlying distribution of minority samples from limited training data
- Evidence anchors: [abstract] "GAN-based over-sampling emerges as an effective preprocessing method", [section 4.3] "GAN-based oversampling is the most used approach", [corpus] TAEGAN confirms GANs remain competitive for synthetic tabular data generation

### Mechanism 2
- Claim: Hybrid GAN-SMOTE or GAN-clustering approaches may reduce class overlap and noise compared to pure GAN oversampling
- Mechanism: Traditional oversampling (e.g., SMOTE) generates initial synthetic samples that are then refined by GANs, or clustering pre-processes data to focus GAN generation on specific sub-distributions
- Core assumption: Combining interpolation-based methods with learned generation captures both local structure (SMOTE) and global distribution patterns (GAN)
- Evidence anchors: [abstract] "GANs were combined with techniques like SMOTE, clustering, and auxiliary classifiers", [section 4.3] "hybrid approaches (17 studies) are gaining momentum", [corpus] Limited direct evidence

### Mechanism 3
- Claim: Conditional GAN variants (CTGAN, CGAN, WCGAN) may provide more controlled minority class generation for structured/tabular data than vanilla GANs
- Mechanism: Conditioning on class labels or feature vectors guides the generator to produce class-specific samples; architecture adaptations handle mixed categorical/continuous features common in tabular data
- Core assumption: The conditioning signal accurately represents the target class distribution, and the architecture correctly handles multi-modal tabular distributions
- Evidence anchors: [section 4.5] "CTGAN and its extensions constitute 23% of all GAN variants", [section 4.5] "CGANs (20%) enable class-based generation", [corpus] TAEGAN and "Synthesizing Tabular Data Using Selectivity Enhanced GANs"

## Foundational Learning

- Concept: Class imbalance and evaluation metrics
  - Why needed here: Standard accuracy is misleading for imbalanced data; you must understand F1, AUC-ROC, AUC-PR, and G-Mean to evaluate GAN effectiveness correctly
  - Quick check question: On a dataset with 1% positive class, a model achieves 99% accuracy by predicting all negatives—is this a good model?

- Concept: GAN training dynamics (mode collapse, Nash equilibrium)
  - Why needed here: GANs for imbalance inherit all standard GAN instabilities plus added difficulty from sparse minority samples; recognizing failure modes is essential for debugging
  - Quick check question: If your generator produces nearly identical minority samples after 1000 epochs, what problem are you likely facing?

- Concept: SMOTE and traditional oversampling
  - Why needed here: Hybrid approaches build on these baselines; you need to understand what SMOTE does (interpolation between neighbors) to evaluate whether GANs add value
  - Quick check question: Why might SMOTE cause class overlap in high-dimensional feature spaces?

## Architecture Onboarding

- Component map:
  - Generator: Maps random noise (z) + optional conditioning (class label, features) → synthetic minority samples
  - Discriminator/Critic: Distinguishes real minority samples from generated samples; provides adversarial loss signal
  - Auxiliary Classifier (optional): Integrated into discriminator for class-conditional feedback (AC-GAN, ACTGAN patterns)
  - Preprocessing Layer: Clustering (K-means), undersampling, or SMOTE-based initialization before GAN training

- Critical path:
  1. Extract minority class samples from imbalanced dataset
  2. Apply optional preprocessing (clustering/undersampling)
  3. Train conditional GAN on minority samples with class conditioning
  4. Generate synthetic samples until target imbalance ratio is achieved
  5. Merge synthetic samples with original dataset
  6. Train downstream classifier on balanced dataset
  7. Evaluate using imbalance-specific metrics (F1, AUC-PR, G-Mean)

- Design tradeoffs:
  - CTGAN vs. WGAN-GP: CTGAN handles tabular/mixed features better; WGAN-GP offers more stable training gradients but requires more tuning
  - Hybrid vs. Pure GAN: Hybrid (SMOTE+GAN) adds complexity but may reduce overfitting on very sparse minorities; pure GAN is simpler but risks mode collapse
  - Single vs. Dual Discriminator: Dual discriminators can improve boundary detection but double training cost

- Failure signatures:
  - Mode collapse: Generated samples show low diversity; check by clustering synthetic samples and measuring intra-cluster variance
  - Training divergence: Loss oscillates without convergence; common with vanilla GAN loss—try WGAN-GP or spectral normalization
  - Poor categorical handling: Generated categorical values are invalid or unrealistic; verify CTGAN-style one-hot encoding and Gumbel-softmax
  - Overfitting to noise: Generator replicates minority outliers; inspect synthetic samples for exact duplicates of real data

- First 3 experiments:
  1. Baseline comparison: Apply CTGAN to a standard imbalanced dataset (e.g., credit card fraud), compare classifier F1/AUC-PR against SMOTE and random oversampling baselines
  2. Ablation on conditioning: Test CGAN vs. unconditional GAN on the same minority class to quantify the value of class conditioning for controlled generation
  3. Hybrid validation: Implement SMOTE→GAN pipeline (generate with SMOTE, refine with GAN) and compare against pure GAN on a dataset with known class overlap issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can diffusion models or reinforcement learning techniques be effectively hybridized with GANs to handle data imbalance?
- Basis in paper: [explicit] The abstract and conclusion explicitly identify a gap where "none of the reviewed studies explicitly explore hybridized GAN frameworks with diffusion models or reinforcement learning techniques"
- Why unresolved: The current body of research focuses primarily on GANs combined with traditional oversampling (SMOTE) or classification adjustments, leaving newer generative paradigms unexplored in this specific context
- What evidence would resolve it: Empirical studies that compare the performance of standard GAN architectures against hybrid GAN-Diffusion or GAN-RL models on benchmark imbalanced datasets

### Open Question 2
- Question: Do the GAN techniques identified as effective for tabular data generalize to image and unstructured data domains?
- Basis in paper: [explicit] The conclusion states that the study's "focus on tabular or structured data applications underlines a research gap in addressing other datasets like image"
- Why unresolved: The systematic mapping was restricted by exclusion criteria (EC7) to studies focusing on tabular data, creating a blind spot regarding the efficacy of identified variants (e.g., CTGAN) on non-tabular imbalanced data
- What evidence would resolve it: A comparative systematic review or experimental study applying the 100 key techniques identified in this paper to image-based imbalanced datasets

### Open Question 3
- Question: To what extent does the reliance on classification metrics (F1, AUC) over statistical fidelity metrics mask the quality limitations of GAN-generated synthetic data?
- Basis in paper: [inferred] The paper notes in Section 4.6 that statistical metrics (e.g., KS Statistics, Silhouette Score) were used in only 2 articles, while classification metrics were used in 90
- Why unresolved: Without statistical validation, synthetic data might improve classification scores by overfitting or distorting distributions, a risk not fully captured by the dominance of F1/AUC scores in the reviewed literature
- What evidence would resolve it: A meta-analysis of the reviewed studies correlating statistical similarity scores of synthetic data against the reported classification improvements to check for alignment or divergence

## Limitations

- Most studies focus on tabular datasets (55%), limiting generalizability to image and unstructured data domains
- Evaluation protocols lack standardization across studies, making direct performance comparisons difficult
- Hybrid approaches show high methodological diversity with limited cross-study validation, constraining reproducibility

## Confidence

- **High confidence**: GAN-based oversampling as dominant approach (83/100 studies), CTGAN and CGAN variants as most prevalent architectures, F1 score and AUC-ROC as primary evaluation metrics
- **Medium confidence**: Domain distribution claims (finance 35%, healthcare 18%), hybrid approach effectiveness, imbalance-specific metric adoption
- **Low confidence**: Long-term sustainability of research trends, comparative performance across hybrid frameworks, optimal synthetic sample ratios

## Next Checks

1. Implement standardized benchmark comparing CTGAN, CGAN, and SMOTE across multiple imbalanced tabular datasets using consistent train/test splits and evaluation metrics
2. Conduct ablation study isolating the contribution of hybrid preprocessing (SMOTE/clustering) versus pure GAN generation for minority class oversampling
3. Replicate selected studies with varying minority class sizes (10%, 5%, 1%) to quantify performance degradation thresholds and identify failure conditions