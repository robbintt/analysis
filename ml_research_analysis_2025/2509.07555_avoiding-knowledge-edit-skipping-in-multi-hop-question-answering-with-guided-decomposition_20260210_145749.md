---
ver: rpa2
title: Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided
  Decomposition
arxiv_id: '2509.07555'
source_url: https://arxiv.org/abs/2509.07555
tags:
- edited
- question
- subquestion
- irake
- facts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of "edit skipping" in multi-hop
  question answering during knowledge editing, where relevant edited facts are skipped
  during inference due to mismatches between the granularity of question decomposition
  and the granularity of facts in edited memory. To solve this, the authors propose
  IRAKE, an iterative retrieval-augmented knowledge editing method that uses guided
  decomposition from both edited facts and edited cases.
---

# Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition

## Quick Facts
- arXiv ID: 2509.07555
- Source URL: https://arxiv.org/abs/2509.07555
- Reference count: 20
- Primary result: IRAKE improves multi-hop knowledge editing accuracy by 14.5-20% by preventing edit skipping through guided decomposition

## Executive Summary
This paper addresses the critical challenge of "edit skipping" in multi-hop question answering during knowledge editing, where relevant edited facts are skipped during inference due to mismatches between the granularity of question decomposition and the granularity of facts in edited memory. The authors propose IRAKE, an iterative retrieval-augmented knowledge editing method that uses guided decomposition from both edited facts and edited cases. IRAKE employs pre-retrieval to identify relevant edited facts, uses atomic questions for guidance, and retrieves similar edited cases to strengthen decomposition. Experimental results show IRAKE significantly outperforms state-of-the-art methods on MQuAKE datasets, with accuracy improvements of 14.5-20% on average, demonstrating its effectiveness in mitigating edit skipping and improving multi-hop knowledge editing.

## Method Summary
IRAKE is an iterative retrieval-augmented knowledge editing method that reverses the standard "decompose-then-retrieve" order to "pre-retrieve-then-decompose" to reduce edit skipping. The method employs three core modules: (1) pre-retrieval to select top-k relevant edited facts from memory using semantic similarity, (2) guided decomposition using atomic questions from edited facts and similar edited case records, and (3) state backtracking to recover from failed guidance. For each question, IRAKE first pre-retrieves candidate edited facts, uses an LLM judge to select the most relevant fact, retrieves similar edited cases for dynamic prompting, performs guided decomposition, and iteratively answers until the final answer is reached. The system uses a stack-based backtracking mechanism to mitigate cascading errors when guidance leads to edit skipping.

## Key Results
- IRAKE achieves 14.5-20% accuracy improvements over state-of-the-art methods on MQuAKE-2002 and MQuAKE-hard datasets
- Pre-retrieval module improves recall of edited facts by 58% while maintaining 83% judgment accuracy with k=3
- Case-level guidance effectiveness depends on similarity threshold θ=0.80, with diminishing returns below this threshold
- Backtracking mechanism provides consistent but modest performance gains across all settings

## Why This Works (Mechanism)

### Mechanism 1: Pre-retrieval Before Decomposition
IRAKE reverses the standard "decompose-then-retrieve" order to "pre-retrieve-then-decompose" to reduce edit skipping by aligning subquestion granularity with edited fact granularity. Given a complex question Q, IRAKE first retrieves top-k candidate edited facts from memory using semantic similarity. An LLM judge selects the most relevant fact, and its corresponding atomic question guides the first decomposition step. For subsequent steps, the original question is rewritten using the previous subquestion-answer pair before pre-retrieval repeats. If no relevant edited fact is found during pre-retrieval (similarity below threshold or LLM judge returns "none"), the system falls back to unguided decomposition.

### Mechanism 2: Case-Level Guidance via Similar Edited Cases
IRAKE uses a case library to store successfully resolved cases and retrieve semantically similar multi-hop questions that share decomposition structures and overlapping edit points. For a new question Q, the most similar past case Q* is retrieved (similarity ≥ threshold θ). Its full decomposition record becomes a dynamic prompt, combined with a static task prompt, to guide current decomposition. The benefit scales with similarity; low-similarity cases provide weak guidance without proportional performance gains. If no case exceeds similarity threshold θ, case-level guidance is skipped.

### Mechanism 3: State Backtracking for Failed Guidance Recovery
A stack-based backtracking mechanism mitigates cascading errors when guidance leads to edit skipping. Before each guided decomposition step, the system pushes a non-guided decomposition state to a stack. If subsequent precise retrieval hits an edited fact, the stack clears (success). If the stack is non-empty at final answer generation, the system pops the last state and resumes reasoning without guidance. Backtracking has bounded depth; if all stacked states are exhausted without hitting edits, the system outputs the best-available answer.

## Foundational Learning

- **Concept: Multi-hop Question Answering (MQuAKE)**
  - Why needed here: Understanding that multi-hop questions require sequential fact chaining, where editing any link in the chain should propagate to the final answer
  - Quick check question: Given edits "A→B" and "B→C", if asked "What follows from A?", can you trace both hops?

- **Concept: Knowledge Editing (RAG-based vs. Parameter Modification)**
  - Why needed here: IRAKE operates in the RAG-based paradigm (edited memory + inference-time retrieval) rather than modifying model weights
  - Quick check question: Why might RAG-based KE be more interpretable than weight-level editing?

- **Concept: Question Decomposition Granularity**
  - Why needed here: The core problem is granularity mismatch—subquestions can be coarser or finer than stored facts, causing retrieval failures
  - Quick check question: If the edited fact is "City X is in country Y" but the subquestion asks "What region is City X in?", will retrieval succeed?

## Architecture Onboarding

- **Component map:** Input Question Q -> [Pre-retrieval Module] -> [LLM Judge] -> [Fact-level Guidance] -> [Case-level Guidance] -> [Guided Decomposition] -> [Precise Retrieval] -> [Question Rewriting] -> [Backtracking Stack] -> (Loop until final answer)

- **Critical path:** Pre-retrieval -> LLM judge -> (fact guidance OR case guidance OR both) -> decomposition -> precise retrieval. If retrieval fails to hit edits, backtracking may be triggered.

- **Design tradeoffs:**
  - Top-k pre-retrieval: Higher k improves recall but increases LLM judge burden (k=3 balances recall ~58% with judgment accuracy ~83%)
  - Similarity threshold θ for cases: Lower θ increases guidance coverage but adds noisy examples
  - Token/runtime cost: IRAKE uses ~2.5× more input tokens than PokeMQA due to pre-retrieval and case prompts

- **Failure signatures:**
  - No relevant facts pre-retrieved: System falls back to unguided decomposition; may miss edits
  - Counterfactual sensitivity: Some LLMs express doubt when encountering edited facts, disrupting reasoning
  - Cold start for case library: Without initial training cases, case-level guidance is unavailable

- **First 3 experiments:**
  1. Reproduce ablation (Table 2): Disable each module independently on MQuAKE-2002 to verify contribution magnitude
  2. Vary top-k pre-retrieval: Test k∈{1,3,5} and measure recall vs. judgment accuracy tradeoff
  3. Cold-start analysis: Run IRAKE with empty case library, then incrementally add training cases to measure performance scaling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the cold start problem be mitigated when initializing the edited case library without access to high-quality training data?
- Basis in paper: The authors state in the Limitations section that they currently sample a small set of cases and will "investigate how to mitigate the cold start problem in the absence of high-quality training data in future work."
- Why unresolved: The current implementation relies on the existence of a training set to build the case library, which may not always be available in real-world scenarios
- What evidence would resolve it: A mechanism or strategy (e.g., synthetic data generation or zero-shot adaptation) that allows IRAKE to achieve comparable performance starting from an empty or noisy case library

### Open Question 2
- Question: How can knowledge editing methods directly enhance the inherent decomposition and reasoning abilities of LLMs, rather than relying solely on external guidance?
- Basis in paper: The authors acknowledge that IRAKE "does not directly enhance the ability of LLMs to decompose problems or answer questions based on context" and that effectiveness is limited by the underlying model's capabilities
- Why unresolved: Current guidance methods correct the reasoning path but do not update the model's internal weights to improve its independent reasoning skills for future, unseen edits
- What evidence would resolve it: A study showing that applying the method improves the base LLM's performance on unguided, out-of-distribution multi-hop questions post-editing

## Limitations

- IRAKE's performance depends on LLM-specific behaviors and may vary significantly across different LLMs due to counterfactual sensitivity
- The method requires substantial initialization with 500 training cases before seeing benefits, creating a cold-start problem
- Performance gains come with increased computational cost (~2.5× more tokens than baseline)
- The effectiveness of case-level guidance is limited by the similarity threshold and quality of the case library

## Confidence

- **High confidence**: The edit skipping problem is well-defined and IRAKE's pre-retrieval mechanism demonstrably reduces granularity mismatches
- **Medium confidence**: Case-level guidance provides consistent improvements, but the relationship between similarity threshold and performance is not fully characterized
- **Medium confidence**: Backtracking mechanism adds value but the improvement is modest and the bounded-depth assumption needs validation

## Next Checks

1. **Ablation with different LLMs**: Test IRAKE with multiple LLM backends (e.g., GPT-4, Claude, Llama) to quantify performance variance due to counterfactual sensitivity and judge reliability

2. **Dynamic threshold optimization**: Implement adaptive similarity threshold θ that adjusts based on case library size and test-set characteristics rather than using fixed θ=0.80

3. **Knowledge edit efficiency analysis**: Measure the relationship between number of edited facts involved in a question and IRAKE's success rate to identify performance ceilings and guidance effectiveness limits