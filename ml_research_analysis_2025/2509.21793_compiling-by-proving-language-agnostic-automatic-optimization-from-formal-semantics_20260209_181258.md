---
ver: rpa2
title: 'Compiling by Proving: Language-Agnostic Automatic Optimization from Formal
  Semantics'
arxiv_id: '2509.21793'
source_url: https://arxiv.org/abs/2509.21793
tags:
- execution
- compilation
- rules
- program
- semantics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents compiling by proving, a paradigm that transforms
  verification proofs into optimized execution rules. By constructing All-Path Reachability
  Proofs through symbolic execution and compiling their graph structure, the approach
  consolidates many semantic rewrites into single rules while preserving correctness
  by construction.
---

# Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics

## Quick Facts
- arXiv ID: 2509.21793
- Source URL: https://arxiv.org/abs/2509.21793
- Reference count: 34
- This paper presents compiling by proving, a paradigm that transforms verification proofs into optimized execution rules, achieving significant performance improvements across different compilation scopes.

## Executive Summary
This paper introduces a novel compilation paradigm that transforms verification proofs into optimized execution rules through All-Path Reachability Proofs (APRPs). The approach constructs proof graphs via symbolic execution and applies graph transformations to consolidate fragmented semantic rewrites into single, efficient rules. By treating proof construction itself as a compilation mechanism, the method unifies verification and optimization while preserving correctness by construction. Implemented as a language-agnostic extension to the K framework, it demonstrates substantial performance improvements across different compilation scopes, from opcode-level optimizations to whole-program compilation.

## Method Summary
The method transforms verification proofs into optimized execution rules through a three-stage process: APRP construction via symbolic execution, graph transformations (step compression and branch lifting), and rule generation with priority integration. Symbolic execution builds proof trees where vertices represent constrained states and edges capture transitions. Graph transformations consolidate multiple steps into single edges and restructure control flow, producing maximally compressed execution graphs. These graphs are then compiled into optimized K rules that execute before original modular rules, maintaining fallback for edge cases.

## Key Results
- Opcode-level compilation achieves 89.6% average reduction in rewriting steps with 73.3s average compilation time
- Concrete EVM conformance tests show 2.19× speedup, symbolic tests show 1.44× speedup
- Whole-program MIR compilation achieves 522× speedup for complete programs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: All-Path Reachability Proofs (APRPs) constructed through symbolic execution encode sufficient information for compilation by capturing complete execution behavior as a directed graph.
- Mechanism: Symbolic execution builds proof trees with vertices as constrained terms (state + constraints) and edges as transitions (steps for deterministic sequences, branches for conditionals, covers for subsumption). Step edges represent basic blocks—optimization opportunities made explicit in graph form.
- Core assumption: The symbolic execution engine can exhaustively explore all execution paths within the compilation boundary defined by program specifications.
- Evidence anchors: [abstract], [section III-B], [corpus]

### Mechanism 2
- Claim: Graph transformations (step compression and branch lifting) convert fragmented proof structures into maximally compressed execution rules.
- Mechanism: Step compression merges consecutive step edges (vA→vB→vC into vA→vC) by composing rule sequences. Branch lifting reorders operations: step-branch lifting moves branches before deterministic steps; branch-branch lifting flattens nested conditionals through constraint composition (αk∘αkj). Iterative transformation produces streamlined graphs where branches lead directly to compressed step sequences.
- Core assumption: Deterministic sequences in step edges have no hidden side effects that would make reordering unsafe.
- Evidence anchors: [section III-D]

### Mechanism 3
- Claim: Priority-based rule integration ensures compiled rules execute before original modular rules while maintaining fallback for edge cases.
- Mechanism: Compiled rules receive higher priority than original K rules. When patterns match, optimized rules fire first, bypassing multi-step execution. Original modular rules remain at lower priority as fallback when compiled rules don't apply (e.g., precondition failures).
- Core assumption: The K framework's priority mechanism correctly orders rule application without race conditions.
- Evidence anchors: [section III-D], [corpus]

## Foundational Learning

- Concept: Term Rewriting Systems (TRS)
  - Why needed here: The K framework executes programs as sequences of rewrite steps transforming terms. Understanding TRS is essential to grasp why consolidating multiple rewrites eliminates overhead.
  - Quick check question: How does a term rewriting system differ from a traditional interpreter, and why would consolidating rewrite steps improve performance?

- Concept: Symbolic Execution with Path Conditions
  - Why needed here: APRP construction uses symbolic execution to explore all paths with symbolic values. The algorithm's execute() and implies() operations build proof trees capturing path constraints.
  - Quick check question: How does symbolic execution differ from concrete execution, and what role do accumulated path conditions play?

- Concept: Matching Logic and Subsumption
  - Why needed here: Cover edges rely on subsumption checking (implies(φ1, φ2)) via matching logic and SMT solving. Critical for loop detection and proof termination.
  - Quick check question: When does state φ1 subsume state φ2, and why is this important for proving loop termination?

## Architecture Onboarding

- Component map: [Program Specs] → [APRP Construction] → [Graph Transforms] → [Rule Generation] → [Priority Integration]
- Critical path: (1) Define specifications pairing initial/final states for compilation units. (2) Implement terminal(T) and sameloop(T,Tprev) predicates for your domain. (3) Run APRP construction with bounds (I, N). (4) Apply graph transformations. (5) Generate and integrate optimized rules with priority override.
- Design tradeoffs: Precision flag P enables exhaustive subsumption (precision mode) vs. faster customized loop detection (fast mode). Larger N creates longer step edges but increases graph complexity. Whole-program compilation yields greater speedups (522× for MIR) but requires more compilation time (73.3s average for EVM opcodes). Note: Contract opcodes remain future work.
- Failure signatures: Specification coverage gaps for complex control flow (JUMP/JUMPI failed, 77.8% Flow Control coverage). Iteration bound exhaustion terminates proofs incomplete. Stuck states occur when execute() returns M=0 (no matching rules). Cross-contract operations have 0% coverage.
- First 3 experiments:
  1. Compile EVM ADD opcode with φinit = ⟨ADD·rest⟩, φfinal = ⟨rest⟩. Measure step reduction against conformance tests.
  2. Compare precision vs. fast mode (flag P) for the same opcode—measure APRP construction time and graph size differences.
  3. Scale whole-program compilation with iterative loops (10, 100, 1000 iterations following the add1 example) to verify speedup scaling claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the approach be extended to compile operations with external side effects and nested execution contexts, such as EVM contract calls?
- Basis in paper: The paper notes that "Contract-level operations (e.g., external calls) have non-trivial semantic boundaries due to nested execution contexts and cross-contract state changes, remaining as future work" (Page 4).
- Why unresolved: These operations failed to compile (0.0% coverage) because their semantics involve complex boundaries that the current specification and proof construction method cannot capture.
- What evidence would resolve it: Successful compilation and execution of opcodes like `CALL` or `DELEGATECALL` with measurable speedups.

### Open Question 2
- Question: How does the compilation time and symbolic execution cost scale when applying whole-program compilation to complex, real-world software?
- Basis in paper: The MIR evaluation is limited to a single, simple iterative program (Page 5), leaving the performance on large, complex codebases with extensive branching unverified.
- Why unresolved: While the method shows 522× speedup for a simple loop, it is unclear if the "exhaustive symbolic execution" required for APRP construction remains tractable for industrial-scale programs.
- What evidence would resolve it: Benchmarks on standard Rust crates or complex algorithms showing compilation times relative to program size.

### Open Question 3
- Question: To what degree can the loop detection and abstraction predicates (`sameloop`, `abstract`) be automated for diverse languages?
- Basis in paper: Algorithm 1 relies on "two user-supplied predicates" (Page 3) for termination and loop abstraction, implying manual tuning is currently required for different semantic domains.
- Why unresolved: The paper does not specify if these predicates can be derived generically or if they represent a significant manual burden for new language definitions.
- What evidence would resolve it: A demonstration of the tool automatically deriving these predicates for a new semantics (e.g., Wasm or LLVM) without manual intervention.

## Limitations

- The approach relies heavily on the K framework, creating platform-specific dependencies that may limit generalizability
- Complex control flow patterns show limited coverage (77.8% for Flow Control opcodes), indicating challenges with certain program structures
- External operations with side effects and nested execution contexts (contract calls) remain unimplemented as future work

## Confidence

- **High Confidence:** The core mechanism of converting proof graphs into optimized rules is sound and well-supported by the formal definitions in Section III-B
- **Medium Confidence:** The reported performance improvements are plausible given the consolidation of rewrite steps, but the exact magnitude depends on parameter tuning and specification quality
- **Low Confidence:** The 522× whole-program speedup claim lacks detailed analysis of whether this scales to more complex programs or if it's specific to the tested example

## Next Checks

1. Implement APRP construction for a simple EVM opcode (e.g., ADD) with multiple specifications to verify the step reduction claims and measure compilation time across different N values
2. Test branch lifting transformations on nested conditional structures to confirm the flattening behavior and constraint composition correctness described in Section III-D
3. Conduct a coverage analysis comparing the implemented `terminal` and `sameloop` predicates against the reported 77.8% Flow Control coverage to identify specification gaps