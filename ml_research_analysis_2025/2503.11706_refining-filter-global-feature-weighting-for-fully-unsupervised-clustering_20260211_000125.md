---
ver: rpa2
title: Refining Filter Global Feature Weighting for Fully-Unsupervised Clustering
arxiv_id: '2503.11706'
source_url: https://arxiv.org/abs/2503.11706
tags:
- shap
- clustering
- feature
- methods
- weighting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using SHAP (SHapley Additive exPlanations)
  values to assign feature weights in unsupervised clustering, aiming to improve clustering
  quality by highlighting relevant features. The approach trains a random forest on
  pseudo-labels from an initial clustering, then uses SHAP values to quantify feature
  contributions and derive normalized weights.
---

# Refining Filter Global Feature Weighting for Fully-Unsupervised Clustering
## Quick Facts
- arXiv ID: 2503.11706
- Source URL: https://arxiv.org/abs/2503.11706
- Reference count: 31
- SHAP-based feature weighting improves unsupervised clustering, with up to 22.69% increase in Adjusted Rand Index

## Executive Summary
This paper introduces a novel approach to unsupervised clustering by integrating SHAP (SHapley Additive exPlanations) values for feature weighting. The method trains a random forest on pseudo-labels derived from an initial clustering, uses SHAP values to quantify feature contributions, and re-weights the data to improve clustering quality. Iterative refinement is possible, and ensemble weighting with other methods often further enhances results. Experiments across five datasets and four clustering algorithms demonstrate consistent improvements, positioning SHAP as a versatile, general-purpose feature weighting technique for clustering.

## Method Summary
The proposed method begins with an initial clustering to generate pseudo-labels, which are then used to train a random forest classifier. SHAP values are computed from this model to quantify each feature's contribution to the clustering outcome. These values are normalized to derive feature weights, which are applied to the data matrix. Clustering is re-run on the weighted data, and the process can be repeated for iterative refinement. Ensemble weighting combines SHAP weights with those from other methods (e.g., mRMR, Lp) to further boost performance. The approach is model-agnostic and adaptable to various clustering algorithms.

## Key Results
- SHAP-based weighting yields up to 22.69% improvement in Adjusted Rand Index (e.g., from 0.586 to 0.719 on the Digits dataset)
- Consistently competitive or superior performance across five datasets (Iris, Wine, Breast Cancer, Digits, Vehicle Silhouette) and four clustering algorithms (k-means, hierarchical, HDBSCAN, GMM)
- Ensemble weighting (e.g., SHAP+mRMR, SHAP+Lp) often further improves clustering quality

## Why This Works (Mechanism)
SHAP values provide a principled way to quantify feature importance by measuring each feature's marginal contribution to model predictions, based on game-theoretic principles. In unsupervised clustering, where labels are unavailable, pseudo-labels from an initial clustering serve as proxies. By training a random forest on these pseudo-labels, SHAP values capture how much each feature influences cluster assignments. Re-weighting features according to their SHAP-based importance emphasizes relevant features and suppresses noise, leading to more coherent clusters upon re-clustering. Iterative application allows for progressive refinement, and ensemble weighting leverages complementary strengths of multiple feature selection methods.

## Foundational Learning
- **SHAP values**: Quantify feature importance in a model-agnostic way; needed to assign meaningful weights to features in unsupervised settings; quick check: verify SHAP values sum to model output for each sample.
- **Random forest for pseudo-label learning**: Provides a robust model for feature importance estimation; needed to translate cluster structure into feature weights; quick check: assess random forest accuracy on pseudo-labels.
- **Feature weighting in clustering**: Adjusts the relative influence of features; needed to highlight relevant dimensions and reduce noise; quick check: compare clustering results with and without weighting.
- **Ensemble weighting**: Combines multiple feature weighting strategies; needed to capture diverse aspects of feature relevance; quick check: test ensemble vs. single-method weighting on benchmark datasets.

## Architecture Onboarding
- **Component map**: Initial clustering -> Pseudo-labels -> Random forest training -> SHAP value computation -> Feature weight normalization -> Re-weighted data -> Re-clustering -> (Optional) Iterative refinement or ensemble weighting
- **Critical path**: Initial clustering → Random forest → SHAP → Weighting → Re-clustering
- **Design tradeoffs**: Accuracy vs. computational cost (SHAP values are expensive); model-agnosticism vs. potential overfitting to pseudo-labels; single vs. ensemble weighting (ensemble is more robust but adds complexity)
- **Failure signatures**: Poor initial clustering propagates errors; SHAP values may be unstable for small or noisy datasets; high-dimensional data increases computational burden
- **First experiments**: 1) Test SHAP weighting on Iris dataset with k-means; 2) Compare single vs. ensemble SHAP weighting on Wine dataset; 3) Evaluate scalability on high-dimensional Digits dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead due to SHAP value calculation, especially for large or high-dimensional datasets
- Performance depends on the quality of initial pseudo-labels, which may propagate errors
- Limited evaluation on diverse or noisy real-world datasets, leaving robustness in question

## Confidence
- Claims about general applicability of SHAP: **High** (consistent performance across algorithms and datasets)
- Claims about ensemble weighting boosting performance: **Medium** (improvements observed but not uniformly significant)
- Claims about limitations (scalability, pseudo-label dependency): **Low to Medium** (limited empirical analysis)

## Next Checks
1. Test SHAP-based weighting on high-dimensional, noisy, or imbalanced datasets to assess robustness.
2. Benchmark against approximate SHAP methods (e.g., Kernel SHAP, Tree SHAP) to evaluate computational trade-offs.
3. Investigate the impact of initial clustering quality on final results by varying initialization strategies or adding noise.