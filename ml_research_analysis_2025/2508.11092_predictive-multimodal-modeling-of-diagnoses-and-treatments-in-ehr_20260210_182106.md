---
ver: rpa2
title: Predictive Multimodal Modeling of Diagnoses and Treatments in EHR
arxiv_id: '2508.11092'
source_url: https://arxiv.org/abs/2508.11092
tags:
- temporal
- tabular
- https
- multimodal
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a multimodal model for predicting ICD codes
  at various stages during a patient's hospital stay. The model integrates clinical
  notes and laboratory test data to improve early predictions, using pre-trained encoders,
  feature pooling, and cross-modal attention to learn optimal representations.
---

# Predictive Multimodal Modeling of Diagnoses and Treatments in EHR

## Quick Facts
- arXiv ID: 2508.11092
- Source URL: https://arxiv.org/abs/2508.11092
- Reference count: 30
- Proposes a multimodal model integrating clinical notes and laboratory data for early ICD code prediction in EHR

## Executive Summary
This paper introduces MIHST, a multimodal predictive model for ICD code classification at multiple temporal points during hospital stays. The model fuses clinical notes and laboratory test data through pre-trained encoders, cross-modal attention, and a weighted temporal loss function. Experiments on MIMIC-III show significant improvements in early prediction performance compared to state-of-the-art methods, particularly in the first 2-5 days after admission.

## Method Summary
The approach uses RoBERTa-base-PM-M3-Voc for text encoding and TP-BERTa for tabular lab data. Laboratory features are preprocessed through Yeo-Johnson transformation, standardization, and quantile binning. A modality mapper aligns tabular embeddings to the text vector space dimension. Feature pooling by timestamp condenses multiple lab measurements, and cross-modal attention enables dynamic fusion. The model is trained with a weighted temporal loss that balances early and final prediction performance across specific cutoffs.

## Key Results
- MIHST outperforms existing state-of-the-art systems in early prediction settings
- Achieved higher Micro-F1, Micro-AUC, and Precision@5 scores in the first 2-5 days after admission
- Weighted temporal loss enhances performance across different time points
- Feature pooling effectively manages large volumes of tabular events without increasing computational complexity

## Why This Works (Mechanism)

### Mechanism 1
Cross-modal fusion of clinical notes and laboratory data improves early-stage ICD code prediction when unimodal signals are sparse. The model uses separate pre-trained encoders (RoBERTa-base-PM-M3-Voc for text; TP-BERTa for tabular), maps tabular embeddings to the textual vector space via a linear layer + LeakyReLU, then merges representations chronologically. A causal attention block allows each time step to attend only to prior events from both modalities, enabling dynamic reweighting as new information arrives.

### Mechanism 2
Feature pooling by timestamp enables efficient handling of high-volume tabular events without diluting the strongest signals. For each unique timestamp, the model applies max pooling over all tabular embeddings at that time, producing one pooled representation per time point. This condenses multiple lab measurements into a single vector comparable to a document chunk embedding, preventing over-representation of tabular modality and reducing sequence length.

### Mechanism 3
Weighted temporal loss balances early prediction performance against final-discharge accuracy by explicitly tuning the gradient contribution from each time point. The loss sums binary cross-entropy over a set of temporal cutoffs (2, 5, 13 days, pre-discharge, discharge), with weights summing to 1. The final point receives weight 0.6, others 0.1 each, preventing overfitting to the discharge summary while leveraging its strong diagnostic evidence.

## Foundational Learning

- **Causal (autoregressive) masking in transformers**: Needed to predict ICD codes at each time point using only past clinical events; future notes or labs would leak information unavailable at inference time. Quick check: If you removed the causal mask and trained the model to predict at day 2 using day 10 notes, what would happen to early prediction validity at deployment?

- **Modality alignment via projection layers**: Needed because text and tabular pre-trained encoders produce embeddings with different dimensions and semantics; a learned mapping enables cross-modal attention without joint pre-training. Quick check: What would go wrong if you concatenated text and tabular embeddings directly without a modality mapper?

- **Multi-label binary cross-entropy with class imbalance**: Needed because ICD coding is multi-label (patients often have multiple codes) and highly imbalanced; the model must optimize per-label probabilities independently. Quick check: Why would a softmax over all ICD codes be inappropriate for this task?

## Architecture Onboarding

- **Component map**: Input (notes + lab events) → Encoders (RoBERTa-base-PM-M3-Voc + TP-BERTa) → Modality mapper (Linear+LeakyReLU) → Feature pooling (max-pool by timestamp) → Fusion & temporal encoder (hierarchical transformer with causal attention) → Label-wise attention (multi-head attention with label embeddings) → Output (projection + sigmoid per label)

- **Critical path**: Tabular preprocessing (Yeo-Johnson, imputation, discretization) → encoder mapping → pooling quality → causal masking correctness → temporal loss weight tuning. Errors in discretization or pooling can silently degrade early predictions.

- **Design tradeoffs**: Pooling reduces sequence length but may lose per-feature granularity at high-volume timestamps. Weighted temporal loss improves early metrics but sacrifices some final-discharge accuracy compared to unimodal baselines. Model is agnostic to encoder choice but requires re-training the modality mapper if encoder dimensions change.

- **Failure signatures**: Early prediction Micro-F1 drops significantly below LAHST baseline → likely issue in lab feature selection, discretization, or pooling implementation. Last-day performance collapses → check if temporal loss weights are misconfigured. Model outputs near-zero probabilities for rare labels → may need label-level threshold tuning.

- **First 3 experiments**: 1) Replicate Table 1 comparison on MIMIC-III test split: train MIHST with default weights, evaluate Micro-F1/AUC/Precision@5 at 2, 5, 13 days and last day. Verify early gains vs. LAHST and last-day tradeoff. 2) Ablate feature pooling: replace max pooling with mean or no pooling. Measure impact on early vs. late metrics and training memory/time. 3) Sweep temporal loss weights: test equal weights, reversed weights, and no temporal loss. Confirm that proposed weighting (0.6 on last, 0.1 others) is Pareto-optimal for early-late balance.

## Open Questions the Paper Calls Out

### Open Question 1
To what extent does the inclusion of additional modalities, such as diagnostic imaging or medication orders, further improve early prediction accuracy? The conclusion states the architecture is agnostic to encoder choice and "easily extends to new modalities" to leverage "a wider range of data sources." This is unresolved because the current study restricts multimodal fusion to only clinical notes and laboratory events.

### Open Question 2
How does the model perform on the "long tail" of rare diseases versus the high-frequency conditions evaluated in this study? The paper limits its evaluation to the "top 50 most frequent codes" and restricts feature selection to avoid overfitting "rare event types." It is unclear if the multimodal fusion benefits the low-prevalence diagnoses that often lack sufficient training data.

### Open Question 3
Does the model maintain its predictive superiority when applied to non-ICU hospital wards or external healthcare systems? The experiments rely exclusively on the MIMIC-III dataset, which is specific to critical care units at a single medical center. The density and availability of laboratory tests in ICU settings may differ significantly from general inpatient or outpatient environments.

## Limitations
- Ablation studies are limited to a small set of architectural variants, making it unclear whether improvements are due to cross-modal fusion or other factors like pre-trained encoders and weighted temporal loss
- Evaluation focuses only on top-50 ICD codes, excluding rare but clinically important diagnoses
- Lab preprocessing pipeline is critical but not fully specified in terms of bin boundaries or exact feature selection criteria

## Confidence

- **High confidence**: Cross-modal attention enabling early predictions when individual modalities are sparse (Mechanism 1) is well-supported by ablation and performance gaps in early prediction windows
- **Medium confidence**: Feature pooling for managing tabular event volume and preventing overfitting (Mechanism 2) is supported internally but lacks external validation or comparison with other pooling methods
- **Medium confidence**: Weighted temporal loss improving early predictions while balancing final accuracy (Mechanism 3) is demonstrated by controlled ablations, though the specific weight configuration may be dataset-specific

## Next Checks

1. **Cross-modal ablation**: Train a multimodal model with concatenated (non-fused) embeddings and compare early prediction performance to the cross-attention baseline. This isolates the contribution of cross-modal fusion.

2. **Pooling variant test**: Replace max pooling with mean pooling and with a learned attention-based pooling. Measure impact on early/late prediction metrics and memory usage to confirm max pooling is optimal.

3. **Weight sensitivity sweep**: Systematically vary the temporal loss weights and plot Pareto frontiers of early vs. late performance to determine if the proposed weighting is truly optimal or dataset-dependent.