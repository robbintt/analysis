---
ver: rpa2
title: Disentangling concept semantics via multilingual averaging in Sparse Autoencoders
arxiv_id: '2508.14275'
source_url: https://arxiv.org/abs/2508.14275
tags:
- concept
- ontology
- class
- average
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether multilingual averaging can isolate
  semantic information in sparse autoencoder representations of ontology classes.
  The authors parse OWL ontology classes into text, translate English versions into
  French and Chinese, and use these as prompts for a Gemma 2B LLM with Sparse Autoencoders
  to obtain concept activations.
---

# Disentangling concept semantics via multilingual averaging in Sparse Autoencoders

## Quick Facts
- **arXiv ID:** 2508.14275
- **Source URL:** https://arxiv.org/abs/2508.14275
- **Reference count:** 19
- **Primary result:** Multilingual averaging of sparse autoencoder activations yields significantly stronger correlations with ground truth ontology alignments than single-language representations.

## Executive Summary
This paper investigates whether multilingual averaging can isolate semantic information in sparse autoencoder (SAE) representations of ontology classes. The authors parse OWL ontology classes into text, translate English versions into French and Chinese, and use these as prompts for a Gemma 2B LLM with Sparse Autoencoders to obtain concept activations. They find that averaging activations across language versions (conceptual average) yields significantly stronger correlations with ground truth ontology alignments compared to single-language representations. For summary text versions, English-only correlations were 0.09 versus 0.39 for English-French averages and 0.33 for English-Chinese averages. The method appears to suppress syntactic and language-specific information, leaving purer semantic representations, suggesting a new technique for improving mechanistic interpretability of LLM internal states.

## Method Summary
The authors use the OAEI 2024 conference track dataset (16 OWL ontologies, 867 classes, 174 ground truth mappings) and parse OWL classes into text using OWLAPI with bespoke logic for different ontology formats. They generate both summary text (class name plus properties) and verbose text (full description with connecting words). English versions are translated to French and Chinese using googletrans, then used as prompts for Gemma 2B with Gemma Scope SAEs (16.4k width, L0 norm 13-23 active features, layers 0-25). Activations are averaged across languages (using only shared concepts), and cosine similarity between all class pairs is computed. Point-Biserial Correlation with random resampling handles class imbalance when comparing against ground truth mappings.

## Key Results
- Multilingual averaging significantly improves correlation with ground truth ontology alignments compared to single-language representations
- English-only correlations were 0.09 versus 0.39 for English-French averages and 0.33 for English-Chinese averages for summary text
- The method appears to suppress syntactic and language-specific information, leaving purer semantic representations
- Averaging across languages shows promise as a technique for improving mechanistic interpretability of LLM internal states

## Why This Works (Mechanism)
The multilingual averaging technique works by exploiting the shared semantic content across language translations while suppressing language-specific syntactic and lexical variations. When the same concept is expressed in multiple languages, the underlying semantic meaning remains constant while surface forms differ. By averaging SAE activations across these different linguistic representations, the method effectively filters out language-specific features and noise, retaining only the shared semantic components. This creates a more robust representation of the concept's meaning that better aligns with ground truth semantic relationships in ontologies.

## Foundational Learning
- **Sparse Autoencoders (SAEs):** Neural network components that learn sparse representations by reconstructing input while enforcing sparsity constraints. Why needed: They provide interpretable feature activations for LLM internal states. Quick check: Verify non-zero activations when running Gemma Scope on test prompts.
- **Point-Biserial Correlation:** Statistical measure for correlation between a continuous variable and a binary variable. Why needed: It evaluates how well cosine similarities predict binary ground truth alignment mappings. Quick check: Confirm calculation produces values between -1 and 1 on test data.
- **OWLAPI parsing:** Java library for working with OWL ontologies. Why needed: Extracts class representations from structured ontology data. Quick check: Verify parsed text contains class names and properties for sample ontologies.
- **Conceptual averaging:** Technique of averaging feature activations across multiple language representations of the same concept. Why needed: Suppresses language-specific features while retaining shared semantics. Quick check: Inspect activation overlap between language pairs before averaging.
- **Cosine similarity:** Measure of similarity between two vectors based on the cosine of the angle between them. Why needed: Quantifies similarity between concept representations for correlation analysis. Quick check: Verify similarity values fall between -1 and 1 for test vector pairs.
- **Random resampling for class imbalance:** Statistical technique to handle imbalanced binary classification problems. Why needed: Ground truth mappings are highly imbalanced (few positive pairs). Quick check: Confirm resampling produces balanced positive/negative pair distributions.

## Architecture Onboarding

**Component Map:** OWL ontologies -> OWLAPI parsing -> Text verbalization -> Googletrans translation -> Gemma 2B + Gemma Scope SAEs -> Feature activation collection -> Multilingual averaging -> Cosine similarity computation -> Point-Biserial correlation

**Critical Path:** The core pipeline flows from ontology parsing through to correlation calculation, with translation and averaging as the key innovation points. Each stage must succeed for meaningful results.

**Design Tradeoffs:** The authors chose googletrans for accessibility despite potential reliability issues, and used a single SAE layer (0-25 shown, final layer unspecified) rather than aggregating across layers. The bespoke OWL parsing trades standardization for potentially better extraction of class semantics.

**Failure Signatures:** Low correlations (<0.05) across all conditions suggest translation failures or insufficient feature extraction. No shared concepts between languages after averaging indicates structural differences in translations or excessive SAE sparsity.

**First Experiments:**
1. Run Gemma Scope SAE on 2-3 sample classes to verify non-zero feature activations are produced
2. Translate sample class descriptions to French/Chinese and verify translations are reasonable and structurally similar
3. Compute cosine similarity between averaged multilingual representations and single-language versions to confirm averaging effect

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the multilingual averaging effect generalize beyond the Gemma 2B architecture to other LLM families and scales?
- **Basis in paper:** The study exclusively uses Gemma 2B with Gemma Scope SAEs; no other models are tested.
- **Why unresolved:** Architectural differences (attention mechanisms, training data, SAE availability) may affect whether language-invariant features exist and can be isolated similarly.
- **What evidence would resolve it:** Replication of the multilingual averaging protocol on at least two other model families (e.g., LLaMA, Mistral) with comparable SAE suites, using the same ontology alignment benchmark.

### Open Question 2
- **Question:** Does averaging across more than two languages yield diminishing, stable, or increasing returns for semantic disentanglement?
- **Basis in paper:** The method averages only English–French or English–Chinese pairs; no experiments with 3+ languages or all-together averaging are reported.
- **Why unresolved:** It is unclear whether shared semantics emerges from any bilingual pair or whether additional languages further suppress language-specific noise.
- **What evidence would resolve it:** Systematic experiments with 3, 5, and 10 language averages on the same ontology classes, reporting correlation curves as language count increases.

### Open Question 3
- **Question:** Can a standardized, less subjective OWL-to-text verbalization pipeline improve reproducibility and alignment correlation?
- **Basis in paper:** "The accuracy of extraction of class representations is exposed to problems of subjectivity. Both the conceptual model used to create an OWL ontology and the extraction process to create a text string version are prone to idiosyncrasies in design."
- **Why unresolved:** Different verbalization strategies (summary vs. verbose) yield different baseline correlations, suggesting prompt engineering influences outcomes.
- **What evidence would resolve it:** A comparative study using multiple existing verbalizers (NaturalOWL, OWL Verbalizer, OntoLAMA) on the same ontologies with fixed translation and SAE pipelines.

### Open Question 4
- **Question:** Do the SAE features retained after multilingual averaging correspond to human-judged semantic concepts rather than surface-level token patterns?
- **Basis in paper:** The automatic interpretations in Table 5 (attending to tokens like "Sant," numerical outputs) do not intuitively match the "Author" concept; the authors claim purer semantics but provide no human evaluation.
- **Why unresolved:** Without human annotation or probing tasks, it is unclear whether retained features capture abstract semantics versus shared low-level patterns across translations.
- **What evidence would resolve it:** Human annotation of whether top-k retained features for sample classes are semantically relevant, or probing tasks testing whether averaged representations improve performance on semantic inference benchmarks.

## Limitations
- The bespoke OWLAPI parsing logic is unspecified, making exact reproduction difficult
- The specific SAE layer(s) used for final reported correlations are ambiguous (plots show layers 0-25 but Table 2 aggregations don't specify which)
- Translation quality via googletrans may vary and could affect results if translations fail or return English unchanged
- No human evaluation of whether retained SAE features correspond to meaningful semantic concepts

## Confidence
- **Experimental design and methodology:** High - The overall approach and evaluation metrics are clearly specified
- **Quantitative results:** Medium - Targets (0.09 English-only vs 0.39 English-French correlations) are specified but depend on correctly implementing unknown parsing and layer selection details
- **Reproducibility:** Medium - Key implementation details are missing, but the core pipeline is well-defined

## Next Checks
1. Verify translation quality and feature extraction: Run a small test with 2-3 classes through googletrans and Gemma Scope SAE, checking that activations are non-zero and translations produce structurally similar outputs
2. Test averaging methodology: Manually inspect activation overlap between language pairs for a few classes to confirm sufficient shared concepts exist before averaging
3. Validate correlation calculation: Compute Point-Biserial Correlation on a small subset with ground truth mappings, confirming the random resampling approach for class imbalance handling