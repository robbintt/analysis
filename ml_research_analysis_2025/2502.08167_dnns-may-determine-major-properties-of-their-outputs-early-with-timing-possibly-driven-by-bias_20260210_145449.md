---
ver: rpa2
title: DNNs May Determine Major Properties of Their Outputs Early, with Timing Possibly
  Driven by Bias
arxiv_id: '2502.08167'
source_url: https://arxiv.org/abs/2502.08167
tags:
- timing
- dnns
- bias
- figure
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores how deep neural networks (DNNs) determine their
  outputs during inference, drawing parallels to human decision-making that relies
  on fast heuristics. The authors propose that DNNs fix major properties of their
  outputs early in the inference process, with timing influenced by the model's inherent
  biases.
---

# DNNs May Determine Major Properties of Their Outputs Early, with Timing Possibly Driven by Bias

## Quick Facts
- **arXiv ID**: 2502.08167
- **Source URL**: https://arxiv.org/abs/2502.08167
- **Reference count**: 22
- **Primary result**: DNNs fix major output properties within first 15 diffusion steps, with timing correlating to model bias toward specific features

## Executive Summary
This paper investigates when deep neural networks determine their outputs during inference, proposing that major properties are fixed early through bias-driven mechanisms. Using diffusion models as a case study, the authors systematically alter text prompts during generation and measure the timing of determination using CLIP similarity scores. Their experiments with five state-of-the-art text-to-image diffusion models demonstrate that outputs are typically determined within the first 15 steps (often within 5 steps) of a 50-step generation process. The timing correlates with the model's bias toward specific features - more biased attributes like color show earlier fixation than less biased ones like material. This pattern holds across different model architectures and attribute types, including human attributes like gender and ethnicity.

## Method Summary
The authors analyze when diffusion models determine output properties by measuring "switching points" during iterative generation. They use five pre-trained text-to-image diffusion models (SD1.4, SDXL, SD3, Kandinsky 3, Karlo UnCLIP) and systematically alter prompts at different timestamps during the 50-step diffusion process. At each timestamp ts, they switch from an initial prompt to an altered prompt and measure CLIP similarity scores to determine when the output aligns with the altered prompt rather than the initial one. Generation diversity is measured via normalized entropy of zero-shot attribute predictions. The study examines four attribute types (color, pattern, shape, material) across various objects, plus human attributes like gender and ethnicity across professions.

## Key Results
- Outputs are typically determined within first 15 diffusion steps (often within 5 steps) out of 50 total steps
- Timing of determination correlates with model bias toward specific features - more biased attributes like color show earlier fixation than less biased ones like material
- Pattern holds across different model architectures and attribute types, including human attributes like gender and ethnicity
- Findings suggest DNNs rely on early-stage intuitive mechanisms influenced by inherent biases

## Why This Works (Mechanism)

### Mechanism 1: Early Output Determination in Diffusion Models
- Claim: DNNs fix major output properties very early in the inference process, often within the first 5-15 steps of a 50-step diffusion trajectory.
- Mechanism: The iterative denoising process reveals a "switching point" where generated images transition from following an initial prompt to an altered prompt.
- Core assumption: The timestamp at which output aligns with altered prompt represents the moment of "decision-making."
- Evidence anchors: [abstract] outputs typically determined within first 15 steps; [section 4.2] switching point often within first 15 steps.

### Mechanism 2: Bias-Timing Correlation
- Claim: The timing of early determination correlates with the model's inherent bias toward specific features.
- Mechanism: Attributes with stronger model bias show earlier fixation than less-biased attributes. Generation diversity serves as proxy for bias level.
- Core assumption: Lower generation diversity for an attribute type indicates stronger model bias toward that attribute.
- Evidence anchors: [abstract] timing correlates with model bias; [section 4.3] positive correlation between normalized entropy and average switching timing.

### Mechanism 3: Heuristic-Based Decision Analogy
- Claim: DNN bias functions analogously to human "fast heuristics" in dual-process theory, enabling efficient but potentially error-prone early decisions.
- Mechanism: Early-stage determination resembles System 1 processing (fast, intuitive, bias-driven); later diffusion steps refine like System 2.
- Core assumption: The cognitive science parallel between human heuristics and DNN statistical biases is valid and informative.
- Evidence anchors: [abstract] drawing parallels to human decision-making; [section 1] dual-process theory may coincide with DNN inference.

## Foundational Learning

- **Concept: Diffusion Model Reverse Process**
  - Why needed: Understanding the step-by-step denoising trajectory is essential to grasp how "early determination" can be isolated and measured within an iterative generation process.
  - Quick check: Can you explain why diffusion models are better suited than single-pass feedforward networks for studying temporal decision dynamics?

- **Concept: CLIP Similarity Scoring**
  - Why needed: The entire measurement framework relies on CLIP image-text similarity to detect when generated outputs switch alignment from initial to altered prompts.
  - Quick check: Given S(x_ts, c_i) = 0.32 and S(x_ts, c_a) = 0.29, which prompt has more influence on the generated image at timestamp ts?

- **Concept: Attribute Bias and Diversity Entropy**
  - Why needed: The paper uses generation diversity (measured via prediction entropy) as a proxy for model bias; understanding this connection is critical for interpreting the timing results.
  - Quick check: Would you expect higher or lower entropy for an attribute that a model is strongly biased toward?

## Architecture Onboarding

- **Component map:**
  Text encoder (CLIP) -> U-Net denoiser -> Latent space -> VAE decoder

- **Critical path:**
  1. Start with random Gaussian noise x_0
  2. Denoise with initial prompt c_i until timestamp t_s
  3. At t_s, switch text condition from c_i to altered prompt c_a
  4. Continue denoising to final image
  5. Compute CLIP similarities S(final_image, c_i) and S(final_image, c_a)
  6. Sweep t_s from 0 to T to find switching point t′s where S(·, c_a) > S(·, c_i)

- **Design tradeoffs:**
  - Step count T: More steps = finer temporal resolution but higher compute
  - Attribute selection: Highly biased attributes (color) show early switching; diverse attributes (material) show later switching
  - Multi-module models (Karlo UnCLIP): Prior and decoder can be controlled separately, yielding different behavior

- **Failure signatures:**
  - Switching point consistently at T for all attributes → prompts may lack semantic distinctness
  - Switching point consistently near 0 for all attributes → measurement framework may not capture meaningful decision dynamics
  - High variance in switching points across random seeds → model may lack stable bias patterns

- **First 3 experiments:**
  1. Replicate color switching (e.g., "red apple" → "green apple") with SD1.4 to establish baseline switching point distribution
  2. Compare switching timing across four attribute types (color, pattern, shape, material) to verify bias-timing correlation
  3. Test human attribute pairs (gender, ethnicity) across professions with known bias levels from StableBias to examine social bias dynamics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the early determination phenomenon generalize to non-iterative (e.g., feedforward) or auto-regressive architectures like large language models?
- Basis in paper: [explicit] The authors explicitly ask, "How can our claim be extended to non-iterative or non-generative models?" in Section 5, noting that findings are grounded in diffusion models.
- Why unresolved: The study relies on the iterative nature of diffusion models to observe "switching points," a mechanism absent in single-pass networks.
- What evidence would resolve it: Probing methods for feedforward networks or intervention studies in LLMs to detect when outputs are effectively fixed.

### Open Question 2
- Question: What are the specific theoretical mechanisms linking training dynamics (e.g., simplicity bias, loss surfaces) to the timing of early determination?
- Basis in paper: [explicit] Section 6 identifies "a deeper understanding of the bias-related mechanism" as a future direction, suggesting a link to "simplicity bias and the loss surface."
- Why unresolved: The paper empirically demonstrates a correlation between bias and timing but does not establish the causal training dynamics that produce this behavior.
- What evidence would resolve it: Experiments analyzing the loss landscape geometry or intervention studies that manipulate shortcut learning during training.

### Open Question 3
- Question: Can "chain-of-thoughts" or progressive prompting strategies reliably shift determination later to mitigate bias?
- Basis in paper: [inferred] Section 6 proposes that mechanisms enforcing iterative processing could reduce reliance on shortcuts, and Appendix B.3 offers qualitative examples, but the effectiveness is not quantitatively validated.
- Why unresolved: The paper hypothesizes this mitigation strategy based on human cognitive analogies but provides only preliminary qualitative support.
- What evidence would resolve it: Quantitative benchmarks showing that progressive diffusion steps or CoT prompting significantly reduces bias metrics.

## Limitations
- The analogy to human dual-process decision-making is compelling but largely theoretical, with limited direct evidence linking human heuristics to DNN bias patterns
- The assumption that generation diversity (entropy) serves as a valid proxy for model bias remains indirect and needs further validation across different model families
- The findings are grounded in diffusion models, and the authors explicitly acknowledge uncertainty about how the claim extends to non-iterative or non-generative models

## Confidence
- **Confidence**: Medium - The claim that DNNs fix output properties early is well-supported by the systematic switching-point measurements, but the interpretation that this reflects "bias-driven" decision-making requires additional theoretical grounding
- **Confidence**: Medium - The correlation between attribute bias levels and switching timing is statistically supported, but the assumption that generation diversity serves as a valid proxy for model bias remains indirect
- **Confidence**: Low - The analogy to human dual-process decision-making is compelling but largely theoretical, with limited direct evidence linking human heuristics to DNN bias patterns

## Next Checks
1. **Cross-architecture validation**: Test the switching-point methodology on non-diffusion architectures (e.g., CLIP-based retrieval, language models with early exit capabilities) to determine if early determination is a general DNN phenomenon or specific to iterative generation processes.

2. **Bias quantification validation**: Develop independent bias measurements for each attribute type using established bias benchmarks, then correlate these with switching timing to verify that generation diversity is a reliable proxy for model bias strength.

3. **Temporal resolution study**: Systematically vary the diffusion step count (e.g., T=25, T=100) and analyze how switching point timing scales with temporal resolution to better understand whether the "early" determination is absolute or relative to the total inference duration.