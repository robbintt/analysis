---
ver: rpa2
title: Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning
arxiv_id: '2506.11166'
source_url: https://arxiv.org/abs/2506.11166
tags:
- diagnosis
- medical
- reasoning
- zero-shot
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addresses the challenge of zero-shot medical image diagnosis
  by enhancing large language model (LLM) reasoning capabilities through test-time
  scaling. The proposed framework processes medical images in two stages: first, a
  vision-language model generates multiple unbiased visual descriptions without direct
  diagnosis prompts; second, these descriptions are fed to an LLM, where test-time
  scaling aggregates multiple candidate outputs to produce a reliable diagnosis.'
---

# Test-Time-Scaling for Zero-Shot Diagnosis with Visual-Language Reasoning

## Quick Facts
- arXiv ID: 2506.11166
- Source URL: https://arxiv.org/abs/2506.11166
- Authors: Ji Young Byun; Young-Jin Park; Navid Azizan; Rama Chellappa
- Reference count: 27
- Primary result: Zero-shot medical image diagnosis framework using two-stage VLM/LLM reasoning with test-time scaling improves accuracy across radiology, ophthalmology, and histopathology modalities.

## Executive Summary
This work addresses the challenge of zero-shot medical image diagnosis by enhancing large language model (LLM) reasoning capabilities through test-time scaling. The proposed framework processes medical images in two stages: first, a vision-language model generates multiple unbiased visual descriptions without direct diagnosis prompts; second, these descriptions are fed to an LLM, where test-time scaling aggregates multiple candidate outputs to produce a reliable diagnosis. Evaluated across radiology, ophthalmology, and histopathology modalities, the method improves classification accuracy compared to baseline zero-shot approaches. Notably, performance follows a power law with increasing sample size during test-time scaling, and using a smaller LLM in the second stage (e.g., 3B parameters) achieves comparable results to larger models, demonstrating computational efficiency without sacrificing diagnostic accuracy.

## Method Summary
The method employs a two-stage framework for zero-shot medical image diagnosis. Stage 1 uses a vision-language model (Llama-3.2-11B-Vision-Instruct) to generate N visual descriptions from medical images using neutral, open-ended prompts that avoid diagnosis-related language. Stage 2 passes these descriptions to a text-only LLM (options include 1B, 3B, 8B, 11B, or Med42-v2-8B) which outputs a diagnosis. Test-time scaling aggregates N sampled outputs through majority voting to approximate marginalization over visual descriptions. The approach is evaluated on MedMNIST v2 datasets (PneumoniaMNIST, PathMNIST, RetinaMNIST) for binary classification using AUC and Average Precision metrics.

## Key Results
- Test-time scaling with N=16 samples achieves significant AUC improvements over single-sample baselines across all three medical imaging modalities
- A 3B parameter LLM in Stage 2 performs comparably to an 11B parameter model, demonstrating computational efficiency gains
- Power-law scaling relationship observed: diagnostic accuracy improves as N increases, following p(ŷ=1|x) ≈ (1/N) Σ I(a^(i)="\boxed{1}")
- Smaller VLMs (1B-4.5B) produce overly generic descriptions lacking medical specificity, while Llama-3.2-11B-Vision-Instruct captures clinically relevant features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separating visual feature extraction from diagnostic reasoning reduces bias and improves zero-shot accuracy.
- Mechanism: Stage 1 uses a VLM with neutral, open-ended prompts (e.g., "Describe visual features detected in the image") without diagnosis-related queries. This prevents the VLM from anchoring on disease-specific cues that may trigger hallucinations. Stage 2 then receives these unbiased descriptions and performs classification via a text-only LLM.
- Core assumption: The VLM can produce clinically relevant visual features without being explicitly guided toward the target disease.
- Evidence anchors: [abstract] "unbiased prompting in the first stage, improves the reliability of LLM-generated diagnoses and enhances classification accuracy"; [Page 7] "prompting the VLM directly with diagnosis-related questions that suggest a particular disease, may make the VLM to more likely hallucinate the answer and introduce bias (e.g., overdiagnosis)"

### Mechanism 2
- Claim: Test-time scaling via multiple sampled outputs approximates marginalization over visual descriptions, improving classification robustness.
- Mechanism: Rather than greedy decoding, the VLM samples N visual descriptions using temperature scaling. Each description v^(i) is passed to the LLM, which outputs a diagnosis. The final probability p(ŷ=1|x) is approximated as (1/N) Σ I(a^(i) = "\boxed{1}"). This aggregates over diverse visual interpretations.
- Core assumption: The sampled descriptions v^(i) ~ p(v|x) capture meaningful diversity, and the LLM's conditional p(ŷ|v) is reasonably calibrated.
- Evidence anchors: [Page 5] Equation (1) explicitly defines the marginalization approximation; [Page 6] "performance follows a power law: as N grows, the predictions become more robust"

### Mechanism 3
- Claim: A smaller LLM (e.g., 3B parameters) in Stage 2 can match larger models when given high-quality visual descriptions from Stage 1.
- Mechanism: The VLM (11B) handles the more computationally intensive visual understanding task. Stage 2 requires only reasoning over text descriptions—a task where smaller LLMs retain strong capabilities. This decoupling enables compute-efficient deployment.
- Core assumption: The visual descriptions from Stage 1 are sufficiently informative that the downstream LLM's task becomes primarily textual reasoning, not knowledge retrieval.
- Evidence anchors: [Page 7, Figure 3b] "A 3B model performs comparably to an 11B model, demonstrating the benefit of using the two-stage framework"

## Foundational Learning

- Concept: **Test-time scaling (inference-time compute)**
  - Why needed here: Core mechanism for improving zero-shot reliability by sampling and aggregating multiple outputs rather than single-pass decoding.
  - Quick check question: Can you explain why majority voting over N samples would fail if the model is systematically biased toward one class?

- Concept: **Zero-shot learning with VLMs**
  - Why needed here: The framework operates without task-specific fine-tuning; understanding how VLMs generalize to unseen medical tasks is essential.
  - Quick check question: What makes a VLM "zero-shot" versus requiring supervised adaptation?

- Concept: **Marginalization over latent variables**
  - Why needed here: The TTS aggregation in Equation (1) approximates integrating over p(v|x)—understanding this statistical framing clarifies why sampling helps.
  - Quick check question: If p(v|x) is concentrated on a single description, does increasing N still help? Why or why not?

## Architecture Onboarding

- Component map: Image → Stage 1 (VLM with neutral prompt) → N visual descriptions → Stage 2 (LLM with diagnosis prompt) → N diagnoses → Aggregation → Final prediction
- Critical path: 1) Image preprocessing to 224×224 (MedMNIST standard); 2) Stage 1 prompt design (must be diagnosis-agnostic); 3) Temperature-scaled sampling (N typically 4–16); 4) Stage 2 prompt with format enforcement ("\boxed{}" output); 5) Majority/aggregation logic for final prediction
- Design tradeoffs: Larger N improves accuracy but increases latency linearly; Smaller Stage 2 LLM saves compute but may struggle on complex multi-class tasks (current work focuses on binary); Dictated prompts in Stage 1 reduce sample efficiency but may improve single-sample performance
- Failure signatures: Single-sample (N=1) with neutral prompts yields low AUC (~0.50) on some datasets—description may not attend to disease-relevant features; Smaller VLMs (Phi-3.5-vision, Qwen2.5-VL-3B) produce overly generic descriptions lacking medical specificity; Dictated prompts cause overdiagnosis/hallucination (Figure 3a)
- First 3 experiments: 1) Baseline replication: Implement zero-shot QA and one-stage CoT QA baselines on PneumoniaMNIST with N=1 and N=16; verify AUC numbers match Table 1; 2) Ablation on N: Sweep N ∈ {1, 2, 4, 8, 16} for both baseline TTS and the proposed two-stage method; plot power-law scaling; 3) Stage 2 model swap: Replace the 11B Stage 2 LLM with 1B, 3B, and 8B variants; compare AUC and latency to quantify compute-accuracy tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed binary test-time scaling formulation be successfully extended to multi-class medical diagnosis settings using one-vs.-all (OvA) or one-vs.-one (OvO) strategies?
- Basis in paper: [explicit] The authors state in Section 2.1 that for multi-class tasks, "this approach can be extended by using one-vs.-all (OvA) or one-vs.-one (OvO) strategies... which we leave for future work."
- Why unresolved: The current framework and theoretical approximation of p(ŷ|x) (Eq. 1) are derived and validated only for binary classification tasks.
- What evidence would resolve it: An evaluation of the framework on multi-class medical imaging datasets (e.g., blood cell classification) demonstrating that TTS improves accuracy over single-sample baselines.

### Open Question 2
- Question: How can smaller, well-distilled vision-language models (VLMs) be optimized to capture domain-specific visual nuances effectively in the description extraction stage?
- Basis in paper: [explicit] The authors note in Section 3 that smaller VLMs (e.g., 1B–4.5B parameters) failed in preliminary experiments, generating "overly generic outputs," and highlight the "need for future work on exploring smaller yet well-distilled models."
- Why unresolved: There is a trade-off between the computational efficiency of smaller VLMs and their ability to provide the detailed visual descriptions necessary for the second-stage LLM to reason accurately.
- What evidence would resolve it: The successful implementation of a distilled VLM (under 5B parameters) that achieves visual description quality comparable to Llama-3.2-11B-Vision on medical feature extraction tasks.

### Open Question 3
- Question: Can sophisticated, medical-domain-specific reward models or verifiers improve the aggregation of candidate outputs compared to the simple test-time scaling strategies currently employed?
- Basis in paper: [explicit] In the Conclusion, the authors suggest that "more sophisticated reward-model-based approaches could offer promising directions, particularly as medical-domain-specific resources become more readily available."
- Why unresolved: The current study relies on simple aggregation (implied averaging/voting) due to the scarcity of labeled data required to train verifiers.
- What evidence would resolve it: A comparative study showing that a medically-trained verifier selects superior reasoning chains or diagnoses compared to the standard aggregation methods used in this work.

## Limitations

- The framework is evaluated only on binary classification tasks across three imaging modalities, leaving unclear how it would perform on multi-class or multi-label scenarios.
- The reliance on specific VLM capabilities means the approach may fail with smaller or less capable vision models, as shown by the poor performance of Phi-3.5-vision-instruct and similar models.
- The computational overhead of sampling N descriptions scales linearly, which may limit practical deployment despite the compute savings from using smaller LLMs in Stage 2.

## Confidence

- **High confidence**: The power-law relationship between test-time scaling sample size and diagnostic accuracy is well-supported by experimental evidence and aligns with established TTS literature.
- **Medium confidence**: The claim that neutral prompting prevents VLM bias is supported by controlled experiments showing dictated prompts cause overdiagnosis, though the mechanism could benefit from more detailed analysis of hallucination triggers.
- **Medium confidence**: The computational efficiency claim (smaller LLM matching larger models) is demonstrated but limited to binary tasks; performance on complex multi-class problems remains untested.

## Next Checks

1. **Multi-class extension**: Implement the framework on a multi-class medical imaging dataset (e.g., CheXpert with multiple pathologies) to test whether Stage 2's text-only reasoning can handle increased classification complexity without VLM fine-tuning.

2. **VLM capability boundary**: Systematically test the framework with VLMs of varying parameter counts and training data compositions to identify the minimum viable VLM size that maintains diagnostic accuracy, and analyze which visual features are lost as model capacity decreases.

3. **Real-world deployment simulation**: Create a domain-shifted test set by applying synthetic artifacts (noise, compression, different acquisition protocols) to the validation data, then measure how test-time scaling robustness degrades compared to baseline approaches.