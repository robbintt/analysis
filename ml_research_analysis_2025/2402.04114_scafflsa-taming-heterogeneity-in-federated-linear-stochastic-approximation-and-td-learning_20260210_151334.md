---
ver: rpa2
title: 'SCAFFLSA: Taming Heterogeneity in Federated Linear Stochastic Approximation
  and TD Learning'
arxiv_id: '2402.04114'
source_url: https://arxiv.org/abs/2402.04114
tags:
- fedlsa
- local
- number
- federated
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes federated linear stochastic approximation (FedLSA)
  algorithms, focusing on how heterogeneity affects communication and sample complexity.
  It shows that FedLSA has polynomial communication complexity in terms of desired
  accuracy, due to bias from local training.
---

# SCAFFLSA: Taming Heterogeneity in Federated Linear Stochastic Approximation and TD Learning

## Quick Facts
- arXiv ID: 2402.04114
- Source URL: https://arxiv.org/abs/2402.04114
- Reference count: 40
- Primary result: SCAFFLSA achieves logarithmic communication complexity and preserves linear speed-up in federated linear stochastic approximation

## Executive Summary
This paper addresses the challenge of heterogeneity in federated learning when solving linear systems via stochastic approximation, particularly for temporal difference (TD) learning. Standard federated approaches suffer from a bias due to client drift when local updates are performed on heterogeneous data. The authors introduce SCAFFLSA, a novel algorithm using control variates to correct for this drift, enabling logarithmic communication complexity and preserving linear speed-up with respect to the number of agents—a property often lost in prior methods.

## Method Summary
SCAFFLSA modifies the standard FedLSA algorithm by introducing control variates to correct for client drift caused by heterogeneous data. Each client maintains a local control variate that estimates the difference between its local oracle and the global objective. The global server aggregates parameters via simple averaging, while clients perform local LSA updates using their data and stored control variates. After communication, clients update their control variates using the gap between their local endpoint and the new global average. This mechanism eliminates the solution bias found in standard FedLSA, allowing for larger local steps without accumulating bias and achieving logarithmic communication complexity.

## Key Results
- SCAFFLSA achieves logarithmic communication complexity O(log(1/ε)) compared to polynomial O(1/ε) for standard FedLSA
- The algorithm preserves linear speed-up, with sample complexity scaling as 1/N with respect to the number of agents
- Applied to federated TD learning, SCAFFLSA demonstrates improved communication efficiency and convergence while maintaining the linear speed-up property
- Numerical experiments confirm theoretical findings, showing SCAFFLSA outperforms FedLSA in heterogeneous settings by eliminating bias

## Why This Works (Mechanism)

### Mechanism 1: Control Variates for Drift Correction
SCAFFLSA eliminates the solution bias caused by heterogeneous local training by maintaining control variates that dynamically cancel out client drift. Each client c maintains a local control variate ξ_c that estimates the difference between its local oracle and the global objective. By subtracting this term from the local update equation, the algorithm prevents agents from optimizing towards their local solutions, enabling convergence to the true global optimum.

### Mechanism 2: Logarithmic Communication Complexity
The algorithm achieves logarithmic communication complexity by removing the heterogeneity bias term from the convergence bound. In standard FedLSA, the bias grows with the number of local steps H, forcing frequent communication to control error. SCAFFLSA's control variates eliminate this bias, allowing H to be set much larger without penalty, drastically reducing the total communication rounds required.

### Mechanism 3: Linear Speed-up via Independent Fluctuation Analysis
SCAFFLSA preserves linear speed-up by carefully analyzing the propagation of stochastic noise across agents. The theoretical analysis decomposes error into transient and fluctuation terms, proving that stochastic noise scales inversely with the number of agents N because the agents' samples are independent. This is achieved through a novel analysis tracking parameter and control variate fluctuations using virtual parameters.

## Foundational Learning

- **Concept: Linear Stochastic Approximation (LSA)**
  - Why needed here: The paper solves a system of linear equations Āθ = b̄ where matrices and vectors are accessed via stochastic oracles, which is the mathematical core of TD learning
  - Quick check question: Can you explain why solving Āθ = b̄ is different from minimizing a convex loss function f(θ)? (Hint: Think about the role of the matrix inverse vs. gradient descent)

- **Concept: Temporal Difference (TD) Learning**
  - Why needed here: The paper instantiates its theory on Federated TD(0) learning, where the Bellman equation maps to the LSA framework
  - Quick check question: In the TD(0) update θ ← θ + η[r + γV̂(s') - V̂(s)]φ(s), can you identify which part corresponds to the matrix A and which to the vector b in the LSA formulation?

- **Concept: Client Drift in Federated Learning**
  - Why needed here: This is the primary failure mode SCAFFLSA fixes—local updates move the model towards local optima, causing the global model to stagnate at a biased point
  - Quick check question: If Agent 1 has data only from class "A" and Agent 2 from class "B", what happens to a locally trained model's accuracy on class "A" after global averaging, compared to a model trained on the pooled data?

## Architecture Onboarding

- **Component map:** Global Server -> Clients (c=1..N) -> Local Solver -> Variate Updater
- **Critical path:** Server broadcasts θ_t → Client c performs H local LSA steps with ξ_c → Client sends θ^c_{t,H} → Server averages to get θ_{t+1} → Client updates ξ_c using gap between local endpoint and global average
- **Design tradeoffs:** Larger H reduces communication rounds logarithmically but increases computation per round; SCAFFLSA allows much larger H than FedLSA without bias penalty. Learning rate η must scale with H and N.
- **Failure signatures:** FedLSA plateaus at high error due to heterogeneity bias; SCAFFLSA may diverge if η is too large relative to data spectrum or if control variates are not updated frequently enough
- **First 3 experiments:** 1) Heterogeneity stress test: Run FedLSA vs. SCAFFLSA on toy linear system with significant differences across clients; 2) Speed-up verification: Fix total sample budget, vary N, plot final error vs N; 3) TD(0) Garnet environment: Replicate Section 6 on heterogeneous RL environment

## Open Questions the Paper Calls Out

### Open Question 1
Can the linear speed-up and logarithmic communication complexity be extended to non-linear function approximation settings, such as neural networks? The current analysis relies heavily on linear update structures and does not address non-asymptotic behavior in non-convex extensions.

### Open Question 2
Is it possible to achieve theoretical guarantees under Markovian noise without requiring the subsampling mechanism? The current analysis requires skipping observations to decouple dependencies, creating a gap between theoretical requirements and practical continuous data usage.

### Open Question 3
Can the strong stability assumption (A3) on the contraction of random matrix products be relaxed to only require the mean system matrices Ā_c to be Hurwitz? Verifying A3 can be difficult in practice compared to checking eigenvalues of the mean matrix.

## Limitations
- The analysis assumes bounded stochastic oracles, Hurwitz matrices for stability, and non-degenerate spectral properties, which may not hold in all practical scenarios
- The claim of linear speed-up is contingent on independent sampling; correlated Markovian noise could eliminate this benefit
- The analysis focuses on linear convergence and does not address non-asymptotic behavior in non-convex extensions or adaptive learning rate scenarios

## Confidence
- **High Confidence:** The mechanism of control variates correcting client drift is well-established and directly supported by algorithm description and theoretical bounds
- **Medium Confidence:** The logarithmic communication complexity and preservation of linear speed-up are rigorously proven under stated assumptions, but robustness to violations is untested
- **Medium Confidence:** Empirical validation demonstrates effectiveness, but specific hyperparameter choices are not fully specified, introducing potential reproducibility concerns

## Next Checks
1. **Stress Test Assumptions:** Implement FedLSA and SCAFFLSA on a linear system where Assumption A3 (Hurwitz matrices) is violated to measure divergence or instability
2. **Dependent Sampling Scenario:** Modify the TD(0) experiment to use correlated Markovian noise without proper subsampling to observe if linear speed-up disappears
3. **Initialization Sensitivity:** Vary initialization distance from true solution θ* beyond the "neighborhood" to determine threshold at which convergence degrades or fails