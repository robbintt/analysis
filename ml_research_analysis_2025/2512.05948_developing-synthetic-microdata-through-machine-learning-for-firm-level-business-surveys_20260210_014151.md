---
ver: rpa2
title: Developing synthetic microdata through machine learning for firm-level business
  surveys
arxiv_id: '2512.05948'
source_url: https://arxiv.org/abs/2512.05948
tags:
- data
- synthetic
- business
- pums
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study demonstrates how synthetic microdata can be generated\
  \ using machine learning for firm-level business surveys while preserving privacy\
  \ and statistical fidelity. The approach uses CART-based synthesizers\u2014specifically\
  \ CenSyn and synthpop\u2014to model the distribution of sensitive survey data and\
  \ generate synthetic datasets that maintain the original data's statistical properties\
  \ without exposing individual records."
---

# Developing synthetic microdata through machine learning for firm-level business surveys

## Quick Facts
- arXiv ID: 2512.05948
- Source URL: https://arxiv.org/abs/2512.05948
- Authors: Jorge Cisneros; Timothy Wojan; Matthew Williams; Jennifer Ozawa; Robert Chew; Kimberly Janda; Timothy Navarro; Michael Floyd; Christine Task; Damon Streat
- Reference count: 20
- One-line primary result: Machine learning can generate synthetic firm-level microdata that preserves statistical properties while protecting privacy, with synthetic data producing qualitatively similar econometric results to restricted-use data.

## Executive Summary
This study demonstrates how synthetic microdata can be generated using machine learning for firm-level business surveys while preserving privacy and statistical fidelity. The approach uses CART-based synthesizers—specifically CenSyn and synthpop—to model the distribution of sensitive survey data and generate synthetic datasets that maintain the original data's statistical properties without exposing individual records. Quality evaluation was performed using the 2007 Survey of Business Owners public-use file, treating it as the "ground truth."

The synthetic datasets were validated through multiple metrics including k-marginal scores (992 achieved vs. baseline 994), principal component analysis showing strong alignment with original data distributions, and econometric replication of a high-impact study on immigrant-owned firm transnational activities. Results showed qualitative consistency in odds ratios and coefficient estimates with most confidence intervals overlapping, though some quantitative differences emerged for rare events and multi-variable interactions. The findings suggest synthetic data can serve as a viable alternative to restricted-use data for exploratory and specification-testing research.

## Method Summary
The study employed CART-based sequential synthesis using both a proprietary system (CenSyn) and the open-source synthpop R package to generate synthetic firm-level microdata from the 2007 Survey of Business Owners. The synthesis process models each variable's distribution conditionally on previously synthesized variables using decision trees, capturing hierarchical decision rules that represent feature correlations. Variable synthesis order was informed by domain expertise, and tree hyperparameters were tuned to balance fidelity against overfitting. Quality evaluation combined distributional metrics (k-marginal scores and PCA visualization) with econometric replication of published analyses to assess utility for research purposes.

## Key Results
- Achieved k-marginal scores of 992 (baseline: 994) for both CenSyn and synthpop synthetic datasets
- Principal component analysis showed strong alignment between synthetic and original data distributions across top five principal components, capturing approximately 25% of total variance
- Synthetic data successfully replicated qualitative findings from econometric analysis on immigrant-owned firm transnational activities, with odds ratios and coefficient estimates showing substantial overlap in confidence intervals

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CART-based sequential synthesis preserves marginal and conditional distributions of firm-level survey data.
- Mechanism: Decision trees recursively partition the data into low-entropy, self-similar groups with respect to each target variable, learning hierarchical decision rules that capture feature correlations. Each variable is synthesized conditionally on previously synthesized variables in sequence.
- Core assumption: The joint distribution of firm characteristics can be approximated by decomposing it into a product of conditional distributions learnable via tree-based models.
- Evidence anchors:
  - [section 4]: "CART-based synthesizers consistently exhibit strong performance on tabular datasets even when compared to complex deep learning models, such as variational autoencoders (VAEs) and generative adversarial networks (GANs)."
  - [section 6]: K-marginal scores of 992 achieved for both CenSyn and synthpop datasets (baseline: 994).
  - [corpus]: Related work on tabular synthetic data generation (arXiv:2504.16506) surveys similar approaches, though direct comparison is limited.
- Break condition: Fails when multi-variable interactions involve rare events (<1% prevalence) or when synthesizing highly skewed continuous variables like revenue with extreme outliers.

### Mechanism 2
- Claim: Privacy preservation emerges from generating records that match statistical distributions without copying actual respondent data.
- Mechanism: The synthesizer learns probability distributions and decision boundaries rather than memorizing records. Synthetic firms are sampled from learned distributions, ensuring no one-to-one correspondence with real businesses.
- Core assumption: Re-identification attacks cannot link synthetic records back to original respondents even when marginal distributions match closely.
- Evidence anchors:
  - [section 4]: "Provided with proper tuning of tree parameters, the synthetic firms cannot be used for learning about specific respondents in the restricted dataset."
  - [section 3]: Discusses how traditional de-identification fails for business data but positions synthetic data as alternative—no formal privacy guarantees stated.
  - [corpus]: No strong corpus evidence for formal privacy proofs; paper frames this as empirical/desirable property.
- Break condition: Privacy claims are not formally proven; differential privacy guarantees are not provided. Risk remains when combining synthesized variables with external public data.

### Mechanism 3
- Claim: Multi-metric validation (distributional + econometric replication) establishes utility for exploratory research.
- Mechanism: K-marginal scores quantify distributional overlap; PCA visualization confirms structural alignment; econometric replication tests whether coefficient signs, significance, and confidence intervals are preserved.
- Core assumption: If synthetic data produces qualitatively similar econometric results (signs, overlapping CIs), it is suitable for specification testing and pre-analysis planning.
- Evidence anchors:
  - [section 7]: "Qualitatively, the results from all three datasets are identical. Immigrant ownership is positively associated with all three transnational activities in all three datasets."
  - [table 3]: 95% confidence intervals for odds ratios show substantial overlap between original and synthetic datasets for most variables.
  - [section 7]: Quantitative differences emerged—"The immigrant CenSyn estimates are statistically lower than the 2007 SBO estimates in the International Branch and Exporting equations."
  - [corpus]: "Guided Persona-based AI Surveys" (arXiv:2501.13955) validates synthetic survey data through preference replication, offering parallel validation approach.
- Break condition: Magnitude-sensitive policy analysis may fail; coefficient estimates for common predictors (e.g., Transnational on Sales) show statistically different magnitudes between synthetic and original data.

## Foundational Learning

- Concept: **Classification and Regression Trees (CART)**
  - Why needed here: Core synthesis engine; understanding recursive partitioning and entropy reduction explains how conditional dependencies are captured.
  - Quick check question: Can you explain how a decision tree determines which feature and split point to use when partitioning data at each node?

- Concept: **K-marginal Distribution Comparison**
  - Why needed here: Primary quality metric; understanding how marginal distributions are sampled and compared enables interpretation of 992 vs. 994 baseline scores.
  - Quick check question: What does a k-marginal score of 992/1000 indicate about the relationship between synthetic and original data distributions?

- Concept: **Sequential Synthesis (Chain Rule Decomposition)**
  - Why needed here: Explains why variable ordering matters and how conditional dependencies are built iteratively rather than jointly.
  - Quick check question: If synthesizing variable A before variable B vs. B before A, how might the resulting joint distribution differ?

## Architecture Onboarding

- Component map:
  Pre-processor -> Synthesizer (CenSyn/synthpop) -> Evaluator Suite -> Post-processor

- Critical path:
  1. Configure variable synthesis order (domain expertise informs which variables should be synthesized first)
  2. Tune tree hyperparameters (depth, minimum leaf size) to balance fidelity vs. overfitting
  3. Run synthesis → evaluate with k-marginal → identify worst-performing features
  4. Iterate with stakeholder feedback on which relationships are analytically critical
  5. Validate with econometric replication on known published results

- Design tradeoffs:
  - **Rare events vs. privacy**: Tighter clustering of rare values improves fidelity but may increase re-identification risk
  - **Geographic detail vs. anonymity**: Fine-grained geography (county-level) with detailed industry (4-6 digit NAICS) creates high re-identification risk; may require tiered release strategy
  - **Sample size vs. verisimilitude**: Subsetting synthetic data for specific analyses (e.g., first-year firms only) reduces fidelity—paper notes sample reduced by 10x led to failed replication

- Failure signatures:
  - K-marginal score <970 indicates poor distributional match
  - PCA plots showing divergent dispersion patterns between original and synthetic data
  - Econometric coefficient signs differ between synthetic and original; confidence intervals do not overlap
  - Multi-variable conditional distributions (e.g., female-black-owned firms in Texas) show substantial count mismatches (Figure 4)

- First 3 experiments:
  1. **Baseline replication**: Synthesize SBO 2007 PUMS subset (54 features, 1M records), compute k-marginal score, and compare PCA plots against original to establish distributional fidelity baseline.
  2. **Variable ordering sensitivity**: Run synthesis with two different variable orderings (geography-first vs. firm-characteristics-first) and compare k-marginal scores and worst-performing features to identify ordering effects.
  3. **Rare event stress test**: Isolate firms with rare characteristic combinations (e.g., <2% prevalence such as international branch ownership) and compare coefficient estimates and confidence intervals between synthetic and original data using logistic regression.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal level of geographic detail for synthetic business microdata that maximizes analytical utility while maintaining acceptable re-identification risk?
- Basis in paper: [explicit] The authors state: "Determining the optimal level of geographic detail for data release is essential, so we will explore factors such as urban-rural distinctions via RUCC and MSAs to provide meaningful insights into regional trends and patterns."
- Why unresolved: Balancing geographic granularity with privacy protection for business data involves complex trade-offs between identifying individual firms in sparse geographic-industry combinations and providing useful regional analysis.
- What evidence would resolve it: A systematic re-identification risk analysis across multiple geographic detail levels, combined with utility metrics for common regional economic analyses.

### Open Question 2
- Question: How does synthetic data verisimilitude degrade when analyses are restricted to small subsets of the population, such as R&D-performing microbusinesses?
- Basis in paper: [explicit] The authors note that replication of first-year firm failure analysis failed and state: "Limiting analysis to a small subset of a synthetic dataset may reduce verisimilitude available in analysis using the full sample. This possibility will be a topic of future research."
- Why unresolved: The current evaluation focused on full-sample analyses; small subpopulations may have distributional characteristics that CART-based synthesizers fail to capture adequately.
- What evidence would resolve it: Targeted replication studies of published ABS analyses focusing on rare subpopulations, with comparison of coefficient estimates and confidence intervals against restricted-use data.

### Open Question 3
- Question: Can releasing multiple synthetic PUMS products with different feature-detail trade-offs serve diverse analytical needs while managing cumulative re-identification risk?
- Basis in paper: [explicit] The authors propose to "explore the possibility of releasing several PUMS of different levels of details for different needs" where "one PUMS carries 2-digit NAICS but county-level information, while a second PUMS dives into 6-digit NAICS but only at a clustered state level."
- Why unresolved: Multiple releases could enable linkage attacks across datasets, and the cumulative privacy implications of tiered synthetic products remain unquantified.
- What evidence would resolve it: Formal privacy analysis of cross-dataset linkage risks and user studies evaluating whether tiered products adequately serve different research communities.

## Limitations
- Privacy preservation claims are not formally proven with differential privacy guarantees, and re-identification risk remains when combining synthetic data with external public sources
- Method shows degraded performance for rare events and multi-variable interactions involving small subpopulations, with some quantitative differences in coefficient estimates
- Proprietary nature of CenSyn limits reproducibility, and specific hyperparameter settings and variable ordering are not fully detailed

## Confidence
- High confidence: Distributional fidelity (k-marginal scores, PCA alignment) and basic econometric replication (sign preservation, CI overlap)
- Medium confidence: Privacy preservation claims and suitability for magnitude-sensitive policy analysis
- Low confidence: Performance on rare event interactions and multi-variable conditional distributions involving small subpopulations

## Next Checks
1. Run a formal differential privacy analysis to quantify re-identification risk when synthetic data is combined with public business registries
2. Conduct sensitivity analysis across multiple variable ordering schemes to identify systematic biases in conditional distribution capture
3. Test performance on a different business survey (e.g., Business Dynamics Statistics) with different sampling frames and variable distributions