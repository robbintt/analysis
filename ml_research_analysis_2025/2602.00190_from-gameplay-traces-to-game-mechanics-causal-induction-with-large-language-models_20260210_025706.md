---
ver: rpa2
title: 'From Gameplay Traces to Game Mechanics: Causal Induction with Large Language
  Models'
arxiv_id: '2602.00190'
source_url: https://arxiv.org/abs/2602.00190
tags:
- game
- wall
- vgdl
- causal
- games
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the problem of causal induction in game environments
  by investigating whether large language models can reverse-engineer game mechanics
  from gameplay traces. The authors focus on the GVGAI framework, treating its VGDL
  specification as a structural causal model, and compare two approaches: direct code
  generation and a two-stage method that first infers a causal graph before generating
  VGDL.'
---

# From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models

## Quick Facts
- arXiv ID: 2602.00190
- Source URL: https://arxiv.org/abs/2602.00190
- Authors: Mohit Jiwatode; Alexander Dockhorn; Bodo Rosenhahn
- Reference count: 40
- Primary result: SCM-guided LLM approach achieves up to 81% preference over direct generation in blind evaluations for reverse-engineering game mechanics from gameplay traces

## Executive Summary
This paper investigates whether large language models can reverse-engineer game mechanics from gameplay traces using the GVGAI framework. The authors propose a two-stage approach that first infers a structural causal model (SCM) from gameplay observations, then translates it into VGDL code. Compared to direct code generation, the SCM-based method significantly improves logical consistency and performance, particularly in low-information settings. Using a benchmark of nine semantically diverse games, the approach achieves strong results in both game identification and VGDL synthesis tasks, with blind evaluations showing up to 81% preference for SCM outputs.

## Method Summary
The approach uses a dual-stream generation system where observations are processed either directly into VGDL (Stream A) or through an intermediate SCM representation (Stream B). The SCM blueprint defines a structured JSON format separating game design, dynamics, and mechanics. Five context levels provide varying amounts of information from raw observations to partial code. The method is evaluated using Qwen3-8B and QwQ-32B models across nine benchmark games selected via semantic clustering from the GVGAI corpus. Evaluation includes game identification accuracy, code similarity metrics, and LLM-based blind preference ranking.

## Key Results
- SCM-guided generation outperforms direct synthesis, achieving up to 81% preference in blind evaluations
- The advantage is most pronounced in low-information settings (Levels 0-3) and diminishes at high context levels
- Larger reasoning-optimized models (QwQ-32B) show better performance than smaller models (Qwen3-8B)
- The approach successfully identifies games and generates mechanically consistent rules, with strong performance in inductive settings

## Why This Works (Mechanism)

### Mechanism 1: SCM-Mediated Decomposition (Neurosymbolic Grounding)
The intermediate SCM representation forces the model to resolve causal ambiguities before generating syntax, acting as a "System 2" constraint that reduces hallucinations. By separating static design, dynamic state, and observations into a structured JSON format, the model must first establish logical relationships before committing to code.

### Mechanism 2: Hierarchical Context Induction
The framework's five context levels create varying information conditions. The SCM approach excels when information is scarce (Levels 0-3) by providing necessary scaffolding, but may introduce noise when code context is nearly complete (Level 4), where direct completion becomes more efficient.

### Mechanism 3: Self-Conditioned Evaluation for Memorization Control
The Destructive prompt variant strips external context, exposing the gap between model memorization and causal reasoning. A significant performance drop when context is removed indicates reliance on memorization rather than genuine understanding of causal laws.

## Foundational Learning

- **Structural Causal Models (SCMs):** The core representation mapping game states, initial conditions, and rules into a graph structure. Quick check: Can you distinguish between a node representing a static entity type (Design Layer) versus a dynamic state variable (Dynamics Layer) in the SCM blueprint?

- **Video Game Description Language (VGDL):** The target output format with four modules (SpriteSet, LevelMapping, InteractionSet, TerminationSet). Quick check: Which VGDL section encodes the collision physics (e.g., "Avatar > Wall: stepBack")?

- **Semantic Clustering (S-BERT + K-Means):** The method used to construct the benchmark by selecting representative games. Quick check: Why did the authors choose k=9 clusters based on the Silhouette Score analysis?

## Architecture Onboarding

- **Component map:** Observations → Context Level Selection → SCM JSON Generation → VGDL Compilation → Evaluator
- **Critical path:** Observations → Context Level Selection → **SCM JSON Generation** (The key bottleneck) → VGDL Compilation
- **Design tradeoffs:** Stream B yields higher logical consistency but adds latency and token cost. Use Stream A for speed/syntax-heavy tasks (Level 4); use Stream B for reasoning-heavy tasks (Levels 0-3). Larger reasoning models handle direct synthesis better than smaller models.
- **Failure signatures:** Portals failure due to high token count causing generation collapse (90% tie rate). Level 4 reversal where SCM overhead introduces noise for smaller models. Hallucinated interactions producing logically inconsistent rules.
- **First 3 experiments:** 1) Zero-shot sanity check comparing Stream A vs. Stream B on Boulderchase at Level 0. 2) Memorization probe using Destructive prompt to verify model doesn't already know GVGAI games. 3) Completion stress test at Level 4 to observe model-specific performance differences.

## Open Questions the Paper Calls Out

- Can formal evaluation metrics be developed that accurately quantify the causal fidelity of generated game rules, moving beyond syntactic similarity and LLM preference?
- Does an iterative "belief SCM" framework, where a model updates its causal graph sequentially as new observations arrive, outperform the batch-processing approach used in this study?
- Does the performance advantage of the SCM-guided pipeline diminish or disappear as the parameter count and reasoning capabilities of the underlying Large Language Model increase?

## Limitations

- The 81% preference rate comes from a small sample of 9 games, limiting generalizability to broader game types
- Strong results depend on QwQ-32B, a reasoning-optimized model requiring substantial computational resources
- The SCM approach adds complexity through additional prompt engineering and a "compiler" step with only partial specification
- Portals failure case demonstrates the pipeline can fail when observation length overwhelms token limits

## Confidence

- **High Confidence:** SCM approach superiority in low-information settings (Levels 0-3) is well-supported by multiple judges and consistent across context levels
- **Medium Confidence:** The claim that SCM "forces causal disambiguation" relies on LLM's ability to populate intermediate representation correctly
- **Low Confidence:** Generalization to entirely new game types or larger corpora is not empirically tested; performance drop in Level 4 contexts for smaller models suggests brittleness

## Next Checks

1. Apply the SCM pipeline to a non-GVGAI game dataset (e.g., arcade games or puzzle games) to evaluate cross-domain generalization and measure if the SCM advantage persists
2. Systematically test the approach across a broader range of model sizes and types to map boundary conditions where SCM becomes beneficial versus detrimental
3. Conduct an ablation study removing or simplifying the intermediate SCM step while keeping all other conditions constant to quantify its exact contribution