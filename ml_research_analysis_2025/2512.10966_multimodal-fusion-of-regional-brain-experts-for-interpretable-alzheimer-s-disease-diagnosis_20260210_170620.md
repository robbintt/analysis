---
ver: rpa2
title: Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease
  Diagnosis
arxiv_id: '2512.10966'
source_url: https://arxiv.org/abs/2512.10966
tags:
- disease
- alzheimer
- mref-ad
- fusion
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces MREF-AD, a Multimodal Regional Expert Fusion
  model for Alzheimer's disease (AD) diagnosis that integrates amyloid PET and MRI
  data through a hierarchical Mixture-of-Experts (MoE) framework. The method decomposes
  each modality into 14 meso-scale brain region experts, employing two-level gating
  networks to learn subject-specific fusion weights.
---

# Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease Diagnosis

## Quick Facts
- **arXiv ID**: 2512.10966
- **Source URL**: https://arxiv.org/abs/2512.10966
- **Reference count**: 0
- **Primary result**: MREF-AD achieves AUROC 0.803, accuracy 0.632, F1 0.628 on ADNI data

## Executive Summary
This paper introduces MREF-AD, a hierarchical Mixture-of-Experts (MoE) framework for Alzheimer's disease diagnosis that fuses amyloid PET and MRI data through subject-specific regional expert weighting. The model decomposes each modality into 14 meso-scale brain region experts and employs two-level gating networks to learn cross-modality and within-modality fusion weights. Evaluated on 1,530 ADNI participants, MREF-AD achieves state-of-the-art performance while providing interpretable insights into regional biomarker relevance, identifying temporal and subcortical regions as key contributors. The approach demonstrates robust performance even with sparse expert activation and shows potential for generalization to other neurological disorders.

## Method Summary
MREF-AD processes 14 regional experts per modality (amyloid PET and MRI) plus demographics through dedicated three-layer MLPs. A two-level hierarchical gating network first allocates weights across modalities (PET, MRI, demographics) then distributes weight within each modality's regional experts. The final expert weight equals the product of modality gate and region gate. The model uses cross-entropy loss with class-balanced weights plus entropy-based sparsity and diversity regularization. Training employs AdamW optimizer with 1e-3 learning rate and 1e-4 weight decay, up to 40 epochs with early stopping. Inputs are z-score normalized per training fold in 10-fold cross-validation.

## Key Results
- Achieves AUROC of 0.803, accuracy of 0.632, and F1-score of 0.628 on ADNI data
- Outperforms concatenation-based baselines and traditional classifiers across all metrics
- Hierarchical gating (0.632 accuracy) significantly outperforms modality-only (0.618) and region-only (0.618) single-level variants
- Maintains performance with sparse expert activation: Top-5 (0.801 AUROC) and Top-3 (0.801 AUROC) match full model (0.803)
- Identifies temporal and subcortical regions as having highest diagnostic contributions in both modalities

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical two-level gating captures both cross-modality and within-modality heterogeneity for subject-specific fusion. A modality-level gate first allocates weights across MRI, PET, and demographics; a region-level gate then distributes weight within each modality's 14 regional experts. Final expert weight = modality gate × region gate product. Core assumption: disease-relevant signals vary across both modalities and brain regions in a subject-dependent manner. Evidence: Table 3 shows hierarchical gating (0.632 accuracy) outperforms modality-only (0.618) and region-only (0.618) single-level variants.

### Mechanism 2
Mesoscale regional expert decomposition enables interpretable, biologically meaningful biomarker attribution. Each expert processes region-specific features (SUVR for PET, volumes for MRI) through a 3-layer MLP, producing logits that are gated and fused. Aggregating gating weights across subjects reveals average regional importance. Core assumption: regional parcellation aligns with disease-relevant spatial patterns; 14-region granularity captures meaningful variation. Evidence: Figure 2 shows elevated contributions from temporal/subcortical regions, consistent with established AD imaging findings.

### Mechanism 3
Sparse expert activation (top-k gating) maintains diagnostic performance while improving interpretability. Top-k gating restricts active experts to k highest-weighted regions, forcing selective fusion. Regularization includes entropy penalty on gating weights and diversity penalty on expert outputs. Core assumption: a small subset of regions drives most diagnostic signal; redundancy exists across experts. Evidence: Table 3 shows Top-5 (0.801 AUROC) and Top-3 (0.801 AUROC) match full model (0.803); Top-1 only drops to 0.794.

## Foundational Learning

- **Concept: Mixture-of-Experts (MoE) Framework**
  - Why needed here: Core architecture; must understand expert-gating interaction before modifying the system
  - Quick check: Can you explain how the gating network produces subject-specific weights and how they combine expert outputs?

- **Concept: Brain Parcellation and Regional Biomarkers**
  - Why needed here: Defines expert boundaries; 14 mesoscale regions from FreeSurfer atlas determine what each expert "sees"
  - Quick check: What types of features would a "Temporal" expert receive for MRI vs. PET modalities?

- **Concept: Multimodal Neuroimaging Complementarity**
  - Why needed here: Motivates fusion; PET captures amyloid deposition, MRI captures atrophy—distinct but related processes
  - Quick check: Why would simple concatenation fail to capture subject-level variation in modality relevance?

## Architecture Onboarding

- **Component map**: Input features → 29 experts (14 PET + 14 MRI + 1 demographics) → Modality gate → Region gates → Combined weights → Weighted sum of expert logits → Softmax prediction

- **Critical path**:
  1. Extract regional features (SUVR/volumes) via FreeSurfer parcellation
  2. Pass each region's features through its dedicated expert MLP
  3. Compute hierarchical gates from concatenated input features
  4. Fuse expert logits using gate-derived weights
  5. Apply cross-entropy loss with class balancing + entropy/diversity regularization

- **Design tradeoffs**:
  - Expert capacity: Lightweight 3-layer MLPs ensure gains come from fusion, not capacity—do NOT increase without ablation
  - Number of regions: 14 is atlas-dependent; finer parcellation increases experts but may fragment signal
  - Sparsity level: Top-k trades interpretability for potential underfitting if k too small

- **Failure signatures**:
  - Gate collapse: All weight concentrates on one expert → check entropy penalty strength
  - Modality dominance: One modality consistently receives >80% weight → verify feature normalization per modality
  - Random expert weights: No interpretable patterns across subjects → increase regularization or check data quality

- **First 3 experiments**:
  1. Reproduce baseline comparison: Train concatenation MLP and late-fusion MLP with identical hyperparameters; verify MREF-AD gap exists
  2. Ablate hierarchical gating: Compare full model vs. modality-only and region-only gating; confirm hierarchical benefit on held-out fold
  3. Sparsity sweep: Test k∈{1,3,5,7,10,14,29}; plot performance vs. k to identify elbow point for interpretability-performance tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
Can the MREF-AD framework be effectively extended to longitudinal data to predict conversion trajectories, such as progression from MCI to AD? The conclusion states the architecture "can be extended to... longitudinal or prognostic modeling tasks," but the current study uses only cross-sectional data from the "last available amyloid–MRI session," preventing analysis of disease progression dynamics.

### Open Question 2
Is the hierarchical MoE architecture generalizable to other neurological disorders with different spatial patterns of biomarker relevance? The authors note the architecture is general and "can be extended to other neurological disorders," but current evaluation is limited to Alzheimer's disease where the model identifies specific regions (temporal, subcortical) known to be relevant to AD; it is untested whether the gating network would correctly identify disease-specific regions for conditions like Parkinson's or FTD.

### Open Question 3
How does the model performance and expert weighting stability change when applied to heterogeneous, real-world clinical data as opposed to the standardized ADNI cohort? The study relies entirely on the standardized ADNI dataset with rigorous quality control; real-world application is implied but not tested. ADNI data is curated and harmonized, whereas clinical data often features higher variance in acquisition protocols, scanner types, and preprocessing quality, which may disrupt the learned gating weights.

## Limitations
- Unknown MLP architecture details including hidden layer dimensions, activation functions, and dropout rates
- Unexplained regularization parameters with exact sparsity and diversity penalty formulations lacking explicit mathematical definitions
- Brain parcellation mapping ambiguity with the specific 14-region subdivision of FreeSurfer atlas not detailed
- Limited comparative validation with performance claims resting primarily on ADNI dataset without external validation on other cohorts

## Confidence
- **High confidence**: Hierarchical gating mechanism effectiveness (verified through ablation showing superior performance vs single-level variants)
- **Medium confidence**: Interpretability claims regarding regional biomarker importance (consistent with established AD literature but lacking cross-validation)
- **Low confidence**: Generalization across datasets (no external cohort validation reported)

## Next Checks
1. **External validation**: Apply MREF-AD to an independent AD cohort (e.g., AIBL, OASIS) to verify cross-dataset performance
2. **Ablation sweep**: Systematically vary expert MLP capacity and gating regularization coefficients to confirm performance robustness
3. **Interpretability verification**: Cross-validate regional importance rankings against pathology progression models and expert radiological assessment