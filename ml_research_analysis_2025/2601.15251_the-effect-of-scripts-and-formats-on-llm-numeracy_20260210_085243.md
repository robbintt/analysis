---
ver: rpa2
title: The Effect of Scripts and Formats on LLM Numeracy
arxiv_id: '2601.15251'
source_url: https://arxiv.org/abs/2601.15251
tags:
- answer
- arithmetic
- script
- scripts
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models (LLMs) achieve high accuracy on arithmetic
  when numbers are expressed in standard Hindu-Arabic numerals, but their performance
  drops substantially when numerals are rendered in non-standard scripts or formats.
  This work evaluates LLM numerical reasoning across 21 numeral scripts and 6 formatting
  variants, showing that model accuracy decreases by 66-87% when arithmetic expressions
  use non-Hindu-Arabic scripts.
---

# The Effect of Scripts and Formats on LLM Numeracy

## Quick Facts
- arXiv ID: 2601.15251
- Source URL: https://arxiv.org/abs/2601.15251
- Reference count: 31
- Large language models achieve high accuracy on arithmetic when numbers are expressed in standard Hindu-Arabic numerals, but their performance drops substantially when numerals are rendered in non-standard scripts or formats.

## Executive Summary
This paper systematically evaluates how numeral scripts and formatting conventions affect the numerical reasoning capabilities of large language models. Through controlled experiments across 21 numeral scripts and 6 formatting variants, the authors demonstrate that LLMs experience significant performance degradation when arithmetic expressions use non-standard representations. The study reveals that both tokenization fragmentation and pretraining distribution mismatches contribute to these failures, while targeted prompting strategies can partially recover accuracy. The findings highlight that LLMs possess limited true numeracy and instead rely heavily on learned statistical associations between familiar numeral forms and arithmetic operations.

## Method Summary
The authors conducted controlled experiments evaluating LLM performance on addition and multiplication problems across 21 numeral scripts and 6 formatting variants. They used seven frontier models (including GPT-4o, Claude 3.5, Gemini 2.5, and others) and measured accuracy under various prompting conditions. The study employed both zero-shot and few-shot prompting strategies, testing explicit numeral mappings and native-language operator translations. Performance was analyzed using generalized linear mixed-effects models to account for repeated observations across conditions. Corpus frequency analysis of 22 billion Hindi text tokens provided additional context for understanding pretraining data distributions.

## Key Results
- Model accuracy decreases by 66-87% when arithmetic expressions use non-Hindu-Arabic scripts compared to standard notation
- Multiplication is significantly more challenging than addition across all scripts and formats
- Few-shot prompting with explicit numeral mappings and examples produces the largest accuracy gains
- Tokenization efficiency strongly influences accuracy, with more fragmented tokens leading to lower performance

## Why This Works (Mechanism)

### Mechanism 1: Tokenization Fragmentation Degradation
Scripts that tokenize into more subword units per digit cause higher arithmetic error rates. When numeral symbols are split into multiple tokens, the model must process longer sequences to represent the same numerical magnitude, increasing attention complexity and creating more opportunities for position-dependent errors.

### Mechanism 2: Pretraining Distribution Mismatch ("Script Tax")
Performance degradation reflects insufficient exposure to non-HA numeral representations during pretraining. LLMs learn statistical associations between numeral glyphs and arithmetic operations, and when glyphs appear sparsely in training data, the model lacks reliable mappings between surface form and numerical magnitude.

### Mechanism 3: Cross-Script Interference in Attention
Mixed-script prompts impair performance more than uniform-script prompts. Attention heads trained on predominantly monolingual contexts may struggle to bind numeral representations to operation semantics when scripts conflict, creating retrieval interference.

## Foundational Learning

- **Tokenization and vocabulary coverage**: Understanding why rare scripts fragment into more tokens requires knowing how BPE/SentencePiece builds vocabularies from frequency statistics. *Quick check*: If a script's digits appear in only 0.1% of pretraining data, will they likely be single tokens or multi-token sequences?

- **In-context learning as parameter-free adaptation**: The paper's core intervention (few-shot prompting) works without weight updates. *Quick check*: Why would few-shot examples help with Osmanya numerals if the model has never learned good Osmanya token embeddings?

- **Mixed-effects modeling for repeated measures**: Section 3.3 uses GLMER to handle non-independent observations. *Quick check*: If each arithmetic expression appears in 20 scripts, why does this violate logistic regression's independence assumption?

## Architecture Onboarding

- **Component map**: Input text → Tokenization (fragmentation check) → Embedding lookup (coverage check) → Attention over operands and operator → Answer generation in target script/format

- **Critical path**: Tokenization fragmentation → Embedding quality → Attention sequence length → Output vocabulary coverage

- **Design tradeoffs**: Larger vocabulary → better single-token coverage for rare scripts, but larger embedding matrix and slower inference; character-level tokenization → uniform fragmentation across scripts, but longer sequences and higher attention cost

- **Failure signatures**: Fragmentation failure (partial outputs or repeated tokens), grounding failure (computes correctly in HA but outputs wrong format), interference failure (returns phonetically similar language name)

- **First 3 experiments**: 
  1. Tokenization audit: Count tokens per digit for each script and correlate with accuracy on simple addition
  2. Few-shot ablation: Test 0-shot vs. 1-shot vs. 2-shot for lowest-performing script
  3. Cross-script interference probe: Present identical arithmetic in three conditions (HA + English, target script + English, target script + native-language)

## Open Questions the Paper Calls Out

### Open Question 1
Would chain-of-thought prompting or tool-calling (e.g., calculator integration) eliminate the performance gaps observed with non-standard numeral scripts and formats? The paper does not exhaustively explore all possible methods for improving model accuracy, such as explicit chain-of-thought prompting or tool-calling.

### Open Question 2
Can fine-tuning on diverse numeral scripts and formatting conventions permanently close the "script tax," or are architectural changes required? The paper demonstrates that few-shot prompting partially mitigates performance degradation but does not test whether parameter updates could produce durable improvements.

### Open Question 3
Why do multiple models consistently confuse Osmanya numerals with the Osage script, given no linguistic or geographic relationship between them? The paper notes this systematic weakness likely reflects shared blind spots in pretraining data, but the mechanism remains unidentified.

## Limitations

- Corpus coverage sampling may not fully represent global web text distributions, potentially missing specialized domains where rare scripts appear more frequently
- The study evaluated only single-script arithmetic expressions, not mixed-script combinations that could reveal different interference patterns
- All evaluated models use transformer architectures with similar tokenization approaches, limiting generalizability to other architectures
- The study focused on simple arithmetic with 2-digit operands, leaving multi-step calculations and larger numbers untested

## Confidence

**High Confidence (95%+)**: Tokenization fragmentation negatively correlates with accuracy across all tested models.

**Medium Confidence (75-95%)**: Pretraining distribution mismatch explains the majority of script-dependent performance gaps.

**Low Confidence (50-75%)**: Cross-script interference significantly impairs performance when operators and numerals use different scripts.

## Next Checks

1. **Tokenization Sensitivity Test**: Systematically vary tokenization granularity for a single low-resource script by forcing character-level vs. byte-pair tokenization to measure whether performance scales with fragmentation independent of script identity.

2. **Corpus Frequency Manipulation**: Fine-tune a base model on artificially boosted frequencies of a specific numeral script while holding other variables constant, then compare accuracy gains to those achieved through few-shot prompting.

3. **Cross-Script Arithmetic Benchmark**: Create a dataset mixing numerals and operators from different scripts and evaluate whether performance degradation exceeds the sum of individual script deficits, indicating true cross-script interference.