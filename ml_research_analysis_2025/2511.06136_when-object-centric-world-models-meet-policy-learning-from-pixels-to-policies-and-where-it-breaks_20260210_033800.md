---
ver: rpa2
title: 'When Object-Centric World Models Meet Policy Learning: From Pixels to Policies,
  and Where It Breaks'
arxiv_id: '2511.06136'
source_url: https://arxiv.org/abs/2511.06136
tags:
- learning
- world
- object-centric
- dlpwm
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces DLPWM, an object-centric world model that
  disentangles visual scenes into object-level latents. While DLPWM achieves strong
  reconstruction and prediction performance, including robustness to out-of-distribution
  visual variations, policies trained on its latents underperform compared to DreamerV3
  in downstream model-based control tasks.
---

# When Object-Centric World Models Meet Policy Learning: From Pixels to Policies, and Where It Breaks

## Quick Facts
- **arXiv ID**: 2511.06136
- **Source URL**: https://arxiv.org/abs/2511.06136
- **Reference count**: 9
- **Primary result**: DLPWM achieves strong reconstruction and prediction performance with robustness to out-of-distribution visual variations, but policies trained on its latents underperform compared to DreamerV3 in downstream model-based control tasks

## Executive Summary
This work introduces DLPWM, an object-centric world model that disentangles visual scenes into object-level latents. While DLPWM demonstrates strong reconstruction and prediction performance, including robustness to out-of-distribution visual variations, policies trained on its latents underperform compared to DreamerV3 in downstream model-based control tasks. Analysis reveals that representation shifts during multi-object interactions, particularly near contact points, lead to unstable policy learning. The authors propose using exponential moving averages of latent slots as a mitigation strategy for future work.

## Method Summary
The authors develop DLPWM (Disentangled Latent Perception World Model), an object-centric world model that represents visual scenes as disentangled object-level latents. The model separates scene understanding into object representations, enabling more interpretable and potentially more robust visual processing. DLPWM is evaluated both for reconstruction and prediction quality, as well as for its effectiveness in downstream policy learning tasks using model-based reinforcement learning approaches.

## Key Results
- DLPWM achieves strong reconstruction and prediction performance across various visual environments
- DLPWM demonstrates robustness to out-of-distribution visual variations including texture, shape, and color changes
- Policies trained on DLPWM latents underperform compared to DreamerV3 in downstream model-based control tasks
- Analysis reveals that representation shifts occur during multi-object interactions, particularly near contact points

## Why This Works (Mechanism)
The object-centric approach works by decomposing visual scenes into individual object representations, allowing the model to capture object-specific dynamics and properties separately. This disentanglement enables better generalization to visual variations since object properties can be modified independently. However, the mechanism breaks down during multi-object interactions where object boundaries become ambiguous, particularly at contact points where representations become unstable and shift unexpectedly.

## Foundational Learning
- **Object-centric representation learning**: Why needed - to enable compositional understanding of scenes; Quick check - verify object boundaries are correctly identified
- **Latent dynamics modeling**: Why needed - to predict future states from current observations; Quick check - validate prediction accuracy over time horizons
- **Model-based policy learning**: Why needed - to use learned world models for decision making; Quick check - measure policy performance on test tasks
- **Representation stability analysis**: Why needed - to understand when and why representations fail; Quick check - track latent trajectory changes during interactions
- **Contact dynamics modeling**: Why needed - to handle physical interactions between objects; Quick check - verify behavior near collision boundaries
- **Cross-modal generalization**: Why needed - to ensure robustness to visual variations; Quick check - test with altered textures, shapes, and colors

## Architecture Onboarding

**Component map**: Raw pixels -> Encoder -> Object latents (slots) -> Decoder/Prediction -> Policy network

**Critical path**: The critical path involves encoding raw observations into object slots, using these slots for both reconstruction/prediction and policy input, then executing actions in the environment based on policy outputs

**Design tradeoffs**: Object-centric design enables better compositional generalization but introduces complexity in handling object-object interactions and maintaining consistent slot assignments across time steps

**Failure signatures**: Representation shifts during contact interactions, inconsistent slot assignments across time steps, and performance degradation when objects interact at boundaries

**First experiments**:
1. Evaluate reconstruction quality with varying object counts and arrangements
2. Test prediction accuracy across different time horizons
3. Compare policy performance using object latents versus monolithic representations

## Open Questions the Paper Calls Out
The authors identify several open questions regarding the stability of object-centric representations during physical interactions, the effectiveness of proposed solutions like exponential moving averages, and the generalizability of their findings to more complex environments and interaction types.

## Limitations
- The claim that representation shifts during contact interactions cause policy instability is supported by trajectory analysis but lacks direct ablation studies isolating perturbation effects
- The proposed exponential moving average solution is only mentioned as future work without empirical validation
- Experiments are limited to specific multi-object manipulation tasks, raising questions about generalizability

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| DLPWM handles out-of-distribution visual variations effectively | High |
| DLPWM's object-level latents outperform DreamerV3 in reconstruction/prediction | High |
| Representation shifts during contact interactions cause policy instability | Medium |
| DLPWM underperforms compared to DreamerV3 in policy learning | High |

## Next Checks
1. Conduct controlled experiments isolating representation shifts by injecting synthetic perturbations into latent slots and measuring policy performance degradation
2. Implement and evaluate the proposed exponential moving average approach on the current tasks to quantify improvements in policy stability
3. Test DLPWM across a broader range of environments including varying object counts, different physical interaction types, and more complex manipulation scenarios to assess generalizability