---
ver: rpa2
title: 'Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech'
arxiv_id: '2507.20140'
source_url: https://arxiv.org/abs/2507.20140
tags:
- speaker
- speech
- unlearning
- forget
- speakers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first machine unlearning framework for
  Zero-Shot Text-to-Speech (ZS-TTS) to address voice privacy concerns. The proposed
  Teacher-Guided Unlearning (TGU) method ensures the model forgets designated speaker
  identities while retaining speech quality for other speakers by guiding the model
  to generate speech with random voice styles for forget speakers.
---

# Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech

## Quick Facts
- **arXiv ID:** 2507.20140
- **Source URL:** https://arxiv.org/abs/2507.20140
- **Reference count:** 40
- **Primary result:** First machine unlearning framework for ZS-TTS; achieves speaker similarity of 0.169 for forget speakers while maintaining 2.8% drop in remain speaker similarity

## Executive Summary
This paper introduces Teacher-Guided Unlearning (TGU), the first machine unlearning framework for Zero-Shot Text-to-Speech (ZS-TTS) systems. The method addresses voice privacy concerns by modifying a pre-trained VoiceBox model to forget specific speaker identities while preserving speech quality for other speakers. TGU guides the model to generate speech with random voice styles when prompted with forget speakers' identities, effectively neutralizing their knowledge while maintaining performance on remain speakers.

## Method Summary
The TGU framework modifies a pre-trained VoiceBox model through a teacher-guided unlearning process. The method employs a frozen teacher model to generate random voice targets for forget speaker prompts, while using standard flow matching for remain speakers. The student model is trained with a weighted loss (0.2 for remain, 0.8 for forget) over 145K steps, sampling forget data with 20% probability. The approach ensures the model cannot replicate designated speakers while maintaining competitive word error rates and linguistic quality for other voices.

## Key Results
- Achieves speaker similarity of 0.169 for forget speakers (comparable to different speakers)
- Maintains only 2.8% decrease in speaker similarity for remain speakers versus original model
- Achieves highest spk-ZRF score, indicating effective neutralization of forget speaker knowledge
- Maintains competitive word error rates while unlearning specific speaker identities

## Why This Works (Mechanism)
The TGU framework works by leveraging a frozen teacher model to generate speech targets with random voice styles for forget speaker prompts. When the student model encounters a forget speaker's prompt, it learns to generate speech that diverges from the original speaker's voice pattern by matching these random targets. For remain speakers, standard flow matching continues, preserving their speech quality. The weighted loss function ensures the model prioritizes unlearning forget speakers while minimizing degradation for others.

## Foundational Learning
- **Zero-Shot TTS:** TTS systems that generate speech for unseen speakers without speaker-specific training data; needed because traditional TTS requires extensive speaker-specific data
- **Conditional Flow Matching:** A diffusion-based generative modeling approach for speech; needed to enable the continuous transformation of speech features
- **Speaker Similarity Metrics:** Automated measurements of voice likeness (e.g., WavLM-TDCNN); needed to quantify unlearning effectiveness
- **Machine Unlearning:** The process of removing specific knowledge from trained models; needed to address privacy concerns about voice replication
- **Random Voice Generation:** Creating speech samples with artificial speaker identities; needed to guide the model toward forgetting specific speakers
- **spk-ZRF Metric:** Proposed metric measuring randomness in generated speaker identities; needed to evaluate the quality of unlearning

## Architecture Onboarding
**Component Map:** Text Condition → VoiceBox (Teacher/Frozen) → Random Target Generation → Flow Matching Loss → Student Model Updates

**Critical Path:** During training, for each forget sample: generate random voice target using frozen teacher → compute flow matching loss → update student weights; for remain samples: standard flow matching loss → update student weights

**Design Tradeoffs:** The 0.8:0.2 forget:remain loss weighting prioritizes unlearning over maintaining quality, accepting some degradation to achieve effective privacy protection. The 20% sampling ratio balances computational efficiency with unlearning effectiveness.

**Failure Signatures:** Catastrophic forgetting manifests as significant SIM-R drops (>5%); mode collapse appears as low spk-ZRF scores indicating static rather than diverse random voices; high WER indicates linguistic content degradation.

**First Experiments:** 1) Verify baseline VoiceBox performance on LibriHeavy with standard flow matching; 2) Implement teacher target generation with random noise and validate random voice diversity; 3) Test TGU training loop with synthetic data to confirm loss weighting effects.

## Open Questions the Paper Calls Out
- How can the framework distinguish between target forget speakers and retain speakers with nearly identical voice characteristics to prevent inadvertent utility loss?
- Is the unlearned model robust against advanced adversarial attacks such as model inversion or targeted voice re-synthesis?
- Can the Teacher-Guided Unlearning methodology be effectively adapted for non-flow-matching architectures, such as autoregressive language models?

## Limitations
- Reproducibility concerns due to incomplete specification of random noise schedule and teacher target generation configuration
- Heavy dependence on the quality and generalization capabilities of the frozen pre-trained baseline model
- Evaluation metrics may not fully capture perceptual quality or practical privacy implications

## Confidence
- **High Confidence:** Experimental results showing TGU effectively reduces speaker similarity for forget speakers while maintaining remain speaker performance
- **Medium Confidence:** Claim of achieving highest spk-ZRF score, dependent on metric interpretation and implementation details
- **Low Confidence:** Assertion of being the first machine unlearning framework for ZS-TTS without comprehensive prior work review

## Next Checks
1. Reproduce TGU with ablation studies varying forget/remain loss weighting and sampling ratios to assess robustness
2. Evaluate neutralized speech quality using alternative metrics and human perceptual studies to validate privacy effectiveness
3. Test TGU framework generalization across different TTS models and datasets to establish broader applicability