---
ver: rpa2
title: Concolic Testing on Individual Fairness of Neural Network Models
arxiv_id: '2509.06864'
source_url: https://arxiv.org/abs/2509.06864
tags:
- fairness
- pyfair
- testing
- discriminatory
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PyFair introduces a concolic testing framework for evaluating individual
  fairness in DNNs. It extends PyCT with a dual network architecture that allows systematic
  exploration of fairness properties, offering completeness guarantees for networks
  expressible in SMT.
---

# Concolic Testing on Individual Fairness of Neural Network Models

## Quick Facts
- **arXiv ID**: 2509.06864
- **Source URL**: https://arxiv.org/abs/2509.06864
- **Reference count**: 40
- **Primary result**: PyFair introduces a concolic testing framework for evaluating individual fairness in DNNs, offering completeness guarantees for networks expressible in SMT.

## Executive Summary
This paper introduces PyFair, a concolic testing framework that systematically evaluates individual fairness in deep neural networks. By constructing a dual-network architecture (2-DNN) that compares outputs for inputs differing only in protected attributes, PyFair transforms fairness verification into an adversarial example search problem. The approach extends PyCT with fairness-specific path constraints and provides formal completeness guarantees when the network can be encoded in SMT. Tested on 25 models, PyFair effectively detects discriminatory instances and verifies fairness, often outperforming existing methods like Fairify. However, scalability remains a challenge for complex architectures, with verification times becoming prohibitive.

## Method Summary
PyFair constructs a 2-DNN by duplicating the original DNN weights and architecture, creating two parallel networks that process inputs differing only in protected attributes. The method employs concolic execution—combining concrete and symbolic execution—to systematically explore network paths. Starting from a concrete input, protected attributes are treated as symbolic variables, and branch conditions from activation functions are collected as path constraints. An SMT solver then finds new inputs satisfying unexplored path constraints. If the solver finds an input where the two networks produce different outputs, an unfairness witness is reported. The approach is complete for networks expressible in linear real arithmetic, meaning exhaustive exploration guarantees that no discriminatory instances exist if none are found.

## Key Results
- PyFair successfully detects discriminatory instances in 19/25 benchmark models, often faster than Fairify
- The framework provides formal fairness certification (completeness guarantee) for small models when expressed in SMT
- Scalability remains a challenge, with verification times becoming prohibitive for complex architectures (e.g., GC5 timed out after 1800 seconds)
- Multi-protected-attribute detection sometimes outperforms single-attribute detection due to the dual-network architecture's native handling of multiple PAs

## Why This Works (Mechanism)

### Mechanism 1: Dual-Network (2-DNN) Architecture Transforms Fairness into Output Equivalence
PyFair constructs a 2-DNN by duplicating the original DNN. One copy receives input with protected attribute (PA) values, the other receives the same non-protected attributes (NPAs) but with PA' (a symbolic duplicate of PA). The outputs are compared: if M(x, y) ≠ M(x', y) for identical NPAs y, the output is 1 (unfairness detected). This transforms fairness checking into an adversarial example search problem on a single combined network.

### Mechanism 2: Concolic Execution with Fairness-Specific Path Constraints
Starting from a concrete input, PyFair treats protected attributes as concolic variables (concrete value + symbolic expression). During forward passes, it collects branch conditions (path constraints) from activation functions. An SMT solver then finds inputs satisfying negations of explored paths, systematically covering unexplored branches.

### Mechanism 3: Completeness via SMT Encodability
For DNNs expressible in linear real arithmetic (e.g., ReLU activations, Softmax/Sigmoid outputs with threshold comparison), PyFair provides formal completeness guarantees—if no unfairness witness is found after exhaustive exploration, the model is certified fair.

## Foundational Learning

- **Concept: Concolic Testing (Concrete + Symbolic)**
  - **Why needed here:** PyFair's core innovation adapts concolic testing from software analysis to neural network fairness. Without understanding concrete execution (actual forward pass) combined with symbolic constraint collection, the mechanism is opaque.
  - **Quick check question:** Given a ReLU node with input -5 + x (concrete -5, symbolic x-y), what branch condition is added to the path constraint? (Answer: (x-y) > 0 for the positive branch)

- **Concept: Individual vs. Group Fairness**
  - **Why needed here:** PyFair targets individual fairness (similar individuals treated similarly), not group fairness (statistical parity across groups). Confusing these leads to misapplying PyFair to problems it cannot solve.
  - **Quick check question:** If a model has equal acceptance rates across genders but treats two individuals identically except for gender differently, does it violate individual fairness, group fairness, or both? (Answer: Individual fairness only)

- **Concept: SMT Solvers and Linear Real Arithmetic**
  - **Why needed here:** PyFair's completeness guarantee hinges on SMT encodability. Understanding what constraints SMT solvers can handle (linear real arithmetic) clarifies why ReLU networks are amenable but complex architectures may not be.
  - **Quick check question:** Why might a network with sigmoid activation functions pose challenges for SMT-based verification? (Answer: Sigmoid is non-linear; requires approximation or threshold discretization for LRA encoding)

## Architecture Onboarding

- **Component map:** Input Layer -> 2-DNN Constructor -> Concolic Execution Engine -> SMT Solver Interface -> Output
- **Critical path:**
  1. Construct 2-DNN from M and PA (Algorithm 2)
  2. Initialize with random concolic input (PA as symbolic variables)
  3. Forward pass through 2-DNN, collecting branch conditions in Q and T
  4. Loop: dequeue constraint from Q → SMT solve → if SAT, test new input → if outputs differ, report unfairness; else, update Q/T and continue
  5. Termination: Q empty (fairness certified) or unfairness found or timeout

- **Design tradeoffs:**
  - Completeness vs. Scalability: PyFair provides formal guarantees but times out on complex models (GC5: 60+ seconds per constraint, 1800s timeout). Fairify uses pruning but may miss cases.
  - Single vs. Multiple PAs: 2-DNN handles multiple PAs natively; experiments show multi-PA detection sometimes faster than single-PA (dual AC models vs. vanilla PyCT)
  - White-box vs. Black-box: Requires full model access (weights, architecture) unlike THEMIS/AEQUITAS

- **Failure signatures:**
  - Timeout on complex models: Large FQ (queue size) + high #sat/#unsat + timeout = path explosion (e.g., GC5: FQ=248, 1 SAT, 2 UNSAT in 1800s)
  - False negatives in non-SMT-encodable networks: If using non-encodable activations, "no witness found" ≠ "fair" (completeness voided)
  - Inconclusive results: "Unk" status means exploration incomplete within time budget

- **First 3 experiments:**
  1. Reproduce Section 5, RQ1 on a simple model: Run PyCT (not PyFair) on AC1-AC3 with single PA (race). Measure #test, #sat, #unsat, time. Compare with Fairify on same models. Goal: understand vanilla concolic testing baseline.
  2. Validate 2-DNN construction (Algorithm 2): Manually construct 2-DNN for the 3-layer DNN in Figure 1. Verify weight matrix dimensions and PA handling match Figure 2. Test with input [0,5,0] and trace through iterations 1-7 as in Section 4.2.
  3. Scalability boundary test: Run PyFair on progressively larger models (AC1 → AC7 → AC12). Plot FQ vs. time. Identify the threshold where verification time exceeds 100s. Compare with RQ4 fair model results to isolate complexity from path explosion vs. constraint solving.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the constraint-solving process be optimized to verify fairness in complex DNN architectures where PyFair currently times out?
  - **Basis in paper:** The Conclusion states future work could enhance the framework with "more efficient algorithms for handling larger architectures" to address scalability.
  - **Why unresolved:** The evaluation (RQ4) shows that PyFair fails to verify complex models like GC5 within the time limit due to the prohibitive cost of constraint solving.
  - **Evidence:** Successful verification of larger, deeper models (beyond the tested benchmarks) within a reasonable time frame would resolve this.

- **Open Question 2:** Can the concolic testing and dual-network construction be adapted for sequence-based models like RNNs or Transformers?
  - **Basis in paper:** The Conclusion explicitly identifies "extension to different network types like RNNs and Transformers" as a direction for future work.
  - **Why unresolved:** The current implementation and evaluation focus exclusively on feed-forward networks with activation functions (ReLU, Sigmoid) easily encoded in SMT.
  - **Evidence:** Demonstrating the successful application of the 2-DNN architecture to a recurrent or attention-based model would resolve this.

- **Open Question 3:** Can PyFair be integrated directly into model training loops to iteratively repair fairness violations?
  - **Basis in paper:** The Conclusion suggests "deeper integration with fair model training techniques" as a potential advancement.
  - **Why unresolved:** PyFair currently operates as a post-hoc verification and testing tool on pre-trained models rather than a component of the training optimization process.
  - **Evidence:** A training framework that utilizes PyFair's discriminatory instances for gradient updates, resulting in a verified fair model upon convergence, would resolve this.

## Limitations

- Scalability remains a fundamental limitation, with complex models like GC5 timing out after 1800 seconds due to path explosion and expensive constraint solving
- Completeness guarantees only hold for networks expressible in SMT (Linear Real Arithmetic), excluding models with complex activation functions or custom layers
- The method requires white-box access to the model (weights and architecture), limiting applicability to black-box scenarios

## Confidence

- **High**: Dual-network architecture correctly transforms fairness into output-equivalence checking (directly specified in Algorithm 2 and validated in experiments)
- **Medium**: Completeness guarantee holds for SMT-encodable networks (theoretically sound but practically limited to small models as shown in RQ4)
- **Low**: PyFair provides practical advantage over Fairify for multi-protected-attribute detection (evidence is mixed—dual AC models show faster detection, but not consistently across all benchmarks)

## Next Checks

1. **Boundary test scalability limits**: Run PyFair on progressively larger AC models (AC1→AC12) and plot constraint solving time vs. model size. Verify the exponential scaling trend matches the paper's timeout observations on GC5.

2. **SMT encodability audit**: For each benchmark model, verify whether all activation functions and output comparisons are faithfully encodable in Linear Real Arithmetic. Test a model with sigmoid activation to confirm the completeness guarantee breaks as claimed in Footnote 1.

3. **Multi-PA vs single-PA detection comparison**: Replicate the dual AC experiments with 2 protected attributes. Measure whether dual-PA detection is consistently faster than running single-PA detection twice, controlling for the same models and timeouts.