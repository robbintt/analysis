---
ver: rpa2
title: Black-Box Time-Series Domain Adaptation via Cross-Prompt Foundation Models
arxiv_id: '2510.00487'
source_url: https://arxiv.org/abs/2510.00487
tags:
- domain
- adaptation
- cpfm
- source
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the black-box time-series domain adaptation
  (BBTSDA) problem, where only an API of a pre-trained source model is available for
  adapting to unlabeled target domains while preserving privacy. Unlike existing vision-focused
  approaches, this work proposes Cross-Prompt Foundation Models (CPFM), built on a
  time-series foundation model with prompt tuning.
---

# Black-Box Time-Series Domain Adaptation via Cross-Prompt Foundation Models

## Quick Facts
- arXiv ID: 2510.00487
- Source URL: https://arxiv.org/abs/2510.00487
- Authors: M. T. Furqon; Mahardhika Pratama; Igor Skrjanc; Lin Liu; Habibullah Habibullah; Kutluyil Dogancay
- Reference count: 8
- One-line primary result: Dual-branch prompt tuning on frozen time-series foundation model achieves up to 11% F1-score improvement in black-box domain adaptation

## Executive Summary
This paper addresses the black-box time-series domain adaptation (BBTSDA) problem where only an API of a pre-trained source model is available for adapting to unlabeled target domains while preserving privacy. The proposed Cross-Prompt Foundation Models (CPFM) approach uses a frozen time-series foundation model with dual learnable prompts and reconstruction learning to capture complementary information and perform implicit domain alignment. Experiments on three time-series datasets show CPFM significantly outperforms state-of-the-art BBDA methods, achieving up to 11% improvement in F1-score.

## Method Summary
CPFM employs a dual-branch network structure built on a frozen time-series foundation model (MOMENT). Each branch uses distinct learnable prompts injected into the model's attention layers, with classification heads trained on the extracted features. The method uses three loss components: classification loss against source model pseudo-labels, prompt reconstruction loss to maintain distinct prompts, and input reconstruction loss for implicit domain alignment. The final prediction aggregates outputs from both branches using confidence weighting. For multi-source scenarios, predictions are weighted by normalized inverse entropy.

## Key Results
- CPFM achieves up to 11% improvement in macro F1-score compared to state-of-the-art BBDA methods
- Dual-branch architecture consistently outperforms single-branch variants across all tested datasets
- Performance scales effectively with multiple source domains, showing consistent gains up to 5 sources
- Ablation studies confirm the importance of prompt tuning and reconstruction strategies, with prompt reconstruction alone contributing over 2% performance gain

## Why This Works (Mechanism)

### Mechanism 1: Dual-branch complementary learning
Distinct prompts guide the frozen backbone to extract non-redundant features; if prompts converge to similar representations (cosine similarity > 0.95), the mechanism fails and the system effectively operates as a single-branch model.

### Mechanism 2: Input reconstruction as implicit domain alignment
A reconstruction head trained on target domain samples using masked auto-encoding learns target-specific spatio-temporal dynamics, closing the domain gap by aligning the representation space to the target data manifold.

### Mechanism 3: Prompt reconstruction prevents branch collapse
An auto-encoder projects high-dimensional prompts into a lower-dimensional manifold and back, penalizing deviations to maintain useful diversity between branches while constraining them to lie on a smooth manifold.

## Foundational Learning

**Concept: Prompt Tuning (in Time-Series Transformers)**
- Why needed here: The entire CPFM architecture relies on freezing the massive foundation model and only training small "prompt" vectors injected into the attention layers
- Quick check question: Can you explain why we prepend learnable tensors to the Query, Key, and Value matrices in the Self-Attention layer rather than fine-tuning the weights themselves?

**Concept: Black-Box Domain Adaptation (BBDA) Constraints**
- Why needed here: Standard Domain Adaptation usually assumes access to source data or weights, but this method specifically addresses scenarios where only an API (inputs in, soft-labels out) is available
- Quick check question: Why does the absence of source gradients necessitate a "teacher-student" or "knowledge distillation" approach using pseudo-labels?

**Concept: Exponential Moving Average (EMA) for Noise Filtering**
- Why needed here: The paper uses EMA to update the "teacher" knowledge, smoothing noisy source model predictions on target data over time to stabilize training
- Quick check question: How does the parameter γ in the EMA equation balance the trust between the static source model's prediction and the evolving target model's prediction?

## Architecture Onboarding

**Component map:**
MOMENT Backbone -> Two Prompt Adapters (p₁, p₂) -> Two Classification Heads (φ₁, φ₂) -> Confidence-weighted Aggregation

**Critical path:**
1. Initialize: Load frozen MOMENT; initialize distinct prompts p₁, p₂
2. API Call: Send target batch xₜ to Black-Box Source API → get soft labels ŷₜⁱ
3. Update Teacher: Refine soft labels using EMA
4. Forward Pass: Process xₜ through both branches (Backbone + Prompts)
5. Loss Calculation: Compute CE Loss (vs. Teacher), Input Recon Loss, Prompt Recon Loss
6. Backprop: Update only Prompts and Heads

**Design tradeoffs:**
- Frozen vs. Full Fine-tuning: Freezing preserves generalization and reduces memory but may limit capacity for specialized targets
- Dual vs. Single Branch: Dual branches increase robustness to noise but double parameter count and complexity

**Failure signatures:**
- Mode Collapse: Prompt Reconstruction loss goes to zero, but classification accuracy stalls
- Negative Transfer: Target accuracy < Source accuracy (check if EMA γ is too high)
- Reconstruction Dominance: Input Recon loss drops rapidly, but CE loss stagnates

**First 3 experiments:**
1. Baseline check: Run CPFM on HAR dataset comparing "w/o Prompt Tuning" vs. Full CPFM
2. Hyperparameter sensitivity: Vary trade-off constants (γ₁, γ₂) to observe balance between reconstruction and classification
3. Visualization: Generate T-SNE plots of embeddings from Branch 1 vs. Branch 2 before and after training

## Open Questions the Paper Calls Out
- How can CPFM be extended to address category shift (open-set or partial-set) problems in time-series domain adaptation?
- Is CPFM's performance dependent on the specific MOMENT foundation model, or does it generalize to other architectures?
- Can the dual-branch prompt reconstruction strategy effectively scale to scenarios with significantly larger numbers of source domains without inducing negative transfer?

## Limitations
- Prompt architecture details underspecified (prompt size, number of layers, encoding dimensions)
- Results limited to only three time-series datasets with relatively small sample sizes
- No ablation study isolating the contribution of dual-branch structure from prompt tuning itself

## Confidence

**High confidence:** CPFM addresses a real gap in black-box time-series domain adaptation, and the dual-branch prompt tuning approach is technically sound

**Medium confidence:** Performance claims show substantial improvements over baselines, but limited dataset diversity and potential hyperparameter overfitting reduce generalizability

**Low confidence:** Limited theoretical justification for why distinct prompts lead to complementary feature learning, and reconstruction-based domain alignment is only empirically demonstrated

## Next Checks
1. Implement CPFM with alternative frozen backbones (not just MOMENT) to verify the approach generalizes beyond the specific foundation model

2. Systematically vary the domain gap between source and target datasets to measure performance degradation and identify failure thresholds

3. During training, track the cosine similarity between p₁ and p₂ to empirically verify they maintain distinct representations rather than collapsing, and correlate this with performance changes