---
ver: rpa2
title: Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram
  Masking
arxiv_id: '2510.09528'
source_url: https://arxiv.org/abs/2510.09528
tags:
- speech
- accent
- persian
- recognition
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of accent and dialect sensitivity
  in automatic speech recognition (ASR) systems, which leads to elevated word error
  rates (WER) for non-native and regional accents. The proposed method uses saliency-driven
  spectrogram masking, where an accent classifier is trained to identify accent-specific
  features, Grad-CAM is used to localize these regions, and a probabilistic masking
  strategy suppresses them during training.
---

# Accent-Invariant Automatic Speech Recognition via Saliency-Driven Spectrogram Masking

## Quick Facts
- arXiv ID: 2510.09528
- Source URL: https://arxiv.org/abs/2510.09528
- Reference count: 0
- Saliency-driven spectrogram masking achieves up to 14% relative WER reduction on accented speech

## Executive Summary
This paper addresses accent and dialect sensitivity in automatic speech recognition systems by introducing a saliency-driven spectrogram masking approach. The method identifies and suppresses accent-specific acoustic features during training, enabling ASR models to learn accent-invariant representations. The approach achieves significant WER reductions on accented English and Persian datasets while maintaining accuracy on native speech, without requiring architectural modifications.

## Method Summary
The method trains an accent classifier to identify accent-specific spectrogram regions using Grad-CAM, then applies probabilistic masking to suppress these regions during ASR training. This forces the model to learn accent-neutral acoustic representations rather than accent-dependent features. The approach is lightweight, model-agnostic, and compatible with existing augmentation techniques like SpecAugment.

## Key Results
- Up to 14% relative WER improvement on accented English speech compared to SpecAugment
- Significant performance gains on Persian accent datasets (PDID)
- Maintains or improves accuracy on native speech while reducing accent-dependent errors
- Outperforms baselines across multiple English (LibriSpeech, EdAcc, CommonAccent) and Persian (CommonVoice-fa, PDID) datasets

## Why This Works (Mechanism)
The approach works by identifying accent-specific acoustic patterns through an accent classifier and then suppressing these patterns during ASR training. By masking saliency regions that the accent classifier relies on, the ASR model is forced to learn representations that are invariant to accent variations rather than memorizing accent-specific cues. This creates a more robust acoustic model that generalizes better across different speaker backgrounds.

## Foundational Learning
- **Accent classifier training**: Needed to identify accent-specific features; quick check: verify classifier accuracy across target accents
- **Grad-CAM saliency localization**: Required to pinpoint accent-dependent spectrogram regions; quick check: visualize saliency maps for different accents
- **Probabilistic masking strategy**: Controls the trade-off between accent suppression and speech preservation; quick check: tune masking probability for optimal WER
- **Accent-invariant representation learning**: The ultimate goal of suppressing accent-specific cues; quick check: measure WER consistency across accents
- **Model-agnostic augmentation**: Enables integration with existing ASR pipelines; quick check: compatibility with different ASR architectures

## Architecture Onboarding
Component map: Accent Classifier -> Grad-CAM Saliency Detection -> Probabilistic Masking -> ASR Model Training

Critical path: Accent classifier output → saliency map generation → spectrogram masking → ASR loss computation

Design tradeoffs: The method balances accent suppression against speech intelligibility preservation through masking probability tuning. Higher masking rates improve accent invariance but may degrade native speech performance.

Failure signatures: Poor accent classifier performance leads to incorrect saliency maps and ineffective masking. Overly aggressive masking can remove important phonetic information.

First experiments: 1) Train accent classifier on target datasets and evaluate accent classification accuracy, 2) Generate and visualize Grad-CAM saliency maps for different accent categories, 3) Apply masking to validation set and measure impact on accent-specific WER metrics.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation under diverse real-world noise conditions
- Unverified generalization to extremely rare or mixed accents
- Computational overhead from accent classification during training

## Confidence
High: Accent adaptation effectiveness, Model-agnostic integration
Medium: Real-world robustness generalization, Scalability to larger architectures

## Next Checks
1. Evaluate performance under diverse real-world noise conditions including reverberation and competing speakers
2. Test generalization on truly unseen accent categories not represented in training data
3. Assess computational efficiency and scalability when applied to larger ASR architectures