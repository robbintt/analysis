---
ver: rpa2
title: CRPS-Based Targeted Sequential Design with Application in Chemical Space
arxiv_id: '2503.11250'
source_url: https://arxiv.org/abs/2503.11250
tags:
- crps
- page
- criteria
- gaussian
- excursion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces a new approach to targeted sequential design
  in Gaussian process modeling, focusing on accurately predicting within a specific
  range of the response of interest. The key idea is using threshold-weighted Continuous
  Ranked Probability Score (CRPS) as the foundation for acquisition functions, where
  two weighting measures are considered: an indicator weight on the excursion set
  and a Gaussian weight centered at the threshold.'
---

# CRPS-Based Targeted Sequential Design with Application in Chemical Space

## Quick Facts
- arXiv ID: 2503.11250
- Source URL: https://arxiv.org/abs/2503.11250
- Reference count: 40
- Key outcome: CRPS-based criteria consistently outperform random selection and show competitive or superior performance compared to existing methods, particularly excelling in precision (CRPSγ1) and sensitivity (CRPSγ2 and ICRPSγ2)

## Executive Summary
This paper introduces a novel approach to targeted sequential design in Gaussian process modeling that focuses on accurately predicting within a specific range of the response of interest. The key innovation is using threshold-weighted Continuous Ranked Probability Score (CRPS) as the foundation for acquisition functions, where two weighting measures are considered: an indicator weight on the excursion set and a Gaussian weight centered at the threshold. Two types of criteria are developed: pointwise selection (CRPSγ1 and CRPSγ2) and Stepwise Uncertainty Reduction (SUR) criteria (ICRPSγ1 and ICRPSγ2). These methods are benchmarked against state-of-the-art approaches on synthetic and real molecular datasets (Photoswitch dataset), showing consistent performance improvements.

## Method Summary
The method employs Gaussian process regression with a Tanimoto kernel for binary molecular fingerprints, using threshold-weighted CRPS as acquisition functions. Two weighting measures are defined: γ1 (indicator weight for excursion set) and γ2 (Gaussian weight centered at threshold). Pointwise criteria maximize marginal uncertainty, while SUR criteria reduce integrated uncertainty across the domain. The approach includes closed-form expressions for efficient computation and is validated on the Photoswitch dataset with 392 molecules, using Morgan fingerprints (2048 bits, radius 3) and comparing against TMSE, TIMSE, IBV, and entropy-based methods.

## Key Results
- CRPSγ1 reduces CRPSγ1 metric by approximately 30% compared to random selection and achieves 10% higher precision
- CRPS-based criteria show competitive or superior performance compared to state-of-the-art methods
- The methods excel in precision (CRPSγ1) and sensitivity (CRPSγ2 and ICRPSγ2)
- Tanimoto kernel outperforms Gaussian and exponential kernels, especially with small training sets

## Why This Works (Mechanism)

### Mechanism 1
Threshold-weighted CRPS enables targeted evaluation of predictive accuracy within a predefined region of interest (excursion set), rather than uniformly across all predictions. By incorporating weighting measures γ that emphasize values near or above threshold t, the CRPS focuses evaluation on regions of practical importance. For γ1 (indicator weight), only values ≥ t contribute to the score; for γ2 (Gaussian weight centered at t), values near the threshold receive exponentially higher weight via the Gaussian density.

### Mechanism 2
Converting threshold-weighted CRPS from a post-hoc evaluation metric to an expected score enables its use as an acquisition function before observing outcomes. During sequential design, the materialized value y is unavailable. The expected score CRPSγ(F) = ∫CRPSγ(F, y')dF(y') replaces unknown y with integration over the predictive distribution. For Gaussian predictions, this yields closed-form expressions involving only mean μ and variance σ², enabling efficient optimization.

### Mechanism 3
Pointwise criteria (CRPSγ1, CRPSγ2) maximize marginal uncertainty, while SUR criteria (ICRPSγ1, ICRPSγ2) reduce integrated uncertainty across the domain, trading off precision vs. sensitivity. Pointwise criteria maximize Gn(x) = CRPSγ(Φμ,σ²) using only marginal statistics. SUR criteria minimize Jn(x) = En,x[∫CRPSγ(ξn+1(x'))dPX(x')], considering how adding point x reduces expected future integrated uncertainty. CRPSγ1 achieves higher precision (prioritizing points likely in excursion set); CRPSγ2 achieves higher sensitivity (focusing near threshold boundary).

## Foundational Learning

- **Gaussian Process Regression**
  - Why needed here: GP modeling provides the predictive distributions (mean mn(x), variance kn(x,x)) that all CRPS-based criteria depend on. Closed-form acquisition expressions derive specifically from Gaussian predictive distributions.
  - Quick check question: Given posterior GP mean mn(x) and variance kn(x,x), how do you compute the probability that f(x) ≥ threshold t?

- **Proper Scoring Rules**
  - Why needed here: CRPS is strictly proper—it incentivizes honest probabilistic forecasts. Understanding properness justifies why threshold-weighted CRPS generalizes to acquisition: expected scores naturally identify high-uncertainty regions.
  - Quick check question: Explain why CRPS being "strictly proper" matters for sequential design, compared to non-proper metrics like Mean Absolute Error.

- **Excursion Set Estimation**
  - Why needed here: The methodology centers on estimating Γ = {x : f(x) ≥ t}. Excursion probability pn(x) = Φ((mn(x)-t)/√kn(x,x)) underpins performance metrics (precision, sensitivity, RMSEΓ, RMSEp).
  - Quick check question: For a binary classification task where excursion set membership is the positive class, how would you derive the optimal classifier threshold on pn(x)?

## Architecture Onboarding

- **Component map:**
  1. **GP Model Layer** (kergp R package): Tanimoto kernel for binary fingerprints → outputs mn(x), kn(x,x')
  2. **Acquisition Layer**: CRPSγ1, CRPSγ2 (pointwise), ICRPSγ1, ICRPSγ2 (SUR) using Theorem 2-3 formulas
  3. **Sequential Loop**: Initial training (n=30) → candidate selection → observe Zn+1 → update GP via kriging formulas
  4. **Evaluation Layer**: CRPS metrics, precision, sensitivity on held-out validation (M=100)

- **Critical path:**
  1. Encode molecules → Morgan fingerprints (2048 bits, radius 3)
  2. Split data: training / candidate / validation
  3. Fit GP with Tanimoto kernel (MLE hyperparameters)
  4. Loop: compute acquisition values → select x* → observe → update GP
  5. Evaluate on validation set each iteration

- **Design tradeoffs:**
  - CRPSγ1 vs CRPSγ2: γ1 optimizes precision (indicator weight), γ2 optimizes sensitivity (Gaussian weight); σγ controls tradeoff width
  - Pointwise vs SUR: Pointwise is faster but myopic; SUR considers global uncertainty reduction at computational cost
  - Tanimoto vs Gaussian kernels: Tanimoto outperforms on binary fingerprints, especially with small training sets (Supplementary Table 1)

- **Failure signatures:**
  - All points classified as excursion: threshold too low or variance underestimated
  - High precision, near-zero sensitivity: model too conservative, not exploring threshold region
  - Flat acquisition function: hyperparameter estimation failed or kernel inappropriate
  - SUR not decreasing: numerical integration issues or update formula bug
  - Performance worse than random: weighting γ or threshold mismatched to actual target region

- **First 3 experiments:**
  1. **Baseline on synthetic data**: Validate implementation using synthetic Photoswitch (known ground truth). Compare all four CRPS criteria vs. random over 50 iterations, tracking CRPSγ1, CRPSγ2, precision, sensitivity.
  2. **Hyperparameter sensitivity**: Vary σγ for γ2-based criteria (try {0.25, 0.5, 1.0, 2.0} × std(y)) and observe precision/sensitivity tradeoffs across different threshold quantiles (0.7, 0.8, 0.9).
  3. **Kernel validation**: On real Photoswitch data, compare Tanimoto vs Gaussian vs Exponential kernels across 10%/20%/30% training splits to confirm Tanimoto superiority before full sequential runs.

## Open Questions the Paper Calls Out

### Open Question 1
Can multivariate scoring rules be effectively adapted for targeted sequential design in a manner similar to the univariate CRPS-based criteria? The authors state, "Future work could explore further alternatives to the CRPS, including multivariate scoring rules." This study derives closed-form expressions only for univariate predictive distributions.

### Open Question 2
Does using the Cumulative Distribution Function (CDF) of the Gaussian weighting measure (γ2) offer performance advantages over the Probability Density Function (PDF) used in this study? The current PDF-based implementation behaves similarly to existing TIMSE methods. Alternative weighting measures could be explored, such as the corresponding CDF of the Gaussian γ2... This would result in a criterion that is less similar to TMSE and TIMSE.

### Open Question 3
Can the sensitivity of the CRPSγ1 criterion be improved by adjusting the threshold within the weighting measure? The current CRPSγ1 excels in precision but performs worse in sensitivity compared to CRPSγ2. We could adjust the threshold in the weighting measure to incorporate the region around the threshold, thereby enhancing the method's sensitivity.

### Open Question 4
Do k-step look-ahead strategies provide tangible efficiency gains over the myopic (one-step) strategies implemented here? Next, k-step look-ahead strategies could be explored as an alternative to myopic ones. The proposed selection criteria act greedily, optimizing only for the immediate next evaluation.

## Limitations
- Performance heavily depends on correct threshold selection t and weighting parameter σγ
- Closed-form expressions are derived specifically for Gaussian predictive distributions, limiting applicability to non-Gaussian settings
- Sequential design introduces exploration-exploitation tradeoffs that may not align with all practical objectives

## Confidence
**High Confidence**: The CRPS-based acquisition functions are mathematically well-defined with closed-form expressions (Theorem 2-3); the GP-Tanimoto kernel combination is established in chemoinformatics literature; synthetic data experiments provide ground truth validation.

**Medium Confidence**: Performance claims on real Photoswitch dataset (30% CRPSγ1 reduction, 10% precision gain) rely on single dataset evaluation; hyperparameter σγ=33 appears arbitrary without sensitivity analysis; Monte Carlo integration for SUR criteria may introduce numerical error not quantified.

**Low Confidence**: The universal applicability claim ("broadly applicable beyond chemistry") lacks diverse domain testing; weighting parameter calibration procedure is unspecified; comparison against all stated state-of-the-art methods may not control for computational budget differences.

## Next Checks
1. **Synthetic Ground Truth Validation**: Generate synthetic Photoswitch data with known f(x), run all four CRPS criteria vs. random selection over 50 iterations, verify the claimed 30% CRPSγ1 reduction and 10% precision gain.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary σγ for γ2-based criteria (try {0.25, 0.5, 1.0, 2.0} × std(y)) and threshold t (0.7, 0.8, 0.9 quantiles) to quantify precision-sensitivity tradeoffs and identify optimal parameter ranges.

3. **Cross-Domain Validation**: Apply the CRPS-based criteria to at least two additional domains (e.g., materials science or robotics) to test the claimed "broadly applicable beyond chemistry" assertion and evaluate performance consistency across different data types.