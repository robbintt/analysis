---
ver: rpa2
title: Towards Robust and Accurate Stability Estimation of Local Surrogate Models
  in Text-based Explainable AI
arxiv_id: '2501.02042'
source_url: https://arxiv.org/abs/2501.02042
tags:
- similarity
- measures
- synonymity
- adversarial
- weighting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the stability of local surrogate models in
  text-based explainable AI (XAI), focusing on the impact of similarity measures used
  to evaluate adversarial perturbations. The authors investigate various similarity
  measures (Jaccard, Kendall's Tau, Spearman's footrule, and RBO) for text-based ranked
  lists, finding that many are overly sensitive, leading to exaggerated instability
  estimates.
---

# Towards Robust and Accurate Stability Estimation of Local Surrogate Models in Text-based Explainable AI

## Quick Facts
- arXiv ID: 2501.02042
- Source URL: https://arxiv.org/abs/2501.02042
- Reference count: 23
- Key outcome: Standard similarity measures (Jaccard, Kendall's Tau, Spearman) are overly sensitive to semantically equivalent text perturbations in XAI stability evaluation, while synonymity weighting significantly improves accuracy.

## Executive Summary
This paper investigates the stability of local surrogate models in text-based explainable AI by examining how different similarity measures evaluate adversarial perturbations. The authors find that standard measures like Kendall's Tau and Jaccard are too sensitive, often registering semantically equivalent word substitutions (like "vomit" → "puked") as complete mismatches. To address this, they propose a synonymity weighting scheme that incorporates semantic similarity between features, significantly reducing false instability detections and providing more accurate robustness assessments of XAI methods.

## Method Summary
The authors evaluate stability of LIME explanations by generating adversarial perturbations to text documents and measuring similarity between original and perturbed explanations using various metrics. They employ a greedy search algorithm to find perturbations that maximize similarity decrease, testing nine different similarity measures including base versions of Jaccard, Kendall's Tau, Spearman's footrule, and RBO, plus weighted variants incorporating synonymity from GloVe embeddings. Experiments are conducted on two datasets (Twitter gender bias and symptoms-to-diagnosis) with DistilBERT classifiers, measuring attack success rates at different similarity thresholds.

## Key Results
- Standard measures like Kendall's Tau and Jaccard show near 100% attack success rates, indicating excessive sensitivity to minor perturbations
- RBO offers a better balance between sensitivity and robustness, with moderate attack success rates across thresholds
- Synonymity weighting drastically reduces false instability detections, especially for Jaccard (success rate drops from 0.88 to 0 at 50% threshold) and Spearman (from 0.83 to 0.02)
- The method becomes computationally expensive for longer documents, requiring ~125 days for full IMDB dataset on A6000 GPU

## Why This Works (Mechanism)

### Mechanism 1: Sensitivity of Standard Similarity Measures
Standard similarity measures are overly sensitive to minor, semantically equivalent perturbations in text-based XAI. These measures use strict equality for feature matching, treating semantically equivalent words like "vomit" → "puked" as complete mismatches, which registers maximal distance despite semantic equivalence. This strictness amplifies perceived instability.

### Mechanism 2: Synonymity Weighting for Accurate Comparison
Incorporating semantic synonymity into similarity measures significantly reduces false instability detections. The synonymity weighting scheme adjusts the penalty for mismatched features using cosine similarity from GloVe embeddings. For example, ("vomit", "puked") would have a high synonymity score, reducing its contribution to overall distance, while dissimilar pairs are penalized more heavily.

### Mechanism 3: Balanced Evaluation via Rank-Biased Overlap (RBO)
RBO offers better balance between sensitivity and perturbed document quality compared to other standard measures. It assigns progressively less weight to features lower in the ranked list, aligning with practical XAI use where top features are most important. Its inherent weighting makes it less prone to extreme sensitivity while avoiding the coarse granularity of Jaccard with synonymity weighting.

## Foundational Learning

- **Concept: Adversarial Attacks on XAI**
  - Why needed here: Understanding that attackers can manipulate an AI's explanation without changing its prediction is fundamental to grasping the motivation and nature of the proposed defense.
  - Quick check question: If an AI model's prediction for a perturbed input remains the same as the original, but its LIME explanation changes significantly, has an adversarial attack on XAI succeeded?

- **Concept: Local Surrogate Models (LIME)**
  - Why needed here: LIME is the specific XAI method used for experimentation. Understanding that it generates local, interpretable explanations for individual predictions is essential for seeing how similarity measures are applied.
  - Quick check question: Does LIME attempt to create a single, global explanation for an entire complex model, or does it create simple, local explanations for individual predictions?

- **Concept: Word Embeddings (e.g., GloVe)**
  - Why needed here: The paper's key contribution relies on using word embeddings to calculate synonymity. Understanding that words are represented as vectors where semantic similarity correlates with cosine distance is essential for comprehending the synonymity weighting mechanism.
  - Quick check question: In a word embedding space, would the vectors for "happy" and "joyful" likely have a higher cosine similarity than the vectors for "happy" and "car"?

## Architecture Onboarding

- **Component map**: Input Text -> DistilBERT Model -> LIME Explanation -> Adversarial Search -> Similarity Measure Module (Standard or Synonymity-Weighted) -> Evaluation against Threshold

- **Critical path**: The key function is `Similarity(Explanation_A, Explanation_B)`. An engineer should first trace how it's called in the adversarial search loop, then dive into implementations for standard measures, and finally examine the `Syn(a,b)` function and how its output integrates into modified formulas.

- **Design tradeoffs**:
  - Sensitivity vs. Robustness: Standard measures like Kendall's Tau are highly sensitive, potentially overestimating risk. Synonymity-weighted Jaccard is less sensitive, potentially underestimating risk.
  - Complexity vs. Explainability: Synonymity weighting adds complexity and dependency on external embedding models but provides more semantically accurate comparison.
  - Measure vs. Dataset: RBO requires tuning parameter `p`. The paper suggests RBO provides good balance but implies `p` may need adjustment based on specific context.

- **Failure signatures**:
  - Misleading Stability Assessment: Concluding XAI method is highly unstable based solely on standard Kendall's Tau when instability is driven by semantically trivial substitutions.
  - Ineffective Synonymity: If chosen word embeddings are poor or context-unaware, `Syn(a,b)` function will return low scores for true synonyms, and weighting will fail to correct similarity score.
  - Computational Infeasibility: Method becomes computationally expensive on long texts, making it impractical for datasets with large documents.

- **First 3 experiments**:
  1. Implement four standard similarity measures and run adversarial attacks on Twitter Gender Bias dataset subset to validate setup and reproduce high success rates for Kendall's Tau.
  2. Implement synonymity weighting logic for Jaccard and Spearman using GloVe embeddings and verify drastic reduction in calculated distance and attack success rate.
  3. Test RBO with range of `p` values on same data to confirm higher `p` values make measure coarser and observe relative insensitivity to synonymity weighting.

## Open Questions the Paper Calls Out

### Open Question 1
Do these findings regarding similarity measure sensitivity generalize to XAI methods with lower inherent instability than LIME? The authors state that XAI methods with less inherent instability may see more useful results from measures like Kendall's Tau, and current conclusions may not apply to them.

### Open Question 2
Can synonymity weighting be effectively combined with intrinsic weighting parameters (such as RBO's $p$ parameter) to create superior hybrid measures? The paper notes that testing measures combining synonymity weighting with default weighting requires enough subjective decisions that they omit construction and testing of these hybrid measures.

### Open Question 3
Can superior estimates of synonymity, such as those incorporating part-of-speech checking or sense disambiguation, improve the accuracy of stability estimation? The authors list the "Optimality of the Synonymity Weighting Methods" as a limitation, noting that superior estimates of synonymity can probably be obtained with alternative methods.

## Limitations
- Computational expense is significant, particularly for longer documents where adversarial search becomes prohibitive
- Current implementation relies on static word embeddings that don't distinguish between parts of speech or multiple meanings
- Results may not generalize to XAI methods with lower inherent instability than LIME
- Optimal choice of RBO parameter `p` is context-dependent and not fully explored

## Confidence

**High Confidence**: The claim that standard similarity measures are overly sensitive to semantically equivalent perturbations is well-supported by experimental results showing near 100% attack success rates for Kendall's Tau and Jaccard across all thresholds.

**Medium Confidence**: The synonymity weighting mechanism's effectiveness is demonstrated, but its performance depends heavily on the quality and appropriateness of the underlying word embeddings. The paper doesn't extensively test different embedding models or contextual embeddings.

**Medium Confidence**: RBO's balance between sensitivity and robustness is demonstrated, but the optimal choice of parameter `p` is context-dependent and not fully explored across different datasets or explanation lengths.

## Next Checks

1. **Embedding Sensitivity Analysis**: Test the synonymity weighting mechanism using different word embedding models (e.g., GloVe vs. word2vec vs. contextual embeddings) to assess robustness to embedding choice.

2. **Parameter Sensitivity for RBO**: Systematically vary the RBO parameter `p` across a wider range (e.g., 0.3 to 0.95) on both datasets to identify optimal settings for different explanation lengths and contexts.

3. **Computational Optimization**: Implement and evaluate optimization strategies (e.g., early stopping, sampling-based search) to reduce the computational burden of the adversarial search, particularly for longer documents.