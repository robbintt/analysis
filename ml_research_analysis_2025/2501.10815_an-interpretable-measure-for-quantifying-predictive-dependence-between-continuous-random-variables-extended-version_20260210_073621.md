---
ver: rpa2
title: An Interpretable Measure for Quantifying Predictive Dependence between Continuous
  Random Variables -- Extended Version
arxiv_id: '2501.10815'
source_url: https://arxiv.org/abs/2501.10815
tags:
- predep
- measure
- association
- data
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PREDEP, a novel non-parametric measure for
  quantifying predictive dependence between continuous random variables X and Y. The
  measure is defined as the expected relative loss in predictive accuracy when the
  distribution of X is ignored in predicting Y, and it is bounded in [0,1], being
  zero if and only if X and Y are independent.
---

# An Interpretable Measure for Quantifying Predictive Dependence between Continuous Random Variables -- Extended Version

## Quick Facts
- **arXiv ID:** 2501.10815
- **Source URL:** https://arxiv.org/abs/2501.10815
- **Reference count:** 40
- **Key outcome:** Introduces PREDEP, a non-parametric measure for quantifying predictive dependence between continuous random variables X and Y, bounded in [0,1] with zero indicating independence.

## Executive Summary
This paper introduces PREDEP, a novel measure for quantifying predictive dependence between continuous random variables. PREDEP is defined as the expected relative loss in predictive accuracy when the distribution of X is ignored in predicting Y. The measure is non-parametric, bounded in [0,1], and captures arbitrary non-linear relationships. The authors propose a bootstrap-based method for estimating PREDEP from empirical data and evaluate it on over 90,000 real and synthetic datasets, benchmarking against leading alternatives.

## Method Summary
PREDEP quantifies predictive dependence by comparing the accuracy of predicting Y using its marginal distribution versus its conditional distribution given X. The measure is theoretically derived from the quadratic Rényi entropy and estimated using a bootstrap-based method that leverages Kernel Density Estimation on pairwise differences. The algorithm partitions X into bins, performs bootstrap sampling within each bin, and estimates conditional densities at zero to compute the relative predictive loss.

## Key Results
- PREDEP provides valuable insights in non-functional relationships where other measures may fail to capture important dependencies.
- PREDEP, MIC, and dcor tend to agree but capture different aspects of association, with PREDEP focusing on predictive capability.
- The asymmetry of PREDEP allows identification of which variable is more predictive of the other, potentially useful for causal discovery.

## Why This Works (Mechanism)

### Mechanism 1: Continuous Generalization of Proportional Error Reduction
PREDEP extends Goodman-Kruskal's τ_b (categorical association) to continuous variables by quantifying the relative improvement in predicting Y when X is known versus when X is ignored. The measure derives the "rate of correct assignment" for a continuous variable by taking the limit of a grid-based contingency table as grid spacing Δx, Δy → 0. This limit converges to the L₂ norm of the density functions (∫f²(y)dy). It compares the marginal prediction success rate (S_Y) against the conditional success rate (S_{Y|X}) to derive α_{Y|X} = (S_{Y|X} - S_Y)/S_{Y|X}.

### Mechanism 2: Convolution-Based Density Estimation
The paper avoids direct integration of squared conditional densities by re-framing the expectation E[f(Y)] as the probability density function of the difference of two independent copies of Y evaluated at zero. If W = Y₁ - Y₂ where Y₁, Y₂ ~ f_Y, the density of W at 0 is mathematically equivalent to the integral of the square of the density (∫f²). This allows the use of Kernel Density Estimation (KDE) on the distribution of pairwise differences (via Bootstrap sampling) rather than deriving analytical solutions for complex conditional distributions.

### Mechanism 3: Asymmetry for Causal/Predictive Direction
PREDEP is fundamentally asymmetric (α_{Y|X} ≠ α_{X|Y}), designed to capture which variable reduces the uncertainty of the other more effectively. The measure computes prediction loss in a specific direction. In non-bijective relationships (e.g., Y=X²), knowing X determines Y, but knowing Y leaves ambiguity about X. PREDEP reflects this by returning a higher score for X → Y than Y → X.

## Foundational Learning

**Concept: Quadratic Rényi Entropy**
- **Why needed here:** The theoretical limit of PREDEP relies on the L₂ norm of the density (∫f²), which is the exponent of the quadratic Rényi entropy. Understanding this helps distinguish PREDEP from Shannon-entropy-based measures (like Mutual Information).
- **Quick check question:** How does measuring the expected value of the density (E[f(Y)]) differ from measuring the expected value of the log-density (Shannon Entropy)?

**Concept: Goodman-Kruskal's τ_b**
- **Why needed here:** This is the categorical predecessor to PREDEP. Grasping the "proportional reduction in error" (PRE) interpretation for contingency tables is necessary to understand why PREDEP is framed as a predictive measure rather than just a correlation coefficient.
- **Quick check question:** In a contingency table, does τ_b measure linearity or the reduction in classification error?

**Concept: Kernel Density Estimation (KDE)**
- **Why needed here:** The algorithm uses KDE to estimate the density of the difference distribution at zero. A lack of understanding here leads to failure in tuning the bootstrap and kernel bandwidth steps.
- **Quick check question:** Why is KDE on the difference variable W=Y₁-Y₂ often more robust than trying to estimate the density of Y directly and squaring it?

## Architecture Onboarding

**Component map:**
Input -> Binning Engine -> Bootstrap Generator -> Density Evaluator -> Aggregator

**Critical path:** The estimation of the conditional component S_{Y|X}. The algorithm must partition X into bins, filter Y values into these bins, and perform bootstrap KDE on each subset. If bins are too sparse, the KDE estimation fails.

**Design tradeoffs:**
- **Binning Strategy:** The paper suggests k=√N. Smaller k loses resolution (bias); larger k results in empty bins or insufficient data for bootstrap in each bin (variance).
- **Bootstrap Size (n_b):** Larger n_b increases precision but computational cost scales linearly.

**Failure signatures:**
- **Flat Distribution:** If Y is Uniform, S_Y is low, but PREDEP might struggle to show relative improvement if density is constant.
- **Sparse Bins:** If N is small, the conditional bins contain too few points to form a meaningful difference distribution for KDE.
- **Discrete Inputs:** The theoretical limit assumes continuous variables; heavily quantized data may not converge correctly.

**First 3 experiments:**
1. **Asymmetry Validation:** Generate synthetic data Y = X² + ε where X ∈ [-1, 1]. Verify that α_{Y|X} > α_{X|Y} significantly.
2. **Independence Test:** Shuffle Y relative to X in a real dataset. Confirm α ≈ 0 (or drops significantly compared to unshuffled).
3. **Binning Sensitivity:** Run the estimator on a fixed dataset varying k (e.g., log(N) to √N to N/10) to visualize the stability of the score.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the asymmetry of PREDEP provide a statistically significant advantage in identifying causal direction over symmetric association measures?
- **Basis in paper:** The authors state that the measure's asymmetry allows identification of which variable is more predictive, suggesting it "may be useful in exploratory analysis aimed at discovering potential causal relationships."
- **Why unresolved:** While the paper demonstrates asymmetry on synthetic examples (e.g., parabolic relationships), it does not benchmark PREDEP on standard causal discovery datasets (like the Tübingen Cause-Effect Pairs) to verify if this property reliably indicates causality in practice.
- **What evidence would resolve it:** An empirical study measuring the accuracy of causal direction classification using α_{Y|X} vs α_{X|Y} compared to established causal inference methods.

### Open Question 2
- **Question:** How does PREDEP perform when extended to measure dependence between high-dimensional random vectors using neural density estimators?
- **Basis in paper:** The authors note that while extending PREDEP to random vectors is theoretically simple, it requires accurate density estimators for multidimensional data, specifically suggesting Mixture Density Networks or Normalizing Flows as potential implementations.
- **Why unresolved:** The current work focuses exclusively on bivariate continuous data using a bootstrap method and kernel density estimation, which suffer from the curse of dimensionality.
- **What evidence would resolve it:** Implementation of PREDEP using Normalizing Flows and evaluation of its performance on multivariate benchmark datasets against methods like HSIC or MMD.

### Open Question 3
- **Question:** How sensitive is the empirical PREDEP estimator to the choice of binning strategy and bandwidth selection in finite samples?
- **Basis in paper:** The estimation method relies on Hierarchical Clustering with k=√N clusters to determine bins, a heuristic the authors admit is "not theoretically rigorous."
- **Why unresolved:** The paper does not analyze the variance or bias introduced by the binning heuristic or the kernel density estimation bandwidth, nor does it compare the stability of the proposed bootstrap confidence intervals against parametric assumptions.
- **What evidence would resolve it:** A sensitivity analysis showing the variance of the PREDEP estimate across different binning strategies (k values) and bandwidth selectors.

## Limitations
- The bootstrap-based estimation method may struggle with small sample sizes where conditional bins contain insufficient data for reliable KDE estimation.
- The theoretical foundation relies on quadratic Rényi entropy, which differs fundamentally from Shannon-entropy-based measures, potentially limiting direct comparability.
- The practical utility of PREDEP in real-world causal discovery scenarios remains unproven, as the paper does not demonstrate application beyond synthetic examples of non-bijective relationships.

## Confidence

**High Confidence (8/10):** The theoretical derivation connecting grid-based contingency measures to continuous density norms is mathematically sound. The asymptotic properties (0 for independence, bounded in [0,1]) are well-established.

**Medium Confidence (6/10):** The bootstrap KDE estimation procedure for conditional densities is methodologically reasonable but lacks extensive empirical validation across diverse data distributions and sample sizes.

**Low Confidence (4/10):** The practical utility of PREDEP in real-world causal discovery scenarios remains unproven, as the paper does not demonstrate application beyond synthetic examples of non-bijective relationships.

## Next Checks

1. **Sample Size Sensitivity Analysis:** Systematically evaluate PREDEP's performance across datasets ranging from N=50 to N=10,000, measuring estimation stability and bias as a function of bin count and bootstrap size.

2. **Comparison on Structured Non-Functional Relationships:** Test PREDEP against alternatives (MIC, dcor) on datasets with known non-functional dependencies (e.g., circular, cross-shaped distributions) to validate claims about capturing different aspects of association.

3. **Causal Discovery Benchmark:** Apply PREDEP to established benchmark datasets for causal discovery (e.g., Tübingen cause-effect pairs) to assess whether the asymmetry property reliably indicates predictive direction in real-world scenarios.