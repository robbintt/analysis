---
ver: rpa2
title: 'CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection
  in Time-Series Streams'
arxiv_id: '2508.21273'
source_url: https://arxiv.org/abs/2508.21273
tags:
- data
- anomaly
- detection
- fine-tuning
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CALM introduces a continuous, adaptive, and LLM-mediated framework
  for anomaly detection in non-stationary time-series streams. The framework uses
  Apache Beam for scalable, stateful processing, TimesFm for forecasting-based detection,
  and an LLM-as-a-Judge for semantic data curation.
---

# CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams

## Quick Facts
- arXiv ID: 2508.21273
- Source URL: https://arxiv.org/abs/2508.21273
- Reference count: 13
- Primary result: CALM improves ROC AUC on most TSB-UAD datasets compared to static TimesFm baseline through adaptive fine-tuning guided by LLM judgments.

## Executive Summary
CALM introduces a streaming framework for anomaly detection in non-stationary time-series that combines TimesFm forecasting, quantile-based thresholds, and an LLM-as-a-Judge to curate fine-tuning data. The system uses Apache Beam for stateful, scalable processing and continuously adapts to concept drift by fine-tuning on anomalies classified as meaningful pattern shifts (KEEP) rather than transient noise (REMOVE). Evaluated on the TSB-UAD benchmark, CALM demonstrates improved detection performance across most datasets compared to a static pre-trained model, particularly in cases where the baseline model struggles.

## Method Summary
CALM processes time-series streams using Apache Beam's stateful API, maintaining ordered buffers and handling out-of-order events via watermarks. TimesFm generates quantile forecasts (q20, q30, q70, q80), and anomalies are detected using IQR-based thresholds that bound detection to forecast uncertainty rather than fixed deviations. Detected anomalies are sent to an LLM (Gemini 1.5 Flash) for semantic classification as KEEP (sustained shift) or REMOVE (transient noise). KEEP-labeled anomalies accumulate in batches, triggering 1-epoch fine-tuning jobs on the updated dataset. The new model artifact is dynamically swapped into the pipeline via side-input monitoring, enabling near real-time adaptation.

## Key Results
- ROC AUC improved on most TSB-UAD datasets compared to static TimesFm baseline
- Largest gains (+0.35, +0.25) occurred where original model was near chance performance
- Single epoch of fine-tuning optimal; additional epochs cause overfitting
- Noise augmentation mitigates overfitting in later epochs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Quantile-based anomaly thresholds reduce false positives under non-Gaussian error distributions.
- **Mechanism:** TimesFm produces quantile forecasts (q20, q30, q70, q80). The system computes IQR from these quantiles and flags anomalies when actual values fall outside [Q1 − 1.5×IQR, Q3 + 1.5×IQR]. This bounds the detection region to the forecast's internal uncertainty rather than a fixed standard deviation.
- **Core assumption:** The forecasting model's quantile outputs are well-calibrated; residuals are stationary within the context window.
- **Evidence anchors:** [Section 3.3] "We compute the interquartile range (IQR) from these quantiles, and flag a data point as anomalous if the actual value lies outside the range... This statistical approach is less sensitive to non-Gaussian error distributions." [Corpus] THEMIS (arXiv:2510.03911) notes concept drift and noise make defining "normal" behavior difficult, supporting the need for dynamic thresholds.
- **Break condition:** If quantile forecasts become miscalibrated (e.g., after domain shift), threshold bounds widen or contract inappropriately, degrading detection precision.

### Mechanism 2
- **Claim:** LLM semantic judgment filters transient noise from meaningful pattern shifts, improving fine-tuning data quality.
- **Mechanism:** When an anomaly is detected, the LLM receives a structured prompt containing: (1) outlier details (timestamp, actual/predicted values, bounds), (2) surrounding data points before and after, and (3) statistical context (mean/std before and after). The LLM returns KEEP (sustained shift) or REMOVE (transient noise) with reasoning. Only KEEP-labeled anomalies enter the fine-tuning buffer.
- **Core assumption:** The LLM can reliably distinguish transient events from sustained shifts based on local context; prompt format does not bias judgments.
- **Evidence anchors:** [Abstract] "LLM-as-a-Judge component... provides semantic, context-aware judgments on detected anomalies to curate a high-quality training dataset, deciding whether an anomaly represents transient noise or a meaningful pattern shift." [Section 3.5] Qualitative example shows LLM correctly identifying a CPU spike followed by new baseline as KEEP. [Corpus] Weak corpus evidence for LLM-as-judge in time-series specifically; this mechanism is not validated in neighbors.
- **Break condition:** If LLM judgments become inconsistent (prompt sensitivity) or systematically biased toward KEEP/REMOVE, the fine-tuning dataset degrades—either overfitting to noise (too many KEEPs) or failing to adapt (too many REMOVEs).

### Mechanism 3
- **Claim:** Continuous fine-tuning on curated data improves ROC AUC by specializing the generalist foundation model to domain-specific drift.
- **Mechanism:** KEEP-labeled anomalies are buffered until a contiguous batch of size N forms. A fine-tuning job is triggered on 80/20 split of this data. The updated model is saved to storage; Apache Beam side-input monitors this location and swaps the model in-flight via callback in the model handler. The next inference cycle uses the new weights.
- **Core assumption:** A single epoch of fine-tuning is sufficient to capture drift without overfitting; the streaming pipeline can tolerate the latency of model swap.
- **Evidence anchors:** [Section 4.3] "The most substantial performance gain is achieved within the very first epoch... subsequent epochs yield marginal improvements, suggesting that the model begins to overfit." [Section 4.3] ROC AUC improved on most TSB-UAD datasets; top gains (+0.35, +0.25) occurred where original model was near chance. [Section 4.4] Noise augmentation flattens the performance curve, mitigating overfitting in later epochs.
- **Break condition:** If fine-tuning data is insufficient or batch trigger fires too frequently, the model overfits to recent anomalies, narrowing prediction intervals and missing future outliers (quantile collapse). Performance degradation observed on already-high-performing datasets (Bottom 10 in Table 2) suggests this risk.

## Foundational Learning

- **Concept: Time-Series Foundation Models (TSFMs) and Patching**
  - **Why needed here:** CALM builds on TimesFm, a decoder-only TSFM that partitions input into "patches" treated as tokens. Without understanding patching, you cannot reason about context length, horizon selection, or why TimesFm handles variable-length inputs.
  - **Quick check question:** Given a 512-point context window with patch size 32, how many tokens does TimesFm process?

- **Concept: Concept Drift and Online Adaptation**
  - **Why needed here:** The paper's core problem is that offline-trained models degrade when data distributions shift. CALM's entire value proposition is automated adaptation to drift via LLM-guided fine-tuning.
  - **Quick check question:** If statistical drift detection (e.g., KS test) triggers on harmless noise, what failure mode results? How does CALM's semantic approach differ?

- **Concept: Stateful Stream Processing (Watermarks, Timers, Side Inputs)**
  - **Why needed here:** CALM runs on Apache Beam and uses ordered state buffers, watermark-driven timers, and side inputs for dynamic model swapping. Without this, you cannot debug late data handling or understand the model swap mechanism.
  - **Quick check question:** An event with timestamp t=100 arrives after the watermark has passed t=100. What happens to it in CALM's windowing logic?

## Architecture Onboarding

- **Component map:** Ingestion → Ordered State Buffer → Gap-Fill/Interpolate → TimesFm Inference → Anomaly Detection (IQR threshold) → LLM-as-a-Judge (Gemini 1.5 Flash) → [KEEP] → Batch Buffer → Fine-Tuning Job → Model Artifact Storage → Side-Input Monitor → In-Flight Model Swap

- **Critical path:** The loop from LLM judgment → batch accumulation → fine-tuning → model swap. Latency here determines adaptation speed. If batch size N is too large, drift accumulates before adaptation; if too small, fine-tuning is unstable.

- **Design tradeoffs:**
  - **Prediction horizon (16–128):** Shorter horizons may be more precise; TimesFm truncates from fixed 128 output. Paper shows robustness across horizons (Figure 6a).
  - **Fine-tuning epochs:** 1 epoch is optimal; more epochs cause overfitting (Figure 6b).
  - **Noise augmentation:** Reduces overfitting but may lower peak performance; requires tuning noise_level hyperparameter.
  - **LLM latency vs accuracy:** Gemini 1.5 Flash chosen for speed; more capable models increase cost and latency.

- **Failure signatures:**
  - **Quantile collapse:** After repeated fine-tuning, predicted intervals [q0.1, q0.9] shrink → model overfits to recent "normal" → misses true anomalies.
  - **Delayed judgment starvation:** If anomalies occur at window ends and insufficient future context arrives, LLM evaluation is deferred indefinitely (timer-based mitigation in Section 3.4).
  - **Model swap race condition:** If fine-tuning writes new model while inference is loading, ensure atomic file replacement or versioning.
  - **Side-input staleness:** If side-input polling interval is longer than fine-tuning frequency, pipeline runs multiple cycles on outdated weights.

- **First 3 experiments:**
  1. **Baseline replication:** Run static TimesFm on a TSB-UAD dataset (first 80% train, last 20% test) with IQR-based thresholds. Confirm ROC AUC matches paper's "Orig" column.
  2. **LLM judge isolation:** Manually inspect 20 detected anomalies with their LLM prompts and judgments. Verify KEEP/REMOVE labels align with semantic intuition (transient vs sustained shift).
  3. **Single-cycle fine-tuning:** Trigger one fine-tuning epoch on KEEP-labeled data from experiment 2. Compare ROC AUC on held-out 20% before and after. Check for quantile narrowing by comparing forecast interval widths.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the CALM framework be effectively extended to multivariate time-series by integrating models like Moirai or DualLMAD?
- **Basis in paper:** [explicit] Section 5 identifies the current limitation to univariate series and proposes extending to multivariate data.
- **Why unresolved:** The current TimesFm 1.0 backbone is univariate, and the LLM Judge logic currently lacks the capacity to reason about inter-variable relationships.
- **Evidence:** Successful integration of a multivariate-capable foundation model and LLM prompts that effectively analyze correlations, validated on multivariate benchmarks.

### Open Question 2
- **Question:** Can Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA reduce the operational cost and latency of the continuous adaptation loop?
- **Basis in paper:** [explicit] Section 5 suggests exploring PEFT to mitigate the costs associated with full model fine-tuning.
- **Why unresolved:** The current implementation uses full fine-tuning, which creates a trade-off between adaptation frequency and resource consumption.
- **Evidence:** A comparative study measuring ROC AUC, training time, and monetary cost between full fine-tuning and LoRA-based adaptation in the streaming pipeline.

### Open Question 3
- **Question:** Does an adaptive fine-tuning trigger based on the rate of "KEEP" decisions improve responsiveness to concept drift compared to fixed-size batching?
- **Basis in paper:** [explicit] Section 5 proposes developing a "more intelligent trigger" based on "KEEP" decision rates to signal significant concept drift.
- **Why unresolved:** The existing system relies on collecting fixed-size batches, which may delay updates during rapid drift or waste resources during stable periods.
- **Evidence:** Evaluation of model recovery speed and detection accuracy using a dynamic trigger versus a static batch size across datasets with varying drift velocities.

## Limitations

- **Quantile Forecast Calibration:** Effectiveness depends on well-calibrated TimesFm quantile forecasts, which are not validated under significant domain shifts.
- **LLM-as-a-Judge Generalization:** Limited quantitative validation of LLM consistency and impact on downstream performance.
- **Overfitting vs. Adaptation Trade-off:** Performance gains plateau and degrade after first epoch; optimal noise augmentation level is dataset-dependent.

## Confidence

- **High Confidence:** The mechanism of using an LLM to semantically classify anomalies as KEEP or REMOVE is clearly specified and demonstrated.
- **Medium Confidence:** The claim that continuous fine-tuning on curated data improves ROC AUC is supported by TSB-UAD experiments but shows dataset-dependent results.
- **Low Confidence:** The core claim that IQR-based threshold mechanism is robust to non-Gaussian error distributions relies on untested assumption of well-calibrated quantile forecasts.

## Next Checks

1. **Quantile Calibration Analysis:** For a TSB-UAD dataset, analyze TimesFm's quantile forecast calibration by computing prediction interval coverage rates before and after fine-tuning.

2. **LLM Consistency Study:** Take held-out anomalies and have LLM evaluate them, then perturb prompts and re-evaluate to measure consistency of KEEP/REMOVE judgments.

3. **Ablation on Fine-tuning Frequency:** Run CALM with varying batch sizes (N=1, 10, 50) on high-drift dataset to determine optimal trade-off between adaptation speed and stability.