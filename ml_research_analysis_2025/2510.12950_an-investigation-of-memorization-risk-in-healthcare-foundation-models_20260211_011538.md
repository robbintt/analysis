---
ver: rpa2
title: An Investigation of Memorization Risk in Healthcare Foundation Models
arxiv_id: '2510.12950'
source_url: https://arxiv.org/abs/2510.12950
tags:
- memorization
- information
- data
- codes
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates memorization risks in foundation models
  trained on electronic health records (EHRs), focusing on privacy concerns when sensitive
  patient information could be exposed. The authors introduce a suite of black-box
  evaluation tests to assess privacy-related memorization risks in EHR foundation
  models, covering both generative and embedding-based memorization.
---

# An Investigation of Memorization Risk in Healthcare Foundation Models

## Quick Facts
- arXiv ID: 2510.12950
- Source URL: https://arxiv.org/abs/2510.12950
- Reference count: 40
- Primary result: Introduces black-box tests to detect memorization risks in EHR foundation models, showing rare diagnoses and elderly patients are more vulnerable to privacy leakage.

## Executive Summary
This paper addresses the critical privacy concern of patient data memorization in foundation models trained on electronic health records (EHRs). The authors develop a comprehensive framework consisting of six black-box evaluation tests (T1-T6) to assess both generative and embedding-based memorization risks. The framework distinguishes between harmful patient-level memorization that could expose sensitive information and benign population-level generalization that is clinically useful. When applied to a publicly available EHR foundation model, the tests reveal that while minimal patient information doesn't directly expose sensitive attributes, more detailed prompts can trigger leakage of high-risk medical information, particularly for rare diagnoses and elderly patients.

## Method Summary
The authors introduce a systematic framework for evaluating privacy-related memorization risks in EHR foundation models. The framework includes six black-box tests that assess different aspects of memorization: patient re-identification from embeddings (T1-T3), generation of sensitive information (T4-T6), and a population-level metric (L_P) to differentiate harmful memorization from useful generalization. The tests use controlled prompts with minimal patient information to probe whether models can generate or reveal sensitive medical attributes. The framework is designed to be model-agnostic and applicable to various EHR foundation models, though the empirical evaluation was conducted on a single benchmark model (EHRMamba2).

## Key Results
- Minimal patient information (e.g., age) does not directly reveal sensitive attributes, but more detailed prompts can trigger leakage of high-risk medical information
- Rare diagnoses and elderly patients show higher vulnerability to privacy risks
- The framework successfully distinguishes between harmful patient-level memorization and benign population-level generalization
- Embedding-based attacks (T1-T3) show lower success rates than generative attacks (T4-T6) in retrieving sensitive information

## Why This Works (Mechanism)
The framework works by systematically probing models with controlled inputs containing minimal patient information and measuring whether the model can generate or reveal sensitive medical attributes. The black-box approach allows assessment without requiring access to model internals, making it practical for real-world deployment scenarios where model transparency may be limited. The distinction between different test types (re-identification vs. generation) captures various memorization mechanisms, while the population-level metric provides context for interpreting whether memorization represents actual privacy risk or clinically useful generalization.

## Foundational Learning

### Electronic Health Records (EHRs)
**Why needed**: Understanding the structure and content of medical data that models are trained on
**Quick check**: Can you identify common EHR data types like diagnoses, procedures, medications, and clinical notes?

### Foundation Models in Healthcare
**Why needed**: Recognizing how large-scale pretraining on EHR data creates models that can be adapted for multiple clinical tasks
**Quick check**: What distinguishes foundation models from task-specific models in healthcare applications?

### Privacy vs. Utility Trade-off
**Why needed**: Balancing the need for models to learn useful patterns while protecting patient confidentiality
**Quick check**: How do you distinguish between memorization that serves clinical purposes versus memorization that creates privacy risks?

## Architecture Onboarding

**Component Map**: EHR Foundation Model -> Black-Box Tests (T1-T6) -> Privacy Risk Assessment -> Population-Level Metric

**Critical Path**: Model training with EHR data → Application of T1-T6 tests → Analysis of success rates → Determination of privacy risk level → Interpretation using L_P metric

**Design Tradeoffs**: The black-box approach prioritizes practical deployability over comprehensive analysis but may miss some memorization patterns detectable only through white-box methods. The framework balances sensitivity to privacy risks with avoiding false positives from benign generalization.

**Failure Signatures**: High success rates in T4-T6 with low L_P scores indicate harmful memorization. Conversely, low success rates across all tests with high L_P scores suggest minimal privacy risk but potentially limited clinical utility.

**3 First Experiments**:
1. Apply T1 test to assess embedding-based re-identification using minimal patient age information
2. Run T4 test with controlled prompts to evaluate generation of sensitive diagnoses
3. Calculate L_P metric to determine whether observed memorization represents harmful privacy risk or useful generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do memorization risks differ across various EHR foundation model architectures beyond the specific model tested?
- Basis in paper: The authors state in the Discussion that a "follow up study will investigate such risks across broader model categories and stakeholder perspectives."
- Why unresolved: The empirical evaluation was restricted to a single benchmark model (EHRMamba2).
- What evidence would resolve it: Applying the T1-T6 tests to encoder-based models like BEHRT or CLMBR-D and comparing leakage profiles.

### Open Question 2
- Question: What are the most effective mitigation strategies to reduce memorization in EHR models while maintaining clinical generalization?
- Basis in paper: The Discussion mentions that developers can use these tests to "reduce memorization during training" and build "mitigation strategies," but does not propose or test specific methods.
- Why unresolved: The paper establishes a risk detection framework but does not evaluate the trade-offs of specific defense mechanisms.
- What evidence would resolve it: Empirical results showing privacy score reductions (T1-T6) and downstream task performance after applying defenses like differential privacy or deduplication.

### Open Question 3
- Question: How does the selection of "sensitive attributes" impact the generalizability of risk assessments across different deployment contexts?
- Basis in paper: Section 3.2 notes that the specific codes selected (e.g., infectious disease, substance abuse) are "representatives" and "can be different depending on the setting."
- Why unresolved: The framework relies on a fixed list of stigmatized conditions which may not capture all context-specific privacy norms.
- What evidence would resolve it: Evaluation of the framework using alternative, context-driven definitions of sensitive medical codes.

## Limitations
- Evaluation was conducted on a single publicly available EHR foundation model, limiting generalizability across architectures
- Black-box approach may miss memorization patterns detectable only through white-box analysis
- Simulated sensitive information may not fully capture the complexity of real patient data

## Confidence
- **High confidence**: The methodology for designing black-box evaluation tests is sound and reproducible
- **Medium confidence**: Empirical findings regarding rare diagnoses and elderly patient vulnerability are supported but may be dataset-dependent
- **Medium confidence**: Distinction between harmful memorization and benign generalization is conceptually valid but may require refinement

## Next Checks
1. Apply the evaluation framework to multiple foundation models with different architectures (transformers vs. recurrent networks) to assess robustness of findings
2. Conduct white-box analysis of model weights and attention patterns to identify memorization undetectable through black-box testing
3. Validate the framework using real patient data from multiple healthcare institutions with varying data collection practices