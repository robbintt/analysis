---
ver: rpa2
title: 'SolidMark: Evaluating Image Memorization in Generative Models'
arxiv_id: '2503.00592'
source_url: https://arxiv.org/abs/2503.00592
tags:
- memorization
- image
- training
- images
- mark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SOLIDMARK, a novel method for evaluating
  image memorization in diffusion models. The method works by embedding random scalar
  keys as grayscale borders around training images during training.
---

# SolidMark: Evaluating Image Memorization in Generative Models

## Quick Facts
- arXiv ID: 2503.00592
- Source URL: https://arxiv.org/abs/2503.00592
- Authors: Nicky Kriplani; Minh Pham; Gowthami Somepalli; Chinmay Hegde; Niv Cohen
- Reference count: 28
- Primary result: Introduces SOLIDMARK, a novel method for evaluating pixel-level image memorization in diffusion models using random scalar border keys

## Executive Summary
This paper introduces SOLIDMARK, a novel method for evaluating image memorization in diffusion models. The method works by embedding random scalar keys as grayscale borders around training images during training. At evaluation time, the model is prompted to outpaint these borders, and the accuracy of the predicted keys serves as a per-image memorization score. SOLIDMARK addresses key limitations of existing metrics, such as dataset-dependent biases and inability to detect pixel-level memorization. The authors demonstrate that SOLIDMARK can evaluate fine-grained pixel-level memorization and re-evaluate existing memorization mitigation techniques, showing that they do not significantly reduce memorization when measured by SOLIDMARK. Additionally, they pretrain and release a foundation model injected with SOLIDMARK's patterns to facilitate further research.

## Method Summary
SolidMark evaluates pixel-level memorization in diffusion models by embedding random scalar keys as grayscale borders around training images. During training, each image receives a unique random border intensity (key). At evaluation, the model is prompted to outpaint the masked border region. The absolute difference between predicted and true key values determines memorization scores. The method uses a modified RePaint algorithm that decodes to pixel space and re-encodes every 10 steps to maintain mask constraints. This approach isolates data storage from semantic inference, enabling detection of fine-grained pixel-level memorization that traditional metrics miss.

## Key Results
- SolidMark successfully detects fine-grained pixel-level memorization in diffusion models
- Existing inference-time mitigation techniques (GNI, RT, CWR) show negligible reduction in SolidMark scores
- Standard metrics like SSCD and ℓ₂ fail to capture fine-grained memorization reductions
- SolidMark outperforms existing metrics on datasets with high monochromatic content

## Why This Works (Mechanism)

### Mechanism 1: Key-Query Association via Random Borders
Embedding random scalar keys as grayscale borders creates a proxy for memorization that isolates data storage from semantic inference. During training, the model maps an input image to a random border value. Since the key is semantically unrelated to the image, the model cannot predict it using general knowledge; it must rely on rote memorization of the specific training instance. At evaluation, successful retrieval of the border value indicates the model has encoded the specific image-key pair. This mechanism assumes the model treats the border as a consistent feature of image identity rather than noise to be ignored.

### Mechanism 2: Pixel-Level Sensitivity (Fine-Grained Memory)
The method captures pixel-level (eidetic) memorization rather than reconstructive (semantic) memorization. SolidMark evaluates the model's ability to recall the exact border intensity. The authors show that minor, non-semantic perturbations to the query image (small rotations, blurring) significantly degrade the model's ability to predict the key. This suggests the memory trace relies on exact pixel configurations rather than high-level semantic understanding. The mechanism assumes semantic features are robust to small geometric transformations, whereas rote pixel memorization is brittle.

### Mechanism 3: Inference-Time Mitigation Invariance
Text-based inference-time mitigations are ineffective against pixel-level memorization because the retrieval is driven by visual cues, not text prompts. Mitigation techniques like Gaussian Noise at Inference (GNI) or Random Token Replacement (RT) alter the conditioning but leave the visual denoising process largely intact. SolidMark reveals that the model still retrieves the memorized border because the visual "query" (the image to be outpainted) remains the primary trigger. The mechanism assumes the retrieval process for pixel-exact memories is decoupled from the text encoder pathway targeted by these mitigations.

## Foundational Learning

- **Concept: Diffusion Inpainting/Outpainting**
  - Why needed here: SolidMark relies on prompting the model to generate a masked region (the border) conditioned on the unmasked image.
  - Quick check question: Can you explain how a diffusion model reconstructs a masked region using the reverse denoising process while keeping the unmasked region fixed?

- **Concept: Eidetic vs. Reconstructive Memorization**
  - Why needed here: The paper re-evaluates mitigation techniques by distinguishing between replicating exact pixels (Eidetic) vs. semantic content (Reconstructive).
  - Quick check question: If a model generates an image of a specific copyrighted painting but changes the lighting and crop, has it committed eidetic memorization according to this paper's definition?

- **Concept: Distance Metrics & Thresholds (ℓ₂, SSCD)**
  - Why needed here: The paper critiques existing metrics for biases and introduces a scalar threshold approach.
  - Quick check question: Why does the paper argue that a 95th percentile scoring function might fail to capture fine-grained reductions in memorization?

## Architecture Onboarding

- **Component map:** Data Augmentor -> Diffusion Training Loop -> Evaluation Pipeline (Query -> Outpainting -> Metric)
- **Critical path:** Maintaining the integrity of the Keymap k(x). If the association between an image and its specific random border is lost during preprocessing, evaluation is impossible.
- **Design tradeoffs:**
  - Border Thickness (p): Thinner borders are less intrusive but may provide a weaker signal. Paper recommends p=16 or 4.
  - Color Space: The paper attempted RGB borders but found models collapsed them to grayscale; sticking to scalar grayscale is more robust.
  - Duplication Handling: SolidMark assigns different keys to duplicate images by default, potentially undercounting memorization from data duplication.
- **Failure signatures:**
  - High Baseline Scores: If δ is too loose, random chance creates false positives.
  - Monochromatic Collapse: If the model simply outputs an "average" gray border for all images, check if the training border variance was too low.
- **First 3 experiments:**
  1. Sanity Check: Finetune on a tiny dataset (100 images) with high duplication. Verify SolidMark reports high memorization (low distance).
  2. Metric Comparison: Run standard inference-time mitigation (e.g., GNI) and compare the drop in SSCD scores vs. SolidMark scores to verify the "visual cue dominance" hypothesis.
  3. Perturbation Ablation: Apply small rotations to query images and plot the degradation in key prediction accuracy to confirm pixel-level sensitivity.

## Open Questions the Paper Calls Out

- **Question:** Can novel mitigation strategies be developed that specifically reduce pixel-level memorization, given that existing inference-time techniques showed no significant reduction when measured by SolidMark?
- **Question:** How can the evaluation framework be adapted to reliably detect memorization in scenarios involving excessive exact data duplication?
- **Question:** Is it possible to refine SolidMark to detect "weak" memorization instances where the model possesses information about an image but lacks the confidence to reconstruct the key precisely?

## Limitations

- The method may struggle with accurately reporting memorization caused by excessive exact duplication due to assigning different keys to duplicate images.
- The method may not report weak memorizations that are not strong enough to capture the key precisely.
- RGB border experiments failed, collapsing to grayscale, limiting color space exploration.

## Confidence

- **High:** The core mechanism of using random scalar borders as a memorization probe is sound and well-validated through controlled experiments.
- **Medium:** The claim that SolidMark detects fine-grained pixel-level memorization is supported by perturbation studies, but the distinction from semantic memorization could be more rigorously quantified.
- **Medium:** The assertion that text-based inference-time mitigations are ineffective against pixel-level memorization is plausible given the visual nature of the probe, but direct ablation studies on latent-space mitigations are needed.

## Next Checks

1. Run SolidMark on a dataset with known duplicates (e.g., CIFAR-10 with artificial duplication) and compare results with and without duplicate key assignment to quantify the impact.
2. Apply a mitigation technique that directly alters image latents (e.g., diffusion noise schedule perturbation) and measure the change in SolidMark scores to test the visual cue dominance hypothesis.
3. Experiment with multi-channel (e.g., RGB) or structured patterns instead of scalar grayscale to assess robustness and potential for richer memorization signals.