---
ver: rpa2
title: 'Deploying Chatbots in Customer Service: Adoption Hurdles and Simple Remedies'
arxiv_id: '2504.06145'
source_url: https://arxiv.org/abs/2504.06145
tags:
- chatbot
- channel
- context
- aversion
- treatment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates why customers underutilize AI-powered chatbots
  in customer service despite technological advancements. Using incentivized online
  experiments, researchers found that chatbot adoption is significantly lower than
  expected-time minimization would predict due to "gatekeeper aversion" - reluctance
  to engage with multi-stage processes where initial imperfect service may require
  transfer to a human agent.
---

# Deploying Chatbots in Customer Service: Adoption Hurdles and Simple Remedies

## Quick Facts
- arXiv ID: 2504.06145
- Source URL: https://arxiv.org/abs/2504.06145
- Reference count: 8
- Primary result: Chatbot adoption can be increased by providing average waiting times (nudge), being transparent about chatbot capabilities, and implementing priority queues for chatbot users who experience failures.

## Executive Summary
This study investigates why customers underutilize AI-powered chatbots in customer service despite technological advancements. Using incentivized online experiments, researchers found that chatbot adoption is significantly lower than expected-time minimization would predict due to "gatekeeper aversion" - reluctance to engage with multi-stage processes where initial imperfect service may require transfer to a human agent. This aversion is amplified by "algorithm aversion" when the stakes are high. The research demonstrates that chatbot adoption can be increased by providing average waiting times (nudge), being transparent about chatbot capabilities, and implementing priority queues for chatbot users who experience failures. A structural estimation of staffing costs revealed potential savings of up to 19.7% through these interventions.

## Method Summary
The researchers conducted incentivized online experiments using oTree software with participants recruited via Prolific. The experimental design involved 33 binary channel choices per participant across three decision sets, with between-subjects treatment arms testing different contexts (algorithmic vs. non-algorithmic), transparency levels, and information disclosure. Treatments included Context/No Context/Deterministic variations, transparency manipulations, and nudge conditions. Analysis employed random effects logit regression with Bonferroni-Holm adjusted p-values and structural utility model estimation.

## Key Results
- Chatbot adoption is significantly lower than expected-time minimization would predict due to gatekeeper aversion
- Algorithm aversion amplifies existing gatekeeper aversion when stakes are high, but is not a primary driver on its own
- Three interventions increase chatbot adoption: average wait time disclosure (nudge), capability transparency, and priority queues for chatbot users who experience failures
- Structural estimation revealed potential staffing cost savings of up to 19.7% through these interventions

## Why This Works (Mechanism)

### Mechanism 1: Gatekeeper Aversion
Customers systematically avoid chatbot channels even when expected wait times favor them, due to aversion to multi-stage service processes with uncertain outcomes. This combines transfer aversion (preference for continuous rather than fragmented service stages) and risk aversion (preference for deterministic wait times over probabilistic ones). Users perceive the chatbot-human handoff as a process failure rather than a feature.

### Mechanism 2: Algorithm Aversion as Amplifier
Algorithm aversion does not independently reduce chatbot uptake when process and performance are held constant, but it amplifies existing gatekeeper aversion when stakes are high. The affective penalty for algorithmic errors becomes salient only when combined with structural process disadvantages.

### Mechanism 3: Information Design Remedies
Low-cost interventions—average wait time disclosure, capability transparency, and priority queues—increase chatbot adoption by redirecting attention to objective performance metrics. These shift decision-making from affective (channel bias) to cognitive (time optimization) processing.

## Foundational Learning

- **Concept: Gatekeeper Service Systems**
  - Why needed here: The chatbot operates as a "gatekeeper"—an initial filter that handles some requests and transfers others to experts. Understanding this structure is essential to diagnose why users avoid it.
  - Quick check question: In a gatekeeper system, if the first-stage server has a 60% success rate and the second stage always succeeds, what is the expected number of service stages a random customer will experience? (Answer: 0.6 × 1 + 0.4 × 2 = 1.4 stages)

- **Concept: Risk Aversion in Time Domain**
  - Why needed here: The paper distinguishes risk aversion (preference for deterministic outcomes) from transfer aversion (preference for continuous processes). Most participants chose the channel with certain longer waits over uncertain shorter expected waits.
  - Quick check question: A customer faces two options: (A) wait exactly 50 seconds, or (B) wait either 20 seconds (70% chance) or 80 seconds (30% chance). Expected wait for B is 38 seconds. Would a risk-averse customer ever choose B? (Answer: Possibly not—risk aversion can cause preference for the certain 50s despite higher expected value.)

- **Concept: Experimental Design for Behavioral Operations**
  - Why needed here: The paper uses incentivized experiments with real time consequences, Multiple Price Lottery elicitation, and between-subjects treatment arms. Understanding these methods is critical to evaluate the validity of causal claims.
  - Quick check question: Why does the paper use a "No Context" treatment where visual cues are identical across channels? (Answer: To isolate process-related preferences from algorithm aversion—if behavior differs between Context and No Context, the difference is attributable to the algorithmic label, not the service structure.)

## Architecture Onboarding

- **Component map:**
Channel Selection Interface
    ├── Channel A (Live Agent Queue)
    │   ├── Queue wait (tA_line)
    │   ├── Service (tA_serve, success rate = 100%)
    │   └── Exit
    └── Channel B (Chatbot Gatekeeper)
        ├── Immediate service (tB_serve1)
        ├── Probabilistic outcome (success with pB)
        │   ├── If success → Exit
        │   └── If failure → Transfer to Queue
        │       ├── Queue wait (tB_line, potentially prioritized)
        │       ├── Second-stage service (tB_serve2)
        │       └── Exit

- **Critical path:** The user makes a channel choice → if they select chatbot and it fails, they re-enter the live agent queue. The effective wait time for chatbot users = tB_serve1 + (1 - pB) × (tB_line + tB_serve2).

- **Design tradeoffs:**
  1. **Transparency vs. False Competence**: Transparent chatbots that admit limitations increase trust (especially for short waits), but non-transparent chatbots that always attempt solutions may initially appear more capable.
  2. **Priority Queue Allocation**: Giving chatbot-failed customers queue priority reduces their effective wait but may increase wait times for direct-to-agent customers.
  3. **Contextual Framing**: Explicitly labeling the chatbot as algorithmic slightly reduces uptake at high stakes.

- **Failure signatures:**
  1. Chatbot underutilization with high live-agent queue lengths → likely gatekeeper aversion
  2. Sharp drop in chatbot use when wait times double → algorithm aversion amplification
  3. No improvement from transparency intervention → check if wait times are already long
  4. Users who experience chatbot failure once avoid it entirely thereafter → transfer aversion is high

- **First 3 experiments:**
  1. **Baseline A/B test**: Deploy chatbot with current configuration. Measure channel selection rates across different queue lengths. Compare to expected-time minimization prediction.
  2. **Nudge intervention**: Add average wait time display for both channels. A/B test against control. Expect +5-20 percentage point increase in chatbot selection.
  3. **Priority queue pilot**: For chatbot users who fail, give 10% queue position bump vs. direct-to-agent customers. Monitor chatbot selection rate, overall staffing requirements, and customer satisfaction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do gatekeeper aversion and algorithm aversion manifest in alternative self-service technologies (e.g., self-checkout stations, automated airport kiosks, digital restaurant ordering)?
- Basis in paper: Authors state in Outlook: "Future research could examine whether key behaviors identified in chatbot interactions – such as gatekeeper aversion and algorithm aversion – are also observed in these alternative automated settings."
- Why unresolved: The current study focused exclusively on online customer service chatbots; the generalizability of findings to physical or hybrid self-service contexts was not tested.
- What evidence would resolve it: Experiments replicating the channel-choice paradigm with different self-service technologies, measuring transfer aversion and algorithm aversion magnitudes.

### Open Question 2
- Question: How do richer interaction modalities (voice, video, virtual reality) affect the magnitude of algorithm aversion in customer service settings?
- Basis in paper: Authors state: "richer server-customer interaction environments such as voice, video, or virtual reality deserve further study as they could produce markedly different levels of algorithm aversion."
- Why unresolved: Experiment 3 only tested click-based vs. hold-button interactions; more immersive modalities were not examined.
- What evidence would resolve it: Randomized experiments comparing chatbot adoption across voice-based, video-based, and text-based interfaces, controlling for performance parameters.

### Open Question 3
- Question: Does the seamlessness of transitions between chatbots and live agents moderate gatekeeper aversion?
- Basis in paper: Authors acknowledge as a limitation: "we did not model...the seamlessness of transitions between gatekeepers and experts."
- Why unresolved: The experimental design treated transfer as binary (success/failure), ignoring how smoothly context and information are handed off to the human agent.
- What evidence would resolve it: Experiments varying transfer quality (e.g., whether the human agent receives conversation history) while holding wait times constant, measuring effects on chatbot uptake.

## Limitations

- External validity concerns: The study uses artificial decision tasks with hypothetical scenarios rather than real customer service interactions, which may not capture all behavioral nuances of actual service encounters.
- Context-dependency of algorithm aversion: The amplification effect is detected only in high-stakes conditions (long wait times), suggesting the threshold for "high stakes" is not precisely defined.
- Implementation constraints: The proposed remedies have varying effectiveness depending on context—transparency helps for short-duration tasks but not long ones, while priority queues require sufficient agent capacity to be meaningful.

## Confidence

- **High**: Gatekeeper aversion exists as a distinct behavioral phenomenon; participants systematically avoid chatbot channels even when expected wait times favor them. The experimental evidence for transfer aversion and risk aversion is robust with strong statistical support.
- **Medium**: Algorithm aversion acts as an amplifier rather than primary driver. The interaction effect is statistically significant but only emerges under specific conditions (long durations/high stakes).
- **Medium**: Information design remedies increase chatbot adoption. Effect sizes are promising (up to 19.7% potential staffing cost savings) but depend on implementation context and service characteristics.

## Next Checks

1. **Field Test Priority Queue Intervention**: Implement the chatbot priority queue in an operational customer service setting and measure both chatbot adoption rates and overall staffing efficiency over a 4-week period. Track whether the predicted 11.5%-14.7% staffing cost reduction materializes in practice.

2. **Cross-Context Algorithm Aversion Test**: Replicate the experiment across different service domains (technical support, billing inquiries, general information) to identify which types of interactions are most susceptible to algorithm aversion amplification. This would clarify the boundary conditions for the amplification mechanism.

3. **Longitudinal Aversion Decay Study**: Track customer behavior after initial chatbot failure experiences to measure whether transfer aversion diminishes with repeated exposure. This would determine whether the aversion is a persistent barrier or can be overcome through positive experiences and appropriate service recovery mechanisms.