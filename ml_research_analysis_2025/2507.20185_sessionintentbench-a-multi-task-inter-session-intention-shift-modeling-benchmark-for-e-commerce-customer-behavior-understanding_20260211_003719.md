---
ver: rpa2
title: 'SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark
  for E-commerce Customer Behavior Understanding'
arxiv_id: '2507.20185'
source_url: https://arxiv.org/abs/2507.20185
tags:
- intention
- product
- session
- task
- products
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces SESSION INTENT BENCH , a multi-task benchmark\
  \ to evaluate L(V)LMs\u2019 ability to understand and model customer intention shifts\
  \ across E-commerce browsing sessions. It proposes an automated pipeline to construct\
  \ an intention tree from session data, extracting product attributes, generating\
  \ customer intentions, analyzing intention shifts, and collecting human annotations."
---

# SessionIntentBench: A Multi-task Inter-session Intention-shift Modeling Benchmark for E-commerce Customer Behavior Understanding

## Quick Facts
- **arXiv ID:** 2507.20185
- **Source URL:** https://arxiv.org/abs/2507.20185
- **Reference count:** 40
- **Primary result:** Current L(V)LMs achieve only ~42% accuracy on the hardest inter-session intention evolution task, highlighting the need for structured intention modeling in e-commerce.

## Executive Summary
SESSION INTENT BENCH introduces a multi-task benchmark to evaluate L(V)LMs' ability to understand and model customer intention shifts across e-commerce browsing sessions. The benchmark constructs an automated intention tree from session data, extracting product attributes, generating customer intentions, analyzing intention shifts, and collecting human annotations. Experiments on 20+ L(V)LMs reveal significant challenges in inter-session intention understanding, with the hardest task (intention evolution modeling) achieving only ~42% accuracy. Fine-tuning and intention injection from external knowledge bases improve performance, demonstrating the importance of structured intention modeling for better e-commerce recommendation systems.

## Method Summary
The benchmark employs an automated pipeline to construct intention trees from e-commerce session data. First, product attributes are extracted using GPT-4o-mini from text and images. Then, customer intentions are iteratively inferred at each time step while branching multiple intention hypotheses. Each branch is enriched with shift rationale, valued attributes, and product comparisons. The benchmark contains four complementary tasks: intent-based purchasing likelihood estimation, purchasing likelihood inference via valued attributes regularization, intention justification via comparison, and intention evolution modeling. Evaluation is conducted across zero-shot, few-shot, and chain-of-thought prompting strategies on both LLMs and LVLMs.

## Key Results
- L(V)LMs struggle with inter-session intention understanding, with intention evolution modeling (Task 4) achieving only ~42% accuracy
- Fine-tuning on the benchmark improves performance, with the hardest task reaching 55.81% accuracy after fine-tuning
- Intention injection from external knowledge bases (MIND) improves Task 1 by 1.75%, Task 2 by 3.09%, and Task 4 by 4.24%
- LVLMs underperform LLMs on all tasks despite visual input, suggesting images add noise rather than signal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-step intention tree construction transforms sparse session interactions into structured metadata for L(V)LM evaluation.
- Mechanism: The pipeline extracts product attributes via GPT-4o-mini (text + images), then iteratively infers customer intentions at each time step while branching multiple intention hypotheses. Each branch is enriched with shift rationale, valued attributes, and product comparisons—creating an "intention tree" rather than linear trajectory.
- Core assumption: Customer browsing behavior follows interpretable intention shifts that can be reverse-engineered from product sequences; L(V)LMs can simulate customer reasoning.
- Evidence anchors: [abstract] "propose an automated pipeline to construct an intention tree from session data, extracting product attributes, generating customer intentions, analyzing intention shifts"; [Section 4.2] "we add the intention information of the previous time step {Ii} to facilitate the model to do the reasoning... constrained to output the five most possible user intentions"

### Mechanism 2
- Claim: Four complementary tasks decompose intention understanding into attribute detection, likelihood inference, justification, and evolution prediction.
- Mechanism: Each task isolates a capability—Task 1 tests intention-to-product alignment; Task 2 tests attribute-driven prediction; Task 3 tests comparative reasoning; Task 4 tests long-horizon trend modeling. This forces models to demonstrate multiple reasoning skills rather than pattern-matching single transitions.
- Core assumption: Intention understanding is factorizable into these sub-skills; improving each independently contributes to overall customer behavior modeling.
- Evidence anchors: [abstract] "evaluates L(V)LMs' capability on understanding inter-session intention shift with four subtasks"; [Section 3.1] Detailed task definitions with formal notation for likelihood scores S1–S4

### Mechanism 3
- Claim: Intention injection from external knowledge bases (e.g., MIND) improves benchmark performance via transfer learning.
- Mechanism: Models first fine-tuned on MIND (co-buy intention knowledge base), then on SESSION INTENT BENCH. Pre-exposure to intention patterns in simpler co-buy contexts helps models generalize to more complex session trajectories.
- Core assumption: Intention reasoning skills learned from pairwise co-buy data transfer to multi-step session sequences; intention representation is somewhat domain-agnostic.
- Evidence anchors: [abstract] "Fine-tuning and intention injection from external knowledge bases improve performance"; [Section 5.4] "improved TASK 1 by 1.75%, TASK 2 by 3.09%, TASK 4 by 4.24%" with MIND+SIB sequential training

## Foundational Learning

- **Concept:** Session-based recommendation vs. sequential recommendation
  - Why needed here: Sessions are short, anonymous interaction sequences without user profiles; modeling must rely on intra-session dynamics. This paper adds inter-session intention shift on top.
  - Quick check question: Given a 4-product session [A→B→C→D], can you articulate why a model predicting D from A,B,C differs from one predicting D from just C?

- **Concept:** Intention as latent variable vs. observable behavior
  - Why needed here: The paper explicitly models inferred intentions (I1, I2, ...) as intermediate variables between products, unlike prior work using only titles/prices.
  - Quick check question: If you observe a user clicking red shoes then white shoes, is "preference for plain colors" an intention or an attribute? How would you distinguish?

- **Concept:** Multi-task evaluation for LLM reasoning
  - Why needed here: The four tasks test different reasoning modes; understanding how they relate informs whether improvements are robust or task-specific gaming.
  - Quick check question: Why might a model excel at Task 3 (comparison justification) but fail at Task 4 (evolution modeling)?

## Architecture Onboarding

- **Component map:** Amazon-M2 sessions + Amazon Review images → GPT-4o-mini attribute extraction → intention tree construction → trajectory sampling → human annotation → L(V)LM evaluation
- **Critical path:** Filter sessions with complete multimodal data → run intention tree construction (GPT-4o-mini, 5-shot prompts) → sample trajectories and send to human annotation → evaluate L(V)LMs on annotated test set across 4 tasks → (Optional) pre-train on MIND, then fine-tune on SIB for transfer experiments
- **Design tradeoffs:**
  - LLM-generated vs. human-labeled intentions: Tree construction is automated and scalable but may hallucinate; human annotation provides ground truth but covers only ~0.8% of trajectories
  - Branching factor: 5-branch early explosion captures diverse hypotheses but increases tree size; capped at 1 after step 5 for tractability
  - Task granularity: 4 tasks enable fine-grained diagnosis but may fragment signal; Task 4 (evolution) is hardest (~42% accuracy) and most practically relevant
- **Failure signatures:**
  - LVLMs underperform LLMs on all tasks despite visual input—suggests images add noise, not signal
  - Fine-tuning helps poor models but plateaus for mid-performers—indicates data distribution dispersion
  - Task 4 accuracy barely exceeds random even after fine-tuning (55.81% vs. 54.38% random)—long-horizon intention modeling remains unsolved
  - Error analysis: 47.5% errors from incorrect metadata understanding, 24% from ground-truth label noise
- **First 3 experiments:**
  1. Baseline sweep: Run all 4 tasks on zero-shot LLMs (Llama-3.1-8B, Mistral-7B, Qwen-2.5-7B) to establish accuracy floors and identify hardest task
  2. Ablate visual modality: Compare LLaVA-v1.6-vicuna-7b (LVLM) vs. Mistral-7B (LLM) to confirm whether images help
  3. Intention injection transfer: Fine-tune Llama-3.1-8B on MIND alone, then on SIB, vs. SIB-only; measure per-task delta to validate transfer mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does incorporating personalized user history (e.g., past purchases, demographics) improve model performance on session-based intention tasks compared to session-only baselines?
- Basis in paper: [explicit] The paper states in the Limitations section: "Our current intention modeling process does not incorporate additional personalized factors such as past purchases... Incorporating these variables... could enhance model reasoning during inference."
- Why unresolved: The current benchmark and experiments deliberately exclude user-specific history to focus on the accessibility of session data, leaving the marginal utility of personalized precomputation untested in this specific multi-task setting.
- What evidence would resolve it: A comparative evaluation where baseline L(V)LMs are augmented with precomputed user profile vectors, showing a statistically significant accuracy increase on the Intention Evolution Modeling (Task 4) subset.

### Open Question 2
- Question: Can replacing the current metadata generator (GPT-4o-mini) with advanced reasoning models (e.g., GPT-o1/o3) reduce hallucination rates and improve the quality of the generated intention tree?
- Basis in paper: [explicit] The authors note: "As LLM space advances, more advanced models like GPT-o1... will become more accessible... which would potentially better mimic customer thinking process... enabling our knowledge base... with even higher quality."
- Why unresolved: The current pipeline relies on GPT-4o-mini for cost-efficiency; the impact of using models with higher reasoning capabilities on the fidelity of the intention entries and trajectory logic remains hypothetical.
- What evidence would resolve it: A reconstruction of the dataset using a reasoning-heavy model, followed by a comparison of inter-annotator agreement scores and the reduction in the 24% error rate attributed to incorrect ground-truth labels.

### Open Question 3
- Question: What specific architectural modifications or noise-filtering techniques are required to enable LVLMs to effectively utilize visual signals for intention inference?
- Basis in paper: [inferred] The paper observes that "LVLMs struggle to make good usage of visual signals," with the best LVLM lagging behind the best LLM by over 11% on Task 4, potentially due to "low signal-noise ratio of the images collected."
- Why unresolved: While the paper identifies the performance gap and suggests noise as a cause, it does not propose or test methods to better align visual features with textual intention metadata.
- What evidence would resolve it: Experiments demonstrating that a visual encoder trained to filter seller-biased imagery or align product thumbnails with attribute text improves performance to match or exceed text-only LLM baselines.

## Limitations
- Intention tree construction relies on GPT-4o-mini's ability to infer customer intentions, but this automation may hallucinate rather than reflect actual user reasoning
- Human-annotated test set covers only 0.8% of trajectories, making it difficult to assess benchmark representativeness
- Transfer learning claims depend on an unspecified MIND dataset and preprocessing pipeline, limiting reproducibility
- LVLMs consistently underperform LLMs on all tasks despite multimodal input, suggesting visual signals add noise rather than signal

## Confidence
- **High**: Task decomposition into four distinct reasoning capabilities is well-specified and empirically supported by task-specific performance gaps
- **Medium**: The automated intention tree generation pipeline is described but not validated against ground-truth intentions beyond the small human-annotated subset
- **Low**: The intention injection mechanism's effectiveness across different model scales and domains lacks comprehensive ablation studies

## Next Checks
1. **Intention Fidelity Test**: Compare GPT-4o-mini generated intentions against customer interview data or post-purchase surveys on a subset of sessions to validate whether inferred intentions reflect actual user reasoning
2. **Cross-Dataset Transfer**: Apply the intention injection approach to a non-e-commerce sequential reasoning task (e.g., recipe completion or code completion) to test whether intention modeling skills generalize beyond product recommendation
3. **Human-in-the-Loop Refinement**: Implement an iterative loop where model-generated intention trees are corrected by human annotators, then measure whether this hybrid approach improves downstream recommendation accuracy compared to fully automated generation