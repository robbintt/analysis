---
ver: rpa2
title: 'CrossPT: Exploring Cross-Task Transferability through Multi-Task Prompt Tuning'
arxiv_id: '2509.14253'
source_url: https://arxiv.org/abs/2509.14253
tags:
- prompts
- prompt
- source
- tasks
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of knowledge transfer in multi-task
  prompt tuning for NLP. The authors propose CrossPT, a modular framework that decomposes
  each task's prompt into shared source prompts and task-specific private prompts,
  combined via a learned attention mechanism.
---

# CrossPT: Exploring Cross-Task Transferability through Multi-Task Prompt Tuning

## Quick Facts
- **arXiv ID**: 2509.14253
- **Source URL**: https://arxiv.org/abs/2509.14253
- **Reference count**: 27
- **Primary result**: Achieves 3-5 percentage points higher accuracy than conventional single-task prompt tuning in few-shot settings (32 examples per task)

## Executive Summary
This paper addresses the challenge of knowledge transfer in multi-task prompt tuning for NLP by proposing CrossPT, a modular framework that decomposes each task's prompt into shared source prompts and task-specific private prompts, combined via a learned attention mechanism. The method enables controlled knowledge transfer while maintaining task-specific specialization, achieving significant accuracy improvements over conventional single-task prompt tuning in few-shot settings. CrossPT demonstrates improved accuracy and robustness compared to traditional prompt tuning methods on GLUE and related benchmarks, particularly in low-resource scenarios.

## Method Summary
CrossPT is a modular framework that decomposes each target prompt into shared source prompts and task-specific private prompts, combined via a learned attention mechanism. The approach trains source prompts independently on individual source tasks, then constructs target prompts as weighted combinations of these source prompts plus a private prompt. The attention module learns which source prompts are relevant for each task, while differential learning rates stabilize optimization. The framework achieves effective knowledge transfer by isolating transferable patterns in source prompts from task-specific variations in private prompts, with performance gains particularly pronounced in few-shot settings.

## Key Results
- Achieves 3-5 percentage points higher accuracy than conventional single-task prompt tuning in few-shot settings with 32 examples per task
- Demonstrates up to 8.8% accuracy improvement over vanilla prompt tuning on GLUE benchmarks in low-resource scenarios
- Shows optimal performance with approximately 3 source prompts for GLUE tasks, with diminishing returns beyond this point

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Decomposing prompts into shared source prompts and task-specific private prompts enables more effective knowledge transfer than single unified prompts or isolated task prompts.
- **Mechanism**: Each target prompt P_t is constructed as a weighted combination: P_t = Σ(w_ts · P_s) + w_tu · P_u, where source prompts capture transferable patterns across task clusters and private prompts specialize for task-specific nuances. The attention module learns which source prompts are relevant for each task.
- **Core assumption**: Tasks share latent structure (semantic patterns, label spaces, reasoning types) that can be isolated from task-specific variations.
- **Evidence anchors**:
  - [abstract] "CrossPT decomposes each target prompt into shared, pre-trained source prompts and task-specific private prompts, combined via a learned attention mechanism."
  - [section 4.2, p.9] "all multi-prompt configurations outperform private-only or source-only baselines, demonstrating the benefit of combining shared and task-specific representations"
  - [corpus] Related work on multi-source visual prompt transfer (arXiv:2504.12311) similarly finds combining multiple source prompts enhances generalization, supporting the decomposition principle.
- **Break condition**: When tasks have minimal semantic overlap (e.g., unrelated domains), shared source prompts provide little benefit and may introduce interference.

### Mechanism 2
- **Claim**: Adaptive temperature scaling in attention prevents prompt selection collapse as the number of source prompts increases.
- **Mechanism**: Temperature τ = 1/M sharpens the softmax distribution as M grows, ensuring the model remains selective rather than assigning uniform weights across all sources.
- **Core assumption**: Larger prompt pools require stronger selectivity signals; standard softmax would flatten attention weights excessively.
- **Evidence anchors**:
  - [section 2.2, p.5] "As the number of source prompts M increases, standard softmax tends to yield flatter distributions, making it harder to select truly relevant prompts."
  - [section 4.8, p.15-16] Shows performance peaks around 3 source prompts; "increasing the number of source prompts beyond a certain point can lead to diminishing returns or even degraded performance"
  - [corpus] No direct corpus evidence on temperature scaling for prompt attention specifically; this appears to be a novel design choice in CrossPT.
- **Break condition**: If temperature is too low (overly sharp), attention may collapse to single-source selection, losing the benefit of multi-source transfer.

### Mechanism 3
- **Claim**: Differential learning rates for attention weights versus prompt embeddings stabilize multi-task prompt optimization.
- **Mechanism**: Attention module uses higher LR (0.1) for rapid weight adaptation; source prompts use moderate LR (0.05-0.15) for shared knowledge acquisition; private prompts use lower LR (~0.02-0.07, typically half of source LR) for fine-grained specialization without destabilizing shared representations.
- **Core assumption**: Attention weights should adapt quickly to leverage existing source prompts, while prompt embeddings require gradual refinement to avoid instability.
- **Evidence anchors**:
  - [section 2.2, p.5-6] "A higher learning rate is used for the attention module to enable rapid adaptation... lower learning rates [for prompts] ensure stable, gradual learning"
  - [section 4.9, p.16-17] "optimal configuration typically occurs when the learning rate for private prompts is approximately half that of the source prompts"
  - [corpus] Assumption: Related multi-task prompt methods (ATTEMPT, MPT in section 5) don't explicitly discuss LR stratification; this appears specific to CrossPT's design.
- **Break condition**: If private prompt LR matches or exceeds source LR, task-specific adaptation overwhelms shared representations, degrading performance (Fig. 11 shows sharp drops when private LR ≥ source LR).

## Foundational Learning

- **Concept: Soft Prompt Tuning**
  - **Why needed here**: CrossPT builds on standard prompt tuning where learnable continuous embeddings prepend frozen LM inputs. Without this baseline, the decomposition into source/private prompts won't make sense.
  - **Quick check question**: Can you explain why prompt tuning is more parameter-efficient than full fine-tuning?

- **Concept: Multi-Task Transfer Learning**
  - **Why needed here**: CrossPT's core hypothesis is that related tasks share knowledge. Understanding positive transfer vs. negative interference is essential for interpreting the attention visualizations.
  - **Quick check question**: What conditions make multi-task learning beneficial versus harmful for a given task?

- **Concept: Attention Mechanisms for Soft Selection**
  - **Why needed here**: The attention module computes weights over source prompts; understanding softmax normalization and temperature scaling is prerequisite to debugging weight collapse issues.
  - **Quick check question**: How does temperature affect the entropy of a softmax distribution?

## Architecture Onboarding

- **Component map**: Source tasks (20 epochs) → Source prompts (P_1, ..., P_m) → Attention module R → Target prompts (P_t = Σ(w_ts · P_s) + w_tu · P_u) → Frozen LM

- **Critical path**:
  1. Train source prompts on individual tasks (20 epochs)
  2. Initialize private prompts (optional: from source prompts)
  3. Joint training: attention module + private prompts (+ optionally source prompts)
  4. Precompute attention weights for all target tasks
  5. Inference: load source prompts, relevant private prompt, apply weights

- **Design tradeoffs**:
  - **More source prompts**: Better task clustering but higher memory and potential over-fragmentation. Paper finds 3 prompts optimal for GLUE, 10 for full-data settings.
  - **Learning source prompts vs. freezing**: Freezing prevents catastrophic forgetting but limits adaptation; learning enables joint optimization but risks interference.
  - **Task prefixes**: Improve task discrimination in shared-prompt settings but may reduce source prompt generality when private prompts exist.
  - **Natural vs. synthetic labels**: Natural semantic labels promote cross-task transfer; synthetic/numeric labels create interference.

- **Failure signatures**:
  - **High variance across seeds**: Likely single shared prompt (SL config) causing task interference
  - **Poor few-shot performance with scratch initialization**: Need pre-trained source prompt initialization (use SILP/SILN instead of SLP/SLN for <16 samples)
  - **Attention weight collapse to uniform**: Temperature too high or insufficient source prompt diversity
  - **Performance drop as source prompts increase**: Over-fragmentation; reduce M to 2-3

- **First 3 experiments**:
  1. **Baseline comparison**: Run P (vanilla prompt tuning), SILP (initialized source+private), and SLPN (scratch source+private) on GLUE with 32 samples/task to validate decomposition benefit.
  2. **Source prompt ablation**: Test SLP with M=1, 2, 3, 5, 8 source prompts on GLUE-32 to find optimal capacity point.
  3. **Learning rate sensitivity**: Sweep private prompt LR from 0.01-0.2 with source LR=0.1 to confirm the 0.5× ratio guideline.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can incorporating instance-specific features (e.g., input embeddings or predictive uncertainty) into the attention mechanism improve fine-grained adaptation over the current task-level static weighting?
- **Basis in paper**: [explicit] Section 6.6 states that "leveraging instance-specific information... during prompt composition could enable more fine-grained adaptation and improve performance on diverse tasks."
- **Why unresolved**: The current design precomputes attention weights per target task during inference, ignoring the specific characteristics of individual input instances.
- **What evidence would resolve it**: Ablation studies comparing the baseline CrossPT against an instance-aware variant on diverse datasets to evaluate if dynamic weighting yields significant accuracy improvements without prohibitive latency costs.

### Open Question 2
- **Question**: Does the CrossPT framework generalize effectively to tasks with open-ended outputs, such as question answering or summarization, where label semantics are less structured?
- **Basis in paper**: [explicit] Section 6.6 lists "enhancing generalization to tasks with open-ended outputs—such as question answering" as a necessary step to broaden the framework's applicability.
- **Why unresolved**: The paper restricts empirical validation to classification and regression benchmarks (GLUE and Group 2), leaving the method's efficacy on generative tasks unverified.
- **What evidence would resolve it**: Experimental results applying the shared/private prompt decomposition to standard generation benchmarks, analyzing if shared prompts can effectively transfer structural knowledge for generative objectives.

### Open Question 3
- **Question**: Can dynamic pruning or relevance-based filtering mechanisms mitigate the linear increase in computational overhead as the number of source prompts grows?
- **Basis in paper**: [explicit] Section 6.6 suggests that "adaptive mechanisms for source prompt selection, such as dynamic pruning or relevance-based filtering, could mitigate computational overhead."
- **Why unresolved**: While the paper notes that increasing source prompts adds capacity, it also identifies scalability limits regarding memory and computation costs that are currently unaddressed.
- **What evidence would resolve it**: Implementation of a sparsity-inducing attention mechanism that selects a subset of source prompts per batch, demonstrating maintained performance with reduced resource consumption.

## Limitations

- **Task similarity assumptions**: The framework assumes tasks can be meaningfully clustered into semantic groups, but the paper doesn't validate this clustering beyond GLUE, potentially limiting effectiveness for unrelated domains.
- **Source prompt capacity sensitivity**: While 3 source prompts are optimal for GLUE-32, this may not generalize across different domains and task diversities, lacking systematic guidelines for determining optimal M.
- **Initialization dependency**: The SILP/SILN initialization strategy shows significant performance differences based on sample size, but the recommendation to use SILP/SILN only for <16 samples lacks theoretical justification.

## Confidence

**High confidence**: The core decomposition mechanism (shared + private prompts) and its superiority over single-prompt approaches is well-supported by multiple ablations showing consistent gains across GLUE tasks and sample sizes.

**Medium confidence**: The optimal learning rate ratios (attention: 0.1, source: 0.05-0.15, private: 0.02-0.07) are empirically validated on GLUE but may not transfer to other domains. The temperature scaling mechanism is theoretically sound but lacks direct ablation evidence.

**Low confidence**: Claims about CrossPT's robustness to noisy labels and its generalization beyond GLUE benchmarks are based on limited experiments. The synthetic label experiments in GLUE-100 don't establish strong generalization guarantees.

## Next Checks

1. **Cross-domain robustness test**: Apply CrossPT to a multi-task benchmark spanning unrelated domains (e.g., biomedical NER, legal contract classification, and sentiment analysis) to test whether the shared prompt decomposition still provides benefits when task similarity is low.

2. **Optimal source prompt determination**: Design a systematic study that varies task diversity, dataset sizes, and domain relatedness to establish guidelines for selecting the optimal number of source prompts (M) across different scenarios, rather than the current GLUE-specific finding of M=3.

3. **Long-tail task performance**: Evaluate CrossPT on benchmarks with long-tail label distributions (e.g., FewGLUE variants with imbalanced classes) to verify the claimed robustness to noisy and imbalanced labels, which the current experiments don't adequately address.