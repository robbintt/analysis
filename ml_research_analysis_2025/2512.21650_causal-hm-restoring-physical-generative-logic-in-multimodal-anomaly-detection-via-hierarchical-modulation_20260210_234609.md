---
ver: rpa2
title: 'Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection
  via Hierarchical Modulation'
arxiv_id: '2512.21650'
source_url: https://arxiv.org/abs/2512.21650
tags:
- anomaly
- physical
- process
- detection
- sensor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses multimodal unsupervised anomaly detection\
  \ in industrial manufacturing, specifically focusing on robotic welding. It proposes\
  \ Physic-HM, a framework that explicitly models the physical Process\u2192Result\
  \ dependency in industrial production."
---

# Causal-HM: Restoring Physical Generative Logic in Multimodal Anomaly Detection via Hierarchical Modulation

## Quick Facts
- **arXiv ID:** 2512.21650
- **Source URL:** https://arxiv.org/abs/2512.21650
- **Reference count:** 14
- **Key outcome:** Achieves state-of-the-art I-AUROC of 90.7% on Weld-4M benchmark with 6x faster inference than memory-bank methods

## Executive Summary
This paper addresses multimodal unsupervised anomaly detection in industrial manufacturing, specifically robotic welding. It proposes Physic-HM, a framework that explicitly models the physical Process→Result dependency in industrial production. The key innovations are Sensor-Guided PHM Modulation, which uses low-dimensional sensor signals to guide high-dimensional feature extraction, and a Physic-Hierarchical Architecture that enforces unidirectional generative mapping. This approach addresses process-logic blindness by treating process modalities (video, audio, sensors) as physical governors rather than symmetric feature sources. Extensive experiments on the Weld-4M benchmark demonstrate that Physic-HM achieves state-of-the-art I-AUROC of 90.7%, showing superior sensitivity to process-hidden defects and maintaining nearly 6x faster inference than traditional memory-bank-based methods.

## Method Summary
Physic-HM introduces a hierarchical framework that restores physical generative logic in multimodal anomaly detection. The method uses Sensor-Guided PHM Modulation where a Mamba-based encoder processes sensor time-series into scaling (γ) and shifting (β) parameters that perform affine transformations on frozen visual/audio features. This enforces a unidirectional Process→Result mapping where the process modalities predict the result modality rather than performing symmetric fusion. The architecture includes anti-generalization constraints (Noisy Bottleneck and Linear Attention Decoder) to prevent identity mapping while maintaining reconstruction capability. The framework is evaluated on the Weld-4M benchmark, demonstrating superior performance for detecting process-hidden defects.

## Key Results
- Achieves state-of-the-art I-AUROC of 90.7% on Weld-4M benchmark
- Shows superior sensitivity to process-hidden defects compared to symmetric fusion methods
- Maintains nearly 6x faster inference (3.7 FPS) than traditional memory-bank-based methods
- Ablation studies show 7.8% performance drop when reversing causal direction and 7.5% drop when removing anti-generalization constraints

## Why This Works (Mechanism)

### Mechanism 1: Sensor-Guided Affine Modulation
The paper posits that low-dimensional sensor signals (e.g., current, voltage) should physically "govern" high-dimensional visual features rather than being treated as symmetric peers, preventing the "drowning out" of critical process context. A Mamba-based temporal encoder processes sensor time-series into a latent state $h_s$, which is projected into scaling ($\gamma$) and shifting ($\beta$) parameters. These parameters perform an affine transformation on frozen visual/audio features ($F_{mod} = F \odot (1 + \gamma) + \beta$), effectively conditioning the visual manifold on the physical process state. The core assumption is that industrial anomalies manifest as inconsistencies between physical process constraints (sensors) and observed visual features.

### Mechanism 2: Unidirectional Generative Mapping ($P \rightarrow R$)
The paper argues that enforcing a strict causal direction (Process $\rightarrow$ Result) allows the model to detect "process-hidden" defects that visually appear normal but violate physical consistency. The architecture prohibits symmetric fusion and instead learns a mapping function $f: P \rightarrow R$. It encodes process modalities (video, audio, sensors) into a process latent $Z_p$ and attempts to predict the result latent $Z_r$. Anomalies are scored based on reconstruction error between observed and process-predicted results. The core assumption is that industrial production strictly follows unidirectional physical generative chain where process dictates result.

### Mechanism 3: Anti-Generalization Constraints
The paper claims that restricting decoder capacity prevents the model from "cheating" by memorizing identity mappings, forcing it to learn robust physical correlations. Two structural safeguards are implemented: a Noisy Bottleneck (Bernoulli mask + Gaussian noise) and a Linear Attention Decoder (kernel-based approximation). These limit rank and precision of attention mechanism, compelling the model to rely on global semantic context rather than local pixel-copying. The core assumption is that powerful decoders tend to reconstruct anomalies too well ("identity mapping"), and noise injection combined with low-rank attention acts as sufficient regularizer.

## Foundational Learning

- **Feature-wise Linear Modulation (FiLM)**: Why needed: PHM Modulation relies on affine transformations ($\gamma, \beta$) to influence visual features. Understanding how scaling and shifting feature vectors alters semantic representation is critical. Quick check: If $\gamma$ is set to zero, does sensor signal have any influence on output? (Answer: Yes, via bias $\beta$, but dynamic range/scaling is removed).

- **State Space Models (Mamba/SSMs)**: Why needed: Paper uses Mamba encoder for sensor signals to capture long-range temporal dependencies with linear complexity. Unlike Transformers, SSMs handle long sequences efficiently. Quick check: Why is Mamba preferred over standard Transformer for 1D sensor time-series in this framework?

- **Frozen Pretrained Backbones**: Why needed: Architecture (L0) relies on off-the-shelf models (V-JEPA, DINOv3, AST) to extract features. System doesn't learn features from scratch; it learns relations between features. Quick check: Does model update weights of V-JEPA encoder during "PHM Modulation" phase?

## Architecture Onboarding

- **Component map:** Sensor Data → Mamba Encoder → γ, β → Modulated Visual Features → Process Latent → Noisy Bottleneck → Predicted Result Latent

- **Critical path:** Sensor Data → **Mamba Encoder** → γ, β → Modulated Visual Features → **Process Latent** → **Noisy Bottleneck** → Predicted Result Latent

- **Design tradeoffs:** Inference Speed vs. Complexity: Replaces memory-bank retrieval (slow) with direct decoder (fast, ~6x speedup), but requires careful tuning of Noisy Bottleneck to prevent over-generalization. Modality Dominance: Explicitly sacrifices visual dominance by forcing visual features to be "modulated" by sensors, which is robust for hidden defects but risky if sensors are unreliable.

- **Failure signatures:** Identity Mapping: Anomaly scores converge to near zero for all samples; decoder likely ignoring bottleneck and copying inputs. Sensor Blindness: Performance drops to visual-only baseline levels; modulation parameters (γ, β) may be vanishing or Mamba encoder failed to converge. Over-Sensitivity: High false positive rate on "Good" samples; Noisy Bottleneck noise level (σ) may be too high, destabilizing reconstruction of normals.

- **First 3 experiments:** 1. Modality Ablation: Verify contribution of each modality by sequentially adding Video, Audio, and Sensors to Image baseline (Table 2). 2. Directionality Test: Compare standard P→R mapping against reversed R→P mapping to validate causal assumption. 3. Noise Robustness: Inject Gaussian noise (σ up to 0.3) into sensor inputs to verify if model maintains performance compared to baselines like M3DM.

## Open Questions the Paper Calls Out

- Can Physic-Hierarchical architecture generalize to industrial domains with fundamentally different physical generative logics (e.g., additive manufacturing or assembly) beyond robotic welding?

- Is the achieved inference speed of 3.7 FPS (268ms latency) sufficient for real-time closed-loop control tasks explicitly identified as target in introduction?

- How does framework perform under conditions of modality asynchrony or intermittent sensor dropout during inference?

## Limitations
- Sensor reliability assumption: Framework's performance critically depends on sensor data quality and correlation with visual outcomes, which may not hold in real-world industrial settings with sensor noise or calibration drift
- Generalizability beyond welding: Model evaluated exclusively on robotic welding applications; unidirectional causal assumption may not hold in manufacturing domains with more stochastic processes
- Architectural constraint validation: While anti-generalization constraints show performance benefits, individual contributions of Noisy Bottleneck and Linear Attention components remain unclear

## Confidence
- **High Confidence**: Core mechanism of using sensor-guided affine modulation to bridge modality heterogeneity is well-supported by both theoretical reasoning and ablation results (7.8% drop when reversed)
- **Medium Confidence**: Unidirectional generative mapping assumption is empirically validated on specific welding domain but lacks broader industrial validation
- **Medium Confidence**: Anti-generalization constraints improve performance, though their individual contributions remain unclear

## Next Checks
1. **Sensor Degradation Study**: Systematically corrupt sensor inputs (additive noise, missing segments, time shifts) and measure performance degradation relative to visual-only baselines to quantify risk of sensor unreliability

2. **Cross-Domain Transfer**: Apply trained Physic-HM model to different manufacturing domain (e.g., CNC machining or quality inspection) without fine-tuning to assess generalizability of causal assumption

3. **Component Isolation**: Create ablations that separately disable Noisy Bottleneck and Linear Attention components to determine their individual contributions to preventing identity mapping