---
ver: rpa2
title: Detecting Instruction Fine-tuning Attacks using Influence Function
arxiv_id: '2504.09026'
source_url: https://arxiv.org/abs/2504.09026
tags:
- data
- influence
- fine-tuning
- poisoned
- sentiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of detecting instruction fine-tuning
  attacks on large language models, where poisoned data is deliberately embedded in
  training datasets to cause harmful behaviors without obvious triggers. The proposed
  method uses influence functions under semantic transformation to identify critical
  poisons by comparing influence distributions before and after transformations, flagging
  examples whose influence remains strong and unchanged across transformations.
---

# Detecting Instruction Fine-tuning Attacks using Influence Function

## Quick Facts
- arXiv ID: 2504.09026
- Source URL: https://arxiv.org/abs/2504.09026
- Reference count: 23
- Primary result: Detects poisoned fine-tuning examples achieving 79.5-95.2% F1 score using influence functions under semantic transformations

## Executive Summary
This paper addresses the challenge of detecting instruction fine-tuning attacks on large language models, where poisoned data is deliberately embedded in training datasets to cause harmful behaviors without obvious triggers. The proposed method uses influence functions under semantic transformation to identify critical poisons by comparing influence distributions before and after transformations, flagging examples whose influence remains strong and unchanged across transformations. A multi-transform ensemble approach achieves high detection accuracy while maintaining low false positive rates.

## Method Summary
The detection method computes influence scores for each training example using influence functions with EK-FAC approximation, then applies six semantic transformations (prefix negation, antonym substitution, paraphrasing, question negation, grammatical negation, clause reordering) to the test data. For each transformation, influence scores are recalculated and compared to the original distribution. The ensemble detection uses two approaches: variance method flagging high-variance samples across transforms, and voting method flagging samples detected across multiple transform categories. Critical poisons are identified as examples whose influence remains strong and unchanged across transformations, indicating they are not dependent on specific semantic patterns.

## Key Results
- F1 scores between 79.5% and 95.2% with precision between 66% and 100% on sentiment classification tasks
- Generalizes to unseen transformation types with 86% F1 score
- Successfully recovers model performance to near-clean levels by removing 1-3% of detected poisons
- Outperforms single-transform baselines with 3.5% precision improvement

## Why This Works (Mechanism)
The method exploits the fundamental property that poisoned examples designed to trigger specific behaviors will have influence scores that remain consistent across semantic transformations, while benign examples show varying influence. By comparing influence distributions before and after transformations, the method identifies examples that are robust to semantic changes, which is characteristic of poisoned data designed to maintain trigger effectiveness.

## Foundational Learning
- **Influence functions**: Mathematical framework for tracing model parameters' changes back to training data points; needed to quantify each training example's contribution to model behavior; quick check: verify influence scores correlate with training loss reduction
- **EK-FAC approximation**: Efficient computation of influence using Kronecker-factored curvature; needed for scalability to large models; quick check: compare EK-FAC vs exact influence computation on small subset
- **Semantic transformations**: Systematic modifications preserving meaning (negation, paraphrasing, reordering); needed to create diverse test conditions; quick check: validate transformations maintain semantic equivalence via human evaluation
- **Ensemble detection**: Combining multiple detection strategies to improve robustness; needed to handle diverse poisoning patterns; quick check: analyze detection overlap between variance and voting methods
- **Poisoning attacks**: Deliberate contamination of training data to induce specific model behaviors; needed to understand threat model; quick check: verify poisoned examples successfully trigger target behavior before detection

## Architecture Onboarding
**Component map**: Data → Fine-tuning → Influence computation → Transformation → Detection → Model recovery

**Critical path**: The detection pipeline (influence computation → transformation → ensemble detection) is the core innovation, with the fine-tuning step providing the poisoned model to analyze and the recovery step validating detection effectiveness.

**Design tradeoffs**: 
- EK-FAC approximation vs exact influence computation (accuracy vs scalability)
- Number of transformations vs detection robustness (more transforms increase coverage but computational cost)
- Variance threshold vs false positive rate (higher threshold reduces false positives but may miss subtle poisons)

**Failure signatures**: 
- High false positive rate indicates overly aggressive variance threshold
- Low detection precision suggests transformations are too weak to expose poison characteristics
- OOM errors during influence computation indicate need to reduce tracked layers or batch size

**3 first experiments**:
1. Run influence computation on clean vs poisoned dataset to establish baseline influence score distributions
2. Apply single transformation (e.g., prefix negation) to test data and compare influence score changes
3. Implement ensemble detection on small dataset to validate variance and voting methods

## Open Questions the Paper Calls Out
None

## Limitations
- Method's effectiveness depends heavily on the choice of semantic transformations, with specific implementations not fully detailed
- Scalability to larger models remains untested beyond the 1.3B parameter DeepSeek-Coder model
- The variance-based detection threshold and voting agreement criteria are unspecified, requiring empirical tuning

## Confidence
- **High confidence**: The method's core approach of using influence functions under semantic transformations to detect poisoned examples is technically sound and well-supported by the results showing F1 scores of 79.5-95.2% and precision of 66-100% on SST-2
- **Medium confidence**: The generalization to unseen transformation types (86% F1) and recovery of model performance by removing 1-3% of detected poisons is demonstrated but relies on the specific poisoning setup and transformation implementations
- **Low confidence**: The method's robustness against adaptive attacks that specifically target the influence function detection mechanism, and its performance on more complex reasoning tasks beyond sentiment classification, remain uncertain

## Next Checks
1. Implement and validate all six semantic transformations independently to ensure the influence score distributions match those reported in the paper, particularly focusing on the paraphrasing and grammatical negation transformations
2. Conduct ablation studies varying the variance percentile threshold and voting agreement criteria to identify optimal values and understand their impact on detection performance across different poisoning ratios
3. Test the method against a more sophisticated poisoning strategy where the trigger is embedded in multiple forms (not just NER replacement) and evaluate whether the ensemble approach maintains its detection capability