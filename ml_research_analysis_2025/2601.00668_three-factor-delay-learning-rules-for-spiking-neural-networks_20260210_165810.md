---
ver: rpa2
title: Three factor delay learning rules for spiking neural networks
arxiv_id: '2601.00668'
source_url: https://arxiv.org/abs/2601.00668
tags:
- learning
- delays
- delay
- accuracy
- synaptic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning temporal delays
  in spiking neural networks (SNNs) for real-time operation in resource-constrained
  environments. The authors propose three-factor delay learning rules to simultaneously
  learn synaptic and axonal delays online in both feedforward and recurrent SNN architectures.
---

# Three factor delay learning rules for spiking neural networks

## Quick Facts
- arXiv ID: 2601.00668
- Source URL: https://arxiv.org/abs/2601.00668
- Reference count: 40
- Three-factor learning rules enable online learning of synaptic and axonal delays in spiking neural networks

## Executive Summary
This paper addresses the challenge of learning temporal delays in spiking neural networks (SNNs) for real-time operation in resource-constrained environments. The authors propose three-factor delay learning rules to simultaneously learn synaptic and axonal delays online in both feedforward and recurrent SNN architectures. Their method employs a smooth Gaussian surrogate function to approximate spike derivatives exclusively for eligibility trace calculation, combined with a top-down error signal to determine parameter updates.

Experiments on speech recognition datasets (SHD and SSC) demonstrate that incorporating delays improves classification accuracy by up to 20% over weights-only baselines. For networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD dataset, the method achieves accuracy comparable to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. The approach particularly benefits small and sparse networks, where delay learning provides significant accuracy improvements despite minimal additional memory overhead.

## Method Summary
The method employs three-factor learning rules based on eligibility traces to learn synaptic and axonal delays in spiking neural networks. The approach uses a Gaussian surrogate kernel to approximate spike derivatives for eligibility trace calculation while maintaining binary spikes during forward inference. This enables online, local updates of delay parameters through a combination of pre-post eligibility traces and top-down error signals. The learning rules are applied to both feedforward and recurrent architectures, with experiments conducted on speech recognition datasets using leaky integrate-and-fire neurons and leaky integrator readout layers.

## Key Results
- Incorporating delays improves classification accuracy by up to 20% over weights-only baselines
- Jointly learning weights and delays yields up to 14% higher accuracy for similar parameter counts
- Achieves comparable accuracy to offline backpropagation on SHD dataset while reducing model size by 6.6x and inference latency by 67%
- Particularly effective in small and sparse networks, providing significant accuracy improvements with minimal memory overhead

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Temporal delays act as learnable time-shifts that align causally relevant spikes to exceed neuronal thresholds, improving temporal pattern recognition without increasing network width.
- **Mechanism:** The network introduces specific delay parameters ($D_{ji}$ or $D_i$) that shift spike arrival times. By learning these delays, the network aligns distinct pre-synaptic spikes to coincide at the post-synaptic neuron, summing their membrane potential contributions to trigger firing (overcoming the decay inherent in Leaky Integrate-and-Fire models).
- **Core assumption:** The performance bottleneck in weights-only SNNs is primarily temporal misalignment of information rather than a lack of representational capacity (width).
- **Evidence anchors:**
  - [abstract]: "...learnable parameters that delay spike times can improve classification performance in temporal tasks..."
  - [section I]: "However, if t1 is delayed to t12 by Dji, then the spikes co-incide and... a spike is emitted."
  - [corpus]: Related work (DeNN, DCLS) supports the general utility of delays in exploiting temporal information.
- **Break condition:** If the task requires complex non-linear spatial transformations rather than temporal alignment, delay learning may offer negligible gains over weights-only baselines.

### Mechanism 2
- **Claim:** A Gaussian surrogate kernel allows gradient-based optimization of discrete delay parameters by approximating the non-differentiable spike derivative during the backward pass.
- **Mechanism:** Spikes are discrete events (Dirac deltas), making direct gradient calculation impossible. The method approximates the spike train with a smooth Gaussian function parameterized by delay. This allows the calculation of $\frac{dx}{dD}$ (derivative of input w.r.t. delay), enabling gradient descent on delay values without altering the forward inference (which uses binary spikes).
- **Core assumption:** The smooth Gaussian derivative is a sufficient proxy for the true temporal gradient to guide learning.
- **Evidence anchors:**
  - [section III-D]: "We overcome this problem by representing the spike with a continuous function... particularly the Gaussian kernel."
  - [section IV-B]: "...the Gaussian kernel is only invoked during parameter updates."
  - [corpus]: "Beyond Rate Coding" confirms surrogate gradients generally enable spike timing learning.
- **Break condition:** If the kernel width ($\sigma$) is misspecified relative to the timestep, the gradient approximation may fail to capture precise timing relationships.

### Mechanism 3
- **Claim:** Three-factor learning rules enable online, local updates of delays by combining pre-post eligibility traces with a top-down error signal, removing the need for global backpropagation through time (BPTT).
- **Mechanism:** Instead of storing a history for BPTT, the network maintains an "eligibility trace" ($e^t_{ji}$)—a recursive record of local neural dynamics. This trace is modulated by a third factor, a top-down error signal ($L^t_j$), to compute updates instantly. This solves the "update-locking" problem, allowing learning in real-time streams.
- **Core assumption:** The local eligibility trace approximates the temporal credit assignment well enough that modulating it with a global error signal converges similarly to BPTT.
- **Evidence anchors:**
  - [abstract]: "...eligibility trace calculation, and together with a top-down error signal determine parameter updates."
  - [section III-C]: "The eligibility trace... incorporates information about the previous spiking activity and can be recursively expressed, permitting real-time implementation."
  - [corpus]: "Three-Factor Learning in Spiking Neural Networks: An Overview..." validates this as a standard framework for local plasticity.
- **Break condition:** In deep recurrent architectures, the approximation error of local traces may accumulate, potentially causing divergence or stalling compared to exact BPTT.

## Foundational Learning

- **Concept: Surrogate Gradient Descent**
  - **Why needed here:** Spiking neurons use a discontinuous step function to generate spikes. You need to understand that we replace this "hard" step with a "soft" derivative (like a Gaussian or piecewise linear function) purely for the math of learning, while keeping the forward pass efficient.
  - **Quick check question:** If the forward pass uses binary spikes (0 or 1), how does the network calculate a gradient for the backward pass?

- **Concept: Eligibility Traces (e-prop)**
  - **Why needed here:** This paper relies on "online" learning. You must understand that an eligibility trace is a memory vector stored locally at the synapse that records "how much did this synapse contribute to recent activity?" so it can be updated later when an error signal arrives, without storing the whole network history.
  - **Quick check question:** How does an eligibility trace allow a synapse to update its weight based on an error that occurs *after* the spike has passed, without waiting for the end of the sequence?

- **Concept: Synaptic vs. Axonal Delays**
  - **Why needed here:** The paper distinguishes these two. Synaptic delays are per-connection ($D_{ji}$), while axonal delays are per-neuron output ($D_j$). This distinction affects memory usage (quadratic vs linear scaling) and implementation complexity.
  - **Quick check question:** Why would axonal delays scale more efficiently with layer size than synaptic delays?

## Architecture Onboarding

- **Component map:** Input Layer -> Hidden Layer (LIF with delays) -> Readout Layer (LI) -> Learning Module
- **Critical path:** The calculation of the eligibility trace (Eq. 9) combined with the Gaussian surrogate derivative (Eq. 11-12). This dictates the precision and latency of the online learning update.
- **Design tradeoffs:**
  - **Synaptic vs. Axonal:** Synaptic delays offer higher accuracy (finer granularity) but scale quadratically with neurons ($O(N^2)$). Axonal delays scale linearly ($O(N)$) but offer less precision.
  - **Online vs. Offline:** Online learning reduces memory/inference latency but may sacrifice 2-3% accuracy compared to offline BPTT on complex tasks.
  - **Sparsity:** Delay learning is most effective in sparse networks (80% sparse), providing significant accuracy recovery with minimal memory overhead.
- **Failure signatures:**
  - **Stagnant Accuracy:** If delays are initialized poorly or learning rates ($10^{-2}$ for delays vs $10^{-4}$ for weights) are mismatched, delays may not converge.
  - **Memory Overflow:** Implementing dense synaptic delays ($D_{max} = 25$) requires significant ring buffers; running out of SRAM usually indicates a need to switch to axonal delays or higher sparsity.
  - **Approximation Drift:** In deep recurrent stacks, if the local eligibility trace diverges from the true gradient, weights may oscillate or diverge.
- **First 3 experiments:**
  1. **Baseline Verification:** Train a weights-only SNN on SHD/SSC datasets to establish a baseline accuracy (e.g., ~79% on SHD).
  2. **Delay Ablation:** Add fixed random delays to verify the hypothesis that mere temporal shifting improves performance (jump to ~92% in paper).
  3. **Online vs. Offline Comparison:** Train delays using the proposed three-factor online rule vs. an offline BPTT method to measure the "approximation gap" and verify convergence speed.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed online delay learning rules scale to cognitively demanding tasks beyond keyword spotting?
- Basis in paper: [explicit] The conclusion states, "While further research is required to scale to cognitively demanding tasks, online delay learning offers a practical solution..."
- Why unresolved: The current experiments are restricted to speech recognition datasets (SHD and SSC), which may not fully represent the temporal complexity of higher-level cognitive processing.
- What evidence would resolve it: Successful application and convergence of the method on complex decision-making tasks or datasets requiring long-term temporal dependencies.

### Open Question 2
- Question: To what extent does increasing network depth improve performance on challenging datasets like SSC?
- Basis in paper: [explicit] Section VI notes, "We anticipate that incorporating multiple layers could further enhance accuracy on both datasets, but would be particularly beneficial for SSC."
- Why unresolved: The authors focus on single-layer networks to demonstrate parameter efficiency and approximation equivalence, leaving deep architectures unexplored.
- What evidence would resolve it: Comparative benchmarks of multi-layer SNNs trained with these rules against single-layer baselines on the SSC dataset.

### Open Question 3
- Question: Can Time-to-First-Spike (TTFS) coding strategies mitigate the performance gap in axonal delay learning?
- Basis in paper: [explicit] Section VI-A suggests, "These inaccuracies could potentially be mitigated by adopting alternative coding strategies, such as time-to-first-spike (TTFS) coding..."
- Why unresolved: The current rate-coded approach results in an 8% accuracy gap for axonal delays compared to backpropagation, suspected to be caused by accumulated approximation errors.
- What evidence would resolve it: Implementation of the learning rules within a TTFS framework showing reduced approximation error and improved axonal delay accuracy.

### Open Question 4
- Question: Can a strictly causal surrogate kernel be developed to support effective delay learning for real-time hardware?
- Basis in paper: [inferred] Section III-D states that "causal kernels... did not support effective learning" in preliminary experiments, forcing the use of non-causal Gaussian kernels which require ring buffers.
- Why unresolved: The dependency on non-causal kernels increases implementation complexity (buffering) for real-time neuromorphic processors.
- What evidence would resolve it: Discovery of a causal surrogate function that provides stable gradient approximations for delay updates without buffering future spikes.

## Limitations

- Missing critical hyperparameters: membrane time constant, decay factor, threshold, timestep, Gaussian kernel width, weight/delay initialization, and optimizer type
- Comparison to offline backpropagation shows "comparable accuracy" without quantitative metrics
- Performance on deep recurrent architectures not evaluated
- Implementation complexity increases for real-time hardware due to non-causal Gaussian kernel requirements

## Confidence

- **High confidence**: The core mechanism of using Gaussian surrogate gradients for delay optimization and three-factor learning rules for online training is well-established in the literature
- **Medium confidence**: The claimed 14% accuracy improvement over weights-only baselines and 67% latency reduction compared to state-of-the-art methods, as these depend on unspecified implementation details
- **Low confidence**: The comparison to offline backpropagation-based approaches showing "comparable accuracy" lacks quantitative metrics and detailed experimental conditions

## Next Checks

1. Verify implementation of analytical LIF dynamics versus Euler integration on a small dataset to measure the 15% accuracy gap mentioned in comparison with SpikingJelly baseline
2. Conduct ablation studies systematically varying Gaussian kernel width (σ) to identify the optimal range and test gradient stability across delay ranges
3. Test the three-factor online learning rule on a deep recurrent architecture to measure approximation error accumulation compared to exact BPTT across multiple layers