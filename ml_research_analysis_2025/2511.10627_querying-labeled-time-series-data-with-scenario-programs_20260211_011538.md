---
ver: rpa2
title: Querying Labeled Time Series Data with Scenario Programs
arxiv_id: '2511.10627'
source_url: https://arxiv.org/abs/2511.10627
tags:
- trace
- label
- scenario
- algorithm
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the sim-to-real validation problem in cyber-physical
  systems, specifically how to verify whether failure scenarios identified in simulation
  are reproducible with real-world sensor data. The authors propose querying labeled
  time series sensor data against formal scenario models expressed in the Scenic probabilistic
  programming language.
---

# Querying Labeled Time Series Data with Scenario Programs

## Quick Facts
- arXiv ID: 2511.10627
- Source URL: https://arxiv.org/abs/2511.10627
- Reference count: 40
- Primary result: Formal scenario querying algorithm achieves 80% accuracy vs 45-60% for VLMs, with 0.06s query time vs 6-41s

## Executive Summary
This paper addresses sim-to-real validation by querying labeled time series sensor data against formal Scenic scenario models. The authors translate Scenic programs into hierarchical finite state machines (HFSMs) and use SMT solvers to check whether real-world labeled traces match the specified scenarios. Experimental results demonstrate significantly higher accuracy and faster query times compared to state-of-the-art vision language models when applied to nuScenes driving dataset.

## Method Summary
The method translates Scenic programs (specifically `try/interrupt` and `do/until` statements) into Hierarchical Finite State Machines (HFSMs) using a syntax-directed approach. Object positions and orientations are extracted from nuScenes videos, and primitive behaviors are classified using a behavior prediction model. The query algorithm uses the `cvc5` SMT solver to find object correspondences and validate that HFSM outputs match observed label traces over a sliding window. The process involves initial scene checking, object correspondence search with type-based pruning, and iterative HFSM evaluation through recursive state traversal.

## Key Results
- Algorithm achieves 80% accuracy versus 45-60% for VLMs on nuScenes validation
- Query runtime is 0.06 seconds versus 6-41 seconds for VLMs
- Runtime scales linearly with video duration but exponentially with object count (8 objects causes timeout at 10 seconds)

## Why This Works (Mechanism)

### Mechanism 1
Translating Scenic programs to hierarchical finite state machines (HFSMs) preserves scenario semantics while enabling efficient trace matching. The syntax-directed translation converts Scenic behavioral constructs into HFSM states with guards, where each behavior becomes a machine and primitive behaviors become base states. The hierarchical structure allows recursive state traversal where parent states transition only after child termination. This works because the supported Scenic fragment ensures guards are memoryless—dependent only on current input, not input history.

### Mechanism 2
SMT-based object correspondence search with type-based pruning reduces the combinatorial explosion while maintaining correctness guarantees. The algorithm extracts object types from both the Scenic AST and label trace, then encodes correspondence constraints as SMT formulas. Only objects matching type and minimum observation duration are candidates. When a correspondence fails, a blocking constraint prevents re-exploration. This relies on the assumption that objects can be uniquely identified and typed in the label trace with sufficient accuracy to enable meaningful pruning.

### Mechanism 3
Guard evaluation via SMT with unobserved variable domain encoding handles probabilistic interrupt conditions without sampling. Unobserved variables are encoded into SMT formulas with their domains, such that guards evaluate to true if any value in the domain satisfies the formula. When both a guard and its negation are satisfiable, non-deterministic transitions occur, producing multiple possible outputs. This assumes unobserved variables have finite, enumerable domains or can be abstracted into SMT-solvable constraints.

## Foundational Learning

- **Probabilistic Programming Languages (specifically Scenic)**: Why needed here: Scenic defines distributions over initial scenes and behaviors; understanding that a program represents a set of possible traces, not a single trace, is essential for grasping the matching semantics. Quick check: Given a Scenic program with `interrupt when distance < Range(1,15)`, what are the possible outputs when distance=10?

- **Hierarchical Finite State Machines (HFSMs)**: Why needed here: The core algorithm operates on HFSMs; you must understand state refinement (parent→child traversal), termination propagation, and how outputs are determined by base states only. Quick check: In an HFSM where state A contains state B which contains base state C, when is C's output produced?

- **Satisfiability Modulo Theories (SMT)**: Why needed here: Guard evaluation and correspondence search both use SMT solvers; understanding non-linear real arithmetic vs. linear integer arithmetic theories determines which constraints are solvable. Quick check: Why can't we encode "object o1 appeared before object o2" using only linear integer arithmetic?

## Architecture Onboarding

- **Component map**: Parser -> AST -> Translator -> HFSM Dictionary -> Correspondence Encoder -> Query Engine -> ValidStep -> SMT Solver
- **Critical path**: 1) Initial scene check (InitialInputMatch) — fast rejection if support mismatch 2) Correspondence search — exponential worst case; dominates runtime for >4 objects 3) ValidStep loop over sliding window — linear in window length, but repeated per correspondence
- **Design tradeoffs**: Accuracy vs. label quality (algorithm is sound but depends on primitive behavior labels), Expressiveness vs. tractability (supported fragment excludes variable assignments), Completeness vs. runtime (checking all correspondences guarantees soundness but causes exponential scaling)
- **Failure signatures**: Empty output set (all currentBaseStates pruned), Timeout on correspondence (>6 objects with similar types), False negatives on valid matches (check primitive behavior classifier accuracy)
- **First 3 experiments**: 1) Minimal reproduction: Write 2-object Scenic program with simple follow/interrupt behavior; verify Query returns True with correct correspondence 2) Correspondence scaling: Replicate objects (2→4→6→8) with identical behaviors; measure query time to confirm exponential trend 3) Label noise sensitivity: Manually corrupt primitive behavior labels (e.g., flip 10% of timesteps); measure accuracy degradation

## Open Questions the Paper Calls Out

### Open Question 1
Can the object correspondence search be optimized to prevent the exponential growth of query time as the number of objects increases? The current SMT-based enumeration leads to factorial increase in search space (8! correspondences for 8 objects). A demonstrated polynomial-time algorithm or heuristic pruning method that maintains accuracy while scaling to dense scenarios with 10+ objects would resolve this.

### Open Question 2
How can the supported Scenic fragment be extended to support stateful behaviors where guards depend on the history of inputs? The current translation relies on memoryless property to evaluate guards based solely on current semantic features. An extended translation methodology that compiles history-dependent Scenic syntax into HFSMs capable of maintaining internal state variables across timesteps would address this.

### Open Question 3
How can the querying algorithm be made robust to errors in the primitive behavior labels provided by upstream prediction models? The algorithm currently assumes label trace is ground truth, performing strict set intersections that fail if behavior classifier produces unrealistic outputs. A probabilistic query mechanism or temporal smoothing integration that allows tolerance for transient misclassifications would resolve this.

## Limitations

- Dependence on high-quality primitive behavior labels from VisionTrap classifier limits practical accuracy
- Exponential scaling with object count makes approach impractical for complex multi-agent situations (8+ objects causes timeout)
- Supported Scenic fragment excludes scenarios requiring memory of past states or complex temporal logic

## Confidence

- **High confidence**: Formal translation from Scenic to HFSMs is sound within supported fragment, following Scenic semantics directly
- **Medium confidence**: Runtime scaling claims based on controlled experiments may not reflect real-world performance with noisy object typing
- **Low confidence**: Practical accuracy ceiling depends entirely on VisionTrap's performance, which isn't characterized in the paper

## Next Checks

1. **Label Noise Sensitivity Analysis**: Systematically vary error rate in primitive behavior labels (0%, 5%, 10%, 20%) for matching traces to quantify how label quality affects algorithm accuracy versus intrinsic matching performance.

2. **Object Typing Robustness**: Test correspondence search with increasingly noisy object type classifications (perfect typing → 90% → 80% accuracy) to determine practical limits of type-based pruning mechanism.

3. **Expressiveness Boundary Test**: Attempt to encode scenario requiring memory (e.g., "interrupt if speed > 20 m/s and ego has been following for >5 seconds") using current framework versus hypothetical extension with variable assignments, to empirically demonstrate expressiveness limitations.