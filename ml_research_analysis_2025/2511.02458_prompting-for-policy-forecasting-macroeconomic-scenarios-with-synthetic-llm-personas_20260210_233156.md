---
ver: rpa2
title: 'Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM
  Personas'
arxiv_id: '2511.02458'
source_url: https://arxiv.org/abs/2511.02458
tags:
- human
- persona
- forecasts
- forecasting
- economic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates whether persona-based prompting improves Large
  Language Model (LLM) performance on macroeconomic forecasting tasks. Using 2,368
  economics-related personas extracted from the PersonaHub corpus, GPT-4o was prompted
  to replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds
  (2013-2025).
---

# Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM Personas

## Quick Facts
- arXiv ID: 2511.02458
- Source URL: https://arxiv.org/abs/2511.02458
- Reference count: 30
- Primary result: Persona-based prompting provides no measurable forecasting advantage in LLM macroeconomic predictions

## Executive Summary
This paper evaluates whether persona-based prompting improves Large Language Model (LLM) performance on macroeconomic forecasting tasks. Using 2,368 economics-related personas extracted from the PersonaHub corpus, GPT-4o was prompted to replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds (2013-2025). The study found that persona descriptions provided no measurable forecasting advantage, with context quality and task framing being the primary drivers of accuracy. GPT-4o forecasts achieved accuracy levels comparable to human expert panels, though AI forecasts exhibited substantially lower dispersion than human forecasts, suggesting limited sensitivity to prompt variations.

## Method Summary
The study filtered the PersonaHub corpus to 2,368 economics-related personas using keyword searches, NER name removal, embedding deduplication (≥0.90 cosine), and LLM relevance rating. GPT-4o (temperature=1) was prompted with system rules, optional persona descriptions, ECB press releases, macro snapshots, and task instructions. Each round generated 2,368 persona-based forecasts plus 100 no-persona baselines. Forecasts were aggregated via cross-sectional median and compared against realized macroeconomic outcomes across four variables (HICP inflation, core HICP, GDP growth, unemployment) at four horizons. Evaluation included in-sample (2013-2023) and out-of-sample (2024-2025) periods with MAE, win-share, and panel dispersion metrics.

## Key Results
- Persona descriptions provided no measurable forecasting advantage over baseline prompts (MAE equivalence, paired t-test significance)
- GPT-4o and human forecasters achieved remarkably similar accuracy levels with statistically significant but practically modest differences
- AI forecasts exhibited substantially lower dispersion than human forecasts (IQRs ~0.001pp vs humans' 0.17-0.58pp)
- Out-of-sample evaluation on 2024-2025 data demonstrated competitive performance on unseen events

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Real-time macroeconomic context drives forecast accuracy, rendering persona descriptions redundant
- **Mechanism:** Model anchors predictions on provided numerical history and ECB communications, prioritizing explicit evidence over implicit behavioral constraints
- **Core assumption:** Model prioritizes context window data over persona behavioral conditioning
- **Evidence anchors:** No measurable advantage from personas; performance depends on data quality and task framing
- **Break condition:** Accuracy would degrade significantly if context data were removed or corrupted

### Mechanism 2
- **Claim:** Synthetic LLM panels exhibit "consensus collapse" where diverse prompts fail to generate diverse outputs
- **Mechanism:** Despite 2,368 unique personas, model converges on narrow distribution, identifying single "optimal" forecast given context
- **Core assumption:** Model perceives task as having "right answer" derived from context, suppressing persona-induced variance
- **Evidence anchors:** AI forecasts show two orders of magnitude lower dispersion than humans; model reverts to "correctness" prior
- **Break condition:** Increasing temperature significantly or introducing adversarial instructions might break convergence

### Mechanism 3
- **Claim:** Out-of-sample generalization achieved through contemporaneous data conditioning rather than memorization
- **Mechanism:** Model utilizes injected real-time economic context for inference, shifting from pattern matching to contextual reasoning
- **Core assumption:** Model has sufficient reasoning capabilities to interpret new data points without relying on historical correlations
- **Evidence anchors:** Competitive performance on 2024-2025 data; model effectively utilizes real-time economic context
- **Break condition:** Performance would likely drop to random chance if context window lacks latest realized data

## Foundational Learning

- **Concept:** **Panel Dispersion (IQR/Standard Deviation)**
  - **Why needed here:** To understand behavioral difference between disagreeing human experts and converging AI agents
  - **Quick check question:** If 1,000 forecasts with different personas yield same number, is your "panel" simulating a crowd or a single mind?

- **Concept:** **Ablation Studies**
  - **Why needed here:** Core contribution proves component (personas) adds no value; understanding variable isolation is key
  - **Quick check question:** If removing component X leaves performance identical, what is component X's implied value?

- **Concept:** **Data Leakage / Memorization**
  - **Why needed here:** Validating out-of-sample results are genuine predictions, not training data recitations
  - **Quick check question:** Why is testing on post-training cutoff data (Oct 2023) critical for genuine predictions?

## Architecture Onboarding

- **Component map:** PersonaHub -> Keyword Search -> NER Removal -> Vector Deduplication -> LLM Rating -> 2,368 Personas -> Prompt Assembler -> GPT-4o -> Aggregator -> Median Forecast

- **Critical path:** Context Injection (Macro Snapshot + ECB Press Release) is critical dependency; Persona pipeline is computationally expensive but functionally inert

- **Design tradeoffs:**
  - Cost vs. Diversity: 118k forecasts vs 100 baseline forecasts; engineering should favor context quality over persona quantity
  - Stability vs. Realism: Low dispersion achieved at cost of behavioral realism (humans disagree more)

- **Failure signatures:**
  - Mode Collapse: Repeated median output across all personas (IQR ≈ 0)
  - Context Ignorance: Ignoring latest realized data block and hallucinating outdated figures

- **First 3 experiments:**
  1. Context Ablation: Run forecasts without ECB press release and macro snapshot to quantify context contribution
  2. Variance Injection: Test if Chain-of-Thought or Town Hall debates increase AI forecast dispersion to match human disagreement
  3. Model Scaling: Replicate with GPT-4o-mini to test if context dominance holds or smaller models rely more on persona cues

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Which specific prompt components genuinely drive forecasting performance versus merely increasing token costs?
- **Basis:** Future Work states need to systematically ablate other prompt components
- **Why unresolved:** Ablation only tested persona descriptions; other components held constant
- **What evidence would resolve:** Factorial ablation study isolating each context component's accuracy contribution

### Open Question 2
- **Question:** Can LLMs generate meaningful density forecasts that quantify uncertainty, not just point estimates?
- **Basis:** Future Work notes evaluating density forecasts would test LLM uncertainty quantification
- **Why unresolved:** Study only evaluated point forecasts; probability distributions not tested
- **What evidence would resolve:** Comparison of LLM-generated probability distributions against human SPF density forecasts

### Open Question 3
- **Question:** Can alternative prompting strategies generate forecast diversity that persona-based prompting failed to achieve?
- **Basis:** Future Work suggests chain-of-thought reasoning or adversarial perspectives may prove more effective
- **Why unresolved:** AI forecasts showed near-zero dispersion despite 2,368 diverse personas
- **What evidence would resolve:** Controlled experiments comparing persona prompting against alternative strategies on dispersion metrics

## Limitations
- Reliance on GPT-4o's deterministic behavior at temperature=1 may suppress persona diversity
- Context injection mechanism's marginal contribution not quantified through systematic variation
- Near-zero dispersion could reflect model architecture constraints or prompt engineering failures rather than fundamental limitations

## Confidence

**High Confidence:** Persona descriptions add no measurable forecasting advantage is robust given controlled ablation design and large sample size

**Medium Confidence:** Context quality dominates over persona effects assumes no confounding variables in prompt design

**Low Confidence:** "Consensus collapse" claim lacks mechanistic explanation for why 2,368 personas produce identical outputs

## Next Checks
1. Systematically remove and reintroduce macro snapshot and ECB press release blocks to measure individual contributions to accuracy
2. Apply Chain-of-Thought prompting or Town Hall debate formats to test if structured reasoning increases forecast disagreement
3. Run identical experiments with GPT-4o-mini and Claude models to test if context dominance is model-specific or represents broader architectural constraint