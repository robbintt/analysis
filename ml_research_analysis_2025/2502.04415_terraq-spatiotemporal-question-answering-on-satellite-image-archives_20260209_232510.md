---
ver: rpa2
title: 'TerraQ: Spatiotemporal Question-Answering on Satellite Image Archives'
arxiv_id: '2502.04415'
source_url: https://arxiv.org/abs/2502.04415
tags:
- knowledge
- terraq
- query
- image
- available
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TerraQ is a spatiotemporal question-answering engine for satellite
  image archives that translates natural language queries into SPARQL queries over
  a specialized knowledge graph containing Sentinel-1/Sentinel-2 metadata and geospatial
  information. The system uses a pipeline of components including dependency parsing,
  entity recognition, concept identification, spatial relation mapping, and query
  generation without relying on predefined templates.
---

# TerraQ: Spatiotemporal Question-Answering on Satellite Image Archives

## Quick Facts
- arXiv ID: 2502.04415
- Source URL: https://arxiv.org/abs/2502.04415
- Reference count: 25
- Outperforms state-of-the-art by 4 percentage points (10% relative improvement) on GeoQuestions1089 benchmark

## Executive Summary
TerraQ is a spatiotemporal question-answering engine designed to process natural language queries over satellite image archives. The system translates user questions into SPARQL queries executed against a specialized knowledge graph containing Sentinel-1/Sentinel-2 metadata and geospatial information. By avoiding predefined templates and using a pipeline approach combining dependency parsing, entity recognition, and spatial relation mapping, TerraQ achieves 44.36% accuracy on the GeoQuestions1089 benchmark, representing a 10% relative improvement over previous systems while maintaining computational efficiency.

## Method Summary
TerraQ implements a template-free approach to convert natural language queries into SPARQL through a pipeline of components: dependency parsing for syntactic structure, named entity recognition for spatial and temporal elements, concept identification for semantic understanding, spatial relation mapping for geospatial context, and query generation for SPARQL construction. The system operates over a materialized knowledge graph containing Sentinel-1/Sentinel-2 metadata with precomputed geospatial relations, enabling efficient query execution without relying on predefined question templates.

## Key Results
- Achieves 44.36% accuracy on GeoQuestions1089 benchmark dataset
- Outperforms state-of-the-art systems by 4 percentage points (10% relative improvement)
- Maintains computational efficiency through heuristic-based approaches and materialization of geospatial relations

## Why This Works (Mechanism)
TerraQ's template-free pipeline approach allows flexible handling of diverse natural language queries by breaking down questions into semantic components rather than matching against predefined patterns. The materialization of geospatial relations in the knowledge graph enables efficient spatial reasoning without complex runtime computations. The integration of dependency parsing with entity recognition ensures accurate identification of spatial relationships and temporal constraints within queries.

## Foundational Learning
- **Dependency Parsing**: Analyzes grammatical structure to identify relationships between words; needed to understand query syntax and extract meaningful components; quick check: verify parsed tree correctly identifies subject-verb-object relationships
- **Named Entity Recognition**: Identifies spatial locations, temporal references, and satellite-related entities; needed to extract query components for knowledge graph matching; quick check: test recognition accuracy on sample spatial and temporal phrases
- **SPARQL Query Generation**: Translates semantic components into executable database queries; needed to bridge natural language understanding with knowledge graph interrogation; quick check: validate generated SPARQL against known answers
- **Knowledge Graph Materialization**: Precomputes and stores geospatial relations; needed to enable efficient spatial reasoning without runtime computation; quick check: measure query response time with and without materialized relations
- **Spatial Relation Mapping**: Converts natural language spatial descriptions into formal geospatial relationships; needed to enable accurate spatial reasoning in queries; quick check: test mapping accuracy on various spatial prepositions
- **Temporal Reasoning**: Handles time-based query constraints and relationships; needed to support queries about satellite imagery over time; quick check: verify temporal filter generation for different time expressions

## Architecture Onboarding

**Component Map:** Natural Language Query -> Dependency Parser -> Entity Recognizer -> Concept Identifier -> Spatial Mapper -> Query Generator -> SPARQL Query -> Knowledge Graph

**Critical Path:** The critical execution path flows from natural language query through parsing and entity recognition to query generation and knowledge graph execution. Each component must successfully process its input for the system to generate valid SPARQL.

**Design Tradeoffs:** The system trades template flexibility for computational efficiency by using heuristic approaches and materialization rather than complex reasoning engines. This choice prioritizes speed and scalability over handling highly complex or ambiguous queries.

**Failure Signatures:** Common failure modes include unrecognized spatial entities, ambiguous temporal references, unsupported spatial relation types, and incomplete knowledge graph coverage. These manifest as either failed query generation or incorrect SPARQL execution.

**First 3 Experiments:**
1. Test basic query processing with simple spatial questions using known entities
2. Evaluate temporal reasoning with straightforward time-based queries
3. Measure performance impact of knowledge graph materialization versus runtime computation

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Heavy dependence on completeness and accuracy of Sentinel-1/Sentinel-2 metadata coverage
- Limited performance on complex spatial relations outside predefined templates
- Storage overhead and potential staleness issues from geospatial relation materialization strategy

## Confidence

**Accuracy Claims:** High - clear methodology and benchmark comparison
**Scalability Claims:** Medium - demonstrated efficiency but limited large-scale testing
**Generalizability Claims:** Low - heavy specialization for Sentinel datasets and limited spatial relation diversity

## Next Checks
1. Evaluate TerraQ on additional question-answering datasets beyond GeoQuestions1089, particularly those involving heterogeneous satellite sources
2. Conduct systematic analysis of query failures to identify specific gaps in geospatial relation materialization and metadata coverage
3. Measure system performance and storage requirements when scaling to full archive of Sentinel imagery spanning multiple years, including real-time update scenarios