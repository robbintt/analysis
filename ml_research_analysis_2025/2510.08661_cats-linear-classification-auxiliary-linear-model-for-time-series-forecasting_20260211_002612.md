---
ver: rpa2
title: 'CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting'
arxiv_id: '2510.08661'
source_url: https://arxiv.org/abs/2510.08661
tags:
- series
- time
- forecasting
- linear
- cats-linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving linear models for
  time series forecasting, which have shown competitive performance against complex
  architectures but lack methodological enhancements. The authors propose CATS-Linear,
  a Classification Auxiliary Trend-Seasonal Decoupling Linear Model that employs Classification
  Auxiliary Channel-Independence (CACI) to dynamically route time series instances
  to dedicated predictors via classification, enabling supervised channel design.
---

# CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting

## Quick Facts
- arXiv ID: 2510.08661
- Source URL: https://arxiv.org/abs/2510.08661
- Reference count: 5
- Primary result: 8% MSE reduction vs. fixed-hyperparameter baselines, 24 top-ranked results across seven benchmark datasets

## Executive Summary
This paper addresses the challenge of improving linear models for time series forecasting, which have shown competitive performance against complex architectures but lack methodological enhancements. The authors propose CATS-Linear, a Classification Auxiliary Trend-Seasonal Decoupling Linear Model that employs Classification Auxiliary Channel-Independence (CACI) to dynamically route time series instances to dedicated predictors via classification, enabling supervised channel design. Additionally, they redesign the trend-seasonal decomposition architecture with a decoupling-linear mapping-recoupling framework for trend components and complex-domain linear projections for seasonal components. The theoretical analysis shows CATS-Linear achieves state-of-the-art accuracy comparable to hyperparameter-tuned baselines while delivering an 8% MSE reduction against fixed-hyperparameter counterparts.

## Method Summary
CATS-Linear combines a classifier with K=10 TSLinear predictors. TSLinear uses complex-domain projection for seasonality and decoupling-linear-recoupling for trends. The supervised training schema assigns each batch sample to the predictor yielding the lowest MSE, using these assignments as classification labels. The classifier learns to route instances to the optimal predictor, while each predictor is trained only on its assigned samples. During inference, the classifier outputs routing probabilities that weight predictions from all K predictors. The method includes RevIN normalization and supports different classifier architectures (CNN for high-dimensional, MLP for others).

## Key Results
- 8% MSE reduction against fixed-hyperparameter baselines across seven benchmark datasets
- 24 top-ranked results in comprehensive experimental evaluation
- Outperforms DLinear by leveraging CACI routing and TSLinear's specialized trend-seasonal decomposition

## Why This Works (Mechanism)

### Mechanism 1: Prediction-Error-Supervised Instance Routing (CACI)
Routing time series instances to specialized predictors based on their functional mapping characteristics reduces expected risk compared to unified or feature-based channel strategies. During training, the algorithm assigns each instance to the category whose predictor yields minimal MSE for that instance. These error-supervised labels train a classifier to recognize instance-to-predictor mappings. At inference, the classifier outputs routing probabilities that weight predictions from all K predictors. When instances within a dataset share near-identical functional mappings, the bias penalty of unified models vanishes while CACI's variance penalty (K× overhead) dominates—observed in Electricity/Traffic datasets where improvement is modest.

### Mechanism 2: Complex-Domain Periodic Emphasis for Seasonal Components
Representing seasonal components in the complex domain preserves periodic relationships better than direct time-domain linear mapping. Transform s_p → z_p = s_p·e^(jw_p) where w = 2π/T. Points separated by period T share identical arguments. Complex linear mapping W_c produces z_y, then convert to real domain: s_y = δ(z_y)·|z_y| where δ determines sign from Re(z_y/e^(jw(q+L))). This ensures periodic structure is preserved through the linear transformation. When periodicity is irregular, non-stationary, or T is mis-specified, the angular encoding misaligns with actual patterns.

### Mechanism 3: Trend Decoupling via Exponential Smoothing State Extraction
Decomposing trend into independent time-step states before linear mapping produces smoother, more physically plausible predictions than direct trend-to-trend mapping. Given trend model t_i = Σ(α^(j-1)·h_(i-j+1)), invert via h_i = t_i - α·t_(i-1). Apply linear mapping to h sequence, then recouple via convolution with kernel [α^m, ..., α, 1]. When trends exhibit non-exponential influence patterns (e.g., step changes, regime shifts), the α-based decoupling misrepresents state dynamics.

## Foundational Learning

- Concept: Bias-Variance Decomposition in Linear Regression
  - Why needed here: Section 4's theoretical analysis frames CACI vs. channel-mixing vs. channel-independence as a bias-variance tradeoff. Understanding expected risk R(θ) = bias² + variance is essential to interpret why CACI reduces variance error by K× vs. channel-independence while introducing minimal bias.
  - Quick check question: Given N samples split into K classes, what happens to variance error when training K separate models vs. one unified model?

- Concept: Time Series Decomposition (Trend-Seasonal-Residual)
  - Why needed here: The entire TSLinear component builds on moving-average decomposition. Without understanding how Autoformer/DLinear extract trend via moving averages and seasonal via subtraction, the decoupling-recoupling modifications are opaque.
  - Quick check question: If a series has period T=24, how does 24-step moving average extract trend, and what remains as seasonal?

- Concept: Complex Number Representation of Periodic Signals
  - Why needed here: Mechanism 2 relies on Euler's formula e^(jθ) = cos(θ) + j·sin(θ). Understanding how phase encodes position within a period and how linear operations in complex domain preserve phase relationships is critical.
  - Quick check question: Why do z_p and z_(p+T) share identical arguments in the complex encoding, and how does this help the linear layer learn periodic patterns?

## Architecture Onboarding

- Component map:
  - RevIN (normalization): Eliminates scale differences across channels
  - Classifier: 2-layer MLP (tanh→softmax) or 4-layer CNN depending on dataset; outputs K-class probabilities
  - K parallel TSLinear predictors: Each contains seasonal branch (complex transform → linear → real convert) and trend branch (decouple → linear → recouple)
  - Aggregation: Probabilistic weighting of K predictions at inference

- Critical path:
  Training: Batch (X,Y) → RevIN.norm → All K predictors forward → Assign labels by min-MSE → Train classifier with labels → Backprop both
  Inference: Instance → RevIN.norm → Classifier probabilities → Weighted sum of K predictor outputs → RevIN.denorm

- Design tradeoffs:
  - K (number of categories): Higher K reduces variance but increases classifier complexity. Paper shows K≥10 is sufficient; K=20-40 shows no additional gain
  - Classifier architecture: CNN for high-dimensional (Weather), MLP for others. Overly complex classifiers may overfit routing patterns
  - Period T: Dataset-specific (144 for Weather, 96 for ETTm, 24 for others). Mis-specified T breaks seasonal encoding

- Failure signatures:
  - Performance degradation vs. DLinear baseline: Likely misclassification dominating inference; check classifier accuracy on validation set
  - Instability across horizons: May indicate period T mis-specification or α mismatch with actual trend dynamics
  - High-dimensional datasets (Electricity, Traffic) showing modest gains: Consistent linear mappings across instances; CACI overhead not justified

- First 3 experiments:
  1. **Sanity check**: Replicate DLinear baseline, then add CACI with K=3 on a single dataset (e.g., ETTh1). Compare MSE and verify classifier is learning non-trivial routing (not all instances to one predictor)
  2. **Component ablation**: Test TSLinear alone (one-channel, no CACI), CACI with standard linear predictors (no TSLinear), then full CATS-Linear. Isolate contribution of each mechanism
  3. **K sensitivity sweep**: On Electricity (321 dims) and ETTm1 (7 dims), test K ∈ {3, 5, 10, 20, 40}. Verify claim that performance plateaus at K≈10 regardless of dimension D

## Open Questions the Paper Calls Out

### Open Question 1
Does the Classification Auxiliary Channel-Independence (CACI) framework degrade performance on datasets where the underlying functional mappings are predominantly homogeneous? The authors note "moderate performance on the Electricity and Traffic datasets," explicitly conjecturing this "may stem from stronger adherence to consistent linear functional mappings" across samples in these domains. The theoretical analysis suggests a bias-variance trade-off where splitting homogeneous data increases variance, but the specific empirical boundary where CACI becomes detrimental remains undefined.

### Open Question 2
Can the CACI framework effectively integrate with architectures that inherently rely on channel-mixing or self-attention mechanisms? While Table 6 shows improvements on PatchTST and TiDE, the authors claim "CACI is a generalizable method" but do not test it on complex channel-mixing Transformers (e.g., iTransformer, Crossformer) where channel tokens are the primary processing unit. It is unclear if removing channel dependencies (via CACI's routing) conflicts with the inductive biases of models designed specifically to capture cross-channel correlations.

### Open Question 3
How does the stability of the training algorithm depend on the convergence of the classifier versus the predictors? Algorithm 1 utilizes a greedy "Top-N" assignment based on immediate prediction errors to generate labels for the classifier. This heuristic creates a moving target for the classifier; if predictors update rapidly, the class assignments may change faster than the classifier can learn, potentially leading to oscillation or suboptimal routing.

## Limitations

- **Hyperparameter sensitivity:** Performance claims heavily depend on specific hyperparameters including K=10 predictors, α=0.5, m=10, and dataset-specific periods T, with limited exploration of sensitivity across diverse datasets.
- **Classifier architecture ambiguity:** The paper specifies "4-layer CNN" for Weather and "2-layer MLP" for other datasets but lacks critical details about hidden dimensions, filter sizes, or neuron counts.
- **Complex-domain implementation complexity:** The seasonal component transformation involves non-trivial operations including sign recovery using δ functions and complex linear mappings, which may be challenging to implement correctly.

## Confidence

**High confidence:** The core theoretical claims about bias-variance decomposition in Theorem 1, the exponential smoothing state extraction formula in Theorem 3, and the 8% MSE reduction vs. fixed-hyperparameter baselines are well-supported by mathematical derivations and empirical evidence across seven datasets.

**Medium confidence:** The mechanism explanations for CACI routing effectiveness and complex-domain periodic emphasis are logically sound and supported by related work, but would benefit from ablation studies isolating each mechanism's contribution.

**Low confidence:** The generalization claims for high-dimensional datasets (Electricity, Traffic) showing only modest gains are plausible given the limited heterogeneity in their functional mappings, but lack systematic investigation of when CACI overhead becomes counterproductive.

## Next Checks

1. **Component ablation validation:** Implement and test TSLinear alone (no CACI) vs. CACI with standard linear predictors vs. full CATS-Linear on ETTh1 to isolate whether the claimed 8% MSE reduction stems from CACI routing, TSLinear architecture, or their combination.

2. **Classifier routing behavior verification:** During CACI training on any dataset, monitor the distribution of class assignments generated in Step 2 of Algo 1. Verify the classifier learns non-trivial routing patterns (not all instances to one predictor) and that classification accuracy on routing validation set exceeds random chance.

3. **K-sensitivity systematic evaluation:** On both low-dimensional (ETTm1) and high-dimensional (Electricity) datasets, sweep K ∈ {3, 5, 10, 20, 40} to empirically verify the claim that performance plateaus at K≈10 regardless of input dimension D, confirming the O(1) complexity claim.