---
ver: rpa2
title: Navigating Sparsities in High-Dimensional Linear Contextual Bandits
arxiv_id: '2510.08435'
source_url: https://arxiv.org/abs/2510.08435
tags:
- uni00000013
- regret
- lasso
- hope
- sparse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses high-dimensional linear contextual bandit
  problems, where traditional methods struggle due to the curse of dimensionality.
  Existing approaches typically handle either sparse model parameters or sparse context
  covariance eigenvalues, but not both simultaneously.
---

# Navigating Sparsities in High-Dimensional Linear Contextual Bandits

## Quick Facts
- **arXiv ID:** 2510.08435
- **Source URL:** https://arxiv.org/abs/2510.08435
- **Reference count:** 40
- **Primary result:** Novel algorithm HOPE handles both sparse model parameters and sparse context covariance eigenvalues in high-dimensional linear contextual bandits, achieving improved regret bounds in homogeneous settings and efficiently solving previously unsolvable heterogeneous settings.

## Executive Summary
This paper addresses the challenge of high-dimensional linear contextual bandits where traditional methods struggle due to the curse of dimensionality. The authors introduce a unified framework that simultaneously handles two types of sparsity: sparse model parameters (many zeros in the parameter vector) and sparse spectral sparsity (few significant eigenvalues in the context covariance matrix). The core innovation is a pointwise estimator (PWE) that adaptively navigates both sparsity types, enabling effective learning in previously unsolvable mixed-sparsity bandit problems.

## Method Summary
The proposed HOPE algorithm follows an explore-then-commit scheme with a novel PointWise Estimator (PWE) at its core. The method works by transforming the high-dimensional linear bandit problem into a scalar estimation problem through dimensionality reduction. During exploration, the algorithm gathers data for each arm, then splits it to first estimate parameter support and initial parameters using Lasso or Ridgeless Least Squares (RDL), depending on the sparsity type. The second half of the data is then used with the PWE, which constructs a transformation matrix to sparsify the nuisance vector, allowing effective denoising through Lasso. The algorithm adaptively selects between Lasso and RDL initializations based on the detected sparsity pattern.

## Key Results
- HOPE achieves improved regret bounds in homogeneous settings compared to single-sparsity baselines
- For the first time, efficiently handles two challenging heterogeneous settings where sparsity types vary across arms
- Experiments validate HOPE's superiority and flexibility across various scenarios, including sparse parameters only, sparse eigenvalues only, both sparsities, and mixed sparsity settings
- The framework generalizes and improves upon previous methods, enabling effective learning in previously unsolvable mixed-sparsity bandit problems

## Why This Works (Mechanism)

### Mechanism 1: Dimensionality Reduction via Pointwise Estimation
- **Claim:** If the regression target is shifted from the global parameter vector $\theta \in \mathbb{R}^p$ to the scalar reward $\mu_t \in \mathbb{R}$, the effective parameter space reduces from the ambient dimension $p$ to the sample size $N$, bypassing the curse of dimensionality.
- **Mechanism:** The PointWise Estimator (PWE) transforms the linear model $y = X\theta + \epsilon$ into $y = \sqrt{N}\alpha_t z_t + \text{nuisance}$. Instead of solving for $p$ parameters with $N$ samples (an under-determined system), it solves for the scalar $\alpha_t$ and a sparse nuisance vector, effectively making the problem over-determined ($N$ samples vs. $1$ target).
- **Core assumption:** The context dimension $p$ is large ($p \gtrsim T$), but the sample size $N$ is sufficient to estimate a scalar projection.
- **Break condition:** If the projection vector $z_t$ is not well-defined or the noise $\epsilon$ dwarfs the signal $\alpha_t$, the scalar estimation fails.

### Mechanism 2: Adaptive Sparsification via Basis Construction
- **Claim:** If a transformation matrix $\Gamma^{(i)}_t$ is constructed using eigen vectors of the covariance and initial parameter estimates, the "nuisance" noise vector becomes sparse, allowing Lasso to denoise it effectively regardless of the underlying sparsity type.
- **Mechanism:** The algorithm constructs $\Gamma^{(i)}_t$ by combining spectral bases (from the covariance structure) and parameter bases (from the initial Lasso estimate). This aligns the nuisance vector $\xi^{(i)}_t$ with a sparse coordinate system, allowing the $\ell_1$ penalty in the final Lasso step to eliminate noise components efficiently.
- **Core assumption:** The nuisance vector is approximately sparse in the constructed basis; the initial estimators (Lasso or RDL) provide sufficient information to align this basis.
- **Break condition:** If the initial parameter estimate is poor and the covariance eigenvalues are not sparse, the constructed basis $\Gamma$ will fail to sparsify the nuisance vector, leading to high estimation error.

### Mechanism 3: Explore-Then-Commit (ETC) Stabilization
- **Claim:** If the exploration phase uses a round-robin schedule to gather $2N$ i.i.d. samples per arm, the theoretical guarantees for the initial estimators (Lasso/RDL) hold, stabilizing the subsequent exploitation phase.
- **Mechanism:** By fixing the exploration length $T_0$, the algorithm guarantees a specific sample size $N$ for the initial Lasso/RDL steps. This decoupling prevents the "partial feedback" loop of standard bandits from destabilizing the high-dimensional convergence bounds required for the initial support and parameter estimation.
- **Core assumption:** The exploration length $T_0$ is chosen correctly (dependent on unknowns like sparsity $s_0$ or time $T$) to satisfy convergence conditions.
- **Break condition:** If $T_0$ is too short (undersampling) or contexts are non-i.i.d. during exploration, the initial estimates $\hat{\theta}$ and supports $S_1$ become unreliable, propagating error to the PWE.

## Foundational Learning

- **Concept:** **High-Dimensional Sparsity (Model vs. Spectral)**
  - **Why needed here:** The paper's core novelty is handling *both* parameter sparsity (many zeros in $\theta$) and spectral sparsity (few significant eigenvalues in $\Sigma$). You must distinguish these to understand why Lasso alone (parameter) or RDL alone (spectral) fails in mixed settings.
  - **Quick check question:** Does the data have few relevant features (Model Sparsity) or is the variance concentrated in a few directions (Spectral Sparsity)?

- **Concept:** **Restricted Eigenvalue / Compatibility Conditions**
  - **Why needed here:** The theoretical guarantees (Prop 1, 3, 4) rely on Assumption 4 (Compatibility) for the Lasso steps. Understanding that the design matrix $X$ must not be "too correlated" in specific directions is crucial for diagnosing why the initial support estimation might fail.
  - **Quick check question:** Is the covariance matrix "well-behaved" enough to allow recovery of sparse parameters despite correlations?

- **Concept:** **Benign Overfitting / Double Descent (RDL context)**
  - **Why needed here:** The paper contrasts its approach with Ridgeless Least Squares (RDL), which relies on "benign overfitting" where the covariance eigenvalues decay quickly. Understanding this helps explain why RDL is the "initial estimator" choice for spectral-sparse settings.
  - **Quick check question:** Can an interpolating predictor (zero training error) generalize well in high dimensions? (Answer: Only under specific spectral decay).

## Architecture Onboarding

- **Component map:** Input Layer: High-dimensional contexts $x^{(i)}_t \in \mathbb{R}^p$ -> Exploration Phase (ETC): Round-robin arm pulls -> Datasets $D_i$ of size $2N$ -> Initialization Module: Split $D_i$, run Lasso/RDL on first half -> Pointwise Estimation Module (PWE): Input second half data, construct basis $\Gamma_t$, solve local Lasso -> Decision Layer: $\arg\max_i \hat{\mu}^{(i)}_t$

- **Critical path:** The **Initialization Module** is the bottleneck. If the support $S_1$ is incorrectly estimated (false negatives), the truncation in PWE discards predictive features. If $S_1$ is too large (false positives), the dimensionality remains high, and the "pointwise" advantage degrades.

- **Design tradeoffs:**
  *   **Homogeneous vs. Heterogeneous Tuning:** The paper notes $N$ (exploration length) depends on sparsity $s_0$. In "agnostic" mode (App. F), you sacrifice rate efficiency ($\tilde{O}(s_0^{1/2})$ vs $\tilde{O}(s_0^{1/3})$) for robustness.
  *   **Data Splitting:** Using half the data for support estimation ($S_1$) and half for the pointwise estimator ensures independence but reduces effective sample size for the final prediction.

- **Failure signatures:**
  *   **Regret flatlines at high values:** Likely the initial Lasso support recovery failed (check sparsity level $s_0$ vs $N$).
  *   **Regret scales with $p$:** The "sparsification" of the nuisance vector failed; check if covariance eigenvalues decay slowly (Assumption 1/C.2 violated).
  *   **Oscillating decisions:** The local Lasso in PWE is unstable; check regularization parameter $\lambda^{(i)}_t$ scaling.

- **First 3 experiments:**
  1.  **Scenario 1 (Sanity Check):** Replicate "Sparse Parameters only" (Fig 2a). Verify HOPE matches standard Lasso-ETC to ensure the PWE wrapper doesn't degrade performance in simple cases.
  2.  **Scenario 3 (Stress Test):** "Both Sparsities" (Fig 2c). Compare HOPE against Lasso-ETC and RDL-ETC simultaneously. This validates the core "adaptivity" claim where single-method baselines should fail.
  3.  **Ablation on Initialization:** Run HOPE using *only* Lasso initialization vs *only* RDL initialization on a Mixed Sparsity dataset (Scenario 4) to observe if the "adaptive" aspect comes from the PWE core or the initialization choice.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PointWise Estimation (PWE) be effectively extended to nonlinear reward models, such as kernel methods or neural networks?
- Basis in paper: [explicit] Appendix I states that the theoretical guarantees are currently restricted to linear settings, but real-world data often exhibits nonlinear patterns.
- Why unresolved: The current theoretical analysis and algorithm design rely on linear assumptions to transform the model and manage high-dimensional parameters.
- What evidence would resolve it: Development of a nonlinear variant of HOPE with corresponding regret bounds, or empirical validation showing performance gains in nonlinear environments.

### Open Question 2
- Question: Can integrating PWE with adaptive exploration strategies like UCB or Thompson Sampling yield tighter regret bounds than the current Explore-Then-Commit (ETC) approach?
- Basis in paper: [explicit] Appendix I notes that while ETC is effective, it "may not fully exploit the advantages of adaptive exploration."
- Why unresolved: The current HOPE implementation relies on a fixed exploration phase (ETC), which may be sample-inefficient compared to algorithms that update beliefs online.
- What evidence would resolve it: Derivation of confidence intervals specific to PWE that allow for adaptive arm selection, accompanied by theoretical regret analysis comparing ETC to UCB/TS variants.

### Open Question 3
- Question: Is the HOPE framework applicable to broader reinforcement learning problems, specifically high-dimensional Contextual Markov Decision Processes (MDPs)?
- Basis in paper: [explicit] Appendix I identifies extending the method to "contextual MDPs where partial feedback and high-dimensional state representations are common" as a critical next step.
- Why unresolved: The current work is limited to the contextual bandit setting (single-step decision making) and does not address the complexities of sequential decision-making with state transitions.
- What evidence would resolve it: Theoretical analysis demonstrating how PWE handles temporal dependencies and state evolution in an MDP setting.

## Limitations

- The theoretical guarantees rely on specific compatibility conditions and eigenvalue decay rates that may not hold in practice
- The exploration phase length $T_0 = 2NK$ depends on unknown sparsity parameters, creating practical tuning challenges
- PWE construction is computationally intensive, requiring careful matrix inversions and cross-validation for basis selection

## Confidence

**High Confidence:**
- Regret bounds for homogeneous settings (Theorem 1) are rigorously proven with explicit dependence on sparsity parameters
- Experimental superiority over single-sparsity baselines in heterogeneous settings (Fig 2c, 2d) is empirically demonstrated

**Medium Confidence:**
- Adaptive selection between Lasso and RDL initializers through cross-validation (mentioned but implementation details unspecified)
- Practical viability of PWE construction when sparsity levels are unknown or extreme

**Low Confidence:**
- Computational complexity of $\Gamma$ matrix construction for large $N$
- Robustness to non-i.i.d. contexts during exploration phase

## Next Checks

1. **Ablation on Initial Estimator Selection**: Run HOPE on mixed sparsity data (Scenario 4) using only Lasso initialization vs only RDL initialization across all arms, measuring performance degradation to quantify the benefit of adaptive selection.

2. **Sensitivity to Exploration Length**: Vary $T_0$ around the theoretical value $2NK$ in Scenario 3 (both sparsities) to empirically determine the relationship between $T_0$, support recovery accuracy, and regret performance.

3. **Numerical Stability Test**: Implement PWE on synthetic data with varying condition numbers of $\Sigma^{(i)}$ to identify the threshold where basis construction fails, comparing theoretical assumptions against practical breakdown points.