---
ver: rpa2
title: 'Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp
  Segmentation'
arxiv_id: '2507.01509'
source_url: https://arxiv.org/abs/2507.01509
tags:
- polyp
- segmentation
- boundary
- sam-magup
- mamba
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of robust polyp segmentation
  in colonoscopy images, where polyps exhibit significant shape, size, and color variations,
  often with weak or indistinct boundaries that resemble surrounding tissues. The
  proposed SAM-MaGuP approach integrates a boundary distillation module and a 1D-2D
  Mamba adapter into the Segment Anything Model (SAM) to enhance feature learning
  and improve boundary detection.
---

# Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation

## Quick Facts
- **arXiv ID**: 2507.01509
- **Source URL**: https://arxiv.org/abs/2507.01509
- **Reference count**: 32
- **Primary result**: Proposes SAM-MaGuP, integrating boundary distillation and 1D-2D Mamba adapters into SAM, achieving mDice of 94.7% on Kvasir-SEG, 95.3% on CVC-ClinicDB, and 85.4% on ETIS.

## Executive Summary
This paper addresses the challenge of robust polyp segmentation in colonoscopy images, where polyps exhibit significant shape, size, and color variations, often with weak or indistinct boundaries that resemble surrounding tissues. The proposed SAM-MaGuP approach integrates a boundary distillation module and a 1D-2D Mamba adapter into the Segment Anything Model (SAM) to enhance feature learning and improve boundary detection. The 1D-2D Mamba module captures long-range interactions across channel and spatial dimensions, while the boundary distillation component refines boundary localization using cross-attention mechanisms. Evaluated on five diverse datasets, SAM-MaGuP achieves state-of-the-art performance with mDice scores of 94.7% on Kvasir-SEG and 95.3% on CVC-ClinicDB, and an mDice of 85.4% on the challenging ETIS dataset, demonstrating superior accuracy and generalization for weak-boundary polyp segmentation.

## Method Summary
SAM-MaGuP integrates boundary distillation and 1D-2D Mamba adapters into SAM to address weak-boundary polyp segmentation. The model uses a two-stage training process: Stage I trains adapters with deep supervision while freezing SAM, and Stage II jointly trains adapters and the decoder with full supervision. The 1D-2D Mamba module employs parallel multi-scale convolutions (kernels 3, 5, 7) and gated Mamba layers to capture long-range interactions across channel and spatial dimensions. The Boundary Distillation Component (BDC) uses cross-attention with ground truth masks to refine boundary localization. Training uses a multi-scale augmentation strategy and a combined Dice and BCE loss function, with distillation loss in Stage I.

## Key Results
- Achieves mDice of 94.7% on Kvasir-SEG and 95.3% on CVC-ClinicDB, with 85.4% on ETIS
- Demonstrates superior performance on five diverse polyp segmentation datasets
- Shows state-of-the-art generalization for weak-boundary polyp segmentation

## Why This Works (Mechanism)
The approach works by enhancing SAM's feature learning capabilities through the integration of 1D-2D Mamba adapters that capture long-range interactions across both channel and spatial dimensions. The boundary distillation component uses cross-attention mechanisms to refine boundary localization by leveraging ground truth masks. This combination addresses the inherent challenge of distinguishing polyps from surrounding tissues when boundaries are weak or indistinct, by providing both improved feature representation and explicit boundary refinement during training.

## Foundational Learning
- **Weak-boundary polyp segmentation**: Why needed - medical imaging often has ambiguous boundaries between target and background tissues; Quick check - can the model maintain performance when polyp edges are not clearly defined
- **Cross-attention mechanisms**: Why needed - to focus on relevant boundary regions by comparing feature maps with ground truth; Quick check - does the model's attention weights correlate with actual boundary locations
- **Mamba state space models**: Why needed - to capture long-range dependencies efficiently in both spatial and channel dimensions; Quick check - does the model show improved context understanding compared to standard transformers
- **Boundary distillation**: Why needed - to explicitly train the model to focus on and accurately localize polyp boundaries; Quick check - does the model show improved boundary precision in evaluation metrics

## Architecture Onboarding

**Component map**: Input images -> SAM ViT-H/16 encoder -> 1D-2D Mamba adapters -> BDC (Boundary Distillation Component) -> SAM decoder -> Output segmentation

**Critical path**: Image input → SAM encoder → 1D-2D Mamba adapters → BDC cross-attention → SAM decoder → Segmentation output

**Design tradeoffs**: The model trades computational efficiency for accuracy by adding Mamba adapters and boundary distillation, resulting in 431 GFLOPs (vs 388 GFLOPs baseline) but significantly improved boundary localization. The two-stage training approach balances adaptation speed with final performance optimization.

**Failure signatures**: 
- Poor boundary localization indicates BDC cross-attention not properly focusing on boundary regions
- Generalization failure on ETIS suggests adapters overfitting to source domain features
- Low performance on weak-boundary cases indicates Mamba adapters not capturing sufficient context

**3 first experiments**:
1. Visualize BDC cross-attention weights to verify they attend to actual polyp boundaries
2. Compare Stage I vs Stage II outputs to confirm adapter adaptation effectiveness
3. Run ablation study removing MSD convolutions and Mamba layers separately to quantify their individual contributions

## Open Questions the Paper Calls Out
- **Real-time applicability**: Does SAM-MaGuP achieve the latency required for real-time clinical application despite the added Mamba and multi-scale convolution overhead?
- **Pseudo-mask generator impact**: How does the accuracy of the automatically generated pseudo-mask $f(\theta)$ impact the final segmentation stability?
- **Robustness to noisy annotations**: Can the Boundary Distillation Component (BDC) remain effective when trained on datasets with sparse or noisy boundary annotations?

## Limitations
- The model's computational overhead (431 GFLOPs) may impact real-time clinical deployment despite improved accuracy
- Heavy reliance on precise ground truth boundary annotations in BDC may limit robustness to annotation variability
- The two-stage training process adds complexity and may require careful hyperparameter tuning for optimal performance

## Confidence
- **High confidence**: Performance metrics on standard benchmarks, ablation study results, and overall framework design
- **Medium confidence**: Architectural integration details (adapter placement, channel dimensions), training loss composition, and the exact SAM checkpoint used
- **Low confidence**: Specific implementation of the pseudo-mask generator f(θ) and the precise Mamba SSM parameterization

## Next Checks
1. Reproduce the two-stage training pipeline with the specified dataset splits and verify convergence behavior on both stages
2. Ablate the boundary distillation component and 1D-2D Mamba module separately to confirm their individual impact on boundary localization accuracy
3. Evaluate model performance on an unseen external dataset (e.g., CVC-612) to independently verify generalization claims beyond the reported test sets