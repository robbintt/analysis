---
ver: rpa2
title: Handling imbalance and few-sample size in ML based Onion disease classification
arxiv_id: '2509.05341'
source_url: https://arxiv.org/abs/2509.05341
tags:
- dataset
- class
- classification
- loss
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of multi-class classification
  of onion crop diseases and pests in the presence of class imbalance and limited
  training samples. The proposed solution enhances a pre-trained DenseNet-121 CNN
  model by integrating a Convolutional Block Attention Module (CBAM) and employing
  a comprehensive data augmentation pipeline, including Cut-Mix and Albumentations.
---

# Handling imbalance and few-sample size in ML based Onion disease classification

## Quick Facts
- arXiv ID: 2509.05341
- Source URL: https://arxiv.org/abs/2509.05341
- Authors: Abhijeet Manoj Pal; Rajbabu Velmurugan
- Reference count: 21
- Primary result: DenseNet-121 with CBAM, WCE loss, and Cut-Mix achieves 96.90% accuracy and 0.96 F1 score on 8-class onion disease classification

## Executive Summary
This paper tackles multi-class classification of onion crop diseases and pests under severe class imbalance and limited training samples. The authors enhance a pre-trained DenseNet-121 CNN by integrating a Convolutional Block Attention Module (CBAM) and employing Cut-Mix augmentation alongside weighted cross-entropy loss. Evaluated on a real-world dataset of 5,330 images across 8 classes, the approach achieves 96.90% overall accuracy and 0.96 F1 score, outperforming previous methods. Ablation studies confirm that the combination of CBAM, weighted cross-entropy, and Cut-Mix yields the best results, with all classes achieving accuracies above 80%.

## Method Summary
The method combines a pre-trained DenseNet-121 backbone with CBAM attention modules, weighted cross-entropy loss, and Cut-Mix augmentation. Images are resized to 224×224 and trained using five-fold cross-validation. Class weights are computed as the ratio of the majority class count to each minority class count. The MLP head architecture and training hyperparameters are unspecified but assumed to include standard configurations. The model is evaluated on a dataset with 64/16/20 train/val/test splits, merging Anthracnose and Twister classes based on domain knowledge.

## Key Results
- DenseNet-121 + CBAM + WCE + Cut-Mix achieves 96.90% accuracy and 0.96 F1 score
- All 8 classes achieve accuracies above 80%, with minority classes like Basal Rot at 87% and Purple Blotch at 91%
- Cut-Mix augmentation alone improves accuracy from 94.10% to 96.00% compared to normal augmentation
- Weighted cross-entropy outperforms imbalanced sampling (90.99% vs 82.44% accuracy)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention modules improve feature discrimination for multi-class disease classification.
- Mechanism: CBAM applies Channel Attention (CAM) to weight important feature channels and Spatial Attention (SAM) to highlight discriminative spatial regions, enhancing the model's focus on disease-relevant patterns rather than background.
- Core assumption: Disease-specific visual features occupy distinct spatial and channel subspaces learnable through attention weights.
- Evidence anchors:
  - [abstract]: "We enhance a pre-trained Convolutional Neural Network (CNN) model by integrating attention based modules"
  - [section]: Table II shows DenseNet-121 + CBAM + WCE + Normal Aug achieves 95.12% vs 94.10% without CBAM
  - [corpus]: Weak direct support; related plant disease papers do not specifically validate CBAM contributions
- Break condition: If diseases share highly similar spatial patterns (e.g., different leaf spots), attention may not provide sufficient discrimination.

### Mechanism 2
- Claim: Weighted Cross-Entropy (WCE) loss outperforms sampling-based balancing for imbalanced multi-class datasets.
- Mechanism: WCE assigns class-specific weights inversely proportional to class frequency (w_yi = max_count / count_yi), increasing penalty for minority class errors without discarding majority samples.
- Core assumption: Class frequency is a reasonable proxy for classification difficulty; minority classes need proportionally higher gradient signals.
- Evidence anchors:
  - [abstract]: "weighted cross-entropy loss is used instead of balancing the dataset"
  - [section]: Table I shows WCE achieves 90.99% vs 82.44% with Imbalanced Sampler on DenseNet-121 (9-class task)
  - [corpus]: Moderate support; multiple neighbor papers cite class imbalance as a key challenge, though WCE vs. sampling comparison is domain-specific
- Break condition: If minority class features are intrinsically harder (not just rarer), re-weighting alone may be insufficient; may need better representations.

### Mechanism 3
- Claim: Cut-Mix augmentation improves generalization under class imbalance and limited samples.
- Mechanism: Cut-Mix creates synthetic training samples by spatially combining two images (x̃ = M⊙x_A + (1−M)⊙x_B) and mixing labels proportionally (ỹ = λy_A + (1−λ)y_B), encouraging the model to learn from partial features and regularize decision boundaries.
- Core assumption: Disease signatures remain recognizable in partial image regions; mixing does not destroy semantic coherence.
- Evidence anchors:
  - [abstract]: "Ablation studies show that combining CBAM, weighted cross-entropy loss, and Cut-Mix augmentation yields the best results"
  - [section]: Table II shows Cut-Mix alone (Pipeline D) achieves 96.00% vs 94.10% with normal augmentation; combined with CBAM + WCE reaches 96.90%
  - [corpus]: Weak domain-specific support; Cut-Mix is cited from general vision literature (Yun et al., 2019), not plant disease papers
- Break condition: If mixed regions create unrealistic disease patterns (e.g., two diseases overlapping unnaturally), model may learn spurious features.

## Foundational Learning

- Concept: **Class Imbalance in Multi-class Classification**
  - Why needed here: Dataset has 7.6:1 imbalance ratio (1072 Healthy vs. 140 Basal Rot images); standard training biases toward majority classes, making accuracy misleading.
  - Quick check question: Given 87% accuracy on Basal Rot (minority) vs. 100% on Healthy (majority), which metric better reflects model quality—overall accuracy or per-class F1?

- Concept: **Transfer Learning with CNN Backbones**
  - Why needed here: Limited agricultural data (5,330 images) benefits from DenseNet-121 pre-trained on ImageNet; fine-tuning adapts general visual features to disease patterns.
  - Quick check question: Should you freeze early convolutional layers or fine-tune the entire network when adapting to a small, domain-specific dataset?

- Concept: **Attention Mechanisms (Channel vs. Spatial)**
  - Why needed here: CBAM helps distinguish visually similar diseases (e.g., Anthracnose/Twister) by learning what to emphasize—color/texture channels or lesion locations.
  - Quick check question: If two diseases differ mainly in lesion shape (not color), which attention submodule (CAM or SAM) would contribute more to discrimination?

## Architecture Onboarding

- Component map:
  Image → DenseNet-121 feature extraction → CBAM attention refinement → MLP → Logits → WCE Loss

- Critical path:
  Image → DenseNet-121 feature extraction → CBAM attention refinement → MLP → Logits → WCE Loss

- Design tradeoffs:
  - DenseNet-121 vs. ResNet-50: DenseNet chosen for fewer parameters (8M vs. 25.6M), better for IoT deployment; ResNet-50 underperforms (87.15% vs. 90.99% accuracy on same task).
  - Cut-Mix vs. Albumentations: Cut-Mix alone outperforms Albumentations (96.00% vs. 91.93%); combining both degrades performance (93.06%), suggesting augmentation diversity can conflict.
  - WCE vs. Focal Loss: WCE achieves 96.90% vs. Focal Loss at 94.56% with same architecture—simpler weighting scheme works better here.
  - Assumption: Training time and compute cost are acceptable; Cut-Mix adds forward/backward passes for image pairs.

- Failure signatures:
  - Low per-class accuracy on Basal Rot (87%) and Purple Blotch (91%) despite overall 96.90%—indicates remaining minority class difficulty.
  - Confusion between Anthracnose and Twister led to class merger (they are the same disease per domain knowledge)—watch for domain-guided label consolidation.
  - Over-augmentation with Albumentations + Cut-Mix drops accuracy to 93.06%—excessive transformation diversity may distort disease features.

- First 3 experiments:
  1. Replicate baseline: Train DenseNet-121 with normal augmentation + WCE loss on 8-class merged dataset; target ~94% accuracy to validate setup.
  2. Ablation CBAM: Add CBAM to baseline without changing augmentation; expect ~1% gain (94.10% → 95.12%) to isolate attention contribution.
  3. Full pipeline: Replace normal augmentation with Cut-Mix + CBAM + WCE; target 96.90% accuracy and verify all per-class accuracies exceed 80%.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the inference latency and energy consumption profiles of the proposed DenseNet-121+CBAM model when deployed on resource-constrained edge devices?
- Basis in paper: [explicit] The introduction states the aim was to build a model for "Internet of Things (IoT) devices" to balance performance with resource constraints.
- Why unresolved: The results section reports only classification accuracy (96.90%) and F1 scores, omitting the computational metrics required to validate feasibility for real-time edge deployment.
- What evidence would resolve it: Benchmarks of frames-per-second (FPS), memory footprint, and power consumption on standard edge hardware (e.g., Raspberry Pi, Jetson Nano).

### Open Question 2
- Question: Does the model maintain high performance when classifying onion diseases in geographical regions outside the specific collection site (Pune, India)?
- Basis in paper: [inferred] The dataset is entirely sourced from the ICAR-Directorate in Pune, and images were taken via specific cameras (DSLR/smartphone) under local conditions.
- Why unresolved: Training on a single-location dataset risks overfitting to local soil colors, lighting conditions, and specific pest strains, limiting global applicability.
- What evidence would resolve it: Evaluation of the pre-trained model on external datasets from different agricultural zones or countries.

### Open Question 3
- Question: Can the classification approach be extended to quantify disease severity rather than solely identifying the presence of a specific disease class?
- Basis in paper: [inferred] The paper addresses the need for "targeted treatments," which often depend on the extent of infection, but the methodology treats all infected samples as single positive classes.
- Why unresolved: The current dataset annotation and loss function (Weighted Cross-Entropy) are designed for categorical classification, not ordinal regression of infection levels.
- What evidence would resolve it: Experimentation using datasets annotated with gradation scales (e.g., percentage of leaf affected) to test correlation with model confidence or regression outputs.

## Limitations

- The paper does not isolate individual contributions of CBAM, WCE, and Cut-Mix components, making it unclear which component drives performance gains.
- Weighted cross-entropy assumes minority class difficulty scales with frequency, which may not hold if intrinsic feature separability is low.
- CBAM placement and hyperparameters are unspecified, raising reproducibility concerns.
- Domain knowledge drives the Anthracnose/Twister merge, but the impact of this consolidation on overall classification difficulty is not quantified.

## Confidence

- **High**: DenseNet-121 + WCE loss achieves robust overall accuracy and F1; ablation results are internally consistent.
- **Medium**: CBAM + Cut-Mix combination contributes positively; the domain-merged label set is valid.
- **Low**: Individual contribution of each component is not experimentally isolated; augmentation strategy lacks full specification.

## Next Checks

1. Perform per-component ablation: isolate CBAM, WCE, and Cut-Mix effects to quantify individual contributions.
2. Test minority class recall on held-out data: confirm Basal Rot and Purple Blotch maintain >80% accuracy under domain shift.
3. Conduct sensitivity analysis: vary Cut-Mix mask ratio and class weight scaling to find stable performance bounds.