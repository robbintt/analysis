---
ver: rpa2
title: 'Rethinking Label Consistency of In-Context Learning: An Implicit Transductive
  Label Propagation Perspective'
arxiv_id: '2512.12175'
source_url: https://arxiv.org/abs/2512.12175
tags:
- label
- demonstrations
- arxiv
- learning
- topk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper rethinks in-context learning (ICL) as a transductive
  learning process and establishes a label propagation framework from a Bayesian perspective.
  It argues that ICL demonstrations guide latent concepts related to the query, with
  consistent labels serving as estimates.
---

# Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective

## Quick Facts
- arXiv ID: 2512.12175
- Source URL: https://arxiv.org/abs/2512.12175
- Reference count: 7
- Achieves 1.4% average accuracy improvement over standard TopK sampling on nine classification and NLI benchmarks

## Executive Summary
This paper reinterprets in-context learning (ICL) as an implicit transductive learning process where demonstrations guide the propagation of labels to query inputs through latent concept formation. The authors establish a Bayesian framework for understanding how label consistency in demonstrations influences ICL performance, arguing that consistent labels serve as estimates of underlying semantic relationships. Based on this insight, they propose TopK-SD, a data synthesis method that interpolates sentence and label embeddings to generate synthetic demonstrations with improved label consistency, achieving consistent performance gains across multiple models and benchmarks.

## Method Summary
The authors develop TopK-SD by first analyzing ICL through a transductive learning lens, establishing that label consistency in demonstrations serves as a proxy for latent concept alignment. They construct a Bayesian framework showing how consistent labels guide the model's understanding of semantic relationships between inputs. TopK-SD then synthesizes new demonstrations by interpolating both sentence and label embeddings of the top-k most similar examples to the query, creating synthetic data points that maintain semantic coherence while enhancing label consistency. This method is evaluated against standard TopK sampling across nine classification and natural language inference benchmarks using LLaMA3, GPT-J, LLaMA2, and DeepSeek models.

## Key Results
- TopK-SD achieves 1.4% average accuracy improvement over standard TopK sampling across nine benchmarks
- Performance gains are consistent across multiple model architectures (LLaMA3, GPT-J, LLaMA2, DeepSeek)
- Ablation studies show 0.4-0.9% improvement when replacing TopK with TopK-SD in MDL, ConE, and DPP methods

## Why This Works (Mechanism)
The method works by recognizing that ICL demonstrations implicitly guide the model toward understanding latent semantic concepts through label consistency. When demonstrations share consistent labels for semantically similar inputs, the model can better propagate this understanding to the query input. By synthesizing demonstrations that explicitly optimize for label consistency through embedding interpolation, TopK-SD strengthens this latent concept formation process, leading to more reliable predictions.

## Foundational Learning
- Transductive learning: Understanding how to apply information from specific training examples to specific test examples; needed to frame ICL as label propagation rather than inductive generalization; quick check: verify whether test examples are used during training or adaptation phase
- Bayesian inference: Provides the mathematical framework for understanding how label consistency serves as evidence for latent concept formation; needed to formalize the relationship between demonstrations and query predictions; quick check: confirm posterior probability calculations align with observed performance gains
- Embedding interpolation: The technique of creating synthetic data points by combining existing embeddings; needed to generate demonstrations with optimized label consistency; quick check: verify interpolated embeddings maintain semantic coherence and don't produce nonsensical combinations

## Architecture Onboarding
**Component Map:** Query Input -> Embedding Extraction -> TopK Similarity Search -> Label Consistency Evaluation -> Embedding Interpolation (TopK-SD) -> Synthetic Demonstration Generation -> ICL Prediction

**Critical Path:** The core pipeline processes input through embedding extraction, identifies top-k similar demonstrations, evaluates label consistency, applies interpolation to generate synthetic demonstrations, and produces predictions through ICL

**Design Tradeoffs:** The method trades computational overhead from interpolation against improved prediction accuracy; maintains demonstration count while enhancing quality rather than increasing quantity

**Failure Signatures:** Poor performance when embedding space poorly captures task-relevant semantics; degradation when label consistency cannot be reliably estimated; computational bottlenecks with very large context windows

**First Experiments:** 1) Compare TopK vs TopK-SD on a single benchmark with one model to establish baseline improvement; 2) Analyze embedding space quality by visualizing interpolated demonstrations; 3) Measure computational overhead of interpolation relative to standard ICL

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Performance gains are modest (1.4% average improvement), suggesting incremental rather than transformative impact
- Effectiveness limited to classification and NLI tasks, with uncertain generalizability to other NLP domains
- Computational overhead of interpolation not fully characterized, particularly for larger datasets

## Confidence
*High Confidence:* The mathematical framework for ICL as transductive label propagation is well-grounded; experimental methodology comparing TopK vs TopK-SD across multiple benchmarks is rigorous and reproducible.

*Medium Confidence:* The interpretation of label consistency as guiding latent concept formation is plausible but relies on assumptions about model processing that may not hold across all architectures.

*Low Confidence:* Generalizability to domains beyond classification and NLI, and to models substantially different from those evaluated, remains uncertain.

## Next Checks
1. Evaluate TopK-SD on broader NLP tasks including question answering, summarization, and generation to assess generalizability beyond classification and NLI.

2. Test with substantially larger context windows (beyond million-token regime) to determine if performance gains scale or diminish with increased context length.

3. Conduct ablation studies isolating the contribution of interpolation versus label consistency components to identify which drives performance improvements.