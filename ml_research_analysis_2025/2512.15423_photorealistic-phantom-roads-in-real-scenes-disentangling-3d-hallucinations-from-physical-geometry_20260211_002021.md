---
ver: rpa2
title: 'Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations
  from Physical Geometry'
arxiv_id: '2512.15423'
source_url: https://arxiv.org/abs/2512.15423
tags:
- depth
- full
- hallucination
- conference
- illusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the 3D Mirage problem, where monocular depth
  models hallucinate non-planar 3D structures from geometrically planar but perceptually
  ambiguous inputs like 3D street art. To address this, the authors propose the first
  end-to-end framework: 1) the 3D-Mirage benchmark of real-world illusions with planar-region
  annotations and context-restricted crops, 2) a Laplacian-based evaluation framework
  with Deviation Composite Score (DCS) for hallucination intensity and Confusion Composite
  Score (CCS) for contextual instability, and 3) Grounded Self-Distillation, a parameter-efficient
  LoRA-based method that enforces planarity on illusion ROIs while preserving background
  knowledge through self-distillation.'
---

# Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations from Physical Geometry

## Quick Facts
- arXiv ID: 2512.15423
- Source URL: https://arxiv.org/abs/2512.15423
- Reference count: 40
- Key outcome: Introduces 3D Mirage problem and first end-to-end framework (3D-Mirage benchmark, Laplacian-based metrics DCS/CCS, Grounded Self-Distillation) that reduces DCS by 93.5% and CCS by 86.1% while preserving general depth estimation accuracy.

## Executive Summary
This paper identifies and addresses the "3D Mirage" problem where monocular depth models hallucinate non-planar 3D structures from geometrically planar but perceptually ambiguous inputs like 3D street art. The authors propose the first end-to-end framework to quantify and mitigate these hallucinations. Their approach combines a new benchmark of real-world illusions with planar-region annotations, novel Laplacian-based evaluation metrics (DCS for hallucination intensity, CCS for contextual instability), and a parameter-efficient LoRA-based self-distillation method that enforces planarity on illusion ROIs while preserving background knowledge.

## Method Summary
The framework uses a frozen teacher model (DAv2-L) and a student model with LoRA adapters. The student is trained with dual losses: $L_{HKR}$ forces the Laplacian response within the illusion ROI toward zero (enforcing planarity), while $L_{NKP}$ aligns the student's prediction for stable background regions with the teacher's prediction (preserving general knowledge). Training uses z-normalization over background pixels, dual-view sampling with crops, and a 1-epoch schedule to prevent catastrophic forgetting. The method is validated on the 3D-Mirage benchmark and shows superior performance on both hallucination metrics and general depth estimation tasks.

## Key Results
- Reduces DCS (hallucination intensity) by 93.5% compared to baseline DAv2-L
- Reduces CCS (contextual instability) by 86.1% while preserving general depth estimation accuracy
- Achieves best scores by an order of magnitude compared to existing SOTA depth models
- Maintains NYU-v2 accuracy and R² correlation while effectively suppressing mirages

## Why This Works (Mechanism)

### Mechanism 1: Laplacian-based hallucination detection
Standard metrics like MAE/RMSE average errors across entire images, diluting localized hallucination errors. The Laplacian operator $L(\cdot)$ responds strongly to rapid depth changes (curvature). Applied to depth maps within planar ROIs, high Laplacian responses indicate non-planarity. DCS measures hallucination intensity while CCS captures contextual instability between full and cropped views. This works because any depth variation in a truly planar region is a hallucination.

### Mechanism 2: Grounded Self-Distillation correction
The method uses a frozen teacher model and student with LoRA adapters. $L_{HKR}$ forces Laplacian responses to zero within illusion ROIs (enforcing planarity), while $L_{NKP}$ preserves background knowledge through self-distillation. This allows targeted hallucination correction without catastrophic forgetting of general depth estimation capabilities.

### Mechanism 3: Semantic prior over-reliance
Foundation models trained on vast datasets develop strong correlations between 2D patterns and 3D structure. When encountering perceptually ambiguous inputs with restricted context (like cropped 3D street art), learned semantic priors override weak local geometric evidence, causing hallucination of expected 3D shapes.

## Foundational Learning

### Concept: Laplacian Operator (2nd Derivative)
- Why needed: Core mathematical tool to detect non-planarity (hallucinations)
- Quick check: What does a high Laplacian response in a depth map indicate? (Answer: High curvature or sharp edge, suggesting non-planar surface)

### Concept: Self-Distillation
- Why needed: Teacher-student paradigm for preserving background knowledge while correcting hallucinations
- Quick check: What is the role of the frozen teacher model? (Answer: Provides stable reference for background regions while student corrects hallucinations)

### Concept: Low-Rank Adaptation (LoRA)
- Why needed: Parameter-efficient adaptation without full fine-tuning
- Quick check: Why is LoRA suitable compared to full fine-tuning? (Answer: Enables targeted adaptation with few parameters, reducing catastrophic forgetting risk)

## Architecture Onboarding

### Component map:
Input RGB image -> LoRA-adapted ViT encoder (DINOv2) -> Depth prediction head -> Dual loss computation ($L_{HKR}$, $L_{NKP}$) -> Parameter update (LoRA only)

### Critical path:
Input flows through LoRA-adapted encoder to depth prediction. $L_{HKR}$ acts on Laplacian of prediction within illusion ROI, providing gradient signal to "flatten" region. $L_{NKP}$ provides counterbalancing signal from background.

### Design tradeoffs:
Primary tradeoff between hallucination suppression and knowledge preservation. Strong $L_{HKR}$ removes mirages but risks over-flattening real objects if $L_{NKP}$ is weak. Strong $L_{NKP}$ preserves background but may not fully correct illusions. Optimal balance found using 1-epoch training.

### Failure signatures:
- Untamed model: High DCS/CCS, spurious 3D bumps/holes on planar surfaces
- Over-flattened model: Low DCS but background distortion, NYU-v2 accuracy drops
- Under-constrained model: High DCS/CCS, behaves like baseline

### First 3 experiments:
1. Metric validation: Run SOTA models on 3D-Mirage benchmark, compute DCS/CCS to establish baseline vulnerability
2. Ablation study: Train variants without $L_{HKR}$, without $L_{NKP}$, and full model; compare DCS, CCS, and NYU-v2 performance
3. Qualitative visualization: Generate depth maps using baseline vs. method; visualize error heatmap to confirm ROI-confined corrections

## Open Questions the Paper Calls Out

### Open Question 1
Can Grounded Self-Distillation work on generative/diffusion-based architectures like Marigold or DepthFM? The method was demonstrated on transformer-based MDE architecture; effectiveness on other architectures remains unexplored.

### Open Question 2
Can planarity-enforcing logic generalize to other perceptual ambiguities (texture-less surfaces, reflections, adverse weather)? Current benchmark focuses on planar surfaces, not encompassing full spectrum of perceptual ambiguity.

### Open Question 3
How to improve robustness for protrusion illusions and photorealistic long-distance scenes where method fails? Current training lacks protrusion-style illusions, and method struggles with depth scaling of distant, realistic textures.

## Limitations

- Evaluation depends on accurate ROI annotations; imperfect annotations could misrepresent hallucination severity
- One-epoch training prevents catastrophic forgetting but may limit adaptability to other hallucination types
- Current focus on 3D street art illusions; generalizability to other hallucination categories needs validation

## Confidence

- **High confidence**: Laplacian filter mechanism for detecting non-planarity is mathematically sound
- **Medium confidence**: DCS/CCS reduction corresponds to "tamed" hallucinations, but needs broader dataset validation
- **Medium confidence**: Grounded Self-Distillation approach effective, but exact contribution of each loss component difficult to isolate

## Next Checks

1. Apply trained model to KITTI or ScanNet benchmarks to verify background preservation and no over-flattening on real 3D structures
2. Systematically vary ROI boundaries by ±5-10 pixels and re-compute DCS/CCS to measure annotation sensitivity
3. Test method on different illusion categories (color-based depth illusions, texture-induced errors) to assess generalizability beyond 3D street art