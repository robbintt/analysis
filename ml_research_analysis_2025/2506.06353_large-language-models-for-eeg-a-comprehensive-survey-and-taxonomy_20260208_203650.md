---
ver: rpa2
title: 'Large Language Models for EEG: A Comprehensive Survey and Taxonomy'
arxiv_id: '2506.06353'
source_url: https://arxiv.org/abs/2506.06353
tags:
- language
- learning
- arxiv
- large
- signals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive overview of how large language
  models (LLMs) are being applied to electroencephalography (EEG) signal analysis.
  It organizes recent studies into four key domains: LLM-inspired foundation models
  for EEG representation learning, EEG-to-language decoding, cross-modal generation,
  and clinical applications including emotion recognition and dataset management.'
---

# Large Language Models for EEG: A Comprehensive Survey and Taxonomy

## Quick Facts
- arXiv ID: 2506.06353
- Source URL: https://arxiv.org/abs/2506.06353
- Reference count: 40
- This survey organizes recent studies on integrating large language models with EEG signal analysis across four domains: foundation models, EEG-to-language decoding, cross-modal generation, and clinical applications.

## Executive Summary
This survey provides a comprehensive overview of how large language models (LLMs) are being applied to electroencephalography (EEG) signal analysis. It organizes recent studies into four key domains: LLM-inspired foundation models for EEG representation learning, EEG-to-language decoding, cross-modal generation, and clinical applications including emotion recognition and dataset management. The survey highlights the use of transformer-based architectures adapted through fine-tuning, few-shot, and zero-shot learning to enable complex tasks such as natural language generation from brain activity, multimodal synthesis, and diagnostic assistance. By offering a structured framework and taxonomy, this work serves as a foundational resource for advancing the integration of neural signal analysis with language models.

## Method Summary
The survey synthesizes existing literature on LLM-EEG integration through systematic literature review, identifying four key domains: foundation models for representation learning, EEG-to-language decoding, cross-modal generation, and clinical applications. It analyzes architectural approaches including transformer-based encoders, alignment strategies (adapters, contrastive learning), and adaptation methods (fine-tuning, few-shot, zero-shot). The methodology focuses on conceptual synthesis rather than empirical validation, organizing findings into a taxonomy that maps technical approaches to specific application domains.

## Key Results
- Transformer-based architectures with self-attention mechanisms effectively capture long-range spatiotemporal dependencies in EEG signals
- Foundation models pretrained with masked or autoregressive objectives produce transferable EEG representations across tasks and subjects
- Contrastive alignment between EEG and language embeddings enables cross-modal generation and zero-shot classification capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Self-attention mechanisms in transformers capture long-range spatiotemporal dependencies in EEG signals more effectively than recurrent architectures.
- Mechanism: The self-attention mechanism assigns dynamic importance weights to different positions in a sequence, enabling both local and global dependency modeling across multichannel EEG time series without the sequential bottlenecks of RNNs.
- Core assumption: EEG signals contain meaningful long-range dependencies that correlate with cognitive states and can be learned through attention patterns.
- Evidence anchors:
  - [abstract] "The survey highlights how transformer-based architectures... have enabled EEG-based models to perform complex tasks such as natural language generation, semantic interpretation, and diagnostic assistance."
  - [section 1.1] "The self-attention mechanism in language models enables dynamic weighting of input features and effectively captures long-range dependencies, which are essential for modeling the spatiotemporal dynamics of signals."
  - [corpus] Weak direct evidence; related paper "Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding" mentions transformer integration for EEG but without FMR score validation.
- Break condition: If attention maps show no interpretable patterns correlating with known neural markers (e.g., P300, ERPs), or if performance degrades on short-window tasks where local features dominate.

### Mechanism 2
- Claim: Large-scale pretraining with masked or autoregressive objectives produces transferable EEG representations that generalize across tasks and subjects.
- Mechanism: Foundation models like LaBraM and EEGPT learn general-purpose embeddings by predicting masked signal segments or next tokens across diverse EEG datasets, creating representations that transfer to downstream tasks with minimal fine-tuning.
- Core assumption: EEG signals share underlying structure across recording sessions, subjects, and paradigms that can be captured through self-supervised learning on large corpora.
- Evidence anchors:
  - [abstract] "LLM-inspired foundation models for EEG representation learning" identified as a key domain.
  - [section 5.1.1] "EEGFormer applies masked token prediction over spatiotemporal patches using a transformer architecture, while LaBraM segments signals into channel-wise patches and employs a vector-quantized tokenizer to enable generalization across datasets."
  - [corpus] "Foundation Models for Cross-Domain EEG Analysis Application: A Survey" (FMR=0.50) directly addresses cross-domain generalization through foundation models.
- Break condition: If pretrained representations fail to transfer to new subjects without substantial fine-tuning, or if inter-subject variability dominates learned features.

### Mechanism 3
- Claim: Contrastive alignment between EEG embeddings and language/image embeddings enables cross-modal generation and zero-shot classification.
- Mechanism: Models like EEG-CLIP and BELT-2 project EEG signals and text into a shared embedding space via contrastive learning, allowing pretrained LLMs to condition on neural representations without task-specific training data.
- Core assumption: Semantic content in EEG (e.g., perceived images, intended speech) has consistent neural signatures that can be mapped to linguistic or visual embedding spaces.
- Evidence anchors:
  - [section 5.2.3] "DeWave employs a quantized variational encoder to generate discrete codes, which are aligned with language representations through contrastive training. SEE introduces a semantic matching module that maps signal features into a shared latent space with text."
  - [section 4.2] "EEG-CLIP aligns time-series data with clinical text reports through contrastive learning, enabling both zero-shot classification and retrieval via a shared embedding space."
  - [corpus] "A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond" addresses this cross-modal bridge explicitly but lacks citation validation.
- Break condition: If aligned embeddings produce semantically incoherent outputs (e.g., generated text unrelated to stimulus), or if alignment requires dataset-specific retraining.

## Foundational Learning

- Concept: **EEG signal characteristics and preprocessing**
  - Why needed here: EEG signals are noisy, multichannel time series (128-1024 Hz) with artifacts from eye movements, muscle activity, and environmental interference. Understanding frequency bands (delta, theta, alpha, beta, gamma) and preprocessing pipelines is essential before any LLM integration.
  - Quick check question: Can you explain why alpha waves (8-13 Hz) might confound a classifier trained on beta-band features during an attention task?

- Concept: **Transformer architecture fundamentals (self-attention, positional encoding, layer normalization)**
  - Why needed here: All surveyed approaches build on transformer backbones. Understanding how self-attention computes pairwise relationships, why positional encodings are needed for time series, and how masked vs. autoregressive pretraining differ is prerequisite knowledge.
  - Quick check question: Given an EEG segment of shape (channels=64, time=256), how would you patch it for transformer input, and what positional information would you encode?

- Concept: **Contrastive learning and embedding space alignment**
  - Why needed here: Cross-modal EEG-to-text/image approaches rely on contrastive objectives (e.g., CLIP-style) to align neural and semantic representations. Understanding InfoNCE loss, temperature scaling, and negative sampling strategies is critical.
  - Quick check question: If your EEG-text contrastive model achieves high training accuracy but generates irrelevant text at inference, what might be failing in the alignment?

## Architecture Onboarding

- Component map:
  Raw EEG → Preprocessing (artifact removal, filtering) → Patch/Token Embedding → EEG Encoder (Transformer, e.g., EEGPT/LaBraM) → [EEG Embeddings] → Task Head (classification: emotion, pathology) / Adapter Module (AdaCT: EEG → pseudo-text/image) / Cross-Modal Decoder (BART/GPT for text, Diffusion for images)

- Critical path:
  1. Select appropriate EEG foundation model based on task (masked modeling for representation learning, autoregressive for sequence generation)
  2. Align EEG embeddings to LLM input space through adapter modules or contrastive pretraining
  3. Choose adaptation strategy: fine-tuning (moderate data), few-shot (limited examples), zero-shot (no task-specific data)

- Design tradeoffs:
  - **Masked vs. Autoregressive pretraining**: Masked (BERT-style) better for classification; autoregressive (GPT-style) better for sequential generation. Some models (EEGPT) offer both variants
  - **Fine-tuning depth vs. efficiency**: Full fine-tuning requires more data/compute; prefix tuning and adapters (AdaCT) enable parameter-efficient transfer but may underfit on complex tasks
  - **Real-time vs. accuracy**: Larger models (GPT-4o) achieve higher performance but cannot meet BCI latency requirements; lightweight models (Qwen2-0.5B) enable real-time inference with reduced accuracy

- Failure signatures:
  - High training loss, low validation accuracy: Inter-subject variability not addressed; consider subject-specific adapters or data augmentation
  - Generated text semantically unrelated to EEG input: Embedding alignment failed; verify contrastive training convergence and check for modality collapse
  - Model performs well on seen subjects, fails on new subjects: Foundation model not sufficiently pretrained on diverse data; expand pretraining corpus or use domain adaptation
  - Zero-shot classification near random: EEG-text embedding space not properly aligned; inspect retrieval quality and temperature parameters

- First 3 experiments:
  1. **Baseline replication**: Reproduce BELT-2 or DeWave on ZuCo dataset for EEG-to-text, measuring BLEU and METEOR scores. This validates your preprocessing pipeline and confirms you can replicate published results
  2. **Ablation on adapter design**: Compare AdaCT-T (pseudo-text) vs. AdaCT-I (pseudo-image) adapters on a classification task (e.g., TUAB abnormality detection) with 10% labeled data. This identifies which modality bridge works better for your target task
  3. **Zero-shot generalization test**: Train EEG-CLIP style contrastive model on one dataset (e.g., TUAB), then evaluate zero-shot classification on an unseen dataset (e.g., NMT) without retraining. This reveals whether learned embeddings generalize across recording protocols

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can model compression techniques (e.g., quantization, knowledge distillation) be optimized to allow LLMs to perform real-time, low-latency EEG inference for neurofeedback applications?
- Basis in paper: [Explicit] Section 6 states that "Achieving real-time performance is essential" and explicitly calls for exploring "model compression techniques—quantization, knowledge distillation, and dynamic attention."
- Why unresolved: EEG signals require high-frequency sampling, and LLMs are computationally expensive, creating a latency barrier that currently prevents effective deployment in live BCI or neurofeedback loops.
- What evidence would resolve it: Demonstration of a compressed EEG-LLM operating on edge devices with sub-second latency while maintaining diagnostic accuracy.

### Open Question 2
- Question: Which adaptation strategies (continual learning, meta-learning, or federated fine-tuning) are most effective for personalizing LLMs to handle high inter-subject EEG variability?
- Basis in paper: [Explicit] Section 6 highlights that "personalization is essential" due to variability and suggests that "continual learning, meta-learning, and federated fine-tuning" are necessary to "improve both accuracy and user trust."
- Why unresolved: Current foundation models struggle to generalize across different individuals and sessions; the specific mechanism to efficiently adapt large models to individual neural signatures without catastrophic forgetting remains undetermined.
- What evidence would resolve it: Comparative studies showing a specific adaptation method maintaining high performance across new subjects with minimal fine-tuning data.

### Open Question 3
- Question: How can explainable AI (XAI) techniques be integrated into EEG-LLMs to transform them from black boxes into clinically valid decision-support tools?
- Basis in paper: [Explicit] Section 6 notes that LLMs "function as black boxes, limiting their adoption in clinical settings" and explicitly calls for "attention maps, saliency visualizations, and natural language rationales."
- Why unresolved: While LLMs improve performance, the lack of transparency regarding how they map raw brain signals to diagnostic outputs prevents clinical regulators and practitioners from trusting the technology.
- What evidence would resolve it: Validation studies where attention maps or generated rationales align with known neurophysiological markers, confirmed by clinical experts.

## Limitations
- The survey is conceptual rather than empirical, lacking novel experimental validation of proposed mechanisms
- Limited systematic evaluation of failure modes and cross-study performance variability
- Insufficient evidence for zero-shot learning scalability in real-world clinical settings

## Confidence

**High Confidence**: The foundational claim that transformer architectures can model spatiotemporal dependencies in EEG signals is well-supported by multiple studies (EEGPT, LaBraM, EEGFormer). The taxonomy itself appears methodologically sound, providing a clear organizational framework for the field.

**Medium Confidence**: Claims regarding cross-modal generation and clinical applications show promise but lack comprehensive validation. While individual studies demonstrate proof-of-concept results, the survey doesn't adequately address inter-study variability in protocols, metrics, and performance benchmarks.

**Low Confidence**: The assertion that zero-shot learning will enable robust clinical deployment requires substantial evidence. Current zero-shot approaches show significant performance gaps compared to task-specific fine-tuning, and the survey doesn't sufficiently address this limitation.

## Next Checks

1. **Cross-Validation Across Clinical Datasets**: Replicate BELT-2 or DeWave performance on at least three independent clinical EEG datasets (e.g., TUAB, SEED, and an external psychiatric dataset) to assess generalizability beyond single-study results.

2. **Real-Time Inference Benchmark**: Implement EEGCLIP or AdaCT framework and measure inference latency on edge devices (Raspberry Pi 4 or Jetson Nano) while maintaining minimum accuracy thresholds (70% for classification, BLEU >0.3 for generation).

3. **Failure Mode Analysis**: Systematically test EEG-to-text models under controlled perturbations (signal corruption, subject mismatch, temporal shuffling) and quantify degradation patterns to identify architectural vulnerabilities and inform robust design improvements.