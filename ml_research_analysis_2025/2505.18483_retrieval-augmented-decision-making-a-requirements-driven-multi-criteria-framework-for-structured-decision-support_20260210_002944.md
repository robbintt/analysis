---
ver: rpa2
title: 'Retrieval Augmented Decision-Making: A Requirements-Driven, Multi-Criteria
  Framework for Structured Decision Support'
arxiv_id: '2505.18483'
source_url: https://arxiv.org/abs/2505.18483
tags:
- decision
- criteria
- hierarchical
- text
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RAD (Retrieval Augmented Decision-Making),
  a framework that integrates multi-criteria decision analysis with large language
  models to automatically extract criteria from industry documents, build weighted
  hierarchical decision models, and generate structured decision reports. RAD addresses
  the limitations of existing LLM-based methods by introducing explicit weight assignments
  and traceable reasoning paths, ensuring transparency and interpretability in decision
  support.
---

# Retrieval Augmented Decision-Making: A Requirements-Driven, Multi-Criteria Framework for Structured Decision Support

## Quick Facts
- arXiv ID: 2505.18483
- Source URL: https://arxiv.org/abs/2505.18483
- Reference count: 40
- Primary result: RAD framework achieves up to 96% accuracy in identifying correct criteria and hierarchical relationships, outperforming baseline methods across multiple evaluation metrics

## Executive Summary
This paper introduces RAD (Retrieval Augmented Decision-Making), a framework that integrates multi-criteria decision analysis with large language models to automatically extract criteria from industry documents, build weighted hierarchical decision models, and generate structured decision reports. RAD addresses the limitations of existing LLM-based methods by introducing explicit weight assignments and traceable reasoning paths, ensuring transparency and interpretability in decision support. The framework demonstrates significant performance improvements over ablation versions and baseline methods like GraphRAG, with particular strengths in criteria identification accuracy and hierarchical relationship modeling.

## Method Summary
RAD combines multi-criteria decision analysis with large language models to create a structured decision support framework. The method automatically extracts decision criteria from industry documents using LLM-based semantic analysis, then builds weighted hierarchical decision models that capture both criteria importance and their interrelationships. A key innovation is the introduction of traceable reasoning paths that enable transparency in the decision-making process, addressing the "black box" nature of traditional LLM approaches. The framework generates structured decision reports that provide clear justification for recommendations while maintaining interpretability through explicit weight assignments and hierarchical organization.

## Key Results
- Achieves up to 96% accuracy in identifying correct criteria and hierarchical relationships
- Outperforms ablation versions and baseline methods like GraphRAG across multiple evaluation metrics
- Demonstrates strong applicability in real-world decision-making tasks with more detailed, rational, and well-structured recommendations

## Why This Works (Mechanism)
The framework's effectiveness stems from its integration of explicit weight assignments with hierarchical structure modeling, which addresses the fundamental limitation of traditional LLM approaches that lack transparency in criteria prioritization. By combining multi-criteria decision analysis principles with LLM-based semantic extraction, RAD creates a traceable reasoning path that enables users to understand not just what decision was made, but why specific criteria were weighted as they were. The hierarchical organization captures the complexity of real-world decision contexts while maintaining interpretability through structured reporting.

## Foundational Learning
- Multi-criteria decision analysis: Essential for understanding how complex decisions are structured around multiple, often competing criteria. Quick check: Can you identify the weighted criteria in a sample decision problem?
- Hierarchical decision modeling: Needed to capture relationships between criteria at different levels of abstraction. Quick check: Does the hierarchy reflect the actual decision complexity?
- Traceable reasoning paths: Critical for transparency and interpretability in AI-driven decision support. Quick check: Can you follow the logic from input criteria to final recommendation?
- LLM-based semantic extraction: Required for automatically identifying relevant criteria from unstructured industry documents. Quick check: Are the extracted criteria comprehensive and relevant to the decision context?
- Weighted aggregation methods: Important for combining multiple criteria into coherent decision scores. Quick check: Do the weights reflect actual importance relationships between criteria?

## Architecture Onboarding
Component map: Document Ingestion -> Criteria Extraction -> Hierarchical Modeling -> Weight Assignment -> Decision Generation -> Structured Reporting

Critical path: The most time-sensitive sequence runs from Criteria Extraction through Decision Generation, as errors at the extraction stage cascade through the entire decision process.

Design tradeoffs: The framework trades computational efficiency for transparency by maintaining detailed trace paths and hierarchical structures, which increases processing time but improves interpretability.

Failure signatures: Common failure modes include criteria extraction missing key requirements, weight assignment becoming skewed by outlier document content, and hierarchical relationships being incorrectly inferred from document structure.

First experiments:
1. Test criteria extraction accuracy on a small set of industry documents with known requirements
2. Validate weight assignment consistency across multiple runs with the same input
3. Verify hierarchical relationship accuracy by comparing generated structures to expert-labeled ground truth

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on internal datasets with synthetic criteria generation, limiting external validity
- Comparison with GraphRAG does not include other contemporary RAG or decision support frameworks
- Paper does not address potential biases in LLM-based criteria extraction or impact of model choice on outcomes

## Confidence
High confidence: Technical framework architecture is well-described and internally consistent; ablation studies demonstrating individual component contributions are methodologically sound.

Medium confidence: Performance improvements over baselines are statistically significant but may not generalize to different domains or document types; interpretability claims depend heavily on assumption that hierarchical structures accurately reflect decision complexity.

Low confidence: Practical applicability in real-world scenarios remains unproven due to lack of longitudinal validation or user studies with domain experts.

## Next Checks
1. External validation with domain experts in multiple industries to assess criteria extraction accuracy and decision quality in real-world contexts
2. Comparative evaluation against a broader range of contemporary decision support frameworks, including those using different RAG architectures
3. Bias and fairness analysis of the LLM-based criteria extraction process across different demographic and cultural contexts