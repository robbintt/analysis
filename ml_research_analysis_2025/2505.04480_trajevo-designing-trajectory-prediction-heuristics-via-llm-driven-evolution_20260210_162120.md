---
ver: rpa2
title: 'TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution'
arxiv_id: '2505.04480'
source_url: https://arxiv.org/abs/2505.04480
tags:
- trajectory
- prediction
- velocity
- heuristics
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TrajEvo automates the design of trajectory prediction heuristics
  using LLMs within an evolutionary framework. It generates fast, interpretable code
  that combines adaptive kinematics, noise, and interaction rules.
---

# TrajEvo: Designing Trajectory Prediction Heuristics via LLM-driven Evolution

## Quick Facts
- **arXiv ID**: 2505.04480
- **Source URL**: https://arxiv.org/abs/2505.04480
- **Reference count**: 40
- **Primary result**: LLM-driven evolution generates interpretable trajectory prediction heuristics that outperform both traditional heuristics and deep learning models on ETH-UCY benchmarks while generalizing best to unseen SDD data

## Executive Summary
TrajEvo introduces a novel framework for automatically designing trajectory prediction heuristics using large language models (LLMs) within an evolutionary optimization process. The system generates fast, interpretable code-based heuristics that combine adaptive kinematics, noise injection, and interaction rules to predict future pedestrian trajectories. By evolving code directly rather than using fixed mathematical forms, TrajEvo discovers novel heuristic structures that significantly outperform traditional hand-designed approaches while maintaining computational efficiency and interpretability.

The framework demonstrates that LLM-driven evolution can bridge the gap between traditional interpretable heuristics and complex deep learning models. TrajEvo heuristics achieve superior performance on standard benchmarks (ETH-UCY) while generalizing better to unseen data (SDD) compared to both traditional methods and state-of-the-art deep learning approaches. The approach requires orders of magnitude less computational resources than deep learning models while producing predictions that can be inspected, modified, and understood by human practitioners.

## Method Summary
TrajEvo employs an evolutionary framework where LLMs generate trajectory prediction heuristics as executable code. The process begins with human-designed heuristic seeds, which the LLM modifies through small perturbations to create offspring candidates. Each candidate heuristic is evaluated on trajectory prediction tasks using standard metrics (minADE, minFDE), and the best-performing candidates are selected for subsequent generations. This evolutionary loop continues for multiple generations, with the LLM learning to generate increasingly effective heuristic structures over time. The framework uses only positional history as input, making the generated heuristics simple and computationally efficient while maintaining strong predictive performance across diverse pedestrian trajectory datasets.

## Key Results
- Outperforms all prior heuristics and several deep learning models on ETH-UCY benchmarks
- Achieves best generalization to unseen SDD data compared to both heuristics and state-of-the-art deep networks
- Requires far less computational resources than deep learning approaches while maintaining interpretable predictions
- Generates novel heuristic structures combining adaptive kinematics, noise, and interaction rules

## Why This Works (Mechanism)
The evolutionary framework leverages LLM reasoning capabilities to explore heuristic design space efficiently. By treating heuristic generation as a code-generation task, the LLM can propose novel combinations of mathematical operations and logical structures that human designers might not consider. The evolutionary pressure ensures that only heuristics with strong empirical performance survive, while the LLM's pattern recognition helps avoid local optima by suggesting diverse modifications. This combination of evolutionary selection and LLM creativity enables discovery of effective heuristic structures that balance accuracy, speed, and interpretability.

## Foundational Learning
- **Evolutionary Algorithms**: Population-based optimization methods that iteratively improve solutions through selection and variation
  - Why needed: Provides systematic way to explore heuristic design space and optimize for prediction performance
  - Quick check: Verify understanding of selection pressure, mutation rates, and convergence criteria
- **Trajectory Prediction Metrics (ADE/FDE)**: Average and Final Displacement Errors measuring prediction accuracy
  - Why needed: Standard evaluation metrics for comparing trajectory prediction methods
  - Quick check: Confirm understanding of minADE/minFDE vs standard ADE/FDE formulations
- **Pedestrian Trajectory Datasets (ETH-UCY, SDD)**: Standard benchmarks for evaluating prediction algorithms
  - Why needed: Provide standardized test environments for comparing methods across research groups
  - Quick check: Review dataset characteristics, scene types, and data collection methods
- **Heuristic vs Deep Learning Approaches**: Trade-offs between interpretable rule-based methods and black-box neural networks
  - Why needed: Context for understanding TrajEvo's contribution to the field
  - Quick check: Compare inference speed, training requirements, and interpretability between approaches
- **LLM Code Generation**: Using language models to produce executable code for specific tasks
  - Why needed: Core mechanism enabling automatic heuristic design
  - Quick check: Verify understanding of prompt engineering and code generation capabilities

## Architecture Onboarding

Component Map: Human-designed heuristics -> LLM perturbation -> Candidate heuristics -> Evaluation -> Selection -> Next generation

Critical Path: Seed heuristic → LLM modification → Code generation → Metric evaluation → Selection → Evolution

Design Tradeoffs: Speed vs accuracy (simple heuristics are fast but potentially less accurate), interpretability vs expressivity (code is readable but may have limited complexity), evolution time vs final performance (more generations yield better results but cost more compute)

Failure Signatures: Poor generalization (overfitting to training data), computational inefficiency (generated code too complex), lack of interpretability (code becomes too convoluted), stagnation (evolution fails to improve beyond initial seeds)

First Experiments:
1. Verify baseline performance of original human-designed heuristics on ETH-UCY datasets
2. Test single-generation LLM perturbation to confirm code generation capability
3. Run full evolutionary process for 5 generations to observe improvement trends

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can TrajEvo heuristics be extended to leverage richer input modalities (e.g., semantic maps, agent types, obstacle positions) while maintaining interpretability?
- Basis in paper: [explicit] Limitations section states: "TRAJ EVO currently does not leverage this complexity. Extending the framework to incorporate and reason about such inputs would represent a significant next step."
- Why unresolved: Current framework uses only positional history; real-world systems have access to additional sensor data.
- What evidence would resolve it: Demonstration of TrajEvo generating heuristics that consume and reason about semantic or environmental features, with comparison to positional-only baselines.

### Open Question 2
- Question: Can TrajEvo directly optimize heuristics for downstream robotic task objectives (e.g., navigation success rate, collision avoidance) rather than prediction metrics?
- Basis in paper: [explicit] Limitations section: "Further developing our framework to optimize heuristics directly for task-specific objectives within a closed loop... represents an interesting avenue for future works."
- Why unresolved: Current optimization uses minADE/minFDE which may not perfectly correlate with downstream task performance.
- What evidence would resolve it: Closed-loop experiments showing heuristics evolved for task objectives outperform those evolved for prediction metrics in simulation environments.

### Open Question 3
- Question: Can the in-distribution accuracy gap between TrajEvo heuristics and specialized deep learning models (e.g., MoFlow) be closed through more advanced evolutionary operators?
- Basis in paper: [explicit] Limitations section notes generated heuristics "do not consistently achieve the absolute lowest error metrics... compared to the most recent, highly specialized deep learning models."
- Why unresolved: Heuristics evolved for interpretability and speed may have inherent expressivity limits.
- What evidence would resolve it: Modified TrajEvo variants matching or exceeding SOTA deep learning ADE/FDE on ETH-UCY while preserving interpretability.

### Open Question 4
- Question: How sensitive is TrajEvo's performance to the choice of LLM backbone?
- Basis in paper: [inferred] All experiments use only Gemini 2.0 Flash; no comparison across different LLMs is provided despite LLM capabilities being core to the approach.
- Why unresolved: LLM reasoning quality may significantly impact heuristic evolution quality.
- What evidence would resolve it: Ablation study comparing TrajEvo performance across multiple LLM backbones (e.g., GPT-4, Claude, open-source models).

## Limitations
- Reliance on curated human-designed heuristics as evolutionary seeds may limit solution diversity and introduce bias toward conventional methods
- Evaluation of generalization limited to single unseen SDD dataset without broader validation across multiple diverse trajectory prediction scenarios
- Generated heuristics do not consistently achieve absolute lowest error metrics compared to most recent highly specialized deep learning models

## Confidence
- **High Confidence**: TrajEvo's ability to generate interpretable, code-based heuristics that outperform traditional heuristic methods on ETH-UCY benchmarks
- **Medium Confidence**: Claims about computational efficiency and inference speed relative to deep learning models, as these depend on specific implementation details and hardware configurations not fully specified
- **Medium Confidence**: Generalization performance to SDD dataset, as the evaluation scope is limited to one external dataset without broader validation across multiple unseen environments

## Next Checks
1. Test TrajEvo's evolutionary framework on trajectory prediction datasets from different domains (e.g., autonomous vehicles, sports analytics, or drone navigation) to verify cross-domain generalization
2. Conduct ablation studies removing the LLM component to quantify its specific contribution versus traditional evolutionary algorithm components
3. Compare TrajEvo's interpretability claims against other explainable AI methods for trajectory prediction using standardized interpretability metrics and human evaluation studies