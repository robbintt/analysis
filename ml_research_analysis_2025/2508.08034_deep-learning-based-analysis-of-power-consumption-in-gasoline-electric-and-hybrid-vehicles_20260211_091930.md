---
ver: rpa2
title: Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and
  Hybrid Vehicles
arxiv_id: '2508.08034'
source_url: https://arxiv.org/abs/2508.08034
tags:
- power
- consumption
- vehicle
- energy
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduced a data-driven approach using deep neural\
  \ networks (DNNs) to predict instantaneous and cumulative power consumption in internal\
  \ combustion engine (ICE), electric vehicle (EV), and hybrid electric vehicle (HEV)\
  \ platforms. Using real-world driving data from three distinct powertrains, the\
  \ models achieved high accuracy for ICE with mean absolute error and root mean squared\
  \ error on the order of 10\u207B\xB3 and cumulative errors under 3%."
---

# Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles

## Quick Facts
- arXiv ID: 2508.08034
- Source URL: https://arxiv.org/abs/2508.08034
- Reference count: 13
- Deep neural networks accurately predict instantaneous and cumulative power consumption across ICE, EV, and HEV platforms with errors below 4%

## Executive Summary
This study introduces a data-driven approach using deep neural networks (DNNs) to predict instantaneous and cumulative power consumption across internal combustion engine (ICE), electric vehicle (EV), and hybrid electric vehicle (HEV) platforms. Using real-world driving data from three distinct powertrains, the models achieved high accuracy for ICE with mean absolute error and root mean squared error on the order of 10⁻³ and cumulative errors under 3%. Transformer and long short-term memory models performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%, respectively. Uncertainty analysis revealed greater variability in EV and HEV datasets than ICE, due to complex power management, emphasizing the need for robust models for advanced powertrains.

## Method Summary
The approach employs sliding window segmentation to convert sequential driving data into structured sequences for temporal learning, using window sizes of 10 timesteps for ICE and HEV and 50 for EV. Four model architectures (TCN, LSTM, Transformer, RF) were trained on mechanical state variables (speed, acceleration, torque, RPM) without battery electrical parameters to maintain generalizability. Models were trained for 300 epochs using Adam optimizer and evaluated on instantaneous and cumulative power prediction accuracy, with uncertainty quantified through Monte Carlo dropout, weight randomization, and Gaussian noise injection.

## Key Results
- ICE models achieved MAE and RMSE on the order of 10⁻³ with cumulative errors under 3%
- Transformer models showed lowest cumulative error for EV (4.1%) and HEV (2.1%)
- Uncertainty analysis revealed higher variability in EV and HEV predictions compared to ICE, attributed to complex power management systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sliding window segmentation captures temporal dependencies essential for accurate power prediction in sequential driving data.
- Mechanism: Non-overlapping windows of length 10-50 timesteps (depending on vehicle type and model) convert pointwise inputs into structured sequences, allowing models to learn acceleration/deceleration patterns, regenerative braking events, and transient power dynamics rather than isolated snapshots.
- Core assumption: Temporal context within the window contains sufficient information to predict the target timestep; future dependencies beyond the window are negligible for instantaneous prediction.
- Evidence anchors:
  - [section 3.2] "This method segments continuous time series data into sequences, ensuring that the model learns from both past and present states."
  - [section 4.4] Optimal window sizes varied: ICE (WS=10), EV (WS=50), HEV (WS=10), indicating powertrain-specific temporal dependency lengths.
  - [corpus] Limited direct corpus support for window size optimization; mostly implicit in time-series forecasting literature.
- Break condition: If driving patterns exhibit dependencies longer than the chosen window (e.g., extended highway cruising or multi-minute energy management cycles in HEVs), shorter windows will truncate relevant context and degrade cumulative prediction accuracy.

### Mechanism 2
- Claim: Powertrain dynamic features (speed, acceleration, torque, RPM) provide sufficient signal for DNNs to learn instantaneous power consumption without requiring battery electrical parameters.
- Mechanism: DNNs approximate the implicit mapping from mechanical state variables to power output, learning nonlinear relationships including regenerative braking (negative acceleration → negative power) without explicit physical equations. The model infers internal power management logic from observable dynamics.
- Core assumption: The selected features fully encode the determinants of power consumption; no unmeasured confounders (e.g., ambient temperature, road grade, HVAC load) significantly bias predictions.
- Evidence anchors:
  - [section 6.3] "Battery-related electrical parameters such as SOC, voltage, and current are intentionally excluded... by relying solely on powertrain dynamic signals, the proposed approach preserves generalizability."
  - [section 5.2-5.4] Tables show best ICE performance with [speed, engine torque, engine RPM] (MAE=0.4×10⁻³), EV best with [acceleration, speed, motor torque, motor RPM] (MAE=6.17), HEV best with full feature set (MAE=4.72).
  - [corpus] Neighbor paper "A Hybrid Surrogate for Electric Vehicle Parameter Estimation" uses physics-informed operators with speed/acceleration inputs, supporting the feasibility of minimal feature sets, though that work incorporates physics modules.
- Break condition: If significant unmeasured factors (e.g., thermal management, auxiliary loads, battery degradation) materially affect power draw, the learned mapping will exhibit systematic bias or increased variance, particularly for cumulative estimates.

### Mechanism 3
- Claim: Monte Carlo-based uncertainty quantification via dropout, weight randomization, and Gaussian noise injection reveals powertrain-specific prediction reliability, with EVs/HEVs exhibiting higher uncertainty than ICE.
- Mechanism: During inference, N=30 stochastic forward passes with activated dropout, randomly initialized weights, and feature-wise Gaussian noise (σ estimated from steady-state segments) produce prediction distributions. Standard deviation quantifies epistemic + aleatoric uncertainty.
- Core assumption: The stochastic inference procedure approximates a Bayesian posterior; dropout and noise adequately sample the model's uncertainty space.
- Evidence anchors:
  - [section 4.2] "We quantified the uncertainty... using a frequentist Monte Carlo-based approach... by applying the model's weight random initialization, additive Gaussian noise, and dropout."
  - [table 8] EV dataset shows highest uncertainty (MAE std=0.63, cumulative MAE% std=5.62%) vs. ICE (near-zero instantaneous std, cumulative std=0.52%), attributed to complex power management.
  - [corpus] No direct corpus validation of this specific uncertainty method for vehicle power; general Monte Carlo dropout approach is established in ML literature per citations (Gal & Ghahramani 2016).
- Break condition: If the noise model mischaracterizes true input variability (e.g., non-Gaussian sensor errors) or dropout rate is poorly tuned, uncertainty estimates will be miscalibrated—either overconfident or excessively conservative.

## Foundational Learning

- Concept: **Time-series sequence modeling (windowing vs. autoregressive)**
  - Why needed here: Power consumption is temporally dependent; single-point inputs lack context for predicting regenerative braking or acceleration transients.
  - Quick check question: Given a window of [t-9, t-8, ..., t], what information would be lost if predicting at t using only the value at t-1?

- Concept: **Uncertainty quantification (epistemic vs. aleatoric)**
  - Why needed here: EVs/HEVs exhibit higher variability; point predictions alone are insufficient for safety-critical energy management applications.
  - Quick check question: If model uncertainty increases with longer prediction horizons, is this epistemic, aleatoric, or both?

- Concept: **Feature-target independence for generalization**
  - Why needed here: Excluding directly computable features (P=V×I) ensures the model learns meaningful mappings rather than trivial identities.
  - Quick check question: If you include battery voltage and current as features, what trivial relationship might the model exploit instead of learning dynamics?

## Architecture Onboarding

- Component map:
  - CAN-bus/OBD-II -> timestamp synchronization (10⁻⁷s resolution) -> sliding window segmentation -> MinMax normalization
  - TCN (dilated 1D convs, kernel=5, dilations=[1,2,4]), LSTM (3 stacked layers, 32 hidden units), Transformer (4 encoder layers, 64-dim embedding, 2 attention heads), RF (baseline, 100 estimators, max_depth=20)
  - Feature-wise Gaussian noise estimation -> N=30 stochastic forward passes with dropout=0.2 + weight randomization -> mean/std aggregation
  - Instantaneous power (scalar regression) + cumulative power (discrete integral via Eq. 2)

- Critical path:
  1. Data collection with consistent sampling (ICE: 2Hz, EV: 0.2Hz, HEV: 1.7Hz) -> synchronization -> windowing
  2. Hyperparameter tuning via Optuna (10% validation split, MAE/RMSE objectives)
  3. Model training (300 epochs, Adam optimizer, LR=0.001, batch=64, MSE loss)
  4. Uncertainty quantification on test set

- Design tradeoffs:
  - **TCN vs. LSTM vs. Transformer**: TCN fastest inference (0.47ms), Transformer most accurate for EVs but slowest (1.03ms, 1.9M params), LSTM best for HEV cumulative prediction
  - **Window size**: Larger windows (EV=50) capture longer dependencies but increase latency; smaller windows (ICE/HEV=10) suffice for simpler powertrains
  - **Feature set**: Fewer features (ICE: speed, torque, RPM) work well; EVs/HEVs require richer sets but still exclude battery parameters to maintain generalization

- Failure signatures:
  - **High instantaneous error with low cumulative error**: Model missing fine-grained dynamics but capturing average trends (check window size, feature completeness)
  - **Increasing uncertainty over cumulative horizon**: Characteristic of EVs due to compounding power management complexity; consider physics-informed constraints
  - **RF outperforming DNNs on cumulative metrics**: DNN may be underfitting; increase model capacity or training data (EV had only 2,275 training samples vs. 17,500 for HEV)

- First 3 experiments:
  1. Replicate ICE baseline: Train TCN on [speed, engine torque, engine RPM] with WS=10; verify MAE<1×10⁻³ on held-out test set. This confirms pipeline correctness on the simplest powertrain.
  2. Ablate window size for EV: Train Transformer on full feature set with WS∈[10, 30, 50, 70]; plot instantaneous vs. cumulative error. Expect diminishing returns beyond WS=50 per paper findings.
  3. Uncertainty calibration check: For EV test set, compute prediction interval coverage (e.g., 95% CI from ±2std should contain ~95% of true values). If miscalibrated, adjust dropout rate or noise σ estimation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating physics-informed neural networks (PINNs) or hybrid physical-data models enhance the generalizability and interpretability of vehicle power consumption predictions?
- Basis in paper: [explicit] Section 7 states that future work could incorporate PINNs to embed physical vehicle dynamics (e.g., Newtonian motion) into the learning process.
- Why unresolved: The current study utilized purely data-driven deep neural networks (DNNs) which, while effective, lack embedded physical constraints and may lack interpretability.
- What evidence would resolve it: A comparative study showing that PINNs maintain lower error rates than standard DNNs when tested on out-of-distribution driving scenarios or different vehicle types.

### Open Question 2
- Question: Does accessing high-resolution data directly from embedded vehicle sensors significantly improve prediction accuracy compared to standard OBD-II interfaces?
- Basis in paper: [explicit] Section 7 suggests moving beyond standard OBD-II interfaces to collect high-resolution data from embedded sensors for better model accuracy.
- Why unresolved: The EV and HEV data in this study were collected via a smartphone application with lower sampling rates (0.2 Hz and 1.7 Hz), which contributed to higher uncertainty.
- What evidence would resolve it: Experiments demonstrating reduced Mean Absolute Error (MAE) and uncertainty bounds in EV models trained on high-frequency embedded sensor data versus OBD-II data.

### Open Question 3
- Question: How robust are the proposed models when applied to highly diverse driving scenarios, such as extreme topographies or aggressive urban driving?
- Basis in paper: [explicit] Section 7 notes that extending data collection to diverse driving scenarios is a necessary future step to assess model generalizability.
- Why unresolved: The dataset was limited to two specific routes in Ontario (highway and rural), potentially limiting the model's exposure to variables like steep gradients or dense urban traffic.
- What evidence would resolve it: Evaluation of the trained Transformer and LSTM models on datasets containing significantly different road types and driving styles, showing consistent error rates below the reported baselines.

## Limitations
- Data representativeness is unclear due to unspecified dataset composition (city vs. highway driving ratios, weather conditions, driver behavior)
- Window size optimization lacks theoretical grounding and may introduce overfitting for EV models with longer windows
- Uncertainty quantification methodology needs comparison to alternative approaches to establish relative efficacy

## Confidence
- **High Confidence**: ICE model performance claims (MAE ~10⁻³, cumulative error <3%) due to consistent results across multiple architectures and simpler powertrain dynamics
- **Medium Confidence**: EV and HEV performance metrics, particularly cumulative error percentages, given higher variability and fewer training samples (especially EV with only 2,275 training points)
- **Medium Confidence**: Uncertainty analysis conclusions, as the Monte Carlo approach is well-established but application-specific calibration is unverified

## Next Checks
1. **Data Augmentation Experiment**: Apply synthetic data generation (e.g., SMOTE for time series or physics-based perturbations) to EV training set and measure impact on cumulative error and uncertainty estimates
2. **Cross-Powertrain Transfer Learning**: Train a single model on combined ICE+EV+HEV data and evaluate per-platform performance
3. **Uncertainty Calibration Benchmark**: Compare Monte Carlo dropout uncertainty estimates against bootstrap ensemble methods using identical data splits and architectures