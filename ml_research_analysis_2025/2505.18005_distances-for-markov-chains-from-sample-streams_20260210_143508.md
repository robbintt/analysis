---
ver: rpa2
title: Distances for Markov chains from sample streams
arxiv_id: '2505.18005'
source_url: https://arxiv.org/abs/2505.18005
tags:
- learning
- stochastic
- algorithm
- markov
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of computing optimal transport
  distances between Markov chains using only sample trajectories, without requiring
  explicit transition models. The authors propose a stochastic optimization method
  based on a new linear programming formulation of bisimulation metrics, which are
  equivalent to optimal transport distances.
---

# Distances for Markov chains from sample streams

## Quick Facts
- arXiv ID: 2505.18005
- Source URL: https://arxiv.org/abs/2505.18005
- Reference count: 40
- Key outcome: Stochastic optimization method for computing optimal transport distances between Markov chains using only sample trajectories, without requiring explicit transition models.

## Executive Summary
This paper addresses the problem of computing optimal transport distances (bisimulation metrics) between Markov chains using only sample trajectories, without requiring explicit transition models. The authors propose a stochastic optimization method based on a new linear programming formulation that reformulates constraints to eliminate direct dependence on transition probabilities. By leveraging stochastic primal-dual optimization and iterate averaging, the algorithm estimates the metric from sample transitions while providing theoretical guarantees on sample complexity.

## Method Summary
The method (SOMCOT) reformulates the bisimulation metric as a linear program over occupancy couplings, then applies stochastic primal-dual optimization. Primal variables (occupancy coupling and conditional distributions) are updated via entropic mirror descent using gradients estimated from sampled transitions, while dual variables (causality and flow constraint multipliers) are updated via projected gradient ascent. Iterate averaging smooths oscillations, and a rounding procedure projects approximate solutions to valid occupancy couplings. The approach requires O(|X||Y|(|X|+|Y|)) iterations for ε-accuracy with each iteration costing Θ(|X|²|Y|²) computation.

## Key Results
- Theoretical sample complexity bound of O(|X||Y|(|X|+|Y|)) iterations for ε-accuracy
- Empirical effectiveness in representation learning and model selection tasks
- Ability to identify latent structures and select true models even with limited sample sizes
- Validation on block Markov chains and discretized Pendulum environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sample-based gradient estimation from occupancy measures preserves unbiasedness for optimizing bisimulation metrics without explicit transition kernels.
- Mechanism: Reformulates LP constraints to eliminate direct dependence on transition probabilities, replacing analytical occupancy measures with sampled transitions from geometric stopping times. Stochastic gradient estimators satisfy unbiasedness conditions enabling stochastic mirror descent-ascent to converge.
- Core assumption: Independent samples from occupancy measures are available and gradients remain bounded.
- Evidence anchors: Abstract states algorithm estimates metrics from sample access without transition models; section 3.2 proves gradient unbiasedness; related stochastic approximation bounds exist.

### Mechanism 2
- Claim: Primal-dual optimization with iterate averaging controls duality gap and stabilizes convergence.
- Mechanism: Treats Lagrangian as saddle-point problem with primal variables updated via entropic mirror descent and dual variables via projected gradient ascent. Averaging smooths oscillations and bounds error via average duality gap decomposition.
- Core assumption: Learning rates are appropriately tuned and dual feasible sets contain optimal comparators.
- Evidence anchors: Section 4 decomposes duality gap into regret terms; section 5 shows averaging smooths oscillations; no direct corpus support for this specific averaging scheme.

### Mechanism 3
- Claim: Analytical rounding bounds the gap between approximate and valid occupancy couplings.
- Mechanism: Projects output violating constraints to valid couplings via Altschuler et al.'s algorithm. Lemma 2 bounds rounding error by linear function of constraint violations.
- Core assumption: Rounding is analysis-only requiring theoretical knowledge of occupancy measures.
- Evidence anchors: Section C.2 applies rounding procedure and bounds error; no corpus papers discuss this specific rounding analysis.

## Foundational Learning

- Concept: Bicausal optimal transport and bisimulation metrics
  - Why needed here: Distance is defined via bicausal couplings respecting temporal structure; standard OT doesn't apply.
  - Quick check question: Why must a bicausal coupling restrict how $X_{t+1}$ depends on $Y_t$ compared to a general coupling?

- Concept: Occupancy measures in Markov chains
  - Why needed here: LP formulation and sampling rely on discounted occupancy measures.
  - Quick check question: Given $\gamma=0.9$, how would you sample from a Markov chain's discounted occupancy measure?

- Concept: Online stochastic mirror descent and regret analysis
  - Why needed here: Convergence guarantees derive from OSMD regret bounds with entropic regularization.
  - Quick check question: For OSMD on probability simplex with entropy regularizer, what's the update rule given gradient estimate $g$?

## Architecture Onboarding

- Component map:
  - Primal variables: $\mu \in \Delta_{\mathcal{X}\mathcal{Y}\mathcal{X}\mathcal{Y}}$ (occupancy coupling), $\lambda^X \in \Delta_{\mathcal{Y}|\mathcal{X}}$, $\lambda^Y \in \Delta_{\mathcal{X}|\mathcal{Y}}$ (conditional distributions)
  - Dual variables: $\alpha^X, \alpha^Y$ (causality constraint multipliers), $V$ (flow constraint multiplier)
  - Gradient estimators: Constructed from sampled transitions and current iterates (Eqs. 10-15)
  - Update rules: Entropic mirror descent for primal (Eqs. 16-18), projected gradient ascent for dual (Eqs. 19-21)
  - Output: Averaged $\bar{\mu}_K$, distance estimate $\hat{d}_\gamma = \langle \bar{\mu}_K, c \rangle$, encoder-decoder maps $\bar{\lambda}^X, \bar{\lambda}^Y$

- Critical path: Initialize $\mu^1$ uniform, $\lambda$ uniform, $\alpha=0, V=0$ → each iteration: sample transitions → compute gradients → update primal → update dual → accumulate $\mu^k$ → output averages

- Design tradeoffs:
  - $\eta/\beta$ ratio: High → constraint violations (underestimation); low → overestimation
  - Iterate averaging: Essential for stability but requires storage/running average
  - Sampling: Geometric stopping-time sampling vs. trajectory-based (cheaper but correlated)

- Failure signatures:
  - Distance → 0: $\beta$ too small or $\eta$ too large
  - Distance overestimates/unstable: $\beta$ too large relative to $\eta$
  - No convergence: Learning rates not decayed; samples too correlated

- First 3 experiments:
  1. Validate on small block Markov chains ($n=10, B=5$) with known ground truth; compare distance estimates and encoder-decoder maps vs. sample size
  2. Ablate $\eta/\beta$ ratio and decay scheme; plot convergence to identify stable regions
  3. Test on discretized Pendulum; verify model selection (identify true gravity parameter) and robustness to non-Markovian discretization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SOMCOT be extended to Markov chains with infinite or continuous state spaces?
- Basis in paper: "Most importantly, it remains unclear how to properly scale our algorithm to larger problems with potentially infinite state spaces."
- Why unresolved: Current LP formulation assumes finite state spaces; while dual variables could be parameterized via kernels or neural networks, approximating primal variables remains challenging.
- What evidence would resolve it: Modified algorithm with sample complexity guarantees for infinite state spaces under structural assumptions.

### Open Question 2
- Question: Can per-iteration computational cost of Θ(|X|²|Y|²) be improved while maintaining sample complexity guarantees?
- Basis in paper: Theoretical results show gap between sample complexity O(|X||Y|(|X|+|Y|)) and per-iteration cost Θ(|X|²|Y|²).
- Why unresolved: Algorithm requires updating all entries of occupancy coupling at each iteration; no exploration of sparse or amortized update schemes.
- What evidence would resolve it: Algorithm variant with per-iteration cost o(|X|²|Y|²) achieving comparable sample complexity bounds.

### Open Question 3
- Question: Can the OT distance computed by SOMCOT be differentiated end-to-end for use in representation learning and model-based RL?
- Basis in paper: "Successful implementation of this idea may lead to strong theoretically sound alternatives to empirically successful methods such as MuZero."
- Why unresolved: Paper identifies potential but doesn't implement or validate gradient-based learning using OT distance as loss function.
- What evidence would resolve it: Empirical demonstration showing differentiating through SOMCOT's output improves representation learning compared to existing methods.

## Limitations

- Theoretical analysis assumes independent samples from occupancy measures, but practical sampling from long-term occupancies remains challenging
- Primal-dual optimization relies on specific parameter regimes that may not be robust to practical deviations
- Empirical validation limited to relatively small-scale problems, leaving scalability to complex domains uncertain

## Confidence

**High confidence** in mathematical formulation and theoretical guarantees for idealized setting with independent occupancy samples and appropriate learning rate tuning.

**Medium confidence** in practical applicability due to unknown factors around sampling efficiency, correlation in trajectory data, and hyperparameter sensitivity.

**Low confidence** in robustness to violations of theoretical assumptions, particularly regarding sampling requirements and correlated transitions.

## Next Checks

1. **Scaling experiment**: Implement on block Markov chains with increasing state space sizes (n=10, 50, 100, 200) while keeping B=5 fixed. Measure runtime, sample complexity, and distance accuracy to identify practical scalability limits and when Θ(|X|²|Y|²) per-iteration cost becomes prohibitive.

2. **Sampling correlation study**: Generate highly correlated trajectory samples and compare convergence rates and final distance estimates against independent occupancy sampling baseline. Quantify performance degradation from correlation and test buffer-based decorrelation techniques.

3. **Rounding procedure implementation**: Implement Altschuler et al.'s rounding algorithm and measure actual constraint violation for various iteration counts and learning rate settings. Compare observed rounding error against theoretical bound and assess impact on final distance estimates.