---
ver: rpa2
title: Skill Learning via Policy Diversity Yields Identifiable Representations for
  Reinforcement Learning
arxiv_id: '2507.14748'
source_url: https://arxiv.org/abs/2507.14748
tags:
- learning
- arxiv
- identifiability
- skill
- skills
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors investigate why mutual information skill learning (MISL)
  methods in reinforcement learning (RL) succeed at learning useful state representations.
  They focus on Contrastive Successor Features (CSF) and prove that its success can
  be explained by identifiable representation learning theory from nonlinear ICA.
---

# Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning

## Quick Facts
- arXiv ID: 2507.14748
- Source URL: https://arxiv.org/abs/2507.14748
- Reference count: 40
- One-line primary result: CSF provably recovers ground-truth environment states up to a linear transformation when using inner product critics and diverse skill-conditioned policies.

## Executive Summary
This paper investigates why mutual information skill learning (MISL) methods like Contrastive Successor Features (CSF) succeed at learning useful state representations in reinforcement learning. The authors prove that CSF's success can be explained by identifiable representation learning theory from nonlinear ICA. Specifically, when using an inner product parametrization for the critic and diverse skill-conditioned policies, CSF learns features up to a linear transformation of the ground-truth states. The work provides theoretical insights into what constitutes a diverse policy, why maximum entropy policies fail, and how different MI objectives affect feature space geometry.

## Method Summary
The Contrastive Successor Features (CSF) algorithm learns representations by maximizing mutual information between skills and state transitions. Skills are sampled uniformly from the hypersphere, and the policy is conditioned on these skills to generate state transitions. The encoder maps observations to feature vectors, and the critic (discriminator) uses an inner product between feature differences and skill vectors to classify the skill. The method uses a contrastive loss to update the encoder and critic, while the policy is updated to maximize the similarity between feature differences and skill vectors. The authors validate their theoretical claims through experiments in MuJoCo and DeepMind Control environments, testing both state-based and pixel-based observations.

## Key Results
- CSF provably recovers ground-truth environment states up to a linear transformation when using inner product critics
- Maximum entropy policies fail because they break the dependence between skills and state transitions
- Mutual information on transitions (I(s,s';z)) is superior to states (I(s;z)) for preventing feature collapse
- R² scores up to 1.0 demonstrate high linear identifiability of learned features
- Oracle returns up to 200 validate zero-shot task transfer capability

## Why This Works (Mechanism)

### Mechanism 1: Linear Identifiability via Inner Product Parametrization
The Contrastive Successor Features (CSF) method recovers ground-truth environment states up to a linear transformation, provided the critic uses an inner product structure. The critic q(z|φ(o), φ(o')) is parametrized as a log-linear model (inner product between feature differences and skill vectors). This structure aligns with nonlinear Independent Component Analysis (ICA) theory, allowing the encoder φ to invert the observation generator function g up to a linear matrix A. The core assumption is that the data generating process is continuous and injective, and the model reaches the global optimum of the contrastive objective. Replacing the inner product critic with a generic MLP without structural constraints likely voids the identifiability guarantee.

### Mechanism 2: Skill Diversity as Auxiliary Interventions
Uniform sampling of skills from the hypersphere acts as a set of distinct "interventions," creating the sufficient variability required to disentangle state features. By conditioning the policy on diverse skills z, the agent generates state transitions (s, s') that vary distinctively depending on z. This satisfies the "sufficient variability" condition of ICA (specifically, the skill set spans R^d), ensuring the marginal distribution of features is uniform and identifiable. The core assumption is that the skill-conditioned policy is diverse, meaning p(s'|s, a) differs for different skills, and the feature differences follow a von Mises-Fisher distribution centered on the skill. Using a maximum-entropy policy or too few fixed skills prevents the spanning of the latent space, causing identifiability to fail.

### Mechanism 3: Geometric Constraints of Transition-Based MI
Maximizing Mutual Information on transitions I(s, s'; z) rather than states I(s; z) enforces geometric constraints that prevent representation collapse. The reward r_z maximizes the inner product [φ(o') - φ(o)]^T z. This forces the feature difference vector to be parallel to the skill vector. Consequently, φ(o) and φ(o') must be distinct and close (sequential states). Optimizing I(s; z) lacks this locality constraint, risking antipodal or collapsed features. The core assumption is that consecutive states (s, s') are distinct but locally correlated. Switching the objective to ignore state transitions (using only I(s;z)) may lead to feature collapse where the encoder maps all states to the same point.

## Foundational Learning

- **Concept: Nonlinear Independent Component Analysis (ICA)**
  - **Why needed here:** The paper frames the RL representation problem as a nonlinear ICA problem. You must understand that "identifiability" refers to the mathematical ability to recover ground-truth latent variables from observations, which is generally impossible in nonlinear cases without specific constraints (like auxiliary variables/skills).
  - **Quick check question:** Why does nonlinear ICA require "auxiliary variables" (like skills) to achieve identifiability, unlike linear ICA?

- **Concept: Mutual Information Skill Learning (MISL)**
  - **Why needed here:** This is the class of algorithms CSF belongs to. It frames the unsupervised RL problem as maximizing the dependence between the agent's behavior (skill) and the resulting states.
  - **Quick check question:** In MISL, what does maximizing I(S; Z) incentivize the policy to do?

- **Concept: von Mises-Fisher (vMF) Distribution**
  - **Why needed here:** The paper assumes feature differences conditioned on skills follow this distribution. It is a probability distribution on the hypersphere, which matches the geometric constraints of the normalized feature space.
  - **Quick check question:** How does the vMF distribution differ from a standard Gaussian in terms of the support of the data?

## Architecture Onboarding

- **Component map:** Skill Prior -> Encoder φ -> Policy π -> Critic q (inner product) -> Contrastive Loss
- **Critical path:**
  1. Sample skill z ~ Uniform(S^{d-1})
  2. Policy executes z, generating (o, o')
  3. Encoder computes feature difference Δφ = φ(o') - φ(o)
  4. Critic computes similarity via Δφ^T z
  5. Update Encoder/Critic via Contrastive Loss (Cross-Entropy); Update Policy to maximize Δφ^T z

- **Design tradeoffs:**
  - **Latent Dimensionality:** Must be ≥ ground-truth state dimension for identifiability. However, lower dimensions may act as a bottleneck that improves downstream task transfer
  - **Discrete vs. Continuous Skills:** Discrete skills are easier to manage but may fail to span the space; continuous sampling is preferred for identifiability
  - **Entropy Regularization:** Avoid standard max-entropy regularization. The paper proves it breaks the dependence between skill and state transitions

- **Failure signatures:**
  - **Low R² Score (Linear Fit):** The number of skills is too low or the skill space is not covered (diversity violation)
  - **Feature Collapse:** Using I(s; z) instead of I(s, s'; z), or the encoder weights collapsing to zero
  - **Stagnant Policy:** Excessive entropy regularization causing the policy to ignore the skill condition

- **First 3 experiments:**
  1. **Linear Decodability Test:** Train CSF on a MuJoCo environment; freeze the encoder; train a linear probe to map φ(o) to ground-truth state s. Success = High R²
  2. **Skill Diversity Ablation:** Fix the number of skills to a small set (e.g., 3, 5, 10) vs. continuous sampling. Plot R² and state coverage to verify the "affine generator system" requirement
  3. **Objective Comparison:** Compare the geometry of the learned latent space for I(s, s'; z) vs. I(s; z) by visualizing φ(o) and φ(o') for consecutive states. Look for collapse or antipodal points in the latter

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the diversity reward function serve as a reliable metric for learning useful representations in offline RL settings where the data distribution is fixed?
  - **Basis in paper:** [explicit] The authors state in Section 3.2: "Understanding when the reward is a good predictor of learning useful representations from a given data set (e.g., in offline RL) is an interesting avenue for future work."
  - **Why unresolved:** The theoretical identifiability relies on the policy actively exploring and creating diverse interventions (skills), a condition not guaranteed in static, pre-collected offline datasets.
  - **What evidence would resolve it:** Theoretical analysis or empirical benchmarks demonstrating a strong correlation between the reward signal and representation quality (R2 score) in standard offline RL datasets.

- **Open Question 2:** Do the identifiability guarantees for Contrastive Successor Features (CSF) hold in a broader range of environments beyond the MuJoCo and DeepMind Control tasks tested?
  - **Basis in paper:** [explicit] The Discussion section notes: "It requires further research whether similar results hold in a broader range of scenarios."
  - **Why unresolved:** The current proofs rely on specific structural assumptions (e.g., the VMF distribution of features) which were validated empirically only in the specific continuous control environments studied.
  - **What evidence would resolve it:** Empirical validation of high R2 identifiability scores in visually complex or significantly different domains (e.g., navigation or strategy games) or theoretical extension of the proof to more general dynamics.

- **Open Question 3:** Why does the linear identifiability of feature differences degrade in pixel-based environments compared to state-based observations?
  - **Basis in paper:** [inferred] Section 4 reports that while individual features φ(o) have high R2 scores in pixel-based tasks, the "feature differences exhibit a more moderate linear relationship," deviating from the theoretical guarantee observed in state-based tasks.
  - **Why unresolved:** The theory predicts feature differences should be identifiable up to a linear map (Prop 1), but the pixel-to-state inversion process (encoder g) appears to introduce non-linearities or bottlenecks that affect the difference term specifically.
  - **What evidence would resolve it:** An ablation study analyzing the encoder's capacity or the geometry of the latent space to determine if the issue stems from optimization difficulties or architectural constraints in the pixel-based encoder.

- **Open Question 4:** Is the von Mises-Fisher (vMF) distribution assumption for skill-conditioned features a necessary condition for identifiability, or is it merely a sufficient condition for the current proof?
  - **Basis in paper:** [inferred] The identifiability proof (Theorem 1) relies on Assumption 1(ii), which requires features to follow a vMF distribution. The authors verify this empirically but do not prove if the theory holds if this distributional assumption is relaxed.
  - **Why unresolved:** If the vMF assumption is strict, the applicability of CSF is limited to environments that naturally exhibit this feature distribution, potentially excluding many real-world scenarios.
  - **What evidence would resolve it:** Theoretical derivation showing identifiability under weaker distributional constraints, or empirical results showing high identifiability in environments where the vMF assumption is explicitly violated.

## Limitations

- The theoretical guarantees assume access to the global optimum, which is rarely achieved in practice
- The requirement that latent dimensionality ≥ ground-truth state dimension may limit scalability
- The proofs assume continuous, injective observation generators that may not hold for all environments

## Confidence

- Identifiability up to linear transformation: High
- Skill diversity requirement: High
- Transition-based MI advantage over state-based MI: Medium
- Practical applicability to complex environments: Low-Medium

## Next Checks

1. Test CSF with a finite set of skills (e.g., 5-10) versus continuous sampling to empirically verify the affine generator system requirement
2. Implement the alternative objective I(s; z) and measure feature collapse through visualization of consecutive state embeddings
3. Evaluate CSF performance when using maximum entropy regularization to confirm the theoretical prediction of skill irrelevance