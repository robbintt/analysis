---
ver: rpa2
title: An Empirical Study of Vulnerable Package Dependencies in LLM Repositories
arxiv_id: '2508.21417'
source_url: https://arxiv.org/abs/2508.21417
tags:
- vulnerabilities
- uni00000011
- packages
- supply
- chain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study empirically analyzes vulnerabilities in the dependency
  supply chains of 52 open-source large language models (LLMs). It examines 482 unique
  Python packages used by these models, identifying 890 security vulnerabilities in
  third-party dependencies.
---

# An Empirical Study of Vulnerable Package Dependencies in LLM Repositories

## Quick Facts
- arXiv ID: 2508.21417
- Source URL: https://arxiv.org/abs/2508.21417
- Reference count: 40
- 75.8% of LLMs contain vulnerable dependencies

## Executive Summary
This study empirically analyzes vulnerabilities in the dependency supply chains of 52 open-source large language models (LLMs). It examines 482 unique Python packages used by these models, identifying 890 security vulnerabilities in third-party dependencies. The research finds that 75.8% of LLMs include vulnerable dependencies in their configuration files, with 87.5% of versions in vulnerable packages affected by at least one vulnerability. The analysis reveals that half of vulnerabilities remain undisclosed for over 56.2 months, significantly longer than in the Python ecosystem.

## Method Summary
The study conducted static analysis of 52 open-source LLM repositories, extracting dependencies from configuration files (requirements.txt, setup.py) and import statements. It mapped these dependencies to security records from Snyk.io, analyzing vulnerability prevalence, disclosure timelines, and maintainer responsiveness. The research employed Kaplan-Meier survival analysis to measure vulnerability lifecycles and used regular expressions to identify vulnerability-related pull requests.

## Key Results
- 75.8% of LLMs include vulnerable dependencies in their configuration files
- 87.5% of versions in vulnerable packages are affected by at least one vulnerability
- Half of vulnerabilities remain undisclosed for over 56.2 months
- Only 17.3% of LLM projects actively address vulnerabilities through pull requests
- Machine learning packages account for 91.1% of all reported vulnerabilities

## Why This Works (Mechanism)

### Mechanism 1: Concentration of Risk in Core ML Frameworks
The prevalence of vulnerabilities in LLM repositories appears driven by a dependency on a small number of core machine learning packages with massive attack surfaces. LLMs rely heavily on foundational libraries (e.g., TensorFlow, PyTorch) for tensor operations and optimizations. A single vulnerability in a core package propagates downstream to a majority of LLMs, creating a "choke point" in the supply chain.

### Mechanism 2: Extended Discovery Latency in Complex Codebases
Vulnerabilities in the LLM supply chain likely remain undiscovered for longer periods (56.2 months) compared to the general Python ecosystem due to the complexity of numerical code obscuring security flaws. ML packages often wrap low-level C++/CUDA code for performance, creating a "security blind spot" not present in standard web libraries.

### Mechanism 3: Maintenance Correlation with Popularity
Vulnerability remediation appears to be a function of project popularity; highly starred projects fix dependencies, while less popular projects (and their dependencies) often remain vulnerable. Popular projects attract more contributors and utilize automated tooling, while less popular packages suffer from "abandonware" effects.

## Foundational Learning

- **Concept: Vulnerability Lifecycle (Introduction vs. Disclosure)**
  - Why needed here: To understand that "using the latest version" is insufficient if the vulnerability is 4 years old but only disclosed yesterday.
  - Quick check question: If a dependency has no published CVEs, does that mean it is secure? (Answer: No, it may simply be undiscovered).

- **Concept: CWE (Common Weakness Enumeration) Taxonomy**
  - Why needed here: To prioritize triage. The paper identifies DoS (CWE-400) as the most frequent but RCE (CWE-94) as high priority.
  - Quick check question: Which vulnerability type is most common in the LLM supply chain, and which is most actively patched by maintainers?

- **Concept: Dependency Constraint Resolution (Loose vs. Strict)**
  - Why needed here: To evaluate the trade-off between reproducibility and security.
  - Quick check question: Does setting `package==1.2.3` guarantee the absence of known vulnerabilities?

## Architecture Onboarding

- **Component map:**
  Application Layer (LLM Repo) -> Supply Chain Interface (PyPI) -> Risk Layer (Snyk.io/NVD) -> Mitigation Layer (PRs)

- **Critical path:**
  Vulnerability Introduction (Package Release) -> Discovery (Median 56.2 months later) -> Fix/Disclosure -> Maintainer Awareness -> PR Update (Median 11 days)

- **Design tradeoffs:**
  - Strict Pinning (`==`) vs. Loose Constraints (`>=`): Strict pinning ensures reproducibility but may pin a vulnerable version indefinitely; loose constraints allow updates but risk breaking changes.
  - Popularity vs. Utility: Using niche, low-popularity packages for efficiency introduces higher risk of "Never Fixed" vulnerabilities compared to standard, high-star libraries.

- **Failure signatures:**
  - The "Silent" Vulnerability: A dependency is used for years; it contains a vulnerability that takes 56 months to disclose.
  - The "Unfixed" Dependency: A low-popularity dependency is flagged; maintainers have abandoned the project.

- **First 3 experiments:**
  1. **Time-to-Fix Audit:** Select 10 dependencies from your current LLM project. Check their history: how long did the last 3 CVEs exist in the codebase before discovery?
  2. **Constraint Safety Simulation:** Duplicate `requirements.txt`. In Copy A, loosen all strict pins to `>=`. In Copy B, pin everything to the latest. Scan both with `pip-audit` or `snyk test`.
  3. **Popularity Risk Assessment:** Identify the lowest-starred dependency in your stack. Check the repository's "Last Commit" date and open security issues.

## Open Questions the Paper Calls Out

- To what extent are the identified vulnerable dependencies in LLMs actually exploitable at runtime?
- Can automated dependency recommendation systems tailored to LLMs improve security and stability better than generic tools?
- How effective are proactive monitoring frameworks in reducing the remediation time for vulnerabilities in LLM repositories?

## Limitations
- The sample of 52 LLM repositories may not fully represent the diverse LLM ecosystem
- Reliance on Snyk.io and Libraries.io introduces potential bias from coverage gaps
- The study focuses exclusively on Python packages, potentially missing vulnerabilities in other components

## Confidence
- **High Confidence:** The core finding that 75.8% of LLMs contain vulnerable dependencies
- **Medium Confidence:** The claim about 56.2-month median time-to-disclosure
- **Medium Confidence:** The correlation between popularity and vulnerability fixing

## Next Checks
1. **Temporal Validation:** Re-run the dependency analysis on the same 52 repositories after 6 months to verify stability
2. **Cross-Database Verification:** Validate the 890 vulnerability count by cross-referencing with NVD and GitHub Security Advisories
3. **Constraint Impact Analysis:** Conduct controlled experiments by creating multiple dependency resolution scenarios to quantify security impact differences