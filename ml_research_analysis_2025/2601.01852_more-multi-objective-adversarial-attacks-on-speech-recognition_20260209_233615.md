---
ver: rpa2
title: 'MORE: Multi-Objective Adversarial Attacks on Speech Recognition'
arxiv_id: '2601.01852'
source_url: https://arxiv.org/abs/2601.01852
tags:
- more
- adversarial
- accuracy
- efficiency
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MORE, the first unified adversarial attack
  method that simultaneously targets both accuracy and efficiency in large-scale automatic
  speech recognition (ASR) models like Whisper. MORE uses a hierarchical two-stage
  strategy combining a repulsion stage for accuracy degradation with an anchoring
  stage that employs a novel repetitive encouragement doubling objective (REDO) to
  induce long, structured repetitions in transcriptions.
---

# MORE: Multi-Objective Adversarial Attacks on Speech Recognition

## Quick Facts
- **arXiv ID**: 2601.01852
- **Source URL**: https://arxiv.org/abs/2601.01852
- **Reference count**: 40
- **One-line result**: First method achieving both high WER and 10-14× longer transcriptions in Whisper ASR models

## Executive Summary
MORE introduces a hierarchical two-stage adversarial attack strategy that simultaneously degrades both accuracy and efficiency in large-scale ASR models like Whisper. The method combines a repulsion stage that destabilizes decoding trajectories with an anchoring stage using repetitive encouragement doubling objective (REDO) to induce long, structured repetitions in transcriptions. Experiments demonstrate that MORE consistently generates transcriptions 10-14 times longer than baseline attacks while maintaining high word error rates, effectively revealing dual vulnerabilities in ASR models. The attack increases inference FLOPs by 9-14× compared to normal outputs, quantifying a significant efficiency vulnerability beyond accuracy degradation.

## Method Summary
MORE employs a hierarchical staged optimization approach to craft adversarial perturbations that target both transcription accuracy and efficiency. The method uses a two-stage process: Stage 1 (Repulsion) maximizes cross-entropy loss to destabilize decoding trajectories across many token positions, while Stage 2 (Anchoring) exploits remaining degrees of freedom to extend sequence length while preserving the high error rate established in Stage 1. The anchoring stage uses REDO, which periodically doubles predicted sequence length through a curriculum-style progression, combined with dual EOS suppression that penalizes EOS probability while boosting the second-highest-probability token. The attack operates under ℓ∞ constraints with SNR levels of 30-35 dB, making perturbations generally inaudible while achieving significant attack strength.

## Key Results
- MORE achieves 10-14× longer transcriptions compared to baseline attacks while maintaining WER >90%
- Across Whisper model sizes (tiny to large), MORE increases inference FLOPs by 9-14× compared to normal outputs
- Ablation studies show each component (L_acc, L_EOS, L_REDO) contributes to attack success, with REDO being critical for efficiency gains
- MORE outperforms single-objective attacks and specialized efficiency attacks like SlothSpeech in both accuracy degradation and efficiency impact

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical two-stage optimization prevents gradient competition between accuracy and efficiency objectives, enabling stable multi-objective attacks.
- Mechanism: Stage 1 (repulsion) maximizes cross-entropy loss to destabilize decoding trajectories across many token positions, producing broad gradient coverage. Stage 2 (anchoring) then exploits remaining degrees of freedom to extend sequence length while preserving the high error rate established in Stage 1.
- Core assumption: Accuracy gradients distribute broadly across token positions with relatively large feasible adversarial sets, while efficiency gradients concentrate narrowly around the EOS token with smaller magnitude, causing joint optimization to be unstable.
- Evidence anchors:
  - [abstract]: "hierarchical staged repulsion-anchoring mechanism that sequentially achieves the dual objectives"
  - [Section 3.2]: "Because accuracy gradients are broad and efficiency gradients are sharp and concentrated, combining them in a single-step optimization often causes one objective to dominate. This makes direct multi-objective optimization unstable."
  - [corpus]: Limited corpus evidence; neighboring papers focus on single-objective accuracy attacks, not multi-objective optimization hierarchies.

### Mechanism 2
- Claim: Periodic target sequence doubling (REDO) creates self-reinforcing semantic loops that extend output length more reliably than EOS suppression alone.
- Mechanism: At each period D, REDO performs a greedy decode on the perturbed input, strips the EOS token, duplicates the remaining segment, and optimizes cross-entropy toward this doubled target. Asymmetric interleaving maintains the target fixed within each period (stabilizing short-horizon gradients) while extending it at period boundaries (curriculum-style progression).
- Core assumption: Transformer decoders exhibit self-reinforcing repetition loops—once a high-probability sequence enters the context, its likelihood of being reproduced increases recursively.
- Evidence anchors:
  - [abstract]: "repetitive encouragement doubling objective (REDO) that induces duplicative text generation by periodically doubling predicted sequence length"
  - [Section 3.4]: "Transformer models are known to enter self-reinforcing repetition loops... This recursive amplification leads to a self-sustaining loop of repetition."
  - [Table 3 ablation]: Removing REDO reduces length from 296.66 to 120.67 while WER remains >90, confirming REDO's central role in structured repetition.
  - [corpus]: Paper cites Xu et al. [35] on repetition loops; corpus papers do not address this doubling mechanism directly.

### Mechanism 3
- Claim: Dual EOS suppression—penalizing EOS while boosting the second-highest-probability token—more effectively extends decoding than EOS-only suppression.
- Mechanism: The EOS loss (Eq. 6) minimizes P_EOS while maximizing P_z where z is the token with second-largest probability at the final position. This dual adjustment discourages termination while guiding continued generation toward a specific continuation.
- Core assumption: EOS probability dominates at natural termination points; simply reducing its likelihood is insufficient without actively promoting an alternative path.
- Evidence anchors:
  - [Section 3.4]: "Penalizing only the EOS token is insufficient since its probability is typically dominant at the final decoding step."
  - [Table 3]: Removing L_EOS drops efficiency (296.66 → 233.84), but REDO compensates; removing both REDO and L_EOS collapses efficiency (296.66 → 30.60).
  - [corpus]: Neighboring Whisper attack papers (e.g., "Whisper Smarter, not Harder") focus on suppression mechanisms but not efficiency-oriented EOS manipulation.

## Foundational Learning

- **Autoregressive decoding in transformers**:
  - Why needed here: MORE exploits the causal structure where each predicted token conditions all future predictions. Understanding how EOS token probability controls termination is essential for efficiency attacks.
  - Quick check question: Given a decoder that has generated tokens [y₁, y₂, y₃], how does predicting y₄ affect the distribution over subsequent tokens?

- **Gradient-based adversarial attacks (PGD framework)**:
  - Why needed here: MORE uses projected gradient descent with ℓ∞ constraints to craft perturbations. The staged optimization requires understanding how gradient updates accumulate and when clipping affects search trajectories.
  - Quick check question: Why does PGD use signed gradients (sign(∇δL)) rather than raw gradient values?

- **Cross-entropy as differentiable WER proxy**:
  - Why needed here: L_acc (Eq. 5) uses negative cross-entropy to maximize transcription error. Understanding why CE correlates with WER—and its limitations—is critical for interpreting attack success.
  - Quick check question: If cross-entropy loss decreases but WER increases, what might explain this divergence?

## Architecture Onboarding

- **Component map**: Raw audio X -> perturbation δ (ℓ∞ constrained) -> Stage 1 (K_a PGD steps optimizing L_acc) -> Stage 2 (M blocks of D steps each, alternating greedy decode + REDO + L_EOS) -> adversarial output

- **Critical path**:
  1. Initialize δ ← 0, run K_a repulsion steps
  2. For each Stage 2 block m: decode Ŷ^(m), strip EOS, duplicate → Ȳ^(m)
  3. Within each block, apply L_REDO + L_EOS for D PGD steps
  4. Clip perturbation to [−ϵ, ϵ] after each update

- **Design tradeoffs**:
  - K_a vs (K−K_a): More repulsion steps improve WER stability but reduce budget for efficiency optimization. Paper uses K_a=50, K=10+K_a*(remaining budget implied by total iterations).
  - Doubling period D: Smaller D increases adaptation frequency but introduces higher gradient variance. Paper doesn't explicitly state D value in main text.
  - SNR level: 30dB yields stronger attacks (Table 2) than 35dB (Table 1), but lower SNR reduces imperceptibility.

- **Failure signatures**:
  - WER drops during Stage 2 (e.g., from >90 to ~50) suggests REDO is sacrificing accuracy for efficiency—may need to increase K_a or reduce efficiency weight.
  - Output length plateaus at ~max_seq_len indicates architectural cap rather than attack failure.
  - Repetition patterns become incoherent suggests competing token selection (z in L_EOS) is poorly aligned with context.
  - Clean WER >10% on victim model indicates pre-existing robustness issues that may confound attack attribution.

- **First 3 experiments**:
  1. **Component ablation**: Remove L_acc, L_EOS, and L_REDO individually and jointly (replicating Table 3) to verify each component's contribution and identify which is rate-limiting.
  2. **Model scaling sensitivity**: Test across Whisper tiny→large to determine if efficiency gains scale with model size or diminish due to increased robustness (Table 1 shows MORE maintains ~10-14× length increase across sizes).
  3. **SNR threshold analysis**: Sweep SNR from 25dB to 40dB to identify the perceptibility-attack-strength frontier; plot WER and length vs. SNR to find practical operating points.

## Open Questions the Paper Calls Out

- **Question**: What defense mechanisms can effectively mitigate MORE-style multi-objective attacks while preserving ASR accuracy?
- **Basis in paper**: [explicit] Ethics Statement: "We will explore some targeting defense mechanisms against MORE in future work."
- **Why unresolved**: The paper proposes defenses conceptually (repetition/loop detectors, band-limiting, adversarial training on EOS/repetition pathologies) but provides no experimental validation of any specific defense.
- **What evidence would resolve it**: Empirical evaluation of candidate defenses (e.g., repetition detection thresholds, spectral filtering, adversarial fine-tuning) measuring both WER preservation and reduction in induced output length under MORE attacks.

## Limitations

- **Gradient Stability Analysis Gap**: The paper claims hierarchical staging is necessary because "combining them in a single-step optimization often causes one objective to dominate," yet the specific gradient magnitude ratios or optimization dynamics that trigger this instability are not quantified.

- **REDO Period Sensitivity**: The doubling period D is mentioned as critical for curriculum progression but its exact value is not specified in the main text, and the ablation studies don't explore how different D values affect attack success rate.

- **Architecture Transferability**: The paper only tests Whisper models with greedy decoding, and neighboring work suggests alternative ASR designs may resist such repetition loops through explicit penalties or beam search constraints, but this is not evaluated.

## Confidence

**High Confidence** - The staged optimization framework is novel and the experimental results showing 9-14× inference FLOPs increase with maintained high WER are reproducible. The ablation studies (Table 3) clearly demonstrate each component's contribution, and the implementation details are sufficiently specified for reproduction.

**Medium Confidence** - The claimed mechanism that accuracy and efficiency gradients have fundamentally different distributions (broad vs. sharp) causing joint optimization instability. While intuitive and supported by the staged approach's success, direct gradient analysis comparing joint vs. staged optimization is not provided.

**Low Confidence** - The generality of REDO's self-reinforcing repetition mechanism across different ASR architectures and decoding strategies. The paper only tests Whisper models with greedy decoding, and neighboring work suggests alternative ASR designs may resist such repetition loops through explicit penalties or beam search constraints.

## Next Checks

1. **Gradient Distribution Analysis** - Implement joint optimization (L_acc + L_eff in single PGD loop) alongside the staged approach on the same samples. Compare gradient norms, distributions, and convergence trajectories to empirically validate whether accuracy and efficiency gradients are indeed incompatible in joint optimization.

2. **REDO Period Sensitivity Sweep** - Systematically vary the doubling period D from 5 to 50 steps while measuring output length, WER stability, and convergence speed. Plot efficiency vs. accuracy trade-offs across different D values to identify optimal period selection and test the claim that "curriculum-style progression" improves stability.

3. **Architecture Transferability Test** - Apply MORE to non-Whisper ASR models (e.g., DeepSpeech, Wav2Vec2) and decoding strategies (beam search with length normalization). Measure whether the 9-14× efficiency gains and high WER maintenance transfer across architectures, or whether certain components (particularly REDO) are Whisper-specific.