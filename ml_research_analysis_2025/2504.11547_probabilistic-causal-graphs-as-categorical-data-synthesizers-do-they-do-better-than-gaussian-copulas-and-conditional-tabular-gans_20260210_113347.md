---
ver: rpa2
title: 'Probabilistic causal graphs as categorical data synthesizers: Do they do better
  than Gaussian Copulas and Conditional Tabular GANs?'
arxiv_id: '2504.11547'
source_url: https://arxiv.org/abs/2504.11547
tags:
- data
- synthetic
- such
- disability
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates methods for generating synthetic categorical
  data, focusing on privacy preservation and capturing causal relationships. It compares
  a Structural Equation Modeling (SEM)-based Bayesian Network (BN) approach against
  Gaussian Copula and Conditional Tabular GAN (CTGAN) methods using accessibility
  barrier data for people with disabilities.
---

# Probabilistic causal graphs as categorical data synthesizers: Do they do better than Gaussian Copulas and Conditional Tabular GANs?

## Quick Facts
- arXiv ID: 2504.11547
- Source URL: https://arxiv.org/abs/2504.11547
- Authors: Olha Shaposhnyk; Noor Abid; Mouri Zakir; Svetlana Yanushkevich
- Reference count: 32
- Primary result: BN achieved TVD of 0.9979, outperforming Gaussian Copula (0.976) and CTGAN (0.90-0.92)

## Executive Summary
This study compares three methods for generating synthetic categorical data while preserving privacy and capturing causal relationships. The Structural Equation Modeling (SEM)-based Bayesian Network approach outperformed Gaussian Copula and Conditional Tabular GAN methods using accessibility barrier data for people with disabilities. The BN model achieved superior Total Variation Distance (TVD) scores and preserved statistical properties across multiple metrics including Chi-square tests, KL divergence, and entropy/mutual information. The research demonstrates that explicitly modeling variable dependencies through directed acyclic graphs produces higher-quality synthetic data than implicit dependency learning methods.

## Method Summary
The study evaluates three synthetic data generation methods on categorical accessibility barrier data: a SEM-based Bayesian Network approach, Gaussian Copula, and Conditional Tabular GAN (CTGAN). The BN method defines causal structures through expert knowledge and SEM validation, estimates conditional probability tables from original data, and generates samples via ancestral sampling. The Gaussian Copula transforms marginals to uniform space, models dependencies in Gaussian copula space, then inverse-transforms back. CTGAN uses adversarial training with mode-specific normalization for categorical data. All methods were evaluated on TVD, Chi-square tests, KL divergence, entropy, and mutual information preservation metrics.

## Key Results
- BN achieved highest TVD of 0.9979, indicating superior statistical alignment with original data
- Gaussian Copula ranked second with TVD of 0.976
- CTGAN exhibited moderate performance with TVD of 0.90-0.92
- All methods preserved statistical properties and relationships while maintaining confidentiality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Explicitly modeling variable dependencies via directed acyclic graphs produces synthetic categorical data that better preserves joint distributions than implicit dependency learning.
- Mechanism: The SEM-based BN approach first defines a causal structure where nodes represent variables and edges encode conditional dependencies (e.g., demographics → disability type → barriers). CPTs are then populated from original data. Synthetic samples are generated by ancestral sampling: drawing from prior distributions (root nodes) then propagating through conditional distributions downstream.
- Core assumption: The true dependency structure among variables can be approximated by a DAG, and expert knowledge plus SEM validation yields a structure sufficiently close to ground truth.
- Evidence anchors:
  - [abstract] "The proposed method outperformed others in statistical metrics...BN model demonstrated superior performance, achieving the highest TVD"
  - [Section 5] "Our BN model demonstrated the highest TVD of 0.9979...This suggests that the data generated by the BN is both statistically significant and highly similar to the observed data"
  - [corpus] Weak direct evidence—neighbors focus on causal discovery rather than synthesis; no comparable BN-to-copula/GAN benchmarks found
- Break condition: If the true causal structure contains cycles, latent confounders not modeled as nodes, or dependencies that require higher-order interactions (beyond pairwise parent-child), the DAG assumption fails and synthesized distributions will diverge.

### Mechanism 2
- Claim: Gaussian Copula captures multivariate dependencies through rank correlation preservation but underperforms on categorical data where marginal distributions are discrete and non-Gaussian.
- Mechanism: Copula methods transform each marginal to uniform via empirical CDF, model dependencies in the Gaussian copula space, then inverse-transform back. For categorical variables, this requires binning or ordinal encoding, which can distort true category boundaries and conditional relationships.
- Core assumption: Dependencies can be adequately captured by a global correlation structure in latent Gaussian space.
- Evidence anchors:
  - [abstract] "Gaussian Copula ranked second" with TVD of 0.976 vs BN's 0.9979
  - [Section 4.2.1] "Gaussian Copula generates synthetic data by modelling the relationships between variables using a statistical model that describes dependencies between variables in a multi-dimensional space"
  - [corpus] No corpus papers directly compare copula to BN for categorical synthesis
- Break condition: When categorical variables have many levels or highly skewed marginals, the uniform transformation introduces artifacts, and the copula's global correlation structure cannot capture local conditional dependencies.

### Mechanism 3
- Claim: CTGAN's mode collapse and training instability limit its effectiveness for small categorical datasets with complex conditional dependencies.
- Mechanism: CTGAN uses a generator-discriminator adversarial game to learn data distributions. For tabular categorical data, it applies mode-specific normalization and conditional sampling. However, adversarial training is sensitive to hyperparameters (epochs, batch size, learning rate) and can overfit or fail to converge.
- Core assumption: The generator can learn an implicit density function that matches the true joint distribution through gradient-based optimization alone.
- Evidence anchors:
  - [abstract] "CTGAN exhibited moderate performance" (TVD 0.90-0.92)
  - [Section 5] "performance slightly declined at epoch 500, suggesting potential overfitting"
  - [corpus] No direct corpus evidence on CTGAN limitations specifically for categorical synthesis
- Break condition: If dataset size is insufficient for deep learning (paper uses 54,000 samples but focuses on a subset), or if categorical dependencies are highly structured in ways adversarial training cannot easily capture from implicit density learning, CTGAN underperforms.

## Foundational Learning

- Concept: **Conditional Probability Tables (CPTs) and Joint Distribution Factorization**
  - Why needed here: BN synthesis relies on the chain rule P(X₁,...,Xₙ) = ∏P(Xᵢ|Parents(Xᵢ)). Without understanding how CPTs encode local dependencies, you cannot debug why synthetic data fails to preserve correlations.
  - Quick check question: Given a simple 3-node BN (A→B→C), write the joint distribution and explain how you'd sample a synthetic record.

- Concept: **Total Variation Distance (TVD)**
  - Why needed here: TVD is the primary evaluation metric. A TVD close to 1 indicates synthetic and real distributions are nearly identical; this guides method selection.
  - Quick check question: If two distributions have TVD = 0.5, what is the maximum difference in probability for any single category?

- Concept: **Mutual Information for Dependency Preservation**
  - Why needed here: Beyond marginal distribution matching, the paper uses MI to verify that variable relationships are preserved in synthetic data.
  - Quick check question: If MI(synthetic) ≈ MI(real) for all variable pairs, does this guarantee the joint distribution is preserved? Why or why not?

## Architecture Onboarding

- Component map: Demographics → Disability Type → Barriers (example BN structure)

- Critical path:
  1. Preprocess raw survey data → normalized tabular format
  2. Define BN structure (iterative: expert → SEM validation → refine)
  3. Estimate CPTs from original data
  4. Generate synthetic samples via ancestral sampling
  5. Evaluate TVD; if < 0.95, revisit structure or preprocessing

- Design tradeoffs:
  - **BN vs Copula**: BN requires upfront structure definition (higher effort) but yields better TVD; Copula is automated but assumes Gaussian latent dependencies
  - **Expert-informed vs learned structure**: Paper uses expert + SEM; fully data-driven structure learning may miss domain-relevant edges
  - **Privacy (epsilon) vs fidelity**: Lower epsilon in differential privacy modes reduces TVD; paper finds epsilon=5-10 balances both for correlated mode

- Failure signatures:
  - TVD < 0.90: Likely incorrect structure or insufficient CPT samples for rare categories
  - Chi-square p-value < 0.05: At least one column distribution significantly differs; check preprocessing
  - High variance across CTGAN runs: Training instability; reduce learning rate or increase batch size

- First 3 experiments:
  1. Replicate BN synthesis on the provided dataset (GitHub available), verify TVD matches 0.9979
  2. Ablate structure: remove one edge (e.g., gender→disability) and measure TVD drop to quantify dependency contribution
  3. Test BN on a different categorical dataset (e.g., UCI adult census) to assess generalization beyond accessibility domain

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does the SEM-based Bayesian Network approach resist privacy attacks (e.g., re-identification or inference attacks) compared to deep learning methods like CTGAN?
- Basis in paper: [inferred] The abstract and introduction emphasize privacy preservation and confidentiality as primary goals ("maintaining confidentiality," "safeguarding participant information"). However, the evaluation metrics (Chi-square, KL divergence, TVD) exclusively measure statistical fidelity and distributional alignment, with no reported metrics for privacy risk or anonymity guarantees.
- Why unresolved: The paper concludes that the method preserves confidentiality, but this claim is supported solely by the statistical similarity of the data rather than a quantitative privacy analysis.
- What evidence would resolve it: Results from privacy attack simulations (such as singling out, linkability, or inference attacks) or formal privacy metrics (e.g., epsilon for differential privacy) applied to the synthetic data generated by the BN model.

### Open Question 2
- Question: Does the SEM-based Bayesian Network maintain its performance advantage over CTGAN and Gaussian Copulas when applied to high-dimensional datasets?
- Basis in paper: [inferred] The authors note in the Methodology section that "the current study focuses only on interaction barriers to simplify our network," implying the tested model was structurally simplified.
- Why unresolved: While BNs performed best on this specific dataset, they suffer from computational complexity as the number of nodes and edges increases (the "curse of dimensionality"). It is unclear if this approach is feasible or superior for datasets with hundreds of variables compared to scalable deep learning methods.
- What evidence would resolve it: A comparative analysis of performance and computational cost using datasets with significantly higher dimensionality and more complex dependency structures.

### Open Question 3
- Question: Can the causal structure of the Bayesian Network be learned effectively without manual expert intervention while still outperforming automated generative models?
- Basis in paper: [inferred] The methodology states that the BN structure was "defined based on expert knowledge" and "iteratively employed," whereas the competing CTGAN and Copula models appear to be applied as automated, off-the-shelf solutions.
- Why unresolved: The superior performance of the BN may be partially attributable to the injection of domain expertise (human-in-the-loop) rather than the generative algorithm itself. It is not tested whether an automatically learned BN structure would yield the same high-fidelity results.
- What evidence would resolve it: An experiment comparing the proposed expert-validated BN against a BN with a structure learned purely from data (structure learning algorithms) on the same fidelity metrics.

## Limitations
- Structural assumption dependency: The BN approach's superiority relies on accurate DAG specification, which may not capture real-world cycles or latent confounders
- Dataset specificity: All evaluations use accessibility barrier data from a single population, limiting generalizability to different domains
- Privacy quantification gap: The paper claims confidentiality preservation but lacks formal privacy metrics or attack resistance evaluation

## Confidence

- **BN mechanism superiority (High)**: TVD metric (0.9979 vs 0.976/0.90-0.92) provides strong quantitative evidence with ablation analysis supporting the mechanism
- **Copula limitation explanation (Medium)**: TVD ranking supports the claim, but lacks direct evidence comparing copula's performance on continuous vs categorical transformations
- **CTGAN training issues (Medium)**: Performance decline at epoch 500 suggests overfitting, but without learning curves or hyperparameter sensitivity analysis, the mechanism remains incompletely characterized

## Next Checks

1. **Structure sensitivity test**: Systematically remove 2-3 edges from the BN structure and measure TVD degradation to quantify dependency contribution

2. **Cross-domain replication**: Apply the BN approach to a UCI repository categorical dataset (e.g., Adult income prediction) with ≥50k samples and compare TVD against CTGAN/Copula baselines

3. **Privacy robustness evaluation**: Conduct membership inference attacks on both original and synthetic accessibility data to quantify actual privacy leakage versus claimed confidentiality preservation