---
ver: rpa2
title: Vector Ontologies as an LLM world view extraction method
arxiv_id: '2506.13252'
source_url: https://arxiv.org/abs/2506.13252
tags:
- genre
- vector
- space
- ontology
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces vector ontologies as a method to extract and
  interpret Large Language Models' internal world models. The authors construct an
  8-dimensional vector ontology of musical genres based on Spotify audio features
  and test whether an LLM's internal model of music can be projected into this space.
---

# Vector Ontologies as an LLM world view extraction method

## Quick Facts
- arXiv ID: 2506.13252
- Source URL: https://arxiv.org/abs/2506.13252
- Reference count: 1
- The paper introduces vector ontologies as a method to extract and interpret Large Language Models' internal world models

## Executive Summary
This paper introduces vector ontologies as a novel method to extract and interpret Large Language Models' internal world models. The authors construct an 8-dimensional vector ontology of musical genres based on Spotify audio features and test whether an LLM's internal model of music can be projected into this space. Using GPT-4o-mini, they analyze genre representations across 47 query formulations to demonstrate that LLMs internalize structured, repurposable knowledge.

The study demonstrates that vector ontologies offer a promising approach for extracting and analyzing LLM knowledge in a transparent and verifiable way. The methodology shows high spatial consistency of genre projections, strong alignment between LLM-inferred genre locations and real-world audio feature distributions, and evidence of a direct relationship between prompt phrasing and spatial shifts in the LLM's inferred vector ontology.

## Method Summary
The authors construct an 8-dimensional vector ontology of musical genres using Spotify's audio features: acousticness, danceability, energy, instrumentalness, liveness, speechiness, valence, and tempo. They test whether an LLM's internal model of music can be projected into this space using GPT-4o-mini to analyze genre representations across 47 different query formulations. The methodology compares the LLM's genre representations against ground truth audio feature distributions and random baselines to validate spatial consistency and alignment.

## Key Results
- High spatial consistency of genre projections (average centroid distance 0.156 vs. random baseline 0.765)
- Strong alignment between LLM-inferred genre locations and real-world audio feature distributions (mean Euclidean distance 0.46)
- Evidence of direct relationship between prompt phrasing and spatial shifts in the LLM's inferred vector ontology

## Why This Works (Mechanism)
Vector ontologies work by mapping LLM-generated genre representations into a pre-defined multi-dimensional feature space. The method leverages the LLM's inherent ability to organize and relate concepts, then projects these relationships onto an interpretable vector space based on established audio features. By analyzing how the LLM positions genres within this space across different prompts, researchers can extract structured knowledge about how the model understands relationships between concepts.

## Foundational Learning
**Multi-dimensional vector spaces**: Why needed - To represent complex relationships between musical genres; Quick check - Can be visualized and analyzed using standard vector operations
**Audio feature extraction**: Why needed - Provides objective ground truth for genre characteristics; Quick check - Spotify's features are widely accepted in music analysis
**Prompt engineering**: Why needed - Different phrasings reveal how LLM's internal representations shift; Quick check - Consistency across multiple prompt formulations validates results

## Architecture Onboarding
**Component map**: LLM output -> Genre feature vector extraction -> 8D vector space projection -> Spatial analysis -> Ground truth comparison
**Critical path**: Prompt generation → LLM response → Feature extraction → Vector projection → Spatial consistency validation
**Design tradeoffs**: Using predefined audio features provides interpretability but may miss semantic relationships the LLM captures; focusing on music limits generalizability but enables ground truth validation
**Failure signatures**: Inconsistent genre positioning across prompts, large distances from ground truth audio features, poor spatial clustering
**First experiments**: 1) Test with different LLM architectures to verify method generalizability; 2) Apply to non-musical domains with established feature spaces; 3) Conduct cross-linguistic validation

## Open Questions the Paper Calls Out
None

## Limitations
- Constrained scope to musical genres may not generalize to more complex knowledge domains
- Reliance on GPT-4o-mini raises questions about replicability across different LLM architectures
- Methodology assumes Spotify's audio features represent ground truth, which may not align with cultural understandings

## Confidence
- High confidence: LLMs produce spatially consistent genre representations within defined vector space
- Medium confidence: Relationship between prompt phrasing and spatial shifts in LLM's inferred vector ontology
- Medium confidence: Alignment between LLM-inferred genre locations and real-world audio feature distributions

## Next Checks
1. Replicate the study using multiple LLM architectures (different providers, model sizes) to assess generalizability of vector ontology extraction
2. Test the methodology on a non-musical domain with established multi-dimensional feature spaces (e.g., medical diagnoses, product attributes)
3. Conduct cross-linguistic validation by testing whether the same vector ontology can be extracted from the same LLM using prompts in different languages