---
ver: rpa2
title: 'ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to
  Outliers'
arxiv_id: '2510.09852'
source_url: https://arxiv.org/abs/2510.09852
tags:
- query
- queries
- routing
- cost
- router
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the challenge of routing language queries to\
  \ the most suitable LLM in a diverse model pool, with the goal of maximizing accuracy\
  \ while minimizing cost. Traditional nonparametric routers like KMeans and kNN struggle\
  \ with generalization to outlier queries\u2014those that differ significantly from\
  \ training data\u2014due to rigid assignment rules and uniform weighting."
---

# ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers

## Quick Facts
- **arXiv ID**: 2510.09852
- **Source URL**: https://arxiv.org/abs/2510.09852
- **Reference count**: 40
- **Primary result**: ProxRouter improves robustness to outlier queries in LLM routing by 8.1 percentage points over kNN-Base on math tasks, approaching the performance of an all-knowledge "AllSee" router.

## Executive Summary
This paper introduces ProxRouter, a novel nonparametric query routing method that improves LLM routing robustness to outlier queries without explicit outlier detection. The approach generalizes traditional KMeans and kNN routers by applying proximity-weighted aggregation over reference clusters or neighbors, using an exponential tilt based on similarity to test queries. Experiments across 14 LLMs and 10 datasets demonstrate significant improvements in routing accuracy for outlier queries while maintaining performance on inliers, with only millisecond-level overhead.

## Method Summary
ProxRouter computes minimum-variance priors over reference clusters or neighbors, then applies an exponential tilt based on proximity to test queries to reduce bias. For each query, it calculates weighted averages of model objective estimates from all reference elements (clusters or neighbors), where weights are higher for elements closer to the test query in embedding space. The method balances bias and variance through a tunable temperature parameter τ, allowing optimal performance on both inlier and outlier queries. ProxRouter requires no explicit outlier detection and applies the same soft aggregation strategy to all queries.

## Key Results
- kNN-Prox improves AUC by 8.1 percentage points over kNN-Base on math outlier tasks
- KM-Prox increases AUC by up to 4.4 points over KM-Base across various datasets
- Performance approaches that of an all-knowledge "AllSee" router with only millisecond-level overhead
- ProxRouter maintains strong performance on inlier queries while significantly improving outlier robustness

## Why This Works (Mechanism)

### Mechanism 1: Proximity-Weighted Soft Aggregation Over Reference Elements
- Claim: Soft, proximity-weighted aggregation over reference clusters or neighbors provides more robust estimates of model performance for outlier queries compared to hard assignments.
- Mechanism: Instead of assigning a query to a single closest cluster or uniformly over the k-nearest neighbors, ProxRouter computes a weighted average of estimates from all reference elements (clusters or neighbors), where weights are higher for elements closer to the test query in embedding space. This is achieved via an "exponentially tilted" weighting scheme derived from a minimum-variance prior.
- Core assumption: Outlier queries, while not identical to training queries, still share some latent characteristics with the training distribution. There is a meaningful distance metric in the embedding space where closer training points provide less biased (though potentially higher variance) estimates of model performance for the test query.
- Evidence anchors:
  - [abstract]: "It applies an exponentially tilted weighting scheme to combine reference cluster or neighbor estimates based on their similarity to the test query, improving robustness to outliers without requiring explicit outlier detection."
  - [section 3]: "ProxRouter does not require any outlier detection and its associated overhead, since it applies the soft aggregation to all queries, both inliers and outliers."
  - [corpus]: The related paper "Rerouting LLM Routers" discusses router adaptability, but does not provide specific evidence for this soft aggregation mechanism. Evidence is weak/missing.
- Break condition: If the embedding space distance metric does not correlate with task similarity or model performance, or if an outlier query is so distant from all training data that no reference element provides useful information (query is in a completely new semantic void), this mechanism will fail, reverting to a biased, high-variance estimate.

### Mechanism 2: Bias-Variance Trade-off Control via a Tunable Temperature Parameter
- Claim: Controlling the weighting scheme with a single temperature parameter (τ) allows the router to navigate the bias-variance trade-off, finding an optimal balance for robust routing.
- Mechanism: The aggregation weights are computed as $w_i(x) \propto p_i(x) \exp(-\phi_i(x)/\tau)$, where $p_i(x)$ are minimum-variance priors and $\phi_i(x)$ is a proximity penalty. A small τ (strong proximity weighting) reduces bias by favoring close reference elements, while a large τ (weak proximity weighting) increases the influence of variance-reducing priors. The optimal τ is found via tuning on a held-out set.
- Core assumption: There exists an optimal point on the bias-variance curve that yields the lowest mean squared error for the model objective estimator. The relationship between distance in the embedding space and the bias of the estimate is monotonic.
- Evidence anchors:
  - [abstract]: "...balance bias and variance in nonparametric routers."
  - [section 3.2]: "This framework provides a controllable bias–variance tradeoff: increasing τ drives the weights toward the low-variance priors p(x), while decreasing τ emphasizes proximity..."
  - [Figure 4 caption]: "Bias-variance tradeoff governed by proximity based prioritization... Optimal router performance typically achieved at an intermediate value 1/τ*."
  - [corpus]: No direct corpus evidence for this specific temperature-based trade-off mechanism.
- Break condition: If the bias-variance trade-off is not the primary factor in routing error for a given dataset, or if the optimal τ is highly sensitive to the specific distribution of queries (e.g., changes drastically over time), a single static τ value will be suboptimal.

### Mechanism 3: Variance Reduction via Least-Variance Priors
- Claim: Initializing the weighting scheme with variance-aware priors based on the characteristics of reference elements reduces the variance of the final objective estimate.
- Mechanism: For clustering-based routers, priors $p_i(x)$ are inversely proportional to the estimated variance of the cluster's summary ($\propto n_i / s_i$, where $n_i$ is cluster size and $s_i$ is its spread). For kNN-based routers, uniform priors over the k-nearest neighbors are used as a baseline. These priors are then re-weighted by proximity.
- Core assumption: Clusters with more points and less internal spread (compactness) provide more reliable (lower variance) estimates of model performance. The variance of an estimate from a reference element is a key component of its uncertainty and error.
- Evidence anchors:
  - [abstract]: "...balance bias and variance..."
  - [section 3.1]: "The optimal least variance estimator weights (priors) p(x) are of the form of p_i(x) ∝ (Var[V_i^(m)])^-1. ... Intuitively, clusters that are more geometrically dispersed contain semantically diverse queries, implying that Var[V_i^(m)] within such clusters is larger..."
  - [corpus]: No corpus evidence found for this specific variance-prior formulation.
- Break condition: If the heuristic used to estimate variance (cluster size/spread) is a poor proxy for the actual variance of model performance within that cluster, the priors will be misleading and could increase overall estimation error.

## Foundational Learning

- Concept: **Bias-Variance Trade-off**
  - Why needed here: The paper explicitly formulates ProxRouter as a method to balance the bias and variance of model performance estimates. Understanding this fundamental statistical concept is essential to grasp why a simple proximity weighting isn't enough and why a tunable temperature parameter (τ) is required.
  - Quick check question: Explain how decreasing the temperature parameter τ in ProxRouter affects the bias and variance of the model objective estimate and why an intermediate value is often optimal.

- Concept: **K-Means Clustering and k-Nearest Neighbors (kNN)**
  - Why needed here: ProxRouter is presented as a generalization of these two standard nonparametric routing baselines (KM-Base and kNN-Base). The entire proposed method is built as a modification to their aggregation strategy.
  - Quick check question: In a standard kNN router, how are weights typically assigned to the k-nearest neighbors? What is the key change ProxRouter introduces to this scheme?

- Concept: **LLM Query Routing & Embedding Spaces**
  - Why needed here: This is the problem domain. One must understand that the goal is to select a model from a pool to maximize an objective (accuracy - λ * cost) for a given query. All operations (clustering, finding neighbors) happen in a fixed-dimensional embedding space generated by a sentence encoder.
  - Quick check question: Why do nonparametric routers rely on a sentence encoder, and why is the quality of the embedding space's distance metric critical to their success?

## Architecture Onboarding

- Component map:
  1. Sentence Encoder: (e.g., MPNet-base) Maps an input text query to a fixed-dimensional vector (x) in the embedding space.
  2. Reference Set (`I`): The pre-computed dataset containing reference vectors (`r_i`, e.g., cluster centroids or individual training query embeddings) and their associated model objective values (`V_i^(m)`).
  3. Prior Calculator: Computes initial low-variance prior weights (`p_i(x)`) for each reference element based on variance proxies (e.g., cluster size/spread).
  4. Proximity Penalty & Tilt: Calculates a proximity penalty `ϕ_i(x)` (based on distance, e.g., cosine distance) for each reference element and applies the exponential tilt using the temperature parameter τ to get intermediate intensities `θ_i(x)`.
  5. Weight Normalizer: Normalizes `θ_i(x)` to get final aggregation weights `w_i(x)`.
  6. Objective Estimator: Computes the final estimated model objective `bU^(m)(x)` for each model `m` using the weighted sum of reference values `V_i^(m)`.
  7. Model Selector: Selects the model `m*` with the highest estimated objective `bU^(m)(x)`.

- Critical path:
  1. **Ingest Query**: Receive a new text query.
  2. **Embed**: Generate its embedding `x` using the chosen sentence encoder.
  3. **Score Proximity**: Calculate distances (e.g., cosine) from `x` to all reference vectors `r_i` in `I`.
  4. **Compute Weights**: Apply the ProxRouter formula: for each reference element, compute its prior weight, apply the exponential tilt based on its distance, and normalize to get final weights `w_i`.
  5. **Aggregate Estimates**: For each model `m` in the pool, compute a single estimated objective value by taking the weighted sum of the reference values `V_i^(m)` using the computed `w_i`.
  6. **Select & Route**: Identify the model `m*` with the highest aggregated objective and route the query to it.

- Design tradeoffs:
  - **τ (temperature) value**: Low τ = more emphasis on proximity (potentially lower bias, higher variance). High τ = more reliance on variance-reducing priors (potentially higher bias, lower variance). Requires tuning.
  - **Reference set granularity**:
    - For clustering (KM-Prox): Fewer clusters (low K) means larger, lower-variance clusters but potentially higher bias for outlier queries. More clusters (high K) means finer-grained estimates but higher variance.
    - For kNN (kNN-Prox): Fewer neighbors (low k) yields lower variance but may miss relevant information. More neighbors (high k) increases the effective sample size but may introduce more distant, less relevant points. ProxRouter aims to make this less brittle.
  - **Encoder Choice**: The entire method depends on the quality of the embedding space. A poor encoder (where semantic similarity doesn't map to embedding proximity) will cause the proximity weighting to fail. The paper notes performance is relatively unaffected by encoder choice among those tested.

- Failure signatures:
  - **Catastrophic Drop on New Outlier Type**: The outlier query falls into a region of the embedding space that is effectively equidistant from all training reference points, or where the embedding distance is not meaningful. The resulting weights become near-uniform, providing no more information than a random guess.
  - **Inlier Performance Degradation**: An improperly tuned τ (too small, for instance) might overemphasize a single very close but noisy training neighbor, leading to high variance and poor routing on in-distribution queries.
  - **No Improvement Over Base**: This suggests either the τ is not tuned correctly, or the training data is so unrepresentative that the base router's hard decisions were already the best possible low-variance choice.

- First 3 experiments:
  1. **Establish Baselines**: Implement and benchmark KM-Base and kNN-Base routers on a test set with a held-out outlier task (e.g., MedQA as outlier). Measure AUC of the accuracy-cost curve for both inlier and outlier queries. This establishes the performance gap ProxRouter aims to close.
  2. **Tune Temperature (τ)**: On a validation set that mimics the expected inlier/outlier split, run a sweep over different values of τ (e.g., 1/τ from 1 to 50). Plot the resulting AUC to find the optimal bias-variance balance point, as suggested by Figure 4 in the paper.
  3. **Compare ProxRouter to AllSee**: Implement KM-Prox and kNN-Prox using the tuned τ. Compare their performance (AUC on inliers, outliers, and overall) against the "AllSee" upper-bound router trained on all tasks. This quantifies how much of the performance gap ProxRouter closes, as shown in Tables 2 and 3.

## Open Questions the Paper Calls Out

- Can the ProxRouter framework be effectively extended to advanced nonparametric methods like fuzzy clustering, spectral clustering, or kernel smoothing?
  - Basis in paper: [explicit] The Conclusion and Appendix A explicitly state that "exploring connections to advanced statistical techniques remains a promising direction" and that future work may consider extending the approach beyond the simplified KMeans and kNN implementations focused on in the study.
  - Why unresolved: The authors deliberately restricted the scope to simple KMeans and kNN routers to prove the concept of proximity-weighting, leaving the integration with more complex statistical techniques untested.
  - What evidence would resolve it: Experiments applying the exponential tilting mechanism to fuzzy or spectral routers, demonstrating comparable or improved AUC gains on outlier tasks relative to the baseline implementations.

- How can a precise cost-aware policy be formulated to trigger router retraining based on the Jaccard overlap metric?
  - Basis in paper: [explicit] Section 4.2 discusses using the Jaccard similarity of top-z models ($J_z^\lambda$) to detect train-test mismatches but notes that "The choice of threshold can be determined by a cost-aware policy," implying the specific logic remains undefined.
  - Why unresolved: While the paper proposes the metric to detect distribution shift, it does not define the decision boundary or the policy required to balance the high cost of evaluating queries on all models against the risk of routing degradation.
  - What evidence would resolve it: A defined policy function (e.g., a threshold optimization algorithm) and an empirical analysis of the trade-off between the frequency of retraining and the cumulative inference cost/accuracy over time.

- Does replacing the heuristic variance priors with ground-truth variance estimates significantly improve the robustness of the router?
  - Basis in paper: [inferred] Section 3.1 notes that exact per-query variance is unknown in practice, forcing the use of heuristics (cluster spread for KMeans) or uniform priors (for kNN).
  - Why unresolved: The paper assumes these heuristics are sufficient proxies for the "least variance priors," but it is untested whether the router's performance is fundamentally limited by the noise in these variance estimates.
  - What evidence would resolve it: Ablation studies comparing the current heuristic-based weights against weights derived from repeated sampling to establish the theoretical performance ceiling of the variance reduction component.

## Limitations

- The effectiveness of ProxRouter critically depends on the existence of a meaningful distance metric in the embedding space. If the sentence encoder fails to map semantically similar queries to proximate vectors, the proximity weighting will be ineffective, rendering the entire approach equivalent to a baseline uniform-weight router.
- The paper's experimental design assumes outlier queries are identifiable by a held-out dataset, but real-world deployment may involve more subtle or gradual distributional shifts that are harder to characterize. The method's performance on these "gray area" queries is not fully explored.
- While ProxRouter improves robustness without explicit outlier detection, the need to tune the temperature parameter τ on a held-out set is a form of implicit model selection that could be a bottleneck in dynamic environments where the inlier/outlier distribution changes frequently.

## Confidence

- **High Confidence**: The core mathematical formulation of the proximity-weighted aggregation and its derivation as a minimum-variance estimator is sound and well-defined.
- **Medium Confidence**: The experimental results showing consistent AUC improvements on both inlier and outlier tasks across multiple datasets and model pools. However, the absolute magnitude of the improvement and its generalizability to entirely unseen domains would benefit from further validation.
- **Medium Confidence**: The claim that the method is robust to the choice of sentence encoder. While tested on a few encoders, the space of possible encoders and their training objectives is vast.

## Next Checks

1. **Embedding Space Quality Audit**: Conduct a controlled experiment where the sentence encoder is deliberately trained or chosen to produce embeddings where semantic similarity does not correlate with embedding proximity (e.g., a random rotation). Measure ProxRouter's performance collapse to quantify the method's dependence on encoder quality.

2. **Dynamic Distribution Test**: Simulate a realistic deployment scenario where the inlier/outlier ratio changes over time. Implement an online version of ProxRouter that periodically re-tunes τ and compare its performance to a static version. This will reveal the practical limitations of the current fixed-parameter design.

3. **Gray Area Query Analysis**: Construct a dataset of queries that are neither clear inliers nor clear outliers (e.g., queries that are semantically related to training data but use different phrasing or domain-specific jargon). Analyze how ProxRouter's soft aggregation performs on this ambiguous set compared to the hard assignments of the baseline routers.