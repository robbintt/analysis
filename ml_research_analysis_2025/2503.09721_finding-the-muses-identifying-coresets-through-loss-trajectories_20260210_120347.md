---
ver: rpa2
title: 'Finding the Muses: Identifying Coresets through Loss Trajectories'
arxiv_id: '2503.09721'
source_url: https://arxiv.org/abs/2503.09721
tags:
- training
- samples
- computational
- coreset
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Loss Trajectory Correlation (LTC), a novel
  metric for coreset selection that quantifies the alignment between training sample
  loss trajectories and validation set loss trajectories to identify critical data
  points driving generalization. LTC is computationally efficient as it uses loss
  trajectories already generated during training, requiring only forward passes for
  query samples, and its property is transferable across architectures.
---

# Finding the Muses: Identifying Coresets through Loss Trajectories

## Quick Facts
- **arXiv ID:** 2503.09721
- **Source URL:** https://arxiv.org/abs/2503.09721
- **Reference count:** 40
- **Primary result:** LTC achieves accuracy within 1% of state-of-the-art methods while requiring only forward passes for coreset selection

## Executive Summary
This paper introduces Loss Trajectory Correlation (LTC), a novel metric for coreset selection that leverages the alignment between training sample loss trajectories and validation loss trajectories to identify critical data points driving generalization. The method is computationally efficient as it uses loss trajectories already generated during training, requiring only forward passes for query samples, and its property is transferable across architectures. Experiments on CIFAR-100 and ImageNet-1k show LTC consistently achieves accuracy on par with or surpassing state-of-the-art methods (within 1% difference), while offering insights into training dynamics at a fraction of the computational cost. The method also demonstrates minimal performance degradation (<2%) when transferring coresets across diverse architectures including ResNet, VGG, DenseNet, and Swin Transformer.

## Method Summary
LTC quantifies the Pearson correlation between the change in loss (Δℓ) of training samples and validation samples over training epochs. The method requires training a source model while logging scalar losses for every training sample and the validation set at each epoch. After training, the correlation between individual training sample loss trajectories and validation trajectories is computed, and samples are ranked by their average LTC score. The top-k samples (class-balanced) form the coreset, which can then be used to train a target model. Critically, the source model for LTC calculation need not match the target model architecture, enabling cross-architecture transferability.

## Key Results
- LTC achieves accuracy within 1% of state-of-the-art coreset methods on CIFAR-100 and ImageNet-1k
- Coreset transferability across architectures shows minimal performance degradation (<2%) between ResNet, VGG, DenseNet, and Swin Transformer
- Computational efficiency: O(QTf) complexity using only forward passes, avoiding the O(Np) gradient storage of methods like TracIn

## Why This Works (Mechanism)

### Mechanism 1: Loss Trajectory Alignment
Training samples with loss trajectories that correlate positively with validation loss trajectories improve generalization. LTC quantifies this alignment using Pearson correlation between the change in loss (Δℓ) of a training sample and a query sample over T epochs. High positive LTC implies synchronized learning dynamics; when the model learns the training sample (loss drops), it simultaneously improves on the validation sample.

### Mechanism 2: Architecture-Agnostic Data Importance
Coreset selection can be decoupled from the target model architecture by using a smaller "source" model. The method relies on the assumption that data importance (as defined by trajectory alignment) is an intrinsic property of the dataset rather than the specific architecture. A lightweight proxy model (e.g., ResNet-18) calculates LTC to identify the coreset, which is then used to train a heavier target model (e.g., Swin Transformer).

### Mechanism 3: Efficient Alternative to Gradient Methods
Loss trajectories provide a computationally efficient alternative to gradient-based influence estimation. Unlike Influence Functions or TracIn, which require backpropagation (∇ℓ) or Hessian approximations, LTC uses scalar loss values ℓ(θₜ, z) generated during the forward pass. This avoids the O(Np) complexity (where p is parameters) of gradient storage, reducing overhead to O(NT) storage for scalars.

## Foundational Learning

- **Concept: Coreset Selection**
  - Why needed here: This is the fundamental problem the paper addresses: selecting a subset Sⱼ ⊂ S such that training on Sⱼ approximates training on the full set S.
  - Quick check question: Can you explain why simply selecting low-loss samples might fail to create a good coreset? (Hint: Redundancy/Easy samples).

- **Concept: Pearson Correlation Coefficient (ρ)**
  - Why needed here: The LTC metric is defined explicitly in Eq (1) as the Pearson correlation between two vectors of loss differences. Understanding linear correlation is vital for interpreting positive (aligned) vs. negative (conflicting) LTC.
  - Quick check question: If a training sample's loss decreases but the query sample's loss increases, what is the sign of the LTC, and what does it imply about the sample?

- **Concept: Training Data Attribution (TDA)**
  - Why needed here: Section 5 positions LTC relative to TDA methods (like TracIn or Influence Functions). Understanding TDA helps contextualize LTC as a "proxy" for influence that sacrifices gradient information for speed.
  - Quick check question: How does the computational complexity of storing loss scalars compare to storing gradients for a batch size of N over T epochs?

## Architecture Onboarding

- **Component map:** Source Trainer -> Trajectory Buffer -> LTC Engine -> Selector
- **Critical path:**
  1. Run standard training for T epochs while logging scalar losses for every sample (requires dataset indexing).
  2. Run forward passes on Validation Set at every epoch (or use pre-computed validation losses if available).
  3. Post-training: Calculate correlation matrix.
  4. Filter dataset using Top-k indices.

- **Design tradeoffs:**
  - Resolution (T): The paper uses the full training schedule (T=90 for ImageNet). Reducing T (early stopping) speeds up selection but may miss long-term dynamics.
  - Validation Size (Q): Larger Q improves the robustness of the "generalization proxy" but increases the forward pass overhead O(QTf).
  - Storage: O(NT) scalar storage. For ImageNet (N ≈ 1.2M, T=90), this is ≈ 0.4 GB (paper estimate), which is manageable, but requires a custom logger.

- **Failure signatures:**
  - Flat Trajectories: If a model converges instantly or losses plateau early, the variance in trajectories drops, making correlation (ρ) unstable or undefined.
  - Negative LTC Selection: Accidentally selecting samples with high negative magnitude would actively harm generalization (conflicting dynamics).
  - Distribution Shift: If the validation set V is not representative of the test set, the selected coreset will optimize for the wrong distribution.

- **First 3 experiments:**
  1. Sanity Check (CIFAR-100): Train ResNet-18, log losses. Select 10% coreset using LTC. Retrain a fresh ResNet-18 on the coreset. Verify accuracy is within 1-2% of full training.
  2. Transfer Validation (ImageNet): Use a pre-trained ResNet-18 (or train from scratch) to generate LTC scores. Select 10% subset. Train a different architecture (e.g., DenseNet-121) on this subset. Verify accuracy drop is < 2% compared to DenseNet-selected coreset.
  3. Trajectory Length Ablation: Calculate LTC using only the first 20%, 50%, and 100% of epochs. Determine the minimum trajectory length required to maintain >95% of the performance gain.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the LTC metric be adapted for scenarios where full training checkpoints are unavailable or storage is severely constrained? The current method requires storing loss trajectories across all epochs (O(NT) storage), which may be infeasible for extremely long training runs or edge devices.

- **Open Question 2:** Does the efficacy of LTC transfer to non-vision domains, such as Natural Language Processing (NLP) or time-series analysis? The experimental evaluation is restricted exclusively to image datasets (CIFAR-100 and ImageNet-1k).

- **Open Question 3:** How can samples with high negative LTC (conflicting dynamics) be utilized beyond simple exclusion from the coreset? The paper identifies these "conflicting" samples but does not explore if they represent a "hard" subset useful for robustness, adversarial training, or debiasing.

## Limitations
- Architecture Transfer Robustness: The assumption that data importance is intrinsic to the dataset may break down for architectures with fundamentally different inductive biases.
- Validation Set Dependency: LTC's effectiveness depends critically on having a representative validation set, which may not be available in practical deployment scenarios.
- Trajectory Resolution Requirements: The method requires storing loss trajectories for every training sample across all epochs, representing additional overhead compared to standard training.

## Confidence

- **Computational Efficiency Claim**: HIGH - Well-supported by complexity analysis (O(QTf) vs O(Np) for gradient storage).
- **Accuracy Parity Claim**: MEDIUM - Shows LTC achieves accuracy within 1% of state-of-the-art methods, but comparison set is limited.
- **Cross-Architecture Transferability**: MEDIUM - Supported by experiments across four architectures, but range is limited and extreme architectural differences are not tested.

## Next Checks

1. **Extreme Architecture Transfer Test**: Test LTC transferability between architectures with fundamentally different biases (e.g., CNN to Vision Transformer) and measure performance degradation when source and target have different texture vs. shape preferences.

2. **Validation Set Sensitivity Analysis**: Systematically vary the validation set composition and size to quantify how representative the validation set must be for LTC to select effective coresets. Compare performance when using in-distribution vs. out-of-distribution validation sets.

3. **Trajectory Compression Study**: Investigate whether lossy compression or subsampling of loss trajectories (e.g., storing every 2nd or 3rd epoch) maintains selection quality while reducing storage requirements. Determine the minimum trajectory resolution needed for effective coreset selection.