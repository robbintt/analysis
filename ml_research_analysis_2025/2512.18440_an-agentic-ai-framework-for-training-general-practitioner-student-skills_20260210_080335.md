---
ver: rpa2
title: An Agentic AI Framework for Training General Practitioner Student Skills
arxiv_id: '2512.18440'
source_url: https://arxiv.org/abs/2512.18440
tags:
- feedback
- medical
- agent
- patient
- personality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'We present an agentic AI framework for training general practitioner
  (GP) student skills that addresses limitations in current virtual simulated patients
  (VSPs), including medical accuracy, consistent roleplaying, scenario generation,
  and educationally structured feedback. The framework integrates three agent roles:
  a generator agent that produces evidence-based vignettes using large language models
  (LLMs) and retrieval augmentation, a conversational agent that simulates patient
  dialogue with controlled response generation and personality customization via Big
  Five traits, and a critic agent that provides standards-based automated feedback
  on communication (using the Master Interview Rating Scale) and clinical reasoning.'
---

# An Agentic AI Framework for Training General Practitioner Student Skills

## Quick Facts
- arXiv ID: 2512.18440
- Source URL: https://arxiv.org/abs/2512.18440
- Reference count: 40
- 14 medical students successfully tested a three-agent VSP framework with realistic dialogue, calibrated difficulty, and highly useful example-rich feedback

## Executive Summary
This paper presents an agentic AI framework for training general practitioner (GP) student skills through virtual simulated patients (VSPs). The system addresses key limitations in current VSP training tools by separating scenario generation, patient dialogue, and assessment into specialized agents. Evaluated with 14 medical students in spoken consultations, the framework demonstrated realistic and vignette-faithful dialogue, appropriate difficulty calibration, stable personality signals, and highly useful feedback with concrete examples.

## Method Summary
The framework implements three specialized agents: a generator agent creates evidence-based vignettes using GPT-4.1 and retrieval augmentation; a conversational agent simulates patient dialogue with controlled response generation and personality customization via Big Five traits using Llama 4 variants; and a critic agent provides standards-based automated feedback on communication (using MIRS) and clinical reasoning. The system uses a tiered model architecture balancing medical fidelity against conversational latency, with GPT-4.1 for high-stakes evaluation tasks and Llama 4 for low-latency dialogue. Medical accuracy is maintained through conditional RAG grounding, and feedback is generated using established educational rubrics with quoted dialogue evidence.

## Key Results
- Realistic dialogue with high vignette fidelity and appropriate difficulty calibration (target 5/10)
- Stable personality signals across conversations with high student consensus ratings (~4.0/5)
- Highly useful feedback rated at ~4.2/5 with particular value placed on concrete dialogue examples (4.43/5)
- Zero reported inconsistencies or incorrect information during conversations
- System Usability Scale score of 80.36 indicating good usability

## Why This Works (Mechanism)

### Mechanism 1
Separating scenario generation, dialogue control, and assessment into distinct agents improves reliability and pedagogical alignment. Role specialization allows each agent to use different models, prompts, and grounding sources optimized for its task (GPT-4.1 for structured generation/evaluation, Llama variants for low-latency dialogue). This reduces interference between creative vignette generation, constrained role-playing, and rubric-based assessment.

### Mechanism 2
Multi-step preprocessing with conditional RAG grounding reduces hallucinations while maintaining conversational naturalness. Before generating responses, the VSP agent classifies whether the answer exists in the vignette, requires external medical knowledge (triggering RAG), is already answered, or requires no medical grounding. This gates retrieval to only when necessary, reducing irrelevant hallucinations while keeping latency acceptable.

### Mechanism 3
Post-session feedback grounded in established educational rubrics (MIRS) with quoted dialogue evidence increases perceived actionability. The critic agent scores each MIRS criterion on a 1-5 Likert scale and generates textual justifications with direct quotes from the conversation. This links abstract criteria to concrete behaviors, making feedback actionable rather than generic.

## Foundational Learning

- **Agent Role Decomposition**: Why needed - The framework's core design separates three distinct responsibilities; understanding why this matters is prerequisite to modifying or extending the system. Quick check - What problem does using different models for generation vs. dialogue vs. critique solve?

- **Retrieval-Augmented Generation (RAG)**: Why needed - The VSP agent conditionally queries a vector database of EBM articles; understanding RAG helps debug when retrieval is triggered and what it returns. Quick check - In this framework, what condition triggers RAG lookup during patient dialogue?

- **Educational Assessment Rubrics (MIRS)**: Why needed - The critic agent outputs structured feedback against the 25-criterion Master Interview Rating Scale; understanding rubrics is necessary to interpret or modify feedback generation. Quick check - Why does the framework use a standardized rubric rather than free-form LLM feedback?

## Architecture Onboarding

- **Component map**: Client Dashboard (NiceGUI/Python) → WebSocket → Backend Server (Python) ↔ LLM Provider (GPT-4.1, Llama 4, GPT-4o-mini) ↔ Medical DB (EBM vector store via LlamaIndex) ↔ Furhat Application (Kotlin) → TTS/STT Provider

- **Critical path**: User configures parameters on dashboard → Generator agent creates vignette (GPT-4.1, async) → User speaks → Furhat STT → VSP agent multi-step reasoning (Llama 4 + optional RAG) → Post-processing (GPT-4o-mini) → Furhat TTS → Session ends → Critic agent generates MIRS scores + clinical feedback (GPT-4.1) → Dashboard display

- **Design tradeoffs**: Latency vs. fidelity (Llama 4 for dialogue speed; GPT-4.1 for evaluation accuracy), RAG coverage vs. complexity (only triggers on medical-knowledge queries), feedback depth vs. conciseness (students rated feedback highly but 6/14 said it was too long)

- **Failure signatures**: High latency (>5s) indicates likely RAG retrieval or slow LLM response; inconsistent persona suggests post-processing failure; generic feedback indicates critic agent may lack transcript context

- **First 3 experiments**: (1) Latency profiling to identify bottlenecks under different query types, (2) RAG ablation to measure hallucination rate without retrieval, (3) Feedback conciseness tuning to optimize usefulness vs. length tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
Do specific Big Five trait combinations result in inaccurate or unstable persona reflections during VSP conversations? The evaluation showed high consensus among students on personality ratings, but these ratings significantly deviated from the scripted target profiles for multiple traits.

### Open Question 2
How can non-verbal communication be effectively integrated to enhance empathy and communicative realism? The current system relies solely on text-to-speech and lacks mechanisms to interpret or display non-verbal cues (e.g., facial expressions, gestures).

### Open Question 3
What is the optimal balance for feedback timing and verbosity to prevent distraction while maintaining educational utility? Students rated the detailed post-session feedback highly but found real-time tips distracting and the final reports overly verbose.

## Limitations
- Single pilot study with 14 medical students from one institution limits generalizability
- Subjective user experience metrics rather than objective learning outcomes or comparison to human standardized patients
- Critical implementation details including exact prompt templates and EBM source documents remain unspecified

## Confidence

- **High confidence**: The agentic separation pattern is a viable architectural approach for VSP systems
- **Medium confidence**: The framework demonstrates practical utility for GP student training based on subjective user ratings
- **Low confidence**: Claims about hallucination reduction and medical accuracy are based on user reports rather than systematic error analysis

## Next Checks

1. Conduct a controlled study comparing knowledge/skill gains between students trained with this framework versus traditional methods or human standardized patients
2. Perform automated transcript analysis to quantify medical errors, inconsistencies, and RAG effectiveness across diverse clinical scenarios
3. Compare the three-agent architecture against monolithic VSP implementations using identical LLMs to isolate the benefits of role separation