---
ver: rpa2
title: 'A2H-MAS: An Algorithm-to-HLS Multi-Agent System for Automated and Reliable
  FPGA Implementation'
arxiv_id: '2508.10904'
source_url: https://arxiv.org/abs/2508.10904
tags:
- module
- code
- hardware
- design
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces A2H-MAS, a multi-agent system for automated
  FPGA implementation of wireless communication algorithms. It addresses the challenge
  of translating MATLAB algorithms into efficient HLS code, which traditionally requires
  expert tuning.
---

# A2H-MAS: An Algorithm-to-HLS Multi-Agent System for Automated and Reliable FPGA Implementation

## Quick Facts
- arXiv ID: 2508.10904
- Source URL: https://arxiv.org/abs/2508.10904
- Authors: Jie Lei; Ruofan Jia; J. Andrew Zhang; Hao Zhang
- Reference count: 27
- Key outcome: Multi-agent system achieves 292.23 MHz and 337.61 MHz for 5G NR and WLAN algorithms with significant resource efficiency through algorithmic transformation over pragma optimization.

## Executive Summary
This paper introduces A2H-MAS, a multi-agent system for automated FPGA implementation of wireless communication algorithms. It addresses the challenge of translating MATLAB algorithms into efficient HLS code, which traditionally requires expert tuning. A2H-MAS uses specialized agents with standardized interfaces and deterministic tools to reduce LLM hallucinations and ensure correctness. The framework employs dataflow-oriented modular decomposition and algorithm-hardware co-design, prioritizing algorithmic transformations over pragma-level optimization. Experiments on 5G NR and WLAN algorithms show consistent production of functionally correct, resource-efficient, and latency-optimized HLS designs.

## Method Summary
A2H-MAS implements an 8-phase multi-agent pipeline using Claude LLM to convert MATLAB algorithms to HLS C++ for FPGA implementation. The process begins with modularization and flattening of MATLAB code, followed by algorithmic transformation from frame-based to sample-based streaming using a Knowledge Library of hardware patterns. The system then translates optimized MATLAB to HLS C++ and performs automated Design Space Exploration for pragma tuning and bit-width optimization. Deterministic tools handle validation throughout, with agents producing standardized output directories for reproducibility. The approach prioritizes algorithmic choices over micro-architectural directives to achieve better resource efficiency.

## Key Results
- Achieves maximum operating frequencies of 292.23 MHz for 5G NR and 337.61 MHz for WLAN algorithms
- Demonstrates significant resource efficiency gains through algorithmic transformation over direct HLS translation
- Validates functional correctness through RTL co-simulation while reducing LUT/DSP usage compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1: Multi-Agent Decomposition with Standardized Interfaces
Decomposing the MATLAB-to-HLS pipeline into specialized agents with standardized interfaces reduces hallucinations and improves reproducibility compared to single-LLM approaches. Each agent receives a structured input directory and produces a standardized output directory, limiting uncontrolled reasoning and enabling execution-based validation at each stage.

### Mechanism 2: Deterministic Tool-Based Validation Over LLM Self-Verification
Replacing LLM self-verification with deterministic external tools (simulators, batch execution, grep-based analysis) improves reliability and reduces hallucination propagation. Agents use deterministic tools for classification and validation while the LLM orchestrates reasoning, ensuring reproducible results.

### Mechanism 3: Algorithm-Hardware Co-Design Prioritizing Algorithmic Transformation
Prioritizing algorithm-level transformations over pragma-level HLS optimization yields larger resource efficiency gains. The framework classifies algorithms and selects appropriate algorithmic patterns before applying HLS directives, recognizing that algorithmic structure has greater impact on hardware efficiency than micro-architectural directives.

## Foundational Learning

- **High-Level Synthesis (HLS)**: Essential for understanding HLS pragmas, dataflow, and streaming interfaces used in the intermediate representation. *Quick check: Can you explain the difference between `#pragma HLS PIPELINE` and `#pragma HLS DATAFLOW`?*
- **Frame-Based vs Sample-Based Processing**: Critical for understanding why phase IV transforms frame-based MATLAB algorithms to sample-based streaming architectures suitable for FPGA dataflow. *Quick check: Why does a FIR filter implemented with global array access require transformation for efficient FPGA implementation?*
- **LLM Hallucination and Forgetting in Code Generation**: Fundamental to understanding why the framework uses multi-agent decomposition and tool-based validation to mitigate these limitations. *Quick check: What specific failure modes in LLM-generated HDL code does tool-based validation address that self-verification cannot?*

## Architecture Onboarding

- **Component map**: Modularization Agent -> Test Data Generator -> Function Flattening Agent -> Optimization Agent -> Translation Agent -> Refinement Agent -> Integration Agent
- **Critical path**: Modularization → Test Data Generation → Function Flattening → Code Optimization (sample-based transformation) → Translation → Refinement (DSE) → Integration
- **Design tradeoffs**: Algorithmic transformation vs pragma optimization prioritized; wider bit-widths initially vs optimized bit-widths later; streaming parallelism vs resource constraints
- **Failure signatures**: Direct translation without optimization causes excessive LUT/DSP usage and timing closure failure; missing function flattening prevents LLM understanding of MATLAB semantics; inadequate test data produces false positives
- **First 3 experiments**: 1) Run ablation comparison on calcThreshold or extractSSBsig across Direct, Adaptation, and Refinement stages; 2) Add new pattern to Knowledge Library and verify correct retrieval/application; 3) Modify Modularization Agent to decompose new wireless communication algorithm and validate interface propagation

## Open Questions the Paper Calls Out
None

## Limitations
- Framework effectiveness relies on deterministic tool validation but lacks source code release and detailed agent implementation specifics
- Reported resource efficiency gains depend on algorithmic transformations that may not generalize beyond 5G NR and WLAN domains tested
- Knowledge Library completeness and pattern applicability to non-wireless algorithms remain unverified

## Confidence

**High Confidence**: Multi-agent decomposition with standardized interfaces improves reliability over monolithic LLM approaches; deterministic tool-based validation is more reliable than LLM self-verification; algorithm-hardware co-design prioritizing algorithmic transformation yields larger efficiency gains than pragma-level optimization.

**Medium Confidence**: The framework generalizes to complex wireless communication algorithms beyond tested examples; the 8-phase pipeline is complete and correctly ordered for optimal results.

**Low Confidence**: Performance scales to non-wireless domains (e.g., image processing, scientific computing); specific agent architectures and prompt engineering details are sufficient for reproducibility without code release.

## Next Checks
1. **Ablation Study Replication**: Recreate calcThreshold and extractSSBsig ablation comparisons across Direct, Adaptation, and Refinement stages to verify reported resource/latency tradeoffs and timing closure behavior.
2. **Knowledge Library Pattern Testing**: Add a new algorithmic pattern (e.g., sliding window FFT) to the library and validate that the Optimization Agent correctly retrieves and applies it, producing functionally equivalent and more efficient HLS output.
3. **Cross-Domain Generalization**: Apply the framework to a non-wireless algorithm (e.g., matrix multiplication or image filter) and measure whether the algorithmic transformation approach maintains efficiency advantages over direct HLS translation.