---
ver: rpa2
title: 'LANE: Lexical Adversarial Negative Examples for Word Sense Disambiguation'
arxiv_id: '2511.11234'
source_url: https://arxiv.org/abs/2511.11234
tags:
- word
- lane
- lexical
- adversarial
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LANE, a method that generates adversarial
  negatives by selectively marking alternate words in the same sentence context to
  improve word sense disambiguation. LANE addresses the limitation of neural language
  models overfitting to global sentence representations and failing to capture fine-grained
  word-level semantics.
---

# LANE: Lexical Adversarial Negative Examples for Word Sense Disambiguation

## Quick Facts
- arXiv ID: 2511.11234
- Source URL: https://arxiv.org/abs/2511.11234
- Authors: Jader Martins Camboim de Sá; Jooyoung Lee; Cédric Pruski; Marcos Da Silveira
- Reference count: 33
- Primary result: LANE achieves up to 2.4% accuracy improvement on word-in-context benchmarks by generating adversarial negatives that force word-level semantic discrimination

## Executive Summary
LANE addresses the fundamental limitation of neural language models overfitting to global sentence representations rather than capturing fine-grained word-level semantics in word sense disambiguation tasks. The method introduces adversarial negatives by selectively marking alternate words within identical sentence contexts, forcing models to encode semantics based solely on the marked token rather than relying on contextual shortcuts. Through progressive scheduling and in-batch contrastive learning with CoSENT loss, LANE consistently improves WSD performance across monolingual and multilingual datasets while enhancing attention focus on target words and cross-lingual generalization in low-resource settings.

## Method Summary
LANE generates adversarial negatives by randomly selecting different words from the same sentence context and marking them as targets, creating challenging training examples where the model must discriminate based on word-level semantics alone. The method employs a linear scheduling strategy that gradually introduces these adversarial examples after an initial warm-up period, preventing early training collapse. Using CoSENT (cosine-based ranking) loss with in-batch negatives, LANE trains models to create more discriminative embeddings that maintain lexical separability even in semantically similar contexts. The approach is model-agnostic and can be integrated into existing contrastive learning frameworks with minimal overhead.

## Key Results
- Achieves up to 2.4% accuracy improvement on word-in-context benchmarks
- Consistently outperforms baseline across multiple transformer architectures (DV3, MBERT, XLM-R)
- Demonstrates enhanced attention focus on target words compared to standard contrastive learning
- Shows improved cross-lingual generalization in low-resource settings

## Why This Works (Mechanism)

### Mechanism 1: Lexical Hard Negative Generation
Generating hard negatives by marking different words within identical sentence contexts forces models to encode word-level semantics rather than relying on global context. The "avoidance of repetition" principle assumes randomly selected substitute words are unlikely to share the same sense as the original target word. However, this creates a risk of false negatives from synonyms, which could harm learning.

### Mechanism 2: Progressive Hard Negative Scheduling
Linearly scheduling the introduction of adversarial negatives prevents early training collapse and improves convergence. The warm-up period allows models to form stable base representations before facing challenging adversarial examples. Too aggressive scheduling risks trapping models in local optima.

### Mechanism 3: In-Batch CoSENT Contrastive Loss
CoSENT loss with in-batch negatives improves sense discrimination by penalizing misranked similarity pairs more heavily than correctly ranked ones. The λ=20 scaling factor promotes semantically coherent clustering via cosine similarity, assuming ground-truth similarity labels from sense keys accurately reflect semantic distinctions.

## Foundational Learning

- **Contrastive Learning Fundamentals**: Understanding how similarity margins and negative sampling work is essential since LANE builds on contrastive learning. Quick check: Can you explain why hard negatives improve contrastive learning more than random negatives?

- **Word Sense Disambiguation Task Formulation**: WiC frames WSD as binary classification (same sense vs. different sense across contexts), differing from traditional sense inventory prediction. Quick check: How does WiC differ from standard WSD evaluation using WordNet synset prediction?

- **Shortcut Learning and Contextual Overfitting**: Understanding how NLMs exploit topical/contextual cues rather than word-level semantics is crucial for appreciating why adversarial marking helps. Quick check: What evidence would indicate a model is using contextual shortcuts rather than target-word semantics?

## Architecture Onboarding

- **Component map**: Input (sentence pairs with marked targets) → Tokenizer with target-word markers → Transformer encoder (XLM-R, DeBERTa, ModernBERT) → Target-word embedding extraction → Adversarial negative generator (Algorithm 1, in-batch) → Scheduled mixing (linear probability over epochs) → CoSENT loss (cosine ranking, λ=20) → AdamW optimizer (lr=1e-5, batch_size=64)

- **Critical path**: The adversarial negative generator (Algorithm 1) is the core novelty—it must correctly identify replacement candidates, handle label reassignment, and integrate with the scheduler. Errors here propagate to the entire training signal.

- **Design tradeoffs**:
  - Random vs. curated substitution: Random selection is simple and scalable but risks false negatives from synonyms; curated substitution using lexical resources would be more accurate but adds complexity and language-specific dependencies
  - Early vs. scheduled introduction: Early introduction reduces training time but risks collapse; scheduled introduction is more stable but requires longer training (20 epochs vs. 10 for baseline)
  - Marker format: Prefix notation (word<s>context) vs. inline markers (<t>word</t>)—paper doesn't deeply evaluate this choice but notes both exist in prior work

- **Failure signatures**:
  - Representation collapse: If adversarial examples are introduced too early or at too high a rate, embeddings converge to a narrow region regardless of marked word
  - False negative contamination: If substitute words frequently share senses with targets, the model learns to push semantically similar instances apart, degrading performance
  - Attention misalignment: Without sufficient adversarial pressure, attention heatmaps show diffuse focus rather than concentration on the marked token

- **First 3 experiments**:
  1. Ablation on scheduling strategy: Reproduce Figure 5 on a held-out dev set comparing (a) no adversarial examples, (b) immediate adversarial introduction, (c) linear scheduled introduction. Measure F1 and embedding space isotropy.
  2. False negative analysis: Manually inspect 100 randomly generated adversarial pairs to estimate synonym contamination rate; correlate contamination rate with performance degradation.
  3. Cross-architecture validation: Apply LANE to a transformer not tested in the paper (e.g., Mistral-7B encoder mode) on a single dataset (WiC) to verify architecture-agnostic claims with minimal compute.

## Open Questions the Paper Calls Out

- **False negative prevention**: How can the adversarial negative generation process be refined to explicitly filter out synonyms or near-synonyms to prevent false negative penalties during training? The current random substitution mechanism risks creating false negatives from synonyms like "buy"→"purchase".

- **Morphologically rich language limitations**: To what extent does the reliance on whitespace tokenization limit LANE's effectiveness in morphologically rich or agglutinative languages? The method assumes simple tokenization by spaces, which may be insufficient for languages with complex word formation.

- **Downstream task generalization**: Does the improved attention focus on target words induced by LANE directly translate to better performance on downstream tasks like neologism identification? While LANE enhances word-level attention and representation discriminability, it does not explicitly test performance on neologism detection.

## Limitations

- **False negative risk**: The random substitution mechanism may occasionally select synonyms, creating false negatives that encourage the model to separate semantically identical contexts
- **Tokenization constraints**: Assumes simple whitespace tokenization, which may be insufficient for languages with complex morphology or rich word formation
- **Computational overhead**: While claimed to have minimal overhead, scaling to larger datasets or longer sequences may reveal hidden costs not evaluated in the paper

## Confidence

- **Mechanism 1 (Lexical Hard Negative Generation)**: Medium confidence. Theoretical rationale is sound with qualitative visualization support, but lacks quantitative validation of false negative rates and untested "avoidance of repetition" assumption
- **Mechanism 2 (Progressive Hard Negative Scheduling)**: Low confidence. Novel to this work with no ablation on optimal warm-up duration or growth rate; suggestive evidence but doesn't isolate scheduling from other variables
- **Mechanism 3 (In-Batch CoSENT Loss)**: High confidence. Established objective adapted from sentence embedding literature with consistent performance gains across multiple architectures
- **Overall Improvement Claims**: Medium confidence. Reported accuracy gains (up to 2.4%) across multiple datasets, but lack of statistical significance testing and potential confounding factors limit definitive conclusions

## Next Checks

1. **False Negative Contamination Analysis**: Manually inspect 100 randomly generated adversarial pairs to estimate synonym contamination rate. Correlate contamination rate with performance degradation on dev sets to quantify the trade-off between hard negative mining and false negative introduction.

2. **Scheduler Sensitivity Analysis**: Systematically vary warm-up duration (0-50% of epochs) and growth rate (linear, exponential, step-wise) on a single dataset (WiC). Measure F1 and embedding space isotropy to identify optimal scheduling parameters and test the claim that early adversarial introduction causes local optimum convergence.

3. **Cross-Lingual Generalization Test**: Apply LANE to a low-resource language pair (e.g., Swahili-English) using a small parallel corpus to evaluate whether adversarial negatives improve cross-lingual sense alignment compared to standard contrastive learning, testing the claim of enhanced generalization in low-resource settings.