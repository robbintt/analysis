---
ver: rpa2
title: 'MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data
  through Question Answering'
arxiv_id: '2508.11163'
source_url: https://arxiv.org/abs/2508.11163
tags:
- data
- trajectory
- mobility
- question
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces MobQA, a benchmark dataset for evaluating
  semantic understanding of human mobility data using natural language question answering.
  The dataset contains 5,800 question-answer pairs across three types: factual retrieval,
  multiple-choice reasoning, and free-form explanation, covering both daily and weekly
  trajectory granularities.'
---

# MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering

## Quick Facts
- arXiv ID: 2508.11163
- Source URL: https://arxiv.org/abs/2508.11163
- Reference count: 40
- State-of-the-art LLMs achieve >80% accuracy on factual retrieval but only 2.0-3.0/5 on semantic reasoning tasks

## Executive Summary
MobQA is a benchmark dataset for evaluating semantic understanding of human mobility data using natural language question answering. Built on the Geolife GPS dataset, it contains 5,800 question-answer pairs across three types: factual retrieval, multiple-choice reasoning, and free-form explanation, covering both daily and weekly trajectory granularities. Experiments reveal strong performance on factual retrieval (accuracy > 80%) but significant limitations on semantic reasoning tasks, with free-form answers scoring only 2.0-3.0 out of 5 on faithfulness and informativeness metrics. Performance degrades substantially for longer weekly trajectories, highlighting current models' challenges in processing extended sequences and extracting meaningful semantic insights from raw GPS data.

## Method Summary
MobQA transforms GPS trajectories into textual sequences of time-stamped coordinates, then pairs them with natural language questions across three reasoning types. The dataset uses Geolife GPS data with 136 users' trajectories, processed through 1-minute downsampling, stay-point merging, and coordinate anonymization. Questions are generated via templates for factual and multiple-choice types, with GPT-4o and manual filtering for free-form explanations. Evaluation uses exact-match accuracy for factual/multiple-choice tasks and an LLM-as-a-Judge framework (Gemini-2.0-Flash) for free-form tasks, measuring faithfulness and informativeness on 1-5 scales. The dataset is split 80/20 for training and testing, with fine-tuning using QLoRA on open-source models.

## Key Results
- Factual retrieval accuracy exceeds 80% across all tested models
- Multiple-choice reasoning accuracy drops to 40-50% for longer weekly trajectories
- Free-form answers score only 2.0-3.0 out of 5 on faithfulness and informativeness metrics
- Performance degrades substantially as trajectory length increases from daily (97.2 avg points) to weekly (787.5 avg points)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Converting GPS coordinates to structured text sequences enables LLMs to process spatial-temporal patterns through their pre-trained language capabilities
- **Mechanism:** Raw trajectories $\{(x_i, y_i, t_i)\}$ are transformed into newline-separated tuples like `(09:02, -0.75, 8.79)\n(09:03, -0.71, 8.65)`, allowing LLMs to apply pattern recognition learned from sequential text to movement sequences
- **Core assumption:** LLMs' sequential reasoning capabilities transfer from natural language to numerical coordinate sequences
- **Evidence anchors:**
  - [abstract] "Trajectory serves as the primary data source, represented as a textual sequence of time-stamped coordinates"
  - [section 3.1] Details the textual trajectory representation format and preprocessing
  - [corpus] MoveFM-R paper confirms LLMs can provide semantic reasoning for mobility patterns but lack innate spatio-temporal understanding
- **Break condition:** When trajectories exceed ~1,000 points (~20,000 tokens), even strong models show degraded performance due to context limitations

### Mechanism 2
- **Claim:** Multi-granularity trajectory evaluation reveals differential model capabilities across reasoning complexity levels
- **Mechanism:** Daily vs. weekly trajectories test short-term contextual extraction vs. long-term pattern recognition, exposing the trade-off between "contextual richness and sequence length"
- **Core assumption:** Semantic understanding requires both immediate pattern extraction and integration of behavioral evidence across extended timeframes
- **Evidence anchors:**
  - [abstract] "Accuracy degrading substantially as trajectory length increases"
  - [section 4.4] Shows GPT models exhibit "sharp drop in accuracy" on factual retrieval for longer trajectories, while multiple-choice reasoning remains more stable
  - [corpus] Zero-Shot Human Mobility Forecasting paper notes generalization challenges with limited labeled data
- **Break condition:** Weekly trajectories average 787.5 data points, creating noise that interferes with coherent generation for free-form tasks

### Mechanism 3
- **Claim:** LLM-as-a-Judge evaluation provides better alignment with human assessment than traditional metrics for subjective trajectory interpretation
- **Mechanism:** Using Gemini-2.0-Flash to score faithfulness (factual accuracy) and informativeness (semantic richness) achieves 0.57-0.60 correlation with human evaluators, outperforming BLEU (0.08-0.23) and ROUGE (-0.19 to 0.17)
- **Core assumption:** LLMs can evaluate semantic coherence and factual grounding in mobility explanations similarly to humans
- **Evidence anchors:**
  - [abstract] Adopts "LLM-as-a-judge framework to assess the faithfulness and informativeness of free-form answers"
  - [section E.1] Shows LLM evaluators achieve 0.40-0.60 correlation range vs. near-zero for automatic metrics
  - [corpus] Weak corpus evidence on LLM-as-judge for mobility specifically; related work on LLM evaluation exists but not domain-specific
- **Break condition:** Self-enhancement bias was limited (r=0.837 correlation between GPT-4o and Gemini-2.0-Flash scores), but cross-validation remains necessary

## Foundational Learning

- **Concept: Context Length vs. Semantic Integration Trade-off**
  - **Why needed here:** Trajectories inherently create long sequences; understanding when additional context helps vs. creates noise is critical for system design
  - **Quick check question:** For a model with 128K context window, should you include full weekly trajectories (~800 points ≈ 16K tokens) or segment them? Consider: multiple-choice accuracy remains stable with length, but free-form faithfulness degrades.

- **Concept: Factual Retrieval vs. Semantic Inference Distinction**
  - **Why needed here:** Different architectures may excel at different tasks; Gemini-2.0 achieves 0.991 on factual retrieval but only ~0.40 on multiple-choice reasoning
  - **Quick check question:** Your application needs to answer "Where was the user at 14:32?" vs. "Why was the user likely at the shopping center?" - should you use the same model for both?

- **Concept: Coordinate Anonymization and Spatial Preservation**
  - **Why needed here:** Privacy-preserving offset transformation $(x'_i, y'_i) = (x_i - x_{ref}, y'_i)$ must preserve relative spatial relationships for reasoning
  - **Quick check question:** After anonymization, can a model still infer that two points are "near each other" or that a trajectory shows "circular movement"? What geometric properties are preserved?

## Architecture Onboarding

- **Component map:** Raw Geolife data → Privacy anonymization → Textual representation → Question pairing → Model inference → Judge evaluation
- **Critical path:** Raw Geolife data → Privacy anonymization → Textual representation → Question pairing → Model inference → Judge evaluation
- **Bottleneck:** Free-form question generation requires GPT-4o + human filtering (90% acceptance rate, ~1,800/2,000 accepted)
- **Design tradeoffs:**
  - **Granularity:** Daily (97.2 avg points) vs. Weekly (787.5 avg points) - richer context but performance degradation
  - **Semantic augmentation:** Adding mobility modes/POIs helps o3-mini (0.67 accuracy) but hurts GPT-4o-mini (0.40 accuracy)
  - **Evaluation metrics:** LLM-as-judge correlates with humans but adds cost and potential bias; traditional metrics are cheap but invalid
- **Failure signatures:**
  - **Hallucination in transit detection:** GPT-4o-mini generates "dining at a restaurant" for coordinates that show clear linear movement (Case Study 1)
  - **Mode misclassification:** o3-mini correctly identifies transit but infers walking instead of bus travel
  - **Surface-level comparison:** GPT-4o-mini notes "different movement patterns" without extracting qualitative insights (Case Study 2)
- **First 3 experiments:**
  1. **Baseline retrieval test:** Evaluate factual retrieval accuracy across trajectory lengths (100-1000 points) on your target model to establish context-length degradation curve
  2. **Semantic augmentation ablation:** Test with/without POI/mode annotations to determine if your model benefits or is distracted by additional context
  3. **Judge calibration:** Compare human vs. LLM-as-judge scores on 50 free-form responses to validate evaluation pipeline before scaling

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can LLMs be improved to maintain semantic reasoning performance on mobility data as trajectory length increases from daily (~97 data points) to weekly (~787 data points) sequences?
- **Basis in paper:** [explicit] The paper states "performance substantially degrading for longer trajectory sequences" and that "fine-tuning...failed to resolve the issue of performance degradation with longer sequences. This highlights the inherent difficulty of the underlying problem."
- **Why unresolved:** All evaluated models showed accuracy drops on longer trajectories; fine-tuning did not address this fundamental challenge.
- **What evidence would resolve it:** Architectural innovations or training methods that show stable or improved performance across both daily and weekly trajectory lengths.

### Open Question 2
- **Question:** What mechanisms determine whether semantic augmentation (mobility modes, POIs, visit reasons) improves or degrades model performance on mobility QA tasks?
- **Basis in paper:** [explicit] Figure 6 shows o3-mini improved substantially with semantic augmentation while gpt-4o-mini performed worse with all types; the paper notes "semantic cues benefit performance only when LLMs can integrate them effectively."
- **Why unresolved:** The paper identifies this mixed effect but does not explain why different models respond oppositely to the same augmentation.
- **What evidence would resolve it:** Systematic analysis correlating model architecture/training characteristics with augmentation effectiveness, or methods that adaptively select when to apply semantic enrichment.

### Open Question 3
- **Question:** How do geographic, demographic, and cultural factors influence LLM performance on mobility semantic understanding tasks?
- **Basis in paper:** [explicit] The Limitations section states: "the geographic and demographic scope remains limited... Future work will seek to build multilingual versions of the dataset with more diversity in geography and demography."
- **Why unresolved:** MobQA is built exclusively on Beijing-based Geolife data and currently constructed in Japanese; generalizability to other contexts is untested.
- **What evidence would resolve it:** Comparative evaluations across datasets spanning different cities, countries, and cultural contexts with multilingual question-answer pairs.

### Open Question 4
- **Question:** Can mobility QA benchmarks be extended to capture subjective reasoning tasks such as user intent inference, preference estimation, or dialogue-based mobility assistance?
- **Basis in paper:** [explicit] The paper states: "these [three tasks] do not exhaust the full space of mobility-related reasoning. Future extensions could incorporate dialogue-based interactions, long-term behavior summarization, or subjective tasks such as intent or preference estimation."
- **Why unresolved:** Current tasks (factual retrieval, multiple-choice, free-form explanation) focus on objective extraction and description rather than subjective user-centered reasoning.
- **What evidence would resolve it:** New benchmark datasets with annotations for user intents, preferences, and multi-turn conversational interactions about mobility data.

## Limitations
- The textual trajectory representation loses precise spatial geometry, limiting metric reasoning about distances and angles
- LLM-as-a-Judge framework shows moderate correlation (0.57-0.60) with human evaluation but drops to 0.40-0.46 for certain metrics
- All experiments use GPT-family models and Gemini variants, potentially reflecting model-specific rather than fundamental LLM constraints

## Confidence
**High Confidence:** The dataset construction methodology, factual retrieval accuracy results, and context-length degradation patterns are well-documented and reproducible. The correlation between LLM evaluators and human judges, while not perfect, shows consistent patterns across multiple experiments.

**Medium Confidence:** The semantic reasoning performance limitations are clearly demonstrated, but the exact causes remain unclear. Is the 2.0-3.0/5 score due to LLM architecture constraints, the textual representation format, or the inherent difficulty of extracting semantic insights from raw trajectories?

**Low Confidence:** Claims about cross-domain applicability are speculative. The dataset is based on Geolife (Beijing residents), and while the methodology could theoretically apply to other mobility datasets, performance on different populations or mobility patterns remains untested.

## Next Checks
1. **Geometry Preservation Validation:** Test whether the anonymization process preserves critical spatial relationships by checking if models can accurately answer questions about relative distances, angles, and geometric patterns after coordinate transformation. Compare performance on anonymized vs. original coordinates for spatial reasoning tasks.

2. **Cross-Dataset Generalization:** Apply the MobQA evaluation pipeline to a different mobility dataset (e.g., Shanghai GPS traces or vehicle telematics data) to verify whether the observed performance patterns hold across different mobility contexts and populations.

3. **Alternative Representation Comparison:** Implement and evaluate alternative trajectory representations (e.g., tokenizing relative movements instead of absolute coordinates, or using mixed text/numerical formats) to determine if the textual tuple format is optimal or if other encodings could improve semantic reasoning performance.