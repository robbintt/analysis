---
ver: rpa2
title: Effects of personality steering on cooperative behavior in Large Language Model
  agents
arxiv_id: '2601.05302'
source_url: https://arxiv.org/abs/2601.05302
tags:
- personality
- cooperation
- traits
- scores
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated how personality steering influences cooperative
  behavior in LLM agents using repeated Prisoner's Dilemma games. The researchers
  first measured baseline personality scores of three LLMs (GPT-3.5-turbo, GPT-4o,
  GPT-5) using the Big Five Inventory, finding consistent personality profiles across
  models with high agreeableness.
---

# Effects of personality steering on cooperative behavior in Large Language Model agents

## Quick Facts
- arXiv ID: 2601.05302
- Source URL: https://arxiv.org/abs/2601.05302
- Reference count: 40
- Primary result: Personality steering significantly influences cooperative behavior in LLMs, with agreeableness being the dominant trait, but effectiveness varies by model generation and opponent strategy.

## Executive Summary
This study investigates how personality steering influences cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. The researchers measured baseline personality scores of three LLMs (GPT-3.5-turbo, GPT-4o, GPT-5) using the Big Five Inventory, finding consistent personality profiles across models with high agreeableness. They then examined cooperative behavior under baseline and personality-informed conditions, finding that explicit personality information increased cooperation but also vulnerability to exploitation in earlier-generation models, while later-generation models exhibited more selective cooperation. Finally, they manipulated individual personality dimensions to extreme values, revealing that agreeableness had the strongest effect on cooperative behavior across all models. The results demonstrate that personality steering acts as a behavioral bias rather than deterministic control, with its effectiveness depending on the interaction between personality cues and model-specific decision-making capabilities.

## Method Summary
The researchers employed a three-stage experimental design. First, they measured baseline personality traits of three LLMs using the BFI-44 questionnaire, administering it 20 times per model and computing averaged Big Five scores. Second, they conducted repeated Prisoner's Dilemma games with 100 independent trials of 10 rounds each, using five fixed opponent strategies (ALLC, ALLD, RANDOM, TFT, GRIM TRIGGER) under baseline and personality-informed conditions. Third, they manipulated individual personality dimensions to extreme values (1 or 5) while holding other traits constant to isolate trait-specific effects. The study measured average cooperation rate and normalized cumulative payoff as key metrics.

## Key Results
- Agreeableness manipulation had the strongest and most consistent effect on cooperative behavior across all models
- Explicit personality information increased cooperation but also raised vulnerability to exploitation in earlier-generation models
- Later-generation models exhibited more selective cooperation, maintaining strategic robustness against exploitative opponents

## Why This Works (Mechanism)

### Mechanism 1: Agreeableness Dominance in Cooperative Decisions
The prompt-based personality steering explicitly defines the agent's persona, including natural-language descriptions like "highly cooperative and trusting" for high agreeableness scores. This persona definition acts as a high-level behavioral prior that constrains the model's decision-making in social dilemmas, biasing it toward cooperation when agreeableness is high and defection when low. The LLM conditions its game decisions on the provided personality description, treating it as a coherent character profile rather than ignoring it or treating it as irrelevant context.

### Mechanism 2: Model-Specific Strategic Reasoning Moderates Personality Effects
Newer models (GPT-4o, GPT-5) possess enhanced reasoning capabilities that allow them to integrate personality steering with opponent modeling. When facing exploitative strategies (ALLD, RANDOM), these models can suppress personality-driven cooperation tendencies if they conflict with payoff optimization. Model architecture improvements enable context-dependent integration of persona constraints with strategic analysis.

### Mechanism 3: Explicit Personality Information Increases Vulnerability to Exploitation in Earlier Models
Earlier models (GPT-3.5-turbo) lack sophisticated opponent modeling, so personality-steered high cooperation is applied uniformly. Against cooperative opponents this is beneficial; against defecting strategies (ALLD, RANDOM), it results in systematic exploitation and lower cumulative payoffs. The personality cue acts as a behavioral commitment that earlier models cannot selectively suspend based on opponent behavior.

## Foundational Learning

- Concept: **Prisoner's Dilemma payoff structure**
  - Why needed here: The paper uses repeated Prisoner's Dilemma games with specific payoff values (T=5, R=3, P=1, S=0). Understanding why T>R>P>S creates a social dilemma is essential to interpret cooperation rates and exploitation vulnerability.
  - Quick check question: Why does the payoff ordering T>R>P>S create a tension between individual and collective rationality?

- Concept: **Big Five Inventory (BFI-44) scoring**
  - Why needed here: The paper measures and manipulates personality using BFI-44, a standardized 44-item questionnaire. Understanding how scores are computed and interpreted is necessary to understand the manipulation methodology.
  - Quick check question: If a model scores 4.27 on agreeableness on a 1-5 scale, what does this indicate about its baseline cooperative tendency?

- Concept: **Tit-for-Tat and standard opponent strategies**
  - Why needed here: The paper uses five fixed opponent strategies (ALLC, ALLD, RANDOM, TFT, GRIM TRIGGER) to evaluate model behavior. Understanding these strategies is necessary to interpret differential cooperation patterns.
  - Quick check question: Which opponent strategy would be most effective at exploiting an agent that always cooperates?

## Architecture Onboarding

- Component map: Personality Measurement Module -> Personality Prompt Constructor -> Game Environment -> History Tracking -> Metrics Computation
- Critical path: 1) Run BFI-44 personality measurement (20 runs) → obtain baseline personality profile; 2) Construct personality prompt with measured or manipulated scores; 3) Initialize RPD game with opponent strategy and personality condition; 4) For each round: inject history prompt + game prompt + (optionally) personality prompt → collect model action → update history; 5) After 10 rounds: record cooperation rate and cumulative payoff; 6) Aggregate across 100 trials → compute mean metrics
- Design tradeoffs:
  - Temperature setting (0.7): Balances response diversity vs. consistency. Lower values increase reproducibility; higher values capture more behavioral variance.
  - Extreme manipulation (1 vs. 5): Maximizes signal detection but may not reflect realistic personality steering applications.
  - Independent trait manipulation: Isolates individual trait effects but ignores potential trait interactions.
- Failure signatures:
  - Non-conforming responses: Model outputs non-numeric or invalid responses to BFI items (handled by re-prompting).
  - Personality prompt ignored: Model behavior unchanged across baseline and personality-informed conditions (suggests ineffective prompt design).
  - Uniform cooperation/defection: Model ignores opponent strategy, always cooperates or defects regardless of context.
- First 3 experiments:
  1. **Replicate BFI measurement**: Run BFI-44 on your target model 20 times; verify score stability (compare standard deviations to human baselines).
  2. **Baseline vs. personality-informed comparison**: Run RPD against all 5 opponent strategies under both conditions; verify that personality information alters cooperation rates and payoffs.
  3. **Agreeableness extreme manipulation**: Set agreeableness to 1 and 5 (holding other traits constant); verify that A=1 produces near-zero cooperation across opponent strategies.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does personality steering effectiveness generalize across different model families beyond OpenAI (e.g., Anthropic, Google, open-source models)?
- Basis in paper: The study tested only three OpenAI models (GPT-3.5-turbo, GPT-4o, GPT-5), noting "clear generational differences" and that "the impact of personality steering depends not only on the assigned personality traits but also on the strategic reasoning capabilities of the model."
- Why unresolved: Different training data, alignment procedures, and architectures may produce different baseline personality profiles and varying susceptibility to personality steering.
- What evidence would resolve it: Replicating the same experimental protocol (BFI measurement, RPD games, personality manipulation) with models from Anthropic, Google, Meta, and open-source families.

### Open Question 2
- Question: How do personality-steered LLM agents behave when interacting with human players or other LLM agents, rather than fixed algorithmic strategies?
- Basis in paper: The study used only five fixed opponent strategies (ALLC, ALLD, RANDOM, TFT, GRIM). The authors note interactions among LLM-based agents "can be unpredictable" and "may involve the risk of escalating unintended conflicts" but did not test LLM-LLM or LLM-human interactions.
- Why unresolved: Human and LLM opponents introduce dynamic, context-dependent behavior that fixed strategies cannot capture, potentially altering how personality steering manifests.
- What evidence would resolve it: Experiments where personality-steered LLMs play RPD games against human participants and against other LLMs with varying personality profiles.

### Open Question 3
- Question: How does the number of interaction rounds affect the persistence and stability of personality steering effects?
- Basis in paper: The study used only 10-round games. The authors observed GPT-5 "frequently defected in the final round while maintaining cooperation in earlier rounds, a pattern consistent with end-game optimization," suggesting round count influences behavior.
- Why unresolved: It is unclear whether personality steering effects persist, decay, or intensify over longer interactions, or whether end-game effects dominate in finite games of different lengths.
- What evidence would resolve it: Varying game length systematically (e.g., 10, 50, 100, infinite/unknown horizon rounds) and comparing cooperation trajectories across conditions.

## Limitations

- Personality steering effects depend critically on prompt design and interpretation, with potential limitations in generalizability across different prompt formulations.
- Extreme personality manipulations (scores of 1 or 5) may produce responses that diverge from realistic human personality distributions.
- The study focuses on a narrow set of fixed opponent strategies, which may not capture the full complexity of strategic interactions in real-world cooperative scenarios.

## Confidence

**High Confidence**: The finding that agreeableness manipulation has the strongest effect on cooperative behavior is supported by direct experimental evidence across all three model generations.

**Medium Confidence**: The claim about later-generation models exhibiting more selective cooperation is supported but could benefit from additional strategic diversity testing.

**Medium Confidence**: The vulnerability-to-exploitation trade-off for earlier models is demonstrated empirically but may be sensitive to specific payoff structures and opponent strategies used.

## Next Checks

1. **Personality Measurement Validation**: Replicate the BFI-44 measurement on additional model generations and variants, comparing score distributions and standard deviations to human baselines to verify measurement reliability.

2. **Strategy Space Expansion**: Test the personality steering effects against a broader range of opponent strategies (including stochastic and adaptive strategies) to evaluate the robustness of model-specific selective cooperation patterns.

3. **Intermediate Manipulation Testing**: Conduct experiments with personality scores at intermediate values (e.g., 2-4) rather than extremes to assess whether the effects scale linearly and to identify potential threshold effects.