---
ver: rpa2
title: A global log for medical AI
arxiv_id: '2510.04033'
source_url: https://arxiv.org/abs/2510.04033
tags:
- clinical
- health
- data
- medical
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Modern healthcare lacks a standardized protocol for logging how
  AI models are used in clinical settings, hindering real-world evaluation, safety
  monitoring, and bias detection. To address this gap, the authors introduce MedLog,
  a universal event-level logging protocol for clinical AI.
---

# A global log for medical AI

## Quick Facts
- **arXiv ID:** 2510.04033
- **Source URL:** https://arxiv.org/abs/2510.04033
- **Reference count:** 40
- **Primary result:** Introduces MedLog, a universal event-level logging protocol for clinical AI enabling safety monitoring, bias detection, and real-world evaluation

## Executive Summary
Modern healthcare lacks standardized logging for AI model usage, hindering safety monitoring and bias detection. MedLog addresses this gap by providing a universal protocol that captures nine core fields for each AI interaction, enabling systematic surveillance and comparative evaluation. The protocol supports both simple prompts and complex multi-stage workflows while balancing storage constraints with privacy considerations. A case study from Clalit Health Services demonstrated how MedLog-like monitoring detected real-world dataset drift, showing its potential to transform healthcare through continuous AI performance tracking.

## Method Summary
MedLog defines a nine-field schema (Header, Model, User, Target, Inputs, Artifacts, Outputs, Outcomes, Feedback) for event-level logging of clinical AI interactions. Records are assembled incrementally from immutable messages over time, supporting both simple and agentic workflows. The protocol leverages existing standards like W3C PROV, OpenTelemetry, and FHIR for interoperability, and supports risk-based sampling and lifecycle-aware retention to balance monitoring needs with storage constraints.

## Key Results
- Standardized nine-field schema enables consistent cross-system AI monitoring
- Incremental record assembly supports both simple prompts and complex agent workflows
- Risk-based sampling and retention policies balance safety monitoring with storage constraints
- Case study demonstrated detection of real-world dataset drift from test kit changes

## Why This Works (Mechanism)

### Mechanism 1
Standardized nine-field schema enables consistent cross-system AI monitoring. Each model invocation creates a MedLog record with header, model instance, user identity, target identity, inputs, internal artifacts, outputs, outcomes, and feedback. This structured schema mirrors how syslog unified heterogeneous infrastructure logging by providing consistent message formats that diverse devices could emit to centralized collectors.

### Mechanism 2
Incremental record assembly from immutable messages supports both simple and agentic workflows. Records are built progressively—initial messages establish event_id with immediately available fields (Header, Model, User, Target, Inputs); subsequent messages append artifacts, outputs, outcomes, and feedback by referencing this identifier. This accommodates multi-stage agent workflows without imposing specific orchestration architecture.

### Mechanism 3
Risk-based sampling and lifecycle-aware retention balance safety monitoring with storage constraints. Institutions can adopt tiered policies—full tracing during pilots and post-update periods, sampled or risk-triggered tracing at steady state, and tiered retention (long-term summaries with shorter-lived detailed artifacts). This preserves forensic value while containing operational overhead.

## Foundational Learning

- **syslog protocol (RFC 5424)**: Why needed here: MedLog is explicitly modeled on syslog's design philosophy—centralized logging of heterogeneous events. Understanding syslog's facility/severity fields, structured data elements, and collector architecture provides the mental model for MedLog. Quick check: Can you explain how syslog separates header metadata from message content, and why this separation matters for centralized log aggregation?

- **W3C PROV data model**: Why needed here: MedLog adopts PROV's provenance ontology (Entity, Activity, Agent) to represent computational provenance. Understanding these primitives is essential for implementing conformant records. Quick check: In PROV terms, what is the relationship between a prov:Entity, prov:Activity, and prov:Agent—and which would represent an AI model invocation?

- **FHIR resources (AuditEvent, Patient, Practitioner)**: Why needed here: MedLog entries should anchor to standardized clinical entities for interoperability with EHR systems. FHIR provides the semantic layer for linking AI events to patient records. Quick check: How would you link a MedLog record's Target identity field to a FHIR Patient resource, and what identifier systems (MRN, NPI) would you use?

## Architecture Onboarding

- **Component map**: Emitter layer -> Collector service -> Storage backend -> Linkage service -> Analysis layer
- **Critical path**: Define MedLog schema version and field conformance profile (minimal: Header, Model, Outputs) → Implement collector service with OpenTelemetry-compatible transport → Deploy emitter as LLM proxy or API gateway wrapper for existing AI systems → Configure retention policies and risk-based sampling triggers → Build outcome linkage queries (initially via temporal proximity, later via provider attestation)
- **Design tradeoffs**: Full tracing vs. sampled tracing (higher observability vs. storage costs and privacy exposure); Real-time vs. write-behind caching (immediate safety alerts vs. resilience in low-connectivity settings); Centralized vs. federated storage (simpler analysis vs. reduced cross-institutional data sharing friction); Complete vs. minimal conformance (richer audit trails vs. easier adoption in resource-constrained settings)
- **Failure signatures**: Orphaned fragments (messages that reference non-existent or deleted event_ids indicate collector failures or retention misconfiguration); Schema drift (records that don't parse against declared MedLog version suggest emitter-collector version mismatch); Outcome linkage gaps (high percentage of records without linked outcomes indicates EHR integration failures or missing temporal correlation logic); Sampling blind spots (adverse events clustering in unsampled periods reveals risk-trigger misconfiguration)
- **First 3 experiments**: Minimal conformance pilot (deploy emitter on single AI model, capture only Header, Model instance, and Outputs fields for 2 weeks; validate storage footprint and schema compliance rates); Risk-triggered sampling test (configure elevated capture rate for 48 hours following model version update; compare drift detection sensitivity between sampled and full-tracing periods using synthetic distribution shifts); Outcome linkage prototype (for a discrete AI use case, implement temporal proximity linking between MedLog event_ids and outcome timestamps; measure linkage success rate and false-positive temporal associations)

## Open Questions the Paper Calls Out

### Open Question 1
What specific governance mechanisms and technical safeguards are required to align incentives for commercial AI vendors, ensuring they participate in MedLog sharing despite risks of model extraction or membership inference attacks? The authors note that success hinges on mechanisms to "align incentives, governance structures, and funding models" and explicitly note that detailed logs could enable attacks that "expose a model's training set" or distill proprietary models.

### Open Question 2
How can MedLog systems reliably automate the linkage of AI recommendations to downstream clinical outcomes when causal links are indirect, data is fragmented, and outcomes are delayed? The paper notes that "Capturing outcomes faces three constraints: the causal link between recommendation and action is often indirect; outcomes may only become observable after significant delays; and relevant data may reside outside the immediate AI workflow."

### Open Question 3
What new methodological frameworks are required to analyze MedLog data for "human-AI epidemiology," specifically to detect clinician over-reliance or workflow automation bias? The authors propose that MedLog "extends [epidemiology] further by treating AI itself as a measurable agent" and suggest using "implementation science approaches" to analyze records for behaviors like "clinician over- or under-reliance on AI."

### Open Question 4
Can the MedLog structure effectively distinguish between dataset drift (changes in patient data) and concept drift (changes in how the model is applied) in complex generative AI workflows? While the paper claims the protocol "allows us to distinguish between shifts in the underlying data distribution and shifts in how models are applied in practice," it relies on future methods like "deep learning-based hypothesis testing" to actually perform this distinction.

## Limitations
- Effectiveness depends on multi-stakeholder adoption—without vendor compliance, cross-system comparability remains theoretical
- Privacy safeguards are described conceptually but not tested against real PHI leakage scenarios
- Outcome linkage reliability depends on temporal correlation methods that may produce false positives
- Paper lacks empirical validation of sampling strategies and retention policies

## Confidence

**High Confidence:**
- The nine-field schema structure and its alignment with syslog design principles are well-defined and technically sound
- The use of established standards (W3C PROV, OpenTelemetry, FHIR) provides solid interoperability foundations

**Medium Confidence:**
- The incremental record assembly mechanism is logically coherent but practical implementation challenges remain untested
- Risk-based sampling concepts are plausible but lack validation data

**Low Confidence:**
- Real-world adoption barriers and privacy implementation specifics are not empirically supported
- Outcome linkage reliability estimates are not empirically validated

## Next Checks
1. **Sampling Policy Validation:** Implement the collector with configurable sampling rates and systematically measure detection sensitivity for synthetic drift events under different sampling frequencies (100%, 10%, 1%)
2. **Privacy Safeguard Testing:** Deploy a MedLog emitter that logs synthetic clinical prompts containing embedded PHI patterns, then measure false-positive/negative rates of automated PHI detection and redaction
3. **Outcome Linkage Accuracy:** For a controlled AI use case, compare the precision of temporal proximity linking versus provider-verified outcome associations across 100+ MedLog records