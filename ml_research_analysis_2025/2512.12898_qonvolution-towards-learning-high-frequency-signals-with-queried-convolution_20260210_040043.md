---
ver: rpa2
title: 'Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution'
arxiv_id: '2512.12898'
source_url: https://arxiv.org/abs/2512.12898
tags:
- image
- high-frequency
- queries
- neural
- psnr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of learning high-frequency signals
  in computer vision and graphics, where neural networks often struggle due to spectral
  bias or optimization difficulties. The proposed solution, Queried-Convolutions (Qonvolutions),
  is a simple yet powerful modification that uses the neighborhood properties of convolution
  to convolve a low-frequency signal with queries (such as coordinates) to enhance
  the learning of intricate high-frequency signals.
---

# Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution

## Quick Facts
- **arXiv ID**: 2512.12898
- **Source URL**: https://arxiv.org/abs/2512.12898
- **Reference count**: 40
- **Primary result**: Qonvolutions enhance high-frequency learning in neural networks, achieving state-of-the-art novel view synthesis performance when combined with Gaussian splatting

## Executive Summary
Qonvolution addresses the challenge of spectral bias in neural networks, where models struggle to learn high-frequency signals. The proposed method, Queried-Convolutions (Qonvolutions), convolves low-frequency signals with coordinate queries to enhance high-frequency learning. This simple modification leverages the neighborhood properties of convolution to capture local spatial structure that MLPs miss. The approach was evaluated across multiple tasks including 1D regression, 2D super-resolution, and novel view synthesis, with the NVS application achieving state-of-the-art results on complex real-world scenes.

## Method Summary
Qonvolutions concatenate low-frequency signal values with encoded coordinate queries, then apply convolution to produce high-frequency residuals that are added to the original signal. The method requires a pre-trained baseline model (like 3DGS) to provide the low-frequency signal. During training, the baseline trains alone for 75% of iterations before QNN is introduced and both are fine-tuned jointly. The architecture uses a 4-layer 2D CNN with 3×3 kernels and 64 channels, processing the concatenated input to predict residual images.

## Key Results
- QNN outperformed all MLP variants (vanilla, Fourier, hash-grid, SIREN) in 1D regression tasks
- In 2D super-resolution, QNN achieved higher PSNR than baseline models on standard benchmarks
- For novel view synthesis, QNN + 3DGS achieved state-of-the-art performance on complex real-world scenes, outperforming Zip-NeRF in image quality while training faster

## Why This Works (Mechanism)

### Mechanism 1: Joint Query-Signal Convolution for Local Context Aggregation
- **Claim**: Convolving low-frequency signals with coordinate queries enables superior high-frequency learning compared to processing queries alone through MLPs.
- **Mechanism**: QNN concatenates encoded neighboring queries with neighboring low-frequency signal values, then applies convolution. Each output location receives both the spatial query pattern and the actual low-frequency signal values from its receptive field.
- **Core assumption**: High-frequency components exhibit local dependencies that can be predicted from neighboring low-frequency values and their spatial arrangement.
- **Evidence anchors**: [abstract] states Qonvolution convolves low-frequency signals with queries; [section 4.1] provides formal definition with explicit neighborhood notation.
- **Break condition**: If high-frequency residuals are statistically independent of local low-frequency context, the mechanism provides no signal.

### Mechanism 2: Theoretical Risk Reduction Through Progressive Feature Augmentation
- **Claim**: Adding neighborhood information, then query coordinates to the feature map monotonically reduces the best achievable approximation error.
- **Mechanism**: Theorem 1 proves R*(ϕ₁,f) ≥ R*(ϕ₂,f) ≥ R*(ϕ₃,f) = 0 where ϕ₁ = (f_low), ϕ₂ = (f_low neighborhood), ϕ₃ = (neighborhood + coordinates).
- **Core assumption**: Target function is deterministic and measurable with no data or computational constraints.
- **Evidence anchors**: [section 4.2] contains full Theorem 1 with proof using conditional variance decomposition.
- **Break condition**: Real-world constraints violate assumptions, making bounds loose.

### Mechanism 3: Convolution Inductive Bias Exploits Local Spatial Structure
- **Claim**: Convolution's weight sharing and local receptive fields capture dependencies MLPs cannot, critical for reconstructing spatially-coherent high-frequency details.
- **Mechanism**: MLPs process each coordinate independently; CNNs aggregate over neighborhoods. QNN applies CNN to concatenated query+signal, combining positional awareness with local filtering.
- **Core assumption**: High-frequency components of interest (edges, textures) have local spatial structure.
- **Evidence anchors**: [table 5] shows ablation where 2D conv outperforms 1×1 linear layers and all MLP variants.
- **Break condition**: If target signal has purely global frequency modes without local structure, convolution's bias becomes harmful.

## Foundational Learning

### Concept 1: Spectral Bias in Neural Networks
- **Why needed here**: The paper's motivation is overcoming spectral bias—MLPs converge on low frequencies faster than high frequencies.
- **Quick check question**: Training an MLP on a signal with frequencies at 1Hz, 10Hz, and 100Hz, which converges first?

### Concept 2: Positional/Query Encodings (γ)
- **Why needed here**: QNN applies γ to queries before concatenation. Prior work showed Fourier encodings help MLPs learn higher frequencies.
- **Quick check question**: Why pass coordinates through γ instead of feeding them directly?

### Concept 3: Gaussian Splatting for NVS
- **Why needed here**: Main experiments use 3DGS as the low-frequency baseline. Understanding that 3DGS rasterizes 3D Gaussians to produce a continuous but bandlimited image clarifies why QNN refines it.
- **Quick check question**: What does 3DGS output, and why might it miss high-frequency details?

## Architecture Onboarding

### Component Map
low_freq [C_low×H×W] + query [C_in×H×W] → concatenate (channel dim) → combined [C_low+C_in × H×W] → optional encoding γ → 4-layer 2D Conv (3×3, 64ch, ReLU) → residual [C_out×H×W] → add → output = low_freq + residual

### Critical Path
1. Low-frequency signal and queries must align spatially before concatenation
2. Concatenation is along channels (dim=1 in PyTorch), not spatial dimensions
3. Residual is added to low-freq signal (not concatenated/multiplied at output)
4. End-to-end: QNN activates after 75% of base model iterations (e.g., 22.5k/30k)

### Design Tradeoffs
- **Query type**: 2D coords (best validation) vs 3D location (best training) vs raymap. 2D generalizes better.
- **Encoding**: Vanilla (identity) outperformed Fourier in ablations—convolution may handle frequencies differently than MLPs.
- **Depth**: 4 conv layers optimal; 2–3 underfit, 5–6 show no gain.
- **Channel budget**: 64ch in QNN vs 256dim in MLP baseline keeps param counts comparable (conv weight sharing).

### Failure Signatures
- **Training great, validation poor**: Likely using 3D location queries—switch to 2D coordinates.
- **No improvement over baseline**: Verify bf_low is informative; if low-freq signal is uninformative noise, QNN has nothing to leverage.
- **Crash on single-pixel query**: Expected—QNN requires neighborhood; cannot process isolated points.

### First 3 Experiments
1. **1D regression replication**: Implement Fig. 3—train MLP (vanilla, Fourier), CNN, QNN on synthetic 1/f^0.5 signal. Confirm QNN > Fourier-MLP on PSNR.
2. **Input ablation**: Train QNN with (a) queries only, (b) low-freq only, (c) both. Expect (c) > (a), (b) per Table 5.
3. **Residual visualization**: On NVS, visualize QNN output—should see edge-enhancement patterns (high-freq detail) not uniform color shifts.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical risk reduction proof relies on idealized assumptions (deterministic, measurable target function with no data/computational constraints)
- Method requires neighborhood information, making it incompatible with single-point queries
- Discrepancy between training and validation performance with different query types (3D location trains better, 2D generalizes better) is not fully explained

## Confidence

| Claim | Confidence |
|-------|------------|
| Core mechanism (joint query-signal convolution) | High |
| Theoretical risk reduction under stated assumptions | Medium |
| Generalization advantage of 2D over 3D queries | Medium |
| Exact normalization strategy and weight initialization | Low |

## Next Checks
1. **Generalization Test**: Train QNN on a complex scene using 3D location queries, then evaluate on a held-out scene to quantify the generalization gap compared to 2D coordinate queries.
2. **Noise Sensitivity**: Add varying levels of structured noise to the low-frequency signal and measure QNN's ability to extract high-frequency components, validating the assumption about local dependencies.
3. **Alternative Architectures**: Replace the 2D CNN with attention-based mechanisms while keeping the query-signal concatenation structure to test whether convolution's specific inductive bias is essential.