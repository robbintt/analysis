---
ver: rpa2
title: 'GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems'
arxiv_id: '2507.13190'
source_url: https://arxiv.org/abs/2507.13190
tags:
- reasoning
- multi-agent
- systems
- communication
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces GEMMAS, a graph-based evaluation framework\
  \ for multi-agent language model systems that assesses collaboration quality beyond\
  \ final-task accuracy. By modeling agent interactions as a directed acyclic graph,\
  \ GEMMAS defines two structural metrics\u2014Information Diversity Score (IDS) and\
  \ Unnecessary Path Ratio (UPR)\u2014to capture semantic uniqueness and reasoning\
  \ redundancy."
---

# GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems

## Quick Facts
- arXiv ID: 2507.13190
- Source URL: https://arxiv.org/abs/2507.13190
- Reference count: 8
- Introduces graph-based metrics (IDS, UPR) to evaluate multi-agent collaboration beyond final-task accuracy

## Executive Summary
This paper introduces GEMMAS, a graph-based evaluation framework for multi-agent language model systems that assesses collaboration quality beyond final-task accuracy. By modeling agent interactions as a directed acyclic graph, GEMMAS defines two structural metrics—Information Diversity Score (IDS) and Unnecessary Path Ratio (UPR)—to capture semantic uniqueness and reasoning redundancy. Experiments on five mathematical reasoning benchmarks using small open-source LLMs reveal that systems with similar accuracy can vary significantly in internal collaboration patterns, demonstrating that outcome-only metrics are insufficient for evaluating multi-agent performance.

## Method Summary
GEMMAS represents multi-agent systems as directed acyclic graphs where nodes are reasoning steps and edges represent information flow. The framework defines two key metrics: Information Diversity Score (IDS) measures semantic uniqueness of reasoning paths, while Unnecessary Path Ratio (UPR) quantifies reasoning redundancy. The approach applies to any multi-agent system where agents collaborate through sequential or parallel reasoning steps, with evaluation based on both final accuracy and internal collaboration structure.

## Key Results
- Systems differing by only 2.1% in accuracy showed 12.8% difference in IDS and 80% difference in UPR on GSM8K
- Significant variation in collaboration patterns exists between systems with similar accuracy across all five tested benchmarks
- Small open-source models (Llama 3.1-8B-Instruct, Qwen 2.5-7B-Instruct) demonstrated measurable differences in IDS and UPR despite comparable final performance

## Why This Works (Mechanism)
The framework works by capturing structural properties of agent collaboration that accuracy metrics miss. By representing reasoning as a graph, GEMMAS can identify redundant reasoning paths (high UPR) and lack of semantic diversity (low IDS) that would be invisible to traditional evaluation. The directed acyclic graph structure naturally models sequential and parallel reasoning patterns, allowing quantitative assessment of how information flows through the multi-agent system.

## Foundational Learning

**Directed Acyclic Graphs (DAGs)**: Why needed - To model agent interactions without cycles that could cause infinite loops; Quick check - Verify graph has no cycles before applying GEMMAS metrics

**Semantic uniqueness**: Why needed - To quantify whether agents are contributing novel information versus repeating existing reasoning; Quick check - Compare token embeddings of different paths for similarity

**Reasoning redundancy**: Why needed - To identify inefficient collaboration where multiple agents perform similar reasoning steps; Quick check - Count parallel paths with high semantic overlap

## Architecture Onboarding

**Component map**: Input -> Agent 1 -> Agent 2 -> ... -> Agent N -> Output, with intermediate reasoning steps forming DAG nodes

**Critical path**: Information flow from initial problem statement through agent interactions to final answer, with GEMMAS metrics applied to the entire reasoning graph

**Design tradeoffs**: The framework prioritizes interpretability and structural analysis over computational efficiency, requiring graph construction and semantic analysis for each evaluation

**Failure signatures**: High UPR indicates inefficient resource usage, while low IDS suggests poor collaboration diversity; both can mask high accuracy

**First experiments**: 1) Compare IDS/UPR across different agent ordering strategies, 2) Test metric sensitivity to reasoning step granularity, 3) Evaluate performance on open-ended tasks with multiple valid solution paths

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Validation limited to five mathematical reasoning benchmarks, constraining generalizability
- Reliance on ground-truth intermediate steps may limit applicability to open-ended tasks
- Assumption that all DAG paths represent meaningful reasoning may not hold for optimized systems

## Confidence

**IDS and UPR metrics capture meaningful collaboration patterns beyond accuracy**: Medium confidence
**Collaboration patterns vary significantly between systems with similar accuracy**: High confidence
**Graph-based evaluation provides actionable insights for system design**: Medium confidence

## Next Checks
1. Test GEMMAS across diverse domains (e.g., code generation, creative writing) to evaluate metric robustness beyond mathematical reasoning
2. Conduct ablation studies comparing IDS/UPR with alternative graph-based metrics to establish their unique contribution to system evaluation
3. Validate the framework's ability to predict system performance degradation under resource constraints (e.g., fewer agents, limited inference steps)