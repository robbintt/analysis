---
ver: rpa2
title: 'AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical
  Visual Question Answering'
arxiv_id: '2510.02328'
source_url: https://arxiv.org/abs/2510.02328
tags:
- medical
- reasoning
- knowledge
- arxiv
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'AMANDA is a training-free agentic framework that enhances data-efficient
  medical visual question answering by addressing two key reasoning bottlenecks: ignoring
  fine-grained image details and lacking specialized medical knowledge. It employs
  coarse-to-fine question decomposition for comprehensive diagnosis and retrieves
  biomedical knowledge graphs to ground reasoning.'
---

# AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering

## Quick Facts
- **arXiv ID**: 2510.02328
- **Source URL**: https://arxiv.org/abs/2510.02328
- **Reference count**: 40
- **Primary result**: Training-free agentic framework achieving 19.36% average accuracy gains over baselines in zero-shot and few-shot Med-VQA settings while reducing hallucinations

## Executive Summary
AMANDA addresses data inefficiency in medical visual question answering by employing a training-free agentic framework that combines coarse-to-fine question decomposition with biomedical knowledge graph retrieval. The system uses five specialized agents to iteratively refine answers through visual reasoning and external knowledge grounding. Extensive experiments across eight benchmarks demonstrate substantial improvements in both zero-shot and few-shot settings, with significant reductions in hallucination rates.

## Method Summary
AMANDA is a training-free agentic framework for medical visual question answering that uses five coordinated agents: Perceiver (Med-MLLM for initial perception), Reasoner (LLM for answer synthesis), Evaluator (LLM for confidence scoring with adaptive stopping), Explorer (LLM + Med-MLLM for hierarchical question decomposition), and Retriever (LLM + SPOKE KG for biomedical knowledge retrieval). The framework employs coarse-to-fine question decomposition to activate latent visual reasoning capabilities and grounds answers with structured medical knowledge to reduce hallucinations. It operates in iterative cycles with adaptive confidence-based stopping.

## Key Results
- Achieves 19.36% average accuracy improvements over baselines across eight Med-VQA benchmarks
- Demonstrates substantial gains in both zero-shot (7.24%) and few-shot (8.68%) settings
- Significantly reduces hallucination rates through biomedical knowledge grounding

## Why This Works (Mechanism)

### Mechanism 1: Coarse-to-Fine Question Decomposition for Visual Reasoning Depth
Breaking down complex medical questions into hierarchical sub-questions (General Observation → Anatomical Analysis → Detailed Findings) progressively builds visual understanding that single-step inference misses. This structured prompting activates latent fine-grained visual capabilities in Med-MLLMs without adding new visual capacity.

### Mechanism 2: Biomedical Knowledge Graph Retrieval for Hallucination Reduction
Grounding reasoning with structured medical facts from SPOKE knowledge graph (42M nodes, 160M edges) reduces hallucinations by integrating verified disease-symptom associations and anatomical relationships into the reasoning process.

### Mechanism 3: Adaptive Confidence-Based Iteration Control
Dynamically terminating reasoning when confidence scores exceed 3/5 threshold prevents over-refinement degradation while improving efficiency by approximately 4.9x (reducing iterations from 3.0 to 0.61).

## Foundational Learning

- **Medical Visual Question Answering (Med-VQA)**: Understanding the task of answering natural language questions about medical images and why it requires fine-grained pathological analysis beyond general-domain VQA.
  - *Why needed*: Task definition and domain-specific reasoning requirements
  - *Quick check*: How does Med-VQA differ from general VQA in terms of required reasoning depth?

- **Retrieval-Augmented Generation (RAG) for Biomedical Domains**: Understanding how retrieval grounds LLM outputs using external knowledge graphs.
  - *Why needed*: Retriever agent implements RAG using SPOKE; essential for debugging knowledge integration failures
  - *Quick check*: What is the role of embedding similarity filtering in ensuring retrieved knowledge relevance?

- **Multi-Agent Orchestration with Shared Reasoning History**: Understanding how five agents coordinate via centralized reasoning history for self-correction.
  - *Why needed*: Critical for extending or modifying the framework
  - *Quick check*: How does accumulated reasoning history enable self-correction across iterations?

## Architecture Onboarding

- **Component map**: Perceiver (Med-MLLM) → Reasoner (LLM) → Evaluator (LLM) → Explorer (LLM + Med-MLLM) → Retriever (LLM + SPOKE) → Reasoner (LLM)
- **Critical path**: 1. Perceiver generates caption + initial answer; 2. Reasoner synthesizes refined answer; 3. Evaluator checks confidence → if < threshold, proceed; 4. Explorer generates sub-questions → Med-MLLM answers → history updated; 5. Retriever extracts concepts → queries SPOKE → filters results → history updated; 6. Loop to step 2 until threshold or max iterations
- **Design tradeoffs**: Training-free approach enables rapid deployment but limited by base Med-MLLM capabilities; iterative refinement improves efficiency but risks early termination on incorrect answers; SPOKE dependency requires network access and may lack subspecialty coverage
- **Failure signatures**: Excessive iterations without confidence improvement (miscalibrated scoring or irrelevant knowledge); irrelevant sub-questions (Explorer prompt failure); persistent hallucinations (Retriever entity extraction failure or SPOKE coverage gaps)
- **First 3 experiments**: 1. Zero-shot AMANDA on VQA-RAD with GPT-4o engine; log per-iteration confidence scores; 2. Ablate Retriever agent; measure hallucination rate change on ProbMed; 3. Swap SPOKE for UMLS subset; compare accuracy and latency

## Open Questions the Paper Calls Out

- **Open Question 1**: How does performance scale with larger language model backbones (70B parameters) compared to tested 7B/13B models? The authors suggest investigating this for potential additional performance gains.
- **Open Question 2**: Can diverse external resources like clinical guidelines and medical textbooks improve performance beyond current SPOKE reliance? The authors note this could enhance framework capability.
- **Open Question 3**: To what extent can lightweight fine-tuning be integrated to improve data efficiency without sacrificing training-free adaptability? The authors suggest this could achieve better performance with reasonable computational requirements.

## Limitations

- Training-free approach performance ceiling is bounded by base Med-MLLM capabilities, limiting gains for rare pathologies or novel cases
- SPOKE knowledge graph access details are unspecified (API endpoints, authentication, rate limits), potentially blocking reproduction
- Exact embedding similarity threshold for filtering retrieved knowledge is not provided, affecting knowledge relevance quality

## Confidence

- **High confidence**: Coarse-to-fine question decomposition mechanism and adaptive confidence-based iteration control show strong empirical support
- **Medium confidence**: Biomedical knowledge graph retrieval's hallucination reduction claim relies on external KG quality and entity extraction accuracy
- **Medium confidence**: Training-free superiority assumes Med-MLLMs possess sufficient latent visual reasoning capabilities for all medical modalities

## Next Checks

1. Measure hallucination rate reduction when ablating the Retriever agent on ProbMed benchmark to quantify extrinsic Med-KA contribution
2. Evaluate AMANDA with alternative biomedical KGs (e.g., UMLS subset) to assess knowledge graph scale tradeoffs and SPOKE dependency
3. Test Perceiver's visual encoding capacity on rare pathology cases to determine if decomposition adds information or noise when visual features are absent