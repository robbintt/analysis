---
ver: rpa2
title: 'UniCoM: A Universal Code-Switching Speech Generator'
arxiv_id: '2508.15244'
source_url: https://arxiv.org/abs/2508.15244
tags:
- speech
- languages
- language
- cs-fleurs
- code-switching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces UniCoM, a universal pipeline for generating
  high-quality code-switching (CS) speech by substituting words with synonyms across
  languages. The method, called SWORDS, uses part-of-speech-aware substitutions and
  voice conversion to preserve speaker identity.
---

# UniCoM: A Universal Code-Switching Speech Generator

## Quick Facts
- arXiv ID: 2508.15244
- Source URL: https://arxiv.org/abs/2508.15244
- Reference count: 21
- Key outcome: Generates 253 language pairs with 654.7k CS utterances using POS-aware word substitution and voice conversion, achieving MOS 4.44, SIS 4.74, and RER 31.6%

## Executive Summary
This paper introduces UniCoM, a pipeline for generating high-quality code-switching speech by substituting words with synonyms across languages. The method, called SWORDS, uses part-of-speech-aware substitutions and voice conversion to preserve speaker identity. CS-FLEURS, the resulting corpus, contains 253 language pairs with 654.7k utterances. Experiments show that CS-FLEURS achieves an average RER of 31.6%, MOS of 4.44, and SIS of 4.74, performing comparably to human-generated CS datasets and improving CS-ASR performance when used for data augmentation.

## Method Summary
UniCoM is a three-stage pipeline that generates code-switching speech: (1) preprocessing—bandpass filtering (80–7000 Hz) and amplitude normalization; (2) SWORDS algorithm—extract parallel sentences, generate POS-classified word pairs using GPT-4o-mini, align with MMS-FA, and substitute 1-3 words; (3) style unification via kNN-VC voice conversion with HiFi-GAN vocoder. The pipeline operates on FLEURS-R dataset (23 Indo-European languages overlapping with VoxPopuli) and produces CS-FLEURS corpus with 253 language pairs.

## Key Results
- Generated CS-FLEURS corpus: 253 language pairs, 654.7k utterances
- MOS of 4.44 (naturalness) and SIS of 4.74 (speaker identity) across all language pairs
- RER of 31.6% (intelligibility) on fine-tuned XLS-R model
- 27× faster inference than diffusion-based VC alternatives
- Data augmentation with CS-FLEURS improves CS-ASR performance by 2.05% WER reduction

## Why This Works (Mechanism)

### Mechanism 1: POS-aware Word Substitution Preserves Syntactic Structure
Substituting words based on part-of-speech categories produces more natural intra-sentential code-switching than phrase-level substitution. SWORDS identifies word pairs with equivalent meanings across languages, classifies them by POS (noun, verb, adverb, adjective, interjection), then substitutes 1-3 words from the embedded language into the matrix language utterance. This preserves syntactic structure and naturalness by leveraging the cross-linguistic universality of POS categories.

### Mechanism 2: Retrieval-based Voice Conversion Unifies Speaker Identity
kNN-VC preserves speaker identity across language segments while maintaining intelligibility in cross-lingual settings. The method retrieves ground-truth self-supervised features from reference speech using k-nearest neighbors, then synthesizes via a language-invariant neural vocoder (HiFi-GAN). This transfers speaker characteristics without requiring language-specific training, enabling consistent speaker identity across substituted segments.

### Mechanism 3: Phonetic Similarity Constraints Enable Quality Voice Conversion
Restricting language pairs to phonetically and orthographically similar languages improves voice conversion quality. CS-FLEURS limits coverage to 23 Indo-European/Latin-script languages that overlap with VoxPopuli, ensuring VC model operates within its effective domain. This constraint improves naturalness scores by +0.76 MOS compared to out-of-domain languages.

## Foundational Learning

- **Concept: Code-Switching Types (Inter-sentential vs. Intra-sentential)**
  - Why needed here: UniCoM specifically targets intra-sentential CS (switching within a sentence), which requires preserving contextual coherence—unlike simpler inter-sentential approaches that concatenate at sentence boundaries.
  - Quick check question: Can you explain why concatenating two monolingual utterances fails to produce realistic intra-sentential code-switching?

- **Concept: Forced Alignment in Speech Processing**
  - Why needed here: SWORDS requires precise word-level timestamps to extract speech segments for substitution. MMS-FA provides this alignment between text and audio.
  - Quick check question: What trade-offs exist between Whisper-based alignment (slower, potentially more accurate) and MMS-FA (faster, requires Romanization)?

- **Concept: Voice Conversion Architectures (Retrieval-based vs. Diffusion-based)**
  - Why needed here: UniCoM selected kNN-VC over diffusion-based alternatives (Diff-HierVC, SeedVC) based on inference speed requirements for large-scale corpus generation.
  - Quick check question: Why might retrieval-based VC be more suitable for cross-lingual scenarios than encoder-decoder approaches?

## Architecture Onboarding

- **Component map:** Preprocessing → GPT-4o-mini word-pair mapping → MMS-FA alignment → Word substitution → kNN-VC conversion → CS-FLEURS output
- **Critical path:** FLEURS-R → LLM word mapping → MMS-FA alignment → Word substitution → kNN-VC conversion → CS-FLEURS output. The voice conversion stage is the primary computational bottleneck.
- **Design tradeoffs:**
  - Word-level vs. phrase-level: Word-level preserves syntactic structure but may miss idiomatic expressions
  - kNN-VC vs. diffusion VC: 27× faster but slightly lower intelligibility (RER 25.0 vs 17.5-20.4)
  - In-domain vs. out-of-domain: Restricting to 23 phonetically similar languages improves quality (MOS +0.76) but limits corpus diversity
- **Failure signatures:**
  - Buzzing/crackling artifacts: Input audio contained noise that VC amplified → requires stricter preprocessing
  - Low MOS with high SIS: VC working but unnatural prosody → check language pair phonetic similarity
  - High RER (>40%): Alignment failures or poor word-pair mappings → audit LLM outputs and alignment quality
  - Blank token outputs in ASR training: Domain mismatch between training and evaluation sets
- **First 3 experiments:**
  1. Alignment quality audit: Run MMS-FA on 50 sentence pairs from two languages, manually verify word boundaries align with expected timestamps. Flag Romanization errors.
  2. VC quality benchmark: Apply kNN-VC to 10 language pairs (5 in-domain, 5 out-of-domain), measure MOS/SIS with 5+ human raters per sample. Establish quality floor.
  3. End-to-end pipeline test: Generate 100 CS samples for one language pair, measure RER using fine-tuned XLS-R model. Compare against human-generated CS baseline (e.g., Spoken Wikipedia Corpus for En-De).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can UniCoM be effectively extended to out-of-domain (OOD) languages with diverse orthographies using a massively multilingual voice conversion model?
- Basis in paper: [explicit] The authors explicitly identify this as a future direction: "In future research, we aim to expand the scope of UniCoM by constructing a multilingual voice conversion model, enabling the application of UniCoM to languages with diverse orthographies."
- Why unresolved: The current implementation is constrained to "in-domain" languages (mostly Latin script) because the kNN-VC model degrades significantly when handling the phonetic mismatches of OOD languages.
- What evidence would resolve it: Generating a CS corpus for non-Latin script languages (e.g., tonal or semitic languages) that achieves MOS and SIS scores comparable to the current in-domain results.

### Open Question 2
- Question: Is it possible to implement syntax-aware phrase-level substitution to generate longer code-switching segments without introducing grammatical errors?
- Basis in paper: [inferred] The authors note in Section 3.2.1 that they abandoned phrase-level substitution because "semantically equivalent substitution... often disregards language-specific grammar," limiting the method to word-level POS tagging.
- Why unresolved: The current SWORDS algorithm relies on the cross-linguistic commonality of parts-of-speech; it cannot yet handle the complex syntactic rearrangements required for natural phrase-level code-switching (Table 1).
- What evidence would resolve it: A modified generation pipeline that successfully swaps multi-word phrases while maintaining the syntactic validity of the matrix language.

### Open Question 3
- Question: How can the domain mismatch between synthetic CS-FLEURS data and human-generated corpora be minimized to improve cross-dataset generalization?
- Basis in paper: [inferred] Table 6 shows that while data augmentation improves performance, models trained on synthetic data struggle when evaluated on human-generated sets (and vice versa), which the authors attribute to domain mismatch.
- Why unresolved: The paper demonstrates the existence of this mismatch but does not isolate the specific acoustic or linguistic features causing the generalization gap.
- What evidence would resolve it: Ablation studies or domain adaptation techniques that result in consistent ASR performance regardless of whether the training data is synthetic or human-generated.

## Limitations
- Dataset scope is highly restricted to 23 Indo-European languages with Latin scripts, excluding major language families
- Human evaluation has limited statistical power with only 12 raters across 253 language pairs
- Word-pair mapping quality lacks systematic semantic preservation evaluation
- Evaluation methodology may be biased due to domain mismatch between synthetic CS speech and XLS-R training data

## Confidence
- **High Confidence:** Pipeline technical soundness, kNN-VC speed advantage, out-of-domain MOS degradation
- **Medium Confidence:** SWORDS naturalness advantage, kNN-VC speaker identity preservation, phonetic similarity benefits
- **Low Confidence:** "Universal" code-switching claim, semantic preservation across all pairs, comparability to human-generated datasets

## Next Checks
1. Semantic Preservation Audit: Analyze 100 randomly selected SWORDS-generated sentence pairs across 5 language pairs. Use bilingual experts to rate semantic similarity (1-5 scale) between original and substituted sentences. Compare against human-generated code-switching from the Spoken Wikipedia Corpus.

2. Cross-Lingual VC Robustness Test: Apply UniCoM to 3 typologically diverse language pairs (e.g., Mandarin-English, Arabic-French, Japanese-Spanish). Measure MOS, SIS, and RER with 10+ human raters per sample. Compare results against the Indo-European baseline to quantify performance degradation.

3. Domain Adaptation Evaluation: Fine-tune XLS-R on 1000 human-generated CS utterances (if available) or augmented UniCoM data. Re-evaluate RER on the same test set. Measure improvement to assess whether current evaluation underestimates intelligibility due to domain mismatch.