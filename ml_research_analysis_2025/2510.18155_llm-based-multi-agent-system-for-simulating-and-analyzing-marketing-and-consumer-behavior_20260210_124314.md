---
ver: rpa2
title: LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer
  Behavior
arxiv_id: '2510.18155'
source_url: https://arxiv.org/abs/2510.18155
tags:
- agents
- agent
- simulation
- consumer
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces an LLM-powered multi-agent framework for simulating
  consumer decision-making and social dynamics in response to marketing promotions.
  Unlike traditional agent-based models, it uses generative agents with memory, planning,
  and reasoning capabilities to model behaviors such as habit formation, word-of-mouth
  diffusion, and social influence without predefined rules.
---

# LLM-Based Multi-Agent System for Simulating and Analyzing Marketing and Consumer Behavior

## Quick Facts
- arXiv ID: 2510.18155
- Source URL: https://arxiv.org/abs/2510.18155
- Reference count: 12
- Primary result: LLM-based agents simulate emergent consumer behavior and social dynamics without predefined rules, capturing marketing effects like loyalty and word-of-mouth.

## Executive Summary
This paper introduces a multi-agent simulation framework powered by large language models to model consumer decision-making and social dynamics in marketing contexts. Unlike traditional agent-based models, it employs generative agents with memory, planning, and reasoning capabilities to simulate behaviors such as habit formation, social influence, and word-of-mouth diffusion without hardcoded rules. In a case study involving a 20% discount promotion at a fried chicken shop, the system successfully captured realistic individual and emergent social patterns, demonstrating 51% revenue increase and authentic loyalty behaviors.

## Method Summary
The framework combines DeepSeek-V3 LLM with a memory-augmented architecture where agents maintain persistent identities through tagged memory streams (EVENT, REFLECTION, CONVERSATION, PURCHASE). Agents possess physiological and financial "Needs Systems" with decaying state variables (Energy, Money, Groceries) that ground decisions in bounded rationality. A shared location tracker enables real-time social coordination and information diffusion. The simulation runs in parallel with thread-safe locks, executing daily routines where agents plan activities, make dining choices based on constraints, and engage in social interactions that can spread promotional awareness organically.

## Key Results
- 20% discount led to 51% revenue increase for promoted shop
- Agents demonstrated realistic loyalty and repeat visitation behaviors without predefined rules
- Social coordination patterns emerged, with agents spreading discount information through word-of-mouth

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Memory-augmented retrieval enables emergent brand loyalty and habit formation without hard-coded rules.
- **Mechanism:** Agents utilize a structured memory stream where purchase history and conversations are tagged (e.g., `EVENT`, `PURCHASE`). When a "hunger" trigger occurs, the system retrieves relevant past experiences (e.g., "previously enjoyed Fried Chicken") and injects them into the LLM prompt. This biases the probabilistic next-token prediction toward repeat visitation, simulating habit.
- **Core assumption:** The LLM weights retrieved context heavily enough to override generic dining preferences, effectively functioning as a "soft constraint" on decision-making.
- **Evidence anchors:**
  - [abstract] "...generative agents... form habits... without predefined rules."
  - [section] III.D (Agent Memory...): "This curated context is then embedded into the LLM prompt... [enabling] agents to form evolving relationships... and remember previously discussed plans."
  - [corpus] Weak direct evidence in neighbors for specific *habit* loops, though "Towards Simulating Social Influence Dynamics" supports memory-driven social consistency.
- **Break condition:** If the memory retrieval logic fails to surface recent high-reward events (e.g., a satisfying meal), agents revert to random selection based solely on immediate proximity, breaking the loyalty simulation.

### Mechanism 2
- **Claim:** Physiological and financial "Needs Systems" ground LLM reasoning in bounded rationality.
- **Mechanism:** Agents possess decaying state variables (Energy, Money, Groceries). Before an action is executed, a logic layer checks if the `FinalPrice` exceeds the agent's `Money` balance or if `Energy` is critically low. If constraints are violated, the LLM is forced to re-plan (e.g., choose a cheaper venue or sleep), preventing the simulation from becoming a fantasy scenario.
- **Core assumption:** The LLM can correctly interpret and adhere to numeric constraints provided in the prompt context; otherwise, agents may attempt impossible actions (e.g., buying with $0).
- **Evidence anchors:**
  - [section] III.E.2: "If the computed FinalPrice exceeds the agent’s available funds, the agent may delay, cancel, or switch to a cheaper option."
  - [section] V.B: "...agents experience natural energy decay... If agents... miss multiple meals... [they become] non-functional."
  - [corpus] "IndoorWorld" supports the integration of physical task solving (resource management) with social simulation.
- **Break condition:** If energy decay rates are miscalibrated against the agent's income cycle, the population collapses into a "dead agent" state, freezing the simulation.

### Mechanism 3
- **Claim:** A Shared Location Tracker facilitates real-time social coordination and word-of-mouth diffusion.
- **Mechanism:** A centralized, thread-safe tracker functions as a "GPS." Agents query this state to identify peers at the same location, triggering dynamic dialogue generation. This allows information (like a discount) to spread socially (e.g., Lisa inviting friends) rather than via global broadcast, creating a "small world" network effect.
- **Core assumption:** The parallel execution engine successfully resolves race conditions (via locks), ensuring Agent A perceives Agent B at the café exactly when B is there.
- **Evidence anchors:**
  - [section] IV.D: "...simulation revealed unexpected social coordination patterns... [Lisa] extended similar invitations to multiple other agents..."
  - [section] III.C.2: "...tracker... allows agents to determine who is present... essential for triggering agents’ spontaneous conversations."
  - [corpus] "Towards Simulating Social Influence Dynamics" validates that LLM agents can simulate conformity and social pressure.
- **Break condition:** If thread locking fails or latency spikes, agents "miss" each other spatially, resulting in a silent population with zero social diffusion.

## Foundational Learning

- **Concept: Generative Agents (Memory + Reflection)**
  - **Why needed here:** Unlike standard scripts, these agents require a persistent identity. You must understand how the "Memory Stream" retains specific purchase events to debug why an agent suddenly changes loyalty.
  - **Quick check question:** If an agent "forgets" a discount exists, is it a prompt failure or a memory retrieval failure?

- **Concept: Bounded Rationality**
  - **Why needed here:** The simulation relies on agents making imperfect but realistic trade-offs (e.g., quality vs. price vs. energy). Understanding this helps distinguish between an LLM "hallucination" and a valid budget-constrained decision.
  - **Quick check question:** Does the agent choose the Fried Chicken shop because it "likes" it, or because it literally cannot afford the alternative with its current wallet balance?

- **Concept: Concurrency & Thread Safety**
  - **Why needed here:** The paper explicitly mentions parallel execution. If you scale this system, you will encounter race conditions where two agents try to update the same shop's revenue simultaneously.
  - **Quick check question:** If two agents enter a shop at the exact same simulation tick, does the revenue log double-count or miss one entry?

## Architecture Onboarding

- **Component map:**
  Prompt Manager -> LLM Engine (DeepSeek-V3) -> Execution System -> State/Memory Update -> Shared Location Tracker

- **Critical path:**
  Trigger (Hunger/Time) -> Prompt Construction -> LLM Inference -> **Safety Check (Money/Energy)** -> Execution -> State/Memory Update. *Note: The Safety Check is the primary guardrail against hallucination.*

- **Design tradeoffs:**
  - **Generative Freedom vs. Grounding:** The system allows "hallucinations" (e.g., inventing a bistro) to preserve natural language flexibility but risks simulation incoherence.
  - **Prompt Length vs. Context:** Long prompts (7,098 chars) ensure high-fidelity decisions but increase latency and cost per simulation step.

- **Failure signatures:**
  - **The "Dead Agent" Loop:** Agents repeatedly fail to plan meals due to low energy/funds, requiring manual forced teleportation to residence.
  - **Semantic Drift:** Agents invent locations not in the map config (e.g., "new bistro") and get stuck in invalid movement loops.

- **First 3 experiments:**
  1. **Baseline Calibration:** Run a 7-day simulation with *no* discounts to establish natural market share equilibrium between the three shops.
  2. **Stress Test (Starvation):** Reduce all agents' starting capital by 50% to observe if the system maintains stability or if the "Dead Agent" rescue logic triggers correctly.
  3. **Isolation Test:** Disable the "Shared Location Tracker" to verify that social coordination (Lisa's breakfast party) disappears, confirming social influence is truly emergent and not pre-scripted.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What formal grounding mechanisms can prevent LLM hallucination in simulations?
- **Basis in paper:** [explicit] "We consider the need for a formal grounding mechanism, or constrained decoding strategy, a promising direction for future work."
- **Why unresolved:** Agents invent nonexistent locations and menu items despite detailed prompt constraints.
- **What evidence would resolve it:** Ablation studies comparing constrained decoding and hybrid symbolic-generative approaches on hallucination rates.

### Open Question 2
- **Question:** Do simulation patterns generalize across different LLM architectures?
- **Basis in paper:** [explicit] "Other models like llama2 occasionally diverged under identical prompt structures—suggesting that simulation reproducibility is not only prompt-dependent but also model-specific."
- **Why unresolved:** Experiments used only DeepSeek-V3; cross-model consistency untested.
- **What evidence would resolve it:** Running identical simulations across multiple LLM families and comparing emergent patterns.

### Open Question 3
- **Question:** Can simulations produce quantitatively accurate marketing predictions?
- **Basis in paper:** [inferred] The paper validates qualitative patterns against literature but lacks validation against actual transaction data.
- **Why unresolved:** Without empirical validation, predictive accuracy for real campaigns is unknown.
- **What evidence would resolve it:** Comparing simulated vs. actual lift metrics from deployed marketing campaigns.

### Open Question 4
- **Question:** Can age-specific fine-tuning improve behavioral authenticity for edge demographics?
- **Basis in paper:** [explicit] "Future work may benefit from persona-specific adapters or age-targeted finetuning."
- **Why unresolved:** Child and elderly agents display age-inappropriate behaviors due to training data bias.
- **What evidence would resolve it:** Fine-tuned models tested on age-appropriate behavioral benchmarks.

## Limitations
- Evaluation relies on a single marketing scenario without comparative baselines from traditional agent-based models
- Revenue metrics (51% increase) lack statistical significance testing across multiple simulation runs
- System behavior heavily depends on prompt engineering quality and memory retrieval parameters

## Confidence
- **High confidence**: The architectural feasibility of integrating memory systems, needs-based reasoning, and shared location tracking with LLMs is well-supported by the described implementation and related work.
- **Medium confidence**: The observed emergent behaviors (habit formation, social diffusion, loyalty) appear realistic but require more rigorous validation across multiple scenarios and statistical analysis.
- **Low confidence**: Generalization claims to broader marketing applications and scalability to larger populations remain untested.

## Next Checks
1. **Baseline Comparison**: Run identical scenarios using traditional rule-based agent models to quantify LLM-specific advantages in behavior realism and computational efficiency
2. **Parameter Sensitivity**: Systematically vary memory decay rates, energy decay speeds, and discount magnitudes to identify breaking points and optimal configurations
3. **Statistical Validation**: Execute 50+ simulation runs with identical initial conditions to establish confidence intervals for key metrics (revenue changes, market share shifts, loyalty rates)