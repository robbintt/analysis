---
ver: rpa2
title: 'Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation
  with Testing Guarantees'
arxiv_id: '2506.14606'
source_url: https://arxiv.org/abs/2506.14606
tags:
- code
- arxiv
- training
- data
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces GG (Guaranteed Guess), a language model-based
  CISC-to-RISC transpiler that directly converts x86 assembly to ARM/RISC-V assembly.
  GG uses a custom-trained LLM with architecture-aware design, extended tokenization,
  and RoPE extrapolation to generate candidate translations, then embeds them in a
  test-driven validation framework to ensure functional correctness.
---

# Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees

## Quick Facts
- arXiv ID: 2506.14606
- Source URL: https://arxiv.org/abs/2506.14606
- Authors: Ahmed Heakl; Sarim Hashmi; Chaimaa Abi; Celine Lee; Abdulrahman Mahmoud
- Reference count: 19
- Primary result: GG achieves 99.39% test accuracy on HumanEval and 49.23% on BringUpBench with 98% code coverage, outperforming Rosetta 2 in real-world Apple M2 Pro case study

## Executive Summary
Guaranteed Guess (GG) introduces a language model-based approach for CISC-to-RISC transpilation that directly converts x86 assembly to ARM/RISC-V assembly with functional correctness guarantees. The system combines a custom-trained LLM with architecture-aware design, extended tokenization, and RoPE extrapolation to generate candidate translations, which are then validated through a test-driven framework. Evaluated on both synthetic benchmarks and a real-world Apple M2 Pro case study, GG demonstrates superior performance metrics including 1.73x faster runtime and 1.47x better energy efficiency compared to Rosetta 2.

## Method Summary
GG employs a transformer-based language model trained specifically for assembly language translation, incorporating architecture-specific knowledge through extended tokenization and position encoding techniques. The model generates multiple candidate translations for each x86 instruction sequence, which are then embedded within a comprehensive testing framework that verifies functional correctness. This test-driven approach ensures that translated binaries maintain semantic equivalence to their original counterparts while achieving the performance benefits of RISC architectures.

## Key Results
- Achieves 99.39% test accuracy on HumanEval benchmark and 49.23% on BringUpBench
- Maintains over 98% code coverage across evaluated workloads
- Delivers 1.73x faster runtime, 1.47x better energy efficiency, and 2.41x lower memory usage than Rosetta 2 in Apple M2 Pro case study

## Why This Works (Mechanism)
GG's success stems from its hybrid approach combining deep learning with formal verification principles. The language model provides the flexibility to handle complex translation patterns and context-dependent decisions that rule-based systems struggle with, while the testing framework ensures correctness through empirical validation. The extended tokenization captures low-level architectural details, and RoPE extrapolation enables the model to handle sequences beyond its training length, addressing the variable-length nature of assembly instructions.

## Foundational Learning

**Transformer architecture**: Why needed - Handles long-range dependencies in assembly code; Quick check - Verify attention mechanisms properly capture instruction relationships

**Assembly language semantics**: Why needed - Ensures accurate translation between different ISAs; Quick check - Confirm understanding of x86 and RISC instruction sets

**Test-driven development**: Why needed - Provides correctness guarantees for generated code; Quick check - Validate test suite coverage and effectiveness

**Position encoding**: Why needed - Maintains instruction ordering in variable-length sequences; Quick check - Verify RoPE extrapolation works for extended sequences

**Language model fine-tuning**: Why needed - Adapts general-purpose models to assembly translation; Quick check - Confirm model performance on held-out validation set

## Architecture Onboarding

**Component map**: x86 assembly -> Tokenizer -> LLM -> Candidate Generator -> Test Framework -> ARM/RISC-V assembly

**Critical path**: Input assembly → Tokenization → LLM inference → Candidate generation → Test execution → Validation → Output selection

**Design tradeoffs**: Accuracy vs. performance in translation vs. computational overhead of testing; longer test sequences provide better coverage but increase validation time

**Failure signatures**: Incorrect translations typically manifest as test failures; common issues include register allocation errors and instruction set mismatches

**First experiments**: 1) Benchmark translation accuracy on HumanEval, 2) Measure code coverage across instruction sets, 3) Compare runtime performance against Rosetta 2

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation primarily focuses on synthetic benchmarks and single real-world case study, limiting generalizability
- Claims of "near-native performance" lack broader cross-platform validation
- Test coverage metrics don't address semantic equivalence beyond specific test cases used

## Confidence

**High confidence**: Test accuracy metrics on established benchmarks, code coverage statistics, and comparative performance metrics for Apple M2 Pro case study

**Medium confidence**: Claims about scalability and real-world applicability beyond tested scenarios

**Medium confidence**: Performance comparisons with Rosetta 2 given limited evaluation scope

## Next Checks
1. Test GG across broader range of real-world applications and multiple hardware architectures to assess generalizability
2. Implement formal verification methods to complement test-driven validation and assess semantic equivalence beyond test coverage
3. Conduct long-term performance monitoring and security analysis of translated binaries in production environments