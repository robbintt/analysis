---
ver: rpa2
title: 'TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in
  Legal and Financial Domain'
arxiv_id: '2511.09854'
source_url: https://arxiv.org/abs/2511.09854
tags:
- contrastive
- arxiv
- terminology
- learning
- financial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TermGPT introduces a multi-level contrastive fine-tuning framework
  to improve domain-specific terminology understanding in legal and financial contexts.
  It constructs a sentence graph to capture semantic relationships and uses graph-driven
  data augmentation to generate high-quality positive and negative samples.
---

# TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain

## Quick Facts
- arXiv ID: 2511.09854
- Source URL: https://arxiv.org/abs/2511.09854
- Authors: Yidan Sun; Mengying Zhu; Feiyue Chen; Yangyang Wu; Xiaolei Dan; Mengyuan Yang; Xiaolin Zheng; Shenglin Ben
- Reference count: 22
- Improves terminology-aware fine-tuning by 6.14% F1 on terminology QA and 2.60% on QCA tasks

## Executive Summary
TermGPT addresses the challenge of domain-specific terminology understanding in legal and financial applications by introducing a multi-level contrastive fine-tuning framework. The method constructs sentence graphs to capture semantic relationships and uses graph-driven data augmentation to generate high-quality contrastive pairs. By combining sentence-level and token-level contrastive learning, TermGPT achieves significant improvements on newly constructed financial terminology datasets and the JecQA benchmark, outperforming baselines by 6.14% in terminology QA and 2.60% in QCA tasks.

## Method Summary
TermGPT employs a three-stage training pipeline: (1) Supervised fine-tuning on question-correct answer pairs to establish task alignment, (2) Sentence-level contrastive learning using InfoNCE loss to maximize similarity between questions and correct answers while pushing apart incorrect candidates, and (3) Token-level contrastive learning with mixup-based augmentation to focus on fine-grained terminology discrimination. The framework constructs sentence graphs using entity and similarity-based edges, then generates semantically consistent yet discriminative positive and negative samples through graph traversal. The method uses LoRA fine-tuning with AdamW optimizer and is evaluated on financial regulations and JecQA datasets.

## Key Results
- Outperforms baselines by 6.14% F1 on terminology QA tasks
- Improves QCA task performance by 2.60% over existing methods
- Ablation studies show SFT contributes 8.55% performance drop when removed, while token-level CL contributes 1.31% average F1 drop

## Why This Works (Mechanism)

### Mechanism 1: Graph-structured data augmentation
Sentence graphs capture semantic and topological relationships between sentences through entity and similarity-based edges. By traversing these graphs, the framework generates anchor-candidate pairs where confusable terms become hard negatives in QCA samples. This structural signal improves discrimination compared to random pairing, though poor entity extraction or mis-calibrated similarity thresholds can connect unrelated sentences.

### Mechanism 2: Token-level contrastive learning with mixup
The method converts (question, correct answer) pairs to declarative sentences and replaces correct terms with negative terms using a Mix function. A binary mask tracks token origins, enabling targeted loss computation that forces attention to term-specific semantics. This prevents sparse terminology (0.08% of JecQA) from being overwhelmed by general contextual patterns, though grammatically incoherent sequences could teach spurious patterns.

### Mechanism 3: Sequential training pipeline
The staged approach (SFT → Sentence-level CL → Token-level CL) establishes task alignment before refining global and local representations. SFT teaches the input-output mapping, sentence-level InfoNCE pulls question-correct answer embeddings together while pushing incorrect candidates apart, and token-level mixup sharpens term boundaries. Skipping SFT leaves the model without task grounding, while incorrect ordering may produce term embeddings lacking contextual coherence.

## Foundational Learning

- **Concept: InfoNCE Contrastive Loss**
  - Why needed here: Equation 1 uses InfoNCE to maximize similarity between question and correct answer while minimizing similarity to distractors
  - Quick check question: Can you explain why InfoNCE uses a temperature parameter τ and how it affects hard vs. easy negatives?

- **Concept: Graph Construction for Text (Entity- and Similarity-based Edges)**
  - Why needed here: The sentence graph underpins all augmentation; edges represent semantic relationships (same entity, similar entity, same type)
  - Quick check question: Given two sentences containing "supervisor" and "executive supervisor" respectively, should they connect via edgesen or edgetok?

- **Concept: Mixup for Sequence-Level Contrastive Learning**
  - Why needed here: Token-level CL replaces correct terms with negatives in-context; the binary mask φ enables targeted loss computation
  - Quick check question: If mixup replaces "supervisor" with "director" in "The supervisor oversees compliance," what does φ mark as 0 vs. 1?

## Architecture Onboarding

- **Component map:** Entity extraction (LLM + schema) → sentence graph construction → edgesen (same entity/type), edgetok (similar entity above threshold) → data augmentation → QCA pairs → SFT phase (cross-entropy) → sentence-level CL (InfoNCE) → token-level CL (Mixup + masked token classification)

- **Critical path:** Graph edge quality → augmentation pair quality → SFT convergence → CL effectiveness. Poor entity extraction or threshold calibration propagates errors downstream.

- **Design tradeoffs:**
  - Higher similarity threshold θ → fewer but higher-quality edges vs. reduced augmentation diversity
  - Stronger token-level weighting → better term discrimination vs. risk of overfitting to sparse terms
  - More hard negatives per sample → richer contrastive signal vs. longer training time

- **Failure signatures:**
  - Low augmentation yield: threshold too high, entity extraction misses domain terms
  - QCA accuracy plateaus early: SFT undertrained, or sentence-level CL insufficiently converged before token-level
  - Token-level loss diverges: mixup produces incoherent sequences; check LLM generation quality

- **First 3 experiments:**
  1. **Ablation by component:** Remove token-level CL, sentence-level CL, and SFT separately to confirm relative contributions on your domain
  2. **Threshold sensitivity:** Sweep θsen ∈ {0.6, 0.7, 0.8, 0.9} and measure augmentation quantity vs. downstream F1 to find calibration sweet spot
  3. **Cross-domain transfer:** Train on financial regulations, evaluate on JecQA (and reverse) to test generalization claims; compare against corpus neighbor baselines like StructCoh or MOSAIC

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can terminology-aware LLMs be effectively fortified against adversarial inputs designed to distort the interpretation of key domain terms?
- **Basis in paper:** [explicit] The Conclusion explicitly identifies this as a direction: "An important direction for future work is enhancing the robustness of terminology-aware LLMs against adversarial inputs."
- **Why unresolved:** Current experiments focus on standard discrimination tasks using clean regulatory and QA datasets, overlooking the vulnerability of fine-tuned models to malicious perturbations in real-world applications.
- **What evidence would resolve it:** Evaluation of TermGPT on adversarial benchmarks (e.g., perturbed questions or synonyms) and the introduction of a robust optimization module.

### Open Question 2
- **Question:** How sensitive is the sentence graph construction to the choice of similarity thresholds, and does this require manual tuning for different sub-domains?
- **Basis in paper:** [inferred] The methodology relies on specific similarity thresholds (θ) to connect nodes (edges_en and edges_tok), but does not provide an ablation study on how varying these thresholds impacts graph connectivity or model performance.
- **Why unresolved:** It is unclear if the fixed threshold values are optimal only for the current dataset composition or if they constitute a robust default for other domains.
- **What evidence would resolve it:** A sensitivity analysis showing the correlation between threshold values, graph density statistics, and downstream QCA accuracy.

### Open Question 3
- **Question:** Does the multi-level contrastive approach generalize to domains with inherently higher semantic ambiguity or less rigid structures than financial regulations?
- **Basis in paper:** [inferred] In the Results section, the paper notes that Civil Law performance lags behind other areas, attributing it to "broader scope and greater ambiguity."
- **Why unresolved:** This suggests the method may struggle when terminology is less strictly defined or more context-dependent than the structured regulatory text it was optimized for.
- **What evidence would resolve it:** Experiments applying TermGPT to non-regulatory, high-ambiguity domains (e.g., literary analysis or conversational dialogue) to test the limits of the hard negative sampling strategy.

## Limitations

- Graph construction calibration: The exact similarity threshold θ for edgetok edges is not numerically specified, critically affecting contrastive pair quality
- Entity extraction schema dependence: Performance varies significantly based on entity extraction quality and domain-specific terminology recognition
- Mixup implementation ambiguity: Insufficient specification of term replacement mechanics and mask alignment could impact gradient quality and training stability

## Confidence

- **High confidence:** Staged training pipeline and InfoNCE contrastive loss are well-established with clear implementation guidance; ablation results are directly reported
- **Medium confidence:** Graph-based augmentation approach is conceptually sound but lacks specific threshold values and entity extraction details
- **Low confidence:** Mixup-based token-level contrastive learning has insufficient implementation specification for guaranteed faithful reproduction

## Next Checks

1. **Threshold calibration study:** Systematically sweep θsen and θ values across 0.6-0.9 to measure augmentation yield and downstream F1, establishing optimal calibration for different domains
2. **Component ablation with controlled graph quality:** Reproduce component ablation while monitoring graph construction metrics to isolate whether performance differences stem from CL mechanisms or graph quality
3. **Cross-domain generalization test:** Train on financial regulations, evaluate on JecQA, then reverse-train on JecQA and evaluate on financial regulations to quantify domain transfer capability