---
ver: rpa2
title: Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis
arxiv_id: '2508.19274'
source_url: https://arxiv.org/abs/2508.19274
tags:
- have
- didn
- page
- data
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This thesis advances the application of domain-adapted pretrained
  language models (PLMs) and multimodal fusion strategies for automated cause of death
  classification using verbal autopsy (VA) data. The key findings include: (1) With
  VA narratives alone, transformer-based PLMs fine-tuned on biomedical/clinical corpora
  outperform leading question-only algorithms at both individual and population levels,
  especially for non-communicable diseases; (2) Multimodal fusion strategies combining
  narratives and structured questions further improve classification accuracy, confirming
  that each modality captures unique information; (3) Classification accuracy is strongly
  associated with information sufficiency as perceived by physicians, with models
  performing better on cases rated as having high sufficiency.'
---

# Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis

## Quick Facts
- **arXiv ID**: 2508.19274
- **Source URL**: https://arxiv.org/abs/2508.19274
- **Reference count**: 0
- **Primary result**: Transformer-based PLMs fine-tuned on biomedical/clinical corpora outperform question-only algorithms for cause of death classification using verbal autopsy data

## Executive Summary
This thesis advances automated cause of death classification from verbal autopsy (VA) data by applying domain-adapted pretrained language models (PLMs) and multimodal fusion strategies. The research demonstrates that transformer-based models using unstructured narratives alone can achieve higher classification accuracy than traditional question-only statistical algorithms, particularly for non-communicable diseases. Multimodal approaches combining narratives and structured questions further improve performance, confirming that each modality captures unique diagnostic information. The work also reveals a strong association between classification accuracy and physician-perceived information sufficiency in VA records.

## Method Summary
The study fine-tunes transformer-based PLMs (BioClinicalBERT, BlueBERT, RoBERTa-PM) on South African verbal autopsy narratives and compares their performance to statistical models using structured questions alone. Multimodal fusion strategies are implemented through data-level fusion (concatenating question text with narratives), feature-level fusion (AutoGluon Multimodal), and decision-level fusion (ensemble voting). The models are evaluated using individual-level metrics (accuracy, weighted F1) and population-level metrics (CSMF accuracy) across three levels of COD granularity.

## Key Results
- PLMs using narratives alone achieve 64.6% accuracy vs 47.0% for leading question-only algorithms, with substantial improvements for circulatory diseases, neoplasms, and liver cirrhosis
- Multimodal fusion strategies combining narratives and questions improve classification accuracy to 69.5%, confirming each modality captures unique information
- Classification accuracy strongly correlates with physician-perceived information sufficiency, with models performing better on cases rated as having high sufficiency
- Performance plateaus around 1500-2000 training samples, indicating data quantity constraints for further improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based PLMs using narratives alone can achieve higher COD classification accuracy than question-only statistical algorithms, particularly for non-communicable diseases.
- Mechanism: Narratives contain rich temporal and contextual information that structured questions cannot fully capture. The self-attention mechanism in transformers allows the model to learn contextual relationships between medically relevant terms even when described in non-clinical language.
- Core assumption: VA narratives share sufficient linguistic patterns with the biomedical/clinical corpora used for PLM pre-training to enable effective domain transfer.
- Evidence anchors:
  - [abstract] "transformer-based PLMs with task-specific fine-tuning outperform leading question-only algorithms at both the individual and population levels, particularly in identifying non-communicable diseases"
  - [section 3.3.2] Table 3.5 shows BioClinicalBERT achieving 64.6% accuracy vs InSilicoVA's 47.0%; Figure 3.4 shows substantial improvements for circulatory disease, neoplasms, and liver cirrhosis
  - [corpus] LAVA paper (arxiv 2509.09602) confirms LLM-assisted VA approaches, but evidence for direct causal mechanisms remains limited across settings
- Break condition: Performance degrades significantly for minority classes (pneumonia, diarrhea, meningitis) due to limited training representation; narrative quality varies by interviewer and respondent.

### Mechanism 2
- Claim: Multimodal fusion combining narratives and structured questions improves classification accuracy over either modality alone because each captures distinct diagnostic information.
- Mechanism: Structured questions provide standardized symptom indicators with consistent encoding, while narratives contribute contextual details about timing, severity, and medical history. Feature-level or decision-level fusion allows the model to leverage complementary signals.
- Core assumption: The information captured by each modality is partially non-overlapping and jointly more informative than either alone.
- Evidence anchors:
  - [abstract] "Multimodal fusion strategies combining narratives and questions further improve classification performance, confirming that each modality captures unique information"
  - [section 4.4.2] Table 4.5 shows soft voting ensemble achieving 69.5% accuracy vs 66.5% (question-only LightGBM) and 64.6% (narrative-only BioClinicalBERT)
  - [corpus] Limited direct corpus evidence for VA-specific multimodal mechanisms; adjacent work on crash narratives (arxiv 2509.07845) shows similar gains from combining structured and unstructured data
- Break condition: Data-level fusion with long-sequence PLMs faces token length constraints; ensemble approaches become computationally expensive and require careful calibration of base models.

### Mechanism 3
- Claim: Classification accuracy for both physicians and models is positively associated with physician-perceived information sufficiency in VA data.
- Mechanism: Information sufficiency reflects the presence of diagnostically discriminative features (signature symptoms, clear temporal patterns, confirmed diagnoses) rather than raw quantity of text or number of symptoms. When sufficiency is low, even physicians struggle to assign accurate COD.
- Core assumption: Physician-perceived sufficiency scores are valid proxies for the true diagnostic value of VA information.
- Evidence anchors:
  - [abstract] "strong associations between sufficiency and classification accuracy for both humans and models"
  - [section 5.3.2] Figure 5.3 shows clear accuracy gradients across sufficiency levels for all models; Figure 5.4 shows physicians achieve higher accuracy when sufficiency is rated higher
  - [corpus] No direct corpus evidence for sufficiency-prediction mechanisms in VA; this remains an underexplored area
- Break condition: Sufficiency prediction models achieved only ~44.5% accuracy, suggesting current features (TF-iDF from narratives, structured questions) may not adequately capture the latent factors driving physician judgments.

## Foundational Learning

- Concept: Transformer self-attention and contextual embeddings
  - Why needed here: Understanding why PLMs can extract diagnostic signals from non-clinical narrative text requires grasping how attention mechanisms capture relationships between distant tokens and how pre-training on biomedical corpora transfers domain knowledge.
  - Quick check question: Can you explain why BERT's bidirectional attention might capture different information than unidirectional models for VA narratives?

- Concept: Pretrain-finetune paradigm with domain adaptation
  - Why needed here: The paper relies on PLMs pre-trained on PubMed/MIMIC (BioClinicalBERT, BlueBERT) being fine-tuned on VA narratives. Understanding this transfer is critical for anticipating when it will succeed or fail.
  - Quick check question: Why might a model pre-trained on clinical notes from ICU patients (MIMIC-III) not perfectly transfer to community-based VA narratives?

- Concept: Multimodal fusion strategies (data-level, feature-level, decision-level)
  - Why needed here: The paper compares three fundamentally different approaches to combining text and tabular data, each with distinct implementation requirements and tradeoffs.
  - Quick check question: What is the key advantage of decision-level fusion over data-level fusion when modalities have different optimal model architectures?

## Architecture Onboarding

- Component map:
  Data preprocessing (GPT-3.5-turbo typo correction) -> Unimodal models (PLMs for narratives, ML models for questions) -> Multimodal strategies (data-level fusion with Longformer, feature-level with AutoGluon Multimodal, decision-level with soft voting ensembles) -> Evaluation (individual and population metrics)

- Critical path:
  1. Prepare training data with PCVA labels at appropriate granularity level
  2. For each candidate PLM, run Optuna hyperparameter optimization (30 trials, 5-fold CV, maximize weighted F1)
  3. Train final models with best hyperparameters on full training set
  4. For multimodal approaches, ensure consistent train-test splits across modalities
  5. Evaluate on held-out test set using both individual and population metrics

- Design tradeoffs:
  - Data-level fusion: Simplest implementation, natural for PLMs, but constrained by 4096-token limit even with Longformer; may not generalize to non-text modalities
  - Feature-level fusion: Most computationally efficient, handles diverse modalities, but requires dimensionality reduction to prevent text embeddings from overwhelming tabular features
  - Decision-level fusion: Most flexible (can incorporate statistical models like InSilicoVA), but most computationally expensive; requires careful base model calibration

- Failure signatures:
  - Low accuracy on minority classes (pneumonia, diarrhea, meningitis) regardless of architecture—indicates data limitation, not modeling failure
  - Large gap between individual accuracy and CSMF accuracy—suggests model may be miscalibrated for population-level estimation
  - Feature-level fusion underperforming unimodal baselines—likely indicates insufficient dimensionality reduction or poor feature scaling

- First 3 experiments:
  1. Baseline establishment: Train InSilicoVA and LightGBM (question-only) plus BioClinicalBERT (narrative-only) on Level 2 COD grouping; confirm narrative-only outperforms question-only as reported
  2. Unimodal robustness: Test BioClinicalBERT with varying training data sizes (10%, 25%, 50%, 75%, 100%) to establish data requirements; expect performance plateau around N=1500-2000
  3. Minimal multimodal test: Implement soft voting ensemble combining top question-only model (LightGBM) and top narrative-only model (BioClinicalBERT); verify accuracy improvement before investing in more complex fusion architectures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well do transformer-based models trained on South African verbal autopsy data generalize to diverse geographic and cultural settings?
- Basis in paper: [explicit] Page 83 states future research should "extend these investigations to younger ages and diverse geographic settings... to test the robustness and generalizability of the proposed methods."
- Why unresolved: This study relied exclusively on the SANCOD dataset from South Africa, which limits the generalizability of the findings to other populations with different cause-of-death profiles or linguistic characteristics.
- What evidence would resolve it: Evaluating the fine-tuned models on external validation datasets from low- and middle-income countries in different regions (e.g., South Asia or Latin America) without further retraining.

### Open Question 2
- Question: Does explicitly incorporating temporal features (timing and sequence of events) improve the classification performance of transformer-based models for verbal autopsy?
- Basis in paper: [explicit] Page 38 notes that current embeddings "can not explicitly reason about temporal structure or event chronology" and suggests exploring "explicitly extracting and incorporating known key features such as timing and sequence of events."
- Why unresolved: While PLMs use position embeddings, they lack explicit reasoning capabilities for the chronological progression of symptoms, which is critical for differential diagnosis.
- What evidence would resolve it: A comparative study measuring the performance delta between standard fine-tuned PLMs and models augmented with explicitly extracted temporal logic features.

### Open Question 3
- Question: Can text balancing techniques, such as synthetic text generation, effectively improve model performance for under-represented causes of death?
- Basis in paper: [explicit] Pages 38 and 64 identify the misclassification of minority classes as a limitation and suggest "text balancing techniques, such as synthetic text generation, to augment minority class representation."
- Why unresolved: Current models tend to favor majority classes (e.g., HIV/AIDS) and perform poorly on rare conditions (e.g., pneumonia, diarrhea) due to class imbalance in the training data.
- What evidence would resolve it: Experiments applying synthetic oversampling to the narrative training data and measuring the resulting improvement in F1-scores for minority cause categories.

## Limitations

- Dataset generalizability: Findings based on single South African dataset may not transfer to populations with different disease patterns or cultural contexts
- Data quantity constraints: Performance plateaus around 1500-2000 training samples, requiring substantially more labeled VA data for further improvements
- Minority class performance: Models consistently underperform on minority causes of death, indicating fundamental limitations in the approach

## Confidence

- **High confidence**: PLMs with narratives outperform question-only statistical algorithms for individual-level classification, particularly for non-communicable diseases
- **Medium confidence**: Multimodal fusion combining narratives and structured questions provides additional accuracy gains beyond either modality alone
- **Low confidence**: The strong association between physician-perceived information sufficiency and model classification accuracy

## Next Checks

1. **Cross-dataset validation**: Apply the best-performing PLM and multimodal fusion approaches to independent VA datasets from different countries/regions to assess generalizability of the reported performance gains

2. **Active learning experiment**: Implement an active learning loop where the sufficiency prediction model identifies low-confidence or low-sufficiency cases for physician review, then measure whether this targeted annotation strategy improves overall system accuracy more efficiently than random sampling

3. **Domain adaptation transfer test**: Train BioClinicalBERT on clinical notes from MIMIC-III and directly apply to VA narratives without fine-tuning, then measure performance degradation to quantify how much of the observed success relies on effective domain transfer