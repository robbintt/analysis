---
ver: rpa2
title: 'Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms'
arxiv_id: '2510.25811'
source_url: https://arxiv.org/abs/2510.25811
tags:
- which
- should
- have
- value
- proposition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational challenge of solving the
  Graves-Lai optimization problem for multimodal bandits with at most m modes. The
  authors propose the first known tractable algorithm to solve this problem by decomposing
  it into subproblems over mode and neighbor pairs, discretizing the constraint space,
  and using dynamic programming to efficiently search for optimal solutions.
---

# Multimodal Bandits: Regret Lower Bounds and Optimal Algorithms

## Quick Facts
- arXiv ID: 2510.25811
- Source URL: https://arxiv.org/abs/2510.25811
- Reference count: 40
- Primary result: Proposes the first tractable algorithm to solve the Graves-Lai optimization problem for multimodal bandits, proving local search strategies are provably suboptimal with arbitrarily large performance gaps.

## Executive Summary
This paper addresses the computational challenge of solving the Graves-Lai optimization problem for multimodal bandits with at most m modes. The authors propose a tractable algorithm that decomposes the problem into subproblems over mode and neighbor pairs, discretizes the constraint space, and uses dynamic programming to efficiently search for optimal solutions. The key theoretical contribution is proving that local search strategies are provably suboptimal for multimodal bandits, with performance gaps that can be arbitrarily large. The authors validate their approach by implementing the OSSB algorithm with their solution method and demonstrating improved regret performance compared to classical unstructured bandits on multimodal instances.

## Method Summary
The paper tackles the problem of optimal adaptive sampling in stochastic multi-armed bandits where the expected reward has at most m modes on a tree graph. The proposed solution involves a dynamic programming approach that breaks down the Graves-Lai optimization problem into manageable subproblems. The algorithm discretizes the constraint space and uses a penalized subgradient descent method (implemented via SLSQP in experiments) to solve each subproblem efficiently. The OSSB algorithm updates its sampling strategy at powers of two, with the optimal sampling distribution η* obtained by solving the decomposed optimization problem. The method is validated through experiments on binary tree graphs with 7 arms, comparing multimodal OSSB against classical unstructured bandit approaches.

## Key Results
- Proposes the first tractable algorithm to solve the Graves-Lai optimization problem for multimodal bandits with O(K^2mnt) complexity
- Proves local search strategies are provably suboptimal with arbitrarily large performance gaps
- Demonstrates improved regret performance of multimodal OSSB over classical unstructured bandits on both peaked (σ=0.5) and flat (σ=4) reward instances

## Why This Works (Mechanism)
The algorithm works by exploiting the multimodal structure of the reward function. Instead of treating all arms uniformly as in classical bandits, it identifies the modes and their neighbors, then uses dynamic programming to optimally allocate exploration efforts. The key insight is that local search strategies fail because they cannot distinguish between arms that are near modes versus those that are actually modes. By decomposing the optimization problem and discretizing the constraints, the algorithm can efficiently find the globally optimal sampling strategy that balances exploration of all modes while exploiting the best one.

## Foundational Learning

**Graves-Lai optimization problem**: The core mathematical framework for deriving asymptotically optimal sampling strategies in multi-armed bandits. Needed to establish theoretical guarantees and compute optimal exploration rates. Quick check: Verify the discretized constraints λ^T d(µ,λ) ≥ 1 are satisfied by the output.

**Dynamic programming decomposition**: Breaking the global optimization into subproblems over mode-neighbor pairs. Needed to make the problem tractable when m > 1. Quick check: Confirm the DP produces valid probability distributions at each step.

**Mode-neighbor pairs**: The structural decomposition where each mode has associated neighboring arms. Needed to exploit the tree structure and reduce dimensionality. Quick check: Verify the graph is correctly constructed as a tree with proper parent-child relationships.

**Penalized subgradient descent**: The optimization method used to solve the decomposed subproblems. Needed to handle the non-smooth nature of the optimization. Quick check: Ensure convergence by monitoring objective value changes across iterations.

**Tree graph structure**: The assumption that the arm relationships form a tree. Needed to enable the hierarchical decomposition approach. Quick check: Confirm the graph has exactly K-1 edges and no cycles.

## Architecture Onboarding

**Component map**: Data generation (binary tree, µ values) -> OSSB algorithm (Algorithm 1) -> Graves-Lai solver (DP + SLSQP) -> Regret computation -> Visualization

**Critical path**: The Graves-Lai solver is the bottleneck; it must correctly solve the decomposed optimization problem to ensure the OSSB algorithm achieves optimal regret bounds.

**Design tradeoffs**: The discretization level n trades off between computational complexity and solution accuracy. Higher n provides better approximations but increases runtime.

**Failure signatures**: Incorrect graph construction leads to DP failure; insufficient discretization causes constraint violations; SLSQP configuration issues prevent convergence to feasible solutions.

**First experiments**: 1) Test DP solver on a simple 3-arm tree with known optimal solution, 2) Verify the exponential reward structure creates the intended multimodal landscape, 3) Compare cumulative regret curves for σ=0.5 vs σ=4 instances.

## Open Questions the Paper Calls Out

**Open Question 1**: What is the minimal computational complexity necessary to solve the Graves-Lai optimization problem for multimodal bandits? The paper provides an upper bound of O(K^2mnt) but does not establish lower bounds or prove computational optimality.

**Open Question 2**: Can the algorithmic framework be extended to general graphs G containing cycles? The current methodology relies on tree structure for dynamic programming decomposition, and cycles would violate the directed acyclic assumptions.

**Open Question 3**: Is the "peaked" function condition a necessary requirement for local search strategies to be quasi-optimal? The paper identifies peakedness as sufficient for local search performance but leaves open whether other reward function structures could also work.

## Limitations

- The algorithm complexity O(K^2mnt) may become prohibitive for large trees with many modes and discretization points
- The tree graph assumption limits applicability to problems where arm relationships naturally form a tree structure
- The theoretical guarantees assume known µ values for the Graves-Lai solution, while practical implementations must estimate these online

## Confidence

**Theoretical contributions**: High - The paper provides rigorous proofs for the lower bounds and algorithmic correctness.

**Computational complexity**: Medium - The O(K^2mnt) bound is established, but optimality remains unproven.

**Experimental results**: Medium - The setup is well-specified, but depends on correct implementation of SLSQP and divergence functions.

## Next Checks

1. Verify the DP-based Graves-Lai solver produces feasible solutions satisfying λ^T d(µ,λ) ≥ 1 for n=100 discretization points

2. Confirm that the exponential reward structure with specified parameters creates the intended multimodal landscape with modes at arms 4 and 6

3. Test that cumulative regret curves show expected improvement of Multimodal OSSB over Classical OSSB for both peaked (σ=0.5) and flat (σ=4) instances