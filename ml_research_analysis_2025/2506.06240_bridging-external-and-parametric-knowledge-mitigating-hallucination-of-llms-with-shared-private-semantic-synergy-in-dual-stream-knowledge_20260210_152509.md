---
ver: rpa2
title: 'Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs
  with Shared-Private Semantic Synergy in Dual-Stream Knowledge'
arxiv_id: '2506.06240'
source_url: https://arxiv.org/abs/2506.06240
tags:
- knowledge
- external
- arxiv
- hallucination
- dssp-rag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of mitigating hallucination in
  large language models (LLMs) caused by conflicts between external retrieved knowledge
  and internal parametric knowledge. The proposed Dual-Stream Knowledge-Augmented
  Framework for Shared-Private Semantic Synergy (DSSP-RAG) introduces a mixed-attention
  mechanism to decompose knowledge into shared and private semantics, enabling fine-grained
  control over knowledge integration.
---

# Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge

## Quick Facts
- arXiv ID: 2506.06240
- Source URL: https://arxiv.org/abs/2506.06240
- Reference count: 28
- Primary result: Introduces DSSP-RAG framework with shared-private semantic decomposition and unsupervised hallucination detection

## Executive Summary
This paper addresses the persistent challenge of hallucination in large language models by proposing a novel Dual-Stream Knowledge-Augmented Framework (DSSP-RAG) that bridges external retrieved knowledge with internal parametric knowledge through shared-private semantic synergy. The framework introduces a mixed-attention mechanism that decomposes knowledge into shared semantics (common across contexts) and private semantics (context-specific), enabling fine-grained control over knowledge integration. It also incorporates an unsupervised hallucination detection mechanism based on cognitive uncertainty and an Energy Quotient approach for filtering noisy external knowledge, achieving significant improvements over strong baselines across multiple benchmarks.

## Method Summary
The DSSP-RAG framework operates through a dual-stream architecture where retrieved external knowledge and parametric knowledge are processed separately before being integrated through a mixed-attention mechanism. The key innovation lies in decomposing knowledge into shared semantics (information common to both knowledge sources) and private semantics (unique to each source), allowing the model to distinguish between reliable and conflicting information. The framework also employs an unsupervised hallucination detection mechanism based on cognitive uncertainty measurements and uses an Energy Quotient to filter noisy external knowledge before integration, creating a more robust knowledge-augmented generation process.

## Key Results
- Achieves 4.72% to 10.22% improvements in exact match scores across multiple datasets
- Outperforms strong baselines including standard RAG approaches
- Demonstrates effectiveness through ablation studies validating the contribution of shared-private semantic decomposition
- Shows consistent performance improvements across different model configurations

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to decompose knowledge into shared and private components, allowing the model to identify and reconcile conflicts between external and parametric knowledge sources. The mixed-attention mechanism enables fine-grained control over which information should be prioritized, while the unsupervised hallucination detection identifies uncertain or potentially hallucinated content through cognitive uncertainty measures. The Energy Quotient filtering ensures that only high-quality external knowledge is integrated, reducing the likelihood of introducing noisy or conflicting information that could trigger hallucinations.

## Foundational Learning

**Shared-Private Semantic Decomposition**: Why needed - To distinguish between common knowledge (shared) and context-specific information (private) across knowledge sources; Quick check - Verify that shared components align across both external and parametric knowledge streams.

**Mixed-Attention Mechanism**: Why needed - To enable selective integration of knowledge components based on their reliability and relevance; Quick check - Ensure attention weights properly reflect the confidence in shared versus private semantic components.

**Cognitive Uncertainty**: Why needed - To measure the model's confidence in its knowledge representations and identify potential hallucination risks; Quick check - Validate that higher uncertainty correlates with actual hallucination occurrences in test cases.

**Energy Quotient Filtering**: Why needed - To quantify and filter noisy or unreliable external knowledge before integration; Quick check - Confirm that filtered knowledge improves downstream generation quality compared to unfiltered input.

## Architecture Onboarding

**Component Map**: External Knowledge Retriever -> Shared-Private Decomposer -> Mixed-Attention Integrator -> Language Model Generator

**Critical Path**: Retrieval -> Semantic Decomposition -> Attention Integration -> Generation

**Design Tradeoffs**: The dual-stream architecture provides fine-grained control but increases computational complexity; shared-private decomposition requires additional parameters but improves hallucination detection accuracy.

**Failure Signatures**: 
- Poor performance when external knowledge quality is consistently low despite Energy Quotient filtering
- Degradation in cases where shared semantics are incorrectly identified across knowledge sources
- Computational overhead becoming prohibitive for real-time applications

**3 First Experiments**:
1. Evaluate exact match score improvements on NQ and TriviaQA datasets with different model sizes
2. Conduct ablation study removing shared-private decomposition to measure its isolated contribution
3. Test hallucination detection accuracy using synthetic hallucination datasets

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation on multilingual datasets, with primary focus on English-language benchmarks
- Performance improvements show considerable variation across datasets (4.72% to 10.22%), suggesting domain-specific effectiveness
- Computational overhead and inference latency not thoroughly characterized for practical deployment considerations

## Confidence
- High confidence in shared-private semantic decomposition effectiveness based on multiple benchmark results
- Medium confidence in unsupervised hallucination detection mechanism due to limited validation against human annotations
- Medium confidence in generalizability claims given the limited scope of tested domains and languages

## Next Checks
1. Evaluate the framework's performance on multilingual datasets to assess cross-lingual generalization capabilities
2. Conduct human evaluation studies to validate the accuracy of the unsupervised hallucination detection mechanism against ground-truth annotations
3. Measure and report the computational overhead (inference time, memory usage) compared to baseline RAG approaches to understand practical deployment implications