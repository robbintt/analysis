---
ver: rpa2
title: Extendable Generalization Self-Supervised Diffusion for Low-Dose CT Reconstruction
arxiv_id: '2509.23885'
source_url: https://arxiv.org/abs/2509.23885
tags:
- data
- image
- noise
- diffusion
- denoising
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generalizable self-supervised
  low-dose CT reconstruction across varying dose levels. The proposed method, EGenDiff,
  leverages a contextual subdata self-enhancing similarity strategy in the projection
  domain to generate an initial prior, followed by a latent diffusion model in the
  image domain for detail refinement.
---

# Extendable Generalization Self-Supervised Diffusion for Low-Dose CT Reconstruction

## Quick Facts
- arXiv ID: 2509.23885
- Source URL: https://arxiv.org/abs/2509.23885
- Authors: Guoquan Wei; Liu Shi; Zekun Zhou; Mohan Li; Cunfeng Wei; Wenzhe Shan; Qiegen Liu
- Reference count: 40
- Primary result: Proposes EGenDiff, a self-supervised diffusion method for low-dose CT reconstruction that generalizes across varying dose levels using contextual subdata similarity and pixel-wise fusion.

## Executive Summary
This paper addresses the challenge of generalizable self-supervised low-dose CT reconstruction across varying dose levels. The proposed method, EGenDiff, leverages a contextual subdata self-enhancing similarity strategy in the projection domain to generate an initial prior, followed by a latent diffusion model in the image domain for detail refinement. During inference, a pixel-wise self-correcting fusion technique balances the projection and image domain priors to enhance data fidelity and enable generalization to higher, lower, and unseen doses. Experiments on benchmark datasets, clinical data, and photon counting CT data demonstrate that EGenDiff consistently outperforms existing methods in quantitative metrics (e.g., PSNR, SSIM) and qualitative visual assessments, achieving superior reconstruction quality and robustness across multiple anatomical planes.

## Method Summary
EGenDiff employs a two-stage approach for low-dose CT reconstruction. First, a self-supervised projection domain denoising network uses contextual subdata self-enhancing similarity to generate an initial reconstruction. This network samples local chunks from the projection data and learns from similar neighborhoods while masking out dissimilar regions. The resulting estimate is then reconstructed via FBP. Second, a latent diffusion model refines the image domain details, guided by knowledge distillation from the initial reconstruction. The method introduces a pixel-wise self-correcting fusion technique during inference that dynamically balances the raw noisy data against the reconstruction prior, enabling generalization to different dose levels.

## Key Results
- Achieves higher PSNR and SSIM values than competing methods across multiple dose levels on benchmark datasets
- Demonstrates robust generalization to higher, lower, and unseen dose levels through pixel-wise self-correcting fusion
- Shows superior qualitative performance on clinical data and photon counting CT data across multiple anatomical planes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Self-supervised denoising is feasible in the projection domain by exploiting spatial redundancy, provided noise is less structured than anatomy.
- **Mechanism:** The architecture divides projection data into local chunks ($H_y/2 \times W_y/2$) and samples contextual sub-data ($s_1, s_2$). It optimizes a network $f_\theta$ using a self-enhancing similarity loss (Eq. 9) that masks out regions with high disparity ($\epsilon_1, \epsilon_2$). This forces the model to learn from similar local neighborhoods while ignoring dissimilar (potentially noisy or high-gradient) regions, approximating supervised loss without clean data.
- **Core assumption:** Adjacent projection data points contain redundant structural information where noise realizations differ but the underlying signal remains correlated (Assumption: valid for Fan-beam CT geometry).
- **Evidence anchors:**
  - [Section III.A]: "Self-enhancing similarity strategy... dynamically excludes regions with significant disparities."
  - [Appendix A]: "When $\varepsilon_1 \to 0$, the noise pairs exhibit high similarity, effectively approximating the performance of the supervised loss."
  - [Corpus]: Neighbor *Filter2Noise* supports the viability of interpretable self-supervised single-image denoising using spatial filtering.
- **Break condition:** Fails if noise correlation exceeds spatial signal correlation, or if artifacts create high-frequency features that are consistently masked, preventing the model from learning edges.

### Mechanism 2
- **Claim:** Latent diffusion models (LDMs) can recover high-frequency details from a noisy prior if initialized with a "good enough" initial reconstruction.
- **Mechanism:** The initial reconstruction $\hat{x}_0$ (from the projection stage) serves as a prior for knowledge distillation. The image domain LDM is trained not just to remove noise, but to minimize the difference between its output and the gradient/structural features of $\hat{x}_0$ (Eq. 14). This steers the diffusion process toward valid anatomical structures rather than hallucinated noise patterns.
- **Core assumption:** The initial FBP reconstruction $\hat{x}_0$ preserves structural edges (gradients) even if it contains residual noise.
- **Evidence anchors:**
  - [Section III.B]: "The initial prior is used to combine knowledge distillation with... latent diffusion models for optimizing image details."
  - [Section IV.E]: "Implementations without this strategy [similarity enhancement] exhibit feature smoothing... impairing the subsequent image-domain refinement."
  - [Corpus]: *Dual-domain Multi-path* paper supports the efficacy of combining domains and diffusion for reconstruction.
- **Break condition:** Fails if the projection domain output $\hat{x}_0$ is over-smoothed (loss of gradient information) or contains systematic artifacts, as the distillation loss would reinforce these errors in the diffusion model.

### Mechanism 3
- **Claim:** Generalization to unseen dose levels is achieved by dynamically balancing raw noisy data against the reconstruction prior.
- **Mechanism:** During inference, a pixel-wise weight $\lambda$ is calculated based on edge confidence ($C_e$) and noise confidence ($C_n$) relative to a baseline (25% dose). This fusion (Eq. 17) adaptively mixes the raw LDCT image ($x_{ld}$) and the prior ($\hat{x}_0$). If the dose is lower (higher noise), $\lambda$ shifts to favor the prior; if higher, it shifts to favor raw data fidelity.
- **Core assumption:** The noise characteristics of the 25% training dose serve as a reliable pivot for distinguishing noise from signal in other doses.
- **Evidence anchors:**
  - [Abstract]: "Pixel-wise self-correcting fusion technique balances the projection and image domain priors."
  - [Section III.C.2]: "Different noise levels determine whether $\lambda$ tends to favor $x_{ld}$ or $\hat{x}_0$."
  - [Corpus]: Evidence in immediate neighbors is weak for this specific "pixel-wise self-correcting" dose-scaling strategy, though general diffusion robustness is noted.
- **Break condition:** Fails for "unseen" doses that fundamentally alter noise texture (e.g., ultra-low dose photon starvation) where the $N_{25\%}$ noise estimation heuristic no longer correlates with actual noise variance.

## Foundational Learning

- **Concept: Noise2Noise (N2N) Learning**
  - **Why needed here:** EGenDiff replaces clean ground truth with noisy pairs. Understanding N2N (Eq. 2) is critical to grasp why the self-supervised loss (Eq. 9) doesn't collapse to trivial solutions.
  - **Quick check question:** If two noisy samples of the same pixel have zero correlation (e.g., structured striping artifacts), does the N2N assumption hold?

- **Concept: Latent Diffusion Models (LDMs)**
  - **Why needed here:** The image refinement stage operates in a compressed latent space to reduce computational cost.
  - **Quick check question:** Why does the paper use a Transformer-based denoiser ($\epsilon_\theta$) in the latent space rather than a standard U-Net?

- **Concept: Filtered Backprojection (FBP)**
  - **Why needed here:** The method bridges the projection and image domains via FBP. Understanding how noise propagates through FBP is necessary to diagnose artifacts in $\hat{x}_0$.
  - **Quick check question:** Does FBP preserve the locality of noise, or does it distribute projection noise across the image? (Hint: Check Section III.A regarding spatial correlation).

## Architecture Onboarding

- **Component map:** $y_{ld} \xrightarrow{\text{Sampling}} s_1, s_2 \xrightarrow{\text{Proj-Net}} \hat{y}_0 \xrightarrow{\text{FBP}} \hat{x}_0 \xrightarrow{\text{Fusion }(\lambda)} \hat{\hat{x}}_0 \xrightarrow{\text{LDM}} \tilde{x}_0$

- **Critical path:** $y_{ld} \xrightarrow{\text{Sampling}} s_1, s_2 \xrightarrow{\text{Proj-Net}} \hat{y}_0 \xrightarrow{\text{FBP}} \hat{x}_0 \xrightarrow{\text{Fusion }(\lambda)} \hat{\hat{x}}_0 \xrightarrow{\text{LDM}} \tilde{x}_0$

- **Design tradeoffs:**
  - **Efficiency:** Uses only 5 sampling steps for diffusion (vs standard 1000) for speed, risking lower fidelity.
  - **Generalization:** Hardcodes a 25% dose reference logic (Eq. 18) which restricts "out-of-the-box" use on scanners with vastly different noise baselines without recalibration.

- **Failure signatures:**
  - **Over-smoothing:** If $\lambda$ is miscalculated, the fusion discards raw data, resulting in plastic-looking images.
  - **CT Value Drift:** As noted in Section IV.D regarding Noise2Sim, improper self-supision can shift Hounsfield Unit (HU) values; monitor histograms of $\tilde{x}_0$.

- **First 3 experiments:**
  1. **Baseline Projection:** Train $f_\theta$ alone with Eq. 9 on simulated data to verify it isn't learning identity mappings.
  2. **Lambda Ablation:** Run inference with fixed $\lambda=0.5$ vs. the proposed adaptive $\lambda$ on 10% and 50% dose data to verify the "Extendable" claim.
  3. **Cross-Domain Check:** Visualize the residual $(x_{ld} - \hat{x}_0)$ to ensure the projection domain isn't removing diagnostic features (lesions) before diffusion.

## Open Questions the Paper Calls Out
None

## Limitations
- The pixel-wise fusion strategy's generalizability to non-standard dose levels remains unverified, as the 25% dose pivot is hardcoded.
- The self-enhancing similarity masking in the projection domain may struggle with structured noise (e.g., metallic artifacts), potentially limiting clinical applicability.
- The paper does not address computational overhead for clinical deployment, particularly the inference-time fusion calculations.

## Confidence
- **High:** Core self-supervised denoising mechanism in projection domain (Mechanism 1) - supported by Noise2Noise literature and ablation studies.
- **Medium:** Latent diffusion refinement effectiveness (Mechanism 2) - demonstrated on benchmarks but lacks comparison to non-diffusion alternatives.
- **Medium:** Generalization across dose levels via pixel-wise fusion (Mechanism 3) - validated on specific dose ranges but untested on extreme or clinically uncommon doses.

## Next Checks
1. **Extreme Dose Testing:** Evaluate EGenDiff on ultra-low dose (1-3%) and very high dose (100%+) data to identify fusion breakdown points.
2. **Artifact Robustness:** Test performance on data with metallic implants or motion artifacts to assess self-enhancing similarity masking limitations.
3. **Computational Profiling:** Measure end-to-end inference time and memory requirements for clinical workflow integration, comparing against standard FBP+postprocessing pipelines.