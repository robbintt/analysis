---
ver: rpa2
title: Tractable Probabilistic Models for Investment Planning
arxiv_id: '2511.13888'
source_url: https://arxiv.org/abs/2511.13888
tags:
- planning
- power
- probabilistic
- expansion
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a tractable probabilistic framework for long-term
  investment planning in power systems, addressing the challenge of uncertainty in
  energy mix and demand forecasting over decades. The approach replaces traditional
  scenario-based methods with sum-product networks (SPNs), enabling exact, scalable
  inference of scenario likelihoods and volatility.
---

# Tractable Probabilistic Models for Investment Planning

## Quick Facts
- **arXiv ID:** 2511.13888
- **Source URL:** https://arxiv.org/abs/2511.13888
- **Reference count:** 40
- **Primary result:** SPN-based investment planning outperforms traditional scenario methods in reliability and risk mitigation, especially under limited data availability.

## Executive Summary
This paper introduces a tractable probabilistic framework for long-term investment planning in power systems, addressing uncertainty in energy mix and demand forecasting over decades. The approach replaces traditional scenario-based methods with sum-product networks (SPNs), enabling exact, scalable inference of scenario likelihoods and volatility. By embedding SPNs into mixed-integer optimization, the framework supports chance-constrained planning, ensuring reliability with prescribed confidence levels. Experimental results on a representative power system case study demonstrate that SPN-based methods outperform traditional scenario-based approaches in consistency and risk mitigation, even under limited data availability.

## Method Summary
The framework uses a three-layer pipeline: (1) a simulator generates labeled data of investment decisions, uncertainty realizations, and system adequacy outcomes; (2) an SPN is trained on this data to learn the joint distribution of decisions, uncertainties, and outcomes; (3) the SPN is encoded into a mixed-integer linear program (MILP) using log-space constraints, enabling chance-constrained optimization. The method replaces scenario enumeration with tractable probabilistic inference, allowing exact computation of densities and expectations required for stochastic and chance-constrained optimization problems. The SPN structure enables polynomial-time inference while capturing complex dependencies in the data.

## Key Results
- SPN-based methods consistently outperform traditional scenario-based approaches (GEP10, GEP50) in reliability and risk mitigation
- Under limited data availability, SPN-based methods provide more conservative and reliable investment decisions with lower shortfall probability
- The framework successfully enforces chance constraints with prescribed confidence levels through MILP embedding

## Why This Works (Mechanism)

### Mechanism 1: Tractable Probabilistic Inference via Sum-Product Networks (SPNs)
SPNs represent complex joint distributions as computational graphs of weighted sums (mixtures) and products (independencies), enabling exact computation of densities and expectations in polynomial time. This structure allows scalable inference without sampling, as complexity is linear in network size rather than scenario count.

### Mechanism 2: Chance-Constraint Embedding via Mixed-Integer Linear Programming (MILP)
The SPN's log-probability computation is encoded using linear constraints for product nodes and mixed-integer constraints using binary variables for sum nodes' log-sum-exp approximation. This allows the optimizer to compute configuration probabilities of satisfying system adequacy and constrain them directly.

### Mechanism 3: Conservative Bias from Approximation Error under Limited Data
Under limited data, the SPN-Max approximation tends to underestimate probability density, imposing a stronger constraint than intended. This conservative bias leads to more reliable investment decisions compared to sparse scenario-based methods that may miss critical stress scenarios.

## Foundational Learning

**Sum-Product Networks (SPNs) and Tractability**
- Why needed: Core probabilistic model enabling exact and polynomial-time inference
- Quick check: Given an SPN, how would you compute the marginal probability P(A) for variable A? (Answer: Set indicators for other variables to 1 and evaluate the network efficiently)

**Chance-Constrained Optimization**
- Why needed: Risk-aware planning requiring probability of constraint violation
- Quick check: Formulate a chance constraint requiring power supply to meet demand with 99% probability. How does this differ from requiring it for all possible outcomes?

**MILP Encoding of Probabilistic Models**
- Why needed: Engineering contribution enabling SPN integration into standard solvers
- Quick check: Why is encoding log-probability of sum nodes difficult? How does SPN-Max approximation simplify this using binary variables?

## Architecture Onboarding

**Component map:** Simulator -> SPN Model -> MILP Optimizer

**Critical path:** Final investment decision depends on simulator fidelity, data quality, SPN accuracy, and MILP approximation tightness

**Design tradeoffs:**
- SPN-Max vs. SPN-Piecewise: Simpler vs. more accurate but complex
- Training data size vs. computational cost: More data improves accuracy but increases training time
- SPN complexity vs. MILP tractability: More complex SPN captures nuances but creates larger MILPs

**Failure signatures:**
- Overconfident/unsafe solution: SPN underestimates shortfall probability
- Infeasible/over-conservative solution: SPN overestimates shortfall probability
- MILP solver time-out: SPN structure creates too many binary variables

**First 3 experiments:**
1. Baseline reproduction with data scaling: Train SPNs on 10%, 50%, 100% of dataset; compare cost and safety against GEP10/GEP50
2. Out-of-sample stress test: Evaluate optimal decisions against large independent Monte Carlo simulation
3. Approximation error ablation: Compare MILP encoding against exact SPN inference to quantify error

## Open Questions the Paper Calls Out

**Open Question 1:** Can alternative probabilistic circuits or hybrid formulations reduce linearization error and calibration overconfidence in the SPN-to-MILP encoding?

**Open Question 2:** Can active learning or uncertainty-aware sampling effectively mitigate data bias and rare event underrepresentation in real-world datasets?

**Open Question 3:** What structural constraints or solver strategies are required to maintain tractability when embedding large, complex SPNs for full-scale power system planning?

## Limitations
- Reliance on simulator fidelity for accurate representation of real-world dynamics
- Approximation errors in MILP encoding potentially introducing estimation errors
- Uncertainty in scalability to large, geographically diverse real-world power systems

## Confidence

**High:** Theoretical framework for tractable probabilistic inference via SPNs and MILP embedding is sound
**Medium:** Experimental results demonstrate effectiveness in tested case study, but real-world generalization uncertain
**Low:** Claim that SPN-Max approximation always acts as beneficial conservative bias is not universally proven

## Next Checks

1. **Out-of-Sample Stress Test:** Evaluate optimal investment decisions against much larger independent Monte Carlo simulation to measure reliability and test for overconfidence
2. **Real-World Data Integration:** Replace synthetic simulator with historical power system operations data and compare resulting investment plans to industry-standard methods
3. **Scalability Benchmark:** Apply framework to larger complex power system model and measure impact on SPN learning time, MILP size, and solver runtime compared to case study