---
ver: rpa2
title: 'ARC: Active and Reflection-driven Context Management for Long-Horizon Information
  Seeking Agents'
arxiv_id: '2601.12030'
source_url: https://arxiv.org/abs/2601.12030
tags:
- context
- interaction
- memory
- turn
- management
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of context rot in long-horizon
  information-seeking agents, where performance degrades as interaction histories
  grow. The proposed ARC framework treats context as a dynamic internal reasoning
  state rather than a static artifact, enabling continuous monitoring and active reorganization
  through reflection-driven memory revision.
---

# ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents

## Quick Facts
- arXiv ID: 2601.12030
- Source URL: https://arxiv.org/abs/2601.12030
- Reference count: 27
- Achieves up to 11% absolute improvement in accuracy on BrowseComp-ZH compared to passive summarization methods

## Executive Summary
This paper addresses the challenge of context rot in long-horizon information-seeking agents, where performance degrades as interaction histories grow. The proposed ARC framework treats context as a dynamic internal reasoning state rather than a static artifact, enabling continuous monitoring and active reorganization through reflection-driven memory revision. ARC introduces a dual-component architecture separating action execution from context management, with a dedicated Context Manager that incrementally summarizes interactions and triggers reflection when misalignment is detected. Experiments on five challenging benchmarks demonstrate ARC's effectiveness, achieving up to 11% absolute improvement in accuracy on BrowseComp-ZH compared to passive summarization methods, with consistent gains across both small and large actor models. The results show that active context management is a learnable capability that enhances long-horizon reasoning by preventing error accumulation and maintaining task-aligned internal states.

## Method Summary
ARC introduces a dual-component architecture where action execution and context management are separated. The Context Manager continuously monitors the agent's interactions, incrementally summarizing context and triggering reflection when misalignment is detected. The framework employs reflection-driven memory revision to actively reorganize the context, treating it as a dynamic reasoning state rather than a passive record. This active approach contrasts with passive summarization methods that simply compress historical data without considering task alignment or error correction.

## Key Results
- ARC achieves up to 11% absolute improvement in accuracy on BrowseComp-ZH compared to passive summarization methods
- Consistent performance gains observed across both small and large actor models (up to 14B parameters)
- Demonstrated effectiveness across five challenging benchmarks including WebShop and CEval

## Why This Works (Mechanism)
The paper's mechanism centers on treating context as an active reasoning state rather than a static record. By continuously monitoring interaction histories and triggering reflection when misalignment is detected, ARC prevents the accumulation of errors that leads to context rot. The dual-component architecture allows for specialized context management separate from action execution, enabling more sophisticated memory revision strategies. The incremental summarization approach maintains task relevance while reducing cognitive load, and the reflection mechanism actively reorganizes context to maintain alignment with current objectives.

## Foundational Learning
- Context management in long-horizon tasks: Essential for understanding how interaction histories affect agent performance over extended sequences. Quick check: Verify that context size grows linearly with interaction steps without management.
- Reflection-driven memory revision: The process of detecting and correcting misalignments in the agent's internal state. Quick check: Measure the frequency of reflection triggers during task execution.
- Incremental summarization: Continuous compression of interaction histories while maintaining task-relevant information. Quick check: Compare context size before and after summarization steps.
- Dual-component architecture: Separation of action execution from context management for specialized optimization. Quick check: Measure performance impact when components are integrated vs. separated.
- Task-aligned context: Ensuring the agent's memory state remains relevant to current objectives rather than just recording history. Quick check: Evaluate context relevance using attention patterns on different task phases.

## Architecture Onboarding

Component map: Actor Model -> Action Execution -> Environment -> Interaction History -> Context Manager -> Reflection Trigger -> Memory Revision -> Updated Context -> Actor Model

Critical path: The agent executes actions, generates interactions, Context Manager monitors for misalignment, triggers reflection when needed, performs memory revision, and updates the context state that feeds back into the actor model.

Design tradeoffs: Active vs. passive context management (ARC vs. simple summarization), continuous monitoring overhead vs. performance gains, reflection frequency vs. computational cost, and the balance between context retention and compression.

Failure signatures: Context rot manifests as degraded performance on long-horizon tasks, accumulation of irrelevant information in memory, misalignment between current task objectives and stored context, and error propagation through sequential decision-making.

First experiments: 1) Baseline comparison showing performance degradation without context management on long-horizon tasks, 2) Ablation study isolating the contribution of active vs. passive components, 3) Scalability test demonstrating consistent gains across different model sizes from small to 14B parameters.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on human-annotated golden answers for the "task completion" metric assumes perfect ground truth availability, which may not generalize to real-world applications where success criteria are ambiguous
- The evaluation focuses on English and Chinese language tasks, with limited evidence for multilingual generalization to other languages or domains
- The reflection mechanism's computational overhead is not fully characterized - while the paper claims efficiency, the additional inference costs from continuous monitoring are not quantified

## Confidence
High confidence in the experimental methodology and benchmark results showing consistent performance gains. Medium confidence in the claim that active context management is "learnable" as a general capability, since the experiments focus on specific task types. Medium confidence in the scalability claims, as the evaluation primarily uses models up to 14B parameters.

## Next Checks
1. Conduct runtime efficiency analysis measuring the overhead of continuous reflection monitoring across varying context lengths and frequencies
2. Test the framework on ambiguous task scenarios where success criteria are not clearly defined to evaluate robustness
3. Evaluate cross-domain generalization by applying ARC to non-web browsing tasks like scientific literature review or legal document analysis