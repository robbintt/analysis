---
ver: rpa2
title: 'DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label
  Learning'
arxiv_id: '2511.20225'
source_url: https://arxiv.org/abs/2511.20225
tags:
- data
- labeled
- learning
- multi-label
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# DiCaP: Distribution-Calibrated Pseudo-labeling for Semi-Supervised Multi-Label Learning

## Quick Facts
- **arXiv ID:** 2511.20225
- **Source URL:** https://arxiv.org/abs/2511.20225
- **Reference count:** 10
- **Primary result:** Achieves state-of-the-art mAP on COCO, VOC, NUS-WIDE, and AWA2 under semi-supervised multi-label learning

## Executive Summary
DiCaP introduces a three-pronged approach to improve pseudo-labeling in semi-supervised multi-label learning. The method calibrates pseudo-label weights based on estimated correctness likelihood, uses dual-thresholding to filter confident predictions, and applies contrastive learning to uncertain samples. By theoretically deriving that pseudo-label weights should reflect correctness likelihood and empirically validating this through ablations, DiCaP achieves state-of-the-art performance across multiple image datasets under varying labeled data ratios.

## Method Summary
DiCaP addresses semi-supervised multi-label learning by splitting labeled data into D_sup (80%) for supervised training and threshold derivation, and D_est (20%) treated as unlabeled for estimating correctness likelihood distributions. The method employs three key mechanisms: Distribution-Calibrated Weighting (DCW) that assigns soft weights to pseudo-labels based on binned confidence scores, Dual-Thresholding (DTH) that filters confident predictions using class-wise thresholds, and Unsupervised Representation Regularization Learning (URRL) that applies contrastive learning to uncertain samples. The framework is trained with a combination of supervised asymmetric loss, weighted pseudo-label loss, and contrastive loss, followed by fine-tuning on D_est.

## Key Results
- State-of-the-art mAP on MS-COCO (5%, 10%, 15%, 20% labeled), Pascal VOC 2007, NUS-WIDE, and AWA2 datasets
- Component ablations show DCW contributes 2.1-4.0 mAP points, DTH adds 1.2-2.5 points, and URRL provides 0.8-1.8 points
- Consistent performance improvements across all tested labeled data ratios

## Why This Works (Mechanism)

### Mechanism 1: Distribution-Calibrated Weighting (DCW)
The method estimates the likelihood that each pseudo-label is correct by treating D_est as unlabeled data and computing bin-wise true positive/negative rates. During training, pseudo-labels receive soft weights via linear interpolation between adjacent bin estimates, down-weighting likely-incorrect labels without discarding them. This reduces gradient noise from incorrect pseudo-labels. The core assumption is that correctness likelihood distributions remain stable across datasets under i.i.d. sampling.

### Mechanism 2: Dual-Thresholding (DTH)
For each class, thresholds are derived from the mid-range of positive and negative confidence scores on D_sup. Predictions with confidence above τ_pos_c receive pseudo-label 1, those below τ_neg_c receive 0, and those in between are marked uncertain (-1) and excluded from pseudo-label loss. This creates a rejection region that prevents ambiguous predictions from corrupting the training signal. The assumption is that confidence boundaries on labeled data generalize to unlabeled data.

### Mechanism 3: Contrastive Learning for Uncertain Samples (URRL)
Uncertain samples (ŷ = -1) undergo class-wise contrastive learning where weak and strong augmentations generate positive pairs, and all other class-wise features in the batch serve as negatives. This provides representational regularization without committing to potentially incorrect hard labels. The assumption is that augmentation consistency provides meaningful learning signal even without label information.

## Foundational Learning

- **Concept: Calibration in deep networks**
  - Why needed here: Modern DNNs produce overconfident predictions, making raw confidence scores unreliable for weight estimation. Understanding calibration explains why bin-wise TP/(TP+FP) estimation is necessary rather than using predicted probabilities directly.
  - Quick check question: Can you explain why a model with 90% predicted confidence might only achieve 60% accuracy on those predictions?

- **Concept: Semi-supervised learning consistency regularization**
  - Why needed here: The contrastive loss on uncertain samples is a form of consistency regularization—enforcing that different views/augmentations of the same input produce similar representations. This is a core SSL primitive.
  - Quick check question: What happens to consistency-based methods if augmentations are too weak (identity) or too strong (destroy semantics)?

- **Concept: Multi-label classification with asymmetric losses**
  - Why needed here: The method uses Asymmetric Loss (ASL) for both supervised and pseudo-label losses. ASL handles label imbalance by differently weighting positive/negative terms—critical for multi-label settings where positive labels are typically sparse.
  - Quick check question: Why might standard binary cross-entropy underperform on multi-label data with severe class imbalance?

## Architecture Onboarding

- **Component map:**
  - D_sup (80% of labeled data) → Supervised training set for warm-up and threshold derivation
  - D_est (20% of labeled data) → Estimation set treated as pseudo-unlabeled for correctness likelihood estimation
  - D_unsup = D_u ∪ D_est → Combined unlabeled pool for pseudo-labeling
  - Bin estimator (K=20 bins) → Tracks n_pos_k, n_neg_k per bin for weight calculation
  - Dual-threshold module → Computes τ_pos_c, τ_neg_c per class from D_sup statistics
  - Weight interpolator → Linear interpolation between adjacent bin weights
  - Contrastive head → Class-wise feature embeddings for uncertain samples
  - EMA model → Exponential moving average (decay 0.9997) for training stability

- **Critical path:**
  1. Warm-up on D_sup with contrastive learning on all data
  2. Estimate weights from D_est (compute bin-wise TP/TN counts)
  3. Derive class thresholds from D_sup
  4. Main training: L = L_sup + L_pseudo (weighted, confident only) + L_uncer (contrastive, uncertain only)
  5. Fine-tune: Freeze backbone, train classification head on D_est

- **Design tradeoffs:**
  - D_sup/D_est split ratio (80/20): Larger D_sup improves threshold reliability; larger D_est improves weight estimation
  - Number of bins (K=20): More bins provide finer weight granularity but require more samples per bin
  - Freezing backbone during fine-tuning: Reduces overfitting and computation but may limit adaptation to D_est labels

- **Failure signatures:**
  - Empty or near-empty bins: Check n_pos_k + n_neg_k per bin; if many bins have <5 samples, weight estimates are unreliable
  - τ_neg_c > τ_pos_c: Occurs if positive samples have lower confidence than negatives; indicates model or data issues
  - D_conf is very small: Most predictions fall in uncertain region; thresholds may be too tight or model is undertrained
  - Weight curve is inverted: Check if n_pos_k/n_neg_k computation is correct; may indicate label noise or implementation bug

- **First 3 experiments:**
  1. Weight estimation accuracy check: On validation split with known labels, compute both estimated weights (from held-out portion) and optimal weights (from true labels). Plot estimated vs. optimal as in Figure 3.
  2. Component ablation: Train with only DCW (no dual-thresholding, no contrastive loss), then add DTH, then add URRL. Use ablation table format to isolate each contribution on COCO at 5% labeled.
  3. Threshold sensitivity analysis: Vary threshold derivation method (mid-range vs. mean vs. percentile-based) and measure both pseudo-label coverage and mAP.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the observed stability of the pseudo-label correctness likelihood distribution hold across different data modalities or under significant domain shifts?
- **Basis in paper:** The method relies on empirical observation that correctness likelihood distributions remain stable on image datasets (COCO, VOC), but does not validate this assumption on non-vision data or out-of-distribution unlabeled data.
- **Why unresolved:** Stability is treated as a dataset-specific constant in the proposed framework, but its universality is not theoretically proven or empirically tested outside of standard image benchmarks.
- **What evidence would resolve it:** Empirical evaluation of DiCaP on non-image multi-label tasks (e.g., text categorization) or cross-domain semi-supervised settings.

### Open Question 2
- **Question:** How sensitive is the model's warm-up performance to the reduction of supervised data caused by the required split between the training set ($D_{sup}$) and the estimation set ($D_{est}$)?
- **Basis in paper:** The authors split labeled data (80/20) to estimate weights, whereas baseline methods utilize the full labeled set for training.
- **Why unresolved:** In extreme low-label regimes (e.g., 5%), holding out 20% of labeled data for estimation might deprive the backbone of necessary supervision during the warm-up phase.
- **What evidence would resolve it:** Sensitivity analysis measuring performance and convergence speed across varying split ratios (e.g., 50/50 vs. 95/5) under the 5% labeled setting.

### Open Question 3
- **Question:** Can the Distribution-Calibrated Weighting (DCW) module be effectively decoupled from the specific Asymmetric Loss (ASL) function used in the paper?
- **Basis in paper:** The paper theoretically derives the optimal weight as a general posterior probability but exclusively employs ASL for the pseudo-label loss without comparing it to standard BCE.
- **Why unresolved:** It is unclear if performance gains are synergistic with ASL's specific handling of negative gradients or if the theoretical weighting framework applies robustly to standard loss functions.
- **What evidence would resolve it:** Ablation study applying estimated DCW weights to standard BCE and Focal Loss functions to isolate the contribution of the weighting strategy.

## Limitations

- The 80/20 split between D_sup and D_est is fixed without systematic ablations showing sensitivity to this ratio
- The claim that D_est treated as unlabeled yields reliable weight estimates assumes minimal domain shift between labeled and unlabeled data
- Component ablations isolate contributions but don't explore hyperparameter sensitivity (bin count, threshold derivation methods) or training duration impacts

## Confidence

- **High confidence:** The core mechanism of using correctness likelihood weights (Mechanism 1) is well-theoretically grounded and empirically validated through component ablations
- **Medium confidence:** The dual-thresholding mechanism (Mechanism 2) shows consistent improvements but its optimality (mid-range thresholds) and robustness to dataset shifts need more validation
- **Medium confidence:** The contrastive learning for uncertain samples (Mechanism 3) follows established SSL patterns but the specific class-wise formulation and its independent contribution require more isolation

## Next Checks

1. **Weight Estimation Validation:** On a validation split with known labels, compute both the estimated weights (from held-out portion) and the optimal weights (from true labels). Plot these against confidence scores to verify the calibration assumption before full training.

2. **Component Ablation with Hyperparameter Sensitivity:** Re-run the component ablation (DCW only → DCW+DTH → DCW+DTH+URRL) while varying K (number of bins: 10, 20, 30) and the D_sup/D_est ratio (70/30, 80/20, 90/10) to identify optimal configurations per dataset.

3. **Distribution Shift Robustness Test:** Intentionally create distribution shifts between D_sup and D_u (e.g., by removing certain classes from D_sup) and measure degradation in weight estimation accuracy and overall performance to quantify the method's sensitivity to the i.i.d. assumption.