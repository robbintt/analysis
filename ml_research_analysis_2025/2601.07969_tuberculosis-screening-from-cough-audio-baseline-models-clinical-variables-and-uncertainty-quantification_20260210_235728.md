---
ver: rpa2
title: 'Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables,
  and Uncertainty Quantification'
arxiv_id: '2601.07969'
source_url: https://arxiv.org/abs/2601.07969
tags:
- cough
- features
- prediction
- conformal
- catboost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present a standardized framework for tuberculosis screening
  from cough audio and clinical metadata, addressing the lack of comparability in
  prior work due to inconsistent datasets, validation, and metrics. Our pipeline uses
  hand-crafted audio features (MFCCs, chroma, spectral statistics) combined with clinical
  variables, and trains two baseline models (Logistic Regression and CatBoost) using
  cougher-independent nested cross-validation.
---

# Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables, and Uncertainty Quantification

## Quick Facts
- arXiv ID: 2601.07969
- Source URL: https://arxiv.org/abs/2601.07969
- Reference count: 13
- One-line primary result: Multimodal fusion of audio and clinical features improves TB screening ROC AUC to ~0.80 vs ~0.70 audio-only, with cougher-independent nested CV and conformal prediction quantifying uncertainty.

## Executive Summary
This work establishes a standardized framework for TB screening from cough audio by addressing the critical issue of inconsistent evaluation protocols in prior research. The authors implement cougher-independent (grouped) cross-validation to prevent information leakage from subject-specific acoustic signatures, and demonstrate that combining hand-crafted audio features with clinical metadata substantially improves discrimination performance. They also introduce probability calibration and conformal prediction to quantify prediction uncertainty, making the system more reliable for real-world screening triage where false negatives have severe consequences.

## Method Summary
The pipeline extracts 261-dimensional audio features (13 MFCCs, 12 Chroma, 4 spectral stats aggregated via 9 functionals) from 0.5s cough recordings, optionally fused with 16 clinical variables (demographics, symptoms, vitals). Two baseline models are trained: Logistic Regression and CatBoost, using cougher-disjoint nested 10×5 stratified cross-validation with hyperparameter tuning via UAR maximization. Isotonic regression calibrates out-of-fold predictions, and conformal prediction generates prediction sets at cougher level using a separate calibration subset. The framework enables fair benchmarking and supports uncertainty-aware TB detection.

## Key Results
- Multimodal fusion improves ROC AUC from ~0.70 (audio-only) to ~0.80 and PR AUC from ~0.46 to ~0.63
- Cougher-independent grouped CV prevents information leakage that inflates performance in random splits
- Conformal prediction coverage stays near target (1-α) with improved prediction set sharpness when using fused features
- Model choice (LR vs CatBoost) primarily affects sensitivity-specificity trade-off rather than overall discrimination

## Why This Works (Mechanism)

### Mechanism 1
Clinical variables provide complementary signal that resolves ambiguity in cough patterns that are acoustically non-specific. The fusion enables the model to access orthogonal information channels—acoustic properties capture physiological changes in the respiratory tract, while clinical variables capture risk factors and symptom history that correlate with TB status. Core assumption: Clinical variables are reliably associated with TB status and collected consistently. Evidence: ROC AUC improves from ~0.70 to ~0.80 with fusion; DeepGB-TB confirms multimodal approach. Break condition: Missing or systematically different clinical data at deployment.

### Mechanism 2
Cougher-independent cross-validation prevents information leakage by keeping all samples from the same individual within one fold. This forces the model to learn generalizable TB-related patterns rather than memorizing subject-specific signatures like vocal tract traits or microphone characteristics. Core assumption: Cough acoustics contain strong subject-specific signatures that random splitting fails to account for. Evidence: Authors note widespread lack of grouped splits in literature; cougher-disjoint validation yields realistic generalization estimates. Break condition: If deployment involves known individuals rather than new patients, this validation underestimates performance.

### Mechanism 3
Conformal prediction provides statistically grounded uncertainty quantification with coverage guarantees under exchangeability. Using a held-out calibration set, it maps model scores to prediction sets that contain the true label with probability ≥1-α. Aggregating to cougher-level probabilities restores exchangeability, since multiple coughs per subject violate independence. Core assumption: Calibration and test samples are exchangeable; cougher-level aggregation satisfies this. Evidence: Fused features reduce prediction set size (1.31-1.32 vs 1.43-1.44 at α=0.10) with higher singleton rates. Break condition: Distribution shift invalidates coverage guarantees.

## Foundational Learning

- **Grouped/Custered Cross-Validation**
  - Why needed here: Multiple recordings per patient create dependencies; standard k-fold CV leaks subject identity and inflates performance. Grouped CV respects the unit of inference (the patient).
  - Quick check question: If you randomly split recordings, could the same person appear in both train and test? If yes, you need grouped splitting.

- **Probability Calibration (Isotonic Regression)**
  - Why needed here: Raw classifier scores are often miscalibrated (over/under-confident). Reliable probabilities are required for threshold selection and conformal prediction.
  - Quick check question: Does a predicted probability of 0.80 mean 80% of such cases are actually positive? If not, you need calibration.

- **Conformal Prediction Basics**
  - Why needed here: Provides distribution-free coverage guarantees for prediction sets; enables uncertainty-aware screening with explicit abstention/referral criteria.
  - Quick check question: Can you bound the error rate of your "I don't know" predictions at a user-specified level (e.g., 10%)? Conformal prediction does this.

## Architecture Onboarding

- **Component map:**
  Audio preprocessing (16kHz, 32ms windows) -> Feature extraction (261-dim MFCCs/Chroma/spectral stats) -> Clinical encoding (z-scored/0-1) -> Fusion (concatenation) -> Model (LR/CatBoost) -> Calibration (Isotonic regression) -> Thresholding (Youden's index) -> Uncertainty (Conformal prediction at cougher level)

- **Critical path:**
  1. Ensure cougher-disjoint splits before any model training
  2. Extract features consistently across all folds
  3. Fit calibrator only on OOF predictions (never training data)
  4. Compute conformal quantiles on separate calibration set, not test

- **Design tradeoffs:**
  - **LR vs CatBoost**: LR yields higher specificity (fewer false alarms); CatBoost yields higher sensitivity (fewer missed TB). Choose based on screening policy.
  - **Audio-only vs Fused**: Fusion improves ROC AUC by ~0.10 and PR AUC by ~0.17. If clinical data is unavailable, accept lower performance.
  - **α level in conformal**: Lower α (stricter coverage) → larger prediction sets → more deferrals. α=0.10 yields ~68% singletons; α=0.05 yields ~49%.

- **Failure signatures:**
  - Random split validation shows ROC AUC >0.90 while grouped CV shows ~0.70-0.80: leakage present.
  - Calibration curve deviates from diagonal: apply isotonic regression.
  - Conformal coverage systematically below target: exchangeability violated or calibration set too small.

- **First 3 experiments:**
  1. **Baseline replication**: Implement audio feature extraction pipeline (MFCCs, Chroma, spectral stats) and validate feature dimensions match (261-dim). Train LR on audio-only with grouped 5-fold CV; confirm ROC AUC ~0.68-0.70.
  2. **Fusion impact test**: Add clinical variables, concatenate with audio features, retrain. Compare ROC AUC and PR AUC against audio-only. Expect ~0.10 ROC AUC gain.
  3. **Uncertainty validation**: Implement conformal prediction at α=0.10 on cougher-level aggregated probabilities. Verify coverage ≈0.90±0.04 across folds. Report singleton rate and average set size.

## Open Questions the Paper Calls Out

### Open Question 1
Do deep learning models (CNNs, RNNs, pretrained audio encoders) operating on spectrotemporal representations outperform the hand-crafted feature baselines under the same rigorous cougher-disjoint nested cross-validation protocol? The authors limited model selection to two tabular baselines and note that future improvements may come from advanced representations like convolutional or recurrent neural models.

### Open Question 2
Does the framework generalize to independent cohorts from different geographic regions, healthcare settings, and recording conditions (domain shift)? The authors note that external validation on independent cohorts and explicit domain-shift experiments are essential to establish generalization beyond the current dataset.

### Open Question 3
Do more sophisticated multimodal fusion architectures (attention-based, late fusion) improve performance over simple feature concatenation? The baseline uses simple concatenation, which "can underutilize cross-modal interactions" according to the authors, who suggest exploring late/attention-based fusion and modality-aware training.

### Open Question 4
What preprocessing choices (denoising, segmentation, silence trimming, augmentation) improve or degrade model performance under cougher-disjoint evaluation? The authors applied no preprocessing and note that some schemes were evaluated without improvement, but acknowledge that fixed preprocessing risks removing diagnostically relevant information or leaving nuisance variability.

## Limitations
- Dataset Representativeness: CODA TB uses solicited coughs under controlled conditions, which may not reflect spontaneous coughs in real-world settings.
- Generalizability: Model is trained and validated on a single dataset from specific populations; cross-dataset validation is not performed.
- Clinical Variable Dependency: Fusion improvements rely on availability of 16 clinical variables that may be missing or collected differently in low-resource settings.

## Confidence

- **High Confidence**: Effectiveness of cougher-independent grouped cross-validation in preventing information leakage; superiority of multimodal fusion over audio-only approaches; novel application of conformal prediction for uncertainty quantification.
- **Medium Confidence**: Absolute performance values (ROC AUC ~0.80, PR AUC ~0.63) and their generalizability to real-world deployment; specific impact of different clinical variables on model performance.
- **Low Confidence**: How well calibrated probabilities and conformal prediction sets will maintain coverage guarantees under deployment conditions with potential distribution shift.

## Next Checks
1. **Cross-Dataset Validation**: Test trained models on an independent TB cough dataset (if available) or perform leave-one-site-out validation to assess generalizability across different recording conditions and populations.
2. **Missing Data Simulation**: Systematically remove clinical variables from the test set to quantify degradation in multimodal fusion performance, identifying which variables are most critical for maintaining the performance advantage.
3. **Distribution Shift Analysis**: Perform controlled experiments introducing synthetic noise, different sampling rates, or demographic shifts to test data to evaluate how calibration and conformal prediction coverage degrades under realistic deployment scenarios.