---
ver: rpa2
title: Synthetic Data Augmentation for Cross-domain Implicit Discourse Relation Recognition
arxiv_id: '2503.20588'
source_url: https://arxiv.org/abs/2503.20588
tags:
- data
- discourse
- linguistics
- computational
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates synthetic data augmentation for cross-domain
  implicit discourse relation recognition (IDRR). The authors attempt to improve IDRR
  performance by generating synthetic discourse continuations using large language
  models (LLMs) and unlabeled target-domain data, then adapting a source-domain model
  (trained on PDTB) with this synthetic data.
---

# Synthetic Data Augmentation for Cross-domain Implicit Discourse Relation Recognition

## Quick Facts
- arXiv ID: 2503.20588
- Source URL: https://arxiv.org/abs/2503.20588
- Reference count: 34
- Primary result: Synthetic data augmentation did not yield significant improvements over baseline models for cross-domain implicit discourse relation recognition

## Executive Summary
This study investigates synthetic data augmentation for cross-domain implicit discourse relation recognition (IDRR) using large language models (LLMs) to generate discourse continuations from unlabeled target-domain data. The authors attempt to improve IDRR performance by adapting a source-domain model (trained on PDTB) with synthetic data generated across three target domains (Europarl, Wikipedia, novels). Despite extensive experimentation with various LLM generations, prompt templates, and screening strategies, the synthetic data augmentation approach failed to yield significant improvements over the baseline model.

The generated samples were found to be less ambiguous and more prototypical than real discourse relations, suggesting that current LLM generations may lack the fine-grained understanding needed for this task. Models adapted with synthetic data performed similarly or worse than pseudo-labeling approaches, indicating that synthetic data quality is crucial but insufficient for IDRR. The authors emphasize the importance of both statistical significance and comparability in evaluation, noting that fine-grained discourse inference remains challenging for LLMs.

## Method Summary
The study employs a two-stage approach to cross-domain IDRR: first, a source-domain model is trained on PDTB data; second, this model is adapted to target domains using synthetic data generated by LLMs. The synthetic data generation process involves prompting LLMs with unlabeled target-domain text to produce discourse continuations that instantiate specific discourse relations. Multiple prompt templates and screening strategies are explored to optimize the quality of generated samples. The adapted models are then evaluated on target-domain test sets across three domains: Europarl, Wikipedia, and novels. Various evaluation metrics are used to assess performance, with comparisons made to baseline models and pseudo-labeling approaches.

## Key Results
- Synthetic data augmentation did not yield significant improvements over baseline models
- Generated samples were less ambiguous and more prototypical than real discourse relations
- Models adapted with synthetic data performed similarly or worse than pseudo-labeling approaches

## Why This Works (Mechanism)
The mechanism behind synthetic data augmentation relies on LLMs generating discourse continuations that instantiate specific discourse relations from unlabeled target-domain data. By fine-tuning a source-domain model with these synthetic examples, the approach aims to adapt the model to the target domain's discourse patterns. However, the study finds that generated samples lack the ambiguity and complexity of real discourse relations, suggesting that LLMs struggle to capture the nuanced inferential patterns required for accurate discourse relation recognition.

## Foundational Learning
- Implicit discourse relation recognition: The task of identifying logical relationships between text segments without explicit connectives
  - Why needed: Core task being addressed by the study
  - Quick check: Can the model identify implicit relations like "cause-effect" or "contrast" without explicit markers?

- Cross-domain adaptation: Adapting models trained on one domain to perform well on data from different domains
  - Why needed: PDTB data differs significantly from target domains like Wikipedia and novels
  - Quick check: Does performance drop significantly when applying source-domain models to target domains?

- Large language model generation: Using LLMs to create synthetic examples for training data augmentation
  - Why needed: Source of synthetic discourse continuations for domain adaptation
  - Quick check: Are generated samples grammatically correct and topically relevant to prompts?

## Architecture Onboarding

**Component Map**: Source-domain model -> LLM generator -> Synthetic data screening -> Target-domain model adaptation -> Evaluation

**Critical Path**: The key sequence is source-domain model training on PDTB data, followed by LLM generation of synthetic examples, screening of these examples for quality, and finally fine-tuning the source model with synthetic data for target-domain evaluation.

**Design Tradeoffs**: The study balances between generating diverse synthetic examples (requiring less screening) versus ensuring high-quality examples (requiring more screening). The tradeoff between computational cost of LLM generation versus potential performance gains from synthetic data augmentation is also considered.

**Failure Signatures**: When synthetic data augmentation fails to improve performance, this manifests as models adapted with synthetic data performing similarly or worse than baseline models. The generated samples being less ambiguous and more prototypical than real discourse relations indicates that LLMs struggle to capture the complexity needed for accurate discourse relation recognition.

**First Experiments**: (1) Train baseline model on PDTB data only; (2) Generate synthetic data using different LLM prompts and screening strategies; (3) Fine-tune baseline model with synthetic data and evaluate on target domains

## Open Questions the Paper Calls Out
The study raises fundamental questions about whether current LLMs can reliably capture the nuanced inferential patterns required for discourse relation recognition. The authors acknowledge that while synthetic data quality is crucial, it remains insufficient for IDRR, suggesting that current LLM generations may lack the fine-grained understanding needed for this task. The comparison with pseudo-labeling approaches indicates that synthetic data augmentation may not provide advantages over simpler domain adaptation strategies.

## Limitations
- Synthetic data augmentation failed to improve IDRR performance despite extensive experimentation
- Generated samples lack the ambiguity and complexity of real discourse relations
- The study does not explore whether different model architectures or training procedures might yield better results

## Confidence

| Claim | Confidence |
|-------|------------|
| Synthetic data augmentation did not yield significant improvements | High |
| Generated samples are less ambiguous and more prototypical than real discourse relations | High |
| Current LLMs may lack fine-grained understanding needed for discourse relation recognition | Medium |

## Next Checks
1. Evaluate whether fine-tuning the LLM specifically on discourse relation tasks before generation improves synthetic data quality and downstream model performance
2. Conduct human evaluations of generated samples to better understand the nature of their deficiencies compared to real discourse relations
3. Test whether combining synthetic data with other domain adaptation techniques (such as adversarial training or feature-based adaptation) produces synergistic effects that single approaches cannot achieve