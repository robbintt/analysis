---
ver: rpa2
title: Factorized RVQ-GAN For Disentangled Speech Tokenization
arxiv_id: '2506.15456'
source_url: https://arxiv.org/abs/2506.15456
tags:
- speech
- latexit
- phonetic
- layer
- sha1
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Hierarchical Audio Codec (HAC), a neural\
  \ speech codec that factorizes its bottleneck into three linguistic levels\u2014\
  acoustic, phonetic, and lexical\u2014within a single model. HAC leverages knowledge\
  \ distillation from HuBERT for phoneme-level structure and from LaBSE for lexical\
  \ cues, enabling it to produce disentangled token sets."
---

# Factorized RVQ-GAN For Disentangled Speech Tokenization

## Quick Facts
- arXiv ID: 2506.15456
- Source URL: https://arxiv.org/abs/2506.15456
- Reference count: 0
- Primary result: HAC achieves PNMI of 0.52 across 8 languages with F1 scores up to 0.8 for word detection

## Executive Summary
This paper introduces Hierarchical Audio Codec (HAC), a neural speech codec that factorizes its bottleneck into three linguistic levels—acoustic, phonetic, and lexical—within a single model. HAC leverages knowledge distillation from HuBERT for phoneme-level structure and from LaBSE for lexical cues, enabling it to produce disentangled token sets. Experiments on English and multilingual data show that HAC's factorized bottleneck yields disentangled token sets: one aligns with phonemes, while another captures word-level semantics. HAC outperforms single-level baselines in both disentanglement and reconstruction quality, with multilingual models achieving the highest average Phoneme Normalized Mutual Information (PNMI) of 0.52 across eight languages, and token sets exhibiting strong word detection F1 scores (up to 0.8 for top-performing models).

## Method Summary
HAC employs a three-level factorization approach where the bottleneck is structured into acoustic, phonetic, and lexical components. The model uses knowledge distillation from HuBERT to learn phoneme-level representations and from LaBSE to capture lexical information. This hierarchical structure allows HAC to generate separate token streams that correspond to different linguistic levels. The architecture is trained end-to-end with reconstruction objectives while maintaining the factorized structure. The distillation process ensures that each level captures its intended linguistic properties, with the acoustic level focusing on fine-grained spectral details, the phonetic level encoding phoneme identities, and the lexical level representing word-level semantic information.

## Key Results
- HAC achieves Phoneme Normalized Mutual Information (PNMI) of 0.52 across eight languages with multilingual models
- Token sets show strong word detection performance with F1 scores reaching up to 0.8 for top-performing models
- HAC outperforms single-level baselines in both disentanglement metrics and reconstruction quality
- Factorized bottleneck successfully separates phoneme-aligned tokens from word-level semantic tokens

## Why This Works (Mechanism)
The factorized approach works by explicitly structuring the model's bottleneck to capture different linguistic levels through knowledge distillation. By learning from HuBERT, HAC acquires strong phoneme-level representations that align with speech sound structures. The LaBSE distillation provides lexical-level information that captures word meanings and semantic relationships. This multi-level supervision forces the model to develop distinct representations at each bottleneck level, preventing the collapse of information into a single undifferentiated space. The hierarchical structure enables the model to maintain fine-grained acoustic details while simultaneously learning higher-level linguistic abstractions, creating a more structured and interpretable representation of speech.

## Foundational Learning
- **Knowledge Distillation**: Transferring learned representations from pre-trained models (HuBERT, LaBSE) to guide the training of HAC. Why needed: Provides structured linguistic priors that would be difficult to learn from scratch. Quick check: Verify distillation losses decrease during training.
- **Phoneme Normalized Mutual Information (PNMI)**: Metric measuring alignment between generated tokens and ground-truth phonemes. Why needed: Quantifies how well the phonetic level captures actual speech sounds. Quick check: Compare PNMI scores against random token baselines.
- **Hierarchical Bottleneck Design**: Architectural choice to split the latent space into three distinct levels. Why needed: Enables separation of acoustic, phonetic, and lexical information. Quick check: Verify each level has appropriate dimensionality and receptive fields.
- **Speech Tokenization**: Process of converting continuous speech signals into discrete token sequences. Why needed: Enables efficient compression and linguistic analysis. Quick check: Measure reconstruction quality with different token vocabularies.
- **Multilingual Training**: Training models on multiple languages simultaneously. Why needed: Improves generalization and captures universal speech patterns. Quick check: Compare performance across different language families.
- **Reconstruction Objectives**: Loss functions that ensure the decoded speech matches the original input. Why needed: Maintains audio quality while learning linguistic structure. Quick check: Measure perceptual quality metrics (e.g., PESQ, STOI).

## Architecture Onboarding

**Component Map**: Raw Audio -> Encoder -> Three-Level Bottleneck (Acoustic → Phonetic → Lexical) -> Decoder -> Reconstructed Audio

**Critical Path**: The most important components are the knowledge distillation modules from HuBERT and LaBSE, which provide the linguistic structure that enables disentanglement. The three-level bottleneck architecture is also critical, as it physically separates the different linguistic representations.

**Design Tradeoffs**: The factorized approach trades some reconstruction efficiency for better linguistic interpretability. While single-level codecs might achieve slightly better compression ratios, HAC gains structured representations that could be valuable for downstream tasks. The use of knowledge distillation adds computational overhead during training but provides strong linguistic priors.

**Failure Signatures**: Poor disentanglement would manifest as low PNMI scores and weak F1 scores for word detection. If the three levels collapse into similar representations, the factorized structure provides no benefit. Reconstruction quality degradation would indicate that the factorized bottleneck cannot adequately represent the full speech signal.

**First Experiments**: 
1. Train HAC on a single language (English) to verify basic disentanglement before scaling to multilingual settings
2. Compare PNMI and F1 scores against single-level baseline models to quantify the benefit of factorization
3. Perform ablation studies removing either HuBERT or LaBSE distillation to measure their individual contributions

## Open Questions the Paper Calls Out
None

## Limitations
- The paper lacks extensive qualitative analysis of whether the linguistic factorized tokens capture semantically meaningful units beyond phoneme and word-level alignment
- Absolute reconstruction quality metrics may lag behind state-of-the-art non-disentangled codecs, raising practical deployment concerns
- Claims about semantic utility of the three-level factorization lack empirical support through downstream task performance or human evaluation

## Confidence
- **High Confidence**: The technical implementation of the factorized bottleneck architecture and the knowledge distillation approach from HuBERT and LaBSE is sound and reproducible
- **Medium Confidence**: The quantitative metrics (PNMI, F1 scores) demonstrating disentanglement are reliable, but their correlation with true linguistic structure requires further validation
- **Low Confidence**: Claims about the semantic utility of the three-level factorization lack empirical support through downstream task performance or human evaluation

## Next Checks
1. Conduct human evaluation studies where linguists or language experts assess whether the factorized tokens at each level (acoustic, phonetic, lexical) correspond to meaningful linguistic units beyond statistical alignment
2. Evaluate HAC's token representations on downstream language tasks (e.g., speech recognition, language modeling) to validate whether the disentangled structure provides practical advantages over unified tokenizers
3. Perform ablation studies removing either the HuBERT or LaBSE distillation components to quantify their individual contributions to the observed disentanglement performance