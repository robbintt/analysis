---
ver: rpa2
title: 'SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language
  Models'
arxiv_id: '2601.20856'
source_url: https://arxiv.org/abs/2601.20856
tags:
- planning
- sokoban
- problem
- reasoning
- pddl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SokoBench, a benchmark designed to evaluate
  the long-horizon planning and reasoning capabilities of large language models (LLMs)
  using simplified Sokoban puzzles. The benchmark isolates long-horizon planning from
  state persistence by using linear corridors with minimal branching, where the only
  challenge is maintaining correct counting and state representation over extended
  sequences of actions.
---

# SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models

## Quick Facts
- **arXiv ID**: 2601.20856
- **Source URL**: https://arxiv.org/abs/2601.20856
- **Reference count**: 17
- **Primary result**: Even advanced reasoning models degrade after ~25 moves in linear corridor Sokoban planning tasks

## Executive Summary
This paper introduces SokoBench, a benchmark designed to evaluate long-horizon planning and reasoning capabilities of large language models using simplified Sokoban puzzles. The benchmark isolates long-horizon planning from state persistence by using linear corridors with minimal branching, where the only challenge is maintaining correct counting and state representation over extended sequences of actions. The study tests both reasoning models alone and models augmented with PDDL planning tools (LLM-modulo setting). Results show that even advanced reasoning models exhibit consistent performance degradation when more than 25 moves are required, indicating fundamental architectural limitations in forward planning capacity.

## Method Summary
The benchmark uses linear corridor maps (width ℓ, height 1) with one player, one box, and one goal. Lengths ℓ range from 5 to 100 in increments of 5, with four rotations per map (80 total maps). The study evaluates models using three metrics: accuracy (exact string match), prefix accuracy (proportion of correct prefix symbols), and Manhattan distance from final position to goal. Two setups are tested: (1) 1-shot inference with no external tools, and (2) LLM-Modulo with PDDL parser/validator/solver tools. Models tested include DeepSeek R1, GPT-5, and GPT-oss 120B, with 8 repetitions for LRM and 4 for LLM-Modulo.

## Key Results
- Performance degrades consistently for plans requiring more than 25 moves
- PDDL tool augmentation yields only modest improvements
- Reasoning tokens increase with corridor length but accuracy plateaus and then drops
- Models exhibit counting drift and repetitive looping as failure modes

## Why This Works (Mechanism)
The benchmark isolates long-horizon planning from state persistence by using linear corridors where the only challenge is maintaining correct counting and state representation over extended action sequences.

## Foundational Learning
- **Linear corridor Sokoban**: Simplified puzzle where player moves box along straight path to goal. Why needed: Eliminates branching complexity to isolate counting challenge. Quick check: Map has one row/column with player, box, and goal in sequence.
- **PDDL (Planning Domain Definition Language)**: Symbolic planning language for describing actions, states, and goals. Why needed: Provides external validation and solution generation for planning tasks. Quick check: Domain file contains :action definitions with :parameters, :precondition, and :effect.
- **LLM-Modulo setting**: LLMs augmented with external tools (PDDL parser, validator, solver). Why needed: Tests whether symbolic grounding can overcome architectural limitations. Quick check: Agent loops through perception, reasoning, and action tool calls.
- **Manhattan distance metric**: L1 distance between final position and goal. Why needed: Measures planning effectiveness when exact solution isn't achieved. Quick check: |x₁-x₂| + |y₁-y₂| for final vs goal coordinates.
- **Prefix accuracy**: Proportion of correct symbols in predicted action sequence prefix. Why needed: Provides finer-grained performance measure than binary accuracy. Quick check: Sum(correct prefix symbols) / total prefix length.

## Architecture Onboarding

**Component map**: Corridor maps → ASCII encoding → LLM input → Solution prediction → Metric evaluation

**Critical path**: Map generation → Model inference → Solution extraction → Performance evaluation

**Design tradeoffs**: Linear corridors eliminate branching complexity but may not generalize to richer planning domains. Tool augmentation helps but doesn't overcome core architectural limitations.

**Failure signatures**: Counting drift (incorrect move counts), repetitive looping (same actions repeated until token limit), orientation sensitivity (performance differences between horizontal

## Open Questions the Paper Calls Out
- How do these limitations generalize to non-linear, branching planning scenarios?
- What architectural modifications could enable better long-horizon reasoning?
- Are there alternative training paradigms that could improve forward planning capacity?
- How do different model families compare in their degradation patterns?
- What is the relationship between reasoning token count and planning accuracy?

## Limitations
- Linear corridor maps may not fully capture the complexity of real-world planning scenarios
- Results are limited to specific model families and may not generalize to other architectures
- The benchmark focuses on planning tasks and may not capture other aspects of reasoning
- PDDL tool augmentation shows limited effectiveness, suggesting potential limitations in tool integration approaches
- Performance differences between horizontal and vertical corridor orientations suggest possible orientation biases

## Confidence
High confidence in the core findings about performance degradation beyond 25 moves. The experimental methodology appears sound with adequate sample sizes and multiple metrics. However, the generalization of these results to more complex planning scenarios remains uncertain.

## Next Checks
- Verify the exact model sizes and configurations used in the experiments
- Examine the specific failure patterns in detail for different corridor lengths
- Review the PDDL domain and problem files used for the tool-augmented experiments
- Check the statistical significance of performance differences between model families
- Investigate whether the counting drift patterns show consistent behavior across different models