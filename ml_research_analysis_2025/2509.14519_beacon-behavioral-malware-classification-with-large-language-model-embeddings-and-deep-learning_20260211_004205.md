---
ver: rpa2
title: 'BEACON: Behavioral Malware Classification with Large Language Model Embeddings
  and Deep Learning'
arxiv_id: '2509.14519'
source_url: https://arxiv.org/abs/2509.14519
tags:
- malware
- classification
- embeddings
- behavioral
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces BEACON, a deep learning framework for malware\
  \ classification that leverages large language model (LLM)-generated embeddings\
  \ from raw behavioral reports. The approach uses Google\u2019s textembedding-gecko@003\
  \ model to create dense, context-aware embeddings from sandbox-generated JSON reports,\
  \ which are then processed by a 1D convolutional neural network (CNN) for multi-class\
  \ malware classification."
---

# BEACON: Behavioral Malware Classification with Large Language Model Embeddings and Deep Learning

## Quick Facts
- arXiv ID: 2509.14519
- Source URL: https://arxiv.org/abs/2509.14519
- Authors: Wadduwage Shanika Perera; Haodi Jiang
- Reference count: 32
- Primary result: 98.5% accuracy on Avast-CTU Public CAPE Dataset using LLM embeddings and 1D CNN

## Executive Summary
BEACON introduces a deep learning framework that leverages large language model embeddings for malware classification from sandbox behavioral reports. The system uses Google's textembedding-gecko@003 to transform raw JSON reports into dense, context-aware embeddings, which are then processed by a 1D convolutional neural network for multi-class classification. Evaluated on the Avast-CTU Public CAPE Dataset, BEACON achieves state-of-the-art performance with 98.5% accuracy, outperforming existing methods across eight of ten malware families. The approach eliminates traditional feature engineering by relying on semantically rich embeddings that capture API calls, file activity, and registry operations.

## Method Summary
BEACON processes raw JSON behavioral reports through a recursive chunking strategy using LangChain's RecursiveJsonSplitter to respect the 2048-token limit of the embedding model. Each chunk is embedded using textembedding-gecko@003 to produce 768-dimensional vectors, which are concatenated per file and standardized to a fixed length of 8,448 dimensions (75th percentile of dataset lengths) via PCA and mean-padding. A 1D CNN with three convolutional blocks (kernel=5) processes the fixed-length vectors, followed by dense layers with dropout for classification into ten malware families. The model is trained using Adam optimizer (lr=0.0001) for 200 epochs with a temporal 76/24 train-test split.

## Key Results
- Achieves 98.5% overall accuracy, precision, recall, and F1-score on Avast-CTU Public CAPE Dataset
- Outperforms existing methods on 8 out of 10 malware families, including complex families like Emotet and Qadars
- Demonstrates strong generalization with consistent performance across minority malware classes

## Why This Works (Mechanism)

### Mechanism 1: Dense Contextual Embeddings Encode Behavioral Semantics
Pre-trained LLM embeddings capture meaningful behavioral patterns from raw JSON reports without domain-specific training. The textembedding-gecko@003 model transforms behavioral text into 768-dimensional vectors that preserve semantic relationships, representing malware behavior in a form amenable to pattern detection.

### Mechanism 2: 1D CNN Extracts Hierarchical Discriminative Features from Sequential Embeddings
A 1D convolutional architecture learns family-specific behavioral signatures from concatenated embedding sequences. Stacked 1D convolutions with batch normalization and max pooling progressively abstract local patterns across the embedding sequence.

### Mechanism 3: Structure-Preserving JSON Chunking Maintains Contextual Integrity
Recursive, hierarchy-aware chunking preserves nested JSON relationships, enabling embeddings to capture behavioral context. This ensures each chunk retains coherent behavioral context rather than arbitrary text fragments.

## Foundational Learning

- **Text Embeddings (Transformer-based)**: Why needed here - BEACON relies entirely on pre-trained LLM embeddings as the feature representation. Quick check - Given two behavioral reports with similar API call patterns but different registry key names, would you expect their embeddings to be closer or farther apart than reports with fundamentally different behaviors?

- **1D Convolutional Neural Networks for Sequences**: Why needed here - The classifier operates on sequential embedding vectors using 1D convolutions. Quick check - If behavioral signatures typically span ~20-30 consecutive embeddings but your CNN has an effective receptive field of only 8, what performance symptom would you expect?

- **Behavioral Malware Analysis and Sandbox Reports**: Why needed here - Input data is CAPEv2 sandbox JSON reports containing API calls, file operations, registry changes. Quick check - Why might two samples from the same malware family produce different behavioral reports, and how does this affect classification?

## Architecture Onboarding

- **Component map**: Raw JSON Report → RecursiveJsonSplitter → Chunks → textembedding-gecko@003 → Embeddings → Concatenation → PCA/Mean-padding → 1D CNN → 10-class softmax output

- **Critical path**: 1) JSON preprocessing and chunking (preserve structure; token limit 2,048) 2) Embedding generation via Google Cloud Gemini API (requires API access) 3) Embedding concatenation and dimensionality normalization (PCA for long vectors, padding for short) 4) CNN training with temporal train-test split (76%/24%) and 5-fold cross-validation

- **Design tradeoffs**: Chunking strategy vs. context preservation (smaller chunks fit token limits but may fragment behavioral sequences); 75th percentile length standardization vs. information loss (higher percentile retains more information but increases padding overhead).

- **Failure signatures**: Low accuracy on specific families (e.g., Zeus at 0.927); high variance across cross-validation folds; embedding API failures or rate limits; padding dominance when most samples are much shorter than 8,448 dimensions.

- **First 3 experiments**: 1) Baseline embedding quality check: Train SVM/MLP on embeddings without CNN to isolate representational power. 2) Ablation on chunking strategy: Compare RecursiveJsonSplitter vs. naive splitting on subset of families. 3) Dimensionality sensitivity: Vary PCA target length and observe impact on accuracy, training time, and memory usage.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can a domain-specific embedding model trained end-to-end on malware behavior data outperform general-purpose LLMs like textembedding-gecko in both accuracy and computational efficiency? The authors state plans to develop an end-to-end framework with custom embedding model tailored to malware behavior data.

- **Open Question 2**: How can explainable AI techniques be effectively integrated to interpret the learned representations and identify which specific behavioral features determined the classification? The authors list incorporating explainable AI techniques as a primary direction for future work.

- **Open Question 3**: Does the chunking strategy used to process large JSON reports result in the loss of critical long-range temporal dependencies or cross-chunk context? The paper notes that the 2,048 token limit necessitated splitting reports into chunks via RecursiveJsonSplitter.

## Limitations

- The approach depends heavily on the generalizability of pre-trained LLM embeddings to structured cybersecurity data, an assumption not empirically validated beyond performance metrics.
- The 75th percentile length standardization (8,448 dimensions) appears data-specific and may not transfer to different datasets.
- No ablation studies on key design choices (embedding model selection, chunking strategy, CNN architecture) limits understanding of which components drive performance.

## Confidence

- **High Confidence**: The BEACON framework architecture is correctly described, including the preprocessing pipeline, embedding generation process, and CNN model structure.
- **Medium Confidence**: The claim that BEACON "outperforms existing methods" is supported by comparison to six baseline approaches, but the temporal train-test split methodology is not fully specified.
- **Low Confidence**: The assertion that LLM embeddings "capture meaningful behavioral patterns without domain-specific training" lacks supporting evidence beyond end-to-end performance.

## Next Checks

1. **Embedding Quality Validation**: Extract embeddings for a subset of samples and perform nearest-neighbor analysis to verify that samples from the same malware family cluster together in embedding space.

2. **Temporal Split Verification**: Reconstruct the exact temporal ordering of samples and verify that the 76/24 split maintains chronological integrity.

3. **Ablation on Chunking Strategy**: Implement and compare alternative chunking methods (e.g., fixed-length text windows vs. RecursiveJsonSplitter) on representative malware families.