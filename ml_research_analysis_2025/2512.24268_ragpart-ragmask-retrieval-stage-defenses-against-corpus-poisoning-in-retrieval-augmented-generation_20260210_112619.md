---
ver: rpa2
title: 'RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented
  Generation'
arxiv_id: '2512.24268'
source_url: https://arxiv.org/abs/2512.24268
tags:
- ragpart
- document
- defenses
- ragmask
- against
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2512.24268
- Source URL: https://arxiv.org/abs/2512.24268
- Authors: Pankayaraj Pathmanathan; Michael-Andrei Panaitescu-Liess; Cho-Yu Jason Chiang; Furong Huang
- Reference count: 32
- Primary result: Retrieval-stage defenses RAGPart (partition-then-embed) and RAGMask (token masking) reduce corpus poisoning ASR to <5% on NQ/FIQA datasets

## Executive Summary
This paper introduces two retrieval-stage defenses against corpus poisoning in RAG systems: RAGPart and RAGMask. RAGPart partitions documents into fragments, embeds them separately, and averages combinations to dilute poison influence. RAGMask identifies and removes suspicious tokens by masking segments and measuring similarity drops. Both defenses achieve >90% success rate preservation while reducing attack success rates to <5% on NQ and FIQA datasets, without requiring generator modification.

## Method Summary
The paper proposes two defenses operating at the retrieval stage. RAGPart fragments documents, embeds each fragment individually, creates all (N choose k) combinations, averages embeddings per combination, and retrieves from multiple indexes with majority voting. RAGMask retrieves extra documents, masks token segments to identify suspicious tokens based on similarity shifts, sanitizes documents by removing identified tokens, then re-ranks. Both aim to reduce poisoning attack success while preserving retrieval utility.

## Key Results
- RAGPart reduces ASR to <5% on NQ/FIQA while maintaining >90% SR under benign conditions
- RAGMask achieves similar ASR reduction with better SR preservation (m=10-15, δ=0.01-0.05)
- Both defenses effective across Contriever, ANCE, Multilingual E5, and GTE Large retrievers
- Theoretical sufficient condition derived for RAGPart robustness under majority voting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pre-embedding document fragments and averaging their combinations dilutes the influence of poisoned content.
- **Mechanism:** Each document is split into N fragments and embedded individually before any combination. Poison tokens are typically optimized to affect a single embedding pass—when averaged with clean fragment embeddings, their influence is suppressed. This contrasts with naive concatenation-then-embedding, where poison persists in raw text.
- **Core assumption:** Dense retrievers exhibit an inductive bias where document fragments produce embeddings similar to the full document (observed empirically across Contriever, ANCE, E5, GTE).
- **Evidence anchors:**
  - [abstract]: "RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points."
  - [Section 3.1]: Describes fragment embedding then averaging; Figure 2 illustrates mean pooling advantage.
  - [corpus]: Related work confirms corpus poisoning is an active threat; no external validation of fragment-embedding robustness.
- **Break condition:** If poison tokens are adversarially crafted to dominate mean pooling (e.g., abnormally large embedding norms), defense weakens; anomaly detection may mitigate.

### Mechanism 2
- **Claim:** Tokens causing large similarity drops when masked are likely poison tokens and can be removed.
- **Mechanism:** For each top-αp document, mask segments of length m, recompute query-document similarity. If masked similarity + δ < original similarity, discard those tokens. Remaining "sanitized" documents are re-ranked.
- **Core assumption:** Poison relies on a small set of high-influence tokens; benign content is semantically robust to partial masking.
- **Evidence anchors:**
  - [abstract]: "RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking."
  - [Section 3.2]: Details the masking and thresholding procedure.
  - [corpus]: Weak—no external corpus papers validate token-masking defenses for RAG specifically.
- **Break condition:** If poison is semantically blended (e.g., "Mount Everest is in Spain"), masking won't help; retriever cannot distinguish misinformation at retrieval stage.

### Mechanism 3
- **Claim:** Majority-vote aggregation across (N choose k) fragment-combination retrievals filters adversarial documents without requiring perfect retrieval.
- **Mechanism:** Build (N choose k) embedding databases, retrieve top-p from each, select p documents appearing most frequently. Adversarial documents must win majority across combinations—unlikely if poison influence is diluted per combination.
- **Core assumption:** Poisoned fragments do not dominate a majority of combination embeddings.
- **Evidence anchors:**
  - [Section 3.1]: Describes aggregation strategies; Figure 5-6 compare intersection vs majority vote.
  - [Section 6]: Theoretical sufficient condition derived for robustness under RAGPart.
  - [corpus]: No external validation of aggregation-based defenses found.
- **Break condition:** If p=1, robustness guarantee restores but utility drops sharply; high p increases chance of adversarial inclusion.

## Foundational Learning

- **Concept: Dense Retrieval & Embedding Spaces**
  - **Why needed here:** Both defenses manipulate embeddings—understanding dot-product similarity and how dense models encode semantics is essential.
  - **Quick check question:** Given two document embeddings e1 and e2 and a query embedding q, how would you compute and interpret their similarity scores?

- **Concept: Contrastive Learning Inductive Biases**
  - **Why needed here:** RAGPart exploits the bias that fragment embeddings approximate full-document embeddings, rooted in how retrievers like Contriever are trained.
  - **Quick check question:** Why might a retriever trained with random-crop positive pairs produce similar embeddings for document fragments?

- **Concept: RAG Pipeline Architecture**
  - **Why needed here:** These defenses operate at the retrieval stage; you need to know where they plug in relative to the generator.
  - **Quick check question:** In a standard RAG pipeline, what are the inputs and outputs of the retrieval stage, and how does the generator use them?

## Architecture Onboarding

- **Component map:**
  - **RAGPart:** Document corpus → Partition (N fragments) → Embed each fragment → Generate all (N choose k) combinations → Average embeddings per combination → Build (N choose k) vector indexes → Query embedding → Retrieve top-p from each index → Majority-vote aggregate → Final top-p documents
  - **RAGMask:** Standard retrieval → Top-αp candidates → For each: segment into chunks of length m → Mask each segment → Recompute similarity → Retain/discard tokens per threshold δ → Sanitized documents → Re-rank by similarity → Final top-p

- **Critical path:**
  1. Choose defense based on constraints (RAGPart: lower compute, slight utility drop; RAGMask: higher compute, better utility preservation)
  2. Index-time (RAGPart) vs query-time (RAGMask) preprocessing
  3. Hyperparameter selection: N, k for RAGPart; m, δ, α for RAGMask

- **Design tradeoffs:**
  - RAGPart requires storing (N choose k) embeddings per document—increases index size but retrieval is fast
  - RAGMask adds query-time compute proportional to (αp × document_length / m) embedding passes
  - Both assume poisons are not semantically indistinguishable from legitimate content

- **Failure signatures:**
  - Semantically coherent misinformation (e.g., plausible but false statements) passes both defenses
  - Utility drop if N too large (fragment too small) or δ too aggressive

- **First 3 experiments:**
  1. **Baseline attack reproducibility:** Run HotFlip and Query-as-Poison on your retriever without defense; measure ASR and SR
  2. **RAGPart hyperparameter sweep:** Vary N ∈ {5, 10, 15} and k ∈ {1, 3, 5} on a held-out query set; plot ASR drop vs SR drop
  3. **RAGMask threshold calibration:** Fix m=10, vary δ ∈ {0.01, 0.05, 0.1, 0.5}; observe tradeoff between ASR reduction and SR preservation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can retrieval-stage defenses be developed to distinguish between documents that are semantically similar to a query but factually incorrect (e.g., "The capital of France is Berlin")?
- **Basis in paper:** [explicit] The paper states in Section 7 (Limitations) that it cannot defend against adversarial documents designed to be semantically similar to the query, noting these "cannot be defended against in the retrieval stage" because retrievers encode similarity, not truth.
- **Why unresolved:** The proposed defenses rely on detecting irregularities in embedding similarity or token influence, but fail when the malicious content is semantically aligned with the query, creating a blind spot that currently requires generation-stage intervention.
- **What evidence would resolve it:** A retrieval-stage mechanism that successfully filters out high-similarity misinformation by incorporating external knowledge verification or factuality metrics without invoking the full generation model.

### Open Question 2
- **Question:** How can the partitioning and masking principles of RAGPart and RAGMask be adapted for sparse retrieval systems (e.g., BM25) or hybrid retrieval architectures?
- **Basis in paper:** [inferred] The paper focuses exclusively on dense retrievers (Contriever, ANCE, etc.) because RAGPart exploits specific training dynamics of dense embeddings (fragment similarity). The methodology is not applied to sparse methods, leaving their robustness unaddressed.
- **Why unresolved:** The inductive bias that "document fragments preserve the semantic meaning of the full document" is specific to dense contrastive learning and does not hold for sparse, frequency-based retrieval methods.
- **What evidence would resolve it:** Empirical results showing the efficacy of modified partitioning or masking algorithms on sparse retrievers, or a theoretical proof that such adaptations are infeasible, firmly defining the scope of these defenses.

### Open Question 3
- **Question:** What is the susceptibility of RAGPart and RAGMask to adaptive white-box attacks specifically optimized to generate poisoned embeddings with large norms or stability under masking?
- **Basis in paper:** [inferred] In Section 3.1, the authors note that counteracting RAGPart would require "crafting embeddings with unusually large norms," which they describe as difficult. However, they do not test against an adversary explicitly optimizing for this constraint or for stability against the masking used in RAGMask.
- **Why unresolved:** While the defenses are tested against gradient-based and interpretable attacks, they are not stress-tested against an adversary who has full knowledge of the defense mechanism (partitioning/masking) and optimizes the poison specifically to bypass it.
- **What evidence would resolve it:** Evaluation against a white-box attack that includes the defense's aggregation or masking function in its loss landscape to determine if the robustness holds under maximum adversarial adaptation.

### Open Question 4
- **Question:** Does fine-tuning retrievers with adversarial hard negatives provide a superior or complementary defense compared to inference-time interventions like RAGPart?
- **Basis in paper:** [explicit] In Appendix A.2 (Q&A), the authors suggest that to solve the problem of semantically similar misinformation, "one should consider enhancing the retriever with more hard negatives," framing it as an alternative direction to inference-time defenses.
- **Why unresolved:** The paper introduces inference-time defenses but does not explore the efficacy of training-time robustness methods (like adversarial training with hard negatives) as a comparison or complement to RAGPart/RAGMask.
- **What evidence would resolve it:** A comparative study measuring the trade-offs in computational cost and robustness between training retrievers on generated adversarial negatives versus applying RAGPart during inference.

## Limitations

- The defenses cannot protect against semantic poisoning where misinformation is semantically similar to legitimate content
- No validation against adaptive attackers who optimize specifically to evade RAGPart or RAGMask
- Effectiveness relies on specific inductive biases of dense retrievers and may not generalize to sparse or hybrid retrieval methods

## Confidence

- **High Confidence**: The core mechanism of document partitioning and fragment averaging in RAGPart is well-supported by empirical observations across multiple dense retrievers. The mathematical framework for majority voting aggregation is sound and the theoretical sufficient condition for robustness is clearly stated.
- **Medium Confidence**: RAGMask's token-masking approach shows reasonable effectiveness in the controlled experiments, but the reliance on similarity shifts may not hold for sophisticated semantic poisoning. The assumption that poison tokens can be identified by their impact on retrieval similarity is plausible but not rigorously proven.
- **Low Confidence**: The practical applicability of both defenses against real-world poisoning remains uncertain. The paper does not demonstrate effectiveness against adaptive attackers or provide validation on production RAG systems.

## Next Checks

1. **Adaptive Attack Evaluation**: Implement a poisoning strategy that crafts content designed to evade fragment averaging (e.g., distributing poison across multiple fragments) and test whether RAGPart's effectiveness degrades. This would validate the robustness of the defense against aware adversaries.

2. **Semantic Poisoning Test**: Create poisoned documents containing plausible but false statements (e.g., "Mount Everest is in Spain") and measure whether RAGMask can detect and remove them. This would test the fundamental assumption that poison tokens can be identified by similarity shifts.

3. **Cross-Retriever Generalization**: Test both defenses on a retriever not included in the original study (e.g., DPR or SPLADE) to verify that the observed fragment embedding similarities and defense effectiveness are not specific to the four retrievers examined.