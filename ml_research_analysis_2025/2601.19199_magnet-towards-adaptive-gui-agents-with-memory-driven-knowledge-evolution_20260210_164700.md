---
ver: rpa2
title: 'MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution'
arxiv_id: '2601.19199'
source_url: https://arxiv.org/abs/2601.19199
tags:
- memory
- arxiv
- action
- agents
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MAGNET introduces a memory-driven framework to address GUI agent\
  \ failures caused by evolving mobile interfaces. It employs dual-level memory\u2014\
  stationary memory linking visual UI features to stable functional semantics, and\
  \ procedural memory capturing reusable workflows across interface changes."
---

# MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution

## Quick Facts
- **arXiv ID:** 2601.19199
- **Source URL:** https://arxiv.org/abs/2601.19199
- **Reference count:** 40
- **Primary result:** MAGNET improves GUI agent success rates by 6-12% over memory-free baselines and 1-2% over memory-augmented agents

## Executive Summary
MAGNET introduces a memory-driven framework to address GUI agent failures caused by evolving mobile interfaces. It employs dual-level memory—stationary memory linking visual UI features to stable functional semantics, and procedural memory capturing reusable workflows across interface changes. A dynamic evolution mechanism continuously updates memories by prioritizing frequently accessed knowledge. Evaluated on AndroidWorld and offline benchmarks (AITZ, GUI-Odyssey, Amex), MAGNET demonstrates effective adaptation to appearance and workflow drift while maintaining performance under distribution shifts.

## Method Summary
MAGNET uses a dual-memory framework for GUI agents. Stationary memory stores UI element patches with functional descriptions extracted via OmniParserV2 and Qwen2.5-VL-32B, enabling robust action grounding despite visual changes. Procedural memory captures workflow templates through instruction clustering and LLM abstraction, generalizing across task instances. Both memories are updated dynamically using a retention-based ranking mechanism inspired by the Ebbinghaus forgetting curve, prioritizing frequently accessed and recently created knowledge while deprioritizing outdated entries.

## Key Results
- MAGNET improves success rates by 6-12% over memory-free baselines across multiple benchmarks
- Memory-augmented performance shows 1-2% gains over standard memory-augmented agents
- Dynamic memory evolution effectively discards outdated knowledge, with Amex-derived procedural memories dropping from 100% to 18% retrieval after AndroidWorld adaptation

## Why This Works (Mechanism)

### Mechanism 1: Stationary Memory for Visual-Semantic Linking
**Claim:** Stationary memory enables robust action grounding despite UI visual changes by linking diverse visual features to stable functional semantics.
**Mechanism:** Visual patches of UI elements are stored with functional descriptions. During execution, the actor retrieves patches by matching subtask descriptions to functional text, using visual exemplars to identify target elements even when appearance has changed.
**Core assumption:** Functional semantics of UI elements remain stable across application updates even when visual appearance changes.
**Evidence anchors:** [abstract], [Section 2.2], EchoTrail-GUI (2512.19396)

### Mechanism 2: Procedural Memory for Workflow Generalization
**Claim:** Procedural memory captures reusable workflow templates that generalize across task instances and interface reorganization.
**Mechanism:** Completed task trajectories are clustered by instruction similarity using maximal clique detection. For each cluster, an LLM abstracts common patterns into workflow templates with categorical placeholders.
**Core assumption:** High-level task intents persist across workflow reorganization, and similar instructions share reusable execution patterns.
**Evidence anchors:** [abstract], [Section 2.1]

### Mechanism 3: Retention-Based Memory Ranking
**Claim:** Retention-based memory ranking prioritizes frequently accessed, recently created knowledge while down-weighting outdated entries.
**Mechanism:** Each memory entry tracks creation timestamp, last access time, and retrieval count. A retention score Ri = exp(-gi/ni) is computed where gi = Cglobal - ti. Two-stage retrieval: semantic similarity filters top-N candidates, then retention score and recency rank to top-K.
**Core assumption:** Frequently retrieved knowledge is more reliable, and newer entries better reflect current interface states.
**Evidence anchors:** [Section 2.3.2], [Table 5]

## Foundational Learning

**Concept: Planner-Actor Architecture**
- **Why needed here:** MAGNET builds on the separation between high-level task decomposition (planner) and low-level action execution (actor). Each component accesses different memory types.
- **Quick check question:** Can you explain why task decomposition and action grounding benefit from different memory structures?

**Concept: Semantic Similarity Search with Embeddings**
- **Why needed here:** Both memory modules use cosine similarity between text embeddings for retrieval. Procedural memory matches instruction embeddings; stationary memory matches functional description embeddings.
- **Quick check question:** Given a query "search for weather," would you expect higher similarity to "Search and Install an App" or "Check Weather Forecast"? Why?

**Concept: Distribution Shift / Domain Adaptation**
- **Why needed here:** The paper evaluates on template-shifted, app-shifted, and domain-shifted subsets to test generalization beyond training distribution.
- **Quick check question:** If stationary memory contains icons from App A, will it help when encountering App B with similar functions but different icons? What about when App A updates its icons?

## Architecture Onboarding

**Component map:**
User Request → Planner (+ Procedural Memory) → Subtasks → Actor (+ Stationary Memory) → Actions

**Critical path:**
1. Initialize procedural memory: collect trajectories → embed instructions → build similarity graph → extract maximal cliques → abstract workflows per cluster
2. Initialize stationary memory: collect screen-action triplets → parse screenshots with OmniParserV2 → identify clicked regions → generate functional descriptions with Qwen2.5-VL-32B
3. At inference: planner retrieves workflows → decomposes task → actor retrieves visual patches → grounds actions → executes
4. After success: extract new workflows/patches → update memory with timestamps → apply retention ranking on next retrieval

**Design tradeoffs:**
- Memory size vs. retrieval latency: Larger memory banks improve coverage but slow retrieval. The two-stage ranking (semantic filter → retention rank) mitigates this.
- Clustering threshold (τ): Lower values create more clusters (finer-grained workflows) but may miss cross-task patterns; higher values merge distinct tasks.
- Specialized vs. general MLLM backbones: Heterogeneous pairings gain more from memory (+4.2% SR) than homogeneous setups, as memory compensates for component mismatches.

**Failure signatures:**
- Clustering failure: Tasks with diverse structures that don't form cliques yield no procedural memory entries. Log: empty cluster set after maximal clique extraction.
- Visual grounding mismatch: Stationary memory returns patches with high semantic similarity but wrong visual context. Log: low IoU between retrieved patch and actual target region.
- Outdated memory: Retention ranking fails to deprioritize old entries if they were accessed frequently in the past. Log: high retrieval count (ni) on entries with old timestamps (τi).

**First 3 experiments:**
1. Validate memory construction pipeline: Run stationary memory pipeline on AITZ training set. Manually inspect 50 random entries to verify OmniParserV2 and Qwen2.5-VL-32B accuracy.
2. Test retrieval mechanisms in isolation: Given a held-out instruction, query procedural memory and measure cosine similarity to top-3 retrieved workflows.
3. Evaluate distribution shift handling: Train on Amex source split, evaluate on app-shifted (AS) and domain-shifted (DS) subsets. Compare baseline, procedural-only, stationary-only, both.

## Open Questions the Paper Calls Out
- How can memory-driven GUI agents be initialized effectively in completely novel domains where initial exploration fails to generate successful trajectories?
- How can workflow abstraction mechanisms be improved to handle highly diverse task structures that do not form clear clustering patterns?
- Does the dynamic memory evolution mechanism lead to catastrophic forgetting of general skills when adapting to specific environment quirks?

## Limitations
- Framework requires successful trajectories for memory construction, making it less effective in completely novel domains
- Clustering-based workflow extraction may struggle with highly diverse task structures that do not form clear patterns
- Memory retrieval and update mechanisms add computational overhead during inference

## Confidence
- **High confidence:** Dual-memory framework architecture and its general design principles; memory construction pipeline using OmniParserV2 and Qwen2.5-VL-32B; retention-based ranking mechanism
- **Medium confidence:** Specific quantitative improvements (6-12% SR gains) and distribution shift results, as these depend on exact hyperparameter choices
- **Low confidence:** Claims about long-term adaptation beyond the 3-iteration AndroidWorld evaluation, and robustness to rapid interface changes

## Next Checks
1. **Semantic stability validation:** Track functional description accuracy over successive app updates by comparing pre-update and post-update UI elements in the stationary memory.
2. **Clustering failure rate analysis:** For each task in the procedural memory construction pipeline, log whether maximal clique extraction succeeds or fails. Quantify the proportion of tasks that cannot be clustered due to structural diversity.
3. **Hyperparameter sensitivity test:** Systematically vary retrieval thresholds (Top-N, Top-K) and clustering similarity threshold τ across the full experimental suite. Document how performance changes with each parameter.