---
ver: rpa2
title: 'GQVis: A Dataset of Genomics Data Questions and Visualizations for Generative
  AI'
arxiv_id: '2510.13816'
source_url: https://arxiv.org/abs/2510.13816
tags:
- data
- visualization
- dataset
- queries
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GQVis, the first large-scale dataset for
  natural language to visualization (NL2VIS) in genomics, containing 2.2 million data
  points including 1.14 million single-query pairs, 628k query pairs, and 589k query
  chains. The dataset pairs genomic data questions with interactive visualizations
  using Gosling's grammar-based system, extending the DQVis pipeline with genomic-specific
  templates, entity types (samples, entities, loci), and enriched metadata including
  design justifications, figure captions, and alt-texts.
---

# GQVis: A Dataset of Genomics Data Questions and Visualizations for Generative AI

## Quick Facts
- arXiv ID: 2510.13816
- Source URL: https://arxiv.org/abs/2510.13816
- Reference count: 31
- Primary result: Introduces GQVis, the first large-scale dataset for natural language to visualization in genomics with 2.2 million data points

## Executive Summary
This paper introduces GQVis, the first large-scale dataset for natural language to visualization (NL2VIS) in genomics, containing 2.2 million data points including 1.14 million single-query pairs, 628k query pairs, and 589k query chains. The dataset pairs genomic data questions with interactive visualizations using Gosling's grammar-based system, extending the DQVis pipeline with genomic-specific templates, entity types (samples, entities, loci), and enriched metadata including design justifications, figure captions, and alt-texts. Data sources include 4DN, ENCODE, and Chromoscope repositories. The method involves template generation, expansion with real genomic data, multi-step query curation, and paraphrasing for query diversity. Quality review software ensures dataset robustness. The dataset enables generative AI models to produce domain-specific genomic visualizations and supports downstream applications like quality assessment and caption generation. Future work includes quality assessment frameworks and fine-tuning large language models for genomic NL2VIS tasks.

## Method Summary
The GQVis dataset was generated through a five-step pipeline: (1) Template generation using abstract queries with S/E/L placeholders paired with Gosling specification templates, (2) Template expansion via constraint satisfaction problem solving to find valid sample-entity-locus combinations, (3) Multi-step query curation creating chains of 2-8 queries using five transition types (layout, comparative addition, overlay, location zoom, data stratification), (4) Paraphrasing with GPT-4o to generate up to 25 variants per query varying expertise and formality, and (5) Quality review through custom software. The dataset uses genomic data from 4DN, ENCODE, and Chromoscope repositories, with abstract templates based on seven genomic visualization tasks from prior work.

## Key Results
- 2.2 million data points including 1.14 million single-query pairs, 628k query pairs, and 589k query chains
- Domain-specific placeholder vocabulary (Sample, Entity, Locus) enables systematic query-visualization generation
- Five transition types capture realistic multi-step genomic analysis workflows
- Dataset spans multiple genomic data modalities including structural variants, Hi-C, ATAC-seq, and ChIP-seq

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific placeholder vocabulary (Sample, Entity, Locus) enables systematic query-visualization generation that captures genomic data complexity.
- Mechanism: Abstract query templates use typed placeholders that map to genomic data structures—Sample (S) for donors/patients with metadata, Entity (E) for data types like RNA-seq or Hi-C, Locus (L) for chromosomal positions. Templates pair with Gosling specifications containing matching placeholders, enabling programmatic expansion.
- Core assumption: The seven abstract task types from Nusrat et al. adequately cover the spectrum of genomic visualization tasks.
- Evidence anchors:
  - [abstract]: "Building on prior work with statistical plots, our approach adapts to the complexity of genomics data and the specialized representations used to depict them."
  - [section 3.1]: "we expand this placeholder vocabulary to include: 1. Sample (S)... 2. Entity (E)... 3. Locus (L)"
  - [corpus]: nvBench 2.0 addresses ambiguity in Text2VIS through stepwise reasoning; GQVis addresses domain-specific complexity through typed placeholders—complementary approaches to different NL2VIS challenges.
- Break condition: Novel genomic visualization tasks outside the seven-type taxonomy would produce incomplete coverage.

### Mechanism 2
- Claim: Formulating template expansion as a constraint satisfaction problem ensures only logically valid query-visualization pairs enter the dataset.
- Mechanism: Each query-visualization pair carries constraints (e.g., "E must be visualizable as bar graph," "S1 ≠ S2 for comparison queries"). The CSP solver finds all sample-entity-locus combinations satisfying constraints before concrete substitution, preventing invalid pairings like asking for a point plot of structural variants.
- Core assumption: Hand-crafted constraints accurately capture all semantic relationships between genomic data types and their valid visualization methods.
- Evidence anchors:
  - [section 3.2]: "The reification of abstract queries with a dataset schema is formulated as a constraint satisfaction problem. This locates all sample-entity-locus combinations within the dataset that meet the required constraints."
  - [section 3.2]: "If we are asking a question with a corresponding bar graph as the output visualization, we would add the constraint that the E must be able to be visualized as a bar graph."
  - [corpus]: Weak corpus evidence on constraint satisfaction specifically for genomic NL2VIS—this appears to be a novel application.
- Break condition: Missing constraints would admit invalid pairs; overly restrictive constraints would reduce coverage unnecessarily.

### Mechanism 3
- Claim: Five transition types (layout, comparative addition, overlay, location zoom, data stratification) capture realistic multi-step genomic analysis workflows.
- Mechanism: Query chains inherit visualization state from predecessors via a linked-list structure. Each transition type triggers specification updates—for location zoom, the genomic region changes; for comparative addition, a new stacked view appears. This provides training data for conversational interfaces that maintain context.
- Core assumption: Real genomic analysis sessions predominantly follow these five transition patterns.
- Evidence anchors:
  - [abstract]: "We further incorporate multiple linked queries and visualizations"
  - [section 3.3]: "These chains can help train conversational models to update figures in accordance with user requests."
  - [corpus]: Text-to-TrajVis introduces trajectory-specific NL2VIS; both papers address domain-specific visualization generation, suggesting the chain-based approach generalizes across specialized domains.
- Break condition: If users employ unanticipated transition patterns (e.g., semantic filtering not captured by stratification), models trained on this data would fail to handle those interactions.

## Foundational Learning

- Concept: Gosling visualization grammar
  - Why needed here: All 2.2M dataset entries specify visualizations using Gosling's declarative JSON format; understanding its primitives (tracks, views, layouts) is prerequisite for working with the dataset or extending templates.
  - Quick check question: How does Gosling's support for circular vs. linear layouts differ from Vega-Lite's chart types?

- Concept: Genomic data modalities and file formats
  - Why needed here: The dataset spans structural variants, Hi-C, ATAC-seq, ChIP-seq with distinct visualization requirements (connectivity plots, heatmaps, signal tracks). Constraint definition requires knowing which data types support which visual encodings.
  - Quick check question: What visualization type is appropriate for Hi-C contact matrix data versus point mutation data?

- Concept: Constraint satisfaction problem formulation
  - Why needed here: Template expansion uses CSP to find valid sample-entity-locus combinations. Extending the dataset requires defining new constraints when adding query types or data sources.
  - Quick check question: How would you formulate a constraint ensuring two samples in a comparison query share at least one metadata attribute?

## Architecture Onboarding

- Component map:
  Template Generator -> Schema Module -> Constraint Engine -> CSP Solver -> Chain Builder -> Paraphraser -> AltGosling Generator -> Review Interface

- Critical path:
  1. Author abstract templates with constraints → 2. Load repository schemas → 3. CSP solver produces valid combinations → 4. Substitute placeholders → 5. Generate justifications/captions/alt-text → 6. Build multi-step chains → 7. Paraphrase for syntactic diversity → 8. Subsample for balance → 9. Human review

- Design tradeoffs:
  - **Balance vs. naturalism**: Original dataset was 80%+ sample comparison queries; subsampling improved representation but retained natural distribution skew. Decision: prioritize coverage of underrepresented types over maintaining real-world frequency.
  - **Template coverage vs. authoring burden**: Seven task types with five transition types may not exhaust genomic analysis patterns. Decision: start with established taxonomy, extend based on review feedback.
  - **Synthetic diversity vs. authenticity**: Paraphrasing adds syntactic variation but queries remain template-derived rather than from real users. Assumption: LLM paraphrasing adequately simulates user query variation.

- Failure signatures:
  - **Invalid pairs**: Query asks for visualization incompatible with entity type (constraint failure)
  - **Broken chains**: Follow-up query references visualization state that doesn't match predecessor output
  - **Semantic drift in paraphrases**: GPT-4o alters query meaning while varying formality/expertise
  - **Category imbalance**: One query type dominates despite subsampling

- First 3 experiments:
  1. **Constraint validation audit**: Sample 100 expanded query-visualization pairs across different task types; manually verify semantic validity and constraint satisfaction.
  2. **Chain coherence test**: Generate 50 three-step chains; verify each transition produces a specification that correctly inherits and modifies the prior visualization state.
  3. **Paraphrase semantic equivalence check**: For 20 templates, verify that paraphrases at different expertise/formality levels preserve the original query intent by checking they produce identical Gosling specs when expanded.

## Open Questions the Paper Calls Out

- **Systematic assessment of query-visualization alignment**: The authors are "actively developing a quality assessment framework" and plan "comprehensive robustness evaluation of the entire dataset" as future work extending beyond this contribution. Current review software collects feedback but lacks systematic metrics or automated evaluation criteria for query-visualization alignment.

- **Generalization to unseen query types**: The authors plan to "examine the ability of these models to generalize to unseen query types, thereby establishing benchmarks for NL2VIS systems in genomics." The dataset covers specific task types and visualization templates; real-world queries may fall outside these distributions.

- **Real-world workflow representation**: Synthetic chains may not capture the complexity, domain knowledge, or hypothesis-driven patterns of real genomic analysis. Comparative analysis between synthetic query chains and logged interactions from real genomics researchers using visualization tools would be needed.

## Limitations
- Template-derived nature limits realism compared to actual user queries
- Exact abstract query templates and constraint specifications not enumerated
- Seven-task taxonomy may not fully capture all genomic visualization scenarios
- Five transition types may not represent all real analysis workflows

## Confidence
- **High Confidence**: The dataset creation methodology (template expansion via CSP, multi-step chain building, paraphrasing) is clearly described and technically sound.
- **Medium Confidence**: The claim that domain-specific placeholders (S/E/L) enable systematic query-visualization generation is well-supported by the mechanism description and constraint satisfaction approach.
- **Medium Confidence**: The claim that five transition types capture realistic genomic workflows is reasonable but based on assumed patterns rather than empirical analysis of actual user sessions.
- **Low Confidence**: The dataset's coverage of real-world genomic analysis diversity, given its synthetic nature and template-based origins.

## Next Checks
1. **Constraint Validation Audit**: Sample 100 expanded query-visualization pairs across different task types; manually verify semantic validity and constraint satisfaction to ensure the CSP solver correctly filters invalid combinations.
2. **Chain Coherence Test**: Generate 50 three-step chains; verify each transition produces a specification that correctly inherits and modifies the prior visualization state, ensuring the linked-list structure maintains proper context.
3. **Paraphrase Semantic Equivalence Check**: For 20 templates, verify that paraphrases at different expertise/formality levels preserve the original query intent by checking they produce identical Gosling specs when expanded, ensuring GPT-4o paraphrasing maintains semantic integrity.