---
ver: rpa2
title: 'DiscoSum: Discourse-aware News Summarization'
arxiv_id: '2506.06930'
source_url: https://arxiv.org/abs/2506.06930
tags:
- news
- discourse
- summarization
- label
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DiscoSum, a discourse-aware news summarization
  dataset and method. The authors propose a novel task of structure-aware summarization,
  where summaries are generated to conform to specific discourse label sequences.
---

# DiscoSum: Discourse-aware News Summarization

## Quick Facts
- arXiv ID: 2506.06930
- Source URL: https://arxiv.org/abs/2506.06930
- Authors: Alexander Spangher; Tenghao Huang; Jialiang Gu; Jiatong Shi; Muhao Chen
- Reference count: 31
- Primary result: Proposed method achieves superior structural alignment with discourse labels while maintaining competitive content accuracy compared to baseline models

## Executive Summary
DiscoSum introduces a novel task of structure-aware summarization, where summaries are generated to conform to specific discourse label sequences. The authors develop a discourse schema with five sentence-level labels and collect a large-scale dataset of 20,000 news articles paired with over 100,000 human-written summaries across four social media platforms and newsletters. Their DiscoSum algorithm employs beam search to generate summaries that adhere to target discourse structures, achieving superior structural alignment while maintaining competitive content accuracy.

## Method Summary
DiscoSum combines discourse-aware structural control with content preservation through a sentence-level beam search approach. The method involves three key components: a 5-label discourse schema derived from clustering LLM-generated sentence labels, a discourse labeler trained to classify summary sentences, and a beam search decoder that generates summaries constrained by target label sequences. The approach is evaluated on a novel dataset of 20,000 articles with over 100,000 professional summaries across four platforms, measuring both structural alignment (Match Score, Levenshtein Distance) and content accuracy (ROUGE-L, FactCC).

## Key Results
- DiscoSum achieves superior structural alignment (Match Score) while maintaining competitive content accuracy compared to baseline models
- The method demonstrates effective balance between structural fidelity and factual consistency across different beam sizes
- Human evaluation via MRR shows preference for DiscoSum-generated summaries with appropriate discourse structures

## Why This Works (Mechanism)

### Mechanism 1
Constraining generation at the sentence level with discourse labels improves structural alignment without sacrificing factual accuracy. A sentence-level classifier scores candidate sentences against a target discourse label during beam search, selecting the sentence maximizing the classifier score for the current position. Core assumption: The discourse labeler's predictions are sufficiently accurate and stable to guide decoding without propagating errors.

### Mechanism 2
A low-dimensional discourse schema provides a tractable control signal for multi-platform summarization. The schema defines five sentence-level labels (Introductory Elements, Contextual Details, Event Narration, Source Attribution, Engagement Directive) that act as a compressed structural vocabulary. Core assumption: A 5-label schema can capture meaningful structural variation across diverse platforms.

### Mechanism 3
A large, diverse cross-platform dataset enables learning and evaluation of structure-aware summarization. DiscoSum collects 20k articles with >100k professional summaries across four platforms, providing multiple reference structures per article for training and benchmarking. Core assumption: Professional summaries on social media/newsletters exhibit consistent and learnable discourse patterns tied to platform norms.

## Foundational Learning

**Concept: Beam search for controllable decoding**
- Why needed: Central to DiscoSum's sentence-level structural control
- Quick check: Can you explain how maintaining a beam of partial sequences and selecting based on a classifier score differs from standard token-level beam search?

**Concept: Sentence-level discourse classification**
- Why needed: Provides the reward/guidance signal for decoding
- Quick check: Given a sentence from a news summary, can you assign it to one of the five schema labels with justification?

**Concept: Dataset construction with weak supervision and LLM verification**
- Why needed: Critical for understanding how DiscoSum pairs articles with summaries
- Quick check: What are the failure modes of using LLMs to segment newsletters and verify article-summary matches?

## Architecture Onboarding

**Component map:** DiscoSum Dataset → Discourse Labeler → Beam Search Decoder → Structured Summary Output

**Critical path:**
1. Load DiscoSum dataset (articles + summaries)
2. Train or validate discourse labeler on annotated sentences
3. For inference, specify target label sequence T
4. Run sentence-level beam search: generate candidates, score with labeler, select best, iterate
5. Evaluate with structural metrics (LCS, Match Score, Levenshtein) and content metrics (ROUGE-L, FactCC, AlignScore)

**Design tradeoffs:**
- Beam size: Larger beams improve structural alignment but increase compute
- Schema granularity: 5 labels are simple but may miss nuance
- Edit-based vs. beam search: Edit-based method can improve structure but hurts ROUGE-L

**Failure signatures:**
- Low Match Score despite high beam size: Indicates labeler errors or target sequence T infeasible
- High structural scores but low FactCC/AlignScore: Suggests model hallucinations or over-constraining
- Poor transfer to new outlets/platforms: Schema may not generalize

**First 3 experiments:**
1. Replicate main results: Train labeler, run beam search with BeamSize=16 on test split
2. Ablate beam size: Compare structural and content metrics at beam sizes 2, 4, 8, 16
3. Schema sensitivity: Test an alternative 7-label schema on a subset

## Open Questions the Paper Calls Out

**Open Question 1:** Can models automatically predict the optimal discourse label sequence for a specific platform or audience?
- Basis: Section 3.1 states "Predicting an optimal structure for new input is left for future work"
- Why unresolved: Current DiscoSum assumes target label sequence is supplied a priori
- Resolution evidence: Development of structure prediction module validated by human preference evaluations

**Open Question 2:** Can RAG be integrated into the structural beam search to enhance factual consistency?
- Basis: Limitations section suggests future work should "integrate more robust fact-checking and retrieval-augmented generation"
- Why unresolved: Current method prioritizes structural matching over factuality
- Resolution evidence: Experiments showing RAG-enhanced model achieves higher FactCC/AlignScore while maintaining structural performance

**Open Question 3:** Does fine-tuning the underlying language model on DiscoSum-generated summaries improve inherent structured generation?
- Basis: Section 5.6 suggests harnessing refined outputs to boost training process
- Why unresolved: Current method relies on test-time alignment rather than learned structural patterns
- Resolution evidence: Comparative study showing model fine-tuned on DiscoSum data performs well in vanilla generation setting

## Limitations

- The discourse labeler architecture and training methodology are underspecified, making it difficult to assess reported 90.90% accuracy robustness
- Dataset availability remains unclear with no public release plan, limiting external validation
- The 5-label schema was validated by only two annotators on 500 sentences, which may not capture full structural complexity

## Confidence

- **High confidence**: Overall approach of combining discourse-aware structural control with content preservation is methodologically sound
- **Medium confidence**: Reported performance improvements are plausible given methodology but lack full implementation details
- **Low confidence**: Claims about schema generalizability across platforms and labeler robustness to domain shift are not sufficiently supported

## Next Checks

1. **Implement and evaluate the discourse labeler independently**: Train a sentence-level classifier using publicly available news summary datasets to assess whether similar performance can be achieved without DiscoSum-specific training data

2. **Ablate beam size and candidate generation strategies**: Systematically vary beam size (2, 4, 8, 16) and candidate generation parameters to identify impact on both structural alignment and content quality

3. **Test schema generalizability on external datasets**: Apply the 5-label schema to news summaries from different sources and measure inter-annotator agreement to assess whether schema captures meaningful structural patterns beyond original dataset