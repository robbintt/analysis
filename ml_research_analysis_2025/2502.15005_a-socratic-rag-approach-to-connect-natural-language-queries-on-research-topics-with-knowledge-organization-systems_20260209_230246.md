---
ver: rpa2
title: A Socratic RAG Approach to Connect Natural Language Queries on Research Topics
  with Knowledge Organization Systems
arxiv_id: '2502.15005'
source_url: https://arxiv.org/abs/2502.15005
tags:
- research
- knowledge
- topic
- topics
- collabnext
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel Retrieval-Augmented Generation (RAG)
  approach that bridges natural language queries with structured Knowledge Organization
  Systems (KOSs) in research domains. The method employs a Socratic dialogue framework
  where the agent iteratively refines user queries through multi-round retrieval and
  reasoning across both broad multi-field KOSs and specialized single-field taxonomies.
---

# A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems

## Quick Facts
- arXiv ID: 2502.15005
- Source URL: https://arxiv.org/abs/2502.15005
- Authors: Lew Lefton; Kexin Rong; Chinar Dankhara; Lila Ghemri; Firdous Kausar; A. Hannibal Hamdallahi
- Reference count: 5
- Primary result: Novel Retrieval-Augmented Generation (RAG) approach that bridges natural language queries with structured Knowledge Organization Systems (KOSs) in research domains

## Executive Summary
This paper introduces a Socratic dialogue-based RAG system that maps colloquial research descriptions to formal taxonomic structures. The approach uses a two-phase retrieval mechanism combining broad multi-field KOSs with specialized single-field taxonomies, enhanced by hierarchy-aware reranking that considers ancestor paths and sibling coherence. The CollabNext application demonstrates the method by focusing on HBCUs and emerging researchers, addressing the Matthew Effect in scientific research. The system enables bidirectional exploration of topics while maintaining transparency through human-curated KOS grounding.

## Method Summary
The method employs a Socratic dialogue framework where the agent iteratively refines user queries through multi-round retrieval and reasoning across both broad multi-field KOSs and specialized single-field taxonomies. A hierarchical retrieval mechanism combines semantic similarity with ontological structure awareness, using weighted ancestor paths and sibling coherence for ranking. The system uses SciBERT for generating topic embeddings, implements cosine similarity search with temperature control, and applies a scoring function that incorporates direct similarity, ancestor path weighting, and sibling coherence. The two-phase approach first queries broad multi-field KOSs (e.g., ASJC, DDC) before narrowing to specialized taxonomies (e.g., CSO, CCS) when available.

## Key Results
- Introduces hierarchy-aware reranking that combines semantic similarity with ontological structure using ancestor paths and sibling coherence
- Implements two-phase retrieval bridging broad multi-field KOSs with specialized single-field taxonomies
- Demonstrates CollabNext application focusing on HBCUs and emerging researchers to counter Matthew Effect
- Enables precise mapping between informal research descriptions and formal knowledge structures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Hierarchy-aware reranking improves topic retrieval by combining semantic similarity with ontological structure.
- **Mechanism:** The system first retrieves candidates via embedding similarity, then reranks using a scoring function that incorporates: (1) direct query-topic similarity, (2) weighted ancestor path similarity with distance decay (β^d), and (3) sibling coherence—topics whose siblings also match the query receive a boost.
- **Core assumption:** Ontological relationships in KOS structures (parent-child, sibling) carry meaningful semantic signal that pure embedding similarity misses.
- **Evidence anchors:**
  - [abstract]: "hierarchical retrieval mechanism combines semantic similarity with ontological structure awareness, using weighted ancestor paths and sibling coherence for ranking"
  - [PAGE 4]: score(t) = sim(q, t) + α × Σ β^d × sim(q, a) formula explicitly defined
  - [corpus]: No direct empirical validation in corpus; related work (Hierarchical Lexical Graph) supports multi-hop/hierarchical retrieval benefits but different formulation
- **Break condition:** If KOS structures are shallow, inconsistent, or sparse within a domain, the ancestor/sibling contributions become noise rather than signal.

### Mechanism 2
- **Claim:** Two-phase retrieval bridges "little semantics" (domain-specific KOS) with "big semantics" (broad bibliometric repositories).
- **Mechanism:** Phase 1 queries broad multi-field KOS (e.g., ASJC, OpenAIRE, DDC) to identify high-level research areas through iterative user dialogue. Phase 2 narrows into specialized single-field KOS (e.g., CSO, CCS for Computer Science) using accumulated context. Fields lacking specialized KOS fall back to stricter multi-field filtering.
- **Core assumption:** Users can effectively disambiguate their intent through structured dialogue at the broad level before diving into granular taxonomies.
- **Evidence anchors:**
  - [abstract]: "bridge 'little semantics' (domain-specific KOS structures) with 'big semantics' (broad bibliometric repositories)"
  - [PAGE 4]: Two-phase approach explicitly described with phase transition trigger ("when users confirm topics that have corresponding single-field KOS coverage")
  - [corpus]: No comparable two-phase KOS bridging found; neighbor papers focus on single-pass or attack robustness
- **Break condition:** If the initial broad classification is wrong or the user lacks domain vocabulary to confirm/reject, subsequent specialization compounds error.

### Mechanism 3
- **Claim:** Socratic dialogue grounds LLM outputs in human-curated KOS, improving explainability and alignment with how researchers think.
- **Mechanism:** Rather than returning ranked lists, the agent asks clarifying questions, presents candidate topics with KOS-derived definitions, and solicits feedback across multiple dialogue turns. This exposes provenance (which KOS, which path) and allows bidirectional topic exploration.
- **Core assumption:** Users prefer iterative clarification over single-shot answers, and KOS definitions are comprehensible to non-experts.
- **Evidence anchors:**
  - [abstract]: "Socratic dialogue framework where the agent iteratively refines user queries through multi-round retrieval"
  - [PAGE 3-4]: "agent should engage in meaningful conversation to examine and understand the user's research topic of interest at multiple levels of granularity"
  - [corpus]: MotivGraph-SoIQ (FMR=0.526) combines Socratic dialogue with knowledge graphs for LLM ideation, suggesting plausibility but different task
- **Break condition:** If dialogue feels tedious, users abandon before reaching disambiguation; if KOS definitions are jargon-heavy, they confuse rather than clarify.

## Foundational Learning

- **Concept: Knowledge Organization Systems (KOS)**
  - Why needed here: KOS (ontologies, taxonomies, thesauri, classification schemes) provide the structured ground truth for entity mapping. Without understanding SKOS, MeSH, or domain ontologies, you cannot reason about hierarchical retrieval or ancestor paths.
  - Quick check question: Can you explain the difference between a taxonomy and an ontology, and why both appear in this architecture?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: The paper extends standard single-shot RAG into multi-round, Socratic RAG. You need to understand baseline RAG (retrieve-then-generate) to see why complex queries require iterative refinement.
  - Quick check question: What specific limitation of single-round RAG does this paper identify for research topic disambiguation?

- **Concept: Semantic Embeddings with Domain Adaptation**
  - Why needed here: The system uses SciBERT (not generic BERT) for topic embeddings. Domain-specific pretraining matters for academic vocabulary—cosine similarity on generic embeddings would fail on specialized terminology.
  - Quick check question: Why would SciBERT outperform BERT for clustering computer science abstracts, and how does this choice affect the retrieval stage?

## Architecture Onboarding

- **Component map:** Embedding Layer → Initial Retrieval → Hierarchy-Aware Reranker → Two-Phase KOS Router → Socratic Dialogue Manager → Knowledge Graph Backend (CollabNext)
- **Critical path:** User natural language query → Embedding lookup → Initial semantic candidates → Hierarchy reranking → Phase 1 broad KOS dialogue → User confirmation → Phase 2 specialized KOS drill-down → Final topic entity IDs → CollabNext graph query
- **Design tradeoffs:**
  - **Temperature τ:** Higher = more diverse candidates (good for exploration), lower = tighter semantic matches (good for precision)
  - **Ancestor weight α:** Too high over-emphasizes broad categories; too low ignores hierarchical structure
  - **Decay rate β:** Controls how much distant ancestors matter; domain-dependent tuning likely required
  - **Dialogue turn limit:** More turns = better disambiguation but higher abandonment risk
- **Failure signatures:**
  1. **Empty KOS coverage:** Query resolves to topic with no specialized KOS → falls back to coarse multi-field filtering, loses granularity
  2. **Vocabulary mismatch:** User's colloquial terms have no embedding proximity to formal KOS labels → initial retrieval returns irrelevant candidates
  3. **Dialogue fatigue:** Users drop off before Phase 2 confirmation → system cannot leverage specialized taxonomies
- **First 3 experiments:**
  1. **Baseline comparison:** Implement single-shot RAG (no dialogue, no hierarchy reranking) vs. full Socratic RAG on a held-out set of ambiguous queries (e.g., "plastic recycling"). Measure precision@5 and user satisfaction.
  2. **Ablation on hierarchy:** Disable ancestor path scoring (set α=0) and sibling coherence separately. Quantify contribution of each component to final ranking quality.
  3. **Domain portability test:** Apply the system to a field with rich KOS (Computer Science → CSO/CCS) vs. a field with sparse KOS. Measure fallback frequency and final topic resolution rate.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How should the agent handle natural language queries for topics that cannot be resolved by the Knowledge Organization Systems (KOSs) currently known to the agent?
- **Basis in paper:** [explicit] The authors explicitly ask, "What happens if there is a topic that cannot be resolved by the KOSs that the agent knows about," noting this could signal an emerging research area.
- **Why unresolved:** The current conceptual framework relies on existing ground truth data, lacking a defined mechanism for identifying or managing concepts outside the curated taxonomies.
- **What evidence would resolve it:** A functional module that identifies "unknown" queries and successfully flags them for KOS curators or suggests dynamic candidate nodes.

### Open Question 2
- **Question:** Can the system support bidirectional exploration, allowing users to broaden or narrow topics vertically while also exploring adjacent sibling topics horizontally?
- **Basis in paper:** [explicit] The authors ask, "Would it be possible for users to explore topics both up and down a refinement... as well as exploring adjacent siblings."
- **Why unresolved:** While the hierarchical retriever utilizes ancestor paths and sibling coherence for ranking, the interactive interface for navigational exploration has not yet been implemented.
- **What evidence would resolve it:** A user interface prototype demonstrating successful traversal of the taxonomic hierarchy in multiple directions during a session.

### Open Question 3
- **Question:** How can user interaction histories and usage patterns be integrated into the agent's knowledge base to improve performance over time?
- **Basis in paper:** [explicit] The authors ask, "How would user interactions be incorporated into the agent’s knowledge over time?" specifically regarding identifying gaps between user needs and KOS structures.
- **Why unresolved:** The proposed design focuses on real-time retrieval and reasoning, without detailing an architecture for persisting and learning from dialogue history.
- **What evidence would resolve it:** Evaluation metrics showing improved retrieval accuracy or reduced disambiguation rounds for noisy topics after training on aggregated user logs.

### Open Question 4
- **Question:** What are the optimal weighting parameters for the hierarchy-aware reranking formula to maximize topic relevance?
- **Basis in paper:** [inferred] The paper proposes a reranking score using parameters $\alpha$ (ancestor influence) and $\beta$ (decay rate), but provides no empirical validation for these values.
- **Why unresolved:** As a "visionary" paper without a completed prototype, the authors have not yet conducted experiments to calibrate the influence of ontological structure versus semantic similarity.
- **What evidence would resolve it:** Ablation studies on benchmark datasets measuring retrieval precision (e.g., Recall@k) across varying settings of $\alpha$ and $\beta$.

## Limitations
- No quantitative validation presented; paper remains a vision/work-in-progress
- Missing hyperparameter values for hierarchy-aware reranking function
- No empirical comparison against single-shot RAG baselines
- Unknown dialogue quality without user study or simulated evaluation
- No stress-testing of critical failure modes like dialogue fatigue or vocabulary mismatch

## Confidence
- Mechanism 1 (Hierarchy-aware reranking): Medium - Formula is explicit but no ablation study provided
- Mechanism 2 (Two-phase KOS bridging): Medium - Architecture described but no coverage analysis of fallback behavior
- Mechanism 3 (Socratic dialogue grounding): Low - No dialogue samples, user study, or LLM prompt specifications

## Next Checks
1. Implement controlled experiment comparing Socratic RAG vs. single-shot RAG on 50 ambiguous research queries; measure precision@5 and task completion rate
2. Conduct ablation study removing ancestor path weighting and sibling coherence separately; quantify contribution to retrieval quality
3. Test system on domain with rich KOS (Computer Science) vs. domain with sparse KOS (Humanities); measure fallback frequency and final topic resolution accuracy