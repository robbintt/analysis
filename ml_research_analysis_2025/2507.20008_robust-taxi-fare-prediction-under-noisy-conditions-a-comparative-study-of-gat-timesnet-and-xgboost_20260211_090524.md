---
ver: rpa2
title: 'Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of
  GAT, TimesNet, and XGBoost'
arxiv_id: '2507.20008'
source_url: https://arxiv.org/abs/2507.20008
tags:
- data
- noisy
- noise
- fare
- xgboost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study compares three models\u2014XGBoost, Graph Attention\
  \ Network (GAT), and TimesNet\u2014for taxi fare prediction on a large-scale real-world\
  \ dataset with over 55 million records. It evaluates performance under both clean\
  \ and noisy conditions, using metrics such as MAE, MSE, and R\xB2."
---

# Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost

## Quick Facts
- arXiv ID: 2507.20008
- Source URL: https://arxiv.org/abs/2507.20008
- Reference count: 16
- XGBoost maintains low prediction error and strong calibration under noise, outperforming GAT and TimesNet

## Executive Summary
This study compares three models—XGBoost, Graph Attention Network (GAT), and TimesNet—for taxi fare prediction on a large-scale real-world dataset with over 55 million records. It evaluates performance under both clean and noisy conditions, using metrics such as MAE, MSE, and R². Results show that XGBoost achieves the highest robustness, maintaining low prediction error and strong calibration under noise. GAT exhibits sensitivity to noise, with degraded calibration and higher uncertainty. TimesNet demonstrates moderate noise tolerance but struggles with calibration and out-of-distribution generalization. Denoising improves performance across models, especially for TimesNet. XGBoost emerges as the most reliable choice for structured data and noise resilience, while GAT and TimesNet offer potential for spatial and temporal modeling with further architectural enhancements.

## Method Summary
The study uses NYC Yellow Taxi Trip Records (55M+ rows) with features including pickup/dropoff coordinates, datetime, passenger count, and fare amount. Pre-processing includes KNN imputation, IQR outlier removal, Haversine distance calculation, and temporal feature extraction. Gaussian noise injection and autoencoder denoising are applied for robustness testing. Three models are compared: XGBoost with grid search and early stopping, TimesNet with sliding window sequences and gradient clipping, and GAT with graph nodes representing trips and edges based on fare similarity and temporal adjacency. Evaluation uses MAE, MSE, R², calibration plots, prediction uncertainty, bin-wise MAE, and OOD testing.

## Key Results
- XGBoost maintains MAE 0.1040 (clean) and 0.8203 (noisy) with strong calibration
- GAT R² drops from 0.2153 (clean) to -1.1237 (noisy) with degraded calibration
- TimesNet shows moderate denoising gains but negative R² indicates architectural mismatch
- Denoising improves performance across models, especially for TimesNet

## Why This Works (Mechanism)

### Mechanism 1
- Claim: XGBoost maintains prediction accuracy under noisy inputs better than deep learning alternatives due to its tree-ensemble structure and built-in regularization.
- Mechanism: Gradient-boosted trees partition feature space through axis-aligned splits; L2 regularization (lambda) penalizes complex trees, and early stopping prevents overfitting to noise artifacts. The ensemble averaging effect reduces variance from individual noisy samples.
- Core assumption: Noise is distributed across features rather than systematically biasing specific decision boundaries; tabular structure preserves signal even with perturbed values.
- Evidence anchors:
  - [abstract] "Results show that XGBoost achieves the highest robustness, maintaining low prediction error and strong calibration under noise."
  - [Section VI-C] "XGBoost maintains a flat error profile across fare bins, with limited error spikes at extreme values. Its stability across low- and high-fare segments confirms its reliability."
  - [Section VII] "XGBoost demonstrates the highest resilience to noise injection due to its inherent tree-ensemble structure and built-in regularization capabilities."
- Break condition: Noise levels that fundamentally alter feature distributions (KS test p < 0.05 with severe distribution shift) or adversarial perturbations targeting specific split points may degrade performance beyond recovery.

### Mechanism 2
- Claim: GAT's attention mechanism amplifies noise sensitivity because attention coefficients are computed from perturbed node features, propagating errors through the graph topology.
- Mechanism: Graph attention dynamically weights neighbor contributions; when node features contain Gaussian noise, attention scores become unreliable, leading to incorrect aggregation. The paper constructs edges based on fare similarity and temporal adjacency—both corrupted by noise—disrupting the learned graph structure.
- Core assumption: Graph topology reflects meaningful spatial-temporal relationships; noise does not create spurious edges that dominate attention.
- Evidence anchors:
  - [abstract] "GAT exhibits sensitivity to noise, with degraded calibration and higher uncertainty."
  - [Section VI-B] "When Gaussian noise is introduced, a significant degradation in model performance is observed across all metrics... The model demonstrates near-perfect calibration on the clean dataset, while noise severely disrupts its ability to produce reliable predictions."
  - [Section VI-B, Table II] R² drops from 0.2153 (clean) to -1.1237 (noisy), indicating variance capture failure.
- Break condition: If noise primarily affects edge weights rather than node features, or if attention is regularized with noise-aware dropout, sensitivity may be reduced.

### Mechanism 3
- Claim: Autoencoder-based denoising improves downstream model performance by learning latent representations that filter high-frequency noise while preserving fare-relevant signal.
- Mechanism: The autoencoder is trained on noisy columns to minimize reconstruction error against clean targets; the bottleneck layer forces compression, discarding noise patterns that do not correlate with the underlying fare structure. Denoised outputs provide cleaner inputs for all models.
- Core assumption: Noise is additive and uncorrelated with the true signal; the autoencoder's capacity is sufficient to learn the clean data manifold without overfitting to training noise.
- Evidence anchors:
  - [abstract] "Denoising improves performance across models, especially for TimesNet."
  - [Section IV-A.4] "A deep autoencoder was trained on noisy columns to learn latent representations and reconstruct clean feature vectors."
  - [Section VI-D] "TimesNet demonstrates moderate gains after denoising but remains challenged by noise-induced variability."
- Break condition: If noise is structured (e.g., systematic sensor drift) rather than Gaussian, or if the autoencoder bottleneck is too narrow/too wide, denoising may remove signal or retain noise.

## Foundational Learning

- **Graph Attention Networks (GAT)**: Why needed here: GAT is the spatial modeling approach tested; understanding how attention coefficients are computed and aggregated is essential for diagnosing noise sensitivity. Quick check question: Given node features [x₁, x₂] and neighbor features [y₁, y₂], can you compute the unnormalized attention coefficient using the learned weight matrix W and attention vector a?

- **Calibration and Reliability Diagrams**: Why needed here: The paper evaluates models on calibration (predicted vs. actual reliability); uncalibrated models produce misleading confidence estimates. Quick check question: If a model predicts fares with 80% confidence but only 60% of predictions fall within the stated interval, is the model overconfident or underconfident?

- **Out-of-Distribution (OOD) Detection**: Why needed here: Real-world taxi systems face distribution shifts; OOD testing with noise-perturbed samples assesses robustness beyond training data. Quick check question: Why might R² become negative on OOD data, and what does this indicate about model generalization?

## Architecture Onboarding

- **Component map**: Raw 55M records -> PySpark chunk loading -> KNN imputation -> Gaussian noise injection (optional) -> IQR outlier removal -> Autoencoder denoising (optional) -> Feature engineering (Haversine distance, temporal features) -> Three parallel model paths (XGBoost, GAT, TimesNet) -> Evaluation (MAE/MSE/R², calibration, uncertainty, bin-wise MAE, OOD testing)

- **Critical path**: Preprocessing is the bottleneck: chunk-wise loading is required for 55M records; incorrect imputation propagates to all models. Graph construction for GAT: edges based on fare similarity and temporal adjacency—if noise distorts these, the entire GAT pipeline fails. XGBoost hyperparameter tuning (grid search on tree depth, lambda) determines whether the model overfits or generalizes.

- **Design tradeoffs**: XGBoost vs. deep learning: XGBoost requires manual feature engineering but is robust; GAT/TimesNet learn representations automatically but are noise-sensitive and computationally expensive. Denoising overhead: Autoencoder training adds preprocessing time but improves TimesNet performance; marginal gains for XGBoost. Graph vs. sequential modeling: GAT captures spatial relationships but struggles with calibration; TimesNet captures temporal patterns but has negative R² on this task.

- **Failure signatures**: GAT: R² < 0 on noisy data; calibration plots deviate significantly from diagonal; uncertainty bands widen erratically. TimesNet: U-shaped bin-wise MAE (high errors at fare extremes); negative R² even on clean data suggests architectural mismatch with task. XGBoost: Sharp MAE spikes at extreme fare bins; overconfident predictions with narrow uncertainty bands on OOD data.

- **First 3 experiments**:
  1. Reproduce XGBoost baseline: Train on the clean subset with default hyperparameters, then with the specified grid search (tree depth, lambda). Compare MAE and calibration plots to Table III values (MAE 0.1040 clean, 0.8203 noisy).
  2. Noise sensitivity sweep: Incrementally increase Gaussian noise standard deviation (e.g., 0.1, 0.5, 1.0) and plot MAE degradation curves for all three models. Verify GAT's steeper degradation slope.
  3. Ablation on autoencoder denoising: Train TimesNet with and without autoencoder-preprocessed inputs. Quantify the MAE reduction and check if calibration improves toward the diagonal.

## Open Questions the Paper Calls Out

- **Open Question 1**: Can adversarial training and domain adaptation techniques systematically improve GAT and TimesNet robustness to distributional shifts in real-world deployments? Basis in paper: [explicit] Section VIII states "adversarial training and domain adaptation techniques can be employed to improve robustness to distributional shifts in real-world deployments." Why unresolved: The paper identifies GAT's sensitivity to noise (R² drops from 0.215 to -1.124) and TimesNet's calibration failures under OOD conditions, but does not implement or test any adversarial training approaches. What evidence would resolve it: Comparative experiments showing GAT/TimesNet with adversarial training maintaining stable R² and calibration metrics under noise-perturbed and OOD test conditions.

- **Open Question 2**: How does the choice of graph construction method (fare similarity and temporal adjacency) affect GAT's noise sensitivity and predictive performance? Basis in paper: [inferred] Section IV-B describes edges constructed "based on fare similarity and temporal adjacency," but noise injection disrupts these very features, causing GAT's R² to collapse. The paper does not test alternative graph topologies. Why unresolved: GAT's performance degrades severely under noise (MAE increases 126%), potentially because the graph structure itself is corrupted by perturbed fare and temporal features. Alternative construction methods remain unexplored. What evidence would resolve it: Ablation studies comparing GAT performance using different edge definitions (spatial proximity only, fixed temporal windows, learned embeddings) under identical noise conditions.

- **Open Question 3**: Would incorporating external contextual data (weather, traffic congestion, event calendars) yield significant accuracy gains, and which model benefits most? Basis in paper: [explicit] Section VIII lists "integrating external data sources, such as weather conditions, traffic congestion indices, and event calendars" as a future direction. Why unresolved: The current study uses only GPS coordinates, timestamps, passenger count, and fare amount. Real-world fare variations from weather or events are not captured, potentially limiting all models. What evidence would resolve it: Experiments augmenting the 55M-record dataset with weather and traffic features, reporting per-model MAE/R² improvements and feature importance rankings.

## Limitations
- Key methodological details missing: autoencoder architecture, Gaussian noise injection parameters, and GAT hyperparameters
- Study limited to NYC taxi data, reducing generalizability to other urban contexts
- Negative R² for TimesNet even on clean data suggests architectural mismatch with task

## Confidence
- **High confidence**: XGBoost's superior noise robustness (supported by MAE degradation curves and calibration plots showing flat error profiles)
- **Medium confidence**: GAT's noise sensitivity mechanism (attention coefficients computed from perturbed features, but specific architectural details missing)
- **Medium confidence**: TimesNet's moderate denoising gains (performance improves but calibration remains problematic; negative R² suggests architectural mismatch)

## Next Checks
1. Hyperparameter sensitivity analysis: Perform grid search on XGBoost's tree depth and lambda regularization across multiple noise levels to verify that the reported noise robustness is robust to hyperparameter choice, not just optimal settings.
2. Attention coefficient perturbation study: Inject controlled noise into GAT node features and measure the correlation between input noise levels and attention weight variance to quantify the attention mechanism's noise amplification factor.
3. OOD detection capability: Test all three models on a held-out subset of extreme fare values (e.g., > $100) not seen during training to measure their ability to flag high-uncertainty predictions on distributional outliers.