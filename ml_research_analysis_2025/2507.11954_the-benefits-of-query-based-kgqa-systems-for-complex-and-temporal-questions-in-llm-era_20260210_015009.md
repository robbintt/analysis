---
ver: rpa2
title: The benefits of query-based KGQA systems for complex and temporal questions
  in LLM era
arxiv_id: '2507.11954'
source_url: https://arxiv.org/abs/2507.11954
tags:
- entity
- question
- kgqa
- knowledge
- sparql
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the limitations of large language models in
  answering complex, multi-hop, and temporal questions by proposing a query-based
  KGQA system that generates executable SPARQL queries over Wikidata. The system employs
  a multi-stage pipeline with entity linking, predicate matching, and text-to-SPARQL
  generation, using both fine-tuned models and Chain-of-Thought reasoning for disambiguation.
---

# The benefits of query-based KGQA systems for complex and temporal questions in LLM era

## Quick Facts
- **arXiv ID:** 2507.11954
- **Source URL:** https://arxiv.org/abs/2507.11954
- **Reference count:** 40
- **Primary result:** Query-based KGQA system with multi-stage pipeline and fine-tuned small models outperforms few-shot LLMs on complex, multi-hop, and temporal questions over Wikidata

## Executive Summary
This work addresses the limitations of large language models in answering complex, multi-hop, and temporal questions by proposing a query-based KGQA system that generates executable SPARQL queries over Wikidata. The system employs a multi-stage pipeline with entity linking, predicate matching, and text-to-SPARQL generation, using both fine-tuned models and Chain-of-Thought reasoning for disambiguation. The approach improves robustness through generalization and rejection studies. Experimental results show strong performance on challenging datasets (LC-QuAD 2.0, QALD-10, RuBQ 2.0, PAT), with F1 scores ranging from 20.8% to 39.0% in cross-validation and outperforming direct QA and few-shot methods, particularly on multi-hop and temporal questions. The system also achieves high rejection accuracy (up to 84.5%) for incorrect queries. Code and data are available at https://github.com/ar2max/NLDB-KGQA-System.

## Method Summary
The system uses a three-stage pipeline: entity detection and disambiguation via ReFinED or BM25+CoT (RetReason), predicate detection and disambiguation via BM25+CoT, and auto-regressive query generation with Qwen2.5 models (0.5B-7B parameters). Fine-tuning uses SFT for smaller models and LoRA for larger ones, with specific hyperparameters (max_length=1024, epochs=3, batch_size=8, lr=2e-5). The approach includes entity-predicate filtering and execution-based rejection to improve reliability.

## Key Results
- Multi-stage KGQA pipeline achieves F1 scores of 20.8%-39.0% across datasets, outperforming few-shot GPT-4o
- Fine-tuned small models (0.5B-7B parameters) surpass few-shot large models on multi-hop and temporal questions
- Execution-based rejection achieves up to 84.5% accuracy for identifying incorrect queries
- Cross-dataset generalization shows performance drops, particularly LC-QuAD 2.0 → QALD-10 (20.8% F1)

## Why This Works (Mechanism)

### Mechanism 1: Multi-Stage Decomposition Reduces Compound Error Propagation
- Claim: Decomposing KGQA into discrete stages (entity linking → predicate matching → query generation) improves performance on multi-hop and temporal questions compared to end-to-end approaches.
- Mechanism: Each stage handles a specific subtask with specialized models, reducing the complexity burden on any single component.
- Core assumption: Error propagation across stages is less damaging than attempting to resolve all ambiguities in a single generation step.
- Evidence anchors: Multi-stage approach enhances performance on challenging benchmarks; staged retrieval-reasoning improves complex QA.

### Mechanism 2: Small Model Fine-Tuning Outperforms Few-Shot LLMs on Structured Generation
- Claim: Fine-tuned small language models (0.5B-7B parameters) achieve better SPARQL generation than few-shot GPT-4o on multi-hop and temporal questions.
- Mechanism: Task-specific fine-tuning teaches models Wikidata's query patterns and syntax more effectively than in-context learning.
- Core assumption: Training distribution sufficiently covers query patterns needed at inference.
- Evidence anchors: Qwen-7B + ReFineD achieves F1=46.8 on RuBQ 2.0 vs GPT-4o few-shot F1=38.3.

### Mechanism 3: Execution-Based Rejection Improves Reliability
- Claim: Combining ontology-based entity-predicate filtering with query execution validation enables high rejection accuracy for incorrect queries.
- Mechanism: System checks entity-predicate compatibility and query execution success before returning results.
- Core assumption: Most incorrect queries manifest as execution errors or entity-predicate mismatches.
- Evidence anchors: Achieves up to 84.5% rejection accuracy on RuBQ 2.0.

## Foundational Learning

- Concept: **Wikidata entity/relation identifiers (Q-IDs and P-IDs)**
  - Why needed here: Mapping natural language to numeric identifiers (e.g., Q5 for "human") is required for query execution.
  - Quick check question: Given "Who directed Inception?", can you identify the Wikidata Q-ID for Inception (Q25188) and the P-ID for director (P57)?

- Concept: **SPARQL query structure over knowledge graphs**
  - Why needed here: System generates executable SPARQL queries with multi-hop patterns, FILTER clauses, and OPTIONAL for qualifier handling.
  - Quick check question: Can you write a basic SPARQL query to find all entities with a "director" property, filtering for films released after 2010?

- Concept: **Chain-of-Thought reasoning for disambiguation**
  - Why needed here: RetReason uses CoT prompting to have reasoning models select correct entities/predicates from candidate sets.
  - Quick check question: Given candidates [Apple (Q312), Apple Inc. (Q3908), Apple (fruit) (Q89)], how would you disambiguate based on question context?

## Architecture Onboarding

- Component map: Question → [Entity Retrieval (BM25)] → [Entity Linking (ReFinED/RetReason)] → [Predicate Matching (BM25+CoT)] → [Text-to-SPARQL Generation] → [Execution + Rejection]
- Critical path: Entity linking errors cascade to query generation; predicate matching accuracy directly impacts query correctness.
- Design tradeoffs: Multi-stage decomposition vs. end-to-end approaches; small model fine-tuning vs. few-shot large models.
- Failure signatures: Poor entity linking F1 (<50%), high false positive rate from queries that execute but return wrong answers.
- First experiments: 1) Isolate entity linking F1 to identify bottlenecks, 2) Test execution rejection on semantically incorrect queries, 3) Evaluate component independence to measure error propagation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can joint or end-to-end architectures reduce error propagation compared to the multi-stage pipeline approach?
- Basis in paper: The authors state: "a common issue observed in systems with successive components is the propagation of errors, which ultimately impacts the overall quality."
- Why unresolved: The paper evaluates components independently and jointly but does not compare against architectures that optimize all stages simultaneously.
- What evidence would resolve it: A comparative study measuring end-to-end performance between the proposed sequential pipeline and a jointly trained model on the same benchmarks.

### Open Question 2
- Question: Why does increasing model scale not yield consistent improvements across all datasets for text-to-SPARQL generation?
- Basis in paper: The authors note: "The figure does not exhibit a consistent trend of quality improvement with an increase in scale across all datasets."
- Why unresolved: The paper reports the phenomenon but does not investigate whether data characteristics, query complexity distributions, or training dynamics cause this inconsistency.
- What evidence would resolve it: An ablation study analyzing performance scaling across controlled subsets of questions grouped by query complexity and structure.

### Open Question 3
- Question: Can entity linking for less popular entities be improved without relying on proprietary reasoning models?
- Basis in paper: ReFineD outperforms RetReason but "struggles with less popular entities and dataset generalization," yet RetReason requires API calls to proprietary models.
- Why unresolved: No open-source, fine-tuned solution closes the gap on rare entity disambiguation while maintaining the efficiency of ReFineD.
- What evidence would resolve it: Development and evaluation of a fine-tuned open model matching ReFinED efficiency while improving recall on tail entities.

## Limitations
- Entity linking errors cascade to query generation, limiting overall performance
- Cross-dataset generalization drops significantly, suggesting potential overfitting
- Rejection mechanism may not catch subtle semantic errors that still execute successfully

## Confidence
- **High confidence**: Multi-stage decomposition approach - supported by multiple related works and logical error propagation reduction
- **Medium confidence**: Small model fine-tuning superiority - comparative results show improvement but limited cross-dataset validation
- **Medium confidence**: Execution-based rejection - high rejection rates reported but effectiveness against subtle semantic errors unverified

## Next Checks
1. **Cross-dataset generalization test**: Train on LC-QuAD 2.0 and evaluate on QALD-10 and RuBQ 2.0 to quantify domain adaptation requirements and overfitting risks
2. **Rejection mechanism stress test**: Create a test set of semantically incorrect queries that still execute successfully to measure rejection accuracy on non-obvious errors
3. **Component isolation study**: Evaluate each pipeline stage independently to determine whether entity linking or predicate matching bottlenecks limit overall performance