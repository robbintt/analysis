---
ver: rpa2
title: 'Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex Multimodal
  Noises'
arxiv_id: '2503.02616'
source_url: https://arxiv.org/abs/2503.02616
tags:
- multimodal
- samples
- information
- strong
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Test-Time Adaptation (TTA)
  in multimodal scenarios with complex noise patterns, such as simultaneous corruptions
  across multiple modalities and missing modalities. The authors propose a new task
  called multimodal wild TTA, where the target domain includes various types of distribution
  shifts, including both weak and strong Out-Of-Distribution (OOD) samples.
---

# Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex Multimodal Noises

## Quick Facts
- **arXiv ID:** 2503.02616
- **Source URL:** https://arxiv.org/abs/2503.02616
- **Reference count:** 26
- **Primary result:** Introduces SuMi, a TTA method for multimodal data with complex noise patterns, achieving significant accuracy gains over state-of-the-art methods.

## Executive Summary
This paper tackles the challenge of Test-Time Adaptation (TTA) for multimodal data under complex noise patterns, including simultaneous corruptions across multiple modalities and missing modalities. The authors propose a new task called multimodal wild TTA, where the target domain includes various types of distribution shifts. To address this, they introduce SuMi, a method combining Interquartile Range (IQR) smoothing for gradual adaptation, unimodal assistance for sample selection, and mutual information sharing for cross-modal alignment. The approach is validated on two public datasets, demonstrating superior performance over existing methods.

## Method Summary
SuMi addresses multimodal TTA by gradually adapting to strong Out-Of-Distribution (OOD) samples while preserving source model knowledge. The method uses IQR smoothing to filter samples based on feature representations, avoiding abrupt distribution shifts. Unimodal assistance selects low-entropy samples with rich multimodal information by considering both multimodal and unimodal entropy. Mutual information sharing aligns information between modalities using KL divergence on predictive distributions. The model updates only affine parameters in normalization layers using a combined entropy and MIS loss.

## Key Results
- SuMi outperforms state-of-the-art TTA methods consistently across weak, strong, and mixed OOD domains on Kinetics50-C and VGGSound-C datasets.
- The IQR smoothing technique effectively prevents catastrophic forgetting by gradually adapting to strong OOD samples.
- Unimodal assistance improves sample selection by identifying samples with rich cross-modal information, leading to better adaptation performance.
- Mutual information sharing enhances robustness, especially under corruption or missing modalities, by aligning information across different modalities.

## Why This Works (Mechanism)

### Mechanism 1: Interquartile Range (IQR) Smoothing for Gradual Adaptation
- **Claim:** A gradual adaptation process using Interquartile Range (IQR) smoothing helps preserve the source model's prior knowledge and improves stability when adapting to strong Out-Of-Distribution (OOD) samples.
- **Mechanism:** IQR smoothing filters samples based on their feature representations relative to the distribution's quartiles. By dynamically expanding the acceptance range (controlled by a smoothing function $f(t)$), the model is first exposed to easier (weak OOD) samples and only gradually to harder (strong OOD) samples. This bridges the large distribution gap between source and target domains, preventing catastrophic forgetting or instability.
- **Core assumption:** Samples within the IQR are more stable/representative of the current model state, and a smooth transition from weak to strong OOD samples is better than abrupt exposure to all noise types.
- **Evidence anchors:**
  - [abstract] "SuMi smooths the adaptation process by interquartile range which avoids the abrupt distribution shifts."
  - [section 3.2.1] "In Figure 3(b), we visualize the sample identification process... at first several iterations, most weak OOD samples are selected. With the increase of t, the data for adaptation is also increasing, including more and more strong OOD samples."
  - [corpus] Weak/missing corpus support for this specific IQR mechanism in TTA, so reliance is on internal paper evidence.
- **Break condition:** If the initial weak OOD samples are themselves very noisy or unrepresentative, the smoothing may converge to a poor local optimum before seeing strong OOD samples, or if the distribution shift is entirely uniform (no weak/strong distinction), the method offers no advantage.

### Mechanism 2: Unimodal Assistance for Sample Selection
- **Claim:** Selecting low multimodal entropy samples with *higher* unimodal entropy improves adaptation by ensuring samples contain rich cross-modal information.
- **Mechanism:** Standard TTA selects low-entropy samples. This method adds a filter: multimodal entropy must be low (high confidence) but the sum of unimodal entropies must be above a threshold. Low unimodal entropy suggests the sample can be classified by a single modality alone (less useful for multimodal fusion). Higher unimodal entropy implies the sample relies on the interaction of modalities, making it a better candidate for optimizing the multimodal fusion layers.
- **Core assumption:** Multimodal models are primarily improved by training on samples where the cross-modal information is necessary for the prediction, and unimodal entropy is a proxy for this "informativeness."
- **Evidence anchors:**
  - [abstract] "SuMi fully utilizes the unimodal features to select low-entropy samples with rich multimodal information for optimization."
  - [section 3.2.2, Figure 3(c)] "for audio and video modality, the samples of (20, 40] interval yield better results than samples of [0, 20]. This indicates that for unimodal entropy, lower entropy does not necessarily correlate with better performance."
  - [corpus] No direct corpus support found for this specific unimodal-multimodal entropy trade-off in sample selection.
- **Break condition:** If the dataset's classes are inherently unimodal (e.g., can be solved by video alone), enforcing higher unimodal entropy may filter out too many useful samples, slowing down adaptation or degrading performance.

### Mechanism 3: Mutual Information Sharing (MIS) for Cross-Modal Alignment
- **Claim:** Aligning information between modalities via KL divergence on their predictive distributions reduces modality discrepancy and improves robustness, especially under corruption or missing modalities.
- **Mechanism:** For each modality, MIS computes a "complementary" distribution (average of other modalities) and minimizes the KL divergence between the modality's prediction and a mixture of its complementary distribution and the final multimodal prediction. This forces modalities to share information and align their outputs. If one modality is corrupted/missing, the KL loss (run for a limited number of iterations $t_0$) ensures the model has learned to rely on the shared information space before strong OOD dominates.
- **Core assumption:** Different modalities should arrive at similar predictions for the same input, and aligning them helps the model be robust when one is degraded.
- **Evidence anchors:**
  - [abstract] "mutual information sharing is introduced to align the information, reduce the discrepancies and enhance the information utilization across different modalities."
  - [section 3.3] "Mutual information sharing can help the model connect and align the information between different modalities. Through mutual information sharing, when there are corrupted modalities including missing modalities, information from other modalities could be utilized to enhance the predictions."
  - [corpus] "Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation" mentions "complex coupling effect of unimodal shallow f[eatures]" and addresses it, which aligns with the need for alignment, but uses a different specific method (progressive re-alignment).
- **Break condition:** If modalities provide fundamentally conflicting or orthogonal information (e.g., a deceptive video contradicting truthful audio), forcing alignment via KL may harm performance rather than help. The paper notes this risk by limiting MIS to early iterations ($t_0$) for strong OOD.

## Foundational Learning
- **Concept: Test-Time Adaptation (TTA)**
  - **Why needed here:** This is the core problem setting. You must understand that the model is updated online using only unlabeled test data, without source data or labels.
  - **Quick check question:** Can you explain why Tent (entropy minimization) can fail catastrophically if applied directly to a batch of data with mixed weak and strong distribution shifts?
- **Concept: Multimodal Fusion and Reliability Bias**
  - **Why needed here:** The paper builds on the idea that modalities can be differently affected by noise. "Reliability bias" is the imbalance in information quality across modalities.
  - **Quick check question:** If the audio modality is corrupted but video is clean (weak OOD), how should a robust fusion mechanism behave compared to when both are corrupted (strong OOD)?
- **Concept: Catastrophic Forgetting and Source Model Prior**
  - **Why needed here:** The central motivation of IQR smoothing is to prevent "abrupt distribution shifts" from destroying the source model's useful knowledge.
  - **Quick check question:** Why is preserving the source model's "prior knowledge" important in the TTA setting, and how does updating on strong OOD samples too quickly risk this?

## Architecture Onboarding
- **Component map:**
  - Source Model (M_theta) -> IQR Smoothing Module -> Unimodal Assistance Filter -> MIS Loss Module -> Optimization Loop
- **Critical path:**
  1.  **Batch Inference:** Pass mixed test batch through encoders and fusion layers to get representations ($h$) and logits ($p_{u1}, p_{u2}, p_m$).
  2.  **IQR Selection:** Compute IQR on concatenated $h$. Select samples satisfying the smoothing threshold based on current iteration $t$.
  3.  **Unimodal Filtering:** From IQR-selected samples, calculate entropies. Keep samples matching low multimodal but higher unimodal entropy criteria.
  4.  **Loss Calculation:** For selected samples, calculate weighted entropy loss + MIS loss (if iteration < $t_0$ for strong OOD).
  5.  **Update:** Backpropagate to update affine parameters of Batch Norm/Layer Norm.

- **Design tradeoffs:**
  - **Smoothing aggressiveness:** Linear vs. exponential smoothing (Table 8). Slower initial smoothing may be better but delays full adaptation. The paper finds linear is sufficient.
  - **MIS timing ($t_0$):** Running MIS for too long under strong OOD can corrupt the model with noisy modalities' information. The paper recommends $t_0 = \text{iter}/2$.
  - **Unimodal entropy threshold ($\gamma_u$):** Sets the trade-off for "rich multimodal information." Too high might discard too much data; too low includes unimodal-easy samples.

- **Failure signatures:**
  - **Rapid accuracy collapse:** Likely IQR smoothing is too permissive ($f(t)$ grows too fast) or initial batch is heavily dominated by strong OOD.
  - **Stagnant performance:** Unimodal assistance filter may be too strict, resulting in too few samples for meaningful updates.
  - **Degradation on weak OOD:** MIS might be forced on samples where modalities genuinely disagree, or smoothing is too conservative.

- **First 3 experiments:**
  1.  **Ablation on IQR Component:** Implement the method with and without IQR smoothing on a mixed batch (50% strong OOD). Plot accuracy over iterations to confirm the "bridge" effect of smoothing on preventing initial collapse.
  2.  **Tuning Smoothing Function ($f(t)$):** Compare linear, exponential, and logarithmic smoothing schedules on a mixed severity dataset. Verify if the paper's finding (linear is adequate, exponential slightly better) holds for your specific modality types.
  3.  **Sensitivity to MIS Cutoff ($t_0$):** Run experiments varying $t_0$ (e.g., iter/4, iter/2, 3iter/4, full iter) on a "Both corrupted" strong OOD scenario. Observe if performance drops when MIS is applied for too long, confirming the need for early stopping.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive or learnable smoothing schedules further improve performance over the fixed linear or exponential functions currently implemented?
- Basis in paper: [inferred] Appendix Table 8 compares linear, exponential, and logarithmic smoothing functions, noting that the exponential function yields slightly better results than the linear default.
- Why unresolved: The paper manually selects smoothing functions, but does not explore if the optimal schedule depends on the specific severity or type of noise encountered during testing.
- What evidence would resolve it: Experiments implementing a learnable controller that dynamically adjusts the smoothing function $f(t)$ based on real-time batch statistics.

### Open Question 2
- Question: How does SuMi scale computationally when applied to high-dimensional data or tasks with significantly more than two modalities?
- Basis in paper: [inferred] While Appendix C.1 briefly validates the method on the three-modality CMU-MOSI dataset, the main analysis and hyperparameter tuning focus on audio-visual pairs.
- Why unresolved: The unimodal assistance and IQR smoothing rely on calculating entropy and quantiles across modalities; the sensitivity of these statistics to increasing modality counts (e.g., 4+) is not analyzed.
- What evidence would resolve it: Evaluation on complex benchmarks containing 4+ modalities (e.g., video, audio, text, and sensors) to observe if sample identification remains stable.

### Open Question 3
- Question: What is the specific computational latency introduced by the Interquartile Range (IQR) smoothing and Mutual Information Sharing (MIS) modules during the test-time adaptation loop?
- Basis in paper: [inferred] The method proposes updating only affine parameters to maintain efficiency, but does not report the actual inference time or memory overhead required for the proposed statistical filtering and KL divergence calculations.
- Why unresolved: TTA is often required in real-time applications; the complexity of computing quantiles and mutual information per batch may be prohibitive compared to simpler entropy minimization.
- What evidence would resolve it: A detailed runtime analysis comparing the milliseconds per iteration of SuMi against baselines like Tent or EATA on equivalent hardware.

## Limitations
- The method's reliance on specific corruption patterns (weak vs. strong OOD) is a fundamental assumption that may not hold in all real-world scenarios.
- The unimodal assistance mechanism assumes that higher unimodal entropy indicates "richer multimodal information," which is not universally validated across different dataset domains.
- The performance gains come at the cost of increased computational complexity during test-time adaptation, which may be prohibitive for resource-constrained deployment scenarios.

## Confidence
- **High Confidence:** The effectiveness of IQR smoothing in preventing catastrophic forgetting during TTA adaptation (supported by ablation studies showing baseline collapse vs. stabilized performance)
- **Medium Confidence:** The superiority of SuMi over existing TTA methods across all OOD scenarios (results show consistent improvements but with varying margins across datasets)
- **Low Confidence:** The generalizability of the unimodal assistance entropy thresholds across different multimodal architectures and datasets (thresholds appear dataset-specific with no cross-dataset validation)

## Next Checks
1. **Distribution Shift Sensitivity:** Test SuMi on datasets where weak and strong OOD samples are not clearly separable (e.g., gradual corruption intensity) to validate IQR smoothing's robustness
2. **Cross-Dataset Transferability:** Apply the learned unimodal assistance thresholds from Kinetics50-C to VGGSound-C without re-tuning to test the universality of the entropy-based sample selection
3. **Resource Efficiency Analysis:** Measure the additional computational overhead during adaptation compared to baseline methods and evaluate the trade-off between performance gains and computational cost