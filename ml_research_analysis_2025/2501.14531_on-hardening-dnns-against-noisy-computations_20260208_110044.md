---
ver: rpa2
title: On Hardening DNNs against Noisy Computations
arxiv_id: '2501.14531'
source_url: https://arxiv.org/abs/2501.14531
tags:
- noise
- quantization
- noisy
- training
- robustness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of improving the robustness of
  deep neural networks (DNNs) against inherent noise in analog hardware computations,
  which can degrade accuracy. The authors investigate two main approaches: quantization-aware
  training (QAT) and noisy training, where noise is injected during training to mimic
  inference conditions.'
---

# On Hardening DNNs against Noisy Computations

## Quick Facts
- arXiv ID: 2501.14531
- Source URL: https://arxiv.org/abs/2501.14531
- Reference count: 35
- Primary result: Noisy training and quantization-aware training with constant scaling significantly improve DNN robustness to analog hardware noise, with ResNet architectures showing highest resilience.

## Executive Summary
This paper investigates methods to improve the robustness of deep neural networks (DNNs) to noise inherent in analog hardware computations. The authors evaluate quantization-aware training (QAT) and noisy training, where noise is injected during training to simulate inference conditions. Experiments on CIFAR-10 with LeNet-5, VGG-11, and ResNet-18 show that noisy training consistently improves robustness across all architectures, with ResNet-18 achieving the highest midpoint noise level (µ) due to skip connections. QAT with constant scaling factors also enhances robustness but typically reduces peak accuracy. The results demonstrate that aligning training conditions with inference noise is crucial for hardware deployment.

## Method Summary
The authors employ two hardening approaches: quantization-aware training using the Brevitas library with uniform per-channel and per-tensor quantization, and noisy training with Gaussian noise injection during forward passes. Models are trained on CIFAR-10 using Adam optimizer with cosine learning rate decay (LR=0.001 for LeNet-5, 1×10⁻⁴ for quantized VGG-11, 0.01 for ResNet-18), batch size 128, and 500 epochs without batch normalization or regularization. Noise is added globally to all layer activations at the same intensity during training. Robustness is quantified using the midpoint noise level (µ), calculated by fitting a logistic curve to accuracy degradation across varying noise intensities (σ from 10⁻² to 10²) during inference, repeated over 10 different initializations.

## Key Results
- Noisy training significantly improves robustness across all architectures, with ResNet-18 showing the highest midpoint noise level (µ) due to skip connections.
- Quantization-aware training with constant scaling factors enhances robustness compared to floating-point baselines, but larger scaling factors reduce peak accuracy.
- Dynamic scaling in QAT yields lower robustness than constant scaling or floating-point baselines.
- Quantization does not further improve the robustness of models already trained with noisy training.

## Why This Works (Mechanism)

### Mechanism 1: Alignment of Training and Inference Noise
The paper demonstrates that exposing networks to noise during training that mimics inference conditions forces adaptation to maintain performance. Gaussian noise injection into activations compels the network to learn robust features invariant to perturbations, preventing overfitting to precise deterministic values. This mechanism assumes the training noise distribution approximates the physical noise characteristics of the target analog hardware.

### Mechanism 2: Static Range Reduction via Constant Scaling
QAT with constant scaling factors increases robustness by expanding the quantization range, which increases rounding errors but forces the network to be less sensitive to small perturbations in activation values. Unlike dynamic scaling that tightly fits the range to data (maximizing precision but sensitivity), constant scaling accepts precision loss for stability, acting as a regularizer that outweighs error amplification effects.

### Mechanism 3: Error Mitigation via Skip Connections
Architectures with skip connections (ResNets) exhibit higher robustness to noise compared to sequential architectures. Skip connections allow gradient flow and activation information to bypass noisy intermediate layers, preserving "clean" identity information and reducing error accumulation through network depth. This mechanism assumes the additive noise in residual blocks doesn't completely overwhelm the signal, allowing the identity path to carry valid information.

## Foundational Learning

- **Concept: Midpoint Noise Level (µ)**
  - **Why needed here:** Primary metric used to compare robustness, quantifying noise intensity required to degrade accuracy to halfway between maximum and minimum.
  - **Quick check question:** If Model A has a higher µ than Model B, which model is more robust?

- **Concept: Quantization-Aware Training (QAT)**
  - **Why needed here:** Investigates QAT as a hardening method; requires understanding how "fake quantization" simulates low-precision hardware during training.
  - **Quick check question:** Why is the Straight Through Estimator (STE) necessary when differentiating the quantization function?

- **Concept: Static vs. Dynamic Scaling**
  - **Why needed here:** Distinguishes these as having opposite effects on robustness; dynamic scaling adapts to input statistics (high accuracy, low robustness), while static/constant scaling fixes the range (lower accuracy, higher robustness).
  - **Quick check question:** Why would a fixed range (constant scaling) make a model more tolerant to unexpected noise spikes compared to a dynamic range?

## Architecture Onboarding

- **Component map:** Input -> LeNet-5/VGG-11/ResNet-18 -> Noise Injection Module (post-activation) -> Quantization Wrapper (Brevitas) -> 10-class Classifier

- **Critical path:**
  1. Initialize model (Floating Point)
  2. Wrap layers with QAT logic (Constant Scaling factor s)
  3. **Forward Pass:** Inject Gaussian noise N(0, σ²) onto activations → Quantize (Round/Clamp)
  4. **Backward Pass:** Use STE to approximate gradients through non-differentiable quantization/noise steps
  5. **Evaluation:** Sweep inference noise σ to calculate Midpoint Noise Level µ

- **Design tradeoffs:**
  - **Accuracy vs. Robustness:** Increasing Constant Scaling Factor (s) increases µ (robustness) but decreases Peak Accuracy
  - **Complexity vs. Stability:** Deeper networks (VGG) achieve higher accuracy but suffer from error amplification and have lower µ without noisy training; ResNets balance depth and stability via skip connections

- **Failure signatures:**
  - **Model Collapse:** VGG-11 fails to train or accuracy drops to ~10% if Constant Scaling Factor exceeds architecture limits (e.g., >2 or 3)
  - **False Robustness:** High peak accuracy with very low µ indicates the model is brittle (common with Dynamic Scaling)

- **First 3 experiments:**
  1. **Baseline Sensitivity:** Train standard FP32 LeNet-5 on CIFAR-10, plot accuracy vs. inference noise σ to find baseline µ
  2. **Scaling Factor Sweep:** Train LeNet-5 with QAT using varying Constant Scaling factors (s=0.5, 1, 2, 8), plot trade-off curve between Peak Accuracy and µ
  3. **Noisy Training Validation:** Retrain baseline model with noise injection (σ_train = σ_inference), verify if curve shifts right (higher µ) compared to QAT models

## Open Questions the Paper Calls Out

### Open Question 1
Does achieving robust performance require precise characterization of the inference noise distribution, or are approximate estimates of noise type and strength sufficient for effective noisy training? The paper's Outlook explicitly asks whether robust performance requires "detailed knowledge of system noise" or if "approximate estimates" suffice. This remains unresolved as experiments assume precise alignment between training and inference noise.

### Open Question 2
How does the inclusion of Batch Normalization impact the effectiveness of quantization-aware and noisy training methods in hardening DNNs? The authors omit Batch Normalization to isolate noise effects but state in a footnote that "Future work will revisit noise and regularization in combination." This is significant since Batch Normalization is standard in modern architectures like ResNet, yet its interaction with global noise injection remains unexplored.

### Open Question 3
Can robustness be significantly improved by optimizing scaling factors or noise injection levels on a per-layer basis rather than using the global settings employed in this study? The methodology applies uniform noise and scaling factors globally, but the Outlook suggests exploring techniques adapted to "each layer's unique sensitivity profile." A granular approach might mitigate the accuracy-robustness trade-off by targeting only sensitive layers.

## Limitations

- The paper doesn't explore the sensitivity of robustness gains to misalignment between training and inference noise distributions or intensities.
- The mechanism explaining ResNet's superior robustness through skip connections lacks detailed validation of how noise specifically affects residual connections versus other architectural components.
- The theoretical justification for why constant scaling enhances robustness while dynamic scaling doesn't remains incomplete, relying primarily on empirical observations.

## Confidence

- **High confidence**: Claims about noisy training improving robustness across all architectures are well-supported by experimental results.
- **Medium confidence**: The mechanism explaining ResNet's superior robustness through skip connections is plausible but not thoroughly validated.
- **Medium confidence**: The explanation of constant scaling's hardening effect through precision reduction is supported but could benefit from more theoretical analysis.

## Next Checks

1. Verify noise injection implementation by testing both weight-based and activation-based noise injection to confirm the paper's assumption of additive noise on activations.
2. Systematically explore the clipping range parameters for constant scaling to identify the relationship between scaling factor and robustness more precisely.
3. Conduct ablation studies on ResNet architectures to isolate the contribution of skip connections to noise robustness by comparing with modified architectures lacking these connections.