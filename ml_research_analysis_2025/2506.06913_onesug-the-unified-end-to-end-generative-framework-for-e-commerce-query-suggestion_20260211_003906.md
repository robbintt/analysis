---
ver: rpa2
title: 'OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion'
arxiv_id: '2506.06913'
source_url: https://arxiv.org/abs/2506.06913
tags:
- query
- onesug
- user
- queries
- suggestion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes OneSug, the first end-to-end generative framework
  for e-commerce query suggestion, addressing inefficiencies in traditional multi-stage
  cascading architectures. The framework incorporates a prefix2query representation
  enhancement module to enrich ambiguous short prefixes with semantically and interactively
  related queries, a unified encoder-decoder generative model to directly output user-interested
  queries, and a reward-weighted ranking strategy to capture fine-grained user preferences.
---

# OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion

## Quick Facts
- **arXiv ID:** 2506.06913
- **Source URL:** https://arxiv.org/abs/2506.06913
- **Reference count:** 40
- **Primary result:** First end-to-end generative framework for e-commerce query suggestion, achieving significant improvements over traditional multi-stage cascading architectures in both offline metrics (HitRate@16, MRR) and online A/B testing (CTR, Order, Revenue, reduced input length and response time).

## Executive Summary
This paper proposes OneSug, the first end-to-end generative framework for e-commerce query suggestion, addressing inefficiencies in traditional multi-stage cascading architectures. The framework incorporates a prefix2query representation enhancement module to enrich ambiguous short prefixes with semantically and interactively related queries, a unified encoder-decoder generative model to directly output user-interested queries, and a reward-weighted ranking strategy to capture fine-grained user preferences. Evaluated on large-scale industry datasets, OneSug significantly outperforms traditional methods, achieving average improvements of 3.19% in HitRate@16 and 4.54% in MRR compared to online multi-stage systems. Online A/B testing shows OneSug decreases average input length by 1.82%, reduces top click position by 9.33%, increases CTR by 2.01%, Order by 2.04%, and Revenue by 1.69%, while reducing system response time by 43.21%.

## Method Summary
OneSug replaces the traditional multi-stage cascading architecture (query recall, pre-ranking, ranking) with a unified end-to-end generative framework. It first enhances short, ambiguous prefixes using a Prefix2Query Representation Enhancement (PRE) module that combines aligned embeddings with RQ-VAE to retrieve semantically related queries. A unified encoder-decoder model (BART/Qwen) then generates the final query list directly from the augmented input. Finally, a reward-weighted ranking strategy with behavior-level weights aligns the model with fine-grained user preferences. The system is trained in two stages: supervised fine-tuning on prefix-query pairs, followed by direct preference optimization using list-wise ranking with dynamic weights based on user interaction levels.

## Key Results
- Achieves average improvements of 3.19% in HitRate@16 and 4.54% in MRR compared to traditional multi-stage systems in offline evaluation
- Online A/B testing shows decreased average input length by 1.82%, reduced top click position by 9.33%, increased CTR by 2.01%, Order by 2.04%, and Revenue by 1.69%
- Reduces system response time by 43.21% compared to traditional cascading architectures

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enhancing ambiguous short prefixes with related semantic and business-context queries improves the recall and relevance of suggestions.
- **Mechanism:** The Prefix2Query Representation Enhancement (PRE) module uses an aligned representation model (BGE) combined with RQ-VAE to map short, ambiguous prefixes (e.g., "apple") to a hierarchy of semantic IDs. It augments the prefix embedding by averaging embeddings of co-occurred queries, bridging the gap between content semantics and business conversion characteristics.
- **Core assumption:** Users often input prefixes with latent commercial intent that is not explicit in the text but is captured in historical interaction logs (co-occurrence).
- **Evidence anchors:**
  - [abstract] "...prefix2query representation enhancement module to enrich prefixes using semantically and interactively related queries..."
  - [section 3.2] "...alleviate the insufficient semantic representation of short prefixes, but also combine semantic and conversion characteristics effectively."
  - [corpus] Neighbor papers (e.g., "From Prompting to Alignment") suggest generative recommendation is an active trend, though specific RQ-VAE prefix augmentation evidence is localized to this paper.
- **Break condition:** If user behavior is highly volatile or non-stationary, historical co-occurrence embeddings may propagate outdated intent, failing to represent current trends.

### Mechanism 2
- **Claim:** Unifying the recall, pre-ranking, and ranking stages into a single generative model eliminates the error accumulation and objective inconsistency inherent in cascading architectures.
- **Mechanism:** The unified encoder-decoder architecture (based on BART/Qwen) replaces the Multi-stage Cascading Architecture (MCA). It takes the prefix, augmented queries, and user history as input and autoregressively generates the final query list. This ensures the optimization objective is consistent throughout the process.
- **Core assumption:** A single generative model has sufficient capacity to model the complex mapping from partial input to ranked query lists without the intermediate funneling of candidates required by traditional systems.
- **Evidence anchors:**
  - [abstract] "...suffer from inefficiencies and suboptimal performance due to inconsistent optimization objectives across stages."
  - [section 1] "...heterogeneous modules with different optimization objectives may lead to sub-optimal performance..."
  - [corpus] "OneSearch" and "EGA" papers confirm a broader industry shift toward unified end-to-end frameworks to overcome MCA limitations.
- **Break condition:** If the beam search size is too small or the model capacity is insufficient, the model may fail to explore the candidate space effectively, resulting in lower recall than multi-stage systems.

### Mechanism 3
- **Claim:** Fine-grained user preference alignment using a Reward-Weighted Ranking (RWR) strategy with list-wise optimization improves ranking accuracy over standard binary preference learning.
- **Mechanism:** Instead of standard pair-wise DPO, this method categorizes user interactions into 6 levels (e.g., Order > Click > Show) and computes a dynamic weight ($r_{w\Delta}$) based on the "level gap" between samples. It uses a hybrid list-wise ranking loss to optimize the model, forcing it to distinguish nuances between multiple negative samples simultaneously.
- **Core assumption:** The "level gap" between user behaviors (e.g., buying vs. viewing) represents a quantifiable difference in preference strength that standard binary labels (positive/negative) fail to capture.
- **Evidence anchors:**
  - [abstract] "...reward-weighted ranking strategy with behavior-level weights to capture fine-grained user preferences."
  - [section 3.4] "...straightforward sampling with only selecting the best and worst samples... fails to fully leverage user preference data..."
  - [corpus] Corpus contains related work on alignment (e.g., "Unifying Ranking and Generation..."), but specific list-wise DPO with behavior-level weighting appears novel to this implementation.
- **Break condition:** If the assumption of behavior hierarchy breaks (e.g., high "Show" counts for a query actually imply higher intent than a misclick "Order"), the reward weights will misguide the alignment.

## Foundational Learning

- **Concept:** **Generative Retrieval (GR) vs. Discriminative Retrieval**
  - **Why needed here:** OneSug replaces the traditional "retrieve-then-rank" (discriminative) pipeline with a "generate" (generative) approach. Understanding that the model generates the query identifier string directly rather than scoring a static list is fundamental.
  - **Quick check question:** Does the model output a probability score for a list of candidates, or does it output the text of the query itself?

- **Concept:** **Residual Quantized Variational AutoEncoder (RQ-VAE)**
  - **Why needed here:** Used in the PRE module to discretize continuous embeddings into hierarchical "Semantic IDs." This allows the system to group similar queries in a tree-like structure for efficient retrieval and augmentation.
  - **Quick check question:** How does the "fine-to-coarse" search strategy using RQ-VAE codes reduce the computational complexity of finding related queries compared to a brute-force vector search?

- **Concept:** **Direct Preference Optimization (DPO)**
  - **Why needed here:** The User Preference Alignment module uses DPO to align the model with human/business preferences without training a separate reward model. You must understand how the policy network is optimized directly against the reference network using preference data.
  - **Quick check question:** In standard DPO, how does the loss function change if the preferred sample ($y_w$) is much more likely under the policy than the rejected sample ($y_l$)?

## Architecture Onboarding

- **Component map:** Input Layer (Prefix, User Profile, History) -> PRE Module (BGE Aligned Embedder -> RQ-VAE -> Prefix2Query Augmentation) -> Backbone (Unified Encoder-Decoder) -> Training/Alignment (SFT -> Reward-Weighted Ranking) -> Inference (Beam Search -> Generated Query List)

- **Critical path:** The most critical path for deployment is the transition from the Seed Model to the Aligned Model. The Seed Model is trained via standard Supervised Fine-Tuning (SFT) on (prefix, query) pairs. The performance gain comes from the second stage: constructing the list-wise preference dataset with specific behavior-level weights and applying the hybrid ranking loss.

- **Design tradeoffs:**
  - Beam Size vs. Latency: The paper notes that while larger beam sizes (up to 256) improve performance, they introduce "unacceptable delay." The deployed version compromises on a smaller beam size (32) to balance business conversion and response time.
  - ID-based Features vs. Text Semantics: The paper explicitly warns against using raw ID-based features (like User ID) in the generative model as they interfere with text semantics. They recommend Semantic IDs or avoiding IDs entirely for open-vocabulary tasks.

- **Failure signatures:**
  - Long-tail drop-off: If the PRE module is ablated, expect a significant performance drop specifically for low-frequency (long-tail) prefixes.
  - Ranking collapse: If using standard pair-wise DPO instead of the proposed list-wise RWR, expect MRR to stagnate because the model fails to distinguish between "good" and "best" candidates effectively.
  - Semantic Drift: If the alignment step (SFT) uses noisy data without filtering for "high-quality" pairs, the model may generate grammatically correct but commercially irrelevant queries.

- **First 3 experiments:**
  1. PRE Ablation: Run offline evaluation with and without the Prefix2Query enhancement module. Verify the delta in HitRate@16 specifically for prefixes with low historical frequency.
  2. Alignment Strategy Comparison: Compare standard pair-wise DPO vs. the proposed List-wise Reward-Weighted Ranking. Check if the gap in MRR justifies the increased complexity of sample construction.
  3. Latency Profiling: Measure end-to-end system response time with beam sizes of [16, 32, 64]. Compare against the traditional MCA baseline to confirm the paper's claim of a ~43% reduction in response time.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can ID-based features be efficaciously introduced into open-vocabulary generative models for query suggestion?
- **Basis in paper:** [explicit] Section 4.5 states that for open-vocabulary tasks, "how to efficaciously introduce ID-based features, is a problem worthy of further research."
- **Why unresolved:** The authors note that simply adding meaningless IDs interferes with semantic sequences, while current Semantic ID methods only achieve parity with non-ID-based models.
- **What evidence would resolve it:** A method that integrates ID-based features into the generative framework to achieve statistically significant gains over the current text-only OneSug baseline.

### Open Question 2
- **Question:** What are the optimal strategies for keeping generative models updated regularly to maintain performance stability?
- **Basis in paper:** [explicit] Section 4.5 poses the question, "How to keep the generative model updated regularly is a question worth thinking about."
- **Why unresolved:** The paper observes that without daily updates, the model suffers a performance drop (-0.6% in CTR), and while a 3-day preference alignment update helps, a comprehensive update strategy is undefined.
- **What evidence would resolve it:** A systematic analysis of update frequencies and data windows that prevents performance degradation over time without incurring prohibitive computational costs.

### Open Question 3
- **Question:** How can the trade-off between beam size and system latency be optimized to maximize prediction accuracy?
- **Basis in paper:** [inferred] Section 4.3 notes that while increasing beam size improves performance, it "companies with increasing unacceptable delay," and concludes this "requires further research."
- **Why unresolved:** The current deployment limits beam size (e.g., to 32) to maintain low latency, potentially capping the model's ranking capability.
- **What evidence would resolve it:** An inference acceleration technique that allows for significantly larger beam sizes (e.g., >100) while maintaining the reduced response time improvements reported in the paper.

## Limitations
- Performance claims rely heavily on proprietary Kuaishou e-commerce data and internal infrastructure, making independent validation difficult
- Several technical details are underspecified, including exact hyperparameter values for DPO margin and regularization weights, specific thresholds for RQ-VAE fine-to-coarse search, and detailed feature engineering for user profile inputs
- The behavioral hierarchy assumption underlying reward-weighted ranking may not generalize across different e-commerce domains or user populations

## Confidence
- **High Confidence:** The general framework architecture (PRE module + unified generative model + reward-weighted ranking) and the overall performance improvement trends are well-supported by the results
- **Medium Confidence:** The specific mechanisms of the RQ-VAE fine-to-coarse search and the exact implementation details of the list-wise DPO with behavior-level weights
- **Low Confidence:** The absolute performance metrics (specific HitRate@16 and MRR percentages) and the generalizability of the reward hierarchy across different e-commerce contexts

## Next Checks
1. **PRE Ablation Study:** Conduct offline evaluation comparing OneSug with and without the Prefix2Query enhancement module, specifically measuring performance degradation on low-frequency prefix queries to validate the module's contribution
2. **Alignment Strategy Comparison:** Implement and compare standard pair-wise DPO against the proposed list-wise Reward-Weighted Ranking using the same dataset, measuring differences in MRR to quantify the impact of the fine-grained preference modeling
3. **Latency-Performance Tradeoff Analysis:** Profile end-to-end system response time across multiple beam sizes (16, 32, 64) and compare against traditional multi-stage architectures to verify the claimed ~43% reduction in response time while maintaining acceptable query suggestion quality