---
ver: rpa2
title: LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding
arxiv_id: '2512.06982'
source_url: https://arxiv.org/abs/2512.06982
tags:
- uni00000013
- uni00000048
- uni00000003
- uni00000011
- architecture
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of designing state encoders
  for reinforcement learning with multiple heterogeneous input sources, such as sensor
  measurements, time-series signals, image observations, and textual instructions.
  The authors propose a composite neural architecture search (NAS) approach called
  LACER that uses a large language model (LLM) as a design agent to automatically
  discover high-performing composite state encoders.
---

# LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding

## Quick Facts
- **arXiv ID:** 2512.06982
- **Source URL:** https://arxiv.org/abs/2512.06982
- **Reference count:** 40
- **Primary result:** LACER outperforms traditional NAS baselines (DARTS, ENAS, PEPNAS) and LLM-based GENIUS framework on mixed-autonomy traffic control task with improved sample efficiency

## Executive Summary
This paper tackles the challenge of designing state encoders for reinforcement learning systems that process multiple heterogeneous input sources including sensor measurements, time-series signals, image observations, and textual instructions. The authors propose LACER, a composite neural architecture search approach that uses a large language model as a design agent to automatically discover high-performing composite state encoders. The LLM leverages language-model priors and intermediate-output signals such as representation quality to guide sample-efficient search through the architecture space.

The experimental results demonstrate that LACER discovers superior architectures with fewer candidate evaluations compared to traditional NAS baselines and the LLM-based GENIUS framework. The approach achieves improved sample efficiency and RL performance by incorporating richer performance feedback signals including task metrics, average rewards, and feature information, making it particularly effective for complex multi-source RL environments.

## Method Summary
LACER employs an LLM-driven design agent that operates as a controller in a neural architecture search framework specifically tailored for composite state encoders in multi-source RL environments. The LLM uses its language model priors to guide the search process, leveraging intermediate-output signals like representation quality and task metrics to make informed architecture selections. The search process evaluates candidate architectures based on multiple feedback signals including average rewards, task-specific metrics, and feature information from intermediate layers, enabling more informed decision-making compared to traditional reward-only optimization approaches.

## Key Results
- LACER discovers higher-performing architectures with fewer candidate evaluations than traditional NAS baselines (DARTS, ENAS, PEPNAS)
- Outperforms LLM-based GENIUS framework on mixed-autonomy traffic control task
- Demonstrates improved sample efficiency and RL performance through incorporation of richer performance feedback signals
- Shows consistent improvements across multiple evaluation metrics in experimental results

## Why This Works (Mechanism)
The approach leverages the LLM's ability to understand and generate architectural patterns through language model priors, which helps guide the search toward promising regions of the architecture space more efficiently than random or gradient-based methods. The LLM can interpret intermediate-output signals like representation quality and task metrics, using these signals to refine its architectural suggestions iteratively. This language-guided search process allows the model to incorporate domain knowledge and architectural best practices encoded in its training data, leading to more informed and sample-efficient exploration of the architecture space.

## Foundational Learning

**Neural Architecture Search (NAS):** Automated methods for discovering optimal neural network architectures
- *Why needed:* Manual architecture design is time-consuming and often suboptimal for complex multi-source RL environments
- *Quick check:* Verify understanding of basic NAS concepts like search space, controller, and evaluation metrics

**Composite State Encoders:** Neural architectures that process and combine multiple heterogeneous input sources
- *Why needed:* RL agents must effectively integrate diverse data types (sensors, images, text) into unified representations
- *Quick check:* Can you explain how different input modalities might require different encoding strategies?

**Large Language Model Priors:** Knowledge and patterns encoded in pre-trained LLMs from massive text corpora
- *Why needed:* Provides inductive biases that guide architecture search toward promising designs
- *Quick check:* Consider what architectural knowledge might be implicitly learned by LLMs during training

**Intermediate-Output Signals:** Performance metrics extracted from intermediate layers during architecture evaluation
- *Why needed:* Provides richer feedback than final task rewards alone, enabling more informed search decisions
- *Quick check:* Identify potential intermediate signals useful for evaluating state encoder quality

## Architecture Onboarding

**Component Map:** LLM Controller -> Architecture Generator -> Candidate Evaluation -> Performance Feedback -> LLM Update -> (repeat)
- The LLM controller generates architecture proposals
- Architecture generator creates concrete implementations
- Candidates are evaluated in the RL environment
- Performance feedback (including intermediate signals) is collected
- LLM updates its understanding for next iteration

**Critical Path:** LLM Controller -> Architecture Generator -> RL Environment Evaluation -> Performance Feedback -> LLM Update
- This loop represents the core search iteration that drives architecture discovery

**Design Tradeoffs:** Sample efficiency vs. search space coverage, LLM prompt complexity vs. search quality, intermediate signal richness vs. evaluation overhead
- Balancing these factors determines overall effectiveness of the search process

**Failure Signatures:** Poor architecture convergence, over-reliance on specific prompt templates, insufficient intermediate signal quality, domain-specific prompt degradation
- These indicate where the LLM-guided search may be breaking down

**Three First Experiments:**
1. Test LLM's ability to generate valid composite encoder architectures from basic prompts
2. Evaluate intermediate signal quality and its correlation with final RL performance
3. Compare search efficiency of LLM-guided approach versus random search baseline

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Focus on single RL domain (mixed-autonomy traffic control) limits generalizability to other multi-source RL problems
- LLM-based design agent performance heavily depends on prompt engineering quality with limited ablation studies on prompt variations
- Intermediate-output signals are domain-specific and may not transfer directly to other RL environments without adaptation
- Computational cost comparison lacks detailed breakdown, making practical deployment trade-offs difficult to assess

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| LACER outperforms traditional NAS baselines (DARTS, ENAS, PEPNAS) | High |
| Improved sample efficiency compared to traditional methods | Medium |
| LLM priors enable better design guidance | Low-Medium |

## Next Checks

1. Replicate experiments across diverse RL domains (robotics, game playing, resource management) to test