---
ver: rpa2
title: 'DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling'
arxiv_id: '2512.01153'
source_url: https://arxiv.org/abs/2512.01153
tags:
- control
- dpac
- guidance
- energy
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DPAC addresses the instability of adversarial diffusion sampling,
  where standard gradient guidance causes catastrophic quality collapse (high FID)
  despite high attack success rates. The core method projects adversarial gradients
  onto the tangent space orthogonal to the score, removing the harmful normal component
  that distorts the data distribution.
---

# DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling

## Quick Facts
- arXiv ID: 2512.01153
- Source URL: https://arxiv.org/abs/2512.01153
- Reference count: 40
- DPAC achieves FID 33.90 at one-third the energy cost of baseline, while baseline catastrophically fails at high guidance scales (FID 69.37 vs. 45.34)

## Executive Summary
DPAC addresses the instability of adversarial diffusion sampling, where standard gradient guidance causes catastrophic quality collapse (high FID) despite high attack success rates. The core method projects adversarial gradients onto the tangent space orthogonal to the score, removing the harmful normal component that distorts the data distribution. Theoretically, this minimizes path-space KL divergence, tightening bounds on Wasserstein distance and FID. Empirically, DPAC achieves superior peak fidelity (FID 33.90) at one-third the energy cost of the baseline (FID 34.66), while remaining robust under extreme guidance scales where the baseline collapses catastrophically (FID 69.37). This validates the theoretical principle that distribution-preserving control unifies effectiveness and fidelity.

## Method Summary
DPAC introduces a novel adversarial control mechanism for diffusion sampling that projects adversarial gradients onto the tangent space orthogonal to the score function. The method decomposes any gradient vector into tangential (density-preserving) and normal (density-changing) components, removing the latter to maintain distribution quality. This projection is applied during the reverse diffusion process, with perturbations injected via a PGD-style denoise-then-perturb approach. The theoretical framework establishes that this tangential control minimizes path-KL divergence, which bounds Wasserstein distance and FID, while also reducing discretization error from O(Δt) to O(Δt²) in discrete samplers.

## Key Results
- DPAC achieves FID 33.90 at one-third the energy cost of baseline AdvDiff (FID 34.66)
- At extreme guidance scale η=10.0, DPAC maintains FID 45.34 while baseline catastrophically fails (FID 70.21)
- Normal-only control achieves near-zero ASR (3.5%) with high FID (58+), confirming the mechanism
- Late-stage (last 20%) injection is optimal; early injection fails completely (0.25% ASR)

## Why This Works (Mechanism)

### Mechanism 1: Tangential Projection Removes Distribution-Destroying Normal Component
- **Claim:** Projecting adversarial gradients onto the score-orthogonal tangent space preserves data distribution while maintaining attack effectiveness.
- **Mechanism:** Any gradient vector decomposes into (1) a tangential component that moves along iso-density surfaces (preserves density), and (2) a normal component parallel to the score that pushes samples off-manifold. The projection operator Π⊥ removes the harmful normal component: u⋆ = w - ⟨w,s⟩G/⟨s,s⟩G · s (Eq. 16).
- **Core assumption:** The score function approximates the true gradient of log-density well enough that score-orthogonality correlates with density preservation.
- **Evidence anchors:** [abstract] "component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift"; [Section 3.3] Fokker-Planck analysis shows ∇·(ptut) = 0 ensures first-order density preservation.

### Mechanism 2: Path-KL Bounds Perceptual Quality via Information-Transport Inequality
- **Claim:** Minimizing path-space KL divergence simultaneously tightens upper bounds on Wasserstein distance and FID.
- **Mechanism:** Girsanov's theorem establishes KL(Pu||P0) = ½∫||ut||²dt (Eq. 5). This path-KL upper-bounds marginal KL at t=0 (Eq. 6), which bounds W₂ via Talagrand inequality (Eq. 7), which bounds FID via Lipschitz embedding (Eq. 8). The chain: path-KL → marginal KL → W₂ → FID.
- **Core assumption:** The clean terminal distribution p₀⁰ satisfies Talagrand T₂(C) inequality; the FID feature embedding ϕ is L-Lipschitz.
- **Evidence anchors:** [abstract] "minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and Fréchet Inception Distance (FID)"; [Section 3.2] Full derivation of Eqs. 5-8 with explicit constants.

### Mechanism 3: Discrete Solver Error Cancellation from Tangential Control
- **Claim:** Tangential control reduces leading discretization error from O(Δt) to O(Δt²) in Wasserstein distance.
- **Mechanism:** In discrete samplers, the normal component Π∥uk contributes a non-vanishing O(1) term to W₂² error (Eq. 18). Tangential control sets this to zero, leaving only O(Δt²max) discretization remainder. The cross-term ⟨δk, u⊥k⟩ vanishes at first order because accumulated error lies in the span of past normal components, orthogonal to current tangential control.
- **Core assumption:** Lipschitz drift/score, uniformly bounded and well-conditioned metric G, shared-noise coupling between controlled and nominal chains.
- **Evidence anchors:** [abstract] "tangent projection cancels the O(Δt) leading error term in the Wasserstein distance, achieving an O(Δt²) quality gap"; [Supp. 13.2] Empirical validation: at η=10.0, baseline FID degrades to 70.21 (N=200) while DPAC maintains 45.34.

## Foundational Learning

- **Stochastic Differential Equations (SDEs) for Diffusion:**
  - Why needed here: The entire theoretical framework builds on reverse-time SDE formulation (Eq. 2) and Girsanov's theorem for changing drift.
  - Quick check question: Can you explain why the reverse SDE requires the score function sθ(Xt,t) = ∇Xt log pt(Xt)?

- **Score Functions and Score Matching:**
  - Why needed here: The score defines the geometry (tangent/normal decomposition) and is the key signal for what constitutes "distribution-preserving."
  - Quick check question: Why does the score point in the direction of highest data density increase?

- **KL Divergence and Talagrand Inequality:**
  - Why needed here: The theoretical chain from path-KL to FID requires understanding how KL bounds Wasserstein distance via T₂ inequality.
  - Quick check question: What does it mean for a distribution to satisfy T₂(C), and why does this matter for transport costs?

- **Girsanov's Theorem (basic intuition):**
  - Why needed here: The identity KL(Pu||P0) = ½∫||ut||²dt is foundational; you need to understand why changing drift changes path measure.
  - Quick check question: How does adding drift ut to an SDE change the path-space distribution?

## Architecture Onboarding

- **Component map:** Base sampler Φbase -> Sensitivity oracle Gk⁻¹ -> Projection module -> Normalization -> Scale scheduler ηk -> Injection
- **Critical path:**
  1. Sample xk and compute score sk via conditional U-Net
  2. Denoise to xclean via base sampler Φbase
  3. Compute adversarial gradient w at xclean (forward + backward pass through classifier)
  4. Project w to tangent space using score sk and metric Gk
  5. Normalize to unit direction û
  6. Apply perturbation: xk-1 = xclean + ηk · û
  7. Repeat for steps in guidance window

- **Design tradeoffs:**
  - **Metric choice (Gk = I vs. noise-scaled):** Ablation (Tab. 2) shows negligible difference; use Gk = I for simplicity.
  - **Guidance window (early vs. late vs. full):** Late 20% is optimal (Tab. 6). Early injection fails (ASR 0.25%) because coarse structure is already set; full window slightly worse FID.
  - **Injection method (SDE drift vs. PGD):** SDE drift modification is numerically unstable (signal vanishes as g·Δt→0); PGD-style is robust and achieves O(1) displacement per step.
  - **Normalization:** Critical for stability. Raw gradients have unbounded magnitude; normalization ensures ηk exclusively controls step size.

- **Failure signatures:**
  - **Catastrophic FID collapse at high η:** Baseline (AdvDiff) shows FID jumping from ~40 to ~70 at η≥5.0; indicates normal component accumulation.
  - **Numerical explosion without normalization:** Raw projected gradients can still have large variance; always project-then-normalize.
  - **Zero ASR with early-only injection:** Semantic structure is fixed early; adversarial control must target fine-grained features late.
  - **High FID with NormalOnly control:** Confirms normal component is purely destructive (Tab. 4: ASR 3.5%, FID 58+).

- **First 3 experiments:**
  1. **Sanity check (η=2.0, N=50):** Compare AdvDiff vs. DPAC with shared noise. Expect DPAC to achieve similar ASR (~100%) with lower FID and ~66% less CPE. Verify projection is working.
  2. **Stability stress test (η=10.0, N=200):** Confirm baseline collapses (FID > 60) while DPAC remains stable (FID ~45). Validates discrete error bound claim.
  3. **Negative control (NormalOnly):** Use only the normal component u∥ = ⟨w,s⟩/⟨s,s⟩·s as control. Expect near-zero ASR and high FID, confirming the mechanism.

**Assumption:** The paper assumes classifier-free guidance (CFG) with scale 3.0 for ygt. If your base model uses different conditioning, adjust the score computation accordingly. The theory assumes clean-conditioned scores; unconditional scores may require metric adjustments.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can higher-order approximations to the exact p_t-divergence-free projector improve upon the first-order score-orthogonal surrogate used in DPAC?
- Basis in paper: [explicit] "The exact p_t-divergence-free projector is intractable in high dimensions; our practical rule removes only the score-parallel component and is therefore a first-order surrogate for the true p_t-tangential field, so that with approximate scores or finite-step discretization a small density-changing residual can remain."
- Why unresolved: Computing the true divergence-free subspace requires solving a high-dimensional PDE constraint (∇·(p_t v) = 0), which is intractable; the paper only explores the simplest orthogonal projection.
- What evidence would resolve it: Empirical comparison with alternative projections (e.g., learned projectors, iterative refinement) showing improved FID at matched ASR and energy.

### Open Question 2
- Question: Is there an optimal metric G_t for the inner product that outperforms the identity and noise-scaled choices, particularly when the score field is highly anisotropic?
- Basis in paper: [explicit] Table 2 shows identity and noise-scaled metrics yield "nearly identical" results, but Section 10.3 notes "for full consistency the true tangential space is {v: ∇·(p_t G_t v) = 0}; we adopt ∇·(p_t v) = 0 for clarity, which coincides when G_t ≈ I."
- Why unresolved: The paper only tests two simple metrics; the relationship between metric choice and performance when score geometry is complex remains unexplored.
- What evidence would resolve it: Ablation with adaptive metrics (e.g., based on local curvature or Fisher information) showing measurable FID/energy differences.

### Open Question 3
- Question: How can the theoretical path-KL bounds be rigorously extended to the discrete PGD-style injection used in practice, which breaks the Girsanov identity?
- Basis in paper: [explicit] "Because the denoise-then-perturb injection breaks the exact path–KL identity, we report CPE as a proxy... This discrete, PGD-style injection breaks the strict assumptions required for the Girsanov identity."
- Why unresolved: The continuous SDE theory provides tight bounds, but the practical algorithm deviates fundamentally; CPE is a heuristic proxy without formal justification.
- What evidence would resolve it: Derivation of modified bounds for PGD-style perturbations, or empirical verification that CPE correlates with terminal distribution metrics across diverse settings.

### Open Question 4
- Question: What is the principled optimal schedule for the guidance window (temporal extent and ramp-up shape), beyond the heuristic late-window strategy?
- Basis in paper: [explicit] "We use a late-window schedule (e.g., last 20% of steps) to reduce early trajectory drift" and Table 6 shows early window fails completely (0.25% ASR).
- Why unresolved: The 20% choice appears arbitrary; early injection causes manifold drift but the trade-off curve between window position, ASR, and FID is not characterized.
- What evidence would resolve it: Systematic sweep over window start times and ramp shapes, with theoretical analysis of when adversarial control most effectively shifts class probability.

## Limitations

- Score approximation quality: The entire tangent/normal decomposition relies on accurate score estimates, but no validation of score quality is provided.
- Real-world attack robustness: Experiments focus on synthetic target classifiers; performance against robust/classifier-trained targets remains unknown.
- Computational overhead trade-offs: Additional forward/backward passes through classifier are not explicitly quantified in CPE calculations.

## Confidence

**High Confidence** (Strong theoretical backing, multiple empirical validations):
- Tangential projection removes normal component and improves stability at high guidance scales
- Path-KL minimization provides upper bounds on Wasserstein distance and FID
- Late-stage (last 20%) injection is optimal for adversarial control
- Normalization is critical for numerical stability

**Medium Confidence** (Well-supported theoretically but limited empirical scope):
- Discrete solver error cancellation achieving O(Δt²) quality gap
- Metric choice (G=I vs. noise-scaled) has negligible impact
- The specific linear ramp schedule for ηk is optimal

**Low Confidence** (Limited direct evidence):
- Performance against robust/classifier-trained targets
- Generalization to other diffusion architectures (e.g., latent diffusion)
- Score quality impact on projection effectiveness

## Next Checks

1. **Score quality ablation**: Evaluate DPAC performance when using unconditional vs. classifier-free guided scores, or with different CFG scales, to quantify score quality impact on projection effectiveness.

2. **Robust classifier evaluation**: Test DPAC against adversarially trained or robust classifiers (e.g., PGD-trained) to assess real-world attack robustness beyond synthetic targets.

3. **Adaptive metric exploration**: Implement and compare adaptive metrics based on local score geometry (e.g., Fisher information-weighted) to test whether better metrics can improve FID/energy trade-offs beyond the simple identity metric.