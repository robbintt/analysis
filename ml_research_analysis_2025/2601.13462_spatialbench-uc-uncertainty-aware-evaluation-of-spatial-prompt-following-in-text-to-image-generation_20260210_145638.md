---
ver: rpa2
title: 'SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following
  in Text-to-Image Generation'
arxiv_id: '2601.13462'
source_url: https://arxiv.org/abs/2601.13462
tags:
- pass
- checker
- confidence
- coverage
- spatial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SpatialBench-UC introduces an uncertainty-aware evaluation framework
  for automated spatial prompt-following assessment in text-to-image generation. The
  key challenge is that object detectors can miss targets, return multiple instances,
  or produce ambiguous geometry, making binary pass/fail verdicts unreliable.
---

# SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation

## Quick Facts
- **arXiv ID**: 2601.13462
- **Source URL**: https://arxiv.org/abs/2601.13462
- **Reference count**: 28
- **Primary result**: Introduces uncertainty-aware evaluation framework for spatial prompt following, allowing abstention and confidence reporting to address detector noise and ambiguity.

## Executive Summary
SpatialBench-UC tackles the challenge of reliably evaluating spatial prompt following in text-to-image generation by introducing an uncertainty-aware framework. Traditional binary pass/fail verdicts are unreliable due to object detector errors and ambiguous geometry. The solution allows explicit abstention (UNDECIDABLE) and reports confidence, framing results as a risk-coverage trade-off. This approach is validated through a lightweight human audit and applied to three methods, showing grounding methods improve pass rate and coverage while reducing risk through higher confidence thresholds.

## Method Summary
The method addresses automated spatial prompt-following assessment by allowing explicit abstention (UNDECIDABLE) and reporting confidence, framing results as a risk-coverage trade-off. It uses 200 prompts grouped into 100 counterfactual pairs via role-swapping for consistency analysis. A lightweight human audit calibrates parameters and validates risk-coverage curves. The framework is applied to three methods—Stable Diffusion 1.5 (prompt-only), SD 1.5+BoxDiff, and SD 1.4+GLIGEN—demonstrating that grounding methods significantly improve both pass rate and coverage, while abstention remains common mainly due to missing detections. Calibration shifts the evaluator toward safer decisions, increasing near-boundary margins and selecting higher confidence thresholds, reducing risk at the cost of lower coverage.

## Key Results
- Grounding methods (BoxDiff, GLIGEN) significantly improve both pass rate and coverage in spatial prompt following.
- Calibration shifts the evaluator toward safer decisions, increasing near-boundary margins and selecting higher confidence thresholds.
- Abstention is dominated by detection failures rather than ambiguity in geometry, suggesting the framework may not yet fully address the uncertainty it aims to measure.

## Why This Works (Mechanism)
The framework works by explicitly acknowledging the inherent uncertainty in object detection outputs, allowing for abstention (UNDECIDABLE) and confidence reporting. This shifts the evaluation from a binary pass/fail verdict to a risk-coverage trade-off, which is more aligned with real-world requirements where reliability is critical. By grouping prompts into counterfactual pairs, the method enables consistency analysis, and calibration through human audit ensures that the evaluator's thresholds are aligned with human judgment.

## Foundational Learning
- **Object detection uncertainty**: Understanding the sources of uncertainty in object detection (missed targets, multiple instances, ambiguous geometry) is crucial for framing the evaluation problem.
- **Risk-coverage trade-off**: This concept is essential for balancing the desire for high coverage (more images evaluated) against the need for low risk (fewer incorrect evaluations).
- **Counterfactual prompt pairs**: Creating counterfactual pairs via role-swapping enables consistency analysis, which is key to validating the evaluator's reliability.
- **Human audit for calibration**: Calibration through human audit ensures that the evaluator's thresholds are aligned with human judgment, increasing trust in the results.

## Architecture Onboarding
- **Component map**: Prompt generation -> Image generation -> Object detection -> Spatial evaluation -> Confidence reporting -> Calibration (human audit)
- **Critical path**: The most critical steps are object detection and spatial evaluation, as errors here propagate to the final confidence and risk estimates.
- **Design tradeoffs**: The main tradeoff is between coverage (evaluating more images) and risk (fewer incorrect evaluations), managed through confidence thresholds.
- **Failure signatures**: Common failures include missed detections leading to abstention, and ambiguous geometry leading to low confidence or incorrect evaluations.
- **First experiments**: (1) Run the framework on a small set of prompts to check for systematic failures; (2) Vary detector confidence thresholds to see their impact on detection accuracy and evaluation reliability; (3) Compare human audit results with automated confidence estimates to validate calibration.

## Open Questions the Paper Calls Out
None

## Limitations
- The reliance on a fixed set of 200 prompts may not generalize to more complex or varied spatial relations.
- The calibration method, though validated by human audit, is limited in scale and may not fully capture edge cases.
- The risk-coverage trade-off is theoretically sound but practically difficult to optimize without clear downstream task requirements.

## Confidence
- **High**: Framing of evaluation as risk-coverage trade-off
- **Medium**: Empirical improvements from grounding methods
- **Low**: Robustness of the calibration process

## Next Checks
1. Test the framework on a broader set of spatial relations and more complex prompts.
2. Conduct a larger-scale human audit to validate calibration thresholds and uncertainty estimates.
3. Evaluate the impact of varying detector confidence thresholds on both detection accuracy and evaluation reliability.