---
ver: rpa2
title: 'FairMT: Fairness for Heterogeneous Multi-Task Learning'
arxiv_id: '2512.00469'
source_url: https://arxiv.org/abs/2512.00469
tags:
- fairness
- task
- learning
- fairmt
- utility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness in multi-task learning (MTL) with
  heterogeneous tasks (classification, detection, regression) and partial label supervision.
  It introduces FairMT, the first unified fairness-aware MTL framework that accommodates
  all three task types under incomplete supervision.
---

# FairMT: Fairness for Heterogeneous Multi-Task Learning

## Quick Facts
- arXiv ID: 2512.00469
- Source URL: https://arxiv.org/abs/2512.00469
- Reference count: 32
- Primary result: First unified fairness-aware MTL framework handling classification, detection, regression with partial supervision; achieves substantial fairness gains without utility loss

## Executive Summary
FairMT introduces the first unified fairness-aware multi-task learning framework for heterogeneous tasks under partial label supervision. It addresses the challenge of fairness across multiple task types by consolidating asymmetric task-dependent fairness violations into a single unified constraint. The method achieves substantial fairness improvements across vision and language benchmarks while maintaining superior task utility, outperforming state-of-the-art baselines on fairness metrics without sacrificing accuracy or F1 scores.

## Method Summary
FairMT employs a primal-dual optimization framework that jointly optimizes utility and fairness across heterogeneous tasks. The core innovation is the Asymmetric Heterogeneous Fairness Disparity Aggregation (AHFDA) module, which aggregates task-specific asymmetric fairness violations using a simplex-constrained optimization. Task heads induce anisotropic geometry in the shared representation space, which FairMT corrects through a head-aware multi-objective optimization proxy. The framework handles three task types (classification, detection, regression) under partial supervision by employing differentiable soft rate estimators and task-specific asymmetric fairness metrics (AEOD, CAEOD, AEP).

## Key Results
- Consistently achieves substantial fairness gains (EOD, EO, KS, CSP) across three heterogeneous MTL benchmarks
- Maintains superior task utility with no significant accuracy, F1, or CCC score degradation
- Outperforms state-of-the-art fairness-aware MTL baselines on all evaluated fairness metrics
- Handles partial label supervision effectively through task-aware masking mechanisms
- Code will be released upon acceptance, enabling reproducibility

## Why This Works (Mechanism)

### Mechanism 1: Asymmetric Fairness Disparity (Directional Correction)
Enforcing fairness through one-sided penalties that target only underperforming groups preserves utility while improving fairness. For each task, anchor to the best-performing group's metrics and apply hinge-style penalties only when groups fall short of reference. This creates a "lift-only" pressure gradient rather than a "pull-down-and-lift" symmetric force. The directional assumption fails if reference groups have noisy/overfit metrics or achieved performance through data leakage.

### Mechanism 2: Projection-Free Simplex Aggregation (AHFDA)
Aggregating heterogeneous task violations via a simplex-constrained optimization concentrates optimization pressure on the most violated tasks. Task violation scores form a vector that is optimized over the simplex using Frank-Wolfe iterations, producing a water-filling structure where tasks below threshold receive zero weight. The aggregation becomes ineffective if μ is set incorrectly (too small causes over-concentration, too large causes uniform weights) or if tasks have intrinsically different violation scales.

### Mechanism 3: Head-Aware Optimization Proxy (Geometry Correction)
Task heads induce anisotropic geometry in the shared representation space, which FairMT corrects through a head-aware Gram matrix. The proxy constructs K = Diag(u) WW^T Diag(u) where W stacks head weights and u captures logit-level sensitivities, encoding pairwise head alignments. The assumption fails if task heads are non-linear (multi-layer MLPs rather than linear) or if logit sensitivities u_t are near zero (saturated logits).

## Foundational Learning

- **Concept: Primal-Dual Optimization with KKT Conditions**
  - Why needed here: FairMT formulates fairness as a constraint Φ(θ) ≤ ε within a multi-objective optimization. Understanding Lagrangian relaxation, dual variables, complementary slackness, and stationarity conditions is essential to grasp why the method simultaneously optimizes utility and fairness.
  - Quick check question: If Φ(θ*) < ε at convergence, what must be true about the dual variable η*?

- **Concept: Simplex Projections and Frank-Wolfe Algorithm**
  - Why needed here: The AHFDA aggregator solves a constrained optimization over the probability simplex Δ^T. The paper uses projection-free Frank-Wolfe rather than projected gradient, exploiting that the simplex's linear minimization oracle returns a vertex.
  - Quick check question: Why does Frank-Wolfe preserve sparsity of iterates better than projected gradient descent on the simplex?

- **Concept: Multi-Task Learning Descent Geometry (MGDA)**
  - Why needed here: FairMT builds on MGDA-style multi-objective optimization, where task weights α control the convex combination of task gradients. The head-aware proxy modifies this to account for head-induced distortions.
  - Quick check question: In standard MGDA, what geometric condition indicates a Pareto-stationary point?

## Architecture Onboarding

- **Component map:** Shared Encoder (θ_s) -> Task Heads ({θ_t}) -> AHFDA Module -> Primal-Dual Optimizer -> Head-Aware Proxy

- **Critical path:**
  1. Forward pass through shared encoder + task heads → obtain logits z_t and predictions
  2. Compute soft rates (TPR, FPR) per task/group using differentiable approximations
  3. Compute asymmetric violations ψ_t via AEOD/CAEOD/AEP
  4. Run AHFDA (Algorithm 1) to aggregate violations → Φ(θ), weights w*
  5. Compute head-aware proxy: construct K, b, solve QP for task weights α
  6. Compute Lagrangian gradients, update parameters
  7. Update dual multiplier η via projected ascent

- **Design tradeoffs:**
  - μ (aggregation aggressiveness): Small μ → concentrated on worst tasks (risk of over-focus); large μ → uniform weights (diluted correction). Start with μ ∈ [0.1, 1.0] and tune.
  - ε (fairness tolerance): Tight ε → stronger fairness but potential utility loss; loose ε → near-utility-only optimization. Set based on application requirements.
  - ρ_η (dual step size): Too large → oscillation; too small → slow constraint satisfaction. Typical range [0.01, 0.1].
  - Head proxy vs. full-model gradients: Proxy is O(T²) vs. O(|θ|); use proxy for large T, fall back to full gradients if heads are non-linear.

- **Failure signatures:**
  - Utility collapse: All task accuracies drop significantly → η may be too large or ε too tight; check dual dynamics.
  - No fairness improvement: Φ(θ) remains high → α weights may be dominated by utility gradients; verify head-aware proxy is active.
  - Single-task dominance: One task's ψ_t always receives w* ≈ 1 → μ too small or that task's violation scale dominates; normalize violations or increase μ.
  - Unstable training: η oscillates or diverges → reduce ρ_η, check gradient norms for fairness term.

- **First 3 experiments:**
  1. Sanity check on homogeneous tasks: Run FairMT on CelebA (binary detection only). Verify that AEOD violations decrease while accuracy remains within 1–2% of MGDA baseline. Isolate the asymmetric mechanism by comparing to a symmetric EOD baseline.
  2. Ablation on head-aware proxy: On AffectNet-VA (regression + detection), compare three variants: (a) FairMT with head-aware proxy, (b) FairMT with MGDA-UB proxy, (c) FairMT with full-model gradients. Measure convergence speed and final fairness/utility.
  3. Partial supervision stress test: Create a synthetic partial-label split where only 30% of samples have labels for each task. Compare FairMT against MGDA-Mean and MGDA-UFaTE. Verify that the masking M_t = 1[t ∈ Ω] correctly handles missing labels in violation computation.

## Open Questions the Paper Calls Out

- **Question:** Can the FairMT framework be theoretically extended to accommodate non-group-based definitions, such as individual fairness or causal fairness?
  - Basis in paper: [explicit] The conclusion states this work opens "avenues for extending FairMT to broader fairness notions," noting the current focus is on group disparity metrics.
  - Why unresolved: The current mathematical formulation (AHFDA) relies on aggregating statistics over discrete groups (G), making it structurally incompatible with individual or causality-based definitions.
  - What evidence would resolve it: A theoretical extension or empirical validation showing FairMT's aggregation mechanism can optimize for counterfactual or individual-level invariance.

- **Question:** How does the Head-Aware Optimization Proxy perform when task heads are deep, non-linear architectures (e.g., multi-layer MLPs or decoders) rather than the implied single linear layer?
  - Basis in paper: [inferred] The proxy relies on a Gram matrix W W^⊤ of head weights, which implicitly assumes a linear mapping from shared representation to logits.
  - Why unresolved: Non-linear heads induce complex, non-convex geometries that cannot be fully captured by the inner product of weights, potentially breaking the proxy's anisotropy correction.
  - What evidence would resolve it: Experiments applying FairMT to tasks requiring deep decoders (e.g., semantic segmentation) comparing the linear proxy against a second-order Taylor approximation.

- **Question:** Is the AHFDA mechanism robust when the selected "reference" group (the best-performing group) achieves high metrics due to data noise or overfitting rather than genuine learnability?
  - Basis in paper: [inferred] The method anchors constraints to τ_t = max [TPR], assuming the maximum performance is a valid and stable upper bound for all groups.
  - Why unresolved: If the reference group is an outlier or benefits from annotation errors, the asymmetric hinge loss will force the model to fit to this noisy ceiling, potentially degrading generalization.
  - What evidence would resolve it: Sensitivity analysis on benchmarks with injected label noise to observe if the reference-group selection destabilizes optimization or leads to overfitting.

## Limitations

- Architecture details (backbone, head configurations) and hyperparameters (learning rates, μ, ε, ρ_η) are not provided, making exact reproduction challenging.
- The assumption that reference group performance represents an achievable upper bound for disadvantaged groups may not hold in practice, particularly if privileged groups achieved performance through data leakage.
- Dual variable dynamics and convergence guarantees are discussed but lack explicit proof or empirical validation.
- The claim that FairMT "consistently achieves substantial fairness gains" across all benchmarks is based on comparisons to baselines without clear ablation studies isolating each mechanism's contribution.

## Confidence

- **High Confidence:** The asymmetric fairness mechanism is clearly articulated and its directional correction logic is internally consistent. The AHFDA formulation follows established optimization principles with verifiable water-filling structure.
- **Medium Confidence:** The head-aware proxy is well-motivated but relies on assumptions about linear heads that may not generalize to deeper architectures. The primal-dual optimization framework is theoretically sound but convergence behavior is not empirically validated.
- **Low Confidence:** The partial supervision handling is mentioned but not detailed. The claim of consistent fairness gains across all benchmarks lacks clear ablation studies isolating each mechanism's contribution.

## Next Checks

1. **Ablation on Asymmetric vs Symmetric Fairness:** Implement a symmetric EOD constraint baseline on CelebA and compare convergence and final fairness/utility trade-offs with FairMT's asymmetric approach.
2. **Head Geometry Stress Test:** Create synthetic MTL tasks where head-induced anisotropy is artificially amplified (e.g., extreme logit scaling differences). Measure whether FairMT's head-aware proxy outperforms standard MGDA-UB proxy in such extreme conditions.
3. **Dual Variable Dynamics Analysis:** Run FairMT on a small benchmark (e.g., CelebA) and track the dual multiplier η over training. Verify that η increases when Φ(θ) > ε and remains stable otherwise, confirming correct complementary slackness behavior.