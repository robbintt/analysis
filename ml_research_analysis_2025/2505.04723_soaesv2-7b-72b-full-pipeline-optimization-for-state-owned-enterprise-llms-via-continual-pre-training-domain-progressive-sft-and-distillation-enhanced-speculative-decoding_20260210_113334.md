---
ver: rpa2
title: 'SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs
  via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative
  Decoding'
arxiv_id: '2505.04723'
source_url: https://arxiv.org/abs/2505.04723
tags:
- domain
- decoding
- data
- language
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study introduces SOAEsV2-7B/72B, a comprehensive pipeline
  for developing domain-specific LLMs for Chinese state-owned assets and enterprises.
  The framework addresses three key limitations in current approaches: constrained
  model capacity, excessive reliance on domain-specific SFT data, and inefficient
  inference for large models.'
---

# SOAEsV2-7B/72B: Full-Pipeline Optimization for State-Owned Enterprise LLMs via Continual Pre-Training, Domain-Progressive SFT and Distillation-Enhanced Speculative Decoding

## Quick Facts
- arXiv ID: 2505.04723
- Source URL: https://arxiv.org/abs/2505.04723
- Reference count: 29
- Develops systematic pipeline for domain-specific LLM development in Chinese state-owned enterprises

## Executive Summary
SOAEsV2-7B/72B introduces a comprehensive three-phase framework for developing state-owned enterprise domain-specific LLMs. The pipeline addresses key limitations in current approaches through continual pre-training to integrate domain knowledge while preserving general capabilities, domain-progressive SFT using curriculum learning, and distillation-enhanced speculative decoding for efficient large-model inference. Experimental results demonstrate significant improvements in both domain-specific performance and inference efficiency while maintaining strong general language capabilities.

## Method Summary
The methodology employs a three-phase approach: (1) continual pre-training integrates domain-specific knowledge into base models while preserving general capabilities through carefully designed training objectives and data mixing strategies; (2) domain-progressive SFT uses curriculum learning to gradually transition from general to specialized data, improving adaptation efficiency; (3) distillation-enhanced speculative decoding enables efficient cooperation between 7B and 72B models, achieving significant speedup without quality degradation. The framework is specifically designed for Chinese state-owned enterprise contexts but demonstrates generalizable principles for specialized domain LLM development.

## Key Results
- Continual pre-training maintains 99.8% of original general language capabilities while improving domain performance (1.08× in Rouge-1, 1.17× in BLEU-4)
- Domain-progressive SFT outperforms single-stage training (1.02× in Rouge-1, 1.06× in BLEU-4)
- Distillation-enhanced speculative decoding achieves 1.39-1.52× speedup without quality loss

## Why This Works (Mechanism)
The three-phase pipeline addresses fundamental challenges in domain-specific LLM development through complementary mechanisms. Continual pre-training preserves general capabilities while embedding domain knowledge, preventing catastrophic forgetting through balanced data mixing. Domain-progressive SFT leverages curriculum learning principles to improve adaptation efficiency by gradually increasing specialization complexity. Distillation-enhanced speculative decoding exploits the complementary strengths of different model sizes, using the smaller model for fast draft generation and the larger model for quality verification, while knowledge distillation ensures the smaller model learns from the larger model's reasoning patterns.

## Foundational Learning
- **Curriculum Learning**: Gradually increasing task complexity during training improves model adaptation efficiency and generalization. Quick check: Monitor performance curves during progressive SFT to ensure smooth capability development.
- **Knowledge Distillation**: Transferring knowledge from larger to smaller models enables efficient deployment while maintaining quality. Quick check: Compare distilled model outputs against teacher model to verify knowledge transfer fidelity.
- **Speculative Decoding**: Parallel draft verification accelerates inference by predicting multiple tokens simultaneously. Quick check: Measure token generation latency and accuracy trade-offs at different speculation depths.

## Architecture Onboarding

**Component Map:** Pre-training -> Progressive SFT -> Speculative Decoding

**Critical Path:** The most critical sequence is continual pre-training followed by domain-progressive SFT, as this establishes the foundational capabilities and domain knowledge that enable effective speculative decoding. Without proper pre-training and progressive fine-tuning, the speculative decoding phase would lack the specialized understanding needed for efficient draft generation.

**Design Tradeoffs:** The framework balances model size (7B vs 72B) for inference efficiency against training complexity and resource requirements. Using curriculum learning in SFT trades increased training time for better domain adaptation and capability preservation. The speculative decoding approach requires careful calibration of draft and verification model capabilities to achieve optimal speedup without quality degradation.

**Failure Signatures:** Poor continual pre-training may result in catastrophic forgetting of general capabilities or insufficient domain knowledge integration. Ineffective progressive SFT can lead to either insufficient specialization or loss of general knowledge. Suboptimal speculative decoding configuration may cause increased latency or quality degradation due to mismatched draft and verification model capabilities.

**3 First Experiments:**
1. Evaluate continual pre-training retention of general capabilities using standardized language benchmarks before and after domain-specific training
2. Test progressive SFT curriculum effectiveness by comparing performance across different curriculum progression speeds and difficulty gradients
3. Validate speculative decoding pairing by measuring speedup and quality metrics across different 7B-72B model combinations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on synthetic domain-specific datasets rather than real-world enterprise applications
- Speedup measurements may not reflect deployment scenarios with varying computational loads
- General language capability retention measured through limited metrics (Rouge-1, BLEU-4)

## Confidence
- Continual pre-training capability preservation: **High** confidence (supported by specific quantitative metrics)
- Domain-progressive SFT effectiveness: **Medium** confidence (synthetic curriculum data may not generalize)
- Speculative decoding speedup: **Medium** confidence (depends on specific model pairing configurations)

## Next Checks
1. Conduct field tests of the 7B-72B model pairing in actual state-owned enterprise scenarios to verify measured speedup benefits under realistic operational conditions
2. Evaluate the domain-progressive SFT approach across multiple distinct specialized domains beyond state-owned enterprises to assess curriculum learning methodology's broader applicability
3. Implement longitudinal studies tracking continual pre-training models' performance over extended periods to verify sustained capability preservation beyond initial evaluation metrics