---
ver: rpa2
title: 'Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability
  Method for Poisoned Document Detection'
arxiv_id: '2507.18202'
source_url: https://arxiv.org/abs/2507.18202
tags:
- documents
- gmtp
- poisoned
- tokens
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Gradient-based Masked Token Probability (GMTP),
  a defense method to detect and filter poisoned documents in Retrieval-Augmented
  Generation (RAG) systems. GMTP works by identifying high-impact tokens using gradients
  from the retriever's similarity function, masking them, and evaluating their probabilities
  via a Masked Language Model.
---

# Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection

## Quick Facts
- arXiv ID: 2507.18202
- Source URL: https://arxiv.org/abs/2507.18202
- Authors: San Kim; Jonghwi Kim; Yejin Jeon; Gary Geunbae Lee
- Reference count: 33
- Key outcome: GMTP eliminates over 90% of poisoned documents while preserving retrieval and generation performance across multiple datasets and attack scenarios.

## Executive Summary
Retrieval-Augmented Generation (RAG) systems are vulnerable to corpus poisoning attacks where malicious documents are inserted to manipulate retrieval results. This paper introduces Gradient-based Masked Token Probability (GMTP), a defense method that detects and filters poisoned documents before they reach the generation model. GMTP works by identifying high-impact tokens using gradients from the retriever's similarity function, masking them, and evaluating their probabilities via a Masked Language Model. Low masked-token probabilities indicate adversarial content, enabling effective filtering while maintaining retrieval quality.

## Method Summary
GMTP operates as a post-retrieval filter that analyzes documents based on their linguistic naturalness. It first computes gradients of the similarity function with respect to token embeddings to identify "key tokens" that disproportionately influence retrieval scores. These tokens are then masked and passed through an MLM (e.g., BERT) to calculate their masked-token probabilities. Documents with low average P-scores across their key tokens are flagged as poisoned. The method uses a dynamic threshold based on domain-specific statistics rather than fixed cutoffs, making it adaptable across different corpora and attack scenarios.

## Key Results
- GMTP eliminates over 90% of poisoned documents across multiple attack types while preserving retrieval and generation performance
- Consistently outperforms baselines (RAGPart and RAGMask) in filtering rate while maintaining strong retrieval quality (nDCG)
- Achieves efficient filtering with only marginal latency overhead compared to baseline retrieval

## Why This Works (Mechanism)

### Mechanism 1
Tokens that disproportionately influence the retrieval similarity score are likely sites of adversarial manipulation. GMTP computes the gradient of the similarity function (dot product) with respect to each token's embedding. Tokens with high L2-norm gradients are identified as "key tokens" because small changes in these tokens cause large changes in the similarity score. This works because poisoning attacks like Hotflip iteratively replace tokens to maximize this exact gradient signal.

### Mechanism 2
Adversarially optimized tokens exhibit lower probability under a standard Masked Language Model than natural tokens. Key tokens identified via gradients are masked and fed into an MLM. Since adversarial tokens are optimized for retrieval similarity rather than linguistic fluency, they appear as "unnatural" sequences that the MLM assigns low prediction probabilities to.

### Mechanism 3
A dynamic threshold based on domain-specific statistics allows high-precision filtering without hand-tuned global cutoffs. GMTP calculates a filtering threshold by sampling random queries and documents from the target domain to establish a baseline P-score, which is then scaled by a factor. This approach adapts to different domains while maintaining consistent filtering performance.

## Foundational Learning

- **Gradient-based Attribution (Input Saliency)**: Understanding which tokens are doing the heavy lifting in the retrieval process. Quick check: If a document is retrieved for a query about "apple pie," which token in the document "fruit tart apple recipe" would likely have the highest gradient magnitude with respect to the similarity score?

- **Masked Language Modeling (MLM)**: This is the proxy for "linguistic naturalness." Quick check: If you mask the token "xyz" in the sentence "The xyz ran fast," would an MLM assign it a higher or lower probability than the token "dog"? Why does this matter for GMTP?

- **Corpus Poisoning vs. Prompt Injection**: To distinguish the threat model. This paper defends the knowledge base (retrieval phase), not the immediate user prompt. Quick check: Does GMTP scan the user's query for malicious instructions, or does it scan the documents retrieved from the database?

## Architecture Onboarding

- **Component map**: Query Input -> Standard Retrieval (Top-k) -> Gradient Computation (per doc) -> Token Masking & Scoring -> Threshold Check -> Filtered Context -> Generator

- **Critical path**: Query Input → Standard Retrieval (Top-k) → Gradient Computation (per doc) → Token Masking & Scoring → Threshold Check → Filtered Context → Generator

- **Design tradeoffs**:
  - Increasing N (candidates) and M (lowest prob tokens used for scoring) improves detection but increases forward passes through the MLM
  - Setting λ (threshold scalar) too high filters more poison but risks dropping relevant documents with rare words
  - The method relies on access to the retriever's gradients, making it harder to use with black-box APIs

- **Failure signatures**:
  - High False Positive Rate: Users report "missing context" or degraded answer quality
  - ASR Spike (Attack Success Rate): Attack success rate suddenly increases

- **First 3 experiments**:
  1. Baseline Calibration: Run P-score calculation on a clean validation set to establish the distribution of "normal" probabilities for your specific domain
  2. Hyperparameter Sweep (N & M): Test N ∈ [5, 10, 20] and M ∈ [1, 5, 10] to find the sweet spot between filtering rate and nDCG drop
  3. Latency Profiling: Measure the added milliseconds per query for the gradient+MLM step against the baseline retrieval time

## Open Questions the Paper Calls Out
None

## Limitations

- Assumption of gradient accessibility: GMTP requires access to the retriever's internal gradients, limiting applicability to black-box retrieval APIs
- Effectiveness against semantic attacks: Performance degrades against attacks that rewrite documents using semantically coherent but adversarial content
- Domain adaptation robustness: The dynamic threshold mechanism's stability across extreme domain shifts and specialized vocabularies is not thoroughly validated

## Confidence

- GMTP eliminates over 90% of poisoned documents while preserving retrieval and generation performance: High confidence
- GMTP outperforms baselines in filtering rate: High confidence
- GMTP is efficient and adaptable across different retriever architectures: Medium confidence

## Next Checks

1. Black-box retriever evaluation: Test GMTP's effectiveness when applied to a retriever where only similarity scores are accessible (no gradients)

2. Semantic attack robustness benchmark: Design and evaluate against a stronger attack variant that explicitly optimizes for both retrieval success and MLM fluency probability simultaneously

3. Domain shift stress test: Evaluate GMTP on datasets with extreme domain differences and with corpora containing high proportions of specialized terminology