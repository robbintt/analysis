---
ver: rpa2
title: 'You Had One Job: Per-Task Quantization Using LLMs'' Hidden Representations'
arxiv_id: '2511.06516'
source_url: https://arxiv.org/abs/2511.06516
tags:
- quantization
- arxiv
- layer
- allocation
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of inefficient quantization in
  large language models (LLMs) by proposing task-aware quantization methods that allocate
  precision based on task-specific sensitivity rather than using uniform or task-agnostic
  approaches. The core method introduces three approaches: TAQ, which scores layers
  using information content and activation stability from hidden representations;
  TAQO, which ranks layers by direct sensitivity testing through single-layer quantization;
  and TAQ-KL, which measures layer importance via KL divergence from output-distribution
  perturbations.'
---

# You Had One Job: Per-Task Quantization Using LLMs' Hidden Representations

## Quick Facts
- arXiv ID: 2511.06516
- Source URL: https://arxiv.org/abs/2511.06516
- Reference count: 40
- One-line primary result: Task-aware quantization methods (TAQ, TAQO, TAQ-KL) significantly outperform task-agnostic approaches by allocating precision based on task-specific sensitivity signals in hidden representations.

## Executive Summary
This paper addresses the inefficiency of uniform quantization in large language models by proposing task-aware methods that identify which layers are most critical for specific tasks and allocate higher precision accordingly. The authors introduce three approaches: TAQ uses information content and activation stability from hidden representations, TAQO directly tests single-layer sensitivity, and TAQ-KL measures layer importance via KL divergence from output perturbations. These methods consistently outperform task-agnostic baselines across multiple models and specialized tasks, achieving superior accuracy-memory trade-offs while maintaining performance within 1% of original accuracy.

## Method Summary
The paper introduces three task-aware quantization methods that use a small calibration set to identify task-relevant layers. TAQ scores layers using spectral entropy of activation covariance and activation stability, combining these into an importance score. TAQO ranks layers by direct sensitivity testing through single-layer quantization. TAQ-KL measures layer importance via KL divergence from output-distribution perturbations caused by uniform noise injection. All methods use group-wise affine weight-only post-training quantization with 128-group sizes, assigning 8-bit to top-ranked layers (25%) and 4-bit to the rest while protecting edge layers in FP16.

## Key Results
- TAQ achieves 42.33 EM / 50.81 F1 on Phi-4, far surpassing AWQ (2.25 / 7.07) while remaining within <1.0% of original accuracy at lower average precision
- TAQO leads on Llama-3.1, Qwen3, and Qwen2.5 models, with TAQ excelling on Phi-4
- Label-free variants (TAQ-KL/TAQ) closely match or occasionally exceed oracle performance, demonstrating that intrinsic model signals can effectively guide quantization without labeled validation sets
- Task-agnostic approaches like AWQ catastrophically fail on specialized tasks, dropping from 50.29% to 20.61% EM on CodeMMLU

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Task-specific signals in LLM hidden representations can identify which layers are most critical for a given task, enabling precision allocation to be concentrated where it matters most.
- Mechanism: Different tasks produce distinct entropy profiles across layers. TAQ measures information content via spectral entropy of activation covariance and stability via activation variance, combining these into a layer importance score.
- Core assumption: Task-relevant computation is unevenly distributed across layers, and this uneven distribution is detectable through activation statistics.
- Evidence anchors: Figure 2 demonstrates distinct entropy profiles across three tasks with error bars showing systematic task-specific structure.

### Mechanism 2
- Claim: Direct single-layer sensitivity testing provides an oracle ranking for precision allocation.
- Mechanism: TAQO quantizes each layer individually to 4-bit while preserving all other layers at FP16, then measures the task performance drop. Layers causing larger drops are retained at higher precision.
- Core assumption: Single-layer quantization sensitivity is predictive of combined multi-layer quantization behavior (assumes effects are approximately additive).
- Evidence anchors: Equation 10 formally defines the oracle sensitivity score as the performance drop under single-layer quantization.

### Mechanism 3
- Claim: KL divergence between baseline and perturbed output distributions serves as a label-free proxy for layer importance.
- Mechanism: TAQ-KL injects uniform noise scaled to approximate 4-bit quantization error at each layer, then measures how much the output probability distribution shifts via KL divergence.
- Core assumption: Uniform noise perturbation approximates the structured error introduced by actual quantization.
- Evidence anchors: TAQ-KL matches or exceeds oracle performance in Table 1, validating the noise model as a proxy for quantization sensitivity.

## Foundational Learning

- **Concept: Post-training quantization (PTQ)**
  - Why needed here: This is the core compression technique being enhanced. Understanding PTQ fundamentals (scale, zero-point, group-wise quantization) is prerequisite.
  - Quick check question: How does group-wise affine quantization (G=128) differ from per-tensor quantization in terms of granularity and overhead?

- **Concept: Activation geometry and spectral analysis**
  - Why needed here: TAQ relies on computing the covariance matrix of activations and its eigenvalue spectrum to measure information content.
  - Quick check question: What does a peaked eigenvalue distribution (low entropy) versus a flat distribution (high entropy) indicate about the representation structure?

- **Concept: Mixed-precision memory budgets**
  - Why needed here: The paper operates under explicit memory constraints, allocating different bit-widths (4/8/16) across layers to meet a target footprint.
  - Quick check question: Given a 7B parameter model, what is the approximate memory footprint for uniform 4-bit quantization versus mixed 4/8-bit with 25% of layers at 8-bit?

## Architecture Onboarding

- **Component map:**
  Calibration Data (512 prompts) -> Hidden State Extraction -> Layer Scorer (TAQ/TAQO/TAQ-KL) -> Importance Ranking -> Budget-Constrained Allocation (top K% -> 8-bit) -> Group-wise Quantization (G=128) -> Quantized Model

- **Critical path:**
  1. Forward pass calibration prompts through FP16 model, capture layer activations
  2. Compute per-layer importance scores using chosen method
  3. Sort layers by score, assign 8-bit to top K% and 4-bit to remainder (edge layers protected)
  4. Apply asymmetric uniform quantization to weight groups

- **Design tradeoffs:**
  - TAQ vs TAQO vs TAQ-KL: TAQ requires one forward pass; TAQO requires L forward passes (expensive but most accurate); TAQ-KL requires ~64 calibration passes with noise injection
  - Calibration set size: 512 examples used; smaller sets risk noisy estimates
  - Top-K threshold: 25% of layers get 8-bit (empirically chosen); optimal K likely varies by task

- **Failure signatures:**
  - Catastrophic collapse on specialized tasks: AWQ dropped from 50.29% to 20.61% EM on CodeMMLU
  - Calibration overfitting: AWQ with on-task calibration collapsed on Phi-4 to 0.73 EM, indicating narrow calibration can be harmful without task-aware allocation

- **First 3 experiments:**
  1. On your target model/task, plot layer-wise matrix entropy to confirm task-specific patterns exist before implementing full TAQ
  2. On a small model, run both TAQO and TAQ-KL, compare layer rankings and final performance to assess proxy quality
  3. Vary Top-K threshold (10%, 25%, 40%) and plot accuracy vs memory to identify the Pareto frontier for your deployment constraints

## Open Questions the Paper Calls Out

- Can the reliance on task-specific calibration prompts be eliminated to achieve fully data-free post-training quantization?
- How can task-aware precision allocations be efficiently interpolated or switched to support multi-tenant serving environments?
- How does the definition of the calibration set affect stability under distribution drift or fuzzy task boundaries?

## Limitations

- Layer granularity ambiguity: The paper switches between "transformer blocks" and "linear weight matrices" without clarifying whether scores apply to entire blocks or individual sub-layers
- Task specificity constraints: Methods rely on having task-representative calibration data and may not work well without it
- Single-layer sensitivity assumptions: TAQO assumes quantization effects are approximately additive across layers, which may not hold for transformer architectures

## Confidence

- **High confidence**: Core experimental results showing TAQ and TAQO outperforming baselines on multiple models and tasks
- **Medium confidence**: Theoretical justification for information content and stability as proxies for quantization sensitivity
- **Low confidence**: KL divergence noise model's fidelity to actual quantization error

## Next Checks

1. Implement TAQ at sub-layer granularity (QKV projections vs FFN) rather than whole blocks to test whether different linear operations within the same block have distinct sensitivity profiles

2. Systematically vary calibration set size (64, 256, 1024 examples) and composition to quantify how calibration quality affects TAQ performance

3. Train TAQ on one task (e.g., TriviaQA) and evaluate on a different task (e.g., CodeMMLU) to measure how much task-specific calibration is actually necessary