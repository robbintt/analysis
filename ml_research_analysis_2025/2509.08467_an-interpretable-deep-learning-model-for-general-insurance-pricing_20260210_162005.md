---
ver: rpa2
title: An Interpretable Deep Learning Model for General Insurance Pricing
arxiv_id: '2509.08467'
source_url: https://arxiv.org/abs/2509.08467
tags:
- interpretability
- function
- actuarial
- learning
- effects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Actuarial Neural Additive Model (ANAM),
  an interpretable deep learning model for general insurance pricing. ANAM assigns
  dedicated neural networks to each covariate and pairwise interaction, incorporating
  architectural constraints for sparsity, smoothness, and monotonicity to ensure interpretability.
---

# An Interpretable Deep Learning Model for General Insurance Pricing

## Quick Facts
- arXiv ID: 2509.08467
- Source URL: https://arxiv.org/abs/2509.08467
- Reference count: 22
- Key outcome: ANAM achieves NLL of 37.88 and RMSE of 36.79 on Belgian motor dataset, outperforming traditional actuarial and machine learning models while maintaining interpretability

## Executive Summary
This paper introduces the Actuarial Neural Additive Model (ANAM), an interpretable deep learning approach for general insurance pricing that balances predictive accuracy with transparency. The model assigns dedicated neural networks to each covariate and pairwise interaction while incorporating architectural constraints for sparsity, smoothness, and monotonicity. Through a three-stage variable selection process and mathematical formulation with penalty terms, ANAM provides both competitive predictive performance and interpretable shape functions that actuaries can analyze. Tested on both synthetic and real datasets, the model demonstrates superior negative log-likelihood and RMSE metrics compared to traditional actuarial models and neural networks.

## Method Summary
ANAM implements a three-stage variable selection process combined with architectural constraints. Stage 1 uses an ensemble of shallow NAMs to rank main effects by shape function variance. Stage 2 adds pairwise interaction terms one-at-a-time under strong heredity constraints, selecting based on validation loss reduction. Stage 3 refits the selected terms jointly. The final model incorporates lattice regression for monotonicity, smoothness penalties via finite differences, and marginal clarity penalties for identifiability. Training uses projected gradient descent with Dykstra's algorithm for monotonicity enforcement and Adam/RMSprop optimization with early stopping.

## Key Results
- On synthetic Gamma-distributed severity data, ANAM outperforms traditional actuarial models in predictive accuracy
- For Belgian motor claim frequency data, ANAM achieves NLL of 37.88 (vs. 37.95 for Neural Nets) and RMSE of 36.79 (vs. 36.81 for Neural Nets)
- ANAM provides interpretable shape functions while maintaining competitive performance metrics

## Why This Works (Mechanism)
ANAM works by decomposing the prediction function into additive components, each handled by dedicated neural networks. This decomposition enables both high predictive accuracy through flexible neural network fitting and interpretability through transparent shape functions. The three-stage variable selection ensures sparsity by identifying only the most important features and interactions. Architectural constraints enforce smoothness and monotonicity where required by domain knowledge, while penalty terms ensure mathematical identifiability. The combination of these elements allows the model to capture complex relationships in insurance data while remaining interpretable to actuaries.

## Foundational Learning
- **Neural Additive Models (NAMs)**: Deep learning models that decompose predictions into additive shape functions for each feature. Needed for interpretability while maintaining predictive power. Quick check: Verify shape functions sum to final prediction.
- **Dykstra's Algorithm**: Projection method for enforcing constraints in optimization. Needed to ensure monotonicity constraints are satisfied during training. Quick check: Test algorithm on simple monotonic projection problem.
- **Lattice Regression**: Technique for fitting monotonic functions with guaranteed monotonicity. Needed for insurance features where higher values must increase risk. Quick check: Verify lattice outputs increase with inputs.
- **Strong Heredity Constraints**: Require interaction terms only when both main effects are present. Needed to maintain model sparsity and interpretability. Quick check: Confirm no interactions without parent main effects.
- **Marginal Clarity**: Mathematical property ensuring unique decomposition of predictions. Needed for stable, interpretable shape functions. Quick check: Verify decomposition uniqueness through coefficient scaling tests.

## Architecture Onboarding
**Component Map:** Data Preprocessing -> 3-Stage Variable Selection -> Constrained Training -> Prediction

**Critical Path:** Variable selection (stages 1-3) → Final model training with constraints → Evaluation

**Design Tradeoffs:** The model trades some potential predictive accuracy for interpretability through its additive structure and constraints. The three-stage selection process balances computational cost against variable selection quality.

**Failure Signatures:** Monotonicity violations indicate Dykstra's algorithm convergence issues. Overfitting to noise suggests insufficient smoothness penalty. Poor variable selection indicates suboptimal ensemble aggregation or validation strategy.

**First Experiments:**
1. Test monotonicity enforcement by training on synthetic monotonic data and verifying shape functions
2. Evaluate smoothness penalty sensitivity by training with varying ω_smooth values on synthetic data
3. Validate three-stage selection by comparing selected variables to ground truth in synthetic experiments

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Hyperparameter selection process lacks transparency with no specified search ranges or optimal values
- Ensemble aggregation method for variable selection is underspecified beyond "average variance"
- Limited ablation studies on the necessity of all architectural constraints
- Computational cost of three-stage selection may be prohibitive for very large datasets

## Confidence
- Method description and mathematical formulation: **High**
- Synthetic experiment reproducibility: **Medium**
- Real data experiment reproducibility: **Medium**
- Comparative performance claims: **Medium**

## Next Checks
1. Implement and test Dykstra's algorithm with varying convergence thresholds (10⁻³ to 10⁻⁶) to verify monotonicity enforcement robustness
2. Conduct sensitivity analysis on smoothness penalty strength ω_smooth across [0.1, 1, 10, 100] to assess impact on shape function interpretability
3. Reproduce the synthetic Gamma severity experiment with the provided data generation equations to verify claimed NLL/RMSE improvements over benchmark models