---
ver: rpa2
title: 'How do Language Models Generate Slang: A Systematic Comparison between Human
  and Machine-Generated Slang Usages'
arxiv_id: '2509.15518'
source_url: https://arxiv.org/abs/2509.15518
tags:
- slang
- word
- usages
- definition
- usage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper compares human and machine-generated slang usages from
  large language models (LLMs) like GPT-4o and Llama-3 against human-attested slang
  from the Online Slang Dictionary. A dataset of over 58,000 machine-generated slang
  usages was created under controlled and uncontrolled generation settings.
---

# How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages

## Quick Facts
- **arXiv ID:** 2509.15518
- **Source URL:** https://arxiv.org/abs/2509.15518
- **Reference count:** 38
- **Key outcome:** LLMs exhibit a "coinage bias" and lower informativeness compared to human slang, with divergent morphological and topical patterns.

## Executive Summary
This study systematically compares human and machine-generated slang across 58,197 entries from GPT-4o and Llama-3-8B. The research evaluates three aspects: usage characteristics (reuse vs. coinage), creativity (morphological complexity, semantic novelty), and informativeness for downstream tasks. Results show LLMs produce more neologisms than reuse, exhibit different word formation preferences, and demonstrate high creativity in novelty but lower morphological coherence compared to humans. Machine-generated slang is less informative for model distillation and downstream interpretation tasks, though it can sometimes improve creativity in student models.

## Method Summary
The study created a dataset of 58,197 machine-generated slang entries under six conditions: Uncontrolled/Controlled Ã— {Free-form, Reuse, Coinage}. Generation used GPT-4o and Llama-3-8B with temperature=1.2, top-p=0.95, filtered via Wiktionary for validity. Evaluation included morphological segmentation (Morfessor), semantic similarity (SBERT), and surprisal scoring (Gemma-2-9b-Instruct). Distillation experiments fine-tuned Llama-3-8B-Instruct using LoRA on partitions of generated data and tested on generation/interpretation tasks.

## Key Results
- LLMs produce significantly more coinage than reuse compared to human patterns
- Machine-generated slang shows different morphological patterns and lower semantic coherence
- Synthetic slang data is less effective for model distillation and downstream interpretation tasks

## Why This Works (Mechanism)

### Mechanism 1: Coinage Bias
LLMs systematically favor generating novel words over reusing existing lexicon. This stems from the model equating "slang generation" with "lexical creation" rather than "semantic extension." The bias is evident when models produce only 3 reuse instances out of 1,000 in uncontrolled settings.

### Mechanism 2: Alignment Decoupling
RLHF techniques decouple LLM-generated slang from taboo topics prevalent in human slang, shifting semantic focus toward safer concepts. Safety filters penalize profanity or controversial content, redirecting generation toward positive but less concrete semantic fields.

### Mechanism 3: Stylistic Transfer Limitation
Synthetic slang transfers morphological complexity to student models but fails to transfer structural grounding for semantic interpretation. Distillation learns surface statistics of the teacher's slang rather than generalized slang semantics, resulting in less informative data for downstream tasks.

## Foundational Learning

- **Morphological Segmentation (Morfessor)**
  - Why needed: To quantify creativity by decomposing coined slang terms into morphemes
  - Quick check: Can you explain how Morfessor distinguishes compounds from blends based on dictionary segment matches?

- **Semantic Surprisal**
  - Why needed: To measure creativity by calculating token predictability in context
  - Quick check: Why is negative log-likelihood used as a proxy for processing effort or novelty?

- **Knowledge Distillation**
  - Why needed: To understand informativeness experiments where student models learn from teacher slang data
  - Quick check: Why might distilling from a creative but unaligned teacher lead to style over accuracy?

## Architecture Onboarding

- **Component map:** OSD -> Generators (GPT-4o, Llama-3-8B) -> Analyzers (Morfessor, SBERT, Gemma-2-9b) -> Controller (prompting framework)
- **Critical path:** 1) Generate 58k dataset with 6 settings and Wiktionary filtering, 2) Analyze with Morfessor for morphology and SBERT for coherence, 3) Fine-tune Llama-3-8B using LoRA on specific partitions
- **Design tradeoffs:** Controlled generation grounds output in human semantics but may stifle creativity; Uncontrolled generation tests internal concepts but yields high duplication
- **Failure signatures:** Low coherence (definition distant from constituents), topic skew (universally positive slang), high rejection rates for strict constraints
- **First 3 experiments:** 1) Replicate Figure 2 to verify coinage bias, 2) Compare base vs. aligned model topic distributions, 3) Fine-tune on GPT-4o vs. OSD data for distillation efficiency

## Open Questions the Paper Calls Out

- How well do quantitative creativity metrics align with human perceptions of naturalness?
- Do systematic biases in slang generation generalize to languages other than English?
- How much do safety alignment techniques drive topical divergences like taboo avoidance?
- Can filtering for higher morphological coherence improve informativeness for distillation?

## Limitations

- Reliance on Wiktionary may misclassify rare legitimate words as coinages
- Controlled generation settings may not capture spontaneous human creative processes
- Alignment mechanism hypothesis remains speculative without direct experimental validation

## Confidence

- **High Confidence:** LLM coinage bias, different morphological patterns, lower informativeness for distillation
- **Medium Confidence:** Alignment influence on topic distribution, creativity-to-performance translation, partial slang knowledge capture
- **Low Confidence:** Exact mechanism of coinage bias creation, primary cause of taboo topic divergence, generalizability to other creative language

## Next Checks

1. **Experimental Ablation of Alignment:** Generate slang using base models and compare topic distributions with aligned models to isolate alignment effects.

2. **Extended Validity Testing:** Implement multiple validity checks beyond Wiktionary to verify the persistence of coinage bias and quantify misclassification rates.

3. **Alternative Distillation Strategies:** Test fine-tuning strategies with semantic constraints or curriculum learning to improve informativeness of machine-generated slang data.