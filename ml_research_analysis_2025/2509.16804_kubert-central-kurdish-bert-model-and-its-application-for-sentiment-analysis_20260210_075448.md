---
ver: rpa2
title: 'KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis'
arxiv_id: '2509.16804'
source_url: https://arxiv.org/abs/2509.16804
tags:
- sentiment
- bert
- kurdish
- language
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents KuBERT, a BERT-based model for sentiment analysis
  in Central Kurdish, a low-resource language. The authors address challenges in sentiment
  analysis due to limited linguistic resources by training BERT on a large Kurdish
  text corpus (296.5 million tokens) and developing multiple classifiers (BiLSTM,
  MLP, and fine-tuning).
---

# KuBERT: Central Kurdish BERT Model and Its Application for Sentiment Analysis

## Quick Facts
- arXiv ID: 2509.16804
- Source URL: https://arxiv.org/abs/2509.16804
- Reference count: 0
- Primary result: BERT-based model achieves 75.37% accuracy for 3-class sentiment analysis in Central Kurdish

## Executive Summary
This study introduces KuBERT, a BERT-based model designed for sentiment analysis in Central Kurdish, a low-resource language with limited linguistic resources. The authors address the challenge of developing NLP tools for Kurdish by training BERT on a large corpus of 296.5 million tokens and creating multiple classifiers including BiLSTM, MLP, and fine-tuned BERT variants. The research demonstrates that KuBERT significantly outperforms traditional models like Word2Vec, achieving 75.37% accuracy in 3-class sentiment analysis and 86.31% in 2-class analysis. The study establishes a new benchmark for Kurdish NLP and highlights the superiority of transformer-based models in capturing nuanced semantics and contextual intricacies of the language.

## Method Summary
The authors developed KuBERT by first collecting a large corpus of 296.5 million tokens from diverse Kurdish sources. They trained the BERT model on this corpus to create language-specific embeddings. For sentiment analysis, they implemented three different classifier architectures: BiLSTM, MLP, and fine-tuning of the pre-trained KuBERT model. The models were evaluated on two datasets - one for 3-class classification (positive, negative, neutral) and another for 2-class classification. The evaluation used standard metrics including accuracy, precision, recall, and F1-score. The researchers also compared KuBERT's performance against Word2Vec to demonstrate the superiority of transformer-based approaches for Kurdish language processing.

## Key Results
- KuBERT achieved 75.37% accuracy in 3-class sentiment analysis (positive, negative, neutral)
- KuBERT achieved 86.31% accuracy in 2-class sentiment analysis
- KuBERT outperformed Word2Vec by substantial margins (75.37% vs 60.54% for 3-class, 86.31% vs 72.39% for 2-class)

## Why This Works (Mechanism)
The success of KuBERT stems from BERT's ability to capture contextual relationships and semantic nuances in text through its bidirectional transformer architecture. Unlike traditional word embeddings that provide static representations, BERT dynamically adjusts word meanings based on surrounding context, which is particularly valuable for a morphologically rich language like Kurdish. The large-scale pre-training on 296.5 million tokens enables KuBERT to learn robust language patterns and representations specific to Central Kurdish, addressing the resource limitations typically faced in low-resource language processing. The fine-tuning approach allows the model to adapt these general language representations to the specific task of sentiment analysis while maintaining the contextual understanding learned during pre-training.

## Foundational Learning

**BERT Architecture**: Bidirectional transformer encoder that processes text in both directions simultaneously. Why needed: Provides context-aware representations essential for understanding sentiment nuances. Quick check: Verify model uses 12-layer transformer with 768 hidden size.

**Tokenization**: WordPiece subword tokenization scheme. Why needed: Handles out-of-vocabulary words common in low-resource languages. Quick check: Confirm vocabulary size is appropriate for Kurdish morphology.

**Fine-tuning**: Task-specific adaptation of pre-trained weights. Why needed: Transfers general language knowledge to sentiment classification. Quick check: Monitor validation loss during fine-tuning to prevent overfitting.

**Imbalanced Classification**: Handling datasets with unequal class distributions. Why needed: Neutral class represents only 12% of samples. Quick check: Examine class-wise F1-scores to identify performance gaps.

## Architecture Onboarding

**Component Map**: Text -> Tokenizer -> BERT Encoder -> Classifier Head -> Sentiment Output

**Critical Path**: Input preprocessing (tokenization, padding) -> BERT forward pass -> Classification layer -> Softmax activation -> Final prediction

**Design Tradeoffs**: The authors chose standard BERT over more efficient variants like DistilBERT, prioritizing performance over computational efficiency. This tradeoff is justified by the low-resource nature of Kurdish, where achieving reasonable accuracy is more important than model size. The decision to implement multiple classifier architectures (BiLSTM, MLP, fine-tuning) allows for comparison of different approaches while acknowledging that fine-tuning pre-trained models typically yields superior results for transfer learning tasks.

**Failure Signatures**: The model struggles particularly with the neutral class due to data imbalance, showing lower precision and recall for this category. Ambiguous or complex expressions also present challenges, as evidenced by the performance gap between 2-class and 3-class classification. These failure modes suggest limitations in the model's ability to capture subtle sentiment distinctions and handle underrepresented classes effectively.

**First 3 Experiments**:
1. Evaluate class-wise performance metrics (precision, recall, F1) to identify specific sentiment categories where the model underperforms
2. Test the impact of data augmentation techniques on the underrepresented neutral class
3. Compare computational requirements and inference speed between KuBERT and alternative transformer architectures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent can data augmentation and dataset balancing techniques improve the model's performance on the underrepresented "neutral" sentiment class?
- Basis in paper: [explicit] The conclusion states, "Future work should focus on expanding and balancing the datasets by combining more diverse sources and using data augmentation techniques."
- Why unresolved: The authors identify data imbalance as a primary limitation, noting that the "neutral" class comprises only 12% of the dataset and subsequently yields lower performance scores.
- What evidence would resolve it: A comparative analysis showing improved F1-scores for the neutral class after applying specific balancing techniques (e.g., oversampling) or synthetic data generation.

### Open Question 2
- Question: Do advanced language models such as RoBERTa and LLaMA offer significant accuracy improvements over the standard BERT architecture for Central Kurdish?
- Basis in paper: [explicit] The authors explicitly recommend, "we should use advanced models such as RoBERTa and LLaMA for Kurdish in the future, but they require large data sets, which can improve the results."
- Why unresolved: This study focused exclusively on establishing a baseline using the standard BERT architecture, leaving newer transformer variants unexplored.
- What evidence would resolve it: Benchmark comparisons of accuracy and F1-scores between KuBERT and newly trained Kurdish-specific RoBERTa or LLaMA models on the same sentiment analysis datasets.

### Open Question 3
- Question: Can the pre-trained KuBERT embeddings be effectively adapted for downstream NLP tasks other than sentiment analysis, such as text summarization or machine translation?
- Basis in paper: [explicit] The conclusion suggests, "Expanding the use of KuBERT to other NLP tasks, such as text summarization and machine translation, is also recommended for future development."
- Why unresolved: The model was validated exclusively on sentiment classification, and its utility for other complex language processing tasks remains unverified.
- What evidence would resolve it: Performance metrics (e.g., ROUGE for summarization, BLEU for translation) obtained by fine-tuning KuBERT on Central Kurdish datasets for these specific tasks.

## Limitations
- Dataset size limitations with only 2,367 sentences for 3-class classification and 2,403 for 2-class classification
- Significant class imbalance, particularly the neutral class comprising only 12% of samples
- Limited evaluation scope focused solely on sentiment analysis without testing on other NLP tasks

## Confidence
- High confidence in KuBERT's superiority over Word2Vec for Kurdish sentiment analysis
- Medium confidence in the practical applicability due to dataset limitations
- Medium confidence in the generalizability of results beyond the tested dataset

## Next Checks
1. Test KuBERT on additional Kurdish sentiment datasets with balanced class distributions to verify consistent performance across different data splits
2. Compare KuBERT against other transformer-based models (RoBERTa, DistilBERT) to establish whether BERT architecture specifically provides advantages
3. Conduct ablation studies to determine the impact of different preprocessing steps, tokenization strategies, and hyperparameter settings on model performance