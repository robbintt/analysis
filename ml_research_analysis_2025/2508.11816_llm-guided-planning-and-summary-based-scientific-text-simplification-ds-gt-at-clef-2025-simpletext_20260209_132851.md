---
ver: rpa2
title: 'LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT
  at CLEF 2025 SimpleText'
arxiv_id: '2508.11816'
source_url: https://arxiv.org/abs/2508.11816
tags:
- simplification
- text
- document
- task
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a plan-driven LLM approach for sentence-level
  scientific text simplification and a summary-guided LLM method for document-level
  simplification. The sentence-level system selects simplification strategies (rephrase,
  delete, split, etc.) through structured prompting, while the document-level approach
  first generates a summary to guide the simplification process.
---

# LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText

## Quick Facts
- arXiv ID: 2508.11816
- Source URL: https://arxiv.org/abs/2508.11816
- Reference count: 14
- Primary result: Plan-driven sentence-level simplification achieves SARI 42.33 and FKGL 7.77; summary-guided document simplification achieves SARI 40.32 on Cochrane-Auto dataset

## Executive Summary
This study presents a plan-driven LLM approach for sentence-level scientific text simplification and a summary-guided LLM method for document-level simplification. The sentence-level system selects simplification strategies (rephrase, delete, split, etc.) through structured prompting, while the document-level approach first generates a summary to guide the simplification process. Evaluation on the Cochrane-Auto dataset shows the sentence-level plan-driven approach achieves a SARI score of 42.33 with improved readability (FKGL 7.77), while the summary-guided document simplification achieves a SARI score of 40.32. Both methods demonstrate effective simplification capabilities while maintaining content fidelity, with the plan-driven approach showing particular strength in balancing simplification quality and semantic preservation.

## Method Summary
The methodology employs a two-stage framework for both sentence-level and document-level simplification. For sentence-level simplification, the LLM first classifies each sentence into one of five operations (rephrase, delete, split, ignore, merge) based on document context and following sentence, then generates simplified output conditioned on this explicit strategy choice. For document-level simplification, the LLM first produces a concise summary capturing main arguments and key findings, which serves as a semantic scaffold to guide the simplification process. Both approaches use few-shot prompting with contextual inputs (full document, target sentence, next sentence) and leverage llama-3.3-70b-versatile for inference. The system was evaluated on the Cochrane-Auto dataset using SARI as the primary metric alongside BLEU, BERTScore, and readability measures.

## Key Results
- Sentence-level plan-driven approach achieves SARI 42.33 (42.98 with BERTScore) and FKGL 7.77
- Summary-guided document simplification achieves SARI 40.32 (42.92 with BERTScore)
- Document-level direct LLM simplification outperforms summary-guided in SARI/BLEU/BERTScore but produces less concise output
- High deletion proportions (0.70-0.75) contribute to low BLEU scores but maintain readability improvements

## Why This Works (Mechanism)

### Mechanism 1: Explicit Strategy Selection Before Generation
Decoupling strategy selection from text generation improves simplification quality compared to direct end-to-end approaches. The LLM first classifies each sentence into one of five operations (rephrase, delete, split, ignore, merge) based on document context and following sentence, then generates simplified output conditioned on this explicit strategy choice. This creates an intermediate reasoning step that constrains downstream generation.

### Mechanism 2: Summary-as-Semantic-Scaffold for Document Coherence
Generating an intermediate summary before simplification provides global semantic anchoring that reduces drift and over-deletion. The document-level pipeline first produces a concise summary capturing main arguments and key findings. This summary is then injected into the simplification prompt as a "semantic scaffold," explicitly constraining the model to produce outputs aligned with high-level document intent.

### Mechanism 3: Contextual Few-Shot Prompting with Local Document Grounding
Providing document-level context (source document + current sentence + next sentence) improves simplification decisions over isolated sentence processing. Few-shot examples demonstrate how to use surrounding context to resolve ambiguity and select appropriate simplification strategies.

## Foundational Learning

- **SARI (System output Against References and Input sentence)**: Primary evaluation metric for simplification tasks, explicitly measuring keep/delete/add operations against both reference and source. Quick check: Can you explain why SARI is more suitable than BLEU for evaluating simplification? (Hint: BLEU penalizes lexical divergence even when simplification improves clarity.)

- **Few-Shot Prompting with Structured Output**: The entire methodology relies on coaxing an LLM to follow explicit reasoning patterns via in-context examples. Understanding prompt design is critical. Quick check: What happens if your few-shot examples demonstrate inconsistent strategy selection patterns?

- **Readability Metrics (FKGL) vs. Semantic Fidelity (BERTScore)**: The paper reports improved FKGL (readability) but lower BLEU (surface overlap)—you must understand this trade-off to interpret results. Quick check: Why might a simplification system achieve good FKGL scores while producing factually incorrect output?

## Architecture Onboarding

- **Component map**: Input Document -> Task 1.1 (Sentence-Level) -> [Few-Shot Prompt Constructor] -> [LLM Strategy Selector] (rephrase/delete/split/ignore/merge) -> [LLM Simplification Generator] -> [Simplified Sentence Output]; Input Document -> Task 1.2 (Document-Level) -> [LLM Summarizer] -> [Generated Summary] -> [LLM Summary-Guided Simplifier] -> [Simplified Document Output]

- **Critical path**: Prompt template construction (Appendix B.1–B.3) — incorrect templates break the entire pipeline; LLM inference for strategy selection / summarization — hallucinations here cascade downstream; Conditional simplification generation — final output quality depends on all upstream signals

- **Design tradeoffs**: Plan-driven vs. Direct simplification yields marginal BLEU/FKGL improvements (Table 5) but adds latency from two-stage inference; Summary-guided vs. Direct document simplification produces more concise output (lower token length in Table 6) but slightly lower SARI/BLEU—trade-off is coherence vs. metric performance; Strategy granularity: Five strategies provide control but risk ambiguity—finer categories increase decision complexity

- **Failure signatures**: Low BLEU + Low FKGL: Aggressive deletion destroying semantic content; High FKGL + Low SARI: Model failing to simplify, outputting near-copy of source; Strategy distribution collapse: Model selecting same strategy (e.g., always "rephrase")—indicates prompt failure; Summary hallucination: Document simplification diverges from source content

- **First 3 experiments**: Ablate strategy selection: Replace plan-driven approach with direct simplification; compare SARI/FKGL to quantify contribution of explicit planning; Prompt template sensitivity: Vary few-shot example quality; measure impact on strategy distribution and final SARI scores; Summary quality analysis: Manually annotate generated summaries for hallucinations and omissions; correlate summary quality with downstream simplification SARI/BERTScore

## Open Questions the Paper Calls Out
- Can integrating automatic evaluation metrics into an iterative feedback loop improve the structural prompting framework for scientific text simplification? (Basis: future research focus on "iterative loop that refines prompts based on automatic evaluation metrics")
- Does summary-guided document simplification yield better human-evaluated coherence and factual alignment than direct LLM simplification, despite scoring lower on automatic metrics? (Basis: Table 6 shows summary-guided underperforms direct simplification on metrics, yet authors claim qualitative advantages)
- To what extent does the high deletion proportion (0.70–0.75) in the generated outputs result in information loss compared to reference simplifications? (Basis: Tables 2 and 4 show very low BLEU scores and high deletion proportions, while Table 1 indicates the "Reference" has a lower deletion proportion)

## Limitations
- LLM inference parameters (temperature, max_tokens, top_p) are not specified, creating uncertainty about output variability
- Exact few-shot examples and prompt construction criteria are partially shown but full details are unclear
- Summary generation quality and hallucination rates are not analyzed, despite being critical to document-level performance

## Confidence
- **High Confidence**: The two-stage plan-driven approach achieves measurable improvements over direct simplification; The summary-guided document simplification produces coherent outputs that follow document-level semantics; The five-strategy framework provides useful control over simplification operations
- **Medium Confidence**: The improvement in FKGL (readability) is sustainable without sacrificing semantic fidelity; The methodology generalizes beyond the Cochrane-Auto dataset to other scientific domains; The trade-off between summary-guided coherence and direct simplification metrics is optimal
- **Low Confidence**: The relative importance of each simplification strategy in different contexts; The robustness of the approach to varying document lengths and complexity levels; The comparison with fine-tuned models is definitive given the lack of detailed ablation studies

## Next Checks
- **Check 1**: Ablation of strategy selection—remove the plan-driven two-stage approach and perform direct simplification using the same LLM. Compare SARI, BLEU, and FKGL scores to quantify the contribution of explicit strategy planning.
- **Check 2**: Summary quality assessment—manually annotate 50 generated summaries for hallucinations, omissions, and semantic coverage. Compute correlation between summary quality scores and downstream simplification SARI/BERTScore to test the semantic scaffold hypothesis.
- **Check 3**: Prompt template sensitivity analysis—systematically vary the few-shot examples in the sentence-level prompt (using well-formed vs. noisy examples, different strategy distributions). Measure impact on strategy selection consistency and final SARI scores.