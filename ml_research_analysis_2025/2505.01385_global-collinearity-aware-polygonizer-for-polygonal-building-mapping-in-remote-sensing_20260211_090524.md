---
ver: rpa2
title: Global Collinearity-aware Polygonizer for Polygonal Building Mapping in Remote
  Sensing
arxiv_id: '2505.01385'
source_url: https://arxiv.org/abs/2505.01385
tags:
- building
- polygon
- polyline
- simplification
- masks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Global Collinearity-aware Polygonizer
  (GCP), a novel framework for mapping polygonal buildings from remote sensing images.
  GCP processes binary masks from instance segmentation models through a pipeline
  that includes polyline regression using a transformer-based module and a globally
  optimal polygon simplification method based on dynamic programming.
---

# Global Collinearity-aware Polygonizer for Polygonal Building Mapping in Remote Sensing

## Quick Facts
- **arXiv ID**: 2505.01385
- **Source URL**: https://arxiv.org/abs/2505.01385
- **Reference count**: 40
- **Key outcome**: Introduces GCP framework achieving state-of-the-art polygonal building mapping on CrowdAI and WHU-Mix benchmarks with AP of 81.5 and N-ratio of 0.83

## Executive Summary
This paper presents the Global Collinearity-aware Polygonizer (GCP), a novel framework for mapping polygonal buildings from remote sensing images. The method processes binary masks from instance segmentation models through a pipeline that includes polyline regression using a transformer-based module and a globally optimal polygon simplification method based on dynamic programming. The simplification module balances fidelity and simplicity while preserving collinearity, and its objective function is differentiable for end-to-end training.

GCP was evaluated on two public benchmarks—CrowdAI Mapping Challenge and WHU-Mix (vector)—achieving state-of-the-art performance. On CrowdAI, it attained AP of 81.5, AP 50 of 96.9, AP 75 of 91.2, and an N-ratio of 0.83, indicating compact and simplified polygon representations. On WHU-Mix, GCP showed superior AP and generalization, especially on the more challenging test set. Ablation studies confirmed the effectiveness of the polyline regression module, global collinearity loss, and the proposed simplification method, which outperformed traditional approaches like Douglas-Peucker in accuracy and compactness.

## Method Summary
The Global Collinearity-aware Polygonizer (GCP) is a framework for polygonal building mapping from remote sensing images that processes binary masks through a pipeline of polyline regression and globally optimal polygon simplification. The polyline regression module uses a transformer-based approach to extract features and predict polyline vertices, while the simplification module employs dynamic programming to optimize a balance between fidelity and simplicity while preserving collinearity. The entire framework is trained end-to-end with a differentiable objective function.

## Key Results
- Achieved AP of 81.5, AP 50 of 96.9, AP 75 of 91.2, and N-ratio of 0.83 on CrowdAI benchmark
- Demonstrated superior performance on WHU-Mix benchmark with better AP and generalization
- Outperformed traditional simplification methods like Douglas-Peucker in accuracy and compactness
- Ablation studies confirmed effectiveness of polyline regression, global collinearity loss, and simplification method

## Why This Works (Mechanism)
The method works by leveraging transformer-based polyline regression to accurately capture building contours, followed by a dynamic programming-based simplification that preserves collinearity while maintaining fidelity. The differentiable nature of the simplification objective enables end-to-end training, allowing the model to optimize both the polyline prediction and simplification jointly for improved mapping accuracy.

## Foundational Learning
- **Instance segmentation masks**: Binary masks isolating individual buildings; needed as input for polygon extraction, quick check: verify mask quality and completeness
- **Transformer-based feature extraction**: Captures long-range spatial dependencies in building contours; needed for accurate polyline regression, quick check: test with different backbone architectures
- **Dynamic programming optimization**: Finds globally optimal vertex sequences; needed for balancing simplicity and fidelity, quick check: compare runtime with different DP state spaces
- **Collinearity preservation**: Ensures straight edges remain straight in simplified polygons; needed for realistic building representations, quick check: measure angular deviation in simplified polygons
- **Differentiable simplification**: Enables end-to-end training; needed for joint optimization, quick check: verify gradient flow through simplification module

## Architecture Onboarding
**Component map**: Instance segmentation masks -> Transformer feature extraction -> Polyline regression -> Dynamic programming simplification -> Simplified polygons

**Critical path**: The critical path involves extracting features from the input masks using a transformer, predicting polyline vertices, and then optimizing the polygon simplification through dynamic programming while preserving collinearity.

**Design tradeoffs**: The method trades off computational complexity in the dynamic programming simplification for improved accuracy and compactness of the resulting polygons. The transformer-based approach increases model complexity but enables better capture of long-range spatial dependencies.

**Failure signatures**: Potential failure modes include poor performance on highly complex or irregular building shapes, sensitivity to noise in the input segmentation masks, and scalability issues with very high vertex counts or dense building layouts.

**3 first experiments**: 1) Test the method on a small subset of buildings with varying complexity to validate the pipeline end-to-end, 2) Compare the simplification results with Douglas-Peucker on a few example buildings to verify the claimed improvements, 3) Perform an ablation study by removing the global collinearity loss to quantify its contribution.

## Open Questions the Paper Calls Out
None

## Limitations
- Primary uncertainty lies in generalizability beyond building extraction to other man-made structures
- Dynamic programming-based simplification may face scalability challenges with very high vertex counts or complex building layouts
- Reliance on high-quality binary masks from instance segmentation models is an implicit assumption not thoroughly examined

## Confidence
- **High confidence** in the technical novelty of the collinearity-aware simplification module and its differentiable design for end-to-end training
- **Medium confidence** in the claimed state-of-the-art performance on CrowdAI and WHU-Mix benchmarks, as the paper provides limited analysis of failure cases or robustness to varying building densities
- **Medium confidence** in the ablation study results, though the specific contributions of individual components could be more precisely quantified

## Next Checks
1. Test the method on diverse remote sensing datasets containing non-building polygonal structures (e.g., roads, parking lots) to assess cross-category generalization
2. Evaluate performance under varying segmentation mask qualities by introducing controlled noise or using different instance segmentation backbones
3. Benchmark runtime and memory usage on large-scale scenes to verify scalability of the dynamic programming simplification approach