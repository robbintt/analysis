---
ver: rpa2
title: 'Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and
  Query-Driven Insights'
arxiv_id: '2510.18277'
source_url: https://arxiv.org/abs/2510.18277
tags:
- reviews
- user
- booking
- instaguide
- review
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces instaGuide, an AI-powered web application
  that summarizes and queries user reviews from Booking.com listings using Large Language
  Models (LLMs) and Retrieval-Augmented Generation (RAG) technology. The tool automates
  review extraction, generates summaries, and allows users to ask specific questions
  about properties.
---

# Enhancing Hotel Recommendations with AI: LLM-Based Review Summarization and Query-Driven Insights

## Quick Facts
- **arXiv ID:** 2510.18277
- **Source URL:** https://arxiv.org/abs/2510.18277
- **Reference count:** 40
- **Primary result:** instaGuide is an AI-powered web application that summarizes and queries user reviews from Booking.com listings using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology.

## Executive Summary
This paper introduces instaGuide, a web application that automates the extraction and summarization of user reviews from Booking.com hotel listings. The system uses Retrieval-Augmented Generation (RAG) to ground Large Language Models in actual review data, enabling both summarization and interactive querying. Multiple LLMs were evaluated for accuracy, speed, and cost, with Gemini 1.5 Flash emerging as the fastest (3 seconds for both tasks) while Claude 3.5 Sonnet provided the most structured and insightful responses. User feedback from a small test group confirmed significant time savings and improved decision-making, though concerns about over-reliance and control were noted.

## Method Summary
The instaGuide system is built on a Python/Django web framework that fetches 200 reviews per listing from Booking.com using either custom web scraping or the Apify API. These reviews are then injected into an LLM's context window via RAG technology, with prompt engineering used to structure outputs into positive, negative, and conclusion sections. The system supports multiple LLM backends (GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Flash) and is containerized using Docker. The evaluation compared latency, cost, and response quality across models, with Gemini 1.5 Flash showing optimal speed and Claude 3.5 Sonnet providing superior structured responses.

## Key Results
- Gemini 1.5 Flash achieved the fastest response times (3 seconds for both summarization and querying) while maintaining reasonable quality
- Claude 3.5 Sonnet provided the most structured and insightful responses, organizing outputs into clear positive/negative aspects and conclusions
- User feedback from a small test group (n=5) confirmed significant time savings and improved decision-making, though concerns about over-reliance were noted

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieval-Augmented Generation (RAG) enables general-purpose LLMs to provide property-specific insights without fine-tuning.
- **Mechanism:** The system fetches external review data (unstructured text) and injects it into the LLM's context window. This grounds the model's response in actual user experiences rather than parametric memory, allowing for summarization of properties the model has never seen.
- **Core assumption:** The LLM's context window is large enough to hold the retrieved reviews (e.g., 200 reviews) without significant information loss.
- **Evidence anchors:**
  - [abstract] "summarizes and queries user reviews... using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology."
  - [section 3.4] "RAG technology enables an LLM to enrich its knowledge base with external material provided by a third party source."
  - [corpus] "End-to-End Aspect-Guided Review Summarization at Scale" confirms the viability of combining LLMs with external data extraction for summarization.
- **Break condition:** The number of reviews exceeds the model's context window (token limit), leading to truncation and incomplete summaries.

### Mechanism 2
- **Claim:** Prompt engineering structures unstructured reviews into distinct "positive," "negative," and "conclusion" blocks.
- **Mechanism:** Rather than asking "What do people think?", the system uses specific prompt instructions (Figure 4) to force the model to categorize feedback. This reduces the cognitive load of parsing narrative text for the end-user.
- **Core assumption:** The reviews contain distinct, extractable sentiments that can be neatly categorized by the model.
- **Evidence anchors:**
  - [section 3.5] "generate the response via careful prompt engineering... [to] provide the fetched reviews, the user’s question."
  - [section 4.2] Notes that Claude 3.5 Sonnet specifically organizes output into positive aspects, negative aspects, and a conclusion.
  - [corpus] "Decomposed Opinion Summarization with Verified Aspect-Aware Modules" supports the efficacy of modular, aspect-guided summarization.
- **Break condition:** Ambiguous or sarcastic reviews are misinterpreted by the model, leading to incorrect classification (e.g., a sarcastic "Great 'service'" filed under positives).

### Mechanism 3
- **Claim:** Latency and user trust are optimized by selecting specific model architectures (e.g., Gemini 1.5 Flash) for interactive query loops.
- **Mechanism:** The architecture prioritizes low-latency inference (3 seconds) over deep reasoning complexity. Fast feedback loops maintain user engagement in a "chat" interface, whereas slower models (GPT-4) may frustrate users.
- **Core assumption:** Users prefer faster, "good enough" answers over slower, potentially more nuanced deep-reasoning outputs (o1-preview) for simple queries like "Is there parking?".
- **Evidence anchors:**
  - [section 3.2.2] "Gemini 1.5 Flash proved to be the best choice overall, primarily due to its significantly higher speed."
  - [table 3] Shows Gemini 1.5 Flash taking 3 seconds vs GPT-4 taking 10 seconds.
  - [corpus] "Improving User Experience with Personalized Review Ranking" emphasizes the need to alleviate information overload to maintain user engagement.
- **Break condition:** Complex queries requiring multi-step reasoning fail or hallucinate due to the "fast" model's lower reasoning capacity compared to "thinking" models like o1.

## Foundational Learning

- **Concept:** **Context Windows**
  - **Why needed here:** The core constraint of the system is how many reviews can fit into a single prompt. Understanding token limits (e.g., 8k vs. 1M tokens) determines whether you summarize 50 or 500 reviews.
  - **Quick check question:** If a property has 5,000 reviews, can Gemini 1.5 Flash read them all in one prompt without chunking?

- **Concept:** **Web Scraping vs. API Integration**
  - **Why needed here:** The paper highlights a major tradeoff: Scraping is fast/free but fragile and legally gray; APIs are robust but costly. This determines the reliability of the data pipeline.
  - **Quick check question:** What happens to the scraper if Booking.com changes their HTML `div` classes tomorrow?

- **Concept:** **Prompt Engineering (System Prompts)**
  - **Why needed here:** The quality of the summary depends on how the LLM is instructed to process the text. Distinguishing between a "system prompt" (context) and a "user query" is vital.
  - **Quick check question:** How do you instruct the model to say "I don't know" if the reviews don't mention a specific amenity?

## Architecture Onboarding

- **Component map:**
  Frontend (Django) -> Data Fetcher (Scraper/Apify API) -> Prompt Constructor -> LLM API Gateway -> UI Rendering

- **Critical path:**
  User URL Input -> **Data Fetcher** (Scrape 200 reviews) -> **Prompt Constructor** (Inject reviews + system instruction) -> **LLM Inference** (Gemini/GPT) -> **UI Rendering** (Display Summary)

- **Design tradeoffs:**
  - **Speed vs. Structure:** Use Gemini 1.5 Flash for speed (3s), or Claude 3.5 Sonnet for structured bullet points (10s)
  - **Cost vs. Maintenance:** Use free Web Scraping (high maintenance, legal risk) vs. paid Apify API ($1/1000 reviews, zero maintenance)
  - **Privacy vs. Capability:** Use cloud LLMs (high capability, data leaves premise) vs. Local LLaMA 3.2 (privacy, but high hardware requirements and lower performance)

- **Failure signatures:**
  - **Empty Summaries:** Scraper fails to find the review container element (HTML changed)
  - **Generic Responses:** Context window overflow (too many reviews) causing the LLM to lose specific details
  - **Timeouts:** Local LLaMA model exceeds 60s processing time (Section 4.2)

- **First 3 experiments:**
  1. **Latency Test:** Feed the exact same 200-review context to GPT-4o, Claude 3.5, and Gemini Flash. Measure time-to-first-token and summary quality side-by-side
  2. **Scraper Fragility Test:** Run the scraper against 10 different hotel layouts (e.g., Hostels vs. Resorts) to identify extraction failures
  3. **Hallucination Check:** Ask the system a question about an amenity known *not* to exist at a specific property to see if the model admits ignorance or invents an answer

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of LLM-based summarization and RAG models generalize to platforms with differing review structures, such as Airbnb or e-commerce marketplaces?
- **Basis in paper:** [explicit] The authors state in Future Work that the solution "could be very well be applied on other platforms... [and] expanded to other fields."
- **Why unresolved:** The current study was strictly limited to scraping and evaluating Booking.com listings, utilizing that site's specific "positive/negative" review structure.
- **Evidence:** A comparative study measuring summary accuracy and latency across Airbnb and Booking.com listings for identical properties.

### Open Question 2
- **Question:** What specific metrics and safeguards are required to effectively detect and mitigate LLM hallucinations in review summaries to prevent misleading users?
- **Basis in paper:** [explicit] The paper identifies "biased or hallucinated LLM outputs" as a critical obstacle requiring "further research and optimization" before real-world deployment.
- **Why unresolved:** The evaluation relied on informal user feedback regarding time savings rather than rigorous fact-checking or consistency metrics against the source text.
- **Evidence:** A benchmark dataset of reviews with verified ground-truth facts, used to measure the hallucination rate of different RAG configurations.

### Open Question 3
- **Question:** To what extent does integrating Explainable AI (XAI) features improve user trust and perceived control compared to standard "black box" LLM responses?
- **Basis in paper:** [explicit] Future Work highlights a user need for "embedding Explainable AI... in an effort to provide a transparent solution."
- **Why unresolved:** The current prototype provides recommendations without justification, and the small test group expressed concerns regarding control and potential over-reliance.
- **Evidence:** A/B testing the current tool against an XAI-enhanced version to measure user confidence scores and the "feeling of control."

## Limitations
- The study's evaluation relies on a very small user test group (n=5), limiting generalizability of satisfaction metrics
- The system's robustness against adversarial or ambiguous reviews (e.g., sarcasm, mixed sentiments) is not validated
- While the paper notes that web scraping carries legal and maintenance risks, it doesn't provide a concrete strategy for handling terms-of-service violations or HTML layout changes

## Confidence

- **High Confidence:** The latency measurements (3 seconds for Gemini 1.5 Flash) and context window analysis (1M token capacity) are directly measurable and reproducible. The architectural flow (scraping → RAG → LLM) is clearly specified.
- **Medium Confidence:** The qualitative comparison between Claude 3.5 Sonnet's structured responses and Gemini 1.5 Flash's speed reflects observable differences but depends on subjective assessment of "insightfulness."
- **Low Confidence:** The claim that instaGuide "significantly reduces cognitive load" is based on user interviews with only 5 participants, making statistical validation impossible.

## Next Checks

1. **Scraper Robustness:** Test the review fetcher against 20 diverse Booking.com property types (luxury hotels, hostels, apartments) to measure extraction failure rates and identify HTML selector fragility.
2. **Hallucination Stress Test:** Systematically query the model about non-existent amenities (e.g., "Does this property have a helipad?") across all three LLMs to measure hallucination frequency and refusal rates.
3. **Context Window Saturation:** Incrementally increase review count (50, 100, 200, 500) and measure when summary quality degrades, identifying the practical token limit before information loss occurs.