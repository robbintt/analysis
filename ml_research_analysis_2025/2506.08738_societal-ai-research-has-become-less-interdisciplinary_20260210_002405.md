---
ver: rpa2
title: Societal AI Research Has Become Less Interdisciplinary
arxiv_id: '2506.08738'
source_url: https://arxiv.org/abs/2506.08738
tags:
- societal
- research
- interdisciplinary
- teams
- orientation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzed over 100,000 AI research papers to examine
  how societal concerns are integrated into technical AI research. Using a machine
  learning classifier, it measured the prevalence of societal orientation in papers
  based on ethical values and societal concerns.
---

# Societal AI Research Has Become Less Interdisciplinary

## Quick Facts
- arXiv ID: 2506.08738
- Source URL: https://arxiv.org/abs/2506.08738
- Reference count: 19
- Primary result: CS-only teams now produce 71% of societally-oriented AI papers, up from 49% in 2014

## Executive Summary
This study analyzed over 100,000 AI research papers to examine how societal concerns are integrated into technical AI research. Using a machine learning classifier, it measured the prevalence of societal orientation in papers based on ethical values and societal concerns. The research found that while interdisciplinary teams are more likely to produce societally-oriented work, computer science-only teams now account for a growing share of the field's overall societal output. Between 2014 and 2024, the proportion of societally-oriented content attributed to CS-only teams increased from 49% to 71%. These teams increasingly focus on societal questions across diverse topics like fairness, safety, healthcare, and misinformation. The findings challenge assumptions about interdisciplinary collaboration driving societal AI and suggest evolving norms within computer science itself are playing a key role.

## Method Summary
The researchers collected 101,919 AI papers from ArXiv (2014-2024) and used a SciBERT-based classifier to identify sentences containing societal orientation (ethical values or societal issues). They analyzed sentences from abstract, introduction, and conclusion sections only, training on 1,002 annotated sentences. Author discipline was inferred from publication history using Semantic Scholar data, classifying teams as CS-only, NSM-only, SSH-only, or interdisciplinary based on whether authors had published at least 90% of their work in one field. They then aggregated results by team type and analyzed temporal trends.

## Key Results
- CS-only teams increased their share of societally-oriented AI papers from 49% to 71% between 2014-2024
- CS-only teams now tackle the full range of societal topics previously associated with interdisciplinary work
- Interdisciplinary teams still have higher average societal orientation per paper, but CS-only teams dominate in volume
- CS-only teams increasingly focus on fairness, safety, healthcare, and misinformation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Institutional pressure may be socializing computer science (CS) researchers into adopting societal framing without interdisciplinary collaboration.
- **Mechanism:** Mandates for ethics statements (e.g., NeurIPS broader impact) and funding requirements incentivize CS-only teams to superficially or substantively integrate societal language to survive peer review and secure grants.
- **Core assumption:** Researchers respond to incentive structures by modifying paper content, specifically in abstract/intro/conclusion sections.
- **Evidence anchors:**
  - [abstract] "CS-only teams... are increasingly integrating societal concerns into their papers... from fairness and safety to healthcare."
  - [section] "Leading AI conferences... have begun asking authors to include ethical or societal impact statements... [this] may reflect a more optimistic perspective."
  - [corpus] "Reflexive Prompt Engineering" discusses frameworks for responsible AI interaction, supporting the trend of formalizing responsibility.
- **Break condition:** If institutional review boards (IRBs) or peer reviewers begin rejecting papers for "ethics washing" rather than rewarding mere inclusion of keywords.

### Mechanism 2
- **Claim:** The capability of Large Language Models (LLMs) to function as general-purpose tools lowers the barrier for technical teams to address applied societal domains.
- **Mechanism:** LLMs reduce the need for domain-specific architectures. This allows CS teams to tackle "societal" problems (e.g., healthcare, misinformation) without deep collaboration with domain experts, as the model abstracts the complexity.
- **Core assumption:** The ease of applying foundation models to new domains outpaces the complexity of understanding the societal nuance of those domains.
- **Evidence anchors:**
  - [abstract] "CS-only teams... tackling a wide range of domains - from fairness and safety to healthcare and misinformation."
  - [section] "With the rise of LLMs... researchers may increasingly shift focus from foundational innovation toward addressing real-world challenges."
  - [corpus] Corpus shows "From Texts to Shields" and "Harnessing Multi-Agent LLMs," indicating convergence trends, though direct evidence of *reduced* collaboration is specific to the paper.
- **Break condition:** If applied problems require deep domain expertise that foundation models cannot simulate, forcing a return to collaboration.

### Mechanism 3
- **Claim:** The rise of "Computational Social Science" (CSS) is blurring disciplinary boundaries, causing interdisciplinary work to be misclassified as CS-only.
- **Mechanism:** Researchers may be trained in social sciences but publish in CS venues (or vice versa). If their publication history is predominantly in ArXiv/CS journals, they are labeled "CS-only," masking the interdisciplinary nature of the work.
- **Core assumption:** Discipline is defined by venue history (Semantic Scholar metadata) rather than epistemological approach.
- **Evidence anchors:**
  - [section] "The results may signal the emergence of computational social science... Researchers working in this space might still [be] categorized as computer scientists."
  - [corpus] "Socio-technical aspects of Agentic AI" implies a blending of technical and social inquiry.
- **Break condition:** If bibliometric classification moves beyond publication venue to methodology or citation network analysis.

## Foundational Learning

- **Concept: Volume vs. Intensity (Mean vs. Share)**
  - **Why needed here:** The paper presents a paradox: Interdisciplinary teams have *higher average* societal orientation (intensity), but CS-only teams produce the *majority* of societal output (volume/share).
  - **Quick check question:** Can a subgroup have a lower average score but dominate the total sum? (Yes, if the subgroup size $N$ is significantly larger).

- **Concept: Operationalization via Classification**
  - **Why needed here:** "Societal orientation" is not a physical measurement; it is a probability score from a SciBERT classifier trained on 1,000 sentences. The findings depend entirely on the validity of this proxy.
  - **Quick check question:** Does the classifier measure deep ethical reasoning or just keyword co-occurrence?

- **Concept: Bibliometric Inference**
  - **Why needed here:** The study infers author discipline from past publication venues (Semantic Scholar API) using a 90% threshold. This reduces complex academic identities to single labels.
  - **Quick check question:** If a researcher publishes 89% in Physics and 11% in AI, how are they labeled? (Likely "Interdisciplinary" or ambiguous, depending on the specific 90% threshold rule).

## Architecture Onboarding

- **Component map:** ArXiv API (101k papers) -> Semantic Scholar API (author history) -> PDF text extraction -> Section filtering (Intro/Abstract/Conclusion) -> SciBERT Embedding -> Logistic Regression Classifier -> Author discipline mapping (CS/NSM/SSH) -> Aggregation by team type -> Time series regression

- **Critical path:** The **Disciplinary Inference** step. The paper admits that applying a 90% threshold to author publication history determines team composition. Misclassification here cascades into the conclusion that "CS-only" teams are dominant.

- **Design tradeoffs:**
  - **Scale vs. Depth:** Analyzing 100k papers allows broad trends but relies on automated "societal orientation" scores rather than qualitative human assessment of argument quality.
  - **Section Limiting:** The system only analyzes Intro/Abstract/Conclusion. This improves efficiency but risks missing technical implementation details of societal constraints found in Methods sections.

- **Failure signatures:**
  - **"Ethics Washing" Detection Failure:** The classifier flags the presence of societal keywords (e.g., "fairness") but cannot detect if the paper then dismisses the concern or treats it procedurally.
  - **False Positive CS-Dominance:** If "Computational Social Scientists" publish primarily in CS venues, they are counted as "CS-only," falsely inflating the perception that pure technologists are solving societal problems alone.

- **First 3 experiments:**
  1. **Robustness Check (Thresholds):** Re-run the analysis dropping the 90% threshold to 70% or 50% for author discipline to see if "CS-only" dominance persists or if it was an artifact of strict labeling.
  2. **Qualitative Audit:** Sample 50 "high societal score" papers from CS-only teams and manually evaluate if they contain substantive ethical engagement or merely "boilerplate" mentions (validating the classifier's semantic depth).
  3. **Citation Network Analysis:** Check if CS-only societal papers cite SSH literature. If they don't, it supports the "internal shift" hypothesis; if they do, it suggests invisible collaboration or influence.

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the implications for AI safety and governance if the majority of societally-oriented research is produced by exclusively technical teams rather than interdisciplinary ones?
- **Open Question 2:** What distinctive perspectives can social sciences and humanities offer when technical fields are increasingly addressing societal demands independently?
- **Open Question 3:** Are important critical perspectives or frameworks being sidelined as computer science-only teams increasingly dominate the production of societal AI research?
- **Open Question 4:** Is the rise in societal orientation within computer science driven by institutional interventions (e.g., ethics statements), a shift to applied research, or the emergence of computational social science?

## Limitations
- Bibliometric inference of disciplinary identity using 90% threshold may misclassify computational social scientists as CS-only
- Societal orientation classifier cannot distinguish substantive ethical engagement from superficial keyword usage
- Analysis limited to abstract, introduction, and conclusion sections, missing methodological details
- Cannot detect absence of specific critical frameworks or minority viewpoints

## Confidence

- **High Confidence:** The core empirical finding that CS-only teams now produce the majority share of societally-oriented AI papers (increasing from 49% to 71% between 2014-2024) is supported by the bibliometric analysis and regression modeling.
- **Medium Confidence:** The interpretation that this trend reflects either "ethics washing" driven by institutional incentives or genuine internalization of societal concerns within computer science requires further validation, as the classifier cannot distinguish substantive from superficial engagement.
- **Low Confidence:** The hypothesis that computational social science is blurring disciplinary boundaries cannot be directly tested with the current methodology, as author discipline is inferred solely from publication venue history.

## Next Checks

1. **Threshold Sensitivity Analysis:** Re-run the analysis using lower author discipline thresholds (70% or 50% instead of 90%) to determine if CS-only dominance persists or represents an artifact of strict labeling criteria.

2. **Qualitative Audit of High-Scoring Papers:** Manually evaluate a random sample of 50 CS-only papers with high societal orientation scores to determine if they contain substantive ethical reasoning or merely "boilerplate" mentions of societal concerns.

3. **Citation Network Analysis:** Examine whether CS-only societal papers cite social science literature. A lack of such citations would support the "internal shift" hypothesis, while citation patterns would suggest invisible interdisciplinary influence.