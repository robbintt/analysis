---
ver: rpa2
title: 'Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via
  Catfish Agent for Clinical Decision Making'
arxiv_id: '2505.21503'
source_url: https://arxiv.org/abs/2505.21503
tags:
- tion
- agent
- catfish
- normal
- ther
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'We identify Silent Agreement as a critical failure mode in multi-agent
  LLM clinical decision making, where agents prematurely converge on diagnoses without
  sufficient critical analysis. To address this, we introduce the Catfish Agent, which
  injects structured dissent using two mechanisms: (i) complexity-aware intervention,
  adapting agent engagement based on case difficulty, and (ii) tone-calibrated intervention,
  modulating dissent strength to maintain constructive dialogue.'
---

# Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making

## Quick Facts
- arXiv ID: 2505.21503
- Source URL: https://arxiv.org/abs/2505.21503
- Reference count: 40
- Primary result: 12.73-point improvement on average (39.2% relative gain) over DeepSeek-R1 on medical Q&A tasks

## Executive Summary
This paper identifies "Silent Agreement" as a critical failure mode in multi-agent LLM clinical decision making, where agents prematurely converge on diagnoses without sufficient critical analysis. To address this, the authors introduce the Catfish Agent, which injects structured dissent using two mechanisms: complexity-aware intervention that adapts engagement based on case difficulty, and tone-calibrated intervention that modulates dissent strength to maintain constructive dialogue. Evaluated on nine medical Q&A and three medical VQA benchmarks, the method demonstrates substantial performance gains across diverse clinical reasoning scenarios.

## Method Summary
The method employs a multi-agent framework with five key components: a Moderator that classifies case complexity and makes final decisions, Expert Agents with domain-specific roles, a Catfish Agent that injects dissent, and a Summary Agent that aggregates round-level reasoning. The framework uses three complexity tiers (Basic, Intermediate, Advanced) with corresponding Catfish autonomy levels. The Catfish employs tone-calibrated interventions (mild, moderate, strong) based on group convergence patterns. The system operates in zero-shot settings using o3-mini via OpenAI API, with termination conditions based on consensus, failed interventions, or round limits.

## Key Results
- 12.73-point improvement on average (39.2% relative gain) over DeepSeek-R1 on Q&A tasks
- 5.33-point improvement (12.7% relative gain) over MDAgent on VQA tasks
- Reduces silent agreement rate from 23.3% to 17.1% while improving non-silent accuracy from 45.5% to 55.2%

## Why This Works (Mechanism)

### Mechanism 1: Complexity-Aware Intervention
Stratifying Catfish Agent autonomy by case difficulty increases intervention relevance and diagnostic accuracy. The Moderator classifies cases as basic/intermediate/advanced, with Catfish performing lightweight critique in basic cases, monitoring multi-turn debate in intermediate cases, and becoming a free-roaming critic in advanced cases. Full design yields 50% accuracy vs. 36% without Catfish on intermediate MedQA cases.

### Mechanism 2: Tone-Calibrated Intervention
Scaling dissent rhetoric based on group convergence preserves collaboration while surfacing overlooked evidence. The Catfish monitors turn-level responses for logical inconsistencies and increases rhetorical intensity with perceived premature consensus: mild (reflective prompts), intermediate (Socratic probes), strong (assertive devil's-advocate challenges). This reduces silent agreement from 23.3% to 17.1% and improves non-silent accuracy from 45.5% to 55.2%.

### Mechanism 3: Structured Dissent Breaking Silent Agreement
Explicitly assigning a dissent-injection role reduces premature consensus and improves diagnostic outcomes. The Catfish is tasked with "breaking the silence" by critiquing assumptions, proposing alternative diagnoses, and challenging superficial consensus. This reduces silent rates from 61-91% to 11-17% in baseline agents.

## Foundational Learning

- **Silent Agreement / Groupthink in Multi-Agent LLMs**: The core diagnosis of the paper; agents prematurely converge without critique. Quick check: Can you distinguish silent agreement (no response/justification) from genuine consensus with explicit reasoning?

- **Role-Based Prompting & Persona Assignment**: The Catfish and Expert Agents are instantiated via structured prompts with domain roles. Quick check: How does constraining an agent's role (e.g., "Nephrologist specializing in diabetic kidney disease") affect its reasoning trajectory?

- **Multi-Round Multi-Agent Debate Dynamics**: The framework uses sequential turns, round summaries, and termination conditions. Quick check: What termination signals indicate productive debate vs. deadlock or silent agreement?

## Architecture Onboarding

- **Component map**: Moderator -> Expert Agents + Catfish Agent -> Summary Agent -> Moderator final decision
- **Critical path**: 1) Complexity classification, 2) Expert recruitment, 3) Multi-turn debate with Catfish monitoring, 4) Summary aggregation, 5) Termination, 6) Moderator final decision
- **Design tradeoffs**: Catfish placement (Moderator-only vs. Team-only vs. both) yields best accuracy but increases API calls and latency; tone intensity must balance dissent strength against discussion derailment
- **Failure signatures**: Moderator overrides Catfish critique, two consecutive failed Catfish interventions, high silent rates (>60%)
- **First 3 experiments**: 1) Replicate Table 1 silent rate analysis with and without Catfish, 2) Ablate Catfish placement on intermediate MedQA, 3) Test tone calibration comparing neutral vs. strategic tones

## Open Questions the Paper Calls Out

- **Question**: How can multi-agent coordination be optimized to reduce inference-time overhead while preserving reasoning depth? Basis: Conclusion states intent to investigate efficient coordination strategies. Why unresolved: Current framework is computationally expensive with no optimization strategies evaluated.

- **Question**: What mechanisms can prevent the Moderator from overriding valid Catfish Agent critiques? Basis: Figure 9 documents failure case where Moderator adheres to original answer despite valid Catfish critique. Why unresolved: Paper demonstrates failure but offers no intervention to improve Moderator receptivity.

- **Question**: How should boundaries between tone calibration levels be optimally determined? Basis: Section 4.2 defines three tones without formal method for threshold determination. Why unresolved: Tone selection mechanism is qualitative with no sensitivity analysis.

## Limitations
- Moderator's complexity classifier effectiveness is not validated against ground truth case difficulty
- Tone calibration mechanisms lack direct comparators in literature and rely on heuristic thresholds
- Silent agreement claim relies on relative comparisons rather than absolute benchmarks across all clinical tasks

## Confidence

- **High**: Silent Agreement is a real phenomenon in multi-agent LLM clinical reasoning (supported by Table 1)
- **Medium**: Complexity-aware and tone-calibrated interventions improve accuracy and reduce silent agreement (supported by ablation studies but dependent on unvalidated classifier and heuristic tone rules)
- **Low**: Catfish Agent's free-roaming role in advanced cases meaningfully improves outcomes beyond simpler interventions (mechanism plausibility but limited direct evidence)

## Next Checks

1. Validate the Moderator's complexity classifier against held-out expert-labeled difficulty dataset to ensure appropriate Catfish autonomy calibration
2. Conduct controlled ablation study comparing neutral vs. calibrated dissent tones on held-out subset to quantify impact of tone modulation
3. Test framework's robustness by introducing adversarial cases designed to trigger silent agreement, measuring whether Catfish interventions consistently prevent premature consensus