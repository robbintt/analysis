---
ver: rpa2
title: 'Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably
  detect hate speech in reader comments of German online newspapers?'
arxiv_id: '2501.01256'
source_url: https://arxiv.org/abs/2501.01256
tags:
- speech
- hate
- dataset
- perspective
- hocon34k
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compared GPT-4o, Perspective API, and Moderation API
  for detecting hate speech in German online newspaper comments. Using the HOCON34k
  dataset, GPT-4o outperformed both APIs and exceeded the BERT-based baseline by ~5
  percentage points (S-score).
---

# Digital Guardians: Can GPT-4, Perspective API, and Moderation API reliably detect hate speech in reader comments of German online newspapers?

## Quick Facts
- arXiv ID: 2501.01256
- Source URL: https://arxiv.org/abs/2501.01256
- Authors: Manuel Weber; Moritz Huber; Maximilian Auch; Alexander Döschl; Max-Emanuel Keller; Peter Mandl
- Reference count: 11
- One-line primary result: GPT-4o outperforms both Perspective API and Moderation API for German hate speech detection, achieving ~5 percentage points higher S-score than BERT baseline.

## Executive Summary
This study evaluates three automated approaches—GPT-4o, Perspective API, and Moderation API—for detecting hate speech in German online newspaper comments using the HOCON34k dataset. GPT-4o, using few-shot prompting with the dataset's specific hate speech definition, significantly outperforms both API-based systems and a BERT baseline fine-tuned on the same data. The Moderation API performs consistently well, while Perspective API struggles with false negatives. Reannotation of the test dataset using GPT-4o as an initial reviewer improved performance metrics across all models by over 10%, highlighting the importance of annotation quality.

## Method Summary
The study compares three automated hate speech detection approaches on German online newspaper comments. GPT-4o is evaluated using zero-shot, one-shot, and few-shot prompting with the HOCON34k hate speech definition and examples. The Perspective API and Moderation API are used with their default configurations, with thresholds adjusted for binary classification. Performance is measured using the Champion-Challenger score (S), which combines normalized Matthews Correlation Coefficient and F2-score. The test set of 1,592 comments is reannotated based on GPT-4o's predictions, and models are re-evaluated on this improved dataset.

## Key Results
- GPT-4o achieves S-score of 0.8268 after reannotation, outperforming both APIs and exceeding BERT baseline by ~5 percentage points
- Few-shot prompting yields best results for GPT-4o (S=0.7059 vs baseline)
- Reannotation improved model performance by over 10% across all approaches
- Perspective API struggles with false negatives, classifying only 6/1,592 samples as hate speech at τ=0.8

## Why This Works (Mechanism)

### Mechanism 1
- Claim: In-context learning with domain-specific definitions enables GPT-4o to outperform fine-tuned baselines on German hate speech detection.
- Mechanism: GPT-4o receives the full HOCON34k hate speech guidelines (racism, xenophobia, sexism, homophobia, antisemitism, insults, threats, etc.) plus labeled examples in the prompt. The model maps input text against this definition without weight updates, leveraging its pretrained multilingual capabilities.
- Core assumption: The model's pretrained representations align sufficiently with the task-specific definition of hate speech.
- Evidence anchors:
  - [abstract] "For GPT-4o, three different promptings are used, employing a Zero-Shot, One-Shot, and Few-Shot approach. The results demonstrate that GPT-4o outperforms both the Perspective API and the Moderation API, and exceeds the HOCON34k baseline by approximately 5 percentage points."
  - [section 4.1] "One-Shot learning yielded the highest scores for Recall, F2-score, and Champion-Challenger score (S). A comparison with the baseline... shows that GPT-4o in One-Shot learning achieved an improved S score, approximately 5 percentage points higher than the baseline (S=0.7059)."
  - [corpus] Related work (Chiu et al. 2021) found Few-Shot learning improved performance by ~25% over Zero-Shot for GPT-3 on hate speech detection.
- Break condition: If the hate speech definition in the prompt diverges significantly from the model's pretrained concept of toxicity, performance degrades. Similarly, if the target language has limited representation in pretraining, in-context learning may fail to bridge the gap.

### Mechanism 2
- Claim: API-based moderation systems with fixed definitions and thresholds produce inconsistent results across languages due to definition misalignment and threshold sensitivity.
- Mechanism: Perspective API outputs probability scores (0-1) across categories (Toxicity, Identity Attack, Insult, etc.) that must be thresholded into binary decisions. Moderation API returns category flags. Neither system uses the HOCON34k definition—both rely on proprietary training data and definitions.
- Core assumption: The API's internal definition of "toxic" or "harmful" content substantially overlaps with the target hate speech definition.
- Evidence anchors:
  - [abstract] "Perspective API struggled with false negatives."
  - [section 4.1] "With τ = 0.8, only 6 out of 1,592 samples were classified as hate speech, resulting in a high number of 323 False Negatives."
  - [section 3.6] "The Perspective API model is pretrained on multilingual texts... not specifically focused on hate speech detection but rather on identifying toxic content."
  - [corpus] Nogara et al. (2023) found Perspective API misreads German as more toxic than intended, suggesting language-specific calibration issues.
- Break condition: When threshold selection is suboptimal, or when API definitions exclude legally-relevant categories (e.g., unconstitutional speech in German law), recall collapses while precision may appear artificially high.

### Mechanism 3
- Claim: Dataset annotation quality is a binding constraint on model evaluation—and by extension, on any downstream fine-tuning.
- Mechanism: The reannotation process identified 314 samples where GPT-4o disagreed with original labels. Human annotators reviewed these; 201 labels were changed. This 10%+ label correction yielded 10-17% improvements in S-scores across models.
- Core assumption: The reannotation process reduced annotation error rather than introducing new bias.
- Evidence anchors:
  - [abstract] "Reannotation of the test dataset improved model performance by over 10%."
  - [section 5.2] "Among these, 401 are labeled as hate speech (previously 329)... The best result was achieved by the One-Shot variant with S = 0.8268. This variant... experienced an increase in the S-score by 17.13% due to the reannotation."
  - [section 5.3] "The selective review may introduce a bias in favor of GPT."
  - [corpus] Weak direct evidence—corpus papers do not systematically address annotation quality impact on moderation API evaluation.
- Break condition: If reannotation is guided by model predictions (as done here), evaluation may be circular. Independent annotation without model guidance is required for unbiased assessment.

## Foundational Learning

- Concept: **Matthews Correlation Coefficient (MCC)**
  - Why needed here: The paper uses MCC as a core metric alongside F2-score. Unlike accuracy, MCC accounts for class imbalance and all four confusion matrix cells—critical when hate speech is ~20% of the dataset.
  - Quick check question: If a classifier predicts "no hate speech" for all 1,592 samples, what would the MCC be?

- Concept: **Fβ-score (specifically F2)**
  - Why needed here: The task prioritizes recall (catching hate speech) over precision (avoiding false alarms), since missed hate speech is more harmful than over-flagging. F2 gives recall twice the weight of precision.
  - Quick check question: Why would F1 be a poor choice if the cost of a false negative is 10x the cost of a false positive?

- Concept: **In-Context Learning (Zero/One/Few-Shot)**
  - Why needed here: The paper's GPT-4o experiments differ only in the number of labeled examples provided in the prompt. Understanding this distinction is essential for interpreting why One-Shot outperformed Few-Shot.
  - Quick check question: What happens to token costs and latency as you move from Zero-Shot to Few-Shot with 10 examples?

## Architecture Onboarding

- Component map:
  ```
  [HOCON34k Test Set] → [GPT-4o API / Moderation API / Perspective API]
                              ↓
                    [Threshold/Mapping Layer]
                              ↓
                    [Binary Classification]
                              ↓
                    [Evaluation: MCC, F2, S-score]
  ```

- Critical path:
  1. **Prompt engineering** for GPT-4o: Include full definition + 1-4 examples + strict output format ("Yes" or "No" only).
  2. **Threshold selection** for Perspective API: Test multiple thresholds (0.38, 0.5, 0.8); lower thresholds increase recall but reduce precision.
  3. **Reproducibility check**: Run each experiment 3×; verify non-determinism in GPT-4o and Moderation API outputs.

- Design tradeoffs:
  - **GPT-4o**: Highest S-score (0.8268 after reannotation), but paid API with non-deterministic outputs and per-token costs.
  - **Moderation API**: Free, near-deterministic, but lower S-score (0.7068) and cannot incorporate custom definitions.
  - **Perspective API**: Free, deterministic, but severe false negative problem at recommended thresholds.
  - **BERT baseline (fine-tuned)**: Deterministic, offline-capable, but requires labeled training data and underperforms by ~10% on S-score.

- Failure signatures:
  - **High precision, near-zero recall**: Threshold too high (Perspective API at τ=0.8 classified only 6/1,592 as hate speech).
  - **Non-deterministic outputs on identical inputs**: Observed in GPT-4o and Moderation API; requires multiple runs and majority voting.
  - **Error messages on dialect/gibberish**: Perspective API without explicit language setting failed on German dialects and uninterpretable strings.

- First 3 experiments:
  1. **Baseline establishment**: Run HOCON34k test set through all three systems with paper-specified configurations; verify S-scores fall within ±0.02 of reported values.
  2. **Threshold sweep for Perspective API**: Test τ ∈ {0.2, 0.3, 0.38, 0.5, 0.7, 0.8}; plot recall-precision curve; identify optimal threshold for your operational constraints.
  3. **Prompt ablation for GPT-4o**: Compare (a) definition-only, (b) definition + 1 example, (c) definition + 4 examples, (d) definition + 4 examples + explicit "think step-by-step" instruction; measure impact on S-score and token cost.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does incorporating contextual information, such as preceding comments or the related article text, significantly improve hate speech detection accuracy compared to analyzing comments in isolation?
  - Basis in paper: [explicit] The authors state in the conclusion that "Future research should focus on incorporating contextual information into hate speech detection models, as expressions often depend on previous comments or the articles."
  - Why unresolved: The current study analyzed text samples strictly in isolation, ignoring context flags present in the dataset.
  - What evidence would resolve it: An experiment evaluating GPT-4o and API performance on the same dataset when prompted with full conversational context versus isolated text.

- **Open Question 2**: Does the GPT-4o-guided reannotation strategy introduce a circular dependency or confirmation bias that artificially inflates GPT-4o's reported performance metrics?
  - Basis in paper: [inferred] The authors acknowledge in Section 5.3 that because the reannotation process only reviewed samples GPT identified as misclassified, this "may introduce a bias in favor of GPT."
  - Why unresolved: While human annotators made final decisions, the selective review mechanism may have systematically favored corrections aligned with GPT-4o's initial predictions.
  - What evidence would resolve it: A blind reannotation of a random control sample of the dataset, including samples GPT-4o initially classified correctly, to verify if error rates differ significantly from the GPT-flagged subset.

- **Open Question 3**: Can specialized detection models trained for specific newspaper sections (e.g., sports vs. politics) outperform general-purpose Large Language Models like GPT-4o in those specific domains?
  - Basis in paper: [explicit] The conclusion suggests that "Specialized models for different sections of online newspapers, like sports or politics, could further improve detection accuracy."
  - Why unresolved: The current study evaluated general models on a heterogeneous dataset without distinguishing between topical domains or fine-tuning for specific sections.
  - What evidence would resolve it: A comparative analysis where BERT-based models are fine-tuned on section-specific subsets of HOCON34k and benchmarked against general GPT-4o prompts.

## Limitations
- Reannotation process guided by GPT-4o predictions may introduce circular bias and artificially inflate performance metrics
- Specific prompt examples for one-shot and few-shot conditions not fully specified, requiring approximation
- Dataset focused on German newspaper comments limits generalizability to other domains, languages, or contexts

## Confidence

- **High confidence**: GPT-4o outperforms both APIs and BERT baseline on HOCON34k test set; Perspective API struggles with false negatives; dataset reannotation improved performance metrics; Moderation API shows consistent but lower performance than GPT-4o
- **Medium confidence**: Generalization to other hate speech definitions or languages; optimal threshold selection for Perspective API across operational contexts; long-term stability of GPT-4o performance
- **Low confidence**: Reannotation process didn't introduce significant bias; exact impact of prompt engineering variations; performance on non-newspaper German content

## Next Checks

1. **Independent reannotation**: Have human annotators without model exposure re-label a random 200-sample subset from the original test set, then compare label stability and model performance on this independently annotated set.

2. **Cross-dataset validation**: Evaluate GPT-4o and APIs on the GermEval 2018 hate speech dataset and a non-newspaper German corpus to test generalization beyond the HOCON34k domain.

3. **Threshold sensitivity analysis**: Systematically vary Perspective API thresholds (0.1 to 0.9) and plot precision-recall curves, identifying operational thresholds that balance false positive and false negative costs for different use cases.