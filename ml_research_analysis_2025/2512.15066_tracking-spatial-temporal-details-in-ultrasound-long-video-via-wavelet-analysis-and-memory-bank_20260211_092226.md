---
ver: rpa2
title: Tracking spatial temporal details in ultrasound long video via wavelet analysis
  and memory bank
arxiv_id: '2512.15066'
source_url: https://arxiv.org/abs/2512.15066
tags:
- segmentation
- video
- ultrasound
- feature
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents MWNet, a memory bank- and wavelet-based network
  for segmentation of ultrasound long videos. The method addresses challenges in ultrasound
  video segmentation such as low contrast, noisy backgrounds, and small object losses.
---

# Tracking spatial temporal details in ultrasound long video via wavelet analysis and memory bank

## Quick Facts
- arXiv ID: 2512.15066
- Source URL: https://arxiv.org/abs/2512.15066
- Authors: Chenxiao Zhang; Runshi Zhang; Junchen Wang
- Reference count: 40
- MWNet achieves state-of-the-art performance on ultrasound video segmentation with significant improvements for small thyroid nodule detection

## Executive Summary
This paper presents MWNet, a memory bank- and wavelet-based network for segmentation of ultrasound long videos. The method addresses challenges in ultrasound video segmentation such as low contrast, noisy backgrounds, and small object losses. MWNet employs a memory-based wavelet convolution backbone to extract multiscale spatial and temporal features, a long short-term memory bank to model long-range dependencies, and a high frequency-aware feature fusion module to emphasize fine-grained details. The approach is evaluated on four ultrasound video datasets (two thyroid nodule, one thyroid gland, and one heart dataset) and demonstrates significant improvements over state-of-the-art methods in segmentation metrics, particularly for small thyroid nodules.

## Method Summary
MWNet integrates wavelet decomposition with memory-based processing to handle the unique challenges of ultrasound video segmentation. The architecture uses wavelet transforms to separate spatial and temporal information across multiple scales, with a memory bank that stores and updates feature representations over time. The high-frequency-aware feature fusion module combines multiscale features while preserving fine details. The system processes video sequences by maintaining temporal coherence through the memory mechanism while addressing ultrasound-specific issues like speckle noise and low contrast through wavelet-based feature extraction.

## Key Results
- Outperforms state-of-the-art methods on four ultrasound video datasets
- Demonstrates significant improvements in segmentation accuracy for small thyroid nodules
- Shows effective handling of low contrast and noisy ultrasound backgrounds
- Achieves better temporal consistency in long video sequences

## Why This Works (Mechanism)
The wavelet-based approach effectively separates spatial and temporal information across multiple scales, allowing the network to capture both global context and fine details simultaneously. The memory bank mechanism enables long-range temporal modeling by storing and updating feature representations, which is crucial for maintaining consistency in long video sequences. The high-frequency-aware feature fusion specifically targets the preservation of fine-grained details that are often lost in standard convolutional approaches, addressing the challenge of small object segmentation in ultrasound imagery.

## Foundational Learning

**Wavelet Decomposition**
- Why needed: Separates spatial and temporal information across scales, handling ultrasound's multi-scale nature
- Quick check: Verify that wavelet coefficients capture both high and low frequency components appropriately

**Memory Bank Mechanism**
- Why needed: Maintains temporal consistency and stores long-range dependencies in video sequences
- Quick check: Ensure memory updates properly balance new information with historical context

**Feature Fusion at Multiple Scales**
- Why needed: Combines information from different scales while preserving important details
- Quick check: Confirm that high-frequency details are not lost during fusion operations

## Architecture Onboarding

**Component Map:**
Wavelet Decomposition -> Memory Bank -> Feature Fusion -> Segmentation Head

**Critical Path:**
The critical path involves wavelet decomposition feeding into the memory bank, which then provides temporal context to the feature fusion module before final segmentation. The memory update mechanism is particularly crucial as it determines how temporal information flows through the network.

**Design Tradeoffs:**
The memory bank size directly impacts both temporal modeling capability and computational cost. Larger memory banks can store more historical information but increase memory requirements and computational overhead. The wavelet decomposition level affects the balance between spatial and temporal resolution, with deeper decompositions capturing more detail but increasing computational complexity.

**Failure Signatures:**
- Poor segmentation at frame boundaries where memory updates are less reliable
- Loss of fine details when wavelet decomposition parameters are not properly tuned
- Temporal inconsistency when memory bank size is insufficient for the video length

**3 First Experiments to Run:**
1. Test memory bank ablation by varying memory size on short vs. long video sequences
2. Evaluate wavelet decomposition level impact on segmentation accuracy and speed
3. Compare high-frequency feature preservation with and without the dedicated fusion module

## Open Questions the Paper Calls Out
None

## Limitations
- Limited validation beyond thyroid nodule and cardiac ultrasound applications
- Computational complexity may impact real-time clinical deployment
- Generalizability to different ultrasound imaging protocols and equipment remains uncertain

## Confidence

**High Confidence:** The technical implementation of wavelet decomposition and memory bank integration is well-documented and reproducible. The segmentation performance improvements over baseline methods are statistically significant across the evaluated datasets.

**Medium Confidence:** The claim of "significant improvements" for small thyroid nodule segmentation requires further validation across larger and more diverse datasets. The specific architectural choices (e.g., memory bank size, wavelet decomposition levels) may need optimization for different clinical scenarios.

**Low Confidence:** The assertion that MWNet addresses "all major challenges" in ultrasound video segmentation may be overstated, as factors such as severe artifacts, extreme patient movement, or varying imaging depths were not extensively evaluated.

## Next Checks
1. Cross-Modality Validation: Test MWNet on ultrasound datasets from different anatomical regions and clinical applications to assess generalization beyond thyroid and cardiac imaging.

2. Computational Efficiency Analysis: Conduct thorough benchmarking of inference speed and memory requirements across different hardware configurations to evaluate clinical deployment feasibility.

3. Longitudinal Stability Assessment: Evaluate segmentation consistency across extended video sequences (10+ minutes) to verify the memory bank's effectiveness in maintaining temporal coherence over very long durations.