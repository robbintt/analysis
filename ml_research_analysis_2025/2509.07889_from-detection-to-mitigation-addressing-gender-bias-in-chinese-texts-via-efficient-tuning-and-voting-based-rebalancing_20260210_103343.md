---
ver: rpa2
title: 'From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via
  Efficient Tuning and Voting-Based Rebalancing'
arxiv_id: '2509.07889'
source_url: https://arxiv.org/abs/2509.07889
tags:
- bias
- gender
- classification
- text
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for detecting, classifying, and mitigating
  gender bias in Chinese texts using large language models. The approach employs LoRA-based
  fine-tuning for efficient adaptation to bias detection, constructs balanced training
  sets to address class imbalance, and uses majority voting across multiple expert
  models to enhance classification performance.
---

# From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing

## Quick Facts
- arXiv ID: 2509.07889
- Source URL: https://arxiv.org/abs/2509.07889
- Reference count: 40
- Key outcome: The method achieved an average score of 47.90%, ranking fourth in the NLPCC-2025 Shared Task 7 competition

## Executive Summary
This paper presents a comprehensive approach for detecting, classifying, and mitigating gender bias in Chinese texts using large language models. The authors employ LoRA-based fine-tuning for efficient adaptation to bias detection, construct balanced training sets to address class imbalance, and use majority voting across multiple expert models to enhance classification performance. A multi-temperature sampling mechanism is introduced to improve the diversity of bias-mitigated outputs. The method demonstrates competitive performance in the NLPCC-2025 shared task, achieving strong recall in detection while acknowledging precision trade-offs.

## Method Summary
The authors propose a three-stage approach using the Qwen2.5-7B-Instruct model with LoRA fine-tuning. First, they address class imbalance by splitting the 21,418 unbiased samples into five subsets and combining each with all 4,172 biased samples to train five expert models, plus a sixth expert trained on the full dataset. Second, they employ majority voting (>3/6 agreement) across these experts for robust classification. Third, for mitigation, they apply multi-temperature sampling (0.01, 0.1, 0.3) to generate diverse debiased outputs. The system is evaluated on the CORGI-PM dataset across three subtasks: binary detection, multi-label classification (AC, DI, ANB), and bias mitigation through text rewriting.

## Key Results
- Detection achieved 0.990 Recall but only 0.566 Precision, indicating aggressive bias catching with high false positive rates
- Classification F1 scores: AC (0.878), DI (0.779), ANB (0.833), with balanced accuracy of 0.871
- Mitigation performance showed minimal variance across temperatures (0.394 vs 0.392), suggesting limited effectiveness of the temperature mechanism
- Overall system achieved 47.90% average score, ranking fourth in the competition

## Why This Works (Mechanism)

### Mechanism 1: Low-Rank Adaptation (LoRA) for Efficient Knowledge Injection
- **Claim:** Applying Low-Rank Adaptation (LoRA) to a base Large Language Model (LLM) allows efficient acquisition of gender-bias detection capabilities without full parameter updates.
- **Mechanism:** By freezing the pre-trained weights of the Qwen2.5-7B model and injecting trainable low-rank decomposition matrices, the model adapts its attention mechanisms to recognize subtle bias patterns in Chinese text using significantly fewer trainable parameters.
- **Core assumption:** The linguistic features of gender bias reside in a low-dimensional subspace that can be captured via rank-decomposition updates, rather than requiring full-rank model retraining.
- **Evidence anchors:** [abstract] "efficiently adapt to the bias detection task via Low-Rank Adaptation (LoRA)." [section 2.3] "LoRA works by keeping the original model weights frozen and introducing trainable low-rank decomposition matrices... enabling efficient adaptation to new tasks with limited data."

### Mechanism 2: Variance Reduction via Class-Balanced Expert Ensembles
- **Claim:** Aggregating predictions from multiple models trained on differently balanced data subsets reduces the variance associated with minority class (biased text) detection.
- **Mechanism:** The unbiased majority class (21,418 samples) is split into subsets and combined with the full biased minority class (4,172 samples) to train six distinct "expert" models. A majority voting strategy (>3/6 agreement) smooths out individual model idiosyncrasies and overfitting to specific data slices.
- **Core assumption:** Errors among the individually trained experts are sufficiently uncorrelated that voting cancels out noise while reinforcing the true signal.
- **Evidence anchors:** [abstract] "construct a more balanced training set... employ a majority voting strategy that integrates outputs from multiple expert models." [section 3.4] "This strategy effectively mitigates overfitting to specific training features by individual experts, and enhances the generalization capability."

### Mechanism 3: Stylistic Diversity via Temperature Scaling
- **Claim:** Sampling generation outputs at varying temperatures allows the model to explore a broader solution space for rewriting biased text, increasing the likelihood of finding a high-quality mitigation.
- **Mechanism:** By adjusting the softmax temperature parameter during inference, the model balances between deterministic rewriting (low temperature) and creative stylistic variation (higher temperature), attempting to capture diverse expressions of the same debiased concept.
- **Core assumption:** The quality of bias mitigation is positively correlated with the diversity of the generated candidates, and the selected temperature range contains the optimal generation strategy.
- **Evidence anchors:** [abstract] "design a multi-temperature sampling mechanism to capture potential variations in bias expression styles." [section 4.2] "for subtask 3, the temperature values range over {0.01, 0.1, 0.3}."

## Foundational Learning

- **Concept: Class Imbalance in Text Classification**
  - **Why needed here:** The dataset has a ~1:5 ratio of biased to unbiased sentences. Without understanding how imbalance skews model probabilities toward the majority class, the voting strategy rationale is unclear.
  - **Quick check question:** If you trained on the raw data without resampling, what would likely happen to the model's Recall score for the "Biased" class?

- **Concept: Parameter-Efficient Fine-Tuning (PEFT)**
  - **Why needed here:** The authors use LoRA to adapt a 7B parameter model. Understanding PEFT is necessary to grasp how they achieved adaptation with "minimal computational overhead" compared to full fine-tuning.
  - **Quick check question:** In LoRA, which weights are updated during backpropagation: the frozen pre-trained weights or the injected low-rank matrices?

- **Concept: Ensemble Learning (Majority Voting)**
  - **Why needed here:** The classification performance relies on a "six-expert voting system." You must understand how bagging/boosting principles apply here to reduce variance.
  - **Quick check question:** Why is it critical that the six experts are trained on *differently* restructured datasets rather than identical copies of the data?

## Architecture Onboarding

- **Component map:** Chinese sentence -> Data splitter (divides 21k unbiased samples into 5 subsets) -> 6 parallel Qwen2.5-7B-Instruct + LoRA adapters (Expert A...N) -> Logits/Labels -> Hard Majority Vote (>=4/6 or >3/6) for classification; Single Expert -> Multi-Temperature Sampling -> Rewritten Sentence for mitigation

- **Critical path:** The **Data Recombination** step (Section 3.3) is the most critical design choice. Creating the 1:1 biased/unbalanced subsets is what enables the individual experts to learn minority features before the voting aggregation.

- **Design tradeoffs:**
  - **Recall vs. Precision:** Table 3 shows the system achieved 0.990 Recall but only 0.566 Precision in detection. The architecture is tuned heavily toward "catching" bias (high recall) at the cost of flagging innocent text (false positives).
  - **Complexity vs. Performance:** Maintaining 6 fine-tuned models increases inference latency and deployment complexity by ~6x compared to a single model.

- **Failure signatures:**
  - **Over-flagging:** The extremely low precision (0.566) suggests the model triggers "false" on valid inputs; likely due to the aggressive 1:1 balancing forcing the model to see bias everywhere.
  - **Static Mitigation:** Table 4 shows almost no variance in Task 3 scores across temperatures (0.394 vs 0.392), suggesting the multi-temperature mechanism may not have effectively altered the output distribution.

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Train a single LoRA adapter on the *original* imbalanced dataset (without resampling) to quantify the exact performance gain from the voting/rebalancing strategy.
  2. **Ablation on Voting Threshold:** Test the system with strict unanimity (6/6) vs. simple majority (4/6) to visualize the precision/recall trade-off curve explicitly.
  3. **Mitigation Temperature Sweep:** Run Task 3 inference on a temperature grid [0.0, 0.5, 1.0] with human evaluation, since the automatic metrics (BLEU/ROUGE) showed insensitivity to the current range.

## Open Questions the Paper Calls Out

- **Open Question 1:** How do loss re-weighting, oversampling, and data augmentation strategies specifically improve the recognition of long-tail bias categories compared to the current ratio-based rebalancing?
  - **Basis in paper:** [explicit] The authors state in Section 4.4 that their current approach "considers only the ratio between biased and non-biased data" and they "plan to address this by incorporating loss re-weighting, oversampling, and data augmentation strategies."
  - **Why unresolved:** The current method addresses global imbalance but fails to account for the skew within the specific biased categories (AC, DI, ANB), limiting the model's upper-bound performance on minority classes.
  - **What evidence would resolve it:** Experimental results showing improved F1 scores for minority bias types when these specific techniques are applied versus the current majority voting method.

- **Open Question 2:** Can an automatic temperature selection mechanism or multi-pass generation with reranking outperform the current fixed multi-temperature sampling approach for bias mitigation?
  - **Basis in paper:** [explicit] Section 4.4 notes that due to constraints, only three temperature values were explored, and the authors "plan to... implement automatic temperature selection or multi-pass generation with reranking."
  - **Why unresolved:** The current search space for generation diversity was limited and manual, potentially missing the optimal configuration for stylistic variation and semantic preservation.
  - **What evidence would resolve it:** Ablation studies comparing the proposed automatic selection methods against the static temperature settings using BLEU, BERTScore, and MAUVE metrics.

- **Open Question 3:** Does dedicated hyperparameter tuning for the mitigation subtask yield better results than reusing the configuration optimized for the detection subtask?
  - **Basis in paper:** [explicit] The authors acknowledge in Section 4.4 that for subtask 3, they "retain the same training configuration used in subtask 1 without further tuning for text generation quality."
  - **Why unresolved:** Parameters optimized for binary or multi-class classification (subtasks 1 & 2) may be suboptimal for the generative requirements of text rewriting (subtask 3).
  - **What evidence would resolve it:** Performance comparison of models tuned specifically for generation tasks against the current baselines on the mitigation leaderboard.

## Limitations

- **LoRA Hyperparameter Specification:** Critical LoRA parameters (rank, alpha, target modules) are not specified, significantly impacting reproducibility and model capacity.
- **Mitigation Output Validation:** Multi-temperature sampling mechanism shows negligible performance variance across temperature settings, suggesting limited effectiveness of the approach.
- **Data Balancing Strategy:** While addressing binary imbalance, the method does not account for class imbalance among the three bias categories (AC, DI, ANB), potentially limiting minority class performance.

## Confidence

- **High Confidence:** The core methodology (LoRA fine-tuning, balanced dataset construction, majority voting ensemble) is clearly described and technically sound.
- **Medium Confidence:** Performance claims are supported by competition results but lack ablation studies demonstrating individual component contributions.
- **Low Confidence:** The effectiveness of the multi-temperature mitigation strategy is questionable given minimal performance differences across temperature settings.

## Next Checks

1. **Ablation Study:** Train a baseline LoRA model on the original imbalanced dataset without resampling to quantify the exact performance gain from the voting/rebalancing strategy.

2. **Temperature Range Optimization:** Conduct a systematic temperature sweep (e.g., [0.0, 0.5, 1.0]) with human evaluation of generated outputs, since automatic metrics (BLEU/ROUGE) showed insensitivity to the current narrow range.

3. **Class-Wise Performance Analysis:** Examine per-class F1 scores for AC, DI, and ANB bias types to identify whether the balancing strategy creates new imbalances and to quantify performance on minority bias categories.