---
ver: rpa2
title: Evaluating Multimodal Large Language Models on Core Music Perception Tasks
arxiv_id: '2510.22455'
source_url: https://arxiv.org/abs/2510.22455
tags:
- audio
- music
- chord
- midi
- pitches
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper benchmarks three multimodal large language models\u2014\
  Gemini 2.5 Pro, Gemini 2.5 Flash, and Qwen2.5-Omni\u2014on three core music perception\
  \ tasks: syncopation scoring, transposition detection, and chord quality identification.\
  \ It isolates perception from reasoning by comparing audio versus MIDI inputs, zero-\
  \ versus few-shot settings, and three prompting strategies: standalone, chain-of-thought,\
  \ and LogicLM (a neuro-symbolic framework that enforces structured reasoning)."
---

# Evaluating Multimodal Large Language Models on Core Music Perception Tasks

## Quick Facts
- arXiv ID: 2510.22455
- Source URL: https://arxiv.org/abs/2510.22455
- Reference count: 40
- Primary result: Current multimodal LLMs excel at reasoning over symbolic music (MIDI) but fail on audio perception, with LogicLM providing structured reasoning only when symbolic transcription is accurate.

## Executive Summary
This paper benchmarks three multimodal large language models—Gemini 2.5 Pro, Gemini 2.5 Flash, and Qwen2.5-Omni—on three core music perception tasks: syncopation scoring, transposition detection, and chord quality identification. It isolates perception from reasoning by comparing audio versus MIDI inputs, zero- versus few-shot settings, and three prompting strategies: standalone, chain-of-thought, and LogicLM (a neuro-symbolic framework that enforces structured reasoning). Across tasks, MIDI inputs yielded near-ceiling performance for Gemini models, while audio inputs caused sharp accuracy drops, revealing a fundamental perception bottleneck. Few-shot examples and prompting strategies offered minimal gains, with LogicLM helping only when symbolic input was reliable. These findings show that current models can reason over musical symbols but do not yet "listen" reliably from audio, underscoring the need for stronger audio front-ends and uncertainty-aware symbolic solvers to build truly audio-native music systems.

## Method Summary
The study evaluates multimodal LLMs on music perception tasks using three prompting strategies: standalone, chain-of-thought, and LogicLM. LogicLM requires models to output structured symbolic schemas (e.g., `rhythm(id, [onsets])`) that are parsed and evaluated by a deterministic external solver (`solver.py`). Experiments compare performance on audio versus MIDI inputs, with tasks drawn from The MUSE Benchmark. The factorial design crosses modality (audio/MIDI), prompting strategy, and shot setting (zero/few-shot). Few-shot examples add worked examples (2-4 per task), and LogicLM includes a self-refinement loop for schema corrections.

## Key Results
- MIDI input yielded near-ceiling scores for Gemini models, while audio reduced accuracy across tasks, highlighting perception from waveform as the primary bottleneck.
- Neither chain-of-thought nor LogicLM compensated for upstream hearing errors in audio mode.
- LogicLM exposed heuristic-based reasoning failures (e.g., matching melody length instead of interval contour) when transcription was imperfect.

## Why This Works (Mechanism)

### Mechanism 1
LogicLM-style neuro-symbolic prompting separates perceptual formulation from symbolic reasoning. The model acts as a "Perceptual Formulator," generating structured symbolic schemas (e.g., `rhythm(id, [onsets])` or `melody(id, [pitches])`). An external, deterministic solver then parses and evaluates this schema. This isolates the model's ability to transcribe/symbolize from its ability to reason. The model can reliably translate its internal state into a strict symbolic format; the solver's logic is a correct and complete implementation of the task rules.

### Mechanism 2
A significant performance gap between MIDI and audio inputs points to the audio encoder as the primary bottleneck for music perception in current multimodal LLMs. When provided with symbolic MIDI data (text), models perform near ceiling, demonstrating strong reasoning. When the same information is presented as audio, performance drops sharply. This suggests the failure occurs during the initial audio-to-representation stage before symbolic reasoning can be applied. The symbolic (MIDI/text) and audio representations are functionally equivalent in the information required for the task, isolating the perceptual conversion step as the key variable.

### Mechanism 3
Few-shot learning and Chain-of-Thought (CoT) prompting offer minimal gains when a model's performance is perceptually bounded. CoT and few-shot prompting are designed to improve reasoning. If model failure is due to a fundamental inability to correctly perceive the input (e.g., identifying onsets in audio), providing reasoning examples cannot correct the upstream error. The model's reasoning capabilities are not the limiting factor; its perceptual encoding is.

## Foundational Learning

- **Symbolic Music Representation**: Understanding what models must produce (e.g., pitch lists, onset grids) for external solvers to work. The entire LogicLM framework depends on this intermediate representation.
  - Quick check: Can you manually create the symbolic schema for a two-note melody with MIDI pitches 60 and 64? (Answer: `melody(id, [60, 64])`)

- **Deterministic Solver / Neuro-symbolic AI**: This is the core of the LogicLM methodology. You must understand that the "reasoning" is offloaded to a rigid, rule-based program (`solver.py`), making it transparent and verifiable.
  - Quick check: If a solver's rule says "identify as a match if interval sequences are identical," and the model transcribes two different melodies identically, will the solver catch the error? (Answer: No. The solver will see identical sequences and classify it as a match. The failure is in perception, not the solver.)

- **Audio Encoder / Perceptual Front-end**: The paper identifies this as the primary point of failure in current multimodal LLMs. Understanding this component is key to interpreting the experimental results.
  - Quick check: Why would a model succeed on a task with MIDI input but fail on the same task with audio input? (Answer: The model's audio encoder fails to reliably convert the raw waveform into an internal representation that captures the necessary musical information like pitch and rhythm.)

## Architecture Onboarding

- **Component map**: Input (audio/MIDI) -> Multimodal LLM (Perceptual Formulator) -> Structured Symbolic Schema -> External Solver (solver.py) -> Final Answer

- **Critical path**:
  1. An input (audio file or MIDI text) is provided to the LLM with a system prompt defining the task.
  2. The LLM attempts to generate a response in the strict symbolic schema (e.g., `rhythm(...)`).
  3. If the schema is malformed, a self-refinement loop is triggered, giving the LLM its output and the error message to try again.
  4. If valid, the `solver.py` script receives the schema, executes its logic, and outputs the final categorical answer (e.g., "A. Major").

- **Design tradeoffs**:
  - **Transparency vs. Robustness**: LogicLM makes reasoning perfectly transparent (in the solver) but shifts all brittleness to the perceptual formulation stage. Any error in transcription leads to failure.
  - **Generality vs. Specificity**: The solver must be hand-crafted for each specific task type, limiting the system's generality compared to an end-to-end model.

- **Failure signatures**:
  - **Perceptual Transcription Error**: The LLM's symbolic schema does not match the ground truth (e.g., lists wrong MIDI pitches). The solver runs correctly on bad data.
  - **Schema Adherence Failure**: The LLM outputs free-form text instead of the required schema. The regex parser in the solver fails.
  - **Degenerate Reasoning Strategy**: The model uses a flawed heuristic (e.g., matching melody length instead of interval contour) which is faithfully executed by the solver.

- **First 3 experiments**:
  1. **A/B Test Audio Encoder**: Compare performance using a high-quality, separate Automatic Music Transcription (AMT) model as a pre-processor to generate MIDI, versus using the LLM's native audio encoding. This tests if the bottleneck is indeed the encoder.
  2. **Self-Refinement Ablation**: Run the LogicLM condition with and without the self-refinement loop enabled. This measures the value of the correction mechanism.
  3. **Solver vs. End-to-End CoT**: Directly compare LogicLM's performance against a standard Chain-of-Thought prompting on the same tasks using *only MIDI inputs*. This isolates the benefit of the neuro-symbolic approach when perception is controlled for.

## Open Questions the Paper Calls Out

- **Can propagation of uncertainty mechanisms enable neuro-symbolic music systems to maintain reasoning accuracy when transcribing noisy audio inputs?**
  - Basis: The authors conclude that progress "will depend on stronger audio front-ends and propagation of uncertainty into downstream solvers."
  - Unresolved: Current LogicLM implementations treat model-generated symbolic schemas as deterministic inputs for solvers, causing the reasoning layer to collapse entirely when the audio front-end produces small transcription errors.
  - Resolution evidence: Demonstrating a system where confidence scores from audio transcription modulate the symbolic solver's constraints or outputs, resulting in higher accuracy on the audio condition.

- **To what extent do current multimodal LLMs rely on superficial heuristics (e.g., sequence length) rather than structural intervallic analysis for music perception tasks?**
  - Basis: The paper notes that "apparent successes can reflect superficial heuristics rather than genuine listening," specifically observing that Gemini Pro often preserved sequence length while failing to capture intervallic structure in transposition tasks.
  - Unresolved: While LogicLM exposed these failures by enforcing consistency, the prevalence of this heuristic strategy across different architectures and musical tasks remains unknown.
  - Resolution evidence: Ablation studies controlling for surface features (like note count) in melodic similarity tasks to see if performance drops when heuristics are made invalid.

- **How can neuro-symbolic frameworks be adapted to handle the expressive nuances (e.g., micro-timing, articulation) stripped by symbolic formats like MIDI?**
  - Basis: The authors state that symbolic formats strip away features making music meaningful and that claims of understanding require handling audio directly, yet they show current audio parsing is the primary bottleneck.
  - Unresolved: The study demonstrates a clear trade-off: MIDI allows perfect reasoning but lacks expressivity; Audio contains expressivity but breaks the reasoning pipeline.
  - Resolution evidence: An evaluation using audio stimuli where expressive timing variations are critical to the task (e.g., swing detection), showing that the model processes these from audio rather than reducing them to quantized symbols.

## Limitations
- The study uses a specific subset of tasks from The MUSE Benchmark, limiting scope to core perception tasks.
- Few-shot examples are described but not fully detailed in the paper, preventing exact replication.
- The self-refinement mechanism's effectiveness isn't systematically quantified across conditions.

## Confidence

- **High confidence**: The central finding that models achieve near-ceiling performance on symbolic MIDI inputs but fail on audio is supported by direct experimental evidence and clear performance gaps.
- **Medium confidence**: Claims about LogicLM's effectiveness and prompting strategies offering minimal gains are mechanistically sound but lack full error analysis and detailed implementation specifics.
- **Medium confidence**: Claims about heuristic-based reasoning failures are observed but not systematically quantified across the full task set.

## Next Checks

1. **Audio Encoder Ablation**: Compare LogicLM performance using a high-quality separate Automatic Music Transcription (AMT) model as pre-processor versus native audio encoding to isolate whether the bottleneck is truly the encoder or downstream processing.

2. **Symbolic Solver Completeness Audit**: Conduct a systematic review of the solver.py implementations to verify they capture all musically relevant edge cases and don't introduce artificial constraints that mask model capabilities.

3. **Long-Context Audio Testing**: Evaluate whether performance degradation in audio mode correlates with input length by testing models on shorter audio clips (e.g., single measures) versus full musical phrases to distinguish perceptual from context-window limitations.