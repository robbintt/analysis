---
ver: rpa2
title: Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems
arxiv_id: '2503.03505'
source_url: https://arxiv.org/abs/2503.03505
tags:
- agents
- task
- arxiv
- agent
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a parallelized planning-acting framework for
  efficient LLM-based multi-agent systems in dynamic environments like Minecraft.
  It introduces a dual-thread architecture with interruptible execution, decoupling
  LLM reasoning from action execution to enable concurrent planning and acting.
---

# Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems

## Quick Facts
- arXiv ID: 2503.03505
- Source URL: https://arxiv.org/abs/2503.03505
- Authors: Yaoru Li, Shunyu Liu, Tongya Zheng, Mingli Song
- Reference count: 24
- Primary result: Dual-thread architecture with interruptible execution enables concurrent planning and acting, achieving 83.3%-100% success rates in Minecraft boss combat while reducing completion times.

## Executive Summary
This paper introduces a parallelized planning-acting framework for LLM-based multi-agent systems in dynamic environments. The core innovation is a dual-thread architecture that decouples LLM reasoning from action execution, enabling concurrent planning and acting with interruptible execution. A centralized memory system supports real-time information sharing among agents, while a comprehensive skill library automates task execution through recursive decomposition. The framework demonstrates significant improvements in efficiency and coordination compared to serialized approaches, particularly in challenging Minecraft scenarios including boss combat, resource collection, and adversarial PvP.

## Method Summary
The framework implements a dual-thread architecture where a planning thread continuously queries an LLM for the next action based on centralized memory observations, while an acting thread executes skills from a single-slot action buffer with interruptible capability. The centralized memory stores observations, chat logs, and action history, enabling real-time information sharing. A skill library with 790+ Minecraft items provides automated task execution through recursive DAG-based dependency resolution. The system uses priority-based interruption to handle dynamic changes, with the LLM outputting explicit interrupt flags and reasons.

## Key Results
- Success rates of 83.3%-100% across boss combat tasks (Elder Guardian, Wither, Ender Dragon)
- Reduced completion times in resource collection compared to serialized frameworks
- Effective coordination in 10-agent PvP scenarios with multimodal observations
- Significant latency reduction through concurrent planning-acting architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoupling LLM reasoning from action execution via dual-thread architecture reduces system latency and enables real-time responsiveness in dynamic environments.
- Mechanism: A planning thread (LLM-driven) writes the next action into a single-slot action buffer, while an acting thread reads from this buffer and executes skills. If the buffer contains a new action with higher priority, an interrupt signal halts the current skill and restarts with the new action. Latency reduction occurs because planning and acting overlap: Tp ≈ T_plan^(1) + Σ max(T_plan^(k), T_act^(k-1)) rather than serialized Σ(T_plan + T_act).
- Core assumption: Skill execution time (T_act) generally exceeds LLM planning latency (T_plan), allowing planning to "hide" behind action execution.
- Evidence anchors:
  - [abstract] "dual-thread architecture with interruptible execution to enable concurrent planning and acting"
  - [section 2.1] Equations 3-5 formalize the latency advantage; the action buffer is a single-slot queue that discards stale plans.
  - [corpus] DynTaskMAS (2503.07675) similarly proposes dynamic task graphs for asynchronous/parallel LLM-MAS, suggesting convergent evidence that parallelization aids efficiency, though no direct comparison is provided.
- Break condition: If T_act < T_plan consistently (e.g., very fast atomic actions with slow LLMs), the latency benefit diminishes; interrupt overhead may then dominate.

### Mechanism 2
- Claim: A centralized memory system with continuous polling enables agents to operate on up-to-date shared information, improving coordination without waiting for action completion.
- Mechanism: Memory M^t = {O^t, C^t, A^t} updates at each timestep, overwriting stale observations. Passive communication runs concurrently with acting (LLM posts observations to chat logs after planning). Active communication allows agents to emit chat messages as skills. Both feed the centralized store, which the planning thread queries before each decision.
- Core assumption: Agents benefit from teammates' observations even when those observations are not synchronized to action boundaries; stale information is worse than potentially noisy real-time updates.
- Evidence anchors:
  - [abstract] "centralized memory system supports real-time information sharing among agents"
  - [section 2.2] Describes observation records, chat logs, action history; passive and active communication modes.
  - [corpus] No direct corpus paper evaluates centralized vs. distributed memory for LLM-MAS; this mechanism lacks external validation.
- Break condition: In high-noise environments where observations are frequently erroneous, continuous updates may propagate misinformation faster than agents can verify.

### Mechanism 3
- Claim: Recursive task decomposition via a DAG-based skill library automates prerequisite resolution, enabling agents to complete complex resource collection with minimal manual intervention.
- Mechanism: Each skill queries a dependency graph G = (V, E, φ) where vertices encode (item type, quantity, operation) and edges encode prerequisites. Function Ψ(v_i) recursively expands tasks until inventory I(t_i) ≥ required quantity. Skills can invoke other skills (e.g., obtainItem → mineItem → craftItem), passing parameters down the DAG.
- Core assumption: The skill library's dependency graph is complete and correct for the target domain; missing or incorrect edges cause task failure.
- Evidence anchors:
  - [abstract] "skill library enables automated task execution through recursive decomposition"
  - [section 2.3 + Table 1] With RTDM, agents complete 5 tasks at 100% SR; without it, 3 tasks fail entirely. Section claims support for 790+ Minecraft items.
  - [corpus] No corpus paper explicitly evaluates recursive skill libraries; validation is domain-specific to Minecraft.
- Break condition: If prerequisite chains are long or involve uncraftable/unsourced items, recursion depth or missing edges cause infinite loops or failure.

## Foundational Learning

- Concept: Producer-consumer concurrency with bounded buffers
  - Why needed here: The action buffer is a single-slot queue; understanding non-blocking writes (overwrite-if-full) vs. blocking semantics is essential to avoid race conditions.
  - Quick check question: What happens if the acting thread reads from an empty buffer?

- Concept: Directed acyclic graphs for task dependencies
  - Why needed here: The skill library uses DAGs to represent prerequisites; topological ordering determines execution sequence.
  - Quick check question: How does the system detect and handle cyclic dependencies?

- Concept: LLM inference latency and throughput tradeoffs
  - Why needed here: Latency analysis assumes T_plan < T_act; knowing your LLM's typical response time determines whether parallelization yields gains.
  - Quick check question: If your LLM averages 5s per request and your fastest skill takes 2s, does the parallelized framework still reduce total latency?

## Architecture Onboarding

- Component map: Planning Thread -> Centralized Memory -> Acting Thread -> Skill Library -> Action Buffer
- Critical path:
  1. Agent polls centralized memory for latest observations/chat.
  2. LLM generates next action JSON (skill + params + interrupt flag + reason).
  3. Action written to single-slot buffer (overwrites if occupied).
  4. Acting thread reads buffer; if interrupt=true and priority higher, current skill is halted.
  5. Skill executes; if recursive, calls sub-skills until base case (inventory satisfied).

- Design tradeoffs:
  - Single-slot buffer ensures most recent plan but discards potentially useful queued actions.
  - Interruptible execution improves responsiveness but may cause thrashing if LLM frequently changes priorities.
  - Centralized memory simplifies coordination but is a single point of failure and potential bottleneck.

- Failure signatures:
  - Agents repeat the same action indefinitely → likely interrupt flag never set or priority logic broken.
  - Task hangs at "obtainItem" → missing prerequisite edge in skill DAG.
  - Chat logs grow unbounded → memory not pruned; performance degrades over long sessions.

- First 3 experiments:
  1. **Latency microbenchmark**: Measure T_plan and T_act for 10 single-agent tasks; verify Tp < Ts per equations 3-5.
  2. **Ablate centralized memory**: Run boss combat with memory disabled (agents rely only on local observations); compare success rate to full system.
  3. **Stress-test interrupts**: In PvP, artificially inflate interrupt frequency (force LLM to set interrupt=true every cycle); observe whether performance degrades due to action thrashing.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the continuous LLM request mechanism be optimized to reduce computational costs while maintaining real-time responsiveness in resource-constrained environments?
- Basis in paper: [explicit] The authors state in Section 6 that the "continuous LLM request design leads to higher computational costs, which may limit scalability."
- Why unresolved: The current architecture prioritizes concurrency by continuously polling the LLM, creating a trade-off between reactivity and resource efficiency that has not been balanced.
- What evidence would resolve it: The introduction of an event-driven or adaptive planning trigger that reduces API calls without significantly degrading task completion time or success rates in dynamic scenarios.

### Open Question 2
- Question: What verification strategies can effectively mitigate LLM hallucinations that currently cause irrational action interruptions?
- Basis in paper: [explicit] Section 6 notes that "LLM hallucinations occasionally result in irrational action interruptions, affecting the reliability of agent behavior."
- Why unresolved: The current interruption mechanism relies entirely on the LLM's judgment of action priority (Eq. 2), lacking an external validation layer to filter out nonsensical interrupts.
- What evidence would resolve it: A validation module that successfully filters hallucinatory interrupts, resulting in higher task efficiency or stability metrics compared to the baseline framework.

### Open Question 3
- Question: How can multimodal fusion be improved to leverage complementary information better than the current reliance on Vision-Language Models (VLMs) alone?
- Basis in paper: [explicit] Section 6 highlights that the current fusion method relies solely on VLMs, "potentially failing to fully exploit the complementarity of multimodal information."
- Why unresolved: The ablation study (Section 3.4) showed that replacing text-based observations with VLMs actually lowered observation accuracy and increased latency.
- What evidence would resolve it: A hybrid fusion architecture that combines text-based state data with visual inputs to outperform the current text-only and VLM-only baselines in accuracy and latency.

## Limitations

- Computational overhead from continuous LLM requests may limit scalability in resource-constrained environments.
- LLM hallucinations can cause irrational action interruptions, affecting reliability without external verification.
- Domain-specific skill library dependencies make generalization to non-Minecraft environments challenging.

## Confidence

- High confidence: The dual-thread architecture's basic latency reduction mechanism (Mechanism 1) - this follows established producer-consumer patterns and the mathematical formulation is explicit.
- Medium confidence: The centralized memory system's coordination benefits (Mechanism 2) - while the mechanism is clearly specified, external validation across different domains is lacking.
- Medium confidence: The skill library's task automation capability (Mechanism 3) - validated within Minecraft but not generalized to other domains or tested against alternative task decomposition approaches.

## Next Checks

1. **Domain generalization test**: Implement the framework in a non-Minecraft environment (e.g., robotics simulation or web navigation) to assess whether the dual-thread architecture and centralized memory provide similar efficiency gains outside the original domain.

2. **Memory architecture ablation**: Compare centralized vs. distributed memory systems in the same multi-agent scenarios to quantify the coordination benefits claimed and identify scalability bottlenecks as agent count increases.

3. **Skill library completeness validation**: Systematically test the dependency graph coverage by attempting to complete tasks requiring increasingly rare or complex item combinations, documenting where the DAG fails to resolve prerequisites and measuring the impact on overall task success rates.