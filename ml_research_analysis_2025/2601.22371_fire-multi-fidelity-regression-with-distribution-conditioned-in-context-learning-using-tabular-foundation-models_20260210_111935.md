---
ver: rpa2
title: 'FIRE: Multi-fidelity Regression with Distribution-conditioned In-context Learning
  using Tabular Foundation Models'
arxiv_id: '2601.22371'
source_url: https://arxiv.org/abs/2601.22371
tags:
- fire
- learning
- regression
- multi-fidelity
- residual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces FIRE, a training-free multi-fidelity regression\
  \ framework that leverages pre-trained tabular foundation models (TFMs) for zero-shot\
  \ in-context learning. The key innovation is using distributional conditioning\u2014\
  incorporating predictive mean, variance, and quantiles from a low-fidelity model\u2014\
  to guide a high-fidelity residual correction model, enabling robust transfer in\
  \ extremely imbalanced data regimes (2\u20135% high-fidelity data)."
---

# FIRE: Multi-fidelity Regression with Distribution-conditioned In-context Learning using Tabular Foundation Models

## Quick Facts
- **arXiv ID:** 2601.22371
- **Source URL:** https://arxiv.org/abs/2601.22371
- **Reference count:** 40
- **Primary result:** FIRE achieves highest Elo rating and lowest average rank for accuracy (NRMSE) and uncertainty quantification (NLL) across 31 multi-fidelity regression tasks, even with only 2-5% high-fidelity data

## Executive Summary
This paper introduces FIRE, a training-free multi-fidelity regression framework that leverages pre-trained tabular foundation models (TFMs) for zero-shot in-context learning. The key innovation is using distributional conditioning—incorporating predictive mean, variance, and quantiles from a low-fidelity model—to guide a high-fidelity residual correction model, enabling robust transfer in extremely imbalanced data regimes (2–5% high-fidelity data). FIRE is benchmarked against seven state-of-the-art methods across 31 tasks spanning synthetic functions, hyperparameter optimization, and physics-based simulations. Results show FIRE achieves the highest Elo rating and lowest average rank for accuracy (NRMSE) and uncertainty quantification (NLL), with runtime advantages over deep learning baselines and robustness to non-nested data splits. The distributional conditioning strategy is shown to be crucial, improving both accuracy and uncertainty calibration. Limitations include context window constraints and dependence on TFM quality. Overall, FIRE demonstrates superior performance in scarce high-fidelity data scenarios, highlighting the value of pre-trained priors in multi-fidelity regression.

## Method Summary
FIRE implements a three-stage framework using frozen tabular foundation models for zero-shot multi-fidelity regression. First, a low-fidelity base model (f_θ) is fitted via in-context learning on aggregated lower-fidelity data with fidelity-index tokens. Second, a high-fidelity residual model (δ_φ) is conditioned on distributional summaries (mean, variance, quantiles) extracted from the base model and trained on augmented residual data. Finally, predictions combine both models' outputs additively, with uncertainty propagated through variance summation. The method uses TabPFN v2.5 as the underlying TFM and requires no task-specific training, making it particularly effective when high-fidelity data is extremely scarce (2-5% of low-fidelity data).

## Key Results
- FIRE achieves highest Elo rating across 31 benchmark tasks spanning synthetic functions, hyperparameter optimization, and physics-based simulations
- Distributional conditioning (mean + variance + quantiles) outperforms mean-only conditioning by ~250 Elo points on average
- FIRE maintains superior performance even with only 2% high-fidelity data, demonstrating extreme data efficiency
- Runtime advantages over deep learning baselines while maintaining competitive accuracy with GP methods

## Why This Works (Mechanism)

### Mechanism 1: Distribution-Conditioned Residual Transfer
Conditioning the high-fidelity residual correction on low-fidelity predictive distributions (mean, variance, quantiles) reduces prediction error compared to mean-only conditioning, particularly in heteroscedastic regimes. FIRE augments the residual model's input with z_aug = [x, μ_θ(x), σ²_θ(x), {q^τ_θ(x)}] where quantiles capture distributional shape (skewness, tails). Theorem 7.2 proves Bayes risk monotonicity: R(Z_aug) ≤ R(Z_mean) under squared error loss. Core assumption: Cross-fidelity residuals exhibit input-dependent variability that correlates with low-fidelity epistemic uncertainty (Assumption 7.3: Var[δ(x)] = g(σ²_θ(x)) for non-constant g).

### Mechanism 2: Zero-Shot Bayesian Inference via Frozen TFM Priors
Pre-trained tabular foundation models (TFMs) approximate Bayesian posterior inference without task-specific training, enabling efficient transfer under extreme HF data scarcity (2-5%). TabPFN is trained on millions of synthetic structural causal models to minimize KL divergence to Bayesian posterior. At inference, q_θ(y|x, D_context) ≈ π(y|x, D) serves as amortized posterior. The frozen prior acts as a regularizer against overfitting. Core assumption: The task prior Π from pre-training has sufficient support to cover the multi-fidelity problem distribution (Assumption 7.1, Theorem C.1).

### Mechanism 3: Bi-Level Fidelity Aggregation with Token Encoding
Aggregating T-1 lower fidelities into a single LF dataset with fidelity-index token improves computational efficiency without sacrificing accuracy, avoiding O(T) surrogate overhead. D_LF = ∪{([x^(t)_i, t], y^(t)_i)} treats fidelity as categorical feature. Single TFM learns shared representation across noise regimes. Only two surrogates needed: base model f_θ and residual model δ_φ. Core assumption: The TFM's attention mechanism can implicitly model fidelity-dependent noise patterns through the token embedding.

## Foundational Learning

- **In-Context Learning (ICL) with Transformers**: FIRE relies on TFMs performing regression by conditioning on context examples in a single forward pass—understanding that predictions emerge from attention over (x, y) pairs, not weight updates. Quick check: Given a 100-example context set, can you explain why a transformer makes predictions without gradient descent?

- **Multi-Fidelity Autoregressive Formulation**: FIRE inherits f^(t)(x) = ρ_t · f^(t-1)(x) + δ_t(x) structure but implements it implicitly via residual learning. Understanding this decomposition is prerequisite to grasping why distributional conditioning matters. Quick check: In Kennedy-O'Hagan AR(1), what does δ(x) represent and why might its variance depend on location?

- **Heteroscedastic vs. Homoscedastic Error**: The paper's central claim is that LF uncertainty varies spatially, and ignoring this (mean-only conditioning) causes misspecification. Appendix C.5 formalizes this as variance-residual coupling. Quick check: If residual variance is constant across x, does Theorem 7.2 still predict gains from variance conditioning?

## Architecture Onboarding

- **Component map:** f_θ (LF base model) -> Feature augmenter -> δ_φ (HF residual model) -> Uncertainty combiner
- **Critical path:** 1) Fit f_θ on D_LF via in-context forward pass (no training), 2) Extract μ_θ(x_HF), σ²_θ(x_HF), quantiles, 3) Compute residuals r = y_HF - μ_θ(x_HF), 4) Construct augmented features z_aug, 5) Fit δ_φ on D_aug via in-context forward pass, 6) At test: predict μ_θ(x*), build z*_aug, predict residual, sum predictions
- **Design tradeoffs:** Context window vs. LF data size (TabPFN limited to ~10K context rows), Quantile count K (paper uses K=9, saturation around this value), Post-hoc ensembling (PHE) (~50 Elo gain but 10× inference cost)
- **Failure signatures:** Exploded variance (check TFM version), No improvement over GP baselines (verify z_aug includes all distributional features), Runtime >GP on small data (TFM inference has O(N²) attention overhead)
- **First 3 experiments:** 1) Sanity check on Forrester (d=1, 2-fidelity) with N_LF=200, N_HF=10 (5%), 2) Ablation: mean-only vs. full distribution on Currin benchmark, 3) Stress test at 2% HF ratio on Car dataset (d=23) with N_HF=10

## Open Questions the Paper Calls Out
- **Active Learning Extension:** The authors state, "Looking forward, we plan to expand FIRE to multi-fidelity optimization setting..." The current framework is evaluated as a static regressor; optimization requires an acquisition function mechanism and repeated re-inference, which may amplify inference latency constraints.
- **Context Window Scaling:** The authors list "context window constraints" as a primary limitation and note inference latency is "bounded by the quadratic complexity of transformer attention." The current experiments use fixed N_LF sizes; performance degradation on massive datasets where the context must be truncated or summarized is unstated.
- **Out-of-Distribution Robustness:** Assumption 7.1 posits the TFM approximates the posterior provided the task prior has "sufficient support," and the text notes dependence on "quality of the pre-trained TFM." It is unclear how robust the method is to out-of-distribution physical systems or tabular structures not well-represented by the synthetic causal models used in pre-training.

## Limitations
- **Context Window Constraints:** FIRE's dependence on TFMs with limited context (TabPFNv2.5: ~10K rows) creates scalability bottlenecks for high-dimensional problems with large LF datasets
- **TFM Quality Dependency:** FIRE's zero-shot success hinges on the pre-trained TFM capturing Bayesian posteriors accurately; if synthetic prior distribution doesn't sufficiently cover target task family, residual corrections may amplify rather than correct LF errors
- **Non-nested Data Assumptions:** While FIRE claims robustness to non-nested splits, the theoretical framework relies on exchangeability assumptions that could be violated when LF and HF domains barely overlap

## Confidence
- **High Confidence:** FIRE's superiority over baselines (Elo ranking, NRMSE, NLL metrics) is well-supported by extensive benchmarking across 31 tasks with 10 trials × 5-fold CV
- **Medium Confidence:** The distributional conditioning mechanism's theoretical justification (Theorem 7.2) assumes heteroscedastic residuals; empirical validation is strong but relies on observed correlations rather than controlled variance regimes
- **Medium Confidence:** Runtime advantages over deep learning baselines are demonstrated but depend on specific hardware and TFM implementation details not fully specified

## Next Checks
1. **Context Window Stress Test:** Reproduce FIRE on Car dataset (d=23) with N_LF=500 and varying subsampling rates. Compare Elo rating degradation vs. full context to quantify scalability limits.
2. **Non-nestedness Boundary:** Create synthetic benchmarks where LF and HF input domains have minimal overlap (e.g., disjoint support). Measure FIRE's accuracy drop vs. GP baselines to identify the non-nestedness threshold where distributional conditioning fails.
3. **TFM Prior Coverage:** Design benchmark tasks deliberately outside TabPFN's synthetic prior support (e.g., discontinuous functions, non-smooth gradients). Compare FIRE's performance degradation to confirm the theoretical assumption that pre-training support must cover task distribution.