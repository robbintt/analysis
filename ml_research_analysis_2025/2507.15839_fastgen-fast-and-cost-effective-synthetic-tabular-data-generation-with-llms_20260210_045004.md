---
ver: rpa2
title: 'FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs'
arxiv_id: '2507.15839'
source_url: https://arxiv.org/abs/2507.15839
tags:
- data
- generation
- fields
- fastgen
- direct-gen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FASTGEN presents a cost-effective approach for generating large-scale
  synthetic tabular data by leveraging LLMs to infer underlying data distributions
  rather than generating records individually. By categorizing fields into numerical,
  categorical, and free-text types, the method produces reusable sampling scripts
  that enable efficient dataset generation without continuous LLM inference.
---

# FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs

## Quick Facts
- arXiv ID: 2507.15839
- Source URL: https://arxiv.org/abs/2507.15839
- Authors: Anh Nguyen; Sam Schafft; Nicholas Hale; John Alfaro
- Reference count: 22
- Primary result: Produces more diverse and realistic synthetic tabular data than direct LLM generation while reducing computational overhead and inference costs by 6× to 60×

## Executive Summary
FASTGEN introduces a novel approach for generating large-scale synthetic tabular data by leveraging LLMs to infer underlying data distributions rather than generating records individually. The method categorizes fields into numerical, categorical, and free-text types, then produces reusable sampling scripts that enable efficient dataset generation without continuous LLM inference. Experimental results demonstrate that FASTGEN achieves superior diversity metrics while substantially reducing computational overhead and inference costs compared to traditional direct generation methods.

## Method Summary
FASTGEN operates through a four-stage pipeline: preprocessing to enrich metadata descriptions, field classification into numerical/categorical/free-text categories, script generation where LLMs output field-specific Python sampling code based on inferred distributions, and validation with execution combining validated field scripts into a unified dataset generator. The approach uses LLaMA-70B with configuration k=10, n=3, s=100. Rather than generating individual records through continuous LLM inference, FASTGEN produces reusable scripts that encode distribution parameters, enabling efficient generation of arbitrarily large datasets with reduced token consumption.

## Key Results
- Vocabulary metrics: FASTGEN achieved scores up to 4.14 compared to 4.00 for direct generation
- Inter-Sample N-gram Frequency: FASTGEN achieved 0.316 versus 0.778 for direct generation
- KL divergence for numerical fields: FASTGEN achieved 0.98 compared to 2.94 for direct generation
- Token efficiency: Requires approximately 6× fewer tokens for 1,000 records and 60× fewer tokens for 10,000 records compared to direct generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generating reusable sampling scripts instead of individual records reduces LLM inference calls by orders of magnitude while maintaining data quality.
- Mechanism: The LLM performs a one-time analysis of field metadata to infer distributions, then outputs executable Python code that encodes sampling logic. This script can generate arbitrarily large datasets without further LLM involvement.
- Core assumption: LLMs can accurately infer statistical distributions from metadata descriptions alone.
- Evidence anchors: [abstract] "By automatically classifying fields... the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale"; [section 3.3] "The LLM is instructed to estimate the distribution type and parameters... and generate a script that samples data accordingly."

### Mechanism 2
- Claim: Field type categorization (numerical/categorical/free-text) enables type-appropriate generation strategies that outperform uniform direct generation.
- Mechanism: The LLM first classifies each field, then applies specialized approaches: parametric distributions for numerical, probability mass functions for categorical, and creative text generation for free-text.
- Core assumption: Three categories sufficiently capture the distributional characteristics of tabular data fields.
- Evidence anchors: [section 5.1.2] "Most of the fields from direct-gen have ISNF scores ranging from 0.6 to 0.9, indicating inflexibility and bias toward popular values"; [corpus] Related work focuses on diffusion-based methods rather than script extraction.

### Mechanism 3
- Claim: Script-based generation captures distributional diversity better than direct LLM generation because scripts encode the full distribution shape rather than samples from it.
- Mechanism: Scripts encode distribution parameters, allowing the sampling process to produce values across the full support including rare categories and tail values.
- Core assumption: The script execution environment provides sufficient randomness and sampling fidelity.
- Evidence anchors: [section 5.3.1] "Both FASTGEN and gt achieve the highest vocabulary in four ID columns that require strictly uniform random generation"; [corpus] Indirect support from related work noting LLM direct generation exhibits limitations in diversity.

## Foundational Learning

- **Concept**: Statistical distribution inference from metadata
  - Why needed here: FASTGEN's core innovation depends on LLMs inferring distribution types from textual descriptions alone
  - Quick check question: Given only the description "Age of the individual, continuous," what additional information would be needed to specify a sampling distribution?

- **Concept**: KL divergence and Optimal Transport for distribution comparison
  - Why needed here: The paper uses these metrics to evaluate how closely generated data matches ground truth
  - Quick check question: Why might Optimal Transport be preferred over KL divergence when comparing categorical distributions where labels differ superficially?

- **Concept**: Token economics in LLM inference
  - Why needed here: The efficiency claims (6× to 60× token reduction) are the primary practical justification
  - Quick check question: If generating 10,000 records requires 800,000 tokens via direct generation, what is the approximate cost at $0.71 per million output tokens?

## Architecture Onboarding

- **Component map**: Preprocessing module → Classification module → Script generation module → Validation layer → Unified execution
- **Critical path**: Metadata input → field classification → distribution inference → script generation → validation → execution
- **Design tradeoffs**:
  - Speed vs. cross-field relationships: Current implementation generates fields independently, sacrificing realism for simplicity and speed
  - Script simplicity vs. distribution fidelity: Simple parametric forms may miss complex multimodal distributions
  - Automation vs. control: Full automation may produce unexpected results; paper recommends exposing LLM reasoning for human modification
- **Failure signatures**:
  - Non-executable scripts after n retries → empty/placeholder field values
  - Complex numerical distributions → higher KL divergence than direct-gen
  - Rare categories dropped in categorical fields → reduced fidelity for long-tail values
- **First 3 experiments**:
  1. Reproduce the Travel Customers vocabulary comparison with a local LLM to validate diversity improvement
  2. Test the preprocessing enrichment step by comparing script quality with original vs. enriched metadata
  3. Inject a deliberate cross-field dependency and measure the realism gap to quantify the acknowledged limitation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can cross-field dependencies be efficiently captured and preserved in distribution-based synthetic tabular data generation?
- Basis in paper: [explicit] Section 6.3 states "A drawback of our current solution is the independent generation of fields, which overlooks relationships across columns"
- Why unresolved: Building a complete dependency map for all fields becomes exponentially costly
- What evidence would resolve it: A method that identifies key primary fields and their dependent secondary fields, with evaluation showing preserved correlations

### Open Question 2
- Question: How can rare but semantically important categories be preserved when LLMs infer categorical distributions from metadata?
- Basis in paper: [explicit] Section 3.3 notes "any rare yet semantically important categories may be dropped in the process, reducing the fidelity"
- Why unresolved: The top-k category approach prioritizes frequent values, and token limitations prevent exhaustive enumeration
- What evidence would resolve it: A modified sampling strategy that retains rare categories, measured through recall of ground-truth rare values

### Open Question 3
- Question: What techniques can improve distribution inference for numerical fields with complex, multi-modal, or non-parametric distributions?
- Basis in paper: [inferred] Section 5.2.1 reports FASTGEN underperformed direct-gen on Hazard Mitigation due to complex distributions
- Why unresolved: FASTGEN relies on simple parametric distributions, limiting expressiveness for complex real-world distributions
- What evidence would resolve it: Hybrid approaches combining parametric and non-parametric methods, evaluated on datasets with known complex numerical distributions

## Limitations
- Cross-field dependencies are not preserved, reducing realism when logical relationships exist between fields
- Complex numerical distributions may be poorly approximated by simple parametric forms, leading to higher KL divergence than direct generation
- The method requires successful script generation without repeated failures; error rates and retry patterns are not quantified

## Confidence

- **High Confidence**: Token efficiency calculations and cost projections (straightforward arithmetic based on stated generation costs)
- **Medium Confidence**: Diversity improvements (vocabulary and ISNF metrics show consistent patterns, but underlying LLM capabilities may vary)
- **Low Confidence**: Distributional fidelity for numerical fields (mixed performance on complex distributions, with some cases showing worse KL divergence than direct generation)

## Next Checks

1. **Distribution Inference Robustness**: Test FASTGEN on datasets with known complex multimodal distributions to quantify how often parametric assumptions fail versus direct generation

2. **Cross-field Dependency Impact**: Measure the practical impact of dropped cross-field relationships by evaluating a downstream ML model trained on FASTGEN data versus ground truth data

3. **Prompt Sensitivity Analysis**: Vary the enrichment sample size (s parameter) and retry count (n parameter) to establish the sensitivity of script generation quality to these configuration choices