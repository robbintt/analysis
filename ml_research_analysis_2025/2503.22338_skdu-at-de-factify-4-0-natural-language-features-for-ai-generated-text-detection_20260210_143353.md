---
ver: rpa2
title: 'SKDU at De-Factify 4.0: Natural Language Features for AI-Generated Text-Detection'
arxiv_id: '2503.22338'
source_url: https://arxiv.org/abs/2503.22338
tags:
- text
- features
- ai-generated
- detection
- nela
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of distinguishing AI-generated
  text from human-written content, a critical need given the increasing sophistication
  of large language models. The authors propose a pipelined approach that combines
  prompt-based rewriting features (RAIDAR) and content-based features (NELA) with
  machine learning classifiers.
---

# SKDU at De-Factify 4.0: Natural Language Features for AI-Generated Text-Detection

## Quick Facts
- **arXiv ID:** 2503.22338
- **Source URL:** https://arxiv.org/abs/2503.22338
- **Reference count:** 23
- **Key outcome:** NELA features significantly outperform RAIDAR features for AI-generated text detection, achieving F1=0.9979 (binary) and 0.8489 (multi-class) with XGBoost on Defactify4.0 dataset.

## Executive Summary
This work addresses the challenge of distinguishing AI-generated text from human-written content, a critical need given the increasing sophistication of large language models. The authors propose a pipelined approach that combines prompt-based rewriting features (RAIDAR) and content-based features (NELA) with machine learning classifiers. Through comprehensive experiments on the Defactify4.0 dataset, they find that NELA features significantly outperform RAIDAR features in both binary and multi-class classification tasks, achieving an F1-score of 0.9979 for binary classification and 0.8489 for multi-class classification when using XGBoost. The study highlights the importance of selecting high-quality, discriminative features and demonstrates that combining RAIDAR and NELA features provides minimal improvement due to redundancy. XGBoost emerged as the most effective classifier for handling the rich feature sets.

## Method Summary
The method employs a pipeline approach with feature extraction followed by machine learning classification. Feature extraction involves two parallel paths: RAIDAR uses an LLM (Llama-3.1-8B) to rewrite text via 7 prompts and extracts statistics from rewriting patterns, while NELA toolkit extracts 87 attributes across stylistic, complexity, and psychological dimensions. The classification phase uses XGBoost with default parameters, though SVC and Random Forest are also tested for comparison. The approach is evaluated on the De-Factify 4.0 dataset containing approximately 50,000 training samples, 10,000 validation samples, and 10,000 test samples across binary (human vs AI) and multi-class (human plus 6 LLM types) classification tasks.

## Key Results
- NELA features achieved F1=0.9979 for binary classification (Task A) versus RAIDAR's 0.9652
- For multi-class classification (Task B), NELA achieved F1=0.8489 versus RAIDAR's 0.4488
- XGBoost outperformed other classifiers, handling complex feature interactions more effectively
- Combining RAIDAR and NELA features provided minimal improvement (F1=0.9968 for Task A, 0.8430 for Task B)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Content-based features (NELA) capture discriminative linguistic and stylistic patterns that separate human from AI-generated text more effectively than rewriting-based features.
- Mechanism: NELA extracts 87 attributes across stylistic (stopwords, punctuation, quotes), complexity (type-token ratio, syntax tree depth), and psychological (LIWC, sentiment) dimensions. These features encode measurable differences in how humans vs. LLMs construct text.
- Core assumption: AI-generated text exhibits systematic, quantifiable deviations from human writing in these specific dimensions that persist across generation contexts.
- Evidence anchors:
  - [abstract] "NELA features significantly outperform RAIDAR features in both tasks, demonstrating their ability to capture nuanced linguistic, stylistic, and content-based differences."
  - [Section 4, Results] With XGBoost, NELA achieved F1=0.9979 (Task A) vs RAIDAR's 0.9652; Task B showed 27-32% relative improvement.
  - [corpus] Related work (arXiv:2505.11550) corroborates multifaceted feature approaches for AI detection, though direct NELA comparisons are limited.
- Break condition: If LLMs are specifically trained to match human distributions across these 87 attributes, discriminative power would likely degrade.

### Mechanism 2
- Claim: XGBoost's gradient boosting with tree-based ensembles effectively handles heterogeneous feature sets with complex nonlinear interactions.
- Mechanism: XGBoost iteratively builds decision trees that correct residual errors, capturing feature interactions without requiring manual specification. This suits the mix of continuous (readability scores) and discrete (word counts) features from NELA.
- Core assumption: The discriminative signal lies in nonlinear combinations of features rather than linear separability.
- Evidence anchors:
  - [Section 4] "XGBoost emerged as the best-performing classifier due to its ability to handle complex feature sets... Its ability to model complex, nonlinear relationships between features allowed it to better exploit the rich information embedded in NELA features."
  - [Section 4] "SVC struggled with the high-dimensional feature space, while Random Forest exhibited reduced performance due to its tendency to overfit on redundant features."
  - [corpus] Limited direct comparison; neighboring papers focus on transformer-based approaches rather than gradient boosting.
- Break condition: If feature dimensions exceed effective training data significantly, or if signals are primarily linear, simpler models may match performance.

### Mechanism 3
- Claim: Combining RAIDAR and NELA features yields minimal improvement because RAIDAR introduces redundancy rather than complementary signal.
- Mechanism: RAIDAR uses an LLM (Llama-3.1-8B) to rewrite text via 7 prompts, then extracts features from rewriting statistics. The paper suggests these features overlap with information already captured by NELA's stylistic analysis.
- Core assumption: RAIDAR's rewriting-based discriminability is subsumed by NELA's direct stylistic measurements.
- Evidence anchors:
  - [abstract] "Combining RAIDAR and NELA features provided minimal improvement, highlighting the redundancy introduced by less discriminative features."
  - [Section 4, Results Table 2] RAIDAR+NELA with XGBoost: F1=0.9968 (Task A), 0.8430 (Task B)—slightly lower than NELA alone.
  - [corpus] No corpus papers directly validate the redundancy claim; this appears to be a dataset-specific finding.
- Break condition: If RAIDAR captures temporal or semantic consistency signals absent from NELA, combination could help in other domains.

## Foundational Learning

- Concept: Stylometric feature extraction
  - Why needed here: NELA's 87 features span multiple stylistic dimensions; understanding what each captures (lexical, syntactic, psychological) is essential for interpreting model decisions and debugging failures.
  - Quick check question: Can you explain why type-token ratio and syntax tree depth might differentiate AI from human text?

- Concept: Gradient boosting for tabular classification
  - Why needed here: XGBoost is the recommended classifier; understanding its handling of mixed feature types, regularization, and overfitting resistance informs hyperparameter choices.
  - Quick check question: Why might XGBoost outperform Random Forest when redundant features are present?

- Concept: Multi-class attribution vs binary detection
  - Why needed here: Task B (identifying specific LLM) is substantially harder (F1=0.85 vs 0.99); confusion matrix shows cross-model misclassification patterns.
  - Quick check question: What does the Gemma-Qwen confusion (91 and 77 misclassifications) suggest about these models' training data?

## Architecture Onboarding

- Component map: Raw text → NELA extraction → XGBoost → Prediction (RAIDAR path optional)
- Critical path: Text → NELA extraction → XGBoost → Prediction. RAIDAR path is optional and adds computational overhead without clear benefit.
- Design tradeoffs:
  - RAIDAR requires LLM inference (computationally expensive, ~1-2 seconds per sample with Llama-3.1-8B)
  - NELA is lightweight but may miss adversarial adaptations targeting its known features
  - XGBoost with default parameters worked well; hyperparameter tuning may yield marginal gains
- Failure signatures:
  - Cross-model confusion: Gemma↔Qwen (shared training distributions suspected)
  - Mid-sized model overlap: LLaMA↔Yi mutual misclassification
  - RAIDAR underperformance on multi-class task (F1=0.44-0.57)
- First 3 experiments:
  1. Replicate NELA+XGBoost baseline on validation split; confirm F1>0.99 (Task A) and >0.84 (Task B).
  2. Ablate NELA feature categories (stylistic only, complexity only, psychological only) to identify most discriminative subset.
  3. Test generalization: train on subset of LLM classes, evaluate on held-out models to assess robustness to novel generators.

## Open Questions the Paper Calls Out

- **Question:** Can rewriting-based feature extraction methods be redesigned to provide complementary, rather than redundant, signals when combined with content-based features?
  - **Basis in paper:** [explicit] The authors state that future work could focus on "improving rewriting-based feature extraction methods to enhance their complementarity with content-based approaches."
  - **Why unresolved:** The study found that combining RAIDAR and NELA features provided minimal improvement because RAIDAR features introduced redundancy due to limited discriminatory capacity.
  - **What evidence would resolve it:** A modified feature extraction pipeline where the fusion of rewriting and content features yields a statistically significant increase in F1-score over content-based features alone.

- **Question:** Do feature representations exist that remain invariant across various LLM architectures while retaining high discriminative power?
  - **Basis in paper:** [explicit] The conclusion suggests "investigating feature representations that remain invariant across various models could also enhance robustness."
  - **Why unresolved:** The current approach shows high misclassification rates between specific model pairs (e.g., Qwen-2-72B and Gemma-2-9B), attributed to shared linguistic patterns or training data distributions.
  - **What evidence would resolve it:** Identification of a feature set that maintains consistent classification accuracy across all tested generative models without the confused overlap seen in the reported confusion matrix.

- **Question:** To what extent can meta-learning strategies improve the generalisation of detection models to unseen AI-generated text sources?
  - **Basis in paper:** [explicit] The authors propose that "meta-learning strategies can be employed to finetune detection models across different LLM architectures" to improve generalisability.
  - **Why unresolved:** The current training relies on a fixed dataset of specific models, risking overfitting to the idiosyncrasies of those generators.
  - **What evidence would resolve it:** Experiments demonstrating that a meta-learned classifier maintains high detection performance on texts generated by LLMs not included in the training distribution.

## Limitations

- The performance gains from NELA features may be specific to the Defactify4.0 dataset's particular mix of human and AI-generated texts, with RAIDAR redundancy claims based on this single dataset.
- RAIDAR's reliance on Llama-3.1-8B for rewriting introduces significant computational overhead (approximately 1-2 seconds per sample) that is not justified by the marginal performance gains observed.
- The study does not evaluate robustness against adversarial attacks or model-specific adaptations designed to evade detection, leaving open questions about real-world deployment viability.

## Confidence

- **High Confidence:** NELA features outperform RAIDAR features in both binary and multi-class classification on the Defactify4.0 dataset, with clear statistical improvements (27-32% relative gain in multi-class task).
- **Medium Confidence:** XGBoost's superior performance is dataset-dependent and may not generalize to all tabular feature sets or datasets with different noise characteristics.
- **Medium Confidence:** The redundancy claim between RAIDAR and NELA features is based on observed performance patterns rather than formal feature correlation analysis or ablation studies.

## Next Checks

1. **Feature Ablation Study:** Systematically remove subsets of NELA features (stylistic only, complexity only, psychological only) to identify which categories contribute most to discriminative power and test if similar performance can be achieved with reduced feature sets.
2. **Cross-Dataset Validation:** Evaluate the NELA+XGBoost pipeline on alternative AI-generated text detection benchmarks (e.g., GLTR, GPT-3 detection datasets) to assess generalizability beyond Defactify4.0.
3. **Adversarial Robustness Testing:** Generate or obtain AI texts specifically crafted to mimic human distributions across NELA's 87 features (e.g., by fine-tuning models on human-like stylistic patterns) and measure detection performance degradation.