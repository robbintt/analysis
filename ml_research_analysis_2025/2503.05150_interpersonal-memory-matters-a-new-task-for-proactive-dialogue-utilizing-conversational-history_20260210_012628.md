---
ver: rpa2
title: 'Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing
  Conversational History'
arxiv_id: '2503.05150'
source_url: https://arxiv.org/abs/2503.05150
tags:
- dialogue
- topic
- user
- chatbot
- proactive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Memory-aware Proactive Dialogue (MapDia),
  a new task integrating memory mechanisms into proactive dialogue systems to enable
  human-like topic transitions based on conversational history. The authors propose
  an automated data construction method and create the first Chinese Memory-aware
  Proactive Dataset (ChMapData), containing 5,453 dialogues across memorable and general
  subjects.
---

# Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History

## Quick Facts
- **arXiv ID**: 2503.05150
- **Source URL**: https://arxiv.org/abs/2503.05150
- **Reference count**: 25
- **Primary result**: Memory-aware proactive dialogue system outperforms baselines on Chinese dataset with 12.2% improvement in topic-shift ratios

## Executive Summary
This paper introduces Memory-aware Proactive Dialogue (MapDia), a novel task that integrates memory mechanisms into proactive dialogue systems to enable human-like topic transitions based on conversational history. The authors propose an automated data construction method and create the first Chinese Memory-aware Proactive Dataset (ChMapData), containing 5,453 dialogues across memorable and general subjects. They develop a RAG-based framework with three components: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting Detection and Generation. Human evaluation shows their model outperforms both a 7B Qwen baseline and GPT-4 on two test sets, achieving higher scores in engagement, overall quality, and topic achievement.

## Method Summary
The authors construct the ChMapData dataset using an automated approach that extracts memorable and general topics from existing conversational data. The proposed RAG-based framework consists of three components working in sequence: Topic Summarization extracts key information from conversational history, Topic Retrieval searches relevant memories or external knowledge, and Proactive Topic-shifting Detection and Generation determines when to shift topics and generates appropriate transitions. The framework is evaluated against strong baselines including a 7B Qwen model and GPT-4 through human evaluation metrics focusing on engagement, overall quality, and topic achievement.

## Key Results
- Human evaluation shows the proposed model outperforms 7B Qwen baseline with engagement scores of 1.18 vs 0.74
- The model achieves higher overall quality (3.23 vs 2.70) and topic achievement (0.82 vs 0.39) compared to GPT-4
- Integration testing in real dialogue system demonstrates 12.2% improvement in topic-shift ratios and 27.9% increase in conversation turns per session

## Why This Works (Mechanism)
The proposed approach works by integrating memory mechanisms into proactive dialogue systems, allowing them to reference conversational history for more natural topic transitions. The three-component RAG framework enables the system to summarize ongoing conversations, retrieve relevant memories or knowledge, and make informed decisions about when and how to shift topics. This memory-aware approach mimics human conversational patterns where speakers naturally reference past interactions and shared experiences to maintain engaging dialogue.

## Foundational Learning
- **Conversational Memory**: Understanding how past interactions influence current dialogue choices - needed to enable context-aware topic transitions
- **Topic Detection and Generation**: Identifying natural conversation pivot points and generating appropriate new topics - critical for proactive dialogue systems
- **RAG Framework**: Combining retrieval and generation for knowledge-intensive tasks - enables leveraging both memory and generation capabilities
- **Human Evaluation Metrics**: Designing subjective quality measures for dialogue systems - essential for assessing engagement and naturalness
- **Automated Data Construction**: Creating large-scale datasets without manual annotation - enables scalable development of dialogue models

## Architecture Onboarding

**Component Map**: Topic Summarization -> Topic Retrieval -> Proactive Topic-shifting Detection and Generation

**Critical Path**: The core processing flow moves from understanding the current conversation state through summarization, to accessing relevant memories via retrieval, and finally to making topic shift decisions and generating transitions.

**Design Tradeoffs**: The RAG-based approach balances between using retrieved knowledge (providing factual accuracy and consistency) and generation capabilities (enabling creativity and adaptation), though it may struggle with topics outside the memory store.

**Failure Signatures**: The system may fail when memory retrieval returns irrelevant or outdated information, when topic shift detection misidentifies appropriate transition points, or when generated topics lack coherence with the conversation flow.

**3 First Experiments**:
1. Validate individual component performance through ablation studies to isolate contributions
2. Test topic shift detection accuracy on held-out conversational data
3. Evaluate memory retrieval relevance using both automated metrics and human judgment

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on human judgment for subjective evaluation metrics may introduce rater bias and lack reproducibility across cultural contexts
- Automated data construction effectiveness depends on source data quality without detailed validation of the approach
- RAG-based framework may struggle with novel topics not present in the memory store
- Results lack statistical significance testing and clear baseline comparisons for integration testing

## Confidence

**High confidence**: The dataset construction methodology and basic three-component RAG architecture are clearly described and technically sound

**Medium confidence**: Human evaluation results showing superior performance compared to baselines, as these depend on subjective judgment and limited sample sizes

**Medium confidence**: Effectiveness of individual components as demonstrated by ablation studies, given standard methodology but lack of statistical significance testing

**Low confidence**: Generalizability of results to languages other than Chinese and different domains beyond memorable and general subjects covered

## Next Checks

1. Conduct statistical significance testing on human evaluation results across multiple rater groups to establish robust performance differences between models

2. Perform cross-linguistic validation by constructing parallel datasets in English or other languages to test generalizability

3. Implement a longitudinal study tracking user engagement and satisfaction over extended conversations (beyond single sessions) to validate real-world effectiveness of the memory-aware approach