---
ver: rpa2
title: 'Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation
  for Surgical Risk Perception in Multimodal Large Language Models'
arxiv_id: '2506.22500'
source_url: https://arxiv.org/abs/2506.22500
tags:
- entities
- conflict
- entity
- dataset
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces VS-KC, a phenomenon where multimodal large
  language models fail to detect visual safety violations in operating rooms despite
  understanding textual safety rules. To study this, the authors create OR-VSKC, a
  dataset of 34,817 synthetic images and 214 human-annotated images depicting 18 types
  of safety-violating entities in OR scenes.
---

# Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models

## Quick Facts
- arXiv ID: 2506.22500
- Source URL: https://arxiv.org/abs/2506.22500
- Reference count: 37
- Primary result: VS-KC (Visual-Semantic Knowledge Conflicts) prevalent in state-of-the-art models; fine-tuning on OR-VSKC dataset significantly improves detection of trained safety entities

## Executive Summary
This paper identifies a critical phenomenon called VS-KC (Visual-Semantic Knowledge Conflicts) in multimodal large language models (MLLMs) operating in surgical contexts. VS-KC occurs when models fail to detect visual safety violations in operating rooms despite understanding the corresponding textual safety rules. To address this gap, the authors created OR-VSKC, a comprehensive dataset containing 34,817 synthetic images and 214 human-annotated images depicting 18 types of safety-violating entities in OR scenes. The study demonstrates that fine-tuning on OR-VSKC significantly improves detection of trained entities (achieving near 100% accuracy) while revealing limitations in generalization to untrained entity types. The dataset and benchmark are released to support further research into VS-KC mitigation.

## Method Summary
The authors introduce VS-KC as a phenomenon where MLLMs fail to detect visual safety violations despite understanding textual safety rules. To study this, they developed OR-VSKC, a dataset of 34,817 synthetic images and 214 human-annotated images depicting 18 types of safety-violating entities in OR scenes. The dataset was created using a controlled data generation pipeline that simulates realistic OR environments with various safety violations. The authors then evaluated state-of-the-art MLLMs on this dataset, demonstrating the prevalence of VS-KC across models. Fine-tuning experiments showed significant improvements in detection accuracy for trained entities, though performance remained poor for untrained entity types.

## Key Results
- VS-KC is prevalent across state-of-the-art multimodal large language models when tested on OR-VSKC dataset
- Fine-tuning on OR-VSKC significantly improves detection accuracy for trained safety entities (near 100% accuracy)
- Models show poor performance on untrained entity types, indicating highly specific learned knowledge rather than generalization
- The approach generalizes to new viewpoints for trained entities but fails to transfer to semantically similar but untrained safety violations

## Why This Works (Mechanism)
VS-KC occurs because MLLMs learn visual and textual representations separately, leading to a disconnect between what the model knows about safety rules (textual understanding) and what it can actually perceive in visual scenes. The fine-tuning process works by providing paired visual-textual examples that explicitly connect safety rules with their visual manifestations, forcing the model to align these previously disconnected representations. The poor performance on untrained entities suggests that the model learns specific visual patterns rather than abstract safety concepts, indicating that current MLLMs require explicit training for each safety violation type rather than developing general safety perception capabilities.

## Foundational Learning
- Multimodal large language models (MLLMs): AI systems that process both visual and textual inputs simultaneously, needed for applications requiring understanding of both modalities like surgical safety monitoring
- Quick check: Verify the model can process both image and text inputs and generate coherent responses

- Visual-Semantic Knowledge Conflicts (VS-KC): The phenomenon where models understand safety rules textually but fail to detect corresponding visual violations, crucial for identifying gaps in MLLM safety applications
- Quick check: Test model on paired visual-textual safety scenarios to identify mismatches

- Synthetic data generation for medical contexts: Creating artificial training data to overcome privacy constraints while maintaining realistic scenarios, essential when real data is scarce or sensitive
- Quick check: Validate synthetic data realism through expert review or comparison with available real examples

- Fine-tuning vs. training from scratch: Adapting pre-trained models to specific tasks using smaller, targeted datasets rather than full training, important for efficiency and leveraging existing capabilities
- Quick check: Compare performance on target task between fine-tuned and fully trained models

- Generalization vs. memorization: The ability of models to apply learned concepts to new situations versus simply recalling specific training examples, critical for real-world deployment
- Quick check: Test model on semantically similar but untrained scenarios to assess true understanding

## Architecture Onboarding

Component map:
Synthetic Data Generator -> OR-VSKC Dataset -> MLLM Fine-tuning Pipeline -> VS-KC Detection Model

Critical path:
Synthetic data generation and human annotation -> Model evaluation on baseline VS-KC detection -> Fine-tuning on OR-VSKC -> Performance evaluation on trained and untrained entities

Design tradeoffs:
- Synthetic vs. real data: Privacy and control vs. ecological validity
- Dataset size: Comprehensive coverage of 18 entity types vs. resource constraints
- Fine-tuning approach: Targeted improvement on specific violations vs. general safety perception development

Failure signatures:
- High accuracy on trained entities but poor performance on semantically similar untrained entities
- Correct textual reasoning about safety rules but failure to identify corresponding visual violations
- Overfitting to specific visual patterns rather than learning abstract safety concepts

First experiments to run:
1. Baseline evaluation of state-of-the-art MLLMs on OR-VSKC to establish VS-KC prevalence
2. Fine-tuning experiments with varying dataset sizes to determine minimum effective training set
3. Cross-viewpoint generalization tests to assess spatial reasoning capabilities for safety violations

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Synthetic data generation introduces questions about ecological validity and real-world applicability
- The 18 safety-violating entity types may not capture the full complexity of real operating room scenarios
- Study focuses on detection accuracy without addressing potential false positive rates or clinical implications

## Confidence
- High confidence in empirical findings showing VS-KC prevalence across tested models and effectiveness of fine-tuning on OR-VSKC
- Medium confidence in generalizability to real surgical settings given synthetic nature of most training data
- Medium confidence in clinical relevance of specific entity types chosen for annotation

## Next Checks
1. Conduct a user study with surgical experts to validate the clinical relevance and prioritization of the 18 safety-violating entity types identified
2. Test model performance on real operating room images (where feasible) or on synthetic data with increased visual diversity and complexity to assess generalization
3. Evaluate the impact of false positive rates on model utility in practice, including the potential for alert fatigue in surgical teams