---
ver: rpa2
title: Differentiable Knapsack and Top-k Operators via Dynamic Programming
arxiv_id: '2601.21775'
source_url: https://arxiv.org/abs/2601.21775
tags:
- knapsack
- differentiable
- have
- dynamic
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a unified framework for differentiable Knapsack
  and Top-k operators using dynamic programming. The core idea is to regularize the
  max operators in Bellman recursions, yielding smooth relaxations that enable gradient-based
  optimization.
---

# Differentiable Knapsack and Top-k Operators via Dynamic Programming

## Quick Facts
- arXiv ID: 2601.21775
- Source URL: https://arxiv.org/abs/2601.21775
- Authors: Germain Vivier-Ardisson; Michaël E. Sander; Axel Parmentier; Mathieu Blondel
- Reference count: 40
- Key outcome: Introduces a unified framework for differentiable Knapsack and Top-k operators using dynamic programming with regularized max operators.

## Executive Summary
This paper introduces a unified framework for differentiable Knapsack and Top-k operators using dynamic programming. The core idea is to regularize the max operators in Bellman recursions, yielding smooth relaxations that enable gradient-based optimization. Key theoretical contributions include proving that Shannon entropy is the unique regularization yielding permutation-equivariant operators, and characterizing regularizers that induce sparse selections. Algorithmically, efficient parallel implementations support both deterministic and stochastic forward passes, with vector-Jacobian products for backward propagation. Experiments demonstrate superior performance over existing methods in decision-focused learning, constrained dynamic assortment RL, and discrete VAEs, with improvements in regret minimization, revenue optimization, and reconstruction quality. The framework offers a principled approach for integrating combinatorial constraints into differentiable programming pipelines.

## Method Summary
The method regularizes the max operators within Bellman dynamic programming recursions to create differentiable relaxations of Knapsack and Top-k problems. The framework uses convex regularizers (Shannon, Gini, Tsallis entropy) to smooth the max operator, enabling gradient flow through the combinatorial optimization. The approach provides both deterministic and stochastic forward passes, with exact vector-Jacobian products for efficient backpropagation. Theoretical analysis characterizes which regularizers induce permutation equivariance and sparsity properties.

## Key Results
- Shannon entropy is the unique regularizer yielding permutation-equivariant operators (Proposition 1)
- Regularizers with bounded gradients (Gini, Tsallis) enable sparse selections, while Shannon entropy produces dense outputs
- Empirical improvements in decision-focused learning, RL assortment optimization, and discrete VAE reconstruction quality
- Reduced gradient variance compared to existing methods in stochastic settings

## Why This Works (Mechanism)

### Mechanism 1: Gradient flow via Bellman recursion smoothing
Replacing the hard `max` operator in the dynamic programming recursion with a smooth regularized operator allows gradients to flow through combinatorial constraints. By substituting it with `max_Ω` (e.g., log-sum-exp or sparsemax), the value function becomes differentiable, enabling gradient-based optimization.

### Mechanism 2: Sparsity via bounded regularization gradients
Regularizers with bounded gradients enable the relaxed operator to produce sparse selections (exact 0s and 1s). If the derivative ω' of the regularizer is bounded on (0,1), the gradient mapping saturates at boundaries when the local advantage exceeds a threshold, forcing outputs to vertices of the convex hull.

### Mechanism 3: Permutation equivariance via associative smoothing
Shannon entropy is the unique regularizer that guarantees permutation-equivariant treatment of input items. This requires the smoothed `max_Ω` operator to be associative, which only Shannon entropy satisfies among convex, separable regularizers.

## Foundational Learning

- **Concept: Dynamic Programming (Bellman Equation)**
  - Why needed: The entire framework relies on mapping Knapsack/Top-k problems into a grid-based DP table where states depend on previous states.
  - Quick check: Can you write the recurrence relation for the 0/1 Knapsack problem value function V[i, c] considering item weights and capacity?

- **Concept: Fenchel Conjugates and Smooth Max Operators**
  - Why needed: The paper defines the smoothed operator via the convex conjugate (max_Ω(θ) = Ω*(θ)). Understanding that log-sum-exp corresponds to Shannon entropy and sparsemax to Gini is critical.
  - Quick check: What is the convex conjugate of negative Shannon entropy (-∑qᵢ log qᵢ), and what does its gradient represent?

- **Concept: Vector-Jacobian Products (VJP)**
  - Why needed: To implement this efficiently, one must compute zᵀ(∇y) without materializing the full Hessian. The algorithm relies on a "reverse-over-forward" VJP derivation.
  - Quick check: Given a layer y = f(θ) and an upstream cotangent z, how does computing the VJP differ from computing the Jacobian-Matrix Product (JVP) when f is a gradient itself (y = ∇g(θ))?

## Architecture Onboarding

- **Component map:** Input logits θ → Forward Pass (Alg 1) → DP table V^w_Ω and local probabilities Q^w_Ω → Operator Output (Alg 2) → Relaxed selection y^w_{C,Ω} → Sampling (Alg 3) for stochastic passes → VJP (Alg 4) for backward pass

- **Critical path:** The implementation hinges on Algorithm 1 (Forward). You must map your combinatorial problem (weights w, capacity C) to the DAG structure described in Section D.3. If the boundary conditions are wrong, the constraints will not hold.

- **Design tradeoffs:**
  - Shannon Entropy: Use if you require permutation equivariance. Expect dense outputs and higher gradient stability.
  - Gini/Tsallis Entropy: Use if you require sparsity or lower gradient variance. Be aware these are not permutation-equivariant.
  - Parallelism: The loops in Alg 1/2 are parallelizable over capacities (wavefront parallelism), but sequential dependency on items remains.

- **Failure signatures:**
  - Non-sparse outputs with Shannon: If you expect hard selections but use Shannon, outputs will strictly be in the interior (0,1)ⁿ. You must switch to Gini or add a threshold.
  - Violated constraints: If the DP table boundaries are initialized incorrectly, "pick" transitions might occur when capacity is insufficient.
  - Order sensitivity: If inputs are shuffled and outputs change drastically while using Gini/Tsallis, it is due to the lack of equivariance.

- **First 3 experiments:**
  1. Verify Sparsity (Prop 2): Run the operator with Gini regularization on random inputs. Increase input magnitude |θ|. Observe if output y snaps to vertices (becomes binary).
  2. Verify Equivariance (Prop 1): Generate random input vector θ and permutation σ. Run Shannon operator on σ(θ) and compare to σ(operator(θ)). Repeat for Gini to observe difference.
  3. Gradient Check: Implement Algorithm 4 (VJP) and compare gradients against numerical differentiation on a small Knapsack instance to ensure "reverse-over-forward" logic is correct.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the theoretical tension between permutation-equivariance (requiring Shannon entropy) and empirical performance (often better with non-equivariant sparse regularizers like Gini/Tsallis) resolve in practice?
- Basis in paper: Proposition 1 proves Shannon entropy is unique for equivariance; Figure 3 shows sparse regularizers outperform Shannon in RL setting; Figure 4 shows Tsallis/Gini outperform Shannon in VAE reconstruction.
- Why unresolved: The paper does not analyze why non-equivariant operators can achieve better empirical results, nor when one should prefer equivariance over sparsity.
- What evidence would resolve it: A theoretical or empirical characterization of task properties that determine which regularization choice is optimal.

### Open Question 2
- Question: Can the O(nC) complexity of the DP-based approach be improved for knapsack problems with very large capacity C relative to the number of items n?
- Basis in paper: Section 4.1 notes the effective parallel complexity is O(n) but does not address fundamental dependence on C; experiments only test C up to ~50.
- Why unresolved: Large capacity settings common in resource allocation problems remain unexplored, and no approximation or alternative algorithm is proposed.
- What evidence would resolve it: Benchmarks on problems where C >> n, or development of approximation algorithms with provable guarantees.

### Open Question 3
- Question: What are the bias and variance properties of the proposed surrogate gradient estimator for the stochastic forward pass, compared to REINFORCE-style or straight-through estimators?
- Basis in paper: Section 5.2 proposes surrogate gradients without theoretical analysis of estimator quality; Figure 3 shows reduced gradient variance empirically but no formal comparison.
- Why unresolved: The gradient estimator's statistical properties are not characterized, making it unclear when it should be preferred over alternatives.
- What evidence would resolve it: Theoretical analysis of estimator bias/variance, plus comprehensive comparison to existing gradient estimators across diverse tasks.

## Limitations
- The O(nC) complexity remains fundamental despite parallelization claims, with no empirical scaling studies for large instances
- The framework requires strictly convex regularizers, potentially limiting applicability with alternative smoothing functions
- Practical implications of Shannon entropy's uniqueness for permutation equivariance are not extensively explored

## Confidence
- Mechanism 1 (Gradient flow): High confidence - The mathematical derivation from Bellman recursion to smoothed DP is sound and well-established
- Mechanism 2 (Sparsity): High confidence - The proof of Proposition 2 is rigorous, and the bounded gradient condition is clearly defined
- Mechanism 3 (Permutation equivariance): High confidence - The proof of Shannon entropy's uniqueness is mathematically complete and well-articulated
- Implementation claims: Medium confidence - While algorithms are described in detail, absence of open-source code makes independent verification difficult

## Next Checks
1. **Scaling Experiment:** Implement the framework and measure runtime and memory consumption for varying problem sizes (items × capacity). Compare against alternative approaches like the top-k differentiable operator from [33] to quantify practical trade-offs.
2. **Regularizer Comparison:** Systematically test the framework with Shannon, Gini, and Tsallis regularizers on a benchmark combinatorial optimization problem. Measure both solution quality and gradient variance to validate theoretical predictions about sparsity and equivariance.
3. **End-to-end Integration Test:** Implement a simple decision-focused learning pipeline (e.g., training a neural network to predict item values for a Knapsack problem) using this framework. Verify that gradients flow correctly through the DP layer and that learned solutions respect combinatorial constraints.