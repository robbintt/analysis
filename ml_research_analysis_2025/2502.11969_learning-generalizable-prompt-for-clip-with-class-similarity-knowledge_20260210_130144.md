---
ver: rpa2
title: Learning Generalizable Prompt for CLIP with Class Similarity Knowledge
arxiv_id: '2502.11969'
source_url: https://arxiv.org/abs/2502.11969
tags:
- classes
- prompts
- prompt
- base
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of learned prompts in vision-language
  models (VLMs) failing to generalize to unseen classes during base-to-new tasks,
  due to incorrect semantic relationships among text embeddings. The proposed Similarity
  Alignment Regularization (SAR) method addresses this by using ChatGPT-4o to generate
  novel classes semantically aligned with base classes, and then aligning the similarity
  relationships among text embeddings generated by learnable prompts with those from
  hand-crafted prompts.
---

# Learning Generalizable Prompt for CLIP with Class Similarity Knowledge

## Quick Facts
- arXiv ID: 2502.11969
- Source URL: https://arxiv.org/abs/2502.11969
- Reference count: 40
- Primary result: SAR improves base-to-new generalization with +4.36% harmonic mean accuracy over 11 datasets

## Executive Summary
This paper addresses the problem of learned prompts in vision-language models (VLMs) failing to generalize to unseen classes during base-to-new tasks, due to incorrect semantic relationships among text embeddings. The proposed Similarity Alignment Regularization (SAR) method addresses this by using ChatGPT-4o to generate novel classes semantically aligned with base classes, and then aligning the similarity relationships among text embeddings generated by learnable prompts with those from hand-crafted prompts. SAR achieves this by minimizing the KL divergence between similarity distribution matrices computed over sampled classes, introducing randomness to mitigate overfitting. Experiments show that SAR consistently improves generalization to unseen classes across 11 datasets and five baselines, with an average accuracy improvement of 4.36% on harmonic mean (H) in 16-shot settings. SAR also incurs minimal resource costs, with no extra parameters and only slight increases in memory and training time.

## Method Summary
The method learns prompts for CLIP by optimizing both cross-entropy loss on base classes and a similarity alignment regularization loss. The regularization aligns the similarity relationships among text embeddings generated by learnable prompts with those from hand-crafted prompts. This is achieved by computing similarity distribution matrices over randomly sampled class embeddings and minimizing KL divergence between the learnable and hand-crafted matrices. The method uses 200 novel classes per dataset generated by ChatGPT-4o as proxies for unseen classes during training. Training involves CoOp/KgCoOp for 100 epochs with λ values tuned per dataset (0.1-0.8).

## Key Results
- SAR improves harmonic mean (H) accuracy by 4.36% on average across 11 datasets in 16-shot settings
- Achieves consistent gains on both base and new classes while maintaining zero-shot performance
- Outperforms five baselines including CoOp, KgCoOp, and VPT across all tested datasets
- Resource overhead is minimal with no extra parameters and only slight increases in memory and training time

## Why This Works (Mechanism)

### Mechanism 1: Relational Structure Preservation via Similarity Alignment
If learned prompts preserve the inter-class relationship structure of hand-crafted prompts, generalization improves because the semantic geometry of the embedding space remains intact. The method computes a similarity distribution matrix for text embeddings and minimizes KL divergence between matrices from learnable and hand-crafted prompts, forcing relative distances between classes to be maintained.

### Mechanism 2: Semantic Anchoring with Synthetic Unseen Classes
Using LLM-generated classes as proxies for unseen classes during training prevents overfitting to specific base class embeddings. ChatGPT-4o generates "novel" classes semantically related to base classes, which are included in the similarity alignment loss to expand semantic coverage and prevent prompts from becoming too specialized.

### Mechanism 3: Stochastic Regularization via Random Embedding Sampling
Randomly sampling subsets of classes instead of computing full similarity matrices introduces beneficial noise that mitigates overfitting. The method samples K embeddings to compute similarity matrix rows, with the paper claiming this randomness acts as a regularizer while providing sufficient gradient direction.

## Foundational Learning

- **Concept: Vision-Language Prompt Tuning (CoOp)**
  - Why needed here: Understanding that prompts are continuous vectors optimized via backpropagation rather than discrete text
  - Quick check: Can you explain the difference between a "hand-crafted prompt" (e.g., "a photo of a dog") and a "learnable prompt" in CLIP?

- **Concept: KL Divergence**
  - Why needed here: The core loss function relies on Kullback-Leibler divergence to measure distribution differences
  - Quick check: If KL divergence is 0, what does that imply about the relationship between two similarity matrices?

- **Concept: Zero-Shot Generalization / Base-to-New**
  - Why needed here: Understanding that the model is trained on "Base" classes and tested on "New" (unseen) classes without updates
  - Quick check: Why does standard fine-tuning often degrade performance on classes not seen during training?

## Architecture Onboarding

- **Component map:** Data Source (Base Classes + Novel Classes) -> Encoders (Frozen CLIP Image & Text Encoders) -> Prompts (Learnable vs. Hand-crafted) -> Loss (Cross-Entropy + SAR Loss)

- **Critical path:** Generation of Novel Classes list is pre-processing. Efficiency depends on how quickly similarity matrices for hand-crafted side can be computed or retrieved, as learned side changes every iteration.

- **Design tradeoffs:**
  - Novel Class Count: More classes improve performance but linearly increase memory and training time
  - Sampling Size (K=64): Higher K gives more accurate similarity estimate but reduces regularization noise
  - Lambda (λ): Controls trade-off between fitting training data and preserving semantic structure

- **Failure signatures:**
  - High SAR loss but low CE loss indicates overfitting to base classes
  - Memory overflow with 200 novel classes suggests reducing to 50 classes with K=16
  - Using alternative word sources resulting in 0 improvement indicates lack of semantic relevance

- **First 3 experiments:**
  1. Run CoOp on EuroSAT with and without SAR to verify +14% uplift on New classes
  2. Sweep λ (0.1 to 1.0) on ImageNet to find harmonic mean peak
  3. Replace ChatGPT-4o classes with random nouns to validate semantic alignment matters

## Open Questions the Paper Calls Out

1. Can the SAR framework be modified to eliminate reliance on hand-crafted prompts while maintaining generalization performance?
2. How can memory and training time overhead for computing text embeddings for novel classes be minimized?
3. What specific semantic properties should generated "novel classes" possess to maximize SAR effectiveness?

## Limitations
- Semantic fidelity of LLM-generated classes depends on ChatGPT-4o output quality and domain relevance
- Assumes hand-crafted prompt similarity matrix represents optimal "gold standard" semantic structure
- Random sampling as regularizer lacks strong empirical validation beyond Table 1
- Linear scaling of memory and compute with novel class count (200 per dataset) could be prohibitive

## Confidence

- **High confidence:** Core mechanism of aligning similarity distributions is mathematically sound; consistent H-mean improvements across 11 datasets
- **Medium confidence:** Use of LLM-generated classes is innovative but relies on assumptions about output quality; hyperparameter sensitivity requires careful tuning
- **Low confidence:** Claim that random sampling acts as regularizer is weakly supported; lacks rigorous ablation studies

## Next Checks

1. **Oracle Class Comparison:** Run SAR with both ChatGPT-generated classes and actual unseen test classes on a subset of datasets to measure performance differences and validate synthetic classes as effective proxies.

2. **Random Sampling Ablation:** Implement fixed similarity matrix version of SAR and compare performance on ImageNet to quantify impact of stochastic regularization.

3. **Cross-Domain Generalization:** Test SAR on domain-shifted dataset (e.g., Sketch-based ImageNet) to evaluate whether semantic alignment generalizes beyond natural images.