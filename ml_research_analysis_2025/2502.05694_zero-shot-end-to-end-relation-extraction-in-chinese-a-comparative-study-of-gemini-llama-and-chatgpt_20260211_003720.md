---
ver: rpa2
title: 'Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of
  Gemini, LLaMA and ChatGPT'
arxiv_id: '2502.05694'
source_url: https://arxiv.org/abs/2502.05694
tags:
- zero-shot
- chinese
- relation
- extraction
- gemini
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates ChatGPT, Gemini, and LLaMA for zero-shot end-to-end
  relation extraction in Chinese. The problem is that most prior work focuses on English
  or assumes pre-annotated entities, leaving their effectiveness in Chinese largely
  unexplored.
---

# Zero-Shot End-to-End Relation Extraction in Chinese: A Comparative Study of Gemini, LLaMA and ChatGPT

## Quick Facts
- arXiv ID: 2502.05694
- Source URL: https://arxiv.org/abs/2502.05694
- Authors: Shaoshuai Du; Yiyi Tao; Yiyi Shen; Hang Zhang; Yanxin Shen; Xinyu Qiu; Chuanqi Shi
- Reference count: 20
- Primary result: ChatGPT achieves highest F1 score (0.358) in zero-shot Chinese RE, while Gemini offers fastest inference (0.57s) but lower accuracy

## Executive Summary
This study evaluates ChatGPT, Gemini, and LLaMA models for zero-shot end-to-end relation extraction in Chinese, addressing the gap where most prior work focuses on English or assumes pre-annotated entities. The research compares these models based on accuracy, efficiency, and adaptability without requiring annotated data, revealing significant trade-offs between performance and inference speed. Results show ChatGPT achieves the best accuracy with F1 score of 0.358, while Gemini provides the fastest inference at 0.57 seconds but sacrifices accuracy. LLaMA underperforms in both dimensions, highlighting the varying effectiveness of different LLM architectures for Chinese relation extraction tasks.

## Method Summary
The study employs zero-shot end-to-end relation extraction on the DuIE 2.0 Chinese dataset using API calls to 12 different models across three families: OpenAI (gpt-4, gpt-4-turbo, gpt-4o-mini, gpt-4o), Google (gemini-1.0-pro, gemini-1.5-flash, gemini-1.5-flash-8b, gemini-1.5-pro), and Meta (llama3.1-70b, llama3.1-405b, llama3.2-3b, llama3.2-90b-vision). Models are prompted with a standardized template to output subject-predicate-object triples in Chinese without task-specific training. Evaluation uses joint precision, recall, and F1 scores with semantic matching to handle linguistic variability, measuring both accuracy and inference latency.

## Key Results
- ChatGPT achieves highest F1 score (0.358) with strong precision (0.363) in zero-shot Chinese RE
- Gemini models provide fastest inference speeds (0.57 seconds for gemini-1.5-flash-8b) but lower accuracy
- LLaMA models underperform in both accuracy (F1=0.117 for llama3.1-405b) and latency compared to competitors
- Clear trade-off exists between accuracy and inference speed across all evaluated models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot end-to-end relation extraction in Chinese is achievable through pre-trained multilingual knowledge encoded in LLMs, without task-specific annotation.
- Mechanism: LLMs leverage their pre-training on diverse corpora to simultaneously perform entity recognition and relation classification in a single inference pass. The prompt instructs the model to output subject-predicate-object triples directly, bypassing traditional pipeline separation.
- Core assumption: The model's pre-training includes sufficient Chinese linguistic patterns and entity-relation co-occurrence statistics to generalize without fine-tuning.
- Evidence anchors:
  - [abstract] "Zero-shot RE aims to extract entities and their semantic relationships without annotated examples, relying solely on a model's pre-trained knowledge and inference capabilities."
  - [section I] "end-to-end RE integrates these two processes into a single framework, reducing error propagation and improving contextual understanding."
  - [corpus] Related work (GLiREL, arXiv:2501.03172) confirms zero-shot RE architectures can generalize across relation types without labeled data, though performance varies by domain.
- Break condition: If the target domain uses specialized terminology or relation schemas absent from pre-training data, zero-shot performance degrades substantially (observed in F1 scores as low as 0.117 for llama3.1-405b).

### Mechanism 2
- Claim: Trade-offs between accuracy and inference latency emerge from model architecture choices and optimization priorities.
- Mechanism: Larger or more computationally complex models (gpt-4: 3.98s latency, F1=0.358) achieve higher accuracy through deeper reasoning, while optimized variants (gemini-1.5-flash-8b: 0.57s latency, F1=0.254) sacrifice extraction quality for speed. The architectural differences in attention mechanisms, model scale, and inference optimization directly affect this balance.
- Core assumption: Latency measurements reflect consistent API behavior and are comparable across providers despite infrastructure differences.
- Evidence anchors:
  - [section IV-B] "OpenAI's models generally exhibit higher latency, with gpt-4 reaching 3.98 seconds... Gemini models offer the lowest latency, with gemini-1.5-flash-8b achieving 0.57 seconds."
  - [section IV-C] "The findings reveal a trade-off between accuracy and inference speed in zero-shot end-to-end RE for Chinese."
  - [corpus] No direct corpus comparison of latency-accuracy trade-offs in Chinese RE; related benchmarks focus primarily on accuracy metrics.
- Break condition: If real-time requirements demand sub-second latency with high precision, no evaluated model satisfies both constraints simultaneously.

### Mechanism 3
- Claim: Semantic matching evaluation accommodates linguistic variability in Chinese relation expression better than exact string matching.
- Mechanism: Chinese conveys relations through contextual inference and implicit syntactic patterns, making exact-match evaluation overly strict. Semantic matching uses word embeddings and contextualized models to measure similarity between predicted and ground-truth triples, accepting partial overlaps and alternative phrasings.
- Core assumption: Semantic similarity metrics correlate with human judgment of extraction correctness.
- Evidence anchors:
  - [section III-B] "To avoid the problem of semantic variability, evaluation methods incorporating semantic similarity measures have been introduced."
  - [section I] "Chinese often conveys relationships through contextual inference rather than explicit syntactic patterns, making relation extraction harder."
  - [corpus] Related work (arXiv:2506.00777) highlights LLM evaluation challenges due to synonym generation and alternative phrasings, supporting semantic evaluation approaches.
- Break condition: If semantic matching threshold is too permissive, it may accept incorrect relations; if too strict, it negates the benefit of flexible evaluation.

## Foundational Learning

- Concept: **Zero-shot learning paradigm**
  - Why needed here: The entire methodology depends on models performing RE without task-specific training data; misunderstanding this leads to inappropriate baseline comparisons.
  - Quick check question: Can you explain why zero-shot RE requires no fine-tuning, and what implicit knowledge the model must already possess?

- Concept: **End-to-end vs. pipeline extraction**
  - Why needed here: The paper explicitly positions end-to-end extraction against pipeline approaches; understanding error propagation is essential for interpreting results.
  - Quick check question: How does separating entity recognition and relation classification in a pipeline introduce error propagation that end-to-end approaches avoid?

- Concept: **Joint evaluation metrics (Precision/Recall/F1 for triples)**
  - Why needed here: The study reports joint precision, recall, and F1; these differ from per-task metrics and require understanding of tuple-level evaluation.
  - Quick check question: If a model extracts ("黄真真", "导演", "闺蜜2") but the ground truth is ("黄真真", "导演", "《闺蜜2》"), how should joint precision be calculated under exact vs. semantic matching?

## Architecture Onboarding

- Component map: Input layer (DuIE 2.0 sentences) -> Prompt template construction -> Model layer (API calls) -> Output parsing (triple extraction) -> Evaluation layer (joint precision/recall/F1 + semantic matching)
- Critical path: 1. Prompt engineering (format specification, language preservation instruction) -> 2. API integration (rate limiting, latency tracking) -> 3. Triple parsing and normalization -> 4. Semantic matching against ground truth
- Design tradeoffs:
  - Accuracy vs. latency: gpt-4-turbo (F1=0.367, ~3s) vs. gemini-1.5-flash-8b (F1=0.254, 0.57s)
  - Precision vs. recall: gpt-4 (P=0.363, R=0.353) vs. gpt-4o-mini (P=0.284, R=0.432)
  - Model scale vs. deployment cost: llama3.1-405b shows no accuracy advantage over smaller variants
- Failure signatures:
  - Low recall with moderate precision: Model is overly conservative (gemini-1.0-pro: R=0.153)
  - Low precision with high recall: Model hallucinates relations (gpt-4o-mini: P=0.284, R=0.432)
  - Both metrics low: Model lacks Chinese RE capability (llama3.1-405b: F1=0.117)
  - High latency without accuracy gain: Inefficient architecture for task (llama3.1-405b: 3.36s, F1=0.117)
- First 3 experiments:
  1. **Baseline replication**: Run gpt-4-turbo and gemini-1.5-flash on a 100-sentence subset of DuIE 2.0 with the paper's exact prompt template; verify F1 scores are within ±0.03 of reported values.
  2. **Prompt sensitivity analysis**: Test 3 prompt variants (minimal, detailed instructions, few-shot examples with 2 examples) on gpt-4o-mini; measure impact on precision/recall balance.
  3. **Latency-stress test**: Measure latency under concurrent API calls (1, 5, 10 parallel requests) for gemini-1.5-flash-8b; determine if 0.57s latency holds under load or if rate-limiting increases response time.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does model performance vary across specific relation categories and long-tail relations in Chinese RE?
- Basis in paper: [explicit] The conclusion states future work should explore "finer-grained evaluation metrics, such as performance on specific relation categories and long-tail relations."
- Why unresolved: The study reports aggregate F1 scores (e.g., 0.367 for gpt-4-turbo) but does not analyze performance breakdowns by relation frequency or type.
- What evidence would resolve it: Per-category precision and recall scores for the DuIE 2.0 dataset, specifically comparing high-frequency relations against sparse, long-tail instances.

### Open Question 2
- Question: Can optimized prompt engineering strategies (e.g., few-shot or Chain-of-Thought) improve the accuracy-latency trade-off?
- Basis in paper: [explicit] The paper identifies "optimizing prompt design" as a key direction for enhancing zero-shot Chinese RE.
- Why unresolved: The methodology uses a single, zero-shot prompt structure for all models; it remains unknown if different prompting techniques could close the performance gap or alter latency rankings.
- What evidence would resolve it: Ablation studies testing various prompting strategies on the same models to measure changes in F1 score relative to the baseline latency.

### Open Question 3
- Question: What specific adaptation techniques are required to make open-source models like LLaMA competitive for Chinese RE?
- Basis in paper: [inferred] The paper notes LLaMA "underperforms in both accuracy and latency," but attributes this to a need for "further adaptation" rather than inherent inability.
- Why unresolved: It is unclear if LLaMA's low F1 (0.117) results from a lack of Chinese instruction-tuning or architectural constraints, and whether fine-tuning could fix this.
- What evidence would resolve it: Experimental results evaluating LLaMA after applying supervised fine-tuning (SFT) or retrieval-augmented generation (RAG) on Chinese extraction tasks.

## Limitations

- Study relies on API-based access to proprietary models, limiting reproducibility and preventing detailed architectural analysis
- Semantic matching evaluation framework lacks full specification of thresholds and embedding models used
- Analysis focuses on a single Chinese dataset (DuIE 2.0), potentially missing broader linguistic patterns

## Confidence

**High Confidence**: The relative performance ranking of models (ChatGPT > Gemini > LLaMA) across accuracy metrics is supported by consistent results across multiple model variants and evaluation runs.

**Medium Confidence**: The absolute F1 scores (ranging from 0.117 to 0.358) depend on semantic matching implementation details that were not fully specified.

**Low Confidence**: The claim that LLaMA underperforms due to architectural limitations rather than dataset fit or prompt sensitivity requires further investigation.

## Next Checks

1. **Cross-dataset validation**: Evaluate the same models and prompts on at least two additional Chinese RE datasets (e.g., FinRE for financial news, medical relation extraction corpora) to test generalization across domains and assess whether the performance patterns hold beyond DuIE 2.0.

2. **Prompt sensitivity analysis**: Systematically test 5-10 prompt variations (including few-shot examples, explicit formatting instructions, and temperature adjustments) across all model families to determine if the observed performance differences persist under optimized prompting or if they reflect prompt sensitivity rather than inherent model capabilities.

3. **Semantic matching calibration**: Conduct human evaluation of 100 randomly sampled predictions to establish ground truth on semantic similarity thresholds, then compare against the automated evaluation to determine if the semantic matching framework introduces systematic bias or misalignment with human judgment.