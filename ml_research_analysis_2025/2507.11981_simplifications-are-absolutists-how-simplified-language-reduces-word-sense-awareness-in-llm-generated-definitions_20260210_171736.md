---
ver: rpa2
title: 'Simplifications are Absolutists: How Simplified Language Reduces Word Sense
  Awareness in LLM-Generated Definitions'
arxiv_id: '2507.11981'
source_url: https://arxiv.org/abs/2507.11981
tags:
- definitions
- prompt
- llama
- sense
- simple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how simplification impacts homonym definition\
  \ quality in LLM-generated outputs. Using three target groups\u2014Normal, Simple,\
  \ and ELI5\u2014the study evaluates models like DeepSeek v3, Llama 4 Maverick, Qwen3-30B\
  \ A3B, GPT-4o mini, and Llama 3.1 8B across multilingual and English datasets."
---

# Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions

## Quick Facts
- arXiv ID: 2507.11981
- Source URL: https://arxiv.org/abs/2507.11981
- Authors: Lukas Ellinger; Miriam Anschütz; Georg Groh
- Reference count: 40
- Primary result: Simplification drastically reduces homonym definition completeness in LLMs, with DPO fine-tuning mitigating this drop.

## Executive Summary
This paper investigates how language simplification impacts homonym definition quality in LLM-generated outputs. Using Normal, Simple, and ELI5 prompts across multiple multilingual datasets, the study finds that simplification drastically reduces definition completeness by neglecting polysemy. The authors demonstrate that models like Llama 3.1 8B can be fine-tuned with Direct Preference Optimization to improve homonym response quality while maintaining simplified language, addressing the tension between simplicity and completeness in educational NLP applications.

## Method Summary
The study uses two datasets: HoWN (164 English homonyms) and ML-WiC (homonyms in 5 languages). Definitions are generated using various LLMs (DeepSeek v3, Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, Llama 3.1 8B) with Normal, Simple, and ELI5 prompts, with and without Multi-Sense-Aware (MSA) instructions. An LLM-as-Judge (GPT-4o mini) evaluates completeness via Helpful Sense Awareness (HeSA) and WordNet synset coverage. DPO fine-tuning is applied to Llama 3.1 8B using 116 preference pairs from Simple prompts, optimizing for completeness while maintaining simplified language.

## Key Results
- Simplification reduces definition completeness from ~80% (Normal) to ~20-40% (Simple) and <15% (ELI5)
- DPO fine-tuning improves completeness by +25.51 percentage points for Simple prompts on unseen words
- Multi-Sense-Aware prompting consistently improves completeness across all prompt types
- Language drift occurs in DPO model, occasionally responding in English when prompted in other languages

## Why This Works (Mechanism)

### Mechanism 1: Stylistic Constraint-Induced Sense Collapse
When LLMs receive "explain like I'm five" or "use simple language" instructions, they prioritize minimizing output complexity over semantic completeness. This triggers a heuristic that conflates linguistic simplicity with semantic reduction, resulting in "Absolutist" outputs that present single meanings as absolute truths.

### Mechanism 2: Preference Alignment via DPO
DPO adjusts the model's internal reward policy by explicitly favoring complete responses over incomplete ones. This decouples the model's association between "simple language" and "single sense," allowing it to maintain simplified linguistic style while recovering the ability to acknowledge multiple senses.

### Mechanism 3: Multi-Sense-Aware Prompting as a Hard Constraint
Explicitly instructing models to consider multiple meanings ("Keep in mind that some words have more than one meaning") forces the attention mechanism to weigh alternative semantic clusters, overriding the implicit bias of "Simple/ELI5" instructions toward single-sense outputs.

## Foundational Learning

- **Helpful Sense Awareness (HeSA)**: Novel evaluation metric checking if responses acknowledge potential incompleteness through "Do you mean X or Y?" questions or statements about unlisted meanings. Needed to evaluate definition safety; quick check: does the model ask for clarification on ambiguous terms?

- **Homonymy vs. Polysemy**: Understanding the distinction between words with multiple distinct meanings (homonyms) vs. related meanings (polysemes). Needed to evaluate definition completeness; quick check: should "bank" define a river bank, financial institution, or both?

- **Direct Preference Optimization (DPO)**: Training method using preference pairs (Winner vs. Loser) rather than raw text generation fine-tuning. Needed to understand how models learn to prefer multi-sense definitions; quick check: how does the model learn to prefer multi-sense over single-sense definitions?

## Architecture Onboarding

- **Component map**: Prompt Constructor -> Target LLM -> LLM-as-Judge -> Evaluation Pipeline
- **Critical path**: Definition evaluation relies on intersection of Full coverage OR HeSA, with LLM-Judge running HeSA extraction prompts as gatekeeper for all results
- **Design tradeoffs**: Simplicity vs. Safety (low FKGL correlates with semantic completeness drop); Judge Reliability (LLM judge efficient but introduces bias in Simple settings)
- **Failure signatures**: "Absolutist" Response (high-confidence single-sense definition for known homonym); Language Drift (DPO responding in wrong language)
- **First 3 experiments**:
  1. Replicate HeSA Validation on 50 random samples to verify judge accuracy vs. human review
  2. Run Multi-Sense-Aware prompt on ELI5 dataset to quantify completeness delta
  3. Test DPO checkpoints on 5 new homonyms not in WordNet to verify generalization

## Open Questions the Paper Calls Out

1. **Overcomplication for single-definition words**: Methods improving homonym completeness might unnecessarily complicate responses for unambiguous words. Study restricted to homonyms; unknown if sense-awareness negatively impacts precision for monosemous words.

2. **Factual accuracy and hallucination**: Study didn't verify factual accuracy of generated definitions. Responses may be "Complete" or "Sense Aware" while being factually incorrect. Need human/automated fact-checking against authoritative dictionaries.

3. **Alternative lexical resources**: Analysis relied solely on WordNet. Findings might not hold when evaluated against Wiktionary or ConceptNet, which may have different sense alignments and could bias completeness scores.

## Limitations

- Reliance on LLM-based evaluation (GPT-4o mini) introduces potential bias, particularly in simplified contexts where judge may struggle
- DPO fine-tuning reproducibility uncertain without complete preference pair dataset and exact generation hyperparameters
- Language drift observed in DPO model (responding in English when prompted in other languages) suggests multilingual generalization instability

## Confidence

- **High Confidence**: Core finding that simplification reduces homonym definition completeness (80% → 20-40% drop) is well-supported across multiple models and languages
- **Medium Confidence**: Effectiveness of Multi-Sense-Aware prompting and DPO fine-tuning shows consistent improvements but magnitude varies; LLM-as-Judge introduces evaluation uncertainty
- **Low Confidence**: Generalization of DPO improvements to truly unseen homonyms and long-term stability of fine-tuned model's multilingual behavior remain uncertain

## Next Checks

1. **Human Validation Study**: Conduct human evaluation on 100 randomly sampled definitions across all prompt types to verify LLM judge's accuracy, particularly for ELI5 responses

2. **Cross-Lingual Stability Test**: Test DPO-optimized model on 20 homonyms from languages not in training preference pairs (e.g., Japanese, Hindi) to assess generalization beyond 5 study languages

3. **Long-Term Consistency Monitoring**: Deploy DPO model in simulated environment generating 1,000+ definitions over time, tracking consistency in response language adherence and completeness metrics