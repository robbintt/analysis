---
ver: rpa2
title: 'Artificial Conversations, Real Results: Fostering Language Detection with
  Synthetic Data'
arxiv_id: '2503.24062'
source_url: https://arxiv.org/abs/2503.24062
tags:
- data
- synthetic
- language
- llms
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of acquiring high-quality training
  data for fine-tuning Large Language Models (LLMs) in non-English languages, focusing
  on Italian inclusive language detection in job advertisements. The authors propose
  a pipeline for generating synthetic data by systematically replacing job titles
  and adjectives in real sentences with alternatives of different grammatical genders,
  then fine-tuning the Phi3-mini model on this synthetic data.
---

# Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data

## Quick Facts
- arXiv ID: 2503.24062
- Source URL: https://arxiv.org/abs/2503.24062
- Reference count: 31
- Key outcome: Synthetic data fine-tuning of Phi3-mini outperforms pre-trained models on Italian inclusive language detection, achieving 0.991 accuracy on synthetic test data and 0.702 balanced accuracy on real data.

## Executive Summary
This study addresses the challenge of acquiring high-quality training data for fine-tuning Large Language Models (LLMs) in non-English languages, focusing on Italian inclusive language detection in job advertisements. The authors propose a pipeline for generating synthetic data by systematically replacing job titles and adjectives in real sentences with alternatives of different grammatical genders, then fine-tuning the Phi3-mini model on this synthetic data. The results show that the fine-tuned model consistently outperformed six pre-trained models on both synthetic and real test datasets, demonstrating that synthetic data is a viable and effective solution for language detection tasks.

## Method Summary
The methodology involves a template-based substitution approach where real Italian job advertisement sentences are converted to templates with labeled placeholders for job titles and adjectives. These templates are pre-split 70/30 into training and test sets before synthetic data generation. A substitution vocabulary provides gender-labeled alternatives (masculine, feminine, neutral), which are systematically combined to generate labeled synthetic samples. The Phi3-mini model is fine-tuned using PEFT/LoRA on ~5,712 chat-formatted samples, with training completed in 26.55 minutes on a Tesla T4 GPU. The approach uses four prompt strategies (ZSL, FSL, ZSLCOT) and evaluates on both synthetic test sets and real manually-annotated seed data.

## Key Results
- Fine-tuned Phi3-mini achieved 0.991 accuracy and 0.993 F1-score on synthetic test data
- On real seed data, fine-tuned model achieved 0.702 balanced accuracy versus 0.647 for best pre-trained model (GPT-4o-mini)
- ZSLCOT prompt strategy consistently outperformed other strategies across multiple models
- The approach demonstrates strong synthetic-to-real transfer, with synthetic-trained models outperforming pre-trained models on real data

## Why This Works (Mechanism)

### Mechanism 1: Template-Based Substitution with Morphological Variation
- Claim: Replacing placeholders with grammatically varied alternatives creates diverse training signal for gender-inclusive language detection.
- Mechanism: Real sentences are converted to templates with labeled placeholders, then substituted with masculine, feminine, or neutral alternatives from a labeled vocabulary.
- Core assumption: Italian grammatical gender markings on job titles and adjectives are the primary signal for detecting non-inclusive language.
- Evidence anchors: [abstract] "creating synthetic datasets by replacing job titles and adjectives in real data with alternatives having different grammatical endings"; [section 3.1] "Sentences containing only one label masculine or feminine were classified as NONINCLUSIVE"
- Break condition: Fails if inclusive language detection requires semantic understanding beyond grammatical gender.

### Mechanism 2: Pre-Splitting Templates to Prevent Structural Leakage
- Claim: Separating templates into train/test sets before synthetic generation reduces overfitting by ensuring structural diversity across splits.
- Mechanism: Templates are partitioned 70/30 at the outset, with each split undergoing independent substitution.
- Core assumption: Sentence structure influences model learning and structural overlap between train/test inflates performance metrics.
- Evidence anchors: [section 3.1] "pre-splitting the templates into separate training and test sets prior to data generation... ensuring that the test set remains sufficiently distinct from the training set"
- Break condition: Fails if vocabulary overlap alone drives overfitting or if template diversity is too limited.

### Mechanism 3: Synthetic-to-Real Transfer Through Morphological Coverage
- Claim: Training on synthetically expanded morphological variants transfers to real-world inclusive language detection.
- Mechanism: Synthetic data exposes the model to systematic grammatical variations that may be underrepresented in limited real data.
- Core assumption: Real-world inclusive language violations follow similar morphological patterns to synthetic variants.
- Evidence anchors: [abstract] "fine-tuned models trained on synthetic data consistently outperformed other models on both real and synthetic test datasets"; [table 2b] Fine-tuned Phi3 achieved 0.702 balanced accuracy on real seed data
- Break condition: Fails if real-world non-inclusive language includes patterns not captured by grammatical substitution.

## Foundational Learning

- **Italian Grammatical Gender Morphology**:
  - Why needed here: The approach hinges on recognizing masculine, feminine, and neutral forms of job titles and adjectives in Italian.
  - Quick check question: Given "Avvocato" (lawyer—traditionally masculine form used generically), what makes this potentially non-inclusive versus a neutral alternative?

- **Parameter-Efficient Fine-Tuning (PEFT/LoRA)**:
  - Why needed here: The study uses LoFTQ configuration to fine-tune only ~30M parameters rather than full 3.8B.
  - Quick check question: Why would full fine-tuning risk catastrophic forgetting or excessive compute for a specialized classification task?

- **Balanced Accuracy for Imbalanced Datasets**:
  - Why needed here: The study reports class imbalance (INCLUSIVE labels appear ~2x more than NONINCLUSIVE), making standard accuracy potentially misleading.
  - Quick check question: If a model predicts "INCLUSIVE" for all inputs in a dataset with 67% INCLUSIVE labels, what would standard accuracy be versus balanced accuracy?

## Architecture Onboarding

- **Component map**: Real data → Template extraction → Pre-split templates → Substitution → Labeling → Chat formatting → Fine-tuning → Inference on both test splits → Metric comparison
- **Critical path**: Real sentences → Template Maker (extracts maskable words, assigns labels) → Chunk Merger (controls text length) → Data Generator (substitutes placeholders) → Response Maker (assigns INCLUSIVE/NONINCLUSIVE labels) → Prompt Generator (creates ZSL, FSL, ZSLCOT variants) → Chat Maker (formats for Phi-3) → Fine-tuning Module (Unsloth + PEFT/LoFTQ) → Inference Evaluator (runs all models)
- **Design tradeoffs**: Template-based substitution vs. LLM-generated text (controlled variation vs. natural outputs); 70/30 pre-split vs. post-generation split (leakage prevention vs. flexibility); Phi-3-mini vs. larger models (faster fine-tuning vs. lower ceiling)
- **Failure signatures**: Low recall on NONINCLUSIVE (majority class bias); large synthetic-to-real performance gap (overfitting); inconsistent prompt performance (prompt sensitivity)
- **First 3 experiments**: 1) Replicate template extraction and substitution on 50 sentences to verify label assignment; 2) Fine-tune with different prompt strategies and compare balanced accuracy; 3) Ablate pre-splitting step and compare test performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed synthetic data generation pipeline be effectively transferred to text domains other than job advertisements?
- Basis in paper: [explicit] The conclusion states the authors plan to "extend this methodology for generating synthetic data to domains beyond job descriptions."
- Why unresolved: The current study validates the approach exclusively within the context of Italian job postings.
- What evidence would resolve it: Applying the pipeline to distinct domains (e.g., academic texts or healthcare records) and benchmarking performance against real-world data.

### Open Question 2
- Question: How would state-of-the-art models (e.g., GPT-4o, Gemini) perform if fine-tuned on this synthetic dataset compared to the fine-tuned Phi-3?
- Basis in paper: [explicit] The authors explicitly intend to "fine-tune other recent and advanced LLMs... to enable comparisons between various fine-tuned models."
- Why unresolved: The current experiment only fine-tuned Phi-3; comparisons relied on pre-trained versions.
- What evidence would resolve it: Fine-tuning larger models on the same synthetic data and comparing balanced accuracy and recall against fine-tuned Phi-3.

### Open Question 3
- Question: Is the specific template-based substitution strategy effective for inclusive language detection in languages that lack the grammatical gender markers found in Italian?
- Basis in paper: [inferred] The methodology relies heavily on replacing words with "alternatives having different grammatical endings" (masculine/feminine).
- Why unresolved: The paper does not address whether this mechanism is transferable to languages without grammatical gender.
- What evidence would resolve it: Adapting the synthetic generation pipeline for a non-gendered language and evaluating performance improvement.

## Limitations
- Dependence on grammatical gender morphology as the sole signal for inclusive language detection, potentially missing nuanced non-inclusive patterns
- Lack of provided substitution vocabulary list and prompt templates, making exact replication challenging
- Unspecified source and volume of the real seed dataset, limiting reproducibility

## Confidence

- **High confidence**: The core finding that synthetic data fine-tuning outperforms pre-trained models on both synthetic and real test data (0.991 accuracy on synthetic, 0.702 balanced accuracy on real)
- **Medium confidence**: The claim that synthetic data is a viable solution for low-resource language tasks (only one language pair and task type examined)
- **Low confidence**: The assertion that pre-splitting templates prevents overfitting (lacks direct empirical validation)

## Next Checks

1. Test synthetic-to-real transfer by training on a small real dataset plus synthetic data, then evaluating on a held-out real test set to quantify real data contribution to performance.

2. Conduct ablation studies removing the template pre-splitting step to measure the actual impact on test performance and verify overfitting prevention claims.

3. Expand evaluation to include additional Italian inclusive language patterns beyond grammatical gender (e.g., occupational stereotypes, coded language) to test method's robustness to more complex non-inclusive language forms.