---
ver: rpa2
title: Self-Attention with State-Object Weighted Combination for Compositional Zero
  Shot Learning
arxiv_id: '2512.18969'
source_url: https://arxiv.org/abs/2512.18969
tags:
- compositions
- states
- object
- objects
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses compositional zero-shot learning (CZSL), which
  aims to recognize novel combinations of states and objects not seen during training.
  The proposed method, SASOW, builds upon the state-of-the-art KG-SP approach by incorporating
  self-attention mechanisms into the state and object classifiers, and introducing
  a weighted combination scheme during composition score calculation.
---

# Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning

## Quick Facts
- arXiv ID: 2512.18969
- Source URL: https://arxiv.org/abs/2512.18969
- Reference count: 26
- Improves CZSL accuracy by 2.1%, 1.7%, and 0.4% on MIT-States, UT Zappos, and C-GQA respectively

## Executive Summary
This paper addresses compositional zero-shot learning (CZSL), where the goal is to recognize novel combinations of states and objects not seen during training. The proposed SASOW method builds on the KG-SP approach by incorporating self-attention mechanisms into state and object classifiers and introducing a weighted combination scheme for composition scores. The self-attention captures feature interactions in complex images, while the weighted combination accounts for varying classifier confidence levels. Experimental results on three benchmark datasets show competitive performance with state-of-the-art methods, with improvements ranging from 0.4% to 2.1% in best unseen accuracy.

## Method Summary
SASOW extends the KG-SP framework by adding self-attention layers to the state and object classifiers, which are MLPs that process ResNet-extracted image features. The self-attention mechanism projects features into query, key, and value vectors to model internal feature relationships. A weighted combination scheme then calculates composition scores by adjusting state probabilities based on the relative accuracy of state and object classifiers. The method operates in the open-world CZSL setting, where it recognizes arbitrary state-object pairs using independent classifiers and filters implausible combinations through a ConceptNet-derived feasibility mask.

## Key Results
- Improves best unseen accuracy by 2.1% on MIT-States dataset
- Improves best unseen accuracy by 1.7% on UT Zappos dataset
- Improves best unseen accuracy by 0.4% on C-GQA dataset
- Ablation study confirms both self-attention and weighted combination components contribute to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Self-Attention on Classifiers for Enhanced Feature Interaction
- Claim: Incorporating a self-attention mechanism into the state and object classifiers allows the model to better capture relationships between different parts of an image, leading to improved classification accuracy for complex images.
- Mechanism: ResNet extracts an image feature vector ($F_{img}$). This vector is passed through a modified Multi-Layer Perceptron (MLP) with a self-attention layer. In this layer, $F_{img}$ is linearly projected into Query (Q), Key (K), and Value (V). The attention scores are computed from the dot product of Q and K, normalized to probabilities. These scores weight the Value vectors, and the result is added back to the original $F_{img}$ to produce attention-enhanced features. This process models interactions and importance within the input feature sequence.
- Core assumption: Complex images contain features whose relationships are crucial for identifying states and objects, and a simple MLP fails to model these interactions adequately. The self-attention mechanism enables the model to focus on relevant features regardless of their position.
- Evidence anchors:
  - [abstract] "The self-attention mechanism enhances the model's ability to capture interactions between different parts of the image..."
  - [section III.A] "...incorporating the Self-Attention mechanism at the feature level, this modified model effectively models the interactions and importance within the input sequence, enabling better capture of the relationships between features."
  - [corpus] Related work on Compositional Zero-Shot Learning (e.g., 'Learning Primitive Relations for Compositional Zero-Shot Learning') highlights the importance of modeling state-object relationships, which is a form of feature interaction, suggesting attention mechanisms are a plausible way to achieve this.
- Break condition: If images have very simple, fixed backgrounds and centrally located objects (like the original UT Zappos dataset), the added complexity of self-attention may offer little to no benefit, as there are few complex feature relationships to model.

### Mechanism 2: State-Object Weighted Combination for Improved Composition Scores
- Claim: Assigning different weights to state and object probabilities when calculating composition scores yields more accurate results by favoring the more reliable classifier.
- Mechanism: The state classifier output ($P_{sta}$) and object classifier output ($P_{obj}$) are used to compute a composition score. Instead of a simple element-wise multiplication ($S_{com} = P_{sta} @ P_{obj}$), a weight is applied. A new state vector is calculated: $P_{sta_i}' = (P_{sta_i})^{\frac{A_{sta}}{A_{obj}}}$, where $A_{sta}$ and $A_{obj}$ are the respective accuracies of the state and object classifiers. This new vector is then multiplied with the object vector: $S_{com_i}' = P_{sta_i}' @ P_{obj_i}$. This weighting scheme amplifies the contribution of the more accurate classifier.
- Core assumption: The object classifier is typically more accurate than the state classifier, and accounting for this performance disparity during composition improves the final joint prediction. The ratio $\frac{A_{sta}}{A_{obj}}$ is often less than 1, which flattens the state probability distribution, thereby giving the object probability more influence.
- Evidence anchors:
  - [abstract] "...introducing a weighted combination scheme during composition score calculation. The weighted combination scheme accounts for the varying confidence levels of the state and object classifiers, assigning different weights based on their respective accuracies."
  - [section III.B] "Since the recognition effect of the object classifier is usually better, the ratio ... is usually smaller than 0, which will reduce the gap between the lower probability and the higher probability in $P_{sta}$... This can increase our confidence in the object classification effect..."
  - [corpus] The paper 'Learning Primitive Relations for Compositional Zero-Shot Learning' and others in the corpus generally focus on modeling state-object interactions, but SASOW's explicit weighting of classifier confidence is a specific contribution. Direct corpus evidence for this exact weighting formula is weak.
- Break condition: If state and object classifiers have similar accuracy, or if the state classifier is more accurate, the current weighting scheme (which assumes object dominance) might not provide the intended benefit and could even degrade performance.

### Mechanism 3: Open-World CZSL with Independent Primitives and a Feasibility Mask
- Claim: Decomposing the problem into independent state and object recognition and then filtering compositions with a feasibility mask is an effective strategy for the open-world setting.
- Mechanism: This architecture builds on the KG-SP framework. It uses separate classifiers for states and objects. This reduces the output space from the Cartesian product of all possible pairs to the much smaller sets of individual states and objects. The predictions from these classifiers are combined to form a composition score. Finally, a feasibility mask, derived from external knowledge (ConceptNet), filters out implausible combinations (e.g., "ripe dog").
- Core assumption: It is computationally more efficient and easier to recognize states and objects independently than to discriminate between a vast number of possible compositions directly. External knowledge can effectively prune the search space of impossible compositions.
- Evidence anchors:
  - [abstract] "SASOW builds upon the state-of-the-art KG-SP approach by incorporating self-attention... KG-SP addresses this issue by training distinct classifiers for states and objects, while leveraging a semantic model to evaluate the plausibility of composed compositions."
  - [section II.B] "The rationale is that while discriminating between compositions is difficult in OW-CZSL due to the extensive search space, recognizing primitives (i.e., objects and states) in isolation is easier..."
  - [corpus] 'Feasibility with Language Models for Open-World Compositional Zero-Shot Learning' strongly supports the use of external models/knowledge to determine the feasibility of state-object pairs, validating the masking approach as a key component of the OW-CZSL strategy.
- Break condition: The independent classifier assumption fails when the identity of the object is strongly dependent on its state or vice versa. The feasibility mask can also be brittle if the external knowledge source is incomplete or incorrect for the domain.

## Foundational Learning

- **Concept: Vision Transformers & Self-Attention**
  - Why needed here: The paper's primary improvement to the classifier is based on the self-attention mechanism, which is the core component of Transformer models. Understanding how Q, K, and V projections create an attention map is essential to grasp how SASOW's classifier works.
  - Quick check question: Can you explain how the dot product of a Query and a Key vector determines the "attention" paid to a specific image feature?

- **Concept: Compositional Zero-Shot Learning (CZSL) vs. Open-World CZSL**
  - Why needed here: The paper positions its work within the OW-CZSL paradigm. Understanding the distinction—that CZSL limits the search space to a subset of compositions while OW-CZSL considers all possible pairs—is crucial for framing the problem and the motivation behind the architecture.
  - Quick check question: What is the fundamental difference in the search space between a standard CZSL model and an Open-World CZSL model during inference?

- **Concept: Multi-Layer Perceptron (MLP) Architectures**
  - Why needed here: The base classifier that the authors modify is an MLP. To understand the contribution of SASOW, one must first understand the simpler baseline architecture it builds upon.
  - Quick check question: What are the basic components of an MLP, and what is a common activation function used within its hidden layers?

## Architecture Onboarding

- Component map:
  1.  **Feature Extractor:** A pre-trained ResNet that converts the raw image into a feature vector ($F_{img}$).
  2.  **State Classifier ($Cla_{sta}$):** An MLP with an integrated self-attention mechanism. It takes $F_{img}$ and outputs a probability distribution over all possible states ($P_{sta}$).
  3.  **Object Classifier ($Cla_{obj}$):** An MLP with an integrated self-attention mechanism. It takes $F_{img}$ and outputs a probability distribution over all possible objects ($P_{obj}$).
  4.  **Weighted Combination Calculator:** A module that takes $P_{sta}$ and $P_{obj}$, applies the accuracy-based weighting to the state vector, and computes the final composition score matrix ($S_{com}'$) via batch matrix multiplication.
  5.  **Feasibility Mask:** A pre-computed mask, derived from ConceptNet, that filters the final $S_{com}'$ to remove implausible state-object pairs.

- Critical path: **Raw Image** → **ResNet (Feature Extractor)** → **Self-Attention-MLP Classifiers** → **State ($P_{sta}$) & Object ($P_{obj}$) Probability Vectors** → **Weighted Combination** → **Composition Score Matrix ($S_{com}'$)** → **(Apply Feasibility Mask)** → **Final Prediction**.

- Design tradeoffs:
  - **Performance vs. Complexity:** Adding self-attention to the classifiers increases model parameters and computational cost compared to the simpler MLP baseline. The paper claims this is justified by accuracy gains, especially on complex images.
  - **Generalization vs. Weighting Specificity:** The weighted combination scheme uses a fixed ratio of accuracies ($\frac{A_{sta}}{A_{obj}}$). While it works well in the reported experiments, it may not generalize well if the accuracy gap between classifiers varies significantly across different datasets or domains. The weighting hyperparameter might need tuning.

- Failure signatures:
  - **Performance drop on simple images:** If the model is evaluated on a dataset with simple, centered objects and uniform backgrounds (like UT Zappos), the self-attention mechanism might be an unnecessary overhead and could even underperform compared to a simpler model due to optimization difficulties.
  - **Dominance of one classifier:** If the accuracy ratio used for weighting is poorly estimated or if the object classifier is overconfident, the final composition will effectively be decided by the object prediction alone, ignoring potentially useful information from the state classifier.
  - **Infeasible compositions:** If the ConceptNet-derived feasibility mask is too restrictive or contains errors, it could filter out valid but rare compositions, leading to incorrect predictions.

- First 3 experiments:
  1.  **Baseline Implementation & Verification:** Implement the original KG-SP model (ResNet + MLP classifiers) and verify that its performance on MIT-States matches the reported baseline. This establishes a solid reference point.
  2.  **Ablation Study - Self-Attention:** Add the self-attention mechanism to the MLP classifiers *without* the weighted combination. Train and evaluate on both a complex dataset (MIT-States) and a simple one (UT Zappos) to confirm the hypothesis that self-attention helps more with complex images. The paper's "UT Zappos-moving" experiment is a perfect guide for this.
  3.  **Ablation Study - Weighted Combination:** Take the model from experiment 2 (with self-attention) and add the weighted combination module. Compare its performance against the model from experiment 2 to isolate the contribution of the weighting scheme, specifically looking for improvements in "best unseen accuracy" (U).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the SASOW framework be effectively adapted to recognize objects possessing multiple concurrent states, particularly regarding the definition of labeling schemes and the management of state contradictions?
- **Basis in paper:** [explicit] The conclusion states, "objects can exist in multiple states, which makes the study of multi-state scenarios a future challenge... defining labeling schemes for multi-states and developing methods to evaluate the recognition of multi-state combinations can be explored."
- **Why unresolved:** The current study is restricted to single-state object datasets (MIT-States, UT Zappos, C-GQA), and the proposed architecture does not implement logic to handle or evaluate the co-occurrence of multiple attributes.
- **What evidence would resolve it:** A modified SASOW architecture capable of processing multi-label inputs, validated on a dataset annotated for multiple concurrent states with a corresponding evaluation metric for state contradiction.

### Open Question 2
- **Question:** Would replacing the ResNet backbone with alternative feature extractors, such as Vision Transformers, improve the utilization of the self-attention mechanism and overall recognition accuracy?
- **Basis in paper:** [explicit] The conclusion suggests, "exploring different methods for extracting image features is crucial. This can further improve the accuracy of state and object recognition and allow for the more effective utilization of self-attention mechanisms."
- **Why unresolved:** The paper exclusively utilizes ResNet for feature extraction; the interaction between the proposed self-attention classifiers and other feature extraction architectures remains uninvestigated.
- **What evidence would resolve it:** A comparative ablation study showing performance metrics (Seen/Unseen accuracy) when SASOW is trained on features extracted by diverse backbones (e.g., ResNet vs. ViT).

### Open Question 3
- **Question:** Can the proposed weighted combination scheme maintain its effectiveness when applied to domain-specific datasets where the distribution of states and objects differs significantly from general benchmarks?
- **Basis in paper:** [explicit] The conclusion notes, "it is essential to establish domain-specific datasets and evaluate the feasibility of applying these methods, thereby adapting them to different domain-specific datasets."
- **Why unresolved:** The validation is limited to three specific academic benchmarks; the paper does not verify if the weighting heuristic ($A_{sta}/A_{obj}$) generalizes to specialized industrial or agricultural domains mentioned in the introduction.
- **What evidence would resolve it:** Experimental results from applying SASOW to specialized datasets (e.g., manufacturing flaw detection) demonstrating that the weighted combination provides statistically significant improvements over baseline models in those domains.

## Limitations

- Several key implementation details remain unspecified, including ResNet variant, MLP architecture specifications, training hyperparameters, and classifier accuracy computation method
- Performance gains may not generalize to datasets with simple, centered objects where self-attention adds unnecessary complexity
- The weighted combination scheme's effectiveness depends on accurate estimation of classifier accuracy ratios, which may vary across domains

## Confidence

- **High confidence**: The core mechanisms of self-attention integration and weighted combination are well-described and logically sound
- **Medium confidence**: The ablation study results showing improvements over KG-SP are compelling, but the lack of detailed training specifications makes exact reproduction uncertain
- **Medium confidence**: The open-world CZSL framing and decomposition strategy is well-established in prior work, but the specific implementation details matter significantly for performance

## Next Checks

1. **Hyperparameter sensitivity**: Test SASOW with varying values of the accuracy ratio (A_sta/A_obj) to determine if the weighting scheme's effectiveness depends on the specific ratio used, or if it's robust across a range

2. **Mask robustness**: Evaluate SASOW's performance when using alternative feasibility masks (e.g., from different knowledge sources or learned from data) to assess whether the ConceptNet dependency is a strength or a potential failure point

3. **Generalization to different domains**: Apply SASOW to a CZSL dataset from a substantially different domain (e.g., satellite imagery or medical imaging) to test whether the self-attention and weighted combination mechanisms generalize beyond natural images of everyday objects