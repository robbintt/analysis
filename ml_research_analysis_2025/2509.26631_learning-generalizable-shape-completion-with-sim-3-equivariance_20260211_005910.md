---
ver: rpa2
title: Learning Generalizable Shape Completion with SIM(3) Equivariance
arxiv_id: '2509.26631'
source_url: https://arxiv.org/abs/2509.26631
tags:
- equivariant
- equivariance
- shape
- completion
- scale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies pose and scale bias in 3D shape completion
  methods that rely on pre-aligned inputs, leading to poor generalization on real-world
  scans. The authors propose the first fully SIM(3)-equivariant shape completion network,
  which integrates feature canonicalization, similarity-invariant geometric reasoning,
  and transform restoration into a modular architecture.
---

# Learning Generalizable Shape Completion with SIM(3) Equivariance

## Quick Facts
- **arXiv ID**: 2509.26631
- **Source URL**: https://arxiv.org/abs/2509.26631
- **Reference count**: 40
- **Primary result**: 17% reduction in minimal matching distance on KITTI and 14% improvement in Chamfer distance on OmniObject3D using fully SIM(3)-equivariant shape completion network

## Executive Summary
This paper addresses the critical problem of pose and scale bias in 3D shape completion methods that assume pre-aligned inputs, which severely limits their performance on real-world scans. The authors propose the first fully SIM(3)-equivariant shape completion network that eliminates the need for ground-truth alignment during inference. The model achieves robust generalization by integrating feature canonicalization, similarity-invariant geometric reasoning, and transform restoration into a modular architecture. Trained on synthetic data, the network directly transfers to real-world datasets like KITTI and OmniObject3D without requiring aligned training data.

## Method Summary
The proposed method introduces a fully SIM(3)-equivariant shape completion network that operates without requiring pre-aligned inputs. The architecture consists of three main components: feature canonicalization, which normalizes input poses and scales to a canonical frame; similarity-invariant geometric reasoning, which processes the canonicalized features while maintaining SIM(3) equivariance; and transform restoration, which maps the completed shape back to the original coordinate frame. The model is trained exclusively on synthetic data and evaluated on real-world scans, demonstrating significant improvements over both equivariant and augmentation baselines.

## Key Results
- Achieves 17% reduction in minimal matching distance on KITTI dataset
- Improves Chamfer distance by 14% on OmniObject3D dataset
- Outperforms equivariant and augmentation baselines under de-biased evaluation protocol

## Why This Works (Mechanism)
The architecture's success stems from its ability to operate independently of input pose and scale through feature canonicalization and SIM(3) equivariant processing. By normalizing inputs to a canonical frame before geometric reasoning and then restoring the original transform, the network learns shape completion that is inherently invariant to alignment variations. This architectural design eliminates the need for alignment supervision during training while maintaining high fidelity shape completion.

## Foundational Learning

**SIM(3) Group Theory**: Understanding similarity transformations (rotation, translation, uniform scaling) and their mathematical properties
- *Why needed*: Forms the theoretical foundation for equivariant design
- *Quick check*: Can verify equivariance by applying random similarity transforms to inputs and confirming consistent outputs

**Canonicalization**: Process of mapping arbitrary pose/scale inputs to a standard reference frame
- *Why needed*: Enables the network to operate on normalized features while maintaining equivariance
- *Quick check*: Ensure canonicalization is differentiable and invertible for transform restoration

**Equivariant Neural Networks**: Networks that transform predictably under group actions
- *Why needed*: Guarantees consistent behavior under pose and scale variations
- *Quick check*: Test with controlled transformations to verify equivariant properties

## Architecture Onboarding

**Component Map**: Input -> Canonicalization -> SIM(3)-Equivariant Processing -> Transform Restoration -> Output

**Critical Path**: Feature extraction → Canonicalization → Geometric reasoning → Transform restoration → Completion output

**Design Tradeoffs**: Full SIM(3) equivariance vs computational complexity; synthetic-only training vs generalization capability; modular design vs end-to-end optimization

**Failure Signatures**: Poor canonicalization leads to geometric reasoning errors; transform restoration inaccuracies cause misalignment; equivariance violations result in inconsistent outputs under transformations

**First Experiments**: (1) Verify equivariance by applying random similarity transforms to inputs, (2) Test canonicalization and restoration pipeline separately, (3) Compare against non-equivariant baselines on aligned vs unaligned data

## Open Questions the Paper Calls Out

Major uncertainties remain regarding the scalability of the SIM(3)-equivariant architecture to larger scenes and more complex object categories beyond those evaluated. The ablation study does not fully isolate the individual contributions of each architectural component, making it difficult to determine which specific design choices are most critical for generalization. Additionally, while the model avoids explicit alignment requirements, it is unclear how sensitive the approach is to severe occlusions or extreme sensor noise in real-world scans.

## Limitations

- Scalability to larger scenes and complex object categories remains unproven
- Ablation study lacks granularity in isolating individual component contributions
- Performance under severe occlusions and extreme sensor noise is not characterized

## Confidence

- **Generalization improvement claim**: High (consistent quantitative improvements across multiple datasets)
- **First fully SIM(3)-equivariant claim**: Medium (exhaustive survey of prior work not provided)
- **De-biasing protocol effectiveness**: High (controlled experimental setup with clear performance gaps)

## Next Checks

1. Test the method on scenes with multiple interacting objects to assess scalability and robustness to complex spatial relationships
2. Conduct user studies or downstream task evaluations to measure practical utility beyond geometric metrics
3. Perform a more granular ablation study that isolates the impact of feature canonicalization, geometric reasoning, and transform restoration components