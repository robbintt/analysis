---
ver: rpa2
title: 'TransformEEG: Towards Improving Model Generalizability in Deep Learning-based
  EEG Parkinson''s Disease Detection'
arxiv_id: '2507.07622'
source_url: https://arxiv.org/abs/2507.07622
tags:
- transformeeg
- data
- deep
- augmentation
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces TransformEEG, a hybrid Convolutional-Transformer\
  \ model designed to improve generalizability in EEG-based Parkinson\u2019s disease\
  \ detection. The key innovation is a depthwise convolutional tokenizer that generates\
  \ channel-specific tokens from EEG windows, enabling more effective feature mixing\
  \ in transformer encoder layers compared to EEGNet-like architectures."
---

# TransformEEG: Towards Improving Model Generalizability in Deep Learning-based EEG Parkinson's Disease Detection

## Quick Facts
- **arXiv ID:** 2507.07622
- **Source URL:** https://arxiv.org/abs/2507.07622
- **Reference count:** 40
- **Primary result:** TransformEEG achieves 78.45% median balanced accuracy with 6.37% IQR in PD detection

## Executive Summary
This study introduces TransformEEG, a hybrid Convolutional-Transformer model designed to improve generalizability in EEG-based Parkinson's disease detection. The key innovation is a depthwise convolutional tokenizer that generates channel-specific tokens from EEG windows, enabling more effective feature mixing in transformer encoder layers compared to EEGNet-like architectures. TransformEEG was evaluated against seven established EEG deep learning models using harmonized data from four public datasets (290 subjects, 140 PD patients, 150 healthy controls) through a rigorous 10-outer, 10-inner Nested-Leave-N-Subjects-Out cross-validation. The model achieved the highest median balanced accuracy (78.45%) and lowest interquartile range (6.37%) among all models. When combined with optimal data augmentation and threshold correction, TransformEEG's median accuracy increased to 80.10% with an interquartile range of 5.74%, demonstrating superior consistency and generalizability compared to other architectures.

## Method Summary
TransformEEG is a hybrid CNN-Transformer architecture that processes 16-second EEG windows (2000 time steps) from 32-channel recordings at 125 Hz. The model uses a depthwise convolutional tokenizer with two blocks to generate channel-specific tokens, followed by two transformer encoder layers and a classification head. Training employs Adam optimizer (lr=2.5e-4, β₁=0.75) with exponential decay, batch size 64, and early stopping (patience=20). The evaluation uses Nested-Leave-N-Subjects-Out cross-validation (10-outer, 10-inner folds) with data augmentation (Time Reverse + Masking at 75% probability) and threshold correction on validation sets. The model was compared against seven established EEG deep learning architectures using harmonized data from four public datasets.

## Key Results
- TransformEEG achieved the highest median balanced accuracy (78.45%) and lowest interquartile range (6.37%) among all evaluated models
- With optimal data augmentation and threshold correction, TransformEEG's median accuracy increased to 80.10% with an IQR of 5.74%
- The depthwise convolutional tokenizer demonstrated superior generalizability compared to standard convolutional tokenizers used in EEGNet-like architectures

## Why This Works (Mechanism)
TransformEEG improves generalizability by using depthwise convolutional tokenizers that preserve channel-specific features while generating effective tokens for transformer encoders. Unlike standard 2D convolutions that mix channels immediately, depthwise convolutions maintain spatial relationships within each channel before feature mixing occurs in the transformer layers. This architecture enables more robust learning of temporal patterns relevant to Parkinson's disease detection while reducing overfitting to specific recording conditions or patient subsets.

## Foundational Learning
- **Nested Leave-N-Subjects-Out Cross-Validation**: Ensures subject independence by splitting at the subject level rather than window level, preventing data leakage and providing robust estimates of generalizability
- **Depthwise Convolutional Tokenization**: Preserves channel-specific temporal features by using grouped convolutions before feature mixing, enabling more effective token generation for transformer encoders
- **Threshold Correction**: Optimizes the classification threshold on validation sets rather than using default 0.5, improving balanced accuracy for imbalanced datasets
- **Data Augmentation for EEG**: Time Reverse and Masking augmentations increase robustness to temporal variations and missing data patterns in EEG recordings
- **Interquartile Range as Generalizability Metric**: Measures model consistency across cross-validation folds, providing a more complete assessment than median accuracy alone
- **Channel-wise Averaging for Missing Data**: Handles incomplete EEG recordings by averaging available channels, maintaining dataset size without introducing bias

## Architecture Onboarding

**Component Map:** EEG Windows -> Depthwise CNN Tokenizer -> Transformer Encoder -> Classification Head

**Critical Path:** Depthwise Convolutional Tokenizer -> Transformer Encoder Layers -> Global Pooling -> Classification Head

**Design Tradeoffs:** The depthwise tokenizer preserves channel-specific information but requires more parameters than standard tokenizers; using 2 transformer layers balances computational efficiency with learning capacity

**Failure Signatures:** Using standard convolutional tokenizers results in ~70-75% accuracy with high variance; data leakage via window splitting causes artificially high accuracy (>90%) with suspiciously low variance

**Three First Experiments:**
1. Implement the depthwise convolutional tokenizer with proper residual connections and verify token shape before transformer input
2. Test subject-wise splitting to ensure no windows from the same subject appear in both training and test sets
3. Apply threshold correction on validation sets and measure its impact on balanced accuracy

## Open Questions the Paper Calls Out

**Open Question 1:** How can temporal and spectral features be optimally integrated within the TransformEEG architecture to enhance generalizability?
- **Basis in paper:** [explicit] The discussion states it "would be of great clinical interest to assess whether combining both temporal and spectral information could further improve model generalizability," noting that the utilized time-domain approach does not explicitly extract mean power features
- **Why unresolved:** Preliminary attempts to add Power Spectral Density (PSD) branches via mid-fusion or cross-attention (Supplementary A.7.2) did not significantly improve performance, suggesting the optimal fusion strategy remains unidentified
- **What evidence would resolve it:** A modified TransformEEG architecture incorporating spectral features that demonstrates a statistically significant reduction in interquartile range and an increase in median balanced accuracy compared to the time-domain baseline

**Open Question 2:** Can reliable subject-level diagnosis be achieved by aggregating TransformEEG's window-level predictions?
- **Basis in paper:** [explicit] The authors state that "it is of greater clinical interest to determine whether the entire EEG originates from an individual with the target disease" and suggest "voting or aggregation procedures should be considered"
- **Why unresolved:** The preliminary analysis of aggregation procedures (Supplementary A.7.1) showed that while median accuracy improved, variability remained similar to window-level predictions and the number of outliers increased
- **What evidence would resolve it:** A rigorous evaluation of a voting or aggregation mechanism that results in higher subject-level balanced accuracy and lower variance compared to the current window-based evaluation method

**Open Question 3:** Is TransformEEG effective at differentiating between Parkinson's disease subtypes or stages of cognitive decline?
- **Basis in paper:** [explicit] The discussion notes that "Differentiating these subtypes is of great clinical importance" and suggests future work should investigate "deep learning approaches to automatically identify PD subcategories within a multi-class classification framework"
- **Why unresolved:** The current study utilized a binary classification task (PD vs. Healthy) due to the difficulty of integrating clinical metadata and the lack of standardized subtype labels in the aggregated datasets
- **What evidence would resolve it:** Successful training and evaluation of the model on a harmonized dataset labeled with specific PD subtypes (e.g., tremor-dominant vs. postural instability/gait disorder) showing robust multi-class performance

## Limitations
- The study relies on specific preprocessing and evaluation protocols that may not generalize to different EEG recording conditions
- The absolute performance numbers depend on exact implementation details of data preprocessing and hyperparameter tuning
- The evaluation focuses exclusively on PD detection and does not assess generalizability to other neurological conditions
- The study assumes the four datasets used are representative of PD populations, potentially missing sampling biases across different recording sites

## Confidence

**High Confidence:** The core architectural innovation (depthwise convolutional tokenizer) and its comparative performance against baseline models. The evaluation methodology using nested cross-validation with multiple datasets is well-specified and reproducible.

**Medium Confidence:** The absolute performance numbers (78.45% median balanced accuracy) which depend on exact data preprocessing steps and hyperparameter tuning that may vary between implementations.

**Medium Confidence:** The generalizability claims, as they are based on performance variance across 100 cross-validation splits but do not include external validation on completely independent datasets.

## Next Checks
1. Replicate the full N-LNSO cross-validation pipeline with the exact random seeds from the published code to verify the reported median balanced accuracy and IQR values
2. Implement the threshold correction algorithm with specified search bounds and granularity to confirm its contribution to the 1.65 percentage point accuracy improvement
3. Test TransformEEG on an independent EEG dataset not used in the original study to validate cross-dataset generalizability beyond the four harmonized datasets