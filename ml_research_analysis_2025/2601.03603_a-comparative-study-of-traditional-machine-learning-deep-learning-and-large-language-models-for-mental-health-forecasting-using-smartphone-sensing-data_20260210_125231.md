---
ver: rpa2
title: A Comparative Study of Traditional Machine Learning, Deep Learning, and Large
  Language Models for Mental Health Forecasting using Smartphone Sensing Data
arxiv_id: '2601.03603'
source_url: https://arxiv.org/abs/2601.03603
tags:
- health
- mental
- data
- forecasting
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper benchmarks three modeling approaches\u2014traditional\
  \ machine learning, deep learning, and large language models\u2014for forecasting\
  \ mental health states from smartphone sensing data. Using the longitudinal CES\
  \ dataset, it systematically compares models across feature granularities, temporal\
  \ windows, personalization, and class imbalance strategies."
---

# A Comparative Study of Traditional Machine Learning, Deep Learning, and Large Language Models for Mental Health Forecasting using Smartphone Sensing Data

## Quick Facts
- arXiv ID: 2601.03603
- Source URL: https://arxiv.org/abs/2601.03603
- Reference count: 40
- Primary result: Deep learning models, especially Transformers, achieve the best overall performance (Macro-F1 = 0.58) for mental health forecasting from smartphone sensing data.

## Executive Summary
This paper benchmarks three modeling approaches—traditional machine learning, deep learning, and large language models—for forecasting mental health states from smartphone sensing data. Using the longitudinal CES dataset, it systematically compares models across feature granularities, temporal windows, personalization, and class imbalance strategies. Deep learning models, especially Transformers, achieve the best overall performance (Macro-F1 = 0.58), while LLMs show weaker temporal modeling despite strong reasoning capabilities. Personalization substantially improves prediction, especially for severe mental health cases. The study highlights the importance of early forecasting, feature representation, and model-specific adaptations, laying the groundwork for adaptive, proactive, and human-centered mental health technologies.

## Method Summary
The study forecasts mental health severity (Normal, Mild, Moderate, Severe) using smartphone sensing data from the CES dataset (215 students, 35 behavioral features). Models evaluated include traditional ML (SVM, XGBoost), deep learning (LSTM, TCN, Transformer), and LLMs (Qwen, GPT) using In-Context Learning. Key innovations include user embeddings for personalization, Focal Loss for class imbalance, and feature aggregation strategies. The Transformer with user embeddings, Focal Loss, and (35-Dimension, Weekly) feature configuration achieved the highest Macro-F1 score of 0.58. Data was split at the user level (7:1:2) to prevent leakage.

## Key Results
- Deep learning models, particularly Transformers, outperform traditional ML and LLMs with Macro-F1 = 0.58
- Personalization via user embeddings significantly improves forecasting, especially for severe mental health states (+0.2894 to +0.3635 Macro-F1)
- LLMs perform better with In-Context Learning using similarity-based examples rather than PEFT
- Feature granularity matters: LLMs prefer weekly summaries while TCNs prefer daily data

## Why This Works (Mechanism)

### Mechanism 1: Personalization via User Embeddings
Integrating user-specific embeddings into deep learning models substantially improves forecasting performance, particularly for severe mental health states. The model learns a unique low-dimensional vector for each user ID, capturing individual behavioral baselines and allowing detection of deviations from a specific user's norm rather than a population average. This works because individual behavioral baselines exist and differ significantly enough that population-level models cannot capture them effectively without explicit identity features. Break condition: If the dataset had very few samples per user, the embeddings would likely overfit or fail to converge.

### Mechanism 2: Temporal Attention for Behavioral Dynamics
Transformer-based architectures outperform traditional ML and other DL architectures by better capturing nonlinear and long-range temporal dependencies in behavioral data. The self-attention mechanism dynamically weights the importance of different time steps, allowing the model to focus on specific past behavioral patterns that are predictive of future mental health while ignoring noise from irrelevant time steps. This works because mental health states are preceded by temporal patterns in behavior that require global context beyond what sequential or local models might miss. Break condition: If behavioral data is extremely sparse or the look-back window is very short, the attention mechanism has insufficient context to form weighted relationships.

### Mechanism 3: LLM In-Context Learning for Numerical Reasoning
LLMs forecast better when using In-Context Learning (ICL) with similarity-based examples compared to Parameter-Efficient Fine-Tuning (PEFT). Converting numerical sensor data into text tables and providing the LLM with "similar" historical examples helps the model ground its reasoning by using the provided examples as a "reference lookup" to classify new data, bypassing its weakness in raw numerical computation. This works because LLMs possess sufficient reasoning capabilities to map semantic descriptions of behavior to mental health states if given context, even if they struggle with raw numerical encoding. Break condition: If text serialization exceeds the LLM's context window or if similar examples are misleading, the reasoning chain will likely break.

## Foundational Learning

- **Concept: User-level Data Partitioning**
  - **Why needed here:** The paper uses a 7:1:2 split based on *users*, not just samples, to prevent "data leakage" where a model sees a user's future behavior during training and falsely appears to perform well.
  - **Quick check question:** If you randomly split the rows of the CES dataset without grouping by user ID, what specific artifact would you introduce into your evaluation?

- **Concept: Class Imbalance (Focal Loss vs. Weighted Loss)**
  - **Why needed here:** The dataset is heavily skewed (Normal: 62%, Moderate: 7%), and standard loss functions optimize for the majority class.
  - **Quick check question:** Why does Focal Loss work better for high-capacity models like Transformers compared to simple Weighted Cross-Entropy in this study?

- **Concept: Feature Granularity (Daily vs. Weekly)**
  - **Why needed here:** Different models have different noise tolerances; LLMs prefer weekly summaries to reduce noise while TCNs prefer daily data.
  - **Quick check question:** Based on the paper, which model architecture would likely fail if you only provided highly volatile, fine-grained daily data, and why?

## Architecture Onboarding

- **Component map:** Data Cleaning -> Feature Selection (35 features) -> User Splitting (Critical to avoid leakage) -> Model Training (Transformer with User Embeddings + Focal Loss)
- **Critical path:** 1. Data Cleaning -> Feature Selection (35 features), 2. **User Splitting** (Critical to avoid leakage), 3. Model Training (Transformer with User Embeddings + Focal Loss)
- **Design tradeoffs:**
  - Accuracy vs. Interpretability: Transformers offer highest Macro-F1 (0.58) but are black boxes; Logistic Regression is interpretable but performs poorly on severe cases
  - Granularity vs. Noise: Daily data improves TCNs (local patterns) but degrades LLMs (token limits/noise); Weekly aggregation aids LLMs but may smooth out crucial spikes needed for TCN
- **Failure signatures:**
  - Majority Class Collapse: High Accuracy (~80%) but Macro-F1 near 0.2-0.3; the model predicts "Normal" for everyone
  - LLM Hallucination: The LLM ignores the provided sensor table and fabricates a mental health status based on training bias
- **First 3 experiments:**
  1. **Baseline Test:** Train a Logistic Regression and a Transformer on the (35-Dimension, Weekly) setting without personalization to verify the Transformer gain (expect ~0.08 Macro-F1 difference)
  2. **Personalization Ablation:** Add User Embeddings to the Transformer. Verify if the Severe class F1-score improves by >0.3 as reported
  3. **Loss Function Comparison:** Swap Cross-Entropy for Focal Loss in the Transformer. Check if the gap between Accuracy and Macro-F1 narrows, indicating better handling of the minority (Severe) class

## Open Questions the Paper Calls Out

- **Can hybrid architectures combining deep learning for quantitative forecasting and large language models (LLMs) for semantic reasoning yield synergistic effects in mental health forecasting?**
  - The study evaluated modeling approaches in isolation, with DL models achieving highest quantitative performance (Macro-F1 = 0.58) and LLMs showing moderate accuracy but strong reasoning. The potential performance of combining these strengths was not tested.

- **How can LLMs be adapted to effectively capture personalized behavioral trajectories, given that simple user identifiers in prompts fail to provide meaningful personalization?**
  - Table 4 shows adding user IDs to LLM prompts resulted in minimal or negative performance changes. Section 5.8 notes this "points toward the need for memory-augmented or history-aware LLMs."

- **Does extending smartphone sensing models to incorporate textual, physiological, and social context signals (multimodal integration) significantly improve generalization and holistic assessment?**
  - The discussion section lists "Toward Multimodal Integration" as a future direction, suggesting that current results "lay a foundation" but extending to these signals "may further enhance generalization."

## Limitations
- The study was limited to smartphone sensing data (behavioral features like mobility and sleep) and did not validate whether superior performance holds when integrating additional modalities
- Exact hyperparameters, architecture details, and LLM prompt templates were not fully specified, potentially limiting exact reproduction
- The dataset, while longitudinal, may not capture all relevant behavioral indicators of mental health states

## Confidence
- High: The experimental methodology is sound with appropriate user-level splitting to prevent data leakage
- Medium: Results are based on a specific dataset (CES) that may not generalize to all populations
- Low: Some implementation details (hyperparameters, LLM prompts) were not fully specified

## Next Checks
1. Verify user-level data splitting is correctly implemented to prevent data leakage before training any models
2. Test Focal Loss implementation on a Transformer model to confirm it addresses class imbalance better than Weighted Cross-Entropy
3. Compare model performance across different feature granularities (daily vs. weekly) to validate the reported architecture-specific preferences