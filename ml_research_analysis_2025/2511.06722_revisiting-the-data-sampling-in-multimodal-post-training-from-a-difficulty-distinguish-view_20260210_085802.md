---
ver: rpa2
title: Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish
  View
arxiv_id: '2511.06722'
source_url: https://arxiv.org/abs/2511.06722
tags:
- grpo
- arxiv
- reasoning
- visual
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of effective data sampling
  for multimodal post-training, specifically focusing on how to identify and utilize
  samples of varying difficulty levels to improve both perception and reasoning capabilities
  in Multimodal Large Language Models (MLLMs). The authors propose two novel difficulty-aware
  sampling strategies: Progressive Image Semantic Masking (PISM), which quantifies
  sample hardness through systematic image degradation, and Cross-Modality Attention
  Balance (CMAB), which assesses cross-modal interaction complexity via attention
  distribution analysis.'
---

# Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View

## Quick Facts
- arXiv ID: 2511.06722
- Source URL: https://arxiv.org/abs/2511.06722
- Reference count: 8
- Key outcome: GRPO-only training on difficulty-stratified samples (medium+hard) outperforms SFT+GRPO pipelines across six multimodal benchmarks

## Executive Summary
This paper addresses the challenge of effective data sampling for multimodal post-training by proposing two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) and Cross-Modality Attention Balance (CMAB). The authors demonstrate that strategically filtering training data based on sample difficulty can replace traditional supervised fine-tuning (SFT) while improving model performance. Their results show that GRPO-only training applied to medium and hard samples consistently outperforms conventional SFT+GRPO pipelines across visual perception and reasoning tasks, with MathVista scores reaching 68.3 versus 53.4 for full-set GRPO.

## Method Summary
The authors propose a difficulty-aware sampling framework that uses PISM to quantify sample hardness through controlled visual degradation and CMAB to assess cross-modal interaction complexity via attention distribution analysis. PISM applies random pixel masking at increasing ratios and identifies failure thresholds where model accuracy drops below a specified threshold. CMAB analyzes attention distributions across layers and tokens to determine whether both modalities are necessary for correct responses. Using these metrics, they stratify samples into difficulty categories and apply GRPO-only training to medium+hard subsets, comparing against traditional SFT+GRPO pipelines across six benchmark datasets.

## Key Results
- GRPO-only training on medium+hard samples achieves 69.0 on MathVista (PISM) versus 53.4 for full-set GRPO
- For visual perception tasks like OCRBench, GRPO-only achieves 77.8, surpassing all SFT+GRPO variants
- HBench scores reach 69.7 for GRPO-only (mid+hard), outperforming SFT+GRPO configurations
- The findings demonstrate that strategic data sampling can replace supervised fine-tuning while improving model accuracy

## Why This Works (Mechanism)

### Mechanism 1: PISM — Progressive Image Semantic Masking
PISM quantifies sample difficulty by measuring model sensitivity to controlled visual degradation. For each image-text pair, random pixel masking is applied at increasing ratios λ ∈ {0.0, 0.1, …, 0.9}. The model's correctness Pc(λ) is computed across K=10 independent mask realizations, and the failure threshold λ*_s is identified where accuracy drops below τ=0.1. Samples failing at low masking (λ*_s ≤ 0.4) are classified as "hard," while those robust to high masking (λ*_s ≥ 0.7) are "easy." This mechanism assumes visual dependence correlates with task complexity for multimodal samples.

### Mechanism 2: CMAB — Cross-Modality Attention Balance
CMAB assesses cross-modal interaction complexity by analyzing attention distribution during generation. For each generated token, attention to image versus text tokens is computed across layers 2 to L-1. The attention ratio ρ(l,t) = S_img/S_txt is calculated, then geometrically averaged across layers and arithmetically averaged across tokens to obtain ρ̄. Balanced attention (0.4 ≤ ρ̄ ≤ 1.6) indicates both modalities are necessary, classifying samples as "hard," while extreme values suggest single-modality dominance and "easy" classification.

### Mechanism 3: GRPO-Only Training on Difficulty-Stratified Samples
GRPO-only training on medium+hard samples outperforms SFT→GRPO pipelines by concentrating the learning signal on samples requiring genuine cross-modal reasoning. Filtering to mid+hard samples reduces gradient dilution from easy samples and avoids reward noise from unsolved samples. The approach leverages GRPO's direct reinforcement of correct reasoning paths via reward, avoiding the "Pseudo-CoT" pattern-matching induced by SFT templates.

## Foundational Learning

- **Concept**: Group Relative Policy Optimization (GRPO)
  - **Why needed**: GRPO is the core RL algorithm; understanding group-based advantage estimation is essential to diagnose training dynamics
  - **Quick check**: Can you explain how GRPO estimates advantage without a separate critic, and why group size matters?

- **Concept**: Cross-Attention in Transformer Decoders
  - **Why needed**: CMAB relies on interpreting cross-attention weights; misunderstanding layer roles or aggregation can invalidate difficulty estimates
  - **Quick check**: How does cross-attention differ from self-attention in a decoder, and which layers typically encode cross-modal fusion?

- **Concept**: Curriculum / Difficulty-Aware Sampling
  - **Why needed**: The paper's central thesis is that data hardness filtering replaces SFT; knowing when/why curriculum learning works helps assess generalizability
  - **Quick check**: What failure modes occur if you train only on hard samples without any easy warm-up?

## Architecture Onboarding

- **Component map**: Data Curation Pipeline (PISM/CMAB → sample classification) → Training Orchestrator (filter mid+hard → GRPO-only/SFT+GRPO) → GRPO Trainer (Swift framework implementation) → Evaluation Harness (OpenCompass on 6 benchmarks)

- **Critical path**: PISM/CMAB difficulty scoring → sample filtering → GRPO-only training on mid+hard → benchmark evaluation

- **Design tradeoffs**: PISM requires 10×10 forward passes per sample (computationally expensive but modality-agnostic); CMAB requires attention extraction hooks (lower compute but architecture-specific); GRPO-only avoids SFT overhead but may be unstable on sparse-reward tasks

- **Failure signatures**: Flat Pc(λ) curve → PISM yields no difficulty separation; all ρ̄ clustered at extremes → CMAB threshold calibration failed; GRPO loss divergence on mid+hard → reward sparsity or hyperparameter mismatch

- **First 3 experiments**:
  1. **PISM sanity check**: Run PISM on 500 samples; visualize Pc(λ) curves for manually labeled easy/hard cases. Verify λ*_s correlates with human intuition
  2. **CMAB attention profiling**: Extract ρ̄ for 500 samples across tasks (OCR, math, VQA). Check distribution spread and validate threshold boundaries
  3. **GRPO-only ablation**: Train a small model (e.g., 1B parameters) on mid+hard vs. random subset for 1 epoch on MathVista. Compare accuracy delta to confirm signal before scaling

## Open Questions the Paper Calls Out

### Open Question 1
Can PISM and CMAB metrics be unified into a single difficulty scoring function, and would such integration improve sample stratification over using either metric alone? The authors note the metrics are "complementary" yet keep them separate throughout experiments without combining them.

### Open Question 2
What theoretical or empirical principles should guide the selection of difficulty thresholds (λ values for PISM; ρ boundaries for CMAB), rather than ad-hoc specification? The specific values used appear arbitrary without justification.

### Open Question 3
Do the findings that GRPO-only outperforms SFT+GRPO generalize across different MLLM architectures, parameter scales, and base model families? All experiments use only Qwen2.5VL-7B, limiting claims about paradigm generalizability.

### Open Question 4
Could "unsolved" samples provide value through curriculum learning or progressive difficulty scheduling, rather than exclusion? These samples are defined and excluded from difficulty assessment but their potential utility remains untested.

## Limitations
- PISM's computational expense (10×10 forward passes per sample) may limit scalability to larger datasets
- CMAB's reliability depends on attention patterns truly reflecting reasoning complexity rather than architectural artifacts
- Results may not generalize to other model families, task domains, or reward structures
- Evaluation focuses on specific benchmarks without addressing potential overfitting or long-tail generalization

## Confidence

- **High confidence**: The effectiveness of difficulty stratification using PISM (visual perturbation-based) for identifying sample hardness; this mechanism is well-grounded in perturbation theory and supported by related work
- **Medium confidence**: The superiority of GRPO-only over SFT+GRPO pipelines for the specific task combinations tested; while results are strong, the mechanism for why SFT is not beneficial needs more exploration
- **Medium confidence**: The CMAB attention-balance metric as a reliable indicator of cross-modal reasoning complexity; this is the weakest mechanistically supported component and lacks direct validation in the corpus
- **Low confidence**: Claims about the general applicability of these findings to other model sizes, architectures, or task domains without additional empirical support

## Next Checks

1. **Cross-dataset generalization test**: Apply PISM and CMAB sampling strategies to a completely different multimodal dataset (e.g., ScienceQA or GQA) and verify whether the same GRPO-only superiority pattern holds

2. **Attention pattern validation**: Conduct detailed analysis of CMAB's attention distribution predictions by correlating ρ̄ values with human-labeled reasoning complexity across diverse sample types

3. **Reward function ablation study**: Systematically vary the reward design (sparse vs dense, different shaping functions) in GRPO-only training to determine the minimum viable reward structure that still enables SFT-free training to outperform SFT+GRPO