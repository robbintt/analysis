---
ver: rpa2
title: Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation
arxiv_id: '2509.19592'
source_url: https://arxiv.org/abs/2509.19592
tags:
- maskgit
- codebooks
- frame
- stacking
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of efficient multi-codebook speech
  generation in LLM-based TTS systems. It introduces frame-stacked local transformers
  that combine an autoregressive or MaskGIT-based local transformer with frame stacking
  to improve speed without compromising perceptual quality.
---

# Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation

## Quick Facts
- arXiv ID: 2509.19592
- Source URL: https://arxiv.org/abs/2509.19592
- Reference count: 0
- The paper introduces frame-stacked local transformers achieving 2.1x faster throughput than baseline while maintaining or improving speaker similarity, neural MOS, and Fréchet Distance

## Executive Summary
This paper addresses the efficiency challenge in LLM-based TTS systems by introducing frame-stacked local transformers that combine autoregressive or MaskGIT-based local transformer architectures with frame stacking. The approach achieves 2.1x faster throughput compared to baseline autoregressive models while maintaining or improving perceptual quality across multiple metrics including speaker similarity, neural MOS, and Fréchet Distance. The method demonstrates superior performance over parallel prediction approaches across all evaluated metrics.

## Method Summary
The authors propose a hybrid architecture that combines frame stacking with local transformer mechanisms to accelerate speech generation in multi-codebook TTS systems. The approach operates by processing speech frames in stacked configurations using either autoregressive or MaskGIT-based local transformers, reducing computational overhead while preserving sequence coherence. Frame stacking enables batch processing of multiple frames simultaneously, while the local transformer architecture constrains attention mechanisms to improve efficiency. The system maintains compatibility with existing multi-codebook frameworks while delivering substantial throughput improvements.

## Key Results
- Achieved 2.1x faster throughput compared to baseline autoregressive models
- Maintained or improved speaker similarity scores across evaluation conditions
- Outperformed parallel prediction methods across all perceptual quality metrics including neural MOS and Fréchet Distance

## Why This Works (Mechanism)
The efficiency gains stem from combining frame stacking with local transformer constraints. Frame stacking allows simultaneous processing of multiple adjacent frames, reducing sequential dependencies and enabling better parallelization. The local transformer architecture limits attention scope to neighboring frames rather than full sequences, dramatically reducing computational complexity from quadratic to linear in sequence length. This combination preserves essential temporal dependencies while eliminating redundant computations inherent in full-sequence attention mechanisms.

## Foundational Learning
- **Multi-codebook TTS systems**: Why needed - these systems separate different aspects of speech (content, prosody, speaker identity) into distinct codebooks for better control and quality. Quick check - verify codebook cardinality and cross-codebook dependencies.
- **Frame stacking in speech processing**: Why needed - enables temporal context aggregation and computational efficiency by processing multiple frames as units. Quick check - validate frame stacking window size and overlap parameters.
- **Local transformer architectures**: Why needed - constrain attention to local neighborhoods to reduce complexity while maintaining essential dependencies. Quick check - examine attention mask patterns and locality constraints.
- **Autoregressive vs parallel prediction**: Why needed - understanding trade-offs between sequential generation quality and parallel processing speed. Quick check - compare generation latency and quality metrics across approaches.
- **MaskGIT for sequence generation**: Why needed - diffusion-based approach offering different trade-offs than autoregressive methods. Quick check - validate noise schedule and sampling parameters.
- **Fréchet Distance for speech quality**: Why needed - measures distribution similarity between generated and reference speech features. Quick check - verify feature extraction and statistics computation.

## Architecture Onboarding

Component Map:
Multi-codebook features -> Frame stacking layer -> Local transformer (autoregressive/MaskGIT) -> Output projection -> Speech waveform

Critical Path:
Input codebook features are stacked into frame groups, processed through constrained local attention mechanisms, then projected back to individual frame representations for waveform synthesis.

Design Tradeoffs:
- Frame stack size vs. computational efficiency: Larger stacks improve throughput but may reduce fine-grained temporal control
- Attention locality radius vs. generation quality: Tighter constraints improve speed but may limit long-range dependencies
- Autoregressive vs. MaskGIT: Autoregressive provides better quality consistency while MaskGIT offers better parallelization potential

Failure Signatures:
- Excessive frame stacking causing artifacts in rapid speech transitions
- Overly constrained attention leading to unnatural prosody or timing issues
- MaskGIT mode collapse under certain noise schedule configurations

First Experiments:
1. Baseline comparison: Run standard autoregressive multi-codebook TTS with identical hyperparameters
2. Frame stacking ablation: Test different stack sizes (2, 4, 8 frames) to find optimal throughput-quality balance
3. Attention locality sweep: Vary local transformer window sizes to quantify quality vs. speed trade-offs

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Evaluation limited to English datasets with clean speech conditions, leaving performance on noisy environments, accented speech, and low-resource languages untested
- MaskGIT variant shows inconsistent results across metrics, suggesting unresolved architectural trade-offs
- Limited comparison against other efficient TTS paradigms like diffusion models or parallel vocoders

## Confidence
High confidence in throughput measurements and quantitative metric improvements.
Medium confidence in perceptual quality claims due to limited acoustic diversity in evaluation.
Low confidence in generalization across languages and acoustic conditions.

## Next Checks
1. Evaluate the frame-stacked local transformer approach on multi-lingual datasets with varying acoustic conditions (noisy environments, accented speech, low-resource languages).
2. Conduct comprehensive head-to-head comparisons against state-of-the-art diffusion-based TTS systems and parallel vocoders under identical hardware constraints.
3. Perform ablation studies isolating the individual contributions of frame stacking versus local transformer architecture to determine optimal configuration parameters for different use cases.