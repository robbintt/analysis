---
ver: rpa2
title: 'FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation'
arxiv_id: '2503.23257'
source_url: https://arxiv.org/abs/2503.23257
tags:
- adaptation
- fisher
- recognition
- expression
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of robust facial expression
  recognition in unconstrained environments, where domain shifts between training
  and testing distributions significantly degrade performance. The authors propose
  a Fisher Information-based Efficient Selective Test-time Adaptation (FIESTA) framework
  that dynamically identifies and updates only the most critical model parameters
  based on their importance as quantified by Fisher information.
---

# FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation

## Quick Facts
- arXiv ID: 2503.23257
- Source URL: https://arxiv.org/abs/2503.23257
- Reference count: 40
- Primary result: Achieves 7.7% F1 improvement over base model while adapting only 22,000 parameters on AffWild2 benchmark

## Executive Summary
This paper addresses domain shift in video-based facial expression recognition by proposing a Fisher Information-based Efficient Selective Test-time Adaptation (FIESTA) framework. The method dynamically identifies and updates only the most critical model parameters during inference, using Fisher information to quantify parameter importance. By integrating this selective adaptation with temporal consistency constraints, FIESTA achieves significant performance improvements while dramatically reducing computational overhead compared to existing test-time adaptation methods.

## Method Summary
FIESTA operates by first training a SE-ResNeXt-101 backbone on combined FER datasets using LDAM loss to handle class imbalance. During test-time adaptation, the framework computes diagonal Fisher scores for each parameter by sampling 1-3 frames from videos, generating pseudo-labels, and backpropagating cross-entropy gradients. The top-k% weights are selected for adaptation (0.2% for all layers, 5% for early layers). Temporal smoothing is applied through median filtering over sliding windows, minimizing L2 loss between raw and filtered logits. Adaptation proceeds for 4 gradient steps using AdamW with learning rate 0.0001, updating only the Fisher-selected parameters.

## Key Results
- Achieves 7.7% improvement in macro F1 score (0.325 → 0.350) over base model on AffWild2 validation
- Adapts only 22,000 parameters compared to TENT's ~400,000 parameters (20x reduction)
- Outperforms TENT baseline by 7.7% while using significantly fewer parameters
- Maintains consistent performance improvements across different domain shift scenarios

## Why This Works (Mechanism)
The effectiveness stems from selectively updating only parameters with high Fisher information, which represent the most sensitive and influential components for the current task distribution. By focusing adaptation on these critical parameters rather than all weights, FIESTA reduces computational cost while maintaining or improving performance. The temporal consistency constraint further enhances stability by smoothing predictions across video frames, preventing overfitting to individual frames while preserving temporal coherence.

## Foundational Learning
- Fisher Information: Measures parameter sensitivity to data likelihood changes. Needed to identify which parameters most influence model predictions and should be adapted.
- Quick check: Compute Fisher scores for a simple logistic regression model and verify they identify weights with highest impact on predictions.

- Test-time Adaptation: Dynamic model adjustment during inference without retraining. Needed to handle domain shifts between training and test distributions.
- Quick check: Implement entropy minimization adaptation on a CIFAR-10 model and verify performance improvement on CIFAR-10-C corruptions.

- LDAM Loss: Label-distribution-aware margin loss for imbalanced datasets. Needed to handle the severe class imbalance in FER datasets where some emotions occur far more frequently.
- Quick check: Train a classifier on imbalanced data with both CE and LDAM loss and verify LDAM better handles minority classes.

## Architecture Onboarding

Component map: Input Frames -> SE-ResNeXt-101 Backbone -> Pseudo-label Generation -> Fisher Score Computation -> Parameter Selection -> Temporal Smoothing Loss -> Parameter Update

Critical path: Frame sampling → pseudo-label generation → Fisher scoring → parameter selection → temporal smoothing adaptation → performance evaluation

Design tradeoffs: Selective adaptation (22k parameters) vs. full adaptation (400k parameters) balances computational efficiency against potential performance gains. Single-frame scoring vs. multi-frame averaging trades estimation accuracy against computational cost.

Failure signatures: Performance degradation occurs when averaging Fisher scores across 5-15 frames (vs. 1-3 frames), suggesting dilution effect or increased noise. TENT baseline degrades by 17.2%, indicating that simple entropy minimization without selection can be harmful.

First experiments: 1) Verify baseline F1 score of 0.325 on AffWild2 validation without adaptation. 2) Implement Fisher scoring and confirm that updating only selected weights improves performance vs. no adaptation. 3) Test temporal smoothing with different frame sampling rates to confirm 1-3 frames optimal.

## Open Questions the Paper Calls Out

Open Question 1: Can the percentage threshold for Fisher-based weight selection be dynamically adjusted based on quantifiable domain shift characteristics? The current fixed thresholds (0.2% for all layers, 5% for early layers) lack a principled mechanism for adaptation to different test conditions.

Open Question 2: What is the underlying mechanism causing Fisher score averaging across multiple frames to degrade performance relative to single-frame estimation? The counterintuitive finding lacks theoretical justification despite only a heuristic "dilution effect" explanation.

Open Question 3: How does the Fisher-based selection strategy generalize to non-video test-time adaptation settings where temporal consistency cannot be exploited? The method's tight coupling with temporal smoothing makes it unclear whether gains come from selection, consistency, or their interaction.

Open Question 4: Does FIESTA transfer effectively to architectures beyond SE-ResNeXt backbones, particularly vision transformers or lightweight mobile architectures? The framework's assumptions about parameter distributions and normalization schemes may not generalize.

## Limitations
- Fixed parameter selection thresholds lack principled mechanism for dynamic adjustment to varying domain characteristics
- Heavy reliance on temporal consistency makes framework less applicable to static image adaptation scenarios
- Limited evaluation to single architecture (SE-ResNeXt-101) raises questions about generalizability across model families

## Confidence

| Claim | Confidence |
|-------|------------|
| 7.7% F1 improvement over base model | Medium |
| 20x reduction in adapted parameters vs. TENT | Medium |
| Single-frame Fisher scoring outperforms multi-frame averaging | Medium |
| Temporal smoothing essential for adaptation success | Medium |

## Next Checks

1. Reproduce base SE-ResNeXt-101 model training with LDAM loss on combined dataset and verify baseline F1 score of 0.325 on AffWild2 validation.

2. Implement Fisher information calculation and parameter selection, then verify that updating only ~22k parameters yields the claimed performance while TENT (updating all parameters) degrades performance by 17.2%.

3. Test the temporal smoothing adaptation with different frame sampling rates (1-3 vs 5-15 frames) to confirm that performance degrades with more frames as reported.