---
ver: rpa2
title: 'TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for
  Enhancing Cross-Subject Motor Imagery Classification'
arxiv_id: '2507.02510'
source_url: https://arxiv.org/abs/2507.02510
tags:
- classification
- dataset
- accuracy
- stft
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents TFOC-Net, a novel approach for enhancing cross-subject
  motor imagery (MI) classification in brain-computer interfaces (BCIs) using EEG
  signals. The method addresses the challenge of inter-subject variability in EEG
  patterns by employing direct classification of Short-Time Fourier Transform (STFT)-transformed
  EEG data, optimized STFT parameters, and a balanced batching strategy during training
  of a Convolutional Neural Network (CNN).
---

# TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification

## Quick Facts
- arXiv ID: 2507.02510
- Source URL: https://arxiv.org/abs/2507.02510
- Authors: Ahmed G. Habashi; Ahmed M. Azab; Seif Eldawlatly; Gamal M. Aly
- Reference count: 40
- Primary result: Novel approach achieves significant improvements in cross-subject motor imagery classification accuracy using optimized STFT parameters and balanced batching strategy.

## Executive Summary
This paper presents TFOC-Net, a novel approach for enhancing cross-subject motor imagery (MI) classification in brain-computer interfaces (BCIs) using EEG signals. The method addresses the challenge of inter-subject variability in EEG patterns by employing direct classification of Short-Time Fourier Transform (STFT)-transformed EEG data, optimized STFT parameters, and a balanced batching strategy during training of a Convolutional Neural Network (CNN). The approach is validated across four datasets, including three benchmark datasets and a newly recorded EEG dataset. The results demonstrate significant improvements in cross-subject classification accuracy, achieving 67.60% on the BCI Competition IV Dataset 1 (IV-1), 65.96% on Dataset 2A (IV-2A), and 80.22% on Dataset 2B (IV-2B), outperforming state-of-the-art techniques. Additionally, the study investigates the classification performance using MI windows ranging from the full 4-second window to 1-second windows, providing insights into optimal time segments for feature extraction. The proposed method contributes to the development of calibration-free BCIs suitable for real-world applications.

## Method Summary
TFOC-Net addresses cross-subject MI classification by transforming EEG signals using Short-Time Fourier Transform with optimized parameters (256-point window, 50% overlap), then directly classifying the raw STFT magnitude matrix with a VGG-style CNN. The method employs a balanced batching strategy during training to ensure equal representation of all subjects in each batch, preventing overfitting to subject-specific features. The architecture uses a series of 3×3 convolutional layers with max pooling and dropout, optimized for the 2D time-frequency representation of EEG data. The approach is evaluated using strict Leave-One-Subject-Out cross-validation across multiple benchmark datasets, demonstrating significant improvements over existing methods while maintaining the goal of creating calibration-free BCI systems.

## Key Results
- Achieves 67.60% cross-subject classification accuracy on BCI Competition IV Dataset 1 (IV-1)
- Achieves 65.96% cross-subject classification accuracy on BCI Competition IV Dataset 2A (IV-2A)
- Achieves 80.22% cross-subject classification accuracy on BCI Competition IV Dataset 2B (IV-2B)
- Outperforms state-of-the-art techniques on all benchmark datasets
- Demonstrates effectiveness of 50% STFT overlap for capturing transient motor imagery events

## Why This Works (Mechanism)

### Mechanism 1: Direct Classification of Raw STFT Matrix
Previous methods converted STFT outputs into fixed-size images (e.g., 32×32), which requires resizing or quantization. TFOC-Net uses the raw STFT matrix directly as a 2D input. This retains the precise resolution of frequency bins and time points, preventing the discarding of subtle transient neural features before they reach the classifier. The discriminative motor imagery features exist in fine-grained time-frequency details that are destroyed by standard image resizing algorithms.

### Mechanism 2: High STFT Overlap for Temporal Continuity
Increasing the overlap between consecutive STFT windows (e.g., to 50%) produces a denser time-frequency representation. This reduces the "jump" between time steps, smoothing the temporal trajectory of spectral features and making transient motor imagery events easier for the CNN to detect compared to minimal overlap. The optimization of the time-resolution vs. frequency-resolution trade-off favors denser temporal sampling for these specific MI tasks.

### Mechanism 3: Balanced Batching as Regularization
By ensuring every training batch contains an equal distribution of data from all training subjects, the model is forced to learn features common to multiple subjects simultaneously. This prevents the gradient descent from settling on local minima that favor the idiosyncrasies of a dominant subject in an imbalanced batch. Features common across subjects exist and can be isolated by preventing subject-specific overfitting during batch updates.

## Foundational Learning

- **Concept: Short-Time Fourier Transform (STFT) Parameters**
  - Why needed here: The paper's core innovation relies on tuning the `n_fft` (window size) and `hop_length` (overlap). Without understanding the trade-off between time and frequency resolution, one cannot replicate the "Optimized STFT" component.
  - Quick check question: If I double the overlap (hop length = N/2), do I get better frequency resolution or better time continuity? (Answer: Time continuity/density; frequency resolution is fixed by window size).

- **Concept: VGG-style CNNs (Small Kernels)**
  - Why needed here: The classifier stacks multiple 3×3 convolutional layers. You must understand why small filters (3×3) are stacked rather than using one large filter to capture the time-frequency features effectively.
  - Quick check question: Why does stacking three 3×3 conv layers provide a Receptive Field of 7×7? (Answer: Sequential convolution adds receptive field sizes: 3 → 5 → 7).

- **Concept: Leave-One-Subject-Out (LOSO) Validation**
  - Why needed here: The results are entirely based on LOSO. Understanding this is critical to distinguishing "Calibration-Free" (true LOSO) from "Transfer Learning" (fine-tuning on target data).
  - Quick check question: In a dataset with 9 subjects, how many models are trained and evaluated in a LOSO scheme? (Answer: 9 models; each trained on 8, tested on 1).

## Architecture Onboarding

- **Component map**: EEG signals → Butterworth filter (8–30Hz) → STFT (256-point window, 50% overlap) → Magnitude matrix → Reshape to (Frequency Bins, Time Points × 3 Channels) → VGG-style CNN → Classification output

- **Critical path**:
  1. Preprocessing: The specific reshaping of the STFT matrix (interleaving channels with time points) is non-standard and critical. Do not treat channels as the image "depth" (RGB-like); treat them as part of the width dimension.
  2. Batching: Ensure the dataloader samples strictly evenly from all training subjects per batch.

- **Design tradeoffs**:
  - Memory vs. Resolution: 50% overlap doubles the time-dimension size of the input matrix, increasing GPU VRAM usage.
  - Generality vs. Accuracy: Strict LOSO (no target data) lowers absolute accuracy compared to fine-tuning methods but enables "zero-calibration" deployment.

- **Failure signatures**:
  - Accuracy Collapse (~50%): Likely failed to reshuffle STFT output correctly or input shape is wrong (e.g., feeding complex numbers instead of magnitude).
  - High Variance in Validation: The model overfits to training subjects. Fix: Check Balanced Batching implementation; if correct, increase Dropout rates.
  - Slow Convergence: RMSprop might be unstable with the initial learning rate; check if STFT values are normalized (scaling helps convergence).

- **First 3 experiments**:
  1. Ablation 1 (Input Format): Train on STFT-converted-to-Image (32×32) vs. Raw STFT Matrix. Verify the "Direct Classification" gain.
  2. Ablation 2 (Overlap): Compare Minimal Overlap vs. 50% Overlap on the IV-2B dataset (where the paper shows the highest gain).
  3. Ablation 3 (Batching): Run LOSO with random (imbalanced) batching vs. Balanced Batching. Plot the training loss curve to observe if balanced batching smooths the gradient descent.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the integration of advanced artifact removal techniques (e.g., EOG/EMG denoising) further enhance the classification accuracy of TFOC-Net in calibration-free scenarios?
- Basis in paper: The Conclusion states, "Future work will focus on exploring additional preprocessing techniques, such as artifact removal and feature selection, to further enhance the quality of EEG signals."
- Why unresolved: The current study relies on standard Butterworth bandpass filtering but does not implement specific algorithms to remove physiological artifacts, which are a major source of noise in real-world EEG recordings.
- What evidence would resolve it: A comparative analysis showing performance gains when applying automated artifact rejection (like Autoreject or ICA) to the input data of TFOC-Net versus the current baseline.

### Open Question 2
- Question: Does the TFOC-Net architecture maintain its efficacy when applied to other BCI paradigms, such as P300 or SSVEP?
- Basis in paper: The Conclusion outlines a plan to "investigate the application of our approach to other BCI paradigms... aiming to develop truly user-friendly and adaptive BCI systems."
- Why unresolved: The optimized STFT parameters and CNN architecture were tuned specifically for the time-frequency characteristics of motor imagery (ERD/ERS), which differ fundamentally from the evoked potentials found in P300 or SSVEP tasks.
- What evidence would resolve it: Benchmark results from applying the TFOC-Net pipeline directly to popular P300 or SSVEP datasets, demonstrating cross-subject accuracy comparable to current motor imagery results.

### Open Question 3
- Question: Can the computational overhead caused by the high STFT overlap be optimized to meet the strict latency requirements of real-time, online BCI applications?
- Basis in paper: The Discussion notes that increasing the STFT overlap to 50% led to better results but "increases computation significantly compared to minimal overlap."
- Why unresolved: While 50% overlap improves accuracy by capturing finer temporal details, the increased processing time per trial may introduce latency that hinders the "real-world applications" and "neurofeedback" the authors aim to support.
- What evidence would resolve it: A system latency analysis measuring the end-to-end processing time of TFOC-Net with 50% overlap to ensure it remains within the real-time constraints (e.g., <100ms delay) required for responsive BCI control.

### Open Question 4
- Question: Is the proposed balanced batching strategy sufficient for generalizing to multi-class motor imagery tasks (beyond binary classification)?
- Basis in paper: The Methodology section notes that the study excluded the foot and tongue classes from Dataset 2A to "keep consistency," limiting the validation to binary (left vs. right hand) classification.
- Why unresolved: The current model uses a 2-unit softmax output, and it is unclear if the direct STFT features and balanced batching can disambiguate the more subtle differences required for 4-class classification without subject-specific calibration.
- What evidence would resolve it: Results from training and evaluating TFOC-Net on the full 4-class BCI Competition IV Dataset 2A using the same LOSO cross-validation approach.

## Limitations
- The paper does not specify how STFT magnitude values are normalized before CNN input, which could significantly affect model convergence and performance.
- Channel concatenation ordering in the input reshaping step is described but lacks implementation details.
- No code repository is provided for verification against the claimed architecture and implementation.

## Confidence

- **High Confidence**: The core methodology of using raw STFT matrices with optimized parameters (50% overlap) and balanced batching strategy is well-supported by the ablation results and ablation experiments.
- **Medium Confidence**: The reported cross-subject classification accuracies (67.60% on IV-1, 65.96% on IV-2A, 80.22% on IV-2B) are promising but should be validated through independent reproduction due to the complexity of the LOSO validation scheme.
- **Low Confidence**: The generalization of these results to other MI tasks beyond left/right hand movement remains untested.

## Next Checks

1. **Ablation Study Replication**: Independently reproduce the three key ablations (raw STFT vs. image conversion, overlap optimization, balanced batching) on BCI Competition IV Dataset 2B to verify the claimed improvements.

2. **Input Normalization Impact**: Systematically test different STFT normalization approaches (log-transform, z-score, min-max scaling) to determine their effect on classification accuracy and convergence.

3. **Alternative LOSO Validation**: Apply the TFOC-Net methodology to another MI dataset (e.g., High Gamma Dataset) using the same LOSO protocol to assess generalizability beyond the original four datasets.