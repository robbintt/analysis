---
ver: rpa2
title: 'QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language
  Models'
arxiv_id: '2512.08646'
source_url: https://arxiv.org/abs/2512.08646
tags:
- qstn
- response
- prompt
- language
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: QSTN is a modular Python framework for robust questionnaire inference
  with large language models. It enables systematic control over questionnaire presentation,
  prompt perturbations, and response generation methods.
---

# QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models

## Quick Facts
- arXiv ID: 2512.08646
- Source URL: https://arxiv.org/abs/2512.08646
- Reference count: 21
- Primary result: Battery presentation reduces Wasserstein distance by ~8% for large models compared to single-item presentation

## Executive Summary
QSTN is a Python framework for generating synthetic survey responses using large language models. The framework enables systematic control over questionnaire presentation, prompt perturbations, and response generation methods to improve alignment with human responses. Using over 40 million synthetic responses across multiple models and datasets, QSTN demonstrates that questionnaire presentation format significantly impacts alignment, with battery presentation showing the strongest improvements for large models while reducing compute costs.

## Method Summary
The framework conducts inference using three presentation modes (single-item, sequential, battery) on synthetic survey responses, evaluating alignment with human answers using Mean Absolute Error and Wasserstein distance. Experiments use ANES 2016 data (7,530 participants, 16 questions) and personas defined by gender, race, and ideology. The method tests multiple LLMs (Llama-3.3-70B, Phi-4-mini, etc.) via vLLM on NVIDIA H100 GPUs, comparing presentation effects and response generation methods including restricted choice, verbalized distributions, and token probability-based approaches.

## Key Results
- Battery presentation yields ~8% better subpopulation alignment (Wasserstein distance) for large models compared to single-item presentation
- Questionnaire presentation affects inference efficiency, with battery mode reducing runtime from 9:29:45 to 1:34:45 (6x faster)
- Response generation method choice significantly impacts alignment; restricted methods and verbalized distributions outperform token probability-based approaches
- LLMs exhibit human-like biases (recency bias, middle-category preference) that prompt perturbations can reveal and partially mitigate

## Why This Works (Mechanism)

### Mechanism 1
Questionnaire presentation format significantly impacts subpopulation-level alignment with human responses, with battery presentation reducing Wasserstein distance by approximately 8% for large models compared to single-item presentation. Battery presentation provides all questions simultaneously in one context, allowing the model to maintain consistency across related questions and develop response patterns that better approximate human distributional tendencies. Effect is highly architecture-dependent for smaller models—Phi-4-mini performs best with sequential, Gemma-3-4b with single-item.

### Mechanism 2
Response generation method choice significantly affects alignment; restricted generation methods and verbalized distributions outperform token probability-based approaches. Token probability extraction from first tokens captures model uncertainty rather than simulated respondent behavior, while constrained generation and verbalized distributions better simulate survey response patterns. Results vary by dataset; verbalized distribution shows significant improvement on ANES 2016 and GLES 2017 but not GLES 2025.

### Mechanism 3
LLMs exhibit human-like survey response biases (recency bias, middle-category preference, A-bias) that prompt perturbations can reveal and partially mitigate. Perturbations stress-test whether model responses reflect semantic understanding versus superficial positional heuristics. Larger models show greater robustness to perturbations than smaller models. Perturbation type matters—reversing options is more harmful than removing refusal categories.

## Foundational Learning

- **Wasserstein Distance (Earth Mover's Distance)**: Primary metric for evaluating subpopulation distributional alignment between LLM-generated and human survey responses. Quick check: If two distributions have identical means but different variances, would Wasserstein distance capture this difference?
- **Total Variation Distance**: Used for categorical response distribution comparison in response generation method evaluation. Quick check: For two probability distributions over 5 categories, what is the maximum possible total variation distance?
- **Prefix Caching and Batching in vLLM**: QSTN leverages these for computational efficiency when running large-scale experiments with shared prompt prefixes. Quick check: Why does prefix caching particularly benefit experiments where many prompts share the same system prompt but vary in user prompts?

## Architecture Onboarding

- **Component map**: Prompt Builder -> Survey Manager -> Parser -> Utilities -> Perturbation Layer
- **Critical path**: 1. Load questionnaire CSV and persona data → 2. Build LLMPrompt objects with presentation mode → 3. Initialize vLLM/OpenAI client → 4. Call appropriate survey_manager method → 5. Parse raw responses
- **Design tradeoffs**: Battery presentation: Best alignment for large models, ~6x faster inference, but architecture-dependent effectiveness. Sequential vs Single-item: Sequential maintains context but adds API calls; single-item is independent but loses inter-question consistency. Restricted vs Open generation: Restricted is efficient and aligned; open allows richer responses but requires classification step
- **Failure signatures**: Token probability misalignment in instruction-tuned models—use restricted or verbalized methods instead. Position bias—same semantic answer selected 20x more often at end position—randomize answer order to detect. Middle-category inflation—67-89% of models over-select middle options on Likert scales—test with odd/even transformation
- **First 3 experiments**: 1. Presentation mode validation: Run same questionnaire with all three presentations on your target model; compare Wasserstein distance and inference time. Start with battery for large models (>30B), sequential for smaller. 2. Perturbation robustness check: Apply randomized response option order and reversed order; calculate share of fully robust responses. If robustness <0.5, model has positional bias requiring mitigation. 3. Response generation comparison: Test restricted choice vs verbalized distribution on a held-out subset. Expect verbalized distribution to improve subpopulation alignment.

## Open Questions the Paper Calls Out

- Do the efficiency and alignment benefits of specific questionnaire presentations (e.g., battery format) generalize to non-survey tasks like data annotation or text classification? The authors state the evaluation is "primarily focused on the creation of synthetic survey responses" and hope for experiments in "other application domains."
- How do non-instruction-tuned models perform within the QSTN framework regarding robustness to prompt perturbations and subpopulation alignment? The paper notes "While we plan to add support for non-instruct models, they are currently not supported."
- What specific architectural features determine whether a model will achieve better alignment with sequential or battery presentation? Section 4.1 notes the effect is "highly architecture-dependent" but doesn't isolate responsible components.

## Limitations

- Dataset scope limited to ANES 2016 with 16 US-focused questions and 7,530 participants; effectiveness on non-US populations or different survey types untested
- Architecture-dependent nature of presentation effects limits generalizability—battery presentation's ~8% improvement for large models doesn't translate to smaller models like Phi-4-mini
- Study relies on synthetic personas rather than real demographic diversity, potentially missing nuanced cultural or socioeconomic response patterns

## Confidence

- **High confidence**: Questionnaire presentation significantly impacts alignment (p<0.01 statistical significance, consistent effect across models and datasets)
- **Medium confidence**: Response generation method recommendations (effectiveness varies by dataset)
- **Low confidence**: Perturbation robustness findings (20x increase in recency bias may reflect dataset-specific artifacts)

## Next Checks

1. Test the three presentation modes on a small (<7B parameter) model to verify that sequential outperforms battery, confirming architecture dependency
2. Apply QSTN to a different survey dataset (e.g., European Social Survey) to test whether presentation effects (~8% improvement) hold across cultural contexts
3. Systematically vary perturbation strength (mild vs. severe typos) and measure robustness decay curves to determine if 20x positional bias is consistent across perturbation types