---
ver: rpa2
title: "$\u03B5$-Softmax: Approximating One-Hot Vectors for Mitigating Label Noise"
arxiv_id: '2508.02387'
source_url: https://arxiv.org/abs/2508.02387
tags:
- noise
- loss
- learning
- softmax
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the challenge of training accurate deep neural\
  \ networks in the presence of noisy labels. The authors propose a simple yet effective\
  \ method called \u03F5-softmax that approximates one-hot vectors with a controllable\
  \ error, enhancing noise tolerance for any loss function."
---

# $ε$-Softmax: Approximating One-Hot Vectors for Mitigating Label Noise

## Quick Facts
- arXiv ID: 2508.02387
- Source URL: https://arxiv.org/abs/2508.02387
- Authors: Jialiang Wang; Xiong Zhou; Deming Zhai; Junjun Jiang; Xiangyang Ji; Xianming Liu
- Reference count: 40
- Key outcome: Proposed $ε$-softmax method achieves superior noise tolerance by approximating one-hot vectors, demonstrating consistent improvements across CIFAR-10/100, human-annotated datasets, and real-world noisy benchmarks.

## Executive Summary
This paper addresses the fundamental challenge of training deep neural networks under label noise by introducing $ε$-softmax, a simple output modification technique that approximates one-hot vectors. The method transforms the softmax layer outputs by adding a constant to the maximum probability element, effectively constraining the hypothesis class to satisfy the symmetric condition for noise tolerance. Extensive experiments demonstrate that $ε$-softmax outperforms standard loss functions and state-of-the-art methods on both synthetic and real-world noisy datasets, while theoretical analysis provides excess risk bounds that guarantee robustness.

## Method Summary
The proposed method modifies softmax outputs by finding the maximum probability index $t$, adding a constant $m$ to it, and re-normalizing: $p_t \leftarrow (p_t + m)/(1+m)$. This approximation to one-hot vectors implicitly enforces the symmetric condition required for noise tolerance. The approach uses an Active-Passive Loss combining $α \cdot L_{CE_ε} + β \cdot L_{MAE}$, balancing the strict convexity of constrained CE with the linearity of MAE for better optimization. The method is architecture-agnostic and can be applied to any loss function, requiring only a 2-line code modification in the forward pass.

## Key Results
- Achieves 93.14% accuracy on CIFAR-10 with 80% symmetric noise (vs. 80.94% baseline)
- Outperforms state-of-the-art methods on CIFAR-100 with 40% symmetric noise
- Demonstrates consistent improvements on real-world noisy datasets (WebVision, Clothing1M)
- Combines with MAE to recover fitting ability on clean datasets while maintaining noise robustness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Modifying softmax outputs to approximate one-hot vectors implicitly satisfies the symmetric condition for noise tolerance.
- **Mechanism:** Standard softmax outputs a probability distribution. $ε$-softmax adds a constant $m$ to the maximum probability element and re-normalizes. As $m$ increases, the output vector $f(x)$ approaches a one-hot vector $e_y$. When outputs are strictly one-hot, the sum of losses over all classes $\sum_{k} L(f(x), k)$ becomes a constant $C$ (the symmetric condition), rendering the loss robust to label noise regardless of the specific loss function used.
- **Core assumption:** The symmetric condition ($\sum L(f(x), k) = C$) is sufficient for noise tolerance, and approximating it via output constraint is equivalent to designing a symmetric loss function.
- **Evidence anchors:**
  - [abstract]: "modifying the outputs of the softmax layer to approximate one-hot vectors... implicitly plays the crucial role in modifying the loss function."
  - [section 1]: "By restricting the hypothesis class H... any loss function can inherently become symmetric."
  - [corpus]: "On Symmetric Losses for Robust Policy Optimization..." verifies that symmetric losses are a established theoretical foundation for robustness.
- **Break condition:** If the hypothesis class cannot be sufficiently restricted (i.e., $m$ is too small), the symmetric condition is not approximated, and robustness is lost.

### Mechanism 2
- **Claim:** The method acts as an implicit gradient scaling mechanism (soft early-stopping) to prevent overfitting to noisy labels.
- **Mechanism:** Theoretical analysis of the gradient (Eq 3.4) shows that when the predicted class $t$ matches the target $y$, the gradient is scaled by $\frac{p_y}{p_y + m}$. This reduces the gradient magnitude significantly compared to standard Cross Entropy. This dampening effect prevents the model from updating aggressively on samples it has already classified correctly (often clean samples), avoiding the late-stage memorization of noisy samples.
- **Core assumption:** Deep networks "learn simple patterns first" (early learning), and suppressing gradients on confident predictions helps preserve this early knowledge against noise.
- **Evidence anchors:**
  - [section 3.3]: "gradient undergoes dynamic scaling... results in smaller gradients, akin to a form of soft early-stopping."
  - [figure 1b]: Shows stable test accuracy curves for CE$ε$ even with 80% noise, unlike standard CE which overfits rapidly.
  - [corpus]: "Learning to Forget..." discusses reweighting objectives to handle noise, aligning with the gradient modulation concept.
- **Break condition:** If $m$ is set too low, the gradient scaling is insufficient to prevent the memorization of noisy labels in later epochs.

### Mechanism 3
- **Claim:** Combining $ε$-softmax with MAE restores the fitting ability compromised by strict output constraints.
- **Mechanism:** Strictly approximating one-hot vectors ($m \to \infty$) creates a strictly convex loss landscape that is robust but hard to optimize (underfitting). MAE is a symmetric loss with linearity properties that treats all samples equally but converges slowly. The combination $CEε + MAE$ balances the strict convexity (robustness) of the constrained CE with the linearity (stability) of MAE.
- **Core assumption:** A hybrid loss can inherit the noise tolerance of the symmetric/constrained component and the optimization properties of the passive component.
- **Evidence anchors:**
  - [section 3.4]: "CE$ε$+MAE not only depicts strong fitting capabilities but also achieves better noise tolerance."
  - [lemma 3]: Proves the excess risk bound of the hybrid loss is equivalent to the robust component alone.
  - [corpus]: "Joint Asymmetric Loss..." discusses the underfitting issue of symmetric losses, validating the need for a hybrid approach.
- **Break condition:** If the weighting $α, β$ is unbalanced, the model may still underfit (too much constraint) or overfit noise (too little constraint).

## Foundational Learning

- **Concept: Symmetric Loss Functions**
  - **Why needed here:** The paper's primary theoretical justification rests on the "symmetric condition" ($\sum L(f(x), k) = C$). You must understand that if a loss sums to a constant, the noise contribution cancels out in expectation.
  - **Quick check question:** If a loss function satisfies $\sum L(f(x), k) = C$, does the gradient update depend on the specific noisy label or the underlying distribution properties?

- **Concept: Hypothesis Class Restriction**
  - **Why needed here:** Unlike standard approaches that design new loss functions, this paper constrains the *outputs* (hypothesis class) to induce robustness. Understanding the difference between "robust loss" and "robust architecture/output" is key.
  - **Quick check question:** How does restricting $f(x)$ to be close to a one-hot vector mathematically enforce the symmetric condition for any generic loss function?

- **Concept: Softmax Properties**
  - **Why needed here:** The method modifies the softmax calculation directly. You need to grasp how adding $m$ and re-normalizing shifts the probability mass to the maximum element.
  - **Quick check question:** As $m \to \infty$ in the $ε$-softmax calculation $p_t \leftarrow (p_t + m)/(1+m)$, what does the output vector converge to?

## Architecture Onboarding

- **Component map:** Logits $h(x)$ -> $ε$-Softmax Module (Find max index $t$, Add $m$, Normalize) -> Hybrid Loss ($α \cdot L_{CE_ε} + β \cdot L_{MAE}$)

- **Critical path:** The "$ε$-Softmax Module" is the critical intervention. It requires identifying the maximum probability $p_t$, adding the hyperparameter $m$ to it, and re-normalizing the vector before loss calculation.

- **Design tradeoffs:**
  - **High $m$ (e.g., $10^5$):** Better noise robustness (closer to one-hot approximation), but risks underfitting on clean data.
  - **Low $m$ (e.g., $10^1$):** Behaves like standard CE; fits clean data well but offers minimal noise protection.
  - **Hybrid ($β > 0$):** Essential for recovering performance on clean/real-world datasets where pure one-hot approximation is too restrictive.

- **Failure signatures:**
  - **Underfitting (Clean Data):** Test accuracy on clean sets is significantly lower than baseline CE. *Fix:* Decrease $m$ or increase the MAE weight $β$ to improve optimization fluidity.
  - **Memorization (High Noise):** Accuracy rises then crashes in later epochs. *Fix:* Increase $m$ to enforce stricter one-hot approximation.

- **First 3 experiments:**
  1.  **Sanity Check (Implementation):** Verify the 2-line code modification. Calculate softmax for a dummy logit vector (e.g., `[2, 1, 0.1]`) with $m=100$ and confirm the output is nearly one-hot.
  2.  **Ablation on $m$:** Train on CIFAR-10 with 40% symmetric noise. Plot accuracy for $m \in \{10, 100, 1000, 10000\}$. Observe the trade-off between convergence speed and final robustness.
  3.  **Hybrid Validation:** Compare $CE_ε$ vs. $CE_ε+MAE$ on a clean vs. noisy split. Confirm that adding MAE improves clean accuracy without degrading noisy accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the theoretical trade-off between noise robustness and the reduced fitting ability on clean datasets be precisely quantified for $ε$-softmax?
- **Basis in paper:** [Explicit] The authors state in Appendix A: "The limitation of $ε$-softmax is that it may slightly reduce fitting ability on clean case."
- **Why unresolved:** While the paper proposes combining $ε$-softmax with MAE to mitigate this empirically, it does not provide a theoretical bound or analysis characterizing the specific loss in accuracy on clean data versus the gain in robustness.
- **What evidence would resolve it:** A theoretical derivation showing the excess risk or convergence rate specifically for the clean data scenario ($\eta=0$) compared to standard softmax.

### Open Question 2
- **Question:** Is there a theoretical principle or adaptive mechanism for selecting the hyperparameter $m$ based on the noise rate or dataset complexity?
- **Basis in paper:** [Inferred] The experimental results in Table 3 and Appendix D show that optimal $m$ values vary significantly (from $1e2$ to $1e5$) depending on the noise type (symmetric vs. asymmetric) and rate, suggesting sensitivity that currently requires manual tuning.
- **Why unresolved:** The paper treats $m$ as a fixed hyperparameter in the theoretical analysis (Lemma 1) and relies on grid search for optimal performance in experiments.
- **What evidence would resolve it:** A proposed rule or algorithm that links $m$ to the estimated noise rate $\eta$ and demonstrates robust performance without dataset-specific tuning.

### Open Question 3
- **Question:** Do the theoretical robustness guarantees (Theorem 1) extend to instance-dependent noise (IDN) scenarios?
- **Basis in paper:** [Inferred] The paper provides empirical results on IDN in Table 8 but restricts the theoretical analysis of the excess risk bound to symmetric and asymmetric noise models.
- **Why unresolved:** Instance-dependent noise violates the class-conditional assumptions used in the proof of Theorem 1, leaving the theoretical grounding for the strong empirical IDN results unexplored.
- **What evidence would resolve it:** An extension of the theoretical proofs to encompass noise transition matrices that are functions of the input instance $x$.

## Limitations
- Theoretical robustness guarantees primarily rely on symmetric noise assumptions, with limited analysis for asymmetric or instance-dependent noise
- Method requires careful hyperparameter tuning of $m$, with no clear universal selection strategy provided
- The $CE_ε+MAE$ hybrid adds complexity and requires additional hyperparameter tuning ($α, β$)

## Confidence
- **High Confidence:** The core mechanism of approximating one-hot vectors through $ε$-softmax output modification, and its effect on gradient scaling, is well-supported by both theoretical analysis and empirical results. The improvement over standard CE on noisy datasets is consistently demonstrated.
- **Medium Confidence:** The theoretical excess risk bound and its equivalence between $CE_ε$ and $CE_ε+MAE$ combinations are mathematically sound, but the practical implications and tightness of the bound require further validation across diverse noise types.
- **Low Confidence:** The generalization performance on highly complex, real-world noisy datasets (WebVision, Clothing1M) shows improvements but the margin is modest, suggesting potential limitations in extreme noise conditions or with complex label distributions.

## Next Checks
1. **Hyperparameter Sensitivity Analysis:** Systematically evaluate $m$ values across multiple noise rates and datasets to establish guidelines for hyperparameter selection and identify potential overfitting/underfitting thresholds.
2. **Asymmetric Noise Robustness:** Test the method on datasets with class-conditional (asymmetric) label noise to validate theoretical assumptions about uniform noise and assess practical robustness beyond symmetric noise.
3. **Architectural Compatibility Study:** Evaluate $ε$-softmax performance across different network architectures (ResNet, EfficientNet, Vision Transformers) and with different loss functions (focal loss, dice loss) to assess its generalizability as a plug-and-play component.