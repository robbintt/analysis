---
ver: rpa2
title: 'Everything is Context: Agentic File System Abstraction for Context Engineering'
arxiv_id: '2512.05470'
source_url: https://arxiv.org/abs/2512.05470
tags:
- context
- memory
- file
- system
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a file-system abstraction for context engineering
  in Generative AI systems, addressing the fragmentation and lack of traceability
  in current practices like prompt engineering and retrieval-augmented generation.
  Inspired by Unix's "everything is a file" philosophy, the approach provides a persistent,
  governed infrastructure for managing heterogeneous context artefacts through uniform
  mounting, metadata, and access control.
---

# Everything is Context: Agentic File System Abstraction for Context Engineering

## Quick Facts
- arXiv ID: 2512.05470
- Source URL: https://arxiv.org/abs/2512.05470
- Authors: Xiwei Xu; Robert Mao; Quan Bai; Xuewu Gu; Yechao Li; Liming Zhu
- Reference count: 30
- Primary result: Introduces file-system abstraction for context engineering in GenAI systems, providing persistent, governed infrastructure with uniform mounting, metadata, and access control

## Executive Summary
This paper addresses the fragmentation and lack of traceability in current Generative AI practices like prompt engineering and retrieval-augmented generation by introducing a file-system abstraction for context engineering. Inspired by Unix's "everything is a file" philosophy, the approach provides a persistent, governed infrastructure for managing heterogeneous context artifacts through uniform mounting, metadata, and access control. Implemented in the open-source AIGNE framework, the architecture realizes a verifiable context-engineering pipeline comprising the Context Constructor, Loader, and Evaluator that assembles, delivers, and validates context under token constraints while ensuring traceability and accountability.

## Method Summary
The paper presents a file system abstraction for context engineering in GenAI systems, addressing fragmentation and lack of traceability in current practices. The approach provides persistent, governed infrastructure for managing heterogeneous context artifacts through uniform mounting, metadata, and access control. The method is implemented in the open-source AIGNE framework and realizes a verifiable context-engineering pipeline comprising Context Constructor, Loader, and Evaluator components that assemble, deliver, and validate context under token constraints. Two exemplars demonstrate the approach: an agent with memory and an MCP-based GitHub assistant.

## Key Results
- File system abstraction reduces integration complexity by projecting heterogeneous context sources into a unified namespace with consistent operations
- Context pipeline manages token budget constraints through selection, compression, and incremental streaming
- Comprehensive logging enables reconstruction of reasoning provenance for audit and verification
- Supports human-AI co-work by embedding human roles as curators and verifiers

## Why This Works (Mechanism)

### Mechanism 1: Uniform Interface Abstraction
The file system abstraction reduces integration complexity by projecting heterogeneous context sources into a unified namespace with consistent operations. Schema-driven resolvers map diverse backends (REST APIs, MCP tools, vector stores, knowledge graphs) into standardized file paths and operations, eliminating per-source integration code. Core assumption: agents can reason effectively over abstracted resources without understanding underlying storage formats. Break condition: if schema mapping complexity exceeds token savings, the approach adds friction rather than reducing it.

### Mechanism 2: Token Budget Management via Context Pipeline
The Constructor/Updater/Evaluator pipeline fits unbounded persistent context within fixed model token windows through selection, compression, and incremental streaming. Metadata attributes guide selection; summarization and token-budget estimation compress selected artifacts; the manifest tracks what was included or excluded for reproducibility. Core assumption: metadata relevance signals correlate sufficiently with actual reasoning utility to avoid critical information loss. Break condition: if compression discards information that cannot be inferred from remaining context or metadata, reasoning quality degrades unpredictably.

### Mechanism 3: Traceability Through Persistent Logging
Recording all file operations as transactions enables reconstruction of reasoning provenance for audit and verification. Each artifact carries lineage metadata; state transitions are logged as versioned events; manifests record selection rationale. Core assumption: comprehensive logging overhead remains tractable at scale, and stored lineage is sufficient to reconstruct meaningful reasoning paths. Break condition: if log volume grows faster than query capacity, provenance reconstruction becomes impractical.

## Foundational Learning

- **Unix "everything is a file" philosophy**: Why needed: The paper's core metaphor directly adapts Unix's uniform read/write interface for heterogeneous resources to AI context management. Quick check: Can you explain how Unix exposes devices, pipes, and sockets through file descriptors, and why uniformity matters for composability?

- **LLM token window constraints and attention complexity**: Why needed: The bounded context problem drives the entire pipeline designâ€”selection, compression, and streaming exist because models cannot attend to unlimited context. Quick check: Why does self-attention's quadratic complexity make context length a hard architectural constraint rather than a soft preference?

- **Memory type taxonomy (scratchpad, episodic, fact, procedural)**: Why needed: The paper distinguishes multiple memory types with different persistence scopes and representations; understanding this hierarchy is essential for configuring the repository. Quick check: What is the difference between scratchpad, episodic memory, and fact memory in terms of lifespan and retrieval patterns?

## Architecture Onboarding

- **Component map**: AFS (Agentic File System) -> SystemFS -> FSMemory/UserProfileMemory/AFSHistory -> MCPAgent -> Context Constructor -> Context Updater -> Context Evaluator

- **Critical path**: 1) Mount context sources into AFS; 2) Constructor queries metadata and generates selection manifest; 3) Updater streams manifest content respecting token budget; 4) Model reasons; Evaluator validates output; 5) Verified artifacts written back to memory/history with lineage; 6) Low-confidence outputs trigger human annotations

- **Design tradeoffs**: Completeness vs. boundedness (Constructor balances coverage against token limits); Transparency vs. overhead (Full logging enables audit but increases storage and latency); Automation vs. human oversight (Evaluator thresholds determine when humans enter the loop)

- **Failure signatures**: Context rot (Stale or contradictory memory degrades retrieval); Token overflow (Manifest underestimates consumption, forcing truncation mid-reasoning); Provenance gaps (Missing lineage prevents reconstruction of how conclusions were reached); Isolation breach (Multi-agent context leaks across session boundaries)

- **First 3 experiments**: 1) Mount FSMemory with SQLite backend; verify conversation persists across sessions by inspecting memory.sqlite3; 2) Mount GitHub MCP server; execute afs_read on /modules/github-mcp/search_repositories to validate uniform abstraction over external tools; 3) Inject context exceeding token limit; inspect Constructor manifest to identify excluded artifacts and assess information loss

## Open Questions the Paper Calls Out

- **Autonomous navigation and evolution**: How can agents autonomously navigate, construct indices, and evolve data structures within the AFS hierarchy without human guidance? The current implementation requires explicit mounting and resolver configurations; agents lack self-organizing capabilities to modify their own context structures.

- **Human tacit knowledge integration**: What mechanisms beyond annotation storage can effectively integrate human tacit knowledge and ethical judgment as first-class context elements? The paper describes human annotations stored as artifacts but doesn't specify how tacit knowledge or ethical reasoning become actionable reasoning components.

- **Evaluation effectiveness**: How effectively does the Context Evaluator detect hallucinations, contradictions, and context drift in complex multi-session reasoning? Detection mechanisms are described aspirationally without specifying algorithms, thresholds, or benchmark performance.

- **Memory deduplication strategies**: What memory deduplication and consolidation strategies preserve critical information while preventing retrieval degradation? The trade-off between deduplication efficiency and information loss remains uncharacterized.

## Limitations

- **Token Budget Management Effectiveness**: The paper claims the pipeline can fit unbounded context within fixed token windows but provides no empirical validation of this critical mechanism. The actual compression algorithms, selection heuristics, and token estimation accuracy remain unspecified.

- **Provenance Completeness and Utility**: While comprehensive logging is proposed for auditability, there's no evidence that the generated lineage metadata is sufficient to reconstruct meaningful reasoning paths or that the overhead remains tractable at scale.

- **Schema Mapping Complexity**: The uniform interface abstraction assumes heterogeneous resources can be automatically projected into standardized file paths without significant complexity, but the paper doesn't address scenarios where schema mapping might be ambiguous or create more integration overhead than it eliminates.

## Confidence

- **High Confidence**: The Unix "everything is a file" philosophical foundation and the general architecture of separating context construction, loading, and evaluation. The problem statement about context engineering fragmentation is well-grounded.

- **Medium Confidence**: The feasibility of mounting heterogeneous resources (MCP servers, memory stores) through file system abstraction, based on conceptual alignment with related work. The traceability mechanisms are plausible but unproven.

- **Low Confidence**: The actual effectiveness of token budget management, the completeness of provenance logging for audit purposes, and the scalability of the approach to complex real-world scenarios.

## Next Checks

1. **Token Budget Validation**: Implement the Context Constructor pipeline and test it with context exceeding token limits. Measure actual token consumption versus estimates, and assess information loss when compression is triggered. Compare reasoning quality with and without the pipeline.

2. **Provenance Reconstruction Test**: Create a multi-step reasoning scenario with the implemented system. Attempt to reconstruct the complete reasoning path from the logged metadata. Evaluate whether the lineage is sufficient to understand decision-making and identify any gaps.

3. **Integration Overhead Benchmark**: Compare development time and code complexity when integrating three different context sources (e.g., REST API, MCP server, vector store) using the file system abstraction versus traditional integration methods. Measure both implementation effort and runtime performance overhead.