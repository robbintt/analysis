---
ver: rpa2
title: 'From Unstructured Communication to Intelligent RAG: Multi-Agent Automation
  for Supply Chain Knowledge Bases'
arxiv_id: '2506.17484'
source_url: https://arxiv.org/abs/2506.17484
tags:
- knowledge
- ticket
- tickets
- synthesis
- multi-agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The authors present a multi-agent framework that transforms unstructured
  support ticket communications into a structured knowledge base for supply chain
  systems. The system employs three specialized agents: Category Discovery (identifies
  knowledge domains), Ticket Categorization (groups related issues), and Knowledge
  Synthesis (generates comprehensive articles).'
---

# From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases

## Quick Facts
- **arXiv ID:** 2506.17484
- **Source URL:** https://arxiv.org/abs/2506.17484
- **Reference count:** 40
- **Primary result:** Transforms unstructured support tickets into structured knowledge base, reducing volume to 3.4% while improving RAG system performance by 26.5% (48.74% vs 38.60% helpful answers)

## Executive Summary
This paper presents a multi-agent framework that converts unstructured supply chain support ticket communications into a structured knowledge base. The system employs three specialized agents - Category Discovery, Ticket Categorization, and Knowledge Synthesis - to identify domains, group related issues, and generate comprehensive articles. The approach achieves a dramatic reduction in knowledge base size while improving the quality of responses when integrated with a RAG system. The offline-first methodology captures institutional knowledge that would otherwise remain siloed, enabling automated resolution of approximately 50% of future support tickets.

## Method Summary
The framework transforms unstructured support ticket communications into a structured knowledge base through a three-agent pipeline. The Category Discovery Agent identifies distinct knowledge domains within the ticket corpus, the Ticket Categorization Agent groups related issues into clusters, and the Knowledge Synthesis Agent generates comprehensive knowledge articles from these clusters. This offline-first approach processes historical ticket data to build a structured knowledge base that can then be integrated with RAG systems for improved query responses. The methodology focuses on capturing institutional knowledge that would otherwise remain trapped in unstructured communications.

## Key Results
- Reduces knowledge base size to 3.4% of original ticket volume while significantly improving quality
- RAG system with generated knowledge base achieves 48.74% helpful answers versus 38.60% for traditional RAG
- Represents 77.4% reduction in unhelpful responses when using the automated knowledge base
- Enables automated resolution of approximately 50% of future support tickets

## Why This Works (Mechanism)
The system works by leveraging multi-agent specialization to transform unstructured data into structured knowledge. Each agent handles a specific aspect of the transformation: discovery identifies what knowledge exists, categorization groups related information, and synthesis creates coherent, comprehensive articles. This division of labor allows for more accurate and complete knowledge extraction than monolithic approaches. The offline-first processing enables thorough analysis of historical data to identify patterns and relationships that would be missed in real-time processing.

## Foundational Learning
- **Multi-agent specialization**: Why needed - Different aspects of knowledge extraction require different capabilities; Quick check - Verify each agent performs its designated function accurately
- **Knowledge clustering**: Why needed - Related issues need to be grouped for comprehensive coverage; Quick check - Measure cluster purity and coherence
- **RAG system integration**: Why needed - Structured knowledge must be accessible for future queries; Quick check - Test retrieval accuracy with synthetic queries
- **Offline processing**: Why needed - Historical data provides context and patterns; Quick check - Compare results with real-time processing approaches
- **Domain-specific vocabulary**: Why needed - Supply chain terminology requires specialized understanding; Quick check - Validate terminology accuracy with domain experts

## Architecture Onboarding

**Component Map:** Category Discovery -> Ticket Categorization -> Knowledge Synthesis -> RAG Integration

**Critical Path:** Historical ticket corpus → Category Discovery Agent → Ticket Clustering → Knowledge Synthesis Agent → Structured Knowledge Base → RAG System → Query Response

**Design Tradeoffs:** Offline processing enables thorough analysis but delays knowledge availability; multi-agent specialization improves accuracy but increases system complexity; structured knowledge base reduces storage but requires maintenance

**Failure Signatures:** Poor category discovery leads to fragmented knowledge; inadequate clustering creates redundant articles; weak synthesis produces incomplete or inaccurate knowledge; poor RAG integration results in retrieval failures

**3 First Experiments:**
1. Test Category Discovery Agent on a small, labeled subset of tickets to validate domain identification accuracy
2. Evaluate Ticket Categorization Agent's clustering quality using silhouette scores and human validation
3. Measure Knowledge Synthesis Agent's article quality through automated readability metrics and human expert review

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond those addressed in the limitations section regarding evaluation methodology and generalizability.

## Limitations
- Evaluation metrics lack clear definition and validation methodology, particularly the "helpfulness" scores
- Offline-first approach raises scalability and real-time applicability concerns
- Predictive claims about future ticket resolution rates appear to be extrapolations without direct measurement
- Generalizability beyond supply chain domains is not established

## Confidence
- **High:** Technical architecture description, percentage reductions in knowledge base size
- **Medium:** Comparison with traditional RAG systems, offline knowledge capture methodology
- **Low:** Predictive claims about future ticket resolution rates, generalizability across domains

## Next Checks
1. Conduct a blind human evaluation of the generated knowledge articles against original tickets to validate the quality claims
2. Test the system on diverse supply chain datasets from different organizations to assess generalizability
3. Implement A/B testing with live support tickets to measure actual resolution rates and measure the real-world impact of the generated knowledge base