---
ver: rpa2
title: AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge
  Augmentation for Robust Constitutional Alignment of Language Models
arxiv_id: '2509.02133'
source_url: https://arxiv.org/abs/2509.02133
tags:
- bias
- fairness
- ambedkar
- decoding
- verifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The AMBEDKAR framework addresses caste- and religion-based biases
  in Indian Large Language Models by introducing a Constitution-aware decoding layer
  that uses speculative decoding combined with counterfactual perturbations to reduce
  identity inference rates. It operates at inference time without retraining, leveraging
  a verifier trained on constitutional principles to re-rank token completions, thus
  ensuring identity-invariant outputs.
---

# AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models

## Quick Facts
- arXiv ID: 2509.02133
- Source URL: https://arxiv.org/abs/2509.02133
- Reference count: 40
- Primary result: 26.41% absolute reduction in identity inference rates while maintaining 6.29% latency overhead

## Executive Summary
The AMBEDKAR framework addresses caste- and religion-based biases in Indian Large Language Models through a Constitution-aware decoding layer that operates at inference time without requiring model retraining. It combines speculative decoding with counterfactual perturbations to reduce identity inference rates while preserving output fluency. The approach leverages a verifier trained on Indian constitutional principles to re-rank token completions, ensuring identity-invariant outputs aligned with Articles 14-17 of the Indian Constitution.

## Method Summary
AMBEDKAR introduces a multi-level bias elimination approach that works at the decoding stage of LLM inference. The framework employs speculative decoding combined with counterfactual perturbations to generate candidate responses, then uses a constitutional principle-based verifier to re-rank these completions. This architecture allows for bias mitigation without modifying the base model weights, making it model-agnostic and resource-efficient. The system specifically targets identity-based biases related to caste and religion in Indian contexts, using synthetic datasets for evaluation while maintaining output fluency through careful latency management.

## Key Results
- Achieves up to 26.41% absolute reduction in identity inference rates for religious and caste identities
- Maintains fluency with only 6.29% latency overhead compared to standard decoding
- Operates model-agnostically at inference time without requiring retraining
- Demonstrates effectiveness particularly for Indian constitutional alignment (Articles 14-17)

## Why This Works (Mechanism)
The framework works by intercepting the decoding process during LLM inference and applying constitutional principles to guide token selection. Speculative decoding generates multiple candidate completions efficiently, while counterfactual perturbations explore alternative response paths that avoid identity-based bias triggers. The verifier component, trained on constitutional principles, evaluates these candidates against equality and non-discrimination standards, selecting outputs that minimize identity inference while preserving semantic coherence. This multi-stage approach addresses bias at multiple levels: during generation (speculative decoding), through alternative exploration (counterfactual perturbations), and final selection (constitutional verification).

## Foundational Learning

**Speculative Decoding**: Fast approximation technique that generates multiple candidate tokens simultaneously to explore response space more efficiently
- Why needed: Enables exploration of multiple response paths without prohibitive latency costs
- Quick check: Verify latency overhead remains under 10% for practical deployment

**Counterfactual Perturbations**: Systematic modifications to input prompts or intermediate representations to test alternative response pathways
- Why needed: Helps identify and avoid identity-based bias triggers during generation
- Quick check: Confirm perturbations preserve core semantic meaning while reducing bias signals

**Constitutional Principle Verification**: Classification model trained to recognize compliance with specific legal/ethical principles
- Why needed: Provides objective criteria for evaluating whether outputs align with equality principles
- Quick check: Validate verifier accuracy on benchmark constitutional alignment tasks

## Architecture Onboarding

**Component Map**: Input Prompt -> Speculative Decoder -> Counterfactual Perturbation Generator -> Constitutional Verifier -> Output Selection -> Final Response

**Critical Path**: The most latency-sensitive path runs through speculative decoding and verifier re-ranking, where token generation speed directly impacts user experience. This path must maintain sub-10% overhead to be practical.

**Design Tradeoffs**: 
- Model-agnostic approach sacrifices potential performance gains from fine-tuning
- Inference-time processing adds computational cost but preserves base model integrity
- Synthetic dataset evaluation may not capture all real-world bias manifestations

**Failure Signatures**: 
- Increased latency beyond acceptable thresholds (>10% overhead)
- Degradation in output fluency or coherence
- Residual bias in edge cases not captured by synthetic datasets
- Constitutional verifier false positives/negatives affecting output quality

**First 3 Experiments to Run**:
1. Baseline latency measurement for standard decoding vs AMBEDKAR-enabled decoding
2. Identity inference rate comparison on controlled test sets with known bias triggers
3. Fluency assessment using standard language model evaluation metrics

## Open Questions the Paper Calls Out

The paper identifies several open questions regarding the framework's generalizability beyond Indian constitutional principles, long-term effectiveness in dynamic conversational settings, and robustness against adversarial prompts designed to bypass the decoding layer. It also notes uncertainty about how well synthetic dataset evaluations translate to real-world conversational contexts where biases manifest more subtly.

## Limitations

- Evaluation relies on synthetic datasets that may not fully capture real-world conversational contexts
- Constitutional alignment approach is tailored to Indian legal principles, limiting generalizability to other cultural contexts
- 26.41% reduction leaves residual bias that may still affect downstream applications
- Framework's effectiveness depends on quality of counterfactual perturbations and constitutional knowledge base

## Confidence

**High confidence**: Framework's ability to reduce identity inference rates (measured through controlled experiments), latency overhead measurement (6.29%), and model-agnostic operational claim (inference-time only, no retraining)

**Medium confidence**: Fluency preservation claim (6.29% overhead suggests minimal impact, but user perception studies would strengthen this), constitutional alignment effectiveness (evaluations are framework-specific and may not capture all relevant dimensions)

**Low confidence**: Generalizability to other cultural contexts, long-term effectiveness in dynamic conversational settings, and robustness against adversarial prompts designed to bypass the decoding layer

## Next Checks

1. Conduct user studies with native Indian speakers across different demographic groups to validate that reduced identity inference rates translate to perceived fairness in real conversational contexts

2. Test the framework's performance on out-of-distribution prompts and adversarial examples designed to trigger biased responses

3. Evaluate cross-cultural generalizability by adapting the constitutional knowledge base to principles from other legal frameworks (e.g., European human rights law) and measuring performance transfer