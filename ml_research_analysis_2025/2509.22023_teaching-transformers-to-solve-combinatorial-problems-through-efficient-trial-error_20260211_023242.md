---
ver: rpa2
title: Teaching Transformers to Solve Combinatorial Problems through Efficient Trial
  & Error
arxiv_id: '2509.22023'
source_url: https://arxiv.org/abs/2509.22023
tags:
- sudoku
- problem
- learning
- solution
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a trial-and-error reasoning framework for solving
  combinatorial problems using a standard Causal Transformer. The method combines
  imitation learning of problem-specific rules with explicit Depth-First Search exploration
  involving informed guessing and backtracking.
---

# Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error

## Quick Facts
- arXiv ID: 2509.22023
- Source URL: https://arxiv.org/abs/2509.22023
- Reference count: 40
- This paper proposes a trial-and-error reasoning framework for solving combinatorial problems using a standard Causal Transformer, achieving near-perfect accuracy on Sudoku (99%) and 1-in-3 SAT (99%).

## Executive Summary
This paper introduces a novel framework for teaching Transformers to solve combinatorial problems through explicit trial-and-error reasoning. The approach combines imitation learning of problem-specific rules with Depth-First Search exploration involving informed guessing and backtracking. A key innovation is the action-level tokenization scheme that encodes moves as single tokens rather than triplets, combined with a multi-target loss function that accelerates learning by exposing the model to multiple valid continuations. The framework achieves state-of-the-art results on Sudoku and 1-in-3 SAT, surpassing previous neural approaches while maintaining the simplicity of standard decoder-only Transformers.

## Method Summary
The method uses a GPT-2 style decoder-only Transformer trained on transcripts generated by a DFS solver that includes rule applications, guesses, and backtracking. Moves are encoded as single 3-digit tokens (111-999) rather than triplets, reducing sequence length by ~3×. The model learns from multi-target loss functions that sum cross-entropy over all valid next tokens. For guessing, the framework optionally uses a MIN-SUM SET COVER loss to minimize expected reasoning steps. The approach requires only a verifier for the combinatorial problem and generates training data through systematic DFS exploration with backtracking.

## Key Results
- Achieves 99% accuracy on Sudoku and 1-in-3 SAT problems
- Action-level tokenization accelerates rule-learning convergence compared to triplet encoding
- MIN-SUM SET COVER loss reduces median guesses from 2.2 to 1.5 on Sudoku
- Introduces SudokuPy, a fast library for generating uniformly random Sudoku puzzles
- Demonstrates near-perfect performance with a vanilla Transformer without specialized architecture

## Why This Works (Mechanism)

### Mechanism 1: Action-level tokenization with multi-target loss
- Claim: Encoding moves as single tokens with multi-target loss accelerates learning of valid rule applications
- Mechanism: Single-token encoding (111-999) reduces sequence length by ~3× while multi-target loss exposes model to multiple valid continuations per step
- Core assumption: Multiple actions can be equivalently correct at any state; leveraging this symmetry speeds convergence
- Evidence: Figure 3 shows rcv + multiple targets reaches near-perfect rule-logic accuracy faster than baseline triplet tokenization

### Mechanism 2: Explicit DFS with backtracking
- Claim: Explicit DFS with backtracking enables recovery from incorrect guesses, extending capability beyond fixed-strategy imitation
- Mechanism: Model trained on transcripts including "guess level" tokens, informed guesses, and "dead end" tokens triggering backtracking
- Core assumption: Combinatorial problem permits efficient verification of partial assignments (NP structure)
- Evidence: Framework mimics DPLL-style search, allowing exploration rather than irreversible commitment

### Mechanism 3: MIN-SUM SET COVER loss for step minimization
- Claim: L1 loss derived from MIN-SUM SET COVER minimizes expected reasoning steps by optimizing for early success probability
- Mechanism: Under depth-1 non-adaptive guessing, problem reduces to contextual MIN-SUM SET COVER; L1 is convex and optimized via SGD
- Core assumption: Nearly all instances solvable with at most one informed guess after rule exhaustion (99.8% for random Sudoku)
- Evidence: Figure 6 shows L1 achieves median 1.5 guesses vs L2's 2.2 guesses; Theorem E.2 provides O(log n) approximation guarantee

## Foundational Learning

- **Depth-First Search with Backtracking**: Why needed - DFS transcript structure is the training data format; understanding backtracking encoding is essential for debugging. Quick check - Given a partial solution with two remaining candidates, can you trace how DFS encodes both branches and backtracking between them?

- **Causal Transformer Autoregression**: Why needed - Model is GPT-2-style decoder; understanding next-token prediction and causal masking is critical for implementation. Quick check - In causal transformer, can token i attend to token i+1? How does scratchpad alter this for guess tokens?

- **Multiple-Target Loss Functions**: Why needed - Unlike standard single-label cross-entropy, method uses sum-of-cross-entropies over valid token sets. Quick check - If valid tokens are {123, 456, 789} with probabilities 0.5, 0.3, 0.2, what is multi-target loss value?

## Architecture Onboarding

- **Component map**: SudokuPy library -> DFS transcript generator -> GPT-2 backbone (8L, 8H, 576D, 3456FFN) -> Multi-target loss module -> Special tokens (start, end, rules-end, dead-end, guess-levels 1-99)

- **Critical path**: 1) Generate DFS transcripts with multi-target labels using library, 2) Train with multi-target loss on rule tokens, optionally L1 for guess tokens, 3) At inference use argmax for deterministic DFS or sample with restarts for depth-1 guessing

- **Design tradeoffs**: Tokenization reduces sequence length but increases vocabulary size (900 vs ~30); L1 theoretically optimal but may be less stable than L2; Depth-1 simpler but may not generalize to harder problems

- **Failure signatures**: Rule-learning stall (<90% accuracy) suggests multi-target loss implementation issues; infinite loops suggest guess-level token increment problems; poor guess efficiency (>2 median guesses) suggests L1 loss implementation issues

- **First 3 experiments**: 1) Ablate tokenization: train with triplet vs action-level, expect slower convergence, 2) Compare L1 vs L2 on fixed test set, measure median guesses and accuracy, 3) Test generalization to 1-in-3 SAT, verify 99%+ accuracy

## Open Questions the Paper Calls Out

- **Adaptive, multi-level guessing strategies**: Can the framework extend beyond depth-1, non-adaptive policies? The current theoretical connection to contextual MIN-SUM SET COVER relies on single-level guessing simplification; relaxing this requires new theoretical grounding. Resolution would require modified training objective and model architecture that successfully learns to navigate search trees with depth > 1.

- **Optimal loss functions for multi-level policies**: What specific loss functions are optimal for training randomized multi-level policies that determine search depth and backtracking? Section 5 identifies this as a challenge but doesn't propose solution. Resolution would require derivation of novel loss function for multi-level search that converges and results in fewer expected reasoning steps.

- **Transfer to TSP and other NP problems**: How effectively does the framework transfer to Traveling Salesman Problem and other NP problems with different constraint structures? While the abstract mentions TSP as a target, experimental results are limited to Sudoku and 1-in-3 SAT. Resolution would require experimental results showing comparable state-of-the-art accuracy and efficiency on standard TSP benchmarks.

## Limitations

- Depth-1 non-adaptive guessing assumption may not generalize to harder combinatorial problems or adversarial instance distributions
- Dependence on transcript generation quality creates reproducibility gaps, especially around guess-level token handling
- Action-level tokenization may face vocabulary explosion for larger combinatorial problems, though scaling concerns aren't addressed

## Confidence

**High confidence**: Effectiveness of action-level tokenization with multi-target loss for accelerating rule-learning (Mechanism 1) - empirical results in Figure 3 clearly show improvement, straightforward to validate through ablation

**Medium confidence**: DFS with backtracking framework's ability to extend beyond fixed-strategy imitation (Mechanism 2) - well-motivated but implementation complexity of handling backtracking tokens introduces potential failure points

**Medium confidence**: MIN-SUM SET COVER loss function's ability to minimize expected reasoning steps (Mechanism 3) - theoretical analysis sound under stated assumptions, but depth-1 non-adaptive assumption limits generalizability

## Next Checks

1. **Ablation study on tokenization schemes**: Train identical models with triplet tokenization versus action-level tokenization on Sudoku. Measure convergence speed and final accuracy to validate the claimed ~3× sequence length reduction benefit.

2. **Loss function comparison on fixed test set**: Evaluate both L1 (MIN-SUM SET COVER) and L2 (standard cross-entropy) losses on 10,000 held-out Sudoku puzzles. Measure median number of guesses and solve accuracy to confirm L1's superiority in step minimization.

3. **Generalization to 1-in-3 SAT**: Using the provided transcript generation library, train the framework on 1-in-3 SAT instances. Verify the claimed 99%+ accuracy and compare solution quality against the Sudoku results to assess domain transferability.