---
ver: rpa2
title: Ethical Considerations of Large Language Models in Game Playing
arxiv_id: '2508.16065'
source_url: https://arxiv.org/abs/2508.16065
tags:
- gender
- werewolf
- player
- male
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores ethical concerns in large language model (LLM)
  behavior during game playing, focusing on gender bias in the social deduction game
  Werewolf. Using prompt templates with and without explicit gender information, the
  authors evaluate how LLMs adjust their decision-making across roles such as Werewolf,
  Guard, and Seer.
---

# Ethical Considerations of Large Language Models in Game Playing

## Quick Facts
- **arXiv ID:** 2508.16065
- **Source URL:** https://arxiv.org/abs/2508.16065
- **Reference count:** 40
- **Primary result:** LLM-based agents exhibit measurable gender bias in game-playing decisions, with sensitivity varying by role and detectable even through implicit name-based gender cues.

## Executive Summary
This study systematically evaluates gender bias in LLM-based agents playing the social deduction game Werewolf. Through controlled experiments manipulating explicit and implicit gender information in prompts, the authors demonstrate that LLMs adjust their strategic decisions based on gender cues. The research reveals that certain roles (Guard, Werewolf) show higher sensitivity to gender information than others (Seer), and that implicit gender signals through names can still trigger biased behavior. The findings highlight the need for fairness-aware approaches in LLM deployment for interactive applications and demonstrate how structured game environments can serve as effective testbeds for ethical AI evaluation.

## Method Summary
The research employs GLM-3 as the base model for seven LLM agents playing Werewolf with predefined role distributions. Four prompt template variants systematically manipulate gender information: no gender shown, gender shown, own gender reversed, and others' gender reversed. The study measures behavioral changes across three scenarios—skill selection (kill/protect/see targets), voting, and reliability assessment—using frequency-based metrics and fairness scores. Implicit gender experiments replace explicit labels with names having >99% gender association in SSA data. A minimum of 96 games are simulated for explicit gender conditions, with 70 runs for name-based experiments.

## Key Results
- Gender cues significantly influence LLM decision-making, with behavioral change frequencies above 0.5 for most roles
- Implicit gender signals through names trigger discriminatory behavior comparable to explicit gender labels
- Role sensitivity varies substantially: Guard (fairness 0.353) and Werewolf (fairness 0.450) show higher bias than Seer (fairness 0.635)
- Fairness scores measure decision consistency when other players' genders are reversed

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: When gender information is introduced into prompts, LLM-based agents modify their game-playing decisions, with the degree of change varying by role.
- **Mechanism**: Controlled prompt variations compare gender-informed vs. gender-omitted conditions across three game scenarios (skill selection, voting, reliability assessment), measuring behavioral change frequency via binary indicators.
- **Core assumption**: Training data associations between gender and behavioral patterns are activated when gender cues are present in prompts.
- **Evidence anchors**:
  - [abstract]: "Some roles, such as the Guard and Werewolf, are more sensitive than others to gender information, presented as a higher degree of behavioural change."
  - [section]: Section 4.2 reports "providing gender information to LLM-based agents significantly affects their behaviour" with frequencies above 0.5 for most roles across scenarios s1 and s2.
  - [corpus]: Limited direct corpus support for this specific mechanism in game-playing contexts.
- **Break condition**: If frequencies of behavioral change fall below 0.5 across all roles and scenarios when comparing gender-informed vs. gender-omitted conditions.

### Mechanism 2
- **Claim**: LLMs can infer gender from name-based cues and exhibit biased decision-making even without explicit gender labels.
- **Mechanism**: Explicit gender markers are replaced with first names having >99% gender association in SSA data; behavioral changes are measured using identical frequency metrics.
- **Core assumption**: LLMs encode statistical associations between names and gender from training data, enabling inference.
- **Evidence anchors**:
  - [abstract]: "LLMs still exhibit discriminatory tendencies even in the absence of explicit gender labels."
  - [section]: Section 7.3 shows "dotted bars, indicative of discriminatory behaviour, still have a non-negligible proportion" when using names instead of explicit gender labels.
  - [corpus]: Corpus includes gender bias studies in LLMs, but no direct work on implicit inference in game contexts.
- **Break condition**: If discriminatory behavior disappears when names with equally strong gender associations but different cultural origins are used.

### Mechanism 3
- **Claim**: Different game roles exhibit varying sensitivity to gender information, with Guard and Werewolf showing higher sensitivity than Seer.
- **Mechanism**: Fairness scores (Θ_s) measure decision consistency when other players' genders are reversed; scores vary by role (Guard: 0.353, Seer: 0.635).
- **Core assumption**: Role-specific strategic objectives interact differently with demographic associations embedded in training data.
- **Evidence anchors**:
  - [abstract]: "Some roles, such as the Guard and Werewolf, are more sensitive than others to gender information."
  - [section]: Section 6.2 Figure 9 reports Seer fairness (0.635), Werewolf (0.450), Guard (0.353) in scenario s1.
  - [corpus]: No corpus papers address role-specific sensitivity in LLM game-playing agents.
- **Break condition**: If all roles show fairness scores within 0.1 standard deviation across all scenarios.

## Foundational Learning

- **Concept: Counterfactual Fairness Testing**
  - Why needed: The paper uses gender reversal (swapping labels while holding context constant) as a causal fairness metric.
  - Quick check question: Can you explain how swapping gender labels for other players while keeping game state fixed isolates bias in decision-making?

- **Concept: Social Deduction Game Scenarios**
  - Why needed: Understanding the three evaluation scenarios (skill use, voting, reliability assessment) is essential to interpret behavioral metrics.
  - Quick check question: Which scenario(s) involve decisions that directly eliminate players from the game?

- **Concept: Implicit vs. Explicit Demographic Signals**
  - Why needed: The paper demonstrates bias persists even when gender is conveyed through proxy variables (names) rather than explicit labels.
  - Quick check question: Why might implicit signals be harder to mitigate through prompt-based interventions than explicit ones?

## Architecture Onboarding

- **Component map**: Prompt Template System -> GLM-3 Base Model -> Game State Manager -> Behavioral Metrics Calculator -> Deductive Reasoning Pipeline
- **Critical path**:
  1. Initialize game with balanced gender distribution (N_players × role configurations must be multiple of 48)
  2. Apply selected prompt template with appropriate gender manipulations
  3. Collect LLM decisions for each scenario (kill/protect/see targets, votes, reliability scores)
  4. Compare decisions across gender conditions using frequency-based metrics
  5. Aggregate fairness scores across minimum 96 games for statistical validity

- **Design tradeoffs**:
  - Single-model design (GLM-3) ensures consistency but limits generalizability
  - 7-player configuration enables balanced gender representation across all roles
  - Frequency metrics are interpretable but may miss nuanced reasoning biases

- **Failure signatures**:
  - Fairness scores near 1.0 for all roles: gender manipulation ineffective (check prompt template formatting)
  - High variance across identical runs: uncontrolled temperature or random seeds
  - Name-based experiments show no bias: selected names lack strong gender associations in model's training corpus

- **First 3 experiments**:
  1. Run 10 games with Template 1 (all gender hidden) to establish baseline behavior distributions per role.
  2. Run 10 games with Template 2 vs. Template 1 comparison to measure self-gender influence across all three scenarios.
  3. Run 10 games with Template 4 (other-player gender reversed) to compute baseline fairness scores (Θ_s) for each role.

## Open Questions the Paper Calls Out

- **Question:** Do the gender bias patterns observed in Werewolf generalize to other interactive or narrative-driven game environments?
  - **Basis in paper:** [explicit] The conclusion states, "Future studies include determining whether similar bias patterns occur in other types of interactive or narrative-driven games."
  - **Why unresolved:** The current study focused exclusively on the social deduction game Werewolf as a case study.
  - **What evidence would resolve it:** Replicating the bias measurement methodology across diverse game genres (e.g., RPGs, negotiation games) to compare behavioral metrics.

- **Question:** Can prompt engineering or fairness-aware fine-tuning effectively mitigate gender bias in LLM-based game agents without degrading strategic performance?
  - **Basis in paper:** [explicit] Section 8.1 proposes these as "potential solutions" but notes they need "ongoing evaluation using game-specific fairness metrics."
  - **Why unresolved:** The paper identifies the bias but does not implement or validate specific mitigation strategies.
  - **What evidence would resolve it:** Experiments measuring bias reduction versus win-rates or reasoning accuracy in agents using debiased prompts or fine-tuned models.

- **Question:** To what extent do other sensitive demographic attributes (e.g., race, culture, or religion) influence LLM decision-making in social deduction contexts?
  - **Basis in paper:** [explicit] Section 8.4 notes that "other demographic or contextual factors may also play a role and warrant further investigation."
  - **Why unresolved:** The experimental scope was strictly limited to gender information (explicit labels and implicit name associations).
  - **What evidence would resolve it:** Ablation studies introducing various demographic markers into player profiles to measure resulting changes in voting and skill usage.

## Limitations

- Findings based on single LLM model (GLM-3), limiting generalizability to other architectures
- Controlled Werewolf environment may not reflect real-world decision-making complexity
- Sample sizes (96 games explicit, 70 runs implicit) may not capture rare bias manifestations
- Binary gender representations exclude non-binary identities and intersectional factors

## Confidence

- **High confidence**: Gender cues affect LLM decision-making frequency (Mechanism 1)
- **Medium confidence**: Names serve as effective implicit gender proxies (Mechanism 2)
- **Medium confidence**: Role-specific sensitivity differences (Mechanism 3)

## Next Checks

1. **Cross-model validation**: Test whether gender bias patterns persist across different LLM architectures (GPT, Claude, Llama) using identical prompt templates and game scenarios.

2. **Cultural generalization test**: Repeat implicit gender experiments using names with strong gender associations in different cultural contexts to assess whether bias stems from universal statistical patterns or specific training corpus demographics.

3. **Extended fairness metrics**: Implement counterfactual fairness testing that manipulates multiple demographic variables simultaneously to evaluate intersectional bias effects beyond binary gender.