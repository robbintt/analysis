---
ver: rpa2
title: 'GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation
  through Formal Language'
arxiv_id: '2510.27448'
source_url: https://arxiv.org/abs/2510.27448
tags:
- geometric
- data
- problems
- language
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GeoFM addresses the scarcity of high-quality geometric data for
  training multimodal large language models (MLLMs) by synthesizing diverse, high-fidelity
  geometric problems. It uses formal languages to explore combinations of metric conditions
  in geometric diagrams, ensuring correctness through symbolic reasoning.
---

# GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language

## Quick Facts
- **arXiv ID:** 2510.27448
- **Source URL:** https://arxiv.org/abs/2510.27448
- **Reference count:** 8
- **Primary result:** GeoFM-8B achieves 79.3% accuracy on MathVista-GPS and 77.9% on GeoQA, surpassing GPT-4o by 18.7% and 16.5% respectively.

## Executive Summary
GeoFM addresses the critical shortage of high-quality geometric data for training multimodal large language models by synthesizing diverse, high-fidelity geometric problems. It uses formal languages to explore combinations of metric conditions within geometric diagrams, ensuring correctness through a symbolic reasoning engine. The system converts seed problems into formal representations, generates new problems with different conditions and goals, and produces corresponding geometric diagrams. Trained models using GeoFM data demonstrate superior geometric reasoning capabilities, achieving state-of-the-art performance on benchmark datasets.

## Method Summary
GeoFM synthesizes geometric reasoning data through a pipeline that formalizes seed problems into Conditional Declaration Language (CDL), generates new problems by systematically substituting metric conditions via symbolic reasoning, and creates corresponding diagrams through constraint-based optimization. The method uses FormalGeo for symbolic solving, GMBL for diagram generation, and LLM-based rewriting with answer verification. The system processes seeds from FormalGeo7K and PGPS9K datasets to produce 80,000 synthetic problem-solution-diagram triples, which are then used to fine-tune MLLMs with full-parameter training for 2 epochs.

## Key Results
- GeoFM-8B achieves 79.3% accuracy on MathVista-GPS and 77.9% on GeoQA
- Outperforms GPT-4o by 18.7% on MathVista-GPS and 16.5% on GeoQA
- Surpasses best open-source model by 5.7% on MathVista-GPS and 2.7% on GeoQA
- Demonstrates 8.2% and 11.1% improvements over MAVIS-Geometry in diagram fidelity

## Why This Works (Mechanism)

### Mechanism 1: Metric Space Exploration via Formal Language Substitution
GeoFM systematically substitutes metric conditions within formal representations of seed problems to generate diverse, solvable geometric problems. By replacing n conditions from the original set with n conditions from the symbolically derived fact set, it explores the combinatorial space of valid question formulations. The effectiveness depends on the symbolic engine deriving sufficient additional metric facts to enable meaningful substitution rather than trivial variations.

### Mechanism 2: Bidirectional Verification for Noise Reduction
Cross-verification between symbolic engine outputs and LLM-rewritten natural language solutions filters noise while preserving fluency. FormalGeo derives formal solutions with explicit theorem traces, templates convert to preliminary natural language, and Qwen2.5-72B-Instruct rewrites for fluency. An LLM-based verifier compares rewritten answers to symbolic ground truth, retaining only consistent pairs to ensure data quality.

### Mechanism 3: Constraint-Tiered Diagram Synthesis via GMBL Optimization
Automated conversion of formal geometric constraints to GMBL, combined with strictness-tiered loss filtering, produces higher-fidelity diagrams than rule-based template methods. Constraints are categorized by strictness (e.g., point-on-line is stricter than segment-length-equality) with different loss thresholds. Images failing thresholds are filtered; passing images receive metric annotations from image CDL, ensuring visual quality perceptible to MLLMs.

## Foundational Learning

### Concept: Formal Language Representation for Geometry (CDL/FormalGeo)
- **Why needed here:** The entire GeoFM pipeline operates on formal representations. Without understanding CDL's four components (construction, text, image, goal), you cannot debug parsing failures or extend the system to new problem types.
- **Quick check question:** Given triangle ABC with AB=5, BC=7, angle B=60°, and goal "find AC", write the construction CDL, text CDL, and goal CDL. What additional metric facts could a symbolic engine derive?

### Concept: Symbolic Reasoning and Breadth-First Theorem Application
- **Why needed here:** GeoFM's correctness guarantee and diversity ceiling depend on the FormalGeo solver's ability to derive all possible metric facts. Understanding how theorem application expands the known fact set is critical for diagnosing low-diversity outputs.
- **Quick check question:** If a problem states AB ⟂ BC, AB=3, BC=4, what metric conditions could a symbolic engine derive that aren't explicitly stated? How would limiting BFS depth to 2 steps affect the derived fact set?

### Concept: Constraint Satisfaction and Loss Thresholding in Computational Geometry
- **Why needed here:** Diagram generation uses numerical optimization to satisfy geometric constraints encoded as loss terms. Understanding why different constraints require different strictness thresholds is essential for producing visually acceptable diagrams at scale.
- **Quick check question:** Why would a "point P lies on line AB" constraint require a stricter loss threshold than "segment CD equals segment EF" for producing diagrams that look correct to humans and MLLMs?

## Architecture Onboarding

### Component Map
Seed Problems (FormalGeo7K, PGPS9K) → Formalization Module → Metric Gatherer → Condition Combiner → Template Converter → LLM Rewriter → Answer Verifier → Formal Language Converter → Numerical Optimizer → Threshold Filter → Metric Annotator → GeoFM80K Dataset

### Critical Path
1. **Formalization Accuracy → Entire Pipeline Validity:** Parsing errors propagate to formal representations and cause systematic drift in generated problems and diagrams.
2. **Metric Richness ($|M_{all}|$) → Diversity Ceiling:** Algorithm 1 requires sufficient additional facts for meaningful substitution; solver completeness limits diversity.
3. **Answer Verification → Data Quality Gate:** This is the only filter between LLM rewriting and final training data; reasoning errors with correct answers may pass undetected.
4. **Diagram Fidelity Thresholds → Model Perception:** Threshold calibration balances quality vs. quantity; mis-calibration affects visual acceptability.

### Design Tradeoffs
| Decision | Benefit | Cost | Revisit When |
|----------|---------|------|--------------|
| FormalGeo over AlphaGeometry | Better metric geometry coverage | May not handle coordinate geometry | Extending beyond plane Euclidean geometry |
| Template + LLM rewrite vs. direct LLM generation | Grounds solutions in symbolic reasoning | Pipeline complexity | Template coverage becomes bottleneck |
| Answer-only verification vs. full solution verification | Scalable, catches most errors | Passes reasoning errors | Models show correct answers but flawed reasoning |
| Random n-condition substitution | Simple, creates combinatorial variety | May generate trivial problems | Difficulty analysis reveals mismatch |
| Heuristic point ordering for GMBL | Enables full automation | May produce suboptimal formulations | High diagram rejection rates |

### Failure Signatures
| Symptom | Likely Root Cause | Diagnostic |
|---------|-------------------|------------|
| Generated problems semantically identical to seeds | Low $|M_{all} \setminus M_p|$ | Sample seeds, run solver, inspect $M_{all}$ size |
| High answer verification rejection rate | LLM rewriter corrupting answers OR verification too strict | Manual inspection of rejected samples |
| Diagrams missing annotations or visually distorted | GMBL conversion errors, optimization failure | Visualize samples at each stage; log loss values |
| Model trained on GeoFM shows no benchmark improvement | Data distribution mismatch OR insufficient diversity | Compare GeoFM distributions to benchmarks |
| Parser failures on specific problem types | Text parser training gaps | Error analysis on held-out seeds |

### First 3 Experiments
1. **Ablation: Metric Space Richness vs. Problem Diversity**
   - Sample 100 seeds across difficulty levels
   - Run FormalGeo solver with varying BFS depth limits
   - Measure $|M_{all}|$ per seed and semantic diversity of generated problems
   - Hypothesis: Diversity scales with metric richness up to saturation point

2. **Validation: Answer Verification Residual Error Rate**
   - Generate 500 problem-solution pairs with full pipeline
   - Manually annotate 100 passed samples for reasoning correctness
   - Compare: pass rate vs. residual reasoning error rate
   - Hypothesis: Answer verification catches most errors but passes ~10-15% with reasoning flaws

3. **Isolation: Diagram Fidelity Contribution**
   - Train two LLaVA-NeXT-8B models: (a) GeoFM problems + GeoFM diagrams, (b) GeoFM problems + MAVIS-style diagrams
   - Evaluate on MathVista-GPS and GeoQA
   - Hypothesis: Diagram fidelity contributes 3-5% of total performance gain

## Open Questions the Paper Calls Out

### Open Question 1
Can geometric problems be synthesized entirely from scratch without relying on manually collected seed problems? The current framework is built upon the metric space and structure of existing seed problems, lacking a mechanism to originate new geometric configurations de novo.

### Open Question 2
How can the formalization pipeline be extended to handle word problems or diagrams lacking explicit geometric point identifiers? The current text and diagram parsers depend heavily on explicit point labels and structural syntax to map natural language to the formal Conditional Declaration Language.

### Open Question 3
Does the strict reliance on symbolic reasoning for solution generation limit the model's ability to learn creative or non-standard reasoning paths? The paper verifies answer accuracy but does not analyze the diversity or "human-likeness" of the reasoning chains in the synthetic data compared to human-authored proofs.

## Limitations
- Relies on manually collected seed problems rather than synthesizing from scratch
- Formalization pipeline struggles with word problems and unlabeled diagrams
- Symbolic reasoning may filter out valid but non-standard human reasoning strategies
- GMBL conversion depends on heuristic point ordering without quantitative validation

## Confidence
- **High confidence:** Benchmark results showing GeoFM models outperform GPT-4o and open-source baselines; formalization pipeline using established tools (FormalGeo, PGDPNet); answer verification methodology following MathVista protocol
- **Medium confidence:** Diagram generation quality claims based on single MAVIS comparison without ablation on diagram fidelity contribution; back-translation training data methodology partially detailed; threshold calibration for GMBL loss filtering not shown
- **Low confidence:** Claims about systematic exploration of metric space without reporting $M_{all}$ statistics or diversity metrics; effectiveness of heuristic point ordering for GMBL conversion without convergence failure analysis; scalability to problem types beyond plane Euclidean geometry

## Next Checks
1. Measure $M_{all}$ size and semantic diversity across 100 seed problems to confirm sufficient metric richness for meaningful substitution
2. Manually validate reasoning correctness (not just answers) in 100 passed samples to quantify residual noise in answer-verified data
3. Train models with GeoFM problems + GeoFM diagrams vs. GeoFM problems + MAVIS diagrams to isolate diagram fidelity contribution to performance