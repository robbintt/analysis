---
ver: rpa2
title: 'CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer'
arxiv_id: '2512.02711'
source_url: https://arxiv.org/abs/2512.02711
tags:
- languages
- safety
- language
- multilingual
- low-resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CREST introduces a multilingual safety guardrail that supports
  100 languages using only 0.13% of the training data by clustering languages based
  on representational similarity in XLM-R embeddings and training on just 13 high-resource
  languages. It outperforms small-scale baselines and matches large-scale models on
  six safety benchmarks, achieving strong zero-shot transfer to low-resource languages.
---

# CREST: Universal Safety Guardrails Through Cluster-Guided Cross-Lingual Transfer

## Quick Facts
- **arXiv ID:** 2512.02711
- **Source URL:** https://arxiv.org/abs/2512.02711
- **Reference count:** 17
- **Key outcome:** Achieves universal safety alignment across 100 languages using only 0.13% of training data via cluster-guided transfer

## Executive Summary
CREST introduces a multilingual safety guardrail that supports 100 languages using only 13 high-resource languages for training. By clustering languages based on representational similarity in XLM-R embeddings, the model achieves strong zero-shot transfer to low-resource languages while maintaining real-time inference speeds. The approach outperforms small-scale baselines and matches large-scale models on six safety benchmarks, demonstrating effective cross-lingual generalization through cluster-guided transfer learning.

## Method Summary
CREST translates the Aegis content safety dataset to 13 high-resource languages and fine-tunes XLM-R with a binary classification head. Languages are clustered using K-means on XLM-R sentence embeddings, enabling cluster-guided transfer where training on one high-resource language transfers to low-resource languages within the same cluster. The model achieves universal safety alignment across 100 languages while using only 0.13% of the training data required by large-scale baselines, with the Base variant (0.25B parameters) running 10x faster than models with ≥2.5B parameters.

## Key Results
- Achieves universal safety alignment across 100 languages using only 13 training languages
- Outperforms small-scale baselines and matches large-scale models on six safety benchmarks
- Base variant (0.25B parameters) runs 10x faster than models with ≥2.5B parameters while maintaining competitive F1 scores

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Training on one high-resource language per cluster transfers to low-resource languages within the same cluster
- **Mechanism:** XLM-R's pretrained embeddings place linguistically similar languages in proximate regions of representation space. When the model learns safety boundaries on a high-resource language (e.g., Hindi), these boundaries generalize to cluster neighbors (e.g., Sindhi, Kannada) because their embeddings occupy overlapping regions.
- **Core assumption:** Embedding proximity in XLM-R reflects functional similarity for safety classification, not just surface form
- **Evidence anchors:**
  - [abstract]: "cluster-based cross-lingual transfer from a few to 100 languages, enabling effective generalization to both unseen high-resource and low-resource languages"
  - [Section 6, Intra-Cluster Transfer]: Hindi-trained model achieved 85.62 F1 vs Sindhi-trained at 78.03 across 15 Indic languages
  - [corpus]: DeFTX (arxiv:2505.15090) confirms sparse fine-tuning transfers across languages sharing representational structure

### Mechanism 2
- **Claim:** Script overlap and subword tokenization coverage improve transfer reliability
- **Mechanism:** Languages sharing Latin script (Galician, Slovenian) show more stable cross-benchmark performance because XLM-R's SentencePiece tokenizer has higher vocabulary coverage, reducing token fragmentation and producing more coherent sentence representations
- **Core assumption:** Tokenization quality directly impacts classification head's ability to learn generalizable patterns
- **Evidence anchors:**
  - [Section 6, Fine-Grained Performance]: "languages written in Latin script exhibit more stable performance across benchmarks...due to script overlap and subword tokenization coverage"
  - [Section 6]: Icelandic underperforms despite Latin script due to "rich and complex morphological structure" causing high token fragmentation
  - [corpus]: Cross-Lingual Transfer for Low-Resource NLP (arxiv:2502.02722) notes tokenization disparities as a transfer bottleneck

### Mechanism 3
- **Claim:** Combining training languages from different clusters yields complementary generalization
- **Mechanism:** Hindi+Chinese training outperforms single-language training on both Indic and East-Southeast Asian clusters. Hindi contributes semantically richer, more transferable representations; Chinese provides character-level patterns. Together they cover diverse structural-lexical patterns
- **Core assumption:** Multi-cluster training reduces overfitting to single-language idiosyncrasies
- **Evidence anchors:**
  - [Section 6, Cross-Cluster Transfer]: Hindi+Chinese achieves 87.61 F1 on Indic cluster vs 86.26 (Hindi-only) and 82.68 (Chinese-only)
  - [Section 6]: "Combining Hindi and Chinese data mitigates this gap...signifying complementary generalization"
  - [corpus]: Limited direct corpus evidence for this specific complementary effect in safety contexts

## Foundational Learning

- **Concept: Cross-lingual transfer learning**
  - Why needed here: CREST's core premise is that knowledge from high-resource languages transfers zero-shot to low-resource languages via shared representations
  - Quick check question: Can you explain why a model trained only on English might still classify French inputs correctly?

- **Concept: K-means clustering on embedding centroids**
  - Why needed here: The paper clusters languages by computing mean embeddings per language and applying K-means; understanding this determines how to modify or extend the clustering
  - Quick check question: What would happen to cluster assignments if you used max-pooling instead of mean-pooling for sentence aggregation?

- **Concept: Binary classification heads on transformer encoders**
  - Why needed here: CREST adds a simple classification layer atop XLM-R; understanding this architecture is prerequisite to modifying the safety taxonomy
  - Quick check question: Where does the [CLS] token representation come from, and why is it used for classification?

## Architecture Onboarding

- **Component map:**
  - XLM-RoBERTa encoder (279M Base / 560M Large) -> Classification head (Dropout → Linear → Tanh → Dropout → Linear) -> Binary output
  - Language clustering module: Mean-pooled sentence embeddings -> per-language centroids -> K-means (k=8)
  - Translation pipeline: GPT-4o, M2M-Bart-50, OPUS-MT, Sarvam-Translate (language-dependent)

- **Critical path:**
  1. Translate Aegis training dataset to 13 selected high-resource languages
  2. Aggregate translated data into unified training corpus
  3. Fine-tune XLM-R with classification head on aggregated data
  4. Evaluate zero-shot on OOD low-resource languages

- **Design tradeoffs:**
  - Model size vs. speed: Base (0.25B) trades ~2 F1 points for faster inference; Large (0.5B) needed for complex reasoning patterns
  - Translation vs. native data: Machine translation scales but may misrepresent cultural nuances; native data is scarce
  - Cluster count (k=8): Chosen via maximal inertia; fewer clusters dilute intra-cluster similarity, more clusters require more training languages

- **Failure signatures:**
  - Unstable performance on morphologically rich languages (e.g., Icelandic) -> token fragmentation
  - Poor transfer across clusters (e.g., Chinese->Indic underperforms Hindi->Indic) -> train on representative from target cluster
  - Degradation on code-switched inputs -> baseline models fail here; CREST's multilingual exposure helps but not fully robust

- **First 3 experiments:**
  1. **Ablate cluster selection:** Train on random 13 languages (not cluster-guided) and compare F1 on OOD low-resource languages to validate clustering contribution
  2. **Vary cluster count:** Test k=4, k=12 to understand sensitivity of the inertia-based selection; measure F1 variance across OOD languages
  3. **Stress-test on cultural safety:** Evaluate on region-specific datasets (IndicSafe, Cultural Kaleidoscope) to identify where translation-based training fails to capture local harm norms

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation scope constrained to six English-centric safety benchmarks with limited cultural safety testing
- Machine translation introduces cultural bias risks and may not capture safety-relevant cultural nuances
- Tokenization quality issues for morphologically rich languages degrade transfer performance

## Confidence
**High Confidence Claims:**
- Cluster-guided transfer significantly reduces training data requirements (0.13% of full-scale baselines)
- Cross-lingual transfer works within linguistically similar clusters (Indic->Indic, East-Southeast Asian->East-Southeast Asian)
- Script overlap and tokenization quality directly impact transfer reliability
- CREST-Base achieves competitive F1 scores while enabling 10x faster inference

**Medium Confidence Claims:**
- Combining training languages from different clusters yields complementary generalization
- Zero-shot transfer generalizes reliably to unseen low-resource languages within clusters
- Machine translation quality (96.2% BLEU) is sufficient for safety alignment tasks

**Low Confidence Claims:**
- Universal safety alignment across 100 languages without any target-language fine-tuning
- Real-time on-device deployment feasibility across all 100 languages
- Cultural safety robustness across diverse regional contexts

## Next Checks
1. **Ablate cluster selection methodology:** Train on 13 randomly selected languages (not cluster-guided) and compare zero-shot F1 performance on OOD low-resource languages to quantify the clustering contribution.

2. **Cultural safety stress testing:** Systematically evaluate on region-specific safety datasets (IndicSafe, CSRT, Cultural Kaleidoscope) with human expert review of false positives/negatives to identify where translation-based training fails to capture local harm norms.

3. **Tokenization quality analysis:** Measure token fragmentation ratios across all 100 languages and correlate with classification performance degradation, focusing on morphologically complex languages to quantify subword tokenization impact on safety classification accuracy.