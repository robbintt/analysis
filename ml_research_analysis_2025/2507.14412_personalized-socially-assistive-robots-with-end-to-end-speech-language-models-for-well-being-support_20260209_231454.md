---
ver: rpa2
title: Personalized Socially Assistive Robots With End-to-End Speech-Language Models
  For Well-Being Support
arxiv_id: '2507.14412'
source_url: https://arxiv.org/abs/2507.14412
tags:
- robot
- participants
- well-being
- sars
- support
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored integrating end-to-end speech-language models
  (SLMs) with socially assistive robots (SARs) to support well-being. Using GPT-4o-realtime,
  the robot engaged 11 university students in a 15-minute gratitude-based exercise.
---

# Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support

## Quick Facts
- arXiv ID: 2507.14412
- Source URL: https://arxiv.org/abs/2507.14412
- Authors: Mengxue Fu; Zhonghao Shi; Minyu Huang; Siqi Liu; Mina Kian; Yirui Song; Maja J. Matarić
- Reference count: 22
- Primary result: GPT-4o-realtime integrated with Blossom robot improved self-reported gratitude and life satisfaction in 11 participants during a 15-minute gratitude exercise.

## Executive Summary
This study integrated GPT-4o-realtime, an end-to-end speech-language model, with a socially assistive robot (Blossom) to support well-being through a gratitude-based exercise. The system used a three-state state machine for non-verbal behaviors (idle/breathing, listening/nodding, speaking/head-shaking) and push-to-talk interaction. Results showed participants perceived natural turn-taking and adaptive responses, with significant improvements in self-reported gratitude and life satisfaction post-interaction. However, robot movements were repetitive and back-channeling lacked synchronization, while the voice was rated appropriate but lacked emotional expressiveness. The findings demonstrate the potential of end-to-end SLMs to enhance SARs for well-being support while highlighting areas for improvement.

## Method Summary
The study deployed GPT-4o-realtime with a modified Blossom robot in a 15-minute gratitude exercise with 11 university students. A Flask server interfaced a web application with the robot, implementing a three-state state machine for non-verbal behavior. Participants used push-to-talk mouse control for speech input. Pre- and post-interaction surveys measured well-being (SWLS, GQ-6) and user experience (Likert scales on turn-taking, empathy, etc.). Analysis used Wilcoxon signed-rank tests to evaluate changes.

## Key Results
- Participants perceived turn-taking as natural and responses as adaptive, though verbal feedback was described as generic and repetitive
- Self-reported gratitude (GQ-6) and life satisfaction (SWLS) scores significantly improved post-interaction
- Robot movements were rated repetitive and not well-synchronized with speech, with vocal expressiveness lacking emotional attunement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: End-to-end SLMs reduce dialogue latency by eliminating intermediate processing steps, enabling more natural turn-taking.
- Mechanism: Traditional SAR dialogue pipelines cascade STT → dialogue management → TTS, where each module's inference time compounds into perceptible delays. An end-to-end SLM (e.g., GPT-4o-realtime) tokenizes audio input directly and synthesizes audio output without intermediate text representation, shortening the feedback loop.
- Core assumption: Users perceive turn-taking as more natural when response latency approaches human conversational timing (typically <500ms).
- Evidence anchors: [abstract] "SLM enables real-time speech input and output without intermediate text steps"; [Section 2.2] Describes cascaded pipeline limitations: "inference time introduced by each module contributed to latency and negatively affected the usability"; [corpus] Weak direct comparison—no baseline condition included in this study; related SAR papers (VITA, Spitale et al.) report similar latency issues but use cascaded approaches.
- Break condition: If network/API latency dominates total response time, the SLM's architectural advantage diminishes. Two participants reported lag "likely caused by network issues."

### Mechanism 2
- Claim: Synchronized non-verbal robot behaviors signal active listening and enhance perceived empathy.
- Mechanism: Robot movement states (idle/breathing, listening/nodding, speaking/head-shaking) are triggered by conversation state changes from the SLM, providing back-channeling cues that indicate attentiveness.
- Core assumption: Users interpret context-appropriate robot movements as evidence of engagement, even when verbal content is generic.
- Evidence anchors: [abstract] Participants perceived "natural turn-taking, back-channeling, and adaptive responses"; [Section 3.1] "movement-related modules... corresponded to different states of the interaction"; [Section 4] H2b (active listening) rated significantly above neutral (p = .004), but H2a (movement synchronization) showed no significant difference from neutral; [corpus] Neighboring SAR papers emphasize multi-modal feedback but don't isolate non-verbal synchronization effects.
- Break condition: Repetitive or poorly-timed movements undermine the effect. Participants reported "nodding a lot... looked too much like a robot" and motor noise during pauses was distracting.

### Mechanism 3
- Claim: LLM-based response generation enables content adaptation to user input, but generic phrasing limits perceived depth of understanding.
- Mechanism: The SLM generates responses conditioned on the user's speech input through its pre-trained conversational capabilities, allowing topic-relevant replies without pre-scripted dialogue trees.
- Core assumption: Users value response relevance but also expect phrasing variety and emotional attunement for well-being contexts.
- Evidence anchors: [abstract] "adaptive responses" observed; "verbal feedback as generic and repetitive"; [Section 4] H3 supported (adaptiveness rated significantly above neutral, p = .010); [Section 5 Discussion] "participants agreed the responses were relevant, they also described them as 'too structured.' One participant remarked, 'I felt like it heard me, but I didn't feel understood.'"; [corpus] Tell Me (arXiv:2511.14445) uses RAG and agentic planning for mental well-being dialogue—suggests prompt engineering alone may be insufficient.
- Break condition: Basic prompting without domain-specific fine-tuning or sophisticated prompting frameworks produces rigid response patterns that users perceive as formulaic.

## Foundational Learning

- Concept: **Cascaded vs. End-to-End Dialogue Architecture**
  - Why needed here: Understanding why replacing STT→LLM→TTS with a unified SLM matters for latency and interaction quality.
  - Quick check question: In a cascaded pipeline with 200ms STT, 300ms LLM, and 150ms TTS, what's the minimum total latency before the robot begins responding?

- Concept: **Back-Channeling in Conversation**
  - Why needed here: Non-verbal cues (nodding, "mm-hmm") signal engagement; their absence makes robots feel unresponsive.
  - Quick check question: If a robot nods continuously regardless of what the user says, how might a user interpret this behavior?

- Concept: **Push-to-Talk vs. Full-Duplex Interaction**
  - Why needed here: This study used mouse press-to-speak, simplifying turn-taking detection; real-world deployment requires voice activity detection.
  - Quick check question: What challenges arise when transitioning from push-to-talk to free-form conversational turn-taking?

## Architecture Onboarding

- Component map:
  - User mouse press → Flask server → robot "listening" state (nodding)
  - User speech → GPT-4o-realtime API → robot "speaking" state (head-shaking)
  - SLM response stream → robot movement synchronized with speech
  - Turn completion signal → robot returns to "idle" (breathing) state

- Critical path:
  1. User presses mouse → Flask receives signal → robot enters "listening" state (nodding)
  2. User releases mouse → audio sent to GPT-4o-realtime → robot enters "speaking" state
  3. SLM streams audio response → robot performs head-shaking movement synchronized with speech
  4. SLM signals turn completion → robot returns to "idle" (breathing) state

- Design tradeoffs:
  - **Fixed vs. generated movements**: Current implementation uses 3 pre-programmed states; generated movements could improve synchronization but add complexity
  - **Push-to-talk vs. VAD**: Push-to-talk eliminates false triggers but feels unnatural; VAD enables hands-free but risks interruption
  - **Prompt engineering vs. fine-tuning**: Basic prompting is fast to implement but produces generic responses; fine-tuning on mental health dialogue data could improve personalization

- Failure signatures:
  - **Network lag**: Stuttering or delayed responses; two participants reported this
  - **Movement desynchronization**: Robot continues nodding after user stops speaking, or head-shaking doesn't align with speech onset
  - **Repetitive verbal patterns**: "That's wonderful!" used multiple times in similar contexts
  - **Flat vocal affect**: Voice doesn't mirror user's emotional tone (H4b not supported)

- First 3 experiments:
  1. **Latency benchmark**: Measure round-trip time from mouse release to first audio output; compare against cascaded baseline (STT+LLM+TTS) to quantify SLM advantage.
  2. **Movement synchronization test**: Vary the timing offset between speech onset and movement trigger; measure user ratings of naturalness at different delays (0ms, 200ms, 500ms).
  3. **Prompt variation study**: Compare basic prompting vs. structured prompting (e.g., role definition, response templates, emotional attunement instructions) on perceived personalization and empathy ratings.

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (N=11) limits generalizability and statistical power for detecting subtle interaction effects
- Push-to-talk interaction model creates artificial barrier compared to natural conversational turn-taking
- Network dependency introduces variability in response timing and quality
- Basic prompting strategy produces generic responses that limit perceived depth of understanding

## Confidence

- **High Confidence**: Well-being improvements (pre/post SWLS and GQ-6 changes). These are objective measurement outcomes with established validity.
- **Medium Confidence**: Natural turn-taking perception. Supported by significant H1 results, though influenced by push-to-talk mechanics rather than pure SLM advantage.
- **Medium Confidence**: Adaptive responses. H3 shows significance, but generic phrasing indicates superficial rather than deep adaptation.
- **Low Confidence**: Emotional expressiveness and synchronization quality. Both H4a and H4b show no significant improvement, and qualitative feedback indicates these are actual weaknesses requiring fundamental architectural changes.

## Next Checks

1. **Baseline Comparison Validation**: Conduct a between-subjects study comparing the end-to-end SLM approach against a cascaded pipeline (STT→LLM→TTS) with identical robot hardware, tasks, and prompts. Measure round-trip latency and user experience metrics to isolate the SLM's contribution beyond hardware improvements.

2. **Real-World Deployment Test**: Deploy the system in an uncontrolled environment (e.g., university counseling center waiting room) for two weeks, tracking usage patterns, user dropout rates, and qualitative feedback about network reliability and interaction naturalness in varied acoustic conditions.

3. **Prompt Engineering Efficacy Study**: Systematically vary prompt complexity across three conditions—basic (current), structured (role definition, response templates), and few-shot (example dialogues included)—while keeping the SLM constant. Measure changes in perceived empathy, personalization, and response variety to determine if prompt sophistication can overcome generic response patterns.