---
ver: rpa2
title: 'Plan-over-Graph: Towards Parallelable LLM Agent Schedule'
arxiv_id: '2502.14563'
source_url: https://arxiv.org/abs/2502.14563
tags:
- graph
- time
- task
- cost
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of enabling parallel execution
  in LLM-based agent planning. It introduces plan-over-graph, a novel paradigm where
  an LLM first extracts a task graph from a textual description and then plans over
  the graph structure to generate parallelizable sub-task plans.
---

# Plan-over-Graph: Towards Parallelable LLM Agent Schedule

## Quick Facts
- arXiv ID: 2502.14563
- Source URL: https://arxiv.org/abs/2502.14563
- Reference count: 40
- Key outcome: Plan-over-graph significantly improves planning performance, with 71.6% optimal rate and 83.6% success rate on abstract graphs, outperforming baseline models.

## Executive Summary
This paper addresses the challenge of enabling parallel execution in LLM-based agent planning by introducing plan-over-graph, a novel paradigm that first extracts task graphs from textual descriptions and then plans over these graph structures to generate parallelizable sub-task plans. The authors construct a synthetic dataset of abstract task graphs and propose a two-stage training scheme combining supervised fine-tuning and direct preference optimization to improve graph understanding. Experiments show that plan-over-graph significantly improves planning performance on both synthetic and real-world tasks, achieving up to 72.5% optimal rates for Llama models while reducing average time ratios by 0.39-0.81×.

## Method Summary
The plan-over-graph framework addresses the challenge of enabling parallel execution in LLM-based agent planning by first extracting task graphs from textual descriptions, then planning over these graph structures to generate parallelizable sub-task plans. The approach involves constructing a synthetic dataset of abstract task graphs with optimal and feasible solutions, then training a two-stage model using supervised fine-tuning followed by direct preference optimization. The model learns to understand graph topology and generate plans that minimize execution time while respecting dependencies, achieving significant improvements over baseline models on both synthetic and real-world tasks.

## Key Results
- Plan-over-graph achieves 71.6% optimal rate and 83.6% success rate on abstract graphs, outperforming baseline models.
- On real-world textual queries, optimal rates increase from 14.5% to 41.5% for Claude and from 0% to 72.5% for Llama.
- The approach reduces average time ratios by 0.39-0.81× and demonstrates time efficiency gains of 0.62-0.88× compared to sequential execution.

## Why This Works (Mechanism)

### Mechanism 1
Representing tasks as Directed Acyclic Graphs (DAGs) enables structural identification of parallelizable subtasks. The paper formalizes tasks as G = (T, E) where vertices are subtasks and edges represent precedence constraints (ti ≺ tj). Subtasks without dependencies can execute concurrently. The end time calculation (End_time(pi) = max(End_time(pj)) + τpi) explicitly accounts for parallel execution rather than sequential blocking. Core assumption: Real-world tasks can be faithfully decomposed into discrete subtasks with well-defined dependencies without losing essential constraints.

### Mechanism 2
Two-stage training (SFT → DPO) improves graph comprehension and optimal plan selection beyond prompting alone. Stage 1 (SFT) trains on both optimal and feasible solutions using LoRA adapters, teaching graph-topology reasoning. Stage 2 (DPO) further refines preference toward optimal solutions by contrasting optimal vs. second-best feasible plans (loss in Eq. 13). This addresses the "comprehension collapse" phenomenon at scale. Core assumption: Graph understanding capability transfers from synthetic abstract graphs to real-world textual queries.

### Mechanism 3
Explicit graph extraction before planning reduces reasoning load compared to end-to-end textual planning. Decomposing into (1) extraction and (2) planning stages separates structural understanding from optimization. Even imperfect extraction (82% similarity for mismatched cases) enables better planning than direct textual inference, as the planning module focuses purely on dependency resolution. Core assumption: Extraction errors that preserve approximate graph structure are tolerable; planning competence matters more than perfect extraction.

## Foundational Learning

- Concept: **Directed Acyclic Graphs (DAGs) and Topological Ordering**
  - Why needed here: The entire framework represents tasks as DAGs; understanding precedence constraints and parallel execution requires knowing why DAGs prevent cycles and how topological sort enables scheduling.
  - Quick check question: Given nodes A→B, A→C, B→D, C→D, which pairs can execute in parallel?

- Concept: **Direct Preference Optimization (DPO)**
  - Why needed here: Stage 2 training uses DPO to distinguish optimal from feasible plans. Understanding the loss function (Eq. 13) and why it improves over SFT alone is essential for reproduction.
  - Quick check question: How does DPO differ from reinforcement learning with a reward model for this task?

- Concept: **Low-Rank Adaptation (LoRA)**
  - Why needed here: Paper uses LoRA for efficient fine-tuning. Understanding adapter architecture helps debug training issues and scale to larger models.
  - Quick check question: What are the memory tradeoffs of LoRA vs. full fine-tuning for a 7B parameter model?

## Architecture Onboarding

- Component map: Graph Extraction Module -> Planning Module -> Data Generation Pipeline -> Training Pipeline
- Critical path:
  1. Generate synthetic graphs (10-50 nodes, random or tree-based)
  2. Annotate with dynamic programming for optimal/feasible labels
  3. SFT training (8,192 context, 10 epochs, lr=1e-6)
  4. DPO refinement
  5. Inference: Extract graph → Plan with adapter loaded
- Design tradeoffs:
  - Random vs. tree-based graphs: Tree-based reflects hierarchical real-world tasks; random tests robustness
  - Edge density: Linear scaling [2n, 3n] avoids token overflow; uniform distribution stress-tests comprehension
  - Mix feasible solutions in SFT: Improves success rate (86.1% vs. 75.7%) but requires DPO to recover optimality
- Failure signatures:
  - **Invalid subtask**: Plan includes subtasks without corresponding rules (11.6% for trained Llama)
  - **Unavailable source**: Dependencies not satisfied before execution (4.8% for trained Llama, down from 30.1%)
  - **Extraction drift**: Generated rules don't match original graph (85% mismatch rate, but 82% avg similarity)
- First 3 experiments:
  1. Replicate pilot study (Table 1): Test base Llama on 10/30/50 node random graphs to confirm comprehension collapse baseline.
  2. Ablate training stages: Compare (SFT-only) vs. (SFT+DPO) on held-out test graphs to validate DPO contribution.
  3. Cross-structure transfer: Train on random graphs, test on tree-based (and vice versa) to assess structure generalization.

## Open Questions the Paper Calls Out

### Open Question 1
Can the "plan-over-graph" framework be extended to support dynamic planning where the agent refines the plan based on environmental feedback and perception? The authors identify this as a future direction, noting that current plans are static while real planning should be a dynamic process interacting with the environment.

### Open Question 2
How can the text-to-graph extraction capability of open-source models be improved to ensure high-fidelity task representation? The paper acknowledges that while planning capability is crucial, open-source models have shown certain flaws in extraction, which currently limits the pipeline's robustness.

### Open Question 3
What techniques can effectively mitigate the "hallucination of invalid subtasks" in trained models? Section 6.3 identifies "Invalid Subtask" errors as the current performance bottleneck, persisting even after training, suggesting a lack of strict constraint grounding.

## Limitations
- The paper demonstrates strong performance on synthetic graph data but limited validation on real-world tasks, with only 200 textual queries tested and modest graph extraction accuracy (15% exact match).
- Training pipeline details have gaps: LoRA rank/alpha values and DPO β temperature are unspecified, making exact reproduction difficult.
- The approach assumes tasks can be cleanly decomposed into DAGs with explicit dependencies, but real-world tasks often contain implicit, probabilistic, or context-dependent constraints that resist formalization.

## Confidence
- **High confidence**: The fundamental insight that DAG representation enables parallel planning is well-grounded and consistently validated across multiple experiments (Table 3, Table 4).
- **Medium confidence**: The two-stage training approach shows clear improvements, but the optimal hyperparameters and their sensitivity to different model scales remain unclear.
- **Medium confidence**: Real-world applicability claims are supported by limited textual query experiments; more diverse task types would strengthen the evidence.

## Next Checks
1. Test plan-over-graph on a benchmark with more diverse real-world tasks (e.g., TPS-Bench) to validate cross-domain generalization beyond the 200 textual queries used.
2. Conduct ablation studies varying LoRA rank and DPO β to understand hyperparameter sensitivity and establish robust configurations for different model sizes.
3. Evaluate performance degradation when introducing implicit dependencies or probabilistic constraints into the synthetic graphs to measure robustness to real-world complexity.