---
ver: rpa2
title: 'Brain-like emergent properties in deep networks: impact of network architecture,
  datasets and training'
arxiv_id: '2411.16326'
source_url: https://arxiv.org/abs/2411.16326
tags:
- brain
- networks
- properties
- page
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated which design principles in deep neural
  networks (DNNs) most strongly influence brain-like visual properties. The authors
  systematically tested over 30 state-of-the-art networks varying in architecture
  (CNNs vs ViTs), training datasets (objects, scenes, faces), and training regimes
  (supervised, self-supervised, adversarial) across 14 perceptual and neural properties
  previously identified as brain-like.
---

# Brain-like emergent properties in deep networks: impact of network architecture, datasets and training

## Quick Facts
- **arXiv ID:** 2411.16326
- **Source URL:** https://arxiv.org/abs/2411.16326
- **Authors:** Niranjan Rajesh; Georgin Jacob; SP Arun
- **Reference count:** 13
- **Primary result:** Network architecture (CNNs vs. ViTs) has the strongest impact on brain-like visual properties compared to training datasets or regimes.

## Executive Summary
This study systematically investigated which design principles in deep neural networks most strongly influence brain-like visual properties. Testing over 30 state-of-the-art networks varying in architecture, training datasets, and training regimes across 14 perceptual and neural properties, the authors found that architecture had the strongest impact on brain-like properties. CNNs excelled at correlated sparseness while vanilla ViTs performed better on mirror confusion and global shape processing. Some properties (object normalization, mirror confusion) emerged universally across all networks, while others (3D processing, surface invariance, relative size encoding) were consistently absent. These findings suggest architecture is the most critical factor in developing brain-like visual computations.

## Method Summary
The study tested over 30 state-of-the-art deep networks across different architectures (CNNs vs Vision Transformers), training datasets (objects, scenes, faces), and training regimes (supervised, self-supervised, adversarial). Researchers extracted penultimate layer activations from each network when presented with specialized stimulus sets designed to isolate specific perceptual properties. They calculated modulation indices for each property and normalized these by empirical "Brain Scores" to obtain Brain Property Scores (BPS). The resulting scores were analyzed through PCA to compare brain-like properties across network designs.

## Key Results
- Network architecture had the strongest impact on brain-like properties compared to dataset and training regime variations
- CNNs consistently showed closer alignment to brain responses in correlated sparseness experiments
- Vanilla ViTs performed better on mirror confusion and global shape processing
- Some properties (object normalization, mirror confusion) emerged universally across all networks
- Properties like 3D processing, surface invariance, and relative size encoding were consistently absent across all tested conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Network architecture imposes the strongest inductive bias on the emergence of brain-like visual properties, outweighing training data or regime.
- **Mechanism:** Architectural families process information through fundamentally different operations (convolution vs. self-attention). CNNs enforce hierarchical, local feature extraction, leading to better alignment with sparseness and Weber's Law. ViTs allow global information mixing from early layers, facilitating better global shape processing and mirror confusion. The structural constraint of the architecture dictates which brain-like properties are mathematically accessible during optimization.
- **Core assumption:** The "Brain Property Score" (BPS) effectively normalizes effect strengths so that disparate properties can be compared fairly across models.
- **Evidence anchors:**
  - [abstract] "First, network architecture had the strongest impact on brain-like properties compared to dataset and training regime variations."
  - [section] Page 12: "CNNs consistently exhibited closer alignment to brain responses in correlated sparseness experiments... only vanilla ViT models approached the brain's global shape processing advantage."
- **Break condition:** If the penultimate layer activations used for measurement fail to capture the full representational capacity of the network, or if specific hyperparameters confound the architectural comparison.

### Mechanism 2
- **Claim:** Optimization for object recognition on natural images universally forces the emergence of specific properties like object normalization and mirror confusion, regardless of architecture.
- **Mechanism:** The pressure to classify objects in cluttered natural scenes forces the network to learn linear superposition properties and statistical regularities. Because these properties are implicit in the structure of natural images and the classification objective, they appear across CNNs, ViTs, and self-supervised models.
- **Core assumption:** The "universally present" properties are emergent solutions to the recognition problem, not artifacts of the specific ImageNet dataset distribution.
- **Evidence anchors:**
  - [abstract] "The results revealed that some properties (object normalization, mirror confusion) emerged universally across all networks."
  - [section] Page 10: "Object Normalization likely emerges because both architectural families' individual units develop approximately linear superposition properties..."
- **Break condition:** If a network is trained on a non-natural dataset lacking distinct objects or vertical symmetry, these properties would likely fail to emerge.

### Mechanism 3
- **Claim:** The absence of 3D processing, surface invariance, and relative size encoding in current DNNs is caused by the lack of explicit depth and metric signals in 2D image datasets.
- **Mechanism:** Standard 2D image classification provides loss signals based on categorical labels but does not penalize the network for failing to separate 3D shape from 2D texture or for ignoring metric depth. Therefore, gradient descent settles on 2D shortcuts rather than developing the complex, invariant representations seen in primate vision.
- **Core assumption:** These properties are "absent" not because the networks lack the capacity to learn them, but because the training paradigm does not require them for the defined task.
- **Evidence anchors:**
  - [section] Page 11: "3D processing deficits likely stem from ImageNet's 2D nature... Surface invariance and relative size encoding may require understanding of shape and scene properties that are not explicitly rewarded by 2D image classification tasks."
- **Break condition:** If specialized datasets or auxiliary losses are introduced, this mechanism predicts these properties should emerge.

## Foundational Learning

- **Concept: Brain Property Score (BPS)**
  - **Why needed here:** To interpret the heatmap results. BPS is a normalized effect strength (model effect / brain effect), where 1.0 is a perfect match to human/monkey data and negative values indicate "anti-brain-like" behavior.
  - **Quick check question:** If a model has a BPS of -0.5 for Mirror Confusion, does it mean it has no mirror confusion or that it has *reverse* mirror confusion?

- **Concept: Inductive Bias (Architecture)**
  - **Why needed here:** To understand why CNNs and ViTs diverge. You must grasp that "inductive bias" refers to the set of assumptions a learner uses to predict outputs for inputs it hasn't encountered (e.g., CNNs assume spatial locality; ViTs assume relational relevance).
  - **Quick check question:** Why would a "Vanilla ViT" handle global shape better than a "Swin Transformer" (which uses windowed attention)?

- **Concept: Penultimate Layer Analysis**
  - **Why needed here:** The study extracts activations specifically from the layer before the classifier. This acts as a proxy for the "high-level visual cortex" (area IT) representation.
  - **Quick check question:** Why might looking *only* at the penultimate layer miss brain-like properties that exist in earlier, more retinotopic layers?

## Architecture Onboarding

- **Component map:** Specialized Stimulus Sets -> State-of-the-art DNNs -> Penultimate layer activations -> Modulation indices -> Brain Property Score (BPS) vector -> PCA projection
- **Critical path:**
  1. Select stimulus sets that isolate a single perceptual property (e.g., Weber's law lines)
  2. Pass stimuli through the network and extract the N-dimensional vector from the final pooling layer
  3. Calculate the specific effect strength formula defined in Methods (e.g., slope of response averaging)
  4. Normalize by the empirical "Brain Score" (the value observed in biological data)
- **Design tradeoffs:**
  - **CNNs:** Better for correlated sparseness and Weber's Law (local, incremental processing). Worse for global shape.
  - **Vanilla ViTs:** Best for global shape and mirror confusion (global attention). Worse for Weber's Law (unless scene/face trained).
  - **Hybrids (ConvNeXt/Swin):** Tend to cluster in the middle, losing the extreme benefits of pure architectures.
- **Failure signatures:**
  - **Anti-brain-like behavior:** Negative BPS (e.g., treating horizontal mirrors as more similar than vertical)
  - **Total absence:** A BPS of ~0 or statistically indistinguishable from noise, indicating the network has no representation for that concept
- **First 3 experiments:**
  1. **Baseline Verification:** Run the Mirror Confusion test (BP2) on a standard ResNet50 and a Vanilla ViT-Base. Verify that the ViT shows a higher positive BPS.
  2. **Layerwise Probe:** Extract activations from early, middle, and late layers of a VGG16 during the Object Normalization test. Confirm that the property (slope â‰ˆ 0.5) emerges only in the final layers (as per Supplementary S2).
  3. **Data Intervention:** Retrain a small CNN on a synthetic dataset with exaggerated depth cues to see if the 3D Processing BPS (BP11) can be shifted from 0 to a positive value.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does explicitly training deep networks to maximize specific Brain Property Scores (BPS) causally improve generalization on out-of-distribution (OOD) benchmarks?
- **Basis in paper:** [explicit] The authors conclude by raising "the intriguing possibility that training deep network to acquire these properties could lead to more generalizable and robust brain-like deep networks" (Page 25).
- **Why unresolved:** The study establishes correlations between properties and robustness (Supplementary S3) but does not perform interventional training to validate if acquiring these properties causes better performance.
- **What evidence would resolve it:** Training new models with a custom loss function weighted by BPS and measuring the resulting change in OOD accuracy and adversarial vulnerability.

### Open Question 2
- **Question:** What specific training modalities or architectural inductive biases are required to induce the "universally absent" properties, such as 3D processing and relative size encoding?
- **Basis in paper:** [inferred] The paper notes properties like 3D processing are consistently absent across all designs, suggesting "fundamental limitations" in current 2D, image-based paradigms (Page 15).
- **Why unresolved:** The study tested varied 2D datasets but did not assess if 3D-native inputs or non-convolutional/attention architectures could overcome these specific deficits.
- **What evidence would resolve it:** Evaluating networks trained on 3D data or equipped with geometric priors for the emergence of the missing relative size and surface invariance properties.

### Open Question 3
- **Question:** Can a hybrid architecture combining CNN local processing with ViT global attention capture the brain-like advantages of both families?
- **Basis in paper:** [inferred] The authors observe that CNNs excel at correlated sparseness while vanilla ViTs excel at global shape processing, with current hybrids clustering separately (Page 12-13).
- **Why unresolved:** The study compares existing families but does not propose a design specifically optimized to combine the distinct brain-like properties observed in separate architectures.
- **What evidence would resolve it:** Designing a network that explicitly couples convolutional locality with global attention mechanisms and testing if it simultaneously achieves high scores in both sparseness and global processing.

## Limitations
- Focus on penultimate layer activations may miss important brain-like properties that exist in earlier or intermediate layers
- Universality claims for object normalization and mirror confusion could be artifacts of specific training protocols or datasets
- Conclusion about "consistently absent" properties may be too strong, based only on tested architectures and training paradigms

## Confidence

- **High Confidence:** Architecture having the strongest impact on brain-like properties is well-supported by systematic comparison across 30+ networks and multiple properties
- **Medium Confidence:** Universality claims for object normalization and mirror confusion are supported but could be strengthened with additional validation
- **Low Confidence:** Conclusion that certain properties are "consistently absent" may be premature without testing alternative approaches

## Next Checks

1. **Layerwise Validation Test:** Re-run the entire battery of 14 perceptual tests across all 30+ networks, extracting activations from 3-4 different layers rather than just the final layer to determine whether observed brain-like properties are truly high-level phenomena.

2. **Architectural Modification Test:** Take the vanilla ViT architecture and systematically modify it to include explicit depth processing capabilities (e.g., depth estimation auxiliary tasks, 3D convolutional layers). Retrain on the same datasets and re-measure the 3D processing, surface invariance, and relative size encoding properties.

3. **Dataset Intervention Test:** Train a subset of CNN and ViT architectures on synthetic datasets that explicitly emphasize 3D structure, metric depth, and surface properties (e.g., ShapeNet renderings with depth maps and surface normals). Compare the emergence of 3D processing properties against models trained on standard 2D datasets.