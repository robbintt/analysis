---
ver: rpa2
title: '"Less is More": Reducing Cognitive Load and Task Drift in Real-Time Multimodal
  Assistive Agents for the Visually Impaired'
arxiv_id: '2511.00945'
source_url: https://arxiv.org/abs/2511.00945
tags:
- via-agent
- user
- load
- systems
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the high cognitive load and task drift issues
  in current multimodal assistive agents for visually impaired people. It introduces
  VIA-Agent, a prototype system co-optimizing a specialized VLM core with a real-time
  communication embodiment.
---

# "Less is More": Reducing Cognitive Load and Task Drift in Real-Time Multimodal Assistive Agents for the Visually Impaired

## Quick Facts
- **arXiv ID**: 2511.00945
- **Source URL**: https://arxiv.org/abs/2511.00945
- **Authors**: Yi Zhao; Siqi Wang; Qiqun Geng; Erxin Yu; Jing Li
- **Reference count**: 40
- **Primary result**: VIA-Agent prototype significantly outperforms baselines on task efficiency (39.9% faster than Doubao), reduces cognitive load, and improves usability for visually impaired users

## Executive Summary
This paper addresses critical limitations in current multimodal assistive agents for visually impaired users: high cognitive load and task drift during real-time interactions. The authors introduce VIA-Agent, a prototype system that co-optimizes a specialized Vision-Language Model (VLM) core with a real-time communication embodiment. The system features a goal-persistent design and calibrated conciseness to generate brief, actionable guidance, combined with streaming video and audio for low-latency interaction. A comparative user study with 9 visually impaired participants demonstrated VIA-Agent's superior performance over baseline systems in task efficiency, cognitive load reduction, and usability scores.

## Method Summary
The authors developed VIA-Agent as a co-optimized system combining a specialized VLM core with real-time communication embodiment. The VLM core implements goal-persistent design and calibrated conciseness to maintain task focus and provide brief, actionable guidance. The embodiment utilizes streaming video and audio for low-latency interaction. The system was evaluated through a comparative user study involving 9 visually impaired participants performing controlled experimental tasks, with performance metrics including task completion time, cognitive load measurements, and usability assessments compared against a baseline system (Doubao).

## Key Results
- VIA-Agent achieved 39.9% faster task completion compared to baseline Doubao system
- Significant reduction in cognitive load measured through standardized assessment tools
- Improved usability scores in comparative evaluation with visually impaired participants

## Why This Works (Mechanism)
VIA-Agent addresses the fundamental challenge of maintaining task focus while minimizing cognitive burden in assistive systems. The goal-persistent VLM core prevents task drift by maintaining context across interactions and filtering irrelevant information. The calibrated conciseness mechanism ensures that responses are brief and actionable rather than verbose, reducing the mental effort required to process guidance. The real-time streaming embodiment enables immediate feedback and low-latency responses, critical for maintaining user engagement and preventing cognitive overload during time-sensitive tasks.

## Foundational Learning
- **Vision-Language Models (VLMs)**: AI systems that process both visual and textual information; needed for understanding visual scenes and generating natural language guidance for visually impaired users; quick check: can the VLM accurately describe complex visual scenes with minimal context loss
- **Cognitive Load Theory**: Framework for understanding mental effort during task processing; needed to optimize information delivery and prevent overwhelming users; quick check: does the system maintain task performance while reducing subjective cognitive effort
- **Real-time Streaming Communication**: Continuous data transmission protocols; needed for immediate feedback in assistive applications; quick check: latency remains under 200ms for interactive tasks
- **Goal-persistent Design**: Architectural pattern maintaining task context across interactions; needed to prevent task drift and maintain focus; quick check: can the system resume interrupted tasks without significant context loss
- **Calibrated Conciseness**: Information delivery optimization balancing brevity and completeness; needed to reduce processing overhead while maintaining guidance quality; quick check: user comprehension remains high with minimal information content

## Architecture Onboarding

**Component Map**: Visual Sensor -> VLM Core -> Response Generator -> Audio Output -> User
                         -> Context Manager
                         -> Goal Tracker

**Critical Path**: Visual Sensor → VLM Core → Response Generator → Audio Output

**Design Tradeoffs**: 
- Conciseness vs. completeness: Prioritizing brief responses may occasionally omit useful details
- Latency vs. processing depth: Real-time requirements limit complex visual analysis
- Goal persistence vs. flexibility: Strong context maintenance may reduce adaptability to new tasks

**Failure Signatures**:
- Task drift: User reports losing track of original objective
- Cognitive overload: User requests repetition or shows hesitation
- Communication breakdown: Extended periods of non-response or irrelevant output

**First 3 Experiments**:
1. Measure task completion time differences between VIA-Agent and baseline across 5 task categories
2. Compare cognitive load scores using standardized NASA-TLX assessment for both systems
3. Evaluate usability ratings through post-task questionnaires focusing on clarity and helpfulness

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size of 9 visually impaired participants limits generalizability across diverse vision impairment levels
- Controlled experimental tasks may not fully represent real-world complexity and variability
- Limited comparison to only one baseline system (Doubao) provides narrow context for performance evaluation
- Study duration focused on controlled tasks rather than extended real-world deployment

## Confidence

**High Confidence**: Task efficiency improvements (39.9% faster) and cognitive load reduction are well-supported by comparative user study methodology and quantitative measurements. Goal-persistent VLM design with calibrated conciseness addresses documented issues in existing systems.

**Medium Confidence**: Usability score improvements and qualitative feedback are credible but would benefit from larger sample sizes and more diverse user populations. Streaming embodiment's low-latency claims are plausible but require more extensive testing.

**Low Confidence**: Long-term effectiveness in real-world settings and sustained cognitive load benefits over extended use cannot be validated from current study design. VLM core calibration optimization may not generalize across different visual assistance task types.

## Next Checks
1. Conduct longitudinal studies with 30+ visually impaired participants across different vision impairment levels using VIA-Agent in real-world environments for 4+ weeks to assess sustained performance and identify emergent issues.

2. Expand comparative evaluation to include 3-4 additional multimodal assistive agents across a broader range of task types and complexity levels.

3. Implement A/B testing with variable levels of VLM core conciseness and goal-persistence to determine optimal parameter ranges for different user groups and task categories.