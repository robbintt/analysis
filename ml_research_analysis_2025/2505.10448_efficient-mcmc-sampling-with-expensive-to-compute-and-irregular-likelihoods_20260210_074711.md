---
ver: rpa2
title: Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods
arxiv_id: '2505.10448'
source_url: https://arxiv.org/abs/2505.10448
tags:
- proxy
- likelihood
- mcmc
- subset
- hints
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses Bayesian inference with Markov Chain Monte
  Carlo (MCMC) when the likelihood function is irregular and expensive to compute,
  as commonly occurs in disease modelling and other complex systems. The authors adapt
  several subset samplers to handle irregular likelihoods where gradient information
  is unavailable or unreliable, introducing data-driven proxies to replace Taylor
  expansions and a novel computation-cost aware adaptive controller.
---

# Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods

## Quick Facts
- arXiv ID: 2505.10448
- Source URL: https://arxiv.org/abs/2505.10448
- Reference count: 10
- Primary result: HINTS with adaptive proposals and data-driven proxy achieves best sampling error within fixed computational budget on disease modeling tasks

## Executive Summary
This work addresses Bayesian inference with Markov Chain Monte Carlo (MCMC) when the likelihood function is irregular and expensive to compute, as commonly occurs in disease modelling and other complex systems. The authors adapt several subset samplers to handle irregular likelihoods where gradient information is unavailable or unreliable, introducing data-driven proxies to replace Taylor expansions and a novel computation-cost aware adaptive controller. Through extensive evaluation on disease modelling tasks and configurable synthetic tasks, the improved Hierarchical Importance with Nested Training Samples (HINTS) sampler with adaptive proposals and a data-driven proxy achieves the best sampling error within a fixed computational budget.

## Method Summary
The paper adapts subset samplers for irregular likelihoods by replacing Taylor-expansion-based control variates with data-driven proxies. A quadratic proxy is fitted via least-squares to chain history (including rejected proposals), providing cheap likelihood approximations that integrate naturally into the HINTS hierarchy. An ϵ-greedy bandit algorithm selects proposal scales to maximize expected squared jump distance per unit computation. The method is evaluated on SEIRS disease models with particle-filter likelihoods and synthetic tasks mimicking particle filter noise characteristics, comparing against standard MCMC, Austerity, Firefly, and various subset sampler configurations.

## Key Results
- HINTS with adaptive proposals and data-driven proxy achieves the best sampling error within fixed computational budget
- HINTS+proxy uses only 18% of full likelihood evaluations per iteration vs 100% for MCMC
- On 4D synthetic task, HINTS+proxy achieves DKL=0.10 vs 0.20 for MCMC (approximately half the sampling error)
- Adaptive control outperforms best fixed proposal scales on most tasks
- Firefly-style samplers evaluate more than the theoretical 50% of scenarios due to likelihood noise

## Why This Works (Mechanism)

### Mechanism 1
Data-driven proxies can replace Taylor-expansion-based control variates when gradients are unavailable or unreliable. Least-squares fitting of quadratic functions to sample history (including rejected proposals) provides a cheap approximation of the likelihood surface. The additive property of least-squares coefficients ensures consistency between subset and full evaluations across the HINTS hierarchy. Core assumption: The target density is approximately Normal in the explored region (motivated by Bernstein-von Mises theorem), or at least well-approximated by a quadratic locally. Evidence anchors: [Section 3.1.1], [Table 3], [corpus]. Break condition: Highly non-Gaussian targets with ridged or multi-modal structure cause quadratic proxy to fail (Section 4.5, Figure 10); NN proxy required instead.

### Mechanism 2
Maximizing expected squared jump distance (ESJD) per unit computation, rather than targeting fixed acceptance rates, finds task-optimal proposal scales for subset samplers. An ϵ-greedy bandit algorithm selects from discrete proposal scale multipliers, tracking ESJD and computational cost per action. This allows samplers to operate in non-standard regimes (e.g., large steps with low acceptance but low computation per step). Core assumption: The optimal acceptance rate varies by sampler and task; a universal target (e.g., 23.4% for random walk) is inappropriate when computational cost varies with proposal scale. Evidence anchors: [Section 3.2.1], [Table 2], [corpus]. Break condition: If proposal scale and asymptotic accuracy are coupled (for inexact samplers like Austerity), maximizing ESJD/eval may select scales that increase error.

### Mechanism 3
Hierarchical delayed acceptance with proxy-only lower levels achieves exact sampling while dramatically reducing computation per iteration. HINTS builds composite proposals from subset evaluations in a tree structure. With proxy integration, lower levels use only cheap proxy evaluations; only the root node evaluates the full likelihood. This combines natural tempering from subsets with proxy pre-screening. Core assumption: The proxy is sufficiently accurate in explored regions that proposals passing proxy acceptance at lower levels will also pass full acceptance at the root at a reasonable rate. Evidence anchors: [Section 3.1.4], [Figure 3f], [Appendix E], [corpus]. Break condition: When proxy is inaccurate (non-Gaussian targets), proposals may pass lower levels but consistently fail at root, causing wasted computation.

## Foundational Learning

- **Concept: Metropolis-Hastings acceptance rule and detailed balance**
  - Why needed here: All samplers derive from MH; understanding asymmetry correction (Ψ) is essential for HINTS composite proposals
  - Quick check question: Can you explain why an asymmetric proposal requires the q(θ|θ′)/q(θ′|θ) ratio in the acceptance probability?

- **Concept: Bernstein-von Mises theorem**
  - Why needed here: Motivates quadratic proxy form; understanding when BvM fails explains why NN proxy is needed for non-Gaussian targets
  - Quick check question: Under what conditions does the posterior converge to a multivariate Normal, and why do disease models often violate these?

- **Concept: Delayed acceptance MCMC**
  - Why needed here: HINTS is a hierarchical generalization of delayed acceptance; the proof in Appendix E extends this framework
  - Quick check question: Why does delayed acceptance preserve the target distribution even when the cheap approximation is imperfect?

## Architecture Onboarding

- **Component map**: Root node (h=H) -> Recursive hierarchy builder -> Proxy module (quadratic or NN) -> Adaptive controller (ϵ-greedy bandit) -> Likelihood cache

- **Critical path**: 1. Initialize proxy (triggered when unique states > D² degrees of freedom) 2. For each root-level step: call hints_move with current θ, level H 3. Recursion builds composite proposal via subset/proxy evaluations 4. Apply MH rule at root with accumulated Ψ 5. Update proxy at geometrically increasing intervals (rate 1.1×) 6. Freeze proxy and adaptation for final sampling interval (strict mode)

- **Design tradeoffs**: Quadratic vs NN proxy: Quadratic extrapolates globally (higher potential gain) but fails on non-Gaussian targets; NN is conservative, only trusted in explored regions. Branch factor: Higher (e.g., 4) reduces computation per step but may lower root acceptance if proposals become too aggressive. Downsampling: Visiting only half of child nodes reduces cost but may reduce proposal quality.

- **Failure signatures**: Root acceptance rate < 5% with proxy: Proxy likely inaccurate for target structure; switch to NN or increase subset size. ˆR > 1.1 across parallel chains: Chains stuck in different modes; consider tempering or restart with dispersed initialization. Firefly-style samplers evaluating >80% of scenarios: Lower bound not tight due to likelihood noise (Figure 5). Austerity using full evaluations (1.0 evals/step): t-test too conservative for this task's noise level.

- **First 3 experiments**: 1. Baseline comparison on 4D synthetic task: Run MCMC, HINTS (no proxy), HINTS+quad proxy, HINTS+NN proxy with identical random seeds and budget (8192 full evals); measure DKL against reference sample. 2. High-correlation stress test: Modify 4D task with ζ=0.485 correlation between consecutive dimensions; verify NN proxy outperforms quadratic proxy (replicate Figure 10). 3. Cost-aware adaptation validation: Run HINTS+proxy with fixed multipliers r∈{0.5, 1, 2, 5} vs adaptive; confirm adaptive achieves ≥90% of best fixed multiplier's variance/eval (replicate Table 2 pattern).

## Open Questions the Paper Calls Out

### Open Question 1
Can Hierarchical Importance with Nested Training Samples (HINTS) be effectively integrated into a Sequential Monte Carlo (SMC) framework to improve sampling efficiency on large inference tasks? Basis in paper: [explicit] Section 6 explicitly states that "Including HINTS inside an SMC sampler is an active area of research that could provide both a speed-up and better samples on large inference tasks." Why unresolved: The paper focuses on MCMC methodologies. Integrating the hierarchical delayed acceptance and subset evaluation logic of HINTS into the resampling and mutation steps of SMC presents architectural challenges not addressed in the current work. What evidence would resolve it: A successful implementation of a HINTS-SMC hybrid and empirical comparison against standard SMC and HINTS-MCMC benchmarks on high-dimensional targets.

### Open Question 2
How does the proposed computation-cost aware adaptive control mechanism interact with gradient-based proposals (such as Langevin dynamics or HMC) when gradients are available? Basis in paper: [explicit] Section 6 identifies "Investigating how the HINTS adaptive control mechanism interacts with gradient-based proposals" as "another exciting avenue for future research." Why unresolved: The current work focuses on random walk proposals because the target irregular likelihoods lack reliable gradient information. It is unknown if the cost-aware objective (maximizing variance per evaluation) is optimal for tuning the step sizes of directed, gradient-based proposals. What evidence would resolve it: Experimental results applying the adaptive controller to regular likelihoods using HINTS with HMC/Langevin subset chains, comparing mixing rates against standard adaptive gradient methods.

### Open Question 3
Can the HINTS framework with data-driven proxies effectively calibrate stochastic agent-based models (ABMs), such as Covasim, where likelihoods are computationally prohibitive? Basis in paper: [explicit] Section 6 notes that "A natural extension of this work is applying these techniques to calibrating agent-based models (ABMs)... A relevant example is Covasim." Why unresolved: While the paper validates the method on disease models (SEIRS) and synthetic tasks, ABMs involve discrete, complex agent interactions that may produce likelihood surfaces with different irregularity characteristics than those tested. What evidence would resolve it: Demonstration of the method on a calibration task for a complex ABM, showing reduced simulation counts compared to standard Approximate Bayesian Computation (ABC) or MCMC while maintaining accuracy.

### Open Question 4
What specific regularization strategies (e.g., restricting to diagonal covariance) are required to maintain the stability and utility of the data-driven quadratic proxy in high-dimensional state spaces (D > 16)? Basis in paper: [inferred] Section 5.2 notes that while the quadratic proxy worked up to 16 dimensions, "In higher dimensions we expect that some regularisation would be required; for example through restricting to a diagonal covariance structure." Why unresolved: The quadratic proxy scales with O(D²) degrees of freedom. Without regularization, the least-squares fit may become unstable or overfit in very high dimensions, but the paper does not test these constraints. What evidence would resolve it: Ablation studies on synthetic tasks with D > 16 comparing full-rank quadratic proxies against regularized (e.g., diagonal or low-rank) proxies in terms of sampling error and proxy fitting stability.

## Limitations
- The quadratic proxy's global extrapolation capability breaks down for non-Gaussian posteriors with ridged or multi-modal structure
- The cost-aware adaptive controller assumes proposal scale and asymptotic accuracy are not coupled, which may not hold for inexact samplers like Austerity
- Computational cost model assumes deterministic evaluation time, though particle filters exhibit stochastic runtime

## Confidence
- **High confidence**: Hierarchical delayed acceptance preserves exact sampling under detailed balance (Appendix E proof); HINTS achieves superior performance on disease modeling tasks with particle-filter likelihoods
- **Medium confidence**: Data-driven proxies can replace Taylor expansions when gradients are unavailable (empirical success on 4D task, but untested on higher dimensions or more complex non-Gaussian structures)
- **Medium confidence**: Cost-aware adaptation outperforms fixed scales (competitive results in Table 2, though only one adaptive method compared)

## Next Checks
1. **High-dimensional scaling test**: Evaluate HINTS+proxy on 16D and 32D variants of the synthetic task to assess quadratic proxy performance as the O(D²) parameter growth becomes prohibitive, comparing against NN proxy and identifying the dimensional crossover point

2. **Non-Gaussian target stress test**: Construct a synthetic target with known ridged structure (e.g., banana-shaped posterior from g-and-k distribution) to explicitly validate when quadratic proxy fails and NN proxy succeeds, quantifying the trade-off between computational savings and accuracy loss

3. **Adaptive controller robustness**: Compare the ϵ-greedy cost-aware controller against alternative bandit algorithms (e.g., UCB, Thompson sampling) and fixed-scale strategies across multiple runs of the 4D task to assess variance in performance and sensitivity to hyperparameters (ϵ, K, exploration rate)