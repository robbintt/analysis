---
ver: rpa2
title: Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation
arxiv_id: '2505.22041'
source_url: https://arxiv.org/abs/2505.22041
tags:
- process
- behavior
- undesired
- traces
- activities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a novel approach for detecting undesired process
  behavior in event logs using Retrieval Augmented Generation (RAG) without requiring
  process models or resource-intensive fine-tuning. The method populates a knowledge
  base with desired and undesired process behavior from diverse processes, then provides
  a general-purpose LLM with relevant examples and log context through RAG to identify
  five established deviation patterns: inserted, skipped, repeated, replaced, and
  swapped activities.'
---

# Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation

## Quick Facts
- arXiv ID: 2505.22041
- Source URL: https://arxiv.org/abs/2505.22041
- Reference count: 26
- One-line primary result: RAG-based LLM approach achieves F1-scores up to 0.99 for detecting process deviations without requiring process models or fine-tuning

## Executive Summary
This paper introduces a novel approach for detecting undesired process behavior in event logs using Retrieval Augmented Generation (RAG) instead of resource-intensive fine-tuning. The method constructs a knowledge base populated with labeled desired and undesired process behavior from diverse processes, then uses RAG to provide a general-purpose LLM with relevant examples and log context to identify five established deviation patterns. Evaluation against four baselines shows the approach achieves high F1-scores (up to 0.99) across different test datasets while being more computationally efficient than fine-tuning approaches. The method demonstrates practical applicability on real-life event logs and offers a viable alternative to traditional conformance checking when process models are unavailable.

## Method Summary
The approach uses an offline component to populate a knowledge base with traces from 6,232 process models, each labeled with known deviation patterns (inserted, skipped, repeated, replaced, swapped). During inference, cosine similarity retrieval selects the most relevant examples from this knowledge base, which are combined with log context (frequent traces and activities) in a prompt for a general-purpose LLM. The LLM processes each trace to detect deviation patterns without requiring task-specific fine-tuning. The method uses Nomic Embed for trace embeddings and Gemma 2 9B for inference, with structured output parsing via BAML schema.

## Key Results
- RAG-based approach achieves F1-scores up to 0.99 for inserted activities and 0.93 for skipped activities with log context
- Outperforms fine-tuning baselines (xSemAD) with better accuracy and lower training time (1.30h vs 227-267h)
- Log context significantly improves skipped activity detection (F1 0.00 → 0.39) while retrieval relevance is crucial for all patterns
- Swap activity pattern remains challenging with F1 ~0.23, indicating limitations in LLM-based order detection

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Providing a general-purpose LLM with retrieved examples of labeled process behavior enables detection of deviation patterns without task-specific fine-tuning.
- **Mechanism:** The offline component populates a knowledge base with traces from 6,232 process models, each labeled with known deviation patterns. During inference, cosine similarity retrieval selects the most relevant examples, which the LLM uses to transfer pattern recognition knowledge to the target trace.
- **Core assumption:** LLMs can generalize deviation pattern definitions across semantically similar but process-distinct traces.
- **Evidence anchors:**
  - [abstract] "use Retrieval Augmented Generation (RAG) to provide an LLM with direct access to a knowledge base that contains both desired and undesired process behavior from other processes, assuming that the LLM can transfer this knowledge"
  - [section 3.3] "retrieve a configurable number of traces with the highest similarity to t as well as all known deviations (if any) in them. These can be used to generalize and transfer (un)desired behavior to t."
- **Break condition:** If the knowledge base lacks semantically similar processes, retrieved examples provide misleading signals, degrading detection accuracy.

### Mechanism 2
- **Claim:** Explicit log context (frequent traces and activities) enables the LLM to establish local normalcy baselines for detecting skipped activities and other omissions.
- **Mechanism:** The prompt includes (1) activities appearing in many traces and (2) the most frequent complete traces from the target event log. This gives the LLM a reference for expected behavior without requiring a formal process model.
- **Core assumption:** Frequent behavior correlates with desired behavior in the absence of ground-truth models.
- **Evidence anchors:**
  - [section 3.3] "we include activities that were executed in many traces in L... Further, we include the most frequent traces from L, giving it an idea of what order of activities was often executed"
  - [section 4.3, Table 2] "No Log Context" baseline achieves 0.00 F1 on skipped activities vs. 0.39 with log context on SAP-SAM-test
- **Break condition:** In highly noisy or adversarial logs where frequent behavior is actually undesired, this signal misleads detection.

### Mechanism 3
- **Claim:** Encoding traces as sentences using a pretrained embedding model captures both activity semantics and ordering relationships for effective similarity retrieval.
- **Mechanism:** Each trace is concatenated into a single string and embedded using Nomic Embed (designed for long-context dependencies). Cosine similarity over these embeddings retrieves structurally and semantically comparable traces.
- **Core assumption:** Sentence embedding models trained on natural language transfer to process trace similarity.
- **Evidence anchors:**
  - [section 3.2] "To ensure that the similarities factor in both the natural language semantics of the individual activities as well as their ordering relations in the trace, we represent each trace as a sentence"
  - [section 4.2] "As pre-trained embedding LLM, our approach uses Nomic Embed [23]. This model has been shown to capture long context dependencies"
- **Break condition:** If activity labels are ambiguous, abbreviated, or non-semantic (e.g., "A1", "B2"), the embedding model cannot capture meaningful similarity.

## Foundational Learning

- **Concept: Event Logs, Traces, and Activities**
  - Why needed here: The entire approach operates on traces (ordered sequences of activities) from event logs; understanding this structure is prerequisite to reading the paper.
  - Quick check question: Given trace ⟨Create PO, Approve, Ship⟩, what is the activity sequence and how would you represent it as a sentence for embedding?

- **Concept: Retrieval Augmented Generation (RAG)**
  - Why needed here: Core architecture; replaces fine-tuning with retrieval-based context provision.
  - Quick check question: In standard RAG, what are the three stages (hint: they form the acronym), and how does this paper's offline/online split map to them?

- **Concept: Conformance Checking vs. Model-Free Anomaly Detection**
  - Why needed here: The paper positions itself as solving conformance checking when process models are unavailable; understanding the baseline problem clarifies the contribution.
  - Quick check question: Why can't traditional conformance checking work without a process model, and what alternative assumption does this approach make?

## Architecture Onboarding

- **Component map:**
  - Offline Component: Process Model Collection (M) → Trace Generation (conforming + deviations) → Sentence Embedding (Nomic Embed) → Knowledge Base (703,614 trace embeddings with deviation labels)
  - Online Component: Event Log (L) → For each trace t: (1) Embed t, (2) Retrieve k similar traces from KB, (3) Extract frequent traces/activities from L, (4) Populate prompt template, (5) Call Gemma 2 9B LLM, (6) Parse output via BAML schema

- **Critical path:** Knowledge base quality → retrieval relevance → prompt construction (especially log context for skips) → LLM inference → output parsing. The paper identifies retrieval quality and log context as key differentiators from baselines.

- **Design tradeoffs:**
  - RAG vs. Fine-tuning: 1.30h KB population vs. 227-267h training, but higher inference time (9.30 min/log vs. 0.40 min for xSemAD)
  - Trace-level analysis vs. constraint-level: Higher accuracy but slower; required for precise deviation localization
  - Hyperparameters: 3 frequent traces, 5 retrieved examples, 20% activity frequency threshold performed best (Section 4.2)

- **Failure signatures:**
  - Swapped activities: F1 = 0.23 (SAP-SAM-test); LLMs struggle with order violations specific to a process
  - Skipped activities without log context: F1 drops to 0.00
  - Cross-seed variance: ±0.05 recall variation on insertions for P2P log

- **First 3 experiments:**
  1. **Baseline ablation:** Run "No Log Context" and "Log Context only" baselines on your event log to quantify the marginal contribution of RAG retrieval vs. local context.
  2. **Knowledge base sensitivity:** Populate KB with only processes from a single domain vs. diverse processes (as in SAP-SAM) and measure retrieval quality and F1 impact.
  3. **Swap detection improvement:** Test whether adding explicit "expected order" constraints (e.g., from frequent trace prefixes) improves swap F1 above 0.23.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can a combination of fine-tuning, RAG, and explicit log context improve detection accuracy compared to the current RAG-only approach?
  - Basis in paper: [explicit] Conclusion states: "we want to assess whether a combination of fine-tuning, RAG, and the inclusion of explicit context from the event log might result in more accurate detections."
  - Why unresolved: The study compared RAG against fine-tuning as mutually exclusive baselines to demonstrate efficiency, but did not evaluate their integration.
  - What evidence would resolve it: Comparative evaluation of a hybrid model against the RAG-only baseline on the SAP-SAM-test and PROP datasets.

- **Open Question 2:** How does the approach perform on realistic, imbalanced event logs where desired behavior significantly outnumbers undesired behavior?
  - Basis in paper: [explicit] Conclusion notes: "we want to investigate how imbalanced processes with significantly more desired than undesired traces influence our approach."
  - Why unresolved: Experiments used synthetically balanced datasets (approx. 55% deviating traces) to maximize exposure to deviation patterns, unlike real-world distributions.
  - What evidence would resolve it: Evaluation metrics (Precision/Recall) on datasets with high class imbalance (e.g., 95% desired traces).

- **Open Question 3:** Can the approach be extended to detect undesired behavior in perspectives other than control-flow, such as data or resources?
  - Basis in paper: [explicit] Conclusion suggests "sophisticated retrieval... might help to extend our approach towards undesired behavior from perspectives other than the control-flow."
  - Why unresolved: The current knowledge base and embedding strategy rely solely on activity sequences, ignoring other event log attributes.
  - What evidence would resolve it: A prototype retrieving multi-perspective examples to detect data-based or resource-based anomalies.

## Limitations

- The swap activity pattern shows consistently poor performance (F1 ~0.23), indicating fundamental limitations in LLM-based order detection
- The approach requires substantial offline infrastructure (703,614 trace embeddings) and significant computational resources for inference (9.30 minutes per log), limiting scalability
- Knowledge base quality and diversity are critical - if test processes differ significantly from training processes, detection accuracy may degrade substantially

## Confidence

- **High confidence:** The core mechanism of using RAG to avoid fine-tuning while achieving high F1-scores (0.99 for insertions, 0.93 for skipped activities with log context) is well-supported by the empirical results across multiple datasets.
- **Medium confidence:** The claim that explicit log context (frequent traces/activities) significantly improves skipped activity detection is demonstrated (F1 0.00 vs 0.39 baseline), but the generality of the 20% frequency threshold across different process domains needs further validation.
- **Low confidence:** The assertion that LLMs can reliably detect swapped activities (F1 0.23) is weakly supported and appears to be a fundamental limitation of the approach for this specific deviation pattern.

## Next Checks

1. **Knowledge base diversity test:** Evaluate detection performance when training knowledge base contains only domain-specific processes versus the diverse SAP-SAM corpus used in the paper, measuring retrieval quality and F1-score degradation.
2. **Swap pattern improvement:** Implement explicit ordering constraints in prompts (e.g., frequent trace prefixes showing expected activity sequences) and measure whether swap F1 exceeds 0.23.
3. **Real-world noise validation:** Apply the approach to event logs with naturally occurring deviations (not synthetically generated) to assess whether the knowledge base and RAG mechanism generalize beyond controlled test conditions.