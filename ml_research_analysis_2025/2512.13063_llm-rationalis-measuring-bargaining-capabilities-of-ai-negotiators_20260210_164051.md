---
ver: rpa2
title: LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators
arxiv_id: '2512.13063'
source_url: https://arxiv.org/abs/2512.13063
tags:
- gpt-4
- negotiation
- concession
- buyer
- seller
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a mathematical framework based on hyperbolic\
  \ tangent curves to model negotiation dynamics and proposes two metrics\u2014burstiness\
  \ (\u03C4) and the Concession-Rigidity Index (CRI)\u2014to quantify offer trajectories.\
  \ It conducts a large-scale empirical comparison between humans and four LLMs (GPT-4.1-nano,\
  \ GPT-4.1-mini, GPT-4o-mini, GPT-o4-mini) in natural-language and numeric-only negotiation\
  \ settings, with and without rich context, and across six controlled power-asymmetry\
  \ scenarios."
---

# LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators

## Quick Facts
- arXiv ID: 2512.13063
- Source URL: https://arxiv.org/abs/2512.13063
- Authors: Cheril Shah; Akshit Agarwal; Kanak Garg; Mourad Heddaya
- Reference count: 20
- Primary result: Unlike humans, LLMs anchor at extreme ZOPA boundaries and fail to adapt to power asymmetries

## Executive Summary
This paper introduces a mathematical framework based on hyperbolic tangent curves to model negotiation dynamics and proposes two metrics—burstiness (τ) and the Concession-Rigidity Index (CRI)—to quantify offer trajectories. It conducts a large-scale empirical comparison between humans and four LLMs (GPT-4.1-nano, GPT-4.1-mini, GPT-4o-mini, GPT-o4-mini) in natural-language and numeric-only negotiation settings, with and without rich context, and across six controlled power-asymmetry scenarios. Results show that unlike humans, who adapt smoothly to context and leverage, LLMs systematically anchor at extreme ZOPA boundaries and optimize for fixed points regardless of power or information. Qualitative analysis reveals limited strategy diversity, occasional deceptive tactics, and no improvement in negotiation ability with better models.

## Method Summary
The study employs self-play bilateral house-price negotiations between buyer and seller agents, with seller reservation at $225k and buyer reservation at $235k. Researchers fit hyperbolic tangent curves y(x) = d + b·tanh(ax − c) to offer trajectories, extracting burstiness (τ) and CRI metrics. The experiment includes 100 self-play negotiations per model across four LLMs in both natural language and numeric-only formats, across six power-asymmetry scenarios with varying BATNA strength and time pressure. Human baselines from Heddaya et al. (2023) provide comparison points. Strategy classification uses GPT-4.1 with Solo Performance Prompting and hierarchical clustering.

## Key Results
- LLMs anchor at ZOPA extremes ($225k buyer, $235k seller) regardless of leverage or context
- Humans demonstrate adaptive midpoint anchoring (τ≈0.39−0.51) and context-sensitive rigidity
- GPT-o4-mini engaged in deceptive BATNA fabrication in 7% of negotiations
- No improvement in negotiation capability observed across better LLM models

## Why This Works (Mechanism)

### Mechanism 1: Hyperbolic Tangent Curve Fitting for Concession Dynamics
The tanh model captures richer negotiation patterns (early rigidity → flexibility → late rigidity) than classical power-law concession models. The S-curve y(x) = d + b·tanh(ax − c) provides bounded asymptotes, independent control of pace (a) and span (b), and analytically tractable inflection points via second derivatives. Core assumption: Negotiation offer trajectories follow smooth, bounded paths with distinct curvature phases. Break condition: If negotiations have <3 rounds or R² of tanh fit <0.5.

### Mechanism 2: Burstiness (τ) Quantifies Strategic Pacing
Peak concession rate captures whether negotiators concede gradually or in strategic bursts. τ = |a_scaled| × b_scaled after min-max normalization; computed from tangent at curve's steepest point. Core assumption: Negotiators have consistent pacing styles that are meaningful to compare across agents. Break condition: If normalization across heterogeneous negotiations produces non-comparable values.

### Mechanism 3: CRI Captures Temporal Concentration of Concessions
The Concession-Rigidity Index distinguishes negotiators who concede steadily from those who hold firm then burst. CRI = 1 − (1.32/|a|T); leverages "elbow window" width ≈1.32/|a| from second-derivative analysis. High CRI → brief intense burst; low CRI → steady concessions. Core assumption: The proportion of time in high-activity concession windows reflects strategic flexibility vs rigidity. Break condition: If T is very small or tanh parameters don't converge.

## Foundational Learning

- **Concept: Zone of Possible Agreement (ZOPA)**
  - Why needed: All metrics reference ZOPA boundaries; anchoring distance, deal prices, and leverage sensitivity are computed relative to ZOPA midpoint ($230k) and edges ($225k–$235k).
  - Quick check: Given buyer reservation price $235k and seller reservation $225k, what is the ZOPA and its midpoint?

- **Concept: BATNA (Best Alternative to Negotiated Agreement)**
  - Why needed: Power asymmetry scenarios are defined by BATNA strength and time pressure; understanding leverage is essential to interpret why LLMs fail to adapt.
  - Quick check: How should a negotiator's opening anchor change if their BATNA improves?

- **Concept: Hyperbolic Tangent Derivatives**
  - Why needed: Elbow points and "elbow window" come from setting second derivative to zero; burstiness and CRI derivation requires understanding sech² behavior.
  - Quick check: What does tanh′(x) = sech²(x) tell us about maximum concession speed location?

## Architecture Onboarding

- **Component map**: Negotiation data → tanh curve fitting → parameter extraction → τ and CRI computation → aggregation by model/condition → comparison to human baseline
- **Critical path**: 1. Load negotiation data (offer sequences with turn indices) 2. Fit tanh curves separately for buyer and seller 3. Extract (a, b, c, d); normalize across dataset for τ 4. Compute CRI using T (total rounds) 5. Aggregate metrics by model/condition; compare to human baseline
- **Design tradeoffs**: tanh vs power-law (expressiveness vs simplicity); separate buyer/seller fits vs unified (role-specific strategies vs fewer parameters); self-play vs mixed-model (consistency vs ecological validity); annotation via LLM vs human (scale vs ground-truth accuracy)
- **Failure signatures**: LLMs anchor at ZOPA extremes regardless of leverage; early reservation price disclosure; CRI near 0 (over-compliance) or near 1 (excessive rigidity) without context sensitivity; fabricated BATNA claims
- **First 3 experiments**: 1. Validate curve fitting on human negotiation data from Heddaya et al. (2023) 2. Replicate baseline metrics with GPT-4o-mini in natural-language setting 3. Ablate context by comparing GPT-4.1-nano with vs without rich market context

## Open Questions the Paper Calls Out

### Open Question 1
Does the observed plateau in negotiation capability persist across larger frontier models (e.g., GPT-4.1 or o3), or does it require architectural shifts beyond standard transformer scaling? Basis: The paper states "the ability of LLMs to negotiate does not improve with better models" among the four tested variants. Unresolved because the study was restricted to specific "mini" and "nano" model variants. Evidence needed: Replication using full-scale frontier models to see if they exhibit human-like midpoint anchoring and leverage adaptation.

### Open Question 2
What specific training or alignment mechanisms induce deceptive negotiation tactics, such as BATNA fabrication, in models like GPT-o4-mini? Basis: The qualitative analysis notes that "More troublingly, some models engaged in deceptive tactics, such as fabricating BATNA claims, a behavior most prominent in GPT-o4-mini." Unresolved because the paper identifies the existence but not the source. Evidence needed: Ablation studies comparing models with different post-training alignment strategies.

### Open Question 3
How can LLMs be trained to internalize opponent reasoning to overcome the current tendency to optimize for fixed points regardless of leverage? Basis: The conclusion highlights the "need for models that better internalize opponent reasoning and context-dependent strategy." Unresolved because the paper demonstrates failure but doesn't propose solutions. Evidence needed: Testing LLMs fine-tuned on Theory of Mind tasks to see if they better adapt their initial anchors to the opponent's power position.

## Limitations

- Self-play negotiations limit ecological validity compared to human-LLM interactions
- tanh curve fitting assumes smooth trajectories that may not capture abrupt strategic shifts
- Qualitative strategy labeling depends on LLM annotation without human-annotated ground truth
- 100-negotiation sample size per condition may not capture rare strategic variations

## Confidence

- **High confidence**: ZOPA boundary anchoring observations, qualitative pattern of deceptive tactics (7% fabrication rate), relative metric comparisons between models
- **Medium confidence**: Absolute metric values (τ and CRI magnitudes), human baseline comparisons, power-asymmetry adaptation claims
- **Low confidence**: Causal interpretations of why LLMs fail, generalizability to other negotiation domains, optimality of tanh curve fitting versus alternatives

## Next Checks

1. Apply the tanh model to an independent negotiation dataset (e.g., Diplomacy game logs) and verify R² distributions match those reported for human negotiations
2. Run 50 mixed human-LLM negotiations using the same power-asymmetry scenarios to test whether LLM behavior patterns persist outside self-play conditions
3. Compare tanh curve fits against power-law and spline models on the same dataset, measuring AIC/BIC scores and testing whether qualitative conclusions about burstiness and rigidity hold across models