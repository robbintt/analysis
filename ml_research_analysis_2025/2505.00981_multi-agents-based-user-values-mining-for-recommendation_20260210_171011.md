---
ver: rpa2
title: Multi-agents based User Values Mining for Recommendation
arxiv_id: '2505.00981'
source_url: https://arxiv.org/abs/2505.00981
tags:
- user
- values
- recommendation
- systems
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ZOOM, a multi-agent framework that automatically
  mines user values from interaction histories using LLMs. It addresses LLM input
  length limits and hallucination issues by summarizing item content and employing
  evaluators and supervisors to collaboratively generate reliable values.
---

# Multi-agents based User Values Mining for Recommendation

## Quick Facts
- **arXiv ID:** 2505.00981
- **Source URL:** https://arxiv.org/abs/2505.00981
- **Reference count:** 40
- **Primary result:** ZOOM framework improves HR@K/NDCG@K by 5.22–49.55% and F1 score up to 0.7282 on human evaluations.

## Executive Summary
This paper introduces ZOOM, a multi-agent framework that mines user values from interaction histories using LLMs to enhance recommender systems. ZOOM addresses LLM input length limits and hallucination issues by summarizing item content and employing evaluators and supervisors to collaboratively generate reliable values. The framework integrates user values into recommender systems via contrastive learning, demonstrating significant performance improvements on PENS and MovieLens datasets with MoRec and EasyRec baselines.

## Method Summary
ZOOM uses a multi-agent LLM system to automatically extract user values from interaction histories based on Schwartz's Theory. The framework consists of evaluator agents that summarize items and generate value candidates using different decoding strategies, and supervisor agents that debate to refine the values through consensus or fallback mechanisms. These mined values are then integrated into recommender systems through contrastive learning, aligning user preference embeddings with value embeddings. The approach addresses LLM limitations by summarizing item content and using collaborative agent workflows to ensure reliability.

## Key Results
- 5.22–49.55% performance improvements in HR@K and NDCG@K metrics
- F1 scores up to 0.7282 on human evaluations for value extraction quality
- Demonstrated effectiveness and generalization across PENS and MovieLens datasets with MoRec and EasyRec recommender systems

## Why This Works (Mechanism)
The framework works by leveraging the collaborative strengths of multiple specialized agents to overcome individual LLM limitations. Evaluators process item summaries using diverse decoding strategies to generate varied value candidates, while supervisors engage in debate to refine and validate these values through consensus-building. This multi-agent approach reduces hallucination and ensures more reliable value extraction compared to single-agent systems. The integration via contrastive learning creates a semantic bridge between user preferences and extracted values, allowing the recommender system to better capture latent user motivations.

## Foundational Learning

1. **Schwartz's Theory of Basic Human Values** - A psychological framework describing 10 universal value types (e.g., power, achievement, benevolence). *Why needed:* Provides the theoretical foundation for categorizing user values. *Quick check:* Verify that extracted values align with Schwartz's 10 dimensions in human evaluations.

2. **Contrastive Learning in Recommender Systems** - A technique that aligns similar embeddings while pushing apart dissimilar ones. *Why needed:* Enables integration of mined values with user preference embeddings. *Quick check:* Monitor embedding space collapse when tuning the contrastive loss weight λ.

3. **Multi-agent Debate Mechanisms** - Collaborative processes where agents discuss and refine outputs through multiple rounds. *Why needed:* Ensures higher quality value extraction through consensus. *Quick check:* Measure consensus vs. fallback rates to identify debate efficiency.

4. **Negative Sampling in Implicit Feedback** - Technique of treating unobserved interactions as negative examples. *Why needed:* Critical for training implicit recommendation models. *Quick check:* Validate 1:4 negative sampling ratio maintains model performance.

## Architecture Onboarding

**Component Map:** Raw Interactions -> Summarization Agent -> Evaluator Agents -> Supervisor Debate -> Value Extraction -> Embedding Layer -> Contrastive Loss -> RS Backbone

**Critical Path:** User interaction history → Item summarization → Evaluator generation → Supervisor debate → Value text extraction → Value embedding creation → Contrastive learning with user preference embedding

**Design Tradeoffs:** The framework trades computational overhead (multiple LLM calls, debate rounds) for improved value reliability. Using multiple backbones (Llama-3-8B, Gemma-2-9B) increases robustness but requires more resources. The 3-round debate limit balances quality with efficiency, though higher rounds might yield better values at increased cost.

**Failure Signatures:** Supervisor debate deadlock (consensus not reached within 3 rounds), training instability from contrastive loss collapse, poor generalization when value embeddings don't align with user preferences, hallucination in value extraction when item summarization fails.

**First Experiments:**
1. Implement value-to-embedding mapping: Test both single-vector pooling vs. separate encoding for e_v, comparing contrastive loss stability.
2. Replicate ablation with minimal prompt sets: Run supervisor-only and evaluator-only variants using simplified instructions to verify claimed improvements stem from the debate mechanism.
3. Stress-test consensus fallback: Intentionally induce supervisor disagreement in the debate loop to measure degradation when falling back to chronological ordering.

## Open Questions the Paper Calls Out
None

## Limitations
- Key prompt templates for agents are referenced but not provided in the manuscript text
- Exact embedding mechanism for mined values (single vector vs. separate encoding) is unclear
- Human evaluation protocol details are not specified, affecting reproducibility of F1 metrics

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance improvements (HR@K/NDCG@K) | High |
| F1 score of 0.7282 on human evaluations | Medium |
| Effectiveness of multi-agent debate mechanism | Medium |
| Generalization across different datasets | Medium |

## Next Checks

1. Implement value-to-embedding mapping: Test both single-vector pooling vs. separate encoding for e_v, comparing contrastive loss stability.
2. Replicate ablation with minimal prompt sets: Run supervisor-only and evaluator-only variants using simplified instructions to verify claimed improvements stem from the debate mechanism.
3. Stress-test consensus fallback: Intentionally induce supervisor disagreement in the debate loop to measure degradation when falling back to chronological ordering.