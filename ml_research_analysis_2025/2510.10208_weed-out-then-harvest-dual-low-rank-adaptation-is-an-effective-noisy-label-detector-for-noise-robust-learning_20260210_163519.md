---
ver: rpa2
title: 'Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label
  Detector for Noise-Robust Learning'
arxiv_id: '2510.10208'
source_url: https://arxiv.org/abs/2510.10208
tags:
- noisy
- clean
- samples
- lora
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning with noisy labels
  in parameter-efficient fine-tuning (PEFT) of large language models (LLMs). The core
  idea is to decouple sample selection from model training by introducing a dual LoRA-based
  noisy label detector.
---

# Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning

## Quick Facts
- **arXiv ID:** 2510.10208
- **Source URL:** https://arxiv.org/abs/2510.10208
- **Reference count:** 40
- **Primary result:** Delora achieves state-of-the-art performance in noisy label detection and text classification accuracy using decoupled dual LoRA adaptation.

## Executive Summary
This paper introduces Delora, a novel framework for learning with noisy labels in parameter-efficient fine-tuning of large language models. The core innovation is decoupling sample selection from model training by using dual LoRA modules to separately memorize clean and noisy data. Clean and noisy LoRAs are trained with dynamic regularization that exploits differential memorization timing, followed by a learnable threshold mechanism for sample selection. The framework demonstrates superior performance on synthetic and real-world noisy datasets compared to existing baselines.

## Method Summary
Delora operates in two stages: first training a noisy label detector using dual LoRA modules, then training a robust classifier on selected clean samples and LLM-relabeled noisy ones. The detector uses clean and noisy LoRAs with dynamic regularization schedules to separately memorize clean and noisy samples. Clean samples are identified using a learnable threshold based on cross-entropy differences between the two LoRAs. The classifier is then trained on these selected clean samples and relabeled noisy samples using reversed cross-entropy loss.

## Key Results
- Delora achieves ~99% precision on Trec under 20-40% noise vs. ~60-81% for small-loss baseline
- Outperforms existing methods in both noisy label detection and text classification accuracy across multiple benchmarks
- Demonstrates successful transfer across different classifier architectures (Llama to BERT)
- Shows robustness to various noise types including symmetric, asymmetric, and instance-dependent noise

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Detection-Training Breaks Confirmation Bias
Separating sample selection from classifier training eliminates the feedback loop where noisy samples corrupt selection criteria. The detector's parameters do not receive gradients from the classifier's task loss.

### Mechanism 2: Dynamic Regularization Exploits Memorization Timing
Constraining parameter updates based on training epoch exploits differential memorization rates of clean vs. noisy samples. Clean LoRA is regularized heavily early, forcing rapid early updates then slowing. Noisy LoRA is regularized heavily late, preventing early noise absorption but allowing it later.

### Mechanism 3: Noisy LoRA as Learnable Sample-Specific Threshold
Using the noisy LoRA's cross-entropy as a dynamic, sample-dependent threshold outperforms fixed global thresholds. For sample xᵢ, compute ϕᵢ = CE(f(xᵢ, w₀ + Δw_n), yᵢ). If CE(f(xᵢ, w₀ + Δw_c), yᵢ) < ϕᵢ, classify as clean.

## Foundational Learning

- **LoRA (Low-Rank Adaptation)**
  - Why needed here: Delora uses two independent LoRA modules; you must understand that LoRA decomposes weight updates Δw = BA where B ∈ R^(m×r), A ∈ R^(r×n), and r << min(m,n). Only A and B are trained; base model weights w₀ are frozen.
  - Quick check question: Given a base weight matrix of 4096×4096 and LoRA rank r=32, how many trainable parameters does one LoRA module add?

- **Memory Effect in Deep Networks**
  - Why needed here: The core scheduling intuition. Deep networks prioritize learning simple/clean patterns before complex/noisy ones. Arpit et al. (2017) showed this empirically; Delora exploits it for scheduling regularization.
  - Quick check question: In a network trained on mixed clean/noisy data, which type of sample will the model learn to classify correctly in earlier epochs?

- **Gaussian Mixture Model (GMM) for Loss-Based Selection**
  - Why needed here: The baseline "small-loss" method you're replacing uses GMM to fit a bimodal distribution to per-sample losses, separating clean (low loss) from noisy (high loss). Understanding this clarifies what Delora improves: fixed threshold → learnable threshold.
  - Quick check question: Why might a fixed global loss threshold fail on a dataset with instance-dependent noise where some classes are inherently harder?

## Architecture Onboarding

- **Component map:**
  Stage 1: Noisy Label Detector -> Frozen LLM backbone (w₀) -> Clean LoRA (Δw_c): learns to fit clean samples -> Noisy LoRA (Δw_n): learns to fit noisy samples (serves as threshold) -> L_ce: cross-entropy with combined LoRAs (task learning) -> L_LoRA: dynamic regularization on parameter change Δσ -> L_Detector: binary classification loss on positive/negative samples
  Stage 2: Classifier Training -> Any LLM backbone (can differ from Stage 1) -> Single LoRA or full fine-tuning -> L_Dc: cross-entropy on selected clean samples -> L_Do: reversed cross-entropy on LLM-relabeled noisy samples

- **Critical path:**
  1. Warm-up (2 epochs): Train L_ce + L_LoRA on full noisy dataset to initialize representations
  2. Detector training (6 epochs): Add L_Detector, continue with dynamic regularization, periodically compute clean subset D_c via Eq. (3)
  3. Relabeling: Use clean samples as few-shot demonstrations for GPT-4o to relabel noisy samples
  4. Classifier training (6 epochs): Train final model on D_c + relabeled samples with robust loss

- **Design tradeoffs:**
  - **Two-stage vs. end-to-end**: Decoupling eliminates feedback loops but requires training two models sequentially (compute cost ~2x). Paper shows this is worth it at high noise rates (Table 6: +7.4% accuracy at 40% noise).
  - **LoRA rank r=32**: Paper uses r=32 for both LoRAs. Higher r increases capacity but also noise absorption risk. No ablation on r provided.
  - **Relabeling with GPT-4o**: Uses external LLM to relabel noisy samples. Assumption: LLM access available and reliable. Adds API dependency and cost.
  - **Hyperparameters h₁, h₂**: Must be tuned per noise ratio (Appendix I.3 shows correlation). If noise ratio is unknown, requires validation set or estimation.

- **Failure signatures:**
  - **Precision drops sharply at high noise (>50%)**: Table 12 shows precision ~97% at 60% noise, but Table 4 shows performance degrades without all components. Watch for clean LoRA collapse.
  - **Clean LoRA memorizes noisy samples**: If regularization is too weak or noise ratio misestimated, Δσ_c won't slow in time. Monitor clean LoRA's accuracy on held-out clean validation set.
  - **Noisy LoRA never activates**: If τ₂(t) is too aggressive, noisy LoRA stays near initialization. Check ||Δw_n|| magnitude during training.
  - **Stage 1-2 distribution shift**: If detector trained on different backbone than classifier, selection quality may not transfer. Paper shows transfer works (Table 5), but validate on your setup.

- **First 3 experiments:**
  1. **Sanity check on synthetic symmetric noise**: Reproduce Table 2 (Trec, 20% symmetric). Use paper's exact hyperparameters (r=32, batch_size∈[16,32], lr∈[1e-4,5e-4], h₁, h₂ per noise ratio). Verify Stage 1 achieves >95% precision on clean sample selection before proceeding.
  2. **Ablate dynamic regularization**: Train with τ₁(t)=τ₂(t)=1 (constant regularization) vs. paper's schedule. Expect ~5-10% accuracy drop per Table 4 ("w/o L_LoRA" row). This confirms the scheduling mechanism matters.
  3. **Test different backbone at Stage 2**: Train detector on Llama-3.1-8B, then train classifier on BERT-full or smaller Llama. Measure transfer gap. Paper shows this works (Table 5), but your domain may differ. If gap >3%, consider using same backbone for both stages.

## Open Questions the Paper Calls Out
- How does Delora perform when scaled to larger language models with significantly more parameters (e.g., Llama-3.2 70B)?
- Can the Delora framework be effectively adapted for text generation tasks, which involve autoregressive decoding rather than standard classification?
- Is the reliance on a strong external LLM (GPT-4o) for generating positive pseudo-labels and relabeling noisy samples replaceable by smaller, local models without performance degradation?

## Limitations
- Performance relies heavily on correctly estimating noise ratio for hyperparameter tuning (h₁, h₂ scheduling), which is not always known in real-world settings
- Approach assumes GPT-4o access for relabeling, creating dependency on external APIs
- Memory effect exploitation assumes LoRA modules exhibit the same clean-first memorization as full networks, which lacks direct empirical validation

## Confidence
- **High Confidence:** The decoupling mechanism works as described (Stage 1 trains detector, Stage 2 trains classifier independently)
- **Medium Confidence:** Dynamic regularization improves performance over constant regularization (supported by ablation, but sensitive to hyperparameter choice)
- **Medium Confidence:** Learnable threshold via noisy LoRA outperforms fixed thresholds (empirical results strong, but no OOD generalization testing)

## Next Checks
1. **Ablation on h₁/h₂ sensitivity:** Systematically vary h₁, h₂ across noise ratios (20%, 40%, 60%) and measure performance degradation. This quantifies robustness to noise ratio misestimation.
2. **Test detector transferability across architectures:** Train detector on Llama-3.1-8B, then use it to select samples for training classifiers on BERT, RoBERTa, and smaller LLMs. Measure selection quality degradation.
3. **Evaluate without GPT-4o relabeling:** Replace LLM relabeling with simple strategies (majority vote, cross-validation) and measure accuracy drop. This tests the method's utility without API dependency.