---
ver: rpa2
title: 'WSS-CL: Weight Saliency Soft-Guided Contrastive Learning for Efficient Machine
  Unlearning Image Classification'
arxiv_id: '2508.04308'
source_url: https://arxiv.org/abs/2508.04308
tags:
- unlearning
- forgetting
- learning
- saliency
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of machine unlearning in image
  classification, aiming to efficiently remove the influence of specific data from
  trained models. The authors propose a two-phase method called WSS-CL (Weight Saliency
  Soft-Guided Contrastive Learning) that leverages weight saliency to focus unlearning
  on critical model parameters.
---

# WSS-CL: Weight Saliency Soft-Guided Contrastive Learning for Efficient Machine Unlearning Image Classification

## Quick Facts
- **arXiv ID**: 2508.04308
- **Source URL**: https://arxiv.org/abs/2508.04308
- **Reference count**: 31
- **Primary result**: Two-phase method achieving 1.54 average gap vs Retrain baseline with 99.39% remaining accuracy and 93.32% test accuracy on CIFAR-10 with 10% random forgetting

## Executive Summary
This paper addresses the problem of machine unlearning in image classification, proposing a two-phase method called WSS-CL that efficiently removes the influence of specific data from trained models. The approach leverages weight saliency to focus unlearning on critical model parameters, using Kullback-Leibler divergence maximization in the first phase to achieve efficient forgetting, followed by adversarial fine-tuning with contrastive learning in the second phase. Experiments on CIFAR-10 and CIFAR-100 datasets with ResNet-18 models demonstrate significantly improved unlearning efficacy with negligible performance loss compared to state-of-the-art approaches.

## Method Summary
WSS-CL is a two-stage machine unlearning method that first maximizes KL divergence between output logits and uniform pseudo-labels to forget specific data, then employs adversarial fine-tuning with contrastive learning to maximize feature space separation between forgotten and retained samples. The method uses soft saliency masking to focus gradient updates on critical model parameters, achieving efficient unlearning while maintaining performance on retained data. The approach is evaluated on CIFAR-10 and CIFAR-100 with various forgetting scenarios including random sample removal and entire class deletion.

## Key Results
- Achieves 1.54 average gap vs Retrain baseline with 99.39% remaining accuracy and 93.32% test accuracy on CIFAR-10 (10% random forgetting)
- Demonstrates significant improvement in unlearning efficacy with negligible performance loss across different unlearning scenarios
- Shows effectiveness in both class-specific and random data deletion scenarios
- Maintains strong resistance to membership inference attacks while achieving high unlearning accuracy

## Why This Works (Mechanism)
The method works by combining two complementary mechanisms: KL divergence maximization pushes the model to produce uniform predictions for forgotten samples, effectively removing their influence, while contrastive learning creates feature space separation between forgotten and retained data. The soft saliency masking ensures that only critical parameters are updated during unlearning, making the process more efficient and focused. This dual approach addresses both the forgetting objective and the need to maintain performance on retained data.

## Foundational Learning

**Kullback-Leibler Divergence Maximization**: Used in Stage 1 to push model outputs toward uniform distribution for forgotten samples, effectively erasing their influence. Quick check: Verify that forgotten sample predictions become uniformly distributed across all classes.

**Contrastive Learning**: Applied in Stage 2 to maximize feature space separation between forgotten and retained samples. Quick check: Confirm that augmented forgetting samples form tight positive pairs while being distant from retain samples in feature space.

**Weight Saliency Masking**: Soft saliency masks focus gradient updates on critical parameters using |2(σ(g_θ) - 0.5)| transformation. Quick check: Compare unlearning efficacy with and without saliency masking to confirm improved targeting.

**Adversarial Fine-tuning**: The second stage uses adversarial training to ensure robust unlearning that resists membership inference attacks. Quick check: Evaluate MIA vulnerability before and after the fine-tuning stage.

## Architecture Onboarding

**Component Map**: Input Data -> ResNet-18 Backbone -> KL Loss (Stage 1) -> Saliency Mask -> Contrastive Loss + CE Loss (Stage 2) -> Output

**Critical Path**: The most important sequence is: (1) KL divergence maximization for forgetting, (2) soft saliency masking of gradients, (3) contrastive loss with retain samples as negatives, and (4) cross-entropy on retain set.

**Design Tradeoffs**: The method trades some computational complexity (two-stage approach with saliency masking) for improved unlearning efficacy and efficiency compared to full retraining. The contrastive learning component adds complexity but provides better feature separation.

**Failure Signatures**: Over-forgetting occurs when remaining accuracy drops significantly; under-forgetting is indicated by high MIA scores and low unlearning accuracy. Poor saliency masking results in slower convergence or ineffective forgetting.

**First Experiments**:
1. Train ResNet-18 on CIFAR-10 from scratch and verify baseline performance
2. Implement KL divergence loss and confirm it pushes forgotten sample predictions toward uniform distribution
3. Run single-stage forgetting with KL loss only and evaluate unlearning metrics to establish baseline efficacy

## Open Questions the Paper Calls Out

**Open Question 1**: Can WSS-CL be adapted to prevent generation of harmful content in conditional generative models? The paper suggests future work in this direction, but current validation is limited to discriminative tasks with ResNet-18.

**Open Question 2**: How does WSS-CL perform when the target model is trained exclusively in self-supervised regimes? The method relies on class logits, which are absent in pure self-supervised models like contrastive pre-training.

**Open Question 3**: Does WSS-CL generalize to larger-scale, high-resolution datasets and non-ResNet architectures like Vision Transformers? Current experiments are restricted to CIFAR datasets with ResNet-18.

## Limitations

- Critical hyperparameters (learning rates, epochs, batch sizes) are unspecified, making exact replication challenging
- Data augmentation strategy for generating positive pairs in contrastive learning is not detailed
- Weighting between contrastive loss and cross-entropy loss in Stage 2 is not specified
- Membership inference attack implementation details are referenced but not provided

## Confidence

**High Confidence**: The overall two-stage methodology is well-specified and represents a sound approach to machine unlearning
**Medium Confidence**: Reported experimental results are plausible given the methodology, though exact replication is uncertain due to missing hyperparameters
**Low Confidence**: Effectiveness of soft saliency masking implementation cannot be fully verified without exact gradient transformation details

## Next Checks

1. Implement the two-stage pipeline with reasonable default hyperparameters and verify that KL divergence actually pushes forgetting sample predictions toward uniform distribution
2. Test the soft saliency masking mechanism by comparing unlearning efficacy with and without the mask to confirm it improves targeted forgetting
3. Run MIA evaluation on the unlearned model using a standard black-box threshold attack to verify claimed reduction in membership inference vulnerability