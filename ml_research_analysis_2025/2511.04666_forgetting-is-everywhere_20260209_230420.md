---
ver: rpa2
title: Forgetting is Everywhere
arxiv_id: '2511.04666'
source_url: https://arxiv.org/abs/2511.04666
tags:
- forgetting
- learner
- learning
- predictive
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel, unified theory of forgetting in
  machine learning. The key insight is that forgetting can be characterised as a lack
  of self-consistency in a learner's predictive distribution, manifesting as a loss
  of predictive information.
---

# Forgetting is Everywhere

## Quick Facts
- arXiv ID: 2511.04666
- Source URL: https://arxiv.org/abs/2511.04666
- Reference count: 40
- Primary result: Forgetting is a fundamental property of learning that can be characterised as loss of self-consistency in predictive distributions

## Executive Summary
This paper introduces a novel, unified theory of forgetting in machine learning, characterizing it as a lack of self-consistency in a learner's predictive distribution and loss of predictive information. The authors propose a general measure of an algorithm's propensity to forget, grounded in this conceptualisation. They demonstrate that forgetting is present across diverse learning paradigms including regression, classification, generative modelling, and reinforcement learning. The work shows that approximate learners benefit from moderate forgetting for efficient adaptation, while exact Bayesian inference allows adaptation without forgetting. This establishes forgetting as a fundamental property of learning and lays the foundation for analysing and improving the information retention capabilities of general learning algorithms.

## Method Summary
The paper develops a unified theoretical framework for understanding forgetting in machine learning by characterizing it as a loss of self-consistency in predictive distributions. The authors introduce a general measure of forgetting based on the mutual information between past and current predictive distributions. They validate their theory across multiple learning paradigms through controlled experiments, demonstrating that approximate learning algorithms exhibit forgetting while exact Bayesian inference does not. The framework is tested in regression, classification, generative modelling, and reinforcement learning contexts to establish its broad applicability.

## Key Results
- Forgetting can be universally characterized as loss of self-consistency in predictive distributions
- Approximate learners benefit from moderate forgetting for efficient adaptation, while exact Bayesian inference avoids forgetting
- The forgetting measure captures expected dynamics such as abrupt increases at task boundaries in continual learning

## Why This Works (Mechanism)
The mechanism underlying forgetting is fundamentally tied to the information-theoretic properties of learning algorithms. When a learner updates its parameters based on new data, it modifies its predictive distribution, which can lead to a divergence from its previous predictions. This divergence represents the loss of self-consistency that characterizes forgetting. The proposed forgetting measure quantifies this divergence by measuring the mutual information between past and current predictive distributions, providing a principled way to assess how much information about past experiences is retained or lost during learning. The effectiveness of approximate learners with moderate forgetting suggests an inherent tradeoff between adaptation speed and information retention.

## Foundational Learning
- **Self-consistency in predictive distributions**: Why needed - forms the theoretical basis for characterizing forgetting; Quick check - verify that predictive distributions converge to similar outputs for repeated inputs
- **Mutual information**: Why needed - provides the mathematical framework for quantifying forgetting; Quick check - ensure mutual information calculations are well-defined and finite
- **Bayesian inference**: Why needed - serves as the gold standard for exact learning without forgetting; Quick check - confirm that Bayesian updates preserve all information from previous observations
- **Approximate learning algorithms**: Why needed - represent the practical majority of ML methods that exhibit forgetting; Quick check - validate that approximations introduce information loss
- **Continual learning**: Why needed - provides the natural context where forgetting dynamics are most apparent; Quick check - track forgetting measures across task boundaries
- **Information retention**: Why needed - the core property being measured and optimized; Quick check - monitor predictive consistency over time

## Architecture Onboarding

**Component Map**: Theoretical Framework -> Forgetting Measure -> Experimental Validation -> Cross-domain Analysis

**Critical Path**: Define forgetting as loss of self-consistency → Develop mutual information-based measure → Test across learning paradigms → Analyze tradeoffs between adaptation and retention

**Design Tradeoffs**: The forgetting measure offers principled quantification but may be computationally expensive for large models. The framework captures forgetting in both parametric and non-parametric settings but requires careful handling of predictive distribution estimation.

**Failure Signatures**: Over-regularization can mask forgetting by artificially enforcing consistency. Non-stationary environments may confound the forgetting measure by introducing concept drift. Computational limitations may prevent accurate estimation of mutual information in high-dimensional spaces.

**First Experiments**:
1. Implement the forgetting measure on a simple linear regression problem with synthetic data
2. Test the measure's sensitivity to approximation quality in a Bayesian logistic regression setting
3. Validate the framework's predictions in a multi-task continual learning scenario

## Open Questions the Paper Calls Out
None

## Limitations
- The forgetting measure may be computationally expensive to implement in real-world applications, particularly for large-scale models
- Experiments focus primarily on controlled environments, limiting generalizability to complex, real-world scenarios
- The theory's applicability to non-stationary environments with concept drift remains uncertain

## Confidence
- Forgetting as loss of self-consistency: High confidence
- Approximate learners benefit from moderate forgetting: Medium confidence
- Exact Bayesian inference avoids forgetting: Medium confidence

## Next Checks
1. Test the forgetting measure's scalability on large language models and computer vision architectures
2. Validate the theory's predictions in non-stationary environments with concept drift
3. Compare the forgetting measure's effectiveness against existing continual learning benchmarks in more diverse application domains