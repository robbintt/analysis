---
ver: rpa2
title: Accelerating Wireless Distributed Learning via Hybrid Split and Federated Learning
  Optimization
arxiv_id: '2511.19851'
source_url: https://arxiv.org/abs/2511.19851
tags:
- learning
- delay
- batch
- devices
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of accelerating hybrid split and
  federated learning (HSFL) in wireless networks by jointly optimizing learning mode
  selection, batch size, model splitting, and bandwidth allocation. The key idea is
  to balance the trade-off between one-round delay and the number of rounds to convergence,
  leveraging the strengths of both federated learning (FL) and split learning (SL).
---

# Accelerating Wireless Distributed Learning via Hybrid Split and Federated Learning Optimization

## Quick Facts
- **arXiv ID:** 2511.19851
- **Source URL:** https://arxiv.org/abs/2511.19851
- **Reference count:** 32
- **Primary result:** Joint optimization of learning mode selection, batch size, model splitting, and bandwidth allocation reduces HSFL learning delay by ~30% compared to baselines across various non-IID data distributions.

## Executive Summary
This paper addresses the problem of accelerating hybrid split and federated learning (HSFL) in wireless networks by jointly optimizing learning mode selection, batch size, model splitting, and bandwidth allocation. The key idea is to balance the trade-off between one-round delay and the number of rounds to convergence, leveraging the strengths of both federated learning (FL) and split learning (SL). The authors conduct convergence analysis to reveal the impact of these hyperparameters, then formulate a delay minimization problem. They propose a two-stage solution using block coordinate descent for relaxed problem solving, followed by a rounding algorithm to recover integer batch sizes. Experimental results demonstrate that the proposed algorithm significantly accelerates convergence to the target accuracy compared to existing methods, achieving the lowest overall learning delay across various settings of non-IID data levels and target accuracy requirements.

## Method Summary
The method optimizes HSFL learning delay through a two-stage approach. First, it formulates a delay minimization problem that jointly optimizes learning mode selection (FL vs SL), batch sizes, model splitting, and bandwidth allocation. The optimization leverages a convergence upper bound that reveals the interplay between mode selection and batch size. Second, it solves the problem using block coordinate descent, alternating between optimizing mode/bandwidth/splitting via Gibbs sampling and bisection methods, and optimizing batch sizes via dual decomposition with projected subgradient. Finally, it applies a rounding algorithm to convert continuous batch size solutions to integer values while maintaining near-optimality. The framework operates under realistic wireless constraints including device heterogeneity, limited bandwidth, and non-IID data distributions.

## Key Results
- Proposed algorithm achieves ~30% lower learning delay compared to vanilla HSFL with batch size optimization (HSFL+BSO) across various non-IID levels and target accuracies.
- Joint optimization of learning mode, batch size, and bandwidth allocation outperforms individual optimizations by up to 40% in delay reduction.
- Algorithm 1 converges within 10 iterations in all tested scenarios with small optimality gaps between continuous and integer solutions.
- Optimal parameter selection (ρ₁=3, ρ₂'=6) consistently yields best performance across different experimental settings.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Convergence-aware tradeoff between learning mode selection and batch size can reduce total learning delay by balancing per-round delay against number of rounds to convergence.
- **Mechanism:** Increasing the number of SL devices (K^S_t) reduces convergence rounds (through the term K^S_t(K^S_t-1) in convergence bound) but increases per-round delay due to SL's sequential nature. Similarly, larger batch sizes reduce rounds but increase per-round computation/communication. The optimization finds the pareto-optimal point balancing these opposing effects.
- **Core assumption:** The convergence upper bound in Theorem 1 accurately characterizes HSFL learning dynamics under assumptions of κ-Lipschitz continuity, ℓ-smoothness, and bounded gradient variance.
- **Evidence anchors:**
  - [abstract] "revealing the interplay between learning mode and batch size"
  - [section IV-A] "increasing K^S_t(K^S_t-1) reduces the second term in W_t, facilitating faster convergence... There exists a tradeoff between increasing ξ_{k,t} and increasing K^S_t"
  - [corpus] Related work on batch size optimization in FL (e.g., DYNAMITE) confirms batch size-convergence coupling, but HSFL-specific mode-batch interaction is novel.
- **Break condition:** If gradient variance bounds are violated (e.g., highly non-stationary data distributions) or Lipschitz constants are misestimated, the convergence-guided tradeoff may not hold.

### Mechanism 2
- **Claim:** Block coordinate descent with optimal subproblem solutions guarantees local convergence to near-optimal hyperparameter configurations.
- **Mechanism:** Decompose (P0) into (P1) for {x_t, l_t, b_t} and (P2) for ξ_t. Solve (P1) via Gibbs sampling for mode selection plus bisection for bandwidth/splitting. Solve (P2) via dual decomposition with projected subgradient. Alternating minimization monotonically decreases objective.
- **Core assumption:** Each subproblem is solved to optimality; the objective is bounded below.
- **Evidence anchors:**
  - [section V-A] "block coordinate descent method can yield a locally optimal solution to the original problem when each subproblem over a block of variables is solved optimally"
  - [Fig. 2] Shows Algorithm 1 converges across multiple (ρ_1, ρ'_2) settings.
  - [corpus] Block coordinate descent is standard in wireless resource allocation; this paper extends it to the mode-batch coupling case.
- **Break condition:** If subproblems are only approximately solved (e.g., early termination of Gibbs sampling), convergence guarantees degrade. Non-convex coupling between blocks could yield local minima.

### Mechanism 3
- **Claim:** Relaxing integer batch size constraints followed by principled rounding yields near-optimal integer solutions with bounded optimality gap.
- **Mechanism:** Solve continuous relaxation of (P0) to get lower bound u^{LB}_t. Floor batch sizes to get feasible integer solution (upper bound u^{UB}_t). Incrementally increase batch sizes of SL devices with smallest allocations until SL delay constraint is satisfied. The gap u^{UB}_t - u^{LB}_t bounds true optimum.
- **Core assumption:** The continuous relaxation closely approximates the integer optimum; rounding perturbations do not drastically change delay structure.
- **Evidence anchors:**
  - [section V-D] "the range is extremely small compared to the magnitude of u_t... verifying the near-optimality of Algorithm 1"
  - [Fig. 3] Shows small optimality gap across parameter settings.
  - [corpus] Limited direct evidence; batch size rounding in distributed learning is underexplored in neighboring papers.
- **Break condition:** If batch sizes are small (D_k ≈ 1), integer constraint violations become significant; rounding may yield far-from-optimal solutions.

## Foundational Learning

- **Concept: Federated Learning (FL)**
  - **Why needed here:** FL is the parallel training baseline where devices train full models locally. Understanding FL's straggler problem and non-IID sensitivity motivates hybrid approaches.
  - **Quick check question:** Can you explain why FL's synchronous aggregation makes it vulnerable to heterogeneous device capabilities?

- **Concept: Split Learning (SL)**
  - **Why needed here:** SL partitions models between device and server, reducing device compute but introducing sequential delay. Understanding this tradeoff is essential for mode selection decisions.
  - **Quick check question:** What is the communication bottleneck in SL (hint: what gets exchanged at the cut layer)?

- **Concept: Block Coordinate Descent**
  - **Why needed here:** The core optimization algorithm alternates between optimizing different variable blocks. Understanding convergence properties (local vs. global) is critical for debugging.
  - **Quick check question:** If one subproblem solver returns a suboptimal solution, does the overall algorithm still converge?

## Architecture Onboarding

- **Component map:** Server -> FL Devices (parallel training) and SL Devices (sequential training) -> Bandwidth Allocator -> Model Aggregation
- **Critical path:**
  1. Server initializes and broadcasts model/mode assignments
  2. FL devices train in parallel; SL devices train sequentially
  3. Server aggregates updates, executes Algorithm 1 for next-round optimization
  4. Repeat until convergence

- **Design tradeoffs:**
  - **More SL devices:** Better convergence (reduced heterogeneity effect), higher per-round delay
  - **Larger batch sizes:** Better gradient estimates, higher compute/communication per round
  - **Higher ρ_1 (SL weight):** Favors SL mode, fewer rounds but potentially longer rounds
  - **Higher ρ_2 (batch penalty):** Favors smaller batches, more rounds but shorter rounds

- **Failure signatures:**
  - **Non-convergence of Algorithm 1:** Check Gibbs sampling temperature δ; may need more iterations or different initialization.
  - **SL delay dominating:** Bandwidth allocation b_{0,t} may be insufficient; verify (32) is satisfied (T^F_t ≈ T^S_t).
  - **Rounding gap too large:** Local dataset sizes D_k may be too small; consider relaxing minimum batch constraint.

- **First 3 experiments:**
  1. **Reproduce Fig. 4:** Sweep (ρ_1, ρ'_2) on CIFAR-10 with φ=1 to find optimal parameter region; validate ~30% delay reduction vs. vanilla HSFL.
  2. **Ablation on mode selection:** Compare full algorithm vs. HSFL+BSO (batch-only) vs. HSFL+LMS (mode-only) to quantify contribution of each component.
  3. **Scalability test:** Vary number of devices K ∈ {10, 30, 50, 100} to observe how SL sequential delay scales and whether mode selection adapts by reducing K^S_t.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the HSFL framework be extended to jointly minimize learning delay and device energy consumption?
- **Basis in paper:** [inferred] The problem formulation (P0) focuses solely on minimizing time delay $T_t$, excluding energy costs from transmission or computation in the objective function.
- **Why unresolved:** Mobile devices have strict battery constraints, and the current algorithm might select resource-intensive modes (like FL with large batches) that drain energy too quickly.
- **What evidence would resolve it:** A modified optimization problem including energy terms and simulations showing the trade-off between energy efficiency and learning delay.

### Open Question 2
- **Question:** How robust is the resource allocation strategy to imperfect or outdated Channel State Information (CSI)?
- **Basis in paper:** [inferred] The bandwidth allocation algorithms (Algorithms 2 & 3) rely on accurate instantaneous channel gains ($h^B_{k,t}, h^U_{k,t}$) to calculate transmission rates.
- **Why unresolved:** Wireless channels fluctuate rapidly; the optimization may fail if channel conditions change significantly between the CSI measurement and the actual data transmission phase.
- **What evidence would resolve it:** Performance analysis of the proposed algorithm under varying CSI feedback delays or estimation error models.

### Open Question 3
- **Question:** Does the joint optimization maintain performance improvements under extreme pathological non-IID data distributions?
- **Basis in paper:** [inferred] Experiments were limited to CIFAR-10 with a Dirichlet distribution ($\phi=1$), representing medium data heterogeneity.
- **Why unresolved:** While the theoretical analysis includes a heterogeneity constant $\Phi$, empirical validation for severe data skew (e.g., where each device holds only a single class) is not provided.
- **What evidence would resolve it:** Experimental results comparing convergence speed and accuracy on datasets with pathological non-IID partitions.

## Limitations
- Convergence analysis relies on convex constants (κ, ℓ, G², M²) that are not empirically validated for the CNN architecture used.
- Block coordinate descent convergence guarantees require optimal subproblem solutions, but practical implementations may only achieve approximate solutions.
- Rounding algorithm's near-optimality claim lacks theoretical guarantees for small batch sizes relative to local dataset sizes.

## Confidence
- **High confidence:** The fundamental mechanism of balancing SL device count against batch size for convergence-round tradeoff (Mechanism 1) is well-supported by the convergence bound analysis and aligns with established distributed learning theory.
- **Medium confidence:** The block coordinate descent algorithm will converge to a locally optimal solution when subproblems are solved exactly (Mechanism 2), though practical implementations may only achieve approximate solutions.
- **Medium confidence:** The rounding algorithm produces near-optimal integer solutions with small optimality gaps under the tested conditions (Mechanism 3), but theoretical bounds are weak for small batch sizes.

## Next Checks
1. **Convergence constant validation:** Measure the actual Lipschitz constants (κ, ℓ) and gradient variance bounds (G², M²) on CIFAR-10 for the 6-layer CNN to verify whether the theoretical convergence bound accurately predicts the observed learning dynamics across different mode-batch configurations.
2. **Subproblem solver accuracy:** Instrument the Gibbs sampling and dual decomposition algorithms to measure convergence metrics (acceptance rate, dual variable stability) and quantify how suboptimal solutions affect the overall objective value compared to theoretical predictions.
3. **Small batch regime robustness:** Test the rounding algorithm on configurations with minimum batch size constraints (ξ_{k,t} ≥ ⌈D_k/K_t⌉) where D_k is small to determine whether the optimality gap grows significantly and whether alternative rounding strategies are needed.