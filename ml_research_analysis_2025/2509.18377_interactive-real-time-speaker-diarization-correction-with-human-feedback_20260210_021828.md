---
ver: rpa2
title: Interactive Real-Time Speaker Diarization Correction with Human Feedback
arxiv_id: '2509.18377'
source_url: https://arxiv.org/abs/2509.18377
tags:
- speaker
- correction
- feedback
- diarization
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an LLM-assisted real-time speaker diarization
  correction system that enables users to verbally fix speaker attribution errors
  during conversations. The method integrates streaming ASR and diarization, uses
  LLM summarization to display concise speaker-attributed content, and accepts brief
  verbal corrections via a wake-word interface.
---

# Interactive Real-Time Speaker Diarization Correction with Human Feedback

## Quick Facts
- arXiv ID: 2509.18377
- Source URL: https://arxiv.org/abs/2509.18377
- Reference count: 0
- Primary result: Real-time speaker diarization correction system reduces DER by 9.92% and speaker confusion by 44.23%

## Executive Summary
This paper introduces an LLM-assisted system for interactive real-time speaker diarization correction that enables users to verbally fix speaker attribution errors during conversations. The system integrates streaming ASR and diarization, uses LLM summarization to display concise speaker-attributed content, and accepts brief verbal corrections via a wake-word interface. Two key techniques are introduced: a split-when-merged (SWM) method that detects and splits mixed-speaker segments using window voting and smoothing, and online enrollments (OE) that proactively update speaker embeddings based on user corrections.

## Method Summary
The system processes streaming ASR output through a pipeline that first applies the SWM algorithm to refine segment boundaries by detecting and splitting merged multi-speaker segments. The refined segments are then passed to an LLM summarizer that creates concise per-speaker summaries for user display. When users provide verbal corrections (e.g., "That was Pat, not Alex"), the LLM parser interprets these corrections and updates the transcript. The online enrollment mechanism adds corrected segment embeddings to the target speaker's enrollment pool, enabling future identification. The system uses ECAPA-TDNN for speaker embeddings and cosine similarity for speaker matching.

## Key Results
- SWM and OE together reduce DER by 9.92% and speaker confusion error by 44.23% on AMI test set
- SWM alone provides 1.4% DER improvement by refining segment boundaries
- One or two online enrollments suffice for optimal correction efficacy
- Summary mode consistently outperforms full conversation mode, especially at longer intervals
- SWM and OE are complementary, with OE particularly effective when SWM first cleans segment boundaries

## Why This Works (Mechanism)

### Mechanism 1: Segment Boundary Refinement via Split-When-Merged (SWM)
The SWM algorithm post-processes ASR output using a sliding window to vote on speaker identity per word within a segment. It searches for the optimal split point that maximizes speaker consistency on both sides, separating mixed-speaker segments into single-speaker units. The algorithm assumes speaker embeddings are sufficiently distinct to allow majority voting within small windows to override the ASR's silence-based segmentation.

### Mechanism 2: Feedback-Driven Embedding Space Adaptation
When users correct speaker labels, the system extracts embeddings from the corrected audio segment and adds them to the target speaker's enrollment pool. Subsequent diarization uses this enriched pool (via max cosine similarity) to identify the corrected speaker, adapting to in-situ acoustic conditions. This assumes the corrected audio segment is acoustically pure enough to serve as a reliable reference prototype.

### Mechanism 3: LLM-Mediated Cognitive Load Reduction
The LLM condenses recent conversation turns into brief per-speaker summaries, allowing users to identify semantic inconsistencies without parsing dense transcripts. This enables faster and more accurate feedback loops by reducing reading burden and making error localization easier. The system assumes the summarization interval and summary accuracy are sufficient for context capture.

## Foundational Learning

- **Concept: Diarization Error Rate (DER)**
  - Why needed: DER is the primary metric for success, specifically targeting the Speaker Confusion component while holding ASR segmentation fixed
  - Quick check: If the system correctly identifies who is speaking but the ASR cuts off the sentence early, does the DER increase? (Yes, via Missed Speech)

- **Concept: Speaker Embeddings (ECAPA-TDNN)**
  - Why needed: The system relies on comparing voice fingerprints to assign labels, using cosine similarity to measure voice similarity
  - Quick check: What does it mean if two audio segments have high cosine similarity in their embeddings? (They likely belong to the same speaker)

- **Concept: Streaming ASR Constraints**
  - Why needed: Streaming ASR often segments by silence, causing merged segments that require explicit boundary handling via SWM
  - Quick check: Why does streaming ASR often merge two speakers into one segment compared to offline processing? (It often relies on immediate silence detection without look-ahead)

## Architecture Onboarding

- **Component map:** Streaming ASR (Google S2T) + Speaker Embedding (ECAPA-TDNN) → SWM → LLM Summarizer → User Interface → LLM Parser → Corrected Transcript → Online Enrollments
- **Critical path:** SWM must run before Online Enrollments to prevent enrollment contamination; mixed segments can poison the embedding pool
- **Design tradeoffs:** Summary interval (shorter=faster correction but less context vs longer=more context but higher cognitive load), dominance threshold (high prevents splitting but leaves merged segments vs low may over-split coherent speech)
- **Failure signatures:** Enrollment contamination (mixed segments added to enrollment pool), LLM hallucination (misinterpreting corrections), aggressive splitting (over-segmentation)
- **First 3 experiments:**
  1. Validate SWM in isolation on raw ASR output to measure standalone DER improvement
  2. Stress test enrollment contamination by feeding un-split segments into OE to quantify degradation
  3. Cognitive load simulation by varying interval I to find saturation point where summary becomes too long

## Open Questions the Paper Calls Out

### Open Question 1
Does the DER improvement hold with actual human users versus LLM simulation? The entire experimental validation relies on GPT-5o-mini simulating user feedback, potentially missing human factors like fatigue, mispronunciation, or varying latency tolerance.

### Open Question 2
How does SWM perform on segments with simultaneous overlapping speech versus adjacent turns? The algorithm appears to sequentialize speech by temporal splitting, which may be insufficient for regions with high overlap where two speakers speak simultaneously.

### Open Question 3
How robust is the correction pipeline to ASR errors within the verbal feedback itself? The system assumes perfect transmission of feedback text, but in real deployment, misheard speaker names in corrections could lead to garbage input for the LLM Corrector.

## Limitations
- Performance heavily depends on LLM component (GPT-5o-mini) whose exact configuration remains unspecified
- Results may not generalize to conversations longer than 50 minutes (tested AMI segments)
- System behavior with more than four speakers per meeting is untested
- Online enrollment effectiveness is contingent on successful SWM boundary refinement

## Confidence
- **High confidence:** DER improvement metrics (9.92% reduction) and speaker confusion reduction (44.23%) are well-supported by ablation studies
- **Medium confidence:** One or two online enrollments suffice claim is based on observed patterns but lacks systematic exploration
- **Low confidence:** Generalization to longer conversations beyond 50 minutes is questionable

## Next Checks
1. Systematically vary the dominance threshold θ (0.5 to 0.9) to quantify its impact on DER and verify the claimed optimal value of 0.7
2. Introduce controlled semantic ambiguities in the LLM summary input to measure false correction rates and assess robustness
3. Deliberately bypass SWM on merged segments to measure degradation attributable to poisoned speaker embeddings in the online enrollment pool