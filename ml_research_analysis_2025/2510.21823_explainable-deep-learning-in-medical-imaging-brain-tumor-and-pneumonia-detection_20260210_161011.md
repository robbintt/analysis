---
ver: rpa2
title: 'Explainable Deep Learning in Medical Imaging: Brain Tumor and Pneumonia Detection'
arxiv_id: '2510.21823'
source_url: https://arxiv.org/abs/2510.21823
tags:
- densenet121
- resnet50
- tumor
- pneumonia
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an explainable deep learning framework for
  brain tumor and pneumonia detection using MRI and chest X-ray images. ResNet50 and
  DenseNet121 CNNs were trained on public Kaggle datasets, with DenseNet121 achieving
  higher accuracy (94.3% for brain tumors vs.
---

# Explainable Deep Learning in Medical Imaging: Brain Tumor and Pneumonia Detection

## Quick Facts
- arXiv ID: 2510.21823
- Source URL: https://arxiv.org/abs/2510.21823
- Authors: Sai Teja Erukude; Viswa Chaitanya Marella; Suhasnadh Reddy Veluru
- Reference count: 15
- DenseNet121 achieved 94.3% brain tumor accuracy and 89.1% pneumonia accuracy, outperforming ResNet50.

## Executive Summary
This study developed an explainable deep learning framework for brain tumor and pneumonia detection using MRI and chest X-ray images. ResNet50 and DenseNet121 CNNs were trained on public Kaggle datasets, with DenseNet121 achieving higher accuracy (94.3% for brain tumors vs. 92.5% for ResNet50; 89.1% for pneumonia vs. 84.4% for ResNet50). Grad-CAM was integrated to generate heatmaps visualizing model attention, showing DenseNet121 consistently focused on core pathological regions while ResNet50 sometimes highlighted peripheral or non-pathological areas. The results demonstrate that combining high-performing architectures with explainable AI enhances interpretability and clinical trust in medical diagnostics.

## Method Summary
The study trained ResNet50 and DenseNet121 convolutional neural networks on brain MRI and chest X-ray datasets for binary classification. Models used ImageNet pretraining and were trained with Adam optimizer (lr=0.0001), batch size 32, and early stopping. Data augmentation included rotation, shifts, zoom, and flips. Grad-CAM generated heatmaps from the final convolutional layer to visualize attention patterns. Four model instances were trained: ResNet50 and DenseNet121 on each dataset, with evaluation using accuracy, AUC-ROC, F1-score, and average precision.

## Key Results
- DenseNet121 achieved 94.3% accuracy on brain tumor detection vs. 92.5% for ResNet50
- DenseNet121 achieved 89.1% accuracy on pneumonia detection vs. 84.4% for ResNet50
- Grad-CAM showed DenseNet121 consistently focused on core pathological regions, while ResNet50 sometimes scattered attention to peripheral or non-pathological areas

## Why This Works (Mechanism)

### Mechanism 1: Dense Connectivity Enables Superior Feature Reuse and Localization
DenseNet121's dense connectivity produces more clinically aligned attention patterns than ResNet50's skip connections. Each layer receives concatenated feature maps from all preceding layers, allowing the final classifier to access multi-level abstractions. This creates stronger gradient flow during backpropagation and encourages the network to refine features rather than relearn them, resulting in sharper focus on discriminative pathological regions.

### Mechanism 2: Grad-CAM Provides Clinically Interpretable Spatial Explanations
Grad-CAM reveals decision-critical image regions without architectural modification. Gradients of the target class score with respect to final convolutional feature maps are global-average-pooled to obtain neuron importance weights. These weights linearly combine with feature maps, producing a coarse localization heatmap that is upsampled and overlaid on the input image.

### Mechanism 3: Transfer Learning Accelerates Convergence on Limited Medical Data
ImageNet pretraining provides effective weight initialization for medical imaging despite domain shift. Low-level convolutional filters (edges, textures, basic shapes) learned from natural images transfer to medical images, reducing the data required to learn domain-specific features.

## Foundational Learning

- **Concept: Residual vs. Dense Connectivity**
  - Why needed here: The paper compares ResNet50 (residual/skip connections) against DenseNet121 (dense/concatenated connections). Understanding how each routes information explains performance and attention differences.
  - Quick check question: Can you explain why DenseNet's feature concatenation produces narrower layers but similar parameter counts compared to ResNet's additive skip connections?

- **Concept: Class Activation Mapping Family**
  - Why needed here: Grad-CAM is the core explainability tool. Understanding its gradient-weighting mechanism is essential for interpreting heatmaps and recognizing limitations.
  - Quick check question: Why does Grad-CAM use the final convolutional layer rather than earlier layers or fully-connected layers?

- **Concept: Transfer Learning in Medical Imaging**
  - Why needed here: Both architectures used ImageNet pretraining. Recognizing what transfers and what doesn't helps diagnose failure modes and decide when domain-specific pretraining is necessary.
  - Quick check question: What types of features are most likely to transfer from ImageNet to chest X-rays, and which are least likely?

## Architecture Onboarding

- **Component map:** Input images → Data augmentation (rotation, shifts, zoom, flip) → ResNet50/DenseNet121 backbone with ImageNet weights → Dense output layer (binary) → Grad-CAM visualization on final convolutional layer → Evaluation metrics

- **Critical path:** 1. Data validation (label integrity, class balance check) 2. Preprocessing and augmentation pipeline setup 3. Model instantiation with ImageNet weights 4. Training with callbacks (checkpoint, early stopping, LR scheduling) 5. Hold-out test evaluation 6. Grad-CAM generation on test samples 7. Qualitative attention pattern analysis

- **Design tradeoffs:** DenseNet121: Higher accuracy and better attention localization, but potentially slower training due to concatenated feature maps requiring more memory. ResNet50: Faster training and inference, but more scattered attention patterns. Grad-CAM: Post-hoc interpretability without retraining, but coarse spatial resolution limited by final convolutional layer dimensions.

- **Failure signatures:** Attention scatter: Heatmaps highlighting skull, heart silhouette, or ribs instead of pathology (observed in ResNet50). Overfitting to peripheral features: High accuracy but attention on non-pathological regions suggests shortcut learning. Class imbalance masking: High accuracy with low F1/AP on minority class.

- **First 3 experiments:** 1. Baseline replication: Train both ResNet50 and DenseNet121 on one dataset with identical hyperparameters; verify accuracy gap and attention pattern differences match paper claims. 2. Grad-CAM sanity check: Use a corrupted/negative control image to confirm heatmaps become diffuse/unfocused, validating that attention is signal-driven not artifact. 3. Ablation on pretraining: Train DenseNet121 from scratch vs. ImageNet weights on a reduced training subset to quantify transfer learning contribution.

## Open Questions the Paper Calls Out

### Open Question 1
Do advanced explainability methods like Score-CAM or Integrated Gradients significantly reduce the "attention scatter" observed in ResNet50?
- Basis: The conclusion explicitly identifies the need for "exploring advanced explainability methods (Grad-CAM++, Score-CAM, or new types of integrated gradients)."
- Why unresolved: The current study only utilized Grad-CAM, leaving the potential performance of sharper or more faithful explanation algorithms untested.
- What evidence would resolve it: A comparative analysis of heatmap localization precision across different XAI techniques on the same trained models.

### Open Question 2
Does the superior visual focus of DenseNet121 translate into measurably higher diagnostic confidence or accuracy for radiologists in a clinical setting?
- Basis: The authors state that future efforts should focus on "conducting clinician-centered user studies."
- Why unresolved: The paper relies on the authors' visual inspection of heatmaps to claim clinical relevance, rather than validating the tool's utility with medical professionals.
- What evidence would resolve it: Results from observer studies measuring radiologist performance with and without the XAI assistance.

### Open Question 3
Does the DenseNet121 architecture maintain its superior accuracy and localization when applied to multi-class tumor classification rather than the binary tasks used in this study?
- Basis: The methodology simplified the original 4-class brain MRI dataset into a binary classification task (tumor vs. no tumor).
- Why unresolved: Clinical diagnosis often requires differentiating between tumor types (e.g., glioma vs. meningioma), which is a more complex problem than binary detection.
- What evidence would resolve it: Performance metrics and Grad-CAM results from models trained on the original, unmodified multi-class datasets.

## Limitations

- Limited ablation studies on architectural variants (e.g., comparing Grad-CAM vs. other XAI methods) restricts understanding of which design choices most impact interpretability vs. performance.
- Dataset-specific claims (particularly for pediatric pneumonia) may not generalize to adult populations or different imaging protocols.
- The binary conversion of the brain tumor dataset loses potentially valuable subtype information that could improve diagnostic specificity.

## Confidence

- **High Confidence:** DenseNet121 achieving higher accuracy than ResNet50 (94.3% vs. 92.5% for brain tumors; 89.1% vs. 84.4% for pneumonia)
- **Medium Confidence:** DenseNet121 producing more clinically aligned attention patterns than ResNet50
- **Low Confidence:** Transfer learning from ImageNet providing substantial benefits for medical imaging

## Next Checks

1. Conduct radiologist review of Grad-CAM heatmaps to validate whether DenseNet121's "core pathological region" focus is clinically meaningful rather than merely visually distinct.
2. Perform model robustness testing with adversarial examples or domain-shifted images to assess if attention patterns remain stable or if ResNet50's scattered attention indicates better generalization.
3. Implement an ablation study training DenseNet121 from scratch on a reduced training subset to quantify the actual contribution of ImageNet pretraining to the observed performance gains.