---
ver: rpa2
title: 'TimeBill: Time-Budgeted Inference for Large Language Models'
arxiv_id: '2512.21859'
source_url: https://arxiv.org/abs/2512.21859
tags:
- time
- inference
- response
- execution
- length
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TimeBill is a time-budgeted inference framework for large language
  models (LLMs) that addresses the challenge of generating accurate responses within
  strict time budgets in time-critical systems. The method uses a fine-grained response
  length predictor (RLP) based on a small language model to predict the response length
  of the target LLM, and a workload-guided execution time estimator (ETE) that combines
  analytical modeling with profiling to accurately estimate end-to-end execution time.
---

# TimeBill: Time-Budgeted Inference for Large Language Models

## Quick Facts
- arXiv ID: 2512.21859
- Source URL: https://arxiv.org/abs/2512.21859
- Authors: Qi Fan; An Zou; Yehan Ma
- Reference count: 8
- Key outcome: TimeBill achieves highest average response performance scores while maintaining competitive task completion rates under various time budgets, with RLP achieving MAE of 42.71 and R-squared of 0.719.

## Executive Summary
TimeBill addresses the challenge of generating accurate responses within strict time budgets in LLM inference systems. The framework uses a fine-grained response length predictor (RLP) based on a small language model to predict the target LLM's response length, combined with a workload-guided execution time estimator (ETE) that accurately estimates end-to-end execution time. TimeBill then adaptively adjusts the key-value cache eviction ratio based on these predictions and the given time budget to balance inference efficiency and response performance. Experiments demonstrate superior performance compared to existing approaches across multiple response quality metrics.

## Method Summary
TimeBill employs a three-component framework: (1) an SLM-based RLP that predicts response length distribution using knowledge distillation from the target LLM, (2) an ETE that combines analytical FLOPs modeling with hardware profiling to estimate execution time bounds, and (3) an adaptive solver that computes optimal KV cache eviction ratios to meet hard deadlines while preserving response quality. The system targets hard real-time constraints where missing deadlines constitutes failure, using pessimistic factors to guarantee worst-case execution time estimates.

## Key Results
- TimeBill achieves the highest average response performance scores among tested approaches
- RLP achieves MAE of 42.71 tokens and R-squared of 0.719 for response length prediction
- ETE provides MAPE of 1.22% for prefill phase and 1.69% for decoding step estimation
- The framework maintains competitive task completion rates under time budgets of 5-10 seconds

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Fine-grained response length prediction enables proactive execution time estimation before decoding begins.
- **Mechanism**: An SLM-based classifier predicts which fixed-size bucket (B=16 tokens) the response length will fall into, rather than predicting exact token count. Knowledge distillation aligns the predictor with the target LLM's generation patterns. Post-processing caps predictions at N_max.
- **Core assumption**: Response length distributions are learnable from input prompts and remain consistent between training and deployment.
- **Evidence anchors**:
  - [abstract] "fine-grained response length predictor (RLP)... to accurately predict the end-to-end execution time"
  - [Section 4.1] Table 1 shows RLP with 512 buckets achieves MAE 42.71 tokens vs. 105.72 for ProxyModel
  - [corpus] Weak direct evidence; neighbor papers focus on KV cache management, not length prediction
- **Break condition**: Distribution shift between training data and deployment prompts invalidates bucket predictions.

### Mechanism 2
- **Claim**: Analytical FLOPs modeling combined with profiling provides accurate execution time bounds.
- **Mechanism**: Prefill phase time modeled as âÑ‚ÊÉa*x² + b*N_x + c (quadratic in input length); decoding step time as p*N_kv + q (linear in KV cache length). Coefficients fitted via least-squares on profiled measurements. Pessimistic factor k≥1 inflates predicted response length for WCET guarantees.
- **Core assumption**: Hardware execution characteristics remain stable during deployment; no major system contention.
- **Evidence anchors**:
  - [Section 4.2] MAPE of 1.22% for prefill phase, 1.69% for decoding step estimation
  - [Section 6.3] Fig. 6 shows ŴWCET provides valid upper bound on actual execution time
  - [corpus] No direct corpus validation of FLOPs-based LLM timing models
- **Break condition**: GPU frequency scaling, thermal throttling, or concurrent workloads violate fitted coefficients.

### Mechanism 3
- **Claim**: Adaptive KV cache eviction ratio minimizes performance degradation while meeting hard deadlines.
- **Mechanism**: Given time budget T, solve for optimal eviction ratio α* that minimizes α (preserving response quality) subject to t_Predict + ŴWCET(x, α, Ŵ_N^W) ≤ T. Closed-form solution in Eq. (11). Eviction applied post-prefill using SnapKV importance scoring.
- **Core assumption**: Response performance is non-increasing as eviction ratio increases (validated by SnapKV).
- **Evidence anchors**:
  - [abstract] "adaptively adjusts the KV cache eviction ratio based on execution time prediction and the given time budget"
  - [Section 5.1] Eq. (11) derives α* = min(α_max, 1 - (T - Ŵprefill - t_Predict)/(p*N_x*(Ŵ_N^W - 1)) + ...)
  - [corpus] BaKLaVa paper mentions budgeted KV cache allocation but for memory, not time constraints
- **Break condition**: Task requires all KV entries (e.g., precise retrieval); any eviction catastrophically degrades output.

## Foundational Learning

- **Concept: Autoregressive decoding and KV caching**
  - Why needed here: Understanding that LLM inference has two phases (prefill, decoding) with fundamentally different time complexities is prerequisite to grasping why eviction ratio affects decoding but not prefill.
  - Quick check question: Why does decoding step time depend on N_kv but prefill time depends on N_x²?

- **Concept: Hard real-time systems and WCET**
  - Why needed here: TimeBill targets hard deadlines where overrun = system failure. The pessimistic factor k and WCET estimation only make sense in this context.
  - Quick check question: What happens to a hard real-time system if predicted execution time underestimates actual time?

- **Concept: Knowledge distillation**
  - Why needed here: RLP uses distillation to align the small predictor model with the target LLM's response length distribution, not just general language patterns.
  - Quick check question: Why can't a generic BERT classifier replace the distilled SLM predictor?

## Architecture Onboarding

- **Component map**: Input prompt → RLP (Qwen2.5-0.5B classifier, 512 buckets) → predicts Ŵ_N → ETE (polynomial models + fitted coefficients) → computes Ŵ_WCET → α-Solver (Eq. 11 closed-form) → outputs eviction ratio → SnapKV eviction layer → applies α* to KV cache post-prefill → Target LLM (Qwen2.5-7B) → generates response

- **Critical path**: Input arrives → RLP predicts length (parallel with prefill) → ETE computes Ŵ_WCET → α* determined after prefill completes → KV cache evicted → decoding proceeds. Latency bottleneck: RLP inference must complete before prefill ends.

- **Design tradeoffs**:
  - Higher bucket count (finer granularity) improves prediction accuracy but increases RLP complexity
  - Larger pessimistic factor k increases deadline guarantees but forces higher eviction ratios, degrading quality
  - Prompt compression reduces RLP overhead but may lose information relevant to length prediction

- **Failure signatures**:
  - Low completion rate despite high α: RLP systematically under-predicts length → Ŵ_WCET too optimistic
  - High completion rate but poor response quality: k too large or α_max too high
  - High variance in completion rate: profiling coefficients don't generalize across batch sizes or system load

- **First 3 experiments**:
  1. Profile target LLM on deployment hardware: measure t_prefill across N_x ∈ [0, 32768] and t_decoding_step across N_kv ∈ [0, 32768]; fit coefficients a, b, c, p, q using least squares.
  2. Train RLP on Arena-Human-Preference-100k prompts paired with target LLM response lengths; evaluate MAE/RMSE on held-out subset; compare against 5/10-class BERT baselines.
  3. End-to-end timing validation: run TimeBill with k=5 on LongBench subset; verify Ŵ_WCET ≥ t_e2e for ≥95% of inferences; if violation rate >5%, increase k.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the pessimistic factor $k$ be dynamically adjusted at runtime rather than pre-defined to better balance the trade-off between deadline guarantees and KV cache eviction aggressiveness?
- **Basis in paper**: [inferred] Section 6.5 analyzes the impact of $k$ and notes that while $k=5$ is standard, an improper value (too small or too large) harms performance; however, the framework currently relies on a static value.
- **Why unresolved**: The paper treats $k$ as a static hyperparameter determined prior to deployment, leaving the optimization of this factor under varying workloads unaddressed.
- **What evidence would resolve it**: An algorithm that adapts $k$ based on historical prediction errors or workload variance, achieving higher average scores than static $k$ baselines.

### Open Question 2
- **Question**: How does TimeBill perform in multi-tenant or batched serving environments where memory bandwidth is shared and prefill phases interfere with decoding phases?
- **Basis in paper**: [inferred] The problem formulation (Eq. 1) and experimental evaluation focus on single-job execution (hard real-time), whereas production systems often handle concurrent requests.
- **Why unresolved**: The execution time estimator (ETE) profiles the target LLM largely in isolation; it does not model contention from concurrent prefill operations typical in serving systems.
- **What evidence would resolve it**: Evaluation metrics (completion rate/score) showing TimeBill's efficacy when multiple distinct inference jobs are scheduled simultaneously on the same hardware.

### Open Question 3
- **Question**: Can the framework effectively optimize response performance by jointly controlling multiple configuration factors $\theta$ (e.g., simultaneously tuning KV cache eviction and quantization bits) rather than just the eviction ratio?
- **Basis in paper**: [inferred] Section 3.1 acknowledges $\theta$ involves "a series of configuration factors," but Section 5.1 simplifies the objective to minimizing only the eviction ratio $\alpha$.
- **Why unresolved**: The solution space is restricted to a single dimension to simplify the derivation of $\alpha^*$, potentially missing optimal operating points that require mixed configurations.
- **What evidence would resolve it**: A multi-variable optimization scheme that outperforms the single-variable TimeBill baseline, particularly under extremely tight time budgets where eviction alone is insufficient.

## Limitations
- Effectiveness depends on stable response length distributions between training and deployment, which may not hold under distribution shift
- Assumes consistent hardware execution characteristics without significant system contention or frequency scaling
- May degrade response quality for tasks requiring complete KV cache retention (e.g., precise retrieval or multi-hop reasoning)

## Confidence
- **Response Length Prediction**: High Confidence - Clear empirical improvement with specific metrics
- **Execution Time Estimation**: Medium Confidence - Theoretical soundness but lacks external validation
- **KV Cache Eviction Strategy**: Medium Confidence - Built on SnapKV work but requires broader validation

## Next Checks
1. **Distribution Shift Robustness**: Evaluate RLP performance on prompts from domains not represented in the Arena-Human-Preference-100k training set (e.g., technical documentation, creative writing) to quantify degradation in prediction accuracy.

2. **Hardware Variability Testing**: Profile execution time estimation accuracy across different GPU models, CPU frequencies, and under concurrent workload conditions to validate the assumption of stable hardware characteristics.

3. **Task Sensitivity Analysis**: Systematically test TimeBill on tasks known to be sensitive to context loss (e.g., multi-hop reasoning, code generation with long dependencies) to determine the maximum tolerable eviction ratio before quality catastrophically degrades.