---
ver: rpa2
title: 'Beyond SEO: A Transformer-Based Approach for Reinventing Web Content Optimisation'
arxiv_id: '2507.03169'
source_url: https://arxiv.org/abs/2507.03169
tags:
- content
- generative
- search
- bart
- visibility
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a transformer-based Generative Engine Optimization
  (GEO) method for improving travel website visibility in AI-driven search engines.
  By fine-tuning BART-base on synthetically generated domain-specific data, the approach
  enhances content fluency, credibility, and discoverability.
---

# Beyond SEO: A Transformer-Based Approach for Reinventing Web Content Optimisation

## Quick Facts
- arXiv ID: 2507.03169
- Source URL: https://arxiv.org/abs/2507.03169
- Authors: Florian Lüttgenau; Imar Colic; Gervasio Ramirez
- Reference count: 7
- Primary result: BART-base fine-tuned on synthetic GEO data achieved 30.96% improvement in position-adjusted word count in generative search responses

## Executive Summary
This paper introduces a transformer-based Generative Engine Optimization (GEO) method that fine-tunes BART-base to enhance travel website visibility in AI-driven search engines. By creating synthetic (raw, optimized) text pairs and conditioning BART to apply citation, statistical, and fluency strategies, the model demonstrates substantial visibility gains. The approach outperforms baseline BART with a ROUGE-L score of 0.249 and BLEU score of 0.200, while extrinsic evaluations show 15.63% improvement in absolute word count and 30.96% gain in position-adjusted word count within generative responses. The work demonstrates that even modest-scale, domain-focused fine-tuning can effectively boost web content visibility in AI search contexts.

## Method Summary
The approach fine-tunes a pre-trained BART-base model on 1,905 synthetic pairs of raw and GEO-optimized travel website content. Raw text is scraped from Google Search top results, while optimized versions are generated by Llama-3.3-70B-Instruct to include credible citations, statistical evidence, and improved fluency. The model uses AdamW optimizer with learning rate 3e-5, trained for 7 epochs with cosine decay. Key architectural modifications include extending the encoder window to 384 tokens and applying length penalty (α=1.1) with no-repeat 3-gram constraints during decoding. Evaluation combines intrinsic metrics (ROUGE-L, BLEU, perplexity) with extrinsic visibility assessments using Llama-3.3-70B to simulate generative search responses.

## Key Results
- ROUGE-L score of 0.249 and BLEU score of 0.200, outperforming baseline BART
- 15.63% improvement in absolute word count within generative search responses
- 30.96% improvement in position-adjusted word count metrics

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning a sequence-to-sequence transformer on synthetic GEO-optimized pairs can improve source visibility in generative search responses. BART's denoising autoencoder pre-training allows supervised fine-tuning on (raw, optimized) pairs to condition the model to apply specific GEO strategies - credible citations, statistical evidence, and improved fluency - that align with how generative engines select and cite sources. The generative engine's citation behavior (Llama-3.3-70B) is assumed consistent and influenceable by surface-level content features. Evidence shows optimized content achieves 15.63% absolute word count and 30.96% position-adjusted word count gains. Break condition: If target engines change algorithms to downweight statistical claims or detect synthetic citations, visibility gains may diminish.

### Mechanism 2
A larger encoder context window improves the model's ability to preserve key information from long-form web content. Increasing the encoder's maximum input length (384 tokens vs. 256 in baseline) allows more source document processing without truncation, giving the decoder richer context for generating faithful, content-preserving rewrites. The assumption is that truncated portions contain relevant information contributing to output quality. Evidence shows the gap suggests the larger encoder window helps the decoder ground predictions in richer context. No direct corpus evidence exists for encoder window size effects in GEO tasks. Break condition: If raw content contains excessive noise in later sections, a larger window may introduce noise and degrade output relevance.

### Mechanism 3
Length and repetition constraints during decoding prevent the model from gaming evaluation metrics with short or repetitive outputs. A length penalty (α = 1.1) discourages overly short outputs, while a no-repeat n-gram size of 3 prevents repetitive copying. Together, these force substantial, varied rewrites rather than gaming ROUGE-L with keyword matching. The assumption is that short or highly repetitive outputs are undesirable even if they achieve competitive ROUGE-L/BLEU scores. Evidence shows these constraints were introduced after early runs produced short summaries that artificially inflated ROUGE-L. No corpus papers discuss this specific technique for GEO. Break condition: If the optimal GEO output is genuinely short (e.g., a concise fact), the length penalty could over-encourage verbose outputs.

## Foundational Learning

- **Concept: Sequence-to-sequence (seq2seq) modeling**
  - Why needed here: BART is a seq2seq model; understanding encoder-decoder architectures, cross-attention, and autoregressive decoding is essential for debugging and modifying the pipeline.
  - Quick check question: Can you explain how the encoder's output is used by the decoder during generation?

- **Concept: Transfer learning & fine-tuning**
  - Why needed here: The paper's core approach is fine-tuning a pre-trained BART model rather than training from scratch. Understanding what pre-training provides and how fine-tuning adapts it is critical.
  - Quick check question: What is the key difference between pre-training and fine-tuning in terms of data and objectives?

- **Concept: GEO-specific optimization strategies (citations, statistics, fluency)**
  - Why needed here: These strategies define the synthetic data generation and are the lever by which the model influences generative engine behavior.
  - Quick check question: Which GEO strategy did Aggarwal et al. (2024) find most effective, and how is it applied in this paper's data generation?

## Architecture Onboarding

- **Component map**: Google Search API → scrape & clean → Llama-3.3-70B synthetic labeling → (w, w') pairs → BART-base fine-tuning → intrinsic evaluation (ROUGE-L, BLEU) + extrinsic visibility simulation (Llama-3.3-70B)

- **Critical path**: Data generation (Sections 3.1–3.3) → Pre-processing → Fine-tuning BART (Section 5) → Intrinsic evaluation (Section 6) → Extrinsic GEO evaluation (Section 7.2)

- **Design tradeoffs**: Pre-trained BART vs. from-scratch (pre-trained chosen due to limited data and compute; from-scratch failed to converge), encoder window (384 vs. 256) (larger window improves context but increases memory/compute), synthetic labels (enables dataset creation but risks hallucinated citations/statistics)

- **Failure signatures**: Overly short outputs (missing length penalty or excessive truncation), repetitive outputs (missing no-repeat n-gram constraint), low ROUGE-L/BLEU with low loss (distribution mismatch or tokenization issues), no visibility gain in extrinsic evaluation (synthetic data strategies don't generalize to target GSE)

- **First 3 experiments**: 
  1. Reproduce baseline BART vs. fine-tuned comparison on the provided test split to validate ROUGE-L, BLEU, and loss curves
  2. Ablate the encoder window size (e.g., 256 vs. 384) to measure impact on intrinsic metrics and sample output quality
  3. Evaluate a small sample of fine-tuned outputs on a different generative engine (e.g., GPT-4o) to assess generalization of visibility gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can reinforcement learning (RL) directly optimize for visibility metrics more effectively than the current supervised cross-entropy approach?
- Basis in paper: The conclusion suggests that "reinforcement learning could directly optimize for visibility metrics, improving practical performance in generative search settings."
- Why unresolved: The current study utilized supervised fine-tuning based on token prediction (cross-entropy), which optimizes for linguistic similarity rather than the specific reward of visibility in an AI engine.
- What evidence would resolve it: A comparative experiment training a model using RL with a reward function based on position-adjusted word count or visibility scores.

### Open Question 2
- Question: Does the fine-tuning approach generalize to domains outside of travel and tourism?
- Basis in paper: The authors note that GEO effectiveness varies by sector and explicitly list "evaluating models across other domains" as a necessary direction for future research.
- Why unresolved: The model was trained exclusively on travel-specific data (1,905 instances) and may have overfit to the linguistic structures or citation styles unique to that industry.
- What evidence would resolve it: Replicating the training pipeline using datasets from distinct domains (e.g., e-commerce, finance) and measuring the resulting visibility changes.

### Open Question 3
- Question: Is the observed visibility improvement statistically significant when evaluated on a larger scale?
- Basis in paper: The authors explicitly state in Section 7.2 that the visibility simulation "sample size (n=50) is too small for statistical significance."
- Why unresolved: While the 30.96% gain is promising, the small sample size and the removal of outliers mean the true statistical reliability of these results remains unconfirmed.
- What evidence would resolve it: Running the extrinsic visibility evaluation on a significantly larger test set (e.g., thousands of queries) to calculate p-values and confidence intervals.

## Limitations

- Synthetic training data introduces uncertainty about real-world generalization, as optimized content relies on hallucinated citations and statistics
- Claims about visibility improvements depend heavily on the specific behavior of a single generative engine (Llama-3.3-70B)
- The evaluation framework assumes improved fluency and citation density directly translate to better generative engine visibility, which may not hold if engines change algorithms

## Confidence

**High Confidence**: Technical implementation details (BART-base fine-tuning, hyperparameters, tokenization limits, decoding constraints) are clearly specified and reproducible. Intrinsic evaluation methodology (ROUGE-L, BLEU, perplexity) is standard and well-documented.

**Medium Confidence**: Claims about visibility improvements (15.63% absolute word count gain, 30.96% position-adjusted gain) are supported by the evaluation framework but depend heavily on the specific behavior of Llama-3.3-70B. Effectiveness of synthetic data generation for GEO tasks is plausible but not extensively validated across different engines or content domains.

**Low Confidence**: Generalizability of GEO strategies (citations, statistics, fluency) across different generative engines and the long-term sustainability of visibility gains given potential algorithmic changes in search engines.

## Next Checks

1. **Cross-engine validation**: Test the fine-tuned model's outputs on multiple generative engines (GPT-4o, Claude, Gemini) to assess whether visibility gains generalize beyond Llama-3.3-70B.

2. **Ablation study of GEO strategies**: Create variant datasets that include only citations, only statistics, or only fluency improvements to isolate which strategy contributes most to visibility gains.

3. **Temporal stability test**: Evaluate the same content using the current model after a 3-month interval to assess whether visibility gains persist as generative engines potentially update their ranking algorithms.