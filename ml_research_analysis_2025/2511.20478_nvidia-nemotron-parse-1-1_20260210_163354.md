---
ver: rpa2
title: NVIDIA Nemotron Parse 1.1
arxiv_id: '2511.20478'
source_url: https://arxiv.org/abs/2511.20478
tags:
- nemotron-parse
- table
- text
- arxiv
- nvidia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NVIDIA introduces Nemotron-Parse 1.1, an advanced end-to-end OCR
  and document parsing model designed to overcome the limitations of traditional pipeline-based
  solutions by integrating layout understanding, text extraction, semantic classification,
  and structured formatting (Markdown/LaTeX) into a single architecture. Building
  on its predecessor, Nemotron-Parse 1.1 uses an encoder-decoder transformer architecture
  with 885M parameters, leveraging a vision encoder initialized from RADIO for robust
  visual feature extraction and a compact 256M-parameter language decoder for efficient
  text generation.
---

# NVIDIA Nemotron Parse 1.1

## Quick Facts
- arXiv ID: 2511.20478
- Source URL: https://arxiv.org/abs/2511.20478
- Reference count: 9
- Primary result: End-to-end OCR model with WER 0.011 and F1 0.958 on GOT benchmark

## Executive Summary
NVIDIA introduces Nemotron-Parse 1.1, an advanced end-to-end OCR and document parsing model designed to overcome the limitations of traditional pipeline-based solutions by integrating layout understanding, text extraction, semantic classification, and structured formatting (Markdown/LaTeX) into a single architecture. Building on its predecessor, Nemotron-Parse 1.1 uses an encoder-decoder transformer architecture with 885M parameters, leveraging a vision encoder initialized from RADIO for robust visual feature extraction and a compact 256M-parameter language decoder for efficient text generation. The model eliminates positional embeddings to improve generalization across varying document lengths and employs multi-token prediction during training to accelerate inference without sacrificing accuracy. It supports rich annotations, including bounding boxes and semantic classes, and delivers state-of-the-art OCR performance on benchmarks like GOT and OmniDocBench, achieving WER of 0.011 and F1 of 0.958 on GOT, along with strong table extraction (TEDS > 80%) and multilingual support across eight languages. Nemotron-Parse-TC, a lightweight variant with 20% faster inference, maintains comparable accuracy, making it ideal for high-throughput or edge deployments. The model is publicly released on Hugging Face and optimized for NVIDIA's NIM container, providing a scalable solution for production-level document understanding.

## Method Summary
Nemotron-Parse 1.1 employs an encoder-decoder transformer architecture with 885M parameters, initialized from RADIO's vision encoder for robust visual feature extraction and a compact 256M-parameter language decoder for efficient text generation. The model uses multi-token prediction during training to accelerate inference and removes positional embeddings to improve generalization across varying document lengths. It integrates layout understanding, text extraction, semantic classification, and structured formatting into a single end-to-end system, supporting rich annotations like bounding boxes and semantic classes. A lightweight variant (Nemotron-Parse-TC) with 20% faster inference is also provided, optimized for high-throughput or edge deployments.

## Key Results
- Achieves WER of 0.011 and F1 of 0.958 on GOT benchmark
- Strong table extraction with TEDS > 80%
- Multilingual support across eight languages
- Nemotron-Parse-TC variant offers 20% faster inference while maintaining comparable accuracy

## Why This Works (Mechanism)
Nemotron-Parse 1.1 integrates layout understanding, text extraction, semantic classification, and structured formatting into a unified architecture, eliminating the inefficiencies of traditional multi-stage OCR pipelines. By leveraging RADIO's vision encoder for robust feature extraction and a compact language decoder, the model balances accuracy and efficiency. The removal of positional embeddings enhances generalization across varying document lengths, while multi-token prediction accelerates inference without compromising accuracy. Rich annotations like bounding boxes and semantic classes enable precise document understanding, and the lightweight Nemotron-Parse-TC variant caters to resource-constrained environments.

## Foundational Learning
- **Encoder-Decoder Transformer**: Combines vision and language models for end-to-end document understanding. Needed to integrate layout, text, and semantic information. Quick check: Verify RADIO initialization in the vision encoder.
- **Multi-Token Prediction**: Accelerates inference by predicting multiple tokens simultaneously during training. Needed to balance speed and accuracy. Quick check: Confirm multi-token prediction settings in training configuration.
- **Positional Embeddings Removal**: Improves generalization across varying document lengths. Needed to handle diverse document layouts. Quick check: Validate document length variability in benchmark tests.

## Architecture Onboarding
- **Component Map**: Document Image -> Vision Encoder (RADIO-initialized) -> Transformer Decoder -> Structured Output (Markdown/LaTeX)
- **Critical Path**: Vision encoder processes document image, transformer decoder generates structured text with annotations
- **Design Tradeoffs**: Eliminated positional embeddings for better generalization vs. potential spatial alignment issues in structured documents
- **Failure Signatures**: Poor performance on low-quality scans, mixed content types, or non-Latin scripts
- **First Experiments**:
  1. Test WER on GOT benchmark with varying document lengths
  2. Evaluate Nemotron-Parse-TC on edge devices for inference speed
  3. Validate multilingual performance on low-resource languages

## Open Questions the Paper Calls Out
None

## Limitations
- Performance metrics are benchmark-specific and may not generalize to real-world heterogeneous document collections
- Exclusion of positional embeddings could impact precise spatial alignment in highly structured documents
- Lightweight variant (Nemotron-Parse-TC) trades 20% faster inference for potentially reduced accuracy on edge cases

## Confidence
- **High**: End-to-end OCR and parsing integration, architectural design (encoder-decoder with RADIO initialization), and benchmark performance on GOT and OmniDocBench
- **Medium**: Generalization across document types, edge deployment performance, and multilingual robustness beyond the eight supported languages
- **Low**: Real-world robustness to noisy or low-quality inputs, scalability to non-Latin scripts, and long-term maintenance of open-source components

## Next Checks
1. Evaluate Nemotron-Parse 1.1 on out-of-domain datasets with mixed document layouts (e.g., invoices, receipts, academic papers) to assess generalization.
2. Benchmark Nemotron-Parse-TC against the full model on edge devices (e.g., NVIDIA Jetson) to quantify accuracy-inference trade-offs under resource constraints.
3. Test multilingual performance on low-resource languages (e.g., Thai, Arabic) not explicitly listed in the eight supported languages to validate cross-script robustness.