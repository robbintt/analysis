---
ver: rpa2
title: 'REvolution: An Evolutionary Framework for RTL Generation driven by Large Language
  Models'
arxiv_id: '2510.21407'
source_url: https://arxiv.org/abs/2510.21407
tags:
- design
- code
- generation
- revolution
- population
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces REvolution, a framework that combines Large
  Language Models (LLMs) with Evolutionary Computation (EC) for automatic RTL code
  generation and optimization. The core method idea involves evolving a population
  of design candidates, each represented as a (Thought, Code, Feedback) tuple, using
  a dual-population algorithm that segregates candidates into Fail and Success groups
  for bug fixing and PPA optimization, respectively.
---

# REvolution: An Evolutionary Framework for RTL Generation driven by Large Language Models

## Quick Facts
- arXiv ID: 2510.21407
- Source URL: https://arxiv.org/abs/2510.21407
- Reference count: 34
- Primary result: Up to 24.0 percentage points increase in initial pass rates, with DeepSeek-V3 achieving 95.5% final pass rate

## Executive Summary
REvolution combines Large Language Models with Evolutionary Computation to automatically generate and optimize RTL code. The framework evolves populations of design candidates using a dual-population algorithm that segregates individuals into Fail and Success groups for targeted bug fixing and PPA optimization, respectively. An adaptive mechanism dynamically adjusts prompt strategy selection probabilities based on their success rates. Experiments on VerilogEval and RTLLM benchmarks demonstrate significant improvements in both functional correctness and PPA metrics compared to baseline approaches.

## Method Summary
REvolution uses evolutionary computation to iteratively improve RTL designs generated by LLMs. Each candidate is represented as a (Thought, Code, Feedback) tuple and evolves through six prompt strategies: Fix, Simplify, Explore, Refactor, Improve, and Fusion. The framework employs a dual-population approach, splitting candidates into Fail and Success groups based on functional correctness, with different strategies applied to each group. Adaptive strategy selection uses a UCB-Softmax mechanism to balance exploration and exploitation. The process iterates through simulation for correctness checking and synthesis for PPA evaluation until convergence or maximum generations are reached.

## Key Results
- Pass rate improvements of up to 24.0 percentage points across different LLMs
- DeepSeek-V3 achieved a final pass rate of 95.5% on benchmark problems
- Generated RTL designs showed significant PPA improvements over reference designs
- The framework outperformed non-evolutionary baselines in both correctness and optimization metrics

## Why This Works (Mechanism)

### Mechanism 1
Dual-population segregation improves search efficiency by applying targeted strategies to functionally distinct groups. Candidates are divided into Fail and Success populations based on simulation results, with bug-fixing strategies applied to Fail and PPA-optimization strategies to Success. This heterogeneous approach prevents wasting computational resources on uniform treatment when different optimization landscapes require different strategies.

### Mechanism 2
LLM prompt strategies function as genetic operators enabling broader design space exploration than iterative refinement. The six strategies generate offspring from parent tuples, with Fusion combining successful parents and Explore generating divergent designs. This parallel exploration approach leverages LLMs' generative capabilities to create meaningful design variations that single-path refinement cannot achieve.

### Mechanism 3
Adaptive prompt strategy selection via UCB-Softmax improves search efficiency by prioritizing historically successful strategies. Each strategy maintains action-values updated by rewards, with UCB scores converted to selection probabilities via softmax. This balances exploitation of known good strategies with exploration of potentially better ones, creating a self-improving optimization loop.

## Foundational Learning

- **Evolutionary Computation fundamentals (population, fitness, selection, crossover/mutation)**: Understanding population-based search is prerequisite to grasping why parallel candidates outperform single-path iteration. Quick check: Can you explain why roulette wheel selection biases toward higher-fitness individuals while maintaining diversity?

- **RTL design basics (functional correctness, synthesis, PPA tradeoffs)**: The dual-population split hinges on understanding that functional correctness is a binary gate; only correct designs have meaningful PPA scores. Quick check: Why might a functionally correct RTL design have worse PPA than a reference implementation?

- **Multi-armed bandit problems and exploration-exploitation tradeoff**: Adaptive prompt selection formulates strategy choice as a bandit problem; understanding UCB is necessary to diagnose why certain strategies dominate. Quick check: What happens if the exploration parameter c is set too low in UCB?

## Architecture Onboarding

- **Component map**: Initialization -> Evaluation (simulation + synthesis) -> Dual-Population Split (Fail/Success) -> Offspring Generation (adaptive strategy selection) -> Survivor Selection -> Termination
- **Critical path**: Evaluation (simulation + synthesis) is the bottleneck—each generation requires N+λ evaluations. Synthesis runtime scales with design complexity.
- **Design tradeoffs**: Population size N=10 balances diversity against API costs; larger populations may improve exploration but scale linearly in LLM calls. Elite preservation n=1 protects best designs but may reduce diversity.
- **Failure signatures**: Stagnant pass rate suggests prompt strategies not generating viable offspring—check LLM response quality. All individuals in Fail population indicates Fix strategy failing—inspect feedback quality. PPA not improving despite high pass rate suggests Success population lacking diversity—increase Explore/Fusion rates.
- **First 3 experiments**: 1) Replicate single-problem case study (8-bit signed adder) with same hyperparameters to validate framework setup. 2) Ablate adaptive selection by fixing uniform strategy probabilities; compare final pass rate and PPA. 3) Vary population size (N=5, 10, 20) on a subset of benchmark problems to characterize compute-quality tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
Can REvolution effectively scale to complex, industrial-grade RTL designs with gate counts significantly higher than the benchmarks used? The evaluation was limited to VerilogEval (avg. 113 gates) and RTLLM-2.0 (avg. 288 gates), which are small compared to industrial designs. The evolutionary loop requires repeated synthesis and simulation, and it is unclear if the LLM context window or the algorithm's convergence speed can handle the complexity of large modules without excessive runtime.

### Open Question 2
Can the computational overhead of the evolutionary loop be reduced to make the framework viable for rapid design iteration? Table II shows runtimes for REvolution are significantly higher (e.g., 1165s–1990s) than the non-evolutionary baseline (386s–785s) due to the iterative synthesis and simulation steps. The current trade-off favors quality over latency, but practical EDA workflows often require faster feedback loops.

### Open Question 3
How sensitive is the algorithm's performance to the selection of evolutionary hyperparameters, such as population size and generation count? The authors fixed hyperparameters ($N=10, G=20$) based on a computational budget constraint without analyzing their impact on search diversity or optimality. Evolutionary algorithms can be brittle; the chosen population size might be insufficient for more complex design spaces, leading to premature convergence.

## Limitations

- Dual-population assumption may not hold if bug fixing and PPA optimization landscapes overlap significantly
- LLM fusion effectiveness depends heavily on prompt engineering quality, which is not fully specified
- Limited external validation of the adaptive UCB-Softmax mechanism
- Results may be toolchain-specific, as reference designs failing to synthesize could bias outcomes

## Confidence

**High confidence**: The fundamental premise that combining LLMs with evolutionary computation improves RTL generation (supported by measurable pass rate and PPA improvements). **Medium confidence**: The specific mechanisms of dual-population segregation and adaptive prompt selection (lacking extensive external validation). **Low confidence**: The generalizability of results across different problem domains and hardware description languages beyond the tested Verilog benchmarks.

## Next Checks

1. **Replicate the adaptive selection ablation**: Run the framework with fixed uniform strategy probabilities and compare final pass rates and PPA improvements to the adaptive version to quantify the mechanism's contribution.

2. **Cross-design consistency analysis**: Test the framework on RTL designs from different domains (e.g., arithmetic vs. control logic) to evaluate whether strategy effectiveness varies significantly across problem types.

3. **External toolchain validation**: Replicate the benchmark synthesis using an alternative toolchain (e.g., Cadence Genus) to verify that results are not toolchain-specific and to identify any reference design synthesis failures.