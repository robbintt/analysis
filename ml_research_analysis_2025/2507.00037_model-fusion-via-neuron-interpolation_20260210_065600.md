---
ver: rpa2
title: Model Fusion via Neuron Interpolation
arxiv_id: '2507.00037'
source_url: https://arxiv.org/abs/2507.00037
tags:
- fusion
- neuron
- level
- fused
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel family of neuron-centric model fusion
  algorithms that effectively combine multiple neural networks into a single model,
  regardless of training data distribution. The key innovation is a principled formulation
  of fusion as a representation matching problem, decomposed into grouping and approximation
  components.
---

# Model Fusion via Neuron Interpolation

## Quick Facts
- arXiv ID: 2507.00037
- Source URL: https://arxiv.org/abs/2507.00037
- Reference count: 40
- Primary result: Introduces neuron-centric model fusion that outperforms previous techniques in zero-shot and non-IID scenarios by incorporating attribution-weighted clustering

## Executive Summary
This paper presents a novel approach to model fusion that combines multiple neural networks into a single model regardless of training data distribution. The key innovation is decomposing fusion into grouping and approximation phases, where neurons from base models are first clustered based on activation similarity, then the fused model's weights are optimized to match these cluster centers. The method incorporates neuron attribution scores to prioritize salient features and generalizes to arbitrary layer types including non-linear architectures.

## Method Summary
The proposed method treats model fusion as a representation matching problem, clustering neurons from base models using either Hungarian matching or K-means, then fitting the fused model's weights to match importance-weighted cluster centers. The approach employs a two-step process: first grouping neurons based on activation similarity (minimizing grouping error), then optimizing the fused model to reproduce these cluster centers (minimizing approximation error). The method uses neuron attribution scores to weight the clustering and optimization, ensuring preservation of salient features. It operates level-wise, handling both linear layers through closed-form solutions and general non-linear layers through gradient-based optimization.

## Key Results
- Outperforms previous fusion techniques in zero-shot and non-IID fusion scenarios
- Approaches ensemble-level performance while maintaining single model inference cost
- Demonstrates robustness across different training regimes including non-IID, sharded, and full-dataset splits
- Attribution-weighted clustering consistently improves performance, particularly in non-IID settings

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Decomposing model fusion into distinct "grouping" and "approximation" phases stabilizes the integration of heterogeneous models better than joint optimization or simple weight averaging.
- **Mechanism**: The algorithm first clusters neurons from base models based on activation similarity to identify functionally analogous units, then explicitly optimizes the fused model's weights to match the centroids of these clusters using weighted least squares or SGD.
- **Core assumption**: Neuron activations serve as a reliable proxy for semantic content, and minimizing the distance between fused activations and base activations preserves functional integrity.
- **Evidence anchors**: [Abstract]: "formulation of fusion as a representation matching problem, decomposed into grouping and approximation components." [Section 4.1]: "The resulting objective naturally decomposes into two interpretable components... grouping error measures how well the original neurons cluster... approximation error quantifies how closely the fused model can reproduce these cluster centers."

### Mechanism 2
- **Claim**: Incorporating neuron attribution scores (saliency) into the fusion loss significantly improves performance in non-IID settings by prioritizing the preservation of "salient" features over noisy or redundant neurons.
- **Mechanism**: The method weights the clustering and approximation loss by neuron importance scores (e.g., Conductance or DeepLIFT), ensuring the fused model prioritizes reconstructing activations of neurons that contribute most to the output.
- **Core assumption**: Attribution scores accurately quantify a neuron's marginal contribution to the model's decision, and these scores are comparable or transferable across the models being fused.
- **Evidence anchors**: [Abstract]: "incorporates neuron attribution scores to guide the fusion process toward preserving salient features." [Section 5.5]: "neuron importance scores consistently improve performance... their main effect is during clustering."

### Mechanism 3
- **Claim**: A "level"-wise construction approach, which fits weights to target activations rather than relying solely on permutation matrices, generalizes fusion to arbitrary layer types and non-linear architectures.
- **Mechanism**: By treating the network as a composition of "levels" and explicitly optimizing the current level's weights to match the output of the clustered previous level, the method corrects for representational drift and avoids error accumulation.
- **Core assumption**: The error introduced by imperfect alignment in one level can be compensated for by the optimization in the subsequent level, provided the target centroids are reachable.
- **Evidence anchors**: [Abstract]: "generalizes to arbitrary layer types." [Section 4.2]: "The algorithm constructs the fused model in a bottom-up way... fit the weights of the fused model to match the importance-weighted cluster centers."

## Foundational Learning

- **Concept: Permutation Invariance**
  - **Why needed here**: The core premise relies on the fact that neurons can be permuted without changing the function. Understanding this is necessary to grasp why we must cluster/align neurons before averaging weights.
  - **Quick check question**: Why can't we simply average the weights of two independently trained models directly (Vanilla Averaging)?

- **Concept: Attribution/Importance Scores (Conductance/DeepLIFT)**
  - **Why needed here**: The paper introduces a "novel feature" of weighting neurons. You need to know what these scores represent (gradient-based importance) to understand the Weighted K-means mechanism.
  - **Quick check question**: How does weighting a neuron by its "Conductance" score change its influence on the final cluster center compared to a uniform weight?

- **Concept: Optimal Transport & Assignment (Hungarian Algorithm)**
  - **Why needed here**: The "Hungarian Fusion" variant solves the grouping problem as a specific case of optimal transport (linear assignment).
  - **Quick check question**: Under what specific constraint does the general clustering problem reduce to the Hungarian Matching problem?

## Architecture Onboarding

- **Component map**: Base models ($M_1 \dots M_n$) + Small calibration dataset ($X$) -> Level Partitioner -> Neuron Grouping -> Weight Fitting -> Fused model
- **Critical path**: The definition of a "Level" is the architectural "hinge." If a level is defined too broadly (encapsulating too many non-linearities), the optimization becomes difficult; if too narrow, you lose the correction of representational drift.
- **Design tradeoffs**:
  - **Linear vs. Gradient Fusion**: Linear is fast and convex (optimal guarantee) but only works on linear layers. Gradient is slow and sensitive to hyperparameters but handles arbitrary non-linear levels (e.g., Transformer blocks).
  - **Hungarian vs. K-means**: Hungarian is exact but restricted to pairwise, equal-sized models. K-means is approximate but handles multi-model, unequal-sized fusion.
- **Failure signatures**:
  - **Vanilla Averaging Performance (~10% accuracy)**: Indicates the model has collapsed; alignment failed completely.
  - **Gradient Mode Divergence**: If learning rates are too high or perturbation ε is wrong, the optimization fails to match targets.
  - **High Sensitivity to Data**: In "Sharded" splits, if the fusion dataset is too small or unrepresentative, the clustering reflects noise rather than semantic structure.
- **First 3 experiments**:
  1. **Sanity Check (Linear)**: Fuse two MLPs trained on MNIST using Hungarian Linear Fusion with uniform weights. Verify that accuracy > simple averaging.
  2. **Importance Ablation**: Repeat step 1 using K-means Linear Fusion with Conductance scores. Compare cluster visualizations (Uniform vs. Weighted) to see if salient neurons are better centered.
  3. **Non-IID Stress Test**: Fuse VGG11 models trained on disjoint class shards (Sharded setup). Compare K-means Gradient against Git Re-Basin to validate the zero-shot generalization claim.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can more expressive clustering methods improve fusion performance beyond standard K-means?
- **Basis in paper**: [explicit] "Future research could evaluate more expressive or adaptive clustering methods to better capture inter-neuron similarity..."
- **Why unresolved**: The paper relies on K-means or Hungarian matching, which are heuristics for the NP-hard grouping problem.
- **What evidence would resolve it**: Comparative experiments using hierarchical or spectral clustering showing reduced grouping error.

### Open Question 2
- **Question**: How do the grouping error and approximation error components individually contribute to the final fusion quality?
- **Basis in paper**: [explicit] The authors call for "A deeper investigation into the relative impact of grouping error versus approximation error on fusion quality..."
- **Why unresolved**: Theorem 1 mathematically decomposes the objective, but the empirical sensitivity of the model to each component remains unquantified.
- **What evidence would resolve it**: Ablation studies that selectively degrade one error component while controlling the other to observe changes in accuracy.

### Open Question 3
- **Question**: Can the fusion objective be optimized effectively via subgradient descent rather than the proposed two-step heuristic?
- **Basis in paper**: [explicit] Regarding the sum of the objective, the paper states: "we leave this for future work."
- **Why unresolved**: The authors currently use a decoupled approach (clustering then fitting) rather than jointly optimizing the subdifferentiable objective.
- **What evidence would resolve it**: Implementation of a subgradient descent optimizer and comparison of its convergence speed and final accuracy against the two-step method.

## Limitations

- **Scalability constraints**: The method requires running forward passes of all base models on a calibration dataset for each fusion, creating quadratic complexity with model count.
- **Attribution reliability**: The performance gains from neuron attribution scores depend critically on the quality of the attribution method, which may not transfer reliably between models with divergent feature representations.
- **Hyperparameter sensitivity**: The perturbation parameter ε for gradient-based fusion and K-means initialization significantly impact results but lack principled selection criteria.

## Confidence

- **High confidence**: The core decomposition into grouping and approximation phases is well-supported by theoretical formulation and empirical results across multiple datasets.
- **Medium confidence**: The attribution-weighted clustering improvement shows consistent gains but depends on attribution method quality and may not generalize to all non-IID scenarios.
- **Medium confidence**: The generalization to arbitrary layer types is demonstrated but the performance gap between linear and gradient fusion suggests limitations in handling complex architectures.

## Next Checks

1. **Attribution robustness test**: Compare fusion performance using multiple attribution methods (Integrated Gradients, SHAP, LIME) across varying degrees of data distribution shift to quantify attribution reliability.

2. **Scalability benchmark**: Systematically measure fusion time and memory scaling with model count and width, and test approximation techniques like clustering on subset activations to identify practical limits.

3. **Architecture stress test**: Evaluate fusion performance on ResNet variants with varying skip connection patterns and Transformer architectures with different attention mechanisms to map the boundary of the method's architectural generality.