---
ver: rpa2
title: 'LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge
  Graph Construction -- A Case Study on SDGs'
arxiv_id: '2602.02090'
source_url: https://arxiv.org/abs/2602.02090
tags:
- uni00000048
- knowledge
- uni00000003
- uni00000057
- relation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'LEC-KG is a collaborative framework for domain-specific knowledge
  graph construction that integrates LLM-based semantic extraction with KGE-based
  structural validation. The framework addresses challenges of heterogeneous entity
  mentions, long-tail relation distributions, and absent schemas through bidirectional
  refinement: KGE provides structure-aware feedback to guide LLM extraction via evidence-grounded
  reasoning, while validated triples progressively improve KGE representations.'
---

# LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs

## Quick Facts
- **arXiv ID**: 2602.02090
- **Source URL**: https://arxiv.org/abs/2602.02090
- **Reference count**: 40
- **Primary result**: 36.8% Micro-F1 on Chinese SDG report extraction, improving 11.2 points over LLM baseline

## Executive Summary
LEC-KG addresses domain-specific knowledge graph construction challenges by integrating LLM-based semantic extraction with KGE-based structural validation. The framework tackles heterogeneous entity mentions, long-tail relation distributions, and absent schemas through bidirectional refinement: KGE provides structure-aware feedback to guide LLM extraction via evidence-grounded reasoning, while validated triples progressively improve KGE representations. A semantic initialization strategy enables structural validation for unseen entities by projecting entity mentions into KGE space via learned alignment. Evaluated on Chinese SDG reports, LEC-KG achieves 36.8% Micro-F1, improving 11.2 points over LLM few-shot extraction and doubling performance on tail relations (13.3% vs 6.7%).

## Method Summary
LEC-KG employs a collaborative framework combining LLM semantic extraction with KGE structural validation. The system uses DeepSeek-V3 for extraction and RotatE for structural validation, with a semantic encoder (Chinese-RoBERTa-wwm-ext) projecting entities into KGE space. The pipeline operates through iterative refinement: LLM extracts triples using hierarchical schema-constrained prompts, KGE validates and scores them, and evidence-guided CoT feedback corrects medium-confidence extractions. A tri-partition routing system directs high-confidence triples to KGE warm-start updates and low-confidence ones back to LLM refinement. The framework handles cold-start scenarios through semantic initialization, enabling structural validation for entities unseen during KGE training.

## Key Results
- 36.79% Micro-F1 on Chinese SDG report extraction
- 11.2 percentage point improvement over LLM few-shot baseline
- 13.3% tail relation F1 vs 6.7% baseline

## Why This Works (Mechanism)
The framework's effectiveness stems from bidirectional collaboration between semantic understanding and structural validation. LLM extraction provides rich contextual understanding while KGE validation enforces global consistency and structural patterns. The semantic initialization bridges the gap for unseen entities, enabling structural validation beyond the training set. Evidence-guided CoT feedback creates a correction loop that improves precision on ambiguous extractions. The tri-partition routing ensures efficient resource allocation by directing different confidence levels to appropriate processing channels.

## Foundational Learning

**Knowledge Graph Construction**: Domain-specific KG extraction requires handling heterogeneous entity mentions and long-tail relations. Why needed: Real-world documents rarely follow standardized schemas. Quick check: Verify entity mention normalization and relation frequency distribution in target corpus.

**KGE Structural Validation**: RotatE embeddings capture relational patterns that validate semantic extractions. Why needed: LLMs alone lack global consistency checking. Quick check: Compute embedding-based triple plausibility scores against ground truth.

**Semantic Initialization**: Projection from semantic encoder to KGE space enables cold-start validation. Why needed: New entities cannot be structurally validated without prior embeddings. Quick check: Measure projection error on known entities before applying to unseen ones.

**Evidence-Guided Refinement**: Retrieval-augmented feedback improves LLM extraction accuracy. Why needed: Contextual evidence resolves entity ambiguities. Quick check: Compare extraction quality with and without evidence grounding.

**Hierarchical Schema Design**: Multi-level relation categorization improves extraction precision. Why needed: Coarse-to-fine classification reduces output space complexity. Quick check: Evaluate schema adherence rate across extraction iterations.

## Architecture Onboarding

**Component Map**: LLM Extraction -> KGE Scoring -> Tri-Partition Routing -> Channel 1 (Evidence-Guided CoT) / Channel 2 (Warm-Start Update) -> Refined KG

**Critical Path**: LLM extraction → KGE validation → evidence retrieval → CoT feedback → LLM correction

**Design Tradeoffs**: Separate semantic initialization vs joint optimization balances training complexity with alignment quality. Exact-match evidence retrieval vs dense retrieval trades precision for coverage.

**Failure Signatures**: High OOS relation generation indicates schema mismatch; low KGE scores on validated triples suggest embedding quality issues; persistent low-confidence routing indicates LLM extraction weakness.

**First Experiments**: 1) Test semantic projection accuracy on held-out entities. 2) Validate tri-partition thresholds on validation set. 3) Measure evidence retrieval coverage vs precision tradeoff.

## Open Questions the Paper Calls Out

**Generalizability**: Can LEC-KG's bidirectional collaboration paradigm generalize to other domains (e.g., climate policy, public health) and languages beyond Chinese SDG reports? The evaluation was restricted to a single domain with a manually designed schema, and effectiveness may vary across languages due to differences in pre-trained language model coverage.

**Joint Optimization**: Would joint optimization of the semantic initialization projection layer and KGE embeddings simultaneously improve cross-space alignment compared to the current separate training approach? Currently, the projection layer is trained separately, which may yield suboptimal alignment when entity surface forms differ substantially from training data.

**Automated Schema Induction**: Can automated schema induction through clustering or LLM-guided ontology generation replace manual schema design while maintaining extraction quality? The current schema required hybrid top-down guidance with bottom-up corpus-driven refinement, including LLM-assisted semantic clustering followed by manual verification.

**Dense Retrieval Evidence**: Would dense retrieval methods improve evidence coverage for paraphrased entity mentions without degrading grounding quality compared to entity-anchored exact matching? Exact-match retrieval guarantees precision but may miss evidence where entities appear with synonyms or morphological variations.

## Limitations

- Evaluation restricted to single domain (SDGs) and language (Chinese) limits generalizability claims
- Cold-start mechanism relies on ad-hoc semantic projection without detailed training specifications
- Framework depends on hard-coded thresholds (25th/70th percentiles) and retry limits whose optimality is not established

## Confidence

- **High Confidence**: Bidirectional refinement architecture combining LLM semantic extraction with KGE structural validation is technically sound
- **Medium Confidence**: 36.8% Micro-F1 result and 11.2-point improvement over baseline are plausible given domain complexity
- **Low Confidence**: Tail relation performance claims (13.3% vs 6.7%) and semantic initialization impact cannot be independently assessed

## Next Checks

1. **Schema Coverage Analysis**: Evaluate percentage of LLM-generated relations outside the predefined 89-relation schema and measure OOS remapping effectiveness
2. **Cold-Start Sensitivity**: Systematically vary semantic projection training parameters and measure impact on early-iteration KGE quality
3. **Cross-Domain Generalization**: Apply LEC-KG to different domains (e.g., biomedical literature) to assess whether 11.2 F1 point improvement is domain-specific or general