---
ver: rpa2
title: 'Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph
  Learning Models'
arxiv_id: '2505.15845'
source_url: https://arxiv.org/abs/2505.15845
tags:
- graph
- token
- lgtl
- attention
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies the hop-overpriority problem in existing
  tokenized graph learning models (TGLMs), where predefined token lists overemphasize
  nearby nodes and harm performance on heterophilic graphs. The authors propose Learnable
  Graph Token List (LGTL), a plug-and-play module that adaptively adjusts hop weights
  and prioritizes informative nodes within hops using a gate module and selection
  module.
---

# Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models

## Quick Facts
- **arXiv ID:** 2505.15845
- **Source URL:** https://arxiv.org/abs/2505.15845
- **Reference count:** 40
- **Primary result:** Proposed LGTL achieves up to 10.39% average accuracy gain on text-attributed graphs and 11.14% on heterophilic benchmarks

## Executive Summary
This paper identifies a critical limitation in existing tokenized graph learning models (TGLMs): the "hop-overpriority problem," where predefined token lists overemphasize nearby nodes and harm performance on heterophilic graphs. The authors propose Learnable Graph Token List (LGTL), a plug-and-play module that adaptively adjusts hop weights and prioritizes informative nodes within hops using a gate module and selection module. Theoretical analysis shows LGTL addresses the hop-overpriority problem, and experiments across diverse TGLM backbones demonstrate consistent improvements, validating its effectiveness and broad applicability.

## Method Summary
LGTL introduces a learnable replacement for static token lists in TGLMs through two core modules: a Gate Module that uses GAT to compute context-aware hop weights, and a Selection Module that applies GAT attention to weigh individual nodes within each hop. The token list is constructed by aggregating these weighted node features, which are then processed by the TGLM backbone. The backbone's attention scores are adjusted using the pre-computed gate weights, allowing the model to suppress noisy near-hop signals in heterophilic graphs while maintaining local information on homophilic graphs.

## Key Results
- LGTL achieves up to 10.39% average accuracy gain on text-attributed graph benchmarks
- LGTL achieves up to 11.14% accuracy improvement on heterophilic graph benchmarks
- Consistent improvements across multiple TGLM backbones including NAGphormer, VCR-Graphormer, and LLaGA

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Hop Re-weighting
The Gate Module uses a GAT layer to process the central node's subgraph and produce context-aware hop scores $\hat{s}_u$, which rescale the Transformer's native attention weights $\alpha$. This forces the model to attend to structurally distant but label-consistent hops rather than defaulting to nearest neighbors. The core assumption is that subgraph structural features contain sufficient signal to predict relative hop utility for the downstream task.

### Mechanism 2: Intra-Hop Node Discrimination
The Selection Module applies GAT attention ($\beta$) to individual nodes within each hop before aggregation, allowing the model to filter out label-inconsistent neighbors even when they are topologically close. This constructs more informative tokens by distinguishing between useful and noisy nodes within the same hop depth.

### Mechanism 3: Theoretical Smoothness Alignment
Theorem 5.2 shows that LGTL minimizes representation distortion by aligning high attention weights with hops exhibiting higher label consistency. By assigning higher gate weights $\hat{s}$ to hops with higher label consistency $C^i_u$, the upper bound of the error norm is minimized, mathematically addressing the overpriority issue.

## Foundational Learning

- **Concept: Tokenized Graph Learning Models (TGLMs)**
  - Why needed: TGLMs are the substrate being modified; understanding how they convert graph neighborhoods into token sequences is essential
  - Quick check: Can you explain how the "Hop-field Overview" (HO) template aggregates neighbors differently from the "Neighborhood Detail" (ND) template?

- **Concept: Homophily vs. Heterophily**
  - Why needed: The hop-overpriority problem is defined by its failure on heterophilic graphs where connected nodes often have different labels
  - Quick check: On a heterophilic graph, why would standard 1-hop aggregation (mean pooling) be detrimental to classification accuracy?

- **Concept: Graph Attention Networks (GAT)**
  - Why needed: LGTL relies on GAT layers in both gate and selection modules to compute importance weights
  - Quick check: How does GAT compute the attention coefficient between a central node and a neighbor, and how does this differ from a standard GCN aggregation?

## Architecture Onboarding

- **Component map:** Central Node $u$ and subgraph $G_u$ -> Gate Module (GAT + Linear + Softmax) -> Hop Weights $\hat{s}$ -> Selection Module (Subgraph Sampler + GAT) -> Node Attention $\beta$ -> Token Aggregation $T$ -> TGLM Backbone (Transformer/LLM) -> Attention Adjustment (Eq. 7)

- **Critical path:**
  1. Extract $L$-hop subgraph for node $u$
  2. Pass subgraph through Gate Module to get scalar weights $\hat{s}_u$ for each hop
  3. For each hop $i$, sample neighbors and use Selection Module to compute node weights $\beta$ and construct token $T_i$
  4. Feed token list $[T_0, \dots, T_L]$ into frozen/pretrained TGLM backbone
  5. Adjust backbone's output attention scores using pre-computed gate weights $\hat{s}$

- **Design tradeoffs:**
  - Computational Overhead: LGTL adds GAT computations before the main Transformer, increasing preprocessing time compared to simple mean-aggregation templates
  - Sampling Size ($n_i$): Larger samples capture more context but increase memory and compute load for GAT attention calculation

- **Failure signatures:**
  - Homophily Collapse: If Gate Module weights collapse to near-zero for local hops even on homophilic graphs, performance may degrade
  - Attention Dilution: If Selection Module assigns uniform weights due to uninformative features, the mechanism reduces to a computationally expensive version of the "HO" template

- **First 3 experiments:**
  1. Run `LLaGA-LGTL` vs. `LLaGA-HO` on `Texas` or `Cornell` dataset to verify claimed accuracy gain (approx. 20-25% lift)
  2. Disable the Gate Module (force uniform hop weights) to measure contribution of "Adaptive Hop Re-weighting" vs. "Intra-Hop Selection" alone
  3. Visualize gate weights $\hat{s}$ on heterophilic dataset to confirm model is suppressing 1-hop attention in favor of 2-hop or central-node features

## Open Questions the Paper Calls Out

1. **Generalization to other graph domains:** Can LGTL generalize to molecular interaction networks or knowledge graphs beyond social and citation networks?
2. **Dynamic graph integration:** How can LGTL be effectively integrated into dynamic graph learning paradigms where structures evolve over time?
3. **Computational overhead:** What is the specific computational and memory overhead introduced by the GAT-based gate and selection modules compared to fixed-template tokenization?

## Limitations
- Theoretical analysis relies on smoothness bounds that may not uniformly hold across all graph types
- Limited ablation studies prevent quantifying individual contributions of gate versus selection modules
- Hyperparameter sensitivity analysis is insufficient, particularly regarding neighbor sampling sizes and GAT layer configurations

## Confidence
- **High Confidence:** Empirical improvements on heterophilic benchmarks (10.39% average accuracy gain) are well-supported by experimental results
- **Medium Confidence:** Theoretical justification for adaptive hop re-weighting is mathematically sound but relies on assumptions about label consistency
- **Low Confidence:** Exact mechanism by which gate module learns to suppress noisy near-hop signals is not fully transparent without detailed visualizations

## Next Checks
1. Implement ablation study disabling the gate module while keeping selection module active to isolate contributions
2. Create synthetic heterophilic graphs with controlled homophily ratios to test performance degradation as homophily decreases
3. Analyze learned gate weights $\hat{s}$ on real-world heterophilic datasets to verify suppression of 1-hop attention in favor of 2-hop or central-node features