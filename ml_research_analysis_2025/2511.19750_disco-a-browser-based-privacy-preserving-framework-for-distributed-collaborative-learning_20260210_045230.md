---
ver: rpa2
title: 'DISCO: A Browser-Based Privacy-Preserving Framework for Distributed Collaborative
  Learning'
arxiv_id: '2511.19750'
source_url: https://arxiv.org/abs/2511.19750
tags:
- learning
- data
- disco
- training
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DISCO is an open-source, browser-based platform for distributed
  collaborative learning that enables users to train machine learning models without
  sharing raw data. The platform supports both federated and decentralized learning
  paradigms, integrates privacy-preserving techniques such as differential privacy
  and secure multi-party computation, and offers a code-free, cross-platform web interface
  accessible on mobile devices.
---

# DISCO: A Browser-Based Privacy-Preserving Framework for Distributed Collaborative Learning

## Quick Facts
- arXiv ID: 2511.19750
- Source URL: https://arxiv.org/abs/2511.19750
- Reference count: 24
- Primary result: DISCO is an open-source, browser-based platform enabling collaborative machine learning without raw data sharing, supporting federated and decentralized modes with privacy-preserving techniques.

## Executive Summary
DISCO is an open-source framework for distributed collaborative learning that enables users to train machine learning models without sharing their raw data. It operates directly in web browsers using TensorFlow.js, supporting both federated learning (centralized aggregation) and decentralized learning (peer-to-peer exchange via WebRTC). The platform incorporates differential privacy and secure multi-party computation to protect user data, while offering a code-free interface accessible on mobile devices. DISCO's modular architecture allows customization of training settings, aggregation strategies, and privacy guarantees, democratizing access to collaborative machine learning while preserving data sovereignty.

## Method Summary
DISCO is a browser-based platform for distributed collaborative machine learning that enables training without sharing raw data. Users join a "DISCOllaborative" task, where local training occurs directly in the browser using TensorFlow.js. In federated mode, clients train locally and send gradients to a server for aggregation (FedAvg algorithm). In decentralized mode, clients exchange weights directly via WebRTC peer-to-peer connections. The platform supports differential privacy (Gaussian noise addition and gradient clipping) and secure multi-party computation (additive secret sharing) for enhanced privacy. Users can create or join predefined tasks through a code-free web interface, with data remaining exclusively on local devices.

## Key Results
- Enables collaborative machine learning without raw data sharing through browser-based local training
- Supports both federated and decentralized learning paradigms with configurable privacy guarantees
- Offers code-free, cross-platform web interface accessible on mobile devices while maintaining data sovereignty

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Browser-based local training preserves data sovereignty while enabling collaborative model improvement.
- **Mechanism:** TensorFlow.js executes all model training directly in the client's browser (WebGL backend leverages GPU; falls back to CPU/WebAssembly). Only model weight updates—never raw data—are transmitted.
- **Core assumption:** Browsers have sufficient computational resources for meaningful training epochs.
- **Evidence anchors:** [abstract] "DISCO's web application trains models locally directly in the browser" [Section 2.3] "TensorFlow.js supports multiple computational backends... The WebGL backend is the most powerful one and leverages the system's GPU"
- **Break condition:** Large models (>100M parameters) or extended training may exhaust browser memory.

### Mechanism 2
- **Claim:** Decentralized learning eliminates the central server's access to weight updates, removing a single point of trust.
- **Mechanism:** Nodes establish direct peer-to-peer connections via WebRTC. The server acts only as a signaling server for peer discovery and round coordination—never receiving weights.
- **Core assumption:** WebRTC can traverse NATs/firewalls reliably.
- **Evidence anchors:** [Section 2.5] "nodes in DL do not share weights with a central server; instead, they exchange them directly... using WebRTC"
- **Break condition:** Symmetric NATs or restrictive corporate firewalls may block WebRTC.

### Mechanism 3
- **Claim:** Differential privacy and secure multi-party computation limit reconstruction attacks on gradient updates.
- **Mechanism:** (1) DP: Gaussian noise is added to gradients, and gradients are clipped to a radius. (2) SMPC: Local weight updates are split into additive secret shares distributed among peers.
- **Core assumption:** Noise scale and clipping radius are tuned appropriately for data sensitivity.
- **Evidence anchors:** [Section 2.4] "adding Gaussian noise to gradient updates by setting a noise scale, as well as clipping gradients by adjusting a clipping radius"
- **Break condition:** Insufficient peers for SMPC share distribution halts training.

## Foundational Learning

- **Federated Learning (FedAvg algorithm):**
  - Why needed here: Core paradigm for centralized aggregation in DISCO.
  - Quick check question: Can you explain why FedAvg averages client gradients rather than aggregating raw data?

- **Differential Privacy (noise + clipping):**
  - Why needed here: Users configure DP settings at task creation.
  - Quick check question: What happens to model accuracy if the noise scale is set too high?

- **WebRTC and P2P Communication:**
  - Why needed here: Enables decentralized mode.
  - Quick check question: In decentralized mode, what information does the server never see?

## Architecture Onboarding

- **Component map:**
  - `discojs` (core library) -> `discojs-web` (browser helpers) -> `discojs-node` (Node.js helpers) -> Server (WebSocket orchestration) -> Web app (code-free UI)

- **Critical path:**
  1. Deploy server (maintainer task)
  2. Define DISCOllaborative: model architecture, data format, hyperparameters
  3. User joins via browser → connects local data → training begins (local epochs → weight exchange → aggregation cycle)
  4. Federated: upload gradients to server → server aggregates → receive global update
  5. Decentralized: server signals ready peers → WebRTC P2P connections → exchange/aggregate weights locally

- **Design tradeoffs:**
  - Federated vs. Decentralized: FL trusts server with gradients; DL removes server trust but requires stable peer connectivity
  - DP strength vs. model utility: Higher noise/clipping → stronger privacy → potential accuracy loss
  - Browser vs. CLI: Browser accessible but resource-limited; CLI enables larger-scale experiments

- **Failure signatures:**
  - Training pauses with "insufficient participants": Threshold for round not met
  - WebRTC connection failures: NAT/firewall blocking
  - Out-of-memory in browser: Model too large
  - SMPC round stalls: Peers dropped mid-share exchange

- **First 3 experiments:**
  1. **Hello FL:** Join a public MNIST DISCOllaborative via browser; observe training curves and global aggregation every 2 epochs.
  2. **Decentralized test:** Create a 3-node DL task using CLI clients on same network; verify WebRTC P2P exchange.
  3. **DP impact:** Run same task with noise scale = 0 vs. noise scale = 1.0; compare final accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does decentralized learning with WebRTC peer-to-peer connections scale as the number of participants increases?
- Basis in paper: [inferred] The paper describes forming "a fully connected topology" for weight exchange but does not evaluate scalability limits.
- Why unresolved: No experiments or analysis are provided for training sessions with more than a few participants.
- What evidence would resolve it: Empirical measurements of training time, bandwidth consumption, and success rates across varying participant counts.

### Open Question 2
- Question: What are the privacy-utility trade-offs when combining differential privacy with secure multi-party computation in browser-based training environments?
- Basis in paper: [explicit] The paper states DP settings are customizable and SMPC is supported, but notes "Neither FL nor DL are immune to attacks on privacy."
- Why unresolved: The paper provides no empirical evaluation of model accuracy degradation under different DP noise levels.
- What evidence would resolve it: Benchmarks comparing model accuracy and training duration across configurations with and without DP/SMPC.

### Open Question 3
- Question: How robust are browser-based training sessions to node churn, network interruptions, and heterogeneous client availability?
- Basis in paper: [inferred] The paper mentions WebRTC supports "re-establishing dropped connections" but no analysis of failure modes is provided.
- Why unresolved: Real-world collaborative learning involves participants joining/leaving unpredictably.
- What evidence would resolve it: Simulated experiments with controlled drop-out rates measuring convergence speed and final accuracy.

## Limitations
- Browser-based training may be constrained by client device memory and computational resources
- WebRTC P2P exchange reliability is untested in environments with restrictive NATs or firewalls
- Privacy-utility trade-offs for combined DP and SMPC configurations lack empirical validation

## Confidence
- **High Confidence:** Core architecture (browser-local training, federated/decentralized modes) is logically sound and well-specified
- **Medium Confidence:** Privacy mechanisms (DP, SMPC) are technically feasible but lack DISCO-specific validation
- **Low Confidence:** Browser scalability, WebRTC robustness, and SMPC efficiency under real-world conditions remain unproven

## Next Checks
1. **Browser Performance Benchmark:** Train identical models in browser vs. Node.js/CLI backend. Measure epoch time, memory usage, and accuracy drop.
2. **WebRTC NAT Traversal Test:** Deploy DISCO in environments with symmetric NATs and corporate firewalls. Log ICE connection failures and peer drop rates.
3. **DP Utility Sweep:** Run a MNIST task with noise scales from 0 to 2.0. Plot accuracy vs. noise to empirically determine the privacy-utility frontier.