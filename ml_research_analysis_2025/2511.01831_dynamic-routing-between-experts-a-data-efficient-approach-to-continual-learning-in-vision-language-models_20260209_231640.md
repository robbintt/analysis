---
ver: rpa2
title: 'Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning
  in Vision-Language Models'
arxiv_id: '2511.01831'
source_url: https://arxiv.org/abs/2511.01831
tags:
- tasks
- learning
- routing
- task
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in vision-language
  models during sequential fine-tuning. The authors propose a dynamic routing approach
  that enables task-specific adaptation while preserving foundational capabilities.
---

# Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models

## Quick Facts
- arXiv ID: 2511.01831
- Source URL: https://arxiv.org/abs/2511.01831
- Authors: Jay Mohta; Kenan Emir Ak; Dimitrios Dimitriadis; Yan Xu; Mingwei Shen
- Reference count: 19
- Primary result: Dynamic routing with task-specific LoRA modules prevents catastrophic forgetting in vision-language models during sequential fine-tuning

## Executive Summary
This paper addresses catastrophic forgetting in vision-language models during sequential fine-tuning by proposing a dynamic routing approach that enables task-specific adaptation while preserving foundational capabilities. The method uses lightweight LoRA modules for task specialization and learns routing vectors to dynamically select the appropriate module during inference. Evaluated on InternVL-2 models (2B and 8B parameters), the approach maintains performance on benchmark tasks while improving accuracy on specialized tasks, matching or exceeding multi-task learning performance without requiring access to all task data simultaneously. The routing mechanism also enables cross-modal transfer between language and vision capabilities.

## Method Summary
The authors propose a dynamic routing mechanism that combines task-specific LoRA modules with learned routing vectors to enable continual learning in vision-language models. During training, the model learns both the task-specific adaptations through LoRA modules and routing vectors that determine which module to activate for each task. At inference time, the routing vector selects the appropriate LoRA module based on the input task, allowing the model to maintain both foundational capabilities and task-specific performance without catastrophic forgetting. The approach is evaluated on InternVL-2 2B and 8B parameter models across three specialized tasks (TextVQA, STVQA, DocVQA) while maintaining performance on benchmark tasks.

## Key Results
- Maintains performance on foundational benchmark tasks while improving accuracy on specialized tasks
- Matches or exceeds multi-task learning performance without requiring simultaneous access to all task data
- Demonstrates computational efficiency by using lightweight LoRA modules for task specialization
- Shows cross-modal transfer capabilities between language and vision tasks

## Why This Works (Mechanism)
The dynamic routing approach works by creating a modular architecture where each task has a dedicated LoRA module that captures task-specific adaptations. The routing vectors learn to identify which task is being presented and select the appropriate module, effectively creating a conditional computation path. This prevents interference between tasks because each specialized module only activates for its corresponding task. The lightweight nature of LoRA modules ensures computational efficiency while the routing mechanism provides flexibility to handle new tasks without retraining the entire model.

## Foundational Learning
- Catastrophic forgetting: When neural networks learn new tasks, they often overwrite knowledge of previous tasks. Understanding this is crucial because the paper directly addresses this problem in continual learning scenarios.
- LoRA (Low-Rank Adaptation): A parameter-efficient fine-tuning method that modifies model weights through low-rank updates. This is needed for computational efficiency when creating task-specific adaptations.
- Vision-language models: Multimodal models that process both visual and textual information. Quick check: Verify that the model can handle both image and text inputs effectively.

## Architecture Onboarding

**Component map:**
Input -> Router (routing vector) -> Task-specific LoRA module -> Vision-language backbone -> Output

**Critical path:**
1. Input processing (vision and/or text)
2. Routing vector computation to determine active task module
3. Activation of corresponding LoRA module
4. Processing through vision-language backbone
5. Output generation

**Design tradeoffs:**
- LoRA vs full fine-tuning: LoRA provides parameter efficiency but may limit adaptation capacity
- Routing complexity vs. model simplicity: More sophisticated routing could improve accuracy but increase computational overhead
- Task isolation vs. cross-task knowledge sharing: Complete isolation prevents interference but may miss beneficial knowledge transfer

**Failure signatures:**
- Incorrect routing leading to activation of wrong LoRA module
- Routing vectors failing to converge, causing inconsistent task selection
- LoRA modules interfering with foundational capabilities despite isolation

**First 3 experiments to run:**
1. Test routing accuracy on a held-out validation set to ensure correct task identification
2. Evaluate catastrophic forgetting by measuring performance degradation on previously learned tasks
3. Compare inference latency with and without routing mechanism to quantify overhead

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Evaluation scope is limited to three specialized tasks, raising questions about scalability to larger task sets
- Routing mechanism stability across training sessions is not thoroughly investigated
- Computational efficiency analysis lacks comprehensive evaluation of routing overhead as task count increases

## Confidence

**Major claim confidence:**
- **High confidence**: The approach works for the specific tasks and model sizes evaluated (InternVL-2 2B and 8B)
- **Medium confidence**: The computational efficiency claims and scalability with model size
- **Low confidence**: Generalization to diverse task distributions and stability of routing across extended continual learning scenarios

## Next Checks
1. Evaluate the approach on a larger benchmark with 10+ diverse vision-language tasks to test scalability and routing stability
2. Test the routing mechanism's performance when tasks are presented in random order rather than sequential fine-tuning order
3. Measure inference latency and memory overhead as the number of task-specific LoRA modules increases beyond three tasks