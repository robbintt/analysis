---
ver: rpa2
title: Adaptive Data Augmentation for Thompson Sampling
arxiv_id: '2506.14479'
source_url: https://arxiv.org/abs/2506.14479
tags:
- contexts
- estimator
- hypothetical
- regret
- bound
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the long-standing challenge of achieving\
  \ optimal regret bounds in linear contextual bandits using Thompson Sampling (LinTS).\
  \ While LinTS performs well empirically, it has historically lagged behind the theoretical\
  \ guarantees of the upper-confidence-bound approach (LinUCB), with a regret bound\
  \ of O(d^{3/2}\u221AT) compared to LinUCB's optimal O(d\u221AT)."
---

# Adaptive Data Augmentation for Thompson Sampling

## Quick Facts
- arXiv ID: 2506.14479
- Source URL: https://arxiv.org/abs/2506.14479
- Reference count: 11
- Achieves optimal O(d√T log T) regret bound for Thompson Sampling in linear contextual bandits

## Executive Summary
This paper introduces a novel approach to Thompson Sampling for linear contextual bandits that achieves optimal theoretical guarantees. By developing a sophisticated data augmentation technique with adaptive coupling between hypothetical and original bandit problems, the proposed method HCSA+TS matches the O(d√T log T) regret bound of upper-confidence-bound methods while maintaining Thompson Sampling's practical advantages. The key innovation is reducing the number of augmented samples from K to at most d+1 per round while preserving the necessary statistical properties for optimal performance.

## Method Summary
The paper presents HCSA+TS, which constructs hypothetical contexts through eigendecomposition of the Gram matrix of unselected arms, enabling efficient data augmentation. At each round, the algorithm builds a hypothetical context set that preserves the covariance structure of original contexts while requiring only d+1 augmented samples. A coupling mechanism resamples until success, connecting the augmented and original problems through shared pseudo-rewards. The method uses a self-normalized error bound based on a Gram matrix incorporating all context vectors, including unselected arms. This framework eliminates the need for restrictive assumptions about context distributions that previous approaches required.

## Key Results
- Achieves optimal O(d√T log T) regret bound matching theoretical lower bounds up to logarithmic factors
- Outperforms LinTS, LinUCB, and doubly-robust variants in empirical tests, especially with missing context features
- Demonstrates superior prediction accuracy across various settings with consistent performance gains
- Eliminates restrictive assumptions about context distributions required by previous methods

## Why This Works (Mechanism)
The method works by creating a coupled system between original and hypothetical bandit problems through adaptive data augmentation. By constructing hypothetical contexts that preserve the covariance structure while drastically reducing sample complexity, the algorithm maintains the statistical power needed for accurate posterior sampling. The coupling mechanism ensures that the augmented samples are properly aligned with the original problem, allowing the self-normalized analysis to work effectively. This combination of efficient augmentation and proper coupling enables the optimal regret bound while avoiding the K-sample limitation of standard approaches.

## Foundational Learning
- Linear contextual bandit regret analysis: Understanding how cumulative regret accumulates over time and the relationship between dimension d and horizon T
- Self-normalized martingale inequalities: Key tool for bounding estimation errors without strong distributional assumptions
- Gram matrix properties: Understanding how covariance structures propagate through hypothetical contexts
- Thompson Sampling posterior sampling: How Gaussian posteriors are constructed and used for arm selection
- Coupling techniques in bandit problems: Methods for connecting related stochastic processes to enable tighter analysis

## Architecture Onboarding

**Component Map:**
Initialize → Build hypothetical contexts → Resample with coupling → Compute HCSA estimator → Thompson sampling → Update

**Critical Path:**
The most critical path is the resampling loop that ensures coupling success. This requires generating θ̃ samples for each arm, attempting selection, and retrying until the coupling condition ã_t = N_t is met. The number of attempts M_t must be sufficient to guarantee success with high probability.

**Design Tradeoffs:**
- γ (coupling probability) vs computational overhead: Smaller γ reduces regularization set size but increases resampling attempts
- Number of augmented samples (d+1) vs statistical efficiency: Minimal augmentation maintains tractability but requires careful Gram matrix construction
- Regularization parameter λ vs estimation accuracy: Must balance bias and variance in ridge regression

**Failure Signatures:**
- Resampling loop never terminates: Indicates γ is too small or implementation error in coupling probability calculation
- V_t becomes singular: Suggests improper orthogonal basis augmentation or insufficient regularization
- Poor regret performance: May indicate incorrect noise scale σ or inappropriate λ parameter

**3 First Experiments:**
1. Implement basic LinTS baseline with varying regularization parameters to establish performance floor
2. Test hypothetical context construction with synthetic data, verifying Gram matrix properties and eigendecomposition correctness
3. Run the full HCSA+TS algorithm with varying γ values (0.1, 0.5, 0.9) and measure average resampling attempts per round

## Open Questions the Paper Calls Out
- Extension to nonlinear bandit settings (e.g., generalized linear models or neural contextual bandits) remains unexplored, requiring fundamentally different self-normalized bounds
- Adaptive selection of the coupling parameter γ is currently treated as a hyperparameter without theoretical guidance on optimal selection
- Computational complexity could potentially be improved from O(d²(K+d)T) to near-linear in d while preserving optimal regret guarantees

## Limitations
- Requires careful tuning of coupling parameter γ, which significantly impacts both theoretical bounds and empirical runtime
- Computational overhead from potentially many resampling attempts may limit scalability in high-dimensional settings
- The algorithm's complexity makes it sensitive to implementation details, particularly in the eigendecomposition and resampling loop

## Confidence
- **High Confidence:** Theoretical regret bound O(d√T log T) is rigorously proven using self-normalized martingale inequalities and Gram matrix analysis
- **Medium Confidence:** Empirical results show consistent outperformance of benchmarks, though synthetic data setup may not fully represent real-world complexity
- **Medium Confidence:** The theoretical justification for reducing augmented samples from K to d+1 is mathematically sound but practical benefits depend on implementation quality

## Next Checks
1. Implement the coupling mechanism with varying γ values (0.1, 0.5, 0.9) and measure average resampling attempts per round to confirm practical feasibility
2. Test HCSA+TS on standard real-world bandit datasets with varying feature sparsity to validate generalization beyond synthetic settings
3. Systematically sweep the regularization parameter λ and h_t threshold computation to identify sensitivity and provide practical guidelines for parameter selection