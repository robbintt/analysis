---
ver: rpa2
title: Improving Local Fidelity Through Sampling and Modeling Nonlinearity
arxiv_id: '2512.05556'
source_url: https://arxiv.org/abs/2512.05556
tags:
- local
- lime
- fidelity
- sampling
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of improving local fidelity in
  explanations generated by LIME, which assumes linear local decision boundaries and
  often fails to capture nonlinear relationships, leading to incorrect explanations.
  The authors propose a novel method that combines N-ball sampling with Multivariate
  Adaptive Regression Splines (MARS) to enhance local fidelity.
---

# Improving Local Fidelity Through Sampling and Modeling Nonlinearity

## Quick Facts
- **arXiv ID:** 2512.05556
- **Source URL:** https://arxiv.org/abs/2512.05556
- **Authors:** Sanjeev Shrestha; Rahul Dubey; Hui Liu
- **Reference count:** 21
- **Primary result:** The proposed method (mLIME) achieves an average reduction of 37% in RMSE compared to LEMON and 69.2% compared to LIME baselines for local model explanations.

## Executive Summary
This paper addresses the problem of improving local fidelity in explanations generated by LIME, which assumes linear local decision boundaries and often fails to capture nonlinear relationships, leading to incorrect explanations. The authors propose a novel method that combines N-ball sampling with Multivariate Adaptive Regression Splines (MARS) to enhance local fidelity. N-ball sampling generates synthetic samples directly from the desired distribution within a local region, while MARS models nonlinear local boundaries by creating piecewise linear regressions. Experiments on three UCI datasets with different classifiers and kernel widths show that the proposed method consistently outperforms LIME and LEMON baselines, achieving significant reductions in RMSE.

## Method Summary
The method replaces LIME's global sampling and linear surrogate with N-ball sampling and MARS. N-ball sampling generates points uniformly within an n-dimensional hypersphere centered on the instance to be explained, ensuring all synthetic samples lie strictly within the local region. The MARS model then fits a piecewise linear surrogate using hinge functions, capturing nonlinear local boundaries through forward and backward passes with GCV-based pruning. This combination aims to improve the faithfulness of local explanations by better modeling the true decision boundary structure.

## Key Results
- mLIME achieves an average reduction of 37% in RMSE compared to LEMON and 69.2% compared to LIME
- The method shows consistent performance improvements across three UCI datasets (Wine, Diabetes, Breast Cancer) with different classifiers
- Higher fidelity is maintained across various kernel widths, demonstrating robustness to parameter selection
- Results indicate better performance particularly in higher-dimensional datasets where nonlinear relationships are more prevalent

## Why This Works (Mechanism)

### Mechanism 1
Restricting synthetic sampling to a strict local neighborhood (N-ball) improves the relevance of training data for the surrogate model, provided the optimal explanation lies within that radius. N-ball sampling generates points uniformly within an n-dimensional hypersphere of radius r centered on the instance, preventing distant, irrelevant feature combinations from influencing the local boundary fit. The core assumption is that the decision boundary relevant to the explanation is fully contained within the defined radius r. This mechanism fails if the kernel width is set too narrow to capture the decision boundary or so wide that it re-introduces global noise.

### Mechanism 2
Modeling non-linear relationships via piecewise linear functions (MARS) captures complex local boundaries better than a single linear hyperplane, conditional on the locality containing curvature. MARS partitions the feature space into overlapping regions using hinge functions, fitting separate linear slopes for each region. This allows the surrogate to approximate curves rather than just flat planes. The core assumption is that the local decision boundary of the black-box model is non-linear or involves feature interactions that a global linear model cannot approximate without high bias. This mechanism fails if the local boundary is highly irregular or if the added complexity leads to overfitting on synthetic sample noise.

### Mechanism 3
Generalized Cross-Validation (GCV) pruning effectively balances the trade-off between surrogate model flexibility and overfitting. During the backward pass of MARS construction, terms are removed based on a GCV score that penalizes model complexity. This retains only those piecewise components that significantly reduce approximation error relative to their complexity cost. The core assumption is that a simpler model with fewer terms generalizes better to unseen points in the local neighborhood than a fully saturated model. This mechanism fails if the penalty factor is misconfigured, leading to pruning of critical non-linear terms or retention of noise.

## Foundational Learning

- **Concept: Local Fidelity vs. Global Fidelity**
  - Why needed: The paper specifically optimizes for local fidelity rather than global behavior, making this distinction critical for interpreting RMSE results.
  - Quick check: Does a model with high local fidelity at point A guarantee high fidelity at a distant point B? (Answer: No)

- **Concept: The "Curse of Dimensionality" in Sampling**
  - Why needed: The paper critiques standard sampling and uses N-ball sampling. In high dimensions, volume grows rapidly and random sampling becomes sparse.
  - Quick check: As feature dimensions (n) increase, does the volume of a unit sphere increase or decrease relative to the enclosing cube? (Answer: The relative volume of the sphere decreases drastically)

- **Concept: Surrogate Model Interpretability**
  - Why needed: The paper argues MARS maintains interpretability while improving fidelity. MARS outputs explicit basis functions which are readable, unlike neural weights.
  - Quick check: Can you easily extract a human-readable rule from a MARS model compared to a Random Forest? (Answer: Yes, MARS provides a symbolic equation)

## Architecture Onboarding

- **Component map:** Target Instance (x) -> N-ball Sampler -> Black-box Oracle -> MARS Engine -> Evaluator
- **Critical path:** The performance bottleneck is likely the MARS fitting stage (O(nps)) rather than the sampling, especially if the number of synthetic samples or predictors is large.
- **Design tradeoffs:**
  - Complexity vs. Speed: MARS is computationally heavier than simple linear regression, expecting longer generation times per explanation
  - Interpretability vs. Accuracy: While MARS is interpretable, high interaction orders can make explanations harder for humans to parse than single-feature weights
- **Failure signatures:**
  - High RMSE at Low Kernel Width: If σ is too small, the N-ball may contain too few effective samples, causing MARS to fail to converge or overfit
  - Instability: If sampling is too sparse for the dimensionality, the surrogate may vary wildly between runs unless sample count is increased
- **First 3 experiments:**
  1. Reproduce RMSE Reduction: Implement N-ball sampling on the Wine dataset with a Random Forest classifier and verify RMSE drops relative to baseline
  2. Sensitivity to Radius: Vary the kernel width σ to observe stability claims and whether mLIME degrades more gracefully than LIME as width increases
  3. Visual Inspection of Boundaries: Pick a 2D slice of a classifier with a known non-linear boundary and visualize decision boundaries of LIME linear model vs. mLIME MARS model

## Open Questions the Paper Calls Out

### Open Question 1
How can the mLIME framework be effectively adapted for high-dimensional, non-tabular data modalities such as images and time-series data? The current N-ball sampling method relies on generating synthetic samples within a continuous Euclidean hypersphere, and MARS is designed for numerical inputs; these do not translate directly to pixel structures of images or temporal dependencies of time-series. Future work can focus on extending its application to other data modalities.

### Open Question 2
Does the integration of N-ball sampling and MARS significantly improve the stability (consistency) of explanations across multiple runs compared to LIME? While N-ball sampling claims to reduce variance by restricting the sample space, the paper does not quantify or test the stability of the generated explanations against the "instability" cited as a limitation of LIME. Improving the stability of explanations is identified as a specific focus for future work.

### Open Question 3
How does mLIME perform on datasets containing categorical features or complex feature interactions? The methodology describes MARS using hinge functions on continuous variables and experiments are restricted to continuous features. The N-ball sampling technique generates points in a continuous hypersphere, which does not inherently account for discrete feature states or the specific distribution of categorical data, potentially limiting the method's generality.

## Limitations
- The paper does not specify MARS hyperparameters (max basis functions, interaction degree, GCV penalty), which could significantly affect results
- The mapping between kernel width σ and sampling radius r is not explicitly defined, raising concerns about fair comparison with LIME
- No information is provided about data preprocessing or scaling, which could influence fidelity scores
- The paper focuses on RMSE as the sole fidelity metric without exploring alternative measures like explanation stability or feature attribution consistency

## Confidence

- **High Confidence:** The core mechanism of using N-ball sampling to improve local relevance is well-supported by the text and has clear theoretical grounding
- **Medium Confidence:** The MARS-based surrogate model's ability to capture nonlinear boundaries is plausible given the methodology described, but lacks direct validation in the paper
- **Low Confidence:** The claim of "37% reduction in RMSE compared to LEMON" is difficult to verify without knowing the exact experimental setup and hyperparameters used

## Next Checks

1. **Parameter Sensitivity Analysis:** Conduct experiments varying MARS hyperparameters (max basis functions, interaction degree) to determine their impact on fidelity scores and identify optimal configurations
2. **Alternative Fidelity Metrics:** Implement and compare mLIME using alternative fidelity measures such as explanation stability (variance across perturbed samples) and feature attribution consistency to provide a more comprehensive evaluation
3. **Real-World Application Test:** Apply mLIME to a high-stakes domain (e.g., medical diagnosis or financial risk assessment) and evaluate its practical utility in terms of both accuracy and interpretability for domain experts