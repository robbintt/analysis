---
ver: rpa2
title: 'Seed-Coder: Let the Code Model Curate Data for Itself'
arxiv_id: '2506.03524'
source_url: https://arxiv.org/abs/2506.03524
tags:
- code
- data
- quality
- performance
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Seed-Coder, a family of open-source code
  LLMs that minimize human effort in data curation by using LLMs to score and filter
  training data. The approach leverages model-centric quality filtering and a multi-stage
  training pipeline, including base pretraining, supervised fine-tuning, and reasoning
  model training with LongCoT reinforcement learning.
---

# Seed-Coder: Let the Code Model Curate Data for Itself

## Quick Facts
- arXiv ID: 2506.03524
- Source URL: https://arxiv.org/abs/2506.03524
- Reference count: 40
- Key outcome: Seed-Coder-8B-Instruct achieves 53.3% on BigCodeBench, 26.4% on MHPP hard set, surpassing some larger models through LLM-driven data curation

## Executive Summary
Seed-Coder introduces a family of open-source code LLMs that minimize human effort in data curation by using LLMs to score and filter training data. The approach leverages model-centric quality filtering and a multi-stage training pipeline, including base pretraining, supervised fine-tuning, and reasoning model training with LongCoT reinforcement learning. Seed-Coder-8B-Instruct achieves state-of-the-art performance among ~8B models, with 53.3% on BigCodeBench and 26.4% on MHPP hard set, surpassing some much larger models. The reasoning variant achieves 53.6% on LiveCodeBench, demonstrating that LLM-driven data curation can yield high-quality code models with reduced human involvement.

## Method Summary
Seed-Coder employs a multi-stage training pipeline with a novel data curation approach. The method uses LLMs to score and filter training data through model-centric quality filtering, reducing the need for human annotation. The training process consists of three stages: base pretraining on filtered code datasets, supervised fine-tuning on curated instruction-response pairs, and reasoning model training using LongCoT reinforcement learning. This approach aims to maintain high data quality while minimizing human effort in the curation process, with the model itself acting as the curator to identify and filter relevant training examples.

## Key Results
- Seed-Coder-8B-Instruct achieves 53.3% on BigCodeBench and 26.4% on MHPP hard set
- Reasoning variant achieves 53.6% on LiveCodeBench, demonstrating strong code reasoning capabilities
- Outperforms some larger models like CodeLlama-34B while maintaining ~8B parameter size

## Why This Works (Mechanism)
Seed-Coder's effectiveness stems from its LLM-driven data curation approach that reduces human annotation requirements while maintaining high-quality training data. The model-centric quality filtering allows the code model to evaluate and score training examples, creating a self-reinforcing loop where the model curates data most relevant to its learning objectives. This approach addresses the challenge of human annotation bottleneck in traditional data curation pipelines, enabling more efficient scaling of code model training while preserving or improving performance metrics.

## Foundational Learning

### Code Generation and Reasoning
- **Why needed**: Code models must generate syntactically correct code and understand complex programming logic
- **Quick check**: Evaluate on BigCodeBench and LiveCodeBench benchmarks for code generation and reasoning tasks

### Reinforcement Learning for Code
- **Why needed**: Fine-tuning code models requires specialized techniques beyond standard supervised learning
- **Quick check**: Assess performance improvements when using LongCoT reinforcement learning compared to supervised fine-tuning alone

### Data Quality Filtering
- **Why needed**: Training data quality directly impacts model performance and generalization
- **Quick check**: Compare model performance when trained on LLM-filtered versus human-curated datasets

## Architecture Onboarding

### Component Map
Seed-Coder -> LLM-based Data Scoring -> Quality Filtered Dataset -> Base Pretraining -> SFT -> LongCoT RL -> Reasoning Model

### Critical Path
Data filtering (LLM scoring) → Base pretraining → Supervised fine-tuning → LongCoT reinforcement learning

### Design Tradeoffs
- Reduced human effort vs. potential bias from LLM-driven filtering
- Model size optimization vs. computational efficiency
- Reasoning capabilities vs. general code generation performance

### Failure Signatures
- Overfitting to LLM filtering criteria
- Performance degradation on out-of-distribution code tasks
- Suboptimal reasoning performance due to insufficient fine-tuning diversity

### First Experiments
1. Compare Seed-Coder performance on standard code generation benchmarks (BigCodeBench) versus reasoning-specific tasks (LiveCodeBench)
2. Test model generalization by evaluating on diverse programming languages and problem domains
3. Assess computational efficiency by measuring inference time and memory usage relative to model size

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains over larger models may not fully account for differences in pretraining corpus size, diversity, or duration
- The actual human effort reduction compared to traditional data curation approaches is not quantified
- Reproducibility of the data filtering methodology is uncertain due to lack of detailed implementation specifications
- Reasoning model performance is demonstrated on a single benchmark (LiveCodeBench) without broader generalization testing

## Confidence

- High confidence: Seed-Coder-8B-Instruct achieves competitive performance on BigCodeBench and MHPP benchmarks relative to other ~8B models
- Medium confidence: The multi-stage training pipeline (base pretraining → SFT → reasoning fine-tuning) contributes to the model's performance gains
- Medium confidence: LLM-driven data curation methodology reduces human involvement while maintaining quality
- Low confidence: The reasoning variant's 53.6% on LiveCodeBench represents state-of-the-art performance for code reasoning models

## Next Checks

1. Conduct ablation studies comparing Seed-Coder's performance when trained on traditional human-curated datasets versus the LLM-filtered datasets to quantify the actual impact of the data curation approach
2. Test the reasoning model's generalization across multiple reasoning benchmarks beyond LiveCodeBench to assess broader capabilities
3. Publish detailed implementation of the LLM-based data scoring mechanism and threshold selection process to enable reproducibility and comparison with alternative curation methods