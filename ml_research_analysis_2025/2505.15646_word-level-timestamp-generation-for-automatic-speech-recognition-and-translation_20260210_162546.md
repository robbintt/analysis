---
ver: rpa2
title: Word Level Timestamp Generation for Automatic Speech Recognition and Translation
arxiv_id: '2505.15646'
source_url: https://arxiv.org/abs/2505.15646
tags:
- timestamp
- timestamps
- speech
- prediction
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a data-driven approach for word-level timestamp
  prediction in the Canary model for both automatic speech recognition (ASR) and automatic
  speech translation (AST). The core method uses NeMo Forced Aligner (NFA) as a teacher
  model to generate word-level timestamps and trains the Canary model to predict timestamps
  directly using a new <|timestamp| token.
---

# Word Level Timestamp Generation for Automatic Speech Recognition and Translation

## Quick Facts
- arXiv ID: 2505.15646
- Source URL: https://arxiv.org/abs/2505.15646
- Reference count: 0
- Primary result: Achieves 80-90% precision/recall for ASR timestamp prediction with 20-120ms errors and minimal WER degradation

## Executive Summary
This paper presents a data-driven approach for word-level timestamp prediction in the Canary model for both ASR and AST. The method leverages NeMo Forced Aligner (NFA) as a teacher to generate word-level timestamps, which are then used to train the model to predict timestamps directly using a new `<|timestamp|>` token. The approach achieves high precision and recall for ASR timestamp prediction while maintaining translation quality for AST tasks, demonstrating capability for cross-lingual timestamp transfer without explicit AST timestamp training data.

## Method Summary
The approach uses NFA to generate word-level timestamps from speech-text pairs, which are discretized into frame indices and injected as special tokens during training. The Canary decoder learns to predict these timestamp tokens alongside text, enabling end-to-end timestamp prediction without external modules. For AST, timestamps from source words are transferred to target words using awesome-align word alignments. The model uses absolute frame indexing (0-450) with 80ms granularity, achieving high accuracy while maintaining translation quality through careful data mixing.

## Key Results
- Achieves 80-90% precision and recall for ASR timestamp prediction with errors ranging from 20-120ms across four languages
- Maintains minimal WER degradation (0.1-0.4 WER increase) compared to baseline models
- Outperforms WhisperTimestamped in ASR timestamp prediction accuracy
- Demonstrates AST timestamp capability with 200ms error range and 4.4 BLEU drop

## Why This Works (Mechanism)

### Mechanism 1
Teacher-generated alignments enable end-to-end timestamp prediction without external modules. NFA produces frame-accurate word boundaries from speech-text pairs, which are discretized into frame indices and injected as special tokens during training. The decoder learns to emit these tokens autoregressively alongside text, internalizing alignment knowledge into model weights. This works because NFA alignments are sufficiently accurate and consistent to serve as ground truth for supervised learning.

### Mechanism 2
Discretizing timestamps as vocabulary tokens enables unified text-time modeling with standard decoder architectures. Rather than regressing continuous time values, timestamps are mapped to integer frame indices and added to the tokenizer vocabulary. Each `<|t|>` token maps to exactly one token ID, reducing sequence length compared to multi-digit encoding. The decoder predicts timestamps like any other token, leveraging existing attention over encoder representations to correlate speech frames with output positions.

### Mechanism 3
Cross-lingual word alignments enable timestamp transfer from ASR to AST without explicit AST timestamp supervision. For AST, NFA first aligns source speech with source transcript, then awesome-align maps source words to target translation words. Timestamps from source words are copied to aligned target words, allowing the model to learn which speech frames correspond to translated words even when syntactic reordering occurs.

## Foundational Learning

- **Forced Alignment**: Understanding how NFA produces training targets; given an acoustic model and known transcript, how would you identify which frames correspond to the word "hello"?
- **Autoregressive Decoding with Mixed Modalities**: The model interleaves text tokens and timestamp tokens; in a transformer decoder, what information must the model attend to when predicting `<|42|>` (a timestamp token)?
- **Knowledge Distillation / Teacher-Student Learning**: NFA serves as a teacher whose outputs become training data; if the teacher model produces systematic errors (e.g., late word boundaries), what would you expect in the student model's predictions?

## Architecture Onboarding

- **Component map**: Audio (10ms frames) -> log-mel features -> Encoder (17-layer FastConformer, 512-dim, 2048 proj, 8× downsampling) -> 80ms frame rate representations -> Decoder (17-layer Transformer, 512-dim) -> interleaved text + timestamp tokens
- **Critical path**: 1) Audio → log-mel features (10ms frames) 2) Encoder → downsampled representations (80ms frames) 3) Decoder attends to encoder outputs, prompted by task tokens 4) For `<|timestamp|>` mode: output sequence = `<|t_start|> word1 <|t_end|> <|t_start|> word2 ...`
- **Design tradeoffs**: Frame rate (80ms) vs. precision chosen to match NFA encoder; absolute timestamps vs. duration deltas (absolute proved more learnable); timestamp data ratio (15%) balances timestamp learning against WER regression
- **Failure signatures**: High WER regression (>0.5%) suggests timestamp data ratio too high; low timestamp precision/recall (<50%) indicates NFA alignment issues; AST timestamp errors spike for specific language pairs suggests awesome-align quality problems
- **First 3 experiments**: 1) Baseline validation on LibriSpeech test-other to verify precision/recall ~90% and SD/ED ~50-70ms 2) Ablation on timestamp data ratio (5%, 15%, 30%) to measure tradeoff curve 3) Cross-lingual AST zero-shot test on model trained ONLY on ASR timestamp data

## Open Questions the Paper Calls Out
- How can the significant degradation in translation quality (4.4 BLEU and 2.6 COMET drop) be reduced while maintaining timestamp accuracy in AST tasks?
- What is the optimal modeling strategy for handling non-consecutive word mappings and syntactic reordering during AST timestamp generation?
- Can few-shot learning approaches enable accurate AST timestamping while preserving the high translation quality of the baseline model?
- Why does direct SentencePiece tokenization of timestamps fail compared to special token mapping?

## Limitations
- Dependence on teacher alignment quality limits achievable timestamp accuracy
- AST timestamping challenges with many-to-many word alignments and syntactic reordering
- Significant computational resources required (170M parameter model, 32×A100 GPUs, 30k steps)

## Confidence
- **High Confidence**: ASR timestamp prediction works as described; discretization approach using `<|timestamp|>` tokens is effective; absolute timestamp representation outperforms duration-based approaches
- **Medium Confidence**: AST timestamp transfer mechanism functions across languages; approach outperforms WhisperTimestamped; cross-lingual zero-shot capability works
- **Low Confidence**: Scalability to extremely long utterances (>36 seconds); generalization to languages beyond four tested; robustness to diverse speaking styles

## Next Checks
1. **Teacher Alignment Quality Analysis**: Systematically evaluate NFA alignment errors across different speech conditions to quantify upper bound on achievable timestamp accuracy
2. **Alignment Transfer Robustness**: Analyze awesome-align mapping quality across language pairs with varying syntactic divergence and implement heuristic for many-to-many cases
3. **Resource Efficiency Scaling**: Evaluate performance with limited compute (8×A100, 5k steps) and smaller model variants to document timestamp accuracy vs. training resources tradeoff