---
ver: rpa2
title: 'CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving'
arxiv_id: '2503.08683'
source_url: https://arxiv.org/abs/2503.08683
tags:
- driving
- negotiation
- vehicles
- scenarios
- cooperative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoLMDriver addresses the challenge of autonomous driving in complex
  multi-vehicle interaction scenarios by integrating large language models (LLMs)
  into a cooperative driving framework. It employs an actor-critic-based negotiation
  module that enables vehicles to reach consensus through language-based dialogue,
  guided by a dynamic grouping mechanism to focus communication on relevant collaborators.
---

# CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving

## Quick Facts
- arXiv ID: 2503.08683
- Source URL: https://arxiv.org/abs/2503.08683
- Authors: Changxing Liu; Genjia Liu; Zijun Wang; Jinchang Yang; Siheng Chen
- Reference count: 40
- One-line primary result: CoLMDriver achieves 11% higher driving scores and improved success rates in multi-vehicle interaction scenarios by using LLM-based negotiation with dynamic grouping.

## Executive Summary
CoLMDriver integrates large language models into a cooperative driving framework to address complex multi-vehicle interaction scenarios. The system employs an actor-critic-based negotiation module that enables vehicles to reach consensus through language-based dialogue, guided by a dynamic grouping mechanism that focuses communication on relevant collaborators. By translating negotiation outcomes into executable waypoints using an intention-guided planner, CoLMDriver balances high-level reasoning with real-time control. Evaluated on a newly introduced InterDrive benchmark with 10 challenging scenarios, the system demonstrates superior performance compared to existing methods, particularly in highly interactive vehicle-to-vehicle situations.

## Method Summary
The method consists of three core components: a VLM-based intention planner (InternVL2-4B + LoRA) for initial driving intentions, an LLM-based negotiation module (Qwen2.5-3B) that uses actor-critic feedback to refine cooperative policies, and an intention-guided waypoint planner that translates consensus outcomes into executable trajectories. Dynamic grouping identifies vehicles likely to conflict via spatiotemporal graph analysis, enabling efficient communication. The system operates asynchronously with perception generating object-level 3D info and BEV features, VLM producing initial intentions, LLM negotiator exchanging messages with actor-critic evaluation, and waypoint planner executing via PID control on predicted trajectories.

## Key Results
- CoLMDriver achieves 11% higher driving scores compared to existing methods on InterDrive benchmark
- System demonstrates superior success rates in multi-vehicle interaction scenarios
- Dynamic grouping improves negotiation efficiency without degrading cooperation quality

## Why This Works (Mechanism)

### Mechanism 1: Actor-Critic Negotiation for Consensus Acceleration
The LLM-based negotiator acts as an actor proposing driving intentions while the evaluator acts as a critic scoring consensus quality, safety, and efficiency. Critic feedback is injected into subsequent negotiation rounds as context, enabling in-context policy refinement without weight updates. LLMs interpret structured textual criticism to adjust cooperative behavior within a negotiation session. Evidence shows negotiation quality scores increase steadily with feedback versus random fluctuations without it.

### Mechanism 2: Dynamic Grouping for Scalable Communication
A spatiotemporal vehicle graph connects pairs whose safety scores exceed a threshold, with DFS identifying connected components as negotiation groups. Historical groups merge across time to maintain policy consistency. Only intra-group communication proceeds, improving efficiency. Core assumption is that spatial proximity and trajectory intersection are sufficient proxies for negotiation necessity.

### Mechanism 3: Intention-to-Waypoint Translation for Spatial Execution
The intention-guided waypoint planner receives BEV occupancy/features and high-level intentions (navigation: turn left/right/straight; speed: STOP/SLOWER/KEEP/FASTER). A Transformer decoder cross-attends environmental and guidance contexts to predict waypoint sequences. Training data is augmented via environment-adaptive acceleration interpolation, aligning waypoints with intention categories under varying traffic density.

## Foundational Learning

- **Actor-Critic Methods (RL)**
  - Why needed here: The negotiation module adopts an actor-critic paradigm where evaluator feedback substitutes for reward signals
  - Quick check question: Can you explain how the critic's feedback differs from traditional RL reward signals in this negotiation context?

- **LLM In-Context Learning**
  - Why needed here: Negotiation refinement relies on LLMs adjusting behavior based on critic feedback within the prompt context, not weight updates
  - Quick check question: How does multi-round negotiation context accumulate, and what failure modes emerge when context length is exceeded?

- **Multi-Agent Communication Protocols**
  - Why needed here: Dynamic grouping and V2V communication require understanding how agents establish, maintain, and prune communication graphs under real-time constraints
  - Quick check question: What tradeoffs exist between communication frequency, group size, and negotiation convergence speed?

## Architecture Onboarding

- **Component map**: Perception (LiDAR/camera) → BEV features → VLM intention planner → LLM negotiator (with dynamic grouping + actor-critic) → intention output → intention-guided waypoint planner → PID controller → vehicle actuators

- **Critical path**: Perception generates object-level 3D info and BEV features (shared across pipelines); VLM produces initial intentions; conflict detection triggers negotiation; dynamic grouping identifies negotiation partners; LLM negotiator exchanges messages; critic evaluates waypoints; consensus intentions guide waypoint planner; PID controller executes waypoints

- **Design tradeoffs**: Negotiation depth vs. latency (more rounds improve consensus but delay action); group size vs. scalability (larger groups capture more interactions but increase LLM inference cost quadratically); intention granularity vs. waypoint precision (coarse intentions enable efficient learning but may limit fine-grained maneuvering)

- **Failure signatures**: Dual-yielding deadlock (both vehicles yield indefinitely); consensus oscillation (critic scores fluctuate without convergence); latency-induced staleness (high LLM inference delay causes waypoint planner to operate on outdated intentions)

- **First 3 experiments**:
  1. Ablate critic feedback: Run negotiation with actor-only and compare convergence rate and driving score against full actor-critic
  2. Stress-test dynamic grouping: Inject scenarios with 6-8 conflicting vehicles; measure negotiation success rate and latency scaling
  3. Validate intention-to-waypoint alignment: Train waypoint planner with and without environment-adaptive acceleration augmentation; evaluate waypoint deviation from negotiated intentions

## Open Questions the Paper Calls Out

### Open Question 1
How does the diversity and scale of language interaction demonstrations impact the generalization capability of the negotiation module in unseen traffic scenarios? The authors state in the conclusion that "One current limit is the diversity of language interaction demonstrations," which they aim to expand in future work.

### Open Question 2
Does the dynamic grouping mechanism and multi-round LLM negotiation maintain real-time performance and safety when scaling to dense traffic environments with significantly more agents? The InterDrive benchmark limits the number of interactive vehicles to 2-8, but computational complexity increases with agent density.

### Open Question 3
How robust is the Actor-Critic negotiation protocol against non-cooperative or malicious agents who provide false state information or refuse consensus? The system assumes all agents participate honestly, relying on shared waypoints for the critic's safety score.

## Limitations

- Actor-critic negotiation mechanism's convergence reliability under extended context windows remains untested
- Dynamic grouping's safety score threshold θ is unspecified, making reproducibility uncertain
- Intention-to-waypoint translation assumes 4 discrete speed categories generalize to complex maneuvers without validation

## Confidence

- High: Driving score improvement (11%) and success rate gains over baselines are supported by InterDrive benchmark results
- Medium: Actor-critic feedback mechanism's effectiveness is demonstrated via qualitative consensus score trends but lacks rigorous analysis of convergence under edge cases
- Medium: Dynamic grouping's scalability is claimed via multi-vehicle stress tests but threshold calibration is not specified
- Low: Generalization of intention-to-waypoint mapping to novel scene configurations is assumed from training data augmentation but not empirically validated

## Next Checks

1. Run negotiation ablations with progressively longer context windows (e.g., 8k→32k tokens) to measure performance degradation and identify context overflow failure modes
2. Conduct systematic safety score threshold sweeps (θ = [0.1, 0.3, 0.5, 0.7]) in multi-vehicle scenarios to quantify tradeoffs between negotiation completeness and latency
3. Test intention-to-waypoint planner on out-of-distribution scenarios (e.g., unsignalized 4-way stops, complex merges) and measure waypoint deviation from negotiated intentions and safety violations