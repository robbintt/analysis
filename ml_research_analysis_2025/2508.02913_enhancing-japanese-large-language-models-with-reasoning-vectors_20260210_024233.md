---
ver: rpa2
title: Enhancing Japanese Large Language Models with Reasoning Vectors
arxiv_id: '2508.02913'
source_url: https://arxiv.org/abs/2508.02913
tags:
- japanese
- reasoning
- llms
- arxiv
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that reasoning capabilities can be effectively
  transferred from English LLMs to Japanese models through reasoning vectors. By extracting
  the weight difference between pre-trained and post-trained reasoning models, the
  authors enhanced a Japanese instruction-tuned target model without additional training
  or labeled data.
---

# Enhancing Japanese Large Language Models with Reasoning Vectors

## Quick Facts
- arXiv ID: 2508.02913
- Source URL: https://arxiv.org/abs/2508.02913
- Reference count: 8
- Primary result: Reasoning capabilities can be transferred from English LLMs to Japanese models via reasoning vectors extracted from weight differences

## Executive Summary
This paper introduces a novel approach to enhance Japanese language models by transferring reasoning capabilities from English models using reasoning vectors. The method computes the weight difference between pre-trained and post-trained reasoning models, then adds this vector to a Japanese instruction-tuned model. Experiments on the AIME24 dataset demonstrate consistent performance improvements across different vector weights, with the enhanced model surpassing the original reasoning model at higher weights. This simple approach offers a promising path for boosting under-resourced language models using existing advancements in other languages, though it requires models to share the same architecture and lacks a held-out set for determining optimal vector weights.

## Method Summary
The method computes reasoning vectors by subtracting the weights of a pre-trained model from those of a post-trained reasoning model. These vectors are then added to a target Japanese model with varying scaling factors to enhance reasoning capabilities. The approach requires all models to share identical architecture for element-wise arithmetic operations to work. The scaling factor w controls the interpolation between base capability and reasoning capability, allowing fine-tuning of the transfer effect.

## Key Results
- Reasoning vectors consistently improve Japanese model performance on AIME24 across all tested weights (w=0.25, 0.50, 0.75, 1.00)
- Enhanced model surpasses original reasoning model performance at higher weight values
- Simple weight arithmetic achieves transfer without additional training or labeled data
- Method requires architectural compatibility but works across language boundaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weight differences between pre-trained and post-trained models encode task-specific capabilities that transfer across language boundaries.
- Mechanism: The reasoning vector v = πpost - πpre captures the direction in weight space representing reasoning acquisition. When added to a Japanese model (πenh = πtgt + w * v), this vector shifts the target model's weights toward the reasoning-capable region without requiring gradient updates.
- Core assumption: Reasoning capability is encoded as a learnable direction in parameter space that is at least partially language-agnostic.
- Evidence anchors: [abstract] "Reasoning vectors are computed by subtracting the weights of a pre-trained model from those of a post-trained reasoning model." [Section 3] "The vector represents the direction of post-training in the weight space and adding this vector to the model equips it with post-training knowledge."

### Mechanism 2
- Claim: Scaling weight w controls the interpolation between base capability and reasoning capability.
- Mechanism: Linear scaling w ∈ [0, 1] modulates how strongly the reasoning direction influences the target model. Higher w increases reasoning capacity but may affect language-specific calibration.
- Core assumption: The beneficial reasoning signal scales monotonically while negative interference remains bounded at moderate w values.
- Evidence anchors: [Section 5] "As w increases to 0.50, performance improves further. Notably, for higher values of w, the enhanced model surpasses the original post-trained reasoning model." [Table 1] Shows monotonic improvement from w=0.00 (4 correct) to w=1.00 (10 correct) on Japanese AIME24.

### Mechanism 3
- Claim: Cross-lingual transfer succeeds because shared architecture provides compatible representational substrates.
- Mechanism: All three models (Qwen-32B, s1-32B, EZO) share identical transformer architecture, enabling element-wise arithmetic. Reasoning patterns learned in English weight space occupy regions that also exist in the Japanese model's weight space.
- Core assumption: Architectural identity implies functional compatibility for weight-space operations.
- Evidence anchors: [Section 4.1] "These models were selected because they represent the only set for which we obtained all pre-trained, post-trained, and target models that share the same architecture." [Section 6] "The pre-trained, post-trained, and target models have to follow the same model architecture for element-wise arithmetic operations to work."

## Foundational Learning

- Concept: **Task Arithmetic / Weight-Space Operations**
  - Why needed here: The entire method depends on understanding that model weights can be treated as vectors supporting arithmetic operations (addition, subtraction, scaling).
  - Quick check question: Can you explain why subtracting πpre from πpost might isolate task-specific learning rather than base language capabilities?

- Concept: **Cross-Lingual Transfer in LLMs**
  - Why needed here: The approach transfers reasoning from English-trained models to Japanese models, requiring understanding of what linguistic knowledge is shared vs. language-specific.
  - Quick check question: What types of representations (syntactic, semantic, reasoning) would you expect to transfer more readily across languages?

- Concept: **Post-Training Enhancement (SFT/RL)**
  - Why needed here: The reasoning vector is extracted from s1-32B, which learned reasoning through supervised fine-tuning on reasoning chains.
  - Quick check question: How does post-training on reasoning chains differ from continued pre-training, and what does each contribute to capability?

## Architecture Onboarding

- Component map:
  - Source pre-trained model (πpre): Qwen-32B base weights
  - Source reasoning model (πpost): s1-32B (Qwen-32B + reasoning SFT)
  - Target Japanese model (πtgt): EZO-Qwen2.5-32B-Instruct
  - Reasoning vector (v): Computed as πpost - πpre
  - Enhanced model (πenh): πtgt + w * v

- Critical path:
  1. Verify all three models share identical architecture (layer count, hidden size, attention heads)
  2. Load πpre and πpost weights, compute v = πpost - πpre
  3. Load πtgt, add scaled vector: πenh = πtgt + w * v
  4. Evaluate on target benchmark at multiple w values (0.25, 0.50, 0.75, 1.00)

- Design tradeoffs:
  - Higher w increases reasoning transfer but risks interference with Japanese language capabilities
  - Single benchmark (AIME24) limits generalization claims
  - Grading heuristic (substring match) may over/underestimate true accuracy
  - No held-out set for w selection (noted as limitation)

- Failure signatures:
  - Architecture mismatch: Element-wise operations fail with shape errors
  - Excessive w: Model outputs become incoherent or switch to English
  - Wrong model pairing: Subtracting unrelated models produces noise vector

- First 3 experiments:
  1. Reproduce w sweep on Japanese AIME24 with more evaluation runs to assess variance
  2. Test on additional Japanese benchmarks (e.g., JCommonsenseQA, JP-MMLU) to validate generalization beyond math reasoning
  3. Ablate by extracting vectors from non-reasoning post-trained models to isolate reasoning-specific vs. general instruction-following transfer

## Open Questions the Paper Calls Out
None

## Limitations
- Narrow evaluation scope: Only tested on AIME24 benchmark, limiting generalization claims
- Grading heuristic may overestimate true reasoning capability through substring matching
- No held-out set for selecting optimal vector weight w
- Assumes weight-space directions encoding reasoning are architecture-locked and language-agnostic

## Confidence
- **High**: The basic mechanism of extracting reasoning vectors via weight arithmetic is valid and reproducible given architectural constraints.
- **Medium**: Performance improvements on AIME24 are real and consistent across different weights.
- **Low**: Generalization to other reasoning tasks or superiority over original reasoning models is not well-supported.

## Next Checks
1. **Generalization Test**: Apply the same reasoning vector to EZO on additional Japanese reasoning benchmarks (e.g., JCommonsenseQA, JP-MMLU math subset) to test whether the improvement extends beyond math competition problems.

2. **Vector Ablation Study**: Extract vectors from non-reasoning post-trained models (e.g., general instruction-tuned models) and apply them to EZO to determine whether the observed gains are specific to reasoning vectors or more general post-training directions.

3. **Statistical Robustness Check**: Run the AIME24 evaluation with 5-10 different random seeds and compute confidence intervals for accuracy at each w value to determine if the observed improvements are statistically significant and reproducible.