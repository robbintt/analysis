---
ver: rpa2
title: 'STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity
  Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments'
arxiv_id: '2510.26148'
source_url: https://arxiv.org/abs/2510.26148
tags:
- data
- signal
- processing
- recognition
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: STAR introduces a privacy-preserving, energy-efficient edge AI
  framework for human activity recognition (HAR) using Wi-Fi CSI data. The approach
  integrates a lightweight GRU-based neural network with adaptive signal processing
  (median filtering, Butterworth low-pass filtering, EMD) to reduce computational
  complexity by 33% compared to LSTM while preserving accuracy.
---

# STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments

## Quick Facts
- arXiv ID: 2510.26148
- Source URL: https://arxiv.org/abs/2510.26148
- Reference count: 40
- Primary result: 93.52% average accuracy across 7 activity classes with 33% fewer parameters than LSTM

## Executive Summary
STAR introduces a privacy-preserving, energy-efficient edge AI framework for human activity recognition using Wi-Fi CSI data. The system integrates a lightweight GRU-based neural network with adaptive signal processing to achieve real-time HAR while reducing computational complexity by 33% compared to LSTM models. Implemented on a Rockchip RV1126 with embedded NPU, the framework achieves 93.52% average recognition accuracy across seven activity classes and 99.11% human presence detection with sub-second latency and low power consumption.

## Method Summary
The STAR framework processes CSI data through a multi-stage pipeline: first computing CSI amplitude from complex samples, then applying median filtering to remove impulse noise, followed by 8th-order Butterworth low-pass filtering to attenuate high-frequency interference. The signal undergoes Empirical Mode Decomposition (EMD) to adaptively separate motion signatures from noise, with high-frequency IMFs discarded. The processed data feeds a 3-layer GRU neural network with 97.6k parameters, trained on 200-sample batches with cross-entropy loss. The model is quantized to INT8 precision and deployed on the Rockchip RV1126's NPU, achieving sixfold speed improvements over CPU-only execution while maintaining accuracy.

## Key Results
- 93.52% average recognition accuracy across seven activity classes (lie down, fall, walk, pickup, run, sit down, stand up)
- 99.11% human presence detection accuracy
- 33% reduction in model parameters compared to conventional LSTM models
- 33 MHz processing speed with 8% CPU utilization on NPU, delivering sixfold speed improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-stage signal decomposition isolates human motion signatures from environmental noise and hardware artifacts.
- Mechanism: The pipeline applies median filtering to remove impulse noise, an 8th-order Butterworth low-pass filter to attenuate high-frequency interference, and Empirical Mode Decomposition (EMD) to adaptively decompose the signal into Intrinsic Mode Functions (IMFs), discarding high-frequency noise components while retaining the lower-frequency motion data.
- Core assumption: Human motion primarily manifests in the lower-frequency sub-bands of the CSI amplitude spectrum, separable from high-frequency noise.
- Evidence anchors: [abstract] "multi-stage pre-processing pipeline combining median filtering, 8th-order Butterworth low-pass filtering, and Empirical Mode Decomposition (EMD)"; [section III.A.4] "The removal of high-frequency IMF components allows for the subsequent smoothing of the CSI signal... high-frequency noise is usually located in the first few orders."

### Mechanism 2
- Claim: Gated Recurrent Units (GRUs) provide sufficient temporal feature modeling for HAR with lower computational overhead than LSTMs.
- Mechanism: By utilizing a 3-layer GRU architecture with only two gates (update and reset) instead of the LSTM's three, the model reduces parameter count by 33% (to 97.6k parameters). This structural simplification decreases the arithmetic operations required per inference step while maintaining the ability to capture temporal dependencies in sequential CSI data.
- Core assumption: The temporal dependencies in the target activities (walking, falling, etc.) do not require the full complexity of an LSTM's separate forget and input gates to be modeled accurately.
- Evidence anchors: [abstract] "reducing model parameters by 33% compared to conventional LSTM models while maintaining effective temporal modeling capability"; [section III.B] "By simplifying the LSTM structure and merging three gates... into two gates... the number of parameters and computational complexity are reduced."

### Mechanism 3
- Claim: Hardware-aware quantization offloads computational load to specialized accelerators (NPUs), decoupling inference speed from general-purpose CPU limitations.
- Mechanism: The trained model is converted to INT8 precision and deployed on the Rockchip RV1126's NPU. This reduces memory bandwidth requirements and allows the dedicated hardware to execute the inference, leaving the CPU idle (8% utilization) for pre-processing and system tasks.
- Core assumption: The information loss inherent in INT8 quantization does not significantly degrade the feature boundaries required to distinguish the 7 activity classes.
- Evidence anchors: [abstract] "INT8 quantized inference achieves a processing speed of 33 MHz with just 8% CPU utilization, delivering sixfold speed improvements"; [section IV.D] "Offloading inference to the NPU significantly reduces CPU utilization to just 8%... INT8 quantization... did not compromise accuracy."

## Foundational Learning

- Concept: **Channel State Information (CSI) Amplitude vs. Phase**
  - Why needed here: The system relies entirely on amplitude data ($|A(i)|$) because it is more robust to hardware imperfections (like carrier frequency offset) than phase data, which requires complex unwrapping algorithms.
  - Quick check question: Why does the pipeline discard phase information and focus solely on the magnitude of the complex CSI signal?

- Concept: **Empirical Mode Decomposition (EMD)**
  - Why needed here: Unlike Fourier transforms which use fixed basis functions, EMD is adaptive and data-driven. This is critical for non-linear, non-stationary physiological signals (like walking/running) where frequency characteristics change over time.
  - Quick check question: How does EMD determine which components (IMFs) represent "noise" versus "signal" without a predefined cutoff frequency?

- Concept: **Quantization (FP32 to INT8)**
  - Why needed here: This is the bridge between a training environment (typically PyTorch/FP32) and an efficient edge deployment. Understanding the trade-off is vital: INT8 reduces model size and speeds up inference but can introduce precision errors.
  - Quick check question: If the "fall" detection accuracy (85.22%) is already the lowest class, what is the risk that INT8 quantization might push its confidence score below the decision threshold?

## Architecture Onboarding

- Component map: ESP32-S3 (CSI extraction at 100Hz) -> RV1126 CPU (Vectorized C/NEON pre-processing) -> RV1126 NPU (INT8 GRU model) -> Activity Class

- Critical path:
  - Data Rate: The system must ingest and process CSI data at 100Hz (10ms intervals).
  - Latency Bottleneck: Pre-processing (Filtering + EMD) must happen faster than the inference time to prevent buffer overflow. The paper claims CPU occupancy of 8% and sub-second latency, suggesting the critical path is well-managed.

- Design tradeoffs:
  - GRU vs. LSTM: Chose GRU for speed/size (33% smaller) potentially at the cost of some modeling nuance.
  - EMD vs. Static Filters: EMD is computationally heavier than a static filter but offers better noise adaptation.
  - INT8 vs. FP16: Chose INT8 for 6x speed boost on NPU, accepting potential (though claimed negligible) accuracy loss.

- Failure signatures:
  - Class Confusion: The "Fall" class has significantly lower accuracy (85.22%) compared to others (>90%). This suggests the features for "Fall" might overlap with "Sit down" or "Pickup."
  - Domain Shift: (Inferred from general CSI literature and corpus "maxVSTAR"): If the environment changes (furniture moved), the multipath profile changes. The model may fail if trained only in one room.
  - EMD Latency: If the signal length increases or noise spikes, EMD computation could spike, breaking the real-time constraint.

- First 3 experiments:
  1. Baseline Accuracy Check: Deploy the pre-trained INT8 model on the RV1126 and verify the "Fall" vs. "Sit down" confusion matrix matches the paper's reported 85.22% for falls.
  2. Pre-processing Latency Profile: Instrument the C-code to measure the exact execution time of the EMD step on the CPU to ensure it does not block the 100Hz data stream.
  3. Quantization Sensitivity: Run inference on the same dataset in both FP16 (CPU) and INT8 (NPU) modes to quantify the exact accuracy delta introduced by quantization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does STAR's recognition accuracy degrade in multi-user scenarios where multiple people perform activities simultaneously within the sensing area?
- Basis: [inferred] The introduction claims CSI enables "concurrent multi-user tracking," yet all experiments involve single-person activities in a controlled environment.
- Why unresolved: No multi-user experiments were conducted; the 97.6k-parameter GRU model was trained and evaluated exclusively on single-subject data.
- What evidence would resolve it: Accuracy measurements when 2+ individuals perform activities concurrently, with analysis of interference patterns and per-user recognition rates.

### Open Question 2
- Question: What is the quantitative energy consumption (in watts) during continuous HAR operation, and how does it compare to CPU-only and cloud-based alternatives?
- Basis: [inferred] The paper repeatedly claims "low power consumption" but provides no wattage measurements, battery life estimates, or energy-per-inference metrics.
- Why unresolved: Power consumption is asserted but never measured or reported in quantitative terms.
- What evidence would resolve it: Power draw measurements during sustained operation, joules-per-inference calculations, and comparison with baseline edge implementations.

### Open Question 3
- Question: How well does the trained model generalize to unseen indoor environments with different room layouts, furniture configurations, and multipath characteristics?
- Basis: [inferred] Data was collected in a single "relatively empty room" with fixed transmitter-receiver positioning.
- Why unresolved: No cross-environment validation was performed; the preprocessing pipeline (Butterworth filter cutoff frequencies, EMD decomposition) may be tuned to this specific environment's noise characteristics.
- What evidence would resolve it: Transfer learning experiments or direct evaluation on CSI data collected from diverse indoor environments without model retraining.

### Open Question 4
- Question: Can fall detection accuracy be improved beyond 85.22% given its critical importance for elderly monitoring applications?
- Basis: [inferred] Fall detection showed the lowest accuracy among all seven activity classes, yet fall detection is emphasized as a key healthcare application.
- Why unresolved: The paper does not analyze why falls are misclassified or propose strategies to improve this specific class.
- What evidence would resolve it: Confusion matrix analysis for fall samples, feature importance study, or targeted model modifications with reported accuracy improvements for the fall class.

## Limitations
- Hardware dependency: The claimed 33 MHz NPU performance and 8% CPU utilization are specific to the Rockchip RV1126 platform and may not generalize to other edge devices.
- Dataset specificity: Model performance is tied to the specific CSI environment and activity execution patterns captured during data collection, with no cross-environment validation reported.
- Computational complexity tradeoff: While EMD improves noise adaptation, it introduces additional computational overhead compared to static filtering, potentially limiting scalability for higher sampling rates.

## Confidence
- High Confidence: The core mechanisms of signal denoising (median + Butterworth + EMD) and GRU-based temporal modeling are well-established in CSI-HAR literature and directly supported by the paper's implementation details and quantitative results.
- Medium Confidence: The 33% parameter reduction claim for GRU vs. LSTM is supported, but the specific architectural choices (hidden dimensions, exact parameter count) are partially inferred due to incomplete specification.
- Medium Confidence: INT8 quantization enabling sixfold speed improvement is plausible given NPU capabilities, but the exact accuracy impact (particularly on low-performing "fall" class) requires empirical validation.

## Next Checks
1. Cross-environment testing: Evaluate model performance in a different physical space with altered multipath characteristics to assess domain adaptation needs and potential accuracy degradation.
2. Real-time constraint validation: Instrument the pre-processing pipeline to measure EMD computation time across varying noise conditions, ensuring it remains below the 10ms window required for 100Hz processing.
3. Quantization impact analysis: Conduct ablation testing comparing FP32, FP16, and INT8 model variants on the same test set to quantify the precise accuracy-cost tradeoff for each activity class, especially "fall" detection.