---
ver: rpa2
title: Cooperative Pseudo Labeling for Unsupervised Federated Classification
arxiv_id: '2510.10100'
source_url: https://arxiv.org/abs/2510.10100
tags:
- label
- pseudo
- learning
- federated
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends unsupervised federated learning to classification
  tasks using CLIP. It introduces FedCoPL, which addresses label skew and CLIP bias
  through cooperative pseudo labeling and partial prompt aggregation.
---

# Cooperative Pseudo Labeling for Unsupervised Federated Classification

## Quick Facts
- **arXiv ID**: 2510.10100
- **Source URL**: https://arxiv.org/abs/2510.10100
- **Reference count**: 40
- **One-line primary result**: FedCoPL significantly outperforms baseline methods, achieving up to 17.09% improvement on RESISC45.

## Executive Summary
This paper extends unsupervised federated learning to classification tasks using CLIP. It introduces FedCoPL, which addresses label skew and CLIP bias through cooperative pseudo labeling and partial prompt aggregation. The cooperative pseudo labeling strategy estimates and globally adjusts pseudo label distributions to ensure balanced training, while partial prompt aggregation only aggregates visual prompts to enhance collaboration and preserve personalization. Extensive experiments show FedCoPL significantly outperforms baseline methods, achieving up to 17.09% improvement on RESISC45 and consistently maintaining high accuracy across varying client numbers and participation rates.

## Method Summary
FedCoPL uses CLIP's zero-shot capability to generate pseudo-labels in a federated setting. Clients filter high-confidence, low-entropy predictions to estimate local label distributions, which are sent to the server. The server redistributes pseudo-label quotas to ensure global class balance, then averages visual prompts while keeping text prompts local. Clients train on their allocated pseudo-labels and updated visual prompts. The method addresses non-IID data through cooperative distribution balancing and preserves personalization by only aggregating visual features.

## Key Results
- FedCoPL achieves up to 17.09% improvement on RESISC45 compared to baseline methods
- Consistent performance gains across varying client numbers and participation rates
- Ablation studies confirm both cooperative pseudo labeling and partial prompt aggregation are critical for success

## Why This Works (Mechanism)

### Mechanism 1
Server-side balancing of pseudo-label budgets mitigates global class imbalance caused by local data skew and CLIP's inherent prediction bias. Instead of training on all high-confidence predictions, the server calculates a fixed global budget per class and allocates this budget to clients based on their estimated local class distributions. This forces the collective training set across all clients to approximate a uniform distribution, ensuring all classes are trained adequately even if local data is heavily skewed.

### Mechanism 2
Aggregating only visual prompts while keeping text prompts local resolves parameter conflicts caused by heterogeneous label distributions. The paper posits that visual prompts learn general feature representations (shareable), whereas text prompts learn classification boundaries (personalized/local). By averaging only visual prompts, clients share "how to see" without conflicting on "how to classify" specific local categories.

### Mechanism 3
Dual-criteria filtering (Confidence + Entropy) cleans raw zero-shot predictions enough to serve as a reliable proxy for ground-truth distribution statistics. Before allocation, clients filter data using thresholds to remove ambiguous samples that might otherwise skew the estimated distribution vector, ensuring the server allocates quotas based on "high certainty" local knowledge.

## Foundational Learning

- **Concept: CLIP (Contrastive Language-Image Pre-training)**
  - **Why needed here**: FedCoPL relies on CLIP's zero-shot capability to generate the initial pseudo-labels. You must understand that CLIP aligns images and text in a shared embedding space, allowing classification via cosine similarity without supervised training on the specific dataset.
  - **Quick check question**: How does CLIP classify an image into a category "dog" without a specific classification head trained for "dog"?

- **Concept: Non-IID Data / Label Skew**
  - **Why needed here**: The core problem FedCoPL solves is that Client A might have only cats while Client B has only birds. Standard averaging fails here. You need to grasp why aggregating models trained on different distributions causes divergence.
  - **Quick check question**: If Client A has 90% Class 1 and Client B has 90% Class 2, why might a global model averaged from A and B perform poorly on both?

- **Concept: Prompt Tuning (Visual vs. Text)**
  - **Why needed here**: The method tunes "prompts" (learnable continuous vectors) rather than full model weights.
  - **Quick check question**: What is the difference between "hard prompts" (text) and "soft/visual prompts" (vectors) in the context of this paper's architecture?

## Architecture Onboarding

- **Component map:**
  - Client Side: CLIP Encoders (Frozen) -> Visual/Text Prompts (Trainable) -> Filter Module -> Allocator Logic
  - Server Side: Distribution Aggregator -> Global Allocator -> Prompt Aggregator

- **Critical path:**
  1. **Estimate**: Client runs inference → Filters noise → Calculates local class histogram
  2. **Sync (Up)**: Client sends histogram and visual prompts to server
  3. **Allocate**: Server sums histograms → Calculates per-client quotas ensuring global balance → Averages visual prompts
  4. **Sync (Down)**: Client receives quotas and global visual prompts
  5. **Train**: Client selects top samples per class → Trains visual and text prompts using Cross-Entropy on pseudo-labels

- **Design tradeoffs:**
  - *Partial Aggregation*: Aggregating visual prompts improves generalization but may limit adaptation to local visual domains. Keeping text prompts local aids personalization but prevents knowledge transfer of textual semantics between clients.
  - *Allocation Strategy*: Enforcing a uniform global budget prevents majority class dominance but assumes the server knows the class set a priori and that every client has some data for most classes.

- **Failure signatures:**
  - **Collapse to Majority Class**: If filtering thresholds are too low, noise dominates the estimated distribution, and allocation becomes random.
  - **Empty Quotas**: If filtering thresholds are too high or local data is extremely scarce, the estimated distribution may be zero for many classes, resulting in no training data assigned.
  - **Text Prompt Overfitting**: Without global aggregation of text prompts, clients may overfit their text prompts to the specific noise of their local pseudo-labels.

- **First 3 experiments:**
  1. **Verify Mechanism 1 (Ablation)**: Run FedCoPL with Standard Pseudo Labeling vs. Cooperative Allocation. Check if global accuracy is more balanced across classes.
  2. **Verify Mechanism 2 (Prompt Drift)**: Plot the "Drift Diversity" for visual vs text prompts. Confirm that text prompts indeed have higher variance across clients.
  3. **Hyperparameter Sensitivity**: Sweep confidence and entropy thresholds on a validation set to determine if the default 0.5 heuristic holds or requires aggressive tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What are the formal theoretical guarantees regarding the convergence, fairness, and privacy of FedCoPL?
- **Basis in paper**: The conclusion states, "In future work, we will conduct a theoretical analysis of FedCoPL, including convergence, privacy, fairness, and other pertinent considerations."
- **Why unresolved**: The current work relies solely on empirical validation without providing mathematical proofs for the stability or fairness of the cooperative labeling process.

### Open Question 2
- **Question**: How does the performance of FedCoPL degrade if the global data distribution is long-tailed rather than uniform?
- **Basis in paper**: The cooperative pseudo labeling strategy assumes a "uniform joint label distribution across all clients" to allocate equal pseudo-labels per class globally.
- **Why unresolved**: Real-world federated data is often globally imbalanced; enforcing a uniform allocation on a long-tailed distribution may introduce noise or suboptimal learning for tail classes.

### Open Question 3
- **Question**: Can the uploaded estimated pseudo-label distributions leak sensitive information about client data despite the proposed privacy claims?
- **Basis in paper**: The paper claims privacy preservation because uploaded distributions are derived from CLIP predictions, yet statistical aggregates can still be vulnerable to inference attacks.
- **Why unresolved**: The claim that it is "infeasible" to infer exact label distributions is asserted without a rigorous security analysis or robustness testing against attribute inference attacks.

## Limitations
- The method assumes clients have some data for most classes or relies on false positives when estimating local distributions
- Optimal prompt architecture details (shallow vs deep integration) are underspecified, creating ambiguity for reproduction
- The claim that visual prompts can be globally shared while text prompts must remain local lacks external validation from the corpus

## Confidence
- **High confidence**: Core mechanism descriptions are clearly articulated and align with established UFL and CLIP literature
- **Medium confidence**: Empirical superiority claims depend heavily on quality of CLIP's zero-shot predictions and chosen hyperparameters
- **Low confidence**: Assumption that visual prompts can be globally shared while text prompts must remain local is asserted via internal analysis but lacks external validation

## Next Checks
1. Run an ablation study comparing FedCoPL's cooperative allocation against standard local pseudo-labeling to confirm global accuracy balance
2. Replicate the "Drift Diversity" analysis to verify that visual prompts indeed have lower inter-client variance than text prompts
3. Perform a hyperparameter sweep on confidence and entropy thresholds to determine if the default 0.5 threshold is robust or dataset-dependent