---
ver: rpa2
title: 'Learning quadratic neural networks in high dimensions: SGD dynamics and scaling
  laws'
arxiv_id: '2508.03688'
source_url: https://arxiv.org/abs/2508.03688
tags:
- have
- proposition
- where
- learning
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the optimization and sample complexity of gradient-based
  training for a two-layer neural network with quadratic activation in the high-dimensional
  regime. The authors analyze both population gradient flow and its online stochastic
  gradient descent (SGD) discretization, deriving scaling laws that highlight power-law
  dependencies on optimization time, sample size, and model width.
---

# Learning quadratic neural networks in high dimensions: SGD dynamics and scaling laws

## Quick Facts
- **arXiv ID:** 2508.03688
- **Source URL:** https://arxiv.org/abs/2508.03688
- **Reference count:** 40
- **Primary result:** Derives scaling laws for optimization and sample complexity of quadratic neural networks in high dimensions, showing power-law dependencies on time, sample size, and width.

## Executive Summary
This paper analyzes the optimization dynamics and sample complexity of training a two-layer neural network with quadratic activation in the high-dimensional regime. The authors study both population gradient flow and online stochastic gradient descent (SGD), deriving precise scaling laws that reveal how risk decays with optimization time and how sample complexity scales with model dimensions. The analysis combines tools from high-dimensional probability, matrix analysis, and optimization theory to establish convergence guarantees for the infinite-dimensional effective dynamics. The key insight is that orthogonal signal directions are recovered sequentially with learning timescales determined by the spectral decay of teacher coefficients, leading to smooth power-law risk decay.

## Method Summary
The method involves training a student neural network to learn a quadratic teacher network through online SGD on the Stiefel manifold. The process consists of two phases: first, feature learning via Riemannian gradient descent on the Stiefel manifold to recover the subspace spanned by teacher features, followed by least-squares fine-tuning to fit the radial components. The analysis derives scaling laws by bounding the high-dimensional dynamics through comparison with decoupled diagonal systems using matrix Riccati monotonicity arguments. For the online SGD case, the authors develop novel operator norm concentration bounds to handle the extensive-width regime where standard Frobenius norm bounds become vacuous.

## Key Results
- Population risk follows a smooth power law $t^{-2\alpha-1}$ due to sequential recovery of orthogonal signal directions
- Online SGD achieves the same scaling laws as population gradient flow with optimal sample complexity up to polylogarithmic factors
- In the extensive-width regime ($r \asymp d^\beta$), operator norm bounds are necessary for tight error control, unlike standard Frobenius norm approaches
- The learning timescale for each feature depends on its corresponding teacher coefficient's spectral decay exponent

## Why This Works (Mechanism)

### Mechanism 1: Sequential Feature Recovery via Power-Law Superposition
The population risk decays according to a smooth power law because the network recovers orthogonal signal directions sequentially, with learning timescales determined by the signal strength coefficients ($\lambda_j \asymp j^{-\alpha}$). The target function acts as an additive model of single-index tasks, and the quadratic activation creates a plateau (length $\sim \log d$) for each feature. Stronger signals break symmetry earlier, resulting in the observed smooth power-law scaling.

### Mechanism 2: Matrix Riccati Monotonicity and Comparison
The high-dimensional dynamics can be tightly bounded by comparing the system to decoupled diagonal systems using the Loewner order. The dynamics of the alignment Gram matrix $G(t)$ follow a Matrix Riccati ODE, and while the trajectory is not necessarily monotone in time, it is monotone with respect to its initialization. By constructing diagonal bounding systems that sandwich the true high-dimensional random initialization, the authors derive deterministic limits for the risk.

### Mechanism 3: Discrete-Time Stiefel SGD via Operator Norm Control
Online SGD on the Stiefel manifold achieves continuous-time scaling laws if discretization error is controlled via operator norm rather than Frobenius norm. In the extensive-width regime, standard Frobenius norm bounds accumulate excessive dimension-dependent error. The authors construct a matrix-monotone comparison framework for discrete time using an auxiliary map that matches SGD up to second-order terms while preserving matrix order.

## Foundational Learning

- **Concept: Hermite Polynomials / Quadratic Activation**
  - Why needed here: The paper analyzes a specific teacher-student setup where $\sigma(z) = z^2 - 1$ (2nd Hermite polynomial). Understanding this link explains why there is a saddle point and a $\log d$ plateau length.
  - Quick check question: Why does a quadratic activation function specifically lead to a "search phase" of length $\log d$ in high dimensions?

- **Concept: Student-Teacher Setup**
  - Why needed here: The entire analysis relies on measuring the "alignment" between the student's learned weights and the teacher's true orthonormal directions. The risk is defined as the distance between the student and teacher weight matrices.
  - Quick check question: How is the "alignment" of the student network quantified relative to the $j$-th teacher feature $\theta_j$?

- **Concept: Power Law Scaling**
  - Why needed here: The primary output is a set of scaling laws where Risk $\sim t^{-2\alpha-1}$. Understanding power laws is necessary to interpret the connection between the spectral decay of teacher coefficients and the convergence rate.
  - Quick check question: How does the decay rate $\alpha$ of the second-layer coefficients $\lambda_j$ affect the asymptotic risk curve?

## Architecture Onboarding

- **Component map:** Isotropic Gaussian data -> Teacher network (orthonormal features, power-law coefficients) -> Student network (quadratic activation) -> Online SGD on Stiefel manifold -> Least-squares fine-tuning

- **Critical path:**
  1. **Initialization:** Weights on Stiefel manifold
  2. **Feature Learning Phase:** Online SGD updates via Riemannian gradient to recover the subspace spanned by teacher features
  3. **Alignment:** Sequential recovery of features based on signal strength (Plateau -> Descent)
  4. **Fine-tuning:** Least-squares step to fit the radial components (norms) of the weights

- **Design tradeoffs:**
  - **Stiefel vs. Euclidean Gradient:** The paper uses a Stiefel (manifold) gradient for the main analysis to isolate directional learning, requiring a separate fine-tuning step for radial components
  - **Extensive-width ($r \asymp d^\beta$) vs. Finite-width:** The "extensive" assumption necessitates complex operator norm analysis but yields scaling laws relevant to large models

- **Failure signatures:**
  - **Infinite Plateau:** If learning rate $\eta$ is smaller than $1/d$, the time to escape the saddle point grows super-polynomially
  - **Dimension Explosion:** If using Frobenius norms for error bounds in the extensive-width regime, theoretical bounds become vacuous

- **First 3 experiments:**
  1. **Verify Scaling Exponents:** Train with different decay exponents $\alpha \in \{0.5, 1.0, 1.5\}$ and plot risk vs. compute to check if log-log slope matches $1-2\alpha$
  2. **Sequential Alignment Visualization:** Plot alignment $A(t, \theta_j)$ for several indices $j$ over time to verify strong features "turn on" earlier
  3. **Sample Complexity Test:** Vary sample size $n$ and dimension $d$ to verify transition between "heavy-tailed" ($n \sim dr^{1+\alpha}$) and "light-tailed" ($n \sim d \cdot \text{polylog}(d)$) regimes

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is the optimal sample complexity for learning extensive-width quadratic networks in the intermediate heavy-tailed regime ($\alpha \in (0, 1/2)$) exactly $T \simeq dr$?
- **Basis in paper:** [explicit] Remark 4 states that the current bound is suboptimal by a factor of $r^\alpha$ and explicitly conjectures the optimal complexity is $T \simeq dr$.
- **Why unresolved:** Current proof techniques yield a bound involving an extra factor of $r^\alpha$, but authors believe the information-theoretic limit matches the isotropic case.
- **What evidence would resolve it:** A proof of an upper bound of $n \simeq dr \cdot \text{polylog}(d)$ for the SGD algorithm in this specific decay regime.

### Open Question 2
- **Question:** Can the derived scaling laws for prediction risk be achieved using standard Euclidean gradient descent without the two-stage Stiefel manifold training procedure?
- **Basis in paper:** [explicit] Remark 3 notes that stage-wise training was used to simplify analysis and states "We conjecture that a standard Euclidean discretization of (GF) can also achieve the same risk scaling."
- **Why unresolved:** The theoretical analysis relies on the specific structure of Stiefel manifold updates to handle discretization errors and noise.
- **What evidence would resolve it:** A proof of convergence for online SGD using standard Euclidean updates under the same scaling regime, or a failure case showing divergent behavior.

### Open Question 3
- **Question:** Does the SGD risk trajectory for neural networks with general activations (e.g., ReLU, GeLU) exhibit a "multi-phase" risk curve consisting of an initial linear drop followed by the power-law decay described for the quadratic component?
- **Basis in paper:** [explicit] Section 6 (Conclusion) identifies understanding the "multi-phase learning dynamics" for $k=1$ activations as an "interesting challenge for future work."
- **Why unresolved:** Current analysis is restricted to quadratic activation ($k=2$) to leverage Matrix Riccati ODE structure; $k=1$ activations lack this specific closed-form solution.
- **What evidence would resolve it:** A rigorous characterization of the risk trajectory for $k=1$ activations, showing distinct phases corresponding to learning of different Hermite components.

## Limitations
- Results are confined to quadratic activation functions and may not extend to other activation types, particularly for higher information exponents where Riccati-based comparison breaks down
- The extensive-width assumption ($r \asymp d^\beta$) requires specific sample complexity scaling that may not hold in practical finite-width scenarios
- The separation between directional learning (Stiefel phase) and radial fitting (least-squares phase) is an idealization that may not cleanly manifest in implementations using standard SGD

## Confidence
- **High confidence:** The power-law scaling of population risk with exponent $1-2\alpha$ is well-supported by the theoretical framework and Theorem 1
- **Medium confidence:** The sample complexity bounds for online SGD are sound within the extensive-width regime but may be conservative for practical settings
- **Low confidence:** The practical relevance of the two-phase optimization procedure to standard training procedures remains uncertain

## Next Checks
1. **Scaling Law Verification:** Implement training across different decay exponents $\alpha$ and empirically verify the predicted log-log slope of the risk decay curve
2. **Sequential Alignment Visualization:** Plot alignment trajectories for multiple feature indices to confirm the sequential "on/off" behavior predicted by the alignment function $A(t, \theta_j)$
3. **Sample Complexity Testing:** Systematically vary sample size $n$ relative to model dimensions to empirically identify the transition between heavy-tailed ($n \sim dr^{1+\alpha}$) and light-tailed ($n \sim d \cdot \text{polylog}(d)$) regimes