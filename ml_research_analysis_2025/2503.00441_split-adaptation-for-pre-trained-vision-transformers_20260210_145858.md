---
ver: rpa2
title: Split Adaptation for Pre-trained Vision Transformers
arxiv_id: '2503.00441'
source_url: https://arxiv.org/abs/2503.00441
tags:
- data
- client
- adaptation
- frontend
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Split Adaptation (SA), a method designed
  to adapt pre-trained Vision Transformers (ViTs) to downstream tasks while protecting
  both the model and data. SA divides the ViT into a frontend and backend, sharing
  only a quantized frontend with the client.
---

# Split Adaptation for Pre-trained Vision Transformers

## Quick Facts
- arXiv ID: 2503.00441
- Source URL: https://arxiv.org/abs/2503.00441
- Reference count: 40
- One-line primary result: Split Adaptation (SA) outperforms state-of-the-art methods in few-shot adaptation while protecting model IP and client data.

## Executive Summary
This paper introduces Split Adaptation (SA), a method designed to adapt pre-trained Vision Transformers (ViTs) to downstream tasks while protecting both the model and data. SA divides the ViT into a frontend and backend, sharing only a quantized frontend with the client. To safeguard data, the client adds noise at two levels—model and representation—while the server employs data- and model-level out-of-distribution enhancements to counteract the noise's impact. SA focuses on few-shot adaptation and incorporates patch retrieval augmentation to alleviate overfitting. Extensive experiments across multiple datasets demonstrate SA's superior performance over state-of-the-art methods, effective defense against data reconstruction attacks, and minimal computational cost on the client side.

## Method Summary
Split Adaptation (SA) is a client-server framework for few-shot adaptation of pre-trained ViTs. The server splits a pre-trained ViT into a frontend (first 2/3 layers) and backend (remaining layers), quantizes the frontend to 8-bit using a Hessian-guided metric, and performs OOD quantization-aware tuning on the backend using Hilbert Transform augmented data. The client receives the quantized frontend, injects bi-level noise (Gaussian on model weights, Laplace on representations), and performs patch retrieval augmentation before sending representations to the server. The server dequantizes representations and tunes the backend and task head. This design protects model IP through quantization, defends against data reconstruction attacks through noise injection, and enables efficient few-shot adaptation.

## Key Results
- SA achieves superior performance over baselines in 3/5/10-shot adaptation across CIFAR-100, Places365, and DomainNet-Clipart.
- SA effectively defends against data reconstruction attacks, significantly reducing reconstruction quality (SSIM from 0.80 to 0.23 on CIFAR-100).
- Client-side computation is minimal, with GPU memory and training time orders of magnitude lower than full model training.

## Why This Works (Mechanism)

### Mechanism 1: Low-bit quantization of the frontend provides model IP protection
The frontend's full-precision weights are converted to low-bit integers (e.g., 8-bit) using a Hessian-guided metric to find optimal scaling factors. This degrades the standalone performance of the quantized frontend, discouraging theft, while preserving sufficient semantic information for adaptation when combined with a tuned backend. The evidence shows that using the quantized frontend alone or with an auxiliary backend yields substantially lower performance than the full SA method.

### Mechanism 2: Bi-level noise injection defends against data reconstruction attacks
The client adds Gaussian noise to the frontend's weights (model-level) and Laplace noise to the extracted representations (representation-level) before sending them to the server. This noise acts as an obfuscation layer, degrading the quality of reconstructed images. The paper empirically shows that the combined effect of these two noise types is synergistic, resulting in reconstructed images with lower PSNR and higher LPIPS compared to using a single noise type.

### Mechanism 3: Out-of-distribution data and model augmentation enable generalization
The server uses Hilbert Transform-based data augmentation to generate OOD samples from its own dataset. It then performs quantization-aware tuning of the backend using a representation-mixup strategy with these OOD samples. This process conditions the backend to be more robust to the distribution shifts caused by quantization and noise. The paper shows that removing this component hurts performance, especially on the DomainNet dataset.

## Foundational Learning

- **Vision Transformer (ViT) Architecture**: Understanding its patch-based processing, multi-head self-attention (MSA), and layer structure is essential to grasp how the model is split into a frontend and backend.
  - Quick check: How does a ViT process an input image into a sequence of tokens for its transformer layers?

- **Split Learning (SL)**: Understanding the basic SL setup, where a model is split between client and server, is necessary to see how SA modifies it for privacy and efficiency.
  - Quick check: In a standard SL setup, what is shared between the client and the server instead of raw data?

- **Data Reconstruction Attacks (DRA)**: Knowing that an attacker can invert intermediate representations to recover input data is key to understanding why SA's defense mechanisms (quantization, noise) are needed.
  - Quick check: What is the goal of a data reconstruction attack against a split learning model?

## Architecture Onboarding

- **Component map**:
  - Server Side: Pre-trained ViT (split into Frontend and Backend) -> OOD Enhanced Quantization Module (applies Hilbert Transform and quantizes Frontend) -> OOD Quantization-aware Tuning Module (tunes Backend using representation mixup)
  - Client Side: Bi-level Noise Injection (adds Gaussian noise to frontend weights and Laplace noise to representations) -> Patch Retrieval Augmentation (generates diverse representations) -> Noisy Quantized Frontend (client's executable module)

- **Critical path**:
  1. Server splits ViT, performs OOD quantization, and sends the quantized frontend to the client.
  2. Client injects model-level noise into the frontend and extracts representations.
  3. Client performs patch retrieval augmentation and adds representation-level noise.
  4. Server dequantizes representations, performs final adaptation on the backend and task head.
  5. Client computes loss and returns it to the server.

- **Design tradeoffs**:
  - Noise Level: Higher noise improves data privacy but degrades adaptation performance (Figure 4 shows a trade-off curve).
  - Quantization Bit-width: Lower bits increase IP protection and reduce computation but may lose more information.
  - Split Point: The paper splits at the 2/3 layer mark. Moving the split earlier reduces client computation but may send less abstract representations, potentially affecting privacy and performance.

- **Failure signatures**:
  - High Client Computation: If the split point is too late or the client is performing full model training, the design goal of minimal client cost is violated.
  - Poor Adaptation Performance: If adaptation accuracy is significantly worse than standard split learning or linear probing, it suggests the noise is too high, the backend tuning is insufficient, or the patch augmentation is failing.
  - Successful DRA: If a standard attack (like FORA) reconstructs high-quality images, the bi-level noise defense has failed.

- **First 3 experiments**:
  1. Ablation on OOD Tuning: Train SA with and without the OOD quantization-aware tuning (e.g., "SA w/o OOD QAT" from Table 4) to confirm its impact on cross-distribution adaptation.
  2. Noise Trade-off Analysis: Replicate the experiment from Figure 4/C.1 by varying the Laplace noise degree and plotting the trade-off between adaptation accuracy and reconstruction quality (PSNR/SSIM).
  3. Baselines Comparison: Compare SA against Split Learning and Linear Probing on a few-shot task (e.g., 5-shot CIFAR-100) to validate the stated performance superiority and privacy benefits.

## Open Questions the Paper Calls Out

### Open Question 1
How can Split Adaptation be modified to support architectures with window-based attention mechanisms, such as Swin Transformers, where patch sequences are inconsistent?
- Basis in paper: Appendix B states that due to the "window sliding mechanism" in Swin-L, the patch sequence is uncertain, rendering the patch retrieval augmentation "inapplicable."
- Why unresolved: The current patch retrieval augmentation relies on fixed positional indices to replace patches with retrieved neighbors, a dependency broken by the shifting windows of Swin Transformers.
- What evidence would resolve it: A modified retrieval mechanism that operates within local windows or aligns patches across layers, demonstrated by successful adaptation results on Swin Transformer backbones.

### Open Question 2
Can the Split Adaptation framework be effectively extended to dense prediction tasks like semantic segmentation or object detection?
- Basis in paper: The paper restricts experiments to image classification, despite the Introduction citing semantic segmentation as a primary application for pre-trained ViTs.
- Why unresolved: The patch retrieval augmentation and noise injection strategies may disrupt the spatial coherence required for dense pixel-wise prediction, and the effect of the frontend-backend split on localization features is untested.
- What evidence would resolve it: Experimental results applying SA to downstream segmentation or detection datasets (e.g., ADE20K or COCO) with analysis on localization accuracy.

### Open Question 3
What is the trade-off between the number of augmented representations ($N_{Aug}$) and communication efficiency in non-few-shot scenarios?
- Basis in paper: Section 3.5 generates $N_{Aug}$ representations per image to alleviate overfitting in few-shot settings, but this linearly increases the data sent to the server.
- Why unresolved: While effective for small $N_C$ (few-shot), this augmentation strategy may become a communication bottleneck if $N_C$ (client dataset size) is large, potentially negating the efficiency benefits of the split learning approach.
- What evidence would resolve it: Analysis of communication costs and performance scaling as the client dataset size increases from few-shot to standard supervised learning scales.

## Limitations
- The paper lacks public code and provides ambiguous implementation details, particularly around the FORA attack adaptation for ViTs and the label protection mechanism.
- The method's effectiveness is limited to few-shot scenarios and may not scale efficiently to larger client datasets due to the communication overhead of augmented representations.
- The assumption that Hilbert Transform captures generalizable semantics for OOD augmentation may not hold for all possible domain shifts.

## Confidence
- **High Confidence**: The core mechanism of splitting the ViT into frontend and backend for IP protection and the basic structure of bi-level noise injection are well-defined and supported by the paper's results.
- **Medium Confidence**: The effectiveness of the OOD quantization-aware tuning and the patch retrieval augmentation are supported by ablation studies, but the exact implementation details and the generalizability of these components are less clear.
- **Low Confidence**: The robustness of the bi-level noise defense against advanced data reconstruction attacks and the scalability of the method to very different client data domains are uncertain due to the lack of details on the attack adaptation and the domain coverage of the OOD augmentation.

## Next Checks
1. Replicate FORA Attack Adaptation: Implement the FORA attack on ViT intermediate representations using the described inverse decoder architecture. Validate the reconstruction quality (PSNR, SSIM) on clean representations before and after SA's bi-level noise injection to confirm the claimed defense effectiveness.
2. Verify Label Protection Mechanism: Design a test to confirm that the server cannot infer client labels from the task module outputs it receives. This could involve checking if the task module gradients or outputs contain any information that could be used to reconstruct the labels.
3. Test Scalability Across Domain Shifts: Evaluate SA on a client dataset that is significantly different from ImageNet (e.g., medical images or satellite imagery). Assess whether the OOD augmentation and backend tuning are sufficient to handle such a large domain gap, or if the performance degrades substantially.