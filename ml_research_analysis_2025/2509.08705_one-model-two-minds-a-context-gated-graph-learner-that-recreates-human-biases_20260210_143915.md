---
ver: rpa2
title: 'One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases'
arxiv_id: '2509.08705'
source_url: https://arxiv.org/abs/2509.08705
tags:
- system
- cognitive
- context
- reasoning
- basket
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents OM2M, a context-gated dual-process neural architecture
  for Theory of Mind reasoning that integrates fast, habitual graph-based inference
  with slower, meta-adaptive belief revision. The model uses a learned gating mechanism
  to dynamically balance System 1 (GCN) and System 2 (meta-MLP) outputs based on contextual
  cues such as cognitive load, framing, and ambiguity.
---

# One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases

## Quick Facts
- arXiv ID: 2509.08705
- Source URL: https://arxiv.org/abs/2509.08705
- Authors: Shalima Binta Manir; Tim Oates
- Reference count: 40
- Primary result: OM2M achieves 90% accuracy on held-out false-belief tasks vs 30-50% for baselines while autonomously reproducing human cognitive biases

## Executive Summary
This paper introduces OM2M, a neural architecture for Theory of Mind reasoning that integrates fast, habitual graph-based inference with slower, meta-adaptive belief revision. The model uses a learned gating mechanism to dynamically balance System 1 (GCN) and System 2 (meta-MLP) outputs based on contextual cues like cognitive load and ambiguity. Experiments demonstrate robust generalization on false-belief tasks and the model's capacity to reproduce human-like cognitive biases including anchoring, priming, cognitive fatigue, and framing effects.

## Method Summary
OM2M uses a dual-process architecture where System 1 (GCN) performs habitual relational reasoning over agent-object-location graphs, while System 2 (MLP meta-controller) predicts parameter deltas for rapid adaptation. A context-sensitive gating network blends these outputs based on environmental cues. The model is trained in two phases: first pretraining the GCN on canonical contexts, then freezing it to train the meta-controller and gate on diverse scenarios. This enables the model to generalize to unseen contexts and reproduce cognitive biases through dynamic arbitration between fast and slow reasoning modes.

## Key Results
- 90% accuracy on held-out 3-bit context combinations vs 30-50% for ablated baselines
- Autonomous reproduction of anchoring bias: belief shift from 0.01 to 1.00 under contradiction
- Cognitive fatigue simulation: accuracy drops from 89% to 3% as gate suppresses System 2 under high load
- Priming effect: one-shot belief override through meta-vector modification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dynamic arbitration between habitual and deliberative reasoning enables context-appropriate belief inference
- **Mechanism:** A learned gating network monitors contextual cues and produces scalar g ∈ (0,1) that blends System 1 and System 2 outputs via convex combination
- **Core assumption:** Contextual features reliably signal when habitual inference is insufficient and deliberation is required
- **Evidence anchors:** Abstract states "Our model dynamically balances intuitive and deliberative reasoning through a learned context gate mechanism"; methodology section describes flexible shift between habit and deliberation
- **Break condition:** If contextual cues are uninformative or adversarially manipulated, the gate may fail to recruit System 2 when needed

### Mechanism 2
- **Claim:** Meta-adaptive parameter modification enables rapid belief revision without full retraining
- **Mechanism:** System 2 receives GCN output logits, flattened GCN parameters, and context vectors, then predicts parameter delta applied via functional parameter injection
- **Core assumption:** Single gradient-based parameter update suffices to correct habitual errors in novel contexts
- **Evidence anchors:** Methodology describes controller predicting "delta" update for GCN parameters; results show meta-controller loss reduction from 3.65 to <0.001
- **Break condition:** If novel contexts require multi-step reasoning beyond single-update capacity, System 2 adaptation will be insufficient

### Mechanism 3
- **Claim:** Structured graph representations with agent-specific meta-vectors enable compositional generalization
- **Mechanism:** Social scenarios encoded as graphs with nodes (agents, objects, locations) and edges (relations); agent-specific meta-vectors concatenate with GCN outputs
- **Core assumption:** ToM reasoning can be reduced to relational graph inference over agent-object-location structures
- **Evidence anchors:** Results show "No Meta" variant drops accuracy from 90% to 50%; methodology describes meta-vectors reflecting persistent beliefs
- **Break condition:** If scenarios require reasoning beyond encoded relations (e.g., temporal dynamics), static graph representation will fail

## Foundational Learning

- **Graph Convolutional Networks (GCNs)**
  - Why needed here: System 1 implements habitual reasoning via GCN over relational graphs encoding agents, objects, and locations
  - Quick check question: Can you explain how message passing in a GCN aggregates neighbor features to update node representations?

- **Meta-Learning (MAML-style gradient-based adaptation)**
  - Why needed here: System 2 uses meta-learning to predict parameter deltas for rapid context-sensitive adaptation without retraining
  - Quick check question: How does model-agnostic meta-learning (MAML) enable fast adaptation to new tasks with limited gradient steps?

- **Dual-Process Theory (System 1/System 2)**
  - Why needed here: The entire architecture operationalizes Kahneman's dual-process framework—understanding fast/slow reasoning tradeoffs is essential
  - Quick check question: What cognitive biases emerge when System 1 dominates, and how does System 2 correct them?

## Architecture Onboarding

- **Component map:** Relational graph → System 1 (GCN + meta-vectors) → System 2 (MLP meta-controller) → Context Gate → Output blend
- **Critical path:** Pretrain System 1 on canonical contexts → Freeze System 1 → Train System 2 + gating on diverse scenarios → At inference, gate blends outputs based on context
- **Design tradeoffs:** Speed vs. flexibility (System 1 fast but rigid; System 2 enables adaptation but adds overhead); interpretability (gate values provide reasoning-effort signals); generalization (meta-vectors improve held-out performance but add parameters)
- **Failure signatures:** System 1 only shows high training accuracy but near-chance on unseen contexts; gate stuck at extremes indicates context features aren't informative; sharp accuracy collapse under load (>80% drop) indicates premature System 2 suppression
- **First 3 experiments:** (1) False-belief generalization: train on 7/8 context combinations, test on held-out (expect System 1 ~chance, full model ~90%); (2) Anchoring bias: conflicting evidence after canonical training (measure gate shift 0.20→0.73, belief correction P(Basket): 0.01→1.00); (3) Cognitive load sensitivity: vary load scalar at test time (confirm gate drops 0.28→0.02, accuracy collapses 89%→3%)

## Open Questions the Paper Calls Out

- **Can OM2M's dual-process architecture scale to dynamic, real-world multi-agent settings beyond the simplified Sally-Anne paradigm?**
  - Basis: Explicit statement about future work extending to dynamic multi-agent settings
  - Why unresolved: Experiments use only 3-bit context vectors, binary location choices, and single false-belief scenarios
  - What evidence would resolve it: Demonstrating robust performance on complex multi-agent environments with more agents, longer temporal horizons, and richer state spaces

- **How quantitatively does OM2M's bias reproduction align with human behavioral data?**
  - Basis: Results show qualitative parallels but no direct statistical comparison to human subject data
  - Why unresolved: Model validation relies on internal consistency rather than empirical human benchmarking
  - What evidence would resolve it: Correlation analysis between model and human responses across standardized bias experiments

- **What determines the gate's threshold for engaging System 2, and can it be trained to be more robust under extreme cognitive load?**
  - Basis: Gate values shift from 0.28 to 0.02 under load causing accuracy collapse, but learning dynamics aren't analyzed
  - Why unresolved: Paper demonstrates effect but doesn't probe whether gate robustness can be improved
  - What evidence would resolve it: Ablation studies varying gate architecture or training curricula with gradual load increases

## Limitations

- Reliance on synthetic ToM scenarios rather than real human behavioral data for bias validation
- Dual-process framework may oversimplify human cognition, particularly for complex social reasoning requiring multiple recursive belief layers
- Cognitive fatigue mechanism depends on load-sensitive gating that hasn't been validated against human performance degradation patterns

## Confidence

- **High confidence:** Architectural mechanisms (GCN for relational encoding, meta-learning for rapid adaptation, context gating for dynamic arbitration) are well-specified and empirically validated
- **Medium confidence:** Bias reproduction claims are mechanistically plausible but rely on specific parameter settings and training procedures not fully detailed
- **Low confidence:** Priming mechanism description is incomplete—only conceptual implementation provided without architectural details

## Next Checks

1. **Human benchmark comparison:** Test same bias protocols (anchoring, priming, framing, cognitive fatigue) on human subjects and compare belief shift magnitudes and gate activation patterns to model's behavior

2. **Multi-step reasoning validation:** Evaluate model on ToM tasks requiring recursive belief attribution to test whether graph representation and meta-adaptation scale beyond simple false-belief scenarios

3. **Adversarial context testing:** Systematically manipulate contextual features (misleading framing, ambiguous load signals) to test whether gating mechanism fails under deceptive or noisy conditions as predicted by break conditions