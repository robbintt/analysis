---
ver: rpa2
title: A data-driven approach to discover and quantify systemic lupus erythematosus
  etiological heterogeneity from electronic health records
arxiv_id: '2501.07206'
source_url: https://arxiv.org/abs/2501.07206
tags:
- data
- sources
- clinical
- signatures
- lupus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a data-driven approach to uncover the latent
  heterogeneity in systemic lupus erythematosus (SLE) using electronic health records
  (EHR). The authors applied Independent Component Analysis (ICA) to discover probabilistic
  independent sources from multimodal, noisy, and irregular EHR data, representing
  latent root causes of SLE.
---

# A data-driven approach to discover and quantify systemic lupus erythematosus etiological heterogeneity from electronic health records

## Quick Facts
- arXiv ID: 2501.07206
- Source URL: https://arxiv.org/abs/2501.07206
- Reference count: 0
- This study presents a data-driven approach to uncover the latent heterogeneity in systemic lupus erythematosus (SLE) using electronic health records (EHR).

## Executive Summary
This paper presents a data-driven approach to uncover the latent heterogeneity in systemic lupus erythematosus (SLE) using electronic health records (EHR). The authors applied Independent Component Analysis (ICA) to discover probabilistic independent sources from multimodal, noisy, and irregular EHR data, representing latent root causes of SLE. These sources were then used as input representations for supervised machine learning models trained to discriminate SLE cases from "near miss" negative records. The method identified 19 predictive sources with high clinical validity, each defining an independent factor of SLE heterogeneity.

## Method Summary
The method generates longitudinal curves from discrete clinical events using modality-specific approaches (RASH for codes, PCHIP for labs, binary curves for meds), samples cross-sections to create a dense matrix, applies fastICA to decompose into mixing matrix (signatures) and source matrix (expressions), and uses these sources as input representations for supervised models. The approach projects labeled patient data into the signature space and trains classifiers (AdaNet, XGBoost, Random Forest, Elastic Net) on the source expressions, enabling richer, more interpretable explanations through SHAP values.

## Key Results
- ICA identified 19 predictive sources with high clinical validity representing independent factors of SLE heterogeneity
- Models using ICA-derived sources achieved slightly lower discrimination (AUROC 0.85-0.89 vs 0.92-0.93) but better calibration than models using original clinical variables
- SHAP explanations based on source representations provided more clinically coherent narratives for individual patient predictions

## Why This Works (Mechanism)

### Mechanism 1
Independent Component Analysis (ICA) can recover latent root causes from observed clinical variables under specific causal assumptions. ICA decomposes the observed data matrix X into mixing matrix A (signatures) and source matrix S (expressions). Each column of A represents how a latent source imprints on clinical variables; each row of S represents how active each source is at a given time point. Under LiNGAM assumptions, these sources correspond to exogenous error terms in the structural equation model. Core assumption: The data generating process follows a Linear Non-Gaussian Acyclic Model where latent causes operate independently and mix linearly to produce observations.

### Mechanism 2
SHAP values computed on ICA-derived sources provide patient-level causal explanations for predictions. Since ICA sources are designed to be independent, SHAP's independence assumption is automatically satisfied for the signatures model. The SHAP value for each source quantifies its marginal contribution to the prediction. Under the causal framework, if a source's SHAP value is positive, it is a root cause of the SLE label; if negative, it is protective. Core assumption: Feature independence holds for ICA sources (which it does by construction), and SHAP values under independence correspond to causal contributions.

### Mechanism 3
Representing patients via latent source expressions trades modest discrimination loss for substantially improved calibration and interpretability. By projecting raw clinical variables onto the signature space, models learn from compressed representations that encode independent causal factors rather than correlated raw features. This reduces overfitting to spurious correlations and forces models to exploit causal paths. Core assumption: The true predictive signal is captured within the discovered sources, and the ICA decomposition preserves this signal adequately.

## Foundational Learning

- **Concept: Independent Component Analysis (ICA)**
  - Why needed here: Core technique for separating mixed signals into statistically independent components. Understanding how ICA recovers sources from linear mixtures is essential for interpreting what signatures represent.
  - Quick check question: If you observe X = AS where A is a mixing matrix and S contains independent sources, what assumptions allow you to recover S from X alone?

- **Concept: Structural Equation Models and Exogenous Error Terms**
  - Why needed here: The paper maps ICA sources to error terms in causal graphs. Understanding this correspondence is critical for interpreting sources as "root causes" rather than just statistical artifacts.
  - Quick check question: In a structural equation Y = f(X, ε), what does the error term ε represent causally, and when can it be interpreted as a root cause?

- **Concept: SHAP Values and Feature Independence**
  - Why needed here: SHAP explanations assume feature independence for computational tractability. The paper exploits that ICA sources satisfy this by design, making explanations more trustworthy.
  - Quick check question: Why does SHAP's independence assumption cause problems when features are correlated, and how does ICA transformation address this?

## Architecture Onboarding

- **Component map:** Data extraction -> Curve generation -> Sampling -> ICA decomposition -> Projection -> Supervised learning -> Explanation
- **Critical path:** Curve generation → Matrix construction → ICA decomposition → Source projection → Model training → SHAP explanation. Errors in curve generation propagate through everything; ICA quality determines downstream interpretability.
- **Design tradeoffs:** Number of sources (k=2000): Limited by RAM; too few sources may mix error terms, too many increases computation. Sampling density: More cross-sections improve ICA stability but increase memory footprint. Model architecture: Linear models (AdaNet) offer oracle property for feature selection; non-linear (XGBoost) may capture residual structure but less interpretable.
- **Failure signatures:** Sources with no clear clinical interpretation during face validity review. Large gap between training and test AUROC suggesting overfitting to sources. SHAP explanations dominated by single source (potential mixing artifact). Calibration curves showing systematic over/under-confidence.
- **First 3 experiments:**
  1. **Reproducibility check:** Run ICA with different random seeds; measure correlation of recovered sources across runs. High variability suggests unstable decomposition.
  2. **Ablation on source count:** Train supervised models with k ∈ {500, 1000, 2000, 3000} sources; plot discrimination vs. calibration tradeoff curve.
  3. **Interpretability validation:** Have clinical domain experts rate the coherence of top-5 predictive source signatures vs. top-5 raw channels; compare clinical face validity scores.

## Open Questions the Paper Calls Out

Would including diverse racial/ethnic populations in the learning set reveal additional latent sources of SLE heterogeneity? The study was limited by its learning set which was mainly of white race and not representative of the SLE population at large. It is reasonable to expect that their inclusion would reveal additional latent sources.

Would increasing the number of latent sources beyond 2000 improve identification of true causal factors? One limitation of the study is the lack of a bijective relationship between observed variables and sources. Having less sources than channels (2000 < 7947) implies that some of the sources may be linear combinations of error terms in the causal graph.

Can the identified SLE subtypes be used to stratify patients for more efficient clinical trials or targeted treatments? While the study identified 19 predictive sources, it did not test whether these sources could inform treatment decisions or trial design.

## Limitations
- Use of synthetic EHR data limits validation of clinical interpretations
- Exact implementation details of AdaNet with sure independence screening not fully specified
- Optimal number of ICA sources for SLE heterogeneity discovery remains unclear

## Confidence
- **High confidence:** ICA decomposition methodology and theoretical foundations are well-established and correctly applied
- **Medium confidence:** Clinical interpretation of the 19 predictive sources relies on face validity assessment rather than external validation
- **Low confidence:** Exact implementation details of AdaNet with sure independence screening and specific fastICA parameters are not fully specified

## Next Checks
1. External validation on independent EHR datasets to confirm the 19 predictive sources and their clinical interpretations generalize beyond the VUMC cohort
2. Sensitivity analysis varying the number of ICA sources (k=500, 1000, 2000, 3000) to identify optimal tradeoff between discrimination and interpretability
3. Comparison of ICA-derived sources against alternative dimension reduction techniques (e.g., variational autoencoders, non-negative matrix factorization) to assess robustness of latent heterogeneity discovery