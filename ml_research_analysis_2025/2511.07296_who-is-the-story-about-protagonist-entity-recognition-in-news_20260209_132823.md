---
ver: rpa2
title: Who Is the Story About? Protagonist Entity Recognition in News
arxiv_id: '2511.07296'
source_url: https://arxiv.org/abs/2511.07296
tags:
- narrative
- protagonist
- entity
- news
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Protagonist Entity Recognition (PER) is introduced as a task that
  identifies the organizations driving a news story's narrative, addressing the limitation
  of traditional NER which treats all entity mentions equally. A gold-standard corpus
  of 50 news articles was manually annotated by four experts, establishing inter-annotator
  reliability and validating the task's feasibility.
---

# Who Is the Story About? Protagonist Entity Recognition in News

## Quick Facts
- arXiv ID: 2511.07296
- Source URL: https://arxiv.org/abs/2511.07296
- Reference count: 8
- Introduces Protagonist Entity Recognition (PER) to identify narrative-driving organizations in news stories, showing LLMs can match human narrative interpretation when guided by exemplars.

## Executive Summary
Protagonist Entity Recognition (PER) is introduced as a task that identifies the organizations driving a news story's narrative, addressing the limitation of traditional NER which treats all entity mentions equally. A gold-standard corpus of 50 news articles was manually annotated by four experts, establishing inter-annotator reliability and validating the task's feasibility. Large Language Models (LLMs), especially when guided by in-context exemplars, demonstrated agreement with human judgments comparable to inter-annotator agreement, showing that LLMs can approximate human narrative interpretation. Automatic labeling was then scaled to larger corpora using NER-guided prompting, enabling high-quality supervision for PER.

## Method Summary
The study created a gold-standard corpus of 50 news articles annotated by four experts to identify protagonist organizations. The PER task was then automated using Large Language Models in two configurations: zero-shot (LLaMA-Base) and in-context learning with exemplars (LLaMA-ICL). NER-guided prompting was used to constrain the task to candidate entities extracted by an off-the-shelf NER system. The approach was evaluated using entity-level Micro-F1 and Macro-F1 metrics, with GPT-5 generating silver labels for large-scale experiments.

## Key Results
- LLaMA-ICL models achieved agreement with human judgments comparable to inter-annotator agreement (Cohen's κ ≈ 0.4)
- Exemplar-based in-context learning calibrated model selection thresholds, mitigating over-selection bias seen in zero-shot baselines
- Larger models (70B+) showed robust performance while smaller models struggled with distributed narrative signals
- Automatic labeling scaled PER to larger corpora through NER-guided prompting

## Why This Works (Mechanism)

### Mechanism 1: Exemplar-Based Threshold Calibration
In-context learning calibrates the LLM's decision boundary for "protagonist" vs. "mention," mitigating the over-selection bias found in zero-shot baselines. By providing annotated exemplars in the prompt, the model infers a stricter inclusion threshold and a more specific definition of narrative centrality.

### Mechanism 2: Candidate-Constrained Reasoning
Reducing the task from unconstrained generation to a classification problem over a candidate list improves reliability. By first running a standard NER system and passing only those identified entities to the LLM, the architecture separates mention detection from narrative reasoning.

### Mechanism 3: Scale-Dependent Discourse Integration
Protagonist recognition requires the synthesis of global document context, a capability that scales with model parameter count. Larger models maintain a "narrative state" that weighs dispersed signals across the document to determine centrality.

## Foundational Learning

- **Named Entity Recognition (NER) vs. Entity Salience**: PER identifies narrative drivers while NER identifies mentions. Quick check: If an article mentions "The European Commission" 5 times but the story is about "TechCorp's" earnings, which entity is the NER output vs. the PER output?

- **In-Context Learning (ICL)**: Performance boost relies on ICL. Quick check: Does LLaMA-ICL require gradient updates to improve performance on the PER task according to the paper?

- **Inter-Annotator Agreement (Cohen's Kappa)**: Validity of the "Gold Standard" rests on agreement scores. Quick check: Why does the paper argue that "Overall agreement" scores might be inflated compared to Cohen's κ?

## Architecture Onboarding

- **Component map**: Raw text -> NER Module -> Prompt Constructor -> LLM Core -> Parser
- **Critical path**: The Prompt Constructor and NER Module. If the NER step misses the entity, the LLM cannot select it.
- **Design tradeoffs**: Recall vs. Precision (over-selection vs. under-selection), Model Size vs. Latency, Guided vs. Unguided prompting.
- **Failure signatures**: Over-selection (returns almost all candidates), Entity Hallucination (invents organizations), Frequency Bias (selects most-mentioned entity).
- **First 3 experiments**: 1) Baseline NER Validation: Verify true protagonist is captured in candidate list. 2) Zero-Shot vs. ICL Comparison: Measure difference in number of protagonists selected. 3) Context Ablation: Compare Headline+Lead vs. Full Text accuracy.

## Open Questions the Paper Calls Out

- To what extent does PER generalize to non-financial news domains like political or investigative reporting? The current study is restricted to financial and organizational news.
- How does exemplar selection systematically influence LLM bias and stability? Different exemplar sets may produce different operating regimes.
- Can PER be extended to identify protagonists among entity types other than organizations, such as persons or geopolitical entities?

## Limitations
- Evaluation relies on a small gold-standard corpus (50 articles) and GPT-5 for silver labels
- Exact prompt templates and exemplar texts are not provided, limiting reproducibility
- Focus on organizational entities may not generalize to other entity types or narrative genres

## Confidence
- **High Confidence**: Feasibility of PER as distinct task, effectiveness of exemplar-based ICL, general pattern that larger models perform better
- **Medium Confidence**: Specific performance numbers and claim that exemplar-based ICL achieves human-level agreement
- **Low Confidence**: Scalability claims for automatic labeling pipeline without access to specific NER system and prompt construction methodology

## Next Checks
1. Implement and test multiple prompt variations on a small validation set to confirm the "calibration" effect
2. Systematically evaluate how NER recall affects PER performance by removing known protagonists from candidate list
3. Apply best-performing PER configuration to a different news domain to assess transfer capability