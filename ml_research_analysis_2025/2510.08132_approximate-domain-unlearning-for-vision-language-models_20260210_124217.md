---
ver: rpa2
title: Approximate Domain Unlearning for Vision-Language Models
arxiv_id: '2510.08132'
source_url: https://arxiv.org/abs/2510.08132
tags:
- domain
- unlearning
- domains
- inproceedings
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Approximate Domain Unlearning (ADU), a novel
  problem setting that extends approximate unlearning from class-level to domain-level.
  Unlike existing approaches that focus on forgetting specific object classes, ADU
  aims to selectively reduce recognition accuracy for images from specified domains
  (e.g., illustrations) while preserving accuracy for other domains (e.g., real photos).
---

# Approximate Domain Unlearning for Vision-Language Models

## Quick Facts
- **arXiv ID**: 2510.08132
- **Source URL**: https://arxiv.org/abs/2510.08132
- **Authors**: Kodai Kawamura; Yuta Goto; Rintaro Yanagi; Hirokatsu Kataoka; Go Irie
- **Reference count**: 26
- **Key outcome**: Introduces Approximate Domain Unlearning (ADU) for VLMs, achieving superior domain-specific unlearning performance through DDL and InstaPG methods on multi-domain benchmarks

## Executive Summary
This paper introduces Approximate Domain Unlearning (ADU), a novel problem setting that extends approximate unlearning from class-level to domain-level. Unlike existing approaches that focus on forgetting specific object classes, ADU aims to selectively reduce recognition accuracy for images from specified domains (e.g., illustrations) while preserving accuracy for other domains (e.g., real photos). This addresses practical scenarios like autonomous driving, where distinguishing real vehicles from illustrated ones is critical for safety. The paper identifies a key challenge: due to strong domain generalization in pre-trained VLMs, domain distributions are highly entangled in feature space, making naive domain-specific unlearning ineffective. To tackle this, the authors propose a novel method combining Domain Disentangling Loss (DDL) to explicitly separate domain distributions and Instance-wise Prompt Generator (InstaPG) to adaptively capture image-level domain variations. Extensive experiments on four multi-domain benchmarks (ImageNet, Office-Home, Mini DomainNet, DomainNet) show significant improvements over strong baselines built upon state-of-the-art VLM tuning techniques, achieving superior domain unlearning performance.

## Method Summary
The proposed Approximate Domain Unlearning method addresses the challenge of domain generalization in VLMs by introducing two key components: Domain Disentangling Loss (DDL) and Instance-wise Prompt Generator (InstaPG). DDL explicitly separates domain distributions in feature space by encouraging domain-specific clusters while maintaining task-relevant features. InstaPG adaptively generates prompts for each image instance based on its domain characteristics, allowing fine-grained control over domain-specific unlearning. The method operates by first computing domain-specific feature representations, then applying DDL to disentangle these representations, and finally using InstaPG to generate adaptive prompts that guide the unlearning process. This approach enables selective reduction of recognition accuracy for target domains while preserving performance on other domains, overcoming the entanglement problem that plagues naive domain-specific unlearning approaches.

## Key Results
- Significant improvement in domain unlearning performance across four multi-domain benchmarks (ImageNet, Office-Home, Mini DomainNet, DomainNet)
- Outperforms strong baselines built on state-of-the-art VLM tuning techniques for domain-specific unlearning
- Successfully achieves selective reduction of recognition accuracy for target domains (e.g., illustrations) while preserving accuracy for other domains (e.g., real photos)

## Why This Works (Mechanism)
The method works by addressing the fundamental challenge of domain entanglement in pre-trained VLMs. By using Domain Disentangling Loss to explicitly separate domain distributions in feature space, the approach creates clearer boundaries between domains, making it possible to target specific domains for unlearning. The Instance-wise Prompt Generator then provides adaptive control at the image level, allowing fine-grained adjustments based on individual image characteristics. This combination effectively overcomes the strong domain generalization that makes traditional unlearning approaches ineffective, enabling selective domain unlearning while maintaining overall model performance.

## Foundational Learning
- **Domain Generalization**: Understanding how VLMs learn to recognize objects across diverse domains is crucial because it explains why naive domain unlearning fails - the model has learned robust cross-domain representations that are difficult to selectively modify.
- **Feature Space Disentanglement**: The concept of separating different factors of variation in feature space is essential for understanding how DDL works to create distinct domain clusters that can be individually targeted.
- **Prompt-based Tuning**: Knowledge of how prompt tuning works in VLMs is necessary to understand InstaPG's role in adaptively modifying model behavior for domain-specific unlearning.

## Architecture Onboarding

**Component Map**: Input Images -> Feature Extractor -> Domain Disentangling Loss (DDL) -> Instance-wise Prompt Generator (InstaPG) -> Output Predictions

**Critical Path**: The critical path involves extracting domain-specific features, applying DDL to disentangle these features into distinct domain clusters, and using InstaPG to generate adaptive prompts that guide the unlearning process for target domains.

**Design Tradeoffs**: The main tradeoff is between the strength of domain disentanglement and the preservation of task-relevant features. Too strong disentanglement may harm overall classification performance, while insufficient disentanglement limits unlearning effectiveness.

**Failure Signatures**: 
- Insufficient domain disentanglement leading to poor unlearning performance
- Over-aggressive unlearning affecting non-target domains
- Loss of task-relevant features due to excessive domain separation
- InstaPG generating ineffective prompts for certain domain variations

**First Experiments**:
1. Test DDL effectiveness on simple synthetic domain separation tasks
2. Evaluate InstaPG's ability to generate distinct prompts for known domain variations
3. Assess the combined method's performance on a controlled multi-domain dataset with clear domain boundaries

## Open Questions the Paper Calls Out
None

## Limitations
- Limited empirical validation of practical safety-critical applications like autonomous driving
- Unclear generalizability across diverse VLM architectures and tasks beyond image classification
- Insufficient analysis of precision-recall trade-offs and potential cross-domain effects

## Confidence

**High Confidence**: The identification of domain generalization as a fundamental challenge for domain unlearning in VLMs is well-supported and technically sound. The formulation of the ADU problem setting is clear and novel.

**Medium Confidence**: The proposed DDL and InstaPG methods demonstrate strong empirical performance on the tested benchmarks. However, the limited scope of evaluation domains and VLM architectures warrants caution in generalizing these results.

**Low Confidence**: Claims about practical safety-critical applications (e.g., autonomous driving) lack direct empirical validation. The translation from benchmark performance to real-world effectiveness remains speculative.

## Next Checks
1. Test DDL and InstaPG on VLMs with different backbone architectures (e.g., CLIP, BLIP, Flamingo) to assess generalizability beyond the specific model used in experiments.

2. Evaluate the unlearning methods on non-classification VLM tasks such as visual question answering and image captioning to verify effectiveness across different VLM capabilities.

3. Assess the stability of unlearned domains over time and under distribution shifts, particularly examining whether domains gradually recover recognition capability through continued model use or fine-tuning.