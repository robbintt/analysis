---
ver: rpa2
title: Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented
  Generation
arxiv_id: '2508.21097'
source_url: https://arxiv.org/abs/2508.21097
tags:
- code
- quantum
- generation
- software
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes using Large Language Models (LLMs) with Retrieval-Augmented
  Generation (RAG) to generate quantum code from UML models. The key insight is that
  prompt engineering dramatically improves LLM performance: a specific, constraint-rich
  prompt increased CodeBLEU scores from 0.16 to 0.57 and Q-F-measure from 0.68 to
  0.99.'
---

# Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID:** 2508.21097
- **Source URL:** https://arxiv.org/abs/2508.21097
- **Reference count:** 40
- **Primary result:** Specific prompt engineering dramatically improves LLM quantum code generation from UML models (CodeBLEU 0.16→0.57, Q-F-measure 0.68→0.99)

## Executive Summary
This paper introduces a model-driven approach for generating quantum computing code from UML models using Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG). The key innovation is a carefully engineered prompt that dramatically improves code generation quality, increasing CodeBLEU scores from 0.16 to 0.57 and quantum-specific metrics to near-perfect levels. While RAG with Qiskit repositories was incorporated into the architecture, it failed to provide meaningful improvements, suggesting the external context was not sufficiently relevant or well-integrated.

## Method Summary
The approach uses LLMs to transform UML model diagrams into executable quantum code. The core methodology involves prompt engineering with specific constraints and context to guide the LLM, combined with RAG that retrieves relevant Qiskit documentation and examples. The system processes UML class diagrams representing quantum circuits and generates corresponding Qiskit code. The prompt engineering strategy includes explicit constraints about quantum operations, circuit structure, and code syntax, while the RAG component aims to provide additional contextual information from quantum computing repositories.

## Key Results
- Specific prompt engineering increased CodeBLEU scores from 0.16 to 0.57
- Quantum-specific metrics reached near-perfect levels (Q-F-measure 0.99, Q-Precision 1.0, Q-Recall 1.0)
- RAG component with Qiskit repositories provided no measurable improvement
- Validation conducted on seven UML model instances only

## Why This Works (Mechanism)
The method works by leveraging LLMs' ability to understand natural language instructions when provided with highly specific, constraint-rich prompts. The prompt engineering approach effectively communicates the domain-specific requirements of quantum computing code generation, guiding the LLM to produce syntactically and semantically correct Qiskit code from UML models. The lack of RAG improvement suggests that the LLM's inherent knowledge and the carefully crafted prompt were sufficient for the task, and the external context from Qiskit repositories was either redundant or not well-integrated into the generation process.

## Foundational Learning

**UML to Quantum Code Transformation**: Understanding how UML class diagrams represent quantum circuits and quantum operations is essential. This knowledge enables the mapping between high-level model abstractions and low-level quantum code. Quick check: Can you trace how a UML class diagram component maps to a specific Qiskit operation?

**Prompt Engineering for LLMs**: Crafting effective prompts with domain-specific constraints and examples is crucial for achieving high-quality code generation. This involves understanding how to structure instructions and provide sufficient context. Quick check: Can you identify the key prompt components that drove the performance improvement?

**Quantum Computing Fundamentals**: Knowledge of quantum gates, circuits, and Qiskit syntax is necessary to evaluate the correctness of generated code and understand the domain constraints. Quick check: Do you understand how basic quantum gates (Hadamard, CNOT, etc.) are represented in Qiskit?

**RAG Context Integration**: Understanding how to effectively retrieve and integrate external documentation into the LLM generation process is important for assessing why RAG failed to improve results. Quick check: Can you explain why the Qiskit repository context might not have been relevant for this specific task?

## Architecture Onboarding

**Component Map**: UML Model → LLM with Prompt Engineering → Quantum Code. Optional path: LLM with RAG Context → Quantum Code.

**Critical Path**: The core transformation flow is UML Model → Specific Prompt → LLM → Quantum Code, with the specific prompt being the critical differentiator.

**Design Tradeoffs**: The approach prioritizes prompt engineering over complex retrieval systems, trading potential context enrichment for prompt simplicity and control. This reduces dependency on external resources but may limit scalability to more complex quantum programs.

**Failure Signatures**: If the prompt is not specific enough, the LLM may generate syntactically correct but semantically incorrect quantum code. If RAG context is not well-integrated or relevant, it adds computational overhead without performance benefits.

**3 First Experiments**:
1. Test prompt variations with different constraint specifications to identify the most critical components.
2. Implement a more targeted RAG retrieval strategy using semantic similarity for quantum-specific documentation.
3. Evaluate the system with more complex UML models representing multi-gate quantum circuits.

## Open Questions the Paper Calls Out
The paper identifies several open questions: how to improve the relevance and integration of RAG context for quantum computing repositories, whether other LLM architectures might perform better for this task, and how to extend the approach to support code-to-code transformations beyond UML-to-quantum code generation.

## Limitations
- Evaluation limited to only seven UML model instances, constraining generalizability
- RAG component failed to provide meaningful improvements, suggesting integration or relevance issues
- Method focused on relatively simple quantum circuit representations, not complex quantum algorithms

## Confidence
- **Prompt Engineering Results**: High - Substantial metric improvements demonstrated with clear before/after comparison
- **RAG Component Results**: Medium - Lack of improvement noted, but methodology for context selection not detailed
- **Overall Method Generalizability**: Low - Small evaluation set and limited model complexity

## Next Checks
1. Expand evaluation to a larger, more diverse set of UML models with varying complexity levels.
2. Refine RAG context selection methodology by using more targeted retrieval strategies (e.g., semantic similarity or domain-specific filtering) and evaluate with different quantum computing frameworks.
3. Conduct ablation studies to isolate the contribution of each prompt component and test alternative LLMs to assess method robustness.