---
ver: rpa2
title: 'Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through
  Generative Models'
arxiv_id: '2507.17008'
source_url: https://arxiv.org/abs/2507.17008
tags:
- data
- generated
- training
- real
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of hand shape classification in
  sign language datasets, which are typically small and severely imbalanced. To address
  this, the authors propose using Generative Adversarial Networks (GANs) to generate
  synthetic data that augments the training set.
---

# Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through Generative Models

## Quick Facts
- arXiv ID: 2507.17008
- Source URL: https://arxiv.org/abs/2507.17008
- Authors: Gaston Gustavo Rios; Pedro Dal Bianco; Franco Ronchetti; Facundo Quiroga; Oscar Stanchi; Santiago Ponte Ahón; Waldo Hasperué
- Reference count: 40
- Key result: GAN-generated synthetic data pre-training followed by real data fine-tuning improves sign language handshape classification accuracy by 5% over state-of-the-art, achieving 85.3% on RWTH dataset.

## Executive Summary
This paper addresses the critical challenge of data imbalance in sign language handshape classification, where small datasets contain severely underrepresented classes. The authors propose using Generative Adversarial Networks (GANs) to generate synthetic training data that balances the dataset. By comparing label-conditioned (ReACGAN) and pose-conditioned (SPADE) GAN architectures, they demonstrate that pre-training classifiers on GAN-generated data followed by fine-tuning on real data yields superior performance compared to direct training or other integration strategies. Their approach achieves 85.3% accuracy on the RWTH dataset, a 5% improvement over previous methods, and shows particular effectiveness for minority classes with minimal training samples.

## Method Summary
The authors employ two GAN architectures—ReACGAN (label-conditioned) and SPADE (pose-conditioned)—to generate synthetic handshape images for dataset balancing. They generate 1,000 synthetic images per class to address severe class imbalance in sign language datasets. The classification pipeline uses EfficientNet v2 M initialized with ImageNet weights, pre-trained on synthetic data and then fine-tuned on real data. The pose-conditioned approach leverages OpenPose to extract 21 hand keypoints, enabling cross-dataset transfer by training generators on large datasets (HaGRID) and applying to smaller ones (RWTH). Evaluation includes standard classification metrics alongside GAN-specific metrics (FID, IS, Coverage, Density) and human perceptual studies.

## Key Results
- Pre-training with GAN-generated data followed by fine-tuning on real data yields best performance (85.3% accuracy on RWTH)
- Dataset balance through generative models boosts per-class accuracy by up to 100% in several cases
- Models pre-trained with generated data converge more rapidly, achieving convergence in about half the epochs
- Pose-conditioned generation trained on HaGRID improves RWTH performance similarly to single-source training

## Why This Works (Mechanism)

### Mechanism 1: Synthetic Pre-training for Domain-Specific Initialization
Pre-training with GAN-generated data followed by fine-tuning on real data yields superior classification performance compared to direct training or other integration strategies. Generated data provides domain-specific feature representations before real data refinement. The continuous generation process creates interpolations between classes that smooth decision boundaries, helping the optimizer avoid sharp local minima associated with sparse, imbalanced real data. Core assumption: Generated images contain sufficiently realistic handshape features that transfer to real image classification, despite containing artifacts. Evidence: Pre-training approach improved accuracy by 5% on RWTH; models converged in half the epochs when pre-trained on generated data. Break condition: Generated data quality degrades significantly, introducing noise that overwhelms the useful signal.

### Mechanism 2: Stratified Generation for Class Balance Restoration
Generating balanced synthetic datasets (1,000 images per class) addresses class imbalance, particularly benefiting minority classes with minimal training samples. By oversampling minority classes through generation rather than duplication, the classifier receives diverse training signal for underrepresented categories. This prevents the model from learning to ignore rare classes. Core assumption: The generator can produce meaningful intra-class variation for minority classes despite having few real training examples. Evidence: Some classes achieved 100% accuracy where baseline model completely failed to classify them, especially noteworthy for classes with 1-3 training instances. Break condition: Generator collapses to limited modes, producing insufficient variation for minority classes even with many generated samples.

### Mechanism 3: Pose-Conditioned Cross-Dataset Transfer
Conditioning generation on pose information (rather than labels) enables generators trained on one dataset to produce useful synthetic data for different sign language datasets. Pose keypoints provide a language-agnostic structural representation of hand configurations. A generator learning the mapping from pose-to-appearance on a large dataset (HaGRID) can synthesize images for poses extracted from a different dataset (RWTH). Core assumption: Pose representations are sufficiently standardized across datasets and capture the essential features needed for handshape discrimination. Evidence: Multi-source training demonstrated improvement in RWTH similar to single-source training (85.15% accuracy). Break condition: Target dataset poses fall outside the distribution learned by the source-trained generator.

## Foundational Learning

- Concept: **Conditional GAN architectures (label vs. spatial conditioning)**
  - Why needed here: The paper compares ReACGAN (label-conditioned via auxiliary classifier) and SPADE (spatially-conditioned via pose maps). Understanding conditioning modes is essential for selecting the right approach.
  - Quick check question: For a new sign language dataset with no labeled training data but available pose estimates, which conditioning approach would be viable?

- Concept: **Class imbalance metrics beyond overall accuracy**
  - Why needed here: The 5% overall improvement masks dramatic per-class differences—some minority classes went from 0% to 100% accuracy.
  - Quick check question: Why could a model achieve 80% overall accuracy while completely failing on 16 of 39 classes?

- Concept: **Generator evaluation metrics (FID, IS, Coverage, Density)**
  - Why needed here: The paper uses multiple metrics to assess generation quality, and these don't always agree (SPADE had better IS but worse FID and human scores).
  - Quick check question: If FID improves but Coverage decreases, what does this indicate about the generated distribution?

## Architecture Onboarding

- Component map:
  - OpenPose extracts 21 hand keypoints from real images
  - GAN Generator (ReACGAN or SPADE) takes (noise, conditioning) and produces synthetic images
  - Discriminator evaluates real vs. generated images using appropriate loss (D2D-CE for ReACGAN, adversarial+pose for SPADE)
  - EfficientNet v2 M classifier takes synthetic data for pre-training, then fine-tunes on real data

- Critical path:
  1. Extract poses from real images using OpenPose
  2. Train generator (ReACGAN on labels OR SPADE on pose maps)
  3. Generate balanced synthetic dataset (1,000 samples per class)
  4. Pre-train EfficientNet classifier on synthetic data
  5. Fine-tune on real data only

- Design tradeoffs:
  - ReACGAN vs. SPADE: ReACGAN produces more realistic images (Human: 2.74 vs 2.32 on RWTH) but SPADE enables cross-dataset transfer
  - Generation volume: Beyond 1,000 samples/class, returns diminish due to generator variability limits
  - Filtering strategy: Top-K filtering by class probability didn't improve results—variety mattered more than per-sample quality

- Failure signatures:
  - Training with generated data only (no fine-tuning) → artifacts degrade performance
  - Regularization/mixup strategies → underperformed pre-training approach
  - SPADE on small datasets → lower realism than ReACGAN (FID 51.05 vs 45.19 on RWTH)

- First 3 experiments:
  1. **Baseline establishment**: Train EfficientNet v2 M on real RWTH data with ImageNet pre-training only. Record overall accuracy and per-class breakdown.
  2. **Ablation on integration strategy**: Compare PRETRAIN vs. REGULARIZER vs. MIXUP using ReACGAN-generated data. Use identical synthetic dataset across conditions.
  3. **Cross-dataset transfer test**: Train SPADE on HaGRID poses, generate images using RWTH pose extractions, pre-train and fine-tune on RWTH. Compare to single-source ReACGAN approach.

## Open Questions the Paper Calls Out

### Open Question 1
Does improving the discriminator loss function in pose-conditioned models (like SPADE) bridge the fidelity gap with label-conditioned models (like ReACGAN) for handshape generation? Basis: The authors note that label-conditioned models generated better images than pose-conditioned ones, potentially due to the usage of a "better discriminator loss," and explicitly state this "requires further study." Unresolved because the paper identifies the performance gap but only hypothesizes the cause without isolating the loss function as the definitive variable. Evidence: An ablation study applying the Data-to-Data Cross-Entropy (D2D-CE) loss used in ReACGAN to the SPADE architecture to see if it improves pose-conditioned image fidelity.

### Open Question 2
Can domain adaptation techniques using image-to-image translation effectively create a universal generator that generalizes across structurally diverse sign languages? Basis: The authors list "domain adaptation using image-to-image generator models with pose information" as future work to realize the goal of a "single generator that can be used to train classifiers on any sign language