---
ver: rpa2
title: 'You Only Debias Once: Towards Flexible Accuracy-Fairness Trade-offs at Inference
  Time'
arxiv_id: '2503.07066'
source_url: https://arxiv.org/abs/2503.07066
tags:
- fairness
- error
- accuracy
- rate
- accuracy-fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes YODO, a method to achieve flexible accuracy-fairness
  trade-offs at inference time using a single model trained once. Existing fairness
  methods offer a fixed trade-off, requiring multiple models for flexibility.
---

# You Only Debias Once: Towards Flexible Accuracy-Fairness Trade-offs at Inference Time

## Quick Facts
- arXiv ID: 2503.07066
- Source URL: https://arxiv.org/abs/2503.07066
- Reference count: 40
- Key outcome: YODO enables flexible accuracy-fairness trade-offs at inference time using a single model, achieving comparable performance to fixed models while providing trade-off flexibility at ultra-low overhead (3.53 seconds for 100 levels vs 425 seconds for training 100 models).

## Executive Summary
This paper introduces YODO (You Only Debias Once), a method that achieves flexible accuracy-fairness trade-offs at inference time using a single model trained once. Traditional fairness methods provide a fixed trade-off between accuracy and fairness, requiring multiple models to achieve different balances. YODO addresses this limitation by learning an objective-diverse neural network subspace with two endpoints - one optimized for accuracy and one for fairness. By interpolating between these endpoints using a parameter α, YODO enables varying trade-offs without retraining.

The key innovation is the ability to select different points along the learned subspace line at inference time, allowing practitioners to adjust the fairness-accuracy balance based on deployment requirements. Experimental results demonstrate that YODO achieves performance comparable to fixed models while providing the flexibility to adapt to changing needs with minimal computational overhead.

## Method Summary
YODO learns a neural network subspace that connects two endpoints: one trained for maximum accuracy and another trained for maximum fairness. The method constructs this subspace by jointly optimizing two objective functions during training, creating a continuous path between the two extremes. At inference time, practitioners can select any point along this path by adjusting a single parameter α, which controls the interpolation between the accuracy-focused and fairness-focused models.

The subspace interpolation allows for real-time adjustment of the fairness-accuracy trade-off without requiring multiple models or retraining. This is achieved through a carefully designed training procedure that ensures the subspace contains valid model configurations for various fairness requirements while maintaining reasonable accuracy levels.

## Key Results
- YODO achieves comparable performance to fixed models across multiple datasets while providing flexible trade-offs
- Inference-time trade-off adjustment requires only 3.53 seconds for 100 different levels on the ACS-E dataset
- YODO significantly outperforms training 100 separate fixed models, which requires 425 seconds
- The method demonstrates effectiveness on both tabular and image datasets

## Why This Works (Mechanism)
YODO works by learning a continuous subspace of neural network parameters that spans the trade-off frontier between accuracy and fairness. The mechanism leverages the fact that neural network parameters exist in a high-dimensional space where different optimization objectives create distinct but related regions. By training two models at opposite ends of the fairness-accuracy spectrum and connecting them through interpolation, YODO captures the essential trade-off dynamics in a single, traversable path.

## Foundational Learning
- **Neural network parameter spaces**: Understanding that model parameters exist in continuous high-dimensional spaces where interpolation can yield meaningful models
  - Why needed: Enables the theoretical foundation for subspace interpolation
  - Quick check: Verify that interpolated parameters produce valid, functional models

- **Fairness-accuracy trade-off frontiers**: The Pareto-optimal boundary between fairness and accuracy in model performance
  - Why needed: Provides the conceptual framework for what YODO aims to capture
  - Quick check: Plot accuracy vs fairness metrics to visualize the frontier

- **Multi-objective optimization**: Techniques for balancing competing optimization objectives during training
  - Why needed: Essential for learning the two endpoints that define the subspace
  - Quick check: Ensure both objectives are properly weighted and optimized

## Architecture Onboarding
- **Component map**: Input -> Model parameter subspace -> α selector -> Interpolated model -> Output predictions
- **Critical path**: Training (learn subspace) → Inference (select α) → Interpolate parameters → Generate predictions
- **Design tradeoffs**: Single model flexibility vs. potential suboptimal performance at specific trade-off points compared to specialized models
- **Failure signatures**: Degraded performance when interpolation produces invalid parameter combinations; poor coverage of trade-off spectrum
- **First experiments**:
  1. Train YODO on a simple binary classification task and verify subspace interpolation produces functional models
  2. Compare accuracy-fairness trade-offs of interpolated models against independently trained models at same points
  3. Measure inference-time overhead for adjusting trade-offs across multiple α values

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Effectiveness across diverse fairness metrics beyond demographic parity and equalized odds remains unclear
- Performance on data modalities beyond tabular and image datasets (e.g., text, time-series) is unexplored
- Assumes access to fairness-sensitive attributes during inference, which may not be available due to privacy or regulatory constraints

## Confidence
- High confidence: The core technical contribution of learning a single model that enables flexible trade-offs via subspace interpolation is well-supported by theoretical justification and experimental results
- Medium confidence: The claimed performance parity with fixed models across different datasets and fairness metrics is reasonably demonstrated but could benefit from more extensive validation
- Low confidence: The generalizability of the approach to other fairness definitions, data modalities, and real-world deployment scenarios with potential distribution shifts

## Next Checks
1. Evaluate YODO's performance on additional fairness metrics (e.g., equal opportunity difference, predictive parity) and across more diverse data modalities including text and time-series datasets
2. Conduct experiments to assess model performance under realistic deployment conditions with potential distribution shifts between training and inference data
3. Perform ablation studies to quantify the impact of subspace dimensionality on trade-off quality and identify optimal subspace sizes for different problem settings