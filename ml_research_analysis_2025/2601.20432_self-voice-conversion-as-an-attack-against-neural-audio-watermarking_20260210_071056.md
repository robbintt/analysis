---
ver: rpa2
title: Self Voice Conversion as an Attack against Neural Audio Watermarking
arxiv_id: '2601.20432'
source_url: https://arxiv.org/abs/2601.20432
tags:
- watermarking
- speech
- audio
- speaker
- self
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates self voice conversion (VC) as a universal,\
  \ content-preserving attack against audio watermarking systems. The authors evaluate\
  \ whether self VC\u2014where speech is remapped to the same identity while altering\
  \ acoustic characteristics\u2014can effectively disrupt embedded watermarks in state-of-the-art\
  \ watermarking approaches."
---

# Self Voice Conversion as an Attack against Neural Audio Watermarking

## Quick Facts
- arXiv ID: 2601.20432
- Source URL: https://arxiv.org/abs/2601.20432
- Reference count: 40
- Primary result: Self voice conversion (VC) drives watermark extraction accuracy to random guessing levels (~0.5) across five watermarking systems while preserving identity and content

## Executive Summary
This paper investigates self voice conversion as a universal, content-preserving attack against audio watermarking systems. The authors evaluate whether self VC—where speech is remapped to the same identity while altering acoustic characteristics—can effectively disrupt embedded watermarks in state-of-the-art watermarking approaches. They conduct experiments on five representative watermarking methods, comparing their performance under no attack, baseline vocoder attacks, and the proposed self VC attack using kNN-VC and RVC models. The results show that self VC consistently drives bitwise watermark extraction accuracy close to random guessing (near 0.5 error) across all tested methods, while preserving speaker identity, linguistic content, and perceptual quality. This demonstrates that self VC is a severe, realistic threat to modern audio watermarking systems.

## Method Summary
The paper evaluates self voice conversion as an attack against neural audio watermarking systems. The authors test five representative watermarking methods (DCT, AudioSeal, Timbre, WMCodec, VoiceMark) under three conditions: no attack, baseline vocoder attack, and self voice conversion attack. Two self VC models are employed: kNN-VC (using WavLM embeddings) and RVC (using HuBERT embeddings). The attack pipeline disentangles speaker identity from linguistic content, reconstructs speech in the same speaker's voice with modified acoustic characteristics, and evaluates the impact on watermark extraction accuracy, speaker similarity, and word error rate.

## Key Results
- Self VC drives bitwise watermark extraction accuracy to ~0.5 (random guessing) across all five tested watermarking systems
- Speaker identity preservation remains high (0.748-0.857 speaker similarity) under self VC attack
- Linguistic content is maintained with word error rates below 0.01 across all systems
- Self VC outperforms baseline vocoder attacks in watermark destruction while better preserving identity and content

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Disentangled representation reconstruction discards watermark-bearing signal components.
- **Mechanism:** Self-VC decomposes watermarked speech into separate latent factors—speaker identity, linguistic content, and optionally pitch—before resynthesizing. Watermark information embedded in acoustic properties that do not contribute to perceptual quality or identity is not reconstructed because it never enters the disentangled representation space.
- **Core assumption:** Watermarks are embedded in acoustic details rather than semantic content or speaker identity embeddings.
- **Evidence anchors:**
  - [abstract] "Self voice conversion remaps a speaker's voice to the same identity while altering acoustic characteristics through a voice conversion model."
  - [Page 3] "This pipeline fundamentally differs from waveform-level distortions, as it modifies speech at the representation level rather than through direct signal manipulation."
  - [corpus] Weak direct evidence; StarVC notes VC "fundamentally involves disentangling speaker identity from linguistic content," supporting the disentanglement premise but not watermark destruction specifically.
- **Break condition:** If watermarks are embedded directly into content embeddings (e.g., HuBERT features) or speaker embeddings rather than residual acoustic cues, this attack would preserve rather than destroy them.

### Mechanism 2
- **Claim:** Foundation model encoders act as low-pass filters on non-perceptual signal variations.
- **Mechanism:** Self-supervised speech representations (S3Rs) like WavLM and HuBERT are trained to capture linguistically and perceptually relevant features. Watermark patterns appearing as fine-grained noise-like perturbations fall outside the distribution these models encode, so they are effectively filtered during the encoding step.
- **Core assumption:** Watermark perturbations are out-of-distribution relative to the training data of foundation speech models.
- **Evidence anchors:**
  - [Page 3] "kNN-VC performs VC by replacing each source frame with its nearest neighbors in the reference utterance within a S3R space extracted by a pretrained WavLM model."
  - [Page 5] "The effectiveness of self VC as an attack is closely tied to the use of large pretrained foundation models, e.g., [33], [36] for content and speaker encoding."
  - [corpus] No direct corpus evidence on S3R filtering behavior.
- **Break condition:** If watermark embeddings are adversarially designed to survive S3R encoding (e.g., by perturbing features the encoder preserves), this filtering effect would be reduced.

### Mechanism 3
- **Claim:** Vocoder resynthesis does not propagate watermark signals absent from intermediate representations.
- **Mechanism:** Neural vocoders like HiFiGAN reconstruct waveforms from acoustic features (mel spectrograms or S3R embeddings). If the watermark information was discarded before reaching this stage, the vocoder has no source from which to reconstruct it—unlike direct vocoder attacks where some watermark components may survive feature extraction.
- **Core assumption:** The vocoder cannot hallucinate or reconstruct information absent from its input features.
- **Evidence anchors:**
  - [Page 5] "Neural vocoders reconstruct waveforms from acoustic features such as mel spectrograms, possibly allowing any watermark components that survive feature extraction to propagate through resynthesis. In contrast, self VC typically operates on disentangled representations."
  - [Page 4, Table II] Vocoder-only attacks show partial watermark survival (e.g., Timbre at 0.006–0.194 error), while self-VC pushes all systems to ~0.5 (random).
  - [corpus] No corpus evidence on vocoder watermark propagation.
- **Break condition:** If vocoders overgenerate or introduce artifacts correlated with original watermark patterns, partial recovery might be possible.

## Foundational Learning

- **Concept: Self-supervised speech representations (S3R)**
  - **Why needed here:** Understanding how models like WavLM and HuBERT encode speech is essential to grasping why watermarks are filtered out—they preserve linguistic content but discard non-semantic acoustic details.
  - **Quick check question:** Given a HuBERT embedding of a watermarked utterance, would you expect the watermark bits to be recoverable from the embedding alone?

- **Concept: Voice conversion disentanglement**
  - **Why needed here:** The attack relies on VC models separating speaker identity from content; if you don't understand this factorization, the mechanism of watermark destruction remains opaque.
  - **Quick check question:** In a VC pipeline, which components must remain fixed for "self-VC" vs. cross-speaker VC?

- **Concept: Bitwise accuracy vs. detection metrics**
  - **Why needed here:** The paper reports attacker performance as 1 – bitwise accuracy, where 0.5 indicates random guessing. Understanding this metric is necessary to interpret the severity of attack success.
  - **Quick check question:** If a watermarking system achieves 0.45 bitwise extraction accuracy under attack, is the watermark still providing meaningful security?

## Architecture Onboarding

- **Component map:**
  - Publisher stage: Watermark embedder (DCT/AudioSeal/Timbre/WMCodec/VoiceMark) → watermarked speech
  - Transmission channel (optional): Compound distortions (noise, compression, resampling)
  - Attacker stage: Self-VC module with speaker encoder + content encoder (+ optional pitch extractor) → decoder → vocoder → regenerated speech
  - Receiver stage: Watermark detector → extracted bits

- **Critical path:** The content encoder (WavLM for kNN-VC, HuBERT for RVC) is the primary failure point for watermarks—this is where acoustic detail is discarded. Speaker encoder (ECAPA) preserves identity but not watermark information.

- **Design tradeoffs:**
  - kNN-VC: Higher speaker similarity (0.857), lower UTMOS (3.941)—better identity preservation, slightly lower perceptual quality
  - RVC: Lower speaker similarity (0.748), higher UTMOS (4.190)—slightly better quality but more identity drift
  - Assumption: Tradeoff may affect which attack is preferred for specific content-preserving requirements.

- **Failure signatures:**
  - If WER increases significantly (>0.15), content is being degraded—attack is too destructive.
  - If speaker similarity drops below ~0.70, identity preservation fails—attack becomes detectable.
  - If bitwise accuracy remains below 0.45, the watermark is partially surviving—disentanglement is insufficient.

- **First 3 experiments:**
  1. **Baseline verification:** Run self-VC (kNN-VC) on clean LibriTTS test-clean, measure speaker similarity and WER to confirm Table I results are reproducible.
  2. **Single-system attack:** Apply kNN-VC to AudioSeal-watermarked speech, measure bitwise extraction accuracy with and without transmission channel distortions to replicate Table II patterns.
  3. **Ablation on representation depth:** Intercept HuBERT/WavLM features at different layers to identify where watermark information is lost—if early layers preserve more, this suggests a potential defense direction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can watermarking schemes be designed to operate directly within the latent representation spaces of foundational models to achieve invariance to content-speaker disentanglement?
- Basis in paper: [explicit] The authors state that robust defenses may require "watermark designs that are invariant to content-speaker disentanglement or operating directly within the representation spaces used by foundational models."
- Why unresolved: The paper demonstrates the failure of current methods which rely on waveform or spectral domains, but does not propose or test a solution that functions within the latent space of the VC models themselves.
- What evidence would resolve it: A novel watermarking architecture that embeds information into S3R (Self-Supervised Speech Representation) features and successfully survives the decoding and resynthesis pipeline of self-VC.

### Open Question 2
- Question: Are there stable acoustic features that can be leveraged for watermarking, or is the reliance on acoustic properties fundamentally flawed due to the "mismatch" with modern representation learning?
- Basis in paper: [explicit] The discussion notes that "watermarking methods implicitly rely on acoustic properties that are unstable under modern representation learning pipelines, highlighting a fundamental mismatch."
- Why unresolved: The paper shows that current acoustic cues are destroyed, but leaves open the theoretical question of whether *any* acoustic property can remain stable under latent decomposition, or if the field must abandon acoustic embedding entirely.
- What evidence would resolve it: An analysis identifying specific acoustic features that persist unchanged before and after the self-VC latent reconstruction process, or a mathematical proof showing such stability is impossible.

### Open Question 3
- Question: Can proactive watermarking be effectively integrated with deepfake detection systems to mitigate the "reactive" limitations of post-hoc analysis?
- Basis in paper: [inferred] The paper notes that applying deepfake detection is a "straightforward response" but is "inherently reactive" and "does not prevent watermark degradation," implying a need for a more integrated approach.
- Why unresolved: The paper evaluates watermarking and implies the insufficiency of detection, but does not explore hybrid systems that might use detection signals to reinforce or recover watermark integrity.
- What evidence would resolve it: A system architecture where deepfake detection triggers a specialized recovery mechanism that successfully extracts watermarks from self-VC audio where standard detectors fail.

### Open Question 4
- Question: Does the vulnerability of watermarking to self-VC generalize to other generative audio processing tasks such as neural speech enhancement or bandwidth extension?
- Basis in paper: [inferred] The authors attribute the attack's success to "content-preserving yet acoustically transformative models," suggesting that other pipelines with similar characteristics (like enhancement) might pose comparable threats.
- Why unresolved: The evaluation is strictly limited to self-VC; the robustness against other neural processing pipelines that also manipulate latent representations remains untested.
- What evidence would resolve it: Benchmark results showing watermark extraction accuracy dropping to near-random levels (approx. 0.5) when processed by state-of-the-art neural speech enhancement models.

## Limitations

- The paper does not evaluate adaptive watermarking defenses that could detect or resist VC attacks, assuming static watermarking schemes without countermeasure mechanisms.
- While self-VC preserves identity and content metrics, the study does not explore whether watermark embedding strategies could be adapted to survive disentanglement-based attacks.
- The experiments focus on a single self-VC model per approach (kNN-VC and RVC), leaving uncertainty about whether results generalize to other VC architectures or training objectives.

## Confidence

- **High confidence:** The empirical demonstration that self-VC drives bitwise accuracy to ~0.5 across five watermarking systems. The experimental methodology is sound and results are statistically clear.
- **Medium confidence:** The mechanism explanation regarding disentanglement discarding watermark-bearing acoustic components. While plausible, direct evidence linking specific acoustic features to watermark survival is limited.
- **Medium confidence:** The claim that self-VC is a "realistic" threat. The attack requires VC models and computational resources, but the paper does not assess practical feasibility or detectability in real-world scenarios.

## Next Checks

1. **Adaptive embedding test:** Modify AudioSeal to embed watermarks in speaker identity features rather than acoustic details, then re-run self-VC attacks to test whether this defense strategy is viable.
2. **Multi-stage attack analysis:** Apply self-VC followed by traditional vocoder attacks to determine if compound attacks achieve even lower extraction accuracy than self-VC alone.
3. **Cross-dataset generalization:** Evaluate the same attack pipeline on non-LibriTTS datasets (e.g., VCTK or Common Voice) to verify that results are not dataset-specific.