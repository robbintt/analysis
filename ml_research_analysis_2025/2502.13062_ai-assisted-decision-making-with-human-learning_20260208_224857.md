---
ver: rpa2
title: AI-Assisted Decision Making with Human Learning
arxiv_id: '2502.13062'
source_url: https://arxiv.org/abs/2502.13062
tags:
- human
- algorithm
- learning
- feature
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for studying AI-assisted decision-making
  where a human learns through repeated interactions with an algorithm. The algorithm
  selects informative features for the human to use, balancing informativeness with
  the human's ability to interpret them correctly.
---

# AI-Assisted Decision Making with Human Learning

## Quick Facts
- **arXiv ID:** 2502.13062
- **Source URL:** https://arxiv.org/abs/2502.13062
- **Reference count:** 40
- **Primary result:** Optimal feature selection for AI-assisted decision-making with human learning has a combinatorial structure reducible to a stationary sequence of feature subsets.

## Executive Summary
This paper introduces a framework for AI-assisted decision-making where a human learns through repeated interactions with an algorithm. The algorithm selects informative features for the human to use, balancing informativeness against the human's ability to interpret them correctly. A key finding is that optimal feature selection has a clean combinatorial structure reducible to a stationary sequence of feature subsets. The paper shows that as the algorithm becomes more patient or the human's learning improves, it increasingly selects more informative features, enhancing both prediction accuracy and the human's understanding.

## Method Summary
The framework optimizes feature selection for AI-assisted human decision-making where the algorithm selects feature subsets A_t (|A_t| ≤ k) to minimize discounted prediction loss over time. The algorithm computes per-feature value V_δ,ϕ({i}) = (1/(1-δ))a_i^2 - Σ_{t=0}^∞ δ^t*ϕ(t)*(a_i - h_i,0)^2, then selects the top-k features with positive values. The core innovation is proving that optimal feature selection has a stationary combinatorial structure, meaning the same subset of features should be selected at each time step.

## Key Results
- Optimal feature selection reduces to a stationary sequence of feature subsets
- More patient algorithms (higher δ) select more informative features over time
- Early investment in learning leads to selection of more informative features than later investment

## Why This Works (Mechanism)

### Mechanism 1: Informativeness vs. Divergence Tradeoff
The algorithm optimizes feature selection by balancing informativeness against the human's current interpretive accuracy. Feature selection is guided by a value function V({i}, h) = 2a_i*h_i - h_i^2, incorporating the true coefficient a_i (informativeness) and the human's belief h_i (divergence). The algorithm selects the top k features with the highest positive value, effectively trading off a feature's predictive power against the human's potential for misusing it.

### Mechanism 2: Stationary Optimal Sequence with Learning
When the human learns over time through a φ-convergent dynamic, the optimal feature selection strategy is a stationary sequence. This is because the value of selecting a feature today incorporates the discounted sum of all future benefits from improved beliefs, making it optimal to consistently select the features that provide the best long-term value.

### Mechanism 3: Growth vs. Fixed Mindset via Patience
A more patient algorithm (higher δ) selects a more informative set of features, prioritizing long-term learning over short-term performance. The feature value V_δ,ϕ({i}) weights the initial divergence cost by a discounted sum of learning progress. As δ increases, the weight on long-term convergence increases, raising the value of more informative but initially divergent features.

## Foundational Learning

- **Mean Squared Error (MSE) & Linear Models**: The entire framework is built on minimizing MSE for a linear prediction model. Understanding how error decomposes into bias and variance is critical for the "informativeness vs. divergence" tradeoff. Quick check: Can you derive the decomposition of MSE(A_t, h_t) for a linear model with standardized features?

- **Discounted Infinite-Horizon Optimization**: The algorithm's objective function is an infinite sum of discounted losses. The patience parameter δ is a fundamental driver of system behavior. Quick check: How does a higher discount factor δ change the weight of losses at time t=100 relative to t=0?

- **Combinatorial Feature Selection**: The paper proves the optimal strategy reduces to a stationary sequence, which itself reduces to a combinatorial selection problem. This simplifies a complex sequential decision problem into a tractable computation. Quick check: Explain why the stationarity result simplifies the optimization from searching over all sequences to searching over all subsets.

## Architecture Onboarding

- **Component map:** Algorithm Designer -> Algorithm Core -> Human Model -> Environment

- **Critical path:**
  1. Initialization: Algorithm initialized with ground truth model (a'), human beliefs (h'_0), learning function (φ'), patience (δ), and budget (k)
  2. Value Computation: Compute long-term discounted value V_δ,ϕ({i}) for each feature
  3. Selection: Select top-k features with positive values as stationary optimal sequence A*
  4. Interaction: Repeat forever - observe features, human predicts and updates beliefs

- **Design tradeoffs:**
  - Model Misspecification: Impact of errors in algorithm's knowledge of a, h, and φ is bounded but can be asymmetric
  - Estimating the Human Model: Algorithm's effectiveness hinges on accurately modeling the human
  - Defining φ: Abstract φ-convergent framework requires mapping to concrete learning rule

- **Failure signatures:**
  - Myopic Optimum: Low δ leads to selection of low-informativity features, trapping human in suboptimal state
  - Divergence Trap: Large initial divergence causes sparse or empty feature set selection
  - Unrealistic Human Model: Actual human learning slower or more erratic than assumed φ

- **First 3 experiments:**
  1. Patience Sweep: Verify selected set A* shifts from low-divergence to high-informativity features as δ increases
  2. Learning Rate Sensitivity: Measure transition point δ* for exponential learning model across different learning rates
  3. Robustness to Model Error: Measure deviation in selected feature set from true optimal under belief and learning rate errors

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the independence assumption on features impact optimal selection, and can the framework be extended to handle correlations between variables over time? The paper explicitly lists exploring correlations as future work.

- **Open Question 2:** Does the optimality of stationary sequences hold for discontinuous or non-convex performance metrics, such as binary classification accuracy? The paper highlights the need to explore metrics "beyond mean squared error."

- **Open Question 3:** How does the interaction evolve if the human decision-maker is a strategic agent who anticipates the algorithm's optimization strategy? The paper suggests studying a human who recognizes the algorithm's intent and acts strategically.

## Limitations
- Assumes perfect knowledge of human's initial beliefs and learning dynamics
- Limited empirical validation beyond mathematical analysis
- Applicability to non-linear models or non-MSE loss functions remains unclear

## Confidence
- **High Confidence:** Core mathematical derivations regarding stationary optimal sequences are rigorously proven
- **Medium Confidence:** Claims about "fixed" to "growth" mindset transition are theoretically sound but lack extensive empirical validation
- **Low Confidence:** Practical effectiveness in real-world applications where algorithm cannot perfectly model human learning

## Next Checks
1. Implement full framework and run extensive simulations across diverse parameter spaces to verify theoretical predictions about feature selection patterns and loss minimization
2. Systematically vary algorithm's estimates of human beliefs and learning dynamics to quantify impact on selected feature sets and overall performance
3. Design and execute small-scale human-subject experiment using simplified prediction task to validate whether theoretical optimal strategy improves human learning and prediction accuracy