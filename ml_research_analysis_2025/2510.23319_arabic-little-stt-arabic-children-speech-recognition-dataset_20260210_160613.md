---
ver: rpa2
title: 'Arabic Little STT: Arabic Children Speech Recognition Dataset'
arxiv_id: '2510.23319'
source_url: https://arxiv.org/abs/2510.23319
tags:
- speech
- arabic
- whisper
- children
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Arabic Little STT, the first publicly available\
  \ dataset of Levantine Arabic child speech, containing 355 utterances from 288 children\
  \ aged 6\u201313. The dataset was collected in classroom settings using standard\
  \ smartphone microphones and manually transcribed and normalized."
---

# Arabic Little STT: Arabic Children Speech Recognition Dataset

## Quick Facts
- **arXiv ID**: 2510.23319
- **Source URL**: https://arxiv.org/abs/2510.23319
- **Reference count**: 3
- **Primary result**: First publicly available Levantine Arabic child speech dataset; 355 utterances from 288 children aged 6–13; Whisper Large-v3 achieves 66% WER on child speech vs 16.0% on adult FLEURS dataset

## Executive Summary
This paper introduces Arabic Little STT, the first publicly available dataset of Levantine Arabic child speech, containing 355 utterances from 288 children aged 6–13. The dataset was collected in classroom settings using standard smartphone microphones and manually transcribed and normalized. The authors evaluated eight variants of the Whisper ASR model on this dataset, comparing performance with adult Arabic benchmarks. Results showed that even the best-performing Whisper model (Large-v3) achieved a 66% word error rate (WER) on child speech—4.1× higher than its 16.0% WER on adult datasets like FLEURS. This aligns with findings in English child speech recognition and highlights the systemic challenges ASR models face when generalizing from adult to child speech, especially in low-resource languages like Arabic. The study underscores the critical need for dedicated child speech datasets and ethical data collection practices to advance equitable ASR technologies for Arabic-speaking children.

## Method Summary
The Arabic Little STT dataset was collected in classroom settings using standard smartphone microphones. The data consists of 355 utterances from 288 children aged 6–13 speaking Levantine Arabic. Recordings were manually transcribed and normalized. The authors evaluated eight variants of the Whisper ASR model on this dataset, comparing performance metrics including Word Error Rate (WER) with adult Arabic speech benchmarks. The study focuses on measuring the performance gap between child and adult speech recognition to establish baseline performance and highlight the need for specialized child speech datasets.

## Key Results
- Whisper Large-v3 model achieves 66% WER on Arabic child speech
- This represents 4.1× higher error rate compared to 16.0% WER on adult FLEURS dataset
- Results align with English child speech recognition findings showing systematic challenges for ASR models generalizing from adult to child speech
- Dataset contains 355 utterances from 288 children aged 6–13 in Levantine Arabic

## Why This Works (Mechanism)
Child speech recognition presents unique challenges due to developmental factors including pronunciation variations, vocal tract differences, and inconsistent speech patterns. The significant performance gap between adult and child speech recognition demonstrates that ASR models trained primarily on adult data struggle to generalize to child speech. The mechanism underlying this challenge involves the acoustic and linguistic differences between child and adult speech, which current ASR architectures are not optimized to handle. The paper's contribution lies in providing empirical evidence of this gap in a low-resource language context and establishing baseline metrics for future research.

## Foundational Learning

**Automatic Speech Recognition (ASR)**: Converts spoken language into text; essential for accessibility, education, and human-computer interaction applications.

**Word Error Rate (WER)**: Measures ASR performance by comparing recognized words against reference transcriptions; critical metric for evaluating speech recognition systems.

**Whisper Model Variants**: Different versions of OpenAI's speech recognition model with varying sizes and capabilities; important for understanding performance tradeoffs in resource-constrained environments.

**Levantine Arabic**: A regional dialect of Arabic spoken in the Levant region; significant for cultural preservation and educational applications in the Arab world.

**Dataset Normalization**: Process of standardizing transcriptions to ensure consistency; crucial for training reliable ASR models and fair evaluation.

**Ethical Data Collection**: Practices ensuring privacy and consent in research involving minors; necessary for responsible development of child-focused technologies.

## Architecture Onboarding

**Component Map**: Whisper Model -> Feature Extraction -> Acoustic Modeling -> Language Modeling -> Output Decoding

**Critical Path**: Audio Input → Feature Extraction → Encoder Network → Decoder Network → Text Output

**Design Tradeoffs**: Model size vs. computational efficiency; accuracy vs. latency; dataset size vs. coverage; standardization vs. dialectal variation.

**Failure Signatures**: High WER indicates poor generalization from adult to child speech; specific error patterns may reveal pronunciation or acoustic challenges unique to child speakers.

**First Experiments**:
1. Test Whisper model variants on different age groups within the 6-13 range to identify age-specific performance patterns
2. Compare Levantine Arabic performance with other Arabic dialects if available to assess dialectal robustness
3. Evaluate transfer learning approaches by fine-tuning Whisper on the Arabic Little STT dataset to measure improvement potential

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset contains only 355 utterances from 288 children, which is relatively small for training robust ASR models
- Comparison between child speech and adult speech performance is based on a single adult Arabic benchmark (FLEURS)
- Paper evaluates eight Whisper model variants but does not provide detailed analysis of which specific variant performs best or why

## Confidence
- Dataset Size and Representativeness: Medium - Small dataset acknowledged but impact on model performance not fully analyzed
- Comparison with Adult Benchmarks: Medium - Single benchmark used without additional cross-linguistic comparisons
- Whisper Model Variants: Medium - Best variant identified but underlying reasons for performance differences not explored

## Next Checks
1. Conduct detailed error analysis on Whisper model outputs to identify specific failure modes in child speech recognition
2. Test transfer learning approaches by fine-tuning Whisper models on the Arabic Little STT dataset to measure performance improvements
3. Expand dataset collection to include more utterances and speakers to improve model robustness and generalization