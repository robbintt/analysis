---
ver: rpa2
title: Sparse Autoencoders Trained on the Same Data Learn Different Features
arxiv_id: '2501.16615'
source_url: https://arxiv.org/abs/2501.16615
tags:
- latents
- features
- saes
- different
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether sparse autoencoders (SAEs) trained
  on the same data and model architecture learn identical features. The researchers
  train multiple SAEs on the same LLM and dataset, differing only in random seed initialization.
---

# Sparse Autoencoders Trained on the Same Data Learn Different Features

## Quick Facts
- arXiv ID: 2501.16615
- Source URL: https://arxiv.org/abs/2501.16615
- Reference count: 11
- Key outcome: SAEs trained on same data and architecture learn different features, with only 30% overlap in Llama 3 8B SAEs with 131K latents

## Executive Summary
This study investigates whether sparse autoencoders (SAEs) trained on the same data and model architecture learn identical features. The researchers train multiple SAEs on the same LLM and dataset, differing only in random seed initialization. They employ the Hungarian algorithm to optimally match features between SAEs and measure cosine similarity between encoder and decoder vectors. The key finding is that SAEs learn significantly different features: only 30% of features are shared across seeds in Llama 3 8B SAEs with 131K latents, and this percentage decreases with model scale. The results challenge the assumption that SAEs uncover a universal, objective feature decomposition of neural networks.

## Method Summary
The researchers train multiple SAEs on the same model (Pythia 160M, GPT2, SmolLM, Llama 3 8B) and dataset (The Pile, first 8B tokens) with identical hyperparameters but different random seeds. They use the `sae` library to train SAEs with 2^15 (32K) latents and compare pairs using Hungarian algorithm for optimal bijective matching. Features are classified as "shared" if both encoder and decoder matchings agree on the counterpart AND both cosine similarities exceed 0.7. The study tests various architectures including ReLU+L1, TopK, and Gated SAEs.

## Key Results
- Only 30% of features are shared across seeds in Llama 3 8B SAEs with 131K latents
- Overlap decreases as number of latents increases and as k (active latents in TopK) increases
- Distribution of matched cosine similarities shows two modes: high-similarity "shared" features and low-similarity "orphan" features
- Orphan features are often interpretable, suggesting individual SAE training runs miss many useful features

## Why This Works (Mechanism)

### Mechanism 1: Bijective Feature Alignment via Hungarian Algorithm
- Claim: Optimal matching between SAE latents reveals a bimodal distribution of "shared" versus "orphan" features.
- Mechanism: The Hungarian algorithm computes a bijection maximizing average cosine similarity between encoder (and separately decoder) vectors across two SAEs. A latent is classified as "shared" if both encoder and decoder matchings agree on the counterpart AND both cosine similarities exceed 0.7.
- Core assumption: Permutation symmetry is the only source of latent ordering differences; true feature differences manifest as low cosine similarity after optimal matching.

### Mechanism 2: Nonconvex Loss Landscape Produces Seed-Dependent Local Optima
- Claim: Different random initializations converge to different local optima representing distinct feature decompositions, not merely permutations of a universal set.
- Mechanism: The SAE reconstruction + sparsity loss is nonconvex. Random initialization determines which basin of attraction optimization enters. Larger SAEs (more latents) and larger models increase the degrees of freedom, creating more distinct local optima.
- Core assumption: The local optima genuinely represent different feature decompositions rather than artifacts of insufficient training.

### Mechanism 3: High-Frequency Features Are More Likely Shared Across Seeds
- Claim: Features that fire frequently tend to be discovered by multiple seeds; rare features are often seed-specific.
- Mechanism: High-frequency features contribute more to reconstruction loss and are thus more strongly reinforced during training across seeds. Rare features occupy low-loss regions that optimization may or may not explore depending on initialization.
- Core assumption: Firing frequency reflects feature "importance" rather than dataset bias or SAE artifacts.

## Foundational Learning

- Concept: **Polysemanticity and Superposition**
  - Why needed here: The entire motivation for SAEs is decomposing polysemantic neurons into interpretable features. Without understanding that multiple features can be superposed in single activation dimensions, the paper's treatment of "features" vs. "neurons" is opaque.
  - Quick check question: Can you explain why a neuron activating on both "dog" and "cat" contexts is problematic for interpretability, and how sparse coding addresses this?

- Concept: **Hungarian Algorithm for Assignment Problems**
  - Why needed here: The core methodological contribution is using this algorithm to match features across SAEs. Understanding it requires knowing the assignment problem formulation.
  - Quick check question: Given two sets of N vectors, how would you formulate finding a bijection that maximizes total pairwise similarity as an assignment problem?

- Concept: **Nonconvex Optimization and Local Minima**
  - Why needed here: The paper's explanation for seed dependence relies on nonconvexity of the SAE loss. Understanding why different initializations reach different optima requires grasping basin-of-attraction dynamics.
  - Quick check question: Why might gradient descent on a nonconvex loss function with multiple local minima produce different solutions from different random seeds, even with identical data?

## Architecture Onboarding

- Component map: Input activations -> Encoder projection -> Activation function (sparsification) -> Decoder reconstruction -> Compute loss -> Backprop

- Critical path: Input activations → Encoder matrix (d_model × n_latents) → Activation function (ReLU+L1 or TopK) → Decoder matrix (n_latents × d_model) → Reconstruction → Loss computation

- Design tradeoffs:
  - ReLU+L1 vs TopK: ReLU shows higher seed stability (greater overlap); TopK achieves better sparsity-reconstruction tradeoff but is more seed-dependent
  - Larger n_latents: Higher resolution decomposition but lower seed overlap
  - Longer training: Increases overlap but with diminishing returns

- Failure signatures:
  - Low overlap across seeds (<40%) suggests SAE is not discovering universal features
  - High-firing orphan features indicate interpretable features being missed by single-seed training
  - Consistent low cosine similarity on encoder but high on decoder (or vice versa) may indicate matching artifacts

- First 3 experiments:
  1. Train 2+ SAEs on Pythia 160M layer 6 MLP output with identical data order but different random seeds (32K latents, 8B tokens from The Pile)
  2. Compute cosine similarity matrices between encoder vectors and decoder vectors across SAE pairs. Run Hungarian algorithm to find optimal bijective matching for each.
  3. Classify latents as "shared" if: (a) encoder and decoder matchings agree on counterpart, AND (b) both cosine similarities ≥ 0.7. Report fraction shared.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why is the feature overlap between different SAE seeds significantly lower than theoretical expectations based on loss landscape nonconvexity?
- Basis in paper: The conclusion states, "One might have expected a priori, however, that different local optima would have more feature overlap than we found in this study."
- Why unresolved: The authors identify the nonconvexity of the loss function as the mathematical cause but lack a theoretical explanation for why the resulting local optima diverge so sharply.

### Open Question 2
- Question: Does feature absorption drive the seed dependence observed in SAEs trained on MLP layers?
- Basis in paper: The ablations section notes, "We have found no evidence of feature absorption on the MLP SAEs we trained, but that may be due to the fact that the current metric is not tuned to find absorption on MLP SAEs."
- Why unresolved: Current metrics for detecting absorption are optimized for the residual stream, leaving the role of absorption in MLP seed dependence unverified.

### Open Question 3
- Question: Can hierarchical or compositional SAE designs mitigate the lack of universality and seed consistency?
- Basis in paper: The authors suggest, "We think feature discovery is best viewed as a compositional problem, wherein we look for useful ways of cutting up the activation space... hierarchically."
- Why unresolved: The paper proposes this viewpoint as an alternative to "flat" SAEs but does not experimentally validate if hierarchical approaches yield more stable features across seeds.

## Limitations

- Methodological ambiguity in "shared" feature definition: The 0.7 cosine similarity threshold is arbitrary and likely influences overlap percentages substantially.
- Potential measurement artifacts: The Hungarian algorithm-based matching assumes permutation symmetry is the only source of ordering differences between SAEs.
- Interpretation generalizability: Results are demonstrated primarily on Pythia 160M and Llama 3 8B models, with limited testing on other model families.

## Confidence

- High confidence in the core empirical finding that SAEs trained on identical data with different seeds learn different features.
- Medium confidence in the interpretation that this reflects fundamental nonconvexity of the SAE loss landscape rather than measurement artifacts.
- Medium confidence in the claim that high-frequency features are more likely shared.

## Next Checks

1. **Threshold sensitivity analysis**: Systematically vary the cosine similarity threshold for "shared" feature classification (e.g., 0.6, 0.7, 0.8) and assess how overlap percentages change.

2. **Extended training comparison**: Train SAEs for significantly longer (e.g., 2-4× the original training steps) and measure whether overlap increases substantially.

3. **Feature importance ablation**: For orphan features that fire frequently in single SAEs, measure their contribution to reconstruction loss to determine if they represent optimization artifacts or meaningful but rare features.