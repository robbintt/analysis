---
ver: rpa2
title: An Explainable Hybrid AI Framework for Enhanced Tuberculosis and Symptom Detection
arxiv_id: '2510.18819'
source_url: https://arxiv.org/abs/2510.18819
tags:
- symptom
- disease
- tuberculosis
- detection
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a DISTL-style teacher\u2013student vision\
  \ transformer framework for joint tuberculosis and symptom detection from chest\
  \ X-rays. The model integrates two supervised heads for disease and symptom classification\
  \ with a self-supervised DINO head, trained on lung-segmented images from a composite\
  \ dataset of tuberculosis, COVID-19, normal cases, and seven symptom labels."
---

# An Explainable Hybrid AI Framework for Enhanced Tuberculosis and Symptom Detection

## Quick Facts
- arXiv ID: 2510.18819
- Source URL: https://arxiv.org/abs/2510.18819
- Reference count: 32
- Primary result: 98.85% accuracy in three-class disease classification and 90.09% macro-F1 score in multi-label symptom detection from chest X-rays

## Executive Summary
This paper introduces a DISTL-style teacher–student vision transformer framework for joint tuberculosis and symptom detection from chest X-rays. The model combines two supervised heads for disease and symptom classification with a self-supervised DINO head, trained on lung-segmented images from a composite dataset. The method achieves state-of-the-art performance in both disease classification (98.85% accuracy) and multi-label symptom detection (90.09% macro-F1), outperforming strong CNN baselines. Grad-CAM visualizations demonstrate that model predictions align with annotated symptom regions, supporting clinically relevant decision-making.

## Method Summary
The framework uses a ViT-Small backbone with three heads: DINO for self-supervised learning, disease classification (TB/COVID-19/Normal), and multi-label symptom detection (7 radiological findings). Training proceeds in three phases: supervised learning on labeled data, DISTL self-training across three unlabeled folds, and correction iterations with weighted sampling. Lung segmentation via U-Net preprocessing ensures focus on anatomical regions, while multi-crop augmentation provides both global context and local detail. The model is initialized with CheXpert-pretrained weights and optimized with AdamW using cosine learning rate scheduling.

## Key Results
- Three-class disease classification accuracy of 98.85%, significantly outperforming CNN baselines
- Multi-label symptom detection achieves 90.09% macro-F1 score across seven radiological findings
- Symptom-specific improvements of 35-40 F1 points for small findings (nodule, mass, effusion) compared to disease-only supervision
- Grad-CAM visualizations show model attention aligns with annotated symptom regions, supporting clinical interpretability

## Why This Works (Mechanism)

### Mechanism 1
Joint disease-symptom supervision produces features that are both discriminative for disease classification and sensitive to fine-grained pathological findings. The two supervised heads share a common ViT-Small backbone, meaning gradient signals from both tasks shape the same feature representations. Disease classification provides high-level discriminative pressure while symptom detection forces the backbone to retain fine-grained spatial patterns. The combined loss prioritizes symptom learning, which the authors attribute to symptom features being more transferable to disease discrimination than vice versa.

### Mechanism 2
DISTL-style self-supervised distillation improves sample efficiency under limited labeled data by mixing DINO self-supervision with knowledge distillation before transitioning to pure distillation. The framework leverages both labeled and unlabeled data through three successive folds. During early epochs, the total loss combines DINO loss with distillation loss. After `ssl_epoch`, training transitions to pure distillation. The teacher is updated via EMA of student parameters, stabilizing learning as unlabeled data proportion increases.

### Mechanism 3
Multi-crop training with lung-focused segmentation exposes the network to both global anatomical context and fine local pathological patterns, improving detection of subtle findings. U-Net preprocessing crops images to lung bounding boxes, reducing non-parenchymal artifacts. The student receives two global crops plus 8 local crops, while the teacher processes only global crops. Local crops force attention to fine-grained details, while global crops preserve anatomical relationships.

## Foundational Learning

- **Concept: Self-supervised learning with DINO**
  - Why needed here: The DINO head enables learning from unlabeled CXR images by enforcing consistency between teacher and student representations across different augmented views.
  - Quick check question: Can you explain why DINO uses a centering and sharpening operation on the teacher output, and what would happen if temperature scheduling were removed?

- **Concept: Knowledge distillation in teacher-student frameworks**
  - Why needed here: The DISTL framework transfers teacher predictions to the student via KL divergence and focal BCE.
  - Quick check question: Why does EMA updating for the teacher stabilize training compared to direct gradient updates?

- **Concept: Multi-label classification with class imbalance**
  - Why needed here: Seven symptom labels are highly imbalanced with multi-label co-occurrence.
  - Quick check question: For a symptom appearing in only 12% of images, what happens if the positive weight is set too high versus too low?

## Architecture Onboarding

- **Component map:** Input CXR → U-Net Segmentation → Quality Control → Crop to Lung ROI → Multi-crop Augmentation → ViT-Small Backbone → DINO Head + Disease Head + Symptom Head
- **Critical path:** Lung segmentation quality → multi-crop augmentation correctness → DINO feature alignment → distillation loss convergence → Grad-CAM interpretability validation
- **Design tradeoffs:** Higher local crop count improves fine-grained symptom detection but increases memory; stronger symptom loss weighting prioritizes symptom learning but may underfit disease classification if symptom labels are noisy
- **Failure signatures:** Segmentation failures if masks miss pathologies; pseudo-label collapse if teacher confidence is systematically miscalibrated; multi-crop misalignment if local crops capture mostly background
- **First 3 experiments:**
  1. Ablate segmentation preprocessing: Train on full CXR images without lung cropping; compare disease accuracy and symptom F1 to baseline
  2. Vary multi-crop configuration: Reduce local crops from 8 to 2; measure impact on symptom-wise F1, particularly for small findings
  3. Calibration analysis on pseudo-labels: Track teacher confidence distributions per symptom across DISTL folds

## Open Questions the Paper Calls Out

### Open Question 1
Does the model maintain robustness and calibration during prospective, multi-site clinical validation? The authors explicitly state the need for prospective, multi-site validation with site-specific calibration to address distribution shifts inherent in their retrospective, multi-source dataset.

### Open Question 2
Can explicit localization heads trained with bounding boxes or weak masks improve the precision of symptom localization beyond Grad-CAM? The authors note that Grad-CAM visualizations derived from image-level labels may result in partial localization and propose developing explicit localization heads as key future work.

### Open Question 3
Does the integration of clinical metadata (e.g., age, symptoms, prior imaging) enhance model calibration and reliability? The authors list integrating clinical metadata as a future direction to specifically improve model calibration and robustness beyond the current image-only framework.

## Limitations

- Symptom pseudo-label quality during DISTL self-training is not validated against ground truth, creating potential error amplification for rare findings
- The 10% test split may be insufficient for reliable statistical inference on macro-F1 for imbalanced symptom classes
- Lung segmentation QC thresholds could exclude diagnostically relevant pathologies in apical regions, though this is not explicitly quantified

## Confidence

- **High confidence** in disease classification accuracy (98.85%) given strong baselines and clear patient-wise split methodology
- **Medium confidence** in symptom detection macro-F1 (90.09%) due to potential pseudo-label noise and class imbalance effects
- **Medium confidence** in Grad-CAM interpretability claims, as alignment with ground-truth boxes is demonstrated but not statistically validated across symptoms

## Next Checks

1. Validate pseudo-label calibration: Analyze teacher confidence distributions for each symptom across DISTL folds to identify symptoms with high variance or systematic miscalibration
2. Quantify segmentation impact: Compare model performance when training on full CXR images versus lung-cropped images to measure the effect of preprocessing on subtle finding detection
3. Statistical significance testing: Perform bootstrap resampling on the 10% test set to establish confidence intervals for per-class F1 scores, particularly for rare symptoms like pneumothorax (14.5% prevalence)