---
ver: rpa2
title: Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization
  in MLLMs
arxiv_id: '2509.24491'
source_url: https://arxiv.org/abs/2509.24491
tags:
- preference
- visual
- curriculum
- alignment
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes SCPO, a novel framework for mitigating visual
  hallucinations in multimodal large language models (MLLMs). SCPO addresses the limitations
  of existing preference optimization methods by introducing three key innovations:
  a semantic curriculum preference pairs dataset that provides fine-grained semantic
  contrasts organized by difficulty, a symmetric and bidirectional optimization objective
  that enforces robust vision-language alignment, and a dynamic curriculum-based training
  strategy with iterative reference model updates.'
---

# Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization in MLLMs

## Quick Facts
- **arXiv ID:** 2509.24491
- **Source URL:** https://arxiv.org/abs/2509.24491
- **Reference count:** 40
- **Primary result:** SCPO reduces visual hallucinations by up to 62.9% while preserving general capabilities in MLLMs

## Executive Summary
This paper introduces SCPO (Semantic Curriculum Preference Optimization), a novel framework designed to mitigate visual hallucinations in multimodal large language models. SCPO addresses the limitations of existing preference optimization methods by introducing a semantic curriculum-based approach that provides fine-grained semantic contrasts organized by difficulty. The method demonstrates state-of-the-art performance on hallucination benchmarks, achieving significant reductions in hallucination rates while maintaining general model capabilities.

## Method Summary
SCPO introduces three key innovations: a semantic curriculum preference pairs dataset that provides fine-grained semantic contrasts organized by difficulty, a symmetric and bidirectional optimization objective that enforces robust vision-language alignment, and a dynamic curriculum-based training strategy with iterative reference model updates. The framework leverages supervised fine-tuning data to construct preference pairs and employs a dual-stage training process that alternates between optimization and reference model updates. This approach enables more effective learning of visual concepts while preventing catastrophic forgetting.

## Key Results
- Reduces hallucination rates by up to 62.9% across multiple model scales
- Achieves state-of-the-art performance on hallucination benchmarks
- Improves factuality without compromising overall model performance
- Demonstrates effectiveness across different MLLM architectures

## Why This Works (Mechanism)
SCPO works by addressing the fundamental limitations of existing preference optimization methods in MLLMs. Traditional approaches struggle with limited supervision signals, semantic gap issues, and catastrophic forgetting. SCPO's semantic curriculum provides fine-grained semantic contrasts that are more effective than binary comparisons, while the symmetric bidirectional optimization enforces balanced learning from both correct and incorrect examples. The dynamic curriculum and iterative reference model updates enable progressive learning that adapts to the model's capabilities.

## Foundational Learning

**Multimodal Large Language Models (MLLMs):** AI models that process both visual and textual inputs to generate coherent responses. Why needed: SCPO specifically targets hallucination issues in these models. Quick check: Understand basic MLLM architecture and common hallucination problems.

**Preference Optimization:** A training method that uses preference pairs to guide model behavior. Why needed: SCPO builds upon this framework but improves it for MLLM contexts. Quick check: Review basic preference optimization concepts and limitations.

**Curriculum Learning:** A training strategy that presents examples in increasing order of difficulty. Why needed: SCPO uses semantic curriculum to organize preference pairs. Quick check: Understand how curriculum learning improves model performance.

## Architecture Onboarding

**Component Map:** Raw Image -> Vision Encoder -> Multimodal Encoder -> Preference Optimization Module -> MLLM Output

**Critical Path:** Image processing → Semantic feature extraction → Preference pair construction → Symmetric optimization → Output generation

**Design Tradeoffs:** SCPO trades increased computational overhead for improved hallucination mitigation. The semantic curriculum approach requires more complex data preparation but provides more effective supervision signals.

**Failure Signatures:** Over-reliance on textual context, inability to handle complex visual reasoning, potential for catastrophic forgetting of general capabilities.

**3 First Experiments:**
1. Evaluate SCPO on simple object recognition tasks to verify basic functionality
2. Test performance on binary preference optimization tasks to establish baseline improvements
3. Assess hallucination rates on controlled image-text pairs with known ground truth

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions, but several areas warrant further investigation based on the methodology and results presented.

## Limitations

- Evaluation primarily focuses on object-level hallucinations, with less attention to complex reasoning or contextual hallucinations
- The semantic curriculum dataset may not fully capture real-world scenario diversity
- Performance gains come at the cost of additional computational overhead during training
- Results may not generalize equally well across all MLLM architectures

## Confidence

- **High:** SCPO's effectiveness in reducing object-level hallucinations
- **Medium:** Claims about preserving general capabilities
- **Medium:** SCPO's superiority over existing methods for broader generalization

## Next Checks

1. Evaluate SCPO on more complex hallucination types beyond object-level errors, including contextual and reasoning-based hallucinations
2. Test SCPO's performance across a wider range of MLLM architectures and training regimes to assess generalizability
3. Conduct ablation studies to quantify the individual contributions of each component (semantic curriculum, symmetric optimization, dynamic training) to overall performance improvements