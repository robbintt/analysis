---
ver: rpa2
title: 'CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image
  Diffusion Models'
arxiv_id: '2512.10655'
source_url: https://arxiv.org/abs/2512.10655
tags:
- memorization
- diffusion
- image
- injection
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses memorization in text-to-image diffusion models,
  where models inadvertently reproduce training examples, raising privacy and copyright
  concerns. The authors propose CAPTAIN, a training-free framework that mitigates
  memorization by directly modifying latent features during denoising.
---

# CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models

## Quick Facts
- arXiv ID: 2512.10655
- Source URL: https://arxiv.org/abs/2512.10655
- Authors: Tong Zhang; Carlos Hinojosa; Bernard Ghanem
- Reference count: 39
- Primary result: Training-free framework that reduces memorization in text-to-image diffusion models by injecting semantic features from non-memorized references

## Executive Summary
This paper introduces CAPTAIN, a training-free framework to mitigate memorization in text-to-image diffusion models during inference. The method addresses the privacy and copyright risks of models inadvertently reproducing training examples by modifying latent features during denoising. CAPTAIN combines frequency-based noise initialization, timestep and spatial localization, and semantic feature injection from retrieved reference images. The approach achieves strong memorization mitigation while maintaining semantic alignment, outperforming baseline methods on Stable Diffusion v1.4 and 2.0.

## Method Summary
CAPTAIN operates during the denoising process of text-to-image diffusion models by first decomposing initialization noise into low-frequency components from a retrieved reference image and high-frequency Gaussian noise. Reference images are selected through an attention-based keyword extraction system combined with multi-criteria scoring (semantic similarity, novelty, and perceptual similarity). The framework identifies an optimal injection window [141,341] based on CLIP score derivatives and applies spatial localization using BE masks combined with concept attention masks. Semantic features are then injected into localized regions during this window using a weighted combination of the current latent and reference latent features, with the injection strength controlled by a parameter δ=0.1.

## Key Results
- CAPTAIN achieves CLIP score of 0.292 and SSCD of 0.250 on Stable Diffusion v1.4, outperforming BE (CLIP 0.275, SSCD 0.400) and PRSS (CLIP 0.210, SSCD 0.230)
- Maintains strong performance on Stable Diffusion 2.0 with CLIP 0.258 and SSCD 0.202
- Successfully balances memorization mitigation with semantic alignment across multiple diffusion models
- Demonstrates effectiveness through quantitative metrics and qualitative visual comparisons

## Why This Works (Mechanism)
CAPTAIN works by strategically injecting semantically relevant but non-memorized features during the denoising process. By decomposing initialization into frequency components, it preserves high-frequency details while introducing meaningful low-frequency structure from external references. The injection window localization ensures features are introduced at the optimal denoising timestep when the model is most receptive to modification. Spatial localization via BE and concept attention masks ensures injection occurs only in regions relevant to the memorized content, minimizing semantic drift. The weighted injection approach gradually steers generation away from memorized patterns while maintaining coherence with the prompt.

## Foundational Learning
- **Diffusion model denoising**: Understanding how latent features evolve during the reverse diffusion process is essential for timing feature injection correctly. Quick check: Verify denoising trajectory visualization shows smooth feature evolution.
- **Frequency decomposition in images**: Knowledge of Fourier transforms and frequency masking is needed to properly blend reference and noise components. Quick check: Confirm frequency masks separate low and high frequencies as intended.
- **Attention mechanisms in transformers**: Required for extracting relevant keywords and computing concept attention masks for spatial localization. Quick check: Validate attention weights highlight semantically relevant words.
- **CLIP model embeddings**: Understanding how CLIP computes image-text similarity is crucial for both reference retrieval and injection window identification. Quick check: Ensure CLIP scores correlate with visual-semantic alignment.
- **BE (Brute-force Extrapolation) masks**: Familiarity with BE mask computation for identifying memorized regions is necessary for spatial localization. Quick check: Verify BE masks correctly highlight generated content matching training examples.

## Architecture Onboarding

Component Map: Prompt -> Attention-based keyword extraction -> Reference retrieval (Pexels/Unsplash + FAISS scoring) -> Frequency initialization (low+high) -> Denoising pipeline -> BE mask + concept attention mask -> Injection window [141,341] -> Semantic feature injection -> Generated image

Critical Path: The most critical sequence is Prompt → Reference retrieval → Frequency initialization → Injection window identification → Semantic feature injection. Each step depends on the previous: without quality references, frequency initialization fails; without proper injection timing, features are introduced too early or late; without correct spatial localization, injection affects irrelevant regions.

Design Tradeoffs: CAPTAIN trades computational overhead (reference retrieval, mask computation) for training-free memorization mitigation. The frequency decomposition preserves high-frequency details but requires careful threshold selection. Spatial localization via mask intersection reduces false positives but may miss some memorized regions. The injection strength parameter δ balances memorization mitigation against semantic drift.

Failure Signatures: Empty spatial masks indicate poor overlap between BE and concept attention masks, suggesting the model isn't properly identifying memorized regions. Low CLIP scores on generated images suggest semantic drift from excessive feature injection. High SSCD scores indicate insufficient memorization mitigation, possibly from weak injection strength or incorrect timing.

First Experiments: 1) Test frequency initialization with various cutoff thresholds on a single prompt to observe impact on SSCD. 2) Validate reference retrieval scoring by comparing top-5 candidates' semantic similarity and novelty scores. 3) Implement and visualize BE masks and concept attention masks separately to confirm they highlight expected regions.

## Open Questions the Paper Calls Out
None identified in the paper.

## Limitations
- Requires external reference image retrieval which may fail if no suitable non-memorized images are available for certain prompts
- Performance depends on the quality and diversity of the reference image dataset (Pexels/Unsplash)
- Computational overhead from reference retrieval and mask computation during inference
- Potential for semantic drift if injection strength or timing is not properly calibrated

## Confidence
- High confidence: Core framework design (frequency initialization + localized semantic injection) and overall effectiveness direction (SSCD ↓, CLIP ↑ vs baselines)
- Medium confidence: Numerical results on Stable Diffusion v1.4 (due to unknown parameter specifics that could shift scores ±0.02)
- Low confidence: Stable Diffusion 2.0 performance claims (only one metric pair reported, no baseline comparisons provided)

## Next Checks
1. Implement and validate the frequency mask design by testing multiple cutoff thresholds and measuring their impact on SSCD reduction
2. Verify concept attention mask extraction by visualizing masks for sample prompts and confirming spatial alignment with memorized content
3. Benchmark against PRSS and BE baselines on the same 500-prompt test set to confirm relative performance margins claimed in the paper