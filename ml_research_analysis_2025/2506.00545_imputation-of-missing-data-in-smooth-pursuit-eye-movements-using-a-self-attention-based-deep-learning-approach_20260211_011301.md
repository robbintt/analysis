---
ver: rpa2
title: Imputation of Missing Data in Smooth Pursuit Eye Movements Using a Self-Attention-based
  Deep Learning Approach
arxiv_id: '2506.00545'
source_url: https://arxiv.org/abs/2506.00545
tags:
- missing
- data
- imputation
- sequences
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of imputing missing data in
  smooth pursuit eye movement (SPEM) sequences, which are often disrupted by eye blinks
  and tracking losses. A novel framework combining Self-Attention-based Imputation
  for Time Series (SAITS) with a refinement autoencoder (RAE) is proposed to reconstruct
  missing segments accurately.
---

# Imputation of Missing Data in Smooth Pursuit Eye Movements Using a Self-Attention-based Deep Learning Approach

## Quick Facts
- arXiv ID: 2506.00545
- Source URL: https://arxiv.org/abs/2506.00545
- Authors: Mehdi Bejani; Guillermo Perez-de-Arenaza-Pozo; Julián D. Arias-Londoño; Juan I. Godino-LLorente
- Reference count: 34
- Primary result: SAITS-RAE achieves MAE of 0.10, MRE of 0.71, RMSE of 0.13 on SPEM sequences

## Executive Summary
This paper addresses the challenge of imputing missing data in smooth pursuit eye movement (SPEM) sequences, which are often disrupted by eye blinks and tracking losses. A novel framework combining Self-Attention-based Imputation for Time Series (SAITS) with a refinement autoencoder (RAE) is proposed to reconstruct missing segments accurately. The method leverages SAITS's ability to capture complex temporal dependencies and uses RAE to restore fine-grained details lost during downsampling. Tested on 5,504 SPEM sequences from 172 participants, the approach achieves superior performance over traditional methods like PCHIP and SSA, with a mean absolute error (MAE) of 0.10, mean relative error (MRE) of 0.71, and root mean square error (RMSE) of 0.13. It also preserves frequency-domain characteristics and demonstrates robustness in handling large missing intervals. The SAITS-RAE method offers a reliable solution for improving SPEM data analysis in clinical diagnostics.

## Method Summary
The proposed framework employs a two-stage approach: SAITS for initial imputation and RAE for refinement. SAITS uses self-attention mechanisms to model long-range temporal dependencies and generate initial estimates for missing segments. The data is then upsampled and passed through the RAE, which reconstructs high-resolution details using convolutional layers. The model is trained on a large dataset of SPEM sequences with artificially introduced missing intervals. The framework is evaluated using metrics including MAE, MRE, RMSE, and spectral similarity measures. Ablation studies confirm the effectiveness of each component in the pipeline.

## Key Results
- Achieves MAE of 0.10, MRE of 0.71, and RMSE of 0.13 on SPEM sequences
- Outperforms traditional methods (PCHIP, SSA) and demonstrates robustness for large missing intervals
- Preserves frequency-domain characteristics of original SPEM signals

## Why This Works (Mechanism)
The SAITS-RAE framework effectively combines the strengths of self-attention mechanisms for capturing long-range temporal dependencies with the detail-preserving capabilities of convolutional autoencoders. SAITS handles the complex temporal patterns inherent in eye movement data, while RAE restores high-frequency details lost during downsampling. This dual approach addresses both the structural and fine-grained aspects of SPEM data reconstruction.

## Foundational Learning
- **Self-Attention Mechanisms**: Essential for capturing long-range dependencies in time series data; quick check: verify attention weights reflect meaningful temporal relationships
- **Time Series Imputation**: Critical for handling missing data in sequential signals; quick check: ensure imputed values maintain temporal coherence
- **Convolutional Autoencoders**: Used for detail restoration in upsampled data; quick check: validate reconstruction quality on clean test data
- **Smooth Pursuit Eye Movements**: Complex biological signals requiring preservation of both temporal and spectral characteristics; quick check: compare frequency spectra of original and imputed data
- **Data Augmentation**: Artificial introduction of missing intervals for training robustness; quick check: verify augmentation strategy covers realistic missing patterns
- **Spectral Analysis**: Important for validating preservation of signal characteristics; quick check: perform FFT comparison between original and imputed sequences

## Architecture Onboarding

Component map: Raw SPEM Data -> SAITS Imputation -> RAE Refinement -> Imputed SPEM Data

Critical path: The core workflow involves downsampling raw SPEM data, applying SAITS for initial imputation, upsampling the imputed data, and passing it through RAE for final refinement. Each component is trained separately but operates as an integrated pipeline.

Design tradeoffs: The downsampling step reduces computational complexity but may lose fine details. SAITS prioritizes temporal coherence over local accuracy. RAE compensates for this by restoring high-frequency components, but adds computational overhead.

Failure signatures: Poor performance may manifest as:
- Inaccurate reconstruction of rapid eye movements
- Spectral distortions in the frequency domain
- Over-smoothing of sharp transitions in the signal

First experiments:
1. Test SAITS alone on data with small missing intervals to establish baseline performance
2. Evaluate RAE's ability to restore details on artificially degraded clean data
3. Perform ablation study removing RAE to quantify its contribution to final accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Limited generalizability to other types of eye movement data or broader time series applications
- Validation conducted exclusively on healthy subjects, raising questions about performance on clinical populations
- Computational efficiency and scalability for real-time applications not thoroughly evaluated

## Confidence

High confidence:
- The reported quantitative results (MAE of 0.10, MRE of 0.71, RMSE of 0.13) are methodologically sound and well-documented
- The superiority over traditional methods is convincingly demonstrated with appropriate statistical measures

Medium confidence:
- The preservation of frequency-domain characteristics is supported but could benefit from more detailed spectral analysis
- The robustness claims for handling large missing intervals are based on reasonable experimental design but would benefit from testing across a wider range of missing data patterns

Low confidence:
- The clinical applicability claims lack validation through actual diagnostic performance metrics
- The method's performance in scenarios with overlapping artifacts (e.g., simultaneous blinks and tracking losses) was not thoroughly explored

## Next Checks
1. Cross-validation on diverse eye movement datasets including clinical populations with known oculomotor deficits to assess generalizability beyond healthy subjects
2. Head-to-head comparison with state-of-the-art deep learning imputation methods developed after 2023 to establish relative performance in the current research landscape
3. Real-time implementation and benchmarking to evaluate computational efficiency and latency, particularly for potential clinical deployment where processing speed is critical