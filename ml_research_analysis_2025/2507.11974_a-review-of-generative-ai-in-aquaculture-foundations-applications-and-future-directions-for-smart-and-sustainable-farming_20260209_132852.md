---
ver: rpa2
title: 'A Review of Generative AI in Aquaculture: Foundations, Applications, and Future
  Directions for Smart and Sustainable Farming'
arxiv_id: '2507.11974'
source_url: https://arxiv.org/abs/2507.11974
tags:
- aquaculture
- generative
- systems
- data
- review
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This review provides the first comprehensive synthesis of Generative\
  \ AI (GAI) applications in aquaculture, mapping core architectures\u2014such as\
  \ diffusion models, transformers, and retrieval-augmented generation\u2014to diverse\
  \ tasks including underwater perception, robotic planning, disease diagnostics,\
  \ and infrastructure monitoring. It demonstrates GAI\u2019s potential to bridge\
  \ data scarcity, automate decision-making, and enhance sustainability across the\
  \ aquaculture value chain."
---

# A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming

## Quick Facts
- arXiv ID: 2507.11974
- Source URL: https://arxiv.org/abs/2507.11974
- Reference count: 40
- First comprehensive synthesis of Generative AI (GAI) applications in aquaculture, mapping core architectures to diverse tasks.

## Executive Summary
This review provides the first comprehensive synthesis of Generative AI (GAI) applications in aquaculture, mapping core architectures—such as diffusion models, transformers, and retrieval-augmented generation—to diverse tasks including underwater perception, robotic planning, disease diagnostics, and infrastructure monitoring. It demonstrates GAI's potential to bridge data scarcity, automate decision-making, and enhance sustainability across the aquaculture value chain. The work consolidates recent experimental systems, prototypes, and real-world deployments, while critically analyzing limitations around data quality, real-time performance, trust, regulation, and environmental impact. By offering an updated application taxonomy and detailed technical insights, the review positions GAI not merely as a tool but as an enabler of smart, resilient, and environmentally aligned aquaculture systems.

## Method Summary
The study conducted a systematic literature review of Scopus-indexed publications from 2021–2025 using queries combining "Generative AI" or "LLM" with "aquaculture" or "fisheries." Papers were screened for scope and classified into four domains: Sensing, Robotics, Planning, and Communication. The review synthesized technical mappings of GAI architectures (Diffusion, Transformers, GANs, VAEs, RAG) to specific aquaculture applications, supplemented by case studies (e.g., OceanChat, Digital Twins). Ambiguities remain in defining the boundary between generative and discriminative models, and exact search queries or inclusion criteria are not fully specified.

## Key Results
- GAI architectures (diffusion models, transformers, GANs, VAEs, RAG) can be mapped to aquaculture tasks across sensing, robotics, planning, and communication.
- Synthetic data generation addresses underwater data scarcity, enabling training of robust perception models.
- LLMs and VLMs enable adaptive robotic mission planning and decision support via natural language interfaces.
- RAG systems enhance decision support by anchoring generative outputs in verifiable regulatory and operational documents.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Generative AI may improve the robustness of underwater perception systems (e.g., fish detection, net inspection) by alleviating data scarcity through synthetic augmentation.
- **Mechanism:** Diffusion models and GANs learn the latent distribution of limited real-world underwater imagery. They then synthesize high-fidelity, annotated variants (e.g., varying turbidity, biofouling levels) to train discriminative models (like CNNs) that would otherwise overfit or fail due to lack of diverse training data.
- **Core assumption:** The synthetic data distribution closely approximates the real-world operational environment (minimizing the *sim-to-real* gap); features learned from generated images transfer effectively to physical sensor inputs.
- **Evidence anchors:**
  - [abstract] Mentions GAI's potential to "bridge data scarcity."
  - [Section 3.1.5] Explicitly states GAI addresses data scarcity by generating realistic synthetic datasets for object detection and segmentation.
  - [corpus] Weak support; neighbor papers focus on medical imaging and animation, confirming the general utility of generative models for data augmentation but not specific to aquaculture.
- **Break condition:** Performance degrades if the generative model hallucinates features unrealistic to the specific aquaculture environment (e.g., incorrect species textures), creating negative transfer during discriminative training.

### Mechanism 2
- **Claim:** Large Language Models (LLMs) may enable adaptive robotic mission planning by translating high-level natural language intent into low-level control code or waypoint sequences.
- **Mechanism:** Transformer-based LLMs map unstructured text commands (e.g., "Inspect the southwest net corner") to structured robotics middleware (e.g., ROS nodes) or behavior trees. This allows operators to bypass manual coding, facilitating rapid replanning in response to dynamic environmental changes.
- **Core assumption:** The LLM possesses sufficient grounding in the robot's kinematic constraints and the environment's spatial logic to generate feasible, collision-free trajectories; the system includes a safety layer to verify generated plans.
- **Evidence anchors:**
  - [abstract] Highlights "autonomous planning for ROV missions."
  - [Section 3.2.2] Describes "MissionGPT" and "OceanChat" as systems using transformer architectures for symbolic mission generation from textual prompts.
  - [corpus] "Generative AI for Character Animation" neighbor paper supports the concept of generative models producing complex sequences, though applied to motion graphics rather than marine robotics.
- **Break condition:** The mechanism fails if the LLM suffers from "hallucination," generating syntactically correct but logically dangerous commands (e.g., plotting a path through a physical obstruction not present in its training data).

### Mechanism 3
- **Claim:** Retrieval-Augmented Generation (RAG) systems may enhance decision support for farm management by anchoring generative responses in verifiable regulatory and operational documents.
- **Mechanism:** Instead of relying solely on pre-trained weights, a RAG architecture retrieves relevant chunks from specific knowledge bases (e.g., government regulations, disease libraries) and feeds them into the LLM context window. This constrains the output, reducing factual inaccuracies in advisory tasks.
- **Core assumption:** The retrieval mechanism accurately identifies the relevant context for the query, and the generative model effectively synthesizes this context without ignoring it in favor of its internal (potentially outdated) pre-trained knowledge.
- **Evidence anchors:**
  - [abstract] Lists "retrieval-augmented generation" as a core architecture.
  - [Section 3.4.2 & 6.7] Suggests RAG is used for enhancing awareness of government programs and "Environmental Intelligence."
  - [corpus] No direct evidence in the provided corpus neighbors regarding RAG specifically in this domain.
- **Break condition:** The system provides outdated or generic advice if the external knowledge base is not synchronized with the latest local regulations or if the retrieval step fails to find the specific document section required.

## Foundational Learning

- **Concept: Generative Adversarial Networks (GANs) vs. Diffusion Models**
  - **Why needed here:** These are the primary engines for creating synthetic visual data (fish images, net defects). Understanding the difference is crucial: GANs are often faster for inference, while Diffusion models typically offer higher fidelity and stability for image generation.
  - **Quick check question:** Which architecture is better suited for generating a high-resolution dataset of rare diseased fish lesions where training stability is a major concern?

- **Concept: Transformers and Self-Attention**
  - **Why needed here:** This architecture underpins the LLMs and Vision-Language Models (VLMs) used for mission planning and multimodal perception. Self-attention allows the model to weigh the relationship between different sensor inputs (e.g., correlating a drop in Dissolved Oxygen with fish behavior changes).
  - **Quick check question:** How does the self-attention mechanism allow an LLM to connect a user's text command with a specific visual anomaly detected by an ROV?

- **Concept: Sim-to-Real Transfer**
  - **Why needed here:** The paper discusses "Digital Twins" and synthetic data. A critical failure mode is when a robot trained in a generative simulation fails in the physical world due to unmodeled physics (e.g., water current drag).
  - **Quick check question:** What is "domain randomization," and how might it be used when training an ROV inspection agent in a generative simulation to ensure it works in a real net pen?

## Architecture Onboarding

- **Component map:** Data Ingestion (Sensor fusion) -> Context Retrieval (if RAG) -> Generative Inference (LLM/World Model) -> Verification/Safety Filter -> Actuation/Report
- **Critical path:** Data Ingestion (Sensor fusion) -> Context Retrieval (if RAG) -> Generative Inference (LLM/World Model) -> Verification/Safety Filter -> Actuation/Report
- **Design tradeoffs:**
  - **Latency vs. Reasoning:** Heavier generative models (e.g., GPT-4 class) offer better reasoning for complex diagnostics but introduce latency incompatible with real-time collision avoidance. Lightweight quantized models or distilled versions are needed for edge deployment on buoys/ROVs.
  - **Generalization vs. Specificity:** General-purpose models (e.g., generic ChatGPT) offer broad advisory capabilities but lack precision in identifying specific aquatic diseases. Domain-specific pre-training (fine-tuning on aquaculture datasets) is required but increases development cost.
- **Failure signatures:**
  - **Hallucinated Pathogens:** The LLM invents a disease name that sounds plausible but does not exist, leading to incorrect treatment advice.
  - **Perception Drift:** The generative vision model, trained on clear water, fails to distinguish biofouling from fish schools in turbid conditions (domain shift).
  - **Prompt Injection:** A malicious or accidental input confuses the robot's control LLM, causing it to ignore safety protocols.
- **First 3 experiments:**
  1. **Synthetic vs. Real Training:** Train a YOLO (object detection) model on real fish images vs. a 50/50 mix of real + GAN-generated synthetic fish images. Compare mAP (mean Average Precision) on a held-out test set.
  2. **RAG Advisory Accuracy:** Build a basic RAG pipeline using 10 aquaculture regulation PDFs. Query the system with 20 specific compliance questions and measure the factual accuracy of the generated answers against a human expert baseline.
  3. **Language-to-Mission:** Implement a simple "MissionGPT" loop using a small LLM (e.g., Llama-3-8B) to convert text commands into a JSON list of waypoints for a simulated BlueROV2 in the Stonefish simulator. Verify successful navigation.

## Open Questions the Paper Calls Out

- **Question:** What is the quantifiable performance gap between general-purpose foundation models and domain-specific pre-trained models for aquaculture tasks, and how much domain-specific data is needed to close this gap?
  - **Basis in paper:** [explicit] "Despite the success of general-purpose foundation models, their performance often degrades when applied to underwater robotics and aquaculture-specific tasks. Domain-specific pretraining... can improve model robustness and contextual understanding." (Section 6.3)
  - **Why unresolved:** The paper advocates for domain-specific pretraining but provides no empirical benchmarks comparing generalist vs. specialist models, nor specifies minimum dataset requirements for effective adaptation.
  - **What evidence would resolve it:** A systematic comparison of models pre-trained on aquaculture datasets (e.g., underwater imagery, sonar, operational logs) against generalist models across standardized tasks, with analysis of data volume thresholds.

- **Question:** Can GAI models for aquaculture be compressed (via pruning, quantization, distillation) to run on edge devices without unacceptable degradation in task-specific accuracy, and what accuracy-latency trade-offs are acceptable for real-time operations?
  - **Basis in paper:** [explicit] "Model compression strategies, such as pruning, quantization, and knowledge distillation, offer partial solutions but often degrade performance if not carefully tuned for specific modalities." (Section 5.2)
  - **Why unresolved:** The paper identifies the real-time deployment challenge but lacks empirical data on acceptable performance thresholds for edge deployment in harsh aquaculture environments.
  - **What evidence would resolve it:** Benchmarks of compressed GAI models running on representative edge hardware (e.g., embedded GPUs, TPUs) for critical tasks like disease detection or biomass estimation, with measured accuracy and latency metrics.

- **Question:** How can federated learning be adapted to the bandwidth-limited, hardware-constrained environment of aquaculture farms to enable collaborative model training without sharing raw data?
  - **Basis in paper:** [explicit] "Key research challenges include designing robust federated algorithms for aquaculture datasets, developing secure aggregation protocols, and ensuring real-time learning performance in bandwidth-limited and hardware-constrained environments." (Section 6.2)
  - **Why unresolved:** Federated learning is proposed for privacy-preserving collaboration, but aquaculture-specific constraints (low connectivity, heterogeneous sensors) remain unaddressed in current implementations.
  - **What evidence would resolve it:** Pilot studies of federated GAI systems across multiple geographically distributed aquaculture farms, demonstrating convergence rates and communication overhead under realistic network conditions.

## Limitations
- **Data Scarcity vs. Generalization Gap:** The extent to which synthetic underwater imagery closes the operational gap (sim-to-real transfer) is uncertain; real-world domain shifts in turbidity and biofouling may degrade performance.
- **Deployment Viability in Real-Time:** It is unclear whether edge-optimized models can retain sufficient reasoning capability for critical tasks like complex mission planning or rare disease identification under latency constraints.
- **Regulatory and Trust Gaps:** RAG systems require continuous synchronization with evolving regulations and lack clear auditability for accountability, which the paper does not fully address.

## Confidence

- **High Confidence:** The technical mapping of GAI architectures (Diffusion, Transformers, GANs, VAEs, RAG) to aquaculture tasks is well-supported by literature and demonstrates a clear conceptual framework. The identification of data scarcity as a primary challenge is consistent with industry reports.
- **Medium Confidence:** The practical effectiveness of GAI for real-time robotic planning and perception under dynamic underwater conditions is plausible but under-validated. The review cites prototypes and case studies, but field trial data demonstrating robust performance across varied environments is limited.
- **Low Confidence:** Claims about GAI's environmental sustainability benefits (e.g., reducing waste, optimizing feeding) are largely speculative, based on potential rather than demonstrated impact. The paper acknowledges this but does not quantify trade-offs (e.g., energy cost of large models vs. operational savings).

## Next Checks
1. **Synthetic Data Fidelity Test:** Conduct a controlled experiment comparing the performance of a fish detection model trained on real vs. GAN-synthesized underwater imagery, measuring mAP on a held-out real dataset to quantify the sim-to-real transfer gap.
2. **Real-Time LLM Planning Feasibility:** Implement and benchmark a lightweight LLM (e.g., Llama-3-8B quantized) for converting text commands to waypoint sequences in a simulated ROV environment, measuring both task success rate and inference latency under edge deployment constraints.
3. **RAG Regulatory Accuracy Audit:** Build a RAG system using a curated set of aquaculture regulations and test it with 50 compliance queries, comparing the factual accuracy and completeness of its responses against a human domain expert baseline, tracking sources of errors (retrieval vs. generation).