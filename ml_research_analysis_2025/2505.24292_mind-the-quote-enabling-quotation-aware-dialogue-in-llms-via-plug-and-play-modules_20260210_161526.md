---
ver: rpa2
title: 'Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play
  Modules'
arxiv_id: '2505.24292'
source_url: https://arxiv.org/abs/2505.24292
tags:
- answer
- quoted
- user
- quada
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper formalizes span-conditioned generation for quotation-aware
  dialogue, enabling LLMs to locate and exploit specific text spans from conversation
  history. The authors propose QuAda, a lightweight training-based method that dynamically
  modulates attention to quoted spans via two bottleneck projections per attention
  head, requiring less than 2.8% additional parameters.
---

# Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules

## Quick Facts
- **arXiv ID:** 2505.24292
- **Source URL:** https://arxiv.org/abs/2505.24292
- **Reference count:** 40
- **Primary result:** QuAda achieves >90% accuracy across five diagnostic quotation-aware dialogue scenarios while using <2.8% additional parameters.

## Executive Summary
This paper addresses the challenge of enabling large language models to properly attend to and utilize specific text spans from conversation history during dialogue generation. The authors formalize this as "span-conditioned generation" and propose QuAda, a lightweight training-based method that dynamically modulates attention to quoted spans via two bottleneck projections per attention head. The approach maintains base model capabilities while adding less than 2.8% parameters. Experiments across five diagnostic scenarios (single span, multiple spans, exclusion, context integration, and coreference resolution) on two model scales show consistent performance improvements over baselines, achieving over 90% accuracy in most tasks while maintaining fluency.

## Method Summary
QuAda introduces span-conditioned attention by attaching two bottleneck MLPs per attention head: Eq for query-side biasing and Ev for value-side enrichment. The method receives token-offset quotation spans R and question start position sq as additional inputs. For tokens within quotation spans, Eq produces a bias vector that modulates attention scores toward or away from quoted content based on task intent, while Ev produces a strengthen vector that enriches the value representations of quoted tokens. The backbone LLM remains frozen during training, with only the adapter parameters updated. The bottleneck width r=256 achieves strong performance across scenarios with minimal parameter overhead (2.8% on Qwen2.5-3B, 1.6% on Llama3.1-8B).

## Key Results
- QuAda achieves 94.8% accuracy on single-span BASE scenario and 92.8% on multi-span MULTI
- The method reaches 87.6% on EXCLUDE scenario where models must ignore quoted spans
- Full method achieves 85.8% on INFO-COMBINE (integrating quote with context) vs 75.0% for value-only
- Maintains fluency while demonstrating strong generalization to unseen topics

## Why This Works (Mechanism)

### Mechanism 1
Value-side enrichment recovers most performance gains by strengthening token representations. A bottleneck MLP (Ev) produces a strengthen vector for tokens inside quotation spans, replacing vj with ṽj = vj + 1_j∈R · bv_j. This enriches cached value vectors without reprocessing history. Quoted tokens carry task-critical information that standard representations under-express. Evidence: value-only achieves 94.8% BASE, 92.8% MULTI, 87.6% EXCLUDE—near full method performance.

### Mechanism 2
Query-side biasing enables intent-adaptive attention steering (amplify or suppress). A bottleneck MLP (Eq) produces bq_i for queries from the current question. The attention score becomes (qi + 1_j∈R · bq_i)⊤kj, selectively biasing scores toward/outside quoted spans based on task demands. Models can learn to associate intent patterns with span-relevance directions in query space. Evidence: attention heatmaps show dark bands at quoted spans for BASE/MULTI, pale regions for EXCLUDE—confirming adaptive direction.

### Mechanism 3
Query-value synergy is essential for context-aware integration (INFO-COMBINE scenario). Query branch directs attention to relevant regions; value branch supplies enriched content. Together they enable merging quoted spans with surrounding context without over-focusing. Complex tasks require both WHERE to attend (query) and WHAT to retrieve (value). Evidence: full method achieves 85.8% on INFO-COMBINE vs. 75.0% for value-only (+10.8%).

## Foundational Learning

- **Self-attention query-key-value decomposition**: Why needed: QuAda modifies both query and value branches independently; understanding their roles is prerequisite. Quick check: Can you explain why modifying the value vector affects what information is retrieved, while modifying the query affects which positions are attended to?

- **Bottleneck projections (low-rank adapters)**: Why needed: QuAda uses 2dr + 2rd parameters per head (r ≪ d), keeping overhead <2.8%. Quick check: Why does a bottleneck width of r=64 already achieve >94% on three tasks? What does this suggest about the dimensionality of span-conditioned behavior?

- **Token-offset span representation**: Why needed: The formalization uses (sl, el) pairs as input alongside dialogue history—this is the external interface contract. Quick check: How should your system handle overlapping spans or spans that cross turn boundaries?

## Architecture Onboarding

- **Component map:** Input layer (tokenized history H + span offsets R + question span Q) -> Per-head adapters (2 bottleneck MLPs Eq, Ev) -> Indicator function (1_j∈R computed from R offsets) -> Frozen backbone (all original LLM weights unchanged)

- **Critical path:**
  1. Receive span offsets R = {(sl, el)} and question start sq
  2. Compute 1_j∈R for all tokens in KV cache
  3. For each generation step i ≥ sq: compute bq_i = Eq(qi)
  4. Apply query bias to attention scores: qi⊤kj + 1_j∈R · (bq_i)⊤kj
  5. Apply value enrichment: ṽj = vj + 1_j∈R · Ev(vj)
  6. Continue standard attention computation with modified scores/values

- **Design tradeoffs:** Smaller r (64) is sufficient for most tasks; r=256 chosen for robustness across scenarios. Training on synthetic data enables scale but requires automated validity checks. Excluding backbone updates preserves base capabilities but limits cross-task transfer.

- **Failure signatures:** EXCLUDE scenario underperforms: Check if query bias direction is learned correctly (should suppress, not amplify). COREF accuracy drops: Verify span offsets are token-accurate, not character-accurate. Fluency degrades: Ensure adapters are only active for i ≥ sq (not for history encoding).

- **First 3 experiments:**
  1. **Sanity check:** Run value-only vs. query-only ablations on BASE scenario—should replicate Table 7 gap (94.8% vs. 78.8%).
  2. **Span encoding test:** Pass intentionally corrupted offsets (shifted by ±1 token) and measure BASE accuracy drop—establishes sensitivity to offset precision.
  3. **Cross-topic generalization:** Train on 67 topics, evaluate on held-out 35—verify >90% accuracy maintained (per Section 4.2 claims).

## Open Questions the Paper Calls Out

### Open Question 1
How does QuAda perform when extended to multimodal quotation tasks involving images, tables, or code blocks? The Conclusion states the work is "confined to monomodal, monolingual quotation" and identifies extending the adapter to multimodal inputs as a necessary step for future work. Adapting this mechanism to non-text modalities requires new methods for defining "spans" and potentially different projection architectures.

### Open Question 2
Can the QuAda mechanism effectively manage cross-lingual quotation where the quoted text and the user's intent are in different languages? The authors note the adapter is trained and evaluated "solely on English text spans" and have not experimented with "multilingual settings—such as quoting a French sentence within an English dialogue." It is unclear if the lightweight bottleneck projections can bridge the representation gap between languages in a frozen backbone.

### Open Question 3
Does the effectiveness of QuAda degrade in extremely long-context scenarios where the quoted span is distant from the current query? The dataset attributes limit conversation history length to 1–10 turns, leaving the method's performance on very long conversations unverified. While the method avoids prompt inflation, attention mechanisms often struggle with long-range dependencies.

## Limitations
- Synthetic data generation pipeline relies on automated validity checks without specified acceptance thresholds or inter-annotator agreement metrics
- Evaluation depends heavily on GPT-4o-mini judge for open-ended consistency with limited discussion of potential judge bias
- Generalization claims to real-world quotation-aware dialogue are not validated on authentic conversational datasets

## Confidence

**High Confidence:** The core architectural contribution is clearly specified and the synthetic data generation pipeline is reproducible. The performance gains over baselines (90%+ accuracy on most scenarios) are consistently demonstrated across two model scales with well-defined ablation studies.

**Medium Confidence:** The claim that query-value synergy is essential for INFO-COMBINE relies on controlled synthetic data where this scenario may be artificially constructed rather than emergent from natural dialogue patterns.

**Low Confidence:** Generalization claims to real-world quotation-aware dialogue are not validated on authentic conversational datasets. The 90% accuracy benchmark comes from synthetic data where the model's own generation pipeline created both training and test examples.

## Next Checks

1. **Real-world generalization test:** Evaluate QuAda on authentic dialogue datasets containing natural quotations (e.g., debate transcripts, interview data) to verify performance doesn't degrade when moving from synthetic to natural quotation patterns.

2. **Attention mechanism validation:** Conduct targeted intervention studies where specific span representations are perturbed to confirm that query-side biasing and value-side enrichment have the hypothesized directional effects on attention distribution.

3. **Robustness to span encoding errors:** Systematically introduce token-level offset errors (±1 to ±3 tokens) and measure performance degradation across all scenarios to establish sensitivity to span encoding precision, which directly impacts practical deployment.