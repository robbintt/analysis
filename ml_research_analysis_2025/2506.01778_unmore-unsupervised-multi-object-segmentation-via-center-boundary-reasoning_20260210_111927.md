---
ver: rpa2
title: 'unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning'
arxiv_id: '2506.01778'
source_url: https://arxiv.org/abs/2506.01778
tags:
- object
- proposal
- center
- objects
- boundary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses unsupervised multi-object segmentation in
  single images, a challenging task due to unclear object definitions and ineffective
  discovery methods. Existing approaches relying on reconstruction objectives or pretrained
  features struggle with complex real-world scenes.
---

# unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning

## Quick Facts
- **arXiv ID:** 2506.01778
- **Source URL:** https://arxiv.org/abs/2506.01778
- **Reference count:** 40
- **Primary result:** 32.6 APbox@50 on COCO* validation set, outperforming prior unsupervised approaches

## Executive Summary
This paper addresses the challenge of unsupervised multi-object segmentation in single images, where object definitions are unclear and discovery methods are ineffective. The authors propose unMORE, a two-stage pipeline that first learns explicit object-centric representations (existence, center field, and boundary distance field) from monolithic object images, then applies a network-free multi-object reasoning module to discover objects. The method significantly outperforms existing approaches on 6 real-world datasets, achieving state-of-the-art performance particularly in crowded images where baselines fail.

## Method Summary
The method consists of two stages: First, an Objectness Network is trained on monolithic object images to predict three explicit representations: object existence probability, object center field (unit vectors pointing to object centers), and object boundary distance field. Second, a network-free Multi-Object Reasoning module iteratively refines bounding box proposals using these geometric cues. The reasoning module checks existence, splits under-segmented proposals using center field anti-center detection, and refines boxes using boundary distance field gradients. The approach can be extended with a trained detector for faster inference.

## Key Results
- Achieves 32.6 APbox@50 on COCO* validation set, surpassing prior unsupervised methods
- Outperforms baselines by 3.5 APbox@50 and 1.8 APmask@50 on average across 6 datasets
- Excels in crowded images where baselines struggle to separate overlapping objects
- Demonstrates zero-shot detection capability on natural images

## Why This Works (Mechanism)

### Mechanism 1: Geometric Disambiguation via Center-Boundary Fields
The method explicitly predicts geometric fields (center vectors and boundary distances) that allow distinguishing adjacent objects better than semantic feature grouping. The "Object Center Field" assigns each pixel a unit vector pointing to its object's center, with divergent directions in boundary regions flagging separate objects.

### Mechanism 2: Recursive Proposal Splitting (Resolution of Under-segmentation)
A kernel-based operation on the center field identifies regions containing multiple objects, enabling recursive splitting of under-segmented proposals. The system convolves a predefined "anti-center" kernel with the center field, with high responses indicating inter-object spaces that trigger splitting.

### Mechanism 3: Gradient-Based Box Refinement (Localization)
The gradient of the normalized boundary distance field provides a signal to iteratively expand or contract bounding boxes to fit the tightest object extent. The system calculates max distance values at box borders, expanding if inside objects and contracting if in background.

## Foundational Learning

- **Concept: Normalized Cuts (NCut) & Spectral Clustering**
  - Why needed here: Used to generate rough pseudo-masks for training the Objectness Network
  - Quick check question: How does the "Object Center Field" fundamentally differ from the eigenvectors used in spectral clustering for localization?

- **Concept: Signed Distance Fields (SDF)**
  - Why needed here: The "Object Boundary Distance Field" is a variant of an SDF
  - Quick check question: Why does the paper normalize the SDF values separately for foreground and background rather than using raw pixel distances?

- **Concept: Region Proposals / Anchor Boxes**
  - Why needed here: The Multi-Object Reasoning module initializes search using proposal generation
  - Quick check question: Why is a network-free reasoning module preferred over training a Region Proposal Network directly in this unsupervised setting?

## Architecture Onboarding

- **Component map:** ImageNet (ImageNet) -> Stage 1 (Objectness Net: ResNet + DPT heads) -> Scene Image -> Stage 2 (Reasoning: Proposal Generator -> Loop [Existence -> Center -> Boundary] -> NMS)
- **Critical path:** The iterative loop in Step 2 (Center Reasoning) and Step 3 (Boundary Reasoning)
- **Design tradeoffs:** Network-free reasoning is conceptually elegant but computationally intensive; optional detector phase trades training time for faster inference
- **Failure signatures:** Merged objects (anti-center detection failure), fragmented objects (over-aggressive splitting/contraction), drifting boxes (noisy boundary gradients)
- **First 3 experiments:**
  1. Validation of Field Learning: Train Objectness Network and visualize predicted fields against VoteCut pseudo-labels
  2. Ablation on Center Splitting: Run reasoning with different τc values on crowded images to quantify under-segmentation impact
  3. Visualization of Reasoning Loop: Track a single proposal through iterations, visualizing anti-center map and box updates

## Open Questions the Paper Calls Out

- **Open Question 1:** Can reinforcement learning be utilized to learn an efficient policy network for object discovery to reduce computational time?
  - Basis: Appendix A.14 states the direct discovery process "takes time" and suggests RL techniques could help
  - Why unresolved: Iterative reasoning module is computationally intensive compared to single-pass detectors

- **Open Question 2:** How can language priors be integrated to resolve failure to separate overlapping objects with similar textures?
  - Basis: Appendix A.14 identifies struggles with overlapping objects of similar textures and proposes language priors
  - Why unresolved: Visual object-centric representations may be insufficient for distinguishing semantically distinct but visually similar occluded instances

- **Open Question 3:** To what extent do object priors from natural images hinder generalization to domains with significant domain gaps like medical imaging?
  - Basis: Section 4.2 notes zero-shot detection works on natural images but may not apply to data with significant domain gaps
  - Why unresolved: Objectness network trained on ImageNet may not align with structural characteristics of non-natural data

## Limitations

- Dependence on high-quality pseudo-masks from VoteCut/CuVLER for training the Objectness Network
- Network-free reasoning module may struggle with highly textured or overlapping objects where geometric cues become ambiguous
- Iterative proposal refinement is computationally expensive compared to learned detectors

## Confidence

- **High Confidence:** Core architectural components and basic implementation details are well-specified and reproducible
- **Medium Confidence:** Quantitative results on COCO are likely reproducible given access to VoteCut pseudo-masks
- **Low Confidence:** Qualitative claims about crowded image performance require careful scrutiny due to limited baseline implementation details

## Next Checks

1. **Pseudo-mask Quality Validation:** Visualize VoteCut pseudo-masks on ImageNet and compare Objectness Network's predicted fields against these labels to verify learning capability
2. **Center Splitting Threshold Sensitivity:** Systematically vary center reasoning threshold τc on crowded COCO images to validate anti-center mechanism's impact on under-segmentation vs. over-splitting
3. **Runtime Profiling:** Measure average iteration count and total inference time per image for reasoning module on COCO validation set, comparing against Cascade Mask R-CNN trained on same pseudo-labels to quantify practical cost