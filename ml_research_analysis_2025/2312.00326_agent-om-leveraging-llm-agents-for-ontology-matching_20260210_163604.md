---
ver: rpa2
title: 'Agent-OM: Leveraging LLM Agents for Ontology Matching'
arxiv_id: '2312.00326'
source_url: https://arxiv.org/abs/2312.00326
tags:
- matching
- ontology
- entity
- llms
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces Agent-OM, an agent-powered LLM-based framework
  for ontology matching (OM). The system addresses limitations of conventional OM
  approaches by employing two Siamese agents for retrieval and matching, using chain-of-thought
  planning, retrieval-augmented generation, and hybrid database storage.
---

# Agent-OM: Leveraging LLM Agents for Ontology Matching

## Quick Facts
- **arXiv ID:** 2312.00326
- **Source URL:** https://arxiv.org/abs/2312.00326
- **Reference count:** 40
- **Primary result:** Agent-OM achieves performance close to long-standing best on simple ontology matching tasks and significantly improves results on complex and few-shot scenarios.

## Executive Summary
This study introduces Agent-OM, an agent-powered LLM-based framework for ontology matching that addresses limitations of conventional approaches. The system employs two Siamese agents for retrieval and matching, using chain-of-thought planning, retrieval-augmented generation, and hybrid database storage. Evaluations across three OAEI tracks show Agent-OM achieves performance very close to the long-standing best on simple tasks and significantly improves results on complex and few-shot OM tasks. The framework demonstrates strong scalability and effectiveness, particularly in challenging scenarios where traditional systems struggle.

## Method Summary
Agent-OM uses a dual-agent architecture where a Retrieval Agent extracts entity metadata, syntactic information, lexical descriptions (via LLM), and semantic information (verbalized triples) stored in a hybrid PostgreSQL/pgvector database. The Matching Agent performs vector similarity search, aggregates results using Reciprocal Rank Fusion, validates top candidates via LLM binary prompts, and merges results bidirectionally. The system supports multiple LLM providers (OpenAI, Anthropic, open-source via Ollama) and employs chain-of-thought planning for task decomposition.

## Key Results
- Achieves performance very close to long-standing best systems on simple OAEI Conference tasks
- Significantly outperforms traditional systems on complex Anatomy and few-shot MSE tracks
- Demonstrates strong scalability across small (Conference) to large (Anatomy) ontology datasets

## Why This Works (Mechanism)
The dual-agent architecture enables specialized handling of retrieval versus matching tasks, with the Siamese design ensuring shared memory for consistent context. Chain-of-thought planning allows systematic decomposition of complex ontology matching into manageable subtasks. The hybrid database combines structured metadata storage with vector embeddings for efficient similarity search. Retrieval-augmented generation enriches entity representations with multiple information types (syntactic, lexical, semantic), while bidirectional validation ensures comprehensive alignment coverage.

## Foundational Learning
- **Siamese Network Architecture**: Two identical neural networks processing different inputs but sharing parameters; needed for consistent entity representation across ontologies, quick check: verify both agents use identical embedding models.
- **Retrieval-Augmented Generation (RAG)**: Combines information retrieval with LLM generation to ground responses in retrieved data; needed to enrich entity descriptions beyond raw text, quick check: confirm lexical descriptions are stored and retrieved from database.
- **Hybrid Database Design**: PostgreSQL for structured metadata plus pgvector for embeddings; needed to balance relational queries with vector similarity search, quick check: verify both metadata and embedding tables exist and are populated.
- **Chain-of-Thought (CoT) Planning**: LLM-based step-by-step reasoning for complex tasks; needed to decompose ontology matching into logical subtasks, quick check: examine agent.log for planning steps.
- **Reciprocal Rank Fusion (RRF)**: Combines multiple ranked lists by aggregating reciprocal ranks; needed to merge results from different similarity measures, quick check: verify RRF is applied in matching agent output.
- **Bidirectional Validation**: Validating alignments in both directions (Os→Ot and Ot→Os); needed to ensure comprehensive coverage and avoid directional bias, quick check: confirm validation runs twice with swapped source/target.

## Architecture Onboarding

**Component Map**: Entity Extraction -> Hybrid Database Storage -> Vector Similarity Search -> Reciprocal Rank Fusion -> Bidirectional LLM Validation -> Result Aggregation

**Critical Path**: Retrieval Agent (entity extraction and storage) → Hybrid Database → Matching Agent (similarity search and validation) → Result Output

**Design Tradeoffs**: The system trades computational cost and API usage for accuracy gains, with Retrieval Agent generating new lexical descriptions for every entity (expensive for large ontologies). The bidirectional validation ensures completeness but introduces redundancy. The hybrid database design requires maintaining two storage systems with different access patterns.

**Failure Signatures**: 
- Database connection errors or schema mismatches indicate pgvector extension issues
- API rate limiting suggests excessive LLM calls during retrieval phase
- Inconsistent results across runs indicate context truncation or non-deterministic LLM behavior
- Poor precision/recall indicates suboptimal similarity thresholds or insufficient top-k candidates

**First Experiments**:
1. Run the Retrieval Agent on a single small ontology (e.g., Conference) and verify entity metadata, lexical descriptions, and semantic subgraphs are correctly stored in the hybrid database.
2. Test the Matching Agent with similarity search on a simple pre-stored pair to confirm vector operations and RRF aggregation work correctly.
3. Execute the complete pipeline on the Conference track and verify output metrics (Precision, Recall, F1) are calculated and stored in result.csv.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the Agent-OM framework be adapted to perform ABox (instance) matching while mitigating the privacy risks associated with leaking personal or sensitive information into LLMs?
- **Basis in paper:** Section 8 explicitly states that ABox matching datasets were excluded due to privacy concerns, noting that additional data engineering (e.g., de-identification and fuzzing) may be required to apply LLMs to these datasets.
- **Why unresolved:** The current proof-of-concept system focuses exclusively on TBox (schema) matching and has not implemented the data sanitization mechanisms necessary to safely process data instances.
- **Evidence:** Implementing privacy-preserving modules and evaluating the system on standard instance matching benchmarks without triggering data leakage.

### Open Question 2
- **Question:** Does implementing Tree of Thoughts (ToT) or Graph of Thoughts (GoT) reasoning improve the accuracy of complex ontology matching compared to the current Chain-of-Thought (CoT) approach?
- **Basis in paper:** Section 7 notes that human reasoning employs complex networks of thoughts (ToT/GoT), exploring multiple paths and backtracking, whereas the current system uses a linear CoT which is an incomplete model of human thought.
- **Why unresolved:** The current implementation relies on CoT for planning; the potential performance gains or computational costs of implementing the more complex ToT/GoT architectures in an OM agent remain untested.
- **Evidence:** Benchmarking Agent-OM variants using ToT/GoT planning modules against the standard CoT implementation on complex OAEI tracks.

### Open Question 3
- **Question:** Can integrating multimodal inputs (such as ontology diagrams or online seminars) enhance the matching performance of Agent-OM?
- **Basis in paper:** Section 9 suggests that the system could be integrated with advanced LLM functions to support multimodal input, providing richer information sources that might improve OM performance.
- **Why unresolved:** The current system relies exclusively on textual entity metadata stored in hybrid databases; the utility of visual or auditory context for alignment is currently theoretical.
- **Evidence:** Extending the Retrieval Agent to ingest visual graph layouts of ontologies and measuring changes in F1 score on specific alignment tasks where textual context is ambiguous.

### Open Question 4
- **Question:** Can Small Language Models (SLMs) effectively support the tool-calling and planning requirements of the Agent-OM framework on resource-constrained devices?
- **Basis in paper:** Section 9 identifies SLMs (e.g., gemma-2-2b) as useful for resource-constrained devices but notes they currently have "problematic tool interfaces" that hinder their use in the agentic framework.
- **Why unresolved:** The study evaluated open-source models (7-9 billion parameters) but did not test smaller models, leaving the lower bound of model size required for reliable tool calling and planning undetermined.
- **Evidence:** Evaluating the tool-calling success rate and matching performance of sub-3B parameter models on the Agent-OM-Lite variant compared to the standard open-source baseline.

## Limitations
- Relies heavily on proprietary LLM APIs, introducing significant operational costs and rate limiting constraints
- Does not address ABox (instance) matching due to privacy concerns with sensitive data
- Scalability claims beyond tested OAEI tracks remain unverified for real-world ontologies with different characteristics

## Confidence

**High Confidence:** The overall methodology and architectural design (Siamese agents, chain-of-thought planning, hybrid storage) are clearly specified and reproducible.

**Medium Confidence:** Performance claims are supported by OAEI benchmark results, but the comparison scope is limited to 2022/2023 baselines without examining the full historical OAEI leaderboard.

**Low Confidence:** Scalability claims beyond the tested OAEI tracks are not validated, and the system's behavior on real-world ontologies with significantly different characteristics (domain, size, structure) remains unverified.

## Next Checks
1. **Database Schema Validation:** Test the system's ability to handle different embedding dimensions by switching between OpenAI (1536) and Ollama (4096) embeddings without database reset, verifying that vector similarity search remains accurate.
2. **Cost Analysis:** Run the complete pipeline on the Anatomy track and calculate total API costs from the cost.csv output, comparing against traditional matching systems to assess economic feasibility.
3. **Context Truncation Testing:** Systematically test the Matching Validator with ontologies of increasing semantic subgraph complexity to identify the maximum context size before token limit errors occur, and measure the impact on alignment quality.