---
ver: rpa2
title: 'Towards Continual Expansion of Data Coverage: Automatic Text-guided Edge-case
  Synthesis'
arxiv_id: '2509.26158'
source_url: https://arxiv.org/abs/2509.26158
tags:
- data
- naive
- dataset
- training
- manual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an automated pipeline for generating edge-case
  data to improve model robustness by leveraging a preference-tuned large language
  model (LLM) to rephrase image captions and a text-to-image (T2I) model to synthesize
  challenging visual scenarios. Evaluated on the FishEye8K object detection benchmark,
  the method achieves superior performance compared to naive augmentation and manually
  engineered prompts, both in terms of overall mAP and mAP w/o TP (a custom metric
  measuring improvements on previously undetected cases).
---

# Towards Continual Expansion of Data Coverage: Automatic Text-guided Edge-case Synthesis

## Quick Facts
- arXiv ID: 2509.26158
- Source URL: https://arxiv.org/abs/2509.26158
- Reference count: 40
- Primary result: Edge-case synthesis pipeline achieves 0.384 mAP (+0.006) and 0.366 mAP w/o TP (+0.004) on FishEye8K vs baseline YOLOv11-small

## Executive Summary
This paper introduces an automated pipeline for generating edge-case data to improve model robustness by leveraging a preference-tuned large language model (LLM) to rephrase image captions and a text-to-image (T2I) model to synthesize challenging visual scenarios. Evaluated on the FishEye8K object detection benchmark, the method achieves superior performance compared to naive augmentation and manually engineered prompts, both in terms of overall mAP and mAP w/o TP (a custom metric measuring improvements on previously undetected cases). The approach effectively expands training data coverage, reduces dataset bias, and automates the identification and synthesis of difficult cases, providing a scalable direction for building more reliable and continuously improving AI systems.

## Method Summary
The method employs a preference-tuned LLM to rephrase image captions into diverse textual prompts that steer a text-to-image model toward generating difficult visual scenarios. The pipeline begins by generating base captions for real images using a captioner (InternVL3-38B), then produces N rephrased caption variants via a preference-tuned LLM (Llama-3-8B with LoRA). These captions are converted to synthetic images using a T2I model (Flux.1-dev with LoKr), which are then pseudo-labeled by a Co-DETR model. The discriminative model (YOLOv11-small) computes task-specific losses to quantify "edge-ness" of each synthetic image. A preference learning loop using Direct Preference Optimization (DPO) fine-tunes the LLM to favor high-loss captions. The final augmented dataset combines real and synthetic data for improved model training.

## Key Results
- Automatic method outperforms naive augmentation (+0.006 mAP, +0.004 mAP w/o TP) and manual prompts on FishEye8K
- Iterative augmentation (v2) shows continued improvement: mAP 0.381→0.384, mAP w/o TP 0.363→0.366
- Performance gains maintained across YOLOv11 model scales (small, medium, large) via data transferability
- Six learned rephrasing patterns identified: scene atmosphere, perspective, temporal visualization, intersection clarification, action emphasis, urban context

## Why This Works (Mechanism)

### Mechanism 1: Preference-Aligned Caption Rephrasing
Fine-tuning an LLM with Direct Preference Optimization (DPO) aligns it to generate captions that produce higher-loss images for a target discriminative model. The LLM generates N caption variants → T2I model synthesizes N images → discriminative model computes task loss per image → highest-loss caption labeled "preferred," lowest-loss "unpreferred" → DPO trains LLM to favor high-loss patterns. This creates a feedback loop where the LLM learns semantic modifications that systematically induce model confusion.

### Mechanism 2: Caption-Space Edge-Case Discovery
Operating at the caption level (vs. latent/embedding space) enables interpretable, scalable edge-case synthesis that leverages off-the-shelf T2I improvements. Caption-level modifications (perspective, lighting, action emphasis, urban context) map to diverse visual outputs through frozen T2I model. The LLM learns patterns like "emphasize dynamic actions" or "transform time metadata into atmospheric descriptions" that systematically expand data coverage.

### Mechanism 3: Iterative Blind-Spot Discovery
Retraining the discriminative model on augmented data enables progressively harder edge-case discovery in subsequent iterations. After augmentation, model M_φ′ has different failure modes than original M_φ. Using M_φ′ as edge-ness scorer shifts preference signal toward new blind spots, creating a curriculum of increasing difficulty.

## Foundational Learning

- **Concept: Direct Preference Optimization (DPO)**
  - Why needed here: Core training method for aligning LLM to edge-case generation without explicit reward model training
  - Quick check question: Can you explain why DPO uses a reference model π_ref and what the β hyperparameter controls?

- **Concept: Pseudo-Labeling / Knowledge Distillation**
  - Why needed here: Synthetic images lack ground truth; pseudo-labeler provides annotations for training discriminative model
  - Quick check question: What failure modes occur if pseudo-labeler is miscalibrated or has systematic blind spots?

- **Concept: Task Loss as Uncertainty Proxy**
  - Why needed here: Edge-ness is defined via L_task; understanding loss-loss connections to model uncertainty is critical
  - Quick check question: Why might high task loss indicate edge-case vs. just annotation error? How would you distinguish these?

## Architecture Onboarding

- **Component map:** InternVL3-38B -> Llama-3-8B (DPO-tuned) -> Flux.1-dev (LoKr) -> Co-DETR -> YOLOv11-small (edge-ness scorer) -> YOLOv11-small (final detector)

- **Critical path:**
  1. Train discriminative model on biased train-D
  2. Sample from train-R, generate captions, rephrase → N variants
  3. Synthesize N images, pseudo-label, compute edge-ness scores
  4. Construct preference pairs (max-loss vs. min-loss captions)
  5. Fine-tune LLM with DPO on preference dataset
  6. Inference: use tuned LLM to generate edge-case captions from train-D images
  7. Augment train-D with synthetic images + pseudo-labels
  8. Optionally iterate from step 1 with augmented dataset

- **Design tradeoffs:**
  - N (caption variants): Higher N increases diversity but multiplies compute (each variant requires T2I + pseudo-labeling). Paper uses N=5.
  - Preference pair selection: Max/min loss is simple but may amplify noise. Percentile-based or margin-based selection could be more robust.
  - Pseudo-labeler choice: Stronger labeler (e.g., larger Co-DETR) improves annotation quality but may not reflect discriminative model's failure modes.
  - Train-D vs. train-R split: Strict separation prevents leakage but requires sufficient data in both splits. Paper uses camera-ID-based split to create intentional bias.

- **Failure signatures:**
  - Synthetic data increases mAP but decreases mAP w/o TP: augmentation helps easy cases but ignores blind spots (check caption diversity)
  - Preference learning fails to converge: edge-ness signal may be too noisy; reduce N or use softer preference labels
  - Generated images lack object diversity: T2I may be under-trained on domain; fine-tune with more real data
  - Class imbalance worsens: pseudo-labeler may be biased toward dominant classes; consider class-balanced sampling for caption generation

- **First 3 experiments:**
  1. Reproduce baseline comparison (naive vs. manual vs. automatic) on FishEye8K with provided configs. Verify mAP and mAP w/o TP improvements.
  2. Ablate preference learning: Compare DPO-tuned LLM vs. untuned LLM vs. random caption selection. Isolate contribution of preference alignment to edge-ness.
  3. Test transferability (Appendix H protocol): Train YOLOv11-medium/large on data curated with YOLOv11-small. Check if automatic method maintains advantage, confirming data quality transfers across model scales.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the proposed caption-based edge-case synthesis pipeline generalize effectively to standard perspective datasets or domains that lack the distinct geometric biases found in fisheye imagery?
- **Basis in paper:** The Conclusion states, "For future work, we plan to extend our study to a broader range of datasets..."
- **Why unresolved:** The study is exclusively evaluated on FishEye8K, a dataset characterized by strong, specific geometric distortions (fisheye effect) that may be particularly amenable to text-guided semantic manipulation.
- **What evidence would resolve it:** Evaluation of the ATES pipeline on standard benchmarks (e.g., COCO, Cityscapes) to determine if semantic rephrasing alone is sufficient to capture diverse edge cases in natural images.

### Open Question 2
- **Question:** Would alternative uncertainty measures, such as entropy or ensemble disagreement, yield superior edge-case data compared to the current task-loss metric for quantifying "edge-ness"?
- **Basis in paper:** The Conclusion identifies the need to "explore alternative uncertainty measures for edge-ness."
- **Why unresolved:** The current implementation relies solely on the task-specific training loss (s_i = L_task) to identify difficult samples, which might conflate data noise with informative edge-case difficulty.
- **What evidence would resolve it:** An ablation study comparing the quality and diversity of synthetic data generated using different "edge-ness" scoring functions within the preference learning loop.

### Open Question 3
- **Question:** To what extent can fine-tuning the text-to-image (T2I) model and pseudo-labeler with explicit bias-mitigation objectives improve the correction of model blind spots?
- **Basis in paper:** The Conclusion notes that "considering dataset bias even during the fine-tuning of T2I models and pseudo-labelers could have improved performance."
- **Why unresolved:** The current method fine-tunes these generative components on the biased training data without specific mechanisms to correct for that bias, potentially limiting the synthetic data's capacity to address the discriminative model's weaknesses.
- **What evidence would resolve it:** Experiments comparing the current fine-tuning approach against a setup where the T2I and pseudo-labeler are trained with debiasing regularization.

### Open Question 4
- **Question:** Is textual rephrasing sufficient to capture visual edge-cases that lack a clear semantic description, such as specific sensor artifacts or low-level texture anomalies?
- **Basis in paper:** The methodology relies on the assumption that "semantic modifications to captions can induce substantial... diversity" (Page 2). This implies a potential limitation in addressing visual anomalies that are non-semantic or difficult to verbalize.
- **Why unresolved:** While the method succeeds in fisheye contexts (often semantic/geometric), it does not validate effectiveness against "blind spots" that are purely visual or texture-based without a corresponding linguistic description.
- **What evidence would resolve it:** Comparative analysis against latent-space perturbation methods (like Guided Imagination) on tasks requiring the detection of non-semantic visual anomalies.

## Limitations
- Dataset specificity: All experiments use a single fisheye-object detection dataset (FishEye8K), limiting generalizability claims to other domains
- Iterative improvement validation: Only two iterations shown; long-term stability and diminishing returns unexamined
- Pseudo-labeler dependency: Performance improvements contingent on pseudo-labeler quality without analysis of error propagation

## Confidence
- **High confidence**: The core technical methodology (preference learning for caption rephrasing, edge-ness quantification via task loss) is sound and well-documented
- **Medium confidence**: Claims about mAP and mAP w/o TP improvements are supported by experiments on the target dataset, though improvements are modest
- **Low confidence**: Claims about general data coverage expansion, bias reduction, and automated edge-case identification lack broad empirical support

## Next Checks
1. **Cross-dataset generalization**: Apply the pipeline to a non-fisheye object detection dataset (e.g., COCO or nuScenes) and evaluate whether the same caption rephrasing patterns and performance improvements emerge
2. **Long-term iterative stability**: Run 5+ augmentation iterations and track mAP/mAP w/o TP trends, along with synthetic data diversity metrics, to validate iterative improvement claims
3. **Pseudo-labeler ablation study**: Replace Co-DETR with progressively weaker pseudo-labelers (including a baseline detector trained only on real data) and measure how performance degrades to quantify the critical dependency on pseudo-labeler quality