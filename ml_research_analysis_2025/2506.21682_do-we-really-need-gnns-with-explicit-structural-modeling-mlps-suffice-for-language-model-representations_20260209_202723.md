---
ver: rpa2
title: Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for
  Language Model Representations
arxiv_id: '2506.21682'
source_url: https://arxiv.org/abs/2506.21682
tags:
- uni00000013
- probing
- language
- module
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper challenges the assumption that Graph Neural Networks
  (GNNs) are necessary for enhancing language model representations with structural
  information. Through a modular probing framework that decouples GNNs into feature-transformation
  and message-passing operations, the authors systematically evaluate the role of
  explicit structural modeling in improving linguistic knowledge captured by language
  models.
---

# Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations

## Quick Facts
- arXiv ID: 2506.21682
- Source URL: https://arxiv.org/abs/2506.21682
- Reference count: 40
- One-line primary result: MLPs without message-passing mechanisms consistently outperform or match GNNs for enhancing LM representations in linguistic probing tasks

## Executive Summary
This paper challenges the assumption that Graph Neural Networks (GNNs) are necessary for enhancing language model representations with structural information. Through a modular probing framework that decouples GNNs into feature-transformation and message-passing operations, the authors systematically evaluate the role of explicit structural modeling in improving linguistic knowledge captured by language models. The experiments, conducted on eight linguistic tasks from the Edge Probing Suite using BERT, T5, and Llama-3-8B, demonstrate that Multi-Layer Perceptrons (MLPs) without message-passing mechanisms consistently outperform or match GNNs, achieving average F1 score improvements of 4.52, 5.82, and 3.06 respectively. The Message module, which focuses solely on structural information propagation, generally underperforms, showing that feature-transformation operations are the primary driver of performance gains.

## Method Summary
The study uses a modular probing framework with three frozen LM backbones (BERT-base, T5-base, Llama-3-8B with LLM2Vec adaptation) and three control modules: GNN (combined message-passing and feature-transformation), Message-only (structural propagation), and MLP-only (feature transformation). The framework processes sentences through Stanza for UD dependency parsing, applies the control module to frozen LM representations, and feeds span representations to task-specific probing classifiers. The system trains probes only (LM frozen) and evaluates using macro F1 scores across five random seeds. Experiments cover eight linguistic tasks from the Edge Probing Suite spanning syntactic and semantic phenomena.

## Key Results
- MLPs without message-passing consistently outperform or match full GNNs across all three LMs, with average F1 improvements of 4.52 (BERT), 5.82 (T5), and 3.06 (Llama-3-8B)
- The Message module, focusing solely on structural propagation, generally underperforms, causing average F1 drops of -1.22 (BERT) and -5.47 (Llama-3-8B), with only +0.18 gain for T5
- Feature-transformation benefits are layer-agnostic, consistently improving performance regardless of which LM layer's hidden states are used as input
- GNNs show marginal advantage only for very long-span relations (>15 tokens), where MLP performance plateaus

## Why This Works (Mechanism)

### Mechanism 1: Feature-Transformation Sufficiency
- **Claim:** MLP-based feature-transformation operations alone are sufficient to enhance LM representations for linguistic probing tasks, matching or exceeding full GNN performance.
- **Mechanism:** An MLP module applies learnable weight transformations and non-linear activations (Eq. 8: Q^(l+1) = ReLU(Q^(l)W^(l) + b^(l))) to LM hidden states without propagating information across graph structures.
- **Core assumption:** The linguistic knowledge required for probing tasks is already encoded in LM representations and primarily needs non-linear transformation rather than structural aggregation.
- **Evidence anchors:**
  - [abstract] "MLPs without message-passing mechanisms consistently outperform or match GNNs, achieving average F1 score improvements of 4.52, 5.82, and 3.06 respectively"
  - [Table III] MLP achieves highest average F1 gains across all three LMs compared to GNN and Message modules
  - [corpus] "InfGraND: An Influence-Guided GNN-to-MLP Knowledge Distillation" reports MLPs as "computationally efficient alternatives" to GNNs

### Mechanism 2: Limited Utility of Explicit Message-Passing for Probing
- **Claim:** Message-passing operations that propagate information along syntactic dependency structures provide marginal or negative value for linguistic probing tasks.
- **Mechanism:** The Message module (Eq. 3-7) aggregates neighbor features via normalized adjacency matrices across k hops, then learns adaptive weights for combining hop-level representations.
- **Core assumption:** Explicit syntactic structure may be redundant when LMs have already internalized implicit structural patterns during pre-training.
- **Evidence anchors:**
  - [abstract] "The Message module, which focuses solely on structural information propagation, generally underperforms"
  - [Table III] Message module causes average performance drops of -1.22 (BERT) and -5.47 (Llama-3-8B); only +0.18 gain for T5
  - [Section VI.A] Random graph experiments show Message module is more sensitive to structural noise than GNN module

### Mechanism 3: Layer-Agnostic Enhancement via Feature Transformation
- **Claim:** Feature-transformation benefits are consistent across different LM layer representations, not limited to specific syntactic or semantic layers.
- **Mechanism:** The MLP module provides consistent performance gains regardless of which BERT layer's hidden states serve as input.
- **Core assumption:** Feature transformation operates orthogonally to the layer-specific linguistic knowledge organization.
- **Evidence anchors:**
  - [Section VI.C / Fig. 5] "regardless of which layer's hidden representation from the language model is used as input... MLP and GNN modules consistently enhance performance"
  - [Section I] Prior work shows LMs hierarchically organize knowledge (surface → syntactic → semantic), yet MLP helps across all layers

## Foundational Learning

- **Concept: Graph Neural Network Decoupling**
  - Why needed here: Understanding that GNNs = Message-Passing + Feature-Transformation allows isolating which operation drives performance
  - Quick check question: Can you write the operations for a GCN layer and identify which part aggregates neighbors vs. transforms features?

- **Concept: Probing Classifiers as Diagnostic Tools**
  - Why needed here: The framework uses probing to measure what linguistic information is accessible in representations, not to solve tasks for production
  - Quick check question: What does a high probing F1 score indicate about the relationship between representations and linguistic properties?

- **Concept: Edge Probing Suite Design**
  - Why needed here: Tasks span syntactic (POS, constituents, dependencies) and semantic (entities, SRL, coreference) phenomena with unified span-based formulation
  - Quick check question: How do unary edge tasks (single span) differ from binary edge tasks (two spans) in the probing formulation?

## Architecture Onboarding

- **Component map:** Stanza → UD dependency parsing → Frozen LM → Control module (GNN/Message/MLP) → Probing classifier → F1 evaluation
- **Critical path:** 1) Parse sentences with Stanza → extract UD dependency trees → construct adjacency matrices 2) Extract frozen LM representations for input tokens 3) Apply Control module (2-layer network with residual connections) 4) Feed span representations to task-specific classifier 5) Train probe only (LM remains frozen); evaluate F1
- **Design tradeoffs:** MLP vs. GNN: MLP is simpler (no graph parsing needed) and performs better, but GNN provides slight edge on very long-span relations (>15 tokens); Layer selection: Final layer is default, but middle layers may better capture syntactic knowledge; LLM2Vec for Llama-3-8B: Required to adapt decoder-only model for bidirectional encoding, but residual autoregressive influence may limit Message module compatibility
- **Failure signatures:** Message module causes significant performance drops on Llama-3-8B (-5.47 avg F1) → indicates incompatibility with decoder-only architectures adapted for encoding; Random graph experiments: Message module more sensitive to structural noise than GNN (larger performance drops); Very short spans ([0,3]) and very long spans (>15): Message module provides no improvement
- **First 3 experiments:**
  1. Replicate the MLP vs. Message comparison on BERT with a single syntactic task (e.g., dependency labeling) to validate feature-transformation dominance
  2. Test random vs. UD graphs on the GNN configuration to confirm structural information is being used meaningfully
  3. Run layer-wise probing (layers 0-12) for one semantic task (e.g., SRL) to verify that MLP benefits are layer-agnostic

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Why does explicit message passing significantly degrade performance in decoder-only models (e.g., Llama-3) while benefiting or mildly affecting encoder-only models?
- **Basis in paper:** [explicit] Section V-B(2) highlights that the Message module causes a "pronounced negative effect" on Llama-3-8B, hypothesizing that residual autoregressive mechanisms make decoder models sensitive to structural context injection.
- **Why unresolved:** The paper identifies the architectural incompatibility but does not isolate the specific representational conflicts within the decoder attention mechanism.
- **What evidence would resolve it:** An analysis of attention head distributions in decoder models during structural injection, or experiments using non-autoregressive decoder variants.

### Open Question 2
- **Question:** Why does message passing benefit Semantic Proto-Role (SPR) labeling while consistently harming standard syntactic tasks?
- **Basis in paper:** [explicit] Section V-B(3) notes that unlike syntactic tasks, the Message module consistently improves SPR performance across all models, suggesting a unique structural requirement for fine-grained semantic attributes.
- **Why unresolved:** The authors report the anomaly but do not determine if this is due to the multi-label nature of SPR or the specific semantic dependencies involved.
- **What evidence would resolve it:** Ablation studies on SPR sub-tasks to correlate performance gains with specific graph traversal depths or neighbor aggregation strategies.

### Open Question 3
- **Question:** Is explicit structural modeling necessary for capturing dependencies in extremely long-distance spans (over 15 tokens)?
- **Basis in paper:** [explicit] Section VI-D indicates that for the $(15, \infty)$ span group, the GNN module slightly outperforms the MLP module, suggesting a marginal advantage for message passing in long-range contexts.
- **Why unresolved:** The general conclusion claims MLPs suffice, but this specific data point suggests a potential failure mode for feature-transformation-only approaches in extreme long-range scenarios.
- **What evidence would resolve it:** Targeted experiments on long-range dependency datasets (e.g., Long-Range Arena) comparing MLP scaling versus GNN depth.

## Limitations
- The study's conclusions are limited to the specific probing task setup and frozen LM approach, which may not generalize to fine-tuning scenarios or tasks beyond the Edge Probing Suite
- The incompatibility of the Message module with LLM2Vec-adapted Llama-3-8B raises questions about decoder-only models' handling of structural information, but the paper doesn't explore native decoder models
- The claim that MLPs "suffice" may not apply to tasks requiring explicit multi-hop reasoning over sparse, long-range dependencies

## Confidence

**High Confidence:** The experimental results showing MLP outperforming or matching GNN on the tested tasks are well-supported by the data (Tables II and III). The finding that the Message module underperforms is also robustly demonstrated.

**Medium Confidence:** The interpretation that feature-transformation is the primary driver of performance gains is reasonable but could benefit from ablations that isolate feature transformation effects more precisely. The claim about layer-agnostic enhancement is supported by the layer-wise analysis but limited to three LMs.

**Low Confidence:** The assertion that MLPs "suffice" for all scenarios involving structural modeling is an overgeneralization. The paper's findings are specific to the probing setup and may not apply to end-to-end fine-tuning or tasks requiring explicit multi-hop reasoning.

## Next Checks

1. **Ablation Study:** Conduct an ablation study to isolate the effect of feature transformation by comparing an MLP with and without non-linear activations (e.g., replacing ReLU with identity) while keeping the message-passing component constant.

2. **Decoder-Only Model Testing:** Test the MLP and Message modules on a native decoder-only LLM (e.g., GPT-2) without LLM2Vec adaptation to determine if the Message module's poor performance is specific to the adaptation process or a broader incompatibility with decoder architectures.

3. **Task Generalization:** Evaluate the MLP and GNN modules on a task outside the Edge Probing Suite that requires explicit multi-hop reasoning (e.g., reading comprehension with complex inference) to test the limits of feature transformation sufficiency.