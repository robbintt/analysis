---
ver: rpa2
title: 'CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous
  Networks'
arxiv_id: '2510.20219'
source_url: https://arxiv.org/abs/2510.20219
tags:
- client
- data
- learning
- local
- personalized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of personalized federated learning\
  \ under heterogeneous and scarce data conditions, where traditional FL approaches\
  \ struggle due to statistical data diversity across clients. The authors propose\
  \ Contribution-Oriented Personalized Federated Learning (CO-PFL), which introduces\
  \ a Contribution-Oriented Weighted Aggregation (COWA) module that dynamically estimates\
  \ each client\u2019s contribution by jointly analyzing gradient direction discrepancies\
  \ and prediction deviations."
---

# CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks

## Quick Facts
- arXiv ID: 2510.20219
- Source URL: https://arxiv.org/abs/2510.20219
- Reference count: 40
- Primary result: CO-PFL achieves 82.86% accuracy on CIFAR10 and 38.76% on Mini-ImageNet under heterogeneous data conditions

## Executive Summary
This paper addresses the challenge of personalized federated learning under heterogeneous and scarce data conditions, where traditional FL approaches struggle due to statistical data diversity across clients. The authors propose Contribution-Oriented Personalized Federated Learning (CO-PFL), which introduces a Contribution-Oriented Weighted Aggregation (COWA) module that dynamically estimates each client's contribution by jointly analyzing gradient direction discrepancies and prediction deviations. This contribution-aware approach enables more discriminative aggregation compared to uniform or data-volume-based methods. CO-PFL also incorporates a Parameter-Wise Personalization Mechanism (PWPM) for fine-grained, dynamic parameter selection, and a Mask-Aware Momentum Optimization (MAMO) module to stabilize training by decoupling momentum updates between shared and personalized submodels.

## Method Summary
CO-PFL operates by partitioning each client's model into shared and personalized submodels, with parameters dynamically selected for personalization based on gradient magnitude during local training. The COWA module computes contribution scores for each client using gradient direction analysis and prediction loss on held-out data, which are then normalized into aggregation weights. MAMO maintains separate momentum buffers for shared and personalized parameters to prevent "momentum leakage" when parameter roles change. The method uses ResNet-18 backbone, runs for 200 communication rounds with 10-20 clients, and evaluates on CIFAR10, CIFAR10C, CINIC10, and Mini-ImageNet datasets with heterogeneous label partitions.

## Key Results
- Achieves 82.86% accuracy on CIFAR10 and 38.76% on Mini-ImageNet under heterogeneous data conditions
- Outperforms state-of-the-art methods including FedAvg, FedPer, and FedAMP
- Demonstrates improved convergence stability and robustness under varying numbers of clients and data scales

## Why This Works (Mechanism)

### Mechanism 1: Contribution-Oriented Weighted Aggregation (COWA)
COWA dynamically weights client updates based on estimated contribution by computing a score $\Gamma_n^k = \Gamma_n^{grad} + \Gamma_n^{pred}$ for each client. The Gradient Score measures angular deviation from other clients' updates, while the Prediction Score measures loss of the aggregated model on client's data. These scores are normalized into aggregation weights $\alpha_n^k$.

**Core assumption:** High-quality client updates are distinct (non-redundant) and/or beneficial to other clients. Gradient direction and prediction loss on a held-out proxy are sufficient indicators of this quality.

**Break condition:** The mechanism may fail if the gradient or prediction scores are noisy or uncorrelated with actual update utility. If a client's unique data is also highly erroneous or adversarial, high gradient deviation might lead to inappropriate weighting.

### Mechanism 2: Parameter-Wise Personalization Mechanism (PWPM)
PWPM dynamically identifies parameters for personalization based on local gradient sensitivity. It computes the magnitude of parameter changes $\Delta w_n^k$ during local training and selects the top-$p$ parameters with largest magnitudes for the personalized submodel, subject to budget $\gamma$.

**Core assumption:** Parameters that undergo the largest magnitude changes during local training are the most "sensitive" and thus most critical to personalize for the local distribution.

**Break condition:** If sensitive parameters are not truly the ones needing personalization (e.g., if gradient magnitudes are dominated by noise), the personalization will be misdirected.

### Mechanism 3: Mask-Aware Momentum Optimization (MAMO)
MAMO maintains separate first-order ($u$) and second-order ($v$) momentum buffers and uses an auxiliary mask $h_n^k$ to route gradients and momentum updates specifically to either shared or personalized submodels, preventing "momentum leakage."

**Core assumption:** Mixing momentum between parameters that switch roles disrupts optimization stability, and independent momentum buffers are beneficial.

**Break condition:** The overhead of managing separate momentum buffers may not yield benefits if the mask evolves very slowly or not at all.

## Foundational Learning

**Concept: Federated Averaging (FedAvg)**
- Why needed here: CO-PFL is a direct modification of the standard FedAvg aggregation rule. Understanding the baseline "equal-contribution" assumption is necessary to grasp the problem COWA solves.
- Quick check question: What is the standard aggregation rule in FedAvg and what assumption does CO-PFL challenge about it?

**Concept: Submodel Partitioning / Decoupling**
- Why needed here: CO-PFL explicitly splits models into shared ($g_n$) and personalized ($p_n$) parts. The PWPM and MAMO modules operate directly on this partitioned structure.
- Quick check question: How does the CO-PFL partition differ from a standard fixed-partition approach (like FedPer)?

**Concept: Adaptive/Weighted Aggregation**
- Why needed here: The central innovation is re-weighting client updates. Understanding the motivation (heterogeneous data quality) is key to understanding the COWA module's design.
- Quick check question: Why might a client's update be considered "low quality" or "high quality" in a heterogeneous system?

## Architecture Onboarding

**Component map:**
Client: Local Data -> MAMO (Local Optimizer) -> Local Model $w_n$ -> PWPM (Mask Generator) -> Mask $m_n$, Shared Submodel $g_n$, Personalized Submodel $p_n$ -> COWA Scorer (Contribution Calculator) -> Score $\Gamma_n$.
Server: Collect $\{g_n, m_n, \Gamma_n\}$ from all clients -> COWA Aggregator (Weighted Average) -> Global Shared Submodel $g$ -> Broadcast $g$ and global mask $m$ to clients.

**Critical path:** The correctness of the COWA score ($\Gamma_n$) and its proper normalization into aggregation weights ($\alpha_n$) is critical. If scores are miscalculated or degenerate, aggregation may fail. The PWPM mask generation logic must correctly enforce the budget $\gamma$.

**Design tradeoffs:**
- Communication: Clients upload submodels, masks, and scores. This is more data than FedAvg but potentially less if the shared submodel is small.
- Computation: Clients must compute gradient magnitudes (PWPM) and potentially a leave-one-out estimate or extra forward passes (COWA), adding client-side compute overhead.
- Hyperparameters: The system is sensitive to the personalization rate $p$ and budget $\gamma$. These must be tuned per dataset.

**Failure signatures:**
- Convergence stall: COWA weights $\alpha_n$ become uniform or stuck on a single client, reverting to FedAvg or a single-client-dominated model. Check normalization of $\Gamma_n$.
- Over-personalization: If $p$ and $\gamma$ are set too high, clients may overfit to local data and shared knowledge degrades. Check $p, \gamma$ settings.
- Unstable loss: If MAMO is disabled or misconfigured, loss may oscillate as masks change. Check MAMO implementation.

**First 3 experiments:**
1. Ablation on COWA: Run CO-PFL with gradient-only scores, prediction-only scores, and combined scores on a simple heterogeneous dataset (e.g., CIFAR10 with 2 classes/client) to validate the contribution metric.
2. Hyperparameter Sensitivity ($p, \gamma$): Sweep personalization rate $p$ and budget $\gamma$ on a target dataset to find the optimal balance between shared and personalized capacity.
3. MAMO Validation: Compare convergence curves (training loss) with and without the MAMO module enabled to confirm its stabilizing effect, especially in early communication rounds.

## Open Questions the Paper Calls Out

**Open Question 1**
How does the requirement for a held-out validation set impact performance in extreme data scarcity regimes?
- Basis in paper: [inferred] The paper targets "scarce and heterogeneous data" (Abstract), yet the COWA module's prediction score ($\Gamma_{data}$) relies on evaluating loss on a "held-out validation set" (Page 7, Eq. 10).
- Why unresolved: In scenarios with very few local samples (e.g., $M_{bound}=10$ in Ablation), partitioning data for validation could starve the training process, potentially degrading model quality more than the contribution weighting improves it.
- What evidence would resolve it: Ablation studies analyzing performance sensitivity to the train/validation split ratio, specifically when local data samples are minimal.

**Open Question 2**
Is the COWA mechanism scalable to massive cross-device federated networks (e.g., millions of clients)?
- Basis in paper: [inferred] Experiments are limited to a maximum of 50 clients (Table II), but the aggregation weight calculation (Eq. 11) requires normalizing contribution scores across all participating clients.
- Why unresolved: Normalizing scores and computing the necessary global statistics for $\bar{\delta}_{-n}$ (gradient score) across millions of clients poses significant server-side computational and communication bottlenecks not addressed by the current evaluation.
- What evidence would resolve it: A complexity analysis of the aggregation step with respect to $N$, or simulation results demonstrating stability and latency with $N > 1,000$.

**Open Question 3**
What is the computational and energy overhead of the COWA and MAMO modules on resource-constrained edge devices?
- Basis in paper: [inferred] The paper claims suitability for "mobile personalization" (Intro) but reports only accuracy and communication rounds, omitting wall-clock time, FLOPs, or energy consumption.
- Why unresolved: Calculating contribution scores requires clients to construct a virtual "leave-one-out" model ($w_{-n}$) and perform extra inference steps (Eq. 10), which adds overhead not quantified in the results.
- What evidence would resolve it: Benchmarks reporting training time per round, energy usage, and FLOPs compared to baselines like FedAvg or FedPer.

## Limitations
- The COWA contribution metric assumes gradient direction and leave-one-out prediction loss are reliable proxies for update quality, but lacks empirical validation of this correlation
- The necessity and optimality of MAMO's complex momentum management is the least validated claim, as simpler alternatives are not adequately explored
- The method requires a held-out validation set for contribution scoring, which may be problematic in extreme data scarcity scenarios

## Confidence

**High Confidence:** The overall performance improvement claims (82.86% CIFAR10 accuracy, 38.76% Mini-ImageNet) are well-supported by the experimental results and ablation studies comparing against strong baselines.

**Medium Confidence:** The mechanism explanations for PWPM (gradient magnitude as sensitivity proxy) and COWA (dual-score contribution estimation) are logically consistent with established PFL principles, but could benefit from deeper empirical validation of the underlying assumptions.

**Low Confidence:** The necessity and optimality of MAMO's complex momentum management is the least validated claim, as simpler alternatives are not adequately explored.

## Next Checks

1. **Correlation Analysis:** Measure the actual correlation between COWA scores (Γ_grad, Γ_pred) and subsequent model improvement to validate the contribution metric assumptions.

2. **MAMO Ablation:** Compare CO-PFL with a simplified version using standard momentum updates and static masks to quantify the specific benefit of mask-aware momentum decoupling.

3. **Sensitivity Analysis:** Systematically vary p and γ across multiple datasets to identify if the claimed optimal values (p=0.25, γ=0.50 for CIFAR10) generalize or are dataset-specific artifacts.