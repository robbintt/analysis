---
ver: rpa2
title: Transcribing Rhythmic Patterns of the Guitar Track in Polyphonic Music
arxiv_id: '2510.05756'
source_url: https://arxiv.org/abs/2510.05756
tags:
- guitar
- rhythmic
- patterns
- inproc
- pattern
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the task of transcribing rhythmic patterns
  of guitar tracks in polyphonic music, an area less explored compared to chord transcription.
  The authors propose a three-step framework: (1) approximate stem separation to isolate
  the guitar part, (2) strum detection using a pre-trained MERT model fine-tuned on
  the separated guitar audio, and (3) pattern decoding using a Viterbi algorithm to
  represent strum sequences with rhythmic patterns from an expert-curated vocabulary.'
---

# Transcribing Rhythmic Patterns of the Guitar Track in Polyphonic Music

## Quick Facts
- **arXiv ID**: 2510.05756
- **Source URL**: https://arxiv.org/abs/2510.05756
- **Reference count**: 40
- **Primary result**: F1 score of 94.7% on rhythmic pattern transcription from polyphonic guitar tracks

## Executive Summary
This paper addresses the challenging task of transcribing rhythmic patterns from guitar tracks in polyphonic music, where the guitar is mixed with other instruments. The authors propose a three-stage framework that first separates the guitar from other instruments, then detects strum onsets, and finally decodes these into human-readable rhythmic patterns with bar lines and time signatures. The method achieves high accuracy (94.7% F1) and automatically produces musically plausible transcriptions that capture the underlying rhythmic structure.

## Method Summary
The approach consists of three main stages: (1) Approximate stem separation using HTDemucs to isolate the "other" stem by removing vocals, bass, and drums, leaving the target guitar with reduced interference; (2) Strum detection using a fine-tuned MERT-v1-95M foundation model with an MLP head, trained on the separated audio with shift-tolerant loss and data augmentation; (3) Pattern decoding using Viterbi algorithm with transition probabilities to represent strum sequences as rhythmic patterns from an expert-curated vocabulary of 924 patterns, while automatically detecting bar lines and time signatures using BeatThis. The system is trained and evaluated on 410 songs with multiple difficulty levels, using ground truth transcriptions from expert musicians.

## Key Results
- Achieves 94.7% F1 score on pattern sequence reconstruction using estimated bar lines and transition probabilities
- Fine-tuning foundation model outperforms frozen probing by 18 percentage points (78.6% → 96.5% F1)
- Transition probabilities reduce time-signature discontinuity from 9.4% to 0.1% while maintaining accuracy
- The method automatically produces human-readable transcriptions with bar lines and time signature markers

## Why This Works (Mechanism)

### Mechanism 1: Approximate Stem Separation via Residual Extraction
Removing well-separated sources (vocals, bass, drums) produces a cleaner "other" stem containing the target guitar with less interference than direct guitar extraction, which suffers from poor source separation quality.

### Mechanism 2: Fine-Tuned Foundation Model for Temporal Feature Adaptation
Fine-tuning all encoder layers of MERT allows the model to reorganize pre-trained temporal representations specifically for guitar strum detection, outperforming frozen probing by enabling implicit source separation within polyphonic mixtures.

### Mechanism 3: Viterbi Decoding with Continuity Priors
Adding transition probabilities to pattern decoding improves human readability by favoring pattern repetition and time-signature consistency, without sacrificing accuracy.

## Foundational Learning

- **Polyphonic source separation**: Why needed here - understanding that different instruments can be isolated (imperfectly) explains why "other" stem strategy works. Quick check - can you explain why removing vocals/bass/drums might help guitar detection more than directly extracting guitar?

- **Onset detection with temporal tolerance**: Why needed here - strum detection is a specialized onset detection task; the shift-tolerant loss and 50ms evaluation tolerance acknowledge human timing imprecision. Quick check - why would a model penalized for 10ms timing errors fail to generalize to real performances?

- **Dynamic programming for sequence optimization (Viterbi)**: Why needed here - pattern decoding requires finding the best sequence through a vocabulary given both local evidence and transition constraints. Quick check - if you only used observation likelihood without transition probabilities, what would happen to pattern consistency?

## Architecture Onboarding

- **Component map**: Polyphonic audio → HTDemucs 4-stem → "other" stem → Fine-tuned MERT-v1-95M + MLP head → frame-level onset probabilities → peak-picking → strum timestamps → BeatThis → downbeat estimates → post-processing → bar lines → Viterbi decoder (observation likelihood + transition costs) → pattern sequence + time signatures → Human-readable rhythmic notation

- **Critical path**: Strum detection quality determines everything downstream. The paper shows F1 drops from 96.9% (strum detection) to 94.7% (reconstructed from patterns)—this 2.2% gap is the pattern vocabulary's approximation cost. Bar line estimation errors propagate to pattern boundaries.

- **Design tradeoffs**: "Other" stem vs. guitar stem (better separation quality vs. more interference), fine-tuning vs. probing (better performance vs. more compute and overfitting risk), continuity prior strength (readability vs. sensitivity to legitimate pattern changes), post-processing bar lines (reduces discontinuities but drops F1 slightly).

- **Failure signatures**: Multiple guitars in backing track ("other" stem contains competing rhythms), tempo changes (steady-tempo post-processing assumption breaks), annotation noise in played recordings (human performers deviate from transcriptions), vocabulary coverage gaps (real patterns outside 924 expert patterns).

- **First 3 experiments**: (1) Ablation on stem choice: train identical models on full mix, guitar stem, and "other" stem to reproduce counterintuitive finding; (2) Transition cost sensitivity: sweep c1 and c2 values to characterize accuracy-readability tradeoff; (3) Difficulty-level analysis: compare performance across simplified/intermediate/advanced versions to understand arrangement complexity effects.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Results depend on proprietary dataset with 410 songs, limiting generalization to other genres or musical traditions
- Method assumes relatively steady tempo and regular meter, struggling with songs containing drastic tempo changes or rubato passages
- With 924 expert-curated patterns, there's inherent approximation error when real strumming patterns fall outside this vocabulary

## Confidence
- **High Confidence**: Strum detection performance (96.9% F1 on isolated guitar), effectiveness of fine-tuning vs. probing (18-point gap), general framework architecture
- **Medium Confidence**: Pattern decoding performance (94.7% F1), transition cost values (c1=c2=1.0), beat/downbeat estimation accuracy
- **Low Confidence**: Generalization to non-Western music, complex tempo changes, and datasets with different guitar playing styles or recording qualities

## Next Checks
1. **Cross-Genre Validation**: Test the complete pipeline on datasets from different musical genres (jazz, metal, flamenco) to assess generalization beyond the proprietary pop/rock corpus.

2. **Vocabulary Robustness**: Measure performance degradation when using smaller pattern vocabularies (100, 500 patterns) to understand how vocabulary size affects accuracy and whether the current 924 patterns are necessary.

3. **Tempo Variation Stress Test**: Evaluate performance on songs with significant tempo changes, rubato passages, or irregular meter to identify failure modes of the steady-tempo assumption.