---
ver: rpa2
title: 'GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory
  Networks into RNA Foundation Models'
arxiv_id: '2503.01682'
source_url: https://arxiv.org/abs/2503.01682
tags:
- gene
- drug
- data
- regulatory
- single-cell
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GRNFormer integrates multi-scale gene regulatory networks into
  RNA foundation models by combining cell-type and single-cell resolution GRNs with
  a structure-aware cross-attention mechanism. The framework addresses topological
  imbalance in regulatory networks through biologically-informed edge perturbation
  using co-expression patterns.
---

# GRNFormer: A Biologically-Guided Framework for Integrating Gene Regulatory Networks into RNA Foundation Models

## Quick Facts
- arXiv ID: 2503.01682
- Source URL: https://arxiv.org/abs/2503.01682
- Reference count: 40
- Primary result: GRNFormer achieves 3.6% increase in drug response prediction correlation, 9.6% improvement in single-cell drug classification AUC, and 1.1% gain in gene perturbation accuracy by integrating multi-scale gene regulatory networks into RNA foundation models.

## Executive Summary
GRNFormer addresses a fundamental limitation in RNA foundation models by integrating gene regulatory networks (GRNs) at multiple biological scales. The framework combines cell-type-specific and cell-specific GRNs with a structure-aware cross-attention mechanism to capture regulatory heterogeneity. By perturbing GRNs with biologically-informed co-expression links, the approach overcomes topological imbalance in regulatory networks. Comprehensive experiments across three clinically-relevant tasks demonstrate consistent improvements over baseline models, with gains ranging from 1.1% to 9.6% in prediction accuracy metrics.

## Method Summary
GRNFormer integrates multi-scale gene regulatory networks into RNA foundation models by combining cell-type-specific and cell-specific GRNs with cross-attention fusion. The method constructs GRNs using SCENIC+ pipeline for cell-type eRegulons and AUCell thresholding for cell-specific activity. Edge perturbation replaces 20% of GRN edges with co-expression links to address sparsity. GraphSAGE with fixed neighbor sampling encodes structural information, which is then fused with expression embeddings via multi-head cross-attention. The framework is compatible with multiple RNA foundation models (scGPT, scFoundation, scPaLM) and demonstrates improved performance across drug response prediction, gene perturbation, and single-cell drug classification tasks.

## Key Results
- 3.6% increase in drug response prediction correlation (PCC) compared to baseline models
- 9.6% improvement in single-cell drug classification AUC over previous state-of-the-art
- 1.1% gain in gene perturbation accuracy while maintaining biological interpretability
- Consistent performance improvements across all three tested RNA foundation model architectures
- TF enrichment ratio of 2.011 indicates effective attention weighting toward regulatory factors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-scale GRNs capture regulatory heterogeneity better than single-resolution approaches.
- Mechanism: Cell-type-specific GRNs identify population-level eRegulons via SCENIC+ motif enrichment; cell-specific GRNs binarize regulon activity per cell using AUCell thresholding with Gaussian mixture modeling. The two embeddings are summed.
- Core assumption: Regulatory relationships operate at both population and single-cell levels, and both contribute orthogonal signal to expression embeddings.
- Evidence anchors: Hierarchical GRNs capture regulatory relationships at both cell-type-specific and cell-specific resolutions; bimodal distributions indicate two distinct cell subpopulations; related work on GRN inference from scRNA-seq emphasizes directed signed graphs but does not address multi-scale fusion.
- Break condition: If regulon activity distributions are uniform or thresholding yields trivial partitions, cell-specific GRNs provide no discriminative signal.

### Mechanism 2
- Claim: Cross-attention fusion mitigates information asymmetry between TF-rich and isolated genes.
- Mechanism: Multi-head cross-attention uses expression embeddings as queries and structural embeddings as keys/values, dynamically up-weighting high-centrality TF-gene edges while attenuating unconnected genes. The query-key mechanism prioritizes nodes with higher topological centrality.
- Core assumption: Topological centrality in GRNs correlates with regulatory importance for downstream tasks.
- Evidence anchors: Graph topological adapter using multi-head cross-attention to weight regulatory relationships dynamically; TF enrichment ratio ρ = 2.011 indicating the model attends disproportionately to TFs; graph Transformer frameworks for GRN inference use attention for link prediction but do not explicitly address asymmetry via cross-attention to expression features.
- Break condition: If attention weights concentrate on a small subset of hub TFs and fail to propagate signal to peripheral genes, performance gains diminish.

### Mechanism 3
- Claim: Co-expression-guided edge perturbation improves robustness under GRN sparsity.
- Mechanism: Replace α=0.2 of GRN edges with co-expression links where both genes have non-zero expression in the same cell. GraphSAGE with fixed-size neighbor sampling then aggregates over perturbed graphs.
- Core assumption: Co-expressed genes in the same cell share functional or regulatory relationships that partially compensate for missing annotations.
- Evidence anchors: Edge perturbation strategy that perturb GRNs with biologically-informed co-expression links; co-expression guided perturbation achieves 0.884 PCC vs 0.870 no augmentation vs 0.867 random perturbation; GEARS uses co-expression for perturbation prediction but not as graph augmentation.
- Break condition: If co-expression links are dominated by housekeeping genes or batch effects, perturbation introduces noise rather than signal.

## Foundational Learning

- Concept: Gene Regulatory Networks (GRNs) as directed signed graphs
  - Why needed here: GRNFormer's entire contribution assumes understanding that GRNs encode TF→target relationships with activation/inhibition semantics, not just co-expression correlations.
  - Quick check question: Given a TF with high out-degree and a target gene with no outgoing edges, how would information asymmetry affect a standard GNN?

- Concept: Cross-attention vs concatenation fusion
  - Why needed here: The paper claims cross-attention handles asymmetry better; understanding query/key/value roles is essential to debug attention patterns.
  - Quick check question: If you swap queries and keys in the cross-attention layer, what qualitative change would you expect in TF enrichment ratios?

- Concept: Fixed-size neighbor sampling in GraphSAGE
  - Why needed here: The paper chooses GraphSAGE over GCN/GIN specifically to handle degree imbalance; understanding sampling is critical for reproducing results.
  - Quick check question: With average TF degree 81.3 and non-TF degree 1.3, what happens to embedding magnitude if you use full-neighbor aggregation without sampling?

## Architecture Onboarding

- Component map: scRNA-seq expression vector -> SCENIC+ pipeline -> cell-type GRN + cell-specific GRN via AUCell -> Edge Perturbation (co-expression graph) -> GraphSAGE encoder -> h_cell ⊕ h_type = h_struct -> scGPT/scFoundation/scPaLM backbone -> h_expr -> Multi-head cross-attention P(h_expr, h_struct) -> h_fusion -> h_combined = h_expr + β·h_fusion -> decoder for MLM or task heads

- Critical path:
  1. GRN construction quality determines structural signal strength
  2. Edge perturbation must preserve biological plausibility while improving connectivity
  3. Cross-attention fusion must successfully reweight TF-rich vs sparse regions

- Design tradeoffs:
  - GraphSAGE vs GCN/GIN: Sampling adds stochasticity but controls degree imbalance (1.4% PCC gain over GIN in ablation)
  - Co-expression vs random perturbation: Biologically grounded but requires expression data; random is simpler but degrades performance
  - Hybrid vs single-scale GRNs: 0.5% PCC gain over cell-specific alone, but doubles GNN computation

- Failure signatures:
  - TF enrichment ratio ρ ≈ 1.0: Cross-attention not differentiating TFs; check key/value construction
  - Random perturbation outperforms co-expression: Co-expression graph may be capturing batch effects; filter low-variance genes
  - Cell-specific GRNs show no improvement over cell-type-only: AUCell thresholding may be too aggressive; visualize activity distributions

- First 3 experiments:
  1. Reproduce drug response PCC on CCLE with scGPT backbone; verify 0.875 → 0.906 improvement with default α=0.2
  2. Ablate edge perturbation strategy: compare no-aug, random, co-expression; expect pattern from Table 4
  3. Visualize TF activity distributions for 3-5 TFs; verify bimodal vs skewed patterns match thresholding logic in Appendix D

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can lifelong learning strategies or pseudo-paired multi-omics data construction reduce GRNFormer's dependency on paired scRNA-seq/scATAC-seq data while maintaining performance gains?
- Basis in paper: "Future work could try integrate lifelong learning strategies to reduce multi-modal dependency through atlas-scale data integration...constructing pseudo-paired multi-omics data from existing resources may better leverage heterogeneous datasets."
- Why unresolved: Current optimal GRN construction requires paired multiome data, limiting applicability to datasets lacking scATAC-seq measurements.
- What evidence would resolve it: Experiments comparing GRNFormer performance using pseudo-paired data versus true paired data across downstream tasks.

### Open Question 2
- Question: How much improvement in regulatory network quality could be achieved by integrating GET-style pseudobulk chromatin profiles to resolve ambiguous TF binding patterns?
- Basis in paper: "Future integration of emerging techniques like GET-style pseudobulk chromatin profiles probably could further improve the reliability of gene regulatory information."
- Why unresolved: Current motif databases cannot disambiguate TF binding within shared motif families, potentially introducing regulatory errors.
- What evidence would resolve it: Comparative benchmarking of eRegulon inference accuracy between current SCENIC+ pipeline and GET-enhanced approaches.

### Open Question 3
- Question: Does the edge perturbation ratio (α=0.2) generalize optimally across different GRN topologies, or should it be adapted based on network density?
- Basis in paper: The paper fixes α=0.2 but acknowledges topological imbalance varies (~40% genes lack reliable regulatory links; TFs average degree 81.3 vs. 1.3 for others).
- Why unresolved: Ablation only compares random versus co-expression guided perturbation strategies, not perturbation intensity.
- What evidence would resolve it: Systematic evaluation of α values across cell types with varying regulatory network sparsity.

### Open Question 4
- Question: How does the reference mapping approach for single-omics downstream datasets affect GRN quality when query cells lack close neighbors in the multiome reference space?
- Basis in paper: The paper mentions reference mapping for single-modality data but doesn't evaluate cases where mapping quality may be poor due to limited reference coverage.
- Why unresolved: Performance degradation with distant query cells could limit clinical deployment where patient samples differ from reference atlases.
- What evidence would resolve it: Analysis of prediction accuracy stratified by nearest-neighbor distance in reference embedding space.

## Limitations

- Edge perturbation strategy lacks qualitative analysis of which specific edges are being added and whether they represent novel regulatory relationships
- Choice of α=0.2 for edge perturbation is not justified through ablation studies
- Biological interpretability claims require validation that perturbed edges genuinely represent novel regulatory relationships
- Current approach requires paired scRNA-seq/scATAC-seq data, limiting applicability to datasets without multi-omics measurements

## Confidence

- **High Confidence**: The core observation that integrating multi-scale GRNs improves foundation model performance (PCC increases of 3.6-9.6% across tasks)
- **Medium Confidence**: The specific mechanism of cross-attention for handling topological imbalance
- **Low Confidence**: The biological interpretability claims regarding perturbed edges and attention patterns

## Next Checks

1. **Edge Perturbation Validation**: Conduct a controlled experiment where co-expression edges are filtered by functional similarity (GO terms, pathway membership) before perturbation. Compare performance against unfiltered perturbation to assess whether biologically meaningful edges drive improvements.

2. **Cross-Attention Ablation**: Replace cross-attention with simpler fusion methods (concatenation followed by linear projection, or gating mechanisms) while keeping all other components constant. Measure whether the 1.4% PCC improvement over GCN/GIN is specifically due to cross-attention or the combination of sampling and fusion.

3. **GRN Quality Impact**: Systematically vary GRN quality by adjusting SCENIC+ parameters (motif databases, co-expression thresholds) and measure downstream performance degradation. This would quantify the sensitivity of GRNFormer to GRN construction quality.