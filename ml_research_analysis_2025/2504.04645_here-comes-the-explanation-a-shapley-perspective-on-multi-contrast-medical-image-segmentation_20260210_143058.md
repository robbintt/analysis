---
ver: rpa2
title: 'Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical
  Image Segmentation'
arxiv_id: '2504.04645'
source_url: https://arxiv.org/abs/2504.04645
tags:
- shapley
- segmentation
- dice
- swin-unetr
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes using contrast-level Shapley values to explain
  multi-contrast medical image segmentation models. The method provides cross-contrast
  understanding by quantifying the contribution of each MRI modality (T1-weighted,
  T1-weighted post-contrast, T2-weighted, and T2 Fluid Attenuated Inversion Recovery)
  to segmentation performance metrics such as Dice score and HD95.
---

# Here Comes the Explanation: A Shapley Perspective on Multi-contrast Medical Image Segmentation

## Quick Facts
- arXiv ID: 2504.04645
- Source URL: https://arxiv.org/abs/2504.04645
- Reference count: 0
- Key outcome: Proposes using contrast-level Shapley values to quantify MRI modality contributions to segmentation performance, revealing architectural biases not captured by pixel-level methods

## Executive Summary
This study introduces a novel explainability framework for multi-contrast medical image segmentation using contrast-level Shapley values. The method quantifies each MRI modality's contribution to segmentation metrics (Dice score, HD95) for models like U-Net and Swin-UNETR on brain tumor segmentation tasks. Results show U-Net exhibits bias toward T1-contrast and FLAIR, while Swin-UNETR provides more balanced contrast utilization. The approach offers clinically relevant insights by aligning with radiologists' practice of detecting lesions through differences between MRI contrasts.

## Method Summary
The framework computes contrast-level Shapley values using exact enumeration of all 2⁴=16 contrast coalitions for four MRI modalities (T1-weighted, T1-weighted post-contrast, T2-weighted, T2 FLAIR). For each coalition, the method evaluates segmentation performance metrics, then calculates marginal contributions weighted by coalition size. Statistical testing (Levene's, Kruskal-Wallis, Dunn's post-hoc) across 5-fold cross-validation identifies consistent explanation patterns. The approach treats each contrast as a "player" in a cooperative game, quantifying how much each modality contributes to overall segmentation quality.

## Key Results
- U-Net shows clear bias toward T1-contrast and FLAIR with higher Shapley values for these modalities
- Swin-UNETR demonstrates more balanced Shapley value distribution across all four contrasts
- Statistical analysis reveals significant fold-wise variation in explanations, with Swin-UNETR showing greater consistency for T1-contrast
- Cross-contrast Shapley values reveal architectural differences invisible to pixel-level methods like GradCAM

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Contrast-level Shapley values quantify each MRI modality's contribution to segmentation performance metrics.
- **Mechanism:** The method computes Shapley values using the formula φᵢ(M) = Σ [|S|!(|N|-|S|-1)!/|N|!] × (M(S∪{i}) - M(S)), where N is the set of all MRI contrasts, S is a subset excluding contrast i, and M is the target metric (Dice or HD95). This evaluates all possible coalitions of contrasts to isolate each contrast's marginal contribution.
- **Core assumption:** The segmentation metric (Dice/HD95) accurately reflects clinically meaningful performance, and contrasts contribute additively in a game-theoretic sense.
- **Evidence anchors:**
  - [section 2.4] Equation 2 defines the contrast-level Shapley value computation with the complete formula.
  - [abstract] "quantifying the contribution of each MRI modality... to segmentation performance metrics such as Dice score and HD95"
  - [corpus] Limited direct corpus validation; neighbor paper "Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement" supports Shapley-based segmentation explanation but not contrast-level specifically.

### Mechanism 2
- **Claim:** Shapley-based cross-contrast explanation reveals architectural biases that pixel-level methods (GradCAM) cannot capture.
- **Mechanism:** Pixel-level methods like GradCAM produce heatmaps showing spatial attention within each contrast independently. Contrast-level Shapley instead treats each contrast as a "player" and computes coalition-based contributions, enabling direct comparison of how architectures weigh modalities. U-Net shows higher Shapley values for t1c and t2f; Swin-UNETR distributes more evenly including t1n.
- **Core assumption:** Balanced contrast utilization correlates with more robust generalization across tumor subtypes (e.g., metastasis vs glioblastoma where necrotic core definitions differ).
- **Evidence anchors:**
  - [section 4] "U-Net exhibits a bias toward features from t1c and t2f, while Swin-UNETR distributes its explanations more evenly across contrasts"
  - [figure 4 caption] Shows case where Swin-UNETR achieves 25% higher Dice, with Shapley revealing positive t1n contribution (0.24) vs U-Net's lower value (0.12)
  - [corpus] Neighbor paper on SHAP for time series notes computational complexity and stability issues—relevant to robustness concerns.

### Mechanism 3
- **Claim:** Statistical testing across folds quantifies explanation consistency, identifying which models learn invariant representations.
- **Mechanism:** For each model-metric-contrast combination, the framework applies Levene's test (variance homogeneity) and Kruskal-Wallis (mean differences) across 5 folds. Post-hoc Dunn's tests identify which fold pairs differ. Swin-UNETR shows more consistent t1c explanations across specific fold pairs (e.g., folds 1&5, 2&3).
- **Core assumption:** Explanation consistency across data splits indicates representation robustness rather than overfitting to training distribution quirks.
- **Evidence anchors:**
  - [section 3.2] "all 32 Levene's tests yield p < 0.01, rejecting H₀(σ)... all 32 Kruskal-Wallis tests yield p < 0.01"
  - [table 2] Shows Swin-UNETR has 4 fold-pairs with no significant t1c explanation difference (p > 0.01), while "All other tests" yield p < 0.01
  - [corpus] No direct corpus evidence on cross-fold explanation consistency metrics.

## Foundational Learning

- **Concept: Shapley Values (Game Theory)**
  - **Why needed here:** Core mathematical framework; without understanding coalition-based marginal contribution, the attribution interpretation is opaque.
  - **Quick check question:** Given 3 players with values [0.3, 0.2, 0.5] representing their Shapley contributions, what does it mean if the sum doesn't equal the total performance gain?

- **Concept: Multi-contrast MRI Physics**
  - **Why needed here:** Each contrast (T1n, T1c, T2w, FLAIR) highlights different tissue properties. Understanding why t2f suppresses CSF signal (making edema visible) explains clinical relevance.
  - **Quick check question:** Why would a model heavily weighting t1c and t2f struggle with metastasis segmentation where the necrotic core definition differs from glioblastoma?

- **Concept: Segmentation Metrics (Dice, HD95)**
  - **Why needed here:** Shapley values are computed *with respect to* these metrics. If the metric doesn't capture what matters clinically, attributions inherit that limitation.
  - **Quick check question:** A segmentation achieves 90% Dice but misses a thin enhancing rim critical for surgical planning—what does this imply for Shapley interpretation?

## Architecture Onboarding

- **Component map:**
  1. Data loader → 4-channel 3D MRI volumes (t1n, t1c, t2w, t2f) + ground truth masks (3 classes: ET, NCR, ED)
  2. Segmentation model → U-Net / SegResNet / UNETR / Swin-UNETR (trained independently)
  3. Shapley evaluator → Iterates over all 2⁴=16 contrast coalitions, computes metric for each
  4. Statistical analyzer → Levene's, Kruskal-Wallis, Dunn's post-hoc, confidence intervals

- **Critical path:**
  1. Train segmentation model on full 4-contrast input (or load pretrained)
  2. For each test subject, enumerate all contrast subsets S ⊆ {t1n, t1c, t2w, t2f}
  3. For each subset, run inference with missing contrasts zeroed/masked, compute Dice/HD95
  4. Apply Shapley formula to compute φᵢ for each contrast
  5. Aggregate across subjects/folds, run statistical tests

- **Design tradeoffs:**
  - **Exact vs. approximate Shapley:** Paper uses exact enumeration (2⁴=16 subsets feasible for 4 contrasts). Scaling to >6 contrasts requires approximation (e.g., SHAP sampling), trading accuracy for speed.
  - **Metric choice:** Dice emphasizes overlap; HD95 emphasizes boundary accuracy. Different metrics yield different Shapley distributions.
  - **Assumption:** Zeroing contrasts (vs. removing channels entirely) may introduce distribution shift artifacts.

- **Failure signatures:**
  - **Inconsistent explanations across folds:** High variance in Cᵢʷ,ᶠ(M) suggests model overfits to contrast-specific features in training split.
  - **Negative Shapley values:** Indicates contrast harms performance for that subject/metric (see Figure 4: t1c has φ = -0.09 for Swin-UNETR on a specific case).
  - **All Shapley values near zero:** Suggests model ignores input contrasts (check data loading, channel ordering).

- **First 3 experiments:**
  1. **Sanity check:** Train U-Net on single-contrast (t1c only) inputs. Verify Shapley assigns ~100% to t1c, near-zero to others.
  2. **Architecture comparison:** Replicate paper's main result—train U-Net and Swin-UNETR on same BraTS fold, compute Shapley for both, confirm U-Net's t1c/t2f bias vs Swin-UNETR's balanced distribution.
  3. **Ablation on metric:** Compute Shapley with respect to Dice vs HD95 for same model. Assess whether attribution patterns are metric-dependent (paper hints they're similar but doesn't show full comparison).

## Open Questions the Paper Calls Out

- **Question:** Can contrast-level Shapley values be utilized as a regularization loss during training to explicitly correct the bias toward specific MRI contrasts in architectures like U-Net?
- **Basis in paper:** [inferred] The paper identifies that U-Net exhibits a bias toward T1-contrast and FLAIR, which may contribute to segmentation errors (e.g., confusing edema), but treats the Shapley value solely as a post-hoc explanation metric.
- **Why unresolved:** The study focuses on analyzing pre-trained models rather than modifying the training objective to optimize for balanced contrast utilization.
- **What evidence would resolve it:** A comparative experiment showing that a model trained with a Shapley-based penalty achieves a more balanced contrast weighting distribution without a reduction in Dice score or HD95.

## Limitations
- The method assumes performance metrics fully capture clinically meaningful segmentation quality
- Contrast-level Shapley assumes additive coalition contributions without considering interaction effects
- Limited to brain tumor segmentation with four specific MRI contrasts, limiting generalizability
- Statistical testing assumptions (independence, sufficient sample sizes) may not be fully validated

## Confidence
- **High confidence:** Shapley computation mechanism and mathematical framework are well-established and correctly applied
- **Medium confidence:** Architectural bias observations are supported by results but require external validation
- **Medium confidence:** Cross-fold consistency analysis is methodologically sound but depends on test assumptions

## Next Checks
1. Validate whether negative Shapley values consistently indicate harmful contrasts across multiple subjects and models
2. Test the method on a different multi-contrast medical imaging task (e.g., cardiac MRI segmentation) to assess generalizability
3. Compare Shapley-based contrast attribution with alternative explanation methods (e.g., integrated gradients at the contrast level) to verify consistency of insights