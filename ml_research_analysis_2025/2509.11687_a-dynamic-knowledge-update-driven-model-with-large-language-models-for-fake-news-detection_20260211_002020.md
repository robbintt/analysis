---
ver: rpa2
title: A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake
  News Detection
arxiv_id: '2509.11687'
source_url: https://arxiv.org/abs/2509.11687
tags:
- news
- knowledge
- detection
- fake
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of fake news detection in the
  context of rapidly evolving news events, where the authenticity of news can change
  as events develop. The proposed model, DYNAMO, integrates large language models
  (LLMs) with dynamically updated knowledge graphs to achieve dual functions: news
  authenticity detection and verification of new knowledge correctness.'
---

# A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection

## Quick Facts
- arXiv ID: 2509.11687
- Source URL: https://arxiv.org/abs/2509.11687
- Reference count: 20
- Accuracy: 62.50% on Hover dataset, 61.67% on Feverous dataset

## Executive Summary
This paper addresses the challenge of fake news detection in rapidly evolving news events where authenticity can change over time. The proposed DYNAMO model integrates large language models with dynamically updated knowledge graphs to achieve dual functions: news authenticity detection and verification of new knowledge correctness. By decomposing complex news into simpler sub-questions using Monte Carlo Tree Search and grounding reasoning with structured knowledge triples, the model demonstrates state-of-the-art performance on two real-world datasets.

## Method Summary
DYNAMO combines large language models with a knowledge graph to detect fake news in evolving news events. The system uses Monte Carlo Tree Search to decompose complex news claims into simpler sub-questions, verifies their authenticity step by step, and extracts new knowledge from verified real news to update the knowledge graph. This creates a feedback loop where the knowledge graph evolves alongside news events, enabling the model to adapt to changing information without retraining the LLM. The approach addresses the timeliness requirements of fake news detection by continuously updating its knowledge base with verified information.

## Key Results
- Achieves 62.50% accuracy on Hover dataset and 61.67% accuracy on Feverous dataset
- Demonstrates 74.01% F1 score on Hover and 74.33% F1 score on Feverous
- Shows 1% performance improvement when using updated knowledge graph compared to static version
- Outperforms baseline models that rely on static knowledge or multimodal fusion approaches

## Why This Works (Mechanism)

### Mechanism 1: Search-Based Semantic Decomposition
Breaking complex news into simpler sub-questions via Monte Carlo Tree Search reduces the reasoning burden on the LLM, potentially increasing detection accuracy. The model explores various reasoning paths, selecting actions to generate and answer sub-questions sequentially, processing smaller semantic chunks rather than long, entangled narratives.

### Mechanism 2: Knowledge Graph Context Injection
Providing structured knowledge triples during reasoning grounds the LLM and mitigates hallucinations from outdated internal parameters. During the MCTS answer phase, the model retrieves relevant triples from the knowledge graph, serving as external memory that explicitly defines entity relationships before the LLM generates answers.

### Mechanism 3: Verification-Gated Knowledge Evolution
Classifying news as "Real" with high confidence and extracting its triples creates a feedback loop that improves future detection capability. The system treats high-confidence "Real" news as ground truth, extracting and storing new triples to update the knowledge graph, allowing adaptation to evolving news events without LLM retraining.

## Foundational Learning

- **Monte Carlo Tree Search (MCTS) in NLP**: Understanding how MCTS balances exploration vs. exploitation to navigate the exponential search space of possible question decompositions is crucial. Quick check: How does the UCT formula prevent the model from getting stuck in loops of irrelevant questions?

- **Knowledge Graph Construction (KGC)**: The system relies on "Entity-Centered" and "Event-Centered" extraction, requiring distinction between static relations and dynamic events. Quick check: Why does the paper distinguish between these two extraction types rather than using a single schema?

- **Retrieval-Augmented Generation (RAG) vs. Knowledge Graphs**: The paper critiques RAG for "noisy information," highlighting the difference between retrieving unstructured chunks and structured triples. Quick check: Why is a structured Knowledge Graph more suitable than standard RAG retrieval from web pages?

## Architecture Onboarding

- **Component map**: KG Constructor -> MCTS Controller -> Reasoner (LLM) -> Updater
- **Critical path**: Input News -> Root Node -> MCTS Loop (Select -> Expand -> Retrieve KG Context -> Evaluate -> Backpropagate) -> Majority Vote on leaf nodes -> Final Label
- **Design tradeoffs**: Height limit (h=5 for Hover, h=9 for Feverous) balances complex reasoning against latency; majority voting requires 5 search iterations for robustness but increases inference time linearly
- **Failure signatures**: KG poisoning from false positives causes topic-specific accuracy drops; empty retrieval occurs when entities aren't in the KG; reasoning loops generate repetitive sub-questions without reaching conclusions
- **First 3 experiments**:
  1. Unit Test KG Retrieval: Verify sub-graph retrieval for known entities like "Dwight D. Eisenhower" returns expected relations
  2. Ablation on Tree Height (h): Compare detection accuracy on Feverous with h=2 vs h=9 on verbose news
  3. Update Validation: Test that model classifies news as "Real" only when update mechanism is enabled for facts established in previous items

## Open Questions the Paper Calls Out

- **Knowledge Extraction from Partially Fake News**: How can the model effectively extract valid knowledge from news articles containing mixtures of true and false information? The current approach ignores "Fake" news entirely, losing potentially useful factual information embedded within fabricated stories.

- **Knowledge Graph Degradation from False Positives**: To what extent does the accumulation of false positive errors degrade the reliability of the knowledge graph over time? The paper doesn't analyze the long-term feedback loop where noisy data from false positives permanently enters the retrieval system.

- **Conflict Resolution for Contradictory Knowledge**: How should the model handle logical contradictions or temporal obsolescence when new knowledge conflicts with existing knowledge graph triples? The update mechanism adds new triples without defining how to delete or correct outdated or contradictory facts.

## Limitations
- The KG construction methodology is vague regarding whether triples come from the same evidence documents used for verification or from a separate reliable corpus
- Critical implementation details like prompt templates, entity linking approach, and UCT parameters are insufficiently documented for exact replication
- The evaluation claims "out-of-distribution" testing but uses datasets that may share underlying distributions, raising questions about generalizability

## Confidence

- **High Confidence**: The mechanism of using MCTS for semantic decomposition and KG grounding to reduce LLM hallucination is theoretically sound and supported by decomposition literature
- **Medium Confidence**: The knowledge evolution mechanism is plausible given the 1% performance improvement, though KG poisoning risk is concerning
- **Low Confidence**: Specific implementation details (prompt templates, entity linking, UCT parameters) are insufficiently documented to guarantee faithful reproduction

## Next Checks

1. **KG Retrieval Robustness Test**: Input a claim with entities known to exist in the Feverous KG and verify consistent retrieval of relevant triples to validate entity linking and KG construction

2. **Decomposition Quality Analysis**: Run MCTS on complex claims and manually evaluate whether generated sub-questions genuinely simplify reasoning or merely rephrase the original claim to test cognitive load reduction

3. **Update Mechanism Safety Test**: Deliberately inject a known false claim labeled as "Real" and track whether it introduces incorrect triples into the KG, monitoring if subsequent similar false information receives higher "Real" classification scores to confirm poisoning hypothesis