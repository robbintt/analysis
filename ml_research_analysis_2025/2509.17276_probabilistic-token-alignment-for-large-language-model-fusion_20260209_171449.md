---
ver: rpa2
title: Probabilistic Token Alignment for Large Language Model Fusion
arxiv_id: '2509.17276'
source_url: https://arxiv.org/abs/2509.17276
tags:
- token
- alignment
- fusion
- pta-llm
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of knowledge fusion between large
  language models (LLMs) with different tokenizers, where existing methods rely on
  manually predefined token alignment that fails to capture context-specific patterns
  and leads to performance degradation. The proposed PTA-LLM method reformulates token
  alignment as an optimal transport problem, introducing a probabilistic alignment
  approach that leverages global generative distributions from source and target models
  to create more coherent fused representations.
---

# Probabilistic Token Alignment for Large Language Model Fusion

## Quick Facts
- arXiv ID: 2509.17276
- Source URL: https://arxiv.org/abs/2509.17276
- Reference count: 40
- PTA-LLM achieves 1.72% average performance gain across 78 tasks compared to state-of-the-art baselines

## Executive Summary
This paper addresses the challenge of knowledge fusion between large language models (LLMs) with different tokenizers, where existing methods rely on manually predefined token alignment that fails to capture context-specific patterns. The proposed PTA-LLM method reformulates token alignment as an optimal transport problem, introducing a probabilistic alignment approach that leverages global generative distributions from source and target models to create more coherent fused representations. This soft alignment captures intricate linguistic context better than hard mapping strategies. Empirical results show PTA-LLM achieves an average 1.72% performance gain across 78 tasks compared to state-of-the-art baselines, with notable improvements in coding (2.06%), safety (3.85%), and multilingual tasks (3.27%), while demonstrating stability in challenging scenarios and interpretability through distributional analysis.

## Method Summary
PTA-LLM operates through a two-stage pipeline: First, an offline alignment stage generates probability matrices for all models, aligns source/target token sequences using dynamic programming, and computes Optimal Transport (Sinkhorn) on Top-10 logits using Minimum Edit Distance (MinED) cost. Second, a training stage fine-tunes the target Llama-2 model using the aligned fused distributions with a combined loss of λ L_CLM + (1-λ) L_Fusion. The method handles sequence length mismatches through dynamic token pairing and creates probabilistic alignments that capture distributional structure rather than relying on static one-to-one mappings.

## Key Results
- PTA-LLM achieves 1.72% average performance gain across 78 tasks compared to state-of-the-art baselines
- Notable improvements in coding tasks (2.06%), safety tasks (3.85%), and multilingual tasks (3.27%)
- Demonstrates stability and interpretability through distributional analysis and performance consistency across challenging scenarios
- Outperforms hard-mapping baselines particularly in tasks with significant vocabulary differences

## Why This Works (Mechanism)

### Mechanism 1
Reformulating token alignment as an Optimal Transport (OT) problem may capture intricate linguistic context better than hard mapping strategies. Instead of a static one-to-one map, PTA-LLM calculates a "transport plan" that minimizes the cost of moving probability mass from source logits to target logits, creating a soft, probabilistic alignment that preserves the distributional structure of the source model's knowledge.

### Mechanism 2
Dynamic token pairing enables architecture-agnostic fusion by handling sequence length mismatches prior to logit alignment. A dynamic programming approach finds an optimal alignment between source and target token sequences of potentially different lengths, allowing a single token in one model to map to multiple tokens in another, resolving structural discrepancies before probabilistic alignment occurs.

### Mechanism 3
Incorporating logit values into the alignment optimization creates more coherent representations than surface-level string matching alone. The optimization objective minimizes "information loss" rather than just string distance, ensuring the fused representation respects the probability distribution (confidence) of the source model, not just the token identity.

## Foundational Learning

- **Concept: Optimal Transport (Sinkhorn Algorithm)**
  - **Why needed here:** This is the mathematical engine of PTA-LLM, converting discrete token alignment into a continuous, solvable optimization problem.
  - **Quick check question:** Can you explain why the Sinkhorn algorithm is preferred over linear programming for computing the transport plan in large-scale settings?

- **Concept: Knowledge Fusion vs. Weight Merging**
  - **Why needed here:** The paper positions itself explicitly against weight merging, operating on output distributions (logits) rather than model parameters.
  - **Quick check question:** Why does weight merging typically require identical architectures, and how does PTA-LLM bypass this requirement?

- **Concept: Tokenization and Vocabulary Misalignment**
  - **Why needed here:** The core problem being solved is that "cat" might be token 51 in one model and 79 in another, creating friction for fusion.
  - **Quick check question:** How does the "vocabulary size" difference between Llama-2 (32k) and MPT (50k) complicate the fusion process?

## Architecture Onboarding

- **Component map:** Inference Engine -> Dynamic Pairing Module -> OT Solver (Sinkhorn) -> Fusion Layer -> Trainer
- **Critical path:** The OT Solver is the bottleneck, converting raw logits into the aligned "fused matrix." If this step is inaccurate or the cost matrix C is poorly defined, the training signal will be noisy.
- **Design tradeoffs:**
  - Window Size (Top-k): Restricting to top-10 logits reduces complexity but risks discarding long-tail knowledge
  - Lambda (λ): High λ retains target's original capabilities but learns less from sources; low λ risks catastrophic forgetting
  - MinCE vs. AvgCE: MinCE selects single best source model per sample (higher variance), AvgCE averages them (lower variance, potential noise dilution)
- **Failure signatures:**
  - Performance Collapse on Reasoning: Soft alignment may smear probability mass too much, losing precise logical inference
  - Training Instability: Loose Sinkhorn convergence threshold causes erratic transport plan and gradient instability
- **First 3 experiments:**
  1. Lambda Sensitivity Analysis: Run ablations on λ (e.g., 0.5, 0.8, 0.9) on small validation set
  2. OT vs. MinED Baseline: Compare specifically on multilingual or coding tasks to verify 3.27% and 2.06% gains
  3. Visualization of Transport: Reproduce Figure 3 to ensure fused tokens cluster closer to target than source distribution

## Open Questions the Paper Calls Out

### Open Question 1
Can an end-to-end fusion pipeline be developed that dynamically controls token alignment during training, rather than relying on a separate pre-computation stage? The current PTA-LLM method splits the process into two stages: offline alignment matrix generation and subsequent supervised training, preventing alignment strategy from adapting dynamically to the model's evolving state during fine-tuning.

### Open Question 2
Do N-1 or 1-N token mapping strategies offer superior performance for knowledge fusion compared to the current strict 1-1 mapping constraint? The Optimal Transport formulation typically enforces strict conservation of mass that aligns with one-to-one mapping, limiting flexibility for complex tokenization differences.

### Open Question 3
Can semantic similarity-based metrics outperform minimum edit distance as the cost function for calculating the optimal transport plan? Minimum edit distance relies on surface-level string character overlaps, which may fail to capture deep semantic relationships between tokens in different vocabularies.

### Open Question 4
How can the fusion framework effectively mitigate the negative impact of fusing significantly weaker source models? While the current method selects distributions based on Minimum Cross-Entropy (MinCE), it lacks a robust mechanism to completely filter out or re-weight capabilities from source models that are universally inferior to the target model on specific tasks.

## Limitations
- Computational bottleneck remains due to Sinkhorn algorithm complexity with large vocabularies, despite Top-10 restriction
- Source model selection ambiguity: rationale for MinCE over averaging is underdeveloped and lacks quantified impact on stability
- Dataset representativeness concerns: MiniPile composition and domain coverage not detailed, potentially limiting generalization to specialized tasks

## Confidence

**High Confidence (80-100%):** The core mathematical framework (Optimal Transport reformulation) is sound and well-established. Empirical results showing PTA-LLM outperforming MinED baseline across multiple task categories are reproducible given specified hyperparameters.

**Medium Confidence (50-80%):** The mechanism by which soft alignment captures "intricate linguistic context" is theoretically plausible but lacks direct quantitative validation and human evaluation of fused outputs.

**Low Confidence (0-50%):** Computational efficiency claims are weak without runtime benchmarks or memory usage analysis, leaving practical viability for large-scale deployment uncertain.

## Next Checks

1. **Scalability Validation:** Reproduce alignment stage with larger vocabulary disparity (e.g., 50k vs. 32k vs. 100k) and measure accuracy degradation and computational overhead to quantify whether Top-10 restriction is sufficient as model sizes increase.

2. **Source Selection Ablation:** Implement and compare MinCE, AvgCE, and hybrid selection strategies across subset of tasks (particularly multilingual and coding) to determine whether variance in MinCE selection meaningfully impacts final model quality.

3. **Cost Matrix Sensitivity Analysis:** Replace MinED cost with semantic similarity measures (e.g., cosine distance of token embeddings) and compare resulting transport plans and downstream task performance to determine whether edit distance is optimal for capturing semantic alignment.