---
ver: rpa2
title: Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion
  Models
arxiv_id: '2506.14919'
source_url: https://arxiv.org/abs/2506.14919
tags:
- image
- diffusion
- images
- medical
- membership
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses privacy risks in diffusion models used for
  medical image generation by proposing a Frequency-Calibrated Reconstruction Error
  (FCRE) method for Membership Inference Attacks (MIA). The core innovation lies in
  mitigating the confounding effect of inherent image difficulty by focusing on reconstruction
  errors within a specific mid-frequency range, excluding both high-frequency regions
  (difficult to reconstruct) and low-frequency regions (less informative).
---

# Frequency-Calibrated Membership Inference Attacks on Medical Image Diffusion Models

## Quick Facts
- arXiv ID: 2506.14919
- Source URL: https://arxiv.org/abs/2506.14919
- Reference count: 26
- This paper proposes a frequency-calibrated reconstruction error method that significantly improves membership inference attack success rates on medical image diffusion models.

## Executive Summary
This paper addresses privacy risks in diffusion models used for medical image generation by proposing a Frequency-Calibrated Reconstruction Error (FCRE) method for Membership Inference Attacks (MIA). The core innovation lies in mitigating the confounding effect of inherent image difficulty by focusing on reconstruction errors within a specific mid-frequency range, excluding both high-frequency regions (difficult to reconstruct) and low-frequency regions (less informative). The method combines frequency-selective analysis with SSIM-based similarity metrics to create a more robust membership inference score.

Experiments on three medical image datasets (FeTS 2022 brain MRI, ChestX-ray8, and CIFAR-10) demonstrate that FCRE significantly outperforms existing MIA methods. On FeTS 2022, FCRE achieves 85.3% Attack Success Rate (ASR) and 92.6% Area Under Curve (AUC), compared to 78.7% ASR and 82.5% AUC for the best baseline. Similar improvements are observed on ChestX-ray8. The results validate the effectiveness of frequency-based difficulty calibration for enhancing membership inference in medical imaging contexts.

## Method Summary
The FCRE method addresses membership inference by calibrating reconstruction error measurements through frequency domain analysis. The attack first computes Laplacian scores on image patches to identify mid-frequency regions, then applies a binary mask to exclude both high-frequency (difficult to reconstruct) and low-frequency (less informative) areas. During the attack, partial DDIM inversion is performed to obtain reconstruction estimates, and the MIA score combines both L2 distance and SSIM-based structural similarity on the masked frequency regions. The method assumes that mid-frequency reconstruction fidelity better distinguishes between member and non-member images than full-spectrum measurements.

## Key Results
- FCRE achieves 85.3% ASR and 92.6% AUC on FeTS 2022 brain MRI dataset, outperforming baseline methods
- On ChestX-ray8 dataset, FCRE demonstrates improved attack performance over existing approaches
- The frequency calibration mechanism reduces false positives by excluding high-frequency regions where reconstruction errors are confounded by inherent difficulty

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** FCRE posits that reconstruction error is a confounded signal, influenced by both "membership" status and "inherent image difficulty" (frequency distribution).
- **Mechanism:** The method disentangles these factors by applying a frequency-domain mask. By calculating the Laplacian score on patches of the original image, it creates a binary mask $L(p)$ that retains only mid-frequency patches. This explicitly excludes high-frequency patches (where diffusion models inherently struggle to reconstruct details, causing false positives for non-members) and low-frequency patches (which offer low discriminatory power).
- **Core assumption:** The method assumes that the "mid-frequency" range is the "sweet spot" where the difference in reconstruction fidelity between member and non-member images is maximized and least affected by noise.
- **Evidence anchors:**
  - [Abstract]: "mitigating the confounding effect of inherent image difficulty by focusing on reconstruction errors within a specific mid-frequency range"
  - [Section 2.2]: "This excludes the area of scores above Lmax and below Lmin in the patches."
  - [Corpus]: Note: Corpus neighbors focus on tabular/VLM domains; specific validation for frequency calibration in medical imaging is absent from the provided neighbors.
- **Break condition:** If a medical imaging dataset lacks distinct frequency polarization (e.g., uniform textures), or if the model is trained to specifically reconstruct high-frequency details perfectly, this frequency masking may discard informative signals.

### Mechanism 2
- **Claim:** Membership inference accuracy improves when error measurement aligns with perceptual similarity rather than just pixel-wise divergence.
- **Mechanism:** The method computes the Structural Similarity Index (SSIM) between the frequency-calibrated reconstruction $\tilde{x}^F_t$ and the original $x^F_t$. This score is converted to a distance $(1 - \text{SSIM})$ and added to the $L_2$ loss. SSIM captures structural changes (luminance, contrast, structure) that simple $L_2$ distances might miss or weight inappropriately.
- **Core assumption:** Assumption: Reconstruction errors in the mid-frequency range manifest as structural distortions that SSIM is uniquely capable of detecting compared to pixel metrics alone.
- **Evidence anchors:**
  - [Section 2.3]: "SSIM focuses on structural similarity... providing more accurate membership inference."
  - [Table 1]: FCRE (L2+SSIM) consistently outperforms FCRE (L2) on medical datasets (FeTS 2022 AUC 0.926 vs 0.898).
  - [Corpus]: Weak direct evidence in neighbors; "MIA-EPT" relies on error prediction for tabular data, lacking the spatial/perceptual component found here.
- **Break condition:** If the diffusion process introduces artifacts that lower SSIM without affecting the "membership" status (e.g., specific noise patterns), or if images are gravitationally aligned but structurally distinct, the metric may fail.

### Mechanism 3
- **Claim:** Deterministic inversion trajectories (DDIM) are more symmetric for training samples (members) than unseen samples.
- **Mechanism:** This leverages the underlying SecMI principle. The attack does not train a separate shadow model. Instead, it observes the discrepancy $||\tilde{x}_t - x_t||$. Because the model $\epsilon_\theta$ has seen member images during training, its posterior estimation during the reverse process aligns more closely with the forward process noise for members than for non-members.
- **Core assumption:** The model has effectively "memorized" or "overfitted" to the training distribution such that the denoising trajectory is measurably tighter for members.
- **Evidence anchors:**
  - [Page 2]: "Specifically, DDIM exhibits better inversion symmetry for images from the training set... so it is able to better reconstruct the original image."
  - [Corpus]: "Winning the MIDST Challenge" supports the general efficacy of MIA on diffusion models, though in a tabular context.
- **Break condition:** If the diffusion model is under-trained or heavily regularized (e.g., differential privacy) such that the loss landscape is flat and reconstruction is equally "average" for all inputs.

## Foundational Learning

- **Concept: Denoising Diffusion Implicit Models (DDIM)**
  - **Why needed here:** The entire attack relies on the deterministic nature of DDIM inversion. Unlike stochastic DDPM, DDIM allows one to map an image back to noise and forward again consistently, which is required to calculate the "reconstruction error."
  - **Quick check question:** Can you explain why a deterministic sampling process is required to measure the "inversion symmetry" error used in this attack?

- **Concept: Frequency Domain Analysis (Laplacian)**
  - **Why needed here:** The core innovation is filtering frequency bands. Understanding that the Laplacian operator detects rapid intensity changes (high frequencies) helps explain how the paper isolates "mid-frequency" patches via thresholding.
  - **Quick check question:** Why would a high Laplacian score typically correspond to "hard-to-reconstruct" high-frequency details in a diffusion model?

- **Concept: SSIM (Structural Similarity Index)**
  - **Why needed here:** The paper combines SSIM with L2 loss. Unlike L2, which averages pixel errors, SSIM is perceptual.
  - **Quick check question:** Why is pure L2 distance potentially misleading when comparing medical image reconstructions where structural fidelity (organ shapes) matters more than exact pixel intensity?

## Architecture Onboarding

- **Component map:** Input Image $x_0$ -> Frequency Analyzer (Laplacian scores) -> Binary Mask $L(p)$ -> Diffusion Inverter (DDIM partial reverse/forward) -> Error Estimator (SSIM + L2 on masked regions) -> Decision Engine (threshold comparison)

- **Critical path:** The definition of the thresholds $L_{min}$ and $L_{max}$. As shown in Table 2, incorrect thresholds (e.g., 0% to 100%) degrade performance significantly. The mask must be calculated on the *original* image and applied to the *noisy* latents.

- **Design tradeoffs:**
  - **Frequency Thresholds:** Dataset dependent. The paper used 15%-85% but noted optimal values vary.
  - **Step Selection:** The paper uses partial reverse processes; the specific time step $t$ or range of steps affects how much "noise" vs "structure" is being compared.

- **Failure signatures:**
  - **High False Positive Rate:** Likely indicates the $L_{max}$ threshold is too low, allowing high-frequency noise (which affects non-members too) to dominate the score.
  - **Random Guess Performance:** Likely indicates the diffusion model was not trained sufficiently or the threshold is too tight, masking all informative regions.

- **First 3 experiments:**
  1. **Baseline Reproduction:** Implement the SecMI attack (L2 only) on FeTS 2022 to establish the "difficulty" baseline where simple images cause false positives.
  2. **Frequency Masking Ablation:** Run FCRE with "All Frequencies" (0%-100%) vs. "Mid-Frequency" (15%-85%) to quantify the lift from the calibration mechanism alone.
  3. **Metric Sensitivity:** Compare FCRE (L2) vs. FCRE (L2+SSIM) specifically on high-resolution medical images (ChestX-ray8) to verify the utility of perceptual metrics on detailed anatomical structures.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can an adaptive mechanism automatically determine the optimal mid-frequency thresholds ($L_{min}, L_{max}$) for different datasets without manual tuning?
- **Basis in paper:** [explicit] Section 3.4 states that "optimal thresholds... vary across datasets" and explicitly lists "adaptive thresholding methods" as future work to enhance generalizability.
- **Why unresolved:** The current implementation relies on manually selected thresholds based on limited ablation studies, which may not generalize to new medical imaging modalities with different frequency distributions.
- **What evidence would resolve it:** A proposed algorithm that dynamically sets frequency bounds based on image spectral characteristics and demonstrates stable attack performance across diverse datasets without manual intervention.

### Open Question 2
- **Question:** How can diffusion models be defended against frequency-calibrated attacks while maintaining generation quality?
- **Basis in paper:** [inferred] The Conclusion states the work motivates "exploration into robust, privacy-preserving generative models" and "defense mechanisms," though the paper only proposes an attack.
- **Why unresolved:** While the paper establishes the vulnerability of the mid-frequency domain, it does not investigate whether filtering or perturbing this domain during training can mitigate the attack without degrading the medical image utility.
- **What evidence would resolve it:** A defensive training strategy (e.g., mid-frequency regularization) that successfully lowers the FCRE Attack Success Rate (ASR) while preserving the Fr√©chet Inception Distance (FID) or clinical utility of generated images.

### Open Question 3
- **Question:** Is FCRE effective against native 3D medical volume generation models, as opposed to 2D slice extraction methods?
- **Basis in paper:** [inferred] The Implementation Details (Section 3.2) note that 3D MRI volumes were processed by extracting 2D slices. The method's reliance on 2D Laplacian scores may not translate directly to volumetric data.
- **Why unresolved:** Medical imaging often relies on 3D context; analyzing 2D slices independently ignores the volumetric frequency characteristics and spatial correlations present in the full MRI or CT scans.
- **What evidence would resolve it:** Experiments applying FCRE to a 3D diffusion model trained on full volumes, utilizing 3D frequency analysis, achieving comparable AUC to the 2D results.

## Limitations
- The frequency masking approach assumes medical images exhibit clear frequency polarization, which may not hold for all imaging modalities
- Optimal frequency thresholds appear dataset-dependent and were not systematically explored across all datasets
- The attack's performance heavily depends on the diffusion model's training quality and regularization

## Confidence
- **High confidence**: The fundamental mechanism of frequency-based difficulty calibration and its impact on reducing false positives
- **Medium confidence**: The universality of the 15%-85% frequency threshold across medical imaging domains
- **Medium confidence**: The superiority of SSIM over L2 alone in all medical imaging contexts

## Next Checks
1. **Cross-modal validation**: Test FCRE on additional medical imaging modalities (CT, ultrasound) to verify frequency calibration effectiveness beyond MRI and X-ray
2. **Threshold sensitivity analysis**: Systematically explore frequency threshold ranges (Lmin, Lmax) across different medical datasets to establish robust calibration guidelines
3. **Adversarial defense evaluation**: Assess FCRE's performance against potential defenses like differential privacy or frequency-domain regularization to understand practical attack resilience