---
ver: rpa2
title: 'Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity,
  Regimes and Spatio-Temporal Patterns'
arxiv_id: '2511.21537'
source_url: https://arxiv.org/abs/2511.21537
tags:
- example
- also
- case
- data
- regimes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of discovering causal graphs that
  change across different contexts (e.g., time or space) in non-stationary data. The
  key problem is extracting information about how the causal graph itself varies,
  without prior knowledge of context assignments.
---

# Context-Specific Causal Graph Discovery with Unobserved Contexts: Non-Stationarity, Regimes and Spatio-Temporal Patterns

## Quick Facts
- arXiv ID: 2511.21537
- Source URL: https://arxiv.org/abs/2511.21537
- Authors: Martin Rabel; Jakob Runge
- Reference count: 40
- One-line primary result: A modular framework for discovering causal graphs that change across unobserved contexts by modifying independence tests to detect marked independence directly.

## Executive Summary
This paper addresses the challenge of discovering causal graphs that vary across different contexts (e.g., time or space) in non-stationary data when context assignments are unobserved. The authors identify two core challenges: global vs. local regime detection and the difficulty of directly testing for regime-dependent independence. Their solution is a modular framework that modifies constraint-based causal discovery algorithms to test for marked independence (dependence, independence, or regime structure) directly, avoiding global clustering or change-point detection. This framework is highly modular, allowing integration of existing methods, and can handle time series, spatial, and other structured data.

## Method Summary
The gLD framework (graph-Local and Direct) modifies Conditional Independence Tests (CITs) to return marked independence states (0: independent, 1: dependent, R: regime-structure). The core mechanism involves dividing data into blocks and testing for homogeneity of dependence scores within blocks. If blocks are non-homogeneous, an acceptance interval method checks for weak regimes. The framework then iteratively runs standard CD algorithms (like PCMCI) using pseudo-CITs that fix regime-dependent values, discovering the multi-valued independence structure. This direct testing approach avoids the convergence degradation seen in indirect methods that must first recover regime assignments before running causal discovery.

## Key Results
- Demonstrates systematic and substantial degradation of indirect methods (clustering-then-CD) as sample size increases
- Outperforms sliding-window and clustering baselines in numerical experiments with synthetic data
- Shows good scalability and robustness to increasing sample sizes and model complexity
- An open-source implementation will be available soon

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Direct testing avoids the convergence degradation seen in indirect methods as sample size increases
- Mechanism: Indirect methods must recover regime assignments before running Causal Discovery. As sample size grows, CD becomes sensitive enough to detect imperfections in preliminary assignments, creating a "race condition" where increased data hurts performance. The gLD framework bypasses this by modifying the CIT to output a third state directly
- Core assumption: The independence test can detect heterogeneity without resolving specific regime assignments
- Evidence anchors: [abstract] "avoiding global clustering or change-point detection"; [section 1] "leads in numerical experiments to systematic degradation... racing our CD vs. our method of regime-assignment"

### Mechanism 2
- Claim: Graph-locality (gL) enables scaling to complex regime structures by assuming causal modularity
- Mechanism: Global regime modeling scales exponentially with the number of changing links. By assuming mechanisms change independently, the framework decomposes the problem into local, per-link decisions
- Core assumption: Causal modularity holds, meaning different links change independently
- Evidence anchors: [abstract] "modular framework... highly modular"; [section 1] "global methods scale exponentially... local signal is obfuscated by the global noise"

### Mechanism 3
- Claim: Persistence is required to make unobserved context identifiability possible
- Mechanism: In pure IID data, mixtures are generally unidentifiable. The framework resolves this by assuming regimes persist over time or space and aggregates data into blocks
- Core assumption: Regimes persist long enough relative to the chosen block size to yield valid statistical samples
- Evidence anchors: [section 5.1] "mixtures generally cannot be easily decomposed... Persistence can help resolving this ambiguity"; [section 5.2] "reduce the problem from a global question to a question about few variables"

## Foundational Learning

### Concept: Constraint-Based Causal Discovery (e.g., PC, FCI)
- Why needed here: The framework is designed as a "drop-in" modification for these algorithms
- Quick check question: How does the PC algorithm use d-separation to remove edges?

### Concept: Mixture Models & Identifiability
- Why needed here: The core theoretical challenge is that a single distribution can represent many different regime combinations
- Quick check question: Why can't we uniquely decompose a Gaussian mixture without additional constraints?

### Concept: Non-Stationarity vs. Modularity
- Why needed here: The paper specifically targets non-stationarity arising from modular mechanism changes
- Quick check question: What is the difference between a parameter drift and a regime switch?

## Architecture Onboarding

### Component map:
Data Processing Layer (mCIT) -> Structure Discovery Layer (wrapped CD algos) -> Composition Layer (Core Algorithm)

### Critical path:
The mCIT implementation is the engine. It requires setting block sizes (B) and cut-offs (c) to test for homogeneity and weak regimes

### Design tradeoffs:
Hyperparameters (B, c) require balancing. Small blocks reduce validity (high noise) but large blocks increase risk of spanning multiple regimes (invalid blocks)

### Failure signatures:
- Regime Degradation: If F1 scores drop as N increases, implementation likely defaulted to an indirect method
- Union Graph Collapse: If output union graph is poor, check the "PC1-phase" logic in time series implementations

### First 3 experiments:
1. Baseline Scaling: Run on synthetic data with increasing N. Verify performance (F1) increases while Regime-PCMCI decreases
2. Node Scaling: Increase node count while keeping link density constant. Verify method scales linearly or quadratically
3. Weak Regime Test: Inject regime where d₀ ≠ 0 but d₀ ≪ d₁. Check if acceptance interval method correctly identifies weak regime

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the gLD-framework effectively synergize with kernel-based methods like CD-NOD to simultaneously detect qualitative regime changes and extract additional edge-orientation information?
- Basis in paper: [explicit] The Introduction and Related Literature sections ask about potential synergy between CD-NOD and gLD
- Why unresolved: gLD focuses on binary context-variables and constraint-based discovery, while CD-NOD extracts orientation via kernel-tests suited for quantitative drifts
- What evidence would resolve it: Empirical results demonstrating improved orientation accuracy on datasets containing both qualitative regime switches and quantitative non-stationarities

### Open Question 2
- Question: How can rigorous uncertainty quantification be implemented for the temporal location of detected regimes during post-processing?
- Basis in paper: [explicit] Authors state in Assumptions and Goals section that giving good uncertainty statements on time-resolutions is relevant but left to future work
- Why unresolved: Current framework treats temporal assignment as a separate post-processing step, and analyzing statistical error propagation was excluded
- What evidence would resolve it: A formal statistical estimator or confidence bound for error in time-resolved indicator mask σ(t)

### Open Question 3
- Question: Can the validity of the "few invalid blocks" assumption be assessed directly from the data distribution of dependence scores?
- Basis in paper: [inferred] Appendix D.7.1 and D.7.2 discuss adaptive hyperparameters and assessing validity
- Why unresolved: Weak-regime test requires validity assumptions to control false positives, but assessing these assumptions currently relies on prior knowledge
- What evidence would resolve it: A derived statistical test or diagnostic metric based on the shape of empirical dependence-score distribution

### Open Question 4
- Question: How can the state-space construction logic be extended to handle cyclic models?
- Basis in paper: [explicit] Appendix F.10.2 states cyclic models require novel "union tests" besides implication tests
- Why unresolved: Current algorithm relies on acyclicity to simplify translation of detected indicators; cycles create "almost cycles" requiring testing disjunctive null hypotheses
- What evidence would resolve it: A formulation of a statistical test for the disjunctive null hypothesis and its integration into state-space construction phase

## Limitations
- Empirical validation limited to linear causal models with Gaussian or similar noise distributions
- Scalability bounds under high-dimensional data or highly dynamic regimes not empirically established
- Robustness to pattern misspecification (wrong block size or spatial aggregation) may degrade performance significantly

## Confidence

### High Confidence:
- Theoretical foundation for homogeneity and weak regime tests is sound
- Modular design and direct testing approach are well-justified

### Medium Confidence:
- Empirical performance claims supported by synthetic experiments
- Limited noise distribution coverage and lack of real-world data validation reduce confidence

### Low Confidence:
- Method's behavior under severe model misspecification (e.g., incorrect pattern assumption)
- Performance in presence of hidden confounders not addressed

## Next Checks

1. **Non-linear SCMs**: Validate framework on synthetic data with non-linear causal mechanisms (polynomial or threshold-based) to test robustness beyond linear assumptions

2. **Real-world Regime Structure**: Apply method to a real-world dataset with known regime changes (climate or financial data) to assess practical utility and sensitivity to pattern misspecification

3. **Hidden Confounding Stress Test**: Introduce hidden confounders into synthetic data and evaluate whether framework can still recover correct regime-dependent causal structure or fails gracefully