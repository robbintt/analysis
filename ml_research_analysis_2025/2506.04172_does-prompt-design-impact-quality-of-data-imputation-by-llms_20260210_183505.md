---
ver: rpa2
title: Does Prompt Design Impact Quality of Data Imputation by LLMs?
arxiv_id: '2506.04172'
source_url: https://arxiv.org/abs/2506.04172
tags:
- data
- prompt
- dataset
- imputation
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study explores how prompt design affects the quality of data
  imputation using large language models for class-imbalanced tabular datasets. A
  token-aware, group-wise CSV-style prompting approach is proposed, focusing on relevant,
  strongly correlated features to minimize input token usage while improving imputation
  accuracy.
---

# Does Prompt Design Impact Quality of Data Imputation by LLMs?
## Quick Facts
- arXiv ID: 2506.04172
- Source URL: https://arxiv.org/abs/2506.04172
- Authors: Shreenidhi Srinivasan; Lydia Manikonda
- Reference count: 8
- Primary result: Group-wise CSV-style prompting with correlation-based feature selection reduces prompt size by up to 76.19% while maintaining or improving imputation quality for class-imbalanced datasets.

## Executive Summary
This study investigates how prompt design affects LLM-based data imputation for class-imbalanced tabular datasets. The authors propose a token-aware, group-wise CSV-style prompting approach that focuses on relevant, strongly correlated features to minimize input token usage while improving imputation accuracy. Experiments on Adult Income and Travel datasets demonstrate that this method reduces prompt size significantly while maintaining or enhancing imputation quality, with notable improvements in minority class F1 scores for smaller datasets.

## Method Summary
The method uses group-wise CSV-style prompting with correlation-based feature selection for LLM data imputation. Correlation coefficients (Pearson for numeric-numeric, Cramer's V for categorical-categorical, eta for categorical-numeric) are calculated between imputation features and all other columns. An elbow-point analysis on sorted correlation values determines the feature retention threshold. Features exceeding this threshold are included in prompts structured by target class groups. Imputation proceeds iteratively, updating the prompt with each new imputation to provide additional context for subsequent imputations. GPT-4.1 performs the imputations, and classification models (XGBoost, Random Forest) evaluate the quality of imputed records.

## Key Results
- Group-wise prompting achieves F1=0.76 for minority class vs F1=0.60 for ungrouped on Adult Income dataset
- Token reduction of 76.19% for Adult Income and 66.67% for Travel datasets while maintaining/improving classification performance
- For smaller datasets, removing irrelevant features improves minority class F1 scores and overall model performance
- Effect is less pronounced in larger datasets where class balance is better represented

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Group-wise CSV-style prompting improves minority class imputation quality compared to ungrouped examples.
- Mechanism: By separating examples by target class (e.g., "Churn" vs "Doesn't churn"), the LLM can learn class-specific patterns more effectively through in-context learning, rather than mixing samples indiscriminately.
- Core assumption: LLMs can recognize and replicate class-conditional distributions when examples are explicitly grouped.
- Evidence anchors:
  - [abstract] "structured group-wise CSV-style prompting technique"
  - [section: Experiments and Insights, Table 2] Grouped prompt achieves F1=0.76 for minority class vs F1=0.60 for ungrouped on Adult Income dataset
  - [corpus] Weak direct support; neighboring papers focus on synthetic data generation rather than group-wise prompting specifically
- Break condition: If classes are not cleanly separable or overlap significantly in feature space, grouping may not provide signal advantage.

### Mechanism 2
- Claim: Removing weakly correlated features from prompts reduces token usage while maintaining or improving imputation quality.
- Mechanism: Irrelevant features introduce noise that degrades LLM pattern recognition. By filtering to strongly correlated predictors (determined via elbow-point analysis on correlation values), the LLM focuses on informative signals.
- Core assumption: Correlation-based feature selection identifies the minimal sufficient feature set for imputation.
- Evidence anchors:
  - [abstract] "focusing on relevant, strongly correlated features to minimize input token usage while improving imputation accuracy"
  - [section: Exploring the effect of token reduction] Tables 3-6 show F1 scores maintained or improved with 66-76% feature reduction
  - [corpus] Partial support from Shi et al. (2023, cited in paper): "Large language models can be easily distracted by irrelevant context"
- Break condition: If missing feature has distributed relationships across many weakly-correlated variables, thresholding may discard useful information.

### Mechanism 3
- Claim: Iterative imputation with progressive context addition improves subsequent imputations.
- Mechanism: Impute features one at a time, updating the prompt after each imputation so that previously-imputed columns provide additional context for remaining missing values.
- Core assumption: Earlier imputations are accurate enough to serve as reliable context for later imputations.
- Evidence anchors:
  - [section: Data Imputation Technique] "We continue to update the prompt after imputing each feature to add more context for the LLM to perform the next imputation"
  - [corpus] No direct corpus support for this specific iterative mechanism
- Break condition: If early imputations contain errors, error propagation through subsequent imputations may compound inaccuracies.

## Foundational Learning

- Concept: **In-context learning**
  - Why needed here: The entire method relies on LLMs learning patterns from examples in the prompt without fine-tuning. Understanding this capability helps explain why structured examples enable imputation.
  - Quick check question: Can you explain why providing completed examples in the prompt enables an LLM to fill in missing values without weight updates?

- Concept: **Correlation measures for mixed data types**
  - Why needed here: The method uses Pearson (numeric-numeric), Cramer's V (categorical-categorical), and eta/η (categorical-numeric) to determine feature relevance. Selecting the appropriate measure is critical for threshold determination.
  - Quick check question: Given a categorical imputation feature and a numeric predictor, which correlation measure would you apply?

- Concept: **Elbow-point detection**
  - Why needed here: The correlation threshold is determined by identifying where correlation values drop sharply, then flatten. This heuristic determines which features to retain.
  - Quick check question: On a sorted correlation plot, what characterizes the "elbow point" vs. points before or after it?

## Architecture Onboarding

- Component map:
  - Correlation analyzer -> Threshold selector -> Feature selector -> Prompt constructor -> Imputation executor -> Context updater -> Evaluator

- Critical path:
  1. Compute correlations → determine threshold → select features
  2. Construct grouped prompt with selected features
  3. Call LLM for imputation
  4. Update dataset with imputed values
  5. Repeat for remaining missing features
  6. Evaluate via downstream classifier performance

- Design tradeoffs:
  - Higher correlation threshold: More token reduction, risk of losing useful signal
  - Lower threshold: More context, but includes noise and increases cost
  - Imputation order: Paper suggests starting with features relevant to most other imputation features, but optimal ordering is not rigorously evaluated
  - Group size in prompt: More examples improve distribution representation but consume tokens

- Failure signatures:
  - Minority class F1 drops significantly after imputation → prompt may lack sufficient minority examples or irrelevant features overwhelming signal
  - Balanced accuracy degrades with feature reduction → threshold too aggressive for this dataset
  - Inconsistent imputations across runs → LLM temperature too high; use lower temperature for deterministic outputs

- First 3 experiments:
  1. Baseline comparison: Run grouped vs. ungrouped prompting on your dataset with all features included to isolate the grouping effect (replicate Table 2 pattern).
  2. Correlation sweep: Test 3-4 threshold values (e.g., 0, 0.1, 0.15, 0.2) and measure token reduction vs. F1/balanced accuracy tradeoff curve.
  3. Feature ablation: For your highest-correlation imputation feature, identify which predictor contributes most to quality by adding/removing individual correlated features.

## Open Questions the Paper Calls Out
- In what specific scenarios does prompting amplify or suppress biases present in the original data via the LLM's training? The authors explicitly list this as a "next set of questions" in the Discussion section, highlighting potential ethical issues in sensitive domains.
- Can the synthetic data generation process be guaranteed to be reproducible for small datasets where the prompt has a larger influence? The authors ask, "if the prompt has a larger influence on datasets of smaller sizes, can we guarantee that the synthetic data generation process could be reproducible?"
- Does the token-aware prompting method maintain its effectiveness when imputing numerical features compared to categorical ones? The Limitations section notes the experiments were restricted to datasets with categorical imputation features, stating results may not generalize to all feature types.

## Limitations
- Results depend heavily on specific datasets used and may not generalize to other tabular domains
- Correlation-based feature selection assumes linear or monotonic relationships, potentially missing complex interactions
- Evaluation focuses on downstream classification performance rather than direct imputation accuracy metrics
- Iterative imputation mechanism lacks theoretical grounding and could suffer from error propagation
- Elbow-point threshold determination is described as "manual or automated" without specifying which was used

## Confidence
- High confidence: The token reduction claims (76.19% for Adult Income, 66.67% for Travel) are well-supported by the experimental results showing direct correlation between feature selection and prompt size reduction.
- Medium confidence: The classification performance improvements for smaller datasets are supported by the results, but the mechanism explaining why this works is partially assumed rather than proven through ablation studies.
- Low confidence: The iterative imputation mechanism's benefits are claimed but not rigorously evaluated through controlled experiments comparing sequential vs. parallel imputation approaches.

## Next Checks
1. Ablation study on feature selection threshold: Systematically test correlation thresholds at 0.05 intervals between 0 and 0.3 to map the full tradeoff curve between token reduction and classification performance, verifying the elbow point identification method.
2. Error propagation analysis: Compare imputation quality when using perfect vs. imperfect earlier imputations as context to quantify how much the iterative approach relies on accurate initial imputations.
3. Minority class balance experiment: Vary the number of minority vs. majority class examples in prompts (e.g., 1:1, 1:2, 1:3 ratios) while keeping total token count constant to determine optimal representation for minority class imputation quality.