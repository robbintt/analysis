---
ver: rpa2
title: Improved Compact Genetic Algorithms with Efficient Caching
arxiv_id: '2504.02972'
source_url: https://arxiv.org/abs/2504.02972
tags:
- cache
- fitness
- function
- number
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces caching into compact genetic algorithms (cGA)
  to avoid redundant fitness evaluations. By maintaining a cache of evaluated chromosomes,
  the proposed approach reduces the number of function evaluations while preserving
  the original algorithm's convergence and accuracy.
---

# Improved Compact Genetic Algorithms with Efficient Caching

## Quick Facts
- arXiv ID: 2504.02972
- Source URL: https://arxiv.org/abs/2504.02972
- Reference count: 29
- Primary result: Caching reduces fitness evaluations in compact genetic algorithms by up to 2× with minimal accuracy impact.

## Executive Summary
This paper introduces caching into compact genetic algorithms (cGA) to avoid redundant fitness evaluations. By maintaining a cache of evaluated chromosomes, the proposed approach reduces the number of function evaluations while preserving the original algorithm's convergence and accuracy. An efficient hash-table-based data structure is presented to support constant-time cache operations. Experiments on two benchmark problems demonstrate significant reductions in fitness evaluations across multiple cGA variants (including elitism-based versions), with speedup improvements ranging from 1.12× to over 2× depending on cache size and problem type.

## Method Summary
The authors implement a cache layer between chromosome generation and fitness evaluation in cGA variants. The cache uses a hash table with chaining to store chromosome→fitness mappings, enabling O(1) average lookup. Two replacement policies are implemented: FIFO (singly-linked list) and LRU (doubly-linked list with O(1) hit reordering). The cache is integrated into cGA, pe-cGA, and ne-cGA algorithms, checking for cached fitness values before expensive evaluations. The approach maintains original convergence behavior since the PV update logic remains unchanged. Experiments use 100-bit Onemax and 30-bit Binary Integer problems with population sizes 10-100 and cache capacities 0-20, averaged over 50 runs.

## Key Results
- Caching reduces fitness evaluations by 1.12× to over 2× across cGA variants
- Even minimal cache capacity (1) yields notable speedup improvements
- LRU slightly outperforms FIFO but both achieve comparable gains
- Diminishing returns observed for cache capacities beyond small values
- Convergence behavior and accuracy preserved identically to non-cached versions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Caching eliminates redundant fitness evaluations when cGAs regenerate identical chromosomes during convergence.
- Mechanism: A hash table maps chromosome bitstrings to cached fitness values. Before evaluating fitness, the algorithm checks the cache; on hit, it returns the stored value in O(1) average time. On miss, it evaluates fitness and stores the result.
- Core assumption: Chromosomes generated from a probability vector exhibit temporal locality—especially as PV values converge toward 0 or 1, the same chromosomes are sampled repeatedly.
- Evidence anchors:
  - [abstract] "cGAs have a tendency to repeatedly generate the same chromosomes as they approach convergence, resulting in unnecessary evaluations of identical chromosomes."
  - [Section III-A] "When the fitness function of a chromosome x has to be evaluated, the cache is checked first."
  - [corpus] Weak direct support; related work (e.g., caching for LLMs, content caching) addresses caching in different domains but not cGA-specific mechanisms.
- Break condition: If chromosomes are highly diverse across iterations (e.g., very large search spaces with low convergence repetition), hit ratios drop and caching overhead may exceed benefits.

### Mechanism 2
- Claim: FIFO and LRU replacement policies maintain cache effectiveness by retaining recently generated chromosomes, which are most likely to recur.
- Mechanism: FIFO evicts the oldest entry; LRU evicts the least recently accessed. A doubly-linked list enables O(1) reordering on cache hits for LRU. The hash table points into the list for fast lookup.
- Core assumption: The probability vector changes slowly, so recently generated chromosomes have higher revisit probability.
- Evidence anchors:
  - [Section III-B] "In FIFO, the oldest chromosome is deleted... In LRU, the chromosome that is least recently accessed is deleted."
  - [Section V-A] "The performance of the two cache replacement strategies—FIFO and LRU—are comparably similar. LRU performs slightly better."
  - [corpus] No direct corpus evidence for cGA-specific replacement policies; general caching literature supports FIFO/LRU utility.
- Break condition: If the probability vector shifts rapidly (e.g., small population sizes with aggressive updates), temporal locality weakens and cache churn increases.

### Mechanism 3
- Claim: Caching preserves cGA convergence behavior and accuracy because the underlying selection and update logic is unchanged—only evaluation cost is reduced.
- Mechanism: The cache is a transparent layer over fitness evaluation. The PV update rule, tournament selection, and convergence criteria remain identical. Speedup = (h + m) / m = 1 + h/m, where h = hits, m = misses.
- Core assumption: Fitness evaluation is deterministic and expensive relative to cache lookup overhead.
- Evidence anchors:
  - [Section III-C-2] "The accuracy and the rate of convergence of cGA with and without caching are the same since the actual algorithm of cGA is not modified here."
  - [Section IV, Lemma 2] "Speedup = 1 / (1 − Hitratio)" formally links hit ratio to speedup.
  - [corpus] No corpus papers address accuracy preservation in cGA caching specifically.
- Break condition: If fitness evaluation is stochastic (different outputs for same input), caching would introduce divergence from uncached behavior.

## Foundational Learning

- Concept: **Compact Genetic Algorithm (cGA) fundamentals**
  - Why needed here: cGA represents a population as a probability vector (PV) of gene-wise allele probabilities, updated via pairwise (or tournament) comparisons. Understanding PV dynamics explains why chromosome repetition occurs.
  - Quick check question: Given a 5-bit chromosome with PV = [0.5, 0.5, 0.5, 0.5, 0.5], what is the probability of generating chromosome [1, 0, 1, 0, 1]? (Answer: 0.5⁵ = 0.03125)

- Concept: **Hash table with chaining for collision resolution**
  - Why needed here: The cache requires O(1) average lookup. Hashing chromosome bitstrings to table slots with chaining handles collisions without degrading correctness.
  - Quick check question: If two distinct chromosomes hash to the same slot, how does chaining ensure both can be stored and retrieved correctly?

- Concept: **Cache replacement policies (FIFO vs LRU)**
  - Why needed here: Choosing between FIFO and LRU affects hit ratio under different locality patterns. FIFO is simpler (singly-linked list); LRU requires doubly-linked list for O(1) hit reordering.
  - Quick check question: For access sequence A, B, C, A, D with cache capacity 2, which policy (FIFO or LRU) yields more hits?

## Architecture Onboarding

- Component map:
  - **Probability Vector (PV)** -> **Chromosome Generator** -> **Cache Layer** -> **Fitness Evaluator** -> **PV Updater** -> **Convergence Checker**

- Critical path:
  1. Generate chromosome from PV.
  2. Compute hash of chromosome bitstring.
  3. Probe cache: if hit, return cached fitness; if miss, evaluate fitness and insert into cache (evicting if at capacity).
  4. Run tournament/selection with cached or newly evaluated fitness.
  5. Update PV based on comparison outcome.
  6. Repeat until convergence.

- Design tradeoffs:
  - **Cache size vs. overhead**: Larger caches increase hit ratio but consume more memory; paper shows diminishing returns beyond small sizes (e.g., 20 for tested problems).
  - **FIFO vs LRU**: LRU slightly outperforms FIFO but requires doubly-linked list; FIFO is simpler and sufficient for modest gains.
  - **Hash function choice**: Poor hash functions cause clustering and degrade lookup to O(n); universal hashing mitigates this.

- Failure signatures:
  - **Stochastic fitness functions**: Caching deterministic values for stochastic evaluations breaks behavioral equivalence.
  - **Excessive cache churn**: Very small cache sizes or highly dynamic PVs yield low hit ratios; speedup approaches 1×.
  - **Hash collisions without proper chaining**: Leads to incorrect cache misses or overwrites.

- First 3 experiments:
  1. **Baseline validation**: Replicate paper's onemax and binary integer experiments with population size 100, cache capacity 1 and 20. Measure speedup and hit ratio against non-cached cGA.
  2. **Hash function sensitivity**: Test multiple hash functions (e.g., simple modulo, polynomial rolling, universal hash) on 30-bit binary integer problem. Compare collision rates and lookup times.
  3. **Expensive fitness simulation**: Replace benchmark fitness with a computationally expensive dummy function (e.g., iterative numerical integration). Confirm that wall-clock speedup matches theoretical speedup from hit ratio.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the caching mechanism perform on problems with computationally expensive fitness functions, such as real-world engineering optimization or simulation-based problems?
- Basis in paper: [explicit] The authors state "This will be particularly useful for the problems for which fitness computation is a time/space consuming procedure" but only test on computationally cheap benchmark problems (onemax and binary integer).
- Why unresolved: The experiments use simple mathematical fitness functions where evaluation cost is negligible; the overhead-benefit tradeoff for expensive functions remains unexplored.
- What evidence would resolve it: Experiments on real-world problems (e.g., neural network hyperparameter tuning, CFD simulations, protein folding) comparing wall-clock time with and without caching.

### Open Question 2
- Question: Can the caching approach be effectively extended to Real-valued Compact Genetic Algorithms (rcGA) and Extended Compact Genetic Algorithms (ecGA)?
- Basis in paper: [inferred] The paper reviews rcGA [8] and ecGA [10-14] as important cGA variants but only implements caching for binary cGA, pe-cGA, and ne-cGA. The hash-table design assumes discrete chromosome keys.
- Why unresolved: Real-valued chromosomes cannot be directly hashed; a different cache structure (e.g., nearest-neighbor lookup or discretization) would be required.
- What evidence would resolve it: Implementation and benchmarking of cache-based rcGA/ecGA with appropriate continuous-valued cache lookup mechanisms.

### Open Question 3
- Question: How can the optimal cache capacity be determined automatically for a given problem and population size?
- Basis in paper: [inferred] Results show "diminishing returns" as cache capacity increases beyond a certain point (Figure 12-14), but no guidance is provided for selecting cache size a priori.
- Why unresolved: The relationship between problem dimensionality, population size, convergence behavior, and optimal cache size is not characterized.
- What evidence would resolve it: Theoretical analysis or empirical study identifying predictive features (e.g., chromosome length, selection pressure) that correlate with optimal cache capacity.

## Limitations
- The core claim that caching preserves convergence behavior is supported by theoretical analysis but not empirically validated against stochastic fitness functions, where caching could introduce behavioral divergence.
- While the paper demonstrates speedup gains, the experimental scope is limited to two synthetic benchmark problems (Onemax and binary integer) without testing on real-world problems or higher-dimensional spaces.
- Hash function choice and collision handling specifics are not provided, leaving implementation-dependent performance variations unaccounted for.

## Confidence
- **High confidence**: The mechanism that caching eliminates redundant evaluations when chromosomes repeat during convergence is well-supported by both theory (Lemma 2) and experiments across multiple cGA variants.
- **Medium confidence**: The claim that FIFO and LRU replacement policies maintain effectiveness is moderately supported—LRU shows slight advantage but experimental comparison is limited.
- **Low confidence**: The assumption that caching will be particularly effective for "computationally expensive" fitness functions is asserted but not experimentally validated with different cost regimes.

## Next Checks
1. Test the cached cGA on stochastic fitness functions to verify that behavioral equivalence is preserved when fitness evaluations are non-deterministic.
2. Implement the approach on a real-world optimization problem (e.g., neural architecture search or combinatorial design) to assess practical utility beyond synthetic benchmarks.
3. Conduct a sensitivity analysis varying hash table size and hash function quality to quantify their impact on cache hit ratios and overall speedup.