---
ver: rpa2
title: Supervised Learning for the (s,S) Inventory Model with General Interarrival
  Demands and General Lead Times
arxiv_id: '2601.12900'
source_url: https://arxiv.org/abs/2601.12900
tags:
- inventory
- time
- training
- moments
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a supervised machine learning framework to
  approximate steady-state performance measures for (s,S) inventory systems with general
  interarrival and lead time distributions. Traditional analytical methods fail under
  non-Markovian assumptions, leaving costly simulation as the only option.
---

# Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times

## Quick Facts
- **arXiv ID**: 2601.12900
- **Source URL**: https://arxiv.org/abs/2601.12900
- **Reference count**: 26
- **Primary result**: ML framework predicts steady-state inventory metrics using moments as features, achieving millisecond inference versus hours for simulation

## Executive Summary
This paper presents a supervised machine learning framework to approximate steady-state performance measures for continuous-review (s,S) inventory systems with general interarrival and lead time distributions. Traditional analytical methods fail under non-Markovian assumptions, leaving simulation as the only option despite its computational expense. The authors train three separate neural networks using moments of input distributions as features and simulation outputs as labels. Experiments show that five moments suffice for accurate predictions across 32 test scenarios, with inference time reduced from hours to milliseconds. The framework offers a scalable, fast alternative to simulation-based steady-state analysis and generalizes to other inventory models.

## Method Summary
The framework trains three separate feed-forward neural networks to predict steady-state inventory metrics: the probability distribution of inventory levels (NN1), expected cycle time (NN2), and lost sales probability (NN3). Inputs consist of (s,S) values plus log-transformed first five moments of interarrival and lead time distributions. Training data comes from 2.5 million Phase-Type distribution samples, each labeled via 180 million demand arrival simulations. NN1 outputs a Softmax probability vector with support constraint projection, NN2 outputs a linear cycle time estimate, and NN3 outputs a Sigmoid-activated probability. The networks use 5 hidden layers with ReLU activations, trained separately with L1/MSE loss functions using Adam optimizer.

## Key Results
- Five moments provide optimal accuracy for NN1, with SAE < 0.03 and REM < 1.5% across test scenarios
- NN2 achieves RE < 5% and AE < 0.02 for cycle time and lost sales probability predictions
- Inference time reduced from hours to milliseconds (0.04 seconds for 1000 instances vs 440 hours for simulation)
- Operational example demonstrates optimal threshold selection in under 0.004 seconds versus 0.42 hours with simulation

## Why This Works (Mechanism)

### Mechanism 1: Moment-Based Distribution Encoding
Encoding continuous distributions via their first five moments provides sufficient information for neural networks to approximate steady-state inventory behavior. Low-order moments capture structural variability while providing fixed-size tensor input. Log transformation stabilizes exponentially growing moment values. The steady-state behavior depends primarily on distributional shape features captured by the first five moments.

### Mechanism 2: Phase-Type Distribution Sampling for Training Coverage
Sampling training distributions from the Phase-Type family ensures the neural network generalizes across the space of possible input distributions. PH distributions can approximate any non-negative continuous distribution. By sampling PH parameters with controlled SCV/skewness/kurtosis diversity, the training set spans a wide range of distributional shapes.

### Mechanism 3: Support-Constraint Projection for Probabilistic Consistency
Post-hoc normalization of predicted probability vectors to the feasible domain [0, S] ensures valid probability mass functions while the loss function penalizes out-of-support predictions during training. The network learns to concentrate probability mass within the correct support based on the (s,S) input parameters.

## Foundational Learning

- **(s, S) Inventory Policy**
  - Why needed here: Understanding this reorder mechanism is essential for interpreting the output metrics
  - Quick check question: If s=5 and S=20, and current inventory is 6, should an order be placed? (Answer: No—order only when inventory ≤ s.)

- **Steady-State vs. Transient Analysis**
  - Why needed here: The neural networks approximate stationary (long-run) performance measures, not time-dependent behavior
  - Quick check question: Why does the paper use 180 million arrivals rather than, say, 10,000? (Answer: To ensure convergence to steady-state and reduce simulation variance.)

- **Phase-Type Distributions**
  - Why needed here: Understanding that PH distributions are a generalization of exponential distributions and can approximate any non-negative distribution
  - Quick check question: Can a PH distribution approximate a deterministic distribution with fixed value 1.0? (Answer: Yes, approximately—though exact representation requires infinite phases.)

## Architecture Onboarding

- **Component map**: (s,S) + log(moments) -> NN1 (distribution) -> support projection; (s,S) + log(moments) -> NN2 (cycle time); (s,S) + log(moments) -> NN3 (lost sales probability)

- **Critical path**: Generate PH distributions with diverse moment profiles -> Run discrete-event simulation (180M arrivals) to produce ground truth labels -> Train three NNs independently -> At inference: feed (s,S,moments) -> apply log transform -> run NNs -> apply support projection to NN1 output

- **Design tradeoffs**: L1 vs. MSE for NN1 chosen for gradient sensitivity; 5 moments vs. more because 6th degraded accuracy; separate NNs allow task-specific architectures

- **Failure signatures**: High SAE with low REM indicates distribution shape correct but probability mass shifted; accuracy collapse for S > 15 due to broader distributions; degradation when both SCV_D > 5 and SCV_L > 5

- **First 3 experiments**: 
  1. Moment ablation: Train NN1 with n=2,3,4,5,6 moments; confirm SAE minimum at n=5
  2. Distribution coverage test: Generate 100 test instances with extreme SCV/skewness/kurtosis; measure SAE degradation
  3. Runtime comparison: Benchmark inference on 1000 instances in parallel vs. single-instance simulation

## Open Questions the Paper Calls Out
- Can this framework scale to multi-echelon inventory systems without suffering from the curse of dimensionality?
- Is the degradation in accuracy when using more than five moments caused by estimation noise or the neural network's inability to process higher-order information?
- How robust is the model to out-of-distribution inputs, specifically test distributions that lie outside the Phase-Type family used for training?

## Limitations
- The framework relies on 5 moments to capture distributional information, which may not hold for distributions with significant higher-order structure
- The post-hoc normalization of probability distributions is a heuristic solution with no formal analysis of distortion introduced
- Accuracy degrades for S > 15 due to broader inventory distributions requiring more training data

## Confidence
- **Medium confidence**: Distribution encoding with 5 moments - validated within tested range but potentially limited for extreme distributions
- **Medium confidence**: PH distribution sampling coverage - supported by denseness property but not independently validated for inventory systems
- **Low confidence**: Support constraint effectiveness - no formal analysis of distortion introduced by projection

## Next Checks
1. Generate test cases with SCV, skewness, and kurtosis values outside training ranges to quantify generalization limits
2. Systematically test NN1 performance with 6, 7, and 8 moments to confirm whether 5-moment choice is optimal
3. Create test cases where true distribution has significant mass near support boundaries to evaluate support constraint projection bias