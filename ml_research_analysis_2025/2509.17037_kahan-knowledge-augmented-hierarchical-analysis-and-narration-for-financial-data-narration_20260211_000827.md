---
ver: rpa2
title: 'KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial
  Data Narration'
arxiv_id: '2509.17037'
source_url: https://arxiv.org/abs/2509.17037
tags:
- market
- insights
- knowledge
- data
- insight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KAHAN introduces a knowledge-augmented hierarchical framework for
  financial data narration, extracting insights across entity, pairwise, group, and
  system levels. The approach uses LLMs as domain experts to generate analytical questions,
  compute metrics, and synthesize multi-level insights with domain knowledge.
---

# KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial Data Narration

## Quick Facts
- arXiv ID: 2509.17037
- Source URL: https://arxiv.org/abs/2509.17037
- Authors: Yajing Yang; Tony Deng; Min-Yen Kan
- Reference count: 40
- Primary result: 20% higher narrative quality than baselines (8.26 vs 6.89) while maintaining 98.2% factuality

## Executive Summary
KAHAN introduces a knowledge-augmented hierarchical framework for financial data narration, extracting insights across entity, pairwise, group, and system levels. The approach uses LLMs as domain experts to generate analytical questions, compute metrics, and synthesize multi-level insights with domain knowledge. Evaluated on DataTales benchmark, KAHAN achieves 20% higher narrative quality than baselines while maintaining 98.2% factuality, with human experts ranking it 80% more useful for investment decisions. Cross-domain testing on healthcare data confirms effective transfer to other specialized domains.

## Method Summary
KAHAN operates through a three-stage pipeline using LLMs for inference-only analysis. Stage 1 performs entity-level analysis by generating domain-specific questions, computing metrics via code execution, and extracting insights. Stage 2 synthesizes multi-level insights across pairwise, group, and system relationships. Stage 3 generates the final narrative using knowledge-augmented generation. The framework employs hierarchical data abstraction, code generation for metric computation, and knowledge distillation from larger models to enable smaller models to achieve quality-factuality balance.

## Key Results
- 20% higher narrative quality than baselines (8.26 vs 6.89 aggregate DnA-Eval score)
- Maintains 98.2% factuality using modified FActScore verification
- Human experts rank KAHAN 80% more useful for investment decisions
- Knowledge reusability enables effective cross-domain transfer to healthcare data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Question-guided knowledge generation improves narrative quality over unguided prompting
- Mechanism: LLMs first generate domain-specific analytical questions, which structure subsequent metric computation and insight extraction. This transforms generic data exploration into domain-contextualized analysis.
- Core assumption: LLMs possess sufficient parametric domain expertise to generate meaningful analytical questions
- Evidence anchors: Section 6.1 shows question-guided generation improves performance by +0.21 aggregate points; Section 3.1 explains the transformation from generic to contextual analysis

### Mechanism 2
- Claim: Hierarchical analysis benefits scale with model capability and vary inversely with market complexity
- Mechanism: Entity → Pairwise → Group → System analysis progressively aggregates insights. Larger models leverage full hierarchy for complex relationship identification, while smaller models peak at intermediate levels.
- Core assumption: Multi-level relationships exist in data that single-level analysis cannot capture
- Evidence anchors: Section 6.2 shows simpler markets (energy) derive greater benefits from hierarchical analysis than complex markets (equity); Figure 5 demonstrates Llama3.1 peaking at entity+pairwise level while GPT-4o gains through full hierarchy

### Mechanism 3
- Claim: Knowledge distillation from larger models enables smaller models to achieve quality-factuality balance
- Mechanism: Smaller models using GPT-4o-generated knowledge achieve highest performance across all dimensions simultaneously, overcoming typical quality-factuality trade-offs.
- Core assumption: Domain knowledge is transferable across models and can be cached for reuse
- Evidence anchors: Section 6.1 shows GPT-4o knowledge enables Llama3.1 to achieve highest simultaneous performance; Section 3.3 explains knowledge reusability across all three stages

## Foundational Learning

- Concept: Hierarchical data abstraction (entity → group → system levels)
  - Why needed here: KAHAN's architecture requires understanding how insights aggregate from individual entities through relationships to system-wide patterns
  - Quick check question: Given financial entities (S&P 500, Nasdaq, bond yields), can you identify what constitutes a "group" vs. "system" insight?

- Concept: Code generation and execution for metric computation
  - Why needed here: Stage 1.2-1.3 generates and executes Python code to compute domain-specific metrics (SMAs, RSI, volatility)
  - Quick check question: How would you handle execution failures or ensure generated code operates on correct data types?

- Concept: Knowledge-augmented generation (KAG) patterns
  - Why needed here: KAHAN differs from RAG by generating knowledge bases via LLM prompting rather than retrieval
  - Quick check question: What domain characteristics would make generated knowledge preferable to retrieved knowledge?

## Architecture Onboarding

- Component map: Question Generator → Code Generator → Code Executor → Insight Extractor → Knowledge Generators (pairwise/group/system) → Synthesis Modules → Narrative Knowledge Generator → Text Generator

- Critical path: Question generation (1.1) → Metric computation (1.2-1.3) → Entity insights (1.4) → Pairwise synthesis (2.4) → Group synthesis (2.5) → System synthesis (2.6) → Narrative (3.2)

- Design tradeoffs:
  - Full hierarchy vs. intermediate stopping: Smaller models may benefit from stopping at pairwise level
  - Knowledge source quality vs. compute cost: GPT-4o knowledge generation is more effective but more expensive
  - Description depth vs. readability: Complex markets show insight-readability trade-off

- Failure signatures:
  - Code generation failures (FinanceLLM/TouchStoneGPT failed at Stage 1)
  - Low factuality with high insight quality (Qwen2.5: 94.1% factuality)
  - Degraded readability with full hierarchy for smaller models

- First 3 experiments:
  1. Replicate entity-level analysis on a single financial market with 3 entities, comparing question-guided vs. direct prompting for metric computation
  2. Test knowledge reusability by caching generated knowledge base and running on 5 different dates for same market structure
  3. Ablate hierarchical levels (entity-only → full) on both simple (3-entity energy) and complex (28+ entity equity) markets to identify optimal stopping point for your target model size

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do narratives generated by KAHAN influence actual investment decision outcomes and financial performance compared to human-generated alternatives?
- Basis in paper: [explicit] The authors state evaluation relies on expert assessment rather than measuring downstream impact on decision-making outcomes
- Why unresolved: Study focused on perceived utility through expert ranking rather than tracking real-world investment performance
- What evidence would resolve it: A longitudinal study tracking investment outcomes for portfolios informed by KAHAN narratives versus human analyst reports

### Open Question 2
- Question: Can incorporating real-time market news into KAHAN's knowledge augmentation improve narrative relevance and timeliness for rapidly changing market conditions?
- Basis in paper: [explicit] Authors identify extending knowledge augmentation by incorporating real-time market news as future research direction
- Why unresolved: KAHAN currently uses LLM-derived domain knowledge and static technical indicators but does not integrate external, time-sensitive information sources
- What evidence would resolve it: An augmented KAHAN system with real-time news feeds, evaluated against baseline on events requiring contextual awareness beyond technical patterns

### Open Question 3
- Question: How should hierarchical depth be adaptively adjusted based on market complexity to optimize the insight–readability trade-off?
- Basis in paper: [inferred] Section 6.2 shows complex markets exhibit insight–readability trade-off absent in simpler markets
- Why unresolved: Framework uses fixed hierarchical levels regardless of dataset characteristics
- What evidence would resolve it: An adaptive version of KAHAN that dynamically selects hierarchical depth based on entity count, data variance, or cross-entity correlation

### Open Question 4
- Question: Why do domain-specific financial LLMs fail at KAHAN's code generation and structured analysis stages, and can they be adapted for this framework?
- Basis in paper: [inferred] FinanceLLM and TouchStoneGPT failed at Stage 1 (code generation) and Stage 2 (structured analysis output)
- Why unresolved: Domain-specific models were expected to outperform general LLMs but failed at executable components
- What evidence would resolve it: Error analysis of FinanceLLM/TouchStoneGPT failures, followed by fine-tuning or prompting interventions

## Limitations

- Evaluation relies heavily on GPT-4o as both analysis engine and quality assessor, creating potential circularity in reported improvements
- Cross-domain transferability claims are based on a single healthcare example without systematic testing across diverse domains
- Cost-effectiveness of knowledge reusability claims lacks explicit quantification of computational savings versus knowledge regeneration

## Confidence

- High Confidence: Hierarchical analysis benefits, factuality scores, code generation failures with specialized financial models
- Medium Confidence: Quality improvement metrics, knowledge distillation benefits, human expert utility rankings
- Low Confidence: Cross-domain generalization claims, knowledge reusability cost-benefit analysis, insight-readability trade-off relationship

## Next Checks

1. Implement independent verification of factuality using a separate knowledge base and validation methodology to assess the 98.2% claim
2. Conduct systematic cross-domain testing across 3-5 diverse domains (e.g., retail, healthcare, manufacturing) to validate generalization beyond the single healthcare example
3. Measure and compare computational costs between knowledge generation and knowledge reuse scenarios across multiple report generations to quantify claimed efficiency gains