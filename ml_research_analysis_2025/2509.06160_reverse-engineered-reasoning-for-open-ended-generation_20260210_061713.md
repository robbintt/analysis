---
ver: rpa2
title: Reverse-Engineered Reasoning for Open-Ended Generation
arxiv_id: '2509.06160'
source_url: https://arxiv.org/abs/2509.06160
tags:
- reasoning
- thinking
- deep
- process
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of instilling deep reasoning
  in large language models for open-ended, creative generation tasks where clear reward
  signals are absent. The proposed Reverse-Engineered Reasoning (REER) paradigm synthesizes
  high-quality reasoning trajectories by working backwards from known good solutions
  using gradient-free local search guided by perplexity minimization.
---

# Reverse-Engineered Reasoning for Open-Ended Generation

## Quick Facts
- arXiv ID: 2509.06160
- Source URL: https://arxiv.org/abs/2509.06160
- Reference count: 40
- Key outcome: Reverse-Engineered Reasoning (REER) synthesizes deep reasoning trajectories for open-ended generation by working backwards from known solutions using perplexity-guided local search, enabling state-of-the-art performance without costly RL or distillation.

## Executive Summary
This paper addresses the challenge of instilling deep reasoning in large language models for open-ended, creative generation tasks where clear reward signals are absent. The proposed Reverse-Engineered Reasoning (REER) paradigm synthesizes high-quality reasoning trajectories by working backwards from known good solutions using gradient-free local search guided by perplexity minimization. This approach avoids the sample inefficiency of reinforcement learning and the high cost of instruction distillation. Using REER, the authors created DeepWriting-20K, a dataset of 20,000 deep reasoning trajectories, and fine-tuned Qwen3-8B to produce DeepWriter-8B. DeepWriter-8B significantly outperforms strong open-source baselines and achieves performance competitive with or superior to leading proprietary models like GPT-4o and Claude 3.5 on benchmarks including LongBench, HelloBench, and WritingBench, demonstrating that sophisticated deep reasoning for open-ended generation can be cultivated without costly RL or distillation.

## Method Summary
REER synthesizes reasoning trajectories by working backwards from known good solutions using gradient-free local search guided by perplexity minimization. The process starts with 16K query-solution pairs from public writing platforms, generates initial trajectories via LLM prompts, then iteratively refines segments by selecting candidates that minimize perplexity of the reference solution. Trajectories undergo filtering for repetitive thinking and end-of-thinking tokens, then mix with public reasoning datasets for a 37K total training corpus. The fine-tuned Qwen3-8B model achieves state-of-the-art performance on open-ended generation benchmarks without requiring reinforcement learning or expensive instruction distillation.

## Key Results
- DeepWriter-8B achieves state-of-the-art performance on LongBench-Write and competitive performance on HelloBench and WritingBench compared to leading proprietary models
- The perplexity-guided iterative refinement procedure produces trajectories with significantly lower perplexity and increased token length compared to initial generation
- Pattern injection (reflection tokens) increases diversity of reasoning phrases and improves performance in literature & arts domains by 8.53 points in LLM-as-judge evaluation

## Why This Works (Mechanism)

### Mechanism 1: Perplexity-Guided Search as Reward Proxy
Minimizing perplexity of a known-good output conditioned on a reasoning trajectory serves as an effective proxy for reasoning quality in non-verifiable domains. Given query x and reference solution y, REER searches for trajectory z* = argmin PPL(y|x,z). Lower perplexity indicates the trajectory better "explains" the reference output, implying higher reasoning coherence. Core assumption: The perplexity signal correlates with human-judged reasoning quality for creative/open-ended tasks.

### Mechanism 2: Iterative Local (Segment-wise) Refinement
Segment-by-segment refinement with perplexity-based selection yields higher-quality trajectories than single-pass generation. Initialize trajectory z(0), then iteratively select segment zi, generate candidates, compute PPL(y|x, z′cand), and accept lowest-perplexity candidate. This "global-to-local" approach avoids expensive MCTS rollouts. Core assumption: Local edits guided by global perplexity signal suffice to discover high-quality reasoning paths.

### Mechanism 3: Human-like Thinking Pattern Injection
Explicit injection of cognitive markers (e.g., "Hmm...", "Wait...", "Alternatively") during synthesis yields more flexible, human-like reasoning after fine-tuning. Prompts encourage self-reflection phrases; these patterns appear in synthesized trajectories; fine-tuned model internalizes them, producing diverse reasoning distributions. Core assumption: Training on reflection-marked trajectories transfers to genuine self-correction behavior.

## Foundational Learning

- **Perplexity as Quality Proxy:**
  - Why needed: Central to REER's gradient-free search; replaces traditional reward signals.
  - Quick check question: Can you explain why lower perplexity of y|x,z might indicate a better reasoning trajectory, and one scenario where this assumption could fail?

- **Gradient-Free Local Search:**
  - Why needed: REER optimizes discrete token sequences without differentiable objectives.
  - Quick check question: How does segment-wise candidate generation differ from beam search or MCTS in terms of search direction and computational cost?

- **Synthetic Data for Instruction Tuning:**
  - Why needed: DeepWriting-20K is entirely synthetic; understanding data quality filters is critical.
  - Quick check question: What two filtering heuristics does REER use to prune degenerate trajectories, and why might each be necessary?

## Architecture Onboarding

- **Component map:** Public writing platforms, Project Gutenberg, WildChat/LongWriter6K → 16K query-solution pairs → Initial trajectory generation via prompt → Iterative refinement loop (segment selection → candidate generation → perplexity evaluation → accept/replace) → Filtering (end-of-thinking, repetition) → Mixing with OpenThoughts → Fine-tuning Qwen3-8B-Base

- **Critical path:** The iterative local search loop is the core innovation. If perplexity computation or candidate generation is flawed, downstream fine-tuning degrades significantly.

- **Design tradeoffs:**
  - Trajectory length vs. task type: Long traces help structured professional writing; shorter traces benefit creative ideation
  - Reflection injection vs. formulaic risk: Over-injection may produce superficial markers; ablation shows domain-specific impact
  - Mixed data vs. specialization: Pure REER data risks overfitting; mixing with math/code reasoning preserves general capabilities

- **Failure signatures:**
  - Repetitive/degenerate thinking: Filtered by end-of-thinking and n-gram repetition heuristics
  - Low perplexity but low quality: Indicates proxy failure; may require human spot-checking
  - Catastrophic forgetting: If general reasoning datasets are under-represented in mix

- **First 3 experiments:**
  1. Ablation on synthesis data: Train without DeepWriting-20K → Expect large drop, especially in HB-B and WB domains
  2. Ablation on iterative search: Use only initial trajectories z(0) without refinement → Expect moderate drop in nuanced tasks
  3. Pattern injection analysis: Compare thinking pattern frequency distributions between full model and ablated model → Expect more diverse distribution with injection

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several remain unresolved: whether perplexity minimization captures genuine reasoning quality versus post-hoc justifications, how effectively REER generalizes to domains with multiple valid solution approaches, whether REER can reduce dependency on high-quality reference solutions, and whether manually injected reflection tokens causally improve reasoning versus affecting stylistic presentation.

## Limitations
- The synthetic nature of DeepWriting-20K may bias the model toward post-hoc rationalization rather than genuine exploratory reasoning
- Perplexity-guided search validation is limited to creative writing domains and may not generalize to domains with ambiguous or non-unique reference solutions
- Filtering heuristics (end-of-thinking, repetition) are heuristic and not tuned via human validation, risking low-quality trajectories passing through or high-quality ones being pruned

## Confidence
- **High Confidence**: Core mechanism of perplexity minimization as reasoning quality proxy for creative writing; iterative local refinement procedure; positive impact of pattern injection on phrase diversity
- **Medium Confidence**: Competitiveness claims with proprietary models (GPT-4o, Claude 3.5) due to reliance on LLM-as-judge; transfer of reasoning skills to non-writing domains; exact contribution of synthetic trajectories versus mixed dataset
- **Low Confidence**: Scalability to domains without clear reference solutions; genuine novel reasoning versus plausible post-hoc narratives; avoidance of superficial mimicry of reasoning patterns

## Next Checks
1. **Domain Generalization Test**: Evaluate DeepWriter-8B on scientific hypothesis generation or policy reasoning benchmarks where reference solutions are non-deterministic. Compare perplexity-guided reasoning outputs against human-written exploratory reasoning to assess whether the model genuinely reasons or merely rationalizes.

2. **Human Validation of Trajectory Quality**: Conduct human evaluation on a sample of DeepWriting-20K trajectories versus trajectories generated without iterative refinement. Measure reasoning coherence, novelty, and logical consistency to validate whether perplexity minimization correlates with human-judged quality.

3. **Ablation of Pattern Injection in Novel Contexts**: Test whether self-reflection phrase injection improves reasoning quality in tasks where such phrases are not culturally normative (e.g., mathematical proof generation). If performance drops or phrases appear superficial, this suggests the patterns are not genuinely improving reasoning but rather mimicking surface features.