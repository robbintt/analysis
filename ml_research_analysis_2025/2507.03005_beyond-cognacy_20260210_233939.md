---
ver: rpa2
title: Beyond cognacy
arxiv_id: '2507.03005'
source_url: https://arxiv.org/abs/2507.03005
tags:
- language
- cognate
- phylogenetic
- sound
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates automated methods for phylogenetic inference
  in historical linguistics, focusing on approaches that bypass expert-annotated cognate
  sets. It compares three methods: traditional cognate-based inference, automatic
  cognate clustering with unigram/concept features, and multiple sequence alignment
  (MSA) derived from a pair-hidden Markov model.'
---

# Beyond cognacy

## Quick Facts
- arXiv ID: 2507.03005
- Source URL: https://arxiv.org/abs/2507.03005
- Reference count: 12
- This paper evaluates automated methods for phylogenetic inference in historical linguistics, focusing on approaches that bypass expert-annotated cognate sets.

## Executive Summary
This paper evaluates automated methods for phylogenetic inference in historical linguistics, focusing on approaches that bypass expert-annotated cognate sets. It compares three methods: traditional cognate-based inference, automatic cognate clustering with unigram/concept features, and multiple sequence alignment (MSA) derived from a pair-hidden Markov model. The MSA method shows superior performance in predicting typological variation, better aligning with established linguistic classifications, and providing clearer phylogenetic signal. Specifically, MSA yields the lowest generalized quartet distance from Glottolog classifications and the best fit to Grambank typological features. These results suggest MSA-based inference is a promising, scalable alternative to traditional cognate-based methods, opening new avenues for global-scale language phylogenies beyond expert annotation bottlenecks.

## Method Summary
The study evaluates three phylogenetic inference methods using Lexibank lexical data (928 languages, 110 concepts) and Grambank typological features. The MSA method trains a pair-HMM classifier on 90 million word pairs to identify cognates, generates Viterbi alignments, and constructs a character matrix via T-Coffee. Phylogenetic trees are inferred using RAxML-NG with GTR+G model. Performance is assessed via Generalized Quartet Distance (GQD) against Glottolog, AIC fit to Grambank features, and PyPythia difficulty scores across full datasets, random 100-language samples, and 14 language families.

## Key Results
- MSA method achieves lowest GQD from Glottolog (0.241 vs 0.377 for expert cognates)
- MSA shows best AIC fit to Grambank typological features (1090.53 vs 1174.94 for cognates)
- MSA provides clearest phylogenetic signal via lowest PyPythia difficulty scores

## Why This Works (Mechanism)
The MSA method captures both cognacy and sound correspondences, providing richer phylogenetic signal than cognate-based or clustering methods. By modeling phonological similarity through pair-HMMs trained on massive word-pair data, it discovers systematic sound changes across languages. This explicit modeling of phonological evolution, combined with MSA aggregation that preserves alignment patterns, creates character matrices that better reflect true linguistic relationships than binary cognate presence/absence.

## Foundational Learning
- Pair-HMMs: Why needed - model phonological evolution between cognate words; Quick check - verify emission probabilities show expected sound correspondences (e.g., /p/ matches /p/, /f/, /b/)
- Generalized Quartet Distance: Why needed - quantify tree topology similarity; Quick check - confirm lower GQD indicates better match to reference classification
- Viterbi algorithm: Why needed - find optimal alignment paths in pair-HMM; Quick check - inspect alignment columns for consistent sound correspondences
- Levenshtein distance filtering: Why needed - reduce computational complexity by focusing on potentially related word pairs; Quick check - verify threshold (<0.7) excludes clearly unrelated pairs
- Character binarization: Why needed - convert MSA to format suitable for phylogenetic inference; Quick check - ensure binary matrix preserves alignment information

## Architecture Onboarding
- Component map: Lexibank data -> IPAâ†’ASJP conversion -> Pair-HMM training -> Viterbi alignments -> T-Coffee MSA -> Binary matrix -> RAxML-NG inference -> Evaluation metrics
- Critical path: The pHMM training and MSA construction steps are most critical, as errors here propagate through all downstream analyses
- Design tradeoffs: MSA captures richer signal but requires more computational resources than simple cognate presence/absence; pair-HMM training is expensive but enables scalable inference
- Failure signatures: pHMM training instability manifests as non-convergent loss; poor MSA quality shows as alignment columns without clear patterns; weak phylogenetic signal appears as high GQD or AIC values
- First experiments: 1) Train pHMM on small language subset and inspect emission probabilities for linguistic plausibility, 2) Generate MSA for single concept and manually verify alignment quality, 3) Run RAxML-NG on binary matrix and check likelihood scores across multiple runs

## Open Questions the Paper Calls Out
- How accurately do the inferred branch lengths and divergence dates produced by the MSA method correspond to true historical values?
- Does the explicit modeling of sound correspondences in the MSA method provide a phylogenetic signal superior to automatic cognate clustering alone?
- Can MSA-based inference effectively recover deep-time relationships between language macro-families where expert cognate annotations do not exist?

## Limitations
- pHMM architecture and SVM training details are underspecified, affecting reproducibility
- Evaluation relies on Glottolog, which classifies only family-level relationships, not testing macro-family recovery
- Branch lengths and divergence dates are not validated against historical evidence

## Confidence
- High: MSA method's superior performance in GQD and AIC metrics is well-supported
- Medium: Scalability claims depend on pHMM generalizability assumptions
- Low: Biological relevance claims lack direct testing

## Next Checks
1. Verify pHMM emission probabilities align with known sound correspondences (e.g., /p/ matches /p/, /f/, /b/)
2. Test MSA method on a held-out language family not used in training to assess scalability
3. Compare MSA-derived phylogenies to an independent gold standard (e.g., Ethnologue) beyond Glottolog