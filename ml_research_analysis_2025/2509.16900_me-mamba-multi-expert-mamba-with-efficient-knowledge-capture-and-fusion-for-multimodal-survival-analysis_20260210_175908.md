---
ver: rpa2
title: 'ME-Mamba: Multi-Expert Mamba with Efficient Knowledge Capture and Fusion for
  Multimodal Survival Analysis'
arxiv_id: '2509.16900'
source_url: https://arxiv.org/abs/2509.16900
tags:
- survival
- expert
- multimodal
- fusion
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ME-Mamba is a multi-expert Mamba-based framework for multimodal
  survival analysis that integrates pathology images and genomics data to predict
  cancer patient outcomes. The method addresses the challenge of extracting discriminative
  features from gigapixel WSIs and high-dimensional genomic data, while efficiently
  fusing multimodal representations without losing critical unimodal information.
---

# ME-Mamba: Multi-Expert Mamba with Efficient Knowledge Capture and Fusion for Multimodal Survival Analysis

## Quick Facts
- **arXiv ID:** 2509.16900
- **Source URL:** https://arxiv.org/abs/2509.16900
- **Reference count:** 40
- **Primary result:** Multi-expert Mamba framework integrating pathology and genomics achieves state-of-the-art survival prediction with 8% average C-index improvement over unimodal methods

## Executive Summary
ME-Mamba addresses the challenge of multimodal survival analysis by integrating Whole Slide Images (WSI) and genomic data through a three-expert architecture. The framework uses attention-guided Mamba architectures to extract discriminative features from long instance sequences in both modalities, while a synergistic expert fuses representations through local token-level alignment (Optimal Transport) and global distribution matching (Maximum Mean Discrepancy). The method achieves state-of-the-art performance on five TCGA cancer datasets, improving C-index scores by an average of 8% over unimodal approaches while maintaining computational efficiency compared to Transformer-based methods.

## Method Summary
ME-Mamba employs three parallel experts: Pathology and Genomics Experts use hybrid Mamba architectures with standard and attention-based scanning to extract discriminative features from gigapixel images and high-dimensional genomic data respectively. The Synergistic Expert fuses modalities through a two-step process using Optimal Transport for local token alignment and Maximum Mean Discrepancy for global distribution consistency, followed by interleaved BiMamba processing. The fused representations are combined with unimodal features and passed through an attention aggregation layer and MLP to predict patient survival outcomes using discrete time-to-event loss.

## Key Results
- Achieves state-of-the-art C-index performance on five TCGA cancer datasets
- Improves average C-index by 8% over unimodal methods and 1.2% over top multimodal approaches
- Maintains computational efficiency with linear complexity versus quadratic Transformers
- Demonstrates effectiveness across diverse cancer types including BLCA, BRCA, UCEC, GBMLGG, and LUAD

## Why This Works (Mechanism)

### Mechanism 1: Attention-Guided Sequence Prioritization
The Pathology and Genomics Experts employ hybrid scanning strategies that combine standard bidirectional Mamba processing with attention-based instance prioritization. By calculating attention scores for each token, sorting instances by descending score, and feeding this prioritized sequence into a dedicated Mamba branch, the model forces State Space Models to compress and propagate the most relevant features first rather than treating all patches equally.

### Mechanism 2: Dual-Granularity Cross-Modal Alignment
The Synergistic Expert uses a two-step fusion process to prevent loss of modality-specific information. First, Optimal Transport creates a transport map aligning local pathology tokens with genomic tokens based on cosine similarity. Second, Maximum Mean Discrepancy enforces global distribution consistency between fused features and original modalities, ensuring both specific token-to-token relationships and overall statistical distributions are preserved.

### Mechanism 3: Interleaved Multimodal State Propagation
After OT and MMD alignment, the Synergistic Expert constructs a unified sequence by interleaving pathology and genomic tokens, which is processed by a BiMamba backbone. This sequential processing allows the recurrent hidden state to carry information from one modality to influence the next, enabling cross-modal interaction at linear computational complexity rather than quadratic costs.

## Foundational Learning

- **Structured State Space Models (SSMs) & Mamba**: Understanding how SSMs discretize continuous systems to map 1D input sequences to outputs via latent states is crucial. *Quick check:* How does Mamba's selection mechanism differ from S4's static parameters for filtering WSI noise?

- **Multiple Instance Learning (MIL)**: Treating WSIs as "bags" of instances where only the bag has a label requires attention-based pooling for aggregation. *Quick check:* How does the Pathology Expert aggregate N instance features into a single slide-level representation for survival loss?

- **Optimal Transport (OT) for Alignment**: OT finds transport plans to move mass between domains at minimal cost. *Quick check:* Why does the paper use simplified OT with argmin instead of full Sinkhorn-Knopp, and what constraint does this satisfy?

## Architecture Onboarding

- **Component map:** Pre-trained ResNet50/SNN → Projection (MLP to 256-d) → Unimodal Experts (3-branch Mamba) → Synergistic Expert (OT + MMD + Interleaver) → BiMamba → Attention Aggregation → MLP → Hazard Function

- **Critical path:** Attention-Ranking in Unimodal Experts and Interleaved BiMamba in Synergistic Expert. Incorrect ranking focuses on noise; removing interleaving degrades performance.

- **Design tradeoffs:** Simplified OT uses hard assignment for efficiency but may lose fine-grained uncertainty. Three-branch Mamba triples SSM computation but allows simultaneous discriminative and spatial processing.

- **Failure signatures:** Memory instability with >20k patches despite linear complexity claims; ablation drop >1% when removing Attention-Ranked Scan indicates heavy reliance on discriminative selection.

- **First 3 experiments:** 1) Run Pathology Expert alone to verify Attention-Mamba outperforms standard MambaMIL on BLCA. 2) Compare "Interleaved BiMamba" vs "Sequential (P then G)" scanning in Synergistic Expert. 3) Profile GPU memory and FLOPs with increasing instance counts comparing ME-Mamba against CMTA.

## Open Questions the Paper Calls Out
The paper explicitly states the proposed model "can be extended to integrate more data modalities in the future, paving the way for its adaptation to more complex tasks involving diverse data types."

## Limitations
- Ablation studies partially validate mechanisms but don't isolate whether benefits come from discriminative selection versus reordering itself
- All experiments use similar multimodal data types (WSI + genomics), limiting generalizability assessment
- Simplified OT's hard assignment may introduce brittleness when token correspondences are ambiguous

## Confidence
- **High Confidence:** Core architectural design and ablation showing performance degradation are well-specified and compelling
- **Medium Confidence:** Efficiency claims versus Transformers are reasonable but lack direct empirical validation with memory/time profiling
- **Low Confidence:** Specific claims about why each mechanism works (e.g., attention scores reliably identifying "discriminative" instances) are plausible but not directly validated

## Next Checks
1. Extract and visualize attention scores from Pathology Expert's ABMIL module, computing correlation with pathologist-annotated discriminative regions to validate clinically meaningful feature identification
2. Implement Synergistic Expert variants using only MMD alignment (removing OT) and only OT (removing MMD) to measure performance and loss components separately
3. Apply ME-Mamba to different multimodal survival analysis task (radiology + longitudinal clinical measurements) to test whether OT-based local alignment captures biological correspondences versus dataset-specific patterns