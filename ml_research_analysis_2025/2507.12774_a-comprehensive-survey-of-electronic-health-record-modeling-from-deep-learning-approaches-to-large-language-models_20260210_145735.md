---
ver: rpa2
title: 'A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning
  Approaches to Large Language Models'
arxiv_id: '2507.12774'
source_url: https://arxiv.org/abs/2507.12774
tags:
- clinical
- learning
- data
- medical
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive overview of deep learning
  and large language model (LLM) approaches for electronic health record (EHR) modeling.
  It addresses the unique challenges posed by EHR data, including heterogeneity, temporal
  irregularity, and domain-specificity, which differ fundamentally from tasks in vision
  and natural language processing.
---

# A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models

## Quick Facts
- **arXiv ID:** 2507.12774
- **Source URL:** https://arxiv.org/abs/2507.12774
- **Reference count:** 40
- **Primary result:** Comprehensive taxonomy of deep learning and LLM approaches for EHR modeling addressing heterogeneity, temporal irregularity, and domain-specificity

## Executive Summary
This survey provides a systematic overview of deep learning and large language model approaches for electronic health record modeling. It addresses the unique challenges posed by EHR data, including heterogeneity, temporal irregularity, and domain-specificity, which differ fundamentally from tasks in vision and natural language processing. The survey introduces a unified taxonomy spanning five key dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. It reviews representative methods for improving data quality, capturing temporal and structural dependencies, self-supervised learning, and integrating clinical knowledge. Emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation are highlighted. The survey also discusses open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings.

## Method Summary
The survey systematically reviews EHR modeling approaches through a five-dimensional taxonomy: data-centric strategies (data quality improvement, feature engineering), neural architecture design (CNNs, RNNs, Transformers, GNNs, tree-based models), learning objectives (supervised, self-supervised, multi-task), multimodal integration (vision, text, EHR), and LLM-based systems (EHR-to-text translation, retrieval-augmented generation). It analyzes representative methods across these dimensions, focusing on mechanisms that handle EHR-specific challenges like irregular temporal sampling and hierarchical code structures. The survey synthesizes findings from 40+ references to establish a structured roadmap for advancing AI-driven EHR modeling and clinical decision support.

## Key Results
- **Unified Taxonomy:** Establishes a comprehensive five-dimensional framework organizing EHR modeling approaches from data preprocessing to LLM-based clinical agents
- **Temporal Mechanisms:** Identifies explicit and implicit time-aware approaches (GRU-D, continuous-time Transformers) as critical for handling irregular EHR sampling patterns
- **LLM Integration:** Demonstrates how EHR-to-text serialization and retrieval-augmented generation enable LLMs to perform clinical reasoning while mitigating hallucination risks
- **Clinical Knowledge Integration:** Shows how structure-aware architectures (tree-based, graph-based) incorporate medical ontologies to reduce data sparsity and improve interpretability

## Why This Works (Mechanism)

### Mechanism 1: Structure-Aware Inductive Bias
- **Claim:** If a model aligns its architecture with the inherent topology of medical data (hierarchies, graphs, or irregular time), it mitigates the sparsity and semantic ambiguity of raw EHR codes
- **Mechanism:** "Structure-aware architecture design" works by injecting domain knowledge directly into the model's connectivity patterns. Tree-based models exploit ICD code hierarchies to share statistical strength between rare and common conditions, while Graph-based models treat visits or medical codes as nodes, allowing reasoning over co-occurrence relationships rather than treating codes as independent inputs
- **Core assumption:** Medical knowledge is structured (ontologies, temporal sequences), and this structure is predictive of outcomes
- **Evidence anchors:** Abstract mentions "inherent heterogeneity, temporal irregularity, and domain-specific nature" as unique challenges requiring specific architectures; Section 4.2 discusses tree-based modeling offering "powerful inductive bias to incorporate clinical knowledge, reduce data sparsity"
- **Break condition:** Likely fails if EHR data is extremely sparse or ontology mappings (e.g., ICD hierarchy) are noisy or irrelevant to the specific clinical outcome being predicted

### Mechanism 2: Temporal Dynamics via Explicit Time-Modeling
- **Claim:** Standard sequence models fail on EHR data because they assume regular intervals; mechanisms that explicitly model time irregularity (decay, interpolation, or continuous-time attention) restore predictive fidelity
- **Mechanism:** EHRs are "irregularly sampled." Two approaches: Implicit (GRU-D uses time decay in hidden states) and Explicit (interpolating missing values or using continuous-time Transformers). These mechanisms work by preventing the model from confusing "no observation" with "normal value" and by weighting recent observations more heavily based on actual elapsed time
- **Core assumption:** The time gap between observations carries diagnostic information, and missingness is informative, not random
- **Evidence anchors:** Abstract highlights "temporal irregularity" as a fundamental challenge; Section 4.3.1 states "Irregular sampling is a core challenge... GRU-D augments recurrent units with decay terms"
- **Break condition:** If missingness is completely random (MCAR) rather than informative (MNAR), or if temporal resolution is too coarse, these complex mechanisms may overfit to noise

### Mechanism 3: LLM-Driven Reasoning via EHR-to-Text Translation
- **Claim:** Large Language Models can perform complex clinical reasoning on structured EHR data if the tabular data is serialized into a text format and grounded with retrieval mechanisms
- **Mechanism:** "EHR-to-text translation" and "Retrieval-Augmented Generation (RAG)" work by converting numerical/categorical codes into natural language descriptions, allowing the LLM to apply its pre-trained medical knowledge. RAG enhances this by retrieving "clinical guidelines" or "similar patient records" to reduce hallucinations and align with current medical standards
- **Core assumption:** The medical knowledge encoded in an LLM's pre-training is applicable to specific patient data, and serializing structured data preserves critical numerical relationships
- **Evidence anchors:** Abstract mentions "LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning"; Section 7.1 discusses "Zero/Few-Shot Prompting" where LLMs infer feature correlations
- **Break condition:** LLMs may hallucinate or fail at precise arithmetic (e.g., calculating exact clinical scores like CHA2DS2-VASc) even with serialization; "quantitative clinical calculations" remain a challenge

## Foundational Learning

**Concept: Medical Code Hierarchies (Ontologies)**
- **Why needed here:** EHR models must handle high dimensionality (thousands of codes). Understanding that ICD-10 or CCS codes are organized in trees allows you to understand why Graph Neural Networks or hierarchical Transformers are used
- **Quick check question:** Can you explain why a generic MLP might struggle to predict a rare disease compared to a Graph-based model?

**Concept: Multimodal Alignment (Vision-Language)**
- **Why needed here:** The survey discusses integrating clinical notes (text) and medical imaging (vision). You need to understand that "Alignment" means mapping pixel patches and text tokens into a shared vector space where related concepts are close
- **Quick check question:** If a model sees a chest X-ray and generates a report, what loss function ensures the word "pneumonia" in the report aligns with the visual features of the lung opacity?

**Concept: Missingness Patterns (MNAR vs MCAR)**
- **Why needed here:** In EHR, data is often missing not at random (MNAR)â€”e.g., a lab test is only ordered if a doctor suspects a problem. Models must distinguish between "not measured" and "normal"
- **Quick check question:** In a standard LSTM, how is a missing lab value usually handled, and why is this problematic for EHR data?

## Architecture Onboarding

**Component map:** Static Demographics -> Dynamic Time-Series (Labs/Vitals) -> Embeddings (Structured/Tree/Graph) -> Encoder (GNN/Transformer/Hybrid) -> Prediction Head (Classification/Regression)

**Critical path:** The transition from raw codes to embeddings. If you simply one-hot encode thousands of medical codes, the model will suffer from the curse of dimensionality. The critical step is using pre-trained embeddings (e.g., from ClinicalBERT or GraphCare) or learning them via end-to-end training

**Design tradeoffs:**
- **Interpretability vs. Accuracy:** Rule-based/Tree models are highly interpretable but may underfit compared to Deep Transformers
- **Regular vs. Irregular Time:** Using standard Transformers assumes regular sampling; switching to Time-Aware Transformers (e.g., ChronoFormer) adds complexity but handles real-world EHR timestamps better

**Failure signatures:**
- **Label Leakage:** Using future data (e.g., discharge summaries) to predict admission
- **Class Imbalance:** Predicting the majority class (e.g., "No Readmission") for all patients because the dataset is 99% negative
- **Hallucination:** LLM-based agents inventing symptoms not present in the record

**First 3 experiments:**
1. **Baseline Establishment:** Implement a simple LSTM or Transformer using MIMIC-III/IV data with basic mean-imputation for missing values to establish a baseline AUROC for a standard task (e.g., Mortality Prediction)
2. **Time-Aware Ablation:** Replace the LSTM with a time-aware variant (e.g., GRU-D or a Time-Aware Attention layer) to measure the performance gain from explicitly modeling time gaps
3. **Structure Injection:** Integrate a Knowledge Graph or hierarchical tree structure into the embedding layer to verify if domain knowledge improves performance on rare disease prediction

## Open Questions the Paper Calls Out
None

## Limitations
- **Lack of Comparative Benchmarks:** Survey provides taxonomy but lacks quantitative comparisons showing which architectural choices consistently outperform others across different clinical tasks
- **Standardization Gaps:** Absence of standardized benchmarking protocols across EHR datasets means reported performance metrics may not be directly comparable
- **Evaluation Framework Deficiency:** While mentioning challenges like explainability and clinical alignment, the survey does not provide concrete evaluation frameworks for these critical aspects

## Confidence
- **High Confidence:** Identification of core challenges (temporal irregularity, data heterogeneity, domain-specificity) is well-supported by both the survey and related literature; taxonomy organization appears systematic and comprehensive
- **Medium Confidence:** Proposed mechanisms (structure-aware architectures, temporal modeling, LLM-driven reasoning) are theoretically sound based on cited works, but their relative effectiveness across diverse clinical settings remains unclear without direct comparative studies
- **Low Confidence:** Claims about specific performance gains from particular architectural choices (e.g., "Graph-based models reduce data sparsity") lack the quantitative evidence needed to establish generalizable best practices

## Next Checks
1. **Comparative Benchmarking:** Implement 2-3 representative architectures (e.g., tree-based, graph-based, transformer) on the same EHR dataset (MIMIC-IV) using identical preprocessing and evaluation protocols to directly compare performance
2. **Temporal Sensitivity Analysis:** Systematically evaluate the impact of different time-aware mechanisms (GRU-D vs. Time-Aware Attention vs. Neural ODE) on the same task to determine which approach is most robust to varying levels of data irregularity
3. **Clinical Alignment Study:** Develop a framework to measure the clinical validity of model predictions (e.g., consistency with clinical guidelines) and apply it to both traditional deep learning models and LLM-based approaches to quantify hallucination rates