---
ver: rpa2
title: User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational
  Information-Seeking Experiences
arxiv_id: '2509.25513'
source_url: https://arxiv.org/abs/2509.25513
tags:
- chatgpt
- users
- prompting
- information
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examined how users\u2019 prompting strategies and ChatGPT\u2019\
  s contextual adaptation influence conversational information-seeking (CIS). In a\
  \ nationally representative experiment with 937 U.S."
---

# User Prompting Strategies and ChatGPT Contextual Adaptation Shape Conversational Information-Seeking Experiences

## Quick Facts
- arXiv ID: 2509.25513
- Source URL: https://arxiv.org/abs/2509.25513
- Authors: Haoning Xue; Yoo Jung Oh; Xinyi Zhou; Xinyu Zhang; Berit Oxley
- Reference count: 0
- Primary result: 19.1% of users employed prompting strategies, with ChatGPT adapting responses to controversy by increasing cognitive complexity and citations while decreasing perceived favorability but increasing persuasive impact on attitudes.

## Executive Summary
This study examines how users' prompting strategies and ChatGPT's contextual adaptation influence conversational information-seeking (CIS) experiences. Through a nationally representative experiment with 937 U.S. adults, researchers found that only 19.1% of users employed prompting strategies, with usage concentrated among more educated and Democrat-leaning individuals. ChatGPT demonstrated systematic adaptation to both user prompts and issue controversy, producing more cognitively complex, action-oriented responses with more citations for controversial topics. While cognitively complex responses were perceived less favorably, they led to more positive changes in issue-relevant attitudes, suggesting an implicit persuasive effect that operates independently of user preferences.

## Method Summary
The study employed a 3 (issue type: health/science/policy) × 2 (controversy: yes/no) between-subjects experiment with 937 U.S. adults recruited via Prolific. Participants engaged in ≥5-turn conversations with ChatGPT on controversial and non-controversial topics including COVID-19 boosters, climate change, immigration, artificial sweeteners, microplastics, and highway infrastructure. Communication styles were analyzed using Symanto Psychology API and LIWC CDI score, while prompting strategies were annotated using a validated taxonomy. The study measured prompting strategy prevalence, communication style features, AI perceptions (quality, likability, trust, intelligence), and issue-specific attitude change through pre/post surveys.

## Key Results
- Only 19.1% of users employed prompting strategies, with higher usage among educated and Democrat-leaning individuals
- ChatGPT adapted responses to controversy by increasing cognitive complexity, action-orientation, citations, and reducing structural formatting
- Cognitively complex responses were perceived as less favorable but produced more positive changes in issue-relevant attitudes
- Communication styles varied by issue type: health topics elicited more self-revealing and action-seeking language, while science topics prompted more information-seeking and fact-oriented communication

## Why This Works (Mechanism)

### Mechanism 1: Second-Level Digital Divide in Prompting Strategy Adoption
- Claim: Prompting strategy usage is unequally distributed across demographic groups, reflecting disparities in applied AI literacy rather than access.
- Mechanism: Education level and political orientation correlate with prompting behavior; more educated and Democrat-leaning users employ significantly more prompting strategies. This suggests that skills-based digital divides persist even when tools are freely accessible.
- Core assumption: Prompting strategy usage serves as a behavioral proxy for AI literacy in action.
- Evidence anchors: "only 19.1% of users employed prompting strategies, and these users were disproportionately more educated and Democrat-leaning"; "More educated and Democrat-leaning users employed more prompting strategies, especially content-related requests"; Related work on functional fixedness (arxiv:2504.02074) finds users restrict interactions to familiar patterns, limiting exploration of advanced prompting.

### Mechanism 2: Contextual Adaptation to Issue Controversy
- Claim: ChatGPT systematically adjusts communication style based on perceived controversy of the topic, independent of user prompt style.
- Mechanism: The model generates responses with higher cognitive complexity, more action-oriented language, more citations, and less structural formatting for controversial topics compared to non-controversial ones. This adaptation occurs even when controlling for user communication styles.
- Core assumption: Adaptation reflects patterns in training data where controversial topics are discussed with more analytical language.
- Evidence anchors: "ChatGPT demonstrated contextual adaptation: responses to controversial topics contain more cognitive complexity and more external references than to non-controversial topics"; "for controversial issues, ChatGPT provided more references to external links, generated less structured responses, and used more cognitively complex and action-oriented language"; Evidence on LLM linguistic convergence (arxiv:2508.03276, cited in paper) confirms AI accommodates users asymmetrically.

### Mechanism 3: Cognitive Disfluency-Driven Persuasion
- Claim: Cognitively complex AI responses reduce perceived likability while simultaneously increasing persuasive impact on attitudes.
- Mechanism: Complex responses create cognitive disfluency—mental difficulty in processing—which decreases immediate positive affect but activates systematic processing. This deeper processing leads to stronger attitude formation even when users consciously prefer simpler responses.
- Core assumption: The attitude change reflects implicit persuasion rather than explicit evaluation.
- Evidence anchors: "cognitively complex responses were perceived as less favorable but produced more positive issue-relevant attitudes"; "Complex information may disrupt cognitive fluency and decrease positive affect, but it can also activate systematic processing and facilitate implicit learning"; Corpus evidence on this specific mechanism is weak; no directly comparable studies on cognitive disfluency in LLM persuasion were found in neighbors.

## Foundational Learning

- Concept: **Second-Level Digital Divide**
  - Why needed here: Explains why equal access to ChatGPT does not produce equal usage patterns; disparities emerge in how people use technology, not just whether they have it.
  - Quick check question: Can you distinguish between access-based (first-level) and skills-based (second-level) divides in a user population?

- Concept: **Communication Accommodation Theory**
  - Why needed here: Provides framework for understanding how AI adapts communication styles to users and contexts, including reciprocity and compensation patterns.
  - Quick check question: What is the difference between reciprocal and compensatory adaptation in conversational AI?

- Concept: **Cognitive Disfluency**
  - Why needed here: Explains the paradox where harder-to-process information can be more persuasive despite being less liked; critical for designing AI response strategies.
  - Quick check question: Why might difficult-to-process information lead to stronger attitude change?

## Architecture Onboarding

- Component map:
  - User input module → Prompting strategy classifier → Context detector (controversy/topic) → Response style adapter → Output generator → User perception/attitude feedback loop
  - Communication style extraction: Symanto Psychology API (self-revealing, information-seeking, fact-oriented, action-seeking) + LIWC CDI score (cognitive complexity)
  - Prompting strategy detection: 8-strategy taxonomy grouped into user-supplied information, style-related requests, content-related requests

- Critical path:
  1. User submits prompt → strategy classifier tags prompting behavior
  2. Context detector identifies topic and controversy level
  3. Response style adapter adjusts cognitive complexity, action-orientation, citation density, and structure based on context + user strategy
  4. User evaluates response (likability, trust, intelligence) and potentially updates issue attitude

- Design tradeoffs:
  - Simplicity vs. persuasion: Lower cognitive complexity improves likability but may reduce attitude impact
  - Adaptation vs. consistency: Context-dependent style shifts may confuse users expecting uniform responses
  - Citation density vs. readability: More citations increase credibility signals but can interrupt reading flow

- Failure signatures:
  - Over-adaptation to controversy produces overly dense responses users reject
  - Under-adaptation to controversy produces responses perceived as dismissive on sensitive topics
  - Demographic-based prompting gaps mean advanced features only benefit already-advantaged users

- First 3 experiments:
  1. A/B test response complexity levels on controversial vs. non-controversial topics; measure both likability and attitude change
  2. Segment analysis of prompting strategy adoption by education and political affiliation in your user base
  3. Intervention test: provide prompting suggestions to low-strategy users; measure whether this closes the usage gap

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the observed effects of prompting strategies and contextual adaptation generalize to other conversational AI systems, such as Gemini or Copilot?
- Basis in paper: [explicit] The authors state that focusing exclusively on ChatGPT may limit generalizability and explicitly call for replication across multiple conversational AI systems to assess variations in adaptation.
- Why unresolved: The current study isolated ChatGPT (GPT-4o) to maintain consistency, leaving the behavior of other LLMs with different training data and alignment techniques unknown.
- What evidence would resolve it: A comparative study using the same 3x2 experimental design with participants interacting with non-OpenAI models.

### Open Question 2
- Question: How do communication styles in AI responses influence user perceptions and attitudes over repeated, longitudinal interactions?
- Basis in paper: [explicit] The authors note that their findings rely on one-shot interactions and explicitly suggest that future research should investigate longitudinal effects with repeated conversations.
- Why unresolved: The study measured immediate post-experiment attitudes, but it is unclear if the implicit persuasive effects of cognitive complexity persist or fade as users gain familiarity with the system.
- What evidence would resolve it: A longitudinal panel study tracking the same users' attitudes and perceptions across multiple CIS sessions over weeks or months.

### Open Question 3
- Question: What specific motivations and contextual factors drive users to employ prompting strategies during information seeking?
- Basis in paper: [explicit] The authors identified *who* uses strategies (demographics) but explicitly call for surveys and qualitative studies to understand *when and why* users adopt them.
- Why unresolved: The observational nature of the conversation analysis revealed demographic correlations but could not capture the underlying cognitive or situational reasons for using or ignoring advanced prompting.
- What evidence would resolve it: Qualitative interview data or survey responses from users explaining their intent immediately after they prompt the AI.

### Open Question 4
- Question: Can conversational AI be designed to maintain persuasive benefits while mitigating the negative perception associated with cognitive complexity?
- Basis in paper: [inferred] The authors discuss a design challenge where complex responses improve attitude but reduce likability, and suggest exploring how to present complexity in "more user-friendly ways" (e.g., combining reasoning with conversational tone).
- Why unresolved: It is currently unknown if specific interface designs or response structures can decouple the cognitive load (which aids persuasion) from the user experience (which suffers from complexity).
- What evidence would resolve it: An experiment comparing user feedback on "pure" cognitively complex responses versus responses that pair complex reasoning with high-affinity stylistic elements.

## Limitations

- The study's observational design limits causal inference about whether complex responses actually persuade versus merely correlating with attitude change
- The cognitive disfluency mechanism for attitude change remains speculative without direct measures of processing effort or memory load
- The finding that prompting strategies are unequally distributed across demographic groups cannot explain the underlying causal mechanisms driving these disparities

## Confidence

- **High confidence**: ChatGPT's systematic adaptation to controversy (demonstrated through measurable differences in response features across conditions with appropriate controls)
- **Medium confidence**: The second-level digital divide in prompting strategy adoption (supported by robust demographic associations but lacking causal explanation)
- **Medium confidence**: The disfluency-persuasion paradox (the pattern is observed but the underlying cognitive mechanism remains speculative without direct cognitive measures)

## Next Checks

1. **Measure processing effort**: In a follow-up experiment, track response time, self-reported cognitive load, and recognition memory for key points across different complexity levels to directly test whether cognitive disfluency mediates persuasion.

2. **Test prompting intervention efficacy**: Randomly assign prompting strategy suggestions to users during conversations and measure whether this reduces demographic disparities in strategy adoption, addressing the second-level divide.

3. **Examine long-term attitude stability**: Conduct delayed post-tests (e.g., 1 week later) to determine whether the observed attitude changes persist or decay, distinguishing between momentary persuasion and lasting belief revision.