---
ver: rpa2
title: Dual-Path Stable Soft Prompt Generation for Domain Generalization
arxiv_id: '2505.18770'
source_url: https://arxiv.org/abs/2505.18770
tags:
- prompt
- domain
- negative
- learning
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses domain generalization in vision-language models
  by introducing a novel prompt generation framework called Dual-Path Stable Soft
  Prompt Generation (DPSPG). The core problem is that existing dynamic prompt learning
  methods suffer from "Prompt Variability," where the same input generates significantly
  different and suboptimal prompts across different random seeds.
---

# Dual-Path Stable Soft Prompt Generation for Domain Generalization

## Quick Facts
- **arXiv ID**: 2505.18770
- **Source URL**: https://arxiv.org/abs/2505.18770
- **Reference count**: 40
- **Primary result**: Introduces DPSPG framework that achieves 1.58-3.94% improvement over state-of-the-art methods while reducing prompt variability and improving training stability

## Executive Summary
This paper addresses domain generalization (DG) in vision-language models by introducing a novel prompt generation framework called Dual-Path Stable Soft Prompt Generation (DPSPG). The core innovation is incorporating negative learning into prompt generation, using a dual-path transformer-based architecture that generates both positive and negative prompts for each input. The method solves the "Prompt Variability" problem where existing dynamic prompt learning methods generate significantly different prompts across random seeds. Theoretical analysis shows that negative learning increases the effective decision margin and reduces the gradient norm upper bound, leading to more robust prompts. Extensive experiments on five benchmark datasets demonstrate consistent improvements over state-of-the-art methods while maintaining prompt stability.

## Method Summary
DPSPG employs a two-stage training pipeline: first learning domain-specific positive and negative prompt labels separately for each source domain using cross-entropy and binary cross-entropy losses respectively, then training two independent transformer generators to align outputs with these domain labels using MSE loss. During inference, class probabilities are computed using a combined scoring function that incorporates both positive and negative prompts with a balancing weight α=0.2. The method addresses the Prompt Variability problem by using transformer-based generators instead of GANs, achieving more stable prompt generation across random seeds and training epochs.

## Key Results
- Achieves 1.58-3.94% improvement in accuracy over state-of-the-art methods on five benchmark datasets
- Reduces intra-to-inter domain distance ratio from 0.97 (DPL) to 0.24, indicating better prompt clustering
- Improves training stability with standard deviation of 3.7 vs 9.8 for SPG in accuracy over last 10 epochs
- 6× faster training time (2h vs 12h) compared to CGAN-based approaches while using half the FLOPs

## Why This Works (Mechanism)

### Mechanism 1: Margin Expansion Through Negative Learning
The combined logit gᵢ(x) = s⁺ᵢ(x) − αs⁻ᵢ(x) introduces a negative score term that enlarges the effective decision margin between ground-truth and competing classes. When negative prompts satisfy the constraint that incorrect classes receive higher negative scores than correct classes (s⁻ᵢ(x) ≥ s⁻ᵧ(x) + δ), the effective margin increases from ∆⁺ᵢ(x) to ∆⁺ᵢ(x) + αδ, improving class separability and robustness.

### Mechanism 2: Gradient Norm Reduction
As the margin ∆ᵢ(x) grows through negative learning, the softmax probability for the true class approaches 1, causing the Jacobian norm to decay exponentially: ||J_f(x)|| ≤ (L/τ)e^(−∆ᵢ(x)/τ). With negative learning, this bound becomes even tighter: ||J_f(x)|| ≤ (L/τ)e^(−(∆⁺ᵢ(x)+αδ)/τ), leading to smoother optimization and improved robustness to input perturbations.

### Mechanism 3: Transformer-Based Stability
Transformer-based prompt generators produce more stable and consistent prompts than GAN-based approaches by capturing long-range dependencies and domain-specific nuances through self-attention without adversarial dynamics. This architectural choice reduces variance across random seeds and training epochs, with DPSPG showing 3.7 std vs SPG's 9.8 in accuracy over last 10 epochs.

## Foundational Learning

- **Concept: Domain Generalization (DG) in Vision-Language Models**
  - Why needed: DPSPG operates in multi-source DG setting where model must generalize to unseen target domains without target data during training
  - Quick check: Why does zero-shot CLIP already perform reasonably well on DG benchmarks, and what specific limitation does prompt learning address?

- **Concept: Prompt Variability Problem**
  - Why needed: This is the core problem DPSPG solves—understanding that existing dynamic prompt methods generate inconsistent prompts across random seeds is essential
  - Quick check: If you run SPG with three different random seeds on the same input, what would you expect to observe about the generated prompts, and why is this problematic?

- **Concept: Negative Learning vs. Contrastive Learning**
  - Why needed: DPSPG introduces negative learning into prompt generation, which differs from contrastive learning's use of negative samples; understanding this distinction is critical for correct implementation
  - Quick check: In negative learning, what does the negative prompt encode, and how does its loss function (BCE) differ from contrastive losses like InfoNCE?

## Architecture Onboarding

- **Component map**: CLIP text encoder ψ -> Domain prompt labels v⁺,dj, v⁻,dj -> Transformer generators G⁺, G⁻ -> Linear projection fc -> Generated prompts v̂⁺, v̂⁻

- **Critical path**: 
  1. Initialize positive "a photo of a {class}" and negative "a photo without a {class}" templates (4 tokens each)
  2. Train v⁺,dj and v⁻,dj for each source domain using SGD (lr=2e-3, 70 epochs, cosine schedule)
  3. Train two transformer-based generators G⁺ and G⁻ using AdamW (lr=2e-5 to 2e-3, 50 epochs) to align outputs with domain labels
  4. Generate v̂⁺ = G⁺(φ(x)) and v̂⁻ = G⁻(φ(x)), compute class probabilities using gᵢ(x) = s⁺ᵢ(x) − αs⁻ᵢ(x)

- **Design tradeoffs**:
  - Transformer (18.9M params) vs CGAN (5.0M params): DPSPG has 3.8× more parameters but is 6× faster (2h vs 12h) and uses half the FLOPs (0.126 vs 0.227)
  - Two-stage vs end-to-end: Decoupling label learning from generator training adds pipeline complexity but enables more stable optimization
  - Negative weight α=0.2: Moderate values balance margin enhancement against over-suppression

- **Failure signatures**:
  - High intra-to-inter domain distance ratio (λ > 0.3) indicates prompts aren't clustering properly
  - High accuracy std across epochs (std > 5) suggests unstable training
  - Negative prompts misclassifying (incorrect class scores exceed correct class scores)

- **First 3 experiments**:
  1. Negative prompt ablation: Compare Pos-only (Exp #3) vs full Pos+Neg (Exp #4) on PACS to confirm ~0.65% improvement
  2. Generator architecture comparison: Compare transformer vs CGAN generator (Exp #2 vs Exp #4) on PACS to validate 2.18% improvement
  3. Prompt distribution visualization: Replicate Figure 2 t-SNE analysis of generated prompts for held-out domain

## Open Questions the Paper Calls Out

- **Open Question 1**: How does DPSPG perform in single-source domain generalization settings compared to the multi-source scenarios evaluated? The method relies on domain prompt labels learned from multiple source domains, making single-source performance uncertain.

- **Open Question 2**: Is the fixed template "a photo without a {class}" optimal for defining negative prompt labels, or can performance be improved via alternative semantic or learnable definitions? The effectiveness relies on VLM's pre-trained understanding of "without," which may not be maximally discriminative.

- **Open Question 3**: Does the "Prompt Variability" phenomenon persist in other Vision-Language Model architectures (e.g., ALIGN, BLIP), and is the dual-path solution equally effective? The instability is linked to CLIP's specific architecture, and generalization to other VLMs remains unverified.

## Limitations
- Architecture specification gap: Limited details on transformer generator architecture (hidden dimensions, attention heads)
- Dataset-specific hyperparameter sensitivity: Inconsistent learning rate specifications across datasets
- Negative learning constraint validity: No verification that s⁻ᵢ(x) ≥ s⁻ᵧ(x) + δ constraint is satisfied in practice
- Limited real-world generalization: Experiments confined to controlled benchmark datasets

## Confidence

**High Confidence (8/10)**:
- Prompt Variability Problem: Well-supported by experimental evidence showing SPG's 9.8 std in accuracy
- Stability Improvement: Clear improvement with DPSPG's 3.7 std, supported by quantitative metrics

**Medium Confidence (6/10)**:
- Margin Expansion Theory: Mathematical derivation sound but practical magnitude of δ unverified
- Performance Gains: 1.58-3.94% improvements significant but may be partially attributed to stability

**Low Confidence (4/10)**:
- Negative Learning vs. Contrastive Learning: No comparison against modern contrastive approaches
- Computational Efficiency Claims: 6× speedup needs validation given increased parameter count

## Next Checks
1. Implement systematic verification that learned negative prompts satisfy s⁻ᵢ(x) ≥ s⁻ᵧ(x) + δ constraint, measuring actual δ values and correlating with performance improvements.

2. Conduct comprehensive ablation study varying α ∈ {0.1, 0.2, 0.5, 1.0} on PACS and DomainNet to identify optimal trade-off between margin enhancement and negative prompt interference.

3. Evaluate DPSPG on real-world multi-domain dataset (WILDS or DomainNet with natural splits) to assess practical generalization beyond controlled benchmarks.