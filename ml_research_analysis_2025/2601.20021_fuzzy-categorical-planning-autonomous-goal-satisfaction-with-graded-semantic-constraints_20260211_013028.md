---
ver: rpa2
title: 'Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic
  Constraints'
arxiv_id: '2601.20021'
source_url: https://arxiv.org/abs/2601.20021
tags:
- planning
- plan
- graded
- fuzzy
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Fuzzy Category-theoretic Planning (FCP) extends categorical planning\
  \ to handle vague predicates by annotating actions with graded applicability degrees\
  \ and composing them via \u0141ukasiewicz t-norm. It grounds these degrees from\
  \ natural language using an LLM with k-sample median aggregation, while preserving\
  \ crisp feasibility checks via pullback verification."
---

# Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints

## Quick Facts
- arXiv ID: 2601.20021
- Source URL: https://arxiv.org/abs/2601.20021
- Reference count: 19
- Primary result: FCP achieves 85.2% success on PDDL3 preference/oversubscription benchmarks and 83.6% success on RecipeNLG-Subs (significantly higher than LLM-only or ReAct baselines).

## Executive Summary
Fuzzy Category-theoretic Planning (FCP) extends categorical planning to handle vague predicates by annotating actions with graded applicability degrees and composing them via Łukasiewicz t-norm. It grounds these degrees from natural language using an LLM with k-sample median aggregation, while preserving crisp feasibility checks via pullback verification. FCP supports bidirectional search with residuum-based backward requirements and accepts plans only after explicit α-cut verification of both feasibility and quality. Evaluated on PDDL3 preference/oversubscription benchmarks and RecipeNLG-Subs (missing-substitute recipe tasks), FCP achieves 85.2% success on PDDL3 (competitive with SGPlan) and 83.6% success on RecipeNLG-Subs (significantly higher than LLM-only or ReAct baselines), while maintaining near-reference BLEU scores.

## Method Summary
FCP implements fuzzy category-theoretic planning by grounding graded applicability from natural language via an LLM with k-sample median aggregation (default k=5), composing plan quality via Łukasiewicz t-norm (a⊗b = max(0, a+b−1)), and preserving crisp feasibility checks through pullback verification. The system uses bidirectional AND-OR search with residuum-based backward requirements and accepts plans only after α-cut verification of both feasibility and quality. Semantic chunking mitigates nilpotent degradation in long plans by grouping coherent action sequences into macro-morphisms with dedicated grounding.

## Key Results
- FCP achieves 85.2% success on PDDL3 preference/oversubscription benchmarks, competitive with SGPlan
- FCP achieves 83.6% success on RecipeNLG-Subs missing-substitute recipe tasks, significantly higher than LLM-only or ReAct baselines
- Ablation studies show k-sample aggregation and semantic chunking are critical for robustness, with Łukasiewicz composition explicitly capturing quality degradation across multi-step plans

## Why This Works (Mechanism)

### Mechanism 1: Łukasiewicz t-Norm Composition for Explicit Degradation Tracking
Composing graded applicability via Łukasiewicz t-norm provides interpretable, linear accumulation of quality loss across multi-step plans. Each action morphism f receives a membership degree μ(f;w) ∈ [0,1]. Plan quality is composed via a⊗b = max(0, a+b−1), yielding closed-form degradation: μ(π) = max(0, Σᵢμᵢ − (n−1)). Six actions with μ=0.8 each produce μ(π)=0, making degradation auditable. Core assumption: Quality degradation under vague satisfaction is approximately additive rather than multiplicative or min-based. Evidence anchors: [abstract] "composes plan quality via a t-norm (Łukasiewicz)... while maintaining near-reference BLEU scores" and [Section 3.1] "This expression makes degradation explicit: for example, six actions with μᵢ = 0.8 yield μ(π) = max(0,4.8−5) = 0". Break condition: Long plans without chunking cause quality to collapse to zero under nilpotent composition (ablation shows 48.3% → 85.2% success with chunking enabled).

### Mechanism 2: k-Sample Median Aggregation for Stable Membership Grounding
Aggregating multiple LLM samples via median reduces outlier sensitivity and improves downstream planning success. For each candidate action, query LLM k times (default k=5) under stochastic decoding, parse 0–100 ratings, normalize to [0,1], take median. Median is robust to occasional mis-scores that would corrupt single-sample decisions. Core assumption: The LLM produces graded judgments that are noisy but centered around a reasonable membership value. Evidence anchors: [abstract] "grounds these degrees from natural language using an LLM with k-sample median aggregation" and [Section 5.2] "removing aggregation (k=1) consistently reduces Success on both benchmarks... aggregation mainly improves decision reliability". Break condition: Systematic LLM bias (e.g., consistently over-optimistic scores) cannot be fixed by aggregation alone; requires calibration.

### Mechanism 3: Pullback Verification Separating Crisp Feasibility from Fuzzy Quality
Preserving crisp pullback-based constraint checks while using fuzzy scores only for quality ranking prevents hard-constraint violations. Fuzzy membership influences search guidance and plan ranking, but any candidate must pass pullback verification (resources, logic, temporal compatibility) before acceptance. Fuzzy scores never override hard feasibility. Core assumption: Hard constraints can be formulated crisply even when objectives involve vague predicates. Evidence anchors: [abstract] "preserving crisp feasibility checks via pullback verification... reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines" and [Section 3.4] "If any crisp constraint is violated... the meet is rejected regardless of fuzzy membership". Break condition: If domain constraints are themselves vague or under-specified, pullback verification cannot provide crisp guarantees.

## Foundational Learning

- **T-norms and fuzzy composition**: Understanding how Łukasiewicz differs from product and Gödel t-norms is essential for grasping the quality tracking mechanism. Quick check: Given three actions with memberships [0.9, 0.8, 0.7], compute the composed quality under Łukasiewicz vs. Gödel (min).
- **Categorical pullbacks**: Pullback verification is the mechanism that enforces hard constraints; understanding it is essential for debugging rejected meets. Quick check: In a category with states as objects and actions as morphisms, what does a pullback represent when merging forward and backward partial plans?
- **Residuation in fuzzy logic**: Backward propagation uses the residuum a⇒b = min(1, 1−a+b) to compute required forward membership; without this, bidirectional search cannot work. Quick check: If a goal state requires μ≥0.6 and a candidate action has μ(f)=0.8, what membership must the preceding state have (using Łukasiewicz residuum)?

## Architecture Onboarding

- **Component map**: LLM Grounding Module -> Fuzzy Composition Engine -> Pullback Verifier -> Bidirectional Search Controller -> α-Cut Acceptor
- **Critical path**: State expansion → LLM grounding query (k samples) → median aggregation → fuzzy composition update → pullback check on meet candidates → α-cut validation → plan output
- **Design tradeoffs**:
  - **k (aggregation width)**: Stability vs. LLM cost. Ablation shows k=1 drops PDDL3 success from 85.2% to 74.5%; k=5 is practical default with diminishing returns beyond.
  - **α (acceptance threshold)**: Higher α improves quality but reduces success rate; adaptive α by plan length mitigates nilpotent degradation.
  - **t-norm choice**: Łukasiewicz provides interpretable degradation; Gödel (min) loses accumulation (69.7% vs 85.2% success).
- **Failure signatures**:
  - **Success drops sharply with plan length (>7 steps)**: Indicates chunking is disabled or insufficient.
  - **High BLEU but low success (LLM/ReAct baselines)**: Fluent text violating hard constraints—pullback verification not active.
  - **k=1 shows high variance across runs**: Aggregation disabled; single-sample grounding is unstable.
- **First 3 experiments**:
  1. **Ablate aggregation**: Run FCP with k=1 vs. k=5 on RecipeNLG-Subs; expect ~5-8% success drop from single-sample variance.
  2. **Disable chunking**: Remove macro-morphism grouping; expect catastrophic success drop (85.2%→48.3%) on plans >5 steps due to nilpotent degradation.
  3. **Swap t-norm**: Replace Łukasiewicz with Gödel (min); expect moderate success drop (85.2%→69.7%) as accumulated quality loss becomes invisible.

## Open Questions the Paper Calls Out

- **Semantic similarity metrics**: How does FCP performance compare when evaluated using semantic similarity metrics or human user studies instead of BLEU? The current evaluation relies on BLEU, which may not fully capture semantic correctness or the quality of substantial, valid edits. Evidence would include correlation analysis between FCP success rates and human ratings, or re-evaluation using embedding-based similarity metrics.

- **Dataset artifacts**: To what extent do systematic artifacts in the RecipeNLG-Subs dataset construction inflate success rates or BLEU scores? Automated dataset construction can introduce artifacts that inflate BLEU or simplify constraint checking. Evidence would include evaluation on a manually curated dataset with adversarially selected substitutes or analysis of distributional bias in automated substitutes.

- **Generalization to less clear boundaries**: Does FCP generalize to domains where the distinction between crisp executability and semantic vagueness is less clear than in PDDL3? The current experiments rely on PDDL3 (crisp dynamics + preferences) and recipes (crisp constraints + vague substitutes); it is unclear if the method works when the hard/soft boundary itself is fuzzy. Evidence would include application to domains with continuous state spaces where the feasibility predicate itself is graded or uncertain.

## Limitations
- Only evaluated on PDDL3 preference/oversubscription benchmarks and RecipeNLG-Subs, which may not fully represent real-world vagueness scenarios.
- Evaluation relies on BLEU metric, which can under-reward semantically valid paraphrases and may not capture true plan quality.
- Dataset construction artifacts may inflate success rates or BLEU scores, limiting generalizability to real-world planning tasks.

## Confidence
- **High confidence**: Core claim that Łukasiewicz t-norm composition provides interpretable quality degradation (explicit formula and ablation evidence).
- **Medium confidence**: Claim that k-sample median aggregation improves robustness (ablation shows 85.2%→74.5% success drop without it, but exact prompt and aggregation method are underspecified).
- **Medium confidence**: Claim that pullback verification prevents hard-constraint violations (strong on RecipeNLG-Subs, but prompt templates and constraint propagation details are unclear).

## Next Checks
1. **Prompt template validation**: Reconstruct the exact LLM prompt and domain-specific factor rubrics; run k=1 vs k=5 aggregation on RecipeNLG-Subs and verify the 10% success gap.
2. **Pullback constraint verification**: Implement a minimal version of the pullback checker; inject synthetic violations (e.g., allergen, equipment conflicts) and confirm they block plan acceptance regardless of fuzzy score.
3. **Chunking necessity test**: Disable semantic chunking and run FCP on a 7-step plan with μ≈0.8 per action; confirm that quality collapses to zero (μ(π)=max(0, 5.6−6)=0) and success drops sharply.