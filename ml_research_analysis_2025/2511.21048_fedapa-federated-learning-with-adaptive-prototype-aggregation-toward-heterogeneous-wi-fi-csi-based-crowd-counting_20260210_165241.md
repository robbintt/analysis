---
ver: rpa2
title: 'FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous
  Wi-Fi CSI-based Crowd Counting'
arxiv_id: '2511.21048'
source_url: https://arxiv.org/abs/2511.21048
tags:
- local
- learning
- client
- prototype
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedAPA is a federated learning method for distributed Wi-Fi CSI-based
  crowd counting that handles heterogeneous data and model architectures. It uses
  adaptive prototype aggregation (APA) to assign similarity-based weights to peer
  prototypes, enabling adaptive client contributions and yielding a personalized global
  prototype for each client.
---

# FedAPA: Federated Learning with Adaptive Prototype Aggregation Toward Heterogeneous Wi-Fi CSI-based Crowd Counting

## Quick Facts
- arXiv ID: 2511.21048
- Source URL: https://arxiv.org/abs/2511.21048
- Reference count: 40
- Primary result: 9.65% accuracy gain, 9% F1 gain, 0.29 MAE reduction, 95.94% communication overhead reduction vs. baselines

## Executive Summary
FedAPA introduces a federated learning method for distributed Wi-Fi CSI-based crowd counting that handles heterogeneous data and model architectures. It uses adaptive prototype aggregation (APA) to assign similarity-based weights to peer prototypes, enabling adaptive client contributions and yielding a personalized global prototype for each client. During local training, a hybrid objective combines classification with representation contrastive learning, stabilized by a warm-up schedule. Experiments on a real-world Wi-Fi CSI crowd-counting dataset across six environments show significant performance improvements over multiple baselines.

## Method Summary
FedAPA addresses heterogeneous Wi-Fi CSI data in federated learning by using adaptive prototype aggregation. Each client maintains local prototypes per class, computed as mean embeddings. The server computes cosine similarity between client prototypes, converts to adaptive weights via softmax, and aggregates personalized global prototypes for each client. A hybrid local objective combines classification loss with prototype contrastive losses (aligning with global and peer prototypes), stabilized by a cosine-based warm-up schedule. Missing-class prototypes are padded using sample-weighted averages from other clients. Only prototype sets are communicated between clients and server, significantly reducing communication overhead.

## Key Results
- 9.65% increase in accuracy compared to multiple baselines
- 9% gain in F1 score across heterogeneous environments
- 0.29 reduction in Mean Absolute Error for crowd counting
- 95.94% reduction in communication overhead by exchanging prototypes instead of model parameters

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Prototype Aggregation (APA) for Personalized Knowledge Transfer
Weighting prototype aggregation by inter-client similarity improves performance over uniform averaging in heterogeneous Wi-Fi sensing. The server computes cosine similarity between class prototypes of different clients, converts similarities to adaptive weights via softmax, and aggregates personalized prototypes for each client. This creates a positive feedback loop strengthening collaboration among similar clients. Core assumption: cosine similarity between class prototypes meaningfully reflects data distribution similarity across clients.

### Mechanism 2: Hybrid Local Objective with Warm-up for Stable Representation Learning
Combining classification loss with prototype contrastive loss, stabilized by a warm-up schedule, aligns local and global representations while preserving classification performance. The local loss combines cross-entropy with two prototype contrastive terms, with a cosine-based warm-up schedule gradually increasing the weight of contrastive losses from near-zero to maximum over training rounds. Core assumption: early-stage classification learning provides a stable foundation for subsequent representation alignment.

### Mechanism 3: Prototype Padding and Inter-Client Prototype Loss for Label-Skew Non-IID
Padding missing class prototypes with sample-weighted averages from other clients and incorporating all client prototypes in the contrastive loss enables effective learning under severe label skew. For absent classes, pseudo-prototypes are created by averaging prototypes from clients that have those classes. These padded prototypes are included in both personalized global prototypes and the inter-client contrastive loss, providing informative negative anchors for unseen classes. Core assumption: averaged prototypes from other clients provide reasonable approximations for missing local classes.

## Foundational Learning

- **Prototype-based Representation Learning**
  - Why needed: FedAPA relies on class prototypes as compact information carriers for aggregation and contrastive alignment. Without understanding prototypes as mean embeddings per class, the rationale for similarity-weighted aggregation and prototype-based losses is unclear.
  - Quick check: Given a batch of embeddings for class c, how would you compute its prototype?

- **Federated Learning under Non-IID Data**
  - Why needed: The core problem is heterogeneous (non-IID) CSI data across Wi-Fi environments. FedAPA's design—personalized prototypes, warm-up, local training objectives—is a response to the failures of standard FedAvg in such settings.
  - Quick check: Why does uniform model averaging (FedAvg) degrade when client data distributions diverge significantly?

- **Contrastive Learning Objectives**
  - Why needed: The hybrid loss uses prototype-based contrastive terms to align local representations with global and peer prototypes. Understanding how contrastive losses structure embedding spaces is essential to grasp the alignment mechanism.
  - Quick check: In a contrastive loss, what role do "positive" and "negative" samples play in shaping the representation?

## Architecture Onboarding

- **Component map**: Client (local CSI data, encoder+classifier, local prototypes) -> Server (similarity computation, adaptive weighting, prototype aggregation) -> Client (personalized global prototypes)

- **Critical path**: 1) Initialize local models and prototype sets 2) For each round: a) Clients receive personalized prototypes and full prototype set b) Clients update λ via warm-up schedule c) Clients perform local SGD on hybrid loss d) Clients compute updated local prototypes e) Clients upload prototypes to server f) Server computes similarity, adaptive weights, and personalized prototypes g) Server pads missing prototypes h) Server returns personalized prototypes and full set to clients

- **Design tradeoffs**:
  - Communication vs. Computation: Reduces communication (prototypes are much smaller than models) but adds computation for prototype-based losses locally
  - Personalization vs. Generalization: Similarity-weighted aggregation promotes personalization but may limit cross-domain generalization if client cohorts are too narrow
  - Warm-up length: Shorter warm-up risks early instability; longer warm-up delays representation alignment

- **Failure signatures**:
  - Convergence stalls or diverges: Check if λ increases too aggressively or if local learning rate is too high
  - Performance degrades under severe label skew: Inspect prototype padding—are pseudo-prototypes for missing classes reasonable?
  - No benefit from APA over uniform averaging: Verify that cosine similarity between prototypes is meaningful

- **First 3 experiments**:
  1. Baseline comparison: Replicate Table III with FedAvg, WiFed, FedCaring, and FedAPA on statistical data heterogeneity
  2. Ablation on warm-up: Test T_warm ∈ {25, 50, 100} and static λ ∈ {0.1, 0.5, 1.0} to confirm warm-up outperforms fixed λ
  3. Ablation on aggregation strategy: Compare global average prototype aggregation vs. FedAPA's similarity-weighted aggregation

## Open Questions the Paper Calls Out

1. How does FedAPA perform under partial client participation, and can a prototype-diversity-aware client selection strategy maintain accuracy while reducing bandwidth?
2. Can the FedAPA framework be adapted for semi-supervised or unsupervised learning to mitigate the reliance on expensive, labeled CSI data?
3. Can the adaptive prototype aggregation mechanism be generalized to support multi-task collaboration (e.g., simultaneous crowd counting and activity recognition)?

## Limitations
- Dataset availability: The core Wi-Fi CSI crowd counting dataset is not publicly accessible, limiting reproducibility
- Prototype initialization: Exact method for initializing prototypes P_0 and Q_0 at round 0 is not specified
- Generalization: Performance gains are demonstrated on a single task (crowd counting) and dataset; effectiveness on other Wi-Fi sensing tasks remains unproven

## Confidence

- Adaptive Prototype Aggregation Mechanism (High): Well-supported by theory and ablation studies
- Hybrid Objective with Warm-up (Medium): Mechanism is sound, but warm-up schedule optimization appears dataset-specific
- Prototype Padding Strategy (Low): Core assumption (averaged prototypes provide reasonable negative anchors) lacks strong empirical or theoretical support

## Next Checks

1. **Dataset independence test**: Validate FedAPA on a different Wi-Fi sensing task (e.g., activity recognition) using a publicly available CSI dataset to test generalizability
2. **Prototype quality analysis**: Visualize and quantify the quality of padded prototypes for missing classes; compare against alternative padding strategies
3. **Robustness to similarity noise**: Test FedAPA's performance when client prototypes are artificially corrupted or when similarity weights are randomized to assess resilience to noisy similarity measures