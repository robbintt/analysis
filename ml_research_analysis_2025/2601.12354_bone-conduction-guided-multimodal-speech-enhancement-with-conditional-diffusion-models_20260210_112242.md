---
ver: rpa2
title: Bone-conduction Guided Multimodal Speech Enhancement with Conditional Diffusion
  Models
arxiv_id: '2601.12354'
source_url: https://arxiv.org/abs/2601.12354
tags:
- speech
- enhancement
- multimodal
- diffusion
- conditioning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BCDM, a multimodal speech enhancement framework
  that integrates bone-conducted speech with air-conducted speech using conditional
  diffusion models. The proposed model employs two conditioning strategies - input
  concatenation and decoder conditioning - to effectively incorporate bone-conduction
  sensor data.
---

# Bone-conduction Guided Multimodal Speech Enhancement with Conditional Diffusion Models

## Quick Facts
- **arXiv ID**: 2601.12354
- **Source URL**: https://arxiv.org/abs/2601.12354
- **Reference count**: 0
- **Primary result**: Introduces BCDM, a multimodal speech enhancement framework using conditional diffusion models that integrates bone-conducted and air-conducted speech, achieving significant improvements in POLQA, PESQ, and ESTOI metrics, particularly at extreme signal-to-noise ratios.

## Executive Summary
This paper presents BCDM, the first application of conditional diffusion models to bone-conduction guided speech enhancement. The framework integrates bone-conducted speech (immune to acoustic noise but bandwidth-limited) with air-conducted speech to enhance speech in extremely noisy environments. The model employs two conditioning strategies - input concatenation and decoder conditioning - to effectively incorporate bone-conduction sensor data. Extensive experiments demonstrate that BCDM substantially outperforms both single-modality diffusion baselines and state-of-the-art multimodal approaches across various acoustic conditions, achieving significant improvements in perceptual quality metrics.

## Method Summary
BCDM uses a modified score-based generative model where the drift coefficient guides the reverse diffusion process toward the noisy mixture rather than pure noise, enabling conditional generation of clean speech. The framework employs two conditioning strategies: Input Concatenation (IC) where bone-conducted and air-conducted signals are concatenated at the input, and Decoder Conditioning (DC) where a separate encoder processes bone-conducted speech and injects features into decoder upsampling layers. The score model is based on NCSN++ U-Net architecture, operating on 256×256 complex STFT spectrograms. Training uses score matching loss with diffusion parameters σ_min=0.05 and σ_max=0.5, and inference employs a predictor-corrector sampler with 60 reverse steps.

## Key Results
- BCDM achieves significant improvements in POLQA, PESQ, and ESTOI metrics across SNR conditions from -10 to 15 dB
- At -10 dB SNR, BCDM-DC-L achieves best POLQA (2.44) and PESQ (2.02), substantially outperforming single-modality diffusion baselines
- Decoder Conditioning strategy achieves higher peak performance than Input Concatenation but requires more reverse steps to converge
- Small model variants achieve comparable performance to large variants at high SNR while being 6× smaller

## Why This Works (Mechanism)

### Mechanism 1: Modified Drift Coefficient for Conditional Generation
The modified drift coefficient guides the diffusion reverse process toward the noisy mixture distribution rather than pure noise, enabling clean speech generation conditioned on corrupted input. Instead of transitioning samples to zero-mean noise in the forward SDE, the drift coefficient `f(xt, y) := γ(y - xt)` moves the mean toward the noisy mixture `y`. This creates a conditional generation process where the score model learns to predict clean speech samples consistent with the observed noisy input.

### Mechanism 2: Noise-Immune Bone-Conduction Modality as Conditioning Signal
Bone-conducted speech provides noise-resistant phonetic content that guides enhancement when air-conducted SNR is extremely low. Bone-conducted speech is recorded via skull vibrations, making it immune to acoustic noise, though it suffers limited bandwidth. By conditioning on this modality, the model gains access to speech content information that remains reliable even at -10 dB SNR where air-conducted signals provide little usable information.

### Mechanism 3: Decoder Conditioning Enables Modality-Specific Feature Extraction
Separate encoders for each modality with decoder-level feature injection outperforms simple input concatenation, particularly at higher SNRs. The DC strategy uses a dedicated encoder for bone-conducted speech that injects features into decoder upsampling layers at each resolution. This allows the network to learn modality-specific representations rather than forcing early fusion, with 1×1 convolutions to manage parameter count.

## Foundational Learning

- **Concept: Score-based generative models and SDEs** - Why needed: The entire framework builds on forward/reverse SDEs where the score function ∇xt log p(xt|y) must be estimated by a neural network. Without understanding how diffusion iteratively denoises, the conditioning strategies won't make sense. Quick check: Can you explain why the reverse SDE requires estimating the score function rather than directly predicting clean speech?

- **Concept: Complex-valued STFT representation** - Why needed: The score model operates on 256×256 complex STFT spectrograms. Understanding time-frequency representations is essential for preprocessing and interpreting model behavior. Quick check: Why would complex-domain processing offer advantages over magnitude-only spectrograms for speech enhancement?

- **Concept: U-Net architectures with skip connections** - Why needed: The backbone is NCSN++ (a multi-resolution U-Net). The DC strategy specifically exploits decoder injection points that assume familiarity with encoder-decoder feature pyramids. Quick check: Where would you inject conditioning features in a U-Net if you wanted early fusion vs. late fusion?

## Architecture Onboarding

- **Component map**: Score model sθ(xt, y, yc, t) -> PC sampler -> iSTFT reconstruction; DC strategy adds: Bone-conduction encoder -> Decoder injection points

- **Critical path**: 1. STFT extraction (510 window, 128 hop → 256 bins, 256 frames) 2. Forward diffusion with modified drift toward noisy mixture 3. Score model prediction conditioned on both modalities 4. Reverse SDE solving via PC sampling 5. iSTFT reconstruction

- **Design tradeoffs**: IC vs DC: IC is simpler with fewer parameters (65.6M vs 67.4M for large variants), but DC achieves higher peak metrics at cost of more reverse steps. Model size: Small variants (11.7-12.3M) achieve comparable performance to large variants at high SNR while being 6× smaller. σ_max selection: Higher values improve noise removal but risk speech component loss

- **Failure signatures**: At high SNR (15 dB), multimodal baselines like BiNet underperform because they act more like bandwidth extension than true enhancement. DCCRN fails at low SNR due to poor bone-conduction utilization. Single-modality SGMSE+ only outperforms multimodal baselines at moderate SNR (5+ dB), highlighting fusion challenges in prior work

- **First 3 experiments**: 1. Reproduce IC vs DC comparison on validation speakers (20 utterances) measuring PESQ trajectory across N=10,20,40,60 reverse steps to verify convergence patterns 2. Ablate bone-conduction input by replacing with zeros at -10 dB SNR to quantify modal contribution 3. Test σ_max sweep [0.3, 0.5, 0.7] on held-out noisy conditions to validate noise removal vs speech preservation trade-off

## Open Questions the Paper Calls Out

### Open Question 1
Can the inference latency of BCDM be reduced to match single-step predictive models without compromising the enhanced perceptual quality? The paper notes that while BCDM outperforms baselines, predictive models produce output in a single function call, whereas diffusion models require multiple reverse steps. The paper characterizes the performance trade-off relative to the number of steps but does not propose methods to bridge the computational gap to real-time single-step methods.

### Open Question 2
Can the architectural trade-off between the rapid convergence of Input Concatenation (IC) and the higher performance ceiling of Decoder Conditioning (DC) be eliminated? The paper observes that IC is efficient while DC is accurate, leaving the challenge of designing a unified strategy that optimizes for both speed and metric performance.

### Open Question 3
Does the BCDM framework generalize to diverse languages and speaker demographics beyond the specific subset of Chinese speakers used in the ABCS dataset? The paper restricts experimental setup exclusively to the ABCS dataset, which consists of 100 Chinese speakers, leaving cross-linguistic robustness unverified.

## Limitations
- The paper relies on a proprietary ABCS dataset that is not publicly available, limiting reproducibility and external validation
- Only one noise dataset (CHiME3) is used for testing, limiting generalizability to other acoustic environments
- The exact architectural details of NCSN++ and the BigGAN-style conditioning encoder are not fully specified
- The time alignment requirements between bone-conducted and air-conducted signals are critical but not quantified in terms of tolerance thresholds

## Confidence
- **High confidence**: The effectiveness of bone-conduction as a noise-immune modality for speech enhancement
- **Medium confidence**: The superiority of decoder conditioning over input concatenation
- **Medium confidence**: The overall state-of-the-art performance based on comparison with published baselines
- **Low confidence**: The generalizability to other bone-conduction sensor types and noise conditions

## Next Checks
1. **Time alignment robustness test**: Introduce controlled misalignment (0-50ms) between bone-conducted and air-conducted signals and measure degradation in POLQA/PESQ to quantify alignment sensitivity

2. **Cross-noise generalization**: Test the trained model on alternative noise datasets (e.g., DNS-Challenge, Librispeech-noise) to evaluate performance beyond CHiME3 and identify potential overfitting

3. **Real-time inference benchmarking**: Measure actual latency of IC vs DC strategies with varying reverse steps (N=10,20,30,60) on GPU/CPU to validate the claimed trade-offs between quality and speed shown in Fig. 2