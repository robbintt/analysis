---
ver: rpa2
title: Towards Mechanistic Defenses Against Typographic Attacks in CLIP
arxiv_id: '2508.20570'
source_url: https://arxiv.org/abs/2508.20570
tags:
- typographic
- attention
- attacks
- heads
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a training-free defense against typographic
  attacks in CLIP models by identifying and ablating specialized attention heads that
  transmit typographic information to the cls token. Using a Typographic Attention
  Score, the authors locate attention heads in later layers that disproportionately
  attend to text regions.
---

# Towards Mechanistic Defenses Against Typographic Attacks in CLIP

## Quick Facts
- arXiv ID: 2508.20570
- Source URL: https://arxiv.org/abs/2508.20570
- Reference count: 40
- Key outcome: Training-free defense against typographic attacks via targeted ablation of specialized attention heads improves robustness by up to 19.6% on ImageNet-100-Typo while preserving <1% clean accuracy drop.

## Executive Summary
This paper addresses the vulnerability of CLIP models to typographic attacks, where adversarial text overlays cause misclassification. The authors propose a novel training-free defense that identifies and ablates specific attention heads responsible for processing typographic information. By computing a Typographic Attention Score and iteratively selecting heads that can be disabled without significant performance loss, they create "dyslexic" CLIP models that maintain strong general image classification while being significantly more robust to typographic attacks. The method demonstrates effectiveness across different CLIP model sizes and remains competitive with fine-tuned defenses.

## Method Summary
The defense identifies attention heads that causally transmit typographic information to the CLS token using a Typographic Attention Score computed on synthetic data. Heads are ranked by this score and iteratively added to an ablation circuit if their removal causes less than 1% accuracy drop on clean validation data. The final "dyslexic" model ablates these heads by zeroing their contribution to the CLS token's residual stream. This training-free approach requires no gradient updates and can be applied to any pre-trained CLIP model.

## Key Results
- Ablation of specialized typographic heads improves robustness to typographic attacks by up to 19.6% on ImageNet-100-Typo
- Clean ImageNet-100 accuracy drops by less than 1% when applying the defense
- The defense generalizes across CLIP model sizes (ViT-B/16, ViT-B/32, ViT-L/14)
- Performance remains competitive with fine-tuned defenses while being training-free

## Why This Works (Mechanism)

### Mechanism 1: Specialized Attention Heads Causally Transmit Typographic Information
The defense exploits the fact that a small subset of attention heads in CLIP's vision encoder is causally responsible for processing and transmitting typographic information to the CLS token. These heads can be precisely identified and disabled without affecting general visual capabilities. The Typographic Attention Score identifies heads that disproportionately attend to text regions, and ablation studies prove their causal role in typographic attack vulnerability.

### Mechanism 2: Typographic Processing Occurs in a Late-Stage Specialized Circuit
Typographic information is not processed uniformly but handled by a specialized circuit that becomes active in later stages. Linear probe analysis shows sharp increases in typographic label accuracy in later layers, distinct from gradual increases in object label accuracy. This suggests a late-stage circuit that "writes" typographic information to the CLS token after general feature extraction.

### Mechanism 3: Targeted Ablation as an Effective Training-Free Defense
Directly intervening on the forward pass by ablating identified typographic circuits provides an efficient defense competitive with retraining. The training-free nature allows application to large models with minimal computational cost. The modularity of typographic heads enables clean disabling without cascading failures, though applications requiring text reading would be harmed.

## Foundational Learning

- **Attention Heads in Vision Transformers**: Understanding how attention heads compute [cls]-to-spatial attention maps and contribute to residual streams is essential since the entire method targets specific head functionality.
  - *Quick check*: Using `transformers`, write a script to extract attention weights from a specific ViT layer for a given image.

- **Linear Probes and Representation Analysis**: Linear probes are used to discover where and when typographic information appears in the model, mapping information flow through layers.
  - *Quick check*: If a linear probe on layer 10 achieves 99% accuracy for "contains_text" but layer 5 only achieves 55%, what does this imply about processing hierarchy?

- **Ablation Studies for Causal Inference**: Identifying heads by score is correlation; ablation proves causation by intervention. Understanding why ablation is the standard tool for establishing causal relationships is critical.
  - *Quick check*: Besides zero-ablation, what is "resampling ablation" or "mean ablation," and why might it be a better control?

## Architecture Onboarding

- **Component Map**: Image x -> CLIP Vision Encoder (L layers, I heads Hi,l) -> Typographic Attention Score Ti,ℓ -> Circuit C (selected heads) -> Ablation (Hi,l(x)cls → 0) -> Dyslexic Model MC -> Output [cls] embedding

- **Critical Path**:
  1. Construct Unsplash-Typo dataset and compute Ti,ℓ for every attention head
  2. Rank heads by Ti,ℓ and iteratively build circuit C, adding heads only if clean accuracy drop < ε = 0.01
  3. Deploy dyslexic model with all heads in C ablated, using as drop-in replacement for original CLIP

- **Design Tradeoffs**: The epsilon parameter controls the robustness-accuracy tradeoff (ε=0.01 allows 1% drop for maximal robustness). Generalization risk exists as circuit is built on synthetic data. Ablation only affects CLS token, preserving spatial information but leaving typographic data in spatial tokens exploitable by downstream systems.

- **Failure Signatures**: Catastrophic forgetting (>1% clean accuracy drop suggests too many heads or poor scoring); incomplete defense (high vulnerability to new attacks suggests circuit too small or poor scoring); overfitting to artifacts (works on synthetic data but fails on real-world text).

- **First 3 Experiments**:
  1. Reproduce head scoring by overlaying text on images and computing/visualizing Ti,ℓ scores to verify late-layer pattern
  2. Implement targeted ablation by modifying forward pass to zero CLS contribution from highest-scoring head and testing adversarial label probability reduction
  3. Run full iterative loop with ε=0.01 on ImageNet subset to determine final circuit size and accuracy tradeoff

## Open Questions the Paper Calls Out
- The defense mechanism's adaptation for Vision-Language Models that utilize spatial tokens rather than just CLS token needs investigation.
- Knowledge of the identified typographic circuit could potentially be exploited to craft stronger adaptive attacks that circumvent the ablation.
- The impact of ablating the typographic circuit on the model's ability to perform benign Optical Character Recognition (OCR) tasks remains unquantified.

## Limitations
- Circuit generalization uncertainty: Defense built on synthetic data with bottom-center text placement lacks quantitative evidence for generalization to arbitrary positions and real-world scenarios.
- Distribution shift in circuit construction: Method measures attention on synthetic computer-generated text, potentially different from real-world typography including handwritten text and artistic fonts.
- Partial defense scope: Ablation only affects CLS token representation, leaving typographic information in spatial tokens exploitable by downstream systems.

## Confidence
- **High Confidence**: Core mechanistic claim that specific heads causally transmit typographic information is well-supported by ablation studies; training-free method and accuracy-robustness tradeoff clearly demonstrated.
- **Medium Confidence**: Claim that typographic processing occurs in specialized late-stage circuit is strongly supported by linear probe analysis, but broader implications not fully explored.
- **Low Confidence**: Long-term generalization of circuit to all forms of real-world text and complete elimination of typographic vulnerabilities not fully established.

## Next Checks
1. Test dyslexic models on ImageNet-100-Typo with text placed in random positions (top, left, right, center) to quantify positional bias in circuit effectiveness.
2. Evaluate circuit ablation effectiveness on real-world images containing natural text from OCR benchmarks versus synthetic Unsplash-Typo data to isolate synthetic vs. natural typography impact.
3. Analyze spatial token representations from final layer of original and dyslexic models to measure if typographic information remains decodable from spatial tokens, confirming partial defense scope.