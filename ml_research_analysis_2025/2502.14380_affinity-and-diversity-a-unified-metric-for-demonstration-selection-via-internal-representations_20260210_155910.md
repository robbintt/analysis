---
ver: rpa2
title: 'Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal
  Representations'
arxiv_id: '2502.14380'
source_url: https://arxiv.org/abs/2502.14380
tags:
- diversity
- affinity
- accuracy
- bm25
- demonstrations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a unified metric for demonstration selection\
  \ in In-Context Learning (ICL) based on the internal representations of the ICL\
  \ model itself. The key idea is to identify an induction head critical for ICL and\
  \ compute two metrics\u2014affinity (similarity between query and demonstrations)\
  \ and diversity (variance among demonstration representations)\u2014using the head\u2019\
  s internal subspace."
---

# Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations

## Quick Facts
- arXiv ID: 2502.14380
- Source URL: https://arxiv.org/abs/2502.14380
- Reference count: 40
- The paper introduces a unified metric for demonstration selection in In-Context Learning (ICL) based on the internal representations of the ICL model itself.

## Executive Summary
This paper proposes a unified approach to demonstration selection for In-Context Learning by leveraging the internal representations of a critical induction head within the LLM. The key insight is that demonstration effectiveness can be evaluated in the same representational space the model uses for ICL inference. By identifying the most effective attention head for pattern induction and computing affinity (similarity) and diversity (variance) metrics in its subspace, the method provides a principled alternative to external retrieval-based approaches. Experiments on 10 classification datasets with Llama 3 8B show that both metrics strongly correlate with test accuracy, outperforming or matching prior methods.

## Method Summary
The method identifies the most effective "induction head" in an LLM by computing attention scores from the query's last token to correct label tokens in demonstrations, selecting the head with maximum total attention. It then uses this head's $W_Q^\top W_K$ projection to map query and demonstration tokens into a shared internal representation space. Two metrics are computed: affinity (mean cosine similarity between query and label token representations) and diversity (trace of covariance matrix of label representations). The method correlates these metrics with accuracy using Spearman's rank correlation for affinity and Ridge regression with Laplacian kernel for diversity.

## Key Results
- Both affinity and diversity metrics strongly correlate with test accuracies across 10 classification datasets
- The proposed metrics outperform or match prior retrieval-based methods (BM25, BGE M3, EPR) in effectiveness
- The unified metrics show strong correlations with scores from prior selection methods, while prior methods show weak or inconsistent correlations among themselves
- The approach is validated using Llama 3 8B on classification tasks including SST2, Rotten Tomatoes, AGNews, and others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Identifying and leveraging the most critical "induction head" provides a more relevant subspace for measuring demonstration quality than external models.
- Mechanism: The method identifies the attention head with the highest total attention score from the query's last token to correct label tokens, then uses this head's $W_Q^\top W_K$ projection to map tokens into a shared internal representation space directly involved in the ICL inference process.
- Core assumption: The effectiveness of a demonstration is best evaluated in the same representational space the model uses to perform the ICL task.
- Evidence anchors: [abstract] "Our experiments show that both affinity and diversity strongly correlate with test accuracies..." [section 2.2] "In this paper, we find the most effective induction head, and define the affinity-diversity metrics on the $W_Q^\top W_K$ mappings of this head."
- Break condition: If the chosen "best induction head" is not stable across different ICL tasks or models, or if the $W_Q^\top W_K$ mapping of a single head is insufficient to capture the complexity of ICL inference.

### Mechanism 2
- Claim: High affinity (cosine similarity) between query's final token representation and demonstration label token representations in the induction head's subspace correlates with higher ICL accuracy.
- Mechanism: High affinity suggests that the model's internal representation of the query's final token is geometrically close to representations of correct label tokens in demonstrations, making it easier for the induction head to attend to and retrieve the correct label pattern.
- Core assumption: Geometric proximity in the $W_Q^\top W_K$ subspace translates to functional relevance for predicting the correct label.
- Evidence anchors: [abstract] "...both affinity and diversity strongly correlate with test accuracies..." [section 4.2] "Fig. 2... indicates that affinity shows a positive correlation across various tasks..."
- Break condition: The correlation might break if demonstration labels are semantically similar but functionally different for the task, or if the model relies more on input tokens than label tokens for induction.

### Mechanism 3
- Claim: High diversity (variance) among demonstration label token representations in the induction head's subspace is complementary to affinity and correlates with higher ICL accuracy.
- Mechanism: High diversity ensures selected demonstrations provide broader coverage of the task's label space, helping the model better delineate decision boundaries or patterns associated with different labels.
- Core assumption: A set of demonstrations that spans more of the internal representational space of labels is more effective for guiding the model's prediction.
- Evidence anchors: [abstract] "...diversity... strongly correlate with test accuracies..." [section 3.2.2] "We define diversity as the variance... across the label token representations of all demonstrations..."
- Break condition: The diversity metric assumes a roughly spherical or well-behaved distribution of label representations. If optimal demonstration set requires more complex, non-linear structure, simple variance metric might be insufficient.

## Foundational Learning

- Concept: **Induction Heads**
  - Why needed here: This is the core architectural component the entire paper's metric is built upon. Understanding that specific attention heads are responsible for the "copying" or pattern-matching behavior in ICL is essential for understanding why their internal subspace is a good place to measure affinity and diversity.
  - Quick check question: Can you explain the function of an induction head in a transformer model and how it differs from a standard attention head?

- Concept: **Query-Key ($W_Q$, $W_K$) Subspace**
  - Why needed here: The paper's metrics are computed on the vectors projected by the $W_Q^\top W_K$ matrix of a specific attention head. Understanding that the dot product of these projected vectors determines the attention score is crucial for interpreting the "affinity" metric.
  - Quick check question: In an attention mechanism, what is the geometric interpretation of the dot product between a query vector and a key vector?

- Concept: **Spearman's Rank Correlation & Coefficient of Determination ($R^2$)**
  - Why needed here: The paper uses these specific statistical measures to validate its claims. Spearman's correlation is used for affinity (a rank-based measure), while $R^2$ is used for diversity (often after regression).
  - Quick check question: What does a Spearman's rank correlation coefficient of 0.8 indicate about the relationship between two variables? What does an $R^2$ of 0.6 indicate?

## Architecture Onboarding

- Component map: Induction Head Locator -> Representation Projector -> Metric Calculator
- Critical path:
  1. Feed a batch of randomly sampled ICL prompts (demonstrations + query) through the LLM
  2. For each attention head, compute attention score from query's last token to all demonstration label tokens
  3. Identify "best induction head" ($\hat{h}$) with highest average score
  4. For any new demonstration set and query, project their label and final query tokens using $W_{\hat{h},Q}^\top W_{\hat{h},K}$
  5. Compute affinity and diversity metrics from projected vectors
- Design tradeoffs: The method relies on a single "best" induction head for simplicity, which is a major simplification of the full ICL circuit involving multiple layers and heads. This makes the metric computationally tractable but may sacrifice some nuance captured by a more complex, multi-head representation.
- Failure signatures: Expect poor results if the identified "best induction head" is unstable across different runs or datasets. A low or inconsistent correlation between computed metrics and accuracy would also signal failure of the core hypothesis.
- First 3 experiments:
  1. **Induction Head Validation:** Re-run induction head identification process on multiple diverse tasks. Is the same head consistently identified, or does it vary?
  2. **Ablation Study:** Compare correlation-to-accuracy of metrics computed from "best" head vs. metrics computed from other heads or pooled representation of multiple heads. Does specific head chosen matter?
  3. **Demonstration Selection via Optimization:** Use unified affinity-diversity metric as objective function (e.g., maximize weighted sum) to actively select demonstrations for downstream task and compare performance against random selection and baselines.

## Open Questions the Paper Calls Out

- Question: How can an efficient demonstration selection algorithm be developed to jointly optimize the proposed affinity and diversity metrics?
  - Basis in paper: [explicit] The authors state in Section 5.4, "Due to space limitations and computational resources, we leave the demonstration selection method as future work."
  - Why unresolved: The current work validates the metrics as evaluation tools (correlating with accuracy) but does not propose or test a mechanism to search for or construct demonstration sets that maximize these specific metrics.
  - What evidence would resolve it: A retrieval algorithm that maximizes the affinity-diversity objective and demonstrates superior downstream task accuracy compared to existing retrievers like BM25 or EPR.

- Question: How does the order of demonstrations impact the effectiveness of sets selected via affinity and diversity?
  - Basis in paper: [explicit] Section 7 (Limitations) explicitly notes the inability to compare performance regarding the "order of demonstrations."
  - Why unresolved: The paper computes metrics on the set of demonstrations but does not account for the sequential nature of ICL; high-affinity sets might perform poorly if ordered incorrectly, a known sensitivity in ICL.
  - What evidence would resolve it: Experiments measuring the variance in accuracy when the same demonstration set (selected via proposed metrics) is presented in different permutations (e.g., random vs. relevance-ordered).

- Question: Do the affinity and diversity metrics derived from induction heads generalize to non-classification tasks or other model architectures?
  - Basis in paper: [inferred] The experimental setup (Section 4.1) is restricted to "10 classification datasets" and the "Llama 3 8B" model.
  - Why unresolved: The reliance on specific "induction heads" may be architecture-dependent, and the correlation between these internal representations and task success is unproven for generative tasks (e.g., summarization) or models with different circuit structures.
  - What evidence would resolve it: Correlation results between the proposed metrics and accuracy on generation benchmarks using a diverse set of model architectures.

## Limitations
- Strong dependence on correctly identifying a single "best induction head" for the entire ICL task, which may not capture the full complexity of ICL inference
- Method assumes the $W_Q^\top W_K$ projection from a single head provides sufficient representational power for measuring demonstration quality
- Exact specification of prompt template and tokenization used in StaICC is ambiguous, particularly which tokens are designated as "label tokens"

## Confidence
- **High Confidence**: The claim that affinity and diversity metrics computed from the best induction head correlate with ICL accuracy
- **Medium Confidence**: The claim that these metrics unify and correlate with prior demonstration selection methods
- **Low Confidence**: The claim that using the model's own internal representations is inherently superior to external retrieval-based methods

## Next Checks
1. **Head Stability Analysis**: Run induction head identification across multiple random seeds and held-out validation sets for each dataset. Quantify variance in selected heads and resulting correlation-to-accuracy metrics.
2. **Multi-Head Ablation**: Extend method to compute affinity and diversity using pooled representations from multiple attention heads (e.g., top-3 or top-5 heads by attention score). Compare correlation-to-accuracy metrics against single-head approach.
3. **Cross-Domain Transfer**: Test method on non-classification ICL tasks (e.g., arithmetic, code generation, commonsense reasoning) using same induction head identification procedure. Evaluate whether affinity and diversity metrics maintain their correlation with accuracy.