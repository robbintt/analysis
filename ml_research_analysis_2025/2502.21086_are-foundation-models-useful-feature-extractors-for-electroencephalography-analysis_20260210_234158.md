---
ver: rpa2
title: Are foundation models useful feature extractors for electroencephalography
  analysis?
arxiv_id: '2502.21086'
source_url: https://arxiv.org/abs/2502.21086
tags:
- band
- time
- series
- general-purpose
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluates whether foundation models, originally developed
  for natural language processing and computer vision, can effectively extract meaningful
  features from electroencephalography (EEG) data. The authors investigate three general-purpose
  time series models (MOMENT, UniTS, OTiS) across three EEG tasks: age prediction,
  seizure detection, and classification of clinically relevant EEG events.'
---

# Are foundation models useful feature extractors for electroencephalography analysis?

## Quick Facts
- **arXiv ID:** 2502.21086
- **Source URL:** https://arxiv.org/abs/2502.21086
- **Reference count:** 33
- **Primary result:** Foundation models pre-trained on heterogeneous time series (0.53% EEG) extract meaningful EEG features, outperform specialized models even without domain adaptation, and enable biomarker localization through frequency band analysis.

## Executive Summary
This study evaluates whether foundation models, originally developed for natural language processing and computer vision, can effectively extract meaningful features from electroencephalography (EEG) data. The authors investigate three general-purpose time series models (MOMENT, UniTS, OTiS) across three EEG tasks: age prediction, seizure detection, and classification of clinically relevant EEG events. They compare these models against specialized EEG models and assess the impact of domain adaptation strategies. The results show that foundation models perform competitively with specialized EEG models, even without domain adaptation, and can localize task-specific biomarkers through frequency band analysis. The study demonstrates that foundation models can reduce reliance on large domain-specific datasets while maintaining clinical utility, particularly for tasks where visual interpretation of raw EEG is feasible. Fine-tuning becomes essential for more complex tasks requiring higher specialization.

## Method Summary
The study evaluates three foundation models (MOMENT, UniTS, OTiS) on three public EEG datasets (LEMON, Epilepsy, TUEV) using three adaptation strategies: zero-shot (frozen model with cosine similarity classification), linear probing (frozen backbone + trained linear head), and fine-tuning (full model training). The models are pre-trained on heterogeneous time series data (ECG 62.48%, weather 31.76%, audio 3.06%, engineering 2.13%, EEG 0.53%). Performance is assessed on age prediction (R²), seizure detection (accuracy), and event classification (balanced accuracy) across 5 random seeds with grid search hyperparameter tuning.

## Key Results
- Foundation models outperform specialized EEG models even without domain adaptation for simple tasks like seizure detection
- Fine-tuning offers no advantages for simple tasks but is essential for complex tasks requiring domain knowledge
- Frequency band analysis reveals task-specific biomarker localization (age-related information in higher frequencies, ictal activity in lower frequencies)

## Why This Works (Mechanism)

### Mechanism 1: Cross-Domain Temporal Feature Transfer
General-purpose time series foundation models pre-trained on heterogeneous domains can extract clinically meaningful EEG features without domain-specific training. Pre-training on diverse time series corpora learns universal temporal patterns—trends, periodicities, transients—that transfer across signal types. The model encodes generalizable representations of temporal dynamics rather than domain-specific semantics.

### Mechanism 2: Frequency Band Biomarker Localization via Representation Partitioning
Foundation model representations encode frequency-specific information, enabling biomarker localization through band-wise feature analysis. EEG signals decomposed into canonical frequency bands (δ: 0.5–4 Hz, θ: 4–8 Hz, α: 8–13 Hz, β: 13–30 Hz, γ: 30–100 Hz) preserve frequency-dependent structure in the learned representations, allowing post-hoc attribution of task-relevant information to specific bands.

### Mechanism 3: Task Complexity–Adaptation Necessity Gradient
The required degree of domain adaptation (zero-shot → linear probing → fine-tuning) scales with task complexity and domain knowledge requirements. Zero-shot features suffice when raw signal visual interpretation is feasible (e.g., seizure detection with clear morphological markers). Fine-tuning becomes necessary when tasks require integrating domain-specific knowledge (e.g., distinguishing eye movement artifacts from background activity).

## Foundational Learning

- **Concept: Foundation Model Pre-training Objective**
  - Why needed here: Understanding that these models learn via self-supervised objectives on heterogeneous time series (not EEG-specific labels) explains their zero-shot transfer capability and limitations.
  - Quick check question: Can you explain why a model pre-trained on weather and ECG data might recognize seizure patterns without ever seeing labeled seizures?

- **Concept: EEG Frequency Band Physiology**
  - Why needed here: Interpreting biomarker localization results requires knowing that delta activity correlates with pathological states, alpha with relaxed wakefulness, and that aging affects high-frequency power.
  - Quick check question: If a model attributes age prediction primarily to gamma band features, would you trust this result given that gamma is often contaminated by muscle artifact?

- **Concept: Linear Probing vs. Fine-tuning Trade-offs**
  - Why needed here: Selecting the appropriate adaptation strategy requires understanding that linear probing preserves pre-trained features while fine-tuning risks catastrophic forgetting on small datasets.
  - Quick check question: For a 500-sample EEG dataset, would you recommend fine-tuning all parameters or linear probing? Why?

## Architecture Onboarding

- **Component map:** Raw EEG → Preprocessing → Frequency decomposition → Foundation model backbone → Representation extraction → Task head → Output
- **Critical path:**
  1. Context length selection - match context window to expected event duration
  2. Pre-processing validation - verify frequency band preservation; aggressive filtering degrades gamma-band tasks to chance
  3. Adaptation strategy selection - start with zero-shot baseline; add fine-tuning only if task complexity warrants and data supports it
- **Design tradeoffs:**
  | Choice | Benefit | Risk |
  |--------|---------|------|
  | Zero-shot | No training data needed, preserves generalization | May underperform on specialized tasks |
  | Linear probing | Fast adaptation, minimal overfitting | Limited expressivity |
  | Full fine-tuning | Maximum task performance | Overfitting on small datasets |
  | Domain-specific pre-training | Optimal if sufficient EEG data | Requires 100+ hours EEG; general-purpose may outperform if limited |
- **Failure signatures:**
  - Fine-tuned model underperforms zero-shot → Dataset too small; switch to linear probing
  - Gamma-band features at chance level → Check pre-processing pipeline for aggressive low-pass filtering
  - High variance across seeds → Reduce learning rate, increase regularization, or reduce model capacity
- **First 3 experiments:**
  1. Zero-shot baseline: Evaluate frozen OTiS on target EEG task using cosine similarity classification
  2. Frequency band ablation: Run inference on band-filtered variants to identify which frequency bands drive predictions
  3. Adaptation comparison: Compare linear probing vs. fine-tuning on 5 random seeds

## Open Questions the Paper Calls Out

- **Open Question 1:** Can general-purpose foundation models maintain competitive performance on EEG tasks requiring temporal segmentation, such as sleep staging or motor imagery classification?
  - Basis in paper: The conclusion explicitly states the work "motivates future exploration in other EEG tasks, such as sleep stage classification or motor imagery."
  - Why unresolved: The current study was restricted to regression and event classification tasks, leaving high-frequency temporal segmentation tasks unexplored.
  - What evidence would resolve it: Benchmarking the evaluated models on standard sleep staging and motor imagery datasets.

- **Open Question 2:** What is the optimal context window length for maximizing the diagnostic accuracy of foundation models in EEG analysis?
  - Basis in paper: The abstract notes that "diagnostic accuracy is substantially influenced by architectural choices such as context length."
  - Why unresolved: While the paper identifies context length as a critical factor, it does not present a systematic ablation study to define optimal settings for different clinical tasks.
  - What evidence would resolve it: A parameter sweep of context lengths for each model and task to plot the relationship between input duration and performance metrics.

- **Open Question 3:** Does increasing the proportion of EEG data in the pre-training mixture yield better performance than general heterogeneous pre-training?
  - Basis in paper: The general OTiS model (0.53% EEG in pre-training) often outperformed the specialized OTiS_EEG, creating ambiguity regarding the value of domain-specific pre-training data versus data diversity.
  - Why unresolved: The comparison shows mixed results where general features sometimes supersede specialized ones, leaving the optimal balance between domain specificity and general time series knowledge unclear.
  - What evidence would resolve it: Pre-training model variants with incrementally increasing ratios of EEG data in the corpus and evaluating the downstream transfer performance.

## Limitations
- Limited representation of EEG data (0.53%) in the foundation model pre-training corpus may affect generalizability to specialized EEG tasks
- Three datasets used may not capture full heterogeneity of clinical EEG scenarios
- Analysis focuses on tasks where visual interpretation is feasible, potentially limiting applicability to more complex neurological assessments

## Confidence
- **High Confidence:** Foundation models outperform specialized EEG models in zero-shot settings for simple tasks like seizure detection
- **Medium Confidence:** Frequency band biomarker localization through representation analysis
- **Medium Confidence:** Task complexity determines adaptation strategy effectiveness

## Next Checks
1. **Domain Transfer Validation:** Test foundation models on EEG datasets with distinct characteristics (e.g., pediatric vs. adult populations, different pathologies) to assess robustness of cross-domain transfer
2. **Frequency Band Ablation Study:** Systematically remove individual frequency bands during inference to quantify their contribution to task performance and validate biomarker localization claims
3. **Small Dataset Performance:** Evaluate foundation models on smaller EEG datasets (<1,000 samples) to confirm the claimed advantage over specialized models when domain adaptation is limited by data scarcity