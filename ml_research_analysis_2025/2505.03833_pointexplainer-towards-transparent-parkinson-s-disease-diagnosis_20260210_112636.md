---
ver: rpa2
title: 'PointExplainer: Towards Transparent Parkinson''s Disease Diagnosis'
arxiv_id: '2505.03833'
source_url: https://arxiv.org/abs/2505.03833
tags:
- point
- hand-drawn
- pointexplainer
- diagnostic
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PointExplainer, a transparent diagnostic
  method for Parkinson's Disease (PD) detection using digitized hand-drawn signals.
  The key innovation is encoding hand-drawn trajectories into 3D point clouds and
  training an interpretable surrogate model to identify diagnostically relevant regions
  by assigning discrete attribution values to hand-drawn segments.
---

# PointExplainer: Towards Transparent Parkinson's Disease Diagnosis

## Quick Facts
- arXiv ID: 2505.03833
- Source URL: https://arxiv.org/abs/2505.03833
- Reference count: 40
- Primary result: Achieves 88.10% accuracy on SST dataset with interpretable attribution maps for Parkinson's Disease diagnosis

## Executive Summary
This paper introduces PointExplainer, a transparent diagnostic method for Parkinson's Disease detection using digitized hand-drawn signals. The key innovation is encoding hand-drawn trajectories into 3D point clouds and training an interpretable surrogate model to identify diagnostically relevant regions by assigning discrete attribution values to hand-drawn segments. The method addresses the black-box nature of existing PD diagnostic models, which limits clinical trust. PointExplainer demonstrates competitive diagnostic performance (e.g., 88.10% accuracy on the SST dataset) while providing intuitive explanations via attribution maps.

## Method Summary
PointExplainer converts hand-drawn spiral test data into 3D point clouds using spatial coordinates and dynamic features like pressure or radius. A patch-based PointNet backbone classifies segments independently, with majority voting for final diagnosis. To explain predictions, the system perturbs segments by collapsing points to their center, trains a surrogate model (XGBoost/Linear) on these binary vectors, and uses the learned weights as attribution values. The method is validated across three datasets with cross-validation and evaluated for both diagnostic accuracy and explanation faithfulness.

## Key Results
- Achieves 88.10% accuracy, 86.67% sensitivity, and 90.00% specificity on SST dataset
- Demonstrates 88.59% accuracy, 88.74% sensitivity, and 88.17% specificity on DST dataset
- Shows robust performance across multiple height feature selections with minimal performance drop (<10%)

## Why This Works (Mechanism)

### Mechanism 1
Encoding hand-drawn trajectories as 3D point clouds preserves fine-grained motor details that 2D image grids often lose during discretization. The system maps 2D coordinates (x, y) and dynamic features (e.g., pressure, radius) into a 3D space (x, y, z), creating a sparse, continuous trajectory representation that retains geometric structure without quantization noise.

### Mechanism 2
Localizing diagnosis via patch-based analysis allows the model to identify specific regions of motor failure rather than just a global label. The cloud is segmented into overlapping patches using a sliding window, with a PointNet backbone classifying each patch independently, and a majority voting scheme aggregating these local predictions.

### Mechanism 3
A perturbation-based surrogate model can faithfully approximate the black-box decision boundary by observing output changes when specific segments are collapsed. The system generates perturbed samples by shifting points in a "superpoint" to its center and trains an interpretable surrogate on these binary vectors to mimic the black-box model's outputs.

## Foundational Learning

- **3D Point Cloud Representation**: Why needed here - The paper fundamentally differs from image-based analysis by treating handwriting as a set of 3D vectors rather than a 2D picture. Quick check: Can you explain why inputting (x, y, pressure) as a 3D coordinate might preserve "movement speed" information better than a static image?

- **Surrogate Models (Local Approximation)**: Why needed here - The core value proposition is "transparency," relying on training a simple model to explain a complex one. Quick check: If a complex model has a highly non-linear decision boundary, would a linear surrogate model provide faithful explanations globally or only in a narrow local region?

- **Superpoints / Segmentation**: Why needed here - The granularity of the explanation depends on how the trajectory is chunked. Quick check: How does the definition of a "superpoint" (e.g., a cluster of points vs. a fixed time window) affect the clinical readability of the resulting attribution map?

## Architecture Onboarding

- **Component map**: Input Layer (digitized signals → 3D Point Cloud) → Diagnosis Module (Patch Segmentation → PointNet Encoder → Majority Voting → Class Probability) → Explanation Module (Superpoint Segmentation → Point Perturbation → Surrogate Training → Attribution Map)

- **Critical path**: The Point Cloud Representation (choosing the correct z attribute) dictates the quality of the Diagnosis Module, which in turn provides the probability distribution required to train the Explanation Module.

- **Design tradeoffs**: Window Size (w) - larger windows capture global shape but may dilute local tremors; Surrogate Complexity - Linear models are highly interpretable but may miss non-linear relationships; Perturbation Strategy - collapsing points removes spatial info but leaves temporal info implicit.

- **Failure signatures**: Low Specificity (detects PD but fails to distinguish HC) → likely due to imbalanced patch voting; Inconsistent Explanations (high PC but low DA) → surrogate mimics probability but gets "direction" wrong; Attribute Collapse (w/o Height performs similarly to w/ Height) → selected height feature carries no diagnostic signal.

- **First 3 experiments**: 1) Attribute Ablation: Run diagnosis using only (x,y) vs. (x,y,z) to verify 3D representation gain; 2) Faithfulness Stress Test: Mask top 3 superpoints with high positive attribution and measure probability drop; 3) Surrogate Benchmark: Compare Linear Regressor vs. XGBoost on Category Alignment (CA).

## Open Questions the Paper Calls Out

- **Unsupervised clustering for symptom patterns**: Can unsupervised clustering effectively identify typical hand-drawn patterns within the attribution-highlighted regions that correspond to specific clinical Parkinson's Disease symptoms? While the method identifies where anomalies are, it doesn't classify what those anomalies represent in clinical terms.

- **Automatic feature selection**: How can the optimal hand-drawn feature (e.g., radius, pressure, velocity) for the point cloud's height attribute be automatically determined or adapted for a given dataset? The paper relies on manual ablation studies to pick the best feature for each dataset.

- **Clinical utility validation**: Does the provision of PointExplainer's attribution maps improve the diagnostic accuracy or confidence of clinicians in a real-world decision-making environment? Quantitative metrics verify internal logic but don't verify that explanations are cognitively useful to human experts.

## Limitations

- The faithfulness validation of explanations relies on the same data used for surrogate training, creating potential overfitting concerns
- The choice of superpoint segmentation method (Ms=11 fixed segments) is not fully specified and could significantly impact results
- Claims about clinical interpretability and utility are largely untested beyond the consistency metrics presented

## Confidence

- **High confidence**: The 3D point cloud encoding mechanism and patch-based diagnosis approach are well-grounded in the literature and technically sound
- **Medium confidence**: The perturbation-based explanation method is theoretically valid, but faithfulness metrics need external validation on held-out data
- **Low confidence**: Claims about clinical interpretability and utility are largely untested beyond the consistency metrics presented

## Next Checks

1. **External faithfulness validation**: Evaluate CA, AC, DA metrics on a completely held-out test set not used for surrogate training to rule out overfitting

2. **Baseline ablation study**: Compare PointExplainer against a simpler 2D image-based approach (e.g., CNN on rendered spirals) to quantify the true benefit of 3D point cloud representation

3. **Clinical expert review**: Have movement disorder specialists examine the attribution maps on real patient data to assess whether identified regions align with known PD motor patterns and provide actionable insights