---
ver: rpa2
title: Optimal Robust Recourse with $L^p$-Bounded Model Change
arxiv_id: '2509.21293'
source_url: https://arxiv.org/abs/2509.21293
tags:
- recourse
- validity
- dataset
- cost
- implementation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of computing optimal robust algorithmic\
  \ recourse when models may change. The authors develop a new algorithm that computes\
  \ optimal recourse under Lp-bounded model changes (p\u22651, p\u2260\u221E) for\
  \ generalized linear models."
---

# Optimal Robust Recourse with $L^p$-Bounded Model Change

## Quick Facts
- arXiv ID: 2509.21293
- Source URL: https://arxiv.org/abs/2509.21293
- Reference count: 40
- Key result: First provably optimal algorithm for computing robust recourse under Lp-bounded model changes (p≠∞) for generalized linear models, achieving up to several orders of magnitude lower recourse prices than prior work

## Executive Summary
This paper addresses the fundamental challenge of computing optimal algorithmic recourse when machine learning models may change over time. The authors develop a new algorithm that computes optimal recourse under Lp-bounded model changes (p≥1, p≠∞) for generalized linear models by solving O(d) convex optimization problems instead of the original non-convex problem. The key insight is that optimal adversarial models differ from the initial model in exactly one dimension by exactly α, allowing decomposition into tractable subproblems. Experiments on real-world datasets demonstrate significantly lower recourse prices (up to several orders of magnitude) compared to prior work, better trade-offs between implementation cost and validity, and more sparse recourses while remaining resilient to post-processing for feasibility.

## Method Summary
The paper proposes computing optimal robust recourse by solving min_x max_θ J(x,θ) where J(x,θ) = ℓ(f_θ(x),1) + λ||x-x₀||₁. For Lp norms (p≠∞), the algorithm leverages the theoretical result that optimal adversarial models θ*(x) lie in the discrete set Θ±(θ₀), allowing decomposition into 2d convex subproblems. Each subproblem is solved via projected subgradient descent with linear constraints ensuring the correct dimension is selected. For non-linear models, local linear approximation via LIME or SmoothGrad is used. The approach is compared against ROAR and RBR baselines on German Credit and SBA datasets with logistic regression and neural network models.

## Key Results
- Algorithm 1 achieves 2-3 orders of magnitude lower recourse prices than ROAR and RBR across all α and λ combinations on German Credit dataset
- For German Credit (linear models), Algorithm 1 achieves instance-wise validity of 0.99-1.00 vs. 0.76-0.97 for ROAR at similar implementation costs
- On SBA dataset with neural networks, Algorithm 1 maintains lower prices than baselines despite relying on local linear approximations
- The algorithm naturally produces sparser recourses (fewer feature changes) compared to baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The non-convex robust recourse problem can be solved optimally by decomposing it into O(d) convex subproblems.
- Mechanism: For Lp norms (p≠∞), the optimal adversarial model θ*(x) always lies in the discrete set Θ±(θ₀)—models that differ from θ₀ by exactly ±α in a single dimension. By enumerating these 2d candidates and solving a constrained convex optimization for each, the algorithm finds the global optimum without directly solving the non-convex min-max problem.
- Core assumption: The model is a generalized linear model (GLM), where f_θ(x) = g(θ⊤x) with g non-decreasing.
- Evidence anchors: [abstract] "The key idea is to solve O(d) convex subproblems instead of the original non-convex problem." [section 4] "θ*(x) ∈ Θ±(θ₀) for all x, meaning that it suffices to narrow down the choice of optimal adversarial models to Θ±(θ₀)."

### Mechanism 2
- Claim: For each candidate adversarial model θ', the constrained optimization in Equation (6) is convex and solvable via projected subgradient descent.
- Mechanism: The objective J(x, θ') = ℓ(f_θ'(x), 1) + λc(x, x₀) is convex because ℓ is convex, f_θ' is linear (for GLMs), and c is convex. The constraint "θ' ∈ θ*(x)" translates to linear constraints: |x_i| ≥ |x_j| for all j, ensuring the chosen dimension i is where |x| is maximized.
- Core assumption: The loss function ℓ is convex and differentiable; the cost function c is convex (L1 norm used).
- Evidence anchors: [section 4] "The objective in Equation 6 is convex... though this optimization problem is not differentiable at all points due to the non-differentiability of the cost function c."

### Mechanism 3
- Claim: Local linear approximation extends the algorithm to non-linear models with empirical but not theoretical guarantees.
- Mechanism: For neural networks, LIME or SmoothGrad computes a local surrogate linear model θ around x₀. Algorithm 1/2 then operates on this approximation. Empirical results show the approach remains effective, though optimality guarantees no longer hold.
- Core assumption: The non-linear model is locally well-approximated by a linear function near x₀.
- Evidence anchors: [section 4] "For non-linear models, both algorithms first approximate the non-linear model locally... with a linear model." [section 5.1, Table 2] Algorithm 1 achieves lowest price for neural networks across all α, λ combinations.

## Foundational Learning

- Concept: **Convex Optimization with Linear Constraints**
  - Why needed here: Each subproblem in Algorithm 1 requires solving a convex problem subject to linear constraints (|x_i| ≥ |x_j|). Understanding projected subgradient descent is essential for implementation.
  - Quick check question: Given a convex objective f(x) and constraint set {x : Ax ≤ b}, how does projected gradient descent ensure feasibility at each iteration?

- Concept: **Generalized Linear Models (GLMs)**
  - Why needed here: Theoretical optimality guarantees only hold for GLMs. Understanding why the adversarial model for a GLM must lie in Θ±(θ₀) is crucial for grasping the mechanism.
  - Quick check question: For a logistic regression model f_θ(x) = σ(θ⊤x), why does the worst-case model under Lp-bounded perturbation focus on the dimension where |x[i]| is largest?

- Concept: **Min-Max Robust Optimization**
  - Why needed here: The robust recourse problem is formulated as min_x max_θ J(x,θ). Understanding how this differs from standard optimization and why it's non-convex is foundational.
  - Quick check question: Why is min_x max_θ J(x,θ) generally non-convex even when J(x,θ) is convex in x for fixed θ?

## Architecture Onboarding

- Component map: Input -> Linearization -> Adversarial Candidate Generator -> Convex Subproblem Solver -> Selection -> Post-Processing
- Critical path: 1. Linearize model at x₀ if non-linear (LIME/SmoothGrad) 2. Generate 2d adversarial candidates Θ±(θ₀) 3. For each candidate θ': solve constrained convex optimization (dominant computational cost) 4. Select recourse with minimum worst-case price 5. Apply feasibility post-processing if needed
- Design tradeoffs:
  - p=1 vs. p=∞: p=1 (Algorithm 1) achieves lower recourse prices but requires O(d) convex subproblems; p=∞ (Algorithm 2) uses greedy coordinate descent, faster but higher prices
  - Sparsity vs. Validity: Lower λ reduces implementation cost but may compromise validity; the algorithm naturally produces sparse solutions without explicit regularization
  - Theoretical vs. Empirical Optimality: GLMs guarantee optimality; neural networks rely on approximation quality
  - Runtime vs. Optimality: Algorithm 1 takes 188.4s vs. Algorithm 2's 0.0001s for German Credit (Table 1 context), but prices can differ by orders of magnitude
- Failure signatures:
  - High-dimensional data (d >> 1000): Algorithm 1's O(d) subproblems become computationally prohibitive. Consider dimensionality reduction or approximate methods
  - Large α values: Linear approximations for non-linear models degrade; recourse may become infeasible or prices explode
  - Categorical features without post-processing: Recourse may assign invalid intermediate values (e.g., 0.5 for binary feature); always apply hardmax projection
  - Non-convex loss functions: Projected subgradient descent may not converge to global optimum; theoretical guarantees void
- First 3 experiments:
  1. Reproduce Table 1 (Linear Models): Implement Algorithm 1 and ROAR baseline on German Credit dataset with logistic regression. Compare recourse prices across α ∈ {0.1, 0.5} and λ ∈ {0.01, 0.1}.
  2. Ablation on Linearization Methods: For neural network models on Small Business dataset, compare LIME vs. SmoothGrad linearization (replicate Tables 2 vs. Table 3 in appendix).
  3. Feasibility Post-Processing Impact: On German Credit, apply hardmax post-processing to categorical features and measure the degradation in instance-wise validity vs. implementation cost frontier (replicate Figure 4).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed algorithm be extended to handle hard feasibility constraints (e.g., immutability or actionability) while maintaining provable optimality?
- Basis in paper: [explicit] The authors state, "extending our algorithm to guarantee optimality in the presence of these constraints is left as future work."
- Why unresolved: The current method relies on post-processing (e.g., projection) to handle feasibility, which invalidates the optimality guarantees of the unconstrained solution.
- What evidence would resolve it: An extension of Theorem 1 that incorporates linear or non-linear constraints into the convex subproblems without requiring post-hoc projection.

### Open Question 2
- Question: How can the framework be adapted to support cost functions that capture feature dependencies rather than relying on separable $L^p$ norms?
- Basis in paper: [explicit] The conclusion notes that using $L^p$ norms "does not allow for capturing feature dependencies present in many applications" and identifies this as an area for future work.
- Why unresolved: The algorithm's efficiency relies on decomposing the problem into $O(d)$ subproblems, an approach that may not hold for complex, non-separable cost functions.
- What evidence would resolve it: An optimal algorithm for robust recourse using graph-based or causal cost metrics that runs in polynomial time.

### Open Question 3
- Question: Can distributionally robust optimization frameworks further reduce the price of recourse compared to the adversarial $L^p$-bounded approach?
- Basis in paper: [explicit] The authors suggest "studying alternative robustness frameworks such as distributionally robust optimization... to further lower the price of recourse."
- Why unresolved: The current adversarial framework assumes a worst-case model shift within a ball, which may be overly conservative compared to shifts defined by distributional uncertainty.
- What evidence would resolve it: A theoretical comparison showing distributionally robust recourses achieve lower implementation costs for the same level of validity under realistic model shift scenarios.

## Limitations

- The theoretical optimality guarantees only apply to generalized linear models, limiting practical applicability to real-world non-linear models
- The algorithm's O(d) complexity for Algorithm 1 becomes prohibitive for high-dimensional problems (d >> 1000)
- The approach relies on local linear approximation for non-linear models, with no theoretical guarantees on approximation quality

## Confidence

- **High Confidence**: The decomposition into O(d) convex subproblems for p≠∞ is mathematically sound and the resulting algorithm correctly implements this decomposition. The experimental results demonstrating lower recourse prices vs. baselines are reproducible.
- **Medium Confidence**: The optimality proof for GLMs is rigorous, but its practical impact is limited since most real-world models are non-linear. The empirical results for neural networks show the approach works in practice but without theoretical guarantees.
- **Low Confidence**: The runtime complexity claims (O(d) convex problems vs. O(d) iterations) need more careful analysis for large-scale problems. The impact of post-processing on the validity-cost tradeoff frontier is shown but not theoretically characterized.

## Next Checks

1. **Scalability Test**: Implement Algorithm 1 on synthetic datasets with varying dimensionality (d=100, 1000, 10000) and measure runtime scaling to verify O(d) complexity empirically.
2. **Approximation Quality**: For neural network models, systematically compare LIME vs. SmoothGrad linearization quality by measuring the approximation error ||f_θ(x) - g(θ⊤x)|| across different neighborhoods of x₀.
3. **Optimality Gap Analysis**: Construct synthetic GLMs where the ground truth optimal recourse is computable, then compare Algorithm 1's output to this oracle to measure the empirical optimality gap.