---
ver: rpa2
title: LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors
arxiv_id: '2512.21404'
source_url: https://arxiv.org/abs/2512.21404
tags:
- malware
- adversarial
- android
- detection
- lamlad
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LAMLAD, a novel adversarial attack framework
  that exploits the generative and reasoning capabilities of Large Language Models
  (LLMs) to bypass ML-based Android malware classifiers. LAMLAD employs a dual-agent
  architecture composed of an LLM manipulator, which generates realistic and functionality-preserving
  feature perturbations, and an LLM analyzer, which guides the perturbation process
  toward successful evasion.
---

# LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors

## Quick Facts
- arXiv ID: 2512.21404
- Source URL: https://arxiv.org/abs/2512.21404
- Authors: Tianwei Lan; Farid NaÃ¯t-Abdesselam
- Reference count: 40
- Primary result: LAMLAD achieves 97% attack success rate against Android malware classifiers

## Executive Summary
This paper introduces LAMLAD, a novel adversarial attack framework that leverages Large Language Models to bypass Android malware classifiers. The framework uses a dual-agent architecture with an LLM manipulator generating realistic feature perturbations and an LLM analyzer guiding the evasion process. By integrating retrieval-augmented generation, LAMLAD achieves high attack success rates while maintaining functionality preservation and stealth.

The framework demonstrates significant effectiveness against Drebin-style feature representations, achieving a 97% attack success rate with an average of only three attempts per adversarial sample. The paper also proposes an adversarial training-based defense strategy that reduces attack success rates by more than 30%, highlighting both the threat posed by LLM-driven attacks and potential mitigation approaches.

## Method Summary
LAMLAD employs a dual-agent architecture consisting of an LLM manipulator and an LLM analyzer. The manipulator generates feature perturbations that preserve app functionality while evading detection, while the analyzer guides the perturbation process toward successful evasion. The framework integrates retrieval-augmented generation to improve efficiency and contextual awareness. Focusing on Drebin-style feature representations, LAMLAD generates stealthy, high-confidence attacks against Android malware detection systems. The paper also introduces an adversarial training defense strategy to enhance model robustness against such attacks.

## Key Results
- LAMLAD achieves a 97% attack success rate against Android malware classifiers
- Average of only three attempts required per adversarial sample
- Adversarial training defense reduces ASR by more than 30% on average

## Why This Works (Mechanism)
LAMLAD exploits the generative and reasoning capabilities of LLMs to create sophisticated adversarial examples. The dual-agent architecture allows for both creative perturbation generation and strategic guidance toward evasion. The LLM manipulator can understand semantic relationships between features and generate contextually appropriate modifications that preserve functionality while avoiding detection. The analyzer component provides iterative feedback, refining attacks based on detection outcomes. Retrieval-augmented generation enhances the system's ability to draw from relevant knowledge bases, making attacks more efficient and effective against specific detection mechanisms.

## Foundational Learning

### LLM-based Adversarial Attacks
- Why needed: Traditional gradient-based attacks struggle with discrete feature spaces and require white-box access
- Quick check: Can LLMs generate meaningful perturbations in discrete feature spaces?

### Dual-Agent Architecture
- Why needed: Separating generation from strategic guidance improves attack efficiency and success rates
- Quick check: Does the analyzer significantly improve attack success compared to pure generation?

### Retrieval-Augmented Generation
- Why needed: Context-specific knowledge improves attack relevance and effectiveness
- Quick check: How much does RAG improve attack success rates versus standard prompting?

### Feature-Level Manipulation
- Why needed: Android malware detectors often use feature-based representations that require discrete modifications
- Quick check: Can generated perturbations maintain semantic equivalence to original features?

## Architecture Onboarding

### Component Map
LLM Analyzer -> LLM Manipulator -> Feature Perturbation Engine -> Detection System

### Critical Path
1. Initial feature analysis by LLM analyzer
2. Perturbation generation by LLM manipulator
3. Feature modification and testing
4. Feedback loop to analyzer for strategy refinement

### Design Tradeoffs
- LLM-based vs. traditional gradient attacks: Better handling of discrete features but higher computational cost
- Dual-agent vs. single-agent: Improved strategic guidance but increased complexity
- RAG integration: Enhanced contextual awareness but additional retrieval overhead

### Failure Signatures
- LLM generation failures resulting in invalid feature modifications
- Analyzer misjudging detection model's vulnerabilities
- Perturbations that break app functionality despite preservation attempts

### First 3 Experiments to Run
1. Baseline comparison: LAMLAD vs. traditional gradient-based attacks on same dataset
2. Ablation study: Dual-agent vs. single-agent performance metrics
3. Transferability test: Attacks generated for one model against different detection systems

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Experimental focus on Drebin-style features limits generalizability to other Android malware detection systems
- No thorough analysis of attack transferability to different models or feature representations
- Computational efficiency and resource requirements not fully explored

## Confidence

| Claim | Confidence |
|-------|------------|
| High attack success rate (97%) | Medium |
| Effectiveness of dual-agent architecture | Medium |
| Defense strategy reduces ASR by 30%+ | Medium |

## Next Checks

1. Evaluate LAMLAD's performance against a broader range of Android malware detection systems, including those using different feature representations and model architectures.

2. Conduct extensive transferability analysis to assess how well attacks crafted for one model generalize to others, including black-box scenarios.

3. Perform a detailed analysis of LAMLAD's computational requirements and runtime efficiency, comparing it to traditional adversarial attack methods.