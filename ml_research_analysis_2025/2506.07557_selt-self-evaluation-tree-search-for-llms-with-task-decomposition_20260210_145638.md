---
ver: rpa2
title: 'SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition'
arxiv_id: '2506.07557'
source_url: https://arxiv.org/abs/2506.07557
tags:
- tree
- reasoning
- search
- node
- selt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SELT introduces a Monte Carlo Tree Search (MCTS) framework that
  enhances large language model (LLM) reasoning by leveraging intrinsic self-evaluation
  without external reward models. It redefines the Upper Confidence Bound (UCT) scoring
  mechanism and decomposes reasoning into atomic subtasks augmented with semantic
  clustering to improve exploration-exploitation balance, reduce redundancy, and mitigate
  hallucination.
---

# SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition

## Quick Facts
- arXiv ID: 2506.07557
- Source URL: https://arxiv.org/abs/2506.07557
- Authors: Mengsong Wu; Di Zhang; Yuqiang Li; Dongzhan Zhou; Wenliang Chen
- Reference count: 10
- Primary result: Achieved 84.31% accuracy on MMLU college physics, outperforming Chain-of-Thought and standard MCTS baselines

## Executive Summary
SELT introduces a Monte Carlo Tree Search framework that enhances LLM reasoning through intrinsic self-evaluation without external reward models. The approach redefines UCT scoring and decomposes reasoning into atomic subtasks with semantic clustering to improve exploration-exploitation balance and reduce redundancy. On MMLU benchmarks, SELT achieved significant accuracy improvements over baselines, reaching 84.31% accuracy in college physics. The method demonstrates strong generalizability across domains without requiring task-specific fine-tuning.

## Method Summary
SELT implements a Monte Carlo Tree Search framework for LLM reasoning that leverages intrinsic self-evaluation mechanisms. The approach redefines the Upper Confidence Bound (UCT) scoring formula to better balance exploration and exploitation during tree search. Reasoning tasks are decomposed into atomic subtasks through semantic clustering, which helps reduce redundancy and improve search efficiency. The framework operates without external reward models, relying instead on the LLM's own evaluation capabilities to guide the search process and mitigate hallucination risks.

## Key Results
- MMLU benchmark: Achieved 84.31% accuracy on college physics, significantly outperforming Chain-of-Thought and standard MCTS baselines
- Seal-Tools benchmark: Reached 96.28% precision and 95.51% F1 score in single-tool scenarios
- No task-specific fine-tuning required, demonstrating strong generalizability across reasoning domains

## Why This Works (Mechanism)
SELT's effectiveness stems from three key innovations: first, the redefined UCT scoring mechanism that better balances exploration and exploitation in the search tree; second, semantic clustering-based task decomposition that reduces redundancy and focuses the search on semantically distinct subtasks; and third, intrinsic self-evaluation that eliminates dependency on external reward models while maintaining robust reasoning quality. The combination of these elements enables more efficient and accurate reasoning compared to traditional approaches.

## Foundational Learning
- Monte Carlo Tree Search (MCTS): A heuristic search algorithm that balances exploration and exploitation through tree-based search - needed for systematic reasoning exploration; quick check: verify tree depth and node expansion patterns
- Upper Confidence Bound (UCT): A formula for balancing exploration vs exploitation in tree search - needed to guide search toward promising reasoning paths; quick check: validate UCT parameter tuning
- Semantic Clustering: Grouping semantically similar concepts or tasks - needed for effective task decomposition; quick check: measure clustering coherence and task separation quality

## Architecture Onboarding
**Component Map**: Problem Task -> Semantic Decomposition -> MCTS Tree Construction -> Intrinsic Self-Evaluation -> UCT Scoring -> Tree Search -> Final Answer
**Critical Path**: Task Decomposition → MCTS Initialization → Tree Search Execution → Answer Generation
**Design Tradeoffs**: Semantic clustering vs. computational overhead; intrinsic evaluation vs. potential self-reinforcing errors; exploration depth vs. efficiency
**Failure Signatures**: Premature convergence to suboptimal paths; excessive tree depth causing inefficiency; semantic clustering producing incoherent subtasks
**First Experiments**: 1) Validate semantic clustering quality on simple reasoning tasks; 2) Test MCTS with baseline UCT scoring; 3) Compare intrinsic vs. external evaluation performance

## Open Questions the Paper Calls Out
None

## Limitations
- Semantic clustering may introduce bias in subtask selection, potentially limiting generalizability to domains with less structured semantic relationships
- Computational overhead of MCTS with semantic clustering is not fully characterized, raising scalability concerns
- Intrinsic self-evaluation may be vulnerable to self-reinforcing error patterns without external validation

## Confidence
- High confidence in core MCTS framework implementation and basic search mechanics
- Medium confidence in semantic clustering approach effectiveness due to limited ablation studies
- Medium confidence in domain generalizability based on validation primarily on two benchmark suites
- Low confidence in hallucination reduction claims without systematic measurement

## Next Checks
1. Conduct ablation studies comparing semantic clustering-based decomposition against alternative strategies (random, hierarchical, heuristic-based) to quantify semantic clustering's specific contribution
2. Perform systematic hallucination analysis using established detection metrics to verify claimed hallucination reduction in complex multi-step reasoning
3. Evaluate scalability and computational efficiency by testing on progressively larger reasoning tasks and measuring wall-clock time, memory usage, and performance trade-offs against simpler baselines