---
ver: rpa2
title: Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly
  Detection Filters
arxiv_id: '2510.26501'
source_url: https://arxiv.org/abs/2510.26501
tags:
- noise
- detection
- filter
- signals
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigated the use of lightweight Unsupervised Anomaly\
  \ Detection (UAD) filters to enhance the robustness of automated ECG classification\
  \ in resource-constrained environments. By benchmarking six UAD methods, including\
  \ Deep SVDD, reconstruction-based models, Masked Anomaly Detection, Normalizing\
  \ Flows, and Denoising Diffusion Probabilistic Models under strict parameter constraints\
  \ (\u2264512k), the research demonstrated that an optimized Deep SVDD filter effectively\
  \ identified Out-of-Distribution (OOD) cardiovascular disease classes and ECG signals\
  \ unsuitable for analysis due to noise."
---

# Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters

## Quick Facts
- arXiv ID: 2510.26501
- Source URL: https://arxiv.org/abs/2510.26501
- Authors: Mustafa Fuad Rifet Ibrahim; Maurice Meijer; Alexander Schlaefer; Peer Stelldinger
- Reference count: 29
- Primary result: Deep SVDD filter improves diagnostic accuracy by up to 21.0 percentage points in realistic deployment scenarios

## Executive Summary
This study demonstrates that lightweight Unsupervised Anomaly Detection (UAD) filters can significantly enhance the robustness of automated ECG classification in resource-constrained environments. By benchmarking six UAD methods under strict parameter constraints (≤512k), the research shows that an optimized Deep SVDD filter effectively identifies Out-of-Distribution (OOD) cardiovascular disease classes and ECG signals unsuitable for analysis due to noise. In a realistic deployment simulation incorporating unseen pathologies and calibrated ambulatory noise, the integrated classifier-filter system improved diagnostic accuracy by up to 21.0 percentage points over a classifier-only baseline.

## Method Summary
The research benchmarks six UAD methods—Deep SVDD, reconstruction-based models, Masked Anomaly Detection, Normalizing Flows, and Denoising Diffusion Probabilistic Models—on PTB-XL, BUT QDB, and MIT-BIH Noise Stress Test datasets. Deep SVDD maps normal ECG data into a compact hypersphere in latent space, using squared Euclidean distance from the center as the anomaly score. The filter is cascaded with a diagnostic classifier (resnet1d wang) and evaluated across four OOD scenarios where one cardiovascular disease superclass is held out during training. Performance is measured through AUC for detection and custom accuracy for the integrated system, with optimal rejection rates determined between 20-40%.

## Key Results
- Deep SVDD consistently achieves the best trade-off between detection performance and computational efficiency
- Integrated system improves diagnostic accuracy by up to 21.0 percentage points over classifier-only baseline
- Detection difficulty varies significantly: HYP/CD detection (AUC ~0.77-0.81) vs. STTC/MI detection (AUC ~0.65-0.69) due to clinical confounding
- All methods achieve high noise detection performance (AUC >0.95), but pathology detection is the bottleneck

## Why This Works (Mechanism)

### Mechanism 1
Mapping in-distribution ECG signals to a compact hypersphere enables detection of both unseen pathologies and severely noisy signals as out-of-distribution. Deep SVDD learns to project normal training data into a minimum-volume hypersphere in latent space. During inference, the squared Euclidean distance from the hypersphere center serves as the anomaly score—larger distances indicate greater deviation from learned normality. This single geometric constraint captures diverse anomaly types without requiring labeled examples. If novel pathologies or noise patterns produce latent representations within the learned hypersphere (e.g., due to shared morphological features with training data), the mechanism will fail to flag them.

### Mechanism 2
Clinical confounding between disease classes limits OOD detection performance when held-out pathologies share morphological features with in-distribution conditions. When STTC or MI is designated OOD, the training data still contains HYP and CD samples. These conditions produce secondary ST-segment and T-wave abnormalities that visually resemble the held-out class. The UAD model learns these shared features as part of its "normal" manifold, reducing detection sensitivity to truly OOD signals. If training data contains no morphologically similar conditions to the OOD class, detection performance will be substantially higher.

### Mechanism 3
Sequential filtering with an optimal rejection threshold (20-40%) maximizes system accuracy by balancing correct OOD rejection against false in-distribution rejection. The upstream filter assigns anomaly scores; a threshold determines the rejection boundary. Below the optimal threshold, the system correctly rejects OOD/noisy samples that the classifier would misclassify. Above it, the filter becomes overly aggressive, rejecting increasing proportions of valid in-distribution data that the classifier could process correctly. If the OOD prevalence in deployment differs significantly from the calibrated 16.5% noise injection rate, the optimal threshold will shift.

## Foundational Learning

- **Unsupervised Anomaly Detection (UAD) vs. Supervised OOD Detection**
  - Why needed here: The filter must detect anomalies never seen during training; supervised approaches require exhaustive labeling of all failure modes.
  - Quick check question: Can you explain why training on "normal" ECG signals alone enables detection of both unseen arrhythmias and motion artifacts?

- **Resource Constraints on Edge Deployment (Flash/SRAM/Parameters)**
  - Why needed here: The 512k parameter limit directly shapes architecture choices; understanding memory/compute budgets is essential for reproducing results.
  - Quick check question: Given a 2MB flash budget and 8-bit quantization, how many parameters can a model have while leaving headroom for firmware?

- **Reconstruction-Based vs. Embedding-Based Anomaly Detection**
  - Why needed here: The paper benchmarks six methods with fundamentally different failure modes; understanding why autoencoders "over-reconstruct" anomalies is critical for interpreting results.
  - Quick check question: Why might an autoencoder achieve low reconstruction error on an anomalous ECG, and how does Deep SVDD avoid this failure mode?

## Architecture Onboarding

- **Component map:**
  Raw ECG Input → Preprocessing (resample to 512 timesteps, normalize) → UAD Filter (Deep SVDD, anomaly score threshold) → [REJECT if score > threshold] → [PASS if score ≤ threshold] → Diagnostic Classifier (resnet1d wang, multilabel) → Prediction Output

- **Critical path:** The Deep SVDD filter inference runs on every input before the classifier. If rejected, classifier is never invoked—this is the energy-saving feature. The filter's anomaly score threshold is the single most impactful hyperparameter for deployment.

- **Design tradeoffs:**
  - Model size vs. AUC: Deep SVDD achieves strong performance with 12-128 initial filters and 3-layer architectures; larger models show diminishing returns
  - Rejection rate vs. accuracy: Higher thresholds improve robustness but reduce system utility; paper shows 20-40% optimal range
  - Detection task difficulty: HYP/CD detection (AUC ~0.77-0.81) vs. STTC/MI detection (AUC ~0.65-0.69) due to clinical confounding
  - Noise detection is trivial (AUC >0.95 for all methods); pathology detection is the bottleneck

- **Failure signatures:**
  - High false-positive rate on in-distribution data → threshold too aggressive for deployment OOD prevalence
  - Poor STTC/MI detection → training data contains confounding HYP/CD samples with similar morphology
  - Diffusion models underperform → standard Gaussian noise may not corrupt low-frequency ECG components
  - Autoencoders over-reconstruct anomalies → architectural bias toward generalization rather than anomaly preservation

- **First 3 experiments:**
  1. Reproduce Deep SVDD Pareto front on single OOD scenario: Train 3-5 Deep SVDD configurations (varying layers: 2-5, filters: 12-128) on PTB-XL with HYP held out. Plot AUC vs. parameter count. Verify performance plateau occurs before 512k limit.
  2. Calibrate rejection threshold on validation set with injected noise: Using best Deep SVDD config from experiment 1, inject MIT-BIH 'em' noise at 16.5% ratio into validation set. Sweep anomaly threshold to find peak custom accuracy. Confirm 20-40% rejection rate optimal range.
  3. Ablate noise-only vs. pathology-only OOD detection: Train classifier on 4-class PTB-XL (excluding MI). Test on: (a) clean MI samples only, (b) noisy in-distribution samples only, (c) combined. Measure classifier-only vs. integrated system accuracy to quantify relative contributions of each OOD type.

## Open Questions the Paper Calls Out

### Open Question 1
What are the real-world latency and energy consumption impacts when deploying these lightweight UAD filters on physical microcontrollers? The conclusion states future work will focus on "implementing the models on physical microcontrollers to measure real-world latency and power consumption." The current study validates efficiency based on parameter counts (≤512k) and theoretical suitability for MCUs, but lacks empirical data from physical hardware execution. On-device benchmarks (inference time, power draw) running the optimized Deep SVDD filter on target hardware (e.g., STM32U3) would resolve this.

### Open Question 2
Can incorporating multimodal data, such as accelerometer signals, effectively distinguish between motion artifacts and physiological anomalies? The authors propose "incorporating multimodal data (e.g. accelerometer data) to differentiate between motion artifacts and physiological anomalies." The current system treats all anomalous inputs identically (rejection), lacking the context to separate non-physiological noise from true cardiac pathologies. A study demonstrating distinct system responses (e.g., correcting vs. alerting) based on the correlation between ECG anomalies and accelerometer data would resolve this.

### Open Question 3
Can specific architectural modifications improve the OOD detection performance of Normalizing Flows and Diffusion models for ECG analysis? The paper suggests "exploring options to improve UAD performance by e.g. using high-level semantic representations for NFs or utilizing simplex noise for DDPMs." These methods underperformed compared to Deep SVDD (e.g., DDPM achieved only 0.518 AUC for MI detection), failing to capture global structural defects or effectively corrupt low-frequency ECG components. Benchmarks showing significantly improved AUC scores for NF and DDPM models on the PTB-XL OOD tasks after implementing the suggested modifications would resolve this.

## Limitations
- Clinical confounding between disease classes creates systematic detection failure for STTC/MI (AUC 0.65-0.69) versus HYP/CD (AUC 0.77-0.81), suggesting architectural solutions may not overcome fundamental morphological overlap in training data
- Training hyperparameter sensitivity remains unquantified—learning rate, batch size, and initialization method for Deep SVDD could significantly impact detection performance
- Real-world OOD prevalence differs from calibrated 16.5% noise injection rate; optimal rejection thresholds may shift substantially in deployment

## Confidence
- **High:** Deep SVDD achieves best trade-off between detection performance and computational efficiency under 512k parameter constraint
- **Medium:** Optimal rejection rate of 20-40% maximizes integrated system accuracy across OOD scenarios
- **Low:** Reconstruction-based methods (AE/VAE) consistently underperform due to anomaly generalization—may be architecture-dependent

## Next Checks
1. **Cross-dataset generalization:** Evaluate integrated system on MIMIC-IV ECG waveforms with unknown pathologies to test OOD detection beyond PTB-XL/BUT QDB distribution
2. **Dynamic threshold calibration:** Implement online threshold adjustment based on observed OOD prevalence to validate robustness across varying deployment conditions
3. **Morphological confounding ablation:** Train Deep SVDD with stratified sampling to minimize shared features between in-distribution and OOD classes, measuring impact on STTC/MI detection AUC