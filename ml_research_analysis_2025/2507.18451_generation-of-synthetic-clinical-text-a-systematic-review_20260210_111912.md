---
ver: rpa2
title: 'Generation of Synthetic Clinical Text: A Systematic Review'
arxiv_id: '2507.18451'
source_url: https://arxiv.org/abs/2507.18451
tags:
- text
- medical
- synthetic
- generation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review analyzed 94 studies on synthetic medical
  text generation to address challenges of data sparsity, privacy, and annotation
  burden in clinical NLP. The review found that synthetic text generation serves multiple
  purposes including privacy preservation, data augmentation, annotation support,
  corpus building, assistive writing, and usefulness evaluation.
---

# Generation of Synthetic Clinical Text: A Systematic Review

## Quick Facts
- arXiv ID: 2507.18451
- Source URL: https://arxiv.org/abs/2507.18451
- Reference count: 40
- Key outcome: Systematic review of 94 studies on synthetic medical text generation addressing data sparsity, privacy, and annotation burden in clinical NLP

## Executive Summary
This systematic review analyzed 94 studies on synthetic medical text generation to address challenges of data sparsity, privacy, and annotation burden in clinical NLP. The review found that synthetic text generation serves multiple purposes including privacy preservation, data augmentation, annotation support, corpus building, assistive writing, and usefulness evaluation. Transformer architectures, particularly GPT models, emerged as the dominant technique for generation. Evaluation methods spanned similarity (BLEU, ROUGE), privacy (PPL, DTP), structure (human assessment, AdvSuc), and utility (classification accuracy across tasks like NER, phenotype classification). While synthetic text showed promise for augmenting real data and improving downstream task performance, privacy concerns remained significant due to potential re-identification risks.

## Method Summary
The study conducted a systematic literature review using Boolean search strings across seven databases (PubMed, ScienceDirect, Web of Science, Scopus, IEEE, Google Scholar, arXiv) for articles published between 2015 and August 2024. Initial searches yielded 1,398 articles, which were reduced to 675 after removing duplicates and applying exclusion criteria (non-English, theses, non-open access). Full-text screening against specific exclusion lists (e.g., image generation, tabular data, non-medical chatbots) resulted in a final set of 94 articles meeting the three requirements: mechanism for generating unstructured free-text, stated purpose, and inference from EMR/EHR data types.

## Key Results
- Transformer architectures, particularly GPT models, emerged as the dominant technique for synthetic clinical text generation
- Synthetic text generation serves multiple purposes: privacy preservation, data augmentation, annotation support, corpus building, assistive writing, and usefulness evaluation
- Privacy concerns remained significant due to potential re-identification risks despite synthetic text's promise for improving downstream task performance

## Why This Works (Mechanism)

### Mechanism 1: Distributional Augmentation for Undersampling
Synthetic text improves downstream NLP performance primarily when used to augment real data for minority classes. Generative models (specifically GPTs) approximate the latent distribution of rare clinical events. By sampling from this learned distribution, they create new instances ($x_{synthetic}$) that preserve the label ($y$) of the minority class. This reduces class imbalance, allowing classifiers to learn more robust decision boundaries for rare diseases. The synthetic data introduces distribution shift or logical contradictions (e.g., mixing "hypertension" and "hypotension" in one record), which degrades classifier performance.

### Mechanism 2: Privacy via Statistical Generalization
Privacy preservation in synthetic text relies on the model generalizing patterns rather than memorizing specific training sequences, though this is probabilistic and prone to re-identification attacks. Models like DP-GPT inject noise (differential privacy) or rely on dropout to prevent the exact reconstruction of input sequences. The goal is to output text that is statistically similar to the corpus but structurally distinct from any single individual's record, minimizing membership inference risks. The model overfits on unique "triggering phrases" (e.g., "the accident was widely reported in the press") or rare sequences, causing it to output verbatim text that acts as a unique identifier.

### Mechanism 3: Conditional Contextualization via Attention
Transformer architectures (GPTs) outperform RNNs/LSTMs for clinical text generation because the self-attention mechanism captures long-range dependencies and complex medical context simultaneously. Unlike RNNs which process sequentially, Transformers use self-attention to weigh the relevance of all tokens in a context window (e.g., 512+ tokens) at once. This allows the model to maintain coherence in clinical narratives where context (e.g., a drug mentioned earlier) dictates later text (e.g., a specific side effect), improving "structure" and "fluency" scores. The context window is exceeded, or the model is a "vanilla" transformer trained on small data, leading to incoherence or hallucination.

## Foundational Learning

**N-grams and Perplexity (PPL)**
- Why needed: The review cites PPL and BLEU (N-gram based) as primary metrics. Understanding PPL is essential to diagnose if a model is "surprised" by clinical terminology.
- Quick check: If a generative model has high perplexity on a test set of discharge summaries, does it mean the text is more or less likely to contain valid medical terminology?

**Differential Privacy (DP) in NLP**
- Why needed: Privacy is a major constraint. Section 4.2 and 4.4 mention "DP-GPT" and "Privacy Budget."
- Quick check: Why does increasing the "Privacy Budget" (epsilon $\epsilon$) generally improve the utility (text quality) but lower the privacy guarantee?

**Auto-regressive Decoding (Temperature)**
- Why needed: The paper highlights GPT's ability to "modify its determinism through... temperature."
- Quick check: To generate diverse synthetic data for augmentation (avoiding mode collapse), should you set the temperature closer to 0 or > 1.0?

## Architecture Onboarding

**Component map:** Real Clinical Text -> Pre-processor (De-identification, Tokenizer) -> Generator (GPT-2/3, BioGPT, or SeqGAN) -> Evaluator (BLEU/PPL for quality; DTP/AdvSuc for privacy; Classifier for utility)

**Critical path:**
1. De-identify: Raw text must be scrubbed of PII before training to reduce the baseline risk of memorizing identities
2. Fine-tune Generator: Adapt a pre-trained Transformer (e.g., GPT-2) on the specific clinical domain using a validation set to tune Temperature
3. Privacy Audit: Use metrics like DTP or manual human assessment to check for "triggering phrases" before release

**Design tradeoffs:**
- Similarity vs. Privacy: Optimizing for high BLEU/ROUGE increases re-identification risk
- Utility vs. Diversity: High diversity can lead to lower coherence
- Pre-training vs. From-scratch: Medical-specific pre-trained models may lack "colloquial tone" but converge faster

**Failure signatures:**
- Verbatim Memorization: Generating exact sequences of rare medical events or names
- Mode Collapse (GANs): Generating the same generic text repeatedly
- Hallucination: Generating medically impossible relations (e.g., "Hepatitis C deficiency")

**First 3 experiments:**
1. Baseline Fidelity: Fine-tune a standard GPT-2 on a clean subset of clinical notes. Evaluate using BLEU and Perplexity to establish a baseline for "fluency."
2. Privacy Stress Test: Train two modelsâ€”one on raw data and one on de-identified data. Attempt to extract PII using membership inference attack or manual probing to measure the "Privacy Gap."
3. Utility Validation: Train a disease classifier using only real data vs. real + synthetic data. Verify if synthetic data improves F1-score on minority classes.

## Open Questions the Paper Calls Out

**Open Question 1:** How do different synthetic text generation techniques compare empirically regarding their pros and cons when applied to clinical NLP tasks?
- Basis: The Conclusion states, "For future direction, conducting an empirical comparison of the generation techniques would provide more comprehensive understanding of the pros and cons."
- Why unresolved: Current literature lacks unified evaluation metrics and relies on diverse datasets, making direct comparisons between architectures difficult.
- What evidence would resolve it: A standardized benchmarking study evaluating multiple generation models on identical datasets using consistent utility and privacy metrics.

**Open Question 2:** What mechanisms can effectively balance the trade-off between data utility (similarity) and privacy preservation in synthetic clinical text?
- Basis: Section 4.5 notes that "efforts toward boosting the similarity would lead to revealing unique medical components... which implies the need for a trade-off mechanism."
- Why unresolved: High similarity to original text often increases re-identification risks, yet low similarity reduces utility for downstream tasks.
- What evidence would resolve it: Development of a framework that maximizes downstream task performance while mathematically guaranteeing a specific privacy budget.

**Open Question 3:** To what extent can automated privacy metrics serve as reliable proxies for human assessment in identifying sensitive information leakage?
- Basis: While Section 4.5 states that "automatic privacy metrics... cannot give a full guarantee," it explicitly argues that "the need for human assessment during privacy evaluation is imperative."
- Why unresolved: It remains unclear if automated metrics like Perplexity (PPL) or DTP correlate strongly with the ability of human experts to detect re-identification risks.
- What evidence would resolve it: A correlation analysis comparing automated privacy scores against human expert evaluations of re-identification potential in the same generated corpus.

## Limitations
- Scope limited to free-text generation from EMR/EHR data, excluding tabular, imaging, and audio modalities
- Rapid evolution of LLMs may quickly make findings outdated
- Does not address computational costs of fine-tuning large models or regulatory implications

## Confidence

**High Confidence:** Transformer dominance in generation, utility of synthetic data for minority class augmentation, and privacy concerns regarding re-identification

**Medium Confidence:** The specific superiority of GPT models over RNNs for long-range dependencies (based on comparative studies)

**Low Confidence:** The generalizability of evaluation metrics across different clinical domains and languages

## Next Checks

1. Conduct a temporal analysis to assess how synthetic text generation techniques have evolved since 2023, particularly with the advent of GPT-4 and domain-specific models.

2. Design a controlled experiment comparing synthetic text generation for minority class augmentation against traditional data augmentation techniques (e.g., SMOTE, back-translation) in a clinical classification task.

3. Perform a systematic audit of publicly available synthetic clinical text datasets to assess their adherence to privacy-preserving guidelines and evaluate their utility across different clinical NLP tasks.