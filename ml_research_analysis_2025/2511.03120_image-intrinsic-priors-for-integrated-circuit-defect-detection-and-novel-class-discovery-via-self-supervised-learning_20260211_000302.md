---
ver: rpa2
title: Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class
  Discovery via Self-Supervised Learning
arxiv_id: '2511.03120'
source_url: https://arxiv.org/abs/2511.03120
tags:
- defect
- normal
- detection
- defects
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles integrated circuit (IC) defect detection and
  novel class discovery in semiconductor manufacturing, where defects are rare, diverse,
  and continually evolving. The proposed method, IC-DefectNCD, addresses these challenges
  by leveraging single-image intrinsic priors rather than relying on support sets,
  enabling robust detection and classification of unseen defect categories.
---

# Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning

## Quick Facts
- arXiv ID: 2511.03120
- Source URL: https://arxiv.org/abs/2511.03120
- Reference count: 40
- Primary result: Image-level AUROC up to 99.19% and pixel-level AUROC up to 98.92% on real-world IC defect dataset

## Executive Summary
This paper addresses the challenging problem of integrated circuit defect detection and novel class discovery in semiconductor manufacturing. The proposed IC-DefectNCD method leverages single-image intrinsic priors rather than requiring support sets, enabling robust detection and classification of unseen defect categories. Through a three-stage pipeline combining self-normal information extraction, adaptive binarization, and self-supervised classification, the approach achieves state-of-the-art performance on a comprehensive real-world dataset spanning multiple fabrication stages.

## Method Summary
The method employs a three-stage pipeline for IC defect detection and classification. Stage 1 uses a learnable normal-information extractor with a reconstruction decoder to identify defects through residual analysis. Stage 2 applies self-saliency-driven adaptive binarization with stability detection across 64 threshold levels to produce defect-centered crops. Stage 3 employs a soft-mask guided attention mechanism within a teacher-student self-supervised framework to classify defects while suppressing background interference. The approach operates on 448×448 pixel images and achieves real-time inference capability.

## Key Results
- Image-level AUROC up to 99.19% across three fabrication stages (BEOL, DEP, DPR)
- Pixel-level AUROC up to 98.92% for precise defect localization
- Classification F1 scores up to 0.9660 with accurate unknown class count estimation

## Why This Works (Mechanism)
The method succeeds by exploiting single-image intrinsic priors rather than relying on support sets or extensive labeled data. The self-normal information extraction captures normal appearance patterns within each image, enabling defect detection through reconstruction residuals. The stability-based adaptive thresholding ensures robust defect segmentation even with varying contrast levels. The soft-mask guided attention mechanism effectively focuses classification on defect regions while minimizing background interference, making the system robust to diverse defect morphologies.

## Foundational Learning
- Self-normal information extraction: Extracts normal appearance patterns from single images without external references; needed to establish baseline for defect detection through residuals
- Stability-based adaptive thresholding: Uses plateau detection across multiple thresholds to identify optimal binarization; needed for robust defect segmentation without manual parameter tuning
- Soft-mask guided attention: Modifies transformer attention with defect-specific bias; needed to focus classification on relevant regions while suppressing background

## Architecture Onboarding

**Component Map:**
NI-Extractor -> NIG-Decoder -> Residual Map -> Adaptive Binarization -> Defect Crops -> SMG-ViT -> Teacher-Student Training

**Critical Path:**
Input image → NI-Extractor (multi-scale features + 6 normal tokens) → NIG-Decoder (masked reconstruction) → Residual computation → Stability-based thresholding (64 sweeps) → Defect crop extraction → SMG-Attention (last j layers with soft-mask bias) → Teacher-student training → Semi-supervised k-means for class count

**Design Tradeoffs:**
- Single-image priors vs. support set requirements: Eliminates need for external references but may miss global defect patterns
- Pseudo-defect synthesis: Enables training without labeled defects but introduces domain gap risk
- Frozen DINOv2 backbone: Reduces training complexity but limits adaptation to domain-specific features

**Failure Signatures:**
- False positives: Occur when normal patterns deviate significantly from training distribution
- Missed defects: Happen with defects having low contrast or ambiguous boundaries
- Incorrect class estimation: Arises when labeled samples poorly represent known defect types

**3 First Experiments:**
1. Test NI-Extractor reconstruction quality on normal vs. defective samples
2. Validate stability plateau detection across different threshold ranges
3. Evaluate SMG-Attention focus quality by visualizing attention maps with and without soft-mask bias

## Open Questions the Paper Calls Out
None

## Limitations
- Pseudo-defect synthesis may introduce domain shift between synthetic and real defects
- Stability-based thresholding may fail for defects with ambiguous boundaries or varying contrast
- Soft-mask guided attention effectiveness depends heavily on accurate Stage 1 defect localization

## Confidence
**High Confidence Claims:**
- Three-stage pipeline architecture is technically sound
- DINOv2 backbone with frozen weights is a valid design choice
- Reported performance metrics are achievable with implementation

**Medium Confidence Claims:**
- Pseudo-defect synthesis effectively captures real defect characteristics
- Stability detection reliably identifies optimal binarization thresholds
- Self-supervised teacher-student training adequately handles unlabeled data

**Low Confidence Claims:**
- Robustness to unseen defect morphologies beyond studied classes
- Generalization across different semiconductor fabrication processes
- Real-time inference performance under varying hardware constraints

## Next Checks
1. Evaluate model on external IC defect dataset from different fabrication facility to assess domain generalization
2. Systematically vary pseudo-defect generation parameters and measure impact on detection/classification performance
3. Manually analyze failure cases of stability-based thresholding for defects with low contrast or ambiguous boundaries