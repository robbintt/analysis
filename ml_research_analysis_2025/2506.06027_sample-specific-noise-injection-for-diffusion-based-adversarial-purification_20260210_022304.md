---
ver: rpa2
title: Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification
arxiv_id: '2506.06027'
source_url: https://arxiv.org/abs/2506.06027
tags:
- noise
- adversarial
- score
- methods
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles a critical issue in diffusion-based adversarial
  purification: the need for sample-specific noise injection levels. Existing methods
  use a fixed noise level for all samples, which overlooks the fact that an optimal
  level varies by sample.'
---

# Sample-Specific Noise Injection For Diffusion-Based Adversarial Purification

## Quick Facts
- arXiv ID: 2506.06027
- Source URL: https://arxiv.org/abs/2506.06027
- Authors: Yuhao Sun; Jiacheng Zhang; Zesheng Ye; Chaowei Xiao; Feng Liu
- Reference count: 40
- Key outcome: SSNI improves DiffPure's clean accuracy by 3.58% and robust accuracy by 0.65% on CIFAR-10 against PGD+EOT attacks

## Executive Summary
This paper addresses a critical limitation in diffusion-based adversarial purification methods: the use of fixed noise levels for all samples. The authors propose Sample-Specific Noise Injection (SSNI), a framework that adaptively adjusts noise injection based on each sample's deviation from the clean data distribution. By leveraging score network estimations to measure sample-specific deviations, SSNI applies a reweighting function to determine optimal noise levels. The method demonstrates significant improvements in both clean and robust accuracy when integrated with existing DBP methods on CIFAR-10 and ImageNet-1K datasets.

## Method Summary
SSNI introduces a novel approach to diffusion-based adversarial purification by replacing fixed noise injection with sample-specific adjustments. The framework uses a pre-trained score network to estimate each sample's deviation from the clean data distribution, measured through score norms. A reweighting function then translates these deviation scores into appropriate noise levels for each sample. This adaptive approach allows the purification process to apply stronger noise to samples further from the clean distribution while using minimal noise for samples already close to the clean manifold. The method is designed to be compatible with existing DBP methods, enhancing their performance without requiring architectural changes to the underlying purification models.

## Key Results
- SSNI improves DiffPure's clean accuracy by 3.58% and robust accuracy by 0.65% on CIFAR-10 against PGD+EOT attacks
- The method demonstrates consistent improvements across both CIFAR-10 and ImageNet-1K datasets
- SSNI shows better performance than fixed noise injection baselines while maintaining compatibility with existing DBP methods

## Why This Works (Mechanism)
The effectiveness of SSNI stems from recognizing that adversarial samples have varying degrees of deviation from the clean data distribution. By using score norms to quantify this deviation, the method can apply noise more strategically - stronger noise for samples further from the clean manifold and weaker noise for those closer to it. This targeted approach prevents over-noising clean-like samples (which would degrade performance) while ensuring sufficient purification for heavily corrupted samples. The reweighting function translates the continuous deviation scores into discrete noise levels that can be practically implemented in the purification pipeline.

## Foundational Learning

**Score Networks**: Why needed - To estimate how far a sample deviates from the clean data distribution; Quick check - Verify the pre-trained score network achieves low reconstruction error on clean validation data

**Score Norms**: Why needed - To quantify the deviation of each sample from the clean manifold; Quick check - Plot score norm distributions for clean vs adversarial samples to confirm separation

**Diffusion-based Purification**: Why needed - Provides the foundation for iterative denoising that can remove adversarial perturbations; Quick check - Confirm the base DBP method achieves reasonable purification on a small set of adversarial examples

## Architecture Onboarding

Component Map: Input sample -> Score Network -> Score Norm Calculation -> Reweighting Function -> Noise Level Selection -> DBP Purification -> Output

Critical Path: The score network estimation and reweighting function form the critical path, as they must complete before noise injection can occur. The DBP purification itself follows as a parallel process that depends on the selected noise level.

Design Tradeoffs: The method trades increased computational overhead (score network inference and reweighting) for improved accuracy. Alternative designs could include using a lighter-weight score estimator or learning the reweighting function end-to-end with the DBP model.

Failure Signatures: Performance degradation occurs when the score network fails to accurately estimate deviations (false positives/negatives), when the reweighting function poorly maps scores to noise levels, or when the added computational overhead becomes prohibitive.

First Experiments:
1. Test SSNI on a small subset of CIFAR-10 with varying attack strengths to verify the correlation between score norms and purification difficulty
2. Compare fixed vs. sample-specific noise injection on a held-out validation set to establish baseline improvements
3. Perform ablation by removing the reweighting function to isolate its contribution to performance gains

## Open Questions the Paper Calls Out
None

## Limitations

- Computational overhead: The method adds processing time through score network estimation and reweighting, with no runtime analysis provided
- Limited attack evaluation: Effectiveness is demonstrated primarily against PGD+EOT attacks, with unclear generalization to other attack types
- Score network vulnerability: The method does not address potential vulnerabilities if the score network itself is attacked or manipulated

## Confidence

High confidence: The experimental results demonstrating improved clean and robust accuracy when SSNI is integrated with existing DBP methods are well-supported by the data provided.

Medium confidence: The claim that SSNI "consistently improves both clean and robust accuracy" across all experiments has some support but would benefit from additional ablation studies.

Low confidence: The assertion that the proposed method is "computationally efficient" is not well-supported by the paper, as no runtime comparisons or complexity analysis are provided.

## Next Checks

1. Conduct runtime analysis comparing the original DBP methods with their SSNI-enhanced versions to quantify the computational overhead introduced by the score network estimation and reweighting process.

2. Test SSNI's effectiveness against a broader range of adversarial attack types beyond PGD+EOT, including decision-based and score-based attacks, to validate its generalizability.

3. Perform ablation studies to determine the individual contributions of the score network and the reweighting function to the overall performance improvement, helping to identify which component is driving the gains.