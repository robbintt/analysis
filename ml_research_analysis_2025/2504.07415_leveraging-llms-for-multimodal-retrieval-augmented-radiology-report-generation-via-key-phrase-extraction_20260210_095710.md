---
ver: rpa2
title: Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report Generation
  via Key Phrase Extraction
arxiv_id: '2504.07415'
source_url: https://arxiv.org/abs/2504.07415
tags:
- report
- phrases
- findings
- right
- radiology
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a retrieval-augmented generation approach
  for automated radiology report generation that leverages large language models to
  extract key phrases and a multimodal retriever for text-image alignment. By using
  RadGraph and LLM-based key phrase extraction, the method avoids hallucinations from
  comparative language while maintaining clinical accuracy.
---

# Leveraging LLMs for Multimodal Retrieval-Augmented Radiology Report Generation via Key Phrase Extraction

## Quick Facts
- arXiv ID: 2504.07415
- Source URL: https://arxiv.org/abs/2504.07415
- Reference count: 40
- Primary result: Achieves state-of-the-art CheXbert scores and competitive RadGraph F1 metrics on MIMIC-CXR without LLM fine-tuning

## Executive Summary
This paper introduces a retrieval-augmented generation approach for automated radiology report generation that leverages large language models to extract key phrases and a multimodal retriever for text-image alignment. By using RadGraph and LLM-based key phrase extraction, the method avoids hallucinations from comparative language while maintaining clinical accuracy. The multimodal retriever combines complementary vision encoders and incorporates contrastive learning and noise injection for improved alignment. Evaluated on the MIMIC-CXR dataset, the approach achieves state-of-the-art CheXbert scores and competitive RadGraph F1 metrics compared to fine-tuned multimodal LLMs, without requiring any LLM fine-tuning. The method also generalizes well to multi-view report generation.

## Method Summary
The approach extracts key phrases from radiology reports using RadGraph entity-relation extraction followed by LLM refinement (Llama 70B) to remove hallucination-prone comparative language. A multimodal retriever trained with complementary vision encoders (XrayDINOv2 + XrayCLIP) predicts semantic embeddings that retrieve the most relevant key phrases from a vector database. At inference, GPT-4o generates reports from the retrieved phrases. The method avoids LLM fine-tuning while achieving state-of-the-art clinical efficacy through careful key phrase extraction and multimodal retrieval alignment.

## Key Results
- Achieves best performance on CheXbert Micro/Macro F1 scores compared to baseline methods
- Outperforms fine-tuned multimodal LLMs on clinical efficacy metrics while maintaining competitive RadGraph F1 scores
- Demonstrates effective generalization to multi-view report generation scenarios
- Shows significant reduction in hallucinated comparative language compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1: LLM-Based Key Phrase Extraction Filters Hallucination-Prone Content
- Claim: Extracting fine-grained key phrases with an LLM, rather than using full sentences or raw RadGraph outputs, reduces hallucinations from comparative language while preserving clinical entities.
- Mechanism: RadGraph extracts entities and relations from the FINDINGS section; rule-based graph construction produces "RadGraph phrases." An LLM (Llama 70B) then refines these into clinically meaningful key phrases, explicitly removing comparative expressions ("unchanged," "improved," "worsened") that cannot be verified from a single image.
- Core assumption: Comparative language in retrieved text is a primary source of hallucinations in single-view RRG, and general-domain LLMs can reliably identify and filter such phrases when given both the original report and RadGraph output as context.
- Evidence anchors:
  - [abstract] "By using RadGraph and LLM-based key phrase extraction, the method avoids hallucinations from comparative language while maintaining clinical accuracy."
  - [section 3.1] "In single-image report generation, words like 'increased' or 'unchanged' are also considered such terms... we incorporate an LLM trained on massive datasets, including medical knowledge, we can interpret reports and segment them into meaningful key phrases while filtering out hallucination-prone words associated with comparisons."
  - [corpus] Related work "CCD: Mitigating Hallucinations in Radiology MLLMs" addresses hallucinations but via contrastive decoding, suggesting hallucination mitigation is a recognized challenge. No direct corpus evidence validates the specific comparative-language filtering mechanism.
- Break condition: If the LLM systematically removes clinically relevant temporal information (e.g., "progressed" in a valid multi-study context) or if RadGraph extraction fails on report formats with non-standard structure, the key phrase extraction would lose critical diagnostic content.

### Mechanism 2: Complementary Vision Encoder Fusion Improves Semantic Alignment
- Claim: Fusing features from vision encoders with different pretraining paradigms (CLIP-style vision-language vs. DINOv2 self-supervised) yields better semantic embeddings for retrieval than either encoder alone.
- Mechanism: Visual tokens from XrayDINOv2 (self-supervised) and XrayCLIP (vision-language) are reshaped to 2D, aligned via interpolation, and concatenated channel-wise. This unified representation feeds the DETR decoder for semantic embedding prediction.
- Core assumption: Self-supervised encoders capture anatomical structure while vision-language encoders capture semantic concepts; their combination provides complementary signals for text-image alignment.
- Evidence anchors:
  - [section 3.2.1] "Since these image encoders have complementary advantages due to their distinct training approaches, we fuse the output features from various vision encoders rather than selecting a single encoder."
  - [section 5.3, Table 3] E3 (XrayDINOv2 alone): MF1-14=41.2; E5 (XrayCLIP alone): MF1-14=41.0; E7 (combined): MF1-14=42.0—showing improvement over individual encoders.
  - [corpus] Weak evidence—neighbor papers do not directly address multi-encoder fusion for medical retrieval.
- Break condition: If encoder outputs are misaligned spatially after interpolation, or if one encoder's features dominate due to scale differences, the fusion may degrade rather than improve alignment.

### Mechanism 3: Noise Injection on Frozen Text Embeddings Prevents Overfitting
- Claim: Adding uniform noise to frozen text embeddings during training improves generalization by preventing the retriever from overfitting to fixed targets.
- Mechanism: Text embeddings from the frozen MPNet encoder receive noise ε ~ Uniform(-1/√d, 1/√d) during training (inspired by NEFTune). This effectively augments the target space for the semantic embedding prediction task.
- Core assumption: Frozen text embeddings create fixed targets that lead to memorization; small perturbations regularize the alignment objective.
- Evidence anchors:
  - [section 3.2.1] "Since we keep the text encoder frozen during training... the text embeddings for a training image remain fixed, which can result in overfitting. Inspired by NEFTune... we also apply random noise to the text embeddings only during training."
  - [section 5.3, Table 3] E8 (no noise, with contrastive loss): MF1-14=41.7; E9 (noise only): MF1-14=42.5; E10 (both): MF1-14=42.3—noise injection shows improvement.
  - [corpus] No corpus validation for this specific noise injection technique in medical retrieval.
- Break condition: If noise magnitude is too large relative to embedding scale, the retriever may learn to match noisy targets that diverge from true semantic content, degrading retrieval precision.

## Foundational Learning

- Concept: **DETR Set Prediction with Hungarian Matching**
  - Why needed here: The retriever predicts a fixed set of N=50 semantic embeddings, which must be matched to a variable number of ground-truth key phrases. The Hungarian algorithm finds optimal bipartite matching for loss computation.
  - Quick check question: Given 3 ground-truth key phrases and N=50 predictions, how does the matching cost account for empty (∅) predictions?

- Concept: **Contrastive Learning (CLIP-style) for Cross-Modal Alignment**
  - Why needed here: In-batch semantic contrastive loss (LSC) pulls matched text-semantic embedding pairs closer while pushing non-matched pairs apart, complementing the pairwise similarity loss in TranSQ.
  - Quick check question: Why does the paper use similarity-based targets rather than treating all non-matched embeddings as hard negatives?

- Concept: **RadGraph Entity-Relation Extraction**
  - Why needed here: RadGraph extracts clinical entities (OBS-DA, OBS-DP, OBS-U) and relations ("located_at," "suggestive_of," "modify"), which form the structured basis for key phrase extraction.
  - Quick check question: How does the rule-based graph construction handle fragmented graphs that should be connected?

## Architecture Onboarding

- Component map:
  - **Offline Pipeline**: Raw reports → RadGraph → Rule-based phrases → LLM (Llama 70B) → Key phrases → Text encoder → Vector DB
  - **Retriever Training**: Image → Vision encoders (XrayDINOv2 + XrayCLIP) → Channel concat → DETR decoder → Semantic embeddings → Match to noisy text embeddings → Loss (TranSQ + contrastive)
  - **Inference**: Image → Trained retriever → Top-k semantic embeddings (threshold ≥ 0.4) → Retrieve key phrases from vector DB → LLM (GPT-4o) → Generated report

- Critical path:
  1. Key phrase extraction quality directly bounds retriever training (garbage in, garbage out).
  2. Semantic embedding threshold (0.4) controls precision/recall tradeoff for retrieval.
  3. LLM prompt design determines how retrieved phrases are synthesized into coherent reports.

- Design tradeoffs:
  - **Extraction granularity**: Sentences (E1) yield better NLG scores but worse clinical efficacy; key phrases (E3) improve CheXbert/RadGraph F1 at lexical overlap cost.
  - **Encoder selection**: BiomedCLIP (E6) underperforms XrayCLIP (E5), suggesting domain-specific pretraining matters more than general biomedical pretraining.
  - **LLM choice**: Llama 70B vs. GPT-4o shows minimal difference for final report generation (E11 vs. E12), suggesting retrieval quality dominates.

- Failure signatures:
  - Hallucinated comparative language ("unchanged," "stable") indicates key phrase extraction failed to filter.
  - Low CheXbert MF1-14 but high NLG scores suggests retrieval captures style but misses clinical entities.
  - Large performance drop on held-out data (MF1-14: 41.7 on MIMIC-CXR → 26.6 on IU X-Ray) indicates domain overfitting.

- First 3 experiments:
  1. **Baseline retrieval without LLM extraction**: Compare E1 (sentences) vs. E3 (key phrases) on CheXbert MF1-14 and RadGraph F1 to validate the extraction mechanism.
  2. **Encoder ablation**: Run E3, E5, E7 to isolate individual encoder contributions vs. fusion benefit on the validation set.
  3. **Threshold sweep**: Vary semantic embedding retrieval threshold (0.3–0.5) and plot retrieved phrase count vs. CheXbert eF1 to find the optimal operating point (Figure 5 shows 0.4 maximizes eF1).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does retrieval-augmented generation (RAG) improve clinical utility and factual consistency compared to fine-tuned MLLMs when evaluated directly by radiologists?
- Basis in paper: [explicit] The Conclusion states, "Future work could include human evaluations of reports generated by the RAG system and an exploration of further applications of this method in the medical domain."
- Why unresolved: The study relies on automated metrics (CheXbert, RadGraph F1) which may not fully capture the subtle clinical nuances or "soft" hallucinations that a human expert would catch.
- What evidence would resolve it: A clinical reader study where board-certified radiologists rate the accuracy, coherence, and helpfulness of reports generated by RA-RRG versus fine-tuned MLLMs.

### Open Question 2
- Question: How can the generalization capability of RA-RRG be improved to maintain performance on held-out external datasets?
- Basis in paper: [inferred] Appendix B notes a sharp performance drop on the IU X-Ray dataset (MF1-14 dropped from 41.7 on MIMIC to 26.6 on IU X-Ray), stating this "warrants further research."
- Why unresolved: The retrieval mechanism depends heavily on the distribution of the training database (MIMIC-CXR), causing performance degradation when stylistic or distributional shifts occur in external data.
- What evidence would resolve it: Experiments implementing domain adaptation techniques or evaluating the model on a more diverse, multi-institutional test set to test robustness.

### Open Question 3
- Question: Would utilizing medical-domain-specific LLMs for the key phrase extraction step significantly improve the quality of retrieval targets compared to general-domain models?
- Basis in paper: [inferred] Section 3.1 mentions that general-domain LLMs are used because they are "not specifically tailored for the medical domain," which necessitates the addition of RadGraph outputs to prevent omission of essential information.
- Why unresolved: It remains unclear if the current two-stage extraction (RadGraph + General LLM) is optimal, or if a single medical-specialized LLM could extract cleaner, more accurate phrases without rule-based assistance.
- What evidence would resolve it: An ablation study comparing the quality of key phrases extracted by general LLMs versus medical-domain LLMs (e.g., Meditron, BioMistral) and their downstream impact on retrieval accuracy.

## Limitations

- The method relies heavily on RadGraph performance, which may vary across different report writing styles and structures
- Computational overhead from running Llama 70B during preprocessing may limit scalability despite avoiding fine-tuning during inference
- The noise injection mechanism lacks empirical validation specific to medical retrieval tasks
- Performance degradation on external datasets (IU X-Ray) suggests potential domain overfitting despite frozen text encoders

## Confidence

**High Confidence**: The retrieval-augmented generation framework successfully reduces hallucinations from comparative language compared to baseline methods. The empirical evidence from CheXbert and RadGraph metrics across multiple ablation studies supports this claim.

**Medium Confidence**: The complementary vision encoder fusion provides meaningful improvement over individual encoders. While Table 3 shows consistent gains (41.2→42.0 MF1-14), the absolute improvements are modest and the mechanism could benefit from additional ablation studies with more diverse encoder combinations.

**Low Confidence**: The noise injection technique meaningfully prevents overfitting to frozen text embeddings. The ablation results show improvement (41.7→42.5 MF1-14), but without ablation on noise magnitude or comparison to alternative regularization methods, the specific contribution remains uncertain.

## Next Checks

1. **Hallucination Content Analysis**: Manually examine 100 generated reports from the best-performing model (E3) and a baseline without LLM extraction (E1) to quantify the reduction in hallucinated comparative language. Compare the frequency of "unchanged," "improved," and "worsened" phrases to validate the key phrase extraction mechanism's effectiveness.

2. **Encoder Fusion Ablation with Domain Shift**: Replicate the IU X-Ray generalization experiment with additional encoder combinations (e.g., XrayDINOv2 + BiomedCLIP, XrayCLIP + BiomedCLIP) to determine whether the performance gap stems from encoder selection or domain adaptation limitations. This would isolate whether the fusion mechanism itself or the specific encoder choices drive the generalization gap.

3. **Noise Injection Sensitivity Analysis**: Conduct a grid search over noise magnitudes (ε ∈ {0.1, 0.5, 1.0, 2.0}/√d) and noise distributions (uniform vs. Gaussian) to determine the optimal regularization strategy. Compare the resulting retrieval performance and generalization to held-out data to validate whether the chosen uniform noise injection is indeed optimal for this task.