---
ver: rpa2
title: 'ConversAR: Exploring Embodied LLM-Powered Group Conversations in Augmented
  Reality for Second Language Learners'
arxiv_id: '2505.24000'
source_url: https://arxiv.org/abs/2505.24000
tags:
- language
- group
- agents
- system
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ConversAR is an AR headset application that enables second language
  learners to practice group conversations with two embodied LLM agents. The system
  uses scene understanding via object detection and features natural voice interaction
  with live captions.
---

# ConversAR: Exploring Embodied LLM-Powered Group Conversations in Augmented Reality for Second Language Learners

## Quick Facts
- arXiv ID: 2505.24000
- Source URL: https://arxiv.org/abs/2505.24000
- Authors: Jad Bendarkawi; Ashley Ponce; Sean Mata; Aminah Aliu; Yuhan Liu; Lei Zhang; Amna Liaqat; Varun Nagaraj Rao; Andrés Monroy-Hernández
- Reference count: 40
- Primary result: AR headset app enables group conversation practice with two LLM agents; users report reduced anxiety and increased autonomy compared to in-person methods

## Executive Summary
ConversAR is an augmented reality headset application that enables second language learners to practice group conversations with two embodied LLM agents. The system uses scene understanding via object detection and features natural voice interaction with live captions. In a study with 10 intermediate or higher Spanish learners, participants reported reduced speaking anxiety and increased learner autonomy compared to in-person practice methods.

## Method Summary
The system runs on Meta Quest 3 headset using Unity application with OpenAI Whisper for STT, GPT-4o for agent responses, and OpenAI TTS for natural voice output. Users trigger speech input with a controller button and conversations feature a 3-second gap between agent responses. Two cartoon humanoid agents engage in group conversation with the user, while a Moderator LLM manages turn-taking. Object detection is currently implemented via Wizard of Oz (manually hardcoded), and live captions follow accessibility guidelines.

## Key Results
- Participants found the system easy to use (mean 6.0/7) and would use it again (mean 6.0/7)
- Reduced speaking anxiety and increased learner autonomy compared to in-person practice methods
- Benefits included reduced anxiety, increased autonomy, and greater willingness to take linguistic risks
- Challenges identified around emotional investment and competing visual elements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-agent group conversations reduce L2 speaking anxiety compared to dyadic or in-person practice.
- Mechanism: Non-judgmental agents eliminate social risk, while the group format allows passive observation before engagement—users can skip turns without halting conversation flow, reducing performance pressure.
- Core assumption: Anxiety reduction transfers to real-world conversation contexts (not tested longitudinally).
- Evidence anchors:
  - [abstract] "participants reported reduced speaking anxiety and increased learner autonomy compared to in-person practice methods"
  - [section 5.1.1] P3: "The aspect that it's not a real person kind of allows for more authenticity. You're more open to making a mistake."
  - [section 5.1.1] P7: "if I didn't have a response to this specific question, I didn't have to answer it, and the other people would just continue talking"
  - [corpus] Related work on MR agents for group conversation (arxiv:2510.08227) similarly targets fear reduction but focuses on scripted scenarios; this system adds unstructured multi-turn dynamics.

### Mechanism 2
- Claim: Contextualized scene understanding increases engagement and relevance for L2 practice.
- Mechanism: Object detection grounds conversations in the user's physical environment, creating situated learning opportunities where vocabulary maps to visible objects—reducing abstraction and increasing retention.
- Core assumption: The Wizard of Oz object detection (manually hardcoded) adequately simulates automated detection for user experience purposes.
- Evidence anchors:
  - [abstract] "features natural voice interaction with live captions" combined with scene understanding
  - [section 3.1] "Studies show that this contextualized learning approach more effectively promotes language acquisition and retention than classroom-based methods"
  - [section 5.1.2] P3: "I was able to speak a lot [and] use words that I already know and they kind of drive the conversation because I was familiar with the topic"
  - [corpus] Corpus shows limited direct evidence; neighbor papers (e.g., VisionARy arxiv:2504.11380) explore similar AR+ChatGPT contextual learning but without multi-agent focus.

### Mechanism 3
- Claim: Controller-triggered speech input with a 3-second conversational gap enables controlled participation pacing.
- Mechanism: Push-to-talk eliminates false triggers from pauses/filler words, while the 3-second gap between agent responses gives learners time to process and decide whether to interject—simulating real group dynamics without real-time pressure.
- Core assumption: The 1-2 second STT-to-TTS delay is acceptable; longer delays would break conversational flow.
- Evidence anchors:
  - [section 3.3.2] "our pilot studies suggested that the button interaction was intuitive and felt familiar to using a walkie-talkie"
  - [section 3.3.2] "This approach also supports mid-speech pausing, addressing a limitation of fully voice-based conversational systems"
  - [section 3.3.3] "Through pilot studies, we determined an optimal gap of 3 seconds between each agent-generated response"
  - [corpus] No corpus papers directly address trigger-based vs. voice-activated input in AR language learning; this remains a design gap in literature.

## Foundational Learning

- Concept: **Turn-taking dynamics in group conversation**
  - Why needed here: Unlike dyadic exchanges, group conversations require tracking multiple speakers, anticipating gaps, and deciding when to interject—the system simulates this through a Moderator LLM.
  - Quick check question: Can you explain why a 3-second gap was chosen over continuous agent speech?

- Concept: **STT-TTS pipeline latency and its impact on conversation flow**
  - Why needed here: The 1-2 second delay between user speech and agent response affects perceived naturalness; understanding this helps diagnose UX friction.
  - Quick check question: What happens to latency when speech inputs are longer and more complex?

- Concept: **Zero-shot prompting for multi-agent conversation management**
  - Why needed here: The Moderator LLM uses a single parameterized prompt (not fine-tuned) to manage turn allocation—understanding prompt structure is essential for customization.
  - Quick check question: What information is passed to the prompt to prevent one-sided interactions?

## Architecture Onboarding

- Component map:
  - Meta Quest 3 headset -> Unity application -> Agent animation
  - Unity application -> OpenAI Whisper (whisper-1) -> STT processing
  - Unity application -> OpenAI TTS -> Agent voice output
  - Unity application -> GPT-4o (Chat Model) -> Agent responses and Moderator LLM
  - Unity application -> Object detection module -> Scene context
  - Unity application -> Caption display -> Real-time text under agents

- Critical path:
  1. User wears headset, selects language and proficiency level
  2. System displays "Detecting Environment..." (hardcoded context loaded)
  3. Two agents begin conversation, alternating with 3-second gaps
  4. User holds controller trigger → audio captured → released → STT processing
  5. Moderator LLM analyzes conversation history, selects responding agent
  6. Selected agent generates response via GPT-4o, outputs via TTS with captions
  7. Loop continues indefinitely; user can interject or observe passively

- Design tradeoffs:
  - Controller trigger vs. voice activation: Trigger prevents false positives from pauses but requires physical action—less natural, more reliable.
  - Zero-shot vs. fine-tuned prompting: Zero-shot is lightweight and fast but may produce less consistent agent personalities; fine-tuning would increase cost and complexity.
  - Cartoon vs. photorealistic avatars: Cartoon reduces uncanny valley effect but limits non-verbal expressivity (noted as challenge in results).
  - Wizard of Oz vs. automated object detection: Manual hardcoding ensures accuracy for study consistency but is not scalable; real detection is a future requirement.

- Failure signatures:
  - High STT latency (>3 seconds): Breaks conversational rhythm; users disengage or repeat themselves.
  - Agent responses ignore user input: Moderator LLM fails to select appropriate agent or prompt guardrails too restrictive—users feel unheard.
  - Captions dominate attention: Users focus on reading text instead of agent embodiment—reduces social presence (reported by P1).
  - Conversation strays from context: Agents discuss topics unrelated to environment—contextual learning value lost.
  - No emotional engagement: Users test agent boundaries (P5's "meta-conversation") and lose interest when responses remain surface-level.

- First 3 experiments:
  1. Automated object detection integration: Replace Wizard of Oz with real-time scene analysis (e.g., Meta Quest's spatial anchors or external vision API); measure accuracy, latency, and user perception of conversation relevance.
  2. Dyadic vs. multi-agent comparison: Run controlled study comparing anxiety, engagement, and linguistic risk-taking between single-agent and dual-agent configurations to isolate group dynamic effects.
  3. Expressivity enhancement test: Implement non-verbal cues (nodding, gaze, facial expressions) synchronized with LLM sentiment analysis; measure whether caption attention decreases and emotional investment increases.

## Open Questions the Paper Calls Out

- Question: How does long-term usage of ConversAR impact actual second language acquisition and speaking proficiency compared to traditional methods?
  - Basis in paper: [explicit] The authors state that "conducting a longitudinal study would enable an analysis of the system’s long-term effects on learning outcomes," as the current study was limited to a single session.
  - Why unresolved: The evaluation focused on immediate user perceptions, anxiety, and system usability rather than measuring skill retention or improvement in speaking ability over time.
  - What evidence would resolve it: A study spanning multiple weeks or months that includes pre- and post-assessments of oral proficiency and vocabulary retention.

- Question: How does the effectiveness of multi-agent group conversation practice compare to single-agent dyadic interactions for L2 learners?
  - Basis in paper: [explicit] The authors explicitly call for "future studies [to] directly compare multi-agent versus dyadic conversation" to isolate the specific benefits of the group dynamic.
  - Why unresolved: While the paper demonstrates the feasibility of group conversation, it does not empirically validate if the added complexity of multiple agents yields better outcomes than the standard one-on-one agent approach.
  - What evidence would resolve it: A comparative experiment measuring anxiety, engagement, and complexity of speech production between users interacting with one agent versus two.

- Question: Does the cognitive load of multi-agent AR interactions hinder beginners or learners with high anxiety?
  - Basis in paper: [inferred] The discussion notes that "group settings may introduce a higher cognitive load for some L2 learners... potentially hindering their ability to actively participate," yet the study only tested intermediate or higher learners.
  - Why unresolved: It is unclear if the system's benefits (reduced anxiety) extend to novices who may find the turn-taking and processing speed of two fluent agents overwhelming.
  - What evidence would resolve it: A user study targeting novice learners that measures cognitive load (e.g., via NASA-TLX) and correlates it with performance and anxiety metrics.

## Limitations

- Relies on Wizard of Oz object detection rather than real-time scene understanding, creating scalability gap
- Small sample size (n=10) limits generalizability of findings
- Lack of longitudinal tracking prevents assessment of whether anxiety reduction translates to sustained skill improvement or real-world transfer

## Confidence

- High confidence: Reduced speaking anxiety compared to in-person practice (directly reported by participants with consistent qualitative support)
- Medium confidence: Increased learner autonomy (supported by participant feedback but not independently measured)
- Low confidence: Long-term effectiveness and real-world skill transfer (not measured in current study design)

## Next Checks

1. Implement automated object detection and measure conversation relevance accuracy versus Wizard of Oz baseline
2. Conduct controlled study comparing single-agent versus dual-agent configurations to isolate group dynamic effects
3. Run 4-6 week longitudinal study tracking anxiety levels, speaking frequency, and skill improvement in real-world contexts