---
ver: rpa2
title: An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized
  LLM Reasoning
arxiv_id: '2505.19954'
source_url: https://arxiv.org/abs/2505.19954
tags:
- diagnostic
- reasoning
- zhang
- wang
- diagnosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a diagnostic framework for neurodegenerative
  dementias that generates synthetic radiology reports from brain MRIs and uses reinforcement
  learning to train LLMs to perform differential diagnosis based on these reports.
  The framework combines volumetric analysis with structured report generation and
  fine-tunes lightweight LLMs using Group Relative Policy Optimization to incentivize
  diagnostic reasoning without requiring labeled reasoning traces.
---

# An Explainable Diagnostic Framework for Neurodegenerative Dementias via Reinforcement-Optimized LLM Reasoning

## Quick Facts
- **arXiv ID**: 2505.19954
- **Source URL**: https://arxiv.org/abs/2505.19954
- **Reference count**: 40
- **Primary result**: Framework matches/exceeds existing DL methods (F1 up to 85.86% for CN, 73.17% for AD) while providing transparent, causally grounded rationales

## Executive Summary
This work introduces a diagnostic framework for neurodegenerative dementias that generates synthetic radiology reports from brain MRIs and uses reinforcement learning to train LLMs to perform differential diagnosis based on these reports. The framework combines volumetric analysis with structured report generation and fine-tunes lightweight LLMs using Group Relative Policy Optimization to incentivize diagnostic reasoning without requiring labeled reasoning traces. Experiments show that the approach matches or exceeds the performance of existing deep learning methods, achieving class-wise F1 scores up to 85.86% for cognitively normal cases and 73.17% for Alzheimer's disease, while also providing transparent, causally grounded rationales. The framework bridges the gap between predictive accuracy and explainability, offering a clinically interpretable solution for differential diagnosis of neurodegenerative diseases.

## Method Summary
The framework uses AssemblyNet for whole-brain segmentation to compute 132+ structure volumes, normalizes these by intracranial volume, and compares them to normative lifespan curves to generate Structural Deviation Scores (SDS). These SDS values are mapped to a 7-point severity scale and converted into structured synthetic radiology reports. Lightweight LLMs (e.g., LLaMA-3.1-8B) are then fine-tuned using Group Relative Policy Optimization, which rewards diagnostic accuracy and proper report structure while regularizing with KL divergence. The approach achieves diagnostic performance comparable to specialized deep learning models while providing interpretable reasoning traces.

## Key Results
- Class-wise F1 scores up to 85.86% for cognitively normal cases and 73.17% for Alzheimer's disease
- Macro-F1 up to 65.09% on differential diagnosis task across five classes (CN, AD, bvFTD, nfvPPA, svPPA)
- Performance matches or exceeds existing deep learning methods while providing transparent rationales
- GRPO fine-tuning significantly outperforms zero-shot and instruction-tuned LLM baselines

## Why This Works (Mechanism)
The framework succeeds by decomposing the complex diagnostic task into interpretable sub-components. First, volumetric analysis provides objective measurements of brain structure changes. Second, normative modeling quantifies deviations from expected aging patterns. Third, synthetic reports translate these quantitative findings into clinically familiar formats. Finally, GRPO fine-tuning incentivizes LLMs to reason through these structured inputs systematically, generating both diagnoses and supporting rationales. This modular approach enables transparent decision-making while maintaining diagnostic accuracy.

## Foundational Learning
- **Volumetric segmentation**: Measuring brain structure volumes from MRI images is essential for detecting neurodegenerative patterns. Quick check: Verify AssemblyNet outputs 132+ structure volumes that sum appropriately to intracranial volume.
- **Normative modeling**: Comparing individual measurements to age- and sex-matched reference populations enables detection of abnormal atrophy patterns. Quick check: Confirm SDS calculations produce reasonable distributions centered around zero for healthy controls.
- **Reinforcement learning for LLMs**: GRPO optimizes language models for task completion without requiring labeled reasoning traces. Quick check: Verify reward function properly balances format compliance, accuracy, and KL regularization.
- **Structured radiology reporting**: Converting quantitative findings into standardized clinical language improves interpretability. Quick check: Ensure severity mappings and sentence templates produce coherent, clinically plausible reports.

## Architecture Onboarding

**Component map**: MRI -> AssemblyNet segmentation -> Volume ratios -> SDS computation -> Severity mapping -> Synthetic reports -> LLM reasoning -> Differential diagnosis

**Critical path**: MRI → Segmentation → Volumetric analysis → Report generation → LLM diagnosis → Clinical decision

**Design tradeoffs**: The framework trades some diagnostic precision for explainability by using interpretable volumetric features rather than end-to-end learned representations. This choice enables transparent reasoning but may miss subtle patterns that deep learning could capture.

**Failure signatures**: 
- Incoherent outputs when β regularization is too low (0.0 vs 0.005)
- Degraded performance when removing group-relative advantage normalization
- Pathology bias when using domain-specialized models trained on non-diverse datasets

**3 first experiments**:
1. Validate synthetic report quality by comparing generated reports against ground truth radiological reports from ADNI dataset
2. Ablate GRPO components by training with β=0 and standard advantage estimation to verify their importance
3. Test domain adaptation effects by comparing generalist LLM performance against domain-specialized models on the same task

## Open Questions the Paper Calls Out
**Open Question 1**: How would the framework perform when validated in prospective clinical settings with practicing clinicians evaluating the generated rationales for diagnostic utility and trustworthiness? The authors position their work as "an important first step" toward clinically useful AI but provide no clinical evaluation data, relying only on retrospective datasets.

**Open Question 2**: Can the synthetic report generation pipeline be extended to incorporate multimodal neuroimaging data (e.g., T2/FLAIR, PET, diffusion MRI) to improve differential diagnostic accuracy? The paper focuses "only on structural MRI" but acknowledges that additional modalities could provide complementary biomarkers for difficult-to-distinguish FTD subtypes.

**Open Question 3**: What strategies could improve diagnostic performance on rare FTD subtypes (nfvPPA, svPPA) where the current framework achieves class-wise F1 scores near or below 50%? The authors acknowledge that "limited samples—particularly for nfvPPA and svPPA—exacerbate these challenges for robust model training and evaluation."

## Limitations
- Missing critical implementation details including exact prompt templates, normative model parameters, and severity threshold values
- Performance depends heavily on quality of synthetic radiology reports, which require precise calibration
- Class imbalance for rare FTD subtypes limits diagnostic performance on these conditions
- No clinical validation of the generated rationales for real-world decision-making utility

## Confidence

**High confidence**: General framework architecture combining volumetric analysis, synthetic reporting, and LLM reasoning is conceptually sound and well-grounded.

**Medium confidence**: Performance claims are plausible given the methodology but cannot be independently verified due to missing implementation details.

**Low confidence**: Exact reasoning quality and clinical utility are difficult to assess without complete system access and clinical validation.

## Next Checks

1. Implement the full MRI-to-report pipeline using publicly available AssemblyNet weights and approximate normative modeling parameters, then validate synthetic report quality against ground truth radiological reports.

2. Conduct ablation studies to verify the importance of β regularization (0.005) and group-relative advantage normalization by training GRPO variants with β=0 and standard advantage estimation.

3. Test domain adaptation effects by comparing generalist LLM performance against domain-specialized models on the same task to validate claims about pathology bias in training data.