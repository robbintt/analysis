---
ver: rpa2
title: Understanding Post-Training Structural Changes in Large Language Models
arxiv_id: '2509.17866'
source_url: https://arxiv.org/abs/2509.17866
tags:
- post-training
- singular
- arxiv
- https
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work systematically analyzes structural changes in model
  parameters after post-training using SVD. The analysis reveals two robust phenomena:
  (1) singular values undergo near-uniform geometric scaling across layers, and (2)
  left and right singular vectors experience highly consistent orthogonal transformations.'
---

# Understanding Post-Training Structural Changes in Large Language Models

## Quick Facts
- arXiv ID: 2509.17866
- Source URL: https://arxiv.org/abs/2509.17866
- Reference count: 40
- Key outcome: SVD analysis reveals post-training relies on uniform singular value scaling (temperature control) and consistent orthogonal transformations (semantic preservation), challenging black-box views of parameter space.

## Executive Summary
This paper presents a systematic analysis of structural changes in large language model parameters after post-training using Singular Value Decomposition (SVD). The authors discover two robust phenomena: singular values undergo near-uniform geometric scaling across layers, and left and right singular vectors experience highly consistent orthogonal transformations. These findings lead to a mathematical framework explaining why post-training capabilities are fundamentally bounded by pre-training foundations. The study demonstrates that different post-training methods produce equivalent parametric effects, with singular value scaling acting as a temperature-controlled mechanism and coordinated vector rotations encoding semantic alignment.

## Method Summary
The paper analyzes structural changes in LLM parameters during post-training by computing reduced SVD on weight matrices from both base and post-trained models. For each matrix W, they calculate W = U·Σ·V^T and analyze the scaling factors (ratios of singular values) and orthogonal transformations (Q matrices from U_base^T·U_post and V_base^T·V_post). They construct Singular Value Scaling Matrices (SVSM) to visualize scaling patterns and measure orthogonality deviations to quantify transformation consistency. The framework is validated through ablation and restoration experiments that confirm the necessity of maintaining both scaling and rotational relationships for model performance.

## Key Results
- Singular values undergo near-uniform geometric scaling across layers, functioning as a global temperature control mechanism
- Left and right singular vectors experience highly consistent orthogonal transformations that preserve semantic alignment
- Different post-training methods (instruction tuning, Long-CoT distillation, RL) produce equivalent parametric effects
- Post-training capability is fundamentally bounded by pre-training data quality and subspace structure

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Near-uniform geometric scaling of singular values functions as a global temperature control mechanism.
- **Mechanism:** Scaling singular values (Σ) is mathematically equivalent to scaling query/key weights (W_Q, W_K), directly influencing the softmax denominator (temperature) in attention layers, modulating attention distribution sharpness without altering semantic subspace structure.
- **Core assumption:** The linear scaling factor α remains sufficiently consistent across layers to be treated as a global regulatory parameter.
- **Evidence anchors:** SVD analysis shows near-uniform scaling patterns; mathematical proof demonstrates equivalence to attention temperature adjustment; SVSM visualizations confirm consistent scaling.
- **Break condition:** If scaling factors were distributed non-uniformly across layers, the global temperature regulation hypothesis would fail.

### Mechanism 2
- **Claim:** Consistent orthogonal transformations of singular vectors preserve pre-trained semantic space by maintaining input-output subspace alignment.
- **Mechanism:** Post-training applies coordinated rotation matrix Q to both left (U) and right (V) singular vectors, rotating orthogonal bases without breaking geometric pairing between input and output subspaces, allowing adaptation without catastrophic forgetting.
- **Core assumption:** The consistency of rotation (Q_1 ≈ Q_2) is a fundamental law of parameter space rather than optimization artifact.
- **Evidence anchors:** Ablation experiments show model collapse when rotations are decoupled; orthogonality deviation measurements confirm transformation consistency; restoration experiments recover performance.
- **Break condition:** If ablation experiment did not result in model collapse, the claim that rotation is essential for semantic preservation would be invalidated.

### Mechanism 3
- **Claim:** Post-training capability is fundamentally bounded by pre-trained base model's subspace quality.
- **Mechanism:** Post-training primarily rotates existing bases (W_post ≈ U_base·Q···) rather than creating new ones, inheriting representational capacity entirely from pre-training and merely unlocking or reorienting existing potential.
- **Core assumption:** Singular vectors of base model form complete enough basis for post-training tasks, making rotation sufficient and new basis creation unnecessary.
- **Evidence anchors:** Performance bounds observed across different post-training methods; structural analysis shows rotation rather than basis creation; mathematical framework formalizes pre-training as capability ceiling.
- **Break condition:** If post-training significantly altered rank or fundamental structure of singular vectors rather than rotating them, the "bounded by pre-training" hypothesis would be false.

## Foundational Learning

- **Concept:** Singular Value Decomposition (SVD)
  - **Why needed here:** The entire analytical framework relies on decomposing weight matrices W into U·Σ·V^T to isolate scaling (Σ) from rotational (U, V) dynamics.
  - **Quick check question:** Can you explain why changing values in Σ affects magnitude of vectors in column space, while changing U or V rotates them?

- **Concept:** Attention Mechanism & Temperature
  - **Why needed here:** The paper posits that singular value scaling is mathematically equivalent to adjusting temperature in softmax function of attention layer.
  - **Quick check question:** How does increasing temperature parameter in softmax function affect probability distribution over tokens (sharpening vs. flattening)?

- **Concept:** Orthogonal Transformations & Subspaces
  - **Why needed here:** Core finding is that post-training applies "consistent orthogonal transformations." You must understand that orthogonal matrices preserve lengths and angles, meaning they rotate data without distorting geometry of semantic space.
  - **Quick check question:** If matrix Q is orthogonal, why is Q^T·Q = I important for preserving structure of data passed through it?

## Architecture Onboarding

- **Component map:** Transformer Block -> Self-Attention (SA: W_Q, W_K, W_V, W_O) and Feed-Forward Network (FFN: W_gate, W_up, W_down) -> Analysis Layer (SVSM computation, Orthogonality deviation N_F^(i))

- **Critical path:** 1) Input: Take weight matrices (W_base and W_post) from same architecture 2) Decomposition: Perform SVD to get U, Σ, V 3) Comparison: Calculate SVSM to check for uniform scaling α; calculate sim_U and sim_V to check for rotation consistency (Q_1 ≈ Q_2) 4) Verification: Use Constructions 7 & 10 (Replacement & Restoration) to confirm performance retention

- **Design tradeoffs:** Spectral vs. Behavioral Analysis: paper chooses data-agnostic, parameter-space approach (SVD) over input/output behavioral tests, allowing structural insights but may miss activation-space nuances. Approximation vs. Exactness: framework relies on approximation W_post ≈ (U_base·Q)(α·Σ_base)(V_base·Q)^T; simplifying to exact equality fails; "near-uniform" and "consistent" are robust averages, not absolute laws.

- **Failure signatures:** Ablation Collapse: if you decouple rotations of U and V (force Q_1 ≠ Q_2), model outputs nonsense (0% accuracy). SVSM Variance: if heatmap shows vertical striations (layer-specific variation) rather than uniform color, "global scaling" law is broken.

- **First 3 experiments:** 1) Visualize SVSM: Calculate Singular Value Scaling Matrix (Eq 4) for base/instruct pair (e.g., Qwen2.5-Math) to visually confirm "near-uniform" heatmap pattern described in Figure 2. 2) Verify Semantic Preservation (Restoration): Implement Construction 10 (Restoration) on small model by forcibly coupling singular vector rotations, check if accuracy recovers from Ablation state (Table 2). 3) Test W_O Hypothesis: Isolate W_O matrix in reasoning model and measure scaling factor α, confirm if significantly higher (~1.35) than other matrices (~1.0) as claimed in Section 4.1.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does pre-training establish the capacity ceiling that post-training operates within?
- Basis in paper: [explicit] The conclusion states: "Understanding how pre-training establishes such a capacity ceiling remains an important direction for future work."
- Why unresolved: Paper demonstrates post-training relies on pre-trained structures but does not investigate how those structures are formed during pre-training itself.
- What evidence would resolve it: Systematic analysis of singular value and vector evolution during pre-training, potentially correlating data quality and pre-training dynamics with robustness of final structural foundations.

### Open Question 2
- Question: What causes the observed asymmetry in co-rotation speed between input and output subspaces during restoration experiments?
- Basis in paper: [explicit] In Appendix D.1, authors state: "This suggests an inherent asymmetry in co-rotation speed, with one subspace consistently leading the other—an intriguing phenomenon warranting further study."
- Why unresolved: Paper documents asymmetry through restoration experiments but offers no mechanistic explanation for why output subspace transformations appear more stable than input subspace transformations.
- What evidence would resolve it: Controlled experiments measuring relative speed and stability of orthogonal transformations in input vs. output subspaces across different post-training regimes and architectures, potentially linking this to gradient flow dynamics.

### Open Question 3
- Question: What is the nature and source of the "noise" that singular value replacement appears to eliminate in some REASONING models?
- Basis in paper: [inferred] Paper observes that replacing singular values with scaled base model values sometimes improves performance, noting: "One possible explanation is that Construction 7 effectively eliminates noise arising from precision limitations or heterogeneous data during singular value adjustment."
- Why unresolved: Noise hypothesis is presented as speculative; paper does not isolate or characterize this noise, nor determine whether it originates from numerical precision, data heterogeneity, or other optimization dynamics.
- What evidence would resolve it: Ablation studies varying numerical precision, training data homogeneity, and optimization hyperparameters to isolate conditions where singular value replacement yields performance gains, coupled with analysis of spectral properties of removed components.

## Limitations
- Framework relies on key assumptions that require further validation, particularly the statistical nature of "near-uniform" scaling
- Orthogonal transformation consistency is measured computationally but lacks theoretical proof of why this symmetry should be fundamental
- Temperature control mechanism, while mathematically demonstrated, requires empirical validation across more diverse architectures
- Analysis focuses on structural patterns but may miss activation-space nuances

## Confidence

- **High Confidence**: Geometric scaling phenomenon and its mathematical equivalence to attention temperature adjustment are well-supported by both theoretical derivation and experimental evidence.
- **Medium Confidence**: Claim that orthogonal transformations preserve semantic space is strongly supported by ablation experiments but relies on computational measurements rather than theoretical guarantees.
- **Medium Confidence**: Assertion that post-training capability is fundamentally bounded by pre-training quality follows logically from structural analysis but requires more extensive testing across diverse base models and task types.

## Next Checks
1. **Cross-Architecture Validation**: Apply SVD analysis framework to models with different architectures (Mixture-of-Experts, different attention mechanisms) to verify if scaling and rotation patterns hold universally or are architecture-dependent.

2. **Longitudinal Study**: Track singular value distributions and orthogonal transformations throughout the post-training process (not just before/after) to understand if these patterns emerge gradually or appear abruptly.

3. **Task Transferability Test**: Train models on task A, apply observed scaling/rotation patterns from task B, and measure performance degradation to validate whether geometric patterns are task-specific or represent general post-training dynamics.