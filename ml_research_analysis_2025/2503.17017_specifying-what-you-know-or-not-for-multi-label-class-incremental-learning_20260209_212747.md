---
ver: rpa2
title: Specifying What You Know or Not for Multi-Label Class-Incremental Learning
arxiv_id: '2503.17017'
source_url: https://arxiv.org/abs/2503.17017
tags:
- classes
- learning
- class
- features
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of catastrophic forgetting in
  multi-label class-incremental learning (MLCIL), where traditional single-label approaches
  fail due to incomplete labels and feature aliasing across sessions. The authors
  propose HCP, a framework that specifies known and unknown knowledge to accommodate
  historical, current, and prospective knowledge.
---

# Specifying What You Know or Not for Multi-Label Class-Incremental Learning

## Quick Facts
- **arXiv ID:** 2503.17017
- **Source URL:** https://arxiv.org/abs/2503.17017
- **Reference count:** 19
- **Primary result:** Achieves SOTA performance, surpassing previous methods by 3.3% on average accuracy for MS-COCO B0-C10 without replay buffers

## Executive Summary
This paper addresses catastrophic forgetting in multi-label class-incremental learning (MLCIL) by proposing HCP, a framework that explicitly specifies known and unknown knowledge across historical, current, and prospective classes. Unlike single-label approaches, HCP handles incomplete labels and feature aliasing through three key innovations: dynamic feature purification using class embeddings, adaptive pseudo-labeling via distribution priors, and prospective knowledge mining through synthetic features. The framework demonstrates state-of-the-art performance on MS-COCO and PASCAL VOC datasets without requiring replay buffers.

## Method Summary
The HCP framework uses a TResNetM backbone to extract patch tokens, which are then processed through feature purification modules that use learnable class embeddings as attention queries. The method maintains separate stability and plasticity classifiers, with the stability classifier weights frozen for old classes while the plasticity classifier learns new classes. Distribution queues store mean confidence values for adaptive thresholding during recall enhancement, and synthetic "unknown" features are generated from absent-class features through interpolation. The framework is trained session-by-session using asymmetric loss with class-balanced weighting.

## Key Results
- Achieves 3.3% average accuracy improvement over SOTA on MS-COCO B0-C10 protocol
- Outperforms previous methods without requiring replay buffers
- Demonstrates effectiveness across multiple evaluation metrics including mAP, CF1, and OF1

## Why This Works (Mechanism)

### Mechanism 1: Dynamic Feature Purification via Class Embeddings
The framework mitigates feature aliasing by isolating fine-grained features for each class using dedicated learnable embeddings. A set of class embeddings acts as queries in a multi-head self-attention block against patch tokens, forcing the model to extract class-specific features rather than relying on a global, entangled feature vector. Old embeddings are frozen to preserve historical spatial attention.

### Mechanism 2: Adaptive Pseudo-Labeling via Distribution Priors
Instead of using a fixed threshold for pseudo-labeling old classes, the method calculates a class-specific threshold based on the mean confidence of the old model. This accounts for variance in confidence forgetting across different classes, where some classes degrade faster than others during incremental learning.

### Mechanism 3: Prospective Knowledge Mining via Synthetic Features
The method interpolates features of "absent" classes (classes not currently labeled in the image) to simulate unknown/prospective classes. This synthetic "unknown" feature forces the classifier to push known class features closer together, improving intra-class compactness and distinguishing them from future classes.

## Foundational Learning

- **Concept: Catastrophic Forgetting**
  - Why needed: The core problem of Class-Incremental Learning where the model must learn new classes without overwriting weights that recognize old classes
  - Quick check: If you train a model on class "Dog" then class "Cat", does it still recognize "Dog"?

- **Concept: Multi-Label Incomplete Labels**
  - Why needed: Distinct from standard CIL where an image might contain objects from old sessions (unlabeled) and future sessions (unlabeled)
  - Quick check: In a session learning "Car", an image contains a Car and a Person. Is "Person" treated as a negative sample or ignored?

- **Concept: Asymmetric Loss (ASL)**
  - Why needed: Multi-label datasets have massive class imbalance (mostly negative labels), and ASL down-weights easy negatives
  - Quick check: How does the loss function handle the overwhelming number of "background" or "absent" class examples?

## Architecture Onboarding

- **Component map:**
  - Backbone (TResNetM) -> Patch Tokens -> Feature Purification (Attention + Class Embeddings) -> Stability Classifier (frozen) + Plasticity Classifier (trainable)

- **Critical path:**
  1. Input: Image → Backbone → Patch Tokens
  2. Context: Retrieve Old Class Embeddings (frozen) + Init New Class Embeddings
  3. Purification: Attention mechanism generates distinct feature vectors for every known class
  4. Recall: Use Old Model + Distribution Prior to generate Pseudo-Labels for old classes
  5. Probing: Synthesize "Unknown" feature from absent class features
  6. Optimization: Calculate Weighted ASL Loss using Ground Truth (new), Pseudo-Labels (old), and Synthetic Label (unknown)

- **Design tradeoffs:**
  - Parallel Prediction vs. Complexity: The method predicts all classes in parallel via embeddings, which is faster than sequential decoders but requires storing an embedding vector for every single class ever learned
  - Synthetic Unknown: Adding an "unknown" class helps future learning but may increase False Positives if the synthetic feature overlaps with actual known class features

- **Failure signatures:**
  - High False Positives on Old Classes: Suggests the Pseudo-Label threshold is too low, or the "unknown" synthetic class is pulling old features into the wrong space
  - Low Accuracy on New Classes: Suggests the Feature Purification is failing to disentangle new objects from old clutter

- **First 3 experiments:**
  1. Ablate the attention-based purification module (replace with Global Average Pooling) to quantify the value of disentangled features vs. entangled ones
  2. Compare static thresholding (e.g., ε=0.5) vs. the proposed distribution-prior thresholding on a validation set of old classes to verify recall improvement
  3. Visualize the t-SNE of features with and without "Probing Unknown" to confirm if cluster compactness actually improves as claimed

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- The paper does not specify Beta distribution parameters for synthetic feature interpolation, which could affect the "prospective knowledge" mechanism's stability
- Class embedding dimensionality and attention head count are unspecified, potentially impacting feature purification effectiveness
- No ablation study isolates the individual contribution of each mechanism (purification, adaptive thresholding, synthetic features)

## Confidence
- **High Confidence:** The overall framework architecture and problem formulation are well-specified and coherent
- **Medium Confidence:** The adaptive thresholding mechanism is theoretically sound but lacks empirical validation of its distribution-prior approach
- **Low Confidence:** The synthetic "unknown" feature generation process is novel but under-specified, making its impact difficult to predict

## Next Checks
1. Ablation Study: Remove the feature purification module and measure the degradation in multi-label accuracy to quantify its contribution to solving feature aliasing
2. Threshold Sensitivity Analysis: Compare static vs. distribution-prior thresholding across multiple sessions to empirically validate the recall improvement claim
3. Synthetic Feature Validation: Visualize feature distributions (t-SNE) with and without the "probing unknown" mechanism to confirm improved cluster separation as measured by the Calinski-Harabasz Index