---
ver: rpa2
title: Towards Automated Regulatory Compliance Verification in Financial Auditing
  with Large Language Models
arxiv_id: '2507.16642'
source_url: https://arxiv.org/abs/2507.16642
tags:
- answer
- financial
- anforderung
- requirement
- ifrs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the potential of large language models (LLMs)
  for automated compliance verification in financial auditing, specifically checking
  whether text passages in financial reports align with regulatory standards such
  as IFRS and HGB. The research extends prior work by integrating a proven text-matching
  system with LLMs to assess compliance of recommended passages.
---

# Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models

## Quick Facts
- arXiv ID: 2507.16642
- Source URL: https://arxiv.org/abs/2507.16642
- Reference count: 31
- Primary result: GPT-4 outperforms other LLMs on overall micro F1 scores for compliance verification; Llama-2-70b excels at detecting non-compliance on IFRS data with 87.50% F1-score.

## Executive Summary
This study evaluates large language models for automated regulatory compliance verification in financial auditing, specifically checking whether text passages in financial reports align with standards like IFRS and HGB. The research extends prior work by integrating a proven text-matching system with LLMs to assess compliance of recommended passages. Experiments compare six LLMs across two custom datasets from PwC Germany, measuring performance via precision, recall, and F1-score per class. Results show GPT-4 performs best overall, while Llama-2-70b excels in detecting non-compliance on IFRS data with high precision (80.21%), recall (96.25%), and F1-score (87.50%). However, all models struggle with German texts, reflecting training bias toward English. The study concludes that out-of-the-box LLMs are not yet reliable for fully automated compliance checks but highlights the potential of targeted fine-tuning, especially for open-source models, to improve accuracy and address data privacy and cost concerns.

## Method Summary
The study evaluates six LLMs (Llama-2-7b/13b/70b-chat, GPT-3.5-Turbo, GPT-3.5-16k, GPT-4) using 8 prompt templates on 100 IFRS and 120 HGB samples from PwC Germany. The system maps regulatory checklist items to document segments via ZeroShotALI, then queries an LLM to classify compliance as yes/no/unclear/not applicable. Performance is measured by precision, recall, and F1-score per class, averaged using macro and micro metrics. The best configuration enforces a closed JSON schema output. Experiments test prompt complexity, model architecture, and language-specific performance.

## Key Results
- GPT-4 achieves the highest overall micro F1-scores (71.65% IFRS, 59.31% HGB)
- Llama-2-70b excels at detecting non-compliance ("No" class) on IFRS data with 87.50% F1-score
- All models struggle significantly with German (HGB) regulatory texts due to English-centric training
- Brief prompts with one-shot examples generally outperform complex reasoning strategies
- No model successfully detected the "Unclear" class; models defaulted to binary yes/no predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can perform regulatory compliance verification through semantic comparison of legal requirements against financial document passages.
- Mechanism: The system maps regulatory checklist items to document segments via ZeroShotALI (a transformer-based recommender), then queries an LLM to classify compliance as yes/no/unclear/not applicable.
- Core assumption: LLMs possess sufficient domain knowledge of accounting standards (IFRS/HGB) to detect semantic gaps between requirements and disclosures.
- Evidence anchors:
  - [abstract] "We find that the open-source Llama-2 70 billion model demonstrates outstanding performance in detecting non-compliance or true negative occurrences"
  - [section IV-E-3] "Llama-2-70b with Precision of 80.21%, Recall of 96.25% and an F1-Score of 87.50% on IFRS data"
  - [corpus] Limited direct evidence; related work on financial LLMs (e.g., "Automating Financial Statement Audits with LLMs") supports general feasibility but not specific mechanisms.
- Break condition: Performance degrades when documents contain language outside the model's dominant training corpus (e.g., German HGB for English-trained models).

### Mechanism 2
- Claim: Constrained response formats and minimal example-guided prompting outperform verbose reasoning strategies for compliance classification.
- Mechanism: Closed JSON-schema responses reduce invalid outputs; one-shot examples provide task calibration without overloading context.
- Core assumption: Constrained outputs reduce hallucination and format parsing failures in production pipelines.
- Evidence anchors:
  - [section IV-D] "the 'closed' format yielded superior performance compared to the 'open-ended' format"
  - [section IV-E-2] "prompt I 'In-Out-Sub-Template' achieved the best score in 4 out of 12 cases"
  - [corpus] Weak direct evidence; RAG frameworks (e.g., "AstuteRAG-FQA") suggest structured outputs help but don't address compliance-specific prompting.
- Break condition: One-shot examples may bias toward the example class if not carefully balanced (the paper notes all one-shot examples showed compliant cases).

### Mechanism 3
- Claim: Open-source models can achieve competitive non-compliance detection on English-language regulatory frameworks while offering privacy advantages.
- Mechanism: Larger parameter counts don't guarantee better performance; task-specific evaluation reveals where open-source models excel (detecting "No" class) versus where they lag (overall multilingual accuracy).
- Core assumption: Fine-tuning on domain-specific compliance data could close the performance gap with proprietary models.
- Evidence anchors:
  - [section IV-E-1] "Llama-2-70b for reference performed worse overall... than its significantly smaller counterpart Llama-2-7b"
  - [section IV-E-1] "Llama-2 models for reference were trained on a 98% English text corpus"
  - [corpus] No direct corpus evidence on open-source vs. proprietary trade-offs for compliance; financial RAG work ("FAITH" framework) highlights hallucination risks in tabular data but not this specific comparison.
- Break condition: Non-English compliance verification currently requires proprietary multilingual models; open-source alternatives fail to produce parseable outputs.

## Foundational Learning

- Concept: Regulatory Compliance Frameworks (IFRS vs. HGB)
  - Why needed here: Understanding that IFRS is international/English-based while HGB is German-specific explains the language-dependent performance gap observed in experiments.
  - Quick check question: Can you explain why models trained on English corpora might fail on HGB compliance checks even if the prompt is translated?

- Concept: Classification Metrics for Imbalanced Data
  - Why needed here: The dataset has skewed class distributions (82 "No" vs. 17 "Yes" for IFRS); understanding micro vs. macro F1 is essential for interpreting results correctly.
  - Quick check question: Why would micro F1 be preferred over macro F1 when false negatives (missed non-compliance) are costlier than false positives?

- Concept: Zero-Shot vs. Few-Shot Prompting
  - Why needed here: The paper tests eight prompt configurations including one-shot variants; understanding when examples help vs. hurt is critical for deployment.
  - Quick check question: What risk does a one-shot example showing only compliant cases introduce to the model's calibration?

## Architecture Onboarding

- Component map:
  - Financial reports -> ZeroShotALI recommender -> LLM compliance check -> Classification output

- Critical path:
  1. Regulatory requirement + document passage -> LLM prompt (system + user + optional example)
  2. LLM inference -> structured response extraction
  3. Response parsing -> invalid outputs cast to "invalid" class
  4. Metric aggregation -> precision/recall/F1 per class plus micro/macro averages

- Design tradeoffs:
  - **Open-source (Llama-2-70b)**: Strong non-compliance detection on English data (87.50% F1 for "No" class), privacy-preserving local deployment, but poor multilingual support and inconsistent parsing
  - **Proprietary (GPT-4)**: Best overall micro F1 (71.65% IFRS, 59.31% HGB), reliable multilingual output, but data privacy concerns and API costs
  - **Prompt complexity**: Brief prompts with one-shot examples outperform Chain-of-Thought and Tree-of-Thought for this task, reducing compute cost per query

- Failure signatures:
  - **Language mismatch**: German prompts to English-trained models produce unparseable outputs (multiple Llama-2 configurations scored 0.00 on HGB prompts)
  - **Verbose response formats**: Open-ended explanations introduce parsing failures and don't improve accuracy
  - **Class imbalance blindness**: No model successfully detected "Unclear" class; models default to binary yes/no predictions
  - **One-shot bias**: Example-only-compliant prompts may skew predictions toward "yes" (Prompt VIII with non-compliant example showed degraded performance)

- First 3 experiments:
  1. Establish baseline with Prompt I (In-Out-Sub-Template) across both datasets using GPT-4 to confirm reproducibility of reported micro F1 scores (target: 66.67% HGB, 73.60% IFRS).
  2. Test Llama-2-70b on IFRS "No" class detection with Prompt VI (In-Out-Tot-One-Shot-Template) to validate the claimed 87.50% F1; add balanced one-shot examples (both compliant and non-compliant) to assess bias correction.
  3. Deploy a hybrid approach: Use Llama-2-70b locally for initial non-compliance screening (high recall), then route flagged cases to GPT-4 for secondary verification; measure false positive reduction and cost savings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent can fine-tuning open-source models on domain-specific accounting data enhance their reliability for regulatory compliance verification compared to proprietary models?
- Basis in paper: [explicit] The authors conclude that "out-of-the-box" LLMs are not yet reliable enough and explicitly suggest that "fine-tuning the model on comprehensive accounting compliance data may enhance its effectiveness," particularly for the Llama-2-70b model which showed promise in detecting non-compliance.
- Why unresolved: The study restricted its evaluation to "out-of-the-box" model capabilities without performing or measuring the impact of domain-specific training.
- What evidence would resolve it: A comparative study evaluating the performance delta of Llama-2-70b before and after fine-tuning on comprehensive IFRS and HGB datasets, specifically measuring improvements in the 'Unclear' and 'Not Applicable' classes.

### Open Question 2
- Question: How can the significant performance gap between English (IFRS) and German (HGB) regulatory standards be mitigated in open-source LLMs?
- Basis in paper: [explicit] The authors note that performance was "significantly worse on HGB data than on IFRS data across all models" and suggest this is likely because "majority of LLMs are likely to exhibit sub-optimal performance on non-English datasets."
- Why unresolved: The paper identifies the linguistic limitation (English-centric training) as the likely cause for the 10-30% drop in F1 scores for HGB data but does not propose or test solutions to bridge this gap.
- What evidence would resolve it: Experiments testing multilingual training data or translation-based pipelines that result in statistical parity between IFRS and HGB compliance detection scores.

### Open Question 3
- Question: Is it possible to develop a universal prompting strategy for compliance tasks, or is custom-tailoring strictly necessary for different model architectures?
- Basis in paper: [explicit] The authors state that "there is no one-size-fits-all prompt" and that "different LLMs responded optimally to varied prompts," noting specifically that advanced techniques like Chain-of-Thought did not consistently outperform simpler prompts.
- Why unresolved: The evaluation of eight prompt configurations revealed high variance in effectiveness depending on the model, leaving the practical implementation of a standardized system undefined.
- What evidence would resolve it: Identification of a prompting framework that yields consistently high Micro F1-scores across both GPT and Llama-2 architectures without requiring parameter-specific optimization.

## Limitations
- The study relies on a private dataset from PwC Germany, limiting external validation and generalizability
- Significant performance gap for German-language compliance checks reflects fundamental limitations of current open-source LLMs
- No model successfully detected the "Unclear" class, suggesting the task formulation may be too ambiguous for current LLM capabilities
- Absence of cost-benefit analysis between proprietary and open-source solutions leaves practical deployment decisions unsupported

## Confidence
- **High Confidence**: GPT-4 outperforms other models on overall micro F1 scores across both IFRS and HGB datasets; constrained JSON output formats improve reliability over open-ended responses
- **Medium Confidence**: Llama-2-70b excels at detecting non-compliance ("No" class) with 87.50% F1 on IFRS data, given this is based on proprietary data that cannot be independently verified
- **Low Confidence**: One-shot examples with brief prompts consistently outperform more complex reasoning strategies, as the paper notes contradictory results

## Next Checks
1. **Independent Dataset Replication**: Construct an open dataset using publicly available IFRS requirements and SEC EDGAR financial reports to verify whether Llama-2-70b maintains its strong "No" class detection performance (87.50% F1) on independently sourced data
2. **Multilingual Model Testing**: Evaluate multilingual open-source models (e.g., BloomZ, XGLM) on the HGB dataset to determine if language-specific pretraining can overcome the performance gap observed with English-trained models like Llama-2
3. **Hybrid System Cost Analysis**: Implement the proposed hybrid approach (Llama-2-70b for initial screening, GPT-4 for verification) and measure the actual reduction in API costs and processing time compared to using GPT-4 exclusively, while tracking changes in false positive rates