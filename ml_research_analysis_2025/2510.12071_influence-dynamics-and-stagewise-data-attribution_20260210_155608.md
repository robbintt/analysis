---
ver: rpa2
title: Influence Dynamics and Stagewise Data Attribution
arxiv_id: '2510.12071'
source_url: https://arxiv.org/abs/2510.12071
tags:
- influence
- data
- learning
- stagewise
- dynamics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces stagewise data attribution, a framework that
  tracks how training data influence changes dynamically during model development,
  particularly at phase transitions. By combining singular learning theory with Bayesian
  influence functions, the authors show that influence is not static but can change
  non-monotonically, including sign flips and sharp peaks aligned with learning transitions.
---

# Influence Dynamics and Stagewise Data Attribution

## Quick Facts
- **arXiv ID:** 2510.12071
- **Source URL:** https://arxiv.org/abs/2510.12071
- **Reference count:** 40
- **Key outcome:** Stagewise data attribution framework that tracks dynamic influence changes during model development, revealing non-monotonic influence patterns at phase transitions

## Executive Summary
This work introduces stagewise data attribution, a framework that tracks how training data influence changes dynamically during model development, particularly at phase transitions. By combining singular learning theory with Bayesian influence functions, the authors show that influence is not static but can change non-monotonically, including sign flips and sharp peaks aligned with learning transitions. They validate this in a hierarchical toy model and at scale in language models, where token-level influence changes correspond to known developmental stages like induction circuit formation. This approach reveals a dynamic, stage-dependent view of data influence, enabling better understanding of how models acquire knowledge over time.

## Method Summary
The framework combines singular learning theory with Bayesian influence functions to track dynamic data influence during training. For a given model checkpoint, posterior samples are generated using RMSProp-preconditioned SGLD with localization. Per-token losses are computed across these samples, and the Bayesian influence function (BIF) is calculated as the negative covariance between sample losses and a target function. This approach works for degenerate loss landscapes where classical influence functions fail. The method is validated through Leave-One-Out retraining comparisons in a hierarchical toy model and applied to language models to study developmental stages like induction circuit formation.

## Key Results
- Influence changes non-monotonically during development, including sign flips and sharp peaks at phase transitions
- BIF trajectories match Leave-One-Out retraining experiments in hierarchical toy model
- Token-level influence patterns in language models align with known developmental stages (induction heads, token structure learning)
- Phase transitions create distinct influence patterns through the interaction of between-phase and within-phase effects

## Why This Works (Mechanism)

### Mechanism 1: Bayesian Influence Functions Enable Degenerate-Landscape Attribution
Classical influence functions fail for neural networks due to singular Hessians at degenerate minima. BIF reformulates influence as negative covariance between observable and sample loss: `BIF(zi, ϕ) = −Cov_p(w|D)(ℓi(w), ϕ(w))`. This eliminates the Hessian inverse entirely, remaining well-defined at any training checkpoint, not just minima.

### Mechanism 2: Phase Transitions Drive Non-Monotonic Influence Changes
When the posterior concentrates in two distinct neighborhoods (phases U and V), total influence decomposes into within-phase and between-phase components. The between-phase term peaks when posterior mass splits evenly (πU ≈ πV ≈ 0.5) and is largest for samples on which the two phases disagree most.

### Mechanism 3: Stagewise Learning Maps to Hierarchical Structure Acquisition
In hierarchical learning, a sample helpful for one stage becomes harmful for another. Influence peaks correspond to branching points in representation-space trajectories, where coarse distinctions (animal vs. plant) give way to finer ones (mammal vs. bird).

## Foundational Learning

- **Singular Learning Theory (SLT):** Why needed: Provides theoretical basis for phase transitions in neural networks. Quick check: Can you explain why the free energy formula `Fn = nLn(w*) + λ(w*)log(n)` predicts phase transitions?
- **Influence Functions (classical formulation):** Why needed: Understanding classical IF assumptions reveals why they fail for neural networks. Quick check: What does `IF(zi, ϕ) = −∇ϕ(w*)^T H^(-1)(w*) ∇ℓi(w*)` measure, and why does H^(-1) become problematic?
- **Covariance decomposition and mixture models:** Why needed: The Law of Total Covariance derivation connects phase transitions to influence dynamics. Quick check: Given mixture posterior `p(w|D) = πU·p(w|U) + πV·p(w|V)`, how does Cov(ℓi, ℓj) decompose?

## Architecture Onboarding

- **Component map:** Hierarchical dataset -> 2-layer deep linear network -> RMSPropSGLD sampler -> Per-token loss extraction -> Covariance computation -> BIF matrix
- **Critical path:** Checkpoint loading → SGLD sampling (T steps × C chains) → Per-token loss extraction → Covariance computation → Group aggregation
- **Design tradeoffs:**
  - Localization strength γ: Higher γ keeps samples closer to checkpoint but may miss posterior structure
  - Step size ε: Too large → poor mixing; too small → slow exploration
  - Inverse temperature β: Controls posterior concentration; affects signal-to-noise in covariance estimates
  - Normalized vs. raw BIF: Normalized (Pearson correlation) more stable for LLMs; raw covariance better for toy models
- **Failure signatures:**
  - Flat influence trajectories: γ too high or sampling hasn't mixed
  - Noisy/unstable BIF: Step size too large or insufficient samples
  - Mismatch with LOO: SGLD hyperparameters poorly calibrated
  - No peaks at known transitions: Token classification may be mislabeled
- **First 3 experiments:**
  1. LLC calibration sweep: Validate SGLD hyperparameters by estimating local learning coefficient on toy model with known ground-truth LLC
  2. Toy model LOO validation: Compute BIF trajectories for data pairs, correlate with Leave-One-Out retraining
  3. Induction head detection: Train small transformer, compute BIF on synthetic sequences, verify spike aligns with induction score rise

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the theoretical gap between the Bayesian learning process of Singular Learning Theory (SLT) and the non-equilibrium dynamics of Stochastic Gradient Descent (SGD) be formally bridged?
- Basis in paper: [explicit] The authors explicitly identify the "link between the Bayesian learning process of SLT and the non-equilibrium dynamics of SGD" as the "primary theoretical gap."
- Why unresolved: The framework assumes SGD dynamics can be modeled by an idealized Bayesian process to predict phase transitions, but a rigorous mathematical derivation connecting the non-equilibrium optimizer to the Bayesian posterior remains undefined.
- What evidence would resolve it: A formal proof or derivation showing that SGD trajectories statistically approximate the Bayesian learning process, particularly during degenerate phase transitions.

### Open Question 2
- Question: How can stagewise data attribution be extended to provide a mechanistic account of how training samples shape specific internal features and circuits?
- Basis in paper: [explicit] The limitations section states that a "key direction is to move from a behavioral to a mechanistic account of influence" to understand "how they shape model internals such as features and circuits."
- Why unresolved: The current work focuses on behavioral influence (loss correlations) and developmental timing, but does not isolate the causal mechanisms within the model (e.g., specific attention heads or neurons) that are affected by the data during transitions.
- What evidence would resolve it: Causal tracing or attribution patching experiments that directly link dynamic influence peaks to the formation or modification of specific circuits, such as induction heads.

### Open Question 3
- Question: Can stagewise data attribution be utilized to actively steer model training by intervening on the data distribution at identified developmental transitions?
- Basis in paper: [inferred] The conclusion suggests the framework opens possibilities for "steering how models learn," but the paper only demonstrates passive observation of influence dynamics.
- Why unresolved: It is untested whether the identification of high-influence windows can be translated into an actionable intervention, such as a dynamic curriculum, that reliably improves generalization.
- What evidence would resolve it: Intervention experiments where specific data samples are re-weighted or ablated during critical transition windows identified by BIF, resulting in predictable changes in developmental trajectory.

## Limitations
- Theoretical gap between SLT's Bayesian learning and SGD's non-equilibrium dynamics remains unvalidated
- SGLD sampling quality directly impacts BIF reliability, but hyperparameter tuning lacks automated calibration
- Hierarchical toy model's simplicity may not capture full complexity of nonlinear networks' stagewise development
- Token-level influence relies on manual structural classification that may miss subtler developmental patterns

## Confidence

- **High:** BIF framework correctly computes influence for models with degenerate loss landscapes (validated via LOO comparison in toy model)
- **Medium:** Phase transitions drive non-monotonic influence changes (strong empirical support, but theoretical bridge from SLT to SGD incomplete)
- **Medium:** Stagewise influence patterns reflect hierarchical structure acquisition (well-supported in toy model, partially supported in LLMs via induction heads)

## Next Checks

1. **Extend LOO validation to nonlinear networks:** Apply toy model validation protocol (BIF vs. LOO correlation) to small MLP on hierarchical dataset to test BIF-LOO correspondence beyond linear models
2. **Automated phase detection:** Develop quantitative metrics to detect phase transitions from BIF trajectories and validate against known architectural transitions
3. **Ablation study on SGLD hyperparameters:** Systematically vary localization strength γ, step size ε, and temperature β across multiple model scales to identify robust hyperparameter ranges and failure modes