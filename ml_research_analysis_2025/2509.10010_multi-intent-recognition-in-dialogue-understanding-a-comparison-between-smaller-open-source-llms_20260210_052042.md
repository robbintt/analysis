---
ver: rpa2
title: 'Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller
  Open-Source LLMs'
arxiv_id: '2509.10010'
source_url: https://arxiv.org/abs/2509.10010
tags:
- intent
- data
- dialogue
- performance
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compares three smaller open-source Large Language Models
  (LLMs) on multi-label intent classification using the MultiWOZ 2.1 dialogue dataset.
  The models tested are Llama2-7B-hf, Mistral-7B-v0.1, and Yi-6B in a few-shot setup
  with 20 examples.
---

# Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs

## Quick Facts
- **arXiv ID**: 2509.10010
- **Source URL**: https://arxiv.org/abs/2509.10010
- **Reference count**: 29
- **Primary result**: Mistral-7B-v0.1 achieved highest F1-score of 0.50 on 14 intent classes using 20 examples from MultiWOZ 2.1 dataset

## Executive Summary
This paper evaluates three smaller open-source Large Language Models (LLMs) - Llama2-7B-hf, Mistral-7B-v0.1, and Yi-6B - on multi-label intent classification using the MultiWOZ 2.1 dialogue dataset. The study employs a few-shot learning approach with only 20 examples to assess the viability of these models for detecting complex multi-intent dialogues in task-oriented chatbots. Mistral-7B-v0.1 demonstrated superior performance with a weighted average F1-score of 0.50, outperforming the other models on 11 out of 14 intent classes.

The research provides a framework for evaluating small open-source LLMs in Natural Language Understanding (NLU) applications while highlighting the significant performance gap compared to supervised learning approaches. A BERT-based supervised learning method achieved an F1-score of 0.92, demonstrating that traditional approaches with sufficient training data still outperform few-shot LLMs. The study contributes valuable insights into the practical limitations and potential of smaller open-source models for multi-intent recognition in dialogue systems.

## Method Summary
The study employs a few-shot learning approach to evaluate three smaller open-source LLMs on multi-label intent classification. The models tested include Llama2-7B-hf, Mistral-7B-v0.1, and Yi-6B, all with approximately 7B parameters. The evaluation uses the MultiWOZ 2.1 dialogue dataset with 20 examples for few-shot training, testing the models' ability to classify 14 different intent classes. The research compares these few-shot results against a BERT-based supervised learning approach trained on the full dataset, providing a baseline for performance comparison. The evaluation metric focuses on weighted average F1-scores across the intent classes to assess model performance.

## Key Results
- Mistral-7B-v0.1 achieved the highest performance with weighted average F1-score of 0.50
- Mistral-7B-v0.1 outperformed other models on 11 out of 14 intent classes
- BERT-based supervised approach achieved significantly higher F1-score of 0.92
- Few-shot learning with only 20 examples showed moderate performance across all tested models

## Why This Works (Mechanism)
The few-shot performance of smaller open-source LLMs in multi-intent recognition works through their pre-trained language understanding capabilities, which allow them to generalize from limited examples. These models leverage their extensive pre-training on diverse text data to capture semantic relationships between dialogue contexts and intent labels, even with minimal fine-tuning. The multi-label nature of the task is handled through the models' ability to process sequential input and generate multiple intent classifications simultaneously, though performance is limited by the small sample size and complexity of multi-intent scenarios.

## Foundational Learning
- **Few-shot learning**: Why needed - enables model adaptation with minimal labeled data; Quick check - verify that models can generalize from 20 examples to unseen dialogue patterns
- **Multi-label classification**: Why needed - dialogues often contain multiple simultaneous intents; Quick check - ensure evaluation metrics properly handle multiple correct labels per example
- **Dialogue understanding**: Why needed - conversational context differs from single utterances; Quick check - validate that models maintain context across multi-turn dialogues
- **Intent classification**: Why needed - core task for task-oriented chatbots; Quick check - confirm that models can distinguish between semantically similar intent classes
- **Weighted F1-score**: Why needed - balances precision and recall across imbalanced classes; Quick check - verify that minority classes receive appropriate weight in evaluation

## Architecture Onboarding

**Component map**: Input dialogue → Tokenization → LLM processing → Intent probability generation → Multi-label classification output

**Critical path**: Tokenization -> LLM inference -> Intent classification -> Evaluation metrics

**Design tradeoffs**: Few-shot learning vs supervised learning (performance vs data efficiency), model size vs inference speed, pre-trained capabilities vs fine-tuning requirements

**Failure signatures**: Low F1-scores on minority intent classes, inability to detect multiple intents in single dialogue, confusion between semantically similar intents, performance degradation with complex multi-turn dialogues

**First experiments**:
1. Test each model's performance on single-intent dialogues to establish baseline capability
2. Evaluate model performance with increasing number of training examples (5, 10, 20) to assess sample efficiency
3. Compare few-shot performance against zero-shot classification using prompt engineering

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Small sample size (20 examples) may not represent real-world deployment scenarios
- Focus on only three specific 7B-parameter models limits generalizability
- Single dataset (MultiWOZ 2.1) evaluation raises questions about performance across different domains
- Does not explore intermediate solutions like few-shot fine-tuning of smaller models

## Confidence
- **High confidence**: The relative performance ranking of Mistral-7B-v0.1 over Llama2-7B-hf and Yi-6B on the tested dataset is well-supported by the results presented.
- **Medium confidence**: The assertion that few-shot LLMs are "viable" for multi-intent recognition, given their moderate F1=0.50 performance compared to supervised approaches.
- **Medium confidence**: The implication that smaller open-source LLMs have "potential" for NLU in task-oriented chatbots, though the study shows significant performance gaps compared to supervised methods.

## Next Checks
1. Replicate the experiment with 5-fold cross-validation on the MultiWOZ 2.1 dataset to assess result stability across different training splits.
2. Test the same models on at least two additional multi-intent dialogue datasets (e.g., Schema-Guided Dialogue Dataset, M2D) to evaluate generalizability.
3. Conduct ablation studies comparing few-shot performance against few-shot fine-tuning approaches (e.g., LoRA) with the same 20-example budget to identify optimal parameter-efficient methods.