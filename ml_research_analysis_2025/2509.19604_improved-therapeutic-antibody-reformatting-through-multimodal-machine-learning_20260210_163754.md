---
ver: rpa2
title: Improved Therapeutic Antibody Reformatting through Multimodal Machine Learning
arxiv_id: '2509.19604'
source_url: https://arxiv.org/abs/2509.19604
tags:
- scfv
- antibody
- features
- sequence
- parental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a multimodal ML framework for predicting antibody
  reformatting success (from IgG to scFv), combining sequence, structural, and biophysical
  features. They evaluate models under three realistic deployment scenarios with varying
  amounts of training data from new antibody families.
---

# Improved Therapeutic Antibody Reformatting through Multimodal Machine Learning

## Quick Facts
- arXiv ID: 2509.19604
- Source URL: https://arxiv.org/abs/2509.19604
- Reference count: 40
- The authors propose a multimodal ML framework for predicting antibody reformatting success (from IgG to scFv), combining sequence, structural, and biophysical features. They evaluate models under three realistic deployment scenarios with varying amounts of training data from new antibody families. Key results show that simple linear models using well-designed domain-specific features outperform large pretrained protein language models, particularly in the most challenging zero-shot setting. Their best multimodal model achieves over 88% AUROC for predicting synthesis failure on unseen antibody families, enabling prioritization of promising candidates and reducing experimental effort. The study demonstrates that multimodal features (sequence + structure + biophysics) consistently outperform unimodal approaches, with the largest gains in cross-family generalization.

## Executive Summary
This paper addresses the challenge of predicting synthesis success when reformatting therapeutic antibodies from full IgG to single-chain variable fragment (scFv) format. The authors develop a multimodal machine learning framework that combines sequence, structural, and biophysical features to predict reformatting outcomes. Their key insight is that simple linear models on domain-specific features outperform complex protein language models, especially when predicting success on antibody families not seen during training. The framework achieves over 88% AUROC in predicting synthesis failure on unseen families, enabling researchers to prioritize candidates and reduce experimental costs.

## Method Summary
The authors propose a multimodal ML framework combining three feature types: (1) Sequence features: AHo-aligned VH/VL sequences (152 residues each) one-hot encoded with linker type and orientation as categorical variables; (2) Structure features: Boltz-2 predicted IgG and scFv structures, aligned rigidly to extract per-residue Cα coordinates and RMSD; (3) Biophysical features: NaturalAntibody platform metrics including PSH, PNC, PPC, and SFvCSP from CDR loops. The framework uses logistic regression with L2 penalty (C=10 for classification) to predict synthesis success/failure. The model is evaluated across three split scenarios: scFv signature (within-family), Parental Family (zero-shot, new parents), and Target Family (few-shot, partial family overlap).

## Key Results
- Simple linear models on domain-specific features (one-hot + biophysical + structural coordinates) outperform large pretrained protein language models by +3.1 AUROC in the most challenging zero-shot Parental Family setting
- Multimodal features (sequence + structure + biophysics) consistently outperform any single modality, with the largest gains in cross-family generalization
- The best multimodal model achieves over 88% AUROC for predicting synthesis failure on unseen antibody families
- Per-residue structural coordinates from Boltz-2 predictions provide superior generalization signal compared to global RMSD metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining sequence, structure, and biophysical features improves generalization to unseen antibody families better than any single modality.
- Mechanism: Sequence features (one-hot) define the specific biochemical identity; structure features (Cα coordinates) define the geometric compatibility between the IgG and scFv formats; biophysical features quantify developability risks. When concatenated, these modalities provide complementary signals that reduce the variance of the model's predictions under distribution shift, preventing it from overfitting to spurious correlations in any single feature space.
- Core assumption: The modalities provide non-redundant information; i.e., structural stability is not perfectly predictable from sequence alone in this dataset.
- Evidence anchors:
  - [abstract] "multimodal features (sequence + structure + biophysics) consistently outperform unimodal approaches, with the largest gains in cross-family generalization."
  - [section 3.3] "dominant synergy arises between sequence and structure features."
  - [corpus] Indirect support from *CAME-AB* which finds cross-modality attention effective for binding sites, though no direct corpus evidence for this specific reformatting task.
- Break condition: If future datasets show structural deviation is perfectly correlated with specific sequence motifs, the multimodal advantage would diminish.

### Mechanism 2
- Claim: In low-data regimes with high distribution shift, simple linear models on sparse, domain-specific features outperform large pretrained protein language models (PLMs).
- Mechanism: PLMs (e.g., AbLang, DPLM2) encode dense representations from vast pretraining data, which may include irrelevant evolutionary signals or biases that do not transfer to the specific biophysics of reformatting. Linear models on one-hot encodings and explicit biophysical metrics impose a strong, simple inductive bias that focuses the learning capacity on the specific input variables present in the training set, reducing overfitting to noise from pretraining.
- Core assumption: The determinants of reformatting success are local and explicit (e.g., specific residues or charge patches) rather than requiring complex, distributed semantic understanding of the protein.
- Evidence anchors:
  - [abstract] "simple linear models using well-designed domain-specific features outperform large pretrained protein language models."
  - [section 3.2] "LogisticReg [on one-hot] significantly outperforms more complex embeddings: +3.1 AUROC... over AbLang."
  - [corpus] No direct corpus validation for this counter-intuitive finding; *Llama-Affinity* and others assume LLMs are beneficial, suggesting this result is specific to this low-data task.
- Break condition: If the training dataset scales by orders of magnitude, PLMs may eventually overcome their inductive bias limitations and surpass linear baselines.

### Mechanism 3
- Claim: Fine-grained structural coordinates between parental IgG and reformatted scFv provide a superior generalization signal compared to global structural metrics like RMSD.
- Mechanism: Global RMSD acts as a coarse summary that averages away critical local changes; it exhibits high heterogeneity across families (correlating positively in some, negatively in others), creating a noisy learning signal. In contrast, per-residue Cα coordinates preserve the spatial correspondence of individual residues, allowing the model to identify specific structural perturbations (e.g., in CDR loops or the VH-VL interface) that consistently predict synthesis failure across diverse families.
- Core assumption: Boltz-2 structural predictions are sufficiently accurate to detect these fine-grained perturbations, and synthesis failure is causally linked to specific local structural strains.
- Evidence anchors:
  - [appendix E.1] "rmsd alone carries little predictive signal (AUROC ≈ 50.0)... seq+struct is uniformly strongest."
  - [appendix E.2] "Several families exhibit a positive RMSD–yield relationship... others show the opposite trend."
  - [section 2.4] "Per-residue coordinate features offer a more fine-grained view, potentially capturing subtle local rearrangements."
- Break condition: If the structural predictor (Boltz-2) fails to accurately model the scFv linker conformation, the coordinate features will be garbage-in/garbage-out.

## Foundational Learning

- **Antibody Reformatting (IgG to scFv)**
  - Why needed here: This is the specific domain task. You must understand that converting a full IgG to a single-chain variable fragment (scFv) involves linking VH and VL domains with a peptide, which can destabilize the structure or prevent synthesis.
  - Quick check question: Why does removing the constant domains (Fc) and linking VH/VL introduce a risk of synthesis failure?

- **Distribution Shift (Parental Families)**
  - Why needed here: This is the core evaluation challenge. Models are trained on families of antibodies derived from one parent and tested on a completely new parent. Understanding this shift explains why PLMs fail and why robust features are needed.
  - Quick check question: In the "Parental Family split," why is memorization of training sequences insufficient for success?

- **Feature Inductive Bias (Linear vs. Deep)**
  - Why needed here: The paper's counter-intuitive result relies on this. Understanding when to use simple linear models vs. deep representations is critical for architecting the solution.
  - Quick check question: In a dataset with only 1,477 samples and high variance between families, why might a high-capacity PLM embedding perform worse than a one-hot vector?

## Architecture Onboarding

- Component map:
  - VH/VL Amino Acid Sequences -> AHo-alignment -> One-Hot Encoding (Branch A)
  - VH/VL Amino Acid Sequences -> Boltz-2 Prediction (IgG & scFv) -> Rigid Alignment -> Extract Cα Coordinates (Branch B)
  - VH/VL Amino Acid Sequences -> NaturalAntibody Platform -> Extract PSH/PNC/PPC (Branch C)
  - Concatenate Features -> Logistic Regression (L2 penalty) (Head)

- Critical path: The **Boltz-2 structure prediction** is the compute bottleneck and the primary source of potential error. If structural features are misaligned or inaccurate, the multimodal gain is lost.

- Design tradeoffs: The authors chose **Logistic Regression** over MLPs for the final multimodal model to maintain interpretability and reduce overfitting, trading off potential non-linear interactions for robust zero-shot performance.

- Failure signatures:
  - PLM-based models achieving <55% AUROC on the Parental-Family split (worse than random guessing in some cases).
  - High variance (std > 15%) in cross-family evaluation metrics.

- First 3 experiments:
  1. **Baseline Sanity Check:** Train a Logistic Regression on *only* one-hot VH/VL sequences on the scFv split to establish the "easy" performance baseline.
  2. **Zero-Shot Stress Test:** Retrain the baseline on the Parental-Family split to quantify the performance drop due to distribution shift.
  3. **Multimodal Integration:** Add the Boltz-2 coordinate features and verify the recovery of AUROC (>80%) in the zero-shot setting, confirming the mechanism works.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can explicit family-context mechanisms resolve the heterogeneous, family-specific structural-to-yield relationships observed across parental families?
- Basis in paper: [explicit] Appendix E.2 notes that "family-specific behavior implies non-stationarity" and suggests incorporating family context via "conditional/mixture-of-experts" gates to handle conflicting RMSD–yield signals.
- Why unresolved: The current linear models treat families uniformly, causing them to regress to a weak average effect when RMSD correlations flip signs across families.
- Evidence: Evaluating conditional models or mixture-of-experts architectures that weight features based on parental family identifiers.

### Open Question 2
- Question: Does the superiority of domain-specific features over protein language models (PLMs) persist as the training dataset scales beyond 1,477 samples?
- Basis in paper: [inferred] The paper notes PLMs fail to outperform linear baselines, but the "ML Considerations" section (Appendix B) suggests the dataset is "limited for modern machine learning" and would "benefit from additional data."
- Why unresolved: It is unclear if the PLM failure is due to the fundamental irrelevance of their embeddings or simply the low-data regime where fine-tuning is ineffective.
- Evidence: Generating learning curves that compare linear multimodal models against PLMs as training data volume increases.

### Open Question 3
- Question: Is the framework effective for other reformatting transitions (e.g., IgG to Fab or bispecifics) where domain connectivity and steric constraints differ significantly?
- Basis in paper: [explicit] The Introduction acknowledges various formats (Figure 1) but the methodology is restricted to IgG→scFv conversion.
- Why unresolved: The specific biophysical features (e.g., linker stress, VH/VL orientation) are tailored to the single-chain constraint of scFvs and may not translate to other multi-domain assemblages.
- Evidence: Applying the multimodal pipeline to datasets involving the reformatting of antibodies into Fabs or bispecific T-cell engagers.

## Limitations
- The paper relies on proprietary antibody synthesis data and the NaturalAntibody platform, preventing direct reproducibility
- The framework is validated only for IgG→scFv reformatting, limiting generalizability to other therapeutic antibody formats
- The accuracy of Boltz-2 structural predictions for scFv conformations is assumed but not independently verified

## Confidence
- **High Confidence:** The multimodal feature superiority over unimodal approaches (AUROC >88%) and the linear model outperforming PLMs on sparse data are well-supported by the experimental results across multiple split scenarios.
- **Medium Confidence:** The mechanism that fine-grained structural coordinates outperform global RMSD relies on Boltz-2 prediction accuracy, which is not independently verified.
- **Low Confidence:** The claim that sequence-structure-biophysics modalities provide non-redundant information assumes no perfect correlation exists in the dataset, which is difficult to definitively establish.

## Next Checks
1. **Structure Prediction Validation:** Compare Boltz-2-predicted scFv structures against experimentally solved structures for a subset of antibodies to quantify prediction accuracy and its impact on feature quality.
2. **Dataset Generalization Test:** Apply the best-performing multimodal model to a completely independent antibody reformatting dataset (if available) to assess cross-dataset generalization beyond the Parental-Family split.
3. **Feature Ablation on Synthetic Data:** Generate synthetic antibody families with controlled structural perturbations and systematically ablate each modality (sequence, structure, biophysics) to quantify the individual contribution of each feature type to prediction performance.