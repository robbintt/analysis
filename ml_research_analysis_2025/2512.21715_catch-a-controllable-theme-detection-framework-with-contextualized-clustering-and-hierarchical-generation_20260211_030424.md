---
ver: rpa2
title: 'CATCH: A Controllable Theme Detection Framework with Contextualized Clustering
  and Hierarchical Generation'
arxiv_id: '2512.21715'
source_url: https://arxiv.org/abs/2512.21715
tags:
- theme
- topic
- clustering
- label
- catch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CATCH, a controllable theme detection framework
  for dialogue systems that jointly addresses theme segmentation and generation while
  incorporating user preference alignment. The framework uses a dual-branch segmentation
  model to enrich short utterances with context, applies preference-guided clustering
  to ensure consistency across dialogues, and employs a hierarchical generation mechanism
  for structured theme labeling.
---

# CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation

## Quick Facts
- arXiv ID: 2512.21715
- Source URL: https://arxiv.org/abs/2512.21715
- Reference count: 13
- Authors: Rui Ke; Jiahui Xu; Shenghao Yang; Kuang Wang; Feng Jiang; Haizhou Li
- One-line primary result: Second place in DSTC-12 theme detection with 8B model, outperforming baselines in clustering accuracy (56.7%), label quality (42.4% ROUGE-L), and human semantic relevance (86.3%)

## Executive Summary
This paper introduces CATCH, a three-stage framework for controllable theme detection in dialogue systems. It jointly addresses theme segmentation and generation while incorporating user preference alignment. The framework uses a dual-branch segmentation model to enrich short utterances with context, applies preference-guided clustering to ensure consistency across dialogues, and employs a hierarchical generation mechanism for structured theme labeling. Evaluated on the DSTC-12 benchmark, CATCH achieves strong performance in both automatic and human evaluations, demonstrating effectiveness in low-resource and cross-domain settings while maintaining a lightweight architecture.

## Method Summary
CATCH operates through a three-stage pipeline: (1) Context-aware segmentation using a dual-branch BERT encoder (Topic + Coherence) with TextTiling to detect boundaries and create topic segments, (2) Preference-enhanced clustering using MPNet embeddings with a Preference Reward Model to incorporate user constraints through a 4-step algorithm, and (3) Hierarchical theme label generation using LLaMA-3-8B with a three-step process (intra-group labeling → majority-vote cleaning → consolidation). The system is trained on DSTC-12 Banking domain dialogues with preference pairs and evaluated across multiple domains without additional training.

## Key Results
- CATCH achieved second place in DSTC-12 with clustering accuracy up to 56.7% and ROUGE-L scores up to 42.4%
- Demonstrated strong generalization across domains (Banking, Finance, Insurance, Travel) with Avg 67.5 label quality score
- Human evaluation showed 86.3% semantic relevance and 83.2% actionability
- Ablation studies confirmed the effectiveness of each component, with GSP (direct SP clustering) failing catastrophically (Acc 15.4%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enriching sparse utterance representations with segment-level context appears to stabilize topic embeddings for downstream clustering.
- **Mechanism:** The system employs a dual-branch encoder (Topic + Coherence) to detect boundaries and groups utterances into "topic segments." Instead of clustering single utterances, it aggregates embeddings within these segments. This pools semantic information, reducing the noise inherent in short, sparse user statements.
- **Core assumption:** Adjacent utterances in a dialogue belong to the same latent topic unless a boundary is detected.
- **Evidence anchors:** [abstract] "...enriches utterance-level semantics using surrounding topic segments..."; [section: Context-Aware Intra-Dialogue Theme Representation] "Each utterance representation is then enriched by aggregating contextual information from its corresponding segment."; [corpus] Neighbors like "DASH" confirm that dialogue-aware segmentation is a critical precursor for topic handling in noisy channels.

### Mechanism 2
- **Claim:** Distorting semantic distance with preference scalars likely allows the system to satisfy user constraints without abandoning semantic geometry.
- **Mechanism:** A Preference Reward Model (PRM) predicts a "linking tendency" ($w_{x,y}$) between topic pairs. The system uses a Semantic-Preference (SP) kernel: $d_{SP} = w \cdot d_{sem}$. Crucially, it does not cluster directly in this space; it identifies "conflict" pairs where preference contradicts semantic clustering and re-clusters only those subsets.
- **Core assumption:** The PRM can generalize binary preference feedback (should-link/cannot-link) to unseen topic pairs.
- **Evidence anchors:** [abstract] "...preference-guided clustering to ensure consistency across dialogues..."; [section: Preference-Enhanced Topic Clustering] "We propose a four-step algorithm grounded in semantic space but progressively incorporating preference signals."; [corpus] Evidence is weak in direct neighbors; standard clustering papers (e.g., BERTopic) focus solely on semantics, highlighting this specific preference-injection as a novel divergence.

### Mechanism 3
- **Claim:** Hierarchical summarization appears to act as a denoising filter, allowing the system to generate robust labels even from imperfect clusters.
- **Mechanism:** Rather than forcing an LLM to label a potentially messy cluster in one shot, the system splits clusters into subgroups → generates local labels → votes for a "Core" label → filters outliers → concludes. This "divide-and-conquer" prevents noisy utterances from dominating the generation prompt.
- **Core assumption:** The "Core" label derived from the majority of subgroups accurately represents the ground truth theme.
- **Evidence anchors:** [abstract] "...hierarchical generation mechanism designed to suppress noise..."; [section: Hierarchical Theme Label Generation] "Group-level labels may include inconsistent or noisy descriptions. To filter these, we prompt LLM to identify a core label... and retain only those... relevant."; [corpus] Fractal Flow (neighbor) supports hierarchical strategies for interpretability, though CATCH specifically uses it for noise suppression.

## Foundational Learning

- **Concept: Contrastive Learning (InfoNCE)**
  - **Why needed here:** Required to train the Topic and Coherence encoders in the segmentation module without massive labeled datasets.
  - **Quick check question:** Can you distinguish between "positive" pairs (neighboring utterances) and "negative" pairs (random samples) in the loss function?

- **Concept: Metric Learning & Distance Kernels**
  - **Why needed here:** Essential for understanding how CATCH fuses semantic Euclidean distance with preference scalars ($d_{SP}$) to manipulate cluster shapes.
  - **Quick check question:** How does multiplying a distance by a scalar $< 1$ (preference link) affect the effective radius of a cluster boundary?

- **Concept: Chain-of-Thought (CoT) Prompting**
  - **Why needed here:** The Hierarchical Generation stage relies on multi-step reasoning (Vote → Filter → Conclude) rather than direct mapping.
  - **Quick check question:** Does the model generate the final label immediately, or does it output intermediate reasoning steps (Core label) first?

## Architecture Onboarding

- **Component map:** TopSeg (BERT dual encoders + TextTiling) -> PeC (MPNet embeddings + PRM + 4-step clustering) -> HieGen (LLaMA3-8B hierarchical prompts)
- **Critical path:** The **Preference-Enhanced Clustering (PeC)** logic is the most complex implementation detail. Specifically, the "Conflict Identification" (Step 3) and "Reassignment" (Step 4) determine whether the system actually respects user preferences or defaults to semantic clustering.
- **Design tradeoffs:** 4-Step vs. Direct Clustering: The paper ablates "GSP" (direct SP clustering), which failed catastrophically (Acc 15.4%). You must anchor in semantic space first and adjust. Cluster Number $K$: Set to 30 default. Too low merges distinct themes; too high fragments them. Model Size: Uses 8B LLM to remain "lightweight." Moving to a smaller model might break the "IsRelevant" filtering capability.
- **Failure signatures:** Label Drift: Final labels describe specific subgroups rather than the cluster whole (HieGen voting failure). Over-fragmentation: High boundary detection frequency leads to tiny segments, preventing meaningful context enrichment. Preference Overfitting: PRM forces unnatural groupings, visible as low NMI scores despite high preference satisfaction.
- **First 3 experiments:** 1. TopSeg Validation: Run the dual-branch segmenter on a held-out set and visualize boundary accuracy vs. semantic similarity; verify context pooling actually increases embedding density. 2. PRM Sensitivity: Vary the preference threshold ($\theta_l, \theta_s$) to observe how "link" and "split" constraints distort the cluster geometry. 3. Ablation on Noise: Inject random noise into clusters and measure if HieGen's "VoteCore" mechanism successfully rejects the noise compared to a flat generation prompt.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can CATCH be adapted to support proactive dialogue systems and real-time dialogue control?
- **Basis in paper:** [explicit] The conclusion states the authors plan to "enable its application to a broader range of downstream scenarios, such as proactive dialogue systems, dialogue control, and fine-grained dialogue analysis."
- **Why unresolved:** The current framework functions as an off-line detection and labeling pipeline; it does not possess a mechanism to utilize identified themes for predicting future user needs or influencing dialogue policy in real-time.
- **What evidence:** Successful integration of CATCH's output into a dialogue manager that triggers unsolicited information delivery or topic transitions, validated by user satisfaction metrics in a live interaction setting.

### Open Question 2
- **Question:** Can the discrepancy between high label quality and low clustering accuracy on unseen domains be resolved without proprietary models?
- **Basis in paper:** [inferred] In the blind test (Table 5), CATCH achieved high label quality (Avg 67.5) but relatively low clustering accuracy (35.8%) compared to the top team (68.0%), suggesting the clustering module struggles to generalize as effectively as the generation module.
- **Why unresolved:** While hierarchical generation (HieGen) is robust to clustering noise, the underlying semantic clustering (PeC) appears brittle in cross-domain settings (Travel), limiting the system's ability to consistently group utterances without the aid of large proprietary models (API).
- **What evidence:** An architectural modification that couples clustering and generation objectives more tightly, resulting in concurrent high scores (e.g., >60%) for both NMI and ROUGE on blind test sets using only open-source models.

### Open Question 3
- **Question:** How does the Preference Reward Model (PRM) perform in zero-shot settings or when preference annotations are extremely sparse?
- **Basis in paper:** [inferred] The methodology relies on "low resource user preference annotation" to train the PRM, but the paper does not establish the minimum data threshold or the performance degradation curve as supervision approaches zero.
- **Why unresolved:** It is unclear if the "preference-guided" aspect of the framework collapses entirely without specific annotated pairs, reverting the system to a purely semantic clustering approach.
- **What evidence:** An ablation study evaluating clustering accuracy (Acc) and label alignment across varying numbers of preference annotations (e.g., 0, 10, 50, 100 pairs) to identify the breaking point of the preference alignment mechanism.

## Limitations
- Evaluation relies entirely on DSTC-12 data, which may not generalize to open-domain or non-dialogue scenarios
- Segmentation module performance depends on fixed TextTiling hyperparameters (window size, threshold=0.5) without ablation
- PRM training uses only 164 preference pairs for Banking domain, raising overfitting concerns
- Hierarchical generation effectiveness depends on undisclosed prompt engineering quality
- 8B model choice is lightweight but scaling effects on performance are unexplored

## Confidence

- **High confidence:** The core segmentation-enrichment mechanism (Mechanism 1) is well-supported by the dual-branch encoder design and ablation evidence (GSP failure)
- **Medium confidence:** The preference-guided clustering (Mechanism 2) is plausible but relies on an under-specified PRM and conflict resolution algorithm; the assumption that PRM generalizes binary preferences is not empirically validated
- **Medium confidence:** The hierarchical generation (Mechanism 3) is logically sound, but the claim that voting suppresses noise depends on the assumption that majority clusters are always correct—this is not tested in highly impure cases

## Next Checks

1. **Segmentation robustness test:** Systematically vary TextTiling's window size and threshold on a held-out set; measure the impact on segment coherence (average intra-segment similarity) and downstream clustering accuracy. This will quantify how sensitive the context enrichment is to segmentation hyperparameters.

2. **PRM generalization probe:** Hold out a subset of preference pairs during PRM training and evaluate its accuracy on unseen pairs. Additionally, test the PRM on synthetic preference constraints (e.g., randomly sampled should-link/cannot-link) to measure false positive/negative rates and their effect on clustering distortion.

3. **Hierarchical generation stress test:** Construct synthetic clusters with known impurity levels (e.g., 60/40, 50/50 theme splits) and measure whether HieGen's VoteCore mechanism correctly identifies the majority theme and rejects the minority. Compare against a flat generation baseline to isolate the benefit of the hierarchical approach.