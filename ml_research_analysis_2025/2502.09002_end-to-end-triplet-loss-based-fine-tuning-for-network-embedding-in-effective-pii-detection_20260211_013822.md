---
ver: rpa2
title: End-to-End triplet loss based fine-tuning for network embedding in effective
  PII detection
arxiv_id: '2502.09002'
source_url: https://arxiv.org/abs/2502.09002
tags:
- features
- data
- embedding
- used
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the detection of personally identifiable information
  (PII) leakage in mobile network traffic using deep learning. The proposed framework
  processes network flows represented in tabular format, employing a pre-trained large
  language model and an autoencoder to generate embeddings, followed by triplet-loss
  based fine-tuning to improve detection accuracy.
---

# End-to-End triplet loss based fine-tuning for network embedding in effective PII detection

## Quick Facts
- arXiv ID: 2502.09002
- Source URL: https://arxiv.org/abs/2502.09002
- Authors: Rishika Kohli; Shaifu Gupta; Manoj Singh Gaur
- Reference count: 34
- Primary result: Achieved 95.68% test accuracy for PII detection using triplet-loss fine-tuning on network flow embeddings

## Executive Summary
This paper presents a deep learning framework for detecting personally identifiable information (PII) leakage in mobile network traffic. The approach processes network flows represented as tabular key-value pairs, using pre-trained sentence embeddings (SBert) to capture semantic relationships between features, followed by autoencoder compression and triplet-loss fine-tuning to improve detection accuracy. Evaluated on ReCon and AntShield datasets, the framework achieves state-of-the-art performance with up to 95.68% accuracy, outperforming existing methods while addressing challenges like overfitting and dimensionality reduction through regularization and PCA.

## Method Summary
The framework processes tabular network flows by first generating 384-dimensional embeddings for each feature value using the SBert model (all-MiniLM-L6-v2). These embeddings pass through an autoencoder (384→128→64→32) to compress them while maintaining semantic relationships. Inter-feature cosine similarity (IFCS) differences between original and compressed embeddings are computed using Wasserstein Distance or KL-Divergence to identify features with high information loss. Triplet-loss fine-tuning is then applied using hard or soft mining strategies on these high-loss features. The final classification uses flattened and PCA-reduced embeddings fed into an MLP classifier, with component selection determined by elbow detection using the kneedle algorithm.

## Key Results
- Achieved 95.68% test accuracy on ReCon dataset and 96.90% on AntShield dataset for PII detection
- Outperformed existing state-of-the-art methods in both binary classification and multi-label PII type identification
- KL-Divergence with hard mining (HM-2) showed best performance, replacing all embeddings rather than selective replacement
- Demonstrated effectiveness of triplet-loss fine-tuning in recovering semantic relationships lost during autoencoder compression

## Why This Works (Mechanism)

### Mechanism 1
Pre-trained sentence embeddings capture semantic relationships between structurally similar network features better than randomly initialized tokenizers. SBert generates 384-dimensional embeddings that place semantically related features (e.g., 'referer'/'referrer', 'google aid'/'user id') closer in vector space, leveraging its training on 1B+ sentence pairs to learn semantic similarity via siamese network architectures.

### Mechanism 2
Triplet-loss fine-tuning selectively recovers inter-feature relationships lost during autoencoder compression. The method computes IFCS differences using Wasserstein Distance or KL-Divergence between original and compressed embeddings, selecting features with high loss for triplet mining. Hard mining selects max-similarity positive and min-similarity negative pairs, while soft mining uses threshold-based random sampling.

### Mechanism 3
PCA dimensionality reduction after embedding flattening mitigates the curse of dimensionality and improves MLP classification. Flattened embeddings can exceed sample counts (e.g., 19,683 samples vs. 22,144 dimensions), so PCA reduces to 280-395 principal components selected via scree plot elbow detection with the kneedle algorithm, improving classification accuracy from 79.38% to 93.86%.

## Foundational Learning

- **Concept: Triplet Loss and Metric Learning**
  - Why needed: Core mechanism for recovering compressed embedding relationships through margin-based distance learning
  - Quick check: Given anchor A, positive P, and negative N embeddings, what happens to the loss when cos(A,N) > cos(A,P) + α?

- **Concept: Autoencoder Bottleneck Representations**
  - Why needed: Dimensionality reduction from 384→32 dims must preserve semantic information while enabling tractable computation
  - Quick check: If reconstruction loss (MSE) is minimized but downstream task accuracy drops, what does this indicate about the bottleneck?

- **Concept: Tabular Data Transformers (Feature Tokenization)**
  - Why needed: Understanding why pre-trained embeddings are necessary vs. trainable tokenizers when FT-Transformer baseline failed
  - Quick check: Why might random weight initialization per feature fail to capture relationships between 'referer' and 'referrer'?

## Architecture Onboarding

- **Component map:** Input preprocessing → SBert embedding → Autoencoder compression → IFCS computation → Triplet mining → Triplet-loss fine-tuning → Flattening + PCA → MLP classifier

- **Critical path:** SBert embedding quality → autoencoder reconstruction fidelity → IFCS-based feature selection → triplet mining quality → PCA component count → MLP capacity. The paper shows IFCS metric choice (KL > WD) and mining strategy (hard > soft for KL) significantly impact accuracy.

- **Design tradeoffs:**
  - Autoencoder bottleneck size: 32 dims matches FT-Transformer but may be too aggressive; paper does not ablate this
  - Triplet mining strategy: Hard mining is deterministic but may select outliers; soft mining adds stochasticity but requires threshold tuning (60%/40% chosen empirically)
  - PCA components: 280-395 selected via scree plot; manual inspection of variance explained is recommended before deployment
  - Assumption: Replacing all embeddings (HM-2/SM-2) vs. only high-IFCS embeddings (HM-1/SM-1) trades coverage vs. potential noise injection

- **Failure signatures:**
  - Overfitting: Training >> validation accuracy (e.g., FT-Transformer: 99.96% train vs. 57.21% test)
  - Embedding collapse: t-SNE shows semantically similar features diverging post-compression
  - PII type coverage gap: Model cannot detect PII types not in training data

- **First 3 experiments:**
  1. Baseline sanity check: Run FT-Transformer on balanced ReCon/AntShield without modifications to confirm overfitting behavior
  2. Ablation: Replace SBert with random 384-dim embeddings → autoencoder → no triplet loss → PCA → MLP to quantify semantic embedding contribution
  3. Component sensitivity: Vary autoencoder bottleneck (16, 32, 64, 128 dims) and PCA components (100, 200, 300, 400) with fixed triplet loss settings to identify optimal compression/reduction balance

## Open Questions the Paper Calls Out

### Open Question 1
Can knowledge distillation effectively compress the proposed LLM-based embedding framework to run on resource-constrained mobile devices without dropping below the reported 95.68% accuracy? The current framework relies on a pre-trained Sentence Transformer and autoencoder, creating heavy computational burden unsuitable for real-time mobile execution.

### Open Question 2
How does the triplet-loss fine-tuning approach perform in a federated learning setting regarding detection accuracy and resilience against adversarial attacks? The current evaluation relies on centralized datasets, whereas federated learning introduces data heterogeneity and communication constraints that may disrupt embedding space alignment.

### Open Question 3
Can class-incremental learning be successfully integrated to dynamically detect new PII types unseen during training without catastrophic forgetting? The framework uses a fixed output layer, making it rigid against evolving data exfiltration patterns and new categories of personal data.

## Limitations
- Dataset-specific performance: Effectiveness validated only on ReCon and AntShield datasets; may degrade with different network traffic patterns or PII types
- Computational overhead: Pipeline involves multiple complex steps that may not scale efficiently to real-time or resource-constrained deployment
- Class-incremental learning gap: Framework cannot detect new PII types introduced after initial training, requiring complete retraining

## Confidence

- **High Confidence:** Using pre-trained SBert embeddings for semantic feature representation is well-established in NLP literature and directly supported by empirical comparisons
- **Medium Confidence:** IFCS-based triplet loss fine-tuning approach is theoretically sound with significant accuracy improvements, but specific thresholds and metric choices were empirically determined
- **Low Confidence:** Claims about real-world deployment readiness are unsupported, as the paper focuses on offline detection without addressing latency or computational constraints

## Next Checks

1. **Cross-dataset generalization test:** Evaluate the framework on an independent mobile network dataset with different feature distributions and PII types to assess domain transferability

2. **Real-time performance benchmarking:** Measure inference latency and resource utilization on typical edge devices to validate deployment feasibility claims

3. **Incremental learning experiment:** Test the framework's ability to adapt to new PII types through continuous learning or fine-tuning without complete retraining, quantifying accuracy degradation over time