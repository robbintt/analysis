---
ver: rpa2
title: BiRating -- Iterative averaging on a bipartite graph of Beat Saber scores,
  player skills, and map difficulties
arxiv_id: '2502.19742'
source_url: https://arxiv.org/abs/2502.19742
tags:
- scores
- maps
- player
- algorithm
- score
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents BiRating, a novel iterative averaging algorithm
  for estimating player skills and map difficulties in Beat Saber using only score
  data. The method models a bilinear relationship between player skill, map ease,
  and scores on a bipartite graph of players and maps.
---

# BiRating -- Iterative averaging on a bipartite graph of Beat Saber scores, player skills, and map difficulties

## Quick Facts
- **arXiv ID:** 2502.19742
- **Source URL:** https://arxiv.org/abs/2502.19742
- **Authors:** Juan Casanova
- **Reference count:** 15
- **Primary result:** Achieved mean absolute error of ~0.156 on 850K+ Beat Saber scores using iterative bilinear averaging

## Executive Summary
BiRating presents a novel unsupervised algorithm for jointly estimating player skills and map difficulties in Beat Saber using only score data. The method models scores as the product of player skill and map ease, operating on a bipartite graph of players and maps through iterative averaging. By transforming scores into a linear space and leveraging connections between players who play the same maps and maps played by the same players, the algorithm converges on stable ratings without requiring labeled training data. The approach achieved a mean absolute error of approximately 0.156 and showed qualitative alignment with community-perceived difficulty.

## Method Summary
The algorithm uses a bilinear relationship where scores equal the product of player skill and map ease (Score = Skill Ã— Ease). It operates on a bipartite graph of players and maps, iteratively updating player skills by averaging skills implied by their scores on maps of known ease, and updating map ease by averaging ease implied by scores from players of known skill. Scores are transformed using a Beta distribution CDF followed by a truncated exponential percentile function to ensure linearity. The system filters out low-quality scores, uses only top 90% of scores per player/map, and stops when error change is minimal or error begins to increase.

## Key Results
- Achieved mean absolute error of approximately 0.156 on full dataset of 850K+ scores
- Qualitative evaluation by experienced community members showed significant alignment with perceived difficulty
- Identified limitations with linearity assumptions and data quality issues affecting certain map types
- Outperformed existing methods for problematic maps with divergent pass/accuracy difficulties

## Why This Works (Mechanism)

### Mechanism 1: Bilinear Factorization of Scores
The algorithm assumes a multiplicative relationship where scores equal the product of player skill and map ease. By rearranging this relationship, the system can estimate one unknown variable if the other two are known. This works when scores are transformed into a linear space, but fails if raw scores are used directly due to Beat Saber's non-linear scoring distribution.

### Mechanism 2: Iterative Averaging on a Bipartite Graph
Alternating averages between connected players and maps allows the system to converge on stable skill and difficulty ratings without labeled training data. The graph's connectivity ensures errors cancel out during averaging, driving the system toward a low-error state. However, incompatible score patterns can cause oscillation rather than convergence.

### Mechanism 3: Probabilistic Score Linearization
Raw scores must be transformed into a linear "value" space to satisfy the bilinear model's assumptions. The system uses a Beta distribution to capture score shape and a truncated exponential distribution to weigh higher scores more heavily, mapping non-linear raw scores (0.0-1.0) to linear values (0-100). Misconfigured distribution parameters can flatten the skill gradient.

## Foundational Learning

- **Concept: Bipartite Graphs** - Essential for visualizing how the algorithm propagates data between two distinct sets (Players and Maps) with edges only connecting across sets. Quick check: Can two player nodes be directly connected in this graph?

- **Concept: Fixed-Point Iteration** - The algorithm seeks a "fixed point" where ratings stop changing significantly. Understanding convergence criteria is necessary to debug why the algorithm might stop too early or run forever. Quick check: If error starts increasing after 5 iterations, what does the `finish_early` flag do?

- **Concept: Mean Absolute Error (MAE) vs. RMSE** - The paper explicitly chooses MAE to preserve linear properties and reduce influence of massive outliers. Quick check: Why would Root Mean Square Error (RMSE) be a poor choice if we want to ignore the impact of a few disastrous scores?

## Architecture Onboarding

- **Component map:** Input -> Preprocessor -> Graph Store -> Iterative Solver -> Evaluator
- **Critical path:** The Score Transformation step (Section 3.2) and the Top-Score Selection logic (Section 3.3). If scores are not linearized correctly, the iterative solver drifts. If outlier scores aren't filtered during averaging, the ratings become unstable.
- **Design tradeoffs:** 
  - Robustness vs. Data Volume: Discards lowest 10% of scores and 65% of old scores to improve signal-to-noise ratio
  - MAE vs. RMSE: MAE treats all deviations linearly, avoiding punishment of outliers inherent in RMSE
  - Convergence Speed vs. Stability: Halts when error change is small to trade potential accuracy for stability
- **Failure signatures:** Oscillation due to incompatible score patterns, stale data bias making older maps appear easier, large train/test gap suggesting poor generalization
- **First 3 experiments:**
  1. Verify Linearization: Run preprocessing on sample dataset and plot transformed score histogram to ensure uniform/normal distribution
  2. Convergence Profiling: Run solver for 50 iterations on subset data and plot MAE per iteration to verify U-shape curve
  3. Hyperparameter Sensitivity: Run grid search on beta_alpha and beta_beta parameters to test impact on final MAE

## Open Questions the Paper Calls Out

### Open Question 1
Can the theoretical convergence of the BiRating iterative averaging process be formally proven, specifically characterizing conditions required for existence of fixed points and contractiveness? The authors state they haven't proven existence of fixed points for every set of possible scores or characterized conditions guaranteeing convergence.

### Open Question 2
How can the algorithm be extended to model multidimensionality of player skill and map difficulty rather than collapsing them into a single scalar value? The current bilinear model inherently assumes multiple dimensions can be quantified in a single number.

### Open Question 3
Can the BiRating framework be adapted to utilize multi-parameter curves to distinguish between different types of difficulty (e.g., passing difficulty vs. accuracy difficulty) within a single map? Current uniparameter curves cannot capture nuances like maps that are easy to pass but hard to full-combo.

### Open Question 4
How can the algorithm mitigate systematic biases in score data, such as score optimization on older maps or low engagement on disliked maps? The algorithm treats all scores as accurate reflections of skill and difficulty, lacking mechanisms to account for temporal effects or engagement patterns.

## Limitations

- The bilinear model's assumption of multiplicative relationship may oversimplify complex player-map interactions
- Performance heavily dependent on quality and recency of input data, with older scores potentially introducing significant bias
- Reliance on score value transformation means miscalibration of Beta/exponential parameters could systematically distort difficulty estimates

## Confidence

- **High Confidence**: Core iterative averaging algorithm and its convergence properties are well-defined and reproducible
- **Medium Confidence**: Score linearization methodology achieves stated target MAE but exact implementation details remain partially unspecified
- **Low Confidence**: Qualitative evaluation of difficulty estimates against community perception lacks systematic measurement criteria

## Next Checks

1. **Distribution Validation**: Generate and analyze histograms of transformed score values to verify they approximate expected uniform/normal distribution rather than retaining original skewed pattern.

2. **Cross-Platform Verification**: Apply algorithm to Beat Saber score data from multiple platforms (Steam, Oculus, PSVR) to test robustness against platform-specific scoring variations and player pools.

3. **Mechanic-Specific Analysis**: Segment evaluation by map mechanics (e.g., one-handed, precision-intensive, speed-focused) to identify whether bilinear model systematically over/under-estimates difficulty for certain map types.