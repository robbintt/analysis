---
ver: rpa2
title: 'SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine'
arxiv_id: '2506.13983'
source_url: https://arxiv.org/abs/2506.13983
tags:
- assertions
- signal
- node
- each
- specification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces SANGAM, a framework that uses LLM-guided
  Monte Carlo Tree Search (MCTS) to automatically generate SystemVerilog Assertions
  (SVAs) from multi-modal specifications. The framework employs a three-stage approach:
  Specification Processing (using Signal Mapper, Spec Analyzer, and Waveform Analyzer
  LLMs), Assertion Reasoning (using MCTS with self-refinement), and Assertion Combination
  (deduplication and syntax correction).'
---

# SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine

## Quick Facts
- arXiv ID: 2506.13983
- Source URL: https://arxiv.org/abs/2506.13983
- Reference count: 26
- This paper introduces SANGAM, a framework that uses LLM-guided Monte Carlo Tree Search (MCTS) to automatically generate SystemVerilog Assertions (SVAs) from multi-modal specifications. The framework employs a three-stage approach: Specification Processing (using Signal Mapper, Spec Analyzer, and Waveform Analyzer LLMs), Assertion Reasoning (using MCTS with self-refinement), and Assertion Combination (deduplication and syntax correction). SANGAM generates twice as many assertions as state-of-the-art methods (AssertLLM and ChIRAAG), with coverage analysis showing above 90% branch and toggle coverage and 74% property coverage for tested designs (I2C and RV-Timer).

## Executive Summary
This paper presents SANGAM, a framework for automatically generating SystemVerilog Assertions (SVAs) from multi-modal specifications using a three-stage pipeline: Specification Processing, Assertion Reasoning via Monte Carlo Tree Search with self-refinement (MCTSr), and Assertion Combination. The approach leverages specialized LLM agents to decompose specifications into signal-wise information, then uses MCTSr with dual feedback (critic and formal verification) to iteratively refine assertions. The framework demonstrates significant improvements over state-of-the-art methods, generating twice as many assertions with above 90% branch and toggle coverage for tested designs.

## Method Summary
SANGAM operates through three stages: (1) Specification Processing uses three LLM agents (Signal Mapper, Spec Analyzer, Waveform Analyzer) to create a Signal-Wise Information Bank from multi-modal inputs; (2) Assertion Reasoning employs MCTSr with n_rollouts=4, using UCT selection, dual feedback from Critic LLM and JasperGold syntax logs, and RAG-retrieved SVA documentation for expansion; (3) Assertion Combination separates assertions into syntax-correct and incorrect sets via JasperGold, corrects the latter with a Correction LLM, and deduplicates the final set with a Deduplication LLM.

## Key Results
- Generated twice as many assertions as state-of-the-art methods (AssertLLM and ChIRAAG)
- Achieved above 90% branch and toggle coverage for tested designs (I2C and RV-Timer)
- Demonstrated 74% property coverage across benchmark designs

## Why This Works (Mechanism)

### Mechanism 1: Multi-Modal Specification Decomposition into Signal-Wise Information Bank
Processing specifications through specialized LLM agents creates structured, signal-specific knowledge that improves assertion completeness. Three LLMs operate in parallel—Signal Mapper links Verilog signals to specification descriptions; Spec Analyzer extracts definition, functionality, and interconnection per signal; Waveform Analyzer extracts timing relationships and causal dependencies from waveform diagrams. Outputs combine into a Signal-Wise Information Bank.

### Mechanism 2: MCTSr for Iterative Assertion Refinement with Dual Feedback
Monte Carlo Tree Search with self-refinement explores multiple reasoning paths per signal, using critic feedback and formal verification to iteratively improve assertions. Each rollout involves UCT-based selection, SVA LLM expansion with dual feedback, critic scoring with suppression/resampling, and backpropagation. After n_rollouts, all nodes combine into assertion set.

### Mechanism 3: Reward Shaping via Score Suppression and Repeated Sampling
Constraining critic scores (suppressing >95, resampling on re-selection) reduces over-optimistic evaluation and encourages continued exploration. Three techniques applied—prompt constraints enforce strict grading, scores above 95 are suppressed, and re-selected nodes have their scores resampled rather than reused.

## Foundational Learning

- Concept: Monte Carlo Tree Search (UCT, Expansion, Simulation, Backpropagation)
  - Why needed here: MCTSr modifies standard MCTS for LLM-driven assertion refinement; understanding selection (UCT), expansion, and backpropagation is prerequisite to grasping how SANGAM explores the assertion space.
  - Quick check question: Can you explain why UCT balances exploration (visiting less-visited nodes) vs exploitation (visiting high-Q nodes)?

- Concept: SystemVerilog Assertions (SVA) Syntax and Semantics
  - Why needed here: The framework generates SVAs; without understanding property declarations, sequences, implication operators (|->), and disable iff, you cannot evaluate generated assertion quality or debug syntax errors.
  - Quick check question: What does `@(posedge clk) disable iff (!rst) (a |-> b)` mean semantically?

- Concept: Retrieval-Augmented Generation (RAG) with FAISS
  - Why needed here: SANGAM uses RAG to provide SVA-relevant documentation snippets during expansion, reducing hallucination. Understanding embedding-based retrieval clarifies why external knowledge is injected.
  - Quick check question: How does a FAISS index retrieve relevant document chunks given a query embedding?

## Architecture Onboarding

- Component map: Signal Mapper LLM -> Spec Analyzer LLM -> Waveform Analyzer LLM -> Signal-Wise Information Bank -> MCTSr (per signal) -> JasperGold syntax check -> Correction LLM -> Deduplication LLM -> Final assertion set

- Critical path: Stage 2 MCTSr loop—each rollout involves: (1) UCT-based node selection; (2) Critic + JasperGold feedback generation; (3) SVA LLM expansion with RAG; (4) Critic scoring with suppression/resampling; (5) Backpropagation. This is the computationally dominant and quality-determining segment.

- Design tradeoffs:
  - More rollouts increase assertion diversity but raise API costs (Table III shows 20 max calls/signal at n_rollouts=4)
  - Strict critic scoring improves precision but may reject valid assertions; lenient scoring increases false positives
  - Waveform Analyzer adds coverage but requires waveform diagrams; unavailable for RV-Timer per paper

- Failure signatures:
  - Low assertion count for a signal → likely weak initial information in Signal-Wise Information Bank; check Spec/Waveform Analyzer outputs
  - High syntax error rate after MCTSr → Critic not prioritizing syntax feedback; verify JasperGold integration
  - Assertions miss core functionality (e.g., mtime >= mtimecmp |-> intr) → reasoning tree converged prematurely; increase n_rollouts or adjust exploration constant c

- First 3 experiments:
  1. Replicate I2C single-signal MCTSr: Pick one signal (e.g., `wb_rst_i`), run 4 rollouts, inspect reasoning tree nodes and Q-values to validate selection/expansion flow
  2. Ablate Critic feedback: Run MCTSr with only JasperGold syntax feedback (no Critic), compare assertion count and coverage vs full dual-feedback
  3. Ablate Waveform Analyzer: For I2C, exclude waveform-derived interdependence info, measure assertion count reduction to quantify waveform contribution

## Open Questions the Paper Calls Out

### Open Question 1
Can a domain-specific LLM replace the general-purpose DeepSeek-R1 to reduce the computational overhead of the multi-LLM framework? The conclusion states that future work should focus on "reducing the overhead from multiple LLM calls by using a domain-specific LLM instead of a general domain LLM." The current implementation requires up to 20 API calls per signal, creating a significant cost and latency bottleneck.

### Open Question 2
How can the reward function used in MCTS node evaluation be refined to improve the search for valid assertions? The authors state that "further improvements can be made in fine-tuning the reward function used during node evaluation." The current reward mechanism relies on a "Critic LLM" which requires ad-hoc heuristics like "Full Score Suppression" and "Repeated Sampling" to prevent over-optimism, suggesting the raw scoring is unstable.

### Open Question 3
How can the framework be extended to guarantee inter-signal assertion irredundancy? Section V explicitly notes that "SANGAM is unable to guarantee inter-signal assertion irredundancy." The current De-duplication LLM operates locally on a per-signal basis (Stage 3), lacking the global context required to detect logical equivalence across assertions generated for different signals.

### Open Question 4
How sensitive is the quality of generated assertions to the number of MCTS rollouts and the exploration constant ($c$)? The implementation sets the number of rollouts ($n_{rollouts}$) to 4 and the exploration constant $c$ to 1.4 without providing an ablation study or justification for these specific hyperparameters.

## Limitations

- The framework cannot guarantee inter-signal assertion irredundancy, requiring manual review for redundancy detection
- Waveform analyzer contribution remains unproven for RV-Timer since waveforms weren't available for this design
- Critic LLM calibration and reward shaping techniques lack ablation studies and independent validation

## Confidence

- **High Confidence**: Stage 1 multi-modal processing framework (Signal Mapper, Spec Analyzer, Waveform Analyzer) is clearly specified and follows established RAG patterns; Stage 3 deduplication and syntax correction methodology is straightforward and implementable
- **Medium Confidence**: MCTSr algorithm structure and parameter choices (n_rollouts=4, c=1.4) are specified, but empirical justification for these values is limited; dual feedback mechanism (Critic + JasperGold) shows promise but calibration remains uncertain
- **Low Confidence**: Claims about MCTSr superiority over single-pass LLM generation lack comparative ablation studies; assertion coverage metrics rely on JasperGold's verification engine without external validation

## Next Checks

1. Ablate Waveform Analyzer: Run SANGAM on I2C excluding waveform-derived interdependence information, then compare assertion count and property coverage against the full system to quantify waveform contribution.

2. Vary MCTSr Parameters: Systematically test different values of n_rollouts (2, 4, 6, 8) and exploration constant c (0.5, 1.0, 1.4, 2.0) on I2C, measuring trade-offs between assertion diversity, quality, and computational cost.

3. Independent Coverage Validation: Use a second formal verification tool (beyond JasperGold) to independently verify the branch/toggle/property coverage metrics claimed in Table IV, checking for potential tool-specific artifacts in the reported 90%+ coverage.