---
ver: rpa2
title: 'Impugan: Learning Conditional Generative Models for Robust Data Imputation'
arxiv_id: '2512.05950'
source_url: https://arxiv.org/abs/2512.05950
tags:
- data
- impugan
- imputation
- missing
- gain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Impugan, a conditional Generative Adversarial
  Network (cGAN) for imputing missing values in heterogeneous datasets. The method
  learns conditional distributions of missing variables from complete data, using
  a generator to reconstruct missing entries and a discriminator to ensure realism.
---

# Impugan: Learning Conditional Generative Models for Robust Data Imputation

## Quick Facts
- arXiv ID: 2512.05950
- Source URL: https://arxiv.org/abs/2512.05950
- Reference count: 37
- Primary result: Achieves up to 82% lower Earth Mover's Distance (EMD) and 70% lower mutual-information deviation (MI) compared to leading baselines

## Executive Summary
Impugan is a conditional Generative Adversarial Network (cGAN) designed for robust data imputation in heterogeneous tabular datasets. It learns conditional distributions of missing variables from complete data, using a generator to reconstruct missing entries and a discriminator to ensure realism. The method handles multi-source integration by preserving nonlinear dependencies and correlations across disparate data through multi-conditional joint conditioning. Experimental results on benchmark datasets demonstrate superior distributional fidelity and downstream classification performance compared to state-of-the-art imputation methods.

## Method Summary
Impugan implements a cGAN architecture where the generator takes noise samples and a multi-hot condition vector built from observed categorical attributes to produce imputations for missing entries. The discriminator evaluates completed samples using a PAC (Packing) strategy, grouping samples jointly to reduce gradient variance. Training alternates between generator and discriminator updates with gradient penalties and a conditional fidelity loss that enforces consistency with specified categorical attributes. The method operates on heterogeneous tabular datasets and can handle various missingness mechanisms (MCAR, MAR, MNAR) by learning the conditional distribution p(X_miss | X_obs) from complete samples.

## Key Results
- Achieves 82% lower Earth Mover's Distance (EMD) compared to leading imputation baselines
- Demonstrates 70% lower mutual-information deviation (MI) preserving inter-attribute dependencies
- Maintains strong downstream classification performance with SVM, RF, and MLP classifiers
- Successfully handles multi-source integration while preserving nonlinear relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial training preserves distributional fidelity better than reconstruction-based methods
- Mechanism: The discriminator provides a learned loss signal that penalizes imputations deviating from the true joint distribution, while the generator samples from latent noise enabling diverse outputs
- Core assumption: Sufficient complete samples exist to learn the conditional distribution p(X_miss | X_obs)
- Evidence anchors: [abstract] captures nonlinear relationships conventional methods cannot represent; [section III.B] generator samples from latent noise z for diverse imputations; [corpus] related work validates adversarial imputation principles

### Mechanism 2
- Claim: Multi-conditional joint conditioning preserves inter-attribute dependencies across heterogeneous sources
- Mechanism: Multi-hot condition vector concatenates one-hot encodings of all observed categorical attributes, with conditional loss aggregating cross-entropy across all requested attributes simultaneously
- Core assumption: Categorical attributes in condition set are observed and reliable; their relationships to missing variables are learnable
- Evidence anchors: [section III.C.2] Impugan can incorporate any subset of observed categorical attributes simultaneously; [table III] MI deviation of 0.03 on Adult vs. 0.10 for GAIN; [corpus] HMVI and MissHDD address similar challenges

### Mechanism 3
- Claim: PAC discriminator and gradient penalties stabilize training and reduce mode collapse
- Mechanism: Discriminator evaluates groups of p samples jointly (PAC strategy), reducing gradient variance; combined with gradient penalties to prevent generator collapse to trivial averages
- Core assumption: Sufficient batch sizes and appropriate PAC grouping exist to provide stable gradient estimates
- Evidence anchors: [section III.C.1] uses PAC discriminator strategy to reduce variance in gradients; [section IV.C] trains for 300 epochs for stable convergence; [corpus] PacGAN provides foundational PAC strategy

## Foundational Learning

- Concept: **Conditional GANs (cGANs)**
  - Why needed here: Impugan extends cGANs to imputation by conditioning generation on observed attributes; understanding base architecture is prerequisite
  - Quick check question: Can you explain how conditioning changes the generator's input space compared to unconditional GANs?

- Concept: **Missing data mechanisms (MCAR, MAR, MNAR)**
  - Why needed here: Paper evaluates across these mechanisms; understanding them is essential for diagnosing when Impugan will succeed or fail
  - Quick check question: If missingness depends on unobserved variables, which mechanism applies and what implication does this have for imputation validity?

- Concept: **Earth Mover's Distance (Wasserstein-1)**
  - Why needed here: Primary evaluation metric showing 82% improvement; understanding EMD helps interpret distributional fidelity claims
  - Quick check question: Why does EMD capture distributional similarity better than RMSE for imputation evaluation?

## Architecture Onboarding

- Component map: z, condition vector, mask -> Generator G -> imputed values; completed samples -> Discriminator D (PAC groups) -> real/synthetic classification
- Critical path:
  1. Extract observed categorical attributes -> build condition vector
  2. Sample noise z ~ N(0, I)
  3. Generator produces candidate imputations
  4. Apply conditional loss (cross-entropy on conditioned attributes)
  5. Discriminator evaluates completed samples in PAC groups
  6. Update G and D alternately with gradient penalties
- Design tradeoffs:
  - PAC size p: Larger p stabilizes gradients but increases memory and may smooth fine-grained distinctions
  - Hard sampling frequency: Improves categorical sharpness but may reduce diversity
  - Conditional weight λ_cond: Higher values enforce fidelity to conditions but may constrain distributional learning
- Failure signatures:
  - Mode collapse: All imputations converge to similar values; check discriminator loss approaching zero
  - Condition mismatch: Imputed categorical values violate specified conditions; increase λ_cond or check condition encoding
  - Distributional drift: EMD/JSD high despite low reconstruction error; discriminator may be too weak
- First 3 experiments:
  1. Reproduce Adult dataset results with 30% MCAR missingness; verify EMD < 0.1 and compare to Table II baseline
  2. Ablate PAC strategy by setting p=1; measure training stability (discriminator loss variance) and final EMD
  3. Test hard sampling by comparing categorical accuracy with and without logit override on held validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Impugan be effectively extended to impute time-series and multimodal data (e.g., combining clinical, textual, and imaging data)?
- Basis in paper: [explicit] The conclusion identifies extending the framework to time series and multimodal settings as a primary avenue for future research
- Why unresolved: Current implementation and experiments focus exclusively on static heterogeneous tabular datasets
- What evidence would resolve it: Successful application to temporal benchmarks (e.g., physio-net) or multimodal datasets, demonstrating maintained distributional fidelity

### Open Question 2
- Question: How can explicit uncertainty quantification be integrated into the adversarial generation process to support risk-sensitive decision-making?
- Basis in paper: [explicit] Authors list incorporating explicit uncertainty quantification as a key direction for improving interpretability
- Why unresolved: Standard GANs typically produce point estimates without inherent probability calibrations or confidence intervals
- What evidence would resolve it: Modified Impugan architecture that outputs confidence intervals for imputed values, validated against ground-truth uncertainties

### Open Question 3
- Question: Do hybrid approaches combining Impugan's adversarial training with probabilistic models (e.g., diffusion models) enhance fidelity and training stability?
- Basis in paper: [explicit] Conclusion suggests exploring hybrid approaches to combine benefits of adversarial training with probabilistic methods
- Why unresolved: Paper acknowledges GAN training requires stabilization techniques while diffusion models offer different stability profile
- What evidence would resolve it: Empirical comparisons showing hybrid model converges faster or achieves lower EMD than standalone cGAN or diffusion baselines

## Limitations
- Core experimental results hinge on underspecified architectural details and hyperparameters, creating potential reproducibility barriers
- Method has only been validated on tabular datasets; generalization to high-dimensional or image data remains unexplored
- Reliance on sufficient complete training samples for conditional distribution learning presents fundamental limitation with extremely sparse data

## Confidence
- **High Confidence**: Adversarial training preserving distributional fidelity better than reconstruction methods; 82% EMD improvement represents substantial measurable gain
- **Medium Confidence**: Multi-conditional conditioning superiority in preserving dependencies supported by MI metrics but lacks ablation studies; PAC strategy contribution to stability is theoretically sound but empirically limited
- **Low Confidence**: Method's robustness across all missingness mechanisms (especially MNAR) is asserted but not thoroughly validated; 70% MI deviation claims would benefit from confidence intervals

## Next Checks
1. Implement systematic ablation study removing PAC discriminator (p=1) and measure training stability metrics (discriminator loss variance) and final EMD scores across all three datasets
2. Conduct sensitivity analysis varying hard sampling frequency from 0% to 50% and measure impact on categorical attribute fidelity (χ² scores) versus imputation diversity
3. Test method performance on a fourth dataset with different characteristics (e.g., higher dimensionality or different feature distributions) to assess generalizability beyond the three benchmark datasets used