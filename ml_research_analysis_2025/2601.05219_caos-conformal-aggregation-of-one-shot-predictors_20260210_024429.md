---
ver: rpa2
title: 'CAOS: Conformal Aggregation of One-Shot Predictors'
arxiv_id: '2601.05219'
source_url: https://arxiv.org/abs/2601.05219
tags:
- caos
- prediction
- conformal
- one-shot
- coverage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CAOS introduces a conformal prediction framework for one-shot learning
  that aggregates multiple one-shot predictors while maintaining valid finite-sample
  marginal coverage. Unlike standard split conformal methods that split data and use
  single predictors, CAOS employs a leave-one-out calibration scheme to fully utilize
  scarce labeled data and adaptively aggregates the k most informative reference examples
  for each test input.
---

# CAOS: Conformal Aggregation of One-Shot Predictors

## Quick Facts
- arXiv ID: 2601.05219
- Source URL: https://arxiv.org/abs/2601.05219
- Authors: Maja Waldron
- Reference count: 28
- Primary result: CAOS reduces prediction set sizes by up to 50% compared to split conformal baselines while maintaining valid coverage

## Executive Summary
CAOS introduces a novel conformal prediction framework for one-shot learning that addresses the challenge of limited labeled data by aggregating multiple one-shot predictors. The method employs a leave-one-out calibration scheme that fully utilizes scarce labeled data and adaptively selects the k most informative reference examples for each test input. Unlike standard split conformal methods that sacrifice data efficiency through explicit splitting, CAOS maintains both data efficiency and valid finite-sample marginal coverage through a monotonicity-based reduction to full conformal prediction.

## Method Summary
The CAOS framework operates by first training multiple one-shot predictors on leave-one-out folds of the calibration set, then aggregating their predictions for each test point. The key innovation lies in the calibration procedure, which computes nonconformity scores for each potential aggregation level k, allowing the method to select the optimal number of reference examples to include in predictions. This approach violates standard exchangeability assumptions but maintains valid coverage through a theoretical reduction to full conformal prediction based on monotonicity properties. The framework adaptively chooses which reference examples to include based on their informativeness for each specific test input.

## Key Results
- Achieves valid finite-sample marginal coverage while violating exchangeability assumptions
- Reduces average prediction set sizes by up to 50% compared to split conformal baselines
- Demonstrates robustness to the aggregation parameter k across different data scarcity regimes
- Particularly effective when labeled data are scarce, fully utilizing available information

## Why This Works (Mechanism)
CAOS works by leveraging the redundancy in one-shot predictors through aggregation while maintaining statistical validity through a carefully designed calibration scheme. The leave-one-out approach ensures that each calibration point contributes to training multiple predictors, maximizing data utilization. The monotonicity-based reduction to full conformal prediction allows the method to handle the non-exchangeable nature of aggregated predictions, which arise because different test points may use different subsets of reference examples.

## Foundational Learning
- Conformal prediction: A framework for uncertainty quantification that provides valid prediction sets with finite-sample guarantees. Needed because standard confidence intervals don't provide distribution-free coverage guarantees. Quick check: Does the method produce valid coverage on exchangeable data?
- One-shot learning: Learning from a single example per class, relevant when labeled data are extremely scarce. Needed because many real-world applications have limited labeled data. Quick check: Can the method handle varying numbers of reference examples per test point?
- Exchangeability assumption: Standard conformal prediction requires data points to be exchangeable. Needed as a baseline for understanding when coverage guarantees break down. Quick check: Does the method maintain coverage when exchangeability is violated?
- Nonconformity scores: Measures of how different a new point is from the training data. Needed for determining which points belong in prediction sets. Quick check: Are nonconformity scores monotonic in the aggregation parameter k?
- Leave-one-out cross-validation: A resampling technique that trains on all but one data point. Needed to maximize data utilization in scarce data regimes. Quick check: Does the method scale to larger datasets?
- Aggregation monotonicity: The property that adding more reference examples doesn't decrease prediction accuracy. Needed for the theoretical reduction to full conformal prediction. Quick check: Is this property empirically observed across different datasets?

## Architecture Onboarding
Component map: Calibration set -> Leave-one-out training -> Multiple one-shot predictors -> Aggregation module -> Nonconformity scoring -> Prediction sets

Critical path: The most important sequence is the leave-one-out training followed by adaptive aggregation and calibration. The method must compute nonconformity scores for each potential value of k to determine optimal aggregation levels.

Design tradeoffs: The main tradeoff is between computational complexity (training multiple predictors) and data efficiency (fully utilizing limited labeled data). The method sacrifices some computational efficiency for improved coverage and smaller prediction sets.

Failure signatures: The method may fail when the monotonicity assumption doesn't hold, leading to invalid coverage. It may also struggle with very large datasets where the leave-one-out approach becomes computationally prohibitive.

Three first experiments:
1. Compare CAOS prediction set sizes against split conformal baselines on a small labeled dataset
2. Test coverage validity as the number of available labeled examples varies
3. Evaluate sensitivity to the aggregation parameter k across different problem types

## Open Questions the Paper Calls Out
None

## Limitations
- Computational complexity of leave-one-out calibration may be prohibitive for large-scale applications
- Theoretical validity relies on monotonicity assumptions that may not hold across all data distributions
- Limited empirical validation beyond facial landmarking and text classification tasks

## Confidence
- Coverage validity: High - The theoretical foundation through monotonicity-based reduction is well-established
- Set size reduction: Medium - While experiments show substantial improvements, the 50% reduction represents best-case scenarios
- Robustness to k: Medium - Reported insensitivity is promising but requires broader validation

## Next Checks
1. Evaluate CAOS performance on high-dimensional and structured data domains (e.g., medical imaging, genomics) to assess scalability and effectiveness beyond the current testbeds.
2. Conduct extensive ablation studies varying k across different data scarcity regimes to establish clear guidelines for hyperparameter selection.
3. Implement and benchmark the computational overhead of CAOS against standard conformal methods on large-scale datasets to quantify practical deployment constraints.