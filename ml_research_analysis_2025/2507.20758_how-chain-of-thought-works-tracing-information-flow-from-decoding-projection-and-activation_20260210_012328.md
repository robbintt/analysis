---
ver: rpa2
title: How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection,
  and Activation
arxiv_id: '2507.20758'
source_url: https://arxiv.org/abs/2507.20758
tags:
- answer
- prompt
- standard
- coin
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the internal mechanisms of Chain-of-Thought
  (CoT) prompting by analyzing information flow through decoding, projection, and
  activation phases. The analysis reveals that CoT narrows the decoding space by leveraging
  answer templates, with stronger adherence to structured reasoning correlating with
  improved performance.
---

# How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation

## Quick Facts
- arXiv ID: 2507.20758
- Source URL: https://arxiv.org/abs/2507.20758
- Reference count: 40
- Key outcome: CoT improves accuracy by up to 338% by narrowing decoding space via answer templates, sharpening probability distributions, and task-dependent neuron modulation

## Executive Summary
This work provides a mechanistic analysis of Chain-of-Thought (CoT) prompting by tracing information flow through three phases: decoding, projection, and activation. The study reveals that CoT narrows the decoding space through structured answer templates, sharpens probability distributions to reduce uncertainty, and modulates neuron activation in task-dependent ways. Experiments across six models (3B–70B) and nine datasets demonstrate consistent performance gains, with CoT improving accuracy by up to 338% in some tasks. The findings offer a framework for designing more efficient prompts and advance mechanistic interpretability in large language models.

## Method Summary
The authors analyze information flow in CoT prompting through three phases: decoding, projection, and activation. They examine how CoT narrows the decoding space by leveraging answer templates, sharpens probability distributions to reduce prediction uncertainty, and modulates neuron engagement in a task-dependent manner. The study uses activation-based analysis across six models (3B–70B) and nine datasets, correlating template adherence with performance and measuring activation patterns in open vs. closed-domain tasks. The mechanistic interpretability framework aims to uncover how structured reasoning emerges during CoT prompting.

## Key Results
- CoT narrows decoding space by leveraging answer templates, with stronger template adherence correlating with improved performance
- CoT sharpens probability distributions, reducing prediction uncertainty and improving accuracy
- Neuron activation is modulated in a task-dependent manner—reduced in open-domain tasks, increased in closed-domain scenarios

## Why This Works (Mechanism)
CoT works by structuring the reasoning process into three phases: decoding (where the model interprets the prompt and generates intermediate reasoning steps), projection (where the model maps these steps to potential answer spaces), and activation (where the model engages specific neurons to refine the final output). The mechanism relies on answer templates to constrain the decoding space, making the reasoning process more focused and efficient. By sharpening probability distributions, CoT reduces uncertainty in predictions, while task-dependent neuron modulation ensures that the model allocates computational resources appropriately—engaging more neurons for complex, closed-domain tasks and fewer for simpler, open-domain ones.

## Foundational Learning
- **Chain-of-Thought Prompting**: A technique where models are prompted to generate intermediate reasoning steps before arriving at a final answer. Why needed: Enables structured reasoning in complex tasks. Quick check: Verify that intermediate steps logically lead to the final answer.
- **Mechanistic Interpretability**: The study of how neural networks process information internally. Why needed: Provides insights into model behavior and aids in designing better prompts. Quick check: Identify key activation patterns during CoT reasoning.
- **Answer Templates**: Structured formats that guide the model's output. Why needed: Constrain the decoding space and improve reasoning accuracy. Quick check: Measure template adherence and its correlation with performance.
- **Probability Distribution Sharpening**: A process where the model reduces uncertainty in its predictions. Why needed: Improves accuracy by focusing on the most likely outcomes. Quick check: Compare probability distributions before and after CoT.
- **Neuron Activation Modulation**: The adjustment of neuron engagement based on task complexity. Why needed: Optimizes computational resources for different task types. Quick check: Analyze activation patterns in open vs. closed-domain tasks.
- **Task-Dependent Modulation**: The adjustment of model behavior based on task characteristics. Why needed: Ensures efficient reasoning for diverse tasks. Quick check: Compare activation patterns across task types.

## Architecture Onboarding
- **Component Map**: Input -> Decoding Phase -> Projection Phase -> Activation Phase -> Output
- **Critical Path**: The sequence from decoding (interpreting the prompt) to activation (refining the final output) is critical for CoT's effectiveness.
- **Design Tradeoffs**: Balancing template adherence (for accuracy) with flexibility (for adaptability) is key. Over-constraining the decoding space may reduce performance on novel tasks.
- **Failure Signatures**: Poor template adherence, overly broad probability distributions, or inappropriate neuron activation patterns can lead to suboptimal performance.
- **First Experiments**:
  1. Measure template adherence in CoT prompts and correlate with accuracy.
  2. Analyze probability distributions before and after CoT to quantify uncertainty reduction.
  3. Compare neuron activation patterns in open vs. closed-domain tasks to identify task-dependent modulation.

## Open Questions the Paper Calls Out
None

## Limitations
- The study relies heavily on activation-based analysis, which may not fully capture complex interactions between attention heads and feed-forward layers.
- The answer template hypothesis lacks direct causal evidence, and it's unclear whether templates constrain decoding or emerge as a byproduct of structured reasoning.
- Performance gains show substantial variability across tasks and model scales, suggesting that CoT's effectiveness may depend on task complexity and model capacity in ways not fully characterized.

## Confidence
- **High confidence**: CoT reduces prediction uncertainty through sharpened probability distributions; performance improvements are reproducible across model scales
- **Medium confidence**: Answer template hypothesis explaining decoding space narrowing; neuron activation modulation patterns
- **Low confidence**: Causal relationship between template adherence and performance; universality of observed activation patterns across different model architectures

## Next Checks
1. Conduct ablation studies removing template-like structures from prompts to test whether decoding space narrowing is causal to CoT effectiveness, controlling for reasoning steps.
2. Perform cross-architecture validation using models with different attention mechanisms (e.g., Mamba, RWKV) to determine if activation modulation patterns are universal or architecture-specific.
3. Carry out fine-grained attention head analysis to trace whether specific attention patterns mediate the transition from encoding to projection phases, providing mechanistic grounding for the three-phase model proposed.