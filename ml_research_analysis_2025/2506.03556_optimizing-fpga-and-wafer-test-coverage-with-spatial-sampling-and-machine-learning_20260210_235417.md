---
ver: rpa2
title: Optimizing FPGA and Wafer Test Coverage with Spatial Sampling and Machine Learning
arxiv_id: '2506.03556'
source_url: https://arxiv.org/abs/2506.03556
tags:
- sampling
- wafer
- fpga
- spatial
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of high testing costs in semiconductor
  manufacturing by proposing optimized sampling strategies that maintain predictive
  accuracy while reducing the number of required tests. The core method introduces
  the Short Distance Elimination (SDE) algorithm, which excludes spatially proximate
  candidate points during sampling to ensure a more uniform distribution of training
  data across the physical domain.
---

# Optimizing FPGA and Wafer Test Coverage with Spatial Sampling and Machine Learning

## Quick Facts
- **arXiv ID:** 2506.03556
- **Source URL:** https://arxiv.org/abs/2506.03556
- **Reference count:** 24
- **One-line primary result:** K-SDE improves upon k-means sampling by 16.26% (wafer) and 13.07% (FPGA); S-SDE improves upon stratified sampling by 16.49% (wafer) and 8.84% (FPGA).

## Executive Summary
This study addresses the challenge of high testing costs in semiconductor manufacturing by proposing optimized sampling strategies that maintain predictive accuracy while reducing the number of required tests. The core method introduces the Short Distance Elimination (SDE) algorithm, which excludes spatially proximate candidate points during sampling to ensure a more uniform distribution of training data across the physical domain. Two hybrid strategies, S-SDE (Stratified + SDE) and K-SDE (k-means + SDE), are developed and evaluated using Gaussian Process Regression on real industrial wafer and FPGA test data. Experimental results show that K-SDE improves upon k-means sampling by 16.26% (wafer) and 13.07% (FPGA), while S-SDE improves upon stratified sampling by 16.49% (wafer) and 8.84% (FPGA). These findings demonstrate that incorporating spatial dispersion through SDE significantly enhances predictive accuracy compared to traditional sampling methods.

## Method Summary
The method combines spatial sampling optimization with Gaussian Process Regression to predict semiconductor test measurements while using only 10% of the available data. The core innovation is the Short Distance Elimination (SDE) algorithm, which ensures uniform spatial distribution by excluding candidates that are too close to already-selected points. Two hybrid strategies are proposed: S-SDE combines stratified sampling with SDE, and K-SDE combines k-means clustering with SDE. The approach is evaluated on two real-world datasets - wafer dynamic current measurements and FPGA oscillator frequencies - using RMSD as the primary metric. The SDE algorithm uses spatial exclusion thresholds (α=2, β=2) to maintain minimum distances between selected samples, ensuring comprehensive coverage of the physical domain.

## Key Results
- K-SDE improves predictive accuracy by 16.26% on wafer data and 13.07% on FPGA data compared to standard k-means sampling
- S-SDE improves predictive accuracy by 16.49% on wafer data and 8.84% on FPGA data compared to standard stratified sampling
- Both hybrid strategies consistently outperform their respective baseline methods across all test cases

## Why This Works (Mechanism)
The spatial sampling approach works by ensuring that training data covers the entire physical domain of the semiconductor device rather than clustering in specific regions. The Short Distance Elimination algorithm specifically addresses the limitation of traditional clustering methods, which can result in samples that are close together spatially but far apart in terms of the underlying physical process. By enforcing minimum distances between selected samples, SDE captures more diverse physical conditions and edge cases that are critical for accurate prediction. This spatial diversity translates directly into better generalization when predicting measurements for untested regions of the device.

## Foundational Learning
- **Spatial sampling importance**: Ensures test data represents the entire physical domain, not just clustered regions - why needed: semiconductor defects and variations are spatially distributed; quick check: verify samples cover all quadrants of the device
- **Short Distance Elimination (SDE)**: Algorithm that excludes spatially proximate candidates to maintain uniform distribution - why needed: prevents clustering bias in traditional sampling; quick check: measure minimum distance between any two selected samples
- **Gaussian Process Regression with RBF kernel**: Probabilistic model that handles spatial correlations naturally - why needed: provides uncertainty estimates and smooth predictions for continuous physical measurements; quick check: examine length-scale hyperparameter values
- **Multisite wafer testing**: Process where multiple dies are tested simultaneously at fixed positions - why needed: creates regular spatial grid but requires careful sampling to avoid systematic bias; quick check: verify sampling respects site grid structure
- **Faulty die removal**: Preprocessing step to exclude defective measurements - why needed: prevents contamination of training data with non-representative outliers; quick check: document criteria used for identifying faulty dies

## Architecture Onboarding
- **Component map**: Data Preprocessing -> Sampling Strategy -> Gaussian Process Regression -> Prediction Evaluation
- **Critical path**: Raw measurement data → Spatial coordinate extraction → Faulty die removal → Sampling selection → GPR training → RMSD calculation
- **Design tradeoffs**: The SDE algorithm trades off some sample density for better spatial coverage, accepting potentially lower absolute sample count to achieve more representative training data. The choice of exclusion thresholds (α, β) represents a key hyperparameter that must balance coverage completeness against sample sufficiency.
- **Failure signatures**: Poor performance manifests as high RMSD values, particularly when sampling fails to capture edge cases or when the spatial distribution of selected samples shows clustering. GPR instability may indicate scaling issues with coordinates or insufficient sample diversity.
- **First experiments**: 1) Compare RMSD across all five sampling methods on a single wafer to verify improvement trends; 2) Test different (α, β) combinations to find optimal spatial exclusion thresholds; 3) Evaluate GPR performance with and without coordinate normalization to assess scaling sensitivity

## Open Questions the Paper Calls Out
- **Open Question 1**: Does the Short Distance Elimination (SDE) algorithm improve predictive performance when applied to non-Bayesian machine learning models? The paper explicitly states that future research includes "applying the SDE approach to other machine learning models such as neural networks and random forests," but the study exclusively evaluated the interaction between SDE and Gaussian Process Regression.
- **Open Question 2**: Can the SDE sampling strategy be adapted for real-time environments where data arrives in batches rather than static datasets? The authors list "developing efficient online sampling strategies for batch data environments" as a specific future direction, but the current methodology assumes a static full dataset from which 10% is selected.
- **Open Question 3**: How does the inclusion of spatially clustered faulty dies impact the reliability of SDE-based sampling? While the paper notes that "faulty dies were removed from the dataset" during preprocessing, SDE enforces uniform spatial dispersion which may inadvertently skip clusters of defects that are critical for training a robust test model.

## Limitations
- The exact number of strata S used in stratified sampling is not specified, which could affect baseline performance comparisons
- GPR hyperparameter settings including noise variance initialization, length-scale bounds, and optimization parameters are not fully detailed
- The preprocessing of faulty dies and site handling lacks explicit definition, creating uncertainty in the experimental protocol

## Confidence
- **High**: K-SDE and S-SDE consistently outperform their respective baselines (k-means and stratified) across both wafer and FPGA datasets
- **Medium**: The reported percentage improvements (16.26% for wafer, 13.07% for FPGA via K-SDE; 16.49% for wafer, 8.84% for FPGA via S-SDE) are valid given the methodology, but depend on exact hyperparameter and preprocessing choices
- **Low**: Relative ranking of Random sampling versus stratified/k-means in isolation, due to potential sensitivity to unknown S

## Next Checks
1. Confirm S = 7 for stratified sampling to match k-means, or justify a different value based on value distribution
2. Explicitly normalize spatial coordinates before GPR training and report resulting hyperparameter distributions
3. Compare SDE performance across different (α, β) pairs (e.g., (1,1), (2,2), (3,3)) to quantify sensitivity to spatial exclusion thresholds