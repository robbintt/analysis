---
ver: rpa2
title: 'AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided
  Data Synthesis'
arxiv_id: '2510.24695'
source_url: https://arxiv.org/abs/2510.24695
tags:
- reasoning
- data
- agent
- agentfrontier
- tool
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a data synthesis approach inspired by the\
  \ educational theory of the Zone of Proximal Development (ZPD) to train large language\
  \ model (LLM) agents on tasks at the frontier of their capabilities. The proposed\
  \ AgentFrontier Engine is an automated pipeline that generates high-quality, multidisciplinary\
  \ data within the LLM\u2019s ZPD by defining two personas: the Less Knowledgeable\
  \ Peer (LKP) and the More Knowledgeable Other (MKO)."
---

# AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis

## Quick Facts
- arXiv ID: 2510.24695
- Source URL: https://arxiv.org/abs/2510.24695
- Authors: Xuanzhong Chen; Zile Qiao; Guoxin Chen; Liangcai Su; Zhen Zhang; Xinyu Wang; Pengjun Xie; Fei Huang; Jingren Zhou; Yong Jiang
- Reference count: 12
- Primary result: ZPD-guided data synthesis achieves SoTA on Humanity's Last Exam, surpassing some proprietary agents

## Executive Summary
This paper introduces AgentFrontier, a data synthesis approach inspired by the Zone of Proximal Development (ZPD) educational theory to train large language model (LLM) agents on tasks at the frontier of their capabilities. The approach automatically generates high-quality, multidisciplinary training data within the LLM's ZPD by defining two personas: the Less Knowledgeable Peer (LKP) and the More Knowledgeable Other (MKO). Tasks unsolvable by the LKP but solvable by the MKO are retained for training. From this framework, the ZPD Exam, a dynamic and automated benchmark, is derived to evaluate agent capabilities on frontier tasks. Training AgentFrontier-30B-A3B on synthesized data achieves state-of-the-art results on Humanity's Last Exam, demonstrating that a ZPD-guided approach offers a scalable path toward building more capable LLM agents.

## Method Summary
The proposed AgentFrontier Engine is an automated pipeline that generates high-quality, multidisciplinary data within the LLM's ZPD through a three-stage process: (I) Seed generation via thematically coherent triplets from 1M public documents, (II) Agentic refinement with escalation operators until questions become unsolvable by the base model, and (III) LKP/MKO filtering where solvable questions become training data and unsolvable questions become benchmark candidates. The pipeline uses tool-augmented agents with search, scholar, browser, and code capabilities. Training involves CPT on 50B tokens plus RFT on 12K trajectories using rejection sampling fine-tuning.

## Key Results
- AgentFrontier-30B-A3B achieves state-of-the-art results on Humanity's Last Exam (text-only), surpassing some leading proprietary agents
- The model shows significant improvements on ZPD Exam-v1 (1,024 questions) and other benchmarks including R-Bench-T and xBench-ScienceQA
- Balanced tool usage is observed: Search (32%), Scholar (66%), Browser (82%), and Code (52%) calls per trajectory
- LLM-as-judge evaluation using o3-mini confirms the quality and difficulty of synthesized questions

## Why This Works (Mechanism)
The approach works by precisely targeting the "zone of proximal development" - tasks that are just beyond the base model's capabilities but solvable with appropriate tools and guidance. By iteratively refining questions until they become unsolvable by the base model but solvable by a tool-augmented agent, the method creates training data that pushes the frontier of model capabilities. The LKP/MKO filtering mechanism ensures that only genuinely challenging questions are retained, while the diversity filter prevents redundancy. This targeted approach to data synthesis allows for efficient scaling of model capabilities without requiring massive amounts of human-labeled data.

## Foundational Learning
- **Zone of Proximal Development (ZPD)**: The gap between what a learner can do independently and what they can achieve with guidance. Needed to identify the optimal difficulty level for training data. Quick check: Can you identify tasks solvable with tools but not without?
- **Tool-augmented agents**: LLMs enhanced with external tools (search, code execution, etc.) to extend capabilities. Needed to simulate the "More Knowledgeable Other" role. Quick check: Does the agent successfully use multiple tools in combination?
- **Thematic coherence in question generation**: Ensuring questions come from related semantic units to create meaningful, multidisciplinary tasks. Needed to avoid trivial or disconnected questions. Quick check: Do generated question triplets share meaningful semantic relationships (τ_theme > 0.8)?
- **Escalation operators**: Knowledge expansion, conceptual abstraction, factual grounding, and computational formulation to increase question difficulty. Needed to systematically push questions beyond base model capabilities. Quick check: Does question difficulty increase monotonically through refinement iterations?
- **Rejection sampling fine-tuning**: Training on accepted trajectories that pass LKP/MKO filtering. Needed to ensure model learns from genuinely challenging examples. Quick check: Are the acceptance rates for training data and benchmark questions as expected (~33% each)?
- **Diversity filtering**: Preventing redundant questions through similarity thresholds. Needed to maintain a broad and varied training set. Quick check: Are synthesized questions sufficiently diverse (similarity < 0.7)?

## Architecture Onboarding

**Component Map:** Document Corpus -> Seed Generator -> Refinement Agent -> LKP/MKO Filter -> Training Data/Benchmark

**Critical Path:** Seed generation (Stage I) → Agentic refinement (Stage II) → LKP/MKO filtering (Stage III) → Training

**Design Tradeoffs:** The three-stage pipeline trades computational complexity for data quality and relevance. The escalation approach (vs. random generation) ensures questions target the capability frontier but requires multiple refinement iterations. The LKP/MKO filtering mechanism adds overhead but guarantees data falls within the ZPD.

**Failure Signatures:**
- Low MKO verification pass rate (<30%): Indicates seed questions don't require genuine multi-document synthesis
- Stagnant refinement (questions not escalating after K_max iterations): Suggests escalation operators aren't effective or questions are already at maximum difficulty
- Skewed tool distribution (one tool dominates): May indicate over-reliance on specific capabilities rather than true multidisciplinary synthesis

**First Experiments:**
1. Build and test the seed generation stage with a public document corpus to verify triplet coherence (τ_theme > 0.8) and expansion quality
2. Implement the LKP/MKO filtering mechanism and validate the escalation behavior across K_max=30 iterations
3. Conduct ablation studies on tool usage patterns to verify balanced distribution and assess individual tool contributions

## Open Questions the Paper Calls Out
None

## Limitations
- The document corpus used for seed generation is not fully specified beyond "1M public documents," making exact reproduction difficult
- The base LLM used for LKP filtering differs from the model reported in results, raising questions about consistency
- The MKO model and its tool-augmentation architecture are not clearly specified, which is critical for understanding the filtering mechanism
- LLM-as-judge evaluation using o3-mini introduces potential bias and reliability concerns for frontier task assessment

## Confidence
- **High confidence**: The ZPD-guided framework is theoretically sound and well-motivated; the three-stage pipeline design is clearly described
- **Medium confidence**: State-of-the-art results on Humanity's Last Exam are demonstrated, but evaluation methodology limitations reduce certainty
- **Low confidence**: Claims about superiority over leading proprietary agents are difficult to verify due to limited transparency in evaluation setup

## Next Checks
1. Reproduce the seed generation stage using a publicly available document corpus and verify triplet coherence (τ_theme=0.8) and expansion quality
2. Implement the LKP/MKO filtering mechanism with specified models and validate the escalation behavior across K_max=30 iterations
3. Conduct ablation studies on tool usage patterns to verify the claimed balanced distribution and assess individual tool contributions to task solvability