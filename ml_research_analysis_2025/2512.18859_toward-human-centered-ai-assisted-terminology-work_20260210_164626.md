---
ver: rpa2
title: Toward Human-Centered AI-Assisted Terminology Work
arxiv_id: '2512.18859'
source_url: https://arxiv.org/abs/2512.18859
tags:
- human
- terminology
- https
- work
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the lack of a human-centered framework for
  integrating generative AI into terminology work. It proposes a three-dimensional
  HCAI framework: the augmented terminologist, ethical AI, and human-centered design.'
---

# Toward Human-Centered AI-Assisted Terminology Work

## Quick Facts
- arXiv ID: 2512.18859
- Source URL: https://arxiv.org/abs/2512.18859
- Authors: Antonio San Martin
- Reference count: 0
- The paper proposes a three-dimensional HCAI framework for integrating AI into terminology work, emphasizing human control, bias mitigation, and human-centered design.

## Executive Summary
This paper addresses the critical need for human-centered frameworks when integrating generative AI into terminology work. It proposes a three-dimensional HCAI framework that balances high automation with strong human control, emphasizes terminologist responsibility for bias mitigation, and prioritizes human-centered design in AI tools. The framework is built on empirical evidence showing that while LLMs show promise in terminology tasks, they remain inconsistent and cannot replace human expertise. The approach aims to preserve terminological quality, accuracy, and diversity while leveraging AI for efficiency and augmentation.

## Method Summary
The paper synthesizes existing literature on terminology work and human-centered AI to develop a framework for AI-assisted terminology. It reviews empirical studies on LLM performance in terminology tasks, analyzes bias sources and types, and examines human-centered design principles. The framework is developed through theoretical analysis rather than empirical testing, drawing on established HCAI principles and terminology domain knowledge. The paper calls for future systematic benchmarking of LLMs across specific terminological tasks and subtasks, evaluation of terminologist preferences for AI augmentation, and empirical testing of human-centered design interventions.

## Key Results
- High automation and strong human control can coexist synergistically in terminology work when properly designed
- Terminologist-led bias mitigation through upstream prompting and downstream critical review reduces linguistic, cultural, epistemic, and social biases
- Human-centered design principles increase terminologist adoption and reduce resistance to AI tools
- LLM performance in terminology tasks shows promise but remains inconsistent, requiring human expertise for validation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: High automation and strong human control can coexist synergistically in terminology work, producing better outcomes than either alone.
- Mechanism: AI handles high-volume pattern recognition and draft generation at speed; humans retain decision authority over validation, contextual judgment, and final dissemination. The workflow alternates control—human defines constraints (prompts, corpora), AI generates, human validates—creating an "AI-in-the-loop" rather than human-in-the-loop configuration.
- Core assumption: Terminologists possess domain expertise and contextual judgment that AI cannot replicate; their value lies in validation and decision-making, not manual execution.
- Evidence anchors:
  - [abstract] "emphasize the compatibility of high automation with strong human control"
  - [section 4.1.1] Uses smartphone camera analogy: AI manages focus/aperture while users control framing/timing
  - [corpus] Weak direct evidence—corpus papers address HCAI generally (e.g., "Human-Centered Artificial Intelligence (HCAI): Foundations and Approaches" FMR=0.54) but not terminology-specific validation
- Break condition: If organizational pressures impose AI output without validation step, or if terminologists are reduced to passive acceptors rather than active validators, the mechanism fails (becomes displacement, not augmentation).

### Mechanism 2
- Claim: Terminologist-led bias mitigation (upstream prompting + downstream critical review) reduces linguistic, cultural, epistemic, and social biases in AI-generated terminological output.
- Mechanism: Bias enters LLMs through training data composition (Common Crawl dominance), algorithmic amplification, and post-training alignment. Terminologists counter this by (1) constraining RAG to curated, representative corpora; (2) designing prompts that specify linguistic/cultural context; (3) critically evaluating outputs against expert judgment and diverse sources.
- Core assumption: Terminologists can recognize bias that LLMs cannot self-detect, and have access to authoritative sources beyond LLM training data.
- Evidence anchors:
  - [section 4.2.2] Details four bias types (linguistic, cultural, epistemic, social) and sources (Common Crawl = 42% English, dominated by US content)
  - [section 4.2.2] "terminologists can mitigate bias both upstream and downstream"
  - [corpus] Tangential support—"Counterspeech for Mitigating the Influence of Media Bias" (FMR=0.53) addresses bias mitigation mechanisms but in media context, not terminology
- Break condition: If terminologists lack time, training, or authority to override AI suggestions; if RAG draws on unfiltered web content dominated by SEO-optimized or AI-generated sources.

### Mechanism 3
- Claim: Human-centered design (needs prioritization, participatory design, cognitive ergonomics) increases terminologist adoption and reduces resistance to AI tools.
- Mechanism: When tools align with existing workflows and values, professionals experience agency rather than imposition. Design features like adjustable automation levels, explainability (RAG sourcing, chain-of-thought), and intentional friction (confirmation dialogs) support critical engagement and prevent over-reliance.
- Core assumption: Terminologists' resistance stems from tool imposition and perceived control loss, not from technology aversion per se.
- Evidence anchors:
  - [section 4.3] Lists four HCD principles: needs prioritization, participatory design, communication support, design for diversity
  - [section 3] Cites Jiménez-Crespo's finding that translators' resistance correlates with top-down tool imposition, not AI itself
  - [corpus] Moderate support—"Organizational Practices and Socio-Technical Design of Human-Centered AI" (FMR=0.53) emphasizes participatory design in HCAI contexts
- Break condition: If tools are designed for emulation (replacing humans) rather than empowerment (augmenting humans); if "reverse adaptation" forces terminologists to conform to tool constraints.

## Foundational Learning

- Concept: **Human-Centered AI (HCAI) paradigm**
  - Why needed here: The entire framework rests on Shneiderman's principles (automation + control compatibility; empowerment over emulation). Without this foundation, AI integration defaults to efficiency-driven displacement.
  - Quick check question: Can you explain why high automation and strong human control are framed as compatible rather than trade-offs? What's the smartphone camera analogy?

- Concept: **Terminology work domains and stakes**
  - Why needed here: Understanding what terminologists do (definition writing, term extraction, equivalence verification, conceptual modeling) reveals where AI assistance fits and where human judgment remains indispensable.
  - Quick check question: What are the two broad categories of AI assistance in terminology work (post-editing TW vs. intelligent support), and can you give an example of each?

- Concept: **LLM bias sources and types**
  - Why needed here: Bias mitigation requires understanding where bias originates (training data, algorithms, post-training) and how it manifests (linguistic, cultural, epistemic, social) in terminological output.
  - Quick check question: What percentage of Common Crawl is English? Why does this matter for term equivalence work between non-English languages?

## Architecture Onboarding

- Component map:
  ```
  Three-Dimensional HCAI Framework for Terminology Work
  │
  ├── 1. Augmented Terminologist
  │   ├── High automation + high human control (subtask-level balancing)
  │   ├── Empowerment-focused task allocation (AI: pattern/speed; Human: judgment/validation)
  │   └── AI literacy competencies (prompting, tool selection, critical evaluation)
  │
  ├── 2. Ethical AI
  │   ├── Terminologist values (autonomy, precision, diversity preservation)
  │   └── Bias mitigation (upstream: prompting/RAG constraints; downstream: critical review)
  │
  └── 3. Human-Centered Design
      ├── Needs prioritization (prevent reverse adaptation)
      ├── Participatory design (terminologist involvement throughout)
      ├── Cognitive ergonomics (reduce load, support decision-making)
      └── Explainability features (RAG sourcing, chain-of-thought)
  ```

- Critical path:
  1. Map existing terminology workflow to identify AI-augmentable subtasks
  2. Benchmark LLM performance on each subtask across relevant languages/domains
  3. Design automation/control allocation at subtask granularity (not whole-task)
  4. Implement RAG with terminologist-curated corpora; add explainability features
  5. Establish validation checkpoints with intentional friction (confirmation dialogs)
  6. Collect terminologist feedback iteratively; adjust tool behavior

- Design tradeoffs:
  - Full automation vs. validation overhead: More automation increases throughput but risks undetected errors/bias; validation adds time but preserves quality
  - RAG explainability vs. training-data insights: RAG provides traceable sources but limits model's broader knowledge; chain-of-thought offers partial explainability for non-retrieved insights
  - Immediate AI suggestions vs. anchoring prevention: Showing AI output first risks anchoring bias; delaying suggestions until human initial analysis preserves independent judgment but adds friction

- Failure signatures:
  - **Over-automation**: Terminologist reduced to "button-clicker" validating without critical engagement → deskilling, missed errors, bias reproduction
  - **Top-down imposition**: Tools deployed without terminologist input → resistance, workaround behaviors, perceived control loss
  - **Anchoring effect**: Terminologists converge on AI suggestions without exploring alternatives → reduced terminological diversity
  - **Bias feedback loop**: AI-generated terminology enters corpora or training data → amplified linguistic/cultural distortion over time

- First 3 experiments:
  1. **Subtask-level benchmarking**: Select 3 terminological tasks (e.g., term extraction, definition generation, equivalence proposal); test 2-3 LLMs across 2 languages (including one non-English) and 2 domains; measure accuracy, consistency, and bias indicators; identify which tasks warrant automation vs. require human control.
  2. **Validation friction A/B test**: Implement two interface variants—one with immediate AI suggestions, one with delayed suggestions after initial human analysis; measure terminologist decision patterns, time-on-task, and output diversity; test whether delayed presentation reduces anchoring.
  3. **Terminologist feedback collection**: Conduct structured interviews with 5-10 practicing terminologists using prototype AI-assisted tools; probe perceived control, tool appropriateness, and unmet needs; iterate on automation levels and interface design based on feedback.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs perform across specific terminological tasks and subtasks when handling complex semantic phenomena such as denominative variation, multidimensionality, and metaphor?
- Basis in paper: [explicit] The paper explicitly calls for "benchmarking LLMs across various tasks and subtasks of TW to identify where they perform well and where they fall short," specifically noting that evaluations must account for complex semantic features (p. 9).
- Why unresolved: Current empirical studies are small-scale and show inconsistent results; there is no comprehensive understanding of how LLMs handle the "intricate semantic phenomena" inherent to terminology work.
- What evidence would resolve it: Systematic performance evaluations of LLMs across diverse languages and domains, specifically testing for accuracy in generating definitions and extracting terms that involve polysemy and metaphorical language.

### Open Question 2
- Question: Which specific forms of AI augmentation do terminologists value most, and how do these preferences align with emerging tool capabilities?
- Basis in paper: [explicit] The author states that "Research should also actively seek input from terminologists about the types of augmentation they find valuable and the forms they would prefer this to take" (p. 10).
- Why unresolved: While tools are being developed, there is a lack of empirical data on whether terminologists prefer embedded AI (e.g., within corpus analysis tools) versus automated output generation, or how they balance efficiency with control.
- What evidence would resolve it: Surveys and focus groups with professional terminologists to rank the utility of different AI-assisted workflows (e.g., post-editing definitions vs. intelligent support).

### Open Question 3
- Question: To what extent do LLMs reproduce linguistic, cultural, and epistemic biases when generating terminological outputs for non-dominant languages and Global South contexts?
- Basis in paper: [explicit] The paper notes that research is needed to contribute to bias mitigation "by evaluating LLMs with respect to different types of bias in terminological tasks" (p. 16).
- Why unresolved: While theoretical links between training data (e.g., Common Crawl) and bias exist, the specific impact of "Anglo-American conceptual systems" or "epistemic bias" on terminological products remains under-evaluated.
- What evidence would resolve it: Comparative studies analyzing AI-generated definitions and term equivalents for low-resource languages to detect hallucinated terms, cultural misrepresentations, or the erasure of local conceptual frameworks.

### Open Question 4
- Question: Do specific human-centered design interventions, such as "intentional friction" or delayed suggestions, successfully mitigate automation risks like reduced critical engagement and anchoring?
- Basis in paper: [explicit] The paper suggests that design options for mitigating anchoring and reduced critical engagement "should be regarded as provisional hypotheses whose practical value depends on systematic empirical evaluation" (p. 19).
- Why unresolved: Strategies like confirmation dialogs or delaying AI output are proposed based on theory, but their effectiveness in actual terminological workflows is unverified.
- What evidence would resolve it: Usability studies and observational research measuring error detection rates and cognitive load in workflows that implement these friction-based design principles versus standard AI interfaces.

## Limitations

- The framework's effectiveness depends heavily on terminologist adoption and sustained engagement, yet the paper provides limited evidence on how to overcome institutional resistance or resource constraints in terminology departments.
- The bias mitigation mechanisms assume terminologists have sufficient time and training to conduct critical reviews, which may not hold in high-volume production environments.
- The framework lacks specific implementation guidelines for different terminology domains (e.g., medical vs. technical) and doesn't address scalability challenges when transitioning from pilot studies to enterprise deployment.

## Confidence

- **High confidence**: The compatibility of high automation with strong human control as a conceptual framework (supported by Shneiderman's HCAI paradigm and multiple related studies)
- **Medium confidence**: The bias mitigation mechanisms through terminologist-led upstream/downstream interventions (theoretically sound but limited empirical validation in terminology context)
- **Medium confidence**: Human-centered design principles increasing adoption (supported by translation studies but not specifically tested with AI-assisted terminology tools)

## Next Checks

1. **Implementation feasibility study:** Conduct a 3-month pilot with 2-3 terminology departments to test the framework's practical applicability, measuring both adoption rates and quality outcomes across different organizational contexts.

2. **Bias detection protocol validation:** Develop and validate a standardized rubric for identifying linguistic, cultural, epistemic, and social biases in AI-generated terminology across multiple language pairs, then test it with terminologists from diverse linguistic backgrounds.

3. **Longitudinal deskilling assessment:** Track terminologist skill development over 6-12 months of AI-assisted work to determine whether the framework prevents deskilling or creates new competency requirements that current training programs don't address.