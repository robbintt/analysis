---
ver: rpa2
title: Data Augmentation for Maltese NLP using Transliterated and Machine Translated
  Arabic Data
arxiv_id: '2509.12853'
source_url: https://arxiv.org/abs/2509.12853
tags:
- arabic
- maltese
- data
- language
- transliteration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether Arabic-language resources can be
  leveraged to improve low-resource Maltese NLP through cross-lingual data augmentation.
  The authors introduce novel transliteration systems that better align Arabic orthography
  with Maltese, and evaluate their impact across monolingual and multilingual models.
---

# Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data

## Quick Facts
- arXiv ID: 2509.12853
- Source URL: https://arxiv.org/abs/2509.12853
- Reference count: 11
- Primary result: Arabic-based augmentation significantly improves low-resource Maltese NLP performance, with cascaded fine-tuning on original, transliterated, and machine-translated Arabic data yielding the best outcomes for multilingual models.

## Executive Summary
This paper addresses the low-resource challenge in Maltese NLP by leveraging Arabic-language resources through cross-lingual data augmentation. The authors introduce novel transliteration systems that better align Arabic orthography with Maltese, and evaluate their impact across monolingual and multilingual models. Results demonstrate that appropriate cross-lingual augmentation strategies can effectively improve performance on Maltese Named-Entity Recognition and Sentiment Analysis tasks, with cascaded fine-tuning approaches showing particular promise for multilingual models.

## Method Summary
The study employs Arabic datasets (ANERCorp for NER, ArSenTD-Lev for SA) to augment low-resource Maltese tasks using three augmentation strategies: original Arabic script, transliterated Arabic (both character-based and morphology-aware), and machine-translated Arabic-to-Maltese text. Models tested include BERTu (monolingual Maltese), mBERT (multilingual), and mBERTu (mBERT with Maltese pre-training). A cascaded fine-tuning approach is introduced for multilingual models, involving sequential training on original Arabic, transliterated Arabic, and Maltese data. The methodology is implemented using the MLRS/maltify_arabic and MLRS/BERTu repositories with CAMeL Tools for Arabic processing.

## Key Results
- Transliteration significantly reduces tokenization "fertility" for monolingual models, improving performance by making semantically related Arabic data readable
- Multilingual models achieve peak performance through cascaded fine-tuning: Original Arabic → Transliterated Arabic → Maltese
- Morphology-aware transliteration (MorphTx) outperforms naive character mapping by explicitly handling affixation rules and reducing noise in the augmented training signal

## Why This Works (Mechanism)

### Mechanism 1: Orthographic Alignment via Fertility Reduction
Monolingual models possess vocabularies optimized for specific scripts. When fed Arabic script, the tokenizer fragments unknown characters into individual bytes or sub-words, destroying semantic content and increasing sequence length (fertility). Transliteration maps these characters to the Latin script expected by the model, lowering fertility and allowing processing of shared Semitic morphology. BERTu fertility drops from ~4 (Original Arabic) to ~1-2 with transliteration, correlating with performance gains.

### Mechanism 2: Cascaded Knowledge Bridge
Multilingual models like mBERT possess pre-trained "knowledge" of Arabic in its native script. By fine-tuning first on original Arabic, the model activates relevant cross-lingual sub-spaces; subsequent fine-tuning on transliterated data bridges these sub-spaces to the target Maltese orthography. This prevents the model from being shocked by a sudden distribution shift which might cause it to "forget" the cross-lingual alignment.

### Mechanism 3: Morphological Residualization
Morphology-aware transliteration (MorphTx) outperforms naive character mapping by explicitly handling affixation rules, reducing noise in the augmented training signal. While CharTx maps characters blindly, MorphTx uses a disambiguator to map specific morphemes (e.g., Arabic 'Al' -> Maltese 'il-'), providing a cleaner training signal that regularizes the model toward correct Maltese grammar.

## Foundational Learning

- **Concept: Tokenizer Fertility** - Explains why simply feeding Arabic text to a Latin-script model fails. High fertility means a single word is shattered into many meaningless tokens, diluting the attention mechanism. *Quick check: If a model's fertility is 5.0 for a dataset, how many sub-tokens does the average word produce?*

- **Concept: Script Mismatch in Transfer Learning** - Standard cross-lingual transfer assumes shared sub-word vocabularies. Script differences (Arabic vs. Latin) break this assumption completely, forcing reliance on transliteration or translation. *Quick check: Why might a multilingual model (mBERT) prefer original script while a monolingual model (BERTu) prefers transliterated script?*

- **Concept: Catastrophic Forgetting vs. Curriculum Learning** - The "Cascaded" approach acts as a curriculum. It prevents the model from being shocked by a sudden distribution shift (from Arabic script to Maltese Latin script) which might cause it to "forget" the cross-lingual alignment. *Quick check: In a cascaded setup, why do we fine-tune on the "Original" source data before the "Transliterated" data for multilingual models?*

## Architecture Onboarding

- **Component map:** Arabic Dataset (ANERCorp/ArSenTD-Lev) → Processor 1 (MorphTx: CAMeL Tools Morphological Disambiguator → Rule-based Mapper → Maltese-like Latin Text) → Processor 2 (MT: Google Translate API → Maltese Text) → Model Zoo (mBERT, BERTu, mBERTu) → Trainer (Cascaded Fine-tuning Loop: Orig → Tx/MT → Target)

- **Critical path:**
  1. Implementing the MorphTx pipeline (dependency on external morphological analyzer)
  2. Orchestrating the Cascaded Training Loop (saving/loading intermediate checkpoints correctly)
  3. Fertility Analysis to validate that transliteration actually lowers token complexity for the target model

- **Design tradeoffs:**
  - CharTx vs. MorphTx: CharTx is faster and stateless but produces noisier orthography. MorphTx is linguistically precise but depends on the accuracy of the disambiguator and processing speed.
  - MT vs. Transliteration: MT produces fluent Maltese but may lose the strict 1:1 lexical alignment with the original Arabic data. Transliteration preserves structure but looks "foreign" (archaic/loan-word heavy).

- **Failure signatures:**
  - High Fertility Failure: BERTu performance collapses (< random guess). Check tokenization stats; likely fed original Arabic script.
  - Semantic Drift Failure: mBERT performs worse on Maltese test set than baseline. Likely fine-tuned *only* on transliterated data, breaking its internal cross-lingual embeddings.
  - Overfitting Failure: Performance on Validation (Maltese) peaks too early. The augmented data might be too voluminous relative to the tiny Maltese fine-tuning set; reduce Arabic data sampling.

- **First 3 experiments:**
  1. Fertility Baseline: Measure and plot tokenizer fertility for BERTu and mBERT across Original, Buckwalter, CharTx, and MT inputs to confirm the orthographic alignment hypothesis.
  2. Mono vs. Multi Augmentation: Fine-tune BERTu on CharTx data and mBERT on Original data to verify the paper's claim that model pre-training dictates the preferred input script.
  3. Cascading Validation: Run a grid search on mBERTu comparing [Orig -> Maltese] vs. [Orig -> Tx -> Maltese] to quantify the specific delta provided by the cascading mechanism.

## Open Questions the Paper Calls Out

- Can unsupervised or self-supervised methods align Arabic and Maltese representations effectively without relying on parallel data or extensive linguistic analysis? The current study relies on manually crafted rules and machine translation; the authors have not yet tested alignment methods that operate without such supervision.

- Can advanced neural transliteration models capture morphological and phonological patterns well enough to outperform the proposed rule-based transliteration systems? The paper introduces and evaluates rule-based systems (CharTx and MorphTx), but does not compare them against neural transliteration baselines.

- Does the benefit of Arabic data augmentation extend to generative tasks like language modeling, or is it limited to the discriminative tasks (NER, SA) tested? The experimental scope was restricted to classification tasks, leaving the impact on generative capabilities unknown.

- To what extent does the specific choice of Arabic dialect (e.g., Tunisian vs. Egyptian) in the morphological analyzer impact the accuracy of Maltese cross-lingual transfer? The study could not isolate the effect of dialectal distance because it was constrained by tool availability, potentially introducing noise in the morphological mapping phase.

## Limitations
- The "fertility" metric used to justify the transliteration approach is a novel construct without broader NLP literature support
- The very small Maltese training sets (155 sentences for NER, 595 for SA) create statistical fragility
- The study only evaluates two downstream tasks (NER and SA), limiting generalizability

## Confidence
- **High Confidence:** Mechanism 1 (Orthographic Alignment via Fertility Reduction) - Supported by direct fertility measurements and BERTu performance drops with original Arabic
- **High Confidence:** Mechanism 2 (Cascaded Knowledge Bridge) - Well-supported by comparative results showing cascaded approaches outperform single-stage fine-tuning
- **Medium Confidence:** Mechanism 3 (Morphological Residualization) - Supported by comparative performance but lacks ablation studies isolating morphological vs. orthographic effects
- **Medium Confidence:** Overall claim that Arabic augmentation meaningfully improves Maltese NLP - While results are positive, the small data sizes and limited task scope warrant caution

## Next Checks
1. Ablation Study on Morphological vs. Orthographic Effects: Create a controlled experiment that separates the impact of script conversion (orthography) from morphological refinement by testing CharTx with and without morphology-aware post-processing on the same models.

2. Cascaded Fine-tuning Robustness Test: Systematically vary the number of epochs and data ratios in each cascaded stage to identify whether the improvement comes from the curriculum structure itself or from simple additional training data exposure.

3. Cross-Dialect Generalizability: Apply the full pipeline (including MorphTx) to Arabic text from a different dialect (e.g., Levantine or Gulf Arabic) to test whether the morphological disambiguator's performance and resulting model improvements hold across dialectal variation.