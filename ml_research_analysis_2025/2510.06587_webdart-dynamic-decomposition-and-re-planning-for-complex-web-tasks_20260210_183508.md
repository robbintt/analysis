---
ver: rpa2
title: 'WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks'
arxiv_id: '2510.06587'
source_url: https://arxiv.org/abs/2510.06587
tags:
- navigation
- page
- information
- task
- webdart
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'WebDART is a framework for improving large language model agents
  on complex web tasks that require multi-step reasoning, long-horizon navigation,
  and structured information extraction. It addresses the cognitive overload that
  occurs when agents attempt to handle all these operations simultaneously by dynamically
  decomposing tasks into three focused subtasks: navigation, information extraction,
  and execution.'
---

# WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks

## Quick Facts
- arXiv ID: 2510.06587
- Source URL: https://arxiv.org/abs/2510.06587
- Reference count: 40
- Primary result: Improves state-of-the-art agent success rates by up to 13.7 percentage points on complex web tasks

## Executive Summary
WebDART addresses the challenge of complex web tasks that require multi-step reasoning, long-horizon navigation, and structured information extraction by introducing a dynamic decomposition framework. The system splits tasks into three focused subtasks—navigation, information extraction, and execution—allowing the model to concentrate on one skill at a time rather than handling all operations simultaneously. A continuous re-planning mechanism adapts the decomposition as new web elements are discovered, avoiding redundant exploration and improving efficiency.

## Method Summary
WebDART is a training-free framework that dynamically decomposes complex web tasks into three focused subtasks: navigation, information extraction, and execution. The framework uses an LLM to generate conservative navigation objectives while deferring complex constraints to later stages. During navigation, a dynamic re-planning module continuously updates the plan when new interface elements like filters or sort options are discovered. The information extraction phase uses LLMs to extract structured data into JSONL format, followed by an execution phase that either generates Python code for analysis or performs short-horizon navigation actions.

## Key Results
- Improves state-of-the-art agent success rates by up to 13.7 percentage points on WebChoreArena
- Reduces navigation steps by up to 14.7% through dynamic re-planning
- Maintains competitive performance on simpler WebArena tasks while excelling at complex chores
- Demonstrates effectiveness across multiple domains including Shopping, Reddit, and recipe tasks

## Why This Works (Mechanism)

### Mechanism 1: Skill-Specific Decomposition
- **Claim:** Decomposing tasks into navigation, extraction, and execution improves success rates
- **Core assumption:** Performance bottlenecks stem from interleaving multiple skills simultaneously
- **Evidence:** Task decomposition reduces cognitive burden and makes complex objectives more tractable

### Mechanism 2: Opportunity-Driven Re-planning
- **Claim:** Dynamically revising navigation plans when discovering new web elements reduces steps
- **Core assumption:** Initial plans can be improved by incorporating information gained during exploration
- **Evidence:** Dynamic re-planning reduces navigation steps from 32.9 to 18.2 in Shopping domain

### Mechanism 3: Deferred Constraint Analysis
- **Claim:** Shifting data operations from navigation to execution phase improves robustness
- **Core assumption:** LLMs are more reliable at data analysis with structured data and code execution
- **Evidence:** Design reduces error propagation and alleviates burden on fragile navigation processes

## Foundational Learning

- **Concept: Accessibility Tree Representation**
  - **Why needed here:** Primary input format for web agent; crucial for debugging observation issues
  - **Quick check question:** How would a complex interactive menu be represented in an accessibility tree vs visual HTML?

- **Concept: In-Context Learning (Few-Shot Prompting)**
  - **Why needed here:** Framework relies entirely on prompting strategies for decomposition and navigation
  - **Quick check question:** How might choice of in-context examples bias agent toward conservative or aggressive navigation?

- **Concept: JSONL (JSON Lines) Data Format**
  - **Why needed here:** Structured output of information extraction and input for execution module
  - **Quick check question:** Why is JSONL suitable for aggregating extracted information from multiple web pages?

## Architecture Onboarding

- **Component map:** Task Description → Decomposition (T_nav, T_ie, T_exec) → Navigation (generates h_T) → Information Extraction (generates JSONL) → Execution (produces Final Answer)

- **Critical path:** The decomposition module splits tasks into three subtasks, navigation generates web page trajectories with dynamic re-planning, information extraction creates structured JSONL data, and execution performs final analysis or actions

- **Design tradeoffs:**
  - Conservative vs. Tight Decomposition: Defaults to conservative plan to ensure coverage but risks inefficiency
  - LLM Extraction vs. Generated Code Parsing: LLM extraction found more robust than code parsing for site structure changes

- **Failure signatures:**
  - Excessive navigation steps: Dynamic re-planning module failing to identify shortcuts
  - Empty/malformed JSONL: Information extraction module failure due to unexpected page content
  - Code execution errors: Mismatch between JSONL data format and analysis expectations

- **First 3 experiments:**
  1. Reproduce WebChoreArena Baseline: Establish baseline success rate and navigation steps for different domains
  2. Ablation of Re-planning: Compare agent performance with and without dynamic re-planning
  3. Analyze Decomposition Quality: Inspect generated (T_nav, T_ie, T_exec) for constraint deferral and navigation conservatism

## Open Questions the Paper Calls Out
- **Multimodal Extension:** Framework focuses on text-based agents but naturally extends to multimodal environments; evaluation on visual benchmarks remains unverified
- **Code Generation for Extraction:** Current prompt-based extraction used despite exploring code generation; potential for self-repairing code unexplored
- **Conservative Strategy Overhead:** Default conservative decomposition may introduce unnecessary overhead on standard websites with predictable layouts

## Limitations
- Relies heavily on LLM's ability to correctly interpret newly discovered web elements
- Evaluated primarily on WebChoreArena with limited testing on open web environments
- Performance characteristics with different backbone LLMs than those tested remain unknown

## Confidence
- **High confidence:** Core skill-specific decomposition mechanism and effectiveness of deferring analysis to execution phase
- **Medium confidence:** Dynamic re-planning mechanism's quantitative improvements depend on specific conditions
- **Low confidence:** Performance on highly dynamic web pages and robustness to significantly different structures

## Next Checks
1. **Cross-Environment Robustness:** Test WebDART on open web environments with different page structures to assess generalizability
2. **Ablation Study on Re-planning Triggers:** Systematically vary re-planning conditions to quantify efficiency gains vs plan disruption
3. **Scalability Analysis:** Evaluate performance as task complexity scales up to identify bottlenecks in extraction or execution phases