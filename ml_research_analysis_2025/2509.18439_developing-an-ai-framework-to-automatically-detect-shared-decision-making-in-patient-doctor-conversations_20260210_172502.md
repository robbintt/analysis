---
ver: rpa2
title: Developing an AI framework to automatically detect shared decision-making in
  patient-doctor conversations
arxiv_id: '2509.18439'
source_url: https://arxiv.org/abs/2509.18439
tags:
- x10-5
- x10-4
- page
- were
- bert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed an AI framework to automatically measure shared
  decision-making (SDM) in patient-doctor conversations using conversational alignment
  (CA) scores. The framework trained deep learning models to understand conversational
  styles and calculated CA scores based on the alignment between patients and clinicians.
---

# Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations

## Quick Facts
- arXiv ID: 2509.18439
- Source URL: https://arxiv.org/abs/2509.18439
- Reference count: 0
- AI framework achieved highest recall@1 of 0.640 using fine-tuned BERTBASE model

## Executive Summary
This study developed an AI framework to automatically measure shared decision-making (SDM) in patient-doctor conversations through conversational alignment (CA) scores. The framework uses deep learning models to understand conversational styles and calculate CA scores based on alignment between patients and clinicians. The researchers found that the fine-tuned BERTBASE model achieved the highest recall@1 of 0.640 among 157 patient-doctor conversations. The Max CA score derived from this model was significantly associated with the Decisional Conflict Scale (DCS) score, while the AbsMax and Max CA scores from the deep learning model without stylebook were significantly associated with the Observing Patient Involvement in Decision-Making 12 (OPTION12) score.

## Method Summary
The researchers developed an AI framework that trained deep learning models to understand conversational styles in patient-doctor interactions. They calculated CA scores based on the alignment between patients and clinicians during conversations. The framework utilized BERTBASE models and compared performance with other deep learning approaches, both with and without stylebook features. The study analyzed 157 patient-doctor conversations, primarily involving type 2 diabetes patients undergoing shared decision-making with a single clinician. The CA scores were validated against two established SDM measurement instruments: the Decisional Conflict Scale (DCS) and the Observing Patient Involvement in Decision-Making 12 (OPTION12).

## Key Results
- Fine-tuned BERTBASE model achieved highest recall@1 of 0.640 among evaluated models
- Max CA score from BERTBASE model significantly associated with DCS score (-27.61 ±12.63, p=0.032)
- AbsMax and Max CA scores from DL model without stylebook significantly associated with OPTION12 score

## Why This Works (Mechanism)
The framework works by capturing the alignment between conversational partners through deep learning models that understand conversational patterns and styles. The CA scores quantify how well patients and clinicians align their communication, which serves as a proxy for shared decision-making quality. The significant associations between CA scores and validated SDM instruments (DCS and OPTION12) demonstrate that conversational alignment is a meaningful indicator of SDM effectiveness. The use of BERTBASE, which has strong language understanding capabilities, enables accurate detection of conversational nuances that contribute to effective shared decision-making.

## Foundational Learning
- **Conversational alignment**: Measure of how well communication partners match their conversational styles and patterns; needed to quantify SDM quality, quick check: correlation with established SDM instruments
- **Shared decision-making**: Collaborative process where patients and clinicians make health decisions together; needed as target outcome, quick check: validated by DCS and OPTION12 scores
- **BERTBASE architecture**: Transformer-based language model pre-trained on large text corpora; needed for understanding conversational nuances, quick check: achieved highest recall@1 of 0.640
- **Decisional Conflict Scale (DCS)**: Patient-reported outcome measure of decisional conflict; needed as gold standard validation, quick check: significant association with Max CA score
- **OPTION12 instrument**: Observational tool measuring patient involvement in decision-making; needed for clinical validation, quick check: significant association with AbsMax and Max CA scores

## Architecture Onboarding

**Component Map**: Patient-doctor conversations -> Text preprocessing -> BERTBASE/DL model -> CA score calculation -> Validation against DCS/OPTION12

**Critical Path**: Conversation data collection → Text preprocessing → Model training/fine-tuning → CA score generation → Statistical validation with SDM instruments

**Design Tradeoffs**: The study chose BERTBASE over simpler models for better language understanding at the cost of computational complexity; opted for validation against established instruments rather than developing new metrics

**Failure Signatures**: Low recall scores would indicate poor model performance; lack of significant associations with DCS/OPTION12 would suggest CA scores don't capture SDM quality; poor generalization to other clinical contexts would limit applicability

**3 First Experiments**:
1. Test model performance on conversations from different medical specialties
2. Compare CA scores with expert human ratings of SDM quality
3. Evaluate model sensitivity to conversation length and structure variations

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Small sample size of 157 conversations may limit generalizability and robustness
- Focus on single clinician and specific patient population (type 2 diabetes) raises external validity concerns
- Reliance on two specific validated instruments may not capture full spectrum of SDM quality
- Black-box nature of deep learning models remains a concern despite explainable CA scores

## Confidence
- High confidence: Technical implementation of BERTBASE model and CA score calculation methodology
- Medium confidence: Significant associations between CA scores and SDM outcomes (DCS and OPTION12)
- Low confidence: Generalizability of findings to broader clinical settings and different patient populations

## Next Checks
1. External validation with a larger, more diverse dataset including multiple clinicians, specialties, and decision types to assess generalizability
2. Head-to-head comparison of the AI framework's CA scores with expert human ratings of SDM quality to establish criterion validity
3. Prospective clinical trial testing whether CA score feedback to clinicians improves shared decision-making outcomes over time compared to control groups