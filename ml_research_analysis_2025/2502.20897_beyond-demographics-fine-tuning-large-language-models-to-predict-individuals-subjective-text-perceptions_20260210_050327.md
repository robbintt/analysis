---
ver: rpa2
title: 'Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals''
  Subjective Text Perceptions'
arxiv_id: '2502.20897'
source_url: https://arxiv.org/abs/2502.20897
tags:
- attributes
- annotator
- degree
- annotators
- sociodemographic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether large language models (LLMs) can be
  trained to predict individuals' subjective text perceptions based on sociodemographic
  attributes. The authors curate DEMO, a dataset combining five tasks (intimacy, offensiveness,
  politeness, safety, sentiment) with standardized sociodemographic metadata.
---

# Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals' Subjective Text Perceptions

## Quick Facts
- arXiv ID: 2502.20897
- Source URL: https://arxiv.org/abs/2502.20897
- Authors: Matthias Orlikowski; Jiaxin Pei; Paul Röttger; Philipp Cimiano; David Jurgens; Dirk Hovy
- Reference count: 40
- Primary result: LLMs cannot reliably model annotators based on sociodemographics alone; they learn individual behavior from examples instead

## Executive Summary
This paper investigates whether large language models can predict individuals' subjective text perceptions based on sociodemographic attributes. The authors curate DEMO, a dataset combining five annotation tasks (intimacy, offensiveness, politeness, safety, sentiment) with standardized sociodemographic metadata. They fine-tune Llama 3 8B using different input formats: content only, content with attributes, content with annotator ID, and content with both attributes and ID. Results show that while models improve when trained with sociodemographics compared to zero-shot prompting, they perform significantly better when given annotator IDs. Critically, models fail to generalize to unseen annotators regardless of whether sociodemographic attributes or IDs are provided. Further analysis reveals that sociodemographic attributes primarily serve as proxies for annotator identity rather than capturing meaningful relationships between attributes and annotation behavior.

## Method Summary
The authors curate DEMO, a dataset combining five subjective annotation tasks with standardized sociodemographic metadata from 2,614 annotators. They fine-tune Llama 3 8B using LoRA (r=8, α=16) with classification heads for 3-5 classes. Four input formats are tested: content only, content with attributes, content with annotator ID, and content with both attributes and ID. Evaluation uses macro-averaged F1 on two splits: instance split (seen annotators) and annotator split (unseen annotators). Models are trained with 30 random seeds and evaluated with 95% confidence intervals via bootstrap. Wasserstein distance measures disagreement prediction quality.

## Key Results
- Models improve when trained with sociodemographics compared to zero-shot prompting, but this gain is largely due to learning annotator-specific behavior rather than sociodemographic patterns
- Models perform significantly better when given annotator IDs versus sociodemographics alone
- Models fail to generalize to unseen annotators regardless of whether sociodemographic attributes or IDs are provided
- Sociodemographic attributes primarily serve as proxies for annotator identity for uniquely identifiable profiles, not for capturing meaningful relationships between attributes and annotation behavior

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fine-tuning with annotator IDs enables individual-level behavior modeling but not demographic generalization
- **Mechanism:** The model associates each unique ID token sequence with specific annotation patterns observed during training. When the ID appears at inference, the model retrieves the learned behavior pattern for that specific annotator. This operates as a lookup table keyed by ID rather than a compositional model of how attributes influence judgments
- **Core assumption:** Annotator behavior is sufficiently consistent across their annotations for patterns to be learnable from training examples
- **Evidence anchors:**
  - [abstract] "models do improve in sociodemographic prompting when trained but that this performance gain is largely due to models learning annotator-specific behaviour rather than sociodemographic patterns"
  - [section 5.2] "when models are prompted with a unique annotator ID, they are even more accurate at predicting the annotator's label"
  - [corpus] Limited direct evidence; neighbor paper "Value Profiles for Encoding Human Variation" explores related individual modeling but via value descriptions rather than IDs
- **Break condition:** When annotators in test set were unseen during training, ID-based models perform no better than content-only baseline (Figure 3)

### Mechanism 2
- **Claim:** Sociodemographic attributes improve prediction only when attribute combinations uniquely identify annotators
- **Mechanism:** For annotators with rare attribute combinations (e.g., "Non-binary, 40-44, Pacific Islander, Graduate degree"), the attribute string functions as a unique key. The model memorizes the mapping from this unique string to annotation behavior. For annotators with common profiles shared by many people, the attribute string is ambiguous and provides no discriminative signal
- **Core assumption:** The training distribution contains sufficient uniquely-identifiable annotators for the apparent "demographic" improvement to manifest
- **Evidence anchors:**
  - [section 6.1] "the largest gains occur when LLMs are predicting ratings for the annotators in the Unique subset, but no consistent or substantial gains for predicting ratings of annotators in the Frequent subset"
  - [section 6.1] "unique sociodemographics are acting as proxies for identity and, thus, the LLM is not learning any meaningful relationship between attributes and labelling"
  - [corpus] Neighbor paper "What Helps Language Models Predict Human Beliefs" suggests prior stances may be more predictive than demographics—consistent with attributes-as-proxy explanation
- **Break condition:** When all annotators share identical attribute profiles, or when evaluating on unseen annotators, attribute-based gains disappear entirely

### Mechanism 3
- **Claim:** Models trained with annotator information better capture disagreement distributions, particularly for high-entropy instances
- **Mechanism:** By learning individual annotator tendencies, models implicitly learn when annotators diverge versus converge on labels. For high-disagreement cases (high label entropy), the model can predict different annotators will assign different labels, producing distribution predictions closer to ground truth
- **Core assumption:** Disagreement patterns are consistent within annotators across instances
- **Evidence anchors:**
  - [section 6.2] "Models get better at predicting cases of disagreement when including attributes and IDs"
  - [section 6.2] "distances to the actual rating distribution are smallest on higher disagreement cases when including IDs"
  - [corpus] Neighbor paper "Humans Hallucinate Too" addresses annotation variation in subjective tasks but focuses on error detection rather than disagreement modeling
- **Break condition:** If annotators are inconsistent in their disagreement patterns, or if disagreement is instance-specific rather than annotator-specific, this mechanism fails

## Foundational Learning

- **Concept: Macro-averaged F1 for multi-class subjective prediction**
  - Why needed here: Standard accuracy masks poor performance on minority labels; subjective tasks often have imbalanced label distributions
  - Quick check question: Given predictions [1,1,1,1,2] and labels [1,1,1,2,2], what is the macro-F1 versus accuracy?

- **Concept: Instance split vs. annotator split evaluation**
  - Why needed here: These partitions test fundamentally different capabilities—generalization to new texts vs. generalization to new people. Conflating them leads to false conclusions about demographic modeling
  - Quick check question: If a model trained with IDs achieves 0.45 F1 on instance split but 0.30 on annotator split, what does this imply about what it learned?

- **Concept: LoRA (Low-Rank Adaptation) fine-tuning**
  - Why needed here: The paper uses LoRA to adapt Llama 3 8B efficiently. Understanding what is and isn't trained (prediction head fully trained, most weights adapted via low-rank updates) matters for interpreting results
  - Quick check question: In LoRA, which parameters are frozen and which are updated? How does this differ from full fine-tuning?

## Architecture Onboarding

- **Component map:** Llama 3 8B base -> LoRA adapter (r=8, α=16) on all linear layers except prediction head and embeddings -> Classification head for 3-5 classes

- **Critical path:**
  1. Format training data with chosen input type (content-only, +Attributes, +ID, +ID+Attributes)
  2. Fine-tune with LoRA using task-specific learning rate (3e-5 to 8e-5)
  3. Evaluate on instance split (seen annotators) and annotator split (unseen annotators)
  4. For analysis: partition test set by unique vs. frequent profiles; compute Wasserstein distance for disagreement analysis

- **Design tradeoffs:**
  - Token budget: Truncating at 232 tokens for content; attributes add ~22 tokens, ID adds ~7 tokens
  - Batch size varies by task (4-16) to fit 48GB GPU memory
  - Learning rate selected per task/format via validation grid search
  - 30 random seeds per configuration for reliable confidence intervals

- **Failure signatures:**
  - Zero-shot prompting with attributes: inconsistent effects, sometimes negative (Figure 7)
  - Fine-tuned models on annotator split: no improvement over content-only baseline
  - Large confidence intervals on smaller tasks (e.g., Safety) indicate instability

- **First 3 experiments:**
  1. **Replicate instance split baseline:** Fine-tune Llama 3 8B on one DEMO task (e.g., Intimacy) with content-only input. Expect macro-F1 ~0.30-0.35
  2. **Add annotator ID:** Re-train with +ID input format on same task. Expect ~5-10 point F1 improvement over content-only
  3. **Test annotator generalization:** Evaluate both models on annotator-split test set. Expect ID-based gains to disappear, confirming lack of generalization

## Open Questions the Paper Calls Out

- **Question:** Can models trained to predict annotator responses generalize across geocultural contexts, or do learned annotator behaviors remain culturally specific?
  - **Basis in paper:** [explicit] The authors state: "The datasets used in our study are only annotated by annotators from the US... Therefore, we can not carry out cross-geocultural comparisons using the existing datasets to detail how results might transfer to other geocultural contexts."
  - **Why unresolved:** All five DEMO datasets use only US annotators, and existing cross-cultural datasets lack the same standardized sociodemographic attributes needed for comparison
  - **What evidence would resolve it:** Training and evaluating models on datasets with identical annotation tasks and sociodemographic attributes across multiple cultural/linguistic contexts

- **Question:** Under what conditions do sociodemographic attributes outperform annotator IDs for modeling individual annotation behavior?
  - **Basis in paper:** [explicit] The Discussion notes "there are apparently cases when learning from identifiable annotators performs less well" (citing Fleisig et al., 2023), and calls for future work to "investigate the influence of dataset characteristics and used architectures."
  - **Why unresolved:** The current study finds IDs consistently outperform attributes across five tasks, but conflicting results in prior work suggest unknown moderating factors
  - **What evidence would resolve it:** Systematic experiments varying dataset size, annotation task type, annotator pool diversity, and model architecture to identify when attributes provide unique predictive value

- **Question:** Do rare sociodemographic profiles correlate with systematically different annotation behaviors due to lived experiences, or are they simply functioning as unique identifiers?
  - **Basis in paper:** [explicit] The Appendix discusses: "An alternative reading of our results thus could relate rare profiles to more impactful personal experiences that might explain annotation behaviour to a larger degree. The exact relationship and interactions of these factors warrants investigation in future work."
  - **Why unresolved:** The analysis shows models improve for unique-profile annotators, but cannot disentangle whether this reflects genuine behavioral differences or mere memorization of individual patterns
  - **What evidence would resolve it:** Studies comparing annotation consistency within rare demographic groups across different tasks and contexts, controlling for sample size

## Limitations

- **Limited generalization capability:** The core finding that sociodemographic attributes fail to generalize to unseen annotators represents a fundamental limitation in using LLMs for demographic modeling of subjective judgments
- **Data representation bias:** The DEMO dataset's demographic distribution (primarily US-based, English-speaking annotators) constrains the generalizability of findings
- **Evaluation metric constraints:** While macro-F1 appropriately handles label imbalance in subjective tasks, it may not fully capture the nuanced prediction challenges in multi-class subjective judgments

## Confidence

- **High confidence:** Models cannot generalize to unseen annotators using sociodemographic attributes alone
- **High confidence:** Annotator IDs enable individual-level behavior modeling but fail at generalization
- **Medium confidence:** Sociodemographic attributes primarily function as identity proxies for uniquely identifiable profiles

## Next Checks

1. Replicate the annotator-split evaluation using a cross-validation approach where each fold contains disjoint annotator sets
2. Test whether increasing model capacity (e.g., Llama 3 70B) improves generalization to unseen annotators
3. Evaluate whether providing historical annotation patterns rather than sociodemographic attributes improves prediction for unseen annotators