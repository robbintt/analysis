---
ver: rpa2
title: 'Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling
  via Unsupervised Neural Instance Modification'
arxiv_id: '2602.00580'
source_url: https://arxiv.org/abs/2602.00580
tags:
- tour
- instance
- tsp-mdf
- heuristic
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TSP-MDF introduces an unsupervised instance modification framework
  that enhances traditional deterministic TSP heuristics by enabling guided sampling
  through strategically shifting node coordinates. The method employs a neural-based
  instance modifier that learns to produce multiple modified instances, allowing the
  base heuristic to explore higher-quality tours and escape local optima.
---

# Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification

## Quick Facts
- **arXiv ID:** 2602.00580
- **Source URL:** https://arxiv.org/abs/2602.00580
- **Reference count:** 40
- **Primary result:** Neural-guided coordinate shifting enhances traditional TSP heuristics, achieving performance comparable to neural tour constructors in under 10 minutes training.

## Executive Summary
TSP-MDF introduces an unsupervised framework that enhances traditional deterministic TSP heuristics by strategically shifting node coordinates to enable guided sampling. The method employs a neural instance modifier that learns to produce multiple modified instances, allowing the base heuristic to explore higher-quality tours and escape local optima. By discretizing coordinate offsets and using self-imitation learning, the approach stabilizes training without requiring ground-truth supervision. Experiments on large-scale TSP benchmarks (500-10000 nodes) demonstrate significant improvements over traditional heuristics while maintaining extremely short training times.

## Method Summary
TSP-MDF enhances traditional TSP heuristics (Farthest/Nearest Insertion) by modifying instance coordinates through a neural network that learns to shift nodes strategically. The system uses an anisotropic graph neural network (AGNN) to encode node features and predict discrete coordinate offsets, which are then applied to create modified instances. The base heuristic runs on these modified instances, and the resulting tour lengths are mapped back to evaluate the original instance. Training employs REINFORCE with self-imitation learning to reinforce modifications that reduce tour length, with coordinate offsets discretized into digits for stability. The method iteratively refines solutions over multiple sampling steps, maintaining a current best instance that guides subsequent modifications.

## Key Results
- Outperforms traditional heuristics (Farthest/Nearest Insertion) on TSP-500/1000/10000 benchmarks by 15-20% gap reduction
- Achieves performance comparable to neural tour constructors with only 10 minutes of training time
- Generalizes well to real-world TSPLib instances, maintaining improvement margins
- Ablation studies confirm neural guidance significantly outperforms random coordinate shifts

## Why This Works (Mechanism)

### Mechanism 1: Indirect Steering via Coordinate Perturbation
Traditional heuristics rely on relative distances for greedy decisions. Small coordinate offsets alter the distance matrix, causing the deterministic algorithm to execute different insertion sequences and discover alternative tour topologies when mapped back to original coordinates. This works because base heuristics are sensitive to small input perturbations, and tours optimal for perturbed instances remain high-quality when remapped.

### Mechanism 2: Density of High-Quality Modifications
The solution space of effective instance modifications is denser than the space of high-quality direct tours. Multiple distinct coordinate shifts can perturb the heuristic toward the same improved tour, increasing the probability of discovery compared to searching for the single optimal tour directly. This "one-to-many" mapping makes the modification space easier to navigate than the tour space.

### Mechanism 3: Stabilization via Discrete Self-Imitation
Modeling coordinate offsets as discrete digits with self-imitation learning prevents high-variance gradients associated with continuous reinforcement learning. The model classifies discrete digits (0-9) for offset values and imitates its own best historical modifications, anchoring exploration to proven gains rather than random noise. This ensures the "unchanged" state remains a stable baseline.

## Foundational Learning

- **Concept: Deterministic Tour Constructors (e.g., Insertion Heuristics)**
  - **Why needed here:** The system acts as a wrapper around these algorithms. You must understand these are fast but "blind" greedy algorithms that produce exactly one output for a given input.
  - **Quick check question:** If you rotate a TSP instance, does a Nearest Insertion heuristic produce the same tour sequence? (Answer: Generally yes, relative to the coordinates, which is why modifying coordinates changes the output).

- **Concept: REINFORCE / Policy Gradients**
  - **Why needed here:** The modifier is trained unsupervised using RL. Understanding that the network is updated by reinforcing actions (modifications) that led to lower tour costs is critical.
  - **Quick check question:** Why is a baseline (e.g., the current best tour length) subtracted from the reward in REINFORCE? (Answer: To reduce variance and focus learning on improvements rather than just "good" states).

- **Concept: Discretization vs. Regression**
  - **Why needed here:** The paper moves from continuous coordinate prediction to classification over digits. This is a key architectural choice for stability.
  - **Quick check question:** Why is predicting a floating-point number like 0.005 harder to stabilize for a sampler than predicting "digit 5 in the third decimal place"?

## Architecture Onboarding

- **Component map:** Input coordinates -> AGNN encoder (50-NN graph, 12 layers, dim=32) -> Sign/Magnitude MLPs -> Discrete offset sampling -> Coordinate modification -> Base heuristic solver -> Tour evaluation -> REINFORCE + self-imitation update

- **Critical path:**
  1. **Training:** Sample batch -> Modify Coordinates -> Run Heuristic -> Calculate Tour Length Reduction -> Update AGNN via REINFORCE + Self-Imitation Loss
  2. **Inference:** Start with original instance -> Iteratively sample modifications -> Keep best tour found across iterations T

- **Design tradeoffs:**
  - **Discretization Precision (M):** Higher M allows finer control but increases classification space computational overhead
  - **Parallel vs. Sequential Sampling:** Increasing samples per step offers diminishing returns compared to increasing refinement steps T

- **Failure signatures:**
  - **Output Collapse:** Model outputs identical offsets for all nodes (requires regularization or checking "unchanged" reward logic)
  - **Mode Collapse/Randomness:** Tour lengths become erratic or huge; indicates self-imitation anchoring failure
  - **No Improvement:** Gap between modified and original tours near zero; likely learning rate too low or discretization too coarse

- **First 3 experiments:**
  1. **Sanity Check (TSP-500):** Verify TSP-MDF (T=1) outperforms random modification to confirm network learns structure
  2. **Ablation on Discretization:** Compare continuous vs. discrete offsets on small training run to verify convergence speed differences
  3. **Visual Inspection:** Plot "Original" vs. "Modified" instance coordinates for solved case to ensure shifts are "small" and strategic

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the text provided. However, several areas warrant further investigation based on the method's design and experimental scope.

## Limitations

- The method's effectiveness depends on the assumption that small coordinate perturbations can reliably steer deterministic heuristics, which is empirically validated but theoretically unproven
- Discretization trades precision for stability, but optimal trade-off points and performance degradation with coarser discretization are unexplored
- Experiments focus exclusively on insertion heuristics, leaving generalization to other deterministic methods (Christofides, Lin-Kernighan) untested
- Claims about real-world TSPLib generalization are based on limited analysis without detailed examination of which instances benefit

## Confidence

**High Confidence:** Empirical results showing TSP-MDF improves traditional heuristics on large-scale TSP instances are well-supported by experimental data and ablation studies.

**Medium Confidence:** Mechanism explanations for why instance modification works better than direct tour construction are plausible but not rigorously proven, lacking quantification of modification space versus tour space navigation difficulty.

**Low Confidence:** Generalization claims to real-world TSPLib instances are based on limited analysis, and method's robustness to different TSP distributions (non-uniform node placement) is unclear.

## Next Checks

1. **Sensitivity Analysis:** Systematically vary discretization precision M and analyze trade-off between tour quality and computational overhead to validate current M=4/6 choices.

2. **Heuristic Transferability:** Test TSP-MDF on non-insertion heuristics like Christofides or Lin-Kernighan to determine if coordinate perturbation mechanism generalizes beyond insertion family.

3. **Perturbation Magnitude Study:** Quantify actual coordinate shifts applied during successful modifications (mean, std, max) and correlate with tour improvements to validate "small shifts" sufficiency.