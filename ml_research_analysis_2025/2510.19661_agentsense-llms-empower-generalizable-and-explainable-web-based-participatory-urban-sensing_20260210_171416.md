---
ver: rpa2
title: 'AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory
  Urban Sensing'
arxiv_id: '2510.19661'
source_url: https://arxiv.org/abs/2510.19661
tags:
- urban
- sensing
- agentsense
- worker
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AgentSense is a training-free framework that integrates large language
  models (LLMs) into participatory urban sensing to address the challenges of limited
  generalization and poor interpretability in existing systems. It combines classical
  planners with a multi-agent refinement loop, iteratively improving baseline solutions
  while producing natural language explanations to enhance transparency and trust.
---

# AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing

## Quick Facts
- arXiv ID: 2510.19661
- Source URL: https://arxiv.org/abs/2510.19661
- Reference count: 40
- Primary result: AgentSense achieves 95-100% success rates across seven disturbance types while maintaining interpretability through natural language explanations.

## Executive Summary
AgentSense addresses the challenge of limited generalization and poor interpretability in participatory urban sensing by integrating large language models with classical planners. The framework iteratively refines baseline task assignments under dynamic disturbances while providing explainable solutions. Through extensive experiments on two large-scale mobility datasets, AgentSense demonstrates superior adaptivity and robustness compared to single-agent LLM baselines, maintaining constraint compliance while improving spatio-temporal coverage.

## Method Summary
AgentSense combines classical planners with LLM-powered multi-agent refinement to solve adaptive participatory urban sensing tasks. The process begins with a classical planner generating a constraint-satisfying baseline solution, which serves as the starting point for iterative refinement. A specialized multi-agent system consisting of Solver, Eval, and Memory agents then works collaboratively: the Solver proposes modifications, the Eval validates feasibility and computes metrics using external tools, and the Memory extracts and retrieves high-impact atomic operations from past refinements. This hybrid approach enables both feasibility guarantees and adaptive generalization while producing natural language explanations for transparency.

## Key Results
- Maintains 95-100% success rates across seven disturbance types in large-scale settings
- Achieves higher improvement rates (AIR) than single-agent LLM baselines while requiring fewer iterations
- Outperforms baselines on adaptability and robustness metrics while preserving constraint compliance
- Demonstrates diminishing returns at strong baselines with token costs rising to 8.27×10⁵ for marginal gains

## Why This Works (Mechanism)

### Mechanism 1: Hybrid Classical-LLM Architecture
AgentSense achieves feasibility guarantees and adaptive generalization by combining classical planners with LLM-powered multi-agent refinement. A classical planner generates a constraint-satisfying baseline solution S₀, bounding the search space within feasible regions. LLM agents then iteratively improve S₀ → S₁ → ... → S_N while preserving spatial-temporal feasibility and budget compliance. The assumption is that baseline solutions are sufficiently close to good solutions for iterative refinement to reach them without exhaustive combinatorial search.

### Mechanism 2: Specialized Multi-Agent Role Decomposition
Decomposing refinement into specialized Solver, Eval, and Memory agents improves solution quality and convergence speed compared to single-agent LLMs. The Solver Agent proposes atomic modifications, the Eval Agent computes coverage and cost with structured feedback, and the Memory Agent extracts meta-operations from successful refinements. The assumption is that structured, role-specialized feedback provides better optimization signals than monolithic LLM reasoning.

### Mechanism 3: Meta-Operation Memory with Impact Scoring
Extracting and reusing high-impact atomic operations accelerates convergence by avoiding redundant exploration. Given solution pairs and metric changes, the Memory Agent computes impact scores for operations and stores top performers for retrieval using embedding similarity. The assumption is that successful operations transfer across similar disturbance contexts, though this may break down for highly dissimilar disturbances.

## Foundational Learning

- **NP-hard combinatorial optimization**: The task assignment problem in WPUS is NP-hard, requiring combinatorial optimization beyond LLMs' generative capacity. Understanding why exhaustive search is infeasible explains the hybrid design. Quick check: Can you explain why adding one more worker to a 60-worker assignment doesn't just add one more solution to check?

- **Participatory sensing and spatial-temporal coverage**: The objective function J(D) balances hierarchical entropy and quantity Q(D). Understanding this tradeoff is essential for interpreting evaluation metrics. Quick check: If all workers concentrate in the city center, would entropy E(D) be high or low?

- **LLM agent tool use and structured outputs**: Agents call external functions and must parse/emit structured JSON. Understanding tool-calling patterns helps debug agent failures. Quick check: What happens if an LLM outputs malformed JSON that the tool parser cannot read?

## Architecture Onboarding

- **Component map**: Disturbance → Parser → [structured instruction] → Classical Planner → S₀ → Solver Agent ←→ Eval Agent (tools + vision) → Memory Agent ← [feedback + metrics] → Meta-op DB → retrieval → S_N (Final Solution)

- **Critical path**: Start from classical planner baseline → ensure budget/feasibility constraints are satisfied → then engage multi-agent loop. If baseline violates constraints, agents waste iterations recovering feasibility.

- **Design tradeoffs**: Stronger baselines (GraphDP) leave less room for improvement but require fewer tokens; weaker baselines (Random, TVPG) yield higher AIR gains but more iterations. Memory granularity: meta-operations vs. raw solutions—meta-operations are more transferable but require extraction overhead. Temperature setting: lower temperatures (0.1-0.5) improve convergence speed; higher temperatures (0.9) introduce instability.

- **Failure signatures**: Budget violations occur when single-agent LLMs exceed budget in Large settings; AgentSense maintains 95-100% SR through Eval Agent verification. Non-convergence happens when ANI approaches iteration limit without improvement—check if disturbance is too severe or baseline is already near-optimal. Memory noise occurs when retrieved operations seem irrelevant—inspect embedding similarity scores.

- **First 3 experiments**:
  1. Reproduce Small setting with TVPG baseline on T-Drive: Train on 20 random task instances, verify SR=100%, AIR≈1.5%. This validates the full pipeline.
  2. Ablate Memory Agent: Run same experiments with memory disabled, expect AIR drop of ~0.3-0.5% and ANI increase of 1-2 iterations. This isolates memory contribution.
  3. Test single disturbance type: Apply "Area blocked" with coordinate [4,4], trace the refinement trajectory (should match Figure 5 pattern: feasibility recovery → coverage optimization → convergence). This validates disturbance handling.

## Open Questions the Paper Calls Out

### Open Question 1
Can AgentSense maintain high performance when adapted to smaller language models (e.g., 7B or 3B parameters) to ensure resource efficiency? The current framework relies on large proprietary models (GPT-4, Claude-3), which are computationally expensive and slow for real-time city-wide deployment. Experiments demonstrating comparable Success Rates and Average Improvement Rates using quantized or distilled open-source models would resolve this.

### Open Question 2
To what extent does incorporating fine-grained geographical attributes improve personalized path planning compared to the current uniform grid representation? The current formulation relies on a discretized spatial-temporal grid, which abstracts away specific urban constraints and semantic context. A comparative study showing higher feasibility or coverage when semantic map data (POIs, road networks) is integrated would resolve this.

### Open Question 3
How does the system's performance and feasibility degrade when the assumption of constant worker speed is violated by real-world traffic variability? Section 4.1.1 states that "workers are assumed to move at constant speed in free space," which simplifies the dynamic nature of urban mobility. Robustness testing using variable-speed trajectories or traffic-aware simulation environments would resolve this.

### Open Question 4
What is the optimal cost-benefit trade-off for the refinement loop when applied to already strong baselines? Section 4.3 notes "diminishing returns" where token costs rise significantly (e.g., to 8.27×10⁵) for marginal improvements (0.175%) on strong baselines like GraphDP. The paper does not define a stopping criterion to prevent the system from wasting computational resources on negligible gains. An analysis defining a utility threshold where the cost of further LLM iterations exceeds the value of the objective improvement would resolve this.

## Limitations

- The meta-operation memory system's scalability remains uncertain, with ANI growth from 5.6 to 9.7 for severe disturbances suggesting potential degradation with scale.
- Evaluation scope is limited to seven disturbance types on two datasets, leaving untested the system's robustness to novel disturbance patterns or different urban morphologies.
- Computational costs beyond token counts are not reported, making practical deployment viability difficult to assess.

## Confidence

- **High Confidence**: The hybrid classical-LLM architecture's basic feasibility—classical planners consistently generate constraint-satisfying baselines that agents can refine without violating constraints. The success rate maintenance (95-100%) across Large settings provides strong empirical backing.

- **Medium Confidence**: The specialized multi-agent decomposition's advantage over single-agent baselines. While Figure 7 shows clear improvements, the comparison lacks statistical significance testing, and the ablation removes entire components rather than testing intermediate configurations.

- **Low Confidence**: The meta-operation memory's cross-context transferability. The paper demonstrates successful retrieval within disturbance types but doesn't test whether operations learned from "area blocked" disturbances transfer to "budget increase" scenarios, which would be necessary for true generalization.

## Next Checks

1. **Scale Boundary Test**: Run AgentSense on a 100-worker, 64×64 grid configuration with mixed disturbance types. Monitor ANI growth and memory retrieval accuracy to determine the practical scale limit.

2. **Transfer Learning Validation**: Train the system on Beijing data, then test on a third city dataset (e.g., NYC taxi data) without retraining. Measure performance degradation and analyze whether retrieved meta-operations remain relevant across urban contexts.

3. **Token Efficiency Analysis**: Instrument the system to log per-iteration token costs and time. Compare against the cost of re-running classical planners from scratch for severe disturbances to determine the breakeven point where refinement becomes more expensive than replanning.