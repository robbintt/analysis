---
ver: rpa2
title: 'Deep Learning for Short-Term Precipitation Prediction in Four Major Indian
  Cities: A ConvLSTM Approach with Explainable AI'
arxiv_id: '2511.11152'
source_url: https://arxiv.org/abs/2511.11152
tags:
- uni00000048
- uni00000042
- uni00000044
- uni00000055
- uni00000057
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study develops an interpretable ConvLSTM deep learning framework\
  \ for short-term precipitation forecasting in four major Indian cities\u2014Bengaluru,\
  \ Mumbai, Delhi, and Kolkata\u2014using ERA5 reanalysis data. The hybrid Time-Distributed\
  \ CNN-ConvLSTM architecture captures both spatial and temporal precipitation patterns,\
  \ with city-specific hyperparameter tuning."
---

# Deep Learning for Short-Term Precipitation Prediction in Four Major Indian Cities: A ConvLSTM Approach with Explainable AI

## Quick Facts
- **arXiv ID:** 2511.11152
- **Source URL:** https://arxiv.org/abs/2511.11152
- **Reference count:** 14
- **Primary result:** ConvLSTM models achieve RMSE of 0.21 mm/day (Bengaluru), 0.52 mm/day (Mumbai), 0.48 mm/day (Delhi), and 1.80 mm/day (Kolkata) using ERA5 reanalysis data

## Executive Summary
This study develops an interpretable ConvLSTM deep learning framework for short-term precipitation forecasting in four major Indian cities using ERA5 reanalysis data. The hybrid Time-Distributed CNN-ConvLSTM architecture captures both spatial and temporal precipitation patterns through city-specific hyperparameter tuning. Through comprehensive interpretability analysis using permutation importance, Grad-CAM, temporal occlusion, and counterfactual perturbation, the study reveals distinct city-specific precipitation drivers and model behaviors. The models demonstrate varying memory dependencies, from single-day reliance in Bengaluru and Mumbai to multi-day sequences in Kolkata.

## Method Summary
The approach uses ERA5 reanalysis data (1998-2020, JJAS season) with 14 meteorological variables at 0.25° resolution. Input consists of 7-day temporal sequences with 1-3 day lagged features, predicting log-transformed precipitation area-averages for each city. The hybrid Time-Distributed CNN-ConvLSTM architecture processes spatial features through 2D convolutions applied to each time step, then aggregates temporal patterns through convolutional LSTM units. City-specific architectures are optimized using Bayesian optimization, with varying filter counts based on local climate complexity. A weighted loss function emphasizes extreme precipitation events (>90th percentile).

## Key Results
- Models achieve RMSE values of 0.21 mm/day (Bengaluru), 0.52 mm/day (Mumbai), 0.48 mm/day (Delhi), and 1.80 mm/day (Kolkata)
- Permutation importance reveals distinct city-specific drivers: Bengaluru relies on wind variables, Mumbai on convective rainfall and cloud cover
- Temporal occlusion analysis shows Kolkata requires 3-6 day historical context for accurate predictions
- Delhi exhibits substitutable predictors with near-zero permutation importance for most variables
- Extreme-event RMSE remains challenging, particularly for high-variance cities

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If a Time-Distributed CNN extracts spatial features from gridded meteorological data before temporal aggregation, the model effectively identifies local convective triggers and pressure gradients.
- **Mechanism:** The TimeDistributed wrapper applies identical 2D convolutional filters to each time step X_t. This preserves the spatial structure of ERA5 grid cells (0.25° × 0.25°) while transforming raw variables (wind, humidity) into higher-level feature maps (spatial gradients, cloud clusters) before temporal processing.
- **Core assumption:** Critical precipitation precursors manifest as spatial patterns rather than just point-wise anomalies.
- **Evidence anchors:** Abstract confirms hybrid architecture captures spatial-temporal patterns; spatial processing section details convolutional filters; literature confirms NWP struggles with localized convective processes.
- **Break condition:** If spatial resolution (0.25°) is too coarse to resolve sub-grid convective events, CNN filters will learn smoothed, unrepresentative features.

### Mechanism 2
- **Claim:** If ConvLSTM units process sequences of these spatial feature maps, the model maintains memory of evolving atmospheric states required for multi-day predictions.
- **Mechanism:** ConvLSTM replaces fully connected operations with convolutional operations in LSTM gates. This allows forget and input gates to selectively retain or discard spatial feature maps over 7-day sequences, preserving regional pattern memory.
- **Core assumption:** Precipitation dynamics depend on multi-day temporal evolution, not just instantaneous snapshots.
- **Evidence anchors:** ConvLSTM section details convolutional gating mechanisms; occlusion analysis shows Kolkata fails when masking t-3 to t-6 data.
- **Break condition:** If input sequence length (T=7) is shorter than physical lag of dominant meteorological driver, temporal attention will fail to capture causal precursor.

### Mechanism 3
- **Claim:** If city-specific hyperparameter tuning is applied, model capacity aligns with inherent predictability and variance of local climate regime.
- **Mechanism:** Optimization varies convolutional filters and kernel sizes to minimize validation loss. Cities with complex rainfall patterns converge on larger capacities (128 filters) to overfit slightly to chaotic signals, while predictable regimes use smaller capacities (32 filters) to prevent overfitting.
- **Core assumption:** Prediction error is dominated by model capacity relative to data complexity, rather than data quality issues.
- **Evidence anchors:** Section 5.2 shows Bengaluru converged to compact configuration (32 filters) while Kolkata required largest architecture (128 filters); abstract shows performance correlates with architecture size.
- **Break condition:** If optimal architecture merely overfits to noise in training split, model will fail to generalize despite low validation loss.

## Foundational Learning

- **Concept: Convolutional LSTM (ConvLSTM) Gating**
  - **Why needed here:** Core engine processes 3D tensors (Time, Lat, Lon) by treating state-to-state transition as convolution, preserving spatial topology in hidden state.
  - **Quick check question:** If you input 7-day sequence of 10x10 grids into ConvLSTM, what are dimensions of hidden state H_t at any step? (Answer: 3D volume, e.g., 16 × 10 × 10 if using 16 filters, not 1D vector).

- **Concept: Permutation Feature Importance**
  - **Why needed here:** Paper relies on this to claim "distinct city-specific variables." Works by shuffling single input column to destroy information content without changing data distribution.
  - **Quick check question:** If shuffling "convective rain rate" in Mumbai causes RMSE to jump significantly, but shuffling "wind speed" does not, what does that imply about model's decision path?

- **Concept: Log-Transformation of Targets**
  - **Why needed here:** Paper uses log(1 + precipitation) as target to handle extreme skew in rainfall data (many zeros/few high values).
  - **Quick check question:** Why would predicting raw mm/day values directly cause model to ignore extreme events? (Answer: Loss function would be dominated by high frequency of near-zero days).

## Architecture Onboarding

- **Component map:** Input Tensor (7 × H × W × F) -> TimeDist CNN (2D Conv → BatchNorm → ReLU → Dropout) -> ConvLSTM (Recurrent layer) -> Head (Global Average Pooling → Dense → Dense)

- **Critical path:** Data pipeline is bottleneck. ERA5 data must be aggregated from 6-hourly to daily, spatially aligned. Lag feature engineering is manual and explicit; if 1-3 day lags are missing, model fails. Target must be log-transformed (log(1+y)).

- **Design tradeoffs:**
  - Area-averaged Target: Model predicts scalar value for whole city rather than pixel-wise map, reducing noise but losing hyper-local precision
  - Reanalysis vs. Radar: ERA5 used instead of real-time radar, making model suitable for climatic analysis but potentially too slow/smooth for operational nowcasting

- **Failure signatures:**
  - Flat/Negative Permutation Importance: Seen in Delhi (Figure 4c), indicates "substitutable predictors" - model is confused or climate too complex/noisy
  - High Extreme-Event RMSE: Observed in Mumbai/Kolkata, weighted loss function fails to force model to learn tails of distribution

- **First 3 experiments:**
  1. Reproduce Bengaluru Baseline: Train with exactly 32 Conv filters and 16 ConvLSTM filters. Verify if RMSE approaches 0.21 mm/day to validate pipeline.
  2. Ablate the Lag Features: Remove 1-3 day lagged variables. Rerun Temporal Occlusion test (Figure 7). Expect error for "Time 6" to drop (model loses recent context).
  3. Threshold Sensitivity Test: Change extreme event weight parameter α in loss function. Determine if increasing α improves Extreme-event RMSE for Mumbai without destroying Overall RMSE.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does systematic inclusion or exclusion of key meteorological variables affect forecast skill of ConvLSTM models?
- **Basis in paper:** Section 6 states "Additional experiments could directly test importance of key variables by measuring how forecast skill changes when these variables are systematically included or excluded."
- **Why unresolved:** Current study identified variable importance using post-hoc explainability methods on full feature set, but did not perform ablation studies to validate if removing less important features improves efficiency or if removing critical features degrades performance as expected.
- **What evidence would resolve it:** Comparative analysis of model RMSE and Extreme-event RMSE when trained on datasets where specific high-importance or low-importance variables are selectively removed.

### Open Question 2
- **Question:** Can coupling ConvLSTM framework with higher-resolution rainfall products and urban hydrological models enhance operational flood forecasting?
- **Basis in paper:** Section 6 notes "Future work could build on this foundation by coupling similar ConvLSTM models with higher-resolution rainfall products and urban hydrological models."
- **Why unresolved:** Current framework relies on 0.25° resolution ERA5 reanalysis data and predicts area-averaged precipitation, which cannot resolve neighborhood-scale gradients or direct flood depths.
- **What evidence would resolve it:** Results from integrated model pipeline where ConvLSTM outputs feed into hydrological model, validated against observed street-level flood events using higher-resolution radar data.

### Open Question 3
- **Question:** How does multicollinearity among meteorological inputs bias permutation-based feature importance rankings?
- **Basis in paper:** Section 6 acknowledges "Permutation analysis can be affected by correlations between inputs," and observed near-zero importance values in Delhi which they interpreted as "interchangeability."
- **Why unresolved:** While paper offers interpretation for substitutable predictors, it does not quantify extent to which correlated features distort importance scores, potentially hiding actual physical drivers.
- **What evidence would resolve it:** Comparison of feature importance rankings using conditional permutation importance or SHAP versus standard permutation method.

### Open Question 4
- **Question:** Do learned spatial attention patterns (Grad-CAM) remain consistent when model is applied to higher-resolution input data?
- **Basis in paper:** Paper visualizes spatial attention using Grad-CAM on coarse ERA5 grids. Discussion notes model cannot resolve "neighbourhood-scale rainfall gradients."
- **Why unresolved:** Unclear if broad spatial attention regions identified are genuine meteorological drivers or artifacts of coarse 0.25° spatial resolution.
- **What evidence would resolve it:** Grad-CAM visualizations generated from same model architecture trained on high-resolution (satellite or radar) gridded data to see if attention maps converge on finer-scale physical features.

## Limitations

- Reliance on ERA5 reanalysis data limits operational applicability and may smooth extreme events
- City-specific performance disparities reveal fundamental limitations with complex monsoon dynamics (Kolkata RMSE 1.80 mm/day)
- Explainability methods operate on post-hoc interpretations that cannot definitively establish causal relationships
- Area-averaged target prediction loses critical hyper-local information needed for urban flood management
- 7-day input window may be insufficient for capturing long-range atmospheric teleconnections

## Confidence

- **High Confidence:** Technical architecture implementation, data preprocessing pipeline, and basic training methodology are well-specified and reproducible
- **Medium Confidence:** Interpretation of city-specific precipitation drivers through explainability methods is plausible but potentially overfitted to training data
- **Low Confidence:** Claims about causal relationships between specific meteorological variables and precipitation outcomes are speculative given correlation-based nature of interpretability methods

## Next Checks

1. **Temporal Generalization Test:** Train models on even years and test on odd years to assess whether city-specific performance differences reflect genuine climate predictability or overfitting to particular monsoon seasons.

2. **Radar vs. Reanalysis Comparison:** Replicate Bengaluru model using both ERA5 and local radar data to quantify performance degradation from using smoothed reanalysis versus high-resolution observations.

3. **Explainability Robustness Check:** Apply adversarial attacks to input meteorological variables and verify whether permutation importance rankings remain stable or are artificially inflated by data artifacts.