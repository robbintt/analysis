---
ver: rpa2
title: '"Stack It Up!": 3D Stable Structure Generation from 2D Hand-drawn Sketch'
arxiv_id: '2508.02093'
source_url: https://arxiv.org/abs/2508.02093
tags:
- block
- blocks
- graph
- stability
- sketch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: StackItUp enables non-expert users to specify complex 3D block
  structures for robot execution using only 2D hand-drawn sketches. It introduces
  an abstract relation graph as an intermediate representation, capturing symbolic
  geometric relations (e.g., left-of) and stability patterns (e.g., two-pillar-bridge)
  while discarding noisy metric details from sketches.
---

# "Stack It Up!": 3D Stable Structure Generation from 2D Hand-drawn Sketch

## Quick Facts
- arXiv ID: 2508.02093
- Source URL: https://arxiv.org/abs/2508.02093
- Reference count: 40
- Primary result: StackItUp enables non-experts to specify complex 3D block structures for robot execution using only 2D hand-drawn sketches

## Executive Summary
StackItUp addresses the challenge of converting hand-drawn 2D sketches into physically stable 3D block structures for robot execution. The system introduces an abstract relation graph as an intermediate representation, capturing symbolic geometric relations and stability patterns while discarding noisy metric details from sketches. By grounding this graph to 3D poses using compositional diffusion models and iteratively updating it to predict hidden supports, StackItUp achieves high stability and visual resemblance across diverse architectural structures.

## Method Summary
The method extracts an abstract relation graph from sketches using rule-based classifiers for geometric relations and stability patterns. This graph is then grounded to 3D poses via compositional diffusion models, where each relation type has a dedicated model trained on synthetic data. The system iteratively updates the graph by predicting hidden internal and rear supports using pattern-guided heuristics until physical stability is achieved in simulation.

## Key Results
- StackItUp achieves 94.5% physical stability versus 12.1% for end-to-end baseline
- Visual resemblance to input sketches reaches 79.9% versus 16.2% for end-to-end baseline
- System demonstrates strong zero-shot generalization across diverse architectural structures

## Why This Works (Mechanism)

### Mechanism 1: Abstract Relation Graph Decouples Noisy Perception from Structured Reasoning
If the system extracts symbolic relations from rough sketches before attempting metric pose prediction, then it can discard noisy visual details while preserving structural intent. The graph encodes qualitative relations using rule-based classifiers operating on regularized bounding boxes, separating what the structure should achieve from exactly where each block sits.

### Mechanism 2: Compositional Diffusion Enables Zero-Shot Generalization to Unseen Graph Structures
If individual diffusion models are trained per-relation-type and composed at inference via product distributions, then the system can generate poses for arbitrary graph combinations without requiring training data covering all possible graph configurations. Each relation has a dedicated model, and at inference the composite score aggregates gradients from all relations in the graph.

### Mechanism 3: Stability-Pattern-Guided Graph Update Constrains the Search for Hidden Supports
If hidden support prediction is guided by matching partial structures against a dictionary of known stability patterns, then the combinatorial search space is pruned to physically plausible completions. When simulation detects instability, the system decomposes the structure into subgraphs matching stability patterns to provide strong priors for where and what hidden blocks to add.

## Foundational Learning

- **Diffusion Models and Score-Based Sampling**: Why needed? The system uses denoising diffusion probabilistic models for pose generation and requires understanding how score functions relate to noise prediction networks. Quick check: Given a trained denoiser, how would you sample from the learned distribution using reverse diffusion? What changes when composing scores from multiple models?

- **Graph-Based Scene Representation**: Why needed? The abstract relation graph is the core intermediate representation. Understanding how nodes, edges, and relation types encode structural constraints is essential for debugging extraction and grounding failures. Quick check: If a sketch contains 5 visible blocks with 7 geometric relations and 2 stability patterns detected, what information does G encode that a pure bounding-box representation would not?

- **Physical Stability for Stacking Structures**: Why needed? The stability pattern library and simulation-based verification require intuition about center of mass, support polygons, and common stable configurations. Quick check: A single block sits partially on top of another (cantilever). Under what geometric conditions will this remain stable versus topple? How does the "cantilever-with-counterbalance" pattern address this?

## Architecture Onboarding

- **Component map**: Input Processing (Sketch → bounding boxes → type labels) → Graph Extraction (Rule-based classifiers → initial graph G0) → Diffusion Models (34 relation-specific models with Shape/Pose/Temporal encoders) → Compositional Inference (ULA sampling with composite scores) → Stability Verification (Physics simulation) → Graph Update (Pattern-matching heuristic search) → Output (Block types and poses)

- **Critical path**: Sketch → G0 extraction (one-time) → compositional pose generation → simulation check → if unstable: pattern-guided graph update → re-ground → repeat until stable

- **Design tradeoffs**: Symbolic vs. learned relation extraction (interpretability vs. nuance), compositional vs. end-to-end diffusion (zero-shot generalization vs. simplicity), pattern library vs. free-form support prediction (efficiency vs. expressiveness)

- **Failure signatures**: Low resemblance but high stability (graph extraction missed relations), high resemblance but low stability (hidden support prediction failing), both metrics low with end-to-end baseline performing similarly (domain gap in sketch preprocessing), iteration count growing without convergence (pattern library missing required configuration)

- **First 3 experiments**:
  1. Validate graph extraction on held-out sketches: Manually annotate ground-truth relations for 10 test sketches; measure precision/recall of rule-based classifiers
  2. Ablate composition strategy: Compare full compositional inference against single-relation-only generation, averaged multi-relation generation, and sequentially satisfying relations
  3. Stress-test pattern library: Design test structures requiring supports between pattern categories; characterize failure modes and identify missing patterns

## Open Questions the Paper Calls Out

- Can multi-view sketch integration improve 3D structure accuracy, and how can node correspondence across views be efficiently inferred? The abstract relation graph provides a natural abstraction for this extension, where the key challenge is inferring correspondence between nodes across views.

- How can block type labels and candidate object geometries be inferred automatically from sketches without explicit labeling? Integrating 3D perception techniques such as single-view reconstruction or multi-view fusion could relax current assumptions.

- Can the fixed library of 10 stability patterns generalize to unseen structural configurations, or does performance degrade on novel patterns? The system may struggle with structures requiring stability patterns outside the current dictionary.

## Limitations

- Synthetic training data creates potential domain gap with real hand-drawn inputs
- System's ability to generate stable structures is fundamentally limited by the completeness of its stability pattern library
- Computational cost of iterative refinement could become expensive for complex structures requiring many hidden supports

## Confidence

**High Confidence**: Compositional diffusion approach significantly outperforms end-to-end baselines; abstract relation graph successfully decouples topological structure from metric details; hidden support prediction via stability patterns substantially improves stability.

**Medium Confidence**: Zero-shot generalization claim relies on compositional approximation working well; stability pattern library covers common configurations but may have blind spots; rule-based relation extraction provides interpretability but may miss nuanced spatial relationships.

**Low Confidence**: Long-term generalization to diverse sketch styles beyond tested examples; scalability to very large or highly complex structures; performance when user intent conflicts with structural necessity.

## Next Checks

1. Stress Test Stability Pattern Library: Systematically construct test cases requiring stability patterns outside current library; measure failure rates and identify specific pattern categories needing extension.

2. Cross-Domain Sketch Evaluation: Evaluate complete system on larger, more diverse set of hand-drawn sketches from different user populations; compare relation extraction accuracy and stability performance against synthetic sketches.

3. Computational Profiling of Iterative Refinement: Profile full system on representative sample of test sketches; measure average iterations until convergence, total inference time, and memory usage; identify bottlenecks in graph update/re-ground cycle.