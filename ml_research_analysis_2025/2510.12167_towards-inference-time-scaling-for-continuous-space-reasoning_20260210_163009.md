---
ver: rpa2
title: Towards Inference-time Scaling for Continuous Space Reasoning
arxiv_id: '2510.12167'
source_url: https://arxiv.org/abs/2510.12167
tags:
- reasoning
- continuous
- correct
- space
- thought
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates inference-time scaling techniques for continuous
  space reasoning models, specifically examining whether established methods from
  text-based reasoning can be effectively adapted to continuous reasoning models like
  COCONUT. The study demonstrates that dropout-based sampling can generate diverse
  reasoning paths in continuous space, with Pass@N analysis revealing substantial
  potential for performance improvements.
---

# Towards Inference-time Scaling for Continuous Space Reasoning

## Quick Facts
- arXiv ID: 2510.12167
- Source URL: https://arxiv.org/abs/2510.12167
- Reference count: 5
- Key outcome: Demonstrates dropout-based sampling enables diverse reasoning paths in continuous space, but reward models struggle to discriminate due to geometric homogeneity of latent representations.

## Executive Summary
This paper investigates whether inference-time scaling techniques from text-based reasoning can be effectively adapted to continuous space reasoning models like COCONUT. The study demonstrates that dropout-based sampling can generate diverse reasoning paths, with Pass@N analysis revealing substantial potential for performance improvements. However, attempts to train Process and Outcome Reward Models using adapted discrete-space annotation protocols yield only marginal improvements. Through systematic analysis of geometric properties and trajectory dynamics, the authors identify that continuous thoughts lack the geometric separability needed for effective discrimination between correct and incorrect reasoning.

## Method Summary
The paper evaluates dropout-based sampling for generating diverse reasoning paths in continuous space, adapting Process and Outcome Reward Models from discrete reasoning frameworks, and probing geometric properties of continuous thoughts. Experiments use COCONUT, a continuous space reasoning model trained on GSM8K, with dropout sampling applied during the continuous reasoning phase. PRM and ORM models are trained using Monte Carlo annotation adapted from MATH-Shepherd. The study systematically analyzes representation geometry, trajectory dynamics, and perturbation responses to understand limitations in continuous space reasoning.

## Key Results
- Dropout sampling achieves 45.72% accuracy at N=32, surpassing deterministic baseline (31.08%) and approaching text CoT performance
- PRM-HE improves accuracy to 33.36% at N=16, but remains below theoretical upper bound of 42.61%
- t-SNE visualization reveals complete intermixing of correct and incorrect thoughts with F1-scores around 51-54%
- IsoScore of 0.013 indicates low isotropy with reasoning operating in limited dimensional subspaces
- Even with complete noise corruption, non-zero performance (12.59%) suggests thoughts may function as positional placeholders

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dropout-based sampling during continuous reasoning generates diverse reasoning paths, enabling inference-time scaling potential.
- Mechanism: Enable dropout selectively during hidden state generation (continuous reasoning phase) while disabling it during text generation (answer production). This confines stochasticity to reasoning without compromising answer integrity.
- Core assumption: Dropout in latent space creates meaningful path diversity rather than random degradation.
- Evidence anchors:
  - [abstract] "We demonstrate the feasibility of generating diverse reasoning paths through dropout-based sampling. Our Pass@N analysis on the generated samples reveals the potential that could enable a significant gain in performance."
  - [section 3] "Pass@N rapidly surpasses the deterministic COCONUT baseline as sample size increases, ultimately exceeding the text CoT baseline at N=32."
  - [corpus] Weak direct evidence for dropout in continuous space; corpus focuses on discrete token-level scaling methods.
- Break condition: If dropout degrades reasoning coherence rather than adding useful diversity, Pass@N gains will not materialize.

### Mechanism 2
- Claim: Process and Outcome Reward Models trained via Monte Carlo annotation yield only marginal improvements in continuous space due to geometric homogeneity.
- Mechanism: Adapt MATH-Shepherd's MC estimation to annotate continuous thought vectors with hard/soft step-wise rewards, then train classification/regression heads on COCONUT backbone.
- Core assumption: Correct and incorrect reasoning trajectories have distinguishable geometric or semantic signatures that reward models can learn.
- Evidence anchors:
  - [abstract] "working recipes for data generation and training PRM and ORM models in the discrete space unlocks only marginal improvements in the continuous space."
  - [section 4.3] "PRM-HE achieving the most consistent improvements, reaching 33.36% accuracy at N=16 compared to the 31.08% baseline... improvement magnitude is limited, less than 2.3 points despite a theoretical upper bound of 42.61%."
  - [corpus] "Rethinking Reward Models for Multi-Domain Test-Time Scaling" examines PRM effectiveness assumptions but in discrete settings.
- Break condition: If correct and incorrect thoughts occupy indistinguishable regions in latent space, reward models cannot learn discriminative features.

### Mechanism 3
- Claim: Continuous thoughts lack geometric separability between correct and incorrect reasoning, preventing effective discrimination.
- Mechanism: Current training supervision applies only to final text tokens while latent thoughts are generated without explicit structural guidance, causing homogeneous representations that cluster without encoding distinctive semantic properties.
- Core assumption: Meaningful reasoning distinctions should manifest as geometric differences in representation space.
- Evidence anchors:
  - [abstract] "Through probing various aspects including geometric properties and trajectory dynamics we identify the underlying reasons that prevent effective discrimination... current limitations stem from the absence of key inductive biases in continuous thought representations."
  - [section 5.3] "differences between correct and incorrect thoughts are negligible... t-SNE visualization... showing that correct and incorrect thoughts are completely intermixed in the representation space."
  - [section 5.5] "even with complete noise corruption (ratio=1.0), Pass@5 remains non-zero at 12.59%. This suggests COCONUT's reasoning does not exclusively depend on latent thoughts."
  - [corpus] No direct corpus evidence on continuous space geometric properties.
- Break condition: If inductive biases are added during training to enforce geometric differentiation, separability may become achievable.

## Foundational Learning

- Concept: **Continuous vs. Discrete Reasoning Paradigms**
  - Why needed here: COCONUT operates in latent space rather than explicit text tokens; understanding this distinction is essential for grasping why standard PRM/ORM approaches may not transfer directly.
  - Quick check question: Can you explain why dropout during continuous reasoning affects path diversity differently than temperature sampling during token generation?

- Concept: **Isotropy and Anisotropy in Representations**
  - Why needed here: The paper uses IsoScore to quantify how uniformly dimensions are utilized; low isotropy indicates reasoning operates in limited subspaces, with implications for discriminability.
  - Quick check question: If thought vectors have low isotropy (0.013), what does this suggest about their dimensional usage and susceptibility to noise in irrelevant dimensions?

- Concept: **Monte Carlo Estimation for Process Supervision**
  - Why needed here: MATH-Shepherd's annotation protocol generates step-level labels without human annotation; understanding this is critical for reproducing PRM training data construction.
  - Quick check question: Why does hard estimation assign a positive label if *any* completion leads to the correct answer, and how might this affect label quality in continuous space?

## Architecture Onboarding

- Component map: Problem prompt -> <bot> token -> 6 continuous thought vectors (dropout-enabled) -> <eot> token -> text answer -> PRM/ORM scoring -> reranking
- Critical path: Problem prompt → <bot> token → 6 continuous thought vectors (dropout-enabled) → <eot> token → text answer → PRM/ORM scoring → reranking
- Design tradeoffs:
  - **Efficiency vs. interpretability**: Continuous reasoning bypasses token generation for speed, but latent thoughts are opaque
  - **Sampling diversity vs. quality**: Dropout enables path diversity but reduces single-sample accuracy (Pass@1 < deterministic)
  - **Annotation reliability vs. cost**: Higher N for MC estimation improves label quality but increases compute
- Failure signatures:
  - **Geometric homogeneity**: t-SNE shows complete overlap of correct/incorrect thoughts; F1-scores ~51-54%
  - **Poor calibration**: Confidence-based reranking provides no improvement; self-consistency shows minimal gains
  - **High false positive rate**: PRM produces 5,535 false positives vs. 3,943 true positives (30.6% vs 21.8%)
  - **Noise robustness paradox**: Non-zero accuracy at 100% noise corruption suggests thoughts may act as positional placeholders
- First 3 experiments:
  1. **Reproduce dropout sampling baseline**: Train COCONUT on GSM8K with GPT-2, enable dropout at inference, measure Pass@N curve (N=1,2,4,8,16,32) and unique answer counts to confirm logarithmic growth pattern.
  2. **Probe geometric separability**: Extract continuous thought vectors from trained COCONUT, compute IsoScore and Hoyer sparsity on correct vs. incorrect subsets, visualize with t-SNE to confirm intermixing before investing in reward model training.
  3. **Pilot inductive bias intervention**: Add contrastive loss term during COCONUT fine-tuning to encourage separation between correct and incorrect reasoning trajectories, then re-evaluate PRM discrimination performance (precision, recall, F1) on held-out test set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating explicit inductive biases into continuous reasoning training frameworks induce the geometric separability necessary for effective reward model discrimination?
- Basis in paper: [explicit] The authors conclude that "introducing targeted inductive biases during training could potentially address these limitations" caused by homogeneous thought vectors.
- Why unresolved: Current supervision focuses solely on final answer accuracy, failing to promote structural differentiation in the latent space, which causes reward models to fail.
- What evidence would resolve it: Successful training of a PRM/ORM that achieves significant Best-of-N gains by utilizing structurally distinct latent representations.

### Open Question 2
- Question: Do continuous thought vectors function as semantic reasoning carriers or merely as positional placeholders, given the observed robustness to noise?
- Basis in paper: [explicit] Section 5.5 notes that non-zero performance under full noise corruption "raises questions about continuous thoughts' actual contribution."
- Why unresolved: The model generates correct answers even when thought vectors are completely replaced by noise, suggesting the latent states may not always encode necessary semantic information.
- What evidence would resolve it: Ablation studies showing performance collapse when specific latent dimensions are corrupted, or analysis proving semantic content transfer.

### Open Question 3
- Question: Can specific techniques like contrastive learning or isotropy regularization successfully enforce the structural differentiation of correct vs. incorrect reasoning paths?
- Basis in paper: [explicit] The discussion identifies "incorporating contrastive learning to teach discrimination" and "encouraging higher isotropy" as "promising directions."
- Why unresolved: Current representations exhibit low isotropy and negligible geometric differences between correct and incorrect thoughts (Table 4).
- What evidence would resolve it: Demonstration that contrastive loss functions create measurable geometric separability (e.g., distinct clusters in t-SNE) for correct trajectories.

## Limitations

- Continuous reasoning representations lack geometric separability, preventing effective reward model discrimination between correct and incorrect reasoning paths.
- Continuous thoughts may function as positional placeholders rather than semantically rich representations, evidenced by robustness to noise corruption.
- Current training supervision focuses only on final answer accuracy without promoting structural differentiation in latent space.

## Confidence

- **High Confidence**: Dropout sampling generates diverse reasoning paths and enables measurable Pass@N improvements.
- **Medium Confidence**: Current training methods fail to induce geometric separability between correct and incorrect reasoning.
- **Low Confidence**: Reward models trained on current protocols cannot learn meaningful discrimination in continuous space.

## Next Checks

1. **Implement contrastive learning during training**: Add a supervised contrastive loss term to COCONUT's fine-tuning objective that explicitly encourages separation between correct and incorrect reasoning trajectories in latent space. Evaluate whether this improves PRM discrimination metrics (precision, recall, F1) by >10 percentage points compared to baseline.

2. **Test alternative representation spaces**: Replace the continuous thought generation with discretized token-based reasoning (similar to text CoT) while maintaining the same overall architecture. Compare PRM performance between continuous and discrete reasoning modes to determine if the representation format itself is the limiting factor.

3. **Conduct ablation on latent space dimensionality**: Systematically vary the number of continuous thought vectors (T) and their dimensionality (c) to identify whether geometric separability improves with more expressive representations. Measure IsoScore, sparsity, and PRM discrimination performance across different architectural configurations.