---
ver: rpa2
title: 'EAVIT: Efficient and Accurate Human Value Identification from Text data via
  LLMs'
arxiv_id: '2505.12792'
source_url: https://arxiv.org/abs/2505.12792
tags:
- value
- uni00000048
- values
- uni0000004c
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of identifying human values
  in text data using large language models (LLMs), which struggle with long contexts
  and high computational costs. The authors propose EAVIT, a framework that combines
  a small local language model (value detector) with an online LLM.
---

# EAVIT: Efficient and Accurate Human Value Identification from Text data via LLMs

## Quick Facts
- arXiv ID: 2505.12792
- Source URL: https://arxiv.org/abs/2505.12792
- Reference count: 25
- Primary result: Achieves 0.69 F1-score on Touché23-ValueEval while reducing LLM token usage by up to 1/6

## Executive Summary
This paper addresses the challenge of identifying human values in text data using large language models (LLMs), which struggle with long contexts and high computational costs. The authors propose EAVIT, a framework that combines a small local language model (value detector) with an online LLM. The value detector generates initial value estimations, which are used to create concise prompts for the LLM, reducing token usage by up to 1/6. The method employs explanation-based fine-tuning, data generation, and sampling strategies to optimize performance. Experiments on public datasets (Webis-ArgValues-22, Touché23-ValueEval) show that EAVIT achieves state-of-the-art F1-scores (e.g., 0.69 on Touché23-ValueEval) while significantly lowering inference costs. The framework also demonstrates high output consistency and potential for scalable applications in value alignment and psychological analysis.

## Method Summary
EAVIT employs a three-stage pipeline for multi-label value identification from text. First, a local value detector (Llama2-13b-chat fine-tuned with QLoRA) generates probability estimates for 20 Schwartz values by sampling its outputs L=5 times. Second, a threshold-based router identifies candidate values (probabilities between 0.2 and 0.8) and immediately accepts/rejects values outside this range. Third, the online LLM (GPT-4o/mini) receives a condensed prompt containing only definitions of candidate values and performs final classification. The framework includes explanation-based fine-tuning, data augmentation via GPT-4o-mini, and chain-of-thought prompting to optimize accuracy while minimizing computational costs.

## Key Results
- Achieves 0.69 F1-score on Touché23-ValueEval test set
- Reduces LLM token usage by up to 1/6 compared to direct LLM queries
- Shows high output consistency with 88% agreement rate across runs
- Maintains performance while significantly lowering inference costs

## Why This Works (Mechanism)

### Mechanism 1: Cascade Filtering via Uncertainty Thresholding
The framework uses a small local model to sample probabilities for 20 potential values, applying dual thresholds ($p_{low}, p_{high}$). Values scoring above $p_{high}$ are accepted immediately; values below $p_{low}$ are rejected. Only values falling in the "uncertain" middle band are sent to the expensive Online LLM. This reduces the prompt context length from ~2.4k tokens (full value system definition) to ~0.45k tokens.

### Mechanism 2: Explanation-Based Representation Alignment
The authors fine-tune the local detector not just to predict "Value X", but to output "Value X: Explanation [text]". This forces the model to internalize the definition of the value and the reasoning logic rather than relying on spurious surface correlations.

### Mechanism 3: Context Compression for "Lost-in-the-Middle" Mitigation
By identifying a small candidate set (avg size 3.3), EAVIT removes ~16/20 value definitions from the prompt. This places the remaining relevant definitions in a shorter context window where the LLM's attention mechanism can focus more effectively, avoiding the "lost in the middle" phenomenon.

## Foundational Learning

- **Concept: Schwartz Value Theory**
  - Why needed: The entire model output space is defined by this specific hierarchy (e.g., distinguishing "Security: personal" vs "Security: societal"). Without understanding the semantic nuance of the labels, one cannot debug misclassifications.
  - Quick check: Can you explain the difference between "Conformity: rules" and "Tradition" in the context of an argument?

- **Concept: QLoRA (Quantized Low-Rank Adaptation)**
  - Why needed: The paper specifies fine-tuning a 13B parameter model on consumer GPUs (RTX 4090). This is only feasible using 4-bit quantization and LoRA adapters.
  - Quick check: Why might a 4-bit quantized model struggle with subtle semantic distinctions compared to a full-precision model?

- **Concept: Monte Carlo Sampling (for Uncertainty)**
  - Why needed: The mechanism relies on sampling the detector $L=5$ times to calculate probability $\bar{V}_i$. This implies the model must be stochastic (temperature > 0) to generate the variance needed for thresholding.
  - Quick check: What happens to the candidate set size if the sampling temperature is set to 0?

## Architecture Onboarding

- **Component map:** Data Augmentation -> Value Detector -> Sampler -> Router -> Prompt Constructor -> Online LLM
- **Critical path:** The **Router** configuration ($p_{low}, p_{high}$). This is the single point of failure for efficiency vs. accuracy. If thresholds are too loose, API costs spike; if too tight, recall drops.
- **Design tradeoffs:**
  - GPT-4o-mini vs. GPT-4o: Paper notes similar performance; choose mini for cost, GPT-4o for edge-case robustness.
  - Detector Size: A 7B detector might be faster but may fail to generate coherent "explanations," breaking the training logic. 13B was chosen likely for instruction-following capability.
- **Failure signatures:**
  - "Empty Candidate Set" Warning: If the detector is too confident (probabilities near 1.0 or 0.0), no values are sent to the LLM. Check temperature settings.
  - High API Cost: If $p_{low}$ is set too low, the candidate set includes too many values, negating the efficiency gains.
  - Low Recall on Rare Values: If the synthetic data generation failed to capture the nuance of rare values, the detector will consistently threshold them out.
- **First 3 experiments:**
  1. Threshold Sweep: Run validation set with varying ($p_{low}, p_{high}$) to plot the Pareto frontier of Cost (Token count) vs. F1 Score.
  2. Explanation Ablation: Retrain the detector *without* the explanation generation step (just labels) to quantify the performance delta claimed in Section 5.3.
  3. Inter-Annotator Agreement: Compare the "Candidate Set" generated by the detector against human annotations to verify if the detector is successfully filtering "easy" vs "hard" cases.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can EAVIT maintain its performance efficiency and accuracy when applied to value systems other than the Schwartz taxonomy?
- Basis: Page 2 states the method is applicable to "any completely defined value system" (e.g., Moral Foundations Theory), but experiments are restricted to Schwartz-based ValueEval datasets.
- Why unresolved: The paper claims generalizability as a feature of the design but provides no empirical evidence of its effectiveness on alternative taxonomies with different structural complexities.
- What evidence would resolve it: Experiments applying the framework to datasets annotated with alternative theories (e.g., Moral Foundations Theory) showing comparable F1-scores and token reductions.

### Open Question 2
- Question: Does EAVIT's identification of values from text correlate strongly with actual human psychological profiles obtained via traditional questionnaires?
- Basis: Page 6 concludes that the method has potential for measuring values without "active collection methods in psychology," but notes the case study relied on "virtual individuals" simulated by GPT-4 rather than real humans.
- Why unresolved: The validation relies on synthetic personas; it is unconfirmed if passively collected text data from real humans reflects their internal values as accurately as self-reporting.
- What evidence would resolve it: A study comparing EAVIT's output on real users' social media history against their results from standardized psychological value surveys.

### Open Question 3
- Question: How robust is the candidate set generation to the specific probability thresholds ($p_{low}, p_{high}$) when processing out-of-distribution text?
- Basis: Section 4.2 and Table 5 optimize thresholds for the ValueEval dataset, but there is no analysis of how these fixed values perform on noisy, non-argumentative, or domain-shifted text.
- Why unresolved: The fixed thresholds might be overfit to the argument structure of the training data; different text domains might require dynamic thresholding to avoid over-pruning relevant values.
- What evidence would resolve it: Sensitivity analysis showing the change in recall and token efficiency when applying the fixed thresholds to diverse text domains (e.g., fiction, dialogue, code).

## Limitations
- The framework's performance relies heavily on the value detector's ability to accurately separate "easy" from "hard" cases, with no per-class performance breakdown provided.
- Explanation-based fine-tuning's contribution is not directly validated through ablation studies.
- Synthetic data generation quality depends on GPT-4o-mini's ability to generate realistic arguments, which could introduce label errors.

## Confidence

- **High Confidence:** The overall cascade architecture and token reduction claims are well-supported by the experimental results and methodology.
- **Medium Confidence:** The F1-score improvements (0.69 on Touché23-ValueEval) are reported but lack per-class breakdowns or statistical significance tests across multiple runs.
- **Low Confidence:** The assertion that explanation-based fine-tuning is the primary driver of detector performance is not directly validated through ablation studies.

## Next Checks

1. **Threshold Calibration Analysis:** Generate precision-recall curves across multiple threshold configurations to identify optimal settings and verify that the chosen thresholds ($p_{low}=0.2, p_{high}=0.8$) are Pareto-optimal for the specific datasets.
2. **Explanation Ablation Study:** Retrain the value detector using standard classification loss (without explanations) and compare performance to quantify the contribution of explanation-based fine-tuning.
3. **Synthetic Data Quality Audit:** Sample 100 synthetic arguments from the augmentation pipeline and have human annotators verify the correctness of value labels to assess potential label noise contamination.