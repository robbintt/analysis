---
ver: rpa2
title: 'Erasing ''Ugly'' from the Internet: Propagation of the Beauty Myth in Text-Image
  Models'
arxiv_id: '2511.00749'
source_url: https://arxiv.org/abs/2511.00749
tags:
- images
- beauty
- image
- prompts
- gender
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines how generative AI models encode and propagate
  beauty standards through two image generation pipelines: a text-to-image model and
  a text-to-language model-to-image model. The authors develop a structured beauty
  taxonomy to prompt three language models and two text-to-image models, generating
  5,984 images.'
---

# Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models

## Quick Facts
- arXiv ID: 2511.00749
- Source URL: https://arxiv.org/abs/2511.00749
- Reference count: 31
- Primary result: Generative AI models systematically reproduce social biases in beauty standards, with 86.5% of generated images depicting lighter skin tones and 74% rated as younger

## Executive Summary
This paper examines how generative AI models encode and propagate beauty standards through two image generation pipelines. The authors develop a structured beauty taxonomy to prompt three language models and two text-to-image models, generating 5,984 images. A human evaluation study with 60 social media users rated 1,200 images across eight dimensions including age, gender, sexualization, and attractiveness.

The results demonstrate systematic bias in beauty standards, with lighter skin tones appearing in 86.5% of images, 74% rated as younger, and 22% containing explicit content despite SFW training. Non-binary individuals were rated as both younger and more sexualized, revealing troubling intersectional effects. Negative/“ugly” prompts consistently produced higher NSFW ratings regardless of gender, highlighting how generative models reinforce problematic beauty hierarchies.

## Method Summary
The study developed a structured beauty taxonomy to prompt three language models and two text-to-image models, generating 5,984 images. A human evaluation study was conducted with 60 social media users who rated 1,200 images across eight dimensions including age, gender, sexualization, and attractiveness. The evaluation methodology required raters to assess multiple attributes simultaneously, which could introduce cognitive load effects on rating consistency.

## Key Results
- 86.5% of generated images depicted lighter skin tones across all models tested
- 74% of images were rated as younger, showing systematic age bias
- 22% contained explicit content despite SFW training, with negative/“ugly” prompts consistently producing higher NSFW ratings
- Non-binary individuals were rated as both younger and more sexualized, revealing intersectional effects

## Why This Works (Mechanism)
The systematic propagation of beauty biases occurs through the training data composition and model architecture. Large language models trained on internet-scale data absorb existing beauty hierarchies, which are then amplified through generation processes. The text-to-image models learn correlations between textual descriptions and visual representations of beauty standards, creating feedback loops that reinforce narrow definitions of attractiveness.

## Foundational Learning
- **Beauty Taxonomy Construction**: Essential for systematically prompting models with diverse beauty standards; quick check involves validating taxonomy coverage across cultural contexts
- **Human Evaluation Methodology**: Critical for measuring subjective beauty perceptions; quick check requires inter-rater reliability assessment
- **Intersectional Bias Analysis**: Necessary for understanding compounded effects on marginalized groups; quick check involves demographic stratification of results
- **NSFW Detection Frameworks**: Important for assessing safety compliance; quick check requires calibration against established content guidelines
- **Skin Tone Classification**: Key for measuring racial bias; quick check involves testing across multiple skin tone scales

## Architecture Onboarding

**Component Map:** Language Model -> Beauty Taxonomy -> Text-to-Image Model -> Image Generation -> Human Evaluation

**Critical Path:** Taxonomy Development → Prompt Engineering → Image Generation → Multi-dimensional Rating → Bias Analysis

**Design Tradeoffs:** The study prioritized comprehensive beauty standard coverage over model-specific optimization, using standardized prompts across different architectures rather than tailoring to individual model strengths.

**Failure Signatures:** Systematic bias toward lighter skin tones, age-related stereotyping, and NSFW content generation despite safety training indicate fundamental encoding of social biases in training data.

**First Experiments:**
1. Test standardized beauty prompts across three additional contemporary text-to-image models
2. Conduct controlled prompt variations to isolate effects of specific beauty descriptors
3. Implement cross-cultural human evaluation with geographically diverse raters

## Open Questions the Paper Calls Out
None

## Limitations
- Beauty taxonomy development relied on manual curation of existing standards, potentially missing cultural diversity
- Human evaluation study limited to 60 social media users, which may not represent global beauty perceptions
- Evaluation methodology required simultaneous assessment of multiple attributes, potentially introducing cognitive load effects
- Study focused primarily on binary gender and skin tone categories, with limited intersectional analysis

## Confidence

**High Confidence:**
- Systematic bias toward lighter skin tones (86.5%) across multiple models
- Consistent younger appearance ratings (74%) in generated images

**Medium Confidence:**
- Intersectional findings regarding non-binary individuals being rated as both younger and more sexualized
- NSFW content generation despite SFW training (22%) due to prompt construction sensitivity

## Next Checks

1. Conduct larger-scale human evaluation with geographically and demographically diverse participants to validate intersectional findings, particularly regarding non-binary beauty standards
2. Test same prompts across additional contemporary text-to-image models to assess consistency of biases across different architectures
3. Implement controlled experiments varying prompt construction and evaluation methodology to determine sensitivity of NSFW rating findings to different assessment approaches