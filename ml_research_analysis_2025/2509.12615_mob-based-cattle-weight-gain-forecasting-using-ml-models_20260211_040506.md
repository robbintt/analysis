---
ver: rpa2
title: Mob-based cattle weight gain forecasting using ML models
arxiv_id: '2509.12615'
source_url: https://arxiv.org/abs/2509.12615
tags:
- weight
- data
- cattle
- dataset
- weather
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study developed and compared machine learning models to forecast\
  \ one-month-ahead weight gain in mob-based cattle, integrating historical weight,\
  \ age, and weather data from a university farm. A Random Forest model achieved the\
  \ best performance, with an R\xB2 of 0.973, RMSE of 0.040, and MAE of 0.033 when\
  \ both weather and age factors were included."
---

# Mob-based cattle weight gain forecasting using ML models

## Quick Facts
- arXiv ID: 2509.12615
- Source URL: https://arxiv.org/abs/2509.12615
- Reference count: 40
- Random Forest model achieved R² of 0.973, RMSE of 0.040, and MAE of 0.033 for one-month-ahead weight gain forecasting

## Executive Summary
This study developed and compared machine learning models to forecast one-month-ahead weight gain in mob-based cattle, integrating historical weight, age, and weather data from a university farm. A Random Forest model achieved the best performance, with an R² of 0.973, RMSE of 0.040, and MAE of 0.033 when both weather and age factors were included. LSTM and SVR models also performed well, but were less accurate, particularly when key features were excluded. The results demonstrate that incorporating age and weather data significantly improves forecasting accuracy, and that RF is a robust tool for mob-based cattle weight gain prediction in variable conditions. An automated data pre-processing tool was also created to facilitate future research.

## Method Summary
The research team developed machine learning models to forecast one-month-ahead weight gain in mob-based cattle using historical weight, age, and weather data from a university farm. Models tested included Random Forest, LSTM, and SVR, with performance evaluated using R², RMSE, and MAE metrics. The study also incorporated an automated data pre-processing tool to streamline future analyses.

## Key Results
- Random Forest model achieved R² of 0.973, RMSE of 0.040, and MAE of 0.033 with weather and age data
- LSTM and SVR models performed well but were less accurate, especially when key features were excluded
- Incorporating age and weather data significantly improved forecasting accuracy
- Automated data pre-processing tool developed to facilitate future research

## Why This Works (Mechanism)
The success of Random Forest in this context is attributed to its ability to handle non-linear relationships and interactions between cattle age, weather, and historical weight data. The model's ensemble approach allows it to capture complex patterns in weight gain influenced by both biological factors (age) and environmental conditions (weather). By integrating multiple data sources, the model can better account for the variability in cattle growth patterns, leading to more accurate predictions compared to simpler models or those lacking key features.

## Foundational Learning
- Random Forest algorithm: why needed - handles non-linear relationships and interactions between features; quick check - verify ensemble averaging reduces overfitting
- LSTM networks: why needed - capture temporal dependencies in weight gain patterns; quick check - confirm sequence length matches weight history intervals
- SVR (Support Vector Regression): why needed - effective for small to medium-sized datasets with non-linear patterns; quick check - ensure kernel choice matches data complexity
- Feature importance: why needed - identify which variables most influence weight gain predictions; quick check - validate with domain expert knowledge
- Automated data pre-processing: why needed - streamline data preparation for reproducibility and scalability; quick check - test tool on external datasets

## Architecture Onboarding
Component map: Raw data -> Pre-processing -> Feature Engineering -> Model Training -> Validation -> Forecasting
Critical path: Data collection and pre-processing are critical, as model performance heavily depends on data quality and feature selection.
Design tradeoffs: Random Forest vs. LSTM - RF offers better interpretability and faster training, while LSTM may capture longer-term temporal patterns but requires more data and computational resources.
Failure signatures: Poor performance may result from inadequate feature engineering, especially omission of weather or age data, or insufficient training data diversity.
First experiments:
1. Test Random Forest model with and without weather features to quantify their impact
2. Compare model performance using different feature subsets (age, weather, weight history)
3. Validate automated pre-processing tool on external cattle datasets

## Open Questions the Paper Calls Out
- How well do the models generalize to commercial farms or different climatic regions beyond the single university farm studied?
- What is the marginal impact of each input variable (weather, age, weight history) on model accuracy?
- How robust is the automated pre-processing tool when applied to diverse datasets outside the original context?

## Limitations
- Single data source (university farm) may limit generalizability to other regions or management systems
- Model improvements with weather and age features are demonstrated but may not transfer to all commercial or climatic conditions
- LSTM and SVR models showed lower accuracy, raising questions about their practical robustness

## Confidence
- Random Forest performance claims: High - well-supported by the reported metrics and comparisons
- Weather and age feature importance: Medium - supported by the data, but limited to one dataset
- LSTM and SVR model comparisons: Medium - results are clear but less robust, especially with feature exclusion

## Next Checks
1. Test the Random Forest and other models on independent cattle datasets from multiple farms or regions to assess generalizability
2. Conduct a feature ablation study to quantify the marginal impact of each input variable (weather, age, weight history) on model accuracy
3. Validate the automated pre-processing tool with datasets from diverse sources to ensure robustness and ease of use in broader contexts