---
ver: rpa2
title: Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing
arxiv_id: '2509.20336'
source_url: https://arxiv.org/abs/2509.20336
tags:
- reasoning
- graph
- should
- answer
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper applies circuit-tracing methods to investigate how\
  \ decoder-only Transformers solve graph reasoning tasks. It identifies two core\
  \ mechanisms\u2014token merging and structural memorization\u2014that underlie the\
  \ models' reasoning processes across path reasoning, attributed graph reasoning,\
  \ and substructure extraction tasks."
---

# Uncovering Graph Reasoning in Decoder-only Transformers with Circuit Tracing

## Quick Facts
- **arXiv ID:** 2509.20336
- **Source URL:** https://arxiv.org/abs/2509.20336
- **Authors:** Xinnan Dai; Chung-Hsiang Lo; Kai Guo; Shenglai Zeng; Dongsheng Luo; Jiliang Tang
- **Reference count:** 40
- **Primary result:** This paper applies circuit-tracing methods to investigate how decoder-only Transformers solve graph reasoning tasks, identifying token merging and structural memorization as core mechanisms.

## Executive Summary
This study investigates the reasoning mechanisms of decoder-only Transformers on graph reasoning tasks through circuit tracing. The authors identify two core mechanisms: token merging, where the model progressively combines tokens to construct relevant substructures, and structural memorization, where the model relies on learned patterns from training data. Using lightweight GPT-2 models trained on synthetic graph data, they demonstrate how these mechanisms operate across different graph densities and model sizes, with larger hidden dimensions enabling more efficient memorization of neighbor nodes in lower layers.

## Method Summary
The study trains lightweight GPT-2 models (5 layers) with ROPE embeddings on synthetic graph data formatted as textual representations. The models are trained on three graph reasoning tasks: path reasoning, attributed graph reasoning, and substructure extraction. To analyze the reasoning mechanisms, cross-layer Transcoders are trained on each layer of the converged model with L1 regularization. These Transcoders are merged to construct an attribution graph (Circuit Tracer) that visualizes token flows. The analysis quantifies token merging through selection accuracy metrics and structural memorization through precision and recall of predicted neighbor nodes.

## Key Results
- Token merging and structural memorization are identified as two core mechanisms underlying graph reasoning in decoder-only Transformers
- Larger hidden dimensions (192 vs 96) enable more efficient memorization of neighbor nodes in lower layers
- Graph density influences which layers handle token merging, with lower density (0.4) showing merging in earlier layers (1-2) and higher density (0.6) deferring it to layer 3
- The attribution graph successfully traces token flows to reveal how substructures are constructed through progressive token combination

## Why This Works (Mechanism)
The decoder-only Transformers solve graph reasoning tasks through two complementary mechanisms. Token merging operates by progressively combining relevant tokens across layers to construct the desired substructure, with the model learning to identify which tokens are important for the reasoning task. Structural memorization involves the model learning and retrieving patterns from the training data, particularly for predicting neighbor nodes. These mechanisms work in concert, with the model allocating different reasoning steps to different layers based on task complexity and graph density.

## Foundational Learning
- **Synthetic Graph Generation**: Creating controlled graph datasets with specific densities and node counts to enable systematic analysis
  - Why needed: Provides controlled environment for studying reasoning mechanisms
  - Quick check: Verify generated graphs match target density parameters
- **Textual Graph Representation**: Converting graph structures into a format that decoder-only Transformers can process
  - Why needed: Enables Transformers to handle graph reasoning tasks
  - Quick check: Ensure serialization preserves graph connectivity
- **Circuit Tracing Methodology**: Using cross-layer Transcoders to build attribution graphs that reveal token flows
  - Why needed: Provides interpretability framework for understanding model reasoning
  - Quick check: Validate attribution graph captures meaningful token interactions
- **Selection Accuracy Metrics**: Quantifying token merging through SE = N_select/N_pred
  - Why needed: Measures effectiveness of token combination process
  - Quick check: Ensure SE scores correlate with reasoning accuracy
- **Structural Memorization Evaluation**: Using precision/recall to measure neighbor prediction accuracy
  - Why needed: Quantifies the model's ability to retrieve learned patterns
  - Quick check: Compare against baseline memorization approaches

## Architecture Onboarding

**Component Map**: Graph Generator -> GPT-2 Backbone -> Cross-layer Transcoders -> Circuit Tracer -> Attribution Graph

**Critical Path**: The core analysis pipeline flows from generating synthetic graphs, training the GPT-2 backbone, training Transcoders on each layer, merging Transcoders to create the attribution graph, and finally analyzing token flows to identify reasoning mechanisms.

**Design Tradeoffs**: The lightweight 5-layer GPT-2 enables tractable circuit tracing but may not capture patterns in larger models. Synthetic data provides control but limits generalizability. The attribution graph methodology trades implementation complexity for interpretability insights.

**Failure Signatures**: High dead neuron count (>50) in Transcoders indicates poor attribution quality. Low selection accuracy scores suggest token merging is not occurring as expected. Poor precision/recall for neighbor prediction indicates weak structural memorization.

**Three First Experiments**:
1. Generate synthetic graphs with densities 0.2-0.4 and train the 5-layer GPT-2 until convergence (>0.9 accuracy)
2. Train cross-layer Transcoders with L1 coefficient 0.0005 and limit dead neurons to 50
3. Run Circuit Tracer inference and calculate selection accuracy for token merging, verifying early layers (1-2) show high SE scores for lower density graphs

## Open Questions the Paper Calls Out
The authors explicitly acknowledge that their analysis is limited to decoder-only Transformers trained from scratch and recognize a gap between these models and real-world large language models. They note that a more thorough investigation into the effects and limitations of circuit tracing should be included in future work, suggesting uncertainty about the reliability and generalizability of the tracing framework itself.

## Limitations
- Reliance on synthetic graph data may not capture real-world graph complexity and variability
- Attribution graph construction depends on external methodology with unspecified implementation details
- Lightweight 5-layer architecture may not reflect reasoning patterns in larger, more capable models
- Limited exploration of the interaction between token merging and structural memorization mechanisms

## Confidence
- **High Confidence**: The empirical observations of token merging and structural memorization behaviors across the three graph tasks, supported by quantitative metrics
- **Medium Confidence**: The layer-wise progression of mechanisms and influence of graph density on mechanism distribution
- **Low Confidence**: Generalizability to larger models, real-world graph data, and precise interpretation of attribution graphs as true reasoning mechanisms

## Next Checks
1. **Cross-Model Validation**: Reproduce the analysis on larger decoder-only Transformers (e.g., LLaMA-7B) trained on the same synthetic graph tasks to verify whether token merging and structural memorization patterns persist with increased model capacity.

2. **Real-World Dataset Testing**: Apply circuit tracing methodology to decoder-only Transformers trained on real graph datasets (e.g., Cora, Citeseer, or molecular graphs) to assess whether identified mechanisms generalize beyond synthetic structures.

3. **Attribution Method Comparison**: Compare the cross-layer Transcoders attribution approach with alternative interpretability methods (e.g., integrated gradients, attention roll-out) on the same models to validate that identified reasoning mechanisms are consistent across different interpretation frameworks.