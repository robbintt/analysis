---
ver: rpa2
title: 'RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative
  Gaussians Reconstruction and 3D/3D Registration'
arxiv_id: '2508.21154'
source_url: https://arxiv.org/abs/2508.21154
tags:
- registration
- reconstruction
- radgs-reg
- x-rays
- x-ray
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces RadGS-Reg, a unified deep learning framework
  for vertebral-level CT/X-ray registration via joint 3D Radiative Gaussians (RadGS)
  reconstruction and 3D/3D registration. The method addresses the limitations of traditional
  "render-and-compare" approaches by reconstructing vertebral geometry from biplanar
  X-rays using a learning-based RadGS model enhanced with Counterfactual Attention
  Learning (CAL) to focus on vertebral regions in noisy X-rays.
---

# RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration

## Quick Facts
- arXiv ID: 2508.21154
- Source URL: https://arxiv.org/abs/2508.21154
- Reference count: 28
- Primary result: 94.51% SSIM and 28.80 dB PSNR for reconstruction, 1.14 mm mTRE for registration

## Executive Summary
This work introduces RadGS-Reg, a unified deep learning framework for vertebral-level CT/X-ray registration via joint 3D Radiative Gaussians reconstruction and 3D/3D registration. The method addresses the limitations of traditional "render-and-compare" approaches by reconstructing vertebral geometry from biplanar X-rays using a learning-based RadGS model enhanced with Counterfactual Attention Learning (CAL) to focus on vertebral regions in noisy X-rays. A patient-specific three-stage pre-training strategy progressively adapts the model from simulated to real data, incorporating shape priors. Experiments on in-house datasets demonstrate state-of-the-art performance with real-time inference capability suitable for image-guided spine surgery.

## Method Summary
RadGS-Reg employs a three-stage pre-training strategy on the VERSE '20 dataset (253 lumbar spine CTs, 32,000 simulated biplanar DRR pairs), followed by synergistic training. The framework consists of two main modules: RecM reconstructs 3D Radiative Gaussians from biplanar X-rays using a ResNet-50 encoder, CAL mechanism, and Gaussian prediction head; RegM performs 3D/3D registration between the reconstructed volume and preoperative CT using a 3D convolutional encoder and geodesic loss. The model achieves real-time performance (0.82s) on RTX 4090 hardware with 24GB memory.

## Key Results
- Reconstruction: 94.51% SSIM and 28.80 dB PSNR on vertebral geometry from biplanar X-rays
- Registration: 1.14 mm mean Target Registration Error (mTRE) with 93.33% success rate at mTRE<2mm
- Capture range: 20-25 mm initial pose offset tolerance
- Runtime: 0.82 seconds for complete reconstruction and registration pipeline

## Why This Works (Mechanism)

### Mechanism 1: Radiative Gaussian Splatting for Sparse-View Reconstruction
Using 3D Radiative Gaussians (RadGS) allows efficient 3D reconstruction from sparse biplanar X-rays, overcoming dense-view limitations of traditional tomography. The model predicts 3D Gaussians (position, density, covariance) directly from 2D features, rasterized via differentiable splatting to generate X-ray projections for supervision, lifting 2D features into 3D space without dense angular sampling.

### Mechanism 2: Counterfactual Attention Learning (CAL) for Noise Robustness
CAL improves reconstruction quality in noisy X-rays by forcing the network to attend specifically to vertebral regions rather than background noise. It computes the difference between "factual" prediction (using learned attention) and "counterfactual" prediction (using random attention weights), optimizing this difference to isolate causal features from noise.

### Mechanism 3: 3D/3D Registration via Domain Lifting
Lifting registration from 2D/3D (X-ray to CT) to 3D/3D (Reconstructed Gaussians to CT) improves robustness and capture range. The framework first converts X-ray into 3D voxelized volume via RadGS, then performs registration in 3D domain using 3D convolutional encoder and geodesic loss, bypassing difficult 2D projection optimization.

## Foundational Learning

- **3D Gaussian Splatting (3DGS) & Radiative Fields**: Core representation using discrete 3D Gaussians with density accumulation along rays; understand how opacity differs from standard surface splatting.
- **Rigid 3D Registration (6-DOF)**: Final output is rigid transformation (3 translation, 3 rotation); understand SE(3) group properties and geodesic loss for pose estimation.
- **Interventional Causality (Counterfactuals)**: CAL mechanism uses counterfactual attention; understand why replacing attention with random weights quantifies "importance" of learned attention map.

## Architecture Onboarding

- **Component map**: Biplanar X-rays → Image Encoder → Counterfactual Attention (CAL) → Gaussian Prediction Head → RadGS Output → Density Voxelizer → 3D Volume → Concatenate(Volume, CT) → 3D Encoder → Pose Head → 6-DOF Transform
- **Critical path**: X-ray Encoder → Gaussian Prediction is the critical inference path; mislocalized Gaussians due to poor attention cause immediate 3D/3D registration failure
- **Design tradeoffs**: Speed vs. memory using voxelizer after Gaussians (512³ grid) allows standard 3D Convs but consumes memory; patient-specific pre-training improves accuracy significantly but requires setup time
- **Failure signatures**: "Ghosting" or blurring in reconstruction indicates CAL failing to suppress background noise; high mTRE (>5mm) with good visual reconstruction suggests RegM overfitting to simulation artifacts
- **First 3 experiments**: 1) Sanity Check: Train RecM only on VERSE dataset, verify SSIM > 90% on simulated DRRs; 2) Ablation: Run inference with/without CAL, visualize attention maps to confirm vertebral highlighting; 3) Capture Range Test: Synthetically perturb CT pose by known offsets (0mm to 30mm), plot mTRE to verify 20-25mm capture range

## Open Questions the Paper Calls Out

- **Non-rigid deformation modeling**: Future work will incorporate deformation models for complex non-rigid regions involving soft tissues and vasculature, as current implementation is restricted to rigid 6-DOF pose estimation
- **Post-reconstruction Gaussian segmentation**: Need to implement post-reconstruction Gaussian segmentation to streamline current preprocessing procedures that require external tools for X-ray detection and CT segmentation
- **Clinical generalization**: Performance on diverse clinical environments and larger patient cohorts remains uncertain due to small in-house dataset (10 patients, 30 vertebral samples) and specific simulation parameters

## Limitations
- Reliance on proprietary in-house data for stages 2-3 pre-training prevents independent validation of full training pipeline
- CAL mechanism lacks direct comparative evidence from literature for this specific registration task
- Voxelization introduces memory overhead and potential information loss compared to maintaining Gaussian representation
- Capture range of 20-25mm limits applicability to cases requiring larger initial pose corrections

## Confidence
- Reconstruction quality (SSIM 94.51%, PSNR 28.80dB): **High** - Clear methodology on VERSE dataset, aligns with state-of-the-art
- Registration accuracy (mTRE 1.14mm, SR 93.33%): **Medium** - Impressive results but based on small proprietary dataset lacking comparison with traditional methods
- Runtime efficiency (0.82s): **High** - Hardware specifications clearly specified, reproducible claim
- CAL mechanism effectiveness: **Medium-Low** - Novel for this application, ablation studies show improvement but implementation lacks detailed specifications

## Next Checks
1. **Cross-dataset generalization test**: Evaluate model on external spine CT/X-ray dataset without patient-specific fine-tuning to assess real-world applicability
2. **Traditional method comparison**: Implement state-of-the-art 2D/3D registration pipeline using same in-house data to establish baseline performance and validate 3D/3D registration advantage
3. **CAL ablation under noise**: Systematically vary X-ray noise levels and visualize attention maps to verify CAL consistently isolates vertebral features across different noise conditions