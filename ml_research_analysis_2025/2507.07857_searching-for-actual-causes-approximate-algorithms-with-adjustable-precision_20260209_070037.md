---
ver: rpa2
title: 'Searching for actual causes: Approximate algorithms with adjustable precision'
arxiv_id: '2507.07857'
source_url: https://arxiv.org/abs/2507.07857
tags:
- beam
- causes
- algorithm
- size
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of identifying actual causes
  (HP-causes) in complex systems, a problem that is NP-complete and has few practical
  solutions. The authors propose a set of algorithms that can identify actual causes
  with polynomial complexity and adjustable precision.
---

# Searching for actual causes: Approximate algorithms with adjustable precision

## Quick Facts
- arXiv ID: 2507.07857
- Source URL: https://arxiv.org/abs/2507.07857
- Reference count: 40
- Primary result: Algorithms identify HP-causes in polynomial time with adjustable precision via beam size parameter

## Executive Summary
This paper addresses the NP-complete problem of identifying actual causes (HP-causes) in complex systems by proposing a set of approximate algorithms with polynomial complexity. The core innovation is a beam search approach that navigates the intervention space efficiently, guided by heuristic functions. The algorithms can handle non-boolean, black-box, and stochastic systems while providing a clear tradeoff between precision and runtime through the beam size parameter. Results demonstrate that these methods can identify actual causes across various system types with accuracy and efficiency, particularly when causal graph structure is known.

## Method Summary
The authors propose a beam search algorithm that approximates the identification of Halpern-Pearl (HP) actual causes by exploring the space of counterfactual interventions. The algorithm maintains a beam of the top-b scoring interventions at each step, expanding them by adding new variable-value pairs until causes emerge or maximum depth is reached. A key innovation is the minimality pruning technique that discards non-minimal interventions during search, preserving correctness while reducing explored space. For systems with known causal graph structure, an Iterative Sub-instance Identification (ISI) algorithm further improves performance by decomposing the search into focused sub-instances based on direct causal parents. A stochastic extension (LUCB) handles black-box systems using confidence bounds to determine when sufficient samples have been collected for reliable decisions.

## Key Results
- Beam search with appropriate heuristics can identify HP-causes with polynomial complexity, trading exhaustiveness for tractability
- Minimality pruning preserves correctness while dramatically reducing search space, discarding non-minimal supersets during exploration
- ISI algorithm leveraging known DAG structure significantly improves both accuracy and runtime compared to base beam search
- Larger beam sizes consistently improve F1 scores at the cost of linear runtime increases, allowing users to balance precision and computational resources

## Why This Works (Mechanism)

### Mechanism 1: Beam Search for Intervention Space Navigation
Beam search with a heuristic function can approximately identify HP causes in polynomial time, trading exhaustiveness for tractability. The algorithm initializes with single-variable counterfactual interventions, evaluates each using the oracle (does it cancel the consequence?) and heuristic (how promising is it?), retains the top-b scoring candidates in the "beam," and iteratively expands them by adding new variable-value pairs until causes emerge or maximum depth is reached. The heuristic provides meaningful guidance toward interventions that cancel the consequence by ranking "nearly-canceling" interventions higher.

### Mechanism 2: Minimality Pruning via HP Definition (AC3)
Pruning non-minimal interventions during search preserves correctness while dramatically reducing the explored space. When an intervention e with ϕ(e)=0 (consequence cancelled) is found, the algorithm checks if its counterfactual variables eC are a superset of any already-identified cause. If so, e is discarded and not expanded—since any descendant in the search tree would also be non-minimal. This ensures only minimal causes are returned while avoiding redundant exploration of supersets.

### Mechanism 3: ISI (Iterative Sub-instance Identification) for DAG Exploitation
When causal graph structure is known, decomposing search via iterative sub-instances improves both accuracy and runtime. ISI starts by searching only among direct causal parents of the target predicate. When a cause C is identified, it creates new sub-instances by replacing each variable in C with its own causal parents, then recursively searches these smaller, more focused instances. This decomposition dramatically reduces the search space when the provided parent sets are reasonably accurate.

## Foundational Learning

- **Halpern-Pearl (HP) Actual Causes**: The algorithms implement the HP definition (AC1: cause and consequence both observed; AC2: counterfactual test with contingency; AC3: minimality). Understanding this is essential to interpret outputs correctly.
  - Quick check question: In the rock-throwing example, why is Suzzy's throw (ST) the actual cause of the bottle shattering, even though Billy would have broken it if Suzzy missed?

- **Structural Causal Models (SCMs) and Interventions**: The algorithms operate on SCMs and query counterfactual worlds via interventions. You must understand how interventions propagate through the structural equations.
  - Quick check question: Given an SCM where Y = f(X, U), what happens to Y when we intervene to set X ← x′? What role does the exogenous variable U play?

- **Beam Search**: The base algorithm is a modified beam search. Understanding how beam size trades breadth vs. depth is critical for parameter tuning.
  - Quick check question: With beam size b=3 and candidates scored [0.1, 0.2, 0.3, 0.4, 0.5], which nodes survive to the next expansion step if lower scores are better?

## Architecture Onboarding

- **Component map**: Oracle function (ϕ) -> Heuristic function (ψ) -> Base beam search (Algorithm 1) -> ISI wrapper (Algorithm 2) -> LUCB (Algorithm 3)
- **Critical path**:
  1. Define variables V, domains D, actual values v*, target predicate T
  2. Implement oracle ϕ (wrap existing model/simulation)
  3. Design heuristic ψ appropriate for domain semantics
  4. Choose beam size b based on accuracy/runtime budget
  5. Run Algorithm 1 (or Algorithm 2 + graph if available)
  6. For stochastic systems: configure LUCB parameters
- **Design tradeoffs**:
  - Beam size (b): Larger → better precision/recall, linear runtime increase
  - Max steps: Limits cause cardinality, setting to 5–7 can cut runtime significantly
  - Early stop: Use only for smallest-cause task
  - ISI vs base: ISI preferred when graph available; use smaller beam with ISI
  - Heuristic choice: Domain-agnostic heuristics work surprisingly well
- **Failure signatures**:
  - High "Overshoot" rate: Beam size too small or max_steps too large
  - High "Missed" rate: Beam size critically insufficient
  - ISI slower than base: Parent sets overly loose
  - Stochastic F1 degraded: Too few samples or tolerance thresholds misconfigured
- **First 3 experiments**:
  1. **Sanity check on rock-throwing example**: Run base algorithm with b=3 on Example 1
  2. **Beam size sweep**: On SMK scenario with 3 attackers, test b ∈ {5, 15, 25, 50}
  3. **ISI vs base at matched runtime**: Compare ISI with b=15 against base with b=50

## Open Questions the Paper Calls Out

### Open Question 1
How can the algorithms be extended to effectively handle continuous variables by automatically identifying relevant boundaries in their domains? The current restriction to discrete domains is a major lack of flexibility, as sampling continuous domains without specific boundaries is inefficient or inaccurate for identifying actual causes.

### Open Question 2
Can the "Iterative Sub-instance Identification" (ISI) algorithm be optimized to reduce redundancy and time complexity through caching or improved exploration strategies? The current ISI implementation may evaluate similar variable subsets repeatedly across different recursion branches, leading to computational overhead.

### Open Question 3
How can the beam size parameter be set adaptively based on the specific system context to manage the tradeoff between precision and runtime without a priori tuning? Results show high variability from one context to another, making it challenging to set beam size in advance.

### Open Question 4
Can these algorithms be integrated with methods for generating interpretable variables to produce user-friendly explanations that satisfy user expectations? The current work focuses on identifying formal HP-causes, but not all counterfactual causes can generate explanations without filtering for relevance or user expectations.

## Limitations

- Heuristic generalization uncertainty: Effectiveness for arbitrary non-Boolean or black-box systems is less established despite promising empirical results
- Graph requirement for ISI: Performance gains depend on having accurate causal graph information, limiting applicability when structure is unknown
- Stochastic sampling robustness: Sensitivity to tolerance parameters and batch size in LUCB extension not thoroughly explored

## Confidence

- **High confidence**: Core algorithmic correctness (HP definition compliance, beam search implementation, minimality pruning)
- **Medium confidence**: Performance claims across diverse system types, with generalization to arbitrary black-box systems partially demonstrated
- **Medium confidence**: Heuristic effectiveness, with theoretical justification for cross-domain success limited

## Next Checks

1. **Heuristic robustness test**: Apply algorithms to 5-10 benchmark causal reasoning problems beyond SMK and Boolean examples, comparing performance across different heuristic strategies
2. **Graph sensitivity analysis**: Systematically vary accuracy of provided causal graphs for ISI, measuring performance degradation as proportion of incorrect parent relationships increases
3. **Stochastic parameter sweep**: For LUCB, conduct comprehensive sensitivity analysis across parameter space (tc, tnc, tb, batch_size) to identify robust configurations and quantify beam size vs. sample size tradeoff