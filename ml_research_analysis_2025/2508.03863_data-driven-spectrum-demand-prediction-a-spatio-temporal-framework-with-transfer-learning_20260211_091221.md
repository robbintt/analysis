---
ver: rpa2
title: 'Data-Driven Spectrum Demand Prediction: A Spatio-Temporal Framework with Transfer
  Learning'
arxiv_id: '2508.03863'
source_url: https://arxiv.org/abs/2508.03863
tags:
- spectrum
- demand
- learning
- accuracy
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of accurately predicting spectrum
  demand for wireless networks, crucial for effective spectrum allocation and regulatory
  planning. It introduces a data-driven spatio-temporal framework that leverages crowdsourced
  user-side KPIs (e.g., traffic volume, latency, signal strength) and regulatory datasets.
---

# Data-Driven Spectrum Demand Prediction: A Spatio-Temporal Framework with Transfer Learning

## Quick Facts
- **arXiv ID:** 2508.03863
- **Source URL:** https://arxiv.org/abs/2508.03863
- **Reference count:** 24
- **Primary result:** Achieves up to 15% reduction in normalized RMSE for spectrum demand prediction using transfer learning from Toronto to Ottawa data

## Executive Summary
This paper introduces a data-driven framework for predicting spectrum demand that leverages crowdsourced user-side KPIs and regulatory datasets. The method employs advanced feature engineering with lagged KPI versions, correlation analysis, and transfer learning to capture spatial and temporal variations in spectrum utilization. Experimental results demonstrate superior prediction accuracy compared to traditional ITU models, with significant improvements in normalized RMSE and prediction accuracy around 86% in some cases.

## Method Summary
The framework combines crowdsourced user-side KPIs (traffic volume, latency, signal strength, etc.) with regulatory bandwidth data, aggregated into geographic tiles and quarterly windows. Key features include lagged versions of KPIs (+1 and +2 quarters) to capture provisioning inertia. The method employs both white-box (Linear Regression, Lasso) and black-box (XGBoost, LightGBM) models, with transfer learning to improve predictions in data-scarce regions. The core innovation is using "Aggregated Deployed Bandwidth" as a proxy for demand, enabling more accurate regulatory-level predictions than theoretical traffic models.

## Key Results
- Normalized RMSE reduction up to 15% when using transfer learning
- Prediction accuracy levels around 86% achieved in some cases
- Correlation between Traffic Volume and Bandwidth increased from 12.75% to 83.37% when using +1 quarter lag
- Linear Regression models outperformed complex ensembles in specific metrics, demonstrating white-box interpretability advantages

## Why This Works (Mechanism)

### Mechanism 1
Pairing current KPIs with time-lagged versions significantly improves correlation with spectrum demand compared to instantaneous values. Spectrum provisioning exhibits inertia and does not react instantly to network load changes. By introducing lagged features (e.g., $KPI_{t-1}$), the model captures the delay between a user-side trigger (e.g., latency spike) and the regulatory/operator response (bandwidth allocation).

### Mechanism 2
Transfer learning enhances generalizability and reduces prediction error when moving from data-rich source domains to data-scarce target domains. A base model learns universal "demand drivers" in a dense urban environment (Source: Toronto), then adapts to the target region (Target: Ottawa) by freezing lower layers and fine-tuning upper layers without requiring a full historical dataset.

### Mechanism 3
Using "Aggregated Deployed Bandwidth" as a proxy for demand is more effective for regulatory prediction than theoretical traffic models. Instead of predicting theoretical user demand (which is unbounded), the model predicts the allocated capacity (proxy), which is a bounded, regulated outcome. This aligns the prediction target with the regulatory decision-making process.

## Foundational Learning

- **Time-Lagged Feature Engineering**: Why needed? The paper relies on the insight that current network KPIs predict future bandwidth needs. Quick check: If you see a spike in Traffic Volume today, would you expect the Bandwidth to increase this quarter or the next? (Answer: Next, due to provisioning inertia).

- **Normalized RMSE (NRMSE)**: Why needed? The paper claims a "15% reduction in NRMSE." NRMSE allows for comparison across different scales. Quick check: Why is RMSE normalized to the mean or range of the signal in this context? (Answer: To compare prediction performance across regions with vastly different traffic scales).

- **Linear vs. Non-Linear Interpretability**: Why needed? The paper surprisingly finds Linear Regression outperforming XGBoost in some cases. Quick check: Why might a Linear Regression be preferred for regulatory policy even if XGBoost is slightly more accurate? (Answer: Regulatory bodies require explainable "drivers" of demand, which linear coefficients provide directly).

## Architecture Onboarding

- **Component map:** Data Ingestion -> Preprocessor -> Feature Store -> Model Zoo -> Transfer Module
- **Critical path:** Data Cleaning -> **Lag Generation** (Key Step) -> Correlation Analysis -> Model Training -> Transfer Learning Validation
- **Design tradeoffs:**
  - Granularity vs. Stability: The paper uses a rolling 3-month window (Quarterly). Finer granularity (daily) offers more data points but introduces high noise and lowers correlation stability.
  - Complexity vs. Explainability: The paper observes that simple Linear/Lasso models achieved ~86% accuracy, outperforming complex ensembles in specific metrics.
- **Failure signatures:**
  - High RMSE on Target Region: Indicates transfer learning failed (likely due to domain shift between source/target); revert to training from scratch.
  - Over-prediction of Demand: If the model mimics ITU benchmarks, it suggests the "Aggregated Deployed Bandwidth" proxy is not being used correctly, or lag features are missing.
  - Low Correlation (<20%): Suggests the selected KPIs (e.g., Jitter) are not leading indicators for the specific region being modeled.
- **First 3 experiments:**
  1. Baseline Correlation Check: Calculate the Pearson correlation between Traffic Volume and Bandwidth with 0, 1, and 2-quarter lags. Confirm the paper's finding that lagged correlation is higher.
  2. Ablation on Model Complexity: Train both a Linear Regressor and an XGBoost model on the lagged features. Verify if the linear model actually performs competitively (as the paper suggests).
  3. Transfer Learning Simulation: Train on 80% of the data (Source), freeze weights, and fine-tune on the remaining 20% (Target). Compare error rates against a model trained solely on the 20% target data to validate the 15% efficiency gain.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed transfer learning framework maintain high prediction accuracy when extended to multi-country datasets with diverse regulatory environments and network standards? The current study validates only within Canada, leaving international generalizability untested.

### Open Question 2
Do attention-based transformers or meta-learning architectures provide superior performance and self-adaptation capabilities compared to the current LSTM and tree-based models? The paper proposes investigating these advanced architectures as future work.

### Open Question 3
To what extent does the inclusion of application-level traffic data (e.g., video vs. IoT traffic) improve the granularity and accuracy of spectrum demand estimates? The current feature set is limited to network-layer metrics and does not distinguish between specific use cases.

### Open Question 4
How can the framework be modified to explicitly identify and mitigate potential sampling bias inherent in crowdsourced user-side data? The paper acknowledges this limitation but does not implement mitigation strategies.

## Limitations
- Reliance on crowdsourced KPI data introduces potential sampling bias, over-representing certain user demographics
- 3-month rolling window aggregation may smooth out short-term demand fluctuations relevant for certain regulatory decisions
- Transfer learning effectiveness is highly dependent on domain similarity between source and target regions, which is not quantified

## Confidence
- **High Confidence:** The correlation improvement with lagged features (12.75% to 83.37%) is well-supported by experimental data
- **Medium Confidence:** The 15% NRMSE reduction claim depends on specific regional characteristics that may not generalize
- **Medium Confidence:** The superiority of linear models over complex ensembles in some cases is surprising but methodologically sound

## Next Checks
1. **Domain Shift Quantification:** Measure and report the statistical distance between source and target regions to better understand transfer learning conditions
2. **Bias Analysis:** Evaluate whether crowdsourced data adequately represents rural versus urban spectrum usage patterns across different socioeconomic groups
3. **Temporal Granularity Study:** Test model performance with 1-month versus 3-month aggregation windows to identify optimal trade-off between noise reduction and responsiveness