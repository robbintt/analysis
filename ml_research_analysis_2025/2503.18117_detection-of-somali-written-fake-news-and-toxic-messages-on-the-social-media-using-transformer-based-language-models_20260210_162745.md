---
ver: rpa2
title: Detection of Somali-written Fake News and Toxic Messages on the Social Media
  Using Transformer-based Language Models
arxiv_id: '2503.18117'
source_url: https://arxiv.org/abs/2503.18117
tags:
- somali
- news
- language
- fake
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the scarcity of AI resources for Somali, a
  low-resource language, by creating human-annotated datasets for fake news and toxicity
  detection and developing a monolingual Somali language model, SomBERTa. The approach
  involved compiling a large, diverse Somali corpus from multiple sources, annotating
  social media data, and fine-tuning a BERT-based model for downstream classification
  tasks.
---

# Detection of Somali-written Fake News and Toxic Messages on the Social Media Using Transformer-based Language Models

## Quick Facts
- arXiv ID: 2503.18117
- Source URL: https://arxiv.org/abs/2503.18117
- Authors: Muhidin A. Mohamed; Shuab D. Ahmed; Yahye A. Isse; Hanad M. Mohamed; Fuad M. Hassan; Houssein A. Assowe
- Reference count: 12
- Primary result: Developed SomBERTa, a Somali language model achieving 87.99% average accuracy on fake news and toxicity detection tasks

## Executive Summary
This study addresses the scarcity of AI resources for Somali, a low-resource language, by creating human-annotated datasets for fake news and toxicity detection and developing a monolingual Somali language model, SomBERTa. The approach involved compiling a large, diverse Somali corpus from multiple sources, annotating social media data, and fine-tuning a BERT-based model for downstream classification tasks. Experimental results show that SomBERTa outperforms several multilingual models on both fake news and toxicity detection tasks, achieving an average accuracy of 87.99% across all evaluated tasks. This research provides a foundational resource for Somali NLP and a replicable framework for other low-resource languages.

## Method Summary
The researchers compiled a large Somali corpus from multiple sources including Somali Wikipedia, news websites, social media platforms, and government documents. They then annotated 6,278 instances for fake news detection and 6,294 instances for toxicity detection. A monolingual Somali language model, SomBERTa, was developed by adapting the BERT architecture specifically for Somali linguistic patterns. The model was fine-tuned on the annotated datasets for binary classification tasks. Performance was evaluated against established multilingual models including mBERT, XLM-R, and AfriBERTa, demonstrating superior results for both fake news and toxicity detection tasks.

## Key Results
- SomBERTa achieved 87.99% average accuracy across fake news and toxicity detection tasks
- Outperformed multilingual models (mBERT, XLM-R, AfriBERTa) on Somali-specific tasks
- Demonstrated effectiveness of monolingual models for low-resource languages

## Why This Works (Mechanism)
SomBERTa works by leveraging monolingual training on a diverse Somali corpus, allowing the model to capture language-specific patterns, idiomatic expressions, and cultural context that multilingual models may miss. The fine-tuning process adapts the pre-trained weights to the specific downstream tasks of fake news and toxicity detection, enabling the model to recognize subtle linguistic cues and contextual patterns indicative of misinformation and harmful content. The human-annotated datasets provide high-quality supervision that aligns with Somali speakers' understanding of these concepts.

## Foundational Learning
1. **Low-resource language modeling** - Understanding challenges in training NLP models with limited data; why needed to address resource scarcity for Somali; quick check: compare training data size to major languages
2. **Transfer learning in NLP** - Pre-training on general corpus then fine-tuning for specific tasks; why needed to leverage limited annotated data; quick check: evaluate performance gains from pre-training
3. **Multilingual vs. monolingual models** - Trade-offs between general multilingual coverage and language-specific performance; why needed to justify monolingual approach; quick check: benchmark against multilingual baselines
4. **Social media text processing** - Handling informal language, code-switching, and platform-specific patterns; why needed for realistic deployment; quick check: analyze token coverage of social media vocabulary
5. **Dataset annotation for toxicity detection** - Challenges in defining and labeling toxic content across cultures; why needed for quality supervision; quick check: inter-annotator agreement scores
6. **Evaluation metrics for classification** - Understanding accuracy, precision, recall, and F1-score in imbalanced datasets; why needed for proper model assessment; quick check: confusion matrix analysis

## Architecture Onboarding
**Component map**: Data collection -> Annotation -> Pre-training (SomBERTa) -> Fine-tuning -> Evaluation -> Comparison with baselines
**Critical path**: Diverse corpus compilation → Human annotation → Monolingual pre-training → Task-specific fine-tuning → Performance evaluation
**Design tradeoffs**: Monolingual vs. multilingual modeling (better language-specific performance vs. broader applicability), binary vs. multi-class classification (simplicity vs. nuance capture)
**Failure signatures**: Poor performance on code-switched content, inability to generalize beyond training platforms, sensitivity to informal language variations
**First experiments**: 1) Benchmark on held-out test set, 2) Cross-platform validation test, 3) Error analysis on false positives/negatives

## Open Questions the Paper Calls Out
None

## Limitations
- Small annotated datasets (6,278 fake news instances, 6,294 toxicity instances) limiting generalizability
- Data collection restricted to Somali social media platforms introducing platform-specific biases
- Binary classification approach may oversimplify complex nature of fake news and toxic content
- No external validation or cross-domain testing mentioned

## Confidence
- Model performance claims: High
- Methodology description: High
- Generalization claims: Medium
- Comparative analysis with baselines: High

## Next Checks
1. Test the model's performance on an external, independently annotated dataset to assess generalization beyond the training corpus
2. Evaluate the model's robustness to adversarial examples and cross-platform social media data to identify potential biases in the current approach
3. Conduct a comprehensive error analysis to identify specific types of false positives and false negatives, particularly for edge cases in fake news and toxicity detection