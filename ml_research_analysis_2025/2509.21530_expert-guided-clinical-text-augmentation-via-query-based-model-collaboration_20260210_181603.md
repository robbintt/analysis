---
ver: rpa2
title: Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration
arxiv_id: '2509.21530'
source_url: https://arxiv.org/abs/2509.21530
tags:
- augmentation
- data
- clinical
- expert
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating safe and accurate
  synthetic clinical text for data augmentation in healthcare. While large language
  models (LLMs) can generate synthetic data, they often introduce factual errors or
  remove critical medical information, posing risks in high-stakes domains.
---

# Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration

## Quick Facts
- arXiv ID: 2509.21530
- Source URL: https://arxiv.org/abs/2509.21530
- Reference count: 23
- Primary result: Query-based model collaboration improves clinical text augmentation safety and accuracy, achieving higher downstream task performance with lower hallucination rates than baselines.

## Executive Summary
This paper addresses the challenge of generating safe and accurate synthetic clinical text for data augmentation in healthcare. While large language models (LLMs) can generate synthetic data, they often introduce factual errors or remove critical medical information, posing risks in high-stakes domains. To solve this, the authors propose a query-based model collaboration framework where a lightweight domain-specific model (weak expert) identifies and preserves critical medical entities, while a generalist LLM (strong generalist) rewrites the text without altering these entities. This ensures semantic fidelity and safety during augmentation. Experiments on clinical prediction tasks (e.g., readmission, mortality) show that the proposed method outperforms baselines like naive paraphrasing and style-only rewriting, achieving higher accuracy (e.g., 0.599 vs. 0.552) and lower hallucination rates. The framework also improves zero-shot/few-shot inference on patient phenotyping and ICD coding tasks. The authors further demonstrate that the collaboration can be distilled into a single model via preference learning, though the dual-model approach remains more reliable.

## Method Summary
The proposed method uses a query-based model collaboration framework for safe clinical text augmentation. A lightweight domain-specific model (weak expert) extracts critical medical entities from clinical notes, while a generalist LLM (strong generalist) rewrites the text while preserving these entities. The weak expert is a DistilBERT-based biomedical NER model (biomedical-ner-all, 107 entity types) that identifies medical keywords. The strong generalist is an instruction-tuned LLM (Qwen-3-0.6B default) that generates rewritten notes conditioned on prompts containing the original text and explicit instructions to preserve identified entities. The framework is evaluated on MIMIC-III clinical notes for downstream tasks including 30-day readmission prediction, in-hospital mortality prediction, and length-of-stay prediction. The approach is also compared against baselines like naive paraphrasing and style-only rewriting, and the collaboration policy is distilled into a single model via preference learning.

## Key Results
- The proposed method achieves higher preservation rates (0.66-0.79) and lower hallucination rates (0.33-0.43) compared to baselines (preservation 0.48-0.51, hallucination 0.59-0.75)
- Downstream task accuracy improves significantly: 0.599 vs 0.552 for readmission prediction compared to strongest baseline
- The collaboration policy can be distilled into a single model via DPO, though dual-model collaboration remains more reliable across backbones
- The framework improves zero-shot/few-shot inference on patient phenotyping and ICD coding tasks

## Why This Works (Mechanism)

### Mechanism 1: Explicit Token-Level Constraints Ground LLM Generation
The framework injects domain-identified entities into the generation prompt, reducing hallucination and omission of critical medical information. A lightweight clinical NER model extracts entity set K_i from input x_i, which are listed verbatim in the prompt to the generalist LLM with explicit instructions to preserve them. This constrained generation conditions G on K_i, reducing the search space and anchoring output to validated medical content. The weak expert's entity extraction must have sufficiently high recall on safety-critical terms to prevent semantic drift.

### Mechanism 2: Decoupling Domain Sensitivity from Generative Fluency
Separating entity identification (weak expert) from text rewriting (strong generalist) yields higher fidelity than requiring a single model to perform both roles without domain specialization. The weak expert provides a structured constraint set while the generalist applies its linguistic fluency only on non-constrained spans. This prevents the generalist from confusing stylistic variation with semantic alteration. Medical terminology forms a bounded, identifiable subset distinguishable from stylistic tokens.

### Mechanism 3: Preference-Based Distillation Provides a Compressed but Less Reliable Alternative
The dual-model collaboration policy can be distilled into a single model via DPO, though with inconsistent gains across backbones. Preference pairs are formed contrasting expert-guided vs naive augmentations, and DPO optimizes the generalist to prefer constraint-respecting outputs. The resulting "Strong Expert" internalizes the constraint signal. However, gains are inconsistent across backbones, and the dual-model pipeline remains more reliable when base models lack medical priors.

## Foundational Learning

- **Named Entity Recognition (NER) for clinical text**: The weak expert relies on accurate extraction of medical entities (diagnoses, symptoms, medications, dosages) to form constraint sets. Quick check: Given a clinical note, can you identify which tokens correspond to medical entities vs stylistic elements?

- **LLM hallucination in domain-specific generation**: The paper's core motivation is that general-purpose LLMs introduce factual errors or omit critical information when augmenting clinical text without supervision. Quick check: Can you distinguish between a valid paraphrase and a hallucinated medical claim in a rewritten clinical note?

- **Direct Preference Optimization (DPO)**: The distillation pathway uses DPO to internalize expert constraints into a single model. Quick check: How does DPO differ from reinforcement learning with a learned reward model for aligning model outputs?

## Architecture Onboarding

- **Component map**: Clinical note x_i → Weak Expert W (biomedical NER) → Entity set K_i → Prompt construction → Strong Generalist G (LLM) → Augmented note x̃_i

- **Critical path**: (1) Input clinical note x_i enters W for entity extraction → K_i (2) Prompt assembled: original note + "Preserve the following tokens: {K_i}" + rewrite instructions (3) G generates x̃_i conditioned on prompt (4) Output validated via Preservation Rate (PR) and Hallucination Rate (HR) before downstream use

- **Design tradeoffs**: Medical-expert vs general-expert W: Medical-specialized NER yields higher PR/lower HR but requires domain training data. Smaller vs larger G: Larger generalists improve PR/HR but increase inference cost. Dual-model vs DPO-distilled single model: Dual-model is more reliable; DPO offers deployment simplicity at cost of inconsistent gains.

- **Failure signatures**: Under-detection by W: Rare or novel medical terms not captured in NER training data pass unconstrained → potential semantic drift. Over-detection by W: Excessive constraints limit augmentation diversity, reducing robustness benefits. Long-context coherence loss: Without CAG, long notes may lose entity coherence across sections.

- **First 3 experiments**: 1) Baseline validation: Run Naive, CATO, and proposed method on 100 MIMIC-III notes. Compute PR and HR. Confirm proposed method achieves PR ≥ 0.75, HR ≤ 0.35. 2) Weak expert ablation: Swap medical-expert NER for general NER. Measure PR/HR degradation. Expect ~0.20 PR drop and ~0.15 HR increase. 3) Downstream task sanity check: Train a BERT classifier on augmented data for readmission prediction. Compare accuracy vs no augmentation vs Naive vs CATO. Expect +0.02–0.05 accuracy gain over strongest baseline.

## Open Questions the Paper Calls Out

### Open Question 1
Can the query-based collaboration mechanism be effectively adapted to operate at the intermediate layer level or during reasoning steps, rather than solely at the input level? The authors state in Appendix A.4 that their current input-level collaboration "may not be optimal in terms of providing supervision" and suggest intermediate-level collaboration as a specific future direction. This remains unresolved because the current implementation only queries the expert model to extract keywords before generation starts, without investigating how expert signals could guide internal states or chain-of-thought during generation.

### Open Question 2
Can preference learning (e.g., DPO) reliably distill the dual-model collaboration policy into a single "Strong Expert" model that performs consistently across diverse backbone architectures? Section 5 notes that since gains are "inconsistent across backbones," creating a "fully model-agnostic Strong Expert" remains an open question. The authors observed that DPO distillation worked significantly better for Qwen-3 (which has medical priors) than for Llama-3.2-3B, suggesting success depends heavily on the base model's pre-existing domain knowledge.

### Open Question 3
Does the proposed framework generalize effectively to other high-stakes expert domains, such as law or finance, while maintaining safety and semantic fidelity? Appendix A.4 identifies expanding the method to other expert domains as a "next step of our research." The framework is designed to be domain-agnostic, but all empirical validation is restricted to clinical notes (MIMIC-III), leaving generalization to other domains untested.

## Limitations

- The framework's effectiveness depends critically on the recall of the weak expert's entity extraction, with any missed safety-critical entities creating potential for semantic drift
- The DPO distillation pathway shows inconsistent performance across model backbones, suggesting the preference learning approach may not generalize reliably without careful tuning
- Long-context handling through CAG is minimally specified, with no implementation details or quantitative evaluation of its effectiveness

## Confidence

- **High Confidence**: The core mechanism of query-based model collaboration (Mechanism 1 and 2) is well-supported by quantitative results across multiple clinical prediction tasks and ablation studies. The preservation and hallucination rate improvements are consistently demonstrated.
- **Medium Confidence**: The distillation pathway via DPO (Mechanism 3) shows promise but with inconsistent gains. The evidence supports its viability as an alternative, but the recommendation for dual-model collaboration when base models lack medical priors indicates incomplete generalization.
- **Low Confidence**: Long-context handling through CAG is minimally specified. The paper mentions it addresses context overflow but provides no implementation details or quantitative evaluation of its effectiveness.

## Next Checks

1. **Edge Case Analysis**: Systematically evaluate augmentation quality on clinical notes containing rare medical terminology, novel drug names, or emerging clinical concepts not present in the biomedical-ner-all training data. Measure how entity preservation degrades as clinical vocabulary novelty increases.

2. **DPO Hyperparameter Sensitivity**: Conduct a grid search over DPO learning rates, batch sizes, and preference sampling strategies across multiple LLM backbones. Quantify the variance in downstream task performance to identify conditions under which distillation succeeds versus fails.

3. **Clinical Expert Review**: Have board-certified physicians review 100 augmented clinical notes from the proposed method versus baselines, blinded to source. Assess for semantic fidelity, clinical accuracy, and potential patient safety concerns. Calculate inter-rater reliability and compare to automated preservation/hallucination metrics.