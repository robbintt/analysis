---
ver: rpa2
title: Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?
arxiv_id: '2502.06555'
source_url: https://arxiv.org/abs/2502.06555
tags:
- data
- private
- synthetic
- public
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates whether API access to large language models
  (LLMs) can improve differentially private (DP) synthetic tabular data generation.
  The authors propose two approaches: adapting Private Evolution (a genetic algorithm
  using LLM API calls) to tabular data with a workload-aware distance function, and
  using one-shot LLM-generated records as public data in existing DP tabular synthesis
  algorithms.'
---

# Is API Access to LLMs Useful for Generating Private Synthetic Tabular Data?

## Quick Facts
- arXiv ID: 2502.06555
- Source URL: https://arxiv.org/abs/2502.06555
- Reference count: 6
- Primary result: LLM API access does not improve differentially private synthetic tabular data generation over state-of-the-art baselines

## Executive Summary
This paper investigates whether API access to large language models can improve differentially private (DP) synthetic tabular data generation. The authors propose two approaches: adapting Private Evolution (a genetic algorithm using LLM API calls) to tabular data with a workload-aware distance function, and using one-shot LLM-generated records as public data in existing DP tabular synthesis algorithms. Experimental results on the UCI Adult dataset show that Private Evolution with DP histograms fails to outperform simple baselines like independent marginal sampling. Among the one-shot approaches, JAM with Gemini-generated data performs best but achieves similar results to JAM with uniform random data, indicating the Gemini-generated data does not provide meaningful improvement. The authors conclude that while API access to LLMs shows promise, it does not currently improve upon state-of-the-art DP tabular synthesis methods, though they suggest potential improvements as foundation models advance.

## Method Summary
The paper proposes two approaches for using LLM APIs to generate DP synthetic tabular data. First, Private Evolution (PE) is adapted for tabular data using a workload-aware distance function that measures predicate-level similarity between private and synthetic records. Second, LLM-generated records (via Gemini 1.0 Pro's structured output) serve as surrogate public data for algorithms like PMWpub and JAM. The workload-aware distance function aligns PE with final workload error by measuring distances using predicates corresponding to workload queries. The one-shot approach generates synthetic public data offline using Gemini, then feeds this data to existing DP synthesis algorithms. Experiments on UCI Adult dataset compare these approaches against baselines including independent marginal sampling, MST, and direct DP workload queries.

## Key Results
- Private Evolution with DP histograms fails to outperform independent marginal sampling baseline
- JAM with Gemini-generated data performs best among one-shot approaches but achieves similar results to JAM with uniform random data
- Workload error without privacy converges, but composition costs destroy utility with DP
- Gemini captures 1-way marginals well but fails on 2-way marginals, causing JAM to fall back to private measurements

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The workload-aware distance function enables Private Evolution to select candidate records that minimize final query error by measuring predicate-level similarity between private and synthetic records.
- **Mechanism:** Linear workload queries decompose into sums over predicates on individual records (qi(x) = Σj ψi(xj)). The distance function Wdistψ(x, c) = Σi |ψi(x) − ψi(c)| translates workload error (dataset-level) into a record-level metric, allowing each private record to "vote" for the most similar synthetic candidate in the DP histogram.
- **Core assumption:** The predicates underlying workload queries capture the relevant structure of tabular data such that minimizing predicate-level distance correlates with minimizing workload error.
- **Evidence anchors:**
  - [abstract]: "The workload-aware distance function aligns the genetic algorithm with the final workload error by measuring distances between individual records using the predicates corresponding to the workload queries."
  - [section 3.1]: Full mathematical derivation showing workload error unpacks to predicates, enabling the Wdist definition.
  - [corpus]: Weak direct support; "Private Evolution Converges" provides theoretical PE analysis but workload-aware distance for tabular data appears novel.
- **Break condition:** When predicates fail to capture multi-way dependencies (e.g., 2-way marginals), causing poor correlation between distance minimization and actual workload error.

### Mechanism 2
- **Claim:** LLM-generated records can serve as surrogate public data for existing DP synthesis algorithms that expect public data, without consuming privacy budget.
- **Mechanism:** Gemini's structured output generates records matching column names and datatypes (offline, no private data in prompts). This "Gem Synth" dataset feeds algorithms like PMWpub (warm-starts distribution estimation) and JAM (chooses per-marginal whether to use public or private data).
- **Core assumption:** LLMs trained on broad corpora encode useful priors about realistic tabular distributions that can bootstrap DP algorithms.
- **Evidence anchors:**
  - [abstract]: "using one-shot LLM-generated records as public data in existing DP tabular synthesis algorithms."
  - [section 4.1]: "We prompt Gemini to generate data records with a response schema matching the column names and datatypes... This data generation occurs 'offline' and in one shot with no loss of privacy budget."
  - [corpus]: "Do You Really Need Public Data?" explores surrogate public data for DP but not LLM-generated; this application appears novel.
- **Break condition:** When generated data matches 1-way marginals but diverges on k-way marginals, causing algorithms like JAM to ignore the public data and fall back to private measurements.

### Mechanism 3
- **Claim:** Private Evolution's iterative genetic algorithm can theoretically converge to match private data distributions, but DP composition costs dominate any gains from iteration in the tabular setting.
- **Mechanism:** Each PE round: (1) LLM generates candidates, (2) private records vote via distance function, (3) DP histogram selects elites, (4) LLM generates variations. Budget splits across rounds via composition.
- **Core assumption:** Iterative refinement improves candidate quality enough to justify privacy cost of composition.
- **Evidence anchors:**
  - [section 3]: Full algorithm description with Random API initialization and Variation API for subsequent rounds.
  - [section 3.2]: "Using only a single iteration was the optimal setting we could find" with DP; without privacy, convergence is observed.
  - [corpus]: "Private Evolution Converges" analyzes PE convergence properties theoretically.
- **Break condition:** When ε budget is limited, composition across iterations reduces per-iteration noise tolerance so severely that single-shot generation outperforms iteration.

## Foundational Learning

- **Concept: Differential Privacy Composition**
  - **Why needed here:** Understanding why single-iteration PE outperformed multi-iteration requires grasping how privacy budget accumulates. Each histogram in PE consumes budget; more iterations = more noise per iteration.
  - **Quick check question:** If you run T iterations each with ε/T budget, how does the noise scale compared to a single ε-budget query?

- **Concept: Marginal Queries and k-way Dependencies**
  - **Why needed here:** All baselines (MST, JAM, independent sampling) operate on marginals. The finding that Gemini captures 1-way but not 2-way marginals explains why JAM ignores the generated data.
  - **Quick check question:** Why would an LLM trained on natural language text plausibly capture 1-way marginals (e.g., "most adults are 25-65 years old") but fail on 2-way marginals (e.g., correlation between education and occupation)?

- **Concept: Public Data Roles in DP Mechanisms**
  - **Why needed here:** PMWpub uses public data for warm-starting a distribution; JAM uses it selectively per-query. This difference explains why the same Gem Synth data might help one algorithm but not another.
  - **Quick check question:** If public data is unrepresentative on some marginals but accurate on others, which algorithm (PMWpub vs. JAM) would you expect to handle this better and why?

## Architecture Onboarding

- **Component map:**
  Private Dataset -> PE Loop (if used) -> Synthetic Output
                    -> Random API (initial candidates)
                    -> Variation API (elite variations)
                    -> Workload-Aware Distance Function
                    -> DP Histogram (noise injection)
  -> One-Shot Path:
                    -> Gemini API (offline) -> Gem Synth
                    -> PMWpub / JAM / MST-modified -> Synthetic Output
  -> Baselines: Independent, DP Workload, MST

- **Critical path:**
  1. Define workload (k-way marginals) and extract predicates
  2. Generate Gem Synth offline via Gemini structured output
  3. Run target algorithm (JAM recommended per results) with private + Gem Synth
  4. Compare workload error against: independent sampling, MST, uniform-data baselines

- **Design tradeoffs:**
  - **PE vs. One-Shot:** PE allows iterative refinement but composition destroys utility at low ε; one-shot preserves full budget for downstream algorithm
  - **Algorithm choice:** JAM most robust to poor public data (falls back to private); PMWpub requires representative public data; MST needs no public data but may underutilize available information
  - **Candidate count:** More LLM-generated records improve coverage but increase API cost linearly

- **Failure signatures:**
  - PE with DP not beating "independent marginal sampling" baseline -> composition cost too high relative to iteration benefit
  - JAM with Gemini ≈ JAM with uniform -> LLM data adds no meaningful signal; algorithm falling back to private measurements
  - Workload error converges without privacy but diverges with DP -> noise overwhelming signal in histogram selection

- **First 3 experiments:**
  1. **Baseline establishment:** Run independent marginal sampling, MST, and direct DP workload queries on UCI Adult with 2-way marginal workload to set performance floor
  2. **One-shot Gemini validation:** Generate ~131K records via Gemini, run JAM with this data, compare against JAM with uniform random data (critical comparison to isolate LLM contribution)
  3. **PE convergence sanity check:** Run PE without privacy (ε=∞) to verify the mechanism can theoretically converge; then run with ε=1 to quantify composition damage

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can a hybrid algorithm combining Private Evolution with one-shot generation techniques achieve higher accuracy for DP synthetic tabular data than either method alone?
- **Basis in paper:** [explicit] The authors conclude by asking, "perhaps there are ways to achieve better accuracy by combining Private Evolution and our one-shot approach."
- **Why unresolved:** The paper evaluates the adaptive Private Evolution and the one-shot "Gem Synth" methods separately, finding neither beats state-of-the-art baselines.
- **What evidence would resolve it:** A proposed algorithm that integrates one-shot generation into the Private Evolution loop and demonstrates lower workload error on the UCI Adult dataset.

### Open Question 2
- **Question:** Does fine-tuning general-purpose LLMs on public tabular data improve the utility of their generated records when used as public data for DP synthesis?
- **Basis in paper:** [explicit] The authors propose that "doing some finetuning on publicly available tabular data could improve the quality of the Gemini-generated tabular records fed into our one-shot method."
- **Why unresolved:** The experiments utilized off-the-shelf Gemini 1.0 Pro, which may lack a strong prior for specific tabular structures compared to a fine-tuned model.
- **What evidence would resolve it:** Comparing the workload error of algorithms like JAM or PMWpub when initialized with records from a standard LLM versus one fine-tuned on relevant public datasets.

### Open Question 3
- **Question:** Can foundation models specifically trained on tabular data improve the fidelity of DP synthetic data generation via API access?
- **Basis in paper:** [explicit] The authors suggest that "combining our methods with better models (e.g. models trained on more tabular data) could potentially improve the final accuracy."
- **Why unresolved:** The study relied on Gemini, a general-purpose model, which may not capture the statistical nuances of tabular data as effectively as a specialized model.
- **What evidence would resolve it:** Replicating the experiments using a foundation model pre-trained specifically on large-scale tabular corpora to see if it outperforms the Gemini baselines.

## Limitations
- Neither proposed approach consistently outperforms simple baselines like independent marginal sampling
- Experimental scope limited to one dataset (UCI Adult) and one workload type (2-way marginals)
- Exact Gemini prompts and PE hyperparameters not fully specified, affecting reproducibility
- Composition costs destroy utility in Private Evolution at practical privacy budgets

## Confidence
- **High Confidence:** Workload error measurements on UCI Adult dataset; baseline comparisons are clearly reported and reproducible.
- **Medium Confidence:** Theoretical justification for workload-aware distance function; the mathematical derivation is sound but empirical validation is limited to one dataset.
- **Low Confidence:** Claims about LLM-generated data usefulness; experimental results show no meaningful improvement over uniform random data, contradicting the paper's premise.

## Next Checks
1. **Cross-dataset validation:** Test both approaches on diverse tabular datasets (e.g., Census, medical data) with varying dimensionality and correlation structures to assess generalizability beyond UCI Adult.

2. **Prompt engineering impact:** Systematically vary Gemini prompts (temperature, top-k, schema specificity) and measure the resulting marginal accuracy of generated data to identify whether prompt improvements could make the one-shot approach viable.

3. **Budget sensitivity analysis:** Conduct experiments across multiple ε values (0.1 to 10) for Private Evolution to precisely quantify where composition costs destroy utility and whether any ε range exists where iterative refinement provides net benefit.