---
ver: rpa2
title: 'Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents'
arxiv_id: '2506.01344'
source_url: https://arxiv.org/abs/2506.01344
tags:
- flowchart
- nodes
- node
- attribution
- flowpathagent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FlowPathAgent addresses the challenge of accurately interpreting
  flowcharts by introducing fine-grained flowchart attribution. It segments flowcharts,
  converts them into symbolic graphs, and employs a neurosymbolic agent to dynamically
  interact with the graph for generating attribution paths.
---

# Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents

## Quick Facts
- **arXiv ID:** 2506.01344
- **Source URL:** https://arxiv.org/abs/2506.01344
- **Reference count:** 40
- **Primary result:** FlowPathAgent achieves 10-14% higher accuracy than baselines on FlowExplainBench dataset for flowchart attribution

## Executive Summary
FlowPathAgent introduces a neurosymbolic approach to flowchart attribution that addresses the challenge of visual hallucinations in flowchart question answering. The system segments flowcharts into labeled regions, converts them into symbolic graphs using Mermaid code, and employs an agentic tool-use framework to dynamically traverse these graphs for generating attribution paths. This architecture bridges visual and symbolic representations, enabling precise attribution of model responses to specific decision points. Experimental results demonstrate significant improvements over strong baselines, reducing visual hallucinations by forcing the agent to reason over discrete logical states rather than continuous pixel data.

## Method Summary
The method operates through a three-stage pipeline: first, FlowMask2Former segments the flowchart image into labeled regions; second, Flow2Mermaid transcribes the labeled visual elements into a structured Mermaid graph representation; third, a neurosymbolic agent equipped with graph traversal tools dynamically interacts with this symbolic representation to answer queries and generate attribution paths. The agent doesn't freely generate text but must use constrained tools (like get_descendants, path_between) to query the actual graph topology, ensuring logical consistency. This neurosymbolic integration separates perception from reasoning, reducing the hallucination burden on the reasoning model while maintaining precise visual-symbolic correspondence.

## Key Results
- Outperforms strong baselines by 10-14% in accuracy on FlowExplainBench dataset
- Achieves 95% segmentation accuracy and 0.98 rate of IoU > 0.5 for node detection
- Significantly reduces visual hallucinations by enforcing reasoning over symbolic graphs rather than pixel data

## Why This Works (Mechanism)

### Mechanism 1: Intermediate Symbolic Representation
The system transcodes flowcharts into symbolic graphs to reduce the visual hallucination burden on the reasoning model. By converting images into structured Mermaid code, it separates perception from reasoning—allowing the downstream agent to operate on discrete logical states (nodes/edges) rather than continuous pixel data. This eliminates reliance on visual recognition for every reasoning step and avoids compounding errors seen in purely visual models. The core assumption is that visual-to-symbolic transcription is accurate enough to serve as ground truth for reasoning.

### Mechanism 2: Agentic Tool-Use for Traversal
Constrained tool use enforces logical consistency in path attribution. Instead of freely generating text paths (which invites hallucination), the agent must interact with the graph via defined APIs (e.g., get_descendants, path_between). This forces the reasoning process to query actual graph topology, ensuring requested paths physically exist before attribution. The core assumption is that the VLM possesses sufficient procedural knowledge to select the correct sequence of graph tools for each query type.

### Mechanism 3: Visual-Symbolic Correspondence Anchoring
Pre-segmentation and labeling create a "grounding map" that prevents the agent from hallucinating visual regions. FlowMask2Former segments and assigns labels (A, B, C) to visual regions before reasoning begins, and the agent reasons strictly using these labels. When the agent outputs a path (e.g., "A -> C"), the system maps these labels back to pre-computed segmentation masks. The core assumption is that the segmentation model can robustly identify nodes across diverse visual styles.

## Foundational Learning

- **Concept: Neurosymbolic Integration**
  - Why needed here: This paper exemplifies combining "Neuro" (VLMs for perception/planning) with "Symbolic" (Graph structures for logic). The Neural part handles noise and perception, while the Symbolic part handles truth and consistency.
  - Quick check question: Can you explain why a purely neural approach might "hallucinate" a connection that doesn't exist, while a symbolic approach would not?

- **Concept: Hallucination in VLMs**
  - Why needed here: The problem statement relies on VLMs fabricating visual connections. Understanding this specific failure mode is crucial.
  - Quick check question: In the context of flowcharts, what is the difference between a "visual hallucination" (seeing a non-existent arrow) and a "logical hallucination" (inferring a wrong cause-and-effect)?

- **Concept: Graph Traversal (BFS/DFS)**
  - Why needed here: The agent's tools rely on basic graph theory. Understanding ancestor/descendant relationships is required to interpret tool outputs.
  - Quick check question: If an agent needs to find the *immediate* next step from a decision node, which graph relationship (ancestor vs. descendant/neighbor) is relevant?

## Architecture Onboarding

- **Component map:** FlowMask2Former (Segmenter) -> Flow2Mermaid (Transcriber) -> Mermaid Parser -> FlowChart object -> Agent with Graph Tools
- **Critical path:** The Flow2Mermaid VLM is the highest leverage point—if this component mistranscribes the visual flow into the Mermaid graph, the Agent cannot reason correctly because it operates on a "broken" map of reality.
- **Design tradeoffs:** Modular pipeline (Segment -> Graph -> Agent) trades simplicity of a single prompt for reliability of explicit graph logic, requiring three distinct models instead of one.
- **Failure signatures:** "Ghost Paths" (agent outputs path that exists in graph but not visual reality due to transcriber error) and "Tool Looping" (agent repeatedly calls same tool without progressing).
- **First 3 experiments:**
  1. Unit Test the Transcriber: Feed flowcharts to Flow2Mermaid and manually verify if output graph structure matches image edges.
  2. Tool Ablation: Run Agent with only local tools (get_neighbors) vs. global tools (path_between) to see which improves performance on topological vs. scenario questions.
  3. Segmentation Robustness: Stress test FlowMask2Former by varying line thickness or grayscale conversion to see if node labeling degrades.

## Open Questions the Paper Calls Out

### Open Question 1
How can the framework be adapted to robustly handle hand-drawn flowcharts with non-standard notation and visual noise? The current FlowMask2Former is trained on synthetic datasets with standard digital styles, lacking the variability and noise inherent in human sketches. Evidence would be successful application on a large-scale dataset of hand-drawn flowcharts (e.g., FC_BScan) using semi-supervised annotation strategies.

### Open Question 2
Can FlowPathAgent be extended to interpret dynamic or interactive flowcharts with evolving decision processes? The current approach is designed for static charts, lacking mechanisms to track state changes or conditional dependencies over time. Evidence would be a modified agent architecture processing sequential visual inputs or logs, validated on time-evolving flowchart streams.

### Open Question 3
Would integrating reinforcement learning (RL) or self-supervised learning improve the agent's adaptability to diverse flowchart formats? The current agent relies on supervised fine-tuning and heuristic tool usage, which may be rigid compared to optimization landscapes offered by RL for path tracing. Evidence would be comparative study showing RL-tuned agent achieves higher generalization scores on out-of-distribution flowchart styles.

## Limitations

- **Symbolic Representation Fidelity:** The approach hinges on accurate conversion from visual flowcharts to symbolic Mermaid graphs, but doesn't fully quantify Mermaid transcription errors which could be the dominant failure mode.
- **Tool Selection Dependency:** The agent's effectiveness depends on selecting appropriate graph tools for each query type, but doesn't address cases where tool selection itself might fail for complex multi-step reasoning tasks.
- **Dataset Representativeness:** The FlowExplainBench dataset focuses on well-structured flowcharts with clear decision points, without addressing performance on flowcharts with ambiguous branching, nested structures, or non-standard visual layouts.

## Confidence

**High Confidence (8/10):** Separating perception (segmentation/transcription) from reasoning (agentic graph traversal) is sound and well-supported by experimental results showing 10-14% accuracy improvements over baselines.

**Medium Confidence (6/10):** The claim that neurosymbolic integration specifically reduces visual hallucinations is plausible but not exhaustively validated—the paper shows improved attribution but doesn't comprehensively compare hallucination rates against pure VLM approaches.

**Low Confidence (4/10):** The scalability claim for diverse flowchart domains is weakly supported, with experiments focusing on a single dataset without extensive testing across different flowchart styles, industries, or complexity levels.

## Next Checks

1. **Error Propagation Analysis:** Systematically measure how errors in Flow2Mermaid transcription cascade through the agent's reasoning pipeline using a controlled test set with known ground truth graphs and synthetic errors.

2. **Tool Selection Ablation:** Compare FlowPathAgent performance when using only local tools (get_neighbors, get_children) versus global tools (path_between, get_ancestors) across different query types to quantify each tool category's contribution.

3. **Cross-Domain Robustness:** Test the complete pipeline on flowcharts from diverse domains (medical decision trees, software flowcharts, business processes) with varying visual styles to assess generalization beyond the FlowExplainBench dataset.