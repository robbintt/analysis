---
ver: rpa2
title: Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic
  Graphs
arxiv_id: '2501.15777'
source_url: https://arxiv.org/abs/2501.15777
tags:
- feedback
- responses
- answer
- text
- students
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an automatic feedback generation system for
  short-answer reading comprehension questions using Answer Diagnostic Graphs (ADG).
  The system addresses the challenge of providing meaningful feedback for student
  responses by integrating the logical structure of reading texts with feedback templates.
---

# Automatic Feedback Generation for Short Answer Questions using Answer Diagnostic Graphs

## Quick Facts
- arXiv ID: 2501.15777
- Source URL: https://arxiv.org/abs/2501.15777
- Reference count: 32
- Primary result: Automatic feedback generation system for short-answer questions using Answer Diagnostic Graphs (ADG)

## Executive Summary
This paper presents an automatic feedback generation system for short-answer reading comprehension questions using Answer Diagnostic Graphs (ADG). The system addresses the challenge of providing meaningful feedback for student responses by integrating the logical structure of reading texts with feedback templates. The ADG maps student responses to nodes in a graph representing the text's structure, enabling targeted feedback generation. The system was evaluated with 39 Japanese high school students who answered two prompts (70-80 words each) and received either model answers with explanations or system-generated feedback.

## Method Summary
The system uses Answer Diagnostic Graphs (ADG) to map student responses to nodes representing the logical structure of reading texts. The approach integrates text structure analysis with feedback templates to generate targeted feedback. The evaluation involved 39 Japanese high school students who answered two short prompts and received either model answers with explanations or system-generated feedback. The system aims to help students identify errors and understand key text points while increasing motivation for learning.

## Key Results
- No significant difference in score improvements between system feedback and model answer groups
- Feedback helped students identify errors and understand key text points
- System-generated feedback significantly increased student motivation

## Why This Works (Mechanism)
The system works by mapping student responses to nodes in a graph that represents the logical structure of reading texts. This allows for targeted feedback generation that addresses specific aspects of student understanding. The integration of text structure analysis with feedback templates enables the system to provide context-specific guidance. By focusing on the logical relationships within texts, the system can identify where student comprehension breaks down and provide appropriate corrective feedback.

## Foundational Learning
- Text structure analysis: Understanding how to represent logical relationships in texts
  - Why needed: Essential for mapping student responses to appropriate feedback
  - Quick check: Can the system correctly identify main ideas and supporting details
- Graph-based representation: Using graph structures to model text comprehension
  - Why needed: Enables systematic mapping between responses and feedback
  - Quick check: Are all relevant text elements properly connected in the graph
- Feedback template integration: Combining structured text analysis with pre-defined feedback patterns
  - Why needed: Provides consistent, targeted feedback for common errors
  - Quick check: Does feedback appropriately match identified comprehension issues

## Architecture Onboarding
Component map: Text Analysis -> ADG Construction -> Response Mapping -> Feedback Generation
Critical path: Student response → Text structure analysis → ADG node matching → Template-based feedback
Design tradeoffs: Limited feedback flexibility vs. consistent quality
Failure signatures: Misalignment between response and graph nodes, template mismatch
First experiments:
1. Test system with simple texts and clear logical structures
2. Evaluate feedback accuracy for common comprehension errors
3. Measure response time and processing efficiency

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (39 students) and single session limit generalizability
- Limited impact on learning outcomes despite increased motivation
- System effectiveness constrained by ability to capture complex text logical structures

## Confidence
- High Confidence: The system can generate targeted feedback for short-answer questions using the ADG approach
- Medium Confidence: The feedback system improves student motivation and helps identify errors
- Low Confidence: The system significantly improves learning outcomes and comprehension of text logical structures

## Next Checks
1. Conduct a longitudinal study with larger, more diverse student populations across multiple sessions to assess sustained learning effects
2. Test the system's scalability and effectiveness on longer, more complex texts with multiple logical structures
3. Implement a controlled comparison with human-generated feedback to quantify the quality gap and identify specific improvement areas