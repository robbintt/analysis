---
ver: rpa2
title: 'From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification
  Framework for Healthcare Analytics'
arxiv_id: '2509.05484'
source_url: https://arxiv.org/abs/2509.05484
tags:
- messages
- classification
- data
- patient
- healthcare
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study developed a multi-stage LLM-based framework to classify
  and analyze unstructured staff messages from hospital call centers, addressing the
  challenge of extracting actionable insights from large volumes of textual data.
  The methodology combined topic modeling with a three-stage classification system:
  keyword-based initial categorization, LLM-driven secondary classification, and context-aware
  tertiary classification using the entire message thread.'
---

# From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics

## Quick Facts
- arXiv ID: 2509.05484
- Source URL: https://arxiv.org/abs/2509.05484
- Reference count: 20
- Primary result: Multi-stage LLM framework achieves 78.4% weighted F1 and 79.2% accuracy for classifying hospital staff messages

## Executive Summary
This study addresses the challenge of extracting actionable insights from unstructured staff messages in hospital call centers by developing a three-stage LLM classification framework. The methodology combines keyword-based initial filtering, LLM-driven secondary classification, and context-aware tertiary classification using full message threads. Performance evaluation of 17 different LLMs demonstrated that reasoning-capable models like OpenAI's o3 achieved the highest accuracy of 78.4% F1-score and 79.2% accuracy, followed closely by gpt-5 and DeepSeek-R1. The classified messages were integrated into a Power BI dashboard for healthcare professionals to identify training opportunities, monitor patient access patterns, and improve operational efficiency through data-driven insights.

## Method Summary
The framework implements a three-stage classification pipeline: Stage 1 applies keyword-based filtering to capture easily classifiable messages; Stage 2 deploys LLM-based classification with prompt engineering on remaining ambiguous cases; Stage 3 provides full message thread context to the LLM for the most difficult cases. Topic modeling using GPT-4o and RAG in Azure Foundry AI derives a hierarchical topic structure from 1,000 sample messages. The methodology evaluates 17 LLMs on a labeled subset of 500 messages, measuring weighted F1-score and accuracy. Results show flagship reasoning models outperform general-purpose models, with o3 achieving 78.4% F1 and 79.2% accuracy. The classified messages are visualized in a Power BI dashboard showing clinical and non-clinical topic distributions and temporal trends.

## Key Results
- OpenAI's o3 achieved the highest weighted F1-score of 78.4% and accuracy of 79.2%
- Reasoning-capable models (o3, DeepSeek-R1, gpt-5) significantly outperformed general-purpose models
- The three-stage approach balanced computational efficiency with classification accuracy for high-volume healthcare messaging data
- Classified messages were successfully integrated into a Power BI decision support dashboard

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A three-stage progressive classification approach balances computational efficiency with classification accuracy for high-volume healthcare messaging data.
- Mechanism: Stage 1 applies low-cost keyword-based filtering to capture easily classifiable messages; Stage 2 deploys LLM-based classification with prompt engineering on remaining ambiguous cases; Stage 3 provides full message thread context to the LLM for the most difficult cases. This cascading approach avoids applying expensive LLM inference to all messages while preserving accuracy through escalating sophistication.
- Core assumption: Messages that match keyword patterns require less contextual reasoning than those that don't, and the marginal accuracy gain from full-thread context justifies its computational cost only for persistently ambiguous cases.
- Evidence anchors: [abstract] "three-stage classification system: keyword-based initial categorization, LLM-driven secondary classification, and context-aware tertiary classification using the entire message thread"; [section 3.2.2] Mathematical formulation showing f₁, f₂, f₃ functions partitioning messages into M₁, O₁, M₂, O₂, with dataset sizes of 2,000 at stage 1, 1,335 at stage 2, and variable at stage 3.

### Mechanism 2
- Claim: Context window expansion through full message threads improves classification accuracy for semantically ambiguous healthcare communications.
- Mechanism: Initial encounter messages often lack complete context about caller intent. By feeding the entire message thread to the LLM at Stage 3, the model can infer implicit reasons from conversational flow, clarifications, and responses—effectively using dialog structure as a reasoning scaffold.
- Core assumption: Message threads contain disambiguating information that single messages lack, and LLMs can effectively extract and weight this information during classification.
- Evidence anchors: [abstract] "context-aware tertiary classification using the entire message thread"; [section 3.2.2] "f₃ applies contextual LLM-based classification with enhanced prompt engineering P₃, where the entire encounter message thread is fed to the LLM instead of just the first message."

### Mechanism 3
- Claim: Reasoning-capable LLMs (o3, DeepSeek-R1) outperform general-purpose models for nuanced healthcare staff message classification due to superior handling of implicit context and domain-specific language patterns.
- Mechanism: Staff messages contain domain jargon, abbreviations, protocol references, and implicit organizational knowledge. Reasoning models decompose classification into intermediate inferential steps—identifying entities, inferring relationships, resolving ambiguities—before assigning categories, whereas general-purpose models may map surface patterns without deeper semantic parsing.
- Core assumption: The performance gap stems from reasoning architecture rather than parameter count alone, and the classification task requires multi-step inference rather than pattern matching.
- Evidence anchors: [abstract] "OpenAI's o3 achieved the highest weighted F1-score of 78.4%... followed closely by gpt-5 and DeepSeek-R1"; [section 4.1] "reasoning capabilities and advanced architecture of large flagship models provide substantial advantages for understanding the nuanced language patterns in staff messages."

## Foundational Learning

- Concept: **Multi-class vs. Multi-label Classification**
  - Why needed here: The paper transforms hierarchical multi-label classification into flat multi-class classification for visualization simplicity—understanding this distinction is essential for interpreting the topic hierarchy design and why only "level 1 and most granular subtopic" appear in the dashboard.
  - Quick check question: If a message could simultaneously belong to "prescription refill" and "insurance inquiry," which classification paradigm handles this, and which does the paper choose for the final output?

- Concept: **LLM Inference Time/Accuracy Tradeoffs**
  - Why needed here: The paper reports inference times ranging from ~10 minutes (Phi-4-mini-instruct) to >90 minutes (DeepSeek-R1), and notes o3's combination of best accuracy and fast computation—critical for production deployment decisions.
  - Quick check question: A hospital needs real-time classification of 400 daily messages with <30-minute batch latency. Which models from Figure 6 are viable, and what accuracy sacrifice does this entail?

- Concept: **HIPAA Compliance in Cloud LLM Deployments**
  - Why needed here: The framework explicitly incorporates "data security measures and HIPAA compliance requirements essential for healthcare environments" via Azure OpenAI—understanding PHI handling, BAA requirements, and data residency is non-negotiable for healthcare AI systems.
  - Quick check question: What specific Azure service features or configurations would be required to maintain HIPAA compliance when processing encounter messages containing patient identifiers?

## Architecture Onboarding

- Component map: Hospital EHR Database → Staff Message Extraction (encounter-level + message-level) → Topic Modeling (GPT-4o + RAG in Azure Foundry AI, n=1,000 sample) → Three-Stage Classification Pipeline → Postprocessing → Power BI Dashboard

- Critical path: Classification accuracy at Stage 2 determines dashboard utility. If weighted F1 drops below ~70%, topic distributions become unreliable for operational decisions (training recommendations, resource allocation). The 500-message labeled subset serves as ground truth—its representativeness is a key validity assumption.

- Design tradeoffs:
  - Accuracy vs. Cost: o3 achieves 78.4% F1 but may have higher API costs than gpt-5-nano (lower accuracy). Paper suggests flagship models "may justify their potential higher computational costs" for healthcare applications.
  - Granularity vs. Usability: Hierarchical topics provide richer information, but dashboard displays only level-1 and leaf nodes for "simplified visualization."
  - Batch vs. Real-time: Current architecture appears batch-oriented; real-time would require rethinking Stage 3 thread-waiting logic.

- Failure signatures:
  - High "Other3" rate: Indicates topic hierarchy incomplete or prompts inadequate for message diversity
  - Per-class F1 variance (see Appendix Figure 11): Some topics may systematically underperform due to ambiguous boundaries
  - Hallucinated classifications: LLM assigns confident but incorrect categories, especially for ambiguous text—paper explicitly warns this "could significantly impact decision-making accuracy"
  - Temporal drift: Topic distributions shift as new message types emerge, requiring periodic topic hierarchy refresh

- First 3 experiments:
  1. **Baseline replication**: Run the three-stage pipeline on a held-out 500-message sample using o3. Compare weighted F1, accuracy, and per-class F1 against reported 78.4%/79.2%. Flag any >5% degradation.
  2. **Ablation study**: Test Stage 3 removal (skip thread context) and measure accuracy drop. This quantifies the marginal value of context expansion and validates Mechanism 2.
  3. **Topic hierarchy validation**: Have domain experts review the LLM-generated topic hierarchy (Figure 4) against a random sample of 100 classified messages. Assess whether categories are mutually exclusive, collectively exhaustive, and actionable for training/resource decisions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the multi-stage framework be extended to detect HIPAA violations, protocol breaches, and dismissive language in addition to topic classification?
- Basis in paper: [explicit] The authors propose future research to cover "HIPAA violation and protocol breach flagging" and "inappropriate staff messaging detection."
- Why unresolved: The current study focused exclusively on multi-class topic categorization and lacked modules for compliance or sentiment-based detection.
- What evidence would resolve it: Implementation of specialized detection prompts and evaluation of precision/recall metrics for violation flagging on staff messages.

### Open Question 2
- Question: Can autonomous LLM agents effectively classify, clean, and validate data to reduce the need for human-in-the-loop intervention?
- Basis in paper: [explicit] The conclusion suggests exploring "LLM-based agents that autonomously classify... and coordinate with other agents to clean, validate, and enrich this data."
- Why unresolved: The existing methodology relies on manual keyword engineering (Stage 1) and human validation for dashboard integration.
- What evidence would resolve it: Development of an agentic workflow and a comparison of its accuracy and reliability against the current human-validated pipeline.

### Open Question 3
- Question: How does the substantial accuracy gap between flagship and lightweight models impact the feasibility of real-time deployment in resource-constrained clinics?
- Basis in paper: [inferred] The paper notes a nearly 40% accuracy gap between the best and worst models and highlights trade-offs between cost, speed, and performance.
- Why unresolved: The study evaluated models on a static dataset, leaving the operational trade-offs for continuous, real-time high-volume processing undefined.
- What evidence would resolve it: Comparative deployment analysis of high-cost (o3) versus efficient (Phi-4) models on live data streams measuring latency and accuracy drift.

## Limitations

- The topic hierarchy and exact keyword/keyphrase lists for Stage 1 classification are not fully specified, making it difficult to assess whether the topic modeling captures all relevant message types
- The LLM prompt templates are not provided, so the specific reasoning strategies and context extraction methods cannot be evaluated for potential biases
- The paper reports results from a single hospital system, raising questions about generalizability across different healthcare settings and organizational protocols
- The 78.4% F1-score still leaves 21.6% of messages potentially misclassified—this error rate may be unacceptable for high-stakes clinical decisions

## Confidence

- High confidence: The three-stage architectural framework is clearly described and logically sound; the performance evaluation methodology (17 LLMs, weighted F1/accuracy metrics) is rigorous
- Medium confidence: The superiority of reasoning-capable models for this task is supported by results but not conclusively proven, as model size and training data differences weren't controlled
- Low confidence: The generalizability of the topic hierarchy and classification accuracy across different healthcare systems and message types remains uncertain

## Next Checks

1. **External validation**: Apply the framework to message datasets from at least two additional hospital systems with different sizes, specialties, and EHR platforms to assess generalizability of both topic hierarchy and classification accuracy

2. **Ablation analysis**: Systematically remove each classification stage (Stage 1 only, Stage 1+2 only) and measure the incremental accuracy gain from thread context to quantify the marginal value of the full three-stage approach

3. **Error analysis**: Perform detailed manual review of messages misclassified by top-performing models (o3, gpt-5) to identify systematic failure patterns—are errors concentrated in specific topic areas, message types, or do they reveal limitations in the topic hierarchy itself?