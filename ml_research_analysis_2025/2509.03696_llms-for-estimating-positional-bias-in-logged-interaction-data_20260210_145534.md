---
ver: rpa2
title: LLMs for estimating positional bias in logged interaction data
arxiv_id: '2509.03696'
source_url: https://arxiv.org/abs/2509.03696
tags:
- position
- relevance
- propensity
- click
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of estimating position bias
  in logged user interaction data for recommender and search systems. The authors
  propose a novel method using Large Language Models (LLMs) to estimate propensities
  of item examination at different positions, offering a cost-effective alternative
  to online experimentation.
---

# LLMs for estimating positional bias in logged interaction data

## Quick Facts
- arXiv ID: 2509.03696
- Source URL: https://arxiv.org/abs/2509.03696
- Reference count: 19
- Proposes LLM-based method for estimating position bias in logged interaction data for recommender systems

## Executive Summary
This paper addresses the challenge of estimating position bias in logged user interaction data for recommender and search systems. The authors propose a novel method using Large Language Models (LLMs) to estimate propensities of item examination at different positions, offering a cost-effective alternative to online experimentation. The approach relies on LLM-as-a-judge scores to estimate relevance independent of position, then uses these scores to compute examination propensities from click logs. Experiments on Viator's grid-based search results show that the LLM-based propensity estimates are stable across different relevance score buckets and reveal row-column effects that simpler heuristics miss. An Inverse Propensity Scoring (IPS)-weighted reranker trained with these propensities matches the production model on NDCG@10 while improving weighted NDCG@10 by roughly 2%.

## Method Summary
The proposed method leverages LLMs to estimate relevance scores independent of item position, enabling the computation of examination propensities from click logs without costly online experiments. The approach uses LLM-as-a-judge to assess item relevance, then applies inverse propensity scoring to reweight logged interactions based on estimated examination probabilities. This creates a framework where positional bias can be quantified and corrected in the learning-to-rank process. The method is particularly valuable for platforms where running A/B tests is expensive or impractical.

## Key Results
- LLM-based propensity estimates are stable across different relevance score buckets
- Method reveals row-column effects in grid-based search that simpler heuristics miss
- IPS-weighted reranker matches production model on NDCG@10 while improving weighted NDCG@10 by roughly 2%

## Why This Works (Mechanism)
The method works by leveraging the LLM's ability to provide relevance judgments independent of position, effectively decoupling content quality from presentation effects. By using these relevance scores to model examination probabilities from click data, the approach can estimate how position influences user attention without requiring explicit randomization experiments. The LLM serves as a stable proxy for human judgment across diverse queries, enabling more accurate propensity estimation than heuristic-based approaches.

## Foundational Learning

**Large Language Model as Judge**: Using LLMs to provide consistent relevance assessments across items and queries, eliminating human annotation costs while maintaining judgment quality.

*Why needed*: Traditional relevance labeling is expensive and inconsistent across annotators; LLM-based scoring provides scalable, reproducible judgments.

*Quick check*: Compare LLM judgments against human-labeled data on a sample of queries to validate consistency.

**Inverse Propensity Scoring (IPS)**: A technique for debiasing logged interaction data by weighting samples according to estimated examination probabilities.

*Why needed*: Click logs are biased by position; IPS corrects this by upweighting items that were less likely to be examined.

*Quick check*: Verify that IPS-corrected metrics align with randomized experiment results on a subset of data.

**Examination Propensity Estimation**: Modeling the probability that users examine items at different positions, independent of their relevance.

*Why needed*: Position bias affects all logged interactions; accurate propensity estimation is essential for fair evaluation and training.

*Quick check*: Test whether estimated propensities correlate with position across multiple datasets and interface types.

## Architecture Onboarding

**Component Map**: Click Logs -> LLM Relevance Scoring -> Examination Propensity Estimation -> IPS-weighted Training -> Reranker Model

**Critical Path**: The core workflow involves processing click logs through LLM scoring to derive position-agnostic relevance, then computing propensities and applying them in the learning-to-rank training pipeline.

**Design Tradeoffs**: The approach trades computational cost of LLM inference against the expense and complexity of online experiments. Using a single LLM model provides consistency but may miss domain-specific nuances that human judges would capture.

**Failure Signatures**: If LLM relevance scores are inconsistent or biased, propensity estimates will be unreliable. Poor alignment between LLM judgments and actual user preferences will manifest as degraded ranking performance despite position bias correction.

**3 First Experiments**:
1. Validate LLM scoring stability by computing consistency metrics across repeated evaluations of the same items
2. Compare propensity estimates from LLM-based method against heuristic baselines on held-out data
3. Test IPS-weighted training with synthetic click logs where ground truth position bias is known

## Open Questions the Paper Calls Out
None

## Limitations
- Limited validation that LLM judgments align with human perception across diverse domains
- Experimental results based solely on grid-based search may not generalize to list interfaces
- Computational costs and scalability with larger datasets not thoroughly explored

## Confidence

**High Confidence**: The core methodology of using LLM-as-a-judge to decouple relevance from position is technically sound and well-explained.

**Medium Confidence**: The experimental results showing improvement over baseline methods are valid for the specific dataset and context studied.

**Low Confidence**: Generalizability of the approach to other domains and the long-term stability of LLM-based propensity estimates.

## Next Checks

1. Conduct cross-domain validation by applying the method to list-based search interfaces and different recommendation domains to test generalizability.

2. Perform ablation studies to quantify the impact of different LLM models and prompt engineering approaches on propensity estimation accuracy.

3. Implement a longitudinal study to assess the stability of LLM-based propensities over time as the underlying model and user behavior patterns evolve.