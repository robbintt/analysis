---
ver: rpa2
title: Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World
  Applications
arxiv_id: '2507.16507'
source_url: https://arxiv.org/abs/2507.16507
tags:
- knowledge
- agent
- inraexplorer
- publications
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the limitations of conventional RAG systems
  in handling complex, multi-hop reasoning tasks, especially in knowledge-intensive
  domains. INRAExplorer is introduced as an agentic RAG system that integrates an
  LLM-based agent with a multi-tool architecture, enabling dynamic engagement with
  a comprehensive knowledge graph derived from INRAE publications.
---

# Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications

## Quick Facts
- **arXiv ID**: 2507.16507
- **Source URL**: https://arxiv.org/abs/2507.16507
- **Reference count**: 18
- **Primary result**: Agentic RAG system with knowledge graph integration for multi-hop reasoning over scientific publications

## Executive Summary
This paper presents INRAExplorer, an agentic RAG system designed to overcome the single-pass limitations of classical RAG for complex, multi-hop reasoning tasks. The system integrates an LLM-based agent with a hybrid knowledge base combining vector search and a comprehensive knowledge graph of INRAE publications. By enabling iterative tool orchestration and structured relationship navigation, INRAExplorer supports exhaustive data retrieval and targeted queries in specialized domains like agricultural research.

## Method Summary
INRAExplorer combines GROBID-extracted INRAE publications with a hybrid knowledge base: a vector database (Qdrant) storing dense and sparse embeddings, and a Neo4j knowledge graph (417K nodes, 1M+ relationships) modeling entities like authors, publications, projects, and concepts. An LLM agent (deepseek-r1-0528) orchestrates four specialized tools—SearchGraph (Cypher queries), SearchPublications (hybrid search), SearchConceptsKeywords, and IdentifyExperts (composite scoring)—to decompose complex queries into iterative retrieval steps. The system supports multi-hop reasoning by using vector search for initial discovery and knowledge graph traversal for exhaustive, relationship-aware results.

## Key Results
- Overcomes single-pass limitation of classical RAG through iterative agentic tool orchestration
- Combines vector search for semantic entry-point discovery with knowledge graph traversal for exhaustive multi-hop reasoning
- Encapsulates domain-specific workflows (e.g., expert identification) for reproducible outputs
- Designed as open, adaptable solution for advanced knowledge exploration in specialized fields

## Why This Works (Mechanism)

### Mechanism 1: Agentic Tool Orchestration for Iterative Query Resolution
An LLM-based agent dynamically decomposes complex queries and selects appropriate tools across multiple retrieval steps, overcoming the single-pass limitation of classical RAG. The agent receives a query, plans a sequence of tool invocations, executes tools iteratively, evaluates intermediate results, and synthesizes a final answer. Tools include SearchGraph (Cypher queries), SearchPublications (hybrid vector search), and specialized encapsulated tools like IdentifyExperts. This approach enables the system to handle queries requiring multiple reasoning steps.

### Mechanism 2: Hybrid Knowledge Base with KG as Structured Backbone
Combining vector search for entry-point discovery with knowledge graph traversal for exhaustive, relationship-aware retrieval enables both semantic flexibility and structural precision. Vector DB stores dense (Jina v3) and sparse (BM25) representations of text chunks for semantic/keyword matching. The KG (Neo4j, 417K nodes, 1M+ relationships) stores entities with explicit relationships. The agent uses vector search to find initial relevant documents, then traverses the KG for complete entity sets and multi-hop paths.

### Mechanism 3: Encapsulated Tool Design for Reproducible Domain Logic
Specialized tools that encapsulate complex, domain-specific workflows produce more consistent and reproducible outputs than raw tool access for every task. The IdentifyExperts tool wraps a predefined workflow: retrieve relevant publications → extract authors → calculate composite expertise scores → return ranked list. The agent invokes this high-level tool rather than manually orchestrating each step, reducing complexity while maintaining domain accuracy.

## Foundational Learning

- **Knowledge Graph querying (Cypher/SPARQL)**: The SearchGraph tool requires formulating Cypher queries to traverse relationships like `FUNDED_BY` and `DESCRIBES`. Understanding graph patterns (nodes, edges, paths) is essential for debugging retrieval failures. Quick check: Can you write a Cypher query to find all publications funded by a specific project?

- **Hybrid search (dense + sparse vectors)**: SearchPublications combines semantic similarity (dense embeddings) with keyword matching (BM25). Understanding the tradeoffs helps interpret reranking behavior and retrieval quality. Quick check: Why would BM25 outperform dense embeddings for exact phrase matching?

- **Agentic reasoning patterns (ReAct-style planning)**: The agent must decompose queries into tool sequences, evaluate intermediate results, and adapt plans. Familiarity with chain-of-thought and reasoning-action interleaving aids prompt design and failure diagnosis. Quick check: What happens if an agent's intermediate reasoning step produces an incorrect entity name used in subsequent tool calls?

## Architecture Onboarding

- **Component map**: LLM Agent (deepseek-r1-0528) -> Mirascope orchestrator -> Vector Database (Qdrant) + Knowledge Graph (Neo4j) -> Specialized Tools (SearchGraph, SearchPublications, SearchConceptsKeywords, IdentifyExperts)

- **Critical path**: 1) Data ingestion: HAL + OpenAire merge → enrichment via DOI lookups → GROBID extraction 2) KG construction: Entity resolution → relationship extraction → INRAE thesaurus integration 3) Vector indexing: Chunk concatenation → dense + sparse embedding 4) Agent deployment: Tool definitions → prompt engineering → end-to-end testing

- **Design tradeoffs**: Exhaustiveness vs. latency (multi-hop traversal vs. fast single-pass), open-source vs. performance (deepseek-r1-0528 vs. proprietary models), encapsulation vs. flexibility (specialized tools vs. raw tool access)

- **Failure signatures**: Empty retrieval (vector search returns nothing), incomplete multi-hop paths (KG traversal stops early), inconsistent expert rankings (IdentifyExperts variations), agent planning failures (wrong tool sequences)

- **First 3 experiments**: 1) Baseline comparison: Run 10 complex multi-hop queries through both classical RAG and INRAExplorer; measure answer completeness and path accuracy 2) Tool ablation: Disable SearchGraph and force agent to rely solely on vector retrieval; assess degradation in relationship-aware queries 3) Encapsulated tool validation: Run IdentifyExperts on 5 known experts; compare agent-driven expert identification vs. manual ranking

## Open Questions the Paper Calls Out

### Open Question 1
How can a tailored evaluation framework effectively measure the accuracy of complex, multi-hop scientific queries where standard benchmarks fail? The authors state that "Future work will focus on developing a tailored evaluation framework" because "Standard benchmarks fail to capture the complexity of scientific, multi-hop queries central to our use case." A validated benchmark co-designed with domain experts would demonstrate correlation with human assessment of structured, multi-hop outputs.

### Open Question 2
Can Reinforcement Learning from Verifiable Feedback (RLVF) successfully specialize smaller language models to perform robust multi-hop reasoning? The paper proposes that "Techniques inspired by reinforcement learning, such as Reinforcement Learning from Verifiable Feedback (RLVF), could be explored to further refine smaller, more efficient language models." Comparative performance analysis showing smaller RLVF-trained models maintaining or exceeding success rates on reasoning chain tasks would resolve this.

### Open Question 3
To what extent does the specific weighting of the composite expertise score influence the accuracy and stability of the expert identification tool? The `IdentifyExperts` tool calculates scores based on "multiple weighted metrics" but the paper does not provide sensitivity analysis. A sensitivity analysis showing ranked lists remain stable across different weighting configurations, or validation against ground-truth rankings, would resolve this.

## Limitations
- **Quantitative evaluation gap**: No formal metrics for multi-hop reasoning accuracy, completeness, or latency; claims lack comparative validation
- **Scalability and generalizability**: Performance on other domains untested; scaling KG to billions of nodes may require architectural changes
- **Tool orchestration reliability**: LLM planning quality assumed but not empirically validated; failures could cascade and degrade performance

## Confidence
- **High confidence**: Combining vector search for entry-point discovery with KG traversal for exhaustive, relationship-aware retrieval is well-supported by KG statistics and hybrid search design
- **Medium confidence**: Agentic tool orchestration model is plausible given architectural description and similar approaches, but lacks direct quantitative validation
- **Low confidence**: Efficacy of encapsulated IdentifyExperts tool's scoring heuristics and reproducibility of domain-specific logic are asserted but not empirically tested

## Next Checks
1. **Baseline comparative evaluation**: Run 20 complex, multi-hop queries through both classical RAG and INRAExplorer; measure answer completeness, path accuracy, and latency
2. **Tool orchestration stress test**: Systematically generate queries requiring 1-4+ reasoning steps; log tool selection accuracy and answer correctness to quantify planning horizon limits
3. **KG schema and tool logic validation**: Publish complete Neo4j schema and IdentifyExperts scoring weights; enable external replication and expert review of domain logic