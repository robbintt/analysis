---
ver: rpa2
title: 'A Computational Approach to Analyzing Disrupted Language in Schizophrenia:
  Integrating Surprisal and Coherence Measures'
arxiv_id: '2511.03089'
source_url: https://arxiv.org/abs/2511.03089
tags:
- schizophrenia
- coherence
- semantic
- surprisal
- subjects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated language disruptions in schizophrenia using
  surprisal and semantic coherence measures. Spontaneous speech data from 39 subjects
  (20 schizophrenia, 19 healthy controls) was analyzed using GPT-2 for surprisal and
  BERT embeddings for semantic coherence.
---

# A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures

## Quick Facts
- arXiv ID: 2511.03089
- Source URL: https://arxiv.org/abs/2511.03089
- Reference count: 0
- Primary result: Schizophrenia subjects showed slightly lower semantic coherence and slightly higher surprisal than healthy controls

## Executive Summary
This study investigates language disruptions in schizophrenia by integrating surprisal (word predictability) and semantic coherence measures from spontaneous speech data. Using GPT-2 for surprisal computation and BERT embeddings for coherence analysis, the researchers found that schizophrenia subjects exhibited reduced coherence and increased surprisal compared to healthy controls. The relationship between coherence and surprisal was inverse in healthy controls but direct in schizophrenia, suggesting fundamental differences in language processing. The findings indicate that these computational measures could serve as objective markers for schizophrenia severity, though the authors emphasize the need for larger, more diverse datasets.

## Method Summary
The study analyzed 140 transcribed interview sessions from 39 subjects (19 schizophrenia, 20 healthy controls) using computational linguistics approaches. Surprisal was calculated using GPT-2 to measure next-word predictability, while semantic coherence was assessed using both LDA topic modeling and BERT contextual embeddings. Coherence was measured as cosine similarity between adjacent sentence embeddings, with utterances requiring at least 3 sentences for inclusion. Clinical symptom severity was quantified using BPRS scores (range 18-67). The analysis compared group differences between schizophrenia and healthy controls and examined correlations between linguistic metrics and symptom severity.

## Key Results
- Schizophrenia subjects showed slightly lower semantic coherence (0.37 vs 0.39 LDA-based, 0.27 vs 0.28 BERT-based) than healthy controls
- Schizophrenia subjects had slightly higher surprisal (50.98 vs 50.45) than healthy controls
- Semantic coherence and surprisal were inversely correlated for healthy controls but directly correlated for schizophrenia subjects
- Surprisal increased with symptom severity (BPRS scores 18-67), while semantic coherence showed no clear trend

## Why This Works (Mechanism)

### Mechanism 1: Surprisal captures word predictability disruptions in schizophrenia
- Schizophrenia subjects produce less predictable word sequences, with unpredictability increasing with symptom severity
- GPT-2 computes next-word probability given context; schizophrenia disrupts normal probabilistic language generation
- Core assumption: Language model surprisal approximates human expectations in natural speech production
- Evidence anchors: Figure 3 shows average surprisal increases with BPRS scores; abstract notes correlation with clinical symptom intensity
- Break condition: If surprisal-severity relationship disappears in larger datasets or is confounded by medication effects

### Mechanism 2: Semantic coherence measures detect discourse-level disruption
- Schizophrenia subjects show reduced semantic coherence compared to healthy controls
- BERT embeddings capture sequential semantic relationships between sentences; cosine similarity quantifies local semantic flow
- Core assumption: Embedding similarity between adjacent sentences reflects meaningful discourse coherence
- Evidence anchors: Table 1 shows coherence differences (0.28 vs 0.27 BERT-based); paper 44704 validates semantic coherence approaches for thought disorder assessment
- Break condition: If utterance-level averaging obscures within-subject variance or fails to distinguish severe cases

### Mechanism 3: Coherence-surprisal relationship inversion signals pathology
- The relationship between semantic coherence and surprisal is fundamentally altered in schizophrenia—inverted in healthy controls, direct in schizophrenia
- Healthy speakers maintain inverse coupling (more coherent speech is more predictable); schizophrenia disrupts this integration
- Core assumption: The coherence-surprisal relationship reflects underlying cognitive integration in language production
- Evidence anchors: Abstract describes the inverse/direct relationship; Figure 2 visualization shows semantic coherence directly proportional to surprisal for schizophrenia subjects
- Break condition: If this pattern is specific to mild-moderate symptom range and doesn't replicate across severity levels

## Foundational Learning

- **Surprisal theory**
  - Why needed here: Core metric for quantifying processing difficulty; surprisal = negative log probability of word given context
  - Quick check question: Given "The cat sat on the ___", would "mat" or "quantum" have higher surprisal?

- **Contextual vs. static embeddings**
  - Why needed here: Study uses BERT (contextual) and LDA (topic-based); understanding different assumptions is critical
  - Quick check question: Why might BERT capture coherence that LDA misses?

- **BPRS (Brief Psychiatric Rating Scale)**
  - Why needed here: Ground truth for symptom severity; 18-item scale, 1-7 per symptom, used as continuous predictor
  - Quick check question: What range of BPRS scores was included, and why might this limit generalizability?

## Architecture Onboarding

- **Component map**:
  Input transcripts -> NLTK tokenization -> GPT-2 surprisal branch AND BERT coherence branch -> Aggregation and clinical correlation

- **Critical path**:
  1. Utterance segmentation (interviewer/subject separation)
  2. Length filtering (≥3 sentences for coherence branch)
  3. Metric computation at utterance level
  4. Aggregation and correlation with clinical scores

- **Design tradeoffs**:
  - GPT-2 chosen over newer LLMs (cost/stability) but may underperform on clinical language
  - Minimum 3-sentence filter reduces data volume but enables coherence calculation
  - Single-session vs. multi-session aggregation: study used 140 sessions from 39 subjects

- **Failure signatures**:
  - Short utterances excluded from coherence analysis (data loss)
  - Mild symptom sample limits signal strength (BPRS 18-67, mostly moderate)
  - No medication effects controlled in analysis
  - GPT-2 training data may not represent clinical populations

- **First 3 experiments**:
  1. Replicate coherence-surprisal relationship on held-out data; test if inversion pattern holds
  2. Stratify by symptom severity bins to test whether effect sizes increase at higher BPRS
  3. Substitute GPT-2 with larger model (e.g., Llama, Mistral) to test robustness of surprisal-severity correlation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the relationships between surprisal, semantic coherence, and symptom severity hold true in larger, more diverse cohorts across the full schizophrenia spectrum?
- Basis in paper: [explicit] Authors state findings are "preliminary results based on a small dataset" and call for "more detailed studies on more diverse and larger datasets that are descriptive of the whole range of the schizophrenia spectrum"
- Why unresolved: Current study limited to 39 subjects who were "normally functioning individuals" with mostly mild to moderate symptoms
- What evidence would resolve it: Replication of inverse/direct relationship between coherence and surprisal in study with significantly larger sample including hospitalized individuals with severe symptoms

### Open Question 2
- Question: Does semantic coherence exhibit a definitive negative trend with increasing symptom severity (BPRS) when data is not imbalanced?
- Basis in paper: [inferred] Paper notes analysis showed "not much of change" and suggests lack of trend might be "because... of an unbalance dataset"
- Why unresolved: Current dataset had high concentration of subjects with BPRS scores in middle and lower ends
- What evidence would resolve it: Regression analysis of semantic coherence and BPRS scores using dataset uniformly distributed across entire 18-67 BPRS range

### Open Question 3
- Question: How do antipsychotic medications impact computational measures of surprisal and coherence in patients with extreme schizophrenia symptoms?
- Basis in paper: [inferred] Authors excluded hospitalized subjects with extreme symptoms, noting "results will be hugely biased because of the medication used to treat extreme schizophrenia symptoms"
- Why unresolved: Study design intentionally avoided this confound by focusing on normally functioning individuals
- What evidence would resolve it: Controlled study comparing linguistic measures in medicated vs. unmedicated patients, or study that statistically controls for medication dosage/type alongside symptom severity

## Limitations
- Small sample size (39 subjects, 140 sessions) and mild-to-moderate symptom range (BPRS 18-67) limit generalizability
- Dataset imbalance (20 healthy vs 19 schizophrenia) and unknown medication status may confound results
- GPT-2 may underperform on clinical language due to training data mismatch
- 3-sentence minimum filter excludes substantial data volume, potentially biasing toward longer utterances
- Dataset access is unclear, preventing independent validation

## Confidence

- **High**: Schizophrenia subjects show lower semantic coherence and higher surprisal than controls (basic group differences are statistically robust)
- **Medium**: Surprisal increases with symptom severity (correlation exists but may be dataset-specific given mild-moderate symptom range)
- **Low**: The coherence-surprisal relationship inversion is a fundamental feature of schizophrenia (based on single dataset with limited sample; no external validation)

## Next Checks

1. **External validation**: Replicate the coherence-surprisal inversion pattern on a completely independent dataset with similar clinical populations to verify this isn't a dataset-specific artifact

2. **Severity stratification**: Analyze whether the surprisal-severity correlation strengthens in higher BPRS bins (>40) to test if mild cases drive the observed pattern

3. **Model robustness**: Replace GPT-2 with larger, more recent language models (e.g., Llama 3, Mistral) to determine if surprisal-severity relationships persist across architectures