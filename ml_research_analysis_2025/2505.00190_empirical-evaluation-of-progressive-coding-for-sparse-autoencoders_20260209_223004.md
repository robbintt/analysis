---
ver: rpa2
title: Empirical Evaluation of Progressive Coding for Sparse Autoencoders
arxiv_id: '2505.00190'
source_url: https://arxiv.org/abs/2505.00190
tags:
- saes
- features
- loss
- matryoshka
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the computational challenge of training and
  using sparse autoencoders (SAEs) of different sizes for neural network interpretability.
  The authors explore two methods for creating progressive SAEs that allow flexible
  reconstruction at varying granularities: Matryoshka SAEs that jointly train nested
  representations with shared weights, and dictionary permutation of pretrained SAEs
  based on feature importance.'
---

# Empirical Evaluation of Progressive Coding for Sparse Autoencoders

## Quick Facts
- arXiv ID: 2505.00190
- Source URL: https://arxiv.org/abs/2505.00190
- Authors: Hans Peter; Anders Søgaard
- Reference count: 15
- Key outcome: Matryoshka SAEs outperform both baseline SAEs and permuted versions across multiple metrics including reconstruction loss, recaptured language modeling loss, and representational similarity, though permuted vanilla SAEs show better interpretability scores.

## Executive Summary
This paper addresses the computational challenge of training and using sparse autoencoders (SAEs) of different sizes for neural network interpretability. The authors explore two methods for creating progressive SAEs that allow flexible reconstruction at varying granularities: Matryoshka SAEs that jointly train nested representations with shared weights, and dictionary permutation of pretrained SAEs based on feature importance. They demonstrate that dictionary importance follows a power law across different model sizes, enabling effective feature prioritization. Matryoshka SAEs outperform both baseline SAEs and permuted versions across multiple metrics including reconstruction loss, recaptured language modeling loss, and representational similarity. However, the permuted vanilla SAEs show better interpretability scores. The paper also presents scaling laws for progressive SAEs and discusses limitations including feature splitting at larger granularities and computational inefficiencies in current implementations.

## Method Summary
The paper presents two approaches to create progressive sparse autoencoders that enable flexible reconstruction at varying granularities. The first method involves training Matryoshka SAEs that jointly optimize multiple nested representations with shared encoder/decoder weights, allowing progressive coding through subset selection. The second method permutes features in pretrained SAEs based on their importance (measured by E[activation²]) without retraining, leveraging the permutation invariance of SAE architectures. Both methods rely on the observation that feature importance follows a power law distribution, enabling effective prioritization. The authors evaluate these approaches on Gemma-2-2b layer 2 activations using metrics including FVU (normalized reconstruction loss), recaptured LLM loss, representational similarity analysis (RSA), and interpretability scores.

## Key Results
- Matryoshka SAEs exhibit lower reconstruction loss and recaptured language modeling loss, as well as higher representational similarity compared to baseline SAEs and permuted versions
- Feature importance in vanilla SAEs follows a power law distribution (exponents -0.54 to -1.27, R² values between 0.916 and 0.922), enabling effective subset selection
- Pruned vanilla SAEs (via permutation) are more interpretable than Matryoshka SAEs, despite worse reconstruction performance
- Feature splitting causes performance degradation when selecting low-granularity subsets from large SAEs, with 65K SAE underperforming native 16K SAE when both use G=16K

## Why This Works (Mechanism)

### Mechanism 1: Dictionary Power Law Enables Feature Prioritization
The paper shows that feature importance in pretrained SAEs follows a power law distribution, enabling efficient subset selection for progressive coding. The eigenvalues of the decoder covariance matrix, mean squared activations E[activation²], and activation frequency all decay according to power laws (exponents -0.54 to -1.27). This hierarchical structure means a small subset of features captures most variance, so sorting features by importance and selecting the first G yields graceful degradation. The core assumption is that feature importance rankings transfer across granularity levels; the relative importance ordering remains stable when selecting subsets.

### Mechanism 2: Matryoshka SAEs Learn Nested Representations via Joint Optimization
Jointly training multiple granularity levels with shared encoder/decoder weights produces better progressive coders than post-hoc permutation of pretrained SAEs. The loss function combines reconstruction losses across all granularities M = {m₁, ..., mₖ} with weights cₘ. Since z₁:ₘ₁ ⊆ z₁:ₘ₂ ⊆ ... ⊆ z₁:ₘₖ, encoding is computed once and amortized. The model learns to place high-importance features in early dimensions because all granularities are optimized simultaneously. The core assumption is that shared weights don't create destructive interference between granularity-specific objectives; the encoder can satisfy nested reconstruction requirements.

### Mechanism 3: Permutation Invariance Permits Post-Hoc Progressive Coding
Pretrained SAEs can be converted to progressive coders by permuting features based on E[activation²], without retraining. SAE features are conditionally independent given the input—each activation zⱼ depends only on its encoder row and bias. Permuting latent dimensions (WEnc Pπ, Pπ⁻¹ WDec) produces identical reconstructions. Sorting by E[activation²] prioritizes high-variance features, enabling subset selection at inference. The core assumption is that E[activation²] is a reliable proxy for downstream functional importance; high-activation features correlate with model performance preservation.

## Foundational Learning

- **Superposition Hypothesis**: Neural networks represent more features than neurons via approximately orthogonal basis vectors, explaining why SAEs need overcomplete dictionaries. Quick check: Can you explain why neural networks might need N >> D basis vectors, and what the Johnson-Lindenstrauss lemma guarantees about approximate orthogonality?

- **TopK Activation Function**: The paper exclusively uses TopK, which fixes sparsity by zeroing all but the K largest activations. Quick check: Given a TopK SAE with dictionary size N=65,536 and K=256, what is the effective sparsity ratio, and how does this change if you select only the first G=16,384 features?

- **Representational Similarity Analysis (RSA)**: RSA bridges reconstruction loss and recaptured LLM loss by measuring second-order isometry between original and reconstructed activations. Quick check: Why might FVU and recaptured LLM loss diverge, and what does RSA correlation (~0.8 in this paper) tell you about their relationship?

## Architecture Onboarding

- **Component map**: Extract activations from target layer → Center via Bcenter, encode to z using TopK → For progressive inference: truncate z to z₁:G, decode using WDec[1:G, :] → Evaluate via FVU, recaptured CE loss, RSA

- **Critical path**: 1) Extract activations from target layer (e.g., Gemma-2-2b layer 2 residual stream) 2) Center via Bcenter, encode to z using TopK 3) For progressive inference: truncate z to z₁:G, decode using WDec[1:G, :] 4) Evaluate via FVU, recaptured CE loss, RSA

- **Design tradeoffs**: Matryoshka vs. Permutation: Matryoshka yields better reconstruction (lower FVU, higher recaptured loss) but lower interpretability (simulation correlation 0.57-0.74 vs. higher for permuted baselines). Sampled vs. Fixed granularities: Sampling mᵢ ~ U(1, N) during training improves progressive coding but adds complexity. Granularity ratio G/N: Performance degrades at low G/N due to feature splitting—permuted 65K SAE underperforms 32K SAE when both use G=16K.

- **Failure signatures**: Dead features: High k_aux values indicate dead features; mitigate with auxiliary loss (scale 1/32). Feature splitting artifacts: In Matryoshka, stepped activation patterns at granularity boundaries (Fig. 17) may indicate suboptimal nesting. Interpretability drop: Innermost granularities (e.g., 16K) more interpretable than outermost (e.g., 65K) in Matryoshka—suggests features aren't uniformly distributed.

- **First 3 experiments**: 1) Power law validation: On your target model, compute E[activation²] across 10⁵ tokens; fit log-log regression to confirm power law (R² > 0.85) before attempting permutation-based progressive coding. 2) Baseline comparison at matched sparsity: Train a 32K TopK SAE and a 65K Matryoshka SAE with M={16K, 32K, 65K}. Compare FVU and recaptured CE loss at G=16K and G=32K, keeping K/G constant. 3) Interpretability probe: Using sae-auto-interp or equivalent, compute simulation scores for Matryoshka vs. permuted SAEs. Focus on whether outermost granularities (indices 32K-65K) show degraded correlation compared to innermost (0-16K).

## Open Questions the Paper Calls Out

- **Can efficient methods be developed to recombine or "reverse" feature-splitting during distillation from large to small SAEs?** The paper notes that feature splitting causes progressive coding performance to degrade as the granularity-to-model-size ratio decreases, since selecting only the most important split features fails to capture complete functionality. Future research could focus on developing efficient methods to recombine or "reverse" this feature-splitting during the distillation process, potentially through feature clustering or adaptive merging strategies.

- **Do the observed power law relationships and Matryoshka SAE benefits hold at much larger scales (tens of millions of features)?** The paper acknowledges that "our methods remain to be validated at larger scales" and that "our experiments were conducted on relatively modest-sized SAEs compared to recent work, scaling to tens of millions of features." Current experiments only tested up to 65k features; scaling behavior may differ qualitatively at production scales.

- **What causes the interpretability-reconstruction tradeoff between Matryoshka SAEs and permuted vanilla SAEs, and can it be bridged?** The paper documents but does not explain why jointly training nested representations (Matryoshka) improves reconstruction while reducing interpretability scores relative to simply reordering pretrained features. The tradeoff between reconstruction quality and interpretability isn't fully characterized—the paper observes lower interpretability for Matryoshka but doesn't explain why this occurs or whether it's inherent to the joint optimization approach.

## Limitations

- The power law analysis relies on activation statistics from a single model (Gemma-2-2b), limiting generalizability across architectures and potentially not holding for different model families or training objectives.
- Progressive coding framework faces fundamental tradeoffs: Matryoshka SAEs achieve superior reconstruction but reduced interpretability, while permuted vanilla SAEs maintain interpretability but underperform on reconstruction metrics.
- Feature splitting is identified as a critical failure mode but isn't systematically analyzed—the paper doesn't establish when this becomes problematic or provide systematic mitigation strategies beyond noting performance degradation at low G/N ratios.

## Confidence

**High confidence**: The Matryoshka SAE implementation details and reconstruction results are well-specified and reproducible. The power law distribution of feature importance (exponents -0.54 to -1.27, R² > 0.9) is directly measurable from decoder covariance matrices and activation statistics.

**Medium confidence**: The claim that permutation-based progressive coding works "without retraining" assumes stable feature importance rankings across inference conditions. While E[activation²] is measurable, the paper doesn't validate whether this remains predictive under distribution shifts or different prompting strategies.

**Low confidence**: The interpretability comparisons between Matryoshka and permuted SAEs rely on simulation correlation scores (0.57-0.74 range) that measure feature functionality but not human interpretability. The tradeoff between reconstruction quality and interpretability isn't fully characterized—the paper observes lower interpretability for Matryoshka but doesn't explain why this occurs or whether it's inherent to the joint optimization approach.

## Next Checks

1. **Cross-model power law validation**: Extract activation statistics from at least two additional models (different sizes, architectures, or training objectives) and verify that feature importance follows power law distributions with comparable exponents. Test whether the same feature importance ranking generalizes across models.

2. **Feature splitting threshold analysis**: Systematically measure the performance gap between 65K→16K progressive coding versus native 16K SAE as G/N decreases. Identify the critical G/N ratio where feature splitting artifacts dominate and evaluate whether alternative feature selection criteria (beyond E[activation²]) can mitigate this degradation.

3. **Interpretability mechanism probe**: Conduct ablation studies on Matryoshka training to isolate why innermost granularities are more interpretable than outermost. Test whether modifying the loss weighting scheme (c_m parameters) or adding interpretability-specific regularization can preserve the reconstruction advantages while improving functional interpretability scores.