---
ver: rpa2
title: Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations
arxiv_id: '2509.07311'
source_url: https://arxiv.org/abs/2509.07311
tags:
- data
- training
- knowledge
- unfamiliar
- familiar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of effective training data selection
  for supervised fine-tuning (SFT) of large language models (LLMs), where increasing
  data volume does not guarantee performance gains and prompt-based knowledge detection
  methods are sensitive to variations. The proposed method, Knowledge Analysis via
  Model Internal Representations (KAMIR), analyzes data by computing similarity scores
  between hidden states at each layer and the final output vector, forming an awareness
  vector that captures the model's familiarity with the input.
---

# Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations

## Quick Facts
- arXiv ID: 2509.07311
- Source URL: https://arxiv.org/abs/2509.07311
- Reference count: 18
- Primary result: KAMIR achieves better SFT performance by training on unfamiliar data detected through internal representation similarity

## Executive Summary
This study addresses the challenge of effective training data selection for supervised fine-tuning (SFT) of large language models (LLMs), where increasing data volume does not guarantee performance gains and prompt-based knowledge detection methods are sensitive to variations. The proposed method, Knowledge Analysis via Model Internal Representations (KAMIR), analyzes data by computing similarity scores between hidden states at each layer and the final output vector, forming an awareness vector that captures the model's familiarity with the input. These awareness vectors are used to train a simple classifier distinguishing familiar from unfamiliar data. Experiments across machine reading comprehension, multiple-choice QA, and summarization tasks demonstrate that training with unfamiliar data consistently outperforms familiar data, with improvements linked to reduced loss, increased prediction entropy, and higher gradient norms, indicating enhanced generalization. This effect was most pronounced in tasks with concise, unambiguous answers. KAMIR offers a prompt-free approach to intrinsic knowledge detection, enabling effective training data selection even with small datasets and simple architectures.

## Method Summary
KAMIR constructs awareness vectors by computing cosine similarity between each layer's hidden state and the final hidden state at the last token position, producing a K-dimensional signature vector for each input. A simple MLP classifier is trained on labeled familiar/unfamiliar data (typically using temporal cutoffs) to distinguish between these awareness vectors. The classifier then filters target SFT datasets, selecting only data classified as unfamiliar for fine-tuning with LoRA adapters. This approach requires no prompt engineering and can work with small datasets, as demonstrated across multiple NLP tasks including MRC, MCQA, and summarization.

## Key Results
- Training on unfamiliar data consistently outperformed training on familiar data across multiple tasks
- Improvements were most pronounced for tasks with concise, unambiguous answers (MRC, MCQA)
- Benefits linked to higher prediction entropy, larger gradient norms, and reduced loss during training
- Simple MLP classifiers sufficed for awareness vector classification, even with limited training data

## Why This Works (Mechanism)

### Mechanism 1: Layer-wise Representation Convergence as Familiarity Signal
- **Claim:** Computing cosine similarity between intermediate layer hidden states and the final hidden state produces a signature vector ("awareness vector") that correlates with whether the model has encountered similar patterns during pretraining.
- **Mechanism:** When processing familiar inputs, the model's intermediate representations converge toward the final representation more uniformly across layers. For unfamiliar inputs, the evolution pattern diverges, producing measurably different awareness vectors that can be classified with a simple MLP.
- **Core assumption:** The final hidden state encapsulates the model's "full interpretation," and similarity to it at each layer reflects processing confidence/familiarity.
- **Evidence anchors:**
  - [abstract] "KAMIR computes similarities between the hidden states of each layer (block) and the final hidden states for a given input to assess the data."
  - [Section 3.1] "We compute the similarity(S) between the hidden states of each intermediate layer and the last hidden state of the final layer. Cosine similarity is employed for this purpose."
  - [Section 3.2 / Figure 2] "the magnitude of activation differs significantly depending on whether the data are familiar or unfamiliar... the clusters are sufficiently distinct to allow meaningful classification"
  - [corpus] Limited direct evidence; neighbor papers probe internal representations but don't validate familiarity-similarity relationships.
- **Break condition:** If awareness vectors don't cluster distinctly for familiar vs. unfamiliar data in your domain, the classifier will fail. Verify with t-SNE visualization before committing to this approach.

### Mechanism 2: Unfamiliar Data Drives Generalization via Higher Entropy and Gradient Signals
- **Claim:** Training on unfamiliar data produces better generalization because it maintains higher prediction entropy and larger gradient norms, preventing overconfident convergence to narrow solutions.
- **Mechanism:** Unfamiliar data forces the model to explore the parameter space more actively rather than reinforcing existing representations. Higher entropy indicates the model isn't collapsing onto confident-but-wrong predictions; larger gradients indicate more substantial parameter updates.
- **Core assumption:** Generalization benefits from maintaining uncertainty during training rather than achieving rapid, confident convergence.
- **Evidence anchors:**
  - [abstract] "improvements linked to reduced loss, increased prediction entropy, and higher gradient norms, indicating enhanced generalization"
  - [Section 4.3 / Table 2] "unfamiliar data maintained loss values that were generally lower or comparable... prediction distributions for unfamiliar data exhibited relatively higher entropy... gradient norms were generally higher"
  - [corpus] No direct validation from neighbors; mechanism is empirically observed but theoretically underexplored.
- **Break condition:** If your task rewards precise extraction over diverse generation (e.g., CNN/DailyMail extractive summarization), unfamiliar data may hurt performance by increasing distributional mismatch.

### Mechanism 3: Task Structure Moderates Unfamiliar Data Benefits
- **Claim:** The benefit of unfamiliar data is strongest for tasks with concise, unambiguous answers and weakest or negative for tasks with high output variability or extractive references.
- **Mechanism:** When answers are short spans (MRC) or single selections (MCQA), higher entropy and exploration help locate correct answers in novel contexts. When multiple valid outputs exist (summarization) or reference sentences are fixed (extractive tasks), exploration increases variance without improving alignment.
- **Core assumption:** Task evaluation methodology determines whether generalization benefits translate to measured performance.
- **Evidence anchors:**
  - [Section 4.3] "Its impact was most pronounced in tasks with concise, unambiguous answers (MRC, MCQA), limited in generation based summarization tasks... even detrimental for long, extractive summaries (CNN/DailyMail)"
  - [Section 4.2] On XLSum: "more than 80% of outcomes resulting in ties... reflects the inherently high variability of valid outputs"
  - [corpus] No neighbor papers address task-specific data selection effects.
- **Break condition:** Before applying unfamiliar-data selection, characterize your task's answer structure. If references are extractive and long, or if evaluation penalizes deviation from specific outputs, unfamiliar data selection may backfire.

## Foundational Learning

- **Cosine Similarity for Representation Comparison**
  - **Why needed here:** The entire KAMIR method depends on computing similarity between vectors. Understanding why cosine (angle-based) is preferred over Euclidean (magnitude-based) for hidden states is critical.
  - **Quick check question:** If two hidden states have the same direction but different magnitudes, what would cosine similarity return? (Answer: 1.0, indicating maximum similarity regardless of scale.)

- **Logit Lens / Layer-wise Interpretation**
  - **Why needed here:** KAMIR builds on the intuition that each layer's hidden state represents an intermediate "interpretation" of the input, with the final layer being the complete interpretation.
  - **Quick check question:** Why might earlier layers show lower similarity to the final hidden state than middle layers? (Assumption: Earlier layers encode syntax/surface features; later layers encode semantics/task-relevant features.)

- **Entropy as Uncertainty Quantification**
  - **Why needed here:** The paper uses entropy to explain why unfamiliar data helps—higher entropy means the model is less confident, which prevents overfitting.
  - **Quick check question:** A model outputs [0.9, 0.05, 0.05] vs. [0.4, 0.3, 0.3]. Which has higher entropy and what does this imply about model uncertainty?

## Architecture Onboarding

- **Component map:** Hidden State Extractor -> Awareness Vector Builder -> Data Awareness Classifier -> Data Selection Filter

- **Critical path:**
  1. Define familiarity labels (temporal cutoff based on model release date, or domain knowledge).
  2. Extract awareness vectors from labeled familiar/unfamiliar data.
  3. Train classifier; validate separation via t-SNE.
  4. Apply to target dataset; train only on unfamiliar subset.
  5. Compare against random baseline (paper shows random often underperforms unfamiliar but outperforms familiar).

- **Design tradeoffs:**
  - **Small vs. large classifier:** Paper uses simple MLP with small datasets successfully—over-engineering may overfit.
  - **Token selection:** Only final token's hidden states are used; this captures full context but may miss entity-specific familiarity signals in long inputs.
  - **Temporal vs. semantic unfamiliarity:** Paper uses temporal cutoff (pre/post model release), but semantic unfamiliarity (domain shift) may be more relevant for some applications. This is not validated in the paper.

- **Failure signatures:**
  - Classifier accuracy near 50%: Awareness vectors not separating; reconsider familiarity labeling or check for data contamination.
  - Unfamiliar-trained model underperforms random baseline: Task likely has extractive or low-variance answer structure (see CNN/DailyMail pattern).
  - High loss divergence on unfamiliar data: Model may be encountering out-of-distribution samples beyond its capacity; consider curriculum mixing.

- **First 3 experiments:**
  1. **Reproduction check:** On a small MCQA dataset (e.g., SciQ subset), extract awareness vectors for known vs. synthetic-unfamiliar data; verify t-SNE separation replicates Figure 2(B).
  2. **Ablation on classifier complexity:** Compare linear classifier vs. 2-layer MLP vs. larger network; paper claims simple is sufficient—test this claim.
  3. **Task boundary test:** Apply KAMIR to one MRC task (expected gain) and one extractive summarization task (expected neutral/negative); verify task-dependent effects replicate before scaling.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can integrating awareness-based sampling and clustering with KAMIR significantly improve SFT convergence speed compared to binary familiar/unfamiliar classification?
- Basis in paper: [explicit] The conclusion states future work includes "integrating awareness-based sampling and clustering to develop more efficient SFT strategies."
- Why unresolved: The current study validates a binary classification approach, leaving potential efficiency gains from fine-grained data density analysis unexplored.
- What evidence would resolve it: Benchmarks comparing training curves of models using clustered KAMIR vectors versus the current binary selection method.

### Open Question 2
- Question: How can training methodologies be adapted to effectively leverage unfamiliar data for generative tasks like summarization, where current benefits are limited?
- Basis in paper: [explicit] The conclusion explicitly calls for "exploring evaluation and training methods to maximize the benefits of unfamiliar data in generative tasks."
- Why unresolved: KAMIR showed limited or negative impact on XLSum and CNN/DailyMail, suggesting standard SFT does not capitalize on the high entropy/gradients of unfamiliar data in these settings.
- What evidence would resolve it: Development of specialized loss functions that penalize distribution discrepancies in generative tasks while retaining the generalization benefits of unfamiliar data.

### Open Question 3
- Question: Why does training on "unfamiliar" data improve performance in extractive MRC (SQuAD) but degrade performance in extractive summarization (CNN/DailyMail)?
- Basis in paper: [inferred] The paper notes conflicting results between extractive tasks, attributing the CNN/DailyMail drop to "answer distribution discrepancies" caused by generative diversity, but does not empirically isolate this mechanism.
- Why unresolved: The paper lacks a controlled ablation to determine if the specific length or structure of CNN/DailyMail answers negates the generalization benefits seen in other extractive tasks.
- What evidence would resolve it: Ablation studies controlling for answer length and variability across both MRC and summarization datasets using the same base model.

## Limitations

- Classifier architecture details are underspecified, making exact reproduction difficult
- Temporal familiarity definitions may not capture true semantic novelty
- Task structure dependency limits applicability to extractive tasks requiring precise output matching

## Confidence

**High Confidence**: The awareness vector construction method (cosine similarity between intermediate and final hidden states) is technically sound and well-specified. The empirical observation that unfamiliar data maintains higher entropy and gradient norms during training is directly measurable and reproducible.

**Medium Confidence**: The claim that unfamiliar data consistently improves generalization across tasks has medium confidence due to strong task dependency effects. While statistically significant in some conditions, the mechanism linking higher entropy to better performance remains theoretically underexplored.

**Low Confidence**: The assertion that simple MLP classifiers are sufficient for awareness vector classification lacks validation. Without architectural specifications or ablation studies, this claim remains unsubstantiated and could significantly impact method effectiveness.

## Next Checks

1. **Classifier Architecture Sensitivity Test**: Systematically vary MLP depth (1-3 layers) and width (32-256 units) while measuring classification accuracy and downstream SFT performance on a held-out MCQA dataset. This would validate whether the "simple" classifier claim holds across architectural configurations.

2. **Semantic vs. Temporal Familiarity Validation**: Construct a controlled experiment where "unfamiliar" data is defined semantically (domain shift) rather than temporally. Compare KAMIR performance using temporal vs. semantic unfamiliarity definitions on tasks with known domain sensitivity (e.g., medical QA vs. general QA).

3. **Task Structure Boundary Analysis**: Test KAMIR across a gradient of task types from extractive (CNN/DailyMail) to abstractive (XLSum) summarization. Measure the correlation between answer reference length/variance and unfamiliar data benefit to establish clear boundaries for when KAMIR should be applied versus avoided.