---
ver: rpa2
title: Bridging the Semantic Gap for Categorical Data Clustering via Large Language
  Models
arxiv_id: '2601.01162'
source_url: https://arxiv.org/abs/2601.01162
tags:
- clustering
- semantic
- categorical
- data
- arise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of categorical data clustering,
  where the lack of inherent distance metrics between attribute values creates a semantic
  gap that obscures latent structures and degrades clustering quality. Existing methods
  rely on within-dataset co-occurrence patterns, which become unreliable with limited
  samples, leaving the semantic context underexplored.
---

# Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models

## Quick Facts
- arXiv ID: 2601.01162
- Source URL: https://arxiv.org/abs/2601.01162
- Reference count: 32
- Primary result: ARISE framework achieves 19-27% ARI gains over baselines by integrating LLM-generated semantic embeddings with identity-preserving features

## Executive Summary
This paper addresses the challenge of categorical data clustering where the lack of inherent distance metrics between attribute values creates a semantic gap that obscures latent structures and degrades clustering quality. Existing methods rely on within-dataset co-occurrence patterns, which become unreliable with limited samples, leaving the semantic context underexplored. The authors propose ARISE, a framework that integrates external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations. ARISE queries LLMs at the attribute-value level to generate descriptions, uses an attention-weighted encoding mechanism to emphasize informative tokens, and adaptively fuses these semantic embeddings with identity-preserving features. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts.

## Method Summary
ARISE addresses categorical clustering by integrating external semantic knowledge from LLMs. The framework queries LLMs once per unique attribute value using a structured prompt (definition, indicators, context, contrast) to generate descriptions. These descriptions are encoded using a transformer model with attention-weighted pooling that emphasizes high-activation tokens. The semantic embeddings are then adaptively fused with one-hot identity features via a weight α selected by maximizing Silhouette Score. The final representation is clustered using k-Means. The approach is evaluated on eight UCI benchmark datasets with varying sizes, showing consistent improvements over seven representative baselines.

## Key Results
- ARISE achieves 19-27% ARI gains across all eight evaluated datasets
- Framework shows particular strength on small-scale datasets (N=101-286)
- Ablation study confirms each component contributes: w/o LLM drops ARI from 0.402 to 0.217, w/o attention drops to 0.387
- Performance is consistent across three different LLM backends (GPT-5.1, Claude, DeepSeek, Gemini)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: External semantic knowledge from LLMs compensates for insufficient co-occurrence statistics in small-scale categorical datasets.
- Mechanism: LLMs generate structured descriptions for each unique attribute value, capturing latent relationships (e.g., ordinality, similarity) that sparse within-dataset co-occurrence cannot reliably infer.
- Core assumption: LLM pretraining corpora contain relevant semantic knowledge for the categorical values in the target domain.
- Evidence anchors:
  - [abstract]: "existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited"
  - [section 3.1]: "value-level querying strategy is adopted, processing the unique vocabulary set V rather than the full dataset. This approach guarantees consistency, as identical values always receive identical descriptions"
- Break condition: Domain-specific identifiers with no general semantic associations (e.g., astronomical codes in Solar Flare) yield marginal or no improvement.

### Mechanism 2
- Claim: Attention-weighted encoding emphasizes discriminative keywords in LLM-generated descriptions, improving embedding quality over uniform pooling.
- Mechanism: Token importance is measured via mean activation s_t = (1/d) Σ h_t,k, producing attention-weighted embeddings e_v = Σ a_t · h_t where a_t ∝ exp(s_t). This parameter-free weighting concentrates on high-activation tokens.
- Core assumption: High mean activation correlates with discriminative semantic content for clustering.
- Evidence anchors:
  - [section 3.2]: "When scores are uniform, the mechanism reduces to mean pooling; when one score dominates, the weighting concentrates accordingly"
  - [table 4]: Ablation shows w/o Attn (CLS pooling) achieves ARI=0.387 vs. ARISE=0.402 on average
- Break condition: When LLM descriptions contain limited semantic variation (specialized scientific/medical terms), attention weighting shows comparable or slightly lower performance.

### Mechanism 3
- Claim: Adaptive fusion of semantic embeddings with identity-preserving features prevents representation collapse while retaining semantic benefits.
- Mechanism: Fused representation Z_α = (1-α)Ê_anc ⊕ αÊ_sem, where α is selected by maximizing Silhouette Score over candidates. One-hot encoding ensures distinct values remain linearly separable.
- Core assumption: Neither pure semantic nor pure identity representations are optimal; the ideal balance varies by dataset.
- Evidence anchors:
  - [section 3.3]: "The orthogonal nature of one-hot encoding ensures that categorically distinct values remain linearly separable regardless of semantic similarity"
  - [table 4]: w/o LLM (identity-only) achieves ARI=0.217; adding semantics nearly doubles performance
- Break condition: When semantic and identity views conflict sharply (e.g., values semantically similar but should remain distinct for clustering), fusion may underperform pure identity.

## Foundational Learning

- Concept: Categorical semantic gap
  - Why needed here: Categorical values lack inherent ordering or distance; treating all as equidistant (d=1) obscures latent structure.
  - Quick check question: Can you explain why "oval" and "round" should have smaller distance than "oval" and "square" in a shape-clustering task?

- Concept: Co-occurrence sparsity in small samples
  - Why needed here: Statistical inference fails when N ≪ |V|×M; ARISE targets datasets with 101–8,124 instances where this is acute.
  - Quick check question: If a dataset has N=150 samples across M=18 attributes with 59 unique values, why might co-occurrence-based distance learning fail?

- Concept: Silhouette Score for unsupervised selection
  - Why needed here: Without labels, α must be selected via internal validation; Silhouette measures cluster cohesion vs. separation.
  - Quick check question: Why is Silhouette Score preferable to within-cluster sum-of-squares for selecting α in this fusion context?

## Architecture Onboarding

- Component map:
  1. **Semantic Representation Enrichment** (offline): Query LLM once per unique value → structured descriptions T_v
  2. **Attention-Weighted Encoding** (offline): Transformer encoder E → token activations → weighted embeddings e_v
  3. **Identity Encoding** (offline): One-hot vectors for each attribute value
  4. **Adaptive Fusion** (online): Grid search over α ∈ G → select α* via Silhouette → k-Means on Z_α*

- Critical path: LLM query cost dominates offline; grid search over α dominates online. Value-level querying amortizes LLM cost to O(|V|) rather than O(N×M).

- Design tradeoffs:
  - Concatenation (chosen) vs. summation: Concatenation preserves full capacity (D dimensions) but increases dimensionality; summation loses view-specific information.
  - One-hot (chosen) vs. learnable embeddings: One-hot is parameter-free and prevents overfitting on small data; learnable may capture more but risks overfitting.
  - Grid search (chosen) vs. learned α: Grid search is interpretable and stable; learned α would require differentiable Silhouette or proxy.

- Failure signatures:
  - Near-zero improvement on datasets with domain-specific jargon (e.g., Solar Flare astronomical codes)
  - High variance across LLM backends suggests noisy descriptions—check attention weight distribution
  - α* → 0 indicates semantic embeddings are not discriminative; α* → 1 indicates identity features are redundant

- First 3 experiments:
  1. **Baseline sanity check**: Run OHK (one-hot + k-means) on all 8 datasets to establish lower bounds; confirm your ARI numbers match table trends.
  2. **Ablation by component**: Disable attention-weighting (use CLS pooling), then disable LLM entirely; verify performance drops match table 4 (w/o LLM: ~0.22, w/o Attn: ~0.39).
  3. **α sensitivity analysis**: For one small dataset (e.g., Breast Cancer, N=286), plot clustering metric vs. α ∈ {0.0, 0.1, ..., 1.0}; confirm Silhouette-selected α* aligns with peak performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ARISE framework be effectively adapted for mixed-type data containing both categorical and numerical attributes?
- Basis in paper: [explicit] The conclusion explicitly states, "The next avenue of this work could be extending to mixed-type data."
- Why unresolved: The current architecture focuses exclusively on discrete categorical values, utilizing semantic embeddings to construct a metric space. Numerical attributes possess inherent metrics that may require a different fusion strategy or normalization technique to combine effectively with LLM-based semantic embeddings.
- What evidence would resolve it: Successful application of the framework to benchmark mixed-type datasets (e.g., UCI Heart Disease) with performance metrics (ARI, NMI) comparable to or exceeding current mixed-data specific baselines.

### Open Question 2
- Question: Can prompt tuning or domain-specific fine-tuning of LLMs improve clustering performance in specialized fields where general semantic knowledge is weak?
- Basis in paper: [explicit] The conclusion identifies "prompt tuning of LLMs for domain- and task-specific adaptation" as a future avenue. [inferred] Results on the Solar Flare dataset (Page 10-11) showed that SigDT occasionally outperformed ARISE, suggesting that general LLM semantics may struggle with specialized astronomical identifiers.
- Why unresolved: The current work utilizes general-purpose LLMs (GPT, Claude, etc.) with a fixed structured prompt. It is untested whether optimizing the prompt or model for specific domain jargon yields significant gains over the general "define/indicate/context/contrast" structure.
- What evidence would resolve it: An ablation study on specialized datasets (e.g., Bioinformatics or Astronomy) comparing the default prompting strategy against domain-adapted prompts or fine-tuned models.

### Open Question 3
- Question: Does the global attribute-value querying strategy fail to capture context-dependent polysemy where the same value has different meanings across different rows?
- Basis in paper: [inferred] The method queries LLMs based on the unique vocabulary set V (Page 5, Prop 1) to ensure consistency and reduce cost. This implies that identical values (e.g., "Apple") receive identical embeddings regardless of the row context (e.g., "Fruit" vs. "Tech Company").
- Why unresolved: The paper assumes a stable semantic meaning for each value. If a dataset contains homographs (values with multiple meanings) where the meaning depends on other attributes in the row, the global embedding approach would conflate these distinct concepts, potentially degrading cluster separation.
- What evidence would resolve it: Evaluation on synthetic or real-world datasets containing high ambiguity/homographs, comparing the current global encoding against a context-aware (instance-level) encoding baseline.

## Limitations

- Performance tightly coupled to LLM description quality, which is not guaranteed for domain-specific identifiers
- Attention-weighting mechanism assumes mean activation correlates with discriminative content without empirical validation
- Adaptive fusion introduces computational overhead through grid search that scales poorly with dimensionality

## Confidence

**High confidence** in the core claim that external semantic knowledge improves categorical clustering on small datasets, supported by consistent 19-27% ARI gains across all eight benchmarks. **Medium confidence** in the attention-weighted encoding mechanism, as ablation results show improvement but lack direct comparison to alternative pooling strategies. **Low confidence** in the adaptive fusion approach's optimality, given that the grid search is heuristic and no comparison is made to learned fusion parameters.

## Next Checks

1. **Domain-specific ablation**: Systematically test ARISE on datasets with increasing proportions of domain-specific jargon (e.g., medical codes, technical identifiers) to quantify the semantic knowledge requirement.

2. **Attention mechanism validation**: Compare the mean-activation attention weighting against alternative token importance measures (e.g., CLS token, max activation, learned attention) on a subset of datasets to establish whether the chosen method is optimal.

3. **Fusion strategy comparison**: Replace the grid search over α with a learned fusion parameter optimized via gradient descent, and compare clustering quality and computational efficiency against the current adaptive approach.