---
ver: rpa2
title: 'MaskSQL: Safeguarding Privacy for LLM-Based Text-to-SQL via Abstraction'
arxiv_id: '2509.23459'
source_url: https://arxiv.org/abs/2509.23459
tags:
- schema
- privacy
- query
- text-to-sql
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MaskSQL is a privacy-preserving text-to-SQL framework that uses
  abstraction to mask sensitive information in LLM prompts while retaining essential
  mapping details. It addresses the privacy-utility tradeoff between untrusted LLMs
  and trusted but less capable SLMs by abstracting schema elements and values into
  symbols, generating SQL via LLM, and reconstructing the query locally.
---

# MaskSQL: Safeguarding Privacy for LLM-Based Text-to-SQL via Abstraction

## Quick Facts
- arXiv ID: 2509.23459
- Source URL: https://arxiv.org/abs/2509.23459
- Reference count: 40
- Primary result: Achieves 55.66% execution accuracy on complex BIRD benchmark subset, 5 points higher than next best trusted method

## Executive Summary
MaskSQL introduces a privacy-preserving text-to-SQL framework that uses abstraction to mask sensitive information in LLM prompts while retaining essential SQL generation capability. The approach employs local SLMs to identify and replace sensitive schema elements and values with abstract symbols, sends the sanitized prompt to an untrusted remote LLM for SQL generation, then reconstructs the concrete query locally using deterministic mapping. MaskSQL achieves strong privacy-utility balance, outperforming leading SLM-based models while supporting flexible privacy policies that allow users to balance abstraction and utility.

## Method Summary
MaskSQL implements a hybrid pipeline where a local SLM performs schema linking and value detection to identify sensitive tokens in the natural language question and database schema. These tokens are replaced with abstract symbols (T1, C1, V1) using a bijective mapping that preserves structural relationships needed for SQL generation. The abstracted prompt is sent to an untrusted remote LLM for SQL generation, which produces abstract SQL that references only these symbols. The local system then reconstructs the concrete SQL using deterministic symbol lookup and applies final self-correction based on execution results. The framework supports flexible privacy policies allowing different levels of abstraction from full masking to category-based protection.

## Key Results
- Achieves 55.66% execution accuracy on complex BIRD benchmark subset
- Outperforms next best trusted method by 5 percentage points
- Demonstrates 61.36% masking recall and 75.47% re-identification resistance
- Shows accuracy improves under less restrictive privacy policies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Abstraction preserves SQL generation capability while masking sensitive schema and value information.
- Mechanism: Replace sensitive tokens (table names, column names, literal values) with abstract symbols (T1, C1, V1) using a bijective mapping. The mapping retains structural relationships needed for SQL logic while obscuring semantic meaning from the remote LLM.
- Core assumption: SQL query structure depends on entity relationships, not specific token names. The LLM can reason over abstract symbols as effectively as concrete ones for syntax generation.
- Evidence anchors:
  - [abstract]: "abstraction retains essential information while discarding unnecessary details, striking an effective privacy–utility balance for the text-to-SQL task"
  - [section 5]: "Specific names or values are not crucial for the structure and syntax of the generated query. Thus, table names, column names, and literal values can be abstracted away in the prompt and later restored by using a bijective mapping"
  - [corpus]: LitE-SQL (arXiv:2510.09014) achieves strong text-to-SQL performance with schema linking, supporting the importance of structural relationships over token-level semantics
- Break condition: If the LLM requires semantic understanding of column meanings to determine appropriate joins or aggregations, abstraction will fail. Complex domain logic embedded in column names may not transfer.

### Mechanism 2
- Claim: Local SLMs can perform accurate schema linking and value detection for privacy-sensitive operations.
- Mechanism: A local SLM (Qwen-2.5-7B-Instruct) identifies tokens in the natural language question that map to database schema elements and literal values. This enables precise abstraction without exposing schema information to remote services.
- Core assumption: SLMs achieve sufficient accuracy on schema linking tasks despite lower general reasoning capability. Prior work supports comparable SLM-LLM performance on this specific subtask.
- Evidence anchors:
  - [section 5.1]: "prior work shows that SLMs achieve accuracy comparable to LLMs for schema linking tasks, making them sufficient for this stage"
  - [section 6]: MaskSQL achieves 55.66% execution accuracy using local SLM for linking, only 5 points below the untrusted baseline with full schema exposure
  - [corpus]: X-SQL (arXiv:2509.05899) emphasizes the importance of schema linking quality for text-to-SQL, suggesting this is a well-studied subtask where specialized models can excel
- Break condition: If schema linking errors compound through the pipeline, reconstruction will fail. The ablation study shows removing value linking drops execution accuracy by ~3 points and masking recall by ~13%.

### Mechanism 3
- Claim: Deterministic reconstruction with local correction outperforms LLM-based unmasking.
- Mechanism: After receiving the abstracted SQL from the remote LLM, apply a deterministic symbol lookup table to restore concrete values. Then use a local SLM to correct execution errors based on actual query results.
- Core assumption: The bijective mapping is complete and unambiguous. The abstract SQL structure from the LLM correctly references all abstract symbols used in the prompt.
- Evidence anchors:
  - [section 5.3]: "Using the symbol lookup table created during abstraction, all abstract symbols are replaced with their corresponding concrete values. The result is an executable SQL query free of abstract identifiers"
  - [appendix C, ablation study]: Replacing deterministic unmasking with SLM prompting reduces execution accuracy by ~21% (from 55.66% to 34.33%)
  - [corpus]: LegalGuardian (arXiv:2501.10915) uses NER for PII detection in legal contexts, supporting that sensitive token identification is tractable but error-prone without careful design
- Break condition: If the LLM generates abstract SQL with symbols not in the lookup table (hallucinated references), reconstruction will fail. The self-correction prompts in appendices F.2-F.3 attempt to mitigate this.

## Foundational Learning

- **Text-to-SQL Task Formulation**:
  - Why needed here: Understanding that the task maps (natural language question Q, database schema S) → executable SQL query Y is foundational to seeing why abstraction preserves utility.
  - Quick check question: Given abstract question "How many T1 with C3 as V2?" and abstract schema showing T1.C3 as a foreign key, can you sketch the join structure needed?

- **SLM vs LLM Capability Gap**:
  - Why needed here: MaskSQL's hybrid design depends on knowing which subtasks SLMs can handle (schema linking) versus where LLMs excel (complex SQL reasoning with nested queries).
  - Quick check question: Why would a 7B parameter model struggle with nested subqueries but succeed at mapping "patient names" to a `patients.name` column?

- **Privacy-Utility Tradeoff in Prompt Sanitization**:
  - Why needed here: Abstraction differs from redaction (removes content) and generalization (broadens tokens). Understanding this distinction clarifies why MaskSQL retains SQL generation capability.
  - Quick check question: If you generalized "HIV status" to "medical condition," how might the LLM's join logic change compared to abstracting it as "C3"?

## Architecture Onboarding

- **Component map**:
  1. Schema Ranking & Filtering (local): Cross-encoder scores schema relevance, retains top-k tables/columns
  2. Value & Reference Linking (local, SLM): Identifies tokens in Q that map to schema elements or literal values
  3. Abstraction Engine (local): Generates Q', S' using symbol substitution, stores bijective mapping
  4. SQL Generation (remote, LLM): Produces abstracted SQL Y' from (Q', S')
  5. LLM Self-Correction (remote): Reviews Y' for errors against abstract schema
  6. SQL Reconstruction (local): Applies symbol lookup table to restore concrete SQL Y
  7. SLM Self-Correction (local): Executes Y, corrects based on execution results

- **Critical path**: Schema filtering → Value linking (determines what gets abstracted) → Abstraction (generates mapping) → LLM generation (creates abstract SQL) → Reconstruction (restores concrete SQL) → Local correction (fixes execution errors). Any failure in linking propagates through the entire pipeline.

- **Design tradeoffs**:
  - Full policy (ΨF) vs category-based policy (ΨC): ΨF abstracts all schema/values, achieving 75.47% re-identification resistance but 55.66% accuracy. ΨC abstracts only person names/locations/occupations, dropping re-identification by 4 points but gaining 7 points in accuracy.
  - Token efficiency: MaskSQL uses 6,114 tokens vs 24,812 for DIN-SQL-SLM, but the overhead comes from multiple linking/correction calls.
  - Deterministic vs learned reconstruction: Ablation shows deterministic lookup outperforms SLM unmasking by 21 points.

- **Failure signatures**:
  - Low masking recall (<60%): Value detection failing to identify literals in Q. Check the SLM's value identification prompts.
  - Re-identification score <70%: Context in remaining unmasked tokens is leaking information. Consider stricter policy or additional abstraction.
  - Execution accuracy <40% with high masking recall: Linking errors causing incorrect abstractions. Review schema linking accuracy separately.
  - Reconstruction failures with "column not found" errors: LLM hallucinated abstract symbols not in the lookup table. Review LLM self-correction effectiveness.

- **First 3 experiments**:
  1. Validate schema linking isolation: Run the local SLM schema linking on 50 examples from your target domain. Measure precision/recall against ground-truth mappings. If <80% precision, the abstraction will introduce noise that propagates to reconstruction.
  2. Measure abstraction leakage: For 20 representative queries, manually inspect Q' and S' to verify no sensitive tokens remain unmasked. Calculate actual masking recall against your policy definition. The paper reports 61.36% on ΨF, so expect similar if using full abstraction.
  3. Test reconstruction robustness: Generate abstract SQL with the remote LLM, then measure reconstruction success rate (valid SQL syntax + executable). The paper's ablation shows this is the most fragile component (21 point drop if using SLM instead of deterministic lookup), so validate your symbol table logic thoroughly before deploying.

## Open Questions the Paper Calls Out

- Can the abstraction-based approach used in MaskSQL be effectively generalized to other semantic tasks such as code generation and debugging?
  - Basis in paper: [explicit] The authors state that "Characterizing the class of tasks to which this approach applies will be the subject of future work," specifically mentioning code generation and debugging.
  - Why unresolved: The current framework and experiments are tailored specifically for text-to-SQL translation, leaving the efficacy of the abstraction mechanism on other structured generation tasks untested.
  - What evidence would resolve it: Empirical evaluations of the MaskSQL framework applied to standard code generation and debugging benchmarks, measuring both utility retention and privacy preservation.

- How can the risk of re-identification of abstracted tokens be further mitigated when surrounding non-abstracted context is available to an adversary?
  - Basis in paper: [explicit] The authors note that "surrounding context may be exploited to re-identify the abstract tokens" and suggest that "additional privacy measures can be applied to mitigate such potential leakage."
  - Why unresolved: While the paper quantifies this risk via a re-identification score, MaskSQL does not currently implement specific defenses against inference attacks leveraging unmasked context.
  - What evidence would resolve it: A study integrating context-aware defenses (e.g., additional noise or context sanitization) into the pipeline that demonstrates a statistically significant improvement in the re-identification score.

- Can improved schema linking or fine-tuning local SLMs close the remaining accuracy gap between MaskSQL and untrusted LLM baselines?
  - Basis in paper: [explicit] The conclusion acknowledges that MaskSQL's "accuracy still falls behind other LLM-based frameworks" and proposes "fine-tuning SLMs, improved schema linking, and token-efficient strategies to reduce this gap."
  - Why unresolved: The current implementation relies on general-purpose local SLMs (Qwen-2.5-7B), which may lack the specific capacity to perfectly reconstruct complex SQL from abstracted forms.
  - What evidence would resolve it: Experimental results comparing the current MaskSQL implementation against variants utilizing fine-tuned SLMs for the reconstruction stage, specifically on complex query subsets (e.g., nested queries).

## Limitations

- Prompt design sensitivity: The masking recall and execution accuracy depend critically on local SLM linking prompts, which are not fully specified in the paper.
- Domain transferability: Performance on simpler schemas or domain-specific databases with embedded domain logic may differ substantially from the BIRD benchmark results.
- Hallucination handling: The paper doesn't extensively quantify how often the remote LLM hallucinates abstract tokens not in the mapping table, which would break deterministic reconstruction.

## Confidence

- High Confidence: The core mechanism of using abstraction for privacy preservation while maintaining SQL generation capability is well-supported by ablation studies showing deterministic reconstruction outperforms LLM-based unmasking by 21 points.
- Medium Confidence: The hybrid approach's effectiveness (55.66% execution accuracy) is validated on the BIRD benchmark, but the exact contribution of each component isn't fully isolated due to complex pipeline dependencies.
- Low Confidence: Claims about general applicability to diverse domains and schema complexities are not directly tested beyond the BIRD benchmark subset.

## Next Checks

1. **Schema Linking Accuracy Validation**: Run the local SLM schema linking independently on 100 queries from your target domain. Measure precision and recall against ground truth. If precision <85%, the abstraction pipeline will introduce systematic errors that compound through reconstruction.

2. **Abstraction Leakage Audit**: For 30 representative queries, manually inspect the abstracted prompts (Q' and S') to verify no sensitive information remains unmasked according to your privacy policy. Calculate actual masking recall and compare against the reported 61.36% for ΨF.

3. **Reconstruction Failure Analysis**: Generate abstract SQL for 50 queries using your remote LLM, then measure reconstruction success rate. Identify the proportion of failures due to symbol mismatches versus SQL syntax errors. This will reveal whether your deterministic lookup table implementation matches the paper's robustness.