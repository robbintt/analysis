---
ver: rpa2
title: 'INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based
  Approaches to Depression Symptom Identification'
arxiv_id: '2506.02924'
source_url: https://arxiv.org/abs/2506.02924
tags:
- symptom
- sentences
- were
- sentence
- depression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study explored fine-tuning, similarity-based, and prompt-based\
  \ approaches for identifying depression symptoms from text using the Beck\u2019\
  s Depression Inventory. The team addressed the challenge of limited labeled training\
  \ data by framing the task as binary classification and experimenting with synthetic\
  \ data augmentation."
---

# INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification

## Quick Facts
- arXiv ID: 2506.02924
- Source URL: https://arxiv.org/abs/2506.02924
- Reference count: 24
- Primary result: Ranked 1st among 17 teams in eRisk 2025 depression symptom identification task

## Executive Summary
This study presents a comprehensive exploration of three different approaches - fine-tuning, similarity-based, and prompt-based - for identifying depression symptoms in text using the Beck's Depression Inventory framework. The team addresses the challenge of limited labeled training data by framing the task as binary classification and employing synthetic data augmentation techniques. Their approach combines multiple methods through ensemble techniques, ultimately achieving top performance in the official eRisk 2025 evaluation across all information retrieval metrics.

## Method Summary
The researchers explored three distinct approaches to depression symptom identification: fine-tuning foundation models on binary classification tasks, unsupervised sentence similarity ranking, and few-shot prompting of large language models. To address limited labeled data, they implemented synthetic data augmentation strategies. The methods were combined through ensemble techniques, with fine-tuning foundation models augmented with synthetic data emerging as the strongest individual approach.

## Key Results
- Fine-tuning foundation models with synthetic data augmentation achieved the best performance
- Ensemble-based approaches ranked first among 17 teams across all IR metrics in official evaluation
- The binary classification framing simplified the complex, continuous nature of depression symptoms

## Why This Works (Mechanism)
The success stems from combining multiple complementary approaches to handle the data scarcity challenge in depression symptom detection. Fine-tuning provides strong baseline performance, similarity-based methods capture semantic relationships, and prompt-based approaches offer flexibility for few-shot scenarios. The ensemble strategy leverages the strengths of each method while mitigating individual weaknesses.

## Foundational Learning
1. **Synthetic Data Augmentation** - Generating artificial training examples to expand limited labeled datasets; needed because depression symptom datasets are typically small and costly to annotate; quick check: validate augmented data quality and distribution alignment with real data.
2. **Binary Classification Framing** - Simplifying continuous depression severity into positive/negative categories; needed to reduce annotation burden and enable broader model applicability; quick check: verify that binary simplification doesn't lose critical severity information.
3. **Ensemble Methods in IR** - Combining multiple model predictions to improve overall retrieval performance; needed because different approaches capture different aspects of depression expression; quick check: analyze ensemble weight distributions and individual model contributions.

## Architecture Onboarding

**Component Map:**
Foundation Models -> Fine-tuning Pipeline -> Binary Classifier
Sentence Similarity Engine -> Ranking Module
LLM Prompting System -> Few-shot Classifier
Ensemble Aggregator -> Final Prediction

**Critical Path:**
Fine-tuning foundation models with synthetic data augmentation → Ensemble combination → Final classification output

**Design Tradeoffs:**
The binary classification simplification reduces annotation complexity but loses nuanced severity information. Synthetic data augmentation expands training data but may introduce distributional artifacts. Ensemble methods improve robustness but add computational overhead and complexity in interpretation.

**Failure Signatures:**
Models may misclassify subtle or culturally-specific depression expressions. Synthetic data artifacts can create spurious correlations. Ensemble voting may mask individual model weaknesses without proper calibration.

**First Experiments:**
1. Baseline fine-tuning performance without synthetic data augmentation
2. Ablation study of individual ensemble components
3. Out-of-distribution testing on culturally diverse depression expressions

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic data augmentation may introduce artifacts that don't reflect real-world depression expressions
- Binary classification framing oversimplifies the continuous, nuanced nature of depression severity
- Individual component contributions to ensemble performance remain unclear without ablation studies

## Confidence
- **High Confidence**: Official evaluation ranking (1st place among 17 teams across all IR metrics)
- **Medium Confidence**: Synthetic data augmentation's crucial role in success, though mechanisms and biases need investigation
- **Medium Confidence**: Relative performance ordering of approaches, but margins and statistical significance not clearly established

## Next Checks
1. Conduct ablation studies to quantify synthetic data augmentation's specific contribution versus model architecture choices
2. Test approach robustness on out-of-distribution data including different demographics, cultural contexts, and text genres
3. Perform error analysis to identify failure modes and understand limitations in symptom detection accuracy