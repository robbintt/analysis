---
ver: rpa2
title: 'CINeMA: Conditional Implicit Neural Multi-Modal Atlas for a Spatio-Temporal
  Representation of the Perinatal Brain'
arxiv_id: '2506.09668'
source_url: https://arxiv.org/abs/2506.09668
tags:
- atlas
- latent
- brain
- cinema
- subjects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CINeMA is a novel deep learning framework that constructs high-resolution,
  spatio-temporal, multi-modal brain atlases for perinatal imaging, addressing the
  limitations of traditional methods that require large datasets and intensive registration.
  Unlike established approaches, CINeMA operates in latent space using implicit neural
  representations (INRs), eliminating the need for deformable registration and reducing
  atlas construction time from days to minutes.
---

# CINeMA: Conditional Implicit Neural Multi-Modal Atlas for a Spatio-Temporal Representation of the Perinatal Brain

## Quick Facts
- arXiv ID: 2506.09668
- Source URL: https://arxiv.org/abs/2506.09668
- Authors: Maik Dannecker; Vasiliki Sideri-Lampretsa; Sophie Starck; Angeline Mihailov; Mathieu Milh; Nadine Girard; Guillaume Auzias; Daniel Rueckert
- Reference count: 40
- Constructs high-resolution, spatio-temporal, multi-modal brain atlases for perinatal imaging using implicit neural representations

## Executive Summary
CINeMA introduces a novel deep learning framework for constructing high-resolution, spatio-temporal, multi-modal brain atlases specifically for perinatal imaging. Unlike traditional methods requiring extensive registration and large datasets, CINeMA operates in latent space using implicit neural representations (INRs), eliminating the need for deformable registration and reducing atlas construction time from days to minutes. The framework enables flexible conditioning on anatomical features such as gestational age, lateral ventricle volume, and agenesis of the corpus callosum, making it suitable for both healthy and pathological brains. CINeMA supports downstream tasks like tissue segmentation and age prediction, and its generative properties allow for synthetic data creation and anatomically informed augmentation.

## Method Summary
CINeMA uses an auto-decoder framework where shared INR weights encode general anatomy while subject-specific latent codes encode individual variations. Subject alignment is learned via rigid transformations optimized jointly with latent codes, bypassing expensive non-rigid registration. The framework introduces explicit conditioning variables (e.g., LV volume, GA, pathology labels) that are concatenated as disjoint dimensions to the latent code, enabling disentangled conditioning on both discrete and continuous properties. Spatial latent codes improve representation of complex local anatomical features compared to global 1D codes, with trilinear interpolation retrieving location-specific latent vectors. The method uses sinusoidal activation functions (SIREN) to capture high-frequency anatomical details and supports test-time adaptation for individual subjects.

## Key Results
- Achieves 0.84 DSC segmentation accuracy vs 0.77 for 1D latent codes on dHCP dataset
- Reduces atlas construction time from days to minutes by eliminating deformable registration
- Outperforms state-of-the-art baselines in image similarity (PSNR, SSIM), segmentation Dice scores, and age prediction MAE
- Successfully conditions on anatomical features including lateral ventricle volume and agenesis of corpus callosum

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Operating in latent space eliminates the need for deformable registration while capturing subject variability.
- Mechanism: CINeMA uses an auto-decoder framework where shared INR weights encode general anatomy while subject-specific latent codes encode individual variations. Subject alignment is learned via rigid transformations optimized jointly with latent codes, bypassing expensive non-rigid registration.
- Core assumption: Subject variability can be compactly encoded in low-dimensional latent codes without explicit deformation fields.
- Evidence anchors:
  - [abstract] "CINeMA operates in latent space, avoiding compute-intensive image registration and reducing atlas construction times from days to minutes."
  - [Section I-A] "CINeMA encodes individual variability directly into subject-specific latent codes via an auto-decoder setup. This eliminates the need for explicit deformable registration."
  - [corpus] Limited direct comparison in neighboring papers; most related work (MultiMorph) focuses on traditional registration acceleration rather than latent-space approaches.
- Break condition: If subjects have fundamentally incompatible anatomical topologies (e.g., different numbers of brain structures), latent codes cannot capture variability without explicit deformation.

### Mechanism 2
- Claim: Explicit conditioning variables disentangle anatomical features from the latent code for controlled atlas generation.
- Mechanism: During training, explicit conditions (e.g., LV volume, GA, pathology labels) are concatenated as disjoint dimensions to the latent code. This forces the network to use these dimensions for the specified feature rather than encoding it implicitly in z.
- Core assumption: The network will use the provided explicit dimensions rather than finding alternative encodings.
- Evidence anchors:
  - [Section III-D] "We introduce additional disjoint dimensions during training, ξ ∈ R^Q, concatenated to the latent code z. This approach enables disentangled conditioning on both discrete and continuous properties."
  - [Section V-E-1] "Explicit conditioning during training ensures a disentangled encoding between conditioned anatomy and other brain structures. This allows modulation of anatomical features for atlases but also for individual subjects."
  - [corpus] Weak evidence; related papers on conditional atlases (Conditional Fetal Brain Atlas Learning) do not explicitly address disentanglement mechanisms.
- Break condition: If the explicit condition dimension is too small or the feature is too complex, the network may ignore explicit conditioning and encode features in z anyway.

### Mechanism 3
- Claim: Spatial latent codes improve representation of complex local anatomical features compared to global 1D codes.
- Mechanism: Each subject has a spatial latent code z ∈ R^(D×X1×X2×X3). For a given coordinate, trilinear interpolation retrieves a location-specific latent vector, allowing spatially-varying subject representations rather than a single global descriptor.
- Core assumption: Complex local features (e.g., cortical folding patterns) require spatially-indexed representations.
- Evidence anchors:
  - [Section III-A-1] "We have found that 1D latent codes, as used in CINA [14], limit the spatial representation of complex anatomical features like the cortical gray matter of the brain."
  - [Table II] Ablation shows spatial latent codes (z_256×3³) achieve 0.84 DSC vs. 0.77 for 1D codes (z_256).
  - [corpus] No direct comparison found in neighboring papers; implicit neural representation papers typically use global codes.
- Break condition: If spatial code resolution is too low relative to anatomical feature scale, benefits diminish. If too high, overfitting may occur despite regularization.

## Foundational Learning

- Concept: **Implicit Neural Representations (INRs)**
  - Why needed here: Core representation method where a coordinate-based MLP maps spatial locations to values, enabling resolution-agnostic outputs.
  - Quick check question: Given an INR trained on 1mm data, can you query it at 0.5mm without retraining? (Answer: Yes, INRs are continuous functions.)

- Concept: **Auto-Decoder vs. Auto-Encoder**
  - Why needed here: CINeMA uses auto-decoders where latent codes are optimized directly during training, not produced by an encoder network.
  - Quick check question: In CINeMA's training, are the latent codes produced by a neural network? (Answer: No, they are free parameters optimized directly.)

- Concept: **Feature-wise Linear Modulation (FiLM)**
  - Why needed here: The mechanism by which latent codes modulate INR layers through scale (α) and shift (β) parameters.
  - Quick check question: What happens if you set all modulation parameters to zero? (Answer: The INR outputs the shared anatomical representation, losing subject-specific details.)

- Concept: **SIREN (Sinusoidal Representations)**
  - Why needed here: CINeMA uses sinusoidal activations with frequency scaling (ω0) to capture high-frequency anatomical details.
  - Quick check question: Why might ReLU activations struggle with detailed cortical folding? (Answer: ReLUs produce piecewise-linear functions, poorly suited for smooth, high-frequency surfaces.)

## Architecture Onboarding

- Component map:
  - INR backbone: 5-layer MLP (1024 units each), sinusoidal activations
  - Spatial latent codes: z ∈ R^(256×3×3×3) per subject, trilinear interpolation
  - Modulation layers: Applied to layers 1, 3, 5 via learned M^h, μ^h
  - Rigid alignment: R_rot ∈ SO(3), t ∈ R^3 per subject (learnable)
  - Explicit conditions: ξ ∈ R^Q concatenated to interpolated latent code
  - Output heads: Separate predictions for intensity (MSE loss) and tissue probability (CE loss)

- Critical path:
  1. **Training**: Initialize z_i ~ N(0, 10^-2), R_i as identity. Sample coordinates, apply learned rigid transform, interpolate z, concatenate ξ, modulate INR, predict intensity/segmentation. Optimize z_i, R_i, θ jointly via Eq. 1.
  2. **Inference**: Regress temporal latent code z̄_t via Gaussian-weighted averaging (Eq. 3). Forward pass generates atlas at any resolution.
  3. **Test-time adaptation**: Freeze θ, optimize new z_j and R_j on unseen subject intensities only (Eq. 5). Use 10% holdout for early stopping.

- Design tradeoffs:
  - Latent code dimension: Larger improves segmentation accuracy; smaller improves downstream task generalization (age prediction).
  - Temporal kernel width (σ): Larger yields smoother, more general atlases; smaller biases toward individual subjects. Paper uses σ ≈ 0.5 weeks.
  - Explicit vs. implicit conditioning: Explicit enables interpretability and controlled generation; implicit may capture unknown factors but is harder to manipulate.

- Failure signatures:
  - Blurry cortical regions: Spatial latent code resolution may be insufficient. Try increasing from 3³ to 5³.
  - Poor pathology adaptation: If baseline (no pathology) performs well but pathological cases fail, add explicit conditioning on pathological features.
  - Collapsed latent space: If age prediction degrades significantly, latent code may be too large (overfitting to spatial details). Reduce dimension or add regularization.
  - Registration artifacts on severe abnormalities: Rigid alignment insufficient. Paper notes STNs could help but aren't implemented.

- First 3 experiments:
  1. **Sanity check**: Train on 10 subjects, verify reconstruction loss converges. Check that latent codes differ between subjects.
  2. **Temporal interpolation**: Generate atlases at intermediate ages (not in training). Visually inspect continuity and anatomical plausibility.
  3. **Conditioning validation**: Train with explicit LV volume conditioning. Generate atlases at LV volumes outside training range. Verify smooth extrapolation (Fig. 3 pattern).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can topology-preserving loss functions or cortical surface map inputs ensure topological correctness of cortical structures in CINeMA-generated atlases?
- Basis in paper: [explicit] Authors state: "ensuring topological accuracy, particularly in cortical structures, remains challenging and cannot be guaranteed in the current work. Future work should focus on integrating topology-preserving loss functions, e.g., via a patch-based regularization term, or incorporating cortical surface maps as additional input modality."
- Why unresolved: Current INR formulation lacks explicit topological constraints; cortical folding representations may have topological errors despite accurate volumetrics.
- What evidence would resolve it: Demonstration that patch-based regularization or cortical surface inputs yield topologically consistent cortical surfaces (e.g., via Euler characteristic or genus validation).

### Open Question 2
- Question: Can multitask learning frameworks enable condition representations to emerge from data rather than requiring predefined labels?
- Basis in paper: [explicit] Authors propose: "A promising extension is the adoption of a multitask learning framework in which condition representations are learned jointly with auxiliary tasks such as age prediction or abnormality classification."
- Why unresolved: Current explicit conditioning depends on predefined labels, limiting flexibility and representation capacity.
- What evidence would resolve it: A multitask model that learns clinically meaningful conditioning variables without explicit labels while maintaining or improving atlas quality metrics.

### Open Question 3
- Question: Do spatial transformer networks improve alignment for anatomically diverse or highly abnormal subjects compared to the current rigid alignment approach?
- Basis in paper: [explicit] Authors note: "STNs could enhance alignment in anatomically diverse or highly abnormal subjects, making them a promising direction for future work" but cite challenges in disentangling spatial transformations from latent codes.
- Why unresolved: Current rigid transformations may be insufficient for severe pathologies; STN integration complexity is unresolved.
- What evidence would resolve it: Comparative segmentation accuracy on severely abnormal subjects (e.g., extreme ventriculomegaly) between rigid-only and STN-augmented models.

### Open Question 4
- Question: Can CINeMA's latent space enable reliable disease classification or anomaly detection in perinatal brain imaging?
- Basis in paper: [explicit] Authors state: "Future work could also further explore CINeMA's latent space, which holds potential for broader applications, such as disease classification or anomaly detection."
- Why unresolved: Latent space applications beyond age prediction and segmentation remain unexplored; clustering and separability of pathological vs. normal subjects in latent space is unknown.
- What evidence would resolve it: Quantitative classification performance (AUC, accuracy) on distinguishing pathologies from latent codes alone.

## Limitations
- Performance on severely pathological brains with major structural abnormalities remains untested
- Rigid registration approach may be insufficient for cases with significant brain malformations
- Limited ablation studies on the impact of explicit versus implicit conditioning
- Choice of spatial latent code resolution (3×3×3) appears arbitrary without systematic exploration

## Confidence
- **High confidence**: The core mechanism of using implicit neural representations with spatial latent codes and explicit conditioning is technically sound and well-supported by the mathematical framework and ablation results.
- **Medium confidence**: Claims about computational efficiency (reducing atlas construction from days to minutes) are supported by runtime measurements but lack direct comparison with established registration-based methods on identical hardware.
- **Medium confidence**: Performance improvements over baselines are demonstrated, but the specific comparison methods are unclear, making independent verification difficult.

## Next Checks
1. Replicate the ablation study comparing spatial latent codes (256×3³) against 1D latent codes (256) on the dHCP dataset to verify the claimed DSC improvement from 0.77 to 0.84.
2. Test test-time adaptation on a held-out subject with known gestational age, comparing the MAE achieved by CINeMA against a simple linear regression baseline on the same latent features.
3. Generate atlases for gestational ages outside the training range (e.g., 20wks or 50wks) to evaluate the model's extrapolation capability and identify potential failure modes.