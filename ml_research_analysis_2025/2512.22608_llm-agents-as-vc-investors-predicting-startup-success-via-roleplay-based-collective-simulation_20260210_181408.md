---
ver: rpa2
title: 'LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based
  Collective Simulation'
arxiv_id: '2512.22608'
source_url: https://arxiv.org/abs/2512.22608
tags:
- investor
- startup
- investment
- investors
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of predicting startup success
  in venture capital by modeling investor collective decision-making rather than isolated
  individual judgments. It introduces SimVC-CAS, a novel framework that simulates
  multi-agent interactions among potential investors using LLM-based role-playing
  and a graph neural network with virtual nodes (VGAT).
---

# LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation

## Quick Facts
- arXiv ID: 2512.22608
- Source URL: https://arxiv.org/abs/2512.22608
- Reference count: 17
- Key outcome: SimVC-CAS achieves approximately 25% relative improvement in average precision@10 over baselines for predicting startup funding success

## Executive Summary
This paper addresses the challenge of predicting startup success in venture capital by modeling collective investor decision-making rather than isolated judgments. The authors introduce SimVC-CAS, a framework that simulates multi-agent interactions among potential investors using LLM-based role-playing and a graph neural network with virtual nodes. By jointly capturing startup fundamentals and investor behavioral dynamics within a co-investment network, the model achieves superior predictive accuracy while providing interpretable reasoning for venture capital decisions.

## Method Summary
SimVC-CAS predicts whether early-stage startups will secure subsequent funding by simulating heterogeneous investor agents evaluating candidate startups. The method constructs detailed startup and investor profiles, samples k=10 potential investors per startup, and uses a two-stage LLM decision process: initial individual evaluations followed by peer-influenced revisions based on predicted interaction patterns from a virtual graph attention network. The model is trained on historical co-investment networks and validated through temporal splits to prevent data leakage.

## Key Results
- Achieves approximately 25% relative improvement in average precision@10 compared to baselines
- Ablation studies show roleplay and interaction components contribute significantly to performance
- VGAT architecture with virtual nodes outperforms standard GAT by 5.84% F1 on joint investment prediction
- k=10 candidate investors provides optimal balance between prediction quality and computational cost

## Why This Works (Mechanism)

### Mechanism 1: Heterogeneous Role-Playing Investor Agents
- Claim: Personalized LLM agents modeling distinct investor personas produce more realistic and diverse evaluations than a single decision-maker.
- Mechanism: Each agent receives structured investor profile (personal info, past investments, employment history) and target startup's panoramic portrait. LLM generates initial investment decision conditioned on persona-specific context, capturing heterogeneous risk preferences and cognitive patterns.
- Core assumption: LLMs can faithfully simulate investor decision-making styles when given biographical and historical investment data as conditioning context.
- Evidence anchors: [abstract] states agents embody unique traits enabling heterogeneous evaluation; ablation shows removing roleplay drops AP@10 from 37.52 to 22.09.

### Mechanism 2: Startup-Centric Virtual Node in VGAT
- Claim: Introducing target startup as virtual node connected to all investor nodes captures how specific deal characteristics mediate investor interactions.
- Mechanism: VGAT architecture embeds startup as virtual node d connected to all real investor nodes with configurable weights. Two GAT layers (global then local) process graph. Virtual node embedding transformed via MLP and used in cross-attention to modulate edge representations between investors, making interaction patterns startup-adaptive.
- Core assumption: Investor-investor influence patterns shift depending on startup being evaluated; virtual node provides learnable mechanism for contextual modulation.
- Evidence anchors: [section] describes VGAT where virtual nodes represent target startup as information hubs; ablation shows VGAT outperforms baseline GAT by 5.84% F1.

### Mechanism 3: Two-Stage Peer-Influenced Decision Revision
- Claim: Allowing agents to revise initial decisions after observing peer judgments improves prediction by simulating real-world information diffusion in co-investment networks.
- Mechanism: Each agent produces initial decision D⁰ᵢ via LLM. VGAT outputs interaction edges E_interact specifying which peers influence each agent. Agents generate final decision D¹ᵢ conditioned on initial judgment plus neighbors' decisions and profiles, aggregated via LLM prompting.
- Core assumption: Co-investment graph topology derived from historical collaborations meaningfully predicts which investors influence each other's decisions on new deals.
- Evidence anchors: [abstract] reports approximately 25% relative improvement with respect to average precision@10; ablation shows FullInteraction underperforms NetworkInteraction, and VGAT Interaction further improves over both.

## Foundational Learning

- Concept: Graph Attention Networks (GAT)
  - Why needed here: VGAT extends GAT with virtual nodes; understanding attention over graph neighborhoods is prerequisite.
  - Quick check question: Can you explain how attention coefficients are computed between connected nodes and how they differ from GCN's fixed normalization?

- Concept: LLM Role-Playing / Persona Prompting
  - Why needed here: Agents must adopt distinct investor personas through prompt engineering.
  - Quick check question: Given an investor profile, how would you construct a prompt to enforce persona-consistent reasoning while avoiding prompt injection?

- Concept: Temporal Data Leakage in LLM Evaluations
  - Why needed here: Paper uses GPT-3.5 (training cutoff Sept 2021) with test data from Sept 2021 onward to prevent leakage.
  - Quick check question: Why does using an LLM trained on data through Sept 2021 to evaluate startups funded after Sept 2021 constitute a leakage control?

## Architecture Onboarding

- Component map: Startup Panoramic Portrait -> Heterogeneous Investor Portraits -> Node Encoder (Jina-ColBert) -> VGAT (Global GAT -> Local GAT -> MLP virtual node transform -> Cross-attention edge prediction) -> Decision Module (LLM initial D⁰ᵢ -> VGAT interaction edges -> LLM revision D¹ᵢ -> Final P_success)

- Critical path: 1) Construct startup portrait and sample k investors; 2) Generate investor profile embeddings via NodeEncoder; 3) Run VGAT to predict interaction edges E_interact; 4) LLM produces initial decisions; then LLM revises based on neighbors; 5) Aggregate final decisions to P_success

- Design tradeoffs: k=10 selected as cost-effective; larger k yields diminishing returns; VGAT supervision uses future co-investment as proxy for latent interaction (strict signal, may miss some valid interactions); Temperature=0 for reproducibility trades off decision diversity

- Failure signatures: Very low AP@10 on new sectors (investor profiles may lack domain-specific investment history); high variance across runs (suggests insufficient profile specificity or unstable interaction edge predictions); FullInteraction outperforming VGAT (indicates learned interaction patterns not capturing domain structure)

- First 3 experiments: 1) Reproduce ablation: compare w/o roleplay vs w/o interaction vs full SimVC-CAS on held-out month to validate component contributions; 2) Vary k ∈ {1, 5, 10, 20} with fixed interaction method to identify inflection point where marginal returns diminish; 3) Replace VGAT with simple threshold-based edge assignment to isolate whether learned attention vs. topology drives gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can predictive modeling of which investors will actually evaluate a given startup improve simulation accuracy over random sampling?
- Basis in paper: [explicit] Conclusion states "the current treatment of potential investor group selection in our model is relatively simplified. To more accurately simulate investment behavior, future work will explore the prediction and modeling of potential investor groups."
- Why unresolved: Current method randomly samples k investors from historical and co-investment partners; paper does not model which investors are realistically likely to evaluate a specific startup.
- What evidence would resolve it: Experiments comparing random sampling against trained investor-selection model, measuring AP@K differences on same test set.

### Open Question 2
- Question: Would integrating dimension-specific analysis agents with collective decision-making agents yield complementary gains?
- Basis in paper: [explicit] Conclusion proposes combining "both the 'multi-agent analysis perspective' and the 'collective agent decision-making perspective'" to build comprehensive framework.
- Why unresolved: Paper focuses solely on collective decision dynamics; does not test whether adding agents specialized for team, market, or financial analysis further improves predictions.
- What evidence would resolve it: Ablation experiments where specialized analysis agents feed structured summaries to collective investor agents, compared against SimVC-CAS alone.

### Open Question 3
- Question: Does using richer supervision signals beyond future co-investment improve interaction modeling?
- Basis in paper: [inferred] Appendix notes future co-investment is "a rather strict standard" that "may lose some potential interaction signals," yet main results show it works as proxy.
- Why unresolved: Latent investor interactions are inherently unobservable; paper relies on one noisy proxy without comparing alternatives.
- What evidence would resolve it: Experiments incorporating additional interaction indicators as auxiliary supervision, evaluating VGAT edge prediction quality and downstream startup success metrics.

### Open Question 4
- Question: Does the collective agent framework transfer to other domains with heterogeneous networked decision-making?
- Basis in paper: [explicit] Abstract and conclusion state "SimVC-CAS also sheds light on other complex group decision scenarios" and "framework can theoretically be extended to other fields involving complex group decision-making dynamics."
- Why unresolved: Claim is theoretical; no experiments validate generalization beyond VC.
- What evidence would resolve it: Applying SimVC-CAS to different domain dataset (e.g., academic grant decisions with reviewer networks), reporting performance against domain-specific baselines.

## Limitations
- Reliance on detailed investor profiles raises concerns about generalizability to emerging sectors where historical investment data is sparse
- Virtual node mechanism's effectiveness depends heavily on quality and completeness of startup panoramic portraits, which may be less reliable for very early-stage companies
- Strict temporal filtering of co-investment networks (positive/negative edge ratio ≥ 0.05) may exclude meaningful but rare collaboration patterns

## Confidence
- High confidence: 25% relative AP@10 improvement claim, supported by ablation studies showing component contributions
- Medium confidence: mechanism explaining investor interaction patterns, as external validation of virtual node approach is limited
- Low confidence: model's robustness across diverse startup sectors, as corpus analysis shows no direct replications of virtual node design

## Next Checks
1. Test SimVC-CAS performance on startups from newly emerged sectors (e.g., AI/ML, clean tech) to assess domain transferability
2. Compare VGAT's interaction predictions against alternative methods (e.g., simple collaboration frequency thresholds) to isolate value of learned attention
3. Conduct sensitivity analysis on startup profile completeness to determine minimum information threshold for reliable predictions