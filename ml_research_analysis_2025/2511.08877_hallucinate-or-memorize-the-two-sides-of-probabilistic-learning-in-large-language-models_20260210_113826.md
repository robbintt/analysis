---
ver: rpa2
title: Hallucinate or Memorize? The Two Sides of Probabilistic Learning in Large Language
  Models
arxiv_id: '2511.08877'
source_url: https://arxiv.org/abs/2511.08877
tags:
- citation
- papers
- information
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines how citation frequency affects hallucination
  rates in LLM-generated bibliographic records. Using GPT-4.1 to generate 100 citations
  across 20 CS domains, we find that citation count strongly correlates with factual
  accuracy (r=0.75, p<0.001).
---

# Hallucinate or Memorize? The Two Sides of Probabilistic Learning in Large Language Models

## Quick Facts
- arXiv ID: 2511.08877
- Source URL: https://arxiv.org/abs/2511.08877
- Authors: Junichiro Niimi
- Reference count: 40
- Key finding: Citation frequency strongly correlates with factual accuracy (r=0.75, p<0.001) in LLM-generated bibliographic records

## Executive Summary
This study investigates the relationship between citation frequency and hallucination rates in LLM-generated bibliographic records. Using GPT-4.1 to generate 100 citations across 20 computer science domains, researchers discovered that citation count strongly correlates with factual accuracy. The findings reveal that bibliographic information becomes nearly verbatim memorized beyond approximately 1,000 citations, with cosine similarity approaching 1.0. However, memory interference occurs when multiple highly cited papers share similar content, leading to fabricated metadata.

The research demonstrates that hallucination and memorization represent two sides of the same probabilistic process in LLMs, determined by knowledge density in pretraining corpora. When information appears frequently enough in training data, models tend to memorize it verbatim, while less frequent information is more likely to be hallucinated or generated probabilistically.

## Method Summary
The study used GPT-4.1 to generate 100 bibliographic citations across 20 computer science domains. Researchers measured factual accuracy and cosine similarity between generated and reference citations to assess memorization patterns. The experimental design focused on citation frequency as the primary variable, examining how different levels of citation density affect the model's tendency to either accurately reproduce information or generate fabricated metadata.

## Key Results
- Strong positive correlation between citation count and factual accuracy (r=0.75, p<0.001)
- Bibliographic information becomes nearly verbatim memorized beyond ~1,000 citations
- Memory interference occurs when multiple highly cited papers share similar content, causing fabricated metadata
- Cosine similarity approaches 1.0 for highly cited bibliographic information

## Why This Works (Mechanism)
The mechanism operates through the probabilistic nature of transformer-based language models. During training, tokens corresponding to frequently cited bibliographic information appear in similar contexts across the training corpus, creating strong associations that the model learns to reproduce accurately. The softmax function in the final layer assigns higher probabilities to these well-learned patterns, making accurate reproduction more likely than generation.

## Foundational Learning
- **Citation patterns**: Why needed - understanding how academic citations distribute in training data; Quick check - analyze citation frequency distribution across domains
- **Cosine similarity metrics**: Why needed - quantifying semantic and lexical similarity between generated and reference text; Quick check - validate similarity scores against human judgment
- **Memory interference**: Why needed - explaining why multiple similar sources cause generation errors; Quick check - test with controlled sets of similar papers
- **Probabilistic generation**: Why needed - understanding how transformers choose between memorization and generation; Quick check - analyze token probability distributions for different citation frequencies
- **Embedding space compression**: Why needed - explaining high similarity scores for semantically similar content; Quick check - examine embedding vectors for highly similar citations

## Architecture Onboarding

**Component Map**: Input tokens -> Embedding layer -> Transformer blocks (attention + feed-forward) -> Output softmax layer -> Token probabilities

**Critical Path**: Input processing -> Attention mechanism (captures citation patterns) -> Feed-forward network (refines representations) -> Softmax output (determines generation vs memorization)

**Design Tradeoffs**: Models must balance memorization capacity with generalization ability; high citation frequency enables accurate reproduction but risks overfitting, while low frequency requires probabilistic generation but increases hallucination risk

**Failure Signatures**: Fabricated metadata when citation similarity is high but exact matches are absent; verbatim copying for extremely frequent citations; inconsistent formatting across generated citations

**3 First Experiments**:
1. Test citation generation accuracy across different citation frequency thresholds (100, 500, 1000, 5000 citations)
2. Compare memory interference effects between semantically similar versus topically similar papers
3. Measure generation quality for citations from emerging versus established research areas

## Open Questions the Paper Calls Out
None

## Limitations
- Single-model experimental design limits generalizability across different LLM architectures
- Focus on computer science domains may not apply to other scientific fields with different citation patterns
- Cosine similarity approaching 1.0 may be artificially inflated by text compression and embedding methods
- Experimental timeframe represents a snapshot that may not capture evolving citation practices

## Confidence

**High confidence**: The correlation between citation frequency and factual accuracy (r=0.75, p<0.001)

**Medium confidence**: The claim that bibliographic information becomes "nearly verbatim memorized" beyond 1,000 citations

**Medium confidence**: The observation of memory interference when multiple highly cited papers share similar content

## Next Checks
1. Replicate the experiment across multiple LLM architectures (e.g., Claude, LLaMA, Gemini) to assess generalizability of findings
2. Conduct temporal analysis by testing with historical citation data to identify changes in memorization patterns over time
3. Implement blinded human evaluation of bibliographic records to validate automated factual accuracy assessments and identify subtle forms of knowledge distortion