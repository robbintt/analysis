---
ver: rpa2
title: LLM-based Contrastive Self-Supervised AMR Learning with Masked Graph Autoencoders
  for Fake News Detection
arxiv_id: '2508.18819'
source_url: https://arxiv.org/abs/2508.18819
tags:
- graph
- news
- fake
- detection
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a self-supervised misinformation detection
  framework that combines Abstract Meaning Representation (AMR) graphs with social
  context propagation graphs. The method uses a novel LLM-based graph contrastive
  loss (LGCL) with negative sampling to improve feature separation, and a multi-view
  graph masked autoencoder to learn news propagation features.
---

# LLM-based Contrastive Self-Supervised AMR Learning with Masked Graph Autoencoders for Fake News Detection

## Quick Facts
- arXiv ID: 2508.18819
- Source URL: https://arxiv.org/abs/2508.18819
- Reference count: 16
- Primary result: Achieves 91.9% accuracy on PolitiFact and 96.8% on GossipCop using minimal labeled data

## Executive Summary
This paper introduces a self-supervised framework for fake news detection that combines Abstract Meaning Representation (AMR) graphs with social context propagation graphs. The method employs an LLM-based graph contrastive loss (LGCL) with negative sampling to improve feature separation, and a multi-view graph masked autoencoder to learn news propagation features. Experiments on the FakeNewsNet dataset demonstrate superior performance compared to state-of-the-art unsupervised methods while requiring minimal labeled data.

## Method Summary
The framework processes news text into AMR graphs using the STOG parser, then augments them with Wikipedia evidence via an Evidence Linking Algorithm to create WikiAMR graphs. A Graph Transformer encodes these graphs with path-aware attention, while a social propagation graph captures spreading patterns. The AMR module uses an LLM (LLaMA3-7B) to generate zero-shot pseudo-labels and compute class centroids for contrastive learning via LGCL loss. The propagation module applies multi-view masked autoencoding with random remasking to learn robust features. These representations are concatenated and classified using a linear SVM.

## Key Results
- Achieves 91.9% accuracy on PolitiFact and 96.8% on GossipCop datasets
- Outperforms state-of-the-art unsupervised methods by 8-9% in accuracy
- Demonstrates strong performance with minimal labeled data requirements
- LGCL component contributes 8-9% accuracy improvement over random negatives

## Why This Works (Mechanism)

### Mechanism 1
LLM-generated negative anchors improve feature separability between real and fake news classes. An LLM assigns zero-shot pseudo-labels, partitioning samples into pseudo-real and pseudo-fake groups. Centroids are computed for each group using BERT features. During contrastive learning, a real sample's negative anchor is the fake centroid (and vice versa), enforced via a margin-based loss that pushes the encoded AMR embedding away from the negative anchor while pulling it toward the original BERT feature.

### Mechanism 2
Multi-view remasking in the graph autoencoder creates robust propagation features invariant to noise. The social propagation graph undergoes two augmentations (50% feature masking, 20% edge dropping). Each augmented view is encoded by a GIN encoder, then decoded with multiple random remaskings per view. The loss jointly minimizes feature reconstruction error across all view-remasking combinations and maximizes cosine similarity between decoded outputs from different views.

### Mechanism 3
WikiAMR graphs with path-encoded attention capture semantic relations that distinguish fake from real news. Text is parsed into an AMR graph, then linked to Wikipedia evidence via ELA to form WikiAMR. A Graph Transformer encodes the graph, with attention computed over shortest relation paths between entity pairs (encoded via bidirectional GRU). This allows the model to reason over multi-hop entity relationships rather than just local context.

## Foundational Learning

- **Abstract Meaning Representation (AMR)**: Converts unstructured news text into a semantic graph where nodes are entities/concepts and edges are relations, enabling structured reasoning. Quick check: Can you explain how AMR differs from dependency parsing in what it represents?

- **Contrastive Learning with Negative Sampling**: Core to LGCL—learn representations by pulling positive pairs together and pushing negative pairs apart in embedding space. Quick check: What happens to contrastive loss if all negatives are easy (already far from the anchor)?

- **Graph Masked Autoencoders**: Enables self-supervised learning on propagation graphs by predicting masked node features from unmasked context. Quick check: Why does masking features (rather than edges) encourage semantic rather than structural reconstruction?

## Architecture Onboarding

- **Component map**: Text → AMR Parser → WikiAMR → Graph Transformer → LGCL; parallel: Propagation Graph Builder → Augmentation Module → GIN Encoder/Decoder → Multi-view Remasking; Feature Fusion → Linear SVM

- **Critical path**: Text → AMR → WikiAMR → Graph Transformer → LGCL; parallel: Propagation graph → augmentations → GIN encoder → multi-view decoder → L_prop; fuse → SVM

- **Design tradeoffs**: LLM choice (LLaMA3-7B vs. Mistral-7B) affects pseudo-label quality; augmentation count (k=2, m≤6) shows diminishing returns beyond 3; Lambda (λ=0.5) balances reconstruction vs. separation

- **Failure signatures**: Silhouette scores not improving across pipeline stages → check LLM pseudo-label quality; propagation loss stuck high → inspect augmentation aggressiveness; AMR graphs sparse/disconnected → verify STOG parser output

- **First 3 experiments**: (1) Ablate LLM negatives: Replace with random negatives; expect 8-9% accuracy drop. (2) Vary training size: Test with 10%, 50%, 80% labels; confirm low-resource robustness. (3) Visualize embedding separation: t-SNE at each pipeline stage; silhouette should increase (0.33→0.64 for PolitiFact).

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but implies several directions for future work through its conclusions about broader applicability.

## Limitations
- Reliance on LLM zero-shot pseudo-labels introduces variability without reported pseudo-label accuracy or stability metrics
- ELA (Evidence Linking Algorithm) component referenced from external work without implementation details
- BERT variant and exact feature extraction pipeline for user posts remain unspecified

## Confidence
- High confidence: Multi-view graph masked autoencoder architecture and core reconstruction mechanism
- Medium confidence: AMR-to-WikiAMR pipeline effectiveness (limited empirical validation in related work)
- Low confidence: LLM-based contrastive loss reliability (no reported pseudo-label accuracy or ablation of LLM model choice)

## Next Checks
1. Run ablation studies with random negatives vs. LLM negatives to quantify the contribution of the LLM-guided contrastive component
2. Implement cross-validation across multiple random seeds to measure variance in the LGCL loss due to LLM pseudo-label generation
3. Test the framework on datasets with different propagation patterns (e.g., COVID-19 misinformation) to validate generalizability beyond the original domains