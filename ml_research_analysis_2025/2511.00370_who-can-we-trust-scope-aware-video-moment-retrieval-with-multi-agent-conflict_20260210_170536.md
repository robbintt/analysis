---
ver: rpa2
title: Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict
arxiv_id: '2511.00370'
source_url: https://arxiv.org/abs/2511.00370
tags:
- video
- agents
- location
- query
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses video moment retrieval (MR), which involves
  locating specific moments in untrimmed videos based on text queries. The authors
  propose a reinforcement learning (RL)-based method called Evidential Scanner for
  RL-based MR (ESRL) that scans the entire video once to find moment boundaries while
  producing locational evidence.
---

# Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict

## Quick Facts
- arXiv ID: 2511.00370
- Source URL: https://arxiv.org/abs/2511.00370
- Reference count: 11
- Primary result: Outperforms state-of-the-art video moment retrieval methods on Charades-STA and ActivityNet-Captions benchmarks

## Executive Summary
This paper addresses video moment retrieval (MR) by proposing a reinforcement learning (RL)-based method called Evidential Scanner for RL-based MR (ESRL) that scans videos once to find moment boundaries while producing locational evidence. The authors introduce a multi-agent system framework (MARLCC) that uses evidential learning to resolve conflicts between agents' localization outputs. The key innovation is using evidential learning to produce evidence and uncertainty for relative location classes, enabling the system to select the most trusted result from competing agents. The method also achieves zero-shot out-of-scope (OOS) query detection by analyzing conflicts between agents.

## Method Summary
The method combines three RL-based agents (ESRL, E-MABAN, E-DARK) that independently process video-query pairs to produce boundary predictions, predicted IoU, and evidence vectors. A multi-agent competition module (MARLCC) selects the winning agent based on a "Trusted IoU" score that incorporates evidential uncertainty. ESRL uses a fixed-window scanning approach with 16 relative location classes, while E-MABAN and E-DARK are variants with different feature inputs. The system achieves zero-shot OOS detection by setting a threshold on maximum pairwise conflict between agents' final locations.

## Key Results
- Outperforms state-of-the-art approaches on Charades-STA and ActivityNet-Captions in Acc@0.5 and Acc@0.7 metrics
- Achieves high accuracy in zero-shot OOS detection (88.42% on ActivityNet-Captions, 66.33% on Charades-STA)
- Ablation studies show evidential learning contributes 2.56% Acc@0.5 improvement on Charades-STA

## Why This Works (Mechanism)
The method works by leveraging evidential deep learning to produce uncertainty estimates alongside predictions, allowing the system to reason about which agent's output to trust. Each agent produces evidence vectors that are converted to uncertainty scores, which are then used by the MARLCC module to select the most reliable result. The competition-based selection mechanism enables graceful degradation - if one agent fails, others can compensate. The zero-shot OOS detection works because OOS queries cause agents to produce conflicting outputs that can be detected without additional training.

## Foundational Learning

- **Evidential Deep Learning (Dirichlet Distribution)**:
  - Why needed here: The core ESRL agent and MARLCC selection mechanism depend on "evidence" and "uncertainty" derived from a Dirichlet distribution, not just standard softmax probabilities
  - Quick check question: Given evidence vector *e* for 16 classes, how is uncertainty *u* calculated? (Answer: *u = C / S*, where *S* is the sum of (*e_j + 1*))

- **Reinforcement Learning (Actor-Critic) for Video Grounding**:
  - Why needed here: Agents are RL agents that learn policies and state values based on rewards from IoU changes and distance to ground truth
  - Quick check question: What is the primary reward signal for an ESRL agent? (Answer: A function of IoU change and distance to the ground truth boundary)

- **Multi-Agent System (MAS) Competition vs. Cooperation**:
  - Why needed here: Framework is built on premise that independent agents compete and winner is selected, rather than cooperating to produce single output
  - Quick check question: How is "winner" of competition determined in MARLCC? (Answer: Agent with highest "Trusted IoU" *U*)

## Architecture Onboarding

- **Component map**: Video & Text encoding -> Three parallel RL agents (ESRL, E-MABAN, E-DARK) -> Per-agent output (location, predicted IoU, evidence vector) -> MARLCC selection module (GRU + FFN) -> Single "Trusted IoU" (*U*) -> Winning agent selection

- **Critical path**: 1) Video & Text encoding, 2) Independent forward passes for all agents, 3) Per-agent Trusted IoU (*U*) calculation, 4) Selection of winning agent based on max(*U*), 5) (Optional) OOS check based on max conflict (Î·) of final locations

- **Design tradeoffs**: Competition vs. Cooperation (competition allows orthogonal agent design but loses cooperative refinement synergies), Zero-shot OOS vs. Supervised (avoids separate training but may be less precise), Scanning Agent (fixed-window ensures coverage but may be less flexible)

- **Failure signatures**: Systematic Overconfidence (all agents produce high evidence for wrong answers), Correlated Errors (agents share common flaw), False OOS Positive (difficult valid query causes agents to diverge)

- **First 3 experiments**: 1) Ablate Evidence (run MARLCC with/without evidence feature to verify contribution), 2) Agent Analysis (compare single agents vs. full MARLCC ensemble), 3) OOS Detection Validation (evaluate zero-shot OOS detection accuracy)

## Open Questions the Paper Calls Out

- **Agent Scaling**: How does increasing agents beyond three affect MARLCC performance, and where is performance bottleneck? (Authors note limited by time/computation resources, need further discussion)

- **Conflict Patterns**: Can conflict patterns during agent movement (not just final outputs) improve OOS detection or MR accuracy? (Authors only discuss final location conflict)

- **Non-RL Integration**: How can MARLCC integrate non-RL-based MR architectures (e.g., anchor-based or transformer methods) within evidential competition framework? (MARLCC only considers RL-based methods)

- **OOS Detection Gap**: What causes substantial gap in zero-shot OOS detection accuracy between ActivityNet-Captions (88.42%) and Charades-STA (66.33%)? (Authors speculate training data scale but haven't validated)

## Limitations

- Architecture Details: Exact network structures of E-MABAN and E-DARK not fully specified, requiring external references
- OOS Data Construction: Methodology for creating out-of-scope query-video pairs not detailed
- Hyperparameter Sensitivity: Performance highly dependent on specific hyperparameters requiring extensive tuning

## Confidence

- **High**: Core concept of using evidential learning to produce uncertainty and overall multi-agent competition framework are well-defined and logically sound
- **Medium**: Performance claims on benchmarks are specific and verifiable, but exact replication challenging without code and full architectural details
- **Low**: Zero-shot OOS detection mechanism relies on simple conflict threshold, robustness across diverse query distributions not thoroughly validated

## Next Checks

1. **Architecture Fidelity**: Implement E-MABAN and E-DARK agents by studying referenced MABAN paper and inferring "excluded area" feature design for E-DARK, then compare single-agent performance to ensemble

2. **OOS Detection Ablation**: Systematically vary OOS conflict threshold `h` and analyze impact on in-scope retrieval accuracy and OOS detection F1-score to find optimal balance

3. **Evidence Calibration**: Analyze distribution of evidential uncertainty scores (`u = C / S`) produced by agents on validation set to check if Dirichlet-based uncertainty is well-calibrated and meaningful