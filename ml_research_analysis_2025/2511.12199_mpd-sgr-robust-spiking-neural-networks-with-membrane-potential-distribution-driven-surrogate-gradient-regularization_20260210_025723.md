---
ver: rpa2
title: 'MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven
  Surrogate Gradient Regularization'
arxiv_id: '2511.12199'
source_url: https://arxiv.org/abs/2511.12199
tags:
- neural
- gradient
- robustness
- adversarial
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of spiking neural networks
  (SNNs) to adversarial attacks despite their inherent robustness. The authors identify
  that the gradient magnitude, determined by the interaction between membrane potential
  distribution (MPD) and surrogate gradient (SG) function, is critical for robustness
  but underexplored.
---

# MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven Surrogate Gradient Regularization

## Quick Facts
- arXiv ID: 2511.12199
- Source URL: https://arxiv.org/abs/2511.12199
- Reference count: 38
- Key outcome: MPD-SGR significantly improves SNN robustness against adversarial attacks while maintaining clean accuracy

## Executive Summary
This paper addresses the vulnerability of spiking neural networks (SNNs) to adversarial attacks by proposing MPD-driven surrogate gradient regularization (MPD-SGR). The method leverages theoretical analysis showing that reducing the overlap between membrane potential distributions (MPD) and surrogate gradient (SG) function ranges mitigates sensitivity to input perturbations. By regularizing this overlap, MPD-SGR improves robustness across multiple datasets and attack types without requiring adversarial training. The approach demonstrates strong generalization across different network architectures, SG functions, and spike encoding schemes.

## Method Summary
MPD-SGR adds a regularization term to the standard SNN training loss that minimizes the overlap between membrane potential distributions and surrogate gradient function ranges. During training, membrane potentials are collected per layer, channel, and timestep, and their mean and standard deviation are computed. The regularization loss calculates the proportion of potentials within the SG's gradient-available interval using the error function, assuming a Gaussian MPD. This loss is combined with the task loss using a coefficient η (typically 0.05) and optimized via SGD with cosine annealing. The method requires LIF neurons with tdBN normalization and works with various SG functions and spike coding schemes.

## Key Results
- Under PGD attacks, MPD-SGR improves robustness by 12-18% on CIFAR-10 compared to state-of-the-art methods
- Maintains comparable clean accuracy while significantly improving robustness against FGSM, PGD, BIM, and CW attacks
- Generalizes effectively across different SG functions (triangle, rectangular, sigmoid) and spike encoding schemes
- Works in both vanilla and adversarial training settings, outperforming prior methods in both

## Why This Works (Mechanism)

### Mechanism 1
Reducing the overlap between membrane potential distribution (MPD) and surrogate gradient (SG) function's gradient-available range mitigates sensitivity to input perturbations. The MPD-SGR regularization explicitly constrains the mean and variance of the MPD to reduce the proportion of membrane potentials within the SG's gradient-available interval, lowering gradient magnitude and making the network less sensitive to small input changes. Core assumption: MPD can be reasonably approximated as Gaussian, and the overlap integral correctly captures the interaction affecting gradient magnitude and robustness.

### Mechanism 2
Gradient magnitude, governed by the MPD-SG interaction, is a key driver of robustness error in SNNs. By reformulating the robustness error bound and expanding it through BPTT dynamics, the surrogate gradient term directly scales the error. Regularizing the SG term via MPD control thus suppresses this error component. Core assumption: The local linearity approximation and BPTT expansion accurately capture the dominant contributors to robustness error.

### Mechanism 3
MPD-SGR improves robustness without requiring adversarial training and is compatible with various SG functions and spike coding schemes. The regularization loss is added to the task loss and optimized via standard SGD, implicitly shaping the MPD to reduce SG overlap. This improves robustness under both vanilla and AT settings and generalizes across configurations because it targets a fundamental gradient-level property. Core assumption: The regularization coefficient η can be tuned to balance clean accuracy and robustness without causing training instability.

## Foundational Learning

**Surrogate Gradient (SG) Learning in SNNs**
- Why needed: SG functions provide approximate gradients for non-differentiable spiking neurons, and their interaction with MPD affects training and robustness
- Quick check: Can you explain why a surrogate gradient function is necessary for training SNNs with backpropagation, and how the gradient-available interval is defined for a triangle SG function?

**Leaky Integrate-and-Fire (LIF) Neuron Dynamics**
- Why needed: MPD is shaped by LIF dynamics (decay, reset, threshold); understanding membrane potential evolution is essential for grasping Theorem 1 and MPD-SGR regularization
- Quick check: Given an iterative LIF neuron with decay factor τ, how does the membrane potential at time step t depend on past inputs and resets?

**Adversarial Robustness in Neural Networks**
- Why needed: The paper's core goal is to improve SNN robustness to adversarial attacks; familiarity with perturbation bounds, attack types, and accuracy-robustness trade-off is necessary to interpret results
- Quick check: What is the difference between a white-box and a black-box adversarial attack, and why is a model's performance under PGD attack often used as a robustness benchmark?

## Architecture Onboarding

**Component map:** Data → Encoder → SNN layers (with tdBN) → Output; During training: Forward pass (with MPD tracking) → Loss computation (task + MPD-SGR) → Backward pass (with SG) → Weight update. The regularization module is the only non-standard component added to the training pipeline.

**Critical path:** Data flows through encoder to SNN layers, with membrane potentials tracked during forward pass. The MPD-SGR module computes overlap loss based on collected MPD statistics, which is combined with task loss. The combined loss is backpropagated using surrogate gradients to update weights.

**Design tradeoffs:** (1) η selection: Higher η improves robustness but risks clean accuracy drop and training instability; lower η preserves accuracy but yields smaller robustness gains. (2) MPD approximation: Assuming Gaussian MPD simplifies overlap integral but may be inaccurate for some layers; more complex distribution models could improve accuracy at cost of complexity. (3) SG function choice: MPD-SGR works with various SG functions, but optimal η may differ; triangle function is default.

**Failure signatures:** (1) Clean accuracy drops significantly (>2-3% compared to baseline) → η likely too high; reduce and retune. (2) Robustness gains are marginal → η may be too low, or MPD is not well-approximated as Gaussian; check MPD histograms and consider adjusting tdBN or neuron parameters. (3) Training loss becomes unstable or diverges → regularization may be causing gradient vanishing; verify overlap computation and ensure Ω remains in reasonable range.

**First 3 experiments:**
1. **Baseline replication:** Train vanilla SNN (VGG11, CIFAR-10, T=4-8, triangle SG, tdBN) and measure clean/FGSM/PGD accuracy to establish baseline numbers matching paper's reported values.
2. **η sensitivity sweep:** Apply MPD-SGR with η ∈ {0.01, 0.03, 0.05, 0.07, 0.1} on CIFAR-10/VGG11, plot clean vs. PGD accuracy, and identify optimal η balancing accuracy and robustness (expected around 0.05).
3. **SG function generalization:** Replace triangle SG with rectangular or sigmoid SG, keep η fixed, and train on CIFAR-10/VGG11; verify MPD-SGR still improves robustness compared to vanilla baseline for each SG type.

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: How does MPD-SGR performance scale when applied to large-scale datasets (e.g., ImageNet) or advanced architectures like Spiking Transformers?
- Basis: Experimental validation is restricted to CIFAR-10/100 and Tiny-ImageNet using VGG and WideResNet architectures.
- Why unresolved: Computational overhead of calculating overlap integral and stability of Gaussian assumption may vary significantly in deeper, more complex, or attention-based models.
- What evidence would resolve it: Robustness benchmarks on ImageNet-1K using modern Spiking Transformer architectures.

**Open Question 2**
- Question: Is the Gaussian assumption for Membrane Potential Distribution valid for SNNs utilizing different normalization techniques or neuron reset mechanisms?
- Basis: Theorem 1 explicitly relies on tdBN to establish Gaussian distribution, and proof uses mean-field approximation for soft reset.
- Why unresolved: Theoretical derivation assumes specific conditions (tdBN, soft reset approximation); method's efficacy may degrade if MPD deviates from Gaussian shape under different configurations.
- What evidence would resolve it: Empirical analysis of MPD statistics and robustness results in networks trained with LayerNorm or different reset strategies.

**Open Question 3**
- Question: Can the regularization coefficient η be dynamically adjusted during training to better optimize the trade-off between clean accuracy and robustness?
- Basis: Appendix C analyzes trade-off imposed by fixed η, identifying optimal static value (0.05) that balances gradient obstruction and constraint enforcement.
- Why unresolved: Static coefficient applies constant constraint throughout training, potentially limiting optimization efficiency during different learning phases.
- What evidence would resolve it: Comparative experiments using scheduled or learnable η strategy against fixed baseline.

## Limitations

- The Gaussian approximation of membrane potential distributions may not hold for all SNN configurations, particularly in deeper layers or with complex input statistics
- Robustness gains are measured only against standard white-box attacks; effectiveness against more sophisticated or black-box attacks remains untested
- The method's performance is highly sensitive to the regularization coefficient η, requiring careful tuning to avoid clean accuracy degradation or training instability

## Confidence

- **Mechanism 1 (MPD-SG overlap reduces sensitivity)**: Medium confidence - theoretical derivation is sound but Gaussian MPD assumption needs empirical validation across diverse SNN configurations
- **Mechanism 2 (Gradient magnitude drives robustness error)**: Medium confidence - error bound decomposition is mathematically rigorous but dominance of SG term over other error components is assumed rather than proven for all scenarios
- **Mechanism 3 (Generalization across SG functions and spike coding)**: High confidence - ablation studies provide strong empirical evidence for cross-function effectiveness, though optimal η may vary

## Next Checks

1. **MPD Distribution Validation**: Generate histograms of membrane potentials across all layers/channels/timesteps for CIFAR-10/VGG11 with and without MPD-SGR. Test normality assumption using statistical tests (e.g., Kolmogorov-Smirnov) and quantify deviation from Gaussian to assess validity of regularization's theoretical foundation.

2. **Black-Box Attack Robustness**: Evaluate MPD-SGR-trained models against black-box attacks (e.g., transfer-based or query-based) to determine if robustness generalizes beyond white-box scenarios, addressing critical gap in understanding real-world adversarial resistance.

3. **Gradient Explosion/Vanishing Analysis**: Monitor magnitude of surrogate gradient term (P3) and MPD overlap Ω during training. Plot their evolution to ensure regularization does not cause gradient vanishing (which would halt learning) or instability (which would prevent convergence).