---
ver: rpa2
title: 3D Cardiac Anatomy Generation Using Mesh Latent Diffusion Models
arxiv_id: '2508.14122'
source_url: https://arxiv.org/abs/2508.14122
tags:
- cardiac
- meshes
- data
- meshldm
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MeshLDM, the first latent diffusion model
  designed to generate 3D meshes of cardiac anatomies. The method combines a geometric
  deep learning-based autoencoder with a fully connected denoising network to learn
  the latent space representation of left ventricular meshes at end-diastolic and
  end-systolic cardiac phases.
---

# 3D Cardiac Anatomy Generation Using Mesh Latent Diffusion Models

## Quick Facts
- **arXiv ID:** 2508.14122
- **Source URL:** https://arxiv.org/abs/2508.14122
- **Reference count:** 13
- **Primary result:** First latent diffusion model for generating 3D cardiac meshes, achieving 2.4% difference in clinical metrics compared to ground truth

## Executive Summary
This paper introduces MeshLDM, the first latent diffusion model designed to generate 3D meshes of cardiac anatomies. The method combines a geometric deep learning-based autoencoder with a fully connected denoising network to learn the latent space representation of left ventricular meshes at end-diastolic and end-systolic cardiac phases. The model was trained on a dataset of 1,034 3D meshes from post-myocardial infarction patients and achieved clinically relevant results while demonstrating the feasibility of applying diffusion models to cardiac anatomy generation.

## Method Summary
MeshLDM employs a two-stage pipeline: first, a Geometric Deep Learning autoencoder (MeshVAE) compresses 3D cardiac meshes into 16-dimensional latent vectors using graph convolutions and pooling layers. Second, a fully connected denoising network learns to generate valid latent vectors through a diffusion process. The model was trained separately for end-diastolic and end-systolic phases to avoid anatomically unrealistic hybrid shapes. Training involved first optimizing the autoencoder on 70% of the data, then using the frozen autoencoder to encode all data to latents before training the denoising network on these representations.

## Key Results
- Achieved 2.4% difference in population mean clinical metrics (LV volume and mass) compared to gold standard test meshes
- 3D mesh quality metrics: 1-NNA scores of 63.46% (ED) and 72.20% (ES), coverage scores of 30.77% (ED) and 23.08% (ES), minimum matching distances of 13.05mm (ED) and 14.83mm (ES)
- Successfully captured anatomical diversity including variations in basal plane tilt, mid-cavity diameter, and shape elongation, though with slightly lower diversity than gold standard

## Why This Works (Mechanism)

### Mechanism 1: Compression-to-Generative Pipeline
Separating high-dimensional mesh reconstruction from generative sampling improves tractability. The autoencoder compresses thousands of 3D vertices into a 16-dimensional latent vector, reducing the generative problem to manipulating a compact representation. This assumes the autoencoder creates a smooth, continuous latent space where small changes correspond to anatomically plausible changes.

### Mechanism 2: Topology-Preserving Convolutions
Graph convolutions preserve structural integrity of cardiac surfaces better than standard 3D grid convolutions. This mechanism processes data based on vertex adjacency rather than spatial location, leveraging the consistent mesh topology present in the dataset. The method assumes input data maintains fixed topology across all meshes.

### Mechanism 3: Phase-Separated Distribution Modeling
Modeling cardiac phases as distinct distributions prevents anatomically impossible intermediate states. Training separate models for ED and ES enforces hard constraints that generated shapes cluster around specific physiological states rather than attempting to bridge them, which could create blended or non-physiological shapes.

## Foundational Learning

- **Concept: Variational Autoencoders (VAEs)** - The core of the "Latent" Diffusion Model is the VAE. Understand how the "reparameterization trick" and KL-divergence regularization force the latent space to be continuous and Gaussian, allowing the diffusion model to sample from it.
  - **Quick check question:** If you feed a random vector into a standard Autoencoder vs. a VAE, why is the VAE's output more likely to be a coherent shape?

- **Concept: Diffusion Process (DDPM)** - This is the generative engine. Understand the forward process (adding Gaussian noise) vs. the reverse process (denoising).
  - **Quick check question:** In the reverse process (sampling), does the model predict the clean image directly or the noise component?

- **Concept: Graph Convolutions vs. Image Convolutions** - The encoder doesn't use standard CNNs. It operates on the mesh graph.
  - **Quick check question:** In a standard image convolution, the "neighborhood" is defined by pixel proximity. How is the neighborhood defined in a graph convolution for a cardiac mesh?

## Architecture Onboarding

- **Component map:** Input Standardized vertex coordinates -> MeshVAE (Graph Conv Encoder -> Latent Vector (Dim 16) -> Graph Conv Decoder) -> Denoising Network (6-layer FC) -> Scheduler (DDPMScheduler)
- **Critical path:** Sequential pipeline: Step 1: Train MeshVAE to convergence. Step 2: Freeze MeshVAE and encode all data to latent vectors. Step 3: Train Denoising Network on these latent vectors.
- **Design tradeoffs:**
  - FC Network vs. U-Net: Uses FC network because latent space is a 1D vector (size 16), not a 3D volume
  - Dim 16: Aggressive compression (thousands of vertices -> 16 numbers) for high efficiency but risks smoothing out fine scar details
- **Failure signatures:**
  - "Blob" shapes: If VAE regularization is too high, latent vectors collapse, and generated meshes look like smooth spheres
  - Mode Collapse: If diffusion training fails, model might generate the same "average" heart every time (low diversity)
  - Non-physiological blending: If forced to do both ED and ES in one model, gets anatomically impossible hybrids
- **First 3 experiments:**
  1. Autoencoder Reconstruction Test: Verify MeshVAE can reconstruct a test mesh with low error before training diffusion
  2. Latent Space Interpolation: Encode two real meshes, linearly interpolate between their latent vectors, and decode to check for smooth, anatomically valid transitions
  3. Clinical Metric Histogram: Generate 1,000 synthetic meshes and plot distribution of LV Volume against real test set to validate 2.4% difference claim

## Open Questions the Paper Calls Out

- **Open Question 1:** Can a conditioning mechanism be integrated into MeshLDM to generate distinct cardiac phases or specific subpopulations within a single model?
  - Basis: The authors state a future extension could incorporate conditioning to generate data for specific subpopulations using the same model
  - Why unresolved: Current study trained separate models for ED and ES to avoid generating anatomically unrealistic shapes that blend phase characteristics
  - Evidence needed: A single conditioned model generating high-fidelity meshes for both phases with clinical metrics comparable to current separate models

- **Open Question 2:** Does augmenting training datasets with MeshLDM-generated synthetic meshes improve performance of downstream cardiac disease classification tasks?
  - Basis: Authors identify data augmentation as a key application but state demonstrating these downstream uses is beyond scope
  - Why unresolved: While generated meshes are anatomically realistic, their utility in improving other machine learning models has not been quantified
  - Evidence needed: Increased classification accuracy or F1-scores in cardiac disease prediction when synthetic meshes are added to training set

- **Open Question 3:** To what extent does increasing training dataset size improve diversity of generated meshes to match gold standard population?
  - Basis: Authors note lower standard deviations in results and suggest larger dataset could increase diversity
  - Why unresolved: Current dataset (1,034 meshes) may be insufficient to capture full variance of human cardiac anatomy
  - Evidence needed: Generated mesh standard deviations for clinical metrics that are statistically indistinguishable from gold standard test set

## Limitations

- Reliance on fixed-topology dataset of post-myocardial infarction patients limits generalizability to other cardiac conditions
- Aggressive 16-dimensional latent space compression raises concerns about potential loss of fine anatomical details
- Separation of ED and ES modeling prevents generation of dynamic cardiac sequences and requires training two separate models

## Confidence

- **High confidence:** Methodological approach of using geometric deep learning autoencoders combined with diffusion models for mesh generation is technically sound
- **Medium confidence:** Reported 2.4% difference in population mean clinical metrics is plausible but difficult to independently verify due to private dataset
- **Medium confidence:** 3D mesh quality metrics appear reasonable, though high minimum matching distances suggest some geometric discrepancy

## Next Checks

1. **Latent space interpolation test:** Select two real meshes, encode to latent space, perform linear interpolation, decode intermediate shapes, and verify smooth, anatomically valid transitions without artifacts
2. **Mode collapse detection:** Generate 1,000 synthetic meshes and compute coefficient of variation (CV) for LV volume and mass; compare against test set CV to quantify diversity loss
3. **Cross-phase consistency check:** Using trained ED and ES models, generate paired meshes and compute structural similarity metrics (e.g., Dice coefficient) to assess whether phase separation has introduced unrealistic anatomical variations