---
ver: rpa2
title: 'Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for
  Text-Attributed Graph Anomaly Detection'
arxiv_id: '2508.00507'
source_url: https://arxiv.org/abs/2508.00507
tags:
- anomaly
- text
- node
- graph
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses text-attributed graph anomaly detection by
  integrating large language models (LLMs) and graph neural networks (GNNs) to capture
  anomaly-specific semantics and high-order structural information. The proposed CoLL
  framework employs multi-LLM collaboration to generate human-readable evidence from
  contextual and structural perspectives, while a GNN with gating mechanism fuses
  textual features and preserves global topology.
---

# Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection

## Quick Facts
- arXiv ID: 2508.00507
- Source URL: https://arxiv.org/abs/2508.00507
- Authors: Yiming Xu; Jiarun Chen; Zhen Peng; Zihan Chen; Qika Lin; Lan Ma; Bin Shi; Bo Dong
- Reference count: 40
- Primary result: Improves average AUC by 2.39% and AP by 13.37% over state-of-the-art methods

## Executive Summary
This paper introduces CoLL, a novel framework for text-attributed graph anomaly detection that leverages multi-LLM collaboration to generate human-readable evidence. The approach combines large language models for contextual and structural analysis with graph neural networks enhanced by gating mechanisms. The framework addresses the challenge of detecting anomalies in graphs where nodes have both structural relationships and textual attributes, capturing anomaly-specific semantics while preserving global topology.

## Method Summary
CoLL employs a dual-perspective LLM collaboration approach where one LLM analyzes contextual relationships between textual attributes while another examines structural patterns in the graph. These LLMs generate evidence that highlights anomaly-specific features, which are then integrated with a GNN that uses gating mechanisms to fuse textual features and maintain global topological information. The framework is designed to be both interpretable, through its evidence generation capability, and effective at capturing high-order structural information in text-attributed graphs.

## Key Results
- Achieves 2.39% average AUC improvement over state-of-the-art methods
- Demonstrates 13.37% average AP improvement across four datasets
- Shows superior interpretability through human-readable evidence generation

## Why This Works (Mechanism)
The framework succeeds by combining the semantic understanding capabilities of LLMs with the structural pattern recognition of GNNs. The contextual LLM captures semantic anomalies in textual attributes, while the structural LLM identifies unusual patterns in graph topology. The gating mechanism in the GNN ensures that both textual and structural information are appropriately weighted based on their relevance to the specific anomaly being detected.

## Foundational Learning
1. **Text-attributed graph anomaly detection** - detecting unusual patterns in graphs where nodes have both structural relationships and textual attributes; needed because traditional GNNs struggle with the semantic complexity of text data; quick check: can the method distinguish between normal and anomalous text patterns in graph contexts?
2. **Multi-LLM collaboration** - using multiple specialized LLMs for different analytical perspectives; needed to capture both contextual semantics and structural patterns; quick check: does combining multiple LLM outputs improve detection accuracy versus single LLM approaches?
3. **GNN with gating mechanisms** - neural networks that preserve global topology while allowing adaptive feature fusion; needed to integrate textual evidence with structural patterns effectively; quick check: can the gating mechanism properly weight textual versus structural features?

## Architecture Onboarding
- **Component map**: Text attributes -> Contextual LLM -> Evidence generation -> Gating mechanism -> Anomaly detection; Graph structure -> Structural LLM -> Evidence generation -> Gating mechanism -> Anomaly detection
- **Critical path**: Input text and graph structure → LLM evidence generation → GNN with gating fusion → Anomaly score output
- **Design tradeoffs**: Computational efficiency versus interpretability (multi-LLM adds overhead but enables evidence generation); feature fusion complexity versus detection accuracy (gating mechanism adds parameters but improves performance)
- **Failure signatures**: Poor performance when textual and structural anomalies are uncorrelated; degraded accuracy when LLM-generated evidence is noisy or irrelevant; scalability issues with very large graphs due to multi-LLM computation
- **First experiments**: 1) Ablation study removing LLM evidence generation to measure its contribution; 2) Testing with synthetic anomalies of varying difficulty; 3) Evaluating evidence quality through human assessment

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Evaluation focuses only on static text-attributed graphs, not dynamic or streaming scenarios
- Computational overhead from multi-LLM collaboration may impact real-time deployment
- Interpretability claims lack rigorous quantitative validation through user studies

## Confidence
- Performance improvement metrics (AUC +2.39%, AP +13.37%): **High confidence** - results are reported across multiple datasets with standard evaluation metrics
- Interpretability through human-readable evidence: **Medium confidence** - demonstrated qualitatively but lacks rigorous user studies
- Efficiency and scalability: **Low confidence** - computational costs and scalability limitations are not thoroughly characterized

## Next Checks
1. Conduct ablation studies isolating the contribution of each LLM perspective (contextual vs structural) to verify their complementary value
2. Perform stress tests on computational efficiency with graphs containing 10K+ nodes to establish practical scalability bounds
3. Design user studies measuring whether generated evidence actually improves human analysts' ability to understand and act on detected anomalies compared to black-box GNN predictions