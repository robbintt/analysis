---
ver: rpa2
title: Generalized Information Gathering Under Dynamics Uncertainty
arxiv_id: '2601.21988'
source_url: https://arxiv.org/abs/2601.21988
tags:
- information
- dynamics
- cost
- belief
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a modular framework for active information
  gathering under dynamics uncertainty that cleanly exposes causal dependencies between
  parameters, beliefs, controls, and observations. This framework enables deriving
  a general information-gathering cost based on Massey's directed information that
  is agnostic to specific modeling choices like dynamics models, belief updaters,
  or observation models.
---

# Generalized Information Gathering Under Dynamics Uncertainty

## Quick Facts
- **arXiv ID:** 2601.21988
- **Source URL:** https://arxiv.org/abs/2601.21988
- **Reference count:** 0
- **Primary result:** A modular framework for active information gathering under dynamics uncertainty that derives a general information-gathering cost based on Massey's directed information, proving that the commonly-used mutual information cost is a special case of their formulation.

## Executive Summary
This paper introduces a modular framework for active information gathering under dynamics uncertainty that cleanly exposes causal dependencies between parameters, beliefs, controls, and observations. The framework enables deriving a general information-gathering cost based on Massey's directed information that is agnostic to specific modeling choices like dynamics models, belief updaters, or observation models. The authors prove that the commonly-used mutual information cost is a special case of their directed information formulation. Using this framework, they establish an explicit connection between mutual information-based costs and information gain in linearized Bayesian estimation, providing theoretical justification for mutual information approaches.

## Method Summary
The framework introduces a modular approach where planning relies on a predicted belief trajectory generated by a generic belief dynamics function, while execution relies on the true belief update. The information-gathering cost is derived from directed information, which accounts for causal relationships between random sequences. Under linearization assumptions, this cost reduces to maximizing the information gain (inverse covariance) in an Extended Kalman Filter update. The framework uses an EKF belief updater with a mutual information cost, optimized using a sampling-based cross-entropy method planner.

## Key Results
- Active information gathering accelerates parameter learning and improves model generalization compared to passive or random approaches
- The framework's modularity allows applying the same EKF belief updater and mutual information cost across diverse dynamical systems without problem-specific derivations
- Experiments demonstrate success on single-agent linear and nonlinear systems, as well as multi-agent pursuit-evasion games with both LQR and differentiable MPC policies

## Why This Works (Mechanism)

### Mechanism 1: Causal Decoupling of Belief Dynamics
Separating the actual learning process from the planner's predicted belief dynamics allows the information-gathering cost to remain agnostic to specific model architectures. The framework enforces a causal graph where planning relies on predicted belief trajectories while execution uses true belief updates.

### Mechanism 2: Directed Information for Sequential Control
Directed information provides a valid optimization target for sequential decision-making where standard Mutual Information fails due to non-causal feedback loops. Unlike MI, directed information sums conditional entropies strictly forward in time, preventing the optimizer from "cheating" by assuming future observations inform past control decisions.

### Mechanism 3: Equivalence of MI Cost and Kalman Gain
Minimizing the derived mutual information cost is mathematically equivalent to maximizing the information gain in an Extended Kalman Filter update. Under linearization, the information cost is proportional to the innovation covariance, which directly relates to the parameter information gain.

## Foundational Learning

- **Concept: Markov Decision Processes (MDPs) & Belief States**
  - Why needed here: The framework builds on Markov dynamical systems where state transitions depend only on current state and control
  - Quick check question: Can you explain why the optimal control depends only on the current belief and state, not the full history?

- **Concept: Bayesian Inference & Kalman Filtering**
  - Why needed here: The framework relies on updating probability distributions over parameters using Bayesian inference
  - Quick check question: In a Kalman Filter, does adding a sensor with lower noise increase or decrease the determinant of the posterior covariance matrix?

- **Concept: Information Theory (Entropy & Mutual Information)**
  - Why needed here: The core cost function is derived from differential entropy and mutual information
  - Quick check question: If $h(\hat{o} \| u, \hat{\vartheta})$ represents remaining uncertainty in observations, should an information-gathering agent minimize or maximize this term?

## Architecture Onboarding

- **Component map:** Execution Environment -> Belief Updater -> Planner -> Cost Constructor
- **Critical path:** The interaction between the Planner and the Belief Dynamics model, where the planner generates controls based on predicted future beliefs
- **Design tradeoffs:** Lambda weight balances task performance vs. exploration; tradeoff between belief model fidelity and computational tractability
- **Failure signatures:** Circular trajectories when lambda is too high, covariance collapse when linearization fails, passive behavior when lambda is too low
- **First 3 experiments:**
  1. Linear Double Integrator: Verify agent deviates from straight line to excite velocity parameters
  2. Damped Pendulum: Verify agent swings pendulum to high-dynamics regions to identify damping
  3. Pursuit-Evasion (LQR Opponent): Verify agent identifies opponent's cost matrix by making provocative moves

## Open Questions the Paper Calls Out

### Open Question 1
Can the theoretical equivalence between minimizing the mutual information cost and maximizing information gain be extended to non-linearized Bayesian estimation methods? The proof relies on linearization and Gaussian assumptions, leaving non-linear or non-Gaussian updaters unverified.

### Open Question 2
How does the framework perform under structural model mismatch, where the known function does not perfectly describe the environment's dynamics? The framework learns parameters for a fixed function, but real-world scenarios often involve modeling errors.

### Open Question 3
Can the directed information cost be simplified for partially observable systems without requiring computationally expensive Monte Carlo integration? Theorem 1 requires full observability to reduce the general directed information cost to a tractable form.

## Limitations
- Framework's modularity introduces sensitivity to the quality of the belief dynamics model, particularly in highly non-linear systems
- Directed information formulation assumes Markov dynamics with additive noise - violations could invalidate theoretical guarantees
- Experimental validation focuses primarily on parameter estimation accuracy rather than downstream task performance benefits

## Confidence
- **High confidence:** Equivalence between mutual information cost and EKF information gain under stated assumptions; causal decoupling mechanism
- **Medium confidence:** Practical utility of directed information over standard MI in sequential control; claimed benefits of modularity across different belief updaters
- **Low confidence:** Framework's robustness to model misspecification and non-Gaussian belief distributions

## Next Checks
1. Systematically evaluate performance degradation as the agent operates farther from the linearization point, comparing against non-linear belief updaters
2. Design experiments where parameter learning directly impacts task success to quantify whether accelerated learning translates to measurable control improvements
3. Compare performance using increasingly sophisticated belief dynamics models while holding the information cost fixed, to quantify the tradeoff between model complexity and planning effectiveness