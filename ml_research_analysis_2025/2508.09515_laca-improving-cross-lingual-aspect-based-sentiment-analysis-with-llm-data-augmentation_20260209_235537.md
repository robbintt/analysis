---
ver: rpa2
title: 'LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data
  Augmentation'
arxiv_id: '2508.09515'
source_url: https://arxiv.org/abs/2508.09515
tags:
- language
- sentiment
- aspect
- data
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses cross-lingual aspect-based sentiment analysis
  (ABSA) by proposing a novel LLM-based data augmentation approach (LACA) to overcome
  limitations of translation-based methods. The core method involves fine-tuning an
  ABSA model on source language data, generating pseudo-labelled target language sentences
  using an LLM prompted with model predictions, and retraining the model on this augmented
  data.
---

# LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation

## Quick Facts
- arXiv ID: 2508.09515
- Source URL: https://arxiv.org/abs/2508.09515
- Reference count: 22
- Primary result: LLM-based data augmentation improves cross-lingual ABSA by up to 2.62% F1 over translation methods

## Executive Summary
LACA addresses the challenge of zero-shot cross-lingual aspect-based sentiment analysis by proposing a novel LLM-based data augmentation framework. The method fine-tunes an ABSA model on source language data, generates pseudo-labelled target language sentences using an LLM prompted with model predictions, and retrains the model on this augmented data. Experiments across six languages and five backbone models demonstrate significant improvements over state-of-the-art translation-based methods and zero-shot baselines, with LLaMA 3.1 70B achieving the best results.

## Method Summary
LACA operates in three stages: First, an ABSA model is fine-tuned on labeled source language data (e.g., English SemEval-2016 restaurant reviews). Second, this model predicts aspect-sentiment tuples for unlabelled target language sentences, which are then used to prompt an LLM to generate new sentences that explicitly encode these predicted labels. Third, generated sentence-label pairs are filtered to ensure quality and combined with the original source data for retraining the ABSA model. The framework supports both sequence labeling (BIO tagging) and generative ABSA architectures.

## Key Results
- LACA achieves up to 2.62% average F1-score improvements over translation-based methods
- Fine-tuned LLMs (LLaMA 3.1 70B) outperform smaller multilingual models (mBERT, XLM-R) in cross-lingual transfer
- The framework is adaptable to both sequence labeling and generative ABSA models
- Self-training baseline degrades performance by 9-20% compared to LACA, validating the LLM generation step

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLM-based sentence generation from predicted labels reduces pseudo-label noise compared to direct self-training on raw predictions
- **Core assumption:** The LLM can more reliably generate text matching a specified label than the ABSA model can correctly predict labels for arbitrary target-language text
- **Evidence anchors:** Ablation shows self-training baseline drops performance by up to 20% (mBERT) and 9% (XLM-R) compared to LACA

### Mechanism 2
- **Claim:** Prediction-based label generation captures language-specific aspect terms better than translation-based approaches
- **Core assumption:** The ABSA model, despite cross-lingual noise, can still surface some language-specific aspect terms that provide signal for data generation
- **Evidence anchors:** Translation-based generation performs ~2% worse than prediction-based generation in ablation study

### Mechanism 3
- **Claim:** Dynamic few-shot prompting with sentiment rebalancing improves data diversity and mitigates class imbalance
- **Core assumption:** The LLM's generation quality depends on example diversity, and sentiment class imbalance in pseudo-labels harms downstream training
- **Evidence anchors:** Removing dynamic few-shot causes ~2% performance drop; sentiment rebalancing improves 0.5-1.2% on average

## Foundational Learning

- **Zero-shot cross-lingual transfer with multilingual PLMs**
  - Why needed: LACA builds on mBERT/XLM-R zero-shot baselines; understanding why direct transfer fails motivates the data augmentation approach
  - Quick check: Can you explain why a model fine-tuned on English might fail to recognize "servicio" as an aspect term in Spanish even if both languages share subword tokens?

- **Pseudo-labeling and self-training**
  - Why needed: LACA is fundamentally a pseudo-labeling method that improves on naive self-training by using LLM generation as a denoising step
  - Quick check: What is the primary failure mode of self-training with noisy pseudo-labels, and why does regenerating text (rather than filtering labels) help?

- **ABSA task formulations (sequence labeling vs. text generation)**
  - Why needed: The framework supports encoder (BIO tagging), encoder-decoder (mT5), and decoder-only (LLaMA/Orca) architectures with different output formats
  - Quick check: For a generative ABSA model, what output format does LACA use for aspect-sentiment tuples?

## Architecture Onboarding

- **Component map:** Initial ABSA model (fine-tuned on source data) → Prediction phase (labels ŷT on target data) → LLM generator (creates ẋT from predictions) → Filtering (quality control) → Final training (combine DG with DS)

- **Critical path:** Prediction quality → LLM generation quality → Filtering stringency → Final training data quality

- **Design tradeoffs:**
  - LLM size vs. resource cost: 70B models perform best but require 4-bit quantization and significant GPU memory; 8B models offer ~1% lower performance with faster inference
  - Generation volume vs. computation: More generated samples improve performance but each requires an LLM forward pass
  - Language support: Orca 2 (English-centric) nearly matches LLaMA 70B on some targets due to better reasoning, but performance drops for unsupported languages like Russian/Turkish

- **Failure signatures:**
  - Self-training collapse: 10-20% F1 drop if using raw predictions without LLM generation
  - Unsupported language degradation: Turkish and Russian show highest error rates with smaller LLMs
  - Aspect boundary errors: Generated text may include extra aspects or miss required ones

- **First 3 experiments:**
  1. Reproduce zero-shot baseline: Fine-tune XLM-R on English SemEval data, evaluate on Spanish test set
  2. Minimal LACA pipeline: Use LLaMA 3.1 8B for generation with 100 Spanish samples, measure delta over baseline
  3. Ablation self-training comparison: Replace LLM generation with direct pseudo-labeling, confirm performance drop

## Open Questions the Paper Calls Out

- **Question:** Can the LACA framework be effectively generalized to other information extraction tasks, specifically Named Entity Recognition (NER)?
- **Question:** How robust is the LACA framework when applied to domains outside of restaurant reviews?
- **Question:** How do closed-source LLMs compare to open-source models in the LACA framework regarding generation quality and cost-efficiency?
- **Question:** Can the performance degradation in unsupported languages be mitigated by strictly using target-language-specific LLMs?

## Limitations

- Language-specific performance gaps are significant, with unsupported languages (Russian, Turkish) showing degraded performance
- The neutral sentiment generation quality is a systematic weakness, with LLMs struggling to produce accurate "mildly positive/negative" sentiment expressions
- LLM prompt template and specific few-shot examples are not fully specified, affecting reproducibility

## Confidence

- **High Confidence:** The core mechanism of using LLM-generated sentences to denoise pseudo-labels is strongly supported by ablation results showing 9-20% performance drops when removed
- **Medium Confidence:** The claim about prediction-based generation capturing language-specific aspects better than translation is supported by 2% performance differences
- **Medium Confidence:** The dynamic few-shot and sentiment rebalancing improvements are supported by ablation, but the 0.5-1.2% gains represent incremental benefits

## Next Checks

1. **Reproduce the self-training ablation:** Implement the direct pseudo-labeling baseline to verify the 9-20% performance degradation reported in Table 5
2. **Test unsupported language generalization:** Evaluate LACA performance on additional low-resource languages beyond the paper's six languages
3. **Analyze neutral sentiment generation:** Conduct a focused study on neutral sentiment examples to quantify misalignment and test alternative prompting strategies