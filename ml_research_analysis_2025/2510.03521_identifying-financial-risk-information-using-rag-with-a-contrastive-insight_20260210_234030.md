---
ver: rpa2
title: Identifying Financial Risk Information Using RAG with a Contrastive Insight
arxiv_id: '2510.03521'
source_url: https://arxiv.org/abs/2510.03521
tags:
- risk
- information
- company
- risks
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a contrastive approach for identifying financial
  risk information using retrieval-augmented generation (RAG). Traditional RAG methods
  extract relevant documents but often yield generic risk factors that apply broadly
  across companies.
---

# Identifying Financial Risk Information Using RAG with a Contrastive Insight

## Quick Facts
- arXiv ID: 2510.03521
- Source URL: https://arxiv.org/abs/2510.03521
- Reference count: 16
- Introduces contrastive approach for identifying financial risk information using retrieval-augmented generation (RAG)

## Executive Summary
This paper introduces a contrastive approach for identifying financial risk information using retrieval-augmented generation (RAG). Traditional RAG methods extract relevant documents but often yield generic risk factors that apply broadly across companies. The proposed method adds a peer-aware comparative inference layer that contrasts risks of a target company with those of similar firms, thereby highlighting company-specific and distinctive risks. Experiments using S&P 500 company data show that the contrastive method consistently outperforms standard RAG across multiple text generation metrics when compared to human-written equity research. The best results were achieved with OpenAI's O3 reasoning model.

## Method Summary
The methodology employs a four-stage pipeline: (1) retrieve document chunks via cosine similarity search using embeddings, (2) extract risks per chunk with an LLM (GPT-4.1-mini), (3) aggregate and deduplicate risks using another LLM (GPT-4.1), and (4) apply a contrastive inference layer comparing target company risks against peer company risks using O3 or GPT-4.1. The system processes SEC filings (10-Ks, 10-Qs, earnings call transcripts) for both target and peer companies, then generates outputs highlighting distinctive risks through comparative analysis. Evaluation is performed against confidential human-written equity research reports using BERTScore and ROUGE metrics.

## Key Results
- Contrastive RAG consistently outperforms standard RAG across BERTScore, ROUGE-1, ROUGE-2, and ROUGE-L metrics
- OpenAI's O3 reasoning model achieves the highest BERTScore (0.1692) and best overall performance
- The approach better aligns with expert risk assessments by focusing on nuanced, context-specific factors rather than generic industry-wide risks
- Performance gains are particularly notable for identifying company-specific risks that differ from peer exposures

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Filtering of Generic Signals
The peer-aware comparative inference layer reduces false positives by filtering industry-wide noise that standard RAG mistakenly identifies as company-specific risk. By forcing a comparison with peer firms, the model identifies which risks are "common" vs. "distinctive," suppressing the former. Core assumption: risks shared across peers are less material to a specific company's valuation than unique or unusually emphasized risks.

### Mechanism 2: In-Context Relativization
Providing the LLM with aggregated risk sets for both target and peers enables relative reasoning, improving alignment with human expert logic. Instead of absolute judgment, the prompt presents a structured comparison (relative judgment). Core assumption: the LLM has sufficient context window and reasoning capability to hold multiple company risk profiles simultaneously and perform set-difference operations.

### Mechanism 3: Evaluation via Expert Alignment
The architecture improves performance metrics by optimizing for "distinctiveness" rather than just "retrievability," which better matches human-written equity research. Human analysts rarely list standard regulatory risks in deep-dive reports; they focus on the delta. The contrastive layer implicitly trains the system to output this delta, increasing overlap with human references. Core assumption: human-written reports in the test set are themselves high-quality and distinct.

## Foundational Learning

- **Concept: Semantic Similarity vs. Salience**
  - Why needed here: The paper critiques standard RAG for conflating "textually similar" sections with "important/salient" information
  - Quick check question: If a text chunk about "General Cybersecurity Compliance" has a 0.95 cosine similarity to a query about "Company Risk," why might it be useless to an analyst?

- **Concept: Peer Groups (Comparables)**
  - Why needed here: The core mechanism relies on "peers" - companies with similar scale, sector, and business model
  - Quick check question: Why would comparing a Tech company's risks to a Utility company's risks fail to produce useful contrastive insights?

- **Concept: Reasoning Models vs. Standard LLMs**
  - Why needed here: The paper notes OpenAI's O3 (a reasoning model) performed best
  - Quick check question: Why might a "reasoning" model handle the prompt "Identify risks unique to Company A compared to Companies B, C, and D" better than a standard completion model?

## Architecture Onboarding

- **Component map:** Ingest (10-Ks, 10-Qs, Transcripts) -> Retrieve (Cosine Similarity Search) -> Extract (LLM prompts risk extraction) -> Aggregate (LLM dedupes/categorizes) -> Contrast (LLM comparative inference)
- **Critical path:** The Contrastive Prompt (Appendix A) - where logic shifts from "extraction" to "analysis"
- **Design tradeoffs:** Latency vs. Specificity (run pipeline for N+1 companies rather than just 1), Recall vs. Precision (contrastive layer acts as high-precision filter)
- **Failure signatures:** "Generic Output" (lists risks found in 90% of S&P 500 companies), "Hallucinated Contrast" (invents differences not supported by text)
- **First 3 experiments:** Peer Ablation (random vs. industry-specific peers), Model Swapping (smaller model in Contrast step), Noise Injection (add irrelevant risk to verify filtering)

## Open Questions the Paper Calls Out

- **Temporal Awareness Integration:** How can temporal awareness be integrated to capture emerging risks from real-time events rather than only periodic filings? Current methodology "does not account for the timeline of ongoing company events" and may "overlook dynamic changes that are crucial for timely and accurate risk assessment."

- **Expert Evaluation Metrics:** Do expert human evaluations and reasoning-based assessment metrics better capture risk identification accuracy than ROUGE and BERTScore? Current metrics "measure surface-level similarity but fail to capture whether the extracted risks are truly aligned with a company's actual exposures."

## Limitations

- Evaluation depends entirely on confidential human-written equity research reports, preventing independent verification
- Peer selection methodology is underspecified and not validated against standard industry classifications
- Temporal dynamics are acknowledged but not tested - may miss recently emerging risks not yet present in peer filings
- Assumes human equity research reports are reliable risk assessments, though analysts may have biases or access to non-public information

## Confidence

- **High confidence** in the core architecture and retrieval methodology
- **Medium confidence** in the contrastive inference layer's effectiveness
- **Low confidence** in the evaluation claims due to unavailable ground truth

## Next Checks

1. **Ground Truth Verification**: Replicate evaluation using publicly available analyst reports from multiple sources to assess whether performance metrics are consistent across different reference sets
2. **Peer Group Sensitivity**: Systematically vary peer selection criteria (strict vs. loose matching) and measure impact on output distinctiveness and metric scores
3. **Temporal Robustness**: Test the system on historical data with known risk events (e.g., 2008 financial crisis, COVID-19) to evaluate detection of emerging vs. persistent risks