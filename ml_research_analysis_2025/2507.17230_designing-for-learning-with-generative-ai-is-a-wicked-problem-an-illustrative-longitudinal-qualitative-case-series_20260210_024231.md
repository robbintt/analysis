---
ver: rpa2
title: 'Designing for Learning with Generative AI is a Wicked Problem: An Illustrative
  Longitudinal Qualitative Case Series'
arxiv_id: '2507.17230'
source_url: https://arxiv.org/abs/2507.17230
tags:
- genai
- career
- students
- learning
- wicked
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that designing for learning with generative AI
  (GenAI) is a "wicked problem," where progress in one area (e.g., GenAI skills) can
  impede progress in others (e.g., ethics, motivation, or career confidence). A longitudinal
  qualitative study of two students in a GenAI-integrated creative media course revealed
  these dynamics.
---

# Designing for Learning with Generative AI is a Wicked Problem: An Illustrative Longitudinal Qualitative Case Series

## Quick Facts
- arXiv ID: 2507.17230
- Source URL: https://arxiv.org/abs/2507.17230
- Reference count: 35
- Primary result: GenAI integration creates multidimensional trade-offs; skill gains can reduce ethics, motivation, and career confidence

## Executive Summary
This longitudinal qualitative case series examines how students' engagement with generative AI (GenAI) in a creative media course produces complex, often contradictory outcomes. Through detailed analysis of two students—Pat, who increased GenAI dependency while lowering ethical standards, and Jay, who heightened ethical awareness but restricted GenAI use—the study demonstrates that designing for learning with GenAI is a "wicked problem." Progress in one dimension (e.g., GenAI proficiency) often impedes progress in others (ethics, motivation, career confidence). The findings challenge single-metric approaches to GenAI integration and argue for multi-dimensional evaluation frameworks that account for these trade-offs.

## Method Summary
The study followed 14 students from a 54-student creative media course through four semi-structured interviews across Fall 2024. Interviews lasted 42-102 minutes (mean 64) and were conducted via Zoom. Two students (Pat and Jay) were selected as focus cases for providing the richest accounts. Data were analyzed using thematic coding in Atlas.ti, guided by a codebook developed from research questions and Social Cognitive Career Theory. Analysis employed pen portraits following Sheard & Marsh's four-stage method. The study tracked changes across four dimensions: GenAI skills, ethics, motivation, and career expectations.

## Key Results
- One student (Pat) increased GenAI dependency while simultaneously reporting reduced learning and diminished ethical standards
- Another student (Jay) developed stronger ethical awareness but limited GenAI use to 10 minutes daily, impeding skill development
- Both students experienced decreased career confidence despite gaining GenAI proficiency, suggesting skills alone don't improve career outlook
- The study identifies GenAI integration as a "wicked problem" where improvements in one educational dimension can undermine others

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Increasing GenAI proficiency can reduce perceived learning and ethical engagement when efficiency becomes the primary value.
- Mechanism: Students adopt GenAI for task completion → experience efficiency gains → shift from learning orientation to performance orientation → reduce ethical scrutiny as dependency normalizes.
- Core assumption: Students who value efficiency over understanding will externalize success attribution to the tool rather than their own developing competence.
- Evidence anchors:
  - [abstract] Pat "started from purposefully avoiding GenAI use, to dependency... described himself as a 'notorious cheater' who now uses GenAI to 'get all the right answers' while acknowledging he's learning less."
  - [section 4.1] Pat stated "if I'm going to submit it for a grade, I'm definitely going to use AI to get all the right answers" and "I really didn't have any ethical views before, and I still don't really."
  - [corpus] "The Agency Gap" (arxiv 2507.04398) examines how GenAI literacy predicts independent performance after support removal—relevant but does not directly confirm this dependency mechanism.
- Break condition: Students maintain reflective practice protocols requiring articulation of their own reasoning before accepting AI outputs.

### Mechanism 2
- Claim: Increased ethical awareness can impede GenAI skill acquisition through self-imposed usage restrictions.
- Mechanism: Ethics instruction raises concern (environmental, labor, consent) → students limit voluntary GenAI exposure → reduced practice opportunities → skill development lags peers.
- Core assumption: Ethical concerns translate into behavioral constraints rather than nuanced, context-dependent engagement strategies.
- Evidence anchors:
  - [abstract] "Jay's newfound environmental concerns led to self-imposed usage limits that impeded skill development."
  - [section 4.2] "Jay was minimally using GenAI, guided by a new self-imposed limit of 10 minutes daily due to concerns about GenAI's environmental impact."
  - [corpus] Weak direct evidence; neighbor papers address responsible use (arxiv 2506.00682) but do not document the ethics-skill trade-off mechanism empirically.
- Break condition: Curricula explicitly scaffold differentiated use strategies (e.g., "high-stakes vs. low-stakes" contexts) rather than binary accept/reject frames.

### Mechanism 3
- Claim: GenAI integration can destabilize career outcome expectations independent of actual skill gains.
- Mechanism: Students observe rapid GenAI adoption in target industries → perceive automation threat → career confidence declines despite (or regardless of) personal GenAI proficiency gains.
- Core assumption: Students form career expectations from external narratives (media, peer discourse) more than curricular signals or personal efficacy experiences.
- Evidence anchors:
  - [abstract] "Increased GenAI proficiency, a potential career skill, did not improve their career confidence."
  - [section 4.2] Jay became "nervous to do any type of writing professionally at this point" due to GenAI adoption despite initially confident that "my job cannot be taken by computers."
  - [corpus] "SPIRAL integration" (arxiv 2505.18771) examines self-efficacy and career outcome expectations but does not confirm this decoupling mechanism directly.
- Break condition: Interventions explicitly connect GenAI skills to agentic career narratives (e.g., "tool mastery expands options") and provide counter-narratives to displacement fears.

## Foundational Learning

- Concept: Wicked problem framing
  - Why needed here: Students and instructors may expect "solutions" to GenAI integration; understanding wickedness reorients toward managing trade-offs rather than optimizing single metrics.
  - Quick check question: Can you name two educational goals that improved GenAI proficiency might unintentionally undermine?

- Concept: Self-efficacy vs. illusion of competence
  - Why needed here: Distinguishes genuine confidence from inflated perceptions that collapse when scaffolding (GenAI) is removed.
  - Quick check question: How would you detect whether a student's high performance reflects understanding or tool dependency?

- Concept: Multi-dimensional evaluation
  - Why needed here: Single-metric assessment (e.g., task accuracy) hides declines in ethics, motivation, or career confidence.
  - Quick check question: What three non-performance dimensions would you track alongside learning outcomes in a GenAI-integrated course?

## Architecture Onboarding

- Component map:
  - Learning dimension: skill acquisition, task performance, help-seeking patterns
  - Ethics dimension: usage guidelines, value articulation, behavioral consistency
  - Motivation dimension: belonging, self-efficacy, intrinsic interest
  - Career dimension: outcome expectations, perceived agency, labor-market mental models

- Critical path:
  1. Baseline assessment across all four dimensions (not just skills)
  2. Intervention with explicit trade-off scaffolding (e.g., "if you prioritize X, Y may decline")
  3. Longitudinal tracking (minimum 2+ timepoints) to detect feedback loops
  4. Reflection prompts that surface value conflicts and behavioral contradictions

- Design tradeoffs:
  - Structured ethics instruction vs. open exploration: structure raises awareness but may trigger restrictive avoidance (see Jay).
  - Efficiency-focused tasks vs. struggle-preserving tasks: efficiency reinforces dependency; struggle builds resilience but may frustrate.
  - Single-metric optimization vs. multi-dimensional dashboards: simpler to implement but obscures critical warning signals.

- Failure signatures:
  - Students report high task performance but explicitly state they are "learning less" (Pat pattern).
  - Students articulate ethical concerns but cannot describe context-sensitive usage strategies (Jay pattern).
  - Career confidence declines despite skill gains; students express fatalism about automation.
  - Ethical reasoning shows domain-specific inconsistency (e.g., avoids GenAI in art but rationalizes paywall bypass).

- First 3 experiments:
  1. Pre/post survey measuring self-efficacy, ethics, motivation, and career expectations alongside skills in one GenAI-integrated assignment.
  2. Structured reflection prompt requiring students to articulate one trade-off they experienced (e.g., "I used GenAI for efficiency but felt I understood less").
  3. A/B comparison: one section receives trade-off-explicit framing; control receives standard GenAI instruction; track dimension-level changes at semester end.

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (2 students analyzed in depth out of 14 participants) limits generalizability
- Selection bias from choosing "richest accounts" may skew findings
- Absence of inter-rater reliability metrics weakens claims about consistent interpretation
- Short one-semester timeframe may miss longer-term adaptation patterns

## Confidence
- **High confidence**: The wicked problem framing and observation that single-metric optimization can mask multidimensional trade-offs (supported by direct quotes from both students).
- **Medium confidence**: The specific mechanisms linking GenAI proficiency to reduced learning and ethical engagement (Pat case), and ethical awareness to restricted skill development (Jay case), are well-documented in these two students but lack broader sample support.
- **Low confidence**: Claims about GenAI destabilizing career confidence independent of skill gains require more participants to establish whether this is a generalizable pattern or individual variation.

## Next Checks
1. **Expand participant pool**: Replicate the study with 20+ students and track the four dimensions (skills, ethics, motivation, career) across all participants to test whether the identified trade-off patterns persist.
2. **Add external benchmarks**: Compare student performance on AI-assisted vs. unassisted tasks at semester end to detect dependency versus genuine skill acquisition.
3. **Test intervention efficacy**: Implement the trade-off-explicit framing in a control/treatment design across two course sections and measure changes in all four dimensions, not just skills.