---
ver: rpa2
title: Hierarchical Scheduling for Multi-Vector Image Retrieval
arxiv_id: '2510.08976'
source_url: https://arxiv.org/abs/2510.08976
tags:
- image
- retrieval
- accuracy
- granularity
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HiMIR, a hierarchical decomposition framework
  for multi-vector image retrieval that addresses the limitations of conventional
  retrieval approaches in multimodal large language model (MLLM) applications. The
  core idea is to extend the traditional "1+N Mode" retrieval to a "1+M+N Mode" by
  introducing multiple intermediate granularities for image decomposition, which better
  aligns varying image objects with query decomposition and reduces redundancy through
  cross-hierarchy similarity consistency and hierarchy sparsity.
---

# Hierarchical Scheduling for Multi-Vector Image Retrieval

## Quick Facts
- arXiv ID: 2510.08976
- Source URL: https://arxiv.org/abs/2510.08976
- Reference count: 23
- Introduces HiMIR, a hierarchical decomposition framework for multi-vector image retrieval

## Executive Summary
This paper introduces HiMIR, a hierarchical decomposition framework for multi-vector image retrieval that addresses the limitations of conventional retrieval approaches in multimodal large language model (MLLM) applications. The core idea is to extend the traditional "1+N Mode" retrieval to a "1+M+N Mode" by introducing multiple intermediate granularities for image decomposition, which better aligns varying image objects with query decomposition and reduces redundancy through cross-hierarchy similarity consistency and hierarchy sparsity. HiMIR also features an automated configuration framework that optimizes parameters for different datasets and deployment scenarios. The experimental results demonstrate that HiMIR achieves substantial accuracy improvements over state-of-the-art methods while reducing computation by up to 3.5 times, making fine-grained multimodal retrieval practical for real-world deployment.

## Method Summary
HiMIR implements hierarchical image decomposition using SLIC segmentation across multiple granularities (N_g). For each query, it retrieves image segments at each granularity level, aggregates similarity scores using maximum pooling across hierarchies, and applies three key optimizations: redundant matching (pruning low-ranking images per hierarchy), hierarchy depth (early exit via Kendall's τ convergence), and hierarchy sparsity (offline granularity pruning). The system uses CLIP embeddings for images and Qwen3-8B for query decomposition through vLLM. An automated configuration framework performs latency-guided grid search to optimize parameters T (initial reduction ratio), α (reduction multiplier), τ (stability threshold), and S_G (granularity stride) for different deployment scenarios.

## Key Results
- Achieves NDCG@10 accuracy of 0.732 on CREPE dataset, outperforming POQD baseline (0.687) and PRCA (0.676)
- Reduces computation by up to 3.5x while maintaining accuracy through hierarchical pruning
- Provides 40% throughput gain through hierarchy depth optimization on Flickr dataset
- Automated configuration completes within tens of minutes and optimizes parameters for different datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Introducing multiple intermediate granularities for image decomposition (extending "1+N" to "1+M+N") may improve alignment between query sub-components and image objects of varying sizes.
- **Mechanism:** The system hierarchically segments images into multiple sets ($M$) with varying patch counts ($N_g$). Instead of forcing a single fixed granularity, it computes a final score by selecting the maximum similarity across all hierarchy levels (Eq. 3). This "max-pooling" over granularities allows a sub-query (e.g., "toy") to match a coarser granularity while another (e.g., "keyboard") matches a finer one.
- **Core assumption:** The optimal segmentation scale for an object is unknown a priori and varies significantly within a single image.
- **Evidence anchors:** [Abstract] Mentions employing "multiple intermediate granularities for varying image objects." [Section III.A] Visualizes how fixed granularity (N=25) fragments shelves or merges toys, while [Section III.B] defines the "1+M+N" aggregation logic. [Corpus] The related paper "POQD" establishes the "1+N" baseline this method improves upon.
- **Break condition:** If visual features are scale-invariant or if the embedding model already captures global-to-local relations effectively, hierarchical decomposition adds computational overhead without retrieval gain.

### Mechanism 2
- **Claim:** Pruning candidate images at coarser granularities likely preserves retrieval accuracy while reducing computation, provided ground-truth images maintain high rank across hierarchy levels.
- **Mechanism:** The system exploits "Cross-Hierarchy Consistency." It iterates from coarse to fine granularities, sorting images by similarity and pruning the bottom percentage ($t_g$) at each step (Alg. 1, L.4–L.6). This prevents expensive fine-grained embeddings from being computed for clearly irrelevant images.
- **Core assumption:** Relevant images appear near the top of the ranking list even at low resolutions.
- **Evidence anchors:** [Abstract] Claims reduction of computation by "up to 3.5 times." [Section IV.B] Fig. 4a shows ground-truth images consistently appear in top ranks across granularities; text describes the pruning logic. [Corpus] Weak corpus support; related works focus on index-level acceleration (e.g., HNSW in Faiss) rather than algorithmic redundancy pruning.
- **Break condition:** If a relevant image is visually homogeneous at coarse scales (hiding the specific object of interest) but distinct at fine scales, it risks being pruned prematurely.

### Mechanism 3
- **Claim:** Terminating the hierarchy search early upon rank stabilization can minimize unnecessary matching steps without substantial accuracy degradation.
- **Mechanism:** The system monitors the ranking of the top-$K$ results between consecutive granularities using Kendall's $\tau$ coefficient (Alg. 1, L.8–L.9). If the ranking order stabilizes ($\tau \ge$ threshold), it implies finer granularities are not changing the result order, and the process exits early.
- **Core assumption:** Retrieval convergence is often reached before the finest granularity.
- **Evidence anchors:** [Section IV.C] Fig. 4c shows Kendall's $\tau$ converging across datasets, validating the early-exit opportunity. [Section VI.B] Results show "Hierarchy Depth Optimization" (O1) adds a ~40% throughput gain.
- **Break condition:** If a dataset contains many "hard negatives" that only distinguish themselves at very fine granularities, early exit may yield false positives.

## Foundational Learning

- **Concept:** Multi-Vector Retrieval (MVR)
  - **Why needed here:** HiMIR builds upon the "1+N" MVR paradigm (specifically POQD), where queries and images are split into multiple vectors for finer matching.
  - **Quick check question:** How does scoring a "Max" similarity across segments differ from a single dot product between global vectors?

- **Concept:** SLIC (Simple Linear Iterative Clustering)
  - **Why needed here:** The paper uses SLIC for the "image decomposition" step. Understanding that this creates superpixels/patches of varying sizes is crucial to grasping the alignment problem.
  - **Quick check question:** Why would a clustering-based segmentation method be preferred over a fixed grid for this specific retrieval task?

- **Concept:** Kendall's $\tau$ Coefficient
  - **Why needed here:** This statistical metric is the core signal for the "Early Retrieval Convergence" optimization.
  - **Quick check question:** In the context of Alg. 1, does a high $\tau$ value indicate the results are getting better or just that they are staying the same?

## Architecture Onboarding

- **Component map:** Offline Profiler -> Hierarchy Sparsity (O3) -> Online Query Decomposer (LLM) -> Hierarchical Scheduler (Alg 1) -> [Granularity Loop: Image Retrieval -> Pruning (O2) -> Stability Check (O1)]

- **Critical path:** The online latency is dominated by the inner loop of Alg. 1, specifically the similarity computation (L.5) which scales with $N_q \times N_D \times N_g$.

- **Design tradeoffs:**
  - **Accuracy vs. Latency:** Controlled by pruning aggressiveness ($T, \alpha$) and early-exit threshold ($\tau$).
  - **Flexibility vs. Overhead:** A smaller granularity stride ($S_G$) increases hierarchy depth ($M$), offering better alignment potential but increasing scheduling overhead.

- **Failure signatures:**
  - **Accuracy collapse at high speeds:** Check if $T$ (initial reduction ratio) is too aggressive or $\tau$ is too low, causing premature pruning or exit.
  - **Stagnant latency:** Verify if the "Hierarchy Sparsity" optimization (O3) is disabled, causing the system to iterate over redundant granularity levels.

- **First 3 experiments:**
  1. **Ablation on Granularity:** Run "1+N" (baseline) vs. "1+M+N" (no opts) to isolate the accuracy gain from the hierarchical structure alone.
  2. **Redundancy Validation:** Plot throughput vs. $\tau$ to visualize the "free lunch" zone where speed increases significantly before accuracy drops (Sec VI.B, Fig 7).
  3. **Profile Dataset:** Run the automated configuration (Sec V) on a new dataset to see if the system selects significantly different $S_G$ or $T$ values compared to the defaults for CREPE/Flickr.

## Open Questions the Paper Calls Out
- The paper notes that HiMIR "opens up opportunities for broader integration with multimodal LLM systems" and calls for "further optimization of specific applications," suggesting potential for end-to-end training or feedback loops within Multimodal LLM generation pipelines.

## Limitations
- The automated configuration framework is underspecified, with unclear grid search ranges and convergence criteria for SETGRAN, making it difficult to assess the optimality of reported parameters.
- The assumption that "relevant images maintain high rank across hierarchy levels" may not hold for all datasets or query types, particularly those with subtle visual differences.
- The paper does not analyze failure cases where relevant images are pruned during the cross-hierarchy pruning optimization.

## Confidence

- **Mechanism 1 (Hierarchical Granularity):** Medium confidence. The theoretical benefit is clear, but experimental validation is limited to qualitative examples and a single ablation.
- **Mechanism 2 (Cross-Hierarchy Pruning):** Medium confidence. Algorithmically sound with some evidence, but lacks analysis of failure cases where relevant images are pruned.
- **Mechanism 3 (Early Retrieval Convergence):** High confidence. Straightforward optimization with clear statistical grounding and strong experimental support.

## Next Checks

1. **Ablation on Granularity Depth:** Conduct a controlled experiment isolating the impact of $M$ (number of hierarchy levels) by comparing "1+N" (POQD baseline) vs. "1+M+N" with optimizations disabled. Measure the marginal accuracy gain from adding each hierarchy level.

2. **Pruning Robustness Analysis:** On a challenging subset of the MS COCO dataset (e.g., images with subtle differences), measure the recall of ground-truth images after each pruning step. This will reveal the failure rate of the "Cross-Hierarchy Consistency" assumption.

3. **Automated Configuration Stress Test:** Apply the Profiler to a new, diverse dataset (e.g., Flickr30k) and compare the selected parameters ($T, \alpha, \tau, S_G$) to those chosen for CREPE. Analyze if the configuration framework consistently selects sensible values or if it overfits to specific dataset characteristics.