---
ver: rpa2
title: 'An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing
  Active Network of Concepts with Energy E3'
arxiv_id: '2601.08224'
source_url: https://arxiv.org/abs/2601.08224
tags:
- tokens
- system
- gestalt
- intelligence
- events
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes SANC(E3), an axiomatic framework for general\
  \ intelligence in which representational units are not given a priori but instead\
  \ emerge as stable outcomes of competitive selection, reconstruction, and compression\
  \ under finite activation capacity, governed by explicit minimization of an energy\
  \ functional E3 = \u03BB1Lrec + \u03BB2Cstruct + \u03BB3Cupdate. The framework introduces\
  \ five core axioms formalizing finite capacity, association from co-occurrence,\
  \ similarity-based competition, confidence-based stabilization, and the reconstruction-compression-update\
  \ trade-off, along with a pseudo-memory-mapped I/O mechanism that unifies perception,\
  \ imagination, prediction, planning, and action under a single representational\
  \ process."
---

# An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3

## Quick Facts
- arXiv ID: 2601.08224
- Source URL: https://arxiv.org/abs/2601.08224
- Authors: Daesuk Kwon; Won-gi Paeng
- Reference count: 36
- Primary result: Proposes an axiomatic framework where representational units emerge as stable outcomes of energetic trade-offs rather than being pre-defined, unifying perception, prediction, imagination, and action under a single process.

## Executive Summary
This paper introduces SANC(E3), a formal axiomatic framework for general intelligence where representational units (tokens) emerge through self-organization rather than being pre-defined. The framework is governed by explicit minimization of an energy functional E3 = λ1Lrec + λ2Cstruct + λ3Cupdate, which balances reconstruction accuracy, structural complexity, and update cost under finite activation capacity. Five core axioms formalize how finite capacity, association from co-occurrence, similarity-based competition, confidence-based stabilization, and the reconstruction-compression-update trade-off drive the emergence of stable concepts and hierarchical organization.

The key contribution is demonstrating that tokens, categories, hierarchy, and forgetting are necessary structural consequences of the axioms rather than design choices. Twelve propositions derived from the axioms show that high-level cognitive activities such as dialogue, authoring, causal inference, and self-improvement are all instances of Gestalt completion under E3 minimization. The framework introduces a pseudo-memory-mapped I/O mechanism that unifies perception, imagination, prediction, planning, and action within a single representational process.

## Method Summary
The SANC(E3) framework formalizes general intelligence through five axioms governing self-organizing networks of concepts under finite capacity constraints. The method defines an energy functional E3 that balances three competing forces: reconstruction loss (λ1Lrec), structural complexity (λ2Cstruct), and update cost (λ3Cupdate). Tokens emerge as stable equilibria from competitive selection among candidate representations based on similarity and confidence scores. The framework unifies cognitive processes through Gestalt completion, where partial patterns are internally completed to generate predictions, imaginations, or actions. The axiomatic approach derives twelve propositions showing that category formation, hierarchical organization, and forgetting are necessary consequences of the energetic constraints rather than design choices.

## Key Results
- Representational units emerge as stable outcomes of competitive selection, reconstruction, and compression under finite activation capacity
- Tokens, categories, hierarchy, and forgetting are necessary structural consequences of the axioms rather than design choices
- Prediction, imagination, and action are computationally identical processes of Gestalt completion under E3 minimization
- The framework unifies perception, imagination, prediction, planning, and action within a single representational process

## Why This Works (Mechanism)

### Mechanism 1: Trade-off Driven Token Emergence
The system minimizes an energy functional E3 = λ1Lrec + λ2Cstruct + λ3Cupdate. High reconstruction loss triggers new associations, high structural complexity forces merging of similar units, and high update cost resists changing existing structures. The three-way optimization creates stable representational units as equilibria. If λ3 is infinite, the system becomes rigid and cannot form new tokens from new experiences.

### Mechanism 2: Similarity-Based Competition and Forgetting
Finite capacity forces competition among similar candidates through selection operator Πt. Winners reinforce their confidence degree while losers decay toward zero and are eventually deleted. The system has a valid similarity metric simt to cluster candidates for competition. If capacity C is unbounded, the pressure to compress and categorize vanishes, leading to memorization without abstraction.

### Mechanism 3: Unified Gestalt Completion (Prediction as Reconstruction)
The pseudo-memory-mapped I/O mechanism treats prediction, imagination, and action as identical processes of completing partial internal patterns. When a partial event sequence is observed, the system retrieves a matching Gestalt and extends it internally for prediction or executes motor components for action. If the environment is purely stochastic with zero statistical regularity, Gestalts cannot form and completion yields random noise.

## Foundational Learning

- **Concept: Energy-Based Models (EBMs)**
  - Why needed here: The core of SANC is explicit definition and minimization of energy E3. Without understanding EBMs, the trade-off between reconstruction and complexity is opaque.
  - Quick check question: Can you explain why minimizing "free energy" or "surprise" might lead an agent to form stable internal representations of the world?

- **Concept: Hebbian Learning / Association**
  - Why needed here: Axiom A5 formalizes Hebbian theory ("fire together, wire together") as the engine of token creation through co-occurrence.
  - Quick check question: If two distinct visual patterns always appear simultaneously, how would a Hebbian mechanism represent them compared to a standard feedforward classifier?

- **Concept: Gestalt Psychology**
  - Why needed here: The framework relies on "the whole is other than the sum of the parts" to justify treating stabilized tokens as functional units distinct from raw sensory components.
  - Quick check question: How does perceiving a "melody" (whole) differ from perceiving a sequence of "notes" (parts) in this architecture?

## Architecture Onboarding

- **Component map:**
  Σsys (System Tokens) -> St (Candidate Set) -> Πt (Selection Operator) -> E3 Evaluator -> Token Stabilization/Decay

- **Critical path:**
  1. Events e enter the system
  2. A5 triggers candidate generation G(x,y) based on co-occurrence with active units
  3. A2 applies Πt to select winners based on similarity and capacity
  4. A4 checks reconstruction success (Lrec)
  5. If reconstruction fails, new tokens are formed; if successful, existing tokens are reinforced (A3)

- **Design tradeoffs:**
  - Lambda Tuning (λ1, λ2, λ3): High λ1 creates detailed but expensive memory; high λ2 creates sparse abstract memory that may miss details
  - Token Stability Threshold (θstab): Low thresholds cause "token explosion"; high thresholds make learning slow and rigid

- **Failure signatures:**
  - Token Explosion: Inventory Σt grows unbounded, causing capacity overflow. Likely cause: λ2 too low relative to λ1
  - Catastrophic Forgetting: Rapid loss of old skills upon learning new ones. Likely cause: λ3 too low, allowing new experience to overwrite old structures
  - Catatonic State: No new tokens formed; system predicts everything as "unknown." Likely cause: Thresholds θerr or θstab too high

- **First 3 experiments:**
  1. Capacity Stress Test: Feed distinct patterns while tightening capacity C. Verify category formation occurs and system prefers compressing similar inputs into shared tokens
  2. Prediction-Action Validation: Train on sequence A→B→C, present only A, verify internal completion activates B and C, and connecting to motor output produces action corresponding to C
  3. Self-Organization Verification: Initialize with zero non-system tokens, feed raw sensory data, verify Σt populates from scratch without manual intervention

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a computable algorithm be constructed that strictly satisfies Axioms A1–A10 and demonstrates the emergence of representational tokens from raw data?
- Basis in paper: [explicit] Section 9.2 states implementing an algorithm that fully satisfies this axiomatic system is a necessary step toward achieving artificial general intelligence
- Why unresolved: The paper provides an axiomatic framework but explicitly "does not prescribe a unique algorithm" for satisfying the constraints
- What evidence would resolve it: A functional prototype that generates tokens from raw character streams across hierarchical levels without pre-defined vocabularies

### Open Question 2
- Question: Can the SANC(E3) framework be extended to embodied agents where energy minimization is coupled with irreversible motor consequences?
- Basis in paper: [explicit] Section 9.2 notes that extending the framework to embodied agents—coupling E3 to irreversible motor consequences—remains the principal theoretical task
- Why unresolved: While the paper proposes that action is a form of Gestalt completion, it acknowledges the theoretical extension to physical irreversibility is unfinished
- What evidence would resolve it: A robotic system successfully utilizing E3 minimization for adaptive control in a dynamic physical environment

### Open Question 3
- Question: How should the weighting constants (λ1, λ2, λ3) and capacity bounds be dynamically determined to ensure the system converges on a token-sequence balance?
- Basis in paper: [inferred] Axiom A4 defines the energy functional with these constants, and Proposition T12 states thresholds are "systemically determined," but no specific mechanism for setting these values is provided
- Why unresolved: The paper asserts that a balance (T4) and threshold tuning (T12) occur, but leaves the specific adjustment scheme "implementation-dependent"
- What evidence would resolve it: Demonstration of an autonomous meta-learning rule that adjusts λ values to prevent token or sequence explosion

## Limitations

- The energy functional E3 requires explicit definitions for reconstruction loss, structural cost, and update cost that are context-dependent and potentially intractable for complex domains
- The similarity metric simt needed for competitive selection lacks a general formulation applicable across sensory modalities
- The framework assumes temporal events form coherent Gestalts, which may not hold in highly stochastic environments
- The stability thresholds and weighting coefficients (λ values) require domain-specific tuning that could significantly impact emergent behavior

## Confidence

**High Confidence**: The axiomatic structure itself is logically sound and the twelve derived propositions follow rigorously from the five axioms. The core insight that representational units emerge from energetic trade-offs rather than being pre-defined is well-supported theoretically.

**Medium Confidence**: The unification of prediction, imagination, and action under Gestalt completion is conceptually compelling and mathematically consistent, but requires empirical validation in implementation. The claim that tokens, categories, and hierarchy are necessary consequences of finite capacity and energetic constraints follows logically from the axioms.

**Low Confidence**: The practical feasibility of computing and minimizing E3 in real-time systems with complex, high-dimensional inputs remains unproven. The scalability of the competitive selection mechanism to large candidate sets and the robustness of the system to noise and adversarial inputs are open questions.

## Next Checks

1. **Minimal Viable Implementation**: Build a simplified version of SANC(E3) with 1D temporal patterns and implement the three energy terms explicitly. Verify that tokens emerge from scratch without pre-defined primitives and that the system exhibits the predicted trade-offs between reconstruction, compression, and update.

2. **Capacity vs. Abstraction Trade-off**: Systematically vary the capacity constraint C while measuring the compression ratio and reconstruction error. Confirm that finite capacity forces category formation (T5) and that this relationship follows the predicted energetic dynamics.

3. **Cross-Domain Transfer Test**: Train the system on one domain (e.g., visual patterns), then test its ability to complete Gestalts in a structurally similar but novel domain (e.g., auditory patterns). Verify that the self-organizing mechanism transfers without domain-specific retraining, supporting the claim of general intelligence.