---
ver: rpa2
title: 'From Associations to Activations: Comparing Behavioral and Hidden-State Semantic
  Geometry in LLMs'
arxiv_id: '2602.00628'
source_url: https://arxiv.org/abs/2602.00628
tags:
- similarity
- behavioral
- hidden-state
- task
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how well behavioral data from psycholinguistic\
  \ tasks can recover a large language model\u2019s internal semantic structure. Across\
  \ eight instruction-tuned transformer models, the authors collected over 17.5 million\
  \ trials using similarity-based forced-choice and free-association paradigms over\
  \ a shared 5,000-word vocabulary."
---

# From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs

## Quick Facts
- **arXiv ID**: 2602.00628
- **Source URL**: https://arxiv.org/abs/2602.00628
- **Reference count**: 40
- **Primary result**: Behavioral data from similarity tasks can recover LLM internal semantic structure

## Executive Summary
This study investigates whether behavioral data from psycholinguistic tasks can recover a large language model's internal semantic structure. The authors collected over 17.5 million trials using similarity-based forced-choice and free-association paradigms across eight instruction-tuned transformer models with a shared 5,000-word vocabulary. They compared behavior-derived similarity matrices to layerwise hidden-state similarities using representational similarity analysis and ridge regression.

The results show that forced-choice behavior aligns substantially more with hidden-state geometry than free association, and behavioral similarity—especially forced choice—predicts unseen hidden-state similarities beyond lexical baselines and cross-model consensus. This indicates that structured behavioral measurements retain recoverable information about a model's internal semantic geometry, bridging behavioral and mechanistic approaches to understanding LLM semantics.

## Method Summary
The study collected behavioral data through automated prompting of eight instruction-tuned transformer models using similarity-based forced-choice and free-association paradigms over a 5,000-word vocabulary. The authors generated over 17.5 million trials across these models. They compared the resulting behavior-derived similarity matrices with layerwise hidden-state similarities using representational similarity analysis (RSA) and ridge regression. The analysis focused on measuring how well behavioral patterns aligned with internal semantic geometry at different layers of the transformer models, and whether behavioral similarity could predict hidden-state similarities beyond what lexical baselines or cross-model consensus would suggest.

## Key Results
- Forced-choice behavior aligned substantially more with hidden-state geometry than free association across all tested models
- Behavioral similarity, particularly from forced-choice tasks, predicted unseen hidden-state similarities beyond lexical baselines
- The behavioral-to-hidden-state mapping worked across different layers and models, indicating generalizable patterns

## Why This Works (Mechanism)
The behavioral tasks tap into semantic relationships that LLMs have learned during training, and these relationships are encoded in the model's internal representations. When models perform similarity judgments, they implicitly access their learned semantic geometry, which is reflected in both their behavior and hidden states. The forced-choice paradigm provides more structured, explicit judgments that better align with the model's internal similarity computations compared to free association. The ridge regression and RSA methods effectively bridge the gap between behavioral outputs and internal representations by finding linear mappings between them, suggesting that the behavioral data captures sufficient information about the model's semantic structure to enable recovery of hidden-state patterns.

## Foundational Learning
- **Representational Similarity Analysis (RSA)**: A technique for comparing the representational geometries of different systems by analyzing the similarity structures between their internal representations. Why needed: To quantify how well behavioral similarity matrices match hidden-state similarity matrices. Quick check: Can you explain how RSA differs from direct vector comparison?
- **Ridge Regression**: A regularized linear regression technique that prevents overfitting by adding a penalty term to the loss function. Why needed: To find stable mappings between behavioral and hidden-state similarities without overfitting to noise. Quick check: What role does regularization play in this analysis?
- **Instruction-tuned Transformers**: Transformer models fine-tuned on instruction-following datasets to improve their ability to follow prompts and generate appropriate responses. Why needed: The study specifically examines this model family to understand how instruction tuning affects behavioral and internal semantic alignment. Quick check: How might results differ for base models vs. instruction-tuned models?

## Architecture Onboarding

**Component Map**: Behavioral Data Collection -> Similarity Matrix Construction -> RSA/Regression Analysis -> Hidden-State Comparison

**Critical Path**: The core analytical pipeline moves from collecting behavioral similarity judgments through automated prompting, constructing behavioral similarity matrices, computing hidden-state similarity matrices from model activations, and finally comparing these using RSA and ridge regression to assess alignment and predictive power.

**Design Tradeoffs**: The study chose automated prompting over human participants for scalability and consistency, accepting potential limitations in ecological validity. They used a fixed 5,000-word vocabulary to enable direct comparison across models but limited exploration of broader semantic relationships. The forced-choice paradigm provides more structured data but may constrain natural semantic associations compared to free association.

**Failure Signatures**: Poor alignment between behavioral and hidden-state similarities could indicate either that the behavioral tasks don't capture the model's actual semantic processing, or that the model's semantic structure isn't well-represented in pairwise similarities. Limited predictive power beyond lexical baselines would suggest the behavioral data doesn't contain unique information about internal representations.

**First Experiments**: 1) Replicate the analysis using a different vocabulary size to test robustness to lexical coverage. 2) Apply the same behavioral-to-hidden-state mapping approach to a single layer to understand layer-specific patterns. 3) Test the predictive power of behavioral data on a held-out set of semantic relationships not used in training the mapping.

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis is limited to instruction-tuned transformer models, restricting generalizability to other model families
- Behavioral data collection relied on automated prompting rather than human participants, raising ecological validity concerns
- The study focuses on pairwise similarity judgments within a fixed vocabulary, potentially missing broader or contextualized semantic relationships

## Confidence
- High confidence: Forced-choice behavior aligns substantially better with hidden-state geometry than free association
- Medium confidence: Behavioral similarity predicts unseen hidden-state similarities beyond lexical baselines
- Medium confidence: Structured behavioral measurements retain recoverable information about internal semantic geometry

## Next Checks
1. Replicate the analysis using human-generated behavioral data for the same semantic tasks to validate whether automated prompting captures comparable semantic relationships
2. Test the behavioral-to-hidden-state mapping approach on non-transformer architectures (e.g., recurrent models, convolutional language models) to assess generalizability across model families
3. Extend the vocabulary size and task complexity beyond pairwise similarity to include higher-order semantic relationships and contextualized word usage patterns