---
ver: rpa2
title: Task-Uniform Convergence and Backward Transfer in Federated Domain-Incremental
  Learning with Partial Participation
arxiv_id: '2601.22274'
source_url: https://arxiv.org/abs/2601.22274
tags:
- learning
- task
- local
- tasks
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles Federated Domain-Incremental Learning (FDIL),
  a challenging setting where tasks arrive sequentially with domain shifts but a fixed
  label space, and data cannot be shared across clients due to privacy. Existing FDIL
  methods struggle to guarantee both backward knowledge transfer (preserving performance
  on earlier tasks) and a task-uniform convergence rate under realistic partial client
  participation.
---

# Task-Uniform Convergence and Backward Transfer in Federated Domain-Incremental Learning with Partial Participation

## Quick Facts
- arXiv ID: 2601.22274
- Source URL: https://arxiv.org/abs/2601.22274
- Authors: Longtao Xu; Jian Li
- Reference count: 40
- Primary result: Proposed SPECIAL achieves task-uniform convergence rate O(√(E/(NT))) for non-convex objectives in FDIL with partial client participation

## Executive Summary
This paper addresses Federated Domain-Incremental Learning (FDIL), where sequential tasks arrive with domain shifts but fixed label spaces, and data privacy prevents sharing across clients. The authors identify key challenges: ensuring backward knowledge transfer (preserving performance on earlier tasks) and achieving task-uniform convergence under realistic partial client participation. Existing FDIL methods struggle to provide both guarantees simultaneously.

The authors propose SPECIAL, a simple, memory-free algorithm that adds a server-side proximal anchor to FedAvg. This anchor nudges the aggregated model toward the previous global model, curbing drift without requiring replay buffers or synthetic data. The approach achieves theoretical guarantees for backward transfer and task-uniform convergence while maintaining practical effectiveness across multiple benchmark datasets.

## Method Summary
SPECIAL introduces a server-side proximal anchor mechanism that modifies the standard FedAvg aggregation process. During each round, after collecting client updates, the server aggregates them as usual but then applies a proximal term that pulls the new global model toward the previous global model. This simple modification creates a drift-controlling effect that preserves knowledge of earlier tasks while still allowing adaptation to new domains. The algorithm is memory-free, requiring no replay buffers or synthetic data generation, making it practical for real-world federated settings where storage and computation resources are limited.

## Key Results
- Achieves the first task-uniform convergence rate O(√(E/(NT))) for non-convex objectives in FDIL under partial participation
- Provides theoretical guarantees for backward knowledge transfer with drift-controlled terms that shrink with more rounds, epochs, and participation
- Outperforms other memory-free methods on four datasets (Digit-10, VLCS, PACS, DN4IL) in average accuracy while maintaining competitive backward transfer
- Ablation studies validate the theoretical trade-offs between stability and plasticity in the proximal anchor mechanism

## Why This Works (Mechanism)

The proximal anchor mechanism works by creating a stability-plasticity balance in the federated learning process. By pulling the aggregated model toward its previous state, it prevents catastrophic forgetting of earlier tasks while still allowing sufficient adaptation to new domains. The drift-controlled term ensures that as training progresses (more rounds, epochs, and client participation), the interference between tasks diminishes, leading to improved backward transfer. The memory-free design avoids the computational overhead of maintaining replay buffers while still achieving competitive performance through the regularization effect of the proximal term.

## Foundational Learning

1. **Federated Domain-Incremental Learning (FDIL)**: Learning sequential tasks with domain shifts in a federated setting where data cannot be shared. Why needed: Real-world federated scenarios often involve evolving data distributions while maintaining privacy constraints.

2. **Backward Knowledge Transfer**: The ability of learning new tasks to improve or preserve performance on earlier tasks. Why needed: Critical for lifelong learning systems to avoid catastrophic forgetting.

3. **Task-Uniform Convergence**: Ensuring all tasks converge at similar rates rather than having some tasks converge much faster than others. Why needed: Prevents early tasks from being neglected as training progresses.

4. **Partial Client Participation**: Not all clients participate in every training round, reflecting realistic federated scenarios. Why needed: Most real-world federated systems cannot guarantee full participation due to device availability and network constraints.

5. **Proximal Optimization**: Using proximity terms to regularize optimization and prevent large parameter changes. Why needed: Provides stability in incremental learning while allowing adaptation.

6. **Non-convex Optimization**: Dealing with optimization landscapes that have multiple local minima, common in deep learning. Why needed: Most modern neural networks have non-convex loss surfaces.

## Architecture Onboarding

**Component Map**: Clients -> Local Training -> Server Aggregation -> Proximal Anchor -> Global Model

**Critical Path**: Client local training → Server aggregation → Proximal anchor application → Global model update

**Design Tradeoffs**: Memory-free approach trades off potential performance gains from replay buffers for practical feasibility and reduced computational overhead. The proximal anchor strength must balance between preventing drift (stability) and allowing adaptation (plasticity).

**Failure Signatures**: 
- Weak proximal anchor strength leads to catastrophic forgetting of earlier tasks
- Excessive proximal anchor strength prevents adaptation to new domains
- Poor hyperparameter tuning across datasets may result in suboptimal performance
- Strong domain drift between tasks may exceed the algorithm's ability to maintain backward transfer

**First Experiments**:
1. Evaluate SPECIAL on Digit-10 with varying client participation rates to assess robustness to participation patterns
2. Test sensitivity to proximal anchor hyperparameter across different domain shift magnitudes
3. Compare performance against memory-based methods on tasks requiring long-term retention of complex patterns

## Open Questions the Paper Calls Out

None specified in the provided content.

## Limitations

- Theoretical analysis relies on strong assumptions about bounded domain drift and convex/non-convex loss functions that may not hold in real-world scenarios
- Proximal anchor mechanism's effectiveness depends on hyperparameter selection, which could be sensitive to dataset characteristics
- Memory-free approach may limit performance on tasks requiring longer-term retention of complex patterns
- Analysis of partial client participation assumes uniform client availability, which may not reflect realistic federated settings with highly variable participation patterns

## Confidence

- Theoretical convergence rate (O(√(E/(NT)))) for non-convex objectives: High
- Backward knowledge transfer guarantees: Medium
- Task-uniform convergence under partial participation: Medium
- Practical effectiveness of proximal anchor mechanism: Medium

## Next Checks

1. Test SPECIAL on federated datasets with highly non-IID distributions and evaluate sensitivity to hyperparameter choices across different data characteristics
2. Extend theoretical analysis to scenarios with bursty or highly irregular client participation patterns
3. Compare SPECIAL's performance against memory-based methods on tasks requiring long-term retention of complex patterns