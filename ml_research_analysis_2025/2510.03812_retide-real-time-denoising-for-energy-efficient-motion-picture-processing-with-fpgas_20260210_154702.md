---
ver: rpa2
title: 'ReTiDe: Real-Time Denoising for Energy-Efficient Motion Picture Processing
  with FPGAs'
arxiv_id: '2510.03812'
source_url: https://arxiv.org/abs/2510.03812
tags:
- denoising
- image
- noise
- quantised
- ieee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ReTiDe addresses the need for efficient, scalable denoising in
  video pipelines by deploying a quantised convolutional neural network on FPGA accelerators.
  It converts a compact U-Net generator into INT8 format using post-training quantisation
  and quantisation-aware fine-tuning, enabling hardware-friendly inference.
---

# ReTiDe: Real-Time Denoising for Energy-Efficient Motion Picture Processing with FPGAs

## Quick Facts
- **arXiv ID:** 2510.03812
- **Source URL:** https://arxiv.org/abs/2510.03812
- **Reference count:** 11
- **Primary result:** INT8-quantized U-Net denoising on FPGA achieves 3,746.09 GOPS throughput and 203.59 GOPS/W energy efficiency, with 37.71× higher throughput and 5.29× greater energy efficiency than prior FPGA accelerators.

## Executive Summary
ReTiDe addresses the need for efficient, scalable denoising in video pipelines by deploying a quantised convolutional neural network on FPGA accelerators. It converts a compact U-Net generator into INT8 format using post-training quantisation and quantisation-aware fine-tuning, enabling hardware-friendly inference. The solution integrates with NUKE workflows through a client-server architecture that offloads computation from host CPU/GPU to networked FPGAs, preserving artist tooling. Evaluation shows ReTiDe achieves denoising quality close to FP32 baselines on both colour and grayscale images, with negligible PSNR loss. Performance-wise, it delivers 37.71× higher throughput and 5.29× greater energy efficiency than prior FPGA denoising accelerators, reaching 3,746.09 GOPS throughput and 203.59 GOPS/W energy efficiency on an Alveo U50 FPGA. The open-source system supports real-time, low-power denoising for encoding pipelines and post-production workflows.

## Method Summary
ReTiDe implements a 6-stage U-Net denoising architecture with INT8 quantization for FPGA deployment. The pipeline uses post-training quantization (PTQ) followed by quantization-aware training (QAT) fine-tuning to preserve quality. The model features LeakyReLU with hardware-optimized approximations (α=0.1015625≈26/256), transposed convolutions for upsampling, and skip connections for detail preservation. It removes batch normalization, dropout, and residual connections to simplify hardware mapping. The client-server architecture integrates with NUKE through extended message buffers, while Vitis-AI Docker container with VART/XRT runtime distributes tasks across multiple DPUs and processing elements on the Alveo U50 FPGA. Training uses AdamW optimization on 256×256 patches from DIV2K and LSDIR datasets with Gaussian noise (σ∈[0,50]), cosine annealing scheduler, and 64-batch sizes for 10,000 epochs, followed by 30 epochs of QAT fine-tuning.

## Key Results
- ReTiDe achieves 3,746.09 GOPS throughput and 203.59 GOPS/W energy efficiency on Alveo U50 FPGA
- 37.71× higher throughput and 5.29× greater energy efficiency compared to previous FPGA denoising accelerators
- PSNR degradation of only 1.09 dB and 0.0147 SSIM compared to FP32 model at noise level σ=45
- Superior detail preservation over L-DnCNN on Urban100 dataset due to encoder-decoder architecture with skip connections

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: INT8 quantization with QAT fine-tuning can preserve near-FP32 denoising quality while enabling efficient FPGA execution.
- **Mechanism**: PTQ converts FP32 weights/activations to 8-bit fixed-point using calibration data to compute scaling factors and zero-points. QAT inserts pseudo-quantization nodes into the computational graph during fine-tuning, allowing the model to adapt to quantization perturbations through gradient-based updates while maintaining FP32 master weights.
- **Core assumption**: Activation distributions captured during calibration are representative of inference-time data; the pseudo-quantization simulation accurately models hardware quantization behavior.
- **Evidence anchors**:
  - [abstract] "with negligible degradation in Peak Signal-to-Noise Ratio (PSNR)/Structural Similarity Index (SSIM)"
  - [section 4.3] "at noise level 45, our 8-bit quantised model is only 1.09 dB and 0.0147 away from the best 32-bit FP32 model in terms of PSNR and SSIM"
  - [corpus] Limited direct evidence in neighboring papers for QAT recovery in image denoising; FPGA-ML papers focus on different tasks
- **Break condition**: If deployment data distributions diverge significantly from calibration data; if quantization error dominates image noise in low-noise scenarios (σ≤15), causing relatively larger quality gaps.

### Mechanism 2
- **Claim**: Hardware-aware U-Net simplification with approximated activations enables efficient LUT-based FPGA mapping without critical quality loss.
- **Mechanism**: The architecture uses 6 downsampling stages (vs 8 in original U-Net), LeakyReLU with α=0.1015625 approximated as 26/256 for bit-shift implementation, omits batch normalization/dropout/residual connections to reduce memory access and control logic, while preserving skip connections for detail recovery.
- **Core assumption**: The approximated LeakyReLU coefficient provides sufficient gradient flow; removed regularization components are not critical for denoising generalization.
- **Evidence anchors**:
  - [section 3.1] "LeakyReLU coefficient α=0.1015625 is approximated as 26/256 on FPGA to enable efficient fixed-point implementation using integer multiplication and bit-shift operations"
  - [section 4.2] "The superior detail-preserving capability of ReTiDe compared to L-DnCNN can be attributed to its encoder-decoder architecture with skip connections"
  - [corpus] Neighbor papers (FINN-GL) explore mixed-precision but don't address activation approximation trade-offs for denoising specifically
- **Break condition**: If gradient vanishing occurs in deeper layers due to approximation; if out-of-distribution noise types require the removed regularization for generalization.

### Mechanism 3
- **Claim**: Hierarchical parallelization across multiple DPUs and PEs maximizes throughput while maintaining workflow compatibility via client-server architecture.
- **Mechanism**: Client-side NUKE plugin chunks 8K data and transmits via extended message buffers; server-side pre-processor segments images for parallel batching; VART/XRT runtime distributes tasks across multiple DPUs via PCIe; each DPU contains multiple PEs for fine-grained convolution parallelism; post-processor reassembles results.
- **Core assumption**: PCIe bandwidth and network latency don't negate throughput gains; image segmentation doesn't introduce visible boundary artifacts.
- **Evidence anchors**:
  - [abstract] "reaching 3,746.09 GOPS throughput and 203.59 GOPS/W energy efficiency"
  - [section 3.3] "tasks are distributed in parallel across multiple DPUs... where further parallelisation is achieved through multiple processing elements (PEs)"
  - [corpus] ApproXAI mentions energy-efficient acceleration but focuses on XAI rather than parallelization hierarchies
- **Break condition**: If PCIe Gen 3x4 bandwidth saturates before compute limits; if tile boundaries create visible seams; if network latency exceeds processing time savings for small batches.

## Foundational Learning

- **Concept: Quantization-Aware Training (QAT) vs Post-Training Quantization (PTQ)**
  - Why needed here: Understanding the two-stage quantization pipeline and why calibration alone is insufficient for quality preservation.
  - Quick check question: Based on Table 2, what is the PSNR gap between PTQ-only and QAT models at noise level σ=5 vs σ=45, and why does the gap differ?

- **Concept: U-Net Skip Connections for Detail Preservation**
  - Why needed here: Understanding why encoder-decoder with skip connections outperforms deep convolution stacking (DnCNN) for fine detail recovery.
  - Quick check question: In Figure 6, which facial features does ReTiDe preserve better than L-DnCNN, and what architectural component enables this?

- **Concept: DPU vs GPU Execution Models**
  - Why needed here: Understanding why quantized inference on DPU provides 5.29× energy efficiency gain over GPU despite lower peak compute.
  - Quick check question: What role does operator fusion play in the Vitis AI runtime, and how does it differ from GPU kernel execution?

## Architecture Onboarding

- **Component map**:
  - Client layer: NUKE ML plugin → Extended message buffer (8K support) → Network interface
  - Server layer: Pre-processor (segmentation/batching) → Vitis-AI Docker container → VART/XRT runtime → DPUs (0..m) → PEs (0..n) → Post-processor (reassembly)
  - Hardware layer: Alveo U50 with HBM, PCIe Gen 3x4 xDMA interface
  - Model layer: 6-stage U-Net (Conv2d+LeakyReLU down, TransposedConv+ReLU up, skip concatenation), compiled to xmodel

- **Critical path**:
  1. Image/video stream arrives at NUKE plugin
  2. Chunked into extended buffers, transmitted to server
  3. Pre-processor segments into tile batches matching DPU input format
  4. VART runtime dispatches batches to available DPUs via XRT
  5. Quantized convolutions execute on parallel PEs
  6. Post-processor reassembles tiles, returns to client

- **Design tradeoffs**:
  - INT8 precision vs FP32 quality: ~1dB loss at high noise, larger gap at low noise where quantization error dominates
  - Tile parallelism vs boundary artifacts: overlap strategy affects both quality and throughput
  - PCIe Gen 3x4 bandwidth vs throughput ceiling: explicitly identified as limiting factor
  - Blind denoising vs noise-specific models: flexibility traded for potential quality ceiling
  - Simplified architecture (no batch norm/dropout) vs generalization to unseen noise distributions

- **Failure signatures**:
  - Visible tile seams in output → segmentation overlap insufficient or misaligned
  - Color shifts in smooth regions → PTQ without QAT; quantization-induced noise visible
  - PSNR unexpectedly low at σ=5 → quantization error exceeding image noise; consider mixed-precision
  - Throughput far below 3,746 GOPS → single DPU active, batch size too small, or PCIe bottleneck
  - Model compilation errors → operator not supported in Vitis AI; check against supported op list

- **First 3 experiments**:
  1. Quantization recovery validation: Benchmark PTQ-only vs QAT models on BSD100 across σ∈{5,15,25,35,45}; quantify PSNR/SSIM recovery at each noise level; expect diminishing returns at higher noise where image noise dominates quantization error.
  2. DPU scaling analysis: Measure throughput with 1/2/3 active DPUs at fixed batch size; plot scaling efficiency; identify PCIe saturation point where additional DPUs provide no gain.
  3. Boundary artifact characterization: Process 4K/8K test images with varying tile overlap (0/8/16 pixels); measure visible seam frequency via edge detection on difference images; quantify throughput-vs-quality tradeoff curve.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can mixed-precision quantization effectively mitigate the performance degradation observed in low-noise scenarios (σ < 15) without compromising the throughput or energy efficiency gains established by the INT8 implementation?
- **Basis in paper**: [explicit] In Section 4.3, the authors note that "under low-noise conditions, quantisation error becomes the dominant factor," and explicitly state in the Conclusion that "hybrid-precision quantisation could mitigate this issue in future work."
- **Why unresolved**: The current ReTiDe model uses uniform INT8 quantization, which introduces noise floors that exceed the actual image noise in low-noise inputs, causing quality loss compared to FP32 baselines.
- **What evidence would resolve it**: A comparative analysis showing PSNR/SSIM recovery on low-noise datasets (e.g., BSD100, σ=5) using mixed-precision weights/activations, alongside updated GOPS/W metrics on the Alveo U50.

### Open Question 2
- **Question**: How does the quantized ReTiDe-Net perform when exposed to non-Gaussian, real-world sensor noise (e.g., shot noise, fixed-pattern noise) compared to the synthetic Gaussian noise used in the current evaluation?
- **Basis in paper**: [explicit] The Conclusion identifies the need for "incorporating... real-world image noise to improve the practical applicability of the proposed solution," while Section 2.1 acknowledges the complexity of noise types like photon shot noise.
- **Why unresolved**: The model was trained and evaluated exclusively using Gaussian noise distributions (Section 4.1), leaving its generalization capabilities for the diverse noise profiles found in cinema post-production and smartphone imaging unproven.
- **What evidence would resolve it**: Benchmark results on datasets containing real sensor noise (e.g., SIDD, PolyU) comparing the INT8 model's restoration quality against FP32 denoisers.

### Open Question 3
- **Question**: What specific trade-offs in detail preservation versus hardware efficiency were introduced by removing normalization, dropout, and residual connections from the U-Net generator?
- **Basis in paper**: [explicit] The Conclusion calls for "conducting systematic model ablation studies to gain deeper insights into design trade-offs." Section 3.1 details that these components were omitted to "simplify the design and reduce hardware cost."
- **Why unresolved**: While the paper demonstrates the final model is efficient, it does not isolate the specific quality cost of these architectural simplifications, making it unclear if the hardware savings justified the potential loss of feature fidelity.
- **What evidence would resolve it**: An ablation study comparing the PSNR/SSIM and resource utilization (BRAM/DSP) of the simplified model against a version equipped with residual connections and normalization layers.

### Open Question 4
- **Question**: To what extent can model sparsification be combined with the existing INT8 quantization to further improve energy efficiency (GOPS/W) on the FPGA accelerator?
- **Basis in paper**: [explicit] The Conclusion explicitly lists "exploring model sparsification to achieve even greater energy efficiency" as a primary direction for future work.
- **Why unresolved**: The current work focuses on density-preserving quantization; the potential additional gains from pruning zero-weight connections (and the associated compiler support for sparse DPUs) remain unquantified.
- **What evidence would resolve it**: Energy efficiency measurements (GOPS/W) and resource usage for a pruned version of ReTiDe-Net deployed on the Alveo U50.

## Limitations

- Gaussian noise only: The model is evaluated exclusively on synthetic Gaussian noise, leaving real-world noise type generalization unproven.
- PCIe bottleneck: Explicit throughput ceiling due to PCIe Gen 3x4 bandwidth limiting multi-DPU scaling efficiency.
- Network latency impact: Client-server architecture benefits for small batch sizes not quantified, potentially negating throughput gains.

## Confidence

- **High confidence**: FPGA performance metrics (GOPS, energy efficiency) - measured on specific hardware with reproducible benchmarks
- **Medium confidence**: Quality preservation claims - PSNR/SSIM comparisons are robust, but real-world noise generalization is untested
- **Medium confidence**: Architectural choices - skip connections are well-established, but removal of regularization components lacks ablation study
- **Low confidence**: Client-server workflow benefits - latency impact and small-batch performance not quantified

## Next Validation Checks

1. **Cross-noise generalization**: Evaluate ReTiDe on non-Gaussian noise types (Poisson, salt-and-pepper, JPEG compression) to verify architectural simplifications don't compromise robustness.
2. **Batch-size sensitivity analysis**: Measure latency and throughput for batch sizes from 1-64 to identify optimal operating points and quantify network overhead impact.
3. **Tile boundary artifact quantification**: Systematically vary tile overlap and measure seam visibility across different image content types (smooth gradients, high-frequency textures, edges) to optimize the quality-throughput tradeoff.