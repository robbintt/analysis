---
ver: rpa2
title: Dissecting Role Cognition in Medical LLMs via Neuronal Ablation
arxiv_id: '2510.24677'
source_url: https://arxiv.org/abs/2510.24677
tags:
- medical
- role
- reasoning
- different
- prompts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines whether role prompts in medical large language
  models (LLMs) truly induce role-specific cognitive reasoning or merely change linguistic
  style. The authors introduce the RP-Neuron-Activated Evaluation Framework (RPNA)
  to test this by analyzing accuracy, neuron activation patterns, representation structure,
  and layer-wise divergence.
---

# Dissecting Role Cognition in Medical LLMs via Neuronal Ablation

## Quick Facts
- **arXiv ID**: 2510.24677
- **Source URL**: https://arxiv.org/abs/2510.24677
- **Reference count**: 37
- **Primary result**: Role prompts in medical LLMs primarily affect linguistic style rather than inducing distinct cognitive reasoning pathways.

## Executive Summary
This paper investigates whether role-playing prompts in medical large language models truly induce role-specific cognitive reasoning or merely alter linguistic style. Using the Role Prompt Neuron-Activated Evaluation Framework (RPNA), the authors analyze accuracy, neuron activation patterns, representation structure, and layer-wise divergence across three medical QA datasets and multiple model sizes. Results show that role prompts do not significantly enhance medical reasoning abilities, with neuron ablation revealing consistent performance drops across roles and no evidence of distinct reasoning pathways. Representation analysis indicates high similarity in hidden states, and layer-wise divergence diminishes in deeper layers. Overall, role prompts mainly affect linguistic style rather than genuine cognitive differentiation, highlighting limitations in current role-playing methods for medical AI.

## Method Summary
The study employs the RPNA framework to test role prompt effects through five stages: (1) constructing role prompts for 10 medical doctor roles using GPT-4o, (2) evaluating multiple-choice accuracy on MedQA, MedMCQA, and MMLU-Med datasets, (3) identifying role-sensitive neurons via activation differencing between role-prompted and baseline conditions, (4) ablating selected neurons and testing both within-role and cross-role masking effects, and (5) analyzing representation similarity using CKA, PCA, and JSD metrics. The framework tests Qwen2.5-7B/14B/32B/72B-Instruct models with greedy decoding, comparing performance across roles to determine if distinct reasoning pathways exist.

## Key Results
- Role prompts do not significantly enhance medical reasoning abilities compared to baseline conditions
- Neuron ablation shows consistent performance drops across all roles with no evidence of distinct reasoning pathways
- Representation analysis reveals high similarity in hidden states across different role conditions
- Layer-wise divergence peaks in early layers but diminishes in deeper layers, suggesting superficial rather than cognitive effects

## Why This Works (Mechanism)

### Mechanism 1: Role-Specific Neuron Selection via Activation Differencing
- Claim: Neurons with highest activation divergence between role-prompted and baseline conditions identify role-sensitive units
- Core assumption: Activation magnitude differences correlate with functional importance for role-conditioned behavior
- Evidence anchors: [abstract] "employing neuron ablation and representation analysis techniques to assess changes in reasoning pathways"; [section 1.4] "This method quantifies the impact of role prompts on the model's internal representations by comparing the hidden state activations under role-playing conditions... and neutral conditions"
- Break condition: If randomly selected neurons produce equivalent performance drops to role-selected neurons, the selection method lacks specificity

### Mechanism 2: Layer-Wise Representation Convergence Detects Stylistic vs. Cognitive Effects
- Claim: Role prompts affect shallow-to-mid layers but converge in deeper layers, indicating surface-level rather than reasoning-level modulation
- Core assumption: Persistent deep-layer divergence would indicate genuine cognitive differentiation; convergence indicates superficial modulation
- Evidence anchors: [abstract] "layer-wise divergence diminishes in deeper layers"; [section 1.9] "significant differences in JSD... were concentrated in the model's shallow-to-mid layers... as the Transformer layers deepen, the representation differences diminish and converge"
- Break condition: If deep-layer divergence remains high across roles, role prompts may induce genuine cognitive differentiation

### Mechanism 3: Cross-Role Ablation Equivalence Indicates Shared Reasoning Substrate
- Claim: Ablating neurons identified for Role A produces similar performance degradation when applied to Role B, indicating no role-specific circuits
- Core assumption: Distinct cognitive pathways would show asymmetric vulnerability—within-role damage should exceed cross-role damage
- Evidence anchors: [abstract] "no evidence of distinct reasoning pathways"; [section 1.7] "cross-role neuron masking experiments showed that the performance drops between roles were almost identical, with no significant differences"
- Break condition: If within-role ablation consistently outperforms cross-role ablation in degradation magnitude, role-specific pathways may exist

## Foundational Learning

- Concept: **Hidden State Representations in Transformers**
  - Why needed here: The entire RPNA framework relies on extracting and comparing hidden states across layers to measure where and how role prompts influence computation
  - Quick check question: Can you explain what h_l ∈ R^(1×T×d) represents in a Transformer, and why mean pooling over tokens is used before comparison?

- Concept: **Ablation as Causal Intervention**
  - Why needed here: Neuron ablation tests whether specific units are necessary for role-conditioned behavior; understanding causality vs. correlation is critical
  - Quick check question: Why is random ablation used as a baseline, and what conclusion would you draw if random and role-selected ablation produced identical accuracy drops?

- Concept: **Representation Similarity Metrics (CKA, JSD, PCA)**
  - Why needed here: Quantifying whether role prompts produce separable representation spaces requires formal similarity measures beyond visual inspection
  - Quick check question: What does a CKA value of 0.98 between two role conditions imply about their representational structure?

## Architecture Onboarding

- Component map: PBRP prompt construction → QA accuracy evaluation → neuron selection via activation differencing → ablation (within-role and cross-role) → representation analysis (CKA/PCA/JSD/clustering)
- Critical path: Neuron selection → ablation → accuracy delta comparison is the causal core; representation analysis provides convergent validation but is not required for the primary claim
- Design tradeoffs: Selecting top-K layers and top-r% neurons balances intervention strength against specificity; higher K/r increases signal but risks confounding general degradation with role-specific effects. Greedy decoding ensures reproducibility but may underestimate role effects that manifest through sampling diversity
- Failure signatures:
  - Random ablation produces equivalent or larger drops than role-selected ablation → selection method failed
  - CKA values below 0.85 with visible PCA clustering → roles may have formed separable representations (contradicts paper's findings)
  - JSD increasing in deep layers → role prompts affecting core reasoning, not just style
- First 3 experiments:
  1. Replicate neuron selection on a single dataset (MedQA) with baseline vs. one role prompt; verify that top-4 layers capture most divergence
  2. Run within-role vs. cross-role ablation at 5% masking; confirm McNemar p > 0.05 indicating no significant difference
  3. Compute CKA matrix across all roles; verify diagonal and off-diagonal values are nearly identical (0.96-1.00 range)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can specific fine-tuning or architectural modifications (beyond Prompt-Based Role Playing) enable LLMs to form distinct, role-specific reasoning pathways?
- **Basis in paper:** [explicit] The conclusion states that current methods fail and emphasizes "the need for a shift towards more advanced cognitive modeling" to simulate genuine cognitive processes rather than linguistic imitation
- **Why unresolved:** The study demonstrates that standard prompting is insufficient, but does not test whether fine-grained instruction tuning or specialized model architectures could successfully induce the distinct cognitive pathways observed in human medical hierarchies
- **What evidence would resolve it:** Architectural or training interventions resulting in separable clusters in representation space (low CKA similarity) and divergent neuron activation patterns for different clinical roles

### Open Question 2
- **Question:** Do multi-agent clinical systems exhibit genuine reasoning improvements, or do they suffer from the same superficial stylistic limitations found in single-agent role-playing?
- **Basis in paper:** [explicit] The introduction notes that despite the appeal of multi-agent designs, "the validity of these agent configurations... and their actual contribution to reasoning quality remain insufficiently tested"
- **Why unresolved:** The RPNA framework was applied to individual models; it remains unknown if the interaction between role-playing agents triggers the missing complementary computation or if it merely compounds stylistic variations without cognitive depth
- **What evidence would resolve it:** Application of the RPNA framework (specifically neuron ablation and representation analysis) to multi-agent dialogue logs to test for distinct, synergistic reasoning pathways

### Open Question 3
- **Question:** Does the failure of role prompts to induce cognitive differentiation persist in open-ended generative tasks or complex longitudinal simulations?
- **Basis in paper:** [inferred] The study relies exclusively on multiple-choice QA datasets (MedQA, MedMCQA, MMLU-Med); however, clinical reasoning often involves generating differential diagnoses or longitudinal patient management, which may require different cognitive mechanisms
- **Why unresolved:** Multiple-choice tasks may rely on recognition/recall, whereas generative tasks might expose different latent representations. It is unclear if the "linguistic style only" finding generalizes to generative clinical contexts
- **What evidence would resolve it:** Repeating the neuron ablation and CKA analysis on open-ended clinical tasks (e.g., case summarization or consultation dialogue) to see if role prompts modulate deeper layers in generative settings

## Limitations

- The analysis may miss subtle cognitive shifts not captured by activation magnitude differences or statistical metrics like CKA and JSD
- The neuron selection method assumes activation divergence correlates with functional importance, but this correlation remains empirically unverified
- Greedy decoding limits detection of role effects that might manifest through sampling diversity

## Confidence

- **High confidence**: Role prompts affect linguistic style more than reasoning ability
- **Medium confidence**: Role prompts do not create distinct cognitive reasoning pathways
- **Low confidence**: Role prompts have no impact on medical reasoning whatsoever

## Next Checks

1. **Replicate with alternative prompting strategies**: Test role prompts using few-shot examples or chain-of-thought prompting alongside the current template to determine if prompt formulation affects detection of cognitive differentiation

2. **Apply perturbation-based interpretability methods**: Use Integrated Gradients or attention rollout analysis to trace decision-making pathways for different roles, complementing the ablation approach with gradient-based attribution

3. **Test with dynamic decoding strategies**: Replicate experiments using temperature sampling (T=0.7) or nucleus sampling (p=0.9) to determine if role effects emerge through stochastic generation that greedy decoding masks