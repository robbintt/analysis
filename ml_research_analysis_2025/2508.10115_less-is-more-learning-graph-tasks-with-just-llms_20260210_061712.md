---
ver: rpa2
title: 'Less is More: Learning Graph Tasks with Just LLMs'
arxiv_id: '2508.10115'
source_url: https://arxiv.org/abs/2508.10115
tags:
- graph
- training
- tasks
- tokens
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work investigates whether large language models can learn\
  \ to solve fundamental graph tasks without specialized graph encoders, and whether\
  \ such learning generalizes to unseen graph structures and tasks. The authors train\
  \ small LLMs using instructive chain-of-thought solutions for four core tasks\u2014\
  node count, node degree, and reachability using BFS or DFS\u2014and evaluate performance\
  \ across multiple approaches including LoRA, P-Tuning, Graph Tokens, and Graph Tokens\
  \ + Text."
---

# Less is More: Learning Graph Tasks with Just LLMs
## Quick Facts
- arXiv ID: 2508.10115
- Source URL: https://arxiv.org/abs/2508.10115
- Reference count: 40
- Small LLMs can learn graph tasks through instruction tuning without specialized graph encoders

## Executive Summary
This work investigates whether large language models can learn fundamental graph tasks without specialized graph encoders, focusing on node count, node degree, and reachability using BFS or DFS. The authors train small LLMs using instructive chain-of-thought solutions and evaluate performance across multiple approaches including LoRA, P-Tuning, Graph Tokens, and Graph Tokens + Text. Results demonstrate that even small LLMs can effectively learn graph tasks with instruction tuning, achieving near-perfect accuracy on in-distribution graphs. The LoRA approach shows particularly strong generalization to larger and out-of-distribution graphs while maintaining high accuracy.

## Method Summary
The authors investigate whether small LLMs can learn fundamental graph tasks without specialized graph encoders by training them using instructive chain-of-thought solutions for four core tasks: node count, node degree, and reachability using BFS or DFS. They evaluate multiple tuning approaches including LoRA, P-Tuning, Graph Tokens, and Graph Tokens + Text on synthetic graph structures. The models are trained on small graphs and tested on both in-distribution and out-of-distribution structures, with additional evaluation on transferability to new tasks and performance on textual graph problems.

## Key Results
- Small LLMs achieve near-perfect accuracy on in-distribution graph tasks with instruction tuning
- LoRA approach demonstrates strong generalization to graphs twice the training size while maintaining high accuracy
- Graph Tokens alone shows brittleness on out-of-distribution graphs compared to LoRA
- Models show transferability to new tasks with minimal additional training

## Why This Works (Mechanism)
The approach leverages instruction tuning to teach LLMs graph reasoning without requiring specialized graph encoders. By providing instructive chain-of-thought solutions during training, the models learn to extract and process graph structures directly from text representations. The LoRA approach appears particularly effective because it adapts the model parameters specifically for graph tasks while preserving the pre-trained knowledge, enabling better generalization to unseen graph sizes and structures.

## Foundational Learning
- Graph representation: Understanding how graphs are encoded as text is essential for LLM processing. Quick check: Can the model correctly parse adjacency lists and node information from text.
- Chain-of-thought reasoning: The ability to follow step-by-step logical processes for graph traversal and analysis. Quick check: Does the model maintain correct reasoning flow through multi-step graph problems.
- BFS/DFS algorithms: Fundamental graph traversal methods that the model must learn to apply correctly. Quick check: Can the model distinguish when to use BFS versus DFS for different reachability problems.

## Architecture Onboarding
- Component map: Input text -> Graph parsing -> Reasoning steps -> Output generation
- Critical path: Graph task input flows through parsing layer, undergoes reasoning via fine-tuned parameters, produces answer
- Design tradeoffs: Specialized graph encoders vs. pure LLM approach; parameter-efficient tuning (LoRA) vs. full fine-tuning
- Failure signatures: Graph Tokens alone shows brittleness on larger/out-of-distribution graphs; P-Tuning may overfit to training distributions
- First experiments: 1) Test basic graph parsing on simple structures, 2) Evaluate BFS/DFS reasoning on small graphs, 3) Assess generalization to graphs twice the training size

## Open Questions the Paper Calls Out
None provided in the input.

## Limitations
- Evaluation focuses on synthetic graph structures, leaving uncertainty about real-world graph performance
- LoRA generalization testing limited to graphs twice training size, with unknown performance on significantly larger structures
- Brittleness observed with Graph Tokens alone suggests method choice critically impacts robustness
- Transferability evaluation covers only a few additional tasks, requiring broader validation

## Confidence
- Core finding (LLMs can learn graph tasks without specialized encoders): High
- Generalization claims (to larger/out-of-distribution graphs): Medium
- Minimal training transferability claims: Medium

## Next Checks
1. Evaluate performance on real-world graph datasets (e.g., social networks, molecular graphs) to assess practical applicability beyond synthetic structures
2. Test LoRA and other approaches on graphs significantly larger than twice the training size (e.g., 10x or 100x) to establish scaling limits
3. Expand transferability evaluation to a broader range of graph tasks, including those requiring multi-step reasoning or graph property prediction