---
ver: rpa2
title: 'Connector-S: A Survey of Connectors in Multi-modal Large Language Models'
arxiv_id: '2502.11453'
source_url: https://arxiv.org/abs/2502.11453
tags:
- arxiv
- features
- connector
- connectors
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey systematically reviews connectors in multi-modal large
  language models (MLLMs), identifying their critical role in bridging modality gaps.
  It presents a structured taxonomy categorizing connectors into atomic operations
  (mapping, compression, mixture of experts) and holistic designs (multi-layer, multi-encoder,
  multi-modal scenarios).
---

# Connector-S: A Survey of Connectors in Multi-modal Large Language Models

## Quick Facts
- arXiv ID: 2502.11453
- Source URL: https://arxiv.org/abs/2502.11453
- Reference count: 9
- Primary result: Systematic taxonomy categorizing connectors into atomic operations (mapping, compression, MoE) and holistic designs (multi-layer, multi-encoder, multi-modal)

## Executive Summary
This survey comprehensively reviews connector architectures in Multi-modal Large Language Models (MLLMs), identifying their critical role in bridging modality gaps between pre-trained encoders and large language models. The paper presents a structured taxonomy that organizes connectors into atomic operations—mapping (linear projection/MLP), compression (spatial pooling/semantic perception), and mixture of experts (dynamic routing)—as well as holistic designs that integrate multiple sources. Through analysis of representative methods across these categories, the survey highlights technical advancements and identifies key challenges in handling high-resolution inputs, dynamic compression, and interpretability. The work aims to serve as a foundational reference for researchers developing next-generation connectors to enhance MLLM performance and adaptability.

## Method Summary
This survey paper systematically categorizes connector architectures in Multi-modal Large Language Models (MLLMs) into three atomic operations and three holistic design patterns. The atomic operations include mapping (linear projection or MLPs to align visual features to LLM embedding space), compression (spatial pooling or semantic perception methods like Q-Former to reduce token count), and mixture of experts (dynamic routing based on token characteristics or external guidance). Holistic designs cover multi-layer fusion (combining features from different encoder layers), multi-encoder fusion (integrating outputs from multiple pre-trained encoders), and multi-modal scenarios (handling video, audio, and text alongside images). The survey evaluates connectors based on their ability to bridge modality gaps and computational efficiency, summarizing representative methods without proposing new architectures.

## Key Results
- Connectors play a pivotal role in bridging diverse modalities and enhancing model performance in MLLMs
- Three main connector types identified: mapping (linear/MLP projection), compression (spatial/semantic reduction), and MoE (specialized routing)
- Future research directions include adaptive compression mechanisms, high-resolution input handling, and interpretability analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Mapping connectors bridge modality gaps through linear dimensionality alignment, trading simplicity for token efficiency.
- Mechanism: Flattening 2D/3D modality features into 1D sequences followed by projection to textual token embedding dimensions. Linear connectors (LLaVA) use single projection matrices; MLP connectors (LLaVA-1.5) add non-linearity via stacked layers with activations.
- Core assumption: The pre-trained encoder outputs share sufficient semantic structure with the LLM's embedding space for simple projection to be effective.
- Evidence anchors:
  - [abstract] "connectors play a pivotal role in bridging diverse modalities and enhancing model performance"
  - [section 3.1] "Mapping operations first flatten 2D or 3D features into 1D in a specific order and directly align the dimension of representations from other modalities with textual token embeddings"
  - [corpus] Weak direct evidence; neighbor papers focus on attention mechanisms rather than projection-based connectors.
- Break condition: When modality features contain high redundancy or require semantic filtering, mapping alone produces excessive token sequences that burden LLM computation.

### Mechanism 2
- Claim: Compression connectors reduce token count by exploiting either spatial locality or semantic relevance.
- Mechanism: Spatial relation methods (pooling, CNN-based C-Abstractor) aggregate neighboring features based on spatial proximity. Semantic perception methods (Q-Former, Resampler) use learnable queries with cross-attention to extract task-relevant information while discarding redundancy.
- Core assumption: Adjacent features share semantic similarity (spatial), or that learnable queries can capture task-critical semantics (semantic perception).
- Evidence anchors:
  - [section 3.2] "features from adjacent regions tend to be more similar in the original modality representation"
  - [section 3.2] "Q-Former introduces a fixed number of learnable tokens as queries, which retrieve relevant information from other modality representations through cross-attention"
  - [corpus] "Hybrid-Level Instruction Injection for Video Token Compression" demonstrates instruction-guided compression, supporting semantic-aware approaches.
- Break condition: Fixed compression rates mismatch input complexity—rich inputs lose critical details; simple inputs retain unnecessary redundancy.

### Mechanism 3
- Claim: Mixture of Experts connectors enable specialization by routing tokens to domain-appropriate processing paths.
- Mechanism: A router network computes expert assignment weights per token (Vanilla MoE) or uses external guidance—modality tags (OneLLM), text instructions (Q-MoE), or task identifiers (Uni-Med)—to select specialized experts. Top-k gating ensures computational efficiency.
- Core assumption: Multi-modal data exhibits heterogeneous patterns that benefit from specialized processing rather than uniform transformation.
- Evidence anchors:
  - [section 3.3] "a set of experts, each specializing in distinct aspects of the multi-modal features, and a router that dynamically selects and combines their outputs"
  - [section 3.3] "X-guided MoE expands the input to the router beyond the individual multi-modal token itself"
  - [corpus] Weak direct evidence; corpus lacks MoE-specific connector studies.
- Break condition: Router collapse where few experts dominate, or guidance information fails to correlate with optimal expert assignment.

## Foundational Learning

- Concept: Cross-attention mechanisms
  - Why needed here: Core to Q-Former and Resampler compression; enables query-based retrieval from modality features.
  - Quick check question: Given a query tensor Q (N tokens) and key-value tensors K,V (M tokens), what is the output shape?

- Concept: Feature dimensionality alignment
  - Why needed here: Connectors must project encoder outputs (variable dimensions) to LLM embedding space (fixed dimension).
  - Quick check question: If CLIP-ViT outputs 1024-dim features and your LLM uses 4096-dim embeddings, what projection shape is needed?

- Concept: Token sequence length vs. computational cost
  - Why needed here: Compression tradeoffs directly impact LLM inference latency and memory; longer sequences quadratically increase attention cost.
  - Quick check question: For a 576-token visual sequence compressed to 64 tokens with an LLM context of 4096, how much attention computation is saved?

## Architecture Onboarding

- Component map:
  - Encoder output → Flattening → Connector (Mapping | Compression | MoE) → Aligned tokens → LLM
  - Compression branches: Spatial (pooling/CNN) vs. Semantic (Q-Former/Resampler)
  - Fusion strategies (holistic): Token concat, Channel concat, Weighted addition, Cross-attention variants

- Critical path:
  1. Identify modality encoder output dimensions and sequence lengths
  2. Select connector type based on token budget and semantic requirements
  3. Implement fusion strategy if multi-layer/multi-encoder inputs exist
  4. Train connector weights while freezing encoder and LLM (standard practice)

- Design tradeoffs:
  - Mapping: Fast convergence, minimal parameters → No compression, long sequences
  - Q-Former: Semantic compression, fixed output length → More parameters, longer training
  - MoE: Specialization, scalability → Router complexity, potential load imbalance
  - Multi-layer fusion: Richer representations → Increased redundancy, feature mismatch risk

- Failure signatures:
  - Token explosion: Mapping without compression exceeds LLM context
  - Semantic loss: Over-aggressive compression removes fine-grained details (DeCo analysis shows Q-Former loses spatial locality)
  - Expert collapse: Router assigns >90% tokens to single expert
  - Feature mismatch: Multi-layer fusion without alignment produces inconsistent gradients

- First 3 experiments:
  1. **Baseline mapping**: Implement linear and MLP connectors on frozen CLIP+LLaMA; measure token count and zero-shot VQA accuracy.
  2. **Compression ablation**: Compare pooling vs. Q-Former at compression ratios [4x, 8x, 16x]; plot accuracy vs. sequence length.
  3. **Multi-encoder fusion**: Integrate CLIP + DINOv2 features using channel concatenation vs. weighted addition; evaluate on detection-heavy benchmarks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can dynamic compression mechanisms be designed to adaptively adjust to the unique characteristics and complexity of specific inputs rather than relying on fixed token counts or compression rates?
- Basis in paper: [explicit] Section 5 states that previous works usually compress tokens using fixed methods, and there is "significant room for developing more adaptive compression mechanisms."
- Why unresolved: Current rigid compression methods risk discarding critical information in complex inputs or adding redundancy in simple ones, leading to suboptimal performance.
- What evidence would resolve it: A connector architecture that successfully varies its output token count based on input entropy, demonstrating superior performance-efficiency trade-offs on standard benchmarks.

### Open Question 2
- Question: How can connectors effectively preserve spatial relationships and interactions between partitioned patches when processing high-resolution inputs?
- Basis in paper: [explicit] Section 5 notes that current partitioning methods for high-resolution images "may disrupt spatial relationships, potentially distorting visual information."
- Why unresolved: Pre-partitioning images into patches is a common workaround for high resolution, but the optimal way for connectors to reintegrate these patches spatially remains an open optimization direction.
- What evidence would resolve it: Novel connector designs that explicitly model cross-patch interactions, outperforming standard partitioning baselines on tasks requiring fine-grained spatial reasoning.

### Open Question 3
- Question: What is the optimal combination strategy for fusing multi-layer or multi-encoder features that minimizes redundancy while maximizing representational richness?
- Basis in paper: [explicit] Section 5 highlights the challenge of "information redundancy" in multi-source fusion and the need to balance "representational richness and efficiency."
- Why unresolved: While strategies like channel concatenation have shown success, the paper notes the field requires a deeper understanding of the trade-offs between different fusion methods (e.g., weighted addition vs. cross-attention).
- What evidence would resolve it: Comparative studies establishing clear principles or guidelines for selecting fusion strategies based on the specific characteristics of the encoders or layers involved.

### Open Question 4
- Question: How can interpretability analysis of connectors reveal specific semantic deficiencies (such as loss of fine-grained attributes) to guide the design of more robust architectures?
- Basis in paper: [explicit] Section 5 discusses "Interpretability" as a challenge, noting that the connector's effectiveness "has not been fully explored from an interpretability perspective."
- Why unresolved: Understanding the internal mechanisms of connectors is difficult, yet necessary to diagnose failures like the loss of spatial locality identified in Q-Former connectors.
- What evidence would resolve it: Development of diagnostic tools or attribution maps that trace generated tokens back through the connector to raw inputs, leading to architectural corrections that fix identified deficiencies.

## Limitations
- Survey may exhibit bias toward connector designs appearing in high-profile papers versus emerging alternative approaches
- Limited coverage of connectors for non-visual modalities (audio, video, point clouds) beyond brief mentions
- Performance comparisons rely on aggregate literature reporting rather than controlled experiments across identical benchmarks

## Confidence
- **High Confidence**: Core taxonomy organization (mapping/compression/MoE atomic operations, multi-layer/multi-encoder/multi-modal holistic categories)
- **Medium Confidence**: Claims about compression effectiveness - performance varies significantly based on input characteristics and task requirements
- **Medium Confidence**: Future research directions - reasonable extrapolations but not empirically validated in surveyed works

## Next Checks
1. **Compression Ratio Validation**: Implement controlled experiments comparing spatial pooling vs. semantic perception methods (Q-Former) across varying compression ratios (4x, 8x, 16x) on identical datasets to quantify accuracy-token tradeoffs
2. **Expert Utilization Analysis**: For MoE connectors, measure expert activation distributions across diverse inputs to identify router collapse patterns and test load-balancing strategies
3. **Multi-Encoder Fusion Benchmarking**: Evaluate different fusion strategies (token concatenation vs. channel concatenation vs. weighted addition) using multiple pre-trained encoders (CLIP + DINOv2) on tasks requiring fine-grained spatial reasoning to assess feature alignment effectiveness