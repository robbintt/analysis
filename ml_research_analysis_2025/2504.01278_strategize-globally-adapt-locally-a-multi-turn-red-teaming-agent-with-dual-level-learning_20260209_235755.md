---
ver: rpa2
title: 'Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level
  Learning'
arxiv_id: '2504.01278'
source_url: https://arxiv.org/abs/2504.01278
tags:
- learning
- goal
- malware
- attack
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GALA, a novel multi-turn red-teaming agent
  that employs dual-level learning to enhance both attack success rate and diversity.
  GALA combines global tactic-wise learning to accumulate knowledge and develop a
  goal-based tactic selection framework, with local prompt-wise learning to refine
  prompt implementations for specific goals.
---

# Strategize Globally, Adapt Locally: A Multi-Turn Red Teaming Agent with Dual-Level Learning

## Quick Facts
- arXiv ID: 2504.01278
- Source URL: https://arxiv.org/abs/2504.01278
- Authors: Si Chen; Xiao Yu; Ninareh Mehrabi; Rahul Gupta; Zhou Yu; Ruoxi Jia
- Reference count: 40
- Key outcome: GALA achieves over 90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns, outperforming state-of-the-art baselines

## Executive Summary
This paper introduces GALA, a novel multi-turn red-teaming agent that employs dual-level learning to enhance both attack success rate and diversity. GALA combines global tactic-wise learning to accumulate knowledge and develop a goal-based tactic selection framework, with local prompt-wise learning to refine prompt implementations for specific goals. Evaluations on JailbreakBench show GALA achieves over 90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns, outperforming state-of-the-art baselines. The framework also demonstrates higher attack diversity, effectively identifying a broader range of vulnerabilities compared to existing approaches.

## Method Summary
GALA operates through a dual-level learning architecture that separates strategic planning from tactical execution. The global tactic-wise learning component maintains a knowledge base of successful attack patterns and develops a goal-based selection framework for choosing appropriate tactics. The local prompt-wise learning refines individual prompt implementations for specific attack goals. This separation allows the agent to strategically plan multi-turn attacks while adapting prompt implementations based on observed model responses. The framework integrates these components through a continuous feedback loop where successful tactics are incorporated into the global knowledge base while unsuccessful attempts inform prompt refinement.

## Key Results
- Achieves over 90% attack success rates against GPT-3.5-Turbo and Llama-3.1-70B within 5 conversation turns
- Demonstrates higher attack diversity compared to existing approaches, identifying broader ranges of vulnerabilities
- Outperforms state-of-the-art red teaming baselines on JailbreakBench evaluation suite

## Why This Works (Mechanism)
GALA's effectiveness stems from its dual-level learning architecture that decouples strategic planning from tactical execution. The global tactic-wise learning accumulates successful attack patterns and develops a goal-based selection framework, enabling the agent to choose optimal tactics based on the current attack state and target model characteristics. Simultaneously, the local prompt-wise learning refines individual prompt implementations through continuous feedback from model responses, allowing the agent to adapt its approach based on real-time observations. This separation of concerns allows GALA to maintain strategic coherence across multiple conversation turns while remaining flexible in prompt construction, leading to both higher success rates and greater attack diversity compared to monolithic approaches.

## Foundational Learning
- **Multi-turn dialogue management**: Required for maintaining conversational context and planning sequential attacks; quick check: verify conversation state tracking across turn boundaries
- **Tactic selection frameworks**: Needed to choose appropriate attack strategies based on current state and target model; quick check: evaluate tactic selection accuracy on held-out scenarios
- **Prompt refinement techniques**: Essential for adapting attack implementations based on model responses; quick check: measure prompt effectiveness improvement over iterations
- **Knowledge base construction**: Critical for accumulating successful attack patterns; quick check: assess knowledge base coverage and retrieval accuracy
- **Attack diversity metrics**: Required to quantify and compare the breadth of vulnerabilities discovered; quick check: validate diversity measures against human expert assessment

## Architecture Onboarding

**Component Map**: Knowledge Base -> Global Tactic Selector -> Local Prompt Refiner -> Model Interface -> Feedback Processor -> Knowledge Base

**Critical Path**: The knowledge base stores successful attack patterns and serves as the foundation for the global tactic selector, which chooses appropriate tactics based on current state. The local prompt refiner then constructs specific prompts for execution, which are sent through the model interface. Feedback from model responses is processed and used to update the knowledge base, completing the learning loop.

**Design Tradeoffs**: The dual-level separation provides flexibility and adaptability but introduces latency in the feedback loop. The knowledge base approach enables knowledge accumulation but requires careful management to avoid stale or overfitted patterns. The framework balances exploration of new tactics against exploitation of known successful approaches.

**Failure Signatures**: Performance degradation occurs when the knowledge base becomes too specialized to specific model architectures, when tactic selection fails to account for model-specific defenses, or when prompt refinement becomes trapped in local optima. The system may also struggle with novel model architectures that fall outside the learned patterns.

**First Experiments**:
1. Baseline comparison against single-level learning approaches on JailbreakBench
2. Knowledge base ablation study to measure contribution of accumulated knowledge
3. Diversity analysis comparing semantic novelty of discovered vulnerabilities

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to larger model families and diverse architectures not fully explored
- Performance primarily evaluated on two specific models (GPT-3.5-Turbo and Llama-3.1-70B)
- Diversity claims lack qualitative analysis of semantic novelty of discovered vulnerabilities

## Confidence
- Attack Success Rates: High
- Dual-Level Learning Efficacy: Medium
- Attack Diversity: Medium

## Next Checks
1. Conduct cross-model generalization tests across at least five different model families and sizes to assess performance consistency and identify potential failure modes.

2. Perform an ablation study isolating the impact of global tactic-wise learning versus local prompt-wise learning on both success rates and diversity metrics.

3. Implement a temporal robustness test where models are periodically retrained with discovered vulnerabilities to evaluate how quickly GALA adapts to defensive updates.