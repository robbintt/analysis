---
ver: rpa2
title: Trojan Cleansing with Neural Collapse
arxiv_id: '2411.12914'
source_url: https://arxiv.org/abs/2411.12914
tags:
- neural
- data
- trojan
- attacks
- cleansing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of trojan attacks on neural networks,
  which embed backdoor triggers to force specific outputs on triggered inputs. The
  authors connect trojan attacks to Neural Collapse, a phenomenon where over-parameterized
  neural networks' feature representations converge to a simple geometric structure.
---

# Trojan Cleansing with Neural Collapse

## Quick Facts
- arXiv ID: 2411.12914
- Source URL: https://arxiv.org/abs/2411.12914
- Authors: Xihe Gu; Greg Fields; Yaman Jandali; Tara Javidi; Farinaz Koushanraf
- Reference count: 40
- Primary result: ETF-FT trojan cleansing method achieves high clean accuracy while removing triggers across multiple architectures

## Executive Summary
This paper introduces a novel approach to trojan cleansing in neural networks by leveraging the phenomenon of Neural Collapse (NC). The authors observe that trojan attacks disrupt the symmetric geometric convergence observed in standard training, specifically affecting the structure of the final layer weights. They propose ETF-FT (Equiangular Tight Frame - Fine-Tuning), which overwrites the final layer weights with a symmetric random simplex ETF and fine-tunes the remaining parameters on clean data. Experiments demonstrate that ETF-FT effectively removes trojan triggers while maintaining clean accuracy across various attack types, architectures (including transformers), and data scarcity scenarios.

## Method Summary
ETF-FT works by first constructing a random simplex Equiangular Tight Frame (ETF) matrix using Algorithm 2, where $W_{ETF} = \sqrt{\frac{K}{K-1}} \times P \times (I - \frac{1}{K} \times 1)^T$ and P is a random orthogonal matrix. The method then replaces the final layer weights of the trojaned model with this ETF matrix and freezes it. Finally, the remaining model parameters (feature extractor) are fine-tuned on a small clean dataset using standard training procedures. The key insight is that this geometric overwrite eliminates the trojan's asymmetric mapping while the fine-tuning step allows the feature extractor to adapt to the new symmetric geometry.

## Key Results
- ETF-FT achieves near-zero ASR while maintaining clean accuracy close to original models across BadNets, WaNet, and SIG attacks
- Method works effectively with as little as 1% clean data, demonstrating robustness to data scarcity
- ETF-FT outperforms baseline cleansing methods including ABS, NC, and RIPPLe across multiple architectures including ViT
- The approach is trigger-agnostic, requiring no knowledge of the specific trojan trigger type

## Why This Works (Mechanism)

### Mechanism 1: Structural Asymmetry Disruption
- **Claim:** Trojan attacks inherently conflict with the symmetric geometric convergence (Neural Collapse) observed in standard training, causing measurable deviations in feature and weight structures.
- **Mechanism:** Neural Collapse drives the final layer features and weights to form a Simplex Equiangular Tight Frame (ETF), characterized by equal norms and maximally separated angles. A trojan creates an asymmetric mapping (many sources → one target), which the paper demonstrates disrupts this symmetry, specifically causing the norm of the target class weight vector to shrink relative to others.
- **Core assumption:** The conflict between the asymmetric trojan objective and the symmetric NC objective forces the network into a sub-optimal geometric state that can be detected and exploited.
- **Evidence anchors:**
  - [Page 3, Intro]: "We hypothesize that this symmetric structure... directly contradicts the asymmetry introduced by data poisoning."
  - [Page 8, Analysis]: Notes that for trojaned models, "the source of this deviation is actually that the norm of the target class is consistently smaller."
  - [Corpus]: Corpus neighbors (e.g., *DeBUGCN*, *MergeGuard*) discuss detection and mitigation but do not address the Neural Collapse geometric mechanism; evidence for this specific mechanism is internal to the paper.
- **Break condition:** If a trojan is designed to explicitly preserve ETF symmetry (e.g., by distributing trigger features across all classes rather than targeting one), or if the model is severely under-trained so that NC has not begun.

### Mechanism 2: Geometric Overwriting (ETF-FT)
- **Claim:** Replacing the final layer weights with a perfectly symmetric random Simplex ETF destroys the trojan's learned pathway without requiring knowledge of the trigger.
- **Mechanism:** The trojan relies on a specific orientation of the final layer weight matrix W to map trigger features to the target class. By overwriting W with W_{ETF} (a matrix with perfect symmetry), the specific "shortcut" vector learned by the trojan is mathematically eliminated, while preserving the structure necessary for standard classification.
- **Core assumption:** The trojan's effectiveness is primarily encoded in the final linear layer's deviation from symmetry, rather than being deeply embedded solely in the feature extractor.
- **Evidence anchors:**
  - [Page 9, Methodology]: "over-writing the weights of the final layer to a randomly generated simplex ETF... prevents the trojan deformation of the final layer."
  - [Abstract]: "overwrites final layer weights with a simplex equiangular tight frame... effectively removes trojan triggers."
- **Break condition:** If the clean dataset is too small or corrupted to allow the feature extractor to re-align with the new frozen ETF head, resulting in a failure to recover accuracy.

### Mechanism 3: Feature Re-alignment via Frozen Fine-tuning
- **Claim:** Fine-tuning the feature extractor g(x) while freezing the ETF head forces the network to learn a clean representation compatible with the symmetric geometry, effectively "washing out" the trigger.
- **Mechanism:** With the head W_{ETF} fixed, the network must adjust g(x) to minimize loss on clean data. Since the trigger is absent from the clean data and the head is no longer biased toward the trigger's asymmetric geometry, the feature extractor updates gradients to suppress the trigger features as noise/irrelevant variance.
- **Core assumption:** The feature extractor retains enough plasticity to adapt to the new geometric constraint using limited clean data.
- **Evidence anchors:**
  - [Page 10, Algorithm 1]: Explicitly lists "Freeze the final layer weight matrix" and "Fine-tune on the clean dataset" as the core steps.
  - [Page 13, Robustness]: Shows the method maintains performance even with 1% imbalanced or corrupted data, supporting the plasticity assumption.
- **Break condition:** If the feature extractor is frozen or has lost plasticity (e.g., linear probing mode), the re-alignment cannot occur.

## Foundational Learning

- **Concept:** **Neural Collapse (NC) & Simplex ETF**
  - **Why needed here:** This is the theoretical pivot of the paper. You must understand that "collapse" implies features converging to class means which form a perfect geometric shape (Simplex ETF) with equal norms and angles.
  - **Quick check question:** If NC1 (variability collapse) is high, are features within a class tightly clustered or widely spread?

- **Concept:** **Data Poisoning (Trojan Attacks)**
  - **Why needed here:** To distinguish this from adversarial attacks. The threat model here is training-time corruption where a "trigger" is baked into the model's weights, not an inference-time perturbation.
  - **Quick check question:** Does a trojan attack require the test-time input to be modified, the training data to be modified, or both?

- **Concept:** **Fine-Tuning with Frozen Layers**
  - **Why needed here:** The solution (ETF-FT) relies on freezing the head to preserve the geometric reset while updating the body. Understanding gradient flow with frozen modules is required for implementation.
  - **Quick check question:** If the final layer is frozen, does the backpropagated error signal update the weights of the penultimate layer?

## Architecture Onboarding

- **Component map:**
  - Input -> Feature Extractor (g(x)) -> Final Layer (W_{ETF}) -> Output

- **Critical path:**
  1. **Construction:** Generate W_{ETF} using Algorithm 2 (requires number of classes K and random orthogonal matrix)
  2. **Overwrite:** Replace model's final FC weights with W_{ETF}
  3. **Freeze:** Disable gradients for the final FC layer
  4. **Optimize:** Run standard training loop (AdamW + ExponentialLR) on the backbone only using clean data

- **Design tradeoffs:**
  - **Clean Accuracy vs. Data Volume:** The method recovers accuracy well with limited data, but extreme scarcity (e.g., < 1%) or significant distribution shift may degrade performance.
  - **Robustness vs. Architecture Compatibility:** The method is architecture-agnostic (works on ResNet and ViT), but transformers (ViT) showed a slightly larger accuracy drop in experiments compared to ResNets.

- **Failure signatures:**
  - **High ASR (Attack Success Rate):** If ASR remains high post-cleansing, the trojan may be encoded in the backbone (feature space) rather than the head, or the clean data is poisoned.
  - **Low ACC (Clean Accuracy):** If accuracy drops significantly, the learning rate may be too high for the frozen-head setup, or the clean data is insufficient to realign features to the new ETF head.

- **First 3 experiments:**
  1. **Sanity Check (BadNets on ResNet18):** Implant a standard patch trigger, apply ETF-FT with 5% clean data, and verify ASR ≈ 0 while ACC ≈ Original.
  2. **Ablation on Data Scarcity:** Run ETF-FT with 1% vs 5% clean data to measure the robustness margin.
  3. **Metric Validation:** Measure NC2/NC3 metrics before and after cleansing to visually confirm the restoration of geometric symmetry.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can a rigorous theoretical framework be established to explain the observed tension between trojan triggers and Neural Collapse?
- **Basis in paper:** [explicit] Section 5.1 states that "developing a theoretical framework" is an important area of future work.
- **Why unresolved:** The current work relies primarily on experimental evidence and heuristic observations of geometric disruption.
- **What evidence would resolve it:** A formal mathematical proof linking the asymmetry of trojan attacks to the degradation of specific NC metrics.

### Open Question 2
- **Question:** Can the measurable disruption of Neural Collapse serve as a reliable metric for detecting trojaned models?
- **Basis in paper:** [explicit] Section 5.1 explicitly lists "building a trojan detection method" as a key direction for future research.
- **Why unresolved:** The paper focuses on defense (cleansing) rather than detection, leaving the diagnostic utility of NC metrics unexplored.
- **What evidence would resolve it:** A detection algorithm that utilizes NC metrics to distinguish between benign and trojaned models with high accuracy.

### Open Question 3
- **Question:** Does the phenomenon of Neural Collapse disruption generalize to non-image domains such as Natural Language Processing (NLP) and audio?
- **Basis in paper:** [explicit] Section 5.1 notes that extending the analysis to language and audio domains is an "interesting direction for future work."
- **Why unresolved:** All experiments were conducted on image classification tasks (CIFAR-10/100, GTSRB).
- **What evidence would resolve it:** Demonstration of NC disruption and successful ETF-FT cleansing on text or audio classification models.

### Open Question 4
- **Question:** How does the specific initialization of the simplex ETF matrix influence the trade-off between clean accuracy and attack mitigation?
- **Basis in paper:** [explicit] Section 5.1 suggests "characterizing the impact of the initial ETF selection as well as optimizing this" for future study.
- **Why unresolved:** The method currently employs a randomly generated ETF, leaving the sensitivity of the results to this initialization unquantified.
- **What evidence would resolve it:** An ablation study comparing the performance of random versus optimized ETF initializations.

## Limitations
- The method assumes trojan effects are primarily encoded in the final layer rather than being deeply embedded in the feature extractor.
- Performance degrades with extremely limited clean data (<1%) or significant distribution shift between training and cleansing data.
- The theoretical framework relies on Neural Collapse occurring in standard training, which may not hold for all architectures or tasks.

## Confidence
- **High Confidence:** The ETF-FT method effectively removes trojan triggers and maintains clean accuracy under standard conditions, as demonstrated across multiple architectures and datasets.
- **Medium Confidence:** The connection between trojan attacks and Neural Collapse disruption is empirically supported but not rigorously proven across all attack types and model architectures.
- **Medium Confidence:** The method's robustness to imbalanced and corrupted clean data is demonstrated but requires further validation in more diverse real-world scenarios.

## Next Checks
1. **Robustness to Feature-Space Trojans:** Test ETF-FT on attacks that embed triggers in intermediate layers or the feature space (e.g., hidden-trigger attacks) to assess whether the method fails when trojan effects are not primarily in the final layer.
2. **Cross-Domain Cleansing:** Evaluate ETF-FT on models trained on significantly different distributions (e.g., natural images vs. medical imaging) to test performance when clean data distribution shifts.
3. **Theoretical Formalization:** Conduct a formal analysis proving that trojan attacks necessarily disrupt the geometric conditions required for Neural Collapse, strengthening the theoretical foundation of the method.