---
ver: rpa2
title: 'Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla
  ASR Transcripts: A Novel Corpus and Benchmarking Analysis'
arxiv_id: '2511.13159'
source_url: https://arxiv.org/abs/2511.13159
tags:
- repetition
- reduplication
- disfluency
- bangla
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of distinguishing Repetition
  Disfluency (unintentional ASR errors) from Morphological Reduplication (deliberate
  grammatical forms) in Bangla ASR transcripts. A novel, manually annotated corpus
  of 20,000 sentences was created to enable this fine-grained classification.
---

# Distinguishing Repetition Disfluency from Morphological Reduplication in Bangla ASR Transcripts: A Novel Corpus and Benchmarking Analysis

## Quick Facts
- **arXiv ID**: 2511.13159
- **Source URL**: https://arxiv.org/abs/2511.13159
- **Reference count**: 8
- **Primary result**: Language-specific BanglaBERT achieves 84.78% accuracy and 0.677 F1 score in distinguishing disfluent repetition from morphological reduplication in Bangla ASR transcripts.

## Executive Summary
This paper addresses the challenge of distinguishing Repetition Disfluency (unintentional ASR errors) from Morphological Reduplication (deliberate grammatical forms) in Bangla ASR transcripts. A novel, manually annotated corpus of 20,000 sentences was created to enable this fine-grained classification. Two approaches were benchmarked: in-context learning with LLMs and task-specific fine-tuning of encoder models. Fine-tuning significantly outperformed prompting, with the language-specific BanglaBERT model achieving the highest accuracy of 84.78% and an F1 score of 0.677. This establishes a strong, linguistically-informed baseline and provides essential data for developing semantic-preserving text normalization systems for Bangla.

## Method Summary
The method involves creating a manually annotated corpus of 20,000 Bangla sentences with word repetitions tagged using BIO format within ±10 word context windows. The corpus labels each repeated word pair as Reduplication, Repetition, or Neither. Three encoder models (BanglaBERT, XLM-RoBERTa, mBERT) were fine-tuned for 3 epochs with batch size 16, learning rate 2e-5, and weight decay 0.01. LLM performance was benchmarked using zero-shot, one-shot, and few-shot prompting with temperature 0.1. The best fine-tuned model (BanglaBERT) was compared against top LLMs (GPT-4o, Claude 4, Gemini 2.5 Flash) on a held-out test set.

## Key Results
- BanglaBERT fine-tuning achieved 84.78% accuracy and 0.677 F1 score, outperforming all LLM prompting approaches.
- LLM prompting reached up to 82.68% accuracy (Claude 4) with few-shot examples, but showed inconsistent performance across models.
- XLM-RoBERTa and mBERT both reached 83.28% accuracy but with lower F1 scores than BanglaBERT.
- The corpus distribution was highly imbalanced: Reduplication (66.3%), Repetition (32.9%), Neither (0.8%).

## Why This Works (Mechanism)

### Mechanism 1
Task-specific fine-tuning of language-specific encoder models outperforms in-context learning with large language models for distinguishing repetition disfluency from morphological reduplication in Bangla ASR transcripts. Fine-tuning with a specialized, manually annotated 20,000-sentence dataset allows the model to learn subtle linguistic distinctions specific to the target language. BanglaBERT's pre-training on a vast Bengali corpus provides a strong linguistic foundation, which is then refined by the labeled data to capture the nuanced differences between grammatical reduplication and unintentional disfluencies.

### Mechanism 2
A language-specific pre-trained model (BanglaBERT) outperforms general multilingual models (mBERT, XLM-RoBERTa) on this fine-grained linguistic classification task. BanglaBERT's pre-training on a large, dedicated Bengali corpus allows it to develop more robust internal representations of the language's specific grammatical structures, including morphological reduplication. This specialized knowledge is more directly applicable to the target task than the broader but shallower representations learned by multilingual models.

### Mechanism 3
Few-shot prompting is the most effective in-context learning strategy for top-tier LLMs on this task, but is inconsistent for lower-tier models. For capable models like GPT-4o and Claude 4, providing a few explicit examples in the prompt helps align their vast pre-existing knowledge with the task's specific requirements, guiding them to attend to the correct linguistic cues. Weaker models may lack the robust internal representations or the ability to generalize effectively from a small number of examples, leading to inconsistent or degraded performance.

## Foundational Learning

- **Morphological Reduplication vs. Repetition Disfluency**
  - Why needed here: This is the core ambiguity the paper addresses. Understanding this distinction is fundamental to grasping the problem and the model's task.
  - Quick check question: In the Bangla sentence "অংকগুেলা কের কের আমরা একট ু আন্ডারস্টয্ািন্ডং েডেভলপ করা েচষ্টা করেবা" (Onkogulo kore kore amra...), does the repetition "কের কের" (kore kore) represent a disfluency or a grammatical reduplication? Why?

- **In-Context Learning (Prompting) vs. Fine-Tuning**
  - Why needed here: The paper benchmarks these two main approaches for applying pre-trained models. Understanding the trade-offs is key to interpreting the results and deciding on a strategy.
  - Quick check question: What is the primary difference in how a model is adapted for a task between in-context learning and fine-tuning? Which approach showed superior results in this paper?

- **Low-Resource Language NLP**
  - Why needed here: Bangla is treated as a low-resource language in NLP, which motivates the data-centric approach and the use of specialized models like BanglaBERT.
  - Quick check question: What is the primary challenge posed by low-resource languages for developing NLP systems, and what strategy did the paper employ to overcome it for this specific task?

## Architecture Onboarding

- **Component map**: Noisy ASR transcripts from YouTube (bn-orig tag) -> Automated filtering pipeline to isolate word repetitions, apply BIO tagging, extract symmetric context windows -> Hybrid annotation (GPT-4o initial labeling + expert human review) -> Gold-standard corpus (20,000 rows) -> Fine-tuning (BanglaBERT, XLM-RoBERTa, mBERT) or LLM prompting (GPT-4o, Claude 4, Gemini 2.5 Flash, Gemma 3, Mistral, Llama 3, Phi-4) -> 3-way classification (Reduplication, Repetition, Neither)

- **Critical path**: The data processing and annotation pipeline is the most critical component. The quality and accuracy of the 20,000-row annotated corpus directly determine the performance of any downstream model. As noted in the paper, manually verifying the LLM-generated labels was essential for ensuring linguistic fidelity.

- **Design tradeoffs**:
  - **LLM Prompting vs. Fine-Tuning**: Prompting is faster and requires no training data but is less accurate. Fine-tuning is more accurate but requires a labeled dataset and computational resources for training.
  - **Multilingual vs. Language-Specific Models**: Multilingual models (mBERT, XLM-R) are more general but may lack nuanced language understanding. The language-specific model (BanglaBERT) proved more accurate for this task but is less versatile.
  - **Precision vs. Recall**: The fine-tuned BanglaBERT model exhibits a high precision (0.901) but lower recall (0.646). This is a strategic trade-off: the model is conservative to avoid deleting valid reduplication (high precision) but may miss some disfluencies (lower recall), prioritizing semantic preservation over comprehensive noise removal.

- **Failure signatures**:
  - **Over-correction by Generic Models**: A standard disfluency correction model not trained for this specific ambiguity would likely fail by erroneously deleting valid morphological reduplications, catastrophically altering semantic content.
  - **Inconsistent LLM Generalization**: Lower-tier open-source LLMs failing to improve with few-shot examples, indicating their internal representations are not well-aligned with the task.
  - **Impact of Imbalanced Data**: A significant gap between precision and recall, with the model likely biased towards the majority class (Reduplication, 66.3% of data).

- **First 3 experiments**:
  1. Establish an LLM Baseline: Evaluate several prominent LLMs (GPT-4o, Claude 4, Gemini 2.5 Flash) on the held-out test set using zero-shot, one-shot, and few-shot prompting to set a performance baseline.
  2. Benchmark Fine-Tuning Approaches: Fine-tune and compare three encoder models (BanglaBERT, XLM-RoBERTa, mBERT) on the training data to measure the gain from task-specific adaptation and compare multilingual vs. language-specific pre-training.
  3. Analyze Performance Trade-offs: Conduct a detailed error analysis on the best-performing model's outputs, comparing its precision and recall to understand the trade-offs between preserving semantic content (reduplication) and removing noise (disfluency).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can LLM-based synthetic data augmentation effectively mitigate class imbalance and close the precision-recall gap for disfluency detection?
- **Basis in paper**: [explicit] The authors state future work must focus on "using Large Language Models (LLMs) specifically as Disfluency Generators to create... synthetic disfluent sentences for the minority class."
- **Why unresolved**: The current best model (BanglaBERT) exhibits a significant disparity between precision (0.901) and recall (0.646) due to the dataset's heavy skew towards Reduplication (66.3%) over Repetition (32.9%).
- **What evidence would resolve it**: Experiments demonstrating improved Macro F1 scores and higher recall for the minority "Repetition" class after fine-tuning on a dataset balanced with synthetic disfluencies.

### Open Question 2
- **Question**: To what extent does the fine-tuned model generalize to conversational speech domains outside of educational YouTube content?
- **Basis in paper**: [explicit] The authors note the corpus is "derived exclusively from educational content" and future work should "target a more diverse range of conversational speech domains" such as talk shows or casual vlogs.
- **Why unresolved**: Educational content may lack the linguistic variability, disfluency patterns, and specific reduplication nuances found in informal or spontaneous speech contexts.
- **What evidence would resolve it**: A cross-domain evaluation benchmarking the current BanglaBERT model on a newly annotated dataset derived from casual or political speech without retraining.

### Open Question 3
- **Question**: Does adversarial training during fine-tuning significantly improve robustness against noisy ASR inputs?
- **Basis in paper**: [explicit] The authors propose "implementing Adversarial Training during the fine-tuning phase" to improve robustness against "noisy, real-world ASR outputs."
- **Why unresolved**: While current fine-tuning yields 84.78% accuracy, the authors suggest that adversarial training is necessary to further improve performance stability and F1 scores.
- **What evidence would resolve it**: A comparative study measuring the performance delta between standard fine-tuned models and adversarially trained models when evaluated on perturbed or highly noisy transcripts.

## Limitations
- The test set (335 sentences) is relatively small, raising questions about statistical robustness of reported metrics.
- Severe class imbalance (66.3% Reduplication vs 32.9% Repetition vs 0.8% Neither) likely limits model performance on minority classes.
- Hybrid LLM-human annotation pipeline introduces uncertainty about inter-annotator reliability and replicability.
- Limited evaluation to Bangla language only; generalization to other languages is not established.

## Confidence
- **High confidence**: Fine-tuning BanglaBERT yields higher accuracy (84.78%) than LLM prompting (82.68% for Claude 4), supported by direct comparison and corroborated by related work on Indo-Aryan languages.
- **Medium confidence**: Language-specific pre-training is crucial for capturing nuanced morphological distinctions, but lack of ablation studies and further linguistic analysis prevents stronger claims.
- **Low confidence**: Claims about general superiority of few-shot prompting for top-tier LLMs or precise mechanism of BanglaBERT's advantage are not fully substantiated due to lack of controlled experiments and detailed error analysis.

## Next Checks
1. **Statistical validation**: Conduct k-fold cross-validation on the full 20,000-sentence corpus to establish confidence intervals for accuracy, F1, precision, and recall, particularly for the minority classes. Supplement with additional metrics such as balanced accuracy and Macro F1 to mitigate the impact of class imbalance.

2. **Ablation study**: Isolate the contributions of language-specific pre-training, task-specific fine-tuning, and dataset size by performing controlled experiments that vary one factor at a time (e.g., compare BanglaBERT to a similarly fine-tuned mBERT, or evaluate performance with reduced training data).

3. **Linguistic error analysis**: Manually inspect a stratified sample of false positives and false negatives for each class, mapping errors to specific linguistic phenomena (e.g., ambiguous reduplication, ASR noise patterns, context truncation). Cross-validate a subset of annotations with a second expert to assess inter-annotator agreement and the robustness of the gold standard.