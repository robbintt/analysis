---
ver: rpa2
title: Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge
arxiv_id: '2509.03256'
source_url: https://arxiv.org/abs/2509.03256
tags:
- training
- loss
- each
- speech
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addressed automatic word-level pronunciation assessment
  for children learning Norwegian as a second language. Three end-to-end architectures
  were evaluated: an encoder-decoder Siamese model (E2E-R), a prefix-tuned wav2vec2.0-based
  direct classification model, and a novel GOP-CTC-based model integrating alignment-free
  goodness-of-pronunciation features computed via CTC.'
---

# Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge

## Quick Facts
- arXiv ID: 2509.03256
- Source URL: https://arxiv.org/abs/2509.03256
- Reference count: 0
- Evaluated three end-to-end architectures for word-level pronunciation assessment in Norwegian L2 children's speech

## Executive Summary
This work presents a comprehensive evaluation of end-to-end speech assessment models for automatic word-level pronunciation scoring in Norwegian as a second language for children. Three architectures were compared: an encoder-decoder Siamese model (E2E-R), a prefix-tuned wav2vec2.0-based direct classification model, and a novel GOP-CTC-based model that integrates alignment-free goodness-of-pronunciation features computed via CTC. The study introduces a weighted ordinal cross-entropy loss to balance performance across unweighted average recall and mean absolute error metrics. The GOP-CTC model achieved the highest performance, substantially surpassing challenge baselines and attaining top leaderboard scores.

## Method Summary
The study evaluated three end-to-end architectures for pronunciation assessment: (1) an encoder-decoder Siamese model (E2E-R) with contrastive loss for speaker-invariant feature learning, (2) a prefix-tuned wav2vec2.0-based direct classification model using wav2vec2.0 features, and (3) a novel GOP-CTC-based model that computes alignment-free goodness-of-pronunciation features via CTC. A weighted ordinal cross-entropy loss was introduced to balance performance across unweighted average recall and mean absolute error. The models were trained and evaluated on the NOCASA 2025 challenge dataset for Norwegian L2 children's speech.

## Key Results
- GOP-CTC-based model achieved highest performance with UAR of 44.8%, F1 of 47.4%, and MAE of 0.505
- Outperformed challenge baselines and achieved top leaderboard scores
- E2E-R and prefix-tuned wav2vec2.0 models showed lower performance than the GOP-CTC approach

## Why This Works (Mechanism)
The GOP-CTC model works by computing alignment-free goodness-of-pronunciation features through CTC-based feature extraction, which captures pronunciation quality without requiring explicit phoneme alignment. This approach directly models the relationship between acoustic features and pronunciation scores, bypassing the need for intermediate alignment steps. The weighted ordinal cross-entropy loss effectively balances the trade-off between unweighted average recall and mean absolute error, optimizing for the specific evaluation metrics of the challenge.

## Foundational Learning

**CTC (Connectionist Temporal Classification)**: A loss function that enables training of sequence models without requiring pre-segmented training data. Why needed: Essential for computing alignment-free features and training models on unaligned speech data. Quick check: Verify that the model can handle variable-length sequences without explicit alignment.

**Goodness of Pronunciation (GOP)**: A measure of pronunciation quality that compares hypothesized phoneme sequences to reference pronunciations. Why needed: Provides interpretable pronunciation scores for L2 assessment. Quick check: Confirm that GOP scores correlate with human expert ratings.

**Ordinal Classification**: A classification problem where classes have a natural order. Why needed: Pronunciation scores are inherently ordinal (e.g., poor, fair, good, excellent). Quick check: Ensure the model respects ordinal relationships in the loss function.

## Architecture Onboarding

**Component Map**: Raw speech -> Feature Extractor (wav2vec2.0/GOP-CTC) -> Classifier -> Pronunciation Score

**Critical Path**: The feature extraction and classification stages form the critical path, where the quality of extracted features directly impacts classification performance.

**Design Tradeoffs**: The GOP-CTC approach trades explicit phoneme alignment for computational efficiency and robustness to alignment errors, while the weighted ordinal loss trades balanced metric optimization for potential overfitting to the specific metric combination.

**Failure Signatures**: Poor performance on out-of-domain accents, sensitivity to background noise, and overfitting to the specific Norwegian L2 dataset are potential failure modes.

**First Experiments**: 1) Test feature extraction quality on held-out validation set, 2) Evaluate ordinal classification performance on synthetic ordinal data, 3) Benchmark against human expert scores on a subset of the data.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains are based on a single evaluation dataset (NOCASA 2025 challenge) without external validation
- The ordinal cross-entropy weighting strategy may be overfitted to this specific metric balance
- Direct comparison between models conflates architectural differences with feature extraction methodology

## Confidence

**High**: The implementation details of all three model architectures are described with sufficient clarity for reproduction

**Medium**: The superiority of GOP-CTC over baselines is well-supported within the challenge context

**Medium**: The ordinal cross-entropy weighting approach is technically sound but may be overfitted to this specific metric balance

## Next Checks
1. Evaluate all three models on an independent Norwegian L2 speech corpus to assess generalizability beyond the challenge dataset
2. Conduct ablation studies isolating the contribution of GOP features versus CTC alignment from other architectural differences
3. Test alternative weighting schemes for the ordinal cross-entropy loss to verify robustness of the performance trade-off between UAR and MAE