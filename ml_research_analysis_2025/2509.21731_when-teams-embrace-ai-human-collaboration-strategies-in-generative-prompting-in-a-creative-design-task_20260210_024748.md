---
ver: rpa2
title: 'When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting
  in a Creative Design Task'
arxiv_id: '2509.21731'
source_url: https://arxiv.org/abs/2509.21731
tags:
- genai
- participants
- design
- creative
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examined how teams of designers collaborate when using
  generative AI tools in a creative stage design task. Pairs of participants with
  design or performance backgrounds worked together to generate stage designs based
  on a poem, using ChatGPT and Midjourney.
---

# When Teams Embrace AI: Human Collaboration Strategies in Generative Prompting in a Creative Design Task

## Quick Facts
- arXiv ID: 2509.21731
- Source URL: https://arxiv.org/abs/2509.21731
- Reference count: 40
- Key outcome: Teams of designers showed two distinct workflows when using generative AI for creative tasks, perceiving AI as a supportive tool rather than a collaborator while facing new cognitive demands during co-prompting

## Executive Summary
This study examined how teams of designers collaborate when using generative AI tools in a creative stage design task. Pairs of participants with design or performance backgrounds worked together to generate stage designs based on a poem, using ChatGPT and Midjourney. Two distinct collaborative workflows emerged: some teams started by building a detailed narrative, while others began with conceptual imagery. Participants frequently sought each other's opinions on prompts and outputs, which helped them refine ideas and reach consensus. However, the process of adjusting prompts was challenging and sometimes hindered creative discussion. Participants perceived GenAI mainly as a supportive tool rather than a true collaborator, valuing their human partner's ideas above AI-generated suggestions.

## Method Summary
Six pairs of participants with design or performance backgrounds collaborated on generating stage designs based on a poem using ChatGPT and Midjourney. The study employed observational methods and interviews to capture collaborative workflows and participant perceptions. Teams were tasked with creating stage designs while documenting their prompting processes and decision-making strategies. The research focused on qualitative analysis of how participants engaged with each other and the AI tools throughout the creative process.

## Key Results
- Two distinct collaborative workflows emerged: narrative-first (building detailed stories before generating imagery) and imagery-first (starting with conceptual visuals)
- Participants perceived generative AI as a supportive tool rather than a true collaborator, consistently prioritizing human partner's ideas
- Co-prompting introduced new cognitive demands, with prompt adjustment challenges sometimes hindering creative discussion

## Why This Works (Mechanism)
Assumption: The collaborative workflows may work because teams can leverage complementary strengths - one member focusing on narrative coherence while another emphasizes visual elements. The supportive tool perception could stem from AI's inability to understand context and emotional nuance that human partners naturally provide. The cognitive demands during co-prompting likely arise from the need to translate abstract creative concepts into precise technical prompts that AI systems can process.

## Foundational Learning
Unknown: The paper doesn't explicitly discuss foundational learning principles. However, it appears to demonstrate that effective human-AI collaboration in creative tasks requires clear role delineation between human creativity and AI execution capabilities.

## Architecture Onboarding
Unknown: The paper doesn't address architecture onboarding specifically. The study focused on collaborative workflows rather than technical implementation details of AI systems.

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample size (n=6 pairs) limits generalizability of findings
- All participants were from design or performance backgrounds, missing perspectives from other domains
- Study focused on a single creative task (stage design based on poetry), so results may not transfer to other creative contexts
- Limited exploration of long-term adaptation to AI collaboration tools
- Lack of quantitative measures for cognitive load during co-prompting

## Confidence
**Major Claim Confidence:**
- Two distinct collaborative workflows emerged (Medium): The observation is based on a small sample, though the qualitative differences were clear
- AI is perceived as a supportive tool rather than a collaborator (High): This perception was consistently reported across participants
- Co-prompting introduces new cognitive demands (Medium): While participants reported challenges, the study lacked objective measures of cognitive load

## Next Checks
1. Replicate the study with larger, more diverse participant pools across different creative domains
2. Implement quantitative measures of creative output quality and team performance to complement qualitative findings
3. Conduct longitudinal studies to examine how collaboration strategies evolve with increased AI tool experience
4. Investigate the impact of different AI tool architectures on collaborative workflows
5. Explore the transferability of findings to non-creative domains and different cultural contexts