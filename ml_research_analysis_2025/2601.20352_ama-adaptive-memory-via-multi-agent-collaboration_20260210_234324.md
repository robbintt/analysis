---
ver: rpa2
title: 'AMA: Adaptive Memory via Multi-Agent Collaboration'
arxiv_id: '2601.20352'
source_url: https://arxiv.org/abs/2601.20352
tags:
- memory
- retrieval
- arxiv
- long-term
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes AMA, a multi-agent memory framework that dynamically
  aligns retrieval granularity with task demands to improve long-term reasoning in
  LLM agents. AMA decomposes memory management into four coordinated roles: Constructor
  (builds multi-granular memory), Retriever (routes queries adaptively), Judge (verifies
  relevance and detects conflicts), and Refresher (updates or deletes inconsistent
  entries).'
---

# AMA: Adaptive Memory via Multi-Agent Collaboration

## Quick Facts
- **arXiv ID**: 2601.20352
- **Source URL**: https://arxiv.org/abs/2601.20352
- **Reference count**: 40
- **Primary result**: AMA achieves up to 0.774 LLM score on LoCoMo and 0.698 accuracy on LongMemEvals while reducing token consumption by ~80%

## Executive Summary
AMA proposes a multi-agent memory framework that dynamically aligns retrieval granularity with task demands to improve long-term reasoning in LLM agents. The framework decomposes memory management into four coordinated roles: Constructor (builds multi-granular memory), Retriever (routes queries adaptively), Judge (verifies relevance and detects conflicts), and Refresher (updates or deletes inconsistent entries). This design enables adaptive retrieval control and explicit consistency maintenance, avoiding noise from static chunking and preventing logical inconsistencies over time. Evaluated on LoCoMo and LongMemEvals benchmarks, AMA significantly outperforms strong baselines while reducing token consumption by approximately 80% compared to full-context methods.

## Method Summary
AMA is an inference-only multi-agent memory framework that uses SQLite for structured storage, FAISS for vector retrieval, and OpenAI embeddings for semantic matching. The framework implements four specialized agents that coordinate memory lifecycle management without training. The Constructor extracts atomic facts using SVO patterns, the Retriever routes queries via intent classification to appropriate granularity levels, the Judge performs relevance and conflict verification with iterative retrieval loops, and the Refresher maintains consistency through targeted updates or deletions. The system operates with temperature=0, Kr=2 retrieval rounds, and RAG top-k=10, using GPT-4o-mini, GPT-4.1-mini, or Qwen3-8B/30B-Instruct as backbone LLMs.

## Key Results
- Achieves up to 0.774 LLM score on LoCoMo benchmark, outperforming strong baselines
- Reaches 0.698 accuracy on LongMemEvals knowledge-intensive reasoning tasks
- Reduces token consumption by approximately 80% compared to full-context methods
- Knowledge-update accuracy reaches 0.897 with Refresher enabled
- Ablation shows multi-granularity memory contributes 0.062 absolute improvement (0.712 → 0.774)

## Why This Works (Mechanism)

### Mechanism 1: Multi-Granularity Memory Alignment
- Claim: Storing memory at multiple granularities and routing queries to appropriate levels reduces noise and preserves logical dependencies
- Mechanism: Constructor decomposes inputs into atomic SVO-pattern facts while preserving raw text and generating episodic summaries; Retriever uses 4D intent vector to select target memory repository via priority routing
- Core assumption: Task complexity correlates with retrieval granularity; fine-grained queries need precise phrasing while abstract queries need high-level semantics
- Evidence anchors: Hierarchical memory design with intent-based mapping O=fM(B); related work HiMem and SEDM support granularity-alignment hypothesis

### Mechanism 2: Iterative Relevance Verification with Feedback Loops
- Claim: Judge agent filtering retrieved content via dual-verification improves precision and triggers corrective retrieval
- Mechanism: After retrieval, Judge assesses pragmatic utility; if information density falls below threshold, triggers Retry with expanded scope or cross-granularity traversal (bounded by Kr=2)
- Core assumption: LLMs can reliably assess information sufficiency and distinguish relevance from noise
- Evidence anchors: Judge verifies relevance and consistency, triggering iterative retrieval when evidence insufficient; Enhancing Reasoning with Collaboration and Memory explores verification loops

### Mechanism 3: Logic-Driven Memory Consistency Maintenance
- Claim: Explicit conflict detection and targeted update/delete operations prevent accumulation of outdated or contradictory memories
- Mechanism: Judge identifies logical inconsistencies and isolates conflict set Cerr; Refresher performs state modification (Update) or removal (Delete only on explicit request or retention-limit expiry)
- Core assumption: Conflicts can be reliably detected via logical comparison, and updates preserve continuity better than naive deletion
- Evidence anchors: Refresher enforces memory consistency by performing targeted updates or removing outdated entries; no directly comparable conflict-resolution mechanism found in related systems

## Foundational Learning

- **Multi-Agent Role Specialization**: Why needed here: AMA decomposes memory lifecycle into four distinct roles; separation matters because conflicting objectives in monolithic design. Quick check: Can you explain why a single LLM controller might struggle to simultaneously handle retrieval, verification, and conflict resolution?

- **Sentence Pattern Parsing (SVO Decomposition)**: Why needed here: Constructor relies on five canonical patterns (S-V, S-V-O, S-V-C, S-V-O-O, S-V-O-C) to create atomic, parsable facts. Quick check: Given "John moved to Paris last week," can you decompose it into valid SVO-pattern atomic facts?

- **Embedding-Based Retrieval with Cosine Similarity**: Why needed here: All retrieval across granularities uses FAISS with cosine similarity; understanding embedding spaces is essential for debugging retrieval quality. Quick check: What happens to retrieval if fact embeddings and query embeddings drift in semantic space over time?

## Architecture Onboarding

- **Component map**: Input → Retriever (query rewrite + intent classification + granularity routing) → FAISS retrieval → Judge (relevance check → conflict check) → (Conditional: Refresher) → Constructor (synthesize validated memory) → Response Generator

- **Critical path**: 1) Input → Retriever routes query → 2) FAISS retrieval → 3) Judge validates → 3a) Pass → Constructor → Response, 3b) Retry → Return to Retriever (max Kr=2 iterations), 3c) Refresh → Refresher → Constructor

- **Design tradeoffs**: Kr=2 balances performance vs. latency; multi-granularity increases storage complexity but ablation shows Fact Knowledge alone (0.712) underperforms full combination (0.774); Refresher's conservative Delete rule prioritizes memory continuity

- **Failure signatures**: Low relevance scores + high retrieval counts → intent classification failure or embedding drift; knowledge-update accuracy drops → Refresher not triggered; high latency with minimal gains → Kr set too high

- **First 3 experiments**: 1) Granularity ablation: Run AMA with only Fact Knowledge, then incrementally add Raw Text and Episode; compare LoCoMo LLM Score (baseline: 0.712 → target: 0.774). 2) Refresher impact test: On LongMemEvals knowledge-update subset, run AMA with Refresher disabled vs. enabled (expect accuracy drop from 0.897 to ~0.568). 3) Retrieval round limit sweep: Vary Kr from 1 to 5 on LoCoMo; plot LLM Score vs. token consumption to confirm Kr=2 as optimal tradeoff.

## Open Questions the Paper Calls Out
None

## Limitations
- Framework relies heavily on LLM-as-Judge for relevance assessment and conflict detection, introducing potential subjectivity and scalability concerns
- Performance validation limited to synthetic benchmarks with controlled conversation flows; real-world deployment with noisy, unstructured inputs may reveal edge cases
- Granularity threshold ambiguity: four-dimensional intent vector determines routing but lacks explicit thresholds for distinguishing fine/abstract/event/atomic intents

## Confidence
- **High Confidence**: 80% token reduction claim well-supported by comparative analysis; multi-granularity memory design's contribution (0.712 → 0.774) demonstrated through systematic ablation
- **Medium Confidence**: Judge agent's conflict detection effectiveness validated on knowledge-update scenarios (0.897 accuracy) but relies on LLM judgment quality; Kr=2 retrieval limit as optimal tradeoff empirically shown but may not generalize to all task types
- **Low Confidence**: Claim that AMA "generalizes across diverse reasoning tasks" supported by two benchmarks only; real-world task diversity and adversarial inputs could expose limitations not captured in current evaluation

## Next Checks
1. **Stress Test with Adversarial Inputs**: Evaluate AMA on intentionally ambiguous or contradictory queries to assess Judge's conflict detection robustness and routing accuracy under edge cases
2. **Cross-LLM Consistency Validation**: Run the same benchmarks using different LLM-as-Judge models (Claude, Gemini) to verify that performance metrics are not dependent on a single LLM's judgment quality
3. **Longitudinal Memory Drift Analysis**: Simulate extended conversation sequences (>10,000 turns) to measure embedding drift effects on retrieval accuracy and identify potential performance degradation over time