---
ver: rpa2
title: 'Signature vs. Substance: Evaluating the Balance of Adversarial Resistance
  and Linguistic Quality in Watermarking Large Language Models'
arxiv_id: '2511.13722'
source_url: https://arxiv.org/abs/2511.13722
tags:
- watermarking
- text
- watermark
- language
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates four watermarking techniques (KGW, SIR, Unbiased,
  EWD) for LLM-generated text, focusing on adversarial robustness and linguistic quality
  preservation. The study uses OPT-1.3B to generate watermarked texts from C4 dataset,
  then applies paraphrasing and backtranslation attacks.
---

# Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models

## Quick Facts
- arXiv ID: 2511.13722
- Source URL: https://arxiv.org/abs/2511.13722
- Authors: William Guo; Adaku Uchendu; Ana Smith
- Reference count: 7
- Primary result: Unbiased watermarking achieves best overall balance with AUC 0.87 (paraphrasing) and 0.59 (backtranslation) while preserving text quality

## Executive Summary
This paper evaluates four watermarking techniques (KGW, SIR, Unbiased, EWD) for LLM-generated text, focusing on adversarial robustness and linguistic quality preservation. The study uses OPT-1.3B to generate watermarked texts from C4 dataset, then applies paraphrasing and backtranslation attacks. Results show that Unbiased watermarking achieves the best overall balance, maintaining detection performance under both attacks while preserving text quality. KGW performs worst under backtranslation (AUC 0.52). Linguistic analysis reveals that predictions correlate positively with structural features like sentence length (r=0.91) and negatively with positive sentiment (r=-0.75). Backtranslation proves more effective than paraphrasing at removing watermarks.

## Method Summary
The study evaluates four watermarking techniques on OPT-1.3B using C4 dataset prompts. Watermarked texts undergo paraphrasing (via LLaMA-3-8B-Instruct) and backtranslation attacks (via Multilingual LLaMA-3-8B, En→Fr→En). Detection uses z-score or log-likelihood ratio tests to compute AUC scores. Linguistic features include POS tags, sentiment (RoBERTa classifier), Levenshtein distance, and descriptive statistics. Pearson correlations examine relationships between linguistic features and detection predictions.

## Key Results
- Unbiased watermarking achieves best overall balance: AUC 0.87 (paraphrasing) and 0.59 (backtranslation)
- Backtranslation more effective than paraphrasing at removing watermarks
- Linguistic richness (sentence length, word length, syntactic density) correlates positively with watermark robustness (r=0.91)
- Positive sentiment correlates negatively with watermark robustness (r=-0.75)
- KGW performs worst under backtranslation (AUC drops to 0.52)

## Why This Works (Mechanism)

### Mechanism 1: Unbiased Reweighting Preserves Output Distribution
Unbiased watermarking uses unbiased reweighting functions that embed detectable signals without altering the model's output distribution. Watermark codes are generated from context and a secret key via pseudorandom functions, making each watermark unique and undetectable without the key. Detection uses a log-likelihood ratio test.

### Mechanism 2: Linguistic Richness Supports Watermark Retention
Longer, syntactically dense sentences provide more tokens and structural complexity for watermark patterns to persist. Conversely, positive sentiment correlates with decreased robustness—possibly because emotionally positive language tends toward simpler, more formulaic expressions.

### Mechanism 3: Cross-Lingual Transformation Disrupts Surface-Level Watermarks
Backtranslation introduces cross-lingual transformations that eliminate low-level syntactic and lexical markers while preserving semantic content. Paraphrasing within the same language retains more latent structural features.

## Foundational Learning

- **Logit manipulation and token sampling in autoregressive LLMs**: Why needed here - Three of four watermarking techniques operate by modifying logits or sampling distributions during generation. Quick check - Given a vocabulary split into "green" and "red" lists, how does adding a fixed constant to green-token logits change the sampling probability distribution?

- **Statistical hypothesis testing (z-scores, log-likelihood ratio tests)**: Why needed here - Detection mechanisms rely on statistical tests to identify whether observed token patterns deviate from expected baseline distributions. Quick check - If human text has ~50% green tokens and watermarked text has ~60%, how would you compute a z-score for detection?

- **Adversarial text transformations (paraphrasing vs. backtranslation)**: Why needed here - Evaluating robustness requires understanding how each attack preserves semantics while altering surface features differently. Quick check - Why might backtranslation preserve semantic meaning while more effectively disrupting token-level watermark patterns than paraphrasing?

## Architecture Onboarding

- **Component map**: MarkLLM pipeline -> OPT-1.3B (base model) -> Watermarking algorithm (KGW/SIR/Unbiased/EWD) -> Generated text -> Attack transformation (paraphrasing via LLaMA-3-8B-Instruct / backtranslation via Multilingual LLaMA) -> Detection pipeline (z-score or log-likelihood test) -> AUC evaluation

- **Critical path**: 1) Generate watermarked text from C4 prompts using each algorithm 2) Apply adversarial transformations (paraphrasing, backtranslation) 3) Run detection and compute ROC/AUC scores 4) Extract linguistic features (POS tags, sentiment, Levenshtein distance, text statistics) 5) Correlate features with detection predictions

- **Design tradeoffs**:
  - KGW: Strong clean detection (AUC 0.95) but highest text alteration (Levenshtein 823) and worst backtranslation robustness (AUC 0.52)
  - SIR: Minimal text alteration (Levenshtein 127), best clean detection (AUC 0.99), but worst paraphrasing robustness (AUC 0.64)
  - Unbiased: Best overall balance—moderate alteration (Levenshtein 375), strong paraphrasing robustness (AUC 0.87), acceptable backtranslation (AUC 0.59)
  - EWD: Middle ground across all metrics

- **Failure signatures**: High positive sentiment → lower robustness (r = -0.75); Short sentences/words → reduced watermark retention; Cross-lingual transformation → significant AUC drops for Unbiased (0.87→0.59) and KGW (0.80→0.52); Sentiment skew: SIR produces 68% negative vs. 47% original; KGW produces highest positive (27%)

- **First 3 experiments**:
  1. Replicate detection AUC baseline: Generate watermarked text with each method, verify clean detection matches reported values (SIR 0.99, EWD 0.98, Unbiased 0.97, KGW 0.95)
  2. Adversarial robustness test: Apply paraphrasing and backtranslation attacks, confirm AUC degradation patterns (especially Unbiased robustness vs. KGW vulnerability)
  3. Linguistic feature correlation: Compute Pearson correlations between linguistic features (sentence length, word length, POS tags, sentiment) and detection predictions to validate r=0.91 and r=-0.75 findings

## Open Questions the Paper Calls Out

- **How do watermarking techniques perform on code generation, dialogue systems, multilingual corpora, and low-resource or noisy text environments?**: All linguistic evaluations were conducted exclusively on a cleaned subset of the English portion of the C4 dataset, limiting generalizability across domains.

- **How do watermarking techniques behave across different LLM architectures such as LLaMA-3, Mistral, Deepseek, and Phi?**: All experiments were conducted using OPT-13B, which differs in training data, architecture, and decoding behavior from other widely used models.

- **What effect do additional adversarial attacks—such as decoding manipulation (temperature tuning, nucleus sampling), prompt injection, and adversarial fine-tuning—have on watermark robustness?**: Techniques such as decoding manipulation, prompt injection, and adversarial fine-tuning were not evaluated.

- **Why is positive sentiment strongly negatively correlated (r = -0.75) with watermark robustness, and can watermark designs mitigate this vulnerability?**: The correlation analysis shows texts with positive sentiment are significantly less robust, but no mechanism is proposed to explain this finding or address it.

## Limitations
- Hyperparameter sensitivity not specified (green list bias strength, seeding schemes, entropy thresholds)
- Model size discrepancy between abstract (OPT-1.3B) and limitations (OPT-13B)
- Attack implementation details missing (decoding parameters, max token lengths)
- Linguistic correlation analysis is descriptive rather than explanatory

## Confidence
- **High Confidence**: Comparative ranking of watermarking methods under clean detection conditions (SIR > EWD > Unbiased > KGW in AUC scores)
- **Medium Confidence**: Unbiased watermarking achieves best overall balance, depending on weighting of multiple factors
- **Low Confidence**: Causal explanation linking positive sentiment to reduced watermark robustness (r=-0.75) is speculative

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary key hyperparameters for each watermarking method and measure impact on detection AUC and linguistic quality to determine robustness to parameter choices.

2. **Cross-Model Generalization Test**: Reproduce experiments using both OPT-1.3B and OPT-13B to verify whether relative performance rankings and linguistic correlation patterns hold across different model scales.

3. **Mechanism Validation for Sentiment Correlation**: Design experiments that directly test whether simpler expressions in positive text explain the correlation, such as controlling for sentence complexity while varying sentiment.