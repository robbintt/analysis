---
ver: rpa2
title: 'Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large
  Language Models'
arxiv_id: '2502.09687'
source_url: https://arxiv.org/abs/2502.09687
tags:
- emotional
- setup
- rational
- persuasion
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzed how 12 large language models (LLMs) generate
  rational versus emotional persuasion by prompting them with tailored instructions
  and analyzing responses using LIWC-22 and human annotation for social influence
  principles. Emotional prompts triggered higher cognitive complexity and insight
  but also greater polarization, while rational prompts emphasized factual, less confrontational
  arguments.
---

# Mind What You Ask For: Emotional and Rational Faces of Persuasion by Large Language Models

## Quick Facts
- arXiv ID: 2502.09687
- Source URL: https://arxiv.org/abs/2502.09687
- Reference count: 8
- Primary result: LLM-generated persuasion varies systematically with emotional versus rational prompt framing, affecting cognitive complexity and social influence principle deployment

## Executive Summary
This study examined how large language models generate rational versus emotional persuasion through tailored prompts. The research team analyzed responses from 12 commercial and open models, revealing that emotional prompts trigger higher cognitive complexity and insight but also greater polarization, while rational prompts emphasize factual, less confrontational arguments. Across all models, the most common social influence principles deployed were social proof, authority, and commitment and consistency. The baseline setup showed a subtle negative affect, particularly anger and sadness, despite its neutral framing.

## Method Summary
The research team employed a mixed-methods approach, combining automated text analysis with human annotation. They prompted 12 large language models with emotional, rational, and neutral instructions, then analyzed responses using LIWC-22 (Linguistic Inquiry and Word Count) software to quantify emotional and cognitive dimensions. Human annotators classified responses for social influence principles including reciprocity, commitment, social proof, authority, liking, and scarcity. The study compared patterns across different model families and evaluated the effectiveness of emotional versus rational persuasion strategies.

## Key Results
- Emotional prompts produced responses with higher cognitive complexity and insight but also greater polarization compared to rational prompts
- The most common social influence principles across all models were social proof, authority, and commitment and consistency
- Baseline neutral prompts exhibited subtle negative affect, particularly anger and sadness, despite their neutral framing

## Why This Works (Mechanism)
Large language models generate persuasive content by leveraging patterns learned during training on vast text corpora. When prompted with emotional instructions, models access and recombine emotional language patterns that trigger higher cognitive processing in readers. The models' architecture allows them to deploy social influence principles effectively because these principles are well-represented in their training data from persuasive texts, marketing materials, and social media content. The variation between emotional and rational outputs reflects the models' ability to match language style to prompt intent while maintaining persuasive effectiveness.

## Foundational Learning
1. **Social influence principles**: Why needed - To understand how LLMs employ persuasion techniques; Quick check - Verify presence of reciprocity, authority, and social proof in model outputs
2. **Cognitive complexity metrics**: Why needed - To measure depth of reasoning in persuasive responses; Quick check - Compare LIWC-22 cognitive processing scores between prompt types
3. **Emotional intensity detection**: Why needed - To quantify affective content in LLM-generated text; Quick check - Validate LIWC-22 affect scores against human annotation
4. **Model family characteristics**: Why needed - To identify systematic differences in persuasion strategies; Quick check - Compare performance across GPT, Claude, and open-source models
5. **Prompt engineering impact**: Why needed - To understand how instruction framing affects output; Quick check - Test multiple variations of emotional and rational prompts

## Architecture Onboarding
**Component Map**: Prompt Input -> LLM Processing -> Text Generation -> LIWC-22 Analysis -> Human Annotation
**Critical Path**: Prompt formulation → Model response generation → Automated linguistic analysis → Human principle classification → Cross-model comparison
**Design Tradeoffs**: Automated analysis provides scalability but may miss nuanced persuasion; human annotation adds accuracy but limits sample size
**Failure Signatures**: Inconsistent principle deployment across models; unexpected negative affect in neutral prompts; variable polarization effects
**First Experiments**:
1. Test additional emotional prompt variations to map the full spectrum of affective responses
2. Compare model families across multiple languages to identify cultural influences on persuasion
3. Conduct controlled human-subject experiments to validate LIWC-22 classifications and measure actual persuasive effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis covered only 12 commercial and open models, potentially missing important variation in other architectures
- LIWC-22's dictionary-based approach may not capture all nuances of emotional versus rational language, particularly for non-English corpora
- Human annotation relied on a small annotator pool with some inter-annotator variability

## Confidence
- High confidence: Emotional versus rational prompt effects on cognitive complexity and emotional intensity
- Medium confidence: Cross-model consistency in social influence principle deployment
- Medium confidence: Baseline condition's negative affect patterns
- Low confidence: Precise quantification of polarization effects

## Next Checks
1. Replicate analysis with additional model families and newer versions released after this study's timeframe
2. Conduct controlled human-subject experiments to validate LIWC-22 classifications and assess actual persuasive effectiveness
3. Test prompt variations across multiple languages to examine cultural and linguistic influences on LLM persuasion patterns