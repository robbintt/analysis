---
ver: rpa2
title: Meta-learning Representations for Learning from Multiple Annotators
arxiv_id: '2506.10259'
source_url: https://arxiv.org/abs/2506.10259
tags:
- data
- annotators
- meta-learning
- learning
- proposed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning accurate classifiers
  from limited noisy labeled data provided by multiple annotators in target tasks,
  by leveraging clean labeled data from related source tasks. The proposed method
  uses meta-learning to train a neural network that embeds examples into a latent
  space, combined with a probabilistic model (Gaussian mixture model) to handle noisy
  labels and estimate annotators' abilities.
---

# Meta-learning Representations for Learning from Multiple Annotators

## Quick Facts
- arXiv ID: 2506.10259
- Source URL: https://arxiv.org/abs/2506.10259
- Reference count: 40
- One-line primary result: Meta-learning approach using pseudo-annotation strategy and EM algorithm achieves 0.892 accuracy on Omniglot, 0.542 on MiniImagenet, and 0.520 on LabelMe for learning from multiple noisy annotators.

## Executive Summary
This paper addresses the challenge of learning accurate classifiers from limited noisy labeled data provided by multiple annotators in target tasks, by leveraging clean labeled data from related source tasks. The proposed method uses meta-learning to train a neural network that embeds examples into a latent space, combined with a probabilistic model (Gaussian mixture model) to handle noisy labels and estimate annotators' abilities. The key innovation is the use of a pseudo-annotation strategy during meta-training, where synthetic noisy labels are generated to simulate the target task environment, and an EM algorithm is used for efficient adaptation.

## Method Summary
The method trains a CNN to embed examples into a latent space, then applies a GMM with prototypes and annotator confusion matrices to model the noisy labels. During meta-training, synthetic noisy labels are generated from clean source data using sampled confusion matrices, and the embedding network is trained via bi-level optimization where the inner loop uses EM to estimate prototypes and confusion matrices. The outer loop updates the embedding parameters by backpropagating through the differentiable EM steps. At test time, given a new task with noisy labels, the model adapts via EM and classifies new examples based on the estimated posterior probabilities.

## Key Results
- Achieves average accuracies of 0.892 on Omniglot, 0.542 on MiniImagenet, and 0.520 on LabelMe
- Outperforms existing meta-learning methods for learning from multiple annotators by 0.5% to 20% depending on dataset and experimental conditions
- Shows robustness to varying spammer ratios while maintaining competitive performance

## Why This Works (Mechanism)

### Mechanism 1: Pseudo-Annotation for Distribution Alignment
Injecting synthetic noise during meta-training improves adaptation to noisy target tasks by creating a training environment that mirrors the test-time distribution of noisy labels. The paper generates pseudo-annotations by simulating annotator confusion matrices from a distribution $p(B)$ and applying them to clean source data, allowing the model to learn robust representations that separate classes despite label noise.

### Mechanism 2: Closed-Form EM for Noise-Robust Prototype Estimation
The EM algorithm jointly estimates class prototypes and annotator reliability, filtering noise during adaptation. The E-step computes responsibilities (probability of true class given noisy labels and current prototypes) using Bayes' rule, weighting annotations by estimated annotator confusion matrices. The M-step updates prototypes as responsibility-weighted averages of embeddings, effectively down-weighting noisy annotations.

### Mechanism 3: Meta-Learned Embeddings for Noise-Resilient Latent Spaces
Meta-learning the embedding network creates representations where classes are separable despite noise. The outer optimization minimizes test loss on query sets after inner-loop adaptation via EM on pseudo-noisy support sets. Gradients backpropagate through the differentiable EM updates to adjust the embedding parameters, shaping the latent space to facilitate EM's noise handling.

## Foundational Learning

- **Concept: Gaussian Mixture Models (GMMs)**
  - Why needed here: The model treats embeddings as generated from class-conditional Gaussians, forming a GMM in latent space where each component is a prototype
  - Quick check question: Can you derive the posterior probability of a point belonging to a Gaussian cluster given its mean and covariance?

- **Concept: Expectation-Maximization (EM) Algorithm**
  - Why needed here: EM iteratively estimates latent true labels and updates model parameters to maximize the data likelihood, handling the missing true labels
  - Quick check question: Explain why EM monotonically increases the log-likelihood and when it might converge to a poor local optimum

- **Concept: Meta-Learning (Bi-Level Optimization)**
  - Why needed here: The method uses an outer loop to learn shared embeddings and an inner loop (EM) for task-specific adaptation, enabling fast learning on new noisy tasks with few examples
  - Quick check question: How does backpropagating through the inner-loop updates (like EM steps) differ from standard fine-tuning?

## Architecture Onboarding

- **Component map:** CNN embedding -> GMM with prototypes and confusion matrices -> EM adapter -> meta-optimizer

- **Critical path:** 1. Meta-training: Sample source task → generate pseudo-noise → embed support/query → EM adaptation on support → compute loss on query → backprop through EM to update embedding parameters. 2. Testing: Given noisy support set from target task → embed → EM adaptation → classify query via posterior

- **Design tradeoffs:** EM steps (J): More steps improve adaptation but increase computation; Embedding dimension (M): Higher dimensions may improve separability but risk overfitting; Confusion matrix complexity: Simple matrices are robust in small-data regimes

- **Failure signatures:** High spammer ratio degrades accuracy; Source-target discrepancy leads to poor performance; Few annotators make confusion matrix estimates unreliable

- **First 3 experiments:** 1. Reproduce Omniglot results (Table 1) to validate pseudo-annotation benefit vs. baseline; 2. Ablate EM steps (vary J∈{1,2,3,5,10}) to confirm J=2 is sufficient; 3. Visualize embeddings via t-SNE to qualitatively assess cluster separation

## Open Questions the Paper Calls Out

- Can the framework be extended to handle input example-dependent confusion matrices to model annotator behaviors more granularly?
- How can the proposed meta-learning approach be adapted for active learning to optimize the selection of examples or annotators?
- Does substituting variational Bayesian inference for the EM algorithm improve the model's robustness or uncertainty estimation?
- How robust is the meta-learning procedure if the source tasks contain label noise rather than the assumed clean ground truth?

## Limitations

- Performance is sensitive to the assumption that source task noise distributions adequately represent target task noise
- Closed-form EM algorithm assumes class-dependent but input-independent annotator errors through confusion matrices
- The method requires clean labeled data from source tasks, which may be difficult to obtain in practice

## Confidence

- **High confidence:** The meta-learning framework and pseudo-annotation strategy are technically sound and well-supported by the paper's mathematical formulation and ablation studies
- **Medium confidence:** The specific performance numbers are likely reproducible with careful implementation, though exact splits and preprocessing details would affect results
- **Medium confidence:** The claimed improvements over baselines are plausible given the method's design, but would require careful baseline reproduction to verify

## Next Checks

1. Create target tasks with annotator behaviors outside the meta-training noise distribution to evaluate the method's limits when the pseudo-annotation assumption breaks
2. Implement an extension where confusion matrices depend on input embeddings and compare performance to validate whether the input-independent assumption is a practical limitation
3. Test the method on a dataset with fundamentally different visual characteristics than Omniglot/MiniImagenet to assess how source-target task distribution shifts affect the meta-learned representations