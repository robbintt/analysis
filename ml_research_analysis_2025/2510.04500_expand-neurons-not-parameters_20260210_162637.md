---
ver: rpa2
title: Expand Neurons, Not Parameters
arxiv_id: '2510.04500'
source_url: https://arxiv.org/abs/2510.04500
tags:
- neurons
- dense
- neuron
- number
- interference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that increasing the number of neurons in
  a network without increasing the number of non-zero parameters improves performance
  by reducing interference between features that would otherwise share the same neurons.
  The authors introduce Fixed Parameter Expansion (FPE), which replaces a neuron with
  multiple children and partitions the parent's weights disjointly across them, so
  that each child inherits a non-overlapping subset of connections.
---

# Expand Neurons, Not Parameters

## Quick Facts
- arXiv ID: 2510.04500
- Source URL: https://arxiv.org/abs/2510.04500
- Authors: Linghao Kong; Inimai Subramanian; Yonadav Shavit; Micah Adler; Dan Alistarh; Nir Shavit
- Reference count: 40
- One-line primary result: Increasing neurons without increasing non-zero parameters improves performance by reducing interference through disjoint weight partitioning

## Executive Summary
This work introduces Fixed Parameter Expansion (FPE), a technique that increases network width while maintaining constant non-zero parameters by partitioning existing neuron weights across multiple children. The method reduces polysemanticity and feature interference, leading to improved accuracy on both synthetic Boolean tasks and real image classification problems. FPE leverages the fact that modern accelerators are bottlenecked by memory movement of non-zero parameters, not parameter count itself.

## Method Summary
FPE replaces each parent neuron with α child neurons, partitioning the parent's weights into disjoint subsets via binary masks. Input connections are split such that each child receives a non-overlapping subset of the parent's connections, while output connections are re-sparsified to maintain the original non-zero parameter count. The method is applied after initial dense training (20-25 epochs for vision tasks), with random or feature-aware splitting. The technique maintains constant non-zero parameters while expanding width, reducing interference between features that would otherwise share neurons.

## Key Results
- FPE systematically reduces polysemanticity metrics and yields higher task accuracy on symbolic Boolean tasks
- Random splits of neuron weights approximate gains from feature-aware splits, indicating reduced collisions are the primary driver
- Benefits grow with increasing interference and are consistent across classifiers over CLIP embeddings and deeper multilayer networks
- Maintains constant non-zero parameter count while improving accuracy, well-suited for memory-bound accelerators

## Why This Works (Mechanism)

### Mechanism 1: Disjoint Weight Partitioning Reduces Feature Interference
Partitioning a neuron's weights across multiple children reduces interference between features that would otherwise compete for the same neuron. Each parent neuron is replaced by α sub-neurons with input connections partitioned via disjoint binary masks so each child receives a non-overlapping subset. Within-feature alignment is preserved while between-feature interactions are suppressed. Core assumption: features use different incident edges to process different features (from combinatorial interpretability). Evidence: Gram matrices show FPE yields "more strongly block-diagonal" structure; clause-split achieves 99.4% vs dense 78.7% accuracy on Boolean DNF (α=2, 8 clauses). Break condition: When network already has sufficient capacity, superposition pressure is low and splitting yields diminishing returns.

### Mechanism 2: Coverage Preservation Under Sparse Expansion
Random sparse connections maintain clause coverage with high probability while reducing collisions exponentially. With αr sparse neurons each connecting to d=m/α inputs, probability of missing any clause is bounded by C·e^(-r/α^(k-1)). Collision probability drops by factor α^-(2k-1). Core assumption: independence between neuron mask selections (relaxed in analysis). Evidence: Theoretical derivation shows Pr[all clauses covered] ≥ 1 - C·e^(-r/α^(k-1)) and collision ratio E_FPE/E_dense ≈ 1/α^(2k-1); random-split FPE achieves 88.7% vs dense 78.7% on Boolean task. Break condition: When m is small relative to k, sparse coverage probability degrades.

### Mechanism 3: Interference-Moderated Performance Gains
Accuracy improvements from FPE scale with polysemantic load; gains are largest when interference is high. Feature capacity increases under FPE; cosine similarity between neuron weight vectors decreases. Regression shows strong correlation between capacity increase and relative accuracy improvement. Core assumption: feature capacity and orthogonality are valid proxies for representational quality. Evidence: Regressions reveal strong correlations between relative improvement and interference metrics with R² shown; on CIFAR-100 with 8 neurons, FPE achieves "double dense performance" in some configurations. Break condition: Beyond ~16 clauses with 8 neurons, capacity saturates and gains plateau.

## Foundational Learning

- **Concept: Superposition hypothesis**
  - Why needed here: Explains why FPE works—networks compress more features than neurons by representing multiple features per neuron, creating interference
  - Quick check question: Can you explain why a network with 8 neurons can learn 16 Boolean clauses but with reduced accuracy?

- **Concept: Polysemanticity and feature capacity**
  - Why needed here: Provides the metrics (feature capacity, cosine similarity) to measure whether FPE actually reduces interference
  - Quick check question: If neuron weight vectors become more orthogonal after FPE, what does this imply about feature interference?

- **Concept: Sparse training and mask-based sparsity**
  - Why needed here: FPE implements structured sparsity via binary masks; understanding mask operations is essential for implementation
  - Quick check question: How does keeping non-zero parameter count constant while increasing neurons differ from standard pruning?

## Architecture Onboarding

- **Component map:** Parent neuron (h) → α child neurons (h' = αh) → Input mask M₁ partitions input dimension into α disjoint masks per parent → Output mask M₂ handles width mismatch via re-sparsification

- **Critical path:** 1) Train dense baseline for warmup epochs (20-25 for vision tasks) → 2) Apply FPE: duplicate neurons, assign disjoint input masks → 3) Re-sparsify output layer to maintain parameter budget → 4) Continue training under fixed non-zero parameter constraint

- **Design tradeoffs:** Clause-aware splitting (requires feature knowledge) vs random splitting (no prior knowledge, still effective); earlier splitting → higher final accuracy but longer sparse training; higher α → more interference reduction but more aggressive sparsity per neuron; unstructured vs 2:4 structured sparsity: latter enables hardware acceleration with minimal accuracy loss

- **Failure signatures:** Gains diminish for wide baselines (≥16 neurons for simple tasks); late splitting after extended dense training may trap network in suboptimal representations; feature-based splitting underperforms expectations when Gram matrix clustering doesn't recover true features

- **First 3 experiments:** 1) Boolean DNF with 8 clauses, 8 neurons, α=2: compare dense vs clause-split vs random-split accuracy and Gram matrix structure → 2) CIFAR-100 CLIP embeddings with 8-32 neurons: measure relative improvement vs cosine similarity reduction across widths → 3) Timing ablation: split at epoch 5, 10, 20, 50 of 100-epoch training to quantify early-split advantage

## Open Questions the Paper Calls Out

- **Can more precise feature attribution or disentanglement methods outperform random splitting in real-world tasks?**
  - Basis in paper: The authors state: "Developing more precise feature attribution or disentanglement methods remains an important avenue for future work" after noting that their Gram matrix clustering approach performed only comparably to random splitting on vision tasks
  - Why unresolved: The feature-based splitting algorithm likely did not recover the "true" underlying feature structure of real data, unlike in Boolean tasks where clause boundaries are known
  - What evidence would resolve it: A method that consistently outperforms random splitting on CIFAR-100/ImageNet by better identifying feature groupings in pretrained networks

- **Does FPE transfer to transformer architectures and attention mechanisms?**
  - Basis in paper: All experiments use MLPs (single-layer and 5-layer classifiers). The methodology of partitioning weights disjointly may interact differently with attention heads, query/key/value projections, or residual connections
  - Why unresolved: FPE is designed for feedforward layers; attention layers have different interference patterns and weight sharing structures not explored in this work
  - What evidence would resolve it: Systematic evaluation of FPE applied to transformer attention layers or MLP sublayers on language/vision tasks

- **What is the optimal timing of the FPE split operation during training?**
  - Basis in paper: The paper notes that "Performing FPE splitting earlier consistently leads to higher final test accuracy than later splits" and suggests late splits may "trap the network in suboptimal representations," but does not characterize the optimal split epoch or criteria
  - Why unresolved: The trade-off between allowing initial representation learning and enabling disentanglement is not fully explored across different architectures and tasks
  - What evidence would resolve it: A sweep over split timing with analysis of when learned representations become sufficiently stable to benefit from expansion

## Limitations
- Benefits diminish as network width increases and superposition pressure decreases
- Theoretical coverage analysis assumes independence between mask selections
- Random-splitting approach may not generalize to all architectural patterns beyond single-hidden-layer MLPs
- Feature-based splitting underperforms expectations when Gram matrix clustering doesn't recover true features

## Confidence
- **High confidence:** The core mechanism of reducing interference through disjoint weight partitioning is well-supported by Gram matrix analysis and empirical results on Boolean tasks
- **Medium confidence:** The claim that random splits approximate clause-aware splits holds for the studied Boolean tasks but may not generalize to more complex feature structures
- **Medium confidence:** The assertion that FPE maintains constant non-zero parameters while improving accuracy is technically sound but requires careful implementation of the re-sparsification step

## Next Checks
1. Test FPE on deeper architectures (2+ hidden layers) to validate scalability beyond single-layer networks
2. Compare FPE against other sparse training methods (dynamic sparse, sparse evolutionary training) on identical parameter budgets
3. Measure inference latency and energy consumption on actual hardware to verify the claimed memory movement advantages