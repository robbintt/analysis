---
ver: rpa2
title: 'Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection'
arxiv_id: '2508.06552'
source_url: https://arxiv.org/abs/2508.06552
tags:
- dataset
- deepfake
- age-diverse
- detection
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses demographic bias in deepfake datasets by focusing
  on age diversity. The core method involves creating an age-diverse deepfake dataset
  through a modular pipeline that combines existing datasets (Celeb-DF, FaceForensics++,
  UTKFace) with synthetic data generated using SimSwap and InsightFace.
---

# Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection

## Quick Facts
- arXiv ID: 2508.06552
- Source URL: https://arxiv.org/abs/2508.06552
- Reference count: 24
- Primary result: Age-diverse dataset improves deepfake detection fairness across age groups with AUC > 0.997, EER < 0.014

## Executive Summary
This paper addresses demographic bias in deepfake datasets by creating an age-diverse dataset through synthetic augmentation. The author combines existing datasets (Celeb-DF, FaceForensics++, UTKFace) with synthetically generated deepfakes using SimSwap and InsightFace to balance age representation. Models trained on this dataset demonstrate fairer performance across age groups and higher generalization compared to those trained on single-source datasets, achieving AUC scores above 0.997 and EER below 0.014 for all age demographics.

## Method Summary
The method involves constructing an age-diverse deepfake dataset through a modular pipeline. First, existing deepfake datasets are analyzed for age distribution bias, revealing underrepresentation of children (0-10), teenagers (10-18), and elderly (51+) groups. The pipeline then undersamples overrepresented groups and generates synthetic deepfakes for underrepresented groups using SimSwap face-swapping guided by InsightFace attribute matching. The resulting dataset contains balanced age groups and is used to train XceptionNet, EfficientNet, and LipForensics models, which are evaluated using AUC, pAUC, and EER metrics.

## Key Results
- Models trained on age-diverse dataset achieved AUC > 0.997 and EER < 0.014 across all age groups
- Cross-dataset generalization improved significantly compared to models trained on source datasets
- Source datasets demonstrated skewed age distribution with null values for evaluation in underrepresented groups (0-10, 10-18, 51+)
- Synthetic data generation achieved average SSIM of 0.40 and PSNR of 0.28 dB

## Why This Works (Mechanism)

### Mechanism 1: Distribution Balancing via Synthetic Augmentation
If models are trained on datasets with skewed age distributions, they overfit to the majority demographic; balancing these distributions via synthetic data generation and undersampling appears to improve cross-dataset generalization. The authors identify underrepresented age groups (0-10, 10-18, 51+) and use a face-swapping pipeline (SimSwap) to generate synthetic deepfakes for these specific groups, while undersampling the overrepresented 19-35 group. This forces the model to learn features distributed across age demographics rather than memorizing the artifacts of the majority group.

### Mechanism 2: Attribute-Constrained Face Swapping
Effective synthetic data generation for underrepresented groups likely depends on matching source images to target videos based on facial attributes (pose, brightness) to ensure the resulting deepfake is learnable. The pipeline uses InsightFace to extract facial attributes (yaw, pitch, brightness) and calculates cosine similarity to match a real image (UTKFace) to a target video before using SimSwap. This constrains the swapping process to feasible pairs, presumably reducing training noise.

### Mechanism 3: Fairness-Aware Regularization through Data Stratification
Training on a dataset stratified evenly across age groups acts as a form of regularization, reducing the variance of the model's error rates across demographics. By constructing a dataset with exactly 525 real videos per age group and ~700+ fake videos, the loss function receives equal gradient updates from each demographic. This prevents the "accuracy paradox" where high overall accuracy masks poor performance on minority groups.

## Foundational Learning

- **Concept: Demographic / Covariate Shift in Computer Vision**
  - Why needed here: The core problem is that training data has a different age distribution (mostly 19-35) than the potential real-world deployment distribution. Understanding domain shift explains why high training accuracy fails to generalize.
  - Quick check question: If a model achieves 99% accuracy on a dataset of only young adults, can we expect it to work reliably on elderly subjects? (Answer: Likely no, due to distribution mismatch).

- **Concept: Synthetic Data Augmentation vs. Oversampling**
  - Why needed here: The paper uses generative models to create new data rather than just duplicating existing minority samples. Understanding the difference is keyâ€”synthetic data adds variance, while oversampling can lead to overfitting.
  - Quick check question: Why might generating a synthetic deepfake of an elderly person be better than simply copying the few existing elderly deepfakes multiple times?

- **Concept: Evaluation Metrics: AUC vs. EER vs. pAUC**
  - Why needed here: The paper relies on these metrics to prove "fairness." AUC measures overall separability, while EER indicates the point where false positives equal false negatives. pAUC focuses on low false-positive rates, which is critical in security contexts.
  - Quick check question: Why is pAUC particularly important for deepfake detection in a security screening context? (Answer: We cannot tolerate many false accusations; low FPR is prioritized).

## Architecture Onboarding

- **Component map**: Frame extraction (OpenCV) -> Age Annotation (DeepFace) -> Demographic Analysis -> Synthetic Pipeline (InsightFace matching + SimSwap generation) -> Training (XceptionNet, EfficientNet, LipForensics) -> Evaluation (Stratified test sets -> AUC/pAUC/EER calculation per age group)

- **Critical path**: The Synthetic Pipeline is the critical novelty. If InsightFace fails to match suitable source/target pairs, or if SimSwap produces low-quality swaps (SSIM < 0.4), the resulting dataset will be noisy and the generalization claims may not hold.

- **Design tradeoffs**: 
  - Quality vs. Diversity: The paper reports an average SSIM of 0.40 for synthetic videos, trading off visual perfection for statistical diversity across age groups
  - Memorization vs. Generalization: Training on single-source datasets leads to memorization (overfitting), whereas the mixed/synthetic dataset forces generalization

- **Failure signatures**:
  - Synthetic Artifacts: If the model detects SimSwap-specific artifacts rather than general deepfake features, it will fail on real-world deepfakes
  - Annotation Noise: Age annotation via DeepFace may be biased (e.g., poor on certain ethnicities), leading to mislabeled "age-diverse" dataset

- **First 3 experiments**:
  1. Replicate the Balance: Take source datasets, perform undersampling, and verify baseline performance drop/gain compared to full imbalanced set
  2. Ablate the Synthetic Data: Train model using only real undersampled data (no synthetic) vs. full synthetic-enhanced dataset to isolate SimSwap value
  3. Cross-Method Generalization: Test trained model on dataset from generator not included in training (e.g., DeepFakes or Face2Face samples from FF++) to check if model learned generic features or just face-swap features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What pipeline modifications are required to improve the structural fidelity (SSIM > 0.40) of synthetic deepfakes for underrepresented age groups?
- Basis in paper: The authors explicitly identify the "improvement of the quality of synthetic data for diverse age groups" as a primary direction for future work, noting the current average SSIM was limited to 0.40.

### Open Question 2
- Question: How robust is the age-diverse model when evaluated against "in-the-wild" deepfake datasets rather than controlled source datasets?
- Basis in paper: The paper lists the "inclusion of unseen data sources in validation" as a key future step, acknowledging the limitation that validation was restricted to source and generated datasets.

### Open Question 3
- Question: Does balancing for age diversity inadvertently introduce or exacerbate biases in other demographic variables like gender or ethnicity?
- Basis in paper: The authors call for the "expansion of fairness assessment in additional demographic variables such as gender and ethnicity" in future research.

## Limitations
- Synthetic data quality is moderate (SSIM 0.40, PSNR 0.28 dB), potentially causing models to learn method-specific artifacts rather than general deepfake features
- Limited testing on unseen deepfake generation methods, leaving true generalization unverified
- Age annotation via DeepFace may introduce bias, particularly across different ethnicities

## Confidence
- **High Confidence**: Claims about dataset construction and specific training procedures (hyperparameters, data preprocessing)
- **Medium Confidence**: Claims about improved cross-dataset generalization and fairness across age groups
- **Low Confidence**: Claims about real-world deployment readiness due to lack of testing on unseen methods

## Next Checks
1. Conduct detailed synthetic data quality analysis comparing SSIM/PSNR to native deepfakes to assess risk of learning method-specific artifacts
2. Evaluate trained models on deepfakes generated by methods not included in training (e.g., DeepFakes, Face2Face) to test true generalization
3. Expand evaluation to include additional fairness metrics such as demographic parity and equal opportunity across age groups