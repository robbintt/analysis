---
ver: rpa2
title: Bandit Pareto Set Identification in a Multi-Output Linear Model
arxiv_id: '2507.04255'
source_url: https://arxiv.org/abs/2507.04255
tags:
- arms
- log2
- algorithm
- linear
- pareto
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of identifying the Pareto set in
  a structured multi-output linear bandit model, where each arm has a feature vector
  and its mean vector depends linearly on this feature through an unknown matrix.
  The authors propose GEGE, the first optimal design-based algorithm for this problem,
  which combines G-optimal design exploration with an accept/reject mechanism based
  on sub-optimality gap estimation.
---

# Bandit Pareto Set Identification in a Multi-Output Linear Model

## Quick Facts
- arXiv ID: 2507.04255
- Source URL: https://arxiv.org/abs/2507.04255
- Reference count: 40
- Authors: Cyrille Kone; Emilie Kaufmann; Laura Richert
- One-line primary result: GEGE is the first optimal design-based algorithm for Pareto set identification in multi-output linear bandits, achieving near-optimal sample complexity that scales with h smallest gaps instead of all K gaps.

## Executive Summary
This paper addresses the problem of identifying Pareto-optimal arms in a structured multi-output linear bandit setting, where each arm's mean vector is linearly related to its feature vector through an unknown parameter matrix. The authors propose GEGE, an algorithm that leverages G-optimal design to reduce sample complexity from depending on all K arms to depending only on the h smallest sub-optimality gaps. The algorithm operates in both fixed-budget and fixed-confidence settings, combining variance-minimizing exploration with an accept/reject mechanism for elimination. Theoretical analysis shows that GEGE achieves near-optimal sample complexity bounds, and extensive experiments demonstrate superior performance compared to unstructured approaches.

## Method Summary
GEGE operates by first computing a G-optimal design over the transformed feature space to uniformly efficiently estimate the shared parameter matrix Θ, then using this estimate to calculate empirical Pareto sets and sub-optimality gaps. The algorithm iteratively pulls arms according to the rounded design, updates the estimate of Θ via ordinary least squares, and eliminates arms that are provably sub-optimal. In the fixed-confidence setting, it allocates samples based on error radius thresholds, while in the fixed-budget setting it allocates proportionally to remaining time. The key innovation is the use of G-optimal design to reduce variance in estimating Θ, combined with a careful elimination mechanism that ensures no Pareto-optimal arm is prematurely discarded.

## Key Results
- Sample complexity scales with h smallest sub-optimality gaps rather than all K gaps
- Achieves near-optimal bounds in both fixed-budget and fixed-confidence settings
- Outperforms unstructured PSI algorithms by a factor of h in sample complexity
- Validated on synthetic data and real-world datasets (Network-on-Chip, Energy Efficiency)
- Theoretical analysis provides explicit sample complexity bounds with tight constants

## Why This Works (Mechanism)

### Mechanism 1: G-Optimal Design for Variance Reduction
GEGE reduces sample complexity from a sum over K arms to a sum over h feature dimensions by exploiting the linear structure via G-optimal design. The algorithm estimates the shared parameter matrix Θ ∈ ℝ^(h×d) rather than K independent mean vectors. It computes a continuous allocation w* (G-optimal design) over the transformed feature space B^T x_i to minimize the maximum variance of the least-squares estimator, then rounds this to an integer allocation. This approach differs fundamentally from prior work that treats arms as unstructured. The core assumption is that mean vectors strictly follow the linear model μ_k = Θ^T x_k with i.i.d. σ-sub-Gaussian noise.

### Mechanism 2: Dominator-Preserving Elimination
The algorithm correctly identifies the Pareto set by ensuring that a sub-optimal arm i is never eliminated before at least one arm that dominates it (i*). The elimination step uses an accept/reject mechanism where arms are discarded only if their empirical gap Δ̂_{i,r} is large relative to the estimation error radius. The analysis introduces a "Good Event" P_r which guarantees that if a sub-optimal arm i is active, a dominating arm i* is also active. This prevents i from falsely appearing Pareto-optimal due to premature removal of better arms. The mechanism relies on the assumption that estimation error is bounded by specific thresholds ε_r (fixed-confidence) or λΔ (fixed-budget).

### Mechanism 3: Adaptive Rounding via Allen-Zhu
The conversion of continuous G-optimal design to discrete sampling sequence maintains O(h) sample efficiency guarantee. Standard rounding methods can degrade optimality guarantees, but GEGE utilizes a rounding procedure (referencing Allen-Zhu et al., 2017) that provides a theoretical bound on the degradation of the optimal design value. Specifically, it ensures that the maximum variance of projected features remains within a (1+6κ) factor of the optimal continuous design. This requires the sampling budget N to be large enough (N ≥ 5h_S/κ^2). The rounding procedure is crucial for maintaining the theoretical guarantees when converting continuous allocations to actual arm pulls.

## Foundational Learning

- **Concept: Pareto Dominance & Sub-optimality Gaps**
  - Why needed here: Unlike standard bandits with a scalar "best arm," here we have a set of non-dominated arms. The complexity measure Δ_i (gap) is defined differently for optimal arms (distance to nearest neighbor) vs. sub-optimal arms (distance to the Pareto front).
  - Quick check question: Can you explain why the gap Δ_i for a Pareto-optimal arm might be very small, and how this differs from the gap of a sub-optimal arm?

- **Concept: Ordinary Least Squares (OLS) with Design Matrices**
  - Why needed here: The core engine of GEGE is estimating the matrix Θ. Understanding how feature covariance (V_n) relates to estimator variance (||Θ̂ - Θ||) is essential to grasp why "optimal design" is necessary.
  - Quick check question: If two feature vectors x_i, x_j are collinear, what happens to the information matrix V_n and the resulting estimate?

- **Concept: Fixed-Budget vs. Fixed-Confidence Settings**
  - Why needed here: The paper provides two variants of GEGE. In Fixed-Budget, you allocate samples proportionally to remaining time; in Fixed-Confidence, you allocate samples based on the current error radius ε_r until you are sure.
  - Quick check question: In the Fixed-Confidence setting, does the algorithm know Δ_i (the gap) before stopping? (Answer: No, it must estimate it adaptively).

## Architecture Onboarding

- **Component map:** Feature Projector (B) -> Design Solver -> Rounding Routine -> Gap Calculator -> Eliminator
- **Critical path:** The loop is `Solve Design` → `Round & Pull` → `Estimate Θ` → `Calculate Gaps` → `Accept/Reject`. The most computationally sensitive step is the Design Solver, which runs in O(N|S|e h^2).
- **Design tradeoffs:**
  - Rounding Precision (κ): Lower κ requires a larger budget N for the rounding to succeed (see N ≥ 5h_S/κ^2), potentially slowing down early rounds but tightening confidence bounds.
  - Aggressiveness: The "tie-breaking" rule (favoring empirically optimal arms) is crucial for the proof of Proposition 1; removing this logic could cause failures in edge cases with small gaps.
- **Failure signatures:**
  - High Variance/Slow Convergence: If the feature matrix has a high condition number (nearly collinear features), V^† will have large norms, requiring exponentially more samples to achieve the same error radius ε.
  - Premature Elimination: If noise σ is underestimated, the concentration inequality (Lemma 2) breaks, leading the algorithm to discard Pareto-optimal arms early.
- **First 3 experiments:**
  1. Synthetic Scaling (K vs h): Run GEGE and unstructured PSI (e.g., EGE-SH) on linear instances while increasing K (e.g., 20 to 500) but keeping h fixed. Verify that GEGE's sample complexity remains constant while EGE-SH scales linearly with K. (See Figure 1).
  2. Real-World Data (NoC): Test on the Network-on-Chip dataset (K=259, h=4, d=2) to verify that the linear assumption holds enough to outperform uniform sampling.
  3. Ablation on Noise: Increase noise variance σ^2 to verify that the error probability scales as exp(-T / (σ^2 H_2)), confirming the theoretical bound in Theorem 1.

## Open Questions the Paper Calls Out
None

## Limitations
- The algorithm critically depends on the linear model assumption and the accuracy of the rounding procedure from Allen-Zhu et al. (2017).
- The complexity analysis assumes sufficient budget for rounding, but in practice, very tight budgets could cause degradation.
- The algorithm's performance in high-dimensional feature spaces or with near-collinear features is not extensively tested.
- The algorithm's robustness to model mis-specification (non-linear mean vectors) is not addressed.

## Confidence

- **High confidence**: The theoretical framework and main convergence guarantees (Theorems 1-4) are well-established, following standard bandit analysis techniques. The sample complexity scaling with h rather than K is mathematically sound under the linear assumption.
- **Medium confidence**: The practical implementation of the rounding procedure and its impact on small-budget regimes is less certain. The experiments validate the theory but don't exhaustively explore edge cases.
- **Low confidence**: The algorithm's robustness to model mis-specification (non-linear mean vectors) is not addressed. The paper assumes strict adherence to the linear model without exploring failure modes.

## Next Checks

1. **Rounding efficiency test**: Implement the Allen-Zhu rounding procedure and verify it maintains the (1+6κ) factor bound across varying budgets N and condition numbers of X.
2. **High condition number stress test**: Generate synthetic instances with increasingly ill-conditioned feature matrices and measure how GEGE's sample complexity degrades compared to theoretical predictions.
3. **Model mis-specification experiment**: Run GEGE on instances where the mean vectors deviate slightly from the linear model (e.g., add small non-linear perturbations) and quantify the error probability increase.