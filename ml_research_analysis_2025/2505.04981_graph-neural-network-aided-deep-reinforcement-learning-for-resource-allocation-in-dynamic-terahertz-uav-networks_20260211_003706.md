---
ver: rpa2
title: Graph Neural Network Aided Deep Reinforcement Learning for Resource Allocation
  in Dynamic Terahertz UAV Networks
arxiv_id: '2505.04981'
source_url: https://arxiv.org/abs/2505.04981
tags:
- network
- allocation
- glove
- power
- resource
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of joint power and sub-array resource
  allocation for Terahertz (THz) links in dynamic Unmanned Aerial Vehicle (UAV) networks,
  aiming to maximize resource efficiency (RE) while minimizing latency and packet
  loss. The dynamic topology and mixed-integer nonlinear programming (MINLP) nature
  of the problem make it challenging for traditional optimization methods.
---

# Graph Neural Network Aided Deep Reinforcement Learning for Resource Allocation in Dynamic Terahertz UAV Networks

## Quick Facts
- arXiv ID: 2505.04981
- Source URL: https://arxiv.org/abs/2505.04981
- Authors: Zhifeng Hu; Chong Han
- Reference count: 40
- Primary result: GLOVE achieves highest resource efficiency and lowest latency while maintaining zero packet loss in dynamic THz UAV networks

## Executive Summary
This paper addresses joint power and sub-array resource allocation for Terahertz links in dynamic UAV networks, formulated as a mixed-integer nonlinear programming problem. The proposed GLOVE algorithm combines Graph Neural Networks with Deep Reinforcement Learning, using a dual-path architecture that aggregates neighbor features while emphasizing self-node characteristics. Experimental results show GLOVE achieves 69%+ higher resource efficiency than discrete-action baselines and maintains zero packet loss throughout training, outperforming benchmark methods including MADDPG and GNN-AC.

## Method Summary
GLOVE uses DDPG with a GNN-based actor network that processes UAV states through parallel GCN and FC layers, concatenating their outputs before task-specific heads for power and sub-array allocation. The action space is factorized using Softmax functions to ensure non-negative, bounded allocations. Safe initialization starts with conservative high allocation, and safe exploration adds zero-sum Gaussian noise to prevent constraint violations. The model uses 5.5×10⁴ trainable parameters and trains on-policy with Adam optimizer (lr_actor=2e-5, lr_critic=1e-2) over 1000 steps.

## Key Results
- GLOVE achieves highest resource efficiency and lowest latency among benchmark methods
- Maintains zero packet loss throughout training, unlike benchmarks experiencing 4×10⁵+ lost packets
- Uses 5.5×10⁴ parameters and completes training in 79ms per step
- Outperforms discrete-action baselines by ≥69% in resource efficiency

## Why This Works (Mechanism)

### Mechanism 1: Dual-Path Feature Extraction (GCN + Self-Node Emphasis)
- Claim: Concatenating GNN-aggregated neighbor features with parallel FC-extracted self-node features improves resource efficiency while reducing latency and packet loss compared to GNN-only approaches.
- Mechanism: GCN layers aggregate features from adjacent UAVs via connectivity-aware propagation, while parallel FC layers process each UAV's local state directly. Concatenation preserves both topological context and critical local channel/demand information before task-specific heads.
- Core assumption: Transmission rate for each UAV's link depends predominantly on self-node state (CSI, distance, buffer), which GNN alone may require many iterations to isolate from aggregated features.
- Evidence anchors:
  - [Section IV-B]: "the self-node state is directly related to the resource-efficient allocation decision...GNN might need many iterations to learn the direct influence of the self-node under the aggregated features"
  - [Figure 3a]: Shows parallel GCN and FC paths feeding into concatenation
  - [corpus]: Limited direct corroboration; neighbor papers focus on DRL or GNN separately, not this specific dual-path design
- Break condition: If self-node features are highly correlated with neighbor features (e.g., static topology, uniform traffic), the parallel FC path provides diminishing returns.

### Mechanism 2: Constrained Action Space via Softmax Factorization
- Claim: Structuring actions as products of utilization-ratio Softmax and allocation-ratio Softmax guarantees physical constraints (0 ≤ allocated resources ≤ maximum) without explicit constraint-handling in the DRL optimizer.
- Mechanism: First Softmax outputs utilized vs. unused proportion. Second Softmax distributes utilized portion across sub-bands/links. Product ensures non-negative values summing to ≤1, satisfying constraints by construction.
- Core assumption: The factorization does not significantly restrict the optimal policy space; near-optimal allocations exist within this parameterization.
- Evidence anchors:
  - [Section IV-B]: "Softmax function is used to determine the utilized and unused proportions...the values of allocated resources are nonnegative and cannot exceed the limitations"
  - [Section III-B]: Defines action as ratios with explicit constraints
  - [corpus]: No direct comparison to constrained DRL methods in neighbors
- Break condition: If optimal policy requires sparse allocations (many zeros), Softmax may introduce unnecessary exploration overhead; sparse-max or alternative parameterizations may be needed.

### Mechanism 3: Safe Initialization + Zero-Sum Noise Exploration
- Claim: Initializing actor to allocate most resources, combined with exploration noise constrained to sum to zero per resource type, prevents constraint violations (severe latency/packet loss) throughout training.
- Mechanism: Safe initialization sets actor parameters to conservative high-allocation policy. Safe exploration adds Gaussian noise but forces sum-to-zero constraint per UAV per resource type, and discards noise causing negative allocations. This maintains constraint satisfaction while exploring.
- Core assumption: Conservative initialization provides feasible baseline; constraint violations primarily arise from under-allocation rather than over-allocation (latency/packet loss are the risks, not power waste).
- Evidence anchors:
  - [Section IV-C]: "parameters of the actor network are configured to use most of the available resources initially...noises for each type of resource in a UAV are forced to sum to zero"
  - [Figure 8-9]: GLOVE maintains ≤15ms latency and zero packet loss; benchmarks show 46ms+ latency and 4×10⁵+ lost packets
  - [corpus]: Neighbor papers mention DRL for resource allocation but do not detail comparable safe exploration mechanisms
- Break condition: If over-allocation causes other issues (interference, energy waste), this safety mechanism may need rebalancing; not tested in interference-limited scenarios per paper model.

## Foundational Learning

- **Deep Deterministic Policy Gradient (DDPG)**
  - Why needed here: The action space includes continuous power ratios and discrete sub-array counts. DDPG handles continuous actions with deterministic policy gradients; discrete approximation (GLOVE-AC baseline) shows 69%+ higher resource usage.
  - Quick check question: Can you explain why DDPG uses a target network and replay buffer, and why GLOVE uses on-policy training instead of replay?

- **Graph Convolutional Networks (GCN)**
  - Why needed here: Network topology is highly dynamic; GCN layers enable parameter-sharing across nodes regardless of graph size, critical for scalability (5.5×10⁴ params vs. 9.7× for MADDPG).
  - Quick check question: How does a GCN layer differ from a standard FC layer in terms of parameter sharing and computational complexity as the graph grows?

- **Multi-Task Learning with Shared/Task-Specific Heads**
  - Why needed here: Power and sub-array allocation are coupled but have different output structures. Shared layers capture common state representations; task-specific heads enable cooperative gradient signals.
  - Quick check question: What is the risk of negative transfer in multi-task learning, and how would you detect it during training?

## Architecture Onboarding

- **Component map**: Input state → [GCN layers (topology aggregation) || FC layers (self-node features)] → Concatenate → [Shared layers → Task-specific heads] → Softmax factorization → Actions (P, S)
- **Critical path**:
  1. State construction (per-UAV: expected packets, buffer occupancy, SINR, distance, location, header flag)
  2. Adjacency matrix update (current routing topology)
  3. Forward pass through actor (GCN+FC parallel → concatenation → heads)
  4. Action scaling via Softmax factorization
  5. Reward computation (Eq. 17: `-χ₁·resource_usage/N + χ₂·latency + χ₃·packet_loss`)
  6. Critic Q-estimate and TD error
  7. Gradient updates (actor: ascent on Q; critic: descent on TD loss)
- **Design tradeoffs**:
  - On-policy vs. off-policy: On-policy chosen for adaptability to rapid topology changes; sacrifices sample efficiency.
  - GCN-only vs. GCN+FC: FC path adds ~13ms latency and 2.6% more parameters but significantly improves RE and eliminates packet loss.
  - Discrete vs. continuous actions: DDPG (continuous) outperforms AC (discrete) by ≥69% in resource efficiency.
- **Failure signatures**:
  - Divergent Q-values: Check learning rates (critic 10⁻², actor 2×10⁻⁵); may need adjustment.
  - Packet loss spikes: Verify safe initialization preserved; noise variance (5%) may be too high.
  - High latency without convergence: Self-node features may be under-weighted; check FC layer dimensions vs. GCN output.
- **First 3 experiments**:
  1. **Baseline sanity check**: Run GLOVE with χ₂=χ₃=0 (no latency/packet loss penalties). Expect higher RE but constraint violations; validates reward shaping role.
  2. **Ablation on self-node emphasis**: Disable FC parallel path (GNN-only). Expect RE degradation and packet loss increase per Figure 5-9 comparisons.
  3. **Topology stress test**: Increase UAV mobility (max speed >100 m/s) or network size (N>25). Monitor whether parameter count remains constant and whether latency/packet loss stay bounded.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GLOVE's performance scale in networks with significantly more UAVs (e.g., N > 100) or denser topologies?
- Basis in paper: [inferred] Simulations use N = 25 UAVs; the paper claims GLOVE has "high scalability" due to GCN's parameter invariance to graph size, but this is not empirically validated beyond 25 nodes.
- Why unresolved: No experiments test larger network sizes; computational complexity analysis is theoretical (O((Ė+N)FF')) without empirical validation.
- What evidence would resolve it: Performance metrics (RE, latency, packet loss, training time) evaluated on networks with 50, 100, or 200 UAVs.

### Open Question 2
- Question: Can GLOVE be extended to jointly optimize UAV trajectories alongside power and sub-array allocation?
- Basis in paper: [inferred] The paper states "UAVs follow a random motion pattern" and "unpredictable movements" without trajectory control; joint trajectory-resource optimization is a natural extension.
- Why unresolved: The problem formulation treats UAV positions as given environmental states rather than controllable decision variables.
- What evidence would resolve it: Modified GLOVE with trajectory action space achieving higher RE than the current position-agnostic approach.

### Open Question 3
- Question: How robust is GLOVE to imperfect channel state information and real-world THz channel estimation errors?
- Basis in paper: [inferred] The paper assumes "channel state information can be obtained" via estimation techniques, but simulations appear to use perfect SINR knowledge without modeling estimation noise or latency.
- Why unresolved: Real THz channels have challenging estimation due to high path loss and narrow beams; estimation errors could degrade allocation decisions.
- What evidence would resolve it: Sensitivity analysis with varying levels of CSI estimation error added to the channel model.

## Limitations

- Exact GCN and FC layer configurations (dimensions, counts) are not fully specified, though the dual-path architecture is clearly defined.
- Beam misalignment and absorption coefficient models rely on external references without implementation details provided.
- Safe exploration noise mechanics beyond "zero-sum Gaussian" are underspecified, though the concept is validated experimentally.
- Results show GLOVE achieves zero packet loss while benchmarks experience significant loss, but the analysis does not explore whether this comes from conservative resource allocation that might reduce throughput in interference-limited scenarios.

## Confidence

- **High Confidence**: Dual-path GCN+FC architecture improves RE and eliminates packet loss compared to GNN-only; Softmax factorization guarantees constraint satisfaction; safe initialization prevents constraint violations during training.
- **Medium Confidence**: GLOVE outperforms benchmarks in RE and latency; computational efficiency claims (5.5×10⁴ parameters, 79ms per step) are well-supported.
- **Low Confidence**: No comparative analysis of GLOVE's robustness to interference or energy waste; limited ablation on individual architectural components beyond the FC path.

## Next Checks

1. **Interference sensitivity test**: Run GLOVE in scenarios with multiple concurrent links to measure throughput degradation and compare against benchmarks.
2. **Parameter sensitivity analysis**: Vary χ₂ and χ₃ to quantify the tradeoff between RE and latency/packet loss, confirming whether zero packet loss comes at the cost of resource efficiency.
3. **Topology scalability stress test**: Increase UAV count beyond 25 and network size beyond 1000×1000m to verify parameter count remains constant and latency/packet loss bounds hold.