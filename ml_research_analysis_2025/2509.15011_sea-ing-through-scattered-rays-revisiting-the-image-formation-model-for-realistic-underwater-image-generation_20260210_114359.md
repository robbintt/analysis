---
ver: rpa2
title: 'Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic
  Underwater Image Generation'
arxiv_id: '2509.15011'
source_url: https://arxiv.org/abs/2509.15011
tags:
- underwater
- images
- image
- data
- water
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating realistic synthetic
  underwater images, particularly in turbid conditions where light scattering significantly
  degrades visibility. The authors improve upon the standard underwater image formation
  model (IFM) by reintroducing the forward scattering term, which is commonly omitted
  in prior work.
---

# Sea-ing Through Scattered Rays: Revisiting the Image Formation Model for Realistic Underwater Image Generation

## Quick Facts
- arXiv ID: 2509.15011
- Source URL: https://arxiv.org/abs/2509.15011
- Reference count: 40
- This paper improves underwater image synthesis by reintroducing forward scattering and stochastic medium inhomogeneity, achieving 82.5% preference in human surveys for coastal water types

## Executive Summary
This paper addresses the challenge of generating realistic synthetic underwater images, particularly in turbid conditions where light scattering significantly degrades visibility. The authors improve upon the standard underwater image formation model (IFM) by reintroducing the forward scattering term, which is commonly omitted in prior work. They also introduce stochastic medium inhomogeneity using Gaussian random fields applied to depth maps to better simulate real-world turbidity variations. A new dataset called BUCKET is introduced, containing images captured under controlled turbidity conditions with corresponding reference images. Qualitative results demonstrate improved realism in high-turbidity scenarios, and a survey of 20 participants showed their model was preferred over the reference model in 82.5% of cases for coastal water types.

## Method Summary
The authors improve underwater image formation modeling by reintroducing forward scattering and stochastic medium inhomogeneity. Their model decomposes underwater images into direct transmission, forward scattering, and backscatter components. The key innovation is the inclusion of forward scattering through convolution with depth-variable Gaussian kernels, and the application of Gaussian Random Fields to depth maps to simulate medium inhomogeneity. The method uses Jerlov water type coefficients and specific empirical parameters (g=0.2, μ=0.3, φ=0.3·mean(b)) to control scattering and attenuation effects. The approach is evaluated on both the BUCKET dataset and EUVP images using qualitative comparisons and a Mean Opinion Ranking survey.

## Key Results
- Reintroducing forward scattering term significantly improves realism in turbid underwater image synthesis
- Stochastic medium inhomogeneity via Gaussian Random Fields creates more natural turbidity variations
- 82.5% preference rate in human survey for coastal water types compared to baseline model
- Visual artifacts reduced and smoother transitions achieved in high-turbidity conditions

## Why This Works (Mechanism)
The improved realism stems from accurately modeling the physical scattering processes that dominate in turbid water. Forward scattering, which was previously omitted, accounts for light rays that deviate from their path but still reach the camera, creating the characteristic blur in underwater images. The stochastic depth modification captures the natural variations in water clarity that occur due to turbulence and suspended particles. By combining these effects with proper spectral integration and depth-dependent attenuation, the model reproduces the complex interplay of light propagation in real underwater environments.

## Foundational Learning
- **Underwater Image Formation Model (IFM)**: Mathematical framework decomposing underwater images into direct transmission, forward scattering, and backscatter; needed to simulate how light propagates through water and creates observed images
- **Jerlov Water Types**: Classification system for oceanic water clarity based on spectral attenuation coefficients; needed to parameterize scattering and absorption properties for different water conditions
- **Gaussian Random Fields (GRFs)**: Stochastic process for generating spatially correlated random variations; needed to model natural inhomogeneities in water turbidity
- **Depth-dependent blur**: Spatially varying point spread function based on scene depth; needed to simulate how scattering increases with distance underwater
- **Spectral integration**: Wavelength-dependent computation of optical effects; needed to accurately model how different colors of light attenuate differently in water

## Architecture Onboarding
**Component Map:** Clear image + Depth map → Depth scaling → IFM components (Direct, Forward, Backscatter) → Spectral integration → Output image

**Critical Path:** Depth map → GRF application → Forward scattering convolution → Final image synthesis

**Design Tradeoffs:** Physical accuracy vs. computational efficiency (GRF adds realism but increases complexity); parameter universality vs. scene-specific tuning (fixed empirical constants may not generalize)

**Failure Signatures:** Overexposed backscatter dominates before blur appears; unnatural depth-dependent degradation patterns; color shifts inconsistent with water type

**First Experiments:**
1. Test basic IFM components separately on clear water images to verify correct attenuation and scattering effects
2. Apply GRF to depth maps and visualize the resulting medium inhomogeneity patterns
3. Compare forward scattering contribution magnitude against direct transmission across different water types

## Open Questions the Paper Calls Out
**Open Question 1:** Does training computer vision models on synthetic data generated with the reintroduced forward scattering term and stochastic inhomogeneity improve performance on real-world underwater downstream tasks (e.g., restoration, object detection)?

**Open Question 2:** How does the gamma scaling of monocular depth maps specifically influence the accuracy of the attenuation and blur synthesis compared to metrically accurate depth?

**Open Question 3:** Can the application of Gaussian Random Fields (GRFs) for medium inhomogeneity be derived as a physical solution to radiative transfer in turbulent water, rather than serving solely as a heuristic degradation technique?

**Open Question 4:** To what extent does the model's realism depend on the specific empirical constants (g=0.2, μ=0.3) chosen, and are these values valid across the full range of Jerlov water types?

## Limitations
- Spectral integration details and camera spectral response coupling not fully specified
- GRF generation parameters beyond basic scaling range are underspecified
- Depth scaling from monocular estimates to metric units relies on scene-specific calibration
- Empirical constants may not generalize across all water types without manual retuning

## Confidence
- High confidence: Core IFM reformulation and mathematical formulation
- Medium confidence: GRF-based medium inhomogeneity implementation
- Medium confidence: Overall visual quality improvements in high-turbidity scenarios

## Next Checks
1. Validate spectral integration implementation by testing with different wavelength sampling densities and comparing against known water types
2. Conduct ablation studies isolating forward scattering, depth inhomogeneity, and blur effects to quantify their individual contributions
3. Test depth scaling robustness across diverse scenes with varying depth ranges and structures beyond the BUCKET dataset