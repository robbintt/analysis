---
ver: rpa2
title: Source-free domain adaptation based on label reliability for cross-domain bearing
  fault diagnosis
arxiv_id: '2503.08749'
source_url: https://arxiv.org/abs/2503.08749
tags:
- domain
- adaptation
- samples
- target
- fault
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel source-free domain adaptation method
  for cross-domain bearing fault diagnosis that addresses key challenges in pseudo-label
  reliability and negative transfer. The proposed SDALR method employs a data-augmentation-based
  label voting strategy to distinguish reliable from unreliable pseudo-labels, then
  applies different optimization strategies to each category: cohesion and repulsion
  loss for reliable samples and entropy maximization for unreliable samples.'
---

# Source-free domain adaptation based on label reliability for cross-domain bearing fault diagnosis

## Quick Facts
- **arXiv ID**: 2503.08749
- **Source URL**: https://arxiv.org/abs/2503.08749
- **Reference count**: 40
- **Primary result**: Proposed SDALR method achieves 96.78% average accuracy on PU dataset and 98.50% on JNU dataset, outperforming previous best SFDA methods by 5.98% and 1.09% respectively

## Executive Summary
This paper addresses the challenge of source-free domain adaptation (SFDA) for cross-domain bearing fault diagnosis, where source data is inaccessible during target adaptation. The proposed SDALR method introduces a novel data-augmentation-based label voting strategy to distinguish reliable from unreliable pseudo-labels, then applies different optimization strategies to each category. For reliable samples, the method employs cohesion and repulsion loss to structure the feature space, while maximizing entropy for unreliable samples to prevent negative transfer. The approach demonstrates superior performance compared to existing SFDA methods, achieving state-of-the-art results on two benchmark bearing fault diagnosis datasets.

## Method Summary
The method employs a ResNet-18 backbone modified for 1D vibration signals, trained on labeled source data using cross-entropy loss. For target adaptation, the model initializes with source weights and uses pseudo-label voting (via flipping, random zeroing, and cyclic shifting) to partition target samples into reliable and unreliable categories. Reliable samples are optimized with label-smoothing cross-entropy, information maximization, and cohesion-repulsion loss, while unreliable samples receive entropy maximization. The target model is fine-tuned using SGD with learning rate 5e-4 for 20 epochs.

## Key Results
- Achieves 96.78% average accuracy on PU dataset (8-class bearing fault diagnosis)
- Achieves 98.50% average accuracy on JNU dataset (4-class bearing fault diagnosis)
- Outperforms previous best SFDA methods by 5.98% on PU and 1.09% on JNU
- Demonstrates effectiveness of utilizing both reliable and unreliable pseudo-labels while maintaining feature discriminability and diversity

## Why This Works (Mechanism)

### Mechanism 1: Data-Augmentation-Based Pseudo-Label Voting
Majority voting across multiple augmented views produces more reliable pseudo-label assessments than single-prediction confidence metrics. Each target sample undergoes three augmentations (flipping, random zeroing, cyclic shifting), and if a single class receives >50% of votes, the sample is marked "reliable" with that pseudo-label; otherwise, it is marked unreliable (-1). This leverages prediction consistency under perturbation as a reliability signal, assuming correctly classified samples yield consistent predictions across semantically equivalent augmentations.

### Mechanism 2: Cohesion and Repulsion Loss (L_car) for Reliable Samples
Explicitly structures the feature space by pulling same-class reliable samples together while pushing different-class samples apart. For each reliable sample, the method constructs similar sets (same pseudo-label in mini-batch) and background sets (different pseudo-labels), maximizing dot products within similar sets and minimizing them with background sets, weighted by β=0.6. This operates on feature dot products, not output probabilities, assuming reliable pseudo-labels sufficiently approximate ground truth to guide feature-space geometry.

### Mechanism 3: Entropy Maximization for Unreliable Samples
Maximizes prediction entropy for unreliable samples to reduce negative transfer by preventing the model from becoming overconfident in incorrect predictions. For samples marked -1, the method computes and maximizes entropy loss, pushing predictions toward uniform distributions and reducing gradient signals that would bias the feature extractor toward potentially erroneous class boundaries. This assumes unreliable samples contain noisy or ambiguous information where forcing uncertainty is safer than committing to wrong labels.

## Foundational Learning

- **Concept: Source-Free Domain Adaptation (SFDA)**
  - **Why needed here:** The entire method operates under the constraint that source data is inaccessible during adaptation. Understanding this paradigm shift—from joint source-target optimization to target-only adaptation—is essential for grasping why pseudo-labels become the primary supervision signal.
  - **Quick check question:** Why can't SFDA use MMD or adversarial alignment between source and target domains?

- **Concept: Pseudo-Labeling and Confirmation Bias**
  - **Why needed here:** The paper's core contribution is improving pseudo-label reliability. Without understanding that erroneous pseudo-labels can reinforce themselves through self-training (confirmation bias), the motivation for the voting strategy is unclear.
  - **Quick check question:** What happens if a model is trained on its own confident but incorrect predictions?

- **Concept: Negative Transfer**
  - **Why needed here:** The paper explicitly claims to reduce negative transfer via entropy maximization. This concept explains why adapting with wrong information can be worse than no adaptation at all.
  - **Quick check question:** Give an example where domain adaptation hurts target performance compared to a source-only model.

## Architecture Onboarding

- **Component map:** Source model M_s -> Target model M_t -> Pseudo-label voting module -> Loss modules (L_lsc + L_uem + L_im + L_car) -> Optimized M_t
- **Critical path:**
  1. Pre-train source model on D_s with L_CE (Eq. 1)
  2. Initialize M_t ← M_s
  3. For each adaptation iteration: Generate/update pseudo-labels via voting (Eqs. 3-7), partition batch into reliable/unreliable, compute respective losses, backpropagate L_tar, update M_t
  4. Evaluate on target test set

- **Design tradeoffs:**
  - **Threshold ∂ (similarity cutoff for initial pseudo-labels):** Higher values → fewer reliable samples, cleaner supervision but potentially insufficient coverage. Paper finds ∂ ≈ 0.6-0.7 works best (Figure 10)
  - **Weight β (repulsion strength in L_car):** Higher β emphasizes inter-class separation. Paper fixes β = 0.6 to balance similar/dissimilar sample weight imbalance
  - **Voting frequency:** Pseudo-labels are not updated every iteration (computationally expensive); update schedule affects stability

- **Failure signatures:**
  - **Accuracy collapse early in training:** Likely threshold ∂ too high, marking most samples unreliable; entropy maximization dominates, no learning signal
  - **Class imbalance in pseudo-labels:** Voting may favor majority classes; paper applies class-balanced augmentation to mitigate
  - **Feature space fragmentation:** Visible in t-SNE as many small clusters within a class; suggests L_car repulsion too strong or pseudo-label noise high

- **First 3 experiments:**
  1. **Reproduce ablation (Table 6/7):** Start with L_lsc + L_im only (SHOT baseline), then incrementally add L_car, voting, and L_uem. Confirm each component contributes to accuracy gains on PU dataset task A1→A2
  2. **Hyperparameter sensitivity:** Sweep ∂ ∈ [0.5, 0.95] and β ∈ [0.1, 1.0] on a single task. Verify optimal ranges match paper claims (∂ ≈ 0.6, β ≈ 0.5-0.7)
  3. **Visualize pseudo-label reliability:** Track the ratio of reliable vs. unreliable samples per epoch. Plot how this ratio evolves and correlates with accuracy. Assumption: Reliable-sample ratio should stabilize as model adapts

## Open Questions the Paper Calls Out
- **Question:** How can the method's resilience be improved when the initial source model has poor generalization capabilities?
  - **Basis in paper:** [explicit] The conclusion states the method's success "heavily depends on the quality of the source model" and suggests future work should "enhance source model generalization."
  - **Why unresolved:** The current framework initializes the target model directly from the source weights but lacks mechanisms to compensate for a poorly pre-trained source model.
  - **What evidence would resolve it:** Experiments evaluating SDALR performance when initialized with source models of varying (low) accuracy, or the introduction of a robustness module.

- **Question:** How does the proposed label-voting strategy function in dynamic adaptation scenarios with continuously drifting distributions?
  - **Basis in paper:** [explicit] The authors explicitly list extending the approach to "dynamic adaptation scenarios" as a direction for future work.
  - **Why unresolved:** The current experimental setup utilizes static transfer tasks (e.g., A1→A2) rather than continuous, online data streams where fault types may evolve.
  - **What evidence would resolve it:** Implementation of the method in an online learning setting using run-to-failure datasets to observe if the voting mechanism adapts to gradual degradation.

- **Question:** Is the fixed set of data augmentations (flipping, zeroing, shifting) universally optimal for distinguishing reliable labels across different vibration signal frequencies?
  - **Basis in paper:** [inferred] The label voting strategy (Eq. 2) relies heavily on specific data augmentations; however, the paper does not justify why these specific transforms preserve fault semantics for all signal types.
  - **Why unresolved:** While the method works on two benchmarks, it is unclear if these augmentations might corrupt spectral features in signals with different sampling rates or noise profiles.
  - **What evidence would resolve it:** An ablation study testing alternative signal transformations (e.g., time-warping or frequency masking) to see if pseudo-label reliability improves on diverse datasets.

## Limitations
- **Major Uncertainties:** The voting strategy's effectiveness relies heavily on augmentation quality and threshold selection, with no validation that consistent predictions across augmentations indicate reliable pseudo-labels when augmentations introduce domain-irrelevant variations.
- **Core Assumptions:** The cohesion-repulsion loss assumes reliable pseudo-labels sufficiently approximate ground truth, but if initial filtering is too permissive, L_car could reinforce incorrect feature separations and degrade the embedding space.
- **Statistical Evidence:** Performance gains (5.98% and 1.09% over previous SFDA methods) are reported without statistical significance tests or confidence intervals across multiple random seeds, limiting claims about robustness.

## Confidence
- **High Confidence:** The core SFDA methodology and general superiority over existing methods are well-supported by results and ablation studies
- **Medium Confidence:** The specific mechanisms (voting reliability, cohesion-repulsion loss, entropy maximization) are logically sound but lack extensive ablation to isolate their individual contributions beyond reported experiments
- **Low Confidence:** Claims about method's robustness to varying data sizes and extreme domain shifts are not thoroughly validated; only specific dataset pairs and class ratios are tested

## Next Checks
1. **Statistical Significance:** Run each task 5 times with different random seeds and report mean accuracy with 95% confidence intervals. Confirm that performance gains over SHOT and other baselines are statistically significant.
2. **Ablation Stress Test:** Systematically vary the pseudo-label similarity threshold (∂) from 0.5 to 0.95 and report accuracy curves. Identify the range where performance degrades to understand the robustness of the voting mechanism.
3. **Visual Feature Analysis:** Generate t-SNE plots of target features at different training epochs (e.g., 0, 5, 10, 20) for a sample task. Verify that reliable samples form coherent clusters and that unreliable samples are more scattered, supporting the intuition behind L_car and L_uem.