---
ver: rpa2
title: Learning with Preserving for Continual Multitask Learning
arxiv_id: '2511.11676'
source_url: https://arxiv.org/abs/2511.11676
tags:
- tasks
- learning
- task
- data
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Learning with Preserving (LwP), a novel framework
  for Continual Multitask Learning (CMTL) where models must sequentially learn new
  tasks on a shared input distribution without forgetting previous tasks. The key
  challenge in CMTL is that conventional continual learning methods fail because they
  learn fragmented, task-specific features that interfere with one another.
---

# Learning with Preserving for Continual Multitask Learning

## Quick Facts
- arXiv ID: 2511.11676
- Source URL: https://arxiv.org/abs/2511.11676
- Authors: Hanchen David Wang; Siwoo Bae; Zirong Chen; Meiyi Ma
- Reference count: 40
- Primary result: Introduces LwP, a continual multitask learning framework that outperforms state-of-the-art methods by preserving geometric structure through distance preservation loss.

## Executive Summary
This paper introduces Learning with Preserving (LwP), a novel framework for Continual Multitask Learning (CMTL) where models must sequentially learn new tasks on a shared input distribution without forgetting previous tasks. The key challenge in CMTL is that conventional continual learning methods fail because they learn fragmented, task-specific features that interfere with one another. LwP addresses this by preserving the geometric structure of the shared representation space through a Dynamically Weighted Distance Preservation (DWDP) loss. This loss regularizes pairwise distances between latent data representations to prevent representation drift, allowing the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer. Extensive evaluations on image and time-series benchmarks show that LwP consistently outperforms state-of-the-art baselines and is the only approach to surpass the single-task learning baseline.

## Method Summary
LwP is a continual multitask learning framework that preserves geometric structure in shared representations to prevent catastrophic forgetting. The method uses a Dynamically Weighted Distance Preservation (DWDP) loss that regularizes pairwise distances between latent data representations, combined with distillation from a frozen teacher model to preserve explicit knowledge. A dynamic masking mechanism prevents conflicts between preservation and discrimination objectives. The framework consists of a shared feature extractor and task-specific heads, with a frozen copy of the previous model serving as a teacher for distillation. Training proceeds sequentially through tasks, with only current task parameters updated while the frozen teacher generates pseudolabels for old tasks.

## Key Results
- LwP consistently outperforms state-of-the-art baselines on image and time-series benchmarks
- LwP is the only approach to surpass the single-task learning baseline
- LwP demonstrates superior robustness to distribution shifts, making it effective for real-world dynamic environments
- The method achieves this without requiring a replay buffer, enhancing privacy and efficiency

## Why This Works (Mechanism)

### Mechanism 1
Preserving pairwise distances in the latent space maintains functional equivalence for all tasks sharing the representation, preventing catastrophic forgetting. The DWDP loss minimizes the difference between squared Euclidean distances in the current and frozen representations. This implicitly preserves the Gram matrix of a Gaussian kernel, ensuring an isometry exists in the RKHS that maps old representations to new ones—meaning any learnable function on the old space has an equivalent solution on the new space.

### Mechanism 2
Dynamic masking of inter-class pairs prevents the preservation loss from conflicting with discriminative objectives. The mask m_ij = 1 only when y_i = y_j (same class) deactivates preservation for cross-class pairs. This allows the model to separate distinct classes via L_cur while still preserving intra-class geometric structure via L_DWDP.

### Mechanism 3
Distillation via frozen teacher pseudolabels preserves explicit task knowledge while the DWDP loss handles implicit geometric knowledge. The previous model (frozen) generates soft labels ỹ for old tasks. The current model matches these outputs via L_old, preserving input-output mappings while the shared backbone adapts.

## Foundational Learning

- **Concept: Catastrophic Forgetting in Sequential Learning**
  - Why needed here: The entire LwP framework is designed to mitigate this phenomenon where neural networks overwrite previously learned knowledge when training on new tasks.
  - Quick check question: Can you explain why standard SGD causes forgetting when task distributions differ, and why simply freezing parameters is insufficient for CMTL?

- **Concept: Kernel Methods and Reproducing Kernel Hilbert Spaces (RKHS)**
  - Why needed here: The theoretical justification for DWDP relies on the connection between distance preservation and kernel matrix preservation, establishing functional equivalence in RKHS.
  - Quick check question: If K(Z) ≈ K(Z') for a Gaussian kernel, what does this imply about the relationship between functions learned on Z versus Z'?

- **Concept: Knowledge Distillation**
  - Why needed here: L_old uses soft targets from a teacher model; understanding temperature scaling and why soft labels preserve more information than hard labels is essential.
  - Quick check question: Why might matching soft teacher outputs (distillation) preserve more transferable knowledge than matching hard labels?

## Architecture Onboarding

- **Component map**:
  f_θs(x) -> Shared feature extractor (ResNet for images, 1D-CNN for time-series)
  g_θt(z) -> Task-specific linear heads (one per task)
  f_θs[t-1] -> Frozen copy of extractor from previous task (teacher)
  Loss combiner: L_lwp = λ_c * L_cur + λ_o * L_old + λ_d * L_DWDP

- **Critical path**:
  1. At task t, duplicate model from t-1
  2. Add randomly initialized head g_θt
  3. Freeze all parameters from t-1 (teacher)
  4. For each batch: compute z[t], z[t-1], current predictions, pseudolabels for old tasks
  5. Compute L_cur (current task), L_old (distillation), L_DWDP (intra-class distance preservation)
  6. Backprop only through current model parameters

- **Design tradeoffs**:
  - λ_d (DWDP weight): Higher values prioritize stability over plasticity. Paper uses 0.01–1.0; ablation shows robustness across range.
  - λ_o (distillation weight): Balances explicit vs. implicit preservation. Default = 1.
  - Distance metric: Squared Euclidean outperforms cosine/RBF (Table 4); preserves global structure better.
  - No replay buffer: Privacy-friendly but relies on pseudolabel quality under distribution shift.

- **Failure signatures**:
  - Sudden accuracy drop on old tasks with high λ_d: Over-constraint preventing necessary adaptation
  - Progressive degradation across tasks: Check if L_old is receiving valid pseudolabels (teacher may be poorly calibrated)
  - Inter-class confusion on new task: Dynamic mask may be too restrictive; verify mask computation matches same-class pairs only
  - Memory growth: Task heads accumulate; consider head pruning if task count becomes large

- **First 3 experiments**:
  1. **Sanity check on toy data**: Replicate the concentric circles → XOR example (Figure 5). Train on task 1 (circles), verify L_DWDP preserves the representation structure needed for task 2 (XOR). Without L_DWDP, XOR should fail.
  2. **Ablation on single dataset**: Run LwP on CelebA with: (a) full model, (b) w/o L_DWDP, (c) w/o L_old, (d) w/o dynamic weighting. Compare against Table 4 patterns to validate implementation.
  3. **Distribution shift robustness test**: Use BDD100K weather-shift protocol. Compare LwP vs. LwF vs. ER under sequential weather conditions. Expect LwP to maintain smaller accuracy drops as reported in Table 2 (77.94% vs. 76.79% for LwF under weather shift).

## Open Questions the Paper Calls Out

### Open Question 1
Can the DWDP loss be extended to preserve inter-class geometric relationships without conflicting with class-separation objectives? The authors acknowledge that the dynamic mask deactivates preservation for pairs with different labels, "alleviating the objective conflict issue at the cost of reducing the scope for preservation to intraclass sets of the current task." This limits the method to preserving only intra-class structure.

### Open Question 2
What are the computational and memory overheads of the DWDP loss when scaling to very large batch sizes or high-dimensional representations? The loss requires calculating dense pairwise distances (O(N²) complexity), which may limit applicability in resource-constrained systems compared to replay buffers.

### Open Question 3
Is preserving Euclidean pairwise distances effective for architectures with non-Euclidean inductive biases, such as Vision Transformers? The theoretical justification relies on RKHS and Euclidean metrics, and all experiments use CNN-based architectures, leaving the method's effectiveness on transformer architectures unexplored.

## Limitations

- The theoretical foundation linking distance preservation to functional equivalence in RKHS assumes the Gaussian kernel structure remains stable, but this may not hold under severe distribution shifts.
- Architectural choices (ResNet variant, 1D-CNN specifics, augmentation strategy) significantly impact performance but are underspecified in the paper.
- The computational complexity of pairwise distance calculations (O(N²)) may limit scalability to large batch sizes or high-dimensional representations.

## Confidence

- **High**: LwP outperforms baselines on average accuracy; dynamic masking effectively prevents conflict with discriminative objectives; DWDP loss successfully prevents representation drift
- **Medium**: Robustness to distribution shifts is superior but not absolute; the method is privacy-friendly (no replay buffer) but this hasn't been independently verified
- **Low**: Theoretical claims about RKHS isometry guaranteeing functional equivalence; the claim of being "the only approach to surpass the single-task learning baseline" needs verification across more diverse benchmarks

## Next Checks

1. **Distribution Shift Sensitivity Analysis**: Systematically vary the magnitude of input distribution shifts (e.g., from minor lighting changes to complete scene type changes) on BDD100K and measure LwP's accuracy decay curve compared to ER and LwF. This will quantify the claimed robustness and identify failure thresholds.

2. **Teacher Pseudolabel Quality Assessment**: On a dataset with known label corruption or domain shift, measure the calibration and accuracy of frozen teacher pseudolabels when evaluated on new task data. This will validate whether L_old is providing beneficial supervision or introducing noise.

3. **RKHS Functional Equivalence Verification**: On a synthetic dataset where the shared representation has known geometric properties (e.g., concentric circles for task 1, XOR pattern for task 2), train LwP and verify that the preserved distance structure enables successful transfer to the second task, while ablating L_DWDP causes failure. This will provide empirical validation of the theoretical mechanism.