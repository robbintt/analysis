---
ver: rpa2
title: 'MMGRec: Multimodal Generative Recommendation with Transformer Model'
arxiv_id: '2404.16555'
source_url: https://arxiv.org/abs/2404.16555
tags:
- recommendation
- item
- multimodal
- rec-id
- mmgrec
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MMGRec, a novel Transformer-based model for
  multimodal recommendation that addresses the limitations of traditional embedding-and-retrieval
  paradigms. The key innovation is introducing a generative recommendation framework
  where items are identified by semantic Rec-IDs - sequences of tokens representing
  both semantic content and popularity information.
---

# MMGRec: Multimodal Generative Recommendation with Transformer Model

## Quick Facts
- **arXiv ID:** 2404.16555
- **Source URL:** https://arxiv.org/abs/2404.16555
- **Reference count:** 40
- **Primary result:** MMGRec achieves 7.17%, 6.79%, and 6.58% NDCG@10 improvements over LightGT baseline on MovieLens, TikTok, and Kwai datasets respectively

## Executive Summary
This paper introduces MMGRec, a novel Transformer-based model for multimodal recommendation that addresses limitations of traditional embedding-and-retrieval paradigms. The key innovation is introducing a generative recommendation framework where items are identified by semantic Rec-IDs - sequences of tokens representing both semantic content and popularity information. The model consists of two components: Graph RQ-VAE, which fuses multimodal and collaborative filtering signals into quantized semantic tokens, and a relation-aware Transformer that generates preferred items' Rec-IDs based on interaction history. Extensive experiments on three datasets demonstrate state-of-the-art performance with promising inference efficiency advantages as item scales increase.

## Method Summary
MMGRec operates through a two-stage pipeline: first, a Graph RQ-VAE component fuses multimodal features (visual, acoustic, textual) with collaborative filtering signals using a bipartite graph convolutional network, then quantizes the fused representations into hierarchical tokens (Rec-IDs) using residual quantization. The second component is a relation-aware Transformer that, given a user's interaction history, autoregressively generates Rec-IDs to identify recommended items. The Rec-ID design incorporates a popularity token to resolve collisions, and the Transformer uses user-specific relation modeling instead of positional encoding to handle non-sequential interaction histories. The model is trained with alternating optimization between BPR loss and reconstruction loss.

## Key Results
- Achieves 7.17%, 6.79%, and 6.58% improvements in NDCG@10 compared to LightGT baseline on MovieLens, TikTok, and Kwai datasets
- Outperforms traditional methods in inference efficiency as item catalog scales increase
- Relation-aware self-attention significantly outperforms standard positional encoding for non-sequential interaction history
- Popularity-based collision resolution outperforms random token assignment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Fusing collaborative filtering (CF) signals with multimodal features into hierarchical tokens creates "semantic" IDs that are easier for a Transformer to generate than random IDs.
- **Mechanism:** The Graph RQ-VAE component uses a GCN to aggregate user-item interaction signals (CF) alongside visual/acoustic/textual features. It then quantizes this fused representation into a tuple of codewords (tokens). Crucially, it resolves ID collisions by appending a popularity token (ranking index) rather than a random token. The paper posits that Transformers struggle to learn the statistical distribution of random noise tokens, whereas popularity is semantically correlated with item features.
- **Core assumption:** Item popularity is sufficiently correlated with its multimodal semantic features such that the popularity token becomes predictable by the model.
- **Evidence anchors:** Section 4.2.2 explains Rec-ID design with popularity token; Table 4 shows "Random" underperforms "Ours" (Popularity); neighbor papers suggest broader trend in fusing signals.
- **Break condition:** If item popularity distribution shifts drastically and independently of semantic content, the popularity token prediction may fail.

### Mechanism 2
- **Claim:** Standard positional encoding fails for user interaction history because it is often non-sequential or lacks explicit timestamps; user-specific relation modeling fixes this.
- **Mechanism:** The architecture replaces absolute positional encoding with Relation-Aware Self-Attention. Instead of adding a position vector, it modifies attention score calculation by adding a user-specific term derived from user-specific projection matrices (W^u_Q, W^u_K). These matrices are generated dynamically from the user's learned representation (h_u), allowing the model to weigh items based on their pairwise relationship relative to that specific user.
- **Core assumption:** A user's latent representation contains enough information to parameterize the "relative importance" between items in their history without needing explicit time-ordering.
- **Evidence anchors:** Section 4.3.2 describes relation-aware attention; Table 5 shows "w/o PE" performs poorly, "Default PE" is better, but "Ours" (Relation-Aware) is best.
- **Break condition:** If user history is extremely long or interactions are genuinely random noise with no relational structure, this mechanism may overfit to spurious patterns.

### Mechanism 3
- **Claim:** Generative recommendation decouples inference cost from the catalog size, offering efficiency gains over inner-product retrieval as item counts scale.
- **Mechanism:** Traditional methods score all items (O(IÂ·D)). MMGRec uses autoregressive decoding with beam search. The cost depends on Rec-ID sequence length, codebook size, and beam width, but not directly on item count. As item count grows, generating M tokens remains relatively constant while matrix multiplication cost grows linearly.
- **Core assumption:** Computational cost of constrained beam search over codebooks is strictly lower than nearest neighbor search in massive embedding space for large-scale systems.
- **Evidence anchors:** Section 4.5 discusses generative paradigm reducing inference time; Figure 5 shows MF/LightGT inference time rises linearly while MMGRec stays flat; abstract mentions efficiency advantages.
- **Break condition:** If codebook size must be increased drastically to distinguish massive numbers of items, the "flat" inference cost will rise.

## Foundational Learning

### Concept: Residual Quantization (RQ-VAE)
- **Why needed here:** Standard VQ-VAE uses one codebook; RQ-VAE stacks them to create a hierarchy of tokens for Rec-ID. Without understanding residual quantization, one cannot understand how a continuous vector becomes a 4-token discrete ID.
- **Quick check question:** Can you explain why we subtract the selected codeword from the vector before passing it to the next level of the codebook? (Answer: To quantize the residual error of the previous step, refining the approximation.)

### Concept: Autoregressive Generation & Beam Search
- **Why needed here:** The "Generative" in MMGRec relies on predicting Token t given Tokens 1...t-1. Beam search is required to keep the top-K possibilities alive at each step to find the best Rec-ID.
- **Quick check question:** Why is greedy search (taking the single best token at each step) insufficient for this architecture? (Answer: It might lead to a locally optimal token sequence that doesn't form a valid or optimal Rec-ID globally.)

### Concept: Bipartite Graph Convolution
- **Why needed here:** The "Graph" in Graph RQ-VAE. The model learns item representations by propagating