---
ver: rpa2
title: 'Got Compute, but No Data: Lessons From Post-training a Finnish LLM'
arxiv_id: '2503.09407'
source_url: https://arxiv.org/abs/2503.09407
tags:
- finnish
- data
- english
- instruction
- preference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a study on post-training a Finnish LLM for
  instruction-following tasks. The authors used machine translation to convert English
  instruction and preference datasets into Finnish, then performed instruction tuning
  and preference optimization using various combinations of English and Finnish data.
---

# Got Compute, but No Data: Lessons From Post-training a Finnish LLM

## Quick Facts
- **arXiv ID**: 2503.09407
- **Source URL**: https://arxiv.org/abs/2503.09407
- **Authors**: Elaine Zosa; Ville Komulainen; Sampo Pyysalo
- **Reference count**: 6
- **Primary result**: Finnish instruction-following performance achieved with <1% native Finnish training data through machine translation and strategic data mixing

## Executive Summary
This paper tackles the challenge of developing instruction-following capabilities for Finnish, a low-resource language, by post-training a multilingual LLM using machine-translated datasets. The authors demonstrate that competitive Finnish instruction-following performance can be achieved with minimal native Finnish data by combining English and Finnish instruction and preference datasets. Using a pragmatic approach of translating English instruction and preference datasets via few-shot prompting, they show that even with only a few hundred Finnish instruction samples, the model achieves strong performance on Finnish instruction-following tasks. The work provides practical insights for low-resource language model development and highlights the importance of strategic data mixing across languages.

## Method Summary
The authors post-train Poro-34B using a combination of machine-translated and native datasets. They translate English instruction datasets (OpenAssistant 2 and HelpSteer2) and preference pairs into Finnish using Poro with few-shot prompting, then apply heuristic cleaning. The training pipeline includes instruction tuning (SFT) with varying mixes of English and Finnish data (0%, 10%, 100% Finnish) using TRL with specific hyperparameters, followed by preference optimization (DPO) on the best SFT checkpoint using English-only, Finnish-only, and combined preference data. The model is evaluated on IFEval benchmark (translated to Finnish via DeepL) using strict accuracy metrics in both English and Finnish, with additional measurement of Finnish response rates for Finnish prompts. Training is conducted on 32 AMD MI250X GPUs with full parameter finetuning.

## Key Results
- Achieved competitive Finnish instruction-following performance with <1% native Finnish training data (approximately 200 Finnish instruction samples)
- Best results obtained using combined English and Finnish preference data, outperforming monolingual preference optimization
- English-only preference optimization provided cross-lingual benefits, though less effective than bilingual preference data
- Model maintained strong English instruction-following capabilities while acquiring Finnish instruction-following skills
- Performance varied by instruction type, with "combination" instructions showing lower accuracy

## Why This Works (Mechanism)
The approach leverages cross-lingual transfer learning where English instruction-following capabilities provide a foundation that can be adapted to Finnish with minimal native data. Machine translation enables rapid dataset creation, while strategic mixing of English and Finnish data during post-training allows the model to maintain bilingual capabilities. Preference optimization on combined language pairs helps the model learn to respond in the appropriate language based on the prompt. The few-shot translation approach using the model itself creates high-quality translations that preserve instruction structure while adapting to Finnish linguistic patterns.

## Foundational Learning
**Cross-lingual transfer learning**: Understanding how knowledge from high-resource languages transfers to low-resource languages is essential for efficient low-resource model development. Quick check: Compare performance of models trained from scratch in low-resource language versus post-trained multilingual models.

**Preference optimization**: DPO and similar methods align model outputs with human preferences through contrastive learning on preference pairs. Quick check: Verify that preference pairs are properly formatted and that model learns to distinguish preferred from dispreferred responses.

**Machine translation for dataset creation**: Using LLMs for few-shot translation enables rapid creation of training data for low-resource languages. Quick check: Evaluate translation quality using back-translation or human evaluation on sample pairs.

**Instruction tuning vs. Preference optimization**: Different post-training objectives serve complementary purposes - instruction tuning teaches task completion while preference optimization refines response quality and style. Quick check: Compare performance gains from each method independently before combining.

**Multilingual response generation**: Models must learn to generate responses in the appropriate language based on prompt language. Quick check: Measure language consistency rates for mixed-language prompts.

## Architecture Onboarding

**Component map**: Raw English datasets -> Machine translation (Poro few-shot) -> Heuristic cleaning -> SFT training (en-fi mixes) -> DPO training (pref data mixes) -> Evaluation (IFEval)

**Critical path**: The most sensitive steps are the machine translation quality and the data mixing ratios during both SFT and DPO phases. Translation quality directly impacts downstream performance, while data mixing determines the balance between maintaining English capabilities and acquiring Finnish skills.

**Design tradeoffs**: The primary tradeoff is between translation quality (using more sophisticated methods or human verification) and scalability/accessibility of the approach. The authors chose few-shot prompting for its simplicity and accessibility, accepting some translation noise for rapid dataset creation.

**Failure signatures**: If the model consistently responds in English to Finnish prompts, this indicates insufficient Finnish data ratio (should be ≥20%). Poor performance on combination instructions suggests the model struggles with multi-step reasoning in Finnish. If DPO degrades performance, this may indicate preference pairs are not properly aligned or the learning rate is too high.

**First experiments**: 1) Translate a small subset of English instructions and verify translation quality through back-translation. 2) Run SFT with 10% Finnish data to confirm the model can follow Finnish instructions. 3) Apply DPO using English-only preference pairs to verify cross-lingual benefits before proceeding to bilingual preference optimization.

## Open Questions the Paper Calls Out
**Cross-lingual preference optimization**: Can preference optimization methods be adapted to prevent unwanted code-switching in multilingual instruction-following? The authors note that DPO did not improve Finnish response rates and state, "Improving the response language of multilingual models through preference optimisation is an area we will explore in future work." Experiments using cross-lingual preference pairs or specific reward modeling that penalizes language mixing in structured outputs would resolve this.

**NEFTune effectiveness across data types**: Why does NEFTune fail to provide benefits when applied to multi-turn instruction tuning? The authors report that NEFTune failed to improve over the vanilla baseline and state, "We leave further examination of NEFTune and other noise augmentation techniques for future work." The failure might be dataset-dependent or linked to the multi-turn nature of the data. Ablation studies comparing NEFTune's impact on single-turn versus multi-turn conversation datasets would resolve this.

**Cultural evaluation benchmarks**: How can an evaluation benchmark effectively capture cultural and linguistic nuances for Finnish LLMs? Section 8 states, "we are interested on developing an evaluation benchmark for open-ended conversations in Finnish that takes cultural and linguistic nuances into account." Current evaluations rely on translated benchmarks (IFEval) which verify instruction adherence but lack cultural context. Creating and validating a native Finnish benchmark that correlates with human judgment on cultural relevance would resolve this.

## Limitations
- Reliance on machine translation quality with unspecified few-shot prompting templates and cleaning heuristics
- Conclusions may not generalize to other low-resource languages given Finnish's unique morphological characteristics
- Relatively small scale of human-verified Finnish data creates uncertainty about robustness of performance metrics
- Use of Finnish prompts to elicit Finnish responses during translation introduces potential bias

## Confidence
- **High confidence**: Even minimal Finnish data (≈200 samples) significantly improves Finnish instruction-following performance compared to English-only models
- **High confidence**: Combining English and Finnish preference data yields better results than either language alone for Finnish instruction following
- **Medium confidence**: Cross-lingual benefits from English preference optimization, given relatively small performance gaps and potential confounding factors
- **Low confidence**: Generalizability of findings to other low-resource languages beyond Finnish

## Next Checks
1. Replicate the translation process using different few-shot prompt templates and compare IFEval performance to establish sensitivity to translation methodology
2. Test the finetuned models on additional Finnish language benchmarks beyond IFEval to validate robustness of instruction-following capabilities
3. Conduct ablation studies varying the proportion of Finnish data in both instruction tuning and preference optimization phases to identify optimal mixing ratios