---
ver: rpa2
title: Score Combining for Contrastive OOD Detection
arxiv_id: '2501.12204'
source_url: https://arxiv.org/abs/2501.12204
tags:
- detection
- test
- rate
- inlier
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses out-of-distribution (OOD) detection by proposing
  a generalized likelihood ratio test (GLRT)-based method for combining multiple inlier
  scores. The core idea is to transform scores to z-values and combine them using
  a GLRT that accounts for negative mean shifts under the OOD hypothesis.
---

# Score Combining for Contrastive OOD Detection

## Quick Facts
- arXiv ID: 2501.12204
- Source URL: https://arxiv.org/abs/2501.12204
- Reference count: 23
- Proposes GLRT-based method for combining multiple inlier scores for OOD detection, outperforming CSI and SupCSI

## Executive Summary
This paper addresses out-of-distribution (OOD) detection by proposing a generalized likelihood ratio test (GLRT)-based method for combining multiple inlier scores. The method transforms scores to z-values and combines them using a GLRT that accounts for negative mean shifts under the OOD hypothesis. Experiments demonstrate superior performance over state-of-the-art techniques including CSI, SupCSI, and various score-combining methods across multiple datasets and experimental setups.

## Method Summary
The proposed method uses a generalized likelihood ratio test (GLRT) to combine multiple inlier scores for OOD detection. The core approach involves transforming scores to z-values and then combining them under a hypothesis that assumes negative mean shifts under the OOD hypothesis. This GLRT-based approach is specifically designed to work with intermediate scores from self-supervised contrastive learning methods, providing a more robust detection mechanism compared to existing techniques.

## Key Results
- GLRT-based method outperforms CSI and SupCSI in dataset-vs-dataset experiments
- Superior area under the receiver operating curve (AUROC) and detection rates achieved
- Best performance across CIFAR-10, SVHN, LSUN, ImageNet, and CIFAR-100 datasets

## Why This Works (Mechanism)
The GLRT-based approach works by leveraging statistical properties of score distributions under inlier and outlier hypotheses. By transforming scores to z-values and explicitly modeling the negative mean shift expected under OOD conditions, the method creates a more discriminative test statistic. This statistical framework allows for optimal combination of multiple scores while accounting for their dependencies and distributional properties.

## Foundational Learning
- Generalized Likelihood Ratio Test (GLRT): Needed to create optimal score combining framework; quick check: understand how GLRT handles composite hypotheses
- Z-value transformation: Required for score standardization; quick check: verify normality assumptions hold
- Contrastive learning scores: Core data source; quick check: understand score generation in self-supervised models
- Score distribution modeling: Essential for hypothesis testing; quick check: examine score distributions under in/outlier conditions
- Hypothesis testing framework: Fundamental to detection mechanism; quick check: understand null vs alternative hypotheses

## Architecture Onboarding
Component map: Contrastive model -> Score extractor -> Z-transform -> GLRT combiner -> OOD decision
Critical path: Score extraction and transformation directly impacts detection performance
Design tradeoffs: Balances computational efficiency with statistical optimality
Failure signatures: Poor performance when score distributions don't follow assumed patterns
First experiments:
1. Compare GLRT vs simple averaging on synthetic score distributions
2. Test z-transformation stability across different score types
3. Evaluate impact of score correlation on detection performance

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Assumed negative mean shift under OOD hypothesis may not hold across all score types and datasets
- Experimental scope limited to specific image datasets and self-supervised contrastive learning methods
- Performance gains may be partially dataset-dependent given specific experimental setup

## Confidence
- High confidence in mathematical derivation and theoretical foundations
- Medium confidence in empirical superiority claims due to specific dataset limitations
- Medium confidence in effectiveness for self-supervised contrastive learning scores

## Next Checks
1. Test the GLRT-based method on non-image datasets and supervised learning scenarios to assess generalizability
2. Evaluate performance when combining scores from different types of inlier distributions to test robustness
3. Conduct ablation studies removing the negative mean shift assumption to quantify its impact on detection performance