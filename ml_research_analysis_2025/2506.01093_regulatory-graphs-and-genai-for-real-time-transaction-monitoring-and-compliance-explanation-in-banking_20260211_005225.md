---
ver: rpa2
title: Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance
  Explanation in Banking
arxiv_id: '2506.01093'
source_url: https://arxiv.org/abs/2506.01093
tags:
- transaction
- graph
- compliance
- financial
- regulatory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a real-time transaction monitoring framework
  that combines graph neural networks, narrative field embeddings, and generative
  AI to detect and explain suspicious financial activities. The system dynamically
  constructs transaction graphs, fuses structural and textual features, and classifies
  anomalies using a graph convolutional network.
---

# Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking

## Quick Facts
- arXiv ID: 2506.01093
- Source URL: https://arxiv.org/abs/2506.01093
- Authors: Kunal Khanvilkar; Kranthi Kommuru
- Reference count: 25
- This paper presents a real-time transaction monitoring framework that combines graph neural networks, narrative field embeddings, and generative AI to detect and explain suspicious financial activities. The system dynamically constructs transaction graphs, fuses structural and textual features, and classifies anomalies using a graph convolutional network. Flagged transactions are explained using retrieval-augmented generation aligned with regulatory clauses. Experiments on the Elliptic dataset show 98.2% F1-score, 97.8% precision, and 97.0% recall, with expert validation confirming high-quality, regulation-aligned explanations.

## Executive Summary
This work addresses the critical need for interpretable, real-time detection of suspicious financial transactions by integrating graph neural networks with generative AI for compliance explanations. The proposed framework constructs dynamic transaction graphs, fuses topological and narrative features, and employs a GCN classifier to identify illicit activities with high accuracy. For flagged transactions, a retrieval-augmented generation module provides audit-ready explanations grounded in regulatory clauses. Experimental results on the Elliptic dataset demonstrate strong performance and highlight the system's potential for practical deployment in banking compliance.

## Method Summary
The framework dynamically constructs transaction graphs from incoming financial streams, extracting structural node features (in/out-degree, betweenness centrality, frequency) and narrative field embeddings via DistilBERT. These features are fused through a learned transformation and classified using a 3-layer GCN with sigmoid output. Flagged transactions trigger a retrieval-augmented generation pipeline: FAISS retrieves top-k regulatory clauses, and GPT-4 generates a natural-language explanation aligned with specific regulations. The system is trained on the Elliptic AML dataset with an 80/20 chronological split, evaluated using F1-score, precision, recall, and expert validation of explanation quality.

## Key Results
- Achieved 98.2% F1-score, 97.8% precision, and 97.0% recall on Elliptic AML dataset for illicit transaction detection
- Expert validation confirms high-quality, regulation-aligned explanations for flagged transactions
- Ablation study shows feature fusion (graph + narrative) improves detection over single-modality approaches
- Real-time framework successfully integrates structural and textual analysis with interpretable AI explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fusing structural graph features with narrative text embeddings improves illicit transaction detection compared to either modality alone.
- Mechanism: Node topological features (in/out-degree, betweenness centrality, transaction frequency) are encoded via linear transformation; narrative fields (e.g., transaction memos) are embedded via DistilBERT; both are concatenated and passed through a ReLU-activated fusion layer. This allows the classifier to leverage both behavioral patterns and semantic context.
- Core assumption: Narrative fields contain domain-relevant signals that correlate with illicit intent, and these signals are complementary to structural graph features.
- Evidence anchors:
  - [abstract] "fuses structural and textual features, and classifies anomalies using a graph convolutional network"
  - [section III.D] "fij = σ(Wf [zi ∥ êij] + bf)" — explicit fusion formula
  - [corpus] TeMP-TraG paper confirms temporal message passing on transaction graphs improves detection, supporting structural feature utility
- Break condition: If narrative fields are missing, corrupted, or uniformly uninformative (e.g., boilerplate text), fusion gains degrade to structural-only baseline.

### Mechanism 2
- Claim: Temporal decay weighting prioritizes recent transactions, improving real-time detection relevance.
- Mechanism: Each edge receives a decay factor δij = exp(−α(τt − τij)), reducing influence of older transactions in the GNN's message passing. This aligns learned representations with current behavioral states.
- Core assumption: Recent transaction patterns are more indicative of current illicit activity than historical patterns; decay rate α is appropriately tuned.
- Evidence anchors:
  - [section III.A] Equation 3 defines temporal decay explicitly
  - [abstract] "system dynamically constructs transaction graphs" — implies temporal awareness
  - [corpus] Weak direct evidence; no corpus papers explicitly validate temporal decay in AML GNNs
- Break condition: If α is mis-specified (too high → ignores history; too low → stale patterns dominate), real-time detection quality suffers.

### Mechanism 3
- Claim: Retrieval-augmented generation produces regulation-aligned explanations that improve audit-readiness.
- Mechanism: Flagged transactions query a FAISS index of pre-encoded regulatory clauses; top-k clauses are retrieved and passed to GPT-4, which generates a natural-language explanation grounded in specific rules.
- Core assumption: The regulatory corpus is comprehensive, up-to-date, and embeddings capture semantic relevance between transaction context and regulatory text; GPT-4 reliably synthesizes coherent justifications.
- Evidence anchors:
  - [section III.F] Equations 12-14 define retrieval and generation pipeline
  - [abstract] "retrieval-augmented generation aligned with regulatory clauses"
  - [corpus] AstuteRAG-FQA paper confirms RAG improves domain-specific accuracy and reduces hallucinations in finance tasks
- Break condition: If regulatory embeddings are misaligned with transaction context, retrieval returns irrelevant clauses → explanation hallucinates or mis-cites regulations.

## Foundational Learning

- Concept: Graph Neural Networks (GCN, message passing)
  - Why needed here: Core detection engine aggregates neighbor information to classify nodes; requires understanding of how node features propagate through edges.
  - Quick check question: Can you explain how a 3-layer GCN updates a node's representation using its neighbors' features?

- Concept: Transformer-based text embeddings (DistilBERT)
  - Why needed here: Encodes narrative fields into dense vectors for fusion with graph features; requires familiarity with pre-trained language models and tokenization.
  - Quick check question: What does normalizing the DistilBERT output (Equation 7) achieve before fusion?

- Concept: Retrieval-Augmented Generation (RAG)
  - Why needed here: Generates audit-ready explanations by grounding LLM outputs in retrieved regulatory text; requires understanding of embedding-based search and prompt construction.
  - Quick check question: How does FAISS retrieve top-k clauses, and what happens if the regulatory corpus lacks coverage for a flagged transaction type?

## Architecture Onboarding

- Component map:
  1. Graph Construction Module — builds dynamic directed graph Gt = (Vt, Et) from transaction stream
  2. Narrative Embedding Module — DistilBERT encodes memo fields, normalized to unit vectors
  3. Feature Fusion Layer — concatenates structural + textual features via learned transformation
  4. GCN Classifier — 3-layer graph convolution with sigmoid output for illicit/licit classification
  5. RAG Explanation Module — FAISS retrieval + GPT-4 generation for flagged transactions

- Critical path: Transaction ingestion → graph update → structural feature extraction + narrative embedding → fusion → GCN classification → if score > θ: retrieve regulations → generate explanation → output alert

- Design tradeoffs:
  - Synthetic vs. real narratives: Paper uses synthetically generated memos; real-world variability may degrade performance
  - Real-time latency vs. model depth: 3-layer GCN balances expressiveness and throughput; deeper models may increase latency
  - Retrieval granularity: Top-k clause selection affects explanation specificity; small k risks missing relevant rules

- Failure signatures:
  - Sudden F1 drop on new data → temporal distribution shift; retrain with recent time steps
  - Irrelevant retrieved clauses → regulatory corpus gaps or embedding misalignment; expand/refresh corpus
  - Inconsistent explanations for similar transactions → embedding noise; check DistilBERT fine-tuning stability

- First 3 experiments:
  1. Ablation study: Run detection with graph-only and narrative-only features; compare F1 to fused model to quantify contribution of each modality.
  2. Temporal robustness test: Train on time steps 1-40, test on 41-49; measure performance drift to assess real-time viability.
  3. Explanation validation: Sample 20 flagged transactions; have compliance experts rate regulatory alignment, clarity, and completeness (replicating Figure 6 methodology).

## Open Questions the Paper Calls Out

- Can the framework maintain performance when exposed to natural, noisy narrative fields rather than synthetically generated descriptions?
- How can the retrieval-augmented generation module be stabilized to prevent inconsistent justifications from marginal input variations?
- Is the current architecture extensible to multilingual regulatory rule sets and cross-jurisdictional compliance without significant retraining?

## Limitations
- Relies on synthetically generated narrative fields rather than real-world transaction memos, limiting generalizability
- Regulatory corpus details are not disclosed, making it difficult to assess coverage for all potential flagged transaction types
- Temporal decay weighting parameters are not specified, leaving optimal tuning for different financial crime patterns uncertain

## Confidence
- High confidence: Graph convolutional network performance metrics (F1-score 98.2%, precision 97.8%, recall 97.0%) on Elliptic dataset
- Medium confidence: Feature fusion mechanism combining structural and textual features improves detection over single modalities
- Medium confidence: Retrieval-augmented generation produces regulation-aligned explanations, based on expert validation in Figure 6

## Next Checks
1. Run ablation experiments comparing detection performance using only structural features, only narrative features, and the fused approach to quantify modality contributions
2. Test temporal robustness by training on earlier time steps and evaluating on later unseen periods to measure real-time detection stability
3. Conduct blind expert evaluation of generated explanations on a fresh sample of flagged transactions to verify regulatory alignment and audit-readiness