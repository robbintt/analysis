---
ver: rpa2
title: 'AI Epidemiology: achieving explainable AI through expert oversight patterns'
arxiv_id: '2512.15783'
source_url: https://arxiv.org/abs/2512.15783
tags:
- expert
- risk
- outputs
- reliability
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "AI Epidemiology presents a framework for governing and explaining\
  \ AI systems through population-level surveillance of outputs, bypassing the need\
  \ for mechanistic transparency into model computations. The approach standardizes\
  \ AI-expert interactions into structured fields\u2014risk level, alignment score,\
  \ and accuracy score\u2014that function as exposure variables predicting output\
  \ failure, analogous to how cholesterol predicts cardiac events."
---

# AI Epidemiology: achieving explainable AI through expert oversight patterns

## Quick Facts
- arXiv ID: 2512.15783
- Source URL: https://arxiv.org/abs/2512.15783
- Authors: Kit Tempest-Walters
- Reference count: 12
- Primary result: Achieves 94% inter-rater reliability (ICC = 0.89) for AI output assessments via RAG-based population surveillance

## Executive Summary
AI Epidemiology introduces a governance framework that treats AI-expert interactions as epidemiological data, creating structured assessment fields that predict output failure. The approach bypasses mechanistic transparency by standardizing expert oversight into measurable exposure variables—risk level, alignment score, and accuracy score—that function analogously to clinical risk factors. A feasibility study demonstrates that RAG-generated assessments can reliably capture these variables, enabling automatic audit trails and continuous model-agnostic governance. The framework democratizes AI oversight by allowing domain experts to identify unreliable outputs without requiring machine learning expertise, potentially preventing harm before it occurs.

## Method Summary
The framework implements Logia Grammar schema with eight structured fields to capture AI-expert interactions. RAG systems retrieve institutional domain guidelines to auto-generate initial assessments for risk level, alignment score (guideline adherence), and accuracy score (factual correctness). Expert decisions (override yes/no, corrective option) are captured passively via middleware integration with workflow systems. All records are stored in Tracelayer database. The triple-signal calibration approach progresses from rapid RAG assessment to expert overrides (medium-term) to outcome tracking (long-term). Reliability score is computed as the minimum of alignment and accuracy scores. Feasibility validation achieved 94% agreement across three ophthalmology cases with one expert reviewer.

## Key Results
- Achieves 94% inter-rater reliability (ICC = 0.89) in feasibility study
- Enables automatic audit trails and continuous model-agnostic governance
- Democratizes AI oversight by requiring domain expertise rather than ML expertise

## Why This Works (Mechanism)
The framework works by transforming opaque AI outputs into epidemiologically trackable variables through structured expert assessment. By treating AI-expert interactions as exposure data, it creates population-level patterns that predict output failure without requiring mechanistic understanding of model internals. The standardization of oversight into consistent fields enables reliable measurement across different AI systems and domains. The passive capture of expert decisions via middleware removes implementation friction, while the triple-signal calibration ensures both rapid response and long-term validation. This approach converts the traditionally one-off AI validation process into continuous population surveillance.

## Foundational Learning
- **Logia Grammar schema**: Standardized 8-field structure for capturing AI-expert interactions—needed to ensure consistent measurement across different domains; quick check: verify all fields are populated in sample cases
- **RAG-based assessment generation**: Retrieval-augmented generation to auto-populate risk and accuracy scores from institutional guidelines—needed to reduce expert burden and ensure consistency; quick check: compare RAG-generated scores against expert assessments
- **Passive middleware capture**: Automatic recording of expert overrides without manual data entry—needed to eliminate friction and ensure complete audit trails; quick check: verify override capture across 3+ workflow systems
- **Triple-signal calibration**: RAG → expert → outcomes progression—needed to balance speed, expertise, and real-world validation; quick check: measure time from RAG assessment to expert override to outcome recording
- **Reliability score computation**: Min(alignment, accuracy) as population-level failure predictor—needed to create actionable risk metrics; quick check: correlate reliability scores with actual output failures in validation set
- **Population-level pattern matching**: Detecting failure patterns across many cases rather than individual outputs—needed to identify systemic issues without mechanistic transparency; quick check: validate pattern detection against known failure modes

## Architecture Onboarding

**Component Map**
Tracelayer database -> RAG pipeline -> Middleware capture layer -> Logia Grammar interface -> Expert validation interface -> Population analytics engine

**Critical Path**
1. RAG retrieves institutional guidelines
2. Generates initial assessment fields
3. Expert reviews and overrides if needed
4. Middleware captures all decisions automatically
5. Data stored in Tracelayer for pattern analysis
6. Population analytics identifies failure trends

**Design Tradeoffs**
- Speed vs accuracy: RAG provides rapid assessment but requires expert validation
- Standardization vs flexibility: Logia Grammar ensures consistency but may miss nuanced failures
- Passive capture vs manual entry: Automation reduces friction but requires complex middleware integration
- Population-level vs individual focus: Patterns enable prediction but may miss rare edge cases

**Failure Signatures**
- Low alignment score reliability (ICC < 0.7) indicating institutional protocol variations
- Expert entrenchment where consensus contradicts outcome data
- Middleware integration failures causing incomplete audit trails
- RAG retrieval failures due to inadequate or outdated institutional documentation

**Three First Experiments**
1. Deploy Logia Grammar with 3 ophthalmology cases to validate field definitions and inter-rater reliability
2. Implement middleware capture with live EHR integration to verify automatic override recording
3. Run population analysis on 100+ AI outputs to test pattern detection for known failure modes

## Open Questions the Paper Calls Out
**Open Question 1**: Does measurement reliability (ICC ≥ 0.89) hold across diverse clinical domains, multiple experts, and larger case samples?
- Basis: Explicit statement that feasibility with one expert on three cases doesn't establish generalisability
- Why unresolved: Limited feasibility study scope (single expert, three ophthalmology cases)
- Evidence needed: Multi-domain deployment with 500+ cases and multiple expert reviewers per domain, achieving ICC ≥ 0.7 across all assessment fields

**Open Question 2**: How can alignment score achieve excellent reliability (ICC ≥ 0.9) given contextual dependence on institution-specific guidelines?
- Basis: Alignment score achieved moderate reliability (ICC = 0.67) with clear calibration pathway noted
- Why unresolved: Expert disagreements on alignment due to institutional protocol variations that RAG cannot anticipate
- Evidence needed: Longitudinal deployment showing supervised learning from expert corrective options improves alignment score ICC to ≥ 0.9

**Open Question 3**: What constitutes a sufficient data threshold for outcome data to override expert consensus when they conflict?
- Basis: Paper explicitly defers threshold decision to future empirical studies
- Why unresolved: No empirical basis currently exists for setting this parameter
- Evidence needed: Simulation studies or prospective deployment data analyzing conflict rates at different thresholds (50, 100, 500 cases)

## Limitations
- Relies heavily on availability and quality of institutional documentation for RAG-based assessments
- Passive middleware integration presents significant technical challenges across heterogeneous systems
- Population-level reliability scoring algorithm lacks sufficient specification for independent replication
- Feasibility study limited to single expert and three cases without validation against actual patient outcomes

## Confidence
**High confidence**: Conceptual framework mapping AI-expert interactions to epidemiological exposure variables is sound and well-justified through cardiac risk analogy
**Medium confidence**: Logia Grammar schema provides structured approach though field definitions require unpublished specification documents
**Low confidence**: Population-level reliability scoring algorithm and threshold determination lack sufficient specification for independent replication

## Next Checks
1. **Implementation trial**: Deploy middleware integration layer in live healthcare setting with 3+ different EHR systems to verify passive override capture functionality and measure integration overhead
2. **Ground truth validation**: Conduct controlled study comparing Logia-generated assessments against blinded expert consensus on 50+ cases, measuring sensitivity and specificity for detecting clinically significant errors
3. **Threshold calibration**: Execute population-level pattern analysis on 1,000+ AI outputs with expert interventions to determine optimal reliability score thresholds and validate their predictive value for actual patient harm outcomes