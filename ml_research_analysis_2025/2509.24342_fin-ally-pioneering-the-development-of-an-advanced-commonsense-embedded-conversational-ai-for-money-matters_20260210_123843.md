---
ver: rpa2
title: 'Fin-Ally: Pioneering the Development of an Advanced, Commonsense-Embedded
  Conversational AI for Money Matters'
arxiv_id: '2509.24342'
source_url: https://arxiv.org/abs/2509.24342
tags:
- financial
- arxiv
- context
- user
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Fin-Ally, a commonsense-embedded conversational
  AI for financial advisory, addressing the lack of contextual understanding in existing
  financial chatbots. The authors introduce Fin-Vault, a multi-turn financial dialogue
  dataset with 1,417 annotated conversations, and develop Fin-Ally by integrating
  COMET-BART for commonsense context, supervised fine-tuning, and Direct Preference
  Optimization (DPO).
---

# Fin-Ally: Pioneering the Development of an Advanced, Commonsense-Embedded Conversational AI for Money Matters

## Quick Facts
- **arXiv ID**: 2509.24342
- **Source URL**: https://arxiv.org/abs/2509.24342
- **Reference count**: 40
- **Primary result**: Fin-Ally achieves superior performance in generating coherent, contextually appropriate, and human-aligned financial responses compared to state-of-the-art LLMs.

## Executive Summary
Fin-Ally is a commonsense-embedded conversational AI for financial advisory that addresses the lack of contextual understanding in existing financial chatbots. The authors introduce Fin-Vault, a multi-turn financial dialogue dataset with 1,417 annotated conversations, and develop Fin-Ally by integrating COMET-BART for commonsense context, supervised fine-tuning, and Direct Preference Optimization (DPO). Experiments across multiple state-of-the-art LLMs show that Fin-Ally achieves superior performance in generating coherent, contextually appropriate, and human-aligned responses, with notable improvements in fluency, adequacy, and financial term retention.

## Method Summary
Fin-Ally employs a three-phase pipeline: (1) COMET-BART generates commonsense context from ConceptNet triples filtered by cosine similarity ≥0.7; (2) Gemma2-9B is fine-tuned with supervised fine-tuning on commonsense-augmented queries; (3) DPO optimization using preference pairs (preferred vs rejected responses). The model is evaluated on Fin-Vault, a dataset of 1,417 multi-turn dialogues covering 10 financial domains, annotated with politeness labels. Key components include a RoBERTa-based politeness classifier, automated metrics (BLEU, ROUGE, BERTScore, METEOR), and human evaluation across five quality dimensions.

## Key Results
- Fin-Ally outperforms baselines (Vicuna-7B, Mistral-7B, LLaMA3-8B) on automated metrics including BLEU, ROUGE, BERTScore, and METEOR.
- Human evaluation confirms Fin-Ally's enhanced response quality, with improvements in fluency, adequacy, consistency, financial term retention, and readability.
- The integration of commonsense context and DPO optimization significantly improves response coherence and human alignment.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Commonsense context enrichment improves response coherence and relevance in multi-turn financial dialogues.
- Mechanism: COMET-BART generates contextual inferences (xReason, xWant, xNeed, xIntent, xEffect) from user queries. These inferences are fused with encoder embeddings via a fusion mechanism before decoder generation. External knowledge triples from ConceptNet are converted to natural language, embedded with Sentence-BERT, and filtered via cosine similarity (threshold: 0.7) against query embeddings.
- Core assumption: Commonsense inference structures from general domains transfer to financial advisory contexts without domain-specific fine-tuning of COMET-BART.
- Evidence anchors: [abstract] "Fin-Ally is powered by COMET-BART-embedded commonsense context"; [section 4.2] Describes fusion mechanism: H′ = Fuse(H, K) and autoregressive decoding P(yᵢ|Y<ᵢ, H′).
- Break condition: If user queries require highly specialized financial knowledge not captured in ConceptNet, context quality degrades.

### Mechanism 2
- Claim: Direct Preference Optimization (DPO) increases alignment with human conversational preferences and reduces impolite or contextually inappropriate responses.
- Mechanism: A preference dataset D_pref is constructed with three response types: Preferred (y⁺), Rejected (y⁻), and Chosen. DPO loss maximizes the preference gap between y⁺ and y⁻ via: L_DPO(θ) = −Σ log σ(β · [log P_θ(y⁺|xₜ) − log P_θ(y⁻|xₜ)]).
- Core assumption: Preference annotations from 2 financial experts generalize across diverse user demographics and query types.
- Evidence anchors: [abstract] "optimized with a Direct Preference Optimization (DPO) mechanism to generate human-aligned responses"; [section 4.4] Describes DPO loss function and preference dataset construction.
- Break condition: If preference annotations exhibit high inter-annotator disagreement or systematic bias, DPO may amplify rather than correct misalignment.

### Mechanism 3
- Claim: Multi-turn dialogue structure with politeness annotation enables context-aware, user-centric financial advisory.
- Mechanism: Fin-Vault dataset contains 1,417 multi-turn dialogues (≥3 turns) annotated with politeness categories (Polite, Impolite, Neutral). Dialogues span banking, credit/debit cards, insurance, investments, loans, and taxation. A RoBERTa-based classifier evaluates generated responses, projecting [CLS] token embeddings through a linear layer to 3-class logits.
- Core assumption: Multi-turn structure and politeness labels capture sufficient signal for coherent, trust-building responses.
- Evidence anchors: [abstract] "Fin-Vault, a multi-turn financial dialogue dataset with 1,417 annotated conversations"; [section 3.3] Describes two-phase annotation protocol with E-FAIR metrics and politeness classification.
- Break condition: If dialogues contain contradictory turns or ambiguous politeness signals, model may generate inconsistent or tone-deaf responses.

## Foundational Learning

- Concept: **Commonsense Knowledge Graphs (e.g., ConceptNet, ATOMIC)**
  - Why needed here: COMET-BART relies on structured knowledge triples to infer user intent, needs, and effects. Without understanding how relations like "UsedFor" or "RelatedTo" work, you cannot debug context generation failures.
  - Quick check question: Given the triple ("credit card", "UsedFor", "emergency expenses"), can you explain how this would enrich a query about "lost debit card"?

- Concept: **Preference Optimization (DPO vs. RLHF)**
  - Why needed here: DPO directly optimizes policy from preference data without an explicit reward model, reducing computational complexity. Understanding this distinction helps diagnose whether misalignment stems from preference data quality or optimization hyperparameters (β).
  - Quick check question: If DPO-trained models still generate stereotyping responses, would you first check the preference dataset or increase β?

- Concept: **Multi-turn Dialogue State Tracking**
  - Why needed here: Fin-Ally must maintain coherence across ≥3 turns. Understanding how context accumulates and degrades helps identify where dialogue breaks down (e.g., topic drift, coreference failures).
  - Quick check question: In a 5-turn dialogue about loan refinancing, what context from turn 2 would still be relevant in turn 5?

## Architecture Onboarding

- Component map:
  Input Layer -> Commonsense Module -> Language Model Backbone -> Alignment Module -> Evaluation Layer
  - User query tokenization (BART tokenizer)
  - COMET-BART encoder + ConceptNet triple retrieval + Sentence-BERT embedding + cosine similarity filtering + fusion mechanism
  - Gemma2-9B (or other SOTA LLMs) fine-tuned on Fin-Vault
  - DPO loss with preference dataset (y⁺, y⁻)
  - RoBERTa politeness classifier + automated metrics + human evaluation

- Critical path:
  1. User query → COMET-BART context generation
  2. Context + query fusion → Gemma2-9B fine-tuned model
  3. DPO optimization → human-aligned response
  4. Politeness classification → quality filtering

- Design tradeoffs:
  - Context richness vs. latency: More ConceptNet triples improve relevance but increase inference time.
  - DPO β hyperparameter: Higher β enforces stronger preference separation but may reduce response diversity.
  - Dataset scale: 1,417 dialogues enable fine-tuning but may underrepresent edge cases.

- Failure signatures:
  - Generic responses: Context module may fail to retrieve relevant triples if similarity threshold (0.7) is too high.
  - Impolite outputs: DPO may not generalize if preference dataset lacks diversity in impolite response types.
  - Incoherent multi-turn: Dialogue state may degrade if earlier turns are not properly encoded in context fusion.

- First 3 experiments:
  1. Ablate COMET-BART context: Compare Gemma2-9B + DPO with and without commonsense context on Fin-Vault test set. Measure BLEU, ROUGE, BERTScore changes.
  2. DPO β sensitivity analysis: Vary β (e.g., 0.1, 0.5, 1.0) and evaluate politeness scores and response diversity (distinct n-grams).
  3. Cross-domain transfer test: Evaluate Fin-Ally on out-of-domain financial queries (e.g., cryptocurrency regulation) not in Fin-Vault to assess generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Fin-Ally architecture be effectively extended to a multimodal framework that processes image inputs while maintaining dialogue coherence?
- Basis in paper: [explicit] The conclusion states: "Our future endeavours include extending this work by developing a multimodal financial conversational agent capable of supporting multi-turn interactions with image inputs."
- Why unresolved: The current Fin-Ally model relies exclusively on text-based inputs and COMET-BART commonsense embeddings; it lacks visual encoding mechanisms required for multimodal tasks.
- What evidence would resolve it: Successful evaluation of a modified Fin-Ally model on a benchmark dataset containing mixed text and financial image queries (e.g., charts, receipts).

### Open Question 2
- Question: Does utilizing politeness as an explicit feedback signal significantly improve response quality and user alignment beyond the current Direct Preference Optimization (DPO) configuration?
- Basis in paper: [explicit] The authors state they "aim to investigate politeness as a feedback signal to further improve response quality and user alignment."
- Why unresolved: While the current model uses a politeness classifier for analysis, it optimizes via DPO using general preference data rather than a dynamic reward loop specifically tuned for politeness metrics.
- What evidence would resolve it: Comparative experiments showing that a reinforcement learning setup using politeness rewards yields higher user satisfaction scores than the current static DPO approach.

### Open Question 3
- Question: How effectively does Fin-Ally generalize to financial regulations and policies introduced after the creation of the static Fin-Vault dataset?
- Basis in paper: [inferred] The authors acknowledge discarding data due to "frequent policy changes" and highlight the need for "real-time" tracking, yet the model relies on a fixed training dataset without external retrieval mechanisms.
- Why unresolved: The model generates advice based on pre-trained weights and a static dataset; it is unclear if it can handle "real-time" regulatory shifts without retraining.
- What evidence would resolve it: Evaluation of model accuracy on queries regarding financial laws or rates enacted after the model's training data cutoff.

## Limitations

- Dataset scale and diversity: The Fin-Vault dataset comprises 1,417 dialogues, which may be insufficient to capture the full complexity of financial advisory across diverse user demographics, regulatory contexts, and edge cases.
- Commonsense knowledge domain mismatch: COMET-BART and ConceptNet are trained on general-domain knowledge, which may not fully align with specialized financial terminology or regulatory nuances.
- Preference dataset construction bias: The preference dataset for DPO is constructed by two financial experts, but the exact size, inter-annotator agreement, and demographic diversity of annotators are unspecified.

## Confidence

**High confidence**: The architectural integration of COMET-BART for commonsense context generation, the DPO optimization mechanism, and the multi-turn dialogue structure are technically sound and well-documented.

**Medium confidence**: The effectiveness of commonsense enrichment in financial domains and the generalization of preference-based alignment across diverse user queries are supported by experimental results but require broader validation.

**Low confidence**: The dataset's sufficiency for capturing all financial advisory scenarios and the absence of cross-cultural or multilingual evaluation represent significant limitations.

## Next Checks

1. **Dataset scale validation**: Expand Fin-Vault to include at least 5,000 dialogues covering underrepresented financial domains (e.g., cryptocurrency regulation, international tax law) and diverse user demographics. Measure impact on model performance and generalization.

2. **Commonsense domain transfer test**: Conduct ablation studies comparing COMET-BART-generated context against finance-specific knowledge graphs (e.g., FIBO). Evaluate response quality differences on regulatory and compliance-focused queries.

3. **Preference dataset bias analysis**: Recruit a diverse pool of financial experts and lay users to annotate the same preference dataset. Measure inter-annotator agreement and identify systematic biases. Re-train DPO with balanced annotations and compare performance.