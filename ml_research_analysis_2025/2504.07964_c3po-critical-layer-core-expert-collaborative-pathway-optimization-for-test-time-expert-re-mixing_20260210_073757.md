---
ver: rpa2
title: 'C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for
  Test-Time Expert Re-Mixing'
arxiv_id: '2504.07964'
source_url: https://arxiv.org/abs/2504.07964
tags:
- optimization
- performance
- experts
- layers
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Mixture-of-Experts (MoE) LLMs suffer from sub-optimal expert pathways,
  with a 10-20% accuracy gap between base models and oracle performance. C3PO addresses
  this by dynamically optimizing expert routing weights at test time using a reference
  set of successful samples.
---

# C3PO: Critical-Layer, Core-Expert, Collaborative Pathway Optimization for Test-Time Expert Re-Mixing

## Quick Facts
- arXiv ID: 2504.07964
- Source URL: https://arxiv.org/abs/2504.07964
- Reference count: 27
- One-line primary result: C3PO achieves 7-15% accuracy improvements over base MoE models by dynamically optimizing expert routing weights at test time.

## Executive Summary
C3PO addresses the sub-optimal expert pathway problem in MoE LLMs by dynamically optimizing routing weights at test time using successful neighbor samples. The method employs three surrogate objectives—mode finding, kernel regression, and neighborhood gradient descent—to guide pathway optimization without ground truth labels. By focusing on critical layers and core experts, C3PO achieves significant accuracy improvements while maintaining efficiency.

## Method Summary
C3PO optimizes expert routing weights for MoE LLMs at test time by leveraging a reference set of successfully answered samples. The method retrieves k-nearest neighbors based on embedding similarity, then applies one of three algorithms (mode finding, kernel regression, or neighborhood gradient descent) to optimize the pathway matrix. Critically, C3PO focuses optimization on the last 5 layers, top 20 experts per layer, and only the last token, achieving 7-15% accuracy improvements while reducing computational overhead.

## Key Results
- 7-15% accuracy improvements over base models on six benchmarks
- OLMoE-C3PO with 1B active parameters surpasses 7-9B dense models
- 85-95% of oracle performance recovered without ground truth labels
- Optimizing only last 5 layers and top 20 experts achieves equivalent performance to full-pathway optimization

## Why This Works (Mechanism)

### Mechanism 1
Optimizing routing weights for expert pathways at test time can recover 85-95% of the oracle performance gap because pretrained routers produce systematically suboptimal expert selections. The pretrained router selects experts based on features learned during training, but these do not generalize optimally to all test samples. By re-weighting expert contributions using information from similar successful samples in a reference set, C3PO shifts the pathway toward configurations that have proven effective for analogous inputs. Core assumption: samples with similar embeddings have similar optimal expert pathways; the reference set contains enough successful neighbors to approximate the optimal pathway. Evidence: abstract notes 10-20% accuracy gap; Table 1 shows NGD attains 85-95% of Oracle potential; break condition: if reference set lacks similar successful samples or embedding similarity does not correlate with pathway similarity.

### Mechanism 2
Optimizing only the last 5 layers and top 20 experts per layer achieves equivalent performance to full-pathway optimization because deeper layers disproportionately influence final predictions and most experts are redundant. The paper empirically shows a hierarchy where L5 > F5 > M5, indicating that late layers specialize in task-specific refinement. Similarly, top-20 experts before optimization cover 99.8% of the post-optimization top-8 experts. Focusing optimization on this reduced subspace preserves expressivity while cutting FLOPs. Core assumption: the importance distribution across layers and experts is stable across tasks and samples. Evidence: Figure 3 shows last five layers yield highest accuracy; Figure 5 shows selecting n ≥ 20 covers almost all core experts. Break condition: if a task relies heavily on early-layer representations or if expert importance shifts dramatically post-optimization.

### Mechanism 3
Optimizing routing weights for only the last token in the sequence is most effective because the final token's pathway aggregates the prediction decision. The last token's hidden state directly conditions the output distribution. Adjusting its expert routing weights influences the final representation without disrupting intermediate computations that have already been cached. Core assumption: the last token's routing weights are the bottleneck for prediction quality. Evidence: Table 3 shows optimizing only last token yields best accuracy (79.20%, 9.25% improvement); Table 9 shows last-1-token optimization consistently outperforms other strategies. Break condition: for tasks requiring multi-token generation, last-token-only optimization may be insufficient.

## Foundational Learning

- **Mixture-of-Experts (MoE) Routing**: C3PO operates on the routing weights that determine which experts are activated per token. Understanding that routers produce soft weights over experts and that a pathway is the sequence of these weights across layers is essential. Quick check: Given an MoE layer with 64 experts and top-8 routing, what does the router output for each token?

- **k-Nearest Neighbors (kNN) and Kernel Regression**: Two of the three C3PO algorithms rely on computing weighted averages over neighbors. Understanding how kernel functions weight similar samples is essential to grasp why Gaussian kernels outperform linear/polynomial alternatives. Quick check: If you have a test sample and a reference set with similarity scores [0.9, 0.7, 0.3], how would a Gaussian kernel weight these compared to uniform weighting?

- **Gradient Descent with Surrogate Objectives**: Neighborhood Gradient Descent minimizes a weighted sum of losses on neighbor samples rather than the unknown true loss. Understanding that this is a proxy optimization is critical to interpreting why NGD achieves 85-95% of oracle without ground truth. Quick check: Why might minimizing neighbor loss fail if neighbors are noisy or task-mismatched?

## Architecture Onboarding

- **Component map**: Input test sample -> Embedding model (NV-Embed-V2) -> kNN search for neighbors -> Retrieve neighbor pathway matrices ωi -> Initialize ω from pretrained router -> Apply optimization algorithm (NGD recommended) -> Forward pass with optimized ω -> Prediction

- **Critical path**: 1) Input test sample → embed with NV-Embed-V2; 2) Retrieve k=3 nearest neighbors from reference set; 3) Extract neighbor pathway matrices ωi; 4) Initialize ω from pretrained router output; 5) Apply NGD for 10 steps on last-token, last-5-layers, top-20-experts; 6) Forward pass with optimized ω → prediction

- **Design tradeoffs**: Mode Finding vs. Kernel Regression vs. NGD: Mode finding is fastest (no backprop) but lowest performance; NGD is most expensive but achieves best results (93% of oracle). More neighbors vs. fewer: k=3 optimal; k=1 underfits, k=5 over-smooths. More optimization steps: gains plateau after 10 steps; 50 steps offers no improvement. Embedding model quality: better embeddings directly improve neighbor quality and final accuracy.

- **Failure signatures**: Accuracy drops below baseline: likely caused by poor neighbor retrieval (embedding model mismatch, reference set too small, or task domain shift). Optimization unstable: check learning rate schedule; fixed LR underperforms cosine decay. No improvement despite correct setup: verify reference set samples have correct pathways (model predictions were correct); noisy pathways will mislead optimization. High variance across runs: k=1 or ε too small causes high sensitivity to individual neighbors.

- **First 3 experiments**: 1) Reproduce critical-layer ablation: On OLMoE, compare optimizing [F5, M5, L5, All16] on ARC-C. Confirm L5 matches or exceeds All16 accuracy. 2) Validate neighbor count sensitivity: Run C3PO (NGD) with k ∈ {1, 3, 5, 10} on MMLU. Plot accuracy vs. k to verify k=3 peak. 3) Test transfer across task types: Apply reference set from CommonsenseQA to PIQA (same task type) vs. from BIG-Bench to PIQA (different task type). Measure performance drop to assess domain sensitivity.

## Open Questions the Paper Calls Out

- Can the dynamic pathways optimized by C3PO be distilled back into the pretrained router to permanently fix the "sub-optimality" of the base model? The Introduction notes that "naive expert selection learned from pretraining leaves a surprising 10-20% accuracy gap," which C3PO fixes at test-time, but the base router remains unchanged.

- Why does optimizing the routing weights for only the last token result in higher accuracy than optimizing for the last three tokens? Table 3 shows optimizing "Last 1 Token" yields 79.2% accuracy, while "Last 3 Tokens" drops to 77.9%, a counter-intuitive result given that more tokens typically provide more information for gradient descent.

- Can the gradient-free surrogate objectives (Mode Finding, Kernel Regression) be improved to match the performance of Neighborhood Gradient Descent (NGD)? Table 1 and the Introduction highlight that while gradient-free methods are proposed to "avoid gradient-based backpropagation," they significantly underperform NGD (e.g., 72.5% vs. 74.4% for DeepSeekMoE).

## Limitations

- Performance gains are contingent on the quality and diversity of the reference set; if the reference set is too small, biased, or not representative of the test distribution, the optimization may not generalize well.

- Improvements are demonstrated on classification tasks; it remains unclear how C3PO would perform on generation tasks or tasks requiring multi-token outputs, where last-token-only optimization might be insufficient.

- Additional computation for neighbor retrieval, embedding, and optimization steps adds latency at test time; the trade-off between accuracy gains and inference speed is not fully explored.

## Confidence

- **High Confidence**: The mechanism of optimizing expert routing weights at test time to recover oracle performance is well-supported by ablation studies (critical layers, core experts, last token optimization). The 85-95% oracle recovery claim is directly tied to experimental results.

- **Medium Confidence**: The efficiency claims (OLMoE-C3PO with 1B active parameters outperforming 7-9B dense models) are supported by benchmarks but may not generalize to all tasks or model scales without further validation.

- **Low Confidence**: The claim that last-token-only optimization is universally optimal is based on single-token prediction benchmarks; its effectiveness on generation or multi-token tasks is not established.

## Next Checks

1. Apply C3PO to a generation task (e.g., summarization or story completion) and compare performance to classification benchmarks. Measure whether last-token-only optimization still yields improvements or if multi-token optimization is necessary.

2. Replace NV-Embed-V2 with a lower-quality or task-specific embedding model (e.g., sentence-BERT) and evaluate the impact on neighbor retrieval quality and final accuracy. This tests the dependency on embedding model quality.

3. Profile the end-to-end inference time of C3PO (including neighbor retrieval, embedding, and optimization steps) and compare it to the baseline MoE model. Quantify the trade-off between accuracy gains and computational overhead.