---
ver: rpa2
title: 'Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal
  Ultrasound-Xray Policy with Limited Labels'
arxiv_id: '2511.18457'
source_url: https://arxiv.org/abs/2511.18457
tags:
- coverage
- ultrasound
- us-only
- policy
- dysplasia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces a measurement-aware, cross-modal ultrasound-X-ray\
  \ policy for pediatric hip dysplasia that uses calibrated lower bounds to selectively\
  \ request radiographs. By pretraining frozen ResNet-18 encoders via SimSiam on large\
  \ unlabeled datasets and fitting small, interpretable heads for Graf \u03B1/\u03B2\
  \ and coverage (US) or acetabular index/center-edge angle (XR), the system achieves\
  \ clinically meaningful accuracies (e.g., \u03B1 MAE \u2248 9.7\xB0, coverage MAE\
  \ \u2248 14.0%)."
---

# Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal Ultrasound-Xray Policy with Limited Labels

## Quick Facts
- arXiv ID: 2511.18457
- Source URL: https://arxiv.org/abs/2511.18457
- Reference count: 9
- Primary result: SimSiam-pretrained frozen encoders with small measurement heads achieve clinically meaningful accuracies (α MAE ≈ 9.7°, coverage MAE ≈ 14.0%) while conformal calibration enables safe US-only decisions with provable coverage guarantees.

## Executive Summary
This work introduces a measurement-aware, cross-modal ultrasound-X-ray policy for pediatric hip dysplasia that uses calibrated lower bounds to selectively request radiographs. By pretraining frozen ResNet-18 encoders via SimSiam on large unlabeled datasets and fitting small, interpretable heads for Graf α/β and coverage (US) or acetabular index/center-edge angle (XR), the system achieves clinically meaningful accuracies (e.g., α MAE ≈ 9.7°, coverage MAE ≈ 14.0%). A one-sided conformal calibration layer provides finite-sample coverage guarantees, enabling safe US-only decisions when uncertainty is low. Decision-curve analysis quantifies trade-offs between radiation use and miss risk, offering interpretable operating points suitable for clinical deployment and external validation.

## Method Summary
The method employs self-supervised SimSiam pretraining on unlabeled US (37,186 images) and XR (19,546 images) datasets, followed by fitting small MLP measurement heads on a limited labeled subset (321 images). Frozen ResNet-18 encoders extract 512-dimensional features, which feed into lightweight heads predicting Graf angles and coverage for US, or AI/CE and IHDI for XR. Affine bias correction and one-sided conformal calibration generate calibrated lower bounds, which are evaluated against rule families (alpha-only, alpha OR coverage, alpha AND coverage) with thresholds (Tα=60°, Tcov=50%). The policy defers to X-ray when bounds fall below thresholds, otherwise proceeds with US-only assessment.

## Key Results
- US measurement accuracy: α MAE ≈ 9.7°, coverage MAE ≈ 14.0%
- XR measurement accuracy: AI MAE ≈ 7.6°, CE MAE ≈ 8.9°
- Conformal calibration achieves empirical coverage close to target (1-δ) across settings
- Decision curves quantify explicit trade-offs between radiation avoidance and miss risk
- US-only rates range from 0% (conservative) to 55% (permissive) depending on δ settings

## Why This Works (Mechanism)

### Mechanism 1
- Self-supervised pretraining on large unlabeled registries produces transferable visual features for downstream measurement tasks with limited labels.
- SimSiam learns by maximizing agreement between two augmented views of the same image via a stop-gradient prediction head, without requiring negative pairs.
- Core assumption: Augmentations used during pretraining (crop, flip, color jitter) preserve clinically relevant anatomical structures while providing useful variance.
- Evidence: Pretraining uses 57K+ unlabeled images; SSL advances demonstrated in related echocardiography work.

### Mechanism 2
- Frozen backbone with small measurement-specific heads achieves clinically meaningful accuracy while remaining label-efficient and interpretable.
- Global average pooled 512-dim features from frozen encoder feed into lightweight MLP heads (one 128-unit hidden layer) that directly regress clinical measurements.
- Core assumption: SSL features contain sufficient spatial and semantic information; measurement heads can learn the mapping without fine-tuning backbone weights.
- Evidence: Achieves α MAE ≈ 9.7° and coverage MAE ≈ 14.0° on clinical measurements.

### Mechanism 3
- One-sided conformal calibration provides finite-sample marginal coverage guarantees for lower bounds, enabling safe deferral decisions under uncertainty.
- On calibration set, compute residuals between corrected predictions and ground truth; take quantile at level (n+1)(1-δ)/n to define radius.
- Core assumption: Calibration and deployment data are exchangeable (i.i.d. or exchangeable draws from same distribution).
- Evidence: Provides provable safety bounds for clinical deployment without distributional assumptions.

## Foundational Learning

- **SimSiam self-supervised learning**: Enables leveraging 57K+ unlabeled images when only 321 labeled images exist for supervised training. Quick check: Why does SimSiam avoid collapse without negative pairs? (Answer: asymmetric design with stop-gradient and prediction MLP.)

- **Conformal prediction coverage guarantees**: Clinical deployment requires provable safety bounds; conformal provides finite-sample guarantees without distributional assumptions. Quick check: What happens to coverage guarantees if calibration set size is 26 images and exchangeability holds? (Answer: Guarantees hold but intervals will be wide due to small n.)

- **Decision-curve analysis for clinical utility**: Quantifies explicit trade-offs between radiation cost (λ) and miss penalty (μ) across operating points for clinical stakeholder buy-in. Quick check: If a site values radiation avoidance highly, how would λ be set relative to μ? (Answer: Higher λ relative to μ shifts optimum toward permissive settings with higher US-only rates.)

## Architecture Onboarding

- **Component map**: Image → frozen encoder → 512-dim pooled features → measurement head → raw predictions → affine correction → calibrated lower bounds → rule evaluation → US-only (1) / defer-to-XR (0)

- **Critical path**: Image → frozen encoder → 512-dim pooled features → measurement head → raw predictions → affine correction → calibrated lower bounds → rule evaluation → US-only (1) / defer-to-XR (0)

- **Design tradeoffs**:
  1. Conservative vs. permissive: Smaller δ → higher coverage (≥1-δ), lower US-only rate; larger δ → lower coverage, higher throughput.
  2. AND vs. OR rules: AND requires both α and coverage bounds exceed thresholds (more conservative); OR requires either (more permissive).
  3. Frozen vs. fine-tuned: Frozen enables rapid iteration and small-data learning; fine-tuning may improve accuracy but requires more labeled data and risks overfitting.

- **Failure signatures**:
  1. Coverage below target: Empirical coverage < 1-δ on eval set → exchangeability violated; recalibrate on site-specific data.
  2. US-only rate ≈ 0: Policy defers everything → δ too conservative; increase δ to enable throughput.
  3. High miss rate among US-only: Miss rate spikes → threshold too aggressive or δ too permissive; tighten bounds.

- **First 3 experiments**:
  1. Calibration validation: Verify empirical one-sided coverage for α and coverage matches target (1-δ) across δ ∈ {0.10, 0.20, 0.30, 0.40}.
  2. Policy sweep: Generate heatmaps of US-only rate and miss rate across (δα, δcov) grid for all three rule families.
  3. Decision-curve replication: For fixed μ ∈ {0, 0.5, 1.0}, plot utility U(λ) vs. λ for each rule family; identify λ thresholds where OR dominates AND and vice versa.

## Open Questions the Paper Calls Out

### External Validity of Conformal Coverage Guarantees
Will the finite-sample conformal coverage guarantees transfer to external clinical sites with different ultrasound equipment, operator expertise, and patient demographics, or will distribution shift violate exchangeability and require site-specific recalibration? The paper demonstrates results suitable for "future external validation" but calibration used only 7 subjects from a single center. Multi-site external validation at ≥3 independent centers would resolve this question.

### Practical Radiation Reduction at Safe Operating Points
Can the system achieve clinically meaningful radiation reduction while maintaining conformal coverage guarantees, or do the large conformal radii force near-zero US-only throughput at safe settings? Table 1 shows AND rule at δ=0.10/0.10 yields US-only rate of 0.00 with coverage ~0.90. Prospective deployment quantifying actual radiation reduction at operating points where empirical coverage meets clinical safety thresholds would resolve this question.

### Prospective Clinical Impact and Workflow Integration
What are the real-world impacts on radiation exposure, return-visit rates, and clinical acceptance when the system is deployed prospectively in routine practice? All reported results are retrospective. Prospective clinical trial with primary endpoints of radiation dose reduction, return-visit rates, and clinician-system agreement metrics would resolve this question.

### US-to-XR Surrogate Prediction for Risk Stratification
Can calibrated models predict radiographic measurements (AI, CE, IHDI) directly from ultrasound, enabling risk-based decision curves rather than threshold-based rules? The current policy compares US measurements against US-specific thresholds rather than predicting what XR would reveal. Development and validation of calibrated US→XR prediction heads would resolve this question.

## Limitations
- Frozen-backbone approach assumes SimSiam features generalize across devices/protocols; without evidence of multi-site diversity in pretraining data, coverage guarantees may degrade in deployment.
- Small calibration sets (n=26) yield wide conformal intervals, potentially limiting throughput.
- Clinical miss-risk trade-offs are evaluated on trainee-annotated labels, which may not fully capture expert variability.
- The paired US-XR dataset is not publicly available, constraining reproducibility.

## Confidence
- **High**: SimSiam pretraining efficacy and conformal coverage guarantees (distribution-free by construction)
- **Medium**: Frozen-backbone measurement accuracy and clinical miss-risk trade-offs (limited empirical validation across sites)
- **Low**: Long-term robustness to device/protocol shifts without site-specific recalibration

## Next Checks
1. Cross-site evaluation: Deploy on independent hospital dataset to verify exchangeability and recalibration needs.
2. Labeler variation analysis: Compare policy performance on trainee vs. expert annotations to quantify uncertainty in miss-risk estimates.
3. Ablation study: Fine-tune encoders on labeled data to assess accuracy-coverage trade-offs vs. frozen backbones.