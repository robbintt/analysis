---
ver: rpa2
title: 'When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal
  Link Prediction'
arxiv_id: '2507.13825'
source_url: https://arxiv.org/abs/2507.13825
tags:
- temporal
- node
- eagle
- graph
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles temporal link prediction on dynamic graphs by
  proposing EAGLE, a lightweight model that integrates short-term temporal recency
  and long-term global structural patterns. EAGLE uses a time-aware module that aggregates
  information from the most recent neighbors and a structure-aware module that leverages
  Temporal Personalized PageRank to capture influential nodes.
---

# When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction

## Quick Facts
- arXiv ID: 2507.13825
- Source URL: https://arxiv.org/abs/2507.13825
- Reference count: 40
- This paper proposes EAGLE, achieving over 50× speedup compared to transformer-based T-GNNs while maintaining superior accuracy across seven real-world datasets.

## Executive Summary
This paper tackles temporal link prediction on dynamic graphs by proposing EAGLE, a lightweight model that integrates short-term temporal recency and long-term global structural patterns. EAGLE uses a time-aware module that aggregates information from the most recent neighbors and a structure-aware module that leverages Temporal Personalized PageRank to capture influential nodes. These modules are combined via an adaptive weighting mechanism. Experiments on seven real-world datasets show EAGLE achieves superior effectiveness and efficiency, delivering over 50× speedup compared to transformer-based T-GNNs, while maintaining high accuracy across all evaluation metrics.

## Method Summary
EAGLE operates on continuous-time dynamic graphs and predicts future links using two complementary modules. The time-aware module aggregates features from a node's top-k_r most recent neighbors using mean pooling followed by a 2-layer MLP to capture immediate behavioral preferences. The structure-aware module leverages Temporal Personalized PageRank (T-PPR) to identify the top-k_s globally influential nodes and computes structural similarity based on shared influential neighbors, requiring no training. An adaptive weighting mechanism dynamically balances these scores based on interaction recency patterns, with nodes having recent activity receiving higher temporal emphasis. The model achieves high efficiency through its training-free structural component and incremental T-PPR updates.

## Key Results
- EAGLE achieves over 50× speedup compared to transformer-based T-GNNs across all tested datasets
- Maintains superior effectiveness with higher AP, MRR, and HR@10 scores than competitive baselines on Wikipedia, AskUbuntu, SuperUser, Reddit, LastFM, Contacts, and Wiki-Talk datasets
- EAGLE-Hybrid consistently outperforms individual time-aware and structure-aware variants by dynamically balancing temporal and structural signals

## Why This Works (Mechanism)

### Mechanism 1: Recent Neighbor Aggregation for Short-Term Recency
Aggregating information from a node's top-k_r most recent neighbors captures immediate behavioral preferences that strongly predict future links. The time-aware module computes node representations by averaging concatenated node and edge features from only the k_r most recent neighbors, then passes through a 2-layer MLP for link scoring. This mechanism assumes recent interactions are more predictive of immediate future behavior than older interactions, reflecting temporal locality in user preferences.

### Mechanism 2: Temporal Personalized PageRank for Global Structure
A small set of globally influential nodes identified via T-PPR captures sufficient long-term structural patterns without requiring multi-hop message passing. T-PPR computes influence scores with time-decayed transition probabilities, and the structure-aware score sums products of shared influential neighbors' T-PPR scores. This approach assumes Personalized PageRank approximates multi-hop structural influence, and temporal decay preserves recency within structural importance.

### Mechanism 3: Adaptive Weighting via Recency-Based Dynamic Balancing
Dynamically weighting time-aware and structure-aware scores based on interaction recency improves prediction over fixed weighting. The hybrid score uses exp(-t̄_v) + exp(-t̄_u) terms to upweight temporal scores for nodes with recent interactions and downweight for nodes with sparse/old activity, falling back to structural patterns. This mechanism assumes nodes with recent activity benefit more from temporal signals while nodes with sparse recent activity rely more on structural context.

## Foundational Learning

- **Personalized PageRank (PPR)**: Why needed - T-PPR is the core of the structure-aware module; understanding PPR's random-walk formulation explains why it captures multi-hop influence without explicit message passing. Quick check - Given a teleport probability α=0.15, what does a high PPR score from node v to node u indicate about their structural relationship?
- **Temporal Graph Representation**: Why needed - EAGLE operates on continuous-time dynamic graphs defined as sequences of interaction events γ(t) = (v, u, e_{v,u}(t), t); distinguishing this from discrete-time snapshots is essential. Quick check - How does a continuous-time dynamic graph G(t) differ from a sequence of static snapshots G_1, G_2, ..., G_T?
- **Link Prediction Evaluation Metrics (AP, MRR, HR@N)**: Why needed - The paper uses AP, MRR, and HR@10; understanding these metrics is required to interpret Tables 3 and 6 and design validation experiments. Quick check - Why might a model achieve high HR@10 but low AP on the same dataset?

## Architecture Onboarding

- **Component map**: Graph state maintains G(t) and T-PPR matrix π_V(t) → Time-aware module aggregates top-k_r recent neighbors → mean pooling → 2-layer MLP → s^{ta}_{v,u}(t) → Structure-aware module computes T-PPR scores → identifies top-k_s influential nodes → computes structural score s^{sa}_{v,u}(t) → Hybrid combiner computes average interaction intervals t̄_v, t̄_u → applies exponential decay weighting → combines with λ parameter → s^{hy}_{v,u}(t)
- **Critical path**: Receive new events {γ(τ_i)}^n_{i=1} → update graph G(τ_{-1}) to G(τ_n) → Update T-PPR matrix via T-PPR_UPDATING (incremental, O(n·k_s·log k_s)) → For each prediction pair (v_j, u_j): fetch k_r recent neighbors, compute time-aware score → Fetch shared top-k_s T-PPR nodes, compute structure-aware score → Compute hybrid score using Equation 11
- **Design tradeoffs**: k_r (recent neighbors): Higher values capture more temporal context but increase computation; paper shows diminishing returns beyond ~40. k_s (influential nodes): Higher values capture more structural context; paper shows stabilization around 20-30. λ (trade-off parameter): Controls temporal vs structural emphasis; tuned via validation set. Assumption: EAGLE-Struc. is training-free (deterministic), reducing overhead but limiting learned adaptation
- **Failure signatures**: OOM on large graphs: T-PPR matrix requires O(k_s|V(t)|) storage; if k_s or |V| grows unbounded, memory explodes. Degraded performance on cold-start nodes: Nodes with fewer than k_r neighbors cannot form complete time-aware representations. Stagnant T-PPR scores: If graph evolves faster than T-PPR converges, structural scores become stale. TLE on high-velocity streams: Batch size n too large triggers T-PPR update bottleneck
- **First 3 experiments**: 1) Ablation on k_r and k_s: Replicate Figure 4 and Figure 5 on your target dataset to find optimal values; plot AP/MRR/HR@10 vs k_r and k_s. 2) Per-module timing breakdown: Instrument code to measure time spent in (a) graph update, (b) T-PPR update, (c) time-aware scoring, (d) structure-aware scoring; identify bottleneck. 3) Cold-start analysis: Filter test set for nodes with <k_r interactions; compare EAGLE-Hybrid performance against baselines on this subset to validate robustness

## Open Questions the Paper Calls Out

### Open Question 1
**Question**: Does the time-aware module's use of mean pooling fail to capture critical sequential dependencies (order of events) within the selected recent neighbors?
**Basis in paper**: [inferred] Equation (6) aggregates features of the top-$k_r$ recent neighbors using a simple average (mean pooling), which effectively discards the specific chronological order of interactions within that subset.
**Why unresolved**: While the paper demonstrates that "recency" is more important than "old" or "uniform" sampling, it does not explicitly test whether the *order* of those recent events matters (i.e., event sequence $A \to B \to C$ vs $C \to B \to A$).
**What evidence would resolve it**: Ablation studies comparing the current mean-pooling approach against sequence-aware encoders (like RNNs or Transformers) applied strictly to the top-$k_r$ neighbors on datasets with complex causal dependencies.

### Open Question 2
**Question**: Is the heuristic adaptive weighting mechanism (Equation 11) robust against interaction patterns characterized by high burstiness or irregular periodicity?
**Basis in paper**: [inferred] The hybrid score relies on the average interaction time interval $\bar{t}$ to balance temporal and structural scores.
**Why unresolved**: A simple average time interval may not accurately represent the "urgency" or relevance of interactions in graphs where events occur in irregular bursts followed by long silences, potentially leading to suboptimal weighting.
**What evidence would resolve it**: Evaluation of the weighting parameter $\lambda$'s stability and performance on synthetic datasets specifically designed with power-law inter-event times or bursty traffic patterns.

### Open Question 3
**Question**: Can the EAGLE framework maintain its memory efficiency when scaling to graphs with billions of nodes given the requirement to store the T-PPR matrix?
**Basis in paper**: [inferred] Section 3.2.4 notes the space complexity is $O(|V|k_s)$ to store the top-$k_s$ T-PPR matrix.
**Why unresolved**: While the model is efficient on the tested datasets (up to 1.1M nodes), the storage requirement grows linearly with the number of nodes, which could become a memory bottleneck for massive-scale industry graphs (e.g., billions of users) without further compression or sampling techniques.
**What evidence would resolve it**: Performance and memory usage benchmarks on datasets with orders of magnitude more nodes (e.g., >10 million) to verify if the storage of the T-PPR matrix remains a "lightweight" constraint.

## Limitations
- The incremental T-PPR update algorithm is referenced from external work without full specification, creating uncertainty in faithful reproduction
- Performance on cold-start nodes may be degraded when nodes have fewer than k_r interactions, limiting robustness for sparse nodes
- Memory requirements scale linearly with node count due to T-PPR matrix storage, potentially limiting scalability to massive graphs without additional optimization

## Confidence
- **High confidence**: Time-aware module effectiveness (recent neighbor aggregation consistently improves performance)
- **Medium confidence**: T-PPR structural mechanism (well-grounded in related work but specific formulation unverified)
- **Medium confidence**: Adaptive weighting benefits (shown in Table 3 but mechanism not independently validated)

## Next Checks
1. Implement and validate the incremental T-PPR update procedure on a small synthetic graph to verify correctness
2. Conduct ablation studies comparing EAGLE's performance on graphs with strong temporal locality versus graphs with cyclical/long-term patterns
3. Test cold-start node performance by filtering evaluation to nodes with <k_r interactions and measuring degradation