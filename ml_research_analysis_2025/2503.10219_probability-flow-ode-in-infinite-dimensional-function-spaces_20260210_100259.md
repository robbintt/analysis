---
ver: rpa2
title: Probability-Flow ODE in Infinite-Dimensional Function Spaces
arxiv_id: '2503.10219'
source_url: https://arxiv.org/abs/2503.10219
tags:
- function
- diffusion
- infinite-dimensional
- equation
- solution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work derives the first probability-flow ODE (PF-ODE) in infinite-dimensional
  Hilbert spaces, extending the concept from finite-dimensional diffusion models.
  The PF-ODE is rigorously formulated using measure-valued Fokker-Planck-Kolmogorov
  equations and functional derivatives, enabling faster sampling without compromising
  quality.
---

# Probability-Flow ODE in Infinite-Dimensional Function Spaces

## Quick Facts
- arXiv ID: 2503.10219
- Source URL: https://arxiv.org/abs/2503.10219
- Reference count: 40
- Primary result: First probability-flow ODE (PF-ODE) in infinite-dimensional Hilbert spaces, enabling faster sampling than SDE-based diffusion models

## Executive Summary
This work extends the probability-flow ODE concept from finite-dimensional diffusion models to infinite-dimensional Hilbert spaces, enabling faster sampling of functions without compromising quality. The authors derive a rigorous mathematical framework using measure-valued Fokker-Planck-Kolmogorov equations and functional derivatives, circumventing the need for probability densities which are undefined in infinite dimensions. Experiments on synthetic 1D functions and PDE solutions demonstrate that PF-ODE achieves comparable or superior generation quality to SDE-based approaches while requiring significantly fewer function evaluations.

## Method Summary
The method trains a Fourier Neural Operator (FNO) score network using score-matching loss on noised data from Pdata, then samples functions by integrating a reverse PF-ODE backward in time from a Gaussian prior. The PF-ODE is formulated using logarithmic gradients along the Cameron-Martin space and derived via measure-valued Fokker-Planck-Kolmogorov equations with cylindrical test functions. At inference, the method samples initial noise from the prior covariance operator Q and solves the ODE using Euler integration, requiring only a single discretization of the infinite-dimensional noise rather than repeated discretization as in SDE sampling.

## Key Results
- ODE sampling with 20 NFE outperforms SDE sampling across all NFEs in 1D function generation
- ODE samples show lower sliced Wasserstein distances and Lp-distances to ground truth PDE solutions compared to SDE samples with same NFE
- The theoretical framework successfully extends PF-ODE to infinite-dimensional spaces using functional derivatives and Fomin differentiability

## Why This Works (Mechanism)

### Mechanism 1: Deterministic Transport via ODE Sampling
Replacing the stochastic SDE path with a deterministic ODE path preserves the marginal distribution at each time while enabling fewer steps. The infinite-dimensional PF-ODE is constructed so that its marginal laws coincide with those of the original SDE, using logarithmic gradients in Hilbert space and the Fokker-Planck-Kolmogorov equation. This removes stochasticity during integration, allowing larger effective step sizes without compounding noise-induced discretization errors.

### Mechanism 2: Functional Derivatives Enable Infinite-Dimensional Extension
Functional derivatives (Gâteaux/Fréchet) and Fomin differentiability allow rigorous derivation without relying on probability densities, which are undefined in infinite-dimensional spaces. The derivation uses measure-valued Fokker-Planck-Kolmogorov equations with cylindrical test functions and logarithmic gradients along the Cameron-Martin space, circumventing the need for a Lebesgue-like reference measure.

### Mechanism 3: Single vs. Repeated Discretization Error
ODE sampling incurs a single discretization error from the initial noise approximation, while SDE sampling accumulates repeated discretization errors from the noise injection at each step. The paper hypothesizes that for SDE solvers, the infinite-dimensional noise is approximated discretely at each step, compounding error. The ODE formulation requires only one such approximation at initialization.

## Foundational Learning

- **Hilbert Spaces & Cameron-Martin Space**
  - Why needed: The entire formulation operates on separable Hilbert spaces (e.g., L²(Ω)) rather than ℝⁿ. The Cameron-Martin space H_Q defines the directions along which logarithmic gradients exist.
  - Quick check: Can you explain why the covariance operator Q must be trace class for a Gaussian measure to exist on an infinite-dimensional Hilbert space?

- **Gâteaux & Fréchet Derivatives**
  - Why needed: Gradients in function spaces are not vectors but linear functionals or operators. The proof relies on Fréchet derivatives of cylindrical test functions and Fomin derivatives of measures.
  - Quick check: Given a functional F: H → ℝ, what is the relationship between its Gâteaux differential along h and its Fréchet derivative?

- **Fokker-Planck-Kolmogorov Equations (Measure-Valued)**
  - Why needed: In infinite dimensions, the Fokker-Planck equation cannot be written in terms of a density. The weak formulation with cylindrical test functions is the core analytical tool.
  - Quick check: How does the weak formulation ∫H L f dμ = ∂t ∫H f dνt replace the classical density-based PDE?

## Architecture Onboarding

- **Component map:** Input functions -> Noise sampling (Q operator) -> Score network (FNO) -> PF-ODE sampler (Euler integration)
- **Critical path:** 1) Train Sθ using score-matching loss on noised data from Pdata; 2) Sample initial noise ξ ~ N(0, Q) via truncated KL expansion or FFT; 3) Integrate PF-ODE backward in time using Euler steps with trained Sθ
- **Design tradeoffs:** ODE vs. SDE Sampler (ODE faster but potentially less robust); Choice of Q (affects smoothness - RBF kernels yield smooth samples, Bessel priors suited for PDE solutions); Discretization Resolution (high enough to approximate infinite-dimensional behavior but impacts computational cost)
- **Failure signatures:** ODE divergence (samples blow up or lose coherence, indicating poor score approximation or too few integration steps); SDE artifacts (excessive noise or blurriness at low NFE, requiring more steps); Kernel mismatch (if Q does not match smoothness of data distribution, samples may be overly rough or smooth)
- **First 3 experiments:**
  1. Synthetic 1D Functions (Quadratic): Train on ax² + ε with a ∈ {-1, 1}, ε ~ N(0, 1), evaluated on x ∈ [-10, 10] at 100 points. Compare ODE vs. SDE sampling at NFEs ∈ {5, 10, 20, 35} using kernel two-sample test power.
  2. Diffusion-Reaction PDE: Train on PDEBench dataset (64×64 resolution). Generate samples at NFEs ∈ {10, 50, 90} and compute sliced Wasserstein distance against test solutions.
  3. Heat Equation (Time-Evolving): Generate 3D spatiotemporal solutions (2D space + time) at NFE=10. Compute L² and L∞ error against numerically solved ground truth with same initial condition.

## Open Questions the Paper Calls Out

### Open Question 1
Can advanced high-order ODE solvers and consistency distillation techniques be effectively adapted to infinite-dimensional function spaces? The current implementation relies on a basic Euler method for solving the ODE, and the adaptation of finite-dimensional acceleration techniques to Hilbert spaces remains unexplored.

### Open Question 2
What are the theoretical bounds on discretization error for infinite-dimensional diffusion models, and how do they differ between the ODE and SDE formulations? The paper identifies the lack of formal error analysis but does not provide bounds for how approximation errors propagate through the infinite-dimensional ODE or SDE solvers.

### Open Question 3
Is the superior performance of PF-ODE strictly attributable to the difference in noise discretization error accumulation (single vs. repeated)? This mechanism is stated as a conjecture to explain the empirical results rather than a proven cause.

### Open Question 4
Does the PF-ODE's advantage over SDE generalize to other variance schedules (e.g., VESDE, sub-VPSDE) beyond the VPSDE used in the experiments? Empirical validation is currently limited to one type of noising process, leaving the robustness of the PF-ODE across different variance schedules unstated.

## Limitations
- The theoretical framework relies on strong regularity conditions (Fomin differentiability) that may not hold for arbitrary data distributions
- Experimental validation is limited to low-dimensional function spaces (1D and 2D) and specific PDE classes, leaving scalability to higher dimensions unexplored
- Comparative analysis against SDE baselines does not explore the full spectrum of solver parameters or alternative ODE formulations

## Confidence
- **High Confidence:** The theoretical derivation of the infinite-dimensional PF-ODE (Theorem 3.1) is mathematically rigorous and follows established stochastic calculus principles. The empirical observation that ODE sampling achieves comparable quality with fewer function evaluations is well-supported by the experimental results.
- **Medium Confidence:** The claim that ODE sampling provides a significant computational advantage over SDE sampling in practice is plausible but requires more extensive validation across diverse problem domains.
- **Low Confidence:** The practical scalability of the approach to truly high-dimensional function spaces (e.g., 3D+time) and its robustness to different types of score network architectures and Q operators are not thoroughly investigated.

## Next Checks
1. **Scalability Test:** Evaluate the PF-ODE approach on 3D spatiotemporal PDE solutions (e.g., Navier-Stokes equations) to assess computational feasibility and sample quality in higher dimensions.
2. **Robustness Analysis:** Compare the performance of different score network architectures (e.g., FNO vs. other Fourier-based models) and Q operators (e.g., Matérn kernels) to determine the sensitivity of the method to architectural choices.
3. **Theoretical Stress Test:** Construct a counterexample where the intermediate measures μt fail to be Fomin differentiable, and analyze the breakdown of the PF-ODE formulation to understand the limits of the theoretical framework.