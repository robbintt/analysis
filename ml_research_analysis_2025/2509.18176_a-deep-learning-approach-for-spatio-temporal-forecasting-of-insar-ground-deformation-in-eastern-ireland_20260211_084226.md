---
ver: rpa2
title: A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation
  in Eastern Ireland
arxiv_id: '2509.18176'
source_url: https://arxiv.org/abs/2509.18176
tags:
- displacement
- data
- spatial
- prediction
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a novel deep learning framework for forecasting
  ground deformation using InSAR time-series data. The key innovation is transforming
  sparse point measurements into dense spatio-temporal tensors, enabling the direct
  application of advanced computer vision architectures.
---

# A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland

## Quick Facts
- arXiv ID: 2509.18176
- Source URL: https://arxiv.org/abs/2509.18176
- Reference count: 25
- Primary result: CNN-LSTM model achieves RMSE of 0.2854 and R² of 0.9901 on Sentinel-1 InSAR data from eastern Ireland

## Executive Summary
This study introduces a deep learning framework for forecasting ground deformation using InSAR time-series data by transforming sparse point measurements into dense spatio-temporal tensors. The proposed CNN-LSTM architecture learns both spatial patterns and temporal dependencies from these tensors, achieving superior performance compared to LightGBM and LASSO regression baselines. The framework demonstrates excellent predictive accuracy (RMSE of 0.2854, R² of 0.9901) while providing insights into why traditional models default to simplistic persistence patterns.

## Method Summary
The framework transforms sparse InSAR Measurement Points into dense 256x256 grids using linear interpolation, creating 5D tensors (samples × timesteps × channels × height × width). A three-block CNN extracts spatial features, compressing 256x256 maps to 32x32 feature maps with 128 channels. An LSTM processes these compressed spatial states sequentially to capture temporal dynamics, followed by a fully connected layer to reconstruct the predicted 256x256 displacement map. The model is trained using MSE loss with Adam optimization, benchmarked against LightGBM and LASSO regression trained on flattened pixel values.

## Key Results
- CNN-LSTM achieves RMSE of 0.2854 and R² of 0.9901, significantly outperforming LightGBM and LASSO baselines
- Interpretability analysis reveals baseline models default to persistence patterns, relying overwhelmingly on the most recent time step
- Grid resolution of 256x256 selected as optimal tradeoff between spatial fidelity and GPU memory constraints
- The model successfully captures complex spatio-temporal deformation dynamics rather than simply replicating previous states

## Why This Works (Mechanism)

### Mechanism 1
Transforming sparse geolocation points into dense tensors allows spatial feature extractors to learn neighborhood dependencies that point-wise models miss. The framework interpolates irregularly spaced Measurement Points onto a regular 256x256 grid, creating topological continuity that enables CNN convolutional kernels to aggregate gradients and textures from adjacent pixels rather than treating locations as isolated time-series.

### Mechanism 2
Hybridizing CNNs with LSTMs enables the model to decouple spatial pattern recognition from temporal state evolution. The CNN acts as a spatial compressor, reducing 256x256 maps to 32x32 feature maps (128 channels), which are fed sequentially into an LSTM. This allows the LSTM to learn temporal transitions across compressed spatial states, preventing overfitting to transient spatial noise.

### Mechanism 3
The model succeeds by learning dynamic change rather than defaulting to autoregressive persistence. Unlike baseline models that rely overwhelmingly on the most recent time step, the CNN-LSTM processes the entire sequence history to minimize reconstruction loss, enabling it to extrapolate non-linear trends rather than simply mirroring the previous state.

## Foundational Learning

- **Spatial Interpolation & Gridding**: Raw InSAR data is sparse point-cloud data requiring regular grids for standard CNNs. Linear interpolation fills gaps between Measurement Points, but may create false deformation bridges between unrelated geological features.
- **Sequence Modeling (LSTM)**: Ground deformation exhibits inertia and momentum requiring memory cells to understand velocity and acceleration from time-series, rather than static regression that treats each time step independently.
- **Persistence vs. Forecasting**: Common failure mode where models simply predict the current state for the next time step. Understanding this helps interpret why baseline models failed despite high correlation metrics.

## Architecture Onboarding

- **Component map:** CSV of sparse points → Interpolator (Scipy `griddata`) → Dense 5D tensor → 3-Block CNN (Conv + Pool) → Feature Maps → LSTM → Fully Connected Layer → Output map
- **Critical path:** Spatial resolution tradeoff. Paper tested 128, 256, and 512 grids, selecting 256x256 as optimal compromise between spatial fidelity and GPU memory (76MB vs 300MB for 512x512).
- **Design tradeoffs:** Higher resolution increases VRAM usage 4x, limiting batch size and potentially destabilizing BatchNorm; linear interpolation is fast but may smooth edges while complex methods might introduce overshoot artifacts.
- **Failure signatures:** Spatial blurring indicates overly aggressive pooling or convergence to mean-value solution; autoregressive drift shows perfect matching of t-1 but slow deviation from ground truth; edge artifacts suggest incorrect padding strategies.
- **First 3 experiments:** 1) Reconstruct sparse-to-dense pipeline and train LASSO to verify persistence failure mode; 2) Remove LSTM and compare RMSE to quantify temporal memory contribution; 3) Train on 128x128 grid to check if fine-grained detail disappears.

## Open Questions the Paper Calls Out

- Can the framework be extended to reliable multi-step forecasting for practical long-term planning and early-warning systems?
- To what extent does fusion of external geophysical and meteorological data improve forecasting accuracy beyond historical InSAR displacement alone?
- Can Graph Neural Networks or Vision Transformers capture long-range spatial dependencies more effectively than the proposed CNN-LSTM architecture?
- Does linear interpolation of sparse InSAR points introduce artifacts that bias the deep learning model rather than representing actual physical changes?

## Limitations

- Framework relies on linear interpolation that may smooth out critical localized deformation features or create artifacts
- Model trained and evaluated on single geographic region (eastern Ireland), limiting generalization to areas with different geological characteristics
- Performance on capturing extreme events or rapid deformation changes remains unclear from presented results

## Confidence

- **High Confidence:** CNN-LSTM architecture effectively captures spatio-temporal patterns on Irish dataset with documented superiority over baselines
- **Medium Confidence:** Interpretability findings showing baseline models default to persistence patterns are convincing but could benefit from more detailed visualizations
- **Medium Confidence:** Resolution choice (256x256) represents appropriate tradeoff, but sensitivity analysis could be more comprehensive

## Next Checks

1. Conduct cross-validation on InSAR datasets from geographically distinct regions (e.g., California vs. Ireland) to assess generalization capability
2. Perform ablation studies systematically removing spatial vs. temporal components to quantify their individual contributions to predictive performance
3. Evaluate model robustness on synthetic datasets with known deformation patterns and controlled levels of measurement sparsity to validate interpolation assumptions