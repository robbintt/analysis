---
ver: rpa2
title: 'FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics'
arxiv_id: '2508.14087'
source_url: https://arxiv.org/abs/2508.14087
tags:
- track
- particle
- data
- sphenix
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work develops FM4NPP, a scalable foundation model for experimental
  nuclear and particle physics, addressing the challenge of applying self-supervised
  learning to sparse, high-dimensional detector data. A novel self-supervised pretraining
  objective is proposed, predicting k-nearest neighbors in the next radial neighborhood
  to avoid learning serialization artifacts, and a physics-informed hierarchical raster
  scan serialization method is introduced to convert unordered 3D spacepoints into
  sequential input.
---

# FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics

## Quick Facts
- arXiv ID: 2508.14087
- Source URL: https://arxiv.org/abs/2508.14087
- Reference count: 31
- Primary result: Foundation model with 188M parameters achieves state-of-the-art performance on track finding (ARI 0.9448), PID (accuracy 0.9039), and noise tagging (accuracy 0.9713) using frozen embeddings with lightweight adapters

## Executive Summary
FM4NPP addresses the challenge of applying self-supervised learning to sparse, high-dimensional detector data in nuclear and particle physics. The model introduces a novel k-Next-Nearest-Neighbor (k-N3) pretraining objective that predicts spatial neighbors in the next radial neighborhood, avoiding artifacts from sequence serialization. Using a physics-informed hierarchical raster scan serialization method, FM4NPP converts unordered 3D spacepoints into sequential input suitable for Mamba-based sequence models. The approach demonstrates strong scaling behavior across model sizes from 0.34M to 188M parameters and enables effective transfer to diverse downstream tasks through frozen embeddings with single linear projections.

## Method Summary
FM4NPP employs a two-stage paradigm: self-supervised pretraining on massive unlabeled collision data followed by lightweight adaptation to downstream tasks. The model uses a physics-informed hierarchical raster scan serialization to convert unordered 3D spacepoints into sequential input, preserving both local track continuity and global particle propagation structure. The k-N3 pretraining objective predicts k-nearest neighbors in the next radial neighborhood, forcing the model to learn genuine spatial relationships rather than sequence position artifacts. A Mamba2 backbone processes the serialized sequences, with frozen pretrained representations enabling task-agnostic transfer through single linear projections to task-specific embeddings.

## Key Results
- Achieves ARI 0.9448, efficiency 96.08%, purity 93.08% on track finding task
- Attains accuracy 0.9039, recall 0.7652, precision 0.8782 on particle identification
- Delivers accuracy 0.9713, recall 0.9367, precision 0.9190 on noise tagging
- Demonstrates consistent performance improvement with model scaling up to 188M parameters
- Shows data-efficient adaptation where frozen embeddings with linear adapters outperform task-specific baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The k-Next-Nearest-Neighbor (k-N3) pretraining objective enables physics-informed representation learning without learning serialization artifacts.
- Mechanism: For each query spacepoint si, the model predicts coordinates of k spatially nearest neighbors residing only in the next radial neighborhood Nc(si) = {sj ∈ E | rj > ri}. This forces the model to learn genuine spatial relationships rather than 1D sequence position artifacts, as the target is defined by 3D geometry rather than serialization order.
- Core assumption: Spatial proximity in detector geometry correlates with physical trajectory continuity; predicting outward radial neighbors aligns with particle propagation physics.
- Evidence anchors:
  - [abstract] "A novel self-supervised pretraining objective is proposed, predicting k-nearest neighbors in the next radial neighborhood to avoid learning serialization artifacts"
  - [section: Self-supervised Pretraining Objectives] "the prediction objective must be decoupled from the sequence order... The target for any given spacepoint si, must be defined by its geometric relationship to other spacepoints in 3D, not its 1D sequence position"
  - [corpus] Weak direct corpus support for k-N3 specifically; related work "Sparse Methods for Vector Embeddings of TPC Data" explores representation learning on TPC data but uses different objectives.
- Break condition: If your detector geometry has non-radial particle propagation (e.g., central collisions with isotropic emission), or if tracking requires backward propagation (inner layers missing), the radial-only neighbor constraint may miss critical context.

### Mechanism 2
- Claim: The Hierarchical Raster Scan serialization preserves both local track continuity and global particle propagation structure.
- Mechanism: Two-level ordering operates on (r, ϕ, η) cylindrical coordinates: (1) Inter-box ordering partitions space into 6×8×8 grid aligned with detector layer boundaries and frequency-based binning, ordering boxes by geometric centers from innermost outward; (2) Intra-box ordering sorts spacepoints by radial coordinate within each box. This balances global physics (outward propagation) with local continuity (same-track points remain proximate).
- Core assumption: Particle tracks follow approximately radial trajectories from collision point; detector layer boundaries provide meaningful structural priors.
- Evidence anchors:
  - [abstract] "a physics-informed hierarchical raster scan serialization method is introduced to convert unordered 3D spacepoints into sequential input"
  - [section: Serialization of Spacepoints] "The serialization strategy must balance two competing objectives: preserving the global structure of particle trajectories... and maintaining local continuity along individual tracks"
  - [corpus] No direct corpus comparison of serialization methods for TPC data found.
- Break condition: If tracks curve significantly in (ϕ, η) due to magnetic field non-uniformity, or if secondary interactions create non-radial trajectories, local continuity within fixed grid cells may fragment tracks.

### Mechanism 3
- Claim: Frozen pretrained representations transfer across diverse downstream tasks via single linear projections.
- Mechanism: The k-N3 objective encodes task-agnostic geometric structure. For downstream tasks, a single learned linear layer projects dmodel-dimensional embeddings to task-specific embeddings before lightweight task heads. PCA visualization shows raw FM embeddings lack class separation, but post-linear-projection features show well-separated track clusters.
- Core assumption: k-neighborhood geometry captures sufficient physics structure to enable linear separability for track finding, PID, and noise tagging; adaptation requires only re-orientation of representation space.
- Evidence anchors:
  - [abstract] "FM embeddings are task-agnostic but can be specialized via a single linear transformation"
  - [section: Insights about FM Adaptation] "the raw FM embeddings exhibit no clear separation among particle tracks... However, after applying a single linear projection, distinct and well-separated clusters emerge"
  - [corpus] "Fine-tuning machine-learned particle-flow reconstruction" demonstrates transfer learning across detector geometries but uses full fine-tuning, supporting the broader transfer hypothesis but not specifically frozen-weights with linear adapters.
- Break condition: If downstream tasks require fundamentally different geometric reasoning (e.g., calorimeter energy reconstruction vs. TPC tracking), or if tasks require integrating information across physically separated detector subsystems not present during pretraining, linear adaptation may be insufficient.

## Foundational Learning

- **State Space Models (SSMs) and Mamba architecture**
  - Why needed here: Mamba provides linear-time sequence processing critical for long TPC sequences (hundreds to thousands of spacepoints per event), avoiding Transformer's quadratic attention cost.
  - Quick check question: Can you explain why Mamba's input-dependent state matrices enable selective information retention vs. RNNs' fixed recurrence?

- **Self-supervised learning with geometric objectives**
  - Why needed here: Massive unlabeled collision data (~11M events) requires objectives that don't need human annotation; k-N3 leverages inherent spatial structure.
  - Quick check question: How does k-N3 differ from contrastive learning, and why might contrastive methods fail on sparse, variable-density point clouds?

- **Neural scaling laws and µ-Parameterization**
  - Why needed here: Stable training across 0.34M to 188M parameters requires principled learning rate and initialization scaling; µP enables zero-shot hyperparameter transfer.
  - Quick check question: What happens to gradient norms if you naively scale model width without adjusting learning rates per µP?

## Architecture Onboarding

- **Component map**: Raw spacepoints (E, x, y, z) → cylindrical transform (r, ϕ, η) → min-max normalization → Hierarchical Raster Scan serialization → Embedding Layer (Energy projection + NeRF positional encoding) → (B, S, dmodel) → L stacked Mamba2 blocks (RMSNorm → Mamba2 → residual) → Pretraining Head (Linear → 3k output) or Downstream Adapters (linear projection → task-specific heads)

- **Critical path**: Spacepoint serialization quality → embedding expressiveness → backbone capacity (scaling) → adapter head design. Serialization errors propagate as fragmented tracks; insufficient model capacity limits neighbor prediction accuracy; poorly designed adapters waste pretrained features.

- **Design tradeoffs**:
  - **Grid granularity**: Finer grid (more boxes) preserves local continuity better but increases sequence fragmentation at boundaries; current 6×8×8 aligns r-bins with detector layer groups.
  - **k value**: Larger k increases task difficulty (predicting more distant neighbors) but may encode richer geometry; paper uses k=10.
  - **Frozen vs. fine-tuned**: Frozen weights enable data-efficient adaptation but may limit peak performance on tasks poorly aligned with k-N3 objective.

- **Failure signatures**:
  - **ARI ~0.72 with AdapterOnly**: Indicates pretrained features provide meaningful signal; if FM+adapter matches AdapterOnly, pretraining failed.
  - **Validation MSE plateaus early**: Check event-difficulty rescaling; dense events may dominate loss.
  - **Track queries predict many "no-object"**: Hungarian matching may be failing due to insufficient queries (N) relative to true track count; check query initialization.

- **First 3 experiments**:
  1. **Scaling curve validation**: Train m1-m3 on 1% data subset; verify power-law MSE decrease with model size. If curve breaks, check µP scaling rules for initialization/learning rate.
  2. **Serialization ablation**: Compare Hierarchical Raster Scan vs. pure radial sort vs. space-filling curve on m3 validation MSE and downstream track-finding ARI. Expect ~5-10% ARI degradation with naive alternatives.
  3. **Linear probe analysis**: Extract frozen m6 embeddings, train only linear layer + classifier on noise tagging; if accuracy <0.85 (vs. 0.97 with full adapter), representations require non-linear adaptation for this task.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the FM paradigm generalize to heavy-ion collisions or be unified across multiple collider experiments worldwide?
- Basis in paper: [explicit] The authors ask in the conclusion: "Another open question is whether the FM paradigm can generalize to heavy-ion collisions or be unified across multiple collider experiments worldwide."
- Why unresolved: The current study is restricted to proton-proton collisions at the RHIC collider.
- What evidence would resolve it: Successful application and evaluation of the model on heavy-ion datasets or data from different colliders (e.g., LHC) without degradation in generalization.

### Open Question 2
- Question: Does the performance plateau observed at the largest model size (188M parameters) indicate a fundamental saturation point?
- Basis in paper: [explicit] In the "Neural Scaling Behaviors" section, the authors note that "performance plateaus at m6, suggesting a possible saturation point, which we leave for future investigation."
- Why unresolved: The study only scales up to 188M parameters, and the cause of the plateau (e.g., data limits vs. architecture limits) is not analyzed.
- What evidence would resolve it: Extending scaling laws to models larger than 188M parameters or varying dataset sizes to see if the saturation point shifts.

### Open Question 3
- Question: Can the FM incorporate additional detector subsystems, such as calorimeters and silicon trackers, to support tasks like particle-flow reconstruction?
- Basis in paper: [explicit] The "Conclusion and Future Work" states that "incorporating additional detector subsystems... could enable broader downstream tasks."
- Why unresolved: The current architecture and serialization are tailored specifically for TPC spacepoints.
- What evidence would resolve it: A modified model that processes heterogeneous input data (e.g., calorimeter hits) and successfully performs tasks requiring multi-detector information.

### Open Question 4
- Question: Can supervised fine-tuning across multiple downstream tasks further improve performance compared to using frozen weights with adapters?
- Basis in paper: [explicit] The "Conclusion and Future Work" suggests it "may also be valuable to extend the FM paradigm to incorporate supervised fine-tuning jointly across multiple downstream tasks."
- Why unresolved: The current two-stage paradigm relies on frozen weights, and the potential benefits or conflicts of joint fine-tuning were not explored.
- What evidence would resolve it: Benchmarking results comparing the frozen-adapter method against a model fine-tuned jointly on track finding, PID, and noise tagging.

## Limitations

- **Detector Geometry Dependency**: The Hierarchical Raster Scan serialization assumes radially-outward particle propagation and detector structures with meaningful layer boundaries, potentially fragmenting tracks for non-radial geometries.
- **Linear Adaptation Boundary**: While effective for three tasks, the k-N3 pretraining objective may not capture sufficient physics for more complex downstream applications requiring different geometric reasoning or multi-detector integration.
- **Scaling Law Generalization**: The reported power-law scaling behavior spans only three orders of magnitude in model size and two orders of magnitude in dataset size, limiting confidence in extrapolation to much larger models or datasets.

## Confidence

- **FM4NPP achieves state-of-the-art performance across three downstream tasks**: High
- **k-N3 pretraining objective avoids serialization artifacts while capturing physical structure**: Medium
- **Single linear transformation enables effective transfer across diverse tasks**: Medium
- **Power-law scaling behavior observed across model and dataset sizes**: Low

## Next Checks

1. **Cross-Detector Transfer Experiment**: Apply pretrained FM4NPP embeddings to a TPC with different geometry (different number of layers, different radial binning, or different magnetic field configuration). Measure degradation in downstream task performance and test whether finetuning frozen weights recovers baseline performance. This directly tests the geometric generalization claims and identifies serialization strategy limitations.

2. **Scaling Law Extrapolation Test**: Train models at 0.1M, 500M, and 1B parameters on 0.1%, 50%, and 200% of the original dataset size. Plot MSE vs. parameters and MSE vs. data on log-log scales to verify power-law behavior holds beyond the reported range. Check for deviations that might indicate saturation effects or regime changes.

3. **Adapter Capacity Ablation**: Systematically vary the adapter architecture complexity (linear → 1-hidden-layer MLP → 2-hidden-layer MLP) for each downstream task while keeping FM embeddings frozen. Measure performance trade-offs to identify whether linear projection is truly sufficient or if non-linear adapters provide meaningful gains for specific tasks, particularly noise tagging which showed the highest baseline accuracy.