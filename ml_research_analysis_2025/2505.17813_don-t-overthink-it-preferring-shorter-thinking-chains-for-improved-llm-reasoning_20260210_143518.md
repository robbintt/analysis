---
ver: rpa2
title: Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning
arxiv_id: '2505.17813'
source_url: https://arxiv.org/abs/2505.17813
tags:
- thinking
- reasoning
- accuracy
- compute
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work challenges the common belief that longer thinking chains\
  \ in reasoning language models lead to better performance. Through extensive experiments\
  \ on four competitive reasoning benchmarks, the authors demonstrate that shorter\
  \ reasoning chains are significantly more likely to yield correct answers\u2014\
  up to 34.5% more accurate than the longest chain generated for the same question\u2014\
  while using 25%\u201350% fewer tokens."
---

# Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning

## Quick Facts
- arXiv ID: 2505.17813
- Source URL: https://arxiv.org/abs/2505.17813
- Reference count: 40
- Primary result: Shorter reasoning chains are significantly more likely to yield correct answers while using fewer tokens and computational resources

## Executive Summary
This work challenges the prevailing assumption that longer thinking chains in reasoning language models lead to better performance. Through extensive experiments on four competitive reasoning benchmarks, the authors demonstrate that shorter reasoning chains are significantly more likely to yield correct answers—up to 34.5% more accurate than the longest chain generated for the same question—while using 25%–50% fewer tokens. The proposed short-m@k method executes k parallel generations and halts computation once the first m chains are completed, selecting the final answer via majority voting among these shortest chains. In low-compute settings, short-1@k (selecting the single shortest chain) outperforms standard majority voting while using up to 40% fewer thinking tokens and reducing wall time by up to 50%. For higher compute regimes, short-3@k consistently surpasses majority voting across all compute budgets while being up to 33% faster.

## Method Summary
The paper introduces short-m@k, a novel inference method that challenges traditional test-time scaling approaches in reasoning LLMs. The method works by executing k parallel generations and halting computation once the first m chains are completed, then selecting the final answer via majority voting among these shortest chains. This approach leverages the observation that shorter reasoning chains are often more accurate than longer ones. The method is particularly effective in low-compute settings where short-1@k (selecting the single shortest chain) outperforms standard majority voting while significantly reducing token usage and wall time. For higher compute budgets, short-3@k provides consistent improvements over majority voting while maintaining efficiency gains. The authors also demonstrate that fine-tuning on shorter reasoning chains leads to improved accuracy and reduced computational overhead compared to training on longer chains.

## Key Results
- Shorter reasoning chains are up to 34.5% more accurate than the longest chain generated for the same question
- short-1@k uses up to 40% fewer thinking tokens and reduces wall time by up to 50% compared to standard majority voting
- short-3@k consistently outperforms majority voting across all compute budgets while being up to 33% faster
- Fine-tuning on shorter reasoning chains improves accuracy and reduces computational overhead compared to training on longer chains

## Why This Works (Mechanism)
The paper's findings suggest that longer reasoning chains often contain unnecessary detours, backtracking, and exploration that don't contribute to finding the correct solution. Correct answers exhibit fewer backtracks and a more direct path to solution, indicating that excessive reasoning can lead to confusion or overcomplication of problems. The short-m@k method effectively exploits this phenomenon by prioritizing shorter, more focused reasoning chains that are more likely to arrive at correct answers efficiently. This approach aligns with cognitive science findings about human problem-solving, where overly complex reasoning processes can sometimes hinder rather than help problem resolution.

## Foundational Learning

**Chain-of-Thought Reasoning**: A prompting technique where LLMs generate intermediate reasoning steps before providing a final answer. Needed because it helps LLMs break down complex problems into manageable steps. Quick check: Can the model solve multi-step problems with correct intermediate reasoning?

**Test-Time Scaling**: The practice of increasing computational resources during inference to improve model performance. Needed because it's commonly assumed that more computation leads to better results. Quick check: Does increasing compute budget improve accuracy monotonically?

**Majority Voting**: A technique where multiple model generations are created and the most common answer is selected. Needed because individual model outputs can be unreliable. Quick check: Does majority voting improve accuracy over single generations?

**Backtracking Analysis**: Examining the paths reasoning chains take to identify when models reconsider previous steps. Needed because it reveals inefficiencies in reasoning processes. Quick check: Do correct answers exhibit fewer backtracking events than incorrect ones?

## Architecture Onboarding

**Component Map**: Input Question -> k Parallel Reasoning Chains -> Chain Length Evaluation -> Select m Shortest Chains -> Majority Voting -> Final Answer

**Critical Path**: The core innovation is the early termination mechanism that stops generation once m chains are completed, rather than waiting for all k chains. This creates a race condition where shorter chains "win" and are prioritized for the final answer selection.

**Design Tradeoffs**: The method trades potential completeness of reasoning for efficiency and accuracy. While longer chains might occasionally find correct answers through extensive exploration, the empirical evidence shows that this is outweighed by the noise and confusion introduced by unnecessary reasoning steps.

**Failure Signatures**: The method may fail on problems requiring extensive exploration or complex multi-step solutions where longer chains are genuinely necessary. It also assumes that chain length correlates with reasoning quality, which may not hold for all problem types.

**First Experiments**: 1) Compare accuracy of shortest vs. longest chains on held-out reasoning tasks, 2) Evaluate wall time and token savings of short-m@k vs. standard majority voting across different k values, 3) Analyze backtracking patterns in correct vs. incorrect answers to validate the mechanism hypothesis.

## Open Questions the Paper Calls Out
None

## Limitations
- Findings are based on open-source reasoning models and may not generalize to proprietary models like OpenAI's o1
- Performance improvements are highly dependent on specific reasoning benchmarks and may not translate to other domains
- The method assumes shorter chains are more likely to be correct, which may not hold for all reasoning tasks
- Computational savings are based on theoretical token counts and may vary in practical implementations

## Confidence
- High confidence in the empirical observation that shorter reasoning chains are often more accurate than longer ones across tested benchmarks
- Medium confidence in the generalizability of short-m@k's performance improvements to other reasoning tasks and model architectures
- Medium confidence in the claim that shorter chains exhibit fewer backtracks, as analysis is based on specific datasets
- Low confidence in universal applicability to all reasoning tasks, particularly those requiring extensive exploration

## Next Checks
1. Test the short-m@k method on proprietary reasoning models (e.g., OpenAI o1, o3) to validate performance improvements across different model architectures and training approaches
2. Evaluate the method on a broader range of reasoning tasks, including those requiring extensive exploration, complex multi-step solutions, or domain-specific knowledge not covered in current benchmarks
3. Conduct ablation studies to determine the optimal value of k for different reasoning tasks and computational budgets, and investigate whether the relationship between chain length and accuracy varies across problem types or difficulty levels