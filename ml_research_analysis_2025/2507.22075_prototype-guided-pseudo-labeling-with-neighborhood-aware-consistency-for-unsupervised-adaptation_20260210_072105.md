---
ver: rpa2
title: Prototype-Guided Pseudo-Labeling with Neighborhood-Aware Consistency for Unsupervised
  Adaptation
arxiv_id: '2507.22075'
source_url: https://arxiv.org/abs/2507.22075
tags:
- pseudo-labels
- clip
- class
- accuracy
- alpha
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces ALPHA, a framework to enhance unsupervised
  CLIP adaptation by addressing the challenge of noisy pseudo-labels in fully unsupervised
  settings. ALPHA integrates two components: PICS, which assesses pseudo-label accuracy
  via in-class compactness and cross-class separation using prototype-based scoring,
  and NALR, which refines noisy pseudo-labels by exploiting neighborhood consistency
  through semantic alignment with LLM-generated text descriptions.'
---

# Prototype-Guided Pseudo-Labeling with Neighborhood-Aware Consistency for Unsupervised Adaptation

## Quick Facts
- arXiv ID: 2507.22075
- Source URL: https://arxiv.org/abs/2507.22075
- Reference count: 40
- Authors: Eman Ali; Chetan Arora; Muhammad Haris Khan
- Key outcome: Achieves state-of-the-art performance on 11 datasets with +10.07% average accuracy over zero-shot CLIP and +7.85% over CuPL

## Executive Summary
This paper introduces ALPHA, a framework to enhance unsupervised CLIP adaptation by addressing the challenge of noisy pseudo-labels in fully unsupervised settings. ALPHA integrates two components: PICS, which assesses pseudo-label accuracy via in-class compactness and cross-class separation using prototype-based scoring, and NALR, which refines noisy pseudo-labels by exploiting neighborhood consistency through semantic alignment with LLM-generated text descriptions. The method also employs an adaptive weighting mechanism to dynamically modulate sample influence based on local semantic coherence. Extensive experiments on 11 diverse datasets demonstrate that ALPHA achieves state-of-the-art performance, with average accuracy improvements of +10.07% over zero-shot CLIP and +7.85% over CuPL, and +1.42% over DPA. Results highlight robust generalization, computational efficiency, and resilience to noisy data.

## Method Summary
ALPHA is a framework for unsupervised adaptation of CLIP models that addresses noisy pseudo-labels through two main mechanisms: PICS (Prototype-based In-class Compactness and Cross-class Separation) for geometric filtering, and NALR (Neighborhood-Aware Label Refinement) for semantic refinement. The method initializes text prototypes using LLM-generated descriptions, builds a memory bank of features and pseudo-labels, filters clean samples via geometric consistency, refines noisy samples through semantic alignment with LLM text, and iteratively updates class prototypes. The model fine-tunes only layer-norm parameters and text prototypes using a combined loss function with adaptive weighting based on neighborhood consistency. Training uses AdamW optimizer, cosine learning rate schedule, weak/strong data augmentations, and runs for 15 epochs.

## Key Results
- Achieves +10.07% average accuracy improvement over zero-shot CLIP baseline
- Outperforms CuPL by +7.85% average accuracy across 11 datasets
- Demonstrates +1.42% improvement over DPA while maintaining computational efficiency
- Shows robust performance across diverse datasets including Caltech101, DTD, EuroSAT, Flowers102, OxfordPets, UCF101, StanfordCars, Food101, CIFAR100, CUB-200-2011, and RESISC45

## Why This Works (Mechanism)

### Mechanism 1: Geometric Filtering via Prototype Consistency (PICS)
Filtering pseudo-labels based on geometric position relative to class prototypes yields cleaner training data than standard confidence thresholds. PICS evaluates a sample $x_i$ by comparing its similarity to its assigned class prototype ($\phi(x_i)$) against its similarity to samples of other classes ($\psi(x_i)$). A sample is retained only if it is more similar to its own class than to others ($\phi(x_i) > \psi(x_i)$). The core assumption is that correctly classified samples cluster tightly around their class centroid (high in-class compactness), while incorrect samples reside in ambiguous inter-class spaces.

### Mechanism 2: Semantic Label Refinement via Neighborhood Consistency (NALR)
Discarding noisy samples wastes data; refining them using LLM-aligned semantic neighbors recovers valid training signal. For samples rejected by PICS, NALR replaces the visual pseudo-label with a label derived from the most similar LLM-generated text description. It then validates this new label by checking local semantic coherence (adaptive weighting $\lambda_i$). The core assumption is that visual features should align with semantic text descriptions, and a valid pair should be more similar to its neighbors than to random pairs.

### Mechanism 3: Feedback Loop via Memory Bank
Iteratively updating prototypes prevents the model from collapsing onto initial errors. A memory bank stores features and confidence scores. As NALR refines labels and PICS filters them, the class prototypes ($\mu_c$) are recomputed, shifting the geometric boundaries for the next epoch. The core assumption is that the model improves incrementally, allowing prototypes to move from noisy initial positions toward true class centers.

## Foundational Learning

**Concept: Vision-Language Alignment (CLIP)**
- Why needed: The method adapts a pre-trained CLIP model; understanding that visual and text embeddings share a space is required to grasp why text prototypes can filter visual labels.
- Quick check: How does cosine similarity between an image embedding and a text embedding determine classification in zero-shot CLIP?

**Concept: Pseudo-Labeling & Confirmation Bias**
- Why needed: ALPHA is designed specifically to mitigate the error accumulation from noisy pseudo-labels.
- Quick check: If a model trains on its own incorrect predictions, what happens to the decision boundary over time?

**Concept: Prototype Learning**
- Why needed: PICS relies on comparing samples to class centroids (prototypes).
- Quick check: In a high-dimensional space, does a "compact" class have high or low variance?

## Architecture Onboarding

**Component map:** Input: Unlabeled images + Class Names → Pre-processing: LLM generates text descriptions → Text Prototypes ($Z$) → Core Logic: PICS Module computes in-class ($\phi$) and cross-class ($\psi$) scores → NALR Module matches noisy images to LLM descriptions → Training: Combined Loss ($L_{st} + L_N + L_{reg}$) updates only Layer Norm parameters → Memory Bank stores $(f_i, \hat{y}_i, \omega_i)$ for prototype recalculation.

**Critical path:** The definition of the cross-class set $O(f_i)$ in PICS (Page 4). If this set is constructed poorly (e.g., random sampling vs. confusion-based), the filtering threshold $\phi > \psi$ becomes unreliable.

**Design tradeoffs:**
- Cross-class Selection (CS vs. RS vs. FS): "CS" (Confidence-based) is safer but might miss hard negatives; "FS" (Confusion-based) targets boundary cases but is riskier if the model is initially very wrong.
- Weighting: Adaptive weighting ($\lambda$) adds computation (retrieval) but saves epochs by not wasting gradient steps on noise.

**Failure signatures:**
- Over-filtering: PICS rejects 90%+ of data (Check: low "Number of Clean Samples" in logs). Fix: Relax threshold or check prototype initialization.
- Semantic Drift: NALR assigns labels that match text but contradict visual reality. Fix: Verify LLM prompts match the visual domain context.

**First 3 experiments:**
1. Baseline Sanity Check: Run Zero-shot CLIP vs. ALPHA-B (no PICS/NALR) vs. ALPHA-FS on EuroSAT (satellite data) to confirm the noise problem exists and is recoverable.
2. Component Isolation: Run ALPHA-CS (PICS only) vs. ALPHA w/o PICS (NALR only) to measure the specific contribution of filtering vs. refinement.
3. Noise Stress Test: Inject 50% irrelevant data (e.g., CIFAR-100 into CIFAR-10) to verify if PICS successfully rejects out-of-distribution noise as per Figure 7.

## Open Questions the Paper Calls Out

**Open Question 1:** How can the ALPHA framework be adapted for dense prediction tasks such as image segmentation and object detection? The authors explicitly state in the conclusion: "Looking ahead, we aim to extend our framework beyond classification to other core visual recognition tasks such as image segmentation and object detection, where label noise remains a significant challenge." The current framework evaluates classification accuracy on image-level embeddings, but dense prediction requires pixel-level or region-level pseudo-labeling and prototype construction.

**Open Question 2:** Can the PICS module be refined to prevent the accidental filtering of informative samples in datasets with high intra-class variability? The authors acknowledge a limitation: "the PICS module's aggressive selectivity may inadvertently filter out informative samples in datasets with high intra-class variability, potentially hindering the model's ability to capture subtle class distinctions." The current mechanism uses a binary indicator function ($\phi > \psi$) to select clean samples, which may struggle with diverse class distributions where valid samples naturally appear distant from the prototype.

**Open Question 3:** To what extent does the quality of the LLM-generated text descriptions impact the robustness of the NALR module? NALR relies on CuPL [21] descriptions to generate pseudo-labels. The paper notes that "mismatches between generated descriptions and the global image view" can occur, necessitating the adaptive weighting, but it assumes the LLM provides useful semantic neighbors. The experiments use a specific LLM setup (CuPL), and it remains untested whether the neighborhood consistency mechanism holds if the LLM descriptions are noisy, sparse, or generated by a weaker model.

## Limitations

- The exact prompt structure and number of LLM-generated descriptions per class (M) remain unspecified beyond "following CuPL style," potentially affecting text prototype quality.
- The cross-class selection strategy (CS, RS, FS) significantly impacts PICS filtering effectiveness, but the paper doesn't provide guidance on when to use each variant.
- The neighbor retrieval mechanism in NALR lacks implementation details (distance metric, exact kNN vs. approximate methods), which could affect consistency weight computation.

## Confidence

**High Confidence:** The core geometric filtering mechanism (PICS) and its theoretical justification are well-established; the accuracy improvements over baselines are clearly demonstrated.

**Medium Confidence:** The NALR semantic refinement mechanism is sound in principle, but the lack of detailed implementation specifications introduces uncertainty about exact behavior.

**Medium Confidence:** The memory bank feedback loop is conceptually valid, but the paper doesn't fully address potential confirmation bias risks when early errors propagate through prototype updates.

## Next Checks

1. **Component Isolation Test:** Run zero-shot CLIP vs. ALPHA-B (baseline w/o PICS/NALR) vs. ALPHA-FS on EuroSAT to quantify the specific contribution of filtering and refinement mechanisms.

2. **Noise Injection Experiment:** Add 50% irrelevant data (e.g., CIFAR-100 samples into CIFAR-10) and verify PICS successfully rejects out-of-distribution samples as claimed in Figure 7.

3. **LLM Prompt Verification:** Test different prompt formulations for generating text descriptions to ensure semantic alignment with visual domains across diverse datasets.