---
ver: rpa2
title: 'RetroMotion: Retrocausal Motion Forecasting Models are Instructable'
arxiv_id: '2505.20414'
source_url: https://arxiv.org/abs/2505.20414
tags:
- trajectories
- motion
- joint
- forecasting
- marginal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RetroMotion, a multi-task learning method
  for motion forecasting that uses retrocausal information flow to improve interaction
  modeling between agents. The method forecasts both marginal trajectory distributions
  for individual agents and joint trajectory distributions for interacting agents.
---

# RetroMotion: Retrocausal Motion Forecasting Models are Instructable

## Quick Facts
- arXiv ID: 2505.20414
- Source URL: https://arxiv.org/abs/2505.20414
- Authors: Royden Wagner; Omer Sahin Tas; Felix Hauser; Marlon Steiner; Dominik Strutz; Abhishek Vivekanandan; Carlos Fernandez; Christoph Stiller
- Reference count: 14
- Primary result: Achieves state-of-the-art 0.2422 mAP on Waymo Interaction Prediction dataset

## Executive Summary
RetroMotion introduces a retrocausal motion forecasting method that predicts both marginal trajectory distributions for individual agents and joint distributions for interacting agent pairs. The model uses a two-stage decoding architecture where marginal trajectories are re-encoded before joint prediction, creating a retrocausal flow of information from later points in marginal trajectories to earlier points in joint trajectories. It achieves state-of-the-art performance on the Waymo Interaction Prediction dataset while also demonstrating the ability to follow goal-based and directional instructions through trajectory modifications. The method uses compressed exponential power distributions to model positional uncertainty, outperforming normal or Laplace distributions alone.

## Method Summary
RetroMotion is a multi-task learning approach that predicts marginal trajectory distributions for individual agents and joint distributions for interacting agent pairs. The architecture consists of a scene encoder that processes polyline inputs (agent history, map, traffic lights) using transformers, followed by two decoders. The marginal decoder predicts K trajectories per agent using learned query anchors, with positional uncertainty modeled as mixtures of normal and Laplace distributions compressed via DCT. The joint decoder re-encodes marginal trajectories through inter-query attention and scene context attention to generate pairwise joint distributions. Training uses negative log-likelihood loss with winner-takes-all assignment, and the model achieves instructability by modifying marginal trajectories before re-encoding.

## Key Results
- Achieves 0.2422 mAP on Waymo Interaction Prediction dataset (state-of-the-art)
- Demonstrates 12% reduction in minFDE when following goal-based instructions
- Shows 20-33% increase in on-road probability (ORP) and 14-22% reduction in overlap rate when adapting directional instructions to scene context
- Outperforms normal and Laplace distributions alone using exponential power distributions with DCT compression

## Why This Works (Mechanism)

### Mechanism 1: Retrocausal Information Flow via Two-Stage Decoding
- Re-encoding marginal trajectories before joint decoding creates a retrocausal pathway where later predicted positions influence earlier joint predictions
- Core assumption: Marginal predictions capture agent intent sufficiently for re-encoding to extract useful interaction signals
- Evidence: Joint decoding significantly improves over raw marginals (Table 1 shows ~30% mAP gap)

### Mechanism 2: Compressed Exponential Power Power Distributions for Uncertainty
- Mixture of normal and Laplace distributions with DCT-compressed location parameters improves forecast accuracy
- Core assumption: Trajectory location parameters are inherently smooth
- Evidence: Exponential power + DCT achieves best mAP (0.195) vs. Laplace alone (0.176) or normal (0.172)

### Mechanism 3: Instructability via Marginal Trajectory Modification
- Modifying marginal trajectories before re-encoding provides interface for goal-based and directional instructions
- Core assumption: Model learns scene-consistent trajectory priors that generalize to novel marginal modifications
- Evidence: Goal-based instructions reduce minFDE by 12%; directional instructions increase ORP by 20-33%

## Foundational Learning

- **Mixture Density Networks (MDN)**: Understanding how to train with negative log-likelihood and winner-takes-all assignment is essential for the model's mixture distribution outputs. Quick check: Can you explain why winner-takes-all (hard assignment) is used instead of soft assignment for multi-trajectory loss?

- **Transformer Attention and Query-Based Decoding**: The scene encoder and joint decoder rely on multi-head attention; queries are learned anchors for trajectory decoding. Quick check: How does inter-query attention differ from standard self-attention, and why does it compress K² combinations to K?

- **Discrete Cosine Transform (DCT) for Sequence Compression**: Location parameters are compressed via IDCT; understanding frequency-domain representation clarifies why smoothing occurs. Quick check: If you retain only the first 16 DCT coefficients for an 80-point trajectory, what type of motion patterns would be preserved vs. lost?

## Architecture Onboarding

- **Component map:**
  - Scene Encoder: Polyline vector inputs → 3-layer MLP embeddings + sinusoidal positional encodings → local agent-centric transformer → cross-attention compression → global scene transformer
  - Marginal Decoder: Scene context → K learned query anchors → MLP heads → (mixture weights, μ, σ, w) per trajectory per timestep → IDCT for location parameters
  - Joint Decoder: Marginal trajectory embeddings → MLP query matrix Q → inter-query attention + scene context attention → pairwise query decoding → joint mixture distributions
  - Loss: Multi-task NLL with λ_marginal weighting; hard assignment selects best trajectory index per agent pair

- **Critical path:**
  1. Scene encoder quality determines downstream fidelity—verify polyline sampling matches dataset preprocessing
  2. Marginal decoder anchors must be learned for best performance; initialize carefully
  3. Joint decoder's softmax temperature τ controls joint confidence aggregation; tune per expert

- **Design tradeoffs:**
  - K trajectories per agent: More trajectories improve multimodal coverage but increase K² joint combinations
  - DCT coefficients: 16 coefficients smooth trajectories but may miss abrupt maneuvers
  - SMoE routing: Rule-based agent-type routing simplifies inference but requires per-expert threshold tuning

- **Failure signatures:**
  - High miss rate on cyclists indicates insufficient multimodal coverage
  - Low ORP suggests map encoding failure or over-aggressive directional instructions
  - Acausal joint forecasts indicate spurious correlation in training data

- **First 3 experiments:**
  1. Reproduce marginal vs. joint gap: Train on Waymo interactive validation; compare marginal-as-joint vs. full joint decoding (expect ~30% mAP gap)
  2. Distribution ablation: Swap exponential power for Laplace-only and normal-only; verify Table 4 trends (expect 1-2% mAP degradation)
  3. Instruction injection test: On Argoverse validation, replace final 1s of marginal trajectories with random goals; measure minFDE change

## Open Questions the Paper Calls Out

### Open Question 1
Can auto-regressive trajectory generation mitigate acausal reactions in retrocausal motion forecasting models? The authors note that instructing a following vehicle to slow down may also slow down a leading vehicle, suggesting data-driven methods can produce physically implausible reactions. Investigating auto-regressive decoding as a mitigation strategy is left to future research.

### Open Question 2
What is the true dimensionality of trajectory feature vectors, and how does it relate to optimal DCT compression? The NRC1 analysis shows feature vectors collapse to a subspace between 32 and 272 dimensions, but the exact dimensionality remains unknown. The paper uses 32 DCT coefficients empirically, but this may not capture all relevant density parameters.

### Open Question 3
Can the instruction-following capability scale beyond pairwise joint modeling to multi-agent scenarios with more than two interacting agents? While the method forecasts motion for up to 8 agents, it only performs pairwise joint modeling for interaction. Whether instructions propagate correctly through chains of pairwise interactions is unexplored.

## Limitations
- The retrocausal mechanism lacks empirical validation of temporal direction of influence
- Instructability has only been demonstrated on synthetic directional instructions, not real human instructions
- Acausal joint predictions suggest the retrocausal framing may be more architectural than theoretically justified

## Confidence
- **High confidence**: Multi-task NLL loss formulation, DCT-based trajectory compression effectiveness, marginal vs. joint performance gap
- **Medium confidence**: Distribution modeling improvements, instruction-following capability on synthetic directions
- **Low confidence**: Retrocausal mechanism explanation, generalization to real human instructions, acausal prediction mitigation

## Next Checks
1. Conduct ablation where marginal trajectories are truncated at different future timesteps to test whether later marginal information truly benefits earlier joint predictions

2. Implement a small user study where human drivers provide natural language instructions to measure whether instruction-following generalizes beyond synthetic quarter-circle turns

3. Design automated test using multi-agent scenarios where only one agent receives an instruction, then measure whether joint predictions show spurious correlations (e.g., leading vehicle slowing when instructed following vehicle slows)