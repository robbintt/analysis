---
ver: rpa2
title: 'Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for
  Metabolic Diseases Based on Chinese Electronic Health Records'
arxiv_id: '2511.06230'
source_url: https://arxiv.org/abs/2511.06230
tags:
- medication
- recommendation
- task
- data
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the CHIP 2025 Shared Task 2, which focused
  on discharge medication recommendation for metabolic diseases using Chinese electronic
  health records. The task involved recommending appropriate medications for patients
  at discharge based on their inpatient records.
---

# Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records

## Quick Facts
- **arXiv ID**: 2511.06230
- **Source URL**: https://arxiv.org/abs/2511.06230
- **Reference count**: 30
- **Key outcome**: Top-performing team achieved Jaccard score of 0.5102 and F1 score of 0.6267 on multi-label discharge medication recommendation from Chinese EHRs.

## Executive Summary
This paper presents the CHIP 2025 Shared Task 2, which focused on discharge medication recommendation for metabolic diseases using Chinese electronic health records. The task involved recommending appropriate medications for patients at discharge based on their inpatient records. A dataset of 5,894 de-identified hospitalization records from 3,190 patients was constructed for this purpose. The task was challenging due to the multi-label nature of medication recommendation, heterogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered for the competition, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102 and an F1 score of 0.6267. These results demonstrate the potential of advanced large language model (LLM)-based ensemble systems for discharge medication recommendation in Chinese EHRs.

## Method Summary
The task involved multi-label discharge medication recommendation from Chinese EHRs, where models needed to predict a subset of 651 candidate drugs per patient visit. The CDrugRed dataset comprised 5,894 visits from 3,190 patients, with fields including demographics, BMI, clinical course, admission condition, history, chief complaint, and discharge diagnoses. The data was split 6:1:3 (3,602/570/1,722 visits) by patient. Models were evaluated using Jaccard and macro F1 scores over predicted versus ground-truth drug sets, with final ranking score as their average. The baseline approach involved supervised fine-tuning (SFT) of GLM4-9B-Chat with LoRA (rank=8, alpha=16, lr=1e-4, batch_size=1, grad_accum=4, epochs=10), using concatenated EHR fields as input and medication lists as output. Maximum model size was limited to 10B parameters, with external resources allowed if declared.

## Key Results
- 526 teams registered, with 167 and 95 submitting valid results to Phase A and B leaderboards
- Top team achieved Jaccard score of 0.5102 and F1 score of 0.6267 on final test set
- Demonstrated potential of LLM-based ensemble systems for discharge medication recommendation
- Highlighted challenges including multi-label nature, heterogeneous clinical text, and patient-specific variability

## Why This Works (Mechanism)
The approach leverages large language models fine-tuned on clinical discharge data to capture complex patterns in patient history, clinical course, and discharge diagnoses that inform medication decisions. The multi-label nature is addressed through constrained generation over a predefined candidate drug set, while ensemble methods improve robustness across diverse patient presentations.

## Foundational Learning
- **Chinese EHR processing**: Understanding Chinese clinical text structure and medical terminology is essential for effective model training and evaluation. Quick check: Verify Chinese text tokenization and medical entity recognition accuracy.
- **Multi-label classification**: Discharge medication recommendation requires predicting multiple drugs simultaneously, necessitating specialized loss functions and evaluation metrics. Quick check: Confirm model handles label co-occurrence patterns appropriately.
- **LoRA fine-tuning**: Low-Rank Adaptation enables efficient fine-tuning of large models while preserving performance, critical for resource-constrained scenarios. Quick check: Monitor training stability and convergence with LoRA.
- **Constrained generation**: Restricting output to a predefined drug candidate set ensures clinically valid recommendations and manageable evaluation. Quick check: Verify all generated medications are within the 651-drug candidate list.
- **Ensemble methods**: Combining multiple model predictions improves overall performance by reducing individual model biases. Quick check: Test ensemble diversity and correlation metrics.

## Architecture Onboarding

**Component map**: EHR text fields -> LLM fine-tuning -> Medication prediction -> Evaluation (Jaccard/F1)

**Critical path**: Data preprocessing → Model fine-tuning → Constrained generation → Metric computation

**Design tradeoffs**: 
- Trade accuracy for computational efficiency by limiting model size to 10B parameters
- Balance recall and precision through ensemble methods versus single model performance
- Prioritize coverage of common medications over rare drug prediction due to label imbalance

**Failure signatures**: 
- Generating medications outside the candidate list indicates insufficient constraint enforcement
- Poor performance on rare medications suggests inadequate handling of label imbalance
- Inconsistent predictions across similar patient profiles may indicate overfitting to training distribution

**3 first experiments**:
1. Re-run baseline LoRA fine-tuning on Train/Val/Test splits to verify reported metrics
2. Test constrained generation by attempting to generate medications outside the 651-drug set
3. Evaluate per-label performance to identify rare medication prediction challenges

## Open Questions the Paper Calls Out
1. **Complete medication regimens**: How can LLMs be adapted to generate complete medication regimens including dosage, frequency, and administration instructions rather than just drug names? The current dataset and evaluation only assess name overlap, not clinical parameters.
2. **Multi-modal data incorporation**: To what extent does incorporating medical imaging and laboratory results improve performance over text-only inputs? Current study uses only text-based EHR fields, leaving potential benefits of multi-modal approaches unexplored.
3. **Cross-institutional generalization**: What domain adaptation techniques ensure models generalize across different hospital systems? Current dataset comes from a single tertiary hospital, potentially limiting real-world applicability.
4. **Label imbalance mitigation**: Which strategies most effectively improve prediction accuracy for rare medications? Despite ensemble approaches, moderate F1 scores suggest ongoing challenges with the long-tail of infrequent drugs.

## Limitations
- Evaluation based on competition results rather than clinical deployment outcomes
- Single Chinese medical corpus with limited temporal validation
- Unverified generalizability to other clinical domains or languages
- Specific Chinese instruction template and drug list not fully accessible for reproduction

## Confidence
- **High confidence**: Task definition, dataset construction, and evaluation framework are clearly described
- **Medium confidence**: Baseline approach and hyperparameters are specified, but exact test performance is unreported
- **Medium confidence**: Claims about LLM potential are supported by results but lack clinical validation

## Next Checks
1. Obtain and validate the complete Chinese instruction template and 651-candidate drug list
2. Re-run LoRA fine-tuning baseline to verify competition metrics and establish benchmark
3. Test trained model on external metabolic disease discharge dataset for generalizability assessment