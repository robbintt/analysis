---
ver: rpa2
title: Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category
  Information Amount
arxiv_id: '2502.03852'
source_url: https://arxiv.org/abs/2502.03852
tags:
- category
- information
- amount
- igam
- categories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of category bias in object detection,
  where models underperform on certain categories even in balanced datasets. The authors
  introduce the concept of "category information amount," which quantifies the diversity
  of instances within a category.
---

# Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount

## Quick Facts
- **arXiv ID:** 2502.03852
- **Source URL:** https://arxiv.org/abs/2502.03852
- **Reference count:** 18
- **Primary result:** Introduces IGAM Loss to address category bias in object detection by dynamically adjusting decision boundaries based on category information amount.

## Executive Summary
This paper addresses the problem of category bias in object detection, where models underperform on certain categories even in balanced datasets. The authors introduce the concept of "category information amount," which quantifies the diversity of instances within a category. They find a strong negative correlation between category information amount and accuracy, suggesting that categories with higher information amounts are harder to learn. To address this issue, the authors propose Information Amount-Guided Angular Margin (IGAM) Loss, which dynamically adjusts the decision space of each category based on its information amount.

## Method Summary
The method introduces Information Amount-Guided Angular Margin (IGAM) Loss, which dynamically adjusts per-class decision spaces based on category information amount. IGAM computes pairwise angular margins between classes using the ratio of their normalized information amounts, expanding decision space for high-IA categories and compressing it for low-IA categories. To efficiently update information amounts during training, the authors introduce a low-cost, end-to-end strategy that aggregates local covariance matrices within an epoch and combines them into a global covariance, significantly reducing storage requirements compared to storing all instance embeddings.

## Key Results
- IGAM Loss achieves state-of-the-art performance on LVIS v1.0 and COCO-LT, particularly improving accuracy on rare categories.
- On Pascal VOC, IGAM significantly outperforms other methods on underrepresented categories, demonstrating its effectiveness in reducing model bias.
- The proposed method shows a strong negative correlation (Pearson correlation ~-0.66 to -0.70) between category information amount and per-class AP.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Category information amount (IA) correlates more strongly with detection difficulty than instance count alone.
- **Mechanism:** IA quantifies intra-category feature diversity via the volume of the perceptual manifold in the embedding space. Categories with higher IA exhibit larger spread in their embeddings, which the paper argues increases learning complexity.
- **Core assumption:** The determinant of the (shrinkage-regularized) covariance matrix of category embeddings is a valid proxy for the perceptual manifold volume and thus for learning difficulty.
- **Evidence anchors:** [abstract] Reports "a strong negative correlation between category information amount and accuracy"; [section] Table 1 shows Pearson correlations around -0.66 to -0.70 between IA and AP on LVIS v1.0 and COCO-LT.
- **Break condition:** If IA does not exhibit consistent negative correlation with per-category AP across diverse detection architectures or datasets, the utility of IA as a difficulty proxy is undermined.

### Mechanism 2
- **Claim:** Dynamically adjusting per-class decision space via information amount-guided angular margins reduces category bias.
- **Mechanism:** IGAM modifies the angular margin mij between class i and j based on the normalized IA ratio. When class i has higher IA than j, mij becomes positive, expanding i's decision space; when lower, mij is negative, compressing i's space. This rebalances capacity allocation according to measured difficulty.
- **Core assumption:** Decision space allocation should reflect information amount rather than enforcing equal space; the model can exploit larger spaces for complex categories without explicit extra supervision.
- **Evidence anchors:** [abstract] States IGAM Loss "dynamically adjusts the decision space of each category based on its information amount"; [section] Equation (6) defines the IGAM objective with margin mij = max(0, 1/π * log(I'_i / I'_j)).
- **Break condition:** If expanding decision space for high-IA categories fails to improve or degrades their AP (or harms low-IA categories disproportionately), the margin formulation may be mis-specified.

### Mechanism 3
- **Claim:** A low-cost end-to-end training strategy enables dynamic IA updates without prohibitive memory overhead.
- **Mechanism:** Instead of storing all instance embeddings, the method aggregates local covariance matrices within an epoch and combines them into a global covariance (via global mean and per-batch means). This reduces storage compared to storing N embeddings directly.
- **Core assumption:** Feature embeddings evolve slowly enough that combining locally estimated covariances yields a sufficiently accurate global covariance at epoch boundaries.
- **Evidence anchors:** [abstract] Mentions a "low-cost, end-to-end training strategy that significantly reduces storage space requirements"; [section] Equations (7–8) and Listing 2 describe the aggregation procedure and storage analysis; claims ~56–74% memory savings in examples.
- **Break condition:** If aggregated covariances yield IA estimates that diverge from those computed from full embeddings, or if the update strategy destabilizes training, the efficiency-accuracy tradeoff may not hold.

## Foundational Learning

- **Concept:** Angular margin softmax basics
  - **Why needed here:** IGAM extends cosine-based classification with per-class angular margins. Understanding how margin m affects the decision boundary angle (e.g., larger margin → tighter class clustering) is essential to interpret mij.
  - **Quick check question:** In a 2D angular margin softmax with s fixed, does increasing the margin for class A expand or contract the angular region confidently classified as A?

- **Concept:** Covariance estimation in high-dimensional spaces
  - **Why needed here:** IA is derived from the determinant of a regularized covariance matrix of embeddings. Shrinkage (Ledoit–Péché) stabilizes estimation when the number of samples is comparable to or smaller than dimensionality.
  - **Quick check question:** Why can the sample covariance become poorly conditioned when p (embedding dimension) is large relative to m (instances per class)?

- **Concept:** Long-tailed recognition fundamentals
  - **Why needed here:** Provides context on why instance-count-based reweighting alone may not suffice and how decision-boundary methods (e.g., weight-norm balancing) relate to IGAM's margin approach.
  - **Quick check question:** In a binary linear classifier, if the weight norm of class 1 is much larger than class 2, which class tends to occupy a larger decision region for the same angular margin?

## Architecture Onboarding

- **Component map:** Backbone detector (e.g., Faster R-CNN) -> RoI features and classification logits -> IGAM Loss with per-class margins from IA -> IA Module (extract embeddings, compute covariances, calculate IA) -> Dynamic margin updates per epoch

- **Critical path:**
  1. Extract embeddings from the classification branch for each RoI.
  2. Accumulate embeddings in fixed-size queue; compute local covariances/means per class.
  3. At epoch end, aggregate into global covariance per class and compute IA.
  4. Normalize IA; compute margins mij.
  5. Apply IGAM Loss with these margins in the next epoch.

- **Design tradeoffs:**
  - Queue length d vs memory: Larger d reduces the number of local covariance chunks but increases memory; the paper provides an R-ratio analysis to select d.
  - Embedding dimension p: Higher p improves expressiveness but makes covariance estimation harder and increases storage for Σ matrices.
  - Update frequency: Per-epoch updates balance freshness with cost; more frequent updates could improve responsiveness at higher overhead.

- **Failure signatures:**
  - IA estimates fluctuating sharply between epochs, causing unstable margins.
  - Numerical issues (negative determinants or NaNs) when estimating Σ_i due to insufficient samples or high p.
  - Degraded AP on frequent classes if margins over-expand rare-class spaces.

- **First 3 experiments:**
  1. Baseline sanity check: Train with standard CE on LVIS v1.0 (R-50-FPN, Faster R-CNN); record overall AP, APr, APc, APf. Then replace CE with IGAM using the paper's hyperparameters (s=30) and compare.
  2. IA correlation analysis: For each class, compute IA at the end of training and plot against per-class AP; compute Pearson correlation and verify it is strongly negative per the paper's claim.
  3. Storage vs accuracy ablation: Vary queue length d (e.g., 10k, 30k, 50k) and measure memory usage vs AP; check if the low-cost update strategy preserves AP relative to a full-embedding baseline (if feasible to implement).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What additional factors beyond category information amount contribute to model bias in object detection?
- **Basis in paper:** [explicit] The conclusion explicitly invites future work: "We encourage other researchers to explore additional potential factors influencing model bias, aiming to design more equitable object detection models."
- **Why unresolved:** While the paper establishes information amount as a superior predictor of difficulty compared to instance count, it does not claim it is the sole cause of bias, leaving other potential causes unidentified.
- **What evidence would resolve it:** Isolating new variables (e.g., shape complexity, background clutter) that correlate with class-wise AP independently of information amount.

### Open Question 2
- **Question:** Can applying information amount-guided margins to the regression branch improve localization performance?
- **Basis in paper:** [explicit] The methodology states: "the embeddings used to calculate the information amount should be extracted from the classification module of the object detection model, not the regression module."
- **Why unresolved:** The current study addresses bias in classification, but it explicitly excludes the regression module, leaving the impact of intra-class geometric diversity on bounding box prediction unexplored.
- **What evidence would resolve it:** Modifying the regression loss to incorporate information amount and measuring changes in localization metrics (e.g., AP75, AP90) on complex categories.

### Open Question 3
- **Question:** How robust is the low-cost covariance approximation strategy when applied to datasets with significantly fewer instances per category?
- **Basis in paper:** [inferred] The authors propose a strategy to merge local covariance matrices to save memory, setting a queue length d=50,000 to handle large datasets like LVIS.
- **Why unresolved:** The efficacy of this approximation relies on sufficient sampling; it is unclear if this method remains accurate for "rare" categories with extremely few instances (1-10 images), potentially leading to noisy margin updates.
- **What evidence would resolve it:** Analyzing the variance of the estimated information amount for rare categories under different queue lengths.

## Limitations

- The correlation between category information amount and detection difficulty lacks external validation in the broader detection literature.
- The effectiveness of the IA-guided angular margin mechanism depends critically on the accuracy of IA estimation and the appropriateness of expanding decision space for high-IA categories.
- Key implementation details for embedding extraction, IA normalization, and multi-scale jittering remain underspecified, potentially affecting reproducibility.

## Confidence

- **High Confidence:** The paper's experimental results on LVIS v1.0 and COCO-LT showing IGAM's superiority over baseline methods and its improvement on rare categories are well-documented and reproducible given the specified hyperparameters.
- **Medium Confidence:** The claim that IA correlates strongly with detection difficulty is supported by the paper's correlation analysis but lacks external validation.
- **Low Confidence:** The effectiveness of the IA-guided angular margin mechanism and the low-cost training strategy's storage-accuracy tradeoff cannot be independently verified without access to the full implementation details.

## Next Checks

1. **External IA-Difficulty Correlation:** Reproduce the correlation analysis on a different long-tailed detection dataset or architecture to validate whether IA consistently correlates with detection difficulty beyond the paper's datasets.

2. **Margin Sensitivity Analysis:** Systematically vary the angular margin scaling (s parameter) and evaluate its impact on AP across different IA groups to test the sensitivity and robustness of the IA-guided margin mechanism.

3. **Storage vs Accuracy Trade-off:** Implement both the low-cost covariance aggregation strategy and a full-embedding baseline, then measure the actual memory savings and AP difference across multiple queue lengths (d) to validate the claimed efficiency-accuracy tradeoff.