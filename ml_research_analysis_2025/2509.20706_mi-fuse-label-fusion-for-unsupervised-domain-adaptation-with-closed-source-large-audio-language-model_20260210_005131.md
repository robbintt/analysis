---
ver: rpa2
title: 'MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source
  Large-Audio Language Model'
arxiv_id: '2509.20706'
source_url: https://arxiv.org/abs/2509.20706
tags:
- lalm
- teacher
- domain
- emotion
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MI-Fuse enables adaptation of speech emotion recognition systems
  to new domains using only unlabeled target data and a closed-source large audio-language
  model (LALM) through a denoised label fusion approach. It combines the LALM with
  a source-domain trained classifier, leveraging mutual-information-based uncertainty
  weighting and an exponential moving average teacher to stabilize training and suppress
  noisy pseudo-labels.
---

# MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model

## Quick Facts
- arXiv ID: 2509.20706
- Source URL: https://arxiv.org/abs/2509.20706
- Reference count: 0
- Primary result: MI-Fuse achieves 3.9% accuracy gain over strongest baseline in cross-domain speech emotion recognition adaptation

## Executive Summary
MI-Fuse addresses source-free unsupervised domain adaptation (SFUDA) for speech emotion recognition by fusing predictions from a closed-source Large Audio-Language Model (LALM) and a source-domain trained classifier. The method uses mutual information-based uncertainty weighting to suppress noisy pseudo-labels and an exponential moving average teacher to stabilize training. Experiments on three emotion datasets and six cross-domain transfers show consistent improvements over both individual teachers and existing SFUDA baselines, achieving a 3.9% accuracy gain over the strongest baseline. The approach enables practical, privacy-compliant emotion-aware speech systems without sharing source data.

## Method Summary
MI-Fuse adapts speech emotion recognition systems to new domains using only unlabeled target data and a closed-source LALM through denoised label fusion. The framework combines WavLM base+ backbone with 2 linear layers, using Gemini 2.5 flash (temperature 0.6) as the LALM. For each unlabeled target sample, the system performs 5 stochastic LALM queries and 8 MC dropout passes through the classifier, computing mutual information to weight predictions. The fused pseudo-labels train a student model initialized from the classifier teacher, with EMA updates (α=0.999) stabilizing the teacher and a diversity loss preventing class collapse. The method operates within the SFUDA constraint, requiring no access to source data during adaptation.

## Key Results
- MI-Fuse achieves 58.38% average accuracy across six cross-domain transfers, outperforming LALM SFUDA (54.48%) and Source model SFUDA (51.01%)
- MI-based uncertainty weighting (59.09%, 57.07%) significantly outperforms entropy weighting (57.34%, 55.53%) and equal weighting (57.98%, 56.64%)
- The framework shows steady accuracy improvement during training while classifier-teacher-only baseline declines after ~400 steps

## Why This Works (Mechanism)

### Mechanism 1: Mutual Information-Based Uncertainty Weighting
MI weighting suppresses noisy pseudo-labels by down-weighting predictions with high epistemic uncertainty. For each sample, K stochastic passes through teachers compute MI(Y,Θ|x) = H(p̄) - (1/K)ΣH(p_k), capturing prediction variability. High MI signals unreliable predictions under domain shift. Evidence shows MI weighting outperforms simpler strategies in Table 2. Break condition: If teachers are systematically wrong, MI will amplify errors.

### Mechanism 2: Exponential Moving Average Teacher Stabilization
EMA updates (θ_cls ← 0.999·θ_cls + 0.001·θ_tgt) provide smooth supervision by filtering short-term noise while allowing teacher evolution with improving student. This temporal averaging prevents accuracy drops seen in classifier-only baselines. Standard in semi-supervised learning but novel for LALM fusion. Break condition: If student drifts to poor local minima early, EMA propagates errors.

### Mechanism 3: Complementary Dual-Teacher Fusion
Combining LALM's zero-shot generalization with classifier's source-domain structure yields better target performance than either alone. MI-weighted fusion dynamically selects the more reliable teacher per-sample, assuming independent errors. Table 1 shows MI-Fuse outperforming single-teacher variants. Break condition: If both teachers are confidently wrong on same samples, fusion amplifies errors.

## Foundational Learning

- **Concept: Mutual Information as Epistemic Uncertainty**
  - Why needed here: MI separates model uncertainty from data ambiguity, signaling where model extrapolates beyond training under domain shift
  - Quick check question: Given predictions [0.7, 0.3], [0.65, 0.35], [0.72, 0.28] vs. [0.9, 0.1], [0.5, 0.5], [0.6, 0.4], which has higher MI and why?

- **Concept: Source-Free Unsupervised Domain Adaptation (SFUDA)**
  - Why needed here: Real-world deployment often cannot share source data (privacy, ownership), defining the constraint space MI-Fuse operates within
  - Quick check question: Why can't we use standard domain adaptation techniques (e.g., DANN, MMD) in the SFUDA setting?

- **Concept: Pseudo-Labeling with Confidence Thresholding**
  - Why needed here: MI-Fuse builds on pseudo-labeling but replaces fixed confidence thresholds with uncertainty-aware fusion
  - Quick check question: What happens to a student model trained on pseudo-labels when the source teacher has 40% accuracy on the target domain?

## Architecture Onboarding

- **Component map:**
  LALM Teacher (API) → K stochastic passes → mean p̄_LM → MI_LM → [MI-weighted fusion] → Student f_tgt ← Cross-entropy
  Classifier Teacher → MC dropout → mean p̄_cls → MI_cls → [MI-weighted fusion] ← Diversity loss
  EMA update ← Student f_tgt

- **Critical path:**
  1. Initialize student with classifier teacher weights
  2. Query LALM 5 times, run classifier with 8 MC dropout passes
  3. Compute MI for each teacher, fuse via exp(-MI) weights
  4. Train student with L = L_CE + λ_div·L_div
  5. Update classifier teacher via EMA (α=0.999)

- **Design tradeoffs:**
  - N_LM=5, N_cls=8: More passes improve MI estimation but increase cost
  - α=0.999: Higher stability vs. slower adaptation to improving student
  - λ_div=1: Prevents collapse but may over-regularize on imbalanced targets
  - Assumption: LALM temperature=0.6 provides meaningful stochasticity

- **Failure signatures:**
  - Accuracy drops after initial improvement: Check if EMA teacher propagates errors
  - Class collapse: Increase λ_div or check diversity loss computation
  - Fusion underperforms single-teacher: Verify MI values capture meaningful variation
  - API rate limits: Reduce N_LM or implement caching

- **First 3 experiments:**
  1. Reproduce ablation: MI-Fuse vs. entropy-weighting vs. equal-weighting on two transfers
  2. Single-teacher baseline: Train student with only LALM or only classifier pseudo-labels
  3. MI sensitivity analysis: Vary N_LM and N_cls to determine cost-effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
Can the MI-Fuse framework be extended to handle heterogeneous label spaces where source and target taxonomies differ? The current methodology assumes aligned output dimensions between teachers and student. Evidence needed: Successful adaptation when source trained on subset of classes while target requires different or superset classes.

### Open Question 2
How does high inference cost and latency of querying closed-source LALMs affect practical viability in low-resource scenarios? The method requires 5 LALM API calls per sample. Evidence needed: Trade-off analysis between LALM queries and accuracy, or successful application using lower-latency models.

### Open Question 3
Is effectiveness dependent on Gemini 2.5's specific architecture or reasoning capabilities? The methodology specifies Gemini 2.5 flash but results may be sensitive to this model's zero-shot capabilities. Evidence needed: Ablation studies using alternative LALMs to determine if gains remain consistent.

### Open Question 4
Can this denoised label fusion approach be successfully applied to other speech processing tasks with structured outputs? The experimental scope is restricted to SER despite potential for universal speech processing applications. Evidence needed: Experiments applying MI-Fuse to speaker verification or spoken language understanding tasks.

## Limitations

- The label fusion scheme assumes fixed discrete emotion categories across datasets, limiting applicability when taxonomies vary
- High inference cost, latency, and reliance on proprietary APIs may hinder practical deployment in resource-constrained settings
- Effectiveness may depend on specific architecture or reasoning capabilities of the chosen LALM model

## Confidence

- **High confidence**: MI-Fuse consistently outperforms both individual teachers and existing SFUDA baselines across all tested cross-domain transfers
- **Medium confidence**: MI-based uncertainty weighting is optimal fusion strategy (small performance differences, no comparison to alternatives)
- **Medium confidence**: EMA teacher stabilization is critical for preventing accuracy degradation (alternative smoothing approaches not explored)
- **Low confidence**: Dual-teacher fusion is strictly necessary (complementary errors not analyzed)

## Next Checks

1. Implement and compare MI-Fuse against simpler fusion approaches including confidence-thresholded pseudo-labeling, temperature-scaled averaging, and attention-based fusion

2. Analyze per-sample prediction disagreements between LALM and classifier teachers, categorizing errors by emotion class, confidence, and domain similarity

3. Vary the number of LALM API calls (N_LM ∈ {1,3,5,10}) and temperature parameter (0.3-1.0) to quantify sensitivity to LALM stochasticity and determine minimum API calls required for stable performance