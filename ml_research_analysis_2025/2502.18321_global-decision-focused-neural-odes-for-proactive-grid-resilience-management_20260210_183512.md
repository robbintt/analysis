---
ver: rpa2
title: Global-Decision-Focused Neural ODEs for Proactive Grid Resilience Management
arxiv_id: '2502.18321'
source_url: https://arxiv.org/abs/2502.18321
tags:
- power
- outage
- neural
- cost
- grid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a global-decision-focused (GDF) neural ODE
  model to address the limitations of traditional predict-then-optimize (PTO) approaches
  in proactive grid resilience management. While PTO frameworks generate forecasts
  independently of downstream optimization, leading to misaligned and suboptimal decisions,
  GDF integrates outage prediction with globally optimized interventions.
---

# Global-Decision-Focused Neural ODEs for Proactive Grid Resilience Management

## Quick Facts
- arXiv ID: 2502.18321
- Source URL: https://arxiv.org/abs/2502.18321
- Reference count: 40
- Primary result: Reduces decision regret by up to 75% compared to two-stage baselines while maintaining predictive accuracy

## Executive Summary
This paper introduces a global-decision-focused (GDF) neural ODE framework that integrates outage prediction with globally optimized interventions for proactive grid resilience management. Unlike traditional predict-then-optimize approaches that generate forecasts independently of downstream decisions, GDF jointly trains predictions with the optimization objective to reduce operational regret. The model uses a dynamical system inspired by epidemiological SIR models to capture spatio-temporal outage dynamics, parameterized by neural networks. Experiments on synthetic and real-world datasets demonstrate significant improvements in decision quality while maintaining predictive accuracy.

## Method Summary
The GDF framework combines a compartmental Neural ODE (SIR-inspired structure) for outage prediction with a differentiable optimization layer for resource allocation decisions. The ODE models each service unit's transition through Unaffected (U), Outaged (Y), and Restored (R) compartments with neural-parameterized transition rates. During training, gradients flow backward through both the ODE solver and the optimization solution via KKT differentiation, aligning predictions with decision objectives. The method is validated on two grid resilience tasks: mobile generator deployment and power line undergrounding, showing up to 75% reduction in decision regret compared to two-stage baselines.

## Key Results
- GDF reduces decision regret by up to 75% compared to two-stage baselines while maintaining predictive accuracy
- Neural ODE achieves lower MSE with only 1,986 parameters versus 12,673+ for RNN/LSTM baselines
- Real-world validation on 2018 Nor'easter in Massachusetts demonstrates effectiveness of undergrounding decisions in high-risk counties

## Why This Works (Mechanism)

### Mechanism 1: Decision-Focused Gradient Alignment
Jointly training predictions with the downstream decision objective reduces operational regret by aligning model parameters with decision quality rather than prediction accuracy alone. Traditional predict-then-optimize trains models to minimize MSE, which ignores how prediction errors propagate into decisions. The GDF loss combines a global-decision-focused term that directly measures decision suboptimality with a prediction regularization term. Gradients flow backward through the optimization solution via differentiable optimization, adjusting the Neural ODE parameters to improve decisions—not just predictions. The core assumption is that the downstream optimization can be relaxed to a differentiable form (quadratic regularization for MILPs) so that gradients can propagate through `argmin`.

### Mechanism 2: Compartmental Neural ODE for Outage Dynamics
An SIR-inspired compartmental structure captures failure and restoration dynamics with far fewer parameters than generic sequence models, improving generalization under data scarcity. Each service unit is modeled with three compartments: Unaffected (U), Outaged (Y), and Restored (R). The transition rates are parameterized by neural networks taking local weather and socioeconomic covariates as input. The ODE dynamics enforce mass conservation (U + Y + R = N), providing inductive bias that matches the physical process. The core assumption is that outages propagate primarily through local transmission-line failures rather than cascading across units; each unit evolves independently given local conditions.

### Mechanism 3: Global Spatial-Temporal Optimization Coupling
Aggregating predictions across all service units into a single optimization problem prevents localized misallocation and ensures spatially coherent decisions. The PATOG framework predicts outage trajectories for all K units simultaneously, then solves a single global optimization over all units and time steps. The GDF loss aggregates decision regret across all units, penalizing predictions that lead to globally suboptimal resource allocation even if local MSE is low. The core assumption is that the decision problem has a known, fixed structure with constraints independent of uncertain parameters.

## Foundational Learning

- **Neural Ordinary Differential Equations:** Needed to understand how continuous dynamics are discretized and how gradients flow through ODE solvers. Quick check: Can you explain why the Neural ODE can extrapolate better than an RNN for a system governed by conservation laws?
- **Decision-Focused Learning / Differentiable Optimization:** Needed to understand how to backpropagate through optimization solutions. Quick check: If the optimization is a MILP, how does adding a small quadratic term enable gradient computation?
- **Mixed-Integer Linear Programming (MILP) for Resource Allocation:** Needed to understand constraint formulation and objective design. Quick check: In the generator deployment problem, what does constraint (13) enforce and why is it necessary?

## Architecture Onboarding

- **Component map:** Covariates z_k -> Rate MLPs -> ODE integrator -> Optimization layer -> Loss computation -> Gradient updates to rate network parameters
- **Critical path:** Covariates → Rate MLPs → ODE rollout (predicted trajectories Ŝ) → Optimization solver (x*) → Loss evaluation → Gradient updates to θ_U, θ_R. The ODE rollout is the computational bottleneck for long horizons.
- **Design tradeoffs:** λ (prediction vs. decision weight): Low λ prioritizes decision quality at potential MSE cost; high λ reverts toward two-stage behavior. ODE solver choice: Euler is fastest but least accurate; RK4 is standard. Pretraining strategy: Pretraining with MSE loss stabilizes training; fine-tuning with GDF loss adds decision alignment.
- **Failure signatures:** MSE improves but regret worsens (classic PTO misalignment); exploding gradients in ODE rollout (check rate network outputs and time step); infeasible MILP solutions during training (increase quadratic regularization).
- **First 3 experiments:** 1) Synthetic ablation (K=3 units, W=1 warehouse) to verify GDF reduces regret vs. two-stage; 2) Parameter efficiency comparison between Neural ODE, RNN, and LSTM on identical data; 3) Real dataset sanity check (Nor'easter, MA) to verify predictions are physically plausible and decisions prioritize high-risk counties.

## Open Questions the Paper Calls Out
- How can stochastic transportation and travel-time uncertainties be integrated into the GDF decision layer?
- Does the assumption of independent unit evolution limit predictive accuracy during transmission-level cascading failures?
- Can the GDF framework be extended to handle decision constraints that depend on the uncertain predicted parameters?

## Limitations
- The SIR-inspired compartmental structure assumes outages propagate independently within units, which may not hold for cascading failures across the grid
- The differentiable optimization approach relies on quadratic regularization of MILPs, which may not scale well to large, complex grid optimization problems
- Real-world validation is limited to one weather event (2018 Nor'easter in Massachusetts), raising questions about performance across different extreme weather types and grid topologies

## Confidence
- **High confidence:** The core claims about decision-focused neural ODEs reducing operational regret by up to 75% for the specific decision tasks and datasets tested
- **Medium confidence:** Generalizability to broader grid topologies, different extreme weather types, and scalability to larger grids with hundreds of service units
- **Low confidence:** Performance in scenarios with significant cascading failures or when decision constraints depend on uncertain parameters

## Next Checks
1. Test GDF performance on a second extreme weather event dataset with different failure patterns to assess robustness
2. Compare against a coupled ODE model that captures inter-unit dependencies to quantify the cost of the independence assumption
3. Evaluate scalability by testing the approach on synthetic grids with 50+ service units and measuring MILP solve times during training