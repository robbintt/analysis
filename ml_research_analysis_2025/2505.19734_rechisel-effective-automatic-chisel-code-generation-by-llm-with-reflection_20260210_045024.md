---
ver: rpa2
title: 'ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection'
arxiv_id: '2505.19734'
source_url: https://arxiv.org/abs/2505.19734
tags:
- code
- chisel
- llms
- verilog
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of generating correct Chisel\
  \ code using large language models (LLMs), a task hindered by Chisel\u2019s relatively\
  \ recent introduction and limited training data compared to Verilog. The authors\
  \ propose ReChisel, an LLM-based agentic system that improves Chisel code generation\
  \ through a reflection mechanism."
---

# ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection

## Quick Facts
- arXiv ID: 2505.19734
- Source URL: https://arxiv.org/abs/2505.19734
- Reference count: 38
- Primary result: ReChisel improves Chisel code generation success rates to match state-of-the-art Verilog systems

## Executive Summary
This paper addresses the challenge of generating correct Chisel code using large language models (LLMs), a task hindered by Chisel's relatively recent introduction and limited training data compared to Verilog. The authors propose ReChisel, an LLM-based agentic system that improves Chisel code generation through a reflection mechanism. ReChisel iteratively refines generated code by incorporating feedback from compilation and simulation processes to correct errors. An escape mechanism is introduced to prevent non-progress loops during the reflection process. Experiments across three benchmarks and five mainstream LLMs show that ReChisel significantly improves success rates, achieving performance comparable to state-of-the-art LLM-based systems for Verilog code generation. The results highlight the potential of Chisel for LLM-assisted hardware design.

## Method Summary
ReChisel is an LLM-based agentic system designed to automatically generate Chisel code from natural language specifications. The system employs a multi-agent workflow consisting of Generator (produces initial code), Compiler (compiles Chisel to FIRRTL to Verilog), Simulator (runs testbenches), Inspector (tracks iteration history), and Reviewer (creates revision plans). The key innovation is the reflection mechanism, which iteratively refines code based on feedback from compilation and simulation errors. An escape mechanism prevents non-progress loops by detecting repeated errors at the same location. The system operates for a maximum of 10 iterations, using in-context learning with common error patterns. Experiments evaluate five mainstream LLMs (GPT-4 Turbo, GPT-4o, GPT-4o mini, Claude 3.5 Sonnet/Haiku) across three benchmark datasets totaling 216 test cases.

## Key Results
- ReChisel achieves Pass@1 success rates comparable to state-of-the-art Verilog generation systems
- Iterative reflection significantly improves code quality, with performance plateauing after approximately 4 iterations
- Escape mechanism effectively prevents non-progress loops during code refinement
- Syntax errors are resolved quickly, while functional errors require more iterations to fix

## Why This Works (Mechanism)
The reflection mechanism works by treating compilation and simulation feedback as structured error reports that guide iterative code refinement. The system treats Chisel's intermediate compilation to FIRRTL and Verilog as a form of automated verification, providing concrete feedback about both syntactic validity and functional correctness. The escape mechanism prevents infinite loops by tracking error patterns across iterations, while the Inspector component maintains iteration history to inform the Reviewer's revision strategy. This creates a closed-loop system where each iteration produces more refined code until either success or maximum iterations are reached.

## Foundational Learning
- Chisel compilation pipeline (Chisel→FIRRTL→Verilog): Why needed - provides structured error feedback; Quick check - verify FIRRTL compiler produces Verilog output
- Testbench-driven simulation: Why needed - validates functional correctness; Quick check - confirm DUT-reference comparison logic
- Pass@k metrics: Why needed - measures success across multiple attempts; Quick check - calculate success rates for k=1,5,10
- Escape mechanism for loop detection: Why needed - prevents infinite refinement cycles; Quick check - test with synthetic non-progress dataset
- In-context learning with error patterns: Why needed - guides LLM toward common fixes; Quick check - verify error knowledge base examples

## Architecture Onboarding

**Component map:** Natural Language Spec → Generator → Chisel Code → Compiler → Verilog → Simulator → Test Results → Inspector → Reviewer → Revision Plan → Generator (iterative)

**Critical path:** Generator → Compiler → Simulator → Reviewer → Generator

**Design tradeoffs:** Reflection vs. one-shot generation (accuracy vs. latency); maximum iterations (completeness vs. resource usage); escape mechanism sensitivity (prevention vs. premature termination)

**Failure signatures:** Non-progress loops (repeated syntax errors at same location); reintroduced syntax errors (functional fixes break previous syntax corrections); plateauing performance (inherent LLM limitations)

**3 first experiments:**
1. Run ReChisel on a simple adder specification to verify basic compilation and simulation pipeline
2. Test escape mechanism by creating a synthetic case that triggers repeated syntax errors
3. Compare baseline LLM output (n=0) against ReChisel output (n=10) on a moderate-complexity circuit

## Open Questions the Paper Calls Out
- **PPA Quality Comparison:** The paper does not analyze whether Chisel-to-Verilog generation produces hardware with superior Power, Performance, and Area (PPA) metrics or maintainability compared to direct Verilog generation. The experiments only evaluate functional correctness, not the quality of the final hardware implementation.
- **Hard Case Characteristics:** The paper identifies a performance plateau where about 10% of cases remain unsolvable, but does not categorize the specific types of logic errors or complexities that cause certain problems to remain unsolvable even after iterative reflection.
- **Syntax-Functional Error Separation:** The reflection mechanism could be enhanced to prevent the re-introduction of syntax errors while fixing functional bugs, as the current approach treats errors sequentially without preserving previously verified syntactic structures.

## Limitations
- The reflection mechanism shows a tendency for syntax errors to reappear in later iterations (9→10), suggesting the current separation between syntax and functional error handling could be improved
- Maximum 10 iterations may be insufficient for certain complex cases, though the escape mechanism prevents infinite loops
- Limited benchmark diversity (3 datasets) may not capture all edge cases in Chisel code generation

## Confidence
- High confidence in the overall methodology and reported success rate improvements
- Medium confidence in the completeness of the escape mechanism design
- Medium confidence in the generalizability of results given limited benchmark diversity

## Next Checks
1. Implement and test the escape mechanism threshold using a synthetic dataset with known non-progress patterns to verify loop detection effectiveness
2. Conduct ablation studies isolating the impact of in-context learning examples versus the reflection mechanism on final success rates
3. Measure and report iteration-specific error type distributions to confirm whether syntax and functional errors can be more effectively decoupled during the reflection process