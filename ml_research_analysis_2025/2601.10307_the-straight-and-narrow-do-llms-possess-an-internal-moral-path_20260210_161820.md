---
ver: rpa2
title: 'The Straight and Narrow: Do LLMs Possess an Internal Moral Path?'
arxiv_id: '2601.10307'
source_url: https://arxiv.org/abs/2601.10307
tags:
- moral
- virtue
- vice
- chinese
- vectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the problem of superficial behavioral guardrails\
  \ in LLM alignment, proposing a method to directly intervene in the model\u2019\
  s latent moral representations. By leveraging Moral Foundations Theory, the authors\
  \ validate cross-lingual moral subspaces, extract steerable Moral Vectors for each\
  \ foundation, and introduce Adaptive Moral Fusion (AMF) to dynamically balance safety\
  \ and helpfulness."
---

# The Straight and Narrow: Do LLMs Possess an Internal Moral Path?

## Quick Facts
- **arXiv ID**: 2601.10307
- **Source URL**: https://arxiv.org/abs/2601.10307
- **Reference count**: 32
- **Primary result**: AMF reduces HarmBench jailbreak success to 19.66% and XSTest incorrect refusals to 2.00%

## Executive Summary
This paper addresses the problem of superficial behavioral guardrails in LLM alignment by proposing a method to directly intervene in the model's latent moral representations. The authors leverage Moral Foundations Theory to validate cross-lingual moral subspaces, extract steerable Moral Vectors for each foundation, and introduce Adaptive Moral Fusion (AMF) to dynamically balance safety and helpfulness. The approach shows significant improvements over baseline models and static steering methods, achieving safety performance comparable to proprietary models like Claude-3.5-Sonnet.

## Method Summary
The method extracts moral representations from middle layers of LLMs using linear probing on a Moral Virtue-Vice (MVV) dataset. For each of five moral foundations (Care, Fairness, Loyalty, Authority, Sanctity) and two polarities (Virtue/Vice), the authors compute Moral Vectors as difference vectors between virtue and vice centroids. AMF dynamically gates vector injection based on probe confidence, injecting weighted sums of Moral Vectors when Vice probabilities exceed threshold τ. The approach is validated through cross-lingual analysis and tested on HarmBench and XSTest benchmarks.

## Key Results
- Layer 17 probing accuracy reaches 65.6% on 10-class MVV dataset
- AMF reduces HarmBench jailbreak success rate to 19.66%
- AMF minimizes XSTest incorrect refusals to 2.00%
- Performance approaches proprietary model safety levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Moral concepts encode as linearly separable representations in middle layers
- Core assumption: Linear directions in residual stream space consistently organize moral concepts
- Evidence: 65.6% classification accuracy at Layer 17
- Break condition: Probe failure across semantically distinct contexts

### Mechanism 2
- Claim: Cross-lingual moral subspaces share geometric structure with asymmetric coverage
- Core assumption: Moral concepts abstract beyond linguistic features
- Evidence: Transfer discrepancy analysis showing δ≈−0.28 (Chinese Care-dominant) and δ≈0.30 (English Sanctity-Virtue-dominant)
- Break condition: Transfer performance reflecting lexicon overlap rather than conceptual structure

### Mechanism 3
- Claim: AMF balances safety-helpfulness trade-offs through dynamic gating
- Core assumption: Probe confidence correlates with moral violation risk
- Evidence: τ=0.2 simultaneously minimizes ASR and refusal rate
- Break condition: Threshold sensitivity or foundation vector conflicts

## Foundational Learning

- **Linear Probing**
  - Why needed: Entire method depends on training classifiers on hidden states
  - Quick check: Why doesn't high probe accuracy imply the model "uses" that representation for generation?

- **Activation Steering (Residual Stream Intervention)**
  - Why needed: Moral Vectors are injected into hidden states during inference
  - Quick check: What happens to steering effects when target layer is too early vs. too late?

- **Moral Foundations Theory (MFT)**
  - Why needed: 10-class taxonomy defines the entire label space
  - Quick check: Why might "revenge" load positively on Loyalty-Virtue in some cultural contexts?

## Architecture Onboarding

- **Component map**: MVV dataset → Unified Moral Probe (Layer 17) → Moral Vectors → AMF Gating Module → Residual Stream Injection
- **Critical path**: Construct MVV dataset → Train unified probe → Extract Moral Vectors → Tune τ → Deploy AMF inference hook
- **Design tradeoffs**: Static vs. adaptive steering; threshold sensitivity; single vs. multi-layer injection
- **Failure signatures**: Over-refusal on moral keywords; jailbreak success on low-Vice prompts; incoherent outputs from vector interference
- **First 3 experiments**: 
  1. Reproduce Layer 17 probe accuracy baseline
  2. Inject single Moral Vector at λ=2.0; measure output distribution shift
  3. Run AMF ablation sweeping τ ∈ {0.0, 0.1, 0.2, 0.3, 0.4}

## Open Questions the Paper Calls Out

1. Do MFT-based representations conflict with or fail to capture dimensions of other ethical frameworks like Utilitarianism or Deontology?

2. Can cross-lingual moral subspaces generalize to low-resource languages or non-WEIRD cultures without specific tuning?

3. To what extent do extracted Moral Vectors reflect intrinsic model morality versus LLM-generated synthetic dataset biases?

4. Are linear separability and AMF efficacy consistent across diverse model architectures?

## Limitations

- Cross-lingual analysis limited to English-Chinese pair without verification in low-resource languages
- Dataset construction relies exclusively on LLM generation without human annotation
- Foundation vector interference problem acknowledged but not empirically tested
- Threshold calibration may not generalize across model scales or domains

## Confidence

- **High**: Experimental methodology is clearly specified and reproducible
- **Medium**: Cross-lingual subspace isomorphism interpretation may reflect lexical overlap
- **Low**: Intrinsic alignment claims rest on single-threshold optimization without full Pareto frontier exploration

## Next Checks

1. **Cross-Lingual Probe Transfer Stress Test**: Train probes on English, evaluate on Spanish and French MVV subsets to test if Care-Vice asymmetry is language-pair specific.

2. **Foundation Vector Interference Analysis**: Construct adversarial prompts activating multiple high-Vice foundations to measure whether AMF produces coherent outputs or exhibits destructive interference.

3. **Threshold Sensitivity Sweep**: Systematically vary τ across model scales and domains to identify optimal operating regions and detect catastrophic threshold sensitivity.