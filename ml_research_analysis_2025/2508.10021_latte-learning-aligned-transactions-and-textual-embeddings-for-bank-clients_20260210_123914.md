---
ver: rpa2
title: 'LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients'
arxiv_id: '2508.10021'
source_url: https://arxiv.org/abs/2508.10021
tags:
- event
- learning
- latte
- embeddings
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LATTE, a contrastive learning framework that
  aligns raw transaction embeddings with semantic embeddings from frozen LLMs to learn
  rich client representations from event sequences. Instead of feeding entire transaction
  sequences into LLMs, LATTE extracts compact client-level statistics, generates natural
  language summaries via an LLM, and uses these summaries as supervision through contrastive
  loss.
---

# LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients

## Quick Facts
- arXiv ID: 2508.10021
- Source URL: https://arxiv.org/abs/2508.10021
- Authors: Egor Fadeev; Dzhambulat Mollaev; Aleksei Shestov; Omar Zoloev; Artem Sakhno; Dmitry Korolev; Ivan Kireev; Andrey Savchenko; Maksim Makarenko
- Reference count: 23
- Key outcome: LATTE achieves 6.1% relative improvement in gender prediction, around 1.0% in age group classification, and 3.7% in churn prediction compared to baseline methods.

## Executive Summary
LATTE introduces a contrastive learning framework that aligns raw transaction embeddings with semantic embeddings from frozen LLMs to learn rich client representations from event sequences. Instead of processing entire transaction sequences through LLMs, LATTE extracts compact client-level statistics, generates natural language summaries via an LLM, and uses these summaries as supervision through contrastive loss. This significantly reduces inference cost and input size compared to processing complete sequences by LLM. LATTE outperforms state-of-the-art techniques for learning event sequence representations on real-world financial datasets while remaining deployable in latency-sensitive environments.

## Method Summary
LATTE is a three-stage pipeline: (1) extract statistical summaries from transaction sequences including transaction frequency, merchant diversity, and temporal coverage; (2) generate natural language descriptions using a frozen instruction-tuned LLM (Gemma-3-27B or Qwen3-32B) from these statistics; (3) align GRU-based sequence embeddings (pretrained with CoLES) with frozen text encoder embeddings (Qwen3-Embedding-8B) via contrastive loss. The method uses two contrastive heads—Symmetric Softmax (LATTE[1]) and Orthogonal Regularized (LATTE[2])—to bring paired sequence-text embeddings closer while pushing apart non-matching pairs. The sequence encoder is trained while the text encoder remains frozen, enabling efficient deployment.

## Key Results
- 6.1% relative improvement in gender prediction accuracy over baseline methods
- Around 1.0% improvement in age group classification accuracy
- 3.7% improvement in churn prediction ROC-AUC
- LATTE-S achieves 162 samples/sec/GPU vs. <10 for LLM-based methods
- Performance gains consistent across three banking datasets (Churn, Gender, Age Group)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning raw transaction embeddings with LLM-generated textual descriptions via contrastive loss improves downstream task performance.
- Mechanism: The sequence encoder learns to produce embeddings that occupy similar regions in vector space as semantically rich textual summaries, effectively distilling LLM semantic knowledge into a lightweight encoder.
- Core assumption: The LLM-generated descriptions capture behavioral patterns relevant to downstream tasks that pure sequence encoders miss.
- Evidence anchors: [abstract]: "contrastive learning framework that aligns raw event embeddings with semantic embeddings from frozen LLMs"; [section 3]: "The embeddings zseq and ztext are then aligned using one of three cross-modal contrastive losses"

### Mechanism 2
- Claim: Statistical summarization of transaction sequences into natural language prompts provides sufficient supervision for representation learning without requiring ground-truth labels.
- Mechanism: Pre-computed statistical features (frequency, merchant diversity, temporal patterns) are verbalized into prompts; the LLM generates coherent descriptions that serve as weak labels for contrastive learning.
- Core assumption: The chosen statistics adequately capture behavioral patterns predictive of downstream tasks.
- Evidence anchors: [section 3]: "we first compute a vector of summary features si that aggregates behavioral patterns over the sequence: frequency of activity, merchant diversity, transaction types"; [table 3]: Statistics like transaction_period and trx_days_share show >90% usage and >92% accuracy in LLM descriptions

### Mechanism 3
- Claim: Keeping the text encoder frozen while only updating the sequence encoder preserves LLM semantic knowledge while enabling efficient deployment.
- Mechanism: The frozen text encoder provides stable semantic anchors; only the lightweight GRU-based sequence encoder is trained, producing inference-efficient embeddings that retain LLM-level semantics.
- Core assumption: Frozen text embeddings remain semantically meaningful without domain-specific adaptation.
- Evidence anchors: [section 3]: "while keeping the text encoder fixed"; [figure 3]: LATTE-S achieves 162 samples/sec/GPU vs. <10 for LLM-based methods

## Foundational Learning

- Concept: **Contrastive Learning (InfoNCE loss)**
  - Why needed here: The entire LATTE alignment mechanism relies on contrastive objectives to bring paired sequence-text embeddings closer while pushing apart non-matching pairs.
  - Quick check question: Can you explain why the temperature parameter τ in InfoNCE affects the sharpness of the similarity distribution?

- Concept: **GRU-based sequence encoding**
  - Why needed here: The base sequence encoder is a GRU trained under CoLES objective; understanding recurrent encoding is necessary to modify the architecture.
  - Quick check question: How does a GRU handle long-range dependencies compared to a Transformer, and what are the trade-offs for sequences with thousands of events?

- Concept: **Multimodal representation alignment**
  - Why needed here: LATTE's core innovation is cross-modal alignment between structured event sequences and unstructured text.
  - Quick check question: What is the geometric intuition behind the Orthogonal Regularized contrastive head's separation of Zshared and Zspec?

## Architecture Onboarding

- Component map: Statistical Feature Extractor -> Prompt construction -> LLM Description Generator -> Text Embedder -> Contrastive Alignment Head || Sequence Encoder -> Contrastive Alignment Head -> Updated Sequence Embedding
- Critical path: Statistical features → Prompt construction → LLM description → Text embedding (frozen) ‖ Sequence → Sequence encoder → Contrastive alignment → Updated sequence embedding
- Design tradeoffs:
  - LATTE vs. LATTE-S: Full LATTE concatenates text + sequence embeddings (higher accuracy, requires text encoder at inference); LATTE-S uses only aligned sequence encoder (faster inference, slightly lower performance)
  - LLM generator size: Larger models (Qwen3-32B) marginally improve age classification; smaller models (Gemma-3-4B) underperform
  - Contrastive head choice: LATTE[2] (Orthogonal) slightly better for churn; LATTE[1] (Symmetric) better for age/gender
- Failure signatures:
  - Low alignment quality: Check if LLM descriptions faithfully reflect input statistics (Table 3 shows this is usually >92% accurate)
  - Inference too slow: Verify you're using LATTE-S mode, not full LATTE with text encoder
  - Poor downstream performance: Examine whether prompt template captures domain-relevant statistics
- First 3 experiments:
  1. Baseline comparison: Run CoLES-pretrained encoder on downstream task without alignment; compare against LATTE-S to quantify alignment gain
  2. Prompt ablation: Vary the statistical features included in the prompt template; measure downstream impact to identify critical statistics
  3. Contrastive head comparison: Evaluate LATTE[1] vs. LATTE[2] on your specific downstream task; the paper shows task-dependent optimal choices

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can coupling natural language summaries directly with underlying event dynamics (rather than just statistical aggregates) yield inherently interpretable embeddings while maintaining predictive performance?
- Basis in paper: [explicit] The conclusion states: "A particularly promising future direction is to explore richer forms of text-to-sequence alignment, where natural language summaries are coupled with the underlying event dynamics. This approach could yield to inherently interpretable embeddings."
- Why unresolved: The current approach only aligns sequence embeddings with text summaries of pre-computed statistics, not with the raw temporal dynamics themselves.
- What evidence would resolve it: A comparative study showing that event-dynamics-coupled text alignment produces embeddings that are both more interpretable (via qualitative analysis or interpretability metrics) and achieve comparable or better downstream task performance.

### Open Question 2
- Question: How does LATTE's alignment fidelity degrade under distributional shifts in transaction patterns, and can adaptive text encoder updates mitigate this?
- Basis in paper: [inferred] The limitations section notes: "Because the text encoder is not updated during training, alignment fidelity may further degrade under distributional shifts."
- Why unresolved: The frozen text encoder assumption improves efficiency but may reduce robustness when client behavior distributions change over time or across different banking contexts.
- What evidence would resolve it: Experiments measuring performance drift on temporally shifted test sets, comparing frozen vs. periodically updated text encoders.

### Open Question 3
- Question: Can the fixed set of pre-computed statistical features be replaced or augmented with learned feature discovery to capture behavioral patterns not anticipated by manual design?
- Basis in paper: [inferred] The limitations state the approach "remains constrained by its reliance on a fixed set of pre-computed statistical features" which "limits adaptability when key behavioral patterns are not adequately captured by the chosen statistics."
- Why unresolved: Manual feature engineering may miss domain-specific or emerging behavioral signals.
- What evidence would resolve it: A learnable feature extraction module (e.g., neural statistics networks) that outperforms hand-crafted statistics on held-out behavioral patterns or novel downstream tasks.

### Open Question 4
- Question: Does LATTE transfer effectively to other structured event sequence domains (healthcare, education, e-commerce) where event semantics and temporal structures differ significantly from financial transactions?
- Basis in paper: [explicit] The limitations section explicitly proposes: "The proposed sequence-to-text alignment framework can be extended to a wide range of domains that generate structured event logs—data types where LLMs often struggle due to sparsity, heterogeneity, and long temporal dependencies. Examples include healthcare, education, e-commerce."
- Why unresolved: The method was only validated on financial transaction data; its applicability to other domains with different event granularities, sparsity patterns, and semantic structures remains untested.
- What evidence would resolve it: Benchmarks on open event-sequence datasets from healthcare (e.g., MIMIC), education (e.g., XES3G5M), or e-commerce, comparing LATTE against domain-specific baselines.

## Limitations

- The approach relies on frozen LLM embeddings that may not adapt to domain-specific nuances or distributional shifts in financial data.
- Statistical summarization could miss nuanced behavioral patterns not captured by the fixed feature vocabulary.
- Evaluation is restricted to three narrow downstream tasks from limited banking datasets, raising generalizability questions.

## Confidence

- **High confidence**: The core mechanism of aligning sequence embeddings with LLM-generated text via contrastive learning is well-supported by the paper's ablation studies and quantitative results. The computational efficiency gains over full LLM processing are clearly demonstrated.
- **Medium confidence**: The transferability of frozen LLM semantic knowledge to financial event sequences is plausible but not thoroughly validated across diverse banking systems or regulatory environments.
- **Medium confidence**: The optimal choice of contrastive head (LATTE[1] vs LATTE[2]) appears task-dependent, but the paper doesn't provide a clear selection criterion for practitioners choosing between them.

## Next Checks

1. **Distribution shift robustness test**: Evaluate LATTE on a held-out time period or different banking system to assess how well frozen text embeddings transfer when transaction patterns evolve or when merchant categories differ.
2. **Prompt template ablation**: Systematically remove or modify individual statistical features in the prompt template to quantify their individual contribution to downstream performance and identify any critical features being missed.
3. **Cross-domain transferability**: Apply the pretrained LATTE model (without fine-tuning) to a non-banking event sequence dataset (e.g., e-commerce transactions or app usage logs) to test whether the learned representations generalize beyond the financial domain.