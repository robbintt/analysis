---
ver: rpa2
title: 'You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage
  Domain Adaptive Detection of Space Terrain'
arxiv_id: '2501.13725'
source_url: https://arxiv.org/abs/2501.13725
tags:
- detection
- only
- features
- feature
- instance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of detecting planetary, lunar,
  and small-body surface terrain in real-time using spacecraft hardware, which is
  critical for autonomous navigation and landing. Traditional methods rely on extensive
  prior imaging and offline processing, limiting real-time operation and generalization
  to new environments.
---

# You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage Domain Adaptive Detection of Space Terrain

## Quick Facts
- arXiv ID: 2501.13725
- Source URL: https://arxiv.org/abs/2501.13725
- Authors: Timothy Chase; Christopher Wilson; Karthik Dantu
- Reference count: 40
- Key outcome: YOCOv2 achieves up to 31% improvement over YOCOv1 and terrestrial methods for UDA terrain detection on Mars, Moon, and Asteroid datasets

## Executive Summary
This work addresses real-time terrain detection for planetary and small-body navigation using spacecraft hardware. Traditional approaches rely on extensive prior imaging and offline processing, limiting real-time operation and generalization. The authors propose YOCOv2, which integrates Visual Similarity-based Alignment (VSA) with lightweight one-stage detection architectures. YOCOv2 introduces perceptual consistency regularization and strong feature filtering to enhance terrain detection under Unsupervised Domain Adaptation, achieving state-of-the-art performance without labeled target data.

## Method Summary
YOCOv2 extends the YOCO framework by adding Perceptual Consistency (PC) regularization and Strong Feature Filtering (SFF) to the Visual Similarity-based Alignment pipeline. PC enforces multi-scale feature matching between source and target domains through weighted L1 loss across detection scales. SFF applies channel-wise attention to retain only the most discriminative features before VSA alignment. The method is evaluated across simulated and real-world datasets, demonstrating improved UDA performance on NASA spacecraft hardware.

## Key Results
- Up to 31% improvement over YOCOv1 and terrestrial methods for UDA terrain detection
- Instance clustering methods outperform feature clustering on multi-class Mars terrain
- PC+SFF achieves 66.3% mAP on YOLOv5-S (Mars) vs 60.7% ViSGA
- Source Only training outperforms all UDA methods on YOLOv5-N for Moon terrain, suggesting architectural limitations

## Why This Works (Mechanism)

### Mechanism 1: Perceptual Consistency Regularization
- **Claim:** PC regularization stabilizes domain alignment by enforcing multi-scale feature matching
- **Mechanism:** Computes weighted L1 loss across three detection scales, prioritizing smaller spatial resolutions
- **Core assumption:** Terrain features at multiple scales contain complementary domain-invariant information
- **Evidence anchors:** Abstract states PC enhances UDA; Equation 4 defines LPC with scale weights emphasizing smaller resolutions
- **Break condition:** If source and target domains share no structural similarity, PC may enforce alignment on incompatible features

### Mechanism 2: Strong Feature Filtering
- **Claim:** SFF improves clustering quality by retaining only the most discriminative channels
- **Mechanism:** Applies channel-wise attention via Global Average Pooling followed by 1D convolution to score each channel
- **Core assumption:** Celestial terrain has sparse distinctive features; low-activation channels contribute noise
- **Evidence anchors:** SFF achieves 66.3% on YOLOv5-S vs 60.7% ViSGA; top-K ranked channels are selected
- **Break condition:** If terrain features are uniformly distributed across channels, SFF may discard useful information

### Mechanism 3: Instance Clustering for Multi-Class Terrain
- **Claim:** Instance clustering outperforms feature clustering for multi-class terrain
- **Mechanism:** Extracts region-based embeddings via bounding box crops, then applies hierarchical or contrastive alignment
- **Core assumption:** Multi-class terrain creates overlapping feature activations that confuse channel-wise clustering
- **Evidence anchors:** Instance methods dominate on Mars; feature methods competitive on single-class Asteroid
- **Break condition:** High intra-class variance may still produce poor instance embeddings regardless of clustering method

## Foundational Learning

- **Concept: Unsupervised Domain Adaptation (UDA)**
  - Why needed here: Space missions cannot obtain labeled target data beforehand; models must transfer from simulations
  - Quick check question: Can you explain why minimizing source-target feature discrepancy enables detection without target labels?

- **Concept: Gradient Reversal Layer (GRL)**
  - Why needed here: Enables adversarial domain discrimination during forward pass while reversing gradients during backprop
  - Quick check question: What happens to the feature extractor's objective when GRL scaling factor is too large?

- **Concept: Hierarchical vs K-Means Clustering**
  - Why needed here: VSA requires grouping visually similar features; hierarchical allows dynamic cluster count
  - Quick check question: Why might K=2 work better for single-class asteroid terrain than hierarchical clustering?

## Architecture Onboarding

- **Component map:**
  Input (Source + Target) → Backbone → [GRL + Domain Discriminator for LImg] → Neck → Detection Heads → Instance Features → [SFF → Clustering → LInst]

- **Critical path:** The instance alignment branch (L_Inst) drives most UDA gains. Trace feature extraction from neck → instance features → SFF scoring → clustering.

- **Design tradeoffs:**
  | Choice | Pro | Con |
  |--------|-----|-----|
  | Instance vs Feature clustering | Better multi-class | Higher compute |
  | Adversarial vs Contrastive | No nearest-neighbor search | Discriminator instability |
  | PC-only vs PC+SFF | Simpler pipeline | May miss filtering benefits |

- **Failure signatures:**
  - YOLOv5-N on Asteroid achieves only 5.4% Source Only—model capacity insufficient for domain gap
  - PC+SFF drops 38% vs PC-only on YOLOv5-N Asteroid—attention mechanism may over-prune
  - Moon Target-Only oracle at ~37% suggests incomplete ground truth labels

- **First 3 experiments:**
  1. Run Source Only baseline on each dataset to quantify domain gap magnitude
  2. Compare PC-only vs PC+SFF on YOLOv5-S across all three environments to validate SFF contribution
  3. Ablate Instance (contrastive) vs Instance (adversarial) on Mars multi-class to confirm discriminator struggles

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can intra-feature clustering be made effective for multi-class terrain detection where class-to-background distinctions are less prominent?
- Basis in paper: Explicit hypothesis that intra-feature clustering could work for certain celestial scenes with prominent class-to-background distinctions
- Why unresolved: Feature clustering underperformed in multi-class Mars scenarios, working best only in single-class Asteroid cases
- What evidence would resolve it: Experiments on multi-class datasets with enhanced feature discernibility mechanisms or hybrid approaches

### Open Question 2
- Question: Why does Source Only training outperform all UDA methods on YOLOv5-N for Moon terrain?
- Basis in paper: Paper documents this anomaly but does not diagnose the root cause or propose remediation
- Why unresolved: No analysis of model capacity thresholds required for VSA or feature space geometry for small models
- What evidence would resolve it: Ablation studies on model capacity or analysis of feature space geometry

### Open Question 3
- Question: How can UDA performance be accurately evaluated when ground truth databases are incomplete?
- Basis in paper: Authors acknowledge the Robbins lunar crater database is incomplete, causing mAP to underestimate true detection capability
- Why unresolved: Quantitative evaluation relies on imperfect labels, potentially masking true method performance
- What evidence would resolve it: Development of comprehensive benchmark datasets or alternative evaluation protocols robust to label sparsity

### Open Question 4
- Question: Can YOCOv2 generalize to entirely unexplored celestial bodies where no prior imagery exists?
- Basis in paper: YOCOv2 was only evaluated on Mars, Moon, and Asteroid where some reference data existed
- Why unresolved: No experiments conducted in zero-prior-information scenarios
- What evidence would resolve it: Sim-to-real experiments using physics-based simulators for novel body compositions without real imagery

## Limitations

- Limited real-world validation: Only 2-3 real terrain examples per environment tested despite claiming practical utility
- Label quality ambiguity: Moon Target-Only oracle performance at ~37% suggests incomplete or inconsistent ground truth annotations
- Scaling behavior unclear: SFF shows 38% performance drop on YOLOv5-N Asteroid with no analysis of when attention over-pruning occurs

## Confidence

- High: YOCOv2 improves UDA performance over YOCOv1 and terrestrial methods (31% gain empirically verified)
- Medium: Perceptual Consistency regularization mechanism (PC weights empirically validated but theoretical justification remains qualitative)
- Low: Strong Feature Filtering universal applicability (SFF shows inconsistent results across model sizes)

## Next Checks

1. Test PC+SFF on 5+ additional asteroid/planetary datasets to verify SFF doesn't over-prune on small objects or sparse terrain
2. Measure YOCOv2 inference latency and memory on actual flight hardware under realistic mission power/thermal constraints
3. Conduct ablation studies varying PC scale weights systematically to quantify optimal configuration and validate theoretical assumptions