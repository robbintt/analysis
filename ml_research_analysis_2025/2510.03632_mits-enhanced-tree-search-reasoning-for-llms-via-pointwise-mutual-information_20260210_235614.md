---
ver: rpa2
title: 'MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information'
arxiv_id: '2510.03632'
source_url: https://arxiv.org/abs/2510.03632
tags:
- reasoning
- search
- tree
- step
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MITS, a framework for enhancing large language
  model reasoning through tree search guided by pointwise mutual information (PMI).
  The core innovation is using PMI as a scoring function to evaluate reasoning path
  quality, enabling efficient search without expensive look-ahead simulations.
---

# MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information

## Quick Facts
- arXiv ID: 2510.03632
- Source URL: https://arxiv.org/abs/2510.03632
- Reference count: 19
- Achieves up to 21.11% accuracy improvement on StrategyQA with superior computational efficiency

## Executive Summary
MITS introduces a tree search framework for large language model reasoning guided by pointwise mutual information (PMI). The method uses PMI as a scoring function to evaluate reasoning path quality without expensive look-ahead simulations, combined with entropy-based dynamic sampling to allocate computational resources adaptively and weighted voting to select final answers. Experiments on StrategyQA, ARC-Challenge, and CommonsenseQA datasets demonstrate MITS consistently outperforms baselines like CoT-SC, RAP, and rStar while achieving 3.2x-12.7x faster inference.

## Method Summary
MITS implements beam search with PMI-based scoring where paths are evaluated using log[p(S|q)/p(S)] to measure question-specific information contribution. The framework employs incremental PMI updates to efficiently extend scoring as reasoning unfolds, avoiding full recomputation. Entropy-based dynamic sampling allocates more candidates to high-uncertainty reasoning steps using quantile-based adaptive thresholds. Final answer selection uses weighted voting combining PMI scores with prediction consensus, selecting top-K chains and computing weighted scores as PMI(q;S) × Freq(Pred(S))/K.

## Key Results
- Achieves 21.11% accuracy improvement on StrategyQA with QWEN2.5-3B
- Demonstrates 5.31% improvement on ARC-Challenge over state-of-the-art
- Shows 3.2x faster inference than RAP and 12.7x faster than rStar while maintaining highest accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PMI-based scoring evaluates reasoning path quality without expensive look-ahead simulations by measuring question-specific information contribution
- Mechanism: Computes PMI(q;S) = log[p(S|q)/p(S)] where p(S|q) measures reasoning fit given the question, and p(S) penalizes generic paths. Uses incremental updates (Equation 4) to efficiently extend scoring as reasoning unfolds, avoiding full recomputation
- Core assumption: LLM log-probabilities accurately reflect true probability distributions for both conditional and marginal reasoning paths
- Evidence anchors: [abstract] confirms PMI enables step-wise evaluation without expensive look-ahead; [Section 3.1] derives incremental PMI update formula; [corpus] TSLM and Policy Guided Tree Search confirm tree-structured reasoning benefits but use different scoring heuristics

### Mechanism 2
- Claim: Entropy-based dynamic sampling allocates more candidates to high-uncertainty reasoning steps, improving compute efficiency
- Mechanism: Computes token-level entropy H_i = -Σ p_i(v)log p_i(v) for each step. Uses quantile-based adaptive thresholds (33rd/67th percentile of historical entropies) to classify uncertainty as low/moderate/high. Adjusts sample count: N = N_base + ΔN_i, where ΔN_i scales with deviation from moderate range
- Core assumption: Higher entropy at a reasoning step correlates with greater benefit from exploring diverse continuations
- Evidence anchors: [abstract] states entropy-based dynamic sampling adaptively allocates computational resources to uncertain reasoning steps; [Section 3.2] details quantile-based thresholds; [corpus] Semantic Exploration with Adaptive Gating supports entropy-as-uncertainty-signal premise

### Mechanism 3
- Claim: Weighted average voting combining PMI scores with prediction frequency improves final answer selection over pure PMI or majority voting alone
- Mechanism: Selects top-K chains by PMI, computes PMI*(q;S) = PMI(q;S) × Freq(Pred(S))/K, then selects chain with highest weighted score. This regularizes against spurious high-PMI paths by requiring consensus
- Core assumption: Agreement across multiple reasoning paths indicates more reliable conclusions, and high-PMI paths should not be trusted in isolation
- Evidence anchors: [abstract] mentions weighted voting scheme combining PMI scores with prediction consensus; [Section 3.3] defines PMI* weighting formula; Table 5 shows K=16-32 outperforms K=1 by 4-6% across datasets

## Foundational Learning

- **Pointwise Mutual Information (PMI)**: Core scoring mechanism; must understand how PMI measures question-specific vs. generic information to interpret why it filters spurious reasoning
  - Quick check: Given PMI(q;S) = log[p(S|q)/p(S)], what happens to the score if a reasoning path S is equally likely with or without seeing question q?

- **Beam Search**: MITS uses beam search for tree expansion with PMI as the ranking criterion; understanding pruning trade-offs is critical for implementation
  - Quick check: If beam width B=32 and each step generates 5 candidates from 10 active paths, how many paths survive after one expansion?

- **Entropy as Uncertainty Quantification**: Dynamic sampling relies on entropy thresholds; must grasp why high entropy suggests allocating more samples
  - Quick check: A step has entropy near the vocabulary maximum (log|V|). What does this imply about the model's next-token confidence?

## Architecture Onboarding

- **Component map**: Generator Model G -> Evaluator Model E -> Entropy Tracker -> Dynamic Sampler -> Beam Search Pruner -> Weighted Voting Aggregator
- **Critical path**: 1) Initialize tree with question q as root 2) For each depth level until max_depth=10: compute entropy → determine sample count N_i → Generator produces N_i candidate next-steps → Evaluator computes incremental PMI contribution → Update cumulative PMI scores; prune to top-B=32 paths 3) Extract top-K=32 complete chains; compute PMI* weighted scores 4) Return prediction from highest PMI* chain
- **Design tradeoffs**: Beam width (B=32) balances coverage vs compute; Top-K for voting (K=32) is dataset-dependent; Generator=Evaluator vs separate models affects memory/compute; PMI aggregation uses average (length-normalized) to reduce length bias
- **Failure signatures**: Length bias if forgetting to normalize PMI by step count; spurious high-PMI paths if not using weighted voting with K>1; static entropy thresholds when m<10 samples accumulated; evaluator mismatch if using weaker evaluator with stronger generator
- **First 3 experiments**: 1) PMI scoring validation: Compare MITS with beam search vs MITS-F (full expansion without pruning) on StrategyQA to isolate PMI-guided pruning contribution 2) Efficiency benchmark: Measure wall-clock time per problem on StrategyQA with QWEN2.5-3B; target ~64s vs RAP's 203s and rStar's 816s 3) Ablation on voting K: Sweep K∈{1,2,4,8,16,32} on ARC-Challenge to identify dataset-optimal aggregation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the optimal number of reasoning paths (K) for weighted voting be determined automatically, or is it fundamentally dependent on the dataset?
- Basis in paper: [explicit] The ablation study (Section 4.3) notes that "Optimal K values are dataset-dependent: StrategyQA peaks at K=16 while ARC-Challenge and CommonsenseQA achieve best results at K=32"
- Why unresolved: The current implementation requires hyperparameter tuning for K on a per-dataset basis, suggesting the voting mechanism lacks adaptive calibration
- What evidence would resolve it: A theoretical analysis or dynamic thresholding mechanism that selects K based on convergence of PMI score distribution or answer entropy without manual tuning

### Open Question 2
- Question: How does the approximation of the marginal probability p(S) using the unconditioned LLM probability affect the reliability of the PMI score?
- Basis in paper: [explicit] Section 3.1 states that to calculate p(S), "we prepend the special Begin-of-Sequence (<bos>) token to the language model," acknowledging this is an implementation choice to estimate the true marginal
- Why unresolved: It is unclear if the model's unconditional probability is a sufficient proxy for "logical generality," or if it introduces biases from the model's training data distribution
- What evidence would resolve it: A comparison of PMI scoring against alternative marginal estimation techniques, or an analysis of failure cases where high-PMI paths result from artificially low unconditional probabilities

### Open Question 3
- Question: Does the PMI scoring heuristic maintain its effectiveness in domains requiring strict symbolic or mathematical reasoning?
- Basis in paper: [inferred] The Introduction identifies "mathematical computation" as a key challenge, yet the experiments (Section 4) are restricted to semantic reasoning tasks (StrategyQA, ARC, CommonsenseQA)
- Why unresolved: It is unknown if penalizing "generic" paths (low information gain) helps in formal domains where reasoning steps must follow rigid logical axioms rather than semantic relevance
- What evidence would resolve it: Experimental results on mathematical benchmarks (e.g., GSM8K, MATH) comparing MITS against verification-based baselines

## Limitations
- PMI scoring mechanism lacks direct corpus validation that it specifically improves reasoning quality versus other scoring heuristics
- Weighted voting benefits not clearly demonstrated over simple frequency voting without PMI weighting
- Dynamic sampling utility unclear without ablation isolating entropy-based allocation from fixed sampling

## Confidence
- **High**: Computational efficiency improvements (3.2x-12.7x speedup), dataset consistency across three benchmarks, baseline comparisons
- **Medium**: PMI scoring mechanism validity, weighted voting benefits (4-6% improvement with K=16-32), dynamic sampling utility
- **Low**: Claims about PMI specifically enabling reasoning quality improvements without expensive look-ahead

## Next Checks
1. Isolate PMI pruning contribution: Run MITS with fixed sampling (N=3 everywhere) versus full dynamic sampling on StrategyQA to measure pure PMI-guided pruning benefit versus entropy-based allocation

2. Validate weighted voting design: Implement frequency-only voting (no PMI weighting) and compare against PMI-weighted voting on ARC-Challenge to determine if PMI weighting provides marginal benefit beyond consensus detection

3. Test evaluator strength independence: Run MITS with Qwen2.5-1.5B evaluator (matching baseline models) to verify performance gains aren't primarily from using stronger evaluation models