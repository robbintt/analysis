---
ver: rpa2
title: Simplifying Adversarially Robust PAC Learning with Tolerance
arxiv_id: '2502.07232'
source_url: https://arxiv.org/abs/2502.07232
tags:
- learning
- hypothesis
- class
- respect
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adversarially robust PAC
  learning with tolerance, where the goal is to learn a hypothesis that performs well
  not just on unperturbed data but also on adversarially perturbed examples. Prior
  work showed that robust learning often requires improper methods with exponential
  sample complexity, though recent approaches using tolerance (allowing comparison
  against a slightly larger perturbation set) achieved linear dependence on VC-dimension
  but relied on complex compression schemes or additional assumptions.
---

# Simplifying Adversarially Robust PAC Learning with Tolerance

## Quick Facts
- **arXiv ID**: 2502.07232
- **Source URL**: https://arxiv.org/abs/2502.07232
- **Reference count**: 21
- **Primary result**: A simple two-stage algorithm (RERM + smoothing/discretization) achieves sample complexity linear in VC-dimension for adversarially robust PAC learning with tolerance

## Executive Summary
This paper addresses the challenge of adversarially robust PAC learning with tolerance, where the goal is to learn a hypothesis that performs well not just on unperturbed data but also on adversarially perturbed examples. Prior work showed that robust learning often requires improper methods with exponential sample complexity, though recent approaches using tolerance (allowing comparison against a slightly larger perturbation set) achieved linear dependence on VC-dimension but relied on complex compression schemes or additional assumptions.

The authors propose a simple two-stage algorithm: first apply Robust ERM to find a hypothesis in the original class, then smooth this hypothesis by taking majority vote over a small perturbation neighborhood. For the realizable case, this yields sample complexity linear in VC-dimension, logarithmic in the tolerance parameter Œ≥, and logarithmic in ambient dimension d. For the agnostic case, they introduce a global discretization approach that discretizes the hypothesis output while maintaining similar sample complexity bounds.

## Method Summary
The method uses a two-stage approach for tolerant adversarially robust PAC learning. First, Robust ERM finds a hypothesis minimizing empirical adversarial loss with respect to a reference perturbation type V. Second, the hypothesis is post-processed via either smoothing (majority vote over a small perturbation neighborhood W) or discretization (nearest-neighbor mapping to a grid-based cover C). The key insight is that tolerance enables the use of simple smoothing operations to convert a robust hypothesis into one that tolerates a larger perturbation set. The method is "almost proper" since the only improperness is in the final smoothing step.

## Key Results
- Achieves sample complexity linear in VC-dimension for tolerant adversarially robust learning
- Simple two-stage algorithm (RERM + smoothing) replaces complex compression schemes
- Extends to agnostic and semi-supervised settings with similar sample complexity bounds
- Proves that proper tolerant learning is impossible in general, justifying the need for improper methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Smoothing a robust hypothesis by majority voting over a perturbation neighborhood converts it to tolerate a larger perturbation set with bounded sample complexity.
- Mechanism: Given RERM hypothesis h with respect to V, define smoothed hypothesis sm_W(h)(x) = 1[ùîº_{x'‚àºW(x)}[h(x')] ‚â• 1/2]. This ensures that if an adversarial point in U(x) causes misclassification, a substantial fraction of its W-neighborhood must also be misclassified, which transfers the loss analysis from U to a discrete perturbation type C ‚äÇ V with finite-sized perturbation sets.
- Core assumption: The smoothing set W(z) occupies sufficient mass under the uniform measure over V(x) (specifically Œº_V(x)(W(z)) ‚â• 3Œ∑).
- Evidence anchors:
  - [abstract]: "first apply Robust ERM to find a hypothesis in the original class, then smooth this hypothesis by taking majority vote over a small perturbation neighborhood"
  - [section 3.1, Theorem 9]: Proves ‚Ñì_U(sm_W(h), x, y) ‚â§ ‚Ñì_C(h, x, y) pointwise via the net argument
  - [corpus]: Related work on distributional-lifting and uniform computability of PAC learning provides context but no direct corroboration of the smoothing mechanism
- Break condition: When W(z) has insufficient mass in V(x), the Œ∑-net argument fails and the loss transfer inequality no longer holds.

### Mechanism 2
- Claim: Discretizing the perturbation type bounds the VC-dimension of the adversarial loss class, enabling standard ERM analysis.
- Mechanism: By constructing discrete perturbation type C where each C(x) = V(x) ‚à© C is finite (bounded by k), Lemma 6 shows VC(H_C) ‚â§ VC(H) ¬∑ log(k). This transforms the adversarial loss class from potentially infinite VC-dimension to tractable finite VC-dimension.
- Core assumption: The perturbation sets admit uniform measures and the discretization C forms an rŒ≥-cover of X.
- Evidence anchors:
  - [section 2.2, Lemma 6]: "VC-dimension of the robust loss class is bounded by VC(H_C) ‚â§ VC(H) log(k)"
  - [section 3.2]: "deÔ¨Åning C to be a grid with appropriate side-length is a simple way to obtain such a cover"
  - [corpus]: "Group-realizable multi-group learning" shows similar VC-dimension-based sample complexity improvements via ERM
- Break condition: If C(x) cannot be uniformly bounded in size (e.g., unbounded domain without proper cover), the log(k) factor becomes infinite.

### Mechanism 3
- Claim: Tolerance relaxes the adversarial robustness requirement sufficiently to enable simple learners while remaining practically meaningful.
- Mechanism: Instead of requiring L^U_P(h) ‚â§ L^U_P(H) + Œµ (exact perturbation match), tolerant learning requires L^U_P(h) ‚â§ L^V_P(H) + Œµ where V is slightly larger than U. The Œ≥-tolerance gap absorbs boundary cases where exact robustness is information-theoretically hard.
- Core assumption: The user is "ambivalent" between perturbation types U and V when they are similar (related by tolerance Œ≥).
- Evidence anchors:
  - [abstract]: "tolerance enables the use of simple smoothing operations to convert a robust hypothesis into one that tolerates a larger perturbation set"
  - [section 2.1, Definition 3]: Formalizes (U,V)-tolerant PAC learning with the relaxed loss comparison
  - [corpus]: No direct corroboration; this relaxation framework appears novel to this paper series
- Break condition: If Œ≥ is too small relative to the discretization granularity, the theoretical guarantees may not translate to practical robustness.

## Foundational Learning

- Concept: **VC-dimension and uniform convergence**
  - Why needed here: Sample complexity bounds depend on VC(H) and VC(H_C); understanding why finite VC implies PAC learnability via ERM is essential.
  - Quick check question: Can you explain why a class with infinite VC-dimension cannot be PAC learned in the distribution-free setting?

- Concept: **Empirical Risk Minimization (ERM) and Robust ERM (RERM)**
  - Why needed here: Both algorithms use RERM as the first stage; understanding the difference between standard ERM (minimizing 0-1 loss) and RERM (minimizing adversarial loss) is critical.
  - Quick check question: For a hypothesis class H and perturbation type V, what does the RERM oracle A^V_H return?

- Concept: **Œ∑-nets and covering numbers**
  - Why needed here: The analysis constructs discrete perturbation types via Œ∑-nets; the sample complexity depends on net size through the log(k) factor.
  - Quick check question: Given a hypothesis class H with VC(H) = d, what sample size suffices to form an Œ∑-net with probability ‚â• 2/3?

## Architecture Onboarding

- Component map:
  - **RERM oracle (A^V_H)**: Takes labeled data S, returns hypothesis minimizing empirical adversarial loss L^V_S(h)
  - **Smoothing operator (sm_W)**: Takes hypothesis h, returns majority-vote smoothed version over perturbation neighborhood W
  - **Discretization (C)**: Global rŒ≥-cover (typically grid points) inducing discrete perturbation type C(x) = V(x) ‚à© C
  - **Nearest-neighbor discretizer (nn_C)**: Takes hypothesis h, returns discretized version assigning each x the label of its nearest neighbor in C

- Critical path:
  1. Construct or access discretization C (rŒ≥-cover of domain)
  2. Call RERM oracle with training data to obtain ƒ•
  3. Apply smoothing (Algorithm 1) or nearest-neighbor discretization (Algorithm 2) to produce final predictor

- Design tradeoffs:
  - **Algorithm 1 vs Algorithm 2**: Algorithm 1 is simpler (no explicit discretization needed at runtime) but the analysis requires a "local" Œ∑-net that may be harder to construct; Algorithm 2 requires explicit global discretization but works in both realizable and agnostic settings
  - **Proper vs improper**: Both algorithms are "almost proper"‚Äîthe only improperness is in the final smoothing/discretization step; this is necessary (Theorem 7 proves proper learning is impossible even with tolerance)
  - **Sample complexity factors**: Depend on VC(H), dimension d, and tolerance parameter Œ≥; smaller Œ≥ increases dependence as log(1/Œ≥)

- Failure signatures:
  - **Excessive sample complexity**: If sample size is insufficient relative to VC(H)log(k)/Œµ, uniform convergence fails and RERM may output a high-loss hypothesis
  - **Inadequate cover granularity**: If C is not a proper rŒ≥-cover, the loss transfer inequality ‚Ñì_U(nn_C(h), x, y) ‚â§ ‚Ñì_C(h, x, y) may fail
  - **Wrong perturbation type in RERM**: Using A^U_H instead of A^V_H violates the theoretical assumptions

- First 3 experiments:
  1. **Synthetic validation**: Implement Algorithm 2 on a simple 2D threshold class with ball perturbations; verify that sample complexity scales as predicted with VC(H) = 1, varying Œ≥ and dimension d
  2. **Ablation on discretization**: Compare grid-based vs random-cover discretizations; measure how cover quality (measured by max |C(x)|) affects empirical robust loss
  3. **Tolerance sensitivity**: Fix sample size and vary Œ≥; identify the minimum Œ≥ for which the algorithm achieves target robust accuracy, comparing against the theoretical bound

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the dependence on ambient dimension d be eliminated for Œ≥ = 1 (the case where actual and reference perturbation sets are equal)?
- Basis in paper: [explicit] "One interesting open question on a technical level is to eliminate the dependence on d for Œ≥ = 1. Montasser et al. [2021b] prove the existence of a transductive learner for Œ≥ = 1 whose sample complexity is independent of d. It will be nice to explore if our techniques can be used to obtain similar bounds in the inductive case."
- Why unresolved: The current analysis requires covering V(x) with W, yielding a cover of size (1 + 1/Œ≥)^d. For Œ≥ = 1, this still has exponential dependence on d, while transductive learners achieve dimension-independent bounds.
- What evidence would resolve it: A modified algorithm and analysis showing sample complexity ÀúO(VC(H)/Œµ) independent of d when Œ≥ = 1, or a lower bound showing dimension dependence is necessary for inductive learning.

### Open Question 2
- Question: Is the factor-3 approximation achieved by the semi-supervised agnostic learner optimal, or can the approximation factor be improved?
- Basis in paper: [inferred] The paper presents a factor-3 agnostic learner for the semi-supervised tolerant setting but does not discuss whether this factor is tight or improvable.
- Why unresolved: The factor arises from pruning strategies that may discard good hypotheses, and the analysis relies on worst-case arguments about hypothesis agreement patterns on the unlabeled set.
- What evidence would resolve it: Either an improved algorithm with a better approximation factor (e.g., factor-2), or a lower bound construction showing that factor-3 is necessary for any semi-supervised learner in this setting.

### Open Question 3
- Question: Are there natural structural assumptions on the hypothesis class or perturbation types under which proper tolerant learning becomes possible?
- Basis in paper: [inferred] Theorem 7 shows proper learning is impossible in general, but the construction uses an artificial hypothesis class. The paper does not explore whether meaningful restricted settings permit proper learning.
- Why unresolved: The impossibility construction exploits adversarial hypothesis classes; whether realistic constraints (e.g., convexity, Lipschitzness) change this picture remains unexplored.
- What evidence would resolve it: Identification of non-trivial hypothesis class properties that enable proper tolerant learning with sample complexity matching or improving upon the improper learners.

## Limitations

- RERM implementation for infinite hypothesis classes requires approximate optimization methods not specified in the paper
- Semi-supervised algorithm scales exponentially with unlabeled data, making it impractical for large datasets
- Sample complexity bounds still have exponential dependence on dimension d through the (1+1/Œ≥)^d term
- Smoothing mechanism's effectiveness depends on the relationship between W and V measures, which may not hold for non-isotropic perturbations

## Confidence

- **High confidence**: The two-stage algorithmic framework (RERM followed by smoothing/discretization) is clearly specified and the theoretical motivation is sound. The VC-dimension bounds for discretized perturbation types (Lemma 6) are straightforward applications of standard learning theory.
- **Medium confidence**: The loss transfer inequality ‚Ñì_U(sm_W(h),x,y) ‚â§ ‚Ñì_C(h,x,y) relies on the Œ∑-net argument which appears correct but requires careful verification of the measure concentration conditions. The global discretization approach for agnostic learning is well-defined but the analysis assumes access to an Œ∑-net that may be computationally expensive to construct.
- **Low confidence**: Practical implementation of RERM for specific hypothesis classes (especially non-linear ones) is not specified beyond oracle access. The semi-supervised algorithm's exponential scaling makes it impractical for realistic problem sizes without approximation methods.

## Next Checks

1. **Synthetic verification**: Implement Algorithm 2 on a simple 2D threshold class with ball perturbations. Measure empirical sample complexity as a function of VC(H), dimension d, and tolerance parameter Œ≥. Verify that the observed scaling matches the theoretical O(VC(H)log(k)/Œµ) prediction where k = Œò((1+1/Œ≥)^d).

2. **Discretization quality analysis**: For a fixed hypothesis class and perturbation type, systematically vary the discretization granularity of C and measure how the cover quality (max |C(x)|) affects both the theoretical bound and empirical robust loss on test data. Compare grid-based discretization against random sampling approaches.

3. **Tolerance sensitivity evaluation**: Fix sample size and hypothesis class, then vary Œ≥ from very small to large values. Plot the achieved robust accuracy versus Œ≥ and compare against the theoretical tolerance threshold. Identify the minimum Œ≥ value where the algorithm achieves acceptable robust performance, and assess whether this matches the predicted 1/(3(1+1/Œ≥)^d) threshold from the smoothing analysis.