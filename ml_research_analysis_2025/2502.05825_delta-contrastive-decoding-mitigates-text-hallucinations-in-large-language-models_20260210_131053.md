---
ver: rpa2
title: Delta -- Contrastive Decoding Mitigates Text Hallucinations in Large Language
  Models
arxiv_id: '2502.05825'
source_url: https://arxiv.org/abs/2502.05825
tags:
- delta
- hallucinations
- language
- tokens
- decoding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Delta -- Contrastive Decoding Mitigates Text Hallucinations in Large Language Models

## Quick Facts
- **arXiv ID**: 2502.05825
- **Source URL**: https://arxiv.org/abs/2502.05825
- **Authors**: Cheng Peng Huang; Hao-Yuan Chen
- **Reference count**: 9
- **Primary result**: Reduces hallucinations in context-rich QA tasks through inference-time contrastive decoding

## Executive Summary
Delta introduces an inference-only method for mitigating text hallucinations in large language models by contrasting outputs from original and randomly masked inputs. The approach works by subtracting logits from masked sequences, which tend to amplify hallucinated content, thereby suppressing implausible outputs while preserving context-grounded answers. Delta achieves significant improvements on context-rich QA benchmarks like SQuAD v2 (14.53 pp improvement in no-answer exact match) without requiring any model retraining.

## Method Summary
Delta applies random token masking (r_mask=0.7) to input sequences and computes contrastive logits by subtracting masked outputs from original outputs with scaling factor α=0.3. The method uses Adaptive Plausibility Constraints (APC) with β=0.1 to filter candidates and prevent semantically incorrect sequences. Implemented on Llama 3.1 8B Instruct with 4-bit quantization, Delta requires approximately twice the inference cost (two forward passes) but achieves substantial hallucination reduction specifically in context-rich tasks where explicit evidence is available.

## Key Results
- 14.53 percentage point improvement in no-answer exact match on SQuAD v2
- Reduces hallucinations in context-rich QA tasks without requiring model retraining
- Shows limited effectiveness on context-free tasks like CommonsenseQA and MMLU
- Demonstrates low variance across runs (standard deviation of 0.66 EM points)

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Logit Subtraction for Hallucination Suppression
Subtracting logits from masked inputs reduces the influence of hallucination-prone tokens by penalizing outputs amplified by masking. Random masking forces models to rely more heavily on pre-trained priors, which tend toward hallucinated content. The contrastive formula `(1+α)·logit_original - α·logit_masked` amplifies context-grounded tokens while suppressing those dependent on masking-induced ambiguity.

### Mechanism 2: Context-Grounding Signal Extraction
Tokens stable across masked and unmasked versions are more likely contextually grounded. The delta between masked and unmasked distributions reveals which tokens depend on context versus priors. By amplifying stable tokens, Delta prioritizes context-grounded answers over prior-based associations.

### Mechanism 3: Adaptive Plausibility Constraints for Coherence Preservation
Constraining token selection to high-probability candidates prevents contrastive manipulation from producing incoherent outputs. The APC filter maintains only tokens with probability ≥ β × max_probability, preventing the contrastive subtraction from pushing implausible tokens to the top of the distribution.

## Foundational Learning

- **Autoregressive Logit Interpretation**: Understanding how logits translate to token probabilities is essential for grasping contrastive manipulation. *Quick check*: Given logits [3.0, 1.0, 0.5] for tokens [A, B, C], what are the softmax probabilities? If you subtract [2.5, 1.5, 0.0] (masked logits) with α=0.5, what are the adjusted logits?

- **Hallucination Taxonomy (Priors vs. Context)**: Delta specifically targets hallucinations from ignoring context; understanding the distinction clarifies scope. *Quick check*: Why would a model answer "yellow" when asked about a "moldy banana's" color? Is this a prior-based or context-based hallucination?

- **Masking Ratio Tradeoffs**: r_mask=0.7 is used; understanding why masking too much or too little degrades performance. *Quick check*: For a 50-token input with r_mask=0.7, how many tokens are masked? What happens if you mask 95% instead?

## Architecture Onboarding

- **Component map**: Input Sequence → [Masking Module] → Masked Sequence → [Original Logit Computation] [Masked Logit Computation] → [Contrastive Adjuster] → [APC Filter (V_head)] → [Softmax Sampler] → Output Token

- **Critical path**:
  1. Tokenize input, track sequence length n
  2. Randomly select m = ⌊r_mask × n⌋ indices for masking (replace with MASK token)
  3. Run forward pass for both sequences (can parallelize)
  4. At each generation step t, compute contrastive logits per Equation 3
  5. Apply APC to constrain candidate set, then sample

- **Design tradeoffs**:
  - **Inference cost**: ~2× forward passes (original + masked); consider batching
  - **Higher α**: Stronger hallucination suppression but risks over-correcting valid outputs
  - **Higher r_mask**: More aggressive ambiguity injection but may remove essential context
  - **Temperature**: Delta shows larger gains with sampling (temperature=1) than greedy decoding

- **Failure signatures**:
  - **Zero improvement on short queries**: Expected if no explicit context provided
  - **Semantic drift**: β too low allowing implausible tokens after contrastive adjustment
  - **Degraded performance on reasoning tasks**: May indicate α too high, suppressing legitimate inference
  - **Inconsistent results across runs**: Random masking introduces variance; consider averaging multiple masks

- **First 3 experiments**:
  1. **Baseline replication on SQuAD v2**: Implement Delta with default parameters (r_mask=0.7, α=0.3, β=0.1), compare exact match and no-answer EM against baseline; validate ~6 pp improvement claim
  2. **Ablation sweep on α and r_mask**: Test α∈{0.1, 0.2, 0.3, 0.4, 0.5} × r_mask∈{0.3, 0.5, 0.7} on held-out set; paper reports low variance (std=0.66 EM) but validate on your model
  3. **Context-free vs. context-rich comparison**: Run Delta on both SQuAD (context-rich) and CommonsenseQA (context-free) to confirm the boundary condition where Delta stops helping

## Open Questions the Paper Calls Out

### Open Question 1
Can targeted or adaptive masking strategies (e.g., prioritizing proper nouns, key terms, or using POS-tagging to mask nouns/verbs) improve Delta's effectiveness over random masking? Authors state in Section 7: "Future research will focus on developing advanced and adaptive masking strategies. One promising direction is targeted masking, prioritizing critical tokens such as proper nouns and key terms rather than applying masking uniformly." Current implementation uses simple random masking.

### Open Question 2
Can Delta be extended to mitigate hallucinations in context-free tasks (e.g., CommonsenseQA, MMLU) that rely on parametric knowledge? Section 7 states: "its impact is limited in context-free tasks like CommonsenseQA and MMLU... These findings position Delta as a powerful solution tailored for context-dependent tasks." Delta's mechanism contrasts masked vs. unmasked context; without external context, the masking operation cannot create meaningful contrast.

### Open Question 3
Does Delta generalize to tasks beyond extractive QA, such as summarization, translation, or long-form generation? Evaluation is limited to four QA datasets; the method's applicability to other hallucination-prone tasks (abstractive summarization, dialogue) is untested. The paper does not discuss or experiment with non-QA tasks where hallucinations also occur.

### Open Question 4
How does model scale and architecture affect Delta's performance, and does the method benefit larger or different model families? Only Llama 3.1 8B Instruct with 4-bit quantization is tested; generalization to other models (e.g., GPT, Mistral) or larger scales is unknown. The experimental setup is fixed to one model; the impact of model capacity, training data, or architecture on Delta's gains is not analyzed.

## Limitations
- **Task boundary ambiguity**: Effectiveness limited to context-rich QA tasks where explicit textual evidence can be masked; unclear how it generalizes to other hallucination types
- **Masking scope uncertainty**: Paper doesn't specify whether masking should apply to entire input sequence or just context passage
- **APC parameter sensitivity**: Optimal β value not explored across different model scales, domains, or instruction styles

## Confidence
- **High confidence** in: The contrastive decoding mechanism itself and its effectiveness for reducing hallucinations in context-rich QA tasks
- **Medium confidence** in: The generalizability of these gains across different model architectures and tasks
- **Low confidence** in: The optimal parameter settings (α=0.3, r_mask=0.7, β=0.1) being universally applicable

## Next Checks
1. **Parameter sensitivity analysis**: Systematically vary α (0.1-0.5), r_mask (0.3-0.7), and β (0.05-0.2) on a held-out validation set to identify optimal combinations for different task types and model scales

2. **Cross-model generalization test**: Implement Delta on a different model architecture (e.g., Mistral 7B or GPT-3.5) and compare performance to the reported Llama 3.1 8B results

3. **Non-QA hallucination evaluation**: Test Delta on tasks designed to elicit different hallucination types: factual consistency checking, logical reasoning, and creative writing to determine if the mechanism generalizes beyond extractive QA hallucinations