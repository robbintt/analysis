---
ver: rpa2
title: Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance
arxiv_id: '2511.05311'
source_url: https://arxiv.org/abs/2511.05311
tags:
- data
- maintenance
- noise
- fleet
- records
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces an LLM-based agent framework to clean noisy
  maintenance logs in automotive predictive maintenance. A synthetic data generator
  creates logs with six types of noise, including typos, missing fields, and incorrect
  dates.
---

# Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance

## Quick Facts
- arXiv ID: 2511.05311
- Source URL: https://arxiv.org/abs/2511.05311
- Authors: Valeriu Dimidov; Faisal Hawlader; Sasan Jafarnejad; Raphaël Frank
- Reference count: 14
- Primary result: LLM-based agents achieve 83.7% error correction on typos and 100% on missing values using zero-shot prompting with structured tool calls

## Executive Summary
This paper introduces an LLM-based agent framework for cleaning noisy maintenance logs in automotive predictive maintenance. The approach uses zero-shot prompting with structured tool calls to classify and repair log entries, achieving strong performance on generic noise patterns while struggling with domain-specific anomalies. The framework demonstrates that pre-trained linguistic knowledge enables effective detection and repair of common data quality issues without requiring task-specific training examples.

## Method Summary
The framework employs zero-shot LLM agents equipped with database tools and a log cleaning API to process maintenance records. Agents receive records with schema context, query reference tables (fleet registry, service catalog, sensor data) via SQL tools, and output structured actions (accept, reject, or update single fields). A synthetic data generator creates controlled environments with six noise types, enabling systematic evaluation. The approach emphasizes autonomy through prompt-only configuration rather than demonstration-based learning.

## Key Results
- GPT-5 achieves 83.7% EDR/ECR on typo corrections and 100% on missing values
- Smaller models detect generative noise but struggle with corruptive noise repairs
- GPT-OSS-120B offers optimal price-latency-quality balance for production deployment
- Near-zero performance on domain-specific noise (wrong end dates, vehicle ID misalignment)

## Why This Works (Mechanism)

### Mechanism 1
Zero-shot LLM agents can detect and repair generic noise patterns (typos, missing fields) without explicit examples by leveraging pre-trained linguistic knowledge. The agent receives a noisy record with schema context, optionally queries reference tables (fleet registry, service catalog) via SQL tools, and maps observed anomalies to correction actions through semantic reasoning. Pre-trained patterns enable typo recognition and missing-field imputation without task-specific training.

### Mechanism 2
Structured tool-calling enables contextual validation against enterprise data sources that pure prompting cannot achieve. The agent queries the fleet registry to verify license plates, checks the service catalog for valid taxonomy hierarchies, and cross-references sensor data for temporal consistency. External lookups ground corrections in actual entity existence rather than plausible hallucinations.

### Mechanism 3
Generative noise (out-of-scope records, test entries) is easier to reject than corruptive noise is to repair because rejection requires only anomaly recognition, not precise field-level reconstruction. For generative noise, the agent detects semantic mismatch against known categories and issues `reject`. For corruptive noise, the agent must identify the specific corrupted field and generate the correct value—a harder task requiring both diagnosis and precise repair.

## Foundational Learning

- **Concept:** Zero-shot agentic reasoning
  - Why needed here: The paper explicitly prohibits few-shot examples; engineers must understand how to craft system prompts and tool specifications that elicit correct behavior without demonstration.
  - Quick check question: Can you write a prompt that specifies available tools, output schema, and task constraints without including solved examples?

- **Concept:** Noise taxonomy design
  - Why needed here: The framework's six noise types (corruptive vs. generative) determine which API action is appropriate; misclassification cascades into wrong corrections.
  - Quick check question: Given a maintenance record with a valid license plate but a non-existent component code, is this corruptive or generative noise?

- **Concept:** Cost-quality-latency tradeoffs in model selection
  - Why needed here: GPT-5 achieves best quality but costs 32× more than GPT-OSS-120B; deployment decisions require mapping error-tolerance budgets to model tiers.
  - Quick check question: If your pipeline processes 10,000 records/day with 1% acceptable error rate, which model tier minimizes cost while meeting SLA?

## Architecture Onboarding

- **Component map:** Synthetic Data Generator -> LLM Agent -> DB Tools -> Log Cleaning API -> Evaluation Layer
- **Critical path:** 1) Environment generation with noise injection 2) Record serialization and prompt construction 3) Agent tool invocation sequence (schema discovery -> validation queries -> action selection) 4) Structured output parsing and retry handling
- **Design tradeoffs:** Zero-shot vs. few-shot (autonomy vs. accuracy), single-field update constraint (evaluation simplicity vs. multi-field repair capability), synthetic vs. real data (controlled benchmarking vs. external validity)
- **Failure signatures:** 0% ECR on wrong end dates (M6) -> temporal reasoning requires domain-specific fine-tuning, <30% ECR on vehicle ID misalignment (M1) -> cross-table entity resolution fails without explicit training, smaller models detect generative noise but cannot correct corruptive noise -> use for rejection-only passes
- **First 3 experiments:** 1) Replicate benchmark on GPT-OSS-120B with your domain's service catalog to establish baseline EDR/ECR 2) Inject only M3 (typos) and M4 (missing values) to isolate achievable correction quality before tackling domain-specific noise 3) Add temporal-logic validators as pre-processing rules to filter M6 (wrong dates), measuring residual workload for the LLM agent

## Open Questions the Paper Calls Out

### Open Question 1
Does the LLM-agent cleaning pipeline maintain its detection and correction performance when applied to authentic, de-identified maintenance logs from industrial partners? The authors state in Section 7 and Section 8 that reliance on synthetic logs limits external validity and explicitly plan to "evaluate the agents using authentic maintenance logs obtained from industrial partners."

### Open Question 2
Can integrating temporal-logic validators or a hybrid rule-LLM architecture significantly improve the near-zero correction rates for domain-specific noise, such as wrong end dates? Section 8 proposes "integrating temporal-logic validators into the agent's toolset" and "adopting a hybrid rule–LLM architecture" to address the models' inability to correct temporal inconsistencies (M6) and entity associations.

### Open Question 3
How does agent performance change when the data generator incorporates complex noise types, specifically multi-field corruptions and inter-record contradictions? Section 8 notes that future work involves "expanded noise taxonomy that captures more complex errors, such as multi-field corruptions, time-series inconsistencies, [and] inter-record contradictions."

## Limitations

- Strong performance on generic noise (typos, missing values) but struggles with domain-specific patterns (wrong end dates, vehicle ID misalignment)
- Zero-shot approach shows limited generalizability without task-specific adaptation or fine-tuning
- Current framework processes records in isolation without cross-record context or pattern recognition

## Confidence

- **High confidence:** Generic noise detection and repair mechanisms (typos, missing values) work reliably with zero-shot agents, as evidenced by 83.7% EDR/ECR on typos and 100% on missing values across multiple models
- **Medium confidence:** Structured tool-calling effectively grounds corrections in enterprise data, though performance depends heavily on reference data quality and completeness
- **Low confidence:** The framework's ability to handle complex temporal reasoning and cross-entity validation without domain-specific fine-tuning, given near-zero performance on wrong end dates and vehicle ID misalignment

## Next Checks

1. Deploy the framework on real maintenance logs from a single vehicle type or plant to measure performance degradation from synthetic to real-world noise patterns
2. Implement a hybrid approach where rule-based validators handle temporal and cross-reference checks before LLM agent processing, measuring accuracy improvement
3. Conduct cost-benefit analysis comparing GPT-OSS-120B vs. GPT-5 for a production workload of 10,000 records/day, factoring in acceptable error rates and correction turnaround time requirements