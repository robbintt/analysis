---
ver: rpa2
title: 'Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis'
arxiv_id: '2510.16973'
source_url: https://arxiv.org/abs/2510.16973
tags:
- segmentation
- medical
- image
- arxiv
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review and meta-analysis mapped the rapid evolution
  of foundation models (FMs) in medical image analysis, categorizing studies into
  vision-only and vision-language FMs. It synthesized 139 VFMs and 82 VLFMs, revealing
  exponential growth since 2021, with segmentation dominating downstream tasks.
---

# Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis

## Quick Facts
- **arXiv ID**: 2510.16973
- **Source URL**: https://arxiv.org/abs/2510.16973
- **Reference count**: 40
- **Key outcome**: Mapped 139 VFMs and 82 VLFMs, revealing exponential growth since 2021, segmentation dominance, and challenges in domain adaptation, interpretability, fairness, and computational constraints.

## Executive Summary
This systematic review and meta-analysis comprehensively mapped the evolution of foundation models in medical image analysis, categorizing 221 studies into vision-only (139 VFMs) and vision-language (82 VLFMs) approaches. The analysis revealed exponential growth since 2021, with segmentation dominating downstream tasks and public datasets like MIMIC-CXR and CheXpert being most frequently used. VFMs focused on universal segmentation capabilities while VLFMs advanced multimodal alignment and reasoning. The review identified persistent challenges including domain adaptation, interpretability, fairness, and computational constraints, proposing future directions such as hybrid FM strategies, advanced training frameworks, robust evaluation, and equity considerations.

## Method Summary
The study conducted a PRISMA-style systematic review across PubMed, IEEE, ArXiv, and Google Scholar for records published until September 2025, using keywords including "foundation model," "self-supervised," and "SAM." Studies were screened based on exclusion criteria (non-medical applications, pure LLMs) and categorized into VFMs and VLFMs. Metadata extraction included backbone architecture, modality, downstream tasks, training strategies, and data size. Quantitative synthesis analyzed dataset utilization, task distribution, and loss function complexity, with statistical validation using Kruskal-Wallis tests on loss function diversity across years.

## Key Results
- **Exponential growth**: FM publications in medical imaging grew exponentially since 2021, with 77% published after 2022
- **Task dominance**: Segmentation was the most common downstream task (32.6%), followed by classification (23.5%) and detection (19.5%)
- **Dataset preferences**: MIMIC-CXR and CheXpert were the most frequently used public datasets for model training and evaluation

## Why This Works (Mechanism)

### Mechanism 1: Self-Supervised Pretraining Extracts Transferable Representations from Unlabeled Data
- **Core assumption**: Visual structures learned from pretext tasks are relevant to downstream clinical tasks
- **Evidence**: FMs leverage large corpora of labeled and unlabeled multimodal datasets to learn generalized representations that can be adapted to various downstream clinical applications with minimal fine-tuning
- **Break condition**: If pretraining data lacks diversity in pathology types, imaging protocols, or patient populations, learned representations will underperform on out-of-distribution clinical cases

### Mechanism 2: Vision-Language Contrastive Alignment Enables Zero-Shot Clinical Reasoning
- **Core assumption**: Clinical reports accurately describe image findings and the language encoder captures medical semantics
- **Evidence**: VFMs demonstrate strong zero- and few-shot performance across diverse medical imaging tasks, from segmentation to report generation
- **Break condition**: Noisy, incomplete, or inconsistent radiology reports degrade alignment quality; fine-grained localization often fails without region-text grounding

### Mechanism 3: Parameter-Efficient Fine-Tuning Bridges the Natural-to-Medical Domain Gap
- **Core assumption**: The pretrained backbone has already learned useful low-level features; only domain-specific adjustments are needed
- **Evidence**: SAMed adopts a parameter-efficient fine-tuning (PEFT) approach through low-rank adaptation (LoRA) layers, achieving segmentation accuracy comparable to full fine-tuning while significantly reducing training time and GPU memory usage
- **Break condition**: For modalities with fundamentally different physics, frozen backbones may lack relevant features—PEFT alone insufficient

## Foundational Learning

**Self-Supervised Learning Paradigms (Contrastive vs. Masked vs. Predictive)**
- Why needed: The paper organizes all FM pretraining into these three categories; understanding their tradeoffs is essential for choosing or designing a training strategy
- Quick check: Given a dataset of 10K unlabeled CT scans with paired radiology reports, which SSL approach would leverage both modalities?

**Vision Transformer (ViT) Architecture and Patch Embedding**
- Why needed: VFMs predominantly use ViT backbones; SAM, MedSAM, and most classification FMs are ViT-based
- Quick check: How does a ViT process a 512×512 chest X-ray, and what information is lost in patch-based tokenization?

**Contrastive Loss Functions (InfoNCE, CLIP-style)**
- Why needed: VLFMs are built on contrastive pretraining; understanding how these losses shape the embedding space is critical for debugging alignment failures
- Quick check: In a batch of 64 image-report pairs, how many negative samples does standard InfoNCE implicitly compare each positive pair against?

## Architecture Onboarding

**Component map:**
SAM-based VFM: Image encoder (ViT/CNN backbone) -> Prompt encoder (points, boxes) -> Mask decoder (segmentation)
VLFM: Vision encoder (ViT/ResNet) + Text encoder (BERT-family) -> Contrastive alignment layer -> Task-specific heads

**Critical path:**
1. Select pretrained backbone (SAM, MedSAM, CLIP, DINOv2) based on modality and task
2. Choose adaptation strategy: zero-shot inference vs. PEFT (LoRA, adapters) vs. full fine-tuning
3. Prepare paired data: images + masks (VFMs) or images + reports (VLFMs)
4. Design loss functions: contrastive for alignment, Dice/CE for segmentation, MLM for text understanding

**Design tradeoffs:**
- **Universal vs. Specialist**: Universal models generalize across tasks but may underperform on rare pathologies; specialist models excel in narrow domains but lack transfer breadth
- **2D vs. 3D**: 2D backbones are computationally efficient but miss inter-slice context for volumetric data; 3D adaptations require more memory and data
- **Prompt-based vs. End-to-end**: Prompt-based models enable interactive refinement but require user input; end-to-end models automate inference but may produce suboptimal masks

**Failure signatures:**
- Domain shift: Model trained on natural images produces poor segmentations on low-contrast medical images
- Hallucination in VLFMs: Report generation includes findings not present in the image
- Catastrophic forgetting: Full fine-tuning degrades zero-shot capabilities on original tasks
- Embedding collapse: Contrastive pretraining fails to separate classes when data is too homogeneous

**First 3 experiments:**
1. **Baseline zero-shot test**: Run pretrained SAM or MedSAM on a held-out medical dataset (50 CT scans with organ masks). Measure Dice score without any fine-tuning to quantify domain gap
2. **PEFT adaptation with LoRA**: Add LoRA adapters to the vision encoder, fine-tune on 100-500 labeled examples, and compare Dice improvement vs. full fine-tuning computational cost
3. **Cross-modal retrieval probe**: For a VLFM like BiomedCLIP, compute image-to-text retrieval accuracy on a chest X-ray dataset with paired reports. Visualize embedding space with t-SNE to check semantic clustering

## Open Questions the Paper Calls Out

**Open Question 1**: How can quantitative saliency benchmarks be developed to rigorously evaluate region-entity grounding in medical foundation models?
- **Basis**: Section 6.3.3 states that "quantitative saliency benchmarks, such as expert-annotated masks with defined evaluation points, are still uncommon in FM evaluation," necessitating a shift from qualitative heatmaps to reproducible metrics
- **Why unresolved**: Current evaluation relies heavily on qualitative visualizations like Grad-CAM, which are prone to over-interpretation and lack the reproducibility required for clinical validation
- **Evidence**: The publication of standardized benchmark datasets containing expert-annotated pathology masks paired with specific evaluation points for FM testing

**Open Question 2**: What strategies can effectively mitigate the utility-fairness trade-off in foundation models trained on geographically skewed data?
- **Basis**: Section 6.4 highlights the "utility–fairness trade-off" where bias mitigation strategies may reduce accuracy for majority groups, and notes the severe underrepresentation of Global South populations in training data
- **Why unresolved**: Current mitigation techniques often improve equity metrics at the expense of overall diagnostic performance, creating a barrier to clinical adoption where high accuracy is paramount
- **Evidence**: Development of adaptation strategies that simultaneously improve fairness metrics (e.g., demographic parity) and maintain or increase baseline AUROC across all represented populations

**Open Question 3**: What is the optimal architectural and training balance for hybrid foundation models to bridge the gap between universal generalizability and specialist precision?
- **Basis**: Section 6.1 discusses the dichotomy between "Universal vs Specialist FMs" and suggests "hybrid strategies" (e.g., PEFT, modular adapters) as a bridge, though the optimal integration method remains unclear
- **Why unresolved**: Universal models often lack sensitivity to domain-specific nuances, while specialist models are computationally expensive and suffer from limited transferability across institutions
- **Evidence**: Comparative studies of hybrid architectures (e.g., LoRA vs. MoE) measuring the trade-off between zero-shot cross-domain generalization and task-specific Dice scores

## Limitations

- **Methodological transparency**: The systematic review lacks complete transparency in search string formulation and screening criteria, making exact reproduction difficult
- **Performance validation**: Meta-analysis relies on self-reported model performance from primary studies without independent validation
- **Temporal bias**: Analysis may be biased toward recently published, high-performing models, potentially underrepresenting earlier foundational work

## Confidence

- **High confidence**: Exponential growth trend in FM publications since 2021, dominance of segmentation tasks, and most frequently used public datasets (MIMIC-CXR, CheXpert)
- **Medium confidence**: Effectiveness of PEFT strategies for domain adaptation, zero-shot performance claims, and the categorization of SSL paradigms
- **Low confidence**: Comparative performance claims between VFM and VLFM approaches, generalizability across all medical imaging modalities, and real-world clinical workflow integration feasibility

## Next Checks

1. Replicate the zero-shot segmentation performance of MedSAM on a held-out CT dataset (50-100 scans) and measure Dice scores against full fine-tuning baselines
2. Conduct a controlled experiment comparing CLIP-based VLFM retrieval accuracy on chest X-ray reports versus traditional supervised classifiers
3. Test the domain adaptation hypothesis by applying a SAM-based VFM trained on natural images to ultrasound datasets and measuring performance degradation without PEFT