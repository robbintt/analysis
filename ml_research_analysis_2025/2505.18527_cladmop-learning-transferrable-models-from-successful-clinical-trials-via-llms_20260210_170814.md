---
ver: rpa2
title: 'CLaDMoP: Learning Transferrable Models from Successful Clinical Trials via
  LLMs'
arxiv_id: '2505.18527'
source_url: https://arxiv.org/abs/2505.18527
tags:
- clinical
- trial
- branch
- cladmop
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLaDMoP introduces a pre-training approach for clinical trial outcome
  prediction that addresses limitations of task-specific loss functions by leveraging
  a large language model (LLM) branch for eligibility criteria and a lightweight Drug-Molecule
  branch with multi-level fusion. The model uses a "pair matching" proxy task and
  InfoNCE loss to learn generalizable representations, achieving up to 10.5% improvement
  in PR-AUC and 3.6% in ROC-AUC compared to state-of-the-art baselines on the Trial
  Outcome Prediction benchmark.
---

# CLaDMoP: Learning Transferrable Models from Successful Clinical Trials via LLMs

## Quick Facts
- arXiv ID: 2505.18527
- Source URL: https://arxiv.org/abs/2505.18527
- Reference count: 40
- Key result: Up to 10.5% improvement in PR-AUC and 3.6% in ROC-AUC for clinical trial outcome prediction

## Executive Summary
CLaDMoP addresses limitations in clinical trial outcome prediction by introducing a pre-training approach that leverages large language models and drug-molecule representations. The method uses a "pair matching" proxy task with InfoNCE loss to learn generalizable representations from successful clinical trials. The model achieves significant improvements over state-of-the-art baselines on the Trial Outcome Prediction benchmark, demonstrating both superior performance and better generalization to new diseases.

## Method Summary
CLaDMoP employs a dual-stream architecture with an LLM branch for processing eligibility criteria and a lightweight Drug-Molecule branch for handling drug and molecule information. The model uses multi-level fusion to combine these representations and learns through a self-supervised pair-matching proxy task with InfoNCE loss. This approach allows the model to learn transferable representations without requiring task-specific loss functions, addressing the limitation of traditional methods that struggle with generalization across different clinical trial contexts.

## Key Results
- Achieves up to 10.5% improvement in PR-AUC and 3.6% in ROC-AUC compared to state-of-the-art baselines
- Demonstrates strong performance on new diseases, with 13.63% higher accuracy in phase I and 8.02% in phase II compared to MEXA-CTP
- Shows improved generalizability through the pair-matching proxy task and InfoNCE loss framework

## Why This Works (Mechanism)
The method works by learning generalizable representations through self-supervised pre-training on successful clinical trials. The pair-matching proxy task encourages the model to learn meaningful relationships between clinical trial components without requiring labeled task-specific data. The dual-stream architecture with multi-level fusion allows the model to effectively combine textual eligibility criteria with drug-molecule information, while the InfoNCE loss provides a principled way to learn discriminative representations that transfer well to new clinical trial scenarios.

## Foundational Learning

1. **InfoNCE Loss**
   - Why needed: Provides contrastive learning objective for learning discriminative representations without labeled data
   - Quick check: Verify the temperature parameter (Ï„) is properly tuned and the in-batch negative sampling is sufficient for the dataset size

2. **Multi-level Fusion Architecture**
   - Why needed: Combines different types of information (textual and molecular) effectively
   - Quick check: Confirm the fusion layers are properly aligned and the information flow between streams is balanced

3. **Pair Matching Proxy Task**
   - Why needed: Enables self-supervised learning without requiring task-specific labeled data
   - Quick check: Validate that the matching pairs are correctly constructed and the task difficulty is appropriate

4. **Dual-stream Design**
   - Why needed: Separates processing of eligibility criteria from drug-molecule information for specialized feature extraction
   - Quick check: Ensure both streams maintain their specialized features before fusion

## Architecture Onboarding

**Component Map**: Eligibility Criteria (LLM) -> Fusion Layer -> Output, Drug-Molecule -> Fusion Layer -> Output

**Critical Path**: The critical path involves the dual-stream processing where eligibility criteria pass through the LLM branch, drug-molecule information through the specialized branch, both streams converge at multi-level fusion layers, and the combined representation is used for prediction through the pair-matching task with InfoNCE loss.

**Design Tradeoffs**: The model trades computational complexity for better generalization by using a dual-stream architecture instead of a single unified model. The lightweight Drug-Molecule branch reduces computational overhead while maintaining effectiveness. The choice of max-pooling for token aggregation may lose fine-grained information but provides computational efficiency.

**Failure Signatures**: Performance degradation may occur when eligibility criteria are particularly complex or when drug-molecule relationships are non-standard. The model may struggle with clinical trials that have unusual combinations of eligibility requirements or novel drug mechanisms not well-represented in training data.

**First Experiments**:
1. Verify the pair-matching accuracy on held-out pairs to ensure the proxy task is working as intended
2. Test the model's ability to distinguish between positive and negative clinical trial pairs using the InfoNCE loss
3. Evaluate the individual contributions of the LLM and Drug-Molecule branches through ablation studies

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Heavy reliance on in-batch negative sampling may not scale well to larger datasets
- Use of max-pooling may lose important fine-grained information in token-level representations
- Limited experimental validation for claims about generalization to completely unseen diseases

## Confidence

**High Confidence**: Technical implementation of pair-matching proxy task and InfoNCE loss is clearly described and represents a reasonable approach. Architectural design is well-specified and reproducible.

**Medium Confidence**: Reported performance improvements are based on comparisons with baselines, but evaluation methodology has some limitations. New disease performance shows promise but requires additional validation.

**Low Confidence**: Claims about generalization to completely unseen diseases are not fully supported by experimental evidence. Practical utility for real-world clinical trial optimization is not demonstrated.

## Next Checks
1. Conduct ablation studies removing the LLM branch or InfoNCE loss to quantify their individual contributions
2. Evaluate the model on a broader range of truly unseen diseases and clinical trial types across different therapeutic areas
3. Test model predictions against actual clinical trial outcomes from independent sources not used in training or validation