---
ver: rpa2
title: 'Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window'
arxiv_id: '2510.08276'
source_url: https://arxiv.org/abs/2510.08276
tags:
- tornado
- tool
- earthquake
- historical
- president
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of training deep search agents
  capable of handling long-horizon, multi-turn interactions. The authors identify
  two key limitations: insufficient task complexity in existing datasets and context
  management issues that limit interaction depth.'
---

# Beyond Turn Limits: Training Deep Search Agents with Dynamic Context Window

## Quick Facts
- arXiv ID: 2510.08276
- Source URL: https://arxiv.org/abs/2510.08276
- Reference count: 40
- Key result: DeepMiner-32B achieves 33.5% accuracy on BrowseComp-en, nearly doubling previous open-source agent performance

## Executive Summary
This paper addresses the challenge of training deep search agents capable of handling long-horizon, multi-turn interactions. The authors identify two key limitations: insufficient task complexity in existing datasets and context management issues that limit interaction depth. To overcome these challenges, they propose DeepMiner, which uses reverse construction of complex QA pairs from authentic web sources and introduces a dynamic context window mechanism that selectively compresses tool responses while preserving assistant reasoning traces. Through reinforcement learning on Qwen3-32B, DeepMiner-32B achieves 33.5% accuracy on BrowseComp-en, nearly doubling the performance of previous open-source agents, and enables sustained interactions of nearly 100 turns within standard 32k context length.

## Method Summary
The authors address the challenge of training search agents for long-horizon, multi-turn web-based QA requiring deep reasoning (verification, backtracking, subgoal decomposition). Their approach involves two key innovations: reverse construction of complex QA pairs from web sources with multi-source synthesis requirements, and a dynamic sliding window context management system. The training pipeline uses Qwen3-32B base with thinking mode enabled, first applying SFT (batch=256, LR=1e-5) then RL with GRPO (batch=32, LR=2e-6, 8 rollouts/question). The dynamic sliding window preserves assistant reasoning traces while compressing tool responses with placeholders, enabling sustained interactions within 32k context limits.

## Key Results
- DeepMiner-32B achieves 33.5% accuracy on BrowseComp-en benchmark
- Performance nearly doubles previous open-source agent results
- Enables sustained interactions of nearly 100 turns within standard 32k context length
- Demonstrates effectiveness across multiple benchmarks including BrowseComp-zh, XBench-DeepSearch, and GAIA

## Why This Works (Mechanism)
The paper's success stems from addressing both data quality and context management limitations. The reverse construction pipeline creates complex questions requiring synthesis from ≥4 sources, while the dynamic sliding window mechanism solves the context explosion problem by compressing distant tool responses while preserving assistant reasoning traces. This allows the model to maintain long-term coherence through assistant turns while managing token constraints, enabling sustained multi-turn interactions that previous approaches couldn't achieve.

## Foundational Learning
- Reverse construction of QA pairs - needed to create complex multi-source questions; quick check: verify generated questions require ≥4 source synthesis
- Dynamic sliding window context management - needed to prevent context overflow while preserving reasoning; quick check: confirm assistant traces remain accessible after tool compression
- GRPO reinforcement learning - needed for optimizing long-horizon decision making; quick check: verify trajectory-level advantages are correctly computed and propagated
- Multi-sequence construction for SFT - needed to train each assistant response exactly once; quick check: ensure masking prevents duplicate training of identical responses
- Tool response compression with placeholders - needed to maintain context while reducing token count; quick check: verify compressed tool outputs can be regenerated if needed

## Architecture Onboarding
- Component map: Web Search -> Fetch/Paginate -> Find -> Dynamic Window Manager -> Qwen3-32B Agent -> LLM Judge
- Critical path: Question reception → Tool selection → Response generation → Dynamic window update → Next turn
- Design tradeoffs: Compressing tool responses vs. potential loss of detail for deep verification; assistant trace preservation vs. token budget constraints
- Failure signatures: Context explosion despite sliding window (assistant reasoning grows too long), training-inference mismatch in window states, compressed tool outputs insufficient for verification
- First experiments: 1) Implement sliding window and test on 100-turn trajectory for context overflow prevention, 2) Build 3-tool suite and verify fetch pagination works correctly, 3) Test reverse construction pipeline on small entity set to validate question difficulty filtering

## Open Questions the Paper Calls Out
None

## Limitations
- Context management trade-off: compressed tool responses limit deep verification capabilities despite enabling longer interactions
- Implementation details underspecified: exact prompts for question generation, obfuscation, and filtering criteria remain unclear
- Limited comparison scope: performance claims based primarily on BrowseComp-en without establishing clear state-of-the-art margins across all evaluated benchmarks

## Confidence
- High confidence in technical feasibility of sliding window approach and basic implementation
- Medium confidence in training data construction methodology due to underspecified filtering criteria
- Medium confidence in performance claims given evaluation methodology and limited comparison set

## Next Checks
1. **Context Management Validation**: Implement sliding window mechanism and verify assistant reasoning traces remain accessible while tool responses are correctly compressed; log token distributions across 100-turn trajectories to confirm prevention of context overflow while maintaining sufficient reasoning information.

2. **Data Pipeline Replication**: Reconstruct reverse construction pipeline using described methodology; generate small validation set (50-100 questions) and test direct search solvability and zero-shot LLM performance to verify filtering criteria produce appropriately challenging multi-source questions.

3. **Training-Inference Consistency Check**: During RL rollouts, record sliding window state at each turn position; after training, generate inference trajectories on held-out questions and compare window states at identical turn positions to ensure consistent context management patterns between training and deployment.