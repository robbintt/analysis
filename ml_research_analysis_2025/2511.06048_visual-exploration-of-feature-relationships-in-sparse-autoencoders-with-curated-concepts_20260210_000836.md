---
ver: rpa2
title: Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated
  Concepts
arxiv_id: '2511.06048'
source_url: https://arxiv.org/abs/2511.06048
tags:
- features
- arxiv
- mapper
- sparse
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of visualizing relationships
  among the vast number of features extracted by sparse autoencoders (SAEs) from large
  language models, which becomes intractable due to sheer scale and the presence of
  polysemantic or low-quality features. To overcome limitations of conventional dimensionality
  reduction methods like UMAP, which introduce distortions and overplotting, the authors
  propose a focused exploration framework that prioritizes curated concept sets and
  their corresponding SAE features.
---

# Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts

## Quick Facts
- arXiv ID: 2511.06048
- Source URL: https://arxiv.org/abs/2511.06048
- Reference count: 40
- Primary result: Introduces a topology-based visual encoding using ball mapper to enable interpretable analysis of SAE behavior across model layers, overcoming limitations of UMAP visualizations.

## Executive Summary
This paper addresses the challenge of visualizing relationships among the vast number of features extracted by sparse autoencoders (SAEs) from large language models. The authors propose a focused exploration framework that prioritizes curated concept sets and their corresponding SAE features, using a topology-based visual encoding called ball mapper. The framework preserves local and global structural properties while enabling interactive analysis of SAE behavior across model layers. Results demonstrate that the approach facilitates deeper insight into concept representation and feature relationships.

## Method Summary
The method retrieves SAE features by computing cosine similarity between concept embeddings and auto-generated feature explanations from Neuronpedia, selecting features above a 0.5 threshold. Ball mapper constructs a graph where nodes represent local clusters (balls of radius ε) and edges indicate overlapping membership, preserving neighborhood structures that UMAP distortions warp. The system integrates ball mapper with dimensionality reduction in an interactive visualization called SAE Semantic Explorer, enabling targeted analysis of SAE behavior across model layers. Parameters include max node size of 5, radius reduction factor η=0.9, and adaptive radius adjustment until size constraints are met.

## Key Results
- The framework successfully overcomes UMAP limitations by preserving local neighborhood structures through ball mapper topology
- Layer-wise analysis reveals evolution from mixed/local clusters in early layers to separated/integrated structures in deeper layers
- Cross-layer comparison demonstrates persistent local semantic proximity across model layers

## Why This Works (Mechanism)

### Mechanism 1
Filtering the massive SAE feature space via human-curated concepts improves signal-to-noise ratio for interpretation. The system retrieves features by computing cosine similarity between concept embeddings and auto-generated feature explanations, selecting only those above a threshold (default >0.5). This bypasses the need to visualize millions of potentially polysemantic or low-quality features. Assumption: The auto-generated textual explanations for features accurately reflect the feature's actual semantic role. Evidence: abstract mentions overcoming limitations due to polysemantic or low-quality features; section 3 describes the retrieval mechanism. Break condition: If LLM-generated explanations hallucinate or produce generic descriptions, the retrieval step will fetch irrelevant features.

### Mechanism 2
Topological graph construction (Ball Mapper) preserves local neighborhood structures that 2D projections (UMAP) distort. Instead of projecting points, Ball Mapper constructs a graph where nodes are local clusters (balls of radius ε) and edges indicate overlapping membership. This explicitly encodes "neighborhood" as a discrete structural property rather than a continuous distance that can be warped by projection. Assumption: A single radius ε (or adaptive max node size) can meaningfully capture the local structure of the manifold without over-fragmenting or over-smoothing it. Evidence: abstract mentions preserving local and global structural properties; section 3 describes how edges denote overlaps between balls, mitigating distortions. Break condition: If the feature space is extremely sparse or the radius is poorly tuned, the graph will either become a dense hairball or a sea of disconnected nodes.

### Mechanism 3
Cross-layer comparison of specific concept clusters reveals the evolution of semantic abstraction. By holding the concept set constant and varying the model layer, the system visualizes how feature representations shift from mixed/local clusters in early layers to separated/integrated structures in deeper layers. Assumption: The SAEs at different layers are learning comparable representations such that "feature 1" at layer N relates meaningfully to the semantic neighborhood at layer N+1. Evidence: abstract mentions layer-wise evolution of concept relationships and persistent local semantic proximity; section 4 describes early layers producing densely clustered representations while deeper layers exhibit clearer intra-category grouping. Break condition: If SAE features are unstable or fail to find "canonical units," the observed trajectory may be an artifact of the encoder rather than the model's semantics.

## Foundational Learning

- **Concept:** **Sparse Autoencoders (SAEs)**
  - **Why needed here:** The entire visualization relies on SAEs decomposing LLM activations into interpretable features. Without understanding that SAEs attempt to solve "superposition" by expanding dimensions, the feature lists are just noise.
  - **Quick check question:** Can you explain why we need an SAE instead of just visualizing the raw residual stream activations?

- **Concept:** **Topological Data Analysis (Mapper Algorithms)**
  - **Why needed here:** The core innovation is the Ball Mapper view. You must understand that nodes represent *clusters* of points and edges represent *shared membership*, not simple distance.
  - **Quick check question:** If two points are in the same Ball Mapper node, what does that imply about their relationship in the original high-dimensional space?

- **Concept:** **The "Superposition" Hypothesis**
  - **Why needed here:** The paper operates on the assumption that LLMs represent more features than they have dimensions. The "focused exploration" exists because the resulting SAE feature set is too large to view all at once.
  - **Quick check question:** Why does visualizing *all* SAE features simultaneously typically result in an unintelligible plot (besides just the number of points)?

## Architecture Onboarding

- **Component map:** Backend/Data Source (Neuronpedia API) -> Preprocessing (cosine similarity search) -> Core Algorithm (Ball Mapper construction) -> Frontend (coordinated views)

- **Critical path:** User selects Concept Set → System retrieves top-k similar features per layer → Ball Mapper constructs graph using radius ε → Frontend renders graph alongside UMAP projection

- **Design tradeoffs:**
  - UMAP vs. Ball Mapper: UMAP provides familiar global gestalt but distorts local neighbors; Ball Mapper preserves local truth but can be structurally complex to navigate
  - Radius ε: A fixed radius is consistent but may fail if feature density varies wildly across layers; the adaptive variant (capping node size) helps but introduces parameter sensitivity

- **Failure signatures:**
  - "Giant Component": The Ball Mapper graph is one massive connected blob (Radius too large or similarity threshold too low)
  - Empty Retrieval: No features found for a concept (Threshold too high or poor concept explanation match)
  - Visual Mismatch: UMAP shows two points close together, but they are in totally different Ball Mapper nodes (UMAP distortion confirmed)

- **First 3 experiments:**
  1. Sanity Check: Load a distinct concept (e.g., "colors"). Verify that the retrieved features actually relate to colors by reading the Feature View
  2. Parameter Sensitivity: For a fixed layer/concept, adjust the similarity threshold. Observe how the Ball Mapper graph connectivity changes (does it fragment or grow?)
  3. Distortion Detection: Find a "nearest neighbor" pair in the UMAP view, then check if they share a Ball Mapper node. If not, investigate why UMAP misled you

## Open Questions the Paper Calls Out

### Open Question 1
Can large language models effectively generate coherent, context-aware explanations for ball mapper nodes representing clusters of SAE features? Basis: authors state they plan to leverage LLMs to automatically generate richer, context-aware explanations for mapper nodes. Why unresolved: current system relies on individual feature explanations; aggregating these into a unified node summary is proposed but not yet implemented or validated. Evidence: developing an aggregation method and evaluating its output against human-generated summaries of the same feature clusters.

### Open Question 2
How does the noise inherent in auto-interpretability affect the stability and reliability of the topological structures generated by the ball mapper? Basis: authors acknowledge a key limitation that the reliability of identified features depends heavily on the quality of their automatically generated explanations. Why unresolved: the framework relies on these explanations to retrieve features, but it is unclear how explanation errors propagate into structural distortions within the visualization. Evidence: a sensitivity analysis varying the quality of input explanations and measuring the resulting variance in the ball mapper graph topology.

### Open Question 3
Does the topological proximity of features in the ball mapper view provide actionable signal for downstream tasks like model editing or steering? Basis: authors anticipate the tool will support "feature-level intervention" and "model editing," but the paper only demonstrates visual interpretation, not functional intervention. Why unresolved: visual clustering implies semantic relationship, but it remains untested whether manipulating features within a ball mapper node yields predictable changes in model behavior. Evidence: experiments comparing the efficacy of steering vectors derived from ball mapper clusters versus those derived from standard UMAP clusters or random selection.

## Limitations
- The system's effectiveness depends on the quality of LLM-generated feature explanations, which may be inaccurate or generic
- Ball mapper implementation requires careful parameter tuning to avoid disconnected graphs or giant components
- Layer-wise evolution observations may reflect SAE-specific feature representations rather than canonical model semantics

## Confidence
- Core visualization claims: Medium confidence (depends on explanation quality and parameter tuning)
- Local structure preservation: Medium confidence (topology preservation varies with concept sets and layers)
- Layer-wise evolution observations: Medium confidence (may reflect SAE instability rather than canonical semantics)

## Next Checks
1. Test feature retrieval with deliberately vague or multi-meaning concepts to quantify semantic drift in explanation matching
2. Compare ball mapper connectivity across multiple radius settings to establish parameter sensitivity bounds
3. Cross-validate observed layer-wise feature evolution patterns with independently trained SAEs on the same model