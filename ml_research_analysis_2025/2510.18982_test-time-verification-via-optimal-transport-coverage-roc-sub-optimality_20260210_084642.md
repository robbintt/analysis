---
ver: rpa2
title: 'Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality'
arxiv_id: '2510.18982'
source_url: https://arxiv.org/abs/2510.18982
tags:
- sub-optimality
- coverage
- sampling
- transport
- verifier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper analyzes test-time scaling through the lens of optimal
  transport, framing verifiable test-time scaling as a sampling problem where the
  goal is to transport a generator''s proposal distribution to an optimal target distribution
  using a potentially imperfect verifier. The study reveals three distinct regimes
  in the sub-optimality-coverage curve: transport (sub-optimality increases with coverage),
  policy improvement (sub-optimality decreases with coverage depending on verifier''s
  Youden''s index), and saturation (sub-optimality plateaus).'
---

# Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality

## Quick Facts
- arXiv ID: 2510.18982
- Source URL: https://arxiv.org/abs/2510.18982
- Reference count: 40
- One-line result: Three-regime characterization of sub-optimality vs coverage curves for test-time verification, with sequential rejection sampling optimal for low coverage and batched best-of-N optimal for high coverage.

## Executive Summary
This paper analyzes test-time scaling through the lens of optimal transport, framing verifiable test-time scaling as a sampling problem where the goal is to transport a generator's proposal distribution to an optimal target distribution using a potentially imperfect verifier. The study reveals three distinct regimes in the sub-optimality-coverage curve: transport (sub-optimality increases with coverage), policy improvement (sub-optimality decreases with coverage depending on verifier's Youden's index), and saturation (sub-optimality plateaus). Two classes of sampling algorithms - sequential and batched - are analyzed, with theoretical results showing that SRS and SMC achieve the same computational complexity and sub-optimality, while AiC violates coverage constraints in low-coverage regimes. Empirical results across Qwen, Llama, and Gemma models confirm the theoretical predictions, demonstrating that rejection sampling-type algorithms are advantageous under low coverage while best-of-N approaches excel under liberal coverage.

## Method Summary
The paper formulates test-time verification as an optimal transport problem where a generator's proposal distribution μ must be transported to an optimal target distribution ν* (defined by ground-truth verifier) under a coverage constraint χ²(μ‖ν) ≤ β−1. The framework assumes access to a ground-truth verifier (r*) and an approximate verifier (r̂) with known ROC characteristics. The analysis derives the optimal policy π* and characterizes its sub-optimality across three regimes determined by the interaction between coverage β and verifier accuracy (Youden's index J). Five sampling algorithms are analyzed: Accept-if-Correct (AiC), Sequential Rejection Sampling (SRS), Sequential Maximal Coupling (SMC), Best-of-N (BoN), and Batch Rejection Sampling (BRS). The methods are validated on GSM8K benchmark using Qwen3, Llama-3.1, and Gemma-3 models, with verifiers constructed via pattern matching and controlled TPR/FPR.

## Key Results
- The sub-optimality-coverage curve exhibits three regimes: transport (O(√β) growth), policy improvement (decreasing sub-optimality), and saturation (constant sub-optimality)
- SRS and SMC achieve identical computational complexity E[τ] = (1∧m_β(s_ver))/s_ver and identical sub-optimality performance
- AiC violates coverage constraints for β < 1/s_ver, while BoN requires N ≤ N_max(β) to satisfy coverage
- Empirical results confirm theoretical predictions: rejection sampling algorithms excel in transport regime, while best-of-N dominates in saturation regime
- Verifier Youden's index J is the critical mediator determining whether policy improvement regime offers performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Test-time verification can be formulated as an optimal transport problem where sub-optimality decomposes into transport cost plus policy improvement.
- Mechanism: The generator's proposal distribution μ is "transported" to a target distribution ν* (defined by ground-truth verifier) via a coupling ρ. Sub-optimality = OTC(β) + policy_improvement_term, where OTC(β) captures intrinsic difficulty of transport under coverage constraint β.
- Core assumption: The optimal policy must satisfy an ℓ₁-type coverage constraint (χ²-divergence ≤ β−1), meaning it cannot arbitrarily deviate from the reference LLM's distribution.
- Evidence anchors:
  - [abstract]: "We frame verifiable test-time scaling as a transport problem...characterizes the interaction of coverage, ROC, and sub-optimality"
  - [Section 2, p.4-5]: Defines coverage constraint Π(β|x), optimal policy π*, and sub-optimality SubOpt(A) = ∫r*dν* − ∫r*dν_A
  - [Lemma 3.1, p.6]: OTC(β) = (1∧m_β(s_r*)) − s_r* provides closed-form transport cost
- Break condition: If the target distribution ν* has no overlap with proposal μ (zero coverage), transport becomes infeasible and sub-optimality diverges.

### Mechanism 2
- Claim: The sub-optimality-coverage curve exhibits three distinct regimes determined by the interaction between coverage constraint β and verifier accuracy (Youden's index J).
- Mechanism: (1) **Transport regime** (β ≤ 1/s_r* ∧ 1/s_ver): Sub-optimality grows as O(√β), dominated by transport cost. (2) **Policy improvement regime**: Sub-optimality may decrease with coverage depending on J = TPR − FPR. (3) **Saturation regime** (β > max thresholds): Sub-optimality plateaus at OTC(β)·(1 − s_r*/s_ver·J).
- Core assumption: Verifier imperfection is characterized by its ROC curve, specifically Youden's index J, which quantifies discriminative power between correct and incorrect responses.
- Evidence anchors:
  - [abstract]: "uncovers that the sub-optimality–coverage curve exhibits three regimes...transport...policy improvement...saturation"
  - [Theorem 3.6, p.8]: SubOpt(A) = OTC(β)·(1−αJ) with α depending on regime and β
  - [Section 3.1, p.8]: "In the transport regime, sub-optimality grows as O(√β)...In the saturation regime, sub-optimality remains constant"
- Break condition: If J ≤ 0 (verifier no better than random), policy improvement regime offers no benefit regardless of coverage.

### Mechanism 3
- Claim: Sequential rejection sampling (SRS) and sequential maximal coupling (SMC) achieve identical computational complexity and sub-optimality, while Accept-if-Correct (AiC) violates coverage constraints in low-coverage regimes.
- Mechanism: SRS and SMC both require E[τ_A] = (1∧m_β(s_ver))/s_ver proposals on average. AiC ignores coverage constraint β, leading to χ²(μ‖ν_AiC) = 1/s_ver − 1 which exceeds β−1 when β < 1/s_ver.
- Core assumption: The sampling algorithm has access to an approximate verifier Ŝ but must estimate the mass s_ver = μ(Ŝ) that the reference policy places on the verifier's acceptance set.
- Evidence anchors:
  - [Theorem 3.5, p.7-8]: "computational complexity is identical...given by E[τ_A] = (1∧m_β(s_ver))/s_ver"
  - [Theorem 3.3, p.7]: "AiC policy does not satisfy the coverage constraint for β < 1/s_ver"
  - [Section 4, p.10-11]: Empirical results on Qwen/Llama/Gemma confirm theoretical predictions; AiC shows constraint violations in transport regime
- Break condition: If s_ver is severely misspecified, SRS/SMC acceptance probabilities become unreliable, potentially degrading to worse-than-AiC performance.

## Foundational Learning

- Concept: **χ²-divergence and coverage constraints**
  - Why needed here: The paper's central constraint limits how far the optimal policy can deviate from the reference LLM, expressed as χ²(μ‖ν) ≤ β−1. Understanding this is essential for interpreting why certain algorithms violate constraints.
  - Quick check question: Given proposal μ with mass 0.3 on correct set and β = 2, what is the maximum mass the optimal policy can place on that set? (Answer: m_β(0.3) = 0.3 + √(0.3×0.7×1) ≈ 0.74)

- Concept: **Youden's index (J = TPR − FPR)**
  - Why needed here: This single scalar captures verifier quality and directly determines policy improvement potential. The paper shows sub-optimality scales with (1−αJ), making J the critical mediator between coverage and performance gains.
  - Quick check question: A verifier has TPR=0.8, FPR=0.3. What is J, and does higher J help or hurt in the policy improvement regime? (Answer: J=0.5; higher J reduces sub-optimality)

- Concept: **Rejection sampling with unknown likelihood ratios**
  - Why needed here: Standard rejection sampling requires the target-to-proposal density ratio. This paper addresses the realistic setting where only an approximate verifier provides binary feedback, requiring modified acceptance rules (SRS envelope M, estimated Radon-Nikodym derivative η̂).
  - Quick check question: Why can't we directly apply standard rejection sampling in test-time verification? (Answer: We lack access to the true target distribution ν* and its density ratio dν*/dμ)

## Architecture Onboarding

- Component map:
  - Generator (reference LLM π_ref) -> Produces proposal distribution μ over responses
  - Ground-truth verifier r* -> Binary oracle defining correct set S* (unit tests, gold solutions) — unavailable at test time
  - Approximate verifier r̂ -> Practical verifier with TPR/FPR imperfections, defines Ŝ
  - Sampling algorithm -> Sequential (AiC, SRS, SMC) or Batched (BoN, BRS) — implements transport plan from μ to ν̂
  - Coverage controller -> Hyperparameter β constraining χ²-divergence; envelope M for rejection sampling

- Critical path:
  1. Estimate s_r* (reference mass on ground-truth correct set) and s_ver (mass on approximate verifier's set) — these determine regime boundaries
  2. Choose β based on acceptable deviation from reference policy (smaller β = more conservative)
  3. Select algorithm: SRS/SMC for low-coverage (transport regime), BoN for high-coverage (saturation regime), BRS for intermediate
  4. Configure envelope M = max{(1/s_ver ∧ m_β(s_ver)/s_ver), (0∨(1−m_β(s_ver))/(1−s_ver))} for SRS/BRS

- Design tradeoffs:
  - **Sequential vs. Batched**: Sequential minimizes expected proposals but requires serial generation; batched enables parallel GPU utilization but wastes samples when N < N_max
  - **AiC vs. SRS/SMC**: AiC has constant complexity 1/s_ver but violates coverage when β < 1/s_ver; SRS/SMC respect coverage with complexity (1∧m_β(s_ver))/s_ver
  - **BoN vs. BRS**: BoN requires N ≤ N_max(β) to respect coverage (infeasible for small β); BRS works for all N but has higher constant-factor sub-optimality

- Failure signatures:
  - **Negative sub-optimality** (better than skyline): BoN with N > N_max violates coverage constraint — check χ²(ν_BoN‖μ)
  - **Sub-optimality not decreasing with N**: Verifier J ≈ 0 (random guessing) — verify ROC curve quality
  - **SRS/SMC requiring many proposals**: s_ver severely overestimated — recalibrate envelope M
  - **SMC underperforming SRS**: Assumed s < true s_ver (over-conservative envelope) — see ablation p.11

- First 3 experiments:
  1. **Validate regime boundaries**: On GSM8K subset, estimate s_r* and s_ver, sweep β from 1.0 to 5.0, plot sub-optimality curve. Verify three-regime shape matches Theorem 3.6 predictions (transport: O(√β) growth; policy improvement: decreasing; saturation: flat).
  2. **Compare sequential algorithms**: Run AiC, SRS, SMC across β range. Confirm AiC violates coverage (χ² > β−1) for small β, while SRS/SMC respect constraint. Measure empirical E[τ] and compare to 1/s_ver (AiC) vs (1∧m_β(s_ver))/s_ver (SRS/SMC).
  3. **Determine algorithm selection rule**: Fix compute budget (e.g., 20 proposals), compare BRS with optimal N vs. SRS sequential generation. Identify crossover point in β where BRS becomes preferable (expected: high β regime where batched efficiency dominates).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the three-regime structure of sub-optimality generalize to non-binary, general reward models?
- Basis in paper: [explicit] Section 5 states that moving "beyond verifiable rewards toward general reward models for inference-time alignment is an important next step."
- Why unresolved: The current theoretical analysis relies on the binary structure of the verifier (set-membership) to derive the closed-form optimal policy (Theorem 2.1) and the resulting sub-optimality curves.
- What evidence would resolve it: Theoretical derivation of sub-optimality regimes for soft reward distributions, or empirical verification that the transport/policy-improvement/saturation regimes persist with continuous rewards.

### Open Question 2
- Question: How can algorithms sample from a target distribution when the target-to-proposal likelihood ratio is unknown and must be estimated from samples?
- Basis in paper: [explicit] Section 5 highlights the "fundamental open problem" of sampling when the target-to-proposal likelihood ratio is "partially or fully unknown and must be estimated from samples."
- Why unresolved: Current algorithms (SRS, SMC) assume access to the mass $s_{ver}$, and the ablation study shows performance degrades with misspecification.
- What evidence would resolve it: An algorithm that explicitly balances exploration (estimating the likelihood ratio) with exploitation (sampling) while maintaining provable coverage constraints.

### Open Question 3
- Question: How do the transport regimes change under difference-based coverage constraints (e.g., Total Variation distance) rather than ratio-based ($\chi^2$) constraints?
- Basis in paper: [explicit] Section 5 notes that "extending from ratio-based to difference-based coverage remains unexplored."
- Why unresolved: The boundaries of the transport, policy improvement, and saturation regimes are derived specifically from the geometry of the $\chi^2$-ball constraint defined in Equation (1).
- What evidence would resolve it: A theoretical analysis of the optimal transport cost and sub-optimality curves under an $L_p$ or Total Variation coverage constraint.

## Limitations

- The analysis assumes access to ground-truth verifier's mass s_r* and approximate verifier's mass s_ver for computing regime boundaries and envelope parameters
- The theoretical framework focuses on binary reward structures (correct/incorrect), limiting direct applicability to more nuanced scoring systems
- The coverage constraint using χ²-divergence may be overly conservative for some applications where moderate deviation from the reference distribution is acceptable

## Confidence

**High confidence**: The three-regime characterization (transport, policy improvement, saturation) and the fundamental relationship between sub-optimality, coverage β, and verifier Youden's index J. The computational complexity results for SRS and SMC (E[τ] = (1∧m_β(s_ver))/s_ver) are mathematically rigorous and empirically validated.

**Medium confidence**: The practical guidance for algorithm selection across regimes assumes idealized conditions. The crossover points between sequential and batched approaches may shift in practice due to implementation details, hardware constraints, and non-ideal verifier performance.

**Low confidence**: The assumption that logprob-based normalization provides reliable estimates of s_r* and s_ver in diverse domains. The GSM8K experiments use pattern-matching verifiers that may not generalize to domains requiring deeper semantic understanding.

## Next Checks

1. **Regime boundary validation**: Implement the GSM8K experiment pipeline to empirically verify the three-regime structure by sweeping β and plotting sub-optimality curves, confirming O(√β) growth in transport regime and plateau in saturation regime.

2. **Estimator robustness study**: Systematically vary the quality of s_r* and s_ver estimates (introducing noise or bias) to quantify impact on SRS/SMC performance and verify the theoretical robustness bounds for envelope parameter M.

3. **Cross-domain generalization**: Apply the framework to a non-mathematical domain (e.g., code generation or text summarization) with a more sophisticated verifier (not pattern-matching) to test whether the three-regime characterization holds and whether the same algorithm selection rules apply.