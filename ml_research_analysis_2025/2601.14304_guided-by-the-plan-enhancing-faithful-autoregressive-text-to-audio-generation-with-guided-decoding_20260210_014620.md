---
ver: rpa2
title: 'Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation
  with Guided Decoding'
arxiv_id: '2601.14304'
source_url: https://arxiv.org/abs/2601.14304
tags:
- audio
- arxiv
- generation
- clap
- prefix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of faithful instruction-following
  in autoregressive (AR) text-to-audio generation, particularly when prompts describe
  multiple complex sound events. AR models struggle with semantic alignment despite
  their strength in temporal coherence.
---

# Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding

## Quick Facts
- arXiv ID: 2601.14304
- Source URL: https://arxiv.org/abs/2601.14304
- Reference count: 23
- Primary result: Achieves up to 10-point improvement in CLAP score over AR baseline while maintaining computational parity with best-of-N decoding

## Executive Summary
This paper addresses the challenge of faithful instruction-following in autoregressive text-to-audio generation, where models struggle to maintain semantic alignment when prompts describe multiple complex sound events. The authors propose Plan-Critic, a lightweight auxiliary model that predicts final instruction-following quality from partial audio sequences using a Generalized Advantage Estimation-inspired objective. By leveraging early-generation signals as implicit planning, Plan-Critic enables guided exploration that prunes low-fidelity trajectories and reallocates computation to high-potential planning seeds. This approach establishes a new state of the art in AR text-to-audio generation, achieving significant improvements in semantic alignment while maintaining computational efficiency comparable to best-of-N decoding.

## Method Summary
The core innovation is Plan-Critic, an auxiliary model trained to predict the final CLAP score (instruction-following quality metric) from partial audio sequences during generation. Plan-Critic uses a GAE-inspired objective that evaluates partial sequences against both the ground truth and the model's own future predictions, creating a self-supervised learning signal. During decoding, Plan-Critic evaluates candidate prefixes early in the generation process, enabling guided exploration where low-fidelity trajectories are pruned and computation is focused on high-potential planning seeds. This approach transforms the standard left-to-right AR generation into a more intelligent search process that maintains temporal coherence while improving semantic alignment with text prompts.

## Key Results
- Achieves up to 10-point improvement in CLAP score compared to AR baseline
- Maintains computational parity with best-of-N decoding while providing superior performance
- Establishes new state-of-the-art results in autoregressive text-to-audio generation

## Why This Works (Mechanism)
The approach works by addressing the fundamental limitation of standard autoregressive models: their inability to plan ahead when following complex multi-event instructions. Plan-Critic acts as a "critic" that evaluates partial generation trajectories based on their predicted final quality, enabling early pruning of unpromising paths. This guided exploration mechanism allows the model to allocate computational resources more efficiently, focusing on trajectories that are likely to achieve high semantic alignment with the input prompt. The GAE-inspired training objective ensures that Plan-Critic learns to make reliable early predictions about final generation quality.

## Foundational Learning

**Generalized Advantage Estimation (GAE)**: An actor-critic method that provides low-variance policy gradient estimates by trading off bias and variance. Why needed: Provides the theoretical foundation for Plan-Critic's training objective, enabling stable learning of quality predictions from partial sequences. Quick check: Verify that the advantage estimation formulation properly balances bias-variance tradeoff for the partial sequence evaluation task.

**CLAP Score**: A metric for evaluating instruction-following quality in text-to-audio generation based on semantic alignment between generated audio and text prompts. Why needed: Provides a quantitative proxy for instruction-following quality that can be used for both training Plan-Critic and evaluating generation performance. Quick check: Ensure CLAP score correlates with human perceptual judgments of instruction-following quality.

**Prefix-based Evaluation**: The technique of evaluating partial generation sequences to predict final quality before complete generation. Why needed: Enables early pruning of low-fidelity trajectories, reducing computational cost while improving final output quality. Quick check: Validate that prefix length is sufficient for reliable quality prediction without being so long as to negate computational benefits.

## Architecture Onboarding

**Component Map**: Text Prompt -> AR Model -> Audio Generation -> Plan-Critic (evaluates partial sequences) -> Guided Decoding (prunes/reallocates computation)

**Critical Path**: The most important computational path is Text Prompt → AR Model → Plan-Critic → Guided Decoding, where Plan-Critic's predictions directly influence which generation trajectories are pursued.

**Design Tradeoffs**: The approach trades additional model complexity (Plan-Critic training) for improved generation quality and computational efficiency during inference. The lightweight nature of Plan-Critic is crucial for maintaining inference speed while providing guidance.

**Failure Signatures**: Potential failures include Plan-Critic making incorrect quality predictions leading to premature pruning of good trajectories, or the method failing to generalize across different prompt types and complexity levels.

**First Experiments**: 1) Evaluate Plan-Critic's prediction accuracy on held-out validation sets, 2) Compare CLAP score improvements across different prefix lengths, 3) Test computational efficiency gains with varying search space sizes.

## Open Questions the Paper Calls Out

None

## Limitations
- Heavy reliance on CLAP score as proxy for instruction-following quality may not fully capture perceptual fidelity
- Limited human evaluation data raises questions about real-world performance
- Computational complexity claims based on theoretical analysis rather than empirical measurements
- Additional development overhead from training auxiliary Plan-Critic model

## Confidence

**High**: Core methodology of using early-generation signals for guided exploration; technical implementation of Plan-Critic with GAE-inspired objectives.

**Medium**: Quantitative improvements in CLAP scores; computational efficiency claims based on theoretical assumptions.

**Low**: Real-world perceptual quality improvements; generalizability across diverse audio prompts and complexity levels.

## Next Checks

1. Conduct comprehensive human evaluation studies with diverse annotators to validate CLAP score improvements correlate with perceived instruction-following quality across different prompt types.

2. Perform empirical runtime measurements comparing wall-clock time for Plan-Critic-guided decoding versus standard AR and best-of-N decoding under realistic conditions.

3. Test robustness of Plan-Critic across different AR model architectures and audio domains (music, environmental sounds, speech) to assess generalizability.