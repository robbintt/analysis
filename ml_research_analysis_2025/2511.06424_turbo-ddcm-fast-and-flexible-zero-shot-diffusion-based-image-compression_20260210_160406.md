---
ver: rpa2
title: 'Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression'
arxiv_id: '2511.06424'
source_url: https://arxiv.org/abs/2511.06424
tags:
- ddcm
- turbo-ddcm
- compression
- image
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression

## Quick Facts
- **arXiv ID:** 2511.06424
- **Source URL:** https://arxiv.org/abs/2511.06424
- **Reference count:** 40
- **Primary result:** Achieves comparable quality to DDCM at 10× speed and 40% lower bitrate

## Executive Summary
Turbo-DDCM accelerates zero-shot diffusion-based image compression by replacing the iterative Matching Pursuit algorithm with a closed-form thresholding solution and reducing diffusion steps from hundreds to just 20. The method leverages the near-orthogonal property of high-dimensional Gaussian codebooks to select multiple noise atoms simultaneously per step, while introducing a combinatorial encoding protocol that exploits the order-invariance of the selection process. This results in order-of-magnitude speedups with competitive reconstruction quality and significant bitrate savings compared to the original DDCM approach.

## Method Summary
Turbo-DDCM is a zero-shot image compression method that operates on the latent space of a pre-trained Stable Diffusion model without additional training. The encoder iteratively computes the residual between the target image and the denoiser's prediction, then selects the top-M atoms from a reproducible Gaussian codebook using a closed-form thresholding approach rather than iterative matching. The selected atoms are encoded using a combinatorial number system that exploits their order-invariance, achieving approximately 40% bitrate savings. The decoder reverses this process by unpacking the bitstream, reconstructing the noise vectors, and performing T=20 reverse diffusion steps. The method supports both uniform and priority-aware encoding through optional mask-based atom selection.

## Key Results
- **Speed:** 10× faster than DDCM with order-of-magnitude reduction in neural function evaluations
- **Compression:** 40% bitrate reduction through combinatorial encoding protocol
- **Quality:** Competitive PSNR/LPIPS/FID scores while maintaining zero-shot flexibility

## Why This Works (Mechanism)

### Mechanism 1: Closed-Form Multi-Atom Selection via Thresholding
The method replaces iterative Matching Pursuit with a closed-form thresholding solution, assuming near-orthogonality of Gaussian codebook vectors in high-dimensional spaces. This allows simultaneous selection of top-M atoms based on their correlation with the residual, solved via simple projection rather than iterative refinement.

### Mechanism 2: Shallow Diffusion via Dense Noise Packing
By selecting M=700 atoms per step instead of 1, the method injects significantly more information into each reverse diffusion step, allowing convergence in just T=20 steps rather than hundreds. This shifts computational burden