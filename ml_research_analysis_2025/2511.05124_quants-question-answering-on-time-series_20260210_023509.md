---
ver: rpa2
title: 'QuAnTS: Question Answering on Time Series'
arxiv_id: '2511.05124'
source_url: https://arxiv.org/abs/2511.05124
tags:
- time
- series
- question
- answer
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces QuAnTS, a novel dataset for question answering
  on time series data, specifically focusing on human motion trajectories. The dataset
  comprises 150,000 samples, each consisting of a numerical time series of synthetic
  human motion tracking data, a textual question, and an answer.
---

# QuAnTS: Question Answering on Time Series

## Quick Facts
- **arXiv ID:** 2511.05124
- **Source URL:** https://arxiv.org/abs/2511.05124
- **Reference count:** 40
- **Key outcome:** QuAnTS is a novel dataset for time series question answering on human motion trajectories, comprising 150,000 synthetic samples with diverse question types; current models struggle with the task, highlighting the need for dedicated architectures.

## Executive Summary
This paper introduces QuAnTS, a synthetic dataset designed to advance research in time series question answering (TSQA). The dataset contains 150,000 samples of human motion trajectory data, each paired with textual questions and answers spanning descriptive, temporal, and comparison types. Questions are answered in binary, multiple-choice, or open formats. The authors evaluate baseline models—including a naive LLM, ChatTS, and a neuro-symbolic pipeline (xQA)—demonstrating that current approaches struggle with the challenging tasks. Human performance provides a reference point for model evaluation. The dataset and code are publicly available to support further research in this emerging field.

## Method Summary
The dataset is generated by first sampling sequences of human actions, then creating diverse question-answer pairs using templated question generation and LLM-assisted paraphrasing with manual review. The time series data is produced using a text-conditioned human motion diffusion model (STMC), which generates realistic 3D skeleton trajectories from textual action descriptions. The resulting dataset includes 30,000 contexts, each with 5 QA pairs, totaling 150,000 samples. Baseline models, including a naive LLM fine-tuned on serialized time series, ChatTS, and a neuro-symbolic pipeline (xQA), are evaluated using accuracy, F1, ROUGE, and METEOR metrics, with LLM-as-a-judge used for open-ended answers.

## Key Results
- QuAnTS contains 150,000 synthetic samples covering 19 action types and 46 question types, with questions requiring descriptive, temporal, and comparison reasoning.
- Current end-to-end models (ChatTS, naive LLM) perform poorly on QuAnTS, with the naive baseline producing mostly unparseable outputs.
- The neuro-symbolic xQA pipeline, which separates action recognition from reasoning, significantly outperforms other baselines by leveraging a symbolic representation of actions.
- Human performance serves as a reference, showing that even humans sometimes misidentify actions, highlighting the dataset's difficulty.

## Why This Works (Mechanism)

### Mechanism 1: Synthetically Generated Diverse Templates
A templated question generation process with manual review creates diverse, consistent question-answer pairs for time series contexts. The system samples action sequences, then selects from 10-20 question templates per type, instantiates them with actions, and uses LLM-assisted paraphrasing followed by manual review to ensure linguistic variety while maintaining logical structure. This prevents template repetition and ensures semantic correctness.

### Mechanism 2: Text-Conditioned Human Motion Diffusion for Grounding
Using a diffusion model (STMC) to generate time series data conditioned on textual action descriptions ensures that the numerical trajectories are semantically aligned with the questions, making the task solvable. STMC takes a sequence of action prompts (e.g., "waving," "catching a ball"), generates multi-track timelines, and performs iterative denoising to produce 3D joint trajectories that visually and numerically represent the described actions.

### Mechanism 3: Neuro-Symbolic Pipeline (xQA) Decomposition
Decoupling perception (action identification) from reasoning (question answering) using a neuro-symbolic pipeline allows a standard LLM to succeed where end-to-end multimodal models fail. An xLSTM-Mixer backbone processes the time series to produce discrete action labels, which are then fed as a text sequence into a frozen LLM (Llama 3.1 or Qwen3) with few-shot examples to generate the final answer.

## Foundational Learning

- **Concept: Action Recognition from Time Series**
  - **Why needed here:** The entire QuAnTS task is built upon the ability to first identify the sequence of actions from the raw skeleton trajectory data. Without this perceptual capability, higher-level reasoning (temporal ordering, counting) is impossible.
  - **Quick check question:** Given a multivariate time series of joint positions, can you train a model to classify the action being performed (e.g., "waving" vs. "punching") with high accuracy?

- **Concept: Large Language Models (LLMs) as Reasoners**
  - **Why needed here:** The xQA baseline treats the LLM as a reasoning engine that operates on a symbolic representation. Understanding that LLMs can follow instructions, use few-shot examples, and output structured JSON is critical to this approach.
  - **Quick check question:** Can you prompt a pre-trained LLM (like Llama or Qwen) with a sequence of symbols and a question, and have it reliably output a correct answer in a specified JSON format?

- **Concept: Diffusion Models for Conditional Generation**
  - **Why needed here:** The dataset's time series component is not real data, but synthetic data generated by a text-conditioned diffusion model (STMC). Understanding how conditioning works in generative models helps in understanding the dataset's strengths (controlled diversity) and potential limitations (misalignment).
  - **Quick check question:** How does a text prompt (e.g., "a person is dancing") guide the iterative denoising process in a diffusion model to generate a corresponding sample?

## Architecture Onboarding

- **Component map:**
  1. **Data Generation Pipeline:**
     - Action Sampler: Randomly selects 4 actions from 19 categories.
     - QA Template Engine: Instantiates one of 46 question types with the chosen actions.
     - Motion Diffusion Model (STMC): Generates the 320x72 time series tensor conditioned on the 4 action prompts.
  2. **xQA Baseline Architecture:**
     - Action Encoder (xLSTM-Mixer): A supervised classifier that takes a time series segment and predicts its action label.
     - Symbolic Reasoner (LLM): A frozen, instruction-tuned LLM (Llama 3.1 8B, Qwen3 8B) that takes the predicted action sequence and the question to generate an answer.
     - Prompt Constructor: Formats the action sequence and question into a structured prompt with few-shot examples and JSON output constraints.
  3. **Evaluation Framework:**
     - Standard Metrics: Accuracy, Precision, Recall, F1 for binary/multi-choice; ROUGE, METEOR for open-ended.
     - LLM-as-a-Judge (Qwen3 8B-AWQ): Evaluates semantic correctness of open-ended answers on a 1-3 scale.

- **Critical path:** The most critical path for a new engineer is understanding the **xQA baseline**. The core insight is that the problem factorizes: perception (TS -> actions) and reasoning (actions + question -> answer). This is where current SOTA TS-LLMs fail (they try to do everything end-to-end) and where the xQA approach succeeds.

- **Design tradeoffs:**
  - **Synthetic vs. Real Data:** The paper uses 100% synthetic data. This allows for perfect control, scalability, and balanced question types, but may introduce artifacts from the motion generator and lacks the messiness of real-world signals.
  - **End-to-End vs. Neuro-Symbolic:** The experiments show that current end-to-end models (ChatTS) struggle. The neuro-symbolic xQA approach is more effective now but requires a supervised perception module. The tradeoff is modularity vs. joint optimization.
  - **Evaluation of Open Answers:** Using an LLM as a judge is scalable and correlates well with humans (0.912 Pearson), but introduces another model's potential biases into the evaluation loop.

- **Failure signatures:**
  - **ChatTS Baseline:** Fails to correctly identify actions, leading to near-random or nonsensical answers. The ablation study ("Only Question") confirms it cannot solve the task from shortcuts.
  - **Naive LLM Baseline:** When fed raw serialized time series numbers, the LLM produces unparsable outputs (60.18% invalid) and performs below random guessing. This indicates that standard tokenization is inadequate for numerical time series.
  - **Human Confusion:** Humans sometimes misidentify actions (e.g., "catching a ball" as "throwing a ball"), which explains the gap between human performance on video vs. the model's performance on ground-truth text descriptions.

- **First 3 experiments:**
  1. **Reproduce the Ablation Study (Q1-Q3):** Run the experiments described in Section 4.1 using the ground-truth action sequences, only the questions, and only the time series. This validates the dataset's integrity and confirms that both modalities are required.
  2. **Train and Evaluate the Action Encoder:** Train the xLSTM-Mixer model on the provided ground-truth action segments. Measure its classification accuracy. This is the perception bottleneck for the xQA system.
  3. **Implement the xQA Pipeline with Ground-Truth Actions:** Bypass the action encoder and feed the *true* action sequences directly to the LLM reasoner. This establishes the "perfect perception" upper bound and isolates the LLM's reasoning capabilities.

## Open Questions the Paper Calls Out

- **Open Question 1:** What is the optimal mixture of generic time series knowledge (e.g., identifying peaks) and domain-specific data (e.g., human motions) for training TSQA models?
  - **Basis:** [explicit] The authors state in the Conclusion that "investigating how to curate optimal mixtures of those is still an open question."
  - **Why unresolved:** It is unclear how to balance training data to ensure models retain both general temporal reasoning skills and specific domain knowledge.
  - **What evidence would resolve it:** Ablation studies on dataset composition demonstrating performance retention across diverse, unseen domains.

- **Open Question 2:** Can conversational abilities for time series be fully retained from general instruction-tuned models, or do they require dedicated TSQA datasets?
  - **Basis:** [explicit] The Conclusion asks to what degree "conversational abilities can be fully retained from instruction-tuned models" versus requiring dedicated datasets.
  - **Why unresolved:** The transferability of text-based conversational skills to multimodal numerical reasoning tasks has not been established.
  - **What evidence would resolve it:** Comparative evaluation of standard instruction-tuned LLMs against models fine-tuned on conversational time series data.

- **Open Question 3:** What architectural advancements are needed for end-to-end models to reliably perceive and reason over time series without explicit symbolic scaffolding?
  - **Basis:** [inferred] The authors highlight the "urgent need for improved architectures" because naive baselines failed while the neuro-symbolic xQA pipeline succeeded using structured inputs.
  - **Why unresolved:** Current Time Series LLMs struggle to perform zero-shot recognition of complex actions directly from numerical inputs.
  - **What evidence would resolve it:** An end-to-end model achieving human-level performance on QuAnTS without relying on intermediate action segmentation labels.

## Limitations

- The dataset is entirely synthetic, so it may not capture the noise and variability of real-world time series data.
- The performance gap between models using ground-truth versus predicted action labels highlights that action recognition is a major bottleneck, but it is unclear if this bottleneck is due to the synthetic generation process or a real-world challenge.
- The neuro-symbolic approach (xQA) requires a supervised action encoder, which limits its applicability to domains where such labeled data is available.

## Confidence

- **High confidence:** The dataset construction methodology (templating + manual review) and the observation that current end-to-end TS-LLMs struggle with the task. The ablation studies clearly demonstrate that both the time series and question modalities are necessary.
- **Medium confidence:** The neuro-symbolic xQA pipeline's effectiveness is well-demonstrated on this synthetic dataset, but its generalizability to real-world time series or different domains is unproven. The LLM-as-a-judge evaluation, while showing good correlation (0.912) with human judgments, introduces another model's potential biases.
- **Low confidence:** The claim that this dataset "fosters research" is aspirational. While the dataset is released, there is no evidence yet of community adoption or whether the specific format and synthetic nature will be useful for the broader TSQA research community beyond human motion.

## Next Checks

1. **Real Data Validation:** Test the xQA pipeline on a real-world time series QA dataset (e.g., from healthcare or industrial monitoring) to determine if the neuro-symbolic approach generalizes beyond synthetic human motion.
2. **Template Diversity Analysis:** Conduct a study to quantify the actual linguistic diversity achieved through LLM-assisted paraphrasing versus the original templates, and test whether models overfit to template patterns rather than learning genuine temporal reasoning.
3. **Perception Bottleneck Isolation:** Systematically evaluate different action recognition models (not just xLSTM-Mixer) on the ground-truth action segments from QuAnTS to identify whether the perception failure is due to the model architecture or the synthetic data distribution.