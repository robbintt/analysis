---
ver: rpa2
title: 'Hallucinations and Truth: A Comprehensive Accuracy Evaluation of RAG, LoRA
  and DoRA'
arxiv_id: '2502.10497'
source_url: https://arxiv.org/abs/2502.10497
tags:
- lora
- dora
- retrieval
- accuracy
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the performance of Retrieval-Augmented Generation
  (RAG), Low-Rank Adaptation (LoRA), and Weight-Decomposed Low-Rank Adaptation (DoRA)
  using 20,000 FAQ-based queries and 400,000 knowledge base entries. Results show
  DoRA achieving the highest accuracy (90.1%), relevance score (0.88), and lowest
  latency (110 ms per query), outperforming both LoRA (85.5%, 0.85, 120 ms) and RAG
  (81.2%, 0.84, 150 ms).
---

# Hallucinations and Truth: A Comprehensive Accuracy Evaluation of RAG, LoRA and DoRA

## Quick Facts
- **arXiv ID**: 2502.10497
- **Source URL**: https://arxiv.org/abs/2502.10497
- **Reference count**: 0
- **Primary result**: DoRA achieves highest accuracy (90.1%), relevance score (0.88), lowest latency (110 ms), and lowest hallucination rate (2.1%) across 20,000 FAQ queries and 400,000 knowledge base entries

## Executive Summary
This study presents a comprehensive evaluation of three major adaptation approaches for large language models: Retrieval-Augmented Generation (RAG), Low-Rank Adaptation (LoRA), and Weight-Decomposed Low-Rank Adaptation (DoRA). Using 20,000 FAQ-based queries and 400,000 knowledge base entries, the research systematically compares performance across accuracy, relevance, latency, hallucination rates, and coverage metrics. The evaluation framework provides practical insights for deploying AI-driven generative systems in accuracy-critical domains where precision and reliability are paramount.

The results demonstrate DoRA's superior performance across all measured metrics, achieving 90.1% accuracy with only 110 ms latency per query while maintaining a remarkably low hallucination rate of 2.1%. This balanced approach to fine-tuning efficiency, computational cost, and real-time adaptability positions DoRA as the optimal choice for enterprise applications in healthcare, finance, and legal services where both accuracy and response speed are critical requirements.

## Method Summary
The study employs a large-scale evaluation framework using 20,000 FAQ-style queries systematically sampled across diverse domains and 400,000 knowledge base entries representing real-world enterprise data. Each adaptation method (RAG, LoRA, DoRA) is tested under identical conditions with consistent evaluation metrics including accuracy, relevance scoring, latency measurement, hallucination detection, and coverage assessment. The controlled experimental setup enables direct comparison of performance characteristics while isolating the impact of each adaptation approach on model behavior and output quality.

## Key Results
- DoRA achieves highest accuracy at 90.1% compared to LoRA (85.5%) and RAG (81.2%)
- Lowest latency observed with DoRA at 110 ms per query versus 120 ms for LoRA and 150 ms for RAG
- Minimum hallucination rate of 2.1% with DoRA compared to higher rates in alternative approaches
- Maximum coverage of 98% demonstrating comprehensive knowledge base utilization

## Why This Works (Mechanism)
DoRA's superior performance stems from its weight-decomposed architecture that efficiently balances fine-tuning depth with computational efficiency. By decomposing weight matrices into lower-rank components, DoRA maintains model capacity while reducing parameter overhead, enabling faster inference without sacrificing accuracy. The architecture's ability to capture complex relationships in the knowledge base while maintaining low-latency responses creates an optimal trade-off between precision and performance that neither pure retrieval-based approaches nor standard low-rank adaptations can achieve.

## Foundational Learning
- **Weight Decomposition**: Breaking down weight matrices into lower-rank components to reduce computational complexity while preserving representational power. Needed for efficient fine-tuning without full parameter updates.
- **Retrieval-Augmented Generation**: Combining retrieval mechanisms with generative models to ground responses in external knowledge bases. Required for ensuring factual accuracy and reducing hallucinations.
- **Low-Rank Adaptation**: Using low-rank matrix decomposition to adapt large models efficiently. Essential for practical deployment where full fine-tuning is computationally prohibitive.
- **Latency-Performance Trade-offs**: Balancing response speed against accuracy requirements. Critical for real-time applications where user experience depends on quick responses.
- **Hallucination Detection**: Identifying when models generate factually incorrect or fabricated information. Necessary for maintaining trust in accuracy-critical domains.

## Architecture Onboarding

**Component Map**: User Query -> Retrieval/Generation Module -> Knowledge Base -> Adaptation Layer (RAG/LoRA/DoRA) -> Response Generator -> Output

**Critical Path**: Query processing and retrieval occur first, followed by adaptation layer processing, then response generation and hallucination filtering before final output delivery.

**Design Tradeoffs**: DoRA prioritizes balanced performance across all metrics, while RAG emphasizes factual grounding at the cost of latency, and LoRA optimizes for computational efficiency with moderate accuracy trade-offs.

**Failure Signatures**: RAG fails with retrieval bottlenecks and outdated knowledge, LoRA struggles with shallow adaptation and limited coverage, DoRA may underperform with extremely sparse knowledge bases.

**First Experiments**:
1. Baseline accuracy testing across all three methods using identical query sets
2. Latency benchmarking under varying load conditions
3. Hallucination detection accuracy validation with controlled misinformation injection

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Evaluation restricted to FAQ-style queries, limiting generalizability to complex conversational scenarios
- Only three adaptation methods compared, excluding other relevant approaches like full fine-tuning or prompt engineering
- Domain-specific performance variations across different knowledge base structures not thoroughly examined

## Confidence

**High Confidence**:
- DoRA accuracy superiority (90.1%) with clear performance gap
- Latency advantages (110ms vs 120-150ms) with measurable differences
- Coverage achievement (98%) across knowledge base

**Medium Confidence**:
- Hallucination rate reduction (2.1%) due to unspecified detection methodology
- Domain applicability claims based on general characteristics rather than specific testing

## Next Checks
1. Cross-domain validation using non-FAQ query types including multi-turn conversations and complex reasoning tasks
2. Ablation studies comparing DoRA against additional adaptation methods under identical conditions
3. Long-term stability testing across extended deployment periods for performance consistency evaluation