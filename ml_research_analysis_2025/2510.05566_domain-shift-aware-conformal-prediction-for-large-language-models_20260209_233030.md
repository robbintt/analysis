---
ver: rpa2
title: Domain-Shift-Aware Conformal Prediction for Large Language Models
arxiv_id: '2510.05566'
source_url: https://arxiv.org/abs/2510.05566
tags:
- prediction
- coverage
- domain
- ds-cp
- shift
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Domain-Shift-Aware Conformal Prediction (DS-CP)
  for large language models (LLMs) to address the problem of unreliable uncertainty
  quantification under domain shift. Standard conformal prediction often under-covers
  when calibration and test data distributions differ, leading to overly narrow prediction
  sets.
---

# Domain-Shift-Aware Conformal Prediction for Large Language Models

## Quick Facts
- arXiv ID: 2510.05566
- Source URL: https://arxiv.org/abs/2510.05566
- Reference count: 35
- Key outcome: DS-CP improves empirical coverage for LLMs under domain shift while maintaining modest increases in prediction set size

## Executive Summary
This paper addresses the problem of unreliable uncertainty quantification for large language models (LLMs) when calibration and test data come from different domains. Standard conformal prediction often under-covers in these scenarios, leading to overly narrow prediction sets. The proposed Domain-Shift-Aware Conformal Prediction (DS-CP) method embeds prompts into a semantic space and reweights calibration samples based on their proximity to the test prompt, thereby preserving validity while enhancing adaptivity. Experiments on the MMLU benchmark across 16 LLM models show that DS-CP consistently improves empirical coverage compared to standard CP, particularly in cases of severe under-coverage.

## Method Summary
DS-CP extends weighted conformal prediction to LLM settings by first embedding prompts into a lower-dimensional semantic space using a pre-trained sentence transformer. A domain classifier is then trained on these embeddings to distinguish calibration from test prompts, producing density ratios that reweight the calibration sample distribution. The method constructs prediction sets using a weighted empirical distribution of nonconformity scores, with a regularization parameter λ preventing degenerate sets under large domain shifts. The approach requires no labeled test data and operates directly on the LLM's logits.

## Key Results
- DS-CP consistently improves empirical coverage compared to standard CP across 16 LLM models on MMLU benchmark
- Coverage improvement is most pronounced in severe under-coverage cases, where standard CP fails to meet the 90% target
- Prediction set size increases modestly compared to standard CP, demonstrating good efficiency
- Method adapts to domain shift without requiring labeled test data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Embedding prompts into a lower-dimensional semantic space makes density ratio estimation statistically tractable for high-dimensional text inputs.
- Mechanism: A pre-trained sentence transformer (e.g., all-MiniLM-L6-v2) maps raw prompts from a vast token-sequence space into a fixed-dimensional embedding (e.g., 384 dims). This dimensionality reduction preserves semantic similarity—prompts with similar meanings cluster nearby—enabling reliable estimation of the density ratio r(z) = P(W=1|Z=z) / P(W=0|Z=z) via a domain classifier.
- Core assumption: The embedding model captures cross-domain semantic similarity well enough that domain shift in prompts translates to detectable shift in the embedding space.
- Evidence anchors:
  - [section 3]: "The embedding model serves two purposes: (i) it reduces the dimensionality of the prompts, making statistical estimation more feasible; and (ii) it captures the semantic information of the prompts, so that prompts with similar meanings are mapped to nearby points in Z."
  - [section 5]: "For the embedding model, we adopt the all-MiniLM-L6-v2 SentenceTransformer, which maps input questions into a 384-dimensional semantic space."
- Break condition: If the embedding model fails to align semantic similarity with domain relevance (e.g., semantically similar prompts from different domains), density ratios become uninformative, and reweighting loses adaptivity.

### Mechanism 2
- Claim: Reweighting calibration samples by estimated density ratios shifts the empirical score distribution toward the test domain, restoring coverage under covariate shift.
- Mechanism: Each calibration sample (Xi, Yi) receives a weight ŵi = r̂(h(Xi)) based on its embedded proximity to the test domain. The weighted empirical distribution of calibration scores places more mass on samples likely under the test distribution. The prediction set threshold is the (1-α) quantile of this weighted distribution plus a regularized test-point contribution.
- Core assumption: The conditional distribution Y|X is similar across domains; only the marginal distribution of X shifts (covariate shift assumption). If the score distribution S(X,Y) changes substantially, coverage gaps persist.
- Evidence anchors:
  - [section 2.2]: "Weighted CP... guarantees valid coverage if the conditional distributions coincide across calibration and test data, i.e., Y_{n+1}|X_{n+1} is the same as the conditional distribution Y_i|X_i for i = 1,...,n."
  - [section 4, Theorem 1]: Coverage bounds include total variation terms TV(S_i, S_{n+1}), which quantify deviation from exchangeability.
- Break condition: When the conditional score distribution differs significantly across domains (e.g., model behavior changes qualitatively), TV(S_i, S_{n+1}) terms dominate, and coverage may fall below 1-α by an unbounded amount.

### Mechanism 3
- Claim: Regularizing the test-point weight λ prevents degenerate prediction sets when domain shift is large.
- Mechanism: Instead of using the raw density ratio at the test point r̂(h(X_{n+1})), which can be extremely large under severe shift, DS-CP substitutes a fixed regularization parameter λ (default 1). This caps the mass placed on δ_∞ in the empirical distribution, avoiding prediction sets that inflate to the entire output space Y.
- Core assumption: The regularization parameter λ provides a reasonable trade-off between validity (conservative sets) and efficiency (informative sets); λ=1 is a neutral default that reduces to standard CP under no shift.
- Evidence anchors:
  - [section 3]: "When the shift between the old and new domains is large, the estimated density ratio can become highly unbalanced... leading the resulting CP set to degenerate into the entire output space Y."
  - [section 3]: "Setting the regularized weight to 1 provides a natural balance between validity and efficiency, and reduces to standard CP under the exchangeability condition."
- Break condition: If λ is set too low, severe shift cases may still under-cover; if set too high, prediction sets become overly conservative. Adaptive λ selection remains an open problem.

## Foundational Learning

- Concept: Conformal Prediction (Split CP)
  - Why needed here: DS-CP extends split conformal prediction; you must understand how calibration scores, quantiles, and coverage guarantees work under exchangeability before grasping non-exchangeable extensions.
  - Quick check question: Given calibration scores [0.1, 0.3, 0.5, 0.7] and α=0.1, what is the conformal quantile and prediction set threshold?

- Concept: Covariate Shift and Density Ratio Estimation
  - Why needed here: DS-CP is grounded in weighted CP under covariate shift; understanding how to estimate r(x) = P_test(x)/P_calib(x) via domain classifiers is central to the method.
  - Quick check question: If you train a logistic classifier to distinguish calibration (W=0) vs. test (W=1) samples, how do you convert P(W=1|X=x) into a density ratio?

- Concept: Total Variation Distance and Exchangeability
  - Why needed here: Theoretical guarantees in DS-CP are expressed as coverage bounds parameterized by TV distance between score distributions; understanding exchangeability helps interpret when these bounds tighten.
  - Quick check question: If calibration and test scores are i.i.d. from the same distribution, what is TV(S_i, S_{n+1}), and what coverage guarantee does DS-CP provide?

## Architecture Onboarding

- Component map:
  1. **Embedding Module**: Pre-trained sentence transformer (e.g., all-MiniLM-L6-v2) → maps raw text prompts to dense vectors
  2. **Density Ratio Estimator**: Binary classifier (e.g., XGBoost) trained on embedded calibration vs. test prompts → outputs P(W=1|Z=z) → converted to ŵi
  3. **Score Computation**: Nonconformity scores S(X_i, Y_i) = 1 - f(X_i)_Y (LAC score) for each calibration sample
  4. **Weighted Quantile Module**: Computes the (1-α) quantile from the weighted empirical score distribution ∑ ŵ_i δ_{S_i} + λ δ_∞
  5. **Prediction Set Constructor**: Filters candidate outputs y ∈ Y by thresholding S(x, y) against the computed quantile

- Critical path:
  1. Embed all calibration prompts and test prompts
  2. Train domain classifier on embedded data; compute density ratios for calibration samples
  3. Compute nonconformity scores for calibration pairs
  4. Build weighted empirical score distribution with regularization λ
  5. For each test prompt, score candidate outputs and retain those below the threshold

- Design tradeoffs:
  - **Embedding model choice**: Larger models (e.g., 768-dim) capture more semantics but increase classifier training cost and overfitting risk
  - **Classifier choice**: XGBoost is robust for moderate dimensions; neural classifiers may overfit with limited calibration data
  - **Regularization λ**: Higher λ → more conservative sets (valid but potentially uninformative); lower λ → adaptive but may under-cover
  - **Score function**: LAC scores are simple; APS scores provide better adaptation for imbalanced classes but require probability sorting

- Failure signatures:
  - **Coverage collapse (< 1-α by large margin)**: Conditional score distribution differs across domains; TV terms dominate. Check if model behavior (confidence calibration) shifts qualitatively
  - **Degenerate sets (|Ĉ(x)| = |Y|)**: Density ratios extreme; λ too low or calibration sample size too small. Increase λ or calibration data
  - **No improvement over standard CP**: Embedding model fails to capture domain-relevant semantics. Inspect embedding space with t-SNE; consider domain-specific embeddings

- First 3 experiments:
  1. **Sanity check (no shift)**: Calibrate and test on the same MMLU subject. Verify DS-CP (λ=1) reduces to standard CP with coverage ≈ 1-α
  2. **Controlled shift pairs**: Pick two subject pairs—one with mild shift (e.g., psychology → sociology) and one with severe shift (e.g., physics → philosophy). Compare coverage and set size of CP vs. DS-CP
  3. **Ablation on λ**: On a severe-shift pair, sweep λ ∈ {0.5, 1, 2, 5} and plot coverage vs. average set size to visualize the validity-efficiency trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DS-CP be effectively adapted for open-ended generation tasks such as summarization or code generation?
- Basis in paper: [explicit] The authors state that extending the framework to open-ended tasks is a key avenue for future research, as current experiments are limited to multiple-choice QA.
- Why unresolved: Open-ended tasks lack discrete ground truth labels, requiring the development of new nonconformity scores and evaluation metrics to operationalize coverage guarantees.
- What evidence would resolve it: Successful application of DS-CP to generative benchmarks with defined coverage metrics and efficiency comparable to the MMLU results.

### Open Question 2
- Question: What constitutes a principled strategy for tuning the regularization parameter $\lambda$ to optimize the trade-off between validity and efficiency?
- Basis in paper: [explicit] The paper notes that while setting $\lambda=1$ is a natural baseline, "more principled tuning strategies remain an open problem."
- Why unresolved: The choice of $\lambda$ currently involves a heuristic trade-off; a systematic method is needed to minimize prediction set size while maintaining valid coverage under varying shifts.
- What evidence would resolve it: An algorithm or theoretical framework for selecting $\lambda$ that consistently outperforms the default setting in terms of set efficiency without violating coverage bounds.

### Open Question 3
- Question: To what extent does the choice of embedding model and density ratio estimator impact the robustness of DS-CP?
- Basis in paper: [explicit] The authors identify reliance on the embedding model as a limitation, noting that "mis-specification at this stage could reduce adaptivity."
- Why unresolved: The study primarily utilizes `all-MiniLM-L6-v2`, and it is untested whether alternative embeddings or classifiers significantly improve the semantic matching required for reweighting.
- What evidence would resolve it: Ablation studies comparing different sentence embeddings (e.g., dimensionality, training domain) and density estimation techniques on the same shift scenarios.

## Limitations

- Theoretical coverage bounds depend on unmeasured TV distance between score distributions across domains
- Method relies heavily on the embedding model capturing cross-domain semantic similarity, which may fail for certain domain pairs
- Regularization parameter λ is set to 1 by default without principled justification or adaptive selection strategy

## Confidence

- **High confidence**: DS-CP improves empirical coverage vs standard CP on MMLU when domain shift exists
- **Medium confidence**: The mechanism of reweighting via density ratios in embedding space reliably captures domain shift
- **Low confidence**: Coverage guarantees hold with bounded deviation from 1-α under all domain shifts

## Next Checks

1. **Empirical TV distance measurement**: For a subset of subject pairs, estimate TV(S_calib, S_test) using kernel density estimation on nonconformity scores. Compare this to observed coverage gaps to validate whether TV terms explain coverage deviations.

2. **Embedding space sanity check**: Visualize calibration vs test prompts in the 384-dim embedding space using t-SNE. Check if domain-shifted prompts cluster separately and if classifier accuracy correlates with coverage improvement.

3. **Adaptive λ exploration**: On severe-shift pairs, sweep λ across multiple orders of magnitude and plot the coverage-set size Pareto frontier. Identify whether a data-driven λ selection rule could improve the validity-efficiency trade-off.