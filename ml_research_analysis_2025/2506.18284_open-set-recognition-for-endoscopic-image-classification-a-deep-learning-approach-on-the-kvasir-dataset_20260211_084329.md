---
ver: rpa2
title: 'Open Set Recognition for Endoscopic Image Classification: A Deep Learning
  Approach on the Kvasir Dataset'
arxiv_id: '2506.18284'
source_url: https://arxiv.org/abs/2506.18284
tags:
- recognition
- image
- classification
- classes
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study addresses the challenge of open set recognition in\
  \ endoscopic image classification using the Kvasir dataset. The research evaluates\
  \ three deep learning architectures\u2014ResNet-50, Swin Transformer, and a hybrid\
  \ ResNet-Transformer model\u2014under both closed-set and open-set conditions using\
  \ OpenMax as the baseline OSR method."
---

# Open Set Recognition for Endoscopic Image Classification: A Deep Learning Approach on the Kvasir Dataset

## Quick Facts
- arXiv ID: 2506.18284
- Source URL: https://arxiv.org/abs/2506.18284
- Reference count: 0
- Primary result: Hybrid ResNet-Transformer model achieves 99.7% closed-set accuracy; ResNet-50 with OpenMax achieves 86.3% open-set accuracy

## Executive Summary
This study addresses open set recognition (OSR) challenges in endoscopic image classification using the Kvasir dataset. The research evaluates three deep learning architectures—ResNet-50, Swin Transformer, and a hybrid ResNet-Transformer model—under both closed-set and open-set conditions using OpenMax as the baseline OSR method. The hybrid model demonstrated the best closed-set performance with 99.7% accuracy, while ResNet-50 with OpenMax achieved the highest open-set performance with 86.3% accuracy, 94.7% AUROC, and 70.4% AUPR-OUT. The Swin Transformer underperformed in open-set scenarios, highlighting the importance of architectural choice and hyperparameter optimization. These results demonstrate that OpenMax significantly improves the model's ability to reject unknown classes while maintaining classification accuracy on known categories, providing valuable insights for deploying reliable AI systems in real-world endoscopic diagnostics where encountering previously unseen conditions is inevitable.

## Method Summary
The study evaluates three deep learning architectures for endoscopic image classification on the Kvasir dataset. The closed-set approach uses standard supervised learning to classify known categories, while the open-set approach employs OpenMax to reject unknown classes. The three architectures tested are ResNet-50, Swin Transformer, and a hybrid ResNet-Transformer model. Performance is measured using accuracy, AUROC, and AUPR-OUT metrics under both closed-set and open-set conditions. The OpenMax method modifies the final classification layer to estimate probability distribution over known classes and reject samples that don't fit any known category.

## Key Results
- Hybrid ResNet-Transformer model achieves 99.7% closed-set classification accuracy
- ResNet-50 with OpenMax achieves 86.3% open-set accuracy, 94.7% AUROC, and 70.4% AUPR-OUT
- Swin Transformer underperforms in open-set scenarios compared to other architectures
- OpenMax significantly improves unknown class rejection while maintaining known class accuracy

## Why This Works (Mechanism)
The effectiveness of this approach stems from combining strong feature extraction capabilities of deep learning architectures with OpenMax's probabilistic rejection mechanism. The hybrid model benefits from both convolutional and transformer-based feature learning, while OpenMax provides calibrated probability estimates that enable reliable distinction between known and unknown classes through Weibull distribution modeling of activation patterns.

## Foundational Learning

**Convolutional Neural Networks (CNNs)**: Essential for extracting spatial features from endoscopic images. Why needed: CNNs capture local patterns and textures crucial for medical image analysis. Quick check: Verify receptive field size matches image resolution requirements.

**Vision Transformers (ViTs)**: Enable global context modeling through self-attention mechanisms. Why needed: Transformers capture long-range dependencies missed by CNNs. Quick check: Confirm patch size and sequence length are appropriate for dataset dimensions.

**OpenMax Algorithm**: Extends softmax to handle unknown classes through probability calibration. Why needed: Standard softmax assumes all possible classes are known during training. Quick check: Validate Weibull parameters are properly estimated from validation data.

## Architecture Onboarding

**Component Map**: Input Images -> Backbone (ResNet/Swin/Hybrid) -> Feature Extractor -> OpenMax Layer -> Output Probabilities

**Critical Path**: Image preprocessing → Backbone feature extraction → Activation vector aggregation → Weibull calibration → Probability distribution → Class prediction or rejection

**Design Tradeoffs**: ResNet offers computational efficiency and proven performance, while Swin provides superior feature representation at higher computational cost. The hybrid approach aims to balance these strengths but adds complexity. OpenMax adds rejection capability but requires careful calibration.

**Failure Signatures**: Poor open-set performance indicates inadequate calibration or feature discrimination. Underperformance of Swin Transformer suggests architectural mismatch with endoscopic data characteristics. Low AUROC values indicate inability to distinguish known from unknown classes.

**First Experiments**:
1. Ablation study removing OpenMax to establish baseline closed-set performance
2. Cross-validation with progressively increasing unknown class proportion
3. Feature visualization to analyze activation patterns for known vs. unknown classes

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies primarily on the Kvasir dataset, which may not represent real-world diversity
- OpenMax baseline comparison lacks newer OSR methods like OE-GNN or uncertainty-based approaches
- Limited architectural exploration beyond three specific models without broader ablation studies
- No assessment of temporal or procedural variations in endoscopic imaging

## Confidence

**Closed-set classification results (99.7% accuracy)**: High confidence
**Open-set classification metrics (86.3% accuracy, 94.7% AUROC, 70.4% AUPR-OUT)**: Medium confidence
**Architectural superiority claims (ResNet-50 + OpenMax best for OSR)**: Medium confidence
**Clinical applicability conclusions**: Low confidence

## Next Checks

1. External validation on diverse endoscopic datasets from multiple clinical centers to assess generalizability across different imaging protocols and patient populations.

2. Comparison with state-of-the-art OSR methods beyond OpenMax, including uncertainty-based approaches and graph-based OSR techniques, to benchmark relative performance.

3. Real-time inference testing under simulated clinical conditions with unknown classes introduced progressively to evaluate model robustness and rejection accuracy in dynamic settings.