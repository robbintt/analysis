---
ver: rpa2
title: 'FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic
  Signal Control'
arxiv_id: '2502.11937'
source_url: https://arxiv.org/abs/2502.11937
tags:
- learning
- traffic
- fitlight
- control
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FitLight, a novel federated imitation learning
  framework for multi-intersection traffic signal control that addresses the high
  learning costs and poor generalizability of existing reinforcement learning methods.
  The key innovation is integrating real-time imitation learning with reinforcement
  learning, allowing agents to quickly find high-quality initial solutions without
  pre-training.
---

# FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic Signal Control

## Quick Facts
- **arXiv ID:** 2502.11937
- **Source URL:** https://arxiv.org/abs/2502.11937
- **Reference count:** 40
- **Primary result:** Achieves superior traffic signal control performance and convergence within 2 episodes using federated imitation learning.

## Executive Summary
This paper introduces FitLight, a novel federated imitation learning framework for multi-intersection traffic signal control. The key innovation is integrating real-time imitation learning with reinforcement learning, allowing agents to quickly find high-quality initial solutions without pre-training. FitLight employs a hybrid pressure concept that combines individual vehicle dynamics with intersection-level traffic conditions, and supports model pruning for deployment on resource-constrained devices. Extensive experiments show FitLight outperforms state-of-the-art methods, achieving superior control performance and convergence rates on both synthetic and real-world datasets.

## Method Summary
FitLight combines federated learning with imitation learning for traffic signal control. Each intersection runs a PPO agent that learns from both expert-labeled actions (via MaxHP heuristic) and reinforcement signals. The state representation uses Hybrid Pressure, incorporating individual vehicle dynamics. Models are pruned for edge deployment, and gradients are aggregated across intersections on a cloud server. The system achieves rapid convergence (within 2 episodes) while maintaining performance under severe resource constraints.

## Key Results
- Achieves convergence within just 2 episodes while maintaining near-optimal performance
- Outperforms state-of-the-art methods on both synthetic and real-world datasets
- Enables deployment on resource-constrained devices (16KB RAM, 32KB ROM)
- Demonstrates effective knowledge sharing across heterogeneous intersections

## Why This Works (Mechanism)

### Mechanism 1
Real-time imitation learning provides a superior initial policy, enabling rapid convergence without pre-training. The PPO agent is trained with a composite loss: $L = \alpha(L_C + L_A) + (1-\alpha)L_I$. An expert algorithm (MaxHP) labels states with "ideal" actions ($a_e$) in real-time. The imitation loss ($L_I$) uses cross-entropy to align the agent's policy with the expert. A balance factor $\alpha$ starts low, prioritizing imitation for jumpstart performance, then increases to allow RL to refine the policy beyond the expert's capabilities.

### Mechanism 2
Hybrid Pressure (HP) creates a more informative state and reward signal by encoding individual vehicle urgency. Unlike traditional pressure (queue length difference), HP for a vehicle ($hp_{veh}$) incorporates distance to the intersection, current speed, and the ratio of waiting time to driving time. These individual metrics are aggregated into directed road and intersection pressures. The reward ($r = -hp_I$) pushes the agent to minimize this combined pressure.

### Mechanism 3
Federated aggregation of heterogeneous pruned models enables effective knowledge sharing across diverse intersections. A dense "base model" is pruned at initialization to create smaller submodels for each resource-constrained intersection. Despite having different structures, gradients from these submodels are aggregated on a cloud server using a weighted average operation that projects them back onto the base model's parameter space.

## Foundational Learning

- **Concept: Proximal Policy Optimization (PPO)**
  - Why needed here: PPO is the core RL algorithm. Its clipping mechanism is what allows the agent to learn stably from the combined imitation and RL losses without large, destabilizing policy updates.
  - Quick check question: How does the clipping parameter in the PPO loss function prevent the new policy from deviating too far from the old one?

- **Concept: Imitation Learning (Behavioral Cloning)**
  - Why needed here: FitLight's primary mode of acceleration is treating TSC as a supervised classification problem (matching expert actions) before an RL problem. Understanding this shift is critical.
  - Quick check question: Why is cross-entropy loss suitable for the imitation learning component $L_I$ in this context?

- **Concept: Model Pruning (Lottery Ticket Hypothesis)**
  - Why needed here: The system is explicitly designed for embedded devices. You need to understand how a large neural network can be reduced to a "winning ticket" subnetwork that retains performance.
  - Quick check question: What is the role of the binary mask $M$ in creating the pruned submodels for edge deployment?

## Architecture Onboarding

- **Component map:**
  - Edge Node (Agent) -> Local intersection interaction -> Memory storage -> Local PPO update -> Gradient upload
  - Cloud Server -> Base model maintenance -> Pruning mask application -> Gradient aggregation -> Model broadcast
  - Cityflow Environment -> State observations -> Reward calculation -> Traffic simulation

- **Critical path:**
  1. Initialization: Cloud prunes the base model and dispatches a submodel to a new edge node
  2. Data Collection: Agent interacts with the environment for a step, storing the state, action, expert action, and reward in memory
  3. Local Update: Once a batch is ready, the agent computes the combined loss ($L$) and performs a gradient update
  4. Global Sync: The agent uploads its gradients to the cloud, which aggregates them with gradients from other nodes and broadcasts the update

- **Design tradeoffs:**
  - Expert vs. RL: A strong initial expert ensures safety and speed but may limit exploration. The balance factor $\alpha$ controls this tradeoff
  - Compression vs. Accuracy: The pruning rate directly trades model memory footprint (16KB target) for policy expressiveness
  - Communication Cost: More frequent federated aggregation improves learning speed but requires more bandwidth and server compute

- **Failure signatures:**
  - Negative Transfer: Local agent performance drops after a federated update. This suggests the global model is averaging gradients from incompatible intersections
  - Flat Reward Curve: If the average travel time doesn't decrease, the reward signal ($-hp_I$) may be poorly scaled or the expert actions are too noisy
  - Memory Overflow: The pruned model is still too large for the target microcontroller (must be < 16KB RAM)

- **First 3 experiments:**
  1. Ablation on State Representation: Run `FitLight` vs. `FitLight(p)` (pressure-only state) on a complex dataset to isolate the benefit of Hybrid Pressure
  2. Convergence Test: Train a single agent without federated sharing vs. a full `FitLight` deployment to quantify the convergence speedup
  3. Resource Scaling: Run `FitLight(mp)` with increasing pruning rates (0.2 -> 0.8) to find the failure point where model capacity becomes too low to control traffic effectively

## Open Questions the Paper Calls Out

### Open Question 1
Can the FitLight framework be extended to support dynamic phase durations to outperform state-of-the-art dynamic methods? The authors note that dynamic duration methods (e.g., FairLight, IPDALight) are "significantly better" than constant methods due to the "full use of duration," yet FitLight is implemented with a fixed 10-second duration to maintain a fair comparison with other constant baselines.

### Open Question 2
How does the method perform on heterogeneous road network topologies rather than the standardized grid structures used in evaluation? The experimental setup explicitly limits datasets to intersections with "four incoming roads and four outgoing roads, where each road has three lanes."

### Open Question 3
What is the impact of highly non-IID (Non-Independent and Identically Distributed) traffic data on the convergence stability of the federated aggregation? The paper demonstrates knowledge sharing between intersections but does not explicitly analyze scenarios where traffic flow distributions (e.g., volume or directional bias) differ drastically between the aggregated edge nodes.

## Limitations

- The paper lacks details on the pruning mask generation process, making exact replication of the 16KB submodels challenging
- No ablation study on the hybrid pressure formulation versus traditional pressure-based methods, limiting understanding of its specific contribution
- The federated aggregation assumes positive transfer across intersections, but the paper doesn't analyze cases where this might fail

## Confidence

- **High confidence** in the convergence claims (within 2 episodes) based on the ablation showing significant jumpstart performance improvements over baselines
- **Medium confidence** in the generalization to real-world datasets, as only one real-world dataset is tested with limited comparison to other methods
- **Low confidence** in the scalability claims to hundreds of intersections, as experiments focus on 3x3 and 4x4 grids without larger-scale validation

## Next Checks

1. Implement the hybrid pressure calculation independently and verify it produces meaningful gradients that correlate with actual travel time improvements
2. Create an artificial dataset with intentionally conflicting traffic patterns to test federated aggregation's robustness to negative transfer
3. Run ablation experiments systematically removing each component (imitation, federated learning, hybrid pressure) to quantify their individual contributions to the final performance