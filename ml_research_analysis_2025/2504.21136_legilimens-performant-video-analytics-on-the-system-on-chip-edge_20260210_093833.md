---
ver: rpa2
title: 'Legilimens: Performant Video Analytics on the System-on-Chip Edge'
arxiv_id: '2504.21136'
source_url: https://arxiv.org/abs/2504.21136
tags:
- legilimens
- retraining
- base
- scene
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Legilimens: Performant Video Analytics on the System-on-Chip Edge

## Quick Facts
- **arXiv ID:** 2504.21136
- **Source URL:** https://arxiv.org/abs/2504.21136
- **Reference count:** 40
- **Primary result:** Achieves 2.8-10× reduction in retraining compute while maintaining accuracy on SoC devices

## Executive Summary
Legilimens is a system for continual video analytics on compute-constrained edge devices that adapts to scene drift while sharing GPU resources between live inference and retraining. The system maintains a base model and a specialized model, using lightweight sampling and dynamic base model updates to minimize retraining costs. By leveraging embedding convergence across scenes and two-stage sampling, Legilimens reduces training set size by 8-14× while maintaining high accuracy.

## Method Summary
The system maintains two models: a base model (meta-learned initialization) and a specialized model (scene-specific). Every 30 seconds, it samples diverse, high-utility datapoints using embedding-based SCPS plus entropy filtering, labels them with a golden teacher, and retrains the specialized model from the base. The base model is updated via dynamic EWMA based on scene similarity (aggressive for similar scenes, conservative for dissimilar ones). Inference and retraining are serialized on the GPU, with sampling and base updates running on CPU in parallel.

## Key Results
- Achieves 2.8-10× reduction in retraining compute compared to baselines
- Maintains 69.3% accuracy on scene-specific classification tasks
- Reduces training set size by 8-14× through two-stage sampling
- Enables real-time adaptation on SoC devices with serialized GPU execution

## Why This Works (Mechanism)

### Mechanism 1: Embedding Convergence Reduces Adaptation Distance
Starting scene specialization from a base model (aggregating cross-scene structure) requires fewer gradient steps than fine-tuning from the prior scene's specialized model. CNNs trained on diverse visual data learn to extract structural cues (object contours, spatial layout) that generalize across lighting, weather, and perspective changes. These shared features stabilize in early layers, causing scene embeddings to converge even as raw pixels drift. A base model positioned near the centroid of past specialized models minimizes average adaptation distance to new scenes.

### Mechanism 2: Two-Stage Sampling Maintains Few-Shot Quality Without Extra Compute
Reusing inference-time embeddings for deduplication plus entropy-based uncertainty filtering yields compact, high-utility training sets without forward passes beyond live inference. Early-layer embeddings from the specialized model correlate strongly (CCA > 0.75) with base model embeddings, allowing semantic redundancy detection without recomputation. Online SCPS sampling filters similar embeddings, then entropy over base model outputs prioritizes samples where the base is uncertain—focusing gradient signal on the scene-specific delta.

### Mechanism 3: Dynamic EWMA Balances Stability and Responsiveness
Adjusting the base model update weight based on scene similarity prevents overfitting to transient drift while enabling fast adaptation to sustained distribution shifts. When consecutive scenes are similar (cosine similarity ≥ 0.9), the system uses aggressive interpolation (α = 0.3) to incorporate new structure. For dissimilar scenes—likely transient—the system uses conservative updates (α = 0.05), insulating the base from bursty noise. This runs entirely on CPU without backpropagation.

## Foundational Learning

- **Concept: Meta-learning (MAML, Reptile)**
  - Why needed here: Legilimens's base model is a meta-learned initialization optimized for fast adaptation. Understanding why Reptile suffices over MAML (no second-order gradients) explains the system's efficiency claims.
  - Quick check question: Can you explain why first-order meta-learning avoids 3-5× overhead while maintaining comparable accuracy for this specific task distribution?

- **Concept: CNN embedding spaces and feature reuse**
  - Why needed here: The core insight depends on embeddings converging across visually distinct scenes. Understanding what early vs. late layers encode explains why embedding reuse works.
  - Quick check question: Why would early-layer features (edges, textures) be more stable across scenes than late-layer features (object categories, scene semantics)?

- **Concept: Active learning and uncertainty sampling**
  - Why needed here: The entropy-based prioritization step assumes uncertain predictions indicate informative samples. This connects to broader active learning theory.
  - Quick check question: In few-shot retraining, why might high-entropy samples be more valuable than low-entropy ones, and when might this heuristic fail?

## Architecture Onboarding

- **Component map:**
  GPU (serialized): Inference (live) ↔ Retraining (periodic, paused inference)
  CPU (parallel): Online sampler (deduplication + entropy filtering), drift monitor (early stopping), base model updater (Reptile interpolation)
  Unified Memory: Base model weights, specialized model weights, embedding cache, selected training samples
  External: Golden teacher model (ResNeXt101 / YOLOv4) for pseudo-labeling

- **Critical path:**
  1. Live inference produces embeddings → cached to memory
  2. Sampler runs on CPU: SCPS deduplication → entropy filtering → top 5% selection
  3. Retraining triggered (every 30s): specialized model initialized from base → trained on selected samples
  4. Early stopping monitors marginal accuracy gain vs. drift → may halt early
  5. Base model updated via dynamic EWMA on CPU while inference resumes

- **Design tradeoffs:**
  - Memory vs. compute: Two models in memory (base + specialized) trades 2× memory footprint for 2.8-10× lower retraining compute
  - EWMA aggressiveness: Higher α speeds adaptation but risks instability; lower α is stable but sluggish
  - Training set size: More samples improve accuracy marginally (3% for 2.5× more data) but linearly increase compute

- **Failure signatures:**
  - Base model divergence: Adaptation time increases over successive scenes instead of decreasing → check if EWMA is too conservative or scene distribution has shifted fundamentally
  - Sampling misses key objects: Accuracy drops despite retraining → verify entropy threshold isn't filtering all uncertain samples; check embedding cache staleness
  - Retraining starves inference: GPU utilization shows >70% training time → early stopping threshold may be too permissive; reduce max epochs

- **First 3 experiments:**
  1. Validate embedding convergence on your data: Extract penultimate-layer embeddings from your model on 10+ hours of video; plot normalized Euclidean distance of scene centroids over time. Confirm plateau behavior before implementing full system.
  2. Ablate sampling pipeline: Compare accuracy and retraining time for (a) random sampling, (b) deduplication only, (c) full pipeline. Quantify the 8-14× training set reduction claim on your workload.
  3. Tune EWMA thresholds: Run synthetic drift scenarios (transient S2 within sustained S1) with different α values. Identify the threshold where return-to-S1 accuracy degrades <2% while S3 adaptation time remains acceptable.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the system efficiently extend to dense prediction tasks like semantic segmentation or tracking on SoC devices?
- Basis: Page 9 claims the approach is "model-agnostic and extends to other tasks such as segmentation or tracking," but only evaluates classification and detection.
- Why unresolved: These tasks typically have higher memory bandwidth and compute demands, potentially breaking the lightweight adaptation and serialization assumptions.
- What evidence would resolve it: Benchmarks of Legilimens using segmentation models (e.g., DeepLab) on Jetson-class hardware.

### Open Question 2
- Question: How does replacing periodic retraining with adaptive drift-detection triggers impact the scheduling policy?
- Basis: Page 6 Footnote 1 identifies drift detection as a "policy decision orthogonal to our design" that was not implemented.
- Why unresolved: Adaptive triggers introduce unpredictable workload bursts that may conflict with the system's inference-aware, serialized GPU scheduling.
- What evidence would resolve it: Analysis of system stability and accuracy when retraining is triggered by distribution shift rather than a fixed timer.

### Open Question 3
- Question: Is it feasible to select between multiple base models at runtime without violating compute constraints?
- Basis: Appendix A.1 demonstrates accuracy gains using multiple bases but explicitly notes the cost/feasibility of the selection mechanism was not accounted for (an oracle was used).
- Why unresolved: A real-time gating mechanism adds compute overhead that could negate the accuracy benefits on constrained SoCs.
- What evidence would resolve it: Implementation and evaluation of a non-oracle, lightweight base model selector.

## Limitations

- Claims about embedding convergence lack direct ablation studies showing how adaptation distance scales with scene diversity
- Generalization across visual domains untested; claims may not hold for drastically different domains (underwater, medical imaging)
- Dynamic EWMA adaptation shows recovery from transient drifts but doesn't test scenarios with frequent scene alternation

## Confidence

- **High Confidence:** Core system architecture and implementation details (GPU/CPU parallelization, serialized inference-training schedule, memory management)
- **Medium Confidence:** Embedding reuse efficiency. While CCA scores >0.9 justify early-layer stability, the paper doesn't validate what happens when architectures or meta-learning schedules change
- **Low Confidence:** Generalization across visual domains. The paper focuses on driving/dashcam scenarios with structurally similar scenes

## Next Checks

1. **Domain Generalization Test:** Run Legilimens on two visually disjoint datasets (e.g., urban driving + underwater inspection). Measure whether adaptation distance from base model increases rather than decreases compared to scene-specialized initialization.

2. **Sampling Ablation:** Implement controlled experiments comparing (a) random sampling, (b) deduplication only, (c) entropy filtering only, (d) full pipeline. Quantify each component's contribution to accuracy and training time reduction.

3. **Transient Drift Stress Test:** Create synthetic scenarios with rapid scene alternation (S1→S2→S1→S2 every 30 seconds). Measure base model drift magnitude and recovery time under different EWMA thresholds to identify optimal α values for bursty vs. sustained changes.