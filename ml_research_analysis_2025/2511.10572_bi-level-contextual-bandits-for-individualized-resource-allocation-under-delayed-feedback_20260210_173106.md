---
ver: rpa2
title: Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed
  Feedback
arxiv_id: '2511.10572'
source_url: https://arxiv.org/abs/2511.10572
tags:
- resource
- allocation
- delayed
- feedback
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of equitable resource allocation
  under delayed feedback in high-stakes domains such as education and healthcare.
  The authors propose a novel bi-level contextual bandit framework, MetaCUB, which
  operates at both meta and base levels: the meta level optimizes subgroup-level budget
  allocations to satisfy fairness constraints, while the base level selects the most
  responsive individuals within each group using a neural network trained on observational
  data.'
---

# Bi-Level Contextual Bandits for Individualized Resource Allocation under Delayed Feedback

## Quick Facts
- **arXiv ID:** 2511.10572
- **Source URL:** https://arxiv.org/abs/2511.10572
- **Reference count:** 34
- **One-line primary result:** Novel bi-level contextual bandit framework achieves higher cumulative outcomes and fairness parity in delayed feedback settings compared to state-of-the-art baselines.

## Executive Summary
This paper addresses equitable resource allocation under delayed feedback in high-stakes domains such as education and healthcare. The authors propose a novel bi-level contextual bandit framework, MetaCUB, which operates at both meta and base levels: the meta level optimizes subgroup-level budget allocations to satisfy fairness constraints, while the base level selects the most responsive individuals within each group using a neural network trained on observational data. The framework explicitly models temporal dynamics and feedback delays via resource-specific delay kernels, and incorporates real-world constraints like cooldown periods and cohort-based population dynamics. Experiments on real-world datasets from education (ELS) and workforce development (JOBS) demonstrate that MetaCUB achieves higher cumulative outcomes and better adapts to delay structures compared to state-of-the-art baselines. Fairness analysis shows that MetaCUB consistently attains near-parity in subgroup allocation, outperforming baselines in both delayed and immediate feedback settings.

## Method Summary
MetaCUB is a bi-level contextual bandit framework that decomposes resource allocation into two stages. At the meta level, the algorithm optimizes subgroup-level budget allocations to satisfy fairness constraints using simulation-based optimization with a learned outcome model as a surrogate. The base level then selects the most responsive individuals within each group using a neural network trained on observational data and an Upper Confidence Bound (UCB) selection rule. The framework explicitly models temporal dynamics and feedback delays via resource-specific delay kernels (discretized Beta distributions), and incorporates real-world constraints like cooldown periods and cohort-based population dynamics. The meta-level uses UCB acquisition over the simplex of subgroup budgets, while the base-level executes individual selection within the constraints set by the meta-optimizer.

## Key Results
- MetaCUB achieves higher cumulative outcomes and better adapts to delay structures compared to state-of-the-art baselines
- The framework consistently attains near-parity in subgroup allocation, outperforming baselines in both delayed and immediate feedback settings
- Experimental results on real-world datasets (ELS and JOBS) demonstrate the effectiveness of delay-aware, data-driven decision-making systems for improving institutional policy and social welfare

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Constraint Satisfaction (Bi-Level Decomposition)
- Decomposing the problem into meta-level (group budget allocation) and base-level (individual selection) reduces inter-group disparity while maintaining high cumulative outcomes compared to flat bandit algorithms
- The meta-level optimizes a fractional budget policy across subgroups first, satisfying fairness constraints before the base-level algorithm selects specific individuals
- Core assumption: The learned outcome model generalizes sufficiently to simulate policy effects accurately at the meta-level

### Mechanism 2: Kernelized Delay Attribution
- Modeling feedback delays as resource-specific probability distributions (kernels) rather than fixed lags allows for more precise credit assignment of past actions to current observed rewards
- When a reward is observed, the algorithm attributes it to past actions using a discretized Beta distribution, allowing the system to learn temporal impact profiles
- Core assumption: The delay kernel parameters are stationary and correctly specified for the domain

### Mechanism 3: Simulation-Based Meta-Optimization
- Reusing the base-level neural network as a surrogate for meta-policy evaluation avoids the computational intractability of Gaussian Processes in high-dimensional action spaces
- Instead of retraining a separate model for the meta-level, the algorithm runs stochastic rollouts using the existing base-level predictor to estimate the utility of a candidate policy
- Core assumption: The uncertainty estimates from the stochastic rollouts are a sufficient proxy for true epistemic uncertainty in the policy space

## Foundational Learning

- **Contextual Multi-Armed Bandits (MAB)**
  - **Why needed here:** The framework relies on balancing exploration and exploitation given individual feature vectors
  - **Quick check question:** Can you explain how the "Upper Confidence Bound" (UCB) formula balances predicted reward against uncertainty?

- **Delayed Feedback / Credit Assignment**
  - **Why needed here:** Standard bandit algorithms assume immediate rewards; understanding how to attribute a reward observed at time t to an action taken at t-k is central to this paper
  - **Quick check question:** If you observe a spike in GPA today, how would you determine if it was caused by a tutoring session last week or a financial aid grant last month?

- **Fairness in Allocation (Demographic Parity)**
  - **Why needed here:** The meta-level enforces equity; understanding the difference between individual fairness and group fairness is required to interpret the constraints
  - **Quick check question:** Does maximizing total GPA always result in fair allocation across different demographic subgroups? Why or why not?

## Architecture Onboarding

- **Component map:** Data Ingestion -> Meta-Policy Sampling -> Simulation (Outcome Model) -> Meta-Policy Selection -> Individual Scoring (Base) -> Allocation -> Delayed Reward Observation -> Model Update
- **Critical path:** The algorithm flows from data ingestion through meta-level policy optimization, base-level individual selection, allocation, and delayed reward observation back to model updates
- **Design tradeoffs:**
  - *Linear vs. Neural:* Linear models are faster but neural networks better capture hidden heterogeneity
  - *GP vs. Surrogate:* The paper trades the theoretical rigor of Gaussian Processes for the speed of simulation-based optimization using the existing neural network
- **Failure signatures:**
  - *High Regret under Delay:* Check if delay kernel parameters match actual data latency
  - *Unfair Allocation:* Verify meta-level constraint solver is not hitting infeasibility errors or defaulting to uniform allocation
- **First 3 experiments:**
  1. **Sanity Check (Immediate Feedback):** Run MetaCUB on a subset with no delay to verify it matches or beats standard LinUCB/UCB
  2. **Delay Kernel Sensitivity:** Test different delay kernel profiles on the JOBS dataset to observe regret trajectory changes
  3. **Fairness Ablation:** Disable meta-level constraints and measure allocation disparity ratios for different subgroups in the ELS dataset

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can MetaCUB jointly learn resource-specific delay kernels and the allocation policy online without destabilizing the exploration-exploitation balance?
- **Basis in paper:** The authors state the framework supports adaptive or meta-learned kernel estimation when greater flexibility is needed, but currently fix parameters based on plausible timing profiles
- **Why unresolved:** Learning the delay distribution simultaneously with the intervention policy introduces non-stationarity that violates standard bandit assumptions
- **What evidence would resolve it:** A convergence proof or empirical study showing regret bounds remain sub-linear while estimating kernel parameters in real-time

### Open Question 2
- **Question:** How can individual-level fairness constraints be integrated into the base-level selection without violating subgroup budget feasibility?
- **Basis in paper:** The appendix notes MetaCUB can incorporate individual-level fairness, but the only limitation is feasibility if budgets or eligibility are too restrictive
- **Why unresolved:** Enforcing strict similarity-based fairness for individuals while maintaining hard group-level parity quotas creates conflicting constraints
- **What evidence would resolve it:** A relaxed constraint formulation or soft penalty approach that guarantees convergence while approximately satisfying both individual and group fairness definitions

### Open Question 3
- **Question:** What are the formal cumulative regret bounds for the bi-level structure under delayed feedback, beyond the provided disparity reduction guarantee?
- **Basis in paper:** The paper provides Lemma 1 for disparity reduction but relies on empirical plots for cumulative regret, lacking a formal theorem bounding regret for the bi-level delayed setting
- **Why unresolved:** Analyzing regret in a hierarchical model with coupled constraints and delayed, weighted rewards is mathematically complex
- **What evidence would resolve it:** A theoretical derivation defining the upper bound of regret relative to the horizon and delay kernel properties

## Limitations
- The framework assumes stationary delay kernels; performance under distribution drift is unknown
- Meta-level simulation relies on base-level model uncertainty estimates that are not fully specified
- Theoretical fairness guarantees depend on accurate subgroup budget enforcement at the base level

## Confidence

- **High confidence:** Delayed feedback modeling improves credit assignment compared to naive approaches (supported by strong empirical results)
- **Medium confidence:** Bi-level decomposition achieves both high cumulative outcomes and fairness parity (results show disparity reduction, but the gap to flat baselines varies)
- **Low confidence:** Theoretical lemma on disparity reduction is not rigorously proven in the appendix

## Next Checks
1. Stress-test the delay kernel assumption by introducing synthetic drift in the ELS dataset and measuring allocation stability
2. Compare meta-level uncertainty estimation methods (MC dropout vs. ensemble) on base-level out-of-distribution prediction error
3. Perform a constraint violation audit: log instances where base-level UCB scores override meta-level budget quotas to quantify fairness fragility