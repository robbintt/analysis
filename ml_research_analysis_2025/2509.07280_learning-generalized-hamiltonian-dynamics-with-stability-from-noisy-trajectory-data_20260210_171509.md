---
ver: rpa2
title: Learning Generalized Hamiltonian Dynamics with Stability from Noisy Trajectory
  Data
arxiv_id: '2509.07280'
source_url: https://arxiv.org/abs/2509.07280
tags:
- hamiltonian
- dynamics
- energy
- systems
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a robust framework for learning generalized
  Hamiltonian dynamics from noisy, sparse phase-space data using variational Bayesian
  inference. The method handles conservative, dissipative, and port-Hamiltonian systems
  by parameterizing the Hamiltonian with random Fourier features and incorporating
  physics-informed regularizers for stability and conservation laws.
---

# Learning Generalized Hamiltonian Dynamics with Stability from Noisy Trajectory Data

## Quick Facts
- arXiv ID: 2509.07280
- Source URL: https://arxiv.org/abs/2509.07280
- Authors: Luke McLennan; Yi Wang; Ryan Farell; Minh Nguyen; Chandrajit Bajaj
- Reference count: 32
- Key outcome: Variational Bayesian framework learns generalized Hamiltonian dynamics from noisy, sparse phase-space data with MSE typically below 0.1, outperforming SSGP and Hamiltonian neural networks across conservative, dissipative, and port-Hamiltonian systems.

## Executive Summary
This paper presents a robust framework for learning generalized Hamiltonian dynamics from noisy, sparse phase-space data using variational Bayesian inference. The method handles conservative, dissipative, and port-Hamiltonian systems by parameterizing the Hamiltonian with random Fourier features and incorporating physics-informed regularizers for stability and conservation laws. The approach outperforms prior methods like SSGP and Hamiltonian neural networks across multiple system types, with mean squared errors typically below 0.1. For example, on the damped pendulum system, the method achieves MSE of 0.0929 compared to 0.1377 for SSGP. The framework also demonstrates improved performance under various noise levels, with MSE remaining below 0.05 even with 5% noise. The key innovation is the combination of probabilistic modeling with physics constraints, enabling accurate learning of complex phase-space dynamics while maintaining stability and respecting conservation laws.

## Method Summary
The method learns Hamiltonian dynamics by parameterizing the Hamiltonian function as a weighted sum of Random Fourier Features (RFF) with learnable parameters. It uses variational Bayesian inference to separate true system dynamics from observation noise, optimizing a variational lower bound (ELBO) that balances data fidelity against model complexity. The framework incorporates physics-informed regularizers as soft constraints to enforce energy conservation, volume preservation, and Lyapunov stability. It handles different system classes (conservative, dissipative, port-Hamiltonian) by decoupling dynamics into conservative (J), dissipative (D), and forcing (F) modules, learning distinct components based on the system type. The method uses a differentiable ODE solver for trajectory integration and trains using gradient descent-ascend or weighted optimization to balance multiple loss terms.

## Key Results
- Achieves MSE of 0.0929 on damped pendulum vs 0.1377 for SSGP baseline
- Maintains MSE below 0.05 even with 5% Gaussian noise in trajectories
- Successfully handles conservative, dissipative, and port-Hamiltonian systems with consistent performance across different system types

## Why This Works (Mechanism)

### Mechanism 1
Parameterizing the Hamiltonian with Random Fourier Features (RFF) and optimizing a variational lower bound (ELBO) allows the model to separate true system dynamics from observation noise. The model places a Gaussian Process (GP) prior on the Hamiltonian function $H$, approximated via RFF to maintain computational efficiency. Instead of deterministic regression, it maximizes the ELBO, which balances data fidelity (likelihood of observed trajectories) against the complexity of the Hamiltonian (KL divergence regularization). This probabilistic formulation treats noisy observations as stochastic realizations rather than absolute truths, filtering out noise during the integration of the dynamics. Core assumption: The observation noise is approximately Gaussian, and the true dynamics can be represented by a Hamiltonian function within the span of the chosen spectral features.

### Mechanism 2
Enforcing physics-informed regularizers (energy conservation and volume preservation) as soft constraints prevents the model from learning non-physical vector fields that fit the data but violate structural laws. The framework adds penalty terms to the loss function for violations of conservation laws. Specifically, it penalizes changes in total energy $H$ over time for conservative systems and enforces zero divergence (Liouville's theorem) to preserve phase-space volume. This guides the gradient descent to find a solution that resides on the physical manifold rather than just minimizing geometric error. Core assumption: The underlying system strictly adheres to Hamiltonian mechanics (symplecticity) and the specified conservation laws (e.g., no friction for the conservative loss term).

### Mechanism 3
Decoupling the dynamics into conservative ($J$), dissipative ($D$), and forcing ($F$) modules allows a single architecture to generalize across conservative, dissipative, and port-Hamiltonian systems. Rather than learning a monolithic vector field $\dot{x} = f(x)$, the model learns distinct components: the symplectic gradient $J\nabla H$, a damping matrix $D$, and an external forcing function $F(t)$. The framework selects the appropriate combination based on the system class. For dissipative systems, it learns $\eta$ to parameterize $D$; for port-Hamiltonian systems, it adds an MLP for $F(t)$. Core assumption: The system class (conservative vs. dissipative) is known a priori, and the dissipation/forcing structure can be captured by the parameterized forms (diagonal $D$, MLP $F$).

## Foundational Learning

- **Concept: Hamiltonian Mechanics & Symplecticity**
  - Why needed here: The entire architecture is built on the assumption that dynamics evolve on a symplectic manifold. You must understand that $\dot{q} = \partial H / \partial p$ and $\dot{p} = -\partial H / \partial q$ to interpret the model's output and the conservation constraints.
  - Quick check question: Can you explain why standard Euclidean regression fails to preserve the phase-space volume of a pendulum system?

- **Concept: Variational Inference & ELBO**
  - Why needed here: The loss function is not a simple MSE. It is a variational objective combining a likelihood term and KL divergence. Understanding this is crucial for debugging convergence and tuning the balance between fitting data and regularizing weights.
  - Quick check question: In the ELBO derivation (Eq. 21), what does the KL divergence term $KL(q(W) \| N(0, \sigma_0^2 I))$ penalize?

- **Concept: Lyapunov Stability**
  - Why needed here: The paper leverages the Hamiltonian as a Lyapunov function to enforce stability. You need to know the condition $\dot{V}(x) \leq 0$ to understand why the ReLU penalty on energy gradients is applied in Section 3.3.
  - Quick check question: Why is the Hamiltonian $H$ a natural candidate for a Lyapunov function in dissipative systems, and what constraint does $L_{Lyap}$ enforce?

## Architecture Onboarding

- **Component map:** Input (noisy trajectories) -> RFF Encoder (basis projection) -> Core (weighted sum to output $H$) -> Dynamics Layer (analytic differentiation to get $\nabla H$, combined with $D$ and $F$ modules) -> Integrator (differentiable ODE solver) -> Loss (multi-term objective)

- **Critical path:** The differentiation of the RFF basis to obtain $\nabla H$ (Eq. 7) is the central physics-informed operation. Errors here propagate directly into the vector field. Furthermore, the soft-balancing of the loss terms (via Gradient Descent-Ascent or simple weighting) is critical for convergence; standard Adam on the total sum often fails to balance the competing objectives.

- **Design tradeoffs:** Hard vs. Soft Constraints: The paper uses soft penalty terms for conservation laws. This is easier to implement than constrained optimization but requires tuning hyperparameters $\lambda$. Noise Handling: If noise levels are known a priori, the parameterization can be simplified (removing $\sigma, a$), improving performance (Table 5).

- **Failure signatures:** Volume Collapse: If $L_{Vol}$ is omitted or under-weighted, the model learns a dissipative vector field even for conservative systems (Figure 6 red line). Forcing Conflation: In port-Hamiltonian systems, if the MLP for $F(t)$ is too weak, the model may try to encode external forcing into the Hamiltonian energy, leading to non-physical energy landscapes. Optimizer Instability: Table 5 shows MTAdam can be unstable compared to GDA or equal weighting in high noise regimes.

- **First 3 experiments:**
  1. **Conservative Baseline:** Train on a noiseless Mass-Spring system. Verify that $L_{ELBO}$ alone achieves low MSE, but $L_{Vol}$ is required to keep the divergence $\nabla \cdot f \approx 0$.
  2. **Noise Robustness:** Train on the Damped Pendulum with 5% Gaussian noise. Compare "Our Method (GDA)" against SSGP to verify the stability of the ELBO objective.
  3. **Port-Hamiltonian Test:** Train on the Forced Duffing system. Inspect the learned forcing function $F_{\theta}(t)$ (implemented as an MLP) to ensure it matches the ground truth sinusoidal input, checking that the model hasn't attributed forcing to dissipation.

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework enforce conservation laws and stability as hard constraints rather than soft penalty terms? The Conclusion states, "Nonetheless, hard-constrained enforcement of conservation laws remains unresolved." The current optimization relies on soft regularization weighted by hyperparameters ($\lambda$), which biases the solution toward physics compliance but does not strictly guarantee it during inference. What evidence would resolve it: A modified architecture (e.g., using constrained optimization layers or projection methods) that yields zero violation of energy/volume conservation laws up to numerical precision.

### Open Question 2
How does the computational cost and accuracy of the RFF-based approach scale with state dimensionality in complex, real-world physical systems? The Conclusion identifies that "Scaling to high-dimensional, real-world systems also remains a key challenge for future work." The experiments were limited to low-dimensional systems (pendulums, springs, 2D Henon-Heiles), and Random Fourier Features can suffer from curse of dimensionality or require exponentially many features in high dimensions. What evidence would resolve it: Benchmarks on systems with significantly larger state spaces (e.g., molecular dynamics or soft robotics) showing maintained MSE performance and feasible training times.

### Open Question 3
Can formal theoretical guarantees be derived for the convergence and stability of the learned dynamics? The Conclusion notes that "formal guarantees are an open question." The combination of variational inference (ELBO) with physics-informed regularizers creates a complex loss landscape where standard convergence proofs do not directly apply. What evidence would resolve it: Rigorous mathematical proofs establishing bounds on the deviation between the learned Hamiltonian flow and the true underlying system under specific noise conditions.

### Open Question 4
Can the framework automatically infer the system class (conservative, dissipative, or port-Hamiltonian) from data rather than requiring it as a prior assumption? Section 2.1 states, "We assume that... the class of Hamiltonian dynamics is specified," and the model parameterization changes based on this assumption. The current methodology requires the user to manually select the correct parameter set (e.g., including $\eta$ for dissipative systems) before training begins. What evidence would resolve it: A unified model or meta-learning algorithm that can determine the presence or absence of damping/forcing terms during the training process without prior specification.

## Limitations
- Assumes system class (conservative/dissipative/port-Hamiltonian) is known a priori, limiting applicability to unknown systems
- Diagonal dissipation matrix assumption restricts modeling of systems with coupled dissipation
- Effectiveness relies on Gaussian noise assumption, which may not hold for all real-world data
- RFF basis size and noise level knowledge significantly impact performance but optimal configurations are system-dependent

## Confidence

- **High Confidence:** The core mechanism of using RFF to parameterize the Hamiltonian and variational inference to handle noise (Mechanisms 1 and 2). The empirical evidence from multiple system types and noise levels strongly supports this.
- **Medium Confidence:** The framework's ability to generalize across system types (Mechanism 3). While Table 4 shows good performance, the assumption of known system class and specific parameterizations (diagonal D, time-only F) limits confidence in truly generalized learning.
- **Low Confidence:** The robustness of the GDA hyperparameter optimization method. Table 5 shows MTAdam can be unstable, and the sensitivity to initial Î» values and update rules is not fully characterized.

## Next Checks

1. **Unknown Noise Distributions:** Validate the method's performance on non-Gaussian noise (e.g., Laplacian or heavy-tailed noise) to test the robustness of the ELBO-based noise handling beyond the assumed Gaussian case.

2. **State-Dependent Forcing:** Modify the port-Hamiltonian system experiments to include state-dependent forcing (F(q,p,t) rather than F(t)) and evaluate whether the current MLP architecture can distinguish this from dissipation effects.

3. **Automatic System Classification:** Implement an experimental setup where the system class is unknown, testing whether the framework can automatically detect whether a system is conservative, dissipative, or port-Hamiltonian from data alone, rather than requiring this information as input.