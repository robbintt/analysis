---
ver: rpa2
title: Increasing LLM response trustworthiness using voting ensembles
arxiv_id: '2510.04048'
source_url: https://arxiv.org/abs/2510.04048
tags:
- arxiv
- voting
- ensemble
- accuracy
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a theoretical framework for understanding\
  \ LLM question-answering reliability through the lens of ensemble voting. It characterizes\
  \ question difficulty using two parameters\u2014deceptiveness (\u03B4) and bewilderment\
  \ (\u03B7)\u2014and shows that restrictive voting ensembles can dramatically increase\
  \ trustworthiness by abstaining from answering when consensus is not reached."
---

# Increasing LLM response trustworthiness using voting ensembles

## Quick Facts
- arXiv ID: 2510.04048
- Source URL: https://arxiv.org/abs/2510.04048
- Authors: Aparna Nair-Kanneganti; Trevor J. Chan; Shir Goldfinger; Emily Mackay; Brian Anthony; Alison Pouch
- Reference count: 40
- The paper shows that restrictive voting ensembles can increase trustworthiness from ~70% to over 90% while maintaining accuracy in high-stakes applications.

## Executive Summary
This paper introduces a theoretical framework for understanding LLM question-answering reliability through the lens of ensemble voting. It characterizes question difficulty using two parameters—deceptiveness (δ) and bewilderment (η)—and shows that restrictive voting ensembles can dramatically increase trustworthiness by abstaining from answering when consensus is not reached. Experimental results on arithmetic and clinical-note domains demonstrate that highly restrictive voting thresholds (k/n close to 1) can increase trust from ~70% to over 90% while maintaining accuracy and only modestly reducing yield. The method is particularly valuable in high-stakes applications like healthcare where certainty is critical and every question need not be automatically answered.

## Method Summary
The method implements a voting ensemble where n homogeneous LLM agents independently answer the same question, and the ensemble returns the mode answer only if it receives at least k votes; otherwise it returns "no consensus." The framework models response behavior using a multinomial distribution over {Correct, Dominant Incorrect, Other Incorrect} with probabilities derived from deceptiveness (δ) and bewilderment (η) parameters. Experiments use Llama3-70B-instruct for arithmetic tasks and Llama3-8B-instruct for clinical note QA, with temperature=1.0 and k/n ratios swept across the range to identify trust-yield-accuracy trade-offs.

## Key Results
- Restrictive voting thresholds (k/n close to 1) can increase trustworthiness from ~70% to over 90% while maintaining accuracy
- Trust increases significantly with voting restrictiveness (from 0.61 to 0.88 for multiplication questions)
- Yield decreases monotonically with restrictiveness, but remains above 50% even at high thresholds
- The framework works across both synthetic arithmetic and real-world clinical note extraction domains

## Why This Works (Mechanism)

### Mechanism 1
Restrictive voting thresholds increase trustworthiness of returned answers by filtering out low-agreement cases. When the ensemble requires a higher proportion of agents to agree (higher k/n ratio), only questions with strong consensus produce an answer. Disagreement-heavy questions are routed to "no consensus," improving P(correct | consensus) at the cost of fewer answered questions. Agreement among agents correlates with answer correctness; disagreement signals uncertainty or deception. Break condition: When δ > 0.5 for a question, the majority consistently prefers the wrong answer—higher thresholds won't help and may accelerate wrong consensus.

### Mechanism 2
Question difficulty decomposes orthogonally into deceptiveness (δ) and bewilderment (η), which jointly determine ensemble behavior. Deceptiveness captures whether a wrong answer looks more plausible than the correct one; bewilderment captures random guessing over many wrong answers. In large ensembles, accuracy asymptotes based purely on δ (< 0.5 → perfect accuracy possible; > 0.5 → wrong-answer dominance), while η governs convergence speed. Each question has one "dominant specious" wrong answer that attracts deceived agents; other wrong answers distribute randomly. Break condition: If multiple wrong answers attract similar "deceived" frequencies (no single dominant specious), the model underestimates required ensemble size.

### Mechanism 3
Permissive voting (k=1) maximizes accuracy; restrictive voting sacrifices yield and accuracy but maximizes trust. Raising the threshold always reduces P(C) (you exclude some correct answers that didn't quite reach threshold) and reduces P(~NC) (you abstain more). The subset that passes is purer, hence higher trust. Agents are conditionally independent given the question; responses follow the multinomial defined by (δ, η). Break condition: If agents are not independent (e.g., shared prompt contamination, correlated failures), variance reductions are overstated and predicted trust gains may not materialize.

## Foundational Learning

- **Concept:** Multinomial distribution over discrete responses
  - **Why needed here:** The entire framework models n agents choosing among {Correct, Dominant Incorrect, Other Incorrect} with probabilities derived from (δ, η).
  - **Quick check question:** If n=10, δ=0.3, η=0.2, what's the single-agent P(C)? Answer: (1-δ)(1-η) = 0.7×0.8 = 0.56.

- **Concept:** Mode vs. threshold-based aggregation
  - **Why needed here:** Standard ensembling takes the mode; this method only returns the mode if it exceeds threshold k, else abstains.
  - **Quick check question:** With n=5 responses [A, A, B, C, D] and k=3, does the ensemble return A or NC? Answer: NC (only 2 votes for A, below threshold 3).

- **Concept:** Trade-off frontier (trust vs. yield vs. accuracy)
  - **Why needed here:** Practitioners must choose operating points along this frontier based on application risk tolerance.
  - **Quick check question:** In a clinical triage setting, would you optimize for trust or yield? Rationale: High trust—wrong answers are dangerous; unanswered cases can be routed to humans.

## Architecture Onboarding

- **Component map:** Query dispatcher -> Response parser -> Vote aggregator -> Threshold gate -> Metrics logger
- **Critical path:** Prompt design -> temperature setting -> n parallel generations -> answer normalization -> threshold comparison. Any drift in normalization (e.g., "42" vs "forty-two" not collapsing to same token) breaks vote counts.
- **Design tradeoffs:**
  - Higher n → better confidence estimation, but linear cost increase
  - Higher temperature → more response diversity (helps estimate η), but may increase noise
  - Higher k → higher trust, lower yield
  - Chain-of-thought prompting → higher single-agent accuracy, but may reduce answer-space discreteness (harder to vote)
- **Failure signatures:**
  - Low yield on easy questions: k set too high relative to n; or temperature too low → insufficient diversity to reach threshold
  - High trust but near-zero yield: Over-restrictive thresholds; system abstains on everything useful
  - Trust collapses at high k: δ > 0.5 for many questions; ensemble converges on wrong answers
  - Vote fragmentation: η underestimated; many unique wrong answers disperse votes, preventing any consensus
- **First 3 experiments:**
  1. Baseline calibration: On a held-out set (e.g., 100 arithmetic problems), run n=20 agents at temperature=1.0, sweep k ∈ {1, 5, 10, 15, 20}. Plot trust, yield, accuracy vs. k to identify operating frontier.
  2. Domain transfer check: Apply same k/n configuration to clinical QA (or your target domain). Measure whether δ/η distribution shifts require re-tuning thresholds.
  3. Temperature sensitivity: Fix k=10, n=20. Sweep temperature ∈ {0.3, 0.6, 1.0, 1.3}. Verify that final ensemble answer is temperature-invariant (paper claims minimal sensitivity), but check yield stability.

## Open Questions the Paper Calls Out

### Open Question 1
How does the voting ensemble framework perform when applied to heterogeneous collections of agents (e.g., different model families or sizes) rather than the homogeneous ensembles tested? The paper defines ensembles as homogeneous collections of independent agents, limiting the theoretical and experimental scope to identical models. Real-world applications often ensemble diverse models to hedge against specific model failures, but the current theoretical derivation assumes agents share the same deceptiveness (δ) and bewilderment (η) parameters. Experiments combining models of varying scales or architectures (e.g., Llama + GPT) on the arithmetic and clinical tasks would measure if trust/yield dynamics hold or require parameter weighting.

### Open Question 2
Can this voting framework be effectively adapted for open-ended generation tasks where the set of potential responses is not discrete? The framework relies on identifying a discrete correct answer C and a dominant specious answer I, which is ill-defined for natural language generation where many answers may be semantically similar but lexically distinct. The mathematical framework excludes "completely open-ended queries" from the definition of questions (Q). An extension that clusters responses by semantic similarity before applying the threshold, tested on open-ended tasks like summarization or creative writing, would resolve this.

### Open Question 3
What is the optimal strategy for resolving ties in practical ensemble sizes, and how does it impact the trade-off between yield and trust? The paper identifies ties as a "potential dilemma" and defaults to assigning ties to "No Consensus," but suggests "recruiting additional agents" or random selection as alternatives. Ties occur in practical sizes (10-50 agents) but the paper does not quantify the performance difference between proposed tie-breaking methods. A comparative analysis on the clinical dataset measuring retention of correct answers when using dynamic agent recruitment versus random selection would resolve this.

## Limitations
- The framework assumes a clean decomposition of question difficulty into orthogonal deceptiveness (δ) and bewilderment (η) components, but real-world questions often exhibit complex interactions
- The independence assumption among ensemble agents is critical but potentially violated in practice through shared training data or correlated reasoning patterns
- The framework focuses on discrete answer spaces, which may not generalize well to open-ended domains requiring nuanced judgment

## Confidence
**High Confidence Claims:**
- Restrictive voting thresholds demonstrably increase trust by filtering out low-consensus cases
- Voting ensemble methodology is mathematically sound for discrete response spaces
- The accuracy-yield-trust trade-off frontier exists and is practically useful

**Medium Confidence Claims:**
- The orthogonal decomposition of question difficulty into δ and η components is theoretically elegant but requires more empirical validation
- The asymptotic behavior predictions may not be practically achievable with finite agent pools
- Domain transfer of optimal k/n thresholds may require recalibration

**Low Confidence Claims:**
- Specific numerical estimates of δ and η for individual questions are highly sensitive to prompt design
- The claim that high thresholds are universally beneficial for high-stakes applications may not hold for questions where consensus indicates systemic error
- Temperature invariance of final ensemble answers may not hold across all model architectures

## Next Checks
1. **Independence Validation:** Design an experiment to measure correlation coefficients between agent responses in the ensemble. Generate 100 questions with known difficulty, run ensembles of size n=50, and calculate pairwise response correlations. If average correlation > 0.3, the independence assumption is violated and trust estimates may be inflated.

2. **Domain Complexity Test:** Apply the voting ensemble framework to a domain with inherently continuous or multi-dimensional outputs (e.g., medical diagnosis severity scores, financial risk ratings). Measure whether the discrete voting approach degrades performance compared to alternative aggregation methods like weighted averaging or probability calibration.

3. **Threshold Robustness Analysis:** For a subset of questions where ensemble consensus reaches k=0.9n, manually verify whether the consensus answer is actually correct. Calculate the false-consensus rate. If this rate exceeds 5% for any k/n threshold, the assumption that consensus implies correctness is violated, suggesting the framework needs additional uncertainty quantification layers.