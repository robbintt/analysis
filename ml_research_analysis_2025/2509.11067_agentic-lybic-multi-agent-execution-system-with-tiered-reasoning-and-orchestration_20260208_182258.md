---
ver: rpa2
title: 'Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration'
arxiv_id: '2509.11067'
source_url: https://arxiv.org/abs/2509.11067
tags:
- system
- execution
- task
- state
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Agentic Lybic, a multi-agent system that\
  \ addresses the challenge of automating complex desktop tasks by implementing a\
  \ finite-state machine (FSM)-based architecture for dynamic orchestration. The system\
  \ coordinates four specialized components\u2014Controller, Manager, three Worker\
  \ roles (Technician, Operator, Analyst), and Evaluator\u2014through principled routing\
  \ and continuous quality control mechanisms."
---

# Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration

## Quick Facts
- **arXiv ID:** 2509.11067
- **Source URL:** https://arxiv.org/abs/2509.11067
- **Reference count:** 40
- **Primary result:** 57.07% success rate on OSWorld benchmark

## Executive Summary
Agentic Lybic introduces a finite-state machine (FSM)-based multi-agent system for automating complex desktop tasks. The system coordinates specialized components—Controller, Manager, three Worker roles (Technician, Operator, Analyst), and Evaluator—through principled routing and continuous quality control mechanisms. By combining code-based operations, GUI interactions, and analytical decision-making, Agentic Lybic achieves state-of-the-art performance on the OSWorld benchmark, outperforming existing methods through adaptive re-planning capabilities and multi-modal execution strategies.

## Method Summary
Agentic Lybic implements a finite-state machine architecture that orchestrates four specialized components for desktop automation. The Controller maintains global state and enforces FSM logic, while the Manager handles planning and constructs Directed Acyclic Graphs (DAGs) for subtask dependencies. Three Worker roles execute specific tasks: Technician for code-based operations, Operator for GUI interactions via visual grounding, and Analyst for analytical decision-making. The Evaluator provides continuous quality control through a gate decision framework that monitors progress and triggers re-planning when necessary. The system uses OpenAI o3 for reasoning and UI-TARS for visual grounding, achieving 57.07% success rate on the OSWorld benchmark within 50 steps.

## Key Results
- Achieves 57.07% success rate on OSWorld benchmark, outperforming existing methods
- Demonstrates 12.61% improvement over the best single-agent baseline
- Shows significant gains in long-horizon task completion through adaptive re-planning

## Why This Works (Mechanism)

### Mechanism 1
Structuring the multi-agent system as a Finite-State Machine (FSM) enables robust handling of long-horizon tasks by enforcing a "state-driven" workflow rather than linear delegation. The system operates as a tuple S = (S_T, S_ST, S_E, C) governed by transition function δ, with the Central Controller managing six specific situations. If a worker stalls, the FSM forces a transition to QUALITY_CHECK rather than allowing the process to hang. This prevents error propagation and enables systematic error recovery through discrete state transitions.

### Mechanism 2
Decoupling execution into specialized "Worker" roles (Technician vs. Operator) allows the system to select the optimal interaction modality (code vs. GUI) for specific subtasks. The Manager assigns subtasks based on a Directed Acyclic Graph (DAG), routing batch processing tasks to the Technician for Bash/Python script generation and visual navigation tasks to the Operator for screenshot-based interaction. This hybrid approach prevents the brittleness of GUI-only methods while maintaining precision for programmatic operations.

### Mechanism 3
Continuous quality control via a dedicated Evaluator prevents error propagation by actively deciding whether to continue, replan, or supplement information. The Evaluator acts as a gate, triggered by events like periodic checks every 5 steps or stagnation after 3 repeated actions. It uses decision function G(s, v_t, v_{t-1}) to compare current visual state against the target, routing the system back to REPLAN if progress stalls. This active monitoring prevents small errors from cascading into complete task failure.

## Foundational Learning

- **Finite State Machines (FSM) in Software Design**
  - Why needed here: The core innovation treats the agent architecture as a formal state machine rather than free-form loop, requiring understanding of states, transitions, and triggers for debugging
  - Quick check question: Can you distinguish between a "state" (e.g., QUALITY_CHECK) and a "trigger" (e.g., rule_quality_check_steps) in this architecture?

- **Directed Acyclic Graphs (DAGs) for Task Planning**
  - Why needed here: The Manager uses DAGs to represent subtask dependencies, respecting execution order while identifying parallel execution opportunities
  - Quick check question: Why is a "cycle" in a task dependency graph fatal to a linear execution planner?

- **Visual Grounding vs. DOM-based Interaction**
  - Why needed here: The Operator worker interacts via screenshots rather than accessibility trees, highlighting why the Technician role is necessary for precision tasks
  - Quick check question: What is the primary failure mode of pure pixel-based interaction when dealing with identical-looking buttons that perform different functions?

## Architecture Onboarding

- **Component map:**
  Controller (OS) -> Manager (Strategist) -> Workers (Technician/Operator/Analyst) -> Evaluator (Conscience) -> Loop or DONE

- **Critical path:**
  User Query → Controller (INIT) → Manager (REPLAN/DAG Gen) → Controller (GET_ACTION) → Worker (Execute) → Evaluator (QUALITY_CHECK) → Loop or DONE

- **Design tradeoffs:**
  - Latency vs. Robustness: FSM introduces overhead but significantly reduces catastrophic forgetting and error propagation
  - Flexibility vs. Determinism: System relies on probabilistic models for decision-making inside deterministic state machine structure

- **Failure signatures:**
  - Infinite Loop: Repeated transitions between QUALITY_CHECK and GET_ACTION without state change
  - Modality Mismatch: Manager assigns Operator to task requiring Technician, leading to repeated gate_fail
  - Hallucinated Completion: Evaluator returns gate_done based on visual similarity despite incorrect underlying data

- **First 3 experiments:**
  1. Ablation on Quality Checks: Disable periodic quality checks to quantify Evaluator's contribution
  2. Modality Constraint: Force only Operator usage for tasks suited to Technician to benchmark hybrid efficiency
  3. Stagnation Sensitivity: Vary repeated_action_consecutive threshold to find optimal balance

## Open Questions the Paper Calls Out

- **Real-time Adaptation:** Can the current discrete FSM architecture handle continuous, real-time visual changes required for tasks like video editing or gaming?
- **Evaluation Rigidity:** To what extent does the reported success rate understate true capability due to rigid benchmark evaluation criteria?
- **Distributed Orchestration:** How can the centralized framework extend to maintain state consistency across collaborative multi-user or distributed environments?

## Limitations
- Heavy dependence on OpenAI o3 and proprietary UI-TARS models limits reproducibility
- FSM architecture may introduce latency incompatible with real-time interaction requirements
- Evaluation limited to Linux environment, with no validation on Windows or macOS platforms

## Confidence

**High Confidence:** The FSM-based architectural design and principle of specialized worker roles are well-supported by methodology and align with established multi-agent principles.

**Medium Confidence:** The 57.07% success rate is plausible given design, but lack of detailed implementation specifications makes independent verification challenging.

**Low Confidence:** Claims about real-world adaptability are speculative without empirical validation beyond the controlled OSWorld benchmark.

## Next Checks

1. Conduct ablation study on quality control mechanisms to quantify the Evaluator's contribution to long-horizon task success
2. Perform modality sensitivity test by forcing GUI-only interactions for code-suitable tasks to benchmark hybrid architecture efficiency
3. Validate system performance on at least one additional desktop environment (Windows or macOS) to assess cross-platform generalization