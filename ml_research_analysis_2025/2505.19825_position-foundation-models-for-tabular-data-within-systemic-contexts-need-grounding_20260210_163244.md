---
ver: rpa2
title: 'Position: Foundation Models for Tabular Data within Systemic Contexts Need
  Grounding'
arxiv_id: '2505.19825'
source_url: https://arxiv.org/abs/2505.19825
tags:
- data
- https
- tabular
- learning
- operational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that foundation models for tabular data are limited
  by missing operational context - the procedural logic, rules, and domain knowledge
  that govern how data is created. Current approaches focus on isolated tables or
  schema-level relationships, missing the operational knowledge that gives data meaning.
---

# Position: Foundation Models for Tabular Data within Systemic Contexts Need Grounding

## Quick Facts
- arXiv ID: 2505.19825
- Source URL: https://arxiv.org/abs/2505.19825
- Authors: Tassilo Klein; Johannes Hoffart
- Reference count: 40
- Primary result: Foundation models for tabular data are limited by missing operational context—the procedural logic, rules, and domain knowledge that govern how data is created—and need grounding in Semantically Linked Tables (SLT) to achieve true understanding.

## Executive Summary
This paper argues that current foundation models for tabular data fail because they treat tables as isolated statistical patterns rather than as products of operational systems governed by rules and business logic. The authors propose Semantically Linked Tables (SLT) as a new model class that grounds tabular data in its operational context, combining relational data with declarative knowledge (policies, rules) and procedural knowledge (source code, validation scripts). They advocate for a dual-phase training approach: pre-training on open-source code-data pairs and synthetic systems to learn business logic mechanics, followed by zero-shot inference on proprietary data. The paper introduces the "Operational Turing Test" benchmark to evaluate whether models truly understand operational semantics versus pattern memorization, calling for community collaboration to advance privacy-preserving data generation and novel architectures purpose-built for operational grounding.

## Method Summary
The proposed approach uses a two-phase Retrieval-Augmented In-Context Learning (RAICL) framework. Phase 1 pre-trains models on open-source code-data pairs and procedurally generated synthetic "System-Table" pairs to learn the meta-capability of applying arbitrary rules to table rows (P(Row|Rule)). The synthetic generator creates business logic (Python validation functions), table states, and execution traces with injected noise and "simulated technical debt" to capture real-world complexity. Phase 2 performs zero-shot inference on proprietary data by retrieving relevant operational artifacts (declarative knowledge like policies and knowledge graphs, procedural knowledge like source code and validation scripts, and relational data like tables linked by foreign keys) and applying the learned reasoning capability. The model ingests code as executable logic (execution semantics) rather than text patterns, enabling perfect accuracy on policy boundaries without training examples.

## Key Results
- Current RAG approaches retrieve code as text, whereas FMSLTs must ingest code as logic to learn causal executable semantics rather than surface-level text patterns.
- Pre-training on execution traces (observing code-data interactions at runtime) learns superior world models versus static code alone.
- The proposed dual-phase bootstrapping from open-source code-data pairs and synthetic systems can learn operational semantics publicly, then specialize privately without exposing sensitive rows.

## Why This Works (Mechanism)

### Mechanism 1: Code-as-Logic Grounding
Pre-training on code execution traces teaches models causal decision boundaries that statistical correlation cannot recover. The model ingests conditional logic (e.g., `if amount >= 5000: require_approval()`) as executable semantics rather than text patterns, enabling perfect accuracy on policy rules without training examples. Core assumption: logical reasoning capabilities transfer across modalities. Evidence: SALT-KG benchmark (FMR=0.56) links enterprise tables to operational knowledge but does not validate code-as-logic transfer.

### Mechanism 2: Dual-Phase Bootstrapping for Privacy Preservation
Models learn operational reasoning mechanics from public code-data pairs, then transfer zero-shot to proprietary data without exposing sensitive rows. Phase 1 pre-trains on open-source ecosystems and synthetic systems to learn the meta-skill of "reading code to predict data outcomes." Core assumption: operational semantics are domain-invariant. Evidence: No corpus papers validate cross-domain transfer of operational reasoning—this remains untested.

### Mechanism 3: Synthetic-to-Real In-Context Learning Transfer
Procedurally generated "System-Table" pairs teach models the meta-capability of applying arbitrary unseen rules to table rows, bypassing privacy constraints. Synthetic data generators create business logic paired with corresponding table states and execution traces. The model learns P(Row|Rule) as a generalizable skill rather than memorizing specific correlations. Core assumption: logical reasoning is modality-invariant. Evidence: Related work on tabular ICL shows in-context learning matches gradient boosting but does not test synthetic-to-real transfer for operational logic.

## Foundational Learning

- **Operational Knowledge (Declarative vs. Procedural)**: FMSLT requires distinguishing between "what the rules are" (declarative: knowledge graphs, policy documents) and "how systems execute them" (procedural: application code, validation scripts). This distinction enables the code-as-logic mechanism. Quick check: Given a business rule ("expenses over $5k require approval"), can you identify both its declarative representation (policy PDF) and procedural implementation (approval.py line 47)?

- **Semantically Linked Tables (SLT)**: SLT provides the semantic frame combining relational data, operational business knowledge, and world knowledge. Understanding this three-layer structure is prerequisite to designing FMSLT architectures. Quick check: For a supply chain database, can you map which tables provide relational structure vs. which operational logic governs valid configurations?

- **In-Context Learning for Tabular Data**: FMSLTs leverage ICL as the mechanism for zero-shot operational reasoning. Unlike fine-tuning, ICL applies learned reasoning skills to new rules without gradient updates. Quick check: Given a new validation rule and 3 example rows, can the model predict outcomes for unlabeled rows? (This is the core ICL capability FMSLT requires.)

## Architecture Onboarding

- **Component map**: Synthetic Data Generator -> Pre-training Pipeline -> Retrieval Module -> Inference Engine

- **Critical path**: Build synthetic generator capturing operational complexity; pre-train on synthetic system-table pairs until model generalizes to unseen rules; implement retriever for mapping database rows to originating code functions (the "Provenance Gap"); validate on Operational Turing Test

- **Design tradeoffs**: Synthetic fidelity vs. privacy (more realistic synthetic data risks memorizing proprietary patterns); retrieval granularity vs. latency (fine-grained artifact retrieval improves grounding but increases inference time); ICL capacity vs. model size (larger models handle more complex rules but may be impractical for edge deployment)

- **Failure signatures**: Model approximates thresholds from correlation rather than exact policy rules; cannot explain decisions by citing operational artifacts (fails Operational Turing Test); accuracy degrades on edge cases where rules conflict or are overridden

- **First 3 experiments**: 1) Train small FMSLT on synthetic expense approval system; test if it achieves 100% accuracy on the >=5000 threshold rule vs. baseline LLM; 2) Pre-train on open-source ERP code-data pairs; evaluate zero-shot performance on held-out synthetic business logic without fine-tuning; 3) Compare FMSLT performance with vs. without retriever access to procedural code; quantify grounding contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can foundation models pass the Operational Turing Test—correctly predicting transaction outcomes and citing relevant operational artifacts solely by reading an organization's declarative knowledge, procedural knowledge, and relational data with only few-shot examples?
- Basis in paper: [explicit] Section 6 formally defines the Operational Turing Test benchmark and states "We assert that no existing tabular foundation model can pass this test."
- Why unresolved: The benchmark requires models to perform zero-shot operational reasoning rather than statistical pattern matching, demanding genuine comprehension of business logic across modalities (code, documents, schemas) that current architectures cannot achieve.
- What evidence would resolve it: A model achieving high accuracy on transaction prediction while correctly tracing decisions to specific source code locations and policy documents in held-out simulated organizations.

### Open Question 2
- Question: How can models be trained to ingest procedural code as executable logic (code-as-logic) rather than merely as text patterns (code-as-text)?
- Basis in paper: [explicit] The paper explicitly contrasts RAG retrieving "code as text" versus FMSLT ingesting "code as logic—learning the causal executable semantics (e.g., branching paths) rather than just surface-level text patterns" (page 2).
- Why unresolved: Current LLMs trained on static code corpora cannot reliably distinguish hard decision boundaries (e.g., `if amount >= 5000`) from learned statistical correlations, leading to systematic errors at boundary conditions.
- What evidence would resolve it: Architectures demonstrating perfect accuracy on policy boundaries without training examples, and ablation studies showing execution-trace pre-training improves boundary reasoning over static-code pre-training.

### Open Question 3
- Question: How can the "Provenance Gap"—mapping database rows to the specific code functions that generated or validated them—be bridged for legacy systems lacking comprehensive logging?
- Basis in paper: [explicit] Section 4 identifies this as "a critical challenge" noting that "retrofitting provenance for legacy systems remains an open problem."
- Why unresolved: Modern microservices may provide traceability, but enterprise environments often contain decades-old systems where data-generating code is undocumented, lost, or entangled with deprecated workflows.
- What evidence would resolve it: Automated provenance reconstruction methods achieving high precision/recall on benchmark legacy systems, or alternative grounding approaches that bypass explicit provenance requirements.

### Open Question 4
- Question: What methods can generate privacy-preserving synthetic multi-table data that preserves complex inter-table dependencies, procedural constraints, and realistic data quality issues (noise, version conflicts, technical debt)?
- Basis in paper: [explicit] Section 6 explicitly calls for investment in methods generating "high-fidelity, multi-table synthetic data preserving complex relational dependencies and operational semantics" and Section 3.4 notes generators "must avoid 'too clean' data by injecting noise, version conflicts, and 'simulated technical debt'."
- Why unresolved: Existing approaches (GANs, diffusion models) capture statistical distributions but not procedural constraints or temporal dynamics; methods for systematically injecting realistic data quality issues remain unspecified.
- What evidence would resolve it: Synthetic benchmarks where models trained only on synthetic data achieve comparable performance on held-out real operational data, with privacy audits confirming no PII leakage.

## Limitations
- No specific FMSLT architecture is defined, making implementation and evaluation uncertain.
- The "Operational Turing Test" benchmark lacks defined evaluation criteria and scoring methodology.
- The core hypothesis that code pre-training transfers operational reasoning capabilities across domains remains untested.

## Confidence
- **High Confidence**: Problem framing is well-justified—standard tabular foundation models miss operational context, and RAG approaches treating code as text are insufficient.
- **Medium Confidence**: Dual-phase bootstrapping approach and synthetic-to-real transfer hypothesis are logically coherent but remain untested.
- **Low Confidence**: Specific FMSLT architecture, retriever design, and Operational Turing Test implementation details are not specified.

## Next Checks
1. **Sanity Check Implementation**: Build a minimal FMSLT prototype trained on synthetic expense approval systems to verify whether models can learn exact decision boundaries (e.g., $4,999 vs $5,000) rather than statistical approximations. Compare against standard LLM baselines.

2. **Cross-Domain Transfer Study**: Pre-train on open-source ERP code-data pairs, then evaluate zero-shot performance on held-out synthetic business logic from different domains (e.g., healthcare billing vs. retail inventory). Measure performance degradation as domain divergence increases.

3. **Operational Turing Test Pilot**: Design and implement a small-scale Operational Turing Test benchmark with 10-15 simulated organizations, each with unique operational artifacts. Evaluate FMSLT models on outcome prediction accuracy and artifact citation quality, comparing against RAG baselines and human experts.