---
ver: rpa2
title: 'HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge
  Graph Alignment'
arxiv_id: '2512.01659'
source_url: https://arxiv.org/abs/2512.01659
tags:
- legal
- entity
- hallugraph
- source
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HalluGraph introduces a graph-theoretic framework for detecting
  hallucinations in legal AI systems by quantifying structural alignment between knowledge
  graphs extracted from source documents and generated responses. It decomposes hallucination
  detection into Entity Grounding (measuring whether response entities appear in source
  documents) and Relation Preservation (verifying asserted relationships are supported
  by context), combined into a Composite Fidelity Index.
---

# HalluGraph: Auditable Hallucination Detection for Legal RAG Systems via Knowledge Graph Alignment

## Quick Facts
- arXiv ID: 2512.01659
- Source URL: https://arxiv.org/abs/2512.01659
- Reference count: 16
- Primary result: HalluGraph achieves AUC 0.94-0.84 on legal hallucination detection vs. semantic baselines at 0.54-0.60

## Executive Summary
HalluGraph introduces a graph-theoretic framework for detecting hallucinations in legal AI systems by quantifying structural alignment between knowledge graphs extracted from source documents and generated responses. It decomposes hallucination detection into Entity Grounding (measuring whether response entities appear in source documents) and Relation Preservation (verifying asserted relationships are supported by context), combined into a Composite Fidelity Index. On legal document understanding tasks involving contracts and case law, HalluGraph achieves AUC scores of 0.94-0.84, significantly outperforming semantic similarity baselines that fail to penalize entity errors.

## Method Summary
HalluGraph extracts (subject, relation, object) triples from legal documents and generated responses using a combination of spaCy NER for entities and Llama 3.1 8B for relation extraction. It constructs knowledge graphs for context and response, then computes Entity Grounding (fraction of response entities matching source) and Relation Preservation (fraction of response relations supported by source context). These metrics combine into a Composite Fidelity Index with α≈0.7 weighting favoring entity grounding. The framework targets entity substitution hallucinations that semantic similarity metrics miss.

## Key Results
- Achieves AUC 0.94-0.84 on legal contracts and case law vs. semantic baselines at 0.54-0.60
- Outperforms NLI (0.69-0.92 AUC) and Named Entity Overlap baselines
- Strong performance requires documents >400 words and >20 entities; fails on short documents (<10 entities)

## Why This Works (Mechanism)

### Mechanism 1: Structural Decomposition of Faithfulness
Hallucination detection can be decomposed into orthogonal components—entity-level grounding and relation-level preservation—that together capture distinct failure modes semantic metrics miss. Entity Grounding computes the fraction of response entities matching source entities via type + normalized text comparison. Relation Preservation checks if each response triple has a supported counterpart in the reference graph. CFI combines them with learned weighting (α≈0.7 favoring EG). Core assumption: Entity substitutions constitute material errors in legal contexts detectable via structural mismatch rather than embedding distance.

### Mechanism 2: Regime-Dependent Graph Density Threshold
HalluGraph's effectiveness depends critically on document structure—specifically context length and entity density—creating an operating regime where performance is either strong or fails predictably. Documents with >400 words and >20 entities produce sufficiently dense knowledge graphs for meaningful alignment. Below this threshold, empty or near-empty graphs yield unreliable metrics. Core assumption: Legal documents naturally fall into the high-density regime due to their entity-rich structure.

### Mechanism 3: Extractor-Quality Bounding
HalluGraph's detection accuracy is upper-bounded by the underlying triple extractor's ability to correctly identify entities and relations from legal text. Uses spaCy NER with legal extensions for entities and an instruction-tuned SLM (Llama 3.1 8B) for (subject, relation, object) extraction. Complex phrasing causes entity drops, lowering factual scores. Core assumption: Small generative models with strong prompts can capture context-specific legal relationships that discriminative models cannot enumerate a priori.

## Foundational Learning

- **Knowledge Graphs and Triple Extraction (OpenIE)**
  - Why needed here: HalluGraph's entire approach assumes you can reliably convert unstructured legal text into (subject, relation, object) triples. Without understanding OpenIE conventions and KG construction, you cannot debug extraction failures or interpret alignment results.
  - Quick check question: Given the sentence "Tenant shall pay Landlord $5,000 on the first day of each month," what triples would you expect to extract?

- **Graph Alignment and Subgraph Isomorphism**
  - Why needed here: The theoretical guarantee (Proposition 1) and RP metric depend on understanding when one graph "embeds" into another. The alignment function determines whether a response relation is "supported" by source context.
  - Quick check question: If G_response has edge (A, "owes", B) and G_source has edge (A, "indebted_to", B), should align() return true? What tradeoffs does this involve?

- **Retrieval-Augmented Generation (RAG) Failure Modes**
  - Why needed here: HalluGraph is designed as a post-generation guardrail for RAG systems. Understanding how RAG can retrieve correct documents but still produce unfaithful outputs motivates why structural verification is necessary.
  - Quick check question: A RAG system retrieves the correct contract clause but outputs "The penalty is $10,000" when the clause says "The penalty shall not exceed $1,000." Would semantic similarity catch this? Would HalluGraph?

## Architecture Onboarding

- **Component map**: Response → Triple extraction → Ga construction → EG/RP computation against Gc∪Gq → CFI threshold decision
- **Critical path**: Response → Triple extraction → Ga construction → EG/RP computation against Gc∪Gq → CFI threshold decision. Extractor quality directly bounds end-to-end performance.
- **Design tradeoffs**: Generative vs. discriminative extractor (generative handles arbitrary relations but is slower); α weighting (higher α prioritizes entity errors but may underweight structural hallucinations); caching (pre-compute graphs for frequent authorities vs. staleness).
- **Failure signatures**: Near-chance AUC on short documents (<100 words, <10 entities); false negatives on complex clauses; high RP but low EG (entity substitution); high EG but low RP (fabricated relations).
- **First 3 experiments**:
  1. **Regime validation on your data**: Sample 50 documents from your target legal domain; compute (word count, entity count) distribution. If median <300 words or <15 entities, HalluGraph may not be appropriate without adaptation.
  2. **Extractor benchmark**: Manually annotate triples from 10 representative clauses; compare extractor output to ground truth. Measure precision/recall on both entities and relations separately.
  3. **Threshold calibration**: Using labeled factual/hallucinated pairs (can synthesize via entity substitution), sweep CFI threshold to find operating point that balances false positive rate vs. false negative rate.

## Open Questions the Paper Calls Out

### Open Question 1
Can HalluGraph's detection performance be maintained when the triple extractor is distilled into lighter models for high-throughput legal AI deployments? The paper proposes distillation as a mitigation but does not evaluate whether smaller extractors preserve extraction quality or how compression affects EG/RP scores.

### Open Question 2
To what extent do extraction errors from the SLM introduce false negatives in hallucination detection, and can metrics like MINE quantify this upper bound? The paper acknowledges extractor errors but does not measure how often the extractor itself hallucinates or misses entities, which could artificially lower fidelity scores.

### Open Question 3
How robust is HalluGraph on diverse real-world legal workflows beyond synthetic control domains and the specific contract/case law tasks evaluated? The evaluation uses synthetic QA pairs generated from documents; performance on naturally occurring legal queries, multi-document reasoning, or regulatory compliance workflows is unknown.

## Limitations
- Operating regime restriction: Performance degrades sharply below 400 words and 20 entities per document
- Extractor dependency ceiling: Entire framework is bounded by the underlying triple extractor's quality
- Dataset specificity: Evaluation relies on proprietary or unpublished legal corpora without publicly available benchmarks

## Confidence

**High Confidence**: Semantic similarity baselines fail to detect entity substitution hallucinations; decomposition into Entity Grounding and Relation Preservation provides complementary coverage; performance advantage is statistically significant on tested legal datasets.

**Medium Confidence**: α≈0.7 weighting favoring Entity Grounding is optimal for tested datasets but may not generalize; 400-word/20-entity density threshold is empirically observed but not theoretically derived; claims about extractor quality bounding are reasonable but not experimentally validated.

**Low Confidence**: Claims about framework's general applicability to "any legal document understanding task" without empirical validation beyond contracts and case law; assertion that HalluGraph provides "full audit trails" is supported by output format descriptions but not demonstrated through traceability studies; scalability claims to large-scale production systems lack latency and resource usage measurements.

## Next Checks

1. **Density Validation Study**: Analyze your organization's legal document corpus to determine the percentage falling below the 400-word/20-entity threshold. Document the distribution and assess whether HalluGraph's operating regime covers your use cases.

2. **Extractor Quality Benchmark**: Implement HalluGraph's extraction pipeline and conduct a controlled evaluation against manually annotated triples from 50 representative legal clauses. Measure precision/recall separately for entities and relations, and identify failure patterns.

3. **Cross-Domain Transfer Test**: Evaluate HalluGraph on at least two additional legal document types not in the original study (e.g., regulatory filings, discovery documents, or legislative texts). Compare performance degradation patterns to identify domain adaptation requirements.