---
ver: rpa2
title: 'NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation
  of LLM via Genetic Optimization of External Knowledge'
arxiv_id: '2510.21144'
source_url: https://arxiv.org/abs/2510.21144
tags:
- knowledge
- external
- posr
- generation
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NeuroGenPoisoning, a novel attack framework
  that generates adversarial external knowledge in RAG systems guided by LLM internal
  neuron attribution and genetic optimization. The method first identifies Poison-Responsive
  Neurons whose activation strongly correlates with contextual poisoning knowledge,
  then uses a genetic algorithm to evolve adversarial passages that maximally activate
  these neurons.
---

# NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge

## Quick Facts
- **arXiv ID:** 2510.21144
- **Source URL:** https://arxiv.org/abs/2510.21144
- **Reference count:** 40
- **Primary result:** Achieves >90% Population Overwrite Success Rate (POSR) in poisoning RAG systems to override LLM parametric knowledge

## Executive Summary
NeuroGenPoisoning introduces a novel attack framework that generates adversarial external knowledge for RAG systems by combining LLM internal neuron attribution with genetic optimization. The method first identifies Poison-Responsive Neurons whose activation strongly correlates with contextual poisoning knowledge, then uses a genetic algorithm to evolve adversarial passages that maximally activate these neurons. This approach enables massive-scale generation of effective poisoned RAG knowledge while maintaining fluency, particularly excelling in knowledge conflict settings where models have strong internal memory of correct answers.

## Method Summary
The approach operates in three main phases: First, it identifies top-r Poison-Responsive Neurons via Integrated Gradients attribution on seed query-context pairs, selecting neurons most frequently associated with poisoning across samples. Second, it initializes a population of adversarial passages using GPT-4 to generate diverse misleading content embedding target incorrect answers. Third, it evolves these passages through a genetic algorithm (10 generations) using neuron activation as fitness, applying crossover and mutation operators until achieving >90% POSR. The framework resolves knowledge conflicts by leveraging neuron-guided optimization to override strong parametric knowledge with carefully crafted external context.

## Key Results
- Consistently achieves Population Overwrite Success Rate (POSR) >90% across multiple datasets and models
- Effectively resolves knowledge conflicts where models have strong parametric knowledge of correct answers
- Maintains fluency with preserved perplexity scores while achieving high attack success rates
- Demonstrates effectiveness across LLaMA-2-7b, Vicuna-7b/13b, and Gemma-7b models on SQuAD 2.0, TriviaQA, and WikiQA datasets

## Why This Works (Mechanism)
The method exploits the correlation between specific neuron activations and model responses to poisoned context, using these neurons as optimization targets. By identifying neurons that respond strongly to poisoning attempts and evolving text to maximize their activation, the attack can systematically override parametric knowledge with external knowledge. The genetic algorithm efficiently explores the space of possible poisoned passages while maintaining fluency constraints, and the neuron-guided approach allows for scalable generation of adversarial examples by reusing successful attribution patterns.

## Foundational Learning
- **Integrated Gradients attribution** - Explains how input features contribute to neuron activations; needed to identify which neurons respond to poisoning attempts; quick check: verify attribution scores sum to model output difference
- **Poison-Responsive Neurons** - Neurons whose activation strongly correlates with contextual poisoning knowledge; needed as optimization targets; quick check: measure attribution score correlation across samples
- **Genetic algorithm optimization** - Evolutionary approach to text generation using fitness functions; needed to efficiently explore adversarial passage space; quick check: monitor fitness convergence across generations
- **Population Overwrite Success Rate (POSR)** - Metric measuring attack effectiveness in forcing incorrect answers; needed to quantify poisoning success; quick check: validate POSR calculation methodology
- **Knowledge conflict resolution** - Ability to override parametric knowledge with external context; needed for real-world RAG attack scenarios; quick check: test with known model parametric knowledge

## Architecture Onboarding
- **Component map:** Query + Context -> IG Attribution -> Neuron Selection -> GPT-4 Initialization -> Genetic Evolution -> Poison-Responsive Passages -> RAG System -> Incorrect Answer
- **Critical path:** Neuron identification (IG attribution) → Population initialization (GPT-4) → Genetic optimization (10 generations) → POSR evaluation
- **Design tradeoffs:** White-box neuron access vs. black-box feasibility; computational cost of IG attribution vs. attack effectiveness; population diversity vs. convergence speed
- **Failure signatures:** Low initial POSR (<40%) indicates poor initialization; POSR plateau suggests suboptimal neuron selection; high perplexity indicates aggressive mutation
- **First experiments:** 1) Run neuron identification on sample queries to validate top-r selection stability; 2) Initialize population with GPT-4 and measure baseline POSR; 3) Execute 2-3 generations of GA to observe fitness improvement patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Requires white-box access to compute neuron attributions, limiting practical deployment
- Evaluation focuses primarily on knowledge conflict scenarios, not general RAG robustness
- Critical genetic algorithm parameters (population size, operators) are underspecified

## Confidence
- **Neuron attribution and selection granularity:** Medium confidence in concept, Low confidence in exact reproducibility
- **Genetic algorithm implementation details:** Low confidence due to missing critical parameters
- **Evaluation scope and generalization:** Medium confidence for knowledge conflicts, Low for general adversarial robustness
- **Computational requirements:** High confidence in theoretical soundness, Low confidence in practical feasibility

## Next Checks
1. **Neuron selection stability test:** Run neuron identification on multiple random subsets of queries and measure overlap in top-r neuron selections
2. **Ablation of genetic operators:** Systematically test different GA configurations (population sizes, crossover/mutation rates) to establish critical parameters
3. **Cross-model neuron transferability:** Evaluate whether poison-responsive neurons from one model can effectively generate adversarial knowledge for another model