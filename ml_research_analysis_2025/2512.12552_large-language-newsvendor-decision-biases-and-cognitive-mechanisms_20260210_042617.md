---
ver: rpa2
title: 'Large Language Newsvendor: Decision Biases and Cognitive Mechanisms'
arxiv_id: '2512.12552'
source_url: https://arxiv.org/abs/2512.12552
tags:
- decision
- biases
- cognitive
- demand
- newsvendor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how leading LLMs (GPT-4, GPT-4o, and LLaMA-8B)
  make decisions in the newsvendor problem, a canonical inventory management model.
  Through dynamic multi-round experiments across different demand distributions, the
  research reveals that LLMs consistently replicate and often amplify human cognitive
  biases like the "Too Low/Too High" ordering pattern, with GPT-4 deviating up to
  70% more than human benchmarks.
---

# Large Language Newsvendor: Decision Biases and Cognitive Mechanisms

## Quick Facts
- **arXiv ID**: 2512.12552
- **Source URL**: https://arxiv.org/abs/2512.12552
- **Reference count**: 10
- **Primary result**: LLMs replicate and amplify human cognitive biases in inventory decisions, with sophisticated models showing greatest deviations due to overanalysis.

## Executive Summary
This study investigates how leading LLMs (GPT-4, GPT-4o, and LLaMA-8B) make decisions in the newsvendor problem, a canonical inventory management model. Through dynamic multi-round experiments across different demand distributions, the research reveals that LLMs consistently replicate and often amplify human cognitive biases like the "Too Low/Too High" ordering pattern, with GPT-4 deviating up to 70% more than human benchmarks. A key finding is the "paradox of intelligence" - GPT-4, despite being the most sophisticated, exhibited the greatest deviations due to overanalysis, while efficiency-optimized GPT-4o achieved near-optimal performance. The study concludes that these biases stem from architectural constraints rather than knowledge gaps, as they persisted even when optimal formulas were provided. These findings highlight the need for human oversight in AI-assisted inventory decisions and suggest that structured, rule-based prompts can effectively constrain heuristic tendencies.

## Method Summary
The researchers conducted controlled experiments using three leading LLMs (GPT-4, GPT-4o, and LLaMA-8B) across multiple rounds of newsvendor problems with varying demand distributions. They compared LLM performance against established human decision-making benchmarks to identify bias patterns. The study employed both synthetic demand distributions for controlled analysis and provided optimal formulas to test whether knowledge gaps were responsible for suboptimal decisions. Performance metrics included ordering patterns, deviation from optimal solutions, and comparison across different model architectures and prompt structures.

## Key Results
- LLMs consistently exhibit the "Too Low/Too High" ordering pattern seen in human decision-makers
- GPT-4 deviated up to 70% more than human benchmarks, demonstrating the "paradox of intelligence"
- Efficiency-optimized GPT-4o achieved near-optimal performance while more sophisticated models overanalyzed
- Biases persisted even when optimal formulas were provided, indicating architectural rather than knowledge limitations
- Structured, rule-based prompts can effectively constrain heuristic tendencies in LLM decision-making

## Why This Works (Mechanism)
Assumption: The persistent bias patterns across different LLMs suggest these models inherit human-like cognitive shortcuts through training data patterns. The overanalysis phenomenon in sophisticated models like GPT-4 may occur because increased model capacity allows for more complex reasoning loops that ultimately lead to decision paralysis or overcomplication of relatively straightforward optimization problems.

## Foundational Learning
Unknown: While the paper demonstrates that LLMs replicate human biases in inventory decisions, it does not explicitly examine whether these models learned these biases from training data containing human decision examples, or whether the biases emerge from fundamental architectural constraints in how transformers process sequential decision problems.

## Architecture Onboarding
Assumption: The findings suggest that transformer architectures may have inherent tendencies toward heuristic-based decision-making when faced with optimization problems, particularly those involving uncertainty and trade-offs. This architectural predisposition appears to manifest regardless of model sophistication, though more capable models may amplify these tendencies through overanalysis.

## Open Questions the Paper Calls Out
None

## Limitations
- Findings based on newsvendor problem may not generalize to other decision-making domains or broader classes of cognitive biases
- Controlled experimental conditions differ significantly from real-world business environments with additional contextual factors
- Reliance on synthetic demand distributions may not fully capture complexity of real market conditions
- Does not explore interaction between different types of cognitive biases or their compounding effects in complex scenarios
- Limited investigation into whether bias patterns vary across different prompt formulations or domain-specific knowledge incorporation

## Confidence
**High Confidence**: LLMs consistently exhibit ordering biases similar to human decision-makers, with robust empirical evidence across multiple rounds and demand distributions.

**Medium Confidence**: Biases stem from architectural constraints rather than knowledge gaps, though this conclusion requires further investigation across different problem types.

**Low Confidence**: The "paradox of intelligence" finding may be specific to the newsvendor context and may not generalize across domains or other optimization problems.

## Next Checks
1. Test the same LLMs on other canonical decision-making problems (e.g., portfolio optimization, project selection) to determine whether bias patterns are specific to inventory management or represent a more general phenomenon.

2. Conduct experiments using actual historical demand data from retail or supply chain operations to assess whether bias patterns persist under realistic market conditions with noise, seasonality, and correlations.

3. Investigate how multiple biased LLMs interact in supply chain scenarios (e.g., vendor-buyer relationships) where decisions are interdependent, examining whether collective behaviors amplify or mitigate individual biases.