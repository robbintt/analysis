---
ver: rpa2
title: 'ProteinGuide: On-the-fly property guidance for protein sequence generative
  models'
arxiv_id: '2505.04823'
source_url: https://arxiv.org/abs/2505.04823
tags:
- sequences
- guidance
- sampling
- used
- protein
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ProteinGuide, a method for on-the-fly conditioning
  of pre-trained protein sequence generative models using auxiliary property information
  without retraining. ProteinGuide works by modulating the sampling process of pre-trained
  models using Bayes' Rule to incorporate predictive models of desired properties.
---

# ProteinGuide: On-the-fly property guidance for protein sequence generative models

## Quick Facts
- arXiv ID: 2505.04823
- Source URL: https://arxiv.org/abs/2505.04823
- Reference count: 40
- Key outcome: ProteinGuide enables on-the-fly conditioning of pre-trained protein sequence generative models using auxiliary property information without retraining

## Executive Summary
ProteinGuide introduces a novel method for guiding pre-trained protein sequence generative models to satisfy auxiliary property constraints without requiring model retraining. The approach works by modulating the sampling process using Bayes' Rule to incorporate predictive models of desired properties, enabling conditioning of diverse model architectures including Masked Language Models, autoregressive models, and diffusion/flow matching models. The method demonstrates effectiveness across interpolative, extrapolative, and multi-property design settings, with particularly compelling in vivo results showing that guided generation achieved higher adenine base editor efficiency in a single round than seven rounds of directed evolution.

## Method Summary
ProteinGuide works by modulating the sampling process of pre-trained generative models using Bayes' Rule to incorporate predictive models of desired properties. For a discrete state space, the conditional transition rate is derived as the unconditional rate multiplied by the likelihood ratio $\frac{p(y|\tilde{x})}{p(y|x)}$, biasing sampling toward states with higher property likelihood while preserving the pre-trained model's prior structure. The method supports both exact guidance (scoring all transitions) and Taylor-approximate guidance (TAG) for computational efficiency, and applies to a broad class of protein generative models by establishing their mathematical equivalence under a masking-based Continuous Time Markov Chain framework.

## Key Results
- In vivo experiments with adenine base editors showed ProteinGuide achieved higher editing efficiency in a single round than seven rounds of directed evolution
- ProteinGuide generated sequences with properties exceeding training data bounds, demonstrating successful extrapolation where fine-tuning failed
- Multi-property Pareto optimization for PbrR metal binding successfully pushed beyond the training data Pareto frontier

## Why This Works (Mechanism)

### Mechanism 1: Unified Masking Equivalence for Cross-Model Guidance
- **Claim:** ProteinGuide enables guidance for diverse discrete models (MLMs, AO-ARMs) by establishing their mathematical equivalence to discrete diffusion models under a masking noise process.
- **Mechanism:** The authors demonstrate that the training objectives and sampling distributions of generative MLMs and AO-ARMs are equivalent to masked flow matching models. By mapping these models to a CTMC with masking rates, the guidance algorithms derived for diffusion become applicable to models that traditionally lacked such frameworks.
- **Core assumption:** The training objective and sampling dynamics can be faithfully represented as recovering a sequence from a masking corruption process where the denoising distribution is independent of the specific time given the current state.
- **Evidence anchors:** Section 1.3 proves that the generative MLM loss is equivalent to a masking discrete flow matching loss ($L_{MLM} = L_{FM}$).
- **Break condition:** If a specific pre-trained model uses a sampling heuristic that fundamentally deviates from the random permutation structure required by the CTMC equivalence, the exact guidance guarantees may break down.

### Mechanism 2: Bayes-Optimal Rate Modulation
- **Claim:** On-the-fly guidance samples from the true conditional distribution $p(x|y)$ by locally applying Bayes' Rule to the generative process.
- **Mechanism:** Instead of retraining, the method modulates the "transition rates" of the generative process. The conditional rate is derived as the unconditional rate multiplied by the likelihood ratio $\frac{p(y|\tilde{x})}{p(y|x)}$, biasing the sampling trajectory toward states with higher property likelihood while preserving the prior structure of the pre-trained model.
- **Core assumption:** The predictive model is capable of estimating likelihoods on "noised" or partially masked intermediate states, not just clean sequences.
- **Evidence anchors:** Section: Intuitive overview describes executing Bayes' Rule at each sampling step to compute a property-conditioned distribution.
- **Break condition:** If the predictive model is not trained on noisy/partial data or suffers from severe miscalibration, the likelihood ratios may drive the sampling into off-manifold regions, resulting in physically implausible sequences.

### Mechanism 3: Extrapolation via Prior Preservation
- **Claim:** Guidance is uniquely suited for extrapolative design because it preserves the support of the pre-trained model, whereas fine-tuning collapses the distribution toward the training data.
- **Mechanism:** Fine-tuning updates model weights to maximize likelihood on a specific dataset, effectively "shifting" the entire distribution toward that data. In contrast, guidance acts as a multiplicative reweighting of the original distribution, creating a "tilt" toward high-property regions rather than a "collapse."
- **Core assumption:** The pre-trained model has non-zero probability mass connecting to the desired property region.
- **Evidence anchors:** Section: Alternative approaches states that fine-tuning coerces sampling from existing pre-trained model distribution rather than enabling extrapolation.
- **Break condition:** If the target property requires sequence features that the pre-trained model considers effectively impossible (zero probability), guidance cannot generate them.

## Foundational Learning

- **Concept:** **Continuous Time Markov Chains (CTMCs) on Discrete State Spaces**
  - **Why needed here:** ProteinGuide formulates discrete generative models as CTMCs rather than continuous gradients. Understanding "holding times" and "transition rates" is necessary to interpret the derivation of conditional guidance.
  - **Quick check question:** Why does assuming only one position mutates in infinitesimal time make the normalization constant for guidance tractable?

- **Concept:** **Predictive Model Noising/Calibration**
  - **Why needed here:** The guidance mechanism requires evaluating the predictor on partially masked sequences, which are out-of-distribution for standard classifiers.
  - **Quick check question:** How does training a classifier on "noised" sequence-label pairs prevent the guidance signal from degrading early in the sampling trajectory?

- **Concept:** **Guidance Strength ($\gamma$) as Temperature**
  - **Why needed here:** The paper uses a parameter $\gamma$ to control the tradeoff between the generative prior and the property constraint.
  - **Quick check question:** If $\gamma = 0$, what distribution is sampled? If $\gamma \to \infty$, what is the risk to sample diversity?

## Architecture Onboarding

- **Component map:** Frozen Pre-trained Backbone -> Noised Predictor -> Guidance Wrapper -> Sampler
- **Critical path:** `Labeled Data` -> `Train Noised Predictor` -> `Init Sequence (All Masks)` -> `Loop: (Predict Next Token Logits + Score Property) -> Apply Bayes Adjustment -> Sample` -> `Output Sequence`
- **Design tradeoffs:**
  - Exact vs. Approximate Guidance: Exact guidance requires $O(D \times S)$ evaluations (expensive for large vocabularies). Taylor-approximate (TAG) requires gradients but is faster.
  - Re-training vs. Guidance: Use Guidance for rapid iteration and extrapolation. Use Fine-Tuning only if you need to permanently specialize the model to a narrow family (interpolation).
- **Failure signatures:**
  - Degenerate Samples: If $\gamma$ is too high, sequences may become repetitive or structurally unsound despite high predicted property.
  - Stagnant Sampling: If the predictor is flat, the likelihood ratio $\approx 1$, resulting in unguided behavior.
  - Mismatch: If the predictor is trained only on clean data, it may misguide early steps where the sequence is heavily masked.
- **First 3 experiments:**
  1. **Stability Interpolation:** Guide ProteinMPNN with a stability predictor. Evaluate success by the rate of $\Delta\Delta G \leq 0$ and structural RMSD $\leq 2\mathring{A}$.
  2. **Pareto Frontier:** Guide ESM-C for PbrR with two predictors (Pb and Zn binding). Plot the joint distribution to visually confirm the model pushes beyond the training data Pareto front.
  3. **Ablation on $\gamma$:** Run the base editor task with $\gamma \in \{1, 10, 100\}$. Observe the trade-off between the mean enrichment score and sequence diversity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can ProteinGuide be effectively combined with re-training-based frameworks like Direct Preference Optimization (DPO) or Reinforcement Learning from Human Feedback (RLHF) to handle targets significantly out of the pre-trained model's distribution?
- Basis in paper: [explicit] The authors state in the Discussion that one might consider combining ProteinGuide with other Bayesian-inspired frameworks that involve re-training a pre-trained model, particularly in cases when the targeted region is significantly out of distribution for the pre-trained generative model.
- Why unresolved: Pure guidance relies on the support of the pre-trained distribution; it remains unclear how to mitigate failure modes where the desired property is so rare that the generative prior assigns it near-zero probability.
- What evidence would resolve it: Experiments comparing ProteinGuide against a hybrid approach (ProteinGuide + Fine-tuning) on extreme extrapolation tasks where the standard guidance method currently struggles.

### Open Question 2
- Question: How can ProteinGuide be extended to guide multimodal generative models that jointly produce protein structure and sequence?
- Basis in paper: [explicit] The authors note that one interesting line of exploration might involve applying ProteinGuide in conjunction with guidance methods for continuous spaces to guide multimodal generative models of both structure and sequence.
- Why unresolved: The current work unifies discrete generative models, but multimodal generation involves continuous structure spaces which require different guidance formulations.
- What evidence would resolve it: Successful application of ProteinGuide to a model like ESM3 or MultiFlow to simultaneously constrain generated backbone structures and sequences to satisfy specified structural or functional criteria.

### Open Question 3
- Question: Can Sequential Monte Carlo (SMC) be integrated with ProteinGuide to improve sample quality, and what are the associated computational trade-offs?
- Basis in paper: [explicit] The authors suggest that it might prove promising to combine ProteinGuide with MCMC-based methods, such as recent works for guiding generative models with Sequential Monte Carlo (SMC), to improve the generation quality, albeit at the expense of added sampling computation time.
- Why unresolved: While ProteinGuide uses first-order approximations (TAG) for speed, it is unknown if the higher computational cost of SMC provides a statistically significant improvement in sample diversity or property satisfaction.
- What evidence would resolve it: A benchmark comparing the diversity and property success rates of ProteinGuide (TAG) against a ProteinGuide-SMC hybrid implementation on complex multi-property tasks.

### Open Question 4
- Question: How robust is ProteinGuide to the systematic errors of the predictive model $p(y|x)$, particularly when the predictor fails to capture higher-order epistatic interactions?
- Basis in paper: [inferred] In the PbrR experiment, the authors used a linear additive model to explicitly mimic the common scenario where initial screens do not capture higher order epistatic interactions.
- Why unresolved: If the guidance predictor cannot extrapolate or generalizes poorly due to limited training data, ProteinGuide may generate sequences that are "high scoring" according to the predictor but fail experimentally.
- What evidence would resolve it: Ablation studies measuring the degradation in experimental success rates when the guidance predictor is deliberately under-parameterized or trained on sparse datasets lacking epistatic terms.

## Limitations
- The unification of all model classes under a single statistical framework is theoretically derived but lacks comprehensive empirical validation across diverse architectures
- The computational complexity of exact guidance scales poorly with sequence length and vocabulary size, potentially limiting practical applications for large proteins or complex structural predictions
- The method relies heavily on the quality of the predictive model, and systematic errors in the predictor can lead to generation of sequences that appear valid but fail experimental validation

## Confidence

**High Confidence**: The interpolation results (stability optimization for ProteinMPNN) and the in vivo base editor experiments show clear, reproducible improvements over baseline methods.

**Medium Confidence**: The extrapolation claims are supported by the Pareto frontier experiments but rely heavily on the assumption that the pre-trained model has non-zero probability mass connecting to the target region.

**Low Confidence**: The unification of all model classes under a single statistical framework is theoretically derived but lacks comprehensive empirical validation across diverse architectures.

## Next Checks

1. **Predictor Robustness Test**: Systematically evaluate how predictor performance degrades when applied to increasingly masked sequences. Compare training predictors on clean vs. noised data to quantify the impact on guidance quality during early sampling steps.

2. **Cross-Architecture Generalization**: Apply ProteinGuide to a third, distinct generative model class (e.g., energy-based models or autoregressive transformers without masking) to validate whether the CTMC unification framework truly generalizes beyond the two model types tested.

3. **Guidance Failure Mode Analysis**: Intentionally design scenarios where the target property requires sequence features outside the pre-trained model's support. Measure whether guidance can identify these limitations or whether it generates structurally invalid sequences that appear valid to the predictor but fail structural validation.