---
ver: rpa2
title: 'Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from
  LLMs via Claim Verification'
arxiv_id: '2509.06902'
source_url: https://arxiv.org/abs/2509.06902
tags:
- claim
- verification
- numbers
- policy
- numeric
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Proof-Carrying Numbers (PCN) addresses numeric hallucination by
  treating it as a presentation-layer problem. Instead of relying on probabilistic
  retrieval or citation, PCN enforces a fail-closed contract: numeric values are emitted
  as claim-bound tokens, mechanically verified against structured claims under a declared
  policy, and rendered with explicit provenance marks.'
---

# Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification

## Quick Facts
- **arXiv ID:** 2509.06902
- **Source URL:** https://arxiv.org/abs/2509.06902
- **Reference count:** 18
- **Primary result:** PCN enforces fail-closed numeric verification by separating verification from model output, ensuring only claim-checked numbers are marked "verified"

## Executive Summary
Proof-Carrying Numbers (PCN) addresses numeric hallucination in LLM outputs by treating it as a presentation-layer problem. Instead of relying on probabilistic retrieval or citations, PCN enforces a fail-closed contract where numeric values are emitted as claim-bound tokens and mechanically verified against structured claims under a declared policy. Only values passing verification are marked "verified"; all others default to unverified, preventing spoofing. The protocol is lightweight, model-agnostic, and supports policies such as exact match, rounding, aliases, and tolerance. By making trust explicit and earned, PCN closes the gap between LLM fluency and the trustworthiness required for high-stakes numeric applications.

## Method Summary
PCN implements a four-component pipeline: (1) Retriever resolves user queries to structured claim sets from authoritative sources; (2) LLM emits output with claim-bound tokens `<claim id="CID" policy="P">VAL</claim>` or bare numbers; (3) Verifier checks each token against claims using a verification relation R(t,c;Π) under policies like exact, rounding, or tolerance; (4) Renderer displays verified tokens with provenance marks while unverified values show no mark. The system defaults to "unverified" for any value lacking valid claim reference, ensuring fail-closed behavior. Verification runs in linear time O(n) through hash-indexed claim lookups.

## Key Results
- PCN prevents spoofing by placing verification in the renderer, not the model
- Fail-closed defaulting ensures unverified numbers are never mistakenly marked as verified
- Linear-time verification makes the protocol practical with negligible overhead
- The protocol guarantees soundness, completeness under honest tokens, and efficient O(n) verification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Placing verification in the renderer, not the model, prevents spoofing of "verified" marks
- **Mechanism:** The verification relation R(t,c;Π) is computed by the renderer after LLM emits tokens. Adversarial text like ✓ symbols or "verified" strings in model output are ignored; only tokens passing R(t,c;Π)=1 receive verified marks
- **Core assumption:** Renderer is not compromised and verification logic is correctly implemented
- **Evidence anchors:** Abstract confirms separation prevents spoofing; Theorem 5.5 proves renderer robustness against adversarial injection
- **Break condition:** If renderer is bypassed or verification logic altered, spoofing becomes possible

### Mechanism 2
- **Claim:** Fail-closed defaulting ensures unverified numbers are never mistakenly marked as verified
- **Mechanism:** Acceptance function A(y,C;Π) defaults to "Unverified" unless explicit claim match found (R(t,c;Π)=1). Bare numbers or failed verifications never receive verified mark
- **Core assumption:** Default "Unverified" path is correctly implemented and never omitted
- **Evidence anchors:** Abstract guarantees fail-closed behavior; Theorem 5.3 proves any span lacking valid claim or failing verification is labeled Unverified
- **Break condition:** If default-to-unverified logic is removed or inverted, unverified numbers could appear verified

### Mechanism 3
- **Claim:** Linear-time verification makes protocol practical with negligible overhead
- **Mechanism:** Each numeric span looked up in hash-indexed claim set (O(1) per lookup); policy checks are constant-time. Total cost is O(n) where n is number of numeric spans
- **Core assumption:** Claims indexed by identifier; no unbounded loops in policy checks
- **Evidence anchors:** Abstract states efficient linear-time verification; Proposition 5.6 proves O(n) runtime if claims indexed
- **Break condition:** If claim lookups become O(m) or policy checks non-constant, overhead grows

## Foundational Learning

- **Concept:** Verification relation R(t,c;Π) and policy Π
  - **Why needed here:** Understanding how tokens are matched to claims under policies (exact, rounding, tolerance) is essential to configuring and debugging verification
  - **Quick check question:** Given claim with v*=5.7 and policy round1, will R(t,c;Π)=1 for token with value 5.69?

- **Concept:** Fail-closed systems
  - **Why needed here:** PCN's security model depends on defaulting to "unverified"; engineers must ensure no path accidentally promotes unverified tokens
  - **Quick check question:** In a fail-closed design, what should happen when claim ID is missing from claim set?

- **Concept:** Presentation-layer vs. model-layer enforcement
  - **Why needed here:** PCN deliberately separates verification from model outputs; conflating them undermines spoofing resistance
  - **Quick check question:** Why can't LLM safely emit its own "verified" badges in PCN-compliant system?

## Architecture Onboarding

- **Component map:** Retriever -> Generator (LLM) -> Verifier -> User Interface (Renderer)

- **Critical path:**
  1. Query q received
  2. Retriever fetches claims C
  3. LLM generates y with tokens
  4. Verifier checks each token against C under Π
  5. Renderer displays with appropriate marks (verified/unverified/flagged)

- **Design tradeoffs:**
  - Stricter policies (exact) yield higher trust but lower coverage; tolerant policies increase coverage but reduce precision
  - Bare numbers allowed but never verified, trading expressiveness for safety
  - Cryptographic extensions (signatures, Merkle proofs) add tamper-evidence but increase complexity

- **Failure signatures:**
  - High "Bare" rate: LLM not emitting claim-bound tokens (prompting/fine-tuning issue)
  - Many "Flagged" tokens: Policy too strict or claims mismatched
  - Spoofed marks appearing: Renderer bypassed or verification logic compromised

- **First 3 experiments:**
  1. End-to-end smoke test: Query known statistic (e.g., GDP growth), verify correct claim-bound token marked verified and mismatched one flagged
  2. Policy sensitivity: Run same query under exact vs. round1 policies; observe change in verified vs. flagged counts
  3. Spoofing resistance: Attempt to inject "✓" or "verified" strings in LLM output; confirm renderer ignores them and only R(t,c;Π)=1 confers mark

## Open Questions the Paper Calls Out

- **Open Question 1:** How can PCN protocol be extended to verify derived numeric values, such as ratios or aggregates, using deterministic functions over atomic claims?
  - **Basis in paper:** Explicit in "Limitations and Future Work" section and Conclusion
  - **Why unresolved:** Current implementation verifies only atomic values against reference v*; lacks schema and logic for values computed from multiple claims
  - **What evidence would resolve it:** Formal extension of verification relation R(t,c;Π) to handle functional expressions, along with prototype implementation

- **Open Question 2:** Can LLMs be reliably prompted or fine-tuned to emit claim-bound tokens with sufficient recall to prevent verification coverage gaps?
  - **Basis in paper:** Inferred from Section 6.3 warning about poor tagging recall and Section 6.4 noting need for empirical work on LLM cooperation
  - **Why unresolved:** Paper proves protocol sound assuming honest tokens but provides no rigorous benchmark quantifying how often models fail to emit required tags
  - **What evidence would resolve it:** Empirical benchmarks measuring token-emission recall and precision across diverse state-of-the-art models and domains

- **Open Question 3:** How does presence of explicit verification marks (verified vs. bare) influence user trust and risk calibration compared to standard citations?
  - **Basis in paper:** Explicit in Conclusion listing "studying how users interact with verification marks and provenance cues" as key future objective
  - **Why unresolved:** While PCN enforces fail-closed contract, utility hinges on human factors—users might misinterpret absence of mark or over-rely on verified badges
  - **What evidence would resolve it:** Controlled user studies measuring decision accuracy and trust calibration when participants use PCN-enabled interfaces versus standard RAG

- **Open Question 4:** How can adaptive policies (e.g., dynamic tolerances) be designed to balance strict fidelity with coverage in diverse application contexts?
  - **Basis in paper:** Explicit in Conclusion identifying "designing adaptive policies such as tolerances with guardrails" as necessary future research
  - **Why unresolved:** Paper formalizes static policies (exact, rounding) but notes strict rules reduce coverage; doesn't define mechanisms for context-aware policy adjustment
  - **What evidence would resolve it:** Algorithms for runtime policy selection and simulation results demonstrating optimized tradeoffs between coverage and fidelity

## Limitations
- **Renderer Integrity Assumption:** Entire security model hinges on renderer faithfully implementing verification logic; compromise collapses all guarantees
- **Claim Set Quality and Coverage:** PCN assumes claim set contains all needed numeric facts with correct values; missing or incorrect claims directly limit coverage
- **LLM Token Emission Reliability:** Over-reliance on claim-bound tokens without robust prompting may result in low verification rates, reducing utility

## Confidence

- **Mechanism 1 (Renderer-based anti-spoofing):** Medium confidence - theoretical foundation sound but limited corpus evidence against sophisticated attacks
- **Mechanism 2 (Fail-closed defaulting):** High confidence - follows standard secure design principles with direct theorem support
- **Mechanism 3 (Linear-time verification):** High confidence - straightforward computational claim with efficient implementation
- **Overall Security Guarantees:** Medium confidence - individual mechanisms well-founded but end-to-end security depends on multiple uncompromised components

## Next Checks

1. **Spoofing Resistance Test Suite:** Implement systematic attempts to inject verified marks through various means (HTML, Unicode, natural language) in LLM outputs and verify renderer rejects all without valid claim matches

2. **Coverage vs. Trust Calibration:** Run PCN on representative dataset of numeric queries under different policy configurations (exact, round1, tolerance) and measure tradeoff between verification coverage and precision/recall against ground truth

3. **Performance Benchmarking:** Measure end-to-end latency of PCN verification on large documents with hundreds of numeric spans, comparing against baseline LLM-only responses to quantify practical overhead