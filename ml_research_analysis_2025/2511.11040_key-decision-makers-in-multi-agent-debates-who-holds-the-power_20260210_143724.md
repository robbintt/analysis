---
ver: rpa2
title: 'Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?'
arxiv_id: '2511.11040'
source_url: https://arxiv.org/abs/2511.11040
tags:
- step
- each
- handshakes
- agents
- debate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?

## Quick Facts
- arXiv ID: 2511.11040
- Source URL: https://arxiv.org/abs/2511.11040
- Authors: Qian Zhang; Yan Zheng; Jinyi Liu; Hebin Liang; Lanjun Wang
- Reference count: 40
- Primary result: Strategic agent positioning improves MAD accuracy by up to 22% (Truth Last strategy)

## Executive Summary
This paper investigates the power dynamics in multi-agent debates (MAD), revealing that agents positioned later in sequential debates wield disproportionate influence over outcomes. Through extensive experiments across three reasoning tasks, the authors demonstrate that the "Truth Last" strategy—placing correct agents in influential positions—significantly outperforms random allocation. They also introduce the MADC algorithm, which uses path consistency as a proxy for correctness to automatically identify and position the most reliable agents without ground truth labels.

## Method Summary
The authors implement a multi-agent debate system with full connectivity and Simultaneous-Talk communication, where agents generate Chain-of-Thought reasoning and extract final viewpoints. The MADC algorithm calculates path consistency by measuring agreement among agents' viewpoints across debate rounds, then reorders agents based on these consistency scores before each new round. The system is evaluated on MATH500, BBH Logical Deduction, and BBH Geometric Shapes tasks, comparing Fixed, Random, and MADC strategies across 20 trials per configuration.

## Key Results
- "Truth Last" strategy improves MAD performance by up to 22% compared to random allocation
- Path consistency serves as an effective proxy for correctness in agent ordering
- Systematic role allocation reduces debate entropy and prevents deadlock
- Agents speaking later have greater influence on debate outcomes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Later-positioned agents exert disproportionate influence due to sequential recency bias
- **Core assumption:** LLMs weight later context more heavily in output distribution
- **Evidence:** 22% performance improvement with "Truth Last" strategy
- **Break condition:** Simultaneous-Talk topology or context window saturation

### Mechanism 2
- **Claim:** Path consistency identifies correct agents without ground truth
- **Core assumption:** Correct answers show higher stability across reasoning paths
- **Evidence:** Agreement-based consistency scoring enables effective agent reordering
- **Break condition:** Tasks with high false positive rates where confident wrong reasoning is common

### Mechanism 3
- **Claim:** Systematic ordering reduces debate entropy
- **Core assumption:** Lower entropy correlates with higher probability of accurate convergence
- **Evidence:** Figure 5 shows ordered roles have lower entropy than random
- **Break condition:** Prioritization of consistent but wrong "confident minority"

## Foundational Learning

- **Multi-Agent Debate Topologies:** Understanding communication structures (fully connected vs. sparse) is essential to replicate positional bias effects
  - Quick check: Does "Truth Last" work if agents are hidden until final summary? (Likely no)

- **Positional Bias in Transformers:** Core to understanding why later inputs matter more in LLM outputs
  - Quick check: If context window is reversed, should "First" agent now hold power? (Theoretically yes)

- **Consistency vs. Accuracy:** Critical for debugging MADC failures
  - Quick check: If agent consistently hallucinates, will MADC promote it? (Yes, unless correctness assumption fails)

## Architecture Onboarding

- **Component map:** Agent Pool -> Path Logger -> Consistency Evaluator -> Allocator -> Debate Loop
- **Critical path:** Initial answers → Consistency evaluation → Agent reordering → New debate round
- **Design tradeoffs:** Oracle (Truth Last) vs. Heuristic (MADC) reliability; low entropy vs. diversity
- **Failure signatures:** Premature convergence (wrong answer, low entropy), oscillation (fluctuating consistency), power flip (primacy bias issues)
- **First 3 experiments:**
  1. Sanity Check: Compare Fixed vs. Truth Last on BBH tasks for 22% delta
  2. Consistency Correlation: Plot Path Consistency vs. Ground Truth Correctness
  3. Reversal Test: 10-agent debate with 5 correct/5 incorrect agents, test position correlation

## Open Questions the Paper Calls Out

- **Hidden Manipulation:** Can developers bias outcomes by allocating preferred agents to key positions?
- **Consistency Echo Chambers:** Does path consistency reinforce convergence without ensuring correctness in subjective domains?
- **Robustness to Adversarial Agents:** Can strategic agents mimic high consistency to secure influential positions?

## Limitations
- Effectiveness may degrade in non-fully-connected topologies where information flow is restricted
- System vulnerable to adversarial agents who optimize for consistency scores rather than correctness
- May reinforce echo chambers in open-ended tasks where convergence doesn't equate to truth

## Confidence
- **High:** Sequential positional bias exists (verified by 22% performance delta)
- **Medium:** Path consistency correlates with correctness for agent ordering
- **Medium:** Systematic role allocation improves debate outcomes

## Next Checks
1. **Topology Dependency Test:** Test "Truth Last" under different communication topologies
2. **Cross-Architecture Replication:** Verify positional bias generalizes beyond Qwen2.5
3. **Failure Mode Analysis:** Design adversarial scenarios with consistently wrong majority agents