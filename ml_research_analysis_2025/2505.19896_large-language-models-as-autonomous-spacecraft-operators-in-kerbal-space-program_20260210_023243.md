---
ver: rpa2
title: Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program
arxiv_id: '2505.19896'
source_url: https://arxiv.org/abs/2505.19896
tags:
- llama
- fine-tuning
- files
- arxiv
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel approach to spacecraft control using
  Large Language Models (LLMs) as autonomous agents. By leveraging prompt engineering,
  few-shot prompting, and fine-tuning techniques, we developed LLM-based agents capable
  of real-time spacecraft maneuvering in the Kerbal Space Program Differential Games
  (KSPDG) challenge.
---

# Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program

## Quick Facts
- arXiv ID: 2505.19896
- Source URL: https://arxiv.org/abs/2505.19896
- Authors: Alejandro Carrasco; Victor Rodriguez-Fernandez; Richard Linares
- Reference count: 15
- Primary result: Fine-tuned LLaMA models achieved performance close to top-ranked differential equations approach in KSPDG challenge

## Executive Summary
This work introduces a novel approach to spacecraft control using Large Language Models (LLMs) as autonomous agents for real-time spacecraft maneuvering. By leveraging prompt engineering, few-shot prompting, and fine-tuning techniques on LLaMA models, the researchers developed LLM-based agents capable of interpreting mission telemetry and generating appropriate control actions within the Kerbal Space Program Differential Games (KSPDG) challenge. The approach addresses limitations of traditional control methods and reinforcement learning by using LLMs to handle complex decision-making scenarios. Results demonstrate that the fine-tuned LLaMA models significantly outperformed baseline models and achieved performance metrics approaching the top-ranked differential equations approach in the competition.

## Method Summary
The researchers developed LLM-based spacecraft control agents through a multi-stage approach. They began with prompt engineering and few-shot prompting techniques to establish baseline performance, then progressed to fine-tuning LLaMA models specifically for the spacecraft control task. The agents were trained to interpret mission telemetry data and generate appropriate control actions in real-time within the KSPDG environment. The evaluation framework compared performance against baseline models and traditional differential equations approaches, measuring success through mission completion rates and control efficiency metrics within the simulated space environment.

## Key Results
- Fine-tuned LLaMA models significantly outperformed baseline models in spacecraft control tasks
- Achieved performance metrics approaching the top-ranked differential equations approach in the competition
- Demonstrated successful real-time interpretation of mission telemetry and generation of control actions

## Why This Works (Mechanism)
The LLM-based approach succeeds by leveraging the model's ability to understand natural language descriptions of spacecraft states and translate them into appropriate control actions. The fine-tuning process enables the LLaMA models to develop specialized knowledge of spacecraft dynamics and mission constraints, allowing them to make contextually appropriate decisions. By processing telemetry data through a language model, the system can handle complex, multi-variable scenarios that would be difficult to encode in traditional rule-based systems. The approach effectively bridges the gap between high-level mission objectives and low-level control commands through the model's understanding of causal relationships and sequential decision-making patterns.

## Foundational Learning
- **Kerbal Space Program (KSP)**: A space flight simulation game that provides a complex but controllable environment for testing spacecraft control algorithms; needed for creating a realistic testing ground without real-world mission risks; quick check: can you launch and control a basic rocket in KSP?
- **Differential Games**: Mathematical frameworks for modeling conflict situations where multiple agents pursue different objectives; needed as the competitive benchmark approach; quick check: can you formulate a simple two-player pursuit-evasion game?
- **Few-shot Prompting**: A technique where LLMs are given a small number of examples to guide their responses; needed to establish baseline performance without extensive training; quick check: can you design a prompt with 3-5 examples that guides consistent LLM behavior?
- **Fine-tuning**: The process of adapting a pre-trained model to a specific task by further training on domain-specific data; needed to optimize LLaMA models for spacecraft control; quick check: can you explain the difference between prompt engineering and fine-tuning?
- **Telemetry Interpretation**: The ability to process and understand spacecraft status data streams; needed for real-time decision making; quick check: can you identify key telemetry metrics for spacecraft attitude control?

## Architecture Onboarding
**Component Map**: KSP Environment -> Telemetry Data -> LLM Agent -> Control Commands -> Spacecraft

**Critical Path**: The sequence from telemetry data reception through LLM processing to control command execution must operate within mission time constraints to maintain spacecraft stability and achieve objectives.

**Design Tradeoffs**: 
- Model complexity vs. inference speed: Larger models provide better decision quality but may not meet real-time requirements
- Training data diversity vs. task specificity: Broader training enables generalization but may reduce performance on specific mission profiles
- Prompt engineering vs. fine-tuning: Engineering is faster but less powerful; fine-tuning requires more resources but yields better results

**Failure Signatures**:
- Incorrect control commands leading to trajectory deviation
- Excessive computation time causing missed control windows
- Misinterpretation of telemetry data resulting in inappropriate responses

**First Experiments**:
1. Test LLM agent performance on basic orbital insertion maneuvers
2. Evaluate response time for emergency trajectory corrections
3. Measure accuracy of telemetry interpretation for standard mission phases

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to simulated KSP environment, not real-world spacecraft operations
- Performance comparison with differential equations approaches doesn't account for edge cases or extended mission scenarios
- Fine-tuning process raises concerns about computational resource requirements and scalability

## Confidence
- High confidence in technical implementation and performance metrics within KSPDG framework
- Medium confidence in claims about LLM superiority over traditional methods within specific challenge scenario
- Low confidence in claims regarding direct applicability to real-world spacecraft operations

## Next Checks
1. Conduct ablation studies comparing LLM performance across different spacecraft sizes and mission complexities within KSP to establish robustness boundaries
2. Implement stress testing scenarios including communication delays, sensor failures, and unexpected environmental conditions to evaluate system reliability
3. Develop a quantitative framework for measuring the computational overhead of LLM-based control compared to traditional methods across varying mission durations