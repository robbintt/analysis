---
ver: rpa2
title: Diffusion Counterfactuals for Image Regressors
arxiv_id: '2503.20595'
source_url: https://arxiv.org/abs/2503.20595
tags:
- image
- regression
- explanations
- counterfactual
- changes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces two novel methods for generating counterfactual
  explanations for image regression tasks using diffusion-based generative models.
  The first method, Adversarial Counterfactual Regression Explanations (AC-RE), adapts
  Adversarial Counterfactual Explanations (ACE) to operate directly in pixel space.
---

# Diffusion Counterfactuals for Image Regressors

## Quick Facts
- **arXiv ID:** 2503.20595
- **Source URL:** https://arxiv.org/abs/2503.20595
- **Reference count:** 0
- **Primary result:** Introduces two novel diffusion-based methods (AC-RE, Diff-AE-RE) for generating counterfactual explanations in image regression tasks, achieving realistic and interpretable counterfactuals that reveal spurious correlations.

## Executive Summary
This paper introduces two novel methods for generating counterfactual explanations for image regression tasks using diffusion-based generative models. The first method, Adversarial Counterfactual Regression Explanations (AC-RE), adapts Adversarial Counterfactual Explanations (ACE) to operate directly in pixel space. The second method, Diffusion Autoencoder Regression Explanations (Diff-AE-RE), operates in the latent space using a Diffusion Autoencoder. Both methods produce realistic, semantic, and smooth counterfactuals on CelebA-HQ and a synthetic dataset, providing interpretable insights into the decision-making process of regression models and revealing spurious correlations.

## Method Summary
The paper proposes two approaches for generating counterfactual explanations for image regression models. AC-RE adapts the ACE framework to regression by replacing the classification loss with MSE loss and adding a reference value ỹ, optimizing in pixel space with early stopping when MAE(ŷ, ỹ) ≤ 0.05. Diff-AE-RE attacks only the semantic latent space z_sem of a pre-trained Diffusion Autoencoder, combining MSE loss on the regressor output with an ℓ1 regularization term to maintain semantic coherence. Both methods leverage pre-trained diffusion models and autoencoders to generate realistic counterfactuals while providing insights into the regression model's decision boundaries and potential spurious correlations.

## Key Results
- Both AC-RE and Diff-AE-RE successfully generate realistic counterfactuals that shift predictions toward target reference values
- Counterfactuals reveal spurious correlations, notably that adding glasses increases predicted age by ~7 years
- Pixel-space counterfactuals (AC-RE) are more sparse while latent-space counterfactuals (Diff-AE-RE) are of higher quality and allow bigger semantic changes
- Feature changes in regression counterfactuals depend on the prediction region, with larger semantic alterations required for significant value shifts

## Why This Works (Mechanism)
The methods work by leveraging the generative capabilities of diffusion models to create realistic image modifications while simultaneously optimizing for changes in the regression model's output. By either working in pixel space (AC-RE) or semantic latent space (Diff-AE-RE), the approaches can generate perturbations that are both meaningful to humans and effective at shifting the regressor's prediction. The use of pre-trained diffusion models ensures that generated counterfactuals remain within the manifold of realistic images, while the adversarial optimization process ensures that changes are targeted and interpretable.

## Foundational Learning
- **Diffusion Models (DDPM)**: Generative models that learn to denoise images step-by-step. Why needed: Provides realistic image generation capabilities for counterfactuals. Quick check: Can generate diverse, high-quality images from noise.
- **Diffusion Autoencoders**: Combine autoencoders with diffusion for latent space operations. Why needed: Enables semantic manipulation in a structured latent space. Quick check: Can reconstruct images from semantic latents while maintaining quality.
- **Counterfactual Explanations**: Perturbations that change model predictions in meaningful ways. Why needed: Provides interpretability for regression models. Quick check: Changes regressor output toward target value while maintaining semantic coherence.
- **Adversarial Attacks**: Optimization-based perturbations to fool models. Why needed: Framework for generating counterfactuals. Quick check: Can effectively change model predictions through small perturbations.
- **FID (Fréchet Inception Distance)**: Metric for evaluating image generation quality. Why needed: Quantifies realism of generated counterfactuals. Quick check: Lower values indicate more realistic images.

## Architecture Onboarding

**Component Map:** DDPM/Classifier -> AC-RE/Diff-AE-RE -> Regressor -> Counterfactual Output

**Critical Path:** Input Image → Diffusion Model/Autoencoder → Latent Space/Pixel Space → Adversarial Optimization → Reconstructed Counterfactual → Regressor Prediction

**Design Tradeoffs:** Pixel-space editing (AC-RE) offers sparsity but limited semantic control vs. latent-space editing (Diff-AE-RE) offers semantic quality but requires careful regularization

**Failure Signatures:** Over-aggressive latent space changes producing artifacts, predictions stuck at original values, non-semantic pixel modifications

**3 First Experiments:**
1. Verify DDPM can reconstruct input image after full denoising process
2. Test regressor prediction stability on original vs. random noise images
3. Run single-step counterfactual generation to validate loss computation

## Open Questions the Paper Calls Out

### Open Question 1
What are the theoretical implications of the Diffusion Autoencoder for Diffeomorphic Counterfactuals, and can similar theoretical guarantees be established for Diff-AE-RE as exist for autoencoder-based approaches? The authors suggest analyzing implications for Diff-AE as future work and reference Dombrowski et al. who demonstrate strong theoretical properties for autoencoders.

### Open Question 2
Can these counterfactual generation methods be successfully adapted to state-of-the-art diffusion models such as Latent Diffusion Models (e.g., Stable Diffusion) while maintaining their effectiveness for regression tasks? The conclusion explicitly states that future work can apply these techniques to state-of-the-art diffusion models.

### Open Question 3
Does the observed spurious correlation (glasses increasing predicted age by ~7 years) exhibit systematic demographic biases, particularly regarding gender, and can counterfactual explanations quantify these biases across protected subgroups? The authors note the effect seems more pronounced for male faces but do not systematically investigate this across demographic groups.

### Open Question 4
Can a unified approach combine the sparsity advantages of pixel-space counterfactuals (AC-RE) with the semantic quality of latent-space counterfactuals (Diff-AE-RE)? The paper identifies a fundamental trade-off but does not propose methods to achieve both properties simultaneously.

## Limitations
- Reliance on pre-trained diffusion models and autoencoders introduces dependencies on external model quality and training data biases
- Spurious correlation interpretations may be dataset-specific and not generalizable to other regression tasks
- Early stopping criterion (MAE ≤ 0.05) is arbitrary and may not ensure meaningful counterfactuals for all prediction ranges
- Limited statistical validation of qualitative claims about counterfactual realism and semantic coherence

## Confidence
- **High confidence**: Methodology for adapting ACE and Diff-AE for regression tasks is clearly described and reproducible
- **Medium confidence**: Qualitative claims about counterfactual realism are supported by examples but lack rigorous statistical validation
- **Low confidence**: Generalizability of findings to other regression tasks and robustness of sparsity-quality trade-off across different domains

## Next Checks
1. Conduct quantitative comparison of counterfactual quality metrics across multiple regression tasks with statistical tests
2. Perform systematic ablation study varying λ_d and τ to quantify sparsity vs. quality trade-off
3. Apply methods to non-facial regression task to assess robustness and identify dataset-specific artifacts