---
ver: rpa2
title: 'DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning
  through Deep Learning and Large Language Models'
arxiv_id: '2512.13742'
source_url: https://arxiv.org/abs/2512.13742
tags:
- reasoning
- llms
- were
- prompt
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a hybrid framework that combines deep learning
  (DL) image classification with large language model (LLM) reasoning to provide structured
  clinical explanations for gastrointestinal diagnoses. A new lightweight model, MobileCoAtNet,
  is proposed for classifying endoscopic images into eight stomach-related conditions,
  achieving 97.53% test accuracy.
---

# DL$^3$M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models

## Quick Facts
- arXiv ID: 2512.13742
- Source URL: https://arxiv.org/abs/2512.13742
- Reference count: 29
- Primary result: Novel hybrid DL$^3$M framework combining deep learning image classification with LLM reasoning for medical explanations, achieving 97.53% test accuracy with proposed MobileCoAtNet model

## Executive Summary
This study introduces a hybrid framework that combines deep learning (DL) image classification with large language model (LLM) reasoning to provide structured clinical explanations for gastrointestinal diagnoses. A new lightweight model, MobileCoAtNet, is proposed for classifying endoscopic images into eight stomach-related conditions, achieving 97.53% test accuracy. The framework uses the classifier's outputs to guide LLMs in generating clinical reasoning, including causes, symptoms, treatment, lifestyle, and follow-up care. Two expert-verified benchmarks were built to evaluate reasoning quality, covering multiple disease categories. Thirty-two LLMs were tested, with 15 selected for further evaluation. While strong classification improved the quality of LLM-generated explanations, none of the models reached human-level reasoning stability. Even top-performing LLMs showed sensitivity to prompt variations, indicating they are not yet reliable for high-stakes medical decisions. The work demonstrates that DL-LLM integration can enhance interpretability in medical imaging, but highlights the need for continued human oversight and domain adaptation.

## Method Summary
The DL$^3$M framework consists of two main components: a deep learning image classifier (MobileCoAtNet) for diagnosing endoscopic images into eight stomach-related conditions, and a large language model that generates clinical reasoning based on the classifier's output. The classifier was trained on 2,628 annotated endoscopic images and achieved 97.53% test accuracy. The framework uses the classification results as input to guide LLMs in generating structured explanations covering causes, symptoms, treatment, lifestyle, and follow-up care. Two expert-verified benchmarks were created to evaluate the quality of LLM reasoning across multiple disease categories. Thirty-two different LLMs were initially tested, with 15 selected for detailed evaluation. The study emphasizes that while the classification component performs strongly, the LLM reasoning component shows variability and sensitivity to prompt changes, preventing reliable clinical deployment without human oversight.

## Key Results
- MobileCoAtNet achieved 97.53% test accuracy for classifying endoscopic images into eight stomach-related conditions
- Expert-verified benchmarks demonstrated that strong classification performance improved the quality of LLM-generated clinical explanations
- All tested LLMs, including top performers, showed sensitivity to prompt variations and failed to reach human-level reasoning stability for medical decision-making

## Why This Works (Mechanism)
The framework works by combining the strengths of deep learning for accurate image classification with the reasoning capabilities of large language models. The DL component provides reliable diagnostic classification, which serves as a factual foundation for the LLM to generate structured clinical explanations. This approach leverages the DL model's domain-specific expertise in image recognition while utilizing the LLM's ability to synthesize comprehensive medical reasoning across multiple dimensions (causes, symptoms, treatment, lifestyle, follow-up). The expert-verified benchmarks ensure quality control of the reasoning outputs, while testing multiple LLMs allows identification of the most capable models for medical reasoning tasks.

## Foundational Learning
- **Endoscopic Image Classification**: Why needed - Accurate diagnosis of gastrointestinal conditions from medical images; Quick check - 97.53% test accuracy on 8-class stomach condition classification
- **Large Language Model Reasoning**: Why needed - Generate comprehensive clinical explanations beyond simple classification; Quick check - Ability to produce structured outputs covering multiple medical aspects
- **Expert-Verified Benchmarks**: Why needed - Ensure quality and reliability of medical reasoning outputs; Quick check - Benchmarks covering multiple disease categories with clinical expert validation
- **Hybrid AI Architecture**: Why needed - Combine strengths of DL for perception and LLMs for reasoning; Quick check - Framework integration where DL output guides LLM reasoning
- **Prompt Sensitivity Analysis**: Why needed - Understand LLM reliability and variability in medical contexts; Quick check - Testing across 32 LLMs with 15 selected for detailed evaluation
- **Domain Adaptation**: Why needed - Ensure medical reasoning quality in specialized clinical contexts; Quick check - Framework performance on expert-verified medical benchmarks

## Architecture Onboarding

Component Map:
MobileCoAtNet (DL Image Classifier) -> LLM Reasoning Engine -> Structured Clinical Output -> Expert Validation

Critical Path:
Image Input -> MobileCoAtNet Classification -> LLM Prompt Generation -> Clinical Reasoning Output -> Quality Assessment

Design Tradeoffs:
- Model complexity vs. inference speed (MobileCoAtNet designed as lightweight)
- Classification accuracy vs. condition coverage (limited to 8 stomach conditions)
- LLM reasoning quality vs. computational cost (tested 32 models, selected 15)
- Expert validation rigor vs. scalability of evaluation process
- Clinical reliability vs. automation level (requires human oversight)

Failure Signatures:
- Classification errors propagating to incorrect LLM reasoning
- LLM sensitivity to prompt variations causing inconsistent outputs
- Limited condition coverage preventing diagnosis of rare conditions
- Over-reliance on LLM reasoning without sufficient human verification
- Prompt engineering failures leading to incomplete or inaccurate explanations

First Experiments:
1. Test MobileCoAtNet classification accuracy on expanded dataset covering more gastrointestinal conditions
2. Evaluate LLM reasoning consistency across multiple prompt variations for the same input
3. Compare framework outputs against clinical expert assessments on real patient cases

## Open Questions the Paper Calls Out
None

## Limitations
- Classification model covers only eight stomach-related conditions, limiting generalizability to broader clinical scenarios
- LLM reasoning shows variability and sensitivity to prompt variations, preventing reliable high-stakes medical decision-making
- Expert-verified benchmarks are relatively small and focused on specific disease categories, not capturing full clinical complexity
- No assessment of potential biases in training data or framework performance across diverse patient populations
- Framework requires continued human oversight and domain adaptation before clinical deployment

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| MobileCoAtNet classification accuracy | High |
| LLM reasoning quality and reliability | Medium |
| Overall framework readiness for clinical use | Medium |

## Next Checks

1. Expand the classification model to cover a broader range of gastrointestinal and other medical conditions to assess generalizability.
2. Conduct large-scale, diverse clinical trials to evaluate the framework's performance across varied patient populations and real-world scenarios.
3. Implement robust bias mitigation strategies and assess the model's fairness and equity in clinical decision-making.