---
ver: rpa2
title: 'Sim-is-More: Randomizing HW-NAS with Synthetic Devices'
arxiv_id: '2504.00663'
source_url: https://arxiv.org/abs/2504.00663
tags:
- latency
- architecture
- training
- devices
- hw-nas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a two-stage hardware-aware neural architecture
  search (HW-NAS) framework that addresses the challenge of designing efficient neural
  networks across multiple devices. The method first trains a reinforcement learning
  controller on a distribution of synthetic devices with randomized latency profiles,
  then deploys it on real target devices using only 10 real-world latency measurements
  for adaptation.
---

# Sim-is-More: Randomizing HW-NAS with Synthetic Devices

## Quick Facts
- arXiv ID: 2504.00663
- Source URL: https://arxiv.org/abs/2504.00663
- Authors: Francesco Capuano; Gabriele Tiboni; NiccolÃ² Cavagnero; Giuseppe Averta
- Reference count: 4
- Primary result: Two-stage HW-NAS framework using synthetic devices and only 10 real latency measurements for adaptation

## Executive Summary
This paper introduces a novel two-stage hardware-aware neural architecture search (HW-NAS) framework that addresses the challenge of designing efficient neural networks across multiple devices. The method employs a reinforcement learning controller trained on a distribution of synthetic devices with randomized latency profiles, which is then deployed on real target devices using minimal real-world latency measurements. By leveraging training-free accuracy proxies and domain randomization, the approach avoids expensive hypernetwork pre-training and inaccurate latency predictors. Experiments on NATS-Bench demonstrate the controller's ability to generalize across unseen devices while maintaining sample efficiency, successfully transferring learned search strategies from synthetic to real devices.

## Method Summary
The proposed framework operates in two distinct stages: First, a reinforcement learning controller is trained on a distribution of synthetic devices with randomized latency profiles, enabling it to learn generalized search strategies without relying on expensive hypernetwork pre-training. Second, the trained controller is deployed on real target devices using only 10 real-world latency measurements for adaptation, making the approach highly sample-efficient. The method leverages training-free accuracy proxies to avoid computationally expensive pretraining while maintaining search quality, and employs domain randomization to ensure the controller can generalize across diverse hardware architectures. This approach effectively circumvents the need for coarse latency approximations or specialized hardware-aware predictors, making it particularly suitable for risk-sensitive deployment scenarios.

## Key Results
- Achieves sample-efficient HW-NAS by requiring only 10 real-world latency measurements for adaptation
- Demonstrates successful transfer of learned search strategies from synthetic to real devices
- Maintains search quality without expensive hypernetwork pre-training or specialized latency predictors
- Shows controller generalization across unseen devices using domain randomization on synthetic latency profiles

## Why This Works (Mechanism)
The framework's effectiveness stems from its two-stage approach that decouples the learning of search strategies from device-specific optimization. By training the reinforcement learning controller on a diverse distribution of synthetic devices with randomized latency profiles, the method learns robust architectural search patterns that are not overfit to any specific hardware. The use of training-free accuracy proxies eliminates the computational overhead of pretraining while still providing reliable performance estimates. The domain randomization technique ensures that the controller develops search strategies that are invariant to specific hardware characteristics, enabling successful transfer to real devices. The minimal requirement of only 10 real latency measurements for adaptation makes the approach highly practical and scalable across different hardware platforms.

## Foundational Learning
- **Reinforcement Learning for NAS**: RL controllers learn to generate neural architectures by maximizing a reward signal; needed to automate architecture design, check by verifying reward optimization during training
- **Domain Randomization**: Technique for training models on synthetic variations to improve real-world generalization; needed for synthetic-to-real transfer, check by testing on unseen devices
- **Training-Free Accuracy Proxies**: Methods to estimate network accuracy without full training; needed to reduce computational cost, check by comparing proxy predictions with actual accuracy
- **Hardware-Aware Search**: Incorporating device-specific constraints into architecture optimization; needed for practical deployment, check by measuring latency on target devices
- **Synthetic Device Modeling**: Creating virtual hardware with randomized latency profiles; needed to generate diverse training environments, check by analyzing synthetic device distribution coverage
- **Sample Efficiency**: Ability to achieve good results with minimal data or measurements; needed for practical deployment, check by varying number of latency measurements

## Architecture Onboarding

**Component Map**: Synthetic Device Generator -> RL Controller -> Training-Free Proxy -> Real Device Adapter -> Final Architecture

**Critical Path**: The core innovation lies in the RL controller's ability to learn generalized search strategies on synthetic devices, then adapt to real devices using minimal latency measurements. This enables transfer learning without expensive pretraining.

**Design Tradeoffs**: The method trades computational efficiency (avoiding hypernetwork pretraining) for potential accuracy gains that learned predictors might provide. It also sacrifices detailed hardware modeling for broader generalization through domain randomization.

**Failure Signatures**: The approach may fail when synthetic device distributions poorly represent real hardware latency profiles, or when the training-free proxy provides inaccurate accuracy estimates. Limited real latency measurements (10) could also constrain adaptation quality.

**First Experiments**:
1. Test controller performance on synthetic devices not seen during training
2. Measure accuracy drop when reducing real latency measurements from 10 to 5
3. Compare architectures found by this method against those from hardware-specific predictors

## Open Questions the Paper Calls Out
None

## Limitations
- Restricted experimental scope to NATS-Bench, which may not capture real-world hardware complexity
- Claims of synthetic device generalization not rigorously validated across multiple actual hardware platforms
- Training-free proxy approach may sacrifice accuracy compared to methods using learned predictors
- Sample efficiency claims based on 10 measurements without establishing optimal measurement count for different hardware

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Domain randomization generalizes to unseen devices | High |
| Sample efficiency with 10 real measurements | Medium |
| Training-free proxy avoids expensive pretraining | Medium |
| Controller transfer from synthetic to real devices | Medium |

## Next Checks

1. **Cross-Device Validation**: Test the framework on at least three distinct real hardware platforms (e.g., mobile GPU, embedded CPU, edge accelerator) to verify transfer learning effectiveness beyond synthetic devices.

2. **Latency Measurement Scalability**: Evaluate how performance scales when increasing the number of real latency measurements from 10 to 50 and 100, establishing the relationship between measurement count and search quality.

3. **Architecture Quality Assessment**: Compare the final architectures against manually designed hardware-efficient networks on the same target devices using actual inference benchmarks, not just proxy metrics.