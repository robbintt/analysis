---
ver: rpa2
title: Sentiment Simulation using Generative AI Agents
arxiv_id: '2505.22125'
source_url: https://arxiv.org/abs/2505.22125
tags:
- sentiment
- agents
- simulation
- agent
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of traditional sentiment analysis
  being limited to surface-level linguistic patterns and retrospective data, hindering
  its ability to capture psychological and contextual drivers of human sentiment.
  To overcome this, the authors propose a framework for sentiment simulation using
  generative AI agents embedded with psychologically rich profiles derived from a
  nationally representative survey of 2,485 Filipino respondents.
---

# Sentiment Simulation using Generative AI Agents

## Quick Facts
- arXiv ID: 2505.22125
- Source URL: https://arxiv.org/abs/2505.22125
- Reference count: 40
- One-line primary result: Contextualized profile encodings achieved 92% alignment in replicating original survey responses and 81%-86% accuracy in sentiment simulation tasks, significantly outperforming categorical encoding (p < 0.0001, Cohen's d = 0.70).

## Executive Summary
This study introduces a framework for simulating human sentiment responses using generative AI agents embedded with psychologically rich profiles derived from a nationally representative survey of 2,485 Filipino respondents. The framework addresses the limitation of traditional sentiment analysis by capturing psychological and contextual drivers of sentiment rather than surface-level linguistic patterns. By encoding psychographic data into narrative descriptions (contextualized encoding) and exposing AI agents to real-world scenarios, the system achieves high alignment with original survey responses while maintaining resilience to scenario framing variations.

## Method Summary
The framework uses a three-stage process: (1) agent embodiment via categorical or contextualized encodings of psychological profiles, (2) exposure to real-world scenarios with randomized positive/negative framing, and (3) generation of sentiment ratings with explanatory rationales and self-assessment validation. The system was implemented using Llama 3.1 70B and evaluated against ground truth survey data using Quadratic Weighted Accuracy (QWA). The study compared performance between categorical encoding (discrete labels) and contextualized encoding (narrative descriptions) across 5 socio-political scenarios with 5 repeated trials per scenario.

## Key Results
- Contextualized encoding achieved 92% alignment in replicating original survey responses versus 83% for categorical encoding
- Sentiment simulation accuracy ranged from 81%-86% for contextualized encoding compared to 68.4%-96.8% for categorical encoding
- Simulation results showed high resilience to scenario framing variations (p = 0.9676, Cohen's d = 0.02)
- Performance gap between encoding strategies was statistically significant (p < 0.0001, Cohen's d = 0.70)

## Why This Works (Mechanism)

### Mechanism 1: Contextualized Profile Encoding vs. Categorical Encoding
LLMs better leverage psychological priors when presented as coherent narrative descriptions rather than abstract variables. The performance gap highlights the benefits of translating psychological variable labels into rich psychographic contexts.

### Mechanism 2: Psychographic Grounding Anchors Agent Responses
Embedding agents with stable psychological profiles makes simulated sentiment responses robust to variations in how scenarios are framed. The psychological profile serves as a strong prior that constrains the agent's internal reasoning.

### Mechanism 3: Self-Assessment Reinforces Internal Coherence
An iterative self-assessment step, where the agent evaluates the logical consistency of its own response, improves the behavioral plausibility of the output by creating an internal feedback loop.

## Foundational Learning

**Concept: Psychographic Profiling (Traits, Values, Beliefs)**
- Why needed here: This is the core data used to instantiate agents, capturing why someone might hold an opinion rather than just demographics
- Quick check: Can you explain how a "high openness to experience" trait might influence a response to a new policy scenario?

**Concept: Quadratic Weighted Accuracy (QWA)**
- Why needed here: Standard accuracy is insufficient for ordered data like Likert scales; QWA appropriately penalizes larger errors more than smaller ones
- Quick check: Why is QWA preferred over simple accuracy for a 5-point sentiment scale?

**Concept: LLM Framing Effects**
- Why needed here: Understanding that LLMs can be swayed by prompt wording is critical to appreciating why the resilience to framing is a key result
- Quick check: What does it mean for a simulation framework to be "resilient" to framing effects?

## Architecture Onboarding

**Component map:**
Survey Data (150 items) -> Encoder Module (Categorical/Contextualized) -> Agent Embodiment Engine (LLM) -> Simulation Engine (Scenario Exposure + Response Generation + Self-Assessment) -> Evaluation Module (QWA + Statistical Tests)

**Critical path:** Survey Data -> Contextualized Encoding -> Agent Embodiment -> Scenario Exposure -> Response Generation -> Evaluation. The shift from Categorical to Contextualized encoding is the primary performance lever.

**Design tradeoffs:**
- Fidelity vs. Generalizability: Deeply contextualized profiles may be more accurate but require careful construction
- Complexity vs. Coherence: Adding the self-assessment step adds inference cost but aims to improve logical consistency

**Failure signatures:**
- Low QWA scores on specific scenarios (e.g., "Political Dynasties" scenario was harder for categorical encoding)
- High sensitivity to prompt re-wording (indicates grounding failure)
- Contradictory rationales (e.g., "I value equality, so I support this discriminatory policy")

**First 3 experiments:**
1. Ablation on Encoding: Run full simulation using only categorical encoding and compare QWA scores against contextualized baseline
2. Framing Stress Test: Expose agents to novel, highly polarized scenario framings not in original set and measure grounding effect stability
3. Profile Noise Injection: Introduce random noise into psychographic profile data and measure QWA degradation

## Open Questions the Paper Calls Out

**Open Question 1:** Why did contextualized encoding fail to outperform categorical encoding in the "Justice System" scenario?
- Basis: Categorical encoding (86.7%) slightly exceeded contextualized (86.2%), contrary to trend in other scenarios
- Why unresolved: Authors hypothesize topic may be driven more by "ideological alignment" than internal psychology, but this was not empirically tested
- What evidence would resolve it: Ablation studies comparing scenarios explicitly designed to trigger ideological identity versus those triggering psychological traits

**Open Question 2:** To what extent are simulation results dependent on specific architecture or safety alignment of Llama 3.1 70B?
- Basis: All simulations conducted exclusively using Llama 3.1 70B
- Why unresolved: Unclear if high alignment scores are an artifact of this specific model's instruction-tuning or general capability
- What evidence would resolve it: Replicating framework using alternative foundation models (GPT-4, Claude) on same dataset

**Open Question 3:** Does efficacy of contextualized profile encoding generalize to non-Filipino or non-WEIRD cultural contexts?
- Basis: Study relies on "nationally representative survey of 2,485 Filipino respondents" and references need to move beyond localized samples
- Why unresolved: While sample is nationally representative of Philippines, unclear if contextualized narrative encodings translate effectively across distinct cultural frameworks
- What evidence would resolve it: Applying same framework to dataset from culturally distinct population to verify performance gap persistence

## Limitations

- Data Representation: Framework performance hinges on quality and representativeness of 2,485 Filipino survey respondents; generalizability to other cultural contexts remains untested
- Mechanism Validation: Core mechanisms are inferred from aggregate performance metrics rather than direct ablation studies isolating each component's contribution
- Statistical Power: Heterogeneous performance across scenarios (68.4% to 96.8% accuracy) isn't fully explained despite significant overall results

## Confidence

- **High Confidence**: Framework architecture is clearly specified and performance metrics (QWA scores, statistical tests) are appropriately calculated for ordered categorical data
- **Medium Confidence**: Psychological grounding mechanism's resilience to framing effects is demonstrated within tested scenario set, but exact boundaries of this resilience are not explored
- **Low Confidence**: Self-assessment loop's contribution to response quality is asserted but not independently validated through ablation studies

## Next Checks

1. **Ablation Study on Self-Assessment**: Run simulation pipeline with and without self-assessment step across all scenarios; compare QWA scores and inter-trial variance to determine if step provides measurable improvement beyond computational cost

2. **Cross-Cultural Transfer Test**: Apply framework to different cultural dataset (e.g., Southeast Asian or Western population) using same scenario prompts; measure performance degradation to establish cultural generalizability limits

3. **Extreme Framing Boundary Test**: Design novel scenarios with maximally divergent framing (identical content with strongly opposing emotional valence) not present in original survey; test whether grounding mechanism maintains claimed resilience under these stress conditions