---
ver: rpa2
title: 'GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root
  Cause Analysis?'
arxiv_id: '2508.12472'
source_url: https://arxiv.org/abs/2508.12472
tags:
- gala
- root
- cause
- reasoning
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GALA, a multi-modal framework for root cause
  analysis in microservice systems that combines statistical causal inference with
  LLM-driven iterative reasoning. The framework uses metrics-based causal structure
  learning alongside a novel trace-based scoring approach (TWIST) to generate initial
  hypotheses, then employs a multi-agent LLM system to iteratively refine root cause
  rankings through evidence-based analysis.
---

# GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?

## Quick Facts
- **arXiv ID:** 2508.12472
- **Source URL:** https://arxiv.org/abs/2508.12472
- **Reference count:** 40
- **Primary result:** GALA achieves up to 42.22% Top-1 accuracy on RCAEval benchmark

## Executive Summary
This paper introduces GALA, a multi-modal framework for root cause analysis in microservice systems that combines statistical causal inference with LLM-driven iterative reasoning. The framework uses metrics-based causal structure learning alongside a novel trace-based scoring approach (TWIST) to generate initial hypotheses, then employs a multi-agent LLM system to iteratively refine root cause rankings through evidence-based analysis. Evaluated on the RCAEval benchmark, GALA achieves up to 42.22% Top-1 accuracy, significantly outperforming state-of-the-art methods. The paper also introduces SURE-Score, a human-guided evaluation framework specifically designed for assessing RCA-related natural language generation tasks.

## Method Summary
GALA is a four-phase, non-training framework for root cause analysis in microservice systems. Phase I generates initial hypotheses through metrics-based causal inference and a trace-based scoring method (TWIST). Phase II creates pod-centric diagnostic bundles containing temporal performance plots, service dependency subgraphs, and error-centric logs. Phase III employs an iterative multi-agent LLM workflow (Re-ranking Agent, Deep Dive Agent, Remediation Agent) to analyze diagnostic bundles and refine rankings. Phase IV synthesizes the final output including ranked root causes, incident summaries, and action recommendations. The framework was evaluated on the RE2-OB dataset from the RCAEval benchmark using accuracy metrics and the proposed SURE-Score.

## Key Results
- GALA achieves 42.22% Top-1 accuracy on RE2-OB, outperforming single-modality approaches
- Dual-modality hypothesis generation (metrics + trace) provides complementary strengths
- Iterative multi-agent reasoning improves ranking accuracy for complex fault types
- SURE-Score provides human-guided evaluation framework for RCA natural language generation

## Why This Works (Mechanism)

### Mechanism 1: Dual-Modality Initial Hypothesis Generation
- **Claim:** Combining metrics-based causal structure learning with trace-based scoring produces complementary initial hypotheses that outperform single-modality approaches.
- **Mechanism:** TWIST integrates four normalized component scores—self-anomaly, trace impact, blast radius, and delay severity—into a weighted composite score, complementing traditional metrics-based causal discovery.
- **Core assumption:** The weighted sum of four trace-derived dimensions meaningfully approximates root cause likelihood.
- **Evidence anchors:** [abstract] "combines statistical causal inference with LLM-driven iterative reasoning" [Section 4.1.2] "TWIST distinguishes itself from other trace-based RCA methods by integrating multiple complementary scoring functions"
- **Break condition:** If trace data is sparse or sampling rates are too low, TWIST's composite scoring degrades.

### Mechanism 2: Iterative Multi-Agent Re-ranking Loop
- **Claim:** An iterative ReAct-style workflow where specialized LLM agents analyze evidence, re-rank candidates, and decide whether to continue improves ranking accuracy over single-pass inference.
- **Mechanism:** The Re-ranking Agent acts as controller, reviewing current rankings and predecessor/successor trace context, either terminating or requesting deeper analysis from the Deep Dive Agent.
- **Core assumption:** Chain-of-thought prompting and structured JSON outputs enable LLMs to maintain causal reasoning consistency across iterations.
- **Evidence anchors:** [Section 6.3.1] "Memory faults required the deepest reasoning (5.93 rounds)... categories with largest accuracy gains (Mem and CPU) correspond to longer reasoning loops"
- **Break condition:** If the Re-ranking Agent fails to converge within iteration bounds, or if hallucinated reasoning chains accumulate errors across iterations.

### Mechanism 3: Modality-Preserving Diagnostic Bundles
- **Claim:** Preserving heterogeneous telemetry in structured, modality-specific artifacts (rather than collapsing into unified embeddings) improves LLM reasoning quality and interpretability.
- **Mechanism:** For each candidate pod, three artifacts are synthesized: temporal performance profiling plots, service dependency subgraphs, and error-centric log abstraction.
- **Core assumption:** LLMs can effectively integrate visual, structural, and textual modalities without cross-modal information loss that unified embeddings suffer.
- **Evidence anchors:** [Section 4.2] "By converting heterogeneous, high-volume data into these structured and visual formats" [Section 8] "GALA fundamentally differs by preserving native characteristics of each telemetry modality"
- **Break condition:** If any modality is severely degraded, the diagnostic bundle loses critical signals.

## Foundational Learning

- **Concept: Causal Structure Learning from Time-Series Metrics**
  - **Why needed here:** GALA's Phase I uses metrics-based causal inference to construct initial DAGs of service dependencies.
  - **Quick check question:** Given two services A and B where A's CPU spike consistently precedes B's latency increase by 5 seconds, can you distinguish whether A causes B's slowdown versus both responding to a third cause?

- **Concept: Distributed Tracing and Trace DAGs**
  - **Why needed here:** TWIST operates on trace DAGs where nodes are spans and edges encode parent-child RPC relationships.
  - **Quick check question:** If a service appears in 80% of anomalous traces but always as a downstream caller rather than the root, would TWIST's self-anomaly score or trace impact score better capture its role?

- **Concept: Agentic Workflows (ReAct Paradigm)**
  - **Why needed here:** GALA's Phase III implements a ReAct loop where agents alternate between reasoning traces and actions.
  - **Quick check question:** If the Re-ranking Agent outputs "Analyze Next: pod-X" three consecutive times without updating the ranking, what failure mode might this indicate?

## Architecture Onboarding

- **Component map:**
  Phase I: Initial Hypothesis Generation -> Metrics-based Causal Inference (BARO/CausalRCA/Granger) -> R^M_Init
  Phase I: Initial Hypothesis Generation -> TWIST Trace Scoring -> R^C_Init
  Phase II: Diagnostic Synthesis -> Temporal Performance Profiling -> Service Dependency Subgraph Extraction -> Error-Centric Log Abstraction -> D_i
  Phase III: LLM Agentic Reasoning -> Re-ranking Agent (controller) -> Deep Dive Agent (analysis) -> Remediation Agent (synthesis)
  Phase IV: Final Output Preparation -> Ranked Root-Cause List -> Incident Summary -> Action Recommendations

- **Critical path:** Phase I (TWIST + metrics ranking) -> Phase III Re-ranking Agent initial call -> Phase II diagnostic bundle creation for top candidates -> Phase III Deep Dive Agent analysis -> Phase III re-ranking update -> loop until "Finish" -> Phase IV Remediation Agent synthesis.

- **Design tradeoffs:**
  - 5-minute metric aggregation: preserves temporal patterns while controlling token budget, but may obscure sub-minute anomalies.
  - Max 6 iterations: bounds latency/cost but may truncate reasoning for complex faults.
  - GPT-4.1-mini vs GPT-4.1: 4.1-mini achieves near-peak performance at lower cost.
  - Temperature 1.0: balances diversity and coherence, but introduces non-determinism across runs.

- **Failure signatures:**
  - TWIST returns poor rankings when trace sampling rate < threshold for capturing anomalous request paths.
  - Re-ranking Agent loops without convergence (stall) when evidence is ambiguous or contradictory across modalities.
  - Deep Dive Agent hallucinates causal links when log abstraction filters out all relevant error entries.
  - Remediation Agent produces generic recommendations when SURE-Score dimensions are not enforced.

- **First 3 experiments:**
  1. Baseline comparison: Run GALA (BARO, M2) vs. BARO-only vs. TWIST-only on RE2-OB subset. Measure AC@1, Avg@3, Avg@5.
  2. Ablation by modality: Disable each diagnostic bundle component and measure accuracy drop.
  3. Iteration depth analysis: Vary max iterations (2, 4, 6, 8) and plot AC@1 vs. iteration count for CPU hog vs. memory leak fault types.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can integrating external knowledge graphs and additional data modalities into GALA further improve diagnostic accuracy?
- **Basis in paper:** [explicit] The conclusion states, "The future work includes exploring integration with even more data modalities, knowledge graphs, and human-in-the-loop refinement."
- **Why unresolved:** The current framework relies on metrics, logs, and traces, but does not leverage structured domain knowledge graphs.
- **What evidence would resolve it:** Experimental results comparing GALA's performance against a variant augmented with domain-specific knowledge graphs.

### Open Question 2
- **Question:** How does GALA perform in large-scale, industrial production environments compared to the evaluated benchmarks?
- **Basis in paper:** [inferred] The "Threats to Validity" section notes that evaluation was limited to the RCAEval benchmark and "might be limited by the specific nature of these datasets."
- **Why unresolved:** The study relies on the RE2-OnlineBoutique application (12 services) rather than complex, industrial-scale architectures.
- **What evidence would resolve it:** Evaluation of the framework on proprietary, large-scale microservice systems with diverse architectural patterns.

### Open Question 3
- **Question:** What are the optimal trade-offs between the number of LLM reasoning iterations, accuracy, and inference latency?
- **Basis in paper:** [inferred] The methodology limited the agentic workflow to six iterations to "control inference latency and computational cost," but did not fully analyze the accuracy degradation at lower iteration counts.
- **Why unresolved:** It is unclear if a "sweet spot" exists where reasonable accuracy is maintained with significantly fewer iterations to reduce costs.
- **What evidence would resolve it:** A sensitivity analysis plotting Top-1 accuracy against wall-clock time and iteration count.

## Limitations
- Evaluation limited to single benchmark dataset (RE2-OB with 90 scenarios) without testing on real-world incidents
- TWIST weight parameters and full agent prompts not published, preventing exact replication
- Iterative reasoning introduces non-deterministic variability through temperature 1.0 sampling

## Confidence
- **High Confidence:** The dual-modality hypothesis generation framework is well-specified and supported by comparative ablation studies
- **Medium Confidence:** The iterative multi-agent re-ranking mechanism achieves measured accuracy gains, but prompt engineering details are incompletely documented
- **Medium Confidence:** The modality-preserving diagnostic bundle design is theoretically sound but lacks empirical comparison to unified embedding approaches

## Next Checks
1. **Parameter Release Validation:** Request and test the exact TWIST weight parameters (w₁-w₄) and full Deep Dive/Remediation agent prompts to reproduce the reported AC@1 scores within 5% tolerance.
2. **Cross-Benchmark Generalization:** Evaluate GALA on an independent RCA benchmark to verify that the 42.22% AC@1 performance generalizes beyond RE2-OB.
3. **Trace Sampling Robustness:** Systematically vary trace sampling rates (10%, 25%, 50%, 100%) and measure degradation in TWIST-based rankings to quantify framework sensitivity to incomplete trace data.