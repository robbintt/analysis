---
ver: rpa2
title: Direct Prediction Set Minimization via Bilevel Conformal Classifier Training
arxiv_id: '2506.06599'
source_url: https://arxiv.org/abs/2506.06599
tags:
- training
- dpsm
- prediction
- conformal
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of minimizing prediction set sizes
  in conformal prediction by developing a novel bilevel optimization framework called
  Direct Prediction Set Minimization (DPSM). The core idea is to explicitly parameterize
  the quantile of conformity scores using quantile regression in the lower-level subproblem,
  which allows for more accurate estimation compared to stochastic approximation methods.
---

# Direct Prediction Set Minimization via Bilevel Conformal Classifier Training

## Quick Facts
- arXiv ID: 2506.06599
- Source URL: https://arxiv.org/abs/2506.06599
- Authors: Yuanjie Shi; Hooman Shahrokhi; Xuesong Jia; Xiongzhi Chen; Janardhan Rao Doppa; Yan Yan
- Reference count: 40
- Key outcome: Achieves O(1/√n) learning bound, improving over existing conformal training methods with Ω(1/s) bounds while reducing prediction set sizes by 20.46%

## Executive Summary
This paper addresses the problem of minimizing prediction set sizes in conformal prediction by developing a novel bilevel optimization framework called Direct Prediction Set Minimization (DPSM). The core idea is to explicitly parameterize the quantile of conformity scores using quantile regression in the lower-level subproblem, which allows for more accurate estimation compared to stochastic approximation methods. The upper-level subproblem then minimizes the prediction set size conditioned on this learned quantile. The paper proves that DPSM achieves a learning bound of O(1/√n), significantly improving over existing conformal training methods with bounds of Ω(1/s). Experiments on benchmark datasets demonstrate that DPSM reduces prediction set sizes by 20.46% compared to the best prior baseline while maintaining valid coverage.

## Method Summary
DPSM formulates conformal prediction as a bilevel optimization problem where the lower-level subproblem learns the empirical quantile via quantile regression (pinball loss minimization), while the upper-level minimizes prediction set size conditioned on this learned quantile. The method splits training data into D₁ and D₂, using D₁ for classification and QR gradients, and D₂ for conformal alignment gradients. This prevents overfitting to the conformal alignment loss. The conformity scores (HPS/APS/RAPS) are computed from classifier outputs, and a sigmoid-smoothed indicator function approximates the set size during training. The method achieves valid coverage while reducing average prediction set size through this explicit quantile parameterization.

## Key Results
- Proves O(1/√n) learning bound, improving over existing methods with Ω(1/s) bounds
- Reduces prediction set sizes by 20.46% compared to best prior baseline
- Maintains valid marginal coverage (≥1-α) across all benchmark datasets
- Demonstrates stable convergence with smaller estimation errors in quantiles compared to ConfTr baseline

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Bilevel optimization decouples quantile estimation from batch-dependent noise, improving learning bounds from Ω(1/s) to O(1/√n).
- **Mechanism:** The lower-level subproblem learns the empirical quantile via quantile regression (pinball loss minimization), while the upper-level minimizes prediction set size conditioned on this learned quantile. This removes the dependency on stochastic batch-level quantiles that plague prior SA-based methods.
- **Core assumption:** Assumption 3.1 (Bi-Lipschitz continuity of conformity scores) and 3.2 (µ-strong concavity of conformal loss around expected batch quantile).
- **Evidence anchors:**
  - [abstract]: "learning bound of O(1/√n), significantly improving over existing conformal training methods with bounds of Ω(1/s)"
  - [Section 4.1, Theorem 4.1]: Formal proof that |LDM_c(f) − Lc(f)| ≤ Õ(1/√n)
  - [corpus]: Weak direct corpus evidence; related work on conformal training (ConfTr, CUT) provides baselines but no competing bilevel approaches.
- **Break condition:** If conformity scores violate Bi-Lipschitz continuity (e.g., severe ties or discontinuous distributions), the bound analysis may not hold.

### Mechanism 2
- **Claim:** Explicit quantile parameterization via a single learnable variable q provides more accurate quantile estimation than stochastic batch-level quantiles.
- **Mechanism:** Instead of computing empirical quantiles on each mini-batch (which introduces variance proportional to 1/s), DPSM maintains a single quantile variable updated via gradient descent on the pinball loss. This allows the quantile to track the model's evolving score distribution across the full training set.
- **Core assumption:** The QR loss satisfies H¨olderian error bound (Lemma 4.5), enabling convergence guarantees even without strong convexity.
- **Evidence anchors:**
  - [Section 4.1]: "explicitly parameterize the quantile of conformity scores using quantile regression in the lower-level subproblem"
  - [Figure 3(a)]: Estimation error between dataset-level and learned quantiles converges to ~0 for DPSM, while ConfTr maintains higher error
  - [corpus]: Test-time augmentation paper mentions efficiency improvements but via different mechanism (data augmentation, not training).
- **Break condition:** If pinball loss optimization fails to converge (e.g., learning rate mismatch between upper/lower levels), quantile estimation degrades.

### Mechanism 3
- **Claim:** Splitting training data into D₁ and D₂ with separate gradient computations prevents overfitting to the conformal alignment loss.
- **Mechanism:** Classification loss and QR gradients use D₁; conformal alignment loss gradients use D₂. This separation reduces the risk that the model overfits to minimize prediction set size at the expense of generalization.
- **Core assumption:** This follows empirical practice from prior conformal training work (CUT) rather than theoretical necessity.
- **Evidence anchors:**
  - [Section 4.2, Algorithm 1, Lines 6-8]: Explicit data splitting and separate batch sampling
  - [Section 4.2]: "helps to prevent over-fitting"
  - [corpus]: No corpus papers discuss this specific technique; appears novel to conformal training context.
- **Break condition:** With very small datasets, the split may leave insufficient samples for either objective.

## Foundational Learning

- **Concept:** Conformal Prediction (split-CP workflow)
  - **Why needed here:** DPSM integrates conformal principles into training; without understanding how calibration produces prediction sets via empirical quantiles, the bilevel formulation is opaque.
  - **Quick check question:** Can you explain why the empirical quantile on a calibration set guarantees valid coverage?

- **Concept:** Bilevel Optimization (upper/lower-level problems)
  - **Why needed here:** The entire DPSM contribution is framed as a bilevel problem; understanding that the lower-level solution constrains the upper-level objective is essential.
  - **Quick check question:** Why can't we simply jointly optimize f and q in a single-level problem?

- **Concept:** Quantile Regression and Pinball Loss
  - **Why needed here:** The lower-level problem minimizes pinball loss to learn quantiles; understanding this loss function is required to implement the algorithm.
  - **Quick check question:** What happens to pinball loss when the predicted quantile is below vs. above the true quantile?

## Architecture Onboarding

- **Component map:** Classifier fθ -> Conformity score module -> Sigmoid-smoothed indicator -> Loss aggregator -> Updated f and q
- **Critical path:** Lower-level QR loss converges first (typically within 5-10 epochs), enabling meaningful upper-level conformal loss gradients. If QR loss diverges, prediction set size minimization fails.
- **Design tradeoffs:**
  - λ (conformal weight): Higher values reduce set size but may harm accuracy; paper uses 0.01-1.0
  - γ vs η (learning rates): Lower-level requires stable convergence; paper uses γ ∈ {0.001-0.1}, typically lower than η
  - Temperature τ_sigmoid: Controls smoothing of indicator function; too low causes gradient issues, too high causes loose set size estimates
- **Failure signatures:**
  - Upper-level loss increases indefinitely: λ too high or learning rate mismatch
  - Quantile estimation error remains high: γ too low or pinball loss implementation error
  - Coverage drops below 1-α: Calibration/test split not exchangeable with training
- **First 3 experiments:**
  1. **Sanity check:** Train on CIFAR-100 with HPS score, λ=0.1, plot both losses and quantile estimation error (should match Figure 2 pattern: lower loss drops quickly, upper loss has initial peak then stabilizes).
  2. **Ablation on data splitting:** Compare D₁/D₂ split vs. using same data for all gradients on Caltech-101; expect slight overfitting without split.
  3. **Learning rate sensitivity:** Grid search γ ∈ {0.001, 0.01, 0.1} with fixed η=0.1; verify Figure 3(a) pattern where DPSM estimation error converges to near-zero after ~35 epochs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a provably convergent stochastic first-order algorithm be developed for the DPSM bilevel problem that accommodates non-smooth, non-strongly-convex lower-level objectives?
- Basis in paper: [explicit] Section 4.2 explicitly states that developing a stochastic gradient algorithm with convergence guarantees for the non-smooth, non-convex conditions of DPSM is "non-trivial and an open challenge," which the authors leave for future work.
- Why unresolved: The authors note that standard bilevel convergence proofs rely on restrictive assumptions (e.g., Lipschitz Hessians, strong convexity) that do not hold for the Quantile Regression (pinball) loss in the lower-level subproblem. While Algorithm 1 works empirically, it lacks formal convergence guarantees.
- What evidence would resolve it: A theoretical proof showing that Algorithm 1 (or a modified variant) converges to a stationary point or optimal solution under the relaxed smoothness and convexity assumptions present in the DPSM formulation.

### Open Question 2
- Question: How does the presence of ties in non-conformity scores affect the stability of the H¨olderian error bound (HEB) and the resulting optimization gap?
- Basis in paper: [inferred] Lemma 4.5 establishes the HEB condition required for the penalty-based reformulation by explicitly assuming "there is no tie in conformity scores."
- Why unresolved: While the "no tie" assumption is common in conformal prediction literature, deep classifiers can produce identical softmax scores for different classes. The paper does not analyze whether the violation of this assumption degrades the HEB property or the approximation quality of the penalized problem.
- What evidence would resolve it: A theoretical analysis or empirical sensitivity study showing the impact of score ties on the convergence rate of the lower-level quantile regression and the final prediction set size.

### Open Question 3
- Question: Does the O(1/√n) learning bound and empirical efficiency of DPSM hold when optimizing directly with complex conformity scores like Adaptive Prediction Sets (APS) during training?
- Basis in paper: [inferred] While the method is theoretically general, the experimental setup (Appendix E) specifies that the conformal alignment loss was minimized using only the Homogeneous Prediction Sets (HPS) score during training, while APS and RAPS were used only for calibration/testing.
- Why unresolved: The paper does not verify if the lower-level quantile regression converges as effectively or if the upper-level loss landscape remains tractable when using the more complex, cumulative-probability-based APS scoring function during the bilevel training process.
- What evidence would resolve it: Experimental results benchmarking DPSM performance when trained end-to-end with APS/RAPS losses compared to the HPS training baseline, specifically checking for valid coverage and set size reduction.

## Limitations

- Limited scalability validation beyond three medium-sized datasets (CIFAR-100, Caltech-101, iNaturalist Fungi)
- Insufficient hyperparameter sensitivity analysis beyond the grid search shown in Figure 3
- Data splitting strategy (D1/D2) lacks theoretical justification for preventing overfitting in conformal training contexts

## Confidence

- **High confidence:** Theoretical learning bound improvement (O(1/√n) vs Ω(1/s)) due to formal proof in Theorem 4.1
- **Medium confidence:** Practical effectiveness given strong experimental results across three datasets but limited hyperparameter exploration
- **Low confidence:** Scalability claims as no experiments test larger models or datasets

## Next Checks

1. **Scalability test**: Apply DPSM to ImageNet-1K with ResNet-50/DenseNet-121 and evaluate whether the O(1/√n) bound holds empirically as dataset size increases from CIFAR-100 scale to ImageNet scale.

2. **Hyperparameter sensitivity**: Systematically vary λ ∈ {0.001, 0.01, 0.1, 1.0, 10.0} and γ/η ratios across all datasets to identify stability regions and potential overfitting patterns with the D1/D2 split.

3. **Comparison to non-bilevel approaches**: Implement a single-level joint optimization baseline (jointly optimizing f and q without bilevel structure) to verify that the bilevel formulation specifically provides the theoretical advantages claimed, not just careful hyperparameter tuning.