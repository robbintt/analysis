---
ver: rpa2
title: 'SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series
  Forecasting'
arxiv_id: '2503.02836'
source_url: https://arxiv.org/abs/2503.02836
tags:
- ptms
- forecasting
- series
- time
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SEQFUSION, a framework for zero-shot time-series
  forecasting that leverages a diverse collection of pre-trained models (PTMs) instead
  of large-scale pre-training data. The key innovation is a model zoo of specialized
  PTMs, each trained on different datasets, which are dynamically selected and aggregated
  based on the characteristics of the target time series.
---

# SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting

## Quick Facts
- arXiv ID: 2503.02836
- Source URL: https://arxiv.org/abs/2503.02836
- Reference count: 40
- Key outcome: Achieves competitive or superior zero-shot forecasting accuracy compared to state-of-the-art methods, particularly for multivariate and univariate time series benchmarks, while requiring only 1.42×10³ MB storage.

## Executive Summary
SeqFusion introduces a framework for zero-shot time-series forecasting that leverages a diverse collection of pre-trained models (PTMs) instead of large-scale pre-training data. The key innovation is a model zoo of specialized PTMs, each trained on different datasets, which are dynamically selected and aggregated based on the characteristics of the target time series. A general extractor with transferability loss is used to obtain time-series representations and align them with PTM representations, enabling effective PTM selection through similarity measurement. Experiments demonstrate that SeqFusion achieves competitive or superior accuracy compared to state-of-the-art zero-shot forecasting methods, particularly in multivariate and univariate time series benchmarks. The approach is memory-efficient, requiring only 1.42×10³ MB storage compared to large-scale models, and uses minimal data for privacy protection, making it practical for real-world applications.

## Method Summary
SeqFusion is a zero-shot time-series forecasting framework that dynamically selects and aggregates specialized pre-trained models (PTMs) based on the characteristics of the target time series. It constructs a model zoo of lightweight PTMs trained on diverse datasets and uses a general extractor with a transferability loss to align time-series representations with PTM representations. The system selects the most suitable PTMs by measuring distances in the shared representation space and performs sequential predictions by recursively applying the selected PTMs. Finally, it aggregates predictions from multiple PTMs to improve accuracy and reliability.

## Key Results
- SeqFusion achieves competitive or superior accuracy compared to state-of-the-art zero-shot forecasting methods.
- The approach is memory-efficient, requiring only 1.42×10³ MB storage compared to large-scale models.
- Aggregating predictions from multiple top-ranked PTMs improves robustness and accuracy over single-model selection.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Matching a target time series to specialized Pre-trained Models (PTMs) via a shared representation space enables effective zero-shot forecasting.
- Mechanism: SeqFusion employs a "General Extractor" (an encoder-decoder) trained with a custom "transferability loss." This loss forces the model to learn representations where the distance between a target series and a PTM's training data correlates with the actual performance of that PTM on the target. The system selects the PTM with the highest cosine similarity to the target series representation.
- Core assumption: Time series with similar temporal characteristics (e.g., frequency, trend) map to similar representations, and a PTM effective on one dataset will be effective on semantically similar data.
- Evidence anchors:
  - [abstract] "...selecting by measuring distances in a shared representation space of the target time series with each PTM."
  - [section 4.2] "transferability loss aligns the learned representations with the transferability potential of PTMs."
  - [corpus] The paper "QuiZSF" similarly supports the mechanism of retrieving specialized models for zero-shot tasks, though SeqFusion focuses on representation alignment rather than synthetic data generation.
- Break condition: If the General Extractor fails to capture semantic alignment (e.g., mapping high-frequency noise to low-frequency trends), the selection process picks irrelevant PTMs, causing forecasting accuracy to degrade to random baseline levels.

### Mechanism 2
- Claim: Fixed-horizon pre-trained models can be adapted for arbitrary-length forecasting through recursive sequential application.
- Mechanism: The framework uses a recursive loop (Algorithm 1). A PTM predicts the next $h$ steps; this output is concatenated with the history, trimmed to the model's input length $T$, and fed back as input for the next $h$ steps. This allows a model trained for short horizons to generate long-term predictions.
- Core assumption: The PTM's output distribution remains stable enough when fed back as input, and error accumulation does not invalidate the signal within the required horizon.
- Evidence anchors:
  - [abstract] "...selects the most suitable PTMs... performs sequential predictions..."
  - [section 3.2] "The task of forecasting a horizon $H$ is decomposed into $n = \lceil H/h \rceil$ forecasting blocks."
  - [corpus] (Weak/Implicit) Standard time-series literature (referenced in the "In-Context..." corpus paper) accepts recursive strategies, but error accumulation remains a known limitation not explicitly solved but managed here by PTM quality.
- Break condition: If the forecast horizon $H$ is significantly larger than the model's native horizon $h$, compounding errors will cause the prediction distribution to drift or flatten (mean-reversion).

### Mechanism 3
- Claim: Aggregating predictions from multiple top-ranked PTMs improves robustness and accuracy over single-model selection.
- Mechanism: Instead of relying on a single "best" PTM, SeqFusion runs the top $k$ selected PTsMs in parallel, normalizes their outputs, and averages them. This acts as an ensemble method, smoothing out the specific biases of individual PTMs.
- Core assumption: The selection mechanism (Mechanism 1) is accurate enough that the top $k$ models are all relevant, and their errors are uncorrelated or cancel out.
- Evidence anchors:
  - [section 4.4] "...incorporating aggregated predictions... enhances the reliability and accuracy... by leveraging multiple sources of knowledge."
  - [figure 5] Shows MSE decreasing as the number of aggregated PTMs increases.
  - [corpus] "Shapelets-Enriched Selective Forecasting" implies that selective utilization of foundation models is a viable strategy, supporting the premise that not one single model fits all.
- Break condition: If the model zoo lacks diversity or the top $k$ models are all biased in the same direction (e.g., all trained on data with seasonality not present in the target), aggregation provides no benefit and increases computational cost.

## Foundational Learning

- Concept: **Zero-Shot Forecasting**
  - Why needed here: The entire premise relies on predicting a target domain without access to its specific training data. You must understand the difference between "transfer learning" (fine-tuning) and "zero-shot" (inference only).
  - Quick check question: Can you explain why a model trained on M3/M4 data might fail on a high-frequency financial dataset without adaptation?

- Concept: **Model Zoos & PTMs (Pre-trained Models)**
  - Why needed here: SeqFusion does not train a new model; it manages a collection of existing ones. Understanding that models encode "knowledge" of temporal patterns is crucial.
  - Quick check question: What is the trade-off between storing one large foundation model (like TimeGPT) vs. storing many lightweight specialized PTMs?

- Concept: **Representation Learning (Embeddings)**
  - Why needed here: The system relies on mapping time series to vectors to calculate "distance" (similarity). You need to grasp that similar vectors imply similar data characteristics.
  - Quick check question: If two time series have different magnitudes but identical shapes (trends), should their representations be close or far apart in a well-designed space?

## Architecture Onboarding

- Component map: Model Zoo -> General Extractor -> Matching Module -> Sequential Fusion Engine
- Critical path: The training of the **General Extractor** (Section 4.2). It must be trained with the *transferability loss* ($L_{trans}$). If this component is poorly trained, the system cannot select the right models, and the architecture fails.
- Design tradeoffs:
  - **Memory vs. Generalization**: The paper argues for storing many small models (approx 1.42GB total) vs. one giant model (approx 1TB). This is efficient but relies on the Zoo containing a model relevant to *every* possible target.
  - **Aggregation Count ($k$)**: Increasing $k$ improves accuracy (Figure 5) but linearly increases inference latency. A balance must be found based on real-time requirements.
- Failure signatures:
  - **High MSE on Traffic/Complex Data**: As noted in Section 5.1 and Figure 4b, if the Model Zoo does not contain a PTM trained on data similar to the target (e.g., Traffic), SeqFusion cannot create knowledge; it can only select the "least bad" model.
  - **Distribution Drift**: If the target time series has a sudden regime change (e.g., a market crash), the historical representation used for matching may select a PTM trained on stable data, leading to poor short-term predictions.
- First 3 experiments:
  1. **Extractor Ablation**: Train the General Extractor *without* the transferability loss and compare retrieval accuracy against the standard version to validate the alignment mechanism.
  2. **Zoo Diversity Stress Test**: Remove all PTMs trained on a specific domain (e.g., Healthcare) from the Zoo and measure the performance drop on the Illness dataset to quantify the "coverage" risk.
  3. **Recursive Stability**: Run the sequential forecasting loop for extreme horizons (e.g., $n=20$ steps) to observe the point of error accumulation collapse compared to the ground truth.

## Open Questions the Paper Calls Out
1. Can more sophisticated fusion strategies, such as adaptive weighting or task-specific optimization, improve performance over the current top-k aggregation method?
2. How can SeqFusion be effectively extended to handle real-time forecasting tasks with streaming data?
3. How can the model zoo be constructed using heterogeneous architectures (e.g., Transformers and MLTs) without introducing conflicting patterns that degrade performance?
4. To what extent does error accumulation in the sequential forecasting loop limit accuracy for very long prediction horizons?

## Limitations
- **Model Zoo Coverage:** The approach assumes the model zoo contains at least one PTM trained on data similar to the target series, but the paper does not quantify the probability of "coverage failure" for truly novel domains.
- **Transferability Loss Generalization:** The effectiveness of the custom transferability loss depends on the quality and representativeness of the "demo data" from the model zoo, which is not thoroughly validated.
- **Error Accumulation in Long Horizons:** While the recursive sequential application is a key innovation, the paper acknowledges but does not rigorously quantify the impact of error propagation over long forecasting horizons.

## Confidence
- **High Confidence:** The core mechanism of using a shared representation space for PTM selection is well-supported by experimental results (Figure 5) and aligns with established retrieval-based methods.
- **Medium Confidence:** The sequential fusion engine's ability to adapt fixed-horizon models for arbitrary-length forecasting is plausible but relies on assumptions about output stability not rigorously tested for very long horizons.
- **Low Confidence:** The claim of "privacy protection" through minimal data usage is weakly justified, with no detailed explanation of what constitutes "minimal data" or how it prevents leakage.

## Next Checks
1. **Extractor Ablation Test:** Train the General Extractor without the transferability loss and compare PTM retrieval accuracy against the standard version to validate the alignment mechanism's necessity.
2. **Zoo Diversity Stress Test:** Remove all PTMs trained on a specific domain (e.g., Healthcare) from the model zoo and measure the performance drop on the Illness dataset to quantify the "coverage" risk for novel domains.
3. **Recursive Stability Benchmark:** Run the sequential forecasting loop for extreme horizons (e.g., $n=20$ steps) and plot the error accumulation curve to identify the point of prediction collapse compared to ground truth.