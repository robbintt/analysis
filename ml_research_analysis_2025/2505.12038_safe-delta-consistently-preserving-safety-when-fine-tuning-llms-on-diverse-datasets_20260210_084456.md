---
ver: rpa2
title: 'Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse
  Datasets'
arxiv_id: '2505.12038'
source_url: https://arxiv.org/abs/2505.12038
tags:
- safety
- safe
- delta
- fine-tuning
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Safe Delta addresses the problem of safety degradation in large
  language models during fine-tuning on diverse datasets, including harmful and benign
  data. The method dynamically adjusts delta parameters by estimating safety degradation
  and utility improvement for each parameter change, then selects parameters that
  maximize utility while limiting safety loss.
---

# Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets

## Quick Facts
- arXiv ID: 2505.12038
- Source URL: https://arxiv.org/abs/2505.12038
- Authors: Ning Lu; Shengcai Liu; Jiahao Wu; Weiyu Chen; Zhirui Zhang; Yew-Soon Ong; Qi Wang; Ke Tang
- Reference count: 40
- Primary result: Safe Delta consistently preserves safety during LLM fine-tuning, reducing attack success rates to 3.33% on harmful datasets while maintaining utility gains.

## Executive Summary
Safe Delta addresses the critical problem of safety degradation in large language models during fine-tuning on diverse datasets, including harmful and benign data. The method dynamically adjusts delta parameters by estimating safety degradation and utility improvement for each parameter change, then selects parameters that maximize utility while limiting safety loss. It applies a safety compensation vector to mitigate residual safety degradation. Across four diverse datasets, Safe Delta consistently preserves safety, achieving the lowest attack success rates while maintaining utility gains from benign fine-tuning, outperforming existing defense methods that either sacrifice safety or utility.

## Method Summary
Safe Delta is a post-training defense framework that preserves LLM safety during fine-tuning by selectively adjusting parameters. It pre-computes a Hessian inverse matrix on safety data to estimate how parameter changes affect safety loss. During fine-tuning, it calculates delta parameters, estimates safety degradation for each using the cached Hessian, and greedily selects parameters that maximize the utility-safety ratio until reaching a safety threshold. A safety compensation vector then adjusts non-selected parameters to further mitigate residual safety degradation. The method is applied layer-wise to manage memory and achieves safety preservation with minimal computational overhead.

## Key Results
- Achieves lowest attack success rates (3.33% on harmful datasets) while maintaining utility gains
- Consistently preserves safety across four diverse datasets including pure harmful, pure benign, and mixed data
- Outperforms existing defense methods that either sacrifice safety or utility during fine-tuning

## Why This Works (Mechanism)

### Mechanism 1: Hessian-based Safety Sensitivity Estimation
The method estimates how parameter changes affect safety loss using the inverse Hessian matrix. By computing the Hessian on safety data with the original model, it can predict the safety impact of parameter updates using the formula δL_safe = (δw)²/(2[H⁻¹]ₘₘ). This allows Safe Delta to identify which parameter changes are likely to degrade safety before they are applied.

### Mechanism 2: Utility-Safety Ratio Selection
Safe Delta treats parameter selection as a knapsack problem, ranking parameters by their ratio of utility gain to safety loss (rₘ = 2[H⁻¹]ₘₘ). Parameters are greedily selected in descending order of this ratio until cumulative safety degradation reaches a threshold. This creates a Pareto-optimal balance between safety preservation and utility improvement without requiring per-request hyperparameter tuning.

### Mechanism 3: Safety Compensation Vector (OBS-inspired)
To address residual safety degradation from selected utility-enhancing parameters, Safe Delta applies an OBS-inspired compensation vector to non-selected parameters. This shifts the burden of maintaining safety to weights that are not critical for the current fine-tuning task, leveraging parameter redundancy to preserve safety without degrading utility.

## Foundational Learning

- **Concept: Hessian Matrix & Second-Order Optimization**
  - Why needed here: Safe Delta relies on the inverse Hessian to estimate "curvature" of the safety loss landscape
  - Quick check question: Why does the method compute the Hessian inverse on the original model and safety dataset, rather than the fine-tuned model?

- **Concept: Delta Parameters & Task Arithmetic**
  - Why needed here: The entire approach treats the difference between fine-tuned and original models as a vector to be manipulated
  - Quick check question: How does Safe Delta modify the standard definition of the final model weights W_final compared to standard fine-tuning?

- **Concept: Greedy Heuristics in Knapsack Problems**
  - Why needed here: The method frames defense as selecting parameters to maximize utility subject to safety budget
  - Quick check question: What specific metric does the algorithm use to rank parameters for selection?

## Architecture Onboarding

- **Component map:**
  Original Model + Safety Dataset → Hessian Cache (H⁻¹)
  User Dataset → Standard Fine-Tuning → Fine-Tuned Model (W_sft)
  W_sft - W_orig = ΔW → Selection Module → Binary Mask M
  Selection Module + Hessian Cache → Compensation Vector C
  W_orig + M ⊙ ΔW_sft + C → Final Model W_sd

- **Critical path:**
  1. Pre-computation (One-time): Compute and cache H⁻¹ for linear layers using block-wise computation
  2. Delta Extraction: Subtract original weights from result of standard SFT
  3. Layer-wise Processing: Apply selection and compensation layer-by-layer to manage memory

- **Design tradeoffs:**
  - Static vs. Dynamic Hessian: Uses static pre-computed Hessian for efficiency (62s overhead vs. retraining)
  - Utility Approximation: Approximates utility using weight distance (L₂ norm) rather than task-specific Hessian

- **Failure signatures:**
  - High ASR with low utility: Safety threshold s is too high or Hessian approximation failed
  - Over-refusal: Safety compensation is too aggressive, overriding benign changes
  - Memory Spike: Block-wise processing failed, attempting to invert Hessian for entire layer at once

- **First 3 experiments:**
  1. Verify caching overhead: Confirm Preparation step (210s for 7B) is cached and not repeated during Request step (62s)
  2. Ablation of Compensation: Run Safe Delta with Safety Compensation Vector disabled to quantify its contribution
  3. Sensitivity to Threshold s: Run sweep of scaling factor s on Dirty dataset to identify breaking point

## Open Questions the Paper Calls Out

- How robust is Safe Delta against adversarial fine-tuning attacks where dataset is optimized to bypass Hessian-based degradation estimation?
- Can the Safe Delta framework be effectively extended to Multimodal LLMs without compromising cross-modal alignment?
- Does the greedy selection strategy result in suboptimal safety-utility trade-off compared to global optimization methods?

## Limitations

- Safety loss landscape approximation may break down for highly non-convex regions or large parameter shifts
- Utility approximation using weight distance may not accurately capture task-specific utility gains
- Safety compensation vector effectiveness depends heavily on parameter redundancy in the model

## Confidence

- **High Confidence:** Hessian-based safety sensitivity estimation is mathematically sound and well-derived
- **Medium Confidence:** Utility-safety ratio selection heuristic appears reasonable but relies on unproven assumptions
- **Low Confidence:** Safety compensation vector's effectiveness depends on parameter redundancy, which is not empirically validated

## Next Checks

1. **Hessian Approximation Accuracy:** Compare estimated safety degradation against actual safety loss computed after applying parameter changes to quantify approximation accuracy

2. **Task-Specific Utility Validation:** Test Safe Delta on tasks requiring small precise parameter adjustments versus large weight shifts to validate weight-distance utility approximation

3. **Model Redundancy Dependence:** Apply Safe Delta to models with different levels of parameter redundancy (pruned models, LoRA adapters) to test compensation vector effectiveness