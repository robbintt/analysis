---
ver: rpa2
title: Augmenting Bias Detection in LLMs Using Topological Data Analysis
arxiv_id: '2508.07516'
source_url: https://arxiv.org/abs/2508.07516
tags:
- bias
- metric
- wasserstein
- language
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a topological data analysis approach to detect
  bias hot spots in GPT-2 self-attention heads. The authors use Wasserstein distances
  between persistence diagrams of attention matrices to measure bias toward stereotypes
  versus anti-stereotypes in StereoSet discourse examples.
---

# Augmenting Bias Detection in LLMs Using Topological Data Analysis

## Quick Facts
- arXiv ID: 2508.07516
- Source URL: https://arxiv.org/abs/2508.07516
- Reference count: 37
- One-line primary result: Topological data analysis using Wasserstein distances between persistence diagrams identifies specific GPT-2 attention heads as "hot spots" for gender, race, profession, and religion bias

## Executive Summary
This study introduces a novel approach to detecting bias in large language models by analyzing the topological structure of self-attention matrices using persistent homology. The authors apply Wasserstein distances between persistence diagrams to quantify how attention patterns differ when processing stereotypical versus anti-stereotypical discourse continuations. They demonstrate that bias is not uniformly distributed across all attention heads but concentrated in specific "hot spots" within the network. The method provides both a quantitative bias metric and a visualization tool to identify which heads contribute most to misrepresentation of particular identity groups.

## Method Summary
The authors extract attention matrices from GPT-2 self-attention heads when processing context-plus-continuation pairs from StereoSet. They construct complete weighted graphs from these matrices and apply epsilon filtration to generate persistence diagrams capturing topological features (0D connected components and 1D cycles). Wasserstein distances between diagrams for stereotypical and anti-stereotypical clusters are computed, with the bias metric defined as the normalized difference between anti-stereotype and stereotype cluster variances relative to irrelevant cluster variance. The method identifies specific heads showing significant topological divergence, indicating potential bias hot spots.

## Key Results
- Bias for gender, race, profession, and religion categories is concentrated in specific attention heads rather than distributed uniformly
- Large variance exists in bias representation across subgroups within each category (e.g., different professions show varying levels of bias)
- Heat maps reveal that bias "hot spots" tend to appear in specific layer positions, with beginning and end heads showing increased misrepresentation
- The topological Wasserstein metric successfully distinguishes between stereotype and anti-stereotype attention patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wasserstein distance between persistence diagrams of attention matrices quantifies the difference in how a model processes stereotypical vs. anti-stereotypical discourse
- Mechanism: Self-attention matrices are treated as weighted adjacency matrices of complete graphs. An epsilon-filtration is applied to each graph to obtain a persistence diagram, which tracks the birth and death of topological features (connected components and cycles) as edge weights are thresholded. The Wasserstein distance then measures the difference between the distributions of these topological features. A higher variance in the topological features of a cluster (e.g., stereotypical continuations) relative to a baseline (irrelevant continuations) indicates a more consistent learned representation for that cluster.
- Core assumption: The topological features of the attention graph are a meaningful proxy for the "structure" of the model's attention patterns, and differences in this structure correlate with bias.
- Evidence anchors: [abstract] "Wasserstein distances between persistence diagrams of attention matrices to measure bias toward stereotypes versus anti-stereotypes"; [section] Section 2.1 & 2.2 detail persistent homology of graphs and the Wasserstein distance formula; [corpus] The paper "Hallucination Detection in LLMs with Topological Divergence on Attention Graphs" uses a similar topological divergence metric on attention graphs.

### Mechanism 2
- Claim: Bias is concentrated in specific self-attention heads ("hot spots"), rather than being uniformly distributed.
- Mechanism: The Wasserstein Bias Statistic (S_{l,h,k}) is computed for each head (h) in each layer (l). By mapping these statistics, the authors identify specific heads with significantly higher bias scores for a given category. This suggests certain heads specialize in or are more heavily influenced by societal biases present in the training data.
- Core assumption: Individual self-attention heads can specialize enough that their individual contributions to overall model behavior can be isolated and measured.
- Evidence anchors: [abstract] "biases for particular categories... are concentrated in attention heads that act as hot spots."; [section] Section 4.1 presents "metric heat maps" (Figures 4-7) showing the z-scores of the bias metric for each head; [corpus] The paper "Attention Pruning: Automated Fairness Repair..." proposes pruning attention heads as a bias mitigation method.

### Mechanism 3
- Claim: The misrepresentation of identity groups varies significantly within a single bias category (e.g., between different professions).
- Mechanism: The Wasserstein Bias Metric is calculated for specific subgroups (e.g., "Sister," "Psychologist"). Comparing the metric's mean and variance across these subgroups reveals a large variance, showing some groups are represented much more negatively than others, even if the average bias for the entire category is near zero.
- Core assumption: The StereoSet dataset accurately captures a comprehensive and representative set of stereotypes for the tested categories.
- Evidence anchors: [abstract] "large variance in bias representation across subgroups within each category."; [section] Tables 1-4 in Section 4.3 show the mean and range of the metric for specific groups; [corpus] Corpus evidence on subgroup-level bias variance is weak.

## Foundational Learning

- Concept: **Persistent Homology of Graphs**
  - Why needed here: It is the core mathematical tool used to convert a raw attention matrix into a topological signature (a persistence diagram) that the paper's bias metric is based on.
  - Quick check question: Given a graph, what does a point (b, d) on its persistence diagram represent?

- Concept: **Wasserstein Distance**
  - Why needed here: It provides the specific formula for quantifying the difference between two topological signatures, which is the basis for the Wasserstein Bias Statistic.
  - Quick check question: Why is the Wasserstein distance a suitable metric for comparing probability distributions in this context?

- Concept: **Self-Attention in Transformers**
  - Why needed here: The entire method operates on the attention matrices produced by the self-attention heads of a GPT-2 model. Understanding the role of these heads is crucial to interpreting the "hot spots."
  - Quick check question: What is the relationship between the attention matrix, the query, and the key in a self-attention head?

## Architecture Onboarding

- Component map: Attention extractor -> Graph constructor -> Persistence diagram calculator -> Wasserstein distance calculator -> Bias statistic calculator -> Permutation test validator

- Critical path:
  1. Run forward passes on StereoSet to extract attention matrices from GPT-2
  2. For each matrix, compute its persistence diagram (0D and 1D features)
  3. Compute the Wasserstein distance between diagrams for the stereotype and anti-stereotype clusters
  4. Aggregate these into the final bias metric per head

- Design tradeoffs: The method uses an approximation for the pseudo-inverse distributions to ensure computational tractability, trading some precision for scalability. Also, the metric's magnitude is not directly tied to model outputs (like token probabilities), making it better suited for comparative analysis (between heads/groups) rather than absolute quantification.

- Failure signatures: A failure mode is if the calculated p-values are not significant, indicating the metric cannot reliably distinguish between stereotype and anti-stereotype clusters. Another is if the metric produces high bias scores for nonsensical subgroups.

- First 3 experiments:
  1. **Reproduce the core heat map:** Implement the pipeline to generate the metric heat map for the 'gender' category on GPT-2 and verify that it shows similar "hot spots" as described in the paper.
  2. **Ablation on a single head:** Identify a head marked as a "hot spot" for the 'profession' category. Compare its attention patterns and persistence diagrams for a stereotypical vs. anti-stereotypical example to qualitatively confirm the topological difference.
  3. **Sanity check with random data:** Generate random attention matrices and feed them into the pipeline. The calculated Wasserstein Bias Metric should be near zero, confirming the metric isn't detecting signal in noise.

## Open Questions the Paper Calls Out

- Can fine-tuning the identified "hot spot" attention heads effectively reduce bias without compromising language modeling capabilities? The authors propose that future work should use the metric to determine which layers to fine-tune to reduce bias without decreasing performance, but do not implement or validate the targeted debiasing intervention.

- Why do self-attention heads at the beginning and end of a layer exhibit increased misrepresentation compared to middle heads? The authors observe this specific architectural pattern in their heat maps and explicitly call for investigation into the reasons for it, providing no theoretical or functional explanation.

- How does the proposed topological Wasserstein bias metric correlate with behavioral bias measures in actual model outputs? The limitations section notes the metric is not directly connected to actual model outputs like word probabilities, suggesting a gap between topological structure and behavior that remains unexplored.

## Limitations

- The Wasserstein distance metric is computationally intensive and requires careful parameter tuning for the pseudo-inverse approximation (particularly the smoothing parameter N).
- The method assumes that topological features of attention graphs meaningfully capture bias-relevant patterns, but this relationship has not been empirically validated beyond correlation.
- The approach depends on the quality and coverage of the StereoSet dataset, which may not capture all relevant stereotypes or may introduce linguistic artifacts that confound the metric.

## Confidence

- **High confidence**: The identification of specific attention heads as "hot spots" for bias is well-supported by the heat map visualizations and consistent with the known phenomenon of attention head specialization in transformers.
- **Medium confidence**: The claim about large variance in bias representation across subgroups is supported by the reported statistics but requires further validation on independent datasets.
- **Low confidence**: The fundamental assumption that topological divergence between persistence diagrams is a meaningful proxy for bias requires additional theoretical grounding and empirical validation.

## Next Checks

1. **Cross-dataset validation**: Apply the topological bias detection pipeline to an independent bias benchmark (such as CrowS-Pairs or Winogender) to verify that the identified "hot spots" generalize beyond StereoSet.

2. **Ablation study on head pruning**: Systematically disable or prune the identified "hot spot" heads and measure the resulting change in bias scores on standard fairness benchmarks to establish causal links between head activity and bias output.

3. **Robustness to attention perturbations**: Introduce controlled noise or perturbations to attention matrices and measure the stability of the Wasserstein bias metric to assess whether the topological features are capturing robust patterns or overfitting to specific attention configurations.