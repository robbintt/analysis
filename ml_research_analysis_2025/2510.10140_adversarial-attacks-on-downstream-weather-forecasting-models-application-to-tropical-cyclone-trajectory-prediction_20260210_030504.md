---
ver: rpa2
title: 'Adversarial Attacks on Downstream Weather Forecasting Models: Application
  to Tropical Cyclone Trajectory Prediction'
arxiv_id: '2510.10140'
source_url: https://arxiv.org/abs/2510.10140
tags:
- adversarial
- trajectory
- forecasts
- upstream
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of deep learning-based weather
  forecasting (DLWF) models to adversarial attacks, specifically focusing on manipulating
  tropical cyclone (TC) trajectory predictions. The key challenge is that standard
  gradient-based attack methods are infeasible due to the black-box nature of TC detection
  systems and the severe class imbalance problem caused by the rarity of TC events.
---

# Adversarial Attacks on Downstream Weather Forecasting Models: Application to Tropical Cyclone Trajectory Prediction

## Quick Facts
- arXiv ID: 2510.10140
- Source URL: https://arxiv.org/abs/2510.10140
- Reference count: 40
- Primary result: Proposed Cyc-Attack achieves DR=0.5570, FAR=0.0536, δC=0.0003 on 285 tropical cyclones

## Executive Summary
This paper addresses the vulnerability of deep learning-based weather forecasting (DLWF) models to adversarial attacks, specifically focusing on manipulating tropical cyclone (TC) trajectory predictions. The key challenge is that standard gradient-based attack methods are infeasible due to the black-box nature of TC detection systems and the severe class imbalance problem caused by the rarity of TC events. The authors propose Cyc-Attack, which introduces a differentiable surrogate model to approximate the TC detection system's output, enabling gradient-based attacks. Experimental results show that Cyc-Attack achieves higher targeted TC trajectory detection rates and lower false alarm rates compared to baseline methods on a dataset of 285 tropical cyclones.

## Method Summary
The method involves training a DeepLabV3+ surrogate model to approximate the black-box TempestExtremes TC detector using Gaussian kernel dilation and focal loss to handle extreme class imbalance. Adversarial trajectories are then generated using projected gradient descent (PGD) with distance-based gradient weighting and regularization to ensure realistic perturbations. The attack is validated by running adversarial forecasts through the actual TempestExtremes detector to measure trajectory detection rates and false alarm rates.

## Key Results
- Cyc-Attack achieves targeted TC trajectory detection rate of 0.5570
- False alarm rate of 0.0536 with perturbation magnitude δC=0.0003
- Outperforms baseline methods in both detection rate and stealthiness
- Successfully demonstrates feasibility of generating adversarial weather forecasts that reliably alter downstream TC trajectory predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A differentiable surrogate model can enable gradient-based attacks against black-box TC detection systems.
- Mechanism: Pre-train a probabilistic segmentation model (DeepLabV3+) to approximate TempestExtremes output, converting opaque rule-based detection into a differentiable function. This allows standard PGD-style gradient attacks to propagate through the surrogate and compute perturbations on upstream forecasts.
- Core assumption: The surrogate's decision boundary sufficiently approximates the black-box detector that adversarial examples transfer.
- Evidence anchors: [abstract] "we pre-train a differentiable surrogate model to approximate the TC detector's output, enabling the construction of gradient-based attacks"

### Mechanism 2
- Claim: Kernel dilation combined with skewness-aware focal loss mitigates extreme class imbalance (<0.01% TC locations).
- Mechanism: Dilate sparse TC labels into soft Gaussian neighborhoods, then apply focal loss that down-weights easy negatives and focuses on uncertain boundaries. Dilation provides spatial context that prevents focal loss from highlighting scattered noise.
- Core assumption: TC influence regions extend beyond exact eye coordinates, and soft labels better capture detection uncertainty.
- Evidence anchors: [Page 5, Section 4.1] "The focal loss alone (without kernel dilation) is insufficient because it can produced false positives scattered all over the map"

### Mechanism 3
- Claim: Distance-based gradient weighting and regularization produce stealthier perturbations concentrated near target trajectories.
- Mechanism: Weight gradients so target locations get full updates while distant locations decay exponentially. Add regularization term that penalizes perturbations away from targets. This suppresses spurious trajectories and zigzag artifacts.
- Core assumption: Realistic TC trajectory perturbations should be spatially localized rather than globally distributed.
- Evidence anchors: [Page 6, Equation 5-6] Full mathematical formulation of weighted PGD update and regularized loss

## Foundational Learning

- **Concept: Projected Gradient Descent (PGD)**
  - Why needed here: Core attack algorithm; Cyc-Attack extends PGD with distance weighting. Without understanding iterative perturbation clipping, the modifications won't make sense.
  - Quick check question: Why does PGD clip perturbations to an ℓ∞ ball after each step?

- **Concept: Focal Loss**
  - Why needed here: Directly modified in Equation 2; understanding α and γ parameters helps interpret skewness-aware variant.
  - Quick check question: How does focal loss differ from cross-entropy when handling imbalanced classes?

- **Concept: Transfer Attacks / Surrogate Models**
  - Why needed here: Entire approach depends on adversarial examples transferring from surrogate to black-box TempestExtremes.
  - Quick check question: What conditions cause surrogate-trained attacks to fail on target models?

## Architecture Onboarding

- Component map: GraphCast forecast (Ŷ) → Surrogate model (g̃) → Predicted TC probabilities (P̂) → Cyc-Attack optimization ← Target trajectory (Z*) → Adversarial forecast (Ŷ') → TempestExtremes (black-box) → Adversarial trajectory

- Critical path:
  1. Train surrogate on ERA5 + TempestExtremes outputs with dilation R∈{2,3}
  2. Construct adversarial target trajectory (Section B.3 algorithm)
  3. Run weighted PGD for 1000 iterations with δ=10.0, η=0.01
  4. Validate transfer by running adversarial forecast through actual TempestExtremes

- Design tradeoffs:
  - Dilation radius R: Higher → better TPR but more zigzag artifacts
  - Clipping threshold δ: Higher → better attack success but easier detection
  - Surrogate architecture: DeepLabV3+ chosen for segmentation; other architectures untested

- Failure signatures:
  - High FAR with low DR → surrogate not transferring, try larger dilation
  - Zigzag trajectories → R too large, reduce to 1-2
  - Attack detected easily → δ too high, reduce perturbation budget
  - Premature termination → calibration mask M not identifying surrogate mispredictions

- First 3 experiments:
  1. Replicate surrogate training on TC1 dataset with R=2, validate TPR/FPR match Table 1
  2. Run Cyc-Attack on 5 TC samples from TC2, compare trajectory visualization to Figure 4
  3. Ablate distance weighting (set w_grad=1 everywhere) and measure FAR increase

## Open Questions the Paper Calls Out

- **Open Question 1:** What specific defense strategies can effectively robustify DLWF models against adversarial attacks like Cyc-Attack without degrading forecast accuracy?
- **Open Question 2:** Can targeted attack strategies be developed to ensure adversarial upstream inputs fully replicate the adversarial target trajectory in an end-to-end setting?
- **Open Question 3:** Do the generated adversarial perturbations maintain physical consistency with dynamical weather laws (e.g., mass conservation, hydrostatic balance) beyond statistical stealthiness?

## Limitations

- The attack's success fundamentally depends on adversarial examples transferring from the surrogate to the black-box detector, with no theoretical guarantees of transfer success.
- Physical plausibility of adversarial forecasts remains unvalidated, with no assessment of whether perturbations violate physical constraints or produce spurious weather phenomena.
- The method assumes TempestExtremes is a pure black box, potentially suboptimal if attackers can access even limited information about detector internals.

## Confidence

- **High Confidence:** Core experimental results showing Cyc-Attack achieves DR=0.5570, FAR=0.0536, δC=0.0003 on the TC2 dataset.
- **Medium Confidence:** Claims about transfer attack effectiveness and stealthiness, which rely on empirical correlation rather than theoretical guarantees.
- **Low Confidence:** Claims about physical plausibility and broader security implications, as the paper does not validate physical consistency or generalization beyond TempestExtremes.

## Next Checks

1. **Transfer Robustness Test:** Generate adversarial examples using a different surrogate architecture (e.g., U-Net instead of DeepLabV3+) and measure transfer success rates to TempestExtremes.

2. **Physical Consistency Validation:** Run adversarial forecasts through a physical consistency checker (e.g., energy conservation, hydrostatic balance) to quantify violations.

3. **Generalization to Other Detectors:** Apply Cyc-Attack to a different TC detection system (e.g., a machine learning-based detector) and compare success rates.