---
ver: rpa2
title: Policy-Aware Generative AI for Safe, Auditable Data Access Governance
arxiv_id: '2510.23474'
source_url: https://arxiv.org/abs/2510.23474
tags:
- data
- governance
- policy
- compliance
- deny
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: A policy-aware AI controller was built to automate safe, auditable
  enterprise data access decisions. It uses a large language model to interpret natural
  language requests against written policies and metadata, following a six-stage reasoning
  framework with early hard policy gates and deny-by-default logic.
---

# Policy-Aware Generative AI for Safe, Auditable Data Access Governance

## Quick Facts
- arXiv ID: 2510.23474
- Source URL: https://arxiv.org/abs/2510.23474
- Reference count: 30
- Built policy-aware AI controller to automate safe, auditable enterprise data access decisions using LLM reasoning over policies and metadata

## Executive Summary
This work presents a policy-aware generative AI controller that automates enterprise data access governance by interpreting natural language requests against written policies and metadata. The system uses a six-stage reasoning framework with early hard policy gates and deny-by-default logic to produce APPROVE, DENY, or CONDITIONAL decisions with machine-readable rationales and enforceable controls. Evaluated on fourteen canonical cases across seven scenario families, it achieved Exact Decision Match of 92.9%, perfect DENY recall, and zero false approvals on must-deny families, demonstrating that policy-constrained LLM reasoning can deliver safe, compliant, and traceable access governance at scale.

## Method Summary
The controller uses Google Gemini 2.0 Flash with temperature ≤0.3 and deterministic decoding to interpret access requests through a six-stage reasoning pipeline: context interpretation, user validation, data classification, business purpose test, compliance mapping, and risk synthesis. Ten hard policy gates are applied pre-aggregation to short-circuit must-deny cases immediately. The system confines LLM inputs to policies and metadata rather than raw data, returning decisions with cited rationales and explicit controls. Evaluation used 14 synthetic test cases across 7 scenario families, with metrics including Exact Decision Match, DENY recall, False Approval Rate, Functional Appropriateness, and Compliance Adherence.

## Key Results
- Achieved Exact Decision Match of 92.9% across 14 test cases
- Perfect DENY recall (1.00) with zero false approvals on must-deny families
- Median decision latency under one minute with expert rationale quality ratings of 4.6-4.9/5
- Perfect scores on Functional Appropriateness (14/14) and Compliance Adherence (14/14)

## Why This Works (Mechanism)

### Mechanism 1
Hard policy gates applied pre-aggregation causally reduce false approvals on must-deny cases. Deterministic gates intercept requests before LLM decision aggregation; if any gate predicate matches (e.g., missing identity, no stated purpose, SoD violation), the system returns DENY immediately, bypassing LLM uncertainty. Core assumption: Gate predicates correctly encode non-negotiable policy constraints and are complete for the domain. Evidence: After applying non-negotiable policy gates, three must-deny errors convert to correct DENY, improving system-level EDM to 13/14 = 92.9% and reducing FAR M from 3/5 to 0/5. Break condition: If gates are underspecified or policies drift without gate updates, false approvals will re-emerge.

### Mechanism 2
Confining LLM inputs to policies and metadata (not raw data) preserves privacy while enabling interpretable reasoning. The controller receives request ⟨u, d, p⟩ plus policy text P and metadata M; the LLM performs classification and compliance mapping without accessing sensitive records, producing rationales grounded in cited policy. Core assumption: Policy text and metadata encode sufficient signal for accurate decisions; raw data inspection is unnecessary for governance logic. Evidence: Prompts include only policy text and metadata, never raw data. Break condition: If edge cases require data-inspection (e.g., content-based redaction), this confinement may under-deny or over-deny.

### Mechanism 3
Deny-by-default with escalation produces safe decisions under ambiguity. When context is missing, gates fail, or aggregation yields uncertainty, the system returns DENY with escalation notes rather than guessing; if enforceable mitigations exist, it returns CONDITIONAL with explicit controls. Core assumption: False denials are operationally preferable to false approvals in governance contexts. Evidence: Use deny by default when context is missing or ambiguous; if calls fail or latency budgets are exceeded, the controller returns DENY with an escalation note. Break condition: In high-throughput environments with frequent ambiguity, excessive denials may create operational bottlenecks and user friction.

## Foundational Learning

- **Concept: Deny-by-default access control**
  - Why needed here: The system's safety guarantees depend on defaulting to DENY when signals are incomplete; understanding this paradigm is essential for interpreting gate logic and escalation paths.
  - Quick check question: If a request lacks a declared purpose, should the system return APPROVE, DENY, or CONDITIONAL—and why?

- **Concept: LLM temperature and deterministic decoding**
  - Why needed here: The paper uses low temperature (≤0.3) and deterministic decoding to ensure reproducible decisions; misconfiguring this can introduce variance in governance outcomes.
  - Quick check question: What happens to decision consistency if temperature is raised to 0.8?

- **Concept: Compliance mapping (GDPR, HIPAA, SOX)**
  - Why needed here: Stage 5 of the reasoning framework maps requests to regulatory controls; without baseline knowledge of these frameworks, you cannot validate the LLM's compliance conclusions.
  - Quick check question: Which regulation would likely require a Data Processing Agreement before third-party access to EU customer data?

## Architecture Onboarding

- **Component map:**
  UI Layer (Streamlit) -> Application Layer -> AI Processing Layer (GovernanceAI class with Gemini 2.0 Flash) -> Domain Modules (Data catalog, sensitivity labeling, role/clearance/SoD rules) -> Audit System

- **Critical path:**
  1. Request submission → Context interpretation (Stage 1)
  2. User validation → Data classification → Business purpose test → Compliance mapping (Stages 2-5)
  3. Hard policy gates evaluated pre-aggregation
  4. Risk synthesis → Decision (A/D/C) with rationale and controls
  5. Audit record written with timestamps, citations, latency

- **Design tradeoffs:**
  - Gates vs. flexibility: Hard gates eliminate false approvals but may block legitimate edge cases requiring human override
  - Latency vs. thoroughness: Six-stage flow adds processing time; median <1 min but p95 tail exists with retries
  - Single-model dependency: Using only Gemini 2.0 Flash simplifies integration but creates vendor lock-in

- **Failure signatures:**
  - Elevated FAR on must-deny families → gates not firing; check gate predicate coverage
  - High variance across runs → temperature misconfigured or seeds not fixed
  - Missing rationale citations → policy text not injected into prompt correctly
  - Latency spikes → API timeouts; circuit-breaker should return D with escalation

- **First 3 experiments:**
  1. Ablation test: Disable each gate individually and measure FAR impact to validate gate necessity
  2. Stress test: Submit batched requests with network jitter; verify deny-by-default triggers correctly under timeout
  3. Cross-org test: Apply controller to synthetic organizations with different policy sets; check if EDM holds or if new gap patterns emerge

## Open Questions the Paper Calls Out

- Does the system maintain high decision quality when scaled to larger, parameterized case suites? (The authors explicitly list "scaling to 40–60 parameterized cases" as a next step)
- How do model drift and fairness affect the controller's long-term reliability? (The paper identifies "studies of drift, fairness, and cost under different retry budgets" as necessary future work)
- Can the controller handle real-world edge cases absent from synthetic benchmarks? (The authors acknowledge that "scenarios are synthetic and may miss real-world edge cases")

## Limitations

- Evaluation relies on synthetic, hand-crafted test cases rather than real-world request logs, potentially missing real-world complexity and edge cases
- Operational metrics such as system throughput under concurrent load, cost per decision at scale, and user acceptance testing are not reported
- Expert rubric details for Functional Appropriateness and Compliance Adherence are omitted, preventing independent validation of qualitative scores

## Confidence

- **High Confidence**: Exact Decision Match of 92.9%, DENY recall of 1.00, and zero false approvals on must-deny families are supported by direct quantitative results from the 14-case evaluation
- **Medium Confidence**: Rationale quality ratings (4.6-4.9/5) and compliance adherence scores (14/14) are reported but lack disclosed rubric and methodology
- **Low Confidence**: Claims about operational safety and scalability in real-world deployments are largely extrapolated from controlled test cases without field evidence

## Next Checks

1. **Ablation Study of Policy Gates**: Systematically disable each of the ten hard policy gates in isolation and measure the resulting change in False Approval Rate (FAR) on must-deny families to empirically validate the necessity and sufficiency of each gate.

2. **Cross-Organizational Generalization Test**: Apply the controller to synthetic organizations with diverse policy sets, role hierarchies, and data sensitivity schemas not seen during development, and evaluate whether EDM remains above 90% across all scenario families.

3. **Real-World Request Log Evaluation**: Acquire and annotate a set of real enterprise data access requests (with sensitive details scrubbed), run them through the controller, and compare decisions and rationales against human auditor judgments to assess real-world performance and identify failure patterns not present in synthetic data.