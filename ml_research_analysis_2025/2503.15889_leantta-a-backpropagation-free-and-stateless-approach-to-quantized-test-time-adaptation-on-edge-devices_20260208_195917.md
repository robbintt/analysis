---
ver: rpa2
title: 'LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time
  Adaptation on Edge Devices'
arxiv_id: '2503.15889'
source_url: https://arxiv.org/abs/2503.15889
tags:
- batch
- adaptation
- data
- leantta
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying machine learning
  models on edge devices, where limited resources, dynamic environments, and distribution
  shifts between training and real-world data create difficulties. Current test-time
  adaptation (TTA) methods are often memory-intensive and not designed for quantization
  or low-resource devices.
---

# LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices

## Quick Facts
- arXiv ID: 2503.15889
- Source URL: https://arxiv.org/abs/2503.15889
- Reference count: 26
- Primary result: 15.7% error reduction, 11.2MB peak memory, sub-200ms latency on edge devices

## Executive Summary
LeanTTA addresses the challenge of deploying machine learning models on edge devices under distribution shifts, where current test-time adaptation (TTA) methods are often memory-intensive and not designed for quantization. The authors propose a backpropagation-free and stateless framework that dynamically updates normalization statistics without relying on large batches or historical data. By combining partial adaptation with quantized module fusion, LeanTTA achieves significant improvements over state-of-the-art TTA methods while maintaining computational efficiency suitable for resource-constrained edge deployments.

## Method Summary
LeanTTA operates by modifying BatchNorm statistics on a per-sample basis using a four-step process: stabilization of target statistics with source statistics via τ=0.9, divergence measurement using Mahalanobis distance, balancing of source and stabilized statistics via λ=0.9, and immediate reset to source statistics after inference. The method restricts adaptation to shallow layers while fusing and quantizing deep layers, enabling aggressive computational gains without significant accuracy loss. This stateless approach eliminates model collapse and catastrophic forgetting under abruptly changing domains, making it particularly suitable for edge deployment scenarios.

## Key Results
- 15.7% error reduction compared to state-of-the-art TTA methods
- Peak memory usage of only 11.2MB for ResNet18 on edge devices
- Adaptation speed within an order-of-magnitude of normal inference speeds
- Maintains gains where baseline TTA methods collapse to random guessing at batch size 1

## Why This Works (Mechanism)

### Mechanism 1
Per-sample divergence estimation enables controlled adaptation without accumulating state. LeanTTA stabilizes raw single-sample target statistics by blending with source statistics using τ=0.9, then quantifies distribution shift using Mahalanobis distance. The distance modulates the final blend between source and stabilized statistics via λ, so high divergence conservatively leans toward source while low divergence incorporates more target signal. After normalization, all statistics reset per-sample, eliminating cross-sample dependency.

### Mechanism 2
Restricting adaptation to shallow layers retains most accuracy gains while enabling aggressive fusion and quantization of deep layers. Layerwise ablation shows adapting only the first half of the network yields accuracy comparable to full adaptation, while removing shallow adaptation hurts more than removing deep adaptation. This motivates partial fusion: fuse deeper BN+Conv layers and keep shallow layers unfused for LeanTTA updates.

### Mechanism 3
Stateless, forward-only adaptation avoids model collapse and catastrophic forgetting under abruptly changing domains. By resetting all normalization statistics after each sample, the model does not accumulate biased statistics from correlated or shifting batches. Backpropagation-free updates avoid gradient-based collapse observed in entropy-minimization TTA under non-i.i.d. data.

## Foundational Learning

### Concept: Batch Normalization statistics as domain signatures
- Why needed here: LeanTTA operates entirely by adjusting BN statistics; understanding how μ, σ² capture domain properties is prerequisite to reasoning about divergence and blending.
- Quick check question: Given a feature map of shape (N, C, H, W), can you compute per-channel mean and variance and explain how they would change under a brightness shift?

### Concept: Mahalanobis distance and covariance-normalized divergence
- Why needed here: The paper uses d ← 1 − e^(−(μ_b−μ_s)^T Σ_s^−1 (μ_b−μ_s)) to measure shift; understanding why covariance normalization matters vs. Euclidean distance is essential.
- Quick check question: Why would Euclidean distance between mean vectors fail to account for feature scale differences, and how does Σ_s^−1 address this?

### Concept: Quantization-aware fusion (BN folding into Conv)
- Why needed here: Partial fusion is central to LeanTTA's efficiency; knowing how BN parameters fold into conv weights clarifies why fused layers cannot be adapted online without dequantization.
- Quick check question: If a Conv–BN sequence is fused, what happens to the BN statistics at inference, and why does this prevent per-sample adaptation?

## Architecture Onboarding

### Component map
Input x_l → LeanTTA Layer (per-sample μ_t, σ²_t → stabilize with τ → compute Mahalanobis d → blend via d·λ → normalize → reset) → fused quantized layers (standard inference) → output

### Critical path
1. Input x_l enters LeanTTA-enabled BN layer
2. Compute μ_t, σ²_t from current sample
3. Stabilize: μ_b ← τμ_s + (1−τ)μ_t, similarly for σ²_b
4. Compute d using Σ_s^−1 (precomputed at calibration)
5. Blend: μ_new ← dλμ_s + (1−dλ)μ_b
6. Normalize x_l using μ_new, σ_new, reset statistics for next sample
7. For fused layers, standard quantized inference proceeds without adaptation

### Design tradeoffs
- τ=0.9 (conservative) prioritizes stability across shifts; tuning per-domain may yield higher accuracy but requires foresight
- Partial fusion trades maximal accuracy for memory/latency; full adaptation is possible but slower
- Stateless design favors abrupt shifts and low-latency edge deployment; may underperform vs. buffered methods under gradual, stable drift

### Failure signatures
- Accuracy drops below source-only baseline → likely τ or λ misconfigured
- Memory OOM on edge device → check that deep layers are fused and not accumulating BN state
- No accuracy gain on gradually shifting data → statelessness may be limiting

### First 3 experiments
1. Validate on CIFAR10-C single-image batches: compare LeanTTA vs. no-adaptation and Tent (batch 1) on abrupt shuffle; expect baseline collapse and LeanTTA gains.
2. Profile memory and latency on target edge hardware: measure per-sample time with full vs. half fusion; confirm ResNet18 INT8 near 11.2MB peak and sub-200ms latency.
3. Ablate τ and λ (grid 0.7–1.0) on two corruption types to confirm conservative 0.9/0.9 is robust; log accuracy curves to identify break conditions per corruption class.

## Open Questions the Paper Calls Out

### Open Question 1
Can LeanTTA be effectively adapted for architectures that utilize Layer Normalization or Group Normalization, specifically Vision Transformers (ViT)? The authors explicitly state that an area of future research is "the interaction of our method with layerwise and group normalization layers, or significantly different architectures, like ViT."

### Open Question 2
Can the dynamic balancing mechanism be improved by replacing the Mahalanobis distance with a more noise-resistant out-of-distribution metric? The authors suggest that "Future work could investigate the possibility of more noise-resistant metrics for calculating how far out-of-distribution an individual data point lies."

### Open Question 3
Can LeanTTA be extended to detect stable distribution periods and freeze adapted statistics to optimize efficiency? The authors propose "investigating whether our method could adapt on a single representative image, then freeze the updated statistics until the distribution shifts again."

## Limitations
- Exact data sampling indices and random seed for "Abrupt" CIFAR10-C test set are unspecified
- Numerical stability parameter (ε) for Mahalanobis distance computation is not explicitly listed
- Layerwise ablation study lacks variance estimates and hyperparameter sensitivity analysis

## Confidence
- **High confidence** in the stateless, backpropagation-free design and its core mechanisms
- **Medium confidence** in claimed 15.7% error reduction and memory efficiency, contingent on exact data sampling and numerical choices
- **Medium confidence** in the generalizability of partial fusion benefits, as ablation is limited to ResNet18 on CIFAR10-C

## Next Checks
1. Reproduce Abrupt Shift Results: Implement LeanTTA on ResNet18 for CIFAR10-C "Abrupt" scenario with batch size 1; compare accuracy to source-only and Tent baselines.
2. Memory & Latency Profiling: Measure peak memory usage and per-sample latency on target edge hardware, confirming ResNet18 INT8 stays near 11.2MB and adapts within an order-of-magnitude of normal inference.
3. Hyperparameter Ablation: Sweep τ and λ (e.g., 0.7–1.0) across corruption types to identify sensitivity and validate the robustness of the default 0.9/0.9 configuration.