---
ver: rpa2
title: 'Endo3R: Unified Online Reconstruction from Dynamic Monocular Endoscopic Video'
arxiv_id: '2504.03198'
source_url: https://arxiv.org/abs/2504.03198
tags:
- depth
- surgical
- reconstruction
- video
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Endo3R is a unified 3D foundation model for online scale-consistent
  reconstruction from monocular endoscopic videos without calibration or priors. The
  key innovation is an uncertainty-aware dual memory mechanism that extends pairwise
  reconstruction to long-term dynamic surgical scenes by maintaining short-term temporal
  and long-term spatial tokens, with Sampson distance filtering to remove unreliable
  matches.
---

# Endo3R: Unified Online Reconstruction from Dynamic Monocular Endoscopic Video

## Quick Facts
- arXiv ID: 2504.03198
- Source URL: https://arxiv.org/abs/2504.03198
- Reference count: 40
- One-line primary result: 0.124 Abs Rel, 1.209 RMSE, and 0.839 δ<1.25 on SCARED; 0.170 Abs Rel, 11.569 RMSE, and 0.707 δ<1.25 on Hamlyn

## Executive Summary
Endo3R is a unified 3D foundation model for online scale-consistent reconstruction from monocular endoscopic videos without calibration or priors. The key innovation is an uncertainty-aware dual memory mechanism that extends pairwise reconstruction to long-term dynamic surgical scenes by maintaining short-term temporal and long-term spatial tokens, with Sampson distance filtering to remove unreliable matches. The method jointly predicts globally aligned pointmaps, scale-consistent depth, camera poses, and intrinsics in a single feed-forward pass. To address data scarcity, a self-supervised training scheme with dynamics-aware flow loss is introduced, decomposing optical flow into scene flow and pose-induced motion. Experiments on SCARED and Hamlyn datasets show state-of-the-art performance with real-time efficiency (~20 FPS).

## Method Summary
Endo3R builds on DUSt3R's pairwise reconstruction architecture, extending it to dynamic surgical video through a dual memory mechanism. The model uses a ViT encoder to process frames, retrieving historical context via cross-attention from short-term temporal and long-term spatial buffers. Sampson distance filtering removes unreliable tokens (dynamic tissue, instruments, occlusions) before insertion into long-term memory. A single feed-forward pass predicts globally aligned pointmaps, depth, camera poses, and intrinsics. Self-supervised training uses dynamics-aware flow loss that decomposes optical flow into scene flow and pose-induced motion, enabling training without ground-truth depth or pose.

## Key Results
- Achieves 0.124 Abs Rel, 1.209 RMSE, and 0.839 δ<1.25 on SCARED dataset
- Demonstrates 0.170 Abs Rel, 11.569 RMSE, and 0.707 δ<1.25 on Hamlyn dataset with zero-shot transfer
- Runs at ~20 FPS on RTX 3090, enabling real-time online reconstruction

## Why This Works (Mechanism)

### Mechanism 1: Uncertainty-Aware Dual Memory
- **Claim:** The uncertainty-aware dual memory mechanism enables online, incremental 3D reconstruction from dynamic surgical video by filtering unreliable tokens via Sampson distance while preserving both short-term temporal and long-term spatial context.
- **Mechanism:** Two-tier memory architecture: (1) Short-term temporal buffer stores recent frame tokens for temporal continuity; (2) Long-term spatial buffer accumulates filtered keyframe tokens. Sampson distance between estimated epipolar geometry and observed optical flow identifies unreliable tokens (dynamic tissue, instruments, occlusions)—those exceeding threshold β are pruned before insertion into long-term memory. Cross-attention retrieves relevant history: F^G = Softmax(QK^T/√C)V + Q.
- **Core assumption:** Sampson distance correlates with token reliability in surgical scenes; high-distance tokens correspond to dynamic objects or outliers rather than stable geometry.
- **Evidence anchors:** [abstract], [section 2.2], [corpus] (Weak direct evidence—related works use different filtering strategies)

### Mechanism 2: Dynamics-Aware Flow Loss
- **Claim:** The dynamics-aware flow loss enables self-supervised training on surgical videos without ground-truth depth or pose by decomposing optical flow into scene flow (tissue/instrument motion) and pose-induced flow (camera motion).
- **Mechanism:** Given precomputed optical flow O(i→j) from RAFT: (1) Extract scene flow from predicted pointmaps: Ŝ(u) = X̂_j(u + O(u)) − X̂_i(u); (2) Reconstruct estimated flow by combining scene flow with pose-induced projection: f̂(u') = K̂T̂_j(X̂_i(u') + Ŝ(u')) − u'; (3) Minimize L1 loss: L_Dflow = ||f̂ − O||_1. This removes the static-scene assumption that breaks in dynamic surgery.
- **Core assumption:** Optical flow correctly captures combined motion; pointmap geometry is sufficiently accurate to derive scene flow; RAFT generalizes to endoscopic domains despite domain shift.
- **Evidence anchors:** [abstract], [section 2.3], [corpus] (Related methods use different self-supervision strategies)

### Mechanism 3: Unified Single-Pass Prediction
- **Claim:** A single feed-forward pass unifies prediction of globally aligned pointmaps, scale-consistent depth, camera poses, and intrinsics without multi-stage pipelines or offline optimization.
- **Mechanism:** Builds on DUSt3R's pairwise reconstruction but replaces pair-based inference with memory-augmented sequential processing: ViT encoder → cross-attention memory retrieval → dual transformer decoders (Tar/Ref) → DPT regression head for pointmaps/confidence → PnP for pose → depth extraction via D̂ = (T̂X̂)_z. Pointmaps are predicted directly in frame 1's coordinate system, ensuring global alignment.
- **Core assumption:** Memory-retrieved context provides sufficient information for incremental global alignment; joint prediction avoids error accumulation inherent in cascaded pose-then-depth pipelines.
- **Evidence anchors:** [abstract], [section 2.1], [corpus] (Related works show competing multi-stage approaches)

## Foundational Learning

- **Concept: DUSt3R pairwise 3D reconstruction**
  - Why needed here: Endo3R directly extends DUSt3R's architecture from static pairwise to dynamic sequential reconstruction. Understanding the base pointmap prediction mechanism is prerequisite.
  - Quick check question: How does DUSt3R predict dense 3D pointmaps from two images without explicit depth supervision?

- **Concept: Epipolar geometry and Sampson distance**
  - Why needed here: Core to the uncertainty filtering mechanism—Sampson distance approximates geometric reprojection error for filtering outlier correspondences.
  - Quick check question: What does Sampson distance measure geometrically, and why does high distance indicate a violation of epipolar constraints?

- **Concept: Cross-attention for memory retrieval**
  - Why needed here: The dual memory uses cross-attention to retrieve relevant historical tokens—understanding Q/K/V mechanics is essential for debugging memory behavior.
  - Quick check question: In cross-attention memory retrieval, what do the query, key, and value respectively represent in this architecture?

## Architecture Onboarding

- **Component map:**
  Input Frame (I_t) → ViT Encoder → Feature Tokens (F_t) → Cross-Attention Retrieval → Fused Tokens (F^G_{t-1}) → Dual Decoder (Tar/Ref) → Decoded Features → DPT Head → Pointmap (X̂_t), Confidence (C_t) → PnP Solver → Pose (T̂_t), Intrinsics (K̂) → Depth (D̂_t = (T̂X̂)_z)

- **Critical path:** Encoding → Memory retrieval → Decoding → Pointmap regression → Pose/Depth extraction. Memory encoding (storing tokens) happens after decoding for next-frame use.

- **Design tradeoffs:**
  - Buffer size (K tokens): Larger K improves long-term consistency but increases memory/compute ~20 FPS cap on RTX 3090
  - Sampson threshold (β): Lower = more aggressive filtering (cleaner geometry but potential data loss)
  - λ weights in total loss: L_Dflow (λ1) vs L_dep (λ2) balance self-supervised vs pseudo-supervised signals
  - Assumption: Memory bank limited to top-K tokens by confidence; may prune valid low-confidence regions

- **Failure signatures:**
  - Depth flickering across frames → Check short-term buffer size or cross-attention weights
  - Trajectory drift on long sequences → Sampson filtering may be insufficient; long-term buffer accumulating noise
  - Artifacts near instruments/moving tissue → Sampson threshold too high (insufficient filtering)
  - Scale inconsistency across clips → Loss weighting (λ1, λ2) may need rebalancing
  - Confidence map degradation in specular regions → Expected; DPT head struggles without texture

- **First 3 experiments:**
  1. **Memory ablation:** Run inference with short-term buffer only vs full dual memory on a 200-frame SCARED sequence; plot depth consistency (δ<1.25) vs frame index to quantify drift.
  2. **Sampson threshold sweep:** Test β ∈ {0.5, 1.0, 2.0, 5.0} on Hamlyn dynamic sequences; report Abs Rel and qualitative token survival rates to find operating point.
  3. **Loss component ablation:** Train three variants—(a) supervised only, (b) +monocular depth loss, (c) +dynamics-aware flow loss—on mixed SCARED + unlabeled AutoLaparo; evaluate zero-shot transfer to Hamlyn to measure self-supervision benefit.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the uncertainty-aware memory mechanism be adapted to explicitly reconstruct dynamic surgical instruments rather than filtering them out as transient noise?
- **Basis in paper:** [explicit] Section 2.2 states the method filters out tokens with high Sampson distance to "eliminate the 3D information of transient objects... to enhance global 3D consistency."
- **Why unresolved:** The current design prioritizes a stable background map by removing non-rigid or moving instruments, which limits the completeness of the scene reconstruction for tasks requiring tool tracking.
- **What evidence would resolve it:** A modified version that retains high-uncertainty tokens in a separate dynamic layer and successfully reconstructs tool geometry alongside tissue.

### Open Question 2
- **Question:** Does the self-supervised training pipeline degrade when the off-the-shelf optical flow model fails on textureless or specular endoscopic surfaces?
- **Basis in paper:** [inferred] Section 2.3 relies on the RAFT model [25] to generate pseudo-ground truth flow $O_{i \to j}$ for the dynamics-aware loss. If the flow is inaccurate due to specular highlights or blood, the supervision signal will be noisy.
- **Why unresolved:** The paper does not analyze the failure modes of the external flow model or the robustness of Endo3R's convergence when flow estimates are poor.
- **What evidence would resolve it:** An ablation study showing performance stability when artificial noise is injected into the flow inputs during self-supervised training.

### Open Question 3
- **Question:** How does the incremental reconstruction accuracy degrade over very long sequences without explicit loop closure or global optimization?
- **Basis in paper:** [inferred] The method predicts globally aligned pointmaps in the coordinate frame of $t=1$ using an incremental memory buffer. While it avoids "offline optimization," it lacks an explicit module to correct drift over long trajectories.
- **Why unresolved:** The evaluation appears focused on video depth/pose accuracy over shorter clips; the accumulation of error in the global pointmap over thousands of frames remains unquantified.
- **What evidence would resolve it:** Quantitative reporting of trajectory drift or map consistency on full-length surgical videos that contain loop closures.

## Limitations
- **Sampson threshold tuning:** The paper states tokens with Sampson distance larger than threshold β are eliminated, but β is unspecified. Too low → over-aggressive filtering loses valid correspondences; too high → dynamic artifacts persist in long-term memory.
- **Flow decomposition assumptions:** The dynamics-aware flow loss assumes RAFT optical flow correctly captures combined motion and that pointmap geometry is sufficiently accurate for scene flow extraction. Neither assumption is validated under extreme specular reflections or textureless tissue common in surgery.
- **Memory capacity constraints:** Dual memory operates on K tokens—unknown if K is specified. Insufficient K may cause catastrophic forgetting of distant geometry; excessive K degrades real-time performance.

## Confidence
- **High confidence:** Single-pass unified prediction (architectural claim well-specified and directly comparable to multi-stage baselines); online efficiency (~20 FPS) (measurable, directly reported)
- **Medium confidence:** Sampson-based filtering efficacy (filtering mechanism described but threshold β unspecified; requires empirical validation); dynamics-aware flow loss benefit (mechanism detailed but RAFT dependency introduces uncontrolled variables)
- **Low confidence:** Zero-shot Hamlyn generalization (performance reported but training data overlap unclear; generalization may be overstated)

## Next Checks
1. **Memory ablation study:** Run inference with short-term buffer only vs full dual memory on a 200-frame SCARED sequence; plot depth consistency (δ<1.25) vs frame index to quantify drift.
2. **Sampson threshold sweep:** Test β ∈ {0.5, 1.0, 2.0, 5.0} on Hamlyn dynamic sequences; report Abs Rel and qualitative token survival rates to find operating point.
3. **Flow loss component ablation:** Train three variants—(a) supervised only, (b) +monocular depth loss, (c) +dynamics-aware flow loss—on mixed SCARED + unlabeled AutoLaparo; evaluate zero-shot transfer to Hamlyn to measure self-supervision benefit.