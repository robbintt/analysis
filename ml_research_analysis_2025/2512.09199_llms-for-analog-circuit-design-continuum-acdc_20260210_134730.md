---
ver: rpa2
title: LLMs for Analog Circuit Design Continuum (ACDC)
arxiv_id: '2512.09199'
source_url: https://arxiv.org/abs/2512.09199
tags:
- layout
- transistor
- design
- data
- transistors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores the use of large language models (LLMs) for\
  \ analog circuit layout design, focusing on automating transistor placement under\
  \ design rule constraints. The authors develop a synthetic dataset to represent\
  \ circuit schematics and train various transformer architectures\u2014from smaller\
  \ models like T5 and GPT-2 to larger ones such as Mistral-7B and GPT-oss-20B\u2014\
  on sub-tasks including masking missing components and full layout generation."
---

# LLMs for Analog Circuit Design Continuum (ACDC)

## Quick Facts
- arXiv ID: 2512.09199
- Source URL: https://arxiv.org/abs/2512.09199
- Authors: Yasaman Esfandiari; Jocelyn Rego; Austin Meyer; Jonathan Gallagher; Mia Levy
- Reference count: 9
- Key outcome: Larger LLMs (20B+) outperform smaller models for analog transistor placement, achieving better non-overlapping and symmetry preservation on both synthetic and real netlists.

## Executive Summary
This paper explores using large language models for automated analog circuit layout, specifically transistor placement under design rule constraints. The authors develop synthetic datasets representing circuit schematics and train transformer architectures ranging from T5 and GPT-2 to Mistral-7B and GPT-oss-20B on sub-tasks including masked component prediction and full layout generation. They investigate different data representations and fine-tuning strategies, finding that larger models demonstrate superior spatial reasoning capabilities for satisfying complex placement constraints. While results show promising performance on both synthetic and real netlists, challenges remain in output parsing reliability and generalization to unseen circuit topologies.

## Method Summary
The authors employ three main training paradigms: (1) masking tasks with smaller models (T5-small, GPT-2) for predicting missing components, (2) sequential Seq2Seq generation with Mistral-7B fine-tuned via LoRA/PEFT for one epoch, and (3) all-at-once joint placement with GPT-oss-20B. They generate synthetic datasets with three format versions—grid-based, fixed width/height with centerpoints, and continuous coordinates in JSON. The models are trained to optimize non-overlapping placement, symmetry preservation, space minimization, and DRC compliance. Output parsing uses regex with secondary LLM judging. Evaluation includes synthetic test sets and real industry netlists, with visual inspection and qualitative assessment of constraint satisfaction.

## Key Results
- Smaller models (GPT-2, T5-small) struggle with complex spatial reasoning tasks, particularly multi-constraint placement
- GPT-oss-20B achieves superior performance on both synthetic and real netlists, demonstrating better non-overlapping accuracy and symmetry preservation
- Convolutional layer augmentation significantly improves smaller models' spatial reasoning on toy problems
- Controlled asymmetry (~20%) in training data enables better transfer to real netlists with GPT-oss-20B
- Output parsing remains challenging, with regex-based approaches failing on verbose model outputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scale-dependent spatial reasoning enables larger LLMs to better satisfy complex placement constraints.
- Mechanism: Larger models develop richer internal representations of spatial relationships, allowing simultaneous reasoning about non-overlapping placement, symmetry preservation, and space minimization.
- Core assumption: Parameter count correlates with capacity for compositional spatial reasoning.
- Evidence anchors: Abstract states smaller models struggle while larger models achieve better non-overlapping and space-minimization performance; section 3.3.3 notes generated placements exhibit no overlap and maintain symmetry.
- Break condition: If task requires precise geometric calculations rather than pattern-based spatial reasoning, scaling benefits may diminish.

### Mechanism 2
- Claim: Architectural modifications (convolutional layers) improve sequence models' ability to capture local spatial relationships.
- Mechanism: Adding 1D convolutional layers before transformer blocks creates local receptive fields that encode relative positional information more effectively than standard positional embeddings alone.
- Core assumption: Spatial relationships in circuit layouts can be partially captured through local convolutional feature extraction.
- Evidence anchors: Section 3.1.1 shows convolutional model achieved 100% accuracy and significantly improved GPT-2's spatial reasoning performance.
- Break condition: If spatial relationships require global reasoning beyond local neighborhoods, convolutional benefits will plateau.

### Mechanism 3
- Claim: Synthetic data fidelity to real-world distribution properties determines transfer success.
- Mechanism: Synthetic data v3 incorporated realistic asymmetries (~20% symmetry violations based on SME guidance) and continuous coordinates rather than grid-based representations, enabling the 20B model to transfer learned placement strategies.
- Core assumption: Real netlist distributions can be approximated through expert-informed synthetic generation.
- Evidence anchors: Section 3.3.1 introduces controlled asymmetry in ~20% of training samples; table 2 shows Mistral-7B failed on real netlists with data v2 while GPT-oss-20B succeeded with data v3.
- Break condition: If real circuits exhibit topologies not represented in synthetic distribution, transfer will fail regardless of model scale.

## Foundational Learning

- Concept: **Transformer masking and autoregressive generation**
  - Why needed here: The paper frames circuit layout as both a masked token prediction problem and sequential generation problem. Understanding how transformers learn to fill in missing information is essential.
  - Quick check question: Can you explain why masking one component and predicting its placement is different from generating all placements jointly?

- Concept: **Design Rule Checking (DRC) and Layout vs. Schematic (LVS)**
  - Why needed here: These are the core constraints the LLM must implicitly satisfy. Section 5.1 explains DRC ensures manufacturability while LVS ensures layout matches the netlist.
  - Quick check question: What would happen if an LLM-generated layout passed visual inspection but failed DRC due to minimum spacing violations?

- Concept: **Netlist representation and transistor grouping heuristics**
  - Why needed here: Section 3.1.2 describes how transistors are grouped by source-drain sharing and bulk connections. The LLM must learn these relational properties from synthetic data.
  - Quick check question: Why might drain-source sharing create natural placement groups in analog layout?

## Architecture Onboarding

- Component map: Input netlist text representation -> Optional convolutional preprocessing -> Transformer backbone -> Output placement coordinates (x, y, cx, cy) with rotation flags

- Critical path: 1. Define data representation (sequential vs. all-at-once; grid vs. continuous coordinates) 2. Generate synthetic training data with realistic constraint distributions 3. Fine-tune with LoRA/PEFT for 1-2 epochs 4. Implement output parser (regex + secondary LLM judge) 5. Validate against DRC/LVS tools

- Design tradeoffs:
  - Sequential vs. joint generation: Sequential allows iterative refinement but propagates errors; joint gives global coherence but requires larger context window
  - Grid vs. continuous coordinates: Grid simplifies learning but unrealistic; continuous matches real designs but harder to learn
  - Model size vs. inference cost: 20B models perform better but require significant compute; 7B models faster but less reliable

- Failure signatures:
  - Low training loss but high overlap penalty → model memorizing positions, not learning constraints
  - Accurate on synthetic data, failures on real netlists → distribution shift in data representation
  - Unparseable outputs → need stronger output formatting constraints or secondary parser model
  - Symmetry violations on real circuits → training data didn't capture realistic asymmetry tolerance

- First 3 experiments:
  1. **Toy problem validation**: Replicate Section 3.1.1 masking experiments with and without convolutional layers on your target architecture to verify spatial reasoning baseline.
  2. **Synthetic data sanity check**: Train T5-small on the subgroup masking task (Section 3.1.2, Table 3); if accuracy <70% with 2 groups masked, revisit data representation.
  3. **Small-scale placement pilot**: Fine-tune Mistral-7B on data v2 (Section 3.2.2) with 10 synthetic samples; verify non-overlapping accuracy >80% before scaling to full dataset.

## Open Questions the Paper Calls Out

- Can fine-tuning dedicated LLMs improve the accuracy and reliability of structured data extraction from layout generation model outputs?
- How can LLM-based layout generators be made robust to unseen circuit topologies and mitigate hallucinated placements?
- Does integrating hypergraph-based representations with multimodal fine-tuning improve LLM performance on analog layout synthesis compared to purely sequential/textual representations?
- What is the minimum model scale and training data composition required for reliable analog layout generation that satisfies all design constraints?

## Limitations
- Output parsing reliability remains problematic with current regex-based approaches failing on verbose model outputs
- Real-world generalization is demonstrated on only a handful of netlists, making broader performance claims uncertain
- Computational cost of large models (20B parameters) limits deployment feasibility

## Confidence

**High Confidence**: Scale-dependent performance differences; synthetic data transfer success to real netlists with v3 format

**Medium Confidence**: Claims about architectural improvements from convolutional layers; generalization potential to arbitrary analog circuits

**Low Confidence**: Deployment readiness assertions; end-to-end workflow reliability

## Next Checks
1. **Parser reliability stress test**: Run the secondary LLM parser on 1,000 synthetic outputs with varying degrees of reasoning verbosity; measure structural accuracy and identify failure modes requiring output format constraints.

2. **Distribution shift quantification**: Systematically vary asymmetry rates in synthetic data (5%, 20%, 50%) and measure transfer performance on real netlists to determine sensitivity to training data distribution parameters.

3. **Compute-performance tradeoff analysis**: Compare Mistral-7B vs GPT-oss-20B on a standardized set of 50 real netlists measuring (a) placement quality metrics, (b) inference time, and (c) DRC pass rates to quantify practical scaling benefits.