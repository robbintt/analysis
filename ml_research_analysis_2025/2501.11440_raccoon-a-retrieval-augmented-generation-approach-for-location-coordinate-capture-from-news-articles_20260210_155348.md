---
ver: rpa2
title: 'RACCOON: A Retrieval-Augmented Generation Approach for Location Coordinate
  Capture from News Articles'
arxiv_id: '2501.11440'
source_url: https://arxiv.org/abs/2501.11440
tags:
- raccoon
- location
- news
- geocoding
- articles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RACCOON, a retrieval-augmented generation
  (RAG) approach for geocoding location coordinates from news articles. RACCOON uses
  a combination of country-assisted retrieval, candidate location ranking, and in-context
  prompting to extract geolocations from text.
---

# RACCOON: A Retrieval-Augmented Generation Approach for Location Coordinate Capture from News Articles

## Quick Facts
- arXiv ID: 2501.11440
- Source URL: https://arxiv.org/abs/2501.11440
- Reference count: 23
- Primary result: RACCOON outperforms LLM-only baselines with mean error of 124.19 km and 86.1% accuracy@161km on GeoVirus dataset

## Executive Summary
RACCOON is a retrieval-augmented generation (RAG) approach designed to extract precise geographic coordinates from location mentions in news articles. It combines country-assisted retrieval, candidate ranking by population, and in-context prompting to an LLM to generate coordinates. The system uses a geospatial database (GeoNames) and was evaluated on three benchmark datasets, showing improved accuracy and precision compared to rule-based and LLM-only baselines, though with some limitations including recall and population bias.

## Method Summary
RACCOON processes news articles through a five-component pipeline: (1) GPT-4o-mini infers the country for each location mention to assist retrieval, (2) BM25 retrieves candidate locations from a GeoNames index, (3) candidates are ranked by population and top 20 selected, (4) GeoNames feature types and state context are included, and (5) an in-context prompt containing candidates, mention, and article text is fed to an LLM (GPT-4o-mini or Gemini) to generate coordinates. The approach is evaluated on three datasets (GeoVirus, GeoWebNews, LGL) using metrics including mean error, accuracy@161km, country accuracy, and AUC.

## Key Results
- RACCOON achieves mean error of 124.19 km and accuracy@161km of 86.1% on GeoVirus dataset
- RACCOON consistently outperforms LLM-only baselines in AUC and mean error across all three datasets
- Population bias is evident, with lower accuracy for low-population locations (Accuracy@161km drops from 87.8% to 57.8% for populations under 10k)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Pre-identifying the country before retrieving candidates reduces toponym ambiguity by constraining the search space.
- **Mechanism:** A lightweight LLM (GPT-4o-mini) first infers the country from the article context. This inferred country is then passed to a Lucene-based BM25 retriever, which searches the GeoNames index for location matches limited to that country. The top 20 candidates are selected for downstream ranking.
- **Core assumption:** The LLM can reliably infer the correct country from surrounding textual context before location resolution begins.
- **Evidence anchors:**
  - [Methodology]: "Given a news article as input, a GPT-4o-mini model is used to identify a country for each location mention (country-assisted retrieval). The inferred country is passed along with the location mention, and helps to narrow down the candidate locations."
  - [Ablation results, Table 2]: Removing country-assisted retrieval degrades performance on LGL (MErr jumps from 284.10 to 524.94), suggesting the component provides meaningful disambiguation value.
  - [Corpus]: Weak direct evidence; corpus neighbors focus on other geocoding challenges but do not confirm country-first strategies.
- **Break condition:** If the LLM misidentifies the country (e.g., inferring "Georgia" the US state instead of "Georgia" the country), the retriever will return candidates from the wrong geographic region, and the pipeline cannot recover.

### Mechanism 2
- **Claim:** Ranking candidate locations by population prioritizes locations more likely to be referenced in news articles.
- **Mechanism:** After BM25 retrieval returns candidate matches, RACCOON sorts them by population and retains the top 20. The assumption is that news articles disproportionately reference populous areas (major cities, capitals) over small localities.
- **Core assumption:** Population correlates positively with likelihood of being the intended referent in news discourse.
- **Evidence anchors:**
  - [Methodology]: "RACCOON sorts the retrieved matches using the population heuristic (i.e., based on population), taking 20 top entries as candidate locations."
  - [Results, Figure 2]: Accuracy@161km is lower for low-population locations, confirming population bias exists.
  - [Ablation results, Table 2]: On LGL (biased toward local US areas), removing the population heuristic improves MErr (284.10 â†’ 262.43), suggesting the heuristic harms performance on datasets with more small-population references.
  - [Corpus]: Related work on geocoding acknowledges population-based heuristics as common but imperfect.
- **Break condition:** For news about rural incidents, small towns, or local events, the correct location may fall outside the top-20 population-ranked candidates, making retrieval failure inevitable.

### Mechanism 3
- **Claim:** Providing structured gazetteer context to an LLM via RAG improves coordinate precision compared to prompting the LLM alone.
- **Mechanism:** Candidate locations (with name, coordinates, feature type, country, state) are injected into an in-context prompt alongside the location mention and article text. The LLM then selects or generates coordinates grounded in retrieved evidence rather than relying solely on parametric knowledge.
- **Core assumption:** LLMs have useful geospatial reasoning capabilities but lack reliable access to precise, up-to-date coordinate data; external grounding compensates for this gap.
- **Evidence anchors:**
  - [Abstract]: "RACCOON uses a retrieval-augmented generation (RAG) approach where candidate locations and associated information are retrieved in the form of context from a location database, and a prompt containing the retrieved context... is fed to an LLM to generate the location coordinates."
  - [Results, Table 2]: RACCOON consistently achieves better AUC (lower is better) than the LLM Base model across all three datasets, indicating improved precision through grounded retrieval.
  - [Corpus]: Related RAG frameworks (e.g., XRAG, ScoreRAG) demonstrate similar benefits of retrieval grounding for factual precision, though not specifically for geocoding.
- **Break condition:** If the retriever fails to include the correct location in the top-20 candidates, the LLM has no path to the correct answer and may produce confident but incorrect coordinates.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** RACCOON's core innovation is applying RAG to geocoding. Understanding how retrieval augments LLM generation (and its limitations) is prerequisite to grasping the architecture.
  - **Quick check question:** If the retriever returns no relevant documents, what happens to the LLM's output quality?

- **Concept: Toponym Resolution / Geocoding**
  - **Why needed here:** This is the task RACCOON addresses. The challenge of ambiguity (e.g., "Springfield" exists in many US states) motivates the multi-component design.
  - **Quick check question:** Why is "Paris" harder to geocode without context than "Paris, France"?

- **Concept: Gazetteers (GeoNames)**
  - **Why needed here:** RACCOON's retriever queries a structured geospatial database. Understanding what gazetteers contain (names, coordinates, feature types, populations) clarifies what RACCOON can and cannot retrieve.
  - **Quick check question:** If a location is not in the gazetteer, can RACCOON correctly geocode it?

## Architecture Onboarding

- **Component map:** News Article Input -> GPT-4o-mini (Country Inference) -> Lucene/GeoNames Index (BM25 Retrieval) -> Population-Based Ranking -> Top 20 Candidates -> Prompt Construction (candidates + article + mention) -> LLM (GPT-4o-mini or Gemini) -> Coordinate Output

- **Critical path:**
  1. Country inference must be correct (otherwise retriever searches wrong region).
  2. Retriever must include the correct location in top-20 candidates (otherwise LLM cannot recover).
  3. LLM must correctly reason over provided context to select coordinates.

- **Design tradeoffs:**
  - **20 candidates vs. more:** More candidates increase retrieval recall but raise prompt token costs and LLM inference time.
  - **Population heuristic:** Improves average-case performance for globally famous locations but introduces systematic bias against small-population referents.
  - **BM25 vs. dense embeddings:** BM25 is cost-effective over large gazetteers but may miss semantic matches; dense retrieval could improve recall at higher compute cost (noted as future work).

- **Failure signatures:**
  - **Country misclassification:** Outputs coordinates in wrong country entirely; check Country Accuracy metric drops.
  - **Population bias:** Low Accuracy@161km for small-population ground-truth locations; verify via population-stratified analysis (Figure 2).
  - **Empty/low recall:** Fewer returned results than expected; check "Num" column in Table 2.

- **First 3 experiments:**
  1. **Ablate country-assisted retrieval:** Run retriever without country constraint; measure impact on MErr and Country Accuracy to quantify disambiguation value.
  2. **Vary candidate count (e.g., 10, 20, 50):** Assess tradeoff between retrieval recall and LLM reasoning performance/cost.
  3. **Stratify evaluation by population bucket:** Confirm population bias by computing Accuracy@161km separately for low, medium, and high population ground-truth locations.

## Open Questions the Paper Calls Out
- Can open-source LLMs be effectively integrated into RACCOON to mitigate the costs associated with proprietary models while maintaining performance?
- Does fine-tuning the underlying model offer superior domain-specific performance compared to the RAG-based approach used in RACCOON?
- How can the population heuristic be modified to improve recall and accuracy for low-population locations?

## Limitations
- Population bias systematically favors high-population locations, degrading accuracy for small towns and rural areas
- Pipeline cannot recover if correct location is not included in top-20 candidates from retriever
- Prompt design dependency - performance may be sensitive to hand-crafted templates not detailed in paper

## Confidence
- High confidence: Retrieval-augmented approach improves precision over LLM-only baselines (AUC and MErr metrics)
- Medium confidence: Country-assisted retrieval meaningfully reduces ambiguity (evidenced by ablation on LGL)
- Low confidence: Claims about computational efficiency relative to dense retrieval are speculative (stated as future work)

## Next Checks
1. **Prompt ablation study:** Systematically vary prompt templates for country inference and coordinate generation to quantify sensitivity to prompt engineering
2. **Population-stratified evaluation:** Compute Accuracy@161km separately for ground-truth locations in low (<10k), medium (10k-100k), and high (>100k) population bins to precisely measure bias severity
3. **Recall ceiling analysis:** For each dataset, determine the percentage of mentions where the correct GeoNames entry appears in the top-20 candidates to establish the fundamental recall limit of the current retrieval design