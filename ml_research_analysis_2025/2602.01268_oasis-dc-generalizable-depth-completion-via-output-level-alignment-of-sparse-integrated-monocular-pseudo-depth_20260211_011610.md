---
ver: rpa2
title: 'OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated
  Monocular Pseudo Depth'
arxiv_id: '2602.01268'
source_url: https://arxiv.org/abs/2602.01268
tags:
- depth
- prior
- completion
- sparse
- shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles depth completion under severe data scarcity,
  where labeled datasets are limited and sensor configurations may change in deployment.
  To address this, the authors propose a framework that uses a foundation monocular
  depth model (Depth Anything v2) as a pseudo-metric depth prior, which is then calibrated
  to sparse LiDAR measurements via a Poisson formulation with hard constraints, creating
  a metrically accurate pseudo-depth map.
---

# OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth

## Quick Facts
- **arXiv ID:** 2602.01268
- **Source URL:** https://arxiv.org/abs/2602.01268
- **Reference count:** 38
- **Primary result:** Strong performance in 1-/10-/100-shot and 1-sequence settings, with RMSE as low as 1.22 m on KITTI and 0.15 m on NYUv2 in the 100-shot case.

## Executive Summary
This paper tackles depth completion under severe data scarcity, where labeled datasets are limited and sensor configurations may change in deployment. The authors propose a framework that uses a foundation monocular depth model (Depth Anything v2) as a pseudo-metric depth prior, which is then calibrated to sparse LiDAR measurements via a Poisson formulation with hard constraints, creating a metrically accurate pseudo-depth map. A lightweight residual network refines this prior, focusing on correcting localized errors such as thin structures and depth discontinuities, rather than learning scale from scratch. The method operates entirely at the output level, avoiding expensive feature-level coupling to the foundation model, making it efficient and deployable.

## Method Summary
The method uses a frozen foundation monocular depth estimator (Depth Anything v2) to provide dense relative depth, which is then calibrated to sparse LiDAR measurements via a Poisson fusion with hard constraints, producing a metrically accurate pseudo-depth prior. A lightweight residual network refines this prior by predicting per-pixel corrections, focusing on localized errors like thin structures and depth discontinuities rather than learning scale from scratch. An optional hyperbolic affinity-based refinement module further suppresses cross-edge bleeding and refines depth via multi-kernel propagation with center-tethering and learnable anchoring. The entire pipeline is trained end-to-end with few-shot supervision, and operates at the output level to remain efficient and modular.

## Key Results
- Achieves strong performance in 1-/10-/100-shot and 1-sequence settings on KITTI and NYUv2.
- RMSE as low as 1.22 m on KITTI and 0.15 m on NYUv2 in the 100-shot case.
- Ablations confirm the necessity of both the pseudo-prior and sparse anchors for robust few-shot generalization.

## Why This Works (Mechanism)

### Mechanism 1
The method aligns a frozen foundation monocular depth estimator output with sparse LiDAR anchors via Poisson fusion to produce a metrically accurate pseudo-depth prior without training. The foundation model provides relative depth that preserves global layout and boundaries, and a Poisson equation with hard constraints at sparse anchor pixels propagates metric scale from LiDAR points into unknown regions, exactly honoring measurements at known pixels while following the MDE gradient field elsewhere. This yields a dense, edge-preserving, metrically calibrated prior. The core assumption is that relative depth from the MDE correctly captures scene structure and boundaries, and sparse anchors are geometrically reliable at sampled locations. Break condition: if the MDE systematically misorders depth ordering (e.g., reflective surfaces, thin structures), gradient guidance will propagate incorrect structure. If LiDAR anchors are sparse in key regions (e.g., far field), metric accuracy degrades proportionally.

### Mechanism 2
A lightweight residual network correcting the pseudo-prior achieves few-shot stability by constraining the hypothesis space. The network receives the pseudo-depth map (global scale already fixed), the raw MDE output, RGB, and the LiDAR mask, and predicts a per-pixel residual; the corrected depth is the sum of the prior and residual. By design, the prior handles low-frequency metric structure, and the residual allocates capacity to high-frequency corrections at discontinuities and thin structures. This decomposition prevents the network from needing to learn absolute scale from few samples. The core assumption is that the pseudo-prior is sufficiently accurate globally that residual corrections remain localized and small-magnitude. Break condition: if the pseudo-prior has systematic regional bias (e.g., due to MDE domain gap), the low-capacity residual may undercorrect. Under extreme data scarcity (1-shot), residual predictions may exhibit variance if the prior is unreliable.

### Mechanism 3
Hyperbolic affinity-based multi-kernel propagation with center-tethering and learnable anchoring refines depth while suppressing cross-edge bleeding. Encoder features are embedded into a Poincaré ball; hyperbolic distances define affinities. Multi-scale kernels (3×3, 5×5, 7×7) are gated per-pixel. Each propagation iteration is center-tethered to the prior to prevent drift. A learnable anchor map blends propagated depth with raw LiDAR where observations exist, allowing soft correction near occlusions/misprojections. The core assumption is that hyperbolic space better captures hierarchical scene geometry; center-tethering prevents over-smoothing. Break condition: if feature embeddings are noisy or the scene lacks clear hierarchical structure, hyperbolic affinity may not improve over Euclidean. If anchor map is miscalibrated, LiDAR artifacts may propagate or valid corrections may be suppressed.

## Foundational Learning

- **Poisson image editing / gradient-domain fusion**
  - Why needed here: The pseudo-depth construction formulates depth completion as a constrained Poisson problem—understanding boundary conditions and gradient guidance is essential for debugging the prior pipeline.
  - Quick check question: Given sparse depth anchors and a dense gradient field from an MDE, can you explain why the solution is unique and how the Laplacian matrix enforces smoothness?

- **Residual learning and hypothesis space**
  - Why needed here: The architecture explicitly splits scale (pseudo-prior) from local corrections (residual). Understanding this decomposition clarifies why the network generalizes from few samples.
  - Quick check question: If you removed the pseudo-prior and trained the residual network from scratch on 10 samples, what failure mode would you expect and why?

- **Hyperbolic neural networks and Poincaré embeddings**
  - Why needed here: The affinity module uses hyperbolic distances. Without this background, the temperature-scaled distance computation and its geometric interpretation are opaque.
  - Quick check question: What property of hyperbolic space makes it suitable for hierarchical or tree-like structures, and how does the exponential map place features on the Poincaré ball?

## Architecture Onboarding

- **Component map:** Foundation MDE (frozen) → dense relative depth E; Poisson prior constructor (non-learned) → pseudo-depth P via conjugate gradients; Encoder: Concatenated [RGB, P, E, LiDAR mask] → multi-scale features F; Residual decoder: F → per-pixel residual R → D₀ = P + R; Affinity refinement module: F → hyperbolic embeddings → multi-kernel gated propagation → center-tethered updates → final D; Anchor head: F → per-pixel anchor weight α for sensor blending.

- **Critical path:** Sparse LiDAR → Poisson prior construction → residual decoder → affinity refinement → output. The prior quality directly gates residual and refinement effectiveness.

- **Design tradeoffs:**
  - Output-level vs. feature-level coupling: Output-level is efficient and deployable (0.219M learnable params, 0.013s inference) but cannot leverage foundation model's internal representations.
  - Residual capacity: Intentionally low-capacity stabilizes few-shot learning but may underfit fine details (observed on NYUv2 vs. UniDC).
  - Anchor weight α: Soft anchoring allows correction near misprojections but risks ignoring valid LiDAR if α is poorly calibrated.

- **Failure signatures:**
  - Depth penetration across object boundaries: Indicates affinity refinement not suppressing cross-edge propagation; check kernel gates and hyperbolic temperature.
  - Scale drift on far-field regions: Indicates insufficient anchor density; verify Poisson solver convergence and LiDAR coverage.
  - Noisy predictions under 1-shot: Normal variance; check that validation uses fixed random seeds per protocol.

- **First 3 experiments:**
  1. Run Poisson prior construction without learned refinement on KITTI validation. Confirm RMSE ~1.7–1.8m (per Table IV) to validate the non-learned pipeline.
  2. Ablate anchor vs. residual: Train with (anchor only, residual only, both, neither) on 100-shot KITTI. Verify that both are necessary and that neither-alone underperforms even the no-modules baseline.
  3. Cross-MDE swap: Replace Depth Anything v2 with ZoeDepth or MiDaS in the prior constructor (no retraining). Compare RMSE and edge fidelity to confirm modularity.

## Open Questions the Paper Calls Out
- **Future work includes stronger uncertainty-aware calibration of the monocular prior.** This is needed because the current Poisson formulation treats sparse LiDAR anchors as hard constraints with binary validity, but real-world LiDAR suffers from multipath returns, occlusion boundaries, and sensor noise, and the method has no mechanism to downweight unreliable anchors.
- **Future work includes dynamic-scene handling.** This is unresolved because the method assumes static geometry: the Poisson fusion aligns a single monocular depth prior with accumulated sparse points. If objects move between the RGB capture and LiDAR sweep, the pseudo-depth prior will be misaligned with anchors, and residual correction may propagate errors rather than fix them.
- **Future work includes extending to more data regimes.** The authors note that the intentionally conservative residual capacity for few-shot stability can underfit fine indoor details relative to larger heads. It is unclear whether a larger residual head would eventually outperform as shots increase, or if the prior-guided inductive bias remains dominant.

## Limitations
- Architecture details of the lightweight encoder/decoder are underspecified, making exact replication challenging.
- Hyperparameter values (curvature κ, kernel temperatures τ_k, iteration count T, d_max) are not disclosed.
- Training procedure lacks details on optimizer choice, learning rate schedule, and batch size.
- The cross-dataset robustness claim relies on a single prior model; generalizability to other MDEs is untested.

## Confidence
- **High:** The Poisson prior construction pipeline and its ablation results (anchors + residual required).
- **Medium:** The residual-only learning framework; likely robust given the hypothesis space constraint but capacity limits on NYUv2 remain unvalidated.
- **Low:** The necessity and exact contribution of the hyperbolic affinity refinement—no ablation isolating it from residual correction, and the Poincaré representation's advantage over Euclidean is not quantitatively justified.

## Next Checks
1. Run the Poisson prior construction alone (no learned refinement) on KITTI validation; confirm RMSE ≈1.7–1.8 m to verify the non-learned baseline.
2. Ablate anchor vs. residual contributions: train with (anchor only, residual only, both, neither) on 100-shot KITTI; confirm both are necessary and that neither-alone performs near the no-modules baseline.
3. Swap the foundation MDE: replace Depth Anything v2 with ZoeDepth or MiDaS in the prior constructor (no retraining); compare RMSE and edge fidelity to test modularity and domain generalization.