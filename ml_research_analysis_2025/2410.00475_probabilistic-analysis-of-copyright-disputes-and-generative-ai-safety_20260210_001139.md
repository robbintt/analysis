---
ver: rpa2
title: Probabilistic Analysis of Copyright Disputes and Generative AI Safety
arxiv_id: '2410.00475'
source_url: https://arxiv.org/abs/2410.00475
tags:
- access
- similarity
- copyright
- evidence
- copying
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies probabilistic analysis to copyright infringement
  disputes, formalizing key evidentiary principles in legal fact-finding. It formally
  proves the "inverse ratio rule," showing that stronger evidence of access reduces
  the similarity threshold needed to prove copying.
---

# Probabilistic Analysis of Copyright Disputes and Generative AI Safety

## Quick Facts
- arXiv ID: 2410.00475
- Source URL: https://arxiv.org/abs/2410.00475
- Reference count: 30
- Primary result: Formal proof of inverse ratio rule for copyright infringement; probabilistic analysis of NAF condition's limitations

## Executive Summary
This paper provides a formal probabilistic framework for analyzing copyright infringement disputes and generative AI safety. It mathematically proves the inverse ratio rule—showing that stronger evidence of access to a copyrighted work reduces the similarity threshold needed to prove copying. The analysis then extends to the Near Access-Free (NAF) condition, demonstrating that while it can reduce copyright infringement risks by making similarity less probative of access, its effectiveness is limited and raises ethical concerns about transparency in training data. The work establishes a theoretical foundation for understanding how copyright law's evidentiary principles interact with emerging AI technologies.

## Method Summary
The paper uses pure theoretical probability analysis with binary random variables (Copy, Access, Substantial, Probative, Striking) and discrete variables for similarity levels. It defines conditional probability relationships representing copyright law's factual copying prong, proves the inverse ratio rule holds under specified assumptions, and extends the framework to analyze NAF's effect on access inference probability. No empirical experiments or model training are conducted—the work consists entirely of mathematical derivations and theoretical bounds.

## Key Results
- Formal proof that the inverse ratio rule holds for the factual copying prong of copyright infringement when properly defined
- Mathematical demonstration that NAF can reduce copyright infringement risks by limiting similarity's evidentiary value for access
- Analysis showing NAF's effectiveness is constrained by baseline access evidence and raises transparency concerns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The inverse ratio rule is mathematically valid when properly defined for the factual copying prong of copyright infringement.
- Mechanism: The probability of copying P(C=1|S=i, E_A=j) = α_i × β_{i,j} decomposes into two factors: (1) probability of copying given access and similarity level, and (2) probability of access given similarity and other evidence. Since the product must exceed threshold λ, stronger evidence of access (higher β_{i,j}) allows lower similarity levels to satisfy the threshold, and vice versa.
- Core assumption: Access is a necessary condition for copying (P(C=1|A=0) = 0), and evidentiary values vary monotonically with similarity and access evidence strength.
- Evidence anchors:
  - [abstract] "a formal proof demonstrates its validity, provided it is properly defined"
  - [section 2.2] Proposition 2.2 formally proves the inverse ratio rule holds for any threshold λ
  - [corpus] No corpus papers directly address inverse ratio rule formalization; this appears to be a novel contribution
- Break condition: If access evidence and similarity do not interact multiplicatively (e.g., if evidence is cumulative rather than complementary), the rule may not hold.

### Mechanism 2
- Claim: The Near Access-Free (NAF) condition bounds the probability of inferring model access to copyrighted works from output similarity.
- Mechanism: NAF imposes P(S=i|A_M=1) ≤ e^ε × P(S=i|A_M=0). This creates an upper bound Γ(ε, δ_k) = e^ε·δ / (1 + δ(e^ε - 1)) on P(A_M=1|S=i, E_{AM}=k), where δ_k is baseline belief about access. As ε→0, similarity loses evidentiary value for inferring access.
- Core assumption: The output distribution satisfies the NAF inequality for all copyrighted works, and evidence of access is conditionally independent of similarity given access status.
- Evidence anchors:
  - [abstract] "The probabilistic approach is then used to analyze the Near Access-Free (NAF) condition... revealing that while it can reduce copyright infringement risks, its effectiveness is limited"
  - [section 3] Definition 3.1 and Proposition 3.2 establish the formal bound
  - [corpus] Vyas et al. (ICML 2023) introduced NAF; "Blameless Users in a Clean Room" (arXiv:2506.19881) discusses its limitations for provable protection
- Break condition: If δ_k is already high (strong external evidence of access), the bound Γ(ε, δ_k) becomes less constraining since Γ ≥ δ always holds.

### Mechanism 3
- Claim: NAF operates by reducing transparency about training data access, which is ethically problematic.
- Mechanism: When ε is small, producing similar outputs does not strongly indicate access. This prevents plaintiffs from using similarity as evidence of access, but contradicts transparency demands. The protection weakens as baseline access evidence δ_k increases through widespread training on copyrighted corpora.
- Core assumption: Ethical frameworks favor transparency in training data disclosure; legal fact-finding benefits from evidentiary value of similarity.
- Evidence anchors:
  - [abstract] "its effectiveness is limited and raises ethical concerns about transparency in training data"
  - [section 3] "this approach may contradict the demand for transparency in training data, as advocated by researchers [19, 25]"
  - [corpus] Sag (2023) and Yoo (2024) cited for transparency advocacy; corpus papers on copyright auditing (arXiv:2601.12937) discuss evidentiary challenges
- Break condition: If courts mandate training data disclosure or accept corpus-wide access evidence, NAF's evidentiary obscuration becomes legally irrelevant.

## Foundational Learning

- Concept: **Bayesian conditional probability and Bayes' theorem**
  - Why needed here: The entire framework represents legal fact-finding as updating beliefs via P(hypothesis|evidence). Understanding how P(A|B) relates to P(B|A) is essential for following the derivations.
  - Quick check question: Given P(C=1|A=1, S=i) = α_i and P(A=1|S=i, E_A=j) = β_{i,j}, what is P(C=1|S=i, E_A=j)?

- Concept: **Copyright infringement elements (Arnstein test)**
  - Why needed here: The paper formalizes two prongs—factual copying and improper appropriation—and treats them differently in probabilistic terms.
  - Quick check question: Why does similarity serve a dual role in copyright analysis, and which prong does NAF primarily address?

- Concept: **Differential privacy and multiplicative bounds**
  - Why needed here: NAF's inequality P(Z|Access=1) ≤ e^ε × P(Z|Access=0) mirrors differential privacy's ε-bounds. Understanding how ε controls the "privacy" (here, "access-freeness") guarantee is crucial.
  - Quick check question: If ε = 0.1, what is the maximum factor by which access can increase output probability?

## Architecture Onboarding

- Component map:
  - **Random variables layer**: C (copying), A (access), S (similarity level), E_A (access evidence), Z (model output)
  - **Legal standard layer**: Threshold λ (preponderance of evidence), substantial similarity determination
  - **NAF constraint layer**: Parameter ε, bound function Γ(ε, δ)
  - **Inference layer**: Posterior probability calculations for P(C=1|...) and P(A_M=1|...)

- Critical path: Define random variables → Specify conditional independence assumptions → Derive P(C=1|S, E_A) = α × β → Apply threshold λ → Extend to NAF with P(S|A_M) bound → Compute Γ(ε, δ) upper bound

- Design tradeoffs:
  - Lower ε provides stronger theoretical guarantees but may severely constrain model utility
  - High baseline access evidence δ_k (e.g., known training on copyrighted corpora) reduces NAF's protective value
  - Formal model abstracts from details like user prompts that may affect infringement analysis

- Failure signatures:
  - Claiming NAF guarantees no infringement: false—NAF only bounds probabilities, doesn't eliminate risk
  - Applying inverse ratio rule to improper appropriation prong: the proof only covers factual copying
  - Using population-level statistics to resolve specific cases: commits the "trial by mathematics" fallacy warned against

- First 3 experiments:
  1. **Validate inverse ratio rule empirically**: Collect copyright case outcomes, code access evidence strength and similarity levels, test whether P(copying|high access, low similarity) ≈ P(copying|low access, high similarity)
  2. **Measure Γ(ε, δ) sensitivity**: For a model satisfying ε-NAF, compute how the upper bound on P(A_M=1|S, E) varies with δ across realistic access evidence scenarios
  3. **Test NAF utility tradeoff**: Train generative models with varying ε constraints and measure both (a) copyright similarity rates and (b) output quality/diversity metrics

## Open Questions the Paper Calls Out

- **Alternative copyright risk mitigation strategies**: The paper explicitly states that "future research should analyze and develop copyright risk mitigation strategies alternative to the Near Access-Free (NAF) condition" due to NAF's limited efficacy and ethical concerns about transparency.

- **Broader application of probabilistic formalization**: The author notes the "approach has wider potential applications within copyright jurisprudence, where many legal doctrines can be understood from evidentiary perspectives," suggesting formal probabilistic analysis could be applied to other contested areas like fair use or substantial similarity.

- **User prompts in infringement analysis**: The author identifies a key limitation: "the analysis abstracts from certain details involved in AI generation, such as the content of user-provided prompts, which may influence the identification of direct or indirect infringers," highlighting the need for models that incorporate prompt content in infringement probability calculations.

## Limitations

- The inverse ratio rule proof only applies to the factual copying prong of copyright infringement, not the improper appropriation prong
- NAF's effectiveness depends heavily on baseline access evidence δ_k, providing minimal protection when this is high (as with widely trained models)
- The model abstracts from real-world complexities like user prompts and specific context in copyright disputes

## Confidence

- **High**: The mathematical proofs for the inverse ratio rule (Proposition 2.2) and NAF bounds (Proposition 3.2) are sound given the stated assumptions
- **Medium**: The legal interpretation of how probabilistic analysis maps to copyright law, given the abstract nature of the formalization
- **Medium**: The ethical implications of NAF reducing transparency, as this depends on contested values about copyright and AI training

## Next Checks

1. **Empirical testing of inverse ratio rule**: Analyze real copyright case outcomes to verify whether stronger access evidence correlates with acceptance of lower similarity thresholds in practice
2. **Quantitative analysis of NAF bounds**: For models claiming NAF compliance, compute how the upper bound Γ(ε, δ) varies across realistic scenarios with different baseline access evidence levels
3. **Utility-cost tradeoff assessment**: Train generative models with varying ε constraints and measure both copyright similarity rates and output quality metrics to evaluate the practical tradeoff of NAF implementation