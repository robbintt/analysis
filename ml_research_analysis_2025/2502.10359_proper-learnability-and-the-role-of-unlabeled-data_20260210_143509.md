---
ver: rpa2
title: Proper Learnability and the Role of Unlabeled Data
arxiv_id: '2502.10359'
source_url: https://arxiv.org/abs/2502.10359
tags:
- learning
- which
- learner
- proper
- learnability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of proper learnability in supervised
  learning, specifically asking under what conditions a hypothesis class can be properly
  learned. The core method idea involves introducing the distribution-fixed PAC model,
  where the learner is given the marginal distribution over unlabeled data, and demonstrating
  that all finite learning problems with bounded metric loss functions can be optimally
  learned by proper learners in this model.
---

# Proper Learnability and the Role of Unlabeled Data

## Quick Facts
- arXiv ID: 2502.10359
- Source URL: https://arxiv.org/abs/2502.10359
- Reference count: 19
- Primary result: Distribution-fixed PAC learning (with known marginal distribution) enables proper learners for all finite learning problems with bounded metric loss, but sample complexity improves by at most a logarithmic factor from classic PAC.

## Executive Summary
This paper investigates proper learnability in supervised learning, asking when a hypothesis class can be properly learned (i.e., when the learner must output a hypothesis from the class). The authors introduce the distribution-fixed PAC model where the learner knows the marginal distribution over unlabeled data. They prove that all finite learning problems with bounded metric loss functions can be optimally learned by proper learners in this model using distributional regularization. The paper also shows that knowing the marginal distribution doesn't substantially improve sample complexities (only by a logarithmic factor) but simplifies the form of the optimal algorithm. Additionally, they demonstrate that proper learnability is logically undecidable, not a monotone property, and not a local property, revealing fundamental complexity in characterizing when proper learning is possible.

## Method Summary
The core approach introduces distributional regularization in the distribution-fixed PAC model, where the learner has oracle access to the marginal distribution D over unlabeled data. The method constructs a zero-sum game between an adversary selecting the ground truth hypothesis and the learner, showing that Bayesian learners with appropriate priors serve as best responses. The optimal learner outputs probability distributions over the hypothesis class that minimize a distributional regularizer subject to zero training error. This construction proves that any finite learning problem with bounded metric loss can be solved by a randomized proper learner achieving optimal expected error up to a factor of 2. The paper also establishes connections between distribution-fixed and classic PAC learning, showing that the marginal knowledge only improves sample complexity by a logarithmic factor in the worst case.

## Key Results
- All finite learning problems with bounded metric loss have optimal proper learners in the distribution-fixed PAC model governed by distributional regularization
- Sample complexities in distribution-fixed PAC shrink by at most a logarithmic factor from classic PAC
- Proper learnability is logically undecidable (independent of ZFC axioms)
- Proper learnability is neither a monotone property nor a local property

## Why This Works (Mechanism)

### Mechanism 1: Distributional Regularization Enables Proper Learning
When the marginal distribution D over unlabeled data is fully known, any finite learning problem with bounded metric loss can be solved by a randomized proper learner using distributional regularization. The learner models the problem as a zero-sum game between an adversary (selecting ground truth h*) and the learner. Bayesian learners with priors over H serve as best responses; convex combinations of these reduce to single Bayesian learners. The resulting learner outputs probability distributions over H that minimize a regularizer ψ subject to zero training error. This works for finite domains with bounded metric loss functions in the realizable setting.

### Mechanism 2: Marginal Knowledge Has Limited Worst-Case Value
Sample complexity in the distribution-fixed model shrinks by at most a logarithmic factor from classic PAC; unlabeled data does not substantially help under worst-case evaluation. Transductive learning serves as an intermediate model. A distribution-fixed learner achieving expected error ε implies a transductive learner achieving error e·ε, via sampling from the empirical distribution. Conversely, transductive error bounds expected PAC error via leave-one-out analysis. This holds for bounded loss functions with evaluation over all possible marginals D (worst-case).

### Mechanism 3: Proper Learnability Is Logically Undecidable
There exist hypothesis classes H for which proper learnability cannot be proven or disproven within ZFC. The paper reduces EMX learning to proper multiclass classification. Construct H where each hypothesis h_A outputs a cofinite set label A on most points; learning reduces to finding large-measure finite subsets, equivalent to EMX on F=X. EMX learnability depends on cardinality (|F| < ℵ_ω), which is independent of ZFC for F=ℝ. This construction works under ZFC axioms with standard cardinality properties.

## Foundational Learning

- **PAC Learning Framework (Definitions 2.1–2.3)**: Entire paper builds on PAC sample complexity; distinguishes expected-error vs high-probability bounds. Quick check: Can you state the PAC learnability condition: for all ε,δ, what must hold for sample size m(ε,δ)?

- **Proper vs Improper Learning**: Central distinction; Daniely-Shalev-Shwartz (2014) showed gaps exist for multiclass but not binary. Quick check: If learner A outputs predictors outside H, what makes it improper? When is this unavoidable?

- **Zero-Sum Games and Minimax Theorem**: Proof of Theorem 3.9 models learner vs adversary as finite zero-sum game; existence of optimal mixed strategies relies on minimax. Quick check: In a finite two-player zero-sum game, what does the minimax theorem guarantee about saddle points?

- **Regularization (Classical and Distributional)**: Classical regularization (Definition 2.5) assigns scores to hypotheses; distributional regularization (Definition 3.6) extends to distributions over H, enabling randomized proper learners. Quick check: How does a distributional regularizer differ from a classical regularizer in its domain?

- **EMX Learning and Cardinality**: Section 4 reduction relies on EMX learnability characterization (|F| < ℵ_ω) to show undecidability. Quick check: For what cardinalities of F is EMX learning decidable according to Ben-David et al. (2019)?

## Architecture Onboarding

- **Component map**: Distribution-Fixed Learner Module -> Distributional SRM Engine -> Game Solver -> EMX-to-Proper Reduction

- **Critical path**: 1. Verify learning problem is finite (finite X, Y, H) and loss is bounded metric. 2. If marginal D is known, invoke distributional SRM learner (Theorem 3.9). 3. If D is unknown, fall back to classic PAC; expect at most logarithmic sample overhead (Theorem 3.4). 4. For characterization attempts, check non-monotonicity (Theorem 4.7) and non-locality (Theorem 4.6) obstacles.

- **Design tradeoffs**: Distribution-fixed vs classic PAC: Distribution-fixed simplifies algorithm form (proper, SRM-based) but requires oracle access to D; classic PAC may require improper learners. Randomized vs deterministic proper learners: Randomization enables factor-2 optimality; deterministic proper learners may have larger gaps. Expected-error vs high-probability guarantees: Theorem 3.9 is proven for expected error; extending to PAC is open.

- **Failure signatures**: Infinite domains without topology: Theorem 3.9 proof requires finite games; infinite X/Y may break minimax application. Agnostic setting: All results assume realizable setting; agnostic case behavior is unstudied. Monotone characterizations: Any approach assuming H⊆H' implies learnability inheritance will fail (non-monotonicity, Theorem 4.7). Local characterizations: Approaches based only on finite restrictions H|_S cannot capture proper learnability (non-locality, Theorem 4.6).

- **First 3 experiments**: 1. Reproduce Theorem 3.9 on a finite toy problem: Take X={1,2,3}, Y={0,1,2}, define H with 5-10 hypotheses; implement distributional SRM using KL-regularizer; verify factor-2 optimality vs best improper learner. 2. Empirical sample complexity comparison: For a finite multiclass problem, measure m_H(ε,δ) in classic PAC vs m^DF_H(ε,δ) with known D; confirm logarithmic gap as predicted by Theorem 3.4. 3. Test non-monotonicity construction: Implement H⊂H' from Theorem 4.7 proof (using finite approximation of EMX-based classes); verify H is not properly learnable while H' is, despite H⊂H'.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Does proper learnability imply learnability by a structural risk minimization (SRM) learner in the classic PAC model for multiclass classification?
- **Basis in paper**: Conjecture 3.12: "H is properly learnable if and only if H can be learned by an SRM learner."
- **Why unresolved**: The paper establishes this equivalence in the distribution-fixed model (Theorem 3.9), but the classic PAC model couples learner behavior across all possible marginal distributions, preventing the same game-theoretic argument.
- **What evidence would resolve it**: A proof that any properly learnable class has an optimal SRM learner, or a counterexample class that is properly learnable but not by any SRM.

### Open Question 2
- **Question**: Can Theorem 3.9 be extended to infinite domains X, perhaps via topological arguments?
- **Basis in paper**: "We conjecture that our results hold for more general choices of X and Y, perhaps via topological arguments."
- **Why unresolved**: The current proof relies on finiteness of X and Y to ensure the zero-sum game G is finite and satisfies the minimax theorem. Natural topological structures were explored but none satisfied all required properties simultaneously.
- **What evidence would resolve it**: A proof extending the distributional regularization result to compact or otherwise structured infinite domains, or an impossibility result showing the finite requirement is necessary.

### Open Question 3
- **Question**: Does there exist a hypothesis class H that is learnable if and only if some superset H′ ⊇ H is properly learnable?
- **Basis in paper**: Conjecture 3.13: "H is learnable if and only if there exists an H′ ⊇ H such that H′ is properly learnable."
- **Why unresolved**: Combined with Conjecture 3.12, this would imply all learnable classification problems can be learned by SRM on some hypothesis class.
- **What evidence would resolve it**: A constructive proof showing how to extend any learnable class to a properly learnable one, or a counterexample of a learnable class with no properly learnable superset.

### Open Question 4
- **Question**: Can Theorem 3.9 be established for the high-probability PAC regime rather than only expected error?
- **Basis in paper**: Remark 3.11: "Another interesting question is whether Theorem 3.9 can also be established for the high-probability regime of learning."
- **Why unresolved**: The current game-theoretic proof optimizes expected error; extending to high-probability guarantees requires different analytical techniques.
- **What evidence would resolve it**: A distributional SRM learner with provable (1−δ)-probability guarantees matching optimal PAC sample complexity up to constant factors.

## Limitations

- The core construction relies heavily on finite domain assumptions (finite X, Y, H) and bounded metric loss
- The main existence proofs for distributional regularization are non-constructive, providing no explicit algorithm for general cases
- The undecidability results depend on specific cardinality properties in ZFC, which may not generalize to other axiom systems

## Confidence

- High confidence: Distributional regularization mechanism for finite domains with known D
- Medium confidence: Logarithmic sample complexity gap claim (worst-case analysis)
- Low confidence: Undecidability characterization (depends on specific model-theoretic properties)

## Next Checks

1. **Construct a concrete finite example**: Implement the distributional SRM learner for a small multiclass problem (e.g., X={1,2,3}, Y={0,1,2}, |H|=5-10) and verify factor-2 optimality against baseline improper learners.

2. **Test the non-monotonicity claim**: Build the H⊂H' construction from Theorem 4.7 where H is not properly learnable but H' is, confirming that learnability is not monotone.

3. **Verify sample complexity bounds empirically**: For a synthetic finite learning problem, measure m_H(ε,δ) in classic PAC vs m^DF_H(ε,δ) with known D to confirm the logarithmic gap predicted by Theorem 3.4.