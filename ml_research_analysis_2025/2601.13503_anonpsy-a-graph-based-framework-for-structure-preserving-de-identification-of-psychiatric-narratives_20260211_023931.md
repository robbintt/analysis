---
ver: rpa2
title: 'Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification
  of Psychiatric Narratives'
arxiv_id: '2601.13503'
source_url: https://arxiv.org/abs/2601.13503
tags:
- narrative
- clinical
- anonpsy
- structure
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Anonpsy, a graph-guided framework for de-identifying
  psychiatric case narratives. Unlike token-level masking or unconstrained LLM rewriting,
  Anonpsy converts narratives into a semantic graph with clinical entities, temporal
  anchors, and typed relations, then applies graph-constrained perturbations and graph-conditioned
  text generation.
---

# Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives

## Quick Facts
- arXiv ID: 2601.13503
- Source URL: https://arxiv.org/abs/2601.13503
- Authors: Kyung Ho Lim; Byung-Hoon Kim
- Reference count: 26
- Primary result: Graph-based de-identification preserves psychiatric diagnostic structure while significantly reducing re-identification risk compared to LLM-only rewriting.

## Executive Summary
Anonpsy introduces a novel graph-guided framework for de-identifying psychiatric case narratives. Unlike token-level masking or unconstrained LLM rewriting, Anonpsy converts narratives into a semantic graph with clinical entities, temporal anchors, and typed relations, then applies graph-constrained perturbations and graph-conditioned text generation. Evaluated on 90 clinician-authored psychiatric case histories, Anonpsy preserves diagnostic structure—achieving similar soft-F1 and acceptability scores to original narratives and LLM-only baselines—while significantly reducing re-identification risk. Human expert ratings and GPT-5 evaluations both show Anonpsy narratives are substantially less semantically similar and recallable than LLM-only outputs, yet remain diagnostically usable. Anonpsy thus achieves a better balance of privacy protection and clinical utility for psychiatric narratives.

## Method Summary
Anonpsy processes psychiatric narratives through a three-stage pipeline: (1) Conversion (E) extracts clinical entities, temporal episodes, and typed relations into a schema-constrained semantic graph; (2) Perturbation (P) rewrites identifying contextual elements (demographics, symptom contexts via STEB decomposition, test values) while preserving the graph structure and clinical logic; (3) Generation (D) serializes the perturbed graph into a coherent narrative using chronological ordering with retrograde symptom-context rewriting. The framework is evaluated against LLM-only baselines on diagnosis preservation, semantic similarity, and expert-rated re-identification risk.

## Key Results
- Anonpsy preserves diagnostic structure with similar soft-F1 and acceptability scores to original narratives and LLM-only baselines.
- Human experts rate Anonpsy narratives as significantly less semantically similar and recallable than LLM-only outputs.
- The graph-constrained approach reduces re-identification risk while maintaining clinical utility for psychiatric narratives.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Explicit graph-based intermediate representation enables targeted, structure-preserving de-identification that text-only approaches cannot achieve.
- Mechanism: The framework converts unstructured psychiatric narratives into a semantic graph (G = E(X)) with clinical entities as nodes and typed relations as edges. This decouples clinical structure (temporal ordering, diagnostic dependencies, causal relations) from surface-level narrative content. Perturbations then operate on the graph level, modifying identifying contextual attributes while preserving the relational and temporal backbone by construction.
- Core assumption: Psychiatric meaning is encoded in relational and temporal dependencies (e.g., symptom-to-diagnosis links, treatment trajectories), not just surface tokens.
- Evidence anchors:
  - [abstract] "Anonpsy converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations"
  - [section 3.5] "Perturbation is restricted to attribute- and context-level fields and does not modify the temporal backbone or the typed inter-entity relations"
- Break condition: If psychiatric diagnostic logic cannot be captured by the schema (e.g., narrative identity is inseparable from symptom presentation itself), graph-constrained perturbation will not reduce recallability without clinical distortion.

### Mechanism 2
- Claim: STEB-schema decomposition isolates manipulable narrative context from diagnostically essential symptom structure.
- Mechanism: Each symptom is decomposed into Situation-Thought-Emotion-Behavior (STEB) frames derived from cognitive-behavioral therapy formulations. Only STEB fields present in the original are rewritten; temporal offsets, duration references, and diagnostic associations remain unchanged. This allows replacement of identifying psychosocial details while preserving clinical meaning.
- Core assumption: The cognitive model of psychopathology correctly identifies which narrative components are contextually identifying vs. diagnostically essential.
- Evidence anchors:
  - [section 3.4/B.1.3] "Symptom episodes are decomposed using a modular Situation-Thought-Emotion-Behavior (STEB) schema... which isolates manipulable contextual elements while preserving clinically meaningful structure"
  - [section B.2.2] "Only the STEB fields present in the original node are rewritten; no new fields are introduced"
- Break condition: If identifying information is embedded within symptom phenomenology itself (e.g., rare compulsive rituals), STEB-level rewriting cannot sufficiently dissociate narrative identity.

### Mechanism 3
- Claim: Graph-conditioned generation with retrograde rewriting schedule produces coherent narratives that resist re-identification while maintaining diagnostic fidelity.
- Mechanism: The generation operator D serializes the perturbed graph chronologically, but symptom contexts are perturbed in retrograde order (most recent first). This allows clinically salient presentation events to constrain earlier rewrites, improving coherence. A similarity filter rejects outputs too close to original text.
- Core assumption: Chronological serialization preserves the narrative logic clinicians use for diagnosis.
- Evidence anchors:
  - [section B.2.2] "All symptom contexts are perturbed in a chronologically retrograde order... later, clinically salient events... shape the rewrites of earlier episodes"
- Break condition: If the original narrative has non-linear structure or complex temporal dependencies not captured by day-offset encoding, serialization will distort clinical logic.

## Foundational Learning

- Concept: Schema-constrained LLM extraction
  - Why needed here: The conversion operator E must extract entities and relations that conform to a fixed schema (node types, edge types, temporal format). Unconstrained extraction would produce inconsistent graphs unsuitable for deterministic perturbation.
  - Quick check question: Can you explain why schema constraints are enforced via deterministic validation rather than relying solely on prompt instructions?

- Concept: Temporal representation relative to index encounter
  - Why needed here: All events are anchored to day 0 (the index clinical encounter) with signed integer offsets. This abstraction removes calendar dates (identifiers) while preserving temporal ordering and episode overlap reasoning.
  - Quick check question: How would you represent a symptom that began "several years ago" and is ongoing, without introducing identifying date information?

- Concept: Soft-F1 diagnosis matching with canonicalization
  - Why needed here: Diagnosis preservation is the proxy for clinical structure. DSM-5-TR labels have surface variations (specifiers, synonyms) that require canonicalization before evaluation to avoid penalizing clinically equivalent predictions.
  - Quick check question: Why is soft-F1 with semantic matching used instead of exact string matching for diagnosis evaluation?

## Architecture Onboarding

- Component map: Raw narrative → semantic graph (E, temp=0.1) → perturbed graph (P, temp=0.7) → de-identified narrative (D, temp=0.1)
- Critical path: Conversion (E) extracts entities, temporal episodes, and relations into YAML schema; Perturbation (P) rewrites demographics, symptom contexts, and test values while preserving graph structure; Generation (D) serializes the perturbed graph chronologically into coherent narrative.
- Design tradeoffs:
  - Local LLM deployment required for privacy-sensitive environments (no cloud APIs), but limits model selection.
  - STEB decomposition adds extraction complexity but enables modular perturbation.
  - Retrograde scheduling may improve coherence but assumes temporal linearity in clinical narrative.
- Failure signatures:
  - Rare diagnoses or distinctive symptom profiles may remain recognizable despite perturbation (Section 6, D.4 qualitative analysis).
  - If conversion produces incomplete graphs (missing entities/relations), generation will lack clinical coherence.
  - High similarity filter thresholds may reject valid rewrites, causing retry loops.
- First 3 experiments:
  1. Run conversion operator on 5 diverse psychiatric cases; validate schema compliance and temporal reconciliation by inspecting intermediate YAML outputs.
  2. Ablate STEB decomposition: compare full perturbation vs. demographic-only perturbation on semantic similarity and expert-rated re-identification risk.
  3. Compare forward vs. retrograde symptom-context rewriting schedules on narrative coherence ratings from clinical reviewers.

## Open Questions the Paper Calls Out

- How effectively does Anonpsy maintain privacy and utility when applied to heterogeneous, real-world electronic health records (EHRs) rather than curated educational case reports?
- What specific perturbation strategies are required to mitigate re-identification risk for patients with rare diagnoses or highly distinctive symptom profiles?
- To what extent does the choice of underlying LLM backbone impact the fidelity of the semantic graph extraction and the resulting de-identification quality?

## Limitations
- The framework's performance depends on a 120B parameter LLM (gpt-oss:120b) that is not publicly available, raising reproducibility concerns.
- The semantic graph schema may not capture all psychiatric complexity, potentially leaving residual identifying information in rare or distinctive cases.
- The framework has only been validated on curated educational case reports, not messy real-world clinical documentation.

## Confidence

- **High confidence**: The graph-based intermediate representation is a novel and plausible mechanism for structure-preserving de-identification. The three-operator architecture (E→P→D) is clearly specified and the evaluation design (expert ratings, GPT-5 similarity, soft-F1 diagnosis matching) is methodologically sound for the stated task.

- **Medium confidence**: The comparative advantage over LLM-only baselines is demonstrated, but the absolute performance levels depend on the specific LLM used. The reported improvements in privacy protection may not generalize to smaller or differently trained models.

- **Low confidence**: The claim that Anonpsy achieves optimal balance between privacy and clinical utility is qualified by qualitative analysis noting that distinctive rare diagnoses or symptom profiles remain vulnerable. The framework's robustness to such edge cases is not quantitatively established.

## Next Checks
1. **Ablation of graph vs. text-only**: Implement a controlled ablation comparing Anonpsy (full graph pipeline) against a text-only LLM rewriting baseline using identical LLM and hyperparameters. Measure semantic similarity, re-identification risk, and diagnosis soft-F1 to isolate the contribution of the graph intermediate representation.

2. **Schema coverage stress test**: Systematically evaluate the semantic graph schema on a held-out set of psychiatric narratives containing rare diagnoses, complex trauma histories, or non-standard presentations. Quantify schema coverage gaps and assess whether missing entities/relations lead to clinical incoherence or residual identifiability.

3. **Model substitution impact**: Reproduce the perturbation and generation operators using a smaller, publicly available LLM (e.g., Llama-3.1-70B). Compare outputs on semantic similarity, GPT-5 re-identification risk, and diagnosis soft-F1 to determine sensitivity to model scale and capability.