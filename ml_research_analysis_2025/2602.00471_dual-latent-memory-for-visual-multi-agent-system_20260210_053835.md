---
ver: rpa2
title: Dual Latent Memory for Visual Multi-agent System
arxiv_id: '2602.00471'
source_url: https://arxiv.org/abs/2602.00471
tags:
- memory
- thinking
- visual
- arxiv
- vmas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper identifies a \"scaling wall\" in visual multi-agent\
  \ systems where increasing agent turns leads to performance degradation and exponential\
  \ token growth, attributed to the inefficiency of text-centric inter-agent communication\
  \ that conflates perception and thinking. To address this, the authors propose L\xB2\
  -VMAS, a model-agnostic framework featuring dual latent memories that decouple perception\
  \ and thinking, dynamically synthesized by all previous agents, and an entropy-driven\
  \ proactive triggering mechanism for on-demand memory access."
---

# Dual Latent Memory for Visual Multi-agent System

## Quick Facts
- arXiv ID: 2602.00471
- Source URL: https://arxiv.org/abs/2602.00471
- Reference count: 40
- Dual latent memory framework improves visual multi-agent system accuracy by 2.7-5.4% while reducing token usage by 21.3-44.8%

## Executive Summary
This paper addresses the "scaling wall" problem in visual multi-agent systems where performance degrades and token usage grows exponentially as agent turns increase. The core issue stems from text-centric inter-agent communication that conflates perception and thinking processes. To overcome this limitation, the authors propose L²-VMAS, a model-agnostic framework featuring dual latent memories that decouple perception and thinking, enabling more efficient multi-agent collaboration.

The proposed framework introduces dynamic memory synthesis by all previous agents and an entropy-driven proactive triggering mechanism for on-demand memory access. Extensive experiments across five VLM backbones, four model sizes, and six multi-agent structures demonstrate significant improvements in both accuracy and efficiency, effectively breaking the scaling wall that has constrained visual multi-agent system performance.

## Method Summary
The paper proposes L²-VMAS (Dual Latent Memory for Visual Multi-agent Systems) to address the scaling wall problem in visual multi-agent systems. The framework decouples perception and thinking processes through dual latent memories - a perception memory for visual feature encoding and a thinking memory for reasoning and decision-making. These memories are dynamically synthesized by all previous agents and accessed through an entropy-driven proactive triggering mechanism that activates memory access only when needed. The approach is model-agnostic and can be integrated with various VLM backbones and multi-agent structures, providing both improved accuracy and reduced token consumption compared to traditional text-centric communication approaches.

## Key Results
- Average accuracy improved by 2.7-5.4% across multiple VLM backbones and model sizes
- Token usage reduced by 21.3-44.8%, addressing the exponential growth problem
- Framework successfully breaks the scaling wall, enabling efficient multi-agent collaboration
- Performance validated across five VLM backbones, four model sizes, and six multi-agent structures

## Why This Works (Mechanism)
The dual latent memory architecture works by fundamentally decoupling perception and thinking processes that are traditionally conflated in text-centric inter-agent communication. By separating these functions into distinct memory modules, agents can maintain efficient visual feature encoding in the perception memory while performing complex reasoning in the thinking memory. The entropy-driven proactive triggering mechanism ensures that memory access occurs only when necessary, preventing unnecessary token consumption. Dynamic synthesis of memories by all previous agents creates a shared knowledge base that evolves with the conversation, enabling more informed decision-making without the exponential token growth associated with traditional approaches.

## Foundational Learning

**Visual Multi-agent Systems**: Collaborative systems where multiple agents work together to solve visual tasks through sequential communication. Needed because single agents often lack sufficient capacity for complex visual reasoning tasks. Quick check: Can the system handle multiple rounds of agent communication without performance degradation?

**Scaling Wall**: Performance degradation and exponential token growth that occurs as agent turns increase in traditional visual multi-agent systems. Needed to understand the fundamental limitation being addressed. Quick check: Does token usage grow linearly or exponentially with agent turns in baseline systems?

**Dual Latent Memory Architecture**: Separation of visual feature encoding (perception memory) and reasoning processes (thinking memory) into distinct modules. Needed to decouple traditionally conflated processes and enable more efficient communication. Quick check: Are perception and thinking operations truly independent in the proposed architecture?

**Entropy-driven Triggering**: Mechanism that activates memory access based on information entropy thresholds rather than fixed schedules. Needed to implement on-demand memory access and prevent unnecessary token consumption. Quick check: How does the entropy threshold affect both performance and efficiency?

## Architecture Onboarding

**Component Map**: Visual Input -> Perception Memory -> Thinking Memory -> Communication Module -> Entropy-driven Trigger -> Updated Memory -> Next Agent

**Critical Path**: Visual input flows through perception memory for feature encoding, then to thinking memory for reasoning, followed by communication where the entropy-driven trigger determines if memory access is needed before passing to the next agent.

**Design Tradeoffs**: The dual memory architecture adds complexity but provides significant efficiency gains; the entropy-driven triggering mechanism requires careful threshold tuning but prevents unnecessary computation; model-agnostic design enables flexibility but may not fully optimize for specific VLM architectures.

**Failure Signatures**: Performance degradation when entropy thresholds are set too high (missing needed memory access) or too low (unnecessary memory access); memory synthesis conflicts when multiple agents update simultaneously; perception-thinking decoupling breakdown when visual features are highly context-dependent.

**First Experiments**:
1. Baseline comparison: Test traditional text-centric multi-agent system vs. L²-VMAS with identical VLM backbone and agent structure
2. Token efficiency analysis: Measure token usage growth as agent turns increase in both systems
3. Memory activation analysis: Track entropy-driven trigger activations across different types of visual reasoning tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, though it acknowledges the need for further validation in real-world deployment scenarios and testing with larger agent populations beyond the six-structure limit examined in the current experiments.

## Limitations
- Real-world deployment implications of entropy-driven triggering remain untested in practical scenarios
- Scalability to truly large-scale multi-agent deployments beyond six agents has not been evaluated
- Performance with heterogeneous agent populations of varying capabilities is unexplored
- Integration process and compatibility with existing VLM architectures not fully characterized
- Privacy and security implications of dynamic memory synthesis across multiple agents not addressed

## Confidence

| Claim | Confidence |
|-------|------------|
| Dual memory architecture effectiveness | High |
| Token reduction claims | High |
| Accuracy improvement claims | High |
| Real-world deployment readiness | Medium |
| Scalability to large agent populations | Medium |
| Framework generality | Medium |

## Next Checks

1. Deploy L²-VMAS in a real-world multi-agent application with heterogeneous agents and measure performance under varying environmental conditions and agent loads.

2. Conduct stress testing with agent populations exceeding six agents to evaluate how the entropy-driven triggering mechanism scales with agent count and communication complexity.

3. Perform ablation studies isolating the contribution of the dual memory architecture from other components, specifically testing whether similar improvements can be achieved with alternative memory architectures or different triggering mechanisms.