---
ver: rpa2
title: 'CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating
  Curriculum Learning'
arxiv_id: '2504.16364'
source_url: https://arxiv.org/abs/2504.16364
tags:
- image
- information
- network
- module
- steganography
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving invisibility and
  security in deep learning-based image steganography, which suffers from issues like
  color distortion and poor security when embedding large amounts of information.
  The authors propose CLPSTNet, a Curriculum Learning Progressive Steganography Network
  that integrates multi-scale feature extraction with progressive convolutional modules.
---

# CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning

## Quick Facts
- **arXiv ID:** 2504.16364
- **Source URL:** https://arxiv.org/abs/2504.16364
- **Reference count:** 38
- **Primary result:** Achieves high PSNR/SSIM and low steganalysis scores across ALASKA2, VOC2012, and ImageNet datasets at 1-6 bpp.

## Executive Summary
This paper addresses the challenge of improving invisibility and security in deep learning-based image steganography, which suffers from issues like color distortion and poor security when embedding large amounts of information. The authors propose CLPSTNet, a Curriculum Learning Progressive Steganography Network that integrates multi-scale feature extraction with progressive convolutional modules. The network combines Inception structures and dilated convolutions to extract features from shallow to deep, enhancing multi-scale feature processing. Experimental results on three large datasets (ALASKA2, VOC2012, and ImageNet) show that CLPSTNet achieves high PSNR and SSIM metrics, along with low steganalysis scores. The model also demonstrates high decoding accuracy across different embedding capacities (1-6 bpp), validating its effectiveness in generating high-quality steganographic images with improved security and invisibility.

## Method Summary
CLPSTNet is an Encoder-Decoder-Critic framework that embeds binary secret information into cover images using progressive multi-scale convolutions. The system concatenates cover images and secret tensors, processes them through a U-Net style encoder with Dense connections and Progressive Multi-scale Convolution Blocks (PMCB), and decodes the secret information using a ResNet-based decoder. The PMCB integrates Inception structures with dilated convolutions using progressive dilation rates (3, 6, 12, 18) to expand the receptive field systematically. Training uses adversarial loss against a XuNet-based critic network, with total loss combining encoding (MSE, SSIM, MS-SIM), decoding (BCE), and steganalysis components. The model supports 1-6 bits per pixel embedding capacity and is trained on ALASKA2, VOC2012, and ImageNet datasets.

## Key Results
- Achieves PSNR values above 40dB and SSIM above 0.95 across all tested datasets and capacities
- Maintains decoding accuracy above 98% at 1bpp, though accuracy drops to 64% at 6bpp on ALASKA2
- Demonstrates low steganalysis scores against the critic network, indicating improved security
- Progressive dilation scheme outperforms single-rate schemes in SSIM and PSNR metrics
- Dense connectivity significantly improves performance, with ablation showing PSNR drops from 50.98 to 34.26 at 1bpp when removed

## Why This Works (Mechanism)

### Mechanism 1
Progressive dilation rates in convolution modules improve steganographic image quality by systematically expanding the receptive field from local details to global structures. The PMCB integrates Inception structures with dilated convolutions using a curriculum-style progression (rates of 3, 6, 12, 18) as data flows through the network, forcing shallow layers to focus on fine-grained local features while deeper layers capture larger context. Core assumption: Steganographic embedding benefits from hierarchical processing where low-level embedding errors are resolved before high-level structural consistency. Evidence: PSNR/SSIM metrics show progressive dilation outperforms single-rate schemes.

### Mechanism 2
Dense connectivity within the encoder/decoder mitigates gradient vanishing and preserves shallow secret information during deep feature extraction. The network uses Dense Layers where each layer's output is concatenated to subsequent inputs, allowing gradient flow directly through the network and ensuring shallow secret information features are preserved and refined in later fusion stages. Core assumption: Secret information features are easily lost in deep non-linear transformations and require explicit skip-connections to survive the encoding process. Evidence: Ablation shows removing Dense Blocks significantly drops PSNR (e.g., from 50.98 to 34.26 at 1bpp).

### Mechanism 3
Adversarial training against a steganalysis network conditions the encoder to generate embeddings that lie in "blind spots" of standard detectors. The system trains an Encoder-Decoder pair alongside a Critic network (based on XuNet), with the Encoder minimizing embedding loss while simultaneously maximizing the loss of the Critic. This pushes steganographic artifacts into distributions statistically harder to distinguish from natural image noise. Core assumption: The steganalysis network used in training is a sufficient proxy for real-world detection attacks. Evidence: Generated images have low steganalysis scores against the critic network.

## Foundational Learning

- **Dilated (Atrous) Convolutions**
  - **Why needed here:** The PMCB module relies on dilated convolutions to expand the receptive field without downsampling. You must understand how the "dilation rate" inserts holes between kernel elements to capture wider context.
  - **Quick check question:** If a 3x3 kernel has a dilation rate of 2, what is the effective spatial size of the kernel coverage? (Answer: 5x5).

- **Inception Modules**
  - **Why needed here:** The PMCB is an evolution of the Inception structure. You need to understand parallel pathways (1x1, 3x3, 5x5 convolutions) processing the same feature map simultaneously to capture multi-scale features.
  - **Quick check question:** Why are 1x1 convolutions typically used before expensive 3x3 or 5x5 convolutions in Inception modules? (Answer: Dimensionality reduction/computational efficiency).

- **Curriculum Learning (Model-based)**
  - **Why needed here:** This paper implements curriculum learning not via data ordering, but via *network structure* (progressive dilation). Distinguishing this from standard data-curriculum is vital to understanding the architecture.
  - **Quick check question:** In this paper, does "curriculum learning" refer to showing easy images first or modifying the network's capacity to perceive complexity over depth? (Answer: The latter).

## Architecture Onboarding

- **Component map:** Preparation (Cover + Secret) -> Encoder (Residual Blocks -> Progressive Blocks -> PMCB -> Bottleneck -> Upsampling) -> Decoder (PMCB) -> Critic (XuNet-based)
- **Critical path:** The PMCB Module configuration. The specific sequence of dilation rates is the "secret sauce." Ensure dilation rates strictly follow the progressive schedule (3 -> 6 -> 12 -> 18) rather than constant rates.
- **Design tradeoffs:** Capacity vs. Accuracy - supports 1-6 bpp but decoding accuracy drops significantly as capacity increases (98% at 1bpp -> 64% at 6bpp). Complexity vs. Speed - combination of Dense connections + Multi-branch PMCB + Dilations is computationally heavier than standard U-Net.
- **Failure signatures:** Color Distortion - if training is unstable or capacity is pushed too high (>4bpp), visual metrics drop and color shifts may appear. Low Decoding Accuracy - if dense connections are broken or dilation progression is flattened, decoder fails to recover binary secret (~50% accuracy).
- **First 3 experiments:** 1) Sanity Check (Ablation) - run model on ALASKA2 at 1bpp with standard Conv blocks vs. PMCB to reproduce PSNR lift. 2) Dilation Validation - test fixed dilation (rate=3) vs. Progressive Dilation (3,6,12,18) to verify curriculum hypothesis. 3) Capacity Stress Test - train at 6bpp and verify if model maintains >35dB PSNR and >60% decoding accuracy.

## Open Questions the Paper Calls Out
- Can CLPSTNet framework be extended to support embedding of complex image data rather than solely binary information? The current architecture and preprocessing pipeline are designed specifically for binary tensor inputs.
- How can the model be optimized to prevent significant drop in decoding accuracy when embedding capacity increases to 4-6 bpp? While visual quality is maintained, decoding accuracy drops substantially (98% to 64% on ALASKA2).
- Does integrating Progressive Multi-scale Convolution Block into decoding network improve steganographic payload recovery? The current study focuses on PMCB's effectiveness in encoder, but decoder uses a distinct simpler structure not yet optimized with progressive module.

## Limitations
- Progressive Multi-scale Convolution Block architecture is central but incompletely specified - dense layer growth rate and dropout probability not provided
- Adversarial training stability not thoroughly evaluated - critic network effectiveness against real-world detectors not validated
- Decoding accuracy degrades significantly with increasing embedding capacity, suggesting fundamental limitations in information capacity not addressed

## Confidence
- **High confidence** in architectural novelty of combining progressive dilation with multi-scale feature extraction (ablation studies provide clear evidence)
- **Medium confidence** in claimed invisibility improvements (metrics reported but no qualitative analysis or human perceptual studies)
- **Low confidence** in security claims (steganalysis scores evaluated only against critic network used during training, not independent tools)

## Next Checks
1. **Ablation validation:** Reproduce PSNR comparison between standard convolution blocks and PMCB modules on ALASKA2 at 1bpp to verify claimed performance improvement.
2. **Dilation schedule validation:** Test fixed dilation rates (constant 3) versus progressive dilation (3,6,12,18) to confirm curriculum learning hypothesis and measure impact on feature extraction quality.
3. **Capacity stress test:** Train model at 6bpp and measure whether it maintains >35dB PSNR and >60% decoding accuracy, or if degradation is more severe than reported.