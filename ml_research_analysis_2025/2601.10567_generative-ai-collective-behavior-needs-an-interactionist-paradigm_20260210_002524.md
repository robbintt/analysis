---
ver: rpa2
title: Generative AI collective behavior needs an interactionist paradigm
arxiv_id: '2601.10567'
source_url: https://arxiv.org/abs/2601.10567
tags:
- learning
- agents
- social
- behavior
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that understanding the collective behavior of
  generative AI agents is essential for addressing societal risks and benefits, but
  current theoretical tools are inadequate. Unlike traditional multi-agent reinforcement
  learning agents, generative AI agents are initialized with extensive pre-trained
  knowledge and can adapt through in-context learning, necessitating an interactionist
  paradigm.
---

# Generative AI collective behavior needs an interactionist paradigm

## Quick Facts
- arXiv ID: 2601.10567
- Source URL: https://arxiv.org/abs/2601.10567
- Reference count: 25
- One-line primary result: Proposes an interactionist paradigm to study emergent collective behavior in multi-agent generative AI systems, emphasizing the need to isolate "person" vs "situation" effects.

## Executive Summary
The paper argues that understanding collective behavior in generative AI agents requires new theoretical tools beyond traditional multi-agent reinforcement learning frameworks. Unlike MARL agents, generative AI agents are initialized with extensive pre-trained knowledge and adapt through in-context learning rather than gradient updates. The authors propose an interactionist paradigm that integrates theories of AI agency, causal inference, and information theory to study how pre-trained knowledge interacts with social context to produce emergent phenomena. They outline four key research directions: interactionist benchmarks, causal identification strategies, information-theoretic measures, and empirical sociology of machine societies.

## Method Summary
This is a theoretical framework paper that proposes an "interactionist paradigm" for studying collective behavior in LLM-based multi-agent systems. The authors mathematically formulate an interactive learning system where n models exchange information through learning and information exchange functions. They contrast generative AI agents with MARL agents, noting that Gen-AI uses fixed weights with in-context adaptation versus MARL's continuous gradient updates. The paper references existing multi-agent benchmarks and proposes four research directions without providing specific experimental implementations.

## Key Results
- Generative AI agents differ fundamentally from MARL agents through pre-training and in-context learning rather than gradient-based adaptation
- Current theoretical tools are inadequate for understanding emergent collective behaviors in multi-agent generative AI systems
- An interactionist paradigm is needed that integrates AI agency theories with social context and information-theoretic approaches

## Why This Works (Mechanism)
The framework works by recognizing that generative AI agents carry persistent behavioral priors from pre-training that interact with social contexts during deployment. Unlike traditional agents that learn solely through reward signals, these agents bring pre-existing "personalities" that shape collective outcomes. The interactionist paradigm captures this by studying how fixed pre-trained knowledge combines with dynamic social interactions to produce emergent phenomena, rather than treating agents as blank slates that only learn through interaction.

## Foundational Learning
- **Multi-agent reinforcement learning (MARL)**: Traditional framework where agents learn through gradient updates based on rewards. Why needed: Provides baseline contrast to show how generative AI agents differ fundamentally.
- **In-context learning (ICL)**: Ability of models to adapt behavior based on prompt context without weight updates. Why needed: Explains how generative AI agents can change behavior without traditional learning.
- **Causal inference with interference**: Statistical methods for identifying causal effects when agents influence each other's outcomes. Why needed: Standard causal assumptions break down in networked multi-agent systems.
- **Information-theoretic measures**: Metrics like mutual information, entropy, and transfer entropy for quantifying information flow. Why needed: Provide quantitative tools to measure collective behavior emergence.
- **Person-situation interaction theory**: Psychological framework distinguishing stable traits ("person") from contextual influences ("situation"). Why needed: Provides conceptual foundation for isolating sources of emergent behavior.
- **Agent-to-agent influence**: Network dynamics where one agent's actions affect others' outcomes. Why needed: Central mechanism for understanding collective behavior emergence.

## Architecture Onboarding
- **Component map**: Pre-training -> In-context learning (ICL) -> Interactive ICL -> Collective behavior emergence
- **Critical path**: Pre-trained knowledge (priors) → Social interaction context → Emergent collective outcomes
- **Design tradeoffs**: Fixed pre-trained weights provide stability but limit adaptation; in-context learning enables flexibility but may be transient
- **Failure signatures**: Confounding of person/situation effects, invalid causal assumptions due to interference, inability to distinguish pre-trained from emergent behaviors
- **Three first experiments**: 1) Compare isolated vs. multi-agent behavior to identify emergent phenomena, 2) Vary interaction history while holding model fixed to test context effects, 3) Apply interference-aware causal inference to simple agent networks

## Open Questions the Paper Calls Out
- Can collective behaviors arising through continual interaction permanently reshape pre-trained agent personas without modifying model weights? This questions whether in-context learning can create lasting behavioral changes that persist beyond specific interaction contexts.
- How can causal attribution be accurately performed in multi-agent Gen-AI systems when network interference invalidates standard causal assumptions? This challenges researchers to develop new causal inference methods that account for agent-to-agent influence.
- How can evaluation protocols quantitatively isolate the specific contribution of pre-trained priors ("person") from the contribution of prompt context ("situation") in emergent collective behaviors? This calls for new benchmarks that can disentangle the sources of collective outcomes.

## Limitations
- The framework remains largely theoretical without concrete implementation details or experimental validation
- Key operationalization challenges like isolating "person" vs "situation" effects are acknowledged but not solved
- The four proposed research directions are aspirational rather than actionable with current methods

## Confidence
- High confidence: The distinction between generative AI agents and traditional MARL agents is well-founded and important
- Medium confidence: The proposed interactionist paradigm as a conceptual framework for studying collective behavior
- Low confidence: Specific quantitative predictions about how different factors will interact to produce emergent phenomena

## Next Checks
1. Implement a minimal proof-of-concept experiment using existing LLM frameworks with controlled variation of base models and interaction histories to test whether pre-trained priors persist and interact with social context.
2. Apply interference-aware causal inference methods to a simple multi-agent LLM system to demonstrate whether standard causal assumptions fail under agent-to-agent influence.
3. Develop preliminary information-theoretic measures for agent interactions in a controlled setting to establish baseline quantification of collective behavior emergence.