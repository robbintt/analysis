---
ver: rpa2
title: 'Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust
  and Efficient Edge-Native Weather Forecasting'
arxiv_id: '2602.00240'
source_url: https://arxiv.org/abs/2602.00240
tags:
- weather
- learning
- forecasting
- search
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Green-NAS addresses the challenge of deploying accurate, efficient
  weather forecasting models on low-resource edge devices in the Global South. The
  core method uses multi-objective neural architecture search (NAS) via NSGA-II to
  automatically discover architectures that optimize both forecasting accuracy and
  computational efficiency, guided by Green AI principles.
---

# Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust and Efficient Edge-Native Weather Forecasting

## Quick Facts
- **arXiv ID:** 2602.00240
- **Source URL:** https://arxiv.org/abs/2602.00240
- **Reference count:** 32
- **Primary result:** Discovers ultra-efficient weather forecasting models (153K parameters, RMSE 0.0988) deployable on edge devices via multi-objective neural architecture search

## Executive Summary
Green-NAS addresses the challenge of deploying accurate, efficient weather forecasting models on low-resource edge devices in the Global South. The core method uses multi-objective neural architecture search (NAS) via NSGA-II to automatically discover architectures that optimize both forecasting accuracy and computational efficiency, guided by Green AI principles. Key results include: a high-accuracy model (Green-NAS-A) achieving RMSE of 0.0988 using only 153k parameters (239× fewer than GraphCast), an ultra-compact model (Green-NAS-C) with 1,064 parameters and RMSE 0.1019 suitable for microcontrollers, and demonstrated transfer learning improving accuracy by 5.2% even with limited data. All models achieve sub-millisecond latency and near-target 95% coverage confidence intervals, making them deployable on resource-constrained edge devices while maintaining competitive accuracy.

## Method Summary
Green-NAS uses multi-objective evolutionary search to discover weather forecasting architectures optimized for both accuracy and efficiency. The method employs NSGA-II to evolve a population of candidate architectures encoded as fixed-length genomes (layer types, units, dropout) over 10 generations with population size 20. The search space includes RNN/CNN/Attention/MLP components with 1-4 layers and 32-256 units per layer. Models are evaluated on 24-hour sliding windows from Open-Meteo weather data across 24 cities spanning tropical to continental climates. Transfer learning pre-trains on 18 data-rich source cities before fine-tuning on target cities, and Split Conformal Prediction provides uncertainty estimates with 95% coverage guarantees. Final architectures range from 153K parameters (Green-NAS-A) to 1,064 parameters (Green-NAS-C) while maintaining competitive RMSE performance.

## Key Results
- Green-NAS-A: RMSE 0.0988, 153K parameters (239× fewer than GraphCast), 0.52ms latency
- Green-NAS-C: RMSE 0.1019, 1,064 parameters suitable for microcontrollers, 0.33ms latency
- Transfer learning improves accuracy by 5.2% (p < 10^-12) even with full target city data
- All models achieve 93.9-96.3% coverage intervals targeting 95% with narrow widths (0.067-0.096)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-objective evolutionary search can discover architectures that simultaneously optimize forecasting accuracy and parameter efficiency.
- Mechanism: NSGA-II maintains a population of candidate architectures encoded as fixed-length genomes (layer types, units, dropout). Each generation applies non-dominated sorting to identify Pareto-optimal solutions—architectures where no single objective can improve without degrading another. Over 10 generations with population 20, the search explores trade-offs between validation RMSE, parameter count, and interpretability (proxied by inverse depth).
- Core assumption: The search space (RNN/CNN/Attention/MLP components, 1-4 layers, 32-256 units) contains architectures suitable for hourly weather prediction with 24-hour lookback windows.
- Evidence anchors:
  - [abstract] "The Green-NAS architecture search method is optimized for both model accuracy and efficiency to find lightweight models with high accuracy and very few model parameters"
  - [section III.C] "We employ the Non-dominated Sorting Genetic Algorithm II (NSGA-II) to optimize three conflicting objectives simultaneously... The genome is represented as a fixed-length vector encoding the layer types and hyperparameters. We use a population size of 20 and run the evolution for 10 generations."
  - [corpus] Related work (arXiv:2501.12215) demonstrates multi-objective NAS for time series via Pareto optimality, supporting the approach but noting it remains an active research area with limited prior application to weather forecasting.
- Break condition: If the search space excludes suitable inductive biases for temporal dynamics, or if evaluation data doesn't represent deployment conditions, NSGA-II will optimize toward spurious optima.

### Mechanism 2
- Claim: Pre-training on data-rich source cities transfers meteorological knowledge to data-sparse target cities, improving accuracy even when full local data is available.
- Mechanism: Models learn shared atmospheric physics (pressure-temperature relationships, diurnal cycles) from 18 source cities spanning tropical to continental climates. During fine-tuning on target cities, learned representations adapt to local patterns while retaining generalizable features. Min-Max scaling per city normalizes inputs to [0,1] to facilitate cross-city transfer.
- Core assumption: Weather dynamics share common physical principles across geographic regions despite local variations in manifestation.
- Evidence anchors:
  - [abstract] "the use of transfer learning will improve the weather forecasting accuracy by approximately 5.2%, in comparison to a naive approach of training a new model for each city"
  - [section V.C] "Even with 100% of the data, there is a statistically significant increase in accuracy of +5.2% (p < 10^-12) for pre-training, which shows that pre-training successfully transfers global weather knowledge into the target cities."
  - [corpus] Transfer learning for time-series faces documented challenges (arXiv:1901.02352 proxy via [25-27] citations) due to temporal characteristic differences; success here appears domain-specific to weather's shared physics.
- Break condition: If target cities exhibit fundamentally different atmospheric dynamics (e.g., polar vortex behavior not represented in source data), transferred knowledge may bias predictions.

### Mechanism 3
- Claim: Split Conformal Prediction produces well-calibrated uncertainty estimates for edge-deployed weather models without distributional assumptions.
- Mechanism: A calibration set (20% of target city test data, ~63,000 samples) computes nonconformity scores as prediction residuals. The (1-α) quantile of these scores defines interval width [ŷ-q, ŷ+q], guaranteeing coverage under exchangeability assumptions.
- Core assumption: Calibration and test samples are exchangeable (drawn from the same distribution).
- Evidence anchors:
  - [section III.D] "This technique generates rigorous confidence intervals [ŷ-q, ŷ+q] such that the true value y falls within the interval with probability 1-α (set to 95%)."
  - [section V.E] "Green-NAS-A: 93.9% coverage (target: 95%), interval width 0.067... All of the models have nearly reached the target coverage with very narrow intervals"
  - [corpus] Limited direct corpus evidence for conformal prediction in weather NAS; technique is well-established (Shafer & Vovk, JMLR 2008) but application to NAS-discovered models is novel.
- Break condition: If weather patterns shift (climate change, extreme events) violating exchangeability, coverage guarantees degrade. Interval width may become impractically large for highly uncertain regimes.

## Foundational Learning

- Concept: **Pareto Optimality and Multi-Objective Optimization**
  - Why needed here: NSGA-II outputs a Pareto front—no single "best" model exists, only trade-offs. Engineers must select based on deployment constraints.
  - Quick check question: Given two models where A has lower RMSE but 10× more parameters than B, which is Pareto-optimal if no third model dominates both?

- Concept: **Exchangeability for Conformal Prediction**
  - Why needed here: The 95% coverage guarantee assumes calibration and deployment data are exchangeable. Seasonal shifts or climate trends violate this.
  - Quick check question: If you calibrate on January-March data but deploy in July-August, is exchangeability maintained? What happens to coverage?

- Concept: **Temporal Inductive Biases (RNN vs CNN vs Attention)**
  - Why needed here: The NAS search discovered that pure recurrent models (GRU) outperformed attention mechanisms for 24-hour lookback. Understanding why guides search space design.
  - Quick check question: For a 24-step lookback predicting 1 step ahead, why might local convolution windows capture insufficient context compared to recurrent state?

## Architecture Onboarding

- Component map:
  Search Space Definition -> NSGA-II Engine -> Evaluation Pipeline -> Transfer Learning Protocol -> Uncertainty Layer

- Critical path:
  1. Define search space constraints (the paper's space favors temporal models; attention underperformed)
  2. Run NSGA-II (114 evaluations, ~2-4 hours on RTX 3060 Ti per the paper's setup)
  3. Extract Pareto front (20 architectures); select based on deployment constraints
  4. Apply transfer learning if target city has limited data
  5. Calibrate conformal prediction intervals before deployment

- Design tradeoffs:
  - **Green-NAS-A (153K params)**: Highest accuracy, fits embedded GPUs, 0.52ms latency
  - **Green-NAS-B (4.2K params)**: Balanced, interpretable single-layer CNN, 0.30ms latency
  - **Green-NAS-C (1K params)**: Ultra-compact for microcontrollers, slight accuracy drop (RMSE +0.003), 0.33ms latency
  - Assumption: The paper's finding that attention underperforms may be specific to 24-hour windows; longer contexts may require different conclusions.

- Failure signatures:
  - Coverage drops below 90%: Exchangeability violated; recalibrate with recent data
  - RMSE degrades on target city despite transfer: Source cities may not span relevant climate dynamics
  - Sub-millisecond latency not achieved: Check for framework overhead (PyTorch vs ONNX/TFLite export)
  - Pareto front contains only high-parameter models: Search space may lack efficient architectures; add depth/unit constraints

- First 3 experiments:
  1. **Reproduce Pareto front on subset**: Run NSGA-II with population 10, 5 generations on 3 source cities to validate search mechanism produces expected accuracy-efficiency trade-off curve.
  2. **Transfer learning ablation**: Train Green-NAS-A from scratch vs. pre-trained on single source city vs. all 18 source cities. Measure RMSE gap at 1%, 10%, 50% target city data.
  3. **Coverage calibration stress test**: Split target city data by season; calibrate on Q1-Q2, evaluate coverage on Q3-Q4 to quantify exchangeability violation magnitude.

## Open Questions the Paper Calls Out

- **Can direct multi-step sequence-to-sequence models mitigate the error accumulation observed in recursive multi-step forecasting?**
  - The authors report that preliminary tests of recursive forecasting showed significant performance degradation (RMSE increasing from 0.03 to 0.16) due to error accumulation, and propose exploring direct multi-step models for 24–48h horizons in future work.

- **Does incorporating satellite image fusion for spatial convolutions improve performance over the current point-based station limitations?**
  - The authors identify the limitation to "point based stations" and explicitly list "incorporating satellite image fusion to allow for spatial convolutions" as a future research direction.

- **How does the Pareto front of discovered architectures shift when explicitly optimizing for energy usage and carbon emissions rather than parameter count?**
  - The paper notes that current optimization uses parameter count as a proxy, but future work could "extend... to include factors other than performance... such as energy usage and carbon emissions."

## Limitations
- Attention mechanisms underperformed in 24-hour window experiments, but this may not generalize to longer forecasting horizons
- Transfer learning benefits appear weather-physics specific and may not transfer to other time-series domains
- Conformal prediction coverage guarantees depend on exchangeability assumptions that seasonal shifts or climate change could violate

## Confidence
- **High Confidence:** The core claim that Green-NAS discovers Pareto-optimal architectures balancing accuracy and efficiency is well-supported by direct evidence (RMSE 0.0988, 153K params vs GraphCast's 36.5M). The transfer learning improvement (+5.2% accuracy) is statistically significant with p < 10^-12.
- **Medium Confidence:** The finding that attention mechanisms underperform recurrent/CNN architectures is likely specific to the 24-hour window used; this may not generalize to longer forecasting horizons.
- **Low Confidence:** The claim that ultra-compact models (1,064 params) maintain competitive accuracy for edge deployment is promising but only validated on a limited set of target cities. Real-world edge deployment may face additional constraints (power, memory fragmentation, framework overhead) not captured in the study.

## Next Checks
1. **Seasonal Coverage Validation:** Split each target city's test data by season; calibrate conformal prediction on Q1-Q2 data and evaluate coverage on Q3-Q4 to quantify exchangeability violation magnitude under seasonal shifts.
2. **Cross-Domain Transfer Learning:** Apply the pre-trained Green-NAS architecture to a non-weather time-series task (e.g., traffic flow or energy consumption) to test whether the transfer learning benefits are weather-physics specific or represent broader temporal modeling improvements.
3. **Architecture Generalization Test:** Modify the search space to include deeper networks (5-8 layers) and larger attention heads; re-run NSGA-II to determine if the original findings about attention underperformance hold for extended temporal contexts.