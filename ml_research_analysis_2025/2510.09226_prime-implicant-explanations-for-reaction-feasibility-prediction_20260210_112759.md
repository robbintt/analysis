---
ver: rpa2
title: Prime Implicant Explanations for Reaction Feasibility Prediction
arxiv_id: '2510.09226'
source_url: https://arxiv.org/abs/2510.09226
tags:
- reaction
- explanations
- graph
- explanation
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PI reaction explanations, a novel formal
  notion of explanations for reaction feasibility prediction tasks. The authors adapt
  prime implicant explanations to graph classification, specifically tailoring them
  to reaction feasibility prediction using Imaginary Transition State (ITS) graphs.
---

# Prime Implicant Explanations for Reaction Feasibility Prediction

## Quick Facts
- arXiv ID: 2510.09226
- Source URL: https://arxiv.org/abs/2510.09226
- Reference count: 40
- Primary result: Introduces PI reaction explanations for graph classification, achieving 16% expert-rated "good" explanations at threshold 0.2

## Executive Summary
This paper introduces PI reaction explanations, a novel formal notion of explanations for reaction feasibility prediction tasks. The authors adapt prime implicant explanations to graph classification, specifically tailoring them to reaction feasibility prediction using Imaginary Transition State (ITS) graphs. Their algorithm computes these explanations by constructing an extension DAG of rooted connected subgraphs and pruning based on classifier predictions. Experimental results using a Graph Isomorphism Network on a small USPTO-derived dataset show that while PI reaction explanations capture ground truth explanations as subgraphs, they often include redundant nodes and edges.

## Method Summary
The method constructs PI reaction explanations by building an extension DAG of all rooted, connected subgraphs of an ITS graph, then pruning branches that receive negative predictions from a GIN classifier. The remaining sink nodes are returned as explanations. The approach exploits chemical domain constraints - specifically that all relevant structures are connected to the reaction center - to restrict the search to connected subgraphs rooted at the reaction center. This transforms the general subgraph enumeration problem into a more tractable rooted, connected subgraph enumeration problem.

## Key Results
- PI reaction explanations capture ground truth explanations as subgraphs but include redundant nodes and edges
- Best explanation quality (16% rated good, 1-2 on 1-6 scale) achieved at positive prediction threshold of 0.2
- Computational complexity is exponential in graph size, limiting application to small graphs (<25 nodes)
- Conservative explanations are supergraphs of ground truth due to classifier limitations

## Why This Works (Mechanism)

### Mechanism 1: Extension DAG Pruning for Minimally Sufficient Subgraph Identification
The algorithm constructs a directed acyclic graph where nodes are all rooted, connected subgraphs of an ITS graph, and edges represent subgraph-supergraph relationships. A top-down traversal classifies each node; if a node receives a negative classification, it and all its descendants are pruned. The remaining sink nodes are the PI reaction explanations, as they are the smallest subgraphs that maintain the original positive prediction.

### Mechanism 2: Chemical Domain Constraints Reducing Search Space
Two key constraints reduce the search space: (1) all relevant structures in an ITS graph are connected to the reaction center, allowing search restriction to only connected subgraphs, and (2) the reaction center itself is essential for any valid explanation, allowing subgraphs to be rooted at this central subgraph.

### Mechanism 3: Conservative Explanations as Supergraphs of Ground Truth
Due to classifier imperfections and non-monotonicity, the algorithm may fail to prune large supergraphs because the classifier assigns them a positive label. Thus, the found PI explanation is the smallest subgraph the classifier deems sufficient, not the smallest subgraph that is chemically sufficient.

## Foundational Learning

**Concept: Prime Implicant (PI) Explanation**
- Why needed: This is the central, formally defined object the paper seeks to compute - a minimal set of features (a subgraph) that is sufficient for a classifier's prediction
- Quick check: Given a simple Boolean function `f(A, B, C) = A AND (B OR C)`, what are the prime implicants? (Answer: `A AND B` is one, `A AND C` is another)

**Concept: Imaginary Transition State (ITS) Graph**
- Why needed: This is the specific data representation for chemical reactions used in the paper - the graph from which subgraphs are extracted
- Quick check: In an ITS graph, what does an edge labeled `(1, 2)` signify? (Answer: A bond whose order increases from 1 to 2 during the reaction)

**Concept: Non-Monotonic Property of a Graph**
- Why needed: A critical theoretical property - the paper proves reaction feasibility is not monotonic, justifying exhaustive search
- Quick check: Is the property "planarity" monotonic? (Answer: Yes, if a graph is planar, all its subgraphs are planar)

## Architecture Onboarding

**Component Map:** Data Pre-processor -> Graph Classifier (GIN) -> Extension DAG Builder -> PI Explanation Engine

**Critical Path:** The Extension DAG Builder is the bottleneck. Its output, the DAG, must be constructed before any explanation can be found. The size of the DAG is exponential in the number of edges of the input graph.

**Design Tradeoffs:**
- Exhaustive search ensures theoretical correctness but sacrifices scalability
- Rooting at reaction center is critical for tractability but assumes all relevant context is near the reaction center
- Edge-induced subgraphs (via line graphs) better capture chemical intuition (valence bonds)

**Failure Signatures:**
- Time Limit Exceeded: Algorithm fails to complete if ITS graph has too many nodes (>25) or high average degree
- Output is the Entire Graph: Implies classifier predicted negative for almost all proper subgraphs
- Output is the Root Only: Suggests classifier is overly biased towards positive predictions

**First 3 Experiments:**
1. Complexity Characterization: Run pipeline on reactions with increasing graph size (10-20 nodes) and measure runtime and DAG size
2. Explanation Quality vs. Threshold: Vary classification threshold (0.1-0.5) and evaluate resulting explanations against expert ratings
3. Ablation on Rooting: Modify algorithm to enumerate all connected subgraphs (not just rooted ones) and compare runtime

## Open Questions the Paper Calls Out

**Open Question 1:** Can exhaustive enumeration be replaced by a sampling-based approach to make PI explanations tractable for larger graphs? (Page 14)

**Open Question 2:** To what extent are observed redundancies in PI explanations caused by generation of chemically infeasible "truly negative" extensions? (Page 13)

**Open Question 3:** Does misalignment between PI explanations and expert-rated ground truth stem primarily from classifier limitations or ambiguity of the feasibility domain? (Page 13)

## Limitations

- Computational intractability limits approach to small graphs (<25 nodes)
- Conservative explanations include redundant atoms/bonds, providing limited mechanistic insight
- Lack of established benchmarks and reliance on expert ratings for evaluation

## Confidence

- **High Confidence:** Formal definition of PI reaction explanations and non-monotonicity proof
- **Medium Confidence:** Effectiveness of 0.2 prediction threshold for explanation quality
- **Low Confidence:** Generalizability beyond Oâ†’N substitution reaction type

## Next Checks

1. **Scalability Validation:** Systematically test algorithm on datasets with varying graph sizes (10-25 nodes) to confirm exponential complexity relationship

2. **Threshold Sensitivity Analysis:** Evaluate explanation quality across broader range of prediction thresholds (0.05-0.5) to determine optimal threshold

3. **Alternative Graph Representation Study:** Apply PI explanation framework to different reaction representation to test whether rooting constraint artificially limits explanation quality