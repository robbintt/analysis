---
ver: rpa2
title: 'FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts'
arxiv_id: '2511.00480'
source_url: https://arxiv.org/abs/2511.00480
tags:
- prompt
- fedmgp
- learning
- groups
- aggregation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FedMGP addresses federated prompt learning challenges by equipping
  each client with multiple paired text-visual prompt groups, enabling diverse semantic
  and instance-level cue capture. It introduces a diversity loss to ensure prompt
  groups specialize in distinct semantic aspects, and employs a dynamic prompt aggregation
  strategy based on similarity-guided probabilistic sampling.
---

# FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts

## Quick Facts
- arXiv ID: 2511.00480
- Source URL: https://arxiv.org/abs/2511.00480
- Reference count: 40
- Key outcome: Achieves SOTA federated prompt learning with lowest communication parameters (5.1k) and 81.85% combined metric across 9 datasets

## Executive Summary
FedMGP addresses federated prompt learning challenges by equipping each client with multiple paired text-visual prompt groups, enabling diverse semantic and instance-level cue capture. It introduces a diversity loss to ensure prompt groups specialize in distinct semantic aspects, and employs a dynamic prompt aggregation strategy based on similarity-guided probabilistic sampling. This approach achieves state-of-the-art performance with the lowest communication parameters (5.1k) among federated prompt learning methods. Extensive experiments across heterogeneous data settings demonstrate superior balance between personalization and generalization.

## Method Summary
FedMGP is a personalized federated learning method for vision-language models that uses multiple paired text-visual prompt groups per client. Each client maintains G=5 text and visual prompt groups, with text prompts initialized from "a photo of a" template and visual prompts randomly initialized. The method combines classification error (LCE) with a diversity loss (Ldiv) to encourage prompt specialization, and uses similarity-guided probabilistic sampling for dynamic aggregation. During training, clients compute predictions across all prompt groups, calculate LCE and Ldiv, then update prompts via SGD. For aggregation, clients compute similarity scores between local and global prompts, convert to probabilities via softmax, and sample top-s groups for weighted aggregation.

## Key Results
- Achieves 81.85% combined metric averaged over nine datasets
- Uses only 5.1k communication parameters, the lowest among federated prompt learning methods
- Maintains strong performance across heterogeneous data distributions and extreme label shift scenarios

## Why This Works (Mechanism)

### Mechanism 1: Multi-Group Text-Visual Prompt Co-Learning
Multiple paired text-visual prompt groups capture complementary semantic patterns that single text-only prompts miss. Each client maintains G prompt groups (pt,j, pv,j). Text prompts concatenate with class embeddings (tk,j = {pt,j, ck}); visual prompts combine with images (vj = {x, pv,j}). Predictions from all groups are averaged at inference (Eq. 6). Core assumption: Local data contains diverse semantic concepts that cannot be captured by a single prompt representation. Break condition: When data is extremely scarce (1-2 shots), groups cannot specialize meaningfully, leading to unstable training.

### Mechanism 2: Diversity Loss for Prompt Specialization
Explicitly penalizing similarity between prompt groups forces them to learn non-redundant representations. Ldiv = Σ(cosine distance between features from different groups within same modality). Combined with LCE as L = LCE + λ·Ldiv (Eq. 5). L1-based formulation outperforms cosine and L2 variants (Table 16). Core assumption: Without explicit regularization, gradient descent converges prompt groups to similar solutions. Break condition: If λ is too high, groups may become too specialized to share useful knowledge during aggregation.

### Mechanism 3: Similarity-Guided Dynamic Aggregation
Selecting prompts based on similarity to previous global prompts filters client-specific noise while preserving transferable knowledge. Compute sim(Pj, P̃T-1) between local groups and global prompts. Convert to probabilities via softmax with temperature τ. Sample top-s groups per client, aggregate via weighted average (Eq. 7-9). Core assumption: Prompts can be decomposed into global (shared), local (client-specific), and noise components; high similarity to global indicates high global-signal-to-noise ratio. Break condition: First round (T=1) requires random selection since no prior global prompts exist; extreme heterogeneity may cause low inter-client similarity scores.

## Foundational Learning

- **Vision-Language Models (VLMs) and CLIP architecture**
  - Why needed here: FedMGP freezes VLM weights and only learns prompts; understanding image encoder f(·) and text encoder g(·) is essential.
  - Quick check question: Can you explain why cosine similarity between image and text features yields class predictions?

- **Federated averaging and non-IID data challenges**
  - Why needed here: The paper's dynamic aggregation modifies FedAvg; understanding why FedAvg struggles under heterogeneity motivates the design.
  - Quick check question: What happens to global model quality when client data distributions diverge significantly?

- **Prompt tuning vs. full fine-tuning**
  - Why needed here: Parameter efficiency (5.1k communication params) is a core claim; prompts are the only learned parameters.
  - Quick check question: How many learnable parameters exist in FedMGP vs. fine-tuning the full ViT-B/16 backbone?

## Architecture Onboarding

- **Component map**: Server -> Global prompts P̃T; Client -> Local multi-group prompts (G text + G visual groups); Frozen VLM -> ViT-B/16 backbone

- **Critical path**: 
  1. Initialize prompts (text: "a photo of a" template, visual: random)
  2. Local training: For each batch, compute predictions per group, aggregate LCE + λ·Ldiv, SGD update
  3. Selection: Compute sim(local, global_prev), softmax, sample top-s groups per client
  4. Aggregation: Weighted average of selected groups across clients
  5. Distribution: Update client prompts with aggregated versions

- **Design tradeoffs**:
  - Prompt length (l): l=2 optimal; longer prompts overfit to local details (Table 4)
  - Number of groups (G): G=5 optimal; fewer groups reduce specialization (Table 5)
  - Selection size (s): s=2 balances personalization/generalization; s=1 preserves specificity, s=4 improves generalization but hurts local accuracy (Table 6)
  - Temperature (τ): τ=1.0 optimal; lower is too deterministic, higher adds too much randomness (Table 14)

- **Failure signatures**:
  - 1-shot scenarios: CM drops below baselines—multi-group decomposition fails without sufficient data
  - All groups converging to similar representations: Check diversity loss weight λ; visualize inter-group similarity
  - No groups selected from certain clients: Check temperature τ; may be too low, causing near-deterministic selection
  - Communication params exceed 5.1k: Verify prompt length l=2 and G=5 per modality

- **First 3 experiments**:
  1. **Sanity check**: Single client, single group (G=1, s=1) should match standard prompt tuning baseline
  2. **Ablation sweep**: Vary G∈{1,2,3,4,5} and s∈{1,2,3,4} on Caltech101 with 16-shot; confirm G=5, s=2 reproduces paper's CM≈97%
  3. **Heterogeneity stress test**: Dirichlet α=0.1, 0.3, 0.5, 1.0 on CIFAR-10 with 100 clients; verify dynamic aggregation outperforms FedAvg-style full aggregation as α decreases

## Open Questions the Paper Calls Out

### Open Question 1
Can an adaptive mechanism be developed to dynamically adjust the number of prompt groups ($G$) based on local data volume to mitigate overfitting in data-scarce clients? Basis in paper: Appendix B suggests developing "adaptive mechanisms to dynamically adjust the number of prompt groups based on available data" to address limitations in extreme low-shot scenarios. Why unresolved: The current implementation uses a static number of groups ($G=5$) for all clients, which causes instability when samples are insufficient to populate the semantic space. What evidence would resolve it: An ablation study comparing static $G$ versus a data-volume-adaptive $G$ strategy in 1-2 shot settings, showing recovered stability and accuracy.

### Open Question 2
How can category-specific linguistic information be integrated into the prompt groups to further enhance diverse representations? Basis in paper: The Conclusion states a future direction is to "integrate category-specific linguistic information to further enhance diverse representations across prompt groups." Why unresolved: The current text prompts are general; leveraging explicit category semantics might improve the separation enforced by the diversity loss. What evidence would resolve it: Experiments comparing standard class embeddings against explicit category-specific linguistic guidance, measuring improvements in the Diversity Loss convergence and final accuracy.

### Open Question 3
Can meta-learning initialization strategies stabilize the multi-group mechanism in 1-shot scenarios where current random initialization fails to disentangle semantic aspects? Basis in paper: Appendix B identifies the "1-shot" failure mode (due to inability to disentangle knowledge) and lists "incorporating meta-learning techniques" as a future direction to improve learning efficiency. Why unresolved: With only one sample, gradient-based optimization of multiple diverse groups is unstable without a strong prior or initialization. What evidence would resolve it: A comparison of standard SGD versus meta-learned initialization (e.g., MAML-based) on 1-shot tasks, demonstrating convergence where the current baseline diverges.

## Limitations

- Visual prompt initialization strategy remains unspecified, creating a potential reproduction gap since text prompts are explicitly initialized while visual prompts are not described.
- The extreme low-data regime (1-2 shots) shows FedMGP's multi-group decomposition fails, revealing a fundamental limitation when training data scarcity prevents prompt specialization.
- The diversity loss formulation contains internal inconsistency: Equation 4 specifies (1-cos), but ablation results indicate L1 formulation performs best, though the exact L1 formulation is not provided in the paper.

## Confidence

- **High confidence** in mechanism claims regarding multi-group prompt co-learning and diversity loss for specialization, supported by controlled ablation studies and visualization of inter-group correlations.
- **Medium confidence** in similarity-guided dynamic aggregation theoretical claims, as the theoretical proof assumes idealized conditions (Gaussian noise, independent components) that may not fully capture real-world federated heterogeneity.
- **Low confidence** in reproduction fidelity without clarification on visual prompt initialization and the exact diversity loss L1 formulation.

## Next Checks

1. Implement controlled ablation comparing L1 vs cosine vs L2 diversity loss formulations on Caltech101 16-shot to verify which yields optimal specialization as claimed.
2. Design stress test varying Dirichlet concentration α from 0.1 to 1.0 on CIFAR-10 with 100 clients to quantify degradation boundaries where similarity-guided aggregation breaks down.
3. Conduct controlled experiment initializing visual prompts with different strategies (random, template-based, zero) to measure impact on convergence and final accuracy, addressing the initialization gap.