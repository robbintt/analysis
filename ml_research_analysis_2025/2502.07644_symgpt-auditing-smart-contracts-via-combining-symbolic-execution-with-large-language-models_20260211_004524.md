---
ver: rpa2
title: 'SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large
  Language Models'
arxiv_id: '2502.07644'
source_url: https://arxiv.org/abs/2502.07644
tags:
- rules
- contract
- contracts
- function
- symgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SymGPT, a tool that combines large language
  models (LLMs) with symbolic execution to automatically audit smart contracts for
  compliance with Ethereum Request for Comment (ERC) rules. SymGPT addresses the challenge
  of manually auditing smart contracts by using an LLM to extract and translate ERC
  rules into an intermediate representation, then using symbolic execution to detect
  violations.
---

# SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models

## Quick Facts
- **arXiv ID**: 2502.07644
- **Source URL**: https://arxiv.org/abs/2502.07644
- **Reference count**: 40
- **Primary result**: Combines LLMs with symbolic execution to audit smart contracts for ERC compliance, finding 5,783 violations in 4,000 real-world contracts

## Executive Summary
SymGPT addresses the challenge of manually auditing smart contracts by combining large language models (LLMs) with symbolic execution. The system uses an LLM to extract and translate ERC rules into an intermediate representation, then applies symbolic execution to detect violations. This hybrid approach leverages the LLM's natural language understanding capabilities while maintaining the formal guarantees of symbolic execution. SymGPT identifies both security vulnerabilities and compliance issues across thousands of contracts, outperforming six automated techniques and a human auditing service in accuracy and efficiency.

## Method Summary
SymGPT employs a three-stage approach to smart contract auditing. First, an LLM extracts ERC rules from specification documents and translates them into a constrained EBNF grammar. Second, the system uses a static analyzer to identify function APIs, anchor functions, and constant fields in target contracts. Third, symbolic execution explores contract execution paths, tracking six generic state variables (TH, EM, CA, BI, BD, BC) and checking for constraint violations using a Z3 solver. The system processes 4,000 real-world contracts, identifying 5,783 ERC rule violations including 1,375 with clear attack paths for financial theft.

## Key Results
- Identifies 5,783 ERC rule violations in 4,000 real-world contracts
- Finds 1,375 violations with clear attack paths for financial theft
- Outperforms six automated techniques and human auditors in accuracy and efficiency
- Achieves significantly higher F1-score than baseline automated auditing tools

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Converting natural language ERC rules into a constrained EBNF grammar before generating logical constraints may reduce LLM hallucination errors compared to direct constraint generation.
- **Mechanism:** The system instructs the LLM to output within a defined Extended Backus-Naur Form (EBNF) grammar rather than free-form text or code. This limits the LLM's output space to valid combinations of terminals (contract elements) and non-terminals (utility functions), reducing statistical variability during the translation phase.
- **Core assumption:** The defined EBNF grammar is sufficiently expressive to represent the semantic nuance of the target ERC rules without forcing oversimplification.
- **Evidence anchors:**
  - [abstract] "instructing an LLM to translate ERC rules into a defined EBNF grammar."
  - [section 4.2] "This two-step process significantly narrows the LLMâ€™s output space... consequently reducing the statistical variability."
  - [corpus] Weak direct evidence in neighbors; "NumScout" and "Validating Solidity" use LLM/pruning hybrids but do not specifically validate the EBNF-reduction hypothesis.
- **Break condition:** If an ERC rule contains logic that cannot be mapped to the pre-defined EBNF non-terminals, the LLM may force an incorrect mapping or fail to capture the rule's intent.

### Mechanism 2
- **Claim:** Abstracting contract-specific implementation details into generic "state variables" allows symbolic execution to verify compliance across different codebases without manual customization.
- **Mechanism:** Instead of tracking specific variable names (e.g., `_balances`), the engine tracks generic state changes (e.g., `TH` for "throw happened", `BI` for "balance increased"). Constraints are synthesized against these generic variables. This decouples the verification logic from the specific naming conventions or structural choices of individual developers.
- **Core assumption:** The six defined state variables (TH, EM, CA, BI, BD, BC) are sufficient to capture all security-relevant behaviors specified in the ERC rules.
- **Evidence anchors:**
  - [abstract] "synthesizes constraints... to represent scenarios where violations may occur."
  - [section 4.3] "We define six types of state variables to track whether _fun_... performs specific actions."
  - [corpus] "NumScout" utilizes a similar approach of abstracting numerical states for analysis.
- **Break condition:** If an ERC rule relies on a semantic state not covered by the six generic variables (e.g., a specific timing constraint or complex state lock), the mechanism will fail to detect violations.

### Mechanism 3
- **Claim:** Decomposing ERC documents by function/event before LLM processing improves extraction accuracy by localizing the context window.
- **Mechanism:** The system splits ERC documents into subsections ending at function declarations. The LLM is prompted with specific text segments and linguistic patterns rather than the entire document, reducing the cognitive load and context noise during rule extraction.
- **Core assumption:** ERC rules are predominantly local to specific functions or events (as found in the empirical study) and do not rely heavily on cross-function inferences that might be lost in segmentation.
- **Evidence anchors:**
  - [section 4.1] "We break each ERC document into subsections... instruct the LLM to analyze each function... based on the patterns."
  - [section 3.2] "Insight 2: Most ERC rules can be checked within a function..."
- **Break condition:** If a rule requires complex cross-function state validation (e.g., a global invariant between two distinct functions) and the segmentation separates these descriptions, the LLM may miss the dependency.

## Foundational Learning

- **Concept: Symbolic Execution**
  - **Why needed here:** SymGPT relies on a symbolic execution engine (built on Slither) to explore execution paths and find inputs that satisfy violation constraints. You must understand how variables become "symbolic" and how solvers (like Z3) check satisfiability.
  - **Quick check question:** If a function has a loop with a symbolic bound, how does the engine handle path explosion? (See SymGPT's loop limit in Section 4.4).

- **Concept: Context-Free Grammars (EBNF)**
  - **Why needed here:** The intermediate representation (IR) used to bridge LLMs and symbolic execution is an EBNF grammar. Understanding terminals vs. non-terminals is required to debug translation errors.
  - **Quick check question:** Can you identify the non-terminals and utility functions in the grammar snippet provided in Figure 3?

- **Concept: Solidity Semantics (ERC Standards)**
  - **Why needed here:** The tool detects violations of specific Ethereum standards (ERC20, ERC721). You need to grasp why rules like "checking caller privileges" are security-critical to distinguish true positives from false positives.
  - **Quick check question:** In Figure 1, why does the lack of `_allowances` subtraction in `transferFrom` constitute a security vulnerability rather than just a logic bug?

## Architecture Onboarding

- **Component map:** LLM Interface -> Static Analyzer -> Constraint Synthesizer -> Symbolic Engine
- **Critical path:** The Constraint Synthesizing step is the bridge. If the EBNF IR is syntactically correct but semantically mismatched to the symbolic engine's capabilities (e.g., referring to a non-existent anchor function), the downstream analysis will fail or produce false positives.
- **Design tradeoffs:**
  - **Accuracy vs. Coverage:** The system limits loops to 2 iterations (Section 4.4). This prevents path explosion (halting analysis) but risks missing vulnerabilities that only manifest after 3+ iterations.
  - **Generic vs. Specific:** Using generic state variables (`BI`, `BD`) enables scalability across 4,000 contracts but introduces coarse-grained analysis that might miss subtle logic errors specific to a single contract's unique state machine.
- **Failure signatures:**
  - **High False Positive Rate (1,510 total):** Primarily driven by LLM extraction errors (hallucinating rules) or symbolic engine limitations with external calls (Section 5.1.2).
  - **Extraction Drift:** The LLM tends to report rules not present in the ERC (e.g., "must not throw" when no such rule exists), leading to systematic false positives across all contracts of that type.
- **First 3 experiments:**
  1. **Unit Test the Grammar:** Run the LLM translation component on a single paragraph of ERC20 text and verify the output JSON strictly adheres to the EBNF schema in Figure 3.
  2. **Trace a False Positive:** Take one of the 1,388 false positives mentioned in Section 5.1.2 (e.g., the "must not throw" hallucination) and trace it back to the specific prompt/pattern that generated it.
  3. **Solver Stress Test:** Run the symbolic engine on a contract with nested loops to verify the loop-limiting heuristic (max 2 iterations) effectively bounds execution time without Z3 timeouts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ERC rules governing function return values be formalized and verified within an automated auditing framework?
- Basis in paper: [explicit] The authors state in Section 4.2 that the EBNF grammar omits return-value rules because of the "difficulty of using contract elements explicitly required by ERCs to define the required return values," and in Section 5.2.2 note a missed violation because "SymGPT does not verify compliance with rules that govern how to generate return values."
- Why unresolved: The semantic meaning of return values (e.g., a token's name) is often decoupled from strict ERC-defined storage locations, making it challenging to derive a generalizable formal constraint for symbolic execution.
- What evidence would resolve it: An extension of the EBNF grammar and symbolic execution engine capable of verifying return values across diverse storage implementations without manual configuration.

### Open Question 2
- Question: How can the reliability of LLM-based rule extraction be improved to eliminate systematic hallucinations that propagate false positives across all analyzed contracts?
- Basis in paper: [inferred] In Section 5.1.2, the authors note that the LLM made seven mistakes during rule extraction, which resulted in 1,388 false positives. While they suggest a heuristic ("ignoring rules violated by all contracts"), this does not solve the underlying issue of the LLM misinterpreting the ERC document.
- Why unresolved: The LLM's probabilistic nature leads it to report non-existent rules or misrepresent constraints, and current prompting strategies do not fully guarantee fidelity to the source text.
- What evidence would resolve it: A validation mechanism or refined extraction methodology that achieves zero extraction errors on the studied ERC standards without requiring post-hoc filtering.

### Open Question 3
- Question: Can symbolic execution be effectively adapted to analyze logic dependencies in external contracts whose source code is unavailable?
- Basis in paper: [inferred] Section 5.1.2 identifies that 116 false positives arose because "a contract retrieves the token balance of an account from another contract, whose code is unavailable during our experiment."
- Why unresolved: The tool currently lacks the ability to soundly model the behavior of external dependencies, defaulting to assumptions that trigger violation reports.
- What evidence would resolve it: A method for safely summarizing or approximating external contract behavior to prevent false positives in multi-contract ecosystems.

## Limitations
- Fixed set of six generic state variables may not capture complex cross-function invariants or semantic states unique to specific contracts
- LLM-based rule extraction shows significant hallucination, generating 1,388 false positives from rules not present in the original ERC documents
- Symbolic execution bounded to two loop iterations, potentially missing vulnerabilities requiring deeper path exploration

## Confidence
- **High Confidence**: The core technical architecture (LLM + EBNF grammar + symbolic execution) is well-documented and the comparative evaluation against six baselines and human auditors is methodologically sound.
- **Medium Confidence**: The claim of superior accuracy over automated techniques is supported by the F1-score comparison, but the human auditor baseline may not represent state-of-the-art manual auditing practices.
- **Low Confidence**: The scalability claims (processing 4,000 contracts) lack detailed runtime analysis, and the false positive rate (1,510 violations) suggests significant extraction noise that may undermine practical utility.

## Next Checks
1. **Grammar Coverage Test**: Manually verify that the EBNF grammar can represent all semantic constructs in a diverse sample of ERC rules (including cross-function dependencies) without forcing incorrect mappings.
2. **False Positive Root Cause Analysis**: For the 1,388 LLM-hallucinated violations, identify the exact prompt patterns and document segments that consistently trigger extraction errors, then measure reduction after prompt engineering.
3. **Loop Bound Sensitivity**: Systematically vary the loop iteration limit (1, 2, 3, 4) on a benchmark of known multi-iteration vulnerabilities to quantify the trade-off between completeness and computational tractability.