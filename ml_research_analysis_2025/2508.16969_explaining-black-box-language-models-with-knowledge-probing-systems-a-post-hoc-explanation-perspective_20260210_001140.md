---
ver: rpa2
title: 'Explaining Black-box Language Models with Knowledge Probing Systems: A Post-hoc
  Explanation Perspective'
arxiv_id: '2508.16969'
source_url: https://arxiv.org/abs/2508.16969
tags:
- knowledge
- frame
- text
- language
- probing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining black-box pre-trained
  language models (PLMs) by probing their understanding of implicit knowledge beyond
  the given text. The authors propose KnowProb, a knowledge-guided probing approach
  that leverages frame semantics from FrameNet to generate knowledge beyond surface-level
  text content.
---

# Explaining Black-box Language Models with Knowledge Probing Systems: A Post-hoc Explanation Perspective

## Quick Facts
- **arXiv ID**: 2508.16969
- **Source URL**: https://arxiv.org/abs/2508.16969
- **Authors**: Yunxiao Zhao; Hao Xu; Zhiqiang Wang; Xiaoli Li; Jiye Liang; Ru Li
- **Reference count**: 40
- **Primary result**: Probing PLMs with frame-based knowledge reveals they learn single distributions of representation and struggle with implicit knowledge beyond surface text

## Executive Summary
This paper addresses the challenge of explaining black-box pre-trained language models (PLMs) by probing their understanding of implicit knowledge beyond the given text. The authors propose KnowProb, a knowledge-guided probing approach that leverages frame semantics from FrameNet to generate knowledge beyond surface-level text content. KnowProb employs a frame semantic parser to model hidden knowledge and constructs a frame-based knowledge graph to represent semantic relationships. Experiments with various PLMs on Chinese machine reading comprehension datasets show that current PLMs struggle to capture hidden knowledge beyond the given text.

## Method Summary
The KnowProb framework extracts implicit knowledge from text using frame semantic parsing, constructs frame-based knowledge graphs, and generates probing questions to test whether black-box PLMs understand this hidden knowledge. The approach involves training a frame semantic parser on annotated Chinese data, converting extracted knowledge triples into multiple-choice QA prompts, and evaluating PLMs both in zero-shot and fine-tuning scenarios. The method specifically targets six probing types that test knowledge understanding versus association reasoning.

## Key Results
- PLMs perform significantly worse on hidden knowledge probing (HKP) compared to surface-level knowledge (SKP), with some models performing below random chance
- Large-scale models like LLaMa-70B show minimal improvement over smaller models on hidden knowledge tasks
- Fine-tuning with frame-based knowledge augmentation improves both hidden and surface-level performance, with some models showing statistically significant gains

## Why This Works (Mechanism)

### Mechanism 1: Frame Semantic Parsing for Knowledge Externalization
- **Claim:** Frame semantic parsers can extract structured representations to externalize hidden knowledge not explicitly stated in surface text
- **Mechanism:** The system encodes input text using a PLM with special tokens marking target words, then applies sequence and token classifiers to predict semantic frames and elements
- **Core assumption:** Frame Semantics accurately models how humans understand hidden context and can be mapped to machine representations
- **Evidence anchors:** Abstract states "employs a frame semantic parser to model hidden knowledge," section 4.1 describes frame identification task
- **Break condition:** The mechanism fails if polysemous words lead to incorrect frame selection, propagating errors into the Knowledge Graph

### Mechanism 2: Post-hoc Probing via Implicit Knowledge Association
- **Claim:** Probing PLMs with questions derived from implicit frame relationships reveals whether models have learned true semantic understanding
- **Mechanism:** Frame-KG triples are converted into multiple-choice QA prompts, testing Hidden Knowledge Performance versus Surface-level Knowledge Performance
- **Core assumption:** Corollary 1 holds—correct answers indicate stored knowledge, while failure implies lack of hidden knowledge capture
- **Evidence anchors:** Abstract validates "current PLMs only learn a single distribution of representation," section 4.3 describes triple-to-QA conversion
- **Break condition:** The mechanism fails if generated probing questions are linguistically unnatural or ambiguous

### Mechanism 3: Knowledge-Enhanced Representation Learning
- **Claim:** Fine-tuning PLMs with augmented data from frame-based hidden knowledge improves representation learning for both hidden and surface tasks
- **Mechanism:** Extracted frame knowledge is injected as data augmentation during fine-tuning, forcing models to attend to semantic roles and frame relationships
- **Core assumption:** Frame semantic parser provides sufficiently accurate ground truth hidden knowledge to serve as useful training signal
- **Evidence anchors:** Section 5.2 shows "integration of frame-based knowledge present has shown significant improvements," table 4 shows accuracy improvements
- **Break condition:** The mechanism fails if frame parser generates noisy or irrelevant hidden knowledge, causing data poisoning

## Foundational Learning

- **Concept: Frame Semantics (FrameNet)**
  - **Why needed here:** Core of this paper relies on understanding that words evoke "frames" (scenarios) with specific "elements" (roles), which is the definition of hidden knowledge being probed
  - **Quick check question:** Given "The student read the book," what Frame might be evoked, and what are potential Frame Elements for "student"?

- **Concept: Knowledge Probing (Black-box)**
  - **Why needed here:** Must understand difference between testing model on task (performance) vs. probing internal state for specific knowledge (explainability/diagnosis)
  - **Quick check question:** How does a "cloze prompt" differ from the "multiple-choice QA" used in this paper?

- **Concept: Sequence & Token Classification**
  - **Why needed here:** KnowProb architecture uses Sequence Classifier (for Frame ID) and Token Classifier (for Argument ID) to build the graph
  - **Quick check question:** Does the [CLS] token embedding represent the whole sentence for Frame ID or Token ID?

## Architecture Onboarding

- **Component map:** Input Processor -> Frame Semantic Parser -> Graph Constructor -> Probing Generator -> Target PLM
- **Critical path:** The Frame Semantic Parser is the bottleneck—errors in Frame Prediction or Argument Identification make probing results meaningless
- **Design tradeoffs:**
  - Parser Accuracy vs. Coverage: Using PLM for parsing introduces model-in-the-loop bias
  - Prompt Specificity: Manual definition of 6 probing types provides control but limits scalability
- **Failure signatures:**
  - Zero-shot Paradox: Models performing worse than random indicates active anti-correlation with hidden knowledge
  - LLM Stagnation: Large models performing barely better than small models indicates scaling alone doesn't resolve single distribution learning
- **First 3 experiments:**
  1. Sanity Check: Replicate Table 1 by running target PLM on HKP questions without training to confirm black-box limitation
  2. Parser Validation: Manually inspect 20 sentences to verify Frame Semantic Parser correctly identifies Frames and Elements
  3. Ablation on Probing Types: Test performance on only "Knowledge-based" vs. "Association-based" reasoning to isolate model failures

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the finding that PLMs only learn a "single distribution of representation" be utilized to develop training paradigms that specifically improve reasoning across out-of-domain distributions?
- **Basis in paper:** [explicit] The conclusion explicitly highlights that current PLMs "only learn a single distribution of representation" and states this reveals "opportunities for future research in improving reasoning across out-of-domain distributions."
- **Why unresolved:** The paper identifies this single-distribution limitation as a cause for poor generalization on hidden knowledge but does not propose a concrete method to force models to learn multi-modal or broader distributions of representation
- **What evidence would resolve it:** A modified training objective or regularization technique that results in statistically significant improvements on out-of-domain (OOD) benchmarks compared to standard fine-tuning

### Open Question 2
- **Question:** Is the efficacy of KnowProb dependent on the specific linguistic structures of the Chinese language, or does the framework generalize effectively to low-resource languages lacking extensive FrameNet databases?
- **Basis in paper:** [inferred] The paper relies exclusively on Chinese datasets (C3-M, C3-D) and resources like the Chinese Tree Bank for annotation, leaving the cross-linguistic applicability of the frame-based probing method unverified
- **Why unresolved:** The methodology depends on a robust, manually annotated frame semantic parser; it is unstated whether the approach is viable for languages where such semantic resources are scarce or structurally different
- **What evidence would resolve it:** Experimental results replicating the KnowProb framework on English or low-resource language benchmarks using cross-lingual alignment or transfer learning

### Open Question 3
- **Question:** To what extent do errors in the initial frame semantic parser propagate through the system, potentially mislabeling the model's ability to capture "hidden knowledge"?
- **Basis in paper:** [inferred] The methodology utilizes a "prior frame semantic parser" to generate the ground truth knowledge graph, but does not analyze the impact of parser inaccuracies on the final probing metrics
- **Why unresolved:** If the parser fails to identify a frame or element (e.g., missing that "reading" implies a "reader"), the probing system might falsely attribute a model's failure to a lack of knowledge rather than a parsing error
- **What evidence would resolve it:** An error analysis quantifying the correlation between parser confidence/accuracy and the subsequent probing performance of the black-box models

## Limitations

- The paper relies heavily on the accuracy of frame semantic parsing as a proxy for "hidden knowledge," but frame parser performance on Chinese data is not fully validated against human annotations
- The claim that PLMs "only learn a single distribution of representation" is based on zero-shot probing performance, which could reflect prompt engineering limitations rather than fundamental knowledge gaps
- Knowledge graph construction from frame semantics assumes FrameNet coverage is sufficient for Chinese MRC datasets, but the paper doesn't address potential coverage gaps or domain-specific terminology mismatches

## Confidence

- **High confidence**: Experimental results showing zero-shot probing failures and fine-tuning improvements are well-documented with multiple PLM evaluations across different model sizes
- **Medium confidence**: The frame semantic approach for extracting hidden knowledge is theoretically sound but practically dependent on parser accuracy that isn't fully validated
- **Low confidence**: The interpretation that poor zero-shot performance definitively proves "single distribution" learning rather than prompt or representation issues

## Next Checks

1. **Frame parser validation**: Manually annotate 50 sentences from Chinese MRC datasets to verify frame identification and argument labeling accuracy, establishing ground truth for knowledge graph quality
2. **Prompt design ablation**: Create multiple prompt variations for the same frame triples to test whether zero-shot failures are consistent across different linguistic formulations or specific to current templates
3. **Cross-linguistic generalization**: Apply the same probing methodology to English MRC datasets using the same frame semantic approach to determine if results generalize beyond Chinese language models