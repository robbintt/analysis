---
ver: rpa2
title: 'VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models'
arxiv_id: '2506.13754'
source_url: https://arxiv.org/abs/2506.13754
tags:
- diffusion
- forward
- inverse
- video
- observation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VideoPDE, a unified generative framework
  for solving partial differential equations (PDEs) by casting PDE-solving as a video
  inpainting problem using diffusion models. Unlike existing methods that require
  separate models for forward, inverse, or partial observation tasks, VideoPDE leverages
  a transformer-based hierarchical video diffusion architecture that conditions on
  arbitrary spatiotemporal patterns of sparse measurements.
---

# VideoPDE: Unified Generative PDE Solving via Video Inpainting Diffusion Models

## Quick Facts
- arXiv ID: 2506.13754
- Source URL: https://arxiv.org/abs/2506.13754
- Reference count: 40
- VideoPDE achieves up to 10x lower error rates than state-of-the-art methods, reducing relative ℓ2 error to 0.44% with only 1% continuous observations

## Executive Summary
VideoPDE introduces a unified generative framework that solves partial differential equations by casting them as video inpainting problems using diffusion models. The approach leverages a transformer-based hierarchical video diffusion architecture that can condition on arbitrary spatiotemporal patterns of sparse measurements, enabling it to handle forward prediction, inverse recovery, and reconstruction tasks with a single model. By operating in pixel space with hierarchical attention and efficient tokenization, VideoPDE achieves significantly better accuracy than existing methods while maintaining flexibility across different PDE types and observation patterns.

## Method Summary
VideoPDE frames PDE-solving as a video inpainting task where the solution evolves over time like a video sequence. The method uses a transformer-based hierarchical video diffusion architecture that processes spatiotemporal data through multiple resolution levels, with cross-attention layers conditioned on sparse PDE observations. The model learns to generate PDE solutions in pixel space, allowing it to handle arbitrary boundary conditions and observation patterns without requiring separate models for different tasks. Training involves reconstructing ground truth solutions from sparse measurements across multiple PDE types simultaneously, enabling the unified framework to generalize across forward prediction, inverse problems, and partial observation reconstruction scenarios.

## Key Results
- Achieves up to 10x lower error rates than state-of-the-art methods
- Reduces relative ℓ2 error to 0.44% with only 1% continuous observations (compared to 4.7-12.7% for baselines)
- Single unified model matches or exceeds performance of task-specific variants across multiple PDE types

## Why This Works (Mechanism)
The key innovation lies in treating PDE solutions as spatiotemporal videos that can be generated through inpainting diffusion models. By leveraging hierarchical attention and efficient tokenization, the model can process high-dimensional PDE solutions while maintaining fine-grained accuracy. The transformer architecture allows the model to learn complex spatiotemporal relationships inherent in PDE dynamics, while the diffusion process provides a natural framework for handling uncertainty and generating high-quality solutions from sparse observations.

## Foundational Learning

**Partial Differential Equations**: Mathematical equations describing how physical quantities change with respect to multiple independent variables like space and time. *Why needed*: The fundamental problem being solved. *Quick check*: Can derive basic heat equation or wave equation.

**Diffusion Models**: Generative models that learn to reverse a gradual noising process to create data. *Why needed*: Provides the core mechanism for generating PDE solutions from sparse observations. *Quick check*: Understand the forward noising and reverse denoising process.

**Transformer Architecture**: Neural network architecture using self-attention mechanisms to process sequential data. *Why needed*: Enables modeling of complex spatiotemporal dependencies in PDE solutions. *Quick check*: Can explain multi-head attention and positional encoding.

**Hierarchical Attention**: Multi-resolution processing where attention operates at different scales. *Why needed*: Allows efficient processing of high-dimensional spatiotemporal data. *Quick check*: Understand how information flows between resolution levels.

## Architecture Onboarding

**Component Map**: Input Observations -> Hierarchical Transformer Encoder -> Cross-Attention Layers -> Diffusion Decoder -> Output Solution

**Critical Path**: The model processes PDE observations through hierarchical transformer layers, where cross-attention modules condition the generation process on sparse measurements. The diffusion decoder then iteratively denoises to produce the final solution, with each step incorporating information from the observations.

**Design Tradeoffs**: 
- Pixel-space operation vs. latent-space approaches: Pixel space maintains fine-grained accuracy but increases computational cost
- Unified model vs. task-specific models: Unified approach reduces complexity but may sacrifice some task-specific optimization
- Hierarchical attention vs. flat attention: Hierarchical approach scales better but adds architectural complexity

**Failure Signatures**:
- Poor performance on PDEs with very different temporal and spatial scales than those tested
- Degraded accuracy when observation noise exceeds training conditions
- Computational bottlenecks when scaling to extremely high-resolution 3D problems

**First Experiments**:
1. Validate basic forward prediction accuracy on a simple PDE (e.g., heat equation) with dense observations
2. Test inverse problem recovery with sparse measurements on a known PDE system
3. Evaluate unified model performance across all three tasks (forward, inverse, reconstruction) on a single PDE type

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability beyond tested PDE classes remains uncertain
- Scalability challenges for extremely high-resolution or 3D spatiotemporal problems
- Computational cost during inference not thoroughly analyzed

## Confidence
- **High**: Performance superiority over baselines on tested PDEs, unified framework's multi-task capability, technical soundness of video inpainting approach
- **Medium**: Scalability claims for different PDE types, efficiency of hierarchical attention for larger problem sizes
- **Low**: Robustness to noisy observations, performance on PDEs with very different temporal/spatial scales

## Next Checks
1. Test the model on a coupled PDE system (e.g., fluid-structure interaction or reaction-diffusion systems) to verify generalizability beyond single-equation problems
2. Evaluate performance with varying levels of observation noise to assess robustness in real-world conditions where measurements are imperfect
3. Benchmark computational efficiency and memory requirements on high-resolution 3D spatiotemporal problems to validate scalability claims