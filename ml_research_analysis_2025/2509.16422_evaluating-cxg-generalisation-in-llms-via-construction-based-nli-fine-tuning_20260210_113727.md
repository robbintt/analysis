---
ver: rpa2
title: Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning
arxiv_id: '2509.16422'
source_url: https://arxiv.org/abs/2509.16422
tags:
- construction
- constructions
- example
- prompt
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models (LLMs) can
  acquire deep, construction-based form-meaning mappings similar to human linguistic
  generalization. The authors introduce ConTest-NLI, a scalable dataset of 80,000
  synthetic sentences covering eight English constructions, and use model-in-the-loop
  filtering to ensure challenge and label reliability.
---

# Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning

## Quick Facts
- **arXiv ID:** 2509.16422
- **Source URL:** https://arxiv.org/abs/2509.16422
- **Reference count:** 3
- **Primary result:** Fine-tuning small LLMs on construction-based NLI improves in-domain accuracy by up to 9%, but models fail to generalize to out-of-distribution constructions with shared syntax.

## Executive Summary
This paper investigates whether large language models can acquire deep, construction-based form-meaning mappings similar to human linguistic generalization. The authors introduce ConTest-NLI, a scalable dataset of 80,000 synthetic sentences covering eight English constructions, and use model-in-the-loop filtering to ensure challenge and label reliability. They fine-tune small LLMs on ConTest-NLI and evaluate performance on naturalistic and adversarial constructional NLI tasks. Results show up to 9% accuracy improvement on in-domain tasks, but models fail to generalize to out-of-distribution, semantically distinct constructions sharing the same syntax. This highlights persistent abstraction gaps, suggesting current LLMs rely on surface-level cues rather than robust constructional semantics, and provides a framework for evaluating construction-informed learning in future models.

## Method Summary
The authors developed ConTest-NLI, an 80,000-sentence synthetic dataset covering eight English constructions, generated using templates and filtered via model-in-the-loop to ensure challenge and label reliability. They fine-tuned small LLMs (1.3B-8B parameters) on this dataset and evaluated them on in-domain and out-of-domain constructional NLI tasks, including naturalistic and adversarial examples. Performance gains of up to 9% accuracy were observed on in-domain tasks, but models failed to generalize to semantically distinct constructions sharing the same syntax, indicating reliance on surface-level cues rather than robust constructional semantics.

## Key Results
- Fine-tuning on ConTest-NLI improved in-domain constructional NLI accuracy by up to 9%.
- Models failed to generalize to out-of-distribution constructions with shared syntax but different semantics.
- Results suggest LLMs rely on surface-level cues rather than robust constructional semantics.

## Why This Works (Mechanism)
Assumption: The model-in-the-loop filtering process creates a dataset that targets specific constructional patterns, forcing the model to attend to form-meaning mappings during fine-tuning. The synthetic nature of ConTest-NLI allows controlled exposure to constructional variations, which may explain the in-domain accuracy gains. However, the failure to generalize suggests that the fine-tuning process does not induce abstract constructional representations that transfer across semantically distinct but syntactically similar constructions.

## Foundational Learning
- **Construction Grammar (CxG):** Framework for analyzing how form-meaning pairings (constructions) drive linguistic generalization; needed to understand the theoretical basis of the study.
- **Natural Language Inference (NLI):** Task involving determining if a premise entails, contradicts, or is neutral to a hypothesis; needed to operationalize constructional understanding.
- **Model-in-the-loop filtering:** Iterative process using model predictions to refine dataset difficulty and label reliability; needed to ensure high-quality synthetic data.
- **Out-of-distribution generalization:** Ability to apply learned knowledge to novel, semantically distinct examples; needed to test robustness of constructional learning.
- **Syntactic-semantic mappings:** Relationships between sentence structure and meaning; needed to analyze constructional generalization failures.

## Architecture Onboarding
**Component Map:** ConTest-NLI dataset generation -> Model-in-the-loop filtering -> Fine-tuning on small LLMs -> Evaluation on in-domain and out-of-domain NLI tasks.

**Critical Path:** Dataset creation and filtering → Model fine-tuning → Evaluation on constructional NLI tasks.

**Design Tradeoffs:** Synthetic data allows scalability and control but may lack ecological validity; small models are computationally efficient but may not capture complex generalizations.

**Failure Signatures:** Inability to generalize to out-of-distribution constructions; reliance on surface-level cues rather than constructional semantics.

**First Experiments:**
1. Evaluate fine-tuned models on naturalistic constructional datasets to assess ecological validity.
2. Test larger LLMs to determine if model scale affects constructional generalization.
3. Conduct ablation studies on the model-in-the-loop filtering process to quantify its impact.

## Open Questions the Paper Calls Out
- Why do models fail to generalize to out-of-distribution constructions despite in-domain success?
- Can larger LLMs overcome the abstraction gaps observed in small models?
- How does the model-in-the-loop filtering process influence the robustness of constructional learning?
- What role do semantic vs. syntactic cues play in constructional generalization?

## Limitations
- Synthetic dataset may not fully capture semantic variability and pragmatic nuance of natural constructions.
- Fine-tuning performed on small models (1.3B-8B parameters), limiting generalizability to larger LLMs.
- Model-in-the-loop filtering introduces potential biases in sentence selection not fully characterized.

## Confidence
- **Core finding (constructional generalization failure):** High
- **Nature of model failures (surface-level reliance):** Medium

## Next Checks
1. Evaluate fine-tuned models on naturalistic constructional datasets to assess ecological validity of synthetic data.
2. Test larger LLMs (e.g., 70B+ parameters) to determine if model scale affects constructional generalization.
3. Conduct ablation studies on the model-in-the-loop filtering process to quantify its impact on dataset difficulty and model performance.