---
ver: rpa2
title: 'CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification'
arxiv_id: '2509.20489'
source_url: https://arxiv.org/abs/2509.20489
tags:
- noise
- channels
- attention
- learning
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes CoSupFormer, a novel end-to-end deep learning
  framework for EEG signal classification that addresses challenges of noise and channel
  variability through several key innovations: a dual-path dilated CNN encoder for
  multi-scale feature extraction, a global attention mechanism to model interactions
  across and within channels, a gating network to filter out noisy channels, and a
  hybrid loss function combining supervised and contrastive learning. The model is
  evaluated on five datasets across multiple applications including CNS disorder treatment
  classification and diagnosis of Parkinson''s and Alzheimer''s disease, showing consistent
  improvement over state-of-the-art transformer baselines.'
---

# CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification

## Quick Facts
- arXiv ID: 2509.20489
- Source URL: https://arxiv.org/abs/2509.20489
- Reference count: 40
- Primary result: Novel end-to-end deep learning framework for EEG signal classification that addresses noise and channel variability challenges through dual-path dilated CNN, global attention, gating network, and hybrid loss function.

## Executive Summary
CoSupFormer introduces a novel end-to-end deep learning framework for EEG signal classification that addresses key challenges in neurological disorder diagnosis and drug development. The model combines a dual-path dilated CNN encoder for multi-scale feature extraction, a global attention mechanism for spatiotemporal interaction modeling, and a gating network for noise filtering, all optimized with a hybrid supervised-contrastive loss function. Evaluated across five datasets for applications including CNS disorder treatment classification and diagnosis of Parkinson's and Alzheimer's disease, CoSupFormer demonstrates consistent improvement over state-of-the-art transformer baselines, achieving up to 95.81% accuracy on TDBrain, 54.95% on ADFTD, and 74.93% on the challenging MACO dataset.

## Method Summary
CoSupFormer processes raw multi-channel EEG signals through a dual-path dilated CNN encoder that captures both high-frequency local patterns (small kernels) and low-frequency oscillations (large dilated kernels). The extracted features are flattened and processed by a global attention mechanism with diagonal masking to model cross-channel and temporal interactions, while a parallel gating network suppresses noisy or irrelevant channels. The model is trained end-to-end using a hybrid CoSup loss that combines cross-entropy with normalized temperature-scaled cross-entropy for contrastive learning, improving generalization and class separability. The architecture is designed to handle the inherent noise and variability in EEG data while maintaining strong performance across different species and clinical applications.

## Key Results
- Achieved 95.81% accuracy on TDBrain dataset for CNS disorder treatment classification
- Demonstrated 54.95% accuracy on ADFTD dataset for Alzheimer's disease diagnosis
- Showed 74.93% accuracy on MACO dataset for Parkinson's disease classification, with superior robustness under noisy conditions compared to transformer baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The dual-path dilated CNN encoder captures multi-scale frequency oscillations more efficiently than standard convolutions by separating high- and low-frequency feature extraction.
- **Mechanism:** Branch 1 uses small kernels for fine-grained, high-frequency local patterns. Branch 2 uses large kernels with dilation (gaps) to expand the receptive field without increasing parameter count, capturing low-frequency oscillations. These are concatenated to form a comprehensive representation.
- **Core assumption:** Distinct EEG information resides in specific frequency bands (0.1–250 Hz) that require different temporal resolutions to encode effectively without redundancy.
- **Evidence anchors:** [abstract]: "...encoder capable of explicitly capturing multi-scale frequency oscillations..." [section 3.1]: "The first branch uses small convolutional kernels... The second branch uses larger kernels with dilation... dilated convolutions expand the receptive field without increasing the number of parameters."
- **Break condition:** If the signal's critical information lies in frequency bands that fall between the chosen kernel sizes or dilation rates, the encoder may fail to capture relevant features.

### Mechanism 2
- **Claim:** The global gated attention mechanism improves signal-to-noise representation by jointly modeling spatiotemporal interactions and explicitly suppressing irrelevant channels.
- **Mechanism:** The model flattens channel and temporal patches into a sequence $CL \times E$. A global attention matrix learns interactions (within-channel, cross-channel same-time, cross-channel different-time) simultaneously. A parallel gating network applies a sigmoid mask to zero out (suppress) patches identified as noisy or non-informative.
- **Core assumption:** Noisy or non-informative EEG channels/patches exhibit activation patterns that can be mathematically distinguished and gated toward zero by a learned network.
- **Evidence anchors:** [abstract]: "...gating network to filter out noisy channels..." [section 3.2]: "The gating mechanism allows the model to completely suppress the contribution of irrelevant or noisy patches... enforcing a stronger, task-driven filtering."
- **Break condition:** If the noise distribution shifts significantly during inference (e.g., new artifact types not seen during training), the gating network may fail to suppress it, retaining high noise levels in the embedding.

### Mechanism 3
- **Claim:** The hybrid CoSup loss enhances generalization and class separability by forcing the latent space to cluster same-class samples closer together than standard cross-entropy alone.
- **Mechanism:** The loss combines standard Cross-Entropy ($L_{CE}$) with Normalized Temperature-scaled Cross Entropy ($L_{NT-Xent}$). The contrastive term pulls embeddings of samples with the same label together and pushes different labels apart, structuring the feature space.
- **Core assumption:** High inter-subject variability in EEG data requires explicit distance-based regularization in the loss function to prevent overfitting to subject-specific noise.
- **Evidence anchors:** [abstract]: "...hybrid loss function combining supervised and contrastive learning... significantly improving model generalization." [appendix d]: "CoSupFormer embeddings form more compact, class-specific clusters... In contrast, the SupFormer embeddings are more dispersed."
- **Break condition:** If the batch size is too small to provide sufficient negative pairs for the contrastive loss, or if the weighting $\lambda$ is poorly tuned, the model may fail to converge or suffer from conflicting gradient signals.

## Foundational Learning

- **Concept:** Dilated (Atrous) Convolutions
  - **Why needed here:** Required to understand how the encoder captures low-frequency brainwaves (broad time windows) without exploding the parameter count or losing resolution via pooling.
  - **Quick check question:** How does inserting gaps (dilation) into a kernel change its receptive field compared to a standard dense kernel of the same size?

- **Concept:** Contrastive Learning (specifically NT-Xent Loss)
  - **Why needed here:** Essential to understand how the model learns "good" representations by looking at pairwise relationships between samples in a batch rather than just mapping input to label.
  - **Quick check question:** In the context of this paper, what constitutes a "positive pair" vs a "negative pair" for the contrastive loss?

- **Concept:** Attention Mechanisms (Query, Key, Value)
  - **Why needed here:** The "Global Attention" module relies on self-attention to model interactions between every patch across all channels. You must understand how $Q K^T$ creates an interaction matrix.
  - **Quick check question:** Why does the paper mask the diagonal of the attention matrix (removing self-attention) before applying softmax?

## Architecture Onboarding

- **Component map:** Raw EEG ($C \times L$) -> Dual-Path CNN Encoder -> Flattened $CL \times E$ -> Global Attention with Diagonal Masking -> Gating Network -> Element-wise Multiplication -> Classifier
- **Critical path:** The Gating Network (Algorithm 2, line 4 & 9) is the critical differentiator. If implemented incorrectly (e.g., applied before attention or without the sigmoid constraint), the noise suppression capability fails. The masking of the attention diagonal (preventing $i \to i$ attention) is also vital for forcing the model to look at interactions rather than just self-features.
- **Design tradeoffs:**
  - Global vs. Local Attention: The paper uses global attention ($CL \times CL$ matrix). This is computationally expensive for long sequences but captures cross-channel time-lagged interactions.
  - Gating vs. Attention-only: Gating "hard" suppresses features (via multiplication), whereas attention only "soft" down-weights them. This improves noise robustness but risks dropping information if the gate is miscalibrated.
- **Failure signatures:**
  - Mode Collapse (Loss): If $\lambda$ is set incorrectly or batch size is too small, the contrastive loss may dominate, causing embeddings to collapse to a single point or fail to separate classes.
  - Over-Gating: If the gating network is too aggressive (high sigmoid threshold), it may zero out valid channels, leading to "data starvation" for the classifier.
  - Memory Overflow: Global attention on $C \times L$ scales quadratically. Long EEG traces may OOM (Out of Memory) without significant patching/downsampling.
- **First 3 experiments:**
  1. Encoder Sanity Check: Run only the Dual-Path Encoder (remove Attention/Gating) with pure Cross-Entropy to verify that multi-scale features provide a baseline better than random or single-branch CNNs.
  2. Ablation on Noise: Train "Global Attention" with and without the "Gating" mechanism specifically on the TDBrain+Noise dataset to measure the delta in robustness attributable to the gating mask.
  3. Loss Tuning: Sweep the $\lambda$ parameter (e.g., 0.1 to 0.9) to find the optimal balance between supervised guidance and contrastive regularization on a validation set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the CoSupFormer architecture generalize effectively to other medical time-series modalities?
- Basis in paper: [explicit] Section 4.2 states, "its applicability to other medical time series such as ECG or EMG remains untested."
- Why unresolved: The dual-path encoder and attention mechanisms are specifically tuned for EEG frequency bands (0.1–250 Hz) and multi-channel noise profiles, which may not align with cardiac or muscular signal characteristics.
- What evidence would resolve it: Benchmarking the unmodified model on open ECG (e.g., PTB-XL) and EMG datasets to assess if the multi-scale encoder captures relevant physiological features without domain-specific re-engineering.

### Open Question 2
- Question: How does the hybrid supervised-contrastive loss function perform in extreme low-data regimes?
- Basis in paper: [explicit] Section 4.2 notes that "in cases where the available training data is very limited, the combined supervised-contrastive loss can occasionally lead to a drop in performance."
- Why unresolved: Contrastive learning typically relies on large batch sizes and diverse negative samples to form useful embeddings; this requirement may conflict with the constraints of small clinical datasets.
- What evidence would resolve it: An ablation study specifically analyzing accuracy and convergence speed when training sample counts are systematically reduced below standard clinical trial sizes.

### Open Question 3
- Question: Can the gating mechanism be made adaptive to prevent the suppression of informative features in low-noise datasets?
- Basis in paper: [inferred] Appendix C.2 reports that removing the gating mechanism improved performance on the ADFTD dataset, suggesting the mechanism may be "overly suppressive" or less beneficial when spatial patterns are consistent.
- Why unresolved: The current gating network uses a static learned mask which might aggressively filter channels that are actually informative in cleaner datasets, limiting flexibility.
- What evidence would resolve it: Developing a dynamic gating threshold or a sparsity-inducing regularizer and comparing the resulting channel selection statistics against the current static sigmoid approach across varying noise levels.

## Limitations

- The exact architecture of the dual-path CNN encoder (kernel sizes, dilation rates, number of layers) is not explicitly defined, which could significantly impact reproducibility.
- The hybrid loss function's hyperparameters (particularly the contrastive weight λ and temperature τ) are not specified in the provided results tables.
- Biological interpretability claims are asserted but not empirically validated through neuroscience collaboration or feature visualization studies.

## Confidence

- **High Confidence**: The core architectural innovations (dual-path dilated CNN, global attention with diagonal masking, gating network) are clearly described and represent novel contributions to EEG classification.
- **Medium Confidence**: The claimed robustness under noisy conditions and superior generalization across species are supported by experimental results, but specific noise simulation methodology is not detailed.
- **Low Confidence**: Biological interpretability claims are asserted but not empirically validated through neuroscience collaboration or feature visualization studies.

## Next Checks

1. **Architectural Sensitivity Analysis**: Systematically vary the dual-path CNN parameters (kernel sizes, dilation rates, layer depth) to determine their impact on performance and identify the minimum viable configuration that achieves competitive results.

2. **Cross-Dataset Generalization Test**: Train CoSupFormer on one dataset (e.g., TDBrain) and evaluate directly on another (e.g., ADFTD) without fine-tuning to rigorously assess true cross-species generalization capabilities beyond the reported cross-validation results.

3. **Noise Robustness Calibration**: Conduct controlled experiments varying noise levels systematically on all datasets to quantify the exact contribution of the gating mechanism to noise robustness, comparing against alternative noise-handling approaches like data augmentation or denoising autoencoders.