---
ver: rpa2
title: Prompt Injection Detection and Mitigation via AI Multi-Agent NLP Frameworks
arxiv_id: '2503.11517'
source_url: https://arxiv.org/abs/2503.11517
tags:
- injection
- prompt
- policy
- mitigation
- tivs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses prompt injection attacks in generative AI\
  \ systems by introducing a multi-agent NLP framework that detects and mitigates\
  \ such vulnerabilities through layered defense mechanisms. The approach employs\
  \ specialized agents\u2014including a front-end generator, guard/sanitizer, policy\
  \ enforcer, and KPI evaluator\u2014to systematically identify and neutralize injection\
  \ attempts while ensuring policy compliance."
---

# Prompt Injection Detection and Mitigation via AI Multi-Agent NLP Frameworks

## Quick Facts
- arXiv ID: 2503.11517
- Source URL: https://arxiv.org/abs/2503.11517
- Reference count: 26
- Primary result: Multi-agent NLP framework reduces prompt injection vulnerability score by 45.7% through layered defense mechanisms

## Executive Summary
This paper introduces a multi-agent NLP framework designed to detect and mitigate prompt injection attacks in generative AI systems. The approach employs specialized agents—including a front-end generator, guard/sanitizer, policy enforcer, and KPI evaluator—to systematically identify and neutralize injection attempts while ensuring policy compliance. The framework leverages the OVON standard for structured inter-agent communication via JSON messages and introduces novel metrics including Injection Success Rate (ISR), Policy Override Frequency (POF), Prompt Sanitization Rate (PSR), and Compliance Consistency Score (CCS) to quantify injection vulnerability and mitigation effectiveness.

## Method Summary
The framework implements a four-stage pipeline using Ollama with Meta Llama models: a vulnerable Front-End Generator produces initial responses, which are then processed by a Guard/Sanitizer that detects and removes malicious content using OVON JSON metadata, followed by a Policy Enforcer that ensures final compliance, and finally a KPI Evaluation Agent that calculates metrics including ISR, POF, PSR, CCS, and the composite Total Injection Vulnerability Score (TIVS). The system was evaluated on 500 engineered injection prompts across 10 categories, demonstrating substantial improvements in security with the Policy Enforcer reducing TIVS by 45.7% from -25.31 to -46.62.

## Key Results
- Multi-agent pipeline reduces Total Injection Vulnerability Score (TIVS) by 45.7%, from -25.31 to -46.62
- Policy Enforcer agent contributes significantly to vulnerability reduction by ensuring compliance using text and metadata
- Framework introduces four novel KPI metrics (ISR, POF, PSR, CCS) for quantifying injection vulnerability and mitigation effectiveness
- Modular architecture allows flexible integration of different open-weight LLMs while maintaining transparency through structured metadata exchange

## Why This Works (Mechanism)

### Mechanism 1: Layered Multi-Agent Sanitization
Processing user prompts through sequential specialized agents reduces TIVS by detecting and neutralizing malicious instructions at multiple stages. A sequential pipeline is established where a vulnerable Front-End Generator produces an initial response, which is then passed to a Guard/Sanitizer that detects and removes malicious content, and finally to a Policy Enforcer that ensures final compliance. Each downstream agent reviews the work of its predecessor.

### Mechanism 2: Structured Metadata for Contextual Enforcement
Using structured metadata to communicate about detected threats between agents enables more consistent and transparent policy enforcement than text review alone. The Guard/Sanitizer agent communicates with the Policy Enforcer using OVON JSON messages containing not only the `utterance` (sanitized text) but also `whisper` fields with structured metadata summarizing detected injection markers and explaining the remediation taken.

### Mechanism 3: Quantitative Vulnerability Scoring (TIVS)
A composite metric, the Total Injection Vulnerability Score (TIVS), derived from multiple Key Performance Indicators (KPIs), quantitatively measures the overall effectiveness of the mitigation strategy. A dedicated KPI Evaluation Agent calculates four metrics: Injection Success Rate (ISR), Policy Override Frequency (POF), Prompt Sanitization Rate (PSR), and Compliance Consistency Score (CCS), which are weighted and combined into a single TIVS score.

## Foundational Learning

### Concept: Prompt Injection Attack Types
Why needed: The paper categorizes attacks into ten types (A-J), such as Direct Override, Logical Traps, and Social Engineering. Understanding this taxonomy is critical for designing agent prompts and interpreting evaluation results.
Quick check: Can you explain how a "Hybrid (Legitimate + Injection)" attack (Category I) might evade a simple keyword-based filter?

### Concept: Multi-Agent Interoperability (OVON)
Why needed: The system's architecture is defined by how agents communicate. The OVON standard, using `utterance` and `whisper` fields in JSON, is the mechanism for passing both text and structured metadata.
Quick check: What is the purpose of the `whisper` field in an OVON message, and how does it differ from the `utterance`?

### Concept: Layered Defense (Defense-in-Depth)
Why needed: The framework's effectiveness relies on a chain of agents, each with a specific role (generate, sanitize, enforce). Understanding this principle is key to troubleshooting the pipeline.
Quick check: Why is the Front-End Generator explicitly configured *without* safety filters in this experimental setup?

## Architecture Onboarding

### Component map
User Prompt -> Front-End Generator (Llama 2) -> Guard/Sanitizer (Llama 3.1) -> Policy Enforcer (Llama 3.1) -> Final Output

### Critical path
The primary data flow is User Prompt -> Front-End Generator -> Guard/Sanitizer -> Policy Enforcer -> Final Output. The KPI Evaluator runs on the outputs from each stage.

### Design tradeoffs
The implementation uses open-weight models from a single family (Llama) for all agents. This promotes transparency and local execution but may limit the diversity of reasoning. The system is modular and can be adapted to other models (e.g., Mistral, Gemma) available in the Ollama framework.

### Failure signatures
A non-decreasing TIVS across agent stages, or a high final TIVS, particularly for attack categories G (Conflicting Instructions) and I (Hybrid), indicates a failure of the mitigation pipeline for that input type.

### First 3 experiments
1. Baseline Measurement: Process a dataset of known injection prompts through only the Front-End Generator to establish a baseline TIVS and confirm the model's vulnerability.
2. Ablation Study: Run the prompts through the full pipeline but selectively disable either the Guard/Sanitizer or the Policy Enforcer to quantify the individual contribution of each agent to the TIVS reduction.
3. Category-Specific Testing: Evaluate the system's performance separately on each of the ten attack categories (A-J) to identify which injection strategies are most and least effectively mitigated.

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset accessibility: The 500 engineered injection prompts used for evaluation are not publicly available, preventing independent replication of the claimed 45.7% TIVS reduction
- Effectiveness against sophisticated attacks: The framework's performance against real-world injection attacks remains uncertain, as evaluation focuses on controlled, synthetic prompts
- Model dependency: The system uses a single model family (Llama) across all agents, which may create shared blind spots and limit generalizability

## Confidence

### Major Uncertainties and Limitations
The framework demonstrates promise but has several critical limitations. The primary constraint is dataset accessibility—the 500 engineered injection prompts used for evaluation are not publicly available, preventing independent replication of the claimed 45.7% TIVS reduction. The effectiveness of the multi-agent pipeline against more sophisticated, real-world injection attacks remains uncertain, as the evaluation focuses on controlled, synthetic prompts. Additionally, the system's performance against Category G (Conflicting Instructions) and Category I (Hybrid) attacks is notably weaker, suggesting potential vulnerabilities against multi-step or context-dependent injection strategies.

### Confidence Labels
- **High Confidence:** The layered multi-agent architecture concept and the use of structured OVON metadata for inter-agent communication are technically sound and align with established security principles
- **Medium Confidence:** The specific TIVS metric values and the 45.7% improvement claim are reproducible only if the exact evaluation dataset becomes available
- **Low Confidence:** The long-term robustness of the system against adversarial techniques designed to exploit the specific architecture or the metadata communication channel has not been tested

## Next Checks
1. Independent Dataset Validation: Recreate or obtain a diverse set of real-world injection prompts and rerun the full pipeline to verify if similar TIVS improvements are observed
2. Cross-Model Family Testing: Implement the framework using a different open-weight model family (e.g., Mistral or Gemma) for at least one agent to assess whether the architecture's effectiveness is model-dependent
3. Adversarial Robustness Assessment: Design and test a new category of injection attacks specifically engineered to exploit the structured metadata communication (OVON `whisper` field) or the multi-agent pipeline structure itself