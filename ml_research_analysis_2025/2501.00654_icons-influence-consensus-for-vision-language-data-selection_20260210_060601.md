---
ver: rpa2
title: 'ICONS: Influence Consensus for Vision-Language Data Selection'
arxiv_id: '2501.00654'
source_url: https://arxiv.org/abs/2501.00654
tags:
- data
- tasks
- influence
- training
- selection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ICONS introduces a gradient-based influence consensus method for
  vision-language data selection that identifies training samples beneficial across
  multiple tasks through majority voting. The approach computes task-specific influence
  scores using first-order training dynamics, then aggregates them to find consistently
  valuable examples while avoiding outlier sensitivity.
---

# ICONS: Influence Consensus for Vision-Language Data Selection

## Quick Facts
- arXiv ID: 2501.00654
- Source URL: https://arxiv.org/abs/2501.00654
- Reference count: 40
- Primary result: Models trained on 20% ICONS-selected subsets retain 98.6-99.8% of full-dataset performance

## Executive Summary
ICONS introduces a gradient-based influence consensus method for vision-language data selection that identifies training samples beneficial across multiple tasks through majority voting. The approach computes task-specific influence scores using first-order training dynamics, then aggregates them to find consistently valuable examples while avoiding outlier sensitivity. Models trained on 20% selected subsets (LLAVA-ICONS-133K, CAMBRIAN-ICONS-1.4M, VISION-FLAN-ICONS-37K) retain 98.6-99.8% of full-dataset performance, significantly outperforming random selection (95.8-91.6%). The method generalizes to unseen tasks and model architectures, demonstrating strong transfer capabilities while enabling 5x reduction in training data.

## Method Summary
ICONS employs a two-stage approach: first, it warms up a LoRA-trained model on 5% of training data, then computes task-specific influence scores by measuring gradient alignment between training samples and validation sets across 10 VL tasks. Second, it aggregates these scores via majority voting, where samples above each task's 80th percentile receive votes, and selects the top-M voted samples. The method uses random projection to reduce gradient dimensionality from 338.7M to 5120 dimensions while preserving inner products. Final training uses 1 epoch LoRA on the selected subset, achieving 98.6% performance at 20% selection ratio compared to full data.

## Key Results
- Models trained on 20% ICONS-selected data retain 98.6% (LLAVA), 99.8% (CAMBRIAN), and 99.4% (VISION-FLAN) of full-dataset performance
- ICONS outperforms random selection by 2.8-8.2 percentage points across benchmarks
- Models trained on ICONS-selected subsets generalize to unseen tasks, achieving 97.3% of models trained on full data
- Selection ratio can be increased to 60% for improved performance (>102%) while maintaining efficiency gains

## Why This Works (Mechanism)

### Mechanism 1: Gradient Alignment Influence Estimation
ICONS uses first-order gradient information to estimate how each training sample influences validation loss, identifying samples whose gradients align with reducing task-specific errors. The method computes a first-order Taylor approximation of loss change when training on a sample z: I_t(z → z') ≈ -η_t ⟨∇ℓ(z'; θ_t), ∇ℓ(z; θ_t)⟩. Training samples with gradients similar to validation gradients are selected, as they directly reduce validation loss through SGD updates. Core assumption: First-order gradient alignment accurately approximates a training sample's contribution to validation performance, ignoring second-order curvature effects.

### Mechanism 2: Cross-Task Majority Voting Consensus
Aggregating task-specific influence scores via majority voting identifies training samples beneficial across multiple tasks, avoiding outlier sensitivity and calibration issues. For each task k, samples above a percentile threshold τ_k receive a vote. Total votes I_vote(z_i) = Σ_k 1[Ī_k(z_i) ≥ τ_k] select samples with broad multi-task utility, bypassing need for cross-task score calibration. Core assumption: Samples beneficial for multiple tasks (high votes) generalize better to unseen tasks than samples optimal for a single task.

### Mechanism 3: Gradient Dimensionality Reduction via Random Projection
Random projection preserves gradient inner products with high probability while reducing storage and computation costs. Gradients g̃_i = R g_i where R ∈ R^(d'×d) (d' ≪ d) is a random projection matrix. Inner products ⟨g̃_i, g̃'_j⟩ approximate ⟨g_i, g'_j⟩ due to Johnson-Lindenstrauss lemma. Core assumption: Projected dimension d'=5120 (reduced from 338.7M LoRA parameters) preserves enough information for accurate influence ranking.

## Foundational Learning
- **First-order Taylor approximation**: Core to estimating influence without expensive Hessian computation. Quick check: Given loss function ℓ, how would you approximate ℓ(θ + Δθ) using only gradients?
- **LoRA (Low-Rank Adaptation)**: ICONS uses LoRA during warmup and gradient computation; understanding trainable parameter count is critical. Quick check: If base model has 7B parameters, how many are trainable after LoRA? (Hint: paper states 338.7M ≈ 4.58%)
- **Validation set as task proxy**: Influence is computed against validation sets representing target tasks; poor validation coverage leads to poor selection. Quick check: If your target task has 10K test samples but validation set has only 50, what risk does this introduce?

## Architecture Onboarding
- **Component map**: Specialist Stage (warmup training → gradient computation → random projection → influence matrix → per-sample average scores) -> Generalist Stage (per-task percentile thresholds → binary votes → sum votes → select top-M by total votes) -> Output (selected subset indices)
- **Critical path**: 1) Warmup training (~0.75 hrs on 8 L40 GPUs for LLAVA-665K) 2) Gradient computation (parallelized, ~1 hr on 100 A6000 GPUs) 3) Influence matrix computation and voting (<1 min on single GPU)
- **Design tradeoffs**: Projection dimension: Higher d' preserves more information but increases storage (103GB for LLAVA-665K). Paper uses 5120; ablation shows plateau around this value. Warmup ratio: Paper finds 5% optimal; more warmup (up to 100%) degrades selection performance (97.8% vs 98.6%). Selection ratio: 20% retains 98.6% performance; 60% achieves >102% (exceeds full data), suggesting full data contains harmful samples.
- **Failure signatures**: Low consensus (many zero-vote samples): At 5% selection, 72.1% get zero votes → selection may overfit to specific tasks. Task-specific outliers: Round Robin or MinRank aggregation overfit to outlier tasks at expense of others. Score calibration issues: Direct score aggregation (Merge, Max) fails when tasks have different influence score distributions (std dev varies 6.5x across tasks).
- **First 3 experiments**: 1) Baseline comparison: Train on 20% randomly selected data vs full data on your target benchmarks to establish Rel. baseline (expect ~92-96% as per paper). 2) Ablate projection dimension: Test d' = [1024, 2560, 5120, 10240] on a held-out task to verify plateau around 5120 (see Appendix Fig. 5a). 3) Cross-validation of selection: Use data selected via one model architecture (e.g., 7B) to train a different architecture (e.g., 13B) and measure Rel. degradation (paper shows 97.3% transfer).

## Open Questions the Paper Calls Out
- **Weighted voting mechanisms**: The majority voting mechanism may under-represent tasks with unique characteristics or those in the long tail. Future work could explore weighted voting mechanisms, in which tasks are assigned weights based on their relative importance or contribution to overall model performance for more balanced data selection.
- **Scaling to larger datasets**: The approach's main limitation is computational expense: computing gradients for large datasets is costly, requiring 103GB storage for LLaVA-665K and scaling linearly with dataset size, potentially constraining applicability to extremely large-scale data.
- **Identifying harmful samples**: ICONS achieves >102% relative performance at 60% selection, with the hypothesis that it filters potentially harmful or noisy training samples. However, no systematic analysis identifies which samples are harmful and why, or what specific failure modes of full-dataset training are avoided.
- **Extending beyond visual instruction tuning**: While focusing on visual instruction tuning data, the influence consensus approach can be naturally extended to other stages of MLLM training, such as alignment stage. Different stages may require different reference models or influence formulations to capture stage-specific training dynamics.

## Limitations
- Computational expense: Computing gradients for large datasets is costly, requiring 103GB storage for LLaVA-665K and scaling linearly with dataset size
- First-order approximation limitations: The method ignores Hessian curvature effects, potentially missing interactions between samples in non-convex VLM loss landscapes
- Task conflict potential: Majority voting assumes beneficial samples are broadly useful, but may dilute performance on specialized tasks when task objectives conflict

## Confidence
- **High confidence**: Relative performance claims (98.6% at 20% selection, 99.8% at 60%) - directly measured and consistent across multiple model sizes
- **Medium confidence**: Cross-task generalization claims - supported by architecture transfer experiments but limited to LLAVA/CAMBRIAN/VISION-FLAN domains
- **Low confidence**: Computational efficiency claims - GPU time estimates provided but real-world scaling with larger datasets not demonstrated

## Next Checks
1. Validate projection dimension sensitivity by testing d' = [1024, 2560, 5120, 10240] on a held-out task to confirm performance plateau around 5120
2. Test selection stability by running ICONS 5 times with different random seeds and measuring variance in selected subsets
3. Evaluate task-specific performance degradation when consensus threshold is varied (τ_k = 75th, 80th, 85th percentile) to quantify specialization-generalization tradeoff