---
ver: rpa2
title: 'KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs'
arxiv_id: '2507.13666'
source_url: https://arxiv.org/abs/2507.13666
tags:
- response
- representative
- responses
- gpt-4
- cascade
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the high cost of using large language models
  (LLMs) by proposing a cascade framework that uses a weaker, cheaper model to generate
  multiple responses and only escalates to a stronger model when necessary. The key
  innovation is a keyword-weighted response selection mechanism that identifies a
  representative answer and evaluates the semantic consistency of other responses
  based on term-level similarity rather than exact text matching.
---

# KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs

## Quick Facts
- **arXiv ID**: 2507.13666
- **Source URL**: https://arxiv.org/abs/2507.13666
- **Reference count**: 24
- **Key outcome**: Achieves 97.53% of GPT-4's accuracy while reducing API costs by 28.81% on average

## Executive Summary
This paper addresses the high cost of using large language models (LLMs) by proposing a cascade framework that uses a weaker, cheaper model to generate multiple responses and only escalates to a stronger model when necessary. The key innovation is a keyword-weighted response selection mechanism that identifies a representative answer and evaluates the semantic consistency of other responses based on term-level similarity rather than exact text matching. This approach enables effective handling of free-form text generation tasks where responses may be semantically equivalent but lexically diverse. Experiments across three benchmarks show that the proposed method achieves 97.53% of GPT-4's accuracy while reducing API costs by 28.81% on average, and even outperforms GPT-4 in one benchmark. The method demonstrates both cost efficiency and performance gains through the complementary use of models with different capabilities.

## Method Summary
The KiC framework implements a two-stage cascade architecture where a weaker LLM (GPT-3.5-turbo) generates N=10 responses per query with temperature=1.0. The method extracts top-k frequent keywords from all responses, assigns higher weights to these keywords during TF-IDF computation, and selects the response with the highest weighted score as representative. Consistency evaluation counts responses scoring at or above the representative's normalized TF-IDF score. If the count Nsim meets or exceeds threshold τ, the representative response is returned; otherwise, the query escalates to the stronger LLM (GPT-4, temperature=0.0). The approach leverages the empirical observation that LLM consistency correlates with correctness, enabling cost-effective routing decisions.

## Key Results
- Achieves 97.53% of GPT-4 accuracy while reducing API costs by 28.81% on average
- Outperforms GPT-4 in MMLU-Professional Psychology benchmark (73.67% vs 72.31%)
- Optimal threshold τ=7-9 provides the best balance between cost and accuracy across benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Keyword-weighted TF-IDF scoring identifies a representative response that reflects the semantic consensus of multiple weak model outputs.
- Mechanism: Top-k frequent keywords are extracted from all responses and assigned weight α > 1 during TF-IDF computation. L2-norm normalization prevents length bias. The response with the highest weighted score is selected as representative.
- Core assumption: Frequent terms across responses correlate with semantic correctness and consensus.
- Evidence anchors:
  - [abstract]: "KiC identifies the most representative answer among multiple outputs from a weaker model"
  - [section III-B]: "we extract the top-k most frequent keywords from the response cluster. These keywords receive higher weights during TF-IDF computation"
  - [corpus]: Weak direct evidence; corpus papers focus on cost-efficiency broadly, not keyword-based selection specifically.
- Break condition: When frequent terms are misleading (e.g., common misconceptions repeated across responses), representative selection may amplify errors.

### Mechanism 2
- Claim: Keyword-weighted similarity scoring captures semantic alignment between free-form responses better than exact matching.
- Mechanism: Keywords from the representative response receive weight β > α > 1. Responses scoring ≥ the representative's normalized TF-IDF score are counted as semantically similar (Nsim).
- Core assumption: Term overlap weighted by keyword importance approximates semantic equivalence despite lexical variation.
- Evidence anchors:
  - [abstract]: "evaluates the semantic alignment of other responses with it"
  - [section III-C]: "assign higher weights to the keywords in the representative response. This ensures that responses with similar term usage receive higher scores"
  - [corpus]: No direct corpus evidence for this specific mechanism.
- Break condition: Semantically equivalent responses using synonyms or paraphrases without keyword overlap will be incorrectly flagged as inconsistent.

### Mechanism 3
- Claim: Threshold-based escalation enables cost reduction while preserving accuracy by exploiting the correlation between response consistency and correctness.
- Mechanism: If Nsim ≥ τ, return the representative response; otherwise invoke the stronger LLM. The threshold τ controls the cost-accuracy tradeoff.
- Core assumption: LLMs produce consistent responses when confident/correct and diverse responses when uncertain/incorrect (self-consistency principle).
- Evidence anchors:
  - [section I]: "LLMs to produce consistent responses when their answers are correct, and diverse responses when they are incorrect"
  - [section IV-B]: "optimal balance between cost and accuracy observed in the range τ = 7 to 9"
  - [corpus]: SATER paper (arXiv:2510.05164) similarly uses threshold-based routing for cost-quality tradeoffs.
- Break condition: When incorrect responses are consistent (systematic errors), or correct responses are inconsistent (legitimate diversity), threshold decisions misroute.

## Foundational Learning

- Concept: **Self-consistency in LLMs**
  - Why needed here: The entire cascade logic rests on the empirical observation that model consistency correlates with answer correctness.
  - Quick check question: If an LLM generates 10 responses to "What is 2+2?" and 9 say "4" while 1 says "5," what does high consistency suggest?

- Concept: **TF-IDF weighting**
  - Why needed here: KiC modifies standard TF-IDF with keyword weights; understanding baseline TF-IDF is prerequisite to grasping the modification.
  - Quick check question: Why does TF-IDF downweight common words like "the" compared to rare content words?

- Concept: **Cascade architecture pattern**
  - Why needed here: KiC is one instance of a broader cost-accuracy tradeoff pattern; recognizing this helps generalize the approach.
  - Quick check question: In a two-model cascade, what information must be extracted from the weaker model to decide whether to escalate?

## Architecture Onboarding

- Component map:
  - Query -> Weak LLM (GPT-3.5-turbo, T=1.0) -> 10 responses -> Keyword Extractor -> Top-k frequent keywords -> Keyword-weighted TF-IDF scorer -> Representative Selector (argmax) -> Consistency Evaluator (β-weighted scoring) -> Decision Router (threshold comparison) -> Final output (weak representative OR strong LLM fallback)

- Critical path: Query → Weak LLM → 10 responses → Keyword extraction → Representative selection → Consistency scoring → Threshold decision → Final output (weak representative OR strong response)

- Design tradeoffs:
  - Higher τ: More escalations, higher cost, higher accuracy (conservative routing)
  - Lower τ: Fewer escalations, lower cost, risk accepting incorrect weak outputs
  - N (number of responses): More responses improve consistency estimation but increase weak model API costs
  - Assumption: The paper uses α and β weights but does not specify exact values; these require tuning.

- Failure signatures:
  - **Consistent errors**: Weak model confidently wrong → Nsim high → incorrect output accepted
  - **Legitimate diversity**: Multiple valid answers for open-ended questions → Nsim low → unnecessary escalation
  - **Keyword mismatch**: Synonym-heavy responses → low TF-IDF overlap → false inconsistency detection

- First 3 experiments:
  1. **Reproduce threshold sweep**: Run KiC on TruthfulQA with τ ∈ {1,...,10}, plot accuracy vs. cost curve, verify the τ=7-9 optimal range.
  2. **Ablate keyword weighting**: Replace keyword-weighted TF-IDF with standard TF-IDF; measure accuracy drop to quantify the contribution of keyword weighting.
  3. **Test break condition**: Construct adversarial queries where frequent terms are misleading (e.g., common misconceptions); measure false acceptance rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can KiC generalize to open-source model cascades or different API pairs without significant performance degradation?
- Basis: [inferred] The experimental scope is limited strictly to the GPT-3.5-turbo and GPT-4 pair.
- Why unresolved: Keyword distributions and self-consistency patterns may differ substantially across model architectures and training data.
- What evidence would resolve it: Applying KiC to open-source cascades (e.g., Llama-2 to Llama-3) or alternative proprietary pairs (e.g., Claude Haiku to Opus).

### Open Question 2
- Question: How sensitive is the performance to the decision threshold $\tau$ when applied to entirely new domains without tuning?
- Basis: [inferred] The authors note the threshold is "empirically explored" and results show variance in optimal $\tau$ across the three benchmarks.
- Why unresolved: It is unclear if a single robust $\tau$ exists or if the method requires per-domain validation sets to be cost-effective.
- What evidence would resolve it: A cross-domain analysis testing a fixed $\tau$ derived from one benchmark on unseen datasets.

### Open Question 3
- Question: Does the keyword-based similarity metric fail to distinguish semantic opposites (e.g., "is effective" vs. "is not effective") that share high lexical overlap?
- Basis: [inferred] The method relies on TF-IDF and frequency weights, which are bag-of-words approaches that generally ignore syntactic negation.
- Why unresolved: High term overlap between a correct answer and a negated incorrect answer could mislead the consistency evaluation.
- What evidence would resolve it: Evaluation on adversarial examples specifically designed to test negation and antonym handling in free-form generation.

## Limitations

- **Hyperparameter sensitivity**: The method requires tuning of keyword weights (α, β) and threshold τ, with performance potentially varying significantly across domains.
- **Consistent error vulnerability**: The approach may accept incorrect responses when weak models produce consistent but wrong answers, as high consistency can correlate with systematic errors.
- **Lexical limitation**: The TF-IDF-based similarity metric may struggle with semantic equivalence expressed through synonyms or paraphrases, potentially missing valid diverse answers.

## Confidence

- **High confidence**: The cascade architecture pattern itself is well-established and KiC's threshold-based routing mechanism follows standard design patterns. The empirical cost reduction (28.81%) and accuracy retention (97.53%) are specific, measurable claims supported by experimental results across multiple benchmarks.
- **Medium confidence**: The keyword-weighted TF-IDF scoring mechanism is technically sound but relies on unstated hyperparameters. The claim that this approach outperforms exact text matching for semantic alignment is reasonable given TF-IDF's known properties, but requires parameter tuning for optimal performance.
- **Low confidence**: The specific performance superiority over GPT-4 in the MMLU-Professional Psychology benchmark (73.67% vs 72.31%) may be domain-specific and not generalizable. Without detailed ablation studies isolating each mechanism's contribution, it's unclear which components drive performance gains versus cost savings.

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary α and β across the valid range (1 < α < β) on a single benchmark, measuring accuracy and cost at each point. Identify whether performance is robust to parameter choice or requires precise tuning, and whether the stated results depend on specific values.

2. **Adversarial consistency test**: Construct a test set where common misconceptions generate consistent but incorrect responses (e.g., "humans only use 10% of their brain"). Measure false acceptance rate to quantify the method's vulnerability to consistent errors, and compare against a random selection baseline.

3. **Semantic equivalence evaluation**: Create response pairs that are semantically equivalent but lexically diverse (e.g., using synonyms or paraphrases). Measure whether KiC correctly identifies them as consistent versus incorrectly flagging them as inconsistent, quantifying the method's robustness to lexical variation.