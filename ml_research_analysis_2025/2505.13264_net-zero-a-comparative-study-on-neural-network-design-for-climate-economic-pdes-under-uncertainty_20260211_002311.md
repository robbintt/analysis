---
ver: rpa2
title: 'Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic
  PDEs Under Uncertainty'
arxiv_id: '2505.13264'
source_url: https://arxiv.org/abs/2505.13264
tags:
- uni00000011
- uni00000013
- uni00000014
- uni00000015
- uni00000016
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational challenges of climate-economic
  modeling under uncertainty by exploring neural network-based approaches for solving
  high-dimensional optimal control problems. The authors develop a continuous-time
  endogenous-growth economic model incorporating ambiguity aversion and multiple mitigation
  pathways, resulting in complex partial differential equations that are computationally
  intractable with traditional numerical methods.
---

# Net-Zero: A Comparative Study on Neural Network Design for Climate-Economic PDEs Under Uncertainty

## Quick Facts
- arXiv ID: 2505.13264
- Source URL: https://arxiv.org/abs/2505.13264
- Reference count: 40
- Primary result: MLP-based neural networks with SiLU activations and residual connections consistently achieve the lowest error rates and outperform specialized alternatives like SIREN and self-attention networks for solving climate-economic HJB PDEs.

## Executive Summary
This paper addresses the computational challenges of climate-economic modeling under uncertainty by exploring neural network-based approaches for solving high-dimensional optimal control problems. The authors develop a continuous-time endogenous-growth economic model incorporating ambiguity aversion and multiple mitigation pathways, resulting in complex partial differential equations that are computationally intractable with traditional numerical methods. The study systematically benchmarks several neural network architectures against finite-difference solutions, evaluating their ability to capture dynamic interactions between uncertainty, technology transitions, and optimal climate policy.

The research finds that appropriate neural architecture selection significantly impacts both solution accuracy and computational efficiency. Specifically, MLP-based networks with SiLU activations and residual connections consistently achieve the lowest error rates and outperform specialized alternatives like SIREN and self-attention networks. The combined error-efficiency metric highlights the practical superiority of MLP-MLP configurations, achieving considerably better efficiency than attention-based alternatives. These findings provide valuable insights for designing neural PDE solvers for climate policy applications and enable more sophisticated modeling of technology transitions under uncertainty.

## Method Summary
The study employs a two-network adversarial framework based on the Deep Galerkin Method with Policy Iteration Algorithm (DGM-PIA) to solve a 3-state Hamilton-Jacobi-Bellman (HJB) equation arising from a continuous-time endogenous-growth economic model with ambiguity aversion. The framework consists of a value network Vθ that approximates the value function and a policy network Pϕ that returns control variables (i_L, i_H). The value network's loss is defined by the HJB equation residual, while the policy network is trained to maximize expected value subject to PDE dynamics. The authors benchmark several neural architectures including MLPs, SIREN, Fourier Neural Operators, and self-attention networks, training them with AdamW optimizer and comparing results against finite-difference solutions generated on a 60³ grid.

## Key Results
- MLP-based networks with SiLU activations and residual connections consistently achieve the lowest error rates across all metrics
- Specialized architectures (SIREN, self-attention) underperform despite theoretical advantages, showing significant performance gaps
- MLP-MLP configurations demonstrate superior efficiency in the combined error-efficiency metric compared to attention-based alternatives
- The value network architecture has asymmetric impact on overall performance, requiring more tuning effort than the policy network

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A two-network adversarial framework enables simultaneous optimization of value functions and control policies for Hamilton-Jacobi-Bellman equations arising in climate-economic models.
- Mechanism: The value network Vθ approximates the value function while the policy network Pϕ returns control variables. The value network's loss is defined by the HJB equation residual; the policy network is trained to maximize expected value subject to PDE dynamics. Alternating optimization creates adversarial pressure toward consistent solutions.
- Core assumption: Optimal policies can be learned through iterative co-adaptation with value function approximations, following the Deep Galerkin Method with Policy Iteration Algorithm (DGM-PIA).
- Evidence anchors:
  - [abstract] "neural network-based approaches for solving high-dimensional optimal control problems arising from models that incorporate ambiguity aversion"
  - [section 5] "two separate networks that work in tandem following an adversarial framework... value network's loss is defined by the residual of the HJB equation"
  - [corpus] AL-PINN paper addresses active learning for physics-informed neural networks in PDE solving, supporting mesh-free neural approaches
- Break condition: If value and policy networks converge to local equilibria with conflicting objectives, adversarial training destabilizes; gradient clipping and differential learning rates mitigate this.

### Mechanism 2
- Claim: SiLU activations with residual connections improve gradient flow and convergence stability for neural PDE solvers compared to TanH baselines.
- Mechanism: SiLU(x) = x · σ(x) provides smoother gradients than bounded activations, beneficial around discontinuities from technological jumps. Residual connections (h_{i+1} = h_i + f_i(h_i)) preserve gradient magnitude through depth, enabling stable training in 5+ layer networks.
- Core assumption: Climate-economic PDE solutions benefit from smooth gradient propagation; high-frequency components play a secondary role in the HJB formulation.
- Evidence anchors:
  - [section 5] "SiLU activations provide smoother gradients, particularly beneficial around the discontinuities caused by technological jumps in our model"
  - [section 6] "MLP-based networks consistently achieve the lowest error rates... outperforming specialized alternatives like SIREN and self-attention networks"
  - [corpus] Weak direct corpus evidence on SiLU for PDEs; related work on PINNs focuses on architecture rather than activation specifically
- Break condition: If the PDE solution contains sharp discontinuities requiring high-frequency representation, SiLU's smoothing may underperform against periodic activations (SIREN).

### Mechanism 3
- Claim: Standard MLPs outperform specialized architectures (SIREN, FNO, self-attention) for climate-economic HJB equations due to alignment between universal approximation and problem smoothness.
- Mechanism: The optimal policy functions in climate-economic models exhibit relatively smooth, low-frequency characteristics. MLPs with residual connections leverage universal approximation without imposing inductive biases misaligned with the solution manifold's spectral properties.
- Core assumption: Climate-economic HJB solutions have inherently smooth solution manifolds; complex inductive biases introduce unnecessary optimization difficulty.
- Evidence anchors:
  - [section 6] "smoothness properties of climate-economic solution manifolds may be better captured by the universal approximation capabilities of MLPs"
  - [section 6] "significant performance gap between theoretical expectations and empirical results for specialized architectures (Self-Attention and SIREN)"
  - [corpus] CALM-PDE explores latent space modeling for time-dependent PDEs, suggesting domain-specific architecture choices matter
- Break condition: If the problem scales to include sharp technological transition boundaries or requires multi-scale dynamics, specialized architectures may recover advantage.

## Foundational Learning

- Concept: Hamilton-Jacobi-Bellman (HJB) Equations
  - Why needed here: The climate-economic model is formulated as a continuous-time stochastic optimal control problem yielding a 3-state HJB equation (Equation 20).
  - Quick check question: Can you derive the first-order conditions for optimal controls i*_L and i*_H from the HJB gradient terms?

- Concept: Deep Galerkin Method (DGM) and Physics-Informed Neural Networks
  - Why needed here: The two-network framework builds on DGM's mesh-free approach using domain sampling to satisfy PDE residuals.
  - Quick check question: How does the DGM loss function combine PDE residual terms with boundary conditions without explicit mesh discretization?

- Concept: Itô's Lemma and Stochastic Differential Equations
  - Why needed here: The economic model uses stochastic dynamics (Wiener processes W_L, W_H, W_Γ) requiring Itô calculus for law-of-motion derivations.
  - Quick check question: Why does the law of motion for S_L (Equation 11) contain the additional ½(σ_L S_L)² term compared to a deterministic ODE?

## Architecture Onboarding

- Component map:
  - Input layer: 3-dimensional state (k, S_L, Γ) normalized to bounded domain
  - Value network Vθ: 5 hidden layers × 512 neurons, SiLU activations, residual connections every layer
  - Policy network Pϕ: 5 hidden layers × 1024 neurons, SiLU activations, residual connections
  - Output: Vθ → scalar value; Pϕ → 2 controls (ι_L, ι_H) with sigmoid boundary enforcement
  - Optimizer: AdamW (β_1=0.9, β_2=0.99), weight decay 0.04, gradient clipping 1.0
  - Learning rates: 0.001 (P), 0.0005 (V), no consistent benefit from schedulers

- Critical path:
  1. Implement finite-difference solver (60³ grid, tolerance 10⁻⁸) for ground truth generation
  2. Construct HJB residual loss incorporating drift (B terms), diffusion (C terms), and utility (D term)
  3. Implement alternating training: 20 P-steps, 20 V-steps per batch of 4096 samples
  4. Validate against FD grid using geometric mean error L_final (Equation 39)

- Design tradeoffs:
  - MLP vs specialized architectures: MLPs offer 6× faster training with comparable/lower error; specialized architectures add complexity without empirical gain
  - Value vs Policy network investment: Value network architecture has asymmetric impact on overall performance—allocate more tuning effort to Vθ
  - Depth vs width: 5-layer configuration balances expressivity and trainability; deeper networks showed diminishing returns

- Failure signatures:
  - SIREN underperformance: Periodic activations mismatch with smooth solution structure, causing oscillatory artifacts
  - Self-attention instability: Attention mechanisms overfit to sampling noise in low-dimensional state space
  - Value network underfitting: Systematic policy errors propagate; check V-gradient magnitudes against FD benchmark

- First 3 experiments:
  1. Baseline MLP-MLP with SiLU+residual on 3-state HJB, training 500 epochs, measuring L_final against FD ground truth
  2. Ablation comparing V-network architectures (MLP vs LSTM vs FNO) with fixed MLP P-network to isolate value approximation effects
  3. Learning rate sensitivity: grid search over [0.0001, 0.0005, 0.001] for V and [0.0005, 0.001, 0.002] for P with AdamW

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do neural architecture rankings change when scaling to higher-dimensional climate-economic PDEs with additional state variables (e.g., carbon capture technologies, multiple regional economies)?
- Basis in paper: [explicit] Conclusion states: "Future work should... explore higher-dimensional problems that incorporate additional mitigation technologies such as carbon capture."
- Why unresolved: Current benchmarks use a 3-state model specifically chosen for tractability with finite-difference methods; scalability remains untested.
- What evidence would resolve it: Systematic evaluation of architectures on 4+ dimensional climate-economic PDEs with documented accuracy and computational cost.

### Open Question 2
- Question: Why do specialized architectures (SIREN, self-attention) underperform despite theoretical advantages for high-frequency components?
- Basis in paper: [inferred] Results show "poor performance of SIREN and Self-Attention networks, despite their theoretical advantages" suggesting misalignment between inductive biases and actual PDE properties.
- Why unresolved: Paper speculates on smoothness properties but provides no systematic analysis of frequency content or discontinuity structure in solutions.
- What evidence would resolve it: Spectral analysis of value/policy functions; controlled experiments with artificially induced high-frequency components.

### Open Question 3
- Question: Do findings generalize across different climate-economic model formulations, or are they specific to this particular HJB structure?
- Basis in paper: [inferred] Model chosen "for its relative simplicity" for benchmarking; no validation on alternative economic frameworks mentioned in literature review.
- Why unresolved: Single model architecture tested; transferability to other IAM formulations (DICE variants, models with different damage functions) unknown.
- What evidence would resolve it: Cross-model validation showing consistent architecture rankings across multiple climate-economic PDE formulations.

### Open Question 4
- Question: What principled hyperparameter selection methods could replace computationally infeasible exhaustive search?
- Basis in paper: [explicit] "It is, however, computationally unfeasible to test every possible combination of model design, size, optimization type, regularization, and every other hyperparameter choice."
- Why unresolved: Current approach uses fixed hyperparameters found through non-systematic search; no guarantees of optimality.
- What evidence would resolve it: Development of adaptive or theory-driven hyperparameter selection achieving comparable or better results with reduced search cost.

## Limitations
- The paper does not specify the economic model parameters and state space bounds, preventing exact reproduction
- Results may not generalize to problems with sharp discontinuities or multi-scale dynamics where specialized architectures could recover advantage
- The adversarial training framework may exhibit instability in edge cases not explored in the study

## Confidence
- **High confidence**: MLP-SiLU with residual connections consistently outperforming specialized architectures (SIREN, attention) for this problem class; the adversarial two-network framework's basic implementation
- **Medium confidence**: The claim that climate-economic solution manifolds are inherently smooth and low-frequency; the specific learning rate asymmetry (P=0.001, V=0.0005) being optimal
- **Low confidence**: Generalization to problems with sharp discontinuities or multi-scale dynamics; whether specialized architectures would recover advantage with different initialization or regularization

## Next Checks
1. Perform parameter sensitivity analysis: systematically vary the economic parameters (ρ, α, σ_Γ, etc.) to test architecture performance robustness across the model's parameter space
2. Edge case testing: evaluate all architectures on HJB problems with artificially introduced discontinuities to identify where SIREN/attention might recover advantage
3. Computational scaling study: benchmark training time and memory usage as state dimensionality increases beyond 3 to assess practical limits of the MLP-SiLU approach