---
ver: rpa2
title: 'Jacobian Scopes: token-level causal attributions in LLMs'
arxiv_id: '2601.16407'
source_url: https://arxiv.org/abs/2601.16407
tags:
- scope
- input
- temperature
- scopes
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Jacobian Scopes, a suite of gradient-based,
  token-level causal attribution methods for interpreting LLM predictions. By analyzing
  the Jacobian matrix, which captures the linearized relation between the predictive
  distribution and input tokens, Jacobian Scopes quantify how input tokens influence
  a model's prediction.
---

# Jacobian Scopes: token-level causal attributions in LLMs

## Quick Facts
- **arXiv ID:** 2601.16407
- **Source URL:** https://arxiv.org/abs/2601.16407
- **Reference count:** 34
- **Key outcome:** Introduces Jacobian Scopes, a suite of gradient-based methods for token-level causal attribution in LLMs by analyzing the Jacobian matrix of the linearized input-output mapping

## Executive Summary
Jacobian Scopes are a suite of gradient-based methods that quantify how individual input tokens influence LLM predictions by analyzing the Jacobian matrix of the linearized relation between the final hidden state and input tokens. Three variants—Semantic Scope, Fisher Scope, and Temperature Scope—target different aspects of the model's output: specific logits, the full predictive distribution, and model confidence respectively. Through case studies on instruction understanding, translation, and in-context time-series forecasting, the methods reveal semantic reasoning processes, expose implicit biases, and provide insights into how LLMs extrapolate temporal data.

## Method Summary
Jacobian Scopes compute token-level influence by projecting the input-to-output Jacobian onto specific vectors. Semantic Scope targets a specific logit by projecting onto the unembedding vector of the target token. Fisher Scope targets the full predictive distribution by computing the trace of the Fisher Information Matrix pulled back to the input space. Temperature Scope targets model confidence by projecting onto the direction of the final hidden state. All methods use automatic differentiation to compute the Jacobian, with Semantic and Temperature requiring one backward pass while Fisher requires d_model passes.

## Key Results
- Successfully identifies which input tokens influence specific predictions in instruction understanding tasks
- Reveals implicit political biases in LLMs through semantic attribution analysis
- Shows that LLMs perform in-context time-series forecasting via pattern matching for chaotic systems but rely on recent tokens for stochastic processes

## Why This Works (Mechanism)

### Mechanism 1
The influence of input tokens on a specific output logit (Semantic Scope) can be quantified by projecting the input-output Jacobian onto the unembedding vector of the target token. The method computes the L_2 norm of the vector-matrix product v^T J_t, where v = w_target is the row of the unembedding matrix corresponding to the predicted token. This measures the maximal first-order change in the target logit induced by an infinitesimal perturbation to the input token embedding.

### Mechanism 2
The influence of input tokens on the entire predictive distribution (Fisher Scope) is governed by the trace of the Fisher Information Matrix (FIM) pulled back to the input space. This approach measures sensitivity of the full probability distribution p(·|X) rather than a single logit. It constructs a local quadratic form using the FIM F_u in the hidden state space and pulls it back through the Jacobian J_t to get F_t = J_t^T F_u J_t. The trace tr(F_t) summarizes the expected KL-divergence induced by isotropic input noise.

### Mechanism 3
Input tokens influence model confidence (Temperature Scope) by affecting the norm of the final hidden state, which acts as an effective inverse temperature β_eff. The method decomposes the hidden state y into norm ||y||_2 and direction ŷ. It projects the Jacobian onto the direction ŷ to find tokens that maximize changes to the norm. Increasing the norm "sharpens" the distribution (increases confidence) without changing the logit ranking.

## Foundational Learning

- **The Jacobian Matrix**: Represents the linear map of how small changes in input tokens (x_t) affect the final hidden state (y). Needed to quantify input-output sensitivity for all Scopes.
  - *Quick check:* If the Jacobian J_t is near-zero for a specific input token, what does that imply about that token's local influence on the prediction?

- **Softmax Temperature**: Temperature Scope relies on the identity that the norm of the hidden state acts as an inverse temperature (β) for the output distribution. Needed to understand how norm changes affect distributional sharpness.
  - *Quick check:* Does increasing the norm of the hidden state vector make the output probability distribution sharper (more confident) or flatter (more uncertain)?

- **Fisher Information Matrix (FIM)**: Fisher Scope uses the FIM to define a metric on the probability distribution space, allowing measurement of "distance" between distributions (KL divergence) induced by input changes. Needed to capture full distributional sensitivity beyond single logits.
  - *Quick check:* Why is the FIM necessary for Fisher Scope instead of just using Euclidean distance on the logits?

## Architecture Onboarding

- **Component map**: Input Layer (token embeddings x_t) -> Model Core (transformer function f(·) mapping to final hidden state y) -> Output Layer (unembedding matrix W mapping y to logits z) -> Probes (projection vectors v used to collapse Jacobian into scalar influence scores)

- **Critical path**: 1) Select Scope (choose projection vector v or target distribution), 2) Define Loss (construct scalar loss L = v^T y or prepare for full Jacobian), 3) Auto-diff (compute gradients ∂L/∂x_t via backprop; 1 backward pass for Semantic/Temp, d_model for Fisher), 4) Norm Calculation (compute ||∂L/∂x_t||_2 to get influence score)

- **Design tradeoffs**: Semantic vs. Fisher (Semantic is fast O(1) but blind to non-target logits; Fisher is comprehensive O(d_model) but computationally expensive); Temperature vs. Fisher (Temperature is a cheap proxy O(1) for distributional sensitivity but may miss nuanced logit shifts); Integrated Gradients (paper advises against path-integration for LLMs due to "attention sink" noise and high compute cost)

- **Failure signatures**: Attention Sinks (early context tokens show artificially high influence scores due to architectural artifacts rather than semantic meaning); Out-of-Distribution (OOD) Gradients (far from training manifold, gradients may be uninformative or noisy); Saturation (extremely confident model, gradients might vanish showing zero influence even for relevant tokens)

- **First 3 experiments**: 1) Sanity Check (Semantic Scope): Run on simple subject-verb agreement task; verify verb prediction attributes strongly to subject noun, not stopwords; 2) Efficiency Benchmark (Temp vs. Fisher): Compare runtime and attribution maps on translation task with >500 tokens; quantify speedup and visual similarity; 3) Bias Detection (Semantic Scope): Replicate political bias experiment by prompting with entity names and checking if geographic tokens attribute strongly to "liberal"/"conservative" logits

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the spectral structure of the Jacobian and Fisher matrices be utilized to develop new, more informative Jacobian Scopes? The discussion section lists this as a "promising direction for future work," suggesting current three variants are not exhaustive.

- **Open Question 2**: Do LLMs perform in-context time-series forecasting primarily via nearest-neighbor search in delayed embedding space? Authors note their attribution signatures support this "conjecture" but stop short of confirming the mechanism.

- **Open Question 3**: How can attribution methods mitigate the "attention sink" phenomenon to distinguish semantic influence from architectural artifacts? The paper states Temperature Scope shows elevated influence for early context tokens due to this phenomenon.

## Limitations

- **Computational Scalability**: Temperature Scope claims to be efficient for long-context regimes but lacks quantified runtime comparisons against Fisher Scope for contexts exceeding 2048 tokens.

- **Attention Sink Artifacts**: Early tokens show artificially high influence scores due to architectural artifacts, with vague mitigation strategies that lack validation.

- **Local Linearity Assumption**: All three Scopes rely on first-order Taylor expansion without establishing quantitative bounds on perturbation size or testing scenarios with strong non-linear behavior.

## Confidence

- **High Confidence**: Mathematical formulation of Jacobian Scopes and their relationship to linearized input-output mappings is sound and well-established.
- **Medium Confidence**: Effectiveness of Semantic Scope for detecting semantic reasoning and implicit biases shows promising qualitative results but lacks systematic evaluation.
- **Low Confidence**: Claim that Temperature Scope provides reliable proxy for distributional sensitivity in long-context scenarios lacks quantitative validation of the norm-based proxy.

## Next Checks

1. **Runtime Benchmarking**: Implement both Temperature Scope and Fisher Scope on a 2048-token translation task using LLaMA-3.2 1B. Measure wall-clock time per token and compute correlation between attribution maps. Document actual speedup factor and qualitative differences.

2. **Attention Sink Quantification**: Systematically measure influence scores of BOS, EOS, and early tokens across 50 diverse prompts. Calculate percentage of total influence attributed to these positions and test whether removing/masking early tokens alters predictions. Develop quantitative metric for identifying and correcting attention sink artifacts.

3. **Non-linearity Stress Test**: Design adversarial prompts forcing non-linear behavior in LLaMA-3.2 1B (extreme context mixing, contradictory instructions). Compare Jacobian-based attributions against ground-truth influence using controlled input perturbations. Measure degradation in attribution quality as function of perturbation magnitude to establish valid operating regime.