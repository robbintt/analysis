---
ver: rpa2
title: 'Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts
  in a Real World Setting'
arxiv_id: '2512.10780'
source_url: https://arxiv.org/abs/2512.10780
tags:
- script
- native
- messages
- language
- roman
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks large language models on maternal and newborn
  healthcare triage across five Indian languages and Nepali in both native and romanized
  scripts. Using a real-world corpus of user-generated messages, models were evaluated
  on triage accuracy, revealing consistent performance gaps of 5-12 percentage points
  in F1 scores for romanized text compared to native script and English.
---

# Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting

## Quick Facts
- arXiv ID: 2512.10780
- Source URL: https://arxiv.org/abs/2512.10780
- Reference count: 40
- Models show 5-12 percentage point F1 score drop for romanized vs native script in medical triage

## Executive Summary
This study benchmarks large language models on maternal and newborn healthcare triage across five Indian languages and Nepali in both native and romanized scripts. Using a real-world corpus of user-generated messages, models were evaluated on triage accuracy, revealing consistent performance gaps of 5-12 percentage points in F1 scores for romanized text compared to native script and English. Even the best-performing models showed higher rates of misclassifying urgent cases as "insufficient information" when presented in romanized form. Analysis showed that models often infer correct intent from romanized messages but remain brittle in final label assignment, suggesting that orthographic noise, not clinical reasoning failure, drives the performance drop. Script normalization experiments confirmed that translating romanized text back to native script recovers most of the lost performance. The findings highlight a critical safety risk for LLM-based triage systems serving multilingual populations, especially when romanized input is prevalent.

## Method Summary
The study evaluated zero-shot triage classification (Emergency, Non-emergency, Insufficient Information) for maternal/newborn healthcare messages in Hindi, Telugu, Kannada, Marathi, Punjabi, and Nepali, comparing performance on native script, romanized script, and English. The dataset comprised 3,156 stratified user messages from WhatsApp, with 300 human-annotated gold samples for validation. Script annotations were assigned via GPT-4o with 97% human agreement. Models tested included GPT-4o, Claude 4.5 Sonnet, LLaMA 4 Maverick, DeepSeek-V3, Qwen3-80B, Sarvam, GPT-OSS-20B, Mixtral-8x7B, and Qwen2.5-7B using a SOP+KB prompt template with temperature=0. Ensemble pseudo-labeling was performed using majority vote from GPT-4o, Claude 4.5, and Qwen3-80B. Script normalization experiments used GPT-4o to translate romanized messages back to native script to measure performance recovery.

## Key Results
- Romanized script messages showed 5-12 percentage point F1 score gaps compared to native script across all evaluated models
- Models disproportionately misclassified urgent cases as "Insufficient Information" when presented in romanized form
- Script normalization recovered 5-6 F1 points, confirming orthographic noise as the primary driver of performance loss
- Models often correctly inferred triage intent from romanized messages but assigned wrong labels, indicating brittle decision boundaries

## Why This Works (Mechanism)
The study demonstrates that large language models exhibit consistent performance degradation when processing medical triage queries in romanized Indian languages compared to native scripts. The mechanism underlying this "script gap" appears to be orthographic noise rather than fundamental comprehension failure. Models maintain the ability to extract clinical intent from romanized messages, as evidenced by correct reasoning in rationales, but fail to translate this understanding into accurate label assignments. This brittleness manifests most critically in emergency cases being misclassified as "insufficient information." Script normalization experiments, where romanized text is converted back to native script, recover most lost performance, confirming that the issue stems from script representation rather than medical knowledge gaps. The higher token-level entropy in romanized text (5.6 bits vs 3.6 bits for native script in GPT-OSS-20B) suggests that orthographic variation introduces noise that destabilizes model predictions.

## Foundational Learning
- **Zero-shot classification**: Models make predictions without task-specific training; needed to evaluate general model robustness across languages; quick check: verify models can handle few-shot examples before full evaluation
- **Script normalization**: Converting romanized text to native script representation; needed to isolate orthographic effects from comprehension; quick check: measure F1 recovery after normalization across multiple translation models
- **Weighted F1 score**: Metric accounting for class imbalance in triage classification; needed because emergency cases are rare but critical; quick check: ensure per-class recall aligns with F1 improvements
- **SOP+KB prompt**: Structured prompt with standard operating procedures and knowledge base; needed for consistent zero-shot evaluation; quick check: validate prompt generates correct triage logic on simple test cases
- **Cross-model consensus**: Agreement rate between different model predictions; needed to assess reliability of pseudo-labels; quick check: measure consensus on gold-standard samples
- **Entropy analysis**: Measuring token-level uncertainty to quantify orthographic noise; needed to differentiate comprehension vs representation issues; quick check: compare entropy distributions between scripts

## Architecture Onboarding
- **Component map**: User messages -> Script annotation (GPT-4o) -> Model inference (multiple LLMs) -> Ensemble pseudo-labeling -> Evaluation metrics (F1, recall, consensus)
- **Critical path**: Script annotation → Model inference → Label assignment → Performance measurement
- **Design tradeoffs**: Zero-shot evaluation ensures generalizability but sacrifices task-specific optimization; ensemble pseudo-labeling improves label quality but introduces model dependency
- **Failure signatures**: Emergency cases misclassified as "Insufficient Information" in romanized script; correct rationales with wrong labels; high entropy in romanized token sequences
- **First experiment**: Run SOP+KB prompt on GPT-4o with temperature=0 on a small sample of native and romanized messages to verify prompt structure and basic functionality
- **Second experiment**: Compare model rationales for correctly and incorrectly classified romanized messages to identify if comprehension or label assignment is failing
- **Third experiment**: Implement script normalization using GPT-4o and measure F1 score recovery to validate orthographic noise hypothesis

## Open Questions the Paper Calls Out
- Does the "script gap" persist or intensify in generative tasks, such as drafting medical advice, compared to the triage classification task evaluated in this study?
- Can training-based interventions (fine-tuning on noisy romanized data) bridge the performance gap more robustly than the inference-time script normalization pipeline?
- How can decision boundaries be recalibrated to reduce the over-prediction of "Insufficient Information" for romanized inputs without compromising safety?

## Limitations
- Proprietary dataset from Maternal Health Organization A is not publicly available, preventing exact replication
- Emergency symptom knowledge base is only sketched, not fully specified
- GPT-OSS-20B model identity is unclear and may not be reproducible
- Script normalization relies on GPT-4o translation, which may introduce its own error propagation
- Attribution of performance gap to orthographic noise is inferred rather than directly measured through model attention analysis

## Confidence
- **High confidence**: Existence of systematic F1 gap between native and romanized scripts across multiple models and languages
- **Medium confidence**: Attribution of gap primarily to orthographic noise rather than comprehension failure
- **Low confidence**: Exact magnitude of F1 gaps for each language-model pair due to proprietary data limitations

## Next Checks
1. Recreate the triage dataset using publicly available transliteration datasets combined with synthetic medical query templates, then run SOP+KB prompt on accessible models to verify the 5-12 percentage point F1 gap
2. Extract and analyze model rationales for misclassified romanized messages to determine whether correct triage intent is present but label is wrong
3. Implement script normalization pipeline using multiple translation models and measure F1 recovery to confirm orthographic normalization drives performance gains