---
ver: rpa2
title: Agentic Retoucher for Text-To-Image Generation
arxiv_id: '2601.02046'
source_url: https://arxiv.org/abs/2601.02046
tags:
- agent
- reasoning
- distortion
- image
- saliency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes Agentic Retoucher, a hierarchical decision-driven
  framework for autonomous post-generation correction of text-to-image (T2I) outputs.
  The core method introduces a perception-reasoning-action loop: a perception agent
  learns context-aware distortion saliency, a reasoning agent performs human-aligned
  diagnostic inference, and an action agent executes localized inpainting.'
---

# Agentic Retoucher for Text-To-Image Generation

## Quick Facts
- arXiv ID: 2601.02046
- Source URL: https://arxiv.org/abs/2601.02046
- Reference count: 40
- This paper proposes a hierarchical decision-driven framework for autonomous post-generation correction of text-to-image outputs, achieving significant perceptual quality improvements over unretouched outputs and state-of-the-art baselines.

## Executive Summary
This paper introduces Agentic Retoucher, a hierarchical framework for autonomous post-generation correction of text-to-image (T2I) outputs. The method employs a perception-reasoning-action loop: a perception agent learns context-aware distortion saliency, a reasoning agent performs human-aligned diagnostic inference, and an action agent executes localized inpainting. The authors construct GenBlemish-27K, a dataset of 6K T2I images with 27K pixel-level annotated artifact regions across 12 categories, to enable fine-grained supervision. Experiments show Agentic Retoucher significantly improves perceptual quality, with plausibility scores increasing from 44.21 to 47.10 and overall scores from 47.15 to 49.27. Human evaluation shows 83.2% preference over unretouched outputs.

## Method Summary
Agentic Retoucher employs a hierarchical perception-reasoning-action loop for autonomous post-generation correction of T2I outputs. The perception agent uses a dual-encoder ViT-T5 backbone with self-attention fusion to predict distortion saliency maps under text-image consistency cues. The reasoning agent performs diagnostic inference using a VLM backbone fine-tuned with SFT and GRPO to generate localized correction instructions. The action agent executes inpainting using a modular tool library. The framework is trained on GenBlemish-27K, a dataset of 6K T2I images with 27K pixel-level annotated artifact regions across 12 categories. Inference involves 2-3 iterative refinement cycles until saliency drops below threshold.

## Key Results
- Perceptual quality improvements: Plausibility increases from 44.21 to 47.10, overall scores from 47.15 to 49.27 on GenBlemish-27K
- Human evaluation: 83.2% preference over unretouched outputs
- Outperforms state-of-the-art VLM-based and mask-based inpainting baselines on both objective metrics and human studies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A dual-encoder architecture with text-image cross-modal fusion enables more accurate distortion localization than pure vision saliency methods.
- Mechanism: ViT encodes visual features, T5 encodes prompt semantics; self-attention fuses representations to capture correspondences between visual structures and textual expectations. This grounds distortion detection in semantic consistency rather than low-level visual contrast alone.
- Core assumption: Distortions manifest as violations of text-image consistency, not just visual anomalies.
- Evidence anchors:
  - [abstract] "perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues"
  - [section 4.2] "A dual-encoder ViT-T5 backbone encodes image and text representations, which are subsequently concatenated and fused via a self-attention mechanism"
  - [corpus] Weak direct evidence; related work on T2I-Copilot and LumiGen also uses multi-agent/LVLM approaches but doesn't specifically validate dual-encoder saliency.
- Break condition: If distortions are visually coherent but semantically incorrect (e.g., correct finger count but wrong gesture), text-conditioned saliency may underperform.

### Mechanism 2
- Claim: Progressive training (SFT → GRPO) produces more human-aligned reasoning than either stage alone.
- Mechanism: Stage 1 (SFT + LoRA) establishes structured output format and taxonomy grounding. Stage 2 (GRPO) applies reinforcement signals from accuracy and semantic rewards to reduce hallucination and align with human judgment patterns.
- Core assumption: VLMs have reasoning capacity but lack task-specific grounding; preference signals can shape behavior without full-parameter updates.
- Evidence anchors:
  - [section 4.3] "SFT establishes structured response formats and distortion taxonomy under limited supervision... GRPO aligns reasoning behavior with human preferences through reinforcement signals"
  - [table 4] Shows Ours (SFT+GRPO) at 80.10% accuracy vs SFT-only at 78.34% vs GRPO-only at 58.97% for Qwen2.5-VL-7B
  - [corpus] No direct corpus validation for GRPO in T2I correction specifically; ProxT2I uses reward guidance but in diffusion sampling, not reasoning alignment.
- Break condition: If reward signals are noisy or taxonomy labels inconsistent, GRPO may amplify biases rather than reduce hallucination.

### Mechanism 3
- Claim: Iterative perception-reasoning-action loops converge to higher perceptual quality than single-pass editing.
- Mechanism: Each iteration produces a saliency map; if distortion remains above threshold, reasoning generates new descriptions and masks, action agent refines. Loop continues until saliency drops below τ_s.
- Core assumption: Residual distortions are detectable and correctable incrementally without global semantic drift.
- Evidence anchors:
  - [abstract] "reformulates post-generation correction as a human-like perception-reasoning-action loop"
  - [section 4.1] "This process repeats until all salient distortions are eliminated... converges within 2-3 reasoning iterations per image"
  - [table 1] Quantitative gains: plausibility 44.21→47.10, overall 47.15→49.27 on GenBlemish-27K
  - [corpus] AgenticIR and MoA-VR also use multi-agent repair paradigms, supporting loop-based refinement generically.
- Break condition: If inpainting introduces new distortions faster than perception can detect, the loop may oscillate or degrade.

## Foundational Learning

- Concept: **Saliency prediction with KLD loss**
  - Why needed here: Standard MSE loss over-smooths predictions; KLD aligns predicted distributions with human fixation patterns, preserving discriminability in ambiguous regions.
  - Quick check question: Can you explain why KLD alone might fail if ground-truth saliency is sparse?

- Concept: **LoRA (Low-Rank Adaptation)**
  - Why needed here: Full VLM fine-tuning is computationally expensive; LoRA decomposes weight updates as ΔW=AB with low rank r, enabling efficient specialization.
  - Quick check question: What happens to LoRA expressiveness if rank r is set too low for complex taxonomy learning?

- Concept: **GRPO (Group Relative Policy Optimization)**
  - Why needed here: Standard RLHF assumes scalar rewards; GRPO uses relative advantages within groups to stabilize policy updates while reducing KL divergence from reference.
  - Quick check question: Why does the paper apply GRPO after SFT rather than before?

## Architecture Onboarding

- Component map:
  ```
  Input: (Image I_t, Prompt P)
     ↓
  Perception Agent: ViT-T5 dual encoder → Self-attention fusion → Saliency map S_t
     ↓ (if S_t > τ_s)
  Reasoning Agent: VLM backbone → SFT+LoRA → GRPO-aligned → {Masks M_i, Descriptions D_i}
     ↓
  Action Agent: Tool selector → Inpainting model (VLM-based OR mask-based) → Refined I_{t+1}
     ↓
  Loop back to Perception until convergence
  ```

- Critical path: Saliency threshold τ_s determines loop entry; incorrect threshold either over-triggers (wasting compute) or under-triggers (missing distortions).

- Design tradeoffs:
  - VLM-based vs mask-based inpainting: VLM-based offers instruction flexibility but weaker spatial grounding; mask-based offers precise localization but requires accurate masks.
  - LoRA rank (r=64): Higher rank improves expressiveness but increases memory; paper chose r=64 as balance point.
  - Iteration limit (2-3): More iterations increase refinement but risk semantic drift; paper empirically found 2-3 sufficient.

- Failure signatures:
  - Saliency map dispersed across irrelevant regions → perception agent not learning context-aware cues; check cross-modal fusion.
  - Reasoning outputs generic or hallucinated → SFT insufficient or GRPO rewards misconfigured; verify taxonomy coverage.
  - Inpainting introduces new artifacts → mask quality poor or inpainting model mismatch; inspect mask-to-region alignment.

- First 3 experiments:
  1. Ablate perception agent: Replace with off-the-shelf saliency (e.g., SALICON) and measure localization metrics (AUC-Judd, NSS drop).
  2. Ablate training stages: Run SFT-only, GRPO-only, and SFT+GRPO on reasoning agent; compare accuracy and semantic alignment scores.
  3. Test loop convergence: Run 1, 2, 3, 5 iterations on held-out images; plot perceptual quality vs compute cost to validate 2-3 iteration claim.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the iterative perception-reasoning-action loop risk introducing new artifacts or degrading global coherence if the Action Agent's inpainting imperfectly alters the image structure?
- Basis in paper: [inferred] Equation (1) describes an iterative update $I_{t+1}$, but the evaluation focuses on successful convergence cases without quantifying failure rates where the loop might amplify errors.
- Why unresolved: The paper reports only the improvements (positive delta) on perceptual metrics but does not analyze the distribution of negative outcomes or oscillation behaviors over multiple iterations.
- What evidence would resolve it: A failure case analysis or a metric quantifying the frequency of quality degradation (e.g., FID increase) after applying the iterative loop on held-out test sets.

### Open Question 2
- Question: How does the computational overhead of the three-agent system compare to the "costly iterative re-generation" approaches criticized in the introduction?
- Basis in paper: [inferred] The introduction explicitly frames the problem as an alternative to expensive regeneration, yet the paper provides no latency, throughput, or FLOPs comparisons.
- Why unresolved: Without efficiency metrics, it is unclear if the added architectural complexity of the agents (Perception + Reasoning + Action) offers a practical speed advantage over simply regenerating the image.
- What evidence would resolve it: A comparative table of inference time (ms/image) and computational cost (GFLOPs) between Agentic Retoucher and standard diffusion regeneration baselines.

### Open Question 3
- Question: Can the framework generalize to correct "semantic" distortions (e.g., logical inconsistencies) that do not exhibit strong visual saliency or high-frequency anomalies?
- Basis in paper: [inferred] Section 4.2 anchors the Perception Agent in predicting "distortion-saliency" based on visual evidence, potentially biasing detection toward structural artifacts like limbs or text.
- Why unresolved: The GenBlemish-27K taxonomy focuses on visible anomalies (e.g., hand distortion, face distortion), leaving the handling of non-salient semantic errors unverified.
- What evidence would resolve it: Evaluation results on a dataset specifically containing logical/semantic violations (e.g., wrong object attributes or physical impossibilities) that lack distinctive visual texture anomalies.

## Limitations

- Relies on GenBlemish-27K dataset with 27K pixel-level annotations; exact annotation quality and inter-annotator agreement are not reported
- Assumes distortions are localized and correctable via inpainting, but complex global semantic errors may not be addressable
- Preference gains (3.12 points on plausibility, 2.12 on overall) are statistically significant but may not translate to large perceptual differences in all use cases

## Confidence

- **High Confidence**: The dual-encoder architecture for perception and the SFT+GRPO pipeline for reasoning are technically sound and supported by ablation studies (table 4). The iterative loop mechanism is clearly specified and empirically validated.
- **Medium Confidence**: The human preference results (83.2%) are compelling but based on pairwise comparisons without statistical significance testing reported. The generalizability across diverse T2I models is assumed but not extensively validated beyond the 20+ models mentioned in dataset construction.
- **Low Confidence**: The exact hyperparameters (α for loss balancing, τ_s threshold, LoRA rank, GRPO settings) and their sensitivity are not thoroughly explored, which could impact reproducibility and robustness.

## Next Checks

1. **Ablate Perception Agent**: Replace the trained perception agent with off-the-shelf saliency predictors (e.g., SALICON, DSS) and measure drops in AUC-Judd, NSS, and final retouch quality to isolate the contribution of the dual-encoder design.

2. **Test Loop Convergence Beyond 3 Iterations**: Run the iterative loop for 1, 2, 3, and 5 iterations on a held-out test set to empirically verify the claim that 2-3 iterations are optimal, and to check for semantic drift or diminishing returns.

3. **Generalizability to Unseen Models**: Evaluate Agentic Retoucher on T2I outputs from models not represented in GenBlemish-27K (e.g., newer or niche models) to test whether the learned distortion patterns transfer or overfit to the training distribution.