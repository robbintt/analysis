---
ver: rpa2
title: 'Deep Contrastive Learning for Feature Alignment: Insights from Housing-Household
  Relationship Inference'
arxiv_id: '2502.11205'
source_url: https://arxiv.org/abs/2502.11205
tags:
- housing
- household
- data
- housing-household
- matching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a deep contrastive learning (DCL) framework
  to infer housing-household relationships from American Community Survey (ACS) microdata.
  The method addresses the challenge of learning joint relationships between distinct
  tabular entities without explicit ground truth labels by leveraging co-occurrence
  patterns and a bisecting K-means clustering approach.
---

# Deep Contrastive Learning for Feature Alignment: Insights from Housing-Household Relationship Inference

## Quick Facts
- arXiv ID: 2502.11205
- Source URL: https://arxiv.org/abs/2502.11205
- Reference count: 40
- Primary result: Achieves 98.33% AP and 99.76% NDCG in housing-household matching for Delaware using ACS microdata

## Executive Summary
This study develops a deep contrastive learning (DCL) framework to infer housing-household relationships from American Community Survey (ACS) microdata without explicit ground truth labels. The method addresses the challenge of learning joint relationships between distinct tabular entities by leveraging co-occurrence patterns and a bisecting K-means clustering approach. The dual-encoder DCL architecture captures semantic differences between housing and household features while mitigating noise from clustering. The model outperforms state-of-the-art approaches, achieving an Average Precision of 98.33% and NDCG of 99.76% in Delaware, with strong transferability to North Carolina.

## Method Summary
The method treats housing and household features appearing in the same microdata record as positive pairs, and features from different records as pseudo-negative pairs. Bisecting K-means clustering is applied separately to housing and household tables to expand training pairs beyond direct co-occurrence, addressing the one-to-one limitation in microdata. A dual-encoder architecture with separate MLPs for housing and household features projects both into a shared latent space where similarity is computed via dot product. The sigmoid contrastive loss supports many-to-many relationships without requiring global normalization across batches, while momentum distillation stabilizes training under noisy labels.

## Key Results
- Achieves 98.33% Average Precision and 99.76% NDCG in Delaware housing-household matching
- Strong transferability to North Carolina with 97.92% AP and 99.80% NDCG
- SHAP analysis identifies tenure status and mortgage information as most influential factors
- Sensitivity analysis shows optimal performance at approximately 3,000 clusters (~5 samples per cluster)

## Why This Works (Mechanism)

### Mechanism 1
Co-occurrence in microdata serves as a pretext task for learning housing-household relationships without explicit labels. The model treats housing and household features appearing in the same microdata record as positive pairs, and features from different records as pseudo-negative pairs. This creates a supervised signal from unlabeled data by treating data structure itself as the label source. Core assumption: Households and housing units that co-occur in records represent compatible matches, while non-co-occurring pairs are more likely to be incompatible. Evidence: Section 3.1 explicitly describes the co-occurrence treatment and acknowledges potential false negatives from unobserved compatible pairs.

### Mechanism 2
Bisecting K-means clustering expands training pairs and captures many-to-many matching relationships while managing noise. By clustering similar housing units and households separately, the method extends matches beyond direct co-occurrence—households can be matched to housing units in the same cluster as their original co-occurring unit. Core assumption: Housing units in the same cluster are interchangeable candidates for households in corresponding clusters. Evidence: Sensitivity analysis shows 3,000 clusters yields AP=98.33%, while 100 clusters yields AP=43.97%, confirming cluster granularity directly impacts performance.

### Mechanism 3
A dual-encoder architecture with sigmoid contrastive loss robustly aligns semantically distinct feature spaces. Separate MLP encoders process housing and household features independently, projecting both into a shared latent space where similarity is computed via dot product. Sigmoid loss supports many-to-many relationships without requiring global normalization across batches. Core assumption: Housing (building) and household (people) features occupy distinct semantic spaces that benefit from separate encoding before alignment. Evidence: DCL achieves AP=0.869 vs. SubTab's 0.304 on synthetic ground truth, supporting architectural contribution.

## Foundational Learning

- **Concept: Contrastive Learning (Self-Supervised)**
  - Why needed here: The core training paradigm—learning representations by pulling positive pairs closer and pushing negative pairs apart in embedding space. Without this, the paper's approach is opaque.
  - Quick check question: Can you explain why contrastive learning doesn't require explicit class labels, and what role the loss function plays in shaping the embedding space?

- **Concept: Pretext Tasks**
  - Why needed here: The paper uses co-occurrence as a pretext task. Understanding this concept explains how the model generates its own supervision from data structure.
  - Quick check question: What makes a good pretext task, and why might co-occurrence be valid here but invalid in other domains?

- **Concept: Many-to-Many Matching vs. Classification**
  - Why needed here: The housing-household problem is not standard classification—it's a retrieval/ranking problem where multiple valid matches exist per query.
  - Quick check question: Why does InfoNCE loss (designed for single-positive matching) fail in many-to-many settings, and how does sigmoid loss address this?

## Architecture Onboarding

- **Component map:** Input preprocessing -> Bisecting K-means clustering -> Dual MLP encoders -> Shared latent space projection -> Sigmoid contrastive loss -> Momentum distillation
- **Critical path:** Clustering quality → positive/negative pair generation → encoder training → embedding alignment. Errors in clustering propagate as label noise; the loss function and momentum distillation are the mitigations.
- **Design tradeoffs:**
  - Cluster count: Small clusters reduce false positives but may miss valid matches; large clusters introduce noise. Paper recommends 4–8 samples per cluster.
  - Encoder depth: 6 MLP layers balance expressiveness and overfitting risk on small tabular data.
  - Sigmoid vs. InfoNCE: Sigmoid supports many-to-many but may be less calibrated for probability outputs.
- **Failure signatures:**
  - High AP but low NDCG: Model distinguishes positive/negative but ranks poorly—check embedding space separation quality.
  - Performance crashes with larger clusters: False positives dominating training—reduce cluster size.
  - Training instability (loss spikes): Noisy pseudo-labels overwhelming gradient signal—verify momentum distillation is active.
- **First 3 experiments:**
  1. **Synthetic ground truth validation**: Replicate the controlled experiment (Section 5) with known non-linear relationships to verify implementation before touching real microdata.
  2. **Cluster sensitivity sweep**: Test cluster counts from 100 to 15,000 on a held-out validation set; plot AP and NDCG to find the plateau region.
  3. **Ablate dual-encoder**: Force a single shared encoder for both housing and household features; compare AP/NDCG to quantify the architectural contribution of separation.

## Open Questions the Paper Calls Out

### Open Question 1
How can a comprehensive ground truth dataset be constructed to evaluate housing-household mismatches beyond the simple tenure-based constraint? The Conclusion states that the current method for generating negative samples "captures only a subset of the true negative instances" and suggests future work investigate "developing complex housing-household unmatching rules or engaging human experts to create a large-scale validation dataset."

### Open Question 2
To what extent does the 5% ACS PUMS sample size limit the model's ability to generalize to the full population, and can integrating alternative data sources correct potential biases? The Conclusion notes that the ACS dataset is "relatively small" (5% sample) and may "lead to gaps in geographic coverage... potentially introducing biases."

### Open Question 3
Can an automated or theoretical method be established to determine the optimal cluster granularity (k) for the Bisecting K-Means preprocessing to minimize false positives without empirical tuning? While Section 6.3 performs a sensitivity analysis, it relies on an empirical search to find the "sweet spot" that balances false negatives and false positives.

## Limitations

- Cluster quality dependency: The entire method relies on bisecting K-means to generate pseudo-labels, but no external validation confirms clusters reflect true semantic compatibility
- Pseudo-negative noise: The method treats non-co-occurring pairs as negatives, but some may be valid matches absent from the data, with false negative impact unquantified
- State-of-the-art comparison scope: Comparison lacks recent contrastive learning approaches for tabular data, potentially overstating architectural advantage

## Confidence

- **High**: Dual-encoder architecture design, sigmoid loss formulation, empirical performance metrics (AP/NDCG) on ACS data
- **Medium**: Clustering-based pair expansion, many-to-many matching claims, transfer learning results to North Carolina
- **Low**: Claims about relative feature importance from SHAP analysis, generalization beyond ACS PUMS data, robustness to different clustering algorithms

## Next Checks

1. **Cluster validation study**: Apply silhouette analysis or external clustering validation metrics to confirm that K-means clusters meaningfully group compatible housing-household pairs before using them as training labels.

2. **False negative sensitivity test**: Create a synthetic validation set with known ground truth matches and measure how many valid matches are excluded by the clustering-based negative sampling strategy.

3. **Ablation on clustering algorithm**: Replace bisecting K-means with alternative clustering methods (e.g., DBSCAN, hierarchical clustering) to test whether the method's success depends specifically on K-means assumptions about feature space structure.