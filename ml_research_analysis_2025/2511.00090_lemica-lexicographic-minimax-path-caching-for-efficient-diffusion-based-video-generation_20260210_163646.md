---
ver: rpa2
title: 'LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video
  Generation'
arxiv_id: '2511.00090'
source_url: https://arxiv.org/abs/2511.00090
tags:
- lemica
- diffusion
- arxiv
- cache
- video
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of accelerating diffusion-based
  video generation while preserving content consistency and visual quality. The authors
  propose LeMiCa, a training-free caching framework that formulates cache scheduling
  as a lexicographic minimax path optimization problem on a directed acyclic graph.
---

# LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation

## Quick Facts
- arXiv ID: 2511.00090
- Source URL: https://arxiv.org/abs/2511.00090
- Reference count: 40
- 2.9× speedup on Latte and LPIPS reduction from 0.134 to 0.05 on Open-Sora compared to prior caching techniques

## Executive Summary
This paper addresses the challenge of accelerating diffusion-based video generation while preserving content consistency and visual quality. The authors propose LeMiCa, a training-free caching framework that formulates cache scheduling as a lexicographic minimax path optimization problem on a directed acyclic graph. By introducing a global outcome-aware error metric and leveraging a static DAG constructed from multiple prompts, LeMiCa explicitly bounds worst-case degradation across the sampling trajectory. Experimental results demonstrate substantial improvements over prior caching techniques while maintaining strong visual quality across various models and settings.

## Method Summary
LeMiCa accelerates diffusion-based video generation through training-free cache scheduling. The method constructs a static directed acyclic graph (DAG) offline by computing global outcome-aware error metrics for candidate cache segments across multiple prompts and noise seeds. During inference, it selects optimal cache paths using lexicographic minimax optimization under a step budget constraint. The framework consists of three offline stages (edge weight estimation, graph construction, path optimization) and one online inference stage where precomputed paths are executed with caching.

## Key Results
- Achieves 2.9× speedup on Latte model while maintaining quality
- Reduces LPIPS from 0.134 to 0.05 on Open-Sora compared to prior caching techniques
- Performance saturates at ~20 samples for DAG construction, with single sample achieving PSNR 24.51 vs 24.67 upper bound
- Lexicographic minimax path achieves LPIPS 0.143, SSIM 0.851 vs shortest path LPIPS 0.203, SSIM 0.809

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Global outcome-aware error metric better predicts final output degradation than local greedy error measures
- Mechanism: Instead of measuring local differences between adjacent timesteps (L1rel), compute the actual final output error when caching over a segment (L1glob). This captures how early-stage errors amplify during denoising while late-stage errors remain localized.
- Core assumption: Diffusion models exhibit temporal heterogeneity where cache position matters more than segment length; early denoising steps shape global structure with amplified downstream effects.
- Evidence anchors: [abstract] "introduce a Global Outcome-Aware error metric... explicitly bounds the worst-case path error"; [section 3.2, Figure 2b] Shows segment-wise error trends where early caches cause substantially higher errors than later caches of equal length

### Mechanism 2
- Claim: Static DAG construction from multiple prompts generalizes to unseen inference prompts
- Mechanism: Build a directed acyclic graph offline by averaging edge errors across diverse prompts and noise seeds. Each edge represents a cache segment with weight = global reconstruction error. Maximum skip length constraint prevents long-range reuse.
- Core assumption: Well-trained diffusion models remain stable along fixed sampling paths; error patterns transfer across prompts.
- Evidence anchors: [section 3.3] "build a static graph by averaging edge errors across diverse prompts and noise seeds"; [section 4.3, Table 2] Performance saturates at ~20 samples; even single sample achieves PSNR 24.51 vs 24.67 upper bound

### Mechanism 3
- Claim: Lexicographic minimax path optimization controls worst-case degradation better than additive shortest-path methods
- Mechanism: Select the path that minimizes the maximum edge weight; if ties exist, compare second-largest weights, etc. This prevents any single cache segment from causing unacceptable quality loss, unlike shortest-path which allows high-error edges if total sum is low.
- Core assumption: Error accumulation is non-additive and non-Markovian; peak errors dominate perceptual degradation more than cumulative errors.
- Evidence anchors: [section 3.3] "lexicographic minimax criterion that explicitly minimizes the highest cache error along the path"; [section 4.3, Table 3] MiniMax Path achieves LPIPS 0.143, SSIM 0.851 vs Shortest Path LPIPS 0.203, SSIM 0.809

## Foundational Learning

- Concept: **Diffusion denoising trajectories and temporal heterogeneity**
  - Why needed here: Understanding that early timesteps shape global structure (high semantic content) while later steps refine details (high-frequency information) is essential for grasping why local greedy caching fails
  - Quick check question: Why would caching at timestep 10 cause more final output error than caching at timestep 80, even if local output differences appear smaller at t=10?

- Concept: **Directed acyclic graphs and path optimization**
  - Why needed here: The method formulates cache scheduling as finding an optimal path through a DAG with weighted edges; must understand source-to-target paths, edge weights, and budget constraints
  - Quick check question: Given a DAG with 100 nodes and budget B=20 full computation steps, what does a valid path look like?

- Concept: **Lexicographic ordering and minimax optimization**
  - Why needed here: The core algorithm compares error vectors lexicographically (sort descending, compare element-wise) rather than summing; this prioritizes worst-case control
  - Quick check question: Between paths with error vectors [0.1, 0.1, 0.1] and [0.05, 0.15, 0.05], which does lexicographic minimax prefer, and why?

## Architecture Onboarding

- Component map:
  Offline Stage 1 (Edge Weight Estimation) -> Offline Stage 2 (Graph Construction) -> Offline Stage 3 (Path Optimization) -> Online Stage (Inference)

- Critical path:
  1. Select representative prompts from target distribution (paper uses T2V-CompBench)
  2. For each candidate edge (i,j), compute global reconstruction error by running denoising with cache segment
  3. Average errors across prompts/seeds to get static edge weights
  4. Run Algorithm 1 to generate optimal paths for B ∈ {slow, fast} configurations
  5. During inference, lookup precomputed path and execute caching schedule

- Design tradeoffs:
  - More samples for DAG construction → better generalization but higher offline cost (paper shows 20 samples sufficient)
  - Larger maximum skip length → more graph edges, potentially better paths, but exponentially more offline computation
  - Smaller budget B → higher speedup but quality degradation (LeMiCa-fast vs LeMiCa-slow)
  - Lexicographic minimax vs shortest path → conservative quality guarantees vs potentially faster but riskier paths

- Failure signatures:
  - High LPIPS on OOD prompts: Check if DAG construction prompts cover similar distribution; may need to expand sample diversity
  - Visual artifacts at specific frames: Indicates a high-error edge in the selected path; verify edge weights and consider increasing B locally
  - Inconsistent acceleration across videos: Static path may not adapt to prompt-specific dynamics; consider prompt-conditioned graph variants
  - Quality collapse under extreme speedup (B very small): Fundamental limit of caching; consider hybrid approaches with selective full computation

- First 3 experiments:
  1. Reproduce Table 2 (sample size ablation): Build DAGs with n ∈ {1, 5, 10, 20} samples on Open-Sora, measure VBench/LPIPS/SSIM/PSNR on held-out prompts to validate saturation at ~20 samples
  2. Reproduce Table 3 (path strategy comparison): Implement both Shortest Path and Lexicographic Minimax selection on same DAG, compare reconstruction metrics to verify ~2× LPIPS improvement
  3. Cross-model transfer test: Build DAG on Latte, apply to Open-Sora (or vice versa) to measure transfer degradation and validate model-specific construction requirement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the lexicographic minimax path caching strategy be effectively generalized to 3D, multi-view, or multi-modal generation tasks?
- Basis in paper: [explicit] The conclusion states this approach may "inspire future research in other domains such as 3D, multi-view, or multi-modal generation where controllable acceleration remains an open challenge."
- Why unresolved: The current framework and experiments are restricted to text-to-video generation; the error propagation dynamics in 3D or multi-modal latent spaces are unexplored.
- What evidence would resolve it: Successful application of LeMiCa to 3D object generation or audio-video generation benchmarks with comparable speedup and fidelity metrics.

### Open Question 2
- Question: How can caching frameworks be adapted to maintain consistency in scenarios involving complex motion dynamics or low-quality base models?
- Basis in paper: [inferred] The Limitations section notes that the method "struggles to consistently generate satisfactory results" when the base model performs poorly on complex motion.
- Why unresolved: The current method relies on the stability of the underlying model; it does not actively correct for representational failures in high-dynamic scenes.
- What evidence would resolve it: Development of a caching mechanism that selectively avoids reusing features during high-variance motion steps, validated on high-dynamic-range video benchmarks.

### Open Question 3
- Question: Does a static, averaged DAG compromise performance on out-of-distribution (OOD) prompts compared to a dynamic, instance-specific graph?
- Basis in paper: [inferred] Section 3.3 states the graph is constructed by "averaging edge errors across diverse prompts" to create a "static DAG," assuming global stability.
- Why unresolved: While static graphs offer efficiency, they may not capture the specific error characteristics of prompts far outside the calibration set, potentially reducing optimality.
- What evidence would resolve it: A comparative study evaluating the gap in LPIPS/VBench scores between LeMiCa's static path and an oracle dynamic path on OOD prompts.

## Limitations

- The method assumes stable error patterns across prompts and seeds, but this transferability is only validated within the paper's controlled setting
- Implementation details for computing global outcome-aware errors are underspecified, potentially leading to implementation variations
- The method struggles with complex motion dynamics when the base model performs poorly, as it relies on underlying model stability

## Confidence

- **High Confidence**: The lexicographic minimax path optimization mechanism and its superiority over shortest-path methods (validated via Table 3 metrics showing ~2× LPIPS improvement)
- **Medium Confidence**: The global outcome-aware error metric's predictive power for final output quality (supported by Figure 2b trends but limited to one model/dataset)
- **Medium Confidence**: The static DAG construction's generalization across prompts (validated via Table 2 sample size ablation but not tested on OOD distributions)

## Next Checks

1. **Sample Size Sensitivity**: Reproduce the DAG construction with varying numbers of training samples (1, 5, 10, 20) on held-out prompts to verify the claimed saturation at ~20 samples and quantify generalization error

2. **Cross-Model Transferability**: Build DAG on one model (Latte) and apply to another (Open-Sora) to measure performance degradation and validate the model-specific construction requirement

3. **Minimax vs Shortest Path Robustness**: Implement both path selection strategies on identical DAGs and test across multiple budget constraints (B values) to verify consistent quality advantages beyond the single dataset shown