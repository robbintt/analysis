---
ver: rpa2
title: Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question
  Answering with Datasets
arxiv_id: '2510.06240'
source_url: https://arxiv.org/abs/2510.06240
tags:
- knowledge
- arxiv
- distillation
- graph
- industrial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of deploying reliable industrial
  question-answering (QA) systems by proposing a Knowledge Graph-guided Multi-Agent
  System Distillation (KG-MASD) framework. The core idea is to integrate structured
  knowledge graph priors into the multi-agent distillation process, formulating it
  as a Markov Decision Process to ensure convergence and enhance reliability.
---

# Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets

## Quick Facts
- arXiv ID: 2510.06240
- Source URL: https://arxiv.org/abs/2510.06240
- Reference count: 40
- Primary result: KG-MASD improves QA accuracy by 2.4-20.1% and reliability in industrial settings.

## Executive Summary
This paper tackles the challenge of deploying reliable industrial question-answering systems by integrating structured knowledge graph priors into a multi-agent distillation framework. The approach formulates the multi-agent system as a Markov Decision Process to ensure convergence and enhance reasoning depth. By combining collaborative reasoning with knowledge grounding, KG-MASD generates high-confidence instruction-tuning data and distills it into compact, deployable student models. Experiments show significant gains in both accuracy and reliability, making it suitable for safety-critical industrial applications.

## Method Summary
KG-MASD introduces a Knowledge Graph-guided Multi-Agent System Distillation framework that leverages structured knowledge priors to enhance the reliability of industrial QA systems. The method employs five specialized agents—KG Master, Entity/Relation Extractors, KR Distiller, and Verifier—to collaboratively reason over both human-generated and GPT-generated QA pairs. These agents work in a loop, distilling verified knowledge triples into instruction-tuning data. The framework uses LoRA fine-tuning to compress the teacher model's reasoning into lightweight student models, targeting edge deployment. The process is formalized as a Markov Decision Process to ensure convergence, and knowledge grounding is enforced through local heterogeneous KGs built via query-guided path expansion.

## Key Results
- KG-MASD improves QA accuracy by 2.4-20.1% over baseline models on industrial datasets.
- The framework enhances reliability, enabling trustworthy AI deployment in safety-critical scenarios.
- Human evaluation and LLM-as-a-judge metrics confirm the high quality of distilled instruction data.

## Why This Works (Mechanism)
The framework works by grounding QA reasoning in structured knowledge graphs, which provide verifiable priors that reduce hallucination and improve consistency. The multi-agent system enables collaborative reasoning, where each agent specializes in a subtask (e.g., entity extraction, relation verification), ensuring depth and accuracy. By formalizing the process as an MDP, the system guarantees convergence and stable knowledge distillation. The use of LoRA fine-tuning allows efficient transfer of this reasoning depth into compact, deployable models without sacrificing performance.

## Foundational Learning
- **Knowledge Graphs (KGs)**: Structured representations of entities and relations; needed for grounding QA in verifiable facts. Quick check: Ensure entity linking accuracy ≥85% on industrial data.
- **Multi-Agent Systems (MAS)**: Collaborative reasoning via specialized agents; needed for modular, scalable QA pipelines. Quick check: Verify agent communication converges within 5-10 iterations.
- **Markov Decision Process (MDP)**: Formal framework for sequential decision-making; needed to ensure convergence and stability. Quick check: Monitor reward stability across distillation rounds.
- **LoRA Fine-tuning**: Low-rank adaptation for efficient model compression; needed for lightweight, deployable students. Quick check: Confirm LoRA rank=16 yields target accuracy gains.
- **GraphRAG**: Retrieval-augmented generation over KGs; needed for constructing global/local KGs from industrial documents. Quick check: Validate KG completeness on held-out QA pairs.
- **Instruction Tuning**: Training models on task-specific instructions; needed to align student models with industrial QA patterns. Quick check: Measure BLEU-4/ROUGE scores on validation set.

## Architecture Onboarding
- **Component Map**: KG Master -> Entity/Relation Extractors -> KR Distiller -> Verifier -> LoRA Student
- **Critical Path**: GraphRAG KG construction → Multi-agent distillation loop → LoRA fine-tuning → Evaluation
- **Design Tradeoffs**: Global KG vs. local heterogeneous KGs (completeness vs. specificity); single-turn QA vs. multi-turn (simplicity vs. real-world applicability).
- **Failure Signatures**: Non-converging verification (Verifier rejects triples indefinitely); noisy triples degrading student performance (low-credibility KG).
- **First Experiments**:
  1. Reconstruct the Global KG using paper's prompts and validate entity linking accuracy.
  2. Implement minimal MAS with explicit message-passing and test convergence on a small KG.
  3. Fine-tune a Qwen2-7B student on KG-grounded triples and evaluate robustness to noisy inputs.

## Open Questions the Paper Calls Out
None

## Limitations
- The framework's reliance on GraphRAG for KG construction lacks specifics on entity/relation schemas and retrieval parameters, introducing uncertainty.
- Agent communication protocols are underspecified, leaving open questions about state-sharing and convergence guarantees.
- The evaluation focuses on single-turn QA, with untested extension to multi-turn or dynamic industrial contexts.

## Confidence
- **High confidence**: Modular MAS design, LoRA-based distillation pipeline, and BLEU/ROUGE/Human Eval metrics are clearly specified.
- **Medium confidence**: 2.4-20.1% accuracy improvements depend on unverified GraphRAG and agent coordination components.
- **Low confidence**: Claims about long-term reliability and safety-critical deployment readiness lack empirical validation.

## Next Checks
1. **GraphRAG Validation**: Reconstruct the Global KG using the paper's prompts and schema assumptions; verify entity linking accuracy on a held-out industrial subset (target: ≥85% precision).
2. **Agent Communication Protocol**: Implement a minimal MAS with explicit message-passing (e.g., JSON-based state updates) and test convergence on a small KG; log iteration counts and reject reasons to diagnose bottlenecks.
3. **Student Model Robustness**: Fine-tune a Qwen2-7B student on KG-grounded triples; evaluate not only on accuracy but also on robustness to noisy inputs (e.g., paraphrased questions, missing entities).