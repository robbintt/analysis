---
ver: rpa2
title: 'TABLET: Table Structure Recognition using Encoder-only Transformers'
arxiv_id: '2506.07015'
source_url: https://arxiv.org/abs/2506.07015
tags:
- table
- recognition
- structure
- https
- tables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses table structure recognition, focusing on efficient
  processing of large, densely populated tables in real-world applications like financial
  documents. The authors propose TABLET, a Split-Merge-based top-down method that
  reformulates row and column splitting as sequence labeling tasks using dual Transformer
  encoders, and merging as a grid cell classification task using another Transformer
  encoder.
---

# TABLET: Table Structure Recognition using Encoder-only Transformers

## Quick Facts
- arXiv ID: 2506.07015
- Source URL: https://arxiv.org/abs/2506.07015
- Authors: Qiyu Hou; Jun Wang
- Reference count: 40
- Key outcome: TABLET achieves 98.97% TEDS score on FinTabNet test set and 96.79% on PubTabNet validation set, processing tables at 18 FPS on a single A100 GPU

## Executive Summary
This paper addresses table structure recognition, focusing on efficient processing of large, densely populated tables in real-world applications like financial documents. The authors propose TABLET, a Split-Merge-based top-down method that reformulates row and column splitting as sequence labeling tasks using dual Transformer encoders, and merging as a grid cell classification task using another Transformer encoder. This approach eliminates unstable bounding box predictions, reduces resolution loss, and maintains fast processing speed. TABLET outperforms existing methods on FinTabNet and PubTabNet datasets, achieving 98.97% TEDS score on FinTabNet test set and 96.79% on PubTabNet validation set. The method is particularly effective for fully and correctly recognized tables, achieving 88.18% accuracy on FinTabNet test set. TABLET processes tables at 18 FPS on a single A100 GPU, significantly faster than previous approaches. The method is well-suited for industrial deployment due to its robustness, scalability, and efficiency.

## Method Summary
TABLET proposes a two-stage pipeline for table structure recognition. The first stage (Split Model) reformulates row and column splitting as sequence labeling tasks on high-resolution feature maps using dual Transformer encoders. It removes the Max Pooling layer from ResNet and halves channel counts to maintain a feature map resolution of H/2 × W/2. The second stage (Merge Model) frames the merging process as a grid cell classification task using a Transformer encoder with 2D positional embeddings. The system uses two separate lightweight ResNet-18 + FPN backbones, with the Split model optimizing for high resolution and the Merge model using standard features. This modular approach allows for optimized efficiency and targeted feature extraction, achieving 18 FPS on a single A100 GPU.

## Key Results
- Achieves 98.97% TEDS score on FinTabNet test set and 96.79% on PubTabNet validation set
- Processes tables at 18 FPS on a single A100 GPU, approximately 2.5x faster than previous best methods
- Particularly effective for fully and correctly recognized tables, achieving 88.18% accuracy on FinTabNet test set

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Reformulating row and column splitting as **sequence labeling tasks** on high-resolution feature maps reduces information loss for densely populated tables compared to pixel-segmentation or bounding box regression.
- **Mechanism:** The model removes the Max Pooling layer from ResNet and halves channel counts to maintain a feature map resolution of H/2 × W/2. It extracts global features (projection) and local features (pooling), concatenates them, and feeds them into dual Transformer encoders to classify split regions.
- **Core assumption:** A resolution of 1/2 the input size is sufficient to distinguish adjacent columns in financial documents without requiring heavier, multi-scale instance segmentation.
- **Evidence anchors:**
  - [abstract] "formulates row and column splitting as sequence labeling tasks... eliminates unstable bounding box predictions, reduces resolution loss"
  - [section 3.1] "feature map... F1/2, has a size of H/2 x W/2... crucial to maintain the resolution"
- **Break condition:** Failure occurs when text regions in adjacent columns overlap significantly in their vertical projections, confusing the binary classifier.

### Mechanism 2
- **Claim:** Framing the merging process as a **grid cell classification task** using a Transformer encoder improves structural validity and eliminates error accumulation found in autoregressive methods.
- **Mechanism:** Instead of generating HTML sequences token-by-token, the method uses the grid structure from the split phase. It applies RoIAlign to extract features for each grid cell and uses a Transformer with 2D positional embeddings to classify relationships (OTSL tokens like "C", "L", "U") between cells.
- **Core assumption:** The structural logic of a table is better captured by modeling relationships across a fixed 2D grid than by sequential generation which may suffer from "drift" or invalid syntax.
- **Evidence anchors:**
  - [abstract] "merging as a grid cell classification task... leveraging an additional Transformer encoder to ensure accurate and coherent merging"
  - [section 3.2] "OTSL is designed to express table structures using a minimized vocabulary... significantly reducing complexity compared to HTML"
- **Break condition:** If the upstream Split Model produces an incorrect grid (e.g., missing a row), the Merge Model's relational classification will likely fail to reconstruct the correct table.

### Mechanism 3
- **Claim:** Decoupling the **Split** and **Merge** models allows for optimized efficiency (18 FPS) and targeted feature extraction, unlike monolithic end-to-end approaches.
- **Mechanism:** The system uses two separate lightweight ResNet-18 + FPN backbones. The Split model optimizes for high resolution (removing MaxPool), while the Merge model uses a standard backbone. This separation reduces the sequential dependency burden found in autoregressive models.
- **Core assumption:** Industrial deployment constraints (speed/robustness) favor a modular pipeline where structural splitting is solved independently from cell content relationship logic.
- **Evidence anchors:**
  - [abstract] "maintains fast processing speed... well-suited for industrial deployment"
  - [section 4.3] "significant speed advantage... approximately 2.5x faster than the previous best... much slower... due to their autoregressive nature"
- **Break condition:** Complex tables with multi-line text within a single cell may be incorrectly split into separate rows if the visual cues are ambiguous, as noted in Appendix 6.3.

## Foundational Learning

- **Concept: Encoder-only Transformer (Self-Attention)**
  - **Why needed here:** Unlike encoder-decoder models used for sequence generation (like HTML), this architecture requires only contextual understanding of feature sequences (rows/cols) and grid relationships.
  - **Quick check question:** Can you explain why positional embeddings (1D for split, 2D for merge) are critical for attention mechanisms processing these sequences?

- **Concept: RoIAlign (Region of Interest Align)**
  - **Why needed here:** The Merge model must extract features from specific, non-uniform grid cells defined by the Split model. RoIAlign maintains spatial precision without rounding misalignments.
  - **Quick check question:** How does RoIAlign differ from standard RoIPooling in terms of pixel-to-feature mapping?

- **Concept: Focal Loss**
  - **Why needed here:** The "Split" task involves identifying sparse split lines among hundreds of non-split lines (background). Focal Loss prevents the vast number of easy negatives (non-splits) from overwhelming the classifier.
  - **Quick check question:** In the split model, why would a standard Cross-Entropy loss struggle with the class imbalance of split lines vs. table content?

## Architecture Onboarding

- **Component map:** ResNet-18 (Modified, no MaxPool) + FPN -> Global/Local Projection -> Transformer Encoders (Separate for Row/Col) -> Binary Classifier -> RoIAlign (Grid Extraction) -> MLP -> Transformer Encoder (2D Position) -> OTSL Classifier

- **Critical path:** The Split Model must run first to define the Grid Structure ($R \times C$). The Merge Model consumes this grid to classify cell relationships. OCR text is injected only at the very end for content matching.

- **Design tradeoffs:**
  - **Resolution vs. Compute:** Authors removed MaxPool and halved channels to keep resolution at H/2. This sacrifices feature depth/channels for spatial precision in dense tables.
  - **Modularity vs. End-to-End:** Training two separate models increases pipeline complexity but allows independent optimization and prevents error propagation common in autoregressive models.

- **Failure signatures:**
  - **Adjacent Column Merging:** Occurs when text bounding boxes in neighboring columns overlap vertically (Appendix 6.1).
  - **Header Misalignment:** Column headers that are visually offset from their data rows are split into independent columns (Appendix 6.2).

- **First 3 experiments:**
  1. **Ablation on Transformer Layers:** Verify Table 2/3 by testing 0, 1, 3, and 6 layers in the Split and Merge encoders to observe the performance "sweet spot" (paper finds 3 layers optimal).
  2. **Resolution Sensitivity:** Re-introduce MaxPool or reduce the FPN channels further to observe the drop in accuracy on dense financial tables (validating the "high resolution" claim).
  3. **Speed Benchmark:** Measure inference time on a single A100 comparing the Split-Only, Merge-Only, and Full Pipeline to confirm the 18 FPS metric and identify the primary latency bottleneck.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the splitting mechanism be improved to correctly separate adjacent columns when their text regions have overlapping vertical projections?
- **Basis in paper:** [explicit] The authors state in Appendix 6.1 that "two adjacent columns are not properly separated due to overlapping vertical projections of their respective text regions," which causes the split model to fail.
- **Why unresolved:** The current sequence labeling approach relies on distinguishing features along axes, but visual overlap physically merges these features in the projection, confusing the classifier.
- **What evidence would resolve it:** An architectural modification or attention mechanism that successfully discriminates overlapping text regions without relying solely on global projections.

### Open Question 2
- **Question:** How can the model prevent multi-line text within a single cell from being incorrectly split into separate rows based on visual gaps?
- **Basis in paper:** [explicit] Appendix 6.3 identifies that "text that spans multiple lines within a single cell is incorrectly split into separate rows" as a common error pattern.
- **Why unresolved:** The splitting model acts on visual cues (white space) to determine row boundaries, lacking the semantic understanding to distinguish a visual line break from a structural row break.
- **What evidence would resolve it:** Integration of semantic features or layout analysis that identifies multi-line content blocks as singular entities during the row splitting phase.

### Open Question 3
- **Question:** To what extent does the exclusion of instance-level modules limit the method's performance on severely distorted or curved tables compared to specialized approaches?
- **Basis in paper:** [inferred] The authors explicitly state on Page 3 that "our proposed method... does not rely on instance-level modules to recognize raw table images from diverse scenarios," choosing instead to rely on external dewarping.
- **Why unresolved:** The paper focuses on financial documents (usually planar) and optimizes for speed by removing complex rectification modules, leaving robustness to unrectified geometric distortions unquantified.
- **What evidence would resolve it:** Evaluation results on datasets containing curved or perspectively distorted tables without pre-processing dewarping.

## Limitations
- Resolution of H/2 × W/2 may not generalize to tables with extremely dense or overlapping text regions
- Errors in the Split phase cannot be recovered in the Merge phase, potentially limiting robustness for complex layouts
- Performance on tables with multi-line cells or irregular structures requires further validation

## Confidence
- **High Confidence**: Claims about speed (18 FPS on A100), modular architecture benefits, and strong performance on FinTabNet and PubTabNet datasets are well-supported by quantitative results.
- **Medium Confidence**: The effectiveness of the sequence labeling approach on 1/2 resolution feature maps for dense tables is plausible but not extensively validated against alternative resolutions or segmentation methods.
- **Medium Confidence**: The OTSL classification approach for merging is innovative, but the claim that it eliminates error accumulation from autoregressive methods assumes the Split model produces accurate grids, which isn't always guaranteed.

## Next Checks
1. **Resolution Sensitivity Analysis**: Systematically vary the feature map resolution (H/4, H/2, H, 2H) and measure accuracy degradation on tables with varying column density to validate the optimal H/2 claim.

2. **Error Propagation Study**: Design experiments where the Split model is intentionally perturbed (adding noise, removing rows/columns) and measure how these errors propagate through the Merge model to quantify the decoupling benefits.

3. **Cross-Dataset Generalization**: Test TABLET on tables with significantly different characteristics (e.g., scanned historical documents, tables with rotated text, or tables from different languages/scripts) to assess robustness beyond the FinTabNet and PubTabNet domains.