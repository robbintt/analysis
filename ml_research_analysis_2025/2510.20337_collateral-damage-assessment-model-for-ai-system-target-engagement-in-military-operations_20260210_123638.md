---
ver: rpa2
title: Collateral Damage Assessment Model for AI System Target Engagement in Military
  Operations
arxiv_id: '2510.20337'
source_url: https://arxiv.org/abs/2510.20337
tags:
- military
- collateral
- systems
- damage
- assessment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research addresses the challenge of assessing collateral damage
  in military operations targeting AI systems, a growing concern as AI becomes integral
  to military operations. The paper introduces a novel collateral damage assessment
  model, CDAIMO, that integrates temporal, spatial, and force dimensions within a
  unified Knowledge Representation and Reasoning (KRR) architecture.
---

# Collateral Damage Assessment Model for AI System Target Engagement in Military Operations

## Quick Facts
- arXiv ID: 2510.20337
- Source URL: https://arxiv.org/abs/2510.20337
- Reference count: 36
- Introduces CDAIMO: a computational collateral damage assessment model for AI system targeting using Knowledge Representation and Reasoning (KRR) ontology

## Executive Summary
This research introduces CDAIMO, a novel computational model for assessing collateral damage in military operations targeting AI systems. The model integrates temporal, spatial, and force dimensions within a unified KRR architecture to capture AI system architectures, engagement vectors, and contextual factors. Through instantiation in a use case, the model demonstrates effectiveness in assessing potential civilian harm from cyber engagement of adversarial AI systems, using specific metrics such as data quality scores and probability assessments to guide mitigation decisions.

## Method Summary
The study employs Design Science Research methodology with iterative ontology construction to develop CDAIMO as a computational collateral damage assessment model. The model is formalized as CDAAIMO = (C, A, R, I) with classes/entities, attributes, relationships, and individuals. Two formal rules are specified: Rule 1 triggers collateral damage classification when DataQualityMetric ≤ 0.5, and Rule 2 mandates mitigation when probability ≥ 0.75 AND severity = "Severe". The model is evaluated through instantiation in a cyber attack use case scenario.

## Key Results
- Multi-dimensional integration of temporal, spatial, and force dimensions enables structured collateral damage assessment
- Threshold-based rules linking data quality and probability/severity metrics to collateral damage classification
- Ontology-based class hierarchies capturing AI architecture types, engagement vectors, and civilian linkages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-dimensional integration of temporal, spatial, and force dimensions enables structured collateral damage assessment for AI system targeting.
- Mechanism: The model formalizes three orthogonal dimensions—duration, propagation scope, and effect type—as first-class ontology classes. This allows reasoning engines to combine them with severity and likelihood metrics to produce proportionality-compliant recommendations.
- Core assumption: Collateral effects from AI system engagement can be meaningfully decomposed into these three independent axes and recombined for decision support.
- Evidence anchors: Abstract statement about multi-dimensional integration; section IV encoding of three fundamental dimensions; corpus shows no direct validation of multi-dimensional integration for AI targeting.

### Mechanism 2
- Claim: Threshold-based rules linking data quality and probability/severity metrics to collateral damage classification and mitigation triggers provide auditable decision support.
- Mechanism: Two formalized rules operate on the ontology. Rule 1 classifies an engagement as carrying collateral damage risk when DataQualityMetric ≤ 0.5 AND the engagement produces a CollateralDamage instance. Rule 2 mandates CDMitigationMethod when probability ≥ 0.75 AND severity = "Severe."
- Core assumption: Threshold values (0.5 for data quality, 0.75 for probability) are operationally meaningful and generalizable across engagement contexts.
- Evidence anchors: Page 5 specification of both rules; evaluation section showing Rule 2 firing with probability=0.81 and severity="Severe"; corpus lacks validation of these specific threshold values.

### Mechanism 3
- Claim: Ontology-based class hierarchies capturing AI architecture types, engagement vectors, and civilian linkages enable granular dependency tracing.
- Mechanism: The model defines TargetAISystem subclasses, TargetEngagement subclasses, and Effect subclasses with relationships like isContributingToCollateralDamage and isExploitingVulnerability. This allows reasoners to trace paths from attack vector through shared infrastructure to civilian harm.
- Core assumption: The class hierarchy adequately captures the relevant AI architectures and civilian dependencies in real-world scenarios.
- Evidence anchors: Section IV differentiation of data-driven, knowledge-driven, and neuro-symbolic architectures; evaluation section showing shared computational backbone; corpus discussion of AI integration challenges without validating this specific structure.

## Foundational Learning

- Concept: Knowledge Representation and Reasoning (KRR)
  - Why needed here: The entire CDAIMO model is built as a computational ontology following KRR principles; understanding classes, properties, relations, and inference rules is prerequisite to extending or instantiating the model.
  - Quick check question: Can you explain the difference between a class hierarchy (subclass relationships) and object properties (relations between instances) in an ontology?

- Concept: International Humanitarian Law (IHL) principles—distinction and proportionality
  - Why needed here: The model's legal framing depends on distinguishing lawful military objectives from protected civilians/objects, and weighing collateral damage against military advantage.
  - Quick check question: Under IHL Article 51(5)(b) and 57(2)(a)(iii), what makes an attack unlawful even if the target is a legitimate military objective?

- Concept: AI system architecture types (data-driven, knowledge-driven, neuro-symbolic)
  - Why needed here: CDAIMO explicitly differentiates these architectures and maps components to different vulnerability and failure modes; assessing collateral damage requires knowing which components exist and their dependencies.
  - Quick check question: What is the architectural difference between a purely data-driven AI system and a neuro-symbolic system, and how might this affect which components are vulnerable to cyber engagement?

## Architecture Onboarding

- Component map:
  - Upper classes: TargetAISystem -> MilitaryOperation -> TargetEngagement -> Effect
  - Key subclasses: Dataset, InferenceEngine, AutonomyLevel (under TargetAISystem); CyberAttack, EWAttack, PhysicalAttack (under TargetEngagement); CivilianDigitalSystemDisruption, CivilianDataDestruction (under Effect)
  - Properties: hasDataQuality (double), hasProbability (double), hasSeverity (string), hasCivilianDataAlterationLevel (enum), hasAttackVectorID (integer)
  - Relations: isAssessedBy, isExploitingVulnerability, isContributingToCollateralDamage, hasTemporalAssessment, isProducingEffect
  - Rules: Rule 1 (data quality → collateral risk), Rule 2 (probability + severity → mitigation trigger)

- Critical path:
  1. Instantiate TargetAISystem with architecture type, components, DataQualityMetric
  2. Define TargetEngagement with attack vector, vulnerability exploited
  3. Map civilian dependencies via isContributingToCollateralDamage relations
  4. Apply Rule 1 to classify collateral risk; apply Rule 2 to trigger mitigation if thresholds met
  5. Output: Effect classification + CDMitigationMethod recommendation

- Design tradeoffs:
  - Fixed vs. adaptive thresholds: Current rules use fixed values (0.5, 0.75); adaptive thresholds could improve context-sensitivity but reduce auditability
  - Qualitative vs. quantitative severity: Hybrid schema supports both but may create ambiguity in borderline cases
  - Ontology expressiveness vs. computational tractability: More detailed class hierarchies improve granularity but increase reasoning complexity

- Failure signatures:
  - Missing civilian dependency: If shared infrastructure is not modeled, isContributingToCollateralDamage returns false negatives
  - Threshold mismatch: If context requires different risk tolerance, fixed thresholds produce inappropriate recommendations
  - Incomplete architecture model: If AI system has components not in the hierarchy, vulnerability assessment is incomplete

- First 3 experiments:
  1. Replicate the cyber engagement use case (AI-DSS with DataQualityMetric = 0.45, shared civilian infrastructure) to verify Rule 1 and Rule 2 fire as documented
  2. Add a new TargetEngagement subclass (e.g., DataPoisoningAttack) and trace its collateral pathways through existing civilian dependency relations
  3. Stress-test thresholds: run scenarios with probability = 0.74 and severity = "Severe" to observe rule boundary behavior and assess whether mitigation recommendations are appropriately conservative or permissive

## Open Questions the Paper Calls Out

- Question: How can Large Language Models (LLMs) and Reinforcement Learning (RL) be integrated into the CDAIMO framework to automate scenario generation and optimize risk mitigation?
  - Basis in paper: The conclusion states that future research "will incorporate LLM-driven scenario generation and RL-based optimization to refine assessments and mitigate risks."
  - Why unresolved: The current model relies on static Knowledge Representation and Reasoning (KRR) rules and a manual instantiation process.
  - What evidence would resolve it: A functional extension of the CDAIMO architecture where RL agents successfully optimize engagement decisions based on LLM-generated scenarios.

- Question: To what extent does the CDAIMO model generalize to kinetic and electronic warfare domains beyond the demonstrated cyber engagement use case?
  - Basis in paper: The conclusion identifies the need for "experimentation across multiple warfare domains" to enable responsible military AI development.
  - Why unresolved: The evaluation section only demonstrates the model via a single cyber attack use case, leaving other engagement vectors (Physical, EW) untested.
  - What evidence would resolve it: Successful instantiation of the model in non-cyber scenarios (e.g., kinetic strikes on AI infrastructure) showing that the temporal, spatial, and force metrics remain valid.

- Question: Are the specific numeric thresholds used in the reasoning rules (e.g., probability > 0.75, data quality < 0.5) empirically valid for legal and operational compliance?
  - Basis in paper: Rules 1 and 2 utilize specific constants ("hasDataQuality max 0.5", "hasProbability min 0.75") to trigger mitigation, but the paper does not cite data justifying these specific values.
  - Why unresolved: The authors present these thresholds as part of the architectural design, but their correlation with actual collateral damage risk or legal standards is not validated.
  - What evidence would resolve it: Sensitivity analysis or domain expert validation confirming that these specific boundary values accurately distinguish acceptable from excessive collateral damage.

## Limitations
- Fixed threshold values (0.5 for data quality, 0.75 for probability) lack empirical justification and may not generalize across different engagement scenarios
- Ontology structure is incompletely specified with referenced figures not fully enumerated in text
- Single cyber engagement use case provides insufficient evidence for systematic performance across diverse AI architectures and attack vectors
- No corpus validation showing multi-dimensional KRR approach outperforms existing single-domain damage assessment methods

## Confidence
- High: Technical architecture of CDAIMO as a KRR ontology with class hierarchies, properties, and SWRL-style rules is clearly specified and implementable
- Medium: Claim about meaningful decomposition of temporal, spatial, and force dimensions depends on assumption that these dimensions are truly orthogonal in practice
- Low: Operational validity of fixed threshold values across different military contexts is unproven and appears arbitrary without empirical validation

## Next Checks
1. Replicate the documented use case with exact parameters (AI-DSS system, DataQualityMetric=0.45, probability=0.81, severity="Severe") to verify Rule 1 correctly classifies collateral risk and Rule 2 triggers appropriate mitigation method
2. Test threshold boundary conditions by running scenarios with probability=0.74 (just below threshold) and probability=0.75 (at threshold) with severity="Severe" to assess model's decision boundaries
3. Expand ontology validation by adding a new TargetEngagement subclass (e.g., DataPoisoningAttack) and tracing its collateral pathways through existing civilian dependency relations