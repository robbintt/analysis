---
ver: rpa2
title: 'BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and
  Non-Hate Speech Classification'
arxiv_id: '2601.20129'
source_url: https://arxiv.org/abs/2601.20129
tags:
- bengali
- hate
- sentiment
- dataset
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BengaliSent140, a large-scale Bengali binary
  sentiment dataset created by merging seven heterogeneous Bengali text corpora into
  a unified benchmark. The dataset is designed to address the scarcity of large, diverse,
  and consistently annotated resources for Bengali hate and non-hate speech classification.
---

# BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification

## Quick Facts
- **arXiv ID**: 2601.20129
- **Source URL**: https://arxiv.org/abs/2601.20129
- **Authors**: Akif Islam; Sujan Kumar Roy; Md. Ekramul Hamid
- **Reference count**: 18
- **Primary result**: A large-scale Bengali binary sentiment dataset for hate and non-hate speech classification, containing 139,792 samples with balanced classes (68,548 hate, 71,244 not-hate)

## Executive Summary
This paper introduces BengaliSent140, a large-scale Bengali binary sentiment dataset created by merging seven heterogeneous Bengali text corpora into a unified benchmark. The dataset is designed to address the scarcity of large, diverse, and consistently annotated resources for Bengali hate and non-hate speech classification. To ensure uniformity, diverse annotation schemes from the source datasets are harmonized into a binary formulation with two classes: Hate (1) and Not Hate (0). The resulting dataset contains 139,792 unique text samples, with 68,548 labeled as hate and 71,244 as not-hate, yielding a balanced class distribution. Multiple text representations—including raw, normalized, and lemmatized versions—are provided to facilitate systematic preprocessing analysis. Baseline experiments using classical machine learning, deep learning, and transfer learning models demonstrate the dataset's effectiveness, with the best-performing model (BERT) achieving a test accuracy of 0.91. BengaliSent140 offers broad linguistic and contextual coverage, making it a valuable resource for training and benchmarking deep learning models for Bengali sentiment and hate speech detection. The dataset is publicly available for research use.

## Method Summary
BengaliSent140 was constructed by merging seven heterogeneous Bengali text corpora into a unified benchmark dataset. The primary challenge was harmonizing diverse annotation schemes from the source datasets into a consistent binary formulation (Hate vs. Not Hate). The final dataset contains 139,792 unique text samples with balanced class distribution. Multiple text representations (raw, normalized, lemmatized) were generated to facilitate systematic preprocessing analysis. The dataset addresses the scarcity of large, diverse, and consistently annotated resources for Bengali hate speech classification.

## Key Results
- Dataset contains 139,792 unique Bengali text samples with balanced class distribution (68,548 hate, 71,244 not-hate)
- Multiple text representations provided: raw, normalized, and lemmatized versions
- Baseline experiments show effectiveness across classical ML, deep learning, and transfer learning models
- Best-performing model (BERT) achieves test accuracy of 0.91

## Why This Works (Mechanism)
BengaliSent140 works effectively because it addresses a critical gap in Bengali natural language processing resources by providing a large-scale, balanced, and consistently annotated dataset specifically for hate speech detection. The harmonization of seven heterogeneous corpora into a unified binary classification framework creates a standardized benchmark that enables systematic comparison of different models. The provision of multiple text representations (raw, normalized, lemmatized) allows researchers to systematically analyze the impact of preprocessing on model performance. The dataset's balanced class distribution prevents model bias toward the majority class, which is crucial for hate speech detection where both positive and negative cases need equal attention. The combination of classical ML, deep learning, and transfer learning baselines demonstrates the dataset's versatility across different modeling approaches.

## Foundational Learning
- **Text Normalization**: Essential for handling the morphological complexity of Bengali and reducing vocabulary size; quick check: compare vocabulary size before/after normalization
- **Lemmatization in Bengali**: Critical for reducing words to their base forms in a morphologically rich language; quick check: analyze reduction in unique tokens after lemmatization
- **Binary Classification Framework**: Simplifies the complex task of hate speech detection into a manageable two-class problem; quick check: examine confusion matrix for class separation quality
- **Dataset Merging and Harmonization**: Necessary for creating large-scale datasets from multiple sources while maintaining annotation consistency; quick check: validate annotation agreement across merged sources
- **Transfer Learning with BERT**: Leverages pre-trained multilingual models for improved performance on low-resource languages like Bengali; quick check: compare BERT performance against non-pretrained models

## Architecture Onboarding

**Component Map**: Raw Text -> Preprocessing (Normalization/Lemmatization) -> Feature Extraction (Classical ML) or Embedding (Deep Learning) -> Classification Model -> Output (Hate/Not Hate)

**Critical Path**: The critical path involves data preprocessing (normalization and lemmatization), followed by model training and evaluation. The preprocessing steps are crucial as they directly impact the quality of features or embeddings used by downstream models.

**Design Tradeoffs**: The binary classification approach simplifies the annotation task but may lose nuanced information about different types of hate speech. Providing multiple text representations increases dataset utility but also storage requirements. Using transfer learning (BERT) offers strong performance but requires significant computational resources compared to classical ML methods.

**Failure Signatures**: Potential failure modes include: (1) poor preprocessing leading to loss of important linguistic features, (2) class imbalance despite reported balance, (3) annotation inconsistency across merged datasets, (4) model overfitting to specific types of hate speech present in training data, (5) poor generalization to dialects or sociolects not well-represented in the dataset.

**First Experiments**:
1. Train and evaluate a simple logistic regression classifier using TF-IDF features to establish a classical ML baseline
2. Fine-tune a multilingual BERT model on the dataset to assess transfer learning effectiveness
3. Perform ablation studies comparing model performance using raw vs. normalized vs. lemmatized text representations

## Open Questions the Paper Calls Out
None

## Limitations
- The paper does not provide detailed information on the inter-annotator agreement or the quality control measures used during the harmonization of the seven source datasets into a unified binary annotation scheme. This raises concerns about the consistency and reliability of the final annotations, especially given the diversity of the source datasets.
- While the dataset is described as "large-scale" and "balanced," the paper does not provide a comprehensive analysis of the dataset's coverage of different dialects, sociolects, or contextual nuances in Bengali. This limits the generalizability of the dataset to all forms of Bengali hate speech.
- The paper does not discuss the potential biases introduced during the merging process, such as overrepresentation of certain types of hate speech or underrepresentation of nuanced cases. This could affect the model's performance in real-world scenarios.

## Confidence
- **High**: The dataset's size (139,792 samples) and balanced class distribution are well-supported by the paper. The claim about the dataset being publicly available is also verifiable.
- **Medium**: The effectiveness of the dataset for hate speech detection is demonstrated through baseline experiments, but the lack of detailed annotation quality metrics reduces confidence in the reliability of the labels.
- **Low**: Claims about the dataset's broad linguistic and contextual coverage are not substantiated with empirical evidence or detailed analysis.

## Next Checks
1. **Annotation Quality Assessment**: Conduct an independent evaluation of the inter-annotator agreement and annotation consistency across the seven source datasets to validate the reliability of the harmonized binary labels.
2. **Bias Analysis**: Perform a detailed analysis of the dataset to identify potential biases in the representation of different types of hate speech, dialects, and sociolects in Bengali.
3. **Generalizability Testing**: Test the dataset's performance on real-world Bengali hate speech detection tasks to assess its generalizability and robustness across diverse contexts.