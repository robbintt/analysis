---
ver: rpa2
title: 'DEER: Disentangled Mixture of Experts with Instance-Adaptive Routing for Generalizable
  Machine-Generated Text Detection'
arxiv_id: '2511.01192'
source_url: https://arxiv.org/abs/2511.01192
tags:
- domain
- expert
- experts
- domains
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DEER, a generalizable MGT detector using disentangled
  mixture-of-experts with instance-adaptive routing. The core idea is to separate
  domain-specific and domain-general patterns via specialized experts, then use RL
  to adaptively select experts at inference without domain labels.
---

# DEER: Disentangled Mixture of Experts with Instance-Adaptive Routing for Generalizable Machine-Generated Text Detection

## Quick Facts
- **arXiv ID:** 2511.01192
- **Source URL:** https://arxiv.org/abs/2511.01192
- **Reference count:** 40
- **Key outcome:** DEER improves MGT detection F1-score by 1.39% (in-domain) and 5.32% (out-of-domain) over state-of-the-art methods

## Executive Summary
This paper introduces DEER (Disentangled Mixture of Experts with Instance-Adaptive Routing), a generalizable machine-generated text (MGT) detection framework. The core innovation lies in separating domain-specific and domain-general patterns through specialized experts, then using reinforcement learning to adaptively select the most appropriate expert at inference without requiring domain labels. Experimental results demonstrate significant improvements in both in-domain and out-of-domain detection performance, with ablation studies confirming the effectiveness of both the disentangled expert design and the adaptive routing mechanism.

## Method Summary
DEER employs a mixture-of-experts architecture where each expert is specialized for either a specific source domain (domain-specific expert) or general MGT patterns (domain-general expert). The framework uses a policy network to learn instance-adaptive routing decisions through reinforcement learning, selecting the optimal expert for each input based on the current domain context. During training, domain labels are used to train specialized experts, but at inference time, the policy network automatically selects the most appropriate expert without requiring domain information. The disentangled architecture allows for modular expansion when new domains are introduced, and the adaptive routing mechanism enables zero-shot adaptation to unseen domains.

## Key Results
- DEER achieves 1.39% improvement in F1-score for in-domain MGT detection compared to state-of-the-art methods
- Out-of-domain performance improves by 5.32% F1-score, demonstrating strong generalization capabilities
- The framework shows robustness against text perturbations including repeat, delete, and replace operations
- Modular expansion capability allows efficient adaptation to new domains with minimal additional training

## Why This Works (Mechanism)
DEER works by decoupling domain-specific patterns from domain-general MGT characteristics through specialized expert networks. The domain-specific experts learn to capture unique stylistic and structural features of their respective source domains, while the domain-general expert learns universal MGT indicators that transcend domain boundaries. The reinforcement learning-based routing mechanism then acts as an intelligent selector, determining which expert is best suited for each input instance based on learned domain context. This separation prevents interference between domain-specific knowledge and general MGT patterns, allowing each component to specialize effectively. The adaptive routing enables the system to handle domain shifts dynamically, selecting appropriate experts for both seen and unseen domains without requiring explicit domain labels at inference time.

## Foundational Learning
- **Mixture of Experts (MoE):** Why needed - enables specialized learning for different domains; Quick check - understand how gating mechanisms route inputs to different experts
- **Reinforcement Learning for Routing:** Why needed - enables adaptive selection without domain labels; Quick check - grasp policy gradient methods and reward design for expert selection
- **Domain Adaptation:** Why needed - critical for handling distribution shifts; Quick check - understand zero-shot learning and domain generalization concepts
- **Disentangled Representation Learning:** Why needed - prevents interference between domain-specific and general patterns; Quick check - review techniques for separating correlated features
- **Instance-Adaptive Processing:** Why needed - allows dynamic response to input characteristics; Quick check - understand conditional computation and input-dependent model selection

## Architecture Onboarding

**Component Map:** Input Text -> Token Embeddings -> Policy Network -> Expert Selection -> (Domain-Specific Expert OR Domain-General Expert) -> Detection Output

**Critical Path:** Input → Tokenization → Embedding Layer → Policy Network → Expert Router → Selected Expert → Classification Head → Output

**Design Tradeoffs:** The framework trades increased model complexity (multiple experts + policy network) for improved generalization and adaptability. While this increases inference latency compared to single-expert models, the benefits in cross-domain performance and modular expansion capability justify the overhead.

**Failure Signatures:** Performance degradation may occur when: (1) domain shift is extreme beyond the training distribution, (2) policy network fails to correctly identify the appropriate expert, (3) source domains are too similar causing expert overlap, or (4) text perturbations significantly alter domain-indicative features.

**First Experiments:** 1) Verify expert specialization by testing each expert's performance on its target domain, 2) Evaluate routing accuracy by checking if the policy network selects the correct expert for domain-labeled test data, 3) Measure computational overhead of the policy network compared to direct classification.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Limited evaluation scope restricted to text classification tasks without testing on more complex MGT detection scenarios
- Performance gains from adaptive routing are modest (5.32% F1 improvement), raising questions about cost-benefit ratio
- The complexity of RL-based routing decisions and lack of interpretability create uncertainty about behavior in extreme domain shifts
- Potential overfitting to specific domain shifts tested without comprehensive error analysis or failure mode characterization

## Confidence
- **High:** Disentangled expert architecture design and ablation results
- **Medium:** Out-of-domain performance improvements
- **Low:** Generalizability to extreme domain shifts and complex MGT detection tasks

## Next Checks
1. Test DEER's performance on cross-lingual MGT detection tasks to validate its generalizability beyond English domains
2. Conduct comprehensive robustness testing against adversarial attacks specifically targeting the adaptive routing mechanism
3. Evaluate the model's performance on multi-class MGT detection tasks to verify its applicability to more complex detection scenarios