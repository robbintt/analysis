---
ver: rpa2
title: 'MedQARo: A Large-Scale Benchmark for Evaluating Large Language Models on Medical
  Question Answering in Romanian'
arxiv_id: '2508.16390'
source_url: https://arxiv.org/abs/2508.16390
tags:
- medical
- cancer
- romanian
- question
- patients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MedQARo, the first large-scale medical question
  answering benchmark in Romanian, comprising 105,880 high-quality QA pairs extracted
  from oncology patient records. The dataset was manually annotated by seven physicians
  over approximately 3,000 work hours, ensuring linguistic and medical accuracy.
---

# MedQARo: A Large-Scale Benchmark for Evaluating Large Language Models on Medical Question Answering in Romanian

## Quick Facts
- arXiv ID: 2508.16390
- Source URL: https://arxiv.org/abs/2508.16390
- Reference count: 40
- First large-scale medical QA benchmark in Romanian with 105,880 QA pairs from oncology patient records

## Executive Summary
This paper introduces MedQARo, the first large-scale medical question answering benchmark in Romanian, comprising 105,880 high-quality QA pairs extracted from oncology patient records. The dataset was manually annotated by seven physicians over approximately 3,000 work hours, ensuring linguistic and medical accuracy. It includes both in-domain and cross-domain test collections to assess model generalization across medical centers and cancer types.

The authors evaluate four open-source LLMs (RoLLaMA2-7B, RoMistral-7B, Phi-4-mini-instruct, and LLaMA3-OpenBioLLM-8B) under zero-shot and fine-tuning configurations, as well as two API-based models (GPT-5.2 and Gemini 3 Flash) in zero-shot mode. Results show that fine-tuned models significantly outperform zero-shot variants, with Phi-4-mini-instruct achieving the best performance (F1 score of 0.667 on in-domain test). The study demonstrates that domain-specific and language-specific fine-tuning is crucial for reliable clinical QA in low-resource languages like Romanian, as even state-of-the-art API-based models are outperformed by smaller fine-tuned LLMs.

## Method Summary
The study employs LoRA-based fine-tuning on four open-source LLMs using the MedQARo dataset with patient-level splits to prevent data leakage. Models are trained with AdamW optimizer, cosine learning rate scheduler, and BFLOAT16 precision. The training objective is token-level cross-entropy for generating answers in a question-context-answer format. Context truncation (2,048-3,072 tokens) is used as implicit regularization, and prompt structure follows Q+E+A format. Evaluation includes both in-domain and cross-domain test sets with F1, EM, BLEU, and METEOR metrics.

## Key Results
- Fine-tuned models significantly outperform zero-shot variants, with Phi-4-mini-instruct achieving the best performance (F1 score of 0.667 on in-domain test)
- Context truncation to 2,048-3,072 tokens acts as regularization, improving performance over longer contexts
- Q+E+A prompt format consistently outperforms E+Q+A across most evaluation metrics
- Cross-domain performance drops significantly (F1 from ~0.67 to ~0.40), indicating overfitting to training distribution
- Fine-tuned smaller models (0.5950-0.667 F1) substantially outperform API-based models like GPT-5.2 (0.2415 F1)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LoRA-based fine-tuning enables task-specific adaptation that pretrained models lack, even when models have prior language or domain specialization.
- Mechanism: Supervised fine-tuning on Romanian clinical QA pairs aligns model outputs to specific answer formats (binary, extractive, reasoning) while LoRA adapters update only attention projection layers (~0.04-0.10% of parameters), preserving base knowledge while learning task-specific patterns. The fine-tuning objective (token-level cross-entropy) directly optimizes for correct answer generation.
- Core assumption: The performance gap stems from lack of task-specific alignment rather than insufficient model capacity.
- Evidence anchors:
  - [abstract] "fine-tuned models significantly outperform zero-shot variants, with Phi-4-mini-instruct achieving the best performance (F1 score of 0.667 on in-domain test)"
  - [section 5.3] "zero-shot models exhibit significantly lower performance than their fine-tuned counterparts... scores can increase by an order of magnitude when going from zero-shot prompting to fine-tuning"
  - [corpus] PersianMedQA and PerMedCQA similarly demonstrate that language-specific benchmarks reveal gaps in pretrained model capabilities for medical QA in low-resource languages.

### Mechanism 2
- Claim: Context truncation acts as implicit regularization, reducing input noise and preventing overfitting to spurious correlations in longer documents.
- Mechanism: Epicrises average 7,829 tokens but contain task-relevant information concentrated in earlier sections (diagnosis, staging, initial treatment). Truncating to 2,048-3,072 tokens removes potentially distracting later content while preserving decision-critical information, improving signal-to-noise ratio for the QA task.
- Core assumption: Medical decision-relevant information follows a predictable distribution pattern within clinical documents.
- Evidence anchors:
  - [section 5.3] "trimming the end part of the epicrisis seems to act as a regularization technique, and finding the optimal context length can be assimilated with the process of tuning the corresponding regularization hyperparameter"
  - [section 5.3, Table 9] "First chunk" approach (0.6618 F1) significantly outperforms "All chunks" with majority voting (0.4913 F1)

### Mechanism 3
- Claim: Placing the question before context (Q+E+A format) improves model attention allocation to task-relevant information.
- Mechanism: Transformer attention patterns weight earlier tokens more heavily; placing the question first primes the model to attend selectively to relevant epicrisis sections while processing context, improving answer extraction accuracy.
- Core assumption: Models exhibit systematic attention bias toward earlier sequence positions that can be exploited through prompt engineering.
- Evidence anchors:
  - [section 5.2] "the Q+E+A format yields higher performance across most evaluation metrics... As confirmed by other studies [5], the first tokens tend to receive more attention"

## Foundational Learning

- Concept: LoRA (Low-Rank Adaptation)
  - Why needed here: All fine-tuning experiments use LoRA to adapt 7-8B parameter models efficiently, updating only 0.04-0.10% of weights. Understanding LoRA rank (r=8), scaling factor (α=16), and target modules (attention projections) is essential for reproducing results.
  - Quick check question: Can you explain why LoRA adapters are injected into self-attention layers rather than feed-forward layers for this task?

- Concept: Patient-level data splitting
  - Why needed here: MedQARo prevents data leakage by ensuring all QA pairs from a single patient remain in one split (train/validation/test). This is critical because epicrises contain redundant information, and QA pairs about the same patient share context.
  - Quick check question: Why would random QA-pair splitting artificially inflate test performance in medical QA datasets?

- Concept: Cross-domain evaluation (center shift + diagnosis shift)
  - Why needed here: MedQARo includes a cross-domain test set from a different medical center with unseen cancer types, revealing that fine-tuned models achieve only ~0.40 F1 vs. ~0.67 in-domain. This tests true generalization beyond memorization.
  - Quick check question: What two distribution shifts does the MedQARo cross-domain test simultaneously introduce?

## Architecture Onboarding

- Component map:
  - Dataset: 105,880 QA pairs (71,772 train / 15,328 validation / 15,546 in-domain test / 3,234 cross-domain test)
  - Input format: Question + Epicrisis + Answer (truncated to optimal token length per model)
  - Models: RoLLaMA2-7B, RoMistral-7B (Romanian-adapted); Phi-4-mini-instruct (long-context); LLaMA3-OpenBioLLM-8B (biomedical)
  - Training: LoRA adapters on attention layers, AdamW optimizer, cosine LR scheduler, 3 epochs max, BFLOAT16 precision

- Critical path:
  1. Load MedQARo dataset with patient-level splits
  2. Format prompts using Q+E+A structure with appropriate token limit (2,048-3,072 optimal for most models)
  3. Initialize LoRA adapters (r=8, α=16) on attention projections
  4. Fine-tune with LR=2×10⁻⁵, dropout=0.05, batch size=8 (via gradient accumulation)
  5. Evaluate with F1, EM, BLEU, METEOR metrics on both in-domain and cross-domain test sets

- Design tradeoffs:
  - Context length vs. signal-to-noise: Longer contexts capture more information but introduce noise; optimal is 2,048-3,072 tokens
  - Language-adapted vs. general models: Romanian-adapted models (RoLLaMA2, RoMistral) provide modest benefits but are outperformed by generic Phi-4-mini with fine-tuning
  - Zero-shot API models vs. fine-tuned open-source: API models (GPT-5.2: 0.2415 F1) are cost-effective for inference but substantially underperform fine-tuned smaller models (0.5950-0.667 F1)

- Failure signatures:
  - Zero-shot models performing near majority-answer baseline (F1 ~0.21) indicates task misalignment
  - Cross-domain F1 dropping from ~0.67 to ~0.40 indicates overfitting to training distribution
  - EM scores exceeding F1 suggests models either match exactly or miss entirely, with few partial matches
  - Performance degradation with 4,096+ token contexts suggests attention dilution or overfitting to noise

- First 3 experiments:
  1. Replicate zero-shot vs. fine-tuned comparison for a single model (e.g., RoMistral-7B) at 2,048 tokens to validate the order-of-magnitude improvement claim.
  2. Test context length sensitivity curve (1,024 / 2,048 / 3,072 / 4,096 tokens) on Phi-4-mini to identify optimal regularization point and verify inverted-U pattern.
  3. Compare Q+E+A vs. E+Q+A prompt formats on validation set to confirm attention-priming effect with statistical significance testing across multiple runs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Retrieval-Augmented Generation (RAG) effectively mitigate the information loss caused by context trimming in long clinical documents?
- Basis in paper: [explicit] The authors state in the conclusion, "In future work, we aim to develop models that integrate retrieval-augmented generation... [to] minimize the risk of eliminating important information during context trimming."
- Why unresolved: The current methodology forces a trade-off where text exceeding the token limit (e.g., 3,072 tokens) is truncated, which explicitly caused errors in tasks like TNM staging where key details appear near the end of the epicrisis.
- What evidence would resolve it: A comparative evaluation showing that a RAG-based approach retrieving specific text segments outperforms the current best fine-tuned model (Phi-4-mini) on reasoning questions requiring information distributed throughout long documents.

### Open Question 2
- Question: What architectural or training modifications are required to enable LLMs to effectively utilize extended context windows (e.g., 16k+ tokens) without suffering from performance degradation?
- Basis in paper: [inferred] Results in Table 6 show that performance degrades for Phi-4-mini as context length increases from 3,072 to 32,768 tokens. The authors hypothesize that longer contexts introduce "input clutter" or overfitting, but the precise mechanism and solution remain unidentified.
- Why unresolved: It is counter-intuitive that providing more patient history degrades the model's QA accuracy; current models appear unable to filter noise effectively in long contexts.
- What evidence would resolve it: Demonstrating a model configuration or attention mechanism that shows a positive correlation between context window size and F1 score on the MedQARo benchmark.

### Open Question 3
- Question: How can the domain gap between distinct medical centers and cancer types be bridged to improve cross-domain generalization?
- Basis in paper: [explicit] The authors note that "fine-tuning alone is not sufficient to recover the domain gap," observing a significant performance drop in cross-domain tests (Table 7) where models encountered patients from a different hospital with unseen cancer types.
- Why unresolved: The study establishes that models overfit to the specific linguistic and medical patterns of the training center (Colțea Clinical Hospital), but does not identify techniques (e.g., domain adaptation, data augmentation) to solve this.
- What evidence would resolve it: An experiment showing that a specific adaptation strategy reduces the performance differential between the in-domain test set (F1 0.667) and the cross-domain test set (F1 0.372).

## Limitations

- Data representativeness and bias: Dataset derives from single Romanian oncology center with limited geographical and institutional diversity
- Performance metrics and clinical relevance: Lacks clinical validation of model outputs and assessment of real-world safety
- Technical constraints and reproducibility: Missing exact inference parameters and precise LoRA target module specifications

## Confidence

**High Confidence:**
- Fine-tuned models significantly outperform zero-shot variants (F1 improvement from ~0.21 to ~0.67)
- Phi-4-mini-instruct achieves the best overall performance (F1=0.667 on in-domain test)
- Context truncation to 2,048-3,072 tokens improves performance compared to longer contexts
- Q+E+A prompt format consistently outperforms E+Q+A across models

**Medium Confidence:**
- Romanian-adapted models (RoLLaMA2, RoMistral) provide modest benefits over generic models
- The regularization effect of context truncation is optimal at specific token lengths
- Cross-domain performance drop reflects genuine distribution shift rather than dataset artifacts

**Low Confidence:**
- Clinical utility and safety of model-generated answers
- Generalizability beyond Romanian oncology contexts
- Long-term stability of fine-tuned models on evolving medical knowledge

## Next Checks

1. **Clinical Validation Study:** Conduct physician evaluation of model outputs on a subset of MedQARo test questions to assess clinical acceptability, safety, and potential harm from incorrect answers.

2. **Multi-Center Generalizability Test:** Expand cross-domain evaluation to include QA pairs from multiple additional Romanian medical centers and non-oncology specialties to better assess true generalization capabilities.

3. **Ablation Study on Context Truncation:** Systematically vary truncation points and analyze which document sections contain the most relevant information, validating whether the observed regularization effect is consistent across different cancer types and question categories.