---
ver: rpa2
title: 'PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based
  Dementia Monitoring'
arxiv_id: '2511.16445'
source_url: https://arxiv.org/abs/2511.16445
tags:
- detection
- user
- drift
- anomaly
- persona
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PersonaDrift introduces a synthetic benchmark for detecting gradual
  communication changes in people living with dementia through digital reminders.
  The benchmark simulates 60-day interaction logs with eight caregiver-informed personas
  exhibiting varied tones, modalities, and expressiveness.
---

# PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring

## Quick Facts
- arXiv ID: 2511.16445
- Source URL: https://arxiv.org/abs/2511.16445
- Reference count: 40
- Primary result: Personalized classifiers outperform generalized ones for detecting dementia-related communication drift

## Executive Summary
PersonaDrift introduces a synthetic benchmark for detecting gradual communication changes in people living with dementia through digital reminders. The benchmark simulates 60-day interaction logs with eight caregiver-informed personas exhibiting varied tones, modalities, and expressiveness. Two key behavioral drifts—flattened sentiment and off-topic replies—are injected progressively at different speeds. Evaluations compare unsupervised methods (CUSUM, EWMA, One-Class SVM), sequence models (GRU + BERT), and personalized versus generalized supervised classifiers. Across both tasks, personalized classifiers consistently outperform generalized ones, emphasizing the importance of user-specific adaptation in dementia monitoring systems.

## Method Summary
The benchmark generates synthetic 60-day interaction logs using eight personas with varied communication characteristics. Two types of anomalies are injected: flattened sentiment (reduced emotional tone) and off-topic replies (semantic drift). Detection methods include statistical approaches (CUSUM, EWMA, One-Class SVM) for sentiment features, and temporal-semantic models (GRU with BERT embeddings) for off-topic detection. Performance is evaluated using F1 scores, detection delay, and ROC AUC across different anomaly speeds and persona types.

## Key Results
- Personalized classifiers consistently outperform generalized ones across both flattened sentiment and off-topic detection tasks
- Flattened sentiment is reliably detected using simple statistical methods in stable personas
- Off-topic detection requires temporal modeling and personalized baselines due to semantic complexity
- Detection delay varies significantly based on anomaly speed and persona expressiveness

## Why This Works (Mechanism)

### Mechanism 1
Personalized baselines are likely required for reliable semantic drift detection in dementia communication monitoring. Generic models struggle to distinguish between a user's natural idiosyncratic speech patterns and genuine cognitive drift. By training on a specific user's history, the model calibrates to that individual's "normal," reducing false positives caused by inter-individual variability. This mechanism breaks if the user exhibits high baseline volatility or if the initial training period is too short to capture a representative behavioral sample.

### Mechanism 2
Different anomaly archetypes (affective vs. semantic) likely require distinct detection architectures—statistical for affect, temporal-semantic for meaning. Flattened sentiment is a scalar, surface-level feature shift that accumulates predictably, making it amenable to statistical process control. In contrast, off-topic replies involve high-dimensional semantic relationships that require contextual embeddings to capture meaning and sequence models to track coherence over time. This breaks if the user has a naturally "flat" baseline affect or if the semantic drift is subtle enough to remain topically similar but contextually wrong.

### Mechanism 3
Synthetic benchmarking via controlled anomaly injection allows for the safe evaluation of detection latency and threshold sensitivity. By mathematically defining the onset, speed, and severity of anomalies, the system creates ground truth labels in a synthetic environment. This permits the calculation of "detection delay" which is ethically impossible to obtain precisely in real-world degenerative scenarios. This mechanism fails if the LLM generates drift that is lexically distinct from human cognitive drift, leading to models that overfit to "synthetic artifacts" rather than genuine pathology.

## Foundational Learning

- **Concept: Cumulative Sum Control Chart (CUSUM)**
  - Why needed here: Primary baseline method for detecting flattened sentiment by summing deviations from a mean to detect sustained shifts
  - Quick check question: If a user's sentiment varies wildly day-to-day but trends downward slowly, would CUSUM flag it faster than a simple threshold check, or would the noise mask the signal?

- **Concept: Contextual Embeddings (BERT)**
  - Why needed here: Standard keyword matching fails to detect "off-topic" replies where words may overlap but meaning diverges
  - Quick check question: Why does the paper use the *cosine distance* between BERT embeddings rather than Euclidean distance to detect semantic drift?

- **Concept: Personalized vs. Generalized Modeling**
  - Why needed here: The paper's central finding is that generalized models fail for this specific task
  - Quick check question: In the "Leave-One-User-Out" experiment, does the generalized model fail because it hasn't seen anomalies, or because it hasn't seen the specific user's normal behavior?

## Architecture Onboarding

- **Component map:** Persona Layer -> Simulation Engine -> Feature Extractor -> Detection Layer -> Evaluation Module
- **Critical path:** Define Persona -> Generate baseline logs -> Inject Drift -> Extract features -> Run Detection
- **Design tradeoffs:** Stability vs. Sensitivity in tuning CUSUM/EWMA parameters; Modality Fidelity (text-only transcripts miss prosodic features)
- **Failure signatures:** High false positives for expressive/voice-based personas; slow drift undetected by One-Class SVM/CUSUM; calibration/thresholding failure for generalized classifiers
- **First 3 experiments:**
  1. Run CUSUM on Persona 1 (Brief, Low Expressiveness) vs. Persona 6 (High Expressiveness) to observe F1 divergence
  2. Train GRU on Persona 5 (Stable Voice) and vary error percentile threshold to visualize trade-off between Detection Delay and False Positives
  3. Train classifier on Personas 1-7 and test on Persona 3 (Hesitant/Variable) to check if model confuses "PM Hesitancy" for "Semantic Drift"

## Open Questions the Paper Calls Out

### Open Question 1
Can multimodal signals (prosody, speech timing, typing behavior) improve detection accuracy for voice-based personas with high baseline variability? The benchmark only processes text; Personas 3, 7, and 8 showed degraded detection due to variability that acoustic features might clarify.

### Open Question 2
How can threshold calibration be improved for models achieving high ROC AUC but moderate F1 scores (e.g., GRU with AUC >0.95 but F1 0.4–0.7)? The paper evaluates existing methods but does not propose solutions for personalized, adaptive thresholding in progressive drift scenarios.

### Open Question 3
Do detection methods validated on PersonaDrift transfer to real PLwD interaction logs, and what performance gaps emerge? The benchmark is synthetic; ecological validity has not been tested against actual caregiver-PLwD reminder interactions.

### Open Question 4
Can additional anomaly types—repetition, lexical retrieval issues, syntactic simplification—be reliably detected using the current benchmark framework? The benchmark only supports flattened sentiment and off-topic drift; caregiver interviews identified these as tractable starting points.

## Limitations
- Synthetic benchmark design introduces uncertainty about real-world transferability
- Confidence in detection performance is Medium due to potential mismatch between LLM-generated and actual dementia progression
- Assumption that controlled anomaly injection accurately represents naturalistic cognitive trajectories remains unverified against clinical data

## Confidence
- **High Confidence:** Personalized classifiers consistently outperform generalized ones across both tasks
- **Medium Confidence:** Different anomaly types require distinct detection architectures
- **Low Confidence:** Synthetic benchmarking allows for precise evaluation of detection latency

## Next Checks
1. Test detection algorithms on a small cohort of actual dementia patients using their real digital communication logs
2. Conduct a stability study to determine how quickly user baselines shift in reality
3. Systematically vary baseline communication volatility in synthetic environment to identify failure conditions