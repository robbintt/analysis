---
ver: rpa2
title: 'MammoClean: Toward Reproducible and Bias-Aware AI in Mammography through Dataset
  Harmonization'
arxiv_id: '2511.02400'
source_url: https://arxiv.org/abs/2511.02400
tags:
- breast
- mammography
- dataset
- images
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents MammoClean, a framework for standardizing and
  harmonizing mammography datasets to address bias and heterogeneity issues that hinder
  AI model generalizability. MammoClean standardizes case selection, image processing
  (including laterality and intensity correction), and unifies metadata into a consistent
  multi-view structure.
---

# MammoClean: Toward Reproducible and Bias-Aware AI in Mammography through Dataset Harmonization

## Quick Facts
- **arXiv ID**: 2511.02400
- **Source URL**: https://arxiv.org/abs/2511.02400
- **Reference count**: 40
- **Primary result**: MammoClean framework standardizes mammography datasets to address bias and heterogeneity, enabling superior cross-domain AI generalization

## Executive Summary
MammoClean addresses critical challenges in mammography AI development by providing a systematic framework for dataset harmonization. The framework tackles heterogeneity across datasets through standardized case selection, image processing (including laterality and intensity correction), and unified metadata structure. By applying MammoClean to three heterogeneous datasets (CBIS-DDSM, TOMPEI-CMMD, VinDr-Mammo), the authors demonstrated that AI models trained on harmonized data achieved superior cross-domain generalization compared to models trained on raw, heterogeneous data.

The study revealed substantial distributional shifts in breast density and abnormality prevalence across datasets, quantifying how data corruption impacts model performance. MammoClean provides a reproducible pipeline for bias-aware AI development in mammography, enabling fairer comparisons and advancing the creation of robust, equitable systems across diverse patient populations.

## Method Summary
MammoClean is a comprehensive framework that standardizes mammography datasets through multiple coordinated steps. The approach begins with case selection criteria to ensure consistent inclusion standards across datasets. Image processing includes laterality correction (ensuring left/right breast images are correctly labeled) and intensity normalization to account for variations in imaging protocols and equipment. Metadata unification transforms diverse annotation schemes into a consistent multi-view structure that captures essential clinical information.

The framework was applied to three heterogeneous mammography datasets, creating a harmonized corpus that enables fairer model training and evaluation. The harmonized datasets were then used to train AI models, with performance compared against models trained on raw, unstandardized data to quantify the benefits of the harmonization process.

## Key Results
- AI models trained on MammoClean-harmonized datasets showed superior cross-domain generalization compared to models trained on raw, heterogeneous data
- Substantial distributional shifts were identified in breast density and abnormality prevalence across the three datasets studied
- Data corruption impacts were quantified, demonstrating how heterogeneity affects model robustness and performance consistency

## Why This Works (Mechanism)
MammoClean works by eliminating systematic variations that prevent models from learning true underlying patterns rather than dataset-specific artifacts. By standardizing case selection, image processing, and metadata structure, the framework removes confounding factors that cause models to overfit to particular dataset characteristics. The harmonization process ensures that models learn features relevant across different clinical settings rather than dataset-specific biases.

The framework addresses both technical heterogeneity (imaging protocols, equipment variations) and annotation heterogeneity (different labeling schemes, case selection criteria). This comprehensive approach creates a more stable learning environment where models can develop generalizable representations that transfer effectively across different clinical contexts and patient populations.

## Foundational Learning
- **Data harmonization**: Why needed - Eliminates systematic variations between datasets that cause overfitting; Quick check - Compare feature distributions across harmonized vs. raw datasets
- **Laterality correction**: Why needed - Ensures anatomical consistency across images; Quick check - Verify left/right breast images are correctly oriented post-processing
- **Intensity normalization**: Why needed - Accounts for equipment and protocol variations; Quick check - Measure intensity distribution consistency across processed images
- **Metadata unification**: Why needed - Creates consistent representation of clinical information; Quick check - Validate that all essential clinical features are preserved and standardized
- **Distributional shift analysis**: Why needed - Identifies dataset-specific biases and variations; Quick check - Compare statistical properties (mean, variance) of key features across datasets
- **Cross-domain generalization**: Why needed - Measures model robustness across different clinical settings; Quick check - Evaluate model performance on held-out datasets from different sources

## Architecture Onboarding

**Component map**: Case selection -> Laterality correction -> Intensity normalization -> Metadata unification -> Model training

**Critical path**: The most critical sequence is: Image preprocessing (laterality + intensity) -> Metadata standardization -> Model training. Without proper image preprocessing, models learn dataset-specific artifacts rather than clinical features.

**Design tradeoffs**: The framework prioritizes standardization over preserving original dataset characteristics. This tradeoff ensures reproducibility but may lose some dataset-specific nuances that could be clinically relevant.

**Failure signatures**: Models trained on harmonized data may underperform on raw, unstandardized data from new sources. Failure to properly correct laterality can cause models to learn reversed anatomical patterns. Incomplete metadata unification can create feature gaps that prevent proper model training.

**Three first experiments**:
1. Apply MammoClean to a fourth mammography dataset and evaluate cross-domain generalization
2. Compare model performance when trained on different subsets of the harmonization pipeline (e.g., only intensity correction vs. full pipeline)
3. Analyze how different harmonization parameters affect model sensitivity to breast density variations

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Validation scope limited to three specific mammography datasets without testing across broader range of sources
- Effectiveness against demographic or socioeconomic biases not explicitly evaluated
- Clinical impact assessment missing - no evaluation of how harmonization affects diagnostic accuracy in simulated clinical workflows

## Confidence

**High confidence**:
- Technical implementation of standardization pipeline
- Cross-domain generalization improvements from harmonization

**Medium confidence**:
- Generalizability to other mammography datasets
- Bias mitigation claims without demographic analysis

**Low confidence**:
- Clinical impact assessment without outcome-based validation

## Next Checks

1. Apply MammoClean to at least five additional mammography datasets from diverse geographic and institutional sources to assess generalizability

2. Conduct a demographic bias analysis by incorporating patient age, race, and socioeconomic indicators to evaluate equity impacts

3. Perform a clinical validation study comparing model performance on harmonized versus raw data in terms of diagnostic accuracy and false positive/negative rates in simulated clinical workflows