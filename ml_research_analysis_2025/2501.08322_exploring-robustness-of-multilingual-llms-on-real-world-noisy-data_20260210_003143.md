---
ver: rpa2
title: Exploring Robustness of Multilingual LLMs on Real-World Noisy Data
arxiv_id: '2501.08322'
source_url: https://arxiv.org/abs/2501.08322
tags:
- noisy
- language
- clean
- performance
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how real-world spelling mistakes affect the
  performance of multilingual large language models (LLMs) across different tasks
  and languages. The authors construct a dataset of real-world typos from Wikipedia
  edit history and use it to create noisy test sets for three NLP tasks: natural language
  inference, named entity recognition, and intent classification in six languages.'
---

# Exploring Robustness of Multilingual LLMs on Real-World Noisy Data

## Quick Facts
- **arXiv ID**: 2501.08322
- **Source URL**: https://arxiv.org/abs/2501.08322
- **Reference count**: 39
- **Primary result**: mT5-13B most robust to real-world typos, with 2.3-4.3 percentage point gap between clean and noisy performance across six languages and three tasks

## Executive Summary
This paper investigates how real-world spelling mistakes affect multilingual large language models across natural language inference, named entity recognition, and intent classification tasks. The authors create a novel dataset of real-world typos from Wikipedia edit history and evaluate nine models ranging from 0.2B to 13B parameters. Results show that encoder-decoder models, particularly mT5-13B, demonstrate superior robustness to noise compared to decoder-only models. The study reveals that task sensitivity varies significantly, with NLI most affected and intent classification least affected, while English shows higher vulnerability than other languages tested.

## Method Summary
The study evaluates nine multilingual models (mBERT, XLM-R, mT5 variants, BLOOM, Falcon) on three tasks using both clean and artificially noised test sets. Real-world typos are mined from Wikipedia edit history to create the WikiTypo dictionary, with noise injected at a 0.2 ratio (up to 4 words per sample). mT5 models are fine-tuned for 2 epochs using DeepSpeed Zero-3, while smaller mT5 variants use 6 epochs for convergence. The primary metric is the performance gap between clean and noisy evaluations, measured in accuracy for NLI/intent classification and F1 for NER.

## Key Results
- mT5-13B shows the smallest performance gap (2.27%) between clean and noisy data
- Decoder-only models (BLOOM, Falcon) show 4-6 percentage point higher degradation than mT5 on NER tasks
- English exhibits 2× more noisy verb instances than other languages, correlating with higher vulnerability
- NLI tasks show 5+ point degradation gaps while intent classification shows <1 point

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Larger pretraining corpus exposure correlates with noise robustness, independent of model parameter count.
- Mechanism: Models trained on more tokens per language encounter more natural spelling variations during pretraining, creating implicit noise robustness through exposure diversity rather than explicit noise training.
- Core assumption: Web-scale pretraining data contains sufficient natural typos for models to learn robust representations.
- Evidence anchors:
  - [abstract] "performance gap... ranges from 2.3 to 4.3 absolute percentage points" with mT5-13B most robust
  - [section 5.1] Table 7 shows mT5 saw 2733B English tokens vs XLM-R's 750B; mT5-13B gap=2.27%, XLM-R gap=3.29%
  - [corpus] "Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors" confirms typos remain underexplored in benchmarks
- Break condition: If pretraining corpora are aggressively filtered for quality (removing typos), this mechanism weakens.

### Mechanism 2
- Claim: Encoder-decoder architecture (mT5) provides superior noise robustness compared to decoder-only models (BLOOM, Falcon) for structured prediction tasks.
- Mechanism: Encoder-decoder models process input bidirectionally before generating output, allowing contextual recovery from corrupted tokens. Decoder-only models must process and generate sequentially, amplifying error propagation.
- Core assumption: The bidirectional encoder can "repair" noisy representations before task-specific decoding.
- Evidence anchors:
  - [section 5.1] "decoder-only models such as BLOOM and Falcon show more vulnerability to noise, especially in the NER task" with BLOOM gap=4.27%, Falcon gap=3.67%
  - [section 5.1] Table 14: BLOOM-7B NER gap=8.32%, mT5-13B NER gap=1.94%
  - [corpus] Limited direct corpus evidence comparing encoder-decoder vs decoder-only noise robustness
- Break condition: For very short inputs where bidirectional context offers limited advantage, architecture differences may diminish.

### Mechanism 3
- Claim: Noise sensitivity scales with semantic density of corrupted tokens—verbs and nouns cause larger degradation than adjectives/adverbs.
- Mechanism: Content words (verbs, nouns) carry more semantic weight and have fewer contextual synonyms for error recovery. English's higher verb/noun typo frequency explains its disproportionate vulnerability.
- Core assumption: Part-of-speech distribution of noise, not just noise quantity, determines task degradation.
- Evidence anchors:
  - [section 5.5] Table 9: English has 4475 noisy verbs vs ~2200-2500 for other languages; "almost twice as many noisy verb instances"
  - [section 5.5] "replacing the adverbs and adjectives has less impact on the semantics of the sentence than the verbs and nouns"
  - [corpus] No corpus papers directly address POS-specific noise sensitivity
- Break condition: If noise uniformly affects all POS tags, language-specific differences would flatten.

## Foundational Learning

- Concept: **Masked Language Modeling (MLM) vs. Causal Language Modeling (CLM)**
  - Why needed here: The paper attributes mT5's robustness partly to its pretraining objective; understanding MLM (bidirectional) vs. CLM (unidirectional) explains why encoder-decoder models handle corrupted inputs better.
  - Quick check question: Can you explain why predicting a masked token using both left and right context might help a model "fill in" a misspelled word?

- Concept: **Tokenization algorithms (WordPiece, SentencePiece, BPE)**
  - Why needed here: Different tokenizers handle character-level noise differently; subword tokenizers may fragment misspelled words into unfamiliar subword sequences.
  - Quick check question: If "restaurant" is tokenized as ["rest", "aurant"] but misspelled as "resturant", how might the tokenization change?

- Concept: **Signal-to-noise ratio in sequence tasks**
  - Why needed here: NLI shows highest sensitivity (5+ point gaps) because longer sequences contain more noise tokens; IC shows lowest (<1 point) due to shorter, intent-focused inputs.
  - Quick check question: Why would a 30-token premise-hypothesis pair be more vulnerable to 3 typos than a 7-token intent query to 1 typo?

## Architecture Onboarding

- Component map:
```
WikiTypo Pipeline:
Wikipedia Edit History → BeautifulSoup Parser → (edit_distance=1 filter) → Language-specific typo dictionaries
                                                                              ↓
                                                                    NLPAug Augmenter (keyboard proximity)
                                                                              ↓
Noisy Test Sets: XNLI (NLI) + WikiANN (NER) + SNIPS (IC) → r=0.2 noise ratio, m=4 max augmentations

Model Zoo (9 models):
Encoder-only: mBERT (179M), XLM-R (279M)
Encoder-decoder: mT5 (300M/580M/1B/3B/13B)
Decoder-only: Falcon-7B, BLOOM-7B
```

- Critical path:
  1. Fine-tune ALL models on CLEAN multilingual training data (2 epochs typical, 6 for convergence)
  2. Evaluate on CLEAN test set → baseline performance
  3. Evaluate SAME model checkpoint on NOISY test set → degradation measurement
  4. Compute Clean-Noisy (C-N) gap per model/language/task

- Design tradeoffs:
  - **Noise source**: WikiTypo (real human errors) vs. NLPAug keyboard simulation—paper uses both; WikiTypo for XNLI/SNIPS, NLPAug for WikiANN (proper nouns rare in Wikipedia edits)
  - **Noise ratio (r=0.2, m=4)**: Higher ratios increase degradation but may not reflect realistic user error rates
  - **Fine-tuning epochs**: 2 epochs prevent overfitting but may undertrain smaller models; Figure 2 shows overfitting after epoch 2

- Failure signatures:
  - BLOOM/Falcon NER degradation >6%: Decoder-only models struggle with token-level classification under noise
  - English gap 2× other languages: Check POS distribution of injected noise
  - Hindi F1 <50% on WikiANN: Likely underrepresentation in pretraining (mT5: 1.21% of training data)

- First 3 experiments:
  1. **Baseline replication**: Fine-tune mT5-580M and BLOOM-7B on XNLI clean data, evaluate on clean vs. noisy (r=0.2). Expect ~5-6 point gap for mT5, ~5-7 for BLOOM on English.
  2. **Noise ratio sweep**: Test mT5-580M on XNLI with r=[0.1, 0.2, 0.3, 0.4]. Plot gap vs. noise ratio to find degradation curve.
  3. **Noisy training abatement**: Fine-tune BLOOM-7B on NOISY WikiANN training data (per §5.4), evaluate on clean and noisy test sets. Expect gap reduction but clean performance drop.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does scaling model parameters beyond 13 billion yield continued improvements in robustness to real-world noise, or does the performance gap plateau?
- Basis in paper: [explicit] The authors state in the Limitations section that due to computational constraints, they "couldn't explore even larger models," noting that current capabilities extend beyond the 13B parameter size studied.
- Why unresolved: The study only covers models up to 13B (mT5-xxl), while state-of-the-art multilingual models often exceed 70B+ parameters.
- What evidence would resolve it: Evaluating larger open-source models (e.g., Llama-3-70B or higher-parameter mT5 variants) on the WikiTypo benchmark to compare the "clean vs. noisy" performance gap.

### Open Question 2
- Question: Is the high vulnerability of the English language to noise consistent across low-resource languages not included in this study?
- Basis in paper: [explicit] The authors note in the Limitations that while they focused on six languages, "recent multilingual models can handle over 100 languages," implying a need for broader assessment.
- Why unresolved: The study found English to be the least robust, but it is unclear if this is specific to the selected languages or applicable to low-resource languages with less pre-training data.
- What evidence would resolve it: Expanding the WikiTypo corpus to include low-resource languages (e.g., Yoruba, Swahili) and evaluating the performance degradation relative to high-resource languages.

### Open Question 3
- Question: How does varying the intensity of noise (insertion ratio) affect the performance degradation curves of encoder-decoder versus decoder-only architectures?
- Basis in paper: [explicit] The Limitations section notes that the study presented results using a fixed "noise insertion ratio of 0.2" and that "various noise levels could be explored."
- Why unresolved: It is unknown if the observed superior robustness of mT5 models holds steady, improves, or degrades relative to BLOOM/Falcon as the noise level increases significantly.
- What evidence would resolve it: A fine-grained ablation study testing noise ratios from 0.0 to 0.5 across the XNLI and SNIPS tasks for all nine models.

## Limitations
- Limited typological diversity: Only six languages tested, all Indo-European except Turkish and Hindi
- Unclear causal mechanism: Cannot definitively prove pretraining data volume causes robustness versus other architectural factors
- Noise model bias: WikiTypo captures only corrected typos, potentially missing certain error types

## Confidence
- **Architecture Claims**: High confidence - consistent 4-6 percentage point gaps across all tasks
- **Task Sensitivity Claims**: High confidence - signal-to-noise ratio explanation mechanistically sound
- **Language Vulnerability Claims**: Medium confidence - supported by data but potential confounds not fully addressed

## Next Checks
- Conduct controlled ablation study varying only pretraining data volume while holding architecture constant
- Implement POS-aware noise injection to normalize error distribution across languages
- Extend evaluation to truly low-resource languages with non-Latin scripts to test generalizability of findings