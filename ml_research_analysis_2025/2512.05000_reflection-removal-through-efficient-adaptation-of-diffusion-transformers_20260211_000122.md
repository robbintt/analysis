---
ver: rpa2
title: Reflection Removal through Efficient Adaptation of Diffusion Transformers
arxiv_id: '2512.05000'
source_url: https://arxiv.org/abs/2512.05000
tags:
- reflection
- data
- image
- removal
- ssim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WindowSeat, a single-image reflection removal
  method that repurposes a pre-trained diffusion transformer (DiT) using physically
  based rendering (PBR) data and efficient LoRA-based fine-tuning. The approach addresses
  limitations of prior methods that rely on simplified alpha blending or small-scale
  real-world datasets.
---

# Reflection Removal through Efficient Adaptation of Diffusion Transformers

## Quick Facts
- arXiv ID: 2512.05000
- Source URL: https://arxiv.org/abs/2512.05000
- Authors: Daniyar Zakarin; Thiemo Wandel; Anton Obukhov; Dengxin Dai
- Reference count: 40
- Key outcome: Achieves state-of-the-art single-image reflection removal via efficient LoRA-based fine-tuning of diffusion transformers using physically based rendering data

## Executive Summary
This paper introduces WindowSeat, a single-image reflection removal method that repurposes a pre-trained diffusion transformer (DiT) using physically based rendering (PBR) data and efficient LoRA-based fine-tuning. The approach addresses limitations of prior methods that rely on simplified alpha blending or small-scale real-world datasets. Instead, it leverages a scalable PBR pipeline in Blender to synthesize realistic training data with accurate light transport through glass materials, varying parameters like index of refraction, thickness, and roughness. The DiT backbone is fine-tuned in one step via flow matching in latent space, without requiring multi-step sampling or auxiliary modules. The resulting model achieves state-of-the-art performance, with PSNR gains up to 1.56 dB and SSIM improvements to 0.940 on zero-shot benchmarks. Qualitative results demonstrate superior reflection detection and removal, including strong inpainting capabilities inherited from the DiT. The lightweight fine-tuning protocol enables one-day training on a single consumer GPU, offering a practical and scalable solution for reflection removal in computational photography.

## Method Summary
WindowSeat fine-tunes a pre-trained diffusion transformer (DiT) for single-image reflection removal using a novel physically based rendering (PBR) data generation pipeline in Blender. Unlike prior methods that use simplified alpha blending or small real-world datasets, WindowSeat synthesizes training pairs by rendering glass with varying optical parameters (index of refraction 1.25-1.75, roughness 0-0.05, thickness 0-5cm) using the Principled BSDF shader. The DiT is fine-tuned in one step via flow matching in latent space, predicting a velocity vector to transform the reflection-contaminated input directly into the transmission layer. Efficient LoRA adapters (rank 128) are applied to the transformer, with 4-bit quantization for memory efficiency. The training uses a combined PSNR-SSIM loss, and inference is performed with a single forward pass, enabling fast and effective reflection removal without multi-step sampling or auxiliary modules.

## Key Results
- Achieves PSNR gains up to 1.56 dB and SSIM improvements to 0.940 on zero-shot benchmarks
- Outperforms prior methods on synthetic and real-world reflection removal datasets
- Enables one-day training on a single consumer GPU with lightweight LoRA fine-tuning

## Why This Works (Mechanism)
WindowSeat works by leveraging a physically accurate simulation of light transport through glass, which captures complex optical phenomena like refraction, specular highlights, and multiple reflections. This realism, achieved through PBR data synthesis in Blender, allows the fine-tuned DiT to learn nuanced patterns of reflection and transmission that simpler alpha-blended datasets miss. The flow matching approach in latent space enables direct, one-step transformation from reflection-contaminated to transmission images, avoiding the complexity and computational cost of iterative sampling. The use of LoRA adapters ensures efficient adaptation of the pre-trained DiT without modifying its full parameter set, making the method scalable and practical for consumer hardware.

## Foundational Learning
- **Physically Based Rendering (PBR)**: Simulates realistic light transport through glass materials using physically accurate parameters like index of refraction and roughness. Needed for generating training data that captures complex optical phenomena. Quick check: Verify that rendered images show accurate refraction and reflection patterns.
- **Diffusion Transformers (DiT)**: Generative models that denoise images in latent space, trained via diffusion or flow matching. Needed for their strong image generation and editing capabilities. Quick check: Confirm that the DiT backbone can reconstruct high-quality images from noisy latents.
- **Flow Matching**: A training objective where the model predicts a velocity vector to transform a source distribution into a target distribution in one step. Needed for efficient, single-step inference. Quick check: Ensure the velocity prediction produces smooth transitions between reflection and transmission layers.
- **LoRA (Low-Rank Adaptation)**: A parameter-efficient fine-tuning method that injects low-rank matrices into transformer layers. Needed to adapt large pre-trained models without full fine-tuning. Quick check: Validate that LoRA adapters improve performance without overfitting.
- **4-bit Quantization**: Reduces model memory footprint by representing weights with 4 bits instead of 16 or 32. Needed for training on consumer GPUs. Quick check: Confirm that quantization does not degrade model accuracy.
- **Index of Refraction (IoR)**: A material property that determines how much light bends when passing through a medium. Needed to simulate realistic glass behavior. Quick check: Verify that IoR sampling matches the paper's stated range (1.25-1.75).

## Architecture Onboarding
- **Component Map**: Blender PBR pipeline -> DiT backbone (Flux.1 Kontext or Qwen Image-Edit) -> LoRA adapters -> Flow matching loss -> Reflection-free output
- **Critical Path**: PBR data generation -> DiT fine-tuning with LoRA -> Single-step flow matching inference
- **Design Tradeoffs**: Uses PBR over alpha blending for realism, flow matching over iterative sampling for speed, and LoRA over full fine-tuning for efficiency
- **Failure Signatures**: Ghosting if IoR/roughness out of training range, poor performance vs. alpha-blended baselines, OOM if quantization/checkpointing missing
- **First Experiments**: (1) Validate PBR pipeline renders reflection-free GT images with correct geometry; (2) Test LoRA fine-tuning on small subset; (3) Run inference tiling on high-res image

## Open Questions the Paper Calls Out
None

## Limitations
- Model may over-remove secondary reflections when ground truth contains them due to PBR data lacking higher-order reflections
- Performance depends on accurate simulation of glass parameters; mismatches in IoR or roughness ranges can degrade results
- Tiling and blending strategy for high-resolution inference is not fully specified, which may affect seamlessness

## Confidence
- **High**: Performance improvements (PSNR/SSIM gains) and one-day training claim are well-supported by experimental details
- **Medium**: Reproducibility is challenged by missing implementation details in PBR pipeline (Blender geometry, node setup) and LoRA layer targeting
- **Medium**: Conditioning text prompt and embedding method are not specified, essential for training and inference

## Next Checks
1. Verify that the Blender PBR pipeline correctly renders both reflection-contaminated and reflection-free images with matching geometry and accurate optical parameters
2. Confirm the text prompt and embedding are consistent with the published method and properly condition the DiT during training and inference
3. Test the tiling and blending strategy on high-resolution images to ensure seamless results and validate the "linear combination" approach mentioned in the paper