---
ver: rpa2
title: Mechanistic Analysis of Circuit Preservation in Federated Learning
arxiv_id: '2512.23043'
source_url: https://arxiv.org/abs/2512.23043
tags:
- circuit
- client
- circuits
- global
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the mechanistic causes of federated learning\
  \ (FL) failure under non-IID data by analyzing neural circuit preservation during\
  \ federated averaging. The authors introduce sparsity as an interpretability tool\
  \ to isolate functional circuits\u2014minimal sub-networks for specific class predictions\u2014\
  and track their structural changes across clients and aggregation rounds."
---

# Mechanistic Analysis of Circuit Preservation in Federated Learning

## Quick Facts
- arXiv ID: 2512.23043
- Source URL: https://arxiv.org/abs/2512.23043
- Reference count: 12
- Primary result: Federated learning under non-IID data fails due to circuit preservation breakdown during federated averaging

## Executive Summary
This paper investigates the mechanistic causes of federated learning failure under non-IID data by analyzing neural circuit preservation during federated averaging. The authors introduce sparsity as an interpretability tool to isolate functional circuits—minimal sub-networks for specific class predictions—and track their structural changes across clients and aggregation rounds. Using Intersection-over-Union (IoU) to quantify circuit preservation, they show that under IID conditions, FedAvg successfully preserves a single canonical circuit structure across all clients. Under non-IID conditions, clients develop structurally disjoint circuits that suffer from either structural drift or destructive interference during aggregation, leading to functional collapse. An ablation study demonstrates that higher weight sparsity acts as a regularizer, mitigating destructive interference and improving global model stability. The findings reframe FL's statistical weight divergence as a concrete structural failure of circuit preservation, offering a new mechanistic perspective on decentralized learning challenges.

## Method Summary
The authors employ a circuit-based interpretability approach to analyze federated learning dynamics. They train local models on distributed MNIST data with varying degrees of non-IIDness, then use weight sparsity to extract minimal functional circuits for specific class predictions. Circuit preservation is quantified using Intersection-over-Union (IoU) between client-specific and global circuits across training rounds. The methodology combines standard FedAvg with systematic circuit analysis to track structural changes during aggregation. An ablation study varies weight sparsity levels to examine their effect on circuit preservation and model stability under non-IID conditions.

## Key Results
- Under IID conditions, FedAvg preserves a single canonical circuit structure across all clients
- Non-IID conditions cause clients to develop structurally disjoint circuits that interfere during aggregation
- Higher weight sparsity acts as a regularizer, mitigating destructive interference and improving global model stability
- Circuit preservation breakdown provides a mechanistic explanation for FL failure beyond statistical weight divergence

## Why This Works (Mechanism)
The paper's mechanism relies on the principle that neural networks develop specialized sub-networks (circuits) for specific tasks, and these circuits must be preserved during federated averaging. When data is IID, all clients learn the same task distribution, leading to consistent circuit structures that aggregate successfully. When data is non-IID, each client learns different local distributions, creating divergent circuit structures. During aggregation, these structurally different circuits either drift apart (structural drift) or interfere destructively when combined, causing functional collapse. Weight sparsity regularizes this process by limiting circuit complexity, reducing the potential for destructive interference.

## Foundational Learning
- **Federated Averaging (FedAvg)**: The standard FL algorithm where clients train locally and aggregate weights centrally. Needed to establish the baseline federated learning framework.
- **Non-IID Data Distribution**: Data heterogeneity across clients where local datasets have different class distributions. Quick check: Verify class distribution variance across clients exceeds a threshold.
- **Neural Circuit Interpretability**: The concept that neural networks contain specialized sub-networks for specific functions. Quick check: Identify minimal subnetworks responsible for single-class predictions.
- **Intersection-over-Union (IoU)**: A metric for measuring overlap between sets, used here to quantify circuit preservation. Quick check: IoU = |A ∩ B| / |A ∪ B| where A and B are circuit sets.
- **Weight Sparsity**: The fraction of weights set to zero, used as a regularization mechanism. Quick check: Monitor sparsity level during training to ensure it remains within target range.
- **Structural Drift vs Destructive Interference**: Two failure modes in circuit aggregation where either circuits diverge or combine destructively. Quick check: Compare circuit IoU scores across aggregation rounds.

## Architecture Onboarding

**Component Map**: Client Models -> Circuit Extraction -> IoU Analysis -> Aggregation -> Global Model

**Critical Path**: Data Distribution → Local Training → Circuit Extraction → IoU Measurement → Aggregation Decision

**Design Tradeoffs**: Higher sparsity improves circuit preservation but may reduce model capacity; lower sparsity maintains capacity but increases interference risk

**Failure Signatures**: Low circuit IoU scores indicate structural drift; decreasing global accuracy despite local improvement suggests destructive interference

**Three First Experiments**:
1. Compare circuit IoU scores between IID and non-IID conditions to establish baseline preservation differences
2. Vary sparsity levels systematically to identify optimal regularization for circuit preservation
3. Track global model accuracy alongside circuit IoU to correlate structural preservation with functional performance

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis focuses exclusively on MNIST, limiting generalizability to complex vision tasks or language models
- Sparsity-based circuit extraction assumes linear separability between classes, which may not hold in nuanced classification scenarios
- Only standard FedAvg is examined, without exploring more sophisticated aggregation methods like FedNova or SCAFFOLD
- The relationship between sparsity regularization and circuit preservation requires more extensive ablation studies across different architectures

## Confidence
- **High Confidence**: The observation that IID conditions preserve a single canonical circuit structure is well-supported by empirical evidence and aligns with theoretical expectations of centralized learning
- **Medium Confidence**: The claim that non-IID conditions lead to destructive interference is plausible but may be influenced by the specific MNIST setup and could vary across datasets and architectures
- **Medium Confidence**: The hypothesis that higher weight sparsity acts as a regularizer requires more extensive ablation studies across different sparsity levels and learning rates to establish robustness

## Next Checks
1. Test circuit preservation analysis on CIFAR-10/100 and ImageNet to evaluate generalizability beyond MNIST's simple structure
2. Compare circuit preservation across different aggregation algorithms (FedNova, SCAFFOLD) to determine if structural drift is inherent to FL or specific to FedAvg
3. Perform ablation studies varying both sparsity levels and learning rates systematically to establish the precise relationship between regularization strength and circuit preservation