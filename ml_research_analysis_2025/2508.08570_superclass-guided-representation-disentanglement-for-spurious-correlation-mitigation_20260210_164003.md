---
ver: rpa2
title: Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation
arxiv_id: '2508.08570'
source_url: https://arxiv.org/abs/2508.08570
tags:
- group
- spurious
- features
- super
- superclass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of improving model robustness to
  spurious correlations in machine learning, particularly in scenarios where group
  annotations and spurious feature information are unavailable. The core idea is to
  leverage superclass information inherent in class labels to guide the model in identifying
  and focusing on genuinely relevant features while ignoring spurious ones.
---

# Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation

## Quick Facts
- **arXiv ID:** 2508.08570
- **Source URL:** https://arxiv.org/abs/2508.08570
- **Reference count:** 40
- **Primary result:** SupER achieves superior worst-group accuracy on multiple datasets by using CLIP-guided gradient attention to disentangle superclass-relevant and irrelevant features.

## Executive Summary
This paper tackles spurious correlation mitigation in machine learning without requiring group annotations or spurious feature labels. The core insight is to leverage superclass information inherent in class labels to guide models toward genuinely relevant features. SupER employs a β-VAE architecture combined with gradient-based attention guided by a pre-trained vision-language model (CLIP) to disentangle superclass-relevant and irrelevant features. An L2 regularization term encourages diverse feature usage for prediction. Experiments demonstrate that SupER significantly outperforms baseline methods across various datasets, achieving robust worst-group accuracy without the need for group annotations during training.

## Method Summary
SupER uses a ResNet50-based β-VAE to disentangle superclass-relevant and irrelevant features through external semantic guidance. The latent vector is split into two components: z₁ (superclass-relevant) and z₂ (superclass-irrelevant). Two classifiers predict the label from each component. A pre-trained CLIP model generates attention maps for superclass prompts (e.g., "a bird") and their inverses. The method aligns model gradients with these attention maps through an attribution alignment loss, while an L2 penalty on one classifier promotes diverse feature usage. The approach is trained end-to-end without group annotations or spurious feature labels.

## Key Results
- SupER achieves superior worst-group accuracy across Waterbirds, SpuCo Dogs, MetaShift, and Spawrious datasets
- The method significantly outperforms baseline approaches in mitigating spurious correlations
- Best performance occurs with balanced superclass prompt specificity (neither too general nor too specific)

## Why This Works (Mechanism)

### Mechanism 1: Semantic Disentanglement via External Guidance
- **Claim:** CLIP's understanding of superclass regions can guide separation of core features from spurious background noise
- **Mechanism:** CLIP generates attribution maps using superclass prompts, which guide a β-VAE to separate features into relevant (z₁) and irrelevant (z₂) components through gradient alignment
- **Core assumption:** CLIP possesses robust semantic understanding and the inverse attention map effectively captures spurious features
- **Evidence anchors:** Abstract states method "employs gradient-based attention guided by a pre-trained vision-language model"; Section 3.2 describes using average attribution maps for guidance
- **Break condition:** Fails if CLIP's attention is biased or the inverse map doesn't capture spurious features

### Mechanism 2: Diversity Enforcement via L2 Regularization
- **Claim:** Penalizing sparse feature usage forces aggregation from multiple features, reducing shortcut reliance
- **Mechanism:** L2 penalty on classifier ω₁ encourages uniform usage across z₁ dimensions rather than relying on single shortcut dimensions
- **Core assumption:** Sparse weight utilization correlates with internal spurious correlations
- **Evidence anchors:** Section 3.2 states L2 penalty "promotes a more uniform usage of all superclass-relevant features"
- **Break condition:** Excessive regularization may cause underfitting by dampening genuinely discriminative features

### Mechanism 3: Information Bottleneck via β-VAE
- **Claim:** Higher β values in β-VAE limit latent space capacity, forcing feature factorization for independence
- **Mechanism:** Setting β > 1 penalizes dependencies between latent units, structurally encouraging z₁ and z₂ to capture independent factors
- **Core assumption:** Core and spurious feature factors are statistically independent or can be decomposed as such
- **Evidence anchors:** Section 3.2 describes β-VAE as promoting independence among components
- **Break condition:** Too high β causes reconstruction failure or posterior collapse

## Foundational Learning

- **Concept: Spurious Correlation (Shortcut Learning)**
  - **Why needed here:** The paper addresses models preferring simple, non-causal features (like background) over complex, causal ones when they correlate with labels during training
  - **Quick check question:** On Waterbirds, why does a standard model achieve high average accuracy but fail on "landbirds on water"?

- **Concept: Disentangled Representation Learning**
  - **Why needed here:** The technical contribution separates features; understanding disentanglement as mapping distinct data variation factors to separate latent dimensions
  - **Quick check question:** Why doesn't standard VAE automatically separate background from foreground without constraints like β or guidance?

- **Concept: Gradient-based Attribution (GradCAM)**
  - **Why needed here:** SupER uses gradients as attention signals, aligning student model gradients with teacher (CLIP) attention
  - **Quick check question:** How do class score gradients with respect to feature maps indicate spatial feature importance?

## Architecture Onboarding

- **Component map:** Input image → ResNet50 encoder → Latent z=[z₁;z₂] → Decoder (reconstruction) → Classifiers ω₁(μ₁), ω₂(μ₂) → Prediction
- **Critical path:** 1) Forward pass: Image → Encoder → z₁,z₂; 2) Classification: ω₁(z₁) → prediction; 3) Guidance: Compute gradients of ω₁,ω₂ w.r.t feature maps → Generate attribution maps; 4) Optimization: Align ω₁ attribution with CLIP L₁ᵀ, ω₂ with CLIP L₂ᵀ
- **Design tradeoffs:** β value (higher improves disentanglement but may hurt reconstruction); guidance strength λ₂ (too low ignores CLIP, too high prevents learning); latent dimension size (must balance capacity and compression)
- **Failure signatures:** Mode collapse (ω₁ and ω₂ have identical accuracy/attention); negative transfer (worst-group accuracy drops below ERM); over-regularization (average accuracy drops significantly)
- **First 3 experiments:** 1) Baseline verification: Train vanilla ERM ResNet50 to confirm spurious correlation presence; 2) Hyperparameter sensitivity: Sweep β values (0.1, 1.0, 5.0, 10.0) to find sweet spot; 3) Ablation study: Train without CLIP guidance loss, then without L2 diversity loss

## Open Questions the Paper Calls Out

- **Can SupER handle spurious correlations entirely within superclass semantic space?**
  - The paper notes performance degrades when spurious features originate within superclass itself, requiring integration with other methods like JTT
  - Resolution would require theoretical extension or architectural modification achieving high worst-group accuracy on intra-class spurious benchmarks without sample re-weighting

- **Does gradient-based guidance transfer or amplify social biases in CLIP?**
  - The paper states pre-trained models may encode social/cultural biases that could be transferred, encouraging investigation of solutions
  - Resolution would require evaluation on fairness-specific datasets measuring disparate error rates between SupER and non-vision-language baselines

- **Can framework automatically determine optimal semantic granularity for superclass prompts?**
  - Ablation study shows using generalized prompts causes performance drop due to coarser semantic alignment, yet method relies on manual prompt specification
  - Resolution would require adaptive prompting strategy dynamically selecting or weighting superclass descriptions based on latent feature alignment

## Limitations

- CLIP guidance effectiveness depends critically on CLIP's ability to generate accurate superclass attention maps; biased or domain-inaccurate CLIP breaks the mechanism
- L2 regularization assumes sparsity in classifier weights indicates spurious reliance, which may not hold across all architectures or tasks
- Method may fail when spurious features originate entirely within the superclass semantic space, requiring hybrid approaches

## Confidence

- **High confidence:** β-VAE mechanism for promoting independence between latent factors; overall experimental design with baseline comparisons and worst-group accuracy metrics
- **Medium confidence:** Specific implementation details of gradient-based attribution and precise L2 regularization effects on feature diversity (not fully specified)
- **Low confidence:** Claim that inverse of CLIP attention accurately captures spurious features (approximation without explicit validation)

## Next Checks

1. **CLIP Guidance Ablation:** Train SupER without the L_ATT loss to measure impact of semantic guidance versus β-VAE structure alone
2. **Attention Map Quality:** Generate and visualize CLIP attention maps for superclass prompt on validation set; manually inspect whether they correctly identify superclass and whether inverse map highlights spurious features
3. **KL-Divergence Analysis:** Monitor KL-divergence term during training for different β values; plot trend to confirm higher β leads to greater independence between z₁ and z₂ without posterior collapse