---
ver: rpa2
title: Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph
  Attention for Autism Spectrum Disorder Classification
arxiv_id: '2511.22178'
source_url: https://arxiv.org/abs/2511.22178
tags:
- graph
- autism
- accuracy
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a multi-branch Graph Convolutional Network
  (GCN) architecture that integrates Chebyshev Spectral Graph Convolution and Graph
  Attention Networks (GAT) for Autism Spectrum Disorder (ASD) classification using
  multimodal neuroimaging and phenotypic data from the ABIDE I dataset. The model
  processes functional MRI, structural MRI, and phenotypic features through dedicated
  branches, constructs a site-based population graph, and employs attention-weighted
  node representations to capture complex inter-subject relationships.
---

# Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph Attention for Autism Spectrum Disorder Classification

## Quick Facts
- **arXiv ID:** 2511.22178
- **Source URL:** https://arxiv.org/abs/2511.22178
- **Reference count:** 30
- **Primary result:** 74.82% accuracy, 0.82 AUC on ABIDE I dataset using multimodal GCN with Chebyshev and attention mechanisms

## Executive Summary
This study presents a multi-branch Graph Convolutional Network architecture that integrates Chebyshev Spectral Graph Convolution and Graph Attention Networks for Autism Spectrum Disorder classification. The model processes functional MRI, structural MRI, and phenotypic features through dedicated branches, constructs a site-based population graph, and employs attention-weighted node representations to capture complex inter-subject relationships. Trained on 870 subjects from the ABIDE I dataset, the approach achieves competitive performance compared to state-of-the-art baselines while providing interpretable attention mechanisms for feature importance.

## Method Summary
The proposed model employs a multi-branch GCN architecture that processes multimodal neuroimaging and phenotypic data through separate branches using Chebyshev spectral graph convolution and GAT layers. The architecture constructs a site-based population graph where each node represents an individual subject with 5,206 features. Attention mechanisms are applied to weight node representations based on their importance for ASD classification. The model is trained using stratified five-fold cross-validation and validated against conventional GCNs, autoencoder-based deep neural networks, and multimodal CNNs using the ABIDE I dataset.

## Key Results
- Test accuracy of 74.82% and AUC of 0.82 achieved on ABIDE I dataset
- Outperforms conventional GCNs, autoencoder-based DNNs, and multimodal CNNs
- Ablation studies confirm effectiveness of graph attention and hyperparameter tuning

## Why This Works (Mechanism)
The model captures complex inter-subject relationships by constructing a population graph where nodes represent subjects and edges encode site-based relationships. Chebyshev spectral graph convolution enables localized feature extraction by approximating graph filters in the spectral domain, while GAT layers provide adaptive attention weights that highlight the most relevant features for classification. The multi-branch architecture allows each modality to be processed optimally before integration, preserving modality-specific characteristics while enabling effective fusion.

## Foundational Learning

**Chebyshev Spectral Graph Convolution**
- Why needed: Enables localized feature extraction on non-Euclidean graph structures without expensive spectral decomposition
- Quick check: Verify filter order matches desired locality and spectral range covers relevant graph frequencies

**Graph Attention Networks (GAT)**
- Why needed: Provides adaptive feature weighting that learns which node relationships are most informative for classification
- Quick check: Confirm attention coefficients are sparse and concentrate on meaningful connections

**Multi-modal Feature Fusion**
- Why needed: Combines complementary information from fMRI, sMRI, and phenotypic data for comprehensive representation
- Quick check: Ensure modality-specific branches preserve distinct characteristics before integration

**Population Graph Construction**
- Why needed: Models inter-subject relationships based on shared characteristics like acquisition site
- Quick check: Verify graph connectivity captures meaningful subject similarities

## Architecture Onboarding

**Component Map**
- Input features (5,206 per subject) -> Site-based population graph construction -> Chebyshev GCN branch -> GAT branch -> Feature fusion -> Classification

**Critical Path**
The core classification pipeline flows from multimodal feature extraction through Chebyshev GCN and GAT branches, followed by attention-weighted fusion and final classification layer.

**Design Tradeoffs**
Chebyshev approximation provides computational efficiency over exact spectral methods but may limit filter expressiveness. GAT introduces adaptive weighting but adds computational overhead and potential overfitting on smaller datasets.

**Failure Signatures**
Poor performance may indicate insufficient graph connectivity, suboptimal attention weight distributions, or modality-specific preprocessing issues. Over-smoothing from excessive graph convolution layers can also degrade performance.

**3 First Experiments**
1. Validate individual branch performance on each modality separately
2. Test graph attention ablation to quantify its contribution
3. Perform hyperparameter sensitivity analysis on Chebyshev polynomial order and attention head count

## Open Questions the Paper Calls Out
None

## Limitations
- Moderate accuracy (74.82%) and AUC (0.82) suggest limited clinical applicability
- Reliance on ABIDE I dataset may limit generalizability across different populations
- Absence of cross-dataset validation prevents assessment of model transferability

## Confidence
- Model architecture design: **High**
- Technical implementation: **Medium**
- Performance improvements over baselines: **Medium**
- Clinical relevance: **Low**

## Next Checks
1. External validation on independent ASD datasets (e.g., ABIDE II, NDAR) to assess generalizability across different acquisition sites and protocols.

2. Comparison with recent transformer-based architectures specifically designed for neuroimaging data to establish whether GCN-based approaches remain state-of-the-art.

3. Clinical validation study with radiologists/psychologists to evaluate whether the model's attention-weighted features align with known ASD biomarkers and provide interpretable clinical insights.