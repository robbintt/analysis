---
ver: rpa2
title: 'Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions'
arxiv_id: '2510.22734'
source_url: https://arxiv.org/abs/2510.22734
tags:
- uni00000013
- uni00000010
- uni00000011
- uni00000008
- uni00000025
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of database configuration auto-tuning
  by developing a novel Bayesian optimization framework that relaxes restrictive distributional
  assumptions made by existing methods. The authors propose Centrum, which combines
  stochastic gradient boosting ensembles with locally adaptive conformal prediction
  to provide both point and interval estimates without assuming Gaussianity or stationarity.
---

# Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions

## Quick Facts
- arXiv ID: 2510.22734
- Source URL: https://arxiv.org/abs/2510.22734
- Reference count: 40
- Primary result: Outperforms 21 state-of-the-art methods with 19.2% better tuned performance and 4.2× speedup

## Executive Summary
This paper addresses the problem of database configuration auto-tuning by developing a novel Bayesian optimization framework that relaxes restrictive distributional assumptions made by existing methods. The authors propose Centrum, which combines stochastic gradient boosting ensembles with locally adaptive conformal prediction to provide both point and interval estimates without assuming Gaussianity or stationarity. Extensive experiments on two DBMS systems and three workloads demonstrate that Centrum outperforms 21 state-of-the-art methods, achieving significant improvements in both tuned performance and tuning speed.

## Method Summary
Centrum is a Bayesian optimization framework for database configuration tuning that uses stochastic gradient boosting ensembles (SGBE) as the surrogate model instead of traditional Gaussian processes or random forests. The method employs a two-phase learning procedure: first training a conformalized SGBE using out-of-bag residuals to build empirical uncertainty estimates, then fine-tuning the ensemble weights using the Cross-Entropy Method to optimize for both point accuracy and interval calibration. The approach introduces a generalized log-linear transformation of conformity scores and uses nested out-of-bag estimation to improve interval estimation without distributional assumptions.

## Key Results
- Achieves 19.2% better tuned performance compared to state-of-the-art methods
- Provides 4.2× speedup in tuning efficiency
- Improves point estimate accuracy by 9.5% (SR2 metric)
- Delivers tighter, better-calibrated intervals with 27.6% improvement in NAIS score

## Why This Works (Mechanism)

### Mechanism 1: Stochastic Gradient Boosting Ensembles (SGBE) for Non-Stationary Surfaces
Centrum replaces Gaussian Process or Random Forest surrogates with Stochastic Gradient Boosting Ensembles to improve point-estimate accuracy on heterogeneous, non-stationary DBMS performance surfaces. SGBE leverages boosting to iteratively correct errors of previous trees, handling complex interactions between configuration knobs more effectively than the "smoothness" priors of GPs. The "stochastic" aspect (subsampling) reduces overfitting in small-sample regimes typical of DBMS tuning.

### Mechanism 2: Locally Adaptive Conformal Prediction for Uncertainty
The method applies conformal inference with log-linear transformed scores to produce tighter, better-calibrated confidence intervals than Gaussian assumptions. Instead of assuming a parametric distribution, this mechanism uses empirical quantiles of past residuals. It introduces a "difficulty estimator" to scale interval width locally—narrowing intervals where prediction is easy and widening them where it is hard.

### Mechanism 3: Two-Phase Ensemble Fine-Tuning
A second fine-tuning phase optimizes the weights of base learners to mitigate sub-optimal averaging found in standard Out-of-Bag methods. Standard OOB averages all learners equally, but Centrum uses a second phase (using Cross-Entropy Method) to learn weights that specifically maximize a joint score of point accuracy and interval accuracy. This prunes correlated or under-fitted base learners.

## Foundational Learning

- **Bayesian Optimization (BO):** The fundamental framework for Centrum, involving surrogate modeling, acquisition function optimization, and evaluation. Understanding the loop of *Surrogate Modeling → Acquisition Function → Evaluation* is required to see where SGBE and Conformal Prediction fit in.
- **Conformal Prediction:** The statistical engine for Centrum's "Distribution-Free" interval estimation. You must understand how it uses quantiles of past errors to generate future confidence intervals without assuming a Bell curve.
- **Gradient Boosting Decision Trees (GBDT):** Centrum replaces Random Forests/GPs with SGBE. Understanding how GBDT sequentially fits residuals to minimize loss helps explain why it captures complex knob interactions better than RF.

## Architecture Onboarding

- **Component map:** DBMS Interface → Phase 1 (Conformalized SGBE) → Phase 2 (Ensemble Fine-Tuner) → Acquisition Function → Next Configuration
- **Critical path:** The fine-tuning phase (Phase 2) is the new critical path. If the optimization for weights w fails or is too slow, the benefits over vanilla SGBE are lost.
- **Design tradeoffs:** Accuracy vs. Compute (Centrum requires training an ensemble and then optimizing it, which is computationally heavier than a single GP or RF update); Robustness vs. Smoothness (loses smooth derivatives of GPs but gains robustness to discrete knobs and non-stationarity).
- **Failure signatures:** "Blind Exploration" (if intervals are too wide, causing random exploration); "Premature Convergence" (if intervals are too thin, causing early exploitation of local optima); Diagnosis: monitor the "Coverage" metric.
- **First 3 experiments:** 1) Sanity Check on synthetic non-stationary function to verify conformal interval coverage; 2) Ablation study disabling Phase 2 to quantify weighted ensemble gains; 3) Workload stress test on high-dimensional workload comparing "Time to 99% Optimal" against SMAC.

## Open Questions the Paper Calls Out
The paper explicitly states that "Other components such as knob selection... are important but out of the scope" of this study, suggesting that integrating Centrum with automated knob selection algorithms for larger parameter spaces remains an open research direction.

## Limitations
- Performance gains rely on the assumption that DBMS performance surfaces are non-stationary and non-smooth; if real-world configurations exhibit more smoothness, simpler GP-based methods might achieve comparable results with fewer samples
- Computational overhead of the two-phase ensemble fine-tuning is not fully characterized; the Cross-Entropy Method optimization could become prohibitive in higher-dimensional spaces
- Calibration of conformal intervals depends critically on the quality of the nested out-of-bag estimator, which may degrade when the initial ensemble is already highly accurate

## Confidence

- **High confidence:** The mechanism of using conformal prediction for distribution-free uncertainty estimation is well-established and the empirical results showing improved interval calibration (27.6% NAIS improvement) are convincing
- **Medium confidence:** The claim that SGBE handles non-stationary surfaces better than GPs is supported by experimental comparison but relies on specific hyperparameters and may not generalize across all DBMS workloads
- **Medium confidence:** The contribution of the two-phase fine-tuning is demonstrated through ablation but computational trade-offs are not fully quantified

## Next Checks

1. **Ablation Study Extension:** Disable Phase 2 (set all weights w=1) and compare both performance gains and computational overhead against the full Centrum system to quantify the specific cost-benefit ratio of the weighted ensemble approach

2. **Smoothness Sensitivity Test:** Apply Centrum to synthetic DBMS-like functions with varying degrees of smoothness (from highly non-stationary to nearly smooth) to identify the threshold where simpler GP-based methods become competitive

3. **Calibration Robustness Test:** Vary the number of base learners (B) and nested bag samples in the conformal prediction to determine how sensitive the interval coverage guarantees are to ensemble size and available calibration data