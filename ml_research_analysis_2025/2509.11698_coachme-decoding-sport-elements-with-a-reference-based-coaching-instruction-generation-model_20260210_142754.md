---
ver: rpa2
title: 'CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction
  Generation Model'
arxiv_id: '2509.11698'
source_url: https://arxiv.org/abs/2509.11698
tags:
- coachme
- instruction
- motion
- instructions
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoachMe is a reference-based model that generates sport-specific
  motion instructions by comparing a learner's movement to a reference video. It integrates
  temporal and physical analysis through a Concept Difference module and a Human Pose
  Perception module to identify errors and provide corrective feedback.
---

# CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model

## Quick Facts
- arXiv ID: 2509.11698
- Source URL: https://arxiv.org/abs/2509.11698
- Authors: Wei-Hsin Yeh; Yu-An Su; Chih-Ning Chen; Yi-Hsueh Lin; Calvin Ku; Wen-Hsin Chiu; Min-Chun Hu; Lun-Wei Ku
- Reference count: 40
- Primary result: CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and 58.3% on boxing

## Executive Summary
CoachMe is a reference-based model that generates sport-specific motion instructions by comparing a learner's movement to a reference video. It integrates temporal and physical analysis through a Concept Difference module and a Human Pose Perception module to identify errors and provide corrective feedback. Experiments show CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and 58.3% on boxing, offering more precise, actionable, and sport-specific guidance. Human evaluation by professional coaches confirms its superiority in detecting errors, identifying timing and body parts, explaining causation, suggesting improvement methods, and describing coordination.

## Method Summary
CoachMe uses a reference-based approach to generate coaching instructions by analyzing differences between learner and reference videos. The system employs a Concept Difference module that uses a pretrained encoder to compute frame-wise differences between videos, aligns sequences via Dynamic Time Warping, and identifies error segments. A Human Pose Perception module extracts skeleton representations and learns attention graphs to highlight key joint relationships. The system is pretrained on general motion-text data (HumanML3D) and fine-tuned on sport-specific datasets using LoRA adapters for efficient adaptation.

## Key Results
- CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and 58.3% on boxing
- Achieves 76.14% accuracy in Error Segment Identification on figure skating dataset
- Human evaluation by professional coaches shows CoachMe's superiority in error detection, timing, body part identification, causation explanation, improvement suggestions, and coordination description

## Why This Works (Mechanism)

### Mechanism 1: Reference-Based Motion Comparison via Concept Difference
- **Claim:** Comparing learner motion to a reference video enables domain-specific error detection without large sport-specific training data.
- **Mechanism:** The Concept Difference module encodes both learner and reference videos using a pretrained encoder (CARL), computes frame-wise differences, aligns sequences via Dynamic Time Warping (DTW), and identifies error segments where concept differences are highest. A transformer encoder predicts error intervals from these embeddings.
- **Core assumption:** The reference video represents correct form; visual embeddings capture biomechanically meaningful differences.
- **Evidence anchors:**
  - [abstract] "CoachMe is a reference-based model that analyzes the differences between a learner's motion and a reference under temporal and physical aspects"
  - [Section 3.1] Formula: `c = F(x_r) - F(x_l)` where F is the Concept Encoder; Error Segment Identification outputs intervals via transformer
  - [corpus] Related work (SportsGPT, arXiv:2512.14121) addresses motion assessment but does not employ reference-based comparison for instruction generation
- **Break condition:** If reference videos contain poor form, or learner movements are structurally incompatible (e.g., different action types), alignment fails and instructions degrade.

### Mechanism 2: Skeleton-Based Pose Perception with Attention Graphs
- **Claim:** Skeleton representations avoid background noise and enable precise joint-level coaching feedback.
- **Mechanism:** HybrIK extracts 22 joint coordinates; Pose Understanding (PU) encodes coordinates and orientations on a skeleton graph via GCNs; Pose Extraction (PE) and Pose Attention (PA) learn local body-part patterns and global coordination, producing attention graphs that highlight key joint relationships.
- **Core assumption:** Skeletal pose captures the essential biomechanics; attention graphs correctly identify informative joint relations.
- **Evidence anchors:**
  - [Section 5.2] "skeleton representations focus solely on motion, leading to more precise instructions... RGB videos often contain irrelevant elements, such as background distractions"
  - [Section 3.2] Equations 4-7 describe the pipeline from PU to PE to PA; attention graphs visualized in Figure 1 correlate with generated instructions
  - [corpus] DeepSport (arXiv:2511.12908) uses MLLMs for sports video reasoning but does not isolate skeletal representations for coaching
- **Break condition:** Fast motions cause joint misalignment; fine rotations (e.g., palm orientation) are difficult to capture from skeleton alone.

### Mechanism 3: Two-Stage Transfer via LoRA Adaptation
- **Claim:** Pretraining on general motion-text data enables effective sport-specific instruction generation with limited labeled data.
- **Mechanism:** Basic CoachMe is pretrained on HumanML3D to generate motion descriptions. LoRA adapters are applied to Human Pose Perception and Projection layers during fine-tuning on sport-specific datasets (FS, BX), enabling lightweight adaptation (~5.64M trainable parameters per sport).
- **Core assumption:** General motion understanding transfers to sport coaching; LoRA captures sport-specific patterns without catastrophic forgetting.
- **Evidence anchors:**
  - [abstract] "illustrates how CoachMe adapts well to specific sports such as skating and boxing by learning from general movements and then leveraging limited data"
  - [Section 3.3] "apply low-rank adaptation (LoRA) to Human Pose Perception and Projection"; Table 13 shows LoRA adds only 5.64M parameters per sport
  - [corpus] No direct corpus comparison for this specific transfer strategy
- **Break condition:** If target sport movements are absent from pretraining data (e.g., figure skating jumps not in HumanML3D), the model may misclassify actions or generate generic instructions.

## Foundational Learning

- **Graph Convolutional Networks (GCNs) for Skeleton Data**
  - Why needed here: Human Pose Perception uses GCNs to process skeleton graphs (joint nodes, edge connections) and capture spatial-temporal dynamics.
  - Quick check question: Given a skeleton sequence, can you sketch how a GCN layer propagates information across joints and time?

- **Dynamic Time Warping (DTW)**
  - Why needed here: Motion Alignment uses DTW to find the optimal correspondence between learner and reference sequences of different lengths.
  - Quick check question: If learner video is 50 frames and reference is 80 frames, how does DTW compute a cost matrix to find the best matching segment?

- **Low-Rank Adaptation (LoRA)**
  - Why needed here: Enables efficient fine-tuning on small sport datasets without modifying the full pretrained model.
  - Quick check question: If a base model has 305M parameters, how does LoRA reduce trainable parameters to ~5M while preserving performance?

## Architecture Onboarding

- **Component map:**
  - Concept Difference: ResNet-50 (finetuned) → MLP (2048→256) → 3-layer Transformer Encoder → Projection (128-dim) → Motion Alignment (DTW) → Error Segment Identification (transformer classifier)
  - Human Pose Perception: HybrIK (pose estimator) → Pose Understanding (5 GCN blocks) → Pose Extraction (5 GCN blocks) → Pose Attention (5 GCN blocks on attention graph) → Token fusion
  - Instruct Motion: Max pooling → Projection (3 linear+BN+ReLU blocks, 512→768) → T5-base (223M) → Beam search decoding (beam=3)

- **Critical path:**
  1. HybrIK pose extraction (~21-35 sec, ~90% of inference time)
  2. Motion Alignment (~0.3 sec)
  3. Human Pose Perception + Instruct Motion (~2 sec)

- **Design tradeoffs:**
  - HybrIK vs VIBE: HybrIK more accurate (lower MPJPE) but ~2x slower; VIBE for fast feedback mode
  - Skeleton vs RGB for Token_diff: Skeleton avoids background noise; RGB may capture context but introduces distraction
  - Beam search vs greedy: Beam size=3 improves output quality at cost of latency

- **Failure signatures:**
  - Misidentification of jump types (30.4% of bad ratings): Caused by HumanML3D lacking sport-specific jumps
  - Correct but generic instruction (21.7%): Model fails to prioritize the most critical error
  - False positive instructions: Dataset bias assumes all inputs need correction

- **First 3 experiments:**
  1. Reproduce Basic CoachMe pretraining on HumanML3D (motion description task); validate with BLEU/ROUGE against Table 2 baselines
  2. Evaluate Error Segment Identification accuracy on FS dataset (reported 76.14%); analyze failure cases on fast movements
  3. Ablate Token_diff modality: compare skeleton-based CoachMe vs CoachMe (RGB) on a held-out FS/BX subset; measure G-Eval drop

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can CoachMe be effectively adapted to provide technical guidance for advanced or professional-level athletes?
- Basis in paper: [explicit] The "Limitations" section states that the model is currently designed for beginner- and intermediate-level practitioners. The authors explicitly propose that "Future work could explore adapting the model to higher-level athletes by incorporating expert demonstrations and more complex movement evaluation."
- Why unresolved: The current datasets (FS and BX) consist of novice athletes performing fundamental movements, which restricts the model's ability to recognize or critique the subtle nuances required for professional-level performance.
- What evidence would resolve it: Experiments evaluating a modified CoachMe model on a dataset of professional athletes, demonstrating high alignment (G-Eval and human evaluation) with expert coach feedback on complex techniques.

### Open Question 2
- Question: Can the model be trained to generalize across diverse coaching styles while maintaining the consistency users prefer?
- Basis in paper: [explicit] The "Limitations" section notes that "CoachMe currently learns only a specific teaching style... which limits its ability to represent the diverse speaking styles and instructional approaches of coaches." The authors suggest future work should focus on "incorporating a broader range of coaching styles."
- Why unresolved: The current implementation prioritizes a single, consistent style to replicate a "real coach," but real-world demand exists for personalized styles which the current architecture cannot support.
- What evidence would resolve it: A user study measuring satisfaction and perceived helpfulness when the model is fine-tuned on a multi-style dataset, verifying it can adapt its tone without losing technical accuracy.

### Open Question 3
- Question: Would introducing a scoring mechanism or positive reinforcement examples mitigate the model's bias towards generating "false positive" corrections?
- Basis in paper: [explicit] In the "Analysis of Human Evaluation" (Sec E.6), the authors identify "False positive instructions" (correcting sound movements) as a key failure mode. They attribute this to a dataset bias where all labels suggest improvements and propose "introducing a scoring mechanism and integrating examples of high-quality movements."
- Why unresolved: The model currently assumes "every input requires correction" due to the nature of the training data, leading to hallucinated errors in well-executed motions.
- What evidence would resolve it: A comparative study showing a reduction in "Incorrect/False Positive" ratings in human evaluations when the model is trained on a balanced dataset including "no correction needed" labels.

## Limitations
- Dataset bias and domain specificity: CoachMe assumes all input videos contain errors needing correction, which may not hold for high-performing learners and could lead to false positive instructions.
- Temporal resolution limitations: The system operates at frame-level granularity, which may miss or mischaracterize rapid movements occurring within a single frame (e.g., hand rotations, fine body adjustments).
- Reliance on reference quality: The Concept Difference mechanism assumes reference videos represent perfect form with no mechanism to validate reference quality or handle structurally incompatible learner movements.

## Confidence
- **High confidence**: Basic motion description generation (BLEU, ROUGE scores on HumanML3D), Human Pose Perception module architecture (GCN-based), LoRA parameter count and adaptation approach.
- **Medium confidence**: Error Segment Identification accuracy (76.14% reported), overall G-Eval improvements over GPT-4o (31.6% on FS, 58.3% on BX), human evaluation superiority claims (based on 180 ratings from 5 coaches).
- **Low confidence**: Generalization to sports outside FS and BX, performance with high-quality learner movements, handling of fast motions requiring sub-frame resolution.

## Next Checks
1. **Dataset bias validation**: Test CoachMe on a subset of high-quality learner movements (known to match reference form) to quantify false positive instruction rate and assess whether the "all inputs need correction" assumption holds.
2. **Temporal resolution stress test**: Create controlled test videos with rapid movements (hand rotations, quick adjustments) occurring within single frames, comparing CoachMe's error detection against expert annotations to measure missed or mischaracterized movements.
3. **Cross-sport generalization**: Evaluate CoachMe on a third sport dataset (e.g., tennis serve, gymnastics routine) using the same pretrained weights and LoRA adaptation process to test whether general motion understanding truly transfers across diverse movement patterns.