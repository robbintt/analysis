---
ver: rpa2
title: Satisfiability Modulo Theory Meets Inductive Logic Programming
arxiv_id: '2512.12918'
source_url: https://arxiv.org/abs/2512.12918
tags:
- numerical
- constraints
- learning
- relational
- pygol
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a modular framework coupling PyGol with Z3
  for learning hybrid symbolic-numerical rules. PyGol generates relational clause
  structures while Z3 instantiates and verifies numerical parameters, enabling learning
  of rules combining symbolic predicates with linear, nonlinear, and relational constraints.
---

# Satisfiability Modulo Theory Meets Inductive Logic Programming

## Quick Facts
- arXiv ID: 2512.12918
- Source URL: https://arxiv.org/abs/2512.12918
- Reference count: 40
- Primary result: Modular PyGol-Z3 framework couples ILP structure search with SMT parameter instantiation, achieving 76-100% accuracy on hybrid symbolic-numerical reasoning tasks inaccessible to existing systems.

## Executive Summary
This paper introduces a modular framework coupling PyGol with Z3 for learning hybrid symbolic-numerical rules. PyGol generates relational clause structures while Z3 instantiates and verifies numerical parameters, enabling learning of rules combining symbolic predicates with linear, nonlinear, and relational constraints. Experiments across five benchmark families show PyGol-Z3 solves tasks requiring variable-variable comparisons, nonlinear arithmetic, and predicate invention—domains inaccessible to existing ILP systems like NUMSYNTH. The modular design enables flexible integration of ILP and SMT reasoning while preserving interpretability.

## Method Summary
The PyGol-Z3 framework decouples relational structure search from numerical parameter instantiation. PyGol performs Meta-Interpretive refinement to generate candidate clause schemas with uninstantiated numerical parameters. These schemas are converted to MaxSMT instances where parameters become free variables, positive examples form hard coverage constraints, and negative examples form soft exclusion constraints. Z3 solves these instances to find parameter values maximizing coverage while respecting background theories. The system iterates with high-precision rules updating background knowledge. The modular design preserves ILP's declarative relational bias while leveraging SMT's theory-specific reasoning capabilities.

## Key Results
- PyGol-Z3 achieves 76-100% accuracy across relational and nonlinear tasks
- Successfully learns variable-variable comparisons (e.g., X1 < X2) inaccessible to constant-based ILP
- Predicate invention critical for multi-hop relational reasoning with 35 percentage point improvements
- Solves nonlinear geometric tasks requiring collinearity and product constraints

## Why This Works (Mechanism)

### Mechanism 1: Structure–Parameter Decoupling
- Claim: Separating relational structure search from numerical parameter instantiation enables learning hybrid rules that neither component could produce alone.
- Mechanism: PyGol proposes clause structures treating numerical values as symbolic parameters. Z3 formulates MaxSMT problems where these parameters become free variables constrained by positive examples (hard) and negative examples (soft).
- Core assumption: Target concepts decompose into discrete relational skeletons plus continuous numerical constraints expressible in supported theories.
- Evidence anchors: Abstract confirms coupling allows numerical parameters to be instantiated while preserving ILP's declarative relational bias. Section 3.2 details MaxSMT formulation with free variables representing numerical parameters.

### Mechanism 2: Variable–Variable Relational Constraints via Theory Reasoning
- Claim: SMT integration enables learning rules involving direct comparisons between variables, which constant-based numerical ILP cannot express.
- Mechanism: Classical ILP restricts numerical literals to values present in individual examples. By encoding candidate clauses as SMT formulas, Z3 can verify and instantiate constraints like x(P) < x(Q) without requiring ground constants.
- Core assumption: Background theory sufficiently captures numerical relationships defining the concept.
- Evidence anchors: Abstract states PyGol-Z3 solves tasks requiring variable-variable comparisons. Geometry2 experiments demonstrate NUMSYNTH's failure on X1 < X2 relations.

### Mechanism 3: Predicate Invention with SMT Threshold Calibration
- Claim: Multi-hop relational patterns become learnable only when predicate invention combines with SMT-based numerical threshold optimization.
- Mechanism: PyGol invents auxiliary predicates capturing intermediate relational structure. Z3 optimizes numerical thresholds against labeled examples. Neither mechanism alone suffices for complex concepts.
- Core assumption: Invented predicates capture meaningful relational abstractions, and sufficient examples exist to constrain threshold learning.
- Evidence anchors: Section 5.4 shows predicate invention alone yields 48-78% accuracy while full PyGol-Z3 achieves 76-100%, with 35 percentage point improvements.

## Foundational Learning

- Concept: Inverse Entailment and Bottom Clauses
  - Why needed here: PyGol builds on Meta Inverse Entailment, extending Progol's bottom-clause construction. Understanding this clarifies why classical ILP cannot synthesize new numerical thresholds.
  - Quick check question: Given one positive example with coordinate x=5, can inverse entailment produce a rule x < 7? Why or why not?

- Concept: Satisfiability Modulo Theories (SMT)
  - Why needed here: Z3 provides theory-specific reasoning (linear arithmetic, nonlinear arithmetic) allowing joint constraint solving over continuous domains. The paper frames ILP hypothesis acceptance as satisfiability conditions under background theories.
  - Quick check question: How does SMT differ from SAT? What background theories does Z3 support for numerical reasoning?

- Concept: MaxSMT and Soft Constraints
  - Why needed here: The framework uses MaxSMT to balance coverage (hard constraints from positive examples) against exclusion (soft constraints from negative examples), enabling optimization when perfect separation is impossible.
  - Quick check question: In MaxSMT, what happens when hard and soft constraints conflict? How does this differ from pure SAT?

## Architecture Onboarding

- Component map: PyGol (ILP structure search) -> Z3 (SMT parameter instantiation) -> MaxSMT formulation -> theory satisfiability verification -> coverage-based scoring
- Critical path: 1) PyGol generates candidate clauses from background knowledge and examples. 2) Each clause schema converts to MaxSMT instance with parameters as free variables. 3) Z3 solves MaxSMT, returns instantiated parameters for theory-satisfiable clauses. 4) High-scoring rules accumulate; high-precision rules update background knowledge. 5) Convergence determined by quality improvement threshold.
- Design tradeoffs: Modularity enables independent inspection/replacement but incurs overhead from repeated MaxSMT calls vs. NUMSYNTH's tighter integration. Expressivity vs. tractability: Nonlinear theories increase power but raise runtime substantially.
- Failure signatures: Timeouts on conjunctive/mixed constraints indicate clause enumeration bottleneck. Low accuracy without SMT confirms threshold calibration dependency. NUMSYNTH's inability to express X1 < X2 relations shows architecture mismatch.
- First 3 experiments: 1) Reproduce Geometry0 (Halfplane): Verify modular pipeline on linear task. Target: ~94% accuracy, ~4s runtime. 2) Ablate SMT on IP task: Run PyGol without Z3 threshold optimization. Confirm accuracy drop from ~79% to ~56%. 3) Stress-test nonlinear (Geometry3: crescent): Profile Z3 time vs. PyGol structure search time.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can solver feedback mechanisms (unsatisfiable cores, theory lemmas, recurring arithmetic substructures) be systematically used to guide hypothesis pruning and bias refinement?
- Basis in paper: Authors state: "How should solver feedback (e.g. satisfiable models, unsatisfiable cores) inform pruning and bias selection?" and propose constraining invention using solver-derived signals.
- Why unresolved: Current implementation uses basic MaxSMT optimization without exploiting solver diagnostics for structural refinement or search guidance.
- What evidence would resolve it: Experiments showing improved convergence or accuracy when unsatisfiable cores are used to prune candidate clause structures compared to baseline PyGol-Z3.

### Open Question 2
- Question: Can constraining predicate invention with solver-derived constraints prevent overfitting while preserving interpretability in numerical domains?
- Basis in paper: "Predicate invention is powerful for relational abstraction, but our results suggest that unconstrained invention risks overfitting or producing uninterpretable constructs when numerical parameters are involved."
- Why unresolved: IP experiments show predicate invention is necessary for multi-hop reasoning, but the paper does not investigate mechanisms to constrain invention based on numerical solver feedback.
- What evidence would resolve it: Comparative experiments on IP benchmarks showing solver-constrained predicate invention maintains or improves accuracy while reducing invented predicate count and improving human interpretability scores.

### Open Question 3
- Question: How can the granularity mismatch between ILP's structural hypothesis space and SMT's fully instantiated arithmetic constraints be efficiently bridged?
- Basis in paper: "A central challenge revealed by our experiments is the granularity mismatch between symbolic ILP and SMT solvers. ILP explores structural hypotheses over first-order predicates, whereas SMT solvers operate over fully instantiated arithmetic constraints."
- Why unresolved: Current modular approach requires careful manual design of bias languages and hypothesis templates.
- What evidence would resolve it: Development of automated methods for mapping first-order clause structures to theory-level constraints that reduce manual specification, validated on complex multi-predicate benchmarks.

### Open Question 4
- Question: Can probabilistic or approximate reasoning be integrated into SMT-ILP to handle noisy numerical observations robustly?
- Basis in paper: "Integrating such probabilistic semantics into an ILP–SMT workflow could enable hypothesis scoring under uncertainty and principled treatment of noisy geometric observations."
- Why unresolved: Current framework uses deterministic satisfiability checks with no mechanism for soft constraint handling or uncertainty quantification over numerical parameters.
- What evidence would resolve it: Experiments on corrupted or noisy versions of Geometry benchmarks showing a probabilistic SMT-ILP variant maintains higher accuracy than the deterministic baseline.

## Limitations
- The coupling between PyGol's structure search and Z3's parameter instantiation remains heuristic with no guarantee of generalization beyond specific examples
- Efficiency degrades substantially with increasing clause complexity and nonlinear theory usage, with challenging tasks requiring over 20 minutes
- Predicate invention may generate spurious predicates that overfit specific example distributions without additional regularization

## Confidence
**High Confidence**: The core mechanism of decoupling relational structure search from numerical parameter instantiation is well-supported by both theoretical reasoning and experimental evidence. The claim that PyGol-Z3 solves tasks requiring variable-variable comparisons is strongly validated by the Geometry2 results showing NUMSYNTH's failure on these exact problems.

**Medium Confidence**: The assertion that predicate invention combined with SMT optimization is necessary for multi-hop relational reasoning (IP tasks) is supported by the 35 percentage point accuracy improvements, but this conclusion rests on a limited set of six benchmark tasks. The break conditions identified are reasonable hypotheses but not empirically validated.

**Low Confidence**: The scalability claims for larger, real-world datasets remain untested. While the framework succeeds on five benchmark families, these are relatively small-scale problems. The paper does not address how the approach would perform on datasets with hundreds of relations, thousands of examples, or more complex numerical theories.

## Next Checks
1. **Cross-validation robustness**: Implement k-fold cross-validation on existing benchmark families to assess whether Z3's parameter instantiation generalizes beyond the specific training examples used during learning, measuring overfitting tendencies.

2. **Runtime scaling experiment**: Systematically increase clause depth, literal count, and nonlinear constraint complexity while measuring PyGol-Z3 runtime versus NUMSYNTH, establishing precise scalability boundaries and identifying when timeouts become prohibitive.

3. **Noise sensitivity analysis**: Introduce varying levels of label noise into positive and negative examples to evaluate how MaxSMT optimization handles contradictory or ambiguous constraints, and whether precision thresholds for background updates remain appropriate under noisy conditions.