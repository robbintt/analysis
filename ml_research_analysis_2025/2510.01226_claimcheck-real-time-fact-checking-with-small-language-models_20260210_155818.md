---
ver: rpa2
title: 'ClaimCheck: Real-Time Fact-Checking with Small Language Models'
arxiv_id: '2510.01226'
source_url: https://arxiv.org/abs/2510.01226
tags:
- evidence
- claim
- search
- claimcheck
- fact-checking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'ClaimCheck introduces a modular fact-checking system using small
  language models to verify real-world claims through live Web evidence retrieval.
  The system decomposes verification into distinct stages: query planning, evidence
  retrieval and summarization, synthesis with optional re-retrieval, and final verdict
  evaluation.'
---

# ClaimCheck: Real-Time Fact-Checking with Small Language Models

## Quick Facts
- arXiv ID: 2510.01226
- Source URL: https://arxiv.org/abs/2510.01226
- Authors: Akshith Reddy Putta; Jacob Devasier; Chengkai Li
- Reference count: 8
- Key result: 76.4% accuracy on AVeriTeC with 4B model, outperforming 70B+ models

## Executive Summary
ClaimCheck is a modular fact-checking system that uses small language models (specifically Qwen3-4B) to verify real-world claims through live Web evidence retrieval. The system achieves 76.4% accuracy on the AVeriTeC benchmark by decomposing verification into five discrete stages: query planning, evidence retrieval, summarization, synthesis with optional re-retrieval, and final verdict evaluation. By leveraging Qwen3's thinking capabilities and careful module design, ClaimCheck demonstrates that smaller models can match or exceed larger models' performance when tasks are properly decomposed and optimized.

## Method Summary
ClaimCheck implements a 5-stage pipeline where each module is optimized for small LLMs. The system uses Qwen3-4B with thinking enabled, communicating through a centralized fact-checking report that records intermediate outputs. Web search is performed via Serper API with top-3 results per query for speed. No model fine-tuning is performed—all improvements come from prompt engineering and modular decomposition. Temporal filtering ensures retrieved evidence predates claim publication. The modular design enables interpretable outputs and computational efficiency while maintaining high accuracy.

## Key Results
- Achieves 76.4% accuracy on AVeriTeC development set using Qwen3-4B
- Outperforms prior SOTA (75.2% with LLaMA3.1-70B) while using a 4B parameter model
- Thinking capability provides 21 percentage point accuracy gain (75.0% vs 54.0% without thinking)
- Qwen3-4B and Qwen3-32B achieve similar accuracy (76.4% vs 76.0%), suggesting architecture matters more than scale

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular pipeline decomposition enables smaller LLMs (4B parameters) to match or exceed larger models (70B+) on fact-checking tasks.
- Mechanism: The system partitions fact-checking into five discrete stages—query planning, evidence retrieval, summarization, synthesis with optional re-retrieval, and evaluation—each with narrow, well-defined inputs/outputs. This reduces per-module reasoning complexity and allows prompt optimization per stage.
- Core assumption: Smaller models fail at end-to-end fact-checking primarily due to cognitive load and context management, not fundamental reasoning incapacity.
- Evidence anchors:
  - [abstract] "Each module is optimized for small LLMs, allowing the system to deliver accurate and interpretable fact-checking with significantly lower computational requirements."
  - [section 2.2] "ClaimCheck generates a comprehensive fact-checking report... This report serves as a central artifact that facilitates communication between modules by recording their intermediate outputs in a structured format."
  - [corpus] Related work (RAMA, arXiv:2507.09174) similarly uses multi-agent decomposition for complex verification tasks, suggesting broader validity of modular approaches.

### Mechanism 2
- Claim: Hybrid "thinking" capabilities in Qwen3 provide a 21 percentage point accuracy gain by enabling explicit stepwise reasoning.
- Mechanism: Qwen3's thinking mode generates internal reasoning chains before producing outputs. The ablation shows evidence summarization and evaluation modules are most reasoning-dependent (-9 to -10 points when disabled).
- Core assumption: The thinking mechanism produces genuinely useful intermediate reasoning, not just longer outputs.
- Evidence anchors:
  - [section 3.4] "The fully thinking configuration achieves 75.0% accuracy, substantially outperforming the all no-think baseline (54% accuracy)."
  - [section 3.4] "The evidence summarization and evaluation modules show the largest degradation (9–10 percentage points), indicating these components are most critical for effective reasoning."
  - [corpus] Corpus evidence on reasoning-augmented fact-checking is limited; no direct replications of this specific thinking mechanism found.

### Mechanism 3
- Claim: Iterative re-retrieval triggered by synthesis-stage gap detection improves evidence sufficiency.
- Mechanism: After initial synthesis, the LLM evaluates whether evidence gaps exist and can generate additional search queries. This loops back through retrieval and summarization.
- Core assumption: The small model can reliably identify when evidence is insufficient without over-retrieving.
- Evidence anchors:
  - [section 2.2] "After the analysis is produced, the LLM will determine whether additional Web search is needed, taking into account any gaps in evidence and previous queries."
  - [section 3.5] No significant accuracy difference between Qwen3-4B and Qwen3-32B (76.4% vs 76.0%), suggesting architecture matters more than scale for evidence integration.
  - [corpus] PASS-FC (arXiv:2504.09866) uses iterative self-reflection with similar logic, achieving 72.0% accuracy.

## Foundational Learning

- Concept: Retrieval-Augmented Generation (RAG) for verification
  - Why needed here: ClaimCheck is fundamentally a RAG system optimized for fact-checking; understanding retrieval-evidence-verdict pipelines is prerequisite.
  - Quick check question: Can you explain why retrieval must be temporally constrained for fair evaluation?

- Concept: Chain-of-Thought / Stepwise Reasoning
  - Why needed here: The hybrid thinking mechanism relies on explicit reasoning traces; understanding CoT helps diagnose when thinking helps vs. adds noise.
  - Quick check question: What types of reasoning tasks benefit most from explicit intermediate steps?

- Concept: AVeriTeC benchmark and verdict taxonomy
  - Why needed here: The four-class verdict scheme (Supported, Refuted, Conflicting Evidence/Cherrypicking, Not Enough Evidence) has nuanced boundaries that affect both training and evaluation.
  - Quick check question: Why might "Conflicting Evidence/Cherrypicking" be harder to predict than binary verdicts?

## Architecture Onboarding

- Component map: Planning -> Execution -> Evidence Summarization -> Evidence Synthesis -> Evaluation
- Critical path:
  1. Claim input → Planning (generates 1-3 queries)
  2. Execution (top-3 results per query for demo speed)
  3. Summarization (filters irrelevant articles, extracts key points)
  4. Synthesis (identifies gaps → may loop to step 2)
  5. Evaluation (assigns verdict with justification)

- Design tradeoffs:
  - Speed vs. thoroughness: Demo limits to 3 results; production could expand
  - Thinking enabled vs. latency: +5 seconds overhead per claim (Table 3)
  - Live web vs. knowledge store: Live retrieval is realistic but noisier; knowledge stores are cleaner but static

- Failure signatures:
  - Prompt overflow in summarization: Qwen3-4B produces overly long summaries when prompts exceed context comfort zone (Appendix B)
  - Temporal leakage: If date filtering fails, verdicts may rely on future information
  - Ambiguous claims: Dataset annotation inconsistencies cap accuracy near 80% (Appendix B)

- First 3 experiments:
  1. Replicate the thinking ablation on a 50-claim subset: Compare all-think vs. all-no-think to validate the 21-point gap.
  2. Test retrieval depth: Vary top-k results (3, 5, 10) and measure accuracy/latency tradeoffs.
  3. Swap base model: Replace Qwen3-4B with another small model (e.g., Phi-4, Gemma 2 9B) using identical prompts to test prompt portability claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can fact-checking performance exceed the ~80% accuracy ceiling implied by AVeriTeC's ambiguous annotations, and would clearer annotation protocols enable better automated systems?
- Basis in paper: [explicit] "Many claims hinge on nuanced or ambiguous interpretations that challenge even human annotators... Such complexities make it difficult for any automated system—even with perfect evidence—to confidently assign the correct verdict. As a result, future benchmarks may need clearer annotation protocols."
- Why unresolved: The paper identifies annotation ambiguity (e.g., similar fracking claims receiving different verdicts) as a fundamental dataset limitation rather than a system limitation.
- What evidence would resolve it: Evaluation on a revised benchmark with stricter annotation guidelines and inter-annotator agreement metrics.

### Open Question 2
- Question: What prompt optimization strategies enable effective cross-model transferability in modular fact-checking pipelines?
- Basis in paper: [explicit] "When using OpenAI's o4-mini as the base LLM, accuracy drops significantly to 67.0%. This degradation likely stems from our prompting strategy being optimized for Qwen3 models, highlighting the importance of model-specific optimization in modular architectures."
- Why unresolved: The paper demonstrates the problem but does not investigate whether universal prompting approaches exist or what makes prompts model-specific.
- What evidence would resolve it: Systematic comparison of prompt performance across multiple model families with controlled prompt variations.

### Open Question 3
- Question: Can context-window management techniques mitigate small LLMs' tendency to summarize entire prompts rather than follow task instructions?
- Basis in paper: [explicit] "When the prompt becomes too long... Qwen3-4B tends to prioritize summarizing the entire prompt over following the specified summarization task. This behavior introduces noise into the downstream synthesis and evaluation stages and occasionally causes prompt overflows."
- Why unresolved: The paper identifies the failure mode but offers no solution beyond noting it as a challenge.
- What evidence would resolve it: Ablation studies testing sliding window approaches, hierarchical summarization, or prompt compression techniques.

## Limitations

- Temporal cutoff enforcement: Exact implementation details for date filtering are not fully specified, creating uncertainty about potential future knowledge leakage
- Generalizability beyond Qwen3: Exceptional performance gains from thinking mode are demonstrated specifically with Qwen3-4B; other models may require prompt re-optimization
- Retrievability bias: AVeriTeC benchmark's reliance on Web-retrievable evidence may advantage live search systems over knowledge-based approaches

## Confidence

- **High confidence**: Modular decomposition approach works as described (76.4% accuracy with 4B model vs 75.2% with 70B model), supported by clear ablation studies
- **Medium confidence**: 21 percentage point thinking advantage is real but may be model-specific; exact gains likely vary across model families
- **Low confidence**: Claims about universal accessibility to both experts and non-experts are not empirically validated beyond the demo interface

## Next Checks

1. Cross-model replication: Replace Qwen3-4B with Phi-4 or Gemma 2 9B using identical prompts and measure accuracy/latency changes to test prompt portability claims
2. Temporal robustness test: Run the pipeline on a subset of claims where you deliberately manipulate the date filtering (allow future evidence, then strictly enforce) to quantify the impact of temporal leakage
3. Re-retrieval cost-benefit analysis: Systematically vary the re-retrieval trigger threshold and measure the accuracy-latency tradeoff curve to identify optimal stopping criteria