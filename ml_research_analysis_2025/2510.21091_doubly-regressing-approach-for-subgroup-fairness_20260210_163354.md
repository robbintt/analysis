---
ver: rpa2
title: Doubly-Regressing Approach for Subgroup Fairness
arxiv_id: '2510.21091'
source_url: https://arxiv.org/abs/2510.21091
tags:
- fairness
- subgroups
- marginal
- subgroup
- draf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes DRAF (Doubly Regressing Adversarial learning
  for Fairness), a novel algorithm for achieving subgroup fairness in machine learning
  models with multiple sensitive attributes. The method addresses two key challenges:
  data sparsity for small subgroups and computational burden when many subgroups exist.'
---

# Doubly-Regressing Approach for Subgroup Fairness

## Quick Facts
- arXiv ID: 2510.21091
- Source URL: https://arxiv.org/abs/2510.21091
- Reference count: 40
- Primary result: DRAF achieves subgroup fairness with computational efficiency independent of subgroup count

## Executive Summary
This paper introduces DRAF (Doubly Regressing Adversarial learning for Fairness), a novel algorithm addressing subgroup fairness in ML models with multiple sensitive attributes. The method tackles two key challenges: data sparsity for small subgroups and computational burden when many subgroups exist. DRAF introduces "subgroup-subset fairness" focusing on larger, active subgroups while maintaining marginal fairness. The algorithm uses a surrogate measure called Doubly Regressing R¬≤ (DR¬≤) which provides an upper bound on the supremum Integral Probability Metric (supIPM) for subgroup fairness, computable efficiently using only a single discriminator regardless of subgroup count.

## Method Summary
DRAF is an adversarial learning algorithm that achieves subgroup fairness through a min-max optimization framework. The method uses DR¬≤ as a surrogate for the supIPM fairness measure, allowing efficient computation with a single discriminator. It introduces the concept of "active subgroups" - those with sufficient sample sizes - and explicitly includes marginal subgroups to prevent fairness gerrymandering. The algorithm iteratively trains a prediction model and discriminator to minimize classification error while enforcing fairness, with theoretical guarantees that DR¬≤ bounds the true supIPM. The approach is validated on four benchmark datasets with varying numbers of sensitive attributes.

## Key Results
- DRAF outperforms baseline methods on benchmark datasets, especially when subgroups are sparse
- The method maintains strong performance on marginal fairness while achieving subgroup fairness
- DR¬≤ can be computed efficiently using only a single discriminator regardless of the number of subgroups
- Theoretical analysis shows DR¬≤ is a valid upper bound of supIPM
- Empirical results demonstrate improved accuracy-fairness tradeoffs compared to existing methods

## Why This Works (Mechanism)

### Mechanism 1: DR¬≤ Surrogate Bounding of supIPM
- Claim: DR¬≤ serves as a computationally tractable upper bound on supIPM, enabling efficient fairness optimization without enumerating all subgroup-subsets
- Mechanism: Reformulates IPM as regression-like quantity by correlating subgroup membership indicators with discriminator outputs, optimizing over continuous weight vector v ‚àà S^M
- Core assumption: Discriminator class G is sufficiently expressive and weight vector v converges near simplex vertices
- Evidence: Theorem 4.1 proves theoretical connection; empirical validation shows positive correlation between DR gap and supIPM

### Mechanism 2: Single Discriminator via Joint Parameterization
- Claim: Single discriminator can measure fairness across all subgroup-subsets by regressing against weighted combination of subgroup membership indicators
- Mechanism: Joint parameterization reduces computational cost from O(|ùí≤|) to O(1) discriminator evaluations
- Core assumption: Joint optimization landscape allows simultaneous improvement without local optima traps
- Evidence: Empirical convergence of v near simplex vertices during training

### Mechanism 3: Subgroup-Subset Selection via Size Threshold
- Claim: Including only "active" subgroups with sample sizes above Œ≥n balances statistical reliability with comprehensive fairness coverage
- Mechanism: Filters to subgroups with sufficient samples based on estimation error scaling O(‚àö(log|ùí≤|/n_W))
- Core assumption: Small subgroups cannot have their fairness reliably estimated from limited data
- Evidence: Theorem 3.1 provides statistical justification; empirical validation shows performance benefits

## Foundational Learning

- **Integral Probability Metrics (IPM)**: Measures distance between probability distributions by finding maximum expectation difference over discriminator class. Why needed: DRAF's theoretical foundation relies on IPM as distributional fairness measure. Quick check: Given two distributions P and Q, explain why IPM with Lipschitz discriminators gives Wasserstein distance.

- **Adversarial Training for Fairness**: Min-max optimization where predictor minimizes classification loss while adversary maximizes fairness violation measure. Why needed: DRAF uses this framework to balance accuracy and fairness. Quick check: In adversarial fairness training, what does it mean when discriminator cannot distinguish predictions across groups?

- **Distributional vs. Prediction-Based Fairness**: DRAF targets distributional fairness (full output distributions match) which is stronger than mean demographic parity. Why needed: Paper argues prediction-based metrics can be satisfied while distributional unfairness remains. Quick check: Why might equal mean predictions across groups still permit harmful discrimination?

## Architecture Onboarding

- **Component map**: 
  - Predictor network f_Œ∏ (MLP with sigmoid) -> Prediction scores
  - Discriminator network g_œÜ (linear + sigmoid) -> Real values
  - Weight vector v (unit vector) -> Selects subgroup-subset to measure
  - Fairness penalty c_DR (z-transformed DR¬≤) -> Fairness violation measure

- **Critical path**:
  1. Forward pass: Compute predictions f_Œ∏(x_i, s_i) for all samples
  2. Compute classification loss L_cls (cross-entropy)
  3. Build membership indicators c_i for all W ‚àà ùí≤
  4. Compute DR¬≤(f, v, g) using current v, g
  5. Apply z-transformation to get c_DR
  6. Update (g, v) via gradient ASCENT on c_DR
  7. Project v onto unit sphere
  8. Update f via gradient DESCENT on L_cls + Œª¬∑c_DR

- **Design tradeoffs**:
  - Œ≥ (size threshold): Lower Œ≥ ‚Üí more subgroups included ‚Üí stricter fairness but potential overfitting
  - Œª (fairness weight): Controls accuracy-fairness tradeoff
  - Discriminator class G: Simple sIPM discriminators vs. complex HIPM

- **Failure signatures**:
  - v does not converge to vertices ‚Üí DR¬≤ bound may be loose
  - Marginal fairness degrades despite subgroup fairness ‚Üí verify marginal subgroups are included
  - Validation fairness diverges from training ‚Üí Œ≥ may be too low

- **First 3 experiments**:
  1. Sanity check on synthetic data: Verify DR¬≤ correlates with ground-truth supIPM and v identifies worst subgroup
  2. Ablation on Œ≥: Sweep Œ≥ on COMMUNITIES vs. ADULT datasets to confirm sparse datasets benefit from moderate Œ≥
  3. Single-attribute baseline comparison: Compare DRAF vs. standard IPM-based fairness methods on dataset with q=1

## Open Questions the Paper Calls Out

- **Open Question 1**: Can subgroup fairness be decomposed into low-order marginal fairness components (analogous to ANOVA decomposition) to improve stability and interpretability? Basis: Authors mention this as possible future work in conclusion. Evidence needed: Theoretical derivation showing subgroup fairness as function of lower-order marginal terms.

- **Open Question 2**: Is there a theoretically optimal criterion for selecting the minimum sample size threshold Œ≥ for active subgroups? Basis: Section 5.1 discusses selecting Œ≥ empirically via Pareto-front analysis without closed-form solution. Evidence needed: Framework or heuristic rule derived from sample complexity bounds specifying optimal Œ≥.

- **Open Question 3**: Can DRAF formulation and theoretical guarantees be extended to continuous sensitive attributes? Basis: Theoretical setup explicitly defines sensitive attributes as binary, leaving continuous case undefined. Evidence needed: Modified algorithm handling continuous s with corresponding extensions of theorems.

## Limitations

- Theoretical foundation relies on empirical convergence of weight vector v near simplex vertices, which is not formally guaranteed
- Method's effectiveness depends critically on choice of Œ≥ and Œª with no principled method for automatic tuning
- Paper focuses on binary classification and may not extend directly to multi-class settings

## Confidence

- **High Confidence**: Theoretical proof that DR¬≤ provides upper bound on supIPM (Theorem 4.1); empirical demonstration that DRAF outperforms baselines
- **Medium Confidence**: Claim that single discriminator can measure all subgroup-subsets simultaneously based on empirical v convergence
- **Medium Confidence**: Subgroup-subset selection strategy using size threshold Œ≥ is statistically sound

## Next Checks

1. **Convergence Robustness**: Test DRAF on datasets where multiple subgroup-subsets have nearly identical fairness violations. Monitor whether v converges to single vertex or oscillates between multiple vertices, and measure resulting gap between DR¬≤ and supIPM.

2. **Cross-Dataset Œ≥ Tuning**: Systematically sweep Œ≥ across datasets with varying subgroup sparsity (from COMMUNITIES to ADULT). Plot accuracy-fairness tradeoffs to identify whether recommended 0.001-0.3 range generalizes or requires dataset-specific calibration.

3. **Marginal Fairness Preservation**: On datasets where marginal fairness is socially critical, verify that DRAF maintains MP(1) parity even when subgroup fairness is achieved. Test edge cases where enforcing subgroup fairness might inadvertently harm marginal groups.