---
ver: rpa2
title: Model Stitching by Functional Latent Alignment
arxiv_id: '2505.20142'
source_url: https://arxiv.org/abs/2505.20142
tags:
- stitching
- functional
- similarity
- fula
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Functional Latent Alignment (FuLA), a new
  method for evaluating functional similarity between neural networks through model
  stitching. Unlike traditional approaches that rely on task-specific losses (TLM)
  or direct feature matching (DM), FuLA aligns intermediate representations while
  avoiding task-level cues that can fabricate similarity.
---

# Model Stitching by Functional Latent Alignment

## Quick Facts
- **arXiv ID:** 2505.20142
- **Source URL:** https://arxiv.org/abs/2505.20142
- **Reference count:** 40
- **Primary result:** FuLA aligns intermediate representations to evaluate functional similarity while avoiding task-level cues that can fabricate similarity.

## Executive Summary
This paper introduces Functional Latent Alignment (FuLA), a new method for evaluating functional similarity between neural networks through model stitching. Unlike traditional approaches that rely on task-specific losses or direct feature matching, FuLA aligns intermediate representations while avoiding task-level cues that can fabricate similarity. Experiments on ResNet architectures show that task-based stitching can produce misleading results by exploiting training shortcuts or adversarial robustness cues, while FuLA provides more reliable functional similarity assessment.

## Method Summary
FuLA is a model stitching method that aligns intermediate representations between a front model and end model using a learnable affine transformation (1×1 convolution). The method minimizes normalized feature distance at both the stitching layer and subsequent layers up to (but excluding) the output layer. This multi-layer alignment approach avoids exploiting task-specific artifacts while maintaining stable performance across distribution shifts, adversarial training, and class subset scenarios. The stitching transformation is initialized via direct matching using the Moore-Penrose pseudoinverse on 100 samples, then trained with Adam for 30 epochs.

## Key Results
- Task-based stitching (SLM/TLM) can produce misleading results by exploiting training shortcuts or adversarial robustness cues, fabricating high functional similarity where none exists.
- FuLA captures non-trivial alignments missed by direct matching methods while maintaining performance stability under distribution shifts and adversarial training.
- Cross-layer stitching experiments confirm that directionality in functional similarity is inherent to model structure, not an artifact of task-based optimization.

## Why This Works (Mechanism)

### Mechanism 1: Multi-Layer Latent Alignment Prevents Fabricated Similarity
- **Claim:** FuLA avoids "hallucinating" functional similarity by aligning representations at multiple depths rather than optimizing solely for task output.
- **Mechanism:** The stitching transformation is trained to minimize normalized feature distance at the stitching layer AND at all subsequent layers up to the output. This forces alignment to propagate functionally through the network rather than finding shortcuts.
- **Core assumption:** If representations are functionally aligned, the end model's intermediate layers should process stitched inputs similarly to their native inputs.
- **Evidence anchors:** Section 3.1 shows task-based stitching displays irregular behavior under adversarial training while FuLA behaves more stably.

### Mechanism 2: Task-Agnostic Objective Reduces Overfitting to Spurious Cues
- **Claim:** Removing output-level supervision during alignment prevents the stitching layer from exploiting dataset artifacts or shortcuts.
- **Mechanism:** FuLA explicitly excludes the output layer from its loss. The alignment transformation cannot access task-specific gradients, so it must find transformations that are genuinely consistent with the end model's internal processing.
- **Core assumption:** Spurious correlations primarily manifest through output-level optimization signals.
- **Evidence anchors:** Section 3.2 shows under shortcut experiments, both SLM and TLM exploit shortcuts while FuLA retains ability to perform well on clean data.

### Mechanism 3: Directionality Emerges from Functional Structure, Not Optimization Artifacts
- **Claim:** The asymmetric nature of functional similarity reflects genuine properties of learned representations, not artifacts of task-based optimization.
- **Mechanism:** By using FuLA (which is task-agnostic), the paper shows that directionality persists even without task loss. Earlier layers retain functionally relevant information when guided by deeper layers; reverse guidance is insufficient.
- **Core assumption:** If directionality were purely an artifact of task-based optimization, removing task objectives should eliminate or significantly reduce it.
- **Evidence anchors:** Section 3.3 finds that task-agnostic FuLA also behaves in a directional manner.

## Foundational Learning

- **Concept: Model Stitching Paradigm**
  - **Why needed here:** FuLA is an optimization condition within the model stitching framework. Understanding stitching—connecting two frozen networks via a learnable affine transformation—is prerequisite to understanding why FuLA's modifications matter.
  - **Quick check question:** Can you explain why stitching uses a low-capacity affine transformation rather than a full neural network to connect models?

- **Concept: Representational vs. Functional Similarity**
  - **Why needed here:** The paper critiques structure-based metrics (CKA, CCA) as agnostic to functional behavior. FuLA explicitly targets functional similarity—whether two models perform comparable transformations, not just whether their activation geometries correlate.
  - **Quick check question:** Given two models with high CKA similarity but poor stitching performance, which metric better reflects functional equivalence?

- **Concept: Knowledge Distillation Hints**
  - **Why needed here:** FuLA draws directly from the "hints" concept in distillation (FitNets), where intermediate layer matching guides student learning. FuLA applies this in reverse: using frozen end model layers as hints to guide the stitching transformation.
  - **Quick check question:** How does FuLA's use of "functional hints" differ from using the same layers for knowledge distillation?

## Architecture Onboarding

- **Component map:** Front model (f≤i) -> Stitching layer (Tθ) -> End model (g>j) -> Output
- **Critical path:**
  1. Initialize Tθ via DM using 100 training samples
  2. Train Tθ on full training set using FuLA objective with Adam, LR=0.001, weight decay=1e-4, 30 epochs
  3. Update running batch statistics of frozen models during training
  4. Evaluate functional similarity on held-out test set
- **Design tradeoffs:**
  - Hint weighting uses uniform weighting; deeper hints may improve functional consistency but increase sensitivity to misalignment
  - Stitching depth: earlier stitching requires more functional alignment through deeper hints; later stitching has less end model to align
  - Training data: FuLA shows better generalization when trained on class subsets, but performance degrades with too few classes
- **Failure signatures:**
  - Fabricated alignment (TLM/SLM): High robust accuracy when stitching non-robust models; large gap between clean and shortcut-augmented performance
  - Missed alignment (DM only): Fails to capture non-trivial transformations; underperforms when functional hints are needed
  - Directionality inversion: Poor performance when stitching shallow-to-deep relative to deep-to-shallow indicates genuine functional dissimilarity
- **First 3 experiments:**
  1. Same-architecture, same-task stitching with FuLA vs. TLM: Train two ResNet18 models on CIFAR-10; stitch at each residual block; plot accuracy vs. depth
  2. Adversarial training stress test: Stitch robust-to-non-robust and non-robust-to-robust models; confirm TLM "hallucinates" robust accuracy while FuLA reports random-chance performance
  3. Shortcut injection: Add pattern-based or location-based markers during stitching; verify TLM/SLM exploit shortcuts while FuLA maintains stable clean performance

## Open Questions the Paper Calls Out
None

## Limitations
- The paper's core claim rests on comparisons with only two alternative stitching objectives (SLM/TLM), without broader ablation across multiple task-based stitching variants
- Directionality findings are limited to ResNet architectures, leaving open questions about whether this property holds for transformers or other architectures
- The assertion that directionality is an inherent property of functional similarity rather than architecture-specific behavior needs validation across diverse model families

## Confidence
- **High confidence:** FuLA's improved stability under adversarial training and shortcut scenarios is well-supported by controlled experiments
- **Medium confidence:** The claim that FuLA captures "non-trivial alignments" missed by direct matching is plausible but lacks quantitative comparison
- **Low confidence:** The assertion that directionality is an inherent property of functional similarity rather than architecture-specific behavior needs validation

## Next Checks
1. **Architecture universality test:** Apply FuLA stitching to transformer models (e.g., ViT or BERT) to verify directionality persists outside ResNet residual blocks
2. **Ablation on hint layers:** Systematically vary the number and positions of hint layers in FuLA to determine whether multi-layer alignment is necessary
3. **Alternative stitching objectives:** Compare FuLA against a broader set of stitching methods including feature decorrelation objectives or mutual information maximization