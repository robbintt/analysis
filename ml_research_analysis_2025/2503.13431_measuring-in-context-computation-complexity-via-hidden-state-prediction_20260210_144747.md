---
ver: rpa2
title: Measuring In-Context Computation Complexity via Hidden State Prediction
arxiv_id: '2503.13431'
source_url: https://arxiv.org/abs/2503.13431
tags:
- loss
- next
- in-context
- layer
- complexity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces PHi (Prediction of Hidden States), a method
  to quantify the "interestingness" of neural sequence models' computation by measuring
  how well the model can predict its own future hidden states. The key insight is
  that low next-token prediction loss can be misleading, as it may arise from trivial
  patterns or memorized sequences rather than meaningful computation.
---

# Measuring In-Context Computation Complexity via Hidden State Prediction

## Quick Facts
- arXiv ID: 2503.13431
- Source URL: https://arxiv.org/abs/2503.13431
- Authors: Vincent Herrmann; Róbert Csordás; Jürgen Schmidhuber
- Reference count: 40
- Primary result: Introduces PHi (Prediction of Hidden States), a method to quantify "interestingness" of neural sequence models' computation by measuring how well the model can predict its own future hidden states

## Executive Summary
This paper addresses a fundamental challenge in evaluating neural sequence models: next-token prediction loss can be misleading as it may reflect memorization or trivial patterns rather than meaningful computation. The authors introduce PHi (Prediction of Hidden States), a method that quantifies the "interestingness" of a model's computation by measuring how well it can predict its own future hidden states. The key insight is that low next-token prediction loss doesn't necessarily indicate complex or meaningful computation - it might simply reflect memorization of common patterns or trivial sequential relationships.

The method works by inserting an information bottleneck layer that compresses hidden states into latent variables, with a learned autoregressive prior predicting future latents. The PHi loss - measured as the KL divergence between posterior and prior distributions over these latent variables - quantifies the novel information gained at each step. Experiments across multiple tasks demonstrate that PHi loss correlates with intuitive notions of task complexity and can distinguish between simple memorization and genuine in-context computation. The method is architecture-agnostic and can be inserted into pre-trained models or trained from scratch.

## Method Summary
PHi introduces an information bottleneck layer that compresses hidden states into latent variables, with a learned autoregressive prior predicting future latents. The PHi loss is measured as the KL divergence between the posterior and prior distributions over these latent variables, quantifying the novel information gained at each step. This captures the complexity of the "in-context program" being executed by the model. The method is architecture-agnostic and can be inserted into pre-trained models or trained from scratch. PHi loss increases with task complexity, differentiates between memorized sequences and novel computation, and correlates with solution correctness in mathematical reasoning tasks.

## Key Results
- On formal language learning tasks, PHi loss increases with the complexity of the underlying automaton
- For mathematical reasoning, PHi loss is higher for difficult problems and correlates with solution correctness, even when controlling for next-token loss
- When applied to large language models like Llama 3B, PHi loss differentiates between simple tasks (memorized sequences, random data) and complex ones (literature, code), while next-token loss does not
- For GSM-8k math problems, choosing the answer with higher PHi loss significantly increases the chance of selecting the correct solution

## Why This Works (Mechanism)
PHi works by measuring the model's uncertainty about its own future states. When a model encounters genuinely novel or complex patterns, it cannot easily predict its future hidden states, resulting in high PHi loss. Conversely, when processing memorized sequences or trivial patterns, the model can accurately predict its future states, yielding low PHi loss. This captures the computational complexity of the "in-context program" being executed rather than just the surface-level predictability of the output sequence.

## Foundational Learning
- Information Bottleneck Theory: Explains why compressing hidden states into latent variables helps capture meaningful information while filtering noise. Why needed: Enables the method to focus on the most relevant aspects of computation. Quick check: Verify that the bottleneck dimension captures task-relevant features by examining latent space representations.
- KL Divergence as Information Gain: Measures the difference between posterior and prior distributions over latent variables. Why needed: Quantifies the novel information gained at each step. Quick check: Confirm that KL values increase for genuinely novel content versus memorized patterns.
- Autoregressive Prior Learning: The prior network learns to predict future latent variables based on past latents. Why needed: Enables the model to measure its own uncertainty about future states. Quick check: Test whether the prior can accurately predict latents for simple sequences but fails for complex ones.

## Architecture Onboarding

Component Map: Input Sequence -> Model Hidden States -> Information Bottleneck -> Latent Variables -> Prior Prediction -> KL Loss

Critical Path: The bottleneck layer and prior network form the core of PHi. The bottleneck compresses high-dimensional hidden states into lower-dimensional latent variables, while the prior network learns to predict future latents based on past ones. The KL divergence between the true posterior and predicted prior constitutes the PHi loss.

Design Tradeoffs: The bottleneck strength (compression ratio) must balance between capturing sufficient information and forcing the model to extract meaningful features. Too much compression leads to information loss, while too little fails to enforce meaningful abstraction. The prior network complexity must be sufficient to capture temporal dependencies but not so complex that it can trivially predict any sequence.

Failure Signatures: High PHi loss on simple memorization tasks indicates the method is working as intended. Low PHi loss on complex reasoning tasks suggests the bottleneck is too weak or the prior is too powerful. Extremely high PHi loss throughout may indicate the bottleneck is too aggressive, causing information collapse.

First Experiments: 1) Test on a simple sequence memorization task to verify low PHi loss. 2) Apply to a formal language with known complexity hierarchy to confirm increasing PHi loss. 3) Use on a mathematical reasoning dataset to check correlation with solution correctness.

## Open Questions the Paper Calls Out
None

## Limitations
- Cannot distinguish between productive computation and redundant operations like copying, which may register as high PHi loss despite low computational complexity
- Current aggregation method (averaging PHi loss across tokens) may not capture temporal structure of computation, potentially diluting transient high-PHi signatures
- Sensitivity to hyperparameters like bottleneck strength and prior learning rate requires systematic investigation to establish reliable baselines

## Confidence
- High confidence: PHi correlates with task complexity across diverse domains (formal languages, mathematics, general text/code processing)
- Medium confidence: PHi can improve mathematical reasoning by selecting high-PHi answers (requires independent replication)
- Medium confidence: PHi differentiates memorized sequences from novel computation (limited negative controls)

## Next Checks
1. Test PHi across multiple random seeds and hyperparameter configurations to establish sensitivity bounds and identify optimal settings for different task types
2. Conduct ablation studies comparing PHi against alternative complexity metrics (e.g., Fisher information, gradient norms) on benchmark reasoning tasks to isolate what aspects of computation PHi uniquely captures
3. Apply PHi to models with known internal structures (e.g., modular architectures or explicitly programmed components) to verify that PHi signatures align with expected computational patterns