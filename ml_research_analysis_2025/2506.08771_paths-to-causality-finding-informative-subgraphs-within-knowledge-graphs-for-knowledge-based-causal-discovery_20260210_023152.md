---
ver: rpa2
title: 'Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs
  for Knowledge-Based Causal Discovery'
arxiv_id: '2506.08771'
source_url: https://arxiv.org/abs/2506.08771
tags:
- subgraph
- causal
- subgraphs
- ranker
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel approach for integrating Knowledge
  Graphs (KGs) with Large Language Models (LLMs) to enhance knowledge-based causal
  discovery. The core method identifies informative metapath-based subgraphs within
  KGs and refines their selection using Learning-to-Rank-based models, which are then
  incorporated into zero-shot prompts to improve LLMs' effectiveness in inferring
  causal relationships.
---

# Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery

## Quick Facts
- **arXiv ID:** 2506.08771
- **Source URL:** https://arxiv.org/abs/2506.08771
- **Reference count:** 40
- **Primary result:** Novel approach integrating KGs with LLMs for knowledge-based causal discovery, achieving up to 44.4 F1 improvement over baselines

## Executive Summary
This paper introduces a novel approach for integrating Knowledge Graphs (KGs) with Large Language Models (LLMs) to enhance knowledge-based causal discovery. The core method identifies informative metapath-based subgraphs within KGs and refines their selection using Learning-to-Rank-based models, which are then incorporated into zero-shot prompts to improve LLMs' effectiveness in inferring causal relationships. Experiments on biomedical and open-domain datasets demonstrate significant performance improvements, with F1 scores increasing by up to 44.4 points compared to baselines. The approach consistently outperforms most baselines across diverse LLMs and KGs, showcasing its generalizability and effectiveness in knowledge-based causal discovery tasks.

## Method Summary
The method operates through a pipeline of four stages: (1) Subgraph Extraction retrieves metapath-based subgraphs from KGs using Neo4j or SPARQL queries, (2) Subgraph Relevancy Estimation scores each subgraph's relevance using an LLM based on log-probability of predicting the ground truth label, (3) Subgraph Ranker Training trains a Learning-to-Rank model (Cross-Encoder or XGBoost) on the LLM-generated scores using pointwise, pairwise, or listwise losses, and (4) Zero-Shot Inference verbalizes the top-ranked subgraph and injects it into prompts for target LLMs to classify causal relationships. The approach is evaluated across Hetionet (biomedical) and Wikidata (open-domain) KGs using datasets including GENEC, ADE, COMAGC, and SEMEVAL.

## Key Results
- Achieved up to 44.4 F1 improvement over baselines across three LLMs and two KGs
- Pairwise RankNet loss generally outperforms pointwise RMSE and listwise ListNet in ranker training
- Top-1 subgraph selection (k=1) typically provides optimal balance between context and noise
- Cross-encoder rankers outperform XGBoost variants in 9 out of 12 experimental conditions
- Performance gains are more pronounced with domain-specific KGs (Hetionet) compared to open-domain KGs (Wikidata)

## Why This Works (Mechanism)

### Mechanism 1: Metapath-Based Contextual Evidence Chains
Structured paths through knowledge graphs provide interpretable evidence chains that improve LLM causal reasoning over metadata-only approaches. Metapaths (e.g., drug→gene→disease) encode semantic sequences that capture mechanistic relationships. When verbalized and provided as prompt context, these paths give LLMs structured relational evidence to reason over, reducing hallucination and grounding predictions in external knowledge. This mechanism assumes KGs contain causal-relevant paths that, when surfaced, provide signal not present in LLM parametric knowledge.

### Mechanism 2: Distillation of LLM Judgment via Learning-to-Rank
Training specialized ranker models on LLM-generated relevance judgments produces more effective subgraph selection than direct LLM ranking or similarity-based retrieval. An LLM first scores subgraphs by predicting causal relations and recording confidence. These scores become training labels for a lightweight ranker (cross-encoder or XGBoost) that learns to prioritize informative paths using metapath metadata (node types, relation sequences). The ranker generalizes LLM judgment more efficiently than repeated prompting. This mechanism assumes LLM relevance judgments, while noisy individually, contain learnable patterns when aggregated across variable pairs.

### Mechanism 3: Zero-Shot Prompting with Verbalized Subgraph Context
Providing top-ranked verbalized subgraphs as prompt context enables zero-shot causal inference without observational data or fine-tuning. Subgraphs are linearized into natural language sequences (e.g., "Gene FGF6 → anatomy tendon → gene SDRDL → disease prostate cancer") and prepended to instruction prompts. The LLM leverages its pretrained knowledge plus this structured context to classify causal relations in a single forward pass. This mechanism assumes LLMs can integrate verbalized graph structure with prior knowledge to make accurate causal judgments on unseen pairs.

## Foundational Learning

- **Concept: Metapaths in Heterogeneous Knowledge Graphs**
  - **Why needed here:** The entire approach depends on extracting and ranking metapath-based subgraphs. Without understanding node type sequences and composite relations, you cannot implement the retrieval or ranking components.
  - **Quick check question:** Given a KG with node types {Drug, Gene, Disease} and edges {upregulates, associates}, can you identify the metapath schema for a 2-hop path from a drug to a disease through a gene?

- **Concept: Learning-to-Rank Objective Functions (Pointwise, Pairwise, Listwise)**
  - **Why needed here:** The Subgraph Ranker module requires choosing between RMSE (pointwise), RankNet (pairwise), and ListNet (listwise) losses. Understanding tradeoffs is essential for implementation and debugging.
  - **Quick check question:** Why might a pairwise loss like RankNet outperform pointwise RMSE when the goal is relative ranking rather than absolute score prediction?

- **Concept: Zero-Shot Prompting with Retrieval-Augmented Context**
  - **Why needed here:** The final inference stage relies on constructing prompts that combine instructions, textual context, and retrieved subgraphs without fine-tuning the LLM.
  - **Quick check question:** What are the failure modes when injecting too much retrieved context into a zero-shot prompt, and how would you detect them?

## Architecture Onboarding

- **Component map:** Subgraph Extraction (KG Querying) → Subgraph Relevancy Estimation (LLM Scoring) → Subgraph Ranker (Training) → Top-k Selection → Zero-Shot Inference (LLM Prompting)

- **Critical path:** Subgraph Extraction → Relevancy Estimation → Ranker Training → Top-k Selection → Zero-Shot Inference. Errors in early stages compound; poor extraction cannot be fixed by better ranking.

- **Design tradeoffs:**
  - **Cross-encoder vs. XGBoost ranker:** Cross-encoders capture semantic nuance but are slower inference; XGBoost is faster with n-gram features but may miss subtle patterns. Paper shows cross-encoder generally better (9/12 cases), but XGBoost wins on some datasets.
  - **Number of subgraphs in prompt (k):** Paper found k=1 optimal on average; more context can introduce noise. Trade-off: richer evidence vs. distraction.
  - **KG choice:** Hetionet (domain-specific) yields larger gains than Wikidata (open-domain), suggesting domain alignment matters.

- **Failure signatures:**
  - **Low F1 despite subgraphs:** Check if KG has coverage for domain; verify metapath extraction is returning non-empty results.
  - **Ranker overfitting:** If NDCG@5 on training data high but inference F1 low, reduce model capacity or increase training diversity.
  - **LLM inconsistent predictions:** Verify prompt formatting; check for tokenization issues with verbalized paths; ensure log-probability extraction is correct.

- **First 3 experiments:**
  1. **Baseline replication:** Run no-subgraph vs. random-subgraph conditions on one dataset (e.g., ADE) to confirm paper's reported ~12.5 F1 improvement. Validates pipeline and LLM access.
  2. **Ranker ablation:** Compare RankNet (pairwise) vs. RMSE (pointwise) cross-encoder on validation split. Confirm pairwise advantage per paper's finding.
  3. **KG coverage analysis:** For a sample of failed predictions, manually inspect whether KG returned relevant paths. Quantify how often failures stem from missing KG coverage vs. ranker/LLM errors.

## Open Questions the Paper Calls Out

- **Question:** Can the proposed pairwise causal discovery method be extended to infer full causal graph structures involving multiple interconnected variables?
  - **Basis in paper:** The conclusion states, "in future work, we aim to explore complex scenarios involving multiple interconnected variables, i.e., full causal graph discovery."
  - **Why unresolved:** The current methodology and evaluation focus exclusively on classifying relationships between isolated variable pairs rather than reconstructing complex multivariate networks.
  - **What evidence would resolve it:** A study applying the method to benchmark datasets with ground-truth causal DAGs (Directed Acyclic Graphs), measuring performance using structural metrics like Structural Hamming Distance (SHD).

- **Question:** How can the integration of LLMs and Knowledge Graphs be co-optimized to improve causal reasoning beyond the current sequential pipeline?
  - **Basis in paper:** The authors plan to "co-optimize the integration of LLMs and KGs, while incorporating causality-related evaluation metrics."
  - **Why unresolved:** The current approach treats KG retrieval and LLM inference as separate, sequential steps (ranker training then prompting), potentially missing synergistic optimization opportunities.
  - **What evidence would resolve it:** An end-to-end framework where the KG retrieval mechanism is fine-tuned jointly with the LLM's causal reasoning objective, showing superior performance over the modular approach.

- **Question:** To what extent does the "Subgraph Ranker" propagate errors from the LLM used for Subgraph Relevancy Estimation?
  - **Basis in paper:** The method relies on a generic LLM (`mistral-7b`) to generate the "ground truth" relevance scores for training the ranker. The introduction notes that LLMs "often produce unstable and inconsistent results."
  - **Why unresolved:** If the teacher LLM hallucinates or incorrectly ranks a subgraph during the Relevancy Estimation phase, the student ranker model will learn to prioritize non-informative paths, compromising the system's reliability.
  - **What evidence would resolve it:** An ablation study analyzing the sensitivity of the final F1 scores to the error rate of the teacher LLM used in the initial estimation phase.

## Limitations

- **Coverage dependency:** The approach only works for entity pairs with existing metapath connections in the KG, falling back to baseline performance for pairs lacking subgraphs.
- **Noise propagation:** The LLM-to-ranker distillation step can propagate noise from the LLM's relevance judgments to the ranker training.
- **Domain alignment:** Performance gains are more pronounced with domain-specific KGs (Hetionet) compared to open-domain KGs (Wikidata), suggesting the approach may not generalize equally well across all domains.

## Confidence

- **High Confidence:** The core pipeline architecture (KG extraction → LLM scoring → ranker training → zero-shot inference) is technically sound and well-documented. The 44.4 F1 improvement over baselines is clearly demonstrated across multiple datasets and LLMs.
- **Medium Confidence:** The claim that metapath-based subgraphs provide "interpretable evidence chains" improving LLM reasoning is supported but could benefit from qualitative analysis of successful vs. failed cases. The superiority of pairwise ranking over other loss functions is shown but may not generalize to all domains.
- **Low Confidence:** The paper's assertion that this approach is "zero-shot" is somewhat misleading since it requires LLM scoring for ranker training, which involves computational costs and potential bias injection.

## Next Checks

1. **Coverage Analysis:** For each dataset, calculate the percentage of entity pairs that have at least one metapath in the KG. Determine if the reported improvements are skewed toward well-connected pairs and quantify the performance gap for pairs without KG coverage.

2. **Ranker Calibration Test:** Run the ranker on held-out validation data and compare its rankings against direct LLM scoring. Calculate correlation metrics (NDCG, Kendall's tau) to verify the ranker is actually learning meaningful patterns rather than overfitting to noise.

3. **Ablation on Prompt Length:** Systematically vary the number of top-k subgraphs included in prompts (k=1, 3, 5, 10) and measure the trade-off between additional context and performance degradation. This would validate the paper's finding that k=1 is optimal and test whether the "too much context" failure mode exists.