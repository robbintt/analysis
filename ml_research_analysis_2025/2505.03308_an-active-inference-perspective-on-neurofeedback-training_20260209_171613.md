---
ver: rpa2
title: An Active Inference perspective on Neurofeedback Training
arxiv_id: '2505.03308'
source_url: https://arxiv.org/abs/2505.03308
tags:
- feedback
- training
- subject
- neurofeedback
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a computational Active Inference model to
  simulate Neurofeedback Training (NFT), addressing the challenge of highly variable
  outcomes in NFT. The model treats subjects as agents navigating a partially observable
  environment, where they learn to control cognitive states based on feedback.
---

# An Active Inference perspective on Neurofeedback Training

## Quick Facts
- arXiv ID: 2505.03308
- Source URL: https://arxiv.org/abs/2505.03308
- Authors: Côme Annicchiarico; Fabien Lotte; Jérémie Mattout
- Reference count: 37
- Primary result: Active Inference model simulates NFT, revealing that training success depends on feedback quality and subject priors, with interoception potentially enhancing outcomes.

## Executive Summary
This paper introduces a computational Active Inference model to simulate Neurofeedback Training (NFT), addressing the challenge of highly variable outcomes in NFT. The model treats subjects as agents navigating a partially observable environment, where they learn to control cognitive states based on feedback. Simulations reveal that training effectiveness is sensitive to feedback noise or bias and to prior beliefs, highlighting the importance of guiding instructions. However, even perfect feedback is insufficient to guarantee high performance. This approach provides a tool for assessing and predicting NFT variability, interpreting empirical data, and potentially developing personalized training protocols.

## Method Summary
The model simulates an Active Inference agent learning self-regulation in a Partially Observable Markov Decision Process (POMDP) with 5 discrete hidden states. The environment has probabilistic transitions defined by "Up" actions (p=0.99 to next state) and "Cognitive pull" actions (p=0.5 to lower state). Observations are 5 discrete feedback levels generated from Gaussian distributions with variable noise. The agent uses Sophisticated Inference for planning (tree search) and Dirichlet posterior updates for learning transition and likelihood models on a trial-by-trial basis. The framework minimizes Variational Free Energy for perception and Expected Free Energy for action selection.

## Key Results
- NFT performance is highly sensitive to feedback noise/bias, with performance degrading non-linearly as noise increases
- Prior beliefs significantly impact learning outcomes; cautious priors show slower but more robust learning than naive priors
- Even perfect feedback is insufficient to guarantee high performance, suggesting the need for both good feedback and appropriate subject expectations

## Why This Works (Mechanism)
The Active Inference framework naturally captures the iterative learning process in NFT where subjects must infer hidden cognitive states from noisy feedback. By treating the subject as an agent with prior beliefs about state transitions and observation likelihoods, the model captures how subjects update their internal models based on experience. The partial observability of the cognitive state space mirrors the real-world challenge where subjects cannot directly observe their brain activity but must infer it from indirect feedback signals.

## Foundational Learning
- **Active Inference framework**: A computational approach where agents minimize free energy to maintain homeostasis and learn about their environment. Why needed: Provides the theoretical foundation for modeling how subjects learn from feedback during NFT.
- **POMDP (Partially Observable Markov Decision Process)**: A decision-making framework for agents that must act based on incomplete observations. Why needed: Captures the fundamental challenge in NFT where cognitive states are hidden and must be inferred from noisy feedback.
- **Sophisticated Inference**: A planning method using tree search to handle partial observability by considering future observation sequences. Why needed: Enables the agent to plan actions when the current state is uncertain.
- **Dirichlet distributions**: Conjugate priors for categorical distributions used to model transition and likelihood matrices. Why needed: Provides a principled way to represent and update beliefs about state transitions and observation probabilities.
- **Variational Free Energy**: A quantity that agents minimize to balance accuracy and complexity in their internal models. Why needed: Guides the perception process by finding the best approximation to the true posterior distribution.
- **Expected Free Energy**: An extension of free energy to planning that balances expected accuracy with expected ambiguity. Why needed: Guides action selection by considering both the predicted outcome and the uncertainty about that outcome.

## Architecture Onboarding
### Component Map
Environment (5-state POMDP) -> Active Inference Agent (Sophisticated Inference + Dirichlet Learning) -> Performance Metrics (Average Feedback, KL Divergence)

### Critical Path
1. Generate observation from true cognitive state + noise
2. Agent updates beliefs about state using Variational Free Energy minimization
3. Agent plans action using Expected Free Energy minimization with tree search
4. Environment transitions to new state based on action
5. Agent updates model parameters using Dirichlet learning rule

### Design Tradeoffs
- **Sophisticated vs Simple Inference**: Sophisticated Inference handles partial observability but is computationally expensive; Simple Inference is faster but fails to account for uncertainty about current state
- **Prior Strength**: Strong priors (high concentration) provide stability but may prevent learning; weak priors (low concentration) allow flexibility but risk overfitting noise
- **Feedback Dimensionality**: Single cognitive dimension simplifies analysis but may miss the complexity of real NFT where multiple brain signals are involved

### Failure Signatures
- **Agent stagnation**: KL divergence between learned and true transition matrices remains high across trials, indicating failure to learn
- **Overfitting to noise**: Learned transition matrix shows spurious high-probability paths not present in the true model
- **Poor exploration**: Agent consistently selects the same action regardless of feedback, suggesting failure to update beliefs

### First 3 Experiments
1. **Vary Feedback Noise with Fixed Priors**: Simulate agents with naive perception model across feedback noise levels (0.1-5.0) to replicate non-linear performance drop-off
2. **Compare Naive vs. Cautious Priors under Noisy Feedback**: Run two groups with moderate noise (0.5); compare learning curves to observe if cautious group shows slower but more robust learning
3. **Ablation of Interoceptive Modality**: Train groups with and without interoceptive signals under high external noise (1.0) to validate generalization mechanism

## Open Questions the Paper Calls Out
### Open Question 1
Can the proposed Active Inference framework be extended to explicitly model neurophysiological dynamics (the biomarker) rather than mapping cognitive states directly to feedback? The authors state that simulating the NF subject physiology is a necessary next step as the current model renders this dimension implicit. This remains unresolved because the current abstraction ignores the signal processing and physiological variability inherent in real BCI loops. Evidence would require an extended model generating synthetic physiological signals from cognitive states and deriving feedback from them.

### Open Question 2
Can this computational model be utilized for Bayesian parameter estimation to predict training outcomes or personalize protocols for individual subjects? The authors identify using Active Inference models for parameter estimation as a primary developmental axis. This remains unresolved because the study simulates agents with pre-defined parameters but doesn't demonstrate fitting the model to empirical data to infer hidden subject traits. Evidence would require fitting the model to real-world NFT data to recover parameters correlating with actual subject performance.

### Open Question 3
Does the accuracy of the learned interoceptive mapping directly predict the ability to transfer self-regulation skills outside the training environment? The authors hypothesize interoception is crucial for generalization but note behavior outside training is not currently simulated. This remains unresolved because while simulations show interoception aids training performance, the mechanism for post-training retention remains theoretical. Evidence would require simulation results showing agents with high interoceptive accuracy maintain performance when external feedback is deactivated.

## Limitations
- The model relies on several parameters not fully specified (tree search depth, discretization scheme), requiring additional assumptions for reproduction
- The single synthetic task (5-state POMDP) may not capture the complexity of real neurofeedback scenarios with multiple interacting cognitive dimensions
- The model treats feedback noise and prior beliefs as independent factors, potentially missing their complex interactions in practice

## Confidence
- **High Confidence**: The core Active Inference framework and its application to neurofeedback is theoretically sound and well-established
- **Medium Confidence**: The specific implementation details and parameter choices are reasonable but not fully verifiable without running the provided code
- **Medium Confidence**: The qualitative conclusions about feedback noise and prior beliefs affecting learning outcomes are supported by the simulations

## Next Checks
1. **Parameter Sensitivity Analysis**: Systematically vary tree search depth and discretization resolution to determine their impact on learning outcomes and identify critical parameters for reproducing results
2. **Real-World Task Validation**: Apply the model to a more complex, multi-dimensional neurofeedback task (e.g., simultaneous regulation of multiple EEG frequency bands) to test generalizability beyond the simple 5-state POMDP
3. **Clinical Translation Assessment**: Compare model predictions with empirical NFT data from heterogeneous populations to evaluate whether the framework can explain inter-individual variability in real-world neurofeedback studies