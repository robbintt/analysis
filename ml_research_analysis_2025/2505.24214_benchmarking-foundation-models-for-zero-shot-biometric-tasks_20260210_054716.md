---
ver: rpa2
title: Benchmarking Foundation Models for Zero-Shot Biometric Tasks
arxiv_id: '2505.24214'
source_url: https://arxiv.org/abs/2505.24214
tags:
- face
- recognition
- dataset
- vision
- iris
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper evaluates the zero-shot and few-shot performance of
  41 publicly available Vision-Language Models (VLMs) and Multi-modal Large Language
  Models (MLLMs) on six biometric tasks: face verification, soft biometric attribute
  prediction (gender and race), iris recognition, iris presentation attack detection
  (PAD), face manipulation detection (morphs and deepfakes), and face manipulation
  detection (morphs and deepfakes). For face verification, the best model achieved
  a True Match Rate (TMR) of 96.77% at 1% False Match Rate (FMR) on Labeled Faces
  in the Wild (LFW).'
---

# Benchmarking Foundation Models for Zero-Shot Biometric Tasks

## Quick Facts
- **arXiv ID:** 2505.24214
- **Source URL:** https://arxiv.org/abs/2505.24214
- **Reference count:** 40
- **Primary result:** VLMs achieve 96.77% TMR at 1% FMR for face verification on LFW

## Executive Summary
This paper evaluates 41 publicly available Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs) on six biometric tasks using zero-shot and few-shot learning approaches. The study assesses model performance across face verification, soft biometric attribute prediction, iris recognition, iris presentation attack detection, and face manipulation detection tasks. The research demonstrates that pretrained foundation models can effectively transfer their knowledge to diverse biometric applications without extensive task-specific fine-tuning, supporting the vision of Artificial General Intelligence for biometric systems.

## Method Summary
The authors evaluated 41 publicly available VLMs and MLLMs across six biometric tasks using zero-shot and few-shot learning paradigms. For face verification, they used Labeled Faces in the Wild (LFW) dataset, while iris recognition was tested on the IITD-R-Full dataset. Soft biometric attribute prediction focused on gender and race classification. Iris presentation attack detection and face manipulation detection (morphs and deepfakes) were also evaluated. The study employed simple classifier heads applied to VLM embeddings for tasks like deepfake detection and iris PAD, rather than task-specific fine-tuning. Performance metrics included True Match Rate (TMR) at 1% False Match Rate (FMR) for verification tasks and accuracy measures for classification tasks.

## Key Results
- Face verification achieved 96.77% TMR at 1% FMR on LFW dataset
- Iris recognition achieved 97.55% TMR at 1% FMR on IITD-R-Full dataset
- Simple classifier heads on VLM embeddings enabled effective deepfake detection, iris PAD, and soft biometric attribute extraction with high accuracy

## Why This Works (Mechanism)
Foundation models trained on large-scale multimodal data develop rich representations that capture generalizable patterns across visual and textual domains. These pretrained models have learned robust feature extractors that can be effectively repurposed for specialized biometric tasks through transfer learning, even without task-specific fine-tuning. The zero-shot and few-shot capabilities emerge from the models' ability to leverage learned relationships between visual features and semantic concepts during their pretraining phase.

## Foundational Learning
- **Vision-Language Model (VLM) architecture** - why needed: Enables joint processing of visual and textual information for multimodal understanding; quick check: Verify model supports both image and text input modalities
- **Transfer learning principles** - why needed: Allows leveraging pretrained knowledge for new tasks without extensive retraining; quick check: Confirm performance degradation when using zero-shot vs fine-tuned approaches
- **Presentation attack detection (PAD)** - why needed: Critical for identifying spoofed biometric samples in security applications; quick check: Test model on diverse attack types including print, replay, and 3D mask attacks
- **Face verification metrics (TMR/FMR)** - why needed: Standardized evaluation framework for biometric matching performance; quick check: Verify threshold selection impacts reported accuracy
- **Few-shot learning techniques** - why needed: Enables adaptation with minimal labeled examples for new biometric tasks; quick check: Compare performance across different shot counts (1-shot, 5-shot, 10-shot)

## Architecture Onboarding

**Component Map:** Data Input -> VLM Backbone -> Embedding Layer -> Classifier Head -> Output

**Critical Path:** Image/Text Input → Vision Encoder → Cross-modal Fusion → Task-specific Head → Prediction Output

**Design Tradeoffs:** Zero-shot approach favors generalization and rapid deployment but may underperform specialized fine-tuned models; simple classifier heads offer computational efficiency but may limit complex task adaptation.

**Failure Signatures:** Performance degradation on out-of-distribution samples, sensitivity to adversarial examples, poor generalization across demographic groups, and reduced accuracy for novel presentation attack types.

**First Experiments:**
1. Baseline evaluation on LFW and IITD-R-Full datasets to establish performance benchmarks
2. Cross-dataset validation to assess generalization capabilities
3. Adversarial robustness testing for presentation attack detection scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses exclusively on publicly available models, potentially excluding more capable proprietary systems
- Zero-shot and few-shot settings may not represent optimal performance achievable through task-specific fine-tuning
- Reliance on established benchmark datasets may not fully capture real-world operational complexity and diversity

## Confidence
- **Face verification performance:** Medium to High
- **Iris recognition performance:** Medium to High
- **Deepfake detection effectiveness:** Medium
- **Presentation attack detection robustness:** Medium

## Next Checks
1. Evaluate model performance on larger, more diverse biometric datasets that better represent real-world operational conditions, including cross-dataset validation to assess generalization capabilities
2. Conduct adversarial robustness testing specifically for presentation attack detection and manipulation detection tasks, assessing vulnerability to emerging attack techniques
3. Perform ablation studies comparing zero-shot/few-shot foundation model performance against task-specific fine-tuned models to quantify the trade-offs between transfer learning and specialized optimization