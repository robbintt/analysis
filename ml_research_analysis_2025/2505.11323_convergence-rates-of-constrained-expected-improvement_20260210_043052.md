---
ver: rpa2
title: Convergence Rates of Constrained Expected Improvement
arxiv_id: '2505.11323'
source_url: https://arxiv.org/abs/2505.11323
tags:
- lemma
- regret
- bound
- function
- simple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes the first theoretical convergence rates\
  \ for constrained expected improvement (CEI), a widely used Bayesian optimization\
  \ method for constrained black-box optimization. The authors analyze CEI's simple\
  \ regret under both frequentist and Bayesian settings, deriving convergence rates\
  \ of O(t^(-1/2) log^((d+1)/2)(t)) for squared exponential kernels and O(t^(-\u03BD\
  /(2\u03BD+d)) log^(\u03BD/(2\u03BD+d))(t)) for Mat\xE9rn kernels (\u03BD 1/2)."
---

# Convergence Rates of Constrained Expected Improvement

## Quick Facts
- arXiv ID: 2505.11323
- Source URL: https://arxiv.org/abs/2505.11323
- Authors: Haowei Wang; Jingyi Wang; Zhongxiang Dai; Nai-Yuan Chiang; Szu Hui Ng; Cosmin G. Petra
- Reference count: 40
- Primary result: Establishes first theoretical convergence rates for Constrained Expected Improvement (CEI) in Bayesian optimization

## Executive Summary
This paper provides the first rigorous theoretical analysis of convergence rates for Constrained Expected Improvement (CEI), a widely-used Bayesian optimization method for constrained black-box optimization. The authors prove that CEI achieves simple regret convergence rates of O(t^(-1/2) log^((d+1)/2)(t)) for squared exponential kernels and O(t^(-ν/(2ν+d)) log^(ν/(2ν+d))(t)) for Matérn kernels under both frequentist and Bayesian settings. These rates are established through careful analysis of the acquisition function's product structure and information-theoretic bounds on posterior variance reduction. The theoretical findings are validated through synthetic experiments on both RKHS and GP-generated functions, demonstrating sublinear convergence patterns consistent with the established rates.

## Method Summary
The method analyzes CEI's simple regret convergence in constrained Bayesian optimization where the objective f and constraint c are modeled as independent Gaussian processes. The CEI acquisition function multiplies Expected Improvement for the objective by the Probability of Feasibility for the constraint. The analysis considers both frequentist settings (f and c lie in RKHS with bounded norms) and Bayesian settings (f sampled from GP prior). Convergence rates are derived using maximum information gain bounds and confidence interval analysis, with separate results for squared exponential and Matérn kernels.

## Key Results
- Proves first theoretical convergence rates for CEI: O(t^(-1/2) log^((d+1)/2)(t)) for SE kernels, O(t^(-ν/(2ν+d)) log^(ν/(2ν+d))(t)) for Matérn kernels
- Establishes simple regret bounds under both frequentist (RKHS assumption) and Bayesian (GP prior) settings
- Derives multiplicative penalty 1/Φ(-B_c) in regret bound from constraint RKHS norm
- Validates theoretical rates through synthetic experiments on RKHS and GP-generated functions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CEI converges by selecting points that balance expected improvement in the objective with probability of constraint satisfaction.
- Mechanism: The acquisition function multiplies Expected Improvement (EI) for the objective by the Probability of Feasibility (POF) for the constraint: EI_C_t(x) = P_t(x) × EI_f_t(x). This product structure ensures the algorithm preferentially samples points where both high improvement is expected AND constraint violation is unlikely. Theoretical convergence is established by bounding the simple regret r_t = f+_t - f(x*) through analyzing how quickly the GP posterior variance σ_f_t(x) decreases as samples are added.
- Core assumption: The objective f and constraint c either lie in a Reproducing Kernel Hilbert Space (RKHS) with bounded norms (frequentist setting) or f is sampled from a GP (Bayesian setting); both are noise-free evaluations; conditional independence between f and c.
- Evidence anchors:
  - [abstract] "CEI is a natural extension of the expected improvement (EI) when constraints are incorporated... deriving convergence rates of O(t^(-1/2) log^((d+1)/2)(t)) for squared exponential kernels"
  - [section] Section 2.2 defines CEI as EI_C_t(x) = P_t(x)EI_f_t(x) = Φ(-μ_c_t(x)/σ_c_t(x))EI_f_t(x), and Algorithm 1 shows the sequential sampling procedure
  - [corpus] Related work on consensus-based optimization (CBO) methods addresses different algorithmic families; corpus has limited direct evidence on CEI-specific mechanisms
- Break condition: If no initial feasible sample exists (f+_t undefined), CEI cannot compute the acquisition function; if constraint boundary is extremely sharp or discontinuous, GP surrogate may fail to model feasibility accurately.

### Mechanism 2
- Claim: Convergence rate is governed by maximum information gain γ_f_t, which captures how much information about f is acquired per sample based on kernel properties.
- Mechanism: Rather than analyzing individual posterior variances, the proof bounds the cumulative sum of σ_f_t(x_t+1) using information-theoretic quantities. The maximum information gain γ_f_t grows as O(log^((d+1))(t)) for squared exponential kernels and O(t^(d/(2ν+d)) log^(2ν/(2ν+d))(t)) for Matérn kernels. By showing that large posterior variances cannot persist too frequently (Lemma A.5), the proof establishes that σ_f_tk(x_tk+1) must eventually decrease, driving simple regret to zero.
- Core assumption: Compact domain; kernels satisfy regularity conditions (Assumptions 1-4 from Bull 2011); Matérn smoothness parameter ν > 1/2.
- Evidence anchors:
  - [abstract] "These rates are proven through careful analysis of the acquisition function's structure, leveraging maximum information gain and confidence interval bounds"
  - [section] Section 3.1.1 introduces improved bounds using γ_f_t; Lemma A.5 bounds how often σ_f_i(x_i+1) can exceed √(tγ_f_t/k)
  - [corpus] Corpus includes work on noisy EI convergence (arxiv 2501.09262) but limited direct coverage of information-theoretic CEI analysis
- Break condition: If kernel hyperparameters are severely misspecified (e.g., length scale too small), γ_f_t bounds become loose and convergence may be slower than theoretical rates suggest.

### Mechanism 3
- Claim: The constraint handling introduces a multiplicative penalty 1/Φ(-B_c) in the regret bound, where B_c bounds the constraint's RKHS norm.
- Mechanism: At the optimal point x*, the probability of feasibility P_tk(x*) = Φ(-μ_c_tk(x*)/σ_c_tk(x*)) must be bounded below. Using the confidence interval |c(x) - μ_c_t(x)| ≤ B_c × σ_c_t(x), and the fact that c(x*) ≤ 0, we obtain -μ_c_tk(x*)/σ_c_tk(x*) ≥ -B_c, hence P_tk(x*) ≥ Φ(-B_c). This term appears in the denominator of the regret bound, meaning problems with larger constraint norm bounds (more complex constraint functions) can have larger regret constants.
- Core assumption: Constraint function c has bounded RKHS norm ||c||_Hkc ≤ B_c; x* is feasible.
- Evidence anchors:
  - [abstract] "Careful analysis of the acquisition function's structure"
  - [section] Remark 3.4 explicitly states "The terms derived from the constraint function in (10) is 1/Φ(-B_c), which emerges from the probability of feasibility function"; equation (48) shows P_tk(x*) ≥ Φ(-B_c)
  - [corpus] Corpus has limited coverage of constraint-specific regret decomposition in CEI
- Break condition: If B_c is very large (highly complex constraint), the multiplicative penalty can make the regret bound vacuously large; if Φ(-B_c) ≈ 0, the bound may not be informative.

## Foundational Learning

- Concept: Reproducing Kernel Hilbert Space (RKHS)
  - Why needed here: The frequentist convergence analysis assumes f and c lie in an RKHS, which provides the mathematical structure to quantify function smoothness and derive confidence intervals.
  - Quick check question: Can you explain why the RKHS norm ||f||_Hk provides a measure of function complexity relative to kernel k?

- Concept: Gaussian Process (GP) Posterior
  - Why needed here: CEI uses GP posteriors to compute μ_f_t, σ_f_t, μ_c_t, and σ_c_t, which appear in both EI and POF computations; understanding how posteriors update with samples is essential.
  - Quick check question: Given a GP prior with zero mean and kernel k, how do the posterior mean μ_t(x) and variance σ_t²(x) change as more observations are added?

- Concept: Simple Regret vs. Cumulative Regret
  - Why needed here: This paper establishes simple regret bounds (r_t = f+_t - f(x*)), which measure the gap between the best found feasible point and the optimum, rather than summing errors over all iterations.
  - Quick check question: Why is simple regret the appropriate metric for optimization settings where we only care about the final best solution?

## Architecture Onboarding

- Component map: GP Surrogates -> Acquisition Function (CEI) -> Optimizer -> Incumbent Tracking
- Critical path:
  1. Initialize with T_0 feasible samples (or handle infeasible initialization separately)
  2. Fit GP models to current data
  3. Optimize CEI acquisition to select next point
  4. Evaluate f(x_t+1) and c(x_t+1)
  5. Update GPs and incumbent; repeat until budget exhausted
- Design tradeoffs:
  - Kernel choice: SE kernel gives faster theoretical rates O(t^(-1/2) log^((d+1)/2)(t)) but assumes infinite smoothness; Matérn with lower ν is more robust to rougher functions but slower rates
  - Initial feasible sample: CEI requires at least one feasible point to start; may need separate feasibility search phase
  - Constraint tolerance (λ > 0): Relaxing feasibility can reduce the 1/Φ(-B_c) penalty but yields ε-optimal feasible solutions
- Failure signatures:
  - No feasible samples after many iterations: GP constraint model may be inaccurate; consider explicit feasibility search
  - Simple regret plateaus: May indicate poor kernel hyperparameter estimation or getting stuck in local feasible regions
  - Acquisition optimization fails to find improving points: CEI surface may be flat; check GP variance and consider exploration boosts
- First 3 experiments:
  1. Validate on synthetic RKHS/GP problems (as in Section 4.1) with known optimum; plot log(regret) vs. log(iterations) to verify sublinear convergence slope
  2. Test sensitivity to constraint norm B_c by scaling constraint function; observe impact on convergence speed
  3. Compare SE vs. Matérn (ν=2.5) kernels on a problem with known smoothness; verify that SE achieves faster convergence on smooth functions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can rigorous simple regret bounds be established for Constrained Expected Improvement (CEI) in settings with noisy objective and constraint observations?
- Basis: [explicit] Remark 3.14 states that extending the analysis to the noisy setting is "non-trivial" due to the ambiguity of defining feasible samples and the incumbent $f^+_t$ when only noisy observations are available.
- Why unresolved: The current proof relies on deterministic evaluations to define feasibility ($c(x) \leq 0$) and the best feasible value ($f^+_t$); noise requires modifying the algorithm to handle uncertainty in these definitions, and the theoretical framework for noisy simple regret in constrained settings remains undeveloped.
- What evidence would resolve it: A derivation of convergence rates for a noise-adapted CEI algorithm (e.g., using "Noisy EI") that defines regret based on the best observed noisy value or posterior mean.

### Open Question 2
- Question: Can the convergence rates for noise-free CEI be further improved by resolving open problems regarding regret bounds in noise-free kernel-based bandits?
- Basis: [explicit] Remark 3.8 notes that "As the open question raised in Vakili [2022] gets answered, further improvement of the convergence rates is possible," specifically referring to regret bounds for noise-free settings.
- Why unresolved: The current analysis relies on maximum information gain bounds (Lemma A.5) which may be conservative for the noise-free case; tighter bounds on posterior variance reduction in noise-free kernel bandits could lead to faster proven rates.
- What evidence would resolve it: A proof showing CEI convergence rates strictly faster than $\mathcal{O}(t^{-1/2} \log^{(d+1)/2}(t))$ (for SE kernels) by utilizing tighter noise-free information gain bounds.

### Open Question 3
- Question: What are the theoretical convergence guarantees for CEI when the optimization process must start with infeasible initial samples?
- Basis: [explicit] Remark 3.15 highlights that "CEI requires initial feasible sample" and that current heuristics revert to standard CEI only "once feasibility is established," leaving the initial feasibility search theoretically unproven.
- Why unresolved: The definition of simple regret ($r_t = f^+_t - f(x^*)$) and the acquisition function rely on the existence of a feasible incumbent $f^+_t$; if $f^+_t$ does not exist, the algorithm enters a feasibility search mode not covered by the current theorems.
- What evidence would resolve it: A convergence analysis covering a "two-phase" algorithm that includes theoretical guarantees on the probability and rate of finding the first feasible sample before convergence to the optimum.

## Limitations

- Theoretical analysis assumes noise-free evaluations, limiting practical applicability to real-world noisy settings
- Requires at least one initial feasible sample, with no theoretical guarantees for the feasibility search phase when starting with infeasible points
- The multiplicative penalty 1/Φ(-B_c) in regret bounds can become prohibitive for complex constraint functions with large RKHS norms
- Limited empirical validation on real-world benchmark problems and comparison to other constrained BO methods

## Confidence

- Theoretical convergence rates (High): The proof structure follows established information-theoretic techniques for GP optimization, with careful handling of the CEI acquisition's product structure
- Experimental validation (Medium): Synthetic experiments support the theoretical predictions, but the limited scope of benchmark problems and lack of comparison to other constrained BO methods reduce confidence in practical superiority claims
- Practical implications (Low): The paper establishes rates but doesn't deeply explore practical deployment considerations like hyperparameter tuning, noisy evaluations, or alternative initialization strategies

## Next Checks

1. **Hyperparameter sensitivity**: Systematically vary length scale and kernel parameters to test how sensitive the theoretical rates are to misspecification; compare achieved rates vs predicted rates

2. **Noisy evaluation robustness**: Extend the theoretical framework to handle noisy constraint evaluations (σ²>0); derive modified convergence rates and validate experimentally

3. **Alternative initialization strategies**: Compare the "feasibility search" heuristic against alternative approaches (e.g., random restarts, constraint-focused initial design) to assess impact on convergence speed and success rate