---
ver: rpa2
title: Scaling laws for activation steering with Llama 2 models and refusal mechanisms
arxiv_id: '2507.11771'
source_url: https://arxiv.org/abs/2507.11771
tags:
- steering
- activation
- refusal
- arxiv
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how the effectiveness of activation steering
  techniques scales with model size, specifically using Llama 2 models (7B, 13B, 70B).
  It applies contrastive activation addition (CAA) to steer refusal behavior by injecting
  learned steering vectors into residual streams at various layers.
---

# Scaling laws for activation steering with Llama 2 models and refusal mechanisms

## Quick Facts
- arXiv ID: 2507.11771
- Source URL: https://arxiv.org/abs/2507.11771
- Authors: Sheikh Abdur Raheem Ali; Justin Xu; Ivory Yang; Jasmine Xinze Li; Ayse Arslan; Clark Benham
- Reference count: 6
- Key outcome: CAA effectiveness diminishes exponentially with model size (y = 0.081 + 2.4·e^(-0.42·x)), most effective at early-mid layers (~0.4 × total layers), with negative steering (toward non-refusal) being 2-3× more potent than positive across all scales.

## Executive Summary
This paper investigates how Contrastive Activation Addition (CAA) effectiveness scales with Llama 2 model sizes (7B, 13B, 70B) for steering refusal behavior. The method extracts steering vectors by contrasting activations from refusal vs. non-refusal responses and injecting them into residual streams at various layers. Results show that steering effectiveness drops exponentially with model size and peaks at approximately 40% of total layers. The study reveals that negative steering (toward less refusal) is consistently more potent than positive steering, potentially due to RLHF training dynamics pushing models toward maximum refusal.

## Method Summary
CAA works by computing the difference between residual stream activations from contrasting example pairs (refusal vs. non-refusal), averaging these directions across examples, and normalizing them. During inference, the steering vector is injected at a single layer before the add & normalize step. The paper sweeps injection across all layers and compares effectiveness across three Llama 2 sizes. Effectiveness is measured by percentage change in correct refusal behavior on a test set. Steering vectors are normalized to the mean dataset norm, though the exact scaling coefficient used during injection is unspecified.

## Key Results
- CAA effectiveness follows exponential decay with model size: y = 0.081 + 2.4·e^(-0.42·x), where x is parameter count
- Steering is most effective at early-mid layers (~0.4 × total layer count), suggesting feature convergence at this depth
- Negative steering (toward non-refusal) is 2-3× more potent than positive steering across all model sizes
- Larger models "drown out" steering signals due to more downstream computation diluting the injected vector

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Direction Extraction
CAA extracts semantically meaningful directions by computing the difference between positive and negative example activations. This isolates behavioral features like "refusal" as approximately linear directions in activation space. The method assumes these features can be isolated via contrastive subtraction, though this may fail if features are highly distributed or non-linearly encoded.

### Mechanism 2: Mid-Layer Feature Convergence
Steering effectiveness peaks at early-mid layers (~0.4 × total layers) where behavioral features are uniquely represented and most orthogonal before being diluted by downstream computation. This heuristic assumes mid-layers serve as a convergence point for feature formation, though different behaviors may have peak layers far from this constant.

### Mechanism 3: Scale-Dependent Signal Dilution
The steering vector's fixed magnitude becomes increasingly diluted in larger models due to more downstream layers reducing its relative influence on final outputs. This assumes signal-to-noise ratio decreases with model depth and parameter count, though if larger models distribute features more orthogonally (superposition), steering could become more precise with scale.

## Foundational Learning

- **Concept: Residual Stream**
  - Why needed here: CAA directly manipulates the residual stream; understanding its additive, accumulative nature is essential for debugging injection effects.
  - Quick check question: Why does the residual stream at layer N contain information from all previous layers in a transformer?

- **Concept: Contrastive Pairs for Feature Extraction**
  - Why needed here: The method relies on computing differences between positive/negative example activations to isolate behavioral directions.
  - Quick check question: Why would subtracting a "non-refusal" activation from a "refusal" activation yield a direction that promotes refusal?

- **Concept: RLHF Training Dynamics**
  - Why needed here: The paper hypothesizes that RLHF pushes models toward "maximum refusal," creating asymmetry in steering effectiveness (negative steering more potent).
  - Quick check question: Why might a safety-tuned model have more "room" to be steered toward less refusal than more refusal?

## Architecture Onboarding

- **Component map:** Forward pass cache -> Steering vector computation -> Injection point -> Evaluation
- **Critical path:** 1) Assemble contrastive dataset (refusal vs. non-refusal prompts) 2) Run forward passes, cache last-token residual stream at every layer 3) Compute direction vectors per layer (refusal − non-refusal) 4) Average across examples and normalize to mean dataset norm 5) During inference, inject steering vector at one layer; sweep all layers
- **Design tradeoffs:** Injection layer (early-mid layers ~0.4× most effective; later layers dilute signal), steering magnitude (too high degrades capabilities; too low yields no effect), single vs. multi-layer injection (paper tests single-layer only), positive vs. negative steering (negative consistently more potent)
- **Failure signatures:** Exponential effectiveness decay with model size (70B << 13B << 7B), positive steering weak or negligible across all scales, wrong-layer injection produces minimal or opposite effects
- **First 3 experiments:** 1) Layer sweep: Inject steering vector at each layer individually; plot effectiveness vs. layer to confirm ~0.4× peak 2) Scale comparison: Apply identical steering vectors to 7B, 13B, 70B; verify exponential decay (y = 0.081 + 2.4·e^(-0.42·x)) 3) Direction asymmetry test: Compare positive (more refusal) vs. negative (less refusal) steering magnitude; confirm negative is 2-3× more potent

## Open Questions the Paper Calls Out

### Open Question 1
Does the asymmetry between positive and negative steering effectiveness generalize beyond refusal behaviors to other RLHF-trained behaviors? The study only tested refusal behavior, and the proposed RLHF explanation remains a hypothesis without evidence from other behavioral domains. Replicating the steering experiments across diverse behaviors (e.g., helpfulness, honesty, sycophancy) in RLHF-trained models would test whether the asymmetry is specific to refusal or general to RLHF-shaped behaviors.

### Open Question 2
Can multi-layer injection or scaled-up steering vectors recover effectiveness in larger models without degrading capabilities? The paper shows exponential decay in steering effectiveness with model size but does not test compensatory strategies. Systematic experiments varying steering vector magnitudes and injection layers (single vs. multi-layer) in 70B+ models, with capability benchmarks to assess collateral degradation, would address this.

### Open Question 3
Do different feature categories exhibit systematically different optimal steering layers, and does layer-feature mapping become more fine-grained in larger models? Only refusal behavior was tested, and the superposition hypothesis suggests larger models may distribute features more distinctly across layers. Layer-wise steering sweeps across multiple behavioral categories (e.g., sentiment, factual accuracy, toxicity) comparing optimal layers across model sizes would resolve this.

## Limitations
- Dataset dependence: Results hinge on the refusal dataset composition and quality, with exact specifications not provided
- Single-layer constraint: Experiments only test injection at one layer at a time, leaving multi-layer strategies unexplored
- Limited parameter range: Exponential decay model is fitted to only three model sizes, limiting extrapolation reliability

## Confidence
- **High confidence**: Mechanism 1 (contrastive direction extraction) and basic CAA procedure are well-grounded in established activation steering literature
- **Medium confidence**: The 0.4× layer heuristic (Mechanism 2) is empirically supported but lacks strong theoretical justification
- **Medium confidence**: The exponential scaling law (Mechanism 3) is supported by the data but based on limited parameter range
- **Low confidence**: The RLHF-induced asymmetry hypothesis (negative steering more potent) is plausible but not empirically validated

## Next Checks
1. **Dataset ablation**: Reproduce steering results using alternative refusal datasets to test robustness and identify potential dataset-specific artifacts
2. **Multi-layer injection sweep**: Extend experiments to test combined steering across multiple layers and compare effectiveness against single-layer injection
3. **Cross-behavior steering**: Apply CAA to steer non-refusal behaviors (e.g., sentiment, topic) and verify whether the 0.4× layer heuristic and scale decay law generalize beyond safety alignment