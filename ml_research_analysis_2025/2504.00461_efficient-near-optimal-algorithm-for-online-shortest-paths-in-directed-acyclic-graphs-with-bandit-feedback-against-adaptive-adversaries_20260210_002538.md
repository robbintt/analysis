---
ver: rpa2
title: Efficient Near-Optimal Algorithm for Online Shortest Paths in Directed Acyclic
  Graphs with Bandit Feedback Against Adaptive Adversaries
arxiv_id: '2504.00461'
source_url: https://arxiv.org/abs/2504.00461
tags:
- path
- regret
- algorithm
- where
- rrbracket
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the online shortest path problem in directed
  acyclic graphs (DAGs) under bandit feedback against adaptive adversaries. The authors
  propose the first computationally efficient algorithm achieving a high-probability
  regret bound of $\tilde O(\sqrt{|E|T\log |X|})$ against any adaptive adversary,
  where $\tilde O(\cdot)$ hides logarithmic factors in the number of edges $|E|$.
---

# Efficient Near-Optimal Algorithm for Online Shortest Paths in Directed Acyclic Graphs with Bandit Feedback Against Adaptive Adversaries

## Quick Facts
- **arXiv ID**: 2504.00461
- **Source URL**: https://arxiv.org/abs/2504.00461
- **Reference count**: 40
- **Primary result**: First computationally efficient algorithm achieving high-probability regret Õ(√|E|T log|X|) against adaptive adversaries in online shortest path problem

## Executive Summary
This paper presents the first computationally efficient algorithm for online shortest paths in directed acyclic graphs (DAGs) with bandit feedback against adaptive adversaries. The algorithm achieves a high-probability regret bound of Õ(√|E|T log|X|) without the typical √|V| factor that appears in prior work. The key technical innovations include a novel importance-sampling-inspired loss estimator with implicit exploration, a centroid-based graph decomposition that reduces path length to O(log|X|), and a relatively unbiased loss difference estimator that enables optimization over the flow polytope.

## Method Summary
The algorithm operates in three main stages: First, it transforms the input DAG G into a compressed DAG G† using centroid-based decomposition, reducing the longest path length from O(|V|) to O(log|X|). Second, it applies Follow-the-Regularized-Leader (FTRL) with a Tsallis-1/2 entropy regularizer over the flow polytope of G† to compute edge flow probabilities. Third, it samples paths according to these probabilities and uses a biased loss estimator with implicit exploration to construct loss estimates for the FTRL update. The algorithm achieves high-probability regret bounds against adaptive adversaries by carefully controlling the variance of loss estimates while maintaining relative unbiasedness for loss differences between paths.

## Key Results
- Achieves high-probability regret bound of Õ(√|E|T log|X|) against adaptive adversaries
- Removes the √|V| factor that appears in all prior efficient algorithms for this problem
- Successfully extends to other combinatorial domains including spanning trees, perfect matchings, and m-sets with improved bounds
- Provides the first efficient algorithm matching the minimax lower bound for DAGs up to logarithmic factors

## Why This Works (Mechanism)

### Mechanism 1: Implicit Exploration via Biased Loss Estimator
Instead of mixing uniform distribution into strategy (EXP3.P), uses biased loss estimator $\hat{y}_t$ with small bias term $\gamma$ in denominator. This effectively "explores" implicitly while keeping variance bounded. Break condition: if $\gamma$ is too low, variance explodes; if too high, bias dominates regret.

### Mechanism 2: Centroid-Based Graph Decomposition (Compression)
Transforms input DAG $G$ into compressed DAG $G^\dagger$ by identifying spanning tree, performing centroid decomposition, and adding shortcut edges. Reduces longest path from O(|V|) to O(log|X|). Break condition: fails if graph contains cycles.

### Mechanism 3: Relatively Unbiased Loss Differences
Constructs extended path representation and estimator $\tilde{y}_t$ such that $E_t[\langle x_1 - x_2, \tilde{y}_t \rangle] = \langle x_1 - x_2, y_t \rangle$. Enables optimization using estimator that's not unbiased for absolute loss but is for differences. Break condition: variable path lengths without auxiliary bit correction bias results.

## Foundational Learning

- **Bandit Feedback vs. Full Information**: Learner only observes loss of chosen path, not all edge weights. Why needed: Understanding information gap explains why importance sampling and high-probability bounds are difficult. Quick check: If you knew weight of every edge after every round, would bandit analysis still be necessary?

- **Follow-the-Regularized-Leader (FTRL)**: Uses FTRL with Tsallis entropy regularizer instead of standard Exponential Weights. Why needed: Framework dictates how strategy $\tilde{x}_t$ updates based on cumulative estimated losses. Quick check: What role does regularizer $F(x)$ play in preventing strategy from collapsing to single edge too quickly?

- **Regret Minimization**: Objective is to minimize difference between learner's loss and best fixed path in hindsight. Why needed: Distinguishes adversarial setting from simple loss minimization. Quick check: Why is "pseudo-regret" often easier to bound than "high-probability regret"?

## Architecture Onboarding

- **Component map**: Graph Transformer -> Flow Optimizer -> Sampler -> Estimator
- **Critical path**: Efficiency hinges on Flow Optimizer. Paper asserts convex hull of path set $\text{co}(X^\dagger)$ can be represented by polynomial linear constraints, allowing standard convex optimization solvers to compute $\tilde{x}_t$ efficiently.
- **Design tradeoffs**: Regret vs. Graph Size (centroid decomposition adds overhead but reduces path length); Probabilistic vs. Deterministic (sampling introduces variance requiring careful control).
- **Failure signatures**: Numerical Instability (square-root operations on small probabilities); Constraint Violation (optimizer returns point outside flow polytope).
- **First 3 experiments**: 1) Unit Test Graph Transformation (verify G→G† conversion on simple layered graph); 2) Optimizer Integration (test FTRL solver on static DAG, ensure flow conservation); 3) Adversarial Stress Test (run full loop against adaptive adversary, verify regret scales as √T).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the proposed approach be generalized to achieve high-probability regret bounds for any combinatorial set in $\{0, 1\}^d$?
- **Basis in paper**: Conclusion asks if approach can be generalized beyond DAGs to any combinatorial set.
- **Why unresolved**: Algorithm relies heavily on DAG structure and flow polytopes which may not directly translate to arbitrary combinatorial sets.
- **What evidence would resolve it**: Algorithm achieving $\tilde{O}(\sqrt{dT\log|X|})$ regret on combinatorial sets that cannot be reduced to DAGs.

### Open Question 2
- **Question**: Does an efficient algorithm exist that achieves a minimax-optimal regret bound of $O(\sqrt{dT\log|X|})$ for any combinatorial set $X \subseteq \{0, 1\}^d$?
- **Basis in paper**: Conclusion explicitly asks for efficient algorithm with minimax-optimal regret for any combinatorial set.
- **Why unresolved**: While efficient algorithms exist for specific sets (like DAGs), general efficient solution matching minimax lower bound is unknown.
- **What evidence would resolve it**: Polynomial-time algorithm proven to achieve minimax bound across all combinatorial subsets of $\{0, 1\}^d$.

### Open Question 3
- **Question**: What are the tight upper and lower bounds on regret relative to a fixed combinatorial set $X$?
- **Basis in paper**: Conclusion asks for tight upper and lower bounds relative to specific sets $X$.
- **Why unresolved**: Minimax lower bounds are often general, and upper bounds may still have logarithmic gaps or depend on parameters rather than specific geometry of $X$.
- **What evidence would resolve it**: Deriving matching upper and lower regret bounds for specific domains that remove polylogarithmic factors present in current results.

## Limitations
- Computational complexity of centroid-based decomposition step not fully specified in implementation details
- Numerical stability concerns when dealing with very small probabilities in FTRL step with square-root operations
- Extension to non-DAG combinatorial structures requires separate analysis and may not directly benefit from current approach

## Confidence

- **High Confidence**: Theoretical regret bound Õ(√|E|T log|X|) is well-supported with clear proofs for implicit exploration and centroid decomposition
- **Medium Confidence**: Extension to other combinatorial domains is plausible but requires separate verification for specific regret bounds
- **Low Confidence**: Computational efficiency of centroid-based decomposition in practice for large complex DAGs not fully demonstrated

## Next Checks

1. **Numerical Stability Test**: Implement algorithm on large-scale DAG with many nodes/edges, measure numerical precision errors when probabilities approach zero, compare performance with/without epsilon-smoothing.

2. **Centroid Decomposition Runtime**: Benchmark runtime of centroid-based decomposition on graphs with varying depth/width, measure overhead and verify polynomial scaling with |V| and |E|.

3. **Adversarial Robustness**: Design adaptive adversary targeting implicit exploration mechanism, run algorithm for large number of rounds, verify high-probability regret bound holds across multiple trials with different random seeds.