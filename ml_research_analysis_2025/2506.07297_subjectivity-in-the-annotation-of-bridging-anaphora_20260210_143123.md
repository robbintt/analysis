---
ver: rpa2
title: Subjectivity in the Annotation of Bridging Anaphora
arxiv_id: '2506.07297'
source_url: https://arxiv.org/abs/2506.07297
tags:
- bridging
- annotation
- entity
- anaphor
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explores subjectivity in bridging anaphora annotation
  through an annotation pilot on the GUM corpus. Three decision points are examined:
  anaphor recognition, antecedent resolution, and bridging subtype selection.'
---

# Subjectivity in the Annotation of Bridging Anaphora
## Quick Facts
- arXiv ID: 2506.07297
- Source URL: https://arxiv.org/abs/2506.07297
- Authors: Lauren Levine; Amir Zeldes
- Reference count: 14
- Primary result: Bridging anaphora annotation shows moderate agreement (κ = 0.58) but high subjectivity in anaphor recognition (F1 = 0.38)

## Executive Summary
This study investigates subjectivity in bridging anaphora annotation through a pilot project on the GUM corpus. The research examines three critical decision points in the annotation process: recognizing bridging anaphors, resolving antecedents, and selecting bridging subtypes. Using an information status-informed approach, annotators identified bridging instances and classified them into 11 subtypes across three relation types plus an OTHER category. The pilot nearly doubled the number of bridging annotations compared to the original GUM corpus, suggesting previous under-annotation. The findings reveal that subjectivity in bridging annotation stems from varying world knowledge, ambiguous entity interpretation, and multiple plausible subtype assignments.

## Method Summary
The annotation pilot employed two annotators who first identified bridging anaphors using an information status-informed approach, then resolved antecedents and classified instances into 11 subtypes under three relation types (COMPARISON, ENTITY, SET) plus OTHER. The process involved resolving disagreements between annotators and analyzing agreement metrics including Cohen's kappa for subtype selection and F1 scores for anaphor recognition. The study produced 401 bridging annotations, nearly doubling the original GUM corpus count, and conducted qualitative analysis of subjective interpretation patterns.

## Key Results
- Moderate agreement on bridging subtype selection (Cohen's κ = 0.58)
- 72% accuracy in antecedent resolution between annotators
- Low overlap in anaphor recognition (F1 = 0.38) indicating high subjectivity
- Nearly doubled bridging annotations compared to original GUM corpus (401 vs 162)

## Why This Works (Mechanism)
Bridging anaphora annotation requires complex inferential reasoning where annotators must recognize implicit semantic relationships between discourse entities. The mechanism works by leveraging world knowledge to connect mentions that are not coreferential but maintain meaningful discourse relationships. Subjectivity emerges when different annotators draw on different knowledge bases or interpret entity accessibility differently, leading to inconsistent recognition and classification decisions.

## Foundational Learning
- Bridging anaphora concept - why needed: Core phenomenon being studied; quick check: Can identify non-coreferential but related entity mentions
- Information status theory - why needed: Framework for anaphor recognition; quick check: Understands how entities become accessible in discourse
- Cohen's kappa metric - why needed: Measures inter-annotator agreement; quick check: Can calculate and interpret agreement statistics
- Entity resolution - why needed: Critical for antecedent identification; quick check: Can correctly match anaphors to their antecedents
- Subtype classification - why needed: Enables detailed analysis of bridging relations; quick check: Can categorize relations into appropriate types

## Architecture Onboarding
- Component map: Text corpus -> Information status filtering -> Anaphor identification -> Antecedent resolution -> Subtype classification -> Agreement analysis
- Critical path: Anaphor recognition (most subjective) -> Antecedent resolution -> Subtype selection
- Design tradeoffs: Precision vs recall in anaphor identification, depth of subtype granularity vs annotation complexity
- Failure signatures: Low F1 scores indicate inconsistent recognition criteria; kappa values below 0.4 suggest problematic definitions
- First experiments: 1) Annotate 50 sentences for anaphor recognition only; 2) Resolve antecedents for 30 bridging cases; 3) Classify 20 instances into subtypes to test criteria clarity

## Open Questions the Paper Calls Out
None

## Limitations
- Limited annotator pool may not capture full spectrum of subjective interpretation
- Confidence in under-annotation claims is medium due to lack of direct comparison with original methodology
- Qualitative analysis based on limited examples needs systematic examination across genres

## Confidence
- Agreement metrics reliability: Medium (based on two annotators)
- Under-annotation claim: Medium (methodology comparison unclear)
- Subjectivity findings: Medium (limited annotator sample)

## Next Checks
1. Replicate the annotation pilot with a larger pool of annotators to better assess the reliability of agreement metrics and identify consistent patterns of subjectivity
2. Compare the current annotation criteria with the original GUM methodology to determine whether the annotation increase reflects genuine under-annotation or definitional differences
3. Test the proposed concrete criteria and priority hierarchies for bridging subtype selection in a separate corpus to evaluate their effectiveness in reducing subjectivity