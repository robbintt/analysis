---
ver: rpa2
title: 'SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability'
arxiv_id: '2601.10455'
source_url: https://arxiv.org/abs/2601.10455
tags:
- planning
- surgical
- phase
- procedural
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies a critical mismatch between current surgical
  planning evaluation protocols and the goal-oriented, multi-path nature of real surgical
  procedures. It proposes a meta-evaluation framework based on phase-goal satisfiability,
  using expert-defined surgical rules to determine whether a step sequence can plausibly
  complete a target phase.
---

# SurgGoal: Rethinking Surgical Planning Evaluation via Goal-Satisfiability

## Quick Facts
- **arXiv ID:** 2601.10455
- **Source URL:** https://arxiv.org/abs/2601.10455
- **Reference count:** 8
- **Primary result:** Traditional surgical planning metrics misjudge plan quality; goal-satisfiability evaluation via expert rules reveals systematic failures in both similarity metrics and LLM-based judges.

## Executive Summary
This paper identifies a critical mismatch between current surgical planning evaluation protocols and the goal-oriented, multi-path nature of real surgical procedures. It proposes a meta-evaluation framework based on phase-goal satisfiability, using expert-defined surgical rules to determine whether a step sequence can plausibly complete a target phase. A meta-evaluation benchmark is constructed with valid procedural variations and systematically invalid plans to assess whether existing metrics align with goal-satisfiability. The study finds that traditional sequence similarity metrics systematically misjudge planning quality, penalizing valid plans and failing to identify invalid ones, while LLM-based judges prioritize semantic completeness over procedural dependencies. A rule-based checker metric is adopted as a high-precision reference to evaluate Video-LLMs across progressively constrained settings, revealing failures due to perception errors and under-constrained reasoning. Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints.

## Method Summary
The paper introduces a meta-evaluation framework for surgical planning that defines correctness via phase-goal satisfiability rather than sequence similarity. Expert-defined surgical rules encode hierarchical phase-step relations, required step sets, allowed step sets, procedural dependencies, and prohibitive orderings. A candidate sequence is validated against these constraints rather than compared to a single reference trajectory. The framework is tested on MultiBypass140, a dataset of 140 laparoscopic Roux-en-Y gastric bypass videos with 11 phases and 45 steps. Zero-shot Video-LLM evaluation is conducted across three progressive tasks: end-to-end planning from video, planning with explicit current step, and knowledge injection (structural/semantic/combined). The rule-based checker provides binary goal-satisfiability accuracy as the primary metric.

## Key Results
- Traditional sequence similarity metrics (NED, JIS, ROA) systematically misjudge planning quality—penalizing valid plans and failing to identify invalid ones
- Structural knowledge injection consistently improves performance across model sizes; semantic guidance alone only helps 32B models when combined with structural constraints
- Perception errors (step recognition accuracy 39.4% for strongest model) are primary bottlenecks in end-to-end planning
- Rule-based evaluation achieves perfect accuracy on meta-evaluation benchmark but requires substantial expert effort to construct

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Rule-based goal-satisfiability checking provides a high-precision reference for evaluating whether surgical plans can plausibly complete a target phase.
- **Mechanism:** Expert-defined surgical rules encode hierarchical phase-step relations, required step sets, allowed step sets, procedural dependencies, and prohibitive orderings. A candidate sequence is validated against these constraints rather than compared to a single reference trajectory.
- **Core assumption:** Surgical correctness is defined by dependency preservation rather than exact sequence identity, and expert rules can conservatively identify definitively invalid plans.
- **Evidence anchors:**
  - [abstract]: "we define planning correctness via phase-goal satisfiability, where plan validity is determined by expert-defined surgical rules"
  - [Section 3.1]: Rules include required steps set, allowed steps set, procedural dependencies, and prohibitive orderings; "50 expert-defined procedural dependencies and prohibitions"
  - [corpus]: SAP-Bench (arXiv:2506.07196) similarly addresses surgical action planning evaluation but does not use rule-based goal-satisfiability; limited corpus support for this specific mechanism.
- **Break condition:** Rule construction does not scale to new procedures or institutions without substantial expert effort; rules may not capture all valid clinical variations.

### Mechanism 2
- **Claim:** Structural knowledge injection (explicit phase-step hierarchy) constrains the planning space more effectively than semantic descriptions alone.
- **Mechanism:** Providing the hierarchical relationship between phases and steps directly narrows the space of admissible plans, reducing cross-phase intrusions and ensuring phase-level requirements are satisfied.
- **Core assumption:** Models can follow explicit structural constraints when provided, and these constraints are more actionable than natural language descriptions.
- **Evidence anchors:**
  - [abstract]: "Structural knowledge consistently improves performance, whereas semantic guidance alone is unreliable and benefits larger models only when combined with structural constraints"
  - [Section 5.5.3]: "For most models, structural knowledge (Task 3.1) is the most effective intervention... leads to large and consistent gains over Task 2"
  - [corpus]: MMPlanner (arXiv:2509.21662) uses chain-of-thought object state reasoning for procedural planning; Web-CogReasoner (arXiv:2508.01858) emphasizes knowledge-induced reasoning—both support knowledge-injected planning but in non-surgical domains.
- **Break condition:** Small models (7B-scale) struggle to combine structural and semantic guidance; combined knowledge underperforms structural-only for these models.

### Mechanism 3
- **Claim:** End-to-end surgical planning from video is constrained primarily by perception errors rather than reasoning limitations.
- **Mechanism:** Video-LLMs misclassify exploratory segments as procedural steps and fail to recognize repeated steps within phases. These perception errors propagate to downstream planning, causing incorrect phase status estimation.
- **Core assumption:** Step recognition accuracy is a prerequisite for coherent planning; models have stronger language backbones than video understanding capabilities.
- **Evidence anchors:**
  - [abstract]: "revealing failures due to perception errors and under-constrained reasoning"
  - [Section 5.5.1]: "even the strongest model... achieves only 39.4% step recognition accuracy"; two dominant failure modes: "confusing exploration with procedural steps" and "failing to recognize repeated steps"
  - [corpus]: SurgVidLM (arXiv:2506.17873) addresses multi-grained surgical video understanding; LabUtopia (arXiv:2505.22634) notes high perception demands in laboratory settings—consistent with perception-as-bottleneck finding.
- **Break condition:** When current step is provided explicitly (Task 2), performance improves but still saturates below 52% for current-phase completion, indicating reasoning also has limitations.

## Foundational Learning

- **Concept: Hierarchical surgical workflow structure (phases → steps → actions)**
  - Why needed here: The paper's entire framework depends on understanding that phases are strategic sub-goals, steps are tactical plans, and actions are execution primitives. Without this, goal-satisfiability evaluation makes little sense.
  - Quick check question: Can you explain why a stapling action during "gastric pouch creation" is valid but the same action during "abdominal closure" would be questionable?

- **Concept: Sequence similarity metrics (edit distance, Jaccard, relative order accuracy)**
  - Why needed here: The paper critiques these metrics for penalizing valid variations and rewarding invalid ones. Understanding their formulations is necessary to grasp the "similarity trap."
  - Quick check question: Why would Jaccard similarity penalize a clinically valid plan that includes an additional hemostasis step not in the reference?

- **Concept: Goal-oriented vs. transition-based planning**
  - Why needed here: The paper reframes surgical planning from "predict what comes next" to "does this sequence accomplish the phase goal under constraints."
  - Quick check question: If a model predicts the next action correctly but the full sequence violates a procedural dependency, is this a goal-satisfiable plan?

## Architecture Onboarding

- **Component map:** Video clips + current phase label + step history + candidate step labels -> Video-LLM backbone (VideoLLaMA3, LLaVA-NeXT-Video, Qwen2.5-VL, Hulu-Med, Lingshu) -> Knowledge injection module (structural/semantic/combined) -> JSON output parser -> Rule-based goal-satisfiability checker

- **Critical path:** Perception (step recognition from video) -> State estimation (current procedural state) -> Planning (generate remaining steps) -> Validation (rule-based goal satisfiability check)

- **Design tradeoffs:**
  - Rule-based evaluation: High precision, perfect accuracy on benchmark, but unscalable to new procedures
  - LLM-based judges: Flexible, capture semantic completeness, but fail on procedural dependencies (order errors)
  - Structural vs. semantic knowledge: Structural works across model sizes; semantic only helps larger models (32B) when combined with structural constraints

- **Failure signatures:**
  - Perception errors: Confusing tissue exploration with procedural steps; miscounting repeated stapling/hemostasis steps
  - Under-constrained reasoning: Mixing steps from different phases (e.g., omentum division steps with gastrojejunal anastomosis steps)
  - Small model overload: 7B models perform worse with combined structural + semantic knowledge than structural alone

- **First 3 experiments:**
  1. Reproduce meta-evaluation of sequence similarity metrics on the constructed benchmark to verify the "similarity trap"—expect NED/JIS high on invalid but poor on valid; ROA high on valid but poor on order errors.
  2. Run Video-LLM end-to-end planning (Task 1) and isolate perception vs. planning errors by comparing step recognition accuracy to downstream goal-satisfiability accuracy.
  3. Ablate knowledge injection types: compare Task 3.1 (structural only), Task 3.2 (semantic only), Task 3.3 (combined) across 7B and 32B models to verify capacity-dependent integration.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can procedural rules for goal-satisfiability be constructed automatically or semi-automatically for new surgical domains without extensive expert annotation?
- **Basis in paper:** [explicit] The authors state in Limitations: "Automated or semi-automated construction of procedural rules, potentially with LLMs assisting clinicians in formalizing surgical knowledge, remains a challenge."
- **Why unresolved:** The current rule-based evaluator relies on manually constructed rules from surgical principles and dataset-specific protocols, limiting scalability to new procedures, institutions, or surgical domains.
- **What evidence would resolve it:** Demonstrating a method that learns or extracts procedural dependencies from surgical video datasets with minimal expert intervention, validated against the rule-based reference across multiple procedures.

### Open Question 2
- **Question:** How can evaluation capture finer-grained planning quality aspects—such as efficiency, redundancy, and preference among valid paths—without reverting to single-trajectory assumptions?
- **Basis in paper:** [explicit] The authors note: "this formulation does not capture finer-grained aspects of planning quality, such as efficiency, redundancy, or preferences among multiple valid procedural paths. Future work could explore more nuanced, goal-aware metrics."
- **Why unresolved:** The current binary goal-satisfiability criterion determines only whether a plan can plausibly complete a phase, treating all satisficing plans as equivalent.
- **What evidence would resolve it:** A metric that differentiates among valid plans based on clinically meaningful criteria (e.g., minimally invasive paths, reduced instrument switches) while preserving multi-path flexibility.

### Open Question 3
- **Question:** How can LLM-based judges be augmented to enforce strict procedural dependencies rather than prioritizing semantic completeness?
- **Basis in paper:** [explicit] The authors find that "LLM-based evaluators...utilize internal medical knowledge to recognize [missing steps]...However, most models struggle with order errors, frequently approving sequences that violate critical procedural dependencies...highlighting a systematic tendency of LLMs to prioritize semantic completeness over strict procedural ordering."
- **Why unresolved:** Current LLM judges detect content errors well but fail on order violations; no existing approach reliably combines semantic understanding with strict constraint enforcement.
- **What evidence would resolve it:** An LLM-based evaluator achieving comparable accuracy to rule-based checkers on order-error detection while maintaining semantic flexibility, tested on the meta-evaluation benchmark.

## Limitations
- Rule-based evaluation framework requires substantial expert effort to construct procedural rules for new surgical domains
- Meta-evaluation benchmark construction process lacks full transparency in how invalid sequences were systematically generated
- Study relies on zero-shot Video-LLM evaluation without fine-tuning, potentially underrepresenting model capabilities
- Evaluation focuses on laparoscopic Roux-en-Y gastric bypass only, limiting generalizability across surgical domains

## Confidence

- **High confidence:** The meta-evaluation of traditional sequence similarity metrics showing systematic misjudgment of planning quality (penalizing valid plans, failing to identify invalid ones). The finding that structural knowledge injection improves performance across model sizes. The identification of perception errors as primary bottlenecks in end-to-end planning.
- **Medium confidence:** The capacity-dependent integration finding (semantic knowledge benefits 32B models only when combined with structural constraints). The claim that LLM-based judges prioritize semantic completeness over procedural dependencies.
- **Low confidence:** The scalability claims about rule-based evaluation without fine-tuning. The generalizability across different surgical procedures and institutions.

## Next Checks

1. **Rule scalability validation:** Apply the rule-based checker to a different surgical procedure (e.g., cholecystectomy) with newly constructed expert rules to assess construction effort and effectiveness on unseen domains.

2. **Perceptual vs. reasoning decomposition:** Systematically ablate perception errors by providing ground-truth step recognition to Video-LLMs and measure the resulting improvement in goal-satisfiability accuracy to quantify the reasoning bottleneck.

3. **Cross-institutional validation:** Test the framework with surgical rules and data from a different institution or geographic region to assess sensitivity to procedural variations and institutional practices.