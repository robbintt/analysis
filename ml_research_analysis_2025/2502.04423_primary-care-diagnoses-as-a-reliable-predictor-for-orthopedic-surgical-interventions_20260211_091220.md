---
ver: rpa2
title: Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions
arxiv_id: '2502.04423'
source_url: https://arxiv.org/abs/2502.04423
tags:
- performance
- clinical
- embeddings
- care
- healthcare
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that primary care diagnostic text can effectively
  predict orthopedic procedural needs, addressing inefficiencies in referral workflows.
  Using machine learning models with Base General Embeddings (BGE), the research analyzed
  2,086 orthopedic referrals from the University of Texas Health at Tyler.
---

# Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions

## Quick Facts
- arXiv ID: 2502.04423
- Source URL: https://arxiv.org/abs/2502.04423
- Reference count: 0
- Achieved ROC-AUC of 0.874 and MCC of 0.540 for predicting orthopedic procedural needs from primary care diagnostic text

## Executive Summary
This study demonstrates that primary care diagnostic text can effectively predict orthopedic procedural needs, addressing inefficiencies in referral workflows. Using machine learning models with Base General Embeddings (BGE), the research analyzed 2,086 orthopedic referrals from the University of Texas Health at Tyler. The optimal model achieved a ROC-AUC of 0.874 and MCC of 0.540, significantly improving procedure rate predictions from 11.27% to 60.1% (433% increase). Noise tolerance experiments confirmed the robustness of BGE embeddings under real-world conditions, while threshold sensitivity analysis identified an optimal decision threshold of 0.30. These findings highlight the potential of AI-driven clinical decision support to streamline workflows, enhance referral accuracy, and improve healthcare efficiency and patient outcomes.

## Method Summary
The study employed BGE-small-en-v1.5 embeddings via SentenceTransformers to convert ICD-10-CM diagnostic text into 384-dimensional vectors. A Random Forest classifier was trained using stratified 5-fold cross-validation with SMOTE applied only to training folds to address class imbalance (11.27% procedure cases). GridSearchCV with 3-fold internal CV optimized hyperparameters including n_estimators, max_depth, min_samples_split, and min_samples_leaf. The optimal decision threshold was determined through sensitivity analysis, identifying 0.30 as the point maximizing F1 score. Performance was evaluated using ROC-AUC, MCC, PR-AUC, and accuracy metrics.

## Key Results
- Achieved ROC-AUC of 0.874 and MCC of 0.540 in predicting orthopedic procedural needs
- Optimal decision threshold identified at 0.30, improving procedure rate predictions from 11.27% to 60.1% (433% increase)
- Noise tolerance experiments confirmed BGE embeddings' robustness to real-world data variations

## Why This Works (Mechanism)
The study leverages semantic embeddings to capture clinical relationships in diagnostic text, enabling accurate prediction of procedural needs. The BGE model effectively represents medical terminology and relationships, while Random Forest handles the high-dimensional feature space well. SMOTE addresses class imbalance without overfitting, and the identified threshold optimizes the trade-off between precision and recall for clinical decision support.

## Foundational Learning
1. **ICD-10-CM Code Descriptions** - Why needed: Provides standardized medical terminology for consistent feature extraction. Quick check: Verify average word count per entry (~12 words) matches reported values.
2. **SMOTE Implementation** - Why needed: Addresses severe class imbalance (11:1 ratio) without introducing test contamination. Quick check: Confirm SMOTE applied only to training folds within cross-validation.
3. **Stratified Cross-Validation** - Why needed: Ensures representative class distribution across folds for reliable performance estimation. Quick check: Verify fold distributions maintain ~11% procedure rate in each split.
4. **ROC-AUC vs Threshold Analysis** - Why needed: Identifies optimal operating point for clinical decision support. Quick check: Plot precision-recall curves at multiple thresholds to confirm 0.30 optimality.

## Architecture Onboarding

**Component Map:** Diagnostic Text -> BGE Embeddings -> SMOTE -> Random Forest -> Threshold Optimization -> Performance Metrics

**Critical Path:** Diagnostic text encoding through BGE embeddings represents the most critical component, as embedding quality directly impacts classification performance. The threshold optimization step is equally critical for translating model outputs into clinically actionable predictions.

**Design Tradeoffs:** The study chose BGE embeddings for their balance of semantic richness and computational efficiency over more complex transformer models. Random Forest was selected over neural networks for better interpretability and reduced overfitting risk with limited data.

**Failure Signatures:** Class imbalance causing poor minority class detection manifests as high accuracy but low recall. Poor embedding quality appears as scattered feature distributions with low separation between classes. Threshold selection errors result in either excessive false positives or missed procedures.

**First 3 Experiments:**
1. Baseline model without SMOTE to quantify its impact on minority class detection
2. Hyperparameter sensitivity analysis varying n_estimators and max_depth
3. Threshold sweep from 0.1 to 0.9 to confirm 0.30 as optimal operating point

## Open Questions the Paper Calls Out
1. Will the BGE-based predictive model maintain comparable ROC-AUC and MCC performance when validated on multicenter orthopedic referral datasets with diverse demographic and geographic characteristics?
2. Does incorporating multimodal clinical data (imaging reports, laboratory results, patient histories) improve predictive accuracy beyond diagnostic text alone?
3. What are the actual clinical and financial outcomes when the model is prospectively deployed in real-world referral workflows, compared to the simulated 60.1% optimal procedure rate?
4. Can fine-tuning BGE embeddings on orthopedic-specific clinical text improve domain-specific semantic capture and predictive performance for procedural prediction?

## Limitations
- Single-institution dataset limits generalizability to other clinical settings
- Missing implementation details for HyDE enrichment process
- No prospective clinical deployment data to validate simulated improvements
- Incomplete neural network architecture details for meaningful comparison

## Confidence
- **High Confidence** in BGE embeddings + Random Forest achieving ROC-AUC of 0.874 and MCC of 0.540
- **Medium Confidence** in noise tolerance claims due to incomplete methodology details
- **Medium Confidence** in 433% improvement claim based on simulation rather than prospective validation

## Next Checks
1. Replicate the HyDE enrichment process using ICD-10-CM code descriptions and verify the average word count of ~12 words per entry through independent implementation
2. Perform ablation studies by removing SMOTE from the pipeline to quantify its contribution to the reported ROC-AUC improvement
3. Implement the optimal threshold analysis (0.30) on held-out test data to verify the 60.1% procedure rate prediction against the reported 11.27% baseline