---
ver: rpa2
title: Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation
  Learning
arxiv_id: '2512.18117'
source_url: https://arxiv.org/abs/2512.18117
tags:
- image
- transport
- primary
- views
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of multimodal representation learning
  in e-commerce, where existing vision-language models often overlook non-primary
  images and auxiliary textual views that provide critical semantics in open marketplaces.
  The authors propose a unified framework based on Factorized Transport, a lightweight
  approximation of optimal transport, to improve multimodal and multi-view learning.
---

# Factorized Transport Alignment for Multimodal and Multiview E-commerce Representation Learning

## Quick Facts
- **arXiv ID**: 2512.18117
- **Source URL**: https://arxiv.org/abs/2512.18117
- **Reference count**: 23
- **Primary result**: +7.9% Recall@500 improvement over multimodal baselines on industrial e-commerce dataset

## Executive Summary
This paper addresses a critical challenge in e-commerce representation learning: how to effectively leverage multiple images and textual views of products while maintaining computational efficiency. The authors observe that existing vision-language models often ignore non-primary images and auxiliary textual views in open marketplaces, missing important semantic information. Their solution, Factorized Transport, uses a lightweight optimal transport approximation that emphasizes primary views while stochastically sampling auxiliary ones during training. This reduces computational complexity from quadratic in the number of views to constant per item, while still achieving significant performance gains in cross-view and query-to-item retrieval tasks.

## Method Summary
The paper proposes a unified framework based on Factorized Transport, which approximates optimal transport alignment for multimodal and multi-view learning in e-commerce. The method strategically emphasizes primary product views (main image and primary description) while incorporating auxiliary views through stochastic sampling during training. This approach maintains the computational efficiency of two-tower retrieval systems by fusing all views into a single cached embedding at inference time. The factorized transport mechanism reduces the alignment complexity from O(n²) to O(n) where n is the number of views, making multi-view pretraining practical at scale. The framework is evaluated on a large industrial dataset of 1M product listings and 0.3M interactions, demonstrating consistent improvements over strong multimodal baselines.

## Key Results
- Achieves up to +7.9% Recall@500 improvement over strong multimodal baselines
- Demonstrates consistent improvements in cross-view and query-to-item retrieval tasks
- Maintains computational efficiency of two-tower retrieval through cached embeddings at inference
- Reduces complexity from quadratic in number of views to constant per item

## Why This Works (Mechanism)
The Factorized Transport framework works by approximating optimal transport alignment while strategically sampling auxiliary views during training. By emphasizing primary views (main product image and primary description) and stochastically incorporating secondary views, the model learns robust representations that capture both essential and supplementary information. The factorized approximation breaks down the complex view alignment problem into manageable components, reducing computational overhead while preserving alignment quality. At inference, the fusion of all views into a single cached embedding maintains retrieval efficiency without sacrificing the benefits of multi-view learning.

## Foundational Learning

**Optimal Transport Theory**: Understanding how to measure and align distributions between different modalities
- Why needed: Provides mathematical foundation for aligning multimodal representations
- Quick check: Verify understanding of Wasserstein distance and its computational complexity

**Multimodal Representation Learning**: Principles of combining visual and textual information in unified embeddings
- Why needed: Core requirement for e-commerce product understanding
- Quick check: Confirm knowledge of contrastive learning and cross-modal alignment

**Two-Tower Architecture**: Design pattern for efficient retrieval systems with separate query and item encoders
- Why needed: Enables scalable real-time search in production systems
- Quick check: Understand cached embeddings and their role in reducing inference latency

## Architecture Onboarding

**Component Map**: Primary Encoder -> Factorized Transport Layer -> Auxiliary View Sampler -> Fusion Layer -> Cached Embedding

**Critical Path**: During training, primary view encoding flows through the factorized transport layer, while auxiliary views are stochastically sampled and aligned. The fusion layer combines all view representations into a unified embedding that gets cached for efficient inference retrieval.

**Design Tradeoffs**: The framework trades some alignment precision (full optimal transport) for significant computational efficiency gains. Stochastic sampling of auxiliary views introduces variability but enables scalability. The decision to cache embeddings at inference prioritizes speed over dynamic view incorporation.

**Failure Signatures**: Poor performance on products with highly similar primary views but different auxiliary views; degradation when auxiliary view sampling rate is too low; potential misalignment between primary and auxiliary view representations.

**First Experiments**:
1. Baseline comparison using only primary views versus full multi-view approach
2. Ablation study varying auxiliary view sampling rate
3. Computational complexity analysis measuring inference latency with cached embeddings

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on single industrial dataset, limiting generalizability across different e-commerce domains
- Computational complexity analysis focuses only on transport alignment component, not complete system efficiency
- Stochastic sampling introduces variability without extensive characterization across random seeds

## Confidence

**High confidence**:
- +7.9% Recall@500 improvement claims based on reported experimental results
- Two-tower efficiency preservation through cached embeddings at inference
- Complexity reduction from O(n²) to O(n) for view alignment

**Medium confidence**:
- Generalizability across different e-commerce domains and product categories
- Long-term stability of embeddings with evolving product catalogs

## Next Checks

1. Conduct ablation studies isolating factorized transport impact versus other architectural choices
2. Evaluate framework performance on public e-commerce datasets (Amazon, Alibaba) to assess generalizability
3. Perform long-term stability analysis measuring embedding quality degradation over time with catalog evolution