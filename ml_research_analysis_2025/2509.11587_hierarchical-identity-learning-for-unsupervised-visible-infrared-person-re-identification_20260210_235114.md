---
ver: rpa2
title: Hierarchical Identity Learning for Unsupervised Visible-Infrared Person Re-Identification
arxiv_id: '2509.11587'
source_url: https://arxiv.org/abs/2509.11587
tags:
- learning
- person
- cluster
- features
- visible-infrared
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a hierarchical identity learning framework
  for unsupervised visible-infrared person re-identification. The method addresses
  the challenge of learning modality-invariant features from unlabeled cross-modal
  data by capturing both coarse-grained and fine-grained identity variations through
  two-stage clustering.
---

# Hierarchical Identity Learning for Unsupervised Visible-Infrared Person Re-Identification

## Quick Facts
- **arXiv ID:** 2509.11587
- **Source URL:** https://arxiv.org/abs/2509.11587
- **Authors:** Haonan Shi; Yubin Wang; De Cheng; Lingfeng He; Nannan Wang; Xinbo Gao
- **Reference count:** 40
- **Primary result:** Proposes a hierarchical identity learning framework for unsupervised visible-infrared person re-identification that achieves state-of-the-art performance on SYSU-MM01 and RegDB datasets.

## Executive Summary
This paper introduces a hierarchical identity learning framework for unsupervised visible-infrared person re-identification (VI-ReID). The method addresses the challenge of learning modality-invariant features from unlabeled cross-modal data by capturing both coarse-grained and fine-grained identity variations through a two-stage clustering approach. A Multi-Center Contrastive Learning strategy is proposed to refine representations by constructing robust positive and negative sample sets from hierarchical cluster centers, while a Bidirectional Reverse Selection Transmission mechanism ensures reliable cross-modal correspondences by filtering pseudo-label matches through bidirectional matching.

## Method Summary
The proposed framework consists of two main components: a two-stage clustering strategy for hierarchical identity learning and a multi-center contrastive learning module with bidirectional reverse selection transmission. In the first stage, coarse-grained clustering is performed separately on visible and infrared images to obtain initial pseudo-labels. The second stage refines these labels by performing fine-grained clustering within each coarse cluster to capture more detailed identity variations. The Multi-Center Contrastive Learning module constructs positive and negative sample sets from hierarchical cluster centers to enhance feature discrimination. The Bidirectional Reverse Selection Transmission mechanism filters cross-modal pseudo-label correspondences by ensuring consistency in both directions, reducing noise in the matching process.

## Key Results
- Achieves state-of-the-art performance on SYSU-MM01 and RegDB datasets
- Demonstrates significant improvements in both Rank-1 accuracy and mAP metrics compared to existing unsupervised methods
- The hierarchical clustering approach effectively captures both coarse-grained and fine-grained identity variations

## Why This Works (Mechanism)
The hierarchical identity learning framework works by progressively refining pseudo-labels through two-stage clustering, which captures identity variations at multiple granularities. The Multi-Center Contrastive Learning strategy enhances feature discrimination by leveraging hierarchical cluster centers to construct diverse positive and negative sample sets. The Bidirectional Reverse Selection Transmission mechanism ensures reliable cross-modal correspondences by filtering matches through bidirectional consistency checks, reducing the impact of noisy pseudo-labels on the learning process.

## Foundational Learning

### Clustering for Pseudo-Label Generation
- **Why needed:** Unsupervised VI-ReID lacks labeled data, requiring automatic identity assignment through clustering
- **Quick check:** Verify that clustering quality directly impacts downstream model performance

### Contrastive Learning for Feature Discrimination
- **Why needed:** Enhances the model's ability to distinguish between different identities across modalities
- **Quick check:** Measure feature similarity distributions between positive and negative pairs

### Cross-Modal Correspondence
- **Why needed:** Ensures learned features are modality-invariant for effective cross-modal matching
- **Quick check:** Evaluate retrieval performance across visible-infrared modality pairs

## Architecture Onboarding

### Component Map
Two-stage clustering -> Multi-Center Contrastive Learning -> Bidirectional Reverse Selection Transmission

### Critical Path
The critical path involves: 1) Initial clustering to generate coarse pseudo-labels, 2) Fine-grained clustering within coarse clusters, 3) Multi-center contrastive learning using hierarchical cluster information, and 4) Bidirectional reverse selection to filter cross-modal correspondences.

### Design Tradeoffs
The framework trades computational complexity for improved accuracy by maintaining multiple cluster centers and performing bidirectional matching. While this increases training time and memory requirements, it significantly reduces the impact of noisy pseudo-labels and improves cross-modal feature alignment.

### Failure Signatures
- Poor clustering quality leading to incorrect pseudo-labels
- Insufficient discrimination between fine-grained identity variations
- Noisy cross-modal correspondences propagating through the bidirectional matching process

### First Experiments to Run
1. Evaluate clustering quality metrics (purity, NMI) on both coarse and fine-grained levels
2. Measure feature similarity distributions before and after contrastive learning
3. Test cross-modal retrieval performance with and without bidirectional filtering

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on pseudo-label quality, which can be sensitive to parameter settings and may propagate errors through the two-stage clustering process
- Potential scalability issues due to computational overhead of maintaining multiple cluster centers and performing bidirectional matching
- Possible challenges with highly ambiguous cross-modal matches in scenarios with significant appearance variations or limited training samples

## Confidence

### High confidence:
- State-of-the-art performance claims on established benchmark datasets (SYSU-MM01 and RegDB)

### Medium confidence:
- The effectiveness of Multi-Center Contrastive Learning in improving feature discrimination
- The robustness of Bidirectional Reverse Selection Transmission in filtering noisy correspondences

## Next Checks
1. Test the method's performance on a third, unseen cross-modal person Re-ID dataset to verify generalizability beyond the two reported benchmarks
2. Conduct an ablation study to quantify the individual contributions of the two-stage clustering, multi-center contrastive learning, and bidirectional reverse selection components
3. Evaluate computational efficiency and memory requirements compared to baseline methods to assess practical deployment feasibility