---
ver: rpa2
title: 'Sonnet: Spectral Operator Neural Network for Multivariable Time Series Forecasting'
arxiv_id: '2505.15312'
source_url: https://arxiv.org/abs/2505.15312
tags:
- forecasting
- time
- sonnet
- attention
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sonnet introduces a novel spectral operator neural network for
  multivariable time series forecasting that captures variable dependencies through
  learnable wavelet transformations and spectral coherence. The core innovation is
  Multivariable Coherence Attention (MVCA), which leverages spectral coherence to
  model inter-variable dependencies more effectively than standard attention mechanisms.
---

# Sonnet: Spectral Operator Neural Network for Multivariable Time Series Forecasting

## Quick Facts
- **arXiv ID**: 2505.15312
- **Source URL**: https://arxiv.org/abs/2505.15312
- **Reference count**: 40
- **Primary result**: Achieved best performance on 34/47 forecasting tasks with 2.2% MAE reduction; MVCA alone reduced MAE by 10.7% when replacing naive attention

## Executive Summary
Sonnet introduces a novel spectral operator neural network for multivariable time series forecasting that captures variable dependencies through learnable wavelet transformations and spectral coherence. The core innovation is Multivariable Coherence Attention (MVCA), which leverages spectral coherence to model inter-variable dependencies more effectively than standard attention mechanisms. Sonnet also incorporates a learnable Koopman operator for stable temporal evolution. In extensive experiments across 47 forecasting tasks spanning 12 real-world datasets, Sonnet achieved the best performance on 34 tasks with an average MAE reduction of 2.2% compared to the most competitive baseline. When replacing naive attention with MVCA in existing models, MAE decreased by 10.7% on average, demonstrating the effectiveness of spectral coherence-based attention for multivariable time series forecasting.

## Method Summary
Sonnet addresses multivariable time series forecasting by predicting a single target variable using multiple exogenous variables in a rolling window setup. The architecture consists of five key components: joint embedding with α-weighted dimensions, learnable wavelet transform with K atoms, MVCA using FFT-based spectral coherence, a unitary Koopman operator via QR decomposition, and a 3-layer convolutional decoder. The model is trained with Adam optimizer using MSE loss, with max 100 epochs and early stopping at 5 epochs without improvement. Key hyperparameters include α ∈ {0, 0.1, 0.25, 0.75}, K ∈ {8, 16, 32}, embedding dimension d=64, and learning rates in the range of {0.05-2}×10^-3 with linear decay. The model operates on input sequences of length L and predicts horizons of length H, with z-score normalization applied to all datasets.

## Key Results
- Best performance on 34 out of 47 forecasting tasks across 12 datasets
- Average MAE reduction of 2.2% compared to the most competitive baseline
- MVCA alone reduced MAE by 10.7% when replacing naive attention in existing models

## Why This Works (Mechanism)
Sonnet's effectiveness stems from its ability to capture complex variable dependencies through spectral coherence. Traditional attention mechanisms struggle with multivariable time series because they cannot effectively model the frequency-domain relationships between variables. MVCA addresses this by computing spectral coherence between input and target variables in the frequency domain using FFT, which captures both phase and amplitude relationships that are missed by time-domain attention. The learnable wavelet transform provides a sparse representation that highlights important frequency components, while the Koopman operator ensures stable temporal evolution by maintaining unitary properties through QR decomposition. This combination allows Sonnet to model both cross-variable dependencies and temporal dynamics more effectively than existing approaches.

## Foundational Learning
**Wavelet Transform**: A mathematical tool that decomposes signals into different frequency components with variable resolution - needed for capturing multi-scale temporal patterns; quick check: verify output has K frequency atoms with learnable parameters
**Spectral Coherence**: Measures the linear relationship between two signals at different frequencies - needed to quantify variable dependencies in frequency domain; quick check: C_{qk} ∈ [0,1] where 0=independent and 1=perfectly correlated
**Koopman Operator**: A linear operator that describes the evolution of observables in dynamical systems - needed for stable temporal modeling in nonlinear systems; quick check: ||K||_2 ≈ 1 (unitary property) throughout training
**FFT-based Attention**: Attention mechanism operating in frequency domain using Fast Fourier Transform - needed to capture phase and amplitude relationships missed by time-domain attention; quick check: FFT output dimensions match input size with complex values
**QR Decomposition**: Matrix factorization into orthogonal Q and upper triangular R matrices - needed to enforce unitary constraint on Koopman operator; quick check: Q^T Q = I (orthogonality) after decomposition

## Architecture Onboarding
**Component map**: Input Z → Joint Embedding → Learnable Wavelet Transform → MVCA (FFT + Spectral Coherence) → Koopman Operator → Decoder → Output ŷ
**Critical path**: The MVCA module is the critical innovation - it transforms inputs into frequency domain, computes spectral coherence between all variable pairs, applies coherence-based attention weights, then transforms back to time domain
**Design tradeoffs**: The model trades computational complexity (FFT operations, K×L×d MVCA output) for improved modeling of cross-variable dependencies. The unitary Koopman operator adds stability but constrains the temporal evolution model.
**Failure signatures**: Complex number overflow in Koopman operator QR decomposition; NaN/Inf values in spectral coherence computation when power spectral densities approach zero; attention weights becoming uniform when spectral coherence fails
**First experiments**:
1. Single-task validation: Run ETTh1 with H=96, L=336, K=16, α=0.5, d=64, seed=42; expect MAE ≈ 0.2145
2. MVCA ablation test: Disable MVCA, expect MAE increase of ~6.3% on ILI/WEA datasets
3. Seed robustness: Test 5 different seeds on ILI-ENG dataset; reported standard deviation <0.07 MAE

## Open Questions the Paper Calls Out
None

## Limitations
- Exact weight initialization schemes for wavelet parameters and Koopman matrix S are unspecified, which could affect numerical stability
- Optimal dropout rate for MVCA is not reported per dataset despite being selected via grid search
- Numerical instability in complex-valued operations (Koopman operator, spectral coherence) may require additional stabilization techniques
- Computational overhead from FFT operations and K×L×d MVCA output may limit scalability to very large datasets

## Confidence
- **High confidence**: Core architectural components (joint embedding, wavelet transform, MVCA, Koopman operator, decoder) are well-specified with clear mathematical formulations
- **Medium confidence**: Overall training procedure and hyperparameter ranges are detailed, but exact optimal values and initialization schemes contain gaps
- **Low confidence**: Numerical stability of complex-valued operations and their sensitivity to initialization details

## Next Checks
1. Verify MVCA implementation by testing on synthetic data with known correlation structures, ensuring spectral coherence computation (Eq. 3) produces expected attention weights and output dimension is K×L×d
2. Test Koopman operator stability by monitoring ||K||_2 ≈ 1 across training iterations and implementing gradient clipping (threshold 1.0) or SVD-based stabilization if numerical instability occurs
3. Validate FFT-based spectral coherence robustness by checking for NaN/Inf values during division, particularly when P_{qq} or P_{kk} approach zero, and implement adaptive epsilon (10^-8 minimum) for small-amplitude inputs after normalization