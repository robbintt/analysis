---
ver: rpa2
title: 'Revisiting Expected Possession Value in Football: Introducing a Benchmark,
  U-Net Architecture, and Reward and Risk for Passes'
arxiv_id: '2502.02565'
source_url: https://arxiv.org/abs/2502.02565
tags:
- pass
- value
- data
- game
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first Expected Possession Value (EPV)
  benchmark and a new U-Net-based EPV model for football. The OJN-Pass-EPV benchmark
  provides a quantitative method to evaluate EPV models by using expert-annotated
  pairs of game states with relative values.
---

# Revisiting Expected Possession Value in Football: Introducing a Benchmark, U-Net Architecture, and Reward and Risk for Passes

## Quick Facts
- arXiv ID: 2502.02565
- Source URL: https://arxiv.org/abs/2502.02565
- Authors: Thijs Overmeer; Tim Janssen; Wim P. M. Nuijten
- Reference count: 2
- Primary Result: Introduced first EPV benchmark (78% accuracy) and U-Net model with reward/risk decomposition

## Executive Summary
This paper addresses the challenge of estimating Expected Possession Value (EPV) in football by introducing the OJN-Pass-EPV benchmark and a novel U-Net-based architecture. The benchmark provides a quantitative method to evaluate EPV models using expert-annotated pairs of game states with relative values. The authors developed a U-Net CNN architecture that incorporates ball height and splits pass value into separate reward and risk components, achieving 78% accuracy in correctly identifying higher-value states and demonstrating strong calibration performance.

## Method Summary
The approach uses a three-model architecture: a pass likelihood model (U-Net CNN) estimating destination probabilities, a pass success model estimating pass completion probability, and a pass value model estimating goal probabilities for successful and unsuccessful passes separately. All models operate on a 104×68 grid representing the football field, using tracking data at 10Hz with additional features including ball height, distance to goal, and angle to goal. The final EPV is computed by combining these probability surfaces. Training used cyclic learning rates and Adam optimizer, with temperature scaling for calibration.

## Key Results
- Achieved 78% accuracy on the OJN-Pass-EPV benchmark for correctly identifying higher-value game states
- Demonstrated well-calibrated probability outputs with low Expected Calibration Error
- Showed the model learns distinct dynamics for ground versus aerial passes when incorporating ball height
- Validated the reward/risk decomposition approach through qualitative examples showing nuanced pass value interpretation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing pass value into separate reward and risk components improves interpretability and utility for assessing passing decisions.
- Mechanism: The model computes separate probability distributions for scoring and conceding after both successful and unsuccessful passes, then combines them weighted by pass success probability. This explicitly quantifies the upside (reward) and downside (risk) of specific pass choices.
- Core assumption: Coaches and analysts can make better tactical decisions when presented with distinct probabilities of positive and negative outcomes rather than just a single net value.
- Evidence anchors: Abstract states "splitting pass value into reward and risk components"; model description shows separate probability surfaces for successful/unsuccessful passes; qualitative example demonstrates how decomposition reveals negative overall value despite pass completion.

### Mechanism 2
- Claim: Including ball height as a feature improves predictive accuracy for pass likelihood, particularly distinguishing aerial and ground passes.
- Mechanism: The model is trained with an additional input feature representing the ball's vertical position, allowing it to learn distinct dynamics associated with aerial passes (can go over opponents, headers are less precise) versus ground passes.
- Core assumption: The vertical dimension provides meaningful, learnable signal about pass outcomes not captured by 2D player/ball positions alone.
- Evidence anchors: Abstract mentions "incorporating ball height"; model description includes z-value of ball as feature; visual comparison shows model learns aerial passes can clear defenders.

### Mechanism 3
- Claim: U-Net CNN architecture with softmax output layer and categorical cross-entropy loss effectively estimates pass value probabilities while mitigating vanishing gradient problems.
- Mechanism: Authors moved from sigmoid-based linear output to softmax layer predicting three distinct probabilities (goal for, no goal, goal against), directly modeling as multi-class classification for more stable gradients.
- Core assumption: EPV value estimation can be effectively framed as image segmentation-like task where each pixel is classified into outcome probabilities, assuming spatial locality and context are paramount.
- Evidence anchors: Abstract describes "U-net-type convolutional neural networks"; training section notes vanishing gradient issues with sigmoid approach; softmax with categorical cross-entropy implemented to solve this.

## Foundational Learning

- Concept: **Expected Possession Value (EPV)**
  - Why needed here: Core metric the paper builds around, representing probability of scoring/conceding next goal from given game state.
  - Quick check question: Can you explain what a positive EPV value versus a negative EPV value means for the team in possession?

- Concept: **U-Net Architecture**
  - Why needed here: Proposed model uses this specific CNN architecture with encoder-decoder structure, skip connections, and spatial processing capabilities.
  - Quick check question: What is the purpose of the "skip connections" in a U-Net, and how does the contracting (encoder) path differ from the expansive (decoder) path?

- Concept: **Model Calibration & Expected Calibration Error (ECE)**
  - Why needed here: Paper emphasizes calibration as key evaluation metric alongside loss, requiring probabilities to be trustworthy.
  - Quick check question: If a model predicts a 70% chance of a pass being successful, what does it mean for the model to be "well-calibrated" over many such predictions?

## Architecture Onboarding

- Component map: Raw tracking data → Preprocessing (scaling, smoothing, aligning) → Tensor creation (104x68 grid) → Feature engineering (positions, velocities, distances, ball height, distance/angle to goal) → Three separate models (Pass Likelihood, Pass Success, Pass Value) → Combined inference (EPV(x,y) = S(x,y) * Value_success(x,y) + (1 - S(x,y)) * Value_unsuccess(x,y)) → Post-processing and evaluation

- Critical path:
  1. Data Ingestion: Raw 10Hz tracking and event data → Preprocessing (scaling, smoothing, aligning) → Tensor creation (104x68 grid)
  2. Feature Engineering: Create tensors for player positions/velocities, ball position/velocity/height, distances, and angles
  3. Training: Train three models separately, overcoming vanishing gradients via U-Net + softmax/categorical cross-entropy for value model
  4. Inference: Run all three models to generate probability surfaces for given game state
  5. Post-processing: Combine surfaces using formula above to get final Pass EPV map

- Design tradeoffs:
  - Grid Resolution (104x68): Chosen for efficient indexing (~1 meter per cell) but may lack fine spatial detail
  - U-Net vs. Prior Architecture: Chosen to fix vanishing gradients but may be less expressive than more modern architectures
  - Separate Value Models: Training two separate value models increases complexity but allows cleaner decomposition
  - 15-Second Window: Fixed based on average possession time; simplicity vs. potentially missing longer-term consequences

- Failure signatures:
  - Vanishing Gradients: Training loss plateaus very early with no improvement (especially for value model)
  - Poor Calibration: Model confidence doesn't match accuracy (wrong when 90% sure)
  - Ignoring Offside: Model underperforms on offside scenarios, assigning high value to offside players
  - Counter-intuitive Value Surfaces: High value assigned to backwards passes when clear forward option exists

- First 3 experiments:
  1. Feature Ablation: Retrain Pass Value model without "distance to goal" and "angle to goal" features; measure drop in OJN-Pass-EPV benchmark performance
  2. Architecture Comparison: Implement simpler CNN (few Conv layers without U-Net structure) for Pass Value model; observe vanishing gradient issues and compare loss/calibration
  3. Ball Height Impact: Run inference with ball height forced to zero vs. true value on goal kicks/crosses; visually inspect change in Pass Likelihood surface

## Open Questions the Paper Calls Out

- How can deep learning architectures for EPV be modified to robustly account for the offside rule, preventing valuation of invalid passes? The model underperforms in scenarios involving offside players, assigning higher pass EPV to game states where a player is offside.

- Can pass intention be explicitly modeled to disentangle quality of player's decision from quality of their execution? Current models evaluate outcomes but lack mechanism to determine if failed pass was good decision poorly executed or poor decision entirely.

- To what extent does incorporating player-specific traits improve EPV accuracy compared to current generalized player representations? Adding player-specific properties is required step for broad practical adoption and would enrich understanding of individual performance.

## Limitations
- Benchmark relies on expert judgments that may contain subjective biases
- Model's known failure on offside scenarios indicates incomplete spatial reasoning
- 15-second outcome window may not capture longer-term strategic consequences of passes
- Use of ball height data assumes availability of 3D tracking, which is not standard in many datasets

## Confidence
- **High**: Benchmark methodology and architecture improvements (U-Net + softmax addressing vanishing gradients)
- **Medium**: Reward/risk decomposition's practical utility (supported by qualitative examples but limited quantitative validation)
- **Medium**: Ball height's contribution (supported by qualitative visual inspection but not rigorous ablation)

## Next Checks
1. Ablation Study: Remove distance-to-goal and angle-to-goal features from Pass Value model and measure performance degradation on OJN-Pass-EPV benchmark to quantify their importance for contextual accuracy.

2. Calibration Robustness: Test temperature scaling across multiple validation splits and match types to ensure calibration improvements generalize beyond reported results.

3. Offside Failure Analysis: Create focused evaluation set of offside scenarios and systematically measure model's performance gap, potentially incorporating explicit offside features if data permits.