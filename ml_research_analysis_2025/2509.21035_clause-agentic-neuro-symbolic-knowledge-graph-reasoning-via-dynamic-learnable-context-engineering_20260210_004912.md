---
ver: rpa2
title: 'CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable
  Context Engineering'
arxiv_id: '2509.21035'
source_url: https://arxiv.org/abs/2509.21035
tags:
- latency
- edge
- context
- learning
- clause
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes CLAUSE, an agentic neuro-symbolic framework\
  \ for knowledge graph question answering that dynamically constructs compact, provenance-preserving\
  \ contexts under explicit latency, token, and edge-budget constraints. Instead of\
  \ static k-hop expansion, CLAUSE uses three coordinated agents\u2014Subgraph Architect,\
  \ Path Navigator, and Context Curator\u2014to jointly build, explore, and curate\
  \ graph evidence, stopping automatically when costs outweigh utility."
---

# CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering

## Quick Facts
- arXiv ID: 2509.21035
- Source URL: https://arxiv.org/abs/2509.21035
- Reference count: 9
- Primary result: CLAUSE achieves higher exact match scores (+39.3 EM@1 on MetaQA-2-hop) while reducing latency by 18.6% and edge growth by 40.9% compared to strong RAG baselines.

## Executive Summary
This paper proposes CLAUSE, an agentic neuro-symbolic framework for knowledge graph question answering that dynamically constructs compact, provenance-preserving contexts under explicit latency, token, and edge-budget constraints. Instead of static k-hop expansion, CLAUSE uses three coordinated agents—Subgraph Architect, Path Navigator, and Context Curator—to jointly build, explore, and curate graph evidence, stopping automatically when costs outweigh utility. It trains these agents with LC-MAPPO, a constrained MARL method that optimizes a centralized multi-head critic with per-resource dual variables to enforce per-query budgets while maximizing answer accuracy. Experiments on HotpotQA, MetaQA, and FactKG show CLAUSE achieves higher exact match scores (e.g., +39.3 EM@1 on MetaQA-2-hop) while reducing latency by 18.6% and edge growth by 40.9% compared to strong RAG baselines, yielding compact, auditable contexts and predictable trade-offs among accuracy, latency, and cost.

## Method Summary
CLAUSE uses three agents—Subgraph Architect (edits KG subgraph), Path Navigator (traverses paths), and Context Curator (selects text)—to build KG contexts under explicit per-query resource budgets. These agents are trained jointly with LC-MAPPO, a constrained MARL method that optimizes a centralized multi-head critic with task and per-resource cost heads, using Lagrangian dual variables to enforce budgets. At inference, operators can set per-query caps or prices to adapt accuracy-latency-cost trade-offs without retraining. The system stops automatically when marginal gain falls below the current resource price, yielding compact, provenance-preserving contexts.

## Key Results
- CLAUSE achieves +39.3 EM@1 on MetaQA-2-hop compared to RAG baselines.
- Reduces latency by 18.6% and edge growth by 40.9% while maintaining or improving accuracy.
- Delivers predictable accuracy-latency-cost trade-offs via per-query budget/price adaptation without retraining.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Budget-aware shaping via Lagrangian duals enforces per-episode latency and cost constraints without hardcoding stopping rules.
- Mechanism: LC-MAPPO augments the reward with per-step shaped return $r'_t = r^{acc}_t - \lambda_{edge}c^{edge}_t - \lambda_{lat}c^{lat}_t - \lambda_{tok}c^{tok}_t$. Dual variables $(\lambda_{edge}, \lambda_{lat}, \lambda_{tok})$ are updated by projected ascent to satisfy $\mathbb{E}[C_k] \leq \beta_k$. Agents learn to stop or backtrack when marginal gain falls below the current price, replacing heuristic k-hop or top-k knobs.
- Core assumption: The constrained Markov decision process (CMDP) decomposition and linear Lagrangian are sufficiently expressive for deployment trade-offs; cost attribution at source (edits/steps/tokens) is accurate.
- Evidence anchors:
  - [abstract] Latency (interaction steps) and prompt cost (selected tokens) are exposed as user-specified budgets or prices, allowing per-query adaptation without retraining.
  - [sections 3–4] CMDP formulation (Eq. 1) and LC-MAPPO (Eq. 2), dual updates, and multi-head centralized critic.
  - [corpus] No direct corpus validation of LC-MAPPO specifics; related work (A2RAG) emphasizes cost-aware retrieval but does not evaluate Lagrangian duals.
- Break condition: If episode costs are dominated by hidden factors not tracked by edge/steps/tokens (e.g., reader LLM overhead), duals may misprice resources and constraints will not hold.

### Mechanism 2
- Claim: Decoupling context construction into three specialized agents (edit/traverse/curate) improves credit assignment and yields compact, provenance-preserving traces.
- Mechanism: Subgraph Architect scores edges with fused signals ($\phi_{ent}, \phi_{rel}, \phi_{nbr}, \phi_{deg}$) and applies gain–price decisions; Path Navigator chooses CONTINUE/BACKTRACK/STOP over a small horizon; Context Curator performs listwise, redundancy-aware selection with learned STOP. Centralized critic with separate cost heads simplifies credit attribution.
- Core assumption: The edit→traverse→curate loop aligns with KGQA structure and the agents' partial observations are sufficient for good joint decisions.
- Evidence anchors:
  - [abstract] Agentic three-agent neuro-symbolic framework... jointly optimized under per-query resource budgets.
  - [sections 4.3–4.4] Agent roles and observations; ablations showing performance drops when any agent or dual updates are removed.
  - [corpus] Weak corpus support for this exact decomposition; neuro-symbolic reasoning and agentic memory works are adjacent but do not validate the three-agent split.
- Break condition: If questions require dense, non-path subgraph patterns (e.g., subgraph isomorphism) rather than path-like reasoning, the traverse agent may over-prune and lose recall.

### Mechanism 3
- Claim: Explicit, per-query budgets ($\beta_{edge}, \beta_{lat}, \beta_{tok}$) or prices ($\lambda$) enable predictable accuracy–latency–cost trade-offs at inference without retraining.
- Mechanism: At deployment, operators choose cap mode (hard budgets) or price mode (soft trade-offs). A single checkpoint adapts per query because policies condition on remaining budgets and duals; stopping rules are learned, not hard-coded.
- Core assumption: Budgets are query-invariant enough that a shared policy can generalize across queries and that the learned STOP reliably respects caps under distribution shift.
- Evidence anchors:
  - [abstract] Per-query adaptation to accuracy-latency-cost trade-offs without retraining; compact, provenance-preserving contexts with predictable performance.
  - [sections 4.5, 5] Inference controls (cap/price modes); normalized latency and edge budgets; Pareto frontiers in sweeps.
  - [corpus] Adjacent work (A2RAG) highlights cost-aware routing but does not corroborate per-query budget guarantees.
- Break condition: Under significant distribution shift (e.g., very different KG densities or question types), learned duals may be misaligned and feasibility can degrade.

## Foundational Learning
- Concept: Constrained RL and Lagrangian methods (e.g., CMDPs, dual ascent).
  - Why needed here: LC-MAPPO relies on Lagrangian relaxation to enforce multiple resource budgets while optimizing task reward.
  - Quick check question: Can you write the Lagrangian for $\max \mathbb{E}[R]$ s.t. $\mathbb{E}[C_k] \leq \beta_k$ and explain how dual updates enforce constraints?
- Concept: Centralized training with decentralized execution (CTDE) in MARL.
  - Why needed here: CLAUSE uses a centralized critic with per-agent actors; understanding credit assignment (COMA-style advantages) is essential.
  - Quick check question: Why does a centralized critic help in CTDE, and how does it differ from independent PPO per agent?
- Concept: Multi-hop KGQA and neuro-symbolic reasoning.
  - Why needed here: Agents edit/traverse/curate KG structures; basic KG notions (entities, relations, paths) and path-query types are prerequisites.
  - Quick check question: What is a 2-hop path query over a KG, and why might static k-hop expansion introduce distractors?

## Architecture Onboarding
- Component map:
  - Subgraph Architect: Entity anchor extraction; multi-signal edge scorer; gain–price decision rule; reversible ADD/DELETE/STOP.
  - Path Navigator: Path prefix encoder; CONTINUE/BACKTRACK/STOP policy over outgoing candidates; step counter $C_{lat}$.
  - Context Curator: Listwise selection over textualized units; redundancy-aware scoring; token budgeting $C_{tok}$ with learned STOP.
  - LC-MAPPO: Centralized multi-head critic ($Q_{task}, Q_{edge}, Q_{lat}, Q_{tok}$); monotonic mixer; COMA-style advantage; projected dual ascent on $(\lambda_{edge}, \lambda_{lat}, \lambda_{tok})$.
  - Reader LLM: Consumes curated context; produces answer $y$.
- Critical path: Entity anchoring → Architect edits → Navigator traversal → Curator selection → Reader answer; duals and budgets condition each stage; STOP can fire at any stage.
- Design tradeoffs:
  - More agents increase coordination overhead but improve credit assignment.
  - Tight caps guarantee constraints but may sacrifice accuracy; higher prices allow soft trade-offs.
  - Horizon $H$ and budget granularity control latency vs. exploration depth.
- Failure signatures:
  - Feasibility drop (budgets violated): duals too small or cost heads inaccurate.
  - Accuracy collapse with tight budgets: STOP triggers too early; path patterns pruned.
  - Over-expansion despite Architect: edge scorer poorly calibrated; gain–price thresholding not applied.
  - High variance across runs: CTDE credit assignment unstable; consider COMA baselines or mixer tuning.
- First 3 experiments:
  1. Budget sweep on a held-out slice of HotpotQA/MetaQA: vary $(\beta_{edge}, \beta_{lat}, \beta_{tok})$ and plot EM@1 vs. latency vs. edge growth to verify Pareto frontiers and constraint feasibility.
  2. Ablate one agent at a time (replace with heuristic: static k-hop for Architect; greedy hop for Navigator; top-k rerank for Curator) to confirm each agent's contribution.
  3. LC-MAPPO vs. baselines: compare against MAPPO (no duals), fixed-penalty PPO, and RCPO on feasibility rate and latency violation under the same per-query budgets.

## Open Questions the Paper Calls Out
- **Question:** How does CLAUSE performance scale when reasoning depth requires significantly more than 3 hops?
- **Basis in paper:** [inferred] The experiments (Table 1) are limited to MetaQA 1–3 hops and HotpotQA, which typically involve 2-hop reasoning.
- **Why unresolved:** The "learned stopping" mechanism and subgraph growth are optimized for the tested horizons; it is unclear if the agent policies degrade or if latency explodes in deeper, more complex reasoning chains.
- **What evidence would resolve it:** Evaluation on datasets requiring 4–5 hop reasoning (e.g., extended versions of MetaQA or complex logic queries) showing EM@1 and latency stability.

- **Question:** How sensitive is the LC-MAPPO optimization to the initialization of the Lagrangian dual variables and PID control gains?
- **Basis in paper:** [inferred] Section 4.4 mentions dual updates are "optionally stabilized with PID control" without providing an ablation on these hyperparameters.
- **Why unresolved:** Constrained RL often suffers from instability where dual variables oscillate, failing to enforce budget caps; the paper does not analyze the robustness of this stabilization.
- **What evidence would resolve it:** A sensitivity analysis showing constraint violation rates and reward convergence curves across varied PID gain settings and initial $\lambda$ values.

- **Question:** Can the neuro-symbolic agents generalize zero-shot to knowledge graphs with vastly different structural densities or relation schemas?
- **Basis in paper:** [inferred] The method is tested on three specific datasets (HotpotQA, MetaQA, FactKG) with distinct but fixed schemas.
- **Why unresolved:** The Subgraph Architect's "multi-signal edge scorer" may overfit to the relation distributions of the training graphs, limiting portability to new domains without retraining.
- **What evidence would resolve it:** Cross-domain transfer experiments (e.g., training on MetaQA movies, testing on a medical KG) reporting performance drops relative to the upper bound.

## Limitations
- Architect scorer details (φ_ent, φ_rel, φ_nbr, φ_deg, w1–w4) are unspecified, limiting generalization.
- LC-MAPPO hyperparameter sensitivity is not characterized (learning rates, horizon, dual step sizes).
- Real-world cost attribution (e.g., LLM reader overhead) may misalign with dual-based pricing.
- Distribution shift robustness is unproven; constraints may fail on novel KG densities or question types.

## Confidence
- **High confidence**: The constrained MDP formulation and Lagrangian dual updates (Mechanism 1) are standard and well-grounded in the literature.
- **Medium confidence**: The three-agent decomposition (Mechanism 2) is theoretically sound and ablation-supported, but the exact empirical benefit over other neuro-symbolic or multi-agent designs is less established.
- **Medium confidence**: Per-query budget/price adaptation (Mechanism 3) is plausible given the learned stopping policies, but corpus evidence for cross-query generalization is limited.

## Next Checks
1. **Constraint feasibility under distribution shift**: Hold out a disjoint KG or question type (e.g., a subset of MetaQA-3-hop or FactKG) and measure whether per-query budgets remain satisfied and accuracy stays stable.
2. **Architect scorer ablation and ablations**: Replace the learned edge scorer with fixed similarity heuristics and compare EM@1 and edge usage to quantify the contribution of the learned signals.
3. **Dual pricing sensitivity**: Systematically vary λ_k across a wide range and measure how constraint violation rates, latency, and EM@1 trade off, to test the robustness of the Lagrangian shaping.