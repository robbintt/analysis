---
ver: rpa2
title: 'FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with
  Uncertainty Estimation'
arxiv_id: '2508.09196'
source_url: https://arxiv.org/abs/2508.09196
tags:
- uncertainty
- segmentation
- federated
- learning
- client
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FIVA, a federated learning approach for universal
  CT segmentation that incorporates uncertainty estimation. The method leverages stochasticity
  in mini-batch SGD to estimate parameter distributions at client nodes, which are
  then aggregated at the server using inverse-variance weighting.
---

# FIVA: Federated Inverse Variance Averaging for Universal CT Segmentation with Uncertainty Estimation

## Quick Facts
- arXiv ID: 2508.09196
- Source URL: https://arxiv.org/abs/2508.09196
- Authors: Asim Ukaye; Numan Saeed; Karthik Nandakumar
- Reference count: 13
- Primary result: FIVA achieves 65.49% mean Dice on universal CT segmentation, outperforming FedAvg (54.16%) and approaching centralized training (67.31%)

## Executive Summary
This paper introduces FIVA, a federated learning framework for universal CT segmentation that incorporates uncertainty estimation. The method leverages stochasticity in mini-batch SGD to estimate parameter distributions at client nodes, which are then aggregated at the server using inverse-variance weighting. During inference, the global parameter distribution is sampled to obtain predictive uncertainty estimates that improve segmentation accuracy by suppressing false-positive background predictions, particularly in ambiguous boundary regions.

## Method Summary
FIVA operates by tracking running mean and variance of gradients (FIVA-G) or parameters (FIVA-P) across mini-batch updates using Welford's algorithm. The server aggregates client contributions using inverse-variance weighting based on these variance estimates, with a forgetting factor of 0.95. During inference, K weight perturbations are sampled from the global parameter distribution to compute uncertainty estimates, which are used to reweight background logits and improve segmentation accuracy. The approach was evaluated on five abdominal CT datasets with a held-out test client.

## Key Results
- FIVA achieved mean Dice score of 65.49%, outperforming FedAvg (54.16%) and approaching centralized training performance (67.31%)
- Uncertainty-weighted inference improved segmentation accuracy by suppressing false-positive background predictions
- FIVA demonstrated better-calibrated predictions with lower Expected Calibration Error compared to baselines
- Parameter-based variance estimation (FIVA-P) showed superior performance to gradient-based (FIVA-G) with 65.49% vs 62.74% mean Dice

## Why This Works (Mechanism)

### Mechanism 1: Online Parameter Variance Estimation via SGD Stochasticity
Mini-batch SGD's inherent noise is leveraged to estimate parameter distributions without additional inference passes. Each client tracks running mean and variance using Welford's algorithm, with gradient variance accumulating into parameter variance via σ²_θ,T = σ²_θ,0 + T·η²·σ²_g,T under independence assumption.

### Mechanism 2: Inverse-Variance Weighted Aggregation
Client contributions are weighted by inverse variance (precision) to improve global model quality under heterogeneous data. Server computes client weights as c_i,r = n̂_i / σ²_i,r and aggregates parameters accordingly, with global variance updated using forgetting factor λ=0.95.

### Mechanism 3: Sampling-Based Uncertainty for Inference Refinement
Global parameter distribution is sampled during inference to obtain predictive uncertainty estimates. K forward passes are computed and averaged, with uncertainty decomposed into aleatoric and epistemic components. Background class channel is reweighted using uncertainty to suppress false-positive predictions.

## Foundational Learning

- **Federated Learning (horizontal split)**: Understanding aggregation and communication rounds is prerequisite since FIVA operates in standard FL with shared architecture but different data. Quick check: Can you explain why FedAvg weights clients by sample size and how FIVA modifies this?

- **Aleatoric vs. Epistemic Uncertainty**: FIVA explicitly decomposes and uses both types—epistemic for aggregation weighting, combined for inference reweighting. Quick check: Which uncertainty type decreases with more data, and which does FIVA track during local training?

- **Welford's Algorithm for Online Statistics**: Memory-efficient computation of running mean/variance without storing full gradient/parameter history (O(M) vs O(TM)). Quick check: Why is Welford's algorithm numerically stable compared to naive two-pass variance computation?

## Architecture Onboarding

- **Component map**: Client module (local trainer + Welford variance estimator) → Server module (inverse-variance aggregation) → Inference module (sampling-based uncertainty refinement)

- **Critical path**: Initialize clients with He initialization → Run T mini-batch SGD steps tracking variance via Welford → Transmit (θ_i, σ²_i) to server → Aggregate using inverse-variance weighting → Broadcast global distribution → Sample K weight perturbations at inference → Compute uncertainty → Reweight background → Final prediction

- **Design tradeoffs**: FIVA-G vs. FIVA-P (gradient vs parameter-based variance), forgetting factor λ (smoothing vs adaptation), K samples at inference (accuracy vs latency)

- **Failure signatures**: Variance collapse (σ² → 0), variance explosion (σ² → ∞), no improvement over FedAvg (similar variances), worse calibration after reweighting (mis-calibrated estimates)

- **First 3 experiments**:
  1. Run FIVA-P on single-client and verify variance estimates are non-zero and bounded
  2. Compare FIVA-G vs. FIVA-P on 2-client setup with known heterogeneity
  3. Run 5-client federation with FedAvg, FIVA-P (no UN), and FIVA-P+UN on held-out client; plot reliability diagrams

## Open Questions the Paper Calls Out

- **Variance Stabilization in Low-Data Regimes**: What techniques can stabilize parameter variance estimates to prevent training destabilization? The paper notes this is an area for future research.

- **Independence Assumption Bias**: Does the independence assumption in gradient-based variance estimation introduce systematic bias that degrades aggregation quality? The computational savings come at the cost of ignoring gradient correlations.

- **Gaussian Distribution Assumption**: Is the Gaussian distribution assumption for parameter sampling during inference valid for deep segmentation networks? The method samples from N(0, σ²_global) without validating this assumption.

## Limitations

- **Variance Reliability**: The effectiveness of using SGD stochasticity for variance estimation is contingent on the assumption that gradient fluctuations reflect epistemic uncertainty rather than optimization noise, particularly problematic in low-data regimes.

- **Aggregation Weight Sensitivity**: Inverse-variance weighting assumes Gaussian-like parameter distributions and independence between client updates; if client data distributions are highly overlapping, the method reduces to FedAvg.

- **Gap to Centralized Performance**: Despite improvements, a significant gap remains between federated and standalone performance (66.42% vs 83.02% Dice), limiting immediate clinical applicability.

## Confidence

- **High Confidence**: Dice score improvements over FedAvg, aggregation mechanism implementation, inference sampling procedure
- **Medium Confidence**: Variance estimation via SGD stochasticity, inverse-variance weighting effectiveness, uncertainty decomposition methodology
- **Low Confidence**: Generalization of calibration improvements across all clients, robustness to batch size effects, behavior in extreme low-data scenarios

## Next Checks

1. **Variance Stability Analysis**: Monitor parameter variance magnitudes across training rounds to verify they remain bounded and discriminative between clients; implement variance clipping or floor/ceiling values.

2. **Ablation on Batch Size**: Compare FIVA performance and variance estimates across different batch sizes (e.g., 4, 8, 16) to quantify how SGD stochasticity quality affects uncertainty estimation.

3. **Multi-Client Calibration Study**: Evaluate Expected Calibration Error for each of the five training clients individually to verify FIVA's calibration benefits generalize across heterogeneous data distributions.