---
ver: rpa2
title: Conditional Performance Guarantee for Large Reasoning Models
arxiv_id: '2601.22790'
source_url: https://arxiv.org/abs/2601.22790
tags:
- reasoning
- score
- group
- error
- g-pac
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: G-PAC reasoning extends PAC reasoning by providing statistical
  guarantees at the group level rather than only marginally. The method partitions
  the input space into groups and calibrates separate thresholds for each group, either
  using known group labels or learning them via clustering.
---

# Conditional Performance Guarantee for Large Reasoning Models

## Quick Facts
- arXiv ID: 2601.22790
- Source URL: https://arxiv.org/abs/2601.22790
- Reference count: 40
- G-PAC reasoning provides group-conditional PAC guarantees, eliminating group-wise error gaps while maintaining computational savings over marginal PAC reasoning

## Executive Summary
This paper extends PAC reasoning to provide conditional performance guarantees at the group level rather than only marginally. The method partitions the input space into groups and calibrates separate thresholds for each group, either using known group labels or learning them via clustering. Theoretical analysis proves that G-PAC achieves group-conditional risk control and strictly improves efficiency over marginal PAC reasoning when groups exhibit heterogeneous risk profiles. Empirical results on MATH-500, ZebraLogic, and GPQA show that G-PAC eliminates group-wise error gaps while maintaining substantial computational savings, and that C-PAC achieves the same when group partitions are unknown.

## Method Summary
The paper proposes G-PAC reasoning, which extends marginal PAC reasoning by providing statistical guarantees at the group level. The method partitions the input space into groups and calibrates separate thresholds for each group using uncertainty scores. For known groups, Algorithm 2 constructs group-specific UCBs via importance sampling with bootstrap samples, then selects the maximum threshold satisfying the risk constraint. For unknown groups, C-PAC uses 1D k-means clustering on uncertainty scores before calibration. The routing decision uses a thinking model for inputs with high uncertainty and a non-thinking model for low-uncertainty inputs, with the threshold determined to ensure group-conditional risk control.

## Key Results
- G-PAC achieves group-conditional risk control with provable efficiency improvements over marginal PAC when groups are heterogeneous
- On MATH-500, G-PAC eliminates group-wise error gaps while achieving 63% STP compared to 70% for marginal PAC
- C-PAC with learned partitions achieves similar performance to G-PAC, demonstrating the approach works without known group labels

## Why This Works (Mechanism)
G-PAC works by recognizing that marginal PAC reasoning can be overly conservative when different groups have different risk profiles. By calibrating separate thresholds for each group based on their specific uncertainty distributions, G-PAC allows more aggressive routing for low-risk groups while maintaining guarantees for high-risk groups. The theoretical guarantee comes from constructing confidence intervals (UCBs) for each group's loss distribution and selecting thresholds that satisfy the risk constraint with high probability.

## Foundational Learning
- **PAC reasoning**: A statistical framework for providing probabilistic performance guarantees by routing inputs based on uncertainty scores. Why needed: Provides the foundation for efficient reasoning with formal guarantees.
- **Group-conditional risk control**: Extending PAC guarantees to hold simultaneously for multiple disjoint groups rather than marginally. Why needed: Enables more efficient routing when groups have heterogeneous risk profiles.
- **Importance sampling in UCB construction**: Using weighted sampling to estimate loss distribution quantiles for threshold selection. Why needed: Enables accurate confidence bounds for threshold selection under the routing policy.
- **Sample splitting vs. joint clustering**: Trade-off between statistical efficiency and coverage guarantees when group labels are unknown. Why needed: Determines how to handle the case when groups must be learned from data.
- **ErrorGap metric**: Measures the difference between maximum and minimum group error rates. Why needed: Quantifies the degree of group-wise performance disparity.

## Architecture Onboarding

**Component map:** Input -> Uncertainty Score -> Group Partition -> UCB Construction -> Threshold Selection -> Router (Thinking/Non-thinking Model) -> Output

**Critical path:** Calibration data generation → Uncertainty score computation → Group partitioning (if unknown) → UCB construction per group → Threshold selection → Test-time routing

**Design tradeoffs:** Split vs. joint clustering (statistical efficiency vs. coverage), choice of k groups (finer control vs. per-group sample scarcity), uncertainty score quality (calibration accuracy vs. computational overhead)

**Failure signatures:** High ErrorGap (>0) indicates group-conditional risk not controlled; STP near 0% means all inputs routed to thinking model; Coverage gap c·δ when using joint clustering indicates theoretical guarantees not met

**3 first experiments:**
1. Verify UCB construction produces valid confidence bounds by checking coverage on simulated data with known distributions
2. Test routing performance with synthetic groups of known risk profiles to confirm efficiency gains
3. Evaluate sensitivity to number of bootstrap samples m and discretization granularity of candidate thresholds U

## Open Questions the Paper Calls Out

**Open Question 1:** How can the efficiency of G-PAC reasoning be improved when uncertainty scores are poorly calibrated or uninformative? The paper notes that uninformative uncertainty estimates may reduce computational savings, but provides no solution.

**Open Question 2:** What is the optimal strategy for balancing sample splitting vs. joint clustering trade-off when calibration data is limited? The paper identifies this as a limitation but doesn't provide guidance on when each approach is preferable.

**Open Question 3:** How should the number of groups k be selected optimally given the trade-off between finer conditional control and per-group sample scarcity? The paper uses k=3 without justification or analysis of sensitivity.

**Open Question 4:** Can the G-PAC framework be extended to provide multicalibration-style guarantees that simultaneously hold for multiple overlapping group definitions? The current framework assumes disjoint partitions, limiting applicability to real-world scenarios with overlapping subgroups.

## Limitations
- Empirical evaluation limited to three small benchmarks (<1,500 total instances) reducing generalizability
- Insufficient details on router model training and hyperparameter choices for faithful reproduction
- No analysis of computational overhead of calibration phase or scalability to larger group partitions

## Confidence

**High confidence:** Theoretical analysis of G-PAC achieving group-conditional risk control and formal proof of improved efficiency over marginal PAC reasoning when groups are heterogeneous.

**Medium confidence:** Empirical results showing G-PAC's effectiveness in eliminating group-wise error gaps and achieving STP improvements, though limited by small sample sizes and dataset diversity.

**Low confidence:** C-PAC clustering approach performance claims and router-based uncertainty scoring implementation details due to insufficient methodological details.

## Next Checks
1. Reproduce the UCB construction by implementing Algorithm 1 with explicit discretization of candidate thresholds and verifying the bootstrap sampling procedure
2. Evaluate sensitivity to group partitioning by testing G-PAC performance across varying numbers of groups (k=2, 5, 10) and different clustering methods
3. Scale to larger datasets by validating the approach on substantially larger reasoning benchmarks (≥10K instances) to assess theoretical advantages with realistic sample sizes