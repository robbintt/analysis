---
ver: rpa2
title: 'Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining
  Whole Slide Image Classification'
arxiv_id: '2511.08464'
source_url: https://arxiv.org/abs/2511.08464
tags:
- attribution
- gradients
- methods
- regions
- integrated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Contrastive Integrated Gradients (CIG), a
  feature attribution method for explaining whole slide image (WSI) classification
  in computational pathology. CIG enhances interpretability by computing contrastive
  gradients in logit space, comparing feature importance relative to a reference class
  from the opposite category, thus highlighting class-discriminative regions more
  effectively.
---

# Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification

## Quick Facts
- arXiv ID: 2511.08464
- Source URL: https://arxiv.org/abs/2511.08464
- Reference count: 40
- Primary result: CIG outperforms existing methods in explaining WSI classification with better attribution quality metrics (MIL-AIC/MIL-SIC) and qualitative alignment with ground truth tumor regions

## Executive Summary
This paper introduces Contrastive Integrated Gradients (CIG), a feature attribution method for explaining whole slide image (WSI) classification in computational pathology. CIG enhances interpretability by computing contrastive gradients in logit space, comparing feature importance relative to a reference class from the opposite category, thus highlighting class-discriminative regions more effectively. The method satisfies the axioms of integrated attribution, ensuring consistency and theoretical soundness. To evaluate attribution quality in weakly supervised WSI settings, the authors propose two metrics, MIL-AIC and MIL-SIC, measuring how predictive information and model confidence evolve with access to salient regions.

## Method Summary
CIG computes feature attributions by integrating gradients of squared logit distances between interpolated inputs and a reference baseline. The method uses opposite-class patches as baselines to enhance discriminative contrast. Attribution quality is evaluated using MIL-AIC and MIL-SIC metrics that measure classification accuracy and confidence as salient patches are progressively revealed. The approach is tested on three datasets (CAMELYON16, TCGA-RCC, TCGA-Lung) using both CLAM and MLP classifiers, demonstrating superior performance in highlighting class-discriminative regions.

## Key Results
- CIG produces more informative and focused attributions than existing methods, both quantitatively (MIL-AIC/MIL-SIC scores) and qualitatively
- Visualizations align closely with ground truth tumor regions across different classifiers and cancer subtypes
- Strong performance across binary and multi-class classification tasks (tumor detection and RCC subtype classification)

## Why This Works (Mechanism)

### Mechanism 1: Logit-Space Contrastive Gradient Integration
- Claim: Computing gradients on squared logit differences relative to a reference class yields more class-discriminative attributions than standard gradient methods.
- Mechanism: Instead of integrating ∂F/∂x along a path, CIG integrates ∂‖f_logit(γ(α)) - f_logit(x')‖²/∂x. The squared Euclidean distance in logit space measures how far the interpolated input is from the reference class decision boundary.
- Core assumption: The logit layer encodes class-discriminative information more relevant for attribution than final softmax probability.
- Evidence anchors: [abstract] "CIG highlights class-discriminative regions by comparing feature importance relative to a reference class"; [section 3.1] Defines CIG with squared logit norm.

### Mechanism 2: Opposite-Class Baseline Sampling
- Claim: Using patches from the opposite class as the reference baseline enhances sensitivity to features that distinguish classes.
- Mechanism: For tumor-positive slides, non-tumor patches define x'. The interpolation path traverses from "normal appearance" to "tumor appearance," capturing features that drive the model from negative to positive class.
- Core assumption: Patch-level features from opposite-class slides form a semantically meaningful baseline that avoids out-of-distribution artifacts.
- Evidence anchors: [abstract] "comparing feature importance relative to a reference class from the opposite category"; [section 3.3.2] Uses baseline from opposite class.

### Mechanism 3: MIL-AIC/MIL-SIC Attribution Quality Metrics
- Claim: Measuring prediction accuracy and confidence as salient patches are progressively introduced provides principled evaluation under weak supervision.
- Mechanism: Starting with control features, replace with target-slide patches in saliency-ranked order. MIL-AIC tracks classification correctness; MIL-SIC tracks softmax confidence.
- Core assumption: In MIL settings, predictions change abruptly after key instances are revealed; evaluation should capture these non-linear transitions.
- Evidence anchors: [abstract] "we propose two attribution quality metrics, MIL-AIC and MIL-SIC"; [section 3.3.3] Describes information-level bins.

## Foundational Learning

- Concept: Integrated Gradients (IG) axiom framework
  - Why needed here: CIG inherits IG's axiomatic foundation (completeness, sensitivity, implementation invariance); understanding these properties is required to evaluate CIG's theoretical soundness.
  - Quick check question: Given an input x and baseline x', if IG attributions sum to F(x) - F(x'), what does CIG's completeness sum to?

- Concept: Multiple Instance Learning (MIL) bag-level supervision
  - Why needed here: CIG operates on patch embeddings within a MIL framework; evaluation metrics are specifically designed for weak supervision where only slide-level labels exist.
  - Quick check question: In a binary MIL setting, if a slide contains 1000 patches and only 3 are tumor-positive, what label does the slide receive?

- Concept: Logit-space representations vs. probability space
  - Why needed here: CIG computes gradients in logit space rather than softmax output; logits preserve inter-class distance information that softmax normalizes away.
  - Quick check question: Why might gradient-based attribution on softmax probabilities be less discriminative than on logits for a 10-class problem?

## Architecture Onboarding

- Component map: Feature extractor (ResNet-50/CONCH) -> patch embeddings -> MIL classifier (CLAM/MLP) -> slide-level logits -> CIG attribution module -> MIL-AIC/MIL-SIC evaluation

- Critical path:
  1. Extract patch embeddings from WSI
  2. Sample baseline embeddings from opposite-class slide pool
  3. For each interpolation step α ∈ {0.02, 0.04, ..., 1.0}: compute γ(α) = x' + α(x - x'), forward pass to get f_logit(γ(α)), compute gradient of ‖f_logit(γ(α)) - f_logit(x')‖² w.r.t. input features
  4. Sum gradients × (x - x') to get final attribution
  5. Map patch-level scores to spatial coordinates for visualization

- Design tradeoffs:
  - Interpolation steps: More steps improve approximation accuracy but increase compute linearly
  - Baseline pool size: 30 slides balance coverage vs. memory
  - Information bins: Top-k captures early decisions; thresholds capture completeness—merging both provides richer evaluation

- Failure signatures:
  - Dispersed/blurry heatmaps: May indicate baseline contains similar features to input
  - Zero attribution on known tumor regions: Check if logits are saturated
  - MIL-AIC stuck near random baseline: Attributions not discriminative

- First 3 experiments:
  1. Reproduce CIG vs. IG comparison on 5 Camelyon16 tumor slides: visualize intermediate gradient maps at α ∈ {0.167, 0.5, 1.0}
  2. Ablate baseline strategy: compare zero vector, dataset mean, same-class random patches, opposite-class patches—measure MIL-AIC delta
  3. Cross-class validation: compute CIG attributions for LUAD vs. LUSC subtypes; verify LUAD-attributed regions align with LUAD-specific histological patterns

## Open Questions the Paper Calls Out

- Question: How do domain experts (pathologists) evaluate CIG-generated attributions compared to existing methods in clinical workflows?
  - Basis in paper: [explicit] "As future work, we plan to incorporate rigorous human-subject evaluations of interpretability."
  - Why unresolved: Current evaluation relies solely on MIL-AIC/MIL-SIC metrics and visual alignment with ground truth masks, without user studies assessing whether CIG attributions improve diagnostic decision-making or trust.

- Question: How can attribution quality be reliably evaluated for tumor-negative (normal) slides in the MIL framework?
  - Basis in paper: [explicit] MIL-AIC and MIL-SIC metrics are less meaningful for normal slides where predictions require removing nearly all tumor-like features.
  - Why unresolved: MIL-AIC and MIL-SIC metrics are asymmetric, designed for tumor-positive cases; the inverse scenario for normal slides produces unreliable metrics.

## Limitations

- Patch extraction parameters (magnification, patch size, stain normalization) and exact model training configurations (MLP optimizer, learning rate, batch size) are not specified
- MIL-AIC/MIL-SIC metrics are less meaningful for tumor-negative slides, limiting evaluation scope
- The paper assumes familiarity with CLAM preprocessing which may not be universally accessible

## Confidence

- CIG mechanism and theoretical foundation: **High**
- MIL-AIC/MIL-SIC attribution quality metrics: **Medium**
- Quantitative performance comparisons: **High**
- Qualitative visualization alignment with ground truth: **Medium**

## Next Checks

1. Reproduce CIG vs. IG comparison on 5 Camelyon16 tumor slides: visualize intermediate gradient maps at α ∈ {0.167, 0.5, 1.0} to verify CIG produces more localized gradients throughout the path
2. Ablate baseline strategy: compare (a) zero vector, (b) dataset mean, (c) same-class random patches, (d) opposite-class patches—measure MIL-AIC delta on held-out tumor slides
3. Cross-class validation: compute CIG attributions for LUAD vs. LUSC subtypes; verify that LUAD-attributed regions align with LUAD-specific histological patterns (mucin, lepidic growth) rather than shared adenocarcinoma features