---
ver: rpa2
title: Neural Variance-aware Dueling Bandits with Deep Representation and Shallow
  Exploration
arxiv_id: '2506.01250'
source_url: https://arxiv.org/abs/2506.01250
tags:
- lemma
- regret
- cumulative
- neural
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NVLDB, the first neural variance-aware dueling
  bandit algorithm with shallow exploration. The key innovation is using a Gram matrix
  constructed only from gradients with respect to the last-layer parameters of a neural
  network, significantly reducing computational overhead compared to prior methods
  that use all parameters.
---

# Neural Variance-aware Dueling Bandits with Deep Representation and Shallow Exploration

## Quick Facts
- arXiv ID: 2506.01250
- Source URL: https://arxiv.org/abs/2506.01250
- Reference count: 40
- Primary result: Introduces the first neural variance-aware dueling bandit algorithm with shallow exploration, achieving sublinear cumulative average regret of order Õ(d√(∑σ²t) + √(dT))

## Executive Summary
This paper introduces NVLDB, a neural dueling bandit algorithm that achieves sublinear regret while being computationally efficient. The key innovation is using shallow exploration that only tracks gradients with respect to the last-layer parameters of a neural network, reducing computational overhead from O(dL²) to O(d) while maintaining theoretical guarantees for sufficiently wide networks. The algorithm constructs a variance-weighted Gram matrix and employs both variance-aware and variance-agnostic variants under UCB and Thompson Sampling frameworks.

## Method Summary
NVLDB addresses contextual dueling bandits by maintaining a neural network feature extractor (φ(x; W)) and last-layer parameters (θ). At each round, it computes the variance of preference feedback using the Bradley-Terry-Luce link function, constructs a Gram matrix weighted by inverse variance, and updates θ using gradient descent. The algorithm selects arm pairs using UCB or Thompson Sampling strategies. Theoretical analysis shows regret bounds of Õ(d√(∑σ²t) + √(dT)) under the assumption that the neural network is sufficiently wide (m scales polynomially with T). Empirical evaluation demonstrates consistent performance improvements over baseline algorithms while being approximately 28x faster than existing neural dueling bandit approaches.

## Key Results
- Achieves sublinear cumulative average regret of order Õ(d√(∑σ²t) + √(dT))
- Runs approximately 28x faster than existing neural dueling bandit approaches
- Consistently outperforms baseline algorithms across synthetic and real-world datasets
- Demonstrates variance-aware exploration improves performance when feedback variances are heterogeneous

## Why This Works (Mechanism)

### Mechanism 1: Shallow Exploration via Last-Layer Gradients
Reducing the Gram matrix construction to only last layer gradients significantly lowers computational overhead while preserving the ability to approximate nonlinear utilities, provided the network is sufficiently wide. The algorithm maintains a confidence ellipsoid only for the last linear layer parameters (θ) while deep layers (W) act as a fixed feature map after initial training steps, allowing exploration to scale with context dimension d rather than the massive parameter count of hidden layers.

### Mechanism 2: Variance-Adaptive Uncertainty Weighting
Weighting the exploration term by the inverse of estimated feedback variance tightens confidence intervals when preferences are clear, leading to lower cumulative regret. The algorithm estimates variance of Bernoulli preference feedback and scales gradient feature differences in the Gram matrix by 1/σ̂²_t, causing less aggressive exploration when the pairwise winner is obvious and more caution when comparison is noisy.

### Mechanism 3: Bias Correction via Bootstrap Argument
The algorithm maintains theoretical regret guarantees despite bias introduced by not updating the full network by iteratively refining bounds on parameter norm. A bootstrap argument combined with the Courant-Fischer theorem bounds the norm of θ_t by first proving a loose bound, using it to refine the bias estimate, and iteratively tightening the bound to achieve the final sublinear regret rate.

## Foundational Learning

- **Contextual Dueling Bandits**: Feedback is relative (pairwise preference) rather than absolute. Understanding why minimizing "average regret" differs from minimizing "weak regret" is crucial for the problem setting.

- **Neural Tangent Kernel (NTK)**: The "sufficiently wide" assumption ensures the network behaves like a kernel method where feature representation is stable. Increasing width makes training dynamics more "linear" by reducing the impact of higher-order terms.

- **Variance-Weighted Least Squares**: Understanding how inverse variance (1/σ²) acts as a confidence weight is crucial. In weighted least squares, very small variance (high confidence) causes the Gram matrix V_t to give more weight to that data point's gradient contribution.

## Architecture Onboarding

- **Component map**: Input contexts → Feature encoder (deep NN φ(x; W)) → Linear head (parameter θ) → Variance estimator → Optimizer (updates V_t and θ)

- **Critical path**: 
  1. Pass contexts through φ(·) to get features
  2. Use θ and V_t⁻¹ to select most informative arm pair (UCB/TS)
  3. Calculate feedback uncertainty based on predicted utility gap
  4. Update V_t using inverse variance weighting and θ via one-step gradient descent

- **Design tradeoffs**: 
  - Variance clamp ε: Too small risks numerical instability when σ̂_t → 0
  - Episode length H: Longer intervals reduce computation but increase feature representation staleness

- **Failure signatures**: 
  - Regret plateaus when network width is insufficient
  - Divergence when variance clamp ε is removed and model becomes overconfident

- **First 3 experiments**:
  1. Run NVLDB vs. linear baseline (ColSTIM) on Cosine utility task to verify linear method fails while NVLDB achieves sublinear regret
  2. Test with m=32 vs m=100 to verify larger width leads to tighter regret bounds
  3. Compare update time of NVLDB (shallow) against NDB (full gradients) to verify ~28x speedup

## Open Questions the Paper Calls Out

- **Open Question 1**: Can neural dueling bandits achieve horizon-free (Õ(d)) regret when variances are negligible, as linear methods do, or is the additional bias from representation learning fundamentally unavoidable? The paper achieves Õ(d√T + d√(Σσ²_t)) but cannot eliminate the √dT term that arises from representation learning bias.

- **Open Question 2**: Can the required network width scaling (currently poly(T)) be reduced to logarithmic or constant while maintaining sublinear regret guarantees? The paper requires m = poly(T, L, β_g, α_g, κ_g, λ, d, log(T/δ), H, δ) which may be impractical for very long horizons.

- **Open Question 3**: How does NVLDB perform when the positive-definiteness assumption on the NTK matrix is violated, and can theoretical guarantees be extended to degenerate cases? Assumption 3 requires λ_m(H) > 0 which may fail with redundant or highly correlated contexts.

## Limitations
- Theoretical regret bounds require polynomially wide networks, but empirical evaluation uses only 32 hidden units with limited evidence that NTK approximation holds at this scale
- Performance critically depends on accurate variance estimation through BTL link function, which may be unreliable in early rounds when the model is poorly trained
- Shallow exploration introduces bias by not updating the full network, and the bootstrap argument for bias correction lacks empirical validation

## Confidence
- **High Confidence**: Computational efficiency claims (28x speedup verified through runtime comparisons) and basic algorithmic functionality across synthetic and real datasets
- **Medium Confidence**: Sublinear regret claims for variance-aware variants, supported by empirical curves but with theoretical assumptions (network width) not fully validated
- **Low Confidence**: The bootstrap argument for bias correction and its impact on regret bounds, as this represents the most novel theoretical contribution without strong empirical backing

## Next Checks
1. **Width Sensitivity Analysis**: Systematically vary the hidden layer width (m=16, 32, 64, 128) and measure both computational time and regret convergence rate to empirically validate the NTK approximation assumption.

2. **Variance Estimation Robustness**: Compare NVLDB performance against a variance-agnostic baseline when injected with synthetic noise in the variance estimates to quantify the algorithm's sensitivity to poor variance estimation.

3. **Regret Curve Analysis**: Plot the cumulative regret curves on a log-log scale for both synthetic and real datasets to empirically verify the sublinear (polynomial) regret rate predicted by the theory, particularly focusing on whether the curves show clear polynomial decay.