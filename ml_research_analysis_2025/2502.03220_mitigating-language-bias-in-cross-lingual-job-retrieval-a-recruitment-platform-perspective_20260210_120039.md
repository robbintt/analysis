---
ver: rpa2
title: 'Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform
  Perspective'
arxiv_id: '2502.03220'
source_url: https://arxiv.org/abs/2502.03220
tags:
- language
- bias
- title
- encoder
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The authors propose a multi-task dual-encoder framework to develop
  a bilingual (Thai-English) sentence encoder for the recruitment domain. The framework
  jointly learns three job-related tasks: job title translation ranking, job description-title
  matching, and job field classification.'
---

# Mitigating Language Bias in Cross-Lingual Job Retrieval: A Recruitment Platform Perspective

## Quick Facts
- arXiv ID: 2502.03220
- Source URL: https://arxiv.org/abs/2502.03220
- Authors: Napat Laosaengpha; Thanit Tativannarat; Attapol Rutherford; Ekapol Chuangsuwanich
- Reference count: 6
- Key outcome: A multi-task dual-encoder framework reduces language bias and improves cross-lingual retrieval in job recommendation, achieving state-of-the-art performance with a smaller model.

## Executive Summary
This paper proposes a multi-task dual-encoder framework for developing a bilingual (Thai-English) sentence encoder tailored to the recruitment domain. The framework jointly learns three job-related tasks—job title translation ranking, job description-title matching, and job field classification—to address the limitations of existing methods that focus on individual components. The authors introduce a novel metric, Language Bias Kullback-Leibler Divergence (LBKL), to quantify language bias in the encoder. Their approach outperforms state-of-the-art models in both cross-lingual performance and language bias reduction, despite having a smaller model size (69M vs 567M parameters).

## Method Summary
The method employs a multi-task dual-encoder framework built on the mUSEsmallCNN base encoder (69M parameters). It jointly learns three tasks: (A) Job Title Translation Ranking using contrastive loss to align semantically equivalent Thai-English title pairs, (B) Job Description-Title Matching using an NLI-style architecture to predict correlation, and (C) Job Field Classification using a multi-label classifier. Training alternates through these tasks per mini-batch with equal weighting. The approach is evaluated on proprietary recruitment datasets (JTG-Synonym for retrieval, JTG-Occupation for classification) and external datasets (SCB-MT, XQuAD-r) using Recall@k, Accuracy@k, and the LBKL metric.

## Key Results
- The full multi-task model achieves 79.43 R@10 on JTG-Synonym, outperforming single-task variants (JT: 77.43, JD: 66.41, JF: 61.50).
- The method reduces LBKL from 1.20 to 0.40 on JTG-Synonym, indicating significant language bias mitigation.
- Despite a smaller model size (69M vs 567M BGE-M3), the framework achieves state-of-the-art cross-lingual performance and bias reduction.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The job title translation ranking task reduces language bias by explicitly aligning semantically equivalent Thai-English title pairs in embedding space.
- **Mechanism:** Contrastive loss maximizes cosine similarity between translation pairs while pushing non-matching titles apart, creating language-agnostic representations.
- **Core assumption:** Job title translation pairs accurately capture semantic equivalence.
- **Evidence anchors:** JT task alone reduces LBKL from 1.20 → 0.40 on JTG-Synonym; JT listed as one of three joint learning tasks.
- **Break condition:** Poor translation pair quality introduces semantic drift rather than bias reduction.

### Mechanism 2
- **Claim:** Multi-task joint learning improves generalizability by forcing a single encoder to handle multiple job-related components simultaneously.
- **Mechanism:** Cycling through three tasks per mini-batch with equal weight penalty acts as implicit regularization, preventing overfitting to one task.
- **Core assumption:** The three tasks share underlying semantic representations.
- **Evidence anchors:** Full model (79.43 R@10) outperforms single-task variants; multi-stakeholder recommender systems suggest multi-task approaches improve robustness.
- **Break condition:** Significant task gradient conflicts (negative transfer) may cause joint training to underperform task-specific models.

### Mechanism 3
- **Claim:** The job description-title matching task transfers matchmaking-relevant structure into embeddings, improving downstream retrieval.
- **Mechanism:** NLI-style architecture learns to predict JD-JT correlation, injecting real platform matching signals.
- **Core assumption:** IoU threshold of 0.5 reliably separates negative from hard-negative pairs.
- **Evidence anchors:** JD task achieves 66.41 R@10 (+4.50 over baseline); task mimics matchmaking process in job recommendation.
- **Break condition:** Aggressive IoU threshold may miss hard negatives; loose threshold may mislabel semantically similar pairs as negative.

## Foundational Learning

- **Contrastive Learning (SimCSE-style):**
  - Why needed here: Understanding how contrastive loss structures embedding space explains why translation ranking works.
  - Quick check question: Given two semantically similar sentences and 5 distractors, can you sketch how the loss term would penalize low similarity to the correct pair?

- **Dual-Encoder Architecture:**
  - Why needed here: The base mUSE model uses dual encoders—understanding query/candidate separation is critical for retrieval efficiency.
  - Quick check question: Why does a dual-encoder enable faster retrieval than cross-encoder approaches at inference time?

- **KL Divergence for Distribution Comparison:**
  - Why needed here: The LBKL metric quantifies how predicted language proportions deviate from ground truth.
  - Quick check question: If ground truth is 50/50 Thai/English and predictions are 80/20, what direction would LBKL indicate?

## Architecture Onboarding

- **Component map:**
  - Base encoder: mUSEsmallCNN (69M params)
  - Task A (JT): Contrastive loss head, temperature τ = 0.05
  - Task B (JD): Cross-feature layer → 2 FC layers (512 dim) → binary classification
  - Task C (JF): Same FC stack → multi-label classification (28 classes)
  - Training: Batch size 512, Adam lr=3e-5, tasks cycled per mini-batch with equal weight

- **Critical path:**
  1. Preprocess job postings → extract (Thai title, English title, description, job fields)
  2. Generate negative pairs for JD task via IoU filtering
  3. Cycle: JT → JD → JF loss computation per batch
  4. Validate on JTG-Synonym (retrieval) and JTG-Occupation (classification)

- **Design tradeoffs:**
  - Smaller model (69M vs 567M BGE-M3) trades absolute accuracy for ~2x faster inference
  - Equal task weighting assumes balanced importance; may need reweighting if deployment prioritizes one task
  - IoU < 0.5 threshold is heuristic; could be tuned per domain

- **Failure signatures:**
  - Combined pool retrieval drops significantly vs separate pools → language bias not mitigated
  - LBKL increases on held-out domains → overfitting to training language distribution
  - JD task accuracy high but JTG-Synonym low → JD-JT correlation not transferring to title-level semantics

- **First 3 experiments:**
  1. **Reproduce ablation:** Train three single-task models (JT-only, JD-only, JF-only) and compare against multi-task to verify Table 2 claims on your data.
  2. **LBKL sanity check:** Plot language histograms (Figures 2-5 style) for your trained model on JTG-Synonym combined pool—confirm midpoint distribution.
  3. **Domain transfer test:** Evaluate LBKL on SCB-MT (general domain) to verify bias reduction generalizes beyond recruitment text.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Why does the Job Description-Title Matching (JD) task increase in-domain Language Bias Kullback–Leibler Divergence (LBKL) compared to the baseline, despite reducing bias in unseen domains?
- **Basis in paper:** Table 5 shows JD task raises in-domain LBKL to 1.26 from baseline 1.20.
- **Why unresolved:** Authors acknowledge increase but don't analyze why matching descriptions to titles amplifies language-specific signals in recruitment domain.
- **What evidence would resolve it:** Analysis of gradient updates during JD task to see if they reinforce language-specific correlations in descriptions.

### Open Question 2
- **Question:** Does the framework's reduction of language bias in recruitment domain come at the cost of bias reduction capabilities in general domains?
- **Basis in paper:** Discussion notes model lowers bias in recruitment tasks but LBKL on XQuAD-r (0.04) is slightly worse than baseline mUSE (0.02).
- **Why unresolved:** Paper doesn't investigate whether domain-specific fine-tuning degrades intrinsic ability to handle language-agnostic retrieval in non-specialized contexts.
- **What evidence would resolve it:** Comparative study of cross-lingual transfer learning dynamics to see if domain-specific fine-tuning creates "negative transfer."

### Open Question 3
- **Question:** To what extent does optimizing for the proposed LBKL metric conflict with retrieval accuracy in scenarios where language alignment is a valid semantic feature rather than a bias?
- **Basis in paper:** Authors state LBKL assesses language bias "without considering model accuracy," yet method optimizes for both.
- **Why unresolved:** In recruitment, query language often implies language requirement (e.g., Thai query for Bangkok customer service). Strictly penalizing language preference might lower practical utility.
- **What evidence would resolve it:** User study or simulation measuring "usefulness" where language requirements are explicitly part of job criteria, compared against LBKL scores.

## Limitations
- Relies on proprietary datasets (Jobtopgun, JTG-Synonym/Occupation) without public access, making full reproducibility difficult.
- Does not specify training duration (epochs/steps) or negative-to-positive sample ratio for JD task, which could affect implementation.
- Core assumption that all three tasks share meaningful semantic representations is not directly validated.

## Confidence
- **High Confidence:** Full multi-task model outperforms single-task variants (Table 2 ablation results); LBKL metric design and calculation are clearly specified.
- **Medium Confidence:** Method significantly reduces language bias (LBKL improvement from 1.20 → 0.40); depends heavily on data quality and translation pair accuracy.
- **Medium Confidence:** Multi-task learning improves generalizability via implicit regularization; direct evidence of shared feature learning is absent.

## Next Checks
1. **Reproduce ablation study:** Train single-task (JT-only, JD-only, JF-only) and full multi-task models on your data to verify the relative performance gains reported in Table 2.
2. **LBKL distribution validation:** Plot language histograms for your trained model on a combined Thai/English test pool to confirm the midpoint distribution and check for residual bias.
3. **Domain transfer test:** Evaluate the trained model's LBKL on a general-domain Thai-English dataset (e.g., SCB-MT or XQuAD-r) to verify that language bias reduction generalizes beyond the recruitment domain.