---
ver: rpa2
title: Analysis of LLM as a grammatical feature tagger for African American English
arxiv_id: '2502.06004'
source_url: https://arxiv.org/abs/2502.06004
tags:
- habitual
- bias
- multiple
- negation
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study compared NLP models for identifying AAE grammatical features,
  focusing on Habitual Be and Multiple Negation. It evaluated rule-based, transformer-based,
  and LLM models using zero-shot and few-shot approaches.
---

# Analysis of LLM as a grammatical feature tagger for African American English
## Quick Facts
- arXiv ID: 2502.06004
- Source URL: https://arxiv.org/abs/2502.06004
- Reference count: 19
- Key outcome: Rule-based and transformer models outperformed LLMs in identifying AAE grammatical features, with transformers achieving F1=0.92 for Habitual Be and rule-based models reaching F1=0.99 for Multiple Negation.

## Executive Summary
This study evaluates the effectiveness of different NLP models in identifying grammatical features specific to African American English (AAE), focusing on Habitual Be and Multiple Negation. The research compares rule-based, transformer-based, and large language model (LLM) approaches using both zero-shot and few-shot learning strategies. Results demonstrate that traditional rule-based and transformer models significantly outperform LLMs for these specific AAE features, challenging assumptions about LLM superiority in linguistic tasks involving dialectal variation.

## Method Summary
The researchers evaluated multiple NLP approaches for detecting AAE grammatical features by testing rule-based systems, transformer models, and LLMs across two specific linguistic phenomena: Habitual Be and Multiple Negation. They employed both zero-shot and few-shot learning paradigms to assess model performance. The evaluation compared F1-scores across different model types and analyzed systematic biases such as recency and formality effects in LLM outputs.

## Key Results
- Transformer models achieved an average F1-score of 0.92 for detecting Habitual Be
- Rule-based models reached F1-score of 0.99 for identifying Multiple Negation
- LLMs exhibited performance biases including recency effects and formality sensitivity

## Why This Works (Mechanism)
The superior performance of rule-based and transformer models stems from their explicit architectural design for pattern recognition in linguistic structures. Rule-based systems directly encode linguistic knowledge about AAE features, while transformer architectures excel at capturing contextual dependencies within sequences. LLMs, despite their broader linguistic capabilities, show performance degradation on dialect-specific features due to training data biases and architectural constraints that favor standard language patterns.

## Foundational Learning
1. **Habitual Be** - A grammatical feature in AAE indicating repeated or habitual actions
   - Why needed: Core AAE linguistic phenomenon distinguishing it from standard English
   - Quick check: Can identify "She be working" as habitual versus "She working" as progressive

2. **Multiple Negation** - Use of multiple negative markers in a single clause
   - Why needed: Common AAE construction that differs from prescriptive grammar rules
   - Quick check: Can recognize "He don't know nothing" as grammatically valid in AAE

3. **Zero-shot learning** - Model evaluation without task-specific training
   - Why needed: Tests model's general linguistic knowledge and adaptability
   - Quick check: Model performs above baseline on unseen task examples

4. **Few-shot learning** - Model evaluation with minimal task-specific examples
   - Why needed: Balances between zero-shot generalization and full fine-tuning
   - Quick check: Performance improves with 3-5 examples but remains below full training

## Architecture Onboarding
Component map: Rule-based models -> Feature extraction rules -> Classification; Transformer models -> Self-attention layers -> Contextual embeddings -> Classification; LLM models -> Pretrained weights -> Prompt engineering -> Classification
Critical path: Data preprocessing → Feature extraction → Model inference → Evaluation metrics
Design tradeoffs: Rule-based models offer high precision but limited generalization; transformers provide contextual understanding but require more computational resources; LLMs offer flexibility but show dialect-specific biases
Failure signatures: LLMs produce recency-biased outputs and struggle with informal AAE constructions; transformers may miss subtle contextual variations; rule-based systems fail on novel linguistic patterns
First experiments: 1) Test rule-based models on additional AAE features beyond Habitual Be and Multiple Negation; 2) Evaluate transformer performance across different AAE speaker demographics; 3) Investigate prompt engineering strategies to mitigate LLM biases in dialect detection

## Open Questions the Paper Calls Out
The study identifies several key uncertainties regarding the generalizability of findings across different LLM architectures and the robustness of zero-shot and few-shot approaches for AAE feature detection. Questions remain about how evaluation results would scale to the broader spectrum of AAE linguistic features and whether identified performance patterns hold across diverse speaker populations and contexts.

## Limitations
- Evaluation focused on only two specific AAE grammatical features
- Results may not generalize across different LLM architectures or broader AAE linguistic phenomena
- Limited assessment of real-world application scenarios and speaker demographic variations

## Confidence
- High confidence: Comparative performance ranking of rule-based and transformer models over LLMs for specific tested features
- Medium confidence: Identification of recency and formality biases in LLM performance, requiring further validation
- Low confidence: Generalizability of findings to broader AAE features or diverse speaker populations

## Next Checks
1. Expand evaluation to include additional AAE grammatical features and dialectal variations to assess model robustness across wider linguistic spectrum
2. Conduct cross-validation with diverse AAE speaker datasets to test model performance across different demographics and contexts
3. Investigate impact of domain-specific language use (informal vs. formal settings) on model accuracy and bias mitigation strategies