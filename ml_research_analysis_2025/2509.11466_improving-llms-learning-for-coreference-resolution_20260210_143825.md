---
ver: rpa2
title: Improving LLMs' Learning for Coreference Resolution
arxiv_id: '2509.11466'
source_url: https://arxiv.org/abs/2509.11466
tags:
- template
- document
- coreference
- training
- resolution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the limitations of Large Language Models
  (LLMs) in coreference resolution, particularly their tendency to hallucinate and
  underperform on the task. To overcome these challenges, the authors propose two
  novel techniques: Reversed Training with Joint Inference and Iterative Document
  Generation.'
---

# Improving LLMs' Learning for Coreference Resolution

## Quick Facts
- arXiv ID: 2509.11466
- Source URL: https://arxiv.org/abs/2509.11466
- Reference count: 13
- Key outcome: Two techniques—Reversed Training with Joint Inference and Iterative Document Generation—significantly improve LLM-based coreference resolution by reducing hallucination and improving accuracy.

## Executive Summary
This paper tackles the persistent problem of hallucination and underperformance in Large Language Models (LLMs) when applied to coreference resolution. The authors introduce two novel techniques: Reversed Training with Joint Inference, which augments the QA Template method with forward and backward training patterns plus singleton detection; and Iterative Document Generation, which eliminates hallucinations by generating cluster IDs for mentions one at a time. Evaluated on OntoNotes and CODI/CRAC datasets with Llama 3.1 and Qwen 2.5 models, the integrated approach achieves state-of-the-art performance, including perfect exact match and alignment pass rates, while also improving robustness on smaller datasets.

## Method Summary
The authors propose two complementary methods to address the weaknesses of LLM-based coreference resolution. First, Reversed Training with Joint Inference improves the QA Template approach by training on both forward ("A refers to B") and backward ("B refers to A") patterns, adding singleton detection, and combining predictions using weighted inference. Second, Iterative Document Generation solves the hallucination problem in the Document Template method by predicting one cluster ID per mention in sequence, rather than generating full cluster documents at once. Both methods are implemented using LoRA-based fine-tuning on Llama 3.1 8B and Qwen 2.5 7B models, with specific hyperparameters and joint inference weighting.

## Key Results
- Reversed Training with Joint Inference consistently improves performance on small datasets and is robust across model families.
- Iterative Document Generation achieves 100% exact match and alignment pass rates, outperforming full document generation.
- The integrated solution of both methods offers an effective and robust approach to LLM-based coreference resolution.

## Why This Works (Mechanism)
The core idea is to address the two main weaknesses of LLM-based coreference resolution: hallucination and underperformance. Reversed Training improves data efficiency and robustness by leveraging both forward and backward training patterns and singleton detection, enabling better generalization especially on smaller datasets. Iterative Document Generation eliminates hallucination by breaking down the task into sequential, constrained predictions, ensuring each step aligns with the source document.

## Foundational Learning
- **Coreference Resolution**: Identifying all mentions in a text that refer to the same real-world entity. *Why needed*: Central task the paper addresses. *Quick check*: Can you explain the difference between mention detection and coreference resolution?
- **Question-Answering Template (QA Template)**: Framing coreference as a QA task (e.g., "A refers to whom?"). *Why needed*: Common LLM approach; this paper improves it. *Quick check*: How does QA Template differ from traditional CR methods?
- **Document Template**: Generating cluster ID documents for coreference chains. *Why needed*: Another LLM approach; this paper fixes its hallucination problem. *Quick check*: What is the main drawback of full document generation?
- **LoRA (Low-Rank Adaptation)**: A parameter-efficient fine-tuning method. *Why needed*: Enables efficient adaptation of large LLMs. *Quick check*: How does LoRA differ from full fine-tuning?
- **Joint Inference**: Combining predictions from multiple models or patterns (e.g., forward/backward) using weighted voting. *Why needed*: Improves robustness and accuracy. *Quick check*: Why might forward and backward patterns give different answers?
- **Exact Match (EM) / Alignment Pass Rate**: Metrics for evaluating if generated coreference clusters match gold clusters exactly. *Why needed*: Standard evaluation for coreference resolution. *Quick check*: What's the difference between EM and CoNLL F1?

## Architecture Onboarding
- **Component Map**: Datasets (OntoNotes, CODI/CRAC) -> Template Conversion (QA/Document) -> LoRA Fine-tuning -> Inference (Joint/Iterative) -> Evaluation (UA scorer, Pass/EM/-SA)
- **Critical Path**: Template creation → LoRA fine-tuning with Reversed Training or Iterative Document Generation → Joint Inference or sequential prediction → Evaluation with UA scorer and Pass/EM/-SA
- **Design Tradeoffs**: QA Template is more generalizable and requires no mention annotations, but Document Template is currently more accurate. Reversed Training improves QA robustness; Iterative Document Generation fixes hallucination in Document Template.
- **Failure Signatures**: Hallucination in full document generation (Pass/EM < 100%); weak performance on small datasets without Reversed Training (low CoNLL scores); misalignment between generated and source documents.
- **First Experiments**:
  1. Run LoRA fine-tuning with Reversed Training on a small CR dataset (e.g., LIGHT) and evaluate CoNLL scores.
  2. Apply Iterative Document Generation to a sample OntoNotes document and check Pass/EM rates.
  3. Perform Joint Inference on forward/backward predictions and compare to single-pattern inference.

## Open Questions the Paper Calls Out
- Can the proposed methods generalize effectively to coreference resolution in non-English languages?
- How does performance scale with model size beyond 8B parameters?
- How robust are the methods when utilizing predicted mentions rather than gold mentions?
- Does the QA Template approach offer superior transfer learning capabilities for downstream tasks compared to the Document Template?

## Limitations
- Exact LoRA configuration and Joint Inference weight initialization are underspecified, making exact reproduction difficult.
- The methods have not been tested on larger-scale LLMs (70B+ parameters) or non-English languages.
- Only two model families (Llama 3.1 8B, Qwen 2.5 7B) were evaluated, limiting generalizability.
- Gold mentions were used; robustness with predicted mentions is unknown.

## Confidence
- **Reversed Training with Joint Inference improves QA Template performance** (Medium): Gains demonstrated, but reproducibility is hindered by underspecified details.
- **Iterative Document Generation eliminates hallucination and achieves perfect Pass/EM rates** (Medium): Empirical results show these metrics, but lack of full ablation and underspecified training details reduce confidence.
- **Integrated solution is more effective than existing LLM-based CR methods** (Medium): Relative to full document generation, improvements are clear, but comparison to other published CR methods is absent.

## Next Checks
1. Reproduce Joint Inference on QA Template with ablations: Train models with forward, backward, and singleton data separately, then apply Joint Inference with varied weight schemes; compare CoNLL scores to verify robustness.
2. Validate Iterative Document Generation on an additional small dataset: Apply the method to another small CR dataset (e.g., ECB+ or PreCo) and measure Pass rate, EM, and -SA scores to test generalizability.
3. Benchmark against a strong fine-tuned baseline: Train a SpanBERT or other SOTA CR model on the same OntoNotes and CODI/CRAC splits; compare results to LLM-based methods for a fairer effectiveness assessment.