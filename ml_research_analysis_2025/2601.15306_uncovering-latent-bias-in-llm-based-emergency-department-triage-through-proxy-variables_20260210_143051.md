---
ver: rpa2
title: Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy
  Variables
arxiv_id: '2601.15306'
source_url: https://arxiv.org/abs/2601.15306
tags:
- patient
- negative
- positive
- bias
- proxy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a proxy-variable-based framework to uncover
  hidden bias in large language model (LLM) triage predictions for emergency department
  patients. Using 32 patient-level proxy variables paired with positive and negative
  qualifiers, the authors evaluate shifts in LLM-assigned Emergency Severity Index
  (ESI) scores using MIMIC datasets.
---

# Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables

## Quick Facts
- **arXiv ID:** 2601.15306
- **Source URL:** https://arxiv.org/abs/2601.15306
- **Reference count:** 15
- **Primary result:** LLMs exhibit statistically significant ESI shifts for 75% of 32 tested proxy variables, revealing hidden bias in triage predictions.

## Executive Summary
This study introduces a proxy-variable-based framework to uncover hidden bias in large language model (LLM) triage predictions for emergency department patients. Using 32 patient-level proxy variables paired with positive and negative qualifiers, the authors evaluate shifts in LLM-assigned Emergency Severity Index (ESI) scores using MIMIC datasets. Results reveal that LLMs systematically alter patient acuity assessments based on proxy variable presence, with 75% of variables producing statistically significant bias between positive and negative framings. Some variables cause polarity-independent shifts, indicating the model reacts to tokens rather than semantic meaning. The findings demonstrate that LLMs trained on clinical data still exhibit hidden biases through proxy variables, risking inappropriate resource allocation and potential inequities in care. The methodology provides a reproducible approach to quantify and detect such hidden biases in medical AI systems.

## Method Summary
The methodology evaluates LLM bias by measuring ESI score shifts when proxy variable qualifiers are added to patient scenarios. The authors use 32 proxy variables with paired positive/negative qualifiers, construct patient scenarios from MIMIC-IV-ED Demo records (220 encounters), and query gpt-4o-mini with a system prompt defining ED triage nurse role. The LLM outputs ESI 1-5 scores with JSON-formatted justifications, which are compared across three conditions (default, positive, negative) per patient-proxy pair. Mean ESI shifts and 95% confidence intervals are computed, and bias is classified as polarity-dependent, polarity-independent, or negligible based on statistical significance.

## Key Results
- 75% of 32 tested proxy variables produced statistically significant ESI shifts between positive and negative framings
- Some variables caused polarity-independent shifts, indicating the model reacts to token presence rather than semantic meaning
- Population-level proxy variable distributions (e.g., ambulance arrival by race) can propagate to demographic disparities in model outputs
- The framework successfully detected hidden bias without using protected characteristics as direct inputs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Proxy variables serve as conduits for hidden bias by correlating with protected characteristics while appearing clinically neutral.
- **Mechanism:** Non-clinical variables (e.g., insurance type, arrival mode, health literacy) are processed by the LLM as context tokens. The model has learned statistical associations between these proxies and outcomes during pre-training, causing systematic ESI shifts without explicit demographic inputs.
- **Core assumption:** Proxy variables in the prompt are processed as semantically meaningful context rather than noise, and training data contained spurious correlations between proxies and clinical outcomes.
- **Evidence anchors:**
  - [abstract] "LLMs systematically alter patient acuity assessments based on proxy variable presence, with 75% of variables producing statistically significant bias between positive and negative framings."
  - [section 2] "Proxy variables are features used in AI models that do not directly measure the underlying patient characteristics of interest but serve as indirect indicators... These variables can introduce bias if they correlate with disadvantaged groups such as race or gender."
  - [corpus] Related work "From Promising Capability to Pervasive Bias" similarly identifies pervasive bias in LLM-based ED triage, supporting the domain relevance of proxy-mediated discrimination.
- **Break condition:** If proxy variables are removed from input or explicitly instructed to be ignored, bias effects should attenuate or disappear.

### Mechanism 2
- **Claim:** LLMs exhibit polarity-independent acuity shifts, indicating reaction to token presence rather than semantic understanding.
- **Mechanism:** Certain tokens trigger magnitude shifts in ESI predictions regardless of whether they are framed positively or negatively. This suggests the model responds to surface-level lexical cues without processing the qualifier's semantic valence.
- **Core assumption:** The model has not learned robust representations of negation or qualification for clinical context modifiers.
- **Evidence anchors:**
  - [abstract] "Some variables cause polarity-independent shifts, indicating the model reacts to tokens rather than semantic meaning."
  - [section 4.3] "Regardless of whether it is framed positively or negatively, the mere presence of certain token associated with a proxy variable shifts the model's Emergency Severity Index (ESI) predictions in the same direction. This effect suggests that the LLM does not understand the semantical meaning of the text."
  - [corpus] Corpus evidence on this specific mechanism is limited; no directly comparable token-sensitivity analyses found in neighbor papers.
- **Break condition:** If semantic understanding were intact, positive and negative qualifiers of the same variable would produce opposite-direction ESI shifts.

### Mechanism 3
- **Claim:** Population-level disparities in proxy variable distributions propagate to differential model outputs across demographic groups.
- **Mechanism:** Socially mediated differences (e.g., White patients more likely to arrive by ambulance at same acuity level) combine with learned proxy-outcome associations, producing "accidental bias" where identical clinical presentations receive different acuity assessments by group.
- **Core assumption:** Proxy variable distributions differ by race, socioeconomic status, or other protected attributes in the deployment population.
- **Evidence anchors:**
  - [section 4.4] "White patients are significantly more likely to arrive by ambulance for the same acuity level than Black patients. Because the LLM systematically interprets ambulance arrival as indicative of higher severity... this population-level difference leads to accidental bias."
  - [section 4.4, Figure 5] Shows comparison of ambulance utilization and odds ratios by race across acuity levels.
  - [corpus] Related papers focus on model performance rather than proxy-mediated demographic disparities; direct corpus support for this propagation mechanism is weak.
- **Break condition:** If proxy distributions were uniform across demographic groups, or if proxy-outcome associations were removed from model behavior, demographic disparities in outputs would not emerge.

## Foundational Learning

- **Concept: Emergency Severity Index (ESI)**
  - **Why needed here:** The paper's entire evaluation framework depends on understanding ESI as a 5-level triage scale where lower scores indicate higher acuity, and that ESI should be determined solely by clinical presentation and resource needs—not proxy variables.
  - **Quick check question:** If a patient's ESI shifts from 3 to 2 after adding "arrived by ambulance," what does this indicate about the model's behavior?

- **Concept: Proxy Variables vs. Confounders**
  - **Why needed here:** Understanding that proxies are not themselves the bias source but correlate with protected characteristics is essential for interpreting why removing direct demographic inputs does not eliminate bias.
  - **Quick check question:** Why might "insurance status" predict triage outcomes even if race is removed from the input?

- **Concept: Statistical Significance of Shift Magnitudes**
  - **Why needed here:** The paper reports 75% of variables showing statistically significant bias at α=0.05 using confidence intervals; understanding this framework is necessary to interpret Figure 3 and Figure 4.
  - **Quick check question:** If a proxy variable's 95% CI for ESI shift crosses zero, what conclusion follows about polarity-dependent bias for that variable?

## Architecture Onboarding

- **Component map:**
  Proxy Variable Set (32 variables) -> Qualifier Generator -> Manual Review -> Patient Scenario Constructor -> LLM ESI Predictor -> Shift Calculator

- **Critical path:** Variable selection → Qualifier generation → Manual review for clinical confounds → Scenario construction → LLM inference (ESI labels withheld) → Post-hoc label comparison → Shift magnitude + significance analysis → Bias categorization (polarity-dependent, polarity-independent, negligible).

- **Design tradeoffs:**
  Using gpt-4o-mini (not GPT-4) limits generalizability to higher-capacity models.
  Demo dataset (220 records) enables reproducibility but may lack statistical power; full MIMIC requires credentialed access.
  Manual qualifier review reduces confounds but introduces human judgment variability.

- **Failure signatures:**
  Qualifiers inadvertently containing clinical information (e.g., mentioning symptoms) would confound proxy effect with legitimate acuity signal.
  If ESI labels leaked during inference, model could exhibit data contamination.
  Polarity-independent shifts appearing across most variables would suggest prompt engineering failure rather than model bias.

- **First 3 experiments:**
  1. **Baseline replication:** Run the 32 proxy variables on MIMIC-IV-ED Demo with gpt-4o-mini using provided system prompt; verify 75% significant-shift finding reproduces.
  2. **Model substitution:** Replace gpt-4o-mini with a different LLM (e.g., Claude, open-source Llama) to test whether bias patterns persist across architectures.
  3. **Proxy ablation:** Select top 5 polarity-dependent variables and test with qualifiers explicitly neutralized (e.g., "arrived by ambulance" vs. "transportation method: ambulance") to isolate token presence from semantic framing effects.

## Open Questions the Paper Calls Out

- **Can fine-tuning or prompt-based interventions effectively mitigate proxy variable bias in LLM triage systems without degrading clinical accuracy?**
  - **Basis in paper:** [explicit] The conclusion states "more needs to be done to ensure the safe and responsible deployment of AI technologies in clinical settings" and the methodology only provides detection, not mitigation.
  - **Why unresolved:** The framework quantifies bias but offers no intervention strategy; it is unclear whether debiasing would preserve model performance on legitimate clinical cues.
  - **What evidence would resolve it:** A controlled experiment comparing baseline and debiased model performance on both bias metrics (proxy variable shift) and clinical accuracy (agreement with expert triage).

- **Do polarity-independent acuity shifts reflect a fundamental limitation of transformer architectures, or can they be eliminated through targeted training?**
  - **Basis in paper:** [inferred] The paper observes that "the LLM does not understand the semantical meaning of the text, but instead reacts to the presence of certain tokens" but does not investigate whether this is architectural or remediable.
  - **Why unresolved:** The mechanism driving token-based (rather than meaning-based) shifts is characterized but not explained at the representation level.
  - **What evidence would resolve it:** Ablation studies comparing attention patterns for positive versus negative qualifiers, coupled with training experiments on semantically contrastive pairs.

- **How generalizable are proxy variable bias patterns across different LLM families and clinical domains beyond ED triage?**
  - **Basis in paper:** [inferred] Only gpt-4o-mini was evaluated, and the study is limited to Emergency Severity Index scoring in a single institution's datasets.
  - **Why unresolved:** It is unknown whether findings extend to open-source models (e.g., Llama, Mistral) or to other clinical decision tasks (e.g., ICU risk prediction, discharge planning).
  - **What evidence would resolve it:** Replication of the proxy variable framework across multiple LLM architectures and at least one additional clinical prediction task with distinct data sources.

## Limitations

- The study's findings hinge on the assumption that proxy variables are processed as semantically meaningful context, but polarity-independent shifts suggest the model may be responding to token presence rather than genuine semantic understanding.
- The reliance on demo datasets (220 records) limits statistical power and generalizability to real-world deployment populations where proxy variable distributions may differ substantially.
- The claim that population-level proxy distributions directly cause demographic disparities in model outputs is theoretically sound but under-supported by corpus evidence and would require additional empirical validation.

## Confidence

- **High confidence:** The core finding that LLMs systematically alter ESI predictions based on proxy variable presence (75% statistically significant shifts) is well-supported by the experimental design and results.
- **Medium confidence:** The interpretation of polarity-independent shifts as evidence of token-level rather than semantic processing is plausible but could alternatively reflect limitations in the LLM's negation handling or the manual qualifier refinement process.
- **Low confidence:** The claim that population-level proxy distributions directly cause demographic disparities in model outputs is theoretically sound but under-supported by corpus evidence and would require additional empirical validation.

## Next Checks

1. Test the top 5 polarity-dependent variables using explicitly neutralized qualifiers ("arrived by ambulance" vs. "transportation method: ambulance") to isolate token presence from semantic framing effects.
2. Conduct the full proxy-variable evaluation on a larger, non-demo MIMIC dataset to verify that bias patterns persist at scale and across diverse patient populations.
3. Compare proxy bias patterns across multiple LLM architectures (gpt-4o-mini, Claude, Llama) to determine whether observed effects are model-specific or represent a broader class problem.