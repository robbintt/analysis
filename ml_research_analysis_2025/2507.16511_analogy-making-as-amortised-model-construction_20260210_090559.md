---
ver: rpa2
title: Analogy making as amortised model construction
arxiv_id: '2507.16511'
source_url: https://arxiv.org/abs/2507.16511
tags:
- analogy
- abstract
- child
- construction
- modules
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes that humans solve the on-demand model construction
  problem by reusing past construals through analogies, formalised as partial MDP
  homomorphisms. This allows them to amortise the computational costs of both model
  construction and planning.
---

# Analogy making as amortised model construction

## Quick Facts
- arXiv ID: 2507.16511
- Source URL: https://arxiv.org/abs/2507.16511
- Reference count: 11
- The paper proposes that humans solve the on-demand model construction problem by reusing past construals through analogies, formalised as partial MDP homomorphisms.

## Executive Summary
The paper introduces a framework for understanding how humans and artificial agents can efficiently construct models of novel situations by reusing past experiences through analogical reasoning. The core insight is that analogy can be formalized as partial homomorphisms between Markov decision processes (MDPs), enabling structural reuse of solution-relevant components. This approach addresses the computational challenge of on-demand model construction by amortizing the costs of both model building and planning across past experiences.

The framework suggests that agents build an internal library of abstract MDP modules over time, which can be recomposed to create new models for novel situations. These modules encode not just MDP fragments but also associated solutions (policies), enabling transfer of prior computations. The approach offers a path toward more robust artificial agents capable of flexible adaptation to novel situations while avoiding the computational intractability of building models from scratch.

## Method Summary
This is a position paper proposing a conceptual framework rather than presenting empirical results or a specific algorithm. The authors formalize analogy as partial MDP homomorphisms and sketch a three-stage decomposition for model construction: construal inference (mapping current situation to library modules), policy inference (transferring and adapting policies from matched modules), and library update (refining the module collection based on experience). The framework draws on existing work in MDP homomorphisms, modular MDP construction, and program synthesis, but does not provide concrete implementation details or training procedures.

## Key Results
- Proposes partial MDP homomorphisms as a formal mechanism for analogical model construction
- Introduces the concept of amortizing model construction costs through library-based reuse of abstract modules
- Addresses the frame problem by focusing on solution-relevant structure rather than complete environmental models
- Suggests a framework for combining modular reuse with flexible adaptation across domains

## Why This Works (Mechanism)

### Mechanism 1: Partial MDP Homomorphisms as Analogical Mappings
- Claim: Analogy can be formalized as partial homomorphisms between source and target MDPs, enabling structural reuse.
- Mechanism: Define a mapping ϕ = (f(s), g(a)) that maps states and actions from a source construal to a target construal. This mapping preserves transition and reward structures only over relevant subsets of the state-action space, amortizing model construction by reusing high-level abstractions.
- Core assumption: The source and target domains share solution-relevant structural essence (approximate homomorphism exists).
- Evidence anchors: Formal definition in Section 3.1 with door-key → email-password example.
- Break condition: If source and target have no shared structure, homomorphism conditions fail.

### Mechanism 2: Modular Library Construction and Reuse
- Claim: A library of abstract MDP modules provides amortized inductive bias for new construals and policies.
- Mechanism: Extract consistently useful fragments from past construals into stand-alone modules. For new situations, condition on the library to infer construal and policy, then update the library based on experience.
- Core assumption: Useful regularities recur across tasks, and modules can be composed without extensive re-calibration.
- Evidence anchors: Three-stage decomposition described in Section 3.2.
- Break condition: If modules are over-abstracted or poorly composed, transferred policies may lead to degraded performance.

### Mechanism 3: Policy and Planning Amortization via Transferred Abstractions
- Claim: Transferring action abstractions and partial policies through analogy reduces planning cost in new construals.
- Mechanism: When an analogy successfully maps source abstractions to target, associated policy fragments are transferred, biasing policy search away from unproductive actions.
- Core assumption: The transferred abstractions remain valid in the new context.
- Evidence anchors: Discussion of policy transfer constraining search in Sections 3.1 and 3.2.
- Break condition: If analogy is only approximate, transferred policy may be suboptimal.

## Foundational Learning

- Concept: **Markov Decision Process (MDP) Basics** (states, actions, transitions, rewards, policies).
  - Why needed here: Analogy is formalized as mappings between MDPs; understanding MDP components is essential.
  - Quick check question: Given a simple grid-world, can you define its state space, action space, transition function, and a reward function for reaching a goal?

- Concept: **SMDP Homomorphisms** (structure-preserving maps between decision processes).
  - Why needed here: The core formalization of analogy as partial homomorphism relies on algebraic notions of homomorphism.
  - Quick check question: If a mapping f(s) merges two states s1 and s2, what condition must the transition dynamics satisfy for f to be a valid homomorphism?

- Concept: **Amortized Inference** (reusing past computation to reduce future inference cost).
  - Why needed here: The framework explicitly frames analogy and library use as amortization of construction and planning costs.
  - Quick check question: In a Bayesian inference setting, how does learning an amortized inference network reduce per-sample computation compared to running MCMC each time?

## Architecture Onboarding

- Component map:
  Source Memory -> Analogy Engine -> Construal Assembler -> Policy Adapter -> Execution -> Library Refactorer

- Critical path:
  1. Encounter new situation; access low-level dynamics
  2. Analogy Engine retrieves candidate modules from Library
  3. Construct partial homomorphisms for each candidate; evaluate fit
  4. Construal Assembler composes best-fitting modules into new construal
  5. Policy Adapter transfers policy fragments and performs residual planning
  6. Execute policy; collect outcomes
  7. Library Refactorer extracts refined modules based on success/failure

- Design tradeoffs:
  - Library granularity vs. reuse frequency: Fine-grained modules increase composability but raise search and alignment costs
  - Homomorphism strictness vs. transfer risk: Strict mappings ensure policy validity but are rarer; partial mappings increase coverage but risk performance loss
  - Library update frequency vs. stability: Frequent updates enable fast adaptation but may introduce instability

- Failure signatures:
  - Repeated selection of irrelevant modules → analogy search fails to find adequate homomorphisms
  - Composed construal has inconsistent interfaces → planning fails or produces invalid actions
  - Transferred policy performs significantly worse than random exploration → homomorphism is too approximate
  - Library grows without useful abstraction → refactorer not extracting generalizable structure

- First 3 experiments:
  1. **Toy domain replication**: Implement door-key → email-password analogy in simplified grid-world with discrete states/actions
  2. **Library ablation**: Compare agents with and without module library on construction time and policy performance across key-door variants
  3. **Compositional scaling**: Test multi-module composition (door + device) in novel office environment; measure planning cost reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can agents balance the reuse of familiar structure against the discovery of genuinely novel construals in environments where no clear analogy applies?
- Basis in paper: "In particular, it remains an open question how agents might balance the reuse of familiar structure against the discovery of genuinely novel construals in environments where no clear analogy applies."
- Why unresolved: The paper proposes amortization through analogy but does not address when analogy should be abandoned in favor of de novo model construction.
- What evidence would resolve it: A formal criterion or quantitative threshold indicating when module search should terminate and novel construal begin.

### Open Question 2
- Question: What are the computational mechanisms for extracting, composing, and abstracting MDP modules over time?
- Basis in paper: "Key challenges include formalizing the processes by which modules are extracted, composed, and abstracted over time..."
- Why unresolved: The paper sketches a framework but provides no algorithmic account of how fragments are identified as reusable.
- What evidence would resolve it: A concrete algorithm implementing module extraction and composition, demonstrating systematic generalization.

### Open Question 3
- Question: How can agents perform tractable search over analogies while maintaining flexibility?
- Basis in paper: "...and identifying mechanisms for searching over analogies that are both flexible and computationally tractable."
- Why unresolved: Searching over a potentially large library to find partial MDP homomorphisms is computationally expensive.
- What evidence would resolve it: An efficient search procedure with bounded complexity, validated against brute-force methods.

## Limitations
- The framework remains conceptual without concrete algorithms for analogy search, module extraction, or library maintenance
- No mechanism specified for quantifying or bounding transfer error when homomorphisms are only approximate
- Claims about human cognitive mechanisms are speculative and lack empirical validation

## Confidence
- High confidence: The core observation that analogy can be formalized as partial MDP homomorphisms
- Medium confidence: The proposed decomposition of the problem into construal inference, policy transfer, and library update
- Low confidence: The claim that this framework directly explains human model construction or will yield more robust artificial agents

## Next Checks
1. Implement the door-key to email-password analogy in a discrete gridworld and verify that partial homomorphism construction yields successful policy transfer
2. Compare agents with and without a module library on a suite of tasks with shared structure, measuring construction time and policy performance
3. Test multi-module composition in a novel domain (e.g., office environment with doors, devices, and objects) and quantify planning cost reduction versus a baseline without analogy