---
ver: rpa2
title: 'Beyond Unified Models: A Service-Oriented Approach to Low Latency, Context
  Aware Phonemization for Real Time TTS'
arxiv_id: '2512.08006'
source_url: https://arxiv.org/abs/2512.08006
tags:
- speech
- persian
- phonemization
- lightweight
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of achieving both high-quality,
  context-aware phonemization and real-time performance in lightweight TTS systems,
  particularly for languages like Persian that require nuanced context-dependent pronunciation.
  The proposed solution is a service-oriented architecture that decouples heavy, context-aware
  phonemization modules (such as homograph disambiguation and Ezafe detection) from
  the core TTS engine, allowing them to operate as independent services via inter-process
  communication.
---

# Beyond Unified Models: A Service-Oriented Approach to Low Latency, Context Aware Phonemization for Real Time TTS

## Quick Facts
- arXiv ID: 2512.08006
- Source URL: https://arxiv.org/abs/2512.08006
- Reference count: 30
- Primary result: Service-oriented architecture achieves PER 4.80%, Ezafe F1 90.08%, homograph accuracy 77.67%, RTF 0.167 on Persian TTS

## Executive Summary
This paper presents a service-oriented architecture for Persian text-to-speech (TTS) that achieves both high-quality context-aware phonemization and real-time performance. The system decouples computationally heavy context-aware phonemization modules (homograph disambiguation and Ezafe detection) from the core TTS engine, running them as independent services via inter-process communication. This design enables the use of advanced phonemization models without embedding their computational overhead directly into the TTS runtime. The proposed system demonstrates that it's possible to maintain real-time responsiveness while achieving high phonemization accuracy, making it suitable for offline and end-device applications like screen readers.

## Method Summary
The authors build upon PiperTTS, a lightweight phoneme-to-speech model, and enhance it with two context-aware phonemization modules: homograph disambiguation and Ezafe detection. Rather than integrating these modules directly into the TTS pipeline, they implement them as separate services communicating via inter-process pipes. The Ezafe detection uses an ALBERT-based model fine-tuned on SpaCy-tagged ManaTTS text, exported to ONNX for efficient CPU inference. Homograph disambiguation employs a statistical model based on contextual co-occurrence patterns. The service-oriented architecture allows these heavy modules to operate independently while maintaining real-time performance through persistent service processes. The Piper P2S model is fine-tuned on corrected phoneme sequences to adapt to the improved phonemization.

## Key Results
- Phoneme Error Rate (PER): 4.80% - significantly lower than baseline unified models
- Ezafe F1 Score: 90.08% - demonstrates high accuracy in detecting Ezafe markers
- Real-Time Factor (RTF): 0.167 - maintains real-time performance on CPU
- Homograph Accuracy: 77.67% - improved disambiguation compared to baseline

## Why This Works (Mechanism)
The service-oriented architecture works by separating concerns: computationally expensive context-aware phonemization tasks are isolated from the real-time TTS engine. This decoupling allows the use of sophisticated models (ALBERT for Ezafe, statistical models for homographs) without compromising the core TTS's low-latency requirements. By running these modules as persistent services with efficient inter-process communication, the system avoids the startup overhead of loading heavy models for each request while keeping the real-time critical path lightweight.

## Foundational Learning
- **Service-oriented architecture**: Why needed - enables use of heavy models without blocking real-time performance; Quick check - verify IPC overhead doesn't exceed 10% of total latency
- **Inter-process communication via pipes**: Why needed - provides low-overhead communication between services; Quick check - measure pipe latency under load
- **Context-aware phonemization**: Why needed - Persian requires nuanced pronunciation based on context; Quick check - validate Ezafe detection on morphologically complex sentences
- **ONNX model export**: Why needed - enables efficient CPU inference without GPU dependencies; Quick check - confirm model runs within 50ms per sentence
- **ALBERT-based sequence classification**: Why needed - captures long-range dependencies for Ezafe detection; Quick check - verify F1 score meets 90% threshold
- **Statistical homograph disambiguation**: Why needed - resolves pronunciation ambiguity based on contextual patterns; Quick check - test on sentences with multiple homographs

## Architecture Onboarding

**Component map**: Text -> Pipe IPC -> Ezafe Service -> Pipe IPC -> Homograph Service -> Pipe IPC -> PiperTTS -> Speech

**Critical path**: The real-time critical path consists of the PiperTTS model and the inter-process communication overhead. The phonemization services operate in parallel to the main TTS process, with communication latency being the primary bottleneck.

**Design tradeoffs**: The service-oriented approach trades some IPC overhead for the ability to use sophisticated phonemization models. Alternative designs (direct integration) would either sacrifice accuracy or real-time performance. The choice of pipe-based IPC balances low overhead with cross-platform compatibility.

**Failure signatures**: 
- High RTF (>0.2): indicates IPC overhead or service startup delays
- Low Ezafe F1 (<85%): suggests ALBERT model misconfiguration or data issues
- Poor homograph accuracy (<70%): indicates statistical model or context window problems

**First experiments**:
1. Measure IPC latency between text input and phoneme output with mocked phonemization services
2. Validate Ezafe detection accuracy on a held-out test set from ManaTTS
3. Profile RTF of the complete system under varying text complexity

## Open Questions the Paper Calls Out

**Open Question 1**: How can higher-level prosodic and expressive features be enhanced within lightweight phoneme-to-speech (P2S) components without increasing computational cost or model size? The authors note that lightweight P2S models have limited capacity to capture higher-level prosodic features and call for research to improve naturalness while maintaining efficiency.

**Open Question 2**: What specific subjective evaluation protocols can effectively isolate phonemization accuracy from other dimensions of naturalness like fluency and prosody? The authors argue that current MOS tests blend pronunciation correctness with voice quality and intonation, making it difficult to assess phonemization accuracy independently.

**Open Question 3**: To what extent can implementing request-level parallelism or asynchronous processing in the service layer further reduce overall system latency and improve scalability? The authors identify these optimization strategies as specific avenues for future enhancement, noting that the decoupled architecture is well-suited for such improvements.

## Limitations
- The lightweight P2S model has limited capacity to capture higher-level prosodic and expressive features
- Current MOS evaluations blend phonemization accuracy with other naturalness dimensions, making isolated assessment difficult
- The architecture hasn't been optimized for request-level parallelism or asynchronous processing

## Confidence
- PER achievement: Medium - plausible given service architecture but lacks full hyperparameter disclosure
- Ezafe F1 score: Medium - dependent on ALBERT fine-tuning details not fully specified
- RTF claim: Medium - ONNX export supports CPU inference but IPC overhead not fully characterized
- MOS score: Low - lacks context on listener panel size and test conditions

## Next Checks
1. Reimplement the ALBERT-based Ezafe detector using the ManaTTS corpus and SpaCy labels, tuning learning rate and sequence length to match the reported F1 score.
2. Reconstruct the homograph disambiguation service, specifying the co-occurrence database format and context window, then validate against the 77.67% accuracy claim.
3. Profile the service-oriented IPC pipeline end-to-end to confirm RTF remains below 0.167 on representative hardware, accounting for pipe communication overhead.