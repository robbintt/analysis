---
ver: rpa2
title: 'R-Capsule: Compressing High-Level Plans for Efficient Large Language Model
  Reasoning'
arxiv_id: '2509.22131'
source_url: https://arxiv.org/abs/2509.22131
tags:
- reasoning
- plan
- latent
- steps
- capsule
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Reasoning Capsules (R-Capsule), a framework
  that improves efficiency and accuracy of LLM reasoning by compressing high-level
  plans into compact latent tokens (capsules) while keeping execution steps lightweight.
  Inspired by the Information Bottleneck principle, the approach enforces minimality
  through a low-capacity bottleneck and sufficiency via dual objectives (task loss
  and plan reconstruction loss).
---

# R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning

## Quick Facts
- **arXiv ID**: 2509.22131
- **Source URL**: https://arxiv.org/abs/2509.22131
- **Reference count**: 20
- **Key outcome**: Achieves +3.3% to +4.1% accuracy gains over CoT baselines with 48% fewer tokens and 2.12x faster inference

## Executive Summary
R-Capsule introduces a framework for compressing high-level reasoning plans into compact latent tokens (capsules) while maintaining execution detail in LLM reasoning. The method applies the Information Bottleneck principle to enforce plan minimality through a low-capacity bottleneck, with sufficiency ensured via dual objectives (task loss and plan reconstruction loss). By separating planning compression from execution, R-Capsule achieves significant improvements in both accuracy and efficiency over standard Chain-of-Thought fine-tuning baselines.

## Method Summary
The R-Capsule framework operates by training a low-capacity Transformer (the capsule generator) to compress high-level plans into a small set of latent tokens, then concatenating these capsules with execution steps as soft prompts for the main LLM. The training objective includes both the standard task loss and a plan reconstruction loss, ensuring capsules capture sufficient plan information while being minimal in representation. The architecture uses a small decoder-only model to generate capsules, which are then fed to a larger pretrained LLM via soft prompting, allowing efficient reasoning without sacrificing accuracy.

## Key Results
- Outperforms Chain-of-Thought fine-tuning baselines by +3.3% to +4.1% absolute accuracy
- Achieves 48% reduction in token count and 2.12x faster inference speed
- Ablation studies confirm plan-only compression is optimal; compressing execution steps degrades performance

## Why This Works (Mechanism)
R-Capsule leverages the Information Bottleneck principle by forcing the model to compress high-level plans into minimal latent representations (capsules) that still retain sufficient information for task completion. This compression reduces redundancy in reasoning traces while maintaining critical strategic information. The dual objective training ensures that capsules are both minimal (low capacity bottleneck) and sufficient (can reconstruct the original plan), creating an optimal balance between compression and expressiveness.

## Foundational Learning
- **Information Bottleneck Principle**: A framework for extracting relevant information by compressing inputs while preserving task-relevant signals. Why needed: Provides theoretical justification for capsule compression and ensures minimal yet sufficient representations.
- **Chain-of-Thought Reasoning**: The process of generating intermediate reasoning steps to improve LLM performance on complex tasks. Why needed: Establishes the baseline approach that R-Capsule improves upon.
- **Soft Prompting**: A technique for injecting task-specific information into LLMs without fine-tuning the full model. Why needed: Enables efficient integration of compressed capsules into the reasoning process.
- **Latent Variable Models**: Models that work with compressed representations rather than raw inputs. Why needed: Underlies the capsule generation and usage mechanism.
- **Dual Objective Training**: Optimization with multiple loss functions to balance competing goals. Why needed: Ensures capsules are both minimal and sufficient through task loss and reconstruction loss.
- **Decoder-only Transformer Architecture**: The standard architecture for autoregressive language models. Why needed: The framework assumes this architecture for capsule generation and reasoning.

## Architecture Onboarding
**Component Map**: High-level plans -> Capsule Generator (small Transformer) -> Latent capsules -> Concatenated with execution steps -> Main LLM (pretrained) -> Final output

**Critical Path**: Plan input → capsule generation (bottleneck compression) → capsule + execution steps → reasoning output. The capsule generator is the performance-critical component, as it must compress plans efficiently while maintaining sufficiency.

**Design Tradeoffs**: Low capsule capacity (K tokens, small d) improves efficiency but risks losing critical information; higher capacity increases computational cost. The framework chooses K=2 as optimal based on experiments. The separation of planning from execution allows compression where it's most beneficial.

**Failure Signatures**: Performance degradation occurs when capsule capacity is too low (losing critical plan information) or when execution steps are compressed (losing inductive biases). The framework shows asymmetric sensitivity to compression in different reasoning stages.

**First Experiments**:
1. Compare K=1,2,3,4 capsules on accuracy and efficiency to determine optimal capacity
2. Test R-Capsule on a held-out dataset to evaluate generalization
3. Measure reconstruction quality of capsules to verify sufficiency constraint

## Open Questions the Paper Calls Out
None

## Limitations
- All experiments use decoder-only models; generalization to encoder-decoder architectures remains untested
- Fixed capsule capacity (K=2) without exploration of how task complexity affects optimal capsule size
- No cross-domain transfer experiments to evaluate capsule generalizability across reasoning domains
- Asymmetric performance between plan and execution compression lacks mechanistic explanation

## Confidence
- **Experimental Results**: High - Extensive benchmarking on multiple datasets with clear performance gains
- **Theoretical Foundation**: Medium - Information Bottleneck principle provides justification but practical implementation details are limited
- **Generalizability**: Low - Limited to decoder-only models with no cross-domain or cross-architecture evaluation
- **Scalability**: Medium - Fixed capsule size may not scale to more complex reasoning tasks

## Next Checks
1. Test R-Capsule on encoder-decoder architectures (T5, BART) to verify architectural generalizability
2. Conduct systematic experiments varying capsule capacity (K, d) across tasks with different plan lengths to identify scaling relationships
3. Perform cross-domain transfer experiments where capsules trained on mathematical reasoning are tested on commonsense reasoning tasks