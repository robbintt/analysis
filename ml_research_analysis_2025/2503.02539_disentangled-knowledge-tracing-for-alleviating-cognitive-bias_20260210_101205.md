---
ver: rpa2
title: Disentangled Knowledge Tracing for Alleviating Cognitive Bias
arxiv_id: '2503.02539'
source_url: https://arxiv.org/abs/2503.02539
tags:
- uni00000013
- knowledge
- student
- uni00000011
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles cognitive bias in Knowledge Tracing (KT), which\
  \ causes overperformers to be under-challenged and underperformers to be overwhelmed\
  \ due to unbalanced question-concept distributions. The bias is traced to a confounder\u2014\
  the historical correct rate distribution\u2014that distorts student representation."
---

# Disentangled Knowledge Tracing for Alleviating Cognitive Bias

## Quick Facts
- **arXiv ID**: 2503.02539
- **Source URL**: https://arxiv.org/abs/2503.02539
- **Reference count**: 40
- **One-line primary result**: DisKT outperforms 16 baselines in AUC, ACC, and RMSE on 11 benchmarks, significantly alleviating cognitive bias and shielding guessing/mistaking effects.

## Executive Summary
This paper addresses cognitive bias in Knowledge Tracing (KT), where unbalanced question-concept distributions lead to overperformers being under-challenged and underperformers being overwhelmed. The authors identify the historical correct rate distribution as a confounder that distorts student representation. They propose Disentangled Knowledge Tracing (DisKT), a causal model that separately tracks familiar and unfamiliar abilities, uses contradiction attention to mitigate guessing and mistaking, and integrates a variant of Item Response Theory for interpretability. Evaluated on 11 benchmarks and 3 synthetic datasets, DisKT significantly outperforms 16 baselines in AUC, ACC, and RMSE while reducing bias (lower EKL scores) and better shielding guessing/mistaking effects.

## Method Summary
DisKT tackles cognitive bias in KT by treating it as a causal inference problem. The model disentangles student ability into "familiar" (from correct responses) and "unfamiliar" (from incorrect responses) representations. It uses a contradiction attention mechanism to dynamically suppress noisy interactions caused by guessing or mistaking. The final prediction integrates these disentangled abilities with question difficulty parameters using a variant of Item Response Theory. The model is trained with a loss function that combines binary cross-entropy with a contrastive term that encourages separation between familiar and unfamiliar embeddings.

## Key Results
- DisKT outperforms 16 baseline models on 11 public benchmarks in AUC, ACC, and RMSE
- Significantly reduces cognitive bias (EKL scores) compared to baselines
- Best performance in mitigating guessing and mistaking rates through contradiction attention
- Maintains interpretability through IRT-inspired prediction layer

## Why This Works (Mechanism)

### Mechanism 1: Causal Disentanglement of Confounding
DisKT addresses cognitive bias by identifying the historical correct rate distribution as a confounder that creates spurious correlations between student representation and prediction scores. The model separates student ability into "familiar" (from correct responses) and "unfamiliar" (from incorrect responses) representations, then calculates predictions by subtracting the natural direct effect of these disentangled abilities from the total effect, effectively blocking the confounding path.

### Mechanism 2: Contradiction Attention
The model introduces a contradiction attention layer that dynamically suppresses interactions where students guess correctly on hard questions or mistake easy questions. It uses a custom attention mechanism that down-weights attention scores based on a contradiction variable, which is triggered when a student's response contradicts the expected difficulty of the concept.

### Mechanism 3: Variant IRT Prediction
DisKT integrates IRT parameters into the prediction layer to enhance interpretability. The model uses a Rasch-model-inspired embedding structure that concatenates the de-biased student state with the difference between familiar and unfamiliar abilities and question difficulty to estimate correct response probability.

## Foundational Learning

- **Confounding in Causal Inference**: Why needed here - The paper frames cognitive bias as a causal inference problem where historical data distribution acts as a confounder affecting both student features and predictions. Quick check - Can you explain why standard correlation-based models might fail if a third variable influences both input and output?
- **Item Response Theory (IRT) Basics**: Why needed here - DisKT extends the Rasch model to create embeddings separating student ability from question difficulty. Quick check - In psychometrics, how does question difficulty relate to probability of correct response for a student of fixed ability?
- **Transformer Attention Mechanisms**: Why needed here - The Knowledge Extractor uses multi-head self-attention with masking techniques to create counterfactual sequences. Quick check - How would you mask a specific position in a sequence so attention ignores it during context calculation?

## Architecture Onboarding

- **Component map**: Rasch Embedding Layer -> Knowledge Extractor (Transformer Encoders) -> Contradiction Attention -> Variant IRT Head
- **Critical path**:
  1. Compute global concept difficulty (diff(c)) from training set correct rates
  2. Generate factual embeddings (S) and counterfactual embeddings (S+ correct-only, S- incorrect-only) using Rasch embeddings
  3. Compute prediction: $\hat{r} = \text{MLP}(X_{t+1} - (H^+ + H^-))$
- **Design tradeoffs**:
  - Robustness vs. Complexity: Adds significant complexity (dual attention streams, causal subtraction) to handle bias, with diminishing returns on already balanced datasets
  - Static Difficulty: Relies on pre-calculated diff(c) without dynamic updates during inference
- **Failure signatures**:
  - Cold Start for Concepts: Undefined diff(c) for concepts appearing only in test set
  - Zero-Bias Data: Subtraction mechanism may erroneously suppress signal on artificially balanced data
- **First 3 experiments**:
  1. Train on ednet-high (biased) and test on ednet-low; verify DisKT degrades less than baseline
  2. Remove contradiction attention modification and measure increase in mistaking rate
  3. Extract dq and H+ - H- for known sequence; verify correlation with simulated student performance

## Open Questions the Paper Calls Out

- **Future Work 1**: How can DisKT be extended to incorporate educational psychology factors like the forgetting curve to model temporal decay of student knowledge? The paper mentions this as an avenue for future exploration.
- **Future Work 2**: How can the "critical points" between simple and difficult questions be mathematically defined and identified for individual students to optimize cognitive load in ITS recommendations?
- **Future Work 3**: What are the "more fine-grained causal relations" affecting knowledge tracing beyond historical correct rate distribution, and how can they be integrated into the model?

## Limitations

- Unknown Transformer layer count (N) affects model capacity and may impact reproducibility
- Contradiction attention relies on static concept difficulty that doesn't update dynamically
- Assumes global concept difficulty is a stable proxy for determining contradictory interactions

## Confidence

- **High Confidence**: Core causal disentanglement mechanism (subtracting H+ and H- from H) is well-defined mathematically
- **Medium Confidence**: Contradiction attention effectiveness depends on stable concept difficulty assumption
- **Medium Confidence**: IRT prediction layer interpretability claims lack qualitative validation

## Next Checks

1. **Bias Injection Test**: Train on biased dataset (ednet-high) and test on balanced/opposite-biased dataset (ednet-low); verify DisKT performance degradation is less than baseline models
2. **Contradiction Ablation**: Remove contradiction attention mechanism and measure increase in guessing/mistaking rates on validation set
3. **Interpretability Check**: Extract and analyze difficulty (dq) and ability difference (H+ - H-) parameters for known sequence; validate correlation with simulated student performance