---
ver: rpa2
title: Code-Mixed Telugu-English Hate Speech Detection
arxiv_id: '2502.10632'
source_url: https://arxiv.org/abs/2502.10632
tags:
- hate
- speech
- telugu
- detection
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates transformer-based models for hate speech detection
  in Telugu, focusing on both original Telugu text and translated English versions.
  Models tested include TeluguHateBERT, HateBERT, DeBERTa, Muril, IndicBERT, Roberta,
  and Hindi-Abusive-MuRIL, with Low-Rank Adaptation (LoRA) used for efficient fine-tuning.
---

# Code-Mixed Telugu-English Hate Speech Detection

## Quick Facts
- arXiv ID: 2502.10632
- Source URL: https://arxiv.org/abs/2502.10632
- Authors: Santhosh Kakarla; Gautama Shastry Bulusu Venkata
- Reference count: 10
- Primary result: Hindi-Abusive-MuRIL achieves 73.14% accuracy and F1-score on Telugu hate speech detection

## Executive Summary
This study evaluates transformer-based models for hate speech detection in Telugu, comparing original Telugu text with translated English versions. The research tests multiple transformer architectures including TeluguHateBERT, HateBERT, DeBERTa, Muril, IndicBERT, Roberta, and Hindi-Abusive-MuRIL using Low-Rank Adaptation (LoRA) for efficient fine-tuning. Results demonstrate that Hindi-Abusive-MuRIL, pretrained on abusive Hindi content, outperforms all other models on both original Telugu and translated datasets, achieving 73.14% accuracy and F1-score on original data.

## Method Summary
The study fine-tunes seven transformer models on a Telugu hate speech dataset using LoRA for parameter-efficient adaptation. Models are evaluated on both original Telugu text and English translations via Google Translate. Training uses AdamW optimizer (lr=2e-5, batch_size=32) for 25 epochs with standard preprocessing including tokenization, padding, and truncation. The Hindi-Abusive-MuRIL model, specifically pretrained on abusive Hindi speech, shows superior generalization to Telugu hate speech compared to models without domain-specific pretraining.

## Key Results
- Hindi-Abusive-MuRIL achieves highest performance: 73.14% accuracy and F1-score on original Telugu dataset
- Translation improves accuracy for most models but reduces F1-scores, indicating loss of linguistic nuances
- Roberta ranks second-best in original dataset with 65.5% accuracy and 62.2% F1-score
- IndicBERT and Muril show poor performance (accuracy ~36-42%, F1 ~41-43%) on original data

## Why This Works (Mechanism)

### Mechanism 1
- Models pretrained on abusive speech in related languages generalize better to hate speech detection than language-specific models without domain pretraining
- Domain-specific pretraining on abusive content creates representations that capture semantic patterns of hateful expression which transfer across linguistically similar languages
- Core assumption: Hindi and Telugu share sufficient structural or cultural patterns in how hate speech manifests that enable cross-linguistic feature reuse
- Evidence: Hindi-Abusive-MuRIL outperforms all other models in both original Telugu dataset and translated dataset; models specifically trained on abusive speech tend to generalize better even for other Indian languages

### Mechanism 2
- Translation to English improves classification accuracy by enabling access to resource-rich English embeddings, but reduces F1-score due to loss of language-specific nuance
- English transformer models have been trained on orders of magnitude more data, capturing richer semantic relationships
- Core assumption: Google Translate preserves enough semantic content for classification while information loss affects boundary cases disproportionately
- Evidence: Translation enables models to leverage richer linguistic features available in English; decline in F1-score after translation is primarily due to loss of linguistic and contextual nuances

### Mechanism 3
- Low-Rank Adaptation (LoRA) enables efficient fine-tuning by learning task-specific adaptations in a low-dimensional subspace while freezing pretrained weights
- LoRA decomposes weight updates into low-rank matrices, dramatically reducing trainable parameters
- Core assumption: Task-specific adaptations for hate speech detection can be captured in a low-dimensional subspace without significant performance loss
- Evidence: LoRA enables transformer models to learn specialized patterns in Telugu hate speech data while maintaining their pre-trained general language understanding

## Foundational Learning

- Concept: **Parameter-efficient fine-tuning (PEFT/LoRA)**
  - Why needed here: The paper uses LoRA to fine-tune large transformers without full parameter updates. Understanding how rank constraints affect adaptation capacity is essential for interpreting results.
  - Quick check question: If LoRA rank is set too low, what type of task-specific patterns might the model fail to learn?

- Concept: **Cross-lingual transfer in transformers**
  - Why needed here: Hindi-Abusive-MuRIL's success depends on cross-lingual knowledge transfer. Understanding shared subspaces in multilingual models explains why Hindi pretraining helps Telugu classification.
  - Quick check question: Why might a model trained on Hindi abusive speech detect Telugu hate speech better than a model trained on general Telugu text?

- Concept: **Precision-Recall trade-off in F1-score**
  - Why needed here: Translation improved accuracy but reduced F1-score. This indicates asymmetric effects on precision and recall, suggesting translation affects false positive and false negative rates differently.
  - Quick check question: If translation neutralizes slang terms, would you expect precision or recall to be more affected, and why?

## Architecture Onboarding

- Component map: Input layer (tokenization) -> Encoder (transformer backbone) -> Adapter (LoRA modules) -> Classification head (binary output)
- Critical path: Dataset preprocessing → tokenization with max-length truncation → Model selection: Start with Hindi-Abusive-MuRIL for Telugu/Indic languages → LoRA configuration: Set rank, alpha, target modules → Training: AdamW optimizer, lr=2e-5, batch_size=32, ~25 epochs → Evaluation: Report both accuracy AND F1-score (macro/weighted)
- Design tradeoffs:
  - Original vs. Translated input: Original preserves nuance (higher F1); translated leverages richer embeddings (higher accuracy for some models)
  - Domain-specific vs. general pretraining: Abusive-speech models generalize better; general models may underfit hate-specific patterns
  - LoRA rank selection: Higher rank = more capacity but more parameters; paper doesn't specify rank used
- Failure signatures:
  - Near-chance accuracy (~50%) with balanced F1: Model failing to learn task (see Muril, IndicBERT on original data)
  - Accuracy rises but F1 drops after translation: Information loss in boundary cases
  - Large accuracy/F1 gap: Model biased toward one class; check class balance and decision threshold
- First 3 experiments:
  1. Replicate Hindi-Abusive-MuRIL baseline on original Telugu data to validate 73% benchmark; compare full fine-tuning vs. LoRA to isolate PEFT effects
  2. Ablate translation: Train identical models on original vs. translated data; analyze confusion matrices to identify which hate speech types are lost in translation
  3. Test LoRA rank sensitivity: Run experiments with ranks {4, 8, 16, 32} to determine minimum rank that preserves performance

## Open Questions the Paper Calls Out

- Can translation techniques be optimized to preserve the linguistic nuances and contextual cues of Telugu hate speech during translation to English?
- What specific features of Hindi-Abusive-MuRIL's pre-training enable it to generalize across Dravidian languages like Telugu, where other multilingual models fail?
- How would model performance scale with larger Telugu hate speech datasets, and what dataset size is necessary to close the performance gap with high-resource languages?

## Limitations

- Dataset transparency: Exact Telugu hate speech dataset source, size, and class distribution remain unspecified
- Hyperparameter opacity: LoRA rank, alpha values, and target module configurations were not reported
- Translation quality assessment: No analysis of Google Translate's semantic preservation quality for hate speech expressions
- Cross-linguistic validation: Paper assumes Hindi-to-Telugu transfer effectiveness without directly testing Telugu-specific domain pretraining

## Confidence

- **High confidence**: Mechanism 1 (Hindi-Abusive-MuRIL performance advantage) - directly supported by reported results
- **Medium confidence**: Mechanism 2 (Translation effects) - results are reported but lack corpus validation of translation-induced information loss
- **Medium confidence**: Mechanism 3 (LoRA efficiency) - mechanism is well-established but not validated specifically for hate speech detection in this context

## Next Checks

1. Obtain and analyze the actual Telugu hate speech dataset to verify class balance, sample size, and distribution; compare model performance across different dataset splits to assess stability
2. Conduct human evaluation of translated samples to identify specific hate speech markers lost during translation; correlate these losses with F1-score degradation patterns
3. Train identical transformer architectures with (a) Telugu-specific pretraining, (b) Hindi abusive pretraining, and (c) general multilingual pretraining on the same Telugu dataset to isolate transfer effects