---
ver: rpa2
title: 'Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit
  domain rules'
arxiv_id: '2509.20501'
source_url: https://arxiv.org/abs/2509.20501
tags:
- clustering
- rule
- aircraft
- rules
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents DART-VAE, a rule-guided multimodal clustering
  framework that incorporates domain-specific constraints directly into representation
  learning. The method extends the VAE architecture by embedding explicit rules, semantic
  representations, and data-driven features into a unified latent space, enforced
  through rule consistency and violation penalties in the loss function.
---

# Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules

## Quick Facts
- **arXiv ID:** 2509.20501
- **Source URL:** https://arxiv.org/abs/2509.20501
- **Reference count:** 21
- **Primary result:** Rule-guided multimodal clustering outperforms purely data-driven models by incorporating domain constraints into representation learning, improving clustering metrics (up to 0.7109 Silhouette Score for aircraft) and producing operationally meaningful clusters.

## Executive Summary
This paper presents DART-VAE, a rule-guided multimodal clustering framework that extends VAE architecture by embedding explicit domain rules, semantic representations, and data-driven features into a unified latent space. Unlike conventional methods that rely solely on visual similarity or apply rules as post-hoc filters, DART-VAE treats rules as first-class learning signals, generated by LLMs and structured into knowledge graphs. The framework achieves more meaningful and consistent clustering outcomes than purely data-driven models, as demonstrated on aircraft and automotive datasets where it successfully isolates UAVs, unifies stealth aircraft, and separates SUVs from sedans while improving traditional clustering metrics.

## Method Summary
DART-VAE integrates domain-specific rules directly into VAE representation learning by concatenating visual features (from YOLOv8/CNN), semantic embeddings (from Sentence-BERT), and rule-encoded vectors (from MLP) into a joint representation. The loss function includes reconstruction, KL divergence, consistency, and violation penalties to enforce rule compliance during training. LLM-generated rules are structured as knowledge graphs and encoded into continuous representations that guide the latent space toward semantically meaningful clusters rather than purely visual similarity.

## Key Results
- **Metric improvements:** Rule-guided clustering achieves up to 0.7109 Silhouette Score and 16,325.64 Calinski-Harabasz Score for aircraft datasets
- **Operational clustering:** Successfully isolates UAVs, unifies stealth aircraft, and separates SUVs from sedans compared to baseline clustering
- **Rule effectiveness:** Two-rule configurations yield better geometric metrics than four-rule configurations, suggesting optimal rule density exists

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Treating domain rules as first-class learning signals produces latent representations that respect operational semantics.
- **Mechanism:** LLM-generated rules are encoded as explicit feature vectors and injected into the VAE encoder alongside visual and semantic features. The loss function includes `L_consistency` and `L_violation` terms that penalize representations violating domain constraints, pulling functionally similar items (e.g., stealth aircraft) closer in latent space despite visual dissimilarity.
- **Core assumption:** LLM-generated rules accurately reflect domain constraints; the rule encoder can translate binary/derived attributes into meaningful continuous representations.
- **Evidence anchors:** [abstract] "DART-VAE treats rules as first-class learning signals... enforced through a loss function combining reconstruction, KL divergence, consistency, and violation penalties."
- **Break condition:** If rules are hallucinated or contradictory, `L_violation` may optimize toward spurious constraints; excessive rules over-constrain latent space.

### Mechanism 2
- **Claim:** Multimodal feature concatenation creates joint representations where rule-compliant similarities can override purely visual similarity.
- **Mechanism:** YOLOv8 extracts ROIs; CNN encodes visual features (100,352D aircraft, 256D vehicles). Sentence-BERT encodes knowledge graphs/metadata (256–768D). Rule MLPs encode binary/derived attributes (16–32D). Concatenated vectors pass through a joint encoder (512→256→64 latent dimensions). The decoder must reconstruct all modalities, forcing latent space to preserve rule-relevant information.
- **Core assumption:** Concatenation preserves modality-specific signals without dominance by highest-dimensional features.
- **Evidence anchors:** [section 3.4] "Aircraft: f_joint ∈ R^100,624 (visual: 100,352D + semantic: 256D + rules: 16D)"
- **Break condition:** If visual dimensions dominate gradients, rule signals may be under-weighted; `α` tuning is critical and domain-specific.

### Mechanism 3
- **Claim:** Rule-consistency loss enforces that items with similar rule profiles have similar latent codes, enabling cross-visual-category functional grouping.
- **Mechanism:** `L_consistency = MSE(sim(z_i, z_j), sim(r_i, r_j))` where `sim(r_i, r_j)` is cosine similarity between rule encoder outputs. This pulls MQ-9 and TB-2 UAVs together despite different visual profiles, and aligns BMW/Mercedes premium vehicles despite brand differences.
- **Core assumption:** Rule encoder outputs capture meaningful continuous similarities.
- **Evidence anchors:** [section 3.6] "sim(r_i, r_j) estimates cosine similarity between 16-dimensional rule features generated by the rule encoder, rather than raw binary inputs."
- **Break condition:** If rule features are sparse or orthogonal, cosine similarities become unstable.

## Foundational Learning

- **Concept: Variational Autoencoder (VAE) fundamentals**
  - Why needed here: DART-VAE extends VAE; you must understand encoder → latent distribution (μ, σ²) → reparameterization → decoder pipeline and why KL divergence regularizes latent space.
  - Quick check question: Can you explain why `z = μ + σ ⊙ ε` (reparameterization) enables backpropagation through sampling?

- **Concept: Knowledge graphs and semantic embeddings**
  - Why needed here: Domain knowledge is structured as JSON triples and encoded via Sentence-BERT; understanding how text/graph → dense vectors is essential for the semantic pathway.
  - Quick check question: Given triples `(F-22, has_capability, stealth)` and `(Su-57, has_capability, stealth)`, why would Sentence-BERT produce similar embeddings?

- **Concept: Clustering validation metrics**
  - Why needed here: Paper reports Silhouette, Davies-Bouldin, Calinski-Harabasz, FPC/FPE; interpreting these metrics (higher/lower = better) is required to evaluate tradeoffs.
  - Quick check question: If Silhouette Score increases but rule violations also increase, what does that suggest about cluster quality?

## Architecture Onboarding

- **Component map:** [YOLOv8 ROI] → [Visual CNN] → [Sentence-BERT] → [MLP] → [Joint Encoder] → [μ, σ²] → [z (64D)] → [Decoder] → [K-means / FCM] → [Rule Refinement]
- **Critical path:** Data prep (YOLOv8 + KG construction) → Feature extraction → Joint encoding → Loss computation → Clustering → Rule-based reassignment. Rule generation (LLM) is upstream and not trained; validate rules before use.
- **Design tradeoffs:** 2-rule vs. 4-rule: 2-rule yields higher Silhouette (0.7109) but fewer constraints; 4-rule improves semantic coherence but lowers geometric metrics (0.3325). Hard (K-means) vs. Soft (Fuzzy C-means): K-means better cluster geometry; FCM fewer violations (8.51 vs. 16.29 automotive). `α` (rule weight): Too high → overfitting to rules, latent collapse; too low → rules ignored. Paper uses 0.15.
- **Failure signatures:** Persistent rule violations (e.g., 85 stealth violations across configs): rule definition may not align with data distribution. Hallucinated rules: LLM generates constraints not grounded in domain; validate against expert sources. Overfitting: Adding rules improves violation metrics but degrades Silhouette/CH; latent space becomes fragmented.
- **First 3 experiments:** 1) **Baseline ablation:** Run DART-VAE with `α = 0` (no rule loss) to establish visual-only clustering performance. 2) **Rule weight sweep:** Test `α ∈ {0.05, 0.10, 0.15, 0.25}` on a holdout subset; plot Silhouette vs. violation count to find Pareto frontier. 3) **Single-rule isolate:** Train with one rule at a time (stealth only, UAV only) to identify which rules most improve separability; verify LLM-generated rule is not hallucinated by cross-checking with domain manuals.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the framework automatically detect and mitigate LLM-generated rule hallucinations or logical conflicts before they bias the representation learning process?
- **Basis in paper:** [explicit] Section 6 states that LLMs may produce "inaccurate or spurious rules" which can "inadvertently bias the clustering process, leading to distortions."
- **Why unresolved:** The current implementation assumes rules are validated before integration, lacking an internal mechanism to filter semantic noise from the LLM.
- **What evidence would resolve it:** Demonstration of an automated validation layer that flags or corrects inconsistent rules without human intervention.

### Open Question 2
- **Question:** What is the optimal trade-off between the number of explicit constraints and model generalizability as domain complexity increases?
- **Basis in paper:** [explicit] Section 6 warns that "applying too many constraints can lead to overfitting" and that scaling to large rule sets risks making the latent space "overly constrained."
- **Why unresolved:** The paper tests 2-rule and 4-rule configurations but does not establish a theoretical or empirical limit for rule density.
- **What evidence would resolve it:** Ablation studies on domains with significantly larger rule sets (e.g., >10 rules) analyzing the point of diminishing returns on Silhouette Scores.

### Open Question 3
- **Question:** Can this rule-guided architecture maintain operational effectiveness in "soft" domains where constraints are subjective or ambiguous rather than physically defined?
- **Basis in paper:** [inferred] Section 6 notes the framework relies on domains where rules are "well aligned with domain expertise," suggesting potential failure in "less formalized" fields.
- **Why unresolved:** The method is validated on aircraft and automobiles which have precise physical doctrines; it is unclear if the loss function handles fuzzy or subjective rules effectively.
- **What evidence would resolve it:** Successful application to domains like art history or fashion, where "rules" are stylistic rather than binary.

## Limitations

- **Rule quality dependency:** Performance heavily depends on LLM-generated rules being accurate and non-hallucinated, creating a potential failure mode where "garbage in, garbage clustered out."
- **Rule dimensionality imbalance:** Visual features (100K+ dimensions) may dominate training and effectively nullify rule signals despite explicit loss terms.
- **Limited domain validation:** Clustering metric improvements don't directly translate to operational meaningfulness without expert validation.

## Confidence

- **High confidence:** VAE architecture integration with rule-based loss functions
- **Medium confidence:** Multimodal clustering improvements over visual-only baselines
- **Low confidence:** Operational meaningfulness of clusters

## Next Checks

1. **Rule quality audit:** Cross-validate LLM-generated rules against domain expert knowledge or authoritative databases. Quantify hallucination rate and assess impact on clustering performance when rules are systematically corrupted.

2. **Dimensionality sensitivity analysis:** Perform ablation studies varying rule feature dimensions (2, 4, 8, 16) and applying feature normalization techniques to test whether rule signals remain effective when visual dimensions are reduced or balanced.

3. **Cross-domain transferability test:** Apply the exact same framework (architecture, hyperparameters, rule generation method) to a third domain (e.g., medical imaging with clinical rules) to assess generalization beyond the two tested domains.