---
ver: rpa2
title: 'Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative
  Spatial Representations'
arxiv_id: '2512.15388'
source_url: https://arxiv.org/abs/2512.15388
tags:
- then
- branches
- begins
- intersection
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper investigates whether qualitative spatial representations\
  \ can improve Large Language Model (LLM) navigation instructions for pedestrian\
  \ wayfinding. The authors use Retrieval-Augmented Generation (RAG) enhanced with\
  \ graph-based knowledge of street networks represented using a dipole calculus\u2014\
  a qualitative spatial reasoning framework."
---

# Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations

## Quick Facts
- arXiv ID: 2512.15388
- Source URL: https://arxiv.org/abs/2512.15388
- Reference count: 10
- Primary result: Graph-RAG with qualitative spatial context improved LLM navigation success from 0% to 62.5% overall (86.6% in Hamburg, 38.3% in Münster)

## Executive Summary
This paper demonstrates that Large Language Models (LLMs) can generate accurate pedestrian navigation instructions when provided with structured geographic context using qualitative spatial representations. The authors introduce a Graph-RAG system that encodes street networks as oriented line segments (dipoles) with pairwise relations from the Dipole Relation Algebra. Experiments in Hamburg and Münster show that navigation success jumps from 0% without geographic context to 62.5% with qualitative spatial context, with Gemini 2.5 Pro achieving the highest success rate at 70%. The results suggest that explicit topological structure is essential for LLM navigation tasks.

## Method Summary
The method converts OpenStreetMap street data into a knowledge graph using dipole calculus, where street segments become oriented line segments and intersections are described by 24 atomic relations from the Dipole Relation Algebra. These relations are verbalized into natural language patterns and injected into LLM prompts via Graph-RAG retrieval. The system was tested on 240 navigation tasks across Hamburg (38 streets, 899m avg routes) and Münster (128 streets, 1272m avg routes) with three different LLM models, comparing performance with and without the qualitative geographic context.

## Key Results
- Control group (LLMs without geographic context): 0% navigation success
- Test group (LLMs with qualitative geographic context): 62.5% overall success rate
- Performance by city: 86.6% success in Hamburg vs 38.3% in Münster
- Performance by LLM: Gemini 2.5 Pro (70%), Claude 4.5 (65%), GPT-4o (52.5%)

## Why This Works (Mechanism)

### Mechanism 1: Qualitative Spatial Representation via Dipole Calculus
- Claim: Encoding street networks as oriented line segment relations provides LLMs with explicit topological structure they otherwise lack.
- Mechanism: Street segments are mapped to dipoles (oriented line segments with start/end points). Pairwise relations at intersections are captured using 24 atomic relations from the Dipole Relation Algebra (DRA_c), describing configurations like "branches off to the left" or "begins at the intersection with."
- Core assumption: LLMs cannot reliably reason about spatial connectivity from parametric knowledge alone; they require explicit relational structure in context.
- Evidence anchors:
  - [abstract] "We use a method called Retrieval-Augmented Generation (RAG)... based on oriented line segments (dipoles) as basic entities"
  - [section 3, page 5] Defines the 24 atomic relations; "jointly exhaustive and pairwise disjoint provided that all point positions are in general position"
  - [corpus] Weak direct evidence; neighbor papers focus on multimodal VPR and general Graph-RAG, not dipole calculi specifically
- Break condition: When street networks have multiple overlapping levels (bridges, tunnels) violating the planar assumption, or when route distances increase significantly (success dropped from 86.6% in Hamburg to 38.3% in Münster with longer routes).

### Mechanism 2: Graph-RAG for Structured Spatial Retrieval
- Claim: Structured graph retrieval outperforms semantic similarity for navigation by preserving connectivity information.
- Mechanism: Unlike traditional RAG retrieving text chunks by vector similarity, Graph-RAG retrieves entity relationships, graph paths showing logical connections, and hierarchical abstractions. The system constructs a knowledge graph from OpenStreetMap where street segments are nodes and dipole relations are edges.
- Core assumption: Navigation success depends on understanding sequential connectivity, which requires graph structure rather than isolated semantic chunks.
- Evidence anchors:
  - [section 2, page 4] "Graph-RAG enhances this by organizing information in a knowledge graph structure, where entities are nodes and relationships are edges"
  - [section 4, page 9] Control group (without geographic context) achieved 0% success; test group achieved 62.5%
  - [corpus] "What Breaks Knowledge Graph based RAG?" (arXiv:2508.08344) discusses KG-RAG reasoning under incomplete knowledge, supporting the general approach
- Break condition: When the knowledge graph is incomplete or when the number of street segments exceeds the retrieval context window.

### Mechanism 3: Verbalization of Qualitative Relations into Natural Language
- Claim: Converting formal dipole relations into linguistic patterns enables LLMs to process spatial structure without specialized spatial reasoning capabilities.
- Mechanism: Dipole relations are verbalized using patterns like "Agathe-Lasch-Weg begins at the intersection with Holmbrook, Paul-Ehrlich-Straße. Emkendorfstraße then branches off to the right." This natural language encoding allows standard LLMs to consume spatial graphs.
- Core assumption: LLMs can perform implicit spatial reasoning when relational structure is presented linguistically, even without explicit spatial training.
- Evidence anchors:
  - [section 4, page 9] "A verbalization of an individual named street starts with segments 1. The first linguistic pattern is name(s1) 'begins at the intersection with' name(ri)"
  - [appendix, pages 11-15] Full verbalization examples for Hamburg street network
  - [corpus] No direct corpus evidence for this specific verbalization approach
- Break condition: When verbalized context becomes too lengthy (Münster had 128 streets vs. Hamburg's 38), potentially overwhelming the LLM's effective context utilization.

## Foundational Learning

- Concept: **Qualitative Spatial Reasoning (QSR)**
  - Why needed here: The dipole calculus is a QSR framework; understanding why qualitative (left/right/adjacent) rather than quantitative (coordinates) representations matter for human-aligned reasoning is essential.
  - Quick check question: Can you explain why "the street branches left" might be more useful for an LLM than "latitude 53.55, longitude 9.99"?

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: The entire method builds on RAG; distinguishing vector-based retrieval from graph-based retrieval is critical for understanding the architectural innovation.
  - Quick check question: What is the difference between retrieving "relevant text chunks" and retrieving "structured graph paths"?

- Concept: **Dipole Relation Algebra**
  - Why needed here: The paper's core contribution is applying this specific spatial calculus to street networks; understanding the 24 atomic relations is necessary to interpret the knowledge graph construction.
  - Quick check question: Given two oriented street segments meeting at an intersection, what information do you need to determine which of the 24 dipole relations holds?

## Architecture Onboarding

- Component map:
  1. **OpenStreetMap Data Source** → Raw street network data
  2. **Dipole Encoding Layer** → Converts street segments to dipoles; computes pairwise DRA_f relations at intersections
  3. **Knowledge Graph Builder** → Nodes = street segments; Edges = dipole relations
  4. **Verbalization Module** → Translates graph structure into natural language patterns (see appendix examples)
  5. **Graph-RAG Retrieval** → Retrieves relevant subgraph based on query origin/destination
  6. **LLM Generator** → Produces navigation instructions from retrieved context

- Critical path: OpenStreetMap → Dipole encoding → Relation computation → Graph construction → Verbalization → RAG retrieval → LLM response. The dipole encoding and verbalization steps are the novel contributions.

- Design tradeoffs:
  - Coarse (24 relations) vs. Fine (72 relations) dipole calculus: Coarse is simpler but cannot represent collinear configurations
  - Route length vs. success rate: Longer routes require more context; performance degrades (38.3% Münster vs. 86.6% Hamburg)
  - Model selection: Gemini 2.5 Pro performed best (70%), but the mechanism should be model-agnostic

- Failure signatures:
  - 0% success without spatial context (control group) → LLM parametric knowledge is insufficient
  - Success drops with longer routes → context window or retrieval limitations
  - Hallucinated street names (e.g., "Willy-Brandt-Allee" in Münster) → indicates missing or ungrounded context

- First 3 experiments:
  1. Replicate the control vs. test comparison with a single LLM on a small urban area (5-10 streets) to verify the 0% → ~60% improvement signal.
  2. Vary route length systematically within the same city to characterize the performance degradation curve (is it linear with distance, or threshold-based?).
  3. Test verbalization alternatives: compare the paper's "branches off to the left" pattern against simpler "turn left onto X" instructions to isolate whether dipole relations or just graph connectivity drives improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does navigation performance degrade specifically due to route length, or is it a result of increased context size from larger street network datasets?
- Basis in paper: [explicit] The authors note the success rate dropped significantly in Münster (38.3%) compared to Hamburg (86.6%) and explicitly state, "it seems like our method gets less successful with longer routes. We will investigate this in more detail in the future."
- Why unresolved: The two test cities differed in both average route distance (899m vs. 1272m) and dataset size (38 vs. 128 streets), confounding the variables.
- What evidence would resolve it: Controlled experiments where route length is varied within the same city, or where context window limits are systematically tested against route complexity.

### Open Question 2
- Question: Is natural language "verbalization" the most efficient format for LLMs to consume graph-based qualitative spatial relations?
- Basis in paper: [inferred] The method relies on converting dipole relations into specific linguistic patterns (e.g., "Agathe-Lasch-Weg begins at the intersection with...").
- Why unresolved: While effective, the paper does not compare this textual approach to providing the graph structure directly (e.g., via JSON or adjacency matrices), which some models might process more accurately.
- What evidence would resolve it: Ablation studies comparing the current verbalization strategy against structured data prompt formats (like Graph-to-Text or direct graph encoding) on the same navigation tasks.

### Open Question 3
- Question: What specific architectural features cause the significant variance in navigation success between different LLM families (e.g., Gemini vs. GPT-4o) when using identical qualitative contexts?
- Basis in paper: [inferred] The results show a substantial gap in performance between models (Gemini 70% vs. GPT-4o 52.5%) despite identical prompting and context.
- Why unresolved: The paper reports the performance differences but does not analyze whether they stem from differences in context window handling, spatial reasoning pre-training, or attention mechanisms.
- What evidence would resolve it: Attention map analysis or probing tasks to determine how each model weights the provided qualitative spatial relations during the generation of route instructions.

## Limitations
- Reproducibility gaps: Lack of detailed LLM prompts, evaluation rubrics, and Graph-RAG retrieval algorithms
- Context window constraints: Performance degrades with larger networks and longer routes, but mechanism unclear
- Evaluation methodology: Manual labeling without explicit criteria introduces potential subjectivity

## Confidence
- High confidence: Core finding that Graph-RAG with qualitative spatial context dramatically improves LLM navigation performance (0% → 62.5% success)
- Medium confidence: Claim that dipole calculus specifically enables this improvement, rather than any structured graph representation
- Low confidence: Generalizability to different urban layouts, larger cities, or multimodal navigation

## Next Checks
1. **Prompt engineering ablation**: Test whether the dipole verbalization patterns are necessary by comparing against simpler graph-RAG with basic "turn left/right onto Street X" instructions, controlling for route length and complexity.
2. **Retrieval strategy analysis**: Systematically vary the subgraph size and depth retrieved by Graph-RAG to determine whether performance is limited by context window size or retrieval quality, using routes of increasing length within the same city.
3. **Cross-city generalization**: Validate the approach on cities with different street patterns (grid vs. organic) and sizes to assess whether the 86.6% success rate in Hamburg is reproducible or represents an optimal case.