---
ver: rpa2
title: 'TABFAIRGDT: A Fast Fair Tabular Data Generator using Autoregressive Decision
  Trees'
arxiv_id: '2509.19927'
source_url: https://arxiv.org/abs/2509.19927
tags:
- data
- fairness
- synthetic
- fair
- tabfairgdt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TABFAIRGDT, a fast and efficient method for
  generating fair synthetic tabular data using autoregressive decision trees. The
  approach generates features sequentially using decision trees and applies a novel
  soft leaf resampling technique to enforce fairness at the target generation step,
  balancing fairness and utility without requiring data pre-processing or specialized
  hardware.
---

# TABFAIRGDT: A Fast Fair Tabular Data Generator using Autoregressive Decision Trees

## Quick Facts
- arXiv ID: 2509.19927
- Source URL: https://arxiv.org/abs/2509.19927
- Authors: Emmanouil Panagiotou; Benoît Ronval; Arjun Roy; Ludwig Bothmann; Bernd Bischl; Siegfried Nijssen; Eirini Ntoutsi
- Reference count: 39
- Primary result: Fast fair synthetic data generation achieving 50% fairness improvement while maintaining utility

## Executive Summary
TABFAIRGDT introduces a novel approach for generating fair synthetic tabular data using autoregressive decision trees with soft leaf resampling. The method generates features sequentially and applies fairness constraints only at the target generation step, avoiding out-of-distribution samples while maintaining predictive performance. It outperforms state-of-the-art deep generative models in fairness-utility trade-off and achieves a 72% average speedup over the fastest baseline, making it highly suitable for real-world fairness-sensitive applications.

## Method Summary
TABFAIRGDT generates fair synthetic tabular data by training sequential decision trees for each feature conditioned on previous features, then applying greedy leaf resampling with soft probability adjustment at the target generation step. The autoregressive approach captures complex feature relationships without parametric assumptions, while the soft resampling technique balances discrimination reduction and predictive accuracy through a tunable parameter λ∈[0,1]. The method enforces fairness constraints only at target generation to prevent out-of-distribution synthetic samples.

## Key Results
- Achieves approximately 50% average improvement in fairness while maintaining high predictive performance
- 72% average speedup over the fastest baseline method
- Generates fair synthetic data for medium-sized datasets (10 features, 10K samples) in just one second on a standard CPU
- Only method achieving fairness improvement on purely categorical datasets

## Why This Works (Mechanism)

### Mechanism 1
Sequential feature generation via decision trees approximates joint distributions of mixed tabular data without parametric assumptions. Each feature X_j is modeled as P_j(X_j | X_{<j}) using a decision tree trained on prior features, with synthetic values flowing through leaves probabilistically based on stored conditional distributions.

### Mechanism 2
Greedy leaf resampling with soft probability adjustment reduces discrimination while preserving utility better than full-distribution alignment. Leaves are ranked by discrimination-to-accuracy ratio, with selected leaves having sampling probabilities adjusted: p'_ℓ = p_ℓ * (1-λ) + (1-p_ℓ) * λ, enabling gradual fairness-utility tradeoff.

### Mechanism 3
Enforcing fairness constraints only at target generation prevents out-of-distribution synthetic samples that violate real-world constraints. By generating all features X first, then sensitive attribute S, then target Y with fairness applied only at Y, the method maintains P(X|S) relationships observed in real data.

## Foundational Learning

- **Autoregressive Generative Models**: Core architecture; sequential conditioning is essential for debugging generation quality. Quick check: If you shuffle feature order, should the joint distribution remain approximately the same? (Yes, theoretically; empirically confirmed)

- **Statistical Parity (Demographic Parity)**: The fairness metric being optimized; defines what "fair" means in this context. Quick check: If P(Y_pred=1|S=0) = 0.3 and P(Y_pred=1|S=1) = 0.4, what is the statistical parity score? (0.3 - 0.4 = -0.1, indicating bias)

- **Decision Tree Leaf Distributions**: Sampling mechanism; each leaf stores a discrete distribution over feature values, not a single prediction. Quick check: A leaf has 80 samples with Y=1 and 20 samples with Y=0. What probability does it store for Y=1? (0.8)

## Architecture Onboarding

- **Component map**: Real Data D → [Feature ordering] → [Tree Fitting Phase] → [Autoregressive Sampling] → [Generate Ŝ] → [Fair Target Generation] → Synthetic Data D̂ = (X̂, Ŝ, Ŷ)

- **Critical path**: The greedy leaf selection loop determines which leaves get adjusted, directly controlling fairness-utility tradeoff. If this loop fails to converge, generation cannot proceed.

- **Design tradeoffs**: λ=1.0 (max fairness) → ~50% fairness improvement, ~2% utility loss; λ=0.0 → no fairness intervention, baseline utility; Tree depth uses default CART.

- **Failure signatures**: High detection score (>0.7) indicates trees overfitting; no fairness improvement suggests greedy loop stuck; OOD samples appearing means S generated at wrong step.

- **First 3 experiments**: 
  1. Reproduce Adult dataset results: Set λ=1.0, train on 66% split, expect ROC AUC ~0.906, Stat. Par. ~0.078, detection score ~0.54.
  2. Ablation on λ: Run λ ∈ {0.0, 0.25, 0.5, 0.75, 1.0} on Dutch Census, confirm λ=1.0 is only method achieving fairness improvement on purely categorical data.
  3. OOD sample audit: Compare generated {sex, relationship} distributions against real data constraints on Adult dataset, expect zero OOD samples for TABFAIRGDT.

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework be extended to support fairness definitions other than statistical parity, such as equalized odds or intersectional fairness? The current greedy algorithm and discrimination metric are designed specifically for statistical parity, and a modified resampling objective would be needed.

### Open Question 2
How can the soft leaf resampling technique be adapted for regression tasks involving continuous target variables? The current method relies on flipping binary labels and calculating discrete accuracy changes, which does not apply to continuous values.

### Open Question 3
To what extent does decision tree complexity, specifically tree depth, influence the fairness-utility trade-off via overfitting or underfitting? The study uses standard tree fitting but does not isolate how structural capacity affects the effectiveness of fair resampling intervention.

## Limitations

- The soft resampling parameter λ=1.0 is presented as optimal, but sensitivity analysis is limited to a single dataset.
- The detection score metric (>0.5 indicates overfitting) is treated as a pass/fail threshold without establishing acceptable synthetic data quality standards.
- The claim that enforcing fairness only at target generation prevents OOD samples is based on qualitative observations rather than systematic evaluation.

## Confidence

- **High confidence**: Speed advantage (72% faster) and scalability claims are directly measurable from reported runtimes and dataset sizes.
- **Medium confidence**: The 50% average fairness improvement is supported by extensive benchmarking across six datasets, though generalizability to non-binary sensitive attributes is untested.
- **Low confidence**: The claim that enforcing fairness only at target generation prevents OOD samples is based on qualitative observations rather than systematic evaluation.

## Next Checks

1. **Order sensitivity test**: Systematically permute feature order on Adult dataset and measure impact on statistical parity and detection score. Compare against random baseline where feature order is randomized across runs.

2. **Real-data distributional alignment**: For each generated dataset, compute 1:1 comparison of joint distributions P(X_i, S, Y) between real and synthetic data using normalized root mean square error. Verify OOD constraints are preserved across all feature combinations.

3. **Threshold robustness analysis**: Run TABFAIRGDT with λ ∈ {0.5, 0.75, 0.9, 1.0} on KDD Census and Bank Marketing datasets where negative fairness improvements are reported. Document the relationship between λ, fairness gain, and utility loss to identify optimal operating points.