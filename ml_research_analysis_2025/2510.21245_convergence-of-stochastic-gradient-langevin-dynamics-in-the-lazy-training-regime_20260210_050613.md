---
ver: rpa2
title: Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime
arxiv_id: '2510.21245'
source_url: https://arxiv.org/abs/2510.21245
tags:
- neural
- gradient
- stochastic
- training
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the convergence of stochastic gradient Langevin
  dynamics (SGLD) in the lazy training regime, extending deterministic lazy training
  analysis to stochastic continuous-time models. The key result shows that under regularity
  conditions on the loss function's Hessian, SGLD achieves exponential convergence
  to the empirical risk minimizer with explicit bounds.
---

# Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime

## Quick Facts
- **arXiv ID:** 2510.21245
- **Source URL:** https://arxiv.org/abs/2510.21245
- **Reference count:** 26
- **Primary result:** SGLD achieves exponential convergence to empirical risk minimizer in lazy training regime with explicit non-asymptotic bounds

## Executive Summary
This paper establishes convergence guarantees for Stochastic Gradient Langevin Dynamics (SGLD) in the lazy training regime, extending deterministic lazy training analysis to stochastic continuous-time models. The key contribution is showing that under regularity conditions on the loss function's Hessian, SGLD converges exponentially to the empirical risk minimizer with explicit bounds. The analysis introduces a stopping time to handle the lazy training regime and proves that parameters remain in the initialization neighborhood indefinitely for sufficiently large output scaling. The work provides non-asymptotic convergence guarantees for both shallow and deep neural networks trained with SGLD, demonstrating exponential decay in training loss while maintaining a well-conditioned Neural Tangent Kernel.

## Method Summary
The paper studies SGLD for teacher-student regression with shallow neural networks in the lazy training regime. The continuous-time dynamics are given by an Itô SDE where parameters follow gradients of the empirical risk plus noise scaled by 1/α. The analysis relies on regularity conditions for the loss function's Hessian (Lipschitz gradients, bounded Hessians, and quadratic growth). A stopping time argument is used to show that with high probability, parameters remain in the initialization neighborhood indefinitely when the output scaling factor α is sufficiently large. The convergence analysis employs a stochastic Grönwall inequality and controls the Neural Tangent Kernel (NTK) spectrum throughout training.

## Key Results
- SGLD achieves exponential convergence to empirical risk minimizer in lazy training regime
- Parameters remain in initialization neighborhood indefinitely with high probability for large α
- NTK minimum eigenvalue remains bounded away from zero throughout training
- Training loss decays exponentially as O(exp(-t/α)) with explicit convergence rates

## Why This Works (Mechanism)
The convergence mechanism relies on the interplay between the lazy training regime and the noise regularization in SGLD. In the lazy regime, neural networks behave like linear models in function space, allowing the use of linear convergence analysis. The 1/α scaling in the noise term ensures that the stochastic component doesn't dominate the gradient flow, while the output scaling α controls the effective learning rate. The stopping time argument guarantees that parameters don't deviate far from initialization, preserving the linear approximation throughout training. This combination enables exponential convergence while maintaining the well-conditioned NTK spectrum required for stable optimization.

## Foundational Learning
- **Itô Calculus**: Stochastic calculus framework for continuous-time optimization; needed to handle the SDE dynamics and derive convergence bounds; quick check: verify Itô's lemma application in the proof.
- **Lazy Training Regime**: Parameter regime where neural networks behave linearly in function space; needed to apply linear convergence analysis to deep networks; quick check: monitor NTK spectrum during training.
- **Neural Tangent Kernel**: Kernel defined by the Jacobian of the network; needed to characterize the effective linear model in lazy regime; quick check: verify NTK minimum eigenvalue remains bounded.
- **Stopping Time Analysis**: Probabilistic tool to bound parameter deviation from initialization; needed to ensure the lazy regime conditions persist; quick check: verify stopping time probability bounds.
- **Stochastic Grönwall Inequality**: Extension of deterministic Grönwall to handle stochastic terms; needed to derive exponential convergence rates; quick check: verify the inequality application in Theorem 2.
- **SDE Discretization (Euler-Maruyama)**: Numerical scheme for simulating SGLDs; needed to implement the continuous dynamics; quick check: verify step size stability conditions.

## Architecture Onboarding
**Component Map:** Synthetic data generation -> Shallow network with centered initialization -> NTK computation -> Euler-Maruyama SGLD simulation -> Convergence monitoring
**Critical Path:** Data generation → Network initialization (centered) → NTK computation at initialization → SGLD discretization with covariance matrix → Monitoring loss/NTK/weights
**Design Tradeoffs:** The output scaling factor α controls the tradeoff between convergence speed (larger α) and noise stability (smaller α). The step size δt must balance discretization accuracy against computational efficiency.
**Failure Signatures:** NTK minimum eigenvalue hitting zero indicates departure from lazy regime; numerical instability in Euler-Maruyama suggests step size too large relative to noise scaling.
**First Experiments:**
1. Implement synthetic data generation and verify teacher-student setup
2. Compute NTK at initialization and verify minimum eigenvalue
3. Implement Euler-Maruyama scheme with different α values and monitor convergence patterns

## Open Questions the Paper Calls Out
1. **Underparameterized Regime:** The paper explicitly identifies the analysis of SGLD in the underparameterized regime as an interesting future research direction, as the current theoretical results rely on the lazy training regime which typically assumes sufficient overparameterization.

2. **Heavy-Tailed Noise Models:** The convergence study of different continuous-time models for SGD, such as those modeling SGD with heavy-tailed Lévy processes, is identified as an open question, requiring different stochastic integration techniques.

3. **Discrete-to-Continuous Translation:** The paper limits results to continuous models and notes that while the SDE is a weak approximation of SGD, it does not provide explicit bounds on the discretization error required to apply continuous bounds to the discrete algorithm.

## Limitations
- The covariance matrix Σ_α(ω) implementation details are unspecified, affecting the noise scaling in simulations
- Extension to deep networks is presented at high level without specific numerical validation
- Assumption of bounded Hessian regularity may not hold uniformly throughout entire parameter space
- Stopping time analysis is theoretically sound but practical manifestation depends on precise initialization choices

## Confidence
- **High confidence:** Theoretical convergence framework and exponential convergence rates are mathematically rigorous with proofs provided
- **Medium confidence:** Experimental setup is reproducible but exact convergence behavior depends on unspecified implementation details
- **Low confidence:** Extension from shallow to deep networks lacks specific numerical validation and general applicability remains unproven

## Next Checks
1. Implement and test multiple variants of Σ_α(ω) computation (full gradient vs mini-batch vs fixed covariance) to assess impact on convergence behavior
2. Systematically vary the Euler-Maruyama step size δt relative to ηα/α² to identify numerical stability boundaries
3. Conduct ablation studies on NTK monitoring: compare convergence rates when NTK minimum eigenvalue approaches zero versus when it remains bounded