---
ver: rpa2
title: 'CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection
  to Augment LLM Scientific Question Answering'
arxiv_id: '2601.21733'
source_url: https://arxiv.org/abs/2601.21733
tags:
- graph
- knowledge
- retrieval
- community
- subgraph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of improving large language models
  (LLMs) for scientific question answering by leveraging semantic relationships in
  academic knowledge graphs. The proposed CE-GOCD method retrieves and optimizes subgraphs
  centered on paper titles, refines them via pruning and completion to uncover implicit
  relations, and applies community detection to group papers by shared themes.
---

# CE-GOCD: Central Entity-Guided Graph Optimization for Community Detection to Augment LLM Scientific Question Answering

## Quick Facts
- arXiv ID: 2601.21733
- Source URL: https://arxiv.org/abs/2601.21733
- Reference count: 0
- Primary result: Achieved F1 scores up to 80.14% on NLP datasets, outperforming baselines by 6.35–9.76%

## Executive Summary
This paper introduces CE-GOCD, a method that enhances LLM scientific question answering by leveraging knowledge graph-based retrieval with community detection. The approach retrieves and optimizes subgraphs centered on paper titles, applies pruning and completion to uncover implicit relations, and uses community detection to group papers by shared themes. Evaluated on three NLP datasets with GPT-4, DeepSeek-V3, and Qwen-Plus, CE-GOCD achieved F1 scores of up to 80.14%, significantly outperforming baseline methods.

## Method Summary
CE-GOCD addresses the challenge of improving LLM performance in scientific question answering by utilizing semantic relationships in academic knowledge graphs. The method involves three key stages: subgraph retrieval (extracting relevant entities and relationships centered on paper titles), subgraph optimization (pruning weak connections and completing missing implicit relations), and community detection (grouping papers by shared themes using the Louvain algorithm). The approach was evaluated on three NLP datasets (NLP-MQA, PeerQA, QASPER) with multiple LLMs, demonstrating significant improvements in answer quality compared to baseline methods.

## Key Results
- Achieved F1 scores up to 80.14% on NLP datasets
- Outperformed baseline methods by 6.35-9.76%
- Demonstrated generalizability to medical domain with maintained performance

## Why This Works (Mechanism)
The method works by exploiting the inherent structure of academic knowledge graphs where papers are central nodes connected to various entities (methods, datasets, tasks, keywords). By anchoring subgraphs on paper titles and optimizing them through semantic pruning and relation completion, the approach captures both explicit and implicit relationships between papers. The community detection step then groups related papers, allowing the LLM to synthesize answers based on thematically coherent clusters rather than isolated papers or flat lists of related work.

## Foundational Learning
- Knowledge Graph Construction: Academic papers connected to methods, datasets, tasks, keywords, and citations; needed to capture semantic relationships between scientific works; quick check: verify graph connectivity and paper centrality
- Semantic Similarity Computation: Using embedding models (BERT/Sentence-BERT) to measure relationship strength; needed for edge pruning and completion decisions; quick check: validate similarity scores align with domain expertise
- Community Detection Algorithms: Louvain method for maximizing modularity in graphs; needed to group semantically related papers; quick check: ensure communities capture thematic coherence

## Architecture Onboarding
- Component Map: LLM Extraction -> Subgraph Retrieval -> Subgraph Optimization -> Community Detection -> Answer Synthesis
- Critical Path: Query → LLM Keyword/Entity Extraction → TF-IDF Entity Retrieval → Path Retrieval (≤5 hops) → Title-anchored Neighbor Extraction → Pruning/Completion → Louvain Community Detection → LLM Answer Generation
- Design Tradeoffs: 5-hop path limit balances completeness vs. noise (baseline exceeded 129s latency); community merging to 3 groups balances granularity vs. answer coherence
- Failure Signatures: Excessive entity count (>1000) or path length (>5 hops) indicates over-retrieval; edge count dropping below 50 suggests over-pruning; >5 communities indicates poor paper-centric clustering
- First Experiments: 1) Test subgraph retrieval with simple queries to verify paper title centrality, 2) Validate pruning effectiveness by comparing relevance scores before/after optimization, 3) Check community detection produces coherent thematic groups with proper paper distribution

## Open Questions the Paper Calls Out
None

## Limitations
- Depends on unreleased NLP-AKG knowledge graph and NLP-MQA dataset
- Method generalizability beyond NLP and medical domains remains unproven
- Performance sensitive to heuristic choices (5-hop limit, 3-community cap)

## Confidence
High confidence in core technical claims regarding architecture and evaluation results
Medium confidence in exact implementation details of LLM prompts and thresholds
Medium confidence in cross-domain generalizability

## Next Checks
1. Verify exact LLM prompts and thresholds used for keyword extraction, pruning, and implicit relation identification by contacting authors or reverse-engineering from code if available
2. Test the method on at least one additional scientific domain (e.g., computer science or biology) using an established academic knowledge graph to assess cross-domain robustness
3. Conduct ablation studies removing community detection (using only optimized subgraphs) and Louvain optimization (using raw subgraphs) to quantify the specific contribution of each major component to performance gains