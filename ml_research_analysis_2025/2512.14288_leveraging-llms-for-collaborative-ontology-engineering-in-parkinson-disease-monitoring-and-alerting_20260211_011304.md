---
ver: rpa2
title: Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease
  Monitoring and Alerting
arxiv_id: '2512.14288'
source_url: https://arxiv.org/abs/2512.14288
tags:
- ontology
- llms
- human
- ontologies
- x-hcome
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents experiments in ontology engineering for Parkinson\u2019\
  s disease (PD) monitoring and alerting using Large Language Models (LLMs). Four\
  \ methodologies were explored: One Shot (OS) and Chain of Thought (CoT) prompts\
  \ for initial ontology generation, X-HCOME combining human expertise with LLM capabilities,\
  \ and SimX-HCOME+ emphasizing continuous human supervision."
---

# Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting

## Quick Facts
- arXiv ID: 2512.14288
- Source URL: https://arxiv.org/abs/2512.14288
- Authors: Georgios Bouchouras; Dimitrios Doumanas; Andreas Soularidis; Konstantinos Kotis; George A. Vouros
- Reference count: 26
- Primary result: X-HCOME methodology achieved 42% F-1 score and 50 classes for Bard/Gemini, with human-LLM collaboration significantly improving ontology comprehensiveness

## Executive Summary
This paper investigates ontology engineering for Parkinson's disease monitoring using Large Language Models (LLMs) across four methodologies: One Shot, Chain of Thought, X-HCOME (combining human expertise with LLM capabilities), and SimX-HCOME+ with continuous human supervision. The experiments demonstrate that while LLMs can generate ontologies independently, the X-HCOME approach—which integrates human expert review—significantly enhances ontology comprehensiveness and accuracy. The Bard/Gemini X-HCOME achieved the highest performance with 42% F-1 score and 50 classes, while expert-reviewed X-HCOME outputs exceeded 100% F-1 score, indicating the critical value of human collaboration in complex medical ontology development.

## Method Summary
The study explored four distinct methodologies for ontology engineering in Parkinson's disease monitoring. The One Shot and Chain of Thought approaches utilized simple prompting strategies to generate ontologies directly from LLMs. X-HCOME introduced a hybrid approach where human experts reviewed and refined LLM-generated ontologies, combining automated generation with domain expertise. SimX-HCOME+ extended this concept by incorporating continuous human supervision throughout the ontology development process. The methodologies were evaluated using standard metrics including F-1 score and class count, with particular attention to the comprehensiveness and accuracy of the resulting ontologies in the medical domain context.

## Key Results
- X-HCOME methodology achieved the highest performance with Bard/Gemini reaching 42% F-1 score and 50 classes
- Human expert review of X-HCOME outputs demonstrated exceptional performance exceeding 100% F-1 score
- LLM-only approaches (One Shot and Chain of Thought) showed significantly lower performance compared to collaborative methods
- The integration of human expertise with LLM capabilities proved essential for developing comprehensive and accurate ontologies in the complex domain of Parkinson's disease monitoring

## Why This Works (Mechanism)
The effectiveness of human-LLM collaboration in ontology engineering stems from the complementary strengths of both approaches. LLMs excel at rapid generation of structured knowledge representations and can process vast amounts of information quickly, while human experts provide critical domain knowledge, contextual understanding, and the ability to identify and correct subtle errors or omissions. This synergistic relationship allows for the creation of more comprehensive and accurate ontologies than either approach could achieve independently, particularly in complex medical domains where nuanced understanding is crucial.

## Foundational Learning
- **Ontology Engineering**: The systematic process of creating formal representations of knowledge domains using structured vocabularies and relationships. Why needed: Provides the foundational framework for representing complex medical concepts in Parkinson's disease monitoring. Quick check: Can you explain the difference between classes, properties, and individuals in an ontology?
- **Large Language Models**: AI systems trained on massive text corpora that can generate human-like text and structured outputs. Why needed: Serve as the automated component for initial ontology generation and knowledge extraction. Quick check: What are the key architectural differences between GPT and Gemini models that might affect ontology generation?
- **X-HCOME Methodology**: A hybrid approach combining LLM generation with human expert review and refinement. Why needed: Addresses the limitations of pure LLM-generated ontologies by incorporating domain expertise. Quick check: Can you outline the steps in the X-HCOME workflow from generation to expert review?
- **F-1 Score in Ontology Evaluation**: A metric combining precision and recall to measure ontology quality and completeness. Why needed: Provides quantitative assessment of how well the generated ontology captures the target domain. Quick check: How does F-1 score differ from simple accuracy in evaluating ontology completeness?
- **Chain of Thought Prompting**: A technique that guides LLMs through step-by-step reasoning to improve output quality. Why needed: Helps LLMs generate more structured and logically coherent ontologies. Quick check: What are the key differences between Chain of Thought and standard prompting approaches?

## Architecture Onboarding
- **Component Map**: Human Expert -> LLM (Bard/Gemini) -> Ontology Output -> Expert Review -> Final Ontology
- **Critical Path**: Expert Review -> LLM Generation -> Expert Refinement -> Ontology Validation
- **Design Tradeoffs**: Speed vs. accuracy (LLM-only is faster but less accurate), automation vs. expertise (full automation misses nuances, full human effort is resource-intensive)
- **Failure Signatures**: Incomplete class coverage, incorrect hierarchical relationships, missing domain-specific terminology
- **First Experiments**:
  1. Compare One Shot vs Chain of Thought outputs for baseline performance
  2. Implement X-HCOME with a single domain expert review cycle
  3. Test SimX-HCOME+ with iterative human supervision on ontology refinement

## Open Questions the Paper Calls Out
None

## Limitations
- Limited scope to Parkinson's disease monitoring without validation in other medical domains
- Potential measurement inconsistencies, particularly the >100% F-1 score claim requiring scrutiny
- Lack of detailed information about specific LLM versions, prompting strategies, and evaluation criteria used
- Possible biases in human expert review process that may affect objectivity of results

## Confidence
- **General collaborative advantage**: Medium to High confidence - the benefit of human-LLM collaboration is well-supported by the results
- **Specific performance metrics**: Low to Medium confidence - the >100% F-1 score claim raises questions about measurement methodology
- **42% F-1 score and 50 classes result**: Medium to High confidence - this appears to be the most reliable quantitative outcome

## Next Checks
1. Replicate the X-HCOME methodology with multiple LLM models and prompt variations to verify the consistency of the 42% F-1 score result
2. Conduct cross-domain testing of the collaborative approach in at least two other medical specialties to assess generalizability
3. Implement blinded expert review of ontology outputs to validate the claimed >100% F-1 score and eliminate potential confirmation bias in the human review process