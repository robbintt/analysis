---
ver: rpa2
title: 'CapGeo: A Caption-Assisted Approach to Geometric Reasoning'
arxiv_id: '2510.09302'
source_url: https://arxiv.org/abs/2510.09302
tags:
- geometric
- reasoning
- arxiv
- captioning
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Geometric reasoning in multimodal large language models (MLLMs)
  is hindered by inadequate visual understanding of diagrams, not by reasoning capability.
  The proposed CapGeo framework converts geometric figures into structured captions
  that capture essential elements, relations, and numerical values, then feeds these
  captions to LLMs for reasoning.
---

# CapGeo: A Caption-Assisted Approach to Geometric Reasoning

## Quick Facts
- arXiv ID: 2510.09302
- Source URL: https://arxiv.org/abs/2510.09302
- Reference count: 30
- Geometric reasoning performance improves dramatically (8.6% to 59.0% accuracy) when diagrams are converted to structured captions

## Executive Summary
CapGeo addresses the challenge of geometric reasoning in multimodal large language models by recognizing that the bottleneck lies in visual understanding of diagrams rather than reasoning capability. The framework converts geometric figures into structured captions that capture essential elements, relationships, and numerical values, which are then processed by LLMs for reasoning. This caption-assisted approach achieves significant performance improvements across multiple MLLM architectures, demonstrating that textual representations of geometric information can effectively bridge the visual-textual modality gap. The authors also introduce CapGeo-Bench, a comprehensive dataset with 4,641 high-quality geometry figure-caption pairs and a keypoint-based evaluation metric that correlates strongly with downstream reasoning performance.

## Method Summary
The CapGeo framework operates through a two-stage process: first, geometric diagrams are analyzed and converted into structured textual captions that identify key elements (points, lines, angles, shapes), their spatial relationships, and associated numerical measurements. These captions are designed to preserve the semantic and quantitative information necessary for geometric problem-solving while eliminating the need for complex visual processing. Second, these structured captions are fed to multimodal large language models, which can leverage their reasoning capabilities on the well-structured textual representation. The approach is validated through extensive experiments on the MathVerse benchmark, demonstrating that even state-of-the-art MLLMs achieve significantly higher accuracy when provided with geometric captions rather than raw visual inputs.

## Key Results
- Qwen2.5-VL-72B accuracy improves from 8.6% to 59.0% on MathVerse Vision-Only tasks using CapGeo
- Claude-Opus-4 improves from 44.8% to 73.0% accuracy with caption-assisted reasoning
- CapGeo-Bench dataset established with 4,641 high-quality geometry figure-caption pairs
- Keypoint-based evaluation metric shows strong correlation with downstream reasoning performance

## Why This Works (Mechanism)
The framework works because geometric reasoning fundamentally requires understanding relationships between elements, spatial configurations, and numerical properties - all of which can be precisely captured in structured text. MLLMs excel at logical reasoning when given well-structured information, but struggle with visual parsing of diagrams. By converting visual geometric information into detailed textual descriptions, CapGeo enables LLMs to focus on the reasoning task rather than the visual interpretation task, effectively separating two distinct cognitive challenges.

## Foundational Learning
- **Geometric Element Recognition**: Identifying points, lines, angles, and shapes in diagrams - needed to extract the fundamental building blocks of geometric problems; quick check: can the system correctly identify all vertices and edges in complex polygons
- **Spatial Relationship Encoding**: Capturing adjacency, parallelism, perpendicularity, and other geometric relationships - essential for understanding how elements interact; quick check: can the system accurately describe relative positions and orientations
- **Numerical Value Extraction**: Detecting measurements, coordinates, and ratios from diagrams - critical for quantitative reasoning; quick check: can the system reliably extract all labeled measurements and implied values
- **Structured Caption Generation**: Converting visual information into organized textual format - bridges visual and textual modalities; quick check: can the system produce captions that maintain all necessary information without ambiguity
- **Multimodal Reasoning**: Applying logical inference to geometric problems - leverages LLM strengths once visual parsing is handled; quick check: can the system solve multi-step problems using only textual geometric descriptions
- **Benchmark Evaluation**: Measuring geometric captioning and reasoning performance - enables systematic improvement and comparison; quick check: does the evaluation metric correlate with actual problem-solving ability

## Architecture Onboarding

**Component Map**: Diagram -> Caption Generator -> Structured Caption -> LLM -> Reasoning Output

**Critical Path**: The most critical components are the caption generation model (must capture all essential geometric information) and the LLM reasoning stage (must process structured captions effectively)

**Design Tradeoffs**: The framework trades computational visual processing for text generation overhead, but this tradeoff is favorable because LLMs are more efficient at reasoning on structured text than visual interpretation. The quality of captions directly determines reasoning success, creating a dependency that must be carefully managed.

**Failure Signatures**: Poor geometric captions lead to reasoning failures - missing elements, incorrect relationships, or imprecise numerical values will propagate through to incorrect solutions. The framework is sensitive to caption quality and may struggle with highly complex diagrams that require extensive spatial reasoning.

**First Experiments**: 1) Test baseline MLLM performance on raw diagrams vs. structured captions; 2) Evaluate different captioning models on the same geometric problems; 3) Conduct ablation studies removing different caption components to identify critical information

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Performance heavily depends on the quality of geometric captioning models, which may vary in their ability to capture complex relationships
- Results may not generalize well across different MLLM architectures or geometric problem types beyond the MathVerse benchmark
- The keypoint-based evaluation metric may not fully capture all aspects of geometric reasoning complexity, particularly for problems requiring spatial intuition

## Confidence

**Geometric reasoning bottleneck hypothesis**: High confidence - substantial performance gains (8.6% to 59.0%) provide strong empirical support
**CapGeo-Bench reliability**: Medium confidence - promising dataset size and correlation metrics, but generalizability needs further validation
**CapGeo as new pathway**: High confidence - demonstrates clear methodology for bridging visual-textual modalities in geometric problem-solving

## Next Checks

1. Test CapGeo's performance with captioning models of varying quality and architectural approaches to establish the minimum caption quality threshold required for reliable geometric reasoning

2. Evaluate the framework on additional geometric reasoning benchmarks beyond MathVerse, including problems involving 3D geometry, coordinate geometry, and real-world diagram interpretation

3. Conduct ablation studies to determine which aspects of geometric captions (element identification, relationship description, numerical precision) contribute most significantly to reasoning performance, and test whether fine-tuning MLLMs on geometric captions further improves results