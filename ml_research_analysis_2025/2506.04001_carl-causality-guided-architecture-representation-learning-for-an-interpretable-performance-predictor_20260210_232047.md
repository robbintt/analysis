---
ver: rpa2
title: 'CARL: Causality-guided Architecture Representation Learning for an Interpretable
  Performance Predictor'
arxiv_id: '2506.04001'
source_url: https://arxiv.org/abs/2506.04001
tags:
- architecture
- search
- features
- carl
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of poor generalization in neural
  architecture search (NAS) performance predictors due to spurious correlations learned
  from biased training samples. The authors propose CARL, a Causality-guided Architecture
  Representation Learning method that disentangles architecture features into critical
  (causal) and redundant (non-causal) components in the latent space.
---

# CARL: Causality-guided Architecture Representation Learning for an Interpretable Performance Predictor

## Quick Facts
- arXiv ID: 2506.04001
- Source URL: https://arxiv.org/abs/2506.04001
- Authors: Han Ji; Yuqi Feng; Jiahao Fan; Yanan Sun
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on five NAS search spaces with 97.67% top-1 accuracy on CIFAR-10 using DARTS

## Executive Summary
This paper addresses the problem of poor generalization in neural architecture search (NAS) performance predictors due to spurious correlations learned from biased training samples. The authors propose CARL, a Causality-guided Architecture Representation Learning method that disentangles architecture features into critical (causal) and redundant (non-causal) components in the latent space. By employing a substructure extractor to separate these features and generating interventional samples through latent space manipulation, CARL achieves state-of-the-art performance across multiple NAS benchmarks while providing interpretable insights into which architectural features determine performance.

## Method Summary
CARL uses a graph neural network encoder to process neural architecture graphs, followed by a substructure extractor with MLP layers that generates soft masks to split the representation into critical and redundant components. The model creates interventional samples by pairing critical representations with redundant representations from different architectures within the same mini-batch. A three-part loss function balances accurate ranking on critical features, suppression of redundant features, and invariance to redundant features during intervention. This causal intervention approach aims to eliminate spurious correlations that typically plague NAS performance predictors.

## Key Results
- Achieves 97.67% top-1 accuracy on CIFAR-10 using DARTS search space
- Ranks first on DARTS, second on NAS-Bench-201, and third on NAS-Bench-101 in overall performance
- Demonstrates superior interpretability by identifying critical features that determine architecture performance
- Shows consistent performance across seven tasks in TransNAS-Bench-101 Micro with an average ranking of 12.29

## Why This Works (Mechanism)

### Mechanism 1
Disentangling architecture features into critical (causal) and redundant (non-causal) substructures isolates the features that genuinely determine performance from those that create spurious correlations. A substructure extractor generates node-level and edge-level masks to split the graph representation into disjoint sets. $L_C$ trains the critical path while $L_R$ forces the redundant path to output uniform mean values, stripping its predictive power. This works because architectures contain distinct motifs responsible for performance while other structural features are coincidentally correlated in training data but causally irrelevant.

### Mechanism 2
Generating interventional samples in the latent space cuts the "backdoor path" of spurious correlations by randomizing the context in which critical features appear. The model pairs a critical representation $Z_C$ from one architecture with a redundant representation $Z_R'$ from a different architecture within the mini-batch. By training the regressor to predict the ground truth of $Z_C$ despite the "foreign" $Z_R'$, the model learns to ignore the redundant features. This works because the latent space allows valid synthesis of hybrid architectures that approximate causal intervention without breaking computational flow.

### Mechanism 3
An intervention-based loss function prioritizes critical features by enforcing ranking consistency across synthetic interventional samples. The total loss balances three goals: accurate ranking on critical features ($L_C$), suppression of redundant features ($L_R$), and invariance to redundant features during intervention ($L_I$). This works because the ground truth performance ranking is invariant to changes in the redundant substructures when critical substructures are held constant.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs)**
  - Why needed here: The paper frames the NAS prediction problem as a causal graph ($X \to Y$, $C \to Y$). Understanding confounders and backdoor paths is required to grasp why the intervention works.
  - Quick check question: Can you draw the causal graph connecting Architecture ($X$), Critical Features ($C$), Redundant Features ($R$), and Performance ($Y$) as described in Section 3.2?

- **Concept: Graph Neural Networks (GNNs)**
  - Why needed here: CARL uses a GCN encoder to process the architecture topology. Understanding node/edge embeddings is critical for implementing the substructure extractor.
  - Quick check question: How does a GCN update the representation of a node based on its neighbors, and why is this suitable for representing neural architecture connectivity?

- **Concept: Neural Architecture Search (NAS) Benchmarks**
  - Why needed here: Evaluation relies on NAS-Bench-101/201 and DARTS. Knowing these are tabular benchmarks (for 101/201) vs. search spaces (DARTS) is vital for interpreting the "Query Cost" and "Ktau" results.
  - Quick check question: Why is Kendall's Tau ($\tau$) a more suitable metric for a performance predictor than Mean Absolute Error (MAE) in the context of NAS?

## Architecture Onboarding

- **Component map:** Encoder (GCN) -> Disentangler (MLPs with masks) -> Intervener (latent space module swapping) -> Regressor (MLPs predicting scores for $Z_C$, $Z_R$, and $Z_I$ streams)

- **Critical path:** The interaction between the Substructure Extractor and the Loss Function. If the masks do not successfully separate features, the interventional loss ($L_I$) will train on noise.

- **Design tradeoffs:**
  - *Latent vs. Graph Intervention:* The paper opts for latent-space intervention (swapping embeddings) because graph-level intervention (swapping graph nodes) often breaks the valid computational flow (e.g., creating disconnected graphs).
  - *Complexity:* Introduces three loss terms ($L_C, L_R, L_I$) and two extra encoders ($g_c, g_r$), increasing training complexity compared to standard regression.

- **Failure signatures:**
  - **Uniform Predictions:** If $L_R$ is too strong, the model outputs the mean performance for all architectures.
  - **Mask Collapse:** The extractor assigns all weight to "Critical" ($\alpha_C \approx 1.0$ everywhere), failing to filter out spurious redundant features.
  - **Low Ktau on Small Data:** If the training portion is too small (e.g., < 0.02%), the model cannot learn the underlying causal motifs, as shown in Table 1 trends.

- **First 3 experiments:**
  1. **Sanity Check (Overfit):** Train CARL on a tiny subset (e.g., 50 samples) of NAS-Bench-201. Verify it can perfectly rank these known samples to validate the pipeline.
  2. **Ablation on Disentanglement:** Remove $L_R$ and $L_I$ (turning it into a standard predictor). Compare Kendall's Tau against the full model on NAS-Bench-101 to quantify the gain from the causal mechanism.
  3. **Visualization:** Replicate Figure 5. Visualize the mask matrices ($M_C$) for the best and worst architectures in NAS-Bench-201 to ensure the model identifies "Skip Connect" or "Conv3x3" as critical motifs rather than random edges.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's performance gains appear most pronounced in NAS-Bench-201 and DARTS search spaces, with more modest improvements in NAS-Bench-101, suggesting the causal mechanism may be less effective for certain architecture topologies.
- The approach assumes that the latent space allows for meaningful pairing of critical and redundant representations without creating invalid architectural configurations - this assumption is plausible but not rigorously proven.
- The theoretical guarantees of the causal intervention are limited, with the paper relying primarily on empirical validation rather than formal causal inference guarantees.

## Confidence
- Mechanism 1 (Disentanglement): **High** - Well-supported by ablation studies and visualization results
- Mechanism 2 (Latent intervention): **Medium** - Strong empirical support but theoretical validation needed for latent space pairing validity
- Mechanism 3 (Intervention loss): **High** - Clear ablation evidence showing the necessity of all three loss components

## Next Checks
1. **Out-of-distribution test**: Evaluate CARL on architectures from search spaces not seen during training to verify generalization of causal feature identification
2. **Mask sensitivity analysis**: Systematically vary the soft mask thresholds to determine how robust the critical feature identification is to hyperparameter changes
3. **Causal attribution validation**: Use intervention analysis on held-out test architectures to verify that identified critical features actually causally determine performance when held constant