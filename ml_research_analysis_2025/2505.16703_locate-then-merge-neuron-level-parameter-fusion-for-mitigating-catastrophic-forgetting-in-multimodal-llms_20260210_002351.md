---
ver: rpa2
title: 'Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic
  Forgetting in Multimodal LLMs'
arxiv_id: '2505.16703'
source_url: https://arxiv.org/abs/2505.16703
tags:
- language
- visual
- arxiv
- neurons
- merging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses catastrophic forgetting in multimodal large
  language models (MLLMs), where visual instruction tuning degrades the base LLM's
  language abilities. The authors propose Locate-then-Merge, a training-free parameter
  fusion framework that first identifies important neurons based on parameter change
  magnitude, then selectively merges them.
---

# Locate-then-Merge: Neuron-Level Parameter Fusion for Mitigating Catastrophic Forgetting in Multimodal LLMs

## Quick Facts
- **arXiv ID**: 2505.16703
- **Source URL**: https://arxiv.org/abs/2505.16703
- **Reference count**: 11
- **Primary result**: Neuron-Fusion method achieves better overall ability (language + visual) than existing model merging approaches while reducing context hallucination and "Not-Known" responses

## Executive Summary
This paper addresses catastrophic forgetting in multimodal large language models (MLLMs), where visual instruction tuning degrades the base LLM's language abilities. The authors propose Locate-then-Merge, a training-free parameter fusion framework that first identifies important neurons based on parameter change magnitude, then selectively merges them. Their Neuron-Fusion method preserves neurons with large parameter changes (likely storing visual capabilities) while suppressing widespread small changes (likely degrading language skills). Experiments on 13 benchmarks across two MLLMs show Neuron-Fusion consistently outperforms existing model merging methods.

## Method Summary
Locate-then-Merge is a training-free parameter fusion framework for multimodal LLMs that addresses catastrophic forgetting through neuron-level analysis. The method operates in two phases: first, it locates important neurons by analyzing parameter change magnitudes between base and tuned models; second, it merges these neurons selectively to preserve critical capabilities while mitigating degradation. The Neuron-Fusion approach specifically targets parameter changes, preserving neurons with large magnitude changes (assumed to store visual capabilities) while suppressing widespread small changes (which tend to degrade language skills). The framework operates without additional training, making it computationally efficient compared to fine-tuning approaches.

## Key Results
- Neuron-Fusion consistently outperforms existing model merging methods (Task Arithmetic, TIES, Breadcrumbs, DARE, DELLA) across 13 benchmarks
- The best configurations (Neu-P-TaskA and Neu-P-Bread) achieve the highest overall accuracy while maintaining both language and visual capabilities
- Generation analysis reveals Neuron-Fusion effectively reduces context hallucination and "Not-Known" responses compared to baseline methods

## Why This Works (Mechanism)
The paper doesn't explicitly detail the mechanism beyond the general approach of identifying and preserving neurons with large parameter changes while suppressing smaller ones. The underlying assumption is that large parameter changes indicate important visual capability storage, while small widespread changes indicate language skill degradation.

## Foundational Learning

**Catastrophic forgetting**: When training on new tasks, neural networks tend to overwrite previously learned knowledge. This is particularly problematic in multimodal models where visual instruction tuning can degrade language capabilities.

*Why needed*: Understanding this phenomenon is crucial because it's the core problem the paper addresses - preventing loss of language skills when adding visual capabilities.

*Quick check*: Verify that performance degrades on original tasks after training on new tasks without intervention.

**Parameter fusion**: The process of combining parameters from different models (base and tuned versions) to create a unified model that retains capabilities from both.

*Why needed*: This is the fundamental technique used to merge visual and language capabilities without additional training.

*Quick check*: Confirm that the merged model performs better than either individual model on combined tasks.

**Neuron importance**: The concept that different neurons contribute unequally to model performance, with some being more critical for specific capabilities.

*Why needed*: This underpins the Locate-then-Merge strategy of selectively preserving certain neurons based on their parameter changes.

*Quick check*: Validate that removing less important neurons has minimal impact on model performance.

## Architecture Onboarding

**Component map**: Base MLLM → Locate Phase (parameter change analysis) → Merge Phase (selective neuron fusion) → Fused MLLM

**Critical path**: The locate phase identifies important neurons through parameter change magnitude analysis, which then informs the merge phase where selective preservation occurs. This two-step process is essential for achieving the reported performance gains.

**Design tradeoffs**: Training-free approach vs. potential gains from fine-tuning; neuron-level granularity vs. computational efficiency; parameter change magnitude as proxy for importance vs. more sophisticated importance metrics.

**Failure signatures**: If parameter change magnitude doesn't correlate with actual importance, the method may preserve wrong neurons; if too aggressive in suppression, language capabilities may still degrade; if too conservative, visual improvements may be limited.

**First experiments**:
1. Compare parameter change distributions between base and tuned models to validate the assumption about large vs. small changes
2. Test neuron ablation on a small subset to verify importance ranking
3. Run ablation studies on different neuron selection thresholds to optimize the merge strategy

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to only two specific MLLM architectures (Vicuna-7B+LLaVA-7B and LLaVA-1.5-7B), raising questions about generalizability to other model architectures or sizes
- Training-free nature may miss nuanced parameter interactions that could be captured through fine-tuning
- Relies heavily on parameter change magnitude as the primary metric for neuron importance, which may not fully capture semantic importance

## Confidence
- Major claims: Medium
- Results show consistent improvements over baseline methods
- Ablation studies support Locate-then-Merge strategy effectiveness
- Limited comparison with recent parameter-efficient fine-tuning methods
- Narrow scope of tested model architectures

## Next Checks
1. Test Neuron-Fusion across a broader range of MLLM architectures (different base models, varying parameter counts) to assess generalizability
2. Conduct ablation studies isolating the impact of parameter change magnitude versus other potential importance metrics for neuron selection
3. Perform extensive qualitative analysis of failure cases, particularly focusing on complex multimodal reasoning tasks where catastrophic forgetting might manifest differently