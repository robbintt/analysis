---
ver: rpa2
title: 'Data Curation Matters: Model Collapse and Spurious Shift Performance Prediction
  from Training on Uncurated Text Embeddings'
arxiv_id: '2506.17989'
source_url: https://arxiv.org/abs/2506.17989
tags:
- line
- linq
- zeta
- collapse
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies a critical failure mode in models trained
  on uncurated text embeddings derived from raw tabular data, termed "model collapse,"
  where predictions converge to a single class regardless of input. The authors propose
  metrics to quantify collapse severity and compare models trained with identical
  hyperparameters on raw tabular data versus their text embedding counterparts.
---

# Data Curation Matters: Model Collapse and Spurious Shift Performance Prediction from Training on Uncurated Text Embeddings

## Quick Facts
- **arXiv ID:** 2506.17989
- **Source URL:** https://arxiv.org/abs/2506.17989
- **Reference count:** 40
- **Primary result:** Models trained on uncurated text embeddings from tabular data can collapse to single-class predictions, artificially inflating spurious Accuracy-on-the-Line correlations.

## Executive Summary
This paper identifies a critical failure mode in models trained on uncurated text embeddings derived from raw tabular data, termed "model collapse," where predictions converge to a single class regardless of input. The authors propose metrics to quantify collapse severity and compare models trained with identical hyperparameters on raw tabular data versus their text embedding counterparts. They find that collapse is a consistent failure mode in the embedding setting, and more insidiously, that strong model collapse can artificially inflate spurious Accuracy-on-the-Line (ACL) correlations, misleading OOD performance prediction. Additionally, they uncover no correlation between MTEB leaderboard rankings and an LLM's effectiveness as a data curation layer for real-world domain shifts.

## Method Summary
The authors compare model performance on raw tabular data versus text embeddings generated by LLM encoders. They serialize tabular rows to natural language using Tab2Text, then encode with 4096-dim LLM embeddings (e5-Mistral, Linq, SFR, Zeta). Seven model families (MLP, LR, SVM, RF, GBM, XGB, CVaR-DRO) are trained using specific hyperparameter grids on both raw data and embeddings. Model collapse is detected when models predict only one class (P_N or P_P ≈ 0). ACL correlation (ID accuracy vs OOD accuracy) and F1L correlation (ID macro F1 vs OOD macro F1) are computed to assess OOD performance prediction validity.

## Key Results
- Model collapse occurs consistently across all tested LLM embeddings and model families, with deep models (MLP, CVaR-DRO) most susceptible
- Strong model collapse artificially inflates ACL R² correlations, creating spurious signals for OOD performance prediction
- Cross-LLM embedding incompatibility amplifies collapse, with models trained on one LLM's embeddings collapsing on others'
- MTEB leaderboard rankings show no correlation with LLM effectiveness as a data curation layer for domain shifts

## Why This Works (Mechanism)

### Mechanism 1: Model Collapse from Uncurated Text Embeddings
Models trained on text embeddings derived from raw tabular data can converge to single-class predictions regardless of input, unlike their raw-tabular counterparts trained with identical hyperparameters. The embedding transformation via LLM appears to lose or obscure discriminative signal necessary for multi-class learning. When a model is trained on LLM|D (embedded data), the loss landscape may contain degenerate minima where predicting the majority class is optimal.

### Mechanism 2: Spurious Inflation of Accuracy-on-the-Line (ACL) via Collapse
Strong model collapse can artificially inflate the R² correlation between in-distribution (ID) and out-of-distribution (OOD) accuracy, creating a misleading signal for OOD performance prediction. When many model configurations collapse to the same single-class prediction, their (ID accuracy, OOD accuracy) coordinates cluster at a single point determined by the majority class ratio in each test set.

### Mechanism 3: Cross-LLM Embedding Incompatibility Amplifies Collapse
Models trained on embeddings from one LLM are highly susceptible to collapse when evaluated on embeddings from a different LLM—even if the model was well-behaved on the training LLM's embeddings. Each LLM encoder creates a distinct embedding space, and a downstream model learns decision boundaries specific to that geometry. When evaluated on embeddings from a different encoder, the feature distribution shifts and the learned boundaries may fall entirely within a single class region of the new space.

## Foundational Learning

- **Text Embeddings as Data Curation**
  - Why needed here: The paper frames LLM embeddings as an automated curation layer that transforms heterogeneous tabular data into dense vectors. Understanding this abstraction is necessary to interpret why "curation" can fail silently.
  - Quick check question: Can you explain why a 4096-dimensional dense vector derived from a serialized table row might lose information compared to the original features?

- **Accuracy-on-the-Line (ACL) and Its Limitations**
  - Why needed here: ACL is the evaluative framework the paper critiques. It assumes that if ID accuracy correlates with OOD accuracy across model configurations, OOD performance can be predicted from ID performance. The paper shows collapse violates this assumption.
  - Quick check question: If 50% of your model configurations predict only the majority class, would you expect the ACL R² to be high or low? Why?

- **Conditional Distribution Shifts (Y|X-shifts)**
  - Why needed here: The paper distinguishes Y|X-shifts (changes in the relationship between features and labels) from X-shifts (covariate shift). Text embeddings are hypothesized to help with Y|X-shifts, but collapse undermines this.
  - Quick check question: In a census income prediction task, would a change in the income distribution across states be an X-shift or a Y|X-shift?

## Architecture Onboarding

- **Component map**: Tabular row → Tab2Text → LLM embedding → Downstream model training → (ID test, OOD test) → (ACL-plane, F1L-plane) → Collapse metrics (CR_s, CR_p)

- **Critical path**: Tabular row → Tab2Text → LLM embedding → Downstream model training → (ID test, OOD test) → (ACL-plane, F1L-plane) → Collapse metrics (CR_s, CR_p)

- **Design tradeoffs**:
  - Raw tabular vs. embeddings: Raw data avoids collapse but may underperform on Y|X-shifts; embeddings may improve robustness but introduce collapse risk
  - LLM selection: MTEB rankings do not predict OOD robustness; a lower-ranked LLM (Zeta, rank 177) outperforms higher-ranked ones on FractionBest comparisons
  - Metric selection: Accuracy masks collapse under class imbalance; macro F1 is more sensitive but still shows spurious correlation when collapse is strong

- **Failure signatures**:
  - Model accuracy equals the majority class ratio in the test set
  - Near-zero predicted positives or predicted negatives (P_N or P_P ≈ 0)
  - High R² in ACL-plane accompanied by clustered points at class-ratio coordinates
  - Models that perform well on one LLM's embeddings collapse on another's

- **First 3 experiments**:
  1. **Establish baseline on raw tabular data**: Train all model families (MLP, LR, XGB, etc.) on raw CA data with the hyperparameter grid from Table 6. Verify that no configuration collapses. This confirms your "well-defined" HP set.
  2. **Introduce embeddings and compute collapse metrics**: For a single LLM (e.g., e5-Mistral), train the same model configurations on e5|CA. Compute CR_s and CR_p for each (source, target) pair. Plot in ACL and F1L planes. Identify which model families are most susceptible.
  3. **Cross-LLM transfer test**: Train an MLP on e5|CA using a known-non-collapsing configuration. Evaluate on Linq|CA, SFR|CA, Zeta|CA (same domain, different encoder). Record confusion matrices. This reveals whether collapse is inherent to the model or to encoder mismatch.

## Open Questions the Paper Calls Out
- What specific data curation or preprocessing techniques can effectively mitigate model collapse when training on uncurated text embeddings derived from tabular data?
- Does the model collapse phenomenon and its resulting spurious correlation hold for multi-class classification tasks, or is it unique to the binary classification setting analyzed?
- Why do Logistic Regression models exhibit geometric stability and avoid collapse while deep models (MLP, CVaR-DRO) collapse on the same uncurated embeddings?

## Limitations
- The underlying mechanism for model collapse remains speculative - attributed to information loss during LLM encoding but not empirically measured
- Cross-LLM incompatibility findings lack baseline comparisons with aligned embedding spaces
- Spurious ACL correlation analysis focuses on binary classification; generalization to multi-class problems is unclear
- Tab2Text serialization template is referenced from external work without explicit specification

## Confidence
- **High confidence**: Model collapse occurs consistently across LLM embeddings and is not observed in raw tabular training with identical hyperparameters
- **Medium confidence**: Cross-LLM embedding incompatibility amplifies collapse risk
- **Medium confidence**: Spurious ACL correlation inflation via collapse

## Next Checks
1. Measure information preservation: Compare mutual information between raw features and embeddings across different LLMs to quantify representational degradation that correlates with collapse likelihood
2. Test embedding alignment: Apply Procrustes alignment to cross-LLM embeddings and retrain models to determine if collapse rates decrease
3. Validate on multi-class tasks: Replicate the ACL correlation analysis on multi-class tabular datasets to verify if spurious correlation patterns persist beyond binary classification