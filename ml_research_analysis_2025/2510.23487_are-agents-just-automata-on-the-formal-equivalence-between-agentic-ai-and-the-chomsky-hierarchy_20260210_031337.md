---
ver: rpa2
title: Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and
  the Chomsky Hierarchy
arxiv_id: '2510.23487'
source_url: https://arxiv.org/abs/2510.23487
tags:
- finite
- probabilistic
- memory
- agent
- controller
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes a formal equivalence between the architectural
  classes of modern agentic AI systems and the abstract machines of the Chomsky hierarchy.
  We posit that the memory architecture of an AI agent is the definitive feature determining
  its computational power and that it directly maps it to a corresponding class of
  automaton.
---

# Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy

## Quick Facts
- arXiv ID: 2510.23487
- Source URL: https://arxiv.org/abs/2510.23487
- Reference count: 30
- One-line primary result: Agent memory architecture determines computational power; reflex agents are finite automata, hierarchical agents are pushdown automata, reflective agents are Turing machines.

## Executive Summary
This paper establishes a formal equivalence between modern agentic AI architectures and the abstract machines of the Chomsky hierarchy, demonstrating that an agent's memory architecture directly determines its computational power. We show that simple reflex agents map to Finite Automata, hierarchical task-decomposition agents map to Pushdown Automata, and agents employing readable/writable memory for reflection map to Turing Machines. This Automata-Agent Framework provides a principled methodology for right-sizing agent architectures to optimize computational efficiency and cost, while creating a direct pathway to formal verification through established techniques from automata theory.

## Method Summary
The paper employs formal proofs via construction of support automata from agent architectures, defining three agent classes based on memory constraints: Regular Agents (bounded memory), Context-Free Agents (stack-scoped memory), and Turing Complete Agents (unbounded read/write memory). For each class, the authors construct corresponding automata (NFA, PDA, TM) and prove the trace language support is regular, context-free, or recursively enumerable. The method includes abstraction maps α: C → Ŝ to finite state spaces for probabilistic model checking, extending the framework to handle probabilistic agents through induced Markov chains, MDPs, and pushdown systems.

## Key Results
- Established formal equivalence between agent memory architectures and automata classes (FA, PDA, TM) based on memory constraints
- Demonstrated induced probabilistic models (Markov chains, MDPs, pushdown systems) support verification for each agent class
- Provided right-sizing guidelines for agent architectures to optimize computational efficiency and cost

## Why This Works (Mechanism)
The framework works because memory architecture fundamentally determines computational power, just as in the Chomsky hierarchy. By constraining how agents store and access information over time, we can precisely classify their capabilities and the complexity of behaviors they can exhibit. This classification enables direct application of formal verification techniques from automata theory, allowing us to guarantee safety and predictability for verifiable systems while acknowledging fundamental undecidability boundaries for more powerful agents.

## Foundational Learning
- **Regular languages and Finite Automata**: Why needed - to understand the computational limits of reflex agents; Quick check - verify that trace languages are regular by constructing NFAs
- **Context-free languages and Pushdown Automata**: Why needed - to analyze hierarchical task-decomposition capabilities; Quick check - test if nested subtask calls create context-free traces
- **Turing Completeness and unbounded memory**: Why needed - to recognize when agents exceed decidable verification boundaries; Quick check - identify if agents can simulate arbitrary computations through persistent memory
- **Abstraction functions for verification**: Why needed - to enable probabilistic model checking while preserving control-relevant distinctions; Quick check - validate that abstract traces correspond to concrete executions

## Architecture Onboarding
- **Component map**: Agent perception -> Memory architecture (bounded/stack/unbounded) -> Action selection -> Environment response
- **Critical path**: Perception processing → Memory state update → Action selection → Tool execution → Observation → Repeat
- **Design tradeoffs**: Memory capacity vs. verification tractability vs. computational expressiveness
- **Failure signatures**: Memory constraint violations (undecidable behavior), abstraction unsoundness (verification gaps), state explosion (tractability loss)
- **First experiments**:
  1. Implement three agent architectures for a booking task and verify trace language classifications
  2. Design abstraction function for Context-Free Agent and test soundness preservation
  3. Build induced Markov chain for probabilistic Regular Agent and apply PRISM model checking

## Open Questions the Paper Calls Out
None

## Limitations
- No concrete implementation details for the case study booking controller (state definitions, transition logic)
- Abstraction function α is not specified for any concrete system, leaving verification pipeline incomplete
- Assumes finite, observable perception and action spaces, which may not hold for continuous or unbounded domains

## Confidence
- Formal equivalence proofs (FA/PDA/TM): High
- Induced probabilistic models: Medium
- Abstraction function design for verification: Low

## Next Checks
1. Implement the three agent architectures (Regular, Context-Free, TC) for a simple booking task with defined Σ and Γ. Verify trace language regularity/context-freeness/recursiveness by constructing the support automata.
2. For the Context-Free Agent, design and test an abstraction function α that preserves control-relevant distinctions. Verify soundness by checking that abstract traces correspond to concrete executions.
3. Extend the Regular Agent with probabilistic tool outcomes (e.g., success/failure). Build the induced Markov chain and apply PRISM model checking to verify a simple safety property (e.g., "no more than 3 retries").