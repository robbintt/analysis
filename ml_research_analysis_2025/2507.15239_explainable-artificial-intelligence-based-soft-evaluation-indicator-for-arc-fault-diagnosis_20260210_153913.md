---
ver: rpa2
title: Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc
  Fault Diagnosis
arxiv_id: '2507.15239'
source_url: https://arxiv.org/abs/2507.15239
tags:
- fault
- accuracy
- score
- feature
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an explainable artificial intelligence (XAI)
  based soft evaluation indicator (XSEI) for arc fault diagnosis models, addressing
  the problem of assessing whether AI models accurately detect real arc faults beyond
  classification accuracy. The XSEI combines SHapley Additive exPlanations (SHAP)
  and occlusion sensitivity to evaluate feature extraction performance against defined
  ground truth features.
---

# Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis

## Quick Facts
- arXiv ID: 2507.15239
- Source URL: https://arxiv.org/abs/2507.15239
- Reference count: 36
- Primary result: Proposes XSEI framework combining SHAP and occlusion sensitivity to evaluate model interpretability in arc fault diagnosis

## Executive Summary
This paper addresses the critical gap between classification accuracy and interpretability in arc fault diagnosis models. The authors introduce a soft evaluation indicator (XSEI) that uses explainable AI techniques to assess whether models correctly identify genuine arc fault features rather than spurious correlations. A lightweight balanced neural network (LBNN) is proposed that achieves competitive accuracy (94.55%) while maintaining high interpretability scores. The framework demonstrates that high classification accuracy does not guarantee reliable fault detection, as models may exploit non-physical features.

## Method Summary
The method introduces XSEI, which combines SHAP (for machine learning models) and occlusion sensitivity (for deep learning models) to evaluate feature extraction performance against defined ground truth features. For ML models, ground truth consists of five statistical features (Variance, Entropy, Range, RMS, Integral), while for DL models it's signal regions where normal and arc currents differ. The LBNN architecture uses average pooling layers to better capture distributed arc fault distortions. The framework evaluates models across varying sampling times and noise levels to identify those with genuine interpretability.

## Key Results
- High classification accuracy (>98%) does not guarantee high model interpretability or reliable fault detection
- XSEI successfully identifies models that reliably locate arc faults, with LBNN achieving 94.55% average accuracy and 0.46 soft score
- Average pooling outperforms max pooling for arc fault feature extraction due to the distributed nature of arc fault distortions
- Models with high soft scores show faster accuracy degradation under adverse conditions (low sampling rates, high noise)

## Why This Works (Mechanism)

### Mechanism 1: Feature Extraction Score via XAI Alignment
XSEI computes a Jaccard-like similarity score between model-attributed features (via SHAP for ML, occlusion sensitivity for DL) and predefined ground truth features. For ML methods, ground truth is five features {Variance, Entropy, Range, RMS, Integral}; for DL, it is signal regions where normal and arc current differ. The core assumption is that ground truth features derived from physical arc fault theory correctly characterize real arc phenomena.

### Mechanism 2: Rapid Accuracy Drop as an Interpretability Proxy
Models with higher soft scores exhibit faster accuracy degradation when sampling precision or SNR changes adversarially. When models genuinely rely on arc-specific features rather than generalizable shortcuts, those features become unreliable under resolution reduction or noise injection, causing sharp accuracy drops.

### Mechanism 3: Average Pooling for Arc Fault Feature Geometry
Average pooling layers better match arc fault signal characteristics than max pooling for interpretable detection. Arc faults manifest as distributed small-area distortions in current signals, not isolated spikes. Average pooling aggregates information over these regions, whereas max pooling may latch onto isolated noise or transient peaks.

## Foundational Learning

- **SHAP (SHapley Additive exPlanations)**:
  - Why needed here: Provides theoretically grounded feature importance scores for ML models, enabling comparison to ground truth
  - Quick check question: If feature A has SHAP value 0.3 and feature B has 0.05, which contributes more to the prediction?

- **Occlusion Sensitivity Analysis**:
  - Why needed here: Identifies which input regions neural networks depend on for predictions, essential for spatial interpretability
  - Quick check question: Masking region R reduces prediction probability from 0.95 to 0.20—what does this imply about R?

- **Arc Fault Signal Physics (High-Frequency Distortions)**:
  - Why needed here: Ground truth definition relies on understanding how arc faults manifest as high-frequency current anomalies under varying loads
  - Quick check question: Why might switch-mode power supply noise be confused with arc fault signatures?

## Architecture Onboarding

- **Component map**: 
  - XSEI evaluator: Takes trained model + validation data → SHAP/occlusion attributions → compares to ground truth features → outputs soft score (0–1)
  - LBNN: Conv(5×1, 6 filters) → AvgPool(2) → Conv(3×1, 16 filters) → AvgPool(2) → FC(256) → FC(16) → Softmax (1.02M parameters)
  - Ground truth generator: For ML—five features {Variance, Entropy, Range, RMS, Integral}; for DL—binary mask of signal regions differing between normal and arc signals

- **Critical path**:
  1. Collect paired normal/arc current signals under target loads
  2. Define ground truth regions (DL) or compute ground truth features (ML)
  3. Train candidate models
  4. Run SHAP (ML) or occlusion sensitivity (DL) on validation set
  5. Compute XSEI score via Eq. (5) or (6)
  6. Select models with acceptable accuracy-interpretability balance

- **Design tradeoffs**:
  - Max pooling vs. average pooling: Max pooling may achieve higher accuracy but lower soft scores; average pooling improves interpretability at potential minor accuracy cost
  - Model complexity: Deeper models (AE: 32.75M params) achieve higher accuracy but not necessarily higher soft scores; lightweight models (ArcNN: 0.14M, LBNN: 1.02M) can balance both
  - Feature pool size: Larger pools may boost accuracy but dilute interpretability if models latch onto non-ground-truth features

- **Failure signatures**:
  - High accuracy (>98%) + low soft score (<0.3): Model likely using spurious features
  - Flat accuracy across SNR/sampling variations: Model may be using robust but irrelevant features
  - SHAP/occlusion attributions scattered across irrelevant regions: Ground truth mismatch

- **First 3 experiments**:
  1. Baseline replication: Train LBNN on Dataset 1 (complex loads) with 5×10⁻³ms sampling, compute XSEI score; verify ~94–95% accuracy with ~0.4–0.5 soft score
  2. Ablation on pooling: Replace average pooling with max pooling in LBNN, compare accuracy and soft score across SNR levels {-5, -3, 1, 5}
  3. Cross-model XSEI ranking: Train SVM, L2/L1, XGBoost, SEmodel, AE, ArcNN on same data; rank by XSEI score; verify that SEmodel/L2/L1 have highest ML soft scores and AE/ArcNN have highest DL soft scores

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the XSEI framework be automated to reduce the high level of expertise currently required to select appropriate combinations of classifiers and XAI techniques?
- Basis in paper: The conclusion states that the "main limitation of this method is the multiple combinations of classifiers and XAI techniques, which require a lot of expertise."
- Why unresolved: The current implementation relies on manual selection and interpretation of complex combinations (e.g., SHAP for feature pools vs. Occlusion for deep learning), which acts as a barrier to entry for practitioners without specialized knowledge.
- What evidence would resolve it: The development of an automated pipeline or meta-learning algorithm that can select the optimal XAI technique for a given model architecture without human intervention, while maintaining evaluation accuracy.

### Open Question 2
- Question: Does the rigid definition of "ground truth features" (Variance, Entropy, Range, RMS, Integral) constrain the evaluation of models that may identify valid but previously undefined physical characteristics?
- Basis in paper: Section III.A defines ground truth features based on existing literature and Mayr's model. The paper limits the "correct explanation" to a specific set of five primary features, potentially ignoring secondary or complex features.
- Why unresolved: If a model extracts a valid, highly accurate feature that is not in the predefined set $S$ (e.g., a specific high-order statistical bias), the XSEI score would penalize it, mistaking novelty for error.
- What evidence would resolve it: An experiment where a model utilizing features outside the set $S$ achieves high arc fault detection accuracy on unseen data, but receives a low XSEI score, triggering a need to expand the ground truth definition.

### Open Question 3
- Question: Can the XSEI methodology be generalized to industrial diagnostics where fault characteristics are less distinct than the high-frequency distortions found in arc faults?
- Basis in paper: The paper states the method "holds the potential for adaptation to other domains," but the methodology relies on the specific phenomenon that arc faults manifest as clear high-frequency signal changes (ground truth definition in Eq. 4).
- Why unresolved: In other domains (e.g., mechanical bearing faults), ground truth "regions" may overlap with normal signal noise or be non-stationary, making the binary definition of ground truth regions ($r_n = 1$ if $x_n \neq \hat{x}_n$) difficult to apply.
- What evidence would resolve it: Successful application of the XSEI framework to a non-electrical dataset (e.g., vibration or acoustic data) where the "ground truth" is defined by subtler, non-binary signal changes.

## Limitations

- The validity of the soft evaluation indicator hinges critically on the accuracy of ground truth feature definitions, which may not fully capture arc fault physics across all operating conditions
- SHAP and occlusion sensitivity methods have known limitations in attribution reliability, particularly for complex deep learning models
- The study focuses on arc fault diagnosis specifically, limiting generalizability to other fault detection domains

## Confidence

- **High Confidence**: The correlation between high classification accuracy and low soft scores (demonstrating accuracy alone is insufficient); the effectiveness of the LBNN architecture in balancing accuracy and interpretability
- **Medium Confidence**: The theoretical foundation of using XAI methods for evaluation; the claim that average pooling better captures arc fault features than max pooling
- **Low Confidence**: The universal applicability of the XSEI framework across different fault types; the assumption that fast accuracy degradation always indicates genuine feature usage

## Next Checks

1. **Ground Truth Robustness Test**: Apply XSEI to synthetic datasets where ground truth features are known with certainty to verify the scoring mechanism works as intended
2. **Cross-Domain Validation**: Test XSEI on different fault detection domains (e.g., bearing fault diagnosis, thermal faults) to assess generalizability
3. **Attribution Method Comparison**: Compare XSEI scores using different XAI methods (LIME, integrated gradients) to evaluate sensitivity to attribution choice