---
ver: rpa2
title: LLMs are Introvert
arxiv_id: '2507.05638'
source_url: https://arxiv.org/abs/2507.05638
tags:
- social
- agents
- agent
- evaluation
- cues
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the gap between large language models (LLMs)
  and human-like social cognition in simulations of information propagation. While
  LLMs excel at linguistic tasks, they struggle to interpret subtle social cues and
  generate nuanced emotional responses.
---

# LLMs are Introvert

## Quick Facts
- arXiv ID: 2507.05638
- Source URL: https://arxiv.org/abs/2507.05638
- Reference count: 40
- Key outcome: SIP-CoT-enhanced agents achieve significantly improved performance in social simulations, with reductions in bias and diversity deviation and better alignment in stance, content, and emotion classification

## Executive Summary
This study addresses the gap between large language models (LLMs) and human-like social cognition in simulations of information propagation. While LLMs excel at linguistic tasks, they struggle to interpret subtle social cues and generate nuanced emotional responses. The authors propose a Social Information Processing-based Chain of Thought (SIP-CoT) mechanism enhanced by emotion-guided memory to bridge this gap. Experimental results show that SIP-CoT-enhanced agents achieve significantly improved performance in social simulations, with reductions in bias and diversity deviation (from 0.108 and 0.087 to 0.0521 and 0.0817, respectively) and better alignment in stance, content, and emotion classification.

## Method Summary
The authors developed a Social Information Processing-based Chain of Thought (SIP-CoT) architecture that implements a five-stage cognitive pipeline (Encoding, Interpretation, Goals, Access, Evaluation) to simulate human-like social reasoning. The system uses emotion-guided memory to store and retrieve both generalized social norms and specific interaction histories, enabling agents to ground responses in continuous personal timelines. The architecture was evaluated through SIP-testing and large-scale agent-based simulations on a Reddit-like platform, measuring distributional alignment metrics including bias, diversity deviation, and statistical shape parameters (kurtosis and skewness).

## Key Results
- SIP-CoT-enhanced agents reduced bias and diversity deviation from 0.108/0.087 to 0.0521/0.0817 respectively
- SIP-testing showed enhanced agents produced responses more closely aligned with human patterns across all five stages of social cognition
- Emotion-guided memory enabled agents to handle ambiguous cues and goal classification more effectively than baseline LLMs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enforcing a structured, multi-stage cognitive pipeline reduces the "rigid self-consistency" and low diversity typical of baseline LLM agents in social contexts.
- **Mechanism:** The SIP-CoT intervenes at the generation level, forcing the model to generate latent states for Cue Interpretation and Goal Classification before accessing a response, introducing friction and nuance.
- **Core assumption:** LLMs possess internal capability to differentiate social nuances but fail to express them without explicit scaffolding.
- **Evidence anchors:** Correlation matrices show enhanced agents decouple goals from fixed responses, evidencing flexible inference.
- **Break condition:** Likely fails if LLM lacks semantic understanding to distinguish between stages, resulting in repetitive reasoning steps.

### Mechanism 2
- **Claim:** Social realism improves when agent memory is partitioned into "Social Cognitive" (schemas/norms) and "Social Behavior" (history) modules.
- **Mechanism:** The Social Memory Module separates generalized knowledge from episodic history, retrieving specific past interactions alongside general norms during Response Access stage.
- **Core assumption:** Human-like social response relies on continuity of "self" across time steps, which standard context windows lose.
- **Evidence anchors:** Social Cognitive Memory stores generalized social knowledge while Social Behavior Memory records specific past interactions.
- **Break condition:** Fails if retrieval mechanism retrieves irrelevant memories, causing mood-congruent bias errors.

### Mechanism 3
- **Claim:** Aligning agent behavior with human statistical distributions requires explicit probabilistic "softening" via emotion-guided prompting.
- **Mechanism:** Emotion-Guided Memory modulates Response Evaluation stage, using emotion tags to skew selection probability space toward human-like skewness and kurtosis.
- **Core assumption:** Standard RLHF training aligns models to be "helpful/harmless" (conservative), diverging from messy, high-variance reality of human social media data.
- **Evidence anchors:** Reductions in bias and diversity deviation metrics; radar charts show enhanced agents matching human kurtosis better.
- **Break condition:** Over-weighting emotion leads to "hysterical" or unstable agent trajectories.

## Foundational Learning

- **Concept: Social Information Processing (SIP) Theory**
  - **Why needed here:** This is the theoretical "blueprint" for the entire architecture. You cannot debug the agent's reasoning without understanding the 5 stages.
  - **Quick check question:** If an agent correctly interprets a hostile cue but chooses a neutral response, which SIP stage likely failed (Interpretation or Goal Classification)?

- **Concept: Agent-Based Modeling (ABM) vs. Prompting**
  - **Why needed here:** The paper simulates populations, not just single turns. You need to understand how macro-level metrics emerge from micro-level agent states.
  - **Quick check question:** Does the simulation update agent states synchronously or asynchronously, and how does that affect propagation?

- **Concept: Distributional Alignment (Kurtosis/Skewness)**
  - **Why needed here:** The paper evaluates success not just on "correctness" but on statistical shape (do agents behave as erratically as humans?).
  - **Quick check question:** Why is matching the "variance" (diversity) of human data arguably more important for simulation fidelity than matching the "mean" (bias)?

## Architecture Onboarding

- **Component map:** Input Event -> Cues Focusing -> Memory Retrieval -> Interpretation -> Goal Setting -> Action
- **Critical path:** Input Event -> Cues Focusing (Filtering noise) -> Memory Retrieval (Contextualizing) -> Interpretation (Emotional tagging) -> Goal Setting (Prioritizing intent) -> Action
- **Design tradeoffs:**
  - **Latency vs. Fidelity:** 5-stage SIP-CoT requires 5 distinct generation steps, significantly increasing token cost and latency compared to single-shot response
  - **Stability vs. Diversity:** Increasing "emotion-guided" randomness improves diversity metrics but risks simulation instability
- **Failure signatures:**
  - **The "Polite Robot":** Agent defaults to "Neutral/Happy" and "Prosocial" regardless of input toxicity. *Diagnosis:* Emotion-guided weighting is too weak
  - **The "Echo Chamber":** Δdiv. drops to 0 (consensus reached instantly). *Diagnosis:* Interpretation of Cues stage is not introducing enough ambiguity/variance
  - **Amnesia:** Agent contradicts its stance from Step T-1 at Step T. *Diagnosis:* Short-term Social Interaction Memory is not persisting or being retrieved correctly
- **First 3 experiments:**
  1. **SIP-Testing Ablation:** Run 13-question SIP test on baseline LLM vs. SIP-CoT prompt. Verify if "Distribution" actually changes visually before running full simulations
  2. **Memory Stress Test:** Construct scenario where agent is insulted in Step 1. Check if agent recalls grudge in Step 10 vs. control agent without memory
  3. **Diversity Scaling:** Run 50-agent simulation. Plot Δbias over 7 steps. If line is flat, agents are not influencing each other; if it diverges wildly, emotion weighting is too high

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the SIP-enhanced cognitive architecture be effectively extended to multimodal environments to interpret non-verbal visual social cues?
- Basis in paper: [explicit] The Discussion section states, "Extending SIP beyond text by integrating visual information could capture non-verbal cues indispensable to social reasoning."
- Why unresolved: The current study relies exclusively on text-based Reddit data, and the standard SIP-CoT implementation does not process image or video inputs.
- What evidence would resolve it: Experimental results showing SIP-CoT agents successfully processing multimodal inputs (e.g., video clips of social interactions) with performance metrics comparable to the text-only results.

### Open Question 2
- Question: Does the SIP-enhanced architecture generalize to different cultural contexts and social media platforms outside of Reddit?
- Basis in paper: [explicit] The Discussion section notes, "Future validation demands multimodal, cross-cultural datasets and various platform assessments."
- Why unresolved: The dataset is limited to Reddit, and social norms (encoded in the agents) may be implicitly biased toward the demographics of that platform.
- What evidence would resolve it: Replication of the simulation experiments on platforms like Weibo or Twitter with culturally diverse datasets, maintaining low bias/diversity deviation scores.

### Open Question 3
- Question: How can the specific performance gap in the "Encoding of Cues" stage for emotion-laden constructs be further reduced?
- Basis in paper: [inferred] The Discussion acknowledges that "emotion-laden constructs—particularly cues encoding still yield lower human–agent agreement," despite overall improvements from SIP-CoT.
- Why unresolved: While SIP-CoT improved global metrics, the specific stage of encoding ambiguous or emotional cues remains a bottleneck where agents differ significantly from humans.
- What evidence would resolve it: Architectural modifications (e.g., specialized emotion encoders) that result in SIP-testing distributions for "Encoding of Cues" that are statistically indistinguishable from human responses.

## Limitations

- Real-world social media platforms exhibit far more complex dynamics including algorithmic curation, external events, and cross-platform information flow that could fundamentally alter agent behavior patterns
- The emotion-guided memory mechanism relies on an external emotion classifier whose accuracy and potential biases could cascade through the entire simulation
- The assumption that human-like variance equals human-like behavior may not hold, as introduced variance might capture statistical noise rather than meaningful social dynamics

## Confidence

**High Confidence:** The architectural improvements in SIP-CoT prompting are well-supported by correlation matrix evidence showing decoupled goal-response relationships compared to baseline models.

**Medium Confidence:** The memory module partitioning shows theoretical soundness and aligns with established ABM practices, but limited evidence on how effectively retrieval matches specific memories to current contexts.

**Low Confidence:** The emotion-guided variance tuning achieves impressive distributional alignment metrics, but the underlying assumption that human-like variance equals human-like behavior may not hold.

## Next Checks

1. **Cross-Platform Validation:** Deploy SIP-CoT agents in a Twitter/X simulation environment with different network topology and information velocity. Compare whether distributional alignment gains persist when network effects differ from Reddit-like environment.

2. **Emotion Classifier Ablation:** Run full simulation pipeline with emotion classifier disabled, using neutral prompts only. Measure whether distributional alignment improvements persist or if driven by emotion classifier output rather than SIP-CoT architecture.

3. **Long-Term Stability Test:** Extend 50-agent simulation from 7 steps to 50 steps while monitoring for emergent behaviors like echo chambers, polarization tipping points, or memory degradation. Track whether SIP-enhanced agents maintain stable social dynamics or exhibit pathological behaviors that emerge only in extended simulations.