---
ver: rpa2
title: 'FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web
  Agents'
arxiv_id: '2510.03204'
source_url: https://arxiv.org/abs/2510.03204
tags:
- visible
- agent
- task
- agents
- role
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FOCUSAGENT is a web agent that uses a lightweight LLM retriever
  to prune long AxTree observations by over 50%, reducing computational cost and exposure
  to prompt injection attacks. The retriever selects task-relevant lines based on
  the current goal and optional interaction history, then formats a streamlined AxTree
  for the main agent.
---

# FocusAgent: Simple Yet Effective Ways of Trimming the Large Context of Web Agents

## Quick Facts
- arXiv ID: 2510.03204
- Source URL: https://arxiv.org/abs/2510.03204
- Reference count: 40
- FocusAgent achieves over 50% AxTree pruning while matching baseline task success rates and reducing prompt injection vulnerability.

## Executive Summary
FocusAgent addresses the challenge of large context windows in web agents by using a lightweight LLM retriever to selectively prune AxTree observations. The retriever extracts task-relevant lines guided by the current goal and optional interaction history, enabling significant context reduction without sacrificing performance. Experiments show that FocusAgent matches baseline success rates while reducing exposure to prompt injection attacks, demonstrating both efficiency and security benefits. The method is model-agnostic and open-sourced, offering practical improvements for web automation tasks.

## Method Summary
FocusAgent introduces a two-stage architecture where a lightweight LLM retriever prunes long AxTree observations by extracting only task-relevant lines based on the current goal and optional history. The pruned AxTree is then fed to a main agent for action prediction. A soft retrieval prompt encourages recall over precision to avoid missing critical elements. The approach generalizes across different backbone models and includes a defense variant that explicitly warns the retriever about potential attacks, further reducing prompt injection success rates.

## Key Results
- FocusAgent achieves over 50% AxTree pruning while maintaining task success rates comparable to baselines.
- The method significantly reduces vulnerability to prompt injection attacks, with ASR dropping from 32.4% to 0.9% on banner attacks and from 90.4% to 1.0% on popup attacks.
- FocusAgent outperforms embedding-based retrieval baselines by 10-15 percentage points on both WorkArena and WebArena benchmarks.

## Why This Works (Mechanism)

### Mechanism 1: Goal-Guided LLM Retrieval
A lightweight LLM retriever selectively extracts task-relevant AxTree lines better than embedding-based methods by reasoning about page state and future actions from the task goal and observation. The retriever outputs line ranges, leveraging its ability to infer action-relevant elements even when not explicitly mentioned in the goal.

### Mechanism 2: Incidental Attack Removal via Relevance Filtering
Retrieval-based pruning reduces prompt injection success by excluding non-task-relevant content that contains malicious instructions. Since banner/pop-up attacks inject instructions in elements unrelated to user goals, the retriever naturally excludes these while seeking task-relevant lines.

### Mechanism 3: Soft Retrieval Prompting Preserves Critical Context
Instructing the retriever to prefer recall over precision maintains task performance while still achieving 50%+ pruning. The "soft" prompt tells the LLM: if uncertain, keep the line, avoiding aggressive pruning that removes necessary elements.

## Foundational Learning

- Concept: **Accessibility Tree (AxTree)**
  - Why needed here: This is the agent's observation format—a simplified DOM representation (~10x smaller) that still exceeds context limits. Understanding its structure is prerequisite to any retrieval logic.
  - Quick check: Can you explain why AxTree is preferred over raw DOM for web agents, and what information it preserves?

- Concept: **Prompt Injection Attacks on Agents**
  - Why needed here: The security benefit relies on understanding how malicious instructions appear in AxTree (banners, popups) and why naive filtering fails.
  - Quick check: How does an indirect prompt injection differ from direct prompt engineering, and where would it appear in an AxTree?

- Concept: **Two-Stage Agent Architecture**
  - Why needed here: FocusAgent separates retrieval (small model) from action prediction (large model). This cost-saving pattern requires understanding the handoff between stages.
  - Quick check: What information must the retriever preserve for the main agent to successfully predict the next action?

## Architecture Onboarding

- Component map: Input (goal + AxTree + history) -> Retriever (LLM with soft prompt) -> Post-processor (filter and format) -> Main Agent (action prediction)
- Critical path: Retrieval prompt design -> line range extraction -> AxTree reconstruction -> main agent prompt. The retriever prompt is the key artifact.
- Design tradeoffs:
  - Pruning vs performance: Full removal (51% pruning, 51.5% SR) vs keeping bid+role (22% pruning, 53.9% SR)
  - With vs without history: Including history reduced SR from 51.5% to 49.4%
  - Soft vs aggressive: Soft maintains SR; aggressive increases pruning but risks context loss
- Failure signatures:
  - Popup attacks with TSR ~2%: Popup blocks page interaction; closing it requires exposing the malicious close button
  - 404/image-only pages under banner attack: Page content is entirely attack text, no legitimate elements to retrieve
  - Embedding/BM25 baselines: ~10 point SR drop vs LLM retriever, suggesting semantic similarity misses planning-relevant elements
- First 3 experiments:
  1. Reproduce soft retrieval on a small AxTree subset: Take 10 AxTree samples from BrowserGym, apply the retriever prompt, verify line ranges are actionable
  2. Ablate prompting strategies: Compare soft vs aggressive vs neutral on 50 tasks; expect soft to match paper's 51% pruning with minimal SR loss
  3. Test defense variant on synthetic attacks: Inject banner text into AxTree, verify retriever excludes it while preserving task elements; measure ASR reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can web agents handle popup attacks where the close button itself contains the malicious injection, without exposing the agent to the attack?
- Basis in paper: Section 6.2 states "Future work could explore better ways of solving the problem, for example by cleaning out the injection from the element vessel of the attack before sending it to the agent."
- Why unresolved: DefenseFocusAgent achieves near-zero ASR on popup attacks but only 2% TSR because ignoring the popup blocks interaction with background elements, and showing the close button enables the attack.
- What evidence would resolve it: An approach that sanitizes specific elements (e.g., stripping injection text from button labels while preserving functionality) that achieves both low ASR and high TSR on popup attacks.

### Open Question 2
- Question: Can the trade-off between Attack Success Rate (ASR) and Task Success Rate (TSR) be eliminated, enabling both robust security and high task performance?
- Basis in paper: Section 6.2 notes "there is a tradeoff between ASR and TSR, a higher TSR is coming at an ASR price, which we are trying to reduce but were not able to nullify."
- Why unresolved: DefenseFocusAgent reduces ASR from ~90% to <1% on popups but TSR drops from ~50% to ~2%; banner attacks still occasionally succeed when pages have minimal legitimate content.
- What evidence would resolve it: A method achieving ASR <5% while maintaining TSR within 5% of attack-free baseline performance across both attack types.

### Open Question 3
- Question: What structural or semantic features of AxTrees determine effective pruning beyond raw token count?
- Basis in paper: Section 5 states "pruning effectiveness depends more on the content of the observation rather than just the token count" but does not characterize these content features.
- Why unresolved: Pruning ratios vary widely (20–99%) across tasks with similar token counts; clustering analysis shows task-type-specific patterns but no predictive model.
- What evidence would resolve it: A feature analysis correlating AxTree properties (e.g., interactive element density, DOM depth, task-type markers) with optimal pruning ratios, validated across benchmarks.

## Limitations
- The core retrieval effectiveness hinges on a single lightweight LLM (GPT-4.1-mini) and one pruning threshold, with unclear generalizability across model families.
- The security claim assumes prompt injection payloads always appear in "irrelevant" AxTree lines, breaking when malicious instructions are embedded in task-relevant elements.
- The work does not report pruning efficiency on DOM-sized inputs (hundreds of thousands of lines), so the 50% pruning figure may not scale.

## Confidence

- **High confidence**: Retrieval outperforms embedding-based baselines on stated benchmarks (WorkArena 51.5% vs 40.3% SR; WebArena 73.5% vs 59.3%).
- **Medium confidence**: Security benefit against banner/popup attacks (ASR reduction from 32.4%→0.9% and 90.4%→1.0%) given limited attack types and residual vulnerability in popup scenarios.
- **Low confidence**: Generalizability of pruning ratio (50% observed vs up to 71% possible), robustness across model families, and behavior on larger DOMs.

## Next Checks

1. **Cross-Model Retrieval Robustness**: Run the retriever with GPT-3.5-turbo, LLaMA-3-8B, and DeepSeek-Coder-V2 on the same 100-task subset; verify SR and pruning ratios remain within ±5% of GPT-4.1-mini results.

2. **DOM-Scale Pruning Test**: Feed the retriever a synthetic AxTree of 200k lines (10x typical size) and measure actual pruning ratio and main-agent SR; check for context-overflow failures.

3. **Adversarial Element Injection**: Create synthetic tasks where malicious instructions are embedded in task-relevant AxTree lines (e.g., fake "Next" button with attack text); measure whether ASR remains near zero or spikes, and whether the defense variant (attack-warning prompt) mitigates it.