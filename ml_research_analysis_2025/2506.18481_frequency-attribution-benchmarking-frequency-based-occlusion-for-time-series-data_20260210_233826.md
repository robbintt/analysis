---
ver: rpa2
title: 'FREQuency ATTribution: Benchmarking Frequency-based Occlusion for Time Series
  Data'
arxiv_id: '2506.18481'
source_url: https://arxiv.org/abs/2506.18481
tags:
- attribution
- frequency
- signal
- input
- approaches
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FreqATT, a framework for post-hoc interpretation
  of time series data using frequency-based occlusion. The method transforms input
  signals into the frequency domain, evaluates and filters relevant frequencies, and
  marks relevant input data, addressing the challenge of interpretability in deep
  neural networks for time series analysis.
---

# FREQuency ATTribution: Benchmarking Frequency-based Occlusion for Time Series Data

## Quick Facts
- arXiv ID: 2506.18481
- Source URL: https://arxiv.org/abs/2506.18481
- Reference count: 16
- Primary result: Introduces FreqATT, a framework combining frequency-based occlusion with traditional attribution methods for improved interpretability of time series classification

## Executive Summary
This paper presents FreqATT, a novel framework for post-hoc interpretation of time series data that leverages frequency-domain analysis to identify and attribute relevant signal components. The method transforms input signals into the frequency domain, evaluates frequency relevance through occlusion techniques, and reconstructs filtered signals while preserving important information. By combining frequency-based optimization with traditional attribution methods, FreqATT demonstrates superior performance in maintaining signal shape while removing irrelevant information, addressing the challenge of interpretability in deep neural networks for time series analysis.

## Method Summary
FreqATT applies a frequency-domain occlusion approach to time series interpretation. The method first transforms input signals to the frequency domain using FFT, then systematically occludes frequency bands through a sliding window mechanism. Each occluded frequency spectrum is passed through a trained InceptionTime classifier, and frequencies are ranked by their impact on prediction accuracy. The framework reconstructs filtered signals using inverse FFT of the top-ranked frequencies, producing attribution maps that highlight relevant signal components. The approach is evaluated across 20 diverse datasets from the UEA & UCR repositories, comparing traditional occlusion methods, FreqATT alone, and combinations of both approaches.

## Key Results
- FreqATT improves continuity and infidelity metrics compared to standalone traditional attribution methods
- The frequency attribution effectively filters noise while preserving important signal components
- Combination of FreqATT with traditional attribution provides more comprehensive explanations than either method alone
- The approach excels at identifying shared frequencies between related classes and reducing cognitive load in interpretation

## Why This Works (Mechanism)
The effectiveness of FreqATT stems from its ability to decompose complex time series signals into their constituent frequencies, allowing for targeted evaluation of which frequency components drive model predictions. By occluding frequency bands rather than individual time points, the method captures the spectral characteristics that are most relevant to classification decisions. This frequency-based approach naturally filters out high-frequency noise while preserving the low-frequency patterns that typically carry semantic meaning in time series data. The combination with traditional attribution provides complementary spatial and spectral perspectives, resulting in more robust and interpretable explanations.

## Foundational Learning

**Fourier Transform (FFT)**: Converts time-domain signals to frequency domain representation. Why needed: Enables frequency-based analysis of time series components. Quick check: Verify Parseval's theorem holds for test signals.

**Frequency Band Occlusion**: Systematically removes frequency components to assess their importance. Why needed: Identifies which spectral components most influence model predictions. Quick check: Plot prediction scores vs. fraction of frequencies removed to verify correct ranking.

**InceptionTime Architecture**: Deep learning model for time series classification. Why needed: Provides the classification backbone for evaluating frequency importance. Quick check: Verify baseline accuracy matches reported values on held-out validation sets.

**Signal Reconstruction**: Inverse FFT to convert filtered frequency spectra back to time domain. Why needed: Produces interpretable time series attribution maps. Quick check: Confirm reconstructed signals maintain temporal structure while removing noise.

## Architecture Onboarding

**Component Map**: Time Series -> FFT Transform -> Frequency Occlusion -> Model Prediction -> Frequency Ranking -> Inverse FFT -> Attribution Map

**Critical Path**: The core pipeline flows from FFT transformation through frequency occlusion evaluation to inverse FFT reconstruction, with model predictions driving the frequency ranking process.

**Design Tradeoffs**: 
- Frequency resolution vs. computational efficiency (window size and stride parameters)
- Complete frequency preservation vs. noise filtering (threshold selection for relevant frequencies)
- Single-channel vs. multi-channel signal handling (FFT implementation for multi-dimensional time series)

**Failure Signatures**:
- Inverted frequency ranking (deletion AUC shows immediate collapse rather than gradual decline)
- Inconsistent metric values across runs (FFT normalization or implementation differences)
- Poor attribution quality on multi-channel signals (inadequate handling of channel-specific frequency patterns)

**First Experiments**:
1. Verify FFT implementation consistency using Parseval's theorem on synthetic test signals
2. Conduct sensitivity analysis on frequency occlusion window size to identify optimal parameter ranges
3. Implement ablation studies comparing single-channel versus multi-channel frequency occlusion handling

## Open Questions the Paper Calls Out
None

## Limitations
- Frequency occlusion implementation details remain underspecified, particularly window size and stride parameters
- Multi-channel time series handling during FFT transform and frequency occlusion is not explicitly defined
- Claims about identifying shared frequencies between related classes require additional systematic validation beyond case studies

## Confidence

**High confidence**: Overall framework concept and evaluation methodology are clearly described with well-specified metrics and dataset selection

**Medium confidence**: Reported improvements in continuity and infidelity metrics are credible, though exact numerical reproduction depends on resolving implementation details

**Low confidence**: Effectiveness claims for identifying shared frequencies between related classes need more rigorous validation beyond limited case studies

## Next Checks
1. Verify Parseval's theorem holds on test signals to confirm consistent FFT implementation conventions
2. Implement sensitivity analysis varying frequency occlusion window size to determine impact on attribution quality
3. Conduct ablation studies comparing single-channel versus multi-channel frequency occlusion handling