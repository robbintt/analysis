---
ver: rpa2
title: Supporting Construction Worker Well-Being with a Multi-Agent Conversational
  AI System
arxiv_id: '2506.07997'
source_url: https://arxiv.org/abs/2506.07997
tags:
- system
- construction
- multi-agent
- baseline
- workers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a conversational multi-agent AI system using
  large language models (LLMs) and retrieval-augmented generation (RAG) to address
  mental health and safety challenges in the construction industry. The system features
  specialized agents (OSH Specialist, HR Advisor, and Worker Peer) that provide tailored
  support for safety, workplace policies, and emotional well-being.
---

# Supporting Construction Worker Well-Being with a Multi-Agent Conversational AI System

## Quick Facts
- arXiv ID: 2506.07997
- Source URL: https://arxiv.org/abs/2506.07997
- Reference count: 0
- Primary result: Multi-agent system outperforms single-agent baseline with 18% higher usability, 40% higher self-determination scores, and 60% improvements in social presence and trust

## Executive Summary
This study develops a conversational multi-agent AI system using large language models and retrieval-augmented generation to address mental health and safety challenges in the construction industry. The system features specialized agents (OSH Specialist, HR Advisor, and Worker Peer) that provide tailored support for safety, workplace policies, and emotional well-being. A user study with 12 participants compared the system against a single-agent baseline across three industry-specific scenarios. Results show the multi-agent system significantly outperformed the baseline across all measured dimensions.

## Method Summary
The study employed a within-subjects design with 12 participants comparing a multi-agent conversational AI system against a single-agent baseline. Participants interacted with both systems across three construction-specific scenarios involving safety concerns, post-injury mental health, and burnout. The multi-agent system used three specialized agents with distinct personas (OSH Specialist, HR Advisor, Worker Peer) integrated with RAG for domain knowledge. Measurements included SUS for usability, Basic Psychological Needs Scale for autonomy/competence/relatedness, and a 3-item scale for social presence and trust. The baseline used a generic single-agent approach with identical knowledge integration.

## Key Results
- 18% higher usability scores (Mean = 84.58 vs 71.88)
- 40% higher self-determination scores
- 60% improvements in both social presence and trust

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Specialized agent roles with distinct personas provide complementary perspectives that reduce cognitive load and improve problem-solving.
- **Mechanism:** Each agent has a bounded domain (OSH regulations, HR/employment law, peer emotional support). Users receive focused, domain-appropriate responses rather than a single monolithic answer, enabling faster processing and more actionable guidance.
- **Core assumption:** Users can more easily integrate specialized perspectives than synthesize a single comprehensive response themselves.
- **Evidence anchors:**
  - [abstract] "configurable agents with distinct personas, such as an OSH specialist, HR advisor, and peer supporter, to provide practical and empathetic support"
  - [section 4.2] P1 commented: "I could quickly process the answers, even for users without relevant knowledge. In contrast, the baseline provides a long list of responses that require more logical processing."
  - [corpus] Related work on multi-module conversational agents for peer support (FMR=0.61) suggests modularity aids emotional regulation, though not specifically tested for role specialization.
- **Break condition:** If agent roles overlap significantly or provide contradictory advice without resolution, users may experience confusion rather than clarity.

### Mechanism 2
- **Claim:** Multi-agent group conversation simulation increases perceived social presence and relatedness.
- **Mechanism:** Agents respond in natural turn-taking patterns, can reference each other's responses, and exhibit distinct personalities. This creates a sense of "being accompanied" rather than querying a tool.
- **Core assumption:** Social presence emerges from observing agent-to-agent interaction dynamics, not just human-to-agent responsiveness.
- **Evidence anchors:**
  - [abstract] "60% gains in social presence and trust"
  - [section 4.2] Relatedness showed the largest improvement: Multi-agent (Mean = 3.83) vs. baseline (Mean = 2.08), p < 0.001. P9: "I feel I have been companied with my colleagues."
  - [corpus] "What People Share With a Robot When Feeling Lonely and Stressed" (FMR=0.53) supports that repeated conversational interaction builds emotional connection over time.
- **Break condition:** If orchestration produces unnatural response patterns (simultaneous identical replies, ignoring direct addresses), the illusion of social presence collapses.

### Mechanism 3
- **Claim:** Domain-specific knowledge integration via RAG improves trust and practical utility of responses.
- **Mechanism:** Documents are chunked, embedded, and indexed in a FAISS vector database. During conversation, relevant passages are retrieved and integrated into responses without explicit source citation, maintaining natural dialogue while grounding answers in authoritative content.
- **Core assumption:** Construction workers will trust and value advice more when it reflects industry-specific regulations and practices, even if they don't see the source.
- **Evidence anchors:**
  - [abstract] "integrates domain knowledge through retrieval-augmented generation (RAG)"
  - [section 4.1] P3: "The baseline gave me any specific suggestions that I can take directly. The response from the baseline is too general."
  - [corpus] Limited direct corpus evidence for RAG-specific mechanisms in this domain; related papers focus on conversational agent design rather than knowledge retrieval.
- **Break condition:** If retrieved chunks are irrelevant or outdated, responses may appear confident but inaccurate, eroding trust quickly.

## Foundational Learning

- **Self-Determination Theory (SDT):**
  - Why needed here: The study measures autonomy, competence, and relatedness as outcome variables. Understanding SDT helps interpret why multi-agent systems might satisfy psychological needs better than single-agent chatbots.
  - Quick check question: Can you explain why "relatedness" showed the largest improvement in this study?

- **Retrieval-Augmented Generation (RAG):**
  - Why needed here: The system's domain knowledge comes from RAG, not fine-tuning. Engineers need to understand chunking strategies, embedding models, and retrieval ranking.
  - Quick check question: How does the system maintain "natural dialogue flow" while integrating retrieved knowledge?

- **Multi-Agent Orchestration:**
  - Why needed here: The system must decide who responds, in what order, and whether agents can reference each other. This is the core coordination logic.
  - Quick check question: What is the difference between sequential and parallel response modes, and when might each be appropriate?

## Architecture Onboarding

- **Component map:** Frontend (React UI) -> Orchestration Layer -> Agent Configuration -> Knowledge Layer (FAISS + OpenAI embeddings) -> LLM Backend (GPT-4o) -> Shared State (conversation history)
- **Critical path:** 1. User sends message via React UI 2. Orchestration evaluates which agents should respond (relevance + direct addressing) 3. Selected agents query RAG for relevant knowledge chunks 4. Agents generate responses (sequential: randomized order with potential cross-references; parallel: simultaneous) 5. UI displays responses with agent avatars and visual distinction
- **Design tradeoffs:**
  - Sequential vs. parallel mode: Sequential enables agent cross-referencing but increases latency; parallel reduces latency but loses dialogue coherence
  - Shared conversation history vs. private knowledge: History sharing enables coherent group discussion; knowledge privacy maintains role boundaries
  - Response filtering threshold: Too aggressive = missed relevant contributions; too permissive = noise
- **Failure signatures:**
  - All agents respond to every message (orchestration relevance check failing)
  - Agents ignore direct addresses ("Hey Alice, what do you think?" receives no response from Alice)
  - Retrieved knowledge chunks are off-topic (RAG embedding/retrieval mismatch)
  - Agents contradict each other without acknowledgment (orchestration not enabling cross-references)
  - Response latency too high for conversational flow
- **First 3 experiments:**
  1. Ablation study: Run multi-agent system with identical knowledge across all agents vs. specialized knowledge per agent to isolate the role specialization effect.
  2. Orchestration mode comparison: Measure user satisfaction and latency for sequential vs. parallel response modes across the same scenarios.
  3. Persona consistency test: Swap agent personas (e.g., give peer agent OSH knowledge) and measure whether trust/social presence scores change, testing whether persona-knowledge alignment matters.

## Open Questions the Paper Calls Out
- Does the multi-agent system demonstrate similar effectiveness with actual construction workers in real-world settings, compared to the general participant sample used in this study?
- How does sustained, repeated interaction with the multi-agent system affect worker well-being and engagement over time?
- What is the optimal number and configuration of specialized agents for balancing psychological need satisfaction and cognitive load?
- How does the multi-agent system compare to traditional human-led mental health interventions for construction workers?

## Limitations
- Small sample size (n=12) limits statistical power and generalizability across diverse construction worker populations
- Within-subjects design may introduce carryover effects between conditions
- Social presence and trust measurements used a newly developed 3-item scale without validation across broader populations

## Confidence
- **High confidence:** The usability improvement (18%) and basic psychological needs satisfaction (40%) are statistically significant with clear effect sizes and well-established measurement scales (SUS, BPN)
- **Medium confidence:** The social presence (60% gain) and trust improvements are based on self-report measures from a newly developed 3-item scale, which hasn't been validated across broader populations
- **Medium confidence:** The mechanism explanations are well-grounded in participant quotes but lack experimental isolation of individual mechanisms (e.g., role specialization vs. knowledge integration effects)

## Next Checks
1. Replicate the study with a larger, more diverse sample across multiple construction sites and geographic regions to assess external validity.
2. Conduct an ablation study where you test: (a) single agent with specialized knowledge vs. (b) multi-agent system with shared knowledge to isolate the impact of role specialization versus knowledge integration.
3. Deploy the system for 4-6 weeks with regular users to measure sustained engagement, trust development, and whether initial social presence effects persist or evolve over time.