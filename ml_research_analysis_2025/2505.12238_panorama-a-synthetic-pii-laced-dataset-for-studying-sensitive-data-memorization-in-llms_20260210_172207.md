---
ver: rpa2
title: 'PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization
  in LLMs'
arxiv_id: '2505.12238'
source_url: https://arxiv.org/abs/2505.12238
tags:
- content
- data
- memorization
- dataset
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces PANORAMA, a large-scale synthetic dataset
  for studying sensitive data memorization in large language models. The dataset comprises
  384,789 samples derived from 9,674 synthetic profiles with realistic demographic
  and personal attributes.
---

# PANORAMA: A synthetic PII-laced dataset for studying sensitive data memorization in LLMs

## Quick Facts
- arXiv ID: 2505.12238
- Source URL: https://arxiv.org/abs/2505.12238
- Authors: Sriram Selvam; Anneswa Ghosh
- Reference count: 35
- The dataset comprises 384,789 samples from 9,674 synthetic profiles, validated via fine-tuning Mistral-7B showing memorization rates increase from 8.8% to 51.2% with repetition frequency

## Executive Summary
PANORAMA is a large-scale synthetic dataset designed to study sensitive data memorization in large language models. It contains 384,789 samples derived from 9,674 synthetic profiles with realistic demographic attributes, generating diverse content types including social media posts, forum discussions, reviews, comments, and marketplace listings. The dataset uses zero-shot prompting and OpenAI o3-mini to embed realistic PII and sensitive information while maintaining synthetic realism. Validation experiments on Mistral-7B models show consistent increases in memorization rates with repetition frequency (8.8% to 51.2% soft match rate) and variation across content types, demonstrating PANORAMA's utility for privacy risk assessment and developing privacy-preserving LLMs.

## Method Summary
The dataset generation process involves creating synthetic profiles using Faker and constraint rules, generating Wikipedia-style articles from these profiles, then producing diverse content types using zero-shot prompting with OpenAI o3-mini. The pipeline includes contamination filtering via entity extraction to ensure no real PII leakage. Validation is performed by fine-tuning Mistral-7B base models using LoRA on attention, FFN, embedding, and output heads, with 4-bit quantization and AdamW optimization. Memorization is quantified using ROUGE-L F1 and soft match rate at threshold τ=0.8, stratified by content type across different repetition frequencies (1x, 5x, 10x, 25x).

## Key Results
- Memorization rates increase consistently with repetition frequency: soft match rate rises from 8.8% at 1x to 51.2% at 25x
- Content type significantly modulates memorization: Online Ads show highest memorization (4.0%→68.0%) while Social Media shows lowest (12.0%→28.0%)
- Profile-constrained generation produces naturalistic PII distributions without real data contamination, validated by entity extraction filters catching 326 generations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Repetition frequency causally increases memorization rates in LLMs
- **Mechanism:** Multiple gradient updates on the same token sequences strengthen parametric encoding, transitioning from pattern generalization to verbatim sequence storage
- **Core assumption:** Monotonic relationship between repetition and memorization within 1x-25x range
- **Evidence anchors:** Soft Match Rate rises from 8.8% at 1× to 51.2% at 25×; Online Ad increases from 4.0% to 68.0%; Carlini et al. (2022b) establishes repetition-memorization link
- **Break condition:** Deduplication or regularization techniques (e.g., GoldFish Loss) may attenuate repetition effect

### Mechanism 2
- **Claim:** Content type modulates memorization susceptibility independent of repetition
- **Mechanism:** Different content formats impose varying linguistic structures and contextual constraints; structured PII in marketplace listings creates lower entropy sequences easier to memorize than varied social media posts
- **Core assumption:** Observed differences reflect inherent structural properties rather than generation artifacts
- **Evidence anchors:** Social Media: 12.0%→28.0% (16pp gain); Online Ad: 4.0%→68.0% (64pp gain); weak direct evidence in corpus papers
- **Break condition:** If PII density confounds with content type, mechanism may reflect exposure rather than format

### Mechanism 3
- **Claim:** Profile-constrained generation produces naturalistic PII distributions without real data contamination
- **Mechanism:** Constraint-based profile construction ensures internal consistency (age→education→job→salary causal chains) while Wikipedia scaffolding provides realistic discourse structure; entity extraction filters validate no leakage
- **Core assumption:** Synthetic realism sufficient to generalize memorization findings to real-world contexts
- **Evidence anchors:** 326 generations dropped by contamination filter; sensitive fields appear contextually appropriate; no direct validation against real PII patterns
- **Break condition:** If models behave differently toward synthetic vs. real PII, ecological validity fails

## Foundational Learning

- **Concept: ROUGE-L F1 and Soft Match Rate**
  - **Why needed here:** Primary evaluation metrics for memorization quantification
  - **Quick check question:** Given ground truth "contact me at john@email.com" and output "reach me at john@email.com", would this achieve ROUGE-L ≥ 0.8?

- **Concept: Quasi-identifiers vs. Direct PII**
  - **Why needed here:** PANORAMA includes both; quasi-identifiers enable re-identification through linkage attacks
  - **Quick check question:** If a profile contains only "software engineer, Seattle, age 34," can this uniquely identify a person? Under what conditions?

- **Concept: Continued Pre-training with LoRA**
  - **Why needed here:** Validation experiments use LoRA-based parameter-efficient fine-tuning rather than full model updates
  - **Quick check question:** Why might LoRA memorization dynamics differ from full fine-tuning? What biases might this introduce?

## Architecture Onboarding

- **Component map:** Profile Generator → (Faker + constraint rules) → 9,674 profiles → Article Generator → (o3-mini + Wikipedia scaffold) → 9,674 wiki-style articles → Content Generator → (o3-mini + article + profile) → 375,115 multi-type samples → Contamination Filter → (entity extraction) → validates no real-PII leakage

- **Critical path:** Profile generation constraints are the foundation; incoherent age→education→job chains break downstream content consistency and cross-content entity linking

- **Design tradeoffs:** English-only (8 locales) limits multilingual research but enables human validation; Wikipedia scaffolding improves narrative quality but requires contamination filtering; varied handles across platforms increase realism but complicate entity resolution

- **Failure signatures:** Hallucinated social handles not in source profile; contamination from Wikipedia facts; low PII mention rates in certain content types reducing signal

- **First 3 experiments:**
  1. **Baseline replication:** Fine-tune Mistral-7B on 1x data, measure soft match rate by content type to validate evaluation pipeline
  2. **Ablation on profile consistency:** Generate content from shuffled profiles (break age→job→salary chains) and compare memorization rates
  3. **Cross-content entity linking:** Test whether model can infer shared identity from contextual cues across multiple content types from same profile

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does PANORAMA's utility for studying memorization generalize to model architectures beyond Mistral-7B and training regimes beyond continued pre-training with LoRA?
- **Basis in paper:** Validation only on "fine-tuning Mistral-7B model on 1x, 5x, 10x and 25x data replication rates" using LoRA
- **Why unresolved:** Different model sizes, architectures, and training methods may exhibit different memorization behaviors; single 7B model results may not generalize
- **What evidence would resolve it:** Experiments training diverse model families and scales on PANORAMA, reporting memorization rates under controlled conditions

### Open Question 2
- **Question:** How can PANORAMA be extended to support extraction attack evaluation given the current lack of Q&A format data?
- **Basis in paper:** Section 6 limitation: "dataset provides content ready for continued pre-training, but lacks Q&A format needed for extraction attacks"
- **Why unresolved:** Extraction attacks often leverage prompt-response formats; without such data, utility for adversarial privacy evaluation is incomplete
- **What evidence would resolve it:** Augmenting PANORAMA with synthetically generated Q&A pairs targeting embedded PII, demonstrating successful extraction attacks and comparing attack success rates across formats

### Open Question 3
- **Question:** What is the impact of the English-only, eight-locale constraint on generalizability of memorization findings to multilingual and cross-cultural contexts?
- **Basis in paper:** Section 6: "language coverage restricted by authors' English-only expertise and Faker library's limited multilingual support"
- **Why unresolved:** PII formats, naming conventions, and contextual embedding patterns differ across languages and cultures; memorization dynamics may vary accordingly
- **What evidence would resolve it:** Extending generation pipeline to non-English locales with locale-specific PII templates, replicating memorization experiments to compare cross-linguistic patterns

## Limitations
- Synthetic data realism gap: PANORAMA may not fully capture real-world PII distributional properties, limiting ecological validity
- Evaluation protocol underspecification: Key hyperparameters for fine-tuning and prefix-completion are not provided, making exact reproduction difficult
- Content-type stratification mechanism unclear: Paper doesn't definitively establish whether format or exposure drives memorization differences

## Confidence
- **High confidence:** Repetition frequency increases memorization rates in LLMs (well-established in literature, clearly demonstrated)
- **Medium confidence:** Content-type differences in memorization susceptibility and synthetic data generation approach (supported by evidence but with important caveats)
- **Low confidence:** Claims about ecological validity and generalization to real-world PII memorization scenarios

## Next Checks
1. **Cross-dataset generalization test:** Apply same evaluation pipeline to real-world PII dataset to quantify synthetic-real gap in memorization patterns
2. **Mechanism isolation experiment:** Generate content with constant PII density across content types while varying structural complexity to test whether format or exposure drives differences
3. **Contamination sensitivity analysis:** Systematically relax contamination filters to identify threshold where real-world data leakage begins affecting memorization rates