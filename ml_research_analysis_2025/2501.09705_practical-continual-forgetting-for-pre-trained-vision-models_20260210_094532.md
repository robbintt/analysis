---
ver: rpa2
title: Practical Continual Forgetting for Pre-trained Vision Models
arxiv_id: '2501.09705'
source_url: https://arxiv.org/abs/2501.09705
tags:
- forgetting
- learning
- classes
- arxiv
- uni000003ec
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses continual forgetting for pre-trained vision
  models, aiming to remove unwanted information (e.g., privacy data, toxic data) while
  maintaining remaining knowledge. The problem is defined as sequential erasure requests
  from users and model owners in real-world scenarios, with three key challenges:
  efficient and effective deletion of unwanted knowledge, minimal impact on remaining
  knowledge, and robustness to scarce or missing training samples.'
---

# Practical Continual Forgetting for Pre-trained Vision Models

## Quick Facts
- arXiv ID: 2501.09705
- Source URL: https://arxiv.org/abs/2501.09705
- Reference count: 40
- Pre-trained vision models can forget unwanted information while preserving remaining knowledge with less than 1% parameter usage

## Executive Summary
This paper addresses the practical challenge of continual forgetting for pre-trained vision models, enabling users and model owners to remove unwanted information such as privacy data or toxic content while maintaining model performance on remaining classes. The proposed GS-LoRA framework uses Low-Rank Adaptation (LoRA) modules with group sparse regularization to efficiently identify and update only the parameters responsible for the unwanted knowledge. The method extends to GS-LoRA++ by incorporating prototype information as supervision, which helps move logits away from forgotten class prototypes while pulling them closer to retained class prototypes. Extensive experiments on face recognition, object detection, and image classification demonstrate effective forgetting with minimal impact on remaining capabilities, achieving high data efficiency and parameter efficiency.

## Method Summary
The GS-LoRA method tackles continual forgetting by introducing a group sparse regularization technique applied to LoRA modules that fine-tune Feed-Forward Network (FFN) layers in Transformer blocks. The approach automatically identifies and updates only the parameters responsible for unwanted knowledge through a zero group ratio mechanism, where groups of parameters are selectively activated during training. GS-LoRA++ extends this by incorporating prototype information as additional supervision - the framework pushes logits away from prototypes of forgotten classes while pulling them closer to prototypes of retained classes. The method operates efficiently by updating less than 1% of total parameters, making it practical for large pre-trained vision models. Both few-shot and missing class scenarios are addressed through class-wise regularization that encourages sparsity in the updated parameter groups.

## Key Results
- GS-LoRA achieves high data efficiency, effectively removing unwanted knowledge with minimal training data
- The method uses less than 1% of total parameters for forgetting, demonstrating strong parameter efficiency
- GS-LoRA++ outperforms baselines on face recognition, object detection, and image classification tasks while maintaining remaining class performance
- The approach successfully handles both few-shot and missing class forgetting scenarios with comparable effectiveness

## Why This Works (Mechanism)
The effectiveness stems from the combination of low-rank adaptation and group sparse regularization. By restricting updates to LoRA modules in FFN layers, the method maintains the core pre-trained knowledge while only modifying a small subset of parameters. The group sparse regularization automatically identifies which parameter groups are responsible for the unwanted knowledge and selectively updates them, creating a sparse yet effective forgetting mechanism. The prototype-based supervision in GS-LoRA++ provides additional guidance by explicitly controlling how logits should be adjusted relative to class prototypes, ensuring that forgotten classes are properly separated while retained classes remain accessible. This targeted approach avoids the computational expense of full retraining while achieving comparable unlearning performance.

## Foundational Learning
- **Low-Rank Adaptation (LoRA)**: A parameter-efficient fine-tuning technique that approximates weight updates using low-rank matrices - needed to minimize parameter updates during forgetting; quick check: verify LoRA matrices are indeed low-rank and sparse
- **Group Sparse Regularization**: A technique that encourages entire groups of parameters to be zero - needed to automatically identify and update only relevant parameters for forgetting; quick check: measure Zero Group Ratio and correlate with forgetting effectiveness
- **Prototype-based Supervision**: Using class prototypes to guide logit adjustments - needed to provide explicit direction for separating forgotten from retained classes; quick check: verify prototypes are computed correctly and logits move as expected
- **Class-wise Regularization**: Applying regularization at the class level rather than globally - needed to handle multiple forgetting requests independently; quick check: ensure class-wise updates don't interfere with each other
- **Transformer FFN Layer Modification**: Focusing updates on Feed-Forward Network layers - needed as these layers capture most task-specific information; quick check: confirm FFN layers contain the most relevant parameters for forgetting

## Architecture Onboarding

**Component Map:**
Pre-trained Vision Model -> LoRA Modules (FFN layers) -> Group Sparse Regularization -> Prototype-based Supervision (GS-LoRA++) -> Forgetting Output

**Critical Path:**
1. Initialize LoRA modules for FFN layers
2. Apply group sparse regularization during training
3. Compute class prototypes from remaining data
4. Apply prototype-based logit adjustment (GS-LoRA++)
5. Update only non-zero parameter groups

**Design Tradeoffs:**
- LoRA vs Full Fine-tuning: LoRA reduces parameter updates from 100% to <1% but may limit expressiveness
- Group vs Matrix Granularity: Finer granularity increases sparsity but may slightly reduce performance
- Prototype Supervision: Adds computational overhead but provides better control over forgetting

**Failure Signatures:**
- High recovery accuracy indicates insufficient forgetting
- Significant performance drop on retained classes suggests over-forgetting
- Persistent non-zero groups after training indicates ineffective sparse regularization

**First 3 Experiments:**
1. Verify group sparse regularization correctly identifies and zeros irrelevant parameter groups
2. Test prototype-based supervision by checking logit distances from forgotten vs retained class prototypes
3. Measure Zero Group Ratio across different grouping strategies (Block vs Matrix) to find optimal sparsity-performance balance

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** How robust is the GS-LoRA++ framework against sophisticated Membership Inference Attacks (MIAs) compared to full retraining or other unlearning baselines?
- **Basis in paper:** [explicit] The authors explicitly state in the Future Work section: "A critical next step is to conduct a rigorous evaluation of our framework against sophisticated membership inference attacks (MIAs) [147]â€“[149]. Such an assessment would empirically validate and formally quantify the data privacy protection capabilities of our approach."
- **Why unresolved:** The paper evaluates "real forgetting" via feature reconstruction attacks and recovery accuracy, but has not yet quantified the probability of an attacker inferring whether a specific data point was used in training (MIAs).
- **What evidence would resolve it:** Empirical results demonstrating that the success rate of state-of-the-art MIAs on the unlearned model is statistically indistinguishable from a model retrained from scratch on the retained data.

### Open Question 2
- **Question:** Can the sparse, low-rank adaptation mechanism be effectively generalized to instance-wise unlearning without defining forgetting sets at the class level?
- **Basis in paper:** [explicit] The authors suggest in Future Work: "...a significant extension is the development of instance-wise unlearning [71]. This presents a compelling challenge, as it requires novel strategies for defining 'forgetting' and 'retaining' sets at the individual data point level."
- **Why unresolved:** The current GS-LoRA++ implementation and prototype regularization rely on class-wise prototypes and aggregate statistics, which may not provide sufficient specificity to selectively remove individual data points while preserving other instances of the same class.
- **What evidence would resolve it:** A modification of the method that successfully unlearns specific images (instances) while retaining high performance on other images within the same class, verified by metrics analogous to the class-wise H-Mean.

### Open Question 3
- **Question:** What is the optimal granularity for grouping LoRA parameters to balance sparsity, parameter efficiency, and forgetting performance?
- **Basis in paper:** [inferred] The ablation study (Table 14) shows that "Matrix" grouping (finer granularity) achieves a higher Zero Group Ratio (0.87 vs 0.50) than "Block" grouping, yet the H-Mean slightly drops (71.39 vs 72.04). The text notes, "With more detailed grouping strategies, the model can achieve excellent performance with sparser modifications," but leaves the trade-off between extreme sparsity and peak accuracy unresolved.
- **Why unresolved:** While the paper demonstrates that both Block and Matrix strategies work, it does not definitively establish if there is a "sweet spot" or if the slight performance drop with finer granularity is inherent to the optimization difficulty or the model structure.
- **What evidence would resolve it:** A comprehensive analysis across varying model sizes and tasks that identifies the grouping strategy which maximizes the H-Mean score while maintaining the highest possible Zero Group Ratio.

## Limitations
- Experiments primarily focus on face recognition and object detection, with limited evaluation on semantic segmentation or multi-modal vision tasks
- The "missing class" scenario validation appears less extensive than the few-shot case, making robustness claims less certain
- Computational overhead analysis lacks detailed measurements of inference latency and memory usage during the forgetting process

## Confidence

**High**: The effectiveness of GS-LoRA in removing unwanted knowledge while preserving remaining capabilities (demonstrated across multiple tasks)

**Medium**: The parameter efficiency claim (less than 1% parameter usage) - while supported by experiments, real-world scaling effects are not fully explored

**Medium**: The robustness to scarce/missing training data - better validated for few-shot than missing class scenarios

**Low**: Generalization to non-face/non-detection vision tasks - limited experimental coverage

## Next Checks

1. Evaluate GS-LoRA on additional vision tasks including semantic segmentation, instance segmentation, and multi-modal vision-language models to assess broader applicability

2. Conduct comprehensive ablation studies on the prototype-based supervision mechanism to quantify its contribution versus the base GS-LoRA approach

3. Measure and report detailed computational overhead metrics including inference latency, memory usage, and training time for the forgetting process across different model scales