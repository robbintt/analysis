---
ver: rpa2
title: 'IBN: An Interpretable Bidirectional-Modeling Network for Multivariate Time
  Series Forecasting with Variable Missing'
arxiv_id: '2509.07725'
source_url: https://arxiv.org/abs/2509.07725
tags:
- missing
- variables
- graph
- ggcn
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of multivariate time series forecasting
  (MTSF) when variables are completely missing due to sensor failures or other causes.
  Conventional spatial-temporal graph neural networks struggle in such cases because
  they cannot reliably model relationships between observed and missing variables.
---

# IBN: An Interpretable Bidirectional-Modeling Network for Multivariate Time Series Forecasting with Variable Missing

## Quick Facts
- **arXiv ID:** 2509.07725
- **Source URL:** https://arxiv.org/abs/2509.07725
- **Authors:** Shusen Ma; Tianhao Zhang; Qijiu Xia; Yun-Bo Zhao
- **Reference count:** 0
- **Primary result:** IBN achieves state-of-the-art forecasting accuracy under various missing rates (25%, 50%, 75%), outperforming the previous best model GinAR by 1.89%–6.72% in MAE across four traffic datasets.

## Executive Summary
This paper tackles the challenge of multivariate time series forecasting (MTSF) when entire variables are missing due to sensor failures or other causes. Conventional spatial-temporal graph neural networks struggle in such cases because they cannot reliably model relationships between observed and missing variables. To address this, the authors propose the Interpretable Bidirectional-Modeling Network (IBN), which integrates three key innovations: Uncertainty-Aware Interpolation (UAI), which uses Monte Carlo Dropout to estimate reconstruction uncertainty and downweight unreliable imputations; Gaussian kernel-based Graph Convolution (GGCN), which explicitly models spatial correlations among variables using both predefined and dynamic distance-based graphs; and a bidirectional Recursive Unit (Bi-RU) that captures temporal dependencies in both forward and backward directions. Experiments on four public datasets (METR-LA, PEMS-BAY, PEMS04, PEMS08) show that IBN achieves state-of-the-art forecasting accuracy under various missing rates (25%, 50%, 75%), outperforming the previous best model GinAR by 1.89%–6.72% in MAE across the datasets. The approach also improves interpretability by linking reconstruction uncertainty to prediction reliability and providing clearer spatial correlation modeling.

## Method Summary
The IBN framework addresses multivariate time series forecasting with variable missing by combining three components: Uncertainty-Aware Interpolation (UAI) uses Monte Carlo Dropout with S=10 samples to estimate reconstruction uncertainty, weighting imputations as x̂_UAI = μ/(1+σ) to downweight unreliable estimates; Gaussian kernel-based Graph Convolution (GGCN) explicitly models spatial correlations among variables using both predefined geographical distance graphs and dynamic graphs constructed via Gaussian kernels exp(-D²/(2γ)); and a bidirectional Recursive Unit (Bi-RU) captures temporal dependencies in both forward and backward directions, with forward and backward hidden states concatenated. The model architecture consists of a two-layer RU structure (Bi-RU → Uni-RU) followed by a decoder with Conv2D layers (1×2D and 1×1 kernels). The approach is evaluated on four traffic datasets (METR-LA, PEMS-BAY, PEMS04, PEMS08) under various missing rates (25%, 50%, 75%).

## Key Results
- IBN outperforms previous state-of-the-art model GinAR by 1.89%–6.72% in MAE across all four datasets
- Consistent performance improvements across all missing rates (25%, 50%, 75%)
- Demonstrates strong interpretability through uncertainty-weighted imputations and explicit spatial correlation modeling
- Shows effectiveness in handling complete variable missing rather than random missing values

## Why This Works (Mechanism)
IBN works by addressing the core challenge of missing variable forecasting through three complementary innovations. The Uncertainty-Aware Interpolation module estimates reconstruction uncertainty using Monte Carlo Dropout, allowing the model to identify and downweight unreliable imputations based on their variance. The Gaussian kernel-based Graph Convolution explicitly models spatial correlations using both predefined geographical distances and dynamic feature-based distances, providing richer relational information than static graphs. The bidirectional Recursive Unit captures temporal dependencies in both directions, enabling the model to leverage both past and future context for better forecasting. Together, these components allow IBN to maintain strong forecasting performance even when large portions of variables are missing, by focusing on reliable information and explicit spatial-temporal modeling.

## Foundational Learning
- **Monte Carlo Dropout for Uncertainty Estimation:** Uses multiple stochastic forward passes to estimate both mean and variance of predictions, allowing uncertainty-aware weighting. Why needed: To quantify reliability of imputations when variables are missing. Quick check: S=10 forward passes produce different outputs with σ > 0.
- **Gaussian Kernel Graph Construction:** Creates dynamic adjacency matrices using exp(-D²/(2γ)) where D is Euclidean distance between node features. Why needed: To capture variable correlations that may change over time beyond static geographical distances. Quick check: A_Gau values in [0,1] and properly scaled by embedding size.
- **Bidirectional Temporal Modeling:** Processes sequences in both forward and backward directions, concatenating hidden states. Why needed: To capture temporal dependencies from both past and future contexts for better forecasting. Quick check: Hidden states properly concatenated and temporal order preserved.

## Architecture Onboarding
- **Component Map:** Data → UAI → GGCN → Bi-RU → Decoder → Forecast
- **Critical Path:** Missing variable masking → UAI uncertainty estimation → GGCN spatial correlation → Bi-RU temporal modeling → Conv2D decoder
- **Design Tradeoffs:** Bidirectional modeling improves accuracy but may require future context unavailable in real-time streaming; MC Dropout increases inference time by factor of 10 but provides uncertainty quantification.
- **Failure Signatures:** Gradient explosion in GGCN due to large distances; uniform uncertainty estimates from disabled dropout; performance degradation at high missing rates due to poor imputation quality.
- **First Experiments:** 1) Test MC Dropout produces varied outputs with S=10 samples; 2) Verify Gaussian kernel produces valid adjacency values in [0,1]; 3) Confirm Bi-RU hidden state concatenation maintains temporal order.

## Open Questions the Paper Calls Out
- **Open Question 1:** How does the Gaussian kernel-based graph construction (GGCN) perform on multivariate time series datasets where variable correlations are not spatially grounded or distance-correlated? The paper evaluates exclusively on traffic datasets where spatial distance is a strong proxy for correlation, but this assumption may not hold for non-spatial domains like finance or healthcare.
- **Open Question 2:** How robust is the IBN framework when the missingness mechanism is "Missing Not At Random" (MNAR) rather than the random masking simulated in experiments? Real-world sensor failures often result from environmental factors that correlate with data values, which may cause uncertainty-weighted imputations to fail.
- **Open Question 3:** What is the computational latency overhead of Monte Carlo Dropout sampling during inference, and does it limit the model's applicability to high-frequency real-time forecasting? The UAI module requires 10× more forward passes than deterministic models, significantly increasing inference time.
- **Open Question 4:** Does the bidirectional recursive unit (Bi-RU) introduce latency that hinders deployment in strictly causal, streaming online forecasting scenarios? Bidirectional models typically require access to future time steps, creating delays in live streaming environments.

## Limitations
- Key hyperparameters (historical window H, forecast length L, embedding dimension D, batch size, learning rate, optimizer) are not specified in the paper
- Predefined graph construction details (distance threshold, normalization method) are unclear
- Train/validation/test split ratios and data preprocessing methods are not described
- Computational overhead of Monte Carlo Dropout during inference is not analyzed
- Bidirectional modeling may not be suitable for real-time streaming applications requiring causal predictions

## Confidence
- **High:** Experimental setup (datasets, metrics, missing rates)
- **Medium:** Model architecture description (UAI, GGCN, Bi-RU components)
- **Low:** Hyperparameter choices and training details

## Next Checks
1. Verify MC Dropout is enabled during inference and S=10 samples produce varied outputs with σ > 0
2. Confirm Gaussian kernel A_Gau values are in [0,1] and γ scales appropriately with embedding size
3. Test Bi-RU hidden state concatenation and temporal order handling for forward/backward passes