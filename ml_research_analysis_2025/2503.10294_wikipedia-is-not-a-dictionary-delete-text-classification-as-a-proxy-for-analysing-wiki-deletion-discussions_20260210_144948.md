---
ver: rpa2
title: Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy for Analysing
  Wiki Deletion Discussions
arxiv_id: '2503.10294'
source_url: https://arxiv.org/abs/2503.10294
tags:
- wikipedia
- delete
- deletion
- prediction
- outcome
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive analysis of automated content
  moderation for collaborative knowledge hubs like Wikipedia and Wikidata. The authors
  construct a novel dataset of deletion discussions across four platforms (Wikipedia,
  Wikidata-Entity, Wikidata-Property, Wikinews, Wikiquote) and three languages (English,
  Spanish, Greek), containing 18,528 English Wikipedia discussions and substantial
  multilingual data.
---

# Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy for Analysing Wiki Deletion Discussions

## Quick Facts
- **arXiv ID**: 2503.10294
- **Source URL**: https://arxiv.org/abs/2503.10294
- **Reference count**: 21
- **Primary result**: RoBERTa-Large achieves up to 0.89 F1 on stance detection for Wikipedia deletion discussions, with cross-platform transfer showing promising generalization

## Executive Summary
This paper presents a comprehensive analysis of automated content moderation for collaborative knowledge hubs like Wikipedia and Wikidata. The authors construct a novel dataset of deletion discussions across four platforms (Wikipedia, Wikidata-Entity, Wikidata-Property, Wikinews, Wikiquote) and three languages (English, Spanish, Greek), containing 18,528 English Wikipedia discussions and substantial multilingual data. They evaluate multiple large language models on three tasks: outcome prediction, stance detection, and policy prediction, demonstrating that PLM-based approaches can significantly assist in managing quality control across diverse Wiki environments.

## Method Summary
The study constructs a dataset from Wikipedia deletion discussions spanning five platforms and three languages, containing 18,528 English Wikipedia discussions. Three classification tasks are evaluated: outcome prediction (predicting final deletion decisions), stance detection (identifying user opinions in comments), and policy prediction (detecting referenced Wikimedia policies). Multiple models are tested including BERT, RoBERTa, DistilBERT, and Twitter-RoBERTa, with both fine-tuning and parameter-efficient methods like SetFit. Two experimental settings are used: Fulltext (with self-assigned labels visible) and Masked (labels redacted). Hyperparameters include 20 epochs for outcome prediction, 5 epochs for stance/policy, learning rate 1e-5/2e-6, batch size 4, and NVIDIA RTX 4090 hardware.

## Key Results
- RoBERTa-Large performs best overall, achieving up to 0.89 F1 on stance detection and 0.58 F1 on outcome prediction
- Surprisingly, self-reported tags don't always improve classification, suggesting user hesitation in discussions
- Cross-platform training works well, with models trained on Wikipedia generalizing to other platforms
- Parameter-efficient methods like SetFit achieve competitive results, especially on smaller datasets
- Multilingual models show strong performance, with XLM-R-Large achieving 0.88 F1 on Spanish Wikipedia

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-trained language models capture deliberation patterns that predict moderation outcomes.
- Mechanism: Transformer-based models encode linguistic structures from discussions that correlate with final decisions. Full-text setting provides explicit stance signals via self-reported tags, while masked settings force models to infer intent from argumentation alone.
- Core assumption: Editorial discourse follows learnable patterns that correlate with outcomes.
- Evidence anchors:
  - [abstract] "discussions leading to deletion are easier to predict"
  - [section 3.1.1] Full-text RoBERTa-Large achieves 0.58 F1 on Wikipedia vs 0.52 masked; confusion matrices show clearer separation for deletion outcomes than keep/merge
  - [corpus] Related work on Wikipedia content governance suggests deletion decisions follow more structured deliberation patterns
- Break condition: If discussion quality degrades significantly (e.g., automated/AI-generated comments dominate), patterns may shift outside training distribution.

### Mechanism 2
- Claim: Self-reported stance tags provide noisy rather than definitive signals.
- Mechanism: Users explicitly tag positions (keep/delete/redirect), but their comments often express deliberation or hesitation. This tag-text mismatch reduces tag informativeness for classifiers.
- Core assumption: Tags reflect stated intent while comments contain actual reasoning; these can diverge.
- Evidence anchors:
  - [abstract] "self-produced tags (keep, delete or redirect) don't always help guiding the classifiers, presumably because of users' hesitation or deliberation"
  - [section 3.1.1] Merge decisions benefit less from full-text tags; "withdrawn" outcomes confuse with "keep"; speedy-delete/delete confusion increases in masked settings
  - [corpus] No corpus papers specifically address tag-reasoning alignment in moderation
- Break condition: If user norms shift toward terse, tag-consistent comments (e.g., through UI enforcement), tag utility would increase.

### Mechanism 3
- Claim: Cross-platform transfer succeeds because deliberation structures are shared across Wiki ecosystems.
- Mechanism: Models trained on Wikipedia generalize to Wikidata, Wikiquote, etc., because core argumentation patterns (policy citation, stance expression) transfer despite platform-specific vocabularies.
- Core assumption: Deletion discourse shares structural invariants across platforms.
- Evidence anchors:
  - [section 3.1.2] Wikipedia-trained models achieve 0.55 F1 on Wikinews (11% higher than in-domain); Wikidata-entity/property models show mutual transferability
  - [section 3.1.2] Wikiquote is an outlier—distinct discussion style, smaller editor base (474 active vs 126,324 for Wikipedia)
  - [corpus] "Machines in the Margins" review notes Wikipedia's reliance on automated bots, suggesting shared infrastructure patterns
- Break condition: Platform-specific policy vocabularies or cultural norms that diverge significantly from training domain.

## Foundational Learning

- **Concept: Multi-class text classification with imbalanced labels**
  - Why needed here: Outcome prediction involves 7+ labels (delete, keep, redirect, no-consensus, merge, speedy-keep, speedy-delete) with skewed distributions
  - Quick check question: Can you explain why macro-F1 vs weighted-F1 matters for imbalanced moderation outcomes?

- **Concept: Fine-tuning vs parameter-efficient methods (SetFit)**
  - Why needed here: SetFit uses contrastive learning on sentence embeddings + logistic regression, achieving competitive results with 100 examples vs full fine-tuning
  - Quick check question: How does SetFit's pair-sampling strategy (K(K-1)/2 pairs) enable few-shot learning?

- **Concept: Masked language model scoring for domain adaptation**
  - Why needed here: Pseudo-log-likelihood analysis revealed Twitter-XLM-R's poor fit for Wiki discourse (bimodal distribution vs expected curve)
  - Quick check question: Why might a social-media-specialized model fail on structured deliberation text?

## Architecture Onboarding

- **Component map:**
  WIDE-ANALYSIS toolkit → discussion parsing → label extraction → BERT/RoBERTa/DistilBERT fine-tuning → SetFit (few-shot) → evaluation

- **Critical path:**
  1. Start with RoBERTa-Large on full-text Wikipedia outcome prediction (strongest baseline: 0.58 F1)
  2. Add SetFit experiments for low-data platforms (Wikinews: 91 discussions → SetFit achieves 0.57 vs 0.47)
  3. Extend to cross-platform transfer testing (binary keep/delete mapping)

- **Design tradeoffs:**
  - Full-text vs masked: Full-text includes explicit tags but may over-rely on them; masked tests model's reasoning capacity
  - Fine-tuning vs SetFit: Fine-tuning for data-rich platforms (Wikidata-entity: 355K discussions); SetFit for sparse platforms
  - Multi-class vs binary: Paper uses full Wikipedia label scheme (7 outcomes) but cross-platform experiments collapse to binary

- **Failure signatures:**
  - "No consensus" predictions near random (even split across delete/keep/no-consensus)
  - Speedy-delete/delete confusion in masked settings (identical discourse, different urgency signals)
  - Twitter-specialized models underperform on Wiki text (pseudo-likelihood shows bimodal distribution)

- **First 3 experiments:**
  1. Replicate RoBERTa-Large outcome prediction on Wikipedia (full-text and masked) to establish baseline
  2. Test SetFit with 100 stratified samples on Wikinews—compare against full fine-tuning
  3. Run cross-platform transfer: train on Wikipedia, evaluate on Wikidata-entity (expect ~0.63 F1 per Table 6)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is SetFit across varied datasets and multiple experimental runs compared to fully fine-tuned PLMs?
- Basis in paper: [explicit] "We leave for future work performing multiple runs to evaluate the robustness of SetFit (or other approaches based on synthetic data generation) when datasets are varied."
- Why unresolved: SetFit's strong performance on small datasets was only tested with single runs and subsampled training sets (100 examples), making it unclear whether results generalize or are sensitive to sampling variance.
- What evidence would resolve it: Multiple experimental runs across different random seeds and dataset variations, comparing SetFit's variance and mean performance against full fine-tuning baselines.

### Open Question 2
- Question: What role does tokenization play in Twitter-XLM-RoBERTa's poor performance on Wiki deletion discussions?
- Basis in paper: [explicit] "Further analysis into the role of tokenization is left for future work" regarding why Twitter-XLM-R underperforms.
- Why unresolved: The pseudo-log-likelihood analysis revealed anomalous distribution patterns suggesting generalization issues, but the specific contribution of tokenization mismatches between Twitter pretraining and Wiki discussion data was not isolated.
- What evidence would resolve it: Comparative tokenization analysis between Twitter and Wiki domains, plus experiments controlling for vocabulary overlap and subword segmentation patterns.

### Open Question 3
- Question: Should the policy label "What Wikipedia is Not" be merged with or split from related policies like "Notability" and "Not a Dictionary"?
- Basis in paper: [explicit] "It would be interesting to explore the actual differences in comments pointing to these arguably interrelated policies, which could perhaps lead to merging them or further splitting 'What Not' into others."
- Why unresolved: Confusion matrix analysis shows 'What Not' acts as an overly generic category confounded with finer-grained policies, but semantic analysis of actual comment content was not performed.
- What evidence would resolve it: Qualitative analysis of comments labeled with these policies, plus ablation studies testing merged vs. split label schemes on classification performance.

### Open Question 4
- Question: How would generative LLMs (e.g., GPT, T5, LLaMA) compare to encoder-only BERT-family models on Wiki content moderation tasks?
- Basis in paper: [inferred] "We also do not explore any other LMs except BERT-family of models" stated in Limitations.
- Why unresolved: The study only evaluated encoder models (BERT, RoBERTa, DistilBERT), leaving untested whether generative or encoder-decoder architectures might better capture the nuanced reasoning in deletion discussions.
- What evidence would resolve it: Systematic comparison of encoder-only, decoder-only, and encoder-decoder architectures across all three tasks (outcome prediction, stance detection, policy prediction) with matched parameter counts.

## Limitations
- Limited to English, Spanish, and Greek languages with no coverage of non-Latin scripts
- Wikiquote shows notably poor cross-platform transfer performance (0.45 F1), suggesting platform-specific discourse patterns may limit transfer learning
- Study relies on self-reported stance tags without validation through user studies or alternative annotation schemes

## Confidence
- **High Confidence**: RoBERTa-Large performance on Wikipedia outcome prediction (0.58 F1 in masked setting, 0.58 F1 in full-text); cross-platform transfer from Wikipedia to Wikidata-Entity/Property showing 0.55-0.63 F1
- **Medium Confidence**: Stance detection performance (0.87-0.89 F1) given the high label count (4 classes) and potential ambiguity in user comments; multilingual model performance on Spanish (0.88 F1) as it represents only one non-English language
- **Low Confidence**: Policy prediction utility (10-class classification on comments), as the paper doesn't demonstrate practical applications beyond classification accuracy; SetFit performance claims for low-data scenarios (Wikinews, Wikiquote) due to limited test samples (91-474 discussions)

## Next Checks
1. Replicate the masked setting performance on Wikipedia with different random seeds to assess stability of the 0.58 F1 baseline and verify that the "speedy delete" vs "delete" confusion pattern persists
2. Conduct ablation study removing self-reported tags entirely to quantify their actual contribution versus the authors' inference that tags are "noisy"
3. Test cross-platform transfer in reverse direction (train on Wikidata, test on Wikipedia) to verify symmetry assumptions and identify which platform's discourse patterns are most generalizable