---
ver: rpa2
title: 'Sysformer: Safeguarding Frozen Large Language Models with Adaptive System
  Prompts'
arxiv_id: '2506.15751'
source_url: https://arxiv.org/abs/2506.15751
tags:
- prompt
- prompts
- sysformer
- system
- safe
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Sysformer is a method for improving safety in large language models
  without retraining. It adapts the system prompt based on the user input by learning
  to transform the system prompt embedding using a transformer architecture.
---

# Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts

## Quick Facts
- arXiv ID: 2506.15751
- Source URL: https://arxiv.org/abs/2506.15751
- Authors: Kartik Sharma; Yiqiao Jin; Vineeth Rakesh; Yingtong Dou; Menghai Pan; Mahashweta Das; Srijan Kumar
- Reference count: 40
- Sysformer is a method for improving safety in large language models without retraining

## Executive Summary
Sysformer introduces a novel approach to enhancing safety in frozen large language models (LLMs) by adapting system prompts based on user input. The method learns to transform system prompt embeddings using a transformer architecture, allowing the frozen LLM to refuse harmful prompts while complying with safe ones. This approach achieves significant improvements in safety alignment without requiring model retraining or fine-tuning.

## Method Summary
Sysformer works by learning to transform system prompt embeddings using a transformer architecture. The transformed system prompt is then fed to a frozen LLM along with the user prompt. The method is trained to optimize for refusing harmful prompts while maintaining compliance with safe ones. By leveraging the frozen LLM's existing capabilities and only modifying the system prompt, Sysformer provides a computationally efficient and practical approach to safety alignment that can be applied to various pre-trained models.

## Key Results
- Increases refusal rate on harmful prompts by up to 80% across five LLMs
- Reduces refusal rate on safe prompts by up to 90%
- Improves robustness against sophisticated jailbreaking attacks by up to 100% when augmented with attack examples during training

## Why This Works (Mechanism)
Sysformer leverages the observation that system prompts significantly influence LLM behavior. By learning to adapt these prompts based on user input context, the method can steer the frozen model's responses toward safer outputs without modifying the underlying model parameters. The transformer architecture learns to encode safety-relevant patterns in the transformation process, effectively creating a lightweight safety alignment layer that operates at the prompt level.

## Foundational Learning

1. **System Prompt Influence** - System prompts guide LLM behavior through framing and context
   - Why needed: Understanding how prompts control model outputs is essential for safety alignment
   - Quick check: Test model responses with different system prompt variations

2. **Prompt Engineering** - Strategic prompt construction can elicit desired behaviors from LLMs
   - Why needed: Forms the basis for steering model behavior without retraining
   - Quick check: Compare model outputs across different prompt formulations

3. **Transformer Architectures** - Deep learning models that process sequential data using attention mechanisms
   - Why needed: Core technology enabling the system prompt transformation
   - Quick check: Verify transformer layer operations on sample embeddings

## Architecture Onboarding

**Component Map:** User Input -> Input Encoder -> Transformer Adapter -> Transformed System Prompt -> Frozen LLM -> Output

**Critical Path:** User Input → Input Encoder → Transformer Adapter → Transformed System Prompt → Frozen LLM

**Design Tradeoffs:** 
- Frozen LLM vs. fine-tuning: Maintains original capabilities but limits safety improvements to prompt level
- System prompt adaptation vs. model retraining: Computationally efficient but potentially less comprehensive
- Transformer adapter complexity vs. real-time performance: Balances safety gains with inference speed

**Failure Signatures:**
- Over-refusal on safe prompts indicates excessive safety constraints
- Under-refusal on harmful prompts suggests inadequate safety transformation
- Inconsistent behavior across similar inputs points to transformer adapter instability

**First Experiments:**
1. Test basic functionality with simple safe and harmful prompts to verify refusal behavior
2. Measure performance on held-out safe prompts to assess false positive rates
3. Evaluate robustness against basic adversarial prompt variations

## Open Questions the Paper Calls Out
None

## Limitations
- Primary limitation is reliance on frozen LLMs, constraining safety improvements to system prompt adaptation
- Evaluation focuses on two specific benchmarks and five LLMs, potentially limiting generalizability
- Robustness against zero-shot novel attacks remains unclear despite augmentation with attack examples

## Confidence
- **High confidence** in the core methodology of using transformer-based system prompt adaptation
- **Medium confidence** in reported performance metrics due to limited benchmark and model scope
- **Medium confidence** in generalization claims, as augmentation with attack examples provides empirical evidence but may not capture all real-world scenarios

## Next Checks
1. Evaluate Sysformer's performance across a broader range of safety benchmarks and diverse LLM architectures
2. Test the method's robustness against zero-shot novel jailbreaking attacks and compare with state-of-the-art safety alignment techniques
3. Investigate potential side effects on non-safety-related capabilities by measuring performance degradation in general tasks