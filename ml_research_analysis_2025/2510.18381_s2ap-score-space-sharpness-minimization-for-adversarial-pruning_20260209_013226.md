---
ver: rpa2
title: 'S2AP: Score-space Sharpness Minimization for Adversarial Pruning'
arxiv_id: '2510.18381'
source_url: https://arxiv.org/abs/2510.18381
tags:
- s2ap
- pruning
- sparsity
- adversarial
- sharpness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces S2AP, a method to improve adversarial pruning
  by minimizing score-space sharpness. Adversarial pruning methods often suffer from
  unstable mask selection due to sharp local minima in the robust loss landscape when
  optimizing importance scores.
---

# S2AP: Score-space Sharpness Minimization for Adversarial Pruning

## Quick Facts
- arXiv ID: 2510.18381
- Source URL: https://arxiv.org/abs/2510.18381
- Reference count: 40
- Primary result: Improves adversarial pruning robustness by up to 2 percentage points with negligible clean accuracy drop

## Executive Summary
This paper introduces S2AP, a method to improve adversarial pruning by minimizing score-space sharpness. Adversarial pruning methods often suffer from unstable mask selection due to sharp local minima in the robust loss landscape when optimizing importance scores. S2AP addresses this by perturbing importance scores and minimizing the corresponding robust loss, thereby stabilizing the pruning process and improving robustness. Experiments across multiple datasets, models, and sparsity levels show that S2AP consistently improves robust accuracy by up to 2 percentage points with negligible drops in clean accuracy. It also demonstrates reduced sharpness in the score-space landscape and improved mask stability, as measured by lower Hamming distances between pruning masks across epochs.

## Method Summary
S2AP is a plug-in method that can be integrated into existing score-based adversarial pruning pipelines. It operates during the mask selection phase by perturbing importance scores (which determine the binary mask) and minimizing the resulting robust loss. This encourages flat minima in the score-space landscape, making the optimization less sensitive to small score fluctuations that cause volatile mask changes. The method involves generating adversarial examples, computing a gradient-based perturbation on the scores (bounded by γ), and updating the scores at the perturbed point. After pruning, an optional finetuning step applies adversarial weight perturbations to the non-pruned weights, aligning with the sharpness minimization principle.

## Key Results
- S2AP improves robust accuracy by up to 2 percentage points across CIFAR-10, SVHN, and ImageNet
- Reduces score-space sharpness as measured by lower λ_max eigenvalues
- Improves mask stability with lower normalized Hamming distances between pruning masks across epochs
- Adds ~10-20% computational overhead compared to baseline pruning methods

## Why This Works (Mechanism)

### Mechanism 1: Score-Space Sharpness Minimization
S2AP improves adversarial pruning by stabilizing mask selection through sharpness minimization in the score-space, not weight-space. The method perturbs importance scores (which determine the binary mask) and minimizes the resulting robust loss. By encouraging flat minima in this score-space landscape, the optimization becomes less sensitive to small score fluctuations that cause volatile mask changes. Core assumption: A flatter score-space landscape implies that mask selection is less sensitive to small score perturbations, leading to more stable and robust pruning. Evidence: S2AP consistently results in improved robust accuracy and reduced score-space sharpness. Break condition: If the score-space loss landscape does not exhibit sharp minima that cause instability, this mechanism's benefit would diminish.

### Mechanism 2: Mask Stability via Hamming Distance Reduction
Flatter score-space directly translates to a more stable mask search, reducing volatility in selected weights across epochs. By finding flatter regions in score-space, small perturbations in importance scores during optimization are less likely to cause large changes in the ranking of scores, preserving the set of top-k weights selected. Core assumption: A more stable mask, as measured by lower Hamming distance between masks across epochs, leads to better final robustness. Evidence: S2AP demonstrates reduced normalized Hamming distances between pruning masks across epochs. Break condition: If mask stability is not a good proxy for final robustness or if the original method's mask instability is not a primary cause of poor robustness, this mechanism would not explain the performance gains.

### Mechanism 3: Finetuning Objective Alignment
Finetuning the pruned model with a weight-space sharpness minimization objective aligned with the S2AP pruning principle provides complementary benefits. The proposed finetuning step applies adversarial weight perturbations (AWP) only to the non-pruned weights defined by the S2AP mask, continuing the sharpness minimization theme in weight-space for final refinement. Core assumption: Aligning the finetuning objective with the pruning-stage sharpness minimization principle provides a complementary benefit. Evidence: The full S2AP pipeline (pruning + aligned finetuning) achieves the best results, though primary gains appear from the pruning stage. Break condition: If the finetuning objective does not interact positively with the S2AP-found mask, or if standard finetuning is just as effective, this specific alignment is not a key driver of performance.

## Foundational Learning

- **Concept: Sharpness-Aware Minimization (SAM)**
  - Why needed here: S2AP is a direct extension of SAM principles, but applied to the *importance scores* during pruning rather than the model weights during training. Understanding SAM's goal (finding flat minima) is crucial to understanding S2AP's objective.
  - Quick check question: What is the core intuition behind why flat minima in a loss landscape are desirable for generalization?

- **Concept: Adversarial Pruning and Importance Scores**
  - Why needed here: S2AP is designed as a "plug-in" method for existing score-based adversarial pruning pipelines (like HARP, HYDRA). One must understand the standard three-step pipeline (pretrain, select mask, finetune) and how importance scores are used to relax the discrete mask selection problem.
  - Quick check question: In a score-based pruning method, how are the continuous importance scores converted into a binary pruning mask?

- **Concept: Robust Loss and Adversarial Training**
  - Why needed here: The entire S2AP framework is built on minimizing a *robust* loss, not just standard cross-entropy. Understanding the robust loss formulation, which involves an inner maximization for adversarial attack generation, is fundamental.
  - Quick check question: How does the robust loss differ from a standard classification loss, and what does the inner maximization represent?

## Architecture Onboarding

- **Component map:** Pretrained robust model -> Score initialization -> S2AP pruning loop (PGD adv examples, score perturbation, robust loss minimization) -> Binary mask extraction -> S2AP finetuning (AWP on non-pruned weights) -> Final pruned robust model
- **Critical path:** The core S2AP logic is the inner loop within the pruning epochs. The gradient is computed at the *perturbed* scores, but the *actual* scores are updated and restored. The hyperparameter γ is critical as it controls the magnitude of the perturbation.
- **Design tradeoffs:**
  - Perturbation magnitude (γ): A value too small may not provide the sharpness-minimizing benefit; a value too large may destabilize training. This is a key hyperparameter to tune.
  - Overhead: S2AP introduces a ~10-20% computational overhead compared to the original pruning method.
  - Integration: S2AP is a plug-in method. It can be added to any score-based AP method without changing its core loss formulation, but it requires access to and the ability to modify the score optimization loop.
- **Failure signatures:**
  - Instability or NaNs during training: This could be caused by a poorly chosen γ leading to excessively large perturbations.
  - No robustness improvement: This could indicate that the pruning method's original instability was not the primary bottleneck, or that the chosen γ is not effective for the model/dataset.
  - Large drop in clean accuracy: While S2AP is shown to have a negligible impact, any aggressive regularization technique carries a risk of overly smoothing the loss landscape at the cost of fitting the training data.
- **First 3 experiments:**
  1. Baseline Reproduction & Integration: Reproduce the robust accuracy of a baseline method like HARP on ResNet18/CIFAR10 at 80% sparsity. Then, integrate S2AP into the HARP pruning loop using the γ value from the paper (γ=0.001) and measure the change in robust and clean accuracy.
  2. Hyperparameter Sensitivity: Perform a sweep of the γ parameter (e.g., {0.0005, 0.001, 0.002, 0.005}) for a single model/dataset/sparsity combination. Plot the final robust accuracy to verify the paper's claim of a single optimal value and understand its sensitivity.
  3. Ablation on Finetuning: For the best-performing γ, run two versions: one with standard finetuning and one with the S2AP-aligned finetuning. Compare the results to isolate the contribution of the finetuning objective alignment.

## Open Questions the Paper Calls Out

### Open Question 1
Can "cheaper" sharpness-aware minimization approaches be adapted to S2AP to reduce the computational overhead inherent in SAM-like objectives? The current S2AP implementation adds an average 15% computational overhead, which might be unsustainable in specific application scenarios. A modified S2AP algorithm that achieves comparable robustness accuracy with significantly lower training time per epoch would resolve this.

### Open Question 2
How can adversarial pruning methods and S2AP be systematically adapted to handle the architectural complexities of modern, large-scale Transformers? Standard AP pipelines often rely on layer-wise sparsity optimizations that are not directly suited for Transformer-specific structures like attention heads. A revised AP pipeline that robustly handles attention mechanisms without manual architectural re-thinking, validated on modern Transformer benchmarks, would resolve this.

### Open Question 3
Can the perturbation scaling factor γ be determined adaptively rather than through a manual grid search? A fixed γ requires tuning for every new model-dataset combination, limiting "plug-in" usability. A dynamic adjustment mechanism for γ based on score distributions or loss landscape curvature that removes the need for external hyperparameter tuning would resolve this.

## Limitations
- The precise role of score-space flatness as a causal mechanism for improved robustness remains empirically demonstrated but theoretically underspecified
- The hyperparameter γ requires careful tuning per architecture/dataset, with no general prescription for selecting it
- The paper does not explore whether S2AP's benefits extend to non-score-based pruning methods or to robustness against other threat models (ℓ₂, ℓ₁ attacks)

## Confidence
- **High confidence** in the empirical observation that S2AP consistently improves robust accuracy (1-2 percentage points) across multiple datasets and sparsity levels while maintaining clean accuracy
- **Medium confidence** in the mechanism that score-space sharpness minimization stabilizes mask selection, as the theoretical justification is sound but the direct causal link to robustness is not fully established
- **Medium confidence** in the finetuning objective alignment providing complementary benefits, as the ablation shows some improvement but the primary gains appear to come from the pruning stage itself

## Next Checks
1. **Causal mechanism test:** Compare S2AP against a variant that optimizes scores but does not explicitly minimize sharpness (e.g., using standard score updates without perturbation). This would isolate whether flatness itself or simply better optimization drives the gains.
2. **Generalization test:** Apply S2AP to a non-score-based pruning method (e.g., one that directly optimizes for robustness) to determine if the sharpness minimization principle is universally beneficial or specific to the score-based relaxation.
3. **Robustness generalization test:** Evaluate S2AP-pruned models against non-ℓ∞ attacks (ℓ₂ PGD, Carlini-Wagner) to determine if the robustness improvements transfer across threat models or are specific to the training objective.