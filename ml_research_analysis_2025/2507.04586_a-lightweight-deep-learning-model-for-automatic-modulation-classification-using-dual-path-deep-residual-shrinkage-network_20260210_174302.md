---
ver: rpa2
title: A Lightweight Deep Learning Model for Automatic Modulation Classification using
  Dual Path Deep Residual Shrinkage Network
arxiv_id: '2507.04586'
source_url: https://arxiv.org/abs/2507.04586
tags:
- classification
- modulation
- accuracy
- signal
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of creating efficient automatic
  modulation classification (AMC) models for resource-constrained edge devices. The
  authors propose a lightweight deep learning model using a dual-path deep residual
  shrinkage network (DP-DRSN) with Garrote thresholding for signal denoising, combined
  with a compact hybrid CNN-LSTM architecture.
---

# A Lightweight Deep Learning Model for Automatic Modulation Classification using Dual Path Deep Residual Shrinkage Network

## Quick Facts
- arXiv ID: 2507.04586
- Source URL: https://arxiv.org/abs/2507.04586
- Authors: Prakash Suman; Yanzhen Qu
- Reference count: 40
- Average classification accuracy: 61.20-63.78% across three datasets with only 27,000 parameters

## Executive Summary
This paper addresses the challenge of creating efficient automatic modulation classification (AMC) models for resource-constrained edge devices. The authors propose a lightweight deep learning model using a dual-path deep residual shrinkage network (DP-DRSN) with Garrote thresholding for signal denoising, combined with a compact hybrid CNN-LSTM architecture. The model achieves average classification accuracies of 61.20%, 63.78%, and 62.13% on the RML2016.10a, RML2016.10b, and RML2018.01a datasets respectively, while maintaining only 27,000 training parameters. This represents a strong balance between model efficiency and classification performance, making it suitable for deployment on edge devices with limited computational resources.

## Method Summary
The proposed DP-DRSN model combines a hybrid CNN-LSTM feature extractor with a novel dual-path residual shrinkage network for denoising. The architecture processes dual inputs (I/Q and A/P representations) through asymmetric convolutional layers and a small LSTM layer, then passes features through four stacked DP-DRSN blocks that apply Garrote thresholding for adaptive denoising. The model uses Adam optimizer with learning rate scheduling and early stopping, trained on synthetic RML datasets with varying signal-to-noise ratios. The key innovation is the dual-path threshold estimation using both global average and maximum pooling, combined with Garrote thresholding to reduce bias in signal coefficient estimation.

## Key Results
- Achieves 61.20% average accuracy on RML2016.10a (11 classes) with 27,000 parameters
- Reaches 63.78% average accuracy on RML2016.10b (10 classes) with 27,000 parameters
- Obtains 62.13% average accuracy on RML2018.01a (24 classes) with 27,000 parameters
- DP-DRSN outperforms SP-DRSN (GAP-only) by 1.7% accuracy
- Garrote thresholding provides 2.2% improvement over soft thresholding in noisy conditions (-4dB to 6dB SNR)

## Why This Works (Mechanism)

### Mechanism 1: Garrote Thresholding Bias Reduction
Garrote thresholding reduces estimation bias compared to soft thresholding by scaling input coefficients inversely proportional to x². For large coefficients (θ > τ), Garrote's bias is τ²/θ versus soft thresholding's constant τ, yielding lower MSE when signal components are sparse and bursty. This preserves large-magnitude signal coefficients more accurately in noisy wireless signals.

### Mechanism 2: Dual-Path Threshold Estimation
The dual-path threshold estimation using both Global Average Pooling (GAP) and Global Maximum Pooling (GMP) captures complementary noise statistics. GAP captures average contextual information while GMP captures prominent high-amplitude features signaling transient noise. A learnable convex combination optimizes the blend via backpropagation, enabling adaptive denoising across heterogeneous SNR conditions.

### Mechanism 3: Hybrid CNN-LSTM Feature Extraction
The hybrid CNN-LSTM architecture with asymmetric convolutions (3×1 and 1×3) and dual I/Q + A/P inputs captures complementary spatiotemporal characteristics while minimizing parameter count. LSTM extracts temporal features while asymmetric CNN filters decompose spatial features horizontally and vertically, reducing parameters versus standard 3×3 convolutions. Dilation expands receptive field without added computation.

## Foundational Learning

- **Concept**: In-phase/Quadrature (I/Q) signal representation
  - **Why needed here**: All input features derive from I/Q baseband signals (2×N matrix). Understanding I/Q is prerequisite to grasping A/P transformation and dual-path input strategy.
  - **Quick check question**: Given I = 0.6 and Q = 0.8, what are the corresponding amplitude A and phase P values?

- **Concept**: Thresholding in wavelet denoising (soft vs. hard vs. Garrote)
  - **Why needed here**: The core innovation is Garrote thresholding in DP-DRSN. Without understanding thresholding fundamentals, the bias-MSE tradeoff argument is opaque.
  - **Quick check question**: For input x = 5 and threshold τ = 2, compute soft thresholding output and Garrote output. Which has lower bias if true coefficient θ = 4.8?

- **Concept**: Recurrent neural networks for sequential data (LSTM basics)
  - **Why needed here**: LSTM extracts temporal features from signal sequences. Understanding why LSTM handles temporal dependencies better than vanilla RNNs clarifies architectural choices.
  - **Quick check question**: Why does LSTM maintain both a hidden state and a cell state, and how does this help with long-term dependencies in signal sequences?

## Architecture Onboarding

- **Component map**: Input → Feature extraction (LSTM + CNN) → 4-layer DP-DRSN denoiser → BatchNorm → ReLU → GAP → Dense → SoftMax

- **Critical path**: Input → feature extraction → DP-DRSN denoising (4 layers) → feature concatenation (I/Q + A/P paths) → GAP → classifier → SoftMax output. The denoiser block's threshold computation (κ, γ learning) is the differentiating component.

- **Design tradeoffs**:
  - DP-DRSN vs. SP-DRSN: DP adds ~2,800 parameters (27k vs. 24.8k) for 1.7% accuracy gain
  - Garrote vs. soft thresholding: Garrote improves accuracy 62.13% → 61.79% without it; 2.2% improvement at -4dB to 6dB SNR
  - Dual I/Q + A/P vs. I/Q only: Adds computational path but captures explicit amplitude/phase
  - 4 LSTM units: Very small—trades temporal modeling capacity for parameter efficiency

- **Failure signatures**:
  - Accuracy plateaus at low SNR (<-10dB): Expected behavior; denoising cannot recover signals buried in noise
  - Training loss doesn't decrease: Check learning rate scheduling and EarlyStopping patience
  - Garrote thresholding produces NaN: Division by zero mitigated by adding 1e-6 to denominator
  - κ or γ stuck at boundary values: May indicate learning rate too high or initialization poor

- **First 3 experiments**:
  1. Baseline reproduction: Train on RML2016.10a with default hyperparameters. Target: ~61% average accuracy, ~91% max accuracy.
  2. Ablation—SP-DRSN vs. DP-DRSN: Replace DP-DRSN with SP-DRSN. Expect ~1.7% accuracy drop on RML2018.01a.
  3. Thresholding comparison: Swap Garrote for soft thresholding. Expect small overall drop but notable degradation at -4dB to 6dB range.

## Open Questions the Paper Calls Out

- **How can advanced lightweight AMC models be designed to optimize the trade-off between classification accuracy and model complexity for resource-constrained edge devices?**
  - Basis: Section III.C explicitly identifies this as the primary research question
  - Why unresolved: Complexity reduction often compromises accuracy, suggesting the optimal balance is ongoing
  - Resolution evidence: A model architecture that surpasses current state-of-the-art accuracy (>64% on RML2018.01a) while maintaining parameter count below 27k

- **How does the proposed DP-DRSN model perform when trained and evaluated on real-world signal data compared to synthesized datasets?**
  - Basis: Section VI.B states future studies should focus on real-world datasets
  - Why unresolved: Synthetic datasets may not fully represent physical environments
  - Resolution evidence: Benchmark results on standardized OTA (over-the-air) recorded signals

- **Can advanced pruning or quantization techniques further reduce the energy consumption and FLOPs of the lightweight AMC model without compromising recognition accuracy?**
  - Basis: Section VI.B explicitly recommends exploring model compression
  - Why unresolved: The proposed model achieves low complexity but further reductions are necessary for strict edge deployment
  - Resolution evidence: Implementation of quantization or pruning resulting in lower energy usage with negligible accuracy degradation

## Limitations

- Model accuracy (62.13% on 24 classes) remains significantly below state-of-the-art deep models, suggesting accuracy-efficiency tradeoff
- Garrote thresholding mechanism lacks empirical validation from corpus literature specifically for AMC applications
- Dual I/Q + A/P input strategy adds computational overhead without clear evidence that benefits outweigh cost
- Extremely small LSTM (4 units) may be insufficient for capturing complex temporal dependencies in 1024-sample sequences

## Confidence

- **High confidence**: The model achieves reported parameter efficiency (27,000 parameters) and demonstrates improved accuracy over basic thresholding approaches
- **Medium confidence**: Garrote thresholding provides measurable benefits, particularly in noisy conditions (-4dB to 6dB SNR range)
- **Low confidence**: Claim of suitability for edge devices lacks hardware-specific validation; effectiveness of 4-unit LSTM for 1024-sample sequences is questionable

## Next Checks

1. **Hardware profiling validation**: Deploy the trained model on representative edge hardware (Raspberry Pi 4, Jetson Nano) and measure actual inference latency, power consumption, and memory usage. Compare against reported 0.14-1.04ms/sample to verify practical deployability claims.

2. **Ablation on LSTM capacity**: Systematically vary the LSTM unit count (4, 8, 16, 32) while keeping other parameters constant to determine if current 4-unit configuration is optimal or unnecessarily restrictive. Measure accuracy and parameter count trade-offs across all three datasets.

3. **Cross-dataset generalization**: Test the trained model on cross-dataset scenarios (train on RML2016.10a, test on RML2018.01a) to evaluate robustness to different SNR distributions, bandwidths, and sampling rates. This would validate whether the model learns generalizable modulation features versus dataset-specific patterns.